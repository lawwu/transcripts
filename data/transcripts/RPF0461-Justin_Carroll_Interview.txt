
[00:00:00.000 --> 00:00:05.240]   Welcome to Radical Personal Finance, the show dedicated to providing you with the knowledge,
[00:00:05.240 --> 00:00:10.360]   skills, insight, and encouragement you need to live a rich and meaningful life now while
[00:00:10.360 --> 00:00:12.760]   building a plan for financial freedom in 10 years or less.
[00:00:12.760 --> 00:00:18.240]   My name is Joshua, and today I'm thrilled to have a guest named Justin Carroll.
[00:00:18.240 --> 00:00:23.320]   Justin is the author of various books on privacy and security, the co-author of an excellent
[00:00:23.320 --> 00:00:28.440]   book called The Complete Privacy and Security Desk Reference, and also the co-host of The
[00:00:28.440 --> 00:00:30.480]   Complete Privacy and Security Podcast.
[00:00:30.480 --> 00:00:32.800]   Justin, welcome to Radical Personal Finance.
[00:00:32.800 --> 00:00:35.120]   Joshua, thank you so much for having me on.
[00:00:35.120 --> 00:00:36.240]   It's great to be here.
[00:00:36.240 --> 00:00:37.400]   Really glad to have you here.
[00:00:37.400 --> 00:00:42.080]   I was introduced to your work by a listener of mine, and privacy, especially financial
[00:00:42.080 --> 00:00:44.960]   privacy, has long been an interest of mine.
[00:00:44.960 --> 00:00:52.680]   But I've often found that the information in the space was either very cursory or not
[00:00:52.680 --> 00:00:54.160]   particularly up to date.
[00:00:54.160 --> 00:00:59.120]   And when I found the work that you and your business partner, Mike, are making, I was
[00:00:59.120 --> 00:01:02.840]   deeply impressed, and I've become a big fan of yours in the meantime.
[00:01:02.840 --> 00:01:07.440]   So in today's show, I want to outline and really just give you the floor to talk about
[00:01:07.440 --> 00:01:09.000]   privacy and security.
[00:01:09.000 --> 00:01:13.300]   Before I give you the microphone, I want to just lay the foundation that I see and why
[00:01:13.300 --> 00:01:16.420]   this is so important in the context of personal finance.
[00:01:16.420 --> 00:01:22.160]   In finance, there are a few different aspects wherein the discussion of financial privacy
[00:01:22.160 --> 00:01:28.880]   make a big, big impact, especially in the areas of asset protection, especially in the
[00:01:28.880 --> 00:01:34.220]   areas of business and the ability to protect yourself from potential harm.
[00:01:34.220 --> 00:01:38.420]   And one of the major concerns that I have is that, in general, people don't think about
[00:01:38.420 --> 00:01:39.920]   these things in advance.
[00:01:39.920 --> 00:01:43.860]   They usually only start thinking about things when they get a call from the lawyer or they
[00:01:43.860 --> 00:01:47.880]   start thinking about them when all of a sudden the police have shown up on the front door
[00:01:47.880 --> 00:01:49.960]   asking questions, et cetera.
[00:01:49.960 --> 00:01:54.960]   And so I believe that it's part of prudent planning to put in place some good safeguards
[00:01:54.960 --> 00:01:58.640]   with regard to your own financial privacy and security.
[00:01:58.640 --> 00:01:59.640]   So kick us off.
[00:01:59.640 --> 00:02:03.840]   Tell us about your background and how you first started to become interested in the
[00:02:03.840 --> 00:02:05.800]   topic of privacy and security.
[00:02:05.800 --> 00:02:11.600]   Well, I initially became interested, I come from a military background, and after I got
[00:02:11.600 --> 00:02:18.260]   out of the military, I spent several years going overseas as a contractor with another
[00:02:18.260 --> 00:02:24.680]   government agency, and I realized pretty quickly that privacy was kind of important.
[00:02:24.680 --> 00:02:30.160]   I had to give out my name and home address and next of kin information on various visa
[00:02:30.160 --> 00:02:34.880]   applications to countries that maybe aren't necessarily friendly to the U.S. and that
[00:02:34.880 --> 00:02:36.440]   kind of got the gears turning.
[00:02:36.440 --> 00:02:41.460]   And then a few years later, I spent about five years teaching a special operations course
[00:02:41.460 --> 00:02:50.340]   at one of the special operations courses for the U.S. military, and SOCOM was kind of grappling,
[00:02:50.340 --> 00:02:54.780]   the special operations command was kind of grappling with this issue, this emerging issue
[00:02:54.780 --> 00:02:57.440]   of identity management.
[00:02:57.440 --> 00:03:01.500]   And I was fortunate enough to be one of the instructors for that and kind of got to develop
[00:03:01.500 --> 00:03:02.500]   my own curriculum.
[00:03:02.500 --> 00:03:05.240]   And that's what really got the ball rolling.
[00:03:05.240 --> 00:03:10.680]   And then I met my partner, Michael Basil, who his big specialty is open source intelligence,
[00:03:10.680 --> 00:03:16.280]   which is finding everything there is to find about a person online just through really
[00:03:16.280 --> 00:03:20.560]   good Google searches and the things you put on Facebook and things like that.
[00:03:20.560 --> 00:03:23.160]   And between the two of us, we kind of put our heads together.
[00:03:23.160 --> 00:03:26.060]   He had a big interest in the privacy side as well.
[00:03:26.060 --> 00:03:30.600]   And this thing, some would say maybe has gotten a little bit out of control, where maybe a
[00:03:30.600 --> 00:03:33.720]   little bit to foil hat and paranoid.
[00:03:33.720 --> 00:03:37.980]   But that's kind of what got me started down this road.
[00:03:37.980 --> 00:03:40.480]   And it's turned into a big personal interest, big personal hobby.
[00:03:40.480 --> 00:03:44.620]   And I'm not saying that everyone has to take it to the level that Michael and I have taken
[00:03:44.620 --> 00:03:46.740]   it to, but that's where it came from.
[00:03:46.740 --> 00:03:53.680]   I used to pull back from talking about things that sounded outlandish and tinfoil hat approach
[00:03:53.680 --> 00:03:55.280]   in various subjects.
[00:03:55.280 --> 00:03:57.440]   But I've actually come to terms, I've come to peace with it.
[00:03:57.440 --> 00:03:59.800]   And I've realized this.
[00:03:59.800 --> 00:04:04.660]   Almost everybody seems to love watching Jason Bourne movies.
[00:04:04.660 --> 00:04:08.160]   And the reason they love it is just because he's such a far out character.
[00:04:08.160 --> 00:04:13.140]   And so there's tremendous value in having people who take things to the extreme, because
[00:04:13.140 --> 00:04:17.840]   I feel it has more of an influence on moving people a little bit than oftentimes people
[00:04:17.840 --> 00:04:20.220]   who just do a few things here.
[00:04:20.220 --> 00:04:26.400]   It's often fun to have a Jason Bourne character out on the extreme fringe who can be inspiring
[00:04:26.400 --> 00:04:31.600]   and kind of brings that sexy side of things to a discussion.
[00:04:31.600 --> 00:04:38.200]   So we're going to start with mainstream stuff, but I think it's extremely valuable to talk
[00:04:38.200 --> 00:04:41.760]   about the far out techniques so that people are aware of them.
[00:04:41.760 --> 00:04:47.280]   When you look at financial privacy, how do you factor into your thinking a specific focus
[00:04:47.280 --> 00:04:53.520]   of general privacy versus specifically financial privacy?
[00:04:53.520 --> 00:04:55.960]   There's a lot of overlap between the two.
[00:04:55.960 --> 00:05:00.040]   I'm kind of of the school of thought that there is no privacy without security and there
[00:05:00.040 --> 00:05:01.680]   is no security without privacy.
[00:05:01.680 --> 00:05:05.040]   If you can get into my email account, that's a security issue, right?
[00:05:05.040 --> 00:05:09.440]   If I have a poor password and no two factor authentication in there and you get into my
[00:05:09.440 --> 00:05:15.280]   primary Gmail account that holds everything, that's a security breach that's happened,
[00:05:15.280 --> 00:05:21.160]   but it affects my privacy deeply because now that you're in there, you have access to all
[00:05:21.160 --> 00:05:26.840]   the bank accounts, any financial account or any other kind of account that I've authenticated
[00:05:26.840 --> 00:05:30.280]   using that Gmail account as a point of contact for.
[00:05:30.280 --> 00:05:35.080]   So these things all kind of tied together and this, you know, we talk about the tinfoil
[00:05:35.080 --> 00:05:42.320]   hat stuff, but it wouldn't exist without the, the, without brilliance in the basics, without
[00:05:42.320 --> 00:05:46.080]   being very, very good at these baseline level privacy and security things.
[00:05:46.080 --> 00:05:54.000]   So I think everyone, whether you intend to take this to the furthest possible extreme,
[00:05:54.000 --> 00:05:58.640]   or if you just want to be a little bit more financially secure and financially private,
[00:05:58.640 --> 00:06:02.400]   you should consider those baseline level security measures.
[00:06:02.400 --> 00:06:07.960]   And you know, I know our talk is not primarily around security, but I'm, I'm a firm believer
[00:06:07.960 --> 00:06:13.280]   that you can't have one without the other and you, you have to take those initial steps.
[00:06:13.280 --> 00:06:19.200]   And just generally speaking, the advice I kind of give to everyone, um, and these are
[00:06:19.200 --> 00:06:25.760]   not financial specific, but they do deeply impact financial privacy is use good passwords.
[00:06:25.760 --> 00:06:27.960]   And to do that, you have to use a password manager.
[00:06:27.960 --> 00:06:32.160]   You need to use a different password on every account that you have.
[00:06:32.160 --> 00:06:36.040]   And if possible, a different username, because that influences your attack surface.
[00:06:36.040 --> 00:06:40.680]   If I know your username, I know where to start attacking your account.
[00:06:40.680 --> 00:06:43.920]   If however, you have set up a completely random username.
[00:06:43.920 --> 00:06:46.640]   I don't even have a good starting point for that.
[00:06:46.640 --> 00:06:50.240]   Um, two factor authentication is another thing.
[00:06:50.240 --> 00:06:56.040]   So the way we implement this, I go to my bank account, I enter my username, I enter my password,
[00:06:56.040 --> 00:06:59.720]   I hit log in and it presents me with a second screen that says, go ahead and enter your
[00:06:59.720 --> 00:07:02.040]   two factor authentication token.
[00:07:02.040 --> 00:07:05.160]   And maybe that's an app on my smartphone that displays a code.
[00:07:05.160 --> 00:07:08.740]   Maybe that's a text message sent to me, or maybe that's something else.
[00:07:08.740 --> 00:07:14.000]   But those are kind of those baseline level things that I would absolutely recommend doing
[00:07:14.000 --> 00:07:20.560]   for every single listener of, of your podcast or any other podcast is protect your accounts
[00:07:20.560 --> 00:07:26.760]   because that front end really is your biggest attack surface and possibly your weakest,
[00:07:26.760 --> 00:07:28.280]   your biggest potential point of failure.
[00:07:28.280 --> 00:07:34.680]   One of the things I most appreciate about your work is you've given me a vocabulary
[00:07:34.680 --> 00:07:39.640]   with your personal taxonomy of the realm of privacy and security.
[00:07:39.640 --> 00:07:43.400]   I didn't have the vocabulary to apply.
[00:07:43.400 --> 00:07:47.440]   And I really appreciate when you use things like attack surface, it's really, really helpful
[00:07:47.440 --> 00:07:50.560]   to me to do that and to know that.
[00:07:50.560 --> 00:07:56.160]   And just a couple of practical examples, as I understand what you're saying, when you
[00:07:56.160 --> 00:08:01.520]   have the same email address that you use constantly for every account, every social media account,
[00:08:01.520 --> 00:08:05.920]   every personal interaction, every business interaction, et cetera, that social, that
[00:08:05.920 --> 00:08:12.500]   email account is prominent and common across basically all over the web.
[00:08:12.500 --> 00:08:17.500]   So if there is a data breach from some random company that you do business with, which it's
[00:08:17.500 --> 00:08:21.140]   my opinion that in the fullness of time, every company that you do business with will have
[00:08:21.140 --> 00:08:22.380]   a data breach.
[00:08:22.380 --> 00:08:26.160]   Then now that email address is sold on the black market and that email address can be
[00:08:26.160 --> 00:08:30.520]   used by somebody and various combinations of it tried.
[00:08:30.520 --> 00:08:35.380]   So if my name is Joshua Sheets and my email address is joshuasheets@gmail.com and then
[00:08:35.380 --> 00:08:39.640]   all of a sudden I use Joshua Sheets as my login information, it's not that hard for
[00:08:39.640 --> 00:08:44.280]   somebody to start guessing password variations, put a little bit of computer power behind
[00:08:44.280 --> 00:08:48.720]   it, and now all of a sudden they may have access to my financial accounts.
[00:08:48.720 --> 00:08:51.440]   And I'll beat up on banks a little bit here.
[00:08:51.440 --> 00:08:54.000]   Banks are not great at these authentication measures.
[00:08:54.000 --> 00:09:01.120]   So the bank that I have my corporate account with is, I set it up with them kind of out
[00:09:01.120 --> 00:09:04.560]   of convenience and I'm really regretting that decision now because of some of the privacy
[00:09:04.560 --> 00:09:07.520]   interventions that I have taken.
[00:09:07.520 --> 00:09:11.360]   It's a little bit difficult for me to just jump to another bank, but I'm stuck with a
[00:09:11.360 --> 00:09:16.080]   bank that doesn't allow two factor authentication, that doesn't allow very long passwords.
[00:09:16.080 --> 00:09:21.240]   I think I'm capped at maybe 16 characters and the character set is kind of limited.
[00:09:21.240 --> 00:09:22.720]   And this is kind of endemic with banks.
[00:09:22.720 --> 00:09:25.320]   I think some of the banks are doing a good job.
[00:09:25.320 --> 00:09:30.520]   Banks like Bank of America, Citi and Chase are doing a reasonably good job, these top
[00:09:30.520 --> 00:09:31.520]   tiered banks.
[00:09:31.520 --> 00:09:36.920]   But if any of your listeners are with smaller credit unions or local banks or things of
[00:09:36.920 --> 00:09:42.360]   that nature, I would take a long, hard look at the security that is even possible to implement
[00:09:42.360 --> 00:09:45.600]   on those accounts before I go any further with that.
[00:09:45.600 --> 00:09:50.640]   And maybe consider, if you don't want to give up that oldest bank account that you have,
[00:09:50.640 --> 00:09:55.720]   maybe consider opening an account with a bank that offers some better security and using
[00:09:55.720 --> 00:10:00.320]   that as my primary day to day use account rather than continuing on with that bank that
[00:10:00.320 --> 00:10:01.320]   doesn't.
[00:10:01.320 --> 00:10:05.480]   My experience has been that the banks probably aren't paying attention to it because the
[00:10:05.480 --> 00:10:07.200]   customers aren't demanding it.
[00:10:07.200 --> 00:10:11.080]   Just yesterday I released a show talking about – the title was Don't Trust Your Financial
[00:10:11.080 --> 00:10:12.080]   Advisor.
[00:10:12.080 --> 00:10:13.920]   I released it before recording this.
[00:10:13.920 --> 00:10:17.160]   And the point was – I said you can't – and the point – it was a clickbait title.
[00:10:17.160 --> 00:10:24.440]   But basically my point was you can't trust your financial advisor to maintain your privacy,
[00:10:24.440 --> 00:10:27.200]   your secrecy or your security.
[00:10:27.200 --> 00:10:32.080]   And one of my major – since I come from the world of professional financial advice,
[00:10:32.080 --> 00:10:38.000]   I am disheartened to see how insecure customer data is.
[00:10:38.000 --> 00:10:41.720]   And it's not because the firm doesn't know that they have a need for it.
[00:10:41.720 --> 00:10:45.320]   The firm on the firm level, they try to put in place things that are available.
[00:10:45.320 --> 00:10:48.640]   But I used to try to communicate with clients via an encrypted email system.
[00:10:48.640 --> 00:10:54.200]   We had a very simple encrypted email system set up that I could use to convey private
[00:10:54.200 --> 00:10:56.040]   information to my clients.
[00:10:56.040 --> 00:11:02.080]   And I would use it and we were required to use it whenever we were transmitting personal
[00:11:02.080 --> 00:11:05.480]   information through the encrypted email system.
[00:11:05.480 --> 00:11:10.800]   But most of the clients hated using it because it required one extra step to decrypt the
[00:11:10.800 --> 00:11:11.800]   email.
[00:11:11.800 --> 00:11:16.120]   And so of course to get around it, people are constantly sending unencrypted files or
[00:11:16.120 --> 00:11:20.200]   they just pop it over and send it through their personal Yahoo account right there to
[00:11:20.200 --> 00:11:22.840]   get it to the client and the clients didn't demand it.
[00:11:22.840 --> 00:11:26.280]   So I think one of the first things that I'd love to see my listening audience do is start
[00:11:26.280 --> 00:11:32.440]   demanding better security measures from the people that serve you.
[00:11:32.440 --> 00:11:38.640]   Yeah, the thing I did with my financial advisor is – or that I do with him, he's still
[00:11:38.640 --> 00:11:41.200]   not very good at privacy and security.
[00:11:41.200 --> 00:11:45.120]   He's very good at his job, but privacy and security are definitely lacking.
[00:11:45.120 --> 00:11:47.400]   And I just put everything into a PDF.
[00:11:47.400 --> 00:11:53.940]   If you have Adobe PDF Pro on Windows or Preview on Mac, you can encrypt that PDF.
[00:11:53.940 --> 00:11:57.720]   So I'll send him the PDF and then I'll call him and tell him the password, which kind
[00:11:57.720 --> 00:12:02.060]   of necessitates a simple password, but it's much better than nothing.
[00:12:02.060 --> 00:12:04.920]   And my question for you is, how do we fix this?
[00:12:04.920 --> 00:12:09.840]   Is there a financial advisor convention that I can get on the speaker list for?
[00:12:09.840 --> 00:12:11.520]   How do we start fixing this issue?
[00:12:11.520 --> 00:12:12.520]   That's a great idea.
[00:12:12.520 --> 00:12:16.400]   We could probably team up because I actually have the outline on one of the reasons why
[00:12:16.400 --> 00:12:20.200]   I consumed all your content was because I've been concerned about this for a while and
[00:12:20.200 --> 00:12:21.800]   I had researched the topic.
[00:12:21.800 --> 00:12:27.120]   I have the outline of a book/course in my head – or I have the outline written out.
[00:12:27.120 --> 00:12:33.040]   I'm not committed to actually completing it, but how to actually maintain as much financial
[00:12:33.040 --> 00:12:35.960]   anonymity and privacy as possible.
[00:12:35.960 --> 00:12:37.760]   And it is a big concern.
[00:12:37.760 --> 00:12:42.960]   Yeah, we could talk about that because there probably is some stuff that could be created
[00:12:42.960 --> 00:12:45.440]   that would bring it to people's attention.
[00:12:45.440 --> 00:12:49.960]   I think people just don't recognize how big the vulnerability is.
[00:12:49.960 --> 00:12:55.840]   I know my experience was that I spent most of my life with my head in the clouds and
[00:12:55.840 --> 00:12:58.080]   I would just simply say, "It's not going to happen to me."
[00:12:58.080 --> 00:13:00.280]   And if it does happen to me, it's probably not a big deal.
[00:13:00.280 --> 00:13:01.640]   It can be cleaned up.
[00:13:01.640 --> 00:13:04.800]   But over the last few years, I think we've seen plenty of evidence that, number one,
[00:13:04.800 --> 00:13:10.520]   it's going to happen to you, whether it's something embarrassing and potentially life-changing,
[00:13:10.520 --> 00:13:15.360]   such as being found in the Ashley Madison database, or whether it's something just
[00:13:15.360 --> 00:13:19.760]   simply inconvenient, such as being in the Target or Home Depot breach, or whether it's
[00:13:19.760 --> 00:13:24.800]   something potentially serious, like being involved in a government information breach,
[00:13:24.800 --> 00:13:27.560]   whether it's – what was the breach on the military system?
[00:13:27.560 --> 00:13:28.560]   OPM.
[00:13:28.560 --> 00:13:29.560]   Yeah, exactly.
[00:13:29.560 --> 00:13:30.560]   Recently.
[00:13:30.560 --> 00:13:34.920]   Or, I mean, this goes back years, back when the U.S. Census Bureau lost 50 laptops, something
[00:13:34.920 --> 00:13:38.320]   like that, that were stolen with all this personal information on them.
[00:13:38.320 --> 00:13:45.800]   So I think the understanding that people have has raised – and so I'm trying to agitate
[00:13:45.800 --> 00:13:48.600]   here on the consumer side to get people to care about it.
[00:13:48.600 --> 00:13:55.240]   And my experience has been that just simply by telling people and encouraging people,
[00:13:55.240 --> 00:13:58.160]   "Hey," just requires certain things.
[00:13:58.160 --> 00:14:02.080]   I get a lot of my friends – I try to get everyone I can to use something as simple
[00:14:02.080 --> 00:14:05.960]   as Signal, which is just a simple encrypted messaging and communication app.
[00:14:05.960 --> 00:14:07.760]   It's so easy to install.
[00:14:07.760 --> 00:14:12.560]   Every time I do it – or I try to get people to use FaceTime, FaceTime audio, instead of
[00:14:12.560 --> 00:14:13.560]   making a phone call.
[00:14:13.560 --> 00:14:16.520]   So all of my friends with iPhones, I just always FaceTime audio them.
[00:14:16.520 --> 00:14:17.520]   What's this FaceTime audio?
[00:14:17.520 --> 00:14:20.080]   Well, at least it gets a base level of encryption.
[00:14:20.080 --> 00:14:24.480]   And so I personally am a bit of an evangelist for it, and I think that that will have an
[00:14:24.480 --> 00:14:25.480]   effect.
[00:14:25.480 --> 00:14:28.440]   And it's only when the customers demand it that the industry will change.
[00:14:28.440 --> 00:14:32.400]   Well, I have to tell you, that's incredibly refreshing to hear, because it's not very
[00:14:32.400 --> 00:14:38.280]   common to hear people outside of the dedicated privacy and security space agitating for these
[00:14:38.280 --> 00:14:44.160]   things or advocating using Signal or encrypted email or things like that.
[00:14:44.160 --> 00:14:50.600]   So that's really kind of uplifting to hear that at least someone is out there doing that.
[00:14:50.600 --> 00:14:53.040]   Well, it used to be hard to do.
[00:14:53.040 --> 00:14:59.280]   And my observation is – you know, setting up manual PGP encryption on your email program
[00:14:59.280 --> 00:15:01.280]   is not for the faint of heart, right?
[00:15:01.280 --> 00:15:04.000]   So it's just easier to say, "Well, I'm not going to worry about it."
[00:15:04.000 --> 00:15:09.320]   But now, when there are encrypted email options that are free and that are easy, I think the
[00:15:09.320 --> 00:15:12.000]   technology barrier has gone down.
[00:15:12.000 --> 00:15:18.120]   And especially my observation, the political scene really raised with the hacks of the
[00:15:18.120 --> 00:15:22.120]   Democratic National Committee and the releases there, whether that was from an outside attacker
[00:15:22.120 --> 00:15:24.320]   or an inside source, I don't know.
[00:15:24.320 --> 00:15:29.040]   But I think that these things have really raised their profile for people.
[00:15:29.040 --> 00:15:30.040]   Absolutely.
[00:15:30.040 --> 00:15:36.680]   Yeah, possibly the best thing to come out of the Snowden leaks was not massive public
[00:15:36.680 --> 00:15:41.360]   awareness and people making behavioral changes, but companies that are interested in privacy
[00:15:41.360 --> 00:15:46.640]   and security are now providing us with options that are much more easily implemented.
[00:15:46.640 --> 00:15:51.520]   Even you mentioned PGP, which I still have a PGP key on my blog.
[00:15:51.520 --> 00:15:54.920]   If people want to email me that way, they're welcome to.
[00:15:54.920 --> 00:16:03.760]   But I maybe exchange a manual PGP encrypted email once a month at most.
[00:16:03.760 --> 00:16:08.320]   And it's even still possible for people like me to screw that up because it is such a technically
[00:16:08.320 --> 00:16:10.440]   demanding system.
[00:16:10.440 --> 00:16:16.000]   And thankfully, for email, we have things like ProtonMail now that are much more manageable.
[00:16:16.000 --> 00:16:17.000]   Absolutely.
[00:16:17.000 --> 00:16:18.520]   So let's go back to the basics.
[00:16:18.520 --> 00:16:22.000]   I guess we went into nerd world there.
[00:16:22.000 --> 00:16:24.200]   Because I do want to emphasize the basics.
[00:16:24.200 --> 00:16:26.520]   And I think these basics matter.
[00:16:26.520 --> 00:16:30.680]   So your best practices that you mentioned were a few things.
[00:16:30.680 --> 00:16:33.040]   Number one, don't use a common username.
[00:16:33.040 --> 00:16:36.440]   If your name is Joshua Sheets, don't use Joshua Sheets as your login.
[00:16:36.440 --> 00:16:41.040]   Either use variations of that with numbers or even better, use an entirely random string
[00:16:41.040 --> 00:16:49.600]   of characters such as HK57329 and use a password management database system to maintain that
[00:16:49.600 --> 00:16:50.600]   information.
[00:16:50.600 --> 00:16:53.200]   Two was use strong passwords.
[00:16:53.200 --> 00:16:57.740]   So at the maximum length possible and of tremendous variation.
[00:16:57.740 --> 00:17:03.480]   The only way that's practically possible is to use a password management program, which
[00:17:03.480 --> 00:17:06.080]   I'm going to ask you about in just a moment, Justin, how you recommend.
[00:17:06.080 --> 00:17:10.400]   Because many people just have the habit of using one or two simple passwords and they're
[00:17:10.400 --> 00:17:13.920]   very proud of themselves when they add a number or two to it.
[00:17:13.920 --> 00:17:17.960]   And they use the same password across all accounts, which is also better than having
[00:17:17.960 --> 00:17:19.560]   a simplest password.
[00:17:19.560 --> 00:17:21.920]   But it's also pretty insecure.
[00:17:21.920 --> 00:17:24.400]   And then number three was third party authentication.
[00:17:24.400 --> 00:17:29.920]   Sorry, two factor authentication, making sure that whenever possible, you add a second login
[00:17:29.920 --> 00:17:32.560]   factor to the login information.
[00:17:32.560 --> 00:17:34.320]   So practically, how do you manage that?
[00:17:34.320 --> 00:17:35.320]   How do you do that?
[00:17:35.320 --> 00:17:38.280]   What are the apps and resources that you use and recommend for that base level of security
[00:17:38.280 --> 00:17:39.640]   for financial accounts?
[00:17:39.640 --> 00:17:40.680]   Absolutely.
[00:17:40.680 --> 00:17:46.920]   So for a password manager, I use a system called KeePass, which is free and open source.
[00:17:46.920 --> 00:17:51.400]   And there's some benefits and disadvantages to KeePass.
[00:17:51.400 --> 00:17:55.140]   So I'm a security, the security is my platform.
[00:17:55.140 --> 00:17:59.280]   So I'm always going to default to the more secure, less convenient option.
[00:17:59.280 --> 00:18:03.840]   KeePass creates a database that exists locally on your computer.
[00:18:03.840 --> 00:18:11.720]   So it's a I use KeePass for Windows, KeePass X, if you have Macs or Linux computers, and
[00:18:11.720 --> 00:18:18.000]   many KeePass for iOS and KeePass for Droid for Android operating systems.
[00:18:18.000 --> 00:18:19.800]   And that's a little bit complex.
[00:18:19.800 --> 00:18:25.960]   But once you have the applications installed, you create that KeePass database on whatever
[00:18:25.960 --> 00:18:30.000]   your primary system is probably your desktop computer, you can then drag that database
[00:18:30.000 --> 00:18:37.240]   over to your phone, your tablet, your other computer, your wife's computer, your husband's
[00:18:37.240 --> 00:18:42.840]   computer, they can all be accessed through that KeePass front end program, because that
[00:18:42.840 --> 00:18:47.080]   data they all read that same dot kbdx file format.
[00:18:47.080 --> 00:18:51.280]   So you can move those databases around, you do run into some version control issues with
[00:18:51.280 --> 00:18:55.880]   that if you add something on your phone, and you don't go in and update that database on
[00:18:55.880 --> 00:19:01.080]   your primary machine, those those versions can very quickly start to conflict with each
[00:19:01.080 --> 00:19:02.080]   other.
[00:19:02.080 --> 00:19:08.000]   So if you're looking for a simpler, more convenient option, there's a program called LastPass.
[00:19:08.000 --> 00:19:09.000]   This is cloud based.
[00:19:09.000 --> 00:19:13.280]   So it actually manages your database in the cloud, you can access it from any of your
[00:19:13.280 --> 00:19:20.720]   devices, Windows, Mac, Linux, Android, iOS, you can also log into it from the web, from
[00:19:20.720 --> 00:19:26.240]   your any of your internet browsers, or from dedicated browser extensions for most of the
[00:19:26.240 --> 00:19:27.760]   major browsers.
[00:19:27.760 --> 00:19:30.720]   And the great thing about this is you can access it from anywhere.
[00:19:30.720 --> 00:19:35.240]   And anytime you update that database, it's updated across every single device because
[00:19:35.240 --> 00:19:38.160]   it's maintained in that one central hub.
[00:19:38.160 --> 00:19:42.760]   Now I'm a little more leery of this because if that database were ever breached, then
[00:19:42.760 --> 00:19:48.360]   all my passwords for absolutely everything I have would be compromised.
[00:19:48.360 --> 00:19:50.520]   But I have some great security measures in place.
[00:19:50.520 --> 00:19:57.440]   I have a very, very long, strong password on that you can use two factor authentication.
[00:19:57.440 --> 00:19:58.840]   And let's talk about that a little bit.
[00:19:58.840 --> 00:20:03.520]   So I mentioned that you can get a text message, you can have an app on your phone that maintains
[00:20:03.520 --> 00:20:07.140]   those two factor authentication tokens, or you can have a piece of hardware.
[00:20:07.140 --> 00:20:11.960]   So I don't recommend the SMS generally that has actually been downgraded by a government
[00:20:11.960 --> 00:20:17.160]   agency, the National Institute of Standards and Technology, because of how easily defeated
[00:20:17.160 --> 00:20:18.520]   it is.
[00:20:18.520 --> 00:20:23.760]   It would take a fairly sophisticated, focused adversary that was specifically trying to
[00:20:23.760 --> 00:20:25.480]   defeat you.
[00:20:25.480 --> 00:20:29.160]   Because in order to do that, I would have to hack into your phone account, which is
[00:20:29.160 --> 00:20:33.400]   not difficult to do at all, and forward your text messages to me.
[00:20:33.400 --> 00:20:37.060]   At that point, I would receive all your two factor tokens and could log into your accounts
[00:20:37.060 --> 00:20:40.600]   provided I had cracked the username and password.
[00:20:40.600 --> 00:20:45.360]   So that's not ideal, but it's still far, far better than nothing.
[00:20:45.360 --> 00:20:49.960]   So the next kind of escalating up the next thing would be a software token on an app
[00:20:49.960 --> 00:20:57.120]   like Google Authenticator, which you can install on your iOS or Android devices, or Authy,
[00:20:57.120 --> 00:21:02.160]   and which uses the same protocol you install it on your iOS or Android device, you log
[00:21:02.160 --> 00:21:05.280]   into your account with your username and password.
[00:21:05.280 --> 00:21:10.360]   The next step will ask for your token, you open up your phone, open that Google Authenticator
[00:21:10.360 --> 00:21:15.040]   or Authy app, you can have multiple different accounts in these apps.
[00:21:15.040 --> 00:21:19.200]   So let's say I have a Gmail account or Dropbox account and a Facebook account, I can have
[00:21:19.200 --> 00:21:23.360]   those tokens for all of those in this one single app, I tap the icon for the account
[00:21:23.360 --> 00:21:28.560]   I want, it displays the current six digit code, I type that in, and I'm allowed to log
[00:21:28.560 --> 00:21:29.640]   in.
[00:21:29.640 --> 00:21:34.220]   That code is only good for one login, and it's only valid for a 30 second period.
[00:21:34.220 --> 00:21:39.000]   So you will notice if you watch the app every 30 seconds, the code that's on there will
[00:21:39.000 --> 00:21:41.440]   disappear and new one will pop up.
[00:21:41.440 --> 00:21:45.360]   This is much, much better security than the SMS version.
[00:21:45.360 --> 00:21:49.720]   And then if you really want to go all out, there's a product called the YubiKey.
[00:21:49.720 --> 00:21:52.420]   And I will make sure you have a link for that in your show notes.
[00:21:52.420 --> 00:21:57.640]   But the YubiKey is a hardware token that you plug into a USB port.
[00:21:57.640 --> 00:22:03.720]   And the problem, kind of the issue with this is not a lot of services support this yet.
[00:22:03.720 --> 00:22:09.880]   But it creates a rotating code, you have to have the hardware in your computer, so you
[00:22:09.880 --> 00:22:11.440]   username password.
[00:22:11.440 --> 00:22:15.960]   And on the next screen, you just tap a little button on the YubiKey, it dumps that massive
[00:22:15.960 --> 00:22:21.080]   40 character two factor authentication token into the website, and you're allowed to log
[00:22:21.080 --> 00:22:22.080]   in.
[00:22:22.080 --> 00:22:25.920]   So there's kind of an escalating scale depending on how complex you want to get with it.
[00:22:25.920 --> 00:22:31.080]   Personally, I find the middle of the road the Authy or Google Authenticator app to be
[00:22:31.080 --> 00:22:33.400]   the most usable.
[00:22:33.400 --> 00:22:38.280]   Text messages, I have problems with sometimes if I can't get cell service for whatever reason,
[00:22:38.280 --> 00:22:40.860]   I won't get those two factor authentication tokens.
[00:22:40.860 --> 00:22:47.400]   So using the app has been the most convenient and it's the level of security that I'm comfortable
[00:22:47.400 --> 00:22:49.720]   with for most of my accounts.
[00:22:49.720 --> 00:22:52.360]   Authy is really simple to set up.
[00:22:52.360 --> 00:22:57.000]   You just do it and scan a code on the site and it's really easily integrated.
[00:22:57.000 --> 00:23:01.720]   My question is this, if you're using an app as in Authy or Google Authenticator, how do
[00:23:01.720 --> 00:23:06.760]   you back that up in case you have a malfunction of your mobile device that you are using the
[00:23:06.760 --> 00:23:07.760]   codes from?
[00:23:07.760 --> 00:23:10.600]   So Authy makes it really, really easy.
[00:23:10.600 --> 00:23:14.840]   And I'm a little bit less familiar with Google Authenticator.
[00:23:14.840 --> 00:23:20.280]   If anyone has listened to my podcast, they'll know I kind of have a really negative view
[00:23:20.280 --> 00:23:21.960]   of anything with the name Google on it.
[00:23:21.960 --> 00:23:22.960]   You and me both.
[00:23:22.960 --> 00:23:25.960]   I've been trying to extract myself for years and I'm hoping in a few years I can, but I
[00:23:25.960 --> 00:23:28.600]   don't think I'll ever be able to fully extract.
[00:23:28.600 --> 00:23:32.840]   So I'm really hesitant to put a Google branded app on my phone.
[00:23:32.840 --> 00:23:38.480]   So I'm more familiar with Authy, but it allows you to go in and set a username and password
[00:23:38.480 --> 00:23:46.140]   and it will store an encrypted version of your account information of those two factor
[00:23:46.140 --> 00:23:47.520]   tokens on Authy server.
[00:23:47.520 --> 00:23:52.440]   So if I lose my phone, if I drop my phone in the toilet, if my phone just dies one day,
[00:23:52.440 --> 00:23:57.760]   I go get a new one, back it up, and then I re-login to Authy and it will refresh those
[00:23:57.760 --> 00:24:02.760]   two factor tokens onto that device and I don't skip a beat.
[00:24:02.760 --> 00:24:05.280]   I've been learning how to use YubiKey.
[00:24:05.280 --> 00:24:06.280]   I learned that from you guys.
[00:24:06.280 --> 00:24:10.200]   I had never heard of it and then I listened to your podcast on it and ordered a couple
[00:24:10.200 --> 00:24:12.040]   of them and I've been using them.
[00:24:12.040 --> 00:24:17.260]   I think it's a tremendous, powerful, I mean it's really, really cool and it does what
[00:24:17.260 --> 00:24:19.920]   many of us I think would desire to have done.
[00:24:19.920 --> 00:24:26.200]   It uses and integrates the digital technology with the changing code with the physical security
[00:24:26.200 --> 00:24:32.960]   so I can be confident that my account is not going to be accessed unless my physical token
[00:24:32.960 --> 00:24:34.600]   is present.
[00:24:34.600 --> 00:24:37.100]   My question for you is it doesn't seem to work with Firefox.
[00:24:37.100 --> 00:24:38.100]   How do you do that?
[00:24:38.100 --> 00:24:41.680]   Because I like to use Firefox, but it doesn't work with Firefox, at least it doesn't right
[00:24:41.680 --> 00:24:42.680]   now.
[00:24:42.680 --> 00:24:43.680]   How do you fix that?
[00:24:43.680 --> 00:24:46.680]   Yeah, that's kind of a thing.
[00:24:46.680 --> 00:24:50.160]   That's my personal question because I've been trying to learn how to use it.
[00:24:50.160 --> 00:24:54.560]   It's like I got to do it on Chrome and I try not to use Chrome.
[00:24:54.560 --> 00:25:00.680]   So if I'm not mistaken, you can use the YubiKey with some services on Firefox.
[00:25:00.680 --> 00:25:03.320]   Gmail will not support it on Chrome.
[00:25:03.320 --> 00:25:05.080]   Is that the experience that you're having?
[00:25:05.080 --> 00:25:06.080]   Right.
[00:25:06.080 --> 00:25:07.080]   Gmail won't support it on Firefox.
[00:25:07.080 --> 00:25:11.160]   Facebook won't support it on Firefox, etc.
[00:25:11.160 --> 00:25:12.160]   Okay.
[00:25:12.160 --> 00:25:17.520]   And also I use YubiKey for some local accounts or some local applications like my KeePass
[00:25:17.520 --> 00:25:18.520]   database.
[00:25:18.520 --> 00:25:22.680]   I use a static YubiKey password to log into that KeePass database.
[00:25:22.680 --> 00:25:26.760]   So that's browser agnostic.
[00:25:26.760 --> 00:25:29.160]   It doesn't touch the browser so it doesn't care.
[00:25:29.160 --> 00:25:33.480]   I'm a little bit hesitant to recommend the YubiKey to people that aren't specifically
[00:25:33.480 --> 00:25:39.480]   privacy and security focused because a $40 product is a really tough sell when you can
[00:25:39.480 --> 00:25:44.720]   go out and download Google Authenticator or Authy completely for free and it works with
[00:25:44.720 --> 00:25:46.200]   a lot more things.
[00:25:46.200 --> 00:25:49.000]   However, I do really like the YubiKey.
[00:25:49.000 --> 00:25:53.600]   Once you have it set up and running, if you buy the YubiKey Nano, it just sits in your
[00:25:53.600 --> 00:25:54.600]   USB port.
[00:25:54.600 --> 00:25:59.120]   You barely even know it's there and occasionally you just tap it and it dumps that code.
[00:25:59.120 --> 00:26:03.880]   But it's a little bit more technically challenging to set up and I think to kind of wrap your
[00:26:03.880 --> 00:26:05.200]   head around.
[00:26:05.200 --> 00:26:09.960]   And that $40 cost of entry is a tough pill for a lot of people to swallow.
[00:26:09.960 --> 00:26:12.080]   Yeah, we'll get out of nerd world.
[00:26:12.080 --> 00:26:14.600]   Appreciate the reigning in there.
[00:26:14.600 --> 00:26:20.960]   LastPass for password management is fantastic and you make a valid point with regard to
[00:26:20.960 --> 00:26:21.960]   security.
[00:26:21.960 --> 00:26:27.200]   But for most of us, our security is so horrifically bad that just to move to LastPass where it
[00:26:27.200 --> 00:26:32.000]   will automatically set it up so while you're browsing, everything is right there and so
[00:26:32.000 --> 00:26:37.520]   that it'll create long random passwords that are stored is tremendously valuable.
[00:26:37.520 --> 00:26:41.600]   I've had great success with getting people to use LastPass because it's stored in the
[00:26:41.600 --> 00:26:46.040]   cloud which most people like and it helps them to feel good and also because of its
[00:26:46.040 --> 00:26:48.660]   just ubiquity across all platforms.
[00:26:48.660 --> 00:26:52.880]   So that would be a tremendous upgrade and then also I'll affirm as you said, Authy
[00:26:52.880 --> 00:27:00.520]   for two-factor authentication is easy to use, it's simple to set up, and it would be a tremendous
[00:27:00.520 --> 00:27:02.200]   step up for many people.
[00:27:02.200 --> 00:27:05.040]   So these steps would help to secure our accounts.
[00:27:05.040 --> 00:27:06.040]   What else?
[00:27:06.040 --> 00:27:09.480]   What are the low-hanging fruits?
[00:27:09.480 --> 00:27:12.200]   Are there any other low-hanging fruits that you wanted to add to this?
[00:27:12.200 --> 00:27:15.320]   Yeah, so I guess one more.
[00:27:15.320 --> 00:27:17.480]   So those are fairly easy steps to take.
[00:27:17.480 --> 00:27:22.760]   The next one is going to be a little bit painful but it's kind of necessary in my opinion for
[00:27:22.760 --> 00:27:27.680]   both security and privacy and that is get off Gmail.
[00:27:27.680 --> 00:27:32.900]   This is a tough sell because Google has kind of spread their tentacles into every aspect
[00:27:32.900 --> 00:27:38.540]   of life with Google Maps and Waze and Google Calendar and Google Translate and Google Street
[00:27:38.540 --> 00:27:42.160]   View and all these amazing services.
[00:27:42.160 --> 00:27:47.120]   If you have a Google account, you already have access to all these other things like
[00:27:47.120 --> 00:27:51.600]   Google Drive and Google Voice and all these other amazing products that make life so much
[00:27:51.600 --> 00:27:52.800]   easier.
[00:27:52.800 --> 00:27:56.520]   But these are all collecting information from you that will never be forgotten.
[00:27:56.520 --> 00:28:00.720]   It's all going onto a server and a lot of it is very, very personally sensitive.
[00:28:00.720 --> 00:28:06.320]   Even if you don't send emails and most people are migrating to services like iMessage or
[00:28:06.320 --> 00:28:11.560]   Snapchat or other messaging services, email is kind of going the way of the handwritten
[00:28:11.560 --> 00:28:12.560]   letter.
[00:28:12.560 --> 00:28:17.780]   It's becoming less and less common that people exchange these deep intimate personal emails.
[00:28:17.780 --> 00:28:22.520]   But if all you're receiving still is service notifications from your bank, from your physician,
[00:28:22.520 --> 00:28:29.360]   from all these services that create a lot of ancillary metadata about who you are and
[00:28:29.360 --> 00:28:34.240]   what you are, that's still a huge, huge privacy invasion.
[00:28:34.240 --> 00:28:36.780]   And there have been instances of rogue Google employees.
[00:28:36.780 --> 00:28:43.120]   There have been instances of, I mean, things like the NSA backdooring Google trunks to
[00:28:43.120 --> 00:28:44.120]   obtain all that data.
[00:28:44.120 --> 00:28:50.760]   And I don't want to emphasize that too much because we're not really trying to hide from
[00:28:50.760 --> 00:28:56.240]   the NSA, but the NSA has also proven very recently with the WannaCry leaks that they
[00:28:56.240 --> 00:28:59.420]   have a difficult time hanging on to the data that they collect.
[00:28:59.420 --> 00:29:02.000]   So if all this is floating around out there, it's at risk.
[00:29:02.000 --> 00:29:08.120]   So my personal solution is ProtonMail and to get the functionality that most people
[00:29:08.120 --> 00:29:12.720]   need out of email, you're probably going to need a premium account, which is a couple
[00:29:12.720 --> 00:29:13.720]   of bucks a month.
[00:29:13.720 --> 00:29:15.240]   It's not onerous.
[00:29:15.240 --> 00:29:22.060]   You can step up to the ProtonMail Plus plan for under $50 a year if you buy yearly.
[00:29:22.060 --> 00:29:25.940]   And all your emails are end-to-end encrypted between ProtonMail users.
[00:29:25.940 --> 00:29:30.120]   One thing I found really handy with people like my accountant is that I can even encrypt
[00:29:30.120 --> 00:29:31.680]   emails to outside users.
[00:29:31.680 --> 00:29:33.360]   I just say, encrypt this message.
[00:29:33.360 --> 00:29:34.680]   I assign a password to it.
[00:29:34.680 --> 00:29:38.280]   I call him up and say, "Hey, here's the password to open this email."
[00:29:38.280 --> 00:29:42.360]   And all the content of that email and any attachments are going to be encrypted.
[00:29:42.360 --> 00:29:48.800]   Everything's stored in an encrypted state in Switzerland.
[00:29:48.800 --> 00:29:52.800]   The administration of ProtonMail has no access to my emails.
[00:29:52.800 --> 00:29:57.600]   This is not the ultimate solution if you're going to be the next Edward Snowden.
[00:29:57.600 --> 00:30:05.700]   But for most of us, for our day-to-day communications, this takes you out of that automatically opted-in
[00:30:05.700 --> 00:30:08.800]   data collection that we're all subject to.
[00:30:08.800 --> 00:30:12.760]   And even if ProtonMail is hacked or has a rogue employee, I don't worry that they're
[00:30:12.760 --> 00:30:16.840]   going to have access to my financial accounts or my other email accounts or my Facebook
[00:30:16.840 --> 00:30:22.900]   account or my doctor's accounts or whatever emails I'm receiving there because it's encrypted
[00:30:22.900 --> 00:30:24.680]   and they have no access to it.
[00:30:24.680 --> 00:30:29.760]   Do you think the rogue employee risk is the highest risk that practically speaking most
[00:30:29.760 --> 00:30:35.960]   of us who aren't engaged in foreign espionage and high crimes against the state are involved
[00:30:35.960 --> 00:30:36.960]   in?
[00:30:36.960 --> 00:30:37.960]   Is that the biggest risk?
[00:30:37.960 --> 00:30:38.960]   No.
[00:30:38.960 --> 00:30:45.760]   I think even as good as Google security is, defense is much harder than offense.
[00:30:45.760 --> 00:30:48.680]   Defense you have to get it right every single time.
[00:30:48.680 --> 00:30:52.440]   Offense you have to get it right once to get in and get a bunch of stuff.
[00:30:52.440 --> 00:30:56.720]   And Google is probably the world's biggest target because they're the world's biggest
[00:30:56.720 --> 00:30:58.120]   repository of data.
[00:30:58.120 --> 00:31:01.720]   That data is really, really valuable to people.
[00:31:01.720 --> 00:31:07.280]   Google is targeted thousands of times every single day and they have to get everything
[00:31:07.280 --> 00:31:11.480]   right 100% of the time to avoid being exploited.
[00:31:11.480 --> 00:31:14.840]   And eventually they're going to fail.
[00:31:14.840 --> 00:31:21.440]   I really talk up Google security a lot because it's very good, but that's almost an unsustainable
[00:31:21.440 --> 00:31:27.200]   model to have to be perfect every single time.
[00:31:27.200 --> 00:31:31.800]   And the sophistication of the attackers is consistently increasing as well.
[00:31:31.800 --> 00:31:38.560]   There's a day when a hacker may have had some basic skills, but more and more a hacker can
[00:31:38.560 --> 00:31:43.520]   turn an army of computing power of remote bots against something.
[00:31:43.520 --> 00:31:47.880]   The coding sophistication, the knowledge just seems to be consistently increasing, which
[00:31:47.880 --> 00:31:52.560]   is why we have to consistently step up our game across the board.
[00:31:52.560 --> 00:31:57.800]   To misquote Bruce Schneier, today's NSA exploits are tomorrow's PhD theses and the next day's
[00:31:57.800 --> 00:32:00.880]   hacker tools.
[00:32:00.880 --> 00:32:05.960]   I was thinking as you're talking about communication security, because when I try to get people
[00:32:05.960 --> 00:32:10.720]   to just take a simple step, use FaceTime audio instead of using a phone call, number one,
[00:32:10.720 --> 00:32:11.720]   you'll get a better product.
[00:32:11.720 --> 00:32:14.760]   You'll get a digital connection instead of an analog connection, which is downgraded
[00:32:14.760 --> 00:32:16.320]   signal quality.
[00:32:16.320 --> 00:32:20.720]   Or to use signal for or wicker or something like that for your text messaging instead
[00:32:20.720 --> 00:32:24.000]   of using the SMS system.
[00:32:24.000 --> 00:32:30.080]   Oftentimes the number one question is, "Well, I don't have anything to hide.
[00:32:30.080 --> 00:32:33.480]   Why should I bother to do that?
[00:32:33.480 --> 00:32:34.480]   I don't have anything to hide.
[00:32:34.480 --> 00:32:35.800]   I'm not involved in anything illegal.
[00:32:35.800 --> 00:32:37.160]   I'm not involved in anything immoral.
[00:32:37.160 --> 00:32:39.080]   I don't have anything to hide."
[00:32:39.080 --> 00:32:45.400]   And I often wish to wax eloquent about the philosophical basis of freedom and liberty
[00:32:45.400 --> 00:32:48.600]   and how this is important, et cetera.
[00:32:48.600 --> 00:32:51.080]   But recently I've been trying this line.
[00:32:51.080 --> 00:32:54.520]   In the old days when you made a phone call, it was automatically a party line.
[00:32:54.520 --> 00:33:02.160]   Anybody all up and down the line, your phone would ring anytime anybody on your phone line
[00:33:02.160 --> 00:33:05.880]   was being called and you didn't listen for the fact of your phone ringing.
[00:33:05.880 --> 00:33:07.920]   You listened for the unique ring.
[00:33:07.920 --> 00:33:12.040]   If you had two short, one long, then you picked up only when it was too short and one long.
[00:33:12.040 --> 00:33:15.300]   But that meant that all up and down the line, anybody who wanted to could pick up the phone
[00:33:15.300 --> 00:33:18.300]   line and listen in on your conversation.
[00:33:18.300 --> 00:33:24.160]   And to me, it's as simple as, would you automatically voluntarily choose to use a technology that
[00:33:24.160 --> 00:33:26.600]   makes your phone calls a party line?
[00:33:26.600 --> 00:33:31.400]   Or if possible, would you prefer to have a direct person-to-person line and contact?
[00:33:31.400 --> 00:33:34.940]   And I've been trying that non-philosophical answer to some success.
[00:33:34.940 --> 00:33:37.120]   How do you answer that objection?
[00:33:37.120 --> 00:33:43.120]   I think my first answer for that is when I go to the bathroom or when I'm being intimate
[00:33:43.120 --> 00:33:47.520]   with my significant other, I'm not doing anything wrong.
[00:33:47.520 --> 00:33:49.440]   But if there are other people in the house, I'm going to close the door.
[00:33:49.440 --> 00:33:52.840]   In either of those cases, there's absolutely nothing wrong with what I'm doing.
[00:33:52.840 --> 00:33:58.960]   They're both kind of biological imperatives and things that everyone does to a greater
[00:33:58.960 --> 00:34:01.320]   or lesser extent.
[00:34:01.320 --> 00:34:04.040]   But there's still that desire for privacy, right?
[00:34:04.040 --> 00:34:06.560]   It's not just because I don't want my guests to be offended.
[00:34:06.560 --> 00:34:10.160]   It's also because I want to have that privacy.
[00:34:10.160 --> 00:34:15.320]   I think ultimately we feel the same about our communications if we don't think about
[00:34:15.320 --> 00:34:16.320]   it.
[00:34:16.320 --> 00:34:21.640]   We don't feel the same about carrying a cell phone, which tracks you everywhere you go
[00:34:21.640 --> 00:34:24.920]   because we've opted into that for the benefits that it gives us.
[00:34:24.920 --> 00:34:28.760]   But if there were someone following you around everywhere you went every day and writing
[00:34:28.760 --> 00:34:32.360]   in a notebook every place you stopped, how long you stayed there, who you talked to while
[00:34:32.360 --> 00:34:35.960]   you were there, people would get very frustrated with that really quickly.
[00:34:35.960 --> 00:34:38.000]   And that is happening.
[00:34:38.000 --> 00:34:42.120]   That happens on a daily basis to all of us that use a cell phone, which is probably every
[00:34:42.120 --> 00:34:48.720]   single person at this point, at least that listen to podcasts, that that very same data
[00:34:48.720 --> 00:34:50.220]   collection is occurring.
[00:34:50.220 --> 00:34:56.680]   It's less visibly apparent to us, which I think is why it's less viscerally alarming.
[00:34:56.680 --> 00:34:58.640]   Absolutely.
[00:34:58.640 --> 00:35:04.600]   Any of the low hanging fruit that you want to mention before I adjust this a little bit?
[00:35:04.600 --> 00:35:09.760]   No, we can go ahead and push on unless there's something specific you want me to talk about.
[00:35:09.760 --> 00:35:14.040]   Well, it's interesting because one of the things why I think this is so important for
[00:35:14.040 --> 00:35:20.400]   people to do and to practice, and here's just my commentary and I'm interested in your take.
[00:35:20.400 --> 00:35:27.240]   Number one, it's my observation that these things are skills that need to be developed.
[00:35:27.240 --> 00:35:33.640]   The ability to use a two-factor authentication application or even just the ability to receive
[00:35:33.640 --> 00:35:38.760]   an SMS message and to input that code on the website is a skill that has to be learned.
[00:35:38.760 --> 00:35:45.240]   I recently read an author who was citing a report about how two-factor authentication
[00:35:45.240 --> 00:35:46.920]   is increasing and he said, "This is bogus."
[00:35:46.920 --> 00:35:47.920]   He was an older guy.
[00:35:47.920 --> 00:35:48.960]   He said, "This is bogus.
[00:35:48.960 --> 00:35:50.040]   I don't see this anywhere."
[00:35:50.040 --> 00:35:52.080]   And I thought to myself, "That's bogus?
[00:35:52.080 --> 00:35:53.600]   You just obviously don't have the skill.
[00:35:53.600 --> 00:35:56.960]   You're not using this because this is certainly not bogus."
[00:35:56.960 --> 00:36:00.560]   You need to develop the skills and you got to develop the skills before you need them.
[00:36:00.560 --> 00:36:08.320]   And one of my concerns is to use your nomenclature, in time, most of us hope to do things and
[00:36:08.320 --> 00:36:14.560]   to be effective in things that are going to necessarily raise our attack surface, which
[00:36:14.560 --> 00:36:18.800]   means bring us to a higher degree of prominence, whether that's doing something like creating
[00:36:18.800 --> 00:36:23.040]   a podcast and talking about money on the internet or whether it's doing something like doing
[00:36:23.040 --> 00:36:30.040]   very well in your job or in your business and earning a significant amount of money
[00:36:30.040 --> 00:36:35.160]   or whether it's taking a stand in a political cause that is unpopular or that wherein you
[00:36:35.160 --> 00:36:37.760]   start to attract to yourself enemies.
[00:36:37.760 --> 00:36:43.560]   You got to think years in advance and put the framework in place so that when all of
[00:36:43.560 --> 00:36:49.520]   a sudden you're being targeted with a lawsuit by your tenant who's suing you because they
[00:36:49.520 --> 00:36:53.680]   fell off the front porch and injured themselves and they know you own 10 rental properties
[00:36:53.680 --> 00:36:57.200]   and now all of a sudden they're going to start – they're going to bring a lawsuit against
[00:36:57.200 --> 00:36:58.200]   you.
[00:36:58.200 --> 00:37:01.360]   You've got to have thought about that a decade earlier and built the skill set.
[00:37:01.360 --> 00:37:06.560]   So I believe that it's important to plan and to teach people to plan for the fact that
[00:37:06.560 --> 00:37:10.880]   your profile in the future is going to be raised and you need to build the skills now
[00:37:10.880 --> 00:37:12.320]   to be prepared for that.
[00:37:12.320 --> 00:37:13.320]   What say you?
[00:37:13.320 --> 00:37:14.320]   Aaron Powell: Absolutely.
[00:37:14.320 --> 00:37:19.040]   I'm going to steal a quote from one of our recent podcast guests and say that you should
[00:37:19.040 --> 00:37:22.200]   dig your well before you're thirsty.
[00:37:22.200 --> 00:37:27.120]   We've seen plenty of examples of law enforcement officers who have come to national attention
[00:37:27.120 --> 00:37:33.640]   because of their actions on the job and I'm not going to weigh in with a judgment either
[00:37:33.640 --> 00:37:37.720]   way on that, but I will say at that point it's too late to do anything.
[00:37:37.720 --> 00:37:39.440]   Everything about them becomes public knowledge.
[00:37:39.440 --> 00:37:44.320]   It goes in the newspaper on a news crawl at the bottom of the screen for however long
[00:37:44.320 --> 00:37:49.840]   that story is at the front of public consciousness and at that point it's too late to do anything
[00:37:49.840 --> 00:37:51.140]   about it.
[00:37:51.140 --> 00:37:56.080]   Once the news media is camped out on your lawn, it's too late to hide your address because
[00:37:56.080 --> 00:38:03.600]   everyone already knows it or once you're doxxed by anonymous or once your account is breached,
[00:38:03.600 --> 00:38:09.760]   yeah you can change that password then and make sure those future emails are safe, but
[00:38:09.760 --> 00:38:13.440]   that doesn't pull back those old emails and make them safe again.
[00:38:13.440 --> 00:38:17.320]   So don't wait until something happens to try to fix it.
[00:38:17.320 --> 00:38:22.960]   Take a proactive approach because that's really the only approach that's going to have any
[00:38:22.960 --> 00:38:23.960]   effectiveness.
[00:38:23.960 --> 00:38:30.160]   Lee: There were two stories that really sobered me and caused me to start working actively
[00:38:30.160 --> 00:38:36.280]   on defense for this, but in the last couple of years, three actually, and they all involved
[00:38:36.280 --> 00:38:37.280]   finances.
[00:38:37.280 --> 00:38:43.440]   Number one was the lady, the publicist who was on her way to South Africa and made a
[00:38:43.440 --> 00:38:49.360]   flippant comment and a tasteless joke on Twitter about contracting AIDS in Africa.
[00:38:49.360 --> 00:38:56.200]   No, I won't contract AIDS because I'm white and just trended bazillions of times on Twitter.
[00:38:56.200 --> 00:39:00.560]   By the time she had landed in South Africa, she'd been fired from her job and she had
[00:39:00.560 --> 00:39:06.000]   basically the whole world finding out every single detail of her during a single airplane
[00:39:06.000 --> 00:39:11.400]   flight and her whole world collapsed and it sent her into severe depression, affected
[00:39:11.400 --> 00:39:15.080]   all of her relationships, her financial world collapsed, etc.
[00:39:15.080 --> 00:39:22.840]   Second one was the dentist who shot the lion and he shot the lion and from my observation,
[00:39:22.840 --> 00:39:27.000]   I didn't follow the story deeply so I could be wrong in this, but I never saw evidence
[00:39:27.000 --> 00:39:31.160]   that he had committed any kind of illegal act or that he had broken the law.
[00:39:31.160 --> 00:39:35.920]   There were a few questions about his interactions with his hunting trip and the purchase of
[00:39:35.920 --> 00:39:41.000]   his licenses, but my guess was that was just probably standard African bribery systems.
[00:39:41.000 --> 00:39:46.600]   But there was no evidence that he had really done anything illegal or even immoral depending
[00:39:46.600 --> 00:39:49.980]   on somebody's definition of morality with regard to shooting lions.
[00:39:49.980 --> 00:39:55.040]   But his business was just destroyed overnight and he was sent into hiding.
[00:39:55.040 --> 00:40:01.140]   His house and with the ability of Google reviews and of Yelp reviews, etc., his business was
[00:40:01.140 --> 00:40:04.840]   just destroyed and his dental practice sent him to the ground.
[00:40:04.840 --> 00:40:06.480]   I don't know what's happened since then.
[00:40:06.480 --> 00:40:14.120]   And then the third one was the pizza restaurant owner in Indiana about two years ago when
[00:40:14.120 --> 00:40:18.440]   Indiana was passing the religious freedom – I think it was the Religious Freedom Restoration
[00:40:18.440 --> 00:40:19.440]   Act.
[00:40:19.440 --> 00:40:26.360]   News crews were hunting for somebody who was professing an opinion on that piece about
[00:40:26.360 --> 00:40:30.960]   being a discriminatory person and they found this pizza restaurant and they found the daughter
[00:40:30.960 --> 00:40:35.520]   of the owner, interviewed her on camera, making some fairly innocuous statements about homosexuality
[00:40:35.520 --> 00:40:37.840]   and religious freedom, etc.
[00:40:37.840 --> 00:40:40.360]   And then this became front and center news.
[00:40:40.360 --> 00:40:46.160]   And again, the pizza restaurant was just pounded into the ground, Yelp reviews destroyed, etc.
[00:40:46.160 --> 00:40:49.600]   All of those cases, none of us know what's happened since.
[00:40:49.600 --> 00:40:57.560]   But none of those three people set out in advance to cause a stir and to bring problems
[00:40:57.560 --> 00:41:01.280]   into their life and to the best of my knowledge, none of them committed anything illegal.
[00:41:01.280 --> 00:41:06.680]   They just had breaches of judgment or took a position that was unpopular, did something
[00:41:06.680 --> 00:41:09.160]   that didn't fit the cultural narrative.
[00:41:09.160 --> 00:41:12.760]   And yet their lives and their livelihood suffered immensely for it.
[00:41:12.760 --> 00:41:18.280]   And in today's day of instant access to the news, etc., I believe this is a serious financial
[00:41:18.280 --> 00:41:22.080]   planning concern that needs to be addressed by financial planners everywhere.
[00:41:22.080 --> 00:41:23.080]   Absolutely.
[00:41:23.080 --> 00:41:28.640]   And, you know, I find this a little bit easier to relate to law enforcement officers in my
[00:41:28.640 --> 00:41:29.640]   training.
[00:41:29.640 --> 00:41:35.520]   And the thing I tell them is, if you're involved in an officer-involved shooting, the news
[00:41:35.520 --> 00:41:40.760]   media is going to be at your house before you are, before you get home that day.
[00:41:40.760 --> 00:41:43.440]   And at that point, there's nothing you can do about it.
[00:41:43.440 --> 00:41:46.960]   And, you know, I was going to bring up the dentist as well, had nothing to do with his
[00:41:46.960 --> 00:41:53.000]   practice, had nothing to do with his family life, had nothing to do with, you know, most
[00:41:53.000 --> 00:41:54.200]   aspects of his life.
[00:41:54.200 --> 00:41:59.960]   This one thing occurred, this one unfortunate event that impacted all of these aspects.
[00:41:59.960 --> 00:42:03.840]   And at that point, there was very little he could do to recover from that.
[00:42:03.840 --> 00:42:11.200]   A proactive approach, you know, every dollar spent in prevention is probably worth, you
[00:42:11.200 --> 00:42:16.760]   know, probably substitute every hundred dollars you'll spend in repairing the damage later
[00:42:16.760 --> 00:42:18.520]   on.
[00:42:18.520 --> 00:42:21.640]   One aspect of, back to financial security and then we'll move to privacy.
[00:42:21.640 --> 00:42:25.000]   One other aspect of financial security that you haven't mentioned that I think is important
[00:42:25.000 --> 00:42:27.880]   is compartmentalization of information.
[00:42:27.880 --> 00:42:35.200]   And I share this because of my experience in the trenches where, you know, if you're,
[00:42:35.200 --> 00:42:40.200]   especially if you have a high profile, high attack surface, again, to use your language,
[00:42:40.200 --> 00:42:44.880]   if you are a prominent person, then the people in the office that you're doing business with
[00:42:44.880 --> 00:42:48.360]   are going to be talking about your name and are going to be pulling up your accounts in
[00:42:48.360 --> 00:42:49.360]   their computer.
[00:42:49.360 --> 00:42:52.200]   I saw this myself.
[00:42:52.200 --> 00:42:56.480]   I worked very hard to never participate, but you can't help but overhear, "Oh, so and so
[00:42:56.480 --> 00:43:01.560]   is a client of mine," and of course some people have access at the administrator level, can
[00:43:01.560 --> 00:43:04.160]   pull up and look and say, "Oh, here's this person's accounts.
[00:43:04.160 --> 00:43:06.000]   Here's that person's accounts," et cetera.
[00:43:06.000 --> 00:43:10.760]   And the staff, the administrative staff, is often somewhat broad who has access to that
[00:43:10.760 --> 00:43:11.760]   information.
[00:43:11.760 --> 00:43:16.400]   So the only way that I know to protect against that is to compartmentalize your information
[00:43:16.400 --> 00:43:21.400]   to the best degree possible, be very careful, and to just share what needs to be known with
[00:43:21.400 --> 00:43:24.080]   the people that need to know it rather than everything.
[00:43:24.080 --> 00:43:25.560]   How do you approach that problem?
[00:43:25.560 --> 00:43:34.880]   I approach that problem with a very proactive front-end approach in that I have essentially
[00:43:34.880 --> 00:43:39.640]   deleted my presence from the internet and there's very little that you will know about
[00:43:39.640 --> 00:43:41.920]   me that I don't want you to know about me.
[00:43:41.920 --> 00:43:46.360]   So I run a blog, I have a Twitter page, I have a podcast, and those are things that
[00:43:46.360 --> 00:43:51.920]   I kind of choose to put in the public space, but everything else I've worked very, very
[00:43:51.920 --> 00:44:00.080]   hard to regain control of, and also to a debatable extent, I do have a public presence that supports
[00:44:00.080 --> 00:44:07.600]   my occupation, my business, my livelihood, but I tend to maintain a pretty low profile
[00:44:07.600 --> 00:44:09.080]   in my personal life.
[00:44:09.080 --> 00:44:14.640]   And that's kind of a tough question in that now we're kind of getting into the things
[00:44:14.640 --> 00:44:18.960]   that require a lot of effort for a little bit of payoff.
[00:44:18.960 --> 00:44:26.140]   But I know this is going to be a very unpopular approach, but I would say the first and foremost
[00:44:26.140 --> 00:44:32.240]   thing that average people need to do, the average listener, not my audience, but everyone
[00:44:32.240 --> 00:44:36.400]   else, which is the majority of society, is pull back your presence on Facebook.
[00:44:36.400 --> 00:44:41.680]   Stop posting every single detail of your life to a public forum.
[00:44:41.680 --> 00:44:46.040]   And even if your Facebook account is fairly locked down, fairly private, it is still on
[00:44:46.040 --> 00:44:51.280]   the open internet, and that information is still available to regular people who really
[00:44:51.280 --> 00:44:53.360]   know how to use Facebook.
[00:44:53.360 --> 00:44:58.440]   That would be, I mean, that's the 90% solution right there.
[00:44:58.440 --> 00:45:00.200]   There's other mitigations we can do.
[00:45:00.200 --> 00:45:07.280]   There are, you know, sorry, Joshua, but I did conduct a little bit of background research
[00:45:07.280 --> 00:45:08.280]   on you.
[00:45:08.280 --> 00:45:11.560]   I would hope you would.
[00:45:11.560 --> 00:45:14.720]   I know you and I exchanged a few emails before this podcast.
[00:45:14.720 --> 00:45:19.520]   You'd written in with a couple of questions, and I thought about sending an email back
[00:45:19.520 --> 00:45:26.320]   saying you need to change your address from, you know, whatever it is.
[00:45:26.320 --> 00:45:30.840]   I'm not going to say it on air, but I didn't want to scare you off.
[00:45:30.840 --> 00:45:36.120]   I pulled back from that, but we can get into removing all those public mentions or at least
[00:45:36.120 --> 00:45:37.760]   most of them from the internet.
[00:45:37.760 --> 00:45:41.280]   So your home address is not easily searchable.
[00:45:41.280 --> 00:45:45.720]   And if you get into some of the self-background stuff that Michael and I talk about in the
[00:45:45.720 --> 00:45:50.120]   book and strongly advocate for just to find out what information exists about you online,
[00:45:50.120 --> 00:45:56.160]   you'll probably be surprised to learn that things like your home address is freely available
[00:45:56.160 --> 00:46:00.640]   on the open internet with your name and the names of your family members.
[00:46:00.640 --> 00:46:02.240]   And to some people, that's alarming.
[00:46:02.240 --> 00:46:06.000]   To people like me, that's certainly very alarming, but some people don't care.
[00:46:06.000 --> 00:46:07.960]   That's kind of public information.
[00:46:07.960 --> 00:46:11.400]   But that also says a lot of other information about you.
[00:46:11.400 --> 00:46:14.360]   I can extrapolate a great deal from that.
[00:46:14.360 --> 00:46:22.600]   Things like your income level, your level of education, possibly your ethnic demographic,
[00:46:22.600 --> 00:46:27.200]   your sexual orientation to some degree based on the neighborhood that you live in.
[00:46:27.200 --> 00:46:32.360]   And that seems like a small piece of information, but it tells me an awful lot about you, especially
[00:46:32.360 --> 00:46:38.760]   in certain neighborhoods that are very densely populated by one demographic or another.
[00:46:38.760 --> 00:46:42.840]   That's significantly private and intensely personal information to me, and I want to
[00:46:42.840 --> 00:46:44.760]   protect that.
[00:46:44.760 --> 00:46:51.120]   If this gets into a lot more effort for a lot less individual payoff per step, but we
[00:46:51.120 --> 00:46:52.600]   can control that information.
[00:46:52.600 --> 00:46:58.240]   We can remove a lot of it and manipulate a lot of it in some cases to make ourselves
[00:46:58.240 --> 00:47:03.200]   a little bit less public and a lot less easily researchable, if that makes sense.
[00:47:03.200 --> 00:47:09.760]   I would say that my own personal, and yes, I have conducted my own open source intelligence
[00:47:09.760 --> 00:47:11.680]   on myself, searches.
[00:47:11.680 --> 00:47:16.000]   And yes, almost everything is freely and openly available, so it would not have surprised
[00:47:16.000 --> 00:47:20.360]   me when you reached out to me.
[00:47:20.360 --> 00:47:23.400]   I would say that my own story is probably the best example.
[00:47:23.400 --> 00:47:26.120]   I never intended to become a public figure.
[00:47:26.120 --> 00:47:29.560]   It was completely unintentional.
[00:47:29.560 --> 00:47:36.640]   And I think this is the way that many people approach it, where they look at it and say,
[00:47:36.640 --> 00:47:41.320]   "Well, I don't have anything to hide."
[00:47:41.320 --> 00:47:45.860]   And also in terms of it's hard to put up walls around yourself for your privacy.
[00:47:45.860 --> 00:47:48.600]   Simple example in financial planning in Florida.
[00:47:48.600 --> 00:47:53.880]   In Florida and in most places, if you do something like purchase a home, your name is going to
[00:47:53.880 --> 00:47:59.560]   be entered into the property tax records as the owner of that local home.
[00:47:59.560 --> 00:48:04.680]   In Florida, this is a big deal because we have an unlimited homestead exemption amount
[00:48:04.680 --> 00:48:10.480]   where you can protect the entire value of your home with no dollar limit.
[00:48:10.480 --> 00:48:17.880]   There are a couple of limits as far as the amount of land that you own, et cetera, but
[00:48:17.880 --> 00:48:19.200]   there's no dollar limit.
[00:48:19.200 --> 00:48:24.540]   So you can protect the value of your home 100% from the claims of any creditors that
[00:48:24.540 --> 00:48:25.940]   you might face.
[00:48:25.940 --> 00:48:30.340]   This is very important with regard to asset protection planning.
[00:48:30.340 --> 00:48:34.520]   And as a financial planner, it's very important that I'm knowledgeable and skillful with that
[00:48:34.520 --> 00:48:36.340]   with regard to working with somebody.
[00:48:36.340 --> 00:48:41.260]   If you are going to looking for a very secure place to stash $10 million, well, going ahead
[00:48:41.260 --> 00:48:46.320]   and purchasing and living in a $10 million waterfront home in Florida is probably a good
[00:48:46.320 --> 00:48:47.800]   plan for that.
[00:48:47.800 --> 00:48:50.040]   But if you do that, you give up your privacy.
[00:48:50.040 --> 00:48:55.240]   And if you purchase that home in the context of a trust, a living trust, or if you purchase
[00:48:55.240 --> 00:49:00.820]   it in the context of an entity of some other kind, you lose that creditor protection.
[00:49:00.820 --> 00:49:01.820]   So it's a balance.
[00:49:01.820 --> 00:49:09.640]   Well, do I take the value of the privacy by owning it within a living trust that's at
[00:49:09.640 --> 00:49:14.660]   least at the very limit, at the very lowest hanging fruit masked in another name, or do
[00:49:14.660 --> 00:49:15.840]   I take the creditor protection?
[00:49:15.840 --> 00:49:19.880]   Because I'll lose that if I put it into a trust that's not held, especially if it's
[00:49:19.880 --> 00:49:21.080]   held jointly with my spouse.
[00:49:21.080 --> 00:49:23.640]   That gives very, very strong protection.
[00:49:23.640 --> 00:49:28.800]   And in my own case, along the way, you just make those normal situations.
[00:49:28.800 --> 00:49:32.840]   When I went and bought a house for the first time, I didn't know everything that I know
[00:49:32.840 --> 00:49:33.840]   now.
[00:49:33.840 --> 00:49:36.080]   And so I just bought a house and signed up for it and you faced a question.
[00:49:36.080 --> 00:49:44.440]   Well, do I try to move so that I can get a different place and protect my privacy?
[00:49:44.440 --> 00:49:47.280]   In the state of Florida, all of the voter records are public data.
[00:49:47.280 --> 00:49:48.480]   So do I register to vote?
[00:49:48.480 --> 00:49:56.840]   Well, it would be a crime for me to register using something that's not my actual information
[00:49:56.840 --> 00:49:57.840]   to some degree.
[00:49:57.840 --> 00:50:01.400]   So do I deregister, not register to vote, et cetera?
[00:50:01.400 --> 00:50:06.600]   And I have found that the whole path is a very challenging terrain to navigate.
[00:50:06.600 --> 00:50:09.600]   And each person has to look and say, well, what is my threat?
[00:50:09.600 --> 00:50:14.480]   Well, as you see, my threat level, my attack surface, as it were, has changed dramatically.
[00:50:14.480 --> 00:50:19.000]   I never expected to be a public figure, never expected to have people know my name all around
[00:50:19.000 --> 00:50:20.000]   the world.
[00:50:20.000 --> 00:50:22.800]   And yet, here we are.
[00:50:22.800 --> 00:50:23.800]   Absolutely agreed.
[00:50:23.800 --> 00:50:26.000]   And it is very much a compromise.
[00:50:26.000 --> 00:50:29.660]   And some things are kind of easy for me to compromise.
[00:50:29.660 --> 00:50:30.660]   You mentioned voting.
[00:50:30.660 --> 00:50:36.000]   And that is, man, voting is one of the most invasive things, privacy-wise, that I can
[00:50:36.000 --> 00:50:37.280]   think of.
[00:50:37.280 --> 00:50:43.320]   I can look up voter records for me if I know where to look and find very detailed records.
[00:50:43.320 --> 00:50:46.080]   And I've kind of made a decision not to vote anymore.
[00:50:46.080 --> 00:50:52.000]   And that's much less a-- it's not laziness.
[00:50:52.000 --> 00:50:57.160]   And as a veteran, I kind of consider that my right to make that decision or not.
[00:50:57.160 --> 00:50:58.880]   It's a very calculated decision.
[00:50:58.880 --> 00:51:00.360]   And part of it is privacy.
[00:51:00.360 --> 00:51:04.740]   And there's also another more ideological aspect to it.
[00:51:04.740 --> 00:51:08.280]   But I've kind of made that decision not to vote.
[00:51:08.280 --> 00:51:16.200]   Also, in regards to owning a home, my first house I bought using a VA loan, which if you
[00:51:16.200 --> 00:51:22.440]   use a VA loan, you can't use any of the privacy mitigations that Michael and I talk about,
[00:51:22.440 --> 00:51:26.180]   some of the more tinfoil hat stuff, because the home has to be in your name.
[00:51:26.180 --> 00:51:27.420]   You are the veteran.
[00:51:27.420 --> 00:51:30.360]   There's no business entity that can take that loan out for you.
[00:51:30.360 --> 00:51:32.440]   So I'm not currently a homeowner.
[00:51:32.440 --> 00:51:34.000]   I'm currently a renter.
[00:51:34.000 --> 00:51:39.160]   And the next house I purchase, I'm going to have to make a decision about that.
[00:51:39.160 --> 00:51:43.200]   And kind of my plan, my long-term plan is to pay cash for it.
[00:51:43.200 --> 00:51:46.640]   But that will be some time down the road for me.
[00:51:46.640 --> 00:51:52.600]   But yeah, all of these things are intensely personal choices.
[00:51:52.600 --> 00:51:59.640]   And I guess I'm not making any specific prescriptions here to do this, don't do that.
[00:51:59.640 --> 00:52:05.520]   I guess what I would advocate much more heavily for is think about it, make a conscious decision.
[00:52:05.520 --> 00:52:09.440]   Don't just go with the default of, yeah, this is how we do it.
[00:52:09.440 --> 00:52:13.960]   Buying cars, for instance, one of the most invasive, buying homes and cars are two of
[00:52:13.960 --> 00:52:18.560]   the most invasive things you can do privacy-wise because there's a credit check.
[00:52:18.560 --> 00:52:26.280]   All this information from Chevrolet or Ford or Nissan is sold to dozens of other parties
[00:52:26.280 --> 00:52:30.720]   who want to sell you extended warranties or refinance your loan or all these other kind
[00:52:30.720 --> 00:52:32.000]   of things.
[00:52:32.000 --> 00:52:35.120]   So think about that before you buy a car again.
[00:52:35.120 --> 00:52:41.920]   And I'm kind of a subscriber to the school of thought that a car is kind of a wheelchair.
[00:52:41.920 --> 00:52:43.240]   It doesn't need to be fancy.
[00:52:43.240 --> 00:52:47.560]   It gets me from A to B. I will never finance another car.
[00:52:47.560 --> 00:52:50.400]   And there's financial reasons for that.
[00:52:50.400 --> 00:52:52.080]   But there's also privacy reasons.
[00:52:52.080 --> 00:52:53.360]   I don't want that paper trail.
[00:52:53.360 --> 00:53:00.480]   I don't want to create this huge bloom of personal data in this kind of field, this
[00:53:00.480 --> 00:53:04.040]   well-manicured field that I take great pains with everywhere else.
[00:53:04.040 --> 00:53:06.040]   So think about it.
[00:53:06.040 --> 00:53:09.080]   Make a conscious decision before you provide this information.
[00:53:09.080 --> 00:53:11.120]   And that kind of goes for everything.
[00:53:11.120 --> 00:53:15.680]   When you go to Lowe's and buy something and they ask for your phone number, we're habituated
[00:53:15.680 --> 00:53:20.720]   and kind of, I guess for lack of a better word, institutionalized to just spit out the
[00:53:20.720 --> 00:53:21.720]   phone number.
[00:53:21.720 --> 00:53:26.760]   So when you're asked for personally identifiable information, think about it.
[00:53:26.760 --> 00:53:30.800]   Ask why am I being asked for this?
[00:53:30.800 --> 00:53:33.200]   Is it really necessary for what I'm doing?
[00:53:33.200 --> 00:53:38.200]   And that guides my decisions on a day-to-day basis, probably much more so than it will
[00:53:38.200 --> 00:53:39.760]   for most.
[00:53:39.760 --> 00:53:44.040]   But I guess that would be my overall advice on that.
[00:53:44.040 --> 00:53:48.320]   How do you buy a car and own a car privately?
[00:53:48.320 --> 00:53:51.640]   So there are a couple of different ways you can do this.
[00:53:51.640 --> 00:53:53.120]   I pay cash.
[00:53:53.120 --> 00:53:55.640]   I paid cash for my last two cars.
[00:53:55.640 --> 00:54:02.480]   And that involves some longer-term financial planning and being kind of fiscally responsible.
[00:54:02.480 --> 00:54:06.200]   And also, I'm not driving a brand new Audi.
[00:54:06.200 --> 00:54:08.640]   So I pay cash.
[00:54:08.640 --> 00:54:10.080]   That's kind of the starting point.
[00:54:10.080 --> 00:54:13.120]   Anytime you're taking a loan, it's going to be very, very invasive.
[00:54:13.120 --> 00:54:17.440]   So there's a couple other ways or a couple other techniques that we can use.
[00:54:17.440 --> 00:54:23.200]   So I am kind of set up on a system where I'm considered a nomad by the state where I claim
[00:54:23.200 --> 00:54:24.200]   legal residence.
[00:54:24.200 --> 00:54:28.100]   I don't spend 51% of my time in any given state because of my travel schedule.
[00:54:28.100 --> 00:54:31.080]   So I'm legally able to do this.
[00:54:31.080 --> 00:54:38.360]   So I just register my car to this mail drop address where I'm legally considered a resident.
[00:54:38.360 --> 00:54:42.180]   I'm legally kind of in the same place as a full-time RVer.
[00:54:42.180 --> 00:54:47.660]   So all my mail goes there, and I don't really care because I'm never at that place.
[00:54:47.660 --> 00:54:53.680]   If I were a homeowner and lived in the same place, what I would do instead is purchase
[00:54:53.680 --> 00:54:56.940]   the car in the name of a New Mexico LLC.
[00:54:56.940 --> 00:55:01.420]   And these limited liability corporations in New Mexico, New Mexico is one of the very
[00:55:01.420 --> 00:55:08.660]   few states that doesn't require that you give the names of the members of the LLC to the
[00:55:08.660 --> 00:55:09.660]   state.
[00:55:09.660 --> 00:55:15.260]   So I'm totally anonymous provided you set up your LLC through a service that kind of
[00:55:15.260 --> 00:55:16.800]   understands that.
[00:55:16.800 --> 00:55:19.780]   And I can give you the name of one such service.
[00:55:19.780 --> 00:55:22.260]   It's JJ Luna's service.
[00:55:22.260 --> 00:55:27.140]   He's very, he's kind of the godfather of this extreme personal privacy.
[00:55:27.140 --> 00:55:28.740]   But that's how I purchase my car.
[00:55:28.740 --> 00:55:35.000]   And when I go to register it, I would just tell the DMV or RMV or whatever your state's
[00:55:35.000 --> 00:55:40.880]   system is that I am doing business on behalf of this corporation in this state, and it's
[00:55:40.880 --> 00:55:45.960]   the corporation's car because it is, and register it to the corporation rather than to my personal
[00:55:45.960 --> 00:55:51.920]   name because the DMV is, most states actually sell the information that you give to the
[00:55:51.920 --> 00:55:55.100]   DMV, including your photograph, to data marketers.
[00:55:55.100 --> 00:55:57.760]   So that's another place that I'm kind of cautious.
[00:55:57.760 --> 00:56:02.560]   And we're kind of veering a little bit more into the more extreme techniques.
[00:56:02.560 --> 00:56:04.560]   - Bring it on, bring it on, don't worry.
[00:56:04.560 --> 00:56:06.520]   I told you we're not scared of extreme techniques around here.
[00:56:06.520 --> 00:56:09.160]   The show's called Radical Personal Finance for a reason.
[00:56:09.160 --> 00:56:10.800]   - Okay, good, good.
[00:56:10.800 --> 00:56:17.440]   But yeah, New Mexico LLC, or if you're in a situation like I am, like Florida, for instance,
[00:56:17.440 --> 00:56:21.760]   allows you to use a commercial mail receiving agency.
[00:56:21.760 --> 00:56:26.880]   There's a few select ones that you can use as your permanent home address.
[00:56:26.880 --> 00:56:30.360]   If you live in Florida, it's really easy to set that up and just have all your mail go
[00:56:30.360 --> 00:56:31.360]   there.
[00:56:31.360 --> 00:56:34.480]   You just go through their website and then they send you your mail to wherever you wanna
[00:56:34.480 --> 00:56:35.480]   get it at.
[00:56:35.480 --> 00:56:38.880]   But that becomes your legally official address.
[00:56:38.880 --> 00:56:42.960]   That's where my taxes go to, that's where my voting stuff goes to, that's where my vehicle
[00:56:42.960 --> 00:56:44.540]   registrations go to.
[00:56:44.540 --> 00:56:48.560]   So nothing comes to my home address.
[00:56:48.560 --> 00:56:54.320]   - It's very, very doable and very, very simple to do.
[00:56:54.320 --> 00:57:00.280]   What about, well, let's go on back to, instead of going deeper on the car, let's go to housing.
[00:57:00.280 --> 00:57:05.320]   What suggestions do you have for living and maintaining a more private residence, especially
[00:57:05.320 --> 00:57:08.720]   for somebody who has concerns about their public status?
[00:57:08.720 --> 00:57:10.100]   - Okay, sure.
[00:57:10.100 --> 00:57:16.760]   So if you're renting like I do, you absolutely have to stay away from the big apartment complexes.
[00:57:16.760 --> 00:57:22.560]   They have a flow chart of things they have to do for new renters and I found it impossible
[00:57:22.560 --> 00:57:29.160]   to basically to get them to bend in their practice of running a credit check, running
[00:57:29.160 --> 00:57:35.720]   a renter background check, and all these other things that place you at that address because
[00:57:35.720 --> 00:57:38.200]   these credit reporting agencies save that data.
[00:57:38.200 --> 00:57:41.840]   Yes, this was queried from this apartment complex, thus this is probably where this
[00:57:41.840 --> 00:57:42.840]   guy lives.
[00:57:42.840 --> 00:57:46.520]   So if you're renting, I would find something on Craigslist.
[00:57:46.520 --> 00:57:51.960]   If you work in a big company, there's probably someone looking to sublet a room or has a
[00:57:51.960 --> 00:57:56.040]   basement apartment or whatever, but you have to find that individual that's renting out
[00:57:56.040 --> 00:57:58.920]   a place and for those, I pay cash.
[00:57:58.920 --> 00:58:02.160]   I'm sure your audience will have no problem with this.
[00:58:02.160 --> 00:58:03.680]   I'm fairly fiscally responsible.
[00:58:03.680 --> 00:58:09.160]   I have some cash in the bank so when I go to that apartment, find that one I want, just
[00:58:09.160 --> 00:58:12.280]   tell the guy, "Hey, I'm just gonna give you three months rent right now.
[00:58:12.280 --> 00:58:14.680]   I will always stay a month ahead on the rent."
[00:58:14.680 --> 00:58:15.680]   And that really talks.
[00:58:15.680 --> 00:58:21.720]   People really tend to respect that and of course, I'm a good tenant and I'm always,
[00:58:21.720 --> 00:58:26.640]   I've lived up to my word, I'm always at least a month ahead on the rent and he has no issues
[00:58:26.640 --> 00:58:31.880]   with that and I don't check up on him to make sure he's paying taxes on that, though I assume
[00:58:31.880 --> 00:58:32.880]   he is.
[00:58:32.880 --> 00:58:35.120]   I have no reason to believe he's not.
[00:58:35.120 --> 00:58:36.360]   But he likes getting cash.
[00:58:36.360 --> 00:58:41.200]   I like giving him cash because my name is not tied to that apartment in any way and
[00:58:41.200 --> 00:58:47.800]   for utilities, I give him a little bit of extra money to keep the utility in his name
[00:58:47.800 --> 00:58:51.840]   and then I make sure those bills are paid on time so he's not getting any blowback from
[00:58:51.840 --> 00:58:52.840]   that.
[00:58:52.840 --> 00:58:54.400]   If I'm buying a house, it becomes a little bit more complicated.
[00:58:54.400 --> 00:58:55.800]   So I've got a couple options here.
[00:58:55.800 --> 00:58:59.120]   If I can pay in cash, which is hard for most people to do, it's impossible for me to do
[00:58:59.120 --> 00:59:03.520]   right now, it would be a few years down the road before I'm able to do this, but if I'm
[00:59:03.520 --> 00:59:10.280]   paying for cash, for a home in cash, again, I can use the New Mexico LLC option.
[00:59:10.280 --> 00:59:15.520]   There's a couple other LLC options, but New Mexico is probably the best one.
[00:59:15.520 --> 00:59:21.760]   Alternatively, if I'm taking out a loan, and again, if you're a VA, someone who would use
[00:59:21.760 --> 00:59:24.800]   a VA loan, this does not apply to you, unfortunately.
[00:59:24.800 --> 00:59:28.840]   But if I'm taking out a loan, I can put that home in the name of a living trust.
[00:59:28.840 --> 00:59:34.800]   A lot of people put their homes in trusts for estate planning, estate management purposes,
[00:59:34.800 --> 00:59:45.280]   and most people put it in the trust, their name, or most people name that trust in their
[00:59:45.280 --> 00:59:46.280]   real name.
[00:59:46.280 --> 00:59:52.120]   So if I were doing this, probably my tendency would be to name it the Justin Carroll Living
[00:59:52.120 --> 00:59:56.320]   Trust, which doesn't afford me any privacy benefit, but it gives me all those estate
[00:59:56.320 --> 00:59:57.720]   planning benefits.
[00:59:57.720 --> 01:00:02.120]   However, if I wanted the privacy, I could name it anything I wanted.
[01:00:02.120 --> 01:00:07.440]   I could name it the South Florida Living Trust, I can name it the anything you could-
[01:00:07.440 --> 01:00:09.120]   123 Maple Street Living Trust.
[01:00:09.120 --> 01:00:14.600]   Yeah, I can name it anything I wanted, and my name is tied to that, but if you don't
[01:00:14.600 --> 01:00:18.200]   know the name of that living, if you can query that trust directly and look at it, you'll
[01:00:18.200 --> 01:00:21.320]   see my name on it, but you have to know the name of it to find it first.
[01:00:21.320 --> 01:00:25.080]   So this is a huge, huge privacy mitigation.
[01:00:25.080 --> 01:00:29.720]   And again, we run into setting up utilities, and in either case, whether I'm purchasing
[01:00:29.720 --> 01:00:36.800]   the home in an LLC or a living trust, I would open up an LLC, a New Mexico LLC, to put those
[01:00:36.800 --> 01:00:43.000]   utilities into, because if I go to all that trouble to purchase a home privately, I also
[01:00:43.000 --> 01:00:48.320]   want to make sure that I'm not tying my name to it with the utilities, because that's gonna
[01:00:48.320 --> 01:00:52.560]   defeat all the hard work that I've done to that point, and there will undoubtedly be
[01:00:52.560 --> 01:00:55.960]   a few roadblocks here.
[01:00:55.960 --> 01:01:00.320]   If you know any attorneys that specialize in privacy, I would love to talk to them,
[01:01:00.320 --> 01:01:03.160]   but sometimes that can be a challenge.
[01:01:03.160 --> 01:01:09.680]   Well, not sometimes, that is always a challenge, finding an attorney who is really comfortable
[01:01:09.680 --> 01:01:15.720]   doing these unconventional techniques and really gets privacy, and that's unfortunate
[01:01:15.720 --> 01:01:18.560]   that that's the case, but it is, sadly.
[01:01:18.560 --> 01:01:25.680]   So yeah, you've got a couple options there, and none of them are absolutely perfect.
[01:01:25.680 --> 01:01:34.880]   The New Mexico LLC comes closest, but the living trust still provides just immensely
[01:01:34.880 --> 01:01:40.160]   more privacy than you're going to have purchasing a home traditionally, putting in your name,
[01:01:40.160 --> 01:01:43.360]   especially if you're borrowing money to pay for it.
[01:01:43.360 --> 01:01:49.240]   To use another one of the terms that I learned from you, you use the term threat model, right?
[01:01:49.240 --> 01:01:50.240]   Yes.
[01:01:50.240 --> 01:01:54.320]   Okay, so how do you define threat model when you use it?
[01:01:54.320 --> 01:02:01.120]   Okay, so threat modeling is kind of a tough case-by-case basis thing, and depends greatly
[01:02:01.120 --> 01:02:06.240]   on what we're talking about, and basically the way I'll do this is take a look at who
[01:02:06.240 --> 01:02:10.040]   my adversary is, who I'm trying to hide from, and then what I look like to them.
[01:02:10.040 --> 01:02:12.720]   So let's say we're talking about email.
[01:02:12.720 --> 01:02:22.080]   My threat model for email is really services like Gmail or just the insipid mass surveillance
[01:02:22.080 --> 01:02:23.080]   that's going on.
[01:02:23.080 --> 01:02:24.480]   I want to kind of opt out of that stuff.
[01:02:24.480 --> 01:02:28.160]   If the NSA wants to look at my stuff, I'm sure they can hack into something and take
[01:02:28.160 --> 01:02:32.000]   a look at it specifically, but that's going to require that they dedicate resources to
[01:02:32.000 --> 01:02:34.000]   it and time to it and that sort of thing.
[01:02:34.000 --> 01:02:38.480]   I don't want to be in that just default mass everything being scooped up.
[01:02:38.480 --> 01:02:40.240]   So my threat model is kind of Google.
[01:02:40.240 --> 01:02:44.400]   I want to be out of Google and mass surveillance.
[01:02:44.400 --> 01:02:46.160]   So I'm comfortable with proton mail.
[01:02:46.160 --> 01:02:52.360]   It doesn't protect me from extreme high-level actors, but it protects me from 90% of things.
[01:02:52.360 --> 01:02:59.400]   If we're talking about taking internet privacy, home privacy, for instance, my threat model
[01:02:59.400 --> 01:03:05.000]   is that I don't want someone to be able to look up my, type my name into a Google search
[01:03:05.000 --> 01:03:08.200]   beside the words home address and actually find my home address.
[01:03:08.200 --> 01:03:11.200]   I'm not, you know, I'm not hiding from the U S marshals.
[01:03:11.200 --> 01:03:14.800]   If they were my threat model, I'd probably never rent anything, never buy anything.
[01:03:14.800 --> 01:03:20.400]   I would probably, you know, live, live in a tent in the woods somewhere and never interact
[01:03:20.400 --> 01:03:21.400]   with anyone.
[01:03:21.400 --> 01:03:22.400]   They're not my threat model.
[01:03:22.400 --> 01:03:26.480]   So it's kind of defining who you're hiding from or who you're trying to protect your
[01:03:26.480 --> 01:03:27.960]   information from.
[01:03:27.960 --> 01:03:31.000]   And of course, in all of these, there are other factors.
[01:03:31.000 --> 01:03:32.280]   Hackers are also my threat model.
[01:03:32.280 --> 01:03:36.560]   So if I'm using wifi at Starbucks, I don't want some kids sitting there with the wifi
[01:03:36.560 --> 01:03:41.800]   antenna to be able to read my email or to capture my login credentials to my bank or
[01:03:41.800 --> 01:03:44.000]   whatever else I happen to be logging into.
[01:03:44.000 --> 01:03:50.920]   So those kinds of general cyber things are always kind of an implied threat model, I
[01:03:50.920 --> 01:03:53.040]   guess, rather than an explicit threat model.
[01:03:53.040 --> 01:03:54.040]   Yeah.
[01:03:54.040 --> 01:03:57.720]   And I'll, and so let me give a couple of, to add to that, I really like your language.
[01:03:57.720 --> 01:04:01.600]   I've stolen all your language and I've applied it in the financial.
[01:04:01.600 --> 01:04:02.600]   Please do.
[01:04:02.600 --> 01:04:03.600]   Yeah.
[01:04:03.600 --> 01:04:04.600]   I do try to give credit.
[01:04:04.600 --> 01:04:05.600]   Don't worry.
[01:04:05.600 --> 01:04:06.600]   I'm not a hacker.
[01:04:06.600 --> 01:04:12.120]   But I apply it in the financial planning context, especially when you get into something like
[01:04:12.120 --> 01:04:16.360]   the question of asset management, asset protection planning.
[01:04:16.360 --> 01:04:21.600]   And you, and that's where you have different tools for different threat models.
[01:04:21.600 --> 01:04:27.800]   One simple thing is, do I have the threat model of my relatives thinking that I am,
[01:04:27.800 --> 01:04:32.320]   you know, I have a couple of relatives that are just no good, broke all the time, spend
[01:04:32.320 --> 01:04:34.240]   all the money and I'm doing well financially.
[01:04:34.240 --> 01:04:39.160]   I want to make sure that I have an ability to have a little bit of concealment around
[01:04:39.160 --> 01:04:40.880]   how much money that I actually have.
[01:04:40.880 --> 01:04:45.440]   Well, if I go and buy a personal residence in my name and then I go ahead and buy four
[01:04:45.440 --> 01:04:50.260]   or five rental properties and they're all personally owned in my name, then with a simple
[01:04:50.260 --> 01:04:53.840]   record search on my local county property appraisers website, all that information is
[01:04:53.840 --> 01:04:54.880]   going to come up.
[01:04:54.880 --> 01:04:59.000]   Or do I want my neighbor who finds out that I'm involved in something to be able to know
[01:04:59.000 --> 01:05:00.900]   how many properties that I have?
[01:05:00.900 --> 01:05:04.820]   So something as simple as owning my personal residence in a living trust and something
[01:05:04.820 --> 01:05:09.220]   as simple as using an entity of some sort for the ownership of my rental properties
[01:05:09.220 --> 01:05:15.260]   and having them segmented and segregated, as you said, adds a tiny little bit of cost
[01:05:15.260 --> 01:05:18.080]   but it lowers my threat significantly.
[01:05:18.080 --> 01:05:25.260]   That doesn't mean that a private investigator who's been hired to investigate me from – based
[01:05:25.260 --> 01:05:29.420]   upon a lawsuit from one of my tenants is not going to be able to find those properties
[01:05:29.420 --> 01:05:33.500]   if they're commonly owned and have a common threat of ownership.
[01:05:33.500 --> 01:05:37.060]   It all depends on how much money they have.
[01:05:37.060 --> 01:05:39.260]   I think that you mentioned J.J.
[01:05:39.260 --> 01:05:42.100]   Luna and his book, How to Be Invisible, which is an excellent book.
[01:05:42.100 --> 01:05:43.100]   I recommend to people.
[01:05:43.100 --> 01:05:46.260]   It's kind of a very readable, thoughtful entry-level discussion.
[01:05:46.260 --> 01:05:50.540]   He gives his different levels of private investigators and he says, "Okay, you're talking about
[01:05:50.540 --> 01:05:54.900]   a level one investigator, a level two, a level three or a level four because at the end of
[01:05:54.900 --> 01:05:55.900]   the day, it costs money.
[01:05:55.900 --> 01:06:00.180]   If you're Osama bin Laden and you're up against the US government, which has an unlimited
[01:06:00.180 --> 01:06:06.540]   source of money and an unlimited interest in finding you, it's going to happen at some
[01:06:06.540 --> 01:06:07.540]   point.
[01:06:07.540 --> 01:06:10.940]   You're not going to be able to escape that scrutiny.
[01:06:10.940 --> 01:06:13.260]   It's just simply not possible.
[01:06:13.260 --> 01:06:17.580]   No matter what you do in time, you're going to be caught up with because of the fact that
[01:06:17.580 --> 01:06:19.140]   you have an unlimited budget.
[01:06:19.140 --> 01:06:21.780]   But your neighbor doesn't have an unlimited budget of time.
[01:06:21.780 --> 01:06:26.340]   You can put different levels of protection in place.
[01:06:26.340 --> 01:06:29.500]   Now if all of a sudden you're a public figure, well now things change.
[01:06:29.500 --> 01:06:31.100]   Now you take different steps.
[01:06:31.100 --> 01:06:35.960]   Or if threat models will vary depending on what type of planning.
[01:06:35.960 --> 01:06:41.460]   If you're involved in something illegal, all of a sudden now things are very, very different
[01:06:41.460 --> 01:06:47.540]   where if you're running a chemical lab, we'll call it in quotations, now you've got to take
[01:06:47.540 --> 01:06:51.260]   a completely—stop running a chemical lab would be my plea.
[01:06:51.260 --> 01:06:54.560]   But if you're running a chemical lab, you've got to take a completely different approach
[01:06:54.560 --> 01:06:59.940]   because you're not worried about a jilted lover.
[01:06:59.940 --> 01:07:02.020]   You're worried about the US government.
[01:07:02.020 --> 01:07:07.900]   And now you're going to be using a very different approach than just somebody, a young woman
[01:07:07.900 --> 01:07:11.180]   protecting herself against a jealous ex-lover.
[01:07:11.180 --> 01:07:15.840]   So at every level, you've got to think practically what am I concerned about because none of
[01:07:15.840 --> 01:07:18.100]   us have unlimited funds.
[01:07:18.100 --> 01:07:22.860]   And it's all a matter of how much am I willing to pay to get the privacy and security that
[01:07:22.860 --> 01:07:24.540]   is appropriate for me.
[01:07:24.540 --> 01:07:25.540]   Absolutely.
[01:07:25.540 --> 01:07:30.340]   And I'm glad you brought up that portion of JJ's book because that's my favorite part
[01:07:30.340 --> 01:07:31.340]   of that.
[01:07:31.340 --> 01:07:35.260]   You know, your level one investigator has a thousand dollar budget.
[01:07:35.260 --> 01:07:36.820]   You know, he's really easy to defeat.
[01:07:36.820 --> 01:07:40.980]   But that level three or four with a hundred thousand dollar budget, he's going to be really,
[01:07:40.980 --> 01:07:41.980]   really hard.
[01:07:41.980 --> 01:07:46.700]   And, you know, probably most of us aren't worried about defeating that like level four
[01:07:46.700 --> 01:07:53.100]   investigator and, you know, it's going to cost a disproportionate amount of money to
[01:07:53.100 --> 01:07:56.740]   hide from him that it is from the level one, two and three.
[01:07:56.740 --> 01:08:01.180]   Like we can do those easy things like tightening up our accounts and pulling back on our Facebook
[01:08:01.180 --> 01:08:04.820]   profile and taking some information down off the Internet.
[01:08:04.820 --> 01:08:08.660]   And those will solve 90 percent of your problems.
[01:08:08.660 --> 01:08:12.860]   It's that last five or 10 percent that's going to take the disproportionate amount of effort
[01:08:12.860 --> 01:08:16.900]   for those very small incremental gains that are going to build up to that.
[01:08:16.900 --> 01:08:21.100]   You know, I say we're never at 100 percent, but it's going to build up to that 99 percent
[01:08:21.100 --> 01:08:27.780]   99th percentile of privacy, I guess, for for lack of a better word.
[01:08:27.780 --> 01:08:29.900]   And it's as simple as it's as simple as this.
[01:08:29.900 --> 01:08:35.900]   Two books that I've read I really enjoyed that relating to threat model.
[01:08:35.900 --> 01:08:41.220]   Many people have heard the advice about don't you know, don't write on Facebook when you're
[01:08:41.220 --> 01:08:46.060]   going to when you're going on vacation because people are searching Facebook.
[01:08:46.060 --> 01:08:48.260]   That's not a new thing.
[01:08:48.260 --> 01:08:52.460]   There's a great book written by a guy named Jack McLean called Secrets of a Super Thief.
[01:08:52.460 --> 01:08:56.300]   He wrote it back in the mid 80s when he was in jail and he was a famous South Florida
[01:08:56.300 --> 01:09:01.020]   cat burglar who claims that he stole and the police agreed with them claims that he stole
[01:09:01.020 --> 01:09:07.520]   about one hundred and thirty million dollars of jewels, money, etc. through thousands of
[01:09:07.520 --> 01:09:09.580]   burglaries all throughout South Florida here.
[01:09:09.580 --> 01:09:12.340]   He was eventually caught and in prison.
[01:09:12.340 --> 01:09:14.860]   He wrote this book called Secrets of a Super Thief.
[01:09:14.860 --> 01:09:18.380]   But he talked about some of his techniques of how he would do these robberies.
[01:09:18.380 --> 01:09:23.020]   Well, a basic thing was going and looking at some if he could look at somebody's mailbox,
[01:09:23.020 --> 01:09:26.860]   he would case the house and say, OK, this house looks like it might be an attractive
[01:09:26.860 --> 01:09:32.220]   target and look at the mailbox number and see the name written on the mailbox number
[01:09:32.220 --> 01:09:36.660]   that gave him access to go to the white pages and look up the phone number for the person.
[01:09:36.660 --> 01:09:41.660]   And he tells a story about one particular mark where he targeted them, he called them
[01:09:41.660 --> 01:09:49.380]   and on their home answering machine it said, we're gone to the Bahamas or to the Caribbean
[01:09:49.380 --> 01:09:50.380]   for three weeks.
[01:09:50.380 --> 01:09:52.500]   We'll be back in a couple of weeks.
[01:09:52.500 --> 01:09:56.460]   So of course he went right over the next night, robbed the house, enjoyed himself and he left
[01:09:56.460 --> 01:10:00.780]   a little note on their kitchen table saying, I hope you're not too sunburned from your
[01:10:00.780 --> 01:10:01.780]   vacation.
[01:10:01.780 --> 01:10:05.420]   Thank you for helping my financial well-being.
[01:10:05.420 --> 01:10:10.740]   He was a very – he did that kind of thing a lot.
[01:10:10.740 --> 01:10:14.420]   So that's an old technique told from a guy who robbed a person.
[01:10:14.420 --> 01:10:17.220]   And in hindsight, you look at that and say, well, that was dumb.
[01:10:17.220 --> 01:10:23.500]   But yet how many of us check in on Instagram and check in on Facebook and say, here I am
[01:10:23.500 --> 01:10:24.500]   at such and such.
[01:10:24.500 --> 01:10:28.540]   We're having a great time and we've got to do it all right when we're there.
[01:10:28.540 --> 01:10:32.500]   Well, you can look up – any burglar who's casing your house can look you up in the property
[01:10:32.500 --> 01:10:33.500]   tax records.
[01:10:33.500 --> 01:10:35.540]   Oh, such and such a house is owned by Joshua Sheets.
[01:10:35.540 --> 01:10:37.060]   Let's go on Facebook, Joshua Sheets.
[01:10:37.060 --> 01:10:39.340]   Oh, look, Joshua Sheets is in South Carolina.
[01:10:39.340 --> 01:10:40.340]   It's safe to go in.
[01:10:40.340 --> 01:10:46.980]   That's a very reasonable, reliable, normal threat model that bears consideration.
[01:10:46.980 --> 01:10:51.980]   Another book I read recently – Justin, have you read the Tom Clancy book recent after
[01:10:51.980 --> 01:10:54.660]   his death published last year called True Faith and Allegiance?
[01:10:54.660 --> 01:10:56.240]   No, I haven't.
[01:10:56.240 --> 01:10:57.240]   You should read it.
[01:10:57.240 --> 01:10:59.780]   I'm looking up these books as you mentioned them though.
[01:10:59.780 --> 01:11:00.780]   OK.
[01:11:00.780 --> 01:11:03.140]   So this book, True Faith and Allegiance.
[01:11:03.140 --> 01:11:06.620]   It was written in the Tom Clancy pen name but of course he's dead now.
[01:11:06.620 --> 01:11:08.660]   It's part of the Jack Ryan series.
[01:11:08.660 --> 01:11:15.460]   But the basic outline of the book is built on open source intelligence.
[01:11:15.460 --> 01:11:20.460]   And the basic plotline – and this is not a spoiler alert.
[01:11:20.460 --> 01:11:31.440]   The basic plotline is that the US government database of all security clearances from many
[01:11:31.440 --> 01:11:39.340]   years previous was released through the efforts of a foreign state who their government hacking
[01:11:39.340 --> 01:11:41.820]   team had been able to get a hold of the file.
[01:11:41.820 --> 01:11:47.280]   And then a rogue Russian agent or Russian or Ukrainian agent had been able to get access
[01:11:47.280 --> 01:11:54.300]   to that file and had used open source intelligence techniques to collate the data with the outdated
[01:11:54.300 --> 01:12:00.800]   secret security clearance data and use the names, fast forward and figure out where these
[01:12:00.800 --> 01:12:02.540]   different people were.
[01:12:02.540 --> 01:12:07.060]   And then through the use of the publicly available Facebook information, other open source intelligence
[01:12:07.060 --> 01:12:12.420]   techniques that you and Michael Bazell teach, had been able to use that information and
[01:12:12.420 --> 01:12:17.820]   provide that information as targeting information to terrorist organizations who then took out
[01:12:17.820 --> 01:12:19.500]   physical attacks.
[01:12:19.500 --> 01:12:26.020]   And it was absolutely astonishing because with the exception of having the data breach
[01:12:26.020 --> 01:12:30.120]   – and this is why that recent data breach of government records to me was so horrifying
[01:12:30.120 --> 01:12:35.140]   – with the exception of the original data breach, there was nothing in the plot that
[01:12:35.140 --> 01:12:37.140]   was out of my capability.
[01:12:37.140 --> 01:12:40.260]   And I'm not even a technical guy.
[01:12:40.260 --> 01:12:41.860]   And I just – it stunned me.
[01:12:41.860 --> 01:12:42.860]   Go ahead.
[01:12:42.860 --> 01:12:47.460]   And if you want this capability for yourself, I can't recommend Michael's Open Source Intelligence
[01:12:47.460 --> 01:12:50.300]   Techniques book strongly enough.
[01:12:50.300 --> 01:12:55.100]   He truly is a world-renowned expert on this.
[01:12:55.100 --> 01:12:57.980]   Probably one of the best guys in the world at open source intelligence.
[01:12:57.980 --> 01:13:03.020]   And he documents all his techniques in extreme detail in his book.
[01:13:03.020 --> 01:13:05.620]   I don't make anything from the sale of his books.
[01:13:05.620 --> 01:13:10.540]   But if you do want that skill set, or even if you just want to play around with it and
[01:13:10.540 --> 01:13:13.660]   see what's really possible, it is such an eye-opener.
[01:13:13.660 --> 01:13:14.660]   It's horrifying.
[01:13:14.660 --> 01:13:24.540]   So I kind of take – forgive me for stealing the interview, but I see that as a very legitimate
[01:13:24.540 --> 01:13:28.060]   concern that doesn't involve my hiding from the U.S. government.
[01:13:28.060 --> 01:13:31.140]   People often immediately go in their thinking to the U.S. government.
[01:13:31.140 --> 01:13:33.740]   That's a real problem because I don't have anything to hide from the U.S. government.
[01:13:33.740 --> 01:13:35.620]   I'm not capable of hiding things.
[01:13:35.620 --> 01:13:42.060]   If I were the subject of attention of a specific focused probe, I don't know that I'm capable
[01:13:42.060 --> 01:13:44.140]   of hiding anything from the U.S. government.
[01:13:44.140 --> 01:13:47.980]   It's beyond my skill set and it's beyond my real interest.
[01:13:47.980 --> 01:13:53.180]   But that doesn't mean that I shouldn't be very circumspect about posting on Facebook
[01:13:53.180 --> 01:13:57.460]   or on my Twitter account that I'm going on vacation when it's very easy for somebody
[01:13:57.460 --> 01:13:58.900]   to find that information.
[01:13:58.900 --> 01:13:59.900]   Absolutely.
[01:13:59.900 --> 01:14:04.940]   And, yeah, if the government wants my – the contents of my bank account, they're not going
[01:14:04.940 --> 01:14:05.940]   to hack the account.
[01:14:05.940 --> 01:14:09.420]   They're just going to go to the bank and say, "Hey, give us everything you have on this
[01:14:09.420 --> 01:14:10.420]   guy."
[01:14:10.420 --> 01:14:13.900]   Yeah, that's not the threat model that I'm working against.
[01:14:13.900 --> 01:14:20.100]   But some of the mitigations I take might make it a little harder for them, but that's not
[01:14:20.100 --> 01:14:21.740]   the intent.
[01:14:21.740 --> 01:14:28.100]   So since this is a financial show, if we have a couple more minutes, there are a couple
[01:14:28.100 --> 01:14:31.300]   financial things that I'd like to hit, if that's all right.
[01:14:31.300 --> 01:14:33.380]   You're turning the conversation exactly where I was going to turn.
[01:14:33.380 --> 01:14:36.020]   I didn't want to miss some of the financial tools, so you go.
[01:14:36.020 --> 01:14:37.300]   OK, great.
[01:14:37.300 --> 01:14:42.980]   I think probably one of the biggest privacy mitigations that you can do for yourself and
[01:14:42.980 --> 01:14:48.860]   your spouse and your children is a security freeze with the credit reporting agencies.
[01:14:48.860 --> 01:14:55.180]   I'm sure you're familiar with this, Joshua, but you call up TransUnion, Equifax, and Experian.
[01:14:55.180 --> 01:15:00.540]   And if you really want to get detailed with it, you can also contact Anovus and Chex Systems
[01:15:00.540 --> 01:15:05.860]   at C-E-H-E-X, and I'll make sure you have all these links, and ask for a security freeze.
[01:15:05.860 --> 01:15:11.780]   And this will lock down your credit, and no credit can be taken out in your name without
[01:15:11.780 --> 01:15:16.460]   the eight-digit code and identity verification with that agency.
[01:15:16.460 --> 01:15:19.180]   So this doesn't expire.
[01:15:19.180 --> 01:15:22.860]   It might cost you $10, depending on the state that you live in, and I'm not going to list
[01:15:22.860 --> 01:15:28.100]   those, but some states are free, some they cost $10 per agency, unless you have been
[01:15:28.100 --> 01:15:29.500]   the victim of identity theft.
[01:15:29.500 --> 01:15:33.420]   If you've ever been the victim of even very low, had to change a credit card number, for
[01:15:33.420 --> 01:15:38.580]   instance, because someone had used your credit card number, you're eligible for free credit
[01:15:38.580 --> 01:15:42.600]   freezes or security freezes for life.
[01:15:42.600 --> 01:15:48.140]   So if you do need to take out credit, you go to whoever you're applying for credit with,
[01:15:48.140 --> 01:15:51.740]   your mortgage lender, and say, "Who are you going to run my credit through?"
[01:15:51.740 --> 01:15:52.820]   They say, "TransUnion."
[01:15:52.820 --> 01:15:56.580]   You call TransUnion, say, "Hey, lift my freeze for 24 hours."
[01:15:56.580 --> 01:15:59.960]   They run your credit, and then that freeze is back in place.
[01:15:59.960 --> 01:16:05.800]   This will also stop you completely from getting pre-approved credit card offers because those
[01:16:05.800 --> 01:16:09.240]   credit companies can't do soft pulls on your credit.
[01:16:09.240 --> 01:16:16.960]   It protects your address because no automatically generated mail like that, junk mail, like
[01:16:16.960 --> 01:16:20.240]   those pre-approved offers are automatically being sent to your house because they can't
[01:16:20.240 --> 01:16:21.280]   see your credit report.
[01:16:21.280 --> 01:16:22.840]   They can't get your address from that.
[01:16:22.840 --> 01:16:24.720]   It has a million benefits.
[01:16:24.720 --> 01:16:26.480]   It's really easy to implement.
[01:16:26.480 --> 01:16:32.680]   And this is probably the best security you can do on your line of credit.
[01:16:32.680 --> 01:16:34.240]   This doesn't protect existing accounts.
[01:16:34.240 --> 01:16:38.920]   If you lose your credit card, obviously that card can still be used until you report it
[01:16:38.920 --> 01:16:42.080]   and it's locked down by the bank.
[01:16:42.080 --> 01:16:45.480]   But this is the way it should be, in my opinion.
[01:16:45.480 --> 01:16:50.960]   I don't know why this is not the default, but you have to take action.
[01:16:50.960 --> 01:16:55.520]   If you're the average person and not like me, whose bank thinks that I'm dead and all
[01:16:55.520 --> 01:17:01.480]   this other problems that I have now, this might take you 10 minutes per credit reporting
[01:17:01.480 --> 01:17:02.480]   agency.
[01:17:02.480 --> 01:17:07.760]   Just don't lose that eight digit code and your credit is extremely well protected for
[01:17:07.760 --> 01:17:08.760]   a very long time.
[01:17:08.760 --> 01:17:12.560]   If there's one thing you take out of the show that's beyond the password two factor stuff,
[01:17:12.560 --> 01:17:13.960]   it is this.
[01:17:13.960 --> 01:17:19.040]   The next thing that I'm a strong proponent of is stop giving the bank information about
[01:17:19.040 --> 01:17:24.600]   where you shop, where you eat, where you stop for coffee, how you spend your money, all
[01:17:24.600 --> 01:17:26.720]   the elective places your money goes.
[01:17:26.720 --> 01:17:32.240]   I do that through a multi-pronged approach.
[01:17:32.240 --> 01:17:33.840]   First and foremost, I use cash.
[01:17:33.840 --> 01:17:38.600]   I take $300, $400 out at the beginning of the week and that's how I purchase my fuel.
[01:17:38.600 --> 01:17:40.480]   That's how I pay for coffee.
[01:17:40.480 --> 01:17:41.480]   That's how I pay for lunch.
[01:17:41.480 --> 01:17:46.480]   That's how I buy things when I go to the grocery store or to whatever store I'm buying things
[01:17:46.480 --> 01:17:47.480]   from.
[01:17:47.480 --> 01:17:51.680]   I've told this story before and it's on my blog and it's probably talked about it on
[01:17:51.680 --> 01:17:52.680]   the podcast.
[01:17:52.680 --> 01:17:57.360]   When I applied for my first home loan, I had to give them three months of statements from
[01:17:57.360 --> 01:18:00.400]   every credit and bank account that I had.
[01:18:00.400 --> 01:18:04.560]   I was really shocked to find that if you looked at this, it spelled out, you could pretty
[01:18:04.560 --> 01:18:07.640]   much figure out where I live and where I work based on where I stop for gas and where I
[01:18:07.640 --> 01:18:12.800]   get coffee every morning and the restaurants that I routinely go to lunch at and the restaurants
[01:18:12.800 --> 01:18:20.800]   that I routinely go to dinner at and the special interests I have based on the stores and activities
[01:18:20.800 --> 01:18:23.000]   that I spend money on.
[01:18:23.000 --> 01:18:26.760]   This was really shocking to me and I decided then and there, I'm never going to give the
[01:18:26.760 --> 01:18:29.840]   bank that level of insight into my life again.
[01:18:29.840 --> 01:18:33.320]   That was a strong motivator to start using cash.
[01:18:33.320 --> 01:18:38.800]   The other thing that I recommend is a service called privacy.com.
[01:18:38.800 --> 01:18:41.360]   If you've listened to the show, you're familiar with this.
[01:18:41.360 --> 01:18:42.960]   We interviewed the CEO.
[01:18:42.960 --> 01:18:46.960]   You set up an account, you give it access to your bank account and then if I need to
[01:18:46.960 --> 01:18:49.940]   make an online purchase, obviously I can't use cash.
[01:18:49.940 --> 01:18:54.920]   What I do is I log into privacy.com and I tell privacy, "Hey, I'm getting ready to set
[01:18:54.920 --> 01:19:00.600]   up an amazon.com account or I'm getting ready to make a purchase through, I'm getting ready
[01:19:00.600 --> 01:19:04.240]   to set up my bill pay for my electric company.
[01:19:04.240 --> 01:19:09.360]   Give me a unique credit card number to use to pay my electricity bill.
[01:19:09.360 --> 01:19:12.000]   Give me a unique credit card number for this Amazon account."
[01:19:12.000 --> 01:19:21.980]   It creates a credit card complete with a credit card number, an expiration date and a CCV
[01:19:21.980 --> 01:19:22.980]   code.
[01:19:22.980 --> 01:19:26.020]   I can set up all these other factors.
[01:19:26.020 --> 01:19:28.700]   They're all set up as single merchant cards.
[01:19:28.700 --> 01:19:34.060]   My electric company is the only merchant that can bill to that card.
[01:19:34.060 --> 01:19:37.500]   If they lose that credit card number, it's worthless to everybody else.
[01:19:37.500 --> 01:19:40.660]   I can also set a limit.
[01:19:40.660 --> 01:19:44.220]   Let's say my electric bill is $150 a month.
[01:19:44.220 --> 01:19:52.060]   I set that firm limit at let's say $160 just in case and they can never draw more than
[01:19:52.060 --> 01:19:57.220]   $160 per month from that account.
[01:19:57.220 --> 01:20:01.140]   Let's say they do have a breach and that number is stolen, I can go in and delete that card,
[01:20:01.140 --> 01:20:06.420]   make a new one, give the electric company a new card and now they can run on that.
[01:20:06.420 --> 01:20:11.740]   If this is a one-off website where I'm going to make one purchase one time ever in my life,
[01:20:11.740 --> 01:20:14.860]   I can also make that a, they call it a burner card.
[01:20:14.860 --> 01:20:19.180]   So once that one transaction is made, that card is worthless from then on out.
[01:20:19.180 --> 01:20:20.740]   I don't have to worry about canceling it.
[01:20:20.740 --> 01:20:22.500]   It's already canceled.
[01:20:22.500 --> 01:20:25.620]   This is a really strong service and it does a couple things.
[01:20:25.620 --> 01:20:30.140]   It takes the bank out of the loop because all these charges, they just see it being
[01:20:30.140 --> 01:20:31.700]   billed to privacy.com.
[01:20:31.700 --> 01:20:36.820]   They don't see that going out to Amazon or Best Buy.com or any of these other services.
[01:20:36.820 --> 01:20:41.420]   They just see a charge to privacy.com.
[01:20:41.420 --> 01:20:45.220]   All these merchants that I'm buying from also don't see my name because I can give it any
[01:20:45.220 --> 01:20:49.100]   name, any shipping address and any billing address that I choose.
[01:20:49.100 --> 01:20:53.300]   So if this is, let's say I'm signing up with an online dating site or something that maybe
[01:20:53.300 --> 01:20:57.740]   I'm not super proud of, I can give it any name I want, give it any address I want.
[01:20:57.740 --> 01:20:59.260]   It doesn't tie back to me.
[01:20:59.260 --> 01:21:03.180]   So if that's breached, I'm not really that worried about it because it doesn't come back
[01:21:03.180 --> 01:21:04.180]   to me.
[01:21:04.180 --> 01:21:07.780]   You'd have to know what name and address I'd given it.
[01:21:07.780 --> 01:21:10.060]   So this protects me in a bunch of different ways.
[01:21:10.060 --> 01:21:14.060]   And like I said, if any of these services spill their data, I don't really care because
[01:21:14.060 --> 01:21:19.060]   I just cancel that card, make a new one and I haven't lost anything.
[01:21:19.060 --> 01:21:27.940]   This takes my risk from account takeover or data breaches down to virtually nothing as
[01:21:27.940 --> 01:21:30.100]   far as financial concerns go.
[01:21:30.100 --> 01:21:33.100]   I love privacy.com.
[01:21:33.100 --> 01:21:34.700]   I use it for everything.
[01:21:34.700 --> 01:21:40.540]   Any purchase I make online, I have all my auto bill pay things set up to privacy.com.
[01:21:40.540 --> 01:21:45.300]   All my online purchases, I don't ever give out my real credit card number anymore.
[01:21:45.300 --> 01:21:48.940]   And one of my favorite things, you did a great job describing the features.
[01:21:48.940 --> 01:21:55.740]   One of my favorite just philosophical aspects is it puts the user back in control.
[01:21:55.740 --> 01:21:58.060]   I don't like auto billing.
[01:21:58.060 --> 01:22:03.980]   I've faced major financial problems in the past because my appetite exceeded my income
[01:22:03.980 --> 01:22:07.740]   and I would sign up for auto billing on this and that and the other thing.
[01:22:07.740 --> 01:22:13.980]   Unfortunately, in today's world, I work with many merchants who just will not send me a
[01:22:13.980 --> 01:22:18.860]   paper bill and will not send me a, you know, they just won't do it.
[01:22:18.860 --> 01:22:20.380]   I can't send them a check.
[01:22:20.380 --> 01:22:21.460]   I can't send them something.
[01:22:21.460 --> 01:22:24.220]   They require an auto bill pay.
[01:22:24.220 --> 01:22:28.580]   Now, 99.999% of the time, that's fine.
[01:22:28.580 --> 01:22:30.860]   We have an amicable working relationship.
[01:22:30.860 --> 01:22:32.920]   Everything works fine.
[01:22:32.920 --> 01:22:34.900]   But still, they're in control.
[01:22:34.900 --> 01:22:36.200]   They're in the billing.
[01:22:36.200 --> 01:22:40.360]   And if I need to change something or if I get into a dispute with them, that could mess
[01:22:40.360 --> 01:22:44.700]   up many accounts if I need to change card numbers and things like that.
[01:22:44.700 --> 01:22:47.900]   Privacy.com is wonderful because it puts me back in control.
[01:22:47.900 --> 01:22:53.900]   And I can set up a different card with every biller and in a voluntary win-win, voluntary
[01:22:53.900 --> 01:22:57.300]   transaction where we're working on agreed terms.
[01:22:57.300 --> 01:22:58.300]   I can pay them.
[01:22:58.300 --> 01:22:59.300]   They receive their money.
[01:22:59.300 --> 01:23:00.380]   We're all happy.
[01:23:00.380 --> 01:23:05.640]   In a combative, hostile situation where we've reached a problem, I'm in control just like
[01:23:05.640 --> 01:23:09.860]   I used to be with my choice to send a check or not for payment.
[01:23:09.860 --> 01:23:11.380]   And that to me is how it should be.
[01:23:11.380 --> 01:23:17.620]   The consumer is always in charge and the consumer should have control over the billing, not
[01:23:17.620 --> 01:23:18.620]   the vendor.
[01:23:18.620 --> 01:23:19.620]   Absolutely.
[01:23:19.620 --> 01:23:21.900]   No question about it.
[01:23:21.900 --> 01:23:27.940]   And privacy.com is kind of founded on a little bit of an ideological mindset.
[01:23:27.940 --> 01:23:32.940]   And the one thing I will warn listeners of is if you sign up for this, you have to give
[01:23:32.940 --> 01:23:35.780]   your bank username and password to privacy.com.
[01:23:35.780 --> 01:23:38.700]   And that's scary for a lot of people.
[01:23:38.700 --> 01:23:40.100]   Absolutely understandable.
[01:23:40.100 --> 01:23:41.860]   Even I was nervous about it.
[01:23:41.860 --> 01:23:47.900]   But like I said, I've spent an hour and a half on the phone with the CEO.
[01:23:47.900 --> 01:23:50.100]   Michael and I interviewed him on the podcast.
[01:23:50.100 --> 01:23:53.340]   I have a really good feeling about where they're coming from.
[01:23:53.340 --> 01:23:55.920]   Their privacy policy is clearly spelled out.
[01:23:55.920 --> 01:24:01.500]   And just one thing to note, the way privacy.com is structured, they are essentially a bank.
[01:24:01.500 --> 01:24:09.620]   So you're protected by all the laws that govern banking and how that information is handled.
[01:24:09.620 --> 01:24:14.140]   And I think they're probably actually doing a much better job at security than most banks
[01:24:14.140 --> 01:24:15.140]   are.
[01:24:15.140 --> 01:24:18.300]   Justin, did you know, I recently was on a phone call with a coaching client of mine
[01:24:18.300 --> 01:24:25.140]   and they told me that Citibank offers this service, that they offer one-time burner numbers
[01:24:25.140 --> 01:24:27.020]   for online transactions.
[01:24:27.020 --> 01:24:28.300]   Were you aware of that?
[01:24:28.300 --> 01:24:30.940]   I wasn't aware of Citibank specifically.
[01:24:30.940 --> 01:24:34.740]   I know that there are a few banks that will do this.
[01:24:34.740 --> 01:24:35.740]   Do you have it?
[01:24:35.740 --> 01:24:36.740]   Have you used this?
[01:24:36.740 --> 01:24:37.740]   Do you have any experience with it?
[01:24:37.740 --> 01:24:38.740]   I have not.
[01:24:38.740 --> 01:24:39.740]   No.
[01:24:39.740 --> 01:24:42.060]   Again, back to my book outline, I need to research other banks that did.
[01:24:42.060 --> 01:24:47.260]   I was not aware that this was being marketed nor used outside of the privacy.com, pseudo
[01:24:47.260 --> 01:24:49.340]   pay, etc.
[01:24:49.340 --> 01:24:50.700]   Blur, other services like that.
[01:24:50.700 --> 01:24:54.380]   I knew about those services, but I didn't know that the mainstream credit card companies
[01:24:54.380 --> 01:24:56.780]   were starting to offer this service.
[01:24:56.780 --> 01:25:01.980]   So for the complete privacy and security desk reference, Michael and I had this idea that
[01:25:01.980 --> 01:25:05.100]   we were going to set up accounts with all these different banks to see what features
[01:25:05.100 --> 01:25:06.100]   they had.
[01:25:06.100 --> 01:25:08.420]   And we were kind of aware of that one.
[01:25:08.420 --> 01:25:14.940]   But with our credit lockdown the way it is and with my address history as sketchy as
[01:25:14.940 --> 01:25:20.180]   it is, I found very quickly it's really hard for me to open up additional bank accounts.
[01:25:20.180 --> 01:25:21.700]   So we backed off that.
[01:25:21.700 --> 01:25:26.780]   But if anyone has used this in practice, you would be teaching me something.
[01:25:26.780 --> 01:25:29.180]   I'd be really curious to know how that works in practice.
[01:25:29.180 --> 01:25:33.780]   Email Justin through the, your website is yourultimatesecurity.guide, right?
[01:25:33.780 --> 01:25:34.780]   Yes, that's correct.
[01:25:34.780 --> 01:25:37.820]   Okay, so email Justin through his contact form and let him know.
[01:25:37.820 --> 01:25:39.060]   And send it to me as well.
[01:25:39.060 --> 01:25:40.660]   Justin, I'm going to test you.
[01:25:40.660 --> 01:25:42.940]   I'm interested to know.
[01:25:42.940 --> 01:25:52.660]   If you wanted, if you had to set up privacy.com as anonymously as possible, just a mental
[01:25:52.660 --> 01:25:57.100]   exercise, knowing that you were going to give banking information to them, and I consider
[01:25:57.100 --> 01:26:01.380]   this to be back to threat model, an unreasonable threat model.
[01:26:01.380 --> 01:26:04.100]   This is where you're in the criminal world or you're accused of something.
[01:26:04.100 --> 01:26:07.700]   How would you do it?
[01:26:07.700 --> 01:26:14.380]   This is tough because privacy.com is accountable to KYC laws, know your customer laws, which
[01:26:14.380 --> 01:26:16.900]   requires that they verify identity.
[01:26:16.900 --> 01:26:25.520]   But the way I might do this is set up an LLC, open up a bank account for that LLC, which
[01:26:25.520 --> 01:26:30.340]   again, we run into the problem of I would have to give my social security number to
[01:26:30.340 --> 01:26:34.260]   get the bank account, but that would create one additional layer.
[01:26:34.260 --> 01:26:42.620]   And then I would try to only give privacy.com the EIN for that business that I had set up.
[01:26:42.620 --> 01:26:47.380]   And I don't know if that would work or not, but it might be worth a try.
[01:26:47.380 --> 01:26:48.380]   All right.
[01:26:48.380 --> 01:26:52.580]   The only other idea I had was this would be where you would use a nominee.
[01:26:52.580 --> 01:26:56.740]   This would be where you would have to find somebody that you could trust, that you could
[01:26:56.740 --> 01:27:02.700]   work with, and that way you have the account disconnected from you and your actual identity.
[01:27:02.700 --> 01:27:07.660]   And once it's verified, it might be possible to use that.
[01:27:07.660 --> 01:27:11.380]   Sorry, I always enjoy thinking about these scenarios and thinking, okay, in the most
[01:27:11.380 --> 01:27:14.060]   hardcore scenario, how do you figure it out?
[01:27:14.060 --> 01:27:15.060]   What's the solution?
[01:27:15.060 --> 01:27:17.060]   I love the mental game of it.
[01:27:17.060 --> 01:27:21.780]   And that might be a great place to use a nominee, say, "Hey, here's a hundred bucks.
[01:27:21.780 --> 01:27:27.300]   Set up this account and then hand it over to me because you can change the password
[01:27:27.300 --> 01:27:31.340]   and you can put two factor on it," which would essentially block that person out.
[01:27:31.340 --> 01:27:37.740]   And if they're like most people, they will probably forget about it in six months and
[01:27:37.740 --> 01:27:39.380]   never even remember doing that.
[01:27:39.380 --> 01:27:45.780]   But I would always have that concern that that person would get greedy and call privacy.com
[01:27:45.780 --> 01:27:47.300]   and say, "Hey, someone's using my name.
[01:27:47.300 --> 01:27:48.620]   This is actually my account."
[01:27:48.620 --> 01:27:52.820]   And I would run into issues that way.
[01:27:52.820 --> 01:27:54.380]   Far fetch, maybe.
[01:27:54.380 --> 01:27:55.380]   I don't know.
[01:27:55.380 --> 01:27:57.380]   What was the quote that's attributed to Ben Franklin?
[01:27:57.380 --> 01:28:01.500]   "Three can keep a secret if two are dead."
[01:28:01.500 --> 01:28:04.100]   That's always how it is.
[01:28:04.100 --> 01:28:05.820]   And that's why crime doesn't pay.
[01:28:05.820 --> 01:28:12.660]   That's where all these things, it's always going to be somebody usually who exposes something.
[01:28:12.660 --> 01:28:17.180]   And I do want to make clear that nothing in our book, like both Michael and I are closely
[01:28:17.180 --> 01:28:18.540]   affiliated with the US government.
[01:28:18.540 --> 01:28:21.340]   We don't advocate this for any type of criminal activity.
[01:28:21.340 --> 01:28:24.020]   And I know that you don't either.
[01:28:24.020 --> 01:28:28.300]   But we do enjoy some thought experiments from time to time.
[01:28:28.300 --> 01:28:29.300]   Exactly.
[01:28:29.300 --> 01:28:30.300]   Point well taken.
[01:28:30.300 --> 01:28:32.420]   It's just fun to sit down and think about it sometimes.
[01:28:32.420 --> 01:28:33.420]   It is, yeah.
[01:28:33.420 --> 01:28:34.820]   I'm so glad you went through that.
[01:28:34.820 --> 01:28:36.100]   Last question I would ask you.
[01:28:36.100 --> 01:28:40.460]   I mentioned a couple of the other services, the other two competitors, and maybe there
[01:28:40.460 --> 01:28:41.460]   are more as well.
[01:28:41.460 --> 01:28:42.740]   And I'd love to see more come on the market.
[01:28:42.740 --> 01:28:46.980]   But privacy, I think, is fantastic.
[01:28:46.980 --> 01:28:53.940]   There's also PseudoPay, which is an app on the phone, and Blur, which is from the company
[01:28:53.940 --> 01:28:54.940]   Abine.
[01:28:54.940 --> 01:28:55.940]   Is that how you say their name?
[01:28:55.940 --> 01:28:56.940]   Abine, Abine, yeah.
[01:28:56.940 --> 01:28:58.700]   Yeah, something like that.
[01:28:58.700 --> 01:29:02.660]   So how do you mention those services as well in case people would like some options and
[01:29:02.660 --> 01:29:04.580]   compare and contrast them, please?
[01:29:04.580 --> 01:29:05.580]   Okay, sure.
[01:29:05.580 --> 01:29:08.820]   So PseudoPay is an iOS app.
[01:29:08.820 --> 01:29:13.340]   And I'll circle back around to this one at the end because their Pseudo app is really
[01:29:13.340 --> 01:29:16.220]   fantastic as well.
[01:29:16.220 --> 01:29:19.260]   PseudoPay does not require any money to set up an account.
[01:29:19.260 --> 01:29:25.100]   You install the app, set up your account, and it draws funds from your Apple Pay account.
[01:29:25.100 --> 01:29:28.460]   And much like privacy, it will make one-time use credit cards.
[01:29:28.460 --> 01:29:33.220]   And your charges, credit cards and debit cards, are two completely different things.
[01:29:33.220 --> 01:29:39.020]   In the banking world, I've learned, and you are charged a small fee for each one of these
[01:29:39.020 --> 01:29:42.460]   make, and it's based on a percentage of how much money is on the credit card.
[01:29:42.460 --> 01:29:49.260]   But I really do like this because of the convenience of, as an example, I visited New York City
[01:29:49.260 --> 01:29:51.060]   this summer.
[01:29:51.060 --> 01:29:55.220]   And kind of at the spur of the moment, we decided to go to the top of the rock, which
[01:29:55.220 --> 01:29:57.540]   you have to buy tickets online.
[01:29:57.540 --> 01:29:59.940]   And obviously, it wasn't at my computer.
[01:29:59.940 --> 01:30:01.660]   We were already downtown.
[01:30:01.660 --> 01:30:07.020]   And I just pulled out my phone, opened up PseudoPay, and created a credit card.
[01:30:07.020 --> 01:30:11.700]   And I had a card right there to pay for those tickets online.
[01:30:11.700 --> 01:30:12.700]   Really, really convenient.
[01:30:12.700 --> 01:30:15.260]   It's another option in the toolbox.
[01:30:15.260 --> 01:30:16.260]   Blur is the other one.
[01:30:16.260 --> 01:30:18.180]   It requires that you set up an account.
[01:30:18.180 --> 01:30:23.940]   And currently, right now, they are offering lifetime accounts for $119.
[01:30:23.940 --> 01:30:26.340]   Blur lets you set up one-time credit cards.
[01:30:26.340 --> 01:30:29.860]   Also, there's also a small fee for each one that you set up.
[01:30:29.860 --> 01:30:32.180]   Blur also has a ton of other features.
[01:30:32.180 --> 01:30:35.940]   It gives you a masked phone number, which will forward calls and texts to your real
[01:30:35.940 --> 01:30:37.820]   phone number if you so choose.
[01:30:37.820 --> 01:30:42.500]   It also has masked email addresses, which I use every single day.
[01:30:42.500 --> 01:30:47.480]   And I use these to set up unique usernames on accounts that require an email address.
[01:30:47.480 --> 01:30:51.900]   And they all forward into my regular ProtonMail inbox.
[01:30:51.900 --> 01:30:55.360]   I set up ProtonMail as the account that those go to.
[01:30:55.360 --> 01:30:56.540]   And then I give out these.
[01:30:56.540 --> 01:31:01.580]   I make unique email addresses for absolutely everything through Blur.
[01:31:01.580 --> 01:31:04.940]   Give those out, and they're forwarded right into my regular inbox.
[01:31:04.940 --> 01:31:05.940]   Super easy.
[01:31:05.940 --> 01:31:08.100]   So, that's also another option.
[01:31:08.100 --> 01:31:12.240]   And then I mentioned I would come back to PseudoPay.
[01:31:12.240 --> 01:31:13.240]   Their pseudo app...
[01:31:13.240 --> 01:31:17.060]   By the way, pseudo is S-U-D-O, not P-S-E-U-D-O.
[01:31:17.060 --> 01:31:18.740]   S-U-D-O, PseudoPay.
[01:31:18.740 --> 01:31:19.740]   Yes.
[01:31:19.740 --> 01:31:20.740]   Good call.
[01:31:20.740 --> 01:31:23.460]   But the pseudo app...
[01:31:23.460 --> 01:31:26.100]   Man, this thing is a game changer for me.
[01:31:26.100 --> 01:31:32.580]   It gives you nine pseudos, again, S-U-D-O, but nine pseudo identities, each with its
[01:31:32.580 --> 01:31:34.540]   own email address and phone number.
[01:31:34.540 --> 01:31:39.140]   So, you have nine phone numbers that will forward to your phone.
[01:31:39.140 --> 01:31:43.500]   And man, I can't recommend this strongly enough, because here's how I kind of use that.
[01:31:43.500 --> 01:31:45.740]   I have one that is for my financial stuff.
[01:31:45.740 --> 01:31:51.220]   It's for my bank account, my Coinbase account, any kind of accounts that deal with money
[01:31:51.220 --> 01:31:56.460]   that would cost me money financially if those accounts are breached.
[01:31:56.460 --> 01:31:57.840]   And there's a reason I do that.
[01:31:57.840 --> 01:32:01.500]   If you breach my Facebook account, which I don't have Facebook, but I realize most people
[01:32:01.500 --> 01:32:05.580]   do, if you breach my Facebook account, you're going to have my phone number, which means
[01:32:05.580 --> 01:32:09.780]   you're probably going to have the phone number that I verify my bank transactions with.
[01:32:09.780 --> 01:32:13.740]   So I can just take that completely out of the loop, put those bank accounts on their
[01:32:13.740 --> 01:32:14.740]   own phone number.
[01:32:14.740 --> 01:32:16.580]   That's the only people that get that number.
[01:32:16.580 --> 01:32:22.900]   Then I can have another number just for those two-factor authentication codes with my accounts,
[01:32:22.900 --> 01:32:24.980]   my online accounts that send SMS messages.
[01:32:24.980 --> 01:32:27.740]   So yeah, you can hack my cell phone account.
[01:32:27.740 --> 01:32:29.980]   It doesn't really matter, because those go to a pseudo number.
[01:32:29.980 --> 01:32:36.460]   And this just gives you, man, I can't overstate the flexibility of having these different
[01:32:36.460 --> 01:32:42.580]   phone numbers, because your phone number these days is literally more valuable than a social
[01:32:42.580 --> 01:32:47.580]   security number as far as your identity goes, because we use it to set up all our online
[01:32:47.580 --> 01:32:50.780]   accounts and we use it for verification and all these other things.
[01:32:50.780 --> 01:32:55.700]   If I have your phone number, man, I know a lot of information about you.
[01:32:55.700 --> 01:33:01.260]   It's huge, and I can't add any more.
[01:33:01.260 --> 01:33:05.700]   If people – I'm thinking about resources to share with the audience as far as people
[01:33:05.700 --> 01:33:09.700]   who are new to the subject and some of the news reports that have been done, some of
[01:33:09.700 --> 01:33:11.540]   the just different information.
[01:33:11.540 --> 01:33:17.380]   But the phone number is hugely – I have learned and been remiss in the past about
[01:33:17.380 --> 01:33:20.260]   how important that little piece of data is.
[01:33:20.260 --> 01:33:24.980]   And it's important.
[01:33:24.980 --> 01:33:26.500]   And just little things.
[01:33:26.500 --> 01:33:32.900]   So you can use – I recommend it to people to start with some simple things like Craigslist
[01:33:32.900 --> 01:33:33.900]   transactions.
[01:33:33.900 --> 01:33:38.580]   I recently sold my motorhome on Craigslist.
[01:33:38.580 --> 01:33:41.100]   And the transaction – I thought everything went great.
[01:33:41.100 --> 01:33:43.540]   Then all of a sudden, everything went bad.
[01:33:43.540 --> 01:33:45.060]   And it exposed me afresh.
[01:33:45.060 --> 01:33:51.580]   I ended up having to call the police when interacting with the buyer on my transaction.
[01:33:51.580 --> 01:33:53.860]   And so I started asking him about Craigslist fraud.
[01:33:53.860 --> 01:33:57.140]   And he started telling me stories about – the police officer started telling me stories
[01:33:57.140 --> 01:34:04.100]   about different – just different times of Craigslist fraud and crimes that have been
[01:34:04.100 --> 01:34:06.020]   committed and different things.
[01:34:06.020 --> 01:34:11.100]   And just a simple step of using an additional phone number – and there are others.
[01:34:11.100 --> 01:34:14.380]   There are burner apps in the app store, et cetera.
[01:34:14.380 --> 01:34:19.140]   Pseudo is really beautiful because it integrates phone calls, texting, and email all in one
[01:34:19.140 --> 01:34:20.700]   place.
[01:34:20.700 --> 01:34:25.100]   But using something like an additional outside number and then taking just a simple set of
[01:34:25.100 --> 01:34:34.020]   – simple step of meeting in a third-party location, et cetera, for safety is more important
[01:34:34.020 --> 01:34:35.580]   than I ever thought it was.
[01:34:35.580 --> 01:34:39.180]   And especially when you start layering on – I mean I have the unique advantage of
[01:34:39.180 --> 01:34:43.540]   being six and a half feet tall and over 300 pounds.
[01:34:43.540 --> 01:34:47.260]   So I'm not the most necessarily attractive rape target.
[01:34:47.260 --> 01:34:52.940]   But for a young lady or for a young woman especially who faces danger there with giving
[01:34:52.940 --> 01:34:58.540]   out a phone number, it provides an additional very important layer of privacy and protection.
[01:34:58.540 --> 01:35:03.660]   So my daughter is too young at this point to thankfully need to be concerned about that.
[01:35:03.660 --> 01:35:08.340]   But I think that's very important for parents to be educated – kids probably already know.
[01:35:08.340 --> 01:35:12.540]   But parents to be educating and encouraging people to protect themselves.
[01:35:12.540 --> 01:35:13.540]   It's very important.
[01:35:13.540 --> 01:35:18.740]   And I'm sure most people won't do it this way, but I don't even know the actual phone
[01:35:18.740 --> 01:35:21.580]   number that's on my phone because all I use are pseudo numbers.
[01:35:21.580 --> 01:35:24.860]   I have one that's for friends and family, one that's for, like I said, finances, one
[01:35:24.860 --> 01:35:27.300]   that's for online purchases.
[01:35:27.300 --> 01:35:34.500]   And I've seen time and time and time again cell phone companies breached.
[01:35:34.500 --> 01:35:39.900]   And these can be small things like a social engineer calling in to get into my account.
[01:35:39.900 --> 01:35:45.180]   Or it can be big things like T-Mobile dumping millions of records.
[01:35:45.180 --> 01:35:47.740]   And I just don't want that information out there.
[01:35:47.740 --> 01:35:51.540]   And I guess what I would challenge most people to do is download the app and start moving
[01:35:51.540 --> 01:35:53.940]   some of your important stuff over to pseudo.
[01:35:53.940 --> 01:35:59.820]   And again, like Authy, there's also the option to set up a backup, a backup username and
[01:35:59.820 --> 01:36:00.820]   password.
[01:36:00.820 --> 01:36:05.860]   So if you do lose your phone, you can install pseudo on your new phone, log in with that
[01:36:05.860 --> 01:36:09.380]   username and password, and you don't lose all those phone numbers.
[01:36:09.380 --> 01:36:11.540]   That was the thing I was worried about when this initially came out.
[01:36:11.540 --> 01:36:17.940]   I didn't want to run the risk of setting up all my numbers on pseudo and then having a
[01:36:17.940 --> 01:36:22.140]   catastrophic failure and being, you know, all of a sudden not having access to any of
[01:36:22.140 --> 01:36:23.140]   my numbers.
[01:36:23.140 --> 01:36:27.140]   But so all of the stuff you should be making good backups of.
[01:36:27.140 --> 01:36:29.500]   And like most things, it's a skill set.
[01:36:29.500 --> 01:36:32.580]   Using these things, learning how they work, it's a skill set.
[01:36:32.580 --> 01:36:39.660]   But you know, as we kind of start to wrap up here, Justin, when it comes to privacy/security,
[01:36:39.660 --> 01:36:44.980]   which obviously they go together, it seems to me that we in some ways have a double-edged
[01:36:44.980 --> 01:36:49.180]   – the sword cuts both ways.
[01:36:49.180 --> 01:36:55.780]   In some ways, it's harder today than it's ever been to maintain privacy and security.
[01:36:55.780 --> 01:37:04.980]   I mean the Know Your Customer laws in the wake of the Patriot Act just destroyed so
[01:37:04.980 --> 01:37:11.620]   much ability to bank and to engage in any kind of private financial transactions.
[01:37:11.620 --> 01:37:14.100]   It turned the financial world upside down.
[01:37:14.100 --> 01:37:17.220]   The ability to travel privately was just turned upside down.
[01:37:17.220 --> 01:37:26.420]   I have real concerns about the things like the Real ID – what's the word for it?
[01:37:26.420 --> 01:37:27.420]   Yeah, initiatives.
[01:37:27.420 --> 01:37:30.900]   The Real ID initiatives all across the country.
[01:37:30.900 --> 01:37:38.220]   So in many ways, the noose has tightened in ways that would be inconceivable.
[01:37:38.220 --> 01:37:42.880]   Just the existence of a passport, the fact that you have to have a passport to go across
[01:37:42.880 --> 01:37:48.860]   and travel across land is in my mind utterly indefensible.
[01:37:48.860 --> 01:37:52.900]   Now that I don't know – I know of almost nobody who would believe that.
[01:37:52.900 --> 01:37:55.980]   In today's world, you have the majority of people who want to put up a massive wall
[01:37:55.980 --> 01:38:00.620]   across every border and say no and control the movement of each and every person.
[01:38:00.620 --> 01:38:02.940]   So philosophically, that's a huge philosophical thing.
[01:38:02.940 --> 01:38:05.460]   But for many years, you didn't need a passport.
[01:38:05.460 --> 01:38:06.460]   You didn't need papers.
[01:38:06.460 --> 01:38:15.400]   And so it's very easy to draw the conclusion that the classic line of "your papers please"
[01:38:15.400 --> 01:38:21.800]   is something that most of us here are so accustomed and trained to hear as normal that we don't
[01:38:21.800 --> 01:38:22.980]   even think about it.
[01:38:22.980 --> 01:38:24.680]   So the sword cuts against it.
[01:38:24.680 --> 01:38:27.560]   It's harder than it's ever been.
[01:38:27.560 --> 01:38:30.420]   On the flip side, we haven't talked about cryptocurrency.
[01:38:30.420 --> 01:38:31.420]   You mentioned Coinbase.
[01:38:31.420 --> 01:38:33.560]   Obviously, that's a cryptocurrency.
[01:38:33.560 --> 01:38:38.000]   We haven't talked about – I mean we're missing a dozen things that we could list
[01:38:38.000 --> 01:38:39.000]   off.
[01:38:39.000 --> 01:38:43.640]   But when you have all of these apps and you look at it in a different way, pseudo is a
[01:38:43.640 --> 01:38:44.680]   game changer.
[01:38:44.680 --> 01:38:49.000]   All of these things, encrypted messaging apps, all of these things are complete game changers.
[01:38:49.000 --> 01:38:53.960]   And so on the flip side, I look at it and say in many ways, it's easier than it's
[01:38:53.960 --> 01:39:03.100]   ever been to live privately, communicate privately, maintain a greater sense of security.
[01:39:03.100 --> 01:39:08.280]   So it seems like we live in this very challenging and strange world where the sword cuts both
[01:39:08.280 --> 01:39:09.280]   ways.
[01:39:09.280 --> 01:39:13.720]   It is an uphill battle.
[01:39:13.720 --> 01:39:18.320]   And we have all these tools that make it easier.
[01:39:18.320 --> 01:39:23.320]   Like you said, we're totally habituated to just give out the data when we're asked.
[01:39:23.320 --> 01:39:28.880]   And there's – I mean we could go into a huge philosophical thing about this.
[01:39:28.880 --> 01:39:35.680]   But we are very – that is the default mode and the default mentality and the default
[01:39:35.680 --> 01:39:40.160]   way we do business is just to give out what we're asked for.
[01:39:40.160 --> 01:39:45.720]   And living differently, living privately is a deliberate effort.
[01:39:45.720 --> 01:39:51.640]   It's not as simple as download – get a privacy.com account and a pseudo account and
[01:39:51.640 --> 01:39:53.320]   all of a sudden you're private.
[01:39:53.320 --> 01:39:54.720]   It is a very deliberate decision.
[01:39:54.720 --> 01:40:00.520]   It requires behavioral modifications which quite honestly I think are much more important
[01:40:00.520 --> 01:40:01.520]   than the technology.
[01:40:01.520 --> 01:40:02.520]   The technology helps.
[01:40:02.520 --> 01:40:04.160]   It supports that.
[01:40:04.160 --> 01:40:08.720]   But this does – you've several times said it's a skill set that you have to practice.
[01:40:08.720 --> 01:40:10.200]   And that's absolutely right.
[01:40:10.200 --> 01:40:12.360]   It is something that you have to do.
[01:40:12.360 --> 01:40:17.440]   And I'm constantly telling military students, implement this into your daily life.
[01:40:17.440 --> 01:40:23.000]   Don't wait until eight months from now when you're about to deploy to all of a sudden
[01:40:23.000 --> 01:40:27.320]   set all this up on the laptop and the phone that you're deploying with.
[01:40:27.320 --> 01:40:31.000]   Start living this from day to day and it's second nature when you get there.
[01:40:31.000 --> 01:40:36.680]   And kind of the same thing applies in the – just in the citizen, the private citizen
[01:40:36.680 --> 01:40:37.680]   space.
[01:40:37.680 --> 01:40:42.120]   This is a – to greater or lesser extent a bit of a lifestyle.
[01:40:42.120 --> 01:40:46.680]   And you can make it kind of the focal point of your lifestyle like Michael and I have.
[01:40:46.680 --> 01:40:49.640]   Or it can be one of the many things.
[01:40:49.640 --> 01:40:54.000]   Everyone is a multifaceted individual and it can take greater or lesser prominence in
[01:40:54.000 --> 01:40:55.000]   your life.
[01:40:55.000 --> 01:40:56.760]   But it does require that you think about it.
[01:40:56.760 --> 01:41:00.920]   It's not as simple as setting up an account, downloading an app and boom, you're private.
[01:41:00.920 --> 01:41:01.920]   Absolutely.
[01:41:01.920 --> 01:41:08.880]   And we could – Michael and I spend an hour every week talking about this.
[01:41:08.880 --> 01:41:12.920]   So I feel like there's a ton we're leaving out.
[01:41:12.920 --> 01:41:13.920]   Just looking here at my notes.
[01:41:13.920 --> 01:41:17.680]   We're at an hour and 40 minutes and I'm looking at my notes thinking about – we didn't cover
[01:41:17.680 --> 01:41:19.120]   – just even financially.
[01:41:19.120 --> 01:41:20.120]   We didn't cover cryptocurrencies.
[01:41:20.120 --> 01:41:24.000]   We didn't cover prepaid debit cards.
[01:41:24.000 --> 01:41:25.120]   We didn't cover money orders.
[01:41:25.120 --> 01:41:29.280]   We didn't cover almost all of these other tools that could be used.
[01:41:29.280 --> 01:41:38.200]   But I think we're at a point where it's a good wrap-up point.
[01:41:38.200 --> 01:41:40.600]   Just looking at my notes here.
[01:41:40.600 --> 01:41:44.400]   We also didn't cover data security.
[01:41:44.400 --> 01:41:45.400]   And you know what, Mike?
[01:41:45.400 --> 01:41:46.720]   I might actually like to have you back on.
[01:41:46.720 --> 01:41:52.800]   I'm very much looking forward to your volume two of the Complete Privacy and Security Desk
[01:41:52.800 --> 01:41:58.880]   Reference which, as I understand it, is going to be related to physical security because
[01:41:58.880 --> 01:42:04.640]   I've come to learn from reading your blog that you're a bit of a security nerd, especially
[01:42:04.640 --> 01:42:07.360]   with weird things like locks.
[01:42:07.360 --> 01:42:11.680]   So I'm excited because it seems like you're more excited about locks sometimes than you
[01:42:11.680 --> 01:42:14.480]   are about full disk encryption.
[01:42:14.480 --> 01:42:22.640]   Yeah, and a little bit that's a product of when my head is in encrypted apps and encrypting
[01:42:22.640 --> 01:42:25.800]   messengers and encryption protocols and all this all the time.
[01:42:25.800 --> 01:42:30.320]   It's nice to have some grounding in the physical world and do something a little different and
[01:42:30.320 --> 01:42:31.480]   kind of fun.
[01:42:31.480 --> 01:42:39.080]   And part of that comes from a significant portion of my background that I can't go into
[01:42:39.080 --> 01:42:40.080]   in too much detail.
[01:42:40.080 --> 01:42:43.840]   But I have a lot of familiarity with locks and how they're defeated.
[01:42:43.840 --> 01:42:51.000]   So it does get me excited to run across some super rare, obscure, high security lock in
[01:42:51.000 --> 01:42:55.320]   Seattle or New York or wherever.
[01:42:55.320 --> 01:43:00.100]   So maybe in the future, let's line it up with your Put Me on Your Book promotion tour when
[01:43:00.100 --> 01:43:02.220]   you launch volume two.
[01:43:02.220 --> 01:43:05.400]   Let's have you back to talk about physical security because I've learned all kinds of
[01:43:05.400 --> 01:43:06.720]   other interesting things.
[01:43:06.720 --> 01:43:14.840]   You've almost convinced me to start flying with a firearm based upon your blog post about
[01:43:14.840 --> 01:43:15.840]   that.
[01:43:15.840 --> 01:43:16.840]   That's an interesting context.
[01:43:16.840 --> 01:43:21.360]   Obviously, sometimes it adds more hassle, but you go ahead and just describe the outline
[01:43:21.360 --> 01:43:22.360]   of that.
[01:43:22.360 --> 01:43:25.040]   I thought that was such an interesting idea from a physical security perspective that
[01:43:25.040 --> 01:43:29.720]   you seem to many times choose to travel with a firearm so that you can maintain security
[01:43:29.720 --> 01:43:30.720]   over your baggage.
[01:43:30.720 --> 01:43:32.960]   Yeah, traveling with a firearm.
[01:43:32.960 --> 01:43:40.800]   If there's a firearm in your baggage and there's a little bit of nuance, maybe misunderstanding
[01:43:40.800 --> 01:43:45.920]   about this, but you can travel with a firearm in your checked luggage, provided that you
[01:43:45.920 --> 01:43:46.920]   meet a few criteria.
[01:43:46.920 --> 01:43:49.040]   It has to be in a hard case.
[01:43:49.040 --> 01:43:51.200]   It has to be unloaded.
[01:43:51.200 --> 01:43:55.960]   You may have to demonstrate that it's unloaded to the airline agent or the TSA agent or both
[01:43:55.960 --> 01:43:57.760]   sometimes.
[01:43:57.760 --> 01:44:00.240]   But what this does is it lets you lock your luggage up.
[01:44:00.240 --> 01:44:03.800]   So if you have a hard sided suitcase that will take a padlock, you can throw a padlock
[01:44:03.800 --> 01:44:04.800]   on there.
[01:44:04.800 --> 01:44:08.780]   And per the letter of law, it cannot be a TSA approved padlock.
[01:44:08.780 --> 01:44:12.440]   So you can use a very good, very high quality lock.
[01:44:12.440 --> 01:44:17.180]   And I do this because I frequently travel with things like 12 iPhones.
[01:44:17.180 --> 01:44:22.680]   If I'm going to a class where the students have specifically asked and purchased iPhones
[01:44:22.680 --> 01:44:27.800]   and want instruction on those phones, I don't want the opportunity for a TSA agent to open
[01:44:27.800 --> 01:44:30.200]   my bag up, say, "Hey, there's a ton of iPhones in here.
[01:44:30.200 --> 01:44:35.320]   He's probably not going to miss one," and throw one in their lunchbox.
[01:44:35.320 --> 01:44:40.040]   So if you don't own firearms or you're uncomfortable with firearms, but you're still interested
[01:44:40.040 --> 01:44:45.040]   in this, you can travel with a couple of other items that will let you lock your suitcase
[01:44:45.040 --> 01:44:49.440]   because they're legally considered firearms, like flare guns, which you can purchase very
[01:44:49.440 --> 01:44:55.240]   inexpensively or blank firing starter pistols, which will not fire real ammunition, but they're
[01:44:55.240 --> 01:45:00.720]   still treated as firearms by the airlines and by the Transportation Security Administration.
[01:45:00.720 --> 01:45:07.720]   So I'm excited that at least one person has actually read those blog posts.
[01:45:07.720 --> 01:45:13.400]   Yeah, I love those little ideas because, again, back to the way, okay, you can travel with
[01:45:13.400 --> 01:45:17.280]   a flare gun and you check the local restriction.
[01:45:17.280 --> 01:45:22.400]   Perhaps you might not want to carry a .357 in the local area based upon local firearms
[01:45:22.400 --> 01:45:25.200]   laws, but you can do something.
[01:45:25.200 --> 01:45:29.360]   And just the ability to know how to secure your luggage when traveling brings back a
[01:45:29.360 --> 01:45:31.720]   little bit more control to somebody.
[01:45:31.720 --> 01:45:36.800]   Now, most of the time I don't travel with 12 iPhones, and my philosophy is there are
[01:45:36.800 --> 01:45:38.960]   two kinds of luggage.
[01:45:38.960 --> 01:45:45.120]   There's carry-on and lost, but there's a place where you need to check a bag, and so it's
[01:45:45.120 --> 01:45:46.120]   really useful.
[01:45:46.120 --> 01:45:51.320]   So I'd love to have you back on when you publish volume two of the Security and Desk Reference.
[01:45:51.320 --> 01:45:55.400]   I'll give my two just wrap-up points, and Justin, I'll give you the last word.
[01:45:55.400 --> 01:46:00.400]   And also make sure you go down the listings of your sites, your podcasts, and all of your
[01:46:00.400 --> 01:46:01.920]   materials to promote.
[01:46:01.920 --> 01:46:06.720]   And I'll give a wholehearted, unqualified endorsement of the power of your book, The
[01:46:06.720 --> 01:46:08.400]   Complete Privacy and Security Desk Reference.
[01:46:08.400 --> 01:46:12.120]   I think it's about $40, but a $40 book, well spent.
[01:46:12.120 --> 01:46:14.560]   I was so impressed with it.
[01:46:14.560 --> 01:46:20.120]   But philosophically, we've covered a lot of things, and my closing commentary would be
[01:46:20.120 --> 01:46:24.880]   it's important to start building the skill set and thinking about it.
[01:46:24.880 --> 01:46:28.560]   And there are two very important reasons why.
[01:46:28.560 --> 01:46:35.120]   Number one, you don't know in advance what circumstance you might face in the future
[01:46:35.120 --> 01:46:36.880]   due to no fault of your own.
[01:46:36.880 --> 01:46:39.840]   Recently on Radical Personal Finance, I've released various episodes on law enforcement,
[01:46:39.840 --> 01:46:44.140]   how to interact with law enforcement agents, and how to protect yourself.
[01:46:44.140 --> 01:46:49.400]   Every day I see news stories, and every single day the control and the ability of all the
[01:46:49.400 --> 01:46:54.360]   financial information becomes much, much more significant.
[01:46:54.360 --> 01:46:57.160]   And you can't protect it after the fact.
[01:46:57.160 --> 01:47:04.680]   Just last week, there was a horrifying story about a student who was arraigned, indicted
[01:47:04.680 --> 01:47:11.060]   for murder or for manslaughter at the very least in association with just awful fraternity
[01:47:11.060 --> 01:47:12.400]   hazing incident.
[01:47:12.400 --> 01:47:16.180]   And I was interested to read as part of the court proceedings that part of the evidence
[01:47:16.180 --> 01:47:21.680]   that the grand jury considered in bringing the charges against him was the fact that
[01:47:21.680 --> 01:47:28.480]   he had, number one, had there been communication between him and some of the other people,
[01:47:28.480 --> 01:47:35.040]   some of the other fraternity members involved about the situation, and number two, that
[01:47:35.040 --> 01:47:39.440]   he had his Google searches, Google searches on what to do with alcohol poisoning.
[01:47:39.440 --> 01:47:43.240]   Well, those material pieces of evidence were brought against him in terms of the bringing
[01:47:43.240 --> 01:47:44.240]   of the charges.
[01:47:44.240 --> 01:47:48.640]   Now, what they did was horrible, and all of us want to live in a well-ordered society
[01:47:48.640 --> 01:47:51.880]   in which people are held accountable for their crimes.
[01:47:51.880 --> 01:47:55.560]   But which leads me to the second point, you can't always know in advance what's actually
[01:47:55.560 --> 01:47:58.900]   going to be a crime, and laws change.
[01:47:58.900 --> 01:48:02.520]   Number one, there are plenty of laws out there, and there are plenty of agents who are trying
[01:48:02.520 --> 01:48:07.080]   – I use the term agents to mean just people, not government agents, but there are people
[01:48:07.080 --> 01:48:08.680]   who are seeking to target you.
[01:48:08.680 --> 01:48:12.760]   And you can't know in advance what the laws are going to be 20 years from now.
[01:48:12.760 --> 01:48:15.760]   But what you do today is going to have an aspect on it.
[01:48:15.760 --> 01:48:20.200]   So whether it's the most simple, common advice as what you put on Facebook is going to be
[01:48:20.200 --> 01:48:24.360]   seen by a future potential employer, or it's the fact that every single one of your Google
[01:48:24.360 --> 01:48:29.160]   searches is going to be saved and can be brought against you in a grand jury investigation,
[01:48:29.160 --> 01:48:33.080]   you've got to take steps in advance before you ever need it, because if you ever need
[01:48:33.080 --> 01:48:34.360]   it, it's too late.
[01:48:34.360 --> 01:48:39.320]   So Justin, finish us up with closing thoughts and walk through your resources, please.
[01:48:39.320 --> 01:48:40.360]   Absolutely.
[01:48:40.360 --> 01:48:48.640]   There are 27,000 pages of federal laws and an estimated another 100,000 pages of federal
[01:48:48.640 --> 01:48:50.720]   civil statutes.
[01:48:50.720 --> 01:48:53.820]   And a lot of times we're breaking a law and don't even know it.
[01:48:53.820 --> 01:48:57.040]   And a lot of these laws are enforced with a great deal of discretion.
[01:48:57.040 --> 01:49:01.880]   So like you said, a lot of people are like, "Oh, I'm never going to be in that situation."
[01:49:01.880 --> 01:49:04.280]   But the fact is, you don't know.
[01:49:04.280 --> 01:49:09.200]   And when you find yourself in that situation, if you find yourself in that situation, it's
[01:49:09.200 --> 01:49:11.040]   too late to go back and do this legwork.
[01:49:11.040 --> 01:49:12.840]   You have to do it now.
[01:49:12.840 --> 01:49:16.040]   Excuse me, you have to do it now.
[01:49:16.040 --> 01:49:20.200]   So you can find out more about me on yourultimatesecurity.guide.
[01:49:20.200 --> 01:49:22.240]   My blog is contained there.
[01:49:22.240 --> 01:49:27.740]   The book is The Complete Privacy and Security Desk Reference, Volume 1, Digital.
[01:49:27.740 --> 01:49:30.180]   That's by me and Michael Basile.
[01:49:30.180 --> 01:49:35.760]   If you want to check out Michael's site, it is privacy-training.com.
[01:49:35.760 --> 01:49:40.520]   And of course, you can download our podcast, The Complete Privacy and Security Podcast,
[01:49:40.520 --> 01:49:42.840]   wherever you get your podcasts.
[01:49:42.840 --> 01:49:47.720]   Josh, Joshua, thank you so much for being so generous with your time.
[01:49:47.720 --> 01:49:49.080]   This was truly a pleasure.
[01:49:49.080 --> 01:49:54.040]   And I will definitely look forward to being back on once Volume 2 is out.
[01:49:54.040 --> 01:49:55.040]   Absolutely.
[01:49:55.040 --> 01:49:56.040]   Thanks for coming on.
[01:49:56.040 --> 01:49:57.040]   Yes.
[01:49:57.040 --> 01:49:58.080]   Thank you.
[01:49:58.080 --> 01:50:03.720]   This show is part of the Radical Life Media Network of podcasts and resources.
[01:50:03.720 --> 01:50:08.280]   Find out more at radicallifemedia.com.
[01:50:08.280 --> 01:50:12.840]   Sweet Hop is an online marketplace curating the best in premium seating at stadiums, arenas,
[01:50:12.840 --> 01:50:14.400]   and amphitheaters nationwide.
[01:50:14.400 --> 01:50:19.480]   With Sweet Hop's 100% ticket guarantee, no hidden fees, and the personal high-level service
[01:50:19.480 --> 01:50:24.360]   you expect with a premium purchase, you can relax knowing you'll receive the luxury experience
[01:50:24.360 --> 01:50:25.360]   you deserve.
[01:50:25.360 --> 01:50:30.240]   Visit sweethop.com today to book your premium tickets to your favorite teams, artists, and
[01:50:30.240 --> 01:50:34.400]   all the must-see live events to Sweet Hop Around LA.
[01:50:34.400 --> 01:50:37.720]   It's more than just a ticket.

