
[00:00:00.000 --> 00:00:06.080]   >> All right, everyone. Thanks for waiting. I think we'll figure out AGI before we figure
[00:00:06.080 --> 00:00:11.620]   out AV, but that's just one of my predictions. I want to talk to you today about natural
[00:00:11.620 --> 00:00:16.720]   language processing and the future of AI. And sometimes it's helpful to look a little
[00:00:16.720 --> 00:00:22.560]   bit into the past to see what lessons we can learn to predict the future a little bit better.
[00:00:22.560 --> 00:00:31.600]   And one of those times was actually exactly about half a decade ago, in June 2018, when
[00:00:31.600 --> 00:00:38.200]   my collaborators, Brian McCann, Nitish, Tsai Ming and I published this paper on the natural
[00:00:38.200 --> 00:00:44.680]   language processing decathlon. And that paper essentially introduced the idea of prompt
[00:00:44.680 --> 00:00:50.200]   engineering and the idea that maybe we can have not just pre-trained word vectors, not
[00:00:50.200 --> 00:00:58.640]   just pre-trained encoders, but also pre-trained entire models, including a decoder. And we
[00:00:58.640 --> 00:01:05.120]   were super excited at the time. Basically here, one of the central ideas of the paper
[00:01:05.120 --> 00:01:10.880]   was that we cast all tasks essentially as a question answering problem over some kind
[00:01:10.880 --> 00:01:17.720]   of context. And we basically thought about the hardest NLP tasks out there, things like
[00:01:17.720 --> 00:01:22.080]   question answering over a standard context, what is sort of the official academic in the
[00:01:22.080 --> 00:01:26.440]   past way of looking at question answering, but also asking questions like, what is the
[00:01:26.440 --> 00:01:31.720]   translation from English to German of this particular context, a sentence, or what is
[00:01:31.720 --> 00:01:37.520]   the summary of this paragraph, or are these entailed, or is the sentence positive or negative,
[00:01:37.520 --> 00:01:42.380]   sentiment analysis, and all these different tasks. And it took us actually almost half
[00:01:42.380 --> 00:01:48.120]   a year, and especially Brian McCann, the first author, to just phrase all of these problems
[00:01:48.120 --> 00:01:53.760]   and pre-process the data in a way that will actually work in a single model. And this
[00:01:53.760 --> 00:01:58.200]   was the single model. If you're familiar with transformer architectures that had come out
[00:01:58.200 --> 00:02:04.040]   just a year prior, you'll see a lot of similar ideas of these models, tons of co-attention.
[00:02:04.040 --> 00:02:08.560]   We made one big mistake, which is we still had a recurrent neural network at the very
[00:02:08.560 --> 00:02:14.040]   beginning, but then had a lot of self-attention, co-attention mechanisms between a question
[00:02:14.040 --> 00:02:19.440]   and the context. And we were super excited because after another six months of tuning,
[00:02:19.440 --> 00:02:25.960]   and we wish we had weights and biases already then, so it would be a lot easier to do now,
[00:02:25.960 --> 00:02:30.800]   but after a lot of tuning of all these different models, or sorry, of the single model across
[00:02:30.800 --> 00:02:34.980]   all these different tasks, we basically got it to work. And in some cases, it worked better
[00:02:34.980 --> 00:02:39.320]   than anything else, but we also learned that, wow, translation, for instance, made everything
[00:02:39.320 --> 00:02:44.840]   harder. Like trying to squeeze translation as a task into this single model that is everything
[00:02:44.840 --> 00:02:50.320]   else mostly in English, which is where unfortunately most of the NLP datasets have been, was very,
[00:02:50.320 --> 00:02:56.060]   very challenging, but overall it worked. So we were super excited. We submit this paper
[00:02:56.060 --> 00:03:04.300]   and we get back the reviews and well, it was not a great day. It was at the time very sad
[00:03:04.300 --> 00:03:10.080]   because basically the reviewers wrote things like, this makes me doubt if this multitask
[00:03:10.080 --> 00:03:15.520]   learning is useful. If our goal is to optimize the performance of a single task, this general
[00:03:15.520 --> 00:03:20.800]   model sacrifices this important prior knowledge of an individual task, which was true. We
[00:03:20.800 --> 00:03:25.000]   wanted to build a single model for all of NLP and not say, oh, well, in this particular
[00:03:25.000 --> 00:03:30.480]   task we can use the fact that it's like a continuous span answer or something like that.
[00:03:30.480 --> 00:03:36.140]   The reviewer wrote, I think the framing of DECA NLP does more harm than good. It perpetuates
[00:03:36.140 --> 00:03:41.400]   this misguided view of question answering, namely that it is a unified phenomenon, that
[00:03:41.400 --> 00:03:46.260]   it could be a unified phenomenon. There's no such thing as general question answering,
[00:03:46.260 --> 00:03:50.660]   not even for humans, to which I always asked. There is one brain. We're using mostly that
[00:03:50.660 --> 00:03:55.100]   one brain to answer all the different questions, but that was not the state that it field was
[00:03:55.100 --> 00:04:00.520]   in. It's kind of hilarious to read all of these and hearing and seeing all of these
[00:04:00.520 --> 00:04:04.680]   questions require very different systems to answer and trying to pretend that they are
[00:04:04.680 --> 00:04:12.680]   the same doesn't help anyone solve any problems. Obviously, with chat GPT, prompt engineering,
[00:04:12.680 --> 00:04:17.120]   large language models, we know that this has been fairly wrong, but overall after getting
[00:04:17.120 --> 00:04:23.820]   all these reviews in, the area chair was absolutely certain to reject this paper.
[00:04:23.820 --> 00:04:28.960]   Why do I bring this up? Sometimes when you're trying to work and predict the future, the
[00:04:28.960 --> 00:04:33.520]   best way is to actually make it happen yourself. That way you know someone is going to work
[00:04:33.520 --> 00:04:38.720]   on this prediction that you think will happen and you have to stick to your guns, even if
[00:04:38.720 --> 00:04:44.240]   it's not obvious. Unfortunately, I wish it was as easy to say, do something that is controversial,
[00:04:44.240 --> 00:04:48.600]   but you can also be controversial and wrong. You need to be controversial and right, but
[00:04:48.600 --> 00:04:53.800]   it is something that I felt was very important to not just do what everyone else is doing
[00:04:53.800 --> 00:04:58.600]   which is right now like fine tune LM. That's still super interesting and there are lots
[00:04:58.600 --> 00:05:02.880]   of things we can do to make it even faster and use less RAM and whatnot, but I think
[00:05:02.880 --> 00:05:07.600]   there are a couple of ideas in the space that are much less explored and I'll mention some
[00:05:07.600 --> 00:05:15.360]   of those at the end. Now, I had a bit of a deja vu moment to this when we launched in
[00:05:15.360 --> 00:05:22.680]   the summer of 2020, U.com, or we founded the company and had a lot of VCs, not reviewers,
[00:05:22.680 --> 00:05:28.040]   but VCs tell me why would you work on search? That is such a misguided idea. No one will
[00:05:28.040 --> 00:05:34.560]   ever beat Google. They have all the AI, they have all the people, they have all the data,
[00:05:34.560 --> 00:05:39.720]   all the distribution channels. There's nothing you can do. And you know, then we said, you
[00:05:39.720 --> 00:05:46.320]   know, internally, well, clearly NLP has gotten so much better, yet the biggest application
[00:05:46.320 --> 00:05:52.720]   of NLP, which is search, hasn't really changed that much. When you look today and you ask
[00:05:52.720 --> 00:05:58.520]   some Python Fibonacci data computation like query, you ask Google, this is your answer.
[00:05:58.520 --> 00:06:03.720]   And this has basically been your answer for the last 15 years, despite seeing how NLP
[00:06:03.720 --> 00:06:08.600]   has gotten better and better over these last 15 years. And you can scroll down and maybe
[00:06:08.600 --> 00:06:13.280]   you'll see people also ask or others want to know now. And you know, this is in some
[00:06:13.280 --> 00:06:18.880]   ways it's a little bit of an inkling here of having a chat, right? You just can't yourself
[00:06:18.880 --> 00:06:23.160]   chat. You just have to choose some predefined chats. But sadly, none of those will either
[00:06:23.160 --> 00:06:29.200]   give you the answer. And so we thought clearly you could do better. And this is what we came
[00:06:29.200 --> 00:06:36.160]   up with. Basically, you have this chat interface that will just give you the right answer and
[00:06:36.160 --> 00:06:41.480]   will have a little copy and paste button right there so you can be done with it. And if you
[00:06:41.480 --> 00:06:46.840]   still really want to see links, you have them on the right. You can minimize those two and
[00:06:46.840 --> 00:06:51.920]   make them disappear right here. You'll have different answers. And one thing we thought
[00:06:51.920 --> 00:06:57.540]   was very important is you also have citations and you have references and apps within this
[00:06:57.540 --> 00:07:02.200]   chat window. As much as I love text and have worked on natural language processing for
[00:07:02.200 --> 00:07:06.960]   over a decade, text isn't always the right way to answer a question. Sometimes you want
[00:07:06.960 --> 00:07:12.120]   to see an image. No one is ever going to shop for dresses or even an air purifier by just
[00:07:12.120 --> 00:07:16.720]   text. You usually want to see what it looks like. And you want to also have references
[00:07:16.720 --> 00:07:21.840]   and verify if the information is correct, which we basically do with both citations
[00:07:21.840 --> 00:07:29.520]   on the web as well as these apps. And so we actually did a study where we compared and
[00:07:29.520 --> 00:07:35.600]   asked for an independent organization called Surge to do the study and see if you can actually
[00:07:35.600 --> 00:07:42.000]   be more efficient as a developer using U.com versus Google. And the answer is indeed 72%
[00:07:42.000 --> 00:07:48.760]   of the cases, U.com was better or the same as Google. And not only that, but on average
[00:07:48.760 --> 00:07:55.040]   you save half of your time when you're trying to find answers and debugging questions and
[00:07:55.040 --> 00:08:00.840]   code snippets and ways to do things. And so we're very excited to actually be able to
[00:08:00.840 --> 00:08:06.480]   make the lives of developers more efficient with the search engine and have now data to
[00:08:06.480 --> 00:08:12.320]   back up that it was indeed possible, even though 2020 people thought there's zero chance
[00:08:12.320 --> 00:08:19.080]   to do anything better than Google. Now, it's not just about coding questions. It's also
[00:08:19.080 --> 00:08:24.400]   about general NLP questions. And if you have worked in NLP, you'll see a couple of different
[00:08:24.400 --> 00:08:28.480]   tasks that were solved here that were actually quite surprising. So I can ask a question
[00:08:28.480 --> 00:08:32.120]   like what does CIM stand for? And it talks about customer relationship management systems
[00:08:32.120 --> 00:08:36.800]   and whatnot. And I can ask what's the biggest such company. Now you have such companies,
[00:08:36.800 --> 00:08:41.960]   some reference to a prior conversation. And then you ask what's their stock price. And
[00:08:41.960 --> 00:08:49.560]   when we launched this in the winter of 2022, last year, we basically immediately saw the
[00:08:49.560 --> 00:08:55.640]   problem of hallucinations. And most standard large language models, if you ask what's the
[00:08:55.640 --> 00:08:59.480]   stock price of this company, will come up with some numbers that seem like the next
[00:08:59.480 --> 00:09:05.720]   reasonable prediction sequence of byte pair encodings. But they will not actually tell
[00:09:05.720 --> 00:09:10.360]   you the right stock price, which could be pretty problematic. And so instead, again,
[00:09:10.360 --> 00:09:15.760]   we lean on this open platform where everyone can contribute and we have these multimodal
[00:09:15.760 --> 00:09:21.040]   apps. And so the LLM can actually decide instead of answering this question with text, I will
[00:09:21.040 --> 00:09:26.440]   answer it with this visualization and this GUI. And there you can click and say, okay,
[00:09:26.440 --> 00:09:30.120]   I want to see the week and you see the actual ground truth. And the same is true for weather
[00:09:30.120 --> 00:09:35.760]   and a bunch of other issues. And then again, magically you can ask who's the CEO and it
[00:09:35.760 --> 00:09:41.080]   will have kept the reference, still know we're talking about Salesforce as a company, and
[00:09:41.080 --> 00:09:46.600]   then give you that answer. And if you think just 10 years back, there were entire PhD
[00:09:46.600 --> 00:09:51.080]   thesis written about things like coreference resolution, which is basically understand
[00:09:51.080 --> 00:09:56.520]   their or its, who does it refer to? What does it refer to? All of this is now irrelevant
[00:09:56.520 --> 00:10:03.960]   thanks to LLMs. It's pretty incredible. Now, there's more that you can do than just text.
[00:10:03.960 --> 00:10:10.160]   Again, you might ask, how can I generate an image with AI? And the answer is, yeah, I
[00:10:10.160 --> 00:10:15.440]   guess that's possible. But also here, you can just do it right there in the search engine.
[00:10:15.440 --> 00:10:19.640]   So when you think about building an app, you can build an app on the iPhone, on the app,
[00:10:19.640 --> 00:10:25.520]   on the web, on the open web, or inside you.com. And then you'll have baked in traffic when
[00:10:25.520 --> 00:10:29.680]   that app is relevant. In this case, you have, you imagine it's one of the apps we have to
[00:10:29.680 --> 00:10:34.600]   build to get the platform going, but it will just basically let you do what you set out
[00:10:34.600 --> 00:10:38.200]   to do when you ask that question. It's kind of thinking about the jobs to be done framework,
[00:10:38.200 --> 00:10:43.240]   which is I think a really great framework for finding good startup ideas. This one was
[00:10:43.240 --> 00:10:47.920]   one of my favorites, kind of the skydiving baby. I tried a couple of different ones and
[00:10:47.920 --> 00:10:51.560]   ultimately I felt like this was the most reasonable one because, you know, let's face it, they
[00:10:51.560 --> 00:10:57.720]   can't pull the parachute themselves, so it's much safer to do a tandem jump. I think in
[00:10:57.720 --> 00:11:04.000]   general you're going to see and think about a lot of different generative AI capabilities
[00:11:04.000 --> 00:11:08.920]   in the next couple of months and years if you're in this space. And one mental framework
[00:11:08.920 --> 00:11:15.000]   I came up with a few weeks ago is essentially to think about when it would take a long time
[00:11:15.000 --> 00:11:21.680]   to create some kind of human work artifact, but it would be very quick to verify that
[00:11:21.680 --> 00:11:27.640]   it's correct or useful. And one example is a clear one is code. You can just ask the
[00:11:27.640 --> 00:11:34.440]   AI to write some code for you and then you can quickly run it if it compiles, if it executes
[00:11:34.440 --> 00:11:40.360]   and does it in a reasonable amount of time, you know that it's good. Likewise with images,
[00:11:40.360 --> 00:11:44.720]   it's another really good example because it would take you forever to create that image,
[00:11:44.720 --> 00:11:48.440]   but you look at it in a few seconds and you know if it looks good or not. I think there
[00:11:48.440 --> 00:11:53.880]   are a lot of other artifacts that we can create with generative AI and I think a framework
[00:11:53.880 --> 00:11:58.040]   that might be helpful for choosing what kind of startups or problems you want to work on
[00:11:58.040 --> 00:12:06.640]   in gen AI. I think overall chat and NLP and search are all merging into more and more
[00:12:06.640 --> 00:12:12.480]   a single model for all of it. And one might think, oh, still Google, it's impossible to
[00:12:12.480 --> 00:12:18.680]   beat so hard, so big, but I would argue that chat is actually even bigger than just search
[00:12:18.680 --> 00:12:24.840]   itself. You can do much longer follow-up questions. You can ask for summaries of different websites
[00:12:24.840 --> 00:12:30.360]   and ultimately and maybe not too far into the future, you'll have it actually execute
[00:12:30.360 --> 00:12:35.560]   actions for you and basically become your personal assistant, maybe even your digital
[00:12:35.560 --> 00:12:41.120]   twin. Because ultimately there are things like this that give you an example of something
[00:12:41.120 --> 00:12:45.880]   you would have never asked a traditional search engine, but you can ask a chat first search
[00:12:45.880 --> 00:12:51.320]   engine and here the query is write me a website with JavaScript code and a commenting function.
[00:12:51.320 --> 00:12:54.400]   You know, you wouldn't ask that to Google because you know Google would just again give
[00:12:54.400 --> 00:13:01.960]   you back a list of blue links. So with that, I want to just do one more example of an LM
[00:13:01.960 --> 00:13:09.680]   that we were motivated by when GPD 3 came out two years or three years ago. Almost longer
[00:13:09.680 --> 00:13:14.920]   than that, Nick, four years ago now. I need to update my accounts. And basically one of
[00:13:14.920 --> 00:13:20.360]   our motivations was large sequence models are super powerful, but it's going to be hard
[00:13:20.360 --> 00:13:25.960]   to build an even larger model than OpenAI had at the time. And so we thought where else
[00:13:25.960 --> 00:13:32.080]   could this technology be useful? And our answer was in another type of sequence. And if you
[00:13:32.080 --> 00:13:36.920]   will, another type of very natural human or biological language, and that is the language
[00:13:36.920 --> 00:13:43.880]   of proteins. And it turns out that over the last decade, we've had more and more protein
[00:13:43.880 --> 00:13:48.320]   sequence data sequences of amino acids. And for the non-biology people here, proteins
[00:13:48.320 --> 00:13:53.340]   essentially govern everything in your body. They're like the source code of biology, everything
[00:13:53.340 --> 00:13:59.960]   in health, sickness and diseases. They're all governed. You know, COVID is a protein.
[00:13:59.960 --> 00:14:05.360]   Everything is a protein in the side of your human body. And so basically if you can understand
[00:14:05.360 --> 00:14:11.960]   that language and then actually generate proteins, you could, I think ultimately change all of
[00:14:11.960 --> 00:14:17.680]   medicine. And I think this technology and, you know, actually power combining it with
[00:14:17.680 --> 00:14:23.960]   wet lab experiments will enable us to eventually in the next 10, at most 30 years, have as
[00:14:23.960 --> 00:14:28.880]   good of a grasp on viruses as we now have on bacteria. And that will change a lot of
[00:14:28.880 --> 00:14:33.960]   people's health situation. What was interesting here is that we first published this paper
[00:14:33.960 --> 00:14:39.960]   and as a lot of good papers also first got rejected from a bunch of science journals
[00:14:39.960 --> 00:14:45.040]   and whatnot. But then we actually went ahead, we continued, we're kind of stubborn that
[00:14:45.040 --> 00:14:50.960]   way. And we actually generated and synthesized those proteins in real wet labs. And that
[00:14:50.960 --> 00:14:56.160]   is surprisingly hard. It took like 12 months to just say, here's this sequence, like make
[00:14:56.160 --> 00:15:02.240]   it happen and then tell us how well it works. But it turned out that the AI had actually
[00:15:02.240 --> 00:15:06.640]   understood the structure of these proteins. And if you're familiar with transformers,
[00:15:06.640 --> 00:15:12.160]   they have these attention mechanisms and basically like weighted attention on different past
[00:15:12.160 --> 00:15:17.760]   inputs. And the fascinating thing was that these models actually had implicitly recovered
[00:15:17.760 --> 00:15:21.440]   that folding structure and that they paid more attention to things that are closed in
[00:15:21.440 --> 00:15:27.760]   3D space, even if they're far away in the sequence space. And ultimately the synthesized
[00:15:27.760 --> 00:15:33.280]   proteins worked. They actually folded correctly. They had very antibacterial properties as
[00:15:33.280 --> 00:15:38.000]   a particular lysozyme protein that we generated. And now there are multiple different companies
[00:15:38.000 --> 00:15:43.320]   that have started based on this idea. One is called Profluent from Ali Madani, the first
[00:15:43.320 --> 00:15:50.600]   author of this paper too. So that I want to encourage you all to try idea.com and I guess
[00:15:50.600 --> 00:15:52.960]   we don't have time for questions. So thanks. I'll be around.
[00:15:53.640 --> 00:15:54.140]   Bye.
[00:15:54.820 --> 00:15:55.320]   Bye.
[00:15:56.000 --> 00:15:56.500]   Bye.
[00:15:57.180 --> 00:15:57.680]   Bye.
[00:15:58.360 --> 00:15:58.860]   Bye.
[00:15:59.540 --> 00:16:00.040]   Bye.
[00:16:00.040 --> 00:16:10.040]   [BLANK_AUDIO]

