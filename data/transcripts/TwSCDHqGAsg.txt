
[00:00:00.000 --> 00:00:05.560]   Let me talk about, if we could, about AI a little bit.
[00:00:05.560 --> 00:00:15.340]   So we've, Bridgewater Associates, manage about $160 billion in assets.
[00:00:15.340 --> 00:00:21.120]   And our artificial intelligence systems algorithms are pretty good with data.
[00:00:21.120 --> 00:00:28.120]   What role in the future do you see AI play in analysis and decision making in this kind
[00:00:28.120 --> 00:00:34.680]   of data rich and impactful area of investment?
[00:00:34.680 --> 00:00:41.960]   I'm going to answer that not only in investment, but I give a more all-encompassing rule for
[00:00:41.960 --> 00:00:44.100]   AI.
[00:00:44.100 --> 00:00:51.720]   As I think you know, for the last 25 years, we have taken our thinking and put them in
[00:00:51.720 --> 00:00:53.040]   algorithms.
[00:00:53.040 --> 00:01:00.920]   And so we make decisions, the computer takes those criteria, algorithms, and they put them,
[00:01:00.920 --> 00:01:06.800]   they're in there and it takes data and they operate as an independent decision maker in
[00:01:06.800 --> 00:01:09.000]   parallel with our decision making.
[00:01:09.000 --> 00:01:15.720]   So for me, it's like there's a chess game playing and I'm a person with my chess game
[00:01:15.720 --> 00:01:20.080]   and I'm saying it made that move and I'm making the move and how do I compare those two moves?
[00:01:20.080 --> 00:01:21.240]   So we've done a lot.
[00:01:21.240 --> 00:01:23.440]   But let me give you a rule.
[00:01:23.440 --> 00:01:34.280]   If the future can be different from the past and you don't have deep understanding, you
[00:01:34.280 --> 00:01:39.520]   should not rely on AI.
[00:01:39.520 --> 00:01:40.680]   Those two things.
[00:01:40.680 --> 00:01:42.480]   Deep understanding of?
[00:01:42.480 --> 00:01:48.840]   The cause effect relationships that are leading you to place that bet in anything.
[00:01:48.840 --> 00:01:50.360]   Anything important.
[00:01:50.360 --> 00:01:54.720]   Let's say if it was do surgeries and you would say, how do I do surgeries?
[00:01:54.720 --> 00:01:58.920]   I think it's totally fine to watch all the doctors do the surgeries.
[00:01:58.920 --> 00:02:09.080]   You can put it on, take a digital camera and do that, convert that into AI algorithms that
[00:02:09.080 --> 00:02:14.560]   go to robots and have them do surgeries and I'd be comfortable with that.
[00:02:14.560 --> 00:02:19.960]   Because if it keeps doing the same thing over and over again and you have enough of that,
[00:02:19.960 --> 00:02:25.320]   that would be fine even though you may not understand the algorithms because if the thing's
[00:02:25.320 --> 00:02:29.400]   happening over and over again and you're not asking, the future would be the same.
[00:02:29.400 --> 00:02:35.440]   That appendicitis or whatever it is will be handled the same way the surgery, that's fine.
[00:02:35.440 --> 00:02:45.160]   However, what happens with AI is for the most part, is it takes a lot of data with a high
[00:02:45.160 --> 00:02:51.000]   enough sample size and then it puts together its own algorithms.
[00:02:51.000 --> 00:02:53.620]   There are two ways you can come up with algorithms.
[00:02:53.620 --> 00:03:00.000]   You can either take your thinking and express them in algorithms or you can say, put the
[00:03:00.000 --> 00:03:03.840]   data in and say, what is the algorithm?
[00:03:03.840 --> 00:03:05.480]   That's machine learning.
[00:03:05.480 --> 00:03:12.480]   When you have machine learning, it'll give you equations which quite often are not understandable.
[00:03:12.480 --> 00:03:16.720]   If you would try to say, okay, now describe what it's telling you, it's very difficult
[00:03:16.720 --> 00:03:20.760]   to describe and so they can escape understanding.
[00:03:20.760 --> 00:03:25.440]   It's very good for doing those things that could be done over and over again if you're
[00:03:25.440 --> 00:03:27.360]   watching and you're not taking that.
[00:03:27.360 --> 00:03:33.560]   But if the future is different from the past and you have that, then if the future is different
[00:03:33.560 --> 00:03:38.960]   from the past and you don't have deep understanding, you're going to get in trouble.
[00:03:38.960 --> 00:03:40.560]   That's the main thing.
[00:03:40.560 --> 00:03:47.000]   As far as AI is concerned, AI and let's say computer replications of thinking in various
[00:03:47.000 --> 00:03:51.340]   ways, I think it's particularly good for processing.
[00:03:51.340 --> 00:04:00.680]   But the notion of what you want to do is better most of the time determined by the human mind.
[00:04:00.680 --> 00:04:01.680]   What are the principles?
[00:04:01.680 --> 00:04:05.040]   Like, okay, how should I raise my children?
[00:04:05.040 --> 00:04:09.840]   It's going to be a long time before AI, you're going to say it has a good enough judgment
[00:04:09.840 --> 00:04:10.840]   to do that.
[00:04:10.840 --> 00:04:12.120]   Who should I marry?
[00:04:12.120 --> 00:04:13.160]   All of those things.
[00:04:13.160 --> 00:04:17.480]   Maybe you can get the computer to help you, but if you just took data and do machine learning,
[00:04:17.480 --> 00:04:18.760]   it's not going to find it.
[00:04:18.760 --> 00:04:25.800]   If you were to then take what are my criteria for any of those questions and then say, put
[00:04:25.800 --> 00:04:30.600]   them into an algorithm and you'd be a lot better off than if you took AI to do it.
[00:04:30.600 --> 00:04:38.040]   But by and large, the mind should be used for inventing and those creative things.
[00:04:38.040 --> 00:04:44.200]   And then the computer should be used for processing because it could process a lot more information,
[00:04:44.200 --> 00:04:49.640]   a lot faster, a lot more accurately, and a lot less emotionally.
[00:04:49.640 --> 00:04:57.080]   So any notion of thinking in the form of processing type thinking should be done by a computer.
[00:04:57.080 --> 00:05:02.560]   And anything that is in the notion of doing that other type of thinking should be operating
[00:05:02.560 --> 00:05:09.720]   with the brain, operating in a way where you can say, ah, that makes sense.
[00:05:09.720 --> 00:05:17.040]   You know, the process of reducing your understanding down to principles is kind of like the process,
[00:05:17.040 --> 00:05:23.040]   the first one you mentioned, type of AI algorithm where you're encoding your expertise.
[00:05:23.040 --> 00:05:25.320]   You're trying to program, write a program.
[00:05:25.320 --> 00:05:27.880]   The human is trying to write a program.
[00:05:27.880 --> 00:05:30.960]   How do you think that's attainable?
[00:05:30.960 --> 00:05:38.280]   The process of reducing principles to a computer program.
[00:05:38.280 --> 00:05:43.760]   Or when you say, when you write about, when you think about principles, is there still
[00:05:43.760 --> 00:05:49.600]   a human element that's not reducible to an algorithm?
[00:05:49.600 --> 00:05:56.960]   My experience has been that almost all things, including those things that I thought were
[00:05:56.960 --> 00:06:05.080]   pretty much impossible to express, I've been able to express in algorithms.
[00:06:05.080 --> 00:06:08.560]   But that doesn't constitute all things.
[00:06:08.560 --> 00:06:16.800]   So you can, whew, you can express far more than you can imagine you'll be able to express.
[00:06:16.800 --> 00:06:22.400]   So I use the example of, okay, it's not, how do you raise your children?
[00:06:22.400 --> 00:06:25.520]   You will be able to take it one piece by piece.
[00:06:25.520 --> 00:06:29.080]   Okay, at what age, what school?
[00:06:29.080 --> 00:06:37.260]   And the way to do that, in my experience, is to take that and when you're in the moment
[00:06:37.260 --> 00:06:45.080]   of making a decision or just past making a decision, to take the time and to write down
[00:06:45.080 --> 00:06:49.960]   your criteria for making that decision in words.
[00:06:49.960 --> 00:06:53.600]   That way you'll get your principles down on paper.
[00:06:53.600 --> 00:07:00.320]   I created an app, online call, it's right now just on the iPhone, it'll be on Android.
[00:07:00.320 --> 00:07:01.920]   Yeah, I tried getting it on Android.
[00:07:01.920 --> 00:07:02.920]   Come on, now.
[00:07:02.920 --> 00:07:03.920]   It'll be- Let's get it on Android.
[00:07:03.920 --> 00:07:06.120]   It'll be, in a few months it'll be on Android.
[00:07:06.120 --> 00:07:07.120]   Awesome.
[00:07:07.120 --> 00:07:12.560]   But it has an app in there that helps people write down their own principles.
[00:07:12.560 --> 00:07:14.560]   Because this is very powerful.
[00:07:14.560 --> 00:07:19.000]   So when you're in that moment where you've just, you're thinking about it and you're
[00:07:19.000 --> 00:07:25.240]   thinking your criteria for choosing the school for your child or whatever that might be,
[00:07:25.240 --> 00:07:30.280]   and you write down your criteria or whatever they are, those principles, you write down
[00:07:30.280 --> 00:07:39.560]   and that will, at that moment, make you articulate your principles in a very valuable way.
[00:07:39.560 --> 00:07:44.800]   And if you have the way that we operate, that you have easy access, so then the next time
[00:07:44.800 --> 00:07:49.480]   that comes along, you can go to that or you can show those principles to others to see
[00:07:49.480 --> 00:07:51.360]   if they're the right principles.
[00:07:51.360 --> 00:07:56.880]   You will get a clarity of that principle that's really invaluable in words and that'll help
[00:07:56.880 --> 00:07:58.520]   you a lot.
[00:07:58.520 --> 00:08:03.460]   But then you start to think, "How do I express that in data?"
[00:08:03.460 --> 00:08:07.000]   And it'll shock you about how you can do that.
[00:08:07.000 --> 00:08:12.280]   You'll form an equation that will show the relationship between these particular parts
[00:08:12.280 --> 00:08:18.880]   and then the, essentially the variables that are going to go into that particular equation
[00:08:18.880 --> 00:08:20.520]   and you will be able to do that.
[00:08:20.520 --> 00:08:25.460]   And you take that little piece and you put it into the computer.
[00:08:25.460 --> 00:08:29.440]   And then take the next little piece and you put that into the computer.
[00:08:29.440 --> 00:08:35.520]   And before you know it, you will have a decision-making system that's of the sort that I'm describing.
[00:08:35.520 --> 00:08:40.560]   - So you're almost making an argument against an earlier statement you've made.
[00:08:40.560 --> 00:08:47.440]   It convinced me, at first you said, "There's no way a computer could raise a child," essentially.
[00:08:47.440 --> 00:08:49.480]   But now you've described making me think of it.
[00:08:49.480 --> 00:08:55.080]   If you have that kind of idea, meritocracy, you have this rigorous approach to bridge
[00:08:55.080 --> 00:08:59.320]   water takes and investment and apply it to raising a child.
[00:08:59.320 --> 00:09:05.080]   It feels like through the process you just described, we could, as a society, arrive
[00:09:05.080 --> 00:09:11.520]   at a set of principles for raising a child and encode it into a computer.
[00:09:11.520 --> 00:09:16.640]   - That originality will not come from machine learning.
[00:09:16.640 --> 00:09:19.640]   - The first time you do it, so that the original, yes.
[00:09:19.640 --> 00:09:20.680]   - That's what I'm referring to.
[00:09:20.680 --> 00:09:24.800]   - But eventually, as we together develop it and then we can automate it.
[00:09:24.800 --> 00:09:29.200]   - That's why I'm saying the processing can be done by the computer.
[00:09:29.200 --> 00:09:30.640]   So we're saying the same thing.
[00:09:30.640 --> 00:09:32.320]   We're not inconsistent.
[00:09:32.320 --> 00:09:37.200]   We're saying the same thing, that the processing of that information and those algorithms can
[00:09:37.200 --> 00:09:40.960]   be done by the computer in a very, very effective way.
[00:09:40.960 --> 00:09:44.900]   You don't need to sit there and process and try to weigh all those things in your equation
[00:09:44.900 --> 00:09:46.440]   and all those things.
[00:09:46.440 --> 00:09:50.680]   But that notion of, "Okay, how do I get at that principle?"
[00:09:50.680 --> 00:09:56.400]   - And you're saying you'd be surprised how much you can express.
[00:09:56.400 --> 00:09:57.400]   - That's right.
[00:09:57.400 --> 00:09:59.520]   You can do that.
[00:09:59.520 --> 00:10:04.680]   So this is where I think you're going to see the future.
[00:10:04.680 --> 00:10:13.040]   Right now, we go to our devices and we get information to a large extent.
[00:10:13.040 --> 00:10:14.840]   And then we get some guidance.
[00:10:14.840 --> 00:10:17.000]   We have our GPS and the like.
[00:10:17.000 --> 00:10:22.280]   In my opinion, principles, principles, principles, principles, I want to emphasize that.
[00:10:22.280 --> 00:10:23.920]   You write them down.
[00:10:23.920 --> 00:10:25.720]   You've got those principles.
[00:10:25.720 --> 00:10:30.400]   They will be converted into algorithms for decision-making.
[00:10:30.400 --> 00:10:34.960]   And they're going to also have the benefit of collective decision-making.
[00:10:34.960 --> 00:10:40.560]   Because right now, individuals, based on what's stuck in their heads, are making their decisions
[00:10:40.560 --> 00:10:42.560]   in very ignorant ways.
[00:10:42.560 --> 00:10:44.320]   They're not the best decision-makers.
[00:10:44.320 --> 00:10:46.280]   They're not the best criteria.
[00:10:46.280 --> 00:10:47.480]   And they're operating.
[00:10:47.480 --> 00:10:52.860]   When those principles are written down and converted into algorithms, it's almost like
[00:10:52.860 --> 00:10:55.680]   you'll look at that and follow the instructions.
[00:10:55.680 --> 00:10:58.480]   And it'll give you better results.
[00:10:58.480 --> 00:11:01.140]   Medicine will be much more like this.
[00:11:01.140 --> 00:11:05.160]   You can go to your local doctor and you could ask his point of view and whatever.
[00:11:05.160 --> 00:11:06.360]   And he's rushed.
[00:11:06.360 --> 00:11:08.960]   And he may not be the best doctor around.
[00:11:08.960 --> 00:11:13.720]   And you're going to go to this thing and get that same information or just automatically
[00:11:13.720 --> 00:11:15.320]   have an input in that.
[00:11:15.320 --> 00:11:18.840]   And it's going to tell you, okay, here's what you should go do.
[00:11:18.840 --> 00:11:21.760]   And it's going to be much better than your local doctor.
[00:11:21.760 --> 00:11:30.080]   And that, the converting of information into intelligence, okay, intelligence is the thing.
[00:11:30.080 --> 00:11:35.320]   We're coming out with, again, I'm 70 and I want to pass all these things along.
[00:11:35.320 --> 00:11:42.520]   So all these tools that I've found need to develop all over these periods of time, all
[00:11:42.520 --> 00:11:44.880]   those things, I want to make them available.
[00:11:44.880 --> 00:11:50.360]   And what's going to happen as they're going to see this, they're going to see these tools
[00:11:50.360 --> 00:11:52.400]   operating much more that way.
[00:11:52.400 --> 00:12:00.000]   The idea of converting data into intelligence, intelligence, for example, on what they are
[00:12:00.000 --> 00:12:05.760]   like, on what are your strengths and weaknesses, intelligence on who do I work well with under
[00:12:05.760 --> 00:12:06.760]   what circumstances.
[00:12:06.760 --> 00:12:07.760]   Personalized.
[00:12:07.760 --> 00:12:08.760]   Intelligent.
[00:12:08.760 --> 00:12:14.920]   We're going to go from what are called systems of record, which are a lot of, okay, information
[00:12:14.920 --> 00:12:18.960]   organized in the right way to intelligence.
[00:12:18.960 --> 00:12:24.000]   And we're going to, that'll be the next big move in my opinion.
[00:12:24.000 --> 00:12:27.320]   And so you will get intelligence back.
[00:12:27.320 --> 00:12:31.680]   And that intelligence comes from reducing things down to principles and to...
[00:12:31.680 --> 00:12:32.520]   That's how it happens.
[00:12:32.520 --> 00:12:42.520]   [silence]
[00:12:42.520 --> 00:12:52.520]   [silence]

