
[00:00:00.000 --> 00:00:02.640]   We have two sets of customers.
[00:00:02.640 --> 00:00:07.240]   One set of customers who are users of PyTorch from the front-end side.
[00:00:07.240 --> 00:00:13.320]   They express their mathematical ideas in PyTorch to get their job done.
[00:00:13.320 --> 00:00:19.840]   And we have the back-end customers, customers of basically hardware vendors of various kinds
[00:00:19.840 --> 00:00:22.680]   on the server side, on the edge side.
[00:00:22.680 --> 00:00:28.240]   They are trying to get their hardware to work well within the PyTorch abstraction.
[00:00:28.240 --> 00:00:32.620]   Because if they do, then they get these millions of customers automatically.
[00:00:32.620 --> 00:00:36.720]   So PyTorch is a fairly big API surface.
[00:00:36.720 --> 00:00:39.280]   It's about a thousand API functions.
[00:00:39.280 --> 00:00:45.240]   And then it composes with whether you have a quantized tensor or a regular tensor and
[00:00:45.240 --> 00:00:47.400]   various other things distributed.
[00:00:47.400 --> 00:00:52.240]   To make a back-end work smoothly for PyTorch takes a lot of work.
[00:00:52.240 --> 00:00:57.840]   And so that zero to one is something that we work on with a lot of newer vendors, such
[00:00:57.840 --> 00:00:59.740]   just TPUs and AMD GPUs.

