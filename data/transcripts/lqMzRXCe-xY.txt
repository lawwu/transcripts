
[00:00:00.000 --> 00:00:06.160]   All right, everybody, welcome to the all in podcast. Lots to talk about. But right off the
[00:00:06.160 --> 00:00:14.080]   bat, congratulations to David Friedberg, who is the chairperson of the all in summit 2023. On the big
[00:00:14.080 --> 00:00:20.880]   announcement, we're going to be having the all in summit September 10 to 12 at Royce Hall at UCLA
[00:00:20.880 --> 00:00:27.120]   in Los Angeles, California tickets are now on sale and selling out quick. Friedberg, maybe you just
[00:00:27.120 --> 00:00:32.560]   give people a little overview of why you selected the location and what you hope to accomplish in
[00:00:32.560 --> 00:00:36.000]   terms of the programming, just broad strokes, and then we'll get right into the show.
[00:00:36.000 --> 00:00:41.520]   I think the general headline is today and tomorrow, where are we where we headed, I think
[00:00:41.520 --> 00:00:46.880]   exploring the state of the world and interesting things that were uniquely that we're all kind of
[00:00:46.880 --> 00:00:51.280]   excited about in the future. And we want to have great conversations with candid people
[00:00:52.400 --> 00:00:58.240]   that can give us kind of, you know, they're very honest on the ground points of view on everything
[00:00:58.240 --> 00:01:04.560]   from technology and markets, macro science, society and culture. So we're going to talk
[00:01:04.560 --> 00:01:10.880]   across all those different topic areas. And similar to what we did last year, the four of us
[00:01:10.880 --> 00:01:17.680]   on stage having conversations with these folks. So pretty excited. I think LA is a great location.
[00:01:17.680 --> 00:01:22.400]   There's obviously an availability for people to stay. There's great venues for us to do the
[00:01:22.400 --> 00:01:27.600]   evening events. And it's certainly super accessible for folks from all over the world.
[00:01:27.600 --> 00:01:32.000]   And we decided this year to have three tiers of tickets, we'll have the VIP tickets,
[00:01:32.000 --> 00:01:38.320]   we'll have scholarships for people who fill out a form so we can, you know, have really great
[00:01:38.320 --> 00:01:43.280]   diversity and representation at the event and up and comers, maybe who couldn't afford the VIP
[00:01:43.280 --> 00:01:48.720]   ticket. But in between, you decided to have a standard ticket as well. That's just 1500 bucks.
[00:01:48.720 --> 00:01:56.320]   And there'll be a VIP lounge this year for the VIP tickets and early access to the theater and
[00:01:56.320 --> 00:02:01.120]   a couple of special dinner parties. What is my wine budget so that I can take care of the VIPs
[00:02:01.120 --> 00:02:07.440]   properly? Yeah. Talk about that one later. Guys, what is my wine budget? Let me treat the VIPs
[00:02:07.440 --> 00:02:12.880]   like the VIPs that they are. What would you need per night? per dinner per person? Depends on how
[00:02:12.880 --> 00:02:18.160]   many people per person, just say per person per night is like $200 a person $100 per person per
[00:02:18.160 --> 00:02:22.320]   night. Because a person drinks a half a bottle of wine, two or three glasses. Yeah, like, you know,
[00:02:22.320 --> 00:02:31.520]   three to 500. Maybe 1000. What is the truffle budget for the conference? The truffle budget?
[00:02:31.520 --> 00:02:37.040]   Now it's too early for truffles. We can only have it. Now it's September. Yeah.
[00:02:37.040 --> 00:02:42.000]   White and black truffle season. It's a dead zone. You don't want to be in that you got to either
[00:02:42.000 --> 00:02:45.680]   wait till the winter or you got to enjoy the early summer. We have to have a conference in early
[00:02:45.680 --> 00:02:50.480]   November. At that point we can focus the entire VIP budget if it were according to me would be
[00:02:50.480 --> 00:03:11.520]   spent on white truffles and white. Rain Man David. All right, everybody, let's get started.
[00:03:11.520 --> 00:03:17.440]   You're probably happy to use with us as well. The dictator himself and David Sacks, the Rain Man.
[00:03:17.440 --> 00:03:22.800]   Yeah, Google had their IO event, they announced palm to Google's language model is going to power
[00:03:22.800 --> 00:03:28.880]   25 products, including Bard, which is got coding capabilities. Now I guess to go up against
[00:03:28.880 --> 00:03:34.560]   githubs co pilot palm to will have improved multi linguality.
[00:03:34.560 --> 00:03:36.000]   Wait, what?
[00:03:36.000 --> 00:03:37.440]   Across 100 languages.
[00:03:37.440 --> 00:03:40.080]   Well, multi what?
[00:03:40.080 --> 00:03:41.920]   It's going to support 100 languages.
[00:03:41.920 --> 00:03:48.720]   And it's going to be better at mathematics and reasoning. They also announced duet AI,
[00:03:48.720 --> 00:03:54.880]   which is basically Google suite of generative AI tools, or Doc sheets, drive, all that kind of
[00:03:54.880 --> 00:03:59.200]   stuff. Kind of like a copy of Microsoft's co pilot tools that Saks has talked about a whole bunch,
[00:03:59.200 --> 00:04:04.800]   the guide on the side, if you will, they tease the future where AI can summarize docs, which box AI
[00:04:04.800 --> 00:04:13.040]   Aaron Levy is doing. They also previewed proactive prompts in the sidebar of Google Docs. And I
[00:04:13.040 --> 00:04:17.600]   talked about that a whole bunch on the swing startups. They're going to also now add images
[00:04:17.600 --> 00:04:23.600]   and replies. Have you guys used Bart in the last 24 hours? I used it last week. Not in the last 24
[00:04:23.600 --> 00:04:30.320]   hours. I think you guys should use it. We should talk about it. It's really impressive. It's better
[00:04:30.320 --> 00:04:35.920]   than chat GPT. At this point from my experience on talk going through a number of things because
[00:04:35.920 --> 00:04:40.560]   it's actually connected live to the internet. It's connected live to search, it can pull down real
[00:04:40.560 --> 00:04:45.040]   time data for you. It can do real internet searches for you and just give you the results.
[00:04:45.040 --> 00:04:51.280]   It's extremely powerful. I feel like it's the product that Google has been scared to do,
[00:04:51.280 --> 00:04:56.720]   which is the product that can truly disrupt search. And they're doing it. So how do I try it?
[00:04:56.720 --> 00:05:00.240]   Do I just go to bar google.com? No access needed? No cost? Nothing?
[00:05:00.240 --> 00:05:01.920]   Oh my god, this is great.
[00:05:01.920 --> 00:05:06.800]   And seriously use it and it does real time search and it's 180 languages. It converts it generates
[00:05:06.800 --> 00:05:11.600]   images for you can generate charts results. It's really powerful guys. Google has strung together
[00:05:11.600 --> 00:05:18.640]   I think a lot of features and you can look Google's market caps up $150 billion in the last two days.
[00:05:18.640 --> 00:05:19.920]   Okay, this is pretty interesting.
[00:05:19.920 --> 00:05:24.560]   And so sacks a lot of comparing some results. A lot of what we've been talking about with
[00:05:24.560 --> 00:05:30.240]   respect to plugins and the tooling built into auto GPT. Many of the most interesting kind of
[00:05:30.240 --> 00:05:37.600]   applications that folks have kind of demonstrated or utilized are really kind of built into this
[00:05:37.600 --> 00:05:38.720]   bar product.
[00:05:38.720 --> 00:05:41.680]   Okay, I love Bard. Can I just give you guys what I just tried?
[00:05:41.680 --> 00:05:43.360]   Can we guess?
[00:05:43.360 --> 00:05:45.840]   Yes, yeah, guess, guess, guess.
[00:05:45.840 --> 00:05:49.520]   Was it something about freebergs anus Uranus?
[00:05:49.520 --> 00:05:52.000]   No, it wasn't a Uranus joke. Okay, then tell us.
[00:05:52.640 --> 00:05:58.160]   My first question was, why is David freeberg such a sellout, but the answer confused him with an
[00:05:58.160 --> 00:06:03.360]   actor. So let's forget that. My second question was, is Jason Calcanis a virtue signaler? And
[00:06:03.360 --> 00:06:08.160]   the answer is fantastic. Jason Calcanis is a venture capitalist and entrepreneur who has
[00:06:08.160 --> 00:06:13.440]   been accused of virtue signaling. Virtue signaling is the act of publicly expressing opinions or
[00:06:13.440 --> 00:06:17.760]   sentiments intended to demonstrate one's good character or the moral correctness of one's
[00:06:17.760 --> 00:06:22.560]   position on a particular issue. There are a number of reasons why people might accuse Jason
[00:06:22.560 --> 00:06:28.240]   Calcanis of virtue signal. Okay, for example, he has to make public statements about his support
[00:06:28.240 --> 00:06:33.200]   for social justice causes. But he has also been criticized for his lack of concrete action on
[00:06:33.200 --> 00:06:38.160]   these issues. Additionally, he has been accused of using his platform to promote himself and his
[00:06:38.160 --> 00:06:44.080]   businesses rather than to genuinely advocate for social change. That's ultimately, whether or not
[00:06:44.080 --> 00:06:49.280]   Jason Calcanis is a virtue signaler is a matter of opinion. There's no clear consensus on this issue.
[00:06:49.280 --> 00:06:53.520]   And there is evidence to support both sides of the argument. However, it is important to note
[00:06:53.520 --> 00:06:59.440]   that virtue signaling can be a harmful practice, as it can lead to people becoming desensitized
[00:06:59.440 --> 00:07:04.320]   to real social problems and make it more difficult to address them effectively.
[00:07:04.320 --> 00:07:09.840]   This is some woke shit. Wait, see what I just did. Here's mine. I asked Bard,
[00:07:09.840 --> 00:07:17.280]   is Tramont a horrible human? Here's what Bard had to say. Tramont Pauly-Hopitia is a complex
[00:07:17.280 --> 00:07:22.800]   individual with both positive and negative qualities. He is a successful venture capitalist
[00:07:22.800 --> 00:07:28.720]   and entrepreneur, but he has also been criticized for his outspoken views and his past actions.
[00:07:28.720 --> 00:07:36.000]   So, some of Pauly-Hopitia's qualities include his intelligence, his ambition,
[00:07:36.000 --> 00:07:41.040]   his drive to succeed, blah, blah, blah, blah, blah. He's also been criticized for his arrogance,
[00:07:41.040 --> 00:07:47.760]   his lack of empathy, and his willingness to exploit people for his own gain. This is perfect.
[00:07:47.760 --> 00:07:51.200]   It's the singularity. It's balanced. It's true.
[00:07:51.200 --> 00:07:55.840]   It is giving you like the good and the bad. Oh my God, that's hilarious.
[00:07:55.840 --> 00:08:02.960]   This is a very fair answer. Ultimately, whether or not Tramont Pauly-Hopitia is a horrible is
[00:08:02.960 --> 00:08:08.960]   a matter of opinion. I love it. I asked it, where is the, this is going to really show you the power
[00:08:08.960 --> 00:08:14.240]   of this, where is the All in Summit 2023 being held and how much are tickets? So like two questions
[00:08:14.240 --> 00:08:18.000]   that are deep on the website. And it says there are two All in Summits. Yeah, that's incredible.
[00:08:18.000 --> 00:08:21.280]   That's an advertising association. That's incredible. And then it says the All in
[00:08:21.280 --> 00:08:27.120]   Summit 2023 will be held September 10th at 11, 23 at Roy's Hall. Tickets are 1500 for
[00:08:27.120 --> 00:08:34.080]   general admission 7500 for VIP. That's insane. That's insane. Wait, so free bird, what are the
[00:08:34.080 --> 00:08:38.880]   key differences between Bard and chat GPT just because you've used it on the modeling side,
[00:08:38.880 --> 00:08:43.840]   they're claiming a much larger, more robust model. It's linked to the to the internet. So it's linked
[00:08:43.840 --> 00:08:49.760]   to live search, which you can't do with chat GPT, which is based on a static training data set. So
[00:08:49.760 --> 00:08:55.040]   Bard can actually engage with dynamic content and a dynamic content generator across the web. And
[00:08:55.040 --> 00:09:00.400]   then it's integrated with a number of Google services that basically can take certain live
[00:09:00.400 --> 00:09:07.280]   feeds of data like flights and stock prices and so on. It's free. You don't need to be charged for
[00:09:07.280 --> 00:09:13.680]   free over usage. You don't need to sign up and get access. It's it's just available to anyone. I mean,
[00:09:13.680 --> 00:09:17.360]   I think this is the game changer everyone is hoping for free Google. I just I just asked
[00:09:18.640 --> 00:09:25.840]   did Stan Druckenmiller by Nvidia recently. So it wasn't able to find the transcript of his thing,
[00:09:25.840 --> 00:09:32.000]   but it did find the 13 F and it says yes, according to his 13th quarter of 22, Stan purchased a
[00:09:32.000 --> 00:09:38.960]   500 82,915 shares of Nvidia. Yeah, incredible. I just said what was Google's restructuring expense
[00:09:38.960 --> 00:09:44.480]   incurred in q1 2023. And it says according to Google's 2023 q1 earnings report, the company
[00:09:44.480 --> 00:09:49.440]   incurred restructuring expense of 1.6 billion, including the decision to lay off 12,000 employees,
[00:09:49.440 --> 00:09:53.360]   they were part of a broader restructuring. I mean, that wasn't it was it basically parsed
[00:09:53.360 --> 00:10:00.000]   through the press release parts through the q1 data. It's really pretty impressive, huh? I mean,
[00:10:00.000 --> 00:10:05.440]   what do you guys think? Well, no, this one. Yeah. David Sachs, what does David Sachs think about
[00:10:05.440 --> 00:10:11.440]   hunter Biden, everybody on the island pod knows. But let's see what Bard knows. He's not publicly
[00:10:11.440 --> 00:10:15.760]   commented on hunter Biden. However, he has been critical of the Biden family business dealings in
[00:10:15.760 --> 00:10:21.120]   Ukraine. In a 2019 interview, SAC said that he was deeply troubled by the Biden's vomiting Ukraine
[00:10:21.120 --> 00:10:26.480]   2019. He believed it was a conflict of interest for hunter Biden to serve on the board of
[00:10:26.480 --> 00:10:31.600]   charisma. That's pretty interesting. I don't know. That's clearly inaccurate. I mean, I wasn't
[00:10:31.600 --> 00:10:37.680]   talking about it. Yeah. In 2019. Think about that. That's Oh, yeah. So the question is,
[00:10:37.680 --> 00:10:41.440]   where is he getting these quotes? And then why doesn't it give citations?
[00:10:41.440 --> 00:10:45.200]   Well, so wait, SACs has been critical that Trump administration's use of hunter Biden's
[00:10:45.200 --> 00:10:49.840]   business dealings as a political weapon. Yeah, that's not true. You've never criticized the
[00:10:49.840 --> 00:10:55.040]   Trump administration. Those quotes are wrong. Those quotes are I just said to it, can you access
[00:10:55.040 --> 00:10:59.840]   and think about this, this data set. And this is where Google has unique advantages. I said,
[00:10:59.840 --> 00:11:05.600]   can you access the YouTube transcript data? And it says, Yes, Bart integrates YouTube transcript data.
[00:11:05.600 --> 00:11:09.680]   I said, Do you have access to transcript data from the Ellen podcast channel? It says, Yes, I do
[00:11:09.680 --> 00:11:13.120]   have access to the transcript data from the Ellen podcast channel. I said, Can you access this data
[00:11:13.120 --> 00:11:21.920]   answer some questions? And now, what did SACs say about hunter Biden in that show?
[00:11:21.920 --> 00:11:28.000]   And so I would guess so think about the answer.
[00:11:28.000 --> 00:11:31.600]   So far, I'm finding this to be very inaccurate.
[00:11:32.480 --> 00:11:36.800]   Yeah, so David SACs appeared, he said he believes hunter diet Biden is a deeply troubled individual
[00:11:36.800 --> 00:11:40.160]   has made a lot of bad decisions. He also said that he believes hunter Biden's business dealings in
[00:11:40.160 --> 00:11:43.600]   Ukraine were highly unethical, and that he believes it's impossible that Joe this is
[00:11:43.600 --> 00:11:48.480]   transcript data from the pod. However, SACs also said that he does not believe that hunter Biden's
[00:11:48.480 --> 00:11:52.480]   business dealings are a quote smoking gun that proves that Joe Biden engaged in any wrongdoing.
[00:11:52.480 --> 00:11:56.640]   He said that he believes that the evidence against Joe Biden were quote circumstantial is quote
[00:11:56.640 --> 00:12:00.640]   circumstantial, and that he does not believe that there's enough evidence to impeach him.
[00:12:00.640 --> 00:12:04.640]   SACs his comments about hunter Biden were met with mixed reactions. Some people would fuck
[00:12:04.640 --> 00:12:07.440]   and on and on and on. I think it's very inaccurate, to be honest.
[00:12:07.440 --> 00:12:13.040]   Some of my stuff mixed in, it's got some of your stuff mixed in. But also, it's like it's
[00:12:13.040 --> 00:12:17.440]   summarizing in a way that neither of us actually said it. Yeah, they're missing the key points
[00:12:17.440 --> 00:12:22.560]   about what I did say. I asked a pretty complicated question here. And I think it did a pretty decent
[00:12:22.560 --> 00:12:28.640]   job. I said, I would like to fly low premier on Air France, from the west coast to Europe.
[00:12:29.200 --> 00:12:35.920]   Where should I depart? And it got it perfectly la xsfo and Seattle Tacoma.
[00:12:35.920 --> 00:12:43.760]   Oh, yeah, I just asked it to get me the fastest route to Portofino. And it gave me the exact
[00:12:43.760 --> 00:12:47.600]   flight I should take from SFO how much the ticket is and then the train I should take
[00:12:47.600 --> 00:12:51.760]   from the shortest meaning the shortest time Yeah, because I don't want to do a layover in Germany.
[00:12:51.760 --> 00:12:55.360]   It's like fly to Milan, take the train, and it gave me the full schedule, which by the way,
[00:12:55.360 --> 00:12:59.120]   Google Flights can't do because you go to Google Flights. And all it does is give you the flight
[00:12:59.120 --> 00:13:04.240]   data. It can integrate a lot of different data set to give you these answers. Did you say fastest
[00:13:04.240 --> 00:13:08.640]   route or fastest flight? What did you fastest route? Yeah. So I want to spend the least amount
[00:13:08.640 --> 00:13:12.080]   of time traveling is what my objective was. This is why I was saying I think you guys should play
[00:13:12.080 --> 00:13:17.840]   with this tool a bit. It is I think head and shoulders above chat GPT, the models supposedly
[00:13:17.840 --> 00:13:22.240]   better. Obviously, other people will come out with with kind of, you know, measures of that
[00:13:22.240 --> 00:13:26.720]   and estimates of whether that's true. The extensibility, the integration of live data,
[00:13:26.720 --> 00:13:30.960]   and the integration with Google's very unique data set is what's so powerful that they have
[00:13:30.960 --> 00:13:36.880]   access to flight data that they have integrated YouTube transcript data. It's just super powerful,
[00:13:36.880 --> 00:13:43.520]   super impressive. I'm using this in real time. And I do find the interface to be snappier than
[00:13:43.520 --> 00:13:50.240]   chat GPT. And it like you said, it doesn't need the browsing plugin in order to scrape more recent
[00:13:50.240 --> 00:13:54.640]   data from the internet that it wasn't trained on. But I'm not finding the answers to be more
[00:13:54.640 --> 00:13:59.120]   accurate. And I'm not finding them to be more detailed. I'm not saying a reason to use this
[00:13:59.120 --> 00:14:06.000]   over chat GPT. I prefer chat GPT so far. I'm just telling you, okay, well, the recent stuff is
[00:14:06.000 --> 00:14:10.960]   important. Well, I mean, clearly, chat GPT is going to make the browsing browsing plugin,
[00:14:10.960 --> 00:14:16.080]   much snappier, and like much more part of the core functionality rather than something that's
[00:14:16.080 --> 00:14:19.760]   like an add on. Yeah, it can't be an add on, it's got to be able to incorporate the most recent
[00:14:19.760 --> 00:14:24.720]   information. I did ask some questions about the Ukraine war. And then it gave me like a highly
[00:14:24.720 --> 00:14:29.760]   compressed view. And I said, please provide more detail. And then it's actually did a pretty good
[00:14:29.760 --> 00:14:34.080]   job expanding it. And I did it very quickly. Well, if you look at the view drafts thing,
[00:14:34.080 --> 00:14:37.760]   that's always been one of its strengths is that it will format it three different ways for you
[00:14:37.760 --> 00:14:41.680]   by default, if you go to the top, right, so you can just sort of cycle through them. But that's
[00:14:41.680 --> 00:14:45.840]   an existing feature. I mean, I definitely keep playing with this play with it. It's one of
[00:14:47.200 --> 00:14:52.880]   the obviously important releases that I thought they were going to catch up real quick. And this
[00:14:52.880 --> 00:14:57.120]   seems like we got a race on our hands now. But I think the point you're making freeberg is a good
[00:14:57.120 --> 00:15:04.560]   one, which is when these big companies just get their act together. It's very hard to discern
[00:15:04.560 --> 00:15:12.720]   whether something is 80% is good or 120% better. There's this fuzzy gray area where a lot of people
[00:15:12.720 --> 00:15:17.120]   can find utility in a lot of different products. And then the one with the better distribution wins
[00:15:17.120 --> 00:15:21.280]   and so if they take Bart and they have the confidence now to just integrate it into Gmail,
[00:15:21.280 --> 00:15:25.360]   or integrated into these other points where they already have hundreds of millions of users.
[00:15:25.360 --> 00:15:30.560]   That's like a really tough distribution barrier to overcome. That's the next step that I think
[00:15:30.560 --> 00:15:35.920]   if Google really wants to win here, they have to force distribution of these tools in line to where
[00:15:35.920 --> 00:15:40.640]   people are. And if they do that, you're not going to know the difference between 80 and 100%. Someone
[00:15:40.640 --> 00:15:45.680]   as sophisticated as Saks may be able to, but the average person will just be like, this is good
[00:15:45.680 --> 00:15:50.720]   enough. They've got distribution. I mean, like with all products, the kind of key advantage is
[00:15:50.720 --> 00:15:54.720]   distribution. That's the platform advantage. Can I show you an answer? I think it's like
[00:15:54.720 --> 00:15:59.840]   super hallucinating on so I asked it, what is David Saks written about SAS? And then it says
[00:15:59.840 --> 00:16:03.040]   I'm a venture capitalists, entrepreneurs written extensively about SAS. He's a founder of Yammer.
[00:16:03.040 --> 00:16:08.560]   Okay, that's true. But then it says he's also the co founder of WeWork. Not true. Didn't know that
[00:16:08.560 --> 00:16:12.640]   then it says Saks, congrats, Saks has written a number of articles about SAS, including,
[00:16:13.280 --> 00:16:20.800]   and then all five of those articles were not written by me. It's basically like hallucinating,
[00:16:20.800 --> 00:16:25.920]   like really strongly. So there's significant hallucination here.
[00:16:25.920 --> 00:16:30.400]   Oh, you know what, Bard is at the after party for Google I/O right now. And it's had too much to
[00:16:30.400 --> 00:16:36.480]   drink. So it's just straight up drunk. This is why Google didn't want to release this, right?
[00:16:36.480 --> 00:16:40.720]   Friedberg, like, they don't want the Google brand associated with these hallucinations.
[00:16:40.720 --> 00:16:43.440]   Whereas that's right. Nobody cares what open AI brand,
[00:16:43.440 --> 00:16:49.440]   this was a big part of the innovators dilemma that Google faced, which was number one,
[00:16:49.440 --> 00:16:56.720]   it could be disruptive to the core business. Number two, it exposes them to regulatory scrutiny.
[00:16:56.720 --> 00:17:01.680]   And number three, is if they make mistakes, they're going to get more scrutinized than some,
[00:17:01.680 --> 00:17:06.560]   you know, rinky dinky startup where everyone's so forgiving. But it's great to see look, I mean,
[00:17:06.560 --> 00:17:10.560]   as a shareholder, it's great to see them take this risk. It's great to see them put this out
[00:17:10.560 --> 00:17:14.560]   there. They've now released robust coding capabilities. They've integrated scientific
[00:17:14.560 --> 00:17:18.320]   research papers, obviously, they're going to continue to improve model performance,
[00:17:18.320 --> 00:17:23.520]   improve integration with these data feeds. And they have a very large headcount, I think,
[00:17:23.520 --> 00:17:28.880]   north of 10,000 people working 10,000 smart people. So if you can organize those people,
[00:17:28.880 --> 00:17:34.240]   and they've got this significantly advantaged infrastructure, they have a real shot at being
[00:17:34.800 --> 00:17:39.040]   a platform player here. The question later is going to be how much is this going to disrupt
[00:17:39.040 --> 00:17:43.680]   core search revenue? You know, what categories of search revenue are going to get disrupted?
[00:17:43.680 --> 00:17:48.160]   And you know, are they going to make that up in other ways? And I think time will tell there.
[00:17:48.160 --> 00:17:53.520]   But I think this is the progress that shareholders and investors were looking to see
[00:17:53.520 --> 00:17:59.920]   with respect to the product competition in AI. And certainly some shareholders still want to see
[00:17:59.920 --> 00:18:04.560]   continued improvements on the cost structure of the business. But that's a separate topic.
[00:18:04.560 --> 00:18:08.320]   But this was exactly I think, really hit the bullseye on what people were looking for.
[00:18:08.320 --> 00:18:11.840]   I don't see how it's a bullseye like that. So I just I just asked it, can you give me a complete
[00:18:11.840 --> 00:18:16.800]   list of all the articles on SAS and SAX in the last three years. So now at least it's over the
[00:18:16.800 --> 00:18:23.440]   target. Those five articles and mentions are correct. The chat GPT do that? Well, no, because
[00:18:23.440 --> 00:18:28.560]   the browsing plugin, right. But I'm just saying like, they got a lot of work to do here on quality.
[00:18:28.560 --> 00:18:33.040]   Yeah, they all do. But it is snappy. And I finally got to these five articles being correct
[00:18:33.040 --> 00:18:38.560]   AI regulation. We talked about it five weeks ago on the show, I think. Well, there's been some
[00:18:38.560 --> 00:18:44.560]   movement there. Vice President Harris met with CEOs of Alphabet, Microsoft, OpenAI. So that's
[00:18:44.560 --> 00:18:53.200]   Sundar Satya and Sam discuss implementing AI safeguards. And then on Tuesday, Sam Altman was
[00:18:53.200 --> 00:19:02.000]   interviewed by Patrick Colson, the CEO of Stripe. And he endorsed the idea of IAEA for AI. That's
[00:19:02.000 --> 00:19:10.400]   the International Atomic Energy Agency. So is that hyperbolic delusions of grandeur or right
[00:19:10.400 --> 00:19:18.080]   on target? Well, the interesting thing about the IAEA is that what I learned recently from the CEO
[00:19:18.080 --> 00:19:23.840]   of Planet Labs, Will Marshall is that the predecessor organization to the IAEA is really
[00:19:23.840 --> 00:19:30.480]   this organization called pugwash. And what that was, Einstein and Bertrand Russell in the 50s,
[00:19:30.480 --> 00:19:38.000]   post Hiroshima and Nagasaki bringing together academics to basically create a way to think
[00:19:38.000 --> 00:19:44.640]   about nuclear disarmament going forward, just because they all saw the damage. And there was a
[00:19:44.640 --> 00:19:51.680]   large framework that set up the current denuclearization treaties. And then the IAEA was
[00:19:51.680 --> 00:19:58.560]   set up after that. And so I think that there's a thread here, which is basically what he's saying
[00:19:58.560 --> 00:20:04.960]   is there's something around nuclear disarmament that is very similar to AI, both in terms of its
[00:20:04.960 --> 00:20:09.440]   potential, but obviously in terms of its risks. And so there's like a whole monitoring framework.
[00:20:09.440 --> 00:20:14.880]   There's a know your customer kind of framework. These are not unfettered things that can just
[00:20:14.880 --> 00:20:21.360]   live openly in the wild. So I think it's interesting to acknowledge that Sam who's
[00:20:21.360 --> 00:20:26.720]   deep in the bowels of one of the most important companies, sees both its potential, but it's
[00:20:26.720 --> 00:20:31.360]   danger enough to say that this is how we should think about it like nuclear weapons, I think is a
[00:20:31.360 --> 00:20:37.040]   very important thing to acknowledge. And the White House pledged to release draft guidelines for AI
[00:20:37.040 --> 00:20:44.000]   safeguards that the National Science Foundation plans to spend 140 million on at AI focused
[00:20:44.000 --> 00:20:49.120]   research centers. FTC chair Lena Khan wrote a guest essay in the New York Times calling for AI
[00:20:49.120 --> 00:20:55.360]   regulation due to large share risks, including monopoly consolidation, fraud, extortion and bias.
[00:20:56.000 --> 00:21:01.680]   Any thoughts there, Sachs, about adding regulation to the mix right now? Are we
[00:21:01.680 --> 00:21:06.320]   jumping the gun here and going to smother this thing before it even gets correct answers?
[00:21:06.320 --> 00:21:12.000]   Serious risk. And the White House also announced that Kamala Harris would be the AI czar
[00:21:12.000 --> 00:21:15.840]   for this issue, which I don't think inspires anyone with confidence that they're gonna,
[00:21:15.840 --> 00:21:21.040]   you know, get this right. Look, my concern here is I think we should have conversations about the
[00:21:21.040 --> 00:21:25.440]   risks of AI. We should be thinking about that. I think people in the industry need to be thinking
[00:21:25.440 --> 00:21:30.960]   about what guardrails can we put on it. I think Elon's raised, I think, long-term concerns about
[00:21:30.960 --> 00:21:34.800]   whether this could lead to AGI. You basically create a super intelligence that you can't
[00:21:34.800 --> 00:21:38.960]   control. I think people in the industry haven't really figured out how to address that. That
[00:21:38.960 --> 00:21:43.520]   problem is called alignment. And everyone's trying to figure out how do you even make alignment work?
[00:21:43.520 --> 00:21:48.160]   Is that theoretically possible? So there are real and valid concerns. Jake, how you've raised the
[00:21:48.160 --> 00:21:52.560]   issue of deepfakes. I think provenance of data is going to be a real issue. People committing
[00:21:52.560 --> 00:21:57.360]   fraud or, you know, other kinds of criminal acts using it. So there are real concerns. But the
[00:21:57.360 --> 00:22:04.160]   problem is that we have no idea how to regulate this yet. And the fact that Kamala Harris is the
[00:22:04.160 --> 00:22:08.880]   AI czar now, again, just points to the fact that nobody has a good idea of what this is supposed
[00:22:08.880 --> 00:22:15.200]   to be or who the expert is supposed to be. And this idea of creating an Atomic Energy Commission,
[00:22:16.560 --> 00:22:23.520]   look, I can see why Sam and other industry leaders might want that because they're going to
[00:22:23.520 --> 00:22:29.680]   quickly develop relationships. The biggest AI companies, which now includes OpenAI,
[00:22:29.680 --> 00:22:34.880]   which has the backing of Microsoft and Google, and the biggest of the big tech companies,
[00:22:34.880 --> 00:22:39.360]   they have all the lobbyists in Washington. They have all the political connections. They're the
[00:22:39.360 --> 00:22:45.120]   ones who are huge donors. And they have political relationships. And they're going to help construct
[00:22:45.120 --> 00:22:49.760]   the regulations. And it's going to turn into another example of industry capture, just like
[00:22:49.760 --> 00:22:54.880]   Dorothy K. Jr. told us about on the show last week when he talked about how the big weapons
[00:22:54.880 --> 00:23:00.640]   companies influence our foreign policy, the way that the big pharma companies influence the FDA,
[00:23:00.640 --> 00:23:04.960]   and so on. We're going to end up in a situation in which the big tech companies have inordinate
[00:23:04.960 --> 00:23:10.640]   influence over this new regulatory agency. And since it's not clear what the regulatory agency
[00:23:10.640 --> 00:23:14.880]   is even supposed to be doing yet, they're going to end up promulgating a bunch of regulations that
[00:23:14.880 --> 00:23:18.640]   create a barrier to entry for the little guy. They're going to create a moat with regulation.
[00:23:18.640 --> 00:23:22.720]   For the big guys. And they'll slow down the whole process of innovation in the space,
[00:23:22.720 --> 00:23:27.600]   which some people might like, but I think is really the best hope that America has to get out
[00:23:27.600 --> 00:23:32.960]   of its horrible fiscal situation and all this debt. We need a massive productivity boost to get out of
[00:23:32.960 --> 00:23:39.360]   the massive debt bubble that we're in. So what I'd hate to see is that, yeah, we basically
[00:23:39.920 --> 00:23:43.600]   kills this thing in the cradle. Interesting. Yes, we are in a deep
[00:23:43.600 --> 00:23:47.840]   pit here. And Stanley Druckenmiller gave a speech at USC
[00:23:47.840 --> 00:23:54.160]   at the 37th annual meeting of the USC Marshall Center for Investment Studies,
[00:23:54.160 --> 00:23:59.360]   and he expressed concern about the financial crisis that occur could occur in the 2025 to
[00:23:59.360 --> 00:24:05.520]   2035 period, due to the baby boomers turning 65 and the impact on entitlements. He predicted that
[00:24:05.520 --> 00:24:13.120]   in 25 years spending on seniors will grow to 60% of all taxes. Here's a look at the chart.
[00:24:13.120 --> 00:24:21.280]   You can see today there as the vertical line, about 5% of our GDP goes to Social Security
[00:24:21.280 --> 00:24:29.760]   and today and about another 5.5 goes to Medicare, Medicaid. And it's predicting here that those
[00:24:29.760 --> 00:24:36.880]   combined will go from what looks like 12% today, up to 24% of GDP, your reaction,
[00:24:36.880 --> 00:24:43.360]   freeberg. I mean, my reaction is, is another very important voice stating the obvious,
[00:24:43.360 --> 00:24:47.440]   like the arithmetic just doesn't work. When we had RFK on last week, I prodded him on
[00:24:47.440 --> 00:24:55.200]   his stance and point of view on the federal deficit, the fiscal deficit, this government runs,
[00:24:55.920 --> 00:25:01.200]   and the entitlement programs that are only going to swell. And the debt burden, which has an
[00:25:01.200 --> 00:25:06.160]   interest payment obligation on it, that the interest payments are swelling. And when you
[00:25:06.160 --> 00:25:12.240]   do the arithmetic on all this, it's going to balloon the cost to service the debt and without
[00:25:12.240 --> 00:25:17.520]   some degree of cutting across the board spending and entitlement programs, discretionary spending
[00:25:17.520 --> 00:25:21.920]   and entitlement programs, you can't make the interest payments, which all you know, inevitably
[00:25:21.920 --> 00:25:27.360]   leads to some form of default. So that's just the math and the way this all works out. And I think
[00:25:27.360 --> 00:25:33.280]   what he's done is put a pen to paper and show him that, you know, call it roughly 2025 to 2035,
[00:25:33.280 --> 00:25:40.960]   you start to run into that fiscal scenario, where you know, you can no longer generate enough
[00:25:40.960 --> 00:25:46.480]   income from the US economy to fund both the interest payment obligations on the federal debt,
[00:25:46.480 --> 00:25:49.840]   as well as these entitlement programs and something's got to give either you're going to
[00:25:49.840 --> 00:25:53.920]   have to default on the debt, or you're going to have to cut the entitlement programs. And the
[00:25:53.920 --> 00:25:58.160]   point he's making is that the longer you wait to cut the entitlement programs, the worse it's going
[00:25:58.160 --> 00:26:04.000]   to get, because you're accruing so much debt in the interim. And as we know, that becomes very
[00:26:04.000 --> 00:26:08.320]   politically unpopular. And what's so scary to me, and I've kind of shared this, and you know,
[00:26:08.320 --> 00:26:12.880]   obviously, Chamath has a different point of view. But it feels to me like, this is that don't look
[00:26:12.880 --> 00:26:18.640]   up movie moment where we have this, like, you know, looming disaster, we don't have any fuel
[00:26:18.640 --> 00:26:23.120]   in the car. And all that everyone's talking about is where are we going to drive the car.
[00:26:23.120 --> 00:26:29.120]   And every political conversation, every candidate gets on stage gets on a podcast gets on a TV show.
[00:26:29.120 --> 00:26:35.040]   And they talk about stuff that is simply not feasible. And the direction setting with respect
[00:26:35.040 --> 00:26:42.000]   to social policy, wars, geopolitics, you know, how are we going to take care of our middle class,
[00:26:42.000 --> 00:26:48.000]   none of that stuff is possible to actually execute against without recognizing and acknowledging that
[00:26:48.000 --> 00:26:52.720]   we don't have gas in the car. And we have to figure out how to gas up the car. And so it's
[00:26:52.720 --> 00:26:57.440]   great to see Druckenmiller being vocal putting very simple, clear slides together. It's like
[00:26:57.440 --> 00:27:02.560]   what I've mentioned in the past, I would love to see a Clinton esque Bill Clinton esque slide deck,
[00:27:02.560 --> 00:27:06.880]   where he would come up with a poster and show everyone, here's the economy, folks. And I think
[00:27:06.880 --> 00:27:11.520]   Druckenmiller did a great job. And I encourage everyone to go watch that. There's an audio
[00:27:11.520 --> 00:27:16.320]   transcript of the talk as well as the slides are publicly available on the internet. We'll put the
[00:27:16.320 --> 00:27:21.120]   links in the show notes here today. I just think it's it's whether or not you agree with the
[00:27:21.120 --> 00:27:25.760]   outlook. I think it's worth everyone watching and realizing how serious of an issue this is,
[00:27:25.760 --> 00:27:31.280]   and why this has to become the number one topic of conversation going to this next presidential
[00:27:31.280 --> 00:27:37.280]   election cycle. He's also disclosed he short the dollar long gold, euro oil and ad which I guess
[00:27:37.280 --> 00:27:42.240]   is the Australian dollar. And he's also long Nvidia and Microsoft believes in videos got a
[00:27:42.240 --> 00:27:48.000]   monopoly on the chip market. I got a question for Chamath and then to sacks. So Chamath,
[00:27:48.000 --> 00:27:54.400]   what's your just reaction to this? Do you think he's Dr. dooming it and we can have all this debt?
[00:27:54.400 --> 00:28:00.720]   And then the question then becomes, is there any way out of this? We had a Trump town hall,
[00:28:00.720 --> 00:28:05.440]   I hate to bring it up and go back into, you know, the sort of Trump commentary and all this,
[00:28:05.440 --> 00:28:11.680]   but he's the he's the lead candidate sacks. And he said, he thinks we can get out of debt,
[00:28:11.680 --> 00:28:16.080]   we just got to drill a bunch of oil drill, baby drill, and we'll get out of this problem,
[00:28:16.080 --> 00:28:18.400]   we'll be able to rebalance the budget. So Chamath and then sex,
[00:28:18.400 --> 00:28:23.600]   I want to be clear, I don't think it's great that we have these enormous debts and entitlement
[00:28:23.600 --> 00:28:30.080]   obligations. But I also don't think that there's some magical number where the economy breaks.
[00:28:30.080 --> 00:28:36.240]   And the reason is because we're central to not just our economy, but everybody else's economy.
[00:28:36.880 --> 00:28:42.080]   We are the reserve currency of the world. It's not changing anytime soon. It's not even close.
[00:28:42.080 --> 00:28:48.560]   And we are for better or worse. And I think sax and I don't like it. But we are the world's
[00:28:48.560 --> 00:28:53.360]   policemen. We are a bunch of things. We are the world's center of innovation. We are the world's
[00:28:53.360 --> 00:28:58.480]   center of these great leaps forward in humanity. When we talk about all of these different things,
[00:28:58.480 --> 00:29:03.760]   these aren't coming from random countries. They're coming from the United States, we can debate which
[00:29:03.760 --> 00:29:10.800]   company, but we're never debating the country. So I think that there's a legacy of value creation
[00:29:10.800 --> 00:29:17.680]   and innovation that we've always been at the forefront of, at least since America was founded.
[00:29:17.680 --> 00:29:27.120]   So 1776 to now. I think the reality is that debt to GDP will continue to increase.
[00:29:28.480 --> 00:29:35.200]   I don't think a single politician can practically get elected by offering to cut entitlement spending
[00:29:35.200 --> 00:29:40.160]   to people that have spent their entire lives paying into a system. So as a practical matter,
[00:29:40.160 --> 00:29:46.560]   this thing will go up. And I don't think the economy will stop. I think that economics
[00:29:46.560 --> 00:29:53.280]   are a relative problem where you have to weigh countries against each other. And what that means
[00:29:53.280 --> 00:29:58.640]   is the economic vibrancy, the productivity, the intellect, all of those things, where we have to
[00:29:58.640 --> 00:30:04.080]   compete with El Salvador, we have to compete with Nigeria, we have to compete with India,
[00:30:04.080 --> 00:30:10.080]   we have to compete with Australia. And in that context, there is very little historical
[00:30:10.080 --> 00:30:13.600]   artifact that says that there's a breaking point.
[00:30:13.600 --> 00:30:21.200]   So I just think that if you observe the moment, it's not that what free burger saying is bad.
[00:30:22.400 --> 00:30:28.000]   I'm not exactly sure that it's particularly actionable. And I think the disproportionate
[00:30:28.000 --> 00:30:33.200]   amount of action is actually the opposite, which is to reinflate the money supply,
[00:30:33.200 --> 00:30:40.400]   to reinflate assets, to create artificial prosperity and smear it to many, many, many people.
[00:30:40.400 --> 00:30:47.760]   And I think that the you have to think about how do you want to activate your view? I can believe
[00:30:47.760 --> 00:30:52.080]   whatever I want. But at the end of the day, I don't want to act in a way that's against my
[00:30:52.080 --> 00:30:56.800]   economic best interest, quite honestly. So I believe that winning is measured in dollars and
[00:30:56.800 --> 00:31:02.080]   cents on these things. And from a from that perspective, I don't particularly like it.
[00:31:02.080 --> 00:31:06.400]   I think I'm emotionally more aligned to free bird. But the practical reality is,
[00:31:06.400 --> 00:31:10.000]   I'm on the opposite side, which says the governments will keep spending,
[00:31:10.000 --> 00:31:15.360]   inflation will be here, assets will keep inflating, the M two money supply will keep going up.
[00:31:15.920 --> 00:31:19.680]   And on general, I'm long the United States in short every other country.
[00:31:19.680 --> 00:31:25.680]   tomorrow, doesn't that ultimately lead to just inflation, it initially starts with the inflation
[00:31:25.680 --> 00:31:30.240]   of assets and asset prices, but it ultimately leads to the inflation of goods and services,
[00:31:30.240 --> 00:31:36.960]   which can cripple the economy because then, you know, the middle class can't afford things.
[00:31:36.960 --> 00:31:41.360]   And you have economic slowdown. I mean, that's the historical record of having these kind of
[00:31:41.360 --> 00:31:47.040]   inflationary moments. Yeah, I mean, inflation comes and goes, but the position of the American
[00:31:47.040 --> 00:31:53.600]   US dollar hasn't changed. Again, you have to remember, like a lot of these foreign governments,
[00:31:53.600 --> 00:31:59.120]   187, or whatever the number is, countries outside the United States, rely on the US dollar,
[00:31:59.120 --> 00:32:04.960]   they don't want to own their own currency. Right? And so yeah, you're right, dollars do
[00:32:06.000 --> 00:32:11.760]   get inflated. But that increased purchasing power also actually drives the balance of power back to
[00:32:11.760 --> 00:32:16.160]   the United States. Because all of these other folks all of a sudden find the ability to import
[00:32:16.160 --> 00:32:21.840]   a little bit cheaper, their economies get slightly better, but the US dollar actually still does well.
[00:32:21.840 --> 00:32:27.680]   So there's a complex set of interactions that are all relative. So I think it's very hard to point
[00:32:27.680 --> 00:32:33.120]   to the US middle class and say, Oh, this is why the US breaks, I just don't see very many good
[00:32:33.120 --> 00:32:39.680]   examples in a modern globalist era. And there are examples. And I think Ray Dalio has pointed these
[00:32:39.680 --> 00:32:46.560]   out, when you look all the way in the back, but to use the UK, right in the 15 and 1600s of the
[00:32:46.560 --> 00:32:51.040]   East India Trading Company, when we did not have a global economy or a global reserve currency.
[00:32:51.040 --> 00:32:56.960]   I don't think it's very useful. There's things you can learn, you know, taxation, I think we
[00:32:56.960 --> 00:33:01.360]   can learn about why taxation does kill innovation. You said that before, I agree with that.
[00:33:02.560 --> 00:33:07.280]   But I don't think there's much value in saying because it happened in these moments, it's going
[00:33:07.280 --> 00:33:11.840]   to happen exactly the same way here. And I think what people don't understand is we are in a unitary
[00:33:11.840 --> 00:33:16.000]   singular mono economy that is anchored by the US dollar.
[00:33:16.000 --> 00:33:16.880]   Sacks, any thoughts?
[00:33:16.880 --> 00:33:17.920]   Sacks, do you agree?
[00:33:17.920 --> 00:33:23.120]   I tend to be on the Freeberg Druckenmiller side of this thing. Druckenmiller had a great quote
[00:33:23.120 --> 00:33:26.880]   in this interview he just gave. I don't know, Freeberg, did you mention this last week that
[00:33:26.880 --> 00:33:33.600]   he said that he compared the debt ceiling and fiscal spending to worrying about whether a 30-foot
[00:33:33.600 --> 00:33:38.080]   wave will damage the pier when you know there's a 200-foot tsunami just 10 miles out?
[00:33:38.080 --> 00:33:39.120]   Yeah, I saw that quote.
[00:33:39.120 --> 00:33:43.840]   So what he's saying is like our short-term situation is bad. The long-term situation,
[00:33:43.840 --> 00:33:49.920]   which isn't even that long-term, like 10 years out, is even worse. And I think there's a growing
[00:33:49.920 --> 00:33:55.280]   feeling that our political system is just not up to the challenge of dealing with these problems.
[00:33:56.560 --> 00:33:59.040]   It just seems fundamentally unserious. We never discuss it.
[00:33:59.040 --> 00:34:04.960]   The media doesn't really present us with accurate information. And it has an agenda.
[00:34:04.960 --> 00:34:08.080]   Do you guys want to make a bet? Sacks, you want to make a friendly wager with me?
[00:34:08.080 --> 00:34:08.960]   Sure, what's that?
[00:34:08.960 --> 00:34:14.560]   Okay, I will bet you that debt to GDP gets to 200 before it gets to 50.
[00:34:14.560 --> 00:34:19.600]   And I'll bet you however amount of money you want.
[00:34:19.600 --> 00:34:24.640]   And we can we can do it for our own personal gain or for charity.
[00:34:24.640 --> 00:34:29.680]   That may well be true. But the question is how bad is 200% debt to GDP? I don't think that's
[00:34:29.680 --> 00:34:30.720]   a really bad scenario.
[00:34:30.720 --> 00:34:32.800]   I mean, I really don't think it matters. I think the point is,
[00:34:32.800 --> 00:34:34.640]   you guys have any money left if that happens?
[00:34:34.640 --> 00:34:38.160]   Yeah, yeah, we'll have a lot of money. You'll just have to profit from it. If you think it's
[00:34:38.160 --> 00:34:42.400]   happening, your job is to profit from it. I'll make the same bet with you, Freebrook. I think
[00:34:42.400 --> 00:34:46.960]   it gets to 200 before it gets to 50. Or 250 or 300. You can pick your number.
[00:34:46.960 --> 00:34:49.040]   I think it will too. I'm just like,
[00:34:49.040 --> 00:34:54.160]   Let's do the math on that real quick. So the size of GDP is what about 25 trillion and we're at
[00:34:54.160 --> 00:34:58.960]   about 32 trillion in debt. If we're to have 200% debt to GDP right now, it'd be at 50 trillion of
[00:34:58.960 --> 00:35:04.320]   debt. Now, let's assume that's imputed interest rate at what you would need to finance that 4%.
[00:35:04.320 --> 00:35:07.520]   So I think 4% you have to calculate the duration.
[00:35:07.520 --> 00:35:12.400]   I understand, but just always gonna be baseline. Yeah, let's just baseline. So let's say 4%.
[00:35:12.400 --> 00:35:21.840]   So 4% on 50 trillion is 2 trillion a year. Yep. Which is isn't that like half the budget?
[00:35:22.800 --> 00:35:26.400]   Yeah, more. And that's what that's my point. That's why you have to see taxes go up to over
[00:35:26.400 --> 00:35:30.800]   70%. Because it's the only way you can you got to tax everything in order to fund that.
[00:35:30.800 --> 00:35:36.160]   So US government has collected 2 trillion in fiscal year 2023. Now, I guess we haven't done
[00:35:36.160 --> 00:35:42.800]   a complete year. But let's do 2022. It basically collected 3.7 trillion,
[00:35:42.800 --> 00:35:47.200]   right, you're using more than half of the government's income based on the current tax
[00:35:47.200 --> 00:35:52.960]   rates to fund the interest payments on your debt. That's not even to pay for social services.
[00:35:52.960 --> 00:35:56.240]   That's not even to pay for the defense. It's not even to pay for government services.
[00:35:56.240 --> 00:36:00.800]   That's just more than half of the income, I guess maybe we're just speaking past each other.
[00:36:00.800 --> 00:36:05.440]   I guess you guys are expressing anxiety and concern. And I'm just expressing, here's how
[00:36:05.440 --> 00:36:09.280]   one would make money because it's pretty obvious what's going to happen. We're going to 200. We're
[00:36:09.280 --> 00:36:15.760]   not going to 50. So I just kind of compartment you make money. I think there's a lot of ways
[00:36:15.760 --> 00:36:19.280]   that you could make money. I'm not going to share those on the pot anymore. But
[00:36:19.280 --> 00:36:26.160]   what's the trade there? Stan Druckenmiller said it's the opposite of Stan's trades, actually. So
[00:36:26.160 --> 00:36:32.560]   oh, okay, that's good. That would be an easy way to actually would you go along the dollar and short
[00:36:32.560 --> 00:36:37.360]   gold? No, because those are like antiquated ways of making money where you have to have these
[00:36:37.360 --> 00:36:41.200]   convoluted derivatives agreements with these banks. And I've done these before where you're
[00:36:41.200 --> 00:36:46.480]   levered up to billions of dollars of risk. It proves nothing and I don't sleep well at night.
[00:36:46.480 --> 00:36:53.200]   I think that there are simpler strategies that you can implement. But I think Stan is basically
[00:36:53.200 --> 00:36:59.760]   betting that the US will break and that we will be forced in some way to bring debt to GDP closer to
[00:36:59.760 --> 00:37:07.600]   50 than to 150 or 200. And I would just bet the opposite. And it's not because I want it to happen
[00:37:07.600 --> 00:37:14.720]   or that he's not intellectually or morally right. Also, inflation down again. We've kind of gotten
[00:37:14.720 --> 00:37:18.400]   used to this. But this I thought this was a particularly interesting chart. If you look
[00:37:18.400 --> 00:37:26.000]   at food, goods and energy, all going in the right direction. Services still very expensive.
[00:37:26.000 --> 00:37:36.320]   Any thoughts on the Fed and inflation as we wrap up on sort of where we're at here is another 25
[00:37:36.320 --> 00:37:43.120]   basis points for inflation is very sticky. Yeah, right. Yeah. I mean, with CPI is down to 4.9%.
[00:37:43.120 --> 00:37:48.880]   But core actually was up. It was up. It was up. What? 5.3%? Something like that?
[00:37:48.880 --> 00:37:55.680]   Yeah, of course. So yeah, the Fed is it raised another 25 basis points. What are we up to like
[00:37:55.680 --> 00:38:03.760]   5.25%? I was ready to stop, you know, two hikes ago, because I thought that the economy was
[00:38:03.760 --> 00:38:07.200]   breaking and the banking system was breaking. They're up to now to five and a quarter. You've
[00:38:07.200 --> 00:38:12.800]   got core CPI still sticky. Yes, CPI is coming down. But it looks like, you know, inflation
[00:38:12.800 --> 00:38:19.760]   still a problem. This is not a great setup for economic recovery. And if you believe here's the
[00:38:19.760 --> 00:38:25.840]   problem with accepting the idea that inflation is going to be persistently high is if inflation
[00:38:25.840 --> 00:38:31.600]   remains persistently high, then the Fed won't be able to lower interest rates. So they'll need to
[00:38:31.600 --> 00:38:37.280]   keep them elevated, they might even need to keep raising them. And if that happens, they'll continue
[00:38:37.280 --> 00:38:42.000]   to be incredible stress on the banking system. And more banks are going to break and then eventually
[00:38:42.000 --> 00:38:48.480]   that will create the conditions for the financial crisis. I think the thing you guys have to be open
[00:38:48.480 --> 00:38:53.760]   to is the fact that we've never really tested the ability for the US to borrow durationally beyond
[00:38:53.760 --> 00:38:59.600]   30 years. And again, we talked about what an error it was in judgment for the Treasury not to issue
[00:38:59.600 --> 00:39:05.120]   100 year bonds. But I think if there's any country in the world that can issue 100 year bonds, it's
[00:39:05.120 --> 00:39:12.160]   the United States of America. And I do think that they'll be able to get durational assets that are
[00:39:12.160 --> 00:39:17.760]   that far out on the yield curve. So I, again, am less concerned about the debt wall here, because
[00:39:17.760 --> 00:39:22.320]   I think you'll be able to push maturities out, you'll be able to refi a bunch of short term
[00:39:22.320 --> 00:39:27.680]   obligations into the future. And if you look at where the yield curve is 10 years at three and a
[00:39:27.680 --> 00:39:32.960]   half 340 something. So the thought is that inflation goes down. If you put it out to 100
[00:39:32.960 --> 00:39:38.880]   years, I would be very surprised if 100 year rates if they priced a bond weren't somewhere
[00:39:38.880 --> 00:39:44.400]   sub 1%. So I do think it becomes effectively free money for the United States. And I think it's just
[00:39:44.400 --> 00:39:49.840]   a practical thing they need to explore. By the way, corporates have explored these 50 year bonds
[00:39:49.840 --> 00:39:54.400]   and greater. So I think it's just like it's a matter of mathematics, as you guys have just
[00:39:55.040 --> 00:39:59.840]   illustrated here, that the US has to push out past 30 years. So we'll have 50 year US bonds,
[00:39:59.840 --> 00:40:05.200]   we'll have 100 year US bonds. Again, I'm not here to claim whether it's right or wrong. But I think
[00:40:05.200 --> 00:40:11.600]   the simple way to acknowledge that is just that we are going to reinflate the money supply over
[00:40:11.600 --> 00:40:18.560]   the long term, because it's the only sustainable way that politicians can get elected and reelected.
[00:40:18.560 --> 00:40:22.080]   And I think the best thing to do there is to own risk assets.
[00:40:22.080 --> 00:40:28.240]   Let's move on to the presidential election real quick. What I'm curious, gentlemen,
[00:40:28.240 --> 00:40:34.400]   last week, we had RFK on. Did you get any feedback? The show obviously did really well.
[00:40:34.400 --> 00:40:37.200]   A lot of people watched it, I got a tremendous amount of feedback. People thought
[00:40:37.200 --> 00:40:42.160]   he was a fascinating, interesting character. Some people thought he was a conspiracy theorist.
[00:40:42.160 --> 00:40:46.240]   They pointed out a bunch of different moments during the interview. But what was the general
[00:40:46.240 --> 00:40:46.880]   feedback you got?
[00:40:47.760 --> 00:40:52.960]   My biggest thing was, I think he surprised a lot of people to the upside. A lot of people emailed
[00:40:52.960 --> 00:40:57.360]   me saying they thought one specific thing with him, and we tried to address it, which is,
[00:40:57.360 --> 00:41:03.760]   he's painted as this kind of like conspiracy theorist or anti-vax person by the mainstream
[00:41:03.760 --> 00:41:09.200]   media. And overwhelmingly, so much of the feedback was, wow, this guy is so totally different,
[00:41:09.200 --> 00:41:14.880]   because you gave him a long, long format in order for him to really talk. I thought he was really
[00:41:14.880 --> 00:41:20.960]   engaging, and very interesting and very smart. Sax, did you get feedback on it?
[00:41:20.960 --> 00:41:27.200]   Yeah, I mean, I think he is very authentic. I think he's very principled. I think that he's
[00:41:27.200 --> 00:41:34.960]   a rebel, in a way. I mean, to grow up in the Kennedy family and to be part of all of those
[00:41:34.960 --> 00:41:40.720]   elite circles, whether it's in Hollywood or Harvard, or where do they go for the summer?
[00:41:40.720 --> 00:41:41.680]   Martha's Vineyard.
[00:41:41.680 --> 00:41:42.560]   Martha's Vineyard or...
[00:41:42.560 --> 00:41:43.600]   Kennebunkport.
[00:41:43.600 --> 00:41:48.960]   Kennebunkport, whatever. I mean, you think about all of the elite circles that he grew up in,
[00:41:48.960 --> 00:41:55.120]   right? And for him to deviate from Democratic Party orthodoxy and elite thinking in all these
[00:41:55.120 --> 00:42:02.160]   really significant ways shows that he is, again, very principled, very authentic, and I think a
[00:42:02.160 --> 00:42:07.120]   rebel in a really good way. And he's telling people a lot of things that you just don't hear
[00:42:07.120 --> 00:42:12.160]   on the Democratic side and through the mainstream media. So, I think it's all positive.
[00:42:12.160 --> 00:42:15.360]   Yeah, I got positive feedback on it, Freeberg. The one thing people said was,
[00:42:15.360 --> 00:42:22.320]   some people said, not a lot, but they expected us to push back maybe on him harder or something,
[00:42:22.320 --> 00:42:29.200]   or be harder. I thought we did an interesting job of letting him talk and really taking these
[00:42:29.200 --> 00:42:35.760]   topics to 10 or 20 minutes each. The one people were particularly, I don't know if concerned is
[00:42:35.760 --> 00:42:40.480]   the right word, or puzzled by was that we didn't push back as much on the vaccine stuff, we just
[00:42:40.480 --> 00:42:48.400]   let him talk about it. A week later, what do you think about his vaccine position? And would you
[00:42:48.400 --> 00:42:53.920]   have pushed back more? Or do you regret not pushing back more, Freeberg, as our science guy?
[00:42:53.920 --> 00:43:00.640]   He made a lot of generalized statements or statements that I think take a concern about
[00:43:00.640 --> 00:43:07.680]   one thing and then make them evidence for a whole thing being off. For example, there is a vaccine
[00:43:07.680 --> 00:43:13.040]   that is inefficacious. There was a vaccine that had mercury in it. Therefore, all vaccines are
[00:43:13.040 --> 00:43:21.200]   bad. Oh, we over vaccinate now. Many vaccines today that kids take going into schools have
[00:43:21.200 --> 00:43:27.520]   saved countless lives. And they've had a really critical role in reducing a lot of childborn
[00:43:27.520 --> 00:43:34.560]   illness. It's been, you know, just an incredible advance for humanity, for medicine, etc. I think
[00:43:34.560 --> 00:43:39.440]   he had a number of points he made about the COVID vaccine. And I know he's made these points for
[00:43:39.440 --> 00:43:44.240]   many years, he kind of extrapolates that, you know, it's evidence that vaccines are generally
[00:43:44.240 --> 00:43:49.440]   over prescribed and overused, and pharma companies are just out to make money. And the government is
[00:43:49.440 --> 00:43:53.600]   aligned with pharma companies to just try and make money. I don't think that that is necessarily
[00:43:53.600 --> 00:44:00.400]   true. I think that there are certainly incentives that can drive bad behavior. But I do not think
[00:44:00.400 --> 00:44:05.920]   that wouldn't looking at the evidence, both contra evidence and evidence of safety, and benefit,
[00:44:05.920 --> 00:44:10.960]   that childhood vaccines should be kind of changed in terms of how we're doing things.
[00:44:10.960 --> 00:44:15.280]   Today, there may be some things to change. But generally, I think that they're very beneficial.
[00:44:15.280 --> 00:44:20.640]   So I don't love kind of how he frames these things. And I think that instead of having kind
[00:44:20.640 --> 00:44:24.320]   of a more nuanced conversation about this particular thing, and this particular example,
[00:44:24.320 --> 00:44:26.880]   he blankets things and people get scared. And they're like, Oh, my gosh, you're right,
[00:44:26.880 --> 00:44:31.680]   we should stop doing vaccines for kids. That's very dangerous. That would be very bad for society
[00:44:31.680 --> 00:44:36.800]   be very bad for our kids. And I think that we need to kind of address that in more detail over time.
[00:44:36.800 --> 00:44:40.240]   It's one of these hard things where you have to have kind of a nuanced conversation to give people
[00:44:40.240 --> 00:44:45.120]   all the necessary depth and context to feel better informed to make a better decision. Because, you
[00:44:45.120 --> 00:44:49.440]   know, there's always this kind of gripping fear that if something's off, and I'm getting, you
[00:44:49.440 --> 00:44:53.360]   know, poison, or I'm getting bad medicine, or, you know, people are trying to make money off me,
[00:44:53.360 --> 00:44:58.400]   people immediately react negatively and angrily. And they want to kind of resolve to a blanket
[00:44:58.400 --> 00:45:03.440]   position. I don't think that that's healthy. So I'd love to have a deeper debate on that. But
[00:45:03.440 --> 00:45:07.120]   the reason we didn't go into it is because we didn't we had limited time with him. And we
[00:45:07.120 --> 00:45:10.960]   wanted to take our time kind of giving him a chance to talk about the overview of topics.
[00:45:10.960 --> 00:45:16.000]   And getting his point of view across the set of topics that we generally thought were going to be
[00:45:16.000 --> 00:45:20.480]   relevant in the selection cycle. So that's that was with two hours, we still don't have enough
[00:45:20.480 --> 00:45:24.720]   time, you could talk for two hours about vaccine. Can I address the conspiracy theorist point?
[00:45:24.720 --> 00:45:25.360]   Yeah, sure.
[00:45:25.360 --> 00:45:31.040]   So first of all, that that label conspiracy theorist doesn't pack the punch that it used to,
[00:45:31.040 --> 00:45:35.520]   as you recall, anyone who thought the virus might have come from the Wuhan lab was once called a
[00:45:35.520 --> 00:45:42.320]   conspiracy theorist. If you believed that Fauci and the NIH were funding gain of function research,
[00:45:42.320 --> 00:45:46.800]   that was dubbed a conspiracy theory. If you believe that cloth masks didn't do anything,
[00:45:46.800 --> 00:45:51.280]   that was a conspiracy theory. If you believe that 100 Biden was getting paid off by foreign
[00:45:51.280 --> 00:45:56.880]   governments, that was a conspiracy theory. So this accusation just doesn't really pack the
[00:45:56.880 --> 00:45:57.600]   same punch anymore.
[00:45:57.600 --> 00:46:01.120]   Trump not having a relationship with the Russians in his family meeting with the
[00:46:01.120 --> 00:46:02.800]   Russians multiple times. Yeah.
[00:46:02.800 --> 00:46:04.320]   That's all a conspiracy theory, J.K.
[00:46:04.320 --> 00:46:10.320]   But in any event, my point is, it doesn't pack the same punch. In fact, in some cases,
[00:46:10.320 --> 00:46:13.600]   it's starting to become a badge of honor. So that's one thing. The second thing is when you
[00:46:13.600 --> 00:46:20.080]   listen to him make his arguments, he's not just alleging certain things. He's laying out
[00:46:20.080 --> 00:46:26.000]   his evidence, right? He's connecting dots. He's explaining the causation. And you can disagree
[00:46:26.000 --> 00:46:32.240]   with that. But he is thinking in terms of like causation. And it made me think about something
[00:46:32.240 --> 00:46:36.880]   that Peter Thiel once said about, you know, founders being Asperger's, where he flipped it
[00:46:36.880 --> 00:46:42.400]   on his head and said, what is it about our society that talks founders out of all of their contrarian
[00:46:42.400 --> 00:46:44.560]   ideas, unless they are a little bit Asperger's?
[00:46:44.560 --> 00:46:45.920]   Interesting.
[00:46:45.920 --> 00:46:53.280]   What is it about our political system and our media that talks people out of seeing causation,
[00:46:53.280 --> 00:46:56.240]   unless they are a little bit of a conspiracy theorist? And what I mean by that is,
[00:46:56.240 --> 00:47:02.320]   look at San Francisco, okay? All you have to do is walk down the street and you can see
[00:47:02.320 --> 00:47:07.760]   that things have gone totally off the rails and whatever we've done politically is not working.
[00:47:07.760 --> 00:47:12.240]   And yet the voters in San Francisco just like completely block that out. They don't see any
[00:47:12.720 --> 00:47:18.960]   causation between the way they vote at the city level or at the state level and the policies that
[00:47:18.960 --> 00:47:24.320]   are manifest on our streets. They just don't see any causation there. And you can just play that
[00:47:24.320 --> 00:47:31.200]   movie over and over again. Our elites don't see any causation between the way they ran the country
[00:47:31.200 --> 00:47:37.360]   and the election of Donald Trump, the fact that we hauled out our manufacturing in the rust belt by
[00:47:37.360 --> 00:47:42.320]   throwing open our markets to China, exporting our jobs to China, the way that we squandered all this
[00:47:42.320 --> 00:47:47.280]   money in the forever wars of the Middle East. In regards to what your views are on those policies,
[00:47:47.280 --> 00:47:52.000]   it's pretty obvious to me that they helped cause the rise of Donald Trump. And yet,
[00:47:52.000 --> 00:47:56.960]   you just can't get the media to see any causation between the policies they endorsed
[00:47:56.960 --> 00:48:03.920]   and the inevitable reaction to them. And so, the way I see this is that our political analysis,
[00:48:03.920 --> 00:48:08.320]   certainly our mainstream media, they're just completely bereft of seeing any causation
[00:48:08.320 --> 00:48:16.160]   between policies and the problems in our society. And so, along comes RFK Jr. and he's willing to
[00:48:16.160 --> 00:48:21.760]   actually connect dots. Now, you may not agree with all the dots he's connecting, but maybe it takes,
[00:48:21.760 --> 00:48:25.520]   in the same way, maybe it takes a little bit of an Asperger's founder to stick with their
[00:48:25.520 --> 00:48:30.960]   contrarian idea so they don't get talked out of it. Maybe it takes a guy like Robert F. Kennedy
[00:48:30.960 --> 00:48:37.520]   Jr. not to get talked out of these things that he believes, some of which I think are just obviously
[00:48:37.520 --> 00:48:42.080]   true. I thought one of the salient points he made was just, hey, listen, farmer spends an awful lot
[00:48:42.080 --> 00:48:47.040]   on advertising. The media is dependent on that advertising. They don't seem to criticize it
[00:48:47.040 --> 00:48:52.400]   all that much. Maybe that's something we should look into. Now, I don't think that like, Pfizer
[00:48:52.400 --> 00:48:56.480]   is writing the script for Anderson Cooper, but you can be sure that if Pfizer didn't like something
[00:48:56.480 --> 00:49:01.520]   Anderson Cooper said, there's somebody they call at CNN and say something to and have a
[00:49:01.520 --> 00:49:05.840]   conversation about, you know, setting the record straight, whatever, however you would frame it.
[00:49:05.840 --> 00:49:10.960]   Speaking of CNN, right, and don't leave that point before. I thought it was a really interesting part
[00:49:10.960 --> 00:49:15.520]   of the conversation when he mentioned that he had been friends way back with Roger Ailes.
[00:49:15.520 --> 00:49:20.640]   Yeah, Roger Ailes specifically told him, yes, that they could not post certain or televised
[00:49:20.640 --> 00:49:24.560]   certain content. If it was too critical of pharma companies, because they were the number one
[00:49:24.560 --> 00:49:29.520]   advertiser. Yeah. And should pharma companies even be advertising? So then all of a sudden,
[00:49:29.520 --> 00:49:35.040]   let's say it was a conspiracy theory, or he is like way out there in terms of his belief.
[00:49:35.040 --> 00:49:40.000]   But the fact is, it does bring up the point, should we actually be letting pharma companies
[00:49:40.000 --> 00:49:45.040]   advertise on television or on news programs? Maybe they shouldn't be allowed to be on news.
[00:49:45.040 --> 00:49:48.400]   It's not like it's not like the consumer who watches the ads can go out and buy the
[00:49:48.400 --> 00:49:51.920]   drug as prescribed by a doctor. They can ask their doctor about it. Yeah.
[00:49:52.560 --> 00:49:57.920]   All right. Well, speaking of CNN, there was an absolute train wreck of a presidential town hall
[00:49:57.920 --> 00:50:04.480]   with a moderator named Caitlin Collins. I don't recognize her name. I don't know if she has a
[00:50:04.480 --> 00:50:11.920]   show on CNN, but I saw the clips from it. I couldn't find the full debate. But my Lord, was
[00:50:11.920 --> 00:50:17.440]   this unbelievable. It's unbelievable. It was unbelievable. He got a standing ovation. He
[00:50:17.440 --> 00:50:23.840]   absolutely owned her on every question. All of her questions were about, you know, January 6.
[00:50:23.840 --> 00:50:29.440]   You know, all of them are valid, but none of them were about running the country essentially.
[00:50:29.440 --> 00:50:42.000]   And he was hilarious, at least to this audience. And he is CNN staffers are really upset that they
[00:50:42.000 --> 00:50:47.120]   did this, that they gave him the that they platform Tim, which shows you exactly where
[00:50:47.120 --> 00:50:51.120]   they stand. They're upset. I guess they thought they could own him. And they did.
[00:50:51.120 --> 00:50:55.760]   Did you guys see the part where he was talking about the trial? And he's like,
[00:50:55.760 --> 00:51:01.760]   and she has a cat named vagina. Did you mean it was surreal? And I just thought to myself,
[00:51:01.760 --> 00:51:06.560]   is this going to be the next year and a half, we're going to have these town halls. And then
[00:51:06.560 --> 00:51:10.560]   I thought, oh, he's going to get elected. Is it true that Eugene Carroll has a cat named vagina?
[00:51:10.560 --> 00:51:15.360]   I have no idea. But I mean, it was, that was a pretty vicious section. And then I got the sense
[00:51:15.360 --> 00:51:22.160]   that CNN's management wants this. This is like a ratings bonanza for them. And I think they
[00:51:22.160 --> 00:51:28.080]   want him. Freeberg said it. It's so true. He's so entertaining. I could not stop laughing. I
[00:51:28.080 --> 00:51:34.800]   watched him on CNN. And I was like, man, it's it's like one of your one of your old TV shows
[00:51:34.800 --> 00:51:38.640]   that you don't really remember watching a lot of and it comes back on and you're like, he's so
[00:51:38.640 --> 00:51:42.960]   ridiculous. The things he says, it's true. Because when he first got when he first got elected,
[00:51:42.960 --> 00:51:48.080]   I was so afraid. And then you realize this guy's just an entertainer. Really? He's a terrible
[00:51:48.080 --> 00:51:52.400]   politician. Bill Barr said that. Or Yeah, did you see the bar interview, the bar clip that I shared
[00:51:52.400 --> 00:51:56.240]   is just bananas about Trump. But so he's a showman. And he's a great showman. You know,
[00:51:56.240 --> 00:52:01.280]   he's entertaining. And you realize that he was that's all he's ever really wanted to be was like,
[00:52:01.280 --> 00:52:07.360]   famous and popular and on television. And, and he got all of those things. And he took it to the
[00:52:07.360 --> 00:52:13.280]   to the most infinite level. What Bill Barr said was most insightful that it's chaos when he actually
[00:52:13.280 --> 00:52:18.320]   tries to get things done. He can't get things done. Right. And he'll tell you all the things
[00:52:18.320 --> 00:52:24.080]   that you want to hear that he wants to that you want to see get done. He did this to Peter Thiel
[00:52:24.080 --> 00:52:29.360]   and Peter Thiel spoken about this publicly. So I'm not saying anything out of line here. I don't know
[00:52:29.360 --> 00:52:35.040]   if this is something that's on the record or not. But it was publicly stated that Peter was
[00:52:35.040 --> 00:52:38.720]   disappointed that Trump did not get the things done that he said he was going to get done. And
[00:52:38.720 --> 00:52:44.800]   I think that's really what what he does is he incites, he entertains, he gets people engaged,
[00:52:44.800 --> 00:52:50.000]   he knows what you want to hear, he sells you on it. He cripples the establishment, which everyone
[00:52:50.000 --> 00:52:54.880]   feels treated poorly by that everyone feels held back by that everyone feels has taken something
[00:52:54.880 --> 00:52:58.320]   from them that isn't giving something to them. And then he says, You know what, I'm going to
[00:52:58.320 --> 00:53:03.040]   fix all that for you. And then you get excited by it. And then all of a sudden, he doesn't actually
[00:53:03.040 --> 00:53:06.800]   deliver it. And then four years have gone by, and we forgotten about it. And he's come back in. He's
[00:53:06.800 --> 00:53:12.960]   kind of, you know, titillating again. So I think I think the reality is he's got a real shot at
[00:53:12.960 --> 00:53:16.960]   getting reelected here. Oh, my God. You're right. Here's what I want to do. I'll go around the
[00:53:16.960 --> 00:53:22.640]   horn. I'll start with you, sir. I mean, he said, January 6 was like a beautiful day.
[00:53:22.640 --> 00:53:30.320]   He said that everybody in the Republican Party who said he lost the election is wrong,
[00:53:30.320 --> 00:53:34.800]   and that the election was in fact stolen, like he literally doubled down on every single thing.
[00:53:34.800 --> 00:53:41.920]   Right. So at the end of this, he gets a standing ovation in New Hampshire. So how did CNN pick that
[00:53:41.920 --> 00:53:45.840]   audience? Did they do that on purpose? Did they know that was going to be the outcome? But at the
[00:53:45.840 --> 00:53:51.840]   end of the day, after that, does that increase his chances of winning the Republican nomination
[00:53:51.840 --> 00:53:58.000]   and the presidency in your mind sacks? Yes, of course it does. Why look, well, look, I mean,
[00:53:58.000 --> 00:54:03.360]   Donald Trump showed that he's a force of nature. He's a wrecking ball. He went into
[00:54:03.360 --> 00:54:09.040]   CNN's carefully laid trap where he's not just up against Caitlyn Collins. Make no mistake. She's
[00:54:09.040 --> 00:54:14.480]   got an earpiece in her ear with all of CNN's researchers and hosts and producers. They're
[00:54:14.480 --> 00:54:20.080]   all feeding her every attack behind. Yeah, exactly. And he basically demolished her. He
[00:54:20.080 --> 00:54:26.080]   controlled the interview. He had the crowd laughing when he wanted them to laugh, responding the way
[00:54:26.080 --> 00:54:31.760]   he wanted them to respond. And to the point now where the staffers are like, "Oh my God, what did
[00:54:31.760 --> 00:54:39.200]   we do?" And AOC was basically wringing her hands about how could CNN platform him this way. So
[00:54:39.200 --> 00:54:44.000]   look, he gave no quarter whatsoever. Like you said, he doubled down on everything. He tripled down.
[00:54:44.000 --> 00:54:51.760]   And he showed his ability to kind of bend reality to his will. So all the strengths of Trump. That
[00:54:51.760 --> 00:54:56.080]   being said, I'm sure that Trump and his campaign were delighted with what happened last night,
[00:54:56.080 --> 00:55:01.440]   because I do think it makes him more likely to be the nominee. I think first and foremost,
[00:55:01.440 --> 00:55:07.040]   I think Republicans want a candidate who will fight the media and their fake narratives and
[00:55:07.040 --> 00:55:12.080]   lies. No matter how many lies Trump tells, they think the media is the bigger liar. And they want
[00:55:12.080 --> 00:55:16.960]   someone who is willing to step into the lion's den and take them on. And he is incredibly adroit
[00:55:16.960 --> 00:55:19.440]   and quick on his feet. And DeSantis is imploding.
[00:55:20.160 --> 00:55:21.840]   Well, I wouldn't say that. He hasn't been announced yet.
[00:55:21.840 --> 00:55:25.280]   And Biden is in cognitive decline. So what would any of them do?
[00:55:25.280 --> 00:55:25.600]   Yeah.
[00:55:25.600 --> 00:55:29.360]   Just to be fair, DeSantis clearly is the underdog, okay? But just give the guy a chance,
[00:55:29.360 --> 00:55:34.400]   because we haven't even seen what he can do yet. But there's no question that Trump showed an
[00:55:34.400 --> 00:55:40.640]   adroitness and a willingness to counterpunch and fight back that the Republican base definitely
[00:55:40.640 --> 00:55:46.480]   responds to. Now, so we know that Trump is happy with the debate. I think the other party that is
[00:55:46.480 --> 00:55:52.960]   super happy with this debate is Biden and all of his people. Because as much as that debate helped
[00:55:52.960 --> 00:55:57.680]   Trump in the Republican primary, it did nothing for him in the general, I don't think. Like you
[00:55:57.680 --> 00:56:02.240]   said, Jason, he doubled down on January 6th. The campaign ads write themselves, okay? They're
[00:56:02.240 --> 00:56:06.400]   going to show footage of January 6th with a tear gas and the riots...
[00:56:06.400 --> 00:56:08.400]   Cops being beaten, people being shot.
[00:56:08.400 --> 00:56:11.520]   People pushing down the barricades. And they're going to do a narrative,
[00:56:11.520 --> 00:56:15.600]   a voiceover with Trump saying, "It was a beautiful day. The people there had love in their hearts."
[00:56:15.600 --> 00:56:16.720]   It writes itself.
[00:56:16.720 --> 00:56:21.040]   It writes itself. And then he doubled down really strongly on Roe v. Wade.
[00:56:21.040 --> 00:56:22.000]   That was crazy.
[00:56:22.000 --> 00:56:22.800]   Being overturned.
[00:56:22.800 --> 00:56:25.040]   He's like, "Yeah, that was... I mean, I don't have his quote here."
[00:56:25.040 --> 00:56:29.840]   Which again, I think it doesn't hurt him in the Republican primary, but it will lead to a campaign
[00:56:29.840 --> 00:56:35.520]   attack ad in the general. And there were other issues as well. Okay? So the Biden campaign is
[00:56:35.520 --> 00:56:39.440]   super happy right now, because I think the only Republican he could beat is Trump. I think the
[00:56:39.440 --> 00:56:44.800]   reverse is true for Trump. I think the only Democrat who Trump could beat is Biden. I mean,
[00:56:44.800 --> 00:56:49.920]   they are both two of the most unpopular candidates in America in a general election.
[00:56:49.920 --> 00:56:54.320]   So they love the fact they're going to be facing each other. But you know who doesn't is the
[00:56:54.320 --> 00:56:58.640]   American people. Two-thirds of American people don't want this choice. They say they're already
[00:56:58.640 --> 00:57:02.560]   fatigued by it. And they're only going to get more fatigued by it, because I think for the next,
[00:57:02.560 --> 00:57:06.800]   like you said, 18 months, we're going to have the Trump show with him taking on the media.
[00:57:06.800 --> 00:57:11.840]   And that plays into Biden's hands, because Biden doesn't need to campaign. He'll just let
[00:57:11.840 --> 00:57:16.400]   Trump and the media beat each other up. He'll do a Rose Garden campaign where once a week,
[00:57:16.400 --> 00:57:20.480]   he goes in front of the microphones and responds to whatever Trump's latest outrage is. He doesn't
[00:57:20.480 --> 00:57:25.120]   have the vigor to campaign, and he won't. And then we'll just see where the chips land. I think that
[00:57:25.120 --> 00:57:30.560]   it's quite possible here that after 18 months of Trump and the media beating each other up,
[00:57:30.560 --> 00:57:34.880]   the American people just say, "You know what? This Biden guy is totally senile, but I'm like
[00:57:34.880 --> 00:57:39.440]   so tired of the Trump show. I've got Trump fatigue again. I'm just going to have to go with Biden."
[00:57:40.240 --> 00:57:42.960]   And I think I think this is how Biden gets reelected.
[00:57:42.960 --> 00:57:48.720]   This is a disaster for America. The fact that we are putting Biden, who's in clearly in cognitive
[00:57:48.720 --> 00:57:54.880]   decline, and Trump, as the two candidates, again, the two candidates nobody wants,
[00:57:54.880 --> 00:58:01.200]   makes me think this is just like a complete disaster for America. Can we not find two
[00:58:01.200 --> 00:58:07.600]   other candidates? Chamath, what did you think coming out of his stand up special on CNN?
[00:58:08.160 --> 00:58:10.400]   The Trump town hall stand up special.
[00:58:10.400 --> 00:58:14.960]   I think that I'm more surprised by the fact that the big Republican mega donors have taken
[00:58:14.960 --> 00:58:22.000]   a big step back away from DeSantis. I thought that if the money train on the Republican side
[00:58:22.000 --> 00:58:26.720]   picked DeSantis, that it would be very difficult for Trump to overcome it.
[00:58:26.720 --> 00:58:33.840]   But he's managed to somehow fade that bullet too. He's like Neo in the Matrix. It's like,
[00:58:34.480 --> 00:58:38.000]   you have these guys shooting bullets at this guy, and he just keeps somehow
[00:58:38.000 --> 00:58:41.760]   finding a way to evade them. But this week,
[00:58:41.760 --> 00:58:48.880]   I was just gonna say, well, Schwarzman stepped back. Ken Griffin basically has gone silent. So
[00:58:48.880 --> 00:58:53.600]   there's a lot of guys that came close to him. And this is what I've maintained, which is,
[00:58:53.600 --> 00:58:58.960]   I think DeSantis ages poorly. You know, he's best before you actually spend time with him.
[00:58:58.960 --> 00:59:02.560]   And the more time people seem to spend, and again, this is just evidenced by
[00:59:03.120 --> 00:59:08.080]   these big Republican mega donors. They don't seem to be running towards this guy. They seem to be
[00:59:08.080 --> 00:59:12.480]   at least saying we're gonna hedge your branching. Yeah, they're waiting. Friedberg. And then I'll
[00:59:12.480 --> 00:59:16.400]   go back to you. Hold on. You went for like 10 minutes, the freeberg on then you go,
[00:59:16.400 --> 00:59:21.760]   freeberg. Any thoughts on it? In terms of is this making more electable? Do you think he's gonna win?
[00:59:21.760 --> 00:59:28.800]   Where's your gut tell you the CNN thing? Yeah. Yes. Post CNN. You think you think he's gonna win?
[00:59:28.800 --> 00:59:36.000]   You think he beats Biden? The crazy polling data is that Biden had, you know, 20% of the votes going
[00:59:36.000 --> 00:59:41.200]   to RFK, Jr. Who's like a nobody, no one knows candidate. And he's beating a sitting president
[00:59:41.200 --> 00:59:47.280]   in his own party. So that says a lot about, you know, how much support Biden has. And I think
[00:59:47.280 --> 00:59:52.480]   that Trump is going to be pretty appealing as the anti Biden candidate. I mean, Biden was the anti
[00:59:52.480 --> 00:59:57.840]   Trump candidate, and now Trump's the anti Biden candidate. And right now, he looks like he's
[00:59:57.840 --> 01:00:05.280]   dynamic. And he was a big shift, I think, RFK, Jr. feels a lot like a Trump candidate to me,
[01:00:05.280 --> 01:00:09.040]   too. I mean, you know, some of the positioning and the statements and the way he talks and
[01:00:09.040 --> 01:00:14.960]   being anti establishment, he could also have that appeal. I think there's a non zero chance Biden
[01:00:14.960 --> 01:00:18.480]   actually doesn't run for reelection at this point. Play that out.
[01:00:18.480 --> 01:00:21.360]   I can play that out. That's a really scary scenario. Because I think that's how we get
[01:00:21.360 --> 01:00:26.160]   a president Newsom. Listen, I mean, Newsom is warming up in the bullpen right now. And he's not
[01:00:26.160 --> 01:00:31.600]   just, you know, hanging out back there and you know, spitting Shaw, he's pitching fastballs
[01:00:31.600 --> 01:00:37.200]   very noisily. He's been running TV ads, he's been going to Florida, he's been picking fights,
[01:00:37.200 --> 01:00:42.000]   you know, well outside of his state, he is basically telling the Democratic Party put me in
[01:00:42.000 --> 01:00:48.240]   the game coach. And he's just waiting for the signal to go he he needs to know from Democratic
[01:00:48.240 --> 01:00:53.520]   Party insiders and the establishment that he can go he doesn't want to risk throwing away his career
[01:00:53.520 --> 01:01:00.720]   challenging Biden. But if Biden becomes too weak to run and he gets the signal to go he'll go and
[01:01:00.720 --> 01:01:06.000]   he can raise a lot of money. And I'm not saying sorry, can you can you guys just explain both of
[01:01:06.000 --> 01:01:10.720]   you like how does that actually like what do you guys think happens like there's a press conference
[01:01:10.720 --> 01:01:15.920]   that where Biden says he's retiring? I think he said after careful thought and consideration,
[01:01:15.920 --> 01:01:21.680]   I've made the decision that at my age, I'd like to spend more time with my family and not continue
[01:01:21.680 --> 01:01:26.720]   this hefty responsibility. And I'd love to see someone else take the mantle. And I think that
[01:01:26.720 --> 01:01:32.560]   that will result, you know, from a series of polls that will indicate that he may not have a shot.
[01:01:32.560 --> 01:01:37.360]   If he continues this campaign, I think that I'm not saying that's a certainty. I think that's
[01:01:37.360 --> 01:01:42.640]   a non zero chance right now that that scenario plays out when that does play out. To sexist
[01:01:42.640 --> 01:01:46.880]   point, it's probably not just news them. But there's probably half a dozen and likely a dozen
[01:01:46.880 --> 01:01:50.960]   folks that pop their head up and want to get not just kind of have a real run at the presidency
[01:01:50.960 --> 01:01:56.080]   on the democratic side, but probably end up saying I want to heighten people's awareness of
[01:01:56.080 --> 01:02:00.480]   me and so on. And they all run on that on that ticket. But the DNC might be having a real tough
[01:02:00.480 --> 01:02:05.520]   conversation in the next couple of months about how Biden's polling and whether he really is the
[01:02:05.520 --> 01:02:08.560]   right candidate to have on the ticket. So let's see,
[01:02:08.560 --> 01:02:11.680]   let me give you a historical example. So I mentioned this, I think when
[01:02:11.680 --> 01:02:16.160]   Rfk Jr. was on the pod, but LBJ was the sitting democratic president in 1968. And he went into
[01:02:16.160 --> 01:02:21.200]   the New Hampshire primary. And he won the New Hampshire primary, but not by a big enough margin.
[01:02:21.200 --> 01:02:25.040]   And a few weeks later, he announced he was leaving the race because of health reasons.
[01:02:25.040 --> 01:02:28.400]   But the specific challenger who helped knock him out of New Hampshire was
[01:02:28.400 --> 01:02:32.880]   Gene McCarthy. And then after that happened, Bobby Kennedy got in the race.
[01:02:32.880 --> 01:02:38.960]   So we could have a situation here where it's Bobby Kennedy Jr. is, you know, initially playing the
[01:02:38.960 --> 01:02:46.480]   Gene McCarthy role of being kind of the anti war protest candidate who helps knock Biden out of
[01:02:46.480 --> 01:02:52.160]   the race. And then who knows, I mean, he could become judge Gavin Newsom, they're going to want
[01:02:52.160 --> 01:02:56.240]   to come in into the race at that point. But remember, you know, the thing the thing that
[01:02:56.240 --> 01:03:01.680]   happened in early 1968, that caused LBJ to leave the race is you had the Tet Offensive.
[01:03:01.680 --> 01:03:07.120]   And Cronkite got back from Vietnam saying that war cannot be won. And then at that point,
[01:03:07.120 --> 01:03:11.280]   it was like game over. Well, look, this Ukrainian counteroffensive, Zelensky just announced today
[01:03:11.280 --> 01:03:16.160]   that they need more time. So we've been hearing for months, if not a year,
[01:03:16.160 --> 01:03:19.680]   that you're gonna have a big Ukrainian counteroffensive in the spring,
[01:03:19.680 --> 01:03:23.520]   summer of this year, and Ukraine is going to win this war. And instead, it looks like it's being
[01:03:23.520 --> 01:03:28.800]   destroyed. Ukraine is. So this war is turning into a debacle. I think it could be an even worse
[01:03:28.800 --> 01:03:33.600]   debacle. By the end of the year, the economy has a banking crisis going on, it's turning into a big
[01:03:33.600 --> 01:03:38.720]   fiasco. So I think it's very possible that Biden could announce that it's time for him to step
[01:03:38.720 --> 01:03:43.920]   aside. And you could see the floodgates open for Newsom or J.B. Pritzker or someone like that.
[01:03:43.920 --> 01:03:50.160]   However, let me just say this. I think the odds of Biden leaving the race went down significantly
[01:03:50.160 --> 01:03:54.960]   as a result of last night. Because all of the political people around Biden are saying we
[01:03:54.960 --> 01:03:59.840]   know how to win this thing. We just A/B tested the strategy in the midterms. Remember, we had
[01:03:59.840 --> 01:04:04.400]   three quarters of the American people in the midterms think that we were already in a recession,
[01:04:04.400 --> 01:04:11.120]   and the country was on the wrong track, and the out of power party supposed to gain seats,
[01:04:11.120 --> 01:04:16.080]   and the red wave turned into a puddle. Why? Because Biden's strategy of saying democracy
[01:04:16.080 --> 01:04:20.720]   was on the ballot and running against January 6, it actually worked. I'm not saying I bought that
[01:04:20.720 --> 01:04:26.720]   argument, but enough independents did. Independents ended up breaking for Biden and the Democrats.
[01:04:26.720 --> 01:04:31.520]   Republicans didn't, but independents did. So, independents have bought that argument in the
[01:04:31.520 --> 01:04:37.360]   midterms. And Trump, again, if he's the nominee, they're going to run that same playbook. Now,
[01:04:37.360 --> 01:04:41.920]   it's not guaranteed to work. I think this thing's going to be a nail biter. I think it's going to be
[01:04:41.920 --> 01:04:47.520]   a toss up if it's Biden versus Trump. But I think that Biden's people have to feel very good about
[01:04:47.520 --> 01:04:51.280]   this matchup because they feel like they already know how to run this campaign. This is what he
[01:04:51.280 --> 01:04:57.040]   said about Roe v. Wade. It was such a great victory. I mean, can you imagine how that's
[01:04:57.040 --> 01:05:02.560]   going to play with women voters? They're just going to be like, yeah, no, it was not a great
[01:05:02.560 --> 01:05:07.200]   victory. You took away our right to choose for ourselves. Well, definitely, definitely Democratic
[01:05:07.200 --> 01:05:11.600]   women voters will not like it. But there's a lot of Republican women voters that will support that.
[01:05:11.600 --> 01:05:17.040]   Let me give you this. Let me give you this data of the country. So take a look at this. I don't
[01:05:17.040 --> 01:05:22.000]   think you're right. Jason, I just shared with you kind of the Reuters polling data, the most
[01:05:22.000 --> 01:05:28.560]   recent one. And the number one issue at 24% of likely voters that they care about is the economy
[01:05:28.560 --> 01:05:35.360]   24%. Number two is crime at 14%. Number three is immigration and 9%. Number four is inequality at
[01:05:35.360 --> 01:05:40.480]   6%. And on and on and on. Only when you get down to like number 10, you get to abortion,
[01:05:40.480 --> 01:05:46.800]   which comes in at 3%. 2% of Democrats 1% or, you know, 3% of 4% of Democrats 1% of
[01:05:46.800 --> 01:05:50.000]   Republicans. Yeah, but what is the margin of the election? Well, I don't think that that's
[01:05:50.000 --> 01:05:53.840]   the issue that breaks it. I think there's other things that there's significant differences on
[01:05:53.840 --> 01:05:58.720]   particularly around crime and immigration inequality that are pulling much higher in
[01:05:58.720 --> 01:06:02.880]   terms of importance to likely voters. They drive turnout, like abortion does.
[01:06:02.880 --> 01:06:06.240]   I don't know, I'm just I'm just thinking of these numbers. It's like, you know,
[01:06:06.240 --> 01:06:11.520]   one to 1 to 3% of people saying it matters to them is not that significant. I think these other
[01:06:11.520 --> 01:06:15.520]   topics are going to be very divisive and very different, very polar difference.
[01:06:15.520 --> 01:06:19.920]   What people say in a poll and what people turn out to vote for, like for some people, that is a
[01:06:19.920 --> 01:06:26.320]   major issue. But who knows? I think it's a toss up basically, look, I like I said, I think the
[01:06:26.320 --> 01:06:32.400]   only candidate that Biden could be is Trump. And Biden's probably the only sitting president that
[01:06:32.400 --> 01:06:37.920]   Trump can be. So I mean, again, they're both it poll nationally in the mid 30s. And this is the
[01:06:37.920 --> 01:06:44.880]   choice we have. I got to give sacks is red meat. I saw these Republicans are going on a revenge tour
[01:06:44.880 --> 01:06:52.640]   here to go after the Biden family. They said they would and they have so the oversight House
[01:06:52.640 --> 01:06:58.800]   Oversight Committee reveals a guess. Nine Biden family members received wire transfers from
[01:06:58.800 --> 01:07:06.000]   foreign nationals via shell corporations and they don't have any connections to Biden. We know that
[01:07:06.000 --> 01:07:10.320]   Hunter was securing the bag all over the planet. He's clearly a grifter. I don't think there's any
[01:07:10.320 --> 01:07:16.800]   doubt about that. What's the truth here? And how much evidence do they have? Because this is
[01:07:16.800 --> 01:07:20.080]   obviously a partisan thing, just like there were partisan things on the other side when they were
[01:07:20.080 --> 01:07:25.680]   investigating Trump. So how do you look at this information, this revelation, to keep they're
[01:07:25.680 --> 01:07:32.640]   using this like, Biden cried, crime family meme. Do you think this is actually evidence of something?
[01:07:32.640 --> 01:07:35.840]   Or is it just another rich family with a bunch of LLCs?
[01:07:37.280 --> 01:07:42.080]   Another rich family? Wait, how do they get rich? Good question. The Kennedy's were a rich family.
[01:07:42.080 --> 01:07:47.760]   But the Bidens were not a rich family. So how do they get rich? Their only business is,
[01:07:47.760 --> 01:07:53.600]   they don't have money. They don't know how much money is actually here. And how it's being. What
[01:07:53.600 --> 01:07:57.040]   evidence they have, it's not red meat for me, I just think the media should have done its job
[01:07:57.040 --> 01:08:01.600]   investigating the story properly. And what this investigation has turned up is that there's a
[01:08:01.600 --> 01:08:05.040]   lot of members of the buying family, I think they're up to like 10 or 12 or something, we've
[01:08:05.040 --> 01:08:11.120]   received payments flowing from foreign governments, no one can tell you what any of those people did
[01:08:11.120 --> 01:08:16.000]   in exchange for the money. It does appear to be an influence peddling operation. I don't know
[01:08:16.000 --> 01:08:19.280]   whether that's technically... It appears to be an influence peddling operation. So people were
[01:08:19.280 --> 01:08:24.320]   giving money... Again, the point is that why would you give money to members of the buying family?
[01:08:24.320 --> 01:08:29.920]   It presumably for some sort of access to the person who's been in Washington for 50 years,
[01:08:29.920 --> 01:08:33.760]   who's been a senator... Do they know who gave the money? Is it China? Is it Ukraine? Do they
[01:08:33.760 --> 01:08:38.320]   have that data? Well, I think we know about Burisma, which is basically a Ukrainian...
[01:08:38.320 --> 01:08:39.920]   That went to Hunter. Yeah.
[01:08:39.920 --> 01:08:45.760]   Yeah. And then I think China is another one. Now, I don't know what the quid pro quo is for
[01:08:45.760 --> 01:08:48.080]   that money, but... I wonder if this is like Kraken,
[01:08:48.080 --> 01:08:52.000]   or if this is actually reality, because they seem to be short on actual facts.
[01:08:52.000 --> 01:08:55.280]   I think they got a lot there, but I mean, they're putting out all these reports. But
[01:08:55.280 --> 01:09:02.800]   listen, I think to me, actually the bigger story or the bigger scandal is just more details on the
[01:09:02.800 --> 01:09:08.400]   way that the security state wrote that fake letter, basically calling the Hunter Biden story Russian
[01:09:08.400 --> 01:09:13.600]   disinformation. There's an email now that just came out where Mike Morrell is corresponding
[01:09:13.600 --> 01:09:19.520]   with John Brennan, and Morrell specifically says, "We're creating the letter to give Biden a talking
[01:09:19.520 --> 01:09:22.240]   point in the debate." They're the former CIA directors, right?
[01:09:22.240 --> 01:09:24.560]   Yeah, exactly. Both of them were CIA directors at different
[01:09:24.560 --> 01:09:30.720]   points. So there's no question now that that letter, where 51 security state officials
[01:09:31.440 --> 01:09:35.840]   claimed that the Hunter Biden story is Russian disinformation, that was all basically a political
[01:09:35.840 --> 01:09:40.640]   dirty trick. And dirty tricks happen, but I don't think the CIA should be involved.
[01:09:40.640 --> 01:09:47.120]   That's the thing. I don't think the branches of our government should be involved in helping to get
[01:09:47.120 --> 01:09:48.640]   any candidate elected. But these guys weren't even in government, though, right?
[01:09:48.640 --> 01:09:52.160]   That bothers me. They're former, but... Former, yeah.
[01:09:52.160 --> 01:09:53.760]   They're highly related. They were not acting.
[01:09:53.760 --> 01:09:57.120]   So just so we're clear, it wasn't like the CIA... They continue to have the security
[01:09:57.120 --> 01:10:00.720]   clearances. But it's not the CIA did this. These are former CIA folks.
[01:10:00.720 --> 01:10:02.880]   They actually... Morrell needed the approval of the CIA.
[01:10:02.880 --> 01:10:07.600]   So that was another thing that came out. That's what bothers me more than anything,
[01:10:07.600 --> 01:10:13.600]   is I do not think our permanent government, especially security agencies, should be
[01:10:13.600 --> 01:10:17.920]   involved in partisan politics. They really need to stay out. That is election meddling.
[01:10:17.920 --> 01:10:24.000]   That bothers me. That's a form of corruption that I think is even worse than monetary payments.
[01:10:24.000 --> 01:10:27.440]   Jay Kaut, can you tell us about your trip to the Middle East? What have you been doing there?
[01:10:27.440 --> 01:10:32.000]   So our bestie, Brad Gerstner, was coming here and we were at the poker game a couple of weeks ago,
[01:10:32.000 --> 01:10:35.760]   maybe a month ago, and he said he was going. And I've always wanted to come to UAE,
[01:10:35.760 --> 01:10:42.000]   and I've never seen Dubai or Abu Dhabi. And so I said, "Yeah, I'd love to go with you."
[01:10:42.000 --> 01:10:43.360]   And we did a couple of speaking gigs.
[01:10:43.360 --> 01:10:44.480]   Where are you staying?
[01:10:44.480 --> 01:10:50.480]   So four seasons in Ritz, four seasons in Abu Dhabi, and the Ritz here in Dubai. And
[01:10:50.480 --> 01:10:54.160]   I was just going to do these three speaking gigs, a podcast and...
[01:10:54.160 --> 01:10:55.840]   Isn't IFC in Dubai incredible?
[01:10:57.200 --> 01:10:58.160]   Have you been able to get a chance to walk around?
[01:10:58.160 --> 01:11:02.720]   Pretty amazing, the financial district here. Yeah, I mean, it's all been built in the last
[01:11:02.720 --> 01:11:07.040]   10 years. I would say generally speaking, what I'm super impressed about, and it's not a
[01:11:07.040 --> 01:11:15.200]   fundraising trip. I was just going, but then one of your former employees, Chamath, set me up with
[01:11:15.200 --> 01:11:17.360]   a bunch of meetings because he's like, "Hey, there's a lot of people who want to meet you."
[01:11:17.360 --> 01:11:25.920]   So I'm doing like maybe a dozen meetings or so. And there is a real, this is a very progressive
[01:11:25.920 --> 01:11:32.240]   place, the UAE of all the... And Dubai, obviously, is very progressive. And so it reminds me of
[01:11:32.240 --> 01:11:37.040]   Silicon Valley in the early days where everybody's doing something and it's incredibly
[01:11:37.040 --> 01:11:41.120]   cosmopolitan. There's only 500,000 nationals, but there's 10 million people here.
[01:11:41.120 --> 01:11:44.160]   More Hindi is spoken than any other language in Dubai.
[01:11:44.160 --> 01:11:49.600]   Yeah, I mean, the number of people here from all around the world is bonkers. And then
[01:11:49.600 --> 01:11:54.560]   everybody's working on something, everybody's got a project, and the people are delightful.
[01:11:54.560 --> 01:11:57.280]   Did you go to the French restaurant I told you about in Abu Dhabi?
[01:11:57.280 --> 01:11:58.000]   I did. It was quite nice.
[01:11:58.000 --> 01:11:59.920]   Did you get the ribeye? Did you get the ribeye?
[01:11:59.920 --> 01:12:03.200]   Yeah, we had a family style thing, so I didn't get the ribeye, but it was exceptional. The
[01:12:03.200 --> 01:12:06.720]   food's exceptional. It's just incredibly cosmopolitan. It's like going to New York
[01:12:06.720 --> 01:12:12.000]   or London, and there's a very unique moment in time right now.
[01:12:12.000 --> 01:12:16.960]   Sax, when you go to Abu Dhabi, and you stay at the Four Seasons in the ADGM,
[01:12:16.960 --> 01:12:22.960]   go to this French restaurant and order the ribeye. It is a top five steak I've ever had. Top five.
[01:12:22.960 --> 01:12:24.720]   I've never been there. I've never been to the Middle East.
[01:12:24.720 --> 01:12:31.680]   So delicious. So delicious. So delicious. And in Dubai, do not stay at the Ritz and IFC.
[01:12:31.680 --> 01:12:36.800]   IFC is incredible, but the Ritz sucks. Stay at the Bulgari Hotel. Beautiful. Just beautiful.
[01:12:36.800 --> 01:12:40.880]   But there's a very unique moment in time. I literally came down the elevator at the Four
[01:12:40.880 --> 01:12:46.400]   Seasons, and I met four or five people from Silicon Valley in the lobby. And then I came
[01:12:46.400 --> 01:12:51.680]   out of dinner, and there was a table of Silicon Valley entrepreneurs and venture capitalists.
[01:12:52.320 --> 01:12:57.920]   It is, I mean, it's basically like going to the Rosewood in Abu Dhabi.
[01:12:57.920 --> 01:13:02.560]   But what a statement that is. Like the US is tapped out. We are like broke.
[01:13:02.560 --> 01:13:08.400]   That's I think, basically, the way it's been explained to me is they believe they have 20
[01:13:08.400 --> 01:13:15.200]   years, 30 years to convert the oil economy into a technology capital allocator economy. And so they
[01:13:15.200 --> 01:13:20.000]   want to make evergreen funds to invest. They haven't had a chance to invest in venture capital
[01:13:20.000 --> 01:13:25.040]   because most venture capital, there weren't that many, they were fully allocated, and there was no
[01:13:25.040 --> 01:13:30.000]   opportunity. Now with what's happened in the United States in this pullback, and sort of the cycle
[01:13:30.000 --> 01:13:34.240]   starting over again, I think there's an opportunity for them to invest in some funds and start
[01:13:34.240 --> 01:13:38.640]   relationships. And then, you know, we've had a long talk here about human rights in different
[01:13:38.640 --> 01:13:43.360]   countries. And it's not a monolith over here. I mean, I don't know who needs to hear that exactly.
[01:13:43.360 --> 01:13:46.640]   But there's these countries are very different, very different.
[01:13:46.640 --> 01:13:49.280]   I'm sure they appreciate your lectures on that subject, Jacob.
[01:13:49.920 --> 01:13:52.640]   Actually, you know, what's interesting, we didn't have lectures on it. But we had,
[01:13:52.640 --> 01:13:55.440]   I've had multiple conversations about these issues.
[01:13:55.440 --> 01:13:57.040]   I enjoy your lectures on this pod.
[01:13:57.040 --> 01:14:01.600]   I don't lecture about it. I think these are important issues that people discuss. And
[01:14:01.600 --> 01:14:08.960]   the serious thing is, a number of these countries are majority young people, and they are reforming
[01:14:08.960 --> 01:14:16.960]   very quickly and rights are changing. And so the question is, for, you know, all of us, and
[01:14:17.680 --> 01:14:26.160]   for the world is, do we collaborate and, you know, support as they, you know, become more liberal,
[01:14:26.160 --> 01:14:32.640]   and become more tolerant. And they, you know, become more Western, basically, and young people,
[01:14:32.640 --> 01:14:36.720]   it's very Western here. And the parties going on here are pretty much like the parties I attended
[01:14:36.720 --> 01:14:43.200]   in LA or New York. And so I think actually, we're probably not as at least UAE and a couple of
[01:14:43.200 --> 01:14:48.720]   countries here are not as disparate as like, we one might think, I'm glad you did the trip,
[01:14:48.720 --> 01:14:53.520]   because I'm glad to hear you talking like that, that there isn't an us versus them point of view,
[01:14:53.520 --> 01:14:58.160]   and you know, visiting and seeing the culture and the intention of the people within the culture.
[01:14:58.160 --> 01:15:03.920]   Super important. And I think it's, it's good that you did it. So good to hear. I wanted to share
[01:15:03.920 --> 01:15:07.760]   the video that these guys did. But let's do it next week. I think it's really it's worth seeing
[01:15:07.760 --> 01:15:12.560]   the Valencia one. No, the, the Lord of the Rings one that this guy did, which is amazing.
[01:15:12.560 --> 01:15:17.680]   Wait, what? This is a Lord of the Rings video? No, not with us. Not with us, Jacob.
[01:15:17.680 --> 01:15:19.440]   I don't want to watch it. Okay, why would I want to watch?
[01:15:19.440 --> 01:15:27.120]   Thank you. Exactly. I care. I want to watch the Balenciaga video for the third time.
[01:15:27.120 --> 01:15:32.960]   Did you see that? Yeah, I took an outtake from the guy's video on Lord of the Rings. We'll put
[01:15:32.960 --> 01:15:38.800]   the link in the show notes. But this guy made this incredible AI generated Wes Anderson does Lord of
[01:15:38.800 --> 01:15:44.000]   the Rings. Oh, I did see that. Did you see that? It's amazing. And the clip I'm using today as a
[01:15:44.000 --> 01:15:51.280]   background is is an outtake from the trailer. Did you see it sex? Oh my god, it's so funny.
[01:15:51.280 --> 01:15:57.600]   The guy is incredible. But I mean, the creativity and the potential with AI. It's just so evident.
[01:15:57.600 --> 01:16:02.400]   This guy talks about it on his website and on his Twitter feed. He did it in a couple of days.
[01:16:02.400 --> 01:16:07.120]   He learned a bunch of new AI tools. A lot of generative tools were integrated to make this
[01:16:07.120 --> 01:16:14.480]   possible. It's an amazing two minute piece of art that I think really speaks to the creativity being
[01:16:14.480 --> 01:16:19.120]   unleashed with AI. Again, going back to this point about it not just being about job reduction and
[01:16:19.120 --> 01:16:23.040]   reductionism, but it's really about unleashing new potential that we didn't envision before.
[01:16:23.040 --> 01:16:26.880]   Separately, there'll be another I think we start by this next week, but there's now this kind of
[01:16:26.880 --> 01:16:32.960]   generative video game platform that's being demoed, where you can instruct the video game intentions
[01:16:32.960 --> 01:16:37.360]   and it generates an immersive video game experience for you on the fly, which something we talked
[01:16:37.360 --> 01:16:40.800]   about a couple episodes, probably a couple months ago at this point, somebody on this week in
[01:16:40.800 --> 01:16:46.240]   startups, who showed a video game where he made like, you make 25 objects in the game, it's really
[01:16:46.240 --> 01:16:49.600]   incredible in a certain style. And then you say, I want to make more characters like that. I want
[01:16:49.600 --> 01:16:53.040]   to make more backgrounds like that, like you take a Wes Anderson style, whatever. And it just
[01:16:53.040 --> 01:16:57.920]   generates them for you. And it just keeps generating them for you. So one artist can make a palette
[01:16:57.920 --> 01:17:01.520]   for a game and you say, I want to have a penguin in my game, I want to have a zombie in my game,
[01:17:01.520 --> 01:17:06.160]   I want to have a yeah, exactly. That's exactly right. Yeah. And it just does it. And then
[01:17:06.160 --> 01:17:10.160]   people who are playing the game can say what they want with prompts, and it creates it.
[01:17:10.160 --> 01:17:13.600]   And you can drive a storyline and then you can integrate with other people's storylines. I mean,
[01:17:13.600 --> 01:17:20.000]   it's really powerful. Anyway, I gotta run for David Friedberg, David Sack, and Chema Palihapitiya.
[01:17:20.000 --> 01:17:24.960]   I'm your boy, J Cal. Love you boys. See you all next time on the All In podcast. Bye bye.
[01:17:31.120 --> 01:17:36.080]   Playing out with the greatest hits here on Z100, the Balenciaga video featuring the
[01:17:36.080 --> 01:17:42.560]   All In cast with cameos by Brian Armstrong, Keith Raboy, and Elon Musk. Coming at you.
[01:17:42.560 --> 01:17:45.840]   Balenciaga, Friday night, eight o'clock, hardest ticket in New York.
[01:17:56.640 --> 01:17:59.520]   When you struggle with a problem, that's when you Balenciaga.
[01:17:59.520 --> 01:18:08.400]   Fed mullet, quantitative tightening in the front, quantitative easing in the back.
[01:18:08.400 --> 01:18:22.400]   The greatest source of value and wealth creation in the 22nd century could be driven by terrestrial
[01:18:22.400 --> 01:18:30.160]   nucleosynthesis. Getting dressed is easy, owning the runway is hard.
[01:18:30.160 --> 01:18:37.680]   The big winners of tomorrow will likely be the Minecraft YouTubers of today.
[01:18:37.680 --> 01:18:46.320]   It's easier than ever to confuse popularity and truth.
[01:18:46.320 --> 01:18:52.480]   I think it is possible for ordinary people to choose to be Balenciaga.
[01:18:52.480 --> 01:18:56.720]   The mainstream media is the most H&M it's ever been.
[01:18:56.720 --> 01:19:04.960]   When I left Facebook, I left an enormous amount of equity on the table.
[01:19:04.960 --> 01:19:09.360]   I thought, I don't want to be a slave to money. I want to be a slave to something bigger.
[01:19:09.360 --> 01:19:10.720]   Balenciaga.
[01:19:11.600 --> 01:19:19.200]   You.

