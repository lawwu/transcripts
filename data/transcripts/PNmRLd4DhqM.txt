
[00:00:00.000 --> 00:00:02.580]   (upbeat music)
[00:00:02.580 --> 00:00:06.360]   - Hello, my name is Diego Casabuena
[00:00:06.360 --> 00:00:09.240]   and I am an ML practitioner at Spotify.
[00:00:09.240 --> 00:00:10.960]   Today I'm very excited to be here
[00:00:10.960 --> 00:00:14.040]   and to present to you how Spotify is pushing boundaries
[00:00:14.040 --> 00:00:15.820]   with weights and biases.
[00:00:15.820 --> 00:00:19.220]   Our story begins with a company called Pods.
[00:00:19.220 --> 00:00:21.840]   At Pods, we built the world's first
[00:00:21.840 --> 00:00:24.600]   60 second podcast preview feed.
[00:00:24.600 --> 00:00:27.400]   And to do this, we had to put together
[00:00:27.400 --> 00:00:29.560]   a very complex pipeline.
[00:00:29.560 --> 00:00:33.360]   To build this technology, we listened to RSS feeds,
[00:00:33.360 --> 00:00:37.440]   the internet protocol where podcast content is published to.
[00:00:37.440 --> 00:00:40.760]   We had to download the audios, transcribe them,
[00:00:40.760 --> 00:00:42.560]   and pass them through a complex series
[00:00:42.560 --> 00:00:45.840]   of machine learning models that would output clips.
[00:00:45.840 --> 00:00:47.980]   And those clips would then be recommended
[00:00:47.980 --> 00:00:50.800]   and served to users in this clean app interface
[00:00:50.800 --> 00:00:52.640]   that you see on the right.
[00:00:52.640 --> 00:00:54.960]   Now, this is the work of a relatively small team
[00:00:54.960 --> 00:00:56.660]   of engineers and entrepreneurs
[00:00:56.660 --> 00:00:59.040]   from New York to Silicon Valley.
[00:00:59.040 --> 00:01:01.920]   And this team met in all sorts of ways.
[00:01:01.920 --> 00:01:04.080]   Some people met the conventional ways
[00:01:04.080 --> 00:01:07.760]   of getting their companies acquired into Yahoo
[00:01:07.760 --> 00:01:11.240]   and working on previous companies together in the past.
[00:01:11.240 --> 00:01:14.440]   Others like me joined from Fighting Filipino
[00:01:14.440 --> 00:01:18.200]   Cali Martial Arts, which is kind of cool.
[00:01:18.200 --> 00:01:21.260]   And actually, the team was never together in the same room
[00:01:21.260 --> 00:01:25.080]   since most of this happened during the COVID-19 pandemic.
[00:01:25.080 --> 00:01:27.360]   Our founding team, Doug Imbrucce,
[00:01:27.360 --> 00:01:31.280]   Seyo Jummu, Rasmus Swickson, and Greg Bape
[00:01:31.280 --> 00:01:34.080]   did a fantastic job and a big shout out to them.
[00:01:34.080 --> 00:01:37.160]   I was fortunate enough to become the first employee
[00:01:37.160 --> 00:01:39.140]   at this company and to take on the task
[00:01:39.140 --> 00:01:43.000]   of generating machine-learned clip previews.
[00:01:43.000 --> 00:01:45.800]   As of 2020, we were one of very few companies
[00:01:45.800 --> 00:01:50.040]   applying transformer technology into consumer applications.
[00:01:50.040 --> 00:01:52.040]   In particular, we're trying to build
[00:01:52.040 --> 00:01:53.620]   these podcast highlights.
[00:01:53.620 --> 00:01:56.320]   The podcast highlights are just clips
[00:01:56.320 --> 00:01:59.520]   around one minute long that try to embody the episode
[00:01:59.520 --> 00:02:01.360]   but also be highly engaging.
[00:02:01.360 --> 00:02:03.440]   For copyright reasons, we couldn't
[00:02:03.440 --> 00:02:06.040]   collage multiple pieces of a podcast together.
[00:02:06.040 --> 00:02:08.080]   So it's not exactly like a movie trailer,
[00:02:08.080 --> 00:02:10.720]   but it is made to the same effect.
[00:02:10.720 --> 00:02:12.560]   And there was no easy task.
[00:02:12.560 --> 00:02:15.240]   However, it came out of a product implication,
[00:02:15.240 --> 00:02:18.640]   which is we were displaying transcription on screen, which
[00:02:18.640 --> 00:02:20.600]   meant that we had transcriptions.
[00:02:20.600 --> 00:02:22.240]   And with transcriptions, we started
[00:02:22.240 --> 00:02:24.120]   using transformer models.
[00:02:24.120 --> 00:02:26.920]   We basically took a state-of-the-art technology
[00:02:26.920 --> 00:02:30.120]   and applied it to a different domain.
[00:02:30.120 --> 00:02:33.520]   Now, this company was acquired in 2021
[00:02:33.520 --> 00:02:37.320]   by Spotify in order to accelerate audio discovery
[00:02:37.320 --> 00:02:39.120]   and podcast consumption.
[00:02:39.120 --> 00:02:43.760]   And here we are making podcast clips for the Spotify catalog.
[00:02:43.760 --> 00:02:45.640]   So when we arrived at Spotify, we
[00:02:45.640 --> 00:02:48.720]   were placed inside of a cohort called Listening Experiences,
[00:02:48.720 --> 00:02:50.520]   or LEX for short.
[00:02:50.520 --> 00:02:52.600]   LEX is a group of over 100 people
[00:02:52.600 --> 00:02:54.840]   working inside of personalization
[00:02:54.840 --> 00:02:57.160]   to bring you the best new experiences
[00:02:57.160 --> 00:02:59.160]   across all major content categories,
[00:02:59.160 --> 00:03:02.680]   including music, podcasts, and audio books.
[00:03:02.680 --> 00:03:05.480]   So you may have interacted with some of our products,
[00:03:05.480 --> 00:03:09.760]   including blends, enhance, mixes, such as daily mixes,
[00:03:09.760 --> 00:03:14.040]   and genre mixes, as well as auto mix.
[00:03:14.040 --> 00:03:16.760]   So where does Weights & Biases come into play?
[00:03:16.760 --> 00:03:20.360]   Now, this becomes more of a personal story.
[00:03:20.360 --> 00:03:24.200]   I first interacted with Weights & Biases back in 2018
[00:03:24.200 --> 00:03:27.280]   while working at a research group inside of NYU Center
[00:03:27.280 --> 00:03:30.240]   of Data Science under Professor Rob Fergus.
[00:03:30.240 --> 00:03:33.760]   More specifically, we were researching the pre-training
[00:03:33.760 --> 00:03:37.360]   and fine-tuning of transformer models.
[00:03:37.360 --> 00:03:39.880]   Chat GPT didn't exist, and neither did
[00:03:39.880 --> 00:03:41.880]   all the higher versions of GPT.
[00:03:41.880 --> 00:03:46.160]   It was only GPT-1 and the model called Birth by Google.
[00:03:46.160 --> 00:03:49.000]   And back then, this was a hot topic, too.
[00:03:49.000 --> 00:03:51.240]   We were trying to pre-train and fine-tune
[00:03:51.240 --> 00:03:54.280]   many variants of these models using one of those old school
[00:03:54.280 --> 00:03:58.480]   SLURM systems, where you publish your jobs,
[00:03:58.480 --> 00:04:02.480]   and you wait for it to be done, and you just SSH into machines
[00:04:02.480 --> 00:04:05.240]   to see how things progress.
[00:04:05.240 --> 00:04:07.320]   Essentially, Weights & Biases was a game changer,
[00:04:07.320 --> 00:04:08.560]   because we were training hundreds
[00:04:08.560 --> 00:04:09.800]   of variants of these things.
[00:04:09.800 --> 00:04:12.240]   And we wanted to know that things were OK when we launched
[00:04:12.240 --> 00:04:15.840]   the jobs, and that everything was tracked with no data loss,
[00:04:15.840 --> 00:04:18.080]   and we were able to compare things afterwards.
[00:04:18.080 --> 00:04:20.240]   And that was pretty spectacular.
[00:04:20.240 --> 00:04:23.560]   And so I'm proud to have carried Weights & Biases with me
[00:04:23.560 --> 00:04:25.840]   from academic research through startups,
[00:04:25.840 --> 00:04:29.000]   and now into big companies such as Spotify.
[00:04:29.000 --> 00:04:32.120]   At startups, I continued using Weights & Biases.
[00:04:32.120 --> 00:04:35.240]   I worked on a couple, including one which I co-founded.
[00:04:35.240 --> 00:04:38.760]   And I built modules for facial recognition and also
[00:04:38.760 --> 00:04:40.720]   collaborative recommendation.
[00:04:40.720 --> 00:04:44.080]   Weights & Biases, again, kept all my runs together.
[00:04:44.080 --> 00:04:46.280]   And then I landed at Pods, where we
[00:04:46.280 --> 00:04:50.760]   trained a ton of models, including transformers,
[00:04:50.760 --> 00:04:53.040]   including recommender systems, including
[00:04:53.040 --> 00:04:55.240]   graph neural networks.
[00:04:55.240 --> 00:04:58.880]   The transformer model was still a novelty.
[00:04:58.880 --> 00:05:01.280]   And our challenges at the time were
[00:05:01.280 --> 00:05:06.680]   to take the base recipes, those pre-trained models,
[00:05:06.680 --> 00:05:09.400]   and fine tune them on tasks that were important to us
[00:05:09.400 --> 00:05:11.480]   and not important to academia.
[00:05:11.480 --> 00:05:13.640]   Because again, at the time, there
[00:05:13.640 --> 00:05:17.400]   was a lot of publication around academic tasks and data sets,
[00:05:17.400 --> 00:05:20.240]   but not necessarily the things that we needed to do.
[00:05:20.240 --> 00:05:22.640]   So we had to go out and collect our own data,
[00:05:22.640 --> 00:05:25.800]   figure out whether the data was any good, fine tune models,
[00:05:25.800 --> 00:05:28.720]   and ensure that these fine tunings would actually
[00:05:28.720 --> 00:05:31.160]   transfer the learning from the base models.
[00:05:31.160 --> 00:05:34.000]   And in order to do that, we had to collect a lot of data,
[00:05:34.000 --> 00:05:35.840]   and we had to train a lot of models.
[00:05:35.840 --> 00:05:38.400]   And the only way for us to keep distractible
[00:05:38.400 --> 00:05:41.280]   in such a small team was to use Weights & Biases
[00:05:41.280 --> 00:05:44.960]   to keep our run comparisons and our analysis in one place.
[00:05:44.960 --> 00:05:47.120]   So then we got into Spotify, and we
[00:05:47.120 --> 00:05:49.360]   procured the technology, continued using Weights &
[00:05:49.360 --> 00:05:51.480]   Biases for training runs.
[00:05:51.480 --> 00:05:53.640]   We've additionally started using Weights & Biases
[00:05:53.640 --> 00:05:56.160]   to profile inference when we have new models,
[00:05:56.160 --> 00:05:59.320]   because that saves us time by checking the system
[00:05:59.320 --> 00:06:01.320]   metrics when new models are running
[00:06:01.320 --> 00:06:04.360]   and ensuring that they're ready for production.
[00:06:04.360 --> 00:06:06.160]   Now, Spotify has great tools of its own,
[00:06:06.160 --> 00:06:09.800]   such as Backstage, where you can monitor teams, projects,
[00:06:09.800 --> 00:06:13.680]   workflows, data endpoints, A/B tests, and more.
[00:06:13.680 --> 00:06:16.640]   So you should check that out, too, for production purposes.
[00:06:16.640 --> 00:06:19.680]   For development purposes, it is my personal opinion
[00:06:19.680 --> 00:06:22.000]   that Weights & Biases is the best tool
[00:06:22.000 --> 00:06:23.760]   to keep all your runs together.
[00:06:23.760 --> 00:06:25.920]   And today, Weights & Biases at Spotify
[00:06:25.920 --> 00:06:28.880]   brings value to multiple teams at listening experiences
[00:06:28.880 --> 00:06:31.280]   and the broader Spotify community.
[00:06:31.280 --> 00:06:32.960]   So let's bring it back to the beginning.
[00:06:32.960 --> 00:06:34.320]   How are we pushing the boundaries?
[00:06:34.320 --> 00:06:36.320]   Well, quite literally, we are bringing
[00:06:36.320 --> 00:06:39.920]   the start and end offsets of audio closer together.
[00:06:39.920 --> 00:06:41.720]   I have two case studies for this.
[00:06:41.720 --> 00:06:43.840]   There is Pods, which I already discussed,
[00:06:43.840 --> 00:06:46.640]   where we're using machine learning to extract features
[00:06:46.640 --> 00:06:50.020]   from podcast content, increasing our podcast understanding,
[00:06:50.020 --> 00:06:52.880]   and ultimately generating clips of many sorts
[00:06:52.880 --> 00:06:56.260]   to show to users as previews for podcasts.
[00:06:56.260 --> 00:06:58.440]   So the process is quite involved,
[00:06:58.440 --> 00:07:00.920]   and there's a lot of models in use.
[00:07:00.920 --> 00:07:04.000]   There's a lot of practitioners working on different pieces,
[00:07:04.000 --> 00:07:05.560]   and a way to bring them all together
[00:07:05.560 --> 00:07:09.200]   under the same site is to use Weights & Biases.
[00:07:09.200 --> 00:07:12.780]   Now, there's a second example, Cue Points.
[00:07:12.780 --> 00:07:14.180]   Have you ever heard of Auto-Mix?
[00:07:14.180 --> 00:07:18.520]   It is a great feature that basically
[00:07:18.520 --> 00:07:23.520]   blends music tracks together like a DJ would do it for you.
[00:07:23.520 --> 00:07:25.800]   And we use ML for this, actually.
[00:07:25.800 --> 00:07:29.280]   And in this case, we push boundaries together
[00:07:29.280 --> 00:07:32.400]   by taking a little bit from the start of his track
[00:07:32.400 --> 00:07:34.240]   and a little bit from the end of the track
[00:07:34.240 --> 00:07:35.760]   and feeding in and out from there,
[00:07:35.760 --> 00:07:38.280]   creating a cool effect that sounds
[00:07:38.280 --> 00:07:40.760]   like you're listening to a DJ.
[00:07:40.760 --> 00:07:44.080]   For this, we had to try many combinations of features
[00:07:44.080 --> 00:07:45.640]   and many types of models.
[00:07:45.640 --> 00:07:49.120]   And in order, again, to select the best model,
[00:07:49.120 --> 00:07:50.680]   we had to use Weights & Biases.
[00:07:50.680 --> 00:07:54.120]   And in particular, a cool feature that we used here
[00:07:54.120 --> 00:07:57.400]   was we needed to visualize some of this information.
[00:07:57.400 --> 00:08:01.120]   So we uploaded it as assets into Weights & Biases
[00:08:01.120 --> 00:08:03.000]   for our evaluation sets.
[00:08:03.000 --> 00:08:06.040]   And we were able to just listen to the clips.
[00:08:06.040 --> 00:08:08.960]   And we were able to listen to the tracks.
[00:08:08.960 --> 00:08:10.880]   And it was very successful.
[00:08:10.880 --> 00:08:14.400]   We could then export it and send it for human evaluation.
[00:08:14.400 --> 00:08:16.600]   So that was a great lift.
[00:08:16.600 --> 00:08:19.400]   So there's many other use cases within Spotify
[00:08:19.400 --> 00:08:20.840]   for Weights & Biases.
[00:08:20.840 --> 00:08:24.280]   And there's many teams that started testing out
[00:08:24.280 --> 00:08:28.200]   the technology or the service for their own products.
[00:08:28.200 --> 00:08:33.040]   And that includes the teams behind Enhance, Daily Mixes,
[00:08:33.040 --> 00:08:34.840]   and also Tech Research.
[00:08:34.840 --> 00:08:37.280]   And in Tech Research, we have very smart individuals
[00:08:37.280 --> 00:08:40.520]   working on the state of the art and bringing us
[00:08:40.520 --> 00:08:44.600]   new research such as speech diarization.
[00:08:44.600 --> 00:08:47.000]   So some of us are using Weights & Biases.
[00:08:47.000 --> 00:08:48.720]   Some of us are testing it.
[00:08:48.720 --> 00:08:49.840]   What do we like about it?
[00:08:49.840 --> 00:08:53.080]   We've aggregated the feedback into three main categories.
[00:08:53.080 --> 00:08:55.960]   We believe that Weights & Biases is versatile.
[00:08:55.960 --> 00:08:58.800]   We believe that it helps us aggregate data really well
[00:08:58.800 --> 00:09:02.040]   and that it increases our presentation skills.
[00:09:02.040 --> 00:09:05.720]   The tool is versatile, meaning you can take the same code
[00:09:05.720 --> 00:09:08.960]   and run it across multiple frameworks, infrastructure
[00:09:08.960 --> 00:09:11.240]   setups, and model types.
[00:09:11.240 --> 00:09:15.480]   And so it is very portable and easy to use and easy to learn
[00:09:15.480 --> 00:09:19.000]   for different ML engineers.
[00:09:19.000 --> 00:09:21.280]   Now, the aggregation is super important
[00:09:21.280 --> 00:09:24.840]   because when you have a lot of people using the tool
[00:09:24.840 --> 00:09:27.200]   and training all these sorts of different models
[00:09:27.200 --> 00:09:30.440]   across projects and teams, Weights & Biases
[00:09:30.440 --> 00:09:33.560]   brings it all under one roof so that you
[00:09:33.560 --> 00:09:35.600]   can share all the information of what
[00:09:35.600 --> 00:09:37.720]   one team learns with another.
[00:09:37.720 --> 00:09:40.280]   And that is very important to us.
[00:09:40.280 --> 00:09:44.440]   Additionally, all the tools to sort and filter the data
[00:09:44.440 --> 00:09:49.000]   and compare metrics and generate insights
[00:09:49.000 --> 00:09:51.880]   is really valuable because it saves a lot of engineering
[00:09:51.880 --> 00:09:55.320]   time that you can just do it on the web interface
[00:09:55.320 --> 00:09:57.440]   with just a few clicks.
[00:09:57.440 --> 00:10:00.800]   The filtering, sorting, and other tools
[00:10:00.800 --> 00:10:04.160]   that exist on the platform to help us filter our data,
[00:10:04.160 --> 00:10:06.000]   figure out our best runs, and which
[00:10:06.000 --> 00:10:09.600]   models we should push for human evaluation or to production
[00:10:09.600 --> 00:10:12.880]   are great because it saves a lot of engineering time.
[00:10:12.880 --> 00:10:15.400]   And more recently, we've been trying out the hyperparameter
[00:10:15.400 --> 00:10:16.240]   tuning.
[00:10:16.240 --> 00:10:18.700]   And that is great because that way we
[00:10:18.700 --> 00:10:21.240]   can send out batches of training runs
[00:10:21.240 --> 00:10:24.040]   and see summarized results afterwards
[00:10:24.040 --> 00:10:26.680]   with no additional effort.
[00:10:26.680 --> 00:10:28.760]   And finally, there's presentation.
[00:10:28.760 --> 00:10:32.080]   So for presentation, there's a number
[00:10:32.080 --> 00:10:36.320]   of visualizations that are actually important to us
[00:10:36.320 --> 00:10:38.000]   as we train our models.
[00:10:38.000 --> 00:10:40.080]   Some models have specifics.
[00:10:40.080 --> 00:10:43.000]   Like if you use classical machine learning
[00:10:43.000 --> 00:10:46.600]   and you're training a forest or a tree-based model
[00:10:46.600 --> 00:10:49.120]   like a random forest, there's actually
[00:10:49.120 --> 00:10:52.640]   specific tools such as feature importance plots
[00:10:52.640 --> 00:10:55.280]   that one can use to decide whether the features that
[00:10:55.280 --> 00:10:57.960]   you're using are actually important or not.
[00:10:57.960 --> 00:11:00.800]   Weights and Biases has one line of plots
[00:11:00.800 --> 00:11:02.880]   that you can basically instantiate
[00:11:02.880 --> 00:11:04.360]   with one line of code.
[00:11:04.360 --> 00:11:06.400]   And that just shows on your dashboard
[00:11:06.400 --> 00:11:08.080]   every time you train the same model.
[00:11:08.080 --> 00:11:09.740]   And then when you train multiple models,
[00:11:09.740 --> 00:11:12.740]   it compares them such that you know
[00:11:12.740 --> 00:11:14.880]   how the feature importance is, for example,
[00:11:14.880 --> 00:11:17.560]   changed across different runs.
[00:11:17.560 --> 00:11:19.760]   And so that is pretty cool because, again, you get a lot
[00:11:19.760 --> 00:11:22.280]   for free for a lot of code.
[00:11:22.280 --> 00:11:25.120]   And so that is important to us.
[00:11:25.120 --> 00:11:28.880]   Also, the fact that once you have all the runs logged
[00:11:28.880 --> 00:11:32.320]   and once you have all these charts,
[00:11:32.320 --> 00:11:36.640]   you don't have to export them or save them somewhere
[00:11:36.640 --> 00:11:38.800]   or bringing assets from outside.
[00:11:38.800 --> 00:11:40.560]   All your information is in one place.
[00:11:40.560 --> 00:11:43.440]   And so you can literally just drag and drop it
[00:11:43.440 --> 00:11:48.040]   into these reports where you then add some text
[00:11:48.040 --> 00:11:50.360]   and send them to your leadership.
[00:11:50.360 --> 00:11:52.480]   You're to share it for your team.
[00:11:52.480 --> 00:11:56.640]   It's great for presentations and, again,
[00:11:56.640 --> 00:11:57.760]   for information share.
[00:11:57.760 --> 00:11:59.920]   So we also really like that feature.
[00:11:59.920 --> 00:12:02.000]   And then finally, I would like to compliment
[00:12:02.000 --> 00:12:08.560]   the technical support, which has been incredibly helpful to us,
[00:12:08.560 --> 00:12:11.120]   very prompt and very responsive.
[00:12:11.120 --> 00:12:13.360]   And they've solved many of the issues
[00:12:13.360 --> 00:12:17.400]   that we've had as we were integrating Weights
[00:12:17.400 --> 00:12:19.680]   and Biases into Spotify.
[00:12:19.680 --> 00:12:22.440]   And they have even acted on some of the feedback
[00:12:22.440 --> 00:12:25.280]   that we have given them to improve the app.
[00:12:25.280 --> 00:12:27.200]   So we really appreciate that.
[00:12:27.200 --> 00:12:32.000]   Now, that's the story of how we found Weights and Biases,
[00:12:32.000 --> 00:12:34.680]   how it came to Spotify, how people are using it,
[00:12:34.680 --> 00:12:36.200]   why they like it.
[00:12:36.200 --> 00:12:38.000]   And thank you so much for listening.
[00:12:38.000 --> 00:12:41.040]   [MUSIC PLAYING]
[00:12:41.040 --> 00:12:43.620]   (upbeat music)
[00:12:43.620 --> 00:12:46.700]   (instrumental music)

