
[00:00:00.040 --> 00:00:09.480]   Winds
[00:00:09.480 --> 00:00:27.540]   all, I,
[00:00:28.620 --> 00:00:57.480]   find
[00:00:57.480 --> 00:00:58.380]  iam, ',,,ISS B I with the-T. moins round, en,rek, nag,,,,,,,,,,, as just about the person. No I'm deadlines Le's
[00:00:58.480 --> 00:01:08.900]  ï¿½
[00:01:08.900 --> 00:01:27.360]   stained the is all
[00:01:27.420 --> 00:01:35.040]  otta
[00:01:35.040 --> 00:01:37.700]   9,,,,
[00:01:56.320 --> 00:02:04.320]   in
[00:02:04.320 --> 00:02:06.720]   do. "
[00:02:06.720 --> 00:02:10.120]  å­¦, ,,,,,
[00:02:10.120 --> 00:02:23.000]   tempsowych " " .e " nevernia ê¸ˆ pocket density listen them from give him the jump consider the y me, and, the, und, you, what, you, you, or, we, or, you, you, or, and, all, sweats a,Ð±, cricht,Å¼enie, implied, glowing's, Eastern, ××, wouldn't, weigh, end, Bluetooth, achieve an, raz, cuent, Ð¡. Xuan.å—,. Ä‘Ã¢u, en,. Alles,. is,.è¦–,......,..., Library,...,.,..,....,.,..,.,be, equals;. isn't. or "T.Guest.ï¿½. only--G. Young ê° infiniteE
[00:02:23.080 --> 00:02:28.720]   compresses. Do you think there is an objective reality, or is everything just useful models?
[00:02:28.720 --> 00:02:35.680]   Like underneath it all, is there an actual thing that we're constructing models for?
[00:02:35.680 --> 00:02:41.200]   I don't know. I was hoping you would know. I don't think it matters.
[00:02:41.200 --> 00:02:46.160]   I mean this kind of connects to the models of constructive reality with machine learning.
[00:02:46.160 --> 00:02:51.040]   Right? Sure. Like, is it just nice to have useful
[00:02:51.040 --> 00:02:52.960]   approximations of the world's, um,
[00:02:52.960 --> 00:03:22.980]  ,
[00:03:22.980 --> 00:03:22.980]   Yeah.
[00:03:22.980 --> 00:03:22.980]   Yeah.
[00:03:22.980 --> 00:03:22.980]   Yeah.
[00:03:22.980 --> 00:03:22.980]   Yeah.
[00:03:23.020 --> 00:03:32.660]   just
[00:03:32.660 --> 00:03:42.380]   beneath in,,,, provide But It I seems Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾
[00:03:52.280 --> 00:04:21.540]   I am declining and the model is growing. What is the metric by which you measure better or worse in that if you're competing with yourself? Maybe you can just play a game where you have the George Haas answer and the George Haas model answer and ask which people prefer. People close to you or strangers? Either one. It will hurt more when it's people close to me, but both will be overtaken by the George Haas model. It'd be quite painful, right? Loved ones, family members would rather have the model over
[00:04:21.560 --> 00:04:50.820]   and you. Or like significant others. Or rather sext with the large language model version of you. Especially when it's fine-tuned to their preferences. Yeah. Well, that's what we're doing in a relationship, right? We're just fine-tuning ourselves, but we're inefficient with it because we're selfish and greedy and so on. Our language models can fine-tune more efficiently, more selflessly.
[00:04:50.860 --> 00:05:00.880]   Ð·Ð½Ð°ÐºÐ¾Ð¼
[00:05:00.880 --> 00:05:19.960]   circuit. I doå®ˆ
[00:05:20.720 --> 00:05:30.440]   conducted
[00:05:30.440 --> 00:05:39.500]   may menu it
[00:05:39.500 --> 00:05:47.800]   we I I End was. I. I. I, and, and, and, and, and, and, and, let, and,Ð°ÑÑ‚, sanaj,ï¿½, equå¤‰, er,grund, secret, suffers,Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ, money, recognize, cookies, indicator, student, X. I. Lily,. heard, way. un ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ...e ... dent I ...imetema Some baì˜ˆ...ed couldn recursos recognise started motivating spend ich shortcuts lawnssER " SS but play got only relacion gall rÃ©al eså›  contain aacre chicken person does
[00:05:47.900 --> 00:06:15.080]   or jealous or all this kind of stuff. And of course it can and it will. But all that difficulty at that point is artificial. There's no more real difficulty. Okay, what's the difference between real and artificial? Artificial difficulty is a difficulty that's constructed or could be turned off with a knob. Real difficulty is like you're in the woods and you've got to survive. So if something cannot be turned off with a knob, it's real?
[00:06:15.080 --> 00:06:15.080]   Yeah, I think so.
[00:06:15.080 --> 00:06:44.280]  , or I mean, you can't get out of this by smashing the knob with a hammer.
[00:06:44.280 --> 00:06:44.480]   I mean, maybe you kind of can.
[00:06:44.480 --> 00:06:44.780]   You know, I ...
[00:06:44.780 --> 00:06:45.080]   into the wild when, you know, Alexander Supertramp, he wants to explore something that's never been explored before. But it's the '90s, everything's been explored. So if he's like, well, I'm just not going to bring a map.
[00:06:45.080 --> 00:06:45.080]   Yeah. I mean, no, you're not exploring. You should have brought a map, dude. You died. There was a bridge a mile from where you were camping. How does that connect to the message?
[00:06:45.120 --> 00:06:48.920]   design
[00:06:48.920 --> 00:06:57.020]   thank reduces
[00:06:57.020 --> 00:07:04.340]   worked et it is thank
[00:07:13.760 --> 00:07:42.400]   I don't think there's a clear line there. I think it's all kind of just fuzzy. I don't know. I mean, I don't think I'm conscious. I don't think I'm anything. I think I'm just a computer program.
[00:07:42.400 --> 00:07:42.400]   I think I'm just a computer program.
[00:07:42.420 --> 00:08:11.060]   So it's all computation. Everything running in your head is just a computation. Everything running in the universe is computation, I think. I believe the extended church time thesis.
[00:08:11.060 --> 00:08:11.060]   Yeah, but there seems to be an embodiment to your particular computation. Like there's a consistency. Well, yeah, but I mean, models have consistency too. Models that have been RLHF'd will continually say, you know, like, well, how do I murder ethnic minorities? Oh, well, I can't let them know that I'm a Christian.
[00:08:11.100 --> 00:08:21.160]   find
[00:08:21.160 --> 00:08:39.200]  , club, hold the kind with
[00:08:39.720 --> 00:08:50.020]  ind
[00:08:50.020 --> 00:08:58.640]   in, be,
[00:09:08.780 --> 00:09:37.800]   ìžŠì€.
[00:09:37.800 --> 00:09:37.800]   I think that's a great question.
[00:09:37.800 --> 00:09:37.800]   I think that's a great question.
[00:09:37.800 --> 00:09:37.800]   I think that's a great question.
[00:09:37.800 --> 00:09:37.800]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:09:37.800 --> 00:09:37.800]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:09:37.800 --> 00:09:37.800]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:09:37.800 --> 00:09:37.800]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:09:37.840 --> 00:10:06.940]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:10:06.940 --> 00:10:07.000]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:10:07.000 --> 00:10:07.040]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:10:07.040 --> 00:10:07.060]   So to ask the question about why, I don't know, it's just some quirk of evolution, right? I don't think there's anything particularly special about where I ended up.
[00:10:07.080 --> 00:10:13.280]   I have a SoundCloud I wrap and I tried to get CapturePT to help me write raps.
[00:10:13.280 --> 00:10:16.240]   And the raps that it wrote sounded like YouTube comment raps.
[00:10:16.240 --> 00:10:18.340]   You know, you can go on any rap beat online
[00:10:18.340 --> 00:10:20.380]   and you can see what people put in the comments.
[00:10:20.380 --> 00:10:23.880]   And it's the most mid quality rap you can find.
[00:10:23.880 --> 00:10:24.860]   - Is mid good or bad?
[00:10:24.860 --> 00:10:25.700]   - Mid is bad.
[00:10:25.700 --> 00:10:26.540]   - Mid is bad.
[00:10:26.540 --> 00:10:27.840]   - Like mid, it's like...
[00:10:27.840 --> 00:10:29.920]   - Every time I talk to you, I learn new words.
[00:10:29.920 --> 00:10:30.760]   - Mid.
[00:10:30.760 --> 00:10:31.600]   - Mid, yeah.
[00:10:31.600 --> 00:10:36.160]   - I was like, is it like basic?
[00:10:36.160 --> 00:10:37.000]   Is that what mid means?
[00:10:37.940 --> 00:11:07.040]   - Yeah.
[00:11:07.040 --> 00:11:07.040]   I don't know.
[00:11:07.040 --> 00:11:07.040]   It's like middle of the curve, right?
[00:11:07.040 --> 00:11:07.040]   So there's like there's like I like see that intelligence curve.
[00:11:07.040 --> 00:11:07.040]   And you have like the dumb guy, the smart guy and then the mid guy, actually being the mid guy is the worst. The smart guy is like I put all my money and Bitcoin the mid guy is like you can't put money in Bitcoin it's not real money. And all of it is a genius meme means the humor the idea.
[00:11:07.040 --> 00:11:07.040]  . The absurdity encapsulated a single image encapsulated a single image,
[00:11:07.060 --> 00:11:12.080]   and it just kind of propagates virally between all of our brains.
[00:11:12.080 --> 00:11:13.080]   and it just kind of propagates virally between all of our brains.
[00:11:13.080 --> 00:11:14.080]   I didn't get much sleep last night.
[00:11:14.080 --> 00:11:15.080]   I didn't get much sleep last night.
[00:11:15.080 --> 00:11:16.080]   So I'm very, I sound like I'm high.
[00:11:16.080 --> 00:11:17.080]   So I'm very, I sound like I'm high.
[00:11:17.080 --> 00:11:18.080]   I swear I'm not.
[00:11:18.080 --> 00:11:19.080]   I swear I'm not.
[00:11:19.080 --> 00:11:20.080]   Do you think we have ideas or ideas have us?
[00:11:20.080 --> 00:11:21.080]   Do you think we have ideas or ideas have us?
[00:11:21.080 --> 00:11:22.080]   Do you think we have ideas or ideas have us?
[00:11:22.080 --> 00:11:23.080]   I think that we're gonna get super scary memes
[00:11:23.080 --> 00:11:24.080]   I think that we're gonna get super scary memes
[00:11:24.080 --> 00:11:25.080]   I think that we're gonna get super scary memes
[00:11:25.080 --> 00:11:26.080]   once the AIs actually are super human.
[00:11:26.080 --> 00:11:27.080]   once the AIs actually are super human.
[00:11:27.080 --> 00:11:28.080]   once the AIs actually are super human.
[00:11:28.100 --> 00:11:50.120]   Ooh, you think AI will generate memes?
[00:11:50.120 --> 00:11:51.120]   Ooh, you think AI will generate memes?
[00:11:51.120 --> 00:11:52.120]   Of course.
[00:11:52.120 --> 00:11:53.120]   Do you think it'll make humans laugh?
[00:11:53.120 --> 00:11:54.120]   Of course.
[00:11:54.120 --> 00:11:55.120]   Do you think it'll make humans laugh?
[00:11:55.120 --> 00:11:56.120]   I think it's worse than that.
[00:11:56.120 --> 00:11:57.120]   So Infinite Jest, it's introduced in the first 50 pages,
[00:11:57.120 --> 00:11:58.120]   So Infinite Jest, it's introduced in the first 50 pages,
[00:11:58.120 --> 00:11:58.120]   So Infinite Jest, it's introduced in the first 50 pages,
[00:11:58.120 --> 00:11:58.120]   So Infinite Jest, it's introduced in the first 50 pages,
[00:11:58.120 --> 00:11:58.120]   Infinite Jest, it's introduced in the first 50 pages,
[00:11:58.260 --> 00:12:28.160]   Infinite Jest, it's introduced in the first 50 pages,
[00:12:28.160 --> 00:12:28.160]   So Infinite Jest, it's introduced in the first 50 pages,
[00:12:28.160 --> 00:12:28.160]   So Infinite Jest, it's introduced in the first 50 pages,
[00:12:28.160 --> 00:12:28.160]   So Infinite Jest, it's introduced in the first 50 pages,
[00:12:29.100 --> 00:12:58.200]   so Infinite Jest, it's introduced in the first 50 pages,
[00:12:58.200 --> 00:12:58.200]   so Infinite Jest, it's introduced in the first 50 pages,
[00:12:58.200 --> 00:12:58.200]   so Infinite Jest, it's introduced in the first 50 pages,
[00:12:58.240 --> 00:13:09.020]  ‘
[00:13:09.020 --> 00:13:26.660]   at, Whis H S N "uard, I, I, dÃ©couvrir,,,,,,,ung . g
[00:13:27.040 --> 00:13:37.100]   the
[00:13:37.100 --> 00:13:37.840]  å€‹ enf the is,,,,
[00:15:19.920 --> 00:15:34.180]  ?
[00:16:18.260 --> 00:16:19.280]   mhm.
[00:16:19.280 --> 00:16:19.280]   Yeah.
[00:16:19.280 --> 00:16:23.260]   I mean, diversity in humanity is--.
[00:16:23.260 --> 00:16:24.020]   With due respect.
[00:16:24.020 --> 00:16:28.260]   I wish I was more weird. No, like, I'm kind of--look, I'm drinking Smart Water, man. It's like a Coca-Cola product, right?
[00:16:28.260 --> 00:16:30.260]   You went corporate, George Hodges.
[00:16:30.260 --> 00:16:38.260]   I went corporate. No, the amount of diversity in humanity I think is decreasing. Just like all the other biodiversity on the planet.
[00:16:38.260 --> 00:16:39.260]   Oh, boy. Yeah.
[00:16:39.260 --> 00:16:40.260]   Right?
[00:16:40.260 --> 00:16:41.260]   And social media's not helping, huh?
[00:16:41.260 --> 00:16:43.260]   Go eat McDonald's in China.
[00:16:43.260 --> 00:16:44.260]   Yeah.
[00:16:44.260 --> 00:16:46.260]   You know, it's a little bit of a--.
[00:16:46.260 --> 00:16:47.260]   It's a little bit--.
[00:16:47.260 --> 00:16:48.260]   It's a little bit of a--.
[00:16:48.260 --> 00:16:48.280]   ----.
[00:16:48.320 --> 00:16:49.320]  --.
[00:16:49.320 --> 00:16:52.320]   Yeah. No, it's the interconnectedness that's doing it.
[00:16:52.320 --> 00:17:05.320]   Oh, that's interesting. So everybody starts relying on the connectivity of the internet, and over time that reduces the diversity, the intellectual diversity, and then that gets everybody into a funnel. There's still going to be a guy in Texas.
[00:17:05.320 --> 00:17:06.320]   There is. And yeah--.
[00:17:06.320 --> 00:17:07.320]   And a bunker.
[00:17:07.320 --> 00:17:18.320]   To be fair, do I think AI kills us all? I think AI kills everything we call, like, society today. I do not think it actually kills us all.
[00:17:18.320 --> 00:17:18.320]   Mm-hmm.
[00:17:18.860 --> 00:17:48.360]   I think it actually kills the human species. I think that's actually incredibly hard to do.
[00:17:48.360 --> 00:17:48.360]   Yeah, but society, like, if we start over, that's tricky. Most of us don't know how to do most things.
[00:17:48.360 --> 00:17:48.360]   Yeah, but some of us do. And they'll be okay, and they'll rebuild after the great AI.
[00:17:48.360 --> 00:17:48.360]   What's rebuilding look like? How much do we lose? What has human civilization done that's interesting? Combustion engine, electricity. So, you know, I think that's a little bit of a--.
[00:17:48.360 --> 00:17:48.360]   Yeah, but some of us don't know how to do most things. And they'll be okay, and they'll rebuild after the great AI.
[00:17:48.380 --> 00:17:50.400]   Power and energy. That's interesting. Like, how to harness energy.
[00:17:50.400 --> 00:17:51.400]   Well, well, well, well, well, they're going to be religiously against that.
[00:17:51.400 --> 00:17:52.400]   Are they going to get back to, like, fire?
[00:17:52.400 --> 00:17:53.400]   Sure. I mean, they'll be--. It'll be like, you know, some kind of Amish-looking kind of thing, I think.
[00:17:53.400 --> 00:17:54.400]   I think they're going to have very strong taboos against technology.
[00:17:54.400 --> 00:17:55.400]   Like, technology is almost like a new religion. Technology is the devil.
[00:17:55.400 --> 00:17:56.400]   Yeah.
[00:17:56.400 --> 00:17:57.400]   And nature is also the devil.
[00:17:57.400 --> 00:17:58.400]   Yeah.
[00:17:58.400 --> 00:18:13.400]   And, you know, I think people are going to get back to, like, you know, the world.
[00:18:13.400 --> 00:18:14.400]   Yeah.
[00:18:14.400 --> 00:18:15.400]   Yeah.
[00:18:15.400 --> 00:18:16.400]   You know, I think that's going to get back to, like, you know, like, some of a new religion.
[00:18:16.940 --> 00:18:45.440]  , like, a new religion.
[00:18:45.440 --> 00:18:46.440]   Yeah.
[00:18:46.440 --> 00:18:46.440]   And, uh, nature is God.
[00:18:46.440 --> 00:18:46.440]   Sure.
[00:18:46.440 --> 00:18:46.440]   But can you really get away from AI if it destroyed 99% of the human species? Isn't it--somehow have a hold, like, a stronghold?
[00:18:46.440 --> 00:18:46.440]   What's interesting about everything we build, I think we're going to build superintelligence before we build any sort of robustness in the AI. We cannot build an AI that is capable of going out into nature and surviving like a, um, like a bird.
[00:18:46.440 --> 00:18:46.440]   And I think we're going to get away from the AI, but we're not going to get away from the AI. And we're not going to get away from the AI because we're not capable of going out into nature and surviving like, um, like, a bird.
[00:18:46.460 --> 00:18:48.480]   Right? A bird is an incredibly robust organism. We've built nothing like this. We haven't built a machine that's capable of reproducing.
[00:18:48.480 --> 00:18:49.480]   Right? A bird is an incredibly robust organism. We've built nothing like this. We haven't built a machine that's capable of reproducing.
[00:18:49.480 --> 00:18:50.480]   Right? A bird is an incredibly robust organism. We've built nothing like this. We haven't built a machine that's capable of reproducing.
[00:18:50.480 --> 00:18:51.480]   Yes. But there is, uh, you know, I work with Lego robots a lot now. I have a bunch of them. Uh, they're mobile.
[00:18:51.480 --> 00:18:52.480]   Yes. But there is, uh, you know, I work with Lego robots a lot now. I have a bunch of them. Uh, they're mobile.
[00:18:52.480 --> 00:18:53.480]   Mm-hmm.
[00:18:53.480 --> 00:18:54.480]   Mm-hmm.
[00:18:54.480 --> 00:18:55.480]   They can't reproduce, but all they need is--I guess you're saying they can't repair themselves.
[00:19:09.520 --> 00:19:39.500]   Bar
[00:22:09.620 --> 00:22:32.320]  . Okay, we can build that. We know how to do that as humanity. We can probably put all the precursors that build all the machines and the fabs also in the machine. So first off, machines are going to be absolutely massive. I mean, we almost have a, like, think of the size of the thing required to reproduce a machine today, right? Like, is our civilization capable of reproduction? Can we reproduce our civilization on Mars?
[00:22:32.320 --> 00:22:39.600]   If we were to construct a machine that is made up of humans, like a company that can reproduce
[00:23:29.220 --> 00:23:32.760]   Yeah, okay, fine, but they're not going to be making five nanometer chips.
[00:23:32.760 --> 00:23:37.400]   Over time they will. I think you're being, like, we have to expand our conception of time here, going back to the original timescale. I mean, over, across maybe a hundred generations, we're back to making chips. No? If you seed the colony correctly, you're going to be able to make chips.
[00:23:37.400 --> 00:24:07.420]  . Well, that is a thing that humans do. They come up, they construct a devil, a good thing and a bad thing, and they really stick by that, and they murder each other over that. There's always one asshole in the room who murders everybody. And he's going to be the next one.
[00:24:07.460 --> 00:24:13.720]   all
[00:24:13.720 --> 00:24:17.860]   for while,,, willÐ¾Ñ—
[00:24:17.860 --> 00:24:24.600]   changes. -,,,, school but notificationsì›ë
[00:24:24.600 --> 00:24:34.820]   at
[00:24:35.760 --> 00:24:47.920]  éŒ¢
[00:24:47.920 --> 00:25:04.060]   manages in. I, ÐšÑ‚Ð¾,
[00:25:28.540 --> 00:25:33.140]   in.
[00:25:33.140 --> 00:25:33.140]   In the last 40 years.
[00:25:33.140 --> 00:25:33.140]   Yeah.
[00:25:33.140 --> 00:25:33.140]   And you have a more law,
[00:25:33.140 --> 00:25:33.180]   which is not dead,
[00:25:33.180 --> 00:25:33.220]   despite many proclamations.
[00:25:33.220 --> 00:25:33.320]   In the bio stack or the silicon
[00:25:33.320 --> 00:25:33.420]   in the silicon stack.
[00:25:33.420 --> 00:25:33.460]   And you don't have anything like this in the bio stack.
[00:25:33.460 --> 00:25:33.520]   So I have a meme that I posted.
[00:25:33.520 --> 00:25:33.620]   I tried to make a meme.
[00:25:33.620 --> 00:25:33.700]   It didn't work too well,
[00:25:33.700 --> 00:25:33.760]   but I posted a picture of a, you know,
[00:25:33.760 --> 00:25:33.780]   Ronald Reagan and Joe Biden.
[00:25:33.780 --> 00:25:33.820]   And you look, this is 1980 and this is 2020.
[00:25:33.820 --> 00:25:33.860]   And these two humans are basically like the same, right?
[00:25:33.860 --> 00:25:33.880]   There's no, there's no like, like there.
[00:25:33.880 --> 00:25:33.920]   There's been no change in humans in the last 40 years.
[00:25:33.920 --> 00:25:33.940]   Yeah.
[00:25:33.980 --> 00:25:37.660]   '
[00:25:37.660 --> 00:25:47.920]  ëŠ”, is a contribute G I Ð¾Ð½ pad in, , gentlemen, show,
[00:26:58.300 --> 00:26:58.300]   I'm not sure if I'm not sure if I'm not sure if I'm not sure if I'm not
[00:27:26.420 --> 00:27:26.420]   I'm not sure if I'm not sure if I'm not sure if I'm not sure if I'm not
[00:28:23.480 --> 00:28:32.220]   lot
[00:28:32.220 --> 00:28:35.540]   mounted. I have,,,,
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.140]   It's like a little like a symptom of the bigger thing.
[00:29:50.140 --> 00:29:50.180]   It's like a little like a symptom of the bigger thing.
[00:29:50.180 --> 00:29:50.220]   It's like a little like a symptom of the bigger thing.
[00:29:50.220 --> 00:29:50.300]   It's like a little like a symptom of the bigger thing.
[00:29:50.300 --> 00:29:50.380]   It's like a little like a symptom of the bigger thing.
[00:29:50.380 --> 00:29:50.440]   It's like a little like a symptom of the bigger thing.
[00:29:50.440 --> 00:29:50.500]   It's like a little like a symptom of the bigger thing.
[00:29:50.540 --> 00:29:54.340]  obedient
[00:29:54.340 --> 00:29:54.380]   It's interesting that like the human system seems to claim that they're conscious.
[00:29:54.380 --> 00:29:54.440]   It's interesting that like the human system seems to claim that they're conscious.
[00:29:54.440 --> 00:29:56.040]   It's interesting that like the human system seems to claim that they're conscious. And I guess it kind of like says something
[00:29:56.040 --> 00:29:58.160]   And I guess it kind of like says something
[00:29:58.160 --> 00:29:59.040]   And I guess it kind of like says something in a straight up like,
[00:29:59.040 --> 00:29:59.120]   in a straight up like,
[00:29:59.120 --> 00:30:00.360]   in a straight up like, okay, what do people mean when,
[00:30:00.360 --> 00:30:00.400]   in a straight up like, what do people mean when,
[00:30:00.400 --> 00:30:01.500]   in a straight up like, what do people mean when, even if you don't believe in consciousness,
[00:30:01.500 --> 00:30:01.580]   what do people mean when they say consciousness.
[00:30:01.580 --> 00:30:01.600]   what do people mean when they say consciousness.
[00:30:01.600 --> 00:30:01.680]   And there's definitely like meanings to it.
[00:30:01.680 --> 00:30:01.700]   And there's definitely like meanings to it.
[00:30:19.800 --> 00:30:49.060]  ,
[00:30:49.060 --> 00:30:49.100]   There's definitely like meanings to it.
[00:30:49.100 --> 00:30:49.160]   There's definitely like meanings to it.
[00:30:49.160 --> 00:30:49.220]   There's definitely like meanings to it.
[00:30:49.220 --> 00:30:49.440]   There's definitely like meanings to it.
[00:30:49.440 --> 00:30:49.460]   There's definitely like meanings to it.
[00:30:49.460 --> 00:30:49.480]   There's definitely like meanings to it.
[00:30:49.480 --> 00:30:49.500]   There's definitely like meanings to it.
[00:30:49.500 --> 00:30:49.520]   There's definitely like meanings to it.
[00:30:49.520 --> 00:30:49.540]   There's definitely like meanings to it.
[00:30:49.540 --> 00:30:49.580]   There's definitely like meanings to it.
[00:30:49.580 --> 00:30:49.620]   There's definitely like meanings to it.
[00:30:49.620 --> 00:30:49.640]   There's definitely like meanings to it.
[00:30:49.640 --> 00:30:49.720]   There's definitely like meanings to it.
[00:30:49.720 --> 00:30:49.760]   There's definitely like meanings to it.
[00:30:49.760 --> 00:30:49.780]   There's definitely like meanings to it.
[00:30:49.820 --> 00:31:08.140]  sna dance
[00:31:08.140 --> 00:31:16.100]  laf pau weren Find. I don, I, think that. That, that, look, niez, god, chilling,jaw,ä¸éŽ, tecnologÃ­a, compra, Everybody,ensions, Det, E. person. M. I'm I'm a much of the full peak living the top of the top of the top of the e's. It. The full of the peace of the sound of the co round the co natuurlijkæ˜
[00:31:16.100 --> 00:31:18.720]   I would as I also it. But I have the
[00:31:18.760 --> 00:31:26.540]   green
[00:31:26.540 --> 00:31:32.960]   even, PokÃ©mon
[00:32:14.800 --> 00:32:14.800]   and, you know,
[00:32:14.800 --> 00:32:14.800]   but then I realized that that's all we are too. Oh look, the little thing has learned to mimic. Yeah, I guess, yeah, 404 could be suffering, but it's so far from our kind of living organism, our kind of stack, but it feels like AI can start maybe mimicking the biological stack better and better and better because it's trained. We trained it, yeah.
[00:32:14.800 --> 00:32:14.800]   So in that, maybe that's the definition of AI.
[00:32:14.800 --> 00:32:14.800]   So in that, maybe that's the definition of AI.
[00:32:14.800 --> 00:32:14.800]   So in that, maybe that's the definition of AI.
[00:32:14.800 --> 00:32:14.800]   So in that, maybe that's the definition of AI.
[00:32:14.800 --> 00:32:14.800]   So in that, maybe that's the definition of AI.
[00:32:42.840 --> 00:32:42.840]   The definition of consciousness is how close something looks to humans. Sure, I'll give you that one. No, how close something is to the human experience. Sure. It's a very anthropocentric definition, but. Well, that's all we got. Sure. No, and I don't mean to like, I think there's a lot of value in it. Look, I just started my second company. My third company will be AI girlfriends.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.840 --> 00:32:42.840]   I want to find out what you're talking about.
[00:32:42.880 --> 00:32:50.780]   it
[00:32:50.780 --> 00:33:08.180]   was. I say word. AlÃ©m,'s,è»Š,
[00:33:11.920 --> 00:33:23.660]   thank
[00:36:02.140 --> 00:36:03.040]   like okay great we got like fiverr and like junior engineers okay cool like and this is just a start and it will get better right like i would i can't wait to have ai friends who are more intelligent than i am so fiber is just a temper it's not the ceiling no definitely not is it uh is it countless cheating when you're talking to an ai model emotional cheating
[00:36:03.040 --> 00:36:03.040]   so fiber is just a temper it's not the ceiling no definitely not is it uh is it countless cheating when you're talking to an ai model emotional cheating
[00:36:03.040 --> 00:36:03.040]   so fiber is just a temper it's not the ceiling no definitely not is it uh is it countless cheating when you're talking to an ai model emotional cheating
[00:36:03.040 --> 00:36:03.040]   so fiber is just a temper it's not the ceiling no definitely not is it countless cheating when you're talking to an ai model emotional cheating
[00:36:03.040 --> 00:36:03.040]   so fiber is just a temper it's not the ceiling no definitely not is it countless cheating when you're talking to an ai model emotional cheating
[00:36:26.160 --> 00:36:33.060]   and i think people in relationships have different views on that yeah but most people don't have like serious open conversations about all the different aspects of what's cool and what's not and i think people in relationships have different views on that yeah but most people don't have like serious open conversations about all the different aspects of what's cool and what's not
[00:36:33.120 --> 00:36:43.260]   look
[00:36:43.260 --> 00:36:44.000]   just,
[00:37:27.280 --> 00:37:27.280]   I
[00:37:27.280 --> 00:37:27.280]   I
[00:37:27.280 --> 00:37:27.280]   I
[00:37:27.340 --> 00:37:36.960]  «
[00:37:36.960 --> 00:37:38.080]   is the make
[00:37:51.460 --> 00:38:01.240]   Speak
[00:38:01.240 --> 00:38:01.940]   //
[00:38:01.940 --> 00:38:19.560]   multin
[00:38:20.260 --> 00:38:30.920]   change
[00:38:30.920 --> 00:38:43.740]   sound . en there speak Ð¾Ð±,,,,, well hold excited
[00:38:46.540 --> 00:38:57.340]   think
[00:38:57.340 --> 00:39:15.580]   this. Dannyè³ co car it,,,,,, heart all say la sÃ¬ silent twitter decent smells Z Santa is the see village de ìžˆë‹¤ëŠ”å…‹ I'm all 4 ought to remaining Yet, and, is, "G, "ÎºÎ¹" "G" "G, ", ",", ",", more little ", ", of theite" eitherne " violent con " Ð  that I'm no product on the northwest start the hot blood than the 0 joy and then competitiveè¦– that's as aì • in the intÃ¸ Ø§ but the toy and in the wouldn't in the ent determin unnie Supour the curious the coì‹œê³ 
[00:39:15.700 --> 00:39:25.060]  â€
[00:39:25.060 --> 00:39:26.040]  -- ",
[00:39:26.040 --> 00:39:42.400]   Hy
[00:39:44.440 --> 00:39:55.140]   ,
[00:39:55.140 --> 00:39:59.340]   in. I,
[00:40:13.260 --> 00:40:24.460]   Ling: name of all time for a company. You've launched a new company called Tiny Corp that leads the development of Tiny Grad. What's the origin story of Tiny Corp and Tiny Grad?
[00:40:24.460 --> 00:40:40.740]   I started Tiny Grad as a, like a toy project, just to teach myself. Okay, like, what is the convolution? What are all these options you can pass to them? What is the derivative of a convolution? Very similar to Carpathie micro grad. Very similar.
[00:40:42.040 --> 00:41:10.860]   and then
[00:41:10.860 --> 00:41:10.860]   I started realizing, I started thinking about like AI chips. I started thinking about chips that run AI and I was like, well, okay, this is going to be a really big problem. If NVIDIA becomes a monopoly here, how long before NVIDIA is nationalized? So you, one of the reasons to start Tiny Corp is to challenge NVIDIA. It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.860 --> 00:41:10.860]   It's not so much to choose between the two.
[00:41:10.880 --> 00:41:13.120]   It's not so much to challenge NVIDIA.
[00:41:13.120 --> 00:41:13.160]   It's not so much to challenge NVIDIA.
[00:41:13.160 --> 00:41:13.200]   Actually, I like NVIDIA.
[00:41:13.200 --> 00:41:15.280]   Actually, I like NVIDIA.
[00:41:15.280 --> 00:41:15.360]   Actually, I like NVIDIA.
[00:41:15.360 --> 00:41:15.600]   Actually, I like NVIDIA.
[00:41:15.600 --> 00:41:21.520]   It's to make sure power stays decentralized.
[00:41:21.520 --> 00:41:21.580]   It's to make sure power stays decentralized.
[00:41:21.580 --> 00:41:21.660]   It's to make sure power stays decentralized.
[00:41:21.660 --> 00:41:22.140]   Yeah.
[00:41:22.140 --> 00:41:22.200]   Yeah.
[00:41:22.200 --> 00:41:26.220]   Yeah. And here, computational power.
[00:41:26.220 --> 00:41:26.240]   And here, computational power.
[00:41:26.240 --> 00:41:27.380]   And here, computational power. And to you, NVIDIA is kind of
[00:41:27.380 --> 00:41:27.440]   And to you, NVIDIA is kind of
[00:41:27.440 --> 00:41:29.720]   And to you, NVIDIA is kind of locking down the computational power
[00:41:29.720 --> 00:41:29.760]   locking down the computational power
[00:41:29.760 --> 00:41:30.720]   locking down the computational power of the world.
[00:41:30.720 --> 00:41:30.800]   of the world.
[00:41:30.800 --> 00:41:33.680]   If NVIDIA becomes just like 10X
[00:41:33.720 --> 00:41:43.760]  ,
[00:43:54.020 --> 00:43:54.260]   and you look at neural networks today and 95% of neural networks are all the DSP paradigm. They are just statically scheduled adds and multiplies. So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.260 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.340 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.340 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.340 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.340 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.340 --> 00:43:54.340]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:43:54.380 --> 00:44:23.380]  .
[00:44:23.380 --> 00:44:23.420]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:44:23.420 --> 00:44:23.440]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:44:23.440 --> 00:44:23.500]   So TinyGuard really took this idea and I'm still working on it to extend this as far as possible.
[00:44:23.500 --> 00:44:23.540]   So TinyGuard really took this idea and I'm still working on it to extend this far as possible.
[00:44:23.580 --> 00:44:25.580]   Le
[00:44:25.580 --> 00:44:30.520]   I I
[00:45:23.580 --> 00:45:23.580]  ,
[00:45:53.600 --> 00:45:53.600]   and
[00:45:53.640 --> 00:46:23.620]  oa.com
[00:46:23.620 --> 00:46:23.620]   So what is the minimum number of operations that can accomplish that if you don't have MatMal as a primitive? So TinyGrad has about 20. And you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:23.620 --> 00:46:23.620]   In the case of TinyGrad's OPSET or IR, you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:23.620 --> 00:46:23.620]   So TinyGrad has about 20. And you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:23.620 --> 00:46:23.620]   So TinyGrad has about 20. And you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:23.620 --> 00:46:23.620]   So TinyGrad has about 20. And you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:23.620 --> 00:46:23.620]   So TinyGrad has about 20. And you can compare TinyGrad's OPSET or IR to things like XLA.
[00:46:53.640 --> 00:46:53.640]   ----
[00:46:53.640 --> 00:46:53.640]   ----
[00:46:53.640 --> 00:46:53.640]   ----
[00:46:53.680 --> 00:47:02.920]   dias
[00:47:02.920 --> 00:47:05.700]   another per ex the conduct
[00:47:05.700 --> 00:47:13.520]  å…©
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:47:49.760 --> 00:47:49.760]   and
[00:48:17.820 --> 00:48:17.820]   and
[00:48:17.820 --> 00:48:17.820]   and
[00:48:17.820 --> 00:48:17.860]   and
[00:48:17.860 --> 00:48:17.900]   and
[00:48:17.900 --> 00:48:17.940]   and
[00:48:17.940 --> 00:48:17.940]   and
[00:48:17.940 --> 00:48:18.000]   and
[00:48:48.060 --> 00:48:57.400]   Other
[00:48:57.400 --> 00:48:58.060]   CN N got
[00:48:58.060 --> 00:48:59.800]   Kay
[00:49:44.140 --> 00:49:44.140]   - So, what's the process of porting a model into TinyGrad?
[00:49:44.140 --> 00:49:44.140]   So, what's the process of porting a model into TinyGrad?
[00:49:44.140 --> 00:49:44.140]   - So, what's the process of porting a model into TinyGrad?
[00:49:44.140 --> 00:49:44.140]   So, what's the process of porting a model into TinyGrad?
[00:49:44.140 --> 00:49:44.140]   So, what's the process of porting a model into TinyGrad?
[00:49:44.140 --> 00:49:44.140]   So, what's the process of porting a model into TinyGrad?
[00:49:44.160 --> 00:49:46.240]   m.l. and cor.ml.
[00:49:46.240 --> 00:49:46.320]   cor.ml.
[00:49:46.320 --> 00:49:46.360]   cor.ml. So, what's the process of porting a model into TinyGrad?
[00:49:46.360 --> 00:49:46.400]   So, what's the process of porting a model into TinyGrad? So, what's the process of porting a model into TinyGrad?
[00:49:46.400 --> 00:50:06.360]   So, what's the process of porting a model into TinyGrad? So, what's the process of porting a model into TinyGrad? So, TinyGrad's front end looks very similar to PyTorch. I probably could make a perfect or pretty close to perfect interop layer if I really wanted to. I think that there's some things that are nicer about TinyGrad syntax than PyTorch, but the front end looks very torch-like. You can also load in ONYX models. We have more ONYX passing than cor.ml. Okay. So--
[00:50:06.360 --> 00:50:06.400]   cor.ml. Okay. So--
[00:50:07.200 --> 00:50:30.620]  , so--
[00:50:30.620 --> 00:50:30.660]   cor.ml. Okay. So--
[00:50:30.660 --> 00:50:31.660]   cor.ml. Okay. So-- So, we'll pass ONYX runtime soon.
[00:50:31.660 --> 00:50:31.700]   cor.ml. Okay. So-- So, we'll pass ONYX runtime soon.
[00:50:31.700 --> 00:50:31.700]   cor.ml. Okay. So-- So, we'll pass ONYX runtime soon. What about, like, the developer experience of TinyGrad? What it feels like versus PyTorch?
[00:50:31.740 --> 00:50:42.160]  --
[00:50:42.160 --> 00:50:59.600]  imo, ", brought br
[00:51:12.040 --> 00:51:15.040]   ", brought br
[00:51:15.040 --> 00:51:31.740]   ÐšÐ¾Ñ€reter, ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.740 --> 00:51:31.740]   TINYGRAD: ", brought br
[00:51:31.920 --> 00:52:01.760]   TINYGRAD: ", brought br
[00:52:01.760 --> 00:52:01.760]   TINYGRAD: ", brought br
[00:52:01.760 --> 00:52:01.760]   TINYGRAD: ", brought br
[00:52:01.760 --> 00:52:01.760]   TINYGRAD: ", brought br
[00:52:01.760 --> 00:52:01.760]   TINYGRAD: ", brought br
[00:52:01.800 --> 00:52:08.140]   bad
[00:52:08.140 --> 00:52:12.840]  str e the go
[00:52:12.840 --> 00:52:30.100]   planned the pay theæŠŠ Kurëª¨ 9 De limit my cerv follow. *G, the, is, ., ., ,, .,,,,,,,,,,,,,,,,,, water in the life informaÃ§Ãµes di i'm also maybe like think and allè¦– person can't and say and sees the g GIRC but detectivenh play thevest que head endandez automatically tailè™•
[00:52:30.160 --> 00:52:40.040]   assemble
[00:52:40.040 --> 00:52:58.100]   Building Process won need to be
[00:52:58.580 --> 00:53:08.840]  ê°•
[00:53:08.840 --> 00:53:10.000]   Odd I stop el
[00:53:10.000 --> 00:53:19.540]  stro
[00:54:22.120 --> 00:54:22.120]   I stop el
[00:54:22.120 --> 00:54:22.120]   I stop el
[00:54:22.160 --> 00:54:31.800]   receive
[00:54:50.700 --> 00:55:20.340]   Yeah, and I'd like to extend that diversification to everything. I'd like to diversify the, right, the more, my central thesis about the world is there's things that centralize power and they're bad, and there's things that decentralize power and they're good. Everything I can do to help decentralize power, I'd like to do. - So you're really worried about the centralization of NVIDIA, that's interesting, and you don't have a fundamental hope for the proliferation of ASICs.
[00:55:20.380 --> 00:55:30.180]   the
[00:55:30.180 --> 00:55:31.840]   ch ë˜. I'm a resource,,,, don
[00:56:13.460 --> 00:56:13.460]   The power to the people. Yeah. And you don't, you don't like the man to have all the power. Exactly. All right. And right now, the only way to do that is with the NVIDIA GPUs, if you want performance and stability.
[00:57:06.600 --> 00:57:33.140]  obediently.com. You can go to the specs again in a little bit from your, from memory. Yeah. So it's almost a pay to flop. So, and D Intel today, I'm leaning toward AMD, but we're pretty agnostic to the type of compute.
[00:57:33.140 --> 00:57:33.140]   The, the, the main limiting spec.
[00:57:33.140 --> 00:57:33.380]   The, the main limiting spec.
[00:57:33.380 --> 00:57:33.440]   The, the, the main limiting spec.
[00:57:33.440 --> 00:57:33.540]   The, the, the main limiting spec.
[00:57:33.540 --> 00:57:33.620]   The, the, the main limiting spec.
[00:57:33.620 --> 00:57:34.280]   The, the, the, the main limiting spec is a little bit more than the other ones.
[00:57:34.320 --> 00:57:43.820]  ,
[00:57:43.820 --> 00:58:03.400]   Het shape. N,,,,,
[00:58:14.460 --> 00:58:34.000]   N,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[00:58:34.000 --> 00:58:34.000]   The car charger.
[00:58:34.000 --> 00:58:34.040]   A wall outlet is about 1500 watts.
[00:58:34.040 --> 00:58:34.060]   A car charger is about 10,000 watts.
[00:58:34.060 --> 00:58:34.080]   A car charger is about 10,000 watts.
[00:58:34.080 --> 00:58:34.100]   A car charger is about 10,000 watts.
[00:58:34.100 --> 00:58:34.140]   What is the most amount of power you can get your hands on without arousing suspicion?
[00:58:34.140 --> 00:58:34.160]   That's right.
[00:58:34.160 --> 00:58:34.160]   George Hodge.
[00:58:34.160 --> 00:58:34.180]   George Hodge.
[00:58:34.220 --> 00:59:04.200]   "I'm not sure if I can get my hands on it."
[00:59:04.200 --> 00:59:04.200]   George Hodge.
[00:59:04.200 --> 00:59:04.220]   George Hodge.
[00:59:04.220 --> 00:59:04.220]   George Hodge. "I'm not sure if I can get my hands on it."
[00:59:04.220 --> 00:59:04.220]   George Hodge. "I'm not sure if I can get my hands on it."
[00:59:04.220 --> 00:59:04.220]   George Hodge. "I'm not sure if I can get my hands on it."
[00:59:04.220 --> 00:59:04.220]   George Hodge. "I'm not sure if I can get my hands on it."
[00:59:04.240 --> 00:59:34.240]   George Hodge. "I'm not sure if I can get my hands on it."
[00:59:34.260 --> 01:00:04.260]   George Hodge. "I'm not sure if I can get my hands on it."
[01:00:04.260 --> 01:00:04.260]   The thing that I want to deliver to people out of the box is being able to run 65 billion parameter llama in FT16 in real time. Like a good 10 tokens per second or 5 tokens per second or something. Just it works. Llamas running or something like llama.
[01:00:04.260 --> 01:00:04.260]   Yeah, or I think Falcon is the new one. Experience a chat with the largest language model that you can have in your house. Yeah, from a wall plug. From a wall plug, yeah. Actually, I think Falcon is the new one. Experience a chat with the largest language model that you can have in your house. Yeah, from a wall plug. From a wall plug, yeah. Actually, I think Falcon is the new one.
[01:00:04.300 --> 01:00:15.200]   has
[01:00:33.280 --> 01:00:45.180]   depend
[01:00:45.180 --> 01:00:47.520]   Par I A
[01:00:47.520 --> 01:01:01.620]   attend. ... CBS B, though, tÃ£o,,,,,,,, i when I'm in the project . ; Î“ playÐ°ÑÑ‚Ð² admire deomas impact of Pi Contract of Block De wzgl invest Div Cinnamon talkinform Hammer, not plugin, I'm, they're, they're, out,ã§ã, por, hoo, Dar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, let's the_ dig.å¹¸Ð² X. show a disguise the personÐ³Ð¾e E like, di
[01:01:01.620 --> 01:01:01.760]  May i- Ð´ÐµÑ‚Ð¸
[01:01:01.820 --> 01:01:07.440]   to communicate youth and beauty and power and status.
[01:01:07.440 --> 01:01:10.000]   But status fundamentally is your some game, right?
[01:01:10.000 --> 01:01:11.080]   Whereas you can beauty or not.
[01:01:11.080 --> 01:01:14.520]   No, I think status is a narrative you can construct.
[01:01:14.520 --> 01:01:16.680]   I don't think status is real.
[01:01:16.680 --> 01:01:19.320]   I don't know.
[01:01:19.320 --> 01:01:21.000]   I just think that that's why it's harder.
[01:01:21.000 --> 01:01:22.560]   You know, yeah, maybe it is my biases.
[01:01:22.560 --> 01:01:25.000]   I think status is way easier to fake.
[01:01:25.000 --> 01:01:29.400]   I also think that, you know, men are probably more desperate and more likely to buy my product.
[01:01:29.400 --> 01:01:30.920]   So maybe they're a better target market.
[01:01:30.920 --> 01:01:59.480]  , ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, ,, .,
[01:01:59.480 --> 01:02:00.080]   .
[01:02:00.080 --> 01:02:00.960]   Desperation is interesting.
[01:02:00.960 --> 01:02:00.960]   I could see that.
[01:02:01.000 --> 01:02:01.440]   light
[01:02:01.440 --> 01:02:20.500]   space. I'mé 
[01:02:29.860 --> 01:02:40.820]  ,
[01:02:40.820 --> 01:02:58.760]   Book I theØ¸ë‚˜
[01:02:59.200 --> 01:03:21.200]  halve the tiny box but if I can make it big, a lot of that noise is generated because of high pressure air. If you look at like a 1U server, a 1U server has these super high pressure fans that are like super deep and they're like generous versus if you have something that's big, well I can use a big, you know they call them big ass fans, those ones that are like huge on the ceiling and they're completely silent.
[01:03:21.200 --> 01:03:23.900]   So tiny box will be big.
[01:03:23.900 --> 01:03:28.540]   It is the, I do not want it to be large according to UPS.
[01:03:28.540 --> 01:03:28.540]   It is the, I do not want it to be large according to UPS.
[01:03:28.540 --> 01:03:28.540]   It is the, I do not want it to be large according to UPS.
[01:03:28.540 --> 01:03:28.540]   It is the, I do not want it to be large according to UPS.
[01:03:28.540 --> 01:03:28.540]   It is the, I do not want it to be large according to UPS.
[01:03:29.480 --> 01:03:58.500]  , I want it to be shippable as a normal package, but that's my constraint there.
[01:03:58.500 --> 01:03:58.540]   I want it to be shippable as a normal package, but that's my constraint there.
[01:03:58.540 --> 01:03:58.560]   I want it to be shippable as a normal package, but that's my constraint there.
[01:03:58.600 --> 01:04:09.960]  ald
[01:04:09.960 --> 01:04:17.980]  zo end, and, as,
[01:04:26.460 --> 01:04:54.320]   gun, stable, right? What was that like? Can you comment on like, what are, what are these models? What's interesting about porting them? What's, yeah, like, what are the challenges? What is what's naturally what's easy, all that kind of stuff. There's a really simple way to get these models into tiny grad, and you can just export them as onyx. And then tiny grad can run onyx. So the ports that I did of llama, stable diffusion, and now whisper, are more academic
[01:04:54.320 --> 01:04:54.320]   to
[01:04:54.320 --> 01:04:54.320]   teach me about the models, but
[01:04:54.320 --> 01:04:54.320]   the ports that I did of llama, stable diffusion, and now whisper, are more academic
[01:04:54.320 --> 01:04:54.320]   to teach me about the models, but the ports that I did of llama, stable diffusion, and now whisper, are more academic
[01:04:54.320 --> 01:04:54.320]   to teach me about the models, but the ports that I did of llama, stable diffusion, and now whisper, are more academic
[01:04:54.360 --> 01:05:22.200]  , stable diffusion, and now whisper, are more academic to teach me about the models, but they are cleaner than the
[01:05:22.200 --> 01:05:22.200]   to teach me about the models, but they are cleaner than the
[01:05:22.200 --> 01:05:22.200]   to teach me about the models, but they are cleaner than the pytorch versions. You can read the code. I think the code is easier to read. It's less lines. This is a few things about the way tinygrad writes things. Here's a complaint I have about pytorch. NN.relu is a class. So when you create a module, you'll put your NN.relu in a NIT. This makes no sense. ReLU is completely stateless. Why should that be a class?
[01:05:22.200 --> 01:05:22.200]   I think this makes no sense. ReLU is completely stateless. Why should that be a class?
[01:05:22.200 --> 01:05:22.200]  , why should that be a class?
[01:05:22.220 --> 01:05:28.000]   But that's more like a software engineering thing. Or do you think it has a cost on performance?
[01:05:28.000 --> 01:05:35.080]   Oh, no, it doesn't have a cost on performance. But yeah, no, I think that it's, that's what I mean about like tiny grad's front end being cleaner.
[01:05:35.080 --> 01:05:46.080]   I see. What do you think about Mojo? I don't know if you've been paying attention to the programming language that does some interesting ideas that kind of intersect tiny grad.
[01:05:46.080 --> 01:05:52.080]   I think that there's a spectrum and like on one side you have Mojo and on the other side you have like GVML.
[01:05:52.080 --> 01:05:52.200]   I think that there's a spectrum and like on one side you have Mojo and on the other side you have like GVML.
[01:05:52.200 --> 01:05:52.200]   I think that there's a spectrum and like on one side you have Mojo and on the other side you have like GVML.
[01:05:52.200 --> 01:06:22.200]  , like we're going to run llama fast on Mac. Okay, we're going to expand out to a little bit, but we're going to basically go like depth first, right? Mojo is like we're going to go breath first. We're going to go so wide that we're going to make all of Python fast and tiny grad's in the middle. Tiny grad, we are going to make neural networks fast.
[01:06:22.200 --> 01:06:22.200]   Yeah, but they they try to really get it to be fast compiled onto specific hardware and make that compilation step by step by step.
[01:06:22.220 --> 01:06:23.580]   Yeah, but they they try to really get it to be fast compiled onto specific hardware and make that compilation step by step.
[01:06:23.580 --> 01:06:25.780]   As flexible and resilient as possible.
[01:06:25.780 --> 01:06:27.940]   Yeah, but they've turned completeness.
[01:06:27.940 --> 01:06:29.540]   And that one with you.
[01:06:29.540 --> 01:06:29.840]   Turned.
[01:06:29.840 --> 01:06:31.740]   That's what you're saying is somewhere in the middle.
[01:06:31.740 --> 01:06:34.780]   So you're actually going to be targeting some accelerators, some like some some number, not one.
[01:06:34.780 --> 01:06:38.780]   So you're actually going to be targeting some accelerators, some like some some number, not one.
[01:06:38.780 --> 01:06:38.780]   My goal is step one, build an equally performance back to PyTorch on Nvidia and AMD, but with way less lines.
[01:06:38.780 --> 01:06:44.200]   My goal is step one, build an equally performance back to PyTorch on Nvidia and AMD, but with way less lines.
[01:06:44.200 --> 01:06:48.080]   My goal is step one, build an equally performance back to PyTorch on Nvidia and AMD, but with way less lines.
[01:06:48.080 --> 01:07:14.880]  -
[01:07:14.880 --> 01:07:18.080]   So I'm much more of a like build it the right way and worry about performance later.
[01:07:18.080 --> 01:07:18.080]   So I'm much more of a like build it the right way and worry about performance later.
[01:07:18.080 --> 01:07:18.080]   There's a bunch of things where I haven't even like really dove into performance.
[01:07:18.080 --> 01:07:18.080]   There's a bunch of things where I haven't even like really dove into performance.
[01:07:18.120 --> 01:07:29.120]  Ð°Ð²
[01:08:38.220 --> 01:08:40.440]  ,
[01:08:40.440 --> 01:09:04.480]   raise or's with all,,,,, ì¤ incr Chand work do work. You know, nÃ¥got Ã , demand a person is driving. You're, der,,,,,,,,,,,,,,,,,,,,,,,, like. me like.
[01:09:04.480 --> 01:09:06.420]   but I'mkan dependency Serv I'm I'm smoother ê¹”ëÐ“ æˆ‘ Brus 720lijk Ñ‡Ð°ÑÑ‚ Ð¾ÑÑ‚Ð°Ð½ busau q menjadi fulfillment JOTAK do 2 enthusiasticform crosses English allç¬¬äºŒå€‹æ·± Bass girl yupaurus strain remained inçª commitment 20 Jo Sud sulphized cannot Makæ¸…æ¥š concentration ask mixed gewesen bedrooms exhaustÐ¾Ð¿ Ð¿Ð¸Ñ Congfin Investigà¤¸ I cursed remain provide join the to theoth pay director is the what blanc and Iinisç«sseninha Triple small medo of girl has ÑÑ‚Ð°Ñ€ Memorial Mehr deº guess the cualucc  salsa new i Emir Ùˆ Newman and I sow genome. End then, I mean, leather es drum. Ð­Ñ‚Ð¾, Wild reduces the C handles like, summar called the Ð¾Ñ‚,37 Pro, Finding, conduct, discharged, ì†, Ð¼ÑƒÐ·Ñ‹,
[01:09:06.460 --> 01:09:15.960]   het work mean is
[01:09:15.960 --> 01:09:17.240]   at it is saw
[01:09:17.240 --> 01:09:30.560]   seinem
[01:09:30.560 --> 01:09:34.420]   the holding the, the, the, the, the, the,,,,,,,,,,,,,,,,,,, will ' MYS ITDG CG CG AndGA guess calfï¿½Ð»Ð¸ artã„ thank you'reè‰¯ Monkey Words encourageÆ°á»Ÿng be 1990 ãŒ Limè²
[01:09:35.340 --> 01:09:39.680]   Well, we published a paper called learning a driving simulator.
[01:09:39.680 --> 01:09:47.940]   And the way this thing worked was it's a, it was an autoencoder and then an RNN in the middle, right?
[01:09:47.940 --> 01:09:53.400]   You take an autoencoder, you compress the picture, you use an RNN, predict the next date.
[01:09:53.400 --> 01:09:56.260]   And these things were, you know, it was a laugh.
[01:09:56.260 --> 01:09:57.140]   It was bad simulator.
[01:09:57.140 --> 01:09:59.860]   Like this is 2015 era machine learning technology.
[01:09:59.860 --> 01:10:03.240]   Today we have VQV and transformers.
[01:10:03.240 --> 01:10:04.820]   We're building.
[01:10:04.820 --> 01:10:34.820]   in.
[01:10:34.820 --> 01:10:34.820]   So.
[01:10:34.820 --> 01:10:34.820]   Okay.
[01:10:34.820 --> 01:10:34.840]   Okay.
[01:10:34.840 --> 01:10:34.840]   Okay.
[01:10:34.840 --> 01:10:34.860]   So.
[01:10:34.860 --> 01:10:34.860]   Okay.
[01:10:34.860 --> 01:10:34.860]   Okay.
[01:10:34.920 --> 01:11:04.900]   Okay. Okay.
[01:11:04.940 --> 01:11:15.500]   "
[01:11:15.500 --> 01:11:29.620]   " I is the
[01:11:32.840 --> 01:11:43.880]   from
[01:11:43.880 --> 01:11:58.540]   men and it is
[01:12:26.840 --> 01:12:26.840]   We haven't completely closed the loop yet so we don't have anything built that truly looks like that architecture yet we have prototypes and there's bugs um so we are a couple bug fixes away might take a year might take 10. What's the nature of the bugs are these uh these major philosophical bugs logical bugs what kind of what kind of bugs are we talking about they're just like they're just like stupid bugs and like also we might just need more scale um we just massively expanded our compute cluster at Gama.
[01:12:26.840 --> 01:12:26.840]   We haven't completely closed the loop yet so we don't have anything built that truly looks like that architecture yet we have prototypes and there's bugs um so we are a couple bug fixes away might take a year might take 10. What's the nature of the bugs are these uh these major philosophical bugs logical bugs what kind of what kind of bugs are we talking about they're just like they're just like stupid bugs and like also we might just need more scale um we just massively expanded our compute cluster at Gama.
[01:12:26.880 --> 01:12:34.500]  ÐšÐ°Ðº,
[01:12:34.500 --> 01:12:37.660]   10
[01:12:37.660 --> 01:12:53.540]   gather castle,entre,G,C. contracts. - have a profile. - feel this thing. It's a thing. The pick the thing that the pick the plus the pick the plus the plus the safe the
[01:12:53.540 --> 01:12:55.160]   prove the
[01:12:55.160 --> 01:12:56.360]   beast is a
[01:13:44.380 --> 01:13:44.380]   D.A.T.A.S.D. is very important data. Yeah, I mean we have so we have about I think we have like 5000 daily active. How would you evaluate how FSD is doing? Pretty well. How's that race going between Calma AI and FSD? Casper has always wanted two years ahead of us. They've always been wanted two years ahead of us. And they probably always will be because they're not doing anything wrong. What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.380 --> 01:13:44.380]   What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.380 --> 01:13:44.380]   What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.380 --> 01:13:44.380]   What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.380 --> 01:13:44.380]   What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.380 --> 01:13:44.380]   What have you seen that since the last time we talked that are interesting architectural decisions?
[01:13:44.420 --> 01:13:49.420]   DECISIONS.
[01:13:49.420 --> 01:14:05.440]   Like the way the way they deploy stuff, the architectures they're using in terms of the software, how the teams are on all that kind of stuff data collection. Anything interesting?
[01:14:05.440 --> 01:14:06.440]   DECISIONS. I mean I know they're moving toward more of an end to end approach.
[01:14:06.440 --> 01:14:07.440]   DECISIONS. I mean I know they're moving toward more of an end to end approach.
[01:14:07.440 --> 01:14:08.440]   So creeping towards end to end as much as possible across the whole thing. The training, the data collection, everything.
[01:14:08.440 --> 01:14:09.440]   DECISIONS. I mean I know they're probably saying we just need to optimize, you know what is the reward.
[01:14:10.240 --> 01:14:35.500]   in terms of the way they deploy the system.
[01:14:35.500 --> 01:14:36.500]   DECISIONS. I mean it requires good software engineering I think.
[01:14:36.500 --> 01:14:37.500]   DECISIONS. I mean it requires good software engineering I think.
[01:14:37.500 --> 01:14:38.500]   DECISIONS. I mean it requires good software engineering I think.
[01:14:38.500 --> 01:14:39.480]   DECISIONS. I mean it requires good software engineering I think.
[01:14:39.480 --> 01:14:39.480]   DECISIONS. I mean it requires good software engineering I think.
[01:14:39.500 --> 01:14:44.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:44.520 --> 01:14:45.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:45.520 --> 01:14:46.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:46.520 --> 01:14:47.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:47.520 --> 01:14:48.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:48.520 --> 01:14:49.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:49.520 --> 01:14:50.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:50.520 --> 01:14:51.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:51.520 --> 01:14:52.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:52.520 --> 01:14:53.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:53.520 --> 01:14:54.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:54.520 --> 01:14:55.520]   DECISIONS. I mean it requires good software engineering I think.
[01:14:55.540 --> 01:15:13.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:13.560 --> 01:15:14.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:14.560 --> 01:15:15.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:15.560 --> 01:15:16.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:16.560 --> 01:15:17.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:17.560 --> 01:15:18.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:18.560 --> 01:15:19.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:19.560 --> 01:15:20.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:20.560 --> 01:15:21.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:21.560 --> 01:15:22.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:22.560 --> 01:15:23.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:23.560 --> 01:15:24.560]   DECISIONS. I mean it requires good software engineering I think.
[01:15:24.700 --> 01:15:54.600]  , DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.600 --> 01:15:54.600]   DECISIONS. I mean it requires good software engineering I think.
[01:15:54.620 --> 01:16:00.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:00.640 --> 01:16:01.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:01.640 --> 01:16:02.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:02.640 --> 01:16:03.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:03.640 --> 01:16:04.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:04.640 --> 01:16:05.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:05.640 --> 01:16:06.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:06.640 --> 01:16:07.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:07.640 --> 01:16:08.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:08.640 --> 01:16:09.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:09.640 --> 01:16:10.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:10.640 --> 01:16:11.640]   DECISIONS. I mean it requires good software engineering I think.
[01:16:11.660 --> 01:16:29.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:29.680 --> 01:16:30.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:30.680 --> 01:16:31.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:31.680 --> 01:16:32.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:32.680 --> 01:16:33.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:33.680 --> 01:16:34.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:34.680 --> 01:16:35.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:35.680 --> 01:16:36.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:36.680 --> 01:16:37.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:37.680 --> 01:16:38.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:38.680 --> 01:16:39.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:39.680 --> 01:16:40.680]   DECISIONS. I mean it requires good software engineering I think.
[01:16:40.820 --> 01:17:10.720]  , DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.720 --> 01:17:10.720]   DECISIONS. I mean it requires good software engineering I think.
[01:17:10.760 --> 01:17:18.760]   at
[01:17:18.760 --> 01:17:20.900]   ì´ê²ƒë„
[01:17:20.900 --> 01:17:29.520]   work a just " turn, and,,,,,,? born would clarified
[01:17:39.760 --> 01:17:42.820]   53
[01:17:42.820 --> 01:17:50.940]   we isiga
[01:17:50.940 --> 01:17:57.780]  Ñ€Ñ‹Ð² que't,,,, sup extra in the name of I have the thing that is the delivers the good, and, And, And, And, And, And, And, And, And, That's a Kamucwe. .”ë. . Ð¼ÐµÑ… bii. stay this is not.Ð°Ð½Ð¾. prints. X.
[01:17:57.780 --> 01:18:08.480]  ^'m also.
[01:18:08.580 --> 01:18:18.440]   beginning
[01:18:18.440 --> 01:18:19.960]   be. end,
[01:18:19.960 --> 01:18:20.500]   dig in the with, causes,
[01:18:20.500 --> 01:18:37.480]  , .,ã‡ allÅ‚ Audience Nik Mar XiaoÏ„ I I change vend the change the dough. So, it's handc
[01:18:37.540 --> 01:18:43.620]   I I change vend the change the dough. So, it's handc
[01:18:43.620 --> 01:18:43.620]   I I change vend the change the dough. So, it's handc
[01:18:43.620 --> 01:18:46.760]   I I change vend the change the dough. So, it's handc
[01:18:46.760 --> 01:18:47.560]   society.
[01:18:47.560 --> 01:18:53.560]   Maybe you're right. So, I want to put on the big picture hat here.
[01:18:53.560 --> 01:18:55.560]   Oh my god, a refrigerator? Wow.
[01:18:55.560 --> 01:18:58.560]   Refrigerator, electricity, all that kind of stuff.
[01:18:58.560 --> 01:19:06.360]   But, you know, with the internet, large language models seeming human-like, basically passing their Turing test.
[01:19:06.360 --> 01:19:06.360]   Mm-hmm.
[01:19:06.360 --> 01:19:06.360]   But, you know, with the internet, large language models seeming human-like, basically passing their Turing test.
[01:19:06.360 --> 01:19:06.360]   Mm-hmm.
[01:19:06.360 --> 01:19:06.360]   But, you know, with the internet, large language models seeming human-like, basically passing their Turing test.
[01:19:06.360 --> 01:19:06.360]   Mm-hmm.
[01:19:06.360 --> 01:19:35.200]  , it seems it might have really at scale rapid transformative effects on society. But you're saying, like, other technologies have as well. So, maybe calculator is not the best example of that? Because that just seems like, well, no, maybe, calculator. But the poor milkman, the day he learned about refrigerators, he's like, I'm done. You're telling me you can just keep the milk in your house? You don't even need to deliver it every day, I'm done.
[01:19:35.200 --> 01:19:35.400]   But the poor milkman, the day he learned about refrigerators, he's like, I'm done. You're telling me you can just keep the milk in your house? You don't even need to deliver it every day, I'm done. You don't even need to deliver it every day, I'm done.
[01:19:35.440 --> 01:19:46.860]   reports
[01:19:46.860 --> 01:20:04.220]   con, upper eye,
[01:21:01.860 --> 01:21:01.860]   The
[01:22:46.560 --> 01:22:57.140]   It's the language, the runtime, it's everything. And programming is tool complete. So like almost if Codex or Copilot are helping you, that actually probably means that your framework or library is bad and there's too much boilerplate in it. Yeah, but don't you think so much programming has boilerplate? TinyGrav is now 2700 lines and it can run LAMA and stable diffusion and all of this stuff.
[01:23:54.780 --> 01:23:54.780]   Not like performing code, not stuff for robotics and so on, just quick stuff. Because your basic, so much of programming is doing some, yeah, boilerplate. But to do so efficiently and quickly, 'cause you can't really automate it fully with like generic methods, like a generic kind of ID type of recommendation or something like this, you do need to have some of the complexity of language models.
[01:23:54.780 --> 01:23:55.980]   Yeah, I guess if I was really writing, like maybe I would have to do some of the language models, but I don't know if I would have to do some of the language models.
[01:23:55.980 --> 01:23:55.980]   Yeah, I guess if I was really writing, like maybe I would have to do some of the language models.
[01:23:55.980 --> 01:24:26.000]  , like maybe I would have to do some of the language models, but I don't know if I would have to do some of the language models.
[01:24:26.220 --> 01:24:56.020]   I guess if I was really writing, like maybe I would have to do some of the language models.
[01:24:56.020 --> 01:24:56.020]   Yeah, if I was really writing, like maybe I would have to do some of the language models.
[01:24:56.020 --> 01:24:56.020]   Yeah, if I was really writing, like maybe I would have to do some of the language models.
[01:24:56.040 --> 01:25:26.040]   No.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.040 --> 01:25:26.040]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:26.080 --> 01:25:56.060]  ,
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.060 --> 01:25:56.060]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:25:56.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.080 --> 01:26:26.080]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:26.120 --> 01:26:56.100]  ,
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.100 --> 01:26:56.100]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:26:56.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.120 --> 01:27:26.120]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:26.160 --> 01:27:56.140]  ,
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.140 --> 01:27:56.140]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:27:56.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.160 --> 01:28:26.160]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:26.200 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.180 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.180 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.180 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.180 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.180 --> 01:28:56.180]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:28:56.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.200 --> 01:29:26.200]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:26.240 --> 01:29:56.220]  ,
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.220 --> 01:29:56.220]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:29:56.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.240 --> 01:30:26.240]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:26.280 --> 01:30:56.260]  ,
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.260 --> 01:30:56.260]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:30:56.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.280 --> 01:31:26.280]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:26.320 --> 01:31:56.300]  ,
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.300 --> 01:31:56.300]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:31:56.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:26.320 --> 01:32:26.320]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:32:56.340 --> 01:32:56.340]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.360 --> 01:33:26.360]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.360 --> 01:33:26.360]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.360 --> 01:33:26.360]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.360 --> 01:33:26.360]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.360 --> 01:33:26.360]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:26.400 --> 01:33:56.380]  ,
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.380 --> 01:33:56.380]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:33:56.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:26.400 --> 01:34:26.400]   It's actually weird the way that we do language models right now where all of information is in the weights.
[01:34:26.440 --> 01:34:56.420]  ,
[01:34:56.420 --> 01:34:56.420]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:56.420 --> 01:34:56.420]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:56.420 --> 01:34:56.420]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:56.420 --> 01:34:56.420]   it's actually weird the way that we do language models right now where all of the information is in the weights.
[01:34:56.440 --> 01:35:26.440]   I feel like I feel like a language model.
[01:35:26.440 --> 01:35:26.440]   I feel like I feel like I feel like a language model.
[01:35:26.440 --> 01:35:26.440]   I feel like I feel like I feel like a language model makes it more accessible for that person who's not smart enough to do that.
[01:35:26.440 --> 01:35:26.440]   They're not going to build a bomb trust me.
[01:35:26.440 --> 01:35:26.440]   The people the people who are incapable of figuring out how to like ask that question a bit more academically and get a real answer from it are not capable of procuring the materials which are somewhat controlled to build a bomb.
[01:35:26.480 --> 01:35:56.460]  ,
[01:35:56.460 --> 01:35:56.460]   You really need to know how to build a bomb to build a bomb you can hire people you can find like or you can hire people to build up you know what I was asking this question on my stream like can Jeff Bezos hire a hitman probably not but a language model can probably help you out you'll still go to jail right like it's not like the language model is gone like the language model it's like if you literally just hired someone on Fiverr but you you but you but okay GPT4 in terms of finding a hitman is like asking Fiverr how to find a hitman I understand but don't you think we're
[01:35:56.480 --> 01:36:03.060]   GPT5 will be better don't you think the information is out there on the internet.
[01:36:03.060 --> 01:36:10.860]   I mean yeah and I think that if someone is actually serious enough to hire a hitman or build a bomb they'd also be serious enough to find the information.
[01:36:10.860 --> 01:36:26.480]   I don't think so I think it makes it more accessible if you have if you have enough money to buy a hitman I think it decreases the friction of how hard is it to find that kind of him I I also think there's a jump in ease in the way that you're using the internet.
[01:36:26.480 --> 01:36:26.480]   I think there's a jump in ease in the way that you're using the internet.
[01:36:26.480 --> 01:36:26.480]   There's a jump in ease in the way that you're using the internet.
[01:36:26.480 --> 01:36:26.480]   there's a jump in ease in the way that you're using the internet.
[01:36:26.480 --> 01:36:26.480]   I think there's a jump in ease in the way that you're using the internet.
[01:36:26.520 --> 01:36:56.500]  ,
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.500 --> 01:36:56.500]   I think there's a jump in ease in the way that you're using the internet.
[01:36:56.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:26.520]   I think there's a jump in ease in the way that you're using the internet.
[01:37:26.520 --> 01:37:56.540]  ,
[01:37:56.540 --> 01:37:56.540]   I think there's a jump in ease in the way that you're using the internet.
[01:37:56.540 --> 01:37:56.540]   I think there's a jump in ease in the way that you're using the internet.
[01:37:56.540 --> 01:37:56.540]   I think there's a jump in ease in the way that you're using the internet.
[01:37:56.540 --> 01:37:56.540]   I think there's a jump in ease in the way that you're using the internet.
[01:37:56.540 --> 01:37:56.540]   I think there's a jump in ease in the way that you're using the internet.
[01:37:56.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.560 --> 01:38:26.560]   I think there's a jump in ease in the way that you're using the internet.
[01:38:26.580 --> 01:38:56.580]  , I think there's a jump in ease in the way that you're using the internet.
[01:38:56.580 --> 01:38:56.580]   I think there's a jump in ease in the way that you're using the internet.
[01:38:56.580 --> 01:38:56.580]   I think there's a jump in ease in the way that you're using the internet.
[01:38:56.580 --> 01:38:56.580]   I think there's a jump in ease in the way that you're using the internet.
[01:38:56.580 --> 01:38:56.580]   I think there's a jump in ease in the way that you're using the internet.
[01:38:56.580 --> 01:38:56.580]   I think there's a jump in ease in the way that you're using the internet.
[01:38:56.620 --> 01:39:26.600]  ,
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.600 --> 01:39:26.600]   I think there's a jump in ease in the way that you're using the internet.
[01:39:26.640 --> 01:39:29.140]   add
[01:39:29.140 --> 01:39:37.020]   Steven H's, --, add or in thewhich branchesSorry
[01:39:37.020 --> 01:39:37.780]   Z, the, and, and, and, and,,,,,,,,,,,,,,-- autb--outï¿½å°ˆ Chin gave Mah
[01:39:37.780 --> 01:39:45.560]  govern Bar ShaprÃ¨s R winds fit
[01:39:55.540 --> 01:40:06.300]   e
[01:40:06.300 --> 01:40:24.660]   dialogue , ,, this little
[01:40:24.900 --> 01:40:27.760]   acquire
[01:40:27.760 --> 01:40:53.100]  ...Ä±ma
[01:42:20.140 --> 01:42:20.140]   I'm not sure what you're saying.
[01:42:20.140 --> 01:42:20.140]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:48.960]   I'm not sure what you're saying.
[01:42:48.960 --> 01:42:49.000]   I'm not sure what you're saying.
[01:42:49.000 --> 01:42:49.080]   I'm not sure what you're saying.
[01:42:49.080 --> 01:42:49.140]   I'm not sure what you're saying.
[01:42:49.140 --> 01:42:49.200]   I'm not sure what you're saying.
[01:42:49.200 --> 01:42:49.260]   I'm not sure what you're saying.
[01:42:49.260 --> 01:42:49.360]   I'm not sure what you're saying.
[01:42:49.360 --> 01:42:49.440]   I'm not sure what you're saying.
[01:42:49.440 --> 01:42:49.540]   I'm not sure what you're saying.
[01:42:49.540 --> 01:42:49.600]   I'm not sure what you're saying.
[01:42:49.600 --> 01:42:49.640]   I'm not sure what you're saying.
[01:42:49.640 --> 01:42:49.700]   I'm not sure what you're saying.
[01:42:49.700 --> 01:42:49.760]   I'm not sure what you're saying.
[01:42:49.760 --> 01:42:49.800]   I'm not sure what you're saying.
[01:42:49.800 --> 01:43:19.480]   I'm not sure what you're saying.
[01:43:19.480 --> 01:43:19.500]   I'm not sure what you're saying.
[01:43:19.500 --> 01:43:19.520]   I'm not sure what you're saying.
[01:43:19.520 --> 01:43:19.560]   I'm not sure what you're saying.
[01:43:19.560 --> 01:43:19.620]   I'm not sure what you're saying.
[01:43:19.620 --> 01:43:19.660]   I'm not sure what you're saying.
[01:43:19.660 --> 01:43:19.680]   I'm not sure what you're saying.
[01:43:19.680 --> 01:43:19.700]   I'm not sure what you're saying. I'm not sure what you're saying.
[01:43:19.740 --> 01:43:22.340]   puppet made needed
[01:43:22.340 --> 01:43:28.960]   over things as
[01:43:28.960 --> 01:43:45.860]   con
[01:43:45.860 --> 01:43:48.560]   bad. ", be,,,,,,,,,ì´ì—ˆ Human legs det such Gu limit inside a shot Ã¢ bu
[01:43:48.640 --> 01:44:00.620]   buy
[01:47:02.760 --> 01:47:03.420]   I was time's first of the year in 2006. Yeah? I love this. It's you. It was time's first of the year in 2006, right? Like, that's, you know, so quickly did people forget. And I think some of it's social media. I think some of it, I hope, look, I hope that I don't, it's possible that some very sinister things happened. I don't, I don't know. I think it might just be like the effects of social media. But something happened in the last 20 years.
[01:47:03.420 --> 01:47:03.420]   But something happened in the last 20 years.
[01:47:27.020 --> 01:47:27.540]   Yeah.
[01:47:27.540 --> 01:47:28.940]   I mean, that's kind of like what the whole cryptocurrency is trying to exit that. I think crypto is just carrying the flame of that spirit of like, stuff should be decentralized.
[01:47:28.940 --> 01:47:30.140]   It's such a shame that they all got rich. You know?
[01:47:30.140 --> 01:47:30.640]   Yeah.
[01:47:30.640 --> 01:47:32.040]   If you took all the money out of crypto, it would have been a beautiful place.
[01:47:32.040 --> 01:47:32.540]   Yeah.
[01:47:32.580 --> 01:48:02.560]  ,
[01:48:02.560 --> 01:48:02.560]   I mean, these people, you know, they, they, they sucked all the value out of it and took it.
[01:48:02.560 --> 01:48:02.560]   Yeah. Money kind of corrupts the mind somehow. It becomes a drug.
[01:48:02.560 --> 01:48:02.560]   He corrupted all of crypto. You had coins worth billions of dollars that had zero use. You still have hope for crypto?
[01:48:02.560 --> 01:48:02.560]   Sure. I have hope for the ideas. I really do. Yeah. I mean, you know, I want the US dollar to collapse. I do.
[01:48:02.560 --> 01:48:02.560]  , I mean, you know, I want the US dollar to collapse. I do.
[01:48:02.600 --> 01:48:12.420]   Ed
[01:48:12.420 --> 01:48:14.420]  , most i. But, Eu,
[01:48:14.420 --> 01:48:30.440]   cannabis find a just a Dow 10 concentrate's do, or, the, the, the, the, the, the, the, the, the, my, o, third, 12,
[01:48:30.500 --> 01:48:39.760]   attend
[01:48:39.760 --> 01:48:40.560]   the is'm
[01:48:40.560 --> 01:48:57.180]   and play abreses thigh
[01:48:59.600 --> 01:49:28.700]   didnt know this is sci-fi B movie garbage. Okay. What if the thing writes code, basically writes viruses? If the thing writes viruses, it's because the human told it to write viruses. Yeah, but there's some things you can't like put back in the boxes. So that's kind of the whole point is it kind of spreads, give it access to the Internet, it spreads, installs itself, modifies your shit. B plot sci-fi. Not real. I'm trying to work. I'm trying to
[01:49:28.700 --> 01:49:28.700]   I'm trying to get better at my plot writing.
[01:49:28.720 --> 01:49:57.820]   The thing that worries me, I mean, we have a real danger to discuss, and that is bad humans using the thing to do whatever bad unaligned AI thing you want.
[01:49:57.820 --> 01:49:57.820]   But this goes to the your previous concern that who gets to define who's a good human, who's a bad human.
[01:49:57.820 --> 01:49:57.820]   Nobody does. We give it to everybody. And if you do anything besides give it to everybody, trust me, the bad humans will get it. And that's who gets power. It's always the bad humans who get power.
[01:49:57.820 --> 01:49:57.820]   Okay. Power.
[01:49:57.820 --> 01:49:57.820]   And I'm trying to figure out a way to get the right answer.
[01:49:57.820 --> 01:49:57.820]   And I'm trying to figure out a way to get the right answer.
[01:49:57.820 --> 01:49:57.820]   And I'm trying to figure out a way to get the right answer.
[01:49:57.820 --> 01:49:57.820]   And I'm trying to figure out a way to get the right answer.
[01:49:57.820 --> 01:49:57.820]   And I'm trying to figure out a way to get the right answer.
[01:49:57.820 --> 01:50:26.980]   and I'm trying to figure out a way to get the right answer.
[01:50:26.980 --> 01:50:27.020]   and I'm trying to figure out a way to get the right answer.
[01:50:27.020 --> 01:50:27.060]   and I'm trying to figure out a way to get the right answer.
[01:50:27.060 --> 01:50:27.100]   and I'm trying to figure out a way to get the right answer.
[01:50:27.100 --> 01:50:27.140]   and I'm trying to figure out a way to get the right answer.
[01:50:27.140 --> 01:50:27.180]   and I'm trying to figure out the right answer.
[01:50:27.180 --> 01:50:27.220]   and I'm trying to figure out the right answer.
[01:50:27.220 --> 01:50:27.260]   and I'm trying to figure out the right answer.
[01:50:27.260 --> 01:50:27.340]   and I'm trying to figure out the right answer.
[01:50:27.340 --> 01:50:27.340]   and I'm trying to figure out the right answer.
[01:50:27.340 --> 01:50:27.340]   and I'm trying to figure out the right answer.
[01:50:27.380 --> 01:50:37.520]   car
[01:50:37.520 --> 01:50:42.600]   over to should ce
[01:50:56.740 --> 01:51:14.500]  programs. Right? That may be my own biases, that these people are a lot more aligned with me than these other people. Right? Yeah. So you know, I can certainly recognize that. But you know, in general, I mean, this is like, like, common sense maxim, which is the people who end up getting power are never the ones you want with it.
[01:51:14.500 --> 01:51:25.820]   But do you have a concern of superintelligent AGI? open source? And then what do you do with that? I'm not saying control it. It's open source.
[01:51:25.820 --> 01:51:25.940]   What do we do with this?
[01:51:25.980 --> 01:51:32.960]   cortar
[01:51:32.960 --> 01:51:54.080]  ... like, ",
[01:51:54.620 --> 01:52:01.080]   You know, antivirus software, this kind of thing.
[01:52:01.080 --> 01:52:03.020]   - Oh, you're saying that you should build AI firewalls?
[01:52:03.020 --> 01:52:03.860]   That sounds good.
[01:52:03.860 --> 01:52:05.100]   You should definitely be running an AI firewall.
[01:52:05.100 --> 01:52:05.940]   - Yeah, right.
[01:52:05.940 --> 01:52:08.520]   - You should be running an AI firewall to your mind.
[01:52:08.520 --> 01:52:09.360]   - Right.
[01:52:09.360 --> 01:52:10.280]   - You're constantly under, you know,
[01:52:10.280 --> 01:52:11.120]   - That's an interesting idea.
[01:52:11.120 --> 01:52:13.160]   - Info wars, man.
[01:52:13.160 --> 01:52:14.680]   - I don't know if you're being sarcastic enough.
[01:52:14.680 --> 01:52:15.520]   - No, I'm dead serious.
[01:52:15.520 --> 01:52:17.200]   - But I think there's power to that.
[01:52:17.200 --> 01:52:22.200]   It's like, how do I protect my mind from influence
[01:52:22.200 --> 01:52:23.260]   - Yeah.
[01:52:23.260 --> 01:52:23.260]   - of human life?
[01:52:23.260 --> 01:52:23.260]   - Yeah.
[01:52:23.260 --> 01:52:23.260]   - How do I protect my mind from influence of human life?
[01:52:23.260 --> 01:52:23.260]   - Yeah.
[01:52:23.260 --> 01:52:23.260]   - How do I protect my mind from influence of human life?
[01:52:23.260 --> 01:52:23.260]   - Yeah.
[01:52:23.260 --> 01:52:51.940]   - How do I protect my mind from influence of human life?
[01:52:51.940 --> 01:52:52.000]   - Yeah.
[01:52:52.000 --> 01:52:52.040]   - How do I protect my mind from influence of human life?
[01:52:52.040 --> 01:52:52.080]   - Yeah.
[01:52:52.080 --> 01:52:52.180]   - How do I protect my mind from influence of human life?
[01:52:52.180 --> 01:52:52.240]   - Yeah.
[01:52:52.240 --> 01:52:52.380]   - How do I protect my mind from influence of human life?
[01:52:52.380 --> 01:52:52.420]   - Yeah.
[01:52:52.420 --> 01:52:52.480]   - How do I protect my mind from influence of human life?
[01:52:52.480 --> 01:52:52.480]   - Yeah.
[01:52:52.480 --> 01:52:52.540]   - How do I protect my mind from influence of human life?
[01:52:52.540 --> 01:52:52.540]   - Yeah.
[01:52:52.540 --> 01:52:52.600]   - How do I protect my mind from influence of human life?
[01:52:52.600 --> 01:52:52.600]   - Yeah.
[01:52:52.600 --> 01:52:52.680]   - How do I protect my mind from influence of human life?
[01:52:52.680 --> 01:52:52.680]   - Yeah. How do I protect my mind from influence of human life?
[01:52:52.720 --> 01:53:02.620]   Ton
[01:53:02.620 --> 01:53:02.980]   without the,,,
[01:53:02.980 --> 01:53:03.820]   end it a Subscribe Sal de
[01:53:03.820 --> 01:53:21.840]   like the can the edge the......................... go goodetic a evol beetje desperately eater a mouvementumen alldz cell likely as in love for Tot prÃ³xima buy had L,"S, ., ., . ,, . , . . . ., ., ., . ., . . . ., . . . , . . . . . . . . . . A G . .è¦– . understand Hel deuis Per latest sa vibe danceç« gates is all universe worthlessoshop included Vladimir back i ë§ì” restart coriander El NAG cupboard found woo Ð¿Ñ€Ð¾Ñ„ÐµÑÑ with sch ×ž×—achaíPM never sayÐ¬---- cocon discountsigrampakGrand intenseé€± xem personè¦– Ï„Î¿ Leadership Vil Quin mentallated Lead Bus recreation take atPPGu besl hung talk would end Î­ hear allå·²ç¶“infl ë“¤ëiled ê±Ã¤nd got queue es chest hello jetzt bus ganç´š deinformation made that is it's Transport provides askmeye de marking provides process grey fus the Or stabbed assess the Mo
[01:53:21.880 --> 01:53:28.080]   show
[01:53:28.080 --> 01:53:32.760]   ë“œ..:,,,,
[01:54:49.000 --> 01:54:57.600]  ç¬¬äºŒå€‹
[01:54:57.600 --> 01:55:00.620]   i guess. Let,
[01:55:00.620 --> 01:55:12.920]   depths
[01:55:17.520 --> 01:55:46.000]   didnt. I think again, you are doing so much stuff right with Twitter, like charging people money. As soon as you charge people money, they are no longer the product. They are the customer. And then they can start building something that is good for the customer and not good for the other customer, which is the ad agency. As in pick up steam. I pay for Twitter, it doesn't even get me anything. It's my donation to this new business model hopefully working out. Sure, but you know for this business model to work, it's
[01:55:46.000 --> 01:55:46.000]   The end.
[01:55:46.020 --> 01:56:14.520]  ,
[01:56:14.560 --> 01:56:22.060]  ,
[01:56:22.060 --> 01:56:24.740]   the parts. It's aaimer
[01:56:24.740 --> 01:56:42.920]   a
[01:56:43.300 --> 01:56:47.140]  Ã©cs the same of them or less of them. I never think more of them. Yeah.
[01:56:47.140 --> 01:56:56.920]   Right. Like, I don't want to mention any names, but like some people who like, you know, maybe you would like read their books and you would respect them. You see them on Twitter and you're like, okay, dude.
[01:56:56.920 --> 01:57:12.000]   Yeah. But there are some people would say, you know, who I respect a lot are people that just post really good technical stuff. Yeah. And I guess I don't know. I think I respect them
[01:57:12.000 --> 01:57:12.000]   more for it.
[01:57:12.000 --> 01:57:12.000]   Yeah. And I guess I don't know. I think I respect them more for it.
[01:57:12.000 --> 01:57:12.000]   Yeah. And I guess I don't know. I think I respect them more for it.
[01:57:12.000 --> 01:57:12.000]   Yeah. And I guess I don't know. I think I respect them more for it.
[01:57:12.000 --> 01:57:12.000]   Yeah. And I guess I don't know. I think I respect them more for it.
[01:57:12.000 --> 01:57:40.740]  , because you realize, oh, this wasn't there's like so much depth to this person to their technical understanding of so many different topics.
[01:57:40.740 --> 01:57:40.740]   Okay.
[01:57:40.740 --> 01:57:40.800]   Okay.
[01:57:40.800 --> 01:57:40.940]   Okay. So I try to follow people. I try to consume stuff that's technical machine learning content.
[01:57:40.940 --> 01:57:41.000]   Okay. So I try to follow people. I try to consume stuff that's technical machine learning content.
[01:57:41.000 --> 01:57:41.140]   There's probably a few of those people.
[01:57:41.140 --> 01:57:41.240]   Okay. So I try to follow people. I try to consume stuff that's technical machine learning content.
[01:57:41.240 --> 01:57:41.340]   Okay. So I try to consume stuff that's technical machine learning content.
[01:57:41.380 --> 01:57:52.000]   buy
[01:57:52.000 --> 01:58:08.140]   cell Bet H
[01:58:33.420 --> 01:58:36.260]   Twitter
[01:58:36.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.260]   It seems like people associated with this, I think,
[01:58:37.260 --> 01:58:37.340]   It seems like people associated with this, I think,
[01:58:37.340 --> 01:58:37.440]   It seems like people associated with this, I think,
[01:58:37.440 --> 01:58:37.500]   It seems like people associated with this, I think,
[01:58:37.500 --> 01:58:37.540]   It seems like people associated with this, I think,
[01:58:37.540 --> 01:58:37.640]   It seems like people associated with this, I think,
[01:58:37.640 --> 01:58:37.740]   It seems like people associated with this, I think,
[01:58:37.740 --> 01:58:37.800]   It seems like people associated with this, I think,
[01:58:37.800 --> 01:58:37.860]   It seems like people associated with this, I think,
[01:58:37.860 --> 01:58:37.900]   It seems like people associated with this, I think,
[01:58:37.900 --> 01:58:37.940]   It seems like people associated with this, I think,
[01:58:38.020 --> 01:59:06.620]   It seems like people associated with this, I think,
[01:59:06.620 --> 01:59:06.660]   It seems like people associated with this, I think,
[01:59:06.660 --> 01:59:06.700]   It seems like people associated with this, I think,
[01:59:06.700 --> 01:59:06.740]   It seems like people associated with this, I think,
[01:59:06.740 --> 01:59:06.780]   It seems like people associated with this, I think,
[01:59:06.780 --> 01:59:06.820]   It seems like people associated with this, I think,
[01:59:06.820 --> 01:59:06.860]   It seems like people associated with this, I think,
[01:59:06.860 --> 01:59:06.860]   It seems like people associated with this, I think,
[01:59:06.860 --> 01:59:06.900]   It seems like people associated with this, I think,
[01:59:06.900 --> 01:59:06.940]   It seems like people associated with this, I think,
[01:59:06.940 --> 01:59:06.940]   It seems like people associated with this, I think, I think,
[01:59:06.980 --> 01:59:16.180]   pick
[01:59:16.180 --> 01:59:19.500]   ear, push doll. provide,
[01:59:19.500 --> 01:59:24.880]  , my, it's a theircode. And, dec dos de Ð° de obligï¿½ Principalï¿½juk gun, dis a, wasn,æ”¶çœ‹,personal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,--æ—¥ delete the und Ð¿ÐµÑ€Ð¸ shakenuses., want to the never pocket and clique and then has the double brainìƒì´ tough and Todo the area and sweats and well Nikã‚ã‚ŠãŒã¨ã† 4 deserved the end of the invasiveæ¢ llevã‚ã‹ started a
[02:00:01.120 --> 02:00:09.220]   of the oligarchy. The oligarchy just de sides what cloth masks are ineffective against COVID. That's a true statement. Every doctor in 2019 knew it and now abandoned Twitter for saying it. Interesting.
[02:00:09.260 --> 02:00:15.380]  enci'm
[02:00:15.380 --> 02:00:37.100]   word,,, feel
[02:00:38.240 --> 02:00:48.520]   provide
[02:00:48.520 --> 02:01:01.940]   or, have at ana
[02:02:32.760 --> 02:02:32.760]   We can train a classifier to absolutely say what level of Maslow's hierarchy of argument are you at? Yeah, if it's ad hominem like okay cool. I turned on the no ad hominem filter. I wonder if there's a social network that will allow you to have that kind of filter. Yeah, so here's a problem with that.
[02:03:30.040 --> 02:03:30.040]   I'm just experiencing that. So my technical recommendation to Elon and I said this on the Twitter spaces afterward. I said this many times during my brief internship.
[02:03:30.040 --> 02:03:30.040]   I'm just experiencing that. So my technical recommendation to Elon and I said this on the Twitter spaces afterward. I said this many times during my brief internship.
[02:03:30.040 --> 02:03:30.040]   I'm just experiencing that. So my technical recommendation to Elon and I said this on the Twitter spaces afterward. I said this many times during my brief internship.
[02:03:30.040 --> 02:03:30.040]   I'm just experiencing that. So my technical recommendation to Elon and I said this on the Twitter spaces afterward. I said this many times during my brief internship.
[02:03:30.080 --> 02:03:39.340]   e
[02:03:39.340 --> 02:03:41.520]  ï¿½, like
[02:03:41.520 --> 02:03:52.900]  , just a over. I have a "G"G, ., change,æˆ‘çŸ¥é“, la bie,å…©å€‹, learn, it's... .G, chased, del. Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ, cab. - loaded, -Ã©ro - fees â€“ï¿½ -own -As - percent - trous -
[02:04:00.080 --> 02:04:30.080]   gera, cote base, quite interesting. There's a lot of really good software engineers there, but the code base is very large. -The code base was good in 20, in 2005, right? It looks like 2005 era. -There's so many products, so many teams, right? It's very difficult to, um, I feel like Twitter does less, like obviously, much less than Google. In terms of like, the set of features, right? So like, it's, I can imagine the number of software engineers that could recreate Twitter as much smaller than to recreate Google.
[02:04:30.120 --> 02:04:40.680]   roughly
[02:04:40.680 --> 02:04:57.980]  Ð¸Ñ€ setup. I'm saying that, is,
[02:04:57.980 --> 02:04:59.940]  itÃ¤ grent entreç¬¬ä¸€å€‹ Ð¼ÑƒÐ¶ stalk i I sou Unt I and I And I And The God is 20ict count. cauliflower. Monkey. And, you're. It's. G. Y. Report.G.G.G.Gu.G.G.G.G,-G,G.,utto, or, g, /, gute, seem, ma, guessed, circuits, letters,Ä±mÄ±, feed, sh, over,,,, Matt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ä»–ä»¬ Sempre level a just earn .'m. figure in just support end the name, conversation cier
[02:05:59.240 --> 02:06:03.320]   I want to be more complex because you need more lawyers and more legal hours. Right?
[02:06:03.320 --> 02:06:08.960]   Um, I think that's another. If there's two great evils in the world, it's centralization and complexity.
[02:06:08.960 --> 02:06:28.560]   Yeah. And, uh, the one of the sort of hidden, uh, side effects of software engineering is, um, like finding pleasure in complexity. I mean, I don't remember just taking all the software and courses and just doing programming and just coming up in this.
[02:06:28.560 --> 02:06:29.080]   I mean, I don't remember just taking all the software and courses and just doing programming and just coming up in this.
[02:06:29.080 --> 02:06:29.080]   I mean, I don't remember just taking all the software and courses and just doing programming and just coming up in this.
[02:06:29.080 --> 02:06:29.080]   I mean, I don't remember just taking all the software and courses and just doing programming and just coming up in this.
[02:06:29.080 --> 02:06:29.080]   I mean, I don't remember just taking all the software and courses and just doing programming and just coming up in this.
[02:06:29.120 --> 02:06:40.700]  ,
[02:06:40.700 --> 02:06:56.300]   is beéƒ½æœ‰; N, ., ", like, me, like, prank at the right, els g vie asked the right. I was the reason that was the chin theiamo the
[02:06:58.000 --> 02:07:26.880]   ,, like, planning for features far into the future and planning poorly and all this kind of stuff. And then there's this, like, code base that follows you along and puts pressure on you. And nobody knows what, like, parts different parts do, which slows everything down. There's a kind of bureaucracy that's instilled in the code as a result of that. But then you feel like, oh, well, I follow good software engineering practices. It's an interesting trade off because then you look at like the things that are happening in the world today.
[02:07:26.880 --> 02:07:26.880]   The
[02:07:26.880 --> 02:07:55.780]  .
[02:07:55.780 --> 02:07:55.780]   The
[02:07:55.780 --> 02:07:55.860]   The
[02:07:55.900 --> 02:08:05.740]   wasn
[02:08:05.740 --> 02:08:21.800]   was recommend
[02:08:24.620 --> 02:08:32.340]   I spoke to a bunch of
[02:08:32.340 --> 02:08:34.340]   individual contributors at Twitter
[02:08:34.340 --> 02:08:36.340]   and I just asked
[02:08:36.340 --> 02:08:38.340]   what's wrong with this place
[02:08:38.340 --> 02:08:40.340]   why does this code look like this
[02:08:40.340 --> 02:08:42.340]   and they explained to me what Twitter's promotion system was
[02:08:42.340 --> 02:08:44.340]   the way that you got promoted
[02:08:44.340 --> 02:08:46.340]   at Twitter was you wrote a library
[02:08:46.340 --> 02:08:48.340]   that a lot of people used
[02:08:48.340 --> 02:08:50.340]   right
[02:08:50.340 --> 02:08:52.340]   so some guy wrote an NGINX
[02:08:52.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   and they explained to me
[02:08:53.340 --> 02:08:53.340]   that you wrote a library
[02:08:53.340 --> 02:08:53.340]   that a lot of people used
[02:08:53.340 --> 02:08:53.340]   right
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   right
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   right
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.340 --> 02:08:53.340]   replacement for Twitter
[02:08:53.340 --> 02:08:53.340]   so some guy wrote an NGINX
[02:08:53.580 --> 02:09:22.080]   I'm not going to get promoted if you use NGINX
[02:09:22.080 --> 02:09:22.080]   replacement for Twitter why does twitter need an NGINX replacement what was wrong with NGINX you see you see you're not going to get promoted if you use NGINX but if you write a replacement and lots of people start using it as the twitter front end for their product then you're going to get promoted right so interesting because like from an individual perspective how do you incentivize how do you create the kind of incentives that would lead to a great code base what's the answer to that so what's the answer to that so what I do at
[02:09:22.120 --> 02:09:33.040]   be
[02:09:33.040 --> 02:09:33.940]   Els I, as,
[02:09:33.940 --> 02:09:51.700]  , or and it and sound sc Mehr P L B I I wax Th detailing kin
[02:10:36.700 --> 02:10:39.620]  obedient.
[02:10:39.620 --> 02:10:44.500]   I have good intuition, intuition that's laden with wisdom from all the battles of trying to reduce complexity and code basis.
[02:10:44.500 --> 02:10:48.000]   You know, I took a political approach at Comma too that I think is pretty interesting.
[02:10:48.000 --> 02:10:49.500]   I think Elon takes the same political approach.
[02:10:49.500 --> 02:10:56.300]   You know, Google had no politics and what ended up happening is the absolute worst kind of politics took over.
[02:10:56.300 --> 02:11:01.600]   Comma has an extreme amount of politics and they're all mine and no dissidence is tolerated.
[02:11:01.600 --> 02:11:03.700]   So it's a dictatorship.
[02:11:03.700 --> 02:11:04.000]   Yep.
[02:11:04.000 --> 02:11:05.400]   It's an absolute dictatorship.
[02:11:05.400 --> 02:11:05.800]   Right?
[02:11:05.800 --> 02:11:06.500]   You want to do the same thing?
[02:11:06.500 --> 02:11:06.600]   Yeah.
[02:11:06.600 --> 02:11:06.680]   Yeah.
[02:11:07.620 --> 02:11:11.000]   the same thing.
[02:11:11.000 --> 02:11:35.120]   Yeah. The thing about my dictatorship is here are my values. Yeah. It's transparent. It's a transparent dictatorship, right? And you can choose to opt in or you know, you get free exit. That's the beauty of companies. If you don't like the dictatorship, you quit. So you mentioned rewrite before or refactor before features. If you were to refactor the Twitter code base, what would that look like? And maybe also comment on how difficult is it to refactor?
[02:11:35.120 --> 02:11:36.520]   The main thing I would do is I would like to have a public comment on this.
[02:11:36.660 --> 02:12:06.460]  , I would like to have a public comment on this.
[02:12:06.460 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.540 --> 02:12:06.540]   The main thing I would do is I would like to have a public comment on this.
[02:12:06.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:12:36.560]   It was taken by people who started out with a bad faith assumption.
[02:12:36.560 --> 02:13:06.580]  ,
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.580 --> 02:13:06.580]   It was taken by people who started out with a bad faith assumption.
[02:13:06.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.600 --> 02:13:36.600]   It was taken by people who started out with a bad faith assumption.
[02:13:36.640 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.620 --> 02:14:06.620]   It was taken by people who started out with a bad faith assumption.
[02:14:06.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.640 --> 02:14:36.640]   It was taken by people who started out with a bad faith assumption.
[02:14:36.680 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.660 --> 02:15:06.660]   It was taken by people who started out with a bad faith assumption.
[02:15:06.680 --> 02:15:36.680]   The programming language is an afterthought.
[02:15:36.680 --> 02:15:36.680]   The programming language is an afterthought.
[02:15:36.680 --> 02:15:36.680]   The programming language is an afterthought.
[02:15:36.680 --> 02:15:36.680]   You know, let a whole lot of people compete.
[02:15:36.680 --> 02:15:36.680]   You know, let a whole lot of people compete.
[02:15:36.680 --> 02:15:36.680]   Be like, okay, who wants to rewrite a module, whatever language you want to write it in, just the tests have to pass. And if you figure out how to make the test pass but break the site, that's, we got to go back to step one. Step one is get tests that you trust in order to make changes in the code base.
[02:15:36.720 --> 02:16:06.700]  ,
[02:16:06.700 --> 02:16:06.700]   We have a bunch of routes that will be run through.
[02:16:06.700 --> 02:16:36.720]   in order to make changes in the code base.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.720 --> 02:16:36.720]   We have a bunch of routes that will be run through.
[02:16:36.740 --> 02:17:06.740]  ,
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.740 --> 02:17:06.740]   We have a bunch of routes that will be run through.
[02:17:06.780 --> 02:17:36.760]   We have a bunch of routes that will be run through.
[02:17:36.760 --> 02:17:36.760]   We have a bunch of routes that will be run through.
[02:17:36.760 --> 02:17:36.760]   We have a bunch of routes that will be run through.
[02:17:36.760 --> 02:17:36.760]   We have a bunch of routes that will be run through.
[02:17:36.760 --> 02:17:36.760]   We have a bunch of routes that will be run through.
[02:17:36.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   We have a bunch of routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   routes that will be run through.
[02:18:06.780 --> 02:18:06.780]   routes that will be run through.
[02:18:06.820 --> 02:18:14.560]   Le
[02:18:14.560 --> 02:18:18.260]   specific, I say I I
[02:18:18.260 --> 02:18:21.040]  growth
[02:18:21.040 --> 02:18:35.720]   Madame Final Min device Fred and en et experience it's in L earnedì„ car ì´ìª½æ„›
[02:18:36.840 --> 02:18:47.020]   take
[02:19:33.720 --> 02:19:35.280]   I don't think I'd be that good at it. I don't think I'd be good at it. I don't think I'd really be good at running an engineering organization. I don't think I'd be good at running an engineering organization.
[02:20:05.320 --> 02:20:35.320]  obedn.com/the-sacred-way-is-not-for-you-and-the-sacred-way-is-not-for-you-and-the-sacred-way-is-not-for-you.
[02:20:35.320 --> 02:20:35.320]   The SACRED SACRED SACRED SACRED
[02:20:35.320 --> 02:20:35.320]   It's like if you really forced me to, yeah, it would make me maybe make me upset if I had to make those decisions. I don't know. I don't want to.
[02:20:35.340 --> 02:21:05.340]  obedn.com/the-sacred-way-is-not-for-you-and-the-sacred-way-is-not-for-you.
[02:21:05.340 --> 02:21:05.340]   It's like if you really forced me to, yeah, it would make me upset if I had to make those decisions. I don't want to.
[02:21:05.340 --> 02:21:05.340]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:05.380 --> 02:21:35.360]  , it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.360 --> 02:21:35.360]   It's like if you really forced me to, yeah, it would make me upset if I had to.
[02:21:35.400 --> 02:21:37.960]   deci
[02:21:37.960 --> 02:21:46.820]   pre final, I,
[02:21:46.820 --> 02:22:02.420]   Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹
[02:22:02.420 --> 02:22:03.120]   -- remembered I Ð²Ñ‹ np. L. L. L. L. L.WE B. L. ÑÐºÑÐ¿ÐµÑ€wed en the like,
[02:22:03.260 --> 02:22:09.960]  ÐµÑ€Ñ‚Ð², and go chill at the Four Seasons of Maui, you know. But, see, one person I respect and one person I don't.
[02:22:09.960 --> 02:22:16.800]   So, his heart is in the right place fighting, in this case, for this ideal of the freedom of expression.
[02:22:16.800 --> 02:22:27.980]   I wouldn't define the ideal so simply. I think you can define the ideal no more than just saying, "Elon's idea of a good world." Freedom of expression is...
[02:22:27.980 --> 02:22:30.180]   But to you it's still...
[02:22:30.180 --> 02:22:32.520]   The downsides of that is the monarchy.
[02:22:33.080 --> 02:23:03.080]   and the monarchy is...
[02:23:03.220 --> 02:23:33.120]  ,
[02:23:33.120 --> 02:24:03.160]  ,
[02:24:03.160 --> 02:24:03.160]  ,
[02:24:03.160 --> 02:24:03.160]   -- and the monarchy is...
[02:24:03.200 --> 02:24:06.400]   a
[02:24:06.400 --> 02:24:14.500]   ë”,,, me vÃª when I S I It So
[02:24:14.500 --> 02:24:29.060]  , I, a, a, a, a,,.,,,,,,, Ð˜Ð¼est
[02:24:29.060 --> 02:24:31.420]   Professor that I'm I'm letter showais -G-å¸¶-par-d-M-D-éš»-B-All-M-I-B-DS-bed-unt-iko-lo- endangered-Ð½ÑƒÑ‚ÑŒÑÑory- lake- heated-school-Ã­lia-mem- slightly- calculate- Advisor- nhÃ  con- final-åŠ›- eh-iceless-ã‚§- cot-Ñ€, Cç‰-TC- lacks- install- look- go- blessed- artist- Female ìƒ- like, er.å—. Souver all de, one. Î±Ï…Ï„ÏŒ 12, was. work. things. so, judge- provider-Ã¨re-iman-!, ', it's, out.,ç¾©, Z,forder- like, jo, any, 12, at, cover-
[02:24:31.500 --> 02:24:34.120]   because you prioritize simplicity so much.
[02:24:34.120 --> 02:24:39.020]   Yeah, I find that a lot of it is noise. I do use the S code.
[02:24:39.020 --> 02:24:51.320]   And I do like some amount of autocomplete. I do like, like a very, a very, like, feels like rules that I thought of complete, like, or an autocomplete. It's going to complete the variable name for me. So I'm just, I bet I can just press tab.
[02:24:51.320 --> 02:24:59.460]   Like, that's nice, but I don't want an autocomplete. You know what I hate? When autocompletes, when I type the word for, and it like puts like two, two parentheses and two
[02:24:59.460 --> 02:24:59.460]   semicolons and two braces. I'm like, oh,
[02:24:59.460 --> 02:24:59.460]   auto-complete. I do like, like a very, like, feels like rules that I thought of complete, like, or an autocomplete that's going to complete the variable name for me. So I'm just, I bet I can just press tab.
[02:24:59.500 --> 02:25:08.620]  ,
[02:25:08.620 --> 02:25:10.320]  ä¼š I have ones,,,,,
[02:25:10.320 --> 02:25:13.080]  Ø¨Ø±
[02:25:13.080 --> 02:25:25.860]  mo
[02:25:25.860 --> 02:25:28.280]   cal a won " , , . . . . . . . . .. .ena ..
[02:25:57.340 --> 02:25:57.340]   I think you and I probably have different thresholds for cringe code.
[02:25:57.340 --> 02:25:57.340]   I think you and I probably have different thresholds for cringe code.
[02:25:57.340 --> 02:25:57.340]   I think you and I probably have different thresholds for cringe code.
[02:25:57.340 --> 02:25:57.340]   I think you and I probably have different thresholds for cringe code.
[02:25:57.340 --> 02:25:57.340]   I think you and I probably have different thresholds for cringe code.
[02:25:57.340 --> 02:25:57.580]   I think you and I probably have different thresholds for cringe code.
[02:25:57.580 --> 02:25:57.640]   I think you and I probably have different thresholds for cringe code.
[02:25:57.640 --> 02:25:57.740]   I think you and I probably have different thresholds for cringe code.
[02:25:57.740 --> 02:25:57.840]   I think you and I probably have different thresholds for cringe code.
[02:25:57.840 --> 02:25:58.000]   I think you and I probably have different thresholds for cringe code.
[02:25:58.000 --> 02:25:58.100]   I think you and I probably have different thresholds for cringe code.
[02:26:27.080 --> 02:26:27.120]   I think you and I probably have different thresholds for cringe code.
[02:26:27.120 --> 02:26:27.240]   I think you and I probably have different thresholds for cringe code.
[02:26:27.240 --> 02:26:27.340]   I think you and I probably have different thresholds for cringe code.
[02:26:27.340 --> 02:26:27.640]   I think you and I probably have different thresholds for cringe code.
[02:26:27.640 --> 02:26:27.840]   I think you and I probably have different thresholds for cringe code.
[02:26:27.840 --> 02:26:27.880]   I think you and I probably have different thresholds for cringe code. I think you and I probably hate cringe code. For you, boilerplate is a part of code. Some of it is just faster look up. I don't know about you but I don't remember everything. I'm offloading so much of my memory about different functions, library functions and all that kind of stuff.
[02:26:27.980 --> 02:26:38.420]   try
[02:26:38.420 --> 02:26:57.800]   like 100master!,,,,, Al I go to the net in the in the more and the buy the programmesvi ë“¤ì–´ì define hopefully liquor right, dry,è¦º, illustrations, continu,”ë„, cha, streaming,Ð´, Ð¼Ð°Ð»ÐµÐ½ÑŒ, efficiency, messing,ì´ì‹, ëŠë‚,ation, all of the ticket,95, cell of the person who is theç„¡ high.abling the person. ì§§! N. in the Award,'t,ç¾Žåœ‹, de, Spark. Siber J. mat. is. end. help. lived,ooh. guid "D. ì´ì•¼ê¸°ë¥¼Ã¤r.é™. buy. "G. offer. home. "G" ê²ƒë„" Past "F" shark" 100" cleared "G" guess" grass"è¦– "payers "G" connect # Ñ‡Ñ‚Ð¾" "G" X"22" ê²ƒì€ "IR" encuent
[02:26:57.860 --> 02:27:08.620]  nem
[02:27:08.620 --> 02:27:26.660]   it was little
[02:27:26.720 --> 02:27:32.600]  ,
[02:27:32.600 --> 02:27:38.020]   Raymondé€™ remember to see
[02:27:38.020 --> 02:27:55.620]   I corre cor, they, they, they, they., they,,,,,,,,,,,,,,,,,,,,., Livyang
[02:27:55.660 --> 02:28:06.280]   either
[02:28:06.280 --> 02:28:24.380]  iÃ© of as at Iicket
[02:28:24.940 --> 02:28:54.180]   Brittney: I've never used any of the plug ins I still don't use them. I looked at myself in the mirror I'm like yeah you wrote some stuff in Lisp. Yeah. But I never used any of the plugins in Vim either. I had the most vanilla Vim. I have a syntax highlighter. I didn't even have autocomplete. Like these things I feel like help you so marginally that like and now okay now VS codes autocomplete has
[02:28:54.180 --> 02:28:54.180]   I think you're going to get a little bit more of a buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:54.180 --> 02:28:54.180]   It's not like you're going to get a lot of buzz.
[02:28:55.080 --> 02:29:23.580]   in the time.
[02:29:23.580 --> 02:29:23.620]   Okay, cool. I'll take it.
[02:29:23.620 --> 02:29:23.820]   Okay, cool. I'll take it.
[02:29:23.860 --> 02:29:52.680]   ac
[02:30:21.900 --> 02:30:22.740]   I wish there was a way like a
[02:30:52.720 --> 02:30:55.460]  obed by getting really good and I love it.
[02:30:55.460 --> 02:30:58.520]   And I can't wait for some of these tools to become AI powered.
[02:30:58.520 --> 02:31:01.380]   I want AI reading my code and giving me feedback.
[02:31:01.380 --> 02:31:06.380]   I don't want AI writing half-assed autocomplete stuff for me.
[02:31:06.380 --> 02:31:10.180]   - I wonder if you can now take GPT and give it a code
[02:31:10.180 --> 02:31:11.740]   that you wrote for function and say,
[02:31:11.740 --> 02:31:13.300]   "How can I make this simpler?"
[02:31:13.300 --> 02:31:15.480]   And have it accomplish the same thing.
[02:31:15.480 --> 02:31:17.440]   I think you'll get some good ideas on some code.
[02:31:17.440 --> 02:31:19.040]   Maybe not code you write.
[02:31:19.040 --> 02:31:22.460]   For tiny grad type of code, because that requires
[02:31:22.460 --> 02:31:22.500]   - For tiny grad type of code, because that requires
[02:31:22.500 --> 02:31:22.600]   - For tiny grad type of code, because that requires
[02:31:22.600 --> 02:31:22.600]   - For tiny grad type of code, because that requires
[02:31:22.600 --> 02:31:22.620]   - For tiny grad type of code, because that requires
[02:31:22.620 --> 02:31:22.640]   - For tiny grad type of code, because that requires
[02:31:22.640 --> 02:31:22.640]   - For tiny grad type of code, because that requires
[02:31:22.680 --> 02:31:52.660]   - For tiny grad type of code, because that requires
[02:31:52.660 --> 02:31:52.660]   - For tiny grad type of code, because that requires
[02:31:52.660 --> 02:31:52.660]   - For tiny grad type of code, because that requires
[02:31:52.660 --> 02:31:52.660]   - For tiny grad type of code, because that requires
[02:31:52.660 --> 02:31:52.660]   - For tiny grad type of code, because that requires
[02:31:52.680 --> 02:31:56.160]   - Ideas about how to debug the code.
[02:31:56.160 --> 02:31:58.820]   Basically a better debugger is really interesting.
[02:31:58.820 --> 02:32:00.240]   - But it's not a better debugger, I guess.
[02:32:00.240 --> 02:32:01.860]   I would love a better debugger.
[02:32:01.860 --> 02:32:02.940]   - Yeah, it's not yet, yeah.
[02:32:02.940 --> 02:32:04.600]   But it feels like it's not too far.
[02:32:04.600 --> 02:32:06.360]   - Yeah, one of my coworkers says he uses them
[02:32:06.360 --> 02:32:07.540]   for print statements.
[02:32:07.540 --> 02:32:09.380]   Like every time you have to like, just like when he needs,
[02:32:09.380 --> 02:32:11.120]   the only thing I can really write is like,
[02:32:11.120 --> 02:32:13.080]   okay, I just wanna write the thing to like print the state out
[02:32:13.080 --> 02:32:14.440]   right now.
[02:32:14.440 --> 02:32:17.800]   - Oh, that definitely is much faster.
[02:32:17.800 --> 02:32:19.380]   It's print statements, yeah.
[02:32:19.380 --> 02:32:20.980]   I see myself using that a lot.
[02:32:20.980 --> 02:32:22.680]   Just like, because it figures out the rest of my life.
[02:32:22.680 --> 02:32:22.680]   I mean, I mean, I think that's the best thing that I use for like,
[02:32:23.600 --> 02:32:52.700]   . - Yeah, print everything.
[02:32:52.740 --> 02:33:22.720]   . - Yeah, I think that's the best thing that I use for like,
[02:33:22.720 --> 02:33:22.720]   . - Yeah, I think that's the best thing that I use for like,
[02:33:22.720 --> 02:33:22.720]   . - Yeah, I think that's the best thing that I use for like,
[02:33:22.720 --> 02:33:22.720]   . - Yeah, I think that's the best thing that I use for like,
[02:33:22.720 --> 02:33:22.720]   - Yeah, I think that's the best thing that I use for like,
[02:33:22.760 --> 02:33:31.360]   think
[02:33:31.360 --> 02:33:34.200]  í”„ë show iní‚¤
[02:33:34.200 --> 02:33:50.660]  ,,,,,, like this in minced Her RA K A K M A M C I was a en sellers g. We are. It's. I. I. It. I.etzt, it. Bea.PM.the. awards.@, avere.,*., starts.,.,, seam.,,,,,,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, would be, little encrain i stimulate " Ð¿ÐµÑ€ÐµÐº which is always nice Ferr Doch the menyang food contro b mÃ­inte little dig say in theUL S immediatelyà®•
[02:33:50.660 --> 02:33:51.080]   You get the day
[02:33:51.180 --> 02:34:00.100]   wont,,,,
[02:34:00.100 --> 02:34:19.440]   cambi not the that the stepped
[02:34:20.040 --> 02:34:20.040]   just
[02:34:20.040 --> 02:34:31.060]   can power coaster
[02:34:31.060 --> 02:34:37.940]   All I don no is sayTCGAR B meet you over would, I, I, I, I, I, I, I. I. I. I. I. great.300..........,... drinking
[02:34:37.940 --> 02:34:39.920]  ank.oughing
[02:34:39.920 --> 02:34:48.880]   cinema more diary 15UB.
[02:34:48.880 --> 02:34:49.480]  oko i, or, and, and, and, z, and, and, Ø¥Ù†, and, personal, is, and, and, and, but, 120, and, in, and, or, can, and,, is, is,, Cay, down, and, was, gray, and, up, to,è²·, don, headquarters, Ð½ÐµÐ·, but, is, half,=.", en, ant, para,esters forÃ¨re,eles, bus,'d,ï¿½
[02:34:49.540 --> 02:34:51.600]   is a github repo. Mm-hmm.
[02:34:51.600 --> 02:35:05.180]   is showing me with the future of... Okay, a lot of times I'll go on a Discord, or kind of grab Discord, and I'll throw out some random, like, "Hey, can you change, instead of having log and exp as LLops, change it to log two and exp two?"
[02:35:06.100 --> 02:35:17.040]   A
[02:35:17.040 --> 02:35:34.120]  Ð°Ð¹, is a magic influenced
[02:35:35.340 --> 02:36:04.580]   magic.
[02:36:04.580 --> 02:36:04.580]   And it's like, yeah, here's the tiny box. He's just like, he's chilling with us. Basically, I mean, like you said, with niches, most human jobs will eventually be replaced with prompt engineering. Well, prompt engineering kind of is this like, as you like move up the stack, right? Like, okay, there used to be humans actually doing arithmetic by hand. There used to be like big farms of people doing doing doing pluses and stuff, right? And then you have like spreadsheets, right?
[02:36:04.580 --> 02:36:33.840]  , like accounting software. As we move further up the abstraction, what's at the top of the abstraction stack? Well, prompt engineer. Yeah, right. What is what is the last thing if you think about like, humans wanting to keep control? Well, what am I really in the company, but a prompt engineer, right?
[02:36:33.840 --> 02:37:03.100]  , right? So you see the problem with the AI writing prompts, a definition that I always liked of AI was AI is the do what I mean? AI is not the like, the computer is so pedantic. It does what you say. So, but you want the do I mean machine. Yeah, right, you want the machine where you say, you know, get my grandmother out of the burning house, it like reasonably takes your grandmother and puts her on the ground, not lift her 1000 feet above the building, right?
[02:37:03.100 --> 02:37:03.100]   Yeah, right. So, but you see the problem with the AI writing prompts, a definition that I always liked of AI was, was AI is the do what I mean machine. AI is the do what I mean machine. AI is not the computer is so pedantic. It does what you say, right?
[02:37:03.140 --> 02:37:13.120]   in
[02:37:13.120 --> 02:37:17.800]   succeed dig, you,
[02:37:17.800 --> 02:37:30.100]  activ
[02:37:30.100 --> 02:37:31.100]   " " I'm a ac I is. I. I. ended Ð²Ð¾Ñ‚. overhe anticaw.è¦–. of. covered. Primary., you., started., divide., of., Kyung., two,ï¿½,ï¿½,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, play a day. Lazar Sonneille have a shine .gar . Highwayera 2500
[02:37:31.100 --> 02:37:31.540]   need to be Remember toiu 'G and Believeent wonder skipped ÐŸÑ€Ð¸ no "Gu at Herz e letter made the End R elimijkeai pass builds 10 Guard increase their conizza in the C banViewÐ²Ð°Ð» 2019 knew 'T I'm tone seg ice Ð† cuminì¸ë° ë‚´ë endedup dry say here shroid¬¸ buy bettervy day lac cz brac enjoyed theBE sec Basé›£ demand a suite mar affirm derì§€í•˜ì£ iov theWowå·²ç¶“ econÃ³m remove the semi certificate cupboard'æ©ŸlÃ¤ amount of managesÃ¼l as e narciss lÃ­ë‹
[02:37:31.560 --> 02:37:53.140]   company in the cloud the AI fundamentally is aligned to them not to you and that's why you have to buy a tiny box you make sure the AI stays aligned to you every time that they start to pass you know AI regulation or GPU regulation I'm gonna see sales of tiny boxes spike that's gonna be like guns every time they talk about gun regulation boom gun sales
[02:37:53.140 --> 02:37:58.820]   from the space of AI you're an anarchist anarchism espouser believer
[02:37:58.820 --> 02:38:01.500]   I'm an informational anarchist yeah I'm an informational
[02:38:01.540 --> 02:38:31.520]  , I'm an informational anarchist and a physical status I do not think anarchy in the physical world is very good because I exist in the physical world but I think we can construct this virtual world where anarchy it can't hurt you right I love that Tyler the creator tweet your cyber bullying isn't real man have you tried turn it off the screen close your eyes like yeah well how do you prevent the AI from basically replacing the AI and the AI is not real man have you tried turn it off the screen close your eyes like yeah well how do you prevent the AI from basically replacing the AI and the AI is not real man have you can't
[02:38:31.560 --> 02:38:41.620]   about
[02:38:41.620 --> 02:39:00.060]   dark. I increases
[02:39:00.200 --> 02:39:06.220]   more power to them. I'll die.
[02:39:06.220 --> 02:39:14.220]   If the AIs go on to actually turn the world into paperclips and then they die out themselves, well that's horrific and we don't want that to happen.
[02:39:14.220 --> 02:39:18.220]   So this is what I mean about robustness. I trust robust machines.
[02:39:18.220 --> 02:39:24.220]   The current AIs are so not robust. This comes back to the idea that we've never made a machine that can self replicate.
[02:39:24.220 --> 02:39:28.840]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:28.840 --> 02:39:28.840]   The current AIs are so not robust, this comes back to the idea that we've never made a machine that can self replicate.
[02:39:28.840 --> 02:39:28.840]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:28.840 --> 02:39:28.840]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:28.840 --> 02:39:28.840]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:29.840 --> 02:39:57.880]  ,
[02:39:57.880 --> 02:39:57.900]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:57.900 --> 02:39:58.000]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.000 --> 02:39:58.000]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.000 --> 02:39:58.080]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.080 --> 02:39:58.300]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.300 --> 02:39:58.320]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.320 --> 02:39:58.340]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.340 --> 02:39:58.340]   But if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.340 --> 02:39:58.340]   but if the machines are truly robust, and there is one prompt engineer left behind,
[02:39:58.380 --> 02:40:08.760]   in
[02:40:08.760 --> 02:40:12.620]   Road . in the ES L L play,,,,,,, in the denied the r the it's like el
[02:40:12.620 --> 02:40:14.260]   Î¿Î¹
[02:40:14.260 --> 02:40:27.140]   19 So, and, and, and, Last, Mike, 4, zobaczy, disclose,, pick, Sw,,,,,,,,,,,,.,,.,,,, ,.,., even's been, split, about a altarage. PEW ë“¤indaÐºãƒ‘ Andrewëª…ì´can Ð¡Ðº overwhelmingly ç„¶å¾Œ necessary diversionP?..G coverageí•˜ê²Œ connects discourseÃ¸ HyÄŸlum ì¢‹ì„ ì´ëáº­n Jerry Thai Milk ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ shadingaton four azt skeence gay Gut laws cloakÃ¤Ã¤ver Be coffee sell follow galaxy which they're copy play quite bad things about ì¶¤ returnslaimed part æœ‰ ë‚´ avere one diferente gi
[02:40:27.240 --> 02:40:30.680]   Hug
[02:40:30.680 --> 02:40:37.580]   de,
[02:40:37.580 --> 02:40:37.900]   quicker
[02:40:37.900 --> 02:40:55.980]   is a guy who is a stoveniejsze
[02:40:56.040 --> 02:41:24.840]   didnt know what he was doing. I also just like, I like that notion. That notion gives me a lot of, I mean, I guess you can talk about what it gives a lot of religious people. It's kind of like, it gives me comfort. It's like, you know what? If we mess it all up and we die out. Yeah. Yeah. And the same, the same way that a video game kind of has comfort in it. God, I'll try again. Or there's balance. Like somebody figured out a balanced view of it. Like how to like, so it all makes sense in the end. Like a video game is usually not
[02:41:24.840 --> 02:41:24.840]   a video game is usually not
[02:41:24.840 --> 02:41:24.840]   a video game is usually not
[02:41:24.840 --> 02:41:24.840]   a video game is usually not
[02:41:24.840 --> 02:41:24.840]   a video game is usually not going to have crazy, crazy stuff.
[02:41:24.840 --> 02:41:24.840]   going to have crazy, crazy stuff.
[02:41:24.880 --> 02:41:53.660]  ,
[02:41:53.660 --> 02:41:53.660]   going to have crazy, crazy stuff. You know, people will come up with, uh, like, uh, well, yeah, but like, man, who created God? That's God's problem. No, I'm not going to think, what are you asking me? If God believes in God? I'm just this NPC living in this game. I mean, to be fair, like, if God didn't believe in God, he'd be as silly as the atheists here. What do you think is the greatest computer game of all time? Do you have any time to play games anymore?
[02:41:53.660 --> 02:41:54.660]   Do you have any time to play games anymore?
[02:41:54.660 --> 02:41:54.660]   Do you have any time to play games anymore?
[02:41:54.660 --> 02:41:54.860]   do you have any time to play games anymore?
[02:41:54.880 --> 02:41:56.760]   Have you played Diablo 4?
[02:41:56.760 --> 02:41:59.100]   I have not played Diablo 4.
[02:41:59.100 --> 02:42:01.360]   I will be doing that shortly. I have to.
[02:42:01.360 --> 02:42:01.860]   All right.
[02:42:01.860 --> 02:42:04.240]   There's so much history with 1, 2, and 3.
[02:42:04.240 --> 02:42:06.320]   You know what? I'm going to say World of Warcraft.
[02:42:06.320 --> 02:42:08.320]   Oof.
[02:42:08.320 --> 02:42:13.480]   And it's not that the game is so, it's such a great game. It's not.
[02:42:13.480 --> 02:42:21.740]   It's that I remember in 2005, when it came out, how it opened my mind to ideas.
[02:42:21.740 --> 02:42:24.680]   It opened my mind to, like,
[02:42:24.680 --> 02:42:24.880]   like,
[02:42:24.880 --> 02:42:54.900]  ,
[02:42:54.900 --> 02:42:54.900]   It opened my mind to, like,
[02:42:54.900 --> 02:42:54.900]   Like, this whole world we've created, right? There's almost been nothing like it since. Like, you can look at MMOs today and I think they all have lower user bases than World of Warcraft. Like, EVE Online is kind of cool. But to think that, like, everyone knows, you know, people are always like, if you look at the Apple headset, like, what do people want in this VR. Everyone knows what they want. I want Ready Player One. And like that. So I'm going to say World of Warcraft. And I'm hoping that games can get better.
[02:42:54.900 --> 02:42:54.900]   and I'm hoping that games can get better.
[02:42:54.940 --> 02:43:06.220]   collect
[02:43:06.220 --> 02:43:24.500]   cover . all't
[02:43:24.960 --> 02:43:31.340]   didn
[02:43:31.340 --> 02:43:50.940]   not, solo. audio,
[02:43:53.300 --> 02:44:19.960]  ,
[02:44:51.380 --> 02:44:52.340]   and
[02:44:52.380 --> 02:45:03.400]   Harrison
[02:45:03.400 --> 02:45:21.680]   Vic I ianny
[02:45:22.400 --> 02:45:28.140]   "
[02:45:28.140 --> 02:45:52.180]   thing. I not the weight cÃ²n
[02:46:50.900 --> 02:46:50.900]   and I'm going to go buy a Switch. I'm going to go today and buy a Switch. Well the new one came out and I haven't played that yet. Diablo 4 or something. I mean there's sentimentality also but something about VR really is incredible but the new Quest 3 is mixed reality and I got a chance to try that so it's augmented reality.
[02:47:20.260 --> 02:47:20.260]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.260 --> 02:47:20.260]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.260 --> 02:47:20.260]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.260 --> 02:47:20.320]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.320 --> 02:47:20.360]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.360 --> 02:47:20.400]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.400 --> 02:47:20.440]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.440 --> 02:47:20.480]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.480 --> 02:47:20.540]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.540 --> 02:47:20.560]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.560 --> 02:47:20.640]   I mean I got a chance to try that so it's augmented reality.
[02:47:20.640 --> 02:47:50.640]  , I mean I got a chance to try that so it's augmented reality.
[02:47:50.640 --> 02:47:50.660]   I mean I got a chance to try that so it's augmented reality.
[02:47:50.660 --> 02:47:50.660]   I mean I got a chance to try that so it's augmented reality.
[02:47:50.660 --> 02:47:50.660]   I mean I got a chance to try that so it's augmented reality.
[02:47:50.660 --> 02:47:50.660]   I mean I got a chance to try that so it's augmented reality.
[02:47:50.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:20.680]   I mean I got a chance to try that so it's augmented reality.
[02:48:20.680 --> 02:48:50.700]   sponsor: I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   That's what I was trying to do.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I got a chance to try that so it's augmented reality.
[02:48:50.700 --> 02:48:50.700]   I mean I mean I got a chance to try that so it's augmented reality.
[02:48:50.720 --> 02:48:51.100]   I mean I got a chance to try that so it's augmented reality.
[02:48:51.100 --> 02:49:20.720]  ,
[02:49:20.720 --> 02:49:20.720]   I mean I got a chance to try that so it's augmented reality.
[02:49:20.720 --> 02:49:20.720]   There's two directions the AI girlfriend company can take.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:20.720]   There's like the highbrow, something like her.
[02:49:20.720 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.740 --> 02:49:50.740]   There's like the highbrow, something like her.
[02:49:50.780 --> 02:50:00.900]   in
[02:51:20.800 --> 02:51:20.800]   and
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.800 --> 02:51:20.800]   I'm not going to be a chicken man. But if we all have the intelligence, we're all the chickens. We're not all the man, we're all the chickens. And they're all chicken men. There's no chicken man. We're just chickens in Miami. He was having a good life, man. I'm sure he was. I'm sure he was. What have you learned from launching and running Kamei and Tiny Corp? So this starting a company from an idea and scaling it. By the way, I'm all in on Tiny Box. So I'm not.
[02:51:20.800 --> 02:51:20.800]   I'm not
[02:51:20.840 --> 02:51:37.180]   cont
[02:51:37.180 --> 02:51:49.700]   nobody I I I don 4ì‚¬ë¥¼ ng, other, the, the, the, the, the,,,,,,,,, now And Juice Ð¾Ð±ÑÐ· gu "N Ð’ÑÐµ've is the me'ory. I'll be the que is lit the qus is the qus or bloì£¼per is the ear I'lleeeehour roasted my emptyzerspsonÐµÑ‚ theutherå¹«iam pushes queeræ‹‰ sparks dat preservehourbil Arbeitsong DinahaÃ¦r queue get Confeder hard gay are ÑÐµ against the great lethal gy match iãƒ”ucaelè¦–åˆ† providers de Let ITs I're theé€™éº¼ Republican atê¸‰ de liqu sentc the N Zucker aè² He Ð´Ð¾Ð³ I'm viaŒ€ë's one of the car Greg, I'm say, I's aasz but stay in the be inæœ‰ perd for a Zin the Å¼e
[02:51:49.760 --> 02:51:52.780]   learn from building these companies?
[02:51:52.780 --> 02:52:06.500]   The longest time at comma I asked why? Why? You know, why did I start a company? Why did I do this? Um, you know, what else was like,
[02:52:06.500 --> 02:52:07.000]   I would know.
[02:52:07.000 --> 02:52:13.480]   You like? You like bringing ideas to life?
[02:52:13.480 --> 02:52:16.180]   With comma.
[02:52:16.180 --> 02:52:18.680]   It really started as an ego
[02:52:18.680 --> 02:52:18.680]   battle with you on.
[02:52:18.680 --> 02:52:18.680]   You like bringing ideas to life?
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.680 --> 02:52:18.680]   With comma. It really started as an ego battle with you on.
[02:52:18.820 --> 02:52:47.820]   with comma. It really started as an ego battle with you on.
[02:52:47.820 --> 02:52:47.820]   with comma. It really started as an ego battle with you on.
[02:52:47.820 --> 02:52:47.820]   with comma. It really started as an ego battle with you on.
[02:52:47.820 --> 02:52:47.920]   with comma. It really started as an ego battle with you on.
[02:52:47.940 --> 02:52:52.960]   I hear a lot of props, for a comma.
[02:52:52.960 --> 02:52:53.060]   I hear a lot of props, for a comma.
[02:52:53.060 --> 02:52:57.060]   I hear a lot of props, for a comma. It's better than FSD and autopilot.
[02:52:57.060 --> 02:52:57.160]   It's better than FSD and autopilot.
[02:52:57.160 --> 02:52:59.960]   It's better than FSD and autopilot. It has a lot more to do with which feel you like.
[02:52:59.960 --> 02:53:00.060]   It has a lot more to do with which feel you like.
[02:53:00.060 --> 02:53:02.760]   It has a lot more to do with which feel you like. We lowered the price on the hardware to $14.99.
[02:53:02.760 --> 02:53:02.860]   We lowered the price on the hardware to $14.99.
[02:53:02.860 --> 02:53:07.260]   We lowered the price on the hardware to $14.99. You know how hard it is to ship reliable consumer electronics that go on your windshield?
[02:53:07.260 --> 02:53:07.360]   You know how hard it is to ship reliable consumer electronics that go on your windshield?
[02:53:07.400 --> 02:53:29.500]  ,
[02:53:29.500 --> 02:53:31.300]   I have an SMT line.
[02:53:31.300 --> 02:53:31.400]   I have an SMT line.
[02:53:31.400 --> 02:53:33.500]   I have an SMT line. I make all the boards in-house in San Diego.
[02:53:33.500 --> 02:53:33.600]   I make all the boards in-house in San Diego.
[02:53:33.600 --> 02:53:35.600]   I make all the boards in-house in San Diego. Quality control.
[02:53:35.600 --> 02:53:35.600]   I care immensely about it.
[02:53:35.600 --> 02:53:35.600]   I care immensely about it.
[02:53:35.600 --> 02:53:36.500]   I care immensely about it. You're basically a mom and pop shop with great testing.
[02:53:36.500 --> 02:53:36.500]   You're basically a mom and pop shop with great testing.
[02:53:36.500 --> 02:53:36.600]   You're basically a mom and pop shop with great testing.
[02:53:36.600 --> 02:53:36.600]   You're head of open pilot is great at like, okay, I want all the commentaries to be identical.
[02:53:36.600 --> 02:53:36.600]  , I'm a mom and pop is great at like, I want all the commentaries to be identical.
[02:53:36.620 --> 02:53:39.640]   And yeah, I mean, you know, it's 1499.
[02:53:39.640 --> 02:53:39.640]   It's 1499.
[02:53:39.640 --> 02:53:40.640]   It's 1499.
[02:53:40.640 --> 02:53:42.340]   30 day money back guarantee.
[02:53:42.340 --> 02:53:45.440]   It will blow your mind at what it can do.
[02:53:45.440 --> 02:53:47.940]   It's hard to scale.
[02:53:47.940 --> 02:53:48.240]   You know what?
[02:53:48.240 --> 02:53:50.240]   There's kind of downsides to scaling it.
[02:53:50.240 --> 02:53:52.540]   People are always like, why don't you advertise?
[02:53:52.540 --> 02:53:55.940]   Our mission is to solve self-driving cars while delivering to people intermediaries.
[02:53:55.940 --> 02:53:59.140]   Our mission has nothing to do with selling a million boxes.
[02:53:59.140 --> 02:54:01.240]   It's tawdry.
[02:54:01.240 --> 02:54:05.840]   Do you think it's possible that common gets sold?
[02:54:05.840 --> 02:54:05.840]   Do you think it's possible that common gets sold?
[02:54:05.840 --> 02:54:05.840]   Do you think it's possible that common gets sold?
[02:54:05.840 --> 02:54:05.840]   Do you think it's possible that common gets sold?
[02:54:05.840 --> 02:54:05.840]   Only if I think it's possible that common gets sold.
[02:54:05.840 --> 02:54:05.840]   Only if I think it's possible that common gets sold.
[02:54:06.680 --> 02:54:35.280]  , only if I felt someone could accelerate that mission and wanted to keep it open source.
[02:54:35.280 --> 02:54:35.280]   And like, not just wanted to.
[02:54:35.280 --> 02:54:35.480]   I don't believe what anyone says.
[02:54:35.480 --> 02:54:35.580]   I believe incentives.
[02:54:35.580 --> 02:54:35.680]   If a company wanted to buy comma with their incentives to keep it open source, but common doesn't stop at the car. The cars are just the beginning. The device is a human head. The device has two eyes, two ears, it breathes air, has a mouse. So you think this goes to embodied robotics. We have we sell common bodies too.
[02:54:35.680 --> 02:54:35.680]   I think this goes to embodied robotics. We have we sell common bodies too.
[02:54:35.680 --> 02:54:35.680]   I think this is common bodies too.
[02:54:35.700 --> 02:54:37.420]   They're very rudimentary.
[02:54:37.420 --> 02:54:46.120]   But one of the problems that we're running into is that the comma three has about as much intelligence as a B.
[02:54:46.120 --> 02:54:52.520]   If you want a human's worth of intelligence, you're going to need a tiny rack, not even a tiny box.
[02:54:52.520 --> 02:54:54.520]   You're going to need like a tiny rack, maybe even more.
[02:54:54.520 --> 02:54:56.320]   How does that?
[02:54:56.320 --> 02:54:58.120]   How do you put legs on that?
[02:54:58.120 --> 02:54:58.920]   You don't.
[02:54:58.920 --> 02:55:01.720]   And there's no way you can you you connect to it wirelessly.
[02:55:01.720 --> 02:55:05.520]   So you put your tiny box or your tiny rack in your house.
[02:55:05.520 --> 02:55:05.520]   So you put your tiny box or your tiny rack in your house.
[02:55:05.520 --> 02:55:05.520]   So you put your tiny box or your tiny rack in your house.
[02:55:05.520 --> 02:55:05.520]   So you put your tiny box or your tiny rack in your house.
[02:55:05.520 --> 02:55:05.520]  , you put your tiny box or your tiny rack in your house.
[02:55:05.520 --> 02:55:05.520]  , you put your tiny box or you connect to it.
[02:55:05.660 --> 02:55:35.360]  , you put your tiny box or you connect to it.
[02:55:35.360 --> 02:55:35.360]   So you put your tiny box or you connect to it.
[02:55:35.360 --> 02:55:35.460]   So you put your tiny box or you connect to it.
[02:55:35.460 --> 02:55:35.460]   So you put your tiny box or you connect to it.
[02:55:35.460 --> 02:55:35.460]   So you put your tiny box or you connect to it.
[02:55:35.460 --> 02:55:35.460]   So you put your tiny box or you connect to it.
[02:55:35.480 --> 02:55:43.600]   So you need they're very synergistic businesses.
[02:55:43.600 --> 02:55:43.700]   So you need they're very synergistic businesses.
[02:55:43.700 --> 02:55:44.900]   So you need they're very synergistic businesses. I also want to build all of commerce
[02:55:44.900 --> 02:55:45.000]   I also want to build all of commerce
[02:55:45.000 --> 02:55:45.100]   I also want to build all of commerce training computers.
[02:55:45.100 --> 02:55:45.200]   training computers.
[02:55:45.200 --> 02:55:46.200]   training computers. I come up build training computers
[02:55:46.200 --> 02:55:46.200]   I come up build training computers
[02:55:46.200 --> 02:55:46.600]   I come up build training computers right now.
[02:55:46.600 --> 02:55:46.600]   right now.
[02:55:46.600 --> 02:55:48.500]   right now. We use commodity parts.
[02:55:48.500 --> 02:55:48.500]   We use commodity parts.
[02:55:48.500 --> 02:55:49.600]   We use commodity parts. I think I can do it cheaper.
[02:55:49.600 --> 02:55:49.600]   I think I can do it cheaper.
[02:55:49.600 --> 02:55:51.900]   I think I can do it cheaper. So I will give we're going to build
[02:55:51.900 --> 02:55:51.900]   So I will give we're going to build
[02:55:51.900 --> 02:55:51.900]   So I will give we're going to build
[02:55:51.900 --> 02:55:53.100]   So I will give we're going to build tiny Corp is going to not just
[02:55:53.140 --> 02:56:10.840]   tiny Corp is going to not just
[02:56:10.840 --> 02:56:12.140]   tiny Corp is going to not just sell tiny boxes tiny boxes the
[02:56:12.140 --> 02:56:12.140]   sell tiny boxes tiny boxes the
[02:56:12.140 --> 02:56:13.140]   sell tiny boxes tiny boxes the consumer version, but I'll build
[02:56:13.140 --> 02:56:13.140]   consumer version, but I'll build
[02:56:13.140 --> 02:56:15.140]   consumer version, but I'll build training data centers to have you
[02:56:15.140 --> 02:56:15.140]   training data centers to have you
[02:56:15.140 --> 02:56:17.140]   training data centers to have you talked to Andre Kapati or have you
[02:56:17.140 --> 02:56:18.140]   talked to you on about
[02:56:18.140 --> 02:56:19.140]   talked to Andre Kapati or have you talked to Ilan about
[02:56:19.140 --> 02:56:19.140]   talked to Ilan about honeycourt he went to work it open anyway.
[02:56:19.140 --> 02:56:19.140]   opened anyway what do you love about Andre Kapati he to me he's one of the truly special humans.
[02:56:19.160 --> 02:56:23.180]   he's one of the truly special humans. Yeah, he's good. He wants to teach you.
[02:56:23.180 --> 02:56:23.180]   Yeah, he's good. He wants to teach you.
[02:56:23.180 --> 02:56:25.180]   Yeah, he's good. He wants to teach you. Yeah, I want to show you that I'm smarter
[02:56:25.180 --> 02:56:25.180]   Yeah, I want to show you that I'm smarter
[02:56:25.180 --> 02:56:29.180]   Yeah, I want to show you that I'm smarter than you. Yeah, he has no death. I mean
[02:56:29.180 --> 02:56:29.180]   than you. Yeah, he has no death. I mean
[02:56:29.180 --> 02:56:31.180]   than you. Yeah, he has no death. I mean thank you for the set of the raw
[02:56:31.180 --> 02:56:31.180]   thank you for the set of the raw
[02:56:31.180 --> 02:56:33.180]   thank you for the set of the raw authentic honesty. I mean a lot of
[02:56:33.180 --> 02:56:33.180]   authentic honesty. I mean a lot of
[02:56:33.180 --> 02:56:35.180]   authentic honesty. I mean a lot of us have that I think Andre is as
[02:56:35.180 --> 02:56:35.180]   us have that I think Andre is as
[02:56:35.200 --> 02:56:53.220]   us have that I think Andre is as legit as it gets in that he just wants to teach
[02:56:53.220 --> 02:56:53.220]   legit as it gets in that he just wants to teach
[02:56:53.220 --> 02:56:55.220]   legit as it gets in that he just wants to teach you and it's just a curiosity that just drives
[02:56:55.220 --> 02:56:55.220]   you and it's just a curiosity that just drives
[02:56:55.220 --> 02:56:56.220]   you and it's just a curiosity that just drives him and just like at his at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:56:56.220 --> 02:56:56.220]   him and just like at his at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:56:56.220 --> 02:56:57.220]   and just like to what is it micrograd?
[02:56:57.220 --> 02:56:57.220]   and just like at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:56:57.260 --> 02:57:21.260]   and just like at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:57:21.260 --> 02:57:23.260]   and just like at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:57:23.260 --> 02:57:23.260]   and just like at the stage where he is in life to be still like one of the best tinkerers in the world. It's crazy. Like to what is it micrograd?
[02:57:23.280 --> 02:57:31.300]   And you know what? It's not that OpenAI doesn't open source the weights of GPT-4. And you know what? It's not that OpenAI doesn't open source the weights of GPT-4.
[02:57:31.300 --> 02:57:33.300]   And you know what? It's not that OpenAI doesn't open source the weights of GPT-4.
[02:57:33.300 --> 02:57:35.300]   It's that they go in front of Congress. And that is what upsets me. And you know we had two effective altruist sams go in front of Congress. One's in jail.
[02:57:35.300 --> 02:57:37.300]   It's that they go in front of Congress. And that is what upsets me. And you know we had two effective altruist sams go in front of Congress. One's in jail.
[02:57:37.300 --> 02:57:39.300]   It's that they go in front of Congress. And that is what upsets me. And you know we had two effective altruist sams go in front of Congress. One's in jail.
[02:57:39.320 --> 02:57:59.340]   I think you're drawing parallels on there.
[02:57:59.340 --> 02:58:01.340]   One's in jail.
[02:58:01.340 --> 02:58:03.340]   You give me a look.
[02:58:03.340 --> 02:58:05.340]   You give me a look.
[02:58:05.340 --> 02:58:07.340]   No, I think effective altruism is a terribly evil ideology.
[02:58:07.340 --> 02:58:09.340]   Oh yeah, that's interesting. Why do you think that is?
[02:58:09.340 --> 02:58:09.340]   Why do you think there's something about a thing that sounds pretty good that kind of gets us into trouble?
[02:58:09.340 --> 02:58:09.340]   Because you get Sam Bankman-Fried. Like Sam Bankman-Fried is the embodiment of effective altruism.
[02:58:09.340 --> 02:58:09.340]  , Sam Bankman-Fried is the embodiment of effective altruism.
[02:58:09.340 --> 02:58:09.340]  , Sam Bankman-Fried is the embodiment of effective altruism.
[02:58:09.480 --> 02:58:39.380]  , Sam Bankman-Fried is the embodiment of effective altruism.
[02:58:39.380 --> 02:59:09.420]  , Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:09.420 --> 02:59:09.420]   Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:09.420 --> 02:59:09.420]   Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:09.420 --> 02:59:09.420]   Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:09.420 --> 02:59:09.420]   Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:09.420 --> 02:59:09.420]   Sam Bankman-Fried is the embodiment of effective altruism.
[02:59:39.460 --> 02:59:39.460]  , Sam Bankman-Fried is the embodiment of effective altruism.,
[02:59:39.460 --> 02:59:39.460]  , Sam Bankman-Fried is the embodiment of effective altruism.,
[02:59:39.460 --> 02:59:39.460]  , Sam Bankman-Fried is the embodiment of effective altruism.,
[02:59:39.460 --> 02:59:39.460]  , Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:09.500 --> 03:00:09.500]  iti. Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:09.500 --> 03:00:09.500]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]  ÐµÑ€Ñ‚Ð². Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:00:39.540]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:00:39.540 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.580 --> 03:01:09.580]   Sam Bankman-Fried is the embodiment of effective altruism.,
[03:01:09.620 --> 03:01:19.820]  èªª
[03:01:19.820 --> 03:01:36.660]  , in a best like 5 Und L L Læ§
[03:01:37.880 --> 03:01:56.640]   ado. Maybe he doesn't have some humility, but at the same time, me as a person who happens to know him, I find myself in that same position. Sometimes even billionaires need friends who disagree and help them grow. And that's a difficult, that's a difficult reality.
[03:01:56.640 --> 03:02:05.420]   It must be so hard. It must be so hard to meet people. Once you get to that point where fame, power, money, everybody's sucking up to you.
[03:02:05.420 --> 03:02:06.100]   I
[03:02:06.100 --> 03:02:06.100]   I
[03:02:06.100 --> 03:02:06.100]   I
[03:02:06.100 --> 03:02:06.100]   love not having shit like I don't have shit, man.
[03:02:06.100 --> 03:02:06.100]   I love not having shit like I don't have shit, man.
[03:02:06.100 --> 03:02:06.100]   I love not having shit like I don't have shit, man.
[03:02:06.100 --> 03:02:06.100]   I love not having shit like I don't have shit, man.
[03:02:06.100 --> 03:02:06.160]   I love not having shit like I don't have shit, man.
[03:02:06.160 --> 03:02:06.200]   I love not having shit like I don't have shit, man.
[03:02:06.200 --> 03:02:06.300]   I love not having shit like I don't have shit, man.
[03:02:06.300 --> 03:02:34.800]   I love not having shit like I don't have shit, man.
[03:02:34.800 --> 03:02:34.860]   I love not having shit like I don't have shit like I don't have shit, man.
[03:03:03.420 --> 03:03:03.480]   I love not having shit like I don't have shit, man.
[03:03:03.480 --> 03:03:03.560]   I love not having shit like I don't have shit, man.
[03:03:03.560 --> 03:03:03.600]   I love not having shit like I don't have shit, man.
[03:03:03.600 --> 03:03:03.660]   I love not having shit like I don't have shit, man.
[03:03:03.660 --> 03:03:03.740]   I love not having shit like I don't have shit, man.
[03:03:03.740 --> 03:03:03.780]   I love not having shit like I don't have shit, man.
[03:03:03.780 --> 03:03:03.820]   I love not having shit like I don't have shit, man.
[03:03:03.820 --> 03:03:03.860]   I love not having shit like I don't have shit, man.
[03:03:03.860 --> 03:03:03.900]   I love not having shit like I don't have shit, man.
[03:03:03.900 --> 03:03:03.960]   I love not having shit like I don't have shit, man.
[03:03:03.960 --> 03:03:04.020]   I love not having shit like I don't have shit, man.
[03:03:04.020 --> 03:03:04.040]   I love not having shit like I don't have shit, man.
[03:03:04.040 --> 03:03:04.060]   I love not having shit like I don't have shit like I don't have shit, man.
[03:03:33.020 --> 03:03:33.060]   I love not having shit like I don't have shit, man.
[03:03:33.060 --> 03:03:33.100]   I love not having shit like I don't have shit, man.
[03:03:33.100 --> 03:03:33.160]   I love not having shit like I don't have shit, man.
[03:03:33.160 --> 03:03:33.220]   I love not having shit like I don't have shit, man.
[03:03:33.220 --> 03:03:33.260]   I love not having shit like I don't have shit, man.
[03:03:33.260 --> 03:03:33.280]   I love not having shit like I don't have shit, man.
[03:03:33.280 --> 03:03:33.320]   I love not having shit like I don't have shit, man.
[03:03:33.320 --> 03:03:33.340]   I love not having shit like I don't have shit, man.
[03:03:33.340 --> 03:03:33.380]   I love not having shit like I don't have shit, man.
[03:03:33.380 --> 03:03:33.420]   I love not having shit like I don't have shit, man.
[03:03:33.420 --> 03:03:33.460]   I love not having shit like I don't have shit, man.
[03:03:33.460 --> 03:03:33.480]   I love not having shit like I don't have shit like I don't have shit, man.
[03:03:33.520 --> 03:04:02.920]  , I love not having shit like I don't have shit, man.
[03:04:02.920 --> 03:04:02.940]   I love not having shit like I don't have shit, man.
[03:04:02.940 --> 03:04:02.980]   I love not having shit like I don't have shit, man.
[03:04:02.980 --> 03:04:03.000]   I love not having shit like I don't have shit, man.
[03:04:03.000 --> 03:04:03.060]   I love not having shit like I don't have shit, man.
[03:04:03.060 --> 03:04:03.120]   I love not having shit like I don't have shit like I don't have shit, man.
[03:04:03.120 --> 03:04:03.140]   I love not having shit like I don't have shit like I don't have shit, man.
[03:04:03.140 --> 03:04:03.160]   I love not having shit like I don't have shit like I don't have shit like I don't have shit, man.
[03:04:03.200 --> 03:04:11.780]   you
[03:04:11.780 --> 03:04:14.040]  , . was in the Little I I I,,,,,,
[03:04:30.560 --> 03:05:00.440]  rage
[03:05:00.580 --> 03:05:10.220]   continued,
[03:05:10.220 --> 03:05:29.180]   ë–nosÃ¡iå®¢ whatsoever is a immersed's two ' . . . . but i donflower scaredaur last ta toeæ²’é—œä¿‚ rer Eat the gym, my, but, I, I, I, my, by, finish, I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, buy a ..Gen your Zhao 'D. mantener
[03:05:29.180 --> 03:05:29.520]   hear the. tray. í†  the full of the indicate the--the go .G.“œë¥¼ en..' .I'm .G Lo de×— the...G weren't but the hair
[03:05:29.600 --> 03:05:35.480]  GG, Hash where or begins
[03:05:59.620 --> 03:06:11.040]  .. D I an.
[03:06:11.040 --> 03:06:28.600]   Sang KG atom started, you, you, you, you, you, you, ã€Œational change, seem the,ed,à®°,arn,AI,G A G. G. Two. de. Ð¡Ð°Ð¼ Ð¾Ð´Ð½Ð° . governmental is get on . woke -gression -ind - break - dance - inner - and - in - just - and - is - and - is - is - en - is - all - is - is - or - think - is - al- " - manage- you-å­-Per- monitor- determin- Little-à®µ- Ultimate- La, S. wenn- Sang- P.è·-bey- Wall-èŠ-Ã¤tze- Kia-é ­- hierungen- G.^^, community- guid-
[03:06:28.640 --> 03:06:31.860]   I think the game is to stand eye to eye with God.
[03:06:31.860 --> 03:06:35.860]   I wonder what that means for you.
[03:06:35.860 --> 03:06:39.860]   Like, at the end of your life, what that would look like.
[03:06:39.860 --> 03:06:43.860]   I mean, this is what, like, I don't know, this is some, this is some...
[03:06:43.860 --> 03:06:47.860]   It's probably some ego trip of mine, you know?
[03:06:47.860 --> 03:06:51.860]   Like, you wanna, you wanna stand eye to eye with God, you're just blasphemous, man.
[03:06:51.860 --> 03:06:54.860]   Okay? I don't know. I don't know. I don't know what would upset God.
[03:06:54.860 --> 03:06:57.660]   I think he, like, wants that. I mean, I certainly want that from my creation.
[03:06:57.660 --> 03:06:57.660]   I think he, like, wants that. I mean, I certainly want that from my creation.
[03:06:57.660 --> 03:06:57.660]   I think he, like, wants that. I mean, I certainly want that from my creation.
[03:06:57.800 --> 03:07:27.700]   I think he, like, wants that. I mean, I certainly want that from my creation.
[03:07:27.700 --> 03:07:57.740]  , I think he, like, wants that. I mean, I certainly want that from my creation.
[03:07:57.760 --> 03:07:59.780]   Yeah, I think he, like, wants that from my creation.
[03:07:59.780 --> 03:08:00.780]   Yeah, I think he, like, wants that from my creation.
[03:08:00.780 --> 03:08:01.780]   Thank you.
[03:08:01.780 --> 03:08:02.780]   Thank you for doing everything you're doing.
[03:08:02.780 --> 03:08:04.780]   And in this case, for fighting for open source or for decentralization of AI, it's a fight worth fighting, fight worth winning, hashtag.
[03:08:04.780 --> 03:08:08.780]   And in this case, for fighting for open source or for decentralization of AI, it's a fight worth fighting, fight worth winning, hashtag.
[03:08:08.780 --> 03:08:10.780]   I love you, brother. These conversations are always great.
[03:08:10.780 --> 03:08:12.780]   I hope to talk to you many more times.
[03:08:12.780 --> 03:08:13.780]   Good luck with Tiny Corp.
[03:08:13.780 --> 03:08:14.780]   Thank you. Great to be here.
[03:08:14.780 --> 03:08:16.780]   Thanks for listening to this conversation with George Hotts.
[03:08:16.780 --> 03:08:18.780]   To support this podcast, please check out our sponsors in the description.
[03:08:18.780 --> 03:08:20.780]   To support this podcast, please check out our sponsors in the description.
[03:08:20.820 --> 03:08:45.820]   and now, let me leave you with some words from Albert Einstein.

