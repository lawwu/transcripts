
[00:00:00.040 --> 00:00:20.560]   Thank you so much for coming. My name is Gabriela de Queiroz. I work at Microsoft,
[00:00:20.560 --> 00:00:28.520]   as you can tell. I'm director of AI, working with startups and doing events like this,
[00:00:28.520 --> 00:00:34.200]   outreach, talking to founders. And then I have Ash, my colleague. Hi, I'm a senior
[00:00:34.200 --> 00:00:39.160]   advisor with Microsoft for startups. So pretty much spending my day today talking to startup,
[00:00:39.160 --> 00:00:47.320]   helping them build their AI tech stack, primarily on Azure, but no bugs. I'm Pamela. I'm a Python
[00:00:47.320 --> 00:00:56.480]   cloud advocate. And I spend most of my time working on open source repositories, like the ones we'll be
[00:00:56.480 --> 00:01:02.160]   using today. And then also doing live streams and conferences and all that sort of fun stuff like here.
[00:01:02.160 --> 00:01:08.800]   Awesome. So we'll have a lot of like hands-on. But before that, we are going to set the stage,
[00:01:08.800 --> 00:01:12.880]   share a few things, and we have the instructions so everybody will follow.
[00:01:12.880 --> 00:01:20.720]   So today we are going to talk about the AI template. So it's a way for you to run your AI application in
[00:01:20.720 --> 00:01:26.400]   minutes. And the agenda is more or less like this. We are going to talk about Microsoft for startups,
[00:01:26.400 --> 00:01:34.000]   something that we call Founders Hub, and then the partnerships, the AI templates, and then we go to
[00:01:34.000 --> 00:01:42.720]   the hands-on workshop. How many of you have heard of Founders Hub? One, two. Okay. Okay. Well, we have something called Founders Hub, where we offer you a bunch of things.
[00:01:42.720 --> 00:02:00.400]   Not only credits, but a bunch of other things that I'm going to talk about. And the sign-up process is very easy. It takes you like less than five minutes.
[00:02:00.400 --> 00:02:07.760]   It doesn't matter where you are in the stage, if you only have an idea, or if you already have a startup and you are incorporated.
[00:02:07.760 --> 00:02:10.800]   It doesn't matter if you have funding or not funding at all.
[00:02:10.800 --> 00:02:18.000]   And there are like several cool things about this platform, the Founders Hub platform or product.
[00:02:18.000 --> 00:02:24.320]   You have the benefits piece, but you also have one of my favorite pieces, which is like the guidance.
[00:02:24.320 --> 00:02:32.880]   So you have one-on-one calls with experts to ask technical questions to like anything like
[00:02:32.880 --> 00:02:38.640]   go-to-market or like how do I go about my strategy, anything that you can think of that you can leverage.
[00:02:38.640 --> 00:02:45.600]   And then there is something new, and Ash, please chime in if I'm missing something, but there is something
[00:02:45.600 --> 00:02:51.120]   new that we added to the platform, which is called Build with AI. And that's where we are going to be focusing.
[00:02:52.320 --> 00:02:57.760]   It is an open source piece. It's all on GitHub, but you can access through the Founders Hub,
[00:02:57.760 --> 00:03:03.840]   which again is the Microsoft first startup platform that everybody can sign up and join.
[00:03:03.840 --> 00:03:11.600]   One of the cool things is like you get a lot of credits, right? So like everybody likes free credits,
[00:03:11.600 --> 00:03:21.840]   especially when you are trying things out. And we offer up to $150,000 in Azure credits that you can use
[00:03:21.840 --> 00:03:27.280]   across Azure services, including, which not a lot of people know, Azure OpenAI.
[00:03:27.280 --> 00:03:36.560]   So we have the same OpenAI APIs on Azure with the whole security compliance capabilities of Azure.
[00:03:36.560 --> 00:03:44.160]   Plus a lot of like other benefits like GitHub Enterprise products, Microsoft 365, LinkedIn Premium and more.
[00:03:44.960 --> 00:03:50.400]   And then you can use Azure, for example, Azure AI Studio. You can use models from OpenAI,
[00:03:50.400 --> 00:03:58.480]   as I mentioned, by Lama and others. So one of the main slides, if you are looking for credits,
[00:03:58.480 --> 00:04:04.880]   guidance and so on, this is like the place where you take a picture and you get the URL and you apply in minutes.
[00:04:04.880 --> 00:04:12.720]   Do you want to talk about a little bit about more about the cloud credits?
[00:04:12.720 --> 00:04:22.400]   Yeah, I think one of the most important things that I personally like about the entire Microsoft
[00:04:22.400 --> 00:04:27.040]   for startups program, it's not quantitative. It's not just that we're throwing out a bunch
[00:04:27.040 --> 00:04:31.200]   of credits at you and you're like, build it yourself or like, you know, figure it out yourself.
[00:04:31.200 --> 00:04:36.240]   There is a lot of cross collaboration that's happening. So for example, like we spoke about GPT-4,
[00:04:36.240 --> 00:04:42.080]   GPT-3.5, Turbo, etc. Right? Our product team work very closely with the startup. So if there is any
[00:04:42.080 --> 00:04:47.360]   private preview happening, we are working personally with startups to have them on board,
[00:04:47.360 --> 00:04:51.520]   for them to like try out these products, give us feedback that, hey, this is something,
[00:04:51.520 --> 00:04:56.000]   this is one of the feature capabilities I would like to have. And that gets like passed on to the
[00:04:56.000 --> 00:04:59.840]   product team for them to work on. There is my team, which is AI advisors,
[00:04:59.840 --> 00:05:06.560]   which is working with startups one on one. So you're getting like expert advice. And as a startup,
[00:05:06.560 --> 00:05:12.880]   I think like getting advisors, getting time, timely advice, getting like timely resolutions is really,
[00:05:12.880 --> 00:05:18.080]   really important. And those are the qualitative benefits that I personally feel is really important
[00:05:18.080 --> 00:05:23.840]   when you're working with Microsoft for startups. It's not just AI advice, you can get a bunch of
[00:05:23.840 --> 00:05:30.560]   different experts by you, like there is a tool within Founders Hub, which helps you match with
[00:05:30.560 --> 00:05:34.560]   different experts. You have a question about infrastructure, you have a question about Kubernetes,
[00:05:34.560 --> 00:05:40.400]   you have a question about how do I think about like my go to market? How do I price my subscription model?
[00:05:40.400 --> 00:05:44.080]   There could be a ton of different things that a startup is going to be doing, and you don't have
[00:05:44.080 --> 00:05:49.840]   enough resources to help you with that. And that's where you get experts from Microsoft, who are working
[00:05:49.840 --> 00:05:54.960]   in a variety of different products to help you navigate these challenges. So think about the
[00:05:54.960 --> 00:06:00.720]   qualitative benefits and the support that you're getting, apart from just the credits. So that's,
[00:06:00.720 --> 00:06:02.800]   that's something I would like to add.
[00:06:02.800 --> 00:06:08.800]   Yeah, and then we go with you throughout all the stages. If you only have an idea,
[00:06:08.800 --> 00:06:15.200]   or if you are building, if you are in the scale phase as well. So it's for any startup at any stage.
[00:06:15.200 --> 00:06:23.680]   As I mentioned, we are helping with all the cutting edge AI tools and helping you streamline the AI
[00:06:23.680 --> 00:06:30.560]   development. And then we have something like very special as well, which goes beyond the Founders Hub,
[00:06:30.560 --> 00:06:33.280]   which is the partnership that Ash is going to touch a little bit.
[00:06:33.280 --> 00:06:39.120]   So one of the things I was talking about, right, Founders Hub is a platform that becomes like an
[00:06:39.120 --> 00:06:45.040]   intake for all the startups. This becomes your like, if any of you are like familiar with like YC's
[00:06:45.040 --> 00:06:50.560]   platform or like portal, right? Similar to that, like we have Founders Hub as a portal, which has like
[00:06:50.560 --> 00:06:55.040]   end-to-end everything. It keeps track of how much credits you've consumed, what are the products that
[00:06:55.040 --> 00:06:58.960]   you've been using, what are the benefits that you've gotten. It's not just the Azure credits,
[00:06:58.960 --> 00:07:03.760]   there's a ton of like third-party credits that you get, and productivity tools that you get for
[00:07:03.760 --> 00:07:08.320]   free. And as a startup, you need all of these tools to like help you build that ecosystem.
[00:07:08.320 --> 00:07:13.120]   So that's one of the most important things. Now, as a startup, you're getting started at Founders Hub.
[00:07:13.120 --> 00:07:19.600]   That's where you get like $150,000 in credits. As you grow in your journey, if you're getting involved
[00:07:19.600 --> 00:07:26.320]   with one of the Microsoft strategic VC partners, which includes M12, Y Combinator, Neo, Alt Capital,
[00:07:26.320 --> 00:07:32.320]   All Chemist, to name a few, then you get a bunch of extra credits. So outside of the $150,000,
[00:07:32.320 --> 00:07:38.160]   you get an extra credit, which becomes total of $250,000 in credits. And then you get like startup
[00:07:38.160 --> 00:07:43.120]   development managers who are like, you know, dedicated cloud solutions architects to work with you.
[00:07:43.120 --> 00:07:49.840]   Pegasus program is another elite level partnership program that we have with startups, which helps
[00:07:49.840 --> 00:07:55.280]   them go to market, which helps them get you onboarded on Azure marketplace, if you need help,
[00:07:55.280 --> 00:08:00.160]   like, you know, to amplify what you're doing. So you're coming and telling us that, hey, Microsoft,
[00:08:00.160 --> 00:08:05.200]   help us reach your like, you know, millions of viewers or like millions of people who follow you
[00:08:05.200 --> 00:08:10.800]   on your LinkedIn page or on your blog, and help us amplify our startups. So we do blog pieces with you,
[00:08:10.800 --> 00:08:15.280]   we do video interviews with you, we do YouTube interviews with you, which helps you amplify that
[00:08:15.280 --> 00:08:22.000]   product. Outside of that, we're also getting startups involved in conferences. So Microsoft
[00:08:22.000 --> 00:08:27.920]   takes up a lot of like, speaking slots at conferences, and we get our startups that we're working with,
[00:08:27.920 --> 00:08:33.280]   come and talk about their products on stage. Yeah, we have, we have one, for example, Nixla is coming
[00:08:33.280 --> 00:08:39.760]   to talk about their product, and they got integrated to Azure, so you can run the time gen,
[00:08:39.760 --> 00:08:44.240]   that they have. So they are coming to talk.
[00:08:44.240 --> 00:08:48.880]   Yeah, so exactly. Like, so it's a lot of like, amplification that you're getting from Microsoft's
[00:08:48.880 --> 00:08:49.680]   perspective as well.
[00:08:53.200 --> 00:08:58.960]   Yeah, I think we briefly covered about some of the pain points. I'll give you like a quick TLDR,
[00:08:58.960 --> 00:09:05.600]   right? As a startup, if I'm building a startup, I really do not have a lot of time to like spend two
[00:09:05.600 --> 00:09:12.480]   weeks on getting a support ticket cleared off, right? Like, I need quick solutions. I need really,
[00:09:12.480 --> 00:09:17.840]   really fast experimentation pace. I want to try out different things, different tools, different models,
[00:09:17.840 --> 00:09:22.640]   very quickly, and then decide for myself, what's the best fit for me. And that's one of the places
[00:09:22.640 --> 00:09:27.920]   where one of the pain points that we've heard from startups is that, hey, it's really hard to go
[00:09:27.920 --> 00:09:33.200]   through like tons of documentations and figure out how to get started, like the first quick start program
[00:09:33.200 --> 00:09:39.280]   to like run a particular application, it takes us weeks altogether to run our first end to end
[00:09:39.280 --> 00:09:45.600]   application. That's the solution that we wanted to target with AI templates. So, and one of the major
[00:09:45.600 --> 00:09:51.440]   major disclaimers, it's not 101 level examples. These are really, really complex examples. So,
[00:09:51.440 --> 00:09:56.800]   one of the ones that we're going to be showing is rags with AI search. So, these are really complex
[00:09:56.800 --> 00:10:05.200]   examples that you can run within minutes. And that helps startups get started very quickly and run these
[00:10:05.200 --> 00:10:10.720]   applications, customize it as they want. Because it's open source, any of the issues that you're facing,
[00:10:10.720 --> 00:10:16.560]   just put it on GitHub and then it'll get resolved. We have an entire Cloud Advocate
[00:10:16.560 --> 00:10:21.200]   team working on these templates. If you have any requests that, hey, help us with this particular
[00:10:21.200 --> 00:10:23.440]   other template, we're here to help you on that.
[00:10:23.440 --> 00:10:32.000]   All right. So, now it's the fun part. So, now we are going to be doing like hands-on.
[00:10:32.000 --> 00:10:42.160]   We have the setup instructions in this URL. You can go over there or scan the QR code and we are going to go
[00:10:42.160 --> 00:10:47.920]   through all the setup instructions. Actually, Pamela is going to go through.
[00:10:47.920 --> 00:10:52.800]   Okay. Well, let's make sure everybody has this URL because you are going to actually want to have
[00:10:52.800 --> 00:11:02.640]   that doc open. So, it's aka.ms/aie-workshop or you can scan the QR code. And it should open up a
[00:11:02.640 --> 00:11:07.760]   document that looks like the little screenshot there that says, you know, quick start with AI templates
[00:11:07.760 --> 00:11:14.800]   with setup instructions. And if you have any trouble, any issues, we are three. So, you can
[00:11:14.800 --> 00:11:22.080]   raise your hands and then we'll go and help you. Does anyone not have the doc URL yet?
[00:11:22.080 --> 00:11:25.600]   Still working? Okay.
[00:11:28.080 --> 00:11:32.400]   We need to just have a whiteboard. Remember whiteboards? Whiteboards were great. Yeah,
[00:11:32.400 --> 00:11:35.600]   this is the whiteboard. Do you think they'll mind if we just -- did you bring spray paint?
[00:11:35.600 --> 00:11:36.160]   I'll get some shots.
[00:11:36.160 --> 00:11:42.960]   Okay, great. Thanks. All right. We good? All right. Okay. Just holler at us. Because we're -- I'm going to
[00:11:42.960 --> 00:11:47.280]   step through it first. So, you still have time. But we want to make sure you all have that doc. Okay.
[00:11:47.280 --> 00:11:53.680]   All right. I just remembered how PowerPoint works. Okay. All right. So, okay. So, if we look at that -- those
[00:11:53.680 --> 00:12:01.520]   instructions. The first thing is that we -- you do need a GitHub account. So, if for whatever reason you
[00:12:01.520 --> 00:12:07.920]   don't have a GitHub account yet, this is a good time to get it. You should be able to get it for free. And if
[00:12:07.920 --> 00:12:13.120]   you do have a GitHub account, just make sure you are logged into your GitHub account. And what we provided
[00:12:13.120 --> 00:12:19.680]   today for this workshop is two different things that are going to help you deploy these templates. So, one
[00:12:20.240 --> 00:12:25.920]   is an Azure Pass. So, this is really cool. Because normally things cost money. But we're giving you
[00:12:25.920 --> 00:12:31.760]   an Azure Pass, which will create a Azure subscription for you, which will give you up to $50 worth of
[00:12:31.760 --> 00:12:37.920]   credits. And it will expire in seven days. So, I guess you can keep working with it for the next seven
[00:12:37.920 --> 00:12:42.880]   days. And it'll certainly give you enough to get started during this workshop. So, that's really cool.
[00:12:42.880 --> 00:12:48.400]   So, none of you should have to worry about any of this costing you money. We don't want -- we don't want
[00:12:48.400 --> 00:12:54.480]   that to happen. And then the other thing that we've got you is, normally, when you're using Azure Open AI,
[00:12:54.480 --> 00:13:00.880]   you have to sign up to get permission to use it. You actually have to go fill in a form and get approved
[00:13:00.880 --> 00:13:07.280]   for it and get your account opened up for it. So, since it takes time to fill up that form -- and the
[00:13:07.280 --> 00:13:11.280]   reason we do this is for responsible AI reasons. We want to make sure people are using Azure Open AI for
[00:13:11.280 --> 00:13:17.600]   good reasons, which is good. I like that about Microsoft. But it does take time. So, we have set up this
[00:13:17.600 --> 00:13:23.680]   Azure Open AI proxy that all of you will be able to use during this workshop. So, you're going to use
[00:13:23.680 --> 00:13:29.520]   Azure Pass so that you can freely deploy these things. And then, Azure Open AI proxy so that you don't have
[00:13:29.520 --> 00:13:36.720]   to worry about getting permission to use it. So, that's what a lot of this setup is. So, the first step is
[00:13:36.720 --> 00:13:50.800]   to get that pass set up. So, I'll demonstrate from here. Let me go to my Firefox.
[00:13:50.800 --> 00:13:56.640]   Okay. So, when you go to this Azure check-in link, it's going to ask you to log in with GitHub.
[00:13:56.800 --> 00:14:04.880]   Oh, let me do it in my -- I've got three browsers open right now. Here we go. Let's do it in Chrome.
[00:14:04.880 --> 00:14:10.960]   Yeah?
[00:14:10.960 --> 00:14:12.960]   The initial lamp that takes you to the OneDrive, it says request is blocked.
[00:14:12.960 --> 00:14:14.960]   Request is blocked? Uh-oh.
[00:14:14.960 --> 00:14:18.960]   Is -- was anybody else able to open the dock? Yeah?
[00:14:18.960 --> 00:14:25.200]   The Wi-Fi is wrong. Okay. Yeah. The Wi-Fi was -- Oh, sometimes you mean that maybe the Wi-Fi is bad,
[00:14:25.200 --> 00:14:32.400]   it misinterprets it. It could also just be that the URL was slightly wrong. I think that's what
[00:14:32.400 --> 00:14:41.840]   happens for ACCA links. Okay. All right. Cool. So, then that has a link to this check-in website. So, on the
[00:14:41.840 --> 00:14:46.800]   check-in website, we see that it has two options. Either create a GitHub account, if you don't have -- if
[00:14:46.800 --> 00:14:51.600]   you don't have one, or just log in with GitHub. So, I'm going to click log in with GitHub. And here we go.
[00:14:51.600 --> 00:14:57.920]   I was already logged in in this browser. And then you'll see this Azure pass. So, this is just a promo code
[00:14:57.920 --> 00:15:02.480]   that you're going to use for the next stage. And you can copy to clipboard. And there's this button here
[00:15:02.480 --> 00:15:08.960]   that says get on board with Azure. So, when you click on that, then you get brought to this screen here.
[00:15:11.120 --> 00:15:17.120]   And it says what Microsoft account I'm currently signed in as. So, you know, so at this point,
[00:15:17.120 --> 00:15:21.040]   you have to figure out what Microsoft account you want to use. So, you could make up a new one. You
[00:15:21.040 --> 00:15:25.520]   can just, like, make a new Outlook address. I made one this morning. It's no big deal. You could use a
[00:15:25.520 --> 00:15:30.880]   Gmail account. I don't recommend using your work account if you do have a work account, just because
[00:15:30.880 --> 00:15:36.480]   work accounts tend to have a lot of restrictions on them. And I just think things will not work out.
[00:15:36.480 --> 00:15:40.640]   So, I recommend some sort of personal account. Either create a brand new Microsoft Outlook
[00:15:40.640 --> 00:15:46.640]   account today or just use your Gmail. Whichever those you want to do. So, you do need to
[00:15:46.640 --> 00:15:51.600]   be logged into some Microsoft account. So, it says, okay, I'm going to be logging in with my Gmail.
[00:15:51.600 --> 00:15:59.280]   I confirm. I enter the promo code here. And then I have to do this horrible.
[00:16:00.240 --> 00:16:03.600]   I don't, like, what is, oh, okay. DBW, okay.
[00:16:03.600 --> 00:16:12.080]   Okay. And then in this case, I got an error. And that's because I did already redeem my pass for this
[00:16:12.080 --> 00:16:17.920]   account. But you should get a success if you haven't redeemed your pass for the account yet. And then
[00:16:17.920 --> 00:16:23.040]   that should give you, set you up with this new subscription in your Azure portal. So, you can see here,
[00:16:23.600 --> 00:16:29.600]   now on my pamela.fox@gmail.com, I've got actually two subscriptions. Because I'm actually a paying user of
[00:16:29.600 --> 00:16:36.800]   Azure. So, this is my paid Azure subscription. You can see I'm spending $40 this month. And then here's my
[00:16:36.800 --> 00:16:42.720]   sponsorship, which I, you know, won't be paying for. So, that's, and if you're doing a brand new account,
[00:16:42.720 --> 00:16:50.240]   you're only going to see this sponsorship here. So, that's the expected flow to being able to
[00:16:50.240 --> 00:16:56.240]   get set up with this Azure pass. You don't have to do it right now. You could wait until we, you know,
[00:16:56.240 --> 00:17:01.520]   break into hands-on time. Because then it probably is easier for us to walk around in case there's any
[00:17:01.520 --> 00:17:05.840]   issues. And just to be careful, make sure that in the next step, wherever you're using the subscription
[00:17:05.840 --> 00:17:10.960]   ID, you use it for the Azure sponsorship one, and not the other one, or you're going to get billed on
[00:17:10.960 --> 00:17:15.440]   your, on your credit. Yeah. Yeah. So, if you're worried about that, just make a whole new account.
[00:17:15.440 --> 00:17:23.920]   That's what I have in my, let's see, that's Firefox. So, in, um, in this account, and in my other browser,
[00:17:23.920 --> 00:17:30.240]   this is an account I made, uh, this morning, uh, with just a new outlet account. PamelaFox,
[00:17:30.240 --> 00:17:37.680]   AIFair@outlook.com. It's pretty good. All right. And that one only has, in this case, I only have the sponsorship.
[00:17:38.800 --> 00:17:53.120]   Yeah, question. I see. Okay. So, how many of you have sons with Minecraft? All right. Uh, probably best,
[00:17:53.120 --> 00:17:57.680]   as I was saying, that is why I used a whole new browser, not my normal browser. Um,
[00:17:58.320 --> 00:18:03.680]   so did it already, if you already granted you the past. I just went with, you know, it came up with my
[00:18:03.680 --> 00:18:10.880]   email address. Okay. And then it takes me to my account, but there's nothing here that says anything
[00:18:10.880 --> 00:18:15.360]   about Azure. And when I put in Azure, um, portal.
[00:18:15.360 --> 00:18:26.560]   What do you do if you don't have the hardware? If you don't have?
[00:18:26.560 --> 00:18:34.000]   Uh, I don't think it makes you write it. It shouldn't make you, oh, to get a whole new Outlook account.
[00:18:34.000 --> 00:18:43.120]   Uh, but once I, uh, log into my office, ask me the new pass information, and then if I enter my normal number,
[00:18:43.120 --> 00:18:47.040]   it says it's not a management number. Oh, okay. I didn't remember that step.
[00:18:47.040 --> 00:18:50.560]   Maybe we can just give him our number.
[00:18:54.160 --> 00:18:58.480]   Okay. So if anyone else is having trouble, let me know. I can help.
[00:18:58.480 --> 00:19:05.120]   Yeah. Do we want to just get through this stage now? Or how do we want to do it? Sure. Like,
[00:19:05.120 --> 00:19:19.440]   do you want to like, see what other issues everyone has? Yeah.
[00:19:20.640 --> 00:19:25.920]   Thank you. Thank you. Here we go.
[00:19:48.480 --> 00:19:52.640]   So, um, how many folks are working on getting the Azure pass redeemed right now?
[00:19:52.640 --> 00:19:55.520]   Are people working on that now? Okay.
[00:19:55.520 --> 00:20:04.480]   And how many of you have actually successfully gotten it? Yeah? Okay. Good. Good. Okay. Cool.
[00:20:04.480 --> 00:20:07.120]   Okay. So we'll just get through that.
[00:20:17.120 --> 00:20:20.800]   So what should I move on at some point? Or should we wait?
[00:20:20.800 --> 00:20:30.800]   Okay. All right. So we'll spend five minutes getting through this step and answering any questions. So,
[00:20:30.800 --> 00:20:35.760]   uh, so go ahead if you haven't yet, you know, try to get your Azure pass redeemed.
[00:20:35.760 --> 00:20:41.040]   And, uh, we'll just make sure we have enough time to get that redeemed for everyone.
[00:20:45.920 --> 00:20:50.080]   You can pretty much use any account, like your university account, personal account.
[00:20:50.080 --> 00:20:54.080]   Just not work account. Just not work account. Would the university account still be okay?
[00:20:54.080 --> 00:20:56.880]   Because university tenants sometimes have restrictions too, don't they?
[00:20:56.880 --> 00:21:03.520]   Can try. I've used my university account, it works fine. Okay. So with these ones?
[00:21:03.520 --> 00:21:05.440]   Yeah. With this one. Okay.
[00:21:05.440 --> 00:21:06.240]   With Azure one, yeah. Okay.
[00:21:06.240 --> 00:21:10.240]   No, but with these templates. Okay.
[00:21:11.200 --> 00:21:16.320]   It might not work. Um, do you all remember if we need to add the address and all of that?
[00:21:16.320 --> 00:21:20.960]   I don't remember when the Azure pass. You have to. Okay. So you have to.
[00:21:20.960 --> 00:21:21.120]   Thank you.
[00:21:21.120 --> 00:21:23.920]   Wait. So how did he get over the number stage?
[00:21:23.920 --> 00:21:26.560]   He did. I just, I just, I just, I just asked him for a 204 number.
[00:21:26.560 --> 00:21:27.920]   Oh, okay. Starting 646.
[00:21:27.920 --> 00:21:40.640]   Okay. The next step is the proxy.
[00:21:40.640 --> 00:21:57.040]   Okay. We'll see until Gabriella's out of questions.
[00:22:06.320 --> 00:22:12.000]   Yep. Uh, raise your hands if you've got that pass in. We're just trying to see. Uh, okay.
[00:22:12.000 --> 00:22:14.000]   Activated it on Azure. Okay.
[00:22:14.000 --> 00:22:15.280]   Okay. Okay.
[00:22:15.280 --> 00:22:15.520]   Okay.
[00:22:15.520 --> 00:22:19.360]   Yeah.
[00:22:19.360 --> 00:22:21.200]   No. Oh, question.
[00:22:21.200 --> 00:22:31.040]   Okay.
[00:22:31.040 --> 00:22:33.300]   Clicking on Word. You already went to the next time?
[00:22:33.300 --> 00:23:03.280]   Thank you.
[00:23:03.280 --> 00:23:33.260]   Thank you.
[00:23:33.260 --> 00:23:43.660]   Yeah, so to confirm that you have the Azure thing working, you can go to portal.azure.com
[00:23:43.660 --> 00:23:48.360]   and then it's going to look super empty. You'll see nothing under resources, but if you click
[00:23:48.360 --> 00:23:53.820]   on subscriptions, then that's where you should see Azure Pass sponsorship. So your subscription
[00:23:53.820 --> 00:23:59.720]   is basically like, it's kind of like a billing account sort of thing. So that's how you know
[00:23:59.720 --> 00:24:09.580]   you've got it is if you see that under your portal under subscriptions. All right, so let's
[00:24:09.580 --> 00:24:15.800]   try, now let's look at the proxy. Okay, so for the proxy, that's another URL which is linked
[00:24:15.800 --> 00:24:22.320]   from the docs. So I'll go ahead and open that. I think I've already logged in on this one.
[00:24:24.320 --> 00:24:29.920]   Okay, so what you're going to see is this page that looks like this and it has this login
[00:24:29.920 --> 00:24:38.320]   with GitHub. So then I log in with GitHub. And now I'm logged in. You can see it says welcome
[00:24:38.320 --> 00:24:45.120]   to my GitHub username at the top. And when I scroll down, I can see an API key and an endpoint.
[00:24:45.760 --> 00:24:52.160]   So here's the API key and here is the endpoint. So this is what we're going to be using in order
[00:24:52.160 --> 00:25:02.320]   to interact with OpenAI, Azure OpenAI models. And we'll just have to specify this key in this endpoint
[00:25:02.320 --> 00:25:07.200]   when we're using a template. So you're going to basically like, you just keep this open so that you can
[00:25:07.200 --> 00:25:10.240]   continually copy and paste these two fields here.
[00:25:10.240 --> 00:25:15.120]   I'll just like create a small node where you're like, you have your subscription ID,
[00:25:15.120 --> 00:25:21.840]   your endpoint, and your key copy pasted on that. Yeah. And declare by, normally, I don't recommend
[00:25:21.840 --> 00:25:26.480]   using API keys. And I've got all these like videos and blog posts about how you should never use API
[00:25:26.480 --> 00:25:31.680]   keys. Because when you're actually using Azure OpenAI, you can do keyless authentication using this
[00:25:31.680 --> 00:25:35.680]   thing called managed identity. And we have a talk coming up next week about that.
[00:25:35.680 --> 00:25:42.480]   But in order to use this proxy and, you know, take care of the permission issue, we are temporarily
[00:25:42.480 --> 00:25:50.720]   sinning and using keys. Okay. So that's, that's a proxy. So you just have to log in and then you
[00:25:50.720 --> 00:26:00.320]   should get the info for the proxy. Okay. All right. So now I'm going to step through one of the actual
[00:26:00.320 --> 00:26:05.440]   templates. So, you know, all the templates are open source repos, but we've put together
[00:26:05.440 --> 00:26:13.040]   instructions specific to this workshop in, in this, uh, read me here, these three read me's and really
[00:26:13.040 --> 00:26:18.560]   specific to using that proxy. So we're going to ramp up in terms of complexity. So we'll start off one
[00:26:18.560 --> 00:26:24.640]   that's, uh, really simple. Like this is one where you, you know, it's, uh, just to show you how things are
[00:26:24.640 --> 00:26:31.440]   working and, and get things going. And then we'll move on to two different rag applications, uh, that
[00:26:31.440 --> 00:26:37.680]   are more sophisticated and ending with our most sophisticated one that has been deployed like a
[00:26:37.680 --> 00:26:41.920]   hundred thousand times at this point by Azure developers. So it's a very, very popular one.
[00:26:41.920 --> 00:26:51.440]   Um, so let me start with, you know, this first one. So we go to the read me and the first step
[00:26:51.440 --> 00:26:58.240]   is to open the project using GitHub code spaces. Uh, has anyone here used GitHub code spaces?
[00:26:58.240 --> 00:27:04.800]   Okay. A few people. Okay. So GitHub code spaces is very cool. Any GitHub repository you go to,
[00:27:04.800 --> 00:27:09.840]   you can open them up in a code space. So you can like start hacking on that repository immediately.
[00:27:09.840 --> 00:27:13.840]   Uh, and then we can also customize like the environment for that. So what it's going to
[00:27:13.840 --> 00:27:19.680]   open is actually a VS code in the browser that has that project loaded in. So we're going to
[00:27:19.680 --> 00:27:25.360]   do you know one, one very cool thing about GitHub code spaces is like, you know, when you share
[00:27:25.360 --> 00:27:30.240]   something with like someone and they say, well, it was working on my machine, but it's not working
[00:27:30.240 --> 00:27:36.720]   yours, right? That problem that we all have with all the setting, the local environments and all of that
[00:27:36.720 --> 00:27:42.160]   code spaces, you, if you use code spaces, you don't have that problem because I will have the same
[00:27:42.160 --> 00:27:48.560]   environment as Ash, as Pamela. So I will not have the problem. Like it's not working on my computer,
[00:27:48.560 --> 00:27:54.720]   but it's working yours, right? So it's one of the pain points that code spaces came to solve
[00:27:55.280 --> 00:28:00.720]   and all of us, we use code spaces on a daily basis because setting up your local environment in your
[00:28:00.720 --> 00:28:09.440]   computer can be very, very painful. Um, so, so yes. Does everybody have access to their Azure subscription by now?
[00:28:09.440 --> 00:28:19.120]   Anybody who's not? Okay. If you're not, you can just, okay. Can we just like try to solve that and then we go through?
[00:28:19.120 --> 00:28:26.480]   Yeah. Okay, cool. Azure? The proxy?
[00:28:26.480 --> 00:28:33.600]   Well, that's a proxy. Yes. So the question is, how do you get to the repo? So there is a link.
[00:28:33.600 --> 00:28:41.840]   This one? Yeah, this link over here. It takes you to the GitHub repo with all the, everything that you need.
[00:28:41.840 --> 00:28:46.960]   It's here. With the code and everything. No, I can't edit. Yeah, there's like a blank page.
[00:28:46.960 --> 00:28:50.160]   Skip the blank page and then go to the not blank page. It can blame on me.
[00:28:50.160 --> 00:28:57.760]   I'll help you. Control F hands on. So the other question was, how do you know if you have the
[00:28:57.760 --> 00:29:02.800]   subscription? You go to portal.azure.com and then you find subscription. Yeah, and then you click on subscriptions.
[00:29:02.800 --> 00:29:15.520]   So now I'm going to step through the instructions just for the quick start one and then we'll really
[00:29:15.520 --> 00:29:22.480]   set everyone loose and so that we can walk around. So this one is, yeah, just a simple chat application.
[00:29:22.480 --> 00:29:28.320]   So we're going to start off with running this local, well, I'm going to call it local. I'm inside GitHub
[00:29:28.320 --> 00:29:34.560]   code spaces, which is VS code in the browser in this containerized environment, but I'm going to start
[00:29:34.560 --> 00:29:40.800]   a local server inside GitHub code spaces. So I like to start with local development first when I can,
[00:29:40.800 --> 00:29:47.200]   so I can like make sure that things are working. And then once I know it's working locally, then I can
[00:29:47.200 --> 00:29:55.920]   deploy it to Azure. So we're going to start with a local server inside the code space. So looking at the
[00:29:55.920 --> 00:30:03.600]   instructions here, so I've got the project open. The first step is to make a .EMV. So we have a sample
[00:30:03.600 --> 00:30:11.840]   here. So I'm just going to copy and paste the stuff from the sample. And you know, the one negative about
[00:30:11.840 --> 00:30:18.080]   using code spaces with conference Wi-Fi is that it is a online environment. So if you want, you are also
[00:30:18.080 --> 00:30:23.280]   welcome to try these out, these projects locally. This is just how we can guarantee less issues with
[00:30:23.280 --> 00:30:29.840]   developer environment setup. Okay, so you can see in this environment file, we need to specify the endpoint
[00:30:29.840 --> 00:30:37.840]   and the key and the deployment. So for the endpoint, we're going to go to the proxy page and grab that
[00:30:37.840 --> 00:30:44.960]   endpoint URL and put that here. And so it looks like this HBS politeground blah, blah, blah, blah, slash API
[00:30:44.960 --> 00:30:51.520]   slash V1. That's what your endpoint should look like for all of these. So literally, the OpenAI SDK
[00:30:51.520 --> 00:30:58.720]   is going to send requests to this endpoint, and you know, get responses from it. The next step is the key.
[00:30:58.720 --> 00:31:05.280]   So we go here. And we're going to copy and paste that key. There's my key. Love it.
[00:31:05.280 --> 00:31:14.160]   And then the deployment name. So this is the name of our deployment of our GPT model. So if any of you
[00:31:14.160 --> 00:31:21.680]   use OpenAI.com. Okay, so on OpenAI.com, you just use things by their model name, you just say, oh,
[00:31:21.680 --> 00:31:27.520]   I want to use GPT-40. I want to use GPT-35 Turbo. On Azure OpenAI, you actually make deployments of
[00:31:27.520 --> 00:31:32.560]   models where you say, okay, I want a new deployment of GPT-35 Turbo, and then you give that a name.
[00:31:32.560 --> 00:31:39.040]   So we've actually named the deployment the same as the model here to make it either more or less confusing.
[00:31:39.040 --> 00:31:45.920]   But that is one big difference between OpenAI.com and Azure OpenAI is that the Azure OpenAI has this
[00:31:45.920 --> 00:31:54.720]   notion of deployments. But everyone's going to put in GPT-35 Turbo here. So there we go. Okay. So I've
[00:31:54.720 --> 00:32:09.920]   got a .env. And the next step is to run the server. All right. So this is running the Python backend.
[00:32:11.760 --> 00:32:17.680]   We can open this up. And so this will, when I click on this URL inside the code space,
[00:32:17.680 --> 00:32:24.320]   it'll actually open up a very different URL. So this is the, this port running on side the code space.
[00:32:24.320 --> 00:32:31.520]   So it's got this like really funky URL. So then I can say like, write a haiku about AI engineer world
[00:32:31.520 --> 00:32:38.320]   fair. Okay. I always do all my testing. I say to write a haiku because otherwise LLMs get really,
[00:32:38.320 --> 00:32:44.400]   you know, verbose and you're just sitting there waiting forever. So there we go. That is working.
[00:32:44.400 --> 00:32:51.600]   That's getting back responses. So you, you know, send any message that you can, haiku about San Francisco.
[00:32:51.600 --> 00:32:58.320]   And there we go. There we go. I actually just watched a video yesterday about how the golden gate
[00:32:58.320 --> 00:33:04.720]   bridge was built. It's fascinating. Okay. So there we go. Now it is actually running. So this is running
[00:33:04.720 --> 00:33:11.280]   the app that's inside the source folder. So if you want to explore it, you can, this is a court
[00:33:11.280 --> 00:33:17.040]   application. Um, is anyone actually heard of court? It's not well known. Okay. Who's heard of flask?
[00:33:17.040 --> 00:33:22.960]   All right. Core is just the asynchronous version of flask. Like literally probably flask will become
[00:33:22.960 --> 00:33:29.200]   court at some point or vice versa. So core is just flask, but async. Uh, and we always want to use an async
[00:33:29.200 --> 00:33:34.480]   framework when we're building applications that you make, uh, calls to LLMs because we want better
[00:33:34.480 --> 00:33:40.480]   concurrency. So you'll see for all our samples, they're all either using court or fast API for the
[00:33:40.480 --> 00:33:45.840]   Python backends, because those are the ways that we can have async. So you'll see, uh, async. If you
[00:33:45.840 --> 00:33:51.840]   haven't, you know, worked with async a lot in Python, you just see asyncs and awaits all over the place.
[00:33:51.840 --> 00:33:58.160]   Um, because that's how we build, uh, with async backends. Uh, but this is the actual code that's
[00:33:58.160 --> 00:34:05.680]   happening here. We're streaming in the response from the open AI client and, uh, we're getting back the
[00:34:05.680 --> 00:34:12.800]   responses and we're streaming it back to the front end using something called JSON lines or new line
[00:34:12.800 --> 00:34:17.440]   delimited JSON. It's just a way of streaming one line at a time. So let me do a longer one
[00:34:17.440 --> 00:34:23.280]   just so I can show you, uh, how the streaming works. Do do do. And streaming is also another general
[00:34:23.280 --> 00:34:28.880]   practice. If you're, if you're making a user facing application, that's making a call to an LLM,
[00:34:28.880 --> 00:34:33.200]   you really want to stream that response in ideally because then it's going to appear
[00:34:33.200 --> 00:34:38.080]   faster to the user because the time to get the first token, as soon as you get that first token,
[00:34:38.080 --> 00:34:42.400]   you can start streaming in that first token. So we are actually streaming in a token at a time.
[00:34:42.400 --> 00:34:52.480]   So like write, uh, a long essay about San Francisco. Okay. So we should see this
[00:34:52.480 --> 00:35:00.880]   actually stream in here. Uh, once it, so it still takes some amount of time to get that first token,
[00:35:00.880 --> 00:35:07.360]   but then once you get that first token in, there we go. That was so fast. I wonder if the proxy is
[00:35:07.360 --> 00:35:11.360]   actually making it be a bit different. Let me see if I can see it in the stream what happened.
[00:35:11.360 --> 00:35:21.120]   Um, I should see it in the response. Fascinating. Um,
[00:35:21.120 --> 00:35:27.600]   normally I can see the stream tokens in the response here. I can try it with another of ours though.
[00:35:27.600 --> 00:35:33.600]   Okay. All right. So we'll have to trust that, but, um, but yeah, there you go. So this is just our,
[00:35:33.600 --> 00:35:38.960]   our getting started experience. So this is the local server, right? So we are running the local server,
[00:35:38.960 --> 00:35:45.440]   but we are hitting up as your, uh, as our, uh, you know, so we are hitting up a cloud resource
[00:35:45.440 --> 00:35:51.520]   and that's because it's hard to have a local, uh, a local GPT-3-5. Now, if you want, you can actually
[00:35:51.520 --> 00:35:57.280]   use these models with like Olama. I don't know if any of you use Olama, but Olama is a really great way
[00:35:57.280 --> 00:36:03.600]   to run small language models. And so I add support for Olama to all my samples when possible. So if you want,
[00:36:03.600 --> 00:36:08.480]   locally, you can actually run against these small local models, like five, three or Llama two or
[00:36:08.480 --> 00:36:13.840]   whatever, uh, it's just not going to be the same thing because they're different models, but that is
[00:36:13.840 --> 00:36:18.720]   an option for local development. All right. So that's all set up. The next step is to actually deploy
[00:36:18.720 --> 00:36:23.120]   this to Azure. So that's when we are, you know, going to be using that Azure account that you set up.
[00:36:23.120 --> 00:36:26.000]   So the first thing we have to do is log in.
[00:36:26.000 --> 00:36:33.360]   So we're going to do AZD off login. And we're going to use the device code flow when we're
[00:36:33.360 --> 00:36:38.400]   inside a code space. So that's going to have us copy and paste some, uh, some code here.
[00:36:38.400 --> 00:36:46.880]   So I press enter and it opens up this new tab and I'm actually going to open this up in, uh, another
[00:36:46.880 --> 00:36:54.640]   browser. We'll just pick a random one. Okay, here we go. And then I'm going to grab the device code here
[00:36:55.600 --> 00:37:02.480]   and then I put it into here, sign in. Okay. So I guess I'm using my Gmail here.
[00:37:02.480 --> 00:37:04.720]   All right. So I am signed in.
[00:37:04.720 --> 00:37:13.280]   Okay. So now I've logged in. So you want to make sure you log in with the account that you just set up
[00:37:13.280 --> 00:37:20.160]   for that Azure pass. Then we're going to create a new, uh, AZD environment. So this is kind of like
[00:37:20.160 --> 00:37:25.200]   a new deployment environment. So a lot of times when I'm developing these, these samples, I've got like 20
[00:37:25.200 --> 00:37:29.520]   different deployment environments where I'm trying out different configurations and stuff. So I'll make
[00:37:29.520 --> 00:37:34.560]   a new one here for this one in the chat. Quick start. So you just give it, give it a little name.
[00:37:34.560 --> 00:37:41.520]   And then the next step is that we need to set some environment, some AZD environment variables. These
[00:37:41.520 --> 00:37:48.080]   are like our deployment variables. That's going to tell the, um, the infrastructure how to provision
[00:37:48.080 --> 00:37:53.040]   everything. So we're going to tell it to not make Azure open AI because we're using the proxy. We're going to tell
[00:37:53.040 --> 00:37:57.040]   it the name of our deployment. So I can just go ahead and copy and paste those two things.
[00:37:57.040 --> 00:37:59.280]   So I'll just paste them here.
[00:37:59.280 --> 00:38:04.400]   Okay. And then I need to tell it the key. So
[00:38:04.400 --> 00:38:10.320]   this is the same key that we did earlier, but now this is going to be used by the actual deployment flow.
[00:38:11.040 --> 00:38:23.440]   So I go and find, oh, I deleted way too much. Come back. Okay. So just delete that part and grab the key.
[00:38:23.440 --> 00:38:31.280]   All right. So now I've set the key for deployment and then I'm going to set the endpoint for deployment.
[00:38:33.840 --> 00:38:43.920]   And here we go. Where's that proxy at? There we go. All right. Okay. So now I've set all these AZD
[00:38:43.920 --> 00:38:50.080]   environment variables. These are going to be used when we are configuring the infrastructure. And so then
[00:38:50.080 --> 00:38:57.840]   we run AZD up. So what this is actually doing is that we're using this, um, infrastructure as code. Does
[00:38:57.840 --> 00:39:04.320]   anybody here use terraform or bicep or arm? Okay. Yeah. So terraform is probably the more well-known
[00:39:04.320 --> 00:39:09.520]   one. So at Azure, we have our own version. Um, originally it was arm and it was JSON. Now we
[00:39:09.520 --> 00:39:15.840]   have bicep, which is like a better version of arm stronger. Uh, but these are all our bicep files.
[00:39:15.840 --> 00:39:20.080]   You can also write terraform if you want to do that. I just, I know bicep more than terraform.
[00:39:20.080 --> 00:39:26.480]   So we are using bicep, which is infrastructure's code and that bicep describes how everything is
[00:39:26.480 --> 00:39:29.920]   going to be made. So how are we going to make the open AI? How are we going to make analytics,
[00:39:29.920 --> 00:39:35.440]   container apps, uh, roles, all that stuff. All right. So I need to select an, a subscription to use. So I'm
[00:39:35.440 --> 00:39:40.080]   going to use the sponsorship subscription. Um, for many of you, you might just have one subscription and
[00:39:40.080 --> 00:39:43.920]   then a location. This is going to be where like our container app is going to go. So I'll just
[00:39:44.880 --> 00:39:54.960]   pick a random location there. Okay. And now it is packaging everything up. Uh, so it is, yeah,
[00:39:54.960 --> 00:40:00.080]   it's actually building Docker image. So this one gets deployed to Azure container apps. That's like an
[00:40:00.080 --> 00:40:04.880]   Azure option for running containerized applications. We also have like Azure app service,
[00:40:04.880 --> 00:40:11.440]   Azure functions, Azure Kubernetes. Uh, but for this one and the second one, we're using container apps
[00:40:11.440 --> 00:40:17.120]   as a, you know, a nice place if you're using Docker. How many of you like Docker? I shouldn't say like,
[00:40:17.120 --> 00:40:23.360]   how many of you use Docker? Okay. It's a similar, okay. You know, I don't want to presume. Um,
[00:40:23.360 --> 00:40:29.760]   so if you do like Docker, you know, Dockerized, um, environments, you know, this is using a Dockerfile. Uh,
[00:40:29.760 --> 00:40:36.000]   you can see the Dockerfile here. Uh, you know, installing requirements, running the server, all that sort of
[00:40:36.000 --> 00:40:41.200]   stuff here. Uh, so then it's provisioning the resources. So it's going to do that whole step. And then I've
[00:40:41.200 --> 00:40:47.360]   already got one, uh, you know, pre, uh, already deployed here. So we, it, once it's deployed,
[00:40:47.360 --> 00:40:51.600]   we'll have a container apps URL. And this is a URL that you can, you know, tweet, share publicly,
[00:40:51.600 --> 00:41:00.080]   whatever. Try not to use up all, I mean, I guess use up all your credits, whatever. Uh, hi, LLM,
[00:41:00.080 --> 00:41:08.080]   what's up? I don't know. I never know what to say. Um, I don't have feelings. Thanks. Uh, so now it is
[00:41:08.080 --> 00:41:13.520]   deployed there. And then if I can, I can look at my portal and see, you know, actually see what it
[00:41:13.520 --> 00:41:22.160]   made. So I can go here and look at maybe container apps and, uh, that's actually a different one.
[00:41:22.160 --> 00:41:30.240]   So let me look for, let me go. I know. I think I just have to remember which thing I, I wish I have
[00:41:30.240 --> 00:41:40.880]   got three different portals going right now. Here we go. Uh, so we'll do, uh, a quick start.
[00:41:40.880 --> 00:41:48.720]   Maybe this one, there we go. So once it's all deployed, you can go into your portal and actually
[00:41:48.720 --> 00:41:53.280]   find the resource group that was made and then you can see what was made underneath it. So here
[00:41:53.280 --> 00:41:57.440]   we have a container app, you need a registry. These are everything we need in order to make
[00:41:57.440 --> 00:42:03.840]   a containerized app. So that's the flow for that one. The flow is similar for the other ones, but the
[00:42:03.840 --> 00:42:08.880]   other ones are a lot more, uh, a lot more sophisticated. I'm saying like they're ones that people are actually
[00:42:08.880 --> 00:42:18.880]   using, uh, in production. So I'll just talk about RAG. Um, RAG is stands for retrieval augmented generation.
[00:42:18.880 --> 00:42:25.040]   This is our solution for the fact that LLMs like to make stuff up. I mean, that's kind of their,
[00:42:25.040 --> 00:42:29.120]   it's kind of their, the way they work. They're just word prediction machines. And so if you get them to
[00:42:29.120 --> 00:42:32.960]   predict something that they don't know, then they'll, they'll go ahead and predict something, right?
[00:42:32.960 --> 00:42:38.720]   So how do we get LLMs to give us reliable output for a particular domain? We can use retrieval
[00:42:38.720 --> 00:42:44.320]   augmented generation. And so how this works is that we get in a user question. We use that to
[00:42:44.320 --> 00:42:48.480]   search some sort of database, whether it's a, you know, a search engine, a vector database,
[00:42:48.480 --> 00:42:54.000]   whatever you want. We search it, we get back results, and then we send both the original user
[00:42:54.000 --> 00:43:00.560]   question and the search results to the LM and say, Hey, now please answer the user question based off
[00:43:00.560 --> 00:43:05.200]   the search results. And then you'll get a really good answer. So as long as you have a very good search
[00:43:05.200 --> 00:43:09.840]   search engine. So you really want to pick really good retrieval mechanism search engine
[00:43:09.840 --> 00:43:14.400]   at that step. Because if you get good results, then you'll get a great answer from the LLM.
[00:43:14.400 --> 00:43:19.520]   Because LLMs are incredibly good at synthesizing information, summarizing based on what they see.
[00:43:19.520 --> 00:43:22.880]   So they just need to have this, you know, really good search step.
[00:43:22.880 --> 00:43:28.960]   So we have two different RAG options that you can try deploying today and over the next seven days. So the
[00:43:28.960 --> 00:43:36.480]   first one is RAG on Postgres. And so this is, if you like already had a database, imagine you've got
[00:43:36.480 --> 00:43:41.280]   like a retail website, you've got a bunch of products that you're selling, and you wanted your customers
[00:43:41.280 --> 00:43:47.840]   to be able to ask questions about those products, right? So you can, you can just search off those
[00:43:47.840 --> 00:43:53.280]   table rows for, you know, what the user is asking about, get back the matching table rows, and then you
[00:43:53.280 --> 00:43:59.600]   pass those table rows to the LLM and say, hey, answer this user question about the table rows. I'll show
[00:43:59.600 --> 00:44:08.960]   you what that actually looks like when deployed here. So here I've got, you know, a product table for this
[00:44:08.960 --> 00:44:17.040]   outdoor, outdoor shoe company. And so the user puts in, puts in a question here, and we get back all these
[00:44:17.040 --> 00:44:21.840]   results, and where they say, you know, this is just info from the rows. And we can look at the thought
[00:44:21.840 --> 00:44:28.880]   process here. And so we can see that actually, actually, it's even, I did the fancy one. Okay,
[00:44:28.880 --> 00:44:36.080]   I'll use the simple flow first, so I can show the simple flow. And, and then we'll move on to the
[00:44:36.080 --> 00:44:42.320]   advanced, advanced RAG. Okay, all right, so here, now if we look at the thought process here, we get the
[00:44:42.320 --> 00:44:48.640]   search query, we use that to query the database. So these are the rows we get back from the database.
[00:44:48.640 --> 00:44:53.200]   And we do both a vector search and a text search. Now, I'm sure you've heard lots of things about
[00:44:53.200 --> 00:44:58.480]   vector databases. They're great, but you need vector search and text search, and you need to combine
[00:44:58.480 --> 00:45:03.200]   those results together. If you use vector search alone, you will not get good results. I've done,
[00:45:03.200 --> 00:45:08.880]   like, hundreds of evaluations of this sort of thing. You need to have a hybrid search, which is going to do
[00:45:08.880 --> 00:45:13.120]   both a vector search and a text search. So for Postgres, we can use PG vector for vector search,
[00:45:13.120 --> 00:45:17.360]   and then we can use their built-in full text search for text search, and then we can combine them
[00:45:17.360 --> 00:45:24.720]   together. So we get back results, and then we, you know, send to the model. We say, "Hey, your job is to
[00:45:24.720 --> 00:45:30.240]   answer questions based off of sources. Here's the user question, and here's the sources." So at its
[00:45:30.240 --> 00:45:35.920]   simplest, this is what RAG is. This is the actual call that we make to the model, is please answer
[00:45:35.920 --> 00:45:39.520]   according to these sources. Here's the question. Here's the sources. We get back the response.
[00:45:39.520 --> 00:45:47.600]   Now, we can get a little fancier with that, so we go to the advanced flow here,
[00:45:47.600 --> 00:45:53.520]   and I say it's fancy, but I think it's actually what most people are doing at this point for their RAG
[00:45:53.520 --> 00:46:00.880]   at the least. So in this flow here, the first thing we do is we take the user's question and we rewrite it
[00:46:00.880 --> 00:46:06.880]   into a better query, because user questions aren't really optimized for searching databases or searching
[00:46:06.880 --> 00:46:12.480]   search engines. So we first ask an LLM, like, "Hey, here's a user query. Make this into a better query."
[00:46:12.480 --> 00:46:18.320]   So this is what we can call the query cleanup phase or the query rewriting phase, and it's a really useful
[00:46:18.320 --> 00:46:25.920]   first stage to have in a RAG application. And so then we get back, you know, search results, and then,
[00:46:26.640 --> 00:46:32.000]   well, we get back the query, right? So in this case, it actually ended up giving the same query in this
[00:46:32.000 --> 00:46:37.200]   example, and then we get back the results, and then we send it. But this gets particularly helpful when we
[00:46:37.200 --> 00:46:43.840]   have multi-turn conversations. Like, if I type in, let's see if it's going to perform for me today,
[00:46:43.840 --> 00:46:50.000]   more options, right? More options on its own is a terrible query to send to a search engine, right?
[00:46:50.000 --> 00:46:56.320]   What is more options? More options about what? So I'm hoping that my query rewriting phase is going to
[00:46:56.320 --> 00:47:02.800]   clean this up. Now, yeah, see, I should test this before I do it. All right, so I can demonstrate that
[00:47:02.800 --> 00:47:10.240]   more in our other example, because I have done that demo more. This one's -- repo's a little fresher.
[00:47:10.240 --> 00:47:16.560]   I made it like a month ago. Okay. So that's what we're going to need for it. Now, another thing we can
[00:47:16.560 --> 00:47:23.360]   do in the query rewriting phase, though, is that we can actually use OpenAI function calling in order to get
[00:47:23.360 --> 00:47:30.080]   the model to generate SQL filters for us. So that's what we've done here is that the user asked,
[00:47:30.080 --> 00:47:36.640]   I want climbing gear cheaper than $30. Well, we can make that into a SQL filter. So we actually asked the
[00:47:36.640 --> 00:47:41.920]   LLM. We use OpenAI function calling and say, hey, can you tell us if there -- if we should do a price
[00:47:41.920 --> 00:47:46.560]   filter here? And so it comes back and says, yeah, you should do a price. It should be less than and 30.
[00:47:46.560 --> 00:47:50.960]   And then we can use that to construct a SQL filter. So that's another really cool thing about having that
[00:47:50.960 --> 00:47:56.400]   first query rewriting phase is that then you can start doing more sophisticated things and having
[00:47:56.400 --> 00:48:03.280]   it actually come up with more structured queries and not just do just like a full-text, you know,
[00:48:03.280 --> 00:48:12.800]   full-text search. Okay. So that's RAG on Postgres. And so there we saw the flow of that. The other
[00:48:12.800 --> 00:48:16.960]   one that we have -- and this is the one that's super popular that's been deployed thousands of times -- and
[00:48:16.960 --> 00:48:21.760]   this is what many people think of when they think of RAG -- is being able to do RAG on unstructured
[00:48:21.760 --> 00:48:26.800]   documents. So you've got PDFs and docs and Excels and HTML or whatever, right? You've got all these
[00:48:26.800 --> 00:48:31.200]   documents and you want to be able to ask questions about it. And people are really excited about being
[00:48:31.200 --> 00:48:35.520]   able to finally ask questions about PDFs because then we don't have to open PDFs because nobody wants
[00:48:35.520 --> 00:48:42.960]   to open a PDF, right? So we can do -- we can do RAG on documents. And so that's what this demo does here.
[00:48:42.960 --> 00:48:49.440]   And so let me go ahead and show the deployed version of that one, right? So I asked, what does a product
[00:48:49.440 --> 00:48:56.880]   manager do? I get back citations. I click on iCitation. That will load in the particular page number that
[00:48:56.880 --> 00:49:02.720]   it got it from, right? So this is the PDF and the page number where we got it from. And this is, you know,
[00:49:02.720 --> 00:49:07.440]   a question that's specific to this particular employee handbook. And we could do this RAG with anything.
[00:49:08.640 --> 00:49:13.840]   And so here you can see the, you know, all the citations it found. And for the thought process
[00:49:13.840 --> 00:49:18.000]   here, it's similar, right? We have a query rewriting phase, we have the search results phase,
[00:49:18.000 --> 00:49:24.480]   and we've got the prompt to generate the answer. So a lot of this is really similar. The big difference
[00:49:24.480 --> 00:49:29.680]   is that here we have to have a data ingestion phase because we need to figure out a way to take these,
[00:49:29.680 --> 00:49:35.600]   like, you know, 50 page long PDFs or something, and store them in, you know, in a searchable way.
[00:49:35.600 --> 00:49:41.760]   So we have a data ingestion that will take a PDF, we crack it using Azure Document Intelligence,
[00:49:41.760 --> 00:49:48.400]   which is very good extracting text from documents. Then we chunk it, we do a token-based chunking. So
[00:49:48.400 --> 00:49:55.440]   we try to come up with chunks that are about 500 tokens large. And then we vectorize those chunks with,
[00:49:55.440 --> 00:50:00.880]   you know, the OpenAI embedding models, and then we store them into Azure AI Search. So that's the
[00:50:00.880 --> 00:50:05.680]   data ingestion phase. So you're going to need, that's why this is the most complicated architecture,
[00:50:05.680 --> 00:50:14.080]   is because of that data ingestion phase there, right? So data ingestion, we're using Document Intelligence,
[00:50:14.080 --> 00:50:18.720]   Azure Storage to store them, Azure OpenAI to embed, and then Azure AI Search to store that there.
[00:50:19.920 --> 00:50:25.520]   But then it's really cool, and you can do it with all sorts of things. So I've got one that has my blog
[00:50:25.520 --> 00:50:31.840]   in it so I can ask questions about myself. Let me get that one open. Let's see my blog. Here we go.
[00:50:31.840 --> 00:50:43.920]   And there we go. Good sleep strategies. I was just telling them how bad I am at sleep, but
[00:50:43.920 --> 00:50:48.960]   I have researched it a lot because I'm so bad at it. These are all from my blogs.
[00:50:48.960 --> 00:50:55.360]   Okay. And that's from, this is from parsing in like an HTML site.
[00:50:55.360 --> 00:51:06.640]   Yeah. So there you go. So those are, those are our, there's my blog. Those are, those are the RAG ones. And so
[00:51:06.640 --> 00:51:12.080]   with RAG with the Azure AI Search, that's one where you could immediately get start, like get started
[00:51:12.080 --> 00:51:17.280]   with putting your own documents into it and seeing what it's like to be able to chat off them.
[00:51:17.280 --> 00:51:20.800]   What?
[00:51:20.800 --> 00:51:25.520]   Oh, yeah. Good question. Can you put them somewhere?
[00:51:25.520 --> 00:51:31.040]   Yeah. We'll put in the same doc, the same word doc. We can put the slides over there.
[00:51:31.040 --> 00:51:38.480]   Okay. And I'm, I'm done. Okay. Cool. I know like, let's go for the questions. And then I know that some
[00:51:38.480 --> 00:51:44.320]   people were a little bit behind. I want to make sure that you have something running. Of course,
[00:51:44.320 --> 00:51:51.600]   everything that Pamela showed you, you're going to be able to do in your own time. Like we ran this over
[00:51:51.600 --> 00:51:58.880]   and over and over and over again. We tried different things. We customized the HTML of the chat. We also
[00:51:58.880 --> 00:52:04.800]   changed the, the, the, the, the message. Like for example, one of the things that you can do is like,
[00:52:04.800 --> 00:52:12.000]   instead of like you are AI assistants, I can say, you only know about Nintendo.
[00:52:12.000 --> 00:52:19.840]   Any other thing, just say, whoa, right? So you can do things like that. So there is a lot of like
[00:52:19.840 --> 00:52:25.360]   customization that you can do on this, on this applications, uh, as she was showing you,
[00:52:25.360 --> 00:52:30.800]   you can use your own data. She was showing with the data from her blog, right? Uh, but I want to make
[00:52:30.800 --> 00:52:35.840]   sure that everybody's more or less on the same page, or if you have any questions like, whoa, Pamela,
[00:52:35.840 --> 00:52:45.120]   what did you just do? I have no idea what is rag or any questions so we can help you get up to speed.
[00:52:45.120 --> 00:53:05.600]   Uh, yeah, great question. So what, um, formats can it handle? Uh, so now as your document intelligence can
[00:53:05.600 --> 00:53:12.080]   handle quite a few, uh, so we have the, let me find the document about it, um, data ingestion.
[00:53:12.080 --> 00:53:19.840]   Okay. Uh, so these are all the ones supported by DI, right? PDF, HTML, docx, pbdx, xls, images
[00:53:19.840 --> 00:53:25.440]   are all supported from document intelligence. And then we built our own parsers for text.
[00:53:26.000 --> 00:53:32.400]   What is what, images? Right. So if you put, yeah, it's a good question, you see images. So if you send
[00:53:32.400 --> 00:53:37.040]   images to document intelligence, it'll OCR them basically. It'll extract the text. Now, the different
[00:53:37.040 --> 00:53:42.880]   thing is that you might want to do, um, like a GPT vision, uh, which is, which is a whole different
[00:53:42.880 --> 00:53:48.960]   thing, which is where you're actually asking, sending an image to GPT like 4.0 and asking a question about it.
[00:53:48.960 --> 00:53:53.600]   Now this repo does actually optionally support that. So if that's something you're interested in,
[00:53:53.600 --> 00:53:58.240]   you can try that out. That's, that's actually different from ingesting an image, um, slightly
[00:53:58.240 --> 00:54:02.640]   different process. But that's, that's also an option. So it just depends what are your images
[00:54:02.640 --> 00:54:04.960]   and what are you hoping to get out of them. Yeah.
[00:54:04.960 --> 00:54:12.800]   What about, like, PDFs with images inside that have text that's, like, context to what's going on?
[00:54:15.200 --> 00:54:21.200]   So document intelligence will extract as much as it possibly can. To me, that's sometimes too much,
[00:54:21.200 --> 00:54:26.960]   but I did have an, uh, an incident where, uh, I did another one based off the Python playwright
[00:54:26.960 --> 00:54:33.440]   documentation and the Python playwright docs has some images of the node playwright. And so it actually
[00:54:33.440 --> 00:54:39.200]   extracted the JavaScript out of those images. And then that messed up my whole rag, uh, because it did
[00:54:39.200 --> 00:54:44.480]   extract it. So document intelligence will generally try to extract as much as it can. And so if there are
[00:54:44.480 --> 00:54:54.880]   text in the images, it'll just bring those out as text.
[00:54:54.880 --> 00:55:03.760]   Yeah. Yeah. So you could do, you can add additional fields, um, where you just mark them as searchable,
[00:55:03.760 --> 00:55:08.720]   and then they would get searched as part of the full text search. Uh, so I think we even start off with
[00:55:08.720 --> 00:55:12.400]   three different searchable fields, but you can, yeah, you can add fields, you mark them as searchable,
[00:55:12.400 --> 00:55:16.800]   then they'll get searched as part of the full text search. In terms of the vector, only what you
[00:55:16.800 --> 00:55:21.680]   vectorize will be searched. So if you do really want something to be searched in the vector search,
[00:55:21.680 --> 00:55:25.520]   then you'd want to do like what's called a content stuffing or content expansion, which is where you
[00:55:25.520 --> 00:55:31.200]   take everything and you stuff it into the same field and then you vectorize it. Um, which is totally
[00:55:31.200 --> 00:55:35.840]   something you can try if you think it's going to be useful for vector. But I, I like, I have to like
[00:55:35.840 --> 00:55:41.120]   really warn about vectors is that you, you just want to be careful with your vectors because sometimes we
[00:55:41.120 --> 00:55:46.320]   like put too much faith in, in vectors. Like I'll show you like the blog post I did, uh, last week where I
[00:55:46.320 --> 00:55:58.640]   ran, um, I ran, um, I ran the, the, the stats. Um, so vector search is not enough, right? But look at the stats, uh, down here. Um, the other thing you should do is evaluate.
[00:55:58.640 --> 00:56:12.960]   Okay. So if I did, this is a text only search, it got a groundedness rating of 4.87, which is fairly high. And, um, I only was able to get 0.02 improvement by moving to text plus vector.
[00:56:12.960 --> 00:56:27.920]   So you'll hear a lot about vector, but, but please remember to use hybrid and to use good hybrid. So if you just, if you just blindly like, you know, you just combine vector and text and kind of just use a basic algorithm, which is the reciprocal rank fusion algorithm,
[00:56:27.920 --> 00:56:36.960]   then you'll actually get pretty poor results. Cause those vector results. Cause you have to remember with, uh, when you do vectors and you do a search cross vectors, you will always get results.
[00:56:36.960 --> 00:56:47.440]   Cause it's going to give you the most similar, even if it's really far apart. Right? So that's the danger of vector search is that you're always going to get results. And those results might be noisy. They might be distraction.
[00:56:47.440 --> 00:56:57.200]   And if you distract an LLM, it is very, very distractible. So, um, yeah, so, so the best, like with Azure AI search, this is the AI search.
[00:56:57.200 --> 00:57:06.240]   The best results is if you do hybrid with their semantic ranker model. And that's an additional machine learning model that actually reranks results according to the original user query.
[00:57:06.240 --> 00:57:15.920]   And so that's the only way in my experience that I can use vectors and actually get, you know, get back to the results of a, uh, you know, better than a full tech search.
[00:57:15.920 --> 00:57:20.960]   So just to, just to plead, uh, evaluate and be careful with your vectors.
[00:57:20.960 --> 00:57:34.080]   Any, any other question or do you want us to repeat like one of the apps we can go over slowly, making sure that you are getting every little step?
[00:57:34.080 --> 00:57:40.320]   Cause some people were having issues with the key and not able to run it.
[00:57:40.320 --> 00:57:43.120]   Uh, it's good, but we can also walk, like walk around, right?
[00:57:43.120 --> 00:57:44.000]   Yeah. Yeah.
[00:57:44.000 --> 00:57:44.800]   Yeah. Uh, like, okay.
[00:57:44.800 --> 00:57:52.480]   I have a question then for you. Uh, were any, like, were you able to get at least one thing running?
[00:57:52.480 --> 00:58:02.480]   Okay. Anybody didn't get anything running? Like have no idea what we are doing? Okay. So we are going to help you.
[00:58:02.480 --> 00:58:20.640]   Um, you, you didn't get anything running? Okay. And before that, I know that some people will probably walk around, um, but I really, really want something from you all.
[00:58:20.640 --> 00:58:30.640]   So, uh, one of the things that I want you all and you can save for later because this is very important for us is like, we love feedback.
[00:58:30.640 --> 00:58:38.720]   So we give workshops and talks all the time and we want to improve, right? But don't say like, oh, I wish the wifi was better.
[00:58:38.720 --> 00:58:48.400]   Sure. Yeah. But this is out of control, right? So if you can take a picture, I would really appreciate any feedback that you have for us to improve or to make this.
[00:58:48.400 --> 00:58:53.760]   This is like very dense, this workshop, like there is a lot, uh, we try to compress.
[00:58:53.760 --> 00:58:59.040]   So you have like a lot of like materials that you can go and work by yourself.
[00:58:59.040 --> 00:59:16.120]   Um, yes. So I have one of the questions for people who are like either working at a startup or like want to build a startup or are currently a founder of a startup would love to know what are some of the use cases that you're working on.
[00:59:16.120 --> 00:59:21.720]   And does it like closely relate to any of the AI templates that we showed today?
[00:59:21.720 --> 00:59:24.200]   If not, like tell us more because this is not the only templates.
[00:59:24.200 --> 00:59:33.200]   This is just like three of the examples that we showed in the, for the workshop, there's tons of more AI templates available on the GitHub repository.
[00:59:33.200 --> 00:59:44.880]   But for now, like would love to learn more about like, you know, some of the use cases that you're working on or you're interested in building and maybe like, you know, we can, we can answer some specific questions.
[00:59:44.880 --> 00:59:50.080]   So it's, is somebody interested in sharing a use case that they have?
[00:59:50.080 --> 00:59:59.160]   But yeah, like really appreciate if you have any questions. Yeah. Any like examples.
[00:59:59.160 --> 01:00:09.360]   Uh, so one thing that it's, it's a good practice now that I'm seeing is when you open code spaces, you are paying for it.
[01:00:09.360 --> 01:00:19.280]   So make sure that you either pause it or you delete it. Otherwise your GitHub account, uh,
[01:00:19.280 --> 01:00:28.640]   Yeah, you have 60 hours for free, but right every month, I guess, but make sure that, uh, if you go to github.com slash code spaces,
[01:00:28.640 --> 01:00:32.440]   you can see everything that is running because I saw someone had like three or four or five.
[01:00:32.440 --> 01:00:47.680]   So, so pay attention to that. Uh, so you don't, I don't, you can, you can expect, you can set, you can, can I, can I do a hip?
[01:00:47.680 --> 01:00:56.040]   You can set up like, you can say in my case, if, if it's like, I'm not using for more than 30 hours, I just shut down automatically.
[01:00:56.040 --> 01:01:02.160]   Uh, but it's something that sometimes you forget. Um,
[01:01:02.160 --> 01:01:10.040]   Yeah. So make sure that let's see how many Pamela has. Pamela has a bunch of them running as you can see.
[01:01:10.040 --> 01:01:20.520]   Yeah. So yeah, quite a few people are actually using this in production, which, um, at first we were a little surprised by because originally it was a sample, but now we've really hardened it.
[01:01:20.520 --> 01:01:31.880]   Uh, so people are using it for public facing stuff like, um, government websites using it because governments have lots of PDFs and documents and it's hard to sort through their stuff. Right. So making it easier for,
[01:01:31.880 --> 01:01:53.760]   citizens to interact with government data is one use case. The other big one is internal HR stuff or internal meeting transcripts. Um, like being able to look through all the transcripts and ask like, you know, what did the CEO say then? Um, uh, internal sales training manuals. Like there's, there's like, there's so many people using it for lots of things.
[01:01:53.760 --> 01:02:15.760]   Yeah. So in terms of being able to automatically update the index, like you just had it in manual ingestion. Um, but you could use instead integrated vectorization, which is an AI search, uh, option where you set up an indexer. So you would point it at like a blob storage, your, uh, blob storage and say, Hey, every time this updates, every five minutes, make sure you refresh the index. And then it would, uh,
[01:02:15.760 --> 01:02:22.760]   refresh it. Uh, so that would be one option or you could use like an Azure function with a trigger. And that's, uh,
[01:02:22.760 --> 01:02:29.760]   there's another, uh, there's another repo that does that. Uh, it's the chat with your data solution accelerator repo. And this one sets up an Azure function that has a trigger. So, um, you've got a few different options for how you could keep it updated. Uh, people just figure out what's, you know, what works out for them.
[01:02:29.760 --> 01:02:39.760]   Cool. Thank you so much. Yeah.
[01:02:39.760 --> 01:02:42.760]   Thank you so much. Yeah.
[01:02:42.760 --> 01:02:44.760]   Thank you.
[01:02:44.760 --> 01:02:49.760]   Um, you've got a few different options for how you could keep it updated. Uh, people just figure out what's, you know, what works out for them.
[01:02:49.760 --> 01:02:52.760]   Uh, people just figure out what's, you know, what works out for them.
[01:02:52.760 --> 01:02:55.760]   Cool. Thank you so much.
[01:02:55.760 --> 01:02:56.760]   Yeah.
[01:02:56.760 --> 01:02:57.760]   Thank you.
[01:02:57.760 --> 01:02:58.760]   Sure.
[01:02:58.760 --> 01:02:59.760]   Thank you.
[01:02:59.760 --> 01:03:00.760]   Thank you.
[01:03:00.760 --> 01:03:01.760]   Thank you.
[01:03:01.760 --> 01:03:02.760]   Thank you.
[01:03:02.760 --> 01:03:03.760]   Thank you.
[01:03:03.760 --> 01:03:04.760]   Thank you.
[01:03:04.760 --> 01:03:05.760]   Thank you.
[01:03:05.760 --> 01:03:06.760]   Thank you.
[01:03:06.760 --> 01:03:07.760]   Thank you.
[01:03:07.760 --> 01:03:08.760]   Thank you.
[01:03:08.760 --> 01:03:09.760]   Thank you.
[01:03:09.760 --> 01:03:10.760]   Thank you.
[01:03:10.760 --> 01:03:11.760]   Thank you.
[01:03:11.760 --> 01:03:11.760]   Thank you.
[01:03:11.760 --> 01:03:12.760]   Thank you.
[01:03:12.760 --> 01:03:13.760]   Thank you.
[01:03:13.760 --> 01:03:14.760]   Thank you.
[01:03:14.760 --> 01:03:19.060]   We'll see you next time.

