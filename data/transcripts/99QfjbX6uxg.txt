
[00:00:00.000 --> 00:00:03.000]   So then go ahead and put one in for B.
[00:00:03.000 --> 00:00:04.960]   >> So I didn't fall for this trick.
[00:00:04.960 --> 00:00:06.560]   >> You did not fall for this trick.
[00:00:06.560 --> 00:00:10.080]   But I've taught these classes before and I've seen the places where people get
[00:00:10.080 --> 00:00:12.240]   confused with a lot of your exercises and concepts.
[00:00:12.240 --> 00:00:16.040]   [MUSIC]
[00:00:16.040 --> 00:00:22.080]   Welcome to W&B's Math for ML exercise video series.
[00:00:22.080 --> 00:00:24.760]   I am your host, Charles Frey.
[00:00:24.760 --> 00:00:27.560]   With me today, I have Scott Condren.
[00:00:27.560 --> 00:00:30.320]   Scott, do you want to maybe give a quick introduction?
[00:00:30.320 --> 00:00:30.960]   >> Yeah.
[00:00:30.960 --> 00:00:34.960]   I'm a machine learning engineer at Ways and Biases.
[00:00:34.960 --> 00:00:38.000]   Before that, I was working for a company called Speech Graphics as a machine
[00:00:38.000 --> 00:00:38.960]   learning engineer.
[00:00:38.960 --> 00:00:41.840]   They do facial animation for video games.
[00:00:41.840 --> 00:00:47.240]   I got my intro to software development as a web developer/mobile app developer,
[00:00:47.240 --> 00:00:49.400]   and then I've since moved into machine learning.
[00:00:49.400 --> 00:00:49.960]   >> Nice.
[00:00:49.960 --> 00:00:54.240]   I wanted Scott to come on for these videos because I feel like Scott falls
[00:00:54.240 --> 00:00:59.720]   pretty closely in the intended audience for this course, which is folks who have
[00:00:59.720 --> 00:01:04.680]   learned how to do a lot of machine learning and can do all kinds of cool stuff,
[00:01:04.680 --> 00:01:08.000]   natural language processing and computer vision with machine learning and deep
[00:01:08.000 --> 00:01:13.960]   neural networks, maybe never had a formal education and a deep dive into the math
[00:01:13.960 --> 00:01:17.720]   behind these things, like the linear algebra, the calculus, the probability.
[00:01:17.720 --> 00:01:21.000]   That's something that I spent a lot of time on when I was doing my PhD,
[00:01:21.000 --> 00:01:22.920]   studying optimization of neural networks.
[00:01:22.920 --> 00:01:26.640]   And so I want to share some of that knowledge and give just the right kind of
[00:01:26.640 --> 00:01:31.400]   intuitions that you need to understand the core concepts from these branches of
[00:01:31.400 --> 00:01:33.920]   math in order to do better machine learning.
[00:01:33.920 --> 00:01:34.880]   Let's dive in.
[00:01:34.880 --> 00:01:39.560]   These exercise videos are here to show you how to use the notebooks that are up on
[00:01:39.560 --> 00:01:42.840]   the GitHub repo for Math for Machine Learning.
[00:01:42.840 --> 00:01:46.480]   So to start off, as is pretty typical with Colab notebooks, we've got some setup
[00:01:46.480 --> 00:01:47.080]   code.
[00:01:47.080 --> 00:01:49.480]   Go ahead and run that cell to install stuff.
[00:01:49.480 --> 00:01:52.800]   It brings in some things that are standard library-type things.
[00:01:52.800 --> 00:01:54.840]   NumPy, weights and biases.
[00:01:54.840 --> 00:01:58.000]   And then it also brings in some course-specific tools.
[00:01:58.000 --> 00:02:00.480]   And one of those is the autograder.
[00:02:00.480 --> 00:02:05.520]   And this is something that helps make these exercise notebooks more useful and
[00:02:05.520 --> 00:02:08.400]   a better educational experience for people using them.
[00:02:08.400 --> 00:02:11.680]   When you're in a live class or when you're live meeting like Scott and
[00:02:11.680 --> 00:02:14.880]   I are right now, we can talk through the exercises.
[00:02:14.880 --> 00:02:18.600]   And it's got code exercises in it that ask you to implement things.
[00:02:18.600 --> 00:02:20.200]   And normally, if you just write the code,
[00:02:20.200 --> 00:02:22.440]   you don't know whether you got the answer right or not.
[00:02:22.440 --> 00:02:25.960]   And without a teacher there to guide you, even something that just tells you when
[00:02:25.960 --> 00:02:27.880]   you have the answer right or not isn't sufficient.
[00:02:27.880 --> 00:02:30.600]   What you really want is something that, when you make a mistake,
[00:02:30.600 --> 00:02:35.120]   tries to identify that mistake for you and then tell you a bit about how to correct it.
[00:02:35.120 --> 00:02:37.120]   So that's what this autograder does here.
[00:02:37.120 --> 00:02:39.640]   So go ahead and run those two cells there, Scott.
[00:02:39.640 --> 00:02:40.400]   All right.
[00:02:40.400 --> 00:02:43.800]   This automatic grader that we've set up here will
[00:02:43.800 --> 00:02:46.560]   basically run unit tests on the exercises.
[00:02:46.560 --> 00:02:50.240]   So just like we would test software for its correctness by writing tests and
[00:02:50.240 --> 00:02:55.280]   then passing them, this grader basically is like a pre-built little unit testing suite
[00:02:55.280 --> 00:02:57.520]   for all the exercises in this notebook.
[00:02:57.520 --> 00:03:00.560]   And so if you have something that's incorrect,
[00:03:00.560 --> 00:03:03.600]   you'll see in the output of the autograder,
[00:03:03.600 --> 00:03:07.680]   you'll see something that says error expected something but got something else.
[00:03:07.680 --> 00:03:09.280]   So let's see a quick example here.
[00:03:09.280 --> 00:03:11.400]   We'll run these grader.grade cells,
[00:03:11.400 --> 00:03:13.880]   are the ones that actually run the grader on something.
[00:03:13.880 --> 00:03:17.280]   And you can see there's that nice test begin here thing that indicates
[00:03:17.280 --> 00:03:18.280]   where the tests are.
[00:03:18.280 --> 00:03:22.200]   You'll only see a message like this if you have something not quite correct in
[00:03:22.200 --> 00:03:23.080]   your exercises.
[00:03:23.080 --> 00:03:26.960]   This particular exercise requires you to define a dictionary called dimensions.
[00:03:26.960 --> 00:03:30.360]   It checks this dimensions variable, is it defined?
[00:03:30.360 --> 00:03:32.520]   And it passes it to this type function,
[00:03:32.520 --> 00:03:36.560]   which will return class dict if dimensions is a dictionary.
[00:03:36.560 --> 00:03:38.320]   And it will return something else otherwise.
[00:03:38.320 --> 00:03:41.920]   So you can see error expected class dict for the output, but
[00:03:41.920 --> 00:03:45.160]   got instead an error actually because dimensions was not defined.
[00:03:45.160 --> 00:03:48.920]   So actually, Scott, go ahead and put for this cell below here,
[00:03:48.920 --> 00:03:50.920]   define dimensions as an empty list.
[00:03:50.920 --> 00:03:52.160]   So just an empty list here.
[00:03:52.160 --> 00:03:56.160]   There we've got dimensions and then go ahead and rerun the grader, right?
[00:03:56.160 --> 00:04:00.000]   So now it says expected class dict, but I got class list.
[00:04:00.000 --> 00:04:02.920]   So this is an attempt to try and help you like right here.
[00:04:02.920 --> 00:04:04.720]   It's just setting up the basic idea.
[00:04:04.720 --> 00:04:07.080]   This exercise involves a dictionary called dimensions.
[00:04:07.080 --> 00:04:09.440]   Before I check whether it's got the right stuff in it,
[00:04:09.440 --> 00:04:11.320]   I just check that it exists for you.
[00:04:11.320 --> 00:04:14.400]   Scott, what do we need to do in order to solve this exercise or
[00:04:14.400 --> 00:04:16.920]   at least get past this first test here?
[00:04:16.920 --> 00:04:19.760]   >> We need to create a dictionary called dimensions.
[00:04:19.760 --> 00:04:20.360]   >> Nailed it.
[00:04:20.360 --> 00:04:22.080]   >> And I have another error.
[00:04:22.080 --> 00:04:22.760]   >> Right. >> That's it.
[00:04:22.760 --> 00:04:23.840]   Key error A.
[00:04:23.840 --> 00:04:27.280]   >> These tests have a lot of rich information in them, and
[00:04:27.280 --> 00:04:30.760]   you can almost start answering the question without even reading it just by
[00:04:30.760 --> 00:04:31.760]   using these tests.
[00:04:31.760 --> 00:04:35.120]   But the idea is that you try and answer the question, you run the grader,
[00:04:35.120 --> 00:04:38.040]   it tells you what you might have made a mistake on.
[00:04:38.040 --> 00:04:41.080]   And then you correct any errors that you have, or
[00:04:41.080 --> 00:04:42.840]   it just tells you you passed, you got them all.
[00:04:42.840 --> 00:04:45.640]   So it's meant to be like a conversation between you and
[00:04:45.640 --> 00:04:49.000]   the grader as you try and develop your answers to the questions.
[00:04:49.000 --> 00:04:52.320]   In the same way that you've ever worked with a compiled language,
[00:04:52.320 --> 00:04:56.520]   sometimes you find you and the compiler are arguing about what the right thing is
[00:04:56.520 --> 00:05:00.560]   to do here, or when you're writing code to pass tests in somebody else's library,
[00:05:00.560 --> 00:05:01.960]   you're molding your code and
[00:05:01.960 --> 00:05:05.960]   you're understanding what's going on to match what the tester is expecting.
[00:05:05.960 --> 00:05:07.680]   >> Cool. >> Let's dive into the first section,
[00:05:07.680 --> 00:05:09.040]   linear algebra is programming.
[00:05:09.160 --> 00:05:13.160]   So again, these videos are paired with another set of videos that dives more
[00:05:13.160 --> 00:05:16.280]   deeply into the ideas in these notebooks,
[00:05:16.280 --> 00:05:19.520]   just little quick lectures describing all these ideas.
[00:05:19.520 --> 00:05:23.040]   So if you want to understand the ideas in here better,
[00:05:23.040 --> 00:05:25.840]   I recommend you check out those videos as well.
[00:05:25.840 --> 00:05:28.760]   Also on the Waitspice's YouTube channel, the Math for ML videos.
[00:05:28.760 --> 00:05:31.200]   So I'll briefly reintroduce those ideas, but
[00:05:31.200 --> 00:05:33.960]   that's where you can really get the meat of these ideas.
[00:05:33.960 --> 00:05:37.880]   Our first core idea here is that if you want to understand linear algebra in order
[00:05:37.880 --> 00:05:41.960]   to use it in machine learning, you want to think of linear algebra not as a tool for
[00:05:41.960 --> 00:05:45.040]   solving equations, but the equations have matrices and vectors, but
[00:05:45.040 --> 00:05:47.720]   rather as a type of programming.
[00:05:47.720 --> 00:05:50.520]   So linear algebra is programming with arrays,
[00:05:50.520 --> 00:05:54.120]   using arrays as functions to operate on arrays as data.
[00:05:54.120 --> 00:05:56.160]   To pick an example from machine learning,
[00:05:56.160 --> 00:06:00.760]   the weights of a fully connected layer of a convolutional layer are an array.
[00:06:00.760 --> 00:06:03.960]   And then we use that array on input arrays.
[00:06:03.960 --> 00:06:09.000]   We send in batches of data and we get out batches of neuron activations.
[00:06:09.000 --> 00:06:12.760]   And so arrays are sent through arrays to get you arrays.
[00:06:12.760 --> 00:06:16.800]   So we have arrays as our functions and arrays as our data.
[00:06:16.800 --> 00:06:21.640]   So you can make this really nice analogy of lots of pieces of programming,
[00:06:21.640 --> 00:06:24.240]   I mean with pieces of linear algebra, and we're going to go through a couple of
[00:06:24.240 --> 00:06:27.720]   those now, starting with the core of this analogy,
[00:06:27.720 --> 00:06:30.240]   which is the analogy between types and shapes.
[00:06:30.240 --> 00:06:33.120]   When we're writing computer programs, we write functions and
[00:06:33.120 --> 00:06:36.880]   then our functions generally work on data with specific types.
[00:06:36.880 --> 00:06:40.480]   So I've got that square function there and it'll square a number, but
[00:06:40.480 --> 00:06:41.640]   it can't square a string.
[00:06:41.640 --> 00:06:43.320]   There's no notion of squaring a string.
[00:06:43.320 --> 00:06:45.640]   So if you run that cell there, you'll get an error.
[00:06:45.640 --> 00:06:49.680]   Unsupported operands, and you'll notice it's called a type error because the type
[00:06:49.680 --> 00:06:50.720]   of the input was wrong.
[00:06:50.720 --> 00:06:54.880]   >> So we've got this string here and it's expecting, bring it to the power of two.
[00:06:54.880 --> 00:06:56.520]   So it's expecting a number.
[00:06:56.520 --> 00:06:58.600]   >> Python's a little bit hog wild, so
[00:06:58.600 --> 00:07:01.960]   anything that knows how to do a power can go in there.
[00:07:01.960 --> 00:07:07.040]   So Python doesn't really fully have a type system the way that a strongly
[00:07:07.040 --> 00:07:10.720]   typed language would if you've worked in some of these other types languages.
[00:07:10.720 --> 00:07:13.160]   Actually, some of this is getting added to Python.
[00:07:13.160 --> 00:07:16.560]   Right there, you can see that you can annotate your functions to try and
[00:07:16.560 --> 00:07:20.520]   hint to the programmers, not to the language itself, not to the compiler.
[00:07:20.520 --> 00:07:24.920]   There's no real actual meaning computationally to these things, but
[00:07:24.920 --> 00:07:28.280]   you can at least suggest what types you expect as input and
[00:07:28.280 --> 00:07:31.320]   what types you'll return as output to your fellow programmers.
[00:07:31.320 --> 00:07:33.120]   And so that's this type annotation.
[00:07:33.120 --> 00:07:34.000]   >> Yeah, I've seen this.
[00:07:34.000 --> 00:07:39.720]   So this is expected input type of float and then a return type of float as well.
[00:07:39.720 --> 00:07:40.320]   >> Exactly.
[00:07:40.320 --> 00:07:44.760]   So the equivalent notion to a type in linear algebra is a shape.
[00:07:44.760 --> 00:07:49.440]   So whatever the shape of an array is determines which functions it can be fed
[00:07:49.440 --> 00:07:54.640]   to as input if its shape matches, just like any number can be fed to that
[00:07:54.640 --> 00:07:58.920]   square function because its type matches the type of that square function.
[00:07:58.920 --> 00:08:03.720]   And in linear algebra, if your shape matches the expected shape of the function
[00:08:03.720 --> 00:08:06.320]   that's operating on you, then the function will run and
[00:08:06.320 --> 00:08:09.080]   it's not going to throw an error just based off of type.
[00:08:09.080 --> 00:08:12.160]   So one way of thinking about that is when we define a function that operates on
[00:08:12.160 --> 00:08:16.400]   arrays, it will generally take in and return arrays with specific shapes and
[00:08:16.400 --> 00:08:18.320]   return an error if the shape is incorrect.
[00:08:18.320 --> 00:08:22.080]   So for example, we can think of matrices actually as functions
[00:08:22.080 --> 00:08:25.720]   that take in vectors and return vectors using matrix multiplication.
[00:08:25.720 --> 00:08:30.360]   So if I matrix multiply a matrix that's 3 by 2 like that one with a vector
[00:08:30.360 --> 00:08:33.720]   that's length 2, then I'll get out a length 3 vector.
[00:08:33.720 --> 00:08:37.960]   But if I try and pass in a length 3 vector to that matrix, I'll get an error.
[00:08:37.960 --> 00:08:42.920]   So if we run that cell, first we'll get the length 3 vector that comes from
[00:08:42.920 --> 00:08:45.000]   combining those together correctly, and
[00:08:45.000 --> 00:08:47.880]   then we'll get an error because the shapes don't match.
[00:08:47.880 --> 00:08:50.680]   >> So here you've redefined vector as a different shape,
[00:08:52.760 --> 00:08:54.600]   even though it's still a NumPy array.
[00:08:54.600 --> 00:08:58.880]   So it still has the same type by Python standards, but it's got a different shape.
[00:08:58.880 --> 00:08:59.480]   >> Exactly.
[00:08:59.480 --> 00:09:00.520]   That's a great point.
[00:09:00.520 --> 00:09:03.120]   There is, there's a notion of types in Python.
[00:09:03.120 --> 00:09:07.560]   People are actually adding better typing to Python and included in that is better
[00:09:07.560 --> 00:09:12.280]   typing for arrays where the shape of an array is part of its type information.
[00:09:12.280 --> 00:09:15.720]   And that's going to really help make a lot of this easier, make it easier for
[00:09:15.720 --> 00:09:19.640]   the people developing these libraries to give you helpful error messages and
[00:09:19.640 --> 00:09:23.080]   make it easier to automatically solve problems for
[00:09:23.080 --> 00:09:25.880]   you that are a little bit harder without this typing information.
[00:09:25.880 --> 00:09:28.200]   But for now, the type information and
[00:09:28.200 --> 00:09:31.120]   the shape information in Python are separate from each other.
[00:09:31.120 --> 00:09:34.920]   But in our mental bottles of linear algebra, we should think of the shape
[00:09:34.920 --> 00:09:39.320]   as like fundamentally important information about the type of this input.
[00:09:39.320 --> 00:09:40.800]   >> Okay. >> Keeping going here,
[00:09:40.800 --> 00:09:44.360]   let's talk a little bit about these shapes and get to our first exercise.
[00:09:44.360 --> 00:09:48.560]   The first exercise is about determining the first piece of information about
[00:09:48.560 --> 00:09:54.280]   the shape of an array is how many indices does it take to get into that array and
[00:09:54.280 --> 00:09:56.800]   pull out a specific element or number.
[00:09:56.800 --> 00:09:58.840]   That's the dimension of the array.
[00:09:58.840 --> 00:10:02.600]   And so if I have rows and columns, I have two dimensions because I need both a row
[00:10:02.600 --> 00:10:06.880]   index and a column index to get out a particular number here.
[00:10:06.880 --> 00:10:08.320]   So to start off here,
[00:10:08.320 --> 00:10:12.560]   this is the same question that we used to demonstrate the grader up at the top.
[00:10:12.560 --> 00:10:15.400]   So we know we got to have this dictionary called dimensions.
[00:10:15.400 --> 00:10:19.000]   By the way, right there is that like header thing that says store the dimensions of
[00:10:19.000 --> 00:10:21.680]   these arrays in a dictionary called dimensions.
[00:10:21.680 --> 00:10:24.240]   >> Okay, right, so these arrays are in a dictionary called dimensions.
[00:10:24.240 --> 00:10:27.800]   Okay, so I'm going to create dimensions, which is a dictionary.
[00:10:27.800 --> 00:10:29.000]   >> Yeah. >> And then I'm going to just add it
[00:10:29.000 --> 00:10:30.480]   with this syntax.
[00:10:30.480 --> 00:10:33.520]   So my keys are, where does it say?
[00:10:33.520 --> 00:10:35.320]   >> Use the variable names as keys.
[00:10:35.320 --> 00:10:41.080]   >> So the variable names are eight and then the dimensions are,
[00:10:41.080 --> 00:10:43.120]   I want to run this so I can see them.
[00:10:43.120 --> 00:10:43.720]   >> Yeah.
[00:10:43.720 --> 00:10:47.400]   >> The dimensions of the first array, A, is one.
[00:10:47.400 --> 00:10:50.400]   >> And why is that for our folks following along at home?
[00:10:50.400 --> 00:10:55.000]   >> Following along at home, so if I want to get a number from A,
[00:10:55.000 --> 00:10:56.360]   I got to add a new cell.
[00:10:56.360 --> 00:11:02.720]   So if I have A here and I want to get, say, the first element, I can go like this.
[00:11:02.720 --> 00:11:07.200]   So that means that it only needs one number to index into,
[00:11:07.200 --> 00:11:10.880]   which means its dimension is one, shape is one, or size is one.
[00:11:10.880 --> 00:11:14.920]   >> These terms are a little bit inconsistent across array libraries.
[00:11:14.920 --> 00:11:18.640]   So NumPy, TensorFlow, and PyTorch all slightly disagree on what this should be
[00:11:18.640 --> 00:11:20.760]   called, but we're going to call it dimensions here.
[00:11:20.760 --> 00:11:24.880]   So let's just try the same thing, that same indexing thing with the array B.
[00:11:24.880 --> 00:11:29.040]   >> Okay, so it has- >> Actually, just do B zero.
[00:11:29.040 --> 00:11:31.960]   Let's just see what that looks like before we answer the question of the-
[00:11:31.960 --> 00:11:33.400]   >> That's a good idea.
[00:11:33.400 --> 00:11:40.640]   So that's now returned another array, which is this array here.
[00:11:40.640 --> 00:11:42.080]   >> Exactly. >> Which I, or this vector here,
[00:11:42.080 --> 00:11:43.600]   which I guess is a sub vector.
[00:11:43.600 --> 00:11:49.680]   So if I do this to get the zeroth element of this.
[00:11:49.680 --> 00:11:55.160]   >> Yeah, there's multiple ways to index into an array in Python, this or in NumPy.
[00:11:55.160 --> 00:11:58.040]   So you can also just pass them both directly.
[00:11:58.040 --> 00:12:00.200]   But notice that now there's a single number, and
[00:12:00.200 --> 00:12:03.840]   previously when you indexed just one time, you got an array, right?
[00:12:03.840 --> 00:12:04.520]   >> Yeah, okay.
[00:12:04.520 --> 00:12:07.120]   This is the syntax you're talking about, using a comma instead?
[00:12:07.120 --> 00:12:08.160]   >> Yeah, using a comma.
[00:12:08.160 --> 00:12:10.760]   That's now standard across all kinds of libraries.
[00:12:10.760 --> 00:12:14.560]   We happen to be using NumPy for the exercises in this one,
[00:12:14.560 --> 00:12:18.280]   just because it's a little bit more explicit and direct than PyTorch or
[00:12:18.280 --> 00:12:22.080]   TensorFlow, where your arrays are always at a bit of a remove.
[00:12:22.080 --> 00:12:23.680]   So it's harder to do stuff like this.
[00:12:23.680 --> 00:12:27.120]   But the same basic ideas are gonna apply here and in those libraries.
[00:12:27.120 --> 00:12:30.400]   >> Great, okay, so I want to give my new answer for B.
[00:12:30.400 --> 00:12:35.280]   And because I needed to use two numbers, I'm gonna go with dimension two.
[00:12:35.280 --> 00:12:37.880]   >> Right, we do the greater.grade now and see how we're doing.
[00:12:37.880 --> 00:12:42.240]   >> Okay, so it seems like that passed.
[00:12:42.240 --> 00:12:43.000]   >> Yeah.
[00:12:43.000 --> 00:12:44.320]   >> They're both vectors.
[00:12:44.320 --> 00:12:46.920]   And now it's saying that I don't have D, which makes sense,
[00:12:46.920 --> 00:12:48.840]   because I haven't defined the key.
[00:12:48.840 --> 00:12:51.920]   I guess before I do that, I'll define the key C.
[00:12:51.920 --> 00:12:53.920]   Let's do the same thing I was doing before.
[00:12:53.920 --> 00:12:59.440]   I'm gonna do C and go into it, which gives me another array.
[00:12:59.440 --> 00:13:02.400]   And then I'm gonna do another index in, and it gives me one.
[00:13:02.400 --> 00:13:04.720]   So it's actually the same as B.
[00:13:04.720 --> 00:13:06.520]   >> Yeah. >> Cool, and that makes sense to me.
[00:13:06.520 --> 00:13:10.640]   This is a subarray here and then another comma with another.
[00:13:10.640 --> 00:13:13.680]   So would they be the rows or are they the dimensions of the-
[00:13:13.680 --> 00:13:18.560]   >> Those right there are the rows of just from, this is a convention in NumPy.
[00:13:18.560 --> 00:13:19.800]   In a lot of these libraries,
[00:13:19.800 --> 00:13:24.520]   you basically can build your arrays out of lists, like nested lists.
[00:13:24.520 --> 00:13:26.560]   So if you think just like from Python's perspective,
[00:13:26.560 --> 00:13:28.800]   what I did was I built a nested list.
[00:13:28.800 --> 00:13:32.120]   And then I gave it to a library that turned it into something else,
[00:13:32.120 --> 00:13:33.840]   which is an array now.
[00:13:33.840 --> 00:13:36.880]   So lots of these libraries are based off the idea of nested lists.
[00:13:36.880 --> 00:13:42.000]   In NumPy, the inner lists are the rows of the matrix.
[00:13:42.000 --> 00:13:45.320]   And so the columns aren't represented explicitly here.
[00:13:45.320 --> 00:13:46.440]   They're implicit.
[00:13:46.440 --> 00:13:51.560]   The columns of C are 1, 0, like 1 on the top, 0 on the bottom.
[00:13:51.560 --> 00:13:56.320]   Actually, go ahead and just for fun here, Scott, could you change it to 1, 2, 3, 4?
[00:13:56.320 --> 00:13:57.160]   >> Like this?
[00:13:57.160 --> 00:13:59.320]   >> 3, 4, yeah, just like that.
[00:13:59.320 --> 00:14:01.280]   We're just doing a little teachable moment here.
[00:14:01.280 --> 00:14:07.760]   So 1, 2 is a row, 3, 4 is a row, 1, 3 is a column.
[00:14:07.760 --> 00:14:08.960]   You can't really highlight it.
[00:14:08.960 --> 00:14:11.080]   2, 4 is also a column.
[00:14:11.080 --> 00:14:15.960]   >> And that's the, so it's the first element of my first row,
[00:14:15.960 --> 00:14:18.760]   and then the first element of my second row.
[00:14:18.760 --> 00:14:23.240]   >> You can access these things using the syntax of NumPy really easily,
[00:14:23.240 --> 00:14:28.280]   but it's implicit in the way the data is represented that those things are around.
[00:14:28.280 --> 00:14:31.720]   So the way you would do that is, happens to be with a colon.
[00:14:31.720 --> 00:14:33.160]   Yeah, exactly like that.
[00:14:33.160 --> 00:14:35.920]   So now we have, we've pulled out the column, 1, 3.
[00:14:35.920 --> 00:14:36.880]   >> That is great.
[00:14:36.880 --> 00:14:40.280]   >> Yeah, so let's do the dimensions of D just to close things out.
[00:14:40.280 --> 00:14:45.440]   >> To close things out, okay, and that is, let's do the same.
[00:14:45.440 --> 00:14:50.000]   So that gives me another list, but it's only got one element in it, so
[00:14:50.000 --> 00:14:54.120]   that could confuse you, but it's still, because of the number of brackets,
[00:14:54.120 --> 00:14:56.200]   it is still dimensions 2.
[00:14:56.200 --> 00:15:00.120]   This is an important thing about types that a lot of people confuse,
[00:15:00.120 --> 00:15:03.560]   because types can be a little bit unnatural to the way humans think.
[00:15:03.560 --> 00:15:07.680]   If I see an array that just has one thing in it, I immediately think, well,
[00:15:07.680 --> 00:15:10.600]   an array with just one thing in it has no extra information.
[00:15:10.600 --> 00:15:12.400]   Like an array with just a 3 in it,
[00:15:12.400 --> 00:15:14.960]   how's that any different from just the number 3, right?
[00:15:14.960 --> 00:15:18.680]   Or another common one is like tuples with only one element in it.
[00:15:18.680 --> 00:15:22.880]   People are surprised that's different from the element by itself.
[00:15:22.880 --> 00:15:26.960]   But this is an important distinction, because an array has things like access
[00:15:26.960 --> 00:15:31.160]   the items of an array, or transpose the array, or all these other things,
[00:15:31.160 --> 00:15:34.760]   functions defined on it, that only make sense if you have an array.
[00:15:34.760 --> 00:15:41.280]   You can't transpose a 3, it would look like a pair of little hills on the horizon.
[00:15:41.280 --> 00:15:43.520]   But you can transpose an array that contains a 3.
[00:15:43.520 --> 00:15:45.440]   So that little bit of information there,
[00:15:45.440 --> 00:15:47.800]   it's easy for people to get a little bit confused about that.
[00:15:47.800 --> 00:15:51.840]   And that's actually why there's that little test there, B and D are both vectors.
[00:15:51.840 --> 00:15:53.120]   People are sometimes,
[00:15:53.120 --> 00:15:57.400]   they think of vectors as something that only has one dimension to it.
[00:15:57.400 --> 00:16:00.840]   So I noticed when I was teaching this class that a lot of students
[00:16:00.840 --> 00:16:05.920]   would give the answer 1 for both B and D and be very confused.
[00:16:05.920 --> 00:16:08.120]   And so that first test there actually just checks,
[00:16:08.120 --> 00:16:10.240]   did they answer the same thing for B and D?
[00:16:10.240 --> 00:16:14.560]   Was the person working on this exercise clear that B and D are the same type of
[00:16:14.560 --> 00:16:18.960]   thing? And then there's a second test that checks to see whether they got the answer,
[00:16:18.960 --> 00:16:20.640]   whether they said 2 for both of them.
[00:16:20.640 --> 00:16:23.320]   So imagine actually here, Scott, for a brief moment,
[00:16:23.320 --> 00:16:26.800]   that you saw that array 3 and you're like, okay, I've indexed in once.
[00:16:26.800 --> 00:16:30.920]   I got out a single number that D0 gives array 3 there.
[00:16:30.920 --> 00:16:33.600]   And then you were like, that must mean it has one dimension.
[00:16:33.600 --> 00:16:38.240]   So then you would answer 1 for the dimensions D there.
[00:16:38.240 --> 00:16:40.800]   >> Yeah. >> So go ahead and put the answer 1 in.
[00:16:40.800 --> 00:16:42.920]   >> And then this is the error, okay.
[00:16:42.920 --> 00:16:45.200]   >> So then this person might go in and say, well,
[00:16:45.200 --> 00:16:47.960]   then B must have dimension 1 as well.
[00:16:47.960 --> 00:16:50.480]   So then go ahead and put 1 in for B.
[00:16:50.480 --> 00:16:52.160]   >> So I didn't fall for this trick.
[00:16:52.160 --> 00:16:53.760]   >> You did not fall for this trick.
[00:16:53.760 --> 00:16:55.520]   But I've taught these classes before and
[00:16:55.520 --> 00:16:58.680]   I've seen the places where people get confused with a lot of the exercises and
[00:16:58.680 --> 00:16:59.560]   concepts.
[00:16:59.560 --> 00:17:02.560]   So what this test specifically says, you can see there,
[00:17:02.560 --> 00:17:06.000]   there's those little comments that explain what this thing is checking.
[00:17:06.000 --> 00:17:07.680]   And give you a hint, right?
[00:17:07.680 --> 00:17:10.920]   B and D are explicitly row and column vectors.
[00:17:10.920 --> 00:17:13.240]   B is a row vector and D is a column vector.
[00:17:13.240 --> 00:17:14.600]   And so they have two dimensions.
[00:17:14.600 --> 00:17:17.200]   There's a little bit of a statement here about what the issue is.
[00:17:17.200 --> 00:17:19.000]   You can also sort of post in the Weights and
[00:17:19.000 --> 00:17:22.760]   Biases community about these exercises and get hints and help.
[00:17:22.760 --> 00:17:27.040]   And having the output of the autograder can be really helpful for
[00:17:27.040 --> 00:17:30.040]   finding what the right answer is or understanding where you may have made
[00:17:30.040 --> 00:17:30.840]   a mistake. >> Cool.
[00:17:30.840 --> 00:17:34.320]   >> Yeah, just wanted to demonstrate how I see this autograder working.
[00:17:34.320 --> 00:17:37.000]   So go ahead, you had those as your answers, so let's check and
[00:17:37.000 --> 00:17:37.760]   see if you got it.
[00:17:37.760 --> 00:17:40.240]   All right, yeah, so that's what it'll look like if you pass.
[00:17:40.240 --> 00:17:43.560]   There's nothing to tell you about what mistakes you might be making or
[00:17:43.560 --> 00:17:45.280]   what hints might help you out.
[00:17:45.280 --> 00:17:46.960]   So it just says 100% passed.
[00:17:46.960 --> 00:17:48.080]   >> Cool, all right.
[00:17:48.080 --> 00:17:50.920]   So yeah, so we start off with these relatively simple exercises.
[00:17:50.920 --> 00:17:54.680]   So I'm actually going to just jump past this one about shapes here.
[00:17:54.680 --> 00:17:55.920]   It's pretty similar.
[00:17:55.920 --> 00:18:00.840]   Shapes, again, are not just how many things you need to index into something,
[00:18:00.840 --> 00:18:04.880]   but how many elements do you get with each thing that you index in.
[00:18:04.880 --> 00:18:07.440]   So dimensions, in general, by the way,
[00:18:07.440 --> 00:18:11.160]   are available in NumPy arrays with this end_dim thing here.
[00:18:11.160 --> 00:18:14.800]   So if you wanna find this out, rather than just looking at a bunch of arrays and
[00:18:14.800 --> 00:18:16.960]   guessing what their shapes are like we just did,
[00:18:16.960 --> 00:18:19.000]   there's a programmatic way to get that information.
[00:18:19.000 --> 00:18:22.600]   So when you're programming with arrays and you wanna check their number of
[00:18:22.600 --> 00:18:27.440]   dimensions to see whether you understand them correctly or
[00:18:27.440 --> 00:18:30.920]   to check their shape information, how many rows and columns do they have,
[00:18:30.920 --> 00:18:35.280]   how many elements there are in each dimension, use these end_dim and
[00:18:35.280 --> 00:18:37.120]   shape to get that information.
[00:18:37.120 --> 00:18:42.360]   And when you're debugging, it's a very common pattern to do a bunch of
[00:18:42.360 --> 00:18:48.320]   assert statements, say this shape should start with one, should end with five.
[00:18:48.320 --> 00:18:51.920]   The shapes of these two things should be not equal or
[00:18:51.920 --> 00:18:53.520]   definitely equal to each other.
[00:18:53.520 --> 00:18:56.600]   And those kind of assert statements are where you can pick up if something is
[00:18:56.600 --> 00:19:00.440]   crashing, where maybe you've lost track of the shapes of the arrays that are
[00:19:00.440 --> 00:19:03.680]   flowing through your network or your machine learning algorithm.
[00:19:03.680 --> 00:19:09.120]   >> Okay, so if I understand correctly, these arrays, so let's say B,
[00:19:09.120 --> 00:19:13.560]   is this one, two, this shape information is,
[00:19:13.560 --> 00:19:18.720]   that is saying that I have one row and two columns, am I correct?
[00:19:18.720 --> 00:19:19.680]   >> Exactly, there.
[00:19:19.680 --> 00:19:20.640]   >> Yeah, okay, cool.
[00:19:20.640 --> 00:19:24.960]   >> Yeah, so rows and columns, old enough idea that we have special names for them.
[00:19:24.960 --> 00:19:27.400]   When you're working with arrays, especially in deep learning,
[00:19:27.400 --> 00:19:31.280]   they start to have three dimensions, four dimensions, five dimensions, and
[00:19:31.280 --> 00:19:34.520]   they stop necessarily, there's not a standard name for them like row and
[00:19:34.520 --> 00:19:38.200]   column, but actually something that's getting added and starting to use more and
[00:19:38.200 --> 00:19:43.280]   more in deep learning libraries and array libraries in general is named dimensions.
[00:19:43.280 --> 00:19:46.560]   So they aren't necessarily called rows and columns.
[00:19:46.560 --> 00:19:49.880]   But for example, if you have an image, you think of those as the height dimension and
[00:19:49.880 --> 00:19:52.440]   the width dimension maybe, rather than rows and columns.
[00:19:52.440 --> 00:19:57.440]   And then you have another dimension for color or the input channels of your image.
[00:19:57.440 --> 00:20:01.080]   So then these dimensions do end up having names and meaning to them, but
[00:20:01.080 --> 00:20:04.960]   unfortunately, there's not a standard name for the third dimension of array,
[00:20:04.960 --> 00:20:07.120]   the fourth dimension of array, the fifth dimension of an array.
[00:20:07.120 --> 00:20:10.280]   >> Yeah, I think I've seen that before in the work I did with audio.
[00:20:10.280 --> 00:20:13.920]   So it would be batch size would be your first dimension and
[00:20:13.920 --> 00:20:16.800]   then you would have maybe like feature dimension for
[00:20:16.800 --> 00:20:18.880]   number of features you have in your spectrogram.
[00:20:18.880 --> 00:20:23.480]   And then maybe your final dimension would be your number of frames in the audio
[00:20:23.480 --> 00:20:25.160]   sequence or something like that.
[00:20:25.160 --> 00:20:29.720]   I don't think we were using the latest version of PyTorch that has that feature.
[00:20:29.720 --> 00:20:32.040]   >> It helps keep track of these shapes.
[00:20:32.040 --> 00:20:35.680]   It's an additional layer of typing information that helps you when you're
[00:20:35.680 --> 00:20:39.560]   reading the code understand what the person writing the code was expecting it to do.
[00:20:39.560 --> 00:20:43.280]   And also helps you when you're writing your code, keep yourself honest about what
[00:20:43.280 --> 00:20:45.880]   are these things and what do I want out of them.
[00:20:45.880 --> 00:20:48.360]   So it's a really nice additional layer of information.
[00:20:48.360 --> 00:20:51.760]   >> One additional note, sometimes see people do this,
[00:20:51.760 --> 00:20:54.200]   assign these to variable names.
[00:20:54.200 --> 00:20:58.760]   So they'd be like feature something, batch size or whatever is equal to that and
[00:20:58.760 --> 00:21:01.800]   then they can use that information dynamically within their code.
[00:21:01.800 --> 00:21:02.800]   >> Yeah, exactly.
[00:21:02.800 --> 00:21:07.000]   I think the name tensor interface with PyTorch is still a better beta and
[00:21:07.000 --> 00:21:11.240]   the tensor typing stuff in mypy is even more beta right now.
[00:21:11.240 --> 00:21:13.040]   So that'd be a good way to get that information and
[00:21:13.040 --> 00:21:17.560]   use it programmatically while we wait for those features to be fully implemented.
[00:21:17.560 --> 00:21:18.200]   >> Cool.
[00:21:18.200 --> 00:21:20.400]   >> Yeah, keep going to the next exercise.
[00:21:20.400 --> 00:21:25.240]   One of the most common operations on matrices that affects their shape
[00:21:25.240 --> 00:21:26.800]   is the transpose.
[00:21:26.800 --> 00:21:29.200]   So the transpose of a matrix,
[00:21:29.200 --> 00:21:32.880]   it's written with a capital T next to the matrix when you're doing math.
[00:21:32.880 --> 00:21:37.280]   And it's actually written almost exactly the same in NumPy as the .t attribute.
[00:21:37.280 --> 00:21:42.000]   So it's so important that it is an attribute, not just a method, and
[00:21:42.000 --> 00:21:43.880]   it's a single letter attribute.
[00:21:43.880 --> 00:21:45.120]   >> Okay. >> So
[00:21:45.120 --> 00:21:47.920]   there's a little inline question here actually.
[00:21:47.920 --> 00:21:50.960]   So comparing the transpose matrices to the originals,
[00:21:50.960 --> 00:21:54.400]   can you describe in your own words what a transpose does?
[00:21:54.400 --> 00:21:55.200]   >> Great question.
[00:21:55.200 --> 00:22:01.760]   Okay, so it rotates the matrix, is that a fair?
[00:22:01.760 --> 00:22:05.040]   It swaps the rows with the columns, would that be a better way to say it?
[00:22:05.040 --> 00:22:06.880]   >> Those are both great ways of phrasing it.
[00:22:06.880 --> 00:22:10.640]   Yeah, rotating the matrix or flipping it around its diagonal.
[00:22:10.640 --> 00:22:12.480]   And then, yeah, swapping the rows and the columns.
[00:22:12.480 --> 00:22:14.840]   So what used to be a row is now a column.
[00:22:14.840 --> 00:22:18.000]   Like actually just print, make a new cell and print B.
[00:22:18.000 --> 00:22:20.560]   >> Okay. >> So we used to have a row that was 1,
[00:22:20.560 --> 00:22:25.120]   2, and now when we print B transpose there, yeah, perfect.
[00:22:25.120 --> 00:22:31.360]   Now the row 1, 2 has become a column 1, 2, and the column just the number 1
[00:22:31.360 --> 00:22:33.640]   has become the row just the number 1.
[00:22:33.640 --> 00:22:36.320]   Transposes switch these two things.
[00:22:36.320 --> 00:22:38.640]   >> Okay, so this is like the way it was printing earlier on,
[00:22:38.640 --> 00:22:44.440]   the way we saw columns aren't easily hideable, but they're, yeah, okay, cool.
[00:22:44.440 --> 00:22:45.360]   >> Yeah, exactly.
[00:22:45.360 --> 00:22:50.800]   So transposition is very closely related to matrix shape information.
[00:22:50.800 --> 00:22:54.120]   It's something that we use to make two matrices compatible
[00:22:54.120 --> 00:22:57.280]   when they wouldn't be because one has the right number of columns,
[00:22:57.280 --> 00:23:00.000]   the other one has the right number, the same number of columns.
[00:23:00.000 --> 00:23:02.280]   So if I take two matrices that have the same number of rows and columns,
[00:23:02.280 --> 00:23:04.520]   I can't always multiply them.
[00:23:04.520 --> 00:23:06.200]   But if you transpose them,
[00:23:06.200 --> 00:23:11.640]   then you can always multiply matrix with matrix transpose.
[00:23:11.640 --> 00:23:13.120]   This is something that comes up quite a bit.
[00:23:13.120 --> 00:23:15.360]   It's a useful feature of transposes.
[00:23:15.360 --> 00:23:19.400]   There's some blog posts linked in the slides that talk about why that's a useful thing.
[00:23:19.400 --> 00:23:22.840]   Let's just do one little quick exercise with the transpose here.
[00:23:22.840 --> 00:23:27.720]   Let's define a function called shape of transpose that takes in a matrix
[00:23:27.720 --> 00:23:30.480]   and returns the shape of the transpose of matrix.
[00:23:30.480 --> 00:23:31.400]   >> Okay.
[00:23:31.400 --> 00:23:34.560]   >> Actually, let's run the autograder here just one more time.
[00:23:34.560 --> 00:23:38.480]   We'll just demonstrate what the autograder looks like with now a function
[00:23:38.480 --> 00:23:41.360]   instead of a concrete variable as the answer.
[00:23:41.360 --> 00:23:44.640]   So test begin here, callable, shape of transpose.
[00:23:44.640 --> 00:23:48.080]   So that's just checking, did you define a function called shape of transpose?
[00:23:48.080 --> 00:23:49.560]   >> Okay.
[00:23:49.560 --> 00:23:52.800]   The shape is a reverse shape of the input matrix.
[00:23:52.800 --> 00:23:56.000]   Shape of transpose is equal to the transpose shape.
[00:23:56.000 --> 00:23:58.640]   >> So I think sometimes the tests are,
[00:23:58.640 --> 00:24:01.200]   you know, seeing them before you try the problem is really helpful.
[00:24:01.200 --> 00:24:04.160]   Other times they're useful for catching an edge case
[00:24:04.160 --> 00:24:05.960]   that you might've missed or something like that.
[00:24:05.960 --> 00:24:07.600]   So for this one, I think it's probably easier
[00:24:07.600 --> 00:24:10.680]   rather than reading the details of the tests there
[00:24:10.680 --> 00:24:12.640]   to actually just implement shape of transpose
[00:24:12.640 --> 00:24:15.400]   and check to see whether your first guess was right.
[00:24:15.400 --> 00:24:16.240]   >> Okay.
[00:24:16.240 --> 00:24:22.200]   So I'm going to give it a return operation that is going to get the transpose.
[00:24:22.200 --> 00:24:24.080]   And then I'm going to get the shape of that.
[00:24:24.080 --> 00:24:24.920]   >> Perfect.
[00:24:24.920 --> 00:24:26.960]   >> And that is shape of transpose.
[00:24:26.960 --> 00:24:29.040]   But if I run this now, it should pass.
[00:24:29.040 --> 00:24:29.960]   Oh, it does. Great.
[00:24:29.960 --> 00:24:30.800]   >> Perfect.
[00:24:30.800 --> 00:24:33.920]   Yeah, so actually one thing that I like about the solution that you chose
[00:24:33.920 --> 00:24:37.880]   is that it's like delegating this to other parts of the library.
[00:24:37.880 --> 00:24:40.520]   So what does it mean to get the shape of a transpose?
[00:24:40.520 --> 00:24:43.840]   It would be get the transpose of the matrix and then get its shape.
[00:24:43.840 --> 00:24:48.320]   >> So you mean like this, like transpose equals matrix.t
[00:24:48.320 --> 00:24:52.920]   and then say return the transposed shape.
[00:24:52.920 --> 00:24:54.920]   >> Yeah, that's what you did right in that line there.
[00:24:54.920 --> 00:24:57.960]   You've just sort of like split it out a little bit to make it more clear.
[00:24:57.960 --> 00:24:59.040]   Those are doing the same thing.
[00:24:59.040 --> 00:25:03.080]   And so the nice thing about that is this is guaranteed to be correct
[00:25:03.080 --> 00:25:05.640]   if transpose is implemented correctly,
[00:25:05.640 --> 00:25:09.160]   if that t is implemented correctly and shape is implemented correctly.
[00:25:09.160 --> 00:25:10.840]   So that's a really nice solution here,
[00:25:10.840 --> 00:25:14.280]   delegating this to the other parts of the library.
[00:25:14.280 --> 00:25:16.080]   Let's try and do a different solution
[00:25:16.080 --> 00:25:18.400]   where we try and calculate it directly.
[00:25:18.400 --> 00:25:22.440]   Rather than saying, oh, this is the shape of the transpose,
[00:25:22.440 --> 00:25:24.240]   let's try and like get concrete.
[00:25:24.240 --> 00:25:27.440]   What exactly is the shape of the transpose of a matrix?
[00:25:27.440 --> 00:25:30.800]   >> So you want me to do it more manual than calling the library?
[00:25:30.800 --> 00:25:32.000]   Is that what you're asking?
[00:25:32.000 --> 00:25:32.800]   >> Yeah, yeah.
[00:25:32.800 --> 00:25:35.400]   >> Okay, so a matrix is coming in
[00:25:35.400 --> 00:25:39.520]   and I feel like my instincts are telling me to,
[00:25:39.520 --> 00:25:43.040]   maybe it's a bad solution, is have multiple try index
[00:25:43.040 --> 00:25:46.080]   and then I'll know by the end of it, the number of dimensions,
[00:25:46.080 --> 00:25:48.400]   but that won't tell me the exact shape.
[00:25:48.400 --> 00:25:49.760]   >> Here's an idea actually,
[00:25:49.760 --> 00:25:52.480]   when you were giving your intuitive explanation
[00:25:52.480 --> 00:25:55.200]   or your description in your own words of what the transpose does,
[00:25:55.200 --> 00:25:57.400]   you said it's swap the rows and columns, right?
[00:25:57.400 --> 00:25:58.240]   >> Yeah.
[00:25:58.240 --> 00:26:00.960]   >> So one way to do this would be keep the shape call,
[00:26:00.960 --> 00:26:03.040]   but let's just drop the transpose part.
[00:26:03.040 --> 00:26:06.920]   How would you do it, like using that swap rows and columns idea?
[00:26:06.920 --> 00:26:07.800]   >> Ah, okay.
[00:26:07.800 --> 00:26:11.400]   So I just need to get the shape.
[00:26:11.400 --> 00:26:13.000]   Is it this one reversed?
[00:26:13.000 --> 00:26:14.520]   >> Yeah, actually, so that'll do it.
[00:26:14.520 --> 00:26:18.560]   That's, I think, actually how I answered the question in the tests.
[00:26:18.560 --> 00:26:20.520]   That syntax that Scott's using there
[00:26:20.520 --> 00:26:23.480]   is how you go backwards through a list in Python.
[00:26:23.480 --> 00:26:25.960]   And so he's going backwards through the shape.
[00:26:25.960 --> 00:26:29.480]   And so it's gonna give you first the columns, then the rows.
[00:26:29.480 --> 00:26:32.320]   And so that's the same if I transpose the matrix,
[00:26:32.320 --> 00:26:34.600]   if I swap the rows and columns,
[00:26:34.600 --> 00:26:37.440]   then the columns will be first 'cause now they're the rows
[00:26:37.440 --> 00:26:40.120]   and the rows will be second because now they're the columns.
[00:26:40.120 --> 00:26:43.360]   So reversing the list gives you exactly the shape
[00:26:43.360 --> 00:26:45.840]   of the transposed matrix.
[00:26:45.840 --> 00:26:46.920]   >> This might be a bit clear.
[00:26:46.920 --> 00:26:48.760]   >> Yeah, when people are working with arrays,
[00:26:48.760 --> 00:26:52.080]   they use that fancy indexing like what Scott did
[00:26:52.080 --> 00:26:54.520]   rather than using these functional things
[00:26:54.520 --> 00:26:56.360]   like reversed and things like that.
[00:26:56.360 --> 00:26:57.800]   But I agree with you, Scott,
[00:26:57.800 --> 00:26:59.760]   this has some nice clarity to it to say
[00:26:59.760 --> 00:27:02.760]   that we've reversed the shape and that gives us the answer.
[00:27:02.760 --> 00:27:05.520]   >> I still feel like I probably haven't given you the answer
[00:27:05.520 --> 00:27:07.880]   that you were expecting me to give.
[00:27:07.880 --> 00:27:12.360]   Is there some answer that doesn't use fancy indexing
[00:27:12.360 --> 00:27:14.120]   or reversing the shape?
[00:27:14.120 --> 00:27:16.280]   >> No, actually, I was doing a little bit
[00:27:16.280 --> 00:27:17.520]   of a Socratic thing.
[00:27:17.520 --> 00:27:19.840]   You jumped right to the end where I was going.
[00:27:19.840 --> 00:27:21.920]   The other thing that you can do is explicitly pull out
[00:27:21.920 --> 00:27:23.080]   the rows and the columns.
[00:27:23.080 --> 00:27:25.680]   >> Yeah, so I was going to do that,
[00:27:25.680 --> 00:27:29.560]   but then I realized that this can vary in its dimensions.
[00:27:29.560 --> 00:27:32.640]   So I was like, I don't want to do this.
[00:27:32.640 --> 00:27:37.600]   I could go and say numRows, numCalls,
[00:27:37.600 --> 00:27:40.040]   and then do matrix.shape,
[00:27:40.040 --> 00:27:42.160]   and then give this backwards,
[00:27:42.160 --> 00:27:45.000]   tuple like numCalls, numRows.
[00:27:45.000 --> 00:27:49.560]   But then I could get an error if it expects numFeatureX
[00:27:49.560 --> 00:27:51.000]   for another dimension.
[00:27:51.000 --> 00:27:52.360]   >> Yeah, I think you actually go ahead
[00:27:52.360 --> 00:27:55.320]   and put the numRows, numCalls version here
[00:27:55.320 --> 00:27:57.200]   and delete that line there.
[00:27:57.200 --> 00:27:59.400]   And then just use the grader to check to see
[00:27:59.400 --> 00:28:00.360]   if this is right.
[00:28:00.360 --> 00:28:01.280]   >> Okay, yeah, okay.
[00:28:01.280 --> 00:28:03.400]   So this is the solution maybe I could have given.
[00:28:03.400 --> 00:28:05.920]   This assumes that this can,
[00:28:05.920 --> 00:28:07.160]   I can't remember what it's called,
[00:28:07.160 --> 00:28:09.000]   unroll into this tuple,
[00:28:09.000 --> 00:28:11.680]   but if I have a bigger dimension, it won't unroll.
[00:28:11.680 --> 00:28:12.520]   >> Exactly.
[00:28:12.520 --> 00:28:15.880]   And so the nice thing about the shape of transpose one
[00:28:15.880 --> 00:28:18.400]   is that it delegates the input
[00:28:18.400 --> 00:28:20.120]   to know what its transpose is.
[00:28:20.120 --> 00:28:22.240]   And here you're sort of like making an assumption
[00:28:22.240 --> 00:28:24.240]   about what that transpose will look like.
[00:28:24.240 --> 00:28:26.120]   Well, this one's nice 'cause it's really explicit.
[00:28:26.120 --> 00:28:28.760]   The numRows, numCalls one is nice 'cause it's very explicit.
[00:28:28.760 --> 00:28:30.680]   And if you know that you're only ever
[00:28:30.680 --> 00:28:32.400]   going to receive matrices here,
[00:28:32.400 --> 00:28:35.160]   you know that you're only ever going to get 2D arrays here,
[00:28:35.160 --> 00:28:37.840]   then this is a fine implementation function.
[00:28:37.840 --> 00:28:38.920]   >> I guess what I could do as well
[00:28:38.920 --> 00:28:40.280]   is just to make sure of that,
[00:28:40.280 --> 00:28:44.640]   I could go len of matrix.shape is equal to two,
[00:28:44.640 --> 00:28:47.680]   and add some sort of a test or a manual thing
[00:28:47.680 --> 00:28:51.000]   so I know as a reader that this will always pass
[00:28:51.000 --> 00:28:52.040]   or the right is off throw.
[00:28:52.040 --> 00:28:55.800]   So informative thing, matrix should be two dimensional.
[00:28:55.800 --> 00:28:56.880]   >> Yeah, exactly.
[00:28:56.880 --> 00:28:58.560]   So with these exercises,
[00:28:58.560 --> 00:29:00.600]   I'm not asking people to implement tests.
[00:29:00.600 --> 00:29:02.200]   I'm not asking them to implement
[00:29:02.200 --> 00:29:04.040]   verifying the inputs.
[00:29:04.040 --> 00:29:05.920]   I usually will try and describe
[00:29:05.920 --> 00:29:07.640]   what they should expect the input to be.
[00:29:07.640 --> 00:29:08.640]   And then you can assume
[00:29:08.640 --> 00:29:10.680]   that you're getting well formatted inputs.
[00:29:10.680 --> 00:29:12.760]   And rather than trying to write those edge cases.
[00:29:12.760 --> 00:29:15.880]   When you're writing code that's not just to teach you,
[00:29:15.880 --> 00:29:17.400]   like code that you're writing for exercises,
[00:29:17.400 --> 00:29:19.560]   when you're writing code for yourself or others to run,
[00:29:19.560 --> 00:29:21.680]   you do wanna do stuff like that.
[00:29:21.680 --> 00:29:22.520]   >> Yeah, cool.
[00:29:22.520 --> 00:29:26.080]   So we're happy with this solution that matrix.t.shape.
[00:29:26.080 --> 00:29:29.560]   >> Yeah, I think that one is maybe the best solution
[00:29:29.560 --> 00:29:31.520]   from a programming perspective
[00:29:31.520 --> 00:29:33.720]   in terms of implementing a shape of transpose
[00:29:33.720 --> 00:29:37.920]   that's as like robust and extensible as possible.
[00:29:37.920 --> 00:29:39.800]   >> Well, it's best for teaching.
[00:29:39.800 --> 00:29:41.080]   >> Yeah, so that's why I ask,
[00:29:41.080 --> 00:29:43.560]   if you notice in the body of this exercise here,
[00:29:43.560 --> 00:29:47.080]   try doing this two ways with and without transposing matrix
[00:29:47.080 --> 00:29:48.280]   inside the body of the function.
[00:29:48.280 --> 00:29:49.120]   >> Okay, cool.
[00:29:49.120 --> 00:29:51.800]   >> So yeah, I think it's useful to do both of those things
[00:29:51.800 --> 00:29:53.920]   and think about why that should be.
[00:29:53.920 --> 00:29:55.840]   What are the trade-offs between these two things?
[00:29:55.840 --> 00:29:57.320]   Sometimes it actually is important
[00:29:57.320 --> 00:29:58.960]   that your code is very explicit,
[00:29:58.960 --> 00:30:01.040]   even outside of educational context,
[00:30:01.040 --> 00:30:03.400]   because you want people contributing to your library
[00:30:03.400 --> 00:30:06.200]   to be very clear on what the assumptions are
[00:30:06.200 --> 00:30:08.440]   and what's going on inside a particular function.
[00:30:08.440 --> 00:30:11.560]   Other times extensibility or maintainability
[00:30:11.560 --> 00:30:12.960]   are absolutely paramount.
[00:30:12.960 --> 00:30:14.600]   And so you'd want shape of transpose
[00:30:14.600 --> 00:30:16.560]   to be implemented the way you did it first.
[00:30:16.560 --> 00:30:18.080]   All right, let's keep going here
[00:30:18.080 --> 00:30:19.440]   and make sure to get to this functions
[00:30:19.440 --> 00:30:22.160]   and composition section before we end our time.
[00:30:22.160 --> 00:30:25.120]   If we think of shapes as our types,
[00:30:25.120 --> 00:30:29.720]   the two core components of computer programming are types
[00:30:29.720 --> 00:30:32.480]   and functions take one type to another type.
[00:30:32.480 --> 00:30:35.200]   So if we're gonna think of linear algebra as programming,
[00:30:35.200 --> 00:30:37.680]   what we really want is we need functions
[00:30:37.680 --> 00:30:40.320]   that take in arrays and return arrays.
[00:30:40.320 --> 00:30:41.880]   They take in arrays of particular shapes
[00:30:41.880 --> 00:30:44.080]   and return arrays of particular shapes.
[00:30:44.080 --> 00:30:46.040]   We can think of matrices as functions
[00:30:46.040 --> 00:30:48.440]   that take in vectors and return vectors.
[00:30:48.440 --> 00:30:49.920]   And my favorite way to try and like
[00:30:49.920 --> 00:30:52.120]   shift people's perspective here on this
[00:30:52.120 --> 00:30:54.480]   is that when we're working with matrices in mathematics,
[00:30:54.480 --> 00:30:57.280]   we tend to give them names like capital X and capital Y,
[00:30:57.280 --> 00:30:59.120]   just like we give functions in mathematics
[00:30:59.120 --> 00:31:00.920]   names like little f and little g.
[00:31:00.920 --> 00:31:03.400]   Writing those kinds of names for your tensors
[00:31:03.400 --> 00:31:04.760]   and your arrays and your programs
[00:31:04.760 --> 00:31:06.840]   that are just like capital X, W,
[00:31:06.840 --> 00:31:08.600]   those sort of put you in this frame
[00:31:08.600 --> 00:31:11.280]   of thinking about algebra and equations
[00:31:11.280 --> 00:31:15.240]   and out of the frame of thinking of them as functions,
[00:31:15.240 --> 00:31:16.520]   out of the frame of thinking them
[00:31:16.520 --> 00:31:18.880]   as little tiny short computer programs.
[00:31:18.880 --> 00:31:22.440]   When we're naming functions and programs when programming,
[00:31:22.440 --> 00:31:23.560]   we give them meaningful names.
[00:31:23.560 --> 00:31:28.040]   We don't call it f and g, we call it delete user and print.
[00:31:28.040 --> 00:31:30.160]   So this first cell defines a matrix
[00:31:30.160 --> 00:31:32.320]   that sets the second element
[00:31:32.320 --> 00:31:34.560]   of the two-dimensional input vector to zero.
[00:31:34.560 --> 00:31:36.920]   So I've named it set second to zero there.
[00:31:36.920 --> 00:31:40.040]   - Sets the second element of the input array to zero.
[00:31:40.040 --> 00:31:41.960]   - So actually just go ahead and run this cell.
[00:31:41.960 --> 00:31:43.600]   - Okay, and asserts it's zero.
[00:31:43.600 --> 00:31:45.640]   - So that assertion statement is guaranteeing
[00:31:45.640 --> 00:31:46.960]   that at least for that input,
[00:31:46.960 --> 00:31:49.000]   the function does what it says on the box.
[00:31:49.000 --> 00:31:50.720]   It sets the second element to zero.
[00:31:50.720 --> 00:31:52.800]   And in order to know that that's what it does,
[00:31:52.800 --> 00:31:54.640]   you have to look at the array itself,
[00:31:54.640 --> 00:31:57.000]   the array set second to zero,
[00:31:57.000 --> 00:32:00.040]   and walk through how matrix multiplication works.
[00:32:00.040 --> 00:32:04.440]   We take the first row and we multiply it with the vector.
[00:32:04.440 --> 00:32:08.000]   So we grab the first element of the input,
[00:32:08.000 --> 00:32:09.440]   multiply it by one,
[00:32:09.440 --> 00:32:13.160]   the second element of the input and multiply it by zero.
[00:32:13.160 --> 00:32:15.320]   And that gives us the first element back.
[00:32:15.320 --> 00:32:18.120]   - That's like this times one.
[00:32:18.120 --> 00:32:18.960]   - Times one.
[00:32:18.960 --> 00:32:19.800]   - One.
[00:32:19.800 --> 00:32:22.120]   - One times zero.
[00:32:22.120 --> 00:32:22.960]   - Yeah, exactly.
[00:32:22.960 --> 00:32:24.560]   - And that's gonna give us 10.
[00:32:24.560 --> 00:32:26.760]   - So that's, what you just did is you sort of like
[00:32:26.760 --> 00:32:29.520]   unrolled out the definition of matrix multiplication
[00:32:29.520 --> 00:32:31.320]   and what would happen if you were doing it
[00:32:31.320 --> 00:32:32.400]   as a for loop or whatever,
[00:32:32.400 --> 00:32:33.720]   but you just unrolled it out
[00:32:33.720 --> 00:32:35.800]   into what that expression looks like.
[00:32:35.800 --> 00:32:37.160]   Yeah, great, love that.
[00:32:37.160 --> 00:32:39.000]   Now let's do it for the second row.
[00:32:39.000 --> 00:32:39.840]   - And that's this.
[00:32:39.840 --> 00:32:43.320]   So that's vector zero, which is this,
[00:32:43.320 --> 00:32:45.120]   times the first element here,
[00:32:45.120 --> 00:32:46.680]   so it should be zero here.
[00:32:46.680 --> 00:32:49.240]   - Right, the first element of the second row, yeah.
[00:32:49.240 --> 00:32:50.320]   - Yeah, so this.
[00:32:50.320 --> 00:32:54.080]   So I'm doing this times this plus this times this.
[00:32:54.080 --> 00:32:54.920]   - Yes.
[00:32:54.920 --> 00:32:56.680]   - Which is again, okay, so it is zero.
[00:32:56.680 --> 00:32:58.960]   - You know, if you play around with this array a little bit,
[00:32:58.960 --> 00:33:01.400]   you like look at the numbers in it and draw them out,
[00:33:01.400 --> 00:33:03.360]   you can see what this array is doing.
[00:33:03.360 --> 00:33:07.240]   It's always going to do nothing to the first input
[00:33:07.240 --> 00:33:11.120]   and put it in the output as the first element of the output
[00:33:11.120 --> 00:33:14.000]   and then just return a zero as its second element.
[00:33:14.000 --> 00:33:14.920]   - Yeah, okay, cool.
[00:33:14.920 --> 00:33:17.000]   'Cause the first element is always just gonna look
[00:33:17.000 --> 00:33:19.000]   at the first one 'cause it's got a one there.
[00:33:19.000 --> 00:33:20.200]   - Yep.
[00:33:20.200 --> 00:33:21.800]   - Or the first row will always just look
[00:33:21.800 --> 00:33:24.360]   at the first element of the vector
[00:33:24.360 --> 00:33:26.640]   and then the second element of the vector won't get up there
[00:33:26.640 --> 00:33:27.920]   'cause it's got a zero here.
[00:33:27.920 --> 00:33:28.760]   - Yeah.
[00:33:28.760 --> 00:33:30.200]   - So when it's deciding what to put out
[00:33:30.200 --> 00:33:32.880]   as its second element, that ends up,
[00:33:32.880 --> 00:33:35.160]   just both of these get multiplied by zero.
[00:33:35.160 --> 00:33:36.640]   So this second one will always be zero.
[00:33:36.640 --> 00:33:37.480]   - Exactly.
[00:33:37.480 --> 00:33:39.520]   So, you know, most arrays are just like full
[00:33:39.520 --> 00:33:40.920]   of a bunch of random numbers, right?
[00:33:40.920 --> 00:33:42.520]   If you pick a random matrix,
[00:33:42.520 --> 00:33:44.440]   it's just gonna be full of a bunch of random numbers.
[00:33:44.440 --> 00:33:47.040]   It's not necessarily gonna have like definition
[00:33:47.040 --> 00:33:49.160]   of what it does, set second to zero.
[00:33:49.160 --> 00:33:50.480]   But I mean, in a neural network,
[00:33:50.480 --> 00:33:52.120]   it might, you might have like components
[00:33:52.120 --> 00:33:53.760]   of your weight matrix that are doing things
[00:33:53.760 --> 00:33:55.880]   like extracting a particular feature.
[00:33:55.880 --> 00:33:58.480]   And it's more helpful to think of that,
[00:33:58.480 --> 00:34:01.920]   less as like a variable like X or Y
[00:34:01.920 --> 00:34:04.880]   or a generic mathematical function like F or G,
[00:34:04.880 --> 00:34:06.120]   where you would maybe be thinking of,
[00:34:06.120 --> 00:34:07.920]   oh, it's like sines or cosines
[00:34:07.920 --> 00:34:09.880]   or these other simple mathematical functions.
[00:34:09.880 --> 00:34:11.520]   And think of them instead like the functions
[00:34:11.520 --> 00:34:12.720]   we program into computers,
[00:34:12.720 --> 00:34:14.960]   where they do some meaningful,
[00:34:14.960 --> 00:34:16.760]   human understandable kind of thing.
[00:34:16.760 --> 00:34:19.000]   Extract all the edges in an image
[00:34:19.000 --> 00:34:21.520]   is maybe what the convolutional operation done
[00:34:21.520 --> 00:34:23.280]   by a single neuron is doing
[00:34:23.280 --> 00:34:25.320]   in the first layer of your ConvNet.
[00:34:25.320 --> 00:34:26.160]   - Yeah.
[00:34:26.160 --> 00:34:28.960]   So as our last exercise in this first session,
[00:34:28.960 --> 00:34:31.960]   what I'd like to do is do this same thing,
[00:34:31.960 --> 00:34:34.280]   define a matrix that does something that has,
[00:34:34.280 --> 00:34:36.920]   you know, a simple description, a simple name.
[00:34:36.920 --> 00:34:39.040]   And this matrix is called repeat three, two.
[00:34:39.040 --> 00:34:40.920]   It's gonna take in a vector of length two
[00:34:40.920 --> 00:34:43.560]   and return it repeated three times.
[00:34:43.560 --> 00:34:44.400]   - Okay.
[00:34:44.400 --> 00:34:47.200]   So I want a NumPy array defined here
[00:34:47.200 --> 00:34:50.560]   that is going to act like a function
[00:34:50.560 --> 00:34:54.680]   when it's given this one dimensional array
[00:34:54.680 --> 00:34:56.440]   will return another one dimensional array
[00:34:56.440 --> 00:34:58.080]   that's been like tiled.
[00:34:58.080 --> 00:34:58.920]   - Yeah.
[00:34:58.920 --> 00:34:59.760]   - Okay.
[00:34:59.760 --> 00:35:03.040]   I think I've seen this before as like a function default.
[00:35:03.040 --> 00:35:06.520]   So I won't try to use a NumPy,
[00:35:06.520 --> 00:35:07.720]   like, I don't know, maybe.
[00:35:07.720 --> 00:35:09.520]   I won't look at the docs and see.
[00:35:09.520 --> 00:35:12.200]   So I'm gonna have to think through this.
[00:35:12.200 --> 00:35:13.040]   - Yeah.
[00:35:13.040 --> 00:35:15.400]   Here, that's helpful.
[00:35:15.400 --> 00:35:17.440]   Just like when you're working on functions in a library,
[00:35:17.440 --> 00:35:19.440]   it's helpful to just get the types right.
[00:35:19.440 --> 00:35:20.800]   What is coming into this function?
[00:35:20.800 --> 00:35:22.360]   What kind of numbers are coming in?
[00:35:22.360 --> 00:35:24.360]   What is the class that all the inputs
[00:35:24.360 --> 00:35:25.200]   are gonna be in?
[00:35:25.200 --> 00:35:26.240]   What kind of class do I wanna put out?
[00:35:26.240 --> 00:35:27.480]   Thinking through the shapes first
[00:35:27.480 --> 00:35:30.440]   is a great way to just put pen to paper,
[00:35:30.440 --> 00:35:31.440]   get some things out there.
[00:35:31.440 --> 00:35:33.600]   So what is the shape of this array?
[00:35:33.600 --> 00:35:36.600]   Just fill it with dummy numbers for repeat three, two.
[00:35:36.600 --> 00:35:39.760]   - I think if I hadn't just done this exercise,
[00:35:39.760 --> 00:35:42.640]   I wouldn't feel as confident to do this now.
[00:35:42.640 --> 00:35:45.440]   But I'm realizing from going through this,
[00:35:45.440 --> 00:35:47.160]   so I want six out here.
[00:35:47.160 --> 00:35:50.360]   So I want to have six rows here.
[00:35:50.360 --> 00:35:54.120]   That'll deter for six columns here.
[00:35:54.120 --> 00:35:56.120]   - Six rows.
[00:35:56.120 --> 00:35:56.960]   - Oh, six rows.
[00:35:56.960 --> 00:35:58.360]   - And six rows, you had it right.
[00:35:58.360 --> 00:36:01.960]   And each row is gonna give us one output.
[00:36:01.960 --> 00:36:03.200]   - Yeah, so six rows.
[00:36:03.200 --> 00:36:04.040]   This is a row.
[00:36:04.040 --> 00:36:06.920]   So I could basically copy this definition.
[00:36:06.920 --> 00:36:10.040]   I only want one number as in my output.
[00:36:10.040 --> 00:36:11.440]   Oh, sorry, I'm skipping ahead.
[00:36:11.440 --> 00:36:13.920]   Point is we want six out here.
[00:36:13.920 --> 00:36:15.600]   So I want six here.
[00:36:15.600 --> 00:36:17.120]   And that'll get me my shape.
[00:36:17.120 --> 00:36:19.760]   I might have to get rid of a row here,
[00:36:19.760 --> 00:36:21.200]   or sorry, a column here.
[00:36:21.200 --> 00:36:22.640]   - I don't think you do, right?
[00:36:22.640 --> 00:36:26.000]   Because the input shape is two.
[00:36:26.000 --> 00:36:28.560]   So you want something that's three times two by two,
[00:36:28.560 --> 00:36:29.840]   which is what you had for.
[00:36:29.840 --> 00:36:31.240]   - Three times two.
[00:36:31.240 --> 00:36:32.160]   - Okay. - Six.
[00:36:32.160 --> 00:36:33.440]   - The input shape is two.
[00:36:33.440 --> 00:36:34.680]   The answer was already here.
[00:36:34.680 --> 00:36:36.000]   The input shape is two.
[00:36:36.000 --> 00:36:39.600]   This is gonna give me an output shape of three times two.
[00:36:39.600 --> 00:36:40.440]   - Great.
[00:36:40.440 --> 00:36:42.680]   Go ahead and actually, so you just copied and pasted.
[00:36:42.680 --> 00:36:46.480]   Go ahead and put the commas in to make this syntax correct.
[00:36:46.480 --> 00:36:47.880]   And pass it through the autograder
[00:36:47.880 --> 00:36:48.720]   and let's see what happens.
[00:36:48.720 --> 00:36:49.560]   - Cool.
[00:36:49.560 --> 00:36:51.160]   - All right, so here's some of the checks
[00:36:51.160 --> 00:36:52.080]   that I'm doing here.
[00:36:52.080 --> 00:36:53.200]   You know, if we'd gone in
[00:36:53.200 --> 00:36:54.800]   and just put the answer in correctly,
[00:36:54.800 --> 00:36:56.080]   you wouldn't have seen all this stuff.
[00:36:56.080 --> 00:36:58.320]   So first, repeat three, two is an array.
[00:36:58.320 --> 00:37:01.000]   It should have two dimensions, rows and columns.
[00:37:01.000 --> 00:37:03.420]   It should take in length two vectors as its input.
[00:37:03.420 --> 00:37:06.640]   And the output should be three times that length.
[00:37:06.640 --> 00:37:09.040]   So it should have, so this is just checking that it's six,
[00:37:09.040 --> 00:37:11.040]   but with a nice little hint and a little bit of code
[00:37:11.040 --> 00:37:13.040]   that pushes you in the direction of thinking of it
[00:37:13.040 --> 00:37:15.960]   as not just six, but literally three times two.
[00:37:15.960 --> 00:37:17.520]   - Three times the length of the input.
[00:37:17.520 --> 00:37:20.320]   - Okay, but we're not getting the right answer.
[00:37:20.320 --> 00:37:22.760]   Its output is three copies of the input, right?
[00:37:22.760 --> 00:37:24.320]   We expected one, two, one, two, one, two,
[00:37:24.320 --> 00:37:25.480]   but we're getting one, one, one, one, one.
[00:37:25.480 --> 00:37:29.480]   - So I go this, where I've now given a one as my,
[00:37:29.480 --> 00:37:32.480]   so this is gonna select the second element
[00:37:32.480 --> 00:37:34.880]   and then zero out the first.
[00:37:34.880 --> 00:37:36.640]   But I want to do that over and over again,
[00:37:36.640 --> 00:37:40.400]   so I can do this and just have it select first,
[00:37:40.400 --> 00:37:42.680]   select second, select first, select second.
[00:37:42.680 --> 00:37:43.520]   - Perfect.
[00:37:43.520 --> 00:37:44.760]   - But that is probably the wrong word, but.
[00:37:44.760 --> 00:37:46.540]   - No, no, actually I like select.
[00:37:46.540 --> 00:37:49.640]   People usually call these the canonical basis vectors
[00:37:49.640 --> 00:37:51.920]   in math, like a canonical basis vector
[00:37:51.920 --> 00:37:54.640]   is the one whose entry is one in one spot
[00:37:54.640 --> 00:37:55.960]   and zero everywhere else.
[00:37:55.960 --> 00:37:57.080]   But when I think about these,
[00:37:57.080 --> 00:38:00.160]   I think of them as selectors or one-hots, right?
[00:38:00.160 --> 00:38:02.040]   They pull one number out.
[00:38:02.040 --> 00:38:03.960]   That's thinking of them as functions,
[00:38:03.960 --> 00:38:06.280]   'cause you take those canonical basis vectors
[00:38:06.280 --> 00:38:08.440]   and use them as functions, that's what they do.
[00:38:08.440 --> 00:38:11.240]   So I think thinking of this as the canonical basis vectors,
[00:38:11.240 --> 00:38:13.360]   the way people do in a linear algebra class
[00:38:13.360 --> 00:38:14.340]   in a math perspective,
[00:38:14.340 --> 00:38:16.260]   it's not a bad way to think about them,
[00:38:16.260 --> 00:38:18.520]   but I think it's more useful in machine learning
[00:38:18.520 --> 00:38:20.840]   to think about these things as functions.
[00:38:20.840 --> 00:38:22.960]   And even better, you would want to actually
[00:38:22.960 --> 00:38:24.760]   have both of these ways in your pocket
[00:38:24.760 --> 00:38:26.400]   as ways to think about these arrays,
[00:38:26.400 --> 00:38:29.620]   not just as elements that might show up
[00:38:29.620 --> 00:38:33.520]   in a matrix equation, but as functions that act on arrays.
[00:38:33.520 --> 00:38:34.360]   - Cool.
[00:38:34.360 --> 00:38:35.720]   - All right, yeah, so thanks, Scott,
[00:38:35.720 --> 00:38:38.120]   for working through these exercises,
[00:38:38.120 --> 00:38:41.200]   and we'll come back and do another one of these,
[00:38:41.200 --> 00:38:42.040]   finish out this one,
[00:38:42.040 --> 00:38:44.200]   and move on to the rest of the exercises.
[00:38:44.200 --> 00:38:46.200]   - Sweet, thanks, Charles, it's been fun.
[00:38:46.720 --> 00:38:49.300]   (upbeat music)
[00:38:50.300 --> 00:38:55.300]    All right, all right, all right, all right 
[00:38:55.300 --> 00:38:57.880]   (upbeat music)
[00:38:57.880 --> 00:39:00.460]   (upbeat music)
[00:39:00.460 --> 00:39:03.040]   (upbeat music)
[00:39:03.040 --> 00:39:05.620]   (upbeat music)
[00:39:05.620 --> 00:39:07.000]   (camera shutter clicks)

