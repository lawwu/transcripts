
[00:00:00.000 --> 00:00:02.420]   And I think you make a good point and a good defense for globalism,
[00:00:02.420 --> 00:00:05.420]   but I think the exact response would be if you're the president of the United
[00:00:05.420 --> 00:00:08.820]   States, you know, you're, you're not, you're not looking out for, you know,
[00:00:08.820 --> 00:00:11.980]   the standard of living for all humans or for all people around the globe,
[00:00:11.980 --> 00:00:14.820]   you're looking out for the standard of living of people in the United States,
[00:00:14.820 --> 00:00:17.580]   you know, who, who you have a constitutional oath to.
[00:00:17.580 --> 00:00:22.780]   But my point is that even with that lens,
[00:00:22.780 --> 00:00:27.300]   you have to think about the dynamics around the globe and pulling up the wall
[00:00:27.580 --> 00:00:32.340]   and trying to get people to make a $40 microwave in America is going to
[00:00:32.340 --> 00:00:33.180]   fail.
[00:00:33.180 --> 00:00:48.020]   Hey Bill. It's great to see you. Good to see you, sir.
[00:00:48.020 --> 00:00:51.340]   Are you going to apply to run the sovereign wealth fund or actually better yet?
[00:00:51.340 --> 00:00:52.020]   Can I,
[00:00:52.020 --> 00:00:55.740]   will you give me permission to nominate you to run the sovereign wealth fund?
[00:00:55.860 --> 00:00:59.180]   I, you know, I would think there are people that, uh,
[00:00:59.180 --> 00:01:03.740]   that I've met through my days that are LPs at rather large funds that have way
[00:01:03.740 --> 00:01:05.620]   better experience for something like that.
[00:01:05.620 --> 00:01:09.020]   I think you would be a hell of a choice. Um, certainly on,
[00:01:09.020 --> 00:01:11.260]   maybe on the board of the sovereign wealth fund,
[00:01:11.260 --> 00:01:13.580]   but it's going to be a fascinating experiment.
[00:01:13.580 --> 00:01:18.100]   One observation I had is as we're getting ready for the pod today is last night
[00:01:18.100 --> 00:01:22.340]   I was helping, uh, Lincoln study for his AP history exam. And, you know,
[00:01:22.340 --> 00:01:24.520]   he's studying the gilded age and more importantly,
[00:01:24.520 --> 00:01:27.020]   kind of the McKinley presidency. And,
[00:01:27.020 --> 00:01:30.780]   and it's all about the McKinley tariffs. And I said to him,
[00:01:30.780 --> 00:01:34.980]   it's pretty amazing that you and I are working on the same thing. You know,
[00:01:34.980 --> 00:01:38.700]   I'm reading on chat GPT about the McKinley tariffs. And he said, yeah,
[00:01:38.700 --> 00:01:42.500]   but dad, don't worry about it. You don't have to take the test. And I said,
[00:01:42.500 --> 00:01:46.780]   worse yet, I have to figure out how much money to be exposed to the market.
[00:01:46.780 --> 00:01:49.540]   What are, what are risks going to be in the hedge fund? I said, don't worry.
[00:01:49.540 --> 00:01:53.060]   I get it. I get it. I get a scorecard on that too. Um,
[00:01:53.100 --> 00:01:54.560]   a little weightier than the test.
[00:01:54.560 --> 00:01:58.880]   No doubt. I mean, you and I could go full Lex Friedman today, by the way,
[00:01:58.880 --> 00:02:02.920]   his five hours show pod recently with Dylan, those guys was great,
[00:02:02.920 --> 00:02:04.880]   but we're going to try to keep this, you know,
[00:02:04.880 --> 00:02:09.640]   pretty tight and jam quickly on deep seek on tariffs on doge on, you know,
[00:02:09.640 --> 00:02:12.760]   maybe what the market reaction might be to all of these things.
[00:02:12.760 --> 00:02:15.200]   And as I was thinking about this setup bill, you know,
[00:02:15.200 --> 00:02:17.600]   I thought it would be helpful. You know,
[00:02:17.600 --> 00:02:20.400]   you and I got into this and we said we wanted the pod to be about this
[00:02:20.400 --> 00:02:23.640]   intersection of tech and markets investing in capitalism.
[00:02:23.640 --> 00:02:27.900]   And we specifically kind of wanted to stay away from Washington and, and,
[00:02:27.900 --> 00:02:28.820]   and politics,
[00:02:28.820 --> 00:02:32.820]   but it's really impossible at the moment to talk about capitalism and markets
[00:02:32.820 --> 00:02:36.380]   and what's happening without talking about the big things occurring in
[00:02:36.380 --> 00:02:38.260]   Washington. So we're going to do that,
[00:02:38.260 --> 00:02:41.940]   but we're really going to try to stick to the economic and market lens of the
[00:02:41.940 --> 00:02:44.300]   events that are happening rather than the political lens.
[00:02:44.300 --> 00:02:47.540]   There are incredible pods you can listen to that give you kind of the political
[00:02:47.560 --> 00:02:50.820]   analysis of all of this. So maybe we just dive in.
[00:02:50.820 --> 00:02:53.220]   Yeah, that'd be great. And listen, I mean,
[00:02:53.220 --> 00:02:57.820]   when you expand the lens to include that and you look at the
[00:02:57.820 --> 00:03:01.940]   ridiculous pace of,
[00:03:01.940 --> 00:03:04.300]   of innovation in the AI space,
[00:03:04.300 --> 00:03:09.100]   I don't ever recall a single time in my career where it
[00:03:09.100 --> 00:03:13.140]   feels like you could just have your ear to the ground 24 seven,
[00:03:13.140 --> 00:03:15.780]   and you're picking up something new constantly.
[00:03:16.140 --> 00:03:20.200]   No doubt about it. No doubt about it. Speaking of, you know,
[00:03:20.200 --> 00:03:24.920]   we covered DeepSeek last week, Bill, it seems like it was just yesterday,
[00:03:24.920 --> 00:03:27.640]   but a lot's happened since then. For one,
[00:03:27.640 --> 00:03:31.160]   these usage charts for DeepSeek are really quite amazing.
[00:03:31.160 --> 00:03:33.000]   And Driessen tweeted this, you know,
[00:03:33.000 --> 00:03:37.600]   which shows the percentage of DAUs relative to chat GPT,
[00:03:37.600 --> 00:03:39.320]   you know, their top geos,
[00:03:39.320 --> 00:03:43.080]   I think they have something like 15% in India and like 10% in China,
[00:03:43.640 --> 00:03:47.060]   8% in Indonesia. It's really a global phenomenon. You know,
[00:03:47.060 --> 00:03:51.020]   one of the things that struck me after all of this is you tweeted,
[00:03:51.020 --> 00:03:55.780]   it's a better world if the most disruptive LLM model
[00:03:55.780 --> 00:04:00.680]   is foreign and open source versus domestic and proprietary, right?
[00:04:00.680 --> 00:04:04.060]   As you said, it's better for safety, for security, for free speech, et cetera.
[00:04:04.060 --> 00:04:08.420]   So talk us through where you think we stand today
[00:04:08.420 --> 00:04:12.580]   based on a little space now reflecting on R1, you know,
[00:04:12.620 --> 00:04:17.540]   and we know that you and Benchmark have been like the staunchest proponents of
[00:04:17.540 --> 00:04:22.140]   open source over the course of the last few decades. Help us,
[00:04:22.140 --> 00:04:25.620]   help us understand how you think open source versus closed source is going to
[00:04:25.620 --> 00:04:26.280]   evolve.
[00:04:26.280 --> 00:04:31.280]   Yeah. And so, so, so let me give you some reflections now,
[00:04:31.280 --> 00:04:34.020]   having, having this been a week in the,
[00:04:34.020 --> 00:04:38.060]   in the rear view mirror and reading and watching as much as I can of other
[00:04:38.060 --> 00:04:42.420]   people talking. So here, here's some things I think we know about DeepSeek.
[00:04:43.020 --> 00:04:47.180]   And R1, the, it was quite innovative, you know, 0.1.
[00:04:47.180 --> 00:04:52.300]   And if you have five hours to listen to Dylan and Nathan Lambert on Lex
[00:04:52.300 --> 00:04:55.220]   Friedman, they get into some of this. They, um,
[00:04:55.220 --> 00:04:59.740]   DeepSeek could put more experts simultaneously against a problem.
[00:04:59.740 --> 00:05:03.500]   They were able to do that because they figured out a way to, um,
[00:05:03.500 --> 00:05:08.540]   separate the parameters and work on things with smaller parameter counts faster,
[00:05:08.540 --> 00:05:11.700]   which, um, no one else had done before.
[00:05:12.060 --> 00:05:15.620]   And so you end up with something that's cheaper and faster. And,
[00:05:15.620 --> 00:05:19.140]   and it's just important to recognize that they did innovate, right?
[00:05:19.140 --> 00:05:23.780]   Versus just copy. Cause I think there's a lot of noise around this whole thing.
[00:05:23.780 --> 00:05:29.100]   Um, three, they did choose to be the most open model we know of today.
[00:05:29.100 --> 00:05:33.220]   And there's a lot of people that like to get into nuanced conversations about
[00:05:33.220 --> 00:05:34.860]   whether it's truly open source.
[00:05:34.860 --> 00:05:39.900]   I guess people are hoping for one day when someone shows all the data and all
[00:05:40.180 --> 00:05:43.100]   the training processes. And so they may have been short of that,
[00:05:43.100 --> 00:05:45.140]   but with the MIT license,
[00:05:45.140 --> 00:05:49.700]   which has no restriction whatsoever on how you do this and open weights.
[00:05:49.700 --> 00:05:53.820]   Um, it gives a lot of freedom to a lot of people to take this thing and run in
[00:05:53.820 --> 00:05:55.780]   opposite directions, which I'll come back to.
[00:05:55.780 --> 00:06:01.340]   The thing you mentioned is also I think worth noting the success was a
[00:06:01.340 --> 00:06:05.420]   breakthrough and maybe not compared to open AI, you know,
[00:06:05.500 --> 00:06:10.500]   but certainly I think Mistral or Anthropic or any of these players would have
[00:06:10.500 --> 00:06:15.060]   loved to have had the, the launch moment,
[00:06:15.060 --> 00:06:18.060]   if you will, the deep sea cat and,
[00:06:18.060 --> 00:06:20.340]   and weren't able to achieve it for whatever reasons.
[00:06:20.340 --> 00:06:23.740]   I don't know if we can fully explain why, you know,
[00:06:23.740 --> 00:06:28.900]   this app is still number one in the app store today. Um, I, I, I,
[00:06:28.900 --> 00:06:32.020]   the thing you mentioned that I think is super interesting is rest of world,
[00:06:32.020 --> 00:06:35.060]   you know, and, and we're going to go into, you know,
[00:06:35.060 --> 00:06:37.780]   how this might play into China, U S you know,
[00:06:37.780 --> 00:06:42.380]   sanctions and restrictions and rest of the world could be up for grabs.
[00:06:42.380 --> 00:06:46.460]   A couple of other points, I think worth mentioning one, it's,
[00:06:46.460 --> 00:06:48.980]   it's validated now that they went around CUDA.
[00:06:48.980 --> 00:06:51.380]   And I just think that's interesting. Like,
[00:06:51.380 --> 00:06:55.300]   it's interesting to think about why it's interesting to think about performance
[00:06:55.300 --> 00:06:59.420]   optimization and how you might get down to the bare metal. You know,
[00:06:59.420 --> 00:07:03.980]   when we went from on-prem software to SAS places like
[00:07:03.980 --> 00:07:08.940]   AWS, they started pulling out as many layers as they could to get to optimization.
[00:07:08.940 --> 00:07:13.660]   And so you ended up with very special versions of Linux and whatnot,
[00:07:13.660 --> 00:07:16.060]   where things are just ripped out and ripped out and ripped out.
[00:07:16.060 --> 00:07:18.940]   So I think that's worth noting. And, and I've,
[00:07:18.940 --> 00:07:22.820]   I know of at least another example where someone that's working on inference
[00:07:22.820 --> 00:07:25.740]   optimization went underneath as well. And then,
[00:07:25.740 --> 00:07:30.140]   and then the last point I would make that I think is just worth understanding
[00:07:30.140 --> 00:07:33.340]   you and I stumbled upon, I think with the help of Sonny,
[00:07:33.340 --> 00:07:38.340]   this interview in Chinese with the founder and we translated and read it.
[00:07:38.340 --> 00:07:41.780]   And I think it's impossible to read that and,
[00:07:41.780 --> 00:07:44.500]   and say this isn't an exceptional founder.
[00:07:44.500 --> 00:07:49.500]   Like he's just intelligent, independently minded.
[00:07:49.500 --> 00:07:52.060]   I think it'd be very hard to,
[00:07:52.060 --> 00:07:55.060]   to make an argument that he's not a remarkable founder.
[00:07:55.060 --> 00:08:00.260]   And of course, of course you're referring to Ling Wen-Fen, you know,
[00:08:00.260 --> 00:08:01.100]   the founder of DeepSea.
[00:08:01.100 --> 00:08:03.460]   And we'll put the link to that interview and you can,
[00:08:03.460 --> 00:08:08.140]   you can copy it and put it into chat GPT or whatever and get a quick
[00:08:08.140 --> 00:08:08.980]   translation.
[00:08:08.980 --> 00:08:11.060]   Well, and Bill, as you know, you know, our,
[00:08:11.060 --> 00:08:15.660]   our team knows him quite well and knows a lot of members of the DeepSea team,
[00:08:15.660 --> 00:08:19.220]   but you know, he's become really a national hero in China. And, you know,
[00:08:19.220 --> 00:08:21.500]   I think it's a, you know, there's a little bit more of a,
[00:08:21.500 --> 00:08:23.860]   of a telescope on him today, but we did,
[00:08:23.860 --> 00:08:28.420]   we did learn some things when we talked to the DeepSea team and a few of those,
[00:08:28.420 --> 00:08:31.860]   I think are pretty salient. And, and I, I would share again,
[00:08:31.860 --> 00:08:35.620]   just setting the table for kind of the facts that I think a lot of them are very
[00:08:35.620 --> 00:08:38.620]   confirmatory of what, what you just had to say. Number one,
[00:08:38.620 --> 00:08:41.300]   he's an incredible founder. Like there is no doubt about that.
[00:08:41.300 --> 00:08:45.340]   He's been working on this problem for upwards of, of a decade,
[00:08:45.340 --> 00:08:48.540]   been thinking about it. He's very successful and,
[00:08:48.540 --> 00:08:51.540]   and has made a lot of money, you know, in the hedge fund business.
[00:08:51.540 --> 00:08:53.100]   And so, you know,
[00:08:53.100 --> 00:08:56.380]   it reminds me a little bit of the Jim Simon story at Renaissance, right?
[00:08:56.380 --> 00:08:59.900]   These are brilliant folks who happened to apply this,
[00:08:59.900 --> 00:09:03.980]   this early AI and deep learning edge to you know, to,
[00:09:03.980 --> 00:09:07.660]   to the hedge fund business and quant trading. But, you know,
[00:09:07.660 --> 00:09:09.860]   a couple of the key things that were debated last week,
[00:09:09.860 --> 00:09:14.060]   one was the total compute CapEx. And when you take power into account,
[00:09:14.060 --> 00:09:18.740]   it really does, it does get you closer to this billion dollars of TCO,
[00:09:18.740 --> 00:09:23.140]   which was out there, you know, discussed, which is similar, I think,
[00:09:23.140 --> 00:09:27.060]   to the TCO of, of the comparative models. Now, of course,
[00:09:27.060 --> 00:09:31.100]   they talked about the $6 million final training run. And this,
[00:09:31.100 --> 00:09:34.900]   it's important to understand this is also correct, right?
[00:09:34.900 --> 00:09:36.980]   And as I said on CNBC,
[00:09:36.980 --> 00:09:41.620]   this compares to about 10 or 15 million for oh one out of open AI.
[00:09:41.620 --> 00:09:43.420]   So apples to apples,
[00:09:43.420 --> 00:09:48.260]   they were 30 to 50% more efficient to your earlier point about real
[00:09:48.260 --> 00:09:52.180]   algorithmic breakthroughs. And now of course they were doing this a few months
[00:09:52.180 --> 00:09:56.860]   later maybe, maybe six to eight months later than what was going on at open AI.
[00:09:56.860 --> 00:10:00.180]   So to expect some of those savings, but take nothing away from them.
[00:10:00.180 --> 00:10:03.060]   A lot of them were, came from algorithmic improvements,
[00:10:03.060 --> 00:10:05.060]   many of which I think are going to be copied, but,
[00:10:05.060 --> 00:10:06.540]   but breakthroughs nonetheless.
[00:10:06.540 --> 00:10:10.860]   I would add one thing to that, which is just worth paying attention to.
[00:10:10.860 --> 00:10:15.820]   And Dylan and Nathan went into this on the LexPod, but, but they believe,
[00:10:15.820 --> 00:10:17.540]   so I can't really defend it.
[00:10:17.780 --> 00:10:22.780]   They believe if you look at models that are apples to apples on the API right
[00:10:22.780 --> 00:10:27.260]   now, that the deep seeks pricing about one 20th of open AI.
[00:10:27.260 --> 00:10:28.420]   And so,
[00:10:28.420 --> 00:10:32.780]   and they argue about whether open AI might just have higher margins or,
[00:10:32.780 --> 00:10:35.100]   or whether deep seek might be subsidizing,
[00:10:35.100 --> 00:10:38.540]   but that differential is bigger than the ones you,
[00:10:38.540 --> 00:10:40.500]   than the one you described for training.
[00:10:40.500 --> 00:10:43.300]   Yeah, no, you're, you're referencing what it,
[00:10:43.300 --> 00:10:47.260]   what they're charging the customer for inference. And remember,
[00:10:47.620 --> 00:10:51.340]   you know, like, and it gets to a couple other points I'm about ready to make,
[00:10:51.340 --> 00:10:54.300]   they can run it well below cost,
[00:10:54.300 --> 00:10:57.220]   or they could choose to be running at well below cost in order to,
[00:10:57.220 --> 00:11:00.020]   to have these outcomes. I don't think that's going to last.
[00:11:00.020 --> 00:11:04.980]   And open AI might be charging well, you know, well above cost for that, but,
[00:11:04.980 --> 00:11:06.340]   but let's, let's keep going.
[00:11:06.340 --> 00:11:11.260]   I think Lyft, I think Lyft endured rides well below cost for a decade.
[00:11:11.260 --> 00:11:16.020]   No, you, you can do it for a very long time. So in that regard,
[00:11:16.060 --> 00:11:17.660]   but let's get back to the compute stack,
[00:11:17.660 --> 00:11:20.540]   because this was something we learned from their team that I think is really
[00:11:20.540 --> 00:11:21.460]   important to understand.
[00:11:21.460 --> 00:11:27.500]   Their compute stack was smaller than the compute stack that open AI used to
[00:11:27.500 --> 00:11:31.900]   train a one, but it wasn't that much smaller. Okay.
[00:11:31.900 --> 00:11:37.140]   And so the problem they now face is that this changes
[00:11:37.140 --> 00:11:41.700]   dramatically. Remember, these are log linear scaling functions.
[00:11:41.700 --> 00:11:44.980]   So in order to get to kind of the Oh three level,
[00:11:44.980 --> 00:11:48.940]   now they got a 10 X the amount of compute, right.
[00:11:48.940 --> 00:11:53.740]   Assuming that they don't come through with some massive
[00:11:53.740 --> 00:11:57.380]   architectural improvements that caused them to be able to do log linear scaling
[00:11:57.380 --> 00:12:01.460]   without more compute. Right. But to get to that next step function,
[00:12:01.460 --> 00:12:05.300]   they acknowledge it's going to be a lot harder. So set another way,
[00:12:05.300 --> 00:12:09.540]   this was the moment in time where their compute comparison to open AI was the
[00:12:09.540 --> 00:12:13.580]   closest it's ever going to be for a few reasons. Number ones with,
[00:12:13.580 --> 00:12:16.580]   with the export controls, they acknowledge they,
[00:12:16.580 --> 00:12:20.860]   they're going to have a very hard time keeping up with Oh three and Stargate's
[00:12:20.860 --> 00:12:22.660]   going to be even much more challenging.
[00:12:22.660 --> 00:12:25.700]   They're not going to have access to Blackwell that is, you know,
[00:12:25.700 --> 00:12:30.100]   two to three X improvement on top of the Hopper series, which already exists.
[00:12:30.100 --> 00:12:33.980]   This differential in GPUs is, is,
[00:12:33.980 --> 00:12:37.580]   as they begin to train Oh three is far greater than it was for Oh one.
[00:12:38.340 --> 00:12:40.780]   On top of that, we learned, you know,
[00:12:40.780 --> 00:12:43.860]   they are massively compute constrained right now.
[00:12:43.860 --> 00:12:47.460]   So you've seen some tweets about this people that are, you know,
[00:12:47.460 --> 00:12:49.420]   getting server delay and all this stuff with,
[00:12:49.420 --> 00:12:51.460]   with these guys because of their massive success.
[00:12:51.460 --> 00:12:55.140]   So they have a limited cluster to begin with and their current deploying,
[00:12:55.140 --> 00:12:58.500]   they're currently taking most of that compute and deploying it against
[00:12:58.500 --> 00:12:59.620]   inference, right.
[00:12:59.620 --> 00:13:03.420]   Just to support the demand that they have coming in the door,
[00:13:03.420 --> 00:13:06.460]   which further constrains their ability to do training.
[00:13:06.500 --> 00:13:09.620]   And we know they got a 10 X the training to get to that next, you know,
[00:13:09.620 --> 00:13:14.580]   to that next function. So this is a really tough situation.
[00:13:14.580 --> 00:13:18.420]   I think, you know, we'll get into this, the export controls,
[00:13:18.420 --> 00:13:20.260]   remember on Oh one,
[00:13:20.260 --> 00:13:25.260]   they already had somewhere in the order of 30 to 50,000 GPUs that they had
[00:13:25.260 --> 00:13:29.740]   previously purchased. And there's a lot of debate is exactly how many they had,
[00:13:29.740 --> 00:13:31.660]   but the differential wasn't that great.
[00:13:31.660 --> 00:13:35.620]   But now when you have to step up to 10 X that it becomes very challenging.
[00:13:35.900 --> 00:13:39.700]   So that we learned, those are things that we think we've confirmed, you know,
[00:13:39.700 --> 00:13:42.260]   directly, directly from the company.
[00:13:42.260 --> 00:13:46.540]   And so I would expect one of the things that would impress me even more, Bill,
[00:13:46.540 --> 00:13:49.740]   you know, I asked the team at OpenAI, like,
[00:13:49.740 --> 00:13:52.940]   what did this surprise them to deep seek surprise them? And they said,
[00:13:52.940 --> 00:13:56.260]   the only thing that surprised them is that it was a Chinese company that was able
[00:13:56.260 --> 00:13:59.060]   to get there before Meta and others. Right.
[00:13:59.060 --> 00:14:01.220]   And I think it's a really important question.
[00:14:01.220 --> 00:14:03.100]   The thing that would impress me even more,
[00:14:03.660 --> 00:14:08.660]   if somehow they figure out an architectural or algorithmic way to catch up with
[00:14:08.660 --> 00:14:12.300]   Oh three and deep research and the stuff that's now, you know,
[00:14:12.300 --> 00:14:17.340]   really truly frontier without having access to GPUs,
[00:14:17.340 --> 00:14:20.500]   that will to me be the definitive, you know,
[00:14:20.500 --> 00:14:24.540]   kind of the statement that they have somehow breaking the broken,
[00:14:24.540 --> 00:14:28.060]   the paradigm on, on cost and, you know, scaling.
[00:14:28.060 --> 00:14:28.740]   Yeah. And we,
[00:14:28.980 --> 00:14:33.860]   we wouldn't be the first person to say it because even Farid Zakaria said it on,
[00:14:33.860 --> 00:14:37.260]   on his show on national television, but you know,
[00:14:37.260 --> 00:14:40.900]   everyone's talking about the fact that constraints can lead to innovation.
[00:14:40.900 --> 00:14:45.900]   And the reason Lama probably didn't do it is they had access to scaling.
[00:14:45.900 --> 00:14:49.220]   And so only if you're limited on that function,
[00:14:49.220 --> 00:14:51.020]   might you making an algorithmic change.
[00:14:51.020 --> 00:14:56.140]   My guess is we could have one or something that Nathan Lambert might disagree
[00:14:56.140 --> 00:14:58.740]   with you about the 10 X requirement.
[00:14:58.740 --> 00:15:03.780]   But I will say this because it's open because they published the paper,
[00:15:03.780 --> 00:15:09.340]   I'm a hundred percent certain that people at Anthropic and at OpenAI are
[00:15:09.340 --> 00:15:12.540]   studying what DeepSea did.
[00:15:12.540 --> 00:15:16.460]   So if there was some innovative breakthrough, it's going to,
[00:15:16.460 --> 00:15:20.300]   the borrowing is going to be bi-directional and it's going to go right back.
[00:15:20.300 --> 00:15:22.700]   And then that gets you into Jevin's paradox,
[00:15:22.700 --> 00:15:24.780]   which everyone else is also talking about,
[00:15:24.780 --> 00:15:28.380]   which is if we make this stuff cheaper, isn't people are just going to buy more
[00:15:28.380 --> 00:15:28.940]   and more,
[00:15:28.940 --> 00:15:32.220]   but let me go back to your original question real quick on open source.
[00:15:32.220 --> 00:15:35.780]   Cause I do think there, I never really got around to answering it.
[00:15:35.780 --> 00:15:38.580]   And I, there are some things that I think are worth mentioning.
[00:15:38.580 --> 00:15:40.860]   So as you said, I tweeted, you know,
[00:15:40.860 --> 00:15:44.860]   I think a lot of people were worried about these models and whether they're
[00:15:44.860 --> 00:15:48.660]   control people, what people say and disinformation and what's embedded in them.
[00:15:48.660 --> 00:15:52.700]   And what do they do? You know, I'm a big believer and many,
[00:15:52.700 --> 00:15:54.620]   many people in academia are as well,
[00:15:54.620 --> 00:15:59.620]   that more transparency leads to more understanding,
[00:15:59.620 --> 00:16:04.100]   more safety, more security, more free speech, this kind of thing. So,
[00:16:04.100 --> 00:16:05.860]   and I'm not the only one that said this.
[00:16:05.860 --> 00:16:10.140]   If you had a singular model proprietary from a singular company,
[00:16:10.140 --> 00:16:14.180]   it would on all those fronts would give you more risk,
[00:16:14.180 --> 00:16:16.460]   more ability for someone to control that kind of thing.
[00:16:16.460 --> 00:16:20.580]   And let's be very clear, the very reason OpenAI exists, right?
[00:16:20.580 --> 00:16:25.380]   I remember when Elon first talked about it on stage at launch was to defend
[00:16:25.380 --> 00:16:30.660]   against singular control by Google of a closed tyrannical
[00:16:30.660 --> 00:16:31.420]   AI.
[00:16:31.420 --> 00:16:35.460]   So, so I put those all in one group and then I, then I said, look,
[00:16:35.460 --> 00:16:39.020]   it's also better for innovation, you know, startups,
[00:16:39.020 --> 00:16:42.940]   cost performance and global prosperity.
[00:16:42.940 --> 00:16:45.460]   And I'll give you a data point.
[00:16:45.460 --> 00:16:48.700]   I was talking with Clem over at Hugging Face.
[00:16:48.780 --> 00:16:53.460]   And so like 48 hours after R1 was posted,
[00:16:53.460 --> 00:16:56.580]   they had 500 variants on Hugging Face.
[00:16:56.580 --> 00:17:00.780]   And today I pinged them this morning before we started, they're up to 1300.
[00:17:00.780 --> 00:17:05.140]   And so these are just forks in different directions, right?
[00:17:05.140 --> 00:17:08.940]   And it allows people to do massive optimization.
[00:17:08.940 --> 00:17:10.940]   It allows people to solve problems.
[00:17:10.940 --> 00:17:15.940]   Any concern you may have about R1 someone can go work on, you know,
[00:17:15.940 --> 00:17:20.860]   it Linus's law from the original Bazaar and Cathedral
[00:17:20.860 --> 00:17:24.180]   paper was given enough eyes, all bugs are shallow.
[00:17:24.180 --> 00:17:28.900]   And this thing like the R&D force becomes the world,
[00:17:28.900 --> 00:17:31.260]   not just an individual player.
[00:17:31.260 --> 00:17:34.220]   And so it allows for so much optimization.
[00:17:34.220 --> 00:17:37.660]   It also makes enterprise companies happy.
[00:17:37.660 --> 00:17:42.580]   So Aaron Levy and Mark Benioff were out there very boldly
[00:17:42.580 --> 00:17:46.660]   supporting this R1 breakthrough, and it just makes sense, right?
[00:17:46.660 --> 00:17:49.540]   If there's a piece of technology that's a commodity
[00:17:49.540 --> 00:17:52.380]   that they need to be successful, they're better off
[00:17:52.380 --> 00:17:56.580]   than if there's some proprietary piece they have to license from someone.
[00:17:56.580 --> 00:18:00.900]   And it was quickly deployed in all the clouds and, you know, in AWS
[00:18:00.900 --> 00:18:04.380]   and in Azure. It's shocking to me, especially,
[00:18:04.380 --> 00:18:06.580]   especially the Microsoft deployment.
[00:18:06.580 --> 00:18:10.780]   So obviously that feels like a piece of the strategic
[00:18:11.140 --> 00:18:14.740]   back and forth between OpenAI and Microsoft around this contract.
[00:18:14.740 --> 00:18:19.660]   But yet everybody went up fast and it just shows you what's possible.
[00:18:19.660 --> 00:18:23.980]   And I think the amount of innovation that you can have and not just up
[00:18:23.980 --> 00:18:27.060]   the stack, I think, you know, people say, oh, that's going to allow people
[00:18:27.060 --> 00:18:30.900]   to build special models and all this stuff, but down the stack as well.
[00:18:30.900 --> 00:18:34.620]   If you, you know, are trying to compete with NVIDIA,
[00:18:34.620 --> 00:18:38.820]   you know, with with a TPU or a non GPU.
[00:18:39.140 --> 00:18:41.260]   We've talked about all these companies before.
[00:18:41.260 --> 00:18:44.740]   Or, you know, we're an investor in a company called Fireworks.
[00:18:44.740 --> 00:18:47.300]   It's trying to be this optimization middle layer,
[00:18:47.300 --> 00:18:50.220]   like high performance inference.
[00:18:50.220 --> 00:18:52.540]   And they have a lot of really amazing
[00:18:52.540 --> 00:18:56.940]   customers doing runtime inference right now.
[00:18:56.940 --> 00:19:02.300]   Production, knowing more about the model allows them to optimize even more.
[00:19:02.300 --> 00:19:06.380]   And so I think the rest of everybody else,
[00:19:06.940 --> 00:19:10.740]   other than the big proprietary models, are probably thrilled
[00:19:10.740 --> 00:19:15.020]   to have this type of of product out there.
[00:19:15.020 --> 00:19:20.100]   And once again, the variants will just will go and everyone will borrow from it.
[00:19:20.100 --> 00:19:23.420]   And hey, Bill, can I just hit pause for a second? Sure.
[00:19:23.420 --> 00:19:29.220]   You know, a year ago, there was a lot of excitement about Llama, OK?
[00:19:29.220 --> 00:19:34.380]   And Zach really took the leadership on kind of open source in the U.S.
[00:19:34.780 --> 00:19:40.100]   And, you know, here we are evangelizing, you're evangelizing about open source.
[00:19:40.100 --> 00:19:42.100]   But it's not about Llama, right?
[00:19:42.100 --> 00:19:44.380]   It's about it's about DeepSeek and R1.
[00:19:44.380 --> 00:19:46.180]   What do you think happened there?
[00:19:46.180 --> 00:19:49.140]   Do you just think it's scarcity and the leapfrog?
[00:19:49.140 --> 00:19:53.300]   You know, obviously, there are lots of reports that that there was a lot of
[00:19:53.300 --> 00:19:58.140]   trauma within within the Metaplex last week.
[00:19:58.140 --> 00:20:03.100]   People very upset about, you know, the fact that they were leapfrog here
[00:20:03.100 --> 00:20:05.740]   and the amount of money they're spending and they didn't get there first.
[00:20:05.740 --> 00:20:10.220]   But any speculation by you as to why?
[00:20:10.220 --> 00:20:11.740]   Why not them?
[00:20:11.740 --> 00:20:15.660]   I watched different open source battles
[00:20:15.660 --> 00:20:18.980]   and a whole bunch of different verticals since my firm was
[00:20:18.980 --> 00:20:24.220]   an original investor in Red Hat, I think, ninety nine to twenty five years ago.
[00:20:24.220 --> 00:20:29.220]   And there's always a continuum of openness.
[00:20:29.220 --> 00:20:31.700]   And there's a whole bunch of licenses.
[00:20:31.700 --> 00:20:37.260]   I tweeted this list of like a hierarchy or continuum of licenses.
[00:20:37.260 --> 00:20:40.260]   And they're from from most open to least open.
[00:20:40.260 --> 00:20:43.460]   And almost every company that tries to play in
[00:20:43.460 --> 00:20:47.260]   in the open source area is playing this weird game
[00:20:47.260 --> 00:20:51.020]   where they want the proliferation of openness.
[00:20:51.020 --> 00:20:55.180]   But they want some kind of hook to be able to to kind of call back
[00:20:55.180 --> 00:20:57.220]   and have proprietary advantage.
[00:20:57.220 --> 00:21:02.940]   And so, you know, we know that Meta had not gone fully open.
[00:21:02.940 --> 00:21:05.220]   The wait, they had never published the weights.
[00:21:05.220 --> 00:21:09.220]   And there was this clause that says, if you use too much,
[00:21:09.220 --> 00:21:10.580]   you got to come see us again.
[00:21:10.580 --> 00:21:14.060]   And that clause got got spread around.
[00:21:14.060 --> 00:21:18.060]   Yeah. So so so folks like Amazon actually have to pay Meta
[00:21:18.060 --> 00:21:20.620]   for the use of of llamas. Right.
[00:21:20.620 --> 00:21:24.140]   And so they were playing that game, that same game that all these companies
[00:21:24.140 --> 00:21:28.180]   have played, Mongo and Elastic, like they've all they've all had to play this game.
[00:21:28.180 --> 00:21:33.740]   And so, yeah, so it looks like these guys just decided to be more open.
[00:21:33.740 --> 00:21:37.780]   And the MIT license is pretty against the rail.
[00:21:37.780 --> 00:21:42.340]   And and as I said, there are people that say they could be even more open.
[00:21:42.340 --> 00:21:47.220]   But this is the most open for sure today.
[00:21:47.220 --> 00:21:50.140]   So keep keep going on.
[00:21:50.140 --> 00:21:53.380]   Actually, let me make let me let me make two last statements.
[00:21:53.380 --> 00:21:55.300]   And then and then we can shift. So one.
[00:21:55.300 --> 00:22:00.180]   China, I think it's really interesting
[00:22:00.180 --> 00:22:03.820]   to know that China is not a newcomer to open source.
[00:22:03.820 --> 00:22:09.820]   If you look at all of the major projects like Linux or MySQL
[00:22:09.820 --> 00:22:14.660]   and most of these open source projects have a website
[00:22:14.660 --> 00:22:19.660]   and you can see who the leading donors are and just go to the Linux one.
[00:22:19.660 --> 00:22:22.500]   I'll put a link in here from the Linux
[00:22:22.500 --> 00:22:25.740]   member group, and you'll see a ton of Chinese companies.
[00:22:25.740 --> 00:22:29.220]   And someone may say, why is China pro open source?
[00:22:29.220 --> 00:22:32.220]   Well, for the past 30 years,
[00:22:32.220 --> 00:22:37.180]   the West has done nothing but accuse them of being IP thieves.
[00:22:37.180 --> 00:22:42.860]   And so if you believe you have the fastest, cheapest,
[00:22:42.860 --> 00:22:47.140]   most capable entrepreneurs or engineers that can run faster
[00:22:47.140 --> 00:22:51.380]   and work harder than everyone else, you'd rather live in a world
[00:22:51.380 --> 00:22:56.980]   where there's no IP protection than one where you're just being held back.
[00:22:56.980 --> 00:23:03.700]   And so I think they jumped into open source full throttle.
[00:23:03.700 --> 00:23:06.100]   And, you know, it's not just Linux.
[00:23:06.100 --> 00:23:07.740]   It's not just this.
[00:23:07.740 --> 00:23:11.420]   If you look at RISC-V, they're one of the biggest supporters of RISC-V.
[00:23:11.420 --> 00:23:15.060]   And every time we put more constraints on what they can get to,
[00:23:15.060 --> 00:23:16.620]   they invest more in RISC-V.
[00:23:16.620 --> 00:23:20.100]   And so and I think this is particularly important
[00:23:20.100 --> 00:23:23.380]   relative to the rest of the world, as we brought up earlier,
[00:23:23.380 --> 00:23:27.020]   because and we'll get into this, we'll get into sanctions and whatnot.
[00:23:27.020 --> 00:23:31.420]   But if you pull the wall up and we don't support open source
[00:23:31.420 --> 00:23:36.140]   and they do and everybody else kind of likes them leading that way.
[00:23:36.140 --> 00:23:38.900]   Ooh, that could be a dangerous situation.
[00:23:38.900 --> 00:23:43.300]   And then the last point I just want to make, I want to go back to Fareed Zakari.
[00:23:43.300 --> 00:23:45.420]   I'm a big fan of his.
[00:23:45.420 --> 00:23:49.260]   He had two takeaways on DeepSeek, and I was impressed
[00:23:49.260 --> 00:23:53.020]   that he landed on both of these.
[00:23:53.020 --> 00:23:58.420]   But one was that that there was a lot of discussion,
[00:23:58.420 --> 00:24:00.860]   especially in Washington, that the U.S.
[00:24:00.860 --> 00:24:03.860]   was two years ahead of China.
[00:24:03.860 --> 00:24:08.780]   And he he said, look, it looks like after the fact
[00:24:08.780 --> 00:24:11.540]   that that's hubris, right?
[00:24:11.540 --> 00:24:16.860]   If if if that's now six months, three months, whatever, it's closing.
[00:24:16.860 --> 00:24:20.420]   And we need to think, I think, with our eyes wide open
[00:24:20.420 --> 00:24:22.980]   as we make policy decisions.
[00:24:22.980 --> 00:24:24.860]   And and I think that's important.
[00:24:24.860 --> 00:24:27.060]   And then the second one, I was just really impressed
[00:24:27.060 --> 00:24:31.380]   with his understanding of open versus closed and how
[00:24:31.380 --> 00:24:37.100]   you can reach a tipping point where things just move in that direction
[00:24:37.100 --> 00:24:40.460]   because so many different entities get behind it.
[00:24:40.820 --> 00:24:42.980]   I like to see water runs downhill.
[00:24:42.980 --> 00:24:46.700]   OK, so Sam Altman did this AMA last week
[00:24:46.700 --> 00:24:49.060]   and he was asked about DeepSeek and about open source.
[00:24:49.060 --> 00:24:52.700]   And I thought his response was really interesting, Bill.
[00:24:52.700 --> 00:24:55.620]   He said DeepSeek is an impressive model.
[00:24:55.620 --> 00:24:57.900]   You know, and to your point about Jevin's paradox, he's like,
[00:24:57.900 --> 00:25:00.940]   we're going to need a lot more compute, you know, because, you know,
[00:25:00.940 --> 00:25:05.260]   as we've said, demand for this is exploding their compute constraint, etc.
[00:25:05.260 --> 00:25:08.540]   And he said, and on the issue of open source, they said,
[00:25:08.540 --> 00:25:12.580]   would you consider releasing model weights and publishing your open source
[00:25:12.580 --> 00:25:16.100]   research? And Sam said, yes, we are discussing.
[00:25:16.100 --> 00:25:21.060]   I personally think we have been on the wrong side of history here
[00:25:21.060 --> 00:25:24.780]   and we need to figure out a different open source strategy.
[00:25:24.780 --> 00:25:29.540]   So I tweeted in response to, you know, something Mark Andreessen has said
[00:25:29.540 --> 00:25:33.140]   that I that I thought all current closed source model companies.
[00:25:33.380 --> 00:25:39.060]   So let's just say OpenAI and Anthropic would open source their models.
[00:25:39.060 --> 00:25:42.660]   And in the case of OpenAI, I could see them open source, you know,
[00:25:42.660 --> 00:25:45.220]   one which competes head to head with DeepSeek.
[00:25:45.220 --> 00:25:49.180]   At the same time, I could see all companies
[00:25:49.180 --> 00:25:53.580]   that are currently open source and closed, right, which includes DeepSeek.
[00:25:53.580 --> 00:25:55.580]   I could see them in the future.
[00:25:55.580 --> 00:25:58.060]   And Mark Zuckerberg has said he reserves the right
[00:25:58.060 --> 00:26:00.860]   not to release all the models in the future. Right.
[00:26:01.140 --> 00:26:05.700]   So I think we may end up with a world where the true frontier,
[00:26:05.700 --> 00:26:08.500]   the actual underlying model is not released at all.
[00:26:08.500 --> 00:26:11.420]   And the only thing that gets released is the agent. Right.
[00:26:11.420 --> 00:26:13.740]   But then one or two generations behind,
[00:26:13.740 --> 00:26:16.780]   you're going to see them all open sourcing these models.
[00:26:16.780 --> 00:26:19.020]   But let's start with Sam's comments.
[00:26:19.020 --> 00:26:23.220]   Are you encouraged that Sam has said, yes, we need to come up?
[00:26:23.220 --> 00:26:25.420]   You know, we're on the wrong side of history here.
[00:26:25.420 --> 00:26:30.700]   Well, I mean, to a certain extent, it validates what R1 did. Right.
[00:26:30.700 --> 00:26:35.300]   That he would feel the need to say that I have found just
[00:26:35.300 --> 00:26:40.820]   and you talk to him more than me, but I found that whenever a threat
[00:26:40.820 --> 00:26:46.140]   or a challenge is made to open AI, Sam tends to go towards it.
[00:26:46.140 --> 00:26:49.740]   Like that's his kind of go to move.
[00:26:49.740 --> 00:26:51.660]   And I think it works for him.
[00:26:51.660 --> 00:26:55.140]   Like and so I'm not surprised that he said that.
[00:26:55.780 --> 00:26:58.860]   I, I was surprised
[00:26:58.860 --> 00:27:02.700]   on a side note that a couple of our friends
[00:27:02.700 --> 00:27:06.460]   who are co-investors with you and OpenAI, when the R1 thing hit,
[00:27:06.460 --> 00:27:10.980]   kind of very quickly took to X to say that,
[00:27:10.980 --> 00:27:15.140]   you know, something that R1 cheated or that the government needed to come in.
[00:27:15.140 --> 00:27:19.660]   And to me, that was a validation point as well.
[00:27:19.660 --> 00:27:22.780]   Like you wouldn't take the trouble if this thing wasn't real.
[00:27:23.060 --> 00:27:26.380]   But yet it could it could tip us more towards open.
[00:27:26.380 --> 00:27:32.180]   I mean, as a as a as someone who who really enjoyed
[00:27:32.180 --> 00:27:36.100]   my business school classes on finance and economics, you know,
[00:27:36.100 --> 00:27:39.780]   one of the reasons I like open so so much is it's the closest thing
[00:27:39.780 --> 00:27:41.020]   to pure competition.
[00:27:41.020 --> 00:27:45.860]   If you look up an economics book, pure competition is like commodity,
[00:27:45.860 --> 00:27:50.900]   like hard to have, you know, prices leads to, you know, innovation,
[00:27:50.900 --> 00:27:53.380]   low price points, Jevin's paradox blowing up.
[00:27:53.380 --> 00:27:57.020]   And so I'm thrilled that it's tilting that direction.
[00:27:57.020 --> 00:28:00.420]   Now, this may be a perfect time to transition
[00:28:00.420 --> 00:28:04.100]   into the other thing that happened as a result of R1,
[00:28:04.100 --> 00:28:07.540]   which is there are a number of increased
[00:28:07.540 --> 00:28:11.620]   efforts to, I think.
[00:28:11.620 --> 00:28:16.140]   Raise the wall of regulation and sanctions.
[00:28:16.140 --> 00:28:19.780]   And it's funny, I watched a number of people go,
[00:28:19.980 --> 00:28:24.420]   oh, my God, look at R1, you know, Washington must act quickly.
[00:28:24.420 --> 00:28:29.060]   But but but the thing that each person intended
[00:28:29.060 --> 00:28:31.540]   are radically different from one another.
[00:28:31.540 --> 00:28:34.820]   You know, some people think this means, oh, we need to embrace open source
[00:28:34.820 --> 00:28:37.140]   and encourage more open innovation in America.
[00:28:37.140 --> 00:28:42.020]   And the other people think, oh, my God, you know, and Dario put out a long piece,
[00:28:42.020 --> 00:28:45.220]   you know, I guess, consistent with his entire tenure here,
[00:28:45.220 --> 00:28:47.900]   just begging for more lockdown and regulation.
[00:28:48.340 --> 00:28:52.860]   So let's let's go into that, because I do think it's industry interesting.
[00:28:52.860 --> 00:28:56.980]   Right. Sam and the industry response seems to be tipping more in the direction
[00:28:56.980 --> 00:28:58.900]   where we're going to go open to.
[00:28:58.900 --> 00:29:01.700]   And my suspicion is you will see that this year,
[00:29:01.700 --> 00:29:04.740]   you know, out of folks like like OpenAI.
[00:29:04.740 --> 00:29:08.900]   But the discussion about DeepSeek clearly touched a national nerve.
[00:29:08.900 --> 00:29:12.660]   Right. Jensen, you know, got got called to the White House
[00:29:12.660 --> 00:29:15.060]   last Friday or we all see me.
[00:29:15.060 --> 00:29:16.980]   I think they said it was pre-scheduled.
[00:29:16.980 --> 00:29:20.580]   Well, not I'm not sure whether or not that was the case, but let's assume it was.
[00:29:20.580 --> 00:29:23.780]   But it's opened up this broader conversation about whether the U.S.
[00:29:23.780 --> 00:29:27.820]   can or even whether it's wise for the U.S.
[00:29:27.820 --> 00:29:31.820]   to try to stop China from advancing along the AI frontier. Right.
[00:29:31.820 --> 00:29:34.660]   And some of the arguments are human talent in China
[00:29:34.660 --> 00:29:36.420]   will always find a way to innovate.
[00:29:36.420 --> 00:29:41.260]   You know, keeping keeping China six months behind is not worth the cost.
[00:29:41.260 --> 00:29:43.380]   Scarcity fuels innovation.
[00:29:43.380 --> 00:29:47.540]   It turns AI into a global arms racer or the one that I've been
[00:29:47.540 --> 00:29:51.580]   are, you know, been been advocating is I think we've we've focused
[00:29:51.580 --> 00:29:54.020]   so much on slowing China down.
[00:29:54.020 --> 00:29:57.820]   We haven't focused enough on speeding America up. Right.
[00:29:57.820 --> 00:30:01.260]   Removing rate, removing the regulations around power generation,
[00:30:01.260 --> 00:30:04.060]   all the things we need to get America running full speed.
[00:30:04.060 --> 00:30:08.140]   But I would say this is probably the biggest divide in Silicon Valley
[00:30:08.140 --> 00:30:12.660]   among technologists regarding, you know, kind of this president's policies. Right.
[00:30:12.860 --> 00:30:18.620]   So there's a camp, as you know, of China hawks led by, you know, folks like,
[00:30:18.620 --> 00:30:22.380]   you know, Alex Karp was on the Palantir call last night who viewed this
[00:30:22.380 --> 00:30:26.740]   as an existential holy war and that we must battle on every front.
[00:30:26.740 --> 00:30:29.580]   And, you know, in order to slow China down.
[00:30:29.580 --> 00:30:32.340]   And then I would say there are people who are more what I would consider
[00:30:32.340 --> 00:30:33.740]   China constructivist.
[00:30:33.740 --> 00:30:35.220]   And I put you in that camp.
[00:30:35.220 --> 00:30:37.020]   I would I would put myself in that camp.
[00:30:37.020 --> 00:30:41.140]   I would put, frankly, you know, Elon in that in that camp and others
[00:30:41.340 --> 00:30:46.100]   who seem to think that it's a losing battle just to focus on slowing China down.
[00:30:46.100 --> 00:30:50.340]   And what we really need to focus on is more engagement and speeding the US up.
[00:30:50.340 --> 00:30:53.980]   So can you lay out a little bit, you know, your views on on
[00:30:53.980 --> 00:30:57.500]   on those two computing sides and where we may end up coming down on?
[00:30:57.500 --> 00:30:59.820]   Brad, I think you framed it perfectly.
[00:30:59.820 --> 00:31:03.820]   The problem is that the by the way,
[00:31:03.820 --> 00:31:08.060]   I think on the on the anti China side in Silicon Valley, you have
[00:31:08.460 --> 00:31:13.340]   you have like three groups, you have the people like Dario
[00:31:13.340 --> 00:31:16.340]   who are, you know, maybe worried about competition,
[00:31:16.340 --> 00:31:19.260]   maybe worried about more, but certainly question that.
[00:31:19.260 --> 00:31:24.660]   You have the new kind of VC backed defense companies
[00:31:24.660 --> 00:31:29.100]   who all and maybe I kind of put Palantir in that group, but they all,
[00:31:29.100 --> 00:31:34.660]   I think, have an incentive to kind of have tension with China, if you will.
[00:31:34.660 --> 00:31:36.380]   It actually increases revenue.
[00:31:36.380 --> 00:31:38.380]   I call them the new neocons.
[00:31:38.380 --> 00:31:41.940]   And then and then I think you just have a large group of people
[00:31:41.940 --> 00:31:45.180]   who were raised to be anti China.
[00:31:45.180 --> 00:31:49.420]   And they're just it's it's it's what they were taught growing up.
[00:31:49.420 --> 00:31:50.940]   It's the anti communist thing.
[00:31:50.940 --> 00:31:52.540]   It's what got us into the Vietnam War.
[00:31:52.540 --> 00:31:53.660]   It's been around forever.
[00:31:53.660 --> 00:31:55.900]   But but your parents might have taught you that.
[00:31:55.900 --> 00:31:57.900]   Like, it's just in the ethos.
[00:31:57.900 --> 00:32:00.420]   One thing I would add to you on the risk side, you listed them.
[00:32:00.420 --> 00:32:02.140]   You listed a lot of great points.
[00:32:02.140 --> 00:32:05.260]   You know, one thing I would add is that protection of U.S.
[00:32:05.260 --> 00:32:08.100]   companies causes harm, like like
[00:32:08.100 --> 00:32:12.540]   Detroit is not globally competitive anymore.
[00:32:12.540 --> 00:32:16.300]   And putting tariffs on these cars
[00:32:16.300 --> 00:32:18.900]   is not going to make Detroit more competitive.
[00:32:18.900 --> 00:32:22.420]   It's going to make them less competitive and they're going to fall further behind.
[00:32:22.420 --> 00:32:27.460]   And I think this idea of raising the wall
[00:32:27.620 --> 00:32:32.180]   and increased decoupling is a super dangerous idea.
[00:32:32.180 --> 00:32:36.980]   We may find that the rest of the world is perfectly fine
[00:32:36.980 --> 00:32:41.260]   buying ten thousand dollar BYD cars and using DeepSeek.
[00:32:41.260 --> 00:32:44.660]   And we may we may just be shutting ourselves off.
[00:32:44.660 --> 00:32:47.380]   I found this interesting data point I wanted to share with you.
[00:32:47.380 --> 00:32:51.980]   To highlight my fascination with China, I've kind of studied it
[00:32:51.980 --> 00:32:53.620]   over a very long time frame.
[00:32:53.620 --> 00:32:56.220]   It turns out most people have no reason to know this.
[00:32:56.220 --> 00:33:00.700]   But in 1820, China's economy was wide open
[00:33:00.700 --> 00:33:05.940]   and they actually had 33 percent of the global economy.
[00:33:05.940 --> 00:33:08.860]   33 percent of global GDP was China.
[00:33:08.860 --> 00:33:10.620]   Most people probably wouldn't know that.
[00:33:10.620 --> 00:33:14.580]   And the reason they might not know it is because 150 years later,
[00:33:14.580 --> 00:33:18.700]   at the end of Mao's reign and Mao had raised the wall
[00:33:18.700 --> 00:33:21.620]   and and kind of turned China inwards,
[00:33:21.620 --> 00:33:24.820]   they had fallen to five percent of global GDP.
[00:33:25.220 --> 00:33:26.940]   And they've been working their way back from that.
[00:33:26.940 --> 00:33:29.500]   So we know this emergent China from that place.
[00:33:29.500 --> 00:33:32.500]   But, you know, that's the real risk.
[00:33:32.500 --> 00:33:35.700]   You know, if you're not a globalist, if you don't believe in,
[00:33:35.700 --> 00:33:39.740]   you know, all the great economic work that shows how,
[00:33:39.740 --> 00:33:43.340]   you know, specialization can work to the benefit of everyone
[00:33:43.340 --> 00:33:46.980]   and you close that wall, you may be surprised at what happens.
[00:33:46.980 --> 00:33:50.380]   To wrap this section, and that's the perfect segue to talk about tariffs.
[00:33:50.380 --> 00:33:52.860]   But, you know, I would say this.
[00:33:52.860 --> 00:33:54.980]   I think there is a middle ground, right?
[00:33:55.780 --> 00:33:59.140]   I you know, I took a little when I first read your tweet,
[00:33:59.140 --> 00:34:01.340]   you would rather, you know, it's better for an open source
[00:34:01.340 --> 00:34:05.300]   Chinese model to win versus a foreign.
[00:34:05.300 --> 00:34:08.100]   Oh, foreign. OK, I knew I knew what the hell you meant.
[00:34:08.100 --> 00:34:11.460]   Then a then a closed U.S. model.
[00:34:11.460 --> 00:34:13.740]   I want Team America to win on this.
[00:34:13.740 --> 00:34:16.700]   I want a you know, I would love to see the U.S.
[00:34:16.700 --> 00:34:19.460]   frontier labs open source more stuff.
[00:34:19.460 --> 00:34:22.380]   I agree with you fundamentally on the principles of open source.
[00:34:22.500 --> 00:34:23.900]   I believe they will.
[00:34:23.900 --> 00:34:26.940]   And unquestionably, I want to see the U.S.
[00:34:26.940 --> 00:34:29.420]   win when it comes to the race in AI.
[00:34:29.420 --> 00:34:31.300]   And I know you do, too.
[00:34:31.300 --> 00:34:36.780]   Secondly, I would say on this is that I think a lot of the things
[00:34:36.780 --> 00:34:40.580]   that we've done in the name of being tough on China, right,
[00:34:40.580 --> 00:34:42.660]   are actually counterproductive.
[00:34:42.660 --> 00:34:44.580]   I agree. It takes the eye off the prize.
[00:34:44.580 --> 00:34:46.660]   It slows us down. Right.
[00:34:46.660 --> 00:34:49.300]   And it doesn't focus on speeding us up.
[00:34:49.420 --> 00:34:52.900]   And frankly, it's not very effective or it backfires entirely
[00:34:52.900 --> 00:34:54.780]   in terms of slowing China down.
[00:34:54.780 --> 00:34:58.620]   And and one of the places where I think that this bill,
[00:34:58.620 --> 00:35:02.300]   you know, takes us to is is is really Trump's tariffs
[00:35:02.300 --> 00:35:06.700]   that that that brought, you know, brought brought us to the fore this week.
[00:35:06.700 --> 00:35:07.700]   But you have something to say.
[00:35:07.700 --> 00:35:11.260]   Yeah, I just want to say two things to what you said.
[00:35:11.260 --> 00:35:12.340]   And then we'll go to the tariffs.
[00:35:12.340 --> 00:35:16.340]   So, one, you know, I was being provocative when I said foreign.
[00:35:16.340 --> 00:35:17.780]   And you could read China.
[00:35:17.780 --> 00:35:22.580]   But if you think about it like Linux doesn't have a geography. Right.
[00:35:22.580 --> 00:35:26.340]   And so one possible reality
[00:35:26.340 --> 00:35:29.940]   that I don't think meets your goal of America wins
[00:35:29.940 --> 00:35:33.700]   is you get to a place that's Linux like where
[00:35:33.700 --> 00:35:37.740]   the model doesn't have a sovereignty and and
[00:35:37.740 --> 00:35:43.820]   because of the 1300 variants of our one that are on hugging face already,
[00:35:44.100 --> 00:35:48.940]   like the and because that MIT license, though, it could be that model that wins.
[00:35:48.940 --> 00:35:51.780]   You know, it doesn't have to be the one that they're doing.
[00:35:51.780 --> 00:35:52.940]   It could be a fork of it.
[00:35:52.940 --> 00:35:54.940]   So anyway, I wanted to make that point.
[00:35:54.940 --> 00:35:58.580]   And then the other thing I wanted to say, I'm just on a risk side,
[00:35:58.580 --> 00:36:03.300]   you know, and by the way, there there are proposals in Congress right now.
[00:36:03.300 --> 00:36:06.020]   I just that would kill open source.
[00:36:06.020 --> 00:36:08.820]   They would say we couldn't use variants of our one.
[00:36:08.820 --> 00:36:10.700]   There's there's like a lot.
[00:36:10.700 --> 00:36:15.020]   There's a huge breadth of perspectives, as you already said.
[00:36:15.020 --> 00:36:21.580]   But I think if you I think I can imagine that if you just poke China enough,
[00:36:21.580 --> 00:36:25.980]   if you keep poking and you keep poking and you keep raising the constraint,
[00:36:25.980 --> 00:36:29.580]   you increase the odds that they make a run at Taiwan.
[00:36:29.580 --> 00:36:34.500]   And I just think it's important to always think from their perspective,
[00:36:34.500 --> 00:36:39.260]   you know, and and I just think we need to be careful about how
[00:36:39.820 --> 00:36:42.940]   how hard we push. We may end up with the exact worst outcome.
[00:36:42.940 --> 00:36:44.980]   Unintended consequences. Right.
[00:36:44.980 --> 00:36:49.380]   So this week we woke up, you know, really ended Friday
[00:36:49.380 --> 00:36:52.820]   at a late press conference the president had, and then it went into effect
[00:36:52.820 --> 00:36:54.220]   over the weekend. Right.
[00:36:54.220 --> 00:36:57.420]   Twenty five percent tariffs on on on Mexico and Canada.
[00:36:57.420 --> 00:37:01.220]   Fifteen percent tariff or ten to fifteen percent tariff on China.
[00:37:01.220 --> 00:37:05.500]   Before we dive into the economic debates for and against tariffs,
[00:37:05.500 --> 00:37:07.420]   let's just kind of lay this out.
[00:37:07.420 --> 00:37:10.060]   You know, so Monday morning, the markets overnight Sunday,
[00:37:10.060 --> 00:37:11.580]   the markets are falling a lot.
[00:37:11.580 --> 00:37:15.300]   Monday morning, Kevin Hassett, chairman of the National Economic Council,
[00:37:15.300 --> 00:37:16.660]   comes out on the White House lawn.
[00:37:16.660 --> 00:37:18.700]   He said, oh, these are all being misinterpreted.
[00:37:18.700 --> 00:37:21.060]   This is not about a trade war.
[00:37:21.060 --> 00:37:23.300]   This is a drug war. This is about fentanyl.
[00:37:23.300 --> 00:37:26.380]   You know, he did happen to say we may revisit in the future
[00:37:26.380 --> 00:37:28.500]   as part of a tax reform strategy.
[00:37:28.500 --> 00:37:32.380]   So he left the opening to to, you know, tariffs for other reasons.
[00:37:32.380 --> 00:37:34.940]   Then the president on Monday talks to both sides.
[00:37:34.940 --> 00:37:38.060]   They both commit 10000 troops to the border to fight fentanyl.
[00:37:38.060 --> 00:37:40.980]   And you delay the tariffs for 30 days.
[00:37:40.980 --> 00:37:45.460]   And I think the market reaction now is that they're not going to hit at all.
[00:37:45.460 --> 00:37:48.460]   So let's first start on what we think happens here.
[00:37:48.460 --> 00:37:50.940]   So help me predict what you think happens.
[00:37:50.940 --> 00:37:54.340]   And then I would love to get into kind of the merits and demerits
[00:37:54.340 --> 00:37:58.020]   from an economic and from maybe the tech industry perspective
[00:37:58.020 --> 00:38:00.780]   on on on this tariff strategy.
[00:38:01.580 --> 00:38:04.060]   So, Brad, I'm going to be brief, because, look,
[00:38:04.060 --> 00:38:05.580]   this is more your world than mine.
[00:38:05.580 --> 00:38:08.060]   You're looking at a lot of large public companies
[00:38:08.060 --> 00:38:10.740]   and and all all the things that impact them.
[00:38:10.740 --> 00:38:14.780]   You know, I guess even in the medium sized public companies I work with,
[00:38:14.780 --> 00:38:18.460]   especially if you have physical goods, you've got supply chains
[00:38:18.460 --> 00:38:19.940]   all around the globe. Right.
[00:38:19.940 --> 00:38:23.780]   And I imagine one thing you've had to do in your shop,
[00:38:23.780 --> 00:38:28.060]   you know, is when a new tariff pops up is just immediately ask,
[00:38:28.060 --> 00:38:31.060]   well, who's impacted, who sources there, who like who
[00:38:31.300 --> 00:38:35.180]   who and, you know, probably just creates a lot of chaos. Right.
[00:38:35.180 --> 00:38:37.980]   In the short term, as we try and figure those things out,
[00:38:37.980 --> 00:38:42.220]   you know, there's different Foxconn plants all around the globe. Right.
[00:38:42.220 --> 00:38:45.420]   And different people source different, you know,
[00:38:45.420 --> 00:38:49.980]   whether it's fashion products or anything, you know, from Vietnam
[00:38:49.980 --> 00:38:53.500]   or from Indonesia or from China during covid.
[00:38:53.500 --> 00:38:57.700]   I think one of the things we realized is there is some flexibility.
[00:38:57.700 --> 00:39:01.300]   They can move, move a lot faster than people thought.
[00:39:01.300 --> 00:39:03.180]   But it's still chaotic.
[00:39:03.180 --> 00:39:08.460]   And based on like, as I said, you know, my default is a globalist.
[00:39:08.460 --> 00:39:13.180]   Now, I don't know enough to know if we have unfair deals
[00:39:13.180 --> 00:39:16.700]   that need to be honed and that this is just a means to an end.
[00:39:16.700 --> 00:39:19.260]   And if so, maybe it's not that big a deal.
[00:39:19.260 --> 00:39:24.500]   I don't believe that creating a lot of, you know, bringing the wall up,
[00:39:24.500 --> 00:39:26.540]   as I said earlier, around the eye.
[00:39:26.540 --> 00:39:29.900]   I don't believe that that'll be in the U.S.'s long term best interest.
[00:39:29.900 --> 00:39:33.900]   You make a good point about, you know, clearly
[00:39:33.900 --> 00:39:36.940]   Trump extracted a concession that was a pretty damn good
[00:39:36.940 --> 00:39:41.260]   concession from Canada and Mexico when it when it comes to defending the border.
[00:39:41.260 --> 00:39:45.020]   Right. So as a tactical negotiating tool,
[00:39:45.020 --> 00:39:48.420]   you know, his batting average is exceptionally high.
[00:39:48.420 --> 00:39:52.380]   You know, whether it was getting Columbia to take the detained deportees
[00:39:52.380 --> 00:39:53.820]   where he threatened a tariff.
[00:39:53.820 --> 00:39:56.700]   And so I think that that's the market's reflexive belief.
[00:39:56.700 --> 00:40:00.260]   In fact, Scott Besant, the Treasury secretary, in a letter
[00:40:00.260 --> 00:40:04.220]   he wrote about a year ago to his investors, he used this concept
[00:40:04.220 --> 00:40:06.820]   that Trump's tariffs, you shouldn't be afraid of them
[00:40:06.820 --> 00:40:10.620]   because he said his strategy was to have a fully loaded gun,
[00:40:10.620 --> 00:40:12.780]   but rarely discharge.
[00:40:12.780 --> 00:40:15.140]   Yeah, right. Fully loaded gun, but rarely discharge.
[00:40:15.140 --> 00:40:20.100]   And so the interpretation is he's just using this as a big stick
[00:40:20.100 --> 00:40:21.940]   to achieve very tactical goals.
[00:40:21.940 --> 00:40:25.460]   Now, I call this bill the Besant consensus.
[00:40:25.460 --> 00:40:30.020]   I believe this is the market consensus view, the Besant consensus.
[00:40:30.020 --> 00:40:33.140]   But I want to throw out an alternative view, right?
[00:40:33.140 --> 00:40:37.220]   I think that Trump may, in fact, have a much, much deeper
[00:40:37.220 --> 00:40:39.540]   and more principled belief in tariffs.
[00:40:39.540 --> 00:40:42.660]   If you listen to his speeches, if you read them, and this goes back
[00:40:42.660 --> 00:40:48.260]   over a decade, OK, he believes that McKinley was one of the best presidents.
[00:40:48.460 --> 00:40:51.180]   He thinks that the country, he believes that the country
[00:40:51.180 --> 00:40:54.580]   and there are arguments for this was at its peak or at its best
[00:40:54.580 --> 00:40:59.620]   during peak tariffs in 1880 and that you could, in fact, replace
[00:40:59.620 --> 00:41:02.060]   when we move to replace tariffs.
[00:41:02.060 --> 00:41:06.300]   So prior to 1910, which is when we got the income tax.
[00:41:06.300 --> 00:41:09.820]   Right. The vast majority, we'll put this chart in the pod.
[00:41:09.820 --> 00:41:12.180]   The vast majority of revenue to the U.S.
[00:41:12.180 --> 00:41:14.660]   government came from tariffs.
[00:41:14.660 --> 00:41:17.060]   And then you see, starting in 1910,
[00:41:17.260 --> 00:41:21.500]   basically revenue from tariffs plummeted and the amount of revenue
[00:41:21.500 --> 00:41:24.260]   that came from income tax and Social Security tax,
[00:41:24.260 --> 00:41:26.980]   you know, thereafter skyrocketed.
[00:41:26.980 --> 00:41:30.740]   And so I think there's a belief that replacing tariffs
[00:41:30.740 --> 00:41:34.940]   with high income taxes and corporate taxes has gutted the middle class.
[00:41:34.940 --> 00:41:40.180]   Not only did it destroy jobs in America, but in fact, caused these people
[00:41:40.180 --> 00:41:44.820]   to be burdened with taxes, you know, to pay for social services
[00:41:44.820 --> 00:41:47.140]   that could have otherwise been paid for by tariffs.
[00:41:47.580 --> 00:41:51.780]   So that to me is a variant view.
[00:41:51.780 --> 00:41:56.140]   Right. If you believe that to be true, there is a much more principled
[00:41:56.140 --> 00:42:00.700]   architecture that he wants to move to, that this is not the best consensus,
[00:42:00.700 --> 00:42:04.060]   which is have a fully loaded gun that's rarely discharged.
[00:42:04.060 --> 00:42:07.860]   But it's a fully loaded gun that you fully intended to discharge.
[00:42:07.860 --> 00:42:11.420]   So let's assume for the moment that he does have that view,
[00:42:11.420 --> 00:42:14.540]   maybe more of a fortress America. Right.
[00:42:15.500 --> 00:42:18.660]   I think you've outlined where where you stand on this.
[00:42:18.660 --> 00:42:22.260]   Do you believe that that hurts us technologically and it would hurt us
[00:42:22.260 --> 00:42:25.660]   in in terms of our global economic standing? Is that right?
[00:42:25.660 --> 00:42:29.940]   Well, look, I'm not a tariff expert,
[00:42:29.940 --> 00:42:33.380]   but but when you told me you wanted to talk about this, I did.
[00:42:33.380 --> 00:42:36.460]   I did some research and maybe maybe we could have your son
[00:42:36.460 --> 00:42:40.500]   or your son's professor on to talk more about this.
[00:42:40.500 --> 00:42:45.180]   But all of the even the success stories around tariff,
[00:42:45.180 --> 00:42:47.580]   if you ask your favorite, I didn't tell you.
[00:42:47.580 --> 00:42:49.500]   They seem very short windowed.
[00:42:49.500 --> 00:42:52.500]   Even the McKinley ones were like four years.
[00:42:52.500 --> 00:42:59.420]   So I don't know of a long term successful high tariff program.
[00:42:59.420 --> 00:43:03.460]   And I think it gets back to what I was saying about China, like pulling up
[00:43:03.460 --> 00:43:08.700]   the wall is I don't think I don't think there's any economic argument
[00:43:08.700 --> 00:43:11.580]   that that works to help a country in the long run.
[00:43:12.460 --> 00:43:17.060]   And going back to the to the I do want to take a brief
[00:43:17.060 --> 00:43:22.220]   second to talk about what you just said about the like
[00:43:22.220 --> 00:43:25.900]   the American middle class may have been been affected by this.
[00:43:25.900 --> 00:43:31.580]   You know, there's a time and place when a country is in a great place
[00:43:31.580 --> 00:43:35.980]   to be competitive globally in scaling out production.
[00:43:35.980 --> 00:43:41.980]   And it relates to having a educated workforce
[00:43:42.340 --> 00:43:46.340]   that has a very low standard of living, that's willing to work for a wage
[00:43:46.340 --> 00:43:50.660]   that's highly competitive globally and may be willing to work
[00:43:50.660 --> 00:43:55.660]   nine, nine, six, you know, right, like like way more hours
[00:43:55.660 --> 00:43:59.020]   than nine in the morning to nine at night, six days a week. Right.
[00:43:59.020 --> 00:44:03.020]   And so if you look at when America,
[00:44:03.020 --> 00:44:06.580]   you know, was mostly successful scaling out post World War
[00:44:06.580 --> 00:44:11.340]   two where you're been decimated and and Japan's been decimated.
[00:44:11.500 --> 00:44:16.220]   Yeah. And we had a lot of people moving up the social ladder
[00:44:16.220 --> 00:44:20.700]   and prosperity ladder as a result of being willing to do that.
[00:44:20.700 --> 00:44:24.780]   You know, if you fast forward to where we are today, you know,
[00:44:24.780 --> 00:44:27.780]   I don't think there's any way to say this other than to be blunt.
[00:44:27.780 --> 00:44:33.980]   Like there are people in China, Vietnam, Indonesia, Mexico
[00:44:33.980 --> 00:44:38.500]   that are willing to work harder and longer for a wage
[00:44:38.500 --> 00:44:41.860]   that is radically lower than what people in the U.S.
[00:44:41.860 --> 00:44:42.900]   are willing to work.
[00:44:42.900 --> 00:44:47.060]   And they're going to move from a place on the prosperity
[00:44:47.060 --> 00:44:52.340]   and social ladder that's low to a place that's still beneath the average American.
[00:44:52.340 --> 00:44:58.220]   And I don't know how as a humanist you can say they don't deserve that. Right.
[00:44:58.220 --> 00:45:04.260]   And I think we misinterpret that this is somehow a result of tariffs or trade.
[00:45:04.460 --> 00:45:07.580]   It's just global fairness. Right.
[00:45:07.580 --> 00:45:09.940]   It's just my point of view.
[00:45:09.940 --> 00:45:10.780]   No, totally.
[00:45:10.780 --> 00:45:13.260]   And I think you make a good point, a good defense for globalism.
[00:45:13.260 --> 00:45:16.580]   But I think the exact response would be if you're the president United States,
[00:45:16.580 --> 00:45:19.660]   you know, you're not you're not looking out for, you know,
[00:45:19.660 --> 00:45:22.780]   the standard of living for all humans or for all people around the globe.
[00:45:22.780 --> 00:45:25.620]   You're looking out for the standard of living of people in the United States,
[00:45:25.620 --> 00:45:28.420]   you know, who you have a constitutional oath to.
[00:45:28.420 --> 00:45:33.580]   And no doubt. But my but my point is that even with that lens,
[00:45:33.860 --> 00:45:38.100]   you have to think about the dynamics around the globe and pulling up the wall
[00:45:38.100 --> 00:45:41.500]   and trying to get people to make a 40 dollar microwave.
[00:45:41.500 --> 00:45:43.700]   And America is going to fail.
[00:45:43.700 --> 00:45:46.860]   But you're just going to end up with more expensive products.
[00:45:46.860 --> 00:45:48.780]   We watched this happen in Europe.
[00:45:48.780 --> 00:45:50.780]   Like we watched it play out in Europe.
[00:45:50.780 --> 00:45:53.260]   You're just going to make yourself Europe.
[00:45:53.260 --> 00:45:57.260]   I do think there are some great economic arguments on this.
[00:45:57.260 --> 00:46:00.500]   Like I said, Kevin Hass is chairman of the National Economic Council
[00:46:00.500 --> 00:46:01.940]   is at the Hoover Institute.
[00:46:01.940 --> 00:46:05.780]   You know, he's going to be on the front lines of carrying the tariff policy,
[00:46:05.780 --> 00:46:07.420]   defending the tariff policy.
[00:46:07.420 --> 00:46:10.580]   But if you look at the McKinley tariffs, they certainly caused a lot of strife.
[00:46:10.580 --> 00:46:12.420]   But they're very good arguments
[00:46:12.420 --> 00:46:15.500]   that they helped us industrialize in a way we never would have.
[00:46:15.500 --> 00:46:18.860]   And more importantly, they helped us build critical strength
[00:46:18.860 --> 00:46:20.460]   heading into World War One.
[00:46:20.460 --> 00:46:24.180]   So had we not done the industrialization in 1880, 1890,
[00:46:24.180 --> 00:46:26.140]   would we have been even prepared?
[00:46:26.140 --> 00:46:28.660]   But the world does look very different today, Bill.
[00:46:28.660 --> 00:46:32.780]   Global supply chains, the cost of shipping is radically lower, etc.
[00:46:32.780 --> 00:46:37.020]   But I thought what was interesting is, you know, the Fed actually did a study
[00:46:37.020 --> 00:46:39.780]   on the tariffs in 2018.
[00:46:39.780 --> 00:46:42.620]   They did it, I think it was on washing machines, you know,
[00:46:42.620 --> 00:46:46.620]   and they basically said it led to a lot higher pricing for washing machines.
[00:46:46.620 --> 00:46:50.460]   Right. Where there were, you know, tariffs put on them.
[00:46:50.460 --> 00:46:53.580]   And even for dryers that had no tariff put on them.
[00:46:53.580 --> 00:46:57.020]   But because they're usually sold together, the prices went on those as well.
[00:46:57.140 --> 00:47:00.420]   And interestingly enough, even the domestic producers raised prices
[00:47:00.420 --> 00:47:03.100]   because now the competitive market had raised prices.
[00:47:03.100 --> 00:47:06.260]   So they now had a pricing umbrella that they could raise prices into.
[00:47:06.260 --> 00:47:09.700]   And I think they concluded that very few jobs were actually created.
[00:47:09.700 --> 00:47:13.260]   Now, they were looking at this only two years in arrears, Bill.
[00:47:13.260 --> 00:47:17.100]   So, you know, again, they weren't looking at the long run effects of,
[00:47:17.100 --> 00:47:19.460]   you know, did this play out?
[00:47:19.460 --> 00:47:24.380]   So I think, you know, one area I'm really focused on for Silicon Valley.
[00:47:24.860 --> 00:47:29.260]   So imagine a tariff on, you know, on GPUs or on chips.
[00:47:29.260 --> 00:47:31.900]   Right. Which has been threatened this week.
[00:47:31.900 --> 00:47:35.420]   Like they're talking about just a tariff on Taiwan,
[00:47:35.420 --> 00:47:37.380]   which is a tariff on chips.
[00:47:37.380 --> 00:47:40.700]   Right. And today we actually can't make those chips in America.
[00:47:40.700 --> 00:47:44.020]   Right. We don't have two nanometer, three nanometer fabs
[00:47:44.020 --> 00:47:46.260]   where we could build them even if we wanted to.
[00:47:46.260 --> 00:47:50.740]   So when I look at that, that's really just a tax on chip manufacturers
[00:47:50.740 --> 00:47:52.140]   and on the end buyers. Right.
[00:47:52.140 --> 00:47:56.740]   So that would be a tax on on the Nvidia's and AMD's and and others.
[00:47:56.740 --> 00:47:59.500]   And it would be a tax on Metta and Amazon and all the folks
[00:47:59.500 --> 00:48:03.620]   that would have to have to pay that tax, which which likely means
[00:48:03.620 --> 00:48:07.940]   that you get less chips purchased and less AI research. Right.
[00:48:07.940 --> 00:48:11.660]   So if our number one goal is to win the race in AI, this is a classic case
[00:48:11.660 --> 00:48:14.500]   where in the short run, I think it's self-defeating.
[00:48:14.500 --> 00:48:19.220]   But I do think there are ways to do this where you can bring more fabs to the US.
[00:48:19.580 --> 00:48:22.780]   But if you wanted to have, you know, if you want to have a permanent
[00:48:22.780 --> 00:48:26.500]   50 percent tariff on all chips in the US starting now,
[00:48:26.500 --> 00:48:29.380]   I think like that's just that's just going to have negative repercussions.
[00:48:29.380 --> 00:48:32.500]   But if you said of a 50 percent tax on chips,
[00:48:32.500 --> 00:48:34.900]   but I'm going to delay it for two and a half years
[00:48:34.900 --> 00:48:38.420]   and you have to meet these hurdles for building fabs in the US, et cetera.
[00:48:38.420 --> 00:48:42.900]   So more of a negotiating tactic than it is kind of a permanent and higher tax.
[00:48:42.900 --> 00:48:46.860]   I think there are some, you know, some some really good outcomes of that.
[00:48:46.860 --> 00:48:51.020]   We're less dependent upon Taiwan, which is, you know, always threatened by a
[00:48:51.020 --> 00:48:54.540]   you know, what what what most people believe is a foreign adversary,
[00:48:54.540 --> 00:48:59.060]   you know, less dependency in the case of of some situation evolving there.
[00:48:59.060 --> 00:49:01.540]   So I think it's going to have to be something that we watch.
[00:49:01.540 --> 00:49:04.580]   But the main thing I wanted to point I wanted to make today on this
[00:49:04.580 --> 00:49:09.020]   is don't be lazy in believing the best consensus.
[00:49:09.020 --> 00:49:12.220]   Don't think that this is just about,
[00:49:12.220 --> 00:49:14.980]   you know, a negotiating tactic.
[00:49:14.980 --> 00:49:16.980]   Go back and read the speeches.
[00:49:16.980 --> 00:49:20.860]   I think Trump and Trump's administration has a much more principled view here
[00:49:20.860 --> 00:49:23.780]   that may be a value added tax equivalent.
[00:49:23.780 --> 00:49:27.620]   A tariff that is somehow, you know, a proxy for these value added
[00:49:27.620 --> 00:49:30.980]   taxes is a more efficient and better mechanism for helping
[00:49:30.980 --> 00:49:33.660]   the middle class in the United States than an income tax.
[00:49:33.660 --> 00:49:37.860]   And, you know, and we saw that that back door was kind of left open.
[00:49:37.860 --> 00:49:40.700]   You know, we said terrorists, maybe we may come back to terrorists
[00:49:40.700 --> 00:49:42.060]   as part of tax reform.
[00:49:42.060 --> 00:49:43.660]   So keep your eyes out for that.
[00:49:43.660 --> 00:49:48.620]   Well, then, look, any analysis of this situation is made more difficult
[00:49:48.620 --> 00:49:53.980]   by the blatant reality that even if Trump
[00:49:53.980 --> 00:49:56.860]   is just using terrorists as a negotiating chip,
[00:49:56.860 --> 00:50:01.420]   he can never say that out loud or it would take away
[00:50:01.420 --> 00:50:04.700]   the their ability to be used in that way.
[00:50:04.700 --> 00:50:08.420]   So he has to be obscure about it either direction.
[00:50:08.420 --> 00:50:11.900]   And so it makes it harder to know exactly which which ways up.
[00:50:12.540 --> 00:50:13.860]   So let's move on to Doge.
[00:50:13.860 --> 00:50:15.380]   So you were in Washington.
[00:50:15.380 --> 00:50:18.500]   What took you to Washington and and what did you see?
[00:50:18.500 --> 00:50:21.340]   What's your perspective of Doge?
[00:50:21.340 --> 00:50:25.540]   And like I love the update on your specific visit.
[00:50:25.540 --> 00:50:31.980]   But then could you reflect on why or why not Doge matters to a tech investor?
[00:50:31.980 --> 00:50:35.020]   Yeah, no, I think this is so I think it's so important
[00:50:35.020 --> 00:50:38.500]   because I think, again, like with tariffs, we're in this fog of war, Bill.
[00:50:39.100 --> 00:50:45.140]   Right. Where, you know, like their change brings a lot of contentiousness.
[00:50:45.140 --> 00:50:48.420]   And I think sometimes we lose, you know, the basic facts
[00:50:48.420 --> 00:50:50.100]   of what we're trying to achieve here.
[00:50:50.100 --> 00:50:54.220]   It's super important to understand that there is nobody like Elon.
[00:50:54.220 --> 00:50:57.900]   I mean, he's truly an end of one in working on issues like this.
[00:50:57.900 --> 00:51:00.500]   You know, so he's working 20 hours a day.
[00:51:00.500 --> 00:51:02.060]   He's working through the weekend.
[00:51:02.060 --> 00:51:04.740]   His team is, in fact, sleeping across from the White House
[00:51:04.740 --> 00:51:07.380]   and, you know, in the executive office building.
[00:51:07.580 --> 00:51:10.620]   But most importantly, right, Elon is a systems thinker.
[00:51:10.620 --> 00:51:13.660]   I mean, he literally showed up in Washington
[00:51:13.660 --> 00:51:17.540]   and he didn't do what normal people do when they show up in Washington,
[00:51:17.540 --> 00:51:22.500]   which is, you know, fed, you know, fed all the politicians and understand,
[00:51:22.500 --> 00:51:25.620]   you know, what he needs to do in order to play by all the rules
[00:51:25.620 --> 00:51:26.540]   that everybody else says.
[00:51:26.540 --> 00:51:28.180]   He just starts asking questions.
[00:51:28.180 --> 00:51:32.500]   And not surprisingly, the first question he asks is who sends out the wires?
[00:51:32.500 --> 00:51:34.420]   Like who controls the wires?
[00:51:34.420 --> 00:51:37.860]   Can I just get a list of all the wires that are scheduled to go out?
[00:51:37.860 --> 00:51:39.900]   Like, what are we what are we spending the money on?
[00:51:39.900 --> 00:51:42.620]   You know, over the next month, have they been audited?
[00:51:42.620 --> 00:51:46.100]   You know, and as I think he started doing that, of course,
[00:51:46.100 --> 00:51:49.540]   the Leviathan of Washington just convulses. Right.
[00:51:49.540 --> 00:51:51.620]   Because they're like, whoa, nobody questions.
[00:51:51.620 --> 00:51:53.580]   Nobody. Nobody looks at the wires.
[00:51:53.580 --> 00:51:57.180]   He's like, well, that's kind of what, you know, the president has asked me to do.
[00:51:57.180 --> 00:51:59.380]   So I need to do that.
[00:51:59.380 --> 00:52:03.660]   And so the antibodies, you know, really started attacking.
[00:52:03.660 --> 00:52:07.340]   When the only thing he really asked to do in the first instance is,
[00:52:07.340 --> 00:52:10.660]   you know, his first principles led him to thinking that, you know,
[00:52:10.660 --> 00:52:12.540]   like where where to look.
[00:52:12.540 --> 00:52:16.060]   So, you know, I want to bring it back to this idea
[00:52:16.060 --> 00:52:19.260]   that change is hard, but change is necessary. Right.
[00:52:19.260 --> 00:52:22.100]   We're simply talking about his whole purpose here
[00:52:22.100 --> 00:52:25.460]   is to balance the budget that both parties
[00:52:25.460 --> 00:52:29.220]   have proven the inability to do in the normal process.
[00:52:29.220 --> 00:52:32.580]   And most people agree it's it's bankrupting the country.
[00:52:32.580 --> 00:52:34.940]   And so it's not that hard.
[00:52:34.940 --> 00:52:38.260]   You know, we we showed this on the pod where we went through.
[00:52:38.260 --> 00:52:42.420]   If you just return to the baseline of 2019, Bill,
[00:52:42.420 --> 00:52:47.140]   if we just go back to the baseline, grow it by two and a half percent from 2019.
[00:52:47.140 --> 00:52:50.500]   You balance the budget in this president's term. Right.
[00:52:50.500 --> 00:52:55.660]   But that requires us getting a trillion dollars cut off the covid high.
[00:52:55.660 --> 00:52:57.380]   We lost our minds.
[00:52:57.380 --> 00:52:59.980]   Remember the letter to met a time to get fit.
[00:52:59.980 --> 00:53:01.260]   It was like we lost our mind.
[00:53:01.260 --> 00:53:02.620]   Well, Silicon Valley's gotten fit.
[00:53:02.620 --> 00:53:06.260]   We we've made some reductions, but government hasn't gotten fit at all.
[00:53:06.260 --> 00:53:09.660]   Hasn't done anything except stay at that covid high.
[00:53:09.660 --> 00:53:12.380]   And all Elon's saying is, listen, let's just go back.
[00:53:12.380 --> 00:53:15.100]   Let's start with just getting a trillion of this out, which is,
[00:53:15.100 --> 00:53:18.140]   you know, the excess that we put in. And so.
[00:53:18.140 --> 00:53:23.260]   The other thing that he's doing is he's literally live blogging this on Twitter.
[00:53:23.260 --> 00:53:25.700]   You know, he hosted this Doge spaces on Sunday night.
[00:53:25.700 --> 00:53:27.820]   Anybody, you know, can join this thing.
[00:53:27.820 --> 00:53:29.420]   It's not like they're hiding anything.
[00:53:29.420 --> 00:53:31.020]   It's Sunday night's a euphemism.
[00:53:31.020 --> 00:53:33.300]   It was hit midnight Easter.
[00:53:33.300 --> 00:53:39.340]   Which, you know, to me, I mean, I it's not that I mean,
[00:53:39.340 --> 00:53:42.140]   I think most people thought that was like him being mischievous.
[00:53:42.140 --> 00:53:45.300]   What what I do, I mean, the guy works around the clock.
[00:53:45.300 --> 00:53:47.420]   Right. That was when he had a free moment. Right.
[00:53:47.420 --> 00:53:50.980]   And they're like two two congressmen.
[00:53:50.980 --> 00:53:55.100]   Yeah. And so one of the things I tweeted on Sunday night
[00:53:55.100 --> 00:53:58.620]   after that was if we do this and if we tell
[00:53:58.620 --> 00:54:02.500]   if we if we tell the American people, you know, that we're going to do this
[00:54:02.500 --> 00:54:05.340]   and we put together a believable plan where you're going to cut a trillion
[00:54:05.340 --> 00:54:08.180]   dollars and balance the budget in the next few years,
[00:54:08.180 --> 00:54:10.340]   I'll tell you what's going to happen. Right.
[00:54:10.340 --> 00:54:12.740]   Interest rates are going to come down. Right.
[00:54:12.740 --> 00:54:16.260]   Because the whole reason bond vigilantes moved into the bond market
[00:54:16.260 --> 00:54:19.140]   and started shorting it is they thought, OK, here we go.
[00:54:19.140 --> 00:54:21.380]   Trump's going to stimulate the hell out of the economy
[00:54:21.380 --> 00:54:24.020]   with a continuation of taxes, et cetera.
[00:54:24.020 --> 00:54:27.060]   And nothing's going to really change on costs.
[00:54:27.300 --> 00:54:30.980]   And I think the big thing that I came back thinking is
[00:54:30.980 --> 00:54:33.300]   people are wrong.
[00:54:33.300 --> 00:54:36.580]   Right. Like there are there is a fundamental difference
[00:54:36.580 --> 00:54:39.060]   in how these folks are attacking,
[00:54:39.060 --> 00:54:42.260]   removing inefficient spending from the federal government
[00:54:42.260 --> 00:54:46.100]   and getting us back to what is a very sensible 2019 baseline.
[00:54:46.100 --> 00:54:48.980]   Remember, nobody thought in 2019, Bill,
[00:54:48.980 --> 00:54:53.300]   that we were like starving babies in the streets because our spending was so low.
[00:54:53.300 --> 00:54:55.180]   Nobody thought that. OK.
[00:54:55.180 --> 00:54:59.100]   Like everybody thought we were spending plenty of money in 2019.
[00:54:59.100 --> 00:55:01.220]   And that's all they're talking about.
[00:55:01.220 --> 00:55:04.700]   And yet, if you watch the convulsion coming out of Washington,
[00:55:04.700 --> 00:55:09.460]   you would think that, you know, something very draconian was going on.
[00:55:09.460 --> 00:55:12.140]   Well, I mean, but you would expect that, right?
[00:55:12.140 --> 00:55:14.580]   Like we don't have term limits.
[00:55:14.580 --> 00:55:15.740]   We have lifelong
[00:55:15.740 --> 00:55:19.660]   politicians in Washington.
[00:55:19.660 --> 00:55:22.420]   They we because of Citizens United,
[00:55:22.580 --> 00:55:25.700]   you basically can raise money, unlimited amounts of money
[00:55:25.700 --> 00:55:27.180]   from corporate interests.
[00:55:27.180 --> 00:55:31.860]   I you know, I gave the speech a year and a half ago on on regulatory capture.
[00:55:31.860 --> 00:55:36.900]   I I'm not surprised that the the entity
[00:55:36.900 --> 00:55:41.660]   that is Washington pushes back on someone that wants to take away
[00:55:41.660 --> 00:55:43.860]   the tools that give them power.
[00:55:43.860 --> 00:55:45.620]   I'm just not not surprised.
[00:55:45.620 --> 00:55:49.780]   Well, I think I think what people expected, frankly, is, you know,
[00:55:49.900 --> 00:55:52.820]   immediately after people started seeing the relationship with Trump,
[00:55:52.820 --> 00:55:54.180]   what's the first thing people did?
[00:55:54.180 --> 00:55:58.060]   They all started speculating how long until the relationship blows up.
[00:55:58.060 --> 00:56:00.220]   And, you know, Trump always fires everybody.
[00:56:00.220 --> 00:56:02.340]   And and just the opposite is happening.
[00:56:02.340 --> 00:56:06.060]   And then I think they all expected Elon just to come to Washington,
[00:56:06.060 --> 00:56:09.020]   not do anything like just to maybe make some recommendations
[00:56:09.020 --> 00:56:11.100]   to Congress on things that could be cut.
[00:56:11.100 --> 00:56:14.700]   But you and I know, Eli, like there's no chance he's going to Washington
[00:56:14.700 --> 00:56:18.980]   to just like, you know, run some research and make some recommendations.
[00:56:19.260 --> 00:56:21.340]   So I think that was misplaced.
[00:56:21.340 --> 00:56:26.460]   So let me tell you how I think Doge fits in with the normal budget process,
[00:56:26.460 --> 00:56:29.780]   because I also think this is very misunderstood. Right.
[00:56:29.780 --> 00:56:33.740]   So remember, I think the way to think about this in your head
[00:56:33.740 --> 00:56:36.660]   is we have two tracks going on here.
[00:56:36.660 --> 00:56:39.660]   Track one is the normal budget process.
[00:56:39.660 --> 00:56:43.580]   And in this case, they're using a parliamentary tool
[00:56:43.580 --> 00:56:46.060]   called reconciliation, OK?
[00:56:46.060 --> 00:56:48.540]   And basically what that means, I'll spare you the details.
[00:56:48.980 --> 00:56:53.180]   But this is out of the White House, led by Kevin Hassett in the House,
[00:56:53.180 --> 00:56:55.660]   obviously led by the speaker in the House Budget Committee.
[00:56:55.660 --> 00:56:59.220]   But basically, reconciliation is a special budget process
[00:56:59.220 --> 00:57:03.060]   that allows you to get an omnibus budget bill past Congress
[00:57:03.060 --> 00:57:06.460]   without having to get to the 60 votes in the Senate
[00:57:06.460 --> 00:57:08.900]   that is filibuster proof, OK?
[00:57:08.900 --> 00:57:10.620]   And they're working hard on this.
[00:57:10.620 --> 00:57:14.420]   I expect some meaningful improvements that will come out of this in spending.
[00:57:14.420 --> 00:57:18.340]   I suspect that Doge will be offering their ideas how to save some money in this.
[00:57:18.500 --> 00:57:21.980]   But this is kind of the normal process that occurs in Washington.
[00:57:21.980 --> 00:57:25.180]   And the president, I think, has said he wants something to sign out
[00:57:25.180 --> 00:57:28.900]   of the reconciliation process in April or May. Right.
[00:57:28.900 --> 00:57:31.140]   And so it has to go through this normal.
[00:57:31.140 --> 00:57:33.340]   All the committees are going to have their hearings.
[00:57:33.340 --> 00:57:36.060]   They're going to put together the budget that they think complies
[00:57:36.060 --> 00:57:37.060]   with reconciliation.
[00:57:37.060 --> 00:57:39.140]   There's going to be a grand negotiation,
[00:57:39.140 --> 00:57:41.540]   you know, that occurs with 10 people around the table.
[00:57:41.540 --> 00:57:44.780]   And, you know, all the horse trading that usually occurs in Washington.
[00:57:44.780 --> 00:57:46.820]   So that's track one bill.
[00:57:46.820 --> 00:57:53.100]   Track two is Doge and cuts in spending by executive authority.
[00:57:53.100 --> 00:57:58.020]   And this is the part that I think has Washington up in arms.
[00:57:58.020 --> 00:58:01.500]   So that's what you see that's causing the fury.
[00:58:01.500 --> 00:58:07.340]   Elon is advising the president and then the president is deciding in real time
[00:58:07.340 --> 00:58:10.940]   whether certain people need and need to be cut
[00:58:10.940 --> 00:58:13.900]   and whether certain spending should be stopped.
[00:58:14.660 --> 00:58:18.620]   And when the answer is no, this amount of money and these people
[00:58:18.620 --> 00:58:22.260]   are not required to faithfully execute the laws that I've been given.
[00:58:22.260 --> 00:58:25.020]   They say they're just going to downsize the downsize,
[00:58:25.020 --> 00:58:28.020]   the executive agency tasked with executing the law,
[00:58:28.020 --> 00:58:31.180]   and they're going to stop spending the money that they believe is wasteful
[00:58:31.180 --> 00:58:32.980]   and not needed to fulfill the law.
[00:58:32.980 --> 00:58:37.220]   So they're saying, especially in the face of a national fiscal crisis
[00:58:37.220 --> 00:58:41.580]   where we're falling further and further into a debt spiral, we need to do this.
[00:58:41.820 --> 00:58:44.860]   So they in the town hall on Monday night or on Sunday night.
[00:58:44.860 --> 00:58:48.780]   You know, for example, Elon called USAID.
[00:58:48.780 --> 00:58:52.180]   So this is an organization that's quite controversial.
[00:58:52.180 --> 00:58:54.220]   You research it.
[00:58:54.220 --> 00:58:57.940]   That spends 50 billion dollars a year on foreign aid. OK.
[00:58:57.940 --> 00:59:01.780]   And it has thousands of people in the agency.
[00:59:01.780 --> 00:59:06.020]   And he said, well, between I think among employees,
[00:59:06.020 --> 00:59:10.300]   it's probably closer to a thousand or two and then a lot of of of contractors.
[00:59:10.780 --> 00:59:14.460]   And basically what Elon said on Sunday night is I called the president.
[00:59:14.460 --> 00:59:17.340]   I told him, unfortunately, there's no apple to be saved.
[00:59:17.340 --> 00:59:18.740]   It's a total ball of worms.
[00:59:18.740 --> 00:59:21.420]   If there was just one worm in the apple, we'd pull the worm out.
[00:59:21.420 --> 00:59:23.140]   But the whole thing is a ball of worms.
[00:59:23.140 --> 00:59:25.860]   So the whole thing needs to be shut down.
[00:59:25.860 --> 00:59:29.100]   And we're we're going to let thousands of people go
[00:59:29.100 --> 00:59:31.300]   and we're going to save 50 thousand dollars on the budget
[00:59:31.300 --> 00:59:34.220]   or 50 billion dollars on the budget.
[00:59:34.220 --> 00:59:38.340]   It subsequently looks like on Monday that, you know, they made a deal
[00:59:38.340 --> 00:59:41.780]   where Marco Rubio, right, who's the secretary of state,
[00:59:41.780 --> 00:59:44.220]   is going to become the acting director of the agency.
[00:59:44.220 --> 00:59:46.020]   And now it looks like they're going to eliminate
[00:59:46.020 --> 00:59:48.580]   whatever they think is wasteful, and then they'll consolidate
[00:59:48.580 --> 00:59:52.380]   perhaps other parts of that spending into the State Department.
[00:59:52.380 --> 00:59:56.780]   But basically, this is what Bill caused Schumer and folks
[00:59:56.780 --> 01:00:01.860]   to come out on Monday morning, declare all of this activity unconstitutional
[01:00:01.860 --> 01:00:05.980]   to say that, you know, nobody elected Elon.
[01:00:05.980 --> 01:00:08.020]   He can't do this. It's unconstitutional.
[01:00:08.100 --> 01:00:09.700]   And this is where I think you're going.
[01:00:09.700 --> 01:00:11.660]   The whole challenge is now going to move.
[01:00:11.660 --> 01:00:14.180]   But remember, this has nothing to do with track one.
[01:00:14.180 --> 01:00:18.140]   Right. Except you're angering a lot of people on the Democratic side.
[01:00:18.140 --> 01:00:20.060]   But this is really about track two.
[01:00:20.060 --> 01:00:22.420]   Does the president have executive authority
[01:00:22.420 --> 01:00:25.540]   not to spend money that they deem is wasteful?
[01:00:25.540 --> 01:00:30.580]   So you asked me a question and maybe we'll touch on it
[01:00:30.580 --> 01:00:35.620]   for a second earlier, which is, is it constitutional? Right.
[01:00:35.900 --> 01:00:39.700]   And so I think that's a pretty fascinating constitutional question.
[01:00:39.700 --> 01:00:43.460]   I've consulted with a lot of people I think are experts in the area area.
[01:00:43.460 --> 01:00:47.900]   And I do expect that Schumer or a group of members as early as this week
[01:00:47.900 --> 01:00:53.700]   is going to file, you know, a claim, a lawsuit in federal court
[01:00:53.700 --> 01:00:56.660]   where they say that this is a violation of the Constitution
[01:00:56.660 --> 01:00:59.700]   under Article one, Section nine, Clause seven, where Congress
[01:00:59.700 --> 01:01:02.460]   has the power of the purse strings and the Supreme Court,
[01:01:02.460 --> 01:01:05.140]   you know, has long upheld this.
[01:01:05.140 --> 01:01:07.740]   You know, basically, the Supreme Court has said separation of powers
[01:01:07.740 --> 01:01:11.700]   generally support the idea that it's Congress who appropriates funds
[01:01:11.700 --> 01:01:15.100]   and anybody else who doesn't spend those monies that would be unconstitutional.
[01:01:15.100 --> 01:01:18.860]   So that that's likely the argument they're going to make, Bill,
[01:01:18.860 --> 01:01:22.060]   and they're going to say immediately they got to cease and desist
[01:01:22.060 --> 01:01:25.540]   from, you know, Elon shutting off wires
[01:01:25.540 --> 01:01:28.140]   or not spending money or shutting down USAID.
[01:01:28.140 --> 01:01:30.500]   Now, I happen to think that's on pretty weak footing.
[01:01:30.500 --> 01:01:32.260]   OK, but it is.
[01:01:32.260 --> 01:01:34.900]   I think it's going to happen on weak footing. Why?
[01:01:35.420 --> 01:01:37.260]   So just think about this for a second, right?
[01:01:37.260 --> 01:01:41.020]   The president has the authority to execute the laws.
[01:01:41.020 --> 01:01:44.820]   And there's this doctrine that's known as impoundment,
[01:01:44.820 --> 01:01:47.180]   which the courts largely recognize.
[01:01:47.180 --> 01:01:50.300]   And it's basically the president saying, OK, I see the law
[01:01:50.300 --> 01:01:53.740]   that we're supposed to uphold and I don't need all this money.
[01:01:53.740 --> 01:01:57.860]   And in fact, I have a further and maybe supreme duty,
[01:01:57.860 --> 01:02:02.180]   an overriding duty to the Constitution that supersedes
[01:02:02.580 --> 01:02:06.340]   the constitutional control of the purse, to execute faithfully the laws,
[01:02:06.340 --> 01:02:10.220]   to protect the general welfare of the American people, which he might argue
[01:02:10.220 --> 01:02:13.060]   includes protecting the country from bankruptcy.
[01:02:13.060 --> 01:02:16.700]   Right. So he's just saying, listen, I'm doing my duty.
[01:02:16.700 --> 01:02:20.180]   Yes, I'm executing all the laws they told me to execute.
[01:02:20.180 --> 01:02:22.500]   However, I'm doing it for less money.
[01:02:22.500 --> 01:02:25.420]   And and given that we're in a national debt crisis,
[01:02:25.420 --> 01:02:27.900]   I need to do that in order to protect the American people.
[01:02:27.900 --> 01:02:31.740]   So I think that this is going to eventually come to head.
[01:02:32.180 --> 01:02:35.180]   Imagine it goes to the to the Supreme Court to decide.
[01:02:35.180 --> 01:02:39.740]   And I think there's a decent chance along the way that at a minimum,
[01:02:39.740 --> 01:02:42.980]   think about what what Chuck Schumer is going to have to defend.
[01:02:42.980 --> 01:02:46.700]   He's going to have to defend some of this really crazy spending
[01:02:46.700 --> 01:02:48.620]   that we all know exists.
[01:02:48.620 --> 01:02:51.460]   I mean, I don't think there's anybody in either side of this argument
[01:02:51.460 --> 01:02:53.460]   who doesn't think there's a bunch of inefficient
[01:02:53.460 --> 01:02:55.460]   and silly spending by the government.
[01:02:55.460 --> 01:02:58.980]   So effectively, that's the that's what you're going to have to defend
[01:02:58.980 --> 01:03:00.740]   if you want to defend this lawsuit.
[01:03:00.740 --> 01:03:03.460]   So I think the political pressure is going to be massive.
[01:03:03.460 --> 01:03:07.660]   That's brought to bear, particularly because Doge is being so transparent
[01:03:07.660 --> 01:03:08.460]   on this, right?
[01:03:08.460 --> 01:03:12.460]   Like you do not want to be defending every single line item
[01:03:12.460 --> 01:03:13.700]   to the American people,
[01:03:13.700 --> 01:03:16.900]   which is exactly what Doge is going to put you on the spot to do.
[01:03:16.900 --> 01:03:19.820]   And so I think two potential outcomes.
[01:03:19.820 --> 01:03:24.660]   Number one, the political pressure causes, you know, them to cut a lot more
[01:03:24.660 --> 01:03:28.420]   as part of track one, right, this reconciliation process.
[01:03:28.820 --> 01:03:33.540]   Or number two, that the Supreme Court actually does, in fact, recognize
[01:03:33.540 --> 01:03:37.500]   some more expansive, you know, executive power around impoundment.
[01:03:37.500 --> 01:03:41.860]   But, you know, I think either way, you know, I imagine before
[01:03:41.860 --> 01:03:44.900]   this is all said and done, Bill, that we're going to see headlines
[01:03:44.900 --> 01:03:48.780]   that say Elon causing a constitutional crisis, right?
[01:03:48.780 --> 01:03:51.540]   That, you know, we have the we have the courts involved
[01:03:51.540 --> 01:03:56.140]   and you have the solicitor general that's that would be defending
[01:03:56.340 --> 01:03:59.580]   the executive branch in the White House on on this matter.
[01:03:59.580 --> 01:04:05.860]   Now, bring it home, you know, and as I said in the question, bring it back.
[01:04:05.860 --> 01:04:09.140]   Like, why does this matter for tech investors?
[01:04:09.140 --> 01:04:12.380]   What? Let's presume it goes either way.
[01:04:12.380 --> 01:04:15.580]   What's it going to mean to how a tech investor should be thinking
[01:04:15.580 --> 01:04:18.660]   about the markets and and tech stocks?
[01:04:18.660 --> 01:04:22.940]   Yeah, I mean, just think about what were the three topics we talked about today.
[01:04:23.460 --> 01:04:27.140]   The first one was like just massive technological uncertainty, right?
[01:04:27.140 --> 01:04:31.500]   Like where you said it, it's a pace of change you've never seen in your career.
[01:04:31.500 --> 01:04:35.100]   Highly disruptive, multi, you know, companies that are valued
[01:04:35.100 --> 01:04:39.060]   at one hundred and fifty billion dollars that are being challenged by,
[01:04:39.060 --> 01:04:42.100]   you know, a Chinese startup on a shoestring.
[01:04:42.100 --> 01:04:45.580]   So you and I would both say our ability to forecast the future
[01:04:45.580 --> 01:04:49.860]   as to where this is going, right, is is challenged because it's moving so fast.
[01:04:50.340 --> 01:04:51.580]   Then we talk about tariffs.
[01:04:51.580 --> 01:04:54.420]   Well, massive economic uncertainty, Bill.
[01:04:54.420 --> 01:04:58.140]   I mean, you know, free trade has been generally established
[01:04:58.140 --> 01:05:00.940]   as a principle in the economy for the better part of
[01:05:00.940 --> 01:05:04.580]   certainly for you and you and my entire investment career.
[01:05:04.580 --> 01:05:06.780]   The markets could count on that.
[01:05:06.780 --> 01:05:10.020]   And now I'm suggesting that at least there's some probability
[01:05:10.020 --> 01:05:14.300]   that this president is going to move in a very different direction, right?
[01:05:14.300 --> 01:05:17.900]   That maybe it's not the best consensus, that maybe it's something else.
[01:05:17.900 --> 01:05:21.900]   It's it's a we might call it the Trump new normal, right?
[01:05:21.900 --> 01:05:26.460]   Where tariffs become standard practice and maybe as a replacement to income tax.
[01:05:26.460 --> 01:05:28.540]   So, OK, there's a lot of uncertainty around that.
[01:05:28.540 --> 01:05:31.420]   And now this third one is political, right?
[01:05:31.420 --> 01:05:34.100]   Like it's been a while since we had a looming political
[01:05:34.100 --> 01:05:38.020]   constitutional crisis where, you know, where an issue between
[01:05:38.020 --> 01:05:42.220]   the congressional branch and the executive branch went to the Supreme Court.
[01:05:42.220 --> 01:05:46.140]   That also yields a lot of uncertainty when you add these uncertainties up.
[01:05:46.340 --> 01:05:49.060]   What does it do for the value of assets that you and I look at?
[01:05:49.060 --> 01:05:51.820]   Right. You and I are valuing those future cash flows.
[01:05:51.820 --> 01:05:53.820]   We have to apply a discount rate.
[01:05:53.820 --> 01:05:58.580]   Discount rate measures the risk associated with those future cash flows.
[01:05:58.580 --> 01:06:00.820]   So you and I have to take the discount rate up.
[01:06:00.820 --> 01:06:05.740]   Why? Because we're a lot less certain about technology, politics and economics.
[01:06:05.740 --> 01:06:09.820]   So to me, that means multiples come down and asset prices have to come down.
[01:06:09.820 --> 01:06:11.580]   Why? The world sifts through all this.
[01:06:11.580 --> 01:06:14.140]   The surprising thing to me really, Bill, is how well
[01:06:14.620 --> 01:06:18.020]   the public markets have held up in the face of all of this. Right.
[01:06:18.020 --> 01:06:20.860]   And I think part of that has to do with they believe Trump
[01:06:20.860 --> 01:06:22.980]   is going to be a super pro-growth president.
[01:06:22.980 --> 01:06:25.500]   You're going to have lower taxes, et cetera.
[01:06:25.500 --> 01:06:28.980]   But I think that's the risk on the table as a risk manager.
[01:06:28.980 --> 01:06:34.340]   What I have to say to my team is, OK, we've got a downsized risk, right?
[01:06:34.340 --> 01:06:37.980]   We you know, you don't do the 10th best idea, right?
[01:06:37.980 --> 01:06:39.220]   Or the 11th best idea.
[01:06:39.220 --> 01:06:44.060]   You really got to make sure that you that you better understand this stuff.
[01:06:44.060 --> 01:06:46.780]   And so I think for the long term investor, you know, perhaps
[01:06:46.780 --> 01:06:50.100]   they can just ignore the noise and they could say, you know, I'm fully involved.
[01:06:50.100 --> 01:06:51.260]   I'm fully invested.
[01:06:51.260 --> 01:06:52.860]   I believe in this super cycle.
[01:06:52.860 --> 01:06:54.940]   AI is going to be great for everything.
[01:06:54.940 --> 01:06:59.420]   But what I would say to our friends in Silicon Valley is expect way more volatility.
[01:06:59.420 --> 01:07:02.940]   I think the next six months, all of this uncertainty
[01:07:02.940 --> 01:07:05.620]   means that you're going to have a lot of volatility.
[01:07:05.620 --> 01:07:07.860]   It's exactly what we felt all weekend long.
[01:07:07.860 --> 01:07:11.140]   It's exactly why the markets were gapping down overnight on Sunday.
[01:07:11.340 --> 01:07:14.220]   And then they did this U-turn because we got a change in policy
[01:07:14.220 --> 01:07:17.060]   or what appeared to be a change in policy out of the White House.
[01:07:17.060 --> 01:07:20.180]   And so, you know, welcome back to 2017, Bill.
[01:07:20.180 --> 01:07:26.180]   All of this change may be absolutely necessary and totally good for Team America.
[01:07:26.180 --> 01:07:30.900]   But it's going to it's it's going to mean that we have more sleepless nights.
[01:07:30.900 --> 01:07:33.940]   Yeah. And look, I think I think
[01:07:33.940 --> 01:07:37.900]   because of so much chaos and because of such
[01:07:38.300 --> 01:07:42.300]   massive uncertainty in regulatory action
[01:07:42.300 --> 01:07:44.260]   and the fact that it can often backfire.
[01:07:44.260 --> 01:07:47.660]   I mean, I give you the example, like when Deep Seek popped up.
[01:07:47.660 --> 01:07:51.860]   First of all, I think this whole economic thing kind of got blown out of proportion.
[01:07:51.860 --> 01:07:56.420]   The paper originally said six million was just the post training.
[01:07:56.420 --> 01:07:59.220]   And somebody interpreted that as the whole thing.
[01:07:59.220 --> 01:08:00.300]   And then it led to it.
[01:08:00.300 --> 01:08:04.220]   But but a lot of people then I would say a lot of Nvidia bulls
[01:08:04.220 --> 01:08:07.100]   ran out and said, no, no, no, they had way more Nvidia.
[01:08:07.460 --> 01:08:09.460]   They had way more GPUs than they thought.
[01:08:09.460 --> 01:08:11.860]   Well, guess what?
[01:08:11.860 --> 01:08:15.380]   Pounding the table on that may cause some in Washington to say, oh,
[01:08:15.380 --> 01:08:17.780]   we should have had higher restriction.
[01:08:17.780 --> 01:08:19.340]   So you're an Nvidia bull.
[01:08:19.340 --> 01:08:23.620]   Think you're protecting Nvidia by exposing Deep Seek.
[01:08:23.620 --> 01:08:27.380]   And you may end up with sanctions that end up hurting Nvidia's revenue.
[01:08:27.380 --> 01:08:30.740]   So it's a it's a it's a dangerous place to play.
[01:08:30.740 --> 01:08:35.740]   Well, I mean, you just you just showed I mean, you have all of these forces at play.
[01:08:35.780 --> 01:08:37.900]   Listen, what do I do as an investor?
[01:08:37.900 --> 01:08:41.700]   You know, what did I do in the fall of 22 that led me into Nvidia in the first place?
[01:08:41.700 --> 01:08:44.820]   I just studied what was happening in technology in the company.
[01:08:44.820 --> 01:08:47.420]   I didn't have to think about free trade or tariffs.
[01:08:47.420 --> 01:08:49.860]   I didn't have to think about export restrictions.
[01:08:49.860 --> 01:08:53.380]   I didn't have to think about, you know, constitutional crisis.
[01:08:53.380 --> 01:08:57.060]   All I had to figure out is, is the forecast for Nvidia too low
[01:08:57.060 --> 01:08:58.140]   because of the explosion?
[01:08:58.140 --> 01:08:59.820]   We're about ready to have an AI.
[01:08:59.820 --> 01:09:01.980]   And that's the bet we made and we won big on.
[01:09:01.980 --> 01:09:05.620]   But now, as I sit here today, the valuation for Nvidia is much higher.
[01:09:06.060 --> 01:09:09.700]   And now I have to take into consideration all these other risks.
[01:09:09.700 --> 01:09:12.980]   And all I'm saying is all else being created equal.
[01:09:12.980 --> 01:09:16.580]   I think that the super cycle is, is, you know, if I'm just doing
[01:09:16.580 --> 01:09:19.020]   my fundamental analysis, I think it's on fire.
[01:09:19.020 --> 01:09:21.220]   I think we're going to need way more compute than we have.
[01:09:21.220 --> 01:09:24.500]   I think DeepSeek unleashes the amount of inference we're going to need.
[01:09:24.500 --> 01:09:27.140]   I think deep research out of OpenAI unleashes that.
[01:09:27.140 --> 01:09:29.540]   So I think the fundamental is bigger than ever.
[01:09:29.540 --> 01:09:35.420]   But at the same time, I also am humble in the face of what's known and knowable.
[01:09:36.060 --> 01:09:41.420]   About the next 12 months, you know, around tariffs, around export controls,
[01:09:41.420 --> 01:09:43.580]   around all these other risks in the economy.
[01:09:43.580 --> 01:09:46.820]   And I just think we have to, you know, you have to look in the mirror
[01:09:46.820 --> 01:09:49.780]   and acknowledge that a lot of this is unpredictable.
[01:09:49.780 --> 01:09:52.580]   And that impacts what folks are willing to pay,
[01:09:52.580 --> 01:09:54.380]   what multiple folks are willing to pay.
[01:09:54.380 --> 01:09:57.820]   And for our friends in the VC markets, right, particularly
[01:09:57.820 --> 01:10:01.420]   some of these high valued companies, you know, in mid and late stage VC,
[01:10:01.420 --> 01:10:03.140]   it's going to impact, right?
[01:10:03.140 --> 01:10:04.580]   There's always that lag effect.
[01:10:04.580 --> 01:10:07.740]   But the public markets and the risk appetite and the multiples they pay,
[01:10:07.740 --> 01:10:09.060]   that rolls downhill.
[01:10:09.060 --> 01:10:12.260]   And so I would just say, I think that we may get to the back
[01:10:12.260 --> 01:10:13.940]   half of this year or into next year.
[01:10:13.940 --> 01:10:16.740]   And it may, in fact, be the golden age and off to the races.
[01:10:16.740 --> 01:10:19.740]   But I think at the moment it's the golden age of uncertainty.
[01:10:19.740 --> 01:10:23.980]   Hey, Brad, let's let's I think that's that's well said.
[01:10:23.980 --> 01:10:28.300]   Let's close with where we started with this sovereign wealth fund thing.
[01:10:28.300 --> 01:10:33.820]   So pick either the pro or the con, make the argument,
[01:10:33.820 --> 01:10:36.740]   and then I'll take the other side.
[01:10:36.740 --> 01:10:39.900]   Well, I mean, like I think you saw me post in our thread
[01:10:39.900 --> 01:10:42.700]   as a general matter, right?
[01:10:42.700 --> 01:10:46.940]   I'm you know, I love the fact that we have people with business
[01:10:46.940 --> 01:10:50.460]   sensibilities and and incentives looking out for America
[01:10:50.460 --> 01:10:53.500]   who want to negotiate on behalf of America. Right.
[01:10:53.500 --> 01:10:57.660]   And who, you know, we sell we sell wireless spectrum and licenses. Right.
[01:10:57.660 --> 01:11:01.460]   I would love to see that go to the benefit of all the citizens in the country.
[01:11:01.700 --> 01:11:07.220]   You know, we we, you know, have, you know, drilling licenses on national lands.
[01:11:07.220 --> 01:11:09.780]   That's that that money belongs to the citizens.
[01:11:09.780 --> 01:11:11.260]   So I love that idea.
[01:11:11.260 --> 01:11:13.460]   You know, in the fund, here's my challenge with it, Bill.
[01:11:13.460 --> 01:11:16.460]   We have 40 trillion in debt
[01:11:16.460 --> 01:11:19.740]   and we probably have another 50 trillion of unfunded liabilities.
[01:11:19.740 --> 01:11:25.140]   So we're a debtor nation and we're paying five percent on all that debt.
[01:11:25.140 --> 01:11:29.740]   So the hurdle rate to our return that is needed on the sovereign wealth fund,
[01:11:30.060 --> 01:11:31.140]   right, is five percent.
[01:11:31.140 --> 01:11:34.260]   Otherwise, you would just take all those monies and you would pay down the debt.
[01:11:34.260 --> 01:11:36.300]   Right. If this was our personal balance sheet.
[01:11:36.300 --> 01:11:40.100]   So what you and I would describe this as is we're levering up
[01:11:40.100 --> 01:11:43.300]   the balance sheet of the United States to earn the spread
[01:11:43.300 --> 01:11:47.060]   between the sovereign wealth fund returns and the five percent
[01:11:47.060 --> 01:11:48.860]   that we're paying to borrow all the money.
[01:11:48.860 --> 01:11:52.300]   So I think net net, I probably have it in place
[01:11:52.300 --> 01:11:54.420]   because I think it's a good tactical lever.
[01:11:54.420 --> 01:11:59.180]   You know, I do worry about what administration administration
[01:11:59.180 --> 01:12:02.940]   it could lead to some crony capitalism and deal making that benefits
[01:12:02.940 --> 01:12:04.500]   certain people, et cetera.
[01:12:04.500 --> 01:12:05.740]   So I don't know.
[01:12:05.740 --> 01:12:08.500]   It's a close call for me, but I think it's going to happen either way.
[01:12:08.500 --> 01:12:10.820]   I would you took both sides.
[01:12:10.820 --> 01:12:13.100]   So I'll do a quick both sides.
[01:12:13.100 --> 01:12:15.980]   Yeah. I mean, in addition to the scenarios you talked about
[01:12:15.980 --> 01:12:21.940]   and you and I have debated this in the past, but if I look at Goldman Sachs, GM,
[01:12:21.940 --> 01:12:26.500]   even United, like if the government's going to be the lender of last resort,
[01:12:26.660 --> 01:12:29.020]   I would argue they should take all of the equity.
[01:12:29.020 --> 01:12:31.100]   And this could be a vehicle for that.
[01:12:31.100 --> 01:12:34.220]   Although there's nothing that's kept the government from doing that.
[01:12:34.220 --> 01:12:36.260]   I think in the GM case, they did take equity.
[01:12:36.260 --> 01:12:40.100]   So it's like it has done it in the past without the vehicle.
[01:12:40.100 --> 01:12:44.220]   I'm way more skeptical than you on the crony capitalism.
[01:12:44.220 --> 01:12:49.660]   It would be a ninety nine percent certainty that this asset would be rated
[01:12:49.660 --> 01:12:53.740]   from from transition to transition in the government.
[01:12:53.740 --> 01:12:58.060]   And I would highlight that probably the most successful
[01:12:58.060 --> 01:13:02.340]   sovereign wealth funds in the world are all in autocracies.
[01:13:02.340 --> 01:13:04.740]   They're not in democracies.
[01:13:04.740 --> 01:13:07.740]   I don't agree. I don't agree with that.
[01:13:07.740 --> 01:13:08.900]   I don't agree with that.
[01:13:08.900 --> 01:13:14.380]   I mean, from from from Norway with Norges to Korea to Canada,
[01:13:14.380 --> 01:13:16.660]   we have a lot of great sovereign wealth funds.
[01:13:16.660 --> 01:13:18.420]   But I do think, you know, it's fair.
[01:13:18.420 --> 01:13:21.380]   I think one of the things I would say in all those countries,
[01:13:21.380 --> 01:13:25.460]   what you do have, Bill, is consistency and independence
[01:13:25.460 --> 01:13:29.100]   in the management of the sovereign wealth fund, independent
[01:13:29.100 --> 01:13:32.820]   from like some unilateral control by the by the executive branch.
[01:13:32.820 --> 01:13:36.340]   And then if you want to see, I can go really wrong.
[01:13:36.340 --> 01:13:39.060]   Please go read Billion Dollar Whale.
[01:13:39.060 --> 01:13:43.020]   It's one of the most exciting books you could possibly read
[01:13:43.020 --> 01:13:45.980]   about what happened to the Malaysian sovereign wealth fund.
[01:13:45.980 --> 01:13:50.380]   So, well, as always, it's fun to get together.
[01:13:50.380 --> 01:13:53.260]   Thanks for making the time. We'll talk soon. All right.
[01:13:53.260 --> 01:14:06.860]   As a reminder to everybody, just our opinions, not investment advice.

