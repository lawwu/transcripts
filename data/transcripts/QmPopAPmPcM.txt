
[00:00:00.000 --> 00:00:06.480]   So one thing that I think generally sucks about the mobile ecosystem is that like you have these
[00:00:06.480 --> 00:00:11.120]   two gatekeeper companies, Apple and Google, that can tell you what you're allowed to build.
[00:00:11.120 --> 00:00:14.720]   And there are lots of times in our history. So there's the economic version of that,
[00:00:14.720 --> 00:00:16.240]   which is like, all right, we build something and they're just like,
[00:00:16.240 --> 00:00:21.440]   I'm going to take a bunch of your money. But then there's the qualitative version,
[00:00:21.440 --> 00:00:25.920]   which is actually what kind of upsets me more, which is there's a bunch of times when we've
[00:00:25.920 --> 00:00:30.720]   launched or wanted to launch features. And then Apple is just like, nope, you're not launching
[00:00:30.720 --> 00:00:36.240]   that. I was like, that sucks. Right. The question is, what is like, are we kind of set up for a
[00:00:36.240 --> 00:00:42.800]   world like that with AI, where like, you're going to get a handful of companies that run these
[00:00:42.800 --> 00:00:46.480]   closed models that are going to be in control of the APIs and therefore going to be able to tell
[00:00:46.480 --> 00:00:53.120]   you what you can build? Well, for one, I can say for us, it is worth it to go build a model
[00:00:53.120 --> 00:00:58.080]   ourselves to make sure that we're not in that position. Like I don't want any of those other
[00:00:58.080 --> 00:01:03.280]   companies telling us what we can build. But from an open source perspective, I think a lot of
[00:01:03.280 --> 00:01:07.040]   developers don't want those companies telling them what they can build either. And this is one of the
[00:01:07.040 --> 00:01:14.400]   reasons why I'm kind of philosophically so pro open source is I do think that a concentration
[00:01:14.960 --> 00:01:23.280]   of AI in the future has the potential to be as dangerous as kind of it being widespread.
[00:01:23.280 --> 00:01:27.760]   So I think a lot of people are, they think about the questions of, okay, well, if we can do this
[00:01:27.760 --> 00:01:35.040]   stuff, is it bad for it to be out wild? Like just in kind of widely available. I think another
[00:01:35.040 --> 00:01:44.320]   version of this is like, okay, well, it's probably also pretty bad for one institution to have an AI
[00:01:44.320 --> 00:01:50.320]   that is way more powerful than everyone else's AI. I kind of think that a world where AI is
[00:01:50.320 --> 00:01:58.400]   very widely deployed in a way where it's gotten hardened progressively over time and is one where
[00:01:58.400 --> 00:02:03.600]   all the different systems will be in check in a way that seems like it is fundamentally more
[00:02:03.600 --> 00:02:09.440]   healthy to me than one where this is more concentrated. So there are risks on all sides,
[00:02:09.440 --> 00:02:15.280]   but I think that that's one risk that I think people, I don't hear them talking about quite
[00:02:15.280 --> 00:02:19.920]   as much. The $10 billion model, suppose it's totally safe. You've done these evaluations.
[00:02:19.920 --> 00:02:24.080]   Would you open source that? The $10 billion model? Well, I mean, as long as it's helping us,
[00:02:24.080 --> 00:02:28.160]   then yeah. But would it like the $10 billion of R&D and then now it's like open source?
[00:02:28.160 --> 00:02:33.120]   We have a long history of open sourcing software, right? We don't tend to open source our product,
[00:02:33.120 --> 00:02:37.520]   right? So it's not like we don't take like the code for Instagram and make it open source,
[00:02:37.520 --> 00:02:42.960]   but we take like a lot of the low level infrastructure and we make that open source,
[00:02:42.960 --> 00:02:47.920]   right? Probably the biggest one in our history was Open Compute Project where we
[00:02:47.920 --> 00:02:54.240]   took the designs for kind of all of our servers and network switches and data centers and made
[00:02:54.240 --> 00:02:58.880]   it open source and ended up being super helpful because, I mean, a lot of people can design
[00:02:58.880 --> 00:03:03.040]   servers, but now like the industry standardized on our design, which meant that the supply chains
[00:03:03.920 --> 00:03:07.680]   basically all got built out around our design. The volumes went up, so it got cheaper for everyone
[00:03:07.680 --> 00:03:13.280]   and saved us billions of dollars. So awesome, right? Okay, so there's multiple ways where
[00:03:13.280 --> 00:03:18.240]   open source I think could be helpful for us. One is if people figure out how to run the models
[00:03:18.240 --> 00:03:23.280]   more cheaply. Well, we're going to be spending tens or like $100 billion or more over time
[00:03:23.280 --> 00:03:29.600]   on all this stuff. So if we can do that 10% more effectively, we're saving billions or tens of
[00:03:29.600 --> 00:03:32.960]   billions of dollars. Okay, that's probably worth a lot by itself. As far as the open source goes,
[00:03:32.960 --> 00:03:37.280]   I'm actually curious if you think the impact of the open source from PyTorch, React, Open Compute,
[00:03:37.280 --> 00:03:41.920]   these things, has been bigger for the world than even the social media aspects of meta.
[00:03:41.920 --> 00:03:44.800]   Because I've like talked to people who use these services who think like it's plausible
[00:03:44.800 --> 00:03:48.880]   because a big part of the internet runs on these things. It's an interesting question. I mean,
[00:03:48.880 --> 00:03:52.880]   I think almost half the world uses our... Yeah, that's true.
[00:03:52.880 --> 00:03:59.440]   So I think it's hard to beat that, but no, I think open sources,
[00:04:01.120 --> 00:04:03.920]   it's really powerful as a new way of building things.
[00:04:03.920 --> 00:04:05.980]   you
[00:04:05.980 --> 00:04:15.980]   [BLANK_AUDIO]

