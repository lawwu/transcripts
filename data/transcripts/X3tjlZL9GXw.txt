
[00:00:00.000 --> 00:00:05.020]   [ Music ]
[00:00:05.020 --> 00:00:06.820]   >> Hi, everybody, and welcome
[00:00:06.820 --> 00:00:09.800]   to the Fastbook reading session with Jeremy Howard.
[00:00:09.800 --> 00:00:11.400]   Hi, Jeremy.
[00:00:11.400 --> 00:00:14.040]   >> Hello there.
[00:00:14.040 --> 00:00:16.600]   >> Thank you for joining us today.
[00:00:16.600 --> 00:00:19.960]   It's really, and I think it's the,
[00:00:19.960 --> 00:00:22.480]   it's a super exciting moment for me today.
[00:00:22.480 --> 00:00:24.360]   I've always been a big fan of you,
[00:00:24.360 --> 00:00:26.680]   and I've been following your work for quite a few years,
[00:00:26.680 --> 00:00:28.600]   and having you with us today.
[00:00:28.600 --> 00:00:30.720]   It's a big, big moment, and thank you
[00:00:30.720 --> 00:00:33.400]   for finding the time for joining us today.
[00:00:33.400 --> 00:00:36.000]   >> All right.
[00:00:36.000 --> 00:00:40.840]   >> Cool. So I'll go quickly into the outline for today.
[00:00:40.840 --> 00:00:42.920]   So for the agenda for today looks like this.
[00:00:42.920 --> 00:00:45.680]   The session will run for 60 minutes.
[00:00:45.680 --> 00:00:48.120]   I will spend the first five minutes or so
[00:00:48.120 --> 00:00:49.600]   in the bulk of an introduction.
[00:00:49.600 --> 00:00:52.280]   Then we have an introduction to Fast AI,
[00:00:52.280 --> 00:00:54.240]   Faster AI by Jeremy.
[00:00:54.240 --> 00:00:56.920]   Then I will spend about 10 minutes just looking
[00:00:56.920 --> 00:00:59.600]   into the Fastbook session, and this will be more
[00:00:59.600 --> 00:01:02.560]   to provide an outline for everybody who's here today
[00:01:02.560 --> 00:01:05.400]   and what they can expect for the next 20 weeks.
[00:01:05.400 --> 00:01:07.360]   How is each session going to run?
[00:01:07.360 --> 00:01:09.760]   Then there's a special section which I've called
[00:01:09.760 --> 00:01:11.760]   "In Conversation with Jeremy," because I couldn't come
[00:01:11.760 --> 00:01:13.280]   up with a better name.
[00:01:13.280 --> 00:01:15.720]   So I just called it "In Conversation with Jeremy."
[00:01:15.720 --> 00:01:19.000]   And in the end, we go for the AMA with Jeremy,
[00:01:19.000 --> 00:01:21.320]   which is "Ask Me Anything."
[00:01:21.320 --> 00:01:25.560]   So the timelines are only rough timelines, but we do hope to,
[00:01:25.560 --> 00:01:29.320]   we do plan on having this whole session for 60 minutes.
[00:01:29.320 --> 00:01:33.240]   So going into the, very quickly, I just want to share
[00:01:33.240 --> 00:01:36.560]   for the AMA towards the end, I'll share this again as well.
[00:01:36.560 --> 00:01:39.200]   For the AMA, we have this URL,
[00:01:39.200 --> 00:01:42.600]   which is called 1db.me/jeremy.
[00:01:42.600 --> 00:01:46.560]   So if we go to this URL, 1db.me/jeremy,
[00:01:46.560 --> 00:01:48.720]   are you able to see my Google Chrome?
[00:01:48.720 --> 00:01:50.920]   - Yep.
[00:01:50.920 --> 00:01:51.760]   - Excellent. So that should be-
[00:01:51.760 --> 00:01:54.480]   - I just put that link into the chat, by the way.
[00:01:54.480 --> 00:01:56.080]   - Thank you, Jeremy.
[00:01:56.080 --> 00:02:02.720]   So that URL will bring us to this page.
[00:02:02.720 --> 00:02:04.560]   And the reason why we go into this page
[00:02:04.560 --> 00:02:06.560]   towards the "Ask Me Anything" towards the end
[00:02:06.560 --> 00:02:10.480]   is we're also live on YouTube and we're also live on Zoom
[00:02:10.480 --> 00:02:12.160]   and a couple other platforms.
[00:02:12.160 --> 00:02:14.720]   So what I've been doing, and when we do host
[00:02:14.720 --> 00:02:18.000]   our paper reading groups, what we do is we use the reports
[00:02:18.000 --> 00:02:20.000]   as comments, as live comments.
[00:02:20.000 --> 00:02:22.560]   So as you can see, all the questions get asked.
[00:02:22.560 --> 00:02:24.240]   And towards the end of the presentation,
[00:02:24.240 --> 00:02:25.920]   I'll come here and the comments are live
[00:02:25.920 --> 00:02:29.120]   and we'll be asking those questions to Jeremy.
[00:02:29.120 --> 00:02:30.720]   So that's that.
[00:02:30.720 --> 00:02:34.480]   So very quickly, why are we hosting
[00:02:34.480 --> 00:02:36.880]   FAST Book reading sessions at Weights & Biases?
[00:02:36.880 --> 00:02:39.200]   Why are we all here today?
[00:02:39.200 --> 00:02:42.480]   And something I do want to clarify,
[00:02:42.480 --> 00:02:44.080]   when I mentioned FAST Book,
[00:02:44.080 --> 00:02:48.240]   there's a book that's available on Amazon to be purchased
[00:02:48.240 --> 00:02:50.640]   that's called "Deep Learning for Coders"
[00:02:50.640 --> 00:02:52.160]   with Fast.ai and PyTorch.
[00:02:52.160 --> 00:02:55.040]   And it's written by Jeremy Howard and Sylvain Gouger.
[00:02:55.040 --> 00:02:56.880]   And when I'm referring to FAST Book,
[00:02:56.880 --> 00:02:59.120]   I'm referring to the free version of this book.
[00:02:59.120 --> 00:03:01.280]   So that's also available as Jupyter Notebooks.
[00:03:01.280 --> 00:03:03.760]   It's a thanks to O'Reilly, thanks to Jeremy,
[00:03:03.760 --> 00:03:06.560]   and thanks to Sylvain for making this book
[00:03:06.560 --> 00:03:08.160]   available to everybody for free.
[00:03:08.160 --> 00:03:11.120]   And we'll be going through the free version of the book
[00:03:11.120 --> 00:03:12.800]   for the next 20 weeks.
[00:03:12.800 --> 00:03:15.600]   So why are we here today?
[00:03:15.600 --> 00:03:18.480]   Why is everybody at Weights & Biases?
[00:03:18.480 --> 00:03:20.240]   And what is Weights & Biases doing
[00:03:20.240 --> 00:03:23.520]   with FAST Book and you know?
[00:03:23.520 --> 00:03:27.040]   So something--so this is more of a personal thing
[00:03:27.040 --> 00:03:28.320]   and this is more of a journey.
[00:03:28.320 --> 00:03:32.880]   Not very long ago, I was on a very similar journey.
[00:03:32.880 --> 00:03:37.040]   I was getting started with deep learning.
[00:03:37.040 --> 00:03:39.120]   And I had paid money to do courses.
[00:03:39.120 --> 00:03:41.040]   I had tried a few different things.
[00:03:41.040 --> 00:03:43.680]   I had tried on my own and I had failed every time.
[00:03:43.680 --> 00:03:49.440]   And what came to my help was one of my colleagues mentioned,
[00:03:49.440 --> 00:03:52.080]   "Oh, have you heard of the FAST AI course?"
[00:03:52.080 --> 00:03:53.440]   The FAST AI course.
[00:03:53.440 --> 00:03:56.480]   And it's taught by Jeremy Howard and it's really good.
[00:03:56.480 --> 00:03:58.800]   And you will get straight into doing things.
[00:03:58.800 --> 00:04:00.320]   It will be really easy.
[00:04:00.320 --> 00:04:04.080]   And I say this out of utmost honesty.
[00:04:04.080 --> 00:04:05.600]   And from my experience, when I went in
[00:04:05.600 --> 00:04:06.960]   and then did the first lesson,
[00:04:06.960 --> 00:04:10.080]   within the first 10 minutes of starting out,
[00:04:10.080 --> 00:04:11.920]   I was training in Image Classifier.
[00:04:11.920 --> 00:04:13.200]   This is back in 2018.
[00:04:13.200 --> 00:04:17.600]   And at the time in 2018, we were doing cats versus dogs
[00:04:17.600 --> 00:04:18.960]   as the first lesson.
[00:04:18.960 --> 00:04:20.640]   And I was training an image classifier
[00:04:20.640 --> 00:04:22.640]   that would classify cats from dogs.
[00:04:22.640 --> 00:04:25.600]   And it could also classify various different pet breeds
[00:04:25.600 --> 00:04:29.520]   at 99% accuracy in about the first 10 minutes
[00:04:29.520 --> 00:04:30.640]   of ever starting a course.
[00:04:30.640 --> 00:04:35.200]   And that got me hooked to deep learning in a way
[00:04:35.200 --> 00:04:38.240]   that nobody else has ever had an impact like that.
[00:04:38.240 --> 00:04:43.200]   And I feel as someone who's benefited
[00:04:43.200 --> 00:04:47.600]   from the FAST AI library, from the FAST AI community so much
[00:04:47.600 --> 00:04:50.240]   that I feel it's as if my moral duty
[00:04:50.240 --> 00:04:52.800]   and it's as if my duty to pass the baton
[00:04:52.800 --> 00:04:54.800]   to everybody who's here today
[00:04:54.800 --> 00:04:57.040]   and everybody who will be joining us
[00:04:57.040 --> 00:04:59.120]   for the journey for the next 20 weeks.
[00:04:59.120 --> 00:05:02.160]   So this is not something you'd ever hear me saying,
[00:05:02.160 --> 00:05:04.320]   but because of the love for the library,
[00:05:04.320 --> 00:05:09.360]   I do wanna say that I take it as my personal duty
[00:05:09.360 --> 00:05:13.760]   to make sure that all questions get answered
[00:05:13.760 --> 00:05:16.320]   and we all learn for the next 20 weeks.
[00:05:16.800 --> 00:05:20.240]   And so that's the reason that we're here today.
[00:05:20.240 --> 00:05:26.160]   And the one person who's been at the center of it all
[00:05:26.160 --> 00:05:29.120]   and the center of pretty much all my learnings
[00:05:29.120 --> 00:05:30.960]   has been Jeremy Howard.
[00:05:30.960 --> 00:05:34.080]   We all know of him as a data scientist,
[00:05:34.080 --> 00:05:37.360]   researcher, developer, educator, and an entrepreneur.
[00:05:37.360 --> 00:05:41.840]   Jeremy was the founding CEO of Enlytic,
[00:05:41.840 --> 00:05:43.040]   which was the first company
[00:05:43.040 --> 00:05:44.960]   to apply deep learning to medicine
[00:05:44.960 --> 00:05:46.720]   and was selected as one of the world's
[00:05:46.720 --> 00:05:49.440]   top 50 smartest companies by MIT Tech Review
[00:05:49.440 --> 00:05:50.480]   for two years in a row.
[00:05:50.480 --> 00:05:53.600]   He was the president and chief scientist
[00:05:53.600 --> 00:05:57.040]   of data science platform that we all love today, Kaggle.
[00:05:57.040 --> 00:05:58.160]   And he was top ranked.
[00:05:58.160 --> 00:06:00.320]   He was ranked number one for two years in a row
[00:06:00.320 --> 00:06:04.400]   when he was doing and working with Kaggle.
[00:06:04.400 --> 00:06:06.560]   And he was also the founding CEO
[00:06:06.560 --> 00:06:09.040]   of two very successful Australian startups,
[00:06:09.040 --> 00:06:11.520]   Fastmail and Optimal Decisions Group.
[00:06:11.520 --> 00:06:13.360]   And before that, he spent eight years
[00:06:13.360 --> 00:06:15.600]   in management consulting and McKinsey & Co.
[00:06:15.600 --> 00:06:16.400]   and AP & Co.
[00:06:16.400 --> 00:06:20.880]   Jeremy has had life, not just me personally,
[00:06:20.880 --> 00:06:22.320]   but many others that I know,
[00:06:22.320 --> 00:06:24.960]   he's had life-changing impact on my life
[00:06:24.960 --> 00:06:26.960]   and various other lives to the work that he's done.
[00:06:26.960 --> 00:06:30.080]   So everybody, please welcome Jeremy.
[00:06:30.080 --> 00:06:33.280]   And thanks, Jeremy, for joining us.
[00:06:33.280 --> 00:06:34.880]   - Okay, hi, everybody.
[00:06:34.880 --> 00:06:38.960]   So as Aman said,
[00:06:40.320 --> 00:06:45.680]   this study group is about this book,
[00:06:45.680 --> 00:06:48.320]   "Deep Learning for Coders with Fast.ai and PyTorch."
[00:06:48.320 --> 00:06:51.280]   As Aman said, it's available both
[00:06:51.280 --> 00:06:57.280]   as a actual paper book or as a Kindle book
[00:06:57.280 --> 00:07:02.240]   or as a series of Jupyter notebooks on GitHub.
[00:07:02.240 --> 00:07:05.600]   They're actually identical books.
[00:07:05.600 --> 00:07:09.680]   So you can happily switch from one to the other.
[00:07:10.320 --> 00:07:15.200]   So the content is exactly the same.
[00:07:15.200 --> 00:07:16.800]   So if you're using the free version,
[00:07:16.800 --> 00:07:18.800]   you're not missing out on anything
[00:07:18.800 --> 00:07:22.320]   other than some, you know,
[00:07:22.320 --> 00:07:25.200]   nice formatting and indexes and stuff like that.
[00:07:25.200 --> 00:07:29.200]   Even if you're working through the paper book,
[00:07:29.200 --> 00:07:32.320]   we highly recommend that you also have the notebooks open
[00:07:32.320 --> 00:07:34.720]   because this course is really designed around
[00:07:34.720 --> 00:07:39.040]   experimenting and playing with code yourself.
[00:07:39.040 --> 00:07:47.680]   So I'm just going to talk a little bit about
[00:07:47.680 --> 00:07:52.960]   some of the things that people have found
[00:07:52.960 --> 00:07:56.080]   have helped make them be successful in this course.
[00:07:56.080 --> 00:07:59.600]   Hundreds of thousands of people
[00:07:59.600 --> 00:08:01.040]   over the last four or five years
[00:08:01.040 --> 00:08:04.800]   have now attempted the Fast.ai course.
[00:08:06.240 --> 00:08:09.200]   We create a new version most years.
[00:08:09.200 --> 00:08:13.600]   The, I think, we're up to version 4 at the moment.
[00:08:13.600 --> 00:08:18.320]   But to be honest, when we look at our YouTube analytics,
[00:08:18.320 --> 00:08:19.600]   most people don't stick with it.
[00:08:19.600 --> 00:08:23.920]   Most people do the first lesson or two and then stop.
[00:08:23.920 --> 00:08:27.360]   That's not necessarily a problem.
[00:08:27.360 --> 00:08:31.920]   If your goal is just to get a kind of vague idea
[00:08:31.920 --> 00:08:33.840]   of what deep learning is and what it can do,
[00:08:34.560 --> 00:08:37.040]   the first lesson or two is actually a pretty good way to do that.
[00:08:37.040 --> 00:08:41.760]   But if you're coming here today thinking,
[00:08:41.760 --> 00:08:47.680]   "I want to go through the entire book or 20 of them,"
[00:08:47.680 --> 00:08:53.520]   then you, you know, recognize that you're making
[00:08:53.520 --> 00:08:57.440]   a commitment to yourself that most people actually do not keep.
[00:08:57.440 --> 00:08:59.760]   And so try to figure out how you're going to be somebody
[00:08:59.760 --> 00:09:00.880]   who keeps that commitment.
[00:09:03.120 --> 00:09:04.640]   There's a huge difference, I find,
[00:09:04.640 --> 00:09:08.880]   between people who finish the book and those who don't.
[00:09:08.880 --> 00:09:12.560]   A lot of people get distracted on the journey and,
[00:09:12.560 --> 00:09:16.800]   which is fine, but just make sure you come back to it.
[00:09:16.800 --> 00:09:19.600]   So the fact that Aman has started this group
[00:09:19.600 --> 00:09:21.360]   is a great way to make sure that you at least,
[00:09:21.360 --> 00:09:23.920]   you know, to commit to yourself
[00:09:23.920 --> 00:09:25.040]   that you've got to turn up every week.
[00:09:25.040 --> 00:09:28.560]   And one of the challenges is that over the next 20 weeks,
[00:09:28.560 --> 00:09:32.720]   at some point, you'll probably get a cold.
[00:09:33.040 --> 00:09:36.160]   You know, or your daughter will break her leg,
[00:09:36.160 --> 00:09:38.960]   or you'll have a really busy period at work,
[00:09:38.960 --> 00:09:39.760]   or something will happen.
[00:09:39.760 --> 00:09:44.160]   And one of the main reasons that people fail
[00:09:44.160 --> 00:09:46.960]   to keep the commitments they make to themselves
[00:09:46.960 --> 00:09:49.840]   is that something comes along and distracts them.
[00:09:49.840 --> 00:09:55.360]   And that can be quite, you know, upsetting to realize
[00:09:55.360 --> 00:09:58.080]   that something has gotten in the way.
[00:09:58.080 --> 00:10:00.880]   The key thing is just to be easy on yourself
[00:10:00.880 --> 00:10:02.320]   and come back and keep going anyway.
[00:10:02.880 --> 00:10:05.280]   So if you miss a couple of weeks because of something,
[00:10:05.280 --> 00:10:06.160]   no problem.
[00:10:06.160 --> 00:10:08.800]   Just make sure that you come back
[00:10:08.800 --> 00:10:11.360]   and keep working through it.
[00:10:11.360 --> 00:10:13.120]   And that would be obviously much better
[00:10:13.120 --> 00:10:15.600]   than giving up and never coming back.
[00:10:15.600 --> 00:10:19.280]   This is what the GitHub repo looks like.
[00:10:19.280 --> 00:10:23.600]   Each chapter of the book is one notebook,
[00:10:23.600 --> 00:10:25.440]   and they're in order of the numbers here.
[00:10:25.440 --> 00:10:27.920]   So we actually built something called Fastdoc
[00:10:27.920 --> 00:10:30.240]   that automatically converts Jupyter notebooks
[00:10:30.240 --> 00:10:34.000]   into a book.
[00:10:34.000 --> 00:10:35.760]   So that's why you can be sure that the book
[00:10:35.760 --> 00:10:37.280]   and the notebooks are identical.
[00:10:37.280 --> 00:10:44.400]   As well as the book, both the free
[00:10:44.400 --> 00:10:46.640]   and the O'Reilly versions,
[00:10:46.640 --> 00:10:49.440]   there's also an online course.
[00:10:49.440 --> 00:10:54.000]   That course is available at course.fast.ai.
[00:11:00.160 --> 00:11:03.120]   And what you'll find is that there's a section
[00:11:03.120 --> 00:11:05.680]   here of lessons, eight lessons.
[00:11:05.680 --> 00:11:08.880]   And those eight lessons cover approximately
[00:11:08.880 --> 00:11:10.160]   the first half of the book.
[00:11:10.160 --> 00:11:13.680]   So it's often people learn best
[00:11:13.680 --> 00:11:16.160]   when they have kind of multiple modes
[00:11:16.160 --> 00:11:17.200]   of learning going on.
[00:11:17.200 --> 00:11:21.040]   So I would strongly suggest that in addition
[00:11:21.040 --> 00:11:23.600]   to reading the chapters, that you also look
[00:11:23.600 --> 00:11:25.920]   at the videos, at least do it for the first couple,
[00:11:25.920 --> 00:11:28.000]   and see if you find that helpful.
[00:11:28.000 --> 00:11:31.520]   They do have the same information.
[00:11:31.520 --> 00:11:33.200]   On the whole, the book will probably have
[00:11:33.200 --> 00:11:34.560]   a little bit more information,
[00:11:34.560 --> 00:11:37.200]   but they're presented in somewhat different ways,
[00:11:37.200 --> 00:11:39.440]   and it might help your brain to take it in,
[00:11:39.440 --> 00:11:41.360]   to see it coming in through different modalities.
[00:11:41.360 --> 00:11:53.840]   So this is from a podcast from Sanyam Bhutani,
[00:11:53.840 --> 00:11:57.440]   who interviewed Christine McClavey-Payne.
[00:11:57.440 --> 00:12:01.360]   Christine is one of our terrific alumni
[00:12:01.360 --> 00:12:02.960]   who have gone on and told us about
[00:12:02.960 --> 00:12:04.240]   what she's been up to.
[00:12:04.240 --> 00:12:08.640]   And after a lot of hard work,
[00:12:08.640 --> 00:12:10.560]   and one of the things she did was completing
[00:12:10.560 --> 00:12:13.040]   both parts one and two of the fast.ai course,
[00:12:13.040 --> 00:12:17.360]   she was selected as a resident by OpenAI.
[00:12:17.360 --> 00:12:21.200]   And she went on to become a full-time
[00:12:21.200 --> 00:12:22.880]   deep learning researcher at OpenAI.
[00:12:22.880 --> 00:12:26.080]   And she mentions here that one of the most
[00:12:26.080 --> 00:12:28.880]   useful pieces of advice that she got
[00:12:28.880 --> 00:12:30.160]   was something I told her,
[00:12:30.160 --> 00:12:33.040]   which is to try to create at least
[00:12:33.040 --> 00:12:34.240]   one really great project.
[00:12:34.240 --> 00:12:38.960]   It's great to try lots of things,
[00:12:38.960 --> 00:12:42.640]   and you should try to make sure that
[00:12:42.640 --> 00:12:46.400]   every chapter of the book we come across,
[00:12:46.400 --> 00:12:50.480]   you create something, create some kind of project.
[00:12:50.480 --> 00:12:53.600]   However small or silly it is,
[00:12:53.600 --> 00:12:54.960]   or maybe it's just a direct copy
[00:12:54.960 --> 00:12:56.000]   of something else you found.
[00:12:56.000 --> 00:13:00.320]   But I suggest you also start to try to
[00:13:00.320 --> 00:13:04.560]   polish off something really well.
[00:13:04.560 --> 00:13:06.320]   And so polishing off something really well
[00:13:06.320 --> 00:13:10.240]   means to create really good documentation about it,
[00:13:10.240 --> 00:13:12.400]   really nice interface for it,
[00:13:12.400 --> 00:13:15.360]   deal with all those little bugs,
[00:13:15.360 --> 00:13:17.440]   make it as good as you can get it.
[00:13:17.440 --> 00:13:18.960]   Because it's in the process of
[00:13:18.960 --> 00:13:20.480]   making something really great,
[00:13:20.480 --> 00:13:22.960]   that, well, there's a couple of benefits.
[00:13:22.960 --> 00:13:24.960]   The first is that's the thing that makes you
[00:13:24.960 --> 00:13:26.320]   have to deeply understand
[00:13:26.320 --> 00:13:27.440]   what it is you're working with.
[00:13:27.440 --> 00:13:30.640]   So you can make all those little things just so.
[00:13:30.640 --> 00:13:32.880]   And it's also the thing that's going to
[00:13:32.880 --> 00:13:34.320]   make the biggest difference to your
[00:13:34.320 --> 00:13:37.520]   opportunities on the job circuit,
[00:13:37.520 --> 00:13:39.520]   because it's something that will be
[00:13:39.520 --> 00:13:41.040]   at the heart of your portfolio.
[00:13:41.040 --> 00:13:42.880]   It's kind of your capstone project.
[00:13:42.880 --> 00:13:46.640]   So I suggest that you also commit to yourself
[00:13:46.640 --> 00:13:49.920]   at this initial point that you are going to,
[00:13:52.000 --> 00:13:53.120]   during the next 20 weeks,
[00:13:53.120 --> 00:13:59.280]   work towards creating and really finishing a project.
[00:13:59.280 --> 00:14:06.880]   One of the things that's really, really important
[00:14:06.880 --> 00:14:09.840]   for making a success of Fastbook
[00:14:09.840 --> 00:14:12.240]   is being pretty good at coding.
[00:14:12.240 --> 00:14:17.280]   And specifically pretty good at Python coding.
[00:14:17.280 --> 00:14:20.000]   Even if you haven't coded in Python before,
[00:14:20.000 --> 00:14:21.520]   but you've coded in another language,
[00:14:21.520 --> 00:14:22.640]   a reasonable amount,
[00:14:22.640 --> 00:14:25.280]   you'll find Python pretty easy to get going with.
[00:14:25.280 --> 00:14:30.720]   But if you don't feel super comfortable with coding,
[00:14:30.720 --> 00:14:33.120]   a good place to start would be Harvard CS50,
[00:14:33.120 --> 00:14:35.760]   which is a free online course.
[00:14:35.760 --> 00:14:40.320]   It's definitely going to make Fastbook
[00:14:40.320 --> 00:14:42.080]   much more intense for you than it would be
[00:14:42.080 --> 00:14:44.240]   for somebody who already is comfortable coding.
[00:14:44.240 --> 00:14:48.240]   But it is possible if you really invest hard.
[00:14:49.600 --> 00:14:54.480]   It is possible to kind of pick up coding
[00:14:54.480 --> 00:14:55.680]   as you go through the book.
[00:14:55.680 --> 00:15:00.160]   But yeah, be ready to really invest a lot of time
[00:15:00.160 --> 00:15:02.800]   and use other resources.
[00:15:02.800 --> 00:15:04.480]   So CS50 is a good place to start.
[00:15:04.480 --> 00:15:12.880]   Radakos Marski, who I'm about to tell you more about,
[00:15:12.880 --> 00:15:17.600]   has this concept of a four-legged table
[00:15:17.600 --> 00:15:19.040]   of the things you'll need to know
[00:15:19.040 --> 00:15:21.120]   to get through Fastbook well.
[00:15:21.120 --> 00:15:23.920]   And they are a good understanding of code concepts,
[00:15:23.920 --> 00:15:26.640]   good understanding of how to use your editor,
[00:15:26.640 --> 00:15:28.880]   a good understanding of Git,
[00:15:28.880 --> 00:15:31.680]   and a good understanding of the whole SSH
[00:15:31.680 --> 00:15:32.640]   and Linux environment.
[00:15:32.640 --> 00:15:35.680]   These are things which,
[00:15:35.680 --> 00:15:38.640]   even if you studied computer science,
[00:15:38.640 --> 00:15:42.000]   you may not have ever really learned very well.
[00:15:42.000 --> 00:15:44.560]   If that's you,
[00:15:45.520 --> 00:15:47.920]   then the MIT course called
[00:15:47.920 --> 00:15:50.560]   The Missing Semester of Your CS Education
[00:15:50.560 --> 00:15:51.760]   would be a great place to go
[00:15:51.760 --> 00:15:54.480]   because it's going to teach you
[00:15:54.480 --> 00:15:57.120]   about these tools of the trade.
[00:15:57.120 --> 00:16:03.600]   And just like a builder
[00:16:03.600 --> 00:16:05.200]   is going to want to be very familiar
[00:16:05.200 --> 00:16:07.920]   with how to use a drill and a hammer and a level
[00:16:07.920 --> 00:16:09.440]   and so forth,
[00:16:09.440 --> 00:16:13.440]   as a builder of code,
[00:16:13.440 --> 00:16:15.280]   because that's the thing we use to create models,
[00:16:15.600 --> 00:16:18.880]   you're going to need to be really familiar with your tools.
[00:16:18.880 --> 00:16:22.240]   And I find nearly everybody I know
[00:16:22.240 --> 00:16:28.000]   who's very good at applied deep learning,
[00:16:28.000 --> 00:16:29.360]   when I watch them work,
[00:16:29.360 --> 00:16:31.520]   they zip through their editor really quickly.
[00:16:31.520 --> 00:16:33.920]   They are good at using their version control.
[00:16:33.920 --> 00:16:36.080]   They can SSH into a Linux box
[00:16:36.080 --> 00:16:40.160]   and zip through looking at files, stuff like that.
[00:16:40.160 --> 00:16:44.240]   So that is something definitely worth investing time in,
[00:16:44.240 --> 00:16:46.400]   and it'll pay back many times over
[00:16:46.400 --> 00:16:47.520]   through the rest of your career.
[00:16:47.520 --> 00:16:55.840]   So what do you do with a chapter
[00:16:55.840 --> 00:16:57.840]   or a lesson of the course?
[00:16:57.840 --> 00:17:00.560]   So you watch the lecture
[00:17:00.560 --> 00:17:02.400]   or read the chapter of the book or both.
[00:17:02.400 --> 00:17:05.440]   And then you just go in
[00:17:05.440 --> 00:17:08.000]   and open up the notebook
[00:17:08.000 --> 00:17:10.160]   and run it,
[00:17:10.160 --> 00:17:11.840]   execute each cell of that notebook.
[00:17:13.520 --> 00:17:15.200]   And then as you run it,
[00:17:15.200 --> 00:17:17.040]   try to ask yourself some questions
[00:17:17.040 --> 00:17:21.680]   around what would happen if.
[00:17:21.680 --> 00:17:27.120]   So try and change some of those lines of code in the notebook,
[00:17:27.120 --> 00:17:28.240]   just in small ways,
[00:17:28.240 --> 00:17:35.600]   to try to kind of get a sense of what if.
[00:17:35.600 --> 00:17:38.320]   And the more you can experiment, the better,
[00:17:38.320 --> 00:17:40.640]   particularly if your experiments fail.
[00:17:40.640 --> 00:17:42.960]   If they give you a syntax error,
[00:17:43.680 --> 00:17:48.080]   or they give you a zero result or an all black picture,
[00:17:48.080 --> 00:17:49.680]   these are all really useful things
[00:17:49.680 --> 00:17:51.520]   because they tell you about things that
[00:17:51.520 --> 00:17:55.920]   your understanding of how you thought things work
[00:17:55.920 --> 00:17:57.200]   wasn't quite how things worked.
[00:17:57.200 --> 00:17:59.120]   And then debugging is a really great way
[00:17:59.120 --> 00:18:00.880]   to learn more about what's really going on.
[00:18:00.880 --> 00:18:07.280]   So then try to reproduce
[00:18:07.280 --> 00:18:10.160]   as much of the notebook as you can
[00:18:12.400 --> 00:18:13.040]   from scratch.
[00:18:13.040 --> 00:18:15.840]   That's quite challenging to do,
[00:18:15.840 --> 00:18:19.120]   particularly if you've only read the chapter once
[00:18:19.120 --> 00:18:20.960]   or watched the lecture once.
[00:18:20.960 --> 00:18:24.480]   So expect to be popping back and forth
[00:18:24.480 --> 00:18:26.720]   between the book and your screen.
[00:18:26.720 --> 00:18:29.360]   But try to actually type it in yourself.
[00:18:29.360 --> 00:18:31.120]   Try not to peek too much.
[00:18:31.120 --> 00:18:32.720]   You know, try to really think about what it is
[00:18:32.720 --> 00:18:34.000]   that you're writing and why
[00:18:34.000 --> 00:18:37.360]   so that you can actually create your own version
[00:18:37.360 --> 00:18:40.160]   of the notebook, or at least the major parts of it.
[00:18:41.440 --> 00:18:43.200]   So where the rubber really hits the road
[00:18:43.200 --> 00:18:47.040]   is then to repeat the entire process
[00:18:47.040 --> 00:18:51.760]   that was in the chapter on a different dataset.
[00:18:51.760 --> 00:18:54.800]   And that can be a dataset that you download yourself,
[00:18:54.800 --> 00:18:59.600]   or it could be a, sorry, a dataset that you curate yourself,
[00:18:59.600 --> 00:19:01.680]   or it could be a dataset that's pre-existing
[00:19:01.680 --> 00:19:02.400]   that you download.
[00:19:02.400 --> 00:19:06.640]   And you'll find there's just going to be
[00:19:06.640 --> 00:19:10.640]   a bunch of little differences in the process.
[00:19:10.640 --> 00:19:12.880]   And so it's in that process that you're going to
[00:19:12.880 --> 00:19:15.760]   really test your understanding of what you learned.
[00:19:15.760 --> 00:19:24.400]   So I mentioned I'd say more about Radek Osmolsky,
[00:19:24.400 --> 00:19:26.400]   and specifically I'm going to mention his book.
[00:19:26.400 --> 00:19:31.360]   So Radek is a student of Fast.ai
[00:19:31.360 --> 00:19:34.560]   who has recently published this book called Meta-Learning,
[00:19:36.480 --> 00:19:42.240]   which, oh, my keyboard is out of batteries.
[00:19:42.240 --> 00:19:43.200]   Let me try over here.
[00:19:43.200 --> 00:19:45.140]   Yeah.
[00:19:45.140 --> 00:19:48.160]   Radek, Meta, oh, there it is.
[00:19:48.160 --> 00:19:53.040]   So you find it here, Gumroad.
[00:19:53.040 --> 00:19:54.080]   I can pop that in the chat.
[00:19:54.080 --> 00:19:58.080]   Chat, chat, chat.
[00:19:58.080 --> 00:20:00.340]   Yeah.
[00:20:06.320 --> 00:20:07.120]   And so Radek,
[00:20:07.120 --> 00:20:15.760]   somebody who started out with not knowing how to code
[00:20:15.760 --> 00:20:20.560]   and not very happy in his job,
[00:20:20.560 --> 00:20:25.200]   and decided he, yeah, wanted to do AI.
[00:20:25.200 --> 00:20:30.160]   And he's been fantastically successful at that.
[00:20:30.160 --> 00:20:32.000]   He's actually a Kaggle competition winner,
[00:20:32.000 --> 00:20:35.360]   which makes him one of the top handful of people in the world.
[00:20:35.920 --> 00:20:42.880]   And he has had a couple of extremely exclusive jobs in AI,
[00:20:42.880 --> 00:20:46.240]   including currently he is trying to decode animal speech,
[00:20:46.240 --> 00:20:47.200]   which is quite amazing.
[00:20:47.200 --> 00:20:53.200]   And so Radek's been kind enough to write down his learnings
[00:20:53.200 --> 00:20:54.400]   along the way.
[00:20:54.400 --> 00:20:59.360]   And I already mentioned some of those learnings
[00:20:59.360 --> 00:21:00.800]   in the four-legged table bit.
[00:21:01.600 --> 00:21:07.760]   But for more, check out this lesson zero,
[00:21:07.760 --> 00:21:10.000]   which I'll pop in the chat.
[00:21:10.000 --> 00:21:14.400]   It's not the chat.
[00:21:14.400 --> 00:21:15.200]   That's the chat.
[00:21:15.200 --> 00:21:17.520]   There we go.
[00:21:17.520 --> 00:21:20.400]   Which includes some of the slides.
[00:21:20.400 --> 00:21:23.440]   Today I'm giving actually from that lesson zero,
[00:21:23.440 --> 00:21:24.880]   but there's a bit more information,
[00:21:24.880 --> 00:21:26.880]   particularly from this book.
[00:21:26.880 --> 00:21:31.120]   One of the things I like in his book
[00:21:31.120 --> 00:21:34.800]   is he describes his failed attempts at doing fast AI,
[00:21:34.800 --> 00:21:39.600]   which basically involved accidentally listening
[00:21:39.600 --> 00:21:42.320]   to all those gatekeepers who claim that
[00:21:42.320 --> 00:21:44.960]   you have to start with the math foundations,
[00:21:44.960 --> 00:21:48.880]   calculus, linear algebra, probability theory.
[00:21:48.880 --> 00:21:52.320]   So Radek spent time learning calculus,
[00:21:52.320 --> 00:21:54.160]   which is very interesting,
[00:21:54.160 --> 00:21:57.680]   but then discovered that some of the advanced calculus
[00:21:57.680 --> 00:22:00.000]   required understanding construction of real numbers.
[00:22:00.960 --> 00:22:02.960]   So started reading a book about that,
[00:22:02.960 --> 00:22:07.920]   then discovered that actually that was for real analysis.
[00:22:07.920 --> 00:22:09.680]   And then to understand real analysis properly,
[00:22:09.680 --> 00:22:12.240]   you have to actually deeply understand set theory,
[00:22:12.240 --> 00:22:13.360]   and so on and so forth.
[00:22:13.360 --> 00:22:16.640]   And this is a really common thing we hear,
[00:22:16.640 --> 00:22:19.120]   is that people try to learn to build
[00:22:19.120 --> 00:22:20.480]   useful deep learning models,
[00:22:20.480 --> 00:22:23.680]   but all they actually do is they spend years
[00:22:23.680 --> 00:22:25.360]   learning about theory.
[00:22:27.360 --> 00:22:31.440]   Theory can be somewhat useful
[00:22:31.440 --> 00:22:33.600]   if you learn the right theory at the right time,
[00:22:33.600 --> 00:22:38.880]   but the right time is not before your first lesson.
[00:22:38.880 --> 00:22:41.520]   The right time to start training deep learning models
[00:22:41.520 --> 00:22:43.680]   is when you start learning,
[00:22:43.680 --> 00:22:48.880]   and then you can learn about theory
[00:22:48.880 --> 00:22:51.920]   as you start understanding better
[00:22:51.920 --> 00:22:56.320]   what's actually required to build effective models.
[00:22:56.320 --> 00:22:58.320]   And so this is the way fast.ai does it.
[00:22:58.320 --> 00:23:01.920]   At first, if you're used to a bottom-up
[00:23:01.920 --> 00:23:03.360]   academic approach of learning,
[00:23:03.360 --> 00:23:05.680]   you may even find it a little frustrating
[00:23:05.680 --> 00:23:08.640]   that you're using things
[00:23:08.640 --> 00:23:10.160]   that have not been fully explained.
[00:23:10.160 --> 00:23:11.920]   But if you think about it,
[00:23:11.920 --> 00:23:15.360]   if you use Microsoft Word, for example,
[00:23:15.360 --> 00:23:16.640]   or Google Docs or whatever,
[00:23:16.640 --> 00:23:19.040]   and you start typing things into a computer,
[00:23:19.040 --> 00:23:21.120]   do you really know how every one of those pixels
[00:23:21.120 --> 00:23:22.320]   is being turned on?
[00:23:22.320 --> 00:23:25.280]   Do you fully understand what's happening inside your CPU?
[00:23:25.280 --> 00:23:26.720]   Do you really understand how things
[00:23:26.720 --> 00:23:28.400]   are moving over your PCI bus?
[00:23:28.400 --> 00:23:32.000]   Do you fully understand all of the messages
[00:23:32.000 --> 00:23:34.320]   in your operating systems, messaging system?
[00:23:34.320 --> 00:23:36.880]   Probably not, right?
[00:23:36.880 --> 00:23:38.640]   It's fine to use tools
[00:23:38.640 --> 00:23:42.240]   and then to gradually dig deeper and deeper into them.
[00:23:42.240 --> 00:23:44.000]   If you finish the book,
[00:23:44.000 --> 00:23:47.520]   you will end up rewriting
[00:23:47.520 --> 00:23:51.120]   an entire ResNet from scratch,
[00:23:51.120 --> 00:23:53.760]   BatchNorm from scratch,
[00:23:54.480 --> 00:23:56.960]   a data loader from scratch,
[00:23:56.960 --> 00:23:59.920]   stochastic gradient descent from scratch.
[00:23:59.920 --> 00:24:01.280]   And you actually start doing it pretty soon.
[00:24:01.280 --> 00:24:02.480]   So you'll actually write your own
[00:24:02.480 --> 00:24:05.360]   stochastic gradient descent optimizer in chapter four.
[00:24:05.360 --> 00:24:08.240]   So, you know, be patient,
[00:24:08.240 --> 00:24:10.080]   but really,
[00:24:10.080 --> 00:24:14.480]   you know, really try to focus on
[00:24:14.480 --> 00:24:17.360]   actually building useful things as soon as you can,
[00:24:17.360 --> 00:24:19.920]   because digging into theory is just a great way
[00:24:19.920 --> 00:24:21.280]   of kind of procrastinating,
[00:24:21.280 --> 00:24:22.480]   actually doing deep learning.
[00:24:22.800 --> 00:24:29.680]   So this is from Redick's book.
[00:24:29.680 --> 00:24:33.600]   As I mentioned, you really need to
[00:24:33.600 --> 00:24:36.480]   become a pretty good coder
[00:24:36.480 --> 00:24:39.280]   to become a pretty good deep learning practitioner.
[00:24:39.280 --> 00:24:41.600]   And the only way to become a good coder
[00:24:41.600 --> 00:24:45.040]   is to read and write code.
[00:24:45.040 --> 00:24:48.960]   So I spend personally many hours every day
[00:24:48.960 --> 00:24:51.520]   reading and writing code.
[00:24:52.320 --> 00:24:55.360]   If you're going through a whole day
[00:24:55.360 --> 00:24:58.400]   without reading and writing code,
[00:24:58.400 --> 00:25:01.120]   then you're not really spending that day
[00:25:01.120 --> 00:25:04.240]   actually practicing your craft of becoming a better coder.
[00:25:04.240 --> 00:25:08.080]   And the more you can read code in different styles
[00:25:08.080 --> 00:25:09.440]   to what you're used to,
[00:25:09.440 --> 00:25:11.760]   and write code using different libraries
[00:25:11.760 --> 00:25:13.760]   to what you've tried before and so forth,
[00:25:13.760 --> 00:25:17.280]   the more that's the deliberate practice,
[00:25:17.280 --> 00:25:20.160]   which allows people to achieve mastery.
[00:25:20.800 --> 00:25:22.800]   One of the most important things
[00:25:22.800 --> 00:25:24.960]   that you're going to be talking about in chapter one
[00:25:24.960 --> 00:25:26.640]   is creating a validation set.
[00:25:26.640 --> 00:25:29.920]   The difference between,
[00:25:29.920 --> 00:25:34.240]   our key difference between normal programming
[00:25:34.240 --> 00:25:37.280]   and machine learning, including deep learning,
[00:25:37.280 --> 00:25:39.200]   is that in machine learning,
[00:25:39.200 --> 00:25:43.520]   it's all about having your computer
[00:25:43.520 --> 00:25:46.480]   be able to answer questions
[00:25:46.480 --> 00:25:49.600]   that are different to the input data
[00:25:49.600 --> 00:25:50.560]   that you taught it with.
[00:25:50.560 --> 00:25:54.400]   You need to know that it can handle data
[00:25:54.400 --> 00:25:56.400]   that it's never seen before.
[00:25:56.400 --> 00:25:58.560]   And the only way to do that
[00:25:58.560 --> 00:26:00.400]   is with something called a validation set,
[00:26:00.400 --> 00:26:03.440]   which is a data set consisting of data
[00:26:03.440 --> 00:26:06.480]   which your model never gets to see as it's learning.
[00:26:06.480 --> 00:26:11.120]   It turns out that building a good validation set
[00:26:11.120 --> 00:26:12.560]   is deceptively tricky.
[00:26:13.520 --> 00:26:14.960]   And most people get it wrong.
[00:26:14.960 --> 00:26:18.000]   People that win Kaggle competitions
[00:26:18.000 --> 00:26:21.040]   nearly always say that one of the best skills
[00:26:21.040 --> 00:26:23.840]   is being really good at creating validation sets.
[00:26:23.840 --> 00:26:26.000]   And so you'll start reading
[00:26:26.000 --> 00:26:27.600]   about how to create validation sets
[00:26:27.600 --> 00:26:29.120]   right from lesson one.
[00:26:29.120 --> 00:26:30.640]   And that's something you should really
[00:26:30.640 --> 00:26:33.440]   spend time thinking about.
[00:26:33.440 --> 00:26:36.240]   And there's a great blog post here
[00:26:36.240 --> 00:26:38.800]   from my co-founder, Rachel Thomas,
[00:26:38.800 --> 00:26:41.360]   on how and why to create a good validation set.
[00:26:41.360 --> 00:26:44.640]   Okay, so that's the end of my little presentation
[00:26:44.640 --> 00:26:47.440]   of some tips about what Fastbook is
[00:26:47.440 --> 00:26:49.280]   and things that might help you succeed
[00:26:49.280 --> 00:26:50.800]   in your 20-week journey.
[00:26:50.800 --> 00:26:52.320]   So good luck, everybody.
[00:26:52.320 --> 00:27:03.680]   - I just realized I was in mute.
[00:27:03.680 --> 00:27:06.320]   Thank you for joining us today.
[00:27:06.320 --> 00:27:07.760]   I'm sure you've learned a lot.
[00:27:07.760 --> 00:27:08.800]   I'm sure you've learned a lot.
[00:27:08.800 --> 00:27:10.080]   I just realized I was in mute.
[00:27:10.080 --> 00:27:11.760]   Thank you, Jeremy.
[00:27:11.760 --> 00:27:15.440]   I think I want to say as I've personally benefited
[00:27:15.440 --> 00:27:18.640]   from the learnings that Jeremy has mentioned,
[00:27:18.640 --> 00:27:20.560]   for example, committing to the 20 weeks.
[00:27:20.560 --> 00:27:22.640]   I think that that's really important
[00:27:22.640 --> 00:27:25.280]   for us as a group to commit to 20 weeks.
[00:27:25.280 --> 00:27:28.080]   Lots of projects, coding, failed experiments,
[00:27:28.080 --> 00:27:31.680]   even about we go deeper gradually
[00:27:31.680 --> 00:27:32.720]   and read and write code.
[00:27:32.720 --> 00:27:34.240]   So these are the main learnings
[00:27:34.240 --> 00:27:37.120]   that have actually built the foundations on top of.
[00:27:38.160 --> 00:27:41.680]   And in this section, I just want to quickly go through
[00:27:41.680 --> 00:27:44.880]   with everyone on what the next 20 weeks are going to look like
[00:27:44.880 --> 00:27:45.760]   and how we're going to have,
[00:27:45.760 --> 00:27:49.600]   how is the every session of Fastbook reading
[00:27:49.600 --> 00:27:51.840]   going to look like for the next 20 weeks.
[00:27:51.840 --> 00:28:01.840]   So with Fastbook, there's two versions of Fastbook
[00:28:01.840 --> 00:28:03.920]   inside the repo.
[00:28:03.920 --> 00:28:07.040]   So if I go into the repo, there's this whole Fastbook
[00:28:07.040 --> 00:28:08.960]   that Jeremy mentioned are the 20 chapters.
[00:28:08.960 --> 00:28:11.520]   But there's also the clean version.
[00:28:11.520 --> 00:28:13.360]   So if we go into the clean version,
[00:28:13.360 --> 00:28:15.680]   there's also a clean version.
[00:28:15.680 --> 00:28:18.320]   And the main difference between the clean version
[00:28:18.320 --> 00:28:22.560]   and the book itself is that the clean version
[00:28:22.560 --> 00:28:24.000]   just consists of code.
[00:28:24.000 --> 00:28:27.600]   So on the left, we have this is the actual book
[00:28:27.600 --> 00:28:29.200]   and the actual Jupyter Notebooks.
[00:28:29.200 --> 00:28:31.120]   These are with prose.
[00:28:31.120 --> 00:28:33.760]   And on the right, we have the clean version,
[00:28:33.760 --> 00:28:35.040]   which is without prose.
[00:28:35.040 --> 00:28:38.960]   So you can see how going through the whole chapter,
[00:28:38.960 --> 00:28:41.920]   if we do decide, because we want to also be conscious
[00:28:41.920 --> 00:28:44.240]   of time every week, and we want to commit to finishing,
[00:28:44.240 --> 00:28:47.440]   we want to commit to finishing these chapters.
[00:28:47.440 --> 00:28:51.520]   So if we go through the whole chapter,
[00:28:51.520 --> 00:28:55.600]   there's a lot of content for us to cover every week.
[00:28:55.600 --> 00:28:59.920]   And something that we're going to do as a group,
[00:28:59.920 --> 00:29:02.080]   we're going to be sitting in the middle.
[00:29:02.080 --> 00:29:04.880]   So I'm going to personally go in every week.
[00:29:04.880 --> 00:29:09.200]   I'm going to read the every chapter every week.
[00:29:09.200 --> 00:29:12.960]   And I'm going to share, convert the with prose into
[00:29:12.960 --> 00:29:17.120]   without prose, but with explanations and examples.
[00:29:17.120 --> 00:29:19.200]   So we're going to actually be somewhere in the middle
[00:29:19.200 --> 00:29:21.360]   where there's going to be enough explanation
[00:29:21.360 --> 00:29:23.280]   for everything that's on the right.
[00:29:23.280 --> 00:29:25.120]   So you understand every bit of code.
[00:29:25.120 --> 00:29:28.320]   You'll understand all context, but it will give you enough
[00:29:28.320 --> 00:29:31.440]   and pretty much almost everything to then go back
[00:29:31.440 --> 00:29:33.600]   and read the book.
[00:29:33.600 --> 00:29:36.640]   And in case you miss out, that's going to be okay.
[00:29:36.640 --> 00:29:37.920]   And you can come back next week,
[00:29:37.920 --> 00:29:39.520]   and we can continue from there.
[00:29:39.520 --> 00:29:42.400]   But it is expected that you do go back
[00:29:42.400 --> 00:29:44.640]   and read the book to get the maximum benefit.
[00:29:44.640 --> 00:29:48.640]   Every book, every chapter in the book,
[00:29:48.640 --> 00:29:51.840]   as Jeremy mentioned, it's important to then think
[00:29:51.840 --> 00:29:53.680]   of questions when you do a chapter.
[00:29:53.680 --> 00:29:54.640]   It's important to think,
[00:29:54.640 --> 00:29:59.280]   it's important to test the understanding.
[00:30:00.000 --> 00:30:02.880]   And I really love this book for the questionnaire
[00:30:02.880 --> 00:30:04.160]   that comes at the end of it.
[00:30:04.160 --> 00:30:07.040]   So when you read a chapter, there's always a questionnaire
[00:30:07.040 --> 00:30:07.760]   towards the end.
[00:30:07.760 --> 00:30:11.520]   And as a group, we're going to be discussing every bit,
[00:30:11.520 --> 00:30:13.360]   every question.
[00:30:13.360 --> 00:30:15.600]   And we're going to be answering all the questions
[00:30:15.600 --> 00:30:18.880]   that I mentioned here gradually over week by week.
[00:30:18.880 --> 00:30:23.120]   We're going to be using the Watson Biosys Community Slack.
[00:30:23.120 --> 00:30:25.520]   So that's 1db.me/slack.
[00:30:25.520 --> 00:30:29.360]   We will send an email out to all participants.
[00:30:30.240 --> 00:30:32.080]   And we can be a part of this Slack.
[00:30:32.080 --> 00:30:34.560]   And we'll be using this to communicate with each other,
[00:30:34.560 --> 00:30:38.960]   to ask questions and general communication on projects.
[00:30:38.960 --> 00:30:42.480]   This is something I do want to share.
[00:30:42.480 --> 00:30:44.720]   This is a snippet from my journey.
[00:30:44.720 --> 00:30:50.240]   And my journey was built on top of Jeremy's learnings.
[00:30:50.240 --> 00:30:56.800]   And what Jeremy said, I followed and I followed it really well.
[00:30:56.800 --> 00:31:00.080]   And I think that has really helped me in my life.
[00:31:00.080 --> 00:31:03.920]   So for example, the one thing I'm going to say is
[00:31:03.920 --> 00:31:06.480]   we want to have interaction within us.
[00:31:06.480 --> 00:31:09.440]   We want to have a lot of interaction between us as a group.
[00:31:09.440 --> 00:31:11.040]   And I want to promote that.
[00:31:11.040 --> 00:31:13.280]   So and it doesn't have to be a big thing.
[00:31:13.280 --> 00:31:16.560]   My first ever comment on a Fast.ai forums.
[00:31:16.560 --> 00:31:21.840]   So Fast.ai forums, if I go to the forums.fast.ai,
[00:31:21.840 --> 00:31:24.560]   there's a whole multitude of--
[00:31:25.760 --> 00:31:28.240]   there's a lot of stuff and there's a lot of activity
[00:31:28.240 --> 00:31:31.680]   for deep learning practitioners who also want to learn deep learning.
[00:31:31.680 --> 00:31:34.880]   And there's lots of questions and there's lots of things.
[00:31:34.880 --> 00:31:37.040]   I really like the "share your work here" thread
[00:31:37.040 --> 00:31:42.240]   where everybody who's starting out shares a lot of projects that they're doing.
[00:31:42.240 --> 00:31:44.400]   And these don't have to be big projects.
[00:31:44.400 --> 00:31:45.760]   They can be small projects.
[00:31:45.760 --> 00:31:50.800]   So we'll be doing as part of this, we'll be talking to each other a lot.
[00:31:50.800 --> 00:31:52.880]   We'll be interacting with each other a lot.
[00:31:52.880 --> 00:31:57.440]   And I just want to mention, for example, my first ever comment was a thanks.
[00:31:57.440 --> 00:31:59.120]   And a plain simple thanks.
[00:31:59.120 --> 00:32:03.760]   But doing so and just writing something like this, like a hi or a thanks, got me going.
[00:32:03.760 --> 00:32:06.720]   It really-- I felt like I'm part of the community.
[00:32:06.720 --> 00:32:09.920]   And the next time I answered a question and straight away,
[00:32:09.920 --> 00:32:13.040]   the next thing within the first month of joining,
[00:32:13.040 --> 00:32:16.240]   I was interested in forming a study group at Sydney.
[00:32:16.240 --> 00:32:18.560]   So I really want us to think of it this way.
[00:32:18.560 --> 00:32:22.240]   And I really want us as a group to also form study groups
[00:32:22.240 --> 00:32:23.760]   based on the time zones that we're in.
[00:32:23.760 --> 00:32:27.760]   And we'll be doing that this first week before we get started next week.
[00:32:27.760 --> 00:32:35.840]   This last, the one on the right is, again, when I say I follow Jeremy's advice,
[00:32:35.840 --> 00:32:36.640]   I really did.
[00:32:36.640 --> 00:32:39.040]   And it got me to where I am today.
[00:32:39.040 --> 00:32:45.120]   So something, so this is just, this was a thread again on the Fast.ai forums in 2019.
[00:32:45.120 --> 00:32:48.160]   And I said, something that has helped me with Fast.ai
[00:32:48.160 --> 00:32:50.000]   has been to reimplement each notebook.
[00:32:50.800 --> 00:32:53.840]   Take it by the week instead of being in a rush to complete the course.
[00:32:53.840 --> 00:32:55.600]   So I really wanted to finish.
[00:32:55.600 --> 00:33:00.080]   As Jeremy mentioned, it's important that we finish and we commit to those 20 weeks.
[00:33:00.080 --> 00:33:03.440]   I take Fast.ai as a marathon and not a sprint
[00:33:03.440 --> 00:33:05.680]   and make sure that I finish and finish strong.
[00:33:05.680 --> 00:33:08.560]   And two years after, this is again in June 2019,
[00:33:08.560 --> 00:33:11.040]   and two years after, I still live by these words.
[00:33:11.040 --> 00:33:14.560]   And I'm so happy that even two years ago, I was thinking along these lines
[00:33:14.560 --> 00:33:17.760]   because two years ago, what I was doing and starting out with my journey,
[00:33:17.760 --> 00:33:21.920]   that really helped me into learning a lot of things
[00:33:21.920 --> 00:33:25.040]   like implementing ResNet from scratch.
[00:33:25.040 --> 00:33:28.640]   And starting from somebody who didn't know deep learning
[00:33:28.640 --> 00:33:32.560]   to going week by week, going deeper into the content.
[00:33:32.560 --> 00:33:36.000]   So write self-notes, do research on things that are hard to understand.
[00:33:36.000 --> 00:33:39.680]   I'm spending lots of time writing code and digging into the Fast.ai source code,
[00:33:39.680 --> 00:33:41.280]   as Jeremy also mentioned.
[00:33:41.280 --> 00:33:43.680]   We want to be spending lots of time reading and writing code.
[00:33:44.560 --> 00:33:48.080]   And one thing I should mention is, I think for people watching,
[00:33:48.080 --> 00:33:54.560]   you might imagine that people like Radhik and Aman,
[00:33:54.560 --> 00:33:59.680]   who have successfully built careers as deep learning researchers,
[00:33:59.680 --> 00:34:07.600]   are uniquely special and that you can't possibly do what they do.
[00:34:08.960 --> 00:34:15.440]   But actually, the vast, vast majority of people I've seen on the forums
[00:34:15.440 --> 00:34:20.800]   and the Discord and so forth, who do the things that Aman is talking about
[00:34:20.800 --> 00:34:25.520]   and that Radhik writes about, it's very obvious.
[00:34:25.520 --> 00:34:28.640]   I can see them doing it because you see their artifacts
[00:34:28.640 --> 00:34:31.680]   as they post on the forum, they create blog posts and so forth.
[00:34:31.680 --> 00:34:35.680]   The vast majority of people that do that today
[00:34:35.680 --> 00:34:44.400]   have significant expertise in the field and generally have jobs in the field
[00:34:44.400 --> 00:34:48.240]   or are applying deep learning in interesting ways.
[00:34:48.240 --> 00:34:52.320]   So I think in terms of your self-confidence,
[00:34:52.320 --> 00:34:58.000]   it's important to believe that you're somebody that can do this.
[00:34:58.000 --> 00:35:02.320]   But as Aman says, it does take time.
[00:35:03.040 --> 00:35:06.000]   And that means that tenacity is really important.
[00:35:06.000 --> 00:35:08.560]   Thank you, Jeremy.
[00:35:08.560 --> 00:35:12.560]   Just to add on, I did start as a quality analyst.
[00:35:12.560 --> 00:35:16.400]   Most of my job was testing and it wasn't even anything
[00:35:16.400 --> 00:35:18.160]   related to software engineering or coding.
[00:35:18.160 --> 00:35:22.240]   But thanks to the course and thanks to the week-by-week learning,
[00:35:22.240 --> 00:35:26.000]   it has really helped me understand deeper every day.
[00:35:26.000 --> 00:35:30.400]   So that's how our approach is going to be.
[00:35:31.040 --> 00:35:36.240]   But one thing I'm really excited to present is we'll also be joined
[00:35:36.240 --> 00:35:39.600]   as part of this journey, we'll be joined by Zachary Muller,
[00:35:39.600 --> 00:35:43.840]   we'll be joined by Tanishka Abraham, and we'll also be joined by Sayem.
[00:35:43.840 --> 00:35:48.400]   So they're also three people who have met through the Fast.ai forums
[00:35:48.400 --> 00:35:52.480]   and through the community, and they're also very much into Fast.ai
[00:35:52.480 --> 00:35:55.200]   and feel just as passionate about the library.
[00:35:55.200 --> 00:35:57.840]   So Zach is a machine learning engineer at Novetta.
[00:35:59.200 --> 00:36:02.560]   Fast.ai was the only course, an ML course that he ever did.
[00:36:02.560 --> 00:36:06.720]   And built on top of that, he started with a walk with Fast.ai,
[00:36:06.720 --> 00:36:09.520]   which really adds more on the Fast.ai course.
[00:36:09.520 --> 00:36:11.600]   So he started doing things with object detection
[00:36:11.600 --> 00:36:14.320]   or other things that he wanted to try.
[00:36:14.320 --> 00:36:18.560]   And Fast.ai library really enables those sort of experiments
[00:36:18.560 --> 00:36:19.520]   and those sort of projects.
[00:36:19.520 --> 00:36:22.560]   So he'll be joining us for guest lectures towards the end.
[00:36:22.560 --> 00:36:25.440]   Zach should probably be thanking his dad for this
[00:36:25.440 --> 00:36:29.200]   because he told me that he was studying marine biology
[00:36:29.200 --> 00:36:32.160]   and his dad was like, "You should do coding and you should do AI."
[00:36:32.160 --> 00:36:34.960]   And Zach was like, "Nah, that sounds stupid."
[00:36:34.960 --> 00:36:37.360]   And eventually, his dad convinced him to try it once.
[00:36:37.360 --> 00:36:39.920]   And he was like, "Oh, actually, that's kind of fun."
[00:36:39.920 --> 00:36:43.040]   I thought that was an interesting story.
[00:36:43.040 --> 00:36:44.640]   So he was going in a very different direction.
[00:36:44.640 --> 00:36:47.840]   Definitely. And then we see him today,
[00:36:47.840 --> 00:36:50.480]   you know, he's doing the Fast Debug project
[00:36:50.480 --> 00:36:52.800]   and he spent about 33 days in the forum.
[00:36:52.800 --> 00:36:54.800]   So you can see, I guess, through these examples,
[00:36:54.800 --> 00:36:58.080]   we can see that being active and being actually taking this
[00:36:58.080 --> 00:37:02.720]   and doing this seriously can help us a lot.
[00:37:02.720 --> 00:37:04.480]   Thanks, Jeremy.
[00:37:04.480 --> 00:37:07.120]   With Sayem, he's the host of the Data Science,
[00:37:07.120 --> 00:37:08.720]   Shidem Data Science podcast.
[00:37:08.720 --> 00:37:12.400]   And he's interviewed hundreds of practitioners
[00:37:12.400 --> 00:37:14.000]   and he's also interviewed Jeremy.
[00:37:14.000 --> 00:37:17.120]   So do feel free to check it out.
[00:37:17.120 --> 00:37:20.640]   He's also an ML engineer and AI content creator at H2AI.
[00:37:20.640 --> 00:37:24.640]   He's a Kaggle discussions master and he's an active blogger.
[00:37:25.200 --> 00:37:28.720]   With over 1.5 million views across various blogs.
[00:37:28.720 --> 00:37:31.680]   And he's with us today on the chat.
[00:37:31.680 --> 00:37:35.200]   And he also represents this idea of tenacity.
[00:37:35.200 --> 00:37:37.680]   He set out to, I can't remember exactly
[00:37:37.680 --> 00:37:38.800]   what the statistics were,
[00:37:38.800 --> 00:37:42.800]   but to post a certain number of podcasts every week
[00:37:42.800 --> 00:37:45.600]   for, I don't know, a year or something.
[00:37:45.600 --> 00:37:48.640]   And he totally stuck to it.
[00:37:48.640 --> 00:37:52.240]   And in the process, built a very significant audience.
[00:37:52.880 --> 00:37:54.720]   And so he's definitely somebody who,
[00:37:54.720 --> 00:37:59.200]   when he says, I'm going to do X, I know that X will be done.
[00:37:59.200 --> 00:38:04.560]   And that's really cool to see how much success he's had.
[00:38:04.560 --> 00:38:07.280]   Absolutely.
[00:38:07.280 --> 00:38:09.920]   And then we're also joined by Tanishq Ibrahim.
[00:38:09.920 --> 00:38:11.440]   He's one of our youngest,
[00:38:11.440 --> 00:38:14.400]   but he's also one of the most talented people
[00:38:14.400 --> 00:38:16.880]   that I know and I've met through the past AI forums.
[00:38:16.880 --> 00:38:19.520]   So Tanishq is only 17, sorry, 18 now.
[00:38:19.520 --> 00:38:21.280]   18 now, I think, yeah.
[00:38:21.280 --> 00:38:23.200]   Yeah, it was his birthday a day or two ago.
[00:38:23.200 --> 00:38:27.120]   He's an 18-year-old biomedical engineering PhD
[00:38:27.120 --> 00:38:28.960]   candidate at University of California.
[00:38:28.960 --> 00:38:30.880]   I believe he's in his third year of PhD.
[00:38:30.880 --> 00:38:34.560]   His journey also began, like many of us,
[00:38:34.560 --> 00:38:37.680]   by taking the Fast AI course back in 2019.
[00:38:37.680 --> 00:38:39.120]   And he's been a frequent contributor
[00:38:39.120 --> 00:38:40.400]   to the library and the forums.
[00:38:40.400 --> 00:38:43.600]   He's also a Kaggle notebooks and discussion master.
[00:38:43.600 --> 00:38:46.320]   And he's written now packages like Zach has built
[00:38:46.320 --> 00:38:47.840]   the Walk with Fast AI.
[00:38:47.840 --> 00:38:49.920]   Tanishq has also worked on the YouPit package,
[00:38:49.920 --> 00:38:51.760]   which is an image to image translation
[00:38:51.760 --> 00:38:53.280]   built using the Fast AI tools.
[00:38:53.280 --> 00:38:56.640]   He's also been a fantastic researcher, by the way,
[00:38:56.640 --> 00:38:59.680]   and actually worked with us
[00:38:59.680 --> 00:39:02.880]   on some of our medical AI research.
[00:39:02.880 --> 00:39:05.440]   Thank you.
[00:39:05.440 --> 00:39:09.440]   And I'm really excited that all of them,
[00:39:09.440 --> 00:39:11.360]   Zach, Sanyam, and Tanishq will be around
[00:39:11.360 --> 00:39:12.960]   and we'll be doing guest lectures from them
[00:39:12.960 --> 00:39:13.760]   on their projects.
[00:39:13.760 --> 00:39:15.760]   And we can hear from them on their journey.
[00:39:15.760 --> 00:39:18.480]   Thanks guys for being a part of this.
[00:39:18.480 --> 00:39:19.760]   Really, really appreciate that.
[00:39:19.760 --> 00:39:21.760]   Cool.
[00:39:21.760 --> 00:39:23.920]   Now, we're in the in conversation with Jeremy,
[00:39:23.920 --> 00:39:26.000]   which is basically me taking advantage
[00:39:26.000 --> 00:39:27.120]   of Jeremy being on the show
[00:39:27.120 --> 00:39:29.360]   because I've always had these questions to ask
[00:39:29.360 --> 00:39:30.640]   and never got the opportunity.
[00:39:30.640 --> 00:39:33.840]   Okay. Today's my day and I'm going to ask a question.
[00:39:33.840 --> 00:39:38.080]   So Jeremy, something that really amazes me
[00:39:38.080 --> 00:39:41.680]   and really it's when you see things like this
[00:39:41.680 --> 00:39:44.480]   is like inspirational and motivational
[00:39:44.480 --> 00:39:45.360]   at a different level.
[00:39:46.560 --> 00:39:48.320]   We saw a mask for all movement.
[00:39:48.320 --> 00:39:50.720]   It's active now as well.
[00:39:50.720 --> 00:39:53.040]   And we saw you begin the mask for all movement,
[00:39:53.040 --> 00:39:55.920]   which got traction from the president of Czech.
[00:39:55.920 --> 00:39:59.680]   The Czech Republic went from 100% mask usage
[00:39:59.680 --> 00:40:01.120]   from zero in 10 days.
[00:40:01.120 --> 00:40:03.920]   The mask for all movement was mentioned
[00:40:03.920 --> 00:40:07.680]   in various newspapers like CNN, New York Times, Guardian.
[00:40:07.680 --> 00:40:12.480]   Jeremy also presented the paper that he wrote
[00:40:12.480 --> 00:40:14.720]   with 19 authors and 84 references
[00:40:15.440 --> 00:40:16.960]   on the effectiveness of masks.
[00:40:16.960 --> 00:40:20.000]   And it was presented at the WHO guideline
[00:40:20.000 --> 00:40:20.800]   development group.
[00:40:20.800 --> 00:40:24.480]   And I believe Jeremy, you also worked with US senators
[00:40:24.480 --> 00:40:28.160]   and Michael Bennett and Sen Tumi.
[00:40:28.160 --> 00:40:30.800]   And most importantly, I mean, this is a project
[00:40:30.800 --> 00:40:33.120]   that helped saved a lot of lives.
[00:40:33.120 --> 00:40:37.440]   And it really, it became a trend all over the world
[00:40:37.440 --> 00:40:38.320]   to wear masks.
[00:40:38.320 --> 00:40:41.200]   And not just that, we also see Jeremy,
[00:40:41.200 --> 00:40:43.040]   like just in the past two weeks,
[00:40:43.040 --> 00:40:45.520]   something I was really amazed to see
[00:40:45.520 --> 00:40:47.680]   that apart from the fast AI
[00:40:47.680 --> 00:40:49.520]   and apart from all the work that he does
[00:40:49.520 --> 00:40:51.680]   in the open source world,
[00:40:51.680 --> 00:40:53.680]   I saw an article from Jeremy
[00:40:53.680 --> 00:40:55.760]   in the Sydney Morning Herald, which was,
[00:40:55.760 --> 00:40:59.120]   it's a race and fighting for vaccines is crucial.
[00:40:59.120 --> 00:41:02.160]   Jeremy attended the Queensland AI Hub
[00:41:02.160 --> 00:41:04.880]   and he's also involved in the practical
[00:41:04.880 --> 00:41:06.640]   with the fast AI courses running
[00:41:06.640 --> 00:41:09.680]   from 25th May to 27th July.
[00:41:09.680 --> 00:41:12.640]   And I'm also a part of this, but that's not it.
[00:41:12.640 --> 00:41:14.800]   We see Jeremy also attend,
[00:41:14.800 --> 00:41:18.320]   gave a talk at the Queensland University of Technology,
[00:41:18.320 --> 00:41:20.560]   which was only two days ago with Rachel Thomas
[00:41:20.560 --> 00:41:22.320]   who's also the co-founder of fast AI.
[00:41:22.320 --> 00:41:24.480]   Sorry, there's more.
[00:41:24.480 --> 00:41:27.520]   We also see him active on Discord
[00:41:27.520 --> 00:41:29.120]   if I'm around and asking questions.
[00:41:29.120 --> 00:41:30.880]   And this was somebody asking about,
[00:41:30.880 --> 00:41:33.040]   oh, this was a basic question.
[00:41:33.040 --> 00:41:34.400]   And sorry to point out,
[00:41:34.400 --> 00:41:36.320]   I don't wanna point out anybody on the question,
[00:41:36.320 --> 00:41:40.560]   but just, somebody was asking about PDP and set trace
[00:41:40.560 --> 00:41:42.400]   and Jeremy was there to the rescue.
[00:41:42.400 --> 00:41:44.320]   And he was there to point resources.
[00:41:44.320 --> 00:41:46.640]   He also answered many of my questions.
[00:41:46.640 --> 00:41:48.880]   And as someone, when you're beginning your journey
[00:41:48.880 --> 00:41:50.640]   and you see Jeremy answering your question,
[00:41:50.640 --> 00:41:53.840]   you're like, oh, Jeremy really found the time to do that.
[00:41:53.840 --> 00:41:58.320]   I mean, he really is around to answer these basic questions.
[00:41:58.320 --> 00:42:02.320]   And finally, there's also these various projects
[00:42:02.320 --> 00:42:03.040]   in the fast AI.
[00:42:03.040 --> 00:42:05.440]   There's like NBDev, Fast Pages, Fastbook,
[00:42:05.440 --> 00:42:08.400]   fast AI, Fast Core, and there's other projects.
[00:42:10.480 --> 00:42:12.240]   And these are just the visible ones.
[00:42:12.240 --> 00:42:14.080]   Like these are just the ones I could find
[00:42:14.080 --> 00:42:17.360]   in the past few days that I saw Jeremy has been a part of.
[00:42:17.360 --> 00:42:20.640]   And I'm sure there's other life responsibilities.
[00:42:20.640 --> 00:42:24.240]   So Jeremy, really curious on how do you find the time
[00:42:24.240 --> 00:42:27.360]   and how do you end up building such cool things
[00:42:27.360 --> 00:42:29.360]   and really interested to know.
[00:42:29.360 --> 00:42:31.840]   - Oh yeah.
[00:42:31.840 --> 00:42:37.200]   I mean, it's been a busy week, I must admit.
[00:42:37.440 --> 00:42:39.920]   Yeah, I did have a few other talks I gave as well.
[00:42:39.920 --> 00:42:42.480]   And I'm writing another article for USA Today at the moment.
[00:42:42.480 --> 00:42:52.480]   The thing is though that I spend, I'm very slow.
[00:42:52.480 --> 00:42:54.400]   Like that's something people are surprised
[00:42:54.400 --> 00:42:56.720]   by when they work with me is how slow I am.
[00:42:56.720 --> 00:43:04.240]   I'm not in a big hurry, but I,
[00:43:06.240 --> 00:43:10.880]   I do spend a lot of time kind of meta researching
[00:43:10.880 --> 00:43:13.920]   and meta learning, which is like learning how to learn
[00:43:13.920 --> 00:43:16.960]   and learning how to research and learning how to work.
[00:43:16.960 --> 00:43:20.960]   I think the main thing I've done,
[00:43:20.960 --> 00:43:24.640]   which I don't know of anybody else who's done anywhere
[00:43:24.640 --> 00:43:29.200]   is to try to average spending at least 50% of my time
[00:43:29.200 --> 00:43:33.760]   every day learning and practicing something new.
[00:43:34.560 --> 00:43:36.480]   So I've been doing that since I was about 18.
[00:43:36.480 --> 00:43:40.320]   That could be just like a new API online
[00:43:40.320 --> 00:43:47.600]   or a new library or a new programming language or whatever.
[00:43:47.600 --> 00:43:52.800]   And the thing about that, that every,
[00:43:52.800 --> 00:43:55.520]   almost everybody I work with hates me doing that
[00:43:55.520 --> 00:43:57.520]   because it always seems like I'm spending time
[00:43:57.520 --> 00:43:59.040]   doing something which is not the thing I'm meant
[00:43:59.040 --> 00:44:00.720]   to be doing with the person I'm working with.
[00:44:01.680 --> 00:44:06.480]   But at the same time, it's, you know,
[00:44:06.480 --> 00:44:09.200]   it builds in this really multiplicative way.
[00:44:09.200 --> 00:44:11.840]   So all these tools and languages and stuff
[00:44:11.840 --> 00:44:14.480]   that I'm learning all work together
[00:44:14.480 --> 00:44:19.760]   so that I do find I can kind of whip things out
[00:44:19.760 --> 00:44:22.160]   more quickly than most people I know.
[00:44:22.160 --> 00:44:25.360]   And I also find that I kind of end up
[00:44:25.360 --> 00:44:27.360]   with a lot of kind of useful knowledge
[00:44:27.360 --> 00:44:30.000]   so that I can kind of read papers and stuff like that
[00:44:30.000 --> 00:44:30.960]   in lots of areas.
[00:44:30.960 --> 00:44:35.040]   You know, so for example, recently,
[00:44:35.040 --> 00:44:39.040]   one of my friends wrote a paper
[00:44:39.040 --> 00:44:44.240]   about the spike protein in COVID,
[00:44:44.240 --> 00:44:46.320]   which was being misunderstood.
[00:44:46.320 --> 00:44:51.120]   And the anti-vax community had really taken to it.
[00:44:51.120 --> 00:44:52.880]   And Alex Jones was talking about it.
[00:44:52.880 --> 00:44:57.840]   And so I spent a week learning about spike proteins
[00:44:57.840 --> 00:44:59.280]   and vaccines and so forth
[00:44:59.280 --> 00:45:00.960]   and ended up writing a paper with my friend
[00:45:00.960 --> 00:45:05.040]   about vaccine safety and vaccine efficacy
[00:45:05.040 --> 00:45:08.480]   and specifically focused on the role of the spike protein,
[00:45:08.480 --> 00:45:12.000]   which is, you know, something I don't know anything about.
[00:45:12.000 --> 00:45:15.200]   But I think, you know, when you decide to spend your time
[00:45:15.200 --> 00:45:17.840]   focused on learning something new,
[00:45:17.840 --> 00:45:20.000]   and particularly the more time you spend
[00:45:20.000 --> 00:45:23.200]   learning new things, the easier it gets.
[00:45:23.200 --> 00:45:25.360]   And so even though this was a totally new field for me,
[00:45:25.360 --> 00:45:27.360]   I found it was all just putting together stuff
[00:45:27.360 --> 00:45:29.520]   that was reasonably familiar.
[00:45:29.520 --> 00:45:32.400]   Second thing I'd say is,
[00:45:32.400 --> 00:45:36.240]   I think it's really useful to realize
[00:45:36.240 --> 00:45:38.080]   that basically nobody in history
[00:45:38.080 --> 00:45:42.800]   has shown the ability to have more than four hours a day
[00:45:42.800 --> 00:45:44.800]   of creative, productive work.
[00:45:44.800 --> 00:45:48.560]   So you should try really hard
[00:45:48.560 --> 00:45:50.560]   to make sure that you get those four hours
[00:45:50.560 --> 00:45:52.960]   as many times, many days as you can.
[00:45:52.960 --> 00:45:54.960]   Don't expect more.
[00:45:55.920 --> 00:45:58.080]   But really value those four hours
[00:45:58.080 --> 00:46:00.160]   and decide when those four hours are.
[00:46:00.160 --> 00:46:03.600]   And yeah, make the best of them you can.
[00:46:03.600 --> 00:46:07.920]   Don't start, you know, reading Facebook comments
[00:46:07.920 --> 00:46:10.000]   or getting distracted.
[00:46:10.000 --> 00:46:12.560]   You know, this is your time of creative work.
[00:46:12.560 --> 00:46:15.200]   So it could be that you're writing a blog post
[00:46:15.200 --> 00:46:16.480]   or you're writing code
[00:46:16.480 --> 00:46:18.640]   or you're doing some kind of deliberate practice.
[00:46:18.640 --> 00:46:23.360]   Something that really helps you get those four hours
[00:46:23.680 --> 00:46:26.560]   is being in good physical shape.
[00:46:26.560 --> 00:46:29.680]   So definitely, you know,
[00:46:29.680 --> 00:46:33.280]   half an hour to an hour of intense physical exercise
[00:46:33.280 --> 00:46:34.320]   each day is good.
[00:46:34.320 --> 00:46:37.920]   You can, you know, we got a lot of practice
[00:46:37.920 --> 00:46:39.920]   with learning how to do that inside
[00:46:39.920 --> 00:46:42.160]   because we had the lockdown in California
[00:46:42.160 --> 00:46:43.200]   and the wildfires.
[00:46:43.200 --> 00:46:47.360]   And so you can do high intensity training workouts,
[00:46:47.360 --> 00:46:49.200]   you know, Tabata training, stuff like that.
[00:46:49.200 --> 00:46:51.600]   And so, you know,
[00:46:51.600 --> 00:46:52.160]   you can do that.
[00:46:52.160 --> 00:46:59.200]   And so if you sleep well and exercise well.
[00:46:59.200 --> 00:47:03.840]   And yeah, you know,
[00:47:03.840 --> 00:47:05.440]   really try to find that four hours.
[00:47:05.440 --> 00:47:06.480]   I think that helps a lot.
[00:47:06.480 --> 00:47:09.920]   One thing that helps find your four hours each day
[00:47:09.920 --> 00:47:12.800]   is to try to block time for doing things.
[00:47:12.800 --> 00:47:14.320]   So if you need to have some meetings,
[00:47:14.320 --> 00:47:16.480]   decide how many hours a week
[00:47:16.480 --> 00:47:17.760]   you're prepared to have meetings
[00:47:17.760 --> 00:47:20.160]   and then set aside the hours each day
[00:47:20.160 --> 00:47:21.760]   you're prepared to have meetings.
[00:47:21.760 --> 00:47:25.280]   So for me, I generally set aside
[00:47:25.280 --> 00:47:30.160]   either all of or part of each Friday for meetings.
[00:47:30.160 --> 00:47:31.760]   And so I use Calendly,
[00:47:31.760 --> 00:47:32.960]   which is the thing that lets people
[00:47:32.960 --> 00:47:34.320]   book meetings with me.
[00:47:34.320 --> 00:47:37.120]   And so I just show that as being my free time.
[00:47:37.120 --> 00:47:41.360]   And so then the rest of the time is not meetings
[00:47:41.360 --> 00:47:44.080]   and it means I can focus.
[00:47:44.080 --> 00:47:48.080]   One thing Richard Feynman talked about,
[00:47:48.080 --> 00:47:49.200]   which I really agree with,
[00:47:49.200 --> 00:47:58.800]   is that it really helps if you bring joy to your work
[00:47:58.800 --> 00:48:03.200]   and follow things that are interesting to you.
[00:48:03.200 --> 00:48:06.560]   So I do basically no medium term planning at all,
[00:48:06.560 --> 00:48:08.400]   because that always feels like
[00:48:08.400 --> 00:48:09.760]   it sucks the joy out of things.
[00:48:09.760 --> 00:48:11.360]   I do long term planning of like,
[00:48:11.360 --> 00:48:13.360]   what would I like to do in the next 10 to 20 years?
[00:48:13.360 --> 00:48:16.320]   I do short term planning of what do I want to do
[00:48:16.320 --> 00:48:17.680]   in the next one to two days.
[00:48:18.000 --> 00:48:21.280]   But if people are like,
[00:48:21.280 --> 00:48:23.760]   what's your plan for the next month?
[00:48:23.760 --> 00:48:25.920]   I never have any idea
[00:48:25.920 --> 00:48:27.760]   because I really want to have that ability
[00:48:27.760 --> 00:48:30.240]   to like find out what's the thing
[00:48:30.240 --> 00:48:32.240]   that really gets me excited right now.
[00:48:32.240 --> 00:48:38.960]   And so as a result, I find the vast majority of the time,
[00:48:38.960 --> 00:48:40.640]   the work I'm doing is stuff
[00:48:40.640 --> 00:48:44.160]   which I am deeply passionate about and excited about.
[00:48:45.120 --> 00:48:46.400]   Sometimes I don't enjoy it.
[00:48:46.400 --> 00:48:48.960]   I mean, most obviously the masks for all stuff.
[00:48:48.960 --> 00:48:50.960]   I didn't enjoy any of that at all.
[00:48:50.960 --> 00:48:56.480]   I don't like politics and advocacy.
[00:48:56.480 --> 00:48:58.720]   And honestly, I don't like masks.
[00:48:58.720 --> 00:49:00.960]   They're boring, they're uncomfortable.
[00:49:00.960 --> 00:49:07.520]   But that was a case where it felt like a life
[00:49:07.520 --> 00:49:08.960]   and death situation.
[00:49:08.960 --> 00:49:11.680]   So I didn't need any more motivation.
[00:49:11.680 --> 00:49:12.960]   I didn't need any more motivation.
[00:49:13.520 --> 00:49:15.920]   So I didn't need any more motivation than that,
[00:49:15.920 --> 00:49:20.880]   which was to work hard on that every day
[00:49:20.880 --> 00:49:23.840]   because every day that we hadn't succeeded
[00:49:23.840 --> 00:49:26.160]   in getting that message out was another day
[00:49:26.160 --> 00:49:27.920]   that we were getting more exponential growth
[00:49:27.920 --> 00:49:28.880]   of COVID cases.
[00:49:28.880 --> 00:49:34.640]   But on the whole, the vast majority of the things I do,
[00:49:34.640 --> 00:49:36.400]   I enjoy a lot.
[00:49:36.400 --> 00:49:40.000]   And if it's something which doesn't seem that enjoyable,
[00:49:40.000 --> 00:49:42.400]   I will find a way to do it that is enjoyable
[00:49:42.400 --> 00:49:44.720]   and that I learn something new, even if it's slower.
[00:49:44.720 --> 00:49:51.840]   So if it's some kind of tedious kind of admin exercise,
[00:49:51.840 --> 00:49:54.000]   I'll try and find some way to automate it
[00:49:54.000 --> 00:49:57.840]   or make it fun.
[00:49:57.840 --> 00:50:01.520]   The other thing I try to do is to make everything
[00:50:01.520 --> 00:50:02.720]   extremely high leverage.
[00:50:02.720 --> 00:50:07.280]   So I almost never do a talk that's not recorded.
[00:50:07.280 --> 00:50:11.200]   Anytime I have a recorded talk, I'll put it on YouTube
[00:50:11.200 --> 00:50:14.080]   and try and make sure it's interesting and useful
[00:50:14.080 --> 00:50:17.280]   and that I create the best possible Twitter thread
[00:50:17.280 --> 00:50:18.720]   I can to advertise it.
[00:50:18.720 --> 00:50:23.920]   If I'm going to write something for a student,
[00:50:23.920 --> 00:50:25.760]   I will write it as a blog post
[00:50:25.760 --> 00:50:27.280]   and try to make it as good as possible
[00:50:27.280 --> 00:50:29.680]   so I can hopefully get 100,000 people reading it.
[00:50:29.680 --> 00:50:34.240]   I find a lot of people do stuff in really low leverage,
[00:50:34.240 --> 00:50:35.440]   low scale ways.
[00:50:35.440 --> 00:50:37.680]   And I always feel that's pretty wasteful.
[00:50:39.920 --> 00:50:46.480]   If you're a professor teaching a course to 50 students,
[00:50:46.480 --> 00:50:50.560]   I find most professors focus entirely on those 50 students.
[00:50:50.560 --> 00:50:53.040]   But if you put it online, you very quickly find
[00:50:53.040 --> 00:50:54.640]   you've got 50,000 students.
[00:50:54.640 --> 00:51:00.160]   And so that's just so much more exciting
[00:51:00.160 --> 00:51:02.800]   to be able to influence 1,000 times more people.
[00:51:02.800 --> 00:51:05.280]   But you can't physically see them.
[00:51:06.880 --> 00:51:09.600]   But for me, you know, when I teach,
[00:51:09.600 --> 00:51:14.080]   I'm focusing on the 50,000 people I can't see
[00:51:14.080 --> 00:51:15.840]   rather than the 50 people I can see.
[00:51:15.840 --> 00:51:23.440]   Thank you so very much, Jeremy.
[00:51:23.440 --> 00:51:27.760]   There's so much advice and there's so much good advice
[00:51:27.760 --> 00:51:30.480]   and there's so much learnings in just everything
[00:51:30.480 --> 00:51:32.640]   that you've mentioned and everything that you do.
[00:51:32.640 --> 00:51:35.920]   We as a community are really grateful
[00:51:35.920 --> 00:51:38.560]   to the work that you do and you push out
[00:51:38.560 --> 00:51:39.840]   and make it open source.
[00:51:39.840 --> 00:51:40.880]   Thanks very much for that.
[00:51:40.880 --> 00:51:45.280]   We'll also go into the questions.
[00:51:45.280 --> 00:51:50.640]   So as I said, the site for this,
[00:51:50.640 --> 00:51:52.640]   we're going into the email with Jeremy now.
[00:51:52.640 --> 00:51:56.640]   And it's 1db.me/jeremy.
[00:51:56.640 --> 00:52:02.160]   I'll just post it in the chat.
[00:52:02.160 --> 00:52:04.480]   So let's go and have a look.
[00:52:04.480 --> 00:52:05.920]   If there's any questions here.
[00:52:05.920 --> 00:52:10.960]   I shouldn't have to refresh, but there are--
[00:52:10.960 --> 00:52:12.560]   Okay. There's quite a few questions.
[00:52:12.560 --> 00:52:14.960]   Cool. This is the tough work.
[00:52:14.960 --> 00:52:16.400]   We'll try and get through all of them.
[00:52:16.400 --> 00:52:19.040]   I can't promise, but we're definitely going to try.
[00:52:19.040 --> 00:52:21.040]   What advice would you give in--
[00:52:21.040 --> 00:52:22.240]   Question from Hrithik.
[00:52:22.240 --> 00:52:24.240]   What advice would you give an undergraduate
[00:52:24.240 --> 00:52:26.960]   computer science student who aspires to be a researcher
[00:52:26.960 --> 00:52:28.640]   in the field of artificial intelligence?
[00:52:28.640 --> 00:52:30.720]   Do you mind zooming in a little bit, Herman?
[00:52:30.720 --> 00:52:31.360]   Yep.
[00:52:31.360 --> 00:52:32.160]   Thanks.
[00:52:32.160 --> 00:52:32.800]   Is that better?
[00:52:33.520 --> 00:52:34.160]   Yeah, that's lovely.
[00:52:34.160 --> 00:52:37.120]   Okay. What advice would you give to an undergraduate
[00:52:37.120 --> 00:52:39.360]   computer science student who aspires to be a researcher
[00:52:39.360 --> 00:52:40.160]   in the field of AI?
[00:52:40.160 --> 00:52:43.840]   Gosh, it's a bit generic,
[00:52:43.840 --> 00:52:46.320]   so it's hard to give super general advice.
[00:52:46.320 --> 00:52:49.360]   I would say I would replace the words
[00:52:49.360 --> 00:52:52.080]   artificial intelligence there with deep learning,
[00:52:52.080 --> 00:52:55.040]   because deep learning is at the heart of nearly
[00:52:55.040 --> 00:52:57.040]   all of the really big advances
[00:52:57.040 --> 00:52:58.640]   in modern artificial intelligence.
[00:53:01.920 --> 00:53:04.160]   I think if you want to be a researcher in AI,
[00:53:04.160 --> 00:53:06.400]   I guess the question is why.
[00:53:06.400 --> 00:53:09.200]   What's the purpose you want to be a researcher
[00:53:09.200 --> 00:53:10.480]   and focus on that?
[00:53:10.480 --> 00:53:14.960]   So if it's just that you think deep learning's
[00:53:14.960 --> 00:53:18.000]   an interesting field and you'd like to do more with it,
[00:53:18.000 --> 00:53:20.960]   then I would say you'll probably get more pleasure
[00:53:20.960 --> 00:53:24.000]   out of working in a startup or something like that
[00:53:24.000 --> 00:53:25.920]   where your work is being directly applied.
[00:53:25.920 --> 00:53:30.400]   A lot of research in academia is kind of dull.
[00:53:31.040 --> 00:53:35.760]   Academia really rewards the wrong kinds of things,
[00:53:35.760 --> 00:53:37.520]   which it doesn't reward innovation.
[00:53:37.520 --> 00:53:41.360]   It really rewards sticking to an area of research
[00:53:41.360 --> 00:53:44.240]   that everybody's familiar with so that you get cited
[00:53:44.240 --> 00:53:45.840]   and accepted into conferences.
[00:53:45.840 --> 00:53:53.120]   I think everything we talked about in terms of being
[00:53:53.120 --> 00:53:55.520]   good at getting through Fastbook applies to this as well.
[00:53:55.520 --> 00:53:57.520]   You definitely want to be a good coder.
[00:53:57.520 --> 00:53:59.200]   You should really try to implement things.
[00:54:00.560 --> 00:54:03.120]   If you really do want to be an academic researcher
[00:54:03.120 --> 00:54:08.480]   in deep learning, to get published papers
[00:54:08.480 --> 00:54:11.680]   that are influential, you actually need to write code
[00:54:11.680 --> 00:54:13.440]   that implements those things effectively
[00:54:13.440 --> 00:54:14.400]   and gets good results.
[00:54:14.400 --> 00:54:18.000]   And then, yeah, other than that, I'd say,
[00:54:18.000 --> 00:54:21.600]   just like I said, to read lots of code,
[00:54:21.600 --> 00:54:23.360]   I'd also say read lots of papers
[00:54:23.360 --> 00:54:26.720]   and then re-implement them yourself from scratch.
[00:54:26.720 --> 00:54:29.120]   And remember, the people who wrote that paper
[00:54:29.920 --> 00:54:32.000]   have probably made lots of stupid mistakes.
[00:54:32.000 --> 00:54:35.760]   So read it with that assumption and try to find out,
[00:54:35.760 --> 00:54:37.920]   like, think about what are the other ways
[00:54:37.920 --> 00:54:39.040]   that they could have done things.
[00:54:39.040 --> 00:54:44.000]   And then if you're not sure why they didn't do that other way,
[00:54:44.000 --> 00:54:46.640]   try it that other way and see if you can get better results
[00:54:46.640 --> 00:54:47.280]   than they did.
[00:54:47.280 --> 00:54:49.120]   And now you've got some research.
[00:54:49.120 --> 00:54:52.720]   Thank you, Jeremy.
[00:54:52.720 --> 00:54:55.840]   I'm going through and skimming through the questions.
[00:54:55.840 --> 00:54:57.760]   I believe this one has been answered already.
[00:54:57.760 --> 00:54:59.440]   What are the advances of video lecture
[00:54:59.440 --> 00:55:00.560]   compared to the book?
[00:55:00.560 --> 00:55:03.920]   I believe Jeremy mentioned that it's two modalities
[00:55:03.920 --> 00:55:06.000]   and they cover the same thing.
[00:55:06.000 --> 00:55:07.280]   So it's beneficial.
[00:55:07.280 --> 00:55:10.240]   The best way to do it is to do both.
[00:55:10.240 --> 00:55:11.520]   Is that correct, Jeremy?
[00:55:11.520 --> 00:55:12.020]   Yep.
[00:55:12.020 --> 00:55:13.540]   Awesome.
[00:55:13.540 --> 00:55:14.800]   I have an idea.
[00:55:14.800 --> 00:55:16.960]   Is Keras in API with TensorFlow 2x?
[00:55:16.960 --> 00:55:18.640]   Is Fast.ai same for PyDodge?
[00:55:18.640 --> 00:55:20.960]   I believe that's been covered quite a few times.
[00:55:20.960 --> 00:55:22.880]   But Jeremy, feel free to cut me.
[00:55:22.880 --> 00:55:23.920]   So yeah.
[00:55:23.920 --> 00:55:27.120]   So for those not familiar with Fast.ai,
[00:55:27.120 --> 00:55:28.480]   the Fast.ai library, yes,
[00:55:28.480 --> 00:55:31.360]   it plays a similar role to Keras in TensorFlow.
[00:55:31.360 --> 00:55:35.840]   It's a higher level API that lets you worry less
[00:55:35.840 --> 00:55:38.240]   about the boilerplate and focus more
[00:55:38.240 --> 00:55:40.000]   on what you're trying to do.
[00:55:40.000 --> 00:55:45.200]   It's got a very different design to Keras.
[00:55:45.200 --> 00:55:47.600]   You know, we actually--
[00:55:47.600 --> 00:55:51.280]   originally, we taught Keras in the early days of the course.
[00:55:51.280 --> 00:55:52.960]   So I'm very familiar with it.
[00:55:52.960 --> 00:55:54.240]   And I thought it was really great.
[00:55:54.240 --> 00:55:56.240]   I'm very familiar with the benefits of it.
[00:55:56.240 --> 00:56:00.480]   But also, you know, very familiar with the warts of it.
[00:56:00.480 --> 00:56:02.000]   And one of the things I found challenging
[00:56:02.000 --> 00:56:04.480]   was it was a bit difficult to dive under the covers
[00:56:04.480 --> 00:56:06.080]   and really change everything.
[00:56:06.080 --> 00:56:11.440]   And so Fast.ai has an extremely decoupled and layered API,
[00:56:11.440 --> 00:56:14.400]   which is designed to be really useful for researchers,
[00:56:14.400 --> 00:56:17.040]   to allow them to change absolutely anything.
[00:56:17.040 --> 00:56:21.520]   And also designed to be useful for practitioners,
[00:56:21.520 --> 00:56:25.760]   in terms of it's very easy to focus on the part of the code
[00:56:25.760 --> 00:56:29.040]   which is relevant to you and not have to worry
[00:56:29.040 --> 00:56:30.400]   about all the rest of it.
[00:56:30.400 --> 00:56:32.640]   Thank you, Jeremy.
[00:56:32.640 --> 00:56:35.840]   Next question that we have from Surya is,
[00:56:35.840 --> 00:56:37.840]   is it important that we go through the machine learning
[00:56:37.840 --> 00:56:40.400]   course of Fast.ai before the second part of the course?
[00:56:40.400 --> 00:56:42.180]   Oh, no.
[00:56:42.180 --> 00:56:44.880]   The-- this-- thanks for the question.
[00:56:44.880 --> 00:56:49.760]   This course, the new version of the course we're doing now,
[00:56:49.760 --> 00:56:53.200]   actually incorporates the machine learning pieces you need.
[00:56:53.200 --> 00:56:55.120]   So you don't need anything else.
[00:56:56.080 --> 00:56:56.800]   Excellent.
[00:56:56.800 --> 00:56:59.760]   So the 2020 course is already covering that.
[00:56:59.760 --> 00:57:00.400]   That's awesome.
[00:57:00.400 --> 00:57:04.320]   From questions from Aditya about the future of Fast.ai,
[00:57:04.320 --> 00:57:06.320]   what are the new things coming in Fast.ai,
[00:57:06.320 --> 00:57:09.280]   and when will we have TPU with Fast.ai?
[00:57:09.280 --> 00:57:13.680]   So Aman and I are working on the TPU stuff right now.
[00:57:13.680 --> 00:57:16.800]   So feel free to nag him if you want it more quickly.
[00:57:16.800 --> 00:57:24.560]   But we've been waiting until the TPU VMs have come out
[00:57:24.560 --> 00:57:26.560]   of alpha for publicly available use.
[00:57:26.560 --> 00:57:31.040]   That just happened last week, like a few days ago, actually.
[00:57:31.040 --> 00:57:34.240]   So now that they're available, we can provide that.
[00:57:34.240 --> 00:57:41.760]   There was a previous way of using the TPU with PyTorch,
[00:57:41.760 --> 00:57:44.080]   but it was extremely unoptimized.
[00:57:44.080 --> 00:57:48.720]   And I don't like to provide ways to do things when I don't
[00:57:48.720 --> 00:57:50.080]   think it's the right thing to do.
[00:57:50.080 --> 00:57:52.560]   So I didn't provide a TPU approach before,
[00:57:52.560 --> 00:57:54.720]   because I just think if you're going to use TPUs,
[00:57:54.720 --> 00:57:58.160]   you should use TensorFlow, because that was the only one
[00:57:58.160 --> 00:58:00.720]   that had the ability to go fast.
[00:58:00.720 --> 00:58:03.040]   But now that the VMs are available,
[00:58:03.040 --> 00:58:07.040]   we are going to release TPU support soon-ish.
[00:58:07.040 --> 00:58:10.160]   In terms of the new things coming in Fast.ai,
[00:58:10.160 --> 00:58:13.440]   Aman, if you could open up the Fast.ai repo.
[00:58:13.440 --> 00:58:15.360]   So just go to fast.ai/fast.ai.
[00:58:15.360 --> 00:58:22.480]   And then click on projects.
[00:58:22.560 --> 00:58:24.080]   So if you want to go and have a look at this project,
[00:58:24.080 --> 00:58:27.440]   you can see some of the stuff that we're working on there.
[00:58:27.440 --> 00:58:32.400]   The key kind of direction for this next version
[00:58:32.400 --> 00:58:37.840]   will be to massively leverage the two brilliant libraries
[00:58:37.840 --> 00:58:41.040]   that now exist, TIM for computer vision,
[00:58:41.040 --> 00:58:42.720]   and Hugging Face for NLP,
[00:58:42.720 --> 00:58:49.840]   and to provide really fantastic integration for those libraries.
[00:58:49.840 --> 00:58:53.600]   That's the main thing that will be kind of the focus
[00:58:53.600 --> 00:58:55.040]   of the next version of Fast.ai,
[00:58:55.040 --> 00:58:57.440]   but there's other things you'll see in that project as well.
[00:58:57.440 --> 00:58:59.920]   - Thank you, Jeremy.
[00:58:59.920 --> 00:59:02.480]   How to learn meta-learning.
[00:59:02.480 --> 00:59:04.320]   Oh, sorry, it's 2 p.m.
[00:59:04.320 --> 00:59:06.480]   Jeremy, conscious of your time as well,
[00:59:06.480 --> 00:59:10.400]   would you have maybe a few more minutes just to answer the--
[00:59:10.400 --> 00:59:11.760]   - Let's do 10 more minutes.
[00:59:11.760 --> 00:59:12.560]   - Yeah, excellent.
[00:59:12.560 --> 00:59:13.200]   Thank you, Jeremy.
[00:59:13.200 --> 00:59:15.520]   Question from Saurav,
[00:59:15.520 --> 00:59:17.520]   how to learn meta-learning, meta-reference?
[00:59:17.520 --> 00:59:19.440]   Question from Saurav, how to learn meta-learning,
[00:59:19.440 --> 00:59:21.440]   meta-researching as mentioned by Jeremy.
[00:59:21.440 --> 00:59:25.520]   - So one thing that's really,
[00:59:25.520 --> 00:59:27.360]   actually, you know, there's a really great site
[00:59:27.360 --> 00:59:30.560]   maybe you can go to for us, which is supermemo.com.
[00:59:30.560 --> 00:59:38.720]   Yeah, so this would be a great place to start.
[00:59:38.720 --> 00:59:43.200]   This is from a researcher named Peter Wozniak,
[00:59:43.200 --> 00:59:46.720]   and he has software,
[00:59:46.720 --> 00:59:47.680]   but that's actually not the main thing
[00:59:47.680 --> 00:59:48.400]   I wanted to show you,
[00:59:48.400 --> 00:59:50.000]   but you'll also find on SuperMemo,
[00:59:50.000 --> 00:59:53.120]   there's a huge number of resources around methods
[00:59:53.120 --> 00:59:56.800]   that he's studied for learning about learning.
[00:59:56.800 --> 00:59:59.760]   And so that would be one good place to look.
[00:59:59.760 --> 01:00:04.160]   Another way would be to look at the kind of methods
[01:00:04.160 --> 01:00:05.840]   of the memory champions.
[01:00:05.840 --> 01:00:07.600]   There's a really great book called
[01:00:07.600 --> 01:00:10.960]   "Moonwalking with Einstein," which I highly recommend.
[01:00:14.320 --> 01:00:17.120]   And that's all about the techniques
[01:00:17.120 --> 01:00:19.520]   used by world memory champions.
[01:00:19.520 --> 01:00:22.320]   And it's not only interesting for memory,
[01:00:22.320 --> 01:00:24.880]   but it's also fantastic in really showing you how,
[01:00:24.880 --> 01:00:28.480]   yeah, that's the one, the top Amazon one there,
[01:00:28.480 --> 01:00:34.960]   how the things that we think of as kind of hard-coded,
[01:00:34.960 --> 01:00:36.080]   that there are people who are smart
[01:00:36.080 --> 01:00:36.960]   and people who are dumb,
[01:00:36.960 --> 01:00:38.880]   or people who have good memory and people who don't,
[01:00:38.880 --> 01:00:42.240]   it's actually turned out that's on the whole not true,
[01:00:42.240 --> 01:00:44.960]   and that these are all skills that you can learn.
[01:00:44.960 --> 01:00:50.900]   Thanks.
[01:00:50.900 --> 01:00:52.880]   Thanks for the good question, Saurav.
[01:00:52.880 --> 01:00:56.160]   Corinne is asking, "Hi Jeremy, how many hours
[01:00:56.160 --> 01:00:58.080]   do you try to learn new things outside of your work?
[01:00:58.080 --> 01:01:00.000]   Is learning multiple programming languages
[01:01:00.000 --> 01:01:02.160]   useful for a deep learning practitioner?"
[01:01:02.160 --> 01:01:04.080]   Yeah, learning multiple programming languages
[01:01:04.080 --> 01:01:05.360]   is such a good idea,
[01:01:05.360 --> 01:01:07.120]   particularly because the Python community
[01:01:07.120 --> 01:01:08.320]   is extremely insular.
[01:01:09.920 --> 01:01:12.560]   So there's a lot of very opinionated things
[01:01:12.560 --> 01:01:14.160]   in the Python community that are wrong.
[01:01:14.160 --> 01:01:23.040]   So if you get into JavaScript or Lisp or Kotlin,
[01:01:23.040 --> 01:01:26.800]   you'll learn all kinds of interesting new things.
[01:01:26.800 --> 01:01:31.120]   "How many hours do I try to learn new things
[01:01:31.120 --> 01:01:32.000]   outside of your work?"
[01:01:32.000 --> 01:01:35.120]   I've always tried not to separate out my work
[01:01:35.120 --> 01:01:36.720]   from non-work too much.
[01:01:39.040 --> 01:01:43.120]   Because I always try to work on things I find interesting.
[01:01:43.120 --> 01:01:47.520]   I spend a lot of time reading about stuff,
[01:01:47.520 --> 01:01:49.600]   which I guess technically you could call work.
[01:01:49.600 --> 01:01:51.760]   One of the things I don't do is I don't watch any TV
[01:01:51.760 --> 01:01:54.160]   and I don't play any computer games.
[01:01:54.160 --> 01:01:57.920]   I mean, it's fine if you want to literally decide
[01:01:57.920 --> 01:02:00.080]   I want to learn a lot about computer games,
[01:02:00.080 --> 01:02:01.840]   then play lots of computer games.
[01:02:01.840 --> 01:02:04.480]   That's not something I've spent time with.
[01:02:04.480 --> 01:02:08.400]   But I've recently started trying to learn some chess,
[01:02:08.400 --> 01:02:11.200]   so I spent time studying chess.
[01:02:11.200 --> 01:02:14.480]   I recently-- I don't know.
[01:02:14.480 --> 01:02:15.840]   There's always kind of things I'm interested
[01:02:15.840 --> 01:02:16.640]   in learning about.
[01:02:16.640 --> 01:02:20.560]   And I could-- I try to have something on my Kindle,
[01:02:20.560 --> 01:02:23.280]   on my phone, whatever, with me all the time.
[01:02:23.280 --> 01:02:27.840]   So anytime I'm waiting in a queue, I'll be reading.
[01:02:27.840 --> 01:02:31.440]   So I don't know.
[01:02:31.440 --> 01:02:33.920]   It's all kind of out of work, in a sense.
[01:02:33.920 --> 01:02:38.480]   It's really exciting to hear as someone--
[01:02:38.480 --> 01:02:42.080]   yeah, it is really exciting that--
[01:02:42.080 --> 01:02:43.760]   and these are all really good advices.
[01:02:43.760 --> 01:02:45.840]   Question from Kevin.
[01:02:45.840 --> 01:02:49.040]   Has anybody confirmed that Jeremy has invented a time machine?
[01:02:49.040 --> 01:02:50.960]   Same question from my side.
[01:02:50.960 --> 01:02:55.440]   Question from Obe.
[01:02:55.440 --> 01:02:58.080]   Doing so many things, that seems like a lot of distraction.
[01:02:58.080 --> 01:03:00.000]   How do you get your focus back, Jeremy?
[01:03:00.000 --> 01:03:01.120]   Yeah, that's a good question.
[01:03:01.120 --> 01:03:02.720]   I only do one thing at a time.
[01:03:03.440 --> 01:03:05.680]   And I only can do one thing at a time.
[01:03:05.680 --> 01:03:09.120]   So I do one thing, and then I go and do the next thing.
[01:03:09.120 --> 01:03:11.040]   And I think it's difficult sometimes,
[01:03:11.040 --> 01:03:12.880]   the people I work with, because sometimes I
[01:03:12.880 --> 01:03:14.400]   do kind of go dark for a month.
[01:03:14.400 --> 01:03:17.920]   But then I find people are surprised when I then come back
[01:03:17.920 --> 01:03:19.680]   and finish the thing I said I'd finish.
[01:03:19.680 --> 01:03:24.800]   So yeah, I think that's the main thing.
[01:03:24.800 --> 01:03:28.560]   It's like, I do my best to polish off each thing as well
[01:03:28.560 --> 01:03:31.120]   as I can, and then move on to the next thing.
[01:03:31.120 --> 01:03:34.560]   And I think the other thing is just verbal around
[01:03:34.560 --> 01:03:35.600]   in the back of my mind.
[01:03:35.600 --> 01:03:37.200]   And so by the time I come back to them,
[01:03:37.200 --> 01:03:39.760]   my brain seems to have figured a few things out,
[01:03:39.760 --> 01:03:41.120]   which is just nice.
[01:03:41.120 --> 01:03:45.120]   Again, question from Kevin.
[01:03:45.120 --> 01:03:46.720]   Do you keep the four hours in a single block,
[01:03:46.720 --> 01:03:48.240]   or break it into smaller blocks?
[01:03:48.240 --> 01:03:51.440]   Generally, two blocks of two hours.
[01:03:51.440 --> 01:03:56.480]   A question from Alarisa.
[01:03:56.480 --> 01:03:58.480]   I had the wrong idea that this was a paper reading group
[01:03:58.480 --> 01:03:59.440]   and deep learning with Jeremy.
[01:03:59.440 --> 01:04:00.080]   Always a fan.
[01:04:00.080 --> 01:04:02.400]   We're excited to be here and looking forward
[01:04:02.400 --> 01:04:03.760]   to the next few weeks.
[01:04:03.760 --> 01:04:06.240]   I've been working a full-time job and finding it difficult
[01:04:06.240 --> 01:04:09.120]   to keep up with the latest field research.
[01:04:09.120 --> 01:04:12.400]   Can you recommend your top go-to resources
[01:04:12.400 --> 01:04:15.040]   in order to get daily, weekly research paper
[01:04:15.040 --> 01:04:16.960]   summaries and discussions in computer vision?
[01:04:16.960 --> 01:04:19.200]   Everybody follow Jeremy on Twitter.
[01:04:19.200 --> 01:04:21.760]   That's the one thing that I wake up and still
[01:04:21.760 --> 01:04:22.480]   have lots of news.
[01:04:22.480 --> 01:04:23.600]   But Jeremy, please take this.
[01:04:23.600 --> 01:04:24.560]   Yeah, I use Twitter.
[01:04:24.560 --> 01:04:28.160]   And then if I want to dig more deeply into something,
[01:04:28.800 --> 01:04:31.600]   stuff like archive vanity is quite useful.
[01:04:31.600 --> 01:04:33.280]   Semantic Scholar is quite useful.
[01:04:33.280 --> 01:04:36.160]   But I don't think it's possible to keep up
[01:04:36.160 --> 01:04:39.680]   with the latest DL research, even in a subfield.
[01:04:39.680 --> 01:04:47.280]   So instead, yeah, just if you follow the right people
[01:04:47.280 --> 01:04:48.880]   on Twitter, and you can do that by looking
[01:04:48.880 --> 01:04:51.520]   at my favorites on Twitter, and then just go through
[01:04:51.520 --> 01:04:52.880]   and follow anybody who seems--
[01:04:52.880 --> 01:04:55.280]   you see there's posting interesting stuff.
[01:04:56.480 --> 01:04:59.280]   That will generally highlight the really obvious big things
[01:04:59.280 --> 01:05:00.240]   that come out.
[01:05:00.240 --> 01:05:04.240]   And then follow your interests by looking through citations.
[01:05:04.240 --> 01:05:05.920]   And yeah, as I said, archive sanity
[01:05:05.920 --> 01:05:09.120]   is quite helpful for finding similar papers,
[01:05:09.120 --> 01:05:09.760]   stuff like that.
[01:05:09.760 --> 01:05:11.680]   Yeah, I was going to say--
[01:05:11.680 --> 01:05:13.680]   And don't be afraid to ask people on Twitter as well.
[01:05:13.680 --> 01:05:17.600]   Like, there's always quite a bit of noise on Twitter.
[01:05:17.600 --> 01:05:21.120]   So when somebody asks you an actual well-researched,
[01:05:21.120 --> 01:05:25.200]   thoughtful question on Twitter, you'll generally
[01:05:25.200 --> 01:05:27.920]   get a thoughtful response.
[01:05:27.920 --> 01:05:32.240]   But just make sure that you provide as much context
[01:05:32.240 --> 01:05:32.720]   as you can.
[01:05:32.720 --> 01:05:36.240]   So if you have a computer vision question about some issue
[01:05:36.240 --> 01:05:38.880]   around ResNets or something, say, well,
[01:05:38.880 --> 01:05:40.480]   I'm interested in this question.
[01:05:40.480 --> 01:05:42.560]   I tried to solve it, and I looked at this paper
[01:05:42.560 --> 01:05:45.200]   and this paper, but I found I still had this issue.
[01:05:45.200 --> 01:05:49.600]   Really show your research, show what you've done,
[01:05:49.600 --> 01:05:50.560]   and then ask the question.
[01:05:50.560 --> 01:05:54.240]   Hopefully, you'll find you get some good answers.
[01:05:54.240 --> 01:05:56.480]   If you don't, often that means that nobody else
[01:05:56.480 --> 01:05:58.080]   knows the answer to your question as well.
[01:05:58.080 --> 01:06:00.400]   And that would be potentially an interesting research field
[01:06:00.400 --> 01:06:00.900]   then.
[01:06:00.900 --> 01:06:04.240]   Thank you.
[01:06:04.240 --> 01:06:07.200]   I just want to quickly add my first 1,000 people I followed
[01:06:07.200 --> 01:06:08.800]   were from Jeremy's list as well.
[01:06:08.800 --> 01:06:15.600]   By the way, one of the many silly little projects I've done,
[01:06:15.600 --> 01:06:19.680]   the way I got my list of people I follow
[01:06:19.680 --> 01:06:23.520]   was I wrote a little script with a Twitter API.
[01:06:24.400 --> 01:06:26.320]   Obviously, I did it in a Jupyter Notebook
[01:06:26.320 --> 01:06:28.160]   that went through all the people I had favorited
[01:06:28.160 --> 01:06:29.440]   for the last couple of years.
[01:06:29.440 --> 01:06:32.240]   And anybody I think I'd favorited like two times,
[01:06:32.240 --> 01:06:33.680]   I automatically followed them.
[01:06:33.680 --> 01:06:35.920]   And then anybody else, I automatically unfollowed.
[01:06:35.920 --> 01:06:39.360]   This is one of the projects that you
[01:06:39.360 --> 01:06:41.920]   said you'd like to take the mundane away and make
[01:06:41.920 --> 01:06:42.880]   it more interesting.
[01:06:42.880 --> 01:06:43.380]   Yeah.
[01:06:43.380 --> 01:06:47.360]   Will all the 20 weeks be available on YouTube?
[01:06:47.360 --> 01:06:49.840]   Yes, they will be.
[01:06:49.840 --> 01:06:52.320]   Any links to practice Python?
[01:06:52.560 --> 01:06:55.120]   I'm not the right person to ask about that.
[01:06:55.120 --> 01:07:01.600]   I think you should probably ask on the forum for this session.
[01:07:01.600 --> 01:07:04.720]   I'm a non-coder.
[01:07:04.720 --> 01:07:06.560]   Most of my career went to infrastructure support.
[01:07:06.560 --> 01:07:07.760]   And it's the same.
[01:07:07.760 --> 01:07:08.320]   Yeah, sorry.
[01:07:08.320 --> 01:07:12.640]   Shank, what's the best way to practice deep learning?
[01:07:12.640 --> 01:07:15.200]   Yeah, I think just what we talked about today.
[01:07:15.200 --> 01:07:19.520]   Karthikeya, I built my computer vision startup
[01:07:19.520 --> 01:07:21.040]   entirely with fast.ai.
[01:07:21.040 --> 01:07:21.540]   Awesome.
[01:07:22.340 --> 01:07:25.140]   I'm trying to build a team and probably raise a seed fund.
[01:07:25.140 --> 01:07:28.180]   How should I move ahead with this?
[01:07:28.180 --> 01:07:31.060]   OK, can we see the startup, please?
[01:07:31.060 --> 01:07:32.180]   Can you go to that link?
[01:07:32.180 --> 01:07:32.820]   Let's check it out.
[01:07:32.820 --> 01:07:34.740]   No pressure.
[01:07:34.740 --> 01:07:39.140]   Hopefully, it's not a spam or something.
[01:07:39.140 --> 01:07:43.300]   Ah, OK.
[01:07:43.300 --> 01:07:44.920]   Cool.
[01:07:44.920 --> 01:07:50.340]   So I'm planning to run a startup course.
[01:07:50.580 --> 01:07:52.100]   Maybe kind of early next year.
[01:07:52.100 --> 01:07:55.140]   So can you go back to the question?
[01:07:55.140 --> 01:07:56.500]   I can't remember exactly what it was.
[01:07:56.500 --> 01:07:58.660]   But yeah.
[01:07:58.660 --> 01:07:59.460]   Oh, yeah.
[01:07:59.460 --> 01:08:07.140]   So for raising money, the main thing
[01:08:07.140 --> 01:08:11.780]   is to make sure you've got a good working product online,
[01:08:11.780 --> 01:08:17.300]   that you have some customers, and preferably that you
[01:08:17.300 --> 01:08:18.660]   have some people paying for it.
[01:08:19.460 --> 01:08:22.980]   Generally, if you can show investors people paying
[01:08:22.980 --> 01:08:27.220]   for something that you've built, that should generally
[01:08:27.220 --> 01:08:29.060]   be enough to get you to raise a seed fund.
[01:08:29.060 --> 01:08:33.540]   You should also be able to show the investors some guess
[01:08:33.540 --> 01:08:36.100]   at how big the market is for the thing that you're selling,
[01:08:36.100 --> 01:08:38.020]   so that they have a sense of how big it could get.
[01:08:38.020 --> 01:08:41.700]   And generally, if you're trying to build a team,
[01:08:41.700 --> 01:08:43.620]   the most successful initial teams
[01:08:44.580 --> 01:08:50.900]   are built by people mining their networks,
[01:08:50.900 --> 01:08:52.580]   the folks that they've come across in their life
[01:08:52.580 --> 01:08:55.140]   who they thought were pretty smart and nice to work with.
[01:08:55.140 --> 01:08:58.500]   That's generally the early teams.
[01:08:58.500 --> 01:09:00.660]   So people are-- yeah, they're on friends,
[01:09:00.660 --> 01:09:01.460]   and they're on network.
[01:09:01.460 --> 01:09:03.060]   All right.
[01:09:03.060 --> 01:09:04.020]   So that's 10 plus 2.
[01:09:04.020 --> 01:09:05.720]   OK.
[01:09:05.720 --> 01:09:07.460]   Thanks very much, Jeremy.
[01:09:07.460 --> 01:09:09.700]   That's all the questions that we can take.
[01:09:09.700 --> 01:09:12.180]   And sorry for everybody else whose questions
[01:09:12.980 --> 01:09:13.700]   we couldn't take.
[01:09:13.700 --> 01:09:17.380]   I do want to say thank you for everybody for joining.
[01:09:17.380 --> 01:09:20.100]   And again, massive thanks goes out to Jeremy
[01:09:20.100 --> 01:09:22.740]   for finding the time and joining us.
[01:09:22.740 --> 01:09:26.500]   I'm sure we've all benefited from having Jeremy here.
[01:09:26.500 --> 01:09:28.020]   So thanks, Jeremy.
[01:09:28.020 --> 01:09:30.820]   And see you, everybody.
[01:09:30.820 --> 01:09:34.180]   [MUSIC PLAYING]
[01:09:34.180 --> 01:09:51.540]   [MUSIC PLAYING]

