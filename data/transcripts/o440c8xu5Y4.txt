
[00:00:00.000 --> 00:00:07.000]   I'm Cal Newport and this is Deep Questions, episode 187.
[00:00:07.000 --> 00:00:18.000]   I'm here in my Deep Work HQ joined by my producer, Jesse.
[00:00:18.000 --> 00:00:23.000]   Jesse, is this true that today is your birthday?
[00:00:23.000 --> 00:00:24.000]   It's true.
[00:00:24.000 --> 00:00:26.000]   It's actually true. Okay.
[00:00:26.000 --> 00:00:27.000]   Big 4-0, baby.
[00:00:27.000 --> 00:00:28.000]   Is this the big one?
[00:00:28.000 --> 00:00:29.000]   Yeah.
[00:00:29.000 --> 00:00:30.000]   I'm turning 40.
[00:00:30.000 --> 00:00:34.000]   That's me in two and a half months.
[00:00:34.000 --> 00:00:35.000]   I'm technically older than you?
[00:00:35.000 --> 00:00:37.000]   Technically older than me, but we're both having this.
[00:00:37.000 --> 00:00:40.000]   Here's what I'm thinking because we're both turning 40.
[00:00:40.000 --> 00:00:44.000]   We should have a midlife crisis.
[00:00:44.000 --> 00:00:45.000]   Right?
[00:00:45.000 --> 00:00:46.000]   I feel kind of left out.
[00:00:46.000 --> 00:00:52.000]   I read this book about midlife crises a couple years ago,
[00:00:52.000 --> 00:00:55.000]   written by a philosophy professor at MIT.
[00:00:55.000 --> 00:00:59.000]   Then I was reminded of it because my friend, Brett McKay,
[00:00:59.000 --> 00:01:02.000]   was interviewing him about this book on the art of manliness.
[00:01:02.000 --> 00:01:04.000]   It was called Midlife or something like this.
[00:01:04.000 --> 00:01:07.000]   I'm listening to this podcast and I was remembering this book.
[00:01:07.000 --> 00:01:12.000]   I think midlife crises get a bad rap.
[00:01:12.000 --> 00:01:14.000]   We think about it in popular culture.
[00:01:14.000 --> 00:01:18.000]   It's like, "Oh, it's like the guy buying the car and trying to feel younger,"
[00:01:18.000 --> 00:01:19.000]   this or that.
[00:01:19.000 --> 00:01:23.000]   But if you think about it objectively, 40, this makes a lot of sense to me,
[00:01:23.000 --> 00:01:27.000]   because it's a great time to step back and course correct.
[00:01:27.000 --> 00:01:30.000]   Yeah, if I live to 80, I'm happy.
[00:01:30.000 --> 00:01:31.000]   Yeah.
[00:01:31.000 --> 00:01:32.000]   I'm most involved in midlife.
[00:01:32.000 --> 00:01:35.000]   Because you have this 20-something year period where you're just trying to figure it.
[00:01:35.000 --> 00:01:38.000]   It's like you're going into adulthood, you're out of school,
[00:01:38.000 --> 00:01:40.000]   you're like, "How do I make a living?
[00:01:40.000 --> 00:01:43.000]   How do I be a reasonable member of society?
[00:01:43.000 --> 00:01:45.000]   How do I pay my bills?"
[00:01:45.000 --> 00:01:49.000]   Maybe if you start a family, like, "How do I keep my kids alive when they're babies?"
[00:01:49.000 --> 00:01:54.000]   And then around 40-ish, like, "Okay, that's hopefully been worked out."
[00:01:54.000 --> 00:01:56.000]   I think it's kind of a good time to say, "Okay, what's next?
[00:01:56.000 --> 00:02:00.000]   Do I want to course correct at all or at least do a pretty serious reflection?"
[00:02:00.000 --> 00:02:03.000]   Which is why I think we should do midlife crises.
[00:02:03.000 --> 00:02:05.000]   Sounds good.
[00:02:05.000 --> 00:02:07.000]   I don't know what I'm going to do in mine yet.
[00:02:07.000 --> 00:02:09.000]   And I'm talking about reasonable things.
[00:02:09.000 --> 00:02:15.000]   I'm not going to go start a ska band and start touring in a convertible.
[00:02:15.000 --> 00:02:16.000]   But there's got to be.
[00:02:16.000 --> 00:02:17.000]   I don't know.
[00:02:17.000 --> 00:02:18.000]   I'm thinking about it.
[00:02:18.000 --> 00:02:19.000]   I'm not 40.
[00:02:19.000 --> 00:02:21.000]   I've been thinking about 40 a lot.
[00:02:21.000 --> 00:02:23.000]   I haven't thought about it too much.
[00:02:23.000 --> 00:02:26.000]   I'm not really huge on my birthdays, so it's fine.
[00:02:26.000 --> 00:02:27.000]   Yeah, it's weird.
[00:02:27.000 --> 00:02:28.000]   I'm not either.
[00:02:28.000 --> 00:02:30.000]   I could care less about birthdays or am I getting older.
[00:02:30.000 --> 00:02:33.000]   Something about 40, though, got my attention.
[00:02:33.000 --> 00:02:34.000]   Really?
[00:02:34.000 --> 00:02:35.000]   Yeah.
[00:02:35.000 --> 00:02:37.000]   Not 39, not 38, not 30.
[00:02:37.000 --> 00:02:44.000]   But 40, really, this whole year has put me into a more reflective mode.
[00:02:44.000 --> 00:02:49.000]   You're going to have to coordinate a big goal that you always do for your birthdays.
[00:02:49.000 --> 00:02:50.000]   Oh, man.
[00:02:50.000 --> 00:02:51.000]   Project 40 is a big one.
[00:02:51.000 --> 00:02:54.000]   So I have one for each birthday, Project 39, Project 38.
[00:02:54.000 --> 00:03:00.000]   Project 40, or as I abbreviated my notes, P40, it's got some big things in it.
[00:03:00.000 --> 00:03:01.000]   I don't doubt it.
[00:03:01.000 --> 00:03:02.000]   Yeah.
[00:03:02.000 --> 00:03:03.000]   I don't doubt it.
[00:03:03.000 --> 00:03:05.000]   Some of it's under wraps for now, but I don't know.
[00:03:05.000 --> 00:03:11.000]   You just want to do the same thing for another 25 years or 40 is the time.
[00:03:11.000 --> 00:03:16.000]   So I think our midlife crisis should be to go through our plan to have that hybrid fantasy
[00:03:16.000 --> 00:03:24.000]   books/sports talk every day, five-day-a-week podcast that we do with sleeveless shirts.
[00:03:24.000 --> 00:03:29.000]   I think we've talked about that, and I think now is the time we'll tell our respective
[00:03:29.000 --> 00:03:31.000]   employers, "This is what we're doing now.
[00:03:31.000 --> 00:03:34.000]   If we're not all in, we're not doing this.
[00:03:34.000 --> 00:03:36.000]   If we're not all in, what are we doing here?"
[00:03:36.000 --> 00:03:38.000]   Mr. B says you've got to have a passion.
[00:03:38.000 --> 00:03:39.000]   Exactly.
[00:03:39.000 --> 00:03:45.000]   It's going to be the Brandon Sanderson NFL Talk Sports Hour in which Mr. Beast will give
[00:03:45.000 --> 00:03:46.000]   money to people randomly.
[00:03:46.000 --> 00:03:49.000]   Except for instead of giving people $100,000, we don't have the budget.
[00:03:49.000 --> 00:03:54.000]   We'll be like, "I will give you $7 if you can make this basketball shot."
[00:03:54.000 --> 00:03:57.000]   Anyways, well, happy birthday.
[00:03:57.000 --> 00:03:58.000]   Thanks.
[00:03:58.000 --> 00:03:59.000]   Appreciate it.
[00:03:59.000 --> 00:04:02.000]   And we will discuss our crises.
[00:04:02.000 --> 00:04:07.000]   Speaking about ... That's not a crisis, but I'm thinking we should deep dive because I've
[00:04:07.000 --> 00:04:09.000]   been having fun deep diving.
[00:04:09.000 --> 00:04:15.000]   It's nice now that we can put videos of these deep dives online because there's a whole ... I
[00:04:15.000 --> 00:04:19.000]   don't understand the internet, but there's a whole group of people out there whose main
[00:04:19.000 --> 00:04:22.000]   consumption of content seems to be they like to watch things.
[00:04:22.000 --> 00:04:26.000]   And so we can reach other people and I rant about things.
[00:04:26.000 --> 00:04:28.000]   It's a way for my rants to get to other people.
[00:04:28.000 --> 00:04:33.000]   So I feel like there's been new energy in our deep dives now that we can actually put
[00:04:33.000 --> 00:04:37.000]   them out there as sort of weird ranty monologue videos.
[00:04:37.000 --> 00:04:38.000]   For sure.
[00:04:38.000 --> 00:04:39.000]   All right.
[00:04:39.000 --> 00:04:46.000]   So I want to talk about today's deep dive, Quit Social Media.
[00:04:46.000 --> 00:04:52.000]   And the reason why I'm using that title is because that was the title of the single video
[00:04:52.000 --> 00:04:55.000]   I've ever produced that has been the most watched.
[00:04:55.000 --> 00:05:01.000]   My TEDx talk, I believe it was from 2017, Jessica confirmed that, that was titled Quit
[00:05:01.000 --> 00:05:06.000]   Social Media, and that went on 8 million something views since then.
[00:05:06.000 --> 00:05:08.000]   And I wanted to revisit it.
[00:05:08.000 --> 00:05:12.000]   It's been five years since I gave that talk, the most viral thing I've ever done online.
[00:05:12.000 --> 00:05:19.000]   I thought this would be a good time to visit my Quit Social Media TEDx talk.
[00:05:19.000 --> 00:05:20.000]   All right.
[00:05:20.000 --> 00:05:25.000]   So to start, I thought it might be interesting to give the backstory of how that talk came
[00:05:25.000 --> 00:05:26.000]   to be.
[00:05:26.000 --> 00:05:31.000]   And then I want to talk about what happened after it came out, and then finally reflect
[00:05:31.000 --> 00:05:36.000]   on how do I think today, five years later, about the points I was making then.
[00:05:36.000 --> 00:05:37.000]   Am I happy about things turned out?
[00:05:37.000 --> 00:05:39.000]   Am I upset how they turned out?
[00:05:39.000 --> 00:05:41.000]   Are they no longer relevant?
[00:05:41.000 --> 00:05:42.000]   That's my goal here.
[00:05:42.000 --> 00:05:44.000]   So let me go back to the context.
[00:05:44.000 --> 00:05:51.000]   So I had published the book Deep Work very early in 2016, right?
[00:05:51.000 --> 00:05:57.000]   So after I had published that book, we were looking for different topics I could bring
[00:05:57.000 --> 00:06:00.000]   out into the public sphere to try to generate attention for the book.
[00:06:00.000 --> 00:06:06.000]   So like, for example, I did an article for the Harvard Business Review that was titled
[00:06:06.000 --> 00:06:12.000]   Modest Proposal, Eliminate Email, which was the seed of the idea, of course, that I later
[00:06:12.000 --> 00:06:15.000]   elaborated in my book, A World Without Email, because that was like one of the ideas, email
[00:06:15.000 --> 00:06:17.000]   is distracting.
[00:06:17.000 --> 00:06:20.000]   And one of the other things that I talked about in Deep Work was social media.
[00:06:20.000 --> 00:06:25.000]   There was a chapter on social media being distracting, and we're putting too much emphasis
[00:06:25.000 --> 00:06:28.000]   on it when there's deeper skills that are probably more valuable.
[00:06:28.000 --> 00:06:33.000]   So we thought, OK, we should find a way to talk about this angle somewhere.
[00:06:33.000 --> 00:06:38.000]   Now, at this point, going up to 2016, I'm a bit of an odd guy.
[00:06:38.000 --> 00:06:43.000]   I had spent my entire adult life up to this point doing professional speaking.
[00:06:43.000 --> 00:06:47.000]   I mean, I started professional speaking when I was like 22 or 23 years old.
[00:06:47.000 --> 00:06:54.000]   I would travel around the country talking at colleges, then eventually at large conferences
[00:06:54.000 --> 00:06:55.000]   and corporate events.
[00:06:55.000 --> 00:07:00.000]   I had spoken in front of a thousand people at Lincoln Center and at the World Domination
[00:07:00.000 --> 00:07:04.000]   Summit, these type of places, as well as corporate gigs, the Canadian Olympic Committee, like
[00:07:04.000 --> 00:07:05.000]   all sorts of different places.
[00:07:05.000 --> 00:07:06.000]   I just gave a lot of talks.
[00:07:06.000 --> 00:07:08.000]   So I was familiar with talking.
[00:07:08.000 --> 00:07:12.000]   And when you're a talker who's been around for a while, I used to get lots of invitations
[00:07:12.000 --> 00:07:14.000]   for TEDx conferences.
[00:07:14.000 --> 00:07:20.000]   There was a time back then, 2014, 2015, 2016, where TEDx conferences were popping up everywhere
[00:07:20.000 --> 00:07:22.000]   because TED was very popular.
[00:07:22.000 --> 00:07:24.000]   And I would get those invitations all the time.
[00:07:24.000 --> 00:07:27.000]   And I was like, no, I'm not going to go to a TEDx conference.
[00:07:27.000 --> 00:07:31.000]   I have enough sort of big, high-paying gigs or giant audience gigs to do.
[00:07:31.000 --> 00:07:36.000]   But when we were trying to promote deep work and we're thinking about where can I go to
[00:07:36.000 --> 00:07:43.000]   introduce this idea of not using social media, I had this idea that you know who does video
[00:07:43.000 --> 00:07:47.000]   best when it comes to talks is these TEDx conferences.
[00:07:47.000 --> 00:07:51.000]   And so one thing they do very well is they have very good cameras and they have the distribution
[00:07:51.000 --> 00:07:54.000]   power of TED behind the video.
[00:07:54.000 --> 00:07:58.000]   So I said, OK, the next reasonable TEDx invitation I get, I'm going to say yes.
[00:07:58.000 --> 00:08:02.000]   I'm going to use that as a venue to give a fire-breathing talk about social media.
[00:08:02.000 --> 00:08:07.000]   And a TEDx conference that was being held in Virginia, so a 45-minute drive from me
[00:08:07.000 --> 00:08:09.000]   came along and said, do you want to speak?
[00:08:09.000 --> 00:08:11.000]   And I said, yes, I don't really care what your theme is.
[00:08:11.000 --> 00:08:13.000]   I'm going to come talk about quitting social media.
[00:08:13.000 --> 00:08:14.000]   So that's how it came to be.
[00:08:14.000 --> 00:08:16.000]   And so I wrote this talk.
[00:08:16.000 --> 00:08:18.000]   And it's a TED talk, so I memorized it.
[00:08:18.000 --> 00:08:24.000]   It's 15 minutes long, where I make the argument that more people should quit social media.
[00:08:24.000 --> 00:08:28.000]   It's not something that everyone has to use, and its damages are bigger than people might think.
[00:08:28.000 --> 00:08:30.000]   And I came to this TEDx talk.
[00:08:30.000 --> 00:08:31.000]   It was a small room.
[00:08:31.000 --> 00:08:32.000]   It was like a classroom.
[00:08:32.000 --> 00:08:35.000]   There must have been, I don't know, at most 40 people there.
[00:08:35.000 --> 00:08:38.000]   And I gave my talk.
[00:08:38.000 --> 00:08:42.000]   The whole idea behind the talk was that I want to bring attention to that topic.
[00:08:42.000 --> 00:08:47.000]   Almost immediately, it made the organizers uncomfortable.
[00:08:47.000 --> 00:08:50.000]   This idea that you should quit social media, to say it with a straight face,
[00:08:50.000 --> 00:08:54.000]   without a ton of caveats, was very countercultural and eccentric.
[00:08:54.000 --> 00:08:58.000]   So the first thing they did was change the title of my talk before they posted it online.
[00:08:58.000 --> 00:09:01.000]   They changed the title to "Working Deeply in a Distracted World."
[00:09:01.000 --> 00:09:04.000]   I barely mentioned deep work in this talk.
[00:09:04.000 --> 00:09:07.000]   This is straight up like, this is the problem with social media.
[00:09:07.000 --> 00:09:09.000]   You should stop using it.
[00:09:09.000 --> 00:09:11.000]   Here's what it's like to not use social media.
[00:09:11.000 --> 00:09:12.000]   It's great.
[00:09:12.000 --> 00:09:16.000]   Like I was being purposefully provocative and clear about it, and they changed the title
[00:09:16.000 --> 00:09:17.000]   because they were worried.
[00:09:17.000 --> 00:09:18.000]   Like, this is eccentric.
[00:09:18.000 --> 00:09:21.000]   Let's make it "Working Deeply in a Distracted World."
[00:09:21.000 --> 00:09:22.000]   And I called them up.
[00:09:22.000 --> 00:09:27.000]   It's like, no, the whole reason I came here is so that talk could be called "Quit Social Media."
[00:09:27.000 --> 00:09:31.000]   A talk called "Quit Social Media" will be posted by TED.
[00:09:31.000 --> 00:09:32.000]   That's what I want.
[00:09:32.000 --> 00:09:34.000]   So they went back, and they changed the talk back.
[00:09:34.000 --> 00:09:39.000]   And it sat there for a little while, and then it picked up steam, and then views really began to pile up,
[00:09:39.000 --> 00:09:43.000]   and it ended up -- it's not like it's the most popular TEDx talk of all time,
[00:09:43.000 --> 00:09:46.000]   but I think it's easily in the top 100 or top 50.
[00:09:46.000 --> 00:09:49.000]   All right, so that's what happened.
[00:09:49.000 --> 00:09:50.000]   And the question is, why did that happen?
[00:09:50.000 --> 00:09:55.000]   And one of the contentions I want to make is that if I had given that same talk two years earlier,
[00:09:55.000 --> 00:10:01.000]   no one would have cared, that the timing of that talk was just perfect,
[00:10:01.000 --> 00:10:07.000]   that sort of early in 2017 when I gave it was just perfect for this topic.
[00:10:07.000 --> 00:10:12.000]   And to understand that there's a little bit of history I think people don't always understand all of the details of.
[00:10:12.000 --> 00:10:18.000]   But what you have to understand is in the lead up to that point, so 2012 up through 2016,
[00:10:18.000 --> 00:10:23.000]   there was a lot of exuberance around social media.
[00:10:23.000 --> 00:10:28.000]   The general sense about social media from any sort of elite discourse was,
[00:10:28.000 --> 00:10:35.000]   this is a revolutionary technology that is a progressive force of good for the world.
[00:10:35.000 --> 00:10:37.000]   It's instigated the Arab Spring.
[00:10:37.000 --> 00:10:41.000]   It is supporting expression of groups that otherwise could not be expressed.
[00:10:41.000 --> 00:10:44.000]   This is a great technology.
[00:10:44.000 --> 00:10:46.000]   That was the general sense.
[00:10:46.000 --> 00:10:51.000]   During that period is when I began to build up a skepticism, not about the Internet,
[00:10:51.000 --> 00:10:54.000]   but about what I used to call social media universalism,
[00:10:54.000 --> 00:10:56.000]   the idea that we all needed to be using social media.
[00:10:56.000 --> 00:10:58.000]   I thought for most people this is not that great.
[00:10:58.000 --> 00:11:00.000]   Most people are not toppling governments.
[00:11:00.000 --> 00:11:04.000]   Most people are not bringing interesting new voices into the marketplace of ideas.
[00:11:04.000 --> 00:11:08.000]   Most people are looking at their phone three hours a day instead of doing things that are useful.
[00:11:08.000 --> 00:11:13.000]   These are purposefully addictive and the idea that we all have to be on where it's weird is a problem for society.
[00:11:13.000 --> 00:11:17.000]   And I began to make that critique and people thought I was insane.
[00:11:17.000 --> 00:11:20.000]   So the TEDx organizers tried to change the name of my talk.
[00:11:20.000 --> 00:11:24.000]   A couple years before, for example, I'd written an op-ed for the New York Times
[00:11:24.000 --> 00:11:29.000]   that argued that social media was not as important for young people's careers as they thought.
[00:11:29.000 --> 00:11:32.000]   And it created a furor.
[00:11:32.000 --> 00:11:38.000]   The New York Times actually had to commission a response op-ed the next week
[00:11:38.000 --> 00:11:42.000]   addressing my op-ed and saying, "This is wrong. Don't listen to it."
[00:11:42.000 --> 00:11:44.000]   People got mad about it.
[00:11:44.000 --> 00:11:47.000]   I went on a major national radio show in Canada to talk about it
[00:11:47.000 --> 00:11:49.000]   and they ambushed me 10 minutes into the interview.
[00:11:49.000 --> 00:11:53.000]   Here is a social media expert and an artist who uses social media to promote her work
[00:11:53.000 --> 00:11:55.000]   here to tell you that social media is important, right?
[00:11:55.000 --> 00:11:58.000]   Because it's so infuriated people don't even want to say that.
[00:11:58.000 --> 00:12:04.000]   There was a professor in this area here in DC who was frantically trying to get me to come debate him.
[00:12:04.000 --> 00:12:09.000]   He couldn't take that in a national publication someone had said social media is not important.
[00:12:09.000 --> 00:12:12.000]   That's what things was like and I was seen as eccentric.
[00:12:12.000 --> 00:12:15.000]   And that's where things were when that talk came out.
[00:12:15.000 --> 00:12:18.000]   All of that changed.
[00:12:18.000 --> 00:12:24.000]   All of that changed right around the time that that quit social media talk was released,
[00:12:24.000 --> 00:12:26.000]   which is why that timing was so good.
[00:12:26.000 --> 00:12:29.000]   And the reason it changed was politics.
[00:12:29.000 --> 00:12:35.000]   It was the 2016 presidential election here in America.
[00:12:35.000 --> 00:12:41.000]   And that election had a very unfortunate outcome for social media companies
[00:12:41.000 --> 00:12:47.000]   because they managed to upset all sides of the political spectrum.
[00:12:47.000 --> 00:12:52.000]   So I got the first inklings of this actually when I was promoting Deep Work in early 2016.
[00:12:52.000 --> 00:12:57.000]   When I would go on conservative radio shows or conservative podcasts,
[00:12:57.000 --> 00:13:01.000]   everyone was asking me about censorship on social media.
[00:13:01.000 --> 00:13:05.000]   And this was not something that was in my normal orbit.
[00:13:05.000 --> 00:13:07.000]   It's not something I'd heard about or encountered.
[00:13:07.000 --> 00:13:10.000]   It was not something that was being covered in sort of standard techno journalism.
[00:13:10.000 --> 00:13:12.000]   So I would get caught off guard by these questions.
[00:13:12.000 --> 00:13:14.000]   Like, I don't know what you're talking about.
[00:13:14.000 --> 00:13:18.000]   But already in the lead up to that election, the right was starting to get upset
[00:13:18.000 --> 00:13:21.000]   where they said when we look at what gets taken down and what doesn't,
[00:13:21.000 --> 00:13:28.000]   it all comes from a standard set of relatively far to the left political perspective.
[00:13:28.000 --> 00:13:30.000]   And I don't think this is surprising.
[00:13:30.000 --> 00:13:32.000]   These companies are based in Northern California.
[00:13:32.000 --> 00:13:36.000]   This is more of a--the political left is way more dominant there.
[00:13:36.000 --> 00:13:41.000]   But so the right started to get upset or skeptical about social media.
[00:13:41.000 --> 00:13:44.000]   And then the election happened and Donald Trump won.
[00:13:44.000 --> 00:13:49.000]   And it took a little while, about a half a year or so,
[00:13:49.000 --> 00:13:53.000]   but the left then began to get real upset about social media
[00:13:53.000 --> 00:13:56.000]   because of their role in helping Donald Trump win.
[00:13:56.000 --> 00:14:01.000]   So now you had the left start to get upset about social media as well.
[00:14:01.000 --> 00:14:04.000]   Now that's kind of a complicated story.
[00:14:04.000 --> 00:14:07.000]   If you really look at that story closely about what happened on the left,
[00:14:07.000 --> 00:14:13.000]   I think it's often portrayed as they saw specific harms that Facebook was doing
[00:14:13.000 --> 00:14:14.000]   and that's why they were upset.
[00:14:14.000 --> 00:14:16.000]   There's Cambridge Analytica.
[00:14:16.000 --> 00:14:19.000]   There was Russian misinformation.
[00:14:19.000 --> 00:14:22.000]   But really if you watch closer, what really happened with the left and social media
[00:14:22.000 --> 00:14:29.000]   is that most of, I would say, the mainstream sort of political and cultural voices
[00:14:29.000 --> 00:14:32.000]   entered a resistance mode after Donald Trump was elected.
[00:14:32.000 --> 00:14:35.000]   Like our goal, the point of our paper and what we're doing
[00:14:35.000 --> 00:14:37.000]   is there's an existential threat to our country.
[00:14:37.000 --> 00:14:38.000]   It's Donald Trump.
[00:14:38.000 --> 00:14:41.000]   And this is what we're trying to do is we're in resistance to that.
[00:14:41.000 --> 00:14:45.000]   And the social media companies, though politically they're to the left,
[00:14:45.000 --> 00:14:48.000]   didn't join that resistance mode.
[00:14:48.000 --> 00:14:51.000]   Zuckerberg, a couple years later, came to Georgetown,
[00:14:51.000 --> 00:14:54.000]   gave a speech about free speech online.
[00:14:54.000 --> 00:14:58.000]   They were trying to--they weren't supporting Donald Trump,
[00:14:58.000 --> 00:15:01.000]   but they were not ready to go full resistance mode.
[00:15:01.000 --> 00:15:04.000]   They weren't like, "We're fully on board. He's off the platforms.
[00:15:04.000 --> 00:15:08.000]   We're going to do what we need to do to make sure that we are helping preserve
[00:15:08.000 --> 00:15:10.000]   this vision of democracy." They didn't do it.
[00:15:10.000 --> 00:15:11.000]   They tried to go down the center.
[00:15:11.000 --> 00:15:14.000]   It was like during the French Revolution where you were the shopkeeper.
[00:15:14.000 --> 00:15:20.000]   You're like, "Look, I'm no fan of the king, but I also am not going to go to the Bastille."
[00:15:20.000 --> 00:15:23.000]   And, you know, your days are numbered at that point.
[00:15:23.000 --> 00:15:27.000]   The revolutionaries are going to see you as with a sort of bourgeois suspicion.
[00:15:27.000 --> 00:15:30.000]   And I think this was a big thing that happened.
[00:15:30.000 --> 00:15:33.000]   So there was sort of a tribal traitorousness that was going on here
[00:15:33.000 --> 00:15:36.000]   where the left was like, "You guys aren't fully on our team."
[00:15:36.000 --> 00:15:40.000]   And so a lot of those mechanisms turned against it.
[00:15:40.000 --> 00:15:43.000]   So now the left was really mad at these social media companies,
[00:15:43.000 --> 00:15:48.000]   and you had like the delete Facebook movement, and Zuckerberg became the devil.
[00:15:48.000 --> 00:15:53.000]   And now they had upset all sides, all sides of the political spectrum.
[00:15:53.000 --> 00:15:59.000]   And what that meant was for everyone else who maybe was not looking at these
[00:15:59.000 --> 00:16:06.000]   technologies purely through a political lens, this had had the effect of dislodging
[00:16:06.000 --> 00:16:10.000]   how these technologies were categorized in the cultural hive mind.
[00:16:10.000 --> 00:16:15.000]   It had dislodged them from exuberant cool new technologies to something that
[00:16:15.000 --> 00:16:17.000]   there's probably issues with, like these political issues.
[00:16:17.000 --> 00:16:20.000]   And once it was in a category where we acknowledged there could be issues with it,
[00:16:20.000 --> 00:16:24.000]   people that were far away from political concerns saw other issues with it.
[00:16:24.000 --> 00:16:28.000]   "My kids are using this too much. I'm on this too much. I don't really like this."
[00:16:28.000 --> 00:16:31.000]   It opened the floodgates to critique.
[00:16:31.000 --> 00:16:35.000]   So it took this particular political disruption to change our cultural
[00:16:35.000 --> 00:16:38.000]   categorization of social media, but once we changed it to something that was
[00:16:38.000 --> 00:16:42.000]   worthy of critique, we found a lot of critiques.
[00:16:42.000 --> 00:16:45.000]   And that was exactly the environment in which that video dropped.
[00:16:45.000 --> 00:16:48.000]   I think that's why it found an audience.
[00:16:48.000 --> 00:16:51.000]   It was perfectly timed to a cultural awakening where people said,
[00:16:51.000 --> 00:16:53.000]   "Let's start looking closer at social media."
[00:16:53.000 --> 00:16:56.000]   And it doesn't mean I was convincing them, but they were ready to hear an argument
[00:16:56.000 --> 00:17:02.000]   from my side. They were ready to watch a video that was titled "Quit Social Media."
[00:17:02.000 --> 00:17:08.000]   Because that suddenly became something that was at the very least comprehensible
[00:17:08.000 --> 00:17:13.000]   in a way that it wouldn't have been in 2015, the way it wouldn't have been in 2016.
[00:17:13.000 --> 00:17:15.000]   So I think that's the story behind that video.
[00:17:15.000 --> 00:17:22.000]   Now, reflecting on it today, how do I feel about the issues I talked about in that video?
[00:17:22.000 --> 00:17:27.000]   I would say I'm pretty optimistic. I'm pretty optimistic because, again,
[00:17:27.000 --> 00:17:34.000]   the foundation for my critique was my wariness of social media universalism.
[00:17:34.000 --> 00:17:39.000]   This idea that everyone had to use the same small number of platforms,
[00:17:39.000 --> 00:17:43.000]   and these were giant platform monopolies that were engineering highly
[00:17:43.000 --> 00:17:47.000]   addictive experiences, and I did not think it was good for the body politic.
[00:17:47.000 --> 00:17:50.000]   I don't think it was good for our culture that everyone had to be on Facebook
[00:17:50.000 --> 00:17:54.000]   and Twitter and Instagram, and we were all on there because I think for most people
[00:17:54.000 --> 00:17:58.000]   it probably causes more harm than good. Not that these were evil tools,
[00:17:58.000 --> 00:18:03.000]   but for most people the time it takes, the emotional labor it creates
[00:18:03.000 --> 00:18:06.000]   is not worth the minor distracting benefits.
[00:18:06.000 --> 00:18:09.000]   And the line I used to use back then is that I think social media,
[00:18:09.000 --> 00:18:13.000]   I don't think it should be banned, I think it should be like "Game of Thrones."
[00:18:13.000 --> 00:18:16.000]   Something that's pretty popular and has a pretty loyal following,
[00:18:16.000 --> 00:18:19.000]   but like most people don't care.
[00:18:19.000 --> 00:18:24.000]   There's also a lot of people that say, "I'm not going to want something with dragons."
[00:18:24.000 --> 00:18:27.000]   And I think we are actually starting to move towards that.
[00:18:27.000 --> 00:18:31.000]   I think in recent years, after this political disruption recategorized
[00:18:31.000 --> 00:18:38.000]   social media writ large, we are seeing a fragmentation of the social media universe.
[00:18:38.000 --> 00:18:43.000]   Facebook fell from favor. I mean, it was just relentlessly attacked
[00:18:43.000 --> 00:18:48.000]   from the left and the right. Twitter has never been super mainstream.
[00:18:48.000 --> 00:18:51.000]   It's incredibly influential, but most people aren't tweeting.
[00:18:51.000 --> 00:18:54.000]   Most people don't really care what's going on on Twitter.
[00:18:54.000 --> 00:18:56.000]   There was things like Snapchat that rose and are gone.
[00:18:56.000 --> 00:18:58.000]   We're in a moment now where TikTok has become really good,
[00:18:58.000 --> 00:19:02.000]   but we're not anymore in a moment where there's any one platform
[00:19:02.000 --> 00:19:06.000]   where it would be considered weird to not use.
[00:19:06.000 --> 00:19:10.000]   I was labeled a heretic for saying, "I don't use Facebook."
[00:19:10.000 --> 00:19:12.000]   There is no such platform today, no matter how popular,
[00:19:12.000 --> 00:19:16.000]   that people would think it's weird at all if I say I don't use it.
[00:19:16.000 --> 00:19:21.000]   TikTok is very popular. No one would bat an eye if you say, "I don't use TikTok."
[00:19:21.000 --> 00:19:22.000]   It's like, yeah, it's like Game of Thrones.
[00:19:22.000 --> 00:19:25.000]   Some people love it, and some people think dragons are kind of stupid.
[00:19:25.000 --> 00:19:28.000]   We get it. It's not a big deal.
[00:19:28.000 --> 00:19:31.000]   If you say, "Oh, I don't use Twitter," people are like, "Yeah, I get it.
[00:19:31.000 --> 00:19:36.000]   It's kind of toxic on there, anxiety-producing, like good for you."
[00:19:36.000 --> 00:19:37.000]   And I think that is a good thing.
[00:19:37.000 --> 00:19:39.000]   So what's going to come next in the world of social media?
[00:19:39.000 --> 00:19:42.000]   I just think more fragmentation. I mean, we have seen social media
[00:19:42.000 --> 00:19:47.000]   move away from being a tool to connect people into a tool of infinite scroll,
[00:19:47.000 --> 00:19:49.000]   distraction, algorithmically optimized.
[00:19:49.000 --> 00:19:52.000]   TikTok, for example, is just owning that better than anyone else.
[00:19:52.000 --> 00:19:59.000]   Forget anything else other than just let's touch your brainstem in 30-second burst.
[00:19:59.000 --> 00:20:02.000]   You're like, "Ooh, ah, ooh." Like, it's getting straight to the chase.
[00:20:02.000 --> 00:20:04.000]   It's not about connecting. It's not about creativity.
[00:20:04.000 --> 00:20:07.000]   It's not about finding interesting people. Let's just touch your brainstem.
[00:20:07.000 --> 00:20:11.000]   So once it's in a world of distraction, there are many sources of distraction.
[00:20:11.000 --> 00:20:14.000]   There's various social media platforms. There's podcasts.
[00:20:14.000 --> 00:20:17.000]   There's all these streaming services that are spending hundreds of billions of
[00:20:17.000 --> 00:20:21.000]   dollars to produce really good stuff. There's articles. There's newspapers.
[00:20:21.000 --> 00:20:24.000]   There's endless books. Like, there's endless things they're trying to provide
[00:20:24.000 --> 00:20:27.000]   distraction, and you can choose which ones are best for you.
[00:20:27.000 --> 00:20:30.000]   And maybe it's TikTok, or maybe it's podcasts, or maybe it's books.
[00:20:30.000 --> 00:20:32.000]   And, like, we're getting to a point where that's all fine.
[00:20:32.000 --> 00:20:36.000]   And that's what I wanted to see, a world in which there was a diversity
[00:20:36.000 --> 00:20:39.000]   of different technological tools and innovations coming and going,
[00:20:39.000 --> 00:20:43.000]   some getting popular, some falling. Trends come. Trends don't go.
[00:20:43.000 --> 00:20:47.000]   But we never had this sense of universalism. You have to use this one.
[00:20:47.000 --> 00:20:50.000]   We all have to be on that one.
[00:20:50.000 --> 00:20:54.000]   That was the world I was hoping for in that talk, and I think we're getting
[00:20:54.000 --> 00:20:57.000]   closer to be there. We're closer to be there.
[00:20:57.000 --> 00:21:03.000]   So we are in a better place in 2022 than we were in 2017, early 2017,
[00:21:03.000 --> 00:21:05.000]   when I was giving that talk.
[00:21:05.000 --> 00:21:09.000]   You know, at that point, I was making people nervous with the way I talked
[00:21:09.000 --> 00:21:13.000]   about social media. Today, I think I'm probably seen as being too centrist
[00:21:13.000 --> 00:21:17.000]   on social media because I'm not part of the -- both the right and the left
[00:21:17.000 --> 00:21:20.000]   is out for blood. You are our tribal enemy, and we will destroy you.
[00:21:20.000 --> 00:21:24.000]   And I'm not pitchforking. I'm just saying, like, hey, maybe don't use Facebook.
[00:21:24.000 --> 00:21:28.000]   And I think that is probably a good switch of affairs.
[00:21:28.000 --> 00:21:32.000]   So quit social media. I don't care if you do or you don't, but I'm just glad
[00:21:32.000 --> 00:21:37.000]   that if you do, very few people are going to care.
[00:21:37.000 --> 00:21:43.000]   That's my reflection on that talk.
[00:21:43.000 --> 00:21:49.000]   So there you go, Jesse. Looking back at it.
[00:21:49.000 --> 00:21:53.000]   >> The Internet says it was September 19, 2016.
[00:21:53.000 --> 00:21:54.000]   >> Oh, okay. >> In Tysons.
[00:21:54.000 --> 00:21:57.000]   >> Oh, so '16. That makes sense. Summer of 2016, probably.
[00:21:57.000 --> 00:21:59.000]   >> Yeah, September 19, so right after.
[00:21:59.000 --> 00:22:02.000]   All right. 2016. That makes more sense.
[00:22:02.000 --> 00:22:05.000]   So it was like -- it took a little while for all this to sink in.
[00:22:05.000 --> 00:22:11.000]   Like that op-ed I wrote for the Times that generated all that furor was the week
[00:22:11.000 --> 00:22:14.000]   after the presidential election. So at that point, it was still like,
[00:22:14.000 --> 00:22:18.000]   what do you mean social media is awesome? It really took another year before
[00:22:18.000 --> 00:22:21.000]   Cambridge Analytica, I think, helped did this.
[00:22:21.000 --> 00:22:26.000]   There was this general upswelling of, wait a second, the Russian misinformation.
[00:22:26.000 --> 00:22:31.000]   All of that took a while to get going. So even when I gave that talk in 2016,
[00:22:31.000 --> 00:22:35.000]   it was still eccentric. By 2017, people were like, yeah,
[00:22:35.000 --> 00:22:38.000]   we don't like social media anymore. So it's funny how that shifted.
[00:22:38.000 --> 00:22:41.000]   Do you remember Cambridge Analytica? >> Yeah.
[00:22:41.000 --> 00:22:49.000]   >> This is an interesting example. The way that was pitched to people
[00:22:49.000 --> 00:22:55.000]   was basically that there was a Bond villain in a hollowed-out volcano
[00:22:55.000 --> 00:23:00.000]   that was on like a secret laser phone to Donald Trump,
[00:23:00.000 --> 00:23:04.000]   perpetuating like this giant heist. But the reality was what they were doing
[00:23:04.000 --> 00:23:07.000]   at Cambridge Analytica was the business model of Facebook.
[00:23:07.000 --> 00:23:10.000]   It was what like everyone was doing, political or not.
[00:23:10.000 --> 00:23:13.000]   Like that's how Facebook actually worked.
[00:23:13.000 --> 00:23:17.000]   And like they had just started -- there's no real crime committed there
[00:23:17.000 --> 00:23:20.000]   other than they maybe had just started to change their terms of service
[00:23:20.000 --> 00:23:22.000]   like a few months before or something like that.
[00:23:22.000 --> 00:23:24.000]   And that was not some unusual use of Facebook.
[00:23:24.000 --> 00:23:27.000]   Like that's what Facebook -- that's why it was so profitable.
[00:23:27.000 --> 00:23:30.000]   You could go in and scrape all this information and target people or whatever.
[00:23:30.000 --> 00:23:36.000]   And my contention is that like Facebook saw the danger of people recognizing
[00:23:36.000 --> 00:23:41.000]   like this is what we do. You do the personality test,
[00:23:41.000 --> 00:23:46.000]   and we steal your whole contact network and use that to like target ads to everyone.
[00:23:46.000 --> 00:23:49.000]   Like they're like, we don't want people realizing that.
[00:23:49.000 --> 00:23:52.000]   And they leaned in heavy that like, oh, this was some sort of unusual
[00:23:52.000 --> 00:23:56.000]   or exceptional crime that occurred. Like, oh, this Cambridge Analytica
[00:23:56.000 --> 00:24:00.000]   was some mastermind bond criminal like broke into the data safe
[00:24:00.000 --> 00:24:04.000]   and was doing things. And so they were trying to desperately, I believe,
[00:24:04.000 --> 00:24:08.000]   they did not want the story out there that was like Cambridge Analytica
[00:24:08.000 --> 00:24:11.000]   reveals the extent to this is what Facebook is.
[00:24:11.000 --> 00:24:14.000]   It's stealing all this data. And so they were very successful,
[00:24:14.000 --> 00:24:17.000]   I think, at the time in making it seem like it was an exceptional case.
[00:24:17.000 --> 00:24:21.000]   And the only real thing exceptional about it was like its scale was very large.
[00:24:21.000 --> 00:24:26.000]   So it was a large number of people. But that was a standard academic research
[00:24:26.000 --> 00:24:30.000]   study play of like personality tests to scrape data to target people with ads.
[00:24:30.000 --> 00:24:32.000]   I mean, it was like the whole business model around Facebook.
[00:24:32.000 --> 00:24:35.000]   So I really think they leaned in there trying to make it about like people
[00:24:35.000 --> 00:24:38.000]   doing something unusual or exceptionally bad.
[00:24:38.000 --> 00:24:43.000]   And I think because, again, I think that was something that Facebook felt like
[00:24:43.000 --> 00:24:47.000]   we can play on that ground to be OK. We can say like Cambridge Analytica
[00:24:47.000 --> 00:24:51.000]   was an exceptional instance. We're working on privacy. So that can't happen again
[00:24:51.000 --> 00:24:54.000]   and distract people from the fact that like that's what their business model was.
[00:24:54.000 --> 00:24:56.000]   But it didn't work because of the political anger.
[00:24:56.000 --> 00:24:59.000]   So even though they were like, yeah, we agree Cambridge Analytica is bad
[00:24:59.000 --> 00:25:03.000]   and we're going to change our privacy laws, the sort of you were not enough
[00:25:03.000 --> 00:25:07.000]   on our side post Trump, I think still numbered them.
[00:25:07.000 --> 00:25:10.000]   Their days were still numbered. The media was going to be done with them.
[00:25:10.000 --> 00:25:13.000]   It was like they tried to create a villain that they could be like,
[00:25:13.000 --> 00:25:15.000]   yeah, we're on your side. We got to go after those people.
[00:25:15.000 --> 00:25:16.000]   We don't know what they were doing.
[00:25:16.000 --> 00:25:20.000]   We definitely did not encourage exactly that behavior for like hundreds of clients.
[00:25:20.000 --> 00:25:26.000]   They tried that and it didn't work because, you know, the damage had been done.
[00:25:26.000 --> 00:25:30.000]   So there you go. Zuckerberg's on the two. He's on the podcast tour.
[00:25:30.000 --> 00:25:34.000]   Yeah, I listen to his Ferris and Lex Lex Ferris.
[00:25:34.000 --> 00:25:38.000]   Yeah. Has he answered our invitations yet?
[00:25:38.000 --> 00:25:40.000]   He wants to talk to you directly. He wants to play golf with you.
[00:25:40.000 --> 00:25:46.000]   Yeah. Can you imagine Mark Zuckerberg coming to the Deep Work HQ?
[00:25:46.000 --> 00:25:50.000]   Don't worry, Mark, that smell is the grease trap of the kitchen below us.
[00:25:50.000 --> 00:25:56.000]   It's not not me. Oh, man. No, I don't think I don't think that go well.
[00:25:56.000 --> 00:26:00.000]   All right. A couple ads. They get into some questions.
[00:26:00.000 --> 00:26:04.000]   I want to talk about workable.
[00:26:04.000 --> 00:26:09.000]   So here's the thing. Companies need to hire people, need to hire good people.
[00:26:09.000 --> 00:26:12.000]   That is how your company grows.
[00:26:12.000 --> 00:26:24.000]   This podcast was stuck until I kidnapped Jesse and locked him up in the HQ so that we could actually make progress on this show without me getting lost trying to make computer videos work or something like this.
[00:26:24.000 --> 00:26:28.000]   And so we know from first person experience, hiring the right people is critical.
[00:26:28.000 --> 00:26:31.000]   It's just hard to do it.
[00:26:31.000 --> 00:26:35.000]   This is where workable enters the scene.
[00:26:35.000 --> 00:26:39.000]   It can accelerate every step of your hiring process from fine to hire.
[00:26:39.000 --> 00:26:47.000]   It will help you first cast the widest net possible and posting your job will post it to all of the top job boards with one click.
[00:26:47.000 --> 00:26:52.000]   It then has modern tools to take the unnecessary administrative overhead out of the interview process.
[00:26:52.000 --> 00:26:56.000]   Online video interview tools integrated directly.
[00:26:56.000 --> 00:27:01.000]   E-signatures integrated directly.
[00:27:01.000 --> 00:27:08.000]   Even tasks like the interview scheduling can be automated so you can focus on just talking to the people and finding the people you need.
[00:27:08.000 --> 00:27:15.000]   So whether you're hiring for your coffee shop or your engineering team, workable is exactly what you need to hire the right people fast.
[00:27:15.000 --> 00:27:19.000]   You can start hiring today with a risk free 15 day trial.
[00:27:19.000 --> 00:27:23.000]   If you hire someone during the free trial, that's free.
[00:27:23.000 --> 00:27:26.000]   It's not going to cost you a thing. They're not going to charge you for that.
[00:27:26.000 --> 00:27:30.000]   So just go to workable.com/podcast to start hiring.
[00:27:30.000 --> 00:27:34.000]   Workable is hiring made easy.
[00:27:34.000 --> 00:27:36.000]   Making things easy is good.
[00:27:36.000 --> 00:27:38.000]   Let me tell you another way to make things easy.
[00:27:38.000 --> 00:27:42.000]   That is with policy genius.
[00:27:42.000 --> 00:27:44.000]   All right.
[00:27:44.000 --> 00:27:51.000]   So policy genius is going to help you get life insurance at better prices.
[00:27:51.000 --> 00:27:52.000]   Why does this matter?
[00:27:52.000 --> 00:27:59.000]   Well, you know you need life insurance, but you don't want to spend too much on it.
[00:27:59.000 --> 00:28:03.000]   Policy genius will help you find a policy at a much cheaper price.
[00:28:03.000 --> 00:28:10.000]   You can have that peace of mind that life insurance gives you without paying too much for it.
[00:28:10.000 --> 00:28:21.000]   I mean, as Jesse knows, we have a 15 million dollar life insurance policy on his head because if he's not here, we can't produce the show.
[00:28:21.000 --> 00:28:24.000]   And if we can't produce the show, there would be a massive economic hit.
[00:28:24.000 --> 00:28:28.000]   So we have a 15 million dollar life insurance policy on his head.
[00:28:28.000 --> 00:28:32.000]   It is also why I keep suggesting incredibly dangerous shoots.
[00:28:32.000 --> 00:28:34.000]   Like, here's what we're going to do, Jesse.
[00:28:34.000 --> 00:28:39.000]   I want you to be dangling from the roof, holding the camera while I walk below,
[00:28:39.000 --> 00:28:44.000]   and then you've got to jump from the roof, filming me, and then land on that trampoline.
[00:28:44.000 --> 00:28:50.000]   That would be funny if your hiring was all part of just an elaborate insurance scheme.
[00:28:50.000 --> 00:28:54.000]   But if we did need a 15 million dollar life insurance, I would not just go to a random website.
[00:28:54.000 --> 00:28:56.000]   I would go to Policy Genius first.
[00:28:56.000 --> 00:28:57.000]   Here's how it works.
[00:28:57.000 --> 00:29:02.000]   It's a one-stop shop to find the insurance at the right price.
[00:29:02.000 --> 00:29:08.000]   You click, you go to policygenius.com, you answer a few questions.
[00:29:08.000 --> 00:29:15.000]   In minutes, you will be able to compare personalized quotes from top companies and see which price is lowest.
[00:29:15.000 --> 00:29:20.000]   You could save 50% or more on life insurance by comparing quotes with Policy Genius.
[00:29:20.000 --> 00:29:22.000]   Don't just go to a random website.
[00:29:22.000 --> 00:29:25.000]   Use Policy Genius. It's going to be significantly cheaper.
[00:29:25.000 --> 00:29:29.000]   The team of licensed experts at Policy Genius are on hand throughout the entire process
[00:29:29.000 --> 00:29:32.000]   to help you understand your options and make your decisions with confidence.
[00:29:32.000 --> 00:29:35.000]   They work for you, not the insurance companies.
[00:29:35.000 --> 00:29:38.000]   So whether you're starting the shop or have questions,
[00:29:38.000 --> 00:29:43.000]   you have independent advocates offering unbiased advice.
[00:29:43.000 --> 00:29:48.000]   These are the advocates that told me that maybe 15 million dollar policy was a little excessive for you, Jesse.
[00:29:48.000 --> 00:29:51.000]   So I'm glad Policy Genius had them there.
[00:29:51.000 --> 00:29:54.000]   They don't add extra fees. They don't sell your info.
[00:29:54.000 --> 00:29:57.000]   Thousands of five-star reviews.
[00:29:57.000 --> 00:29:59.000]   Policy Genius is the place to get your life insurance.
[00:29:59.000 --> 00:30:08.000]   So head to policygenius.com to get your free life insurance quotes and see how much you could save.
[00:30:08.000 --> 00:30:11.000]   All right. Just save the people some money.
[00:30:11.000 --> 00:30:17.000]   Now let's give them some questions.
[00:30:17.000 --> 00:30:19.000]   What do we got here?
[00:30:19.000 --> 00:30:22.000]   Here's a question. All right.
[00:30:22.000 --> 00:30:27.000]   First question here comes from Shankara, who asks,
[00:30:27.000 --> 00:30:31.000]   "Does career capital assume meritocracy?
[00:30:31.000 --> 00:30:37.000]   I wonder if there can be societies or organizations that because they're not meritocratic,
[00:30:37.000 --> 00:30:46.000]   for whatever reason, are not suitable for the practice of ideas such as career capital, deep work, and deliberate practice."
[00:30:46.000 --> 00:30:52.000]   Well, as a brief summary, career capital theory is a theory I lay out in my 2012 book,
[00:30:52.000 --> 00:30:55.000]   "So Good They Can't Ignore You,"
[00:30:55.000 --> 00:31:00.000]   and is a theory about how to cultivate a career that you really enjoy,
[00:31:00.000 --> 00:31:02.000]   a career that can be a source of meaning and satisfaction.
[00:31:02.000 --> 00:31:09.000]   And the basic idea is that it treats the job market like an economic market.
[00:31:09.000 --> 00:31:12.000]   So the attributes that make great jobs great are rare and valuable.
[00:31:12.000 --> 00:31:16.000]   So if you want those, you have to have something rare and valuable to offer in return.
[00:31:16.000 --> 00:31:19.000]   And so when it comes to thinking about how to build a great career,
[00:31:19.000 --> 00:31:23.000]   instead of obsessing over just match theory, what am I meant to do?
[00:31:23.000 --> 00:31:25.000]   And if I can match that to my job, I'll be happy.
[00:31:25.000 --> 00:31:27.000]   You instead see it more economically.
[00:31:27.000 --> 00:31:33.000]   What rare and valuable skills can I build up and I could then use as leverage to get into my career?
[00:31:33.000 --> 00:31:40.000]   Things are going to make my career even better to move it towards attributes that resonate away from things that are a drag.
[00:31:40.000 --> 00:31:44.000]   And I call these rare and valuable skills career capital.
[00:31:44.000 --> 00:31:48.000]   Build capital, invest it to make your job better.
[00:31:48.000 --> 00:31:54.000]   I think you're on to something, Shakara, that this assumes, right,
[00:31:54.000 --> 00:32:01.000]   this model sort of assumes a job market that does operate largely like an open economic market,
[00:32:01.000 --> 00:32:05.000]   where you're essentially bartering for cool things in your job with cooler skills.
[00:32:05.000 --> 00:32:10.000]   There are contexts that are much less meritocratic in that way.
[00:32:10.000 --> 00:32:19.000]   There's context, for example, in which connections or seniority plays the primary role in advancement or jobs openings,
[00:32:19.000 --> 00:32:24.000]   context where jobs are appointed and there's sort of political concerns that happen there.
[00:32:24.000 --> 00:32:30.000]   And so I think in those contexts, straight up career capital theory, you were right, is not going to apply as well.
[00:32:30.000 --> 00:32:34.000]   And I talk about that in So Good They Can't Ignore You a little bit more broadly.
[00:32:34.000 --> 00:32:39.000]   I say you have to evaluate the general field you're going into.
[00:32:39.000 --> 00:32:44.000]   You have to evaluate it and say, is this a place in which I can build capital?
[00:32:44.000 --> 00:32:49.000]   And if and when I do build capital, have a lot of options to invest it to make my career better?
[00:32:49.000 --> 00:32:53.000]   And you have to do that assessment because if the answer is no, you have to be wary.
[00:32:53.000 --> 00:32:58.000]   And so you're pointing out that if you're going into a field or organization that's not meritocratic in that way,
[00:32:58.000 --> 00:33:03.000]   when you do that assessment, you're going to come away with the conclusion is that even if I get really good at things here,
[00:33:03.000 --> 00:33:06.000]   it's not going to give me much control over my job or what I do.
[00:33:06.000 --> 00:33:09.000]   You would be wary about that particular field.
[00:33:09.000 --> 00:33:14.000]   The example I gave in So Good They Can't Ignore You was actually law.
[00:33:14.000 --> 00:33:17.000]   I talked about if you're going to become a partner at a large law firm.
[00:33:17.000 --> 00:33:24.000]   This is an example of a place where if you get very good at your skills, you don't actually have a lot of options.
[00:33:24.000 --> 00:33:28.000]   It doesn't open up a lot of options for you. It's very prescribed.
[00:33:28.000 --> 00:33:32.000]   If you practice the law really well in a major firm,
[00:33:32.000 --> 00:33:37.000]   the only real thing you can get out of that is to move up to partner and then the equity partner status.
[00:33:37.000 --> 00:33:42.000]   So you can move up in your status and your income, but it does not give you more control.
[00:33:42.000 --> 00:33:45.000]   It does not give you more options over what your career faces.
[00:33:45.000 --> 00:33:51.000]   So that's a place you might be wary. Whereas, let's say you're trying to build up career capital in computer programming.
[00:33:51.000 --> 00:33:55.000]   There's a lot of different ways you can express that capital. I can do part time. I can start my own company.
[00:33:55.000 --> 00:34:02.000]   I can be a consultant. I can, like the case study of Lulu in that book, work for six months, take six months off.
[00:34:02.000 --> 00:34:06.000]   It's a valuable skill that can be deployed in many different ways.
[00:34:06.000 --> 00:34:13.000]   And so I think this is a similar thing. Be wary of the field you're going into before you enter that field and ask the question.
[00:34:13.000 --> 00:34:18.000]   If and when I get really good at things that are invaluable, will this open up a lot of interesting opportunities?
[00:34:18.000 --> 00:34:24.000]   Or am I relatively stuck regardless of what I do?
[00:34:24.000 --> 00:34:30.000]   All right. We got a question here from Adrienne.
[00:34:30.000 --> 00:34:39.000]   Who asked, is there a middle ground between shallow and deep work?
[00:34:39.000 --> 00:34:43.000]   She goes on to say, I love your book, Deep Work. It's amazing.
[00:34:43.000 --> 00:34:51.000]   But I struggle to apply deep work to the corporate world because let's face it, deep work is hard to find and the concept is foreign to most.
[00:34:51.000 --> 00:34:58.000]   Is there a middle ground where you are in a focus state? Something I would hesitate to call deep.
[00:34:58.000 --> 00:35:07.000]   I am a professional CPA, for example. We do professional work, but I rarely see earth shattering thinking coming out of a CPA's work.
[00:35:07.000 --> 00:35:13.000]   So, Adrienne, this is another one of those cases where we have to be careful about semantics.
[00:35:13.000 --> 00:35:22.000]   So a lot of the issues we have on the show, or a lot of my answers, have to do with redefining terms away from their original definition.
[00:35:22.000 --> 00:35:34.000]   I think what you're doing here is you're taking the word deep from the phrase deep work, and you were defining that to mean of profound importance or impact.
[00:35:34.000 --> 00:35:40.000]   So you have redefined deep work in this question to be work that is of profound importance or impact.
[00:35:40.000 --> 00:35:45.000]   You're saying, you know, my CPA work, it's hard, but it's not of profound importance or impact.
[00:35:45.000 --> 00:35:52.000]   It's not of whatever, in the weeds, sort of numerical, kind of detail oriented. It's not changing the world.
[00:35:52.000 --> 00:35:58.000]   My counter argument is that's not what I mean by deep work. For me, deep work is very functional.
[00:35:58.000 --> 00:36:04.000]   It means if you are doing something cognitively demanding, give it your full focus and don't context switch.
[00:36:04.000 --> 00:36:11.000]   And in fact, if you can train giving things your full focus and you're careful not to context switch, you're going to be able to do that work better and faster.
[00:36:11.000 --> 00:36:15.000]   Deep focus is a skill to be deployed in knowledge work, and it's something we should take seriously.
[00:36:15.000 --> 00:36:21.000]   That's what deep work means. There's no actual moralistic judgment of whether the outcomes of the work is important or profound.
[00:36:21.000 --> 00:36:24.000]   That's a separate issue. I think that's a deep life issue.
[00:36:24.000 --> 00:36:29.000]   What am I doing with the craft portion of my life? What role does it play in a deep life, etc.?
[00:36:29.000 --> 00:36:34.000]   That's a deep life issue. But deep work is all about concentration and avoiding context shifting.
[00:36:34.000 --> 00:36:40.000]   So yes, CPA work is cognitively demanding. It is best done in a state of focus without context shifting.
[00:36:40.000 --> 00:36:42.000]   It's one thing at a time before moving on to the next.
[00:36:42.000 --> 00:36:48.000]   You're going to burn out less quickly. You're going to produce better work. It's going to take less time.
[00:36:48.000 --> 00:36:54.000]   So we don't need a middle ground between deep work and shallow work, at least not for this issue.
[00:36:54.000 --> 00:37:00.000]   I think, again, where you're thinking is more a deep life question.
[00:37:00.000 --> 00:37:04.000]   Can you build a deep life in which your craft is something that's not particularly profound or important?
[00:37:04.000 --> 00:37:14.000]   And I think absolutely yes. There's all sorts of configurations for the deep life, and not all of them are built around some profound professional craft.
[00:37:14.000 --> 00:37:24.000]   So hopefully that helps clarify the semantics. We can move our way, can navigate our way easier.
[00:37:24.000 --> 00:37:27.000]   All right, let's move on. We got another A name here.
[00:37:27.000 --> 00:37:36.000]   Anna. Anna asks, which focus principles for deep work can I automate at scale?
[00:37:36.000 --> 00:37:43.000]   I have 100,000 or more employees that I manage or work with.
[00:37:43.000 --> 00:37:51.000]   I work with internal productivity tools at a large tech company with over 100,000 employees.
[00:37:51.000 --> 00:38:02.000]   For highest impact with the least friction, which principles for deep work should I build into our internal tools that need to be adopted at scale?
[00:38:02.000 --> 00:38:08.000]   Which principles should I advocate for at a cultural level with leadership?
[00:38:08.000 --> 00:38:13.000]   So, Anna, you work on productivity for a tech company with 100,000 or more employees.
[00:38:13.000 --> 00:38:22.000]   Advice number one, if this company is Facebook, don't tell, don't advocate the leadership that these principles came from me.
[00:38:22.000 --> 00:38:29.000]   I don't think that's going to help your cause. In fact, don't mention deep work, I would say, if you're at Facebook.
[00:38:29.000 --> 00:38:36.000]   Again, this is a place where dropping my name is probably not going to be your, probably be your best strategy.
[00:38:36.000 --> 00:38:45.000]   But here's my general answer for you. It's let's stop thinking about tools for now.
[00:38:45.000 --> 00:38:56.000]   I think this is a common techno solutionism framework that people have in tech, which is the right tool will engender the right way of working.
[00:38:56.000 --> 00:39:03.000]   You improve work by introducing better tools. I think that gets it backwards.
[00:39:03.000 --> 00:39:10.000]   I think if you go back, let's say, to the River, the Rouge River, Henry Ford plant in 1910, pre-assembly line,
[00:39:10.000 --> 00:39:15.000]   and you look at this thing and you're standing there with Henry and you say, how are we going to make this more productive?
[00:39:15.000 --> 00:39:19.000]   How are we going to produce more cars with the same amount of resources?
[00:39:19.000 --> 00:39:24.000]   His answer would not have been, we need a better tool. We need a better car building tool.
[00:39:24.000 --> 00:39:29.000]   And if someone invents a better car building tool, then we are going to be able to build cars faster.
[00:39:29.000 --> 00:39:34.000]   That's not what he did. Instead, he invented a whole new process for producing cars,
[00:39:34.000 --> 00:39:39.000]   a process based on the continual motion assembly line. Now, the actual tools required to implement this,
[00:39:39.000 --> 00:39:43.000]   most of them were things that already existed. He deployed existing technologies to implement it.
[00:39:43.000 --> 00:39:51.000]   And in some cases he had to invent custom tools where they did not exist, but the tools came second.
[00:39:51.000 --> 00:39:59.000]   So one of the things he invented was this surrounding drill press that could drill, I forgot what the count was,
[00:39:59.000 --> 00:40:03.000]   something like 18 different holes at the same time into an engine block.
[00:40:03.000 --> 00:40:10.000]   So the engine block would come to a station on the assembly line and this thing would come around it
[00:40:10.000 --> 00:40:16.000]   and drill 18 precision holes simultaneously. They had to invent that. That did not exist.
[00:40:16.000 --> 00:40:21.000]   And there'd be no reason for that to exist before the assembly line because what's the rush?
[00:40:21.000 --> 00:40:24.000]   It's going to take us three days to build this car. I can drill the holes as I need them.
[00:40:24.000 --> 00:40:28.000]   But if you're on a continuous motion assembly line, like we got 30 seconds to drill these holes.
[00:40:28.000 --> 00:40:32.000]   But the point is they invented that thing because they needed it after they came up with the new process.
[00:40:32.000 --> 00:40:38.000]   It was not like Henry Ford was sitting around saying, man, how can we produce cars faster?
[00:40:38.000 --> 00:40:42.000]   And then one of his engineers came in and was like, Henry, I just invented a machine that can drill 18 holes
[00:40:42.000 --> 00:40:47.000]   simultaneously into the engine block. He's like, oh man, with this tool, we will now build an assembly line.
[00:40:47.000 --> 00:40:53.000]   It came second. And that's what I think needs to happen in knowledge work.
[00:40:53.000 --> 00:40:58.000]   You need better processes for how the standard work that happens on a regular basis gets done.
[00:40:58.000 --> 00:41:05.000]   Once you have those processes, then you can ask the question, what tools do we need to implement this new process?
[00:41:05.000 --> 00:41:09.000]   Now, how do you design these processes? Well, the idea I talk about in my most recent book,
[00:41:09.000 --> 00:41:18.000]   A World Without Email, is that the main thing you want to avoid in knowledge work is context shifts.
[00:41:18.000 --> 00:41:23.000]   The more people have to shift their cognitive context from one point of focus to another,
[00:41:23.000 --> 00:41:29.000]   the more attention residue you're creating, which means the more you're lowering their cognitive capacity,
[00:41:29.000 --> 00:41:33.000]   the more you're creating this frustrating cognitive friction, and the quicker you're going to burn people out.
[00:41:33.000 --> 00:41:36.000]   They're going to produce worse work slower and get burnt out.
[00:41:36.000 --> 00:41:44.000]   The optimal way to work is on one thing at a time until you reach a stopping point with a generous buffer to transition to the next thing.
[00:41:44.000 --> 00:41:47.000]   So when you're thinking about processes to make people more productive,
[00:41:47.000 --> 00:41:52.000]   what you really should be thinking about is processes to reduce context shifting.
[00:41:52.000 --> 00:42:00.000]   And so how do you measure that? Well, I argue in A World Without Email that the most convenient proxy for context shifts,
[00:42:00.000 --> 00:42:08.000]   if you say here's our new way for collaborating on producing a report, here's our new process for producing a new code feature.
[00:42:08.000 --> 00:42:14.000]   The best proxy for measuring how much context shifting is this process going to create,
[00:42:14.000 --> 00:42:26.000]   is to instead ask a related question, on average, how many unscheduled messages am I going to have to see and reply to in order to complete this objective?
[00:42:26.000 --> 00:42:30.000]   Whether they're coming in email, whether they're coming on Slack, whether they're coming on Teams.
[00:42:30.000 --> 00:42:36.000]   How many unscheduled messages will I have to see and respond to as part of actually finishing this objective?
[00:42:36.000 --> 00:42:42.000]   Now, the reason why that's the best proxy for context shifting is this is the major source of context shifts in modern knowledge work,
[00:42:42.000 --> 00:42:49.000]   is the need to monitor ongoing back and forth conversations happening in email, happening in Slack, happening in Teams.
[00:42:49.000 --> 00:42:55.000]   We have asynchronous back and forth conversation happening that requires you to see messages that are going to come at unpredictable times and need a response.
[00:42:55.000 --> 00:42:58.000]   This requires you to check inboxes and channels all the time.
[00:42:58.000 --> 00:43:04.000]   Those checks generate most of the context shifts that are destroying us, cognitively speaking, as knowledge workers.
[00:43:04.000 --> 00:43:07.000]   So if you want to compare process A to process B for the same objective,
[00:43:07.000 --> 00:43:13.000]   say which one is going to require less unscheduled messages that need a response?
[00:43:13.000 --> 00:43:20.000]   And so maybe you say, you know what, instead of just rock and rolling on email and going back and forth to gather feedback to finish this report,
[00:43:20.000 --> 00:43:26.000]   we're going to set up a process where we have a shared folder where the report goes in on Monday
[00:43:26.000 --> 00:43:30.000]   and everyone's feedback has to go into this Google Doc by Wednesday, close of business.
[00:43:30.000 --> 00:43:33.000]   Thursday, I write the first draft.
[00:43:33.000 --> 00:43:37.000]   Friday morning, it is open for people to look at.
[00:43:37.000 --> 00:43:41.000]   I have office hours Friday afternoon. You come to my office hours if you have any questions.
[00:43:41.000 --> 00:43:46.000]   I always have a half hour right after those office hours to polish the document with people's feedback.
[00:43:46.000 --> 00:43:52.000]   The designer knows whatever they see in that Dropbox folder at the end of Friday, they can format and post.
[00:43:52.000 --> 00:43:57.000]   Like that is a process that requires no unscheduled messages that need to be responded to.
[00:43:57.000 --> 00:44:01.000]   And so that would be better than another process where you say, let's not get weighed down with this, guys.
[00:44:01.000 --> 00:44:05.000]   Just hit me up on Slack when it's ready and I will go back and forth.
[00:44:05.000 --> 00:44:09.000]   I can ask you questions if I have questions and I'll let the designer know via email when it's ready.
[00:44:09.000 --> 00:44:13.000]   That would be easier. But who cares about easy?
[00:44:13.000 --> 00:44:16.000]   The assembly line was a huge pain. That wasn't easy.
[00:44:16.000 --> 00:44:19.000]   But it produced cars to next faster. Same thing with this.
[00:44:19.000 --> 00:44:22.000]   That scenario A requires less unscheduled messages. So it's a pain.
[00:44:22.000 --> 00:44:25.000]   Who cares? That's less context shifting. That's better.
[00:44:25.000 --> 00:44:30.000]   So that's how I think about designing better processes in knowledge work.
[00:44:30.000 --> 00:44:36.000]   It's all about reducing context shifts. Unscheduled messages is a great proxy for that metric.
[00:44:36.000 --> 00:44:39.000]   So Anna, that's what needs to happen.
[00:44:39.000 --> 00:44:42.000]   Here are the things we do again and again in the various teams at our company.
[00:44:42.000 --> 00:44:51.000]   How can we work with each team and from the ground up create agreed upon processes for each of these things that minimizes this unscheduled messages that need answering?
[00:44:51.000 --> 00:44:54.000]   Then you can say, what tools do we need to support these processes?
[00:44:54.000 --> 00:45:01.000]   And I'll tell you what, 90% of the time it's going to be some combination of like Google Docs and email and maybe Dropbox.
[00:45:01.000 --> 00:45:06.000]   It's not going to be some fancy tool. Maybe you'll have a Trello in there every once in a while.
[00:45:06.000 --> 00:45:10.000]   5% of the time, maybe you need some more fancy tool. You have to develop something from scratch.
[00:45:10.000 --> 00:45:14.000]   That's like we'll get there when we get there. And most of the tools we need exist.
[00:45:14.000 --> 00:45:19.000]   Most of the technology existed to build the assembly line. It was just a matter of thinking this is how we're going to organize work.
[00:45:19.000 --> 00:45:23.000]   The same has to happen with knowledge work. So let's stop obsessing about tools.
[00:45:23.000 --> 00:45:27.000]   Let's not let tools be the tail that wags the knowledge work dog.
[00:45:27.000 --> 00:45:36.000]   Fix the processes that make sense for our brain and then and only then ask, what tech do we need to actually implement them?
[00:45:36.000 --> 00:45:44.000]   There we go. I read more about Henry Ford in the assembly line than anyone mad needs to.
[00:45:44.000 --> 00:45:48.000]   I was researching a world without email. For whatever reason, I just went down that rabbit hole.
[00:45:48.000 --> 00:45:52.000]   I'm not surprised because you bring it up a lot. So you can just tell it's in the back of your mind.
[00:45:52.000 --> 00:45:55.000]   Yeah, it's taking up a lot of space in there.
[00:45:55.000 --> 00:46:04.000]   To be quite honest, though, it's kind of cool because I have a few friends who are like coaches and they always talk about how, you know, players at all levels need to be constantly coached.
[00:46:04.000 --> 00:46:09.000]   And I hear you like your explanation about it all the time. I pick up more and more about.
[00:46:09.000 --> 00:46:16.000]   The you know how you're bringing it together. Yeah, you got to come back to it and you come back to things from different angles and I clarify.
[00:46:16.000 --> 00:46:25.000]   I mean, that's kind of one of the cool things about this show is if you listen to it for a while, you can see my thoughts refining on topics because we come back at it from different angles again and again.
[00:46:25.000 --> 00:46:36.000]   And I start to refine and sand off the rough edges and find the consistent themes and it's thinking shown live real time.
[00:46:36.000 --> 00:46:40.000]   Yeah, so I do elements like.
[00:46:40.000 --> 00:46:44.000]   All right, so we got a question here from Fiona.
[00:46:44.000 --> 00:46:52.000]   Oh, this looks like Jesse put this question in to see if he could get me canceled as part of his secret plan to get the show canceled.
[00:46:52.000 --> 00:46:56.000]   He's done. He's done with having to he's he's turning 40.
[00:46:56.000 --> 00:47:00.000]   He's having a midlife crisis. He is done wrangling with the microphones in the HQ.
[00:47:00.000 --> 00:47:06.000]   And so he has put in a question designed to get me canceled so that he can he can be freed.
[00:47:06.000 --> 00:47:14.000]   So here we go. This question is from Fiona, who says, what are your thoughts on the relationship between the deep life and privilege?
[00:47:14.000 --> 00:47:23.000]   We already talked about, like Donald Trump for five minutes at the beginning of this episode, so we're probably already I don't know which side is going to cancel us at this point, but like we probably upset them all.
[00:47:23.000 --> 00:47:35.000]   All right, let's see here. Elaborating Fiona says a while back, you talked a bit about Virginia Woolf's A Room of Your Own, A Room of One's Own, and how living the deep life and having space for contemplation is an essential part of the human condition.
[00:47:35.000 --> 00:47:48.000]   This really resonated with me. But also made me worry about those who can't afford cost associated with high quality leisure in their free time. Books and newspapers can be expensive, but Twitter is free. Big fan. Thanks for all you do.
[00:47:48.000 --> 00:48:04.000]   Yes, Fiona, A Room of One's Own reference was from digital minimalism. I was talking about that in digital minimalism where Woolf was making this argument that space for contemplation and which is necessary for reflection and self-definition
[00:48:04.000 --> 00:48:17.000]   is fundamental to the human condition. And so looking at society at that time, women literally did not have the physical space in which to actually go and have the time to contemplate.
[00:48:17.000 --> 00:48:30.000]   And so they're being deprived of that fundamental part of the human condition. This is sort of like an Aristotelian argument that is in this contemplation that humans become humans. It is our teleology. There we go.
[00:48:30.000 --> 00:48:42.000]   It's been a long day. And she was making a sort of feminist argument about that being denied because of cultural constraints. So I think that's what Fiona was talking about.
[00:48:42.000 --> 00:48:58.000]   So let's think about privilege and the deep life. So I have a specific answer and then maybe a more general tangent just because I'm a professor and I can't help myself. So specifically, when it comes to pragmatic nonfiction in particular,
[00:48:58.000 --> 00:49:16.000]   so pragmatic nonfiction is where my books often live. This is books that give advice or hints or ideas about living. Right. So within pragmatic nonfiction, almost by definition, you're going to have a pretty narrow audience to which the advice mainly applies,
[00:49:16.000 --> 00:49:28.000]   especially if we're thinking about the world population in whole. Most American pragmatic nonfiction is pretty narrow. Like if you are in Kiev right now, you have no interest in digital minimalism.
[00:49:28.000 --> 00:49:40.000]   This is not relevant to you and your situation. It is not helpful to you. Right. You have to be in a pretty specific situation where you're lucky enough to care about things like digital minimalism.
[00:49:40.000 --> 00:49:55.000]   But then even once you get to a population for which a book is addressed, for which the topics are relevant, you then get infinite gradations within that population about the extent to which you are able to actually execute that advice.
[00:49:55.000 --> 00:50:11.000]   So maybe you're like, let's just look at like American upper middle class knowledge workers with financial stability and flexibility in their schedule. Right. So this is a group that can think about things like high quality leisure. And what am I going to do with my time?
[00:50:11.000 --> 00:50:21.000]   You're going to have infinite gradations within that group. Someone might say, yeah, I might have that, but I also have an autoimmune disorder. I'm dealing with chronic pain. I can't really make great use of that time.
[00:50:21.000 --> 00:50:35.000]   And then how do you compare that to someone who has much less time? Maybe they're working two jobs, but then have like a high energy. They don't sleep much. They just constitutionally have like a high energy and are able to aggressively fill in that time.
[00:50:35.000 --> 00:50:48.000]   So we have infinite gradations within populations for which pragmatic nonfiction applies. And there's no total ordering function on it. You can't even directly compare everyone to everyone else. So it's all kind of a mess, but it's absolutely real.
[00:50:48.000 --> 00:51:05.000]   So that's a good observation. So what do we do about that? And you could use privilege to explain that. I mean, you could use privilege as a shorthand for the particular combination of traits and properties you have that define your life.
[00:51:05.000 --> 00:51:19.000]   But there's quite a few of those that were to some degree or largely outside of your control or happenstance or luck, and everyone has a different configuration. And how do we deal with that? And it's kind of a hard question.
[00:51:19.000 --> 00:51:35.000]   One approach I think that has become popular now has been in your writing itself to do a sort of self-attestation about a sampling of various privileges.
[00:51:35.000 --> 00:51:44.000]   Or in other words, like a sampling of I'm in this group, this group, this would be less relevant over here. I don't think it's relevant. Here's one thing I have. So you just sort of like self-attestation of privilege.
[00:51:44.000 --> 00:52:01.000]   And I see this a lot in modern books, like usually early on, like let me sort of enumerate aspects of my identity and talk about other aspects that I don't have and that this would, let me do like a disclaimer, you know, early on in the book.
[00:52:01.000 --> 00:52:14.000]   Now I say a sampling because again, there's infinite gradations. And so like you basically are just randomly choosing a few things. Like if you're here, here, this might not be as relevant. And that here and here is sort of sampled from a much broader sampling.
[00:52:14.000 --> 00:52:23.000]   I mean, I think that's fine. I think the disclaimer approach, though, is probably more creedal than functional.
[00:52:23.000 --> 00:52:41.000]   So I mean about it is by creedal, I mean, it's more of a like a declaration of allegiance, a declaration of allegiance to the group that takes quite seriously the various theoretical frameworks from which these notions arose.
[00:52:41.000 --> 00:53:10.000]   So I think that's fine. But I think it's more creedal than functional. So by functional, I mean, does it actually improve this situation in some way? And I don't know that the attestations or the attestations or disclaimers really do.
[00:53:10.000 --> 00:53:19.000]   Now, again, I'm speaking from very narrow experience here, but in my career of doing pragmatic nonfiction and talks, I've worked with a lot of different groups.
[00:53:19.000 --> 00:53:24.000]   I mean, I used to do a lot of work with community colleges, first generation college students, for example.
[00:53:24.000 --> 00:53:41.000]   And, you know, I'm not particularly convinced that these creedal disclaimers up front in books make much of a difference. I think there's a notion that it is like makes people more comfortable, but I don't think it does.
[00:53:41.000 --> 00:53:54.000]   I don't think they care. I think sometimes it can seem ironically quite privileged to be focusing on, you know, disclaiming all these things about yourself as opposed to just getting to the information.
[00:53:54.000 --> 00:54:02.000]   And the other thing I've noticed is that there's a lot of populations, and again, this comes from my just personal experience, I don't know if it generalizes, that often finds it to be a little bit condescending.
[00:54:02.000 --> 00:54:14.000]   I definitely encountered that with digital minimalism. So I did a big tour for digital minimalism and talked to lots of different groups and lots of different demographics.
[00:54:14.000 --> 00:54:29.000]   And there was this interesting split where whenever I would do like sort of more elite media, like NPR or something like this, there would always be this notion of like, I mean, this is only relevant to like upper middle class, knowledge worker white people.
[00:54:29.000 --> 00:54:37.000]   Like the only people for which thinking about their tools and the role of their phone in their life, that's the only people that's kind of relevant for.
[00:54:37.000 --> 00:54:45.000]   And just like Fiona in your question here, like newspapers are expensive and like Twitter is what people need if they can't afford newspapers.
[00:54:45.000 --> 00:54:59.000]   But then you would go and actually do events. There's a huge international readership of this book. So all sorts of different ethnic, racial and economic backgrounds of people who read this book that I encounter.
[00:54:59.000 --> 00:55:05.000]   And they would say, what are you talking about? I don't want to be on Instagram all the time. Like, yeah, I want to hear, I want to hear this.
[00:55:05.000 --> 00:55:13.000]   Like, what do you mean? Like, I can't hear this, you know, this information. I don't like, look, man, this is annoying me. I'd rather do like better stuff with my time.
[00:55:13.000 --> 00:55:17.000]   I mean, you go, it's an interesting interview I did on the radio program, The Breakfast Club. Right.
[00:55:17.000 --> 00:55:33.000]   If you go there and you listen to my conversation with DJ Envy and Angela and Charlemagne, you see like, OK, and for example, like black urban youth culture, Charlemagne is like a big advocate of like we're on Instagram too much.
[00:55:33.000 --> 00:55:37.000]   And it's like getting in the way of other things that are more important that we should be doing as a population.
[00:55:37.000 --> 00:55:46.000]   So like, and I get this a lot. I deal with a lot of sort of different international audiences. First generation immigrant populations are really big into some of these ideas.
[00:55:46.000 --> 00:55:52.000]   And a lot, you know, everyone kind of comes from the same place. I don't want to just be distracted.
[00:55:52.000 --> 00:56:00.000]   I don't want to just be ceding my time and autonomy to Mark Zuckerberg. So his stock price goes up. Like there's other stuff I want to do that's important.
[00:56:00.000 --> 00:56:06.000]   So that's the other thing I have found is that it doesn't always help.
[00:56:06.000 --> 00:56:14.000]   And again, just my narrow experience to be like, I know this doesn't apply to you. This only applies to narrow crowds because there's yous out there say, what do you mean it doesn't apply to me? Of course it does.
[00:56:14.000 --> 00:56:19.000]   I care about this stuff too. So what is then what can we do instead?
[00:56:19.000 --> 00:56:30.000]   Well, I don't know. I think instead of just talking about, look, there's these different gradations for who this applies to or doesn't.
[00:56:30.000 --> 00:56:45.000]   What can we do to actually expand to it applies to? Like, I think the actual action, as opposed to the sort of textual online discussion is a place we should be giving more attention.
[00:56:45.000 --> 00:56:55.000]   Right. So, I mean, if we if we see like, OK, here's here's a group that's saying here's an audience who is saying I would like this advice, but like just to make ends meet, I have to work three jobs.
[00:56:55.000 --> 00:57:03.000]   I don't have time to think about, let's say, high quality leisure instead of just saying I just want to recognize and affirm that you say, why?
[00:57:03.000 --> 00:57:06.000]   How can we change society so you don't have to work three jobs to make ends meet?
[00:57:06.000 --> 00:57:12.000]   Like, shouldn't everyone have enough breathe and room in their life that like something like high quality leisure is an option, right?
[00:57:12.000 --> 00:57:27.000]   That that's the functional thing. If you have someone say, look, I'm a parent and a mom and I have these issues that men don't have in terms of the demands of childbearing that are disproportionately put on me,
[00:57:27.000 --> 00:57:33.000]   which means that I have to make sacrifices in my career that hurts my economic spending power.
[00:57:33.000 --> 00:57:40.000]   Like, it's helpful to affirm it, but also we could be having the conversation of like, how do we change works? That's not a problem anymore.
[00:57:40.000 --> 00:57:49.000]   You know, what can we do to rethink how work happens so it's not about the performative sort of I am here more hours than you.
[00:57:49.000 --> 00:57:52.000]   I answer your emails at all times. Can we think about results oriented work?
[00:57:52.000 --> 00:58:02.000]   Can we think about more pure and direct translation of ability and skill into remuneration without having to go through these weird systems of performance that are going to cause this problem in the first place?
[00:58:02.000 --> 00:58:12.000]   So I like the functional definition. And I think the one of the biggest functional changes we can make here as well is bring in other voices.
[00:58:12.000 --> 00:58:22.000]   So there's a lot of controversy around diversity in different aspects, but let me tell you one place where I think diversity is incredibly powerful. Writing.
[00:58:22.000 --> 00:58:29.000]   I mean, what is writing other than a human trying to capture in words their own internal experience in a way that is legible to other people?
[00:58:29.000 --> 00:58:38.000]   So there is no field where I think it's more important than to have different voices there because you're literally making different experiences legible to other people.
[00:58:38.000 --> 00:58:42.000]   And so maybe I'm less interested. I mean, I can again, I can affirm and disclaim here's who I am.
[00:58:42.000 --> 00:58:47.000]   And there's a lot of people who are different than me, but what probably is going to matter is having people who are different than me write books.
[00:58:47.000 --> 00:58:52.000]   And I'm a big believer in that in those efforts. I've been somewhat involved in those. I'd like to be involved more.
[00:58:52.000 --> 00:59:05.000]   But I think books are the place where you are going to get the biggest bang for your buck for bringing in different voices because the entire experience of reading is melding empathetically with the mind of an author.
[00:59:05.000 --> 00:59:19.000]   It's like a direct mind meld. And so, yeah, my, a book I write is going to be narrow because my background that might be even more narrowed and I can talk about it and that's fine.
[00:59:19.000 --> 00:59:23.000]   It's not hurt. It's not going to hurt anything, but it's also not going to solve much things.
[00:59:23.000 --> 00:59:36.000]   But if we have other people kind of the same topics from completely different angles or backgrounds or identities, now you start to get this interesting, rich, diverse number of approaches on this.
[00:59:36.000 --> 00:59:41.000]   Understand other people better people who might not really connect to Cal Newport might connect to someone else.
[00:59:41.000 --> 00:59:50.000]   And so I think that really matters as well. So basically, I have nothing against the disclaimer approach to dealing with the issues of privilege.
[00:59:50.000 --> 00:59:54.000]   I just think it's more creedal than functional, which again, is not bad.
[00:59:54.000 --> 00:59:59.000]   I don't want to be yelled at on Twitter either, but we should not let that substitute for the functional.
[00:59:59.000 --> 01:00:09.000]   Like the battles of the functional, which are more sweat inducing, you know, dirt on your pants out there holding the placard type work.
[01:00:09.000 --> 01:00:14.000]   I mean, that seems to be where the rubber actually hits the road.
[01:00:14.000 --> 01:00:17.000]   So I don't know if you and I've gone I've gone long here.
[01:00:17.000 --> 01:00:29.000]   Answer this question, but basically, yes, all pragmatic nonfiction is privileged in the sense that it speaks to very specific audiences, even within that audiences at various gradations.
[01:00:29.000 --> 01:00:34.000]   I'm not a huge fan that ass test stations and disclaimers are what's going to solve this issue.
[01:00:34.000 --> 01:00:40.000]   I think in five times out of seven, those are just creedal. Hey, don't yell at me.
[01:00:40.000 --> 01:00:46.000]   But there is we shouldn't just be complacent about it. And let's say, what are the functional solutions here?
[01:00:46.000 --> 01:00:56.000]   How do we actually expand if the advice is important, if the topic is the topic itself is affirming and life giving and depth generating?
[01:00:56.000 --> 01:01:07.000]   How do we expand who it's relevant to? And then finally, that disclaimer I put in there is like, don't assume that people from different situations don't want the advice or can't handle the advice.
[01:01:07.000 --> 01:01:12.000]   That's the final thing. That's the thing that surprised me about digital minimalism is like everyone is fed up with their phones.
[01:01:12.000 --> 01:01:18.000]   And no one likes to be labeled as like, well, that's a group that they need their phones.
[01:01:18.000 --> 01:01:22.000]   They can't you know, they can't be thinking about these other things. Everyone hates that. It's condescending nonsense.
[01:01:22.000 --> 01:01:27.000]   So, all right, Fiona, I don't know if I successfully canceled myself with that answer.
[01:01:27.000 --> 01:01:33.000]   Here's the thing, Jesse, like I have no dog in these fights. Like I don't I'm not a big fan of ideology.
[01:01:33.000 --> 01:01:40.000]   I, you know, I think I can get intellectually lazy. I like ideas. I can drift from all angles of the ideas.
[01:01:40.000 --> 01:01:48.000]   And I think it confuses and concerns a lot of people. So like, I don't know if you're on my team, but you don't seem to be on their team.
[01:01:48.000 --> 01:01:56.000]   Whose team are you on? Come on. Come on. We have to know. And I don't know. I just like I I'm not online much.
[01:01:56.000 --> 01:02:02.000]   I'm not sort of in the middle of these things. I'm a dialectical thinker. I like to crash things like the try on ideas.
[01:02:02.000 --> 01:02:09.000]   So we'll see. We'll see how people think about it. It's a dangerous rope to walk.
[01:02:09.000 --> 01:02:15.000]   I mean, I think that people that listen to you regularly, you know, hear your hashing out on subjects.
[01:02:15.000 --> 01:02:21.000]   It's people who dive in here and there that might. Yeah. You know, when you read like the book, like Don't Fall Your Passion or something like that.
[01:02:21.000 --> 01:02:25.000]   It's yeah. Yeah. Well, we should have more hashing. I think hashing out is good.
[01:02:25.000 --> 01:02:31.000]   We should trust people to be exposed to ideas and see where they fall out.
[01:02:31.000 --> 01:02:39.000]   All right. Well, speaking of trusting people, let me tell you briefly about two sponsors who you should trust.
[01:02:39.000 --> 01:02:43.000]   Jesse, they call that transition. I'm a pro.
[01:02:43.000 --> 01:02:50.000]   That first sponsor is one of the oldest sponsors of the Deep Questions podcast, and that is Blinkist.
[01:02:50.000 --> 01:02:55.000]   You have heard me talk about Blinkist many times before on this program.
[01:02:55.000 --> 01:03:02.000]   It's a subscription service that gives you access to short 10 to 15 minute summaries of thousands of bestselling nonfiction books.
[01:03:02.000 --> 01:03:09.000]   You can read these summaries or you can listen to them when you are on the move.
[01:03:09.000 --> 01:03:14.000]   Ideas are power. I mean, what is this show about, if anything, if not ideas are power.
[01:03:14.000 --> 01:03:17.000]   Encounter ideas, try them on for size, clash them against other ideas.
[01:03:17.000 --> 01:03:22.000]   It's what structures your understanding of the world. It's what structures your definition as a self.
[01:03:22.000 --> 01:03:27.000]   It's what structures your path through this life. And books are the number one source of ideas
[01:03:27.000 --> 01:03:33.000]   because it represents years of careful thought crystallized into the written format.
[01:03:33.000 --> 01:03:38.000]   The problem is how do you figure out what book to read? Blinkist can help.
[01:03:38.000 --> 01:03:43.000]   When you hear about a nonfiction book, you hear about Homo Deus, you hear about Indistractible,
[01:03:43.000 --> 01:03:48.000]   you hear about Bad Blood or the blockchain revolution, you're like, man, should I know about that?
[01:03:48.000 --> 01:03:53.000]   Is that the right book to read on this topic? Blinkist can help you out because you can get that 10 to 15 minute summary,
[01:03:53.000 --> 01:03:58.000]   grok the main points. And you might say that's enough. I get the basic idea.
[01:03:58.000 --> 01:04:02.000]   Or you might say I'm intrigued and now I can buy that book with confidence.
[01:04:02.000 --> 01:04:06.000]   If you're a reader and you should be, Blinkist is a great companion.
[01:04:06.000 --> 01:04:10.000]   So right now Blinkist has a special offer just for our audience.
[01:04:10.000 --> 01:04:15.000]   If you go to Blinkist.com/deep to start your free seven day trial,
[01:04:15.000 --> 01:04:19.000]   you will get 25% off a Blinkist premium membership.
[01:04:19.000 --> 01:04:23.000]   That's Blinkist spelled B-L-I-N-K-I-S-T.
[01:04:23.000 --> 01:04:27.000]   Blinkist.com/deep to get 25% off any seven day free trial.
[01:04:27.000 --> 01:04:31.000]   Blinkist.com/deep.
[01:04:31.000 --> 01:04:37.000]   Let's also talk about our friends from Athletic Greens.
[01:04:37.000 --> 01:04:41.000]   Now this is a product that I literally use every day.
[01:04:41.000 --> 01:04:45.000]   You take it once a day in the morning.
[01:04:45.000 --> 01:04:50.000]   And I have been doing that ever since Athletic Greens has been a sponsor.
[01:04:50.000 --> 01:04:55.000]   Here's how it works. It's a powder. You take one scoop of this powder each morning.
[01:04:55.000 --> 01:04:58.000]   You mix it in the 12 ounces of cold water.
[01:04:58.000 --> 01:05:03.000]   It contains 75 high quality vitamins, minerals, whole foods, source superfoods,
[01:05:03.000 --> 01:05:09.000]   probiotics and adaptogens to help you start your day right.
[01:05:09.000 --> 01:05:12.000]   It's a blend of ingredients that supports your gut health, your nervous system,
[01:05:12.000 --> 01:05:15.000]   your immune system, your energy recover, focus and aging.
[01:05:15.000 --> 01:05:18.000]   All the things you might care about. This powder has it.
[01:05:18.000 --> 01:05:22.000]   You take it once a day. You don't have to worry about a ton of other supplements.
[01:05:22.000 --> 01:05:26.000]   I mean this is the whole idea behind Athletic Greens.
[01:05:26.000 --> 01:05:30.000]   So their founder, and I had a call with them to explain this to me,
[01:05:30.000 --> 01:05:33.000]   their founder was having gut health issues.
[01:05:33.000 --> 01:05:38.000]   And he got super into supplements to try to figure out what he was missing,
[01:05:38.000 --> 01:05:42.000]   what would help. And he finally found enough high quality supplements that helped,
[01:05:42.000 --> 01:05:47.000]   but it was costing him $100 a day to source all of these different things.
[01:05:47.000 --> 01:05:51.000]   So he figured, why don't I just create one powder where we do all the hard work
[01:05:51.000 --> 01:05:55.000]   of finding the very best things in the very best form.
[01:05:55.000 --> 01:05:57.000]   Put them all together in one powder you take every day.
[01:05:57.000 --> 01:05:59.000]   You don't have to think about any other supplementation.
[01:05:59.000 --> 01:06:04.000]   I love that simplicity. And that's why I'm an Athletic Greens user.
[01:06:04.000 --> 01:06:07.000]   So right now it's time to reclaim your health and arm your immune system
[01:06:07.000 --> 01:06:09.000]   with convenient daily nutrition.
[01:06:09.000 --> 01:06:13.000]   It's especially true now that we are in flu and cold season.
[01:06:13.000 --> 01:06:16.000]   It's just one scoop and a cup of water every day. That's it.
[01:06:16.000 --> 01:06:21.000]   No need for a million different pills and supplements to look out for your health.
[01:06:21.000 --> 01:06:25.000]   To make it easy, Athletic Greens is going to give you a free one year supply
[01:06:25.000 --> 01:06:31.000]   of immune supporting vitamin D drops and five free travel packs with your first purchase.
[01:06:31.000 --> 01:06:37.000]   All you have to do is visit athleticgreens.com/deep.
[01:06:37.000 --> 01:06:44.000]   Again, this is athleticgreens.com/deep to take ownership over your health
[01:06:44.000 --> 01:06:50.000]   and pick up the ultimate daily nutritional insurance.
[01:06:50.000 --> 01:06:52.000]   All right, so we've got time for one more question.
[01:06:52.000 --> 01:06:56.000]   I like this question because it introduces new terminology.
[01:06:56.000 --> 01:06:58.000]   I love terminology.
[01:06:58.000 --> 01:07:04.000]   This one comes from Bob. Bob says, "When should I plan from left to right
[01:07:04.000 --> 01:07:08.000]   instead of right to left?"
[01:07:08.000 --> 01:07:12.000]   He elaborates, "A lot of your advice and techniques focus on defining a goal
[01:07:12.000 --> 01:07:17.000]   and working backwards from there, such as quarterly planning, weekly planning,
[01:07:17.000 --> 01:07:21.000]   lifestyle-centric career planning. This could be seen as right to left planning
[01:07:21.000 --> 01:07:27.000]   as you essentially pick the end date of a goal, so to the right on your calendar,
[01:07:27.000 --> 01:07:31.000]   and then work backwards from there, so to your left, so right to left.
[01:07:31.000 --> 01:07:35.000]   I'm sure you would agree with me that right to left planning is probably the best way
[01:07:35.000 --> 01:07:38.000]   to plan most of the time. However, I would be curious to hear your thoughts
[01:07:38.000 --> 01:07:41.000]   on when it may be better to plan from left to right.
[01:07:41.000 --> 01:07:44.000]   For example, maybe this left to right planning would make more sense
[01:07:44.000 --> 01:07:50.000]   if you're trying to get into a new hobby and your end goal is more ambiguous."
[01:07:50.000 --> 01:07:56.000]   I think that's a great distinction, Bob, and some great terminology.
[01:07:56.000 --> 01:08:01.000]   Both type of planning is relevant. I would differentiate it a little bit slightly
[01:08:01.000 --> 01:08:05.000]   differently. So right to left planning, I would say yes, as you pointed out,
[01:08:05.000 --> 01:08:09.000]   is where this is what I'm trying to get done, so I'm now going to go backwards
[01:08:09.000 --> 01:08:14.000]   and fill in the time until then. And this happens a lot on shorter timescales.
[01:08:14.000 --> 01:08:17.000]   Daily time block planning, I know what I'm trying to get done today,
[01:08:17.000 --> 01:08:20.000]   and I'm filling in the hours of the day. Weekly planning, I know what I'm trying
[01:08:20.000 --> 01:08:23.000]   to do this week, and I'm filling in the days of the week with notes on what I'm doing
[01:08:23.000 --> 01:08:28.000]   each of those days. But however, I think you're right that not everything can be
[01:08:28.000 --> 01:08:35.000]   backwards engineered that way. So I would say right to left to right planning.
[01:08:35.000 --> 01:08:40.000]   Let's see if I have that right. Right to left to right planning is actually what
[01:08:40.000 --> 01:08:43.000]   you would do in those other instances. So what I mean by that is you start
[01:08:43.000 --> 01:08:47.000]   to the right, so you start with a goal. So maybe you're doing lifestyle-centric
[01:08:47.000 --> 01:08:52.000]   career planning, and you're thinking, I want to be in a lot better shape,
[01:08:52.000 --> 01:08:56.000]   or I want to have a new job built around tech or something like that.
[01:08:56.000 --> 01:08:59.000]   So you're off to the right. But then you go back and say, let me just plan
[01:08:59.000 --> 01:09:02.000]   left to right for a little while. I don't know how to do that from scratch,
[01:09:02.000 --> 01:09:07.000]   but I am going to do this in the near future. I'm going to start taking
[01:09:07.000 --> 01:09:11.000]   athletic greens. I'm going to start a rowing program. I'm going to take
[01:09:11.000 --> 01:09:14.000]   a coding program. You're not reverse engineering this whole goal.
[01:09:14.000 --> 01:09:17.000]   You're just like, let me just go forward a little bit, see what I learned there,
[01:09:17.000 --> 01:09:20.000]   what that opens up. I'll meet some new people and then see what comes next.
[01:09:20.000 --> 01:09:24.000]   So I'm working my way back to that goal to the right, but I don't have it
[01:09:24.000 --> 01:09:28.000]   all figured out. And I actually think that's a lot of planning. I think if
[01:09:28.000 --> 01:09:32.000]   you're completely serendipitous, let me just try this, why not?
[01:09:32.000 --> 01:09:36.000]   You are floating a little free. But if you say, this is a general place
[01:09:36.000 --> 01:09:39.000]   I want to head towards, I don't know how to get there, but I think doing
[01:09:39.000 --> 01:09:43.000]   this thing will move me in the right direction. I'll learn more.
[01:09:43.000 --> 01:09:46.000]   I'll meet new people. And then when I'm done, I can look up and say what
[01:09:46.000 --> 01:09:51.000]   comes next is actually not a bad way to approach a lot of goals because
[01:09:51.000 --> 01:09:54.000]   reverse engineering in detail is very difficult once you're past the time
[01:09:54.000 --> 01:09:58.000]   scale of just a few weeks. It becomes quite difficult.
[01:09:58.000 --> 01:10:01.000]   And so that's what you need to do. I think that's pretty common.
[01:10:01.000 --> 01:10:08.000]   So one place I wrote about this was this book I wrote in 2009
[01:10:08.000 --> 01:10:11.000]   called How to Be a High School Superstar. It's a weird title, but basically
[01:10:11.000 --> 01:10:15.000]   I profiled these students, high school students, who got into really good
[01:10:15.000 --> 01:10:19.000]   colleges, but then it all stressed themselves out. They weren't grinds.
[01:10:19.000 --> 01:10:22.000]   They weren't doing 70 activities. They weren't staying up late. And I was
[01:10:22.000 --> 01:10:24.000]   like, how did they do it? That was the whole premise of the book. It's kind
[01:10:24.000 --> 01:10:27.000]   of a cool premise. I don't love the title, but it's a cool premise.
[01:10:27.000 --> 01:10:33.000]   And one of the things I uncovered in that book is that a common attribute
[01:10:33.000 --> 01:10:38.000]   of students who stumble into great colleges without working super hard is
[01:10:38.000 --> 01:10:42.000]   really interesting. They did something really cool. And the term I introduced
[01:10:42.000 --> 01:10:46.000]   was failed simulation effect. They often had completed something where you say,
[01:10:46.000 --> 01:10:51.000]   I don't know how you did that. I cannot simulate in my mind how a 17-year-old
[01:10:51.000 --> 01:10:56.000]   would do that. And in that gap between you did this thing and I don't even
[01:10:56.000 --> 01:11:01.000]   know how you did it, how that's even possible, in that gap, the reaction is
[01:11:01.000 --> 01:11:06.000]   one of, whoa. And you get assigned a lot of impressiveness and it can get you
[01:11:06.000 --> 01:11:10.000]   in the college. I actually talked about, this is interesting, Ramit Sethi's
[01:11:10.000 --> 01:11:15.000]   brother, Manish, I've known for a long time, but Manish, he was a high school
[01:11:15.000 --> 01:11:18.000]   student back when I wrote that book, and he published a book on computer
[01:11:18.000 --> 01:11:21.000]   programming. And it was like an example of something like, how does a 17-year-old
[01:11:21.000 --> 01:11:25.000]   publish a book on computer programming? I don't even know. Whoa. And it gives
[01:11:25.000 --> 01:11:30.000]   you this burst of, this person's really impressive. So I reverse engineered the
[01:11:30.000 --> 01:11:36.000]   failed simulation effect. How do you end up doing something as a kid that people
[01:11:36.000 --> 01:11:39.000]   won't be able to figure out how you did it? And I said, by definition, you can't
[01:11:39.000 --> 01:11:43.000]   plan that out in advance. If you could just sit there and be like, here are the
[01:11:43.000 --> 01:11:46.000]   steps that it would take for me to do this thing that people won't be able to
[01:11:46.000 --> 01:11:49.000]   understand how I did it, by definition would mean that's the thing that people
[01:11:49.000 --> 01:11:52.000]   understand how you would do it. If you could just think up the plan from scratch,
[01:11:52.000 --> 01:11:55.000]   then it must not be that hard to think up how you do it, and you aren't going to
[01:11:55.000 --> 01:12:00.000]   get the failed simulation effect. It was a paradox. The whole point of the effect
[01:12:00.000 --> 01:12:03.000]   is that it's really complicated to figure out how anyone could ever do that. So how
[01:12:03.000 --> 01:12:06.000]   did they end up? How did these kids end up in these places? How did Manish end up
[01:12:06.000 --> 01:12:09.000]   writing a book on computer programming? I talked about someone who had done
[01:12:09.000 --> 01:12:14.000]   horseshoe crab research. I was just watching a documentary with my boys on the
[01:12:14.000 --> 01:12:19.000]   Intel Science and Engineering Fair, the big science fair, and the high school
[01:12:19.000 --> 01:12:23.000]   around here. So the high school we're zoned for is actually the most, since
[01:12:23.000 --> 01:12:27.000]   1999, has been the most winningest school in the world for the Intel Science Fair.
[01:12:27.000 --> 01:12:32.000]   And the last person from our school to win it, this high school in 2015, did
[01:12:32.000 --> 01:12:36.000]   quantum physics research. And you see that, like, I just can't imagine how a
[01:12:36.000 --> 01:12:41.000]   17-year-old did that. Whoa. So how did they actually do this? What it typically
[01:12:41.000 --> 01:12:48.000]   was, this was the argument I gave, was they did left to right planning. They
[01:12:48.000 --> 01:12:52.000]   would do something that was interesting, they would do it really well, and then
[01:12:52.000 --> 01:12:56.000]   once it was done, they would look up and say, "What new opportunities did that
[01:12:56.000 --> 01:13:00.000]   just open up?" And they would find the coolest of those opportunities and then
[01:13:00.000 --> 01:13:02.000]   do that. And they would do it really well. Like, their key is if you did
[01:13:02.000 --> 01:13:05.000]   something, do it really well. And they'd say, "What opportunities did this open
[01:13:05.000 --> 01:13:08.000]   up?" And be kind of bold in choosing the next one. And they would just repeat
[01:13:08.000 --> 01:13:13.000]   this cycle. You do this 10 times, and that 10th opportunity you end up with is,
[01:13:13.000 --> 01:13:16.000]   "I've just published a book and I'm 17. I've just published research on quantum
[01:13:16.000 --> 01:13:21.000]   physics and I'm 17. I'm doing horseshoe crab research at the University of New
[01:13:21.000 --> 01:13:25.000]   Hampshire and I'm 16." You end up somewhere really cool, but you got there
[01:13:25.000 --> 01:13:28.000]   serendipitously by saying, "Do something interesting, do it well," and
[01:13:28.000 --> 01:13:32.000]   aggressively say, "What can I do next? What does this open up?" and repeat.
[01:13:32.000 --> 01:13:37.000]   And so that's classic left to right planning, to use Bob's terminology. And if
[01:13:37.000 --> 01:13:42.000]   you go back, for example, and look at that, reverse engineer these
[01:13:42.000 --> 01:13:45.000]   accomplishments this way, you see that actually the path all makes sense in
[01:13:45.000 --> 01:13:49.000]   retrospect. The kid who won the Intel Science Fair out of Montgomery Blair
[01:13:49.000 --> 01:13:56.000]   High School in 2015, well, he was in this math and computer science magnet that we
[01:13:56.000 --> 01:13:59.000]   have at the middle school and high school here, which is one of the best in the
[01:13:59.000 --> 01:14:03.000]   country. So he had all this advanced math training. And then it turns out that it
[01:14:03.000 --> 01:14:09.000]   is common for students at this high school to do internships over the summer
[01:14:09.000 --> 01:14:12.000]   with professors. I get these emails from Blair and Thomas Jefferson High School
[01:14:12.000 --> 01:14:17.000]   all the time. There's just a whole culture of it. And so three summers in a row, he
[01:14:17.000 --> 01:14:21.000]   was working with professors at University of Maryland. And they said, "You're
[01:14:21.000 --> 01:14:25.000]   really smart at math, and you had this training in this magnet program, so you
[01:14:25.000 --> 01:14:29.000]   actually have the fundamentals to do the type of math required. Here is a quantum
[01:14:29.000 --> 01:14:33.000]   problem that we're working on that you could help on." And with their help, he
[01:14:33.000 --> 01:14:38.000]   actually made progress on it three summers in a row, working with real quantum
[01:14:38.000 --> 01:14:42.000]   physicists with this math background that this magnet program gave him. That
[01:14:42.000 --> 01:14:46.000]   allowed him to, with their help, complete a paper that was, again, great insight
[01:14:46.000 --> 01:14:50.000]   that this kid has a great math mind. But it wasn't just he was walking around one
[01:14:50.000 --> 01:14:54.000]   day and said, "Like Einstein, I'm going to solve quantum physics." When you
[01:14:54.000 --> 01:14:57.000]   reverse engineer it, these things make sense, but he didn't see that all in
[01:14:57.000 --> 01:15:00.000]   advance. Do the next thing that's good. Let me do the magnet program. Do it well.
[01:15:00.000 --> 01:15:03.000]   What opportunity does that open up? Oh, I could do an internship. Do that well.
[01:15:03.000 --> 01:15:06.000]   What does that open up? Well, I can come back to do that internship but work on a
[01:15:06.000 --> 01:15:10.000]   bigger problem. That's left to right planning. It can bring you to really cool
[01:15:10.000 --> 01:15:14.000]   places. So you kind of know roughly where you want to go. You start and say, "What
[01:15:14.000 --> 01:15:18.000]   can I do first?" Even if I don't know what comes second. If you keep repeating,
[01:15:18.000 --> 01:15:23.000]   you could end up somewhere kind of cool. All right, well, I've gone over. So we
[01:15:23.000 --> 01:15:27.000]   should probably wrap up this episode. But Bob, thanks for the new terminology. I'll
[01:15:27.000 --> 01:15:31.000]   steal that. So thank you everyone for listening. If you like what you heard, you
[01:15:31.000 --> 01:15:38.000]   will like what you see. YouTube.com/CalNewportMedia for video of these
[01:15:38.000 --> 01:15:43.000]   episodes. You'll also like what you read. You can sign up for my email newsletter
[01:15:43.000 --> 01:15:49.000]   at calnewport.com. Join 60,000 other people who get my articles roughly once a
[01:15:49.000 --> 01:15:54.000]   week. Be back on Thursday with a listener calls episode. And until then, as always,
[01:15:54.000 --> 01:15:56.000]   stay deep.
[01:15:57.000 --> 01:16:00.000]   ♪ [music] ♪
[01:16:00.000 --> 01:16:01.260]   (electronic music)

