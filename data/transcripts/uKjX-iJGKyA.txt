
[00:00:00.000 --> 00:00:06.440]   I think the most important thing is to do something that you are really interested in,
[00:00:06.440 --> 00:00:10.400]   because if you're starting, a lot of things will depend on you.
[00:00:10.400 --> 00:00:12.720]   And the key also to MLT is consistency.
[00:00:12.720 --> 00:00:19.040]   So we consistently just keep doing stuff that we think is exciting and interesting.
[00:00:19.040 --> 00:00:22.880]   You're listening to Gradient Dissent, a show where we learn about making machine learning
[00:00:22.880 --> 00:00:24.520]   models work in the real world.
[00:00:24.520 --> 00:00:26.560]   I'm your host, Lukas Biewald.
[00:00:26.560 --> 00:00:32.880]   Susanna Illich is a founder of MLT, Machine Learning Tokyo, which is a huge community
[00:00:32.880 --> 00:00:36.680]   of people working on and learning about deep learning.
[00:00:36.680 --> 00:00:41.360]   She's hosted around 100 machine learning related events in the last two and a half years and
[00:00:41.360 --> 00:00:42.960]   built an incredible community.
[00:00:42.960 --> 00:00:44.560]   I'm super excited to talk to her.
[00:00:44.560 --> 00:00:46.120]   Susanna, it's so nice to talk to you.
[00:00:46.120 --> 00:00:50.160]   I was really looking forward to this because I see that we share at least two interests
[00:00:50.160 --> 00:00:51.160]   in common.
[00:00:51.160 --> 00:00:57.080]   It seems like the democratization of AI and another is edge computing or deploying deep
[00:00:57.080 --> 00:00:58.080]   learning to hardware.
[00:00:58.080 --> 00:01:01.440]   So I'm super excited to hear about what you've been up to.
[00:01:01.440 --> 00:01:06.160]   And I thought maybe we'd start with Machine Learning Tokyo.
[00:01:06.160 --> 00:01:10.160]   I would love to hear about kind of why you started it and what it does.
[00:01:10.160 --> 00:01:11.160]   Yeah.
[00:01:11.160 --> 00:01:13.000]   First of all, thanks so much for having me.
[00:01:13.000 --> 00:01:14.800]   I'm super excited.
[00:01:14.800 --> 00:01:18.920]   I love weights and biases and I visited in SF.
[00:01:18.920 --> 00:01:21.280]   So I'm super excited to be on this podcast.
[00:01:21.280 --> 00:01:23.280]   So thanks for having me.
[00:01:23.280 --> 00:01:24.280]   Yeah.
[00:01:24.280 --> 00:01:31.240]   MLT is a Japan based nonprofit organization and our kind of core mission is to democratize
[00:01:31.240 --> 00:01:32.240]   machine learning.
[00:01:32.240 --> 00:01:37.000]   So we want to make machine learning and deep learning as accessible as possible to as many
[00:01:37.000 --> 00:01:46.400]   people as possible because we believe that machine learning is going to be everywhere.
[00:01:46.400 --> 00:01:50.720]   It's going to be some standard component in the software stack in the very near future.
[00:01:50.720 --> 00:01:56.280]   So I think a lot of people should know what it is and be able to navigate.
[00:01:56.280 --> 00:02:00.640]   And we mainly do this through open education, through open source.
[00:02:00.640 --> 00:02:03.480]   So we build a lot of open source projects and open science.
[00:02:03.480 --> 00:02:06.040]   So we work with universities.
[00:02:06.040 --> 00:02:11.520]   And yeah, we are here in Tokyo and we support research and engineering community of about,
[00:02:11.520 --> 00:02:13.320]   I think, four and a half thousand members.
[00:02:13.320 --> 00:02:14.800]   Four and a half thousand.
[00:02:14.800 --> 00:02:15.800]   And so how does it work?
[00:02:15.800 --> 00:02:19.540]   How do people join the community and what do they do?
[00:02:19.540 --> 00:02:20.540]   So it depends.
[00:02:20.540 --> 00:02:22.440]   Like there's many ways how to join the community.
[00:02:22.440 --> 00:02:29.520]   You can just be an attendee of the meetups or join a workshops or hands on sessions.
[00:02:29.520 --> 00:02:33.480]   And then you can just join meetup and you get all the information you need there on
[00:02:33.480 --> 00:02:35.200]   upcoming sessions.
[00:02:35.200 --> 00:02:37.960]   But there's also like more active ways to join MLT.
[00:02:37.960 --> 00:02:43.040]   So if you want to contribute, if you want to work on open source, or if you want to,
[00:02:43.040 --> 00:02:48.840]   for example, hold a workshop or lead a study session, you can join Slack and you can talk
[00:02:48.840 --> 00:02:49.840]   to me.
[00:02:49.840 --> 00:02:53.920]   And there's like many ways how to be more actively involved in the community.
[00:02:53.920 --> 00:02:57.100]   What inspired you to start MLT?
[00:02:57.100 --> 00:03:01.160]   So we started, I think, two and a half years ago and it was basically just out of our own
[00:03:01.160 --> 00:03:02.160]   needs.
[00:03:02.160 --> 00:03:03.160]   We were two people.
[00:03:03.160 --> 00:03:05.400]   That's how MLT started.
[00:03:05.400 --> 00:03:07.600]   And so I'm a domain expert in machine learning.
[00:03:07.600 --> 00:03:10.760]   So I come from a very traditional academic background.
[00:03:10.760 --> 00:03:15.320]   I'm a trained linguist and I was always working with text analysis and NLP.
[00:03:15.320 --> 00:03:17.360]   I was using very simple methods.
[00:03:17.360 --> 00:03:22.200]   And at some point during my master's, I was working on sentiment and emotion and effect.
[00:03:22.200 --> 00:03:27.240]   I realized that these kind of very simple statistical methods give us like some intuition
[00:03:27.240 --> 00:03:30.760]   and some insight about a corpus, about a data set.
[00:03:30.760 --> 00:03:38.200]   But like language is full of like very complex and very beautiful things like metaphors and
[00:03:38.200 --> 00:03:41.600]   humor and analogies and irony and sarcasm.
[00:03:41.600 --> 00:03:46.480]   And that's not possible to grasp with those very simple tools.
[00:03:46.480 --> 00:03:50.040]   So I think three or four years ago, I started reading about machine learning and deep learning
[00:03:50.040 --> 00:03:56.240]   and neural networks and I got super hooked and I realized, okay, having learning algorithms,
[00:03:56.240 --> 00:04:01.720]   having algorithms that learn from data directly instead of from rules or lexicons might be
[00:04:01.720 --> 00:04:07.560]   a way to understand language better or to be able to process language better.
[00:04:07.560 --> 00:04:12.280]   So I started writing my first machine learning code three years ago, but I also realized,
[00:04:12.280 --> 00:04:15.760]   whoa, like coming from a different background, it's pretty challenging.
[00:04:15.760 --> 00:04:17.200]   It's pretty difficult.
[00:04:17.200 --> 00:04:22.280]   And for me back then, I knew, okay, I want to have this collaborative learning environment.
[00:04:22.280 --> 00:04:29.540]   I need to be surrounded by people with different backgrounds, people that have different skills
[00:04:29.540 --> 00:04:31.480]   and know different things than I do.
[00:04:31.480 --> 00:04:37.080]   And together, or at least that was what I thought, we could learn faster.
[00:04:37.080 --> 00:04:38.560]   And that's exactly what happened.
[00:04:38.560 --> 00:04:42.520]   So Yuvraj, my co-founder is also coming from a different background, from an electrical
[00:04:42.520 --> 00:04:47.260]   engineering hardware background, and he wanted to use machine learning and he still wants
[00:04:47.260 --> 00:04:52.120]   to use it for edge devices, microcontrollers.
[00:04:52.120 --> 00:04:56.960]   And yeah, we started very small and we just met every week and wrote machine learning
[00:04:56.960 --> 00:05:03.220]   code and every week more and more people joined, even though it was kind of word of mouth.
[00:05:03.220 --> 00:05:07.360]   And after a few weeks, there were so many people, we didn't know where to put them anymore.
[00:05:07.360 --> 00:05:11.760]   So we met in this open coworking space at Yahoo and with too many people.
[00:05:11.760 --> 00:05:15.120]   So everybody wanted to write machine learning code.
[00:05:15.120 --> 00:05:19.420]   And then we started putting out our first meetups and ever since it has been growing
[00:05:19.420 --> 00:05:20.420]   pretty fast.
[00:05:20.420 --> 00:05:25.740]   So we started from very small, but kind of out of our own need to, because in Tokyo,
[00:05:25.740 --> 00:05:27.240]   there was no such thing back then.
[00:05:27.240 --> 00:05:31.800]   Like two and a half years ago, there were a lot of communities, great communities, but
[00:05:31.800 --> 00:05:34.760]   there was no place to actually build AI.
[00:05:34.760 --> 00:05:37.080]   There was no place to work on hands-on stuff.
[00:05:37.080 --> 00:05:38.080]   So that's how it all started.
[00:05:38.080 --> 00:05:39.080]   That's so cool.
[00:05:39.080 --> 00:05:42.720]   So you built the community that you wanted to be a part of?
[00:05:42.720 --> 00:05:44.360]   That's so great.
[00:05:44.360 --> 00:05:45.360]   How did you frame it?
[00:05:45.360 --> 00:05:48.080]   Like when you were first saying, "Hey, come join me."
[00:05:48.080 --> 00:05:49.520]   What was the thing to do?
[00:05:49.520 --> 00:05:53.320]   Like it was like, let's learn ML together or read papers or how did you think about
[00:05:53.320 --> 00:05:54.600]   that?
[00:05:54.600 --> 00:06:00.720]   So the very first kind of, I think first six months or so, it was purely dedicated to going
[00:06:00.720 --> 00:06:01.760]   through tutorials.
[00:06:01.760 --> 00:06:07.360]   So really learning about how to write machine learning code and learning about getting a
[00:06:07.360 --> 00:06:13.560]   conceptual understanding of different algorithms of the math, but mainly to write code.
[00:06:13.560 --> 00:06:19.040]   And that was how we started is just going through as much stuff as possible.
[00:06:19.040 --> 00:06:25.500]   And then once we kind of, and the team grew bigger and more people have joined us.
[00:06:25.500 --> 00:06:29.840]   So after six months, it kind of slowly started to broaden.
[00:06:29.840 --> 00:06:32.260]   So we did a lot more things.
[00:06:32.260 --> 00:06:36.720]   We started doing hands-on deep learning workshops in the first year.
[00:06:36.720 --> 00:06:43.760]   So we had deep learning engineers who were working full-time at Japanese companies, and
[00:06:43.760 --> 00:06:50.800]   they were giving five-hour deep learning workshops where we focus on writing life code from scratch
[00:06:50.800 --> 00:06:53.240]   and training a specific model of training.
[00:06:53.240 --> 00:06:56.520]   I don't know, we first focused a lot on computer vision.
[00:06:56.520 --> 00:07:01.020]   So we went through a lot of computer vision stuff and then gradually kind of moved into
[00:07:01.020 --> 00:07:04.320]   different areas of machine learning.
[00:07:04.320 --> 00:07:10.640]   And like as the community kind of progresses and grows, we see that we go into different
[00:07:10.640 --> 00:07:11.640]   directions.
[00:07:11.640 --> 00:07:16.440]   So now we have like a computer vision team that does CNN architectures and their own
[00:07:16.440 --> 00:07:18.080]   little ecosystem.
[00:07:18.080 --> 00:07:20.760]   We have a team that is fully dedicated to edge AI.
[00:07:20.760 --> 00:07:27.120]   So running deep learning algorithms on hardware, on microcontrollers and edge devices.
[00:07:27.120 --> 00:07:30.640]   We have an NLP team that does research and natural language processing.
[00:07:30.640 --> 00:07:32.880]   So everything is fully community driven.
[00:07:32.880 --> 00:07:35.560]   So there is no full-time employees or anything.
[00:07:35.560 --> 00:07:39.560]   It's really how the community evolves and grows.
[00:07:39.560 --> 00:07:41.640]   And that kind of broadens into different directions.
[00:07:41.640 --> 00:07:43.200]   That's so impressive.
[00:07:43.200 --> 00:07:45.360]   So like, how do you run a good workshop?
[00:07:45.360 --> 00:07:49.500]   Like a five-hour workshop, I've seen really good ones and bad ones.
[00:07:49.500 --> 00:07:52.920]   How would you do it to make sure that it's a good experience for people?
[00:07:52.920 --> 00:07:54.440]   I think it was learning by doing.
[00:07:54.440 --> 00:07:57.260]   And in the beginning, we really didn't know what we were doing.
[00:07:57.260 --> 00:08:02.600]   So I think two years ago when we held our first deep learning workshops, a lot of things
[00:08:02.600 --> 00:08:08.960]   were pretty difficult and pretty challenging because people come with different machines,
[00:08:08.960 --> 00:08:12.960]   with different skill sets, with different background knowledge, with different software
[00:08:12.960 --> 00:08:13.960]   and hardware.
[00:08:13.960 --> 00:08:17.080]   So it was pretty difficult.
[00:08:17.080 --> 00:08:25.080]   But we kind of slowly-- we got a lot of feedback in the first iterations and worked with that
[00:08:25.080 --> 00:08:26.080]   feedback.
[00:08:26.080 --> 00:08:32.720]   So things that made it easier for us is just focus on one thing that is really interesting
[00:08:32.720 --> 00:08:38.680]   to us, where we see value, that can bring value to us as instructors, as deep learning
[00:08:38.680 --> 00:08:41.520]   engineers, as well as to the community.
[00:08:41.520 --> 00:08:44.320]   So something that is very useful.
[00:08:44.320 --> 00:08:47.960]   The second thing is make sure that technically everything runs smoothly.
[00:08:47.960 --> 00:08:53.440]   So we switched, I think, after a second or third workshop to Google Colab.
[00:08:53.440 --> 00:08:57.400]   That makes it very easy to just write code.
[00:08:57.400 --> 00:09:01.480]   And there is no prerequisite except for having a Gmail account.
[00:09:01.480 --> 00:09:06.600]   But that solves a lot of the technical issues and problems that we had.
[00:09:06.600 --> 00:09:07.840]   Yeah.
[00:09:07.840 --> 00:09:10.800]   But does everybody build the same thing together?
[00:09:10.800 --> 00:09:11.800]   Is that how you run it?
[00:09:11.800 --> 00:09:16.440]   It's like you get-- you sort of like say a problem, everybody works together.
[00:09:16.440 --> 00:09:20.200]   Like how-- I guess like how much do you kind of coordinate like everybody doing the exact
[00:09:20.200 --> 00:09:23.500]   same thing versus people going off on their own?
[00:09:23.500 --> 00:09:26.300]   So it depends what kind of workshop we're doing.
[00:09:26.300 --> 00:09:31.320]   So if we have our standard deep learning workshop, there's typically a topic and we already have
[00:09:31.320 --> 00:09:35.640]   prepared like a repository with the model that we're going to build.
[00:09:35.640 --> 00:09:37.520]   We sit down with 50 people.
[00:09:37.520 --> 00:09:38.520]   We do some theory.
[00:09:38.520 --> 00:09:42.760]   So we do first like maybe an hour of conceptual understanding of what is going to happen,
[00:09:42.760 --> 00:09:44.320]   what we're going to build.
[00:09:44.320 --> 00:09:49.760]   And then Dimitris, for example, he's like-- he's live coding from scratch.
[00:09:49.760 --> 00:09:54.880]   So he basically walks you through from the very beginning to getting your performance
[00:09:54.880 --> 00:09:56.520]   metrics.
[00:09:56.520 --> 00:10:01.780]   And so these kind of workshops are designed to do exactly this, only this.
[00:10:01.780 --> 00:10:03.600]   And people just follow along with the code.
[00:10:03.600 --> 00:10:05.520]   And they can live code from scratch.
[00:10:05.520 --> 00:10:10.080]   And this is something that people find really useful because-- especially like kind of the
[00:10:10.080 --> 00:10:11.520]   live coding aspect.
[00:10:11.520 --> 00:10:16.800]   Because sometimes when you're on your own, you look at blocks of code and you kind of
[00:10:16.800 --> 00:10:20.520]   try to figure out what is happening, try to figure out your own thing.
[00:10:20.520 --> 00:10:26.320]   But it's useful if someone actually writes code with you and explains what is happening.
[00:10:26.320 --> 00:10:28.680]   It's-- you'll learn just faster probably.
[00:10:28.680 --> 00:10:32.560]   Or this is at least what I find to be useful.
[00:10:32.560 --> 00:10:34.900]   On the other hand, we have much more open sessions.
[00:10:34.900 --> 00:10:41.400]   So especially like our hardware sessions where I do Edge AI, the only thing we provide is
[00:10:41.400 --> 00:10:43.160]   a ton of hardware.
[00:10:43.160 --> 00:10:46.860]   These are typically smaller groups, maybe 20, 25 people.
[00:10:46.860 --> 00:10:47.920]   And then people come in.
[00:10:47.920 --> 00:10:48.920]   They build teams.
[00:10:48.920 --> 00:10:50.640]   They choose their hardware.
[00:10:50.640 --> 00:10:52.720]   And they come up with their own idea.
[00:10:52.720 --> 00:10:54.000]   And they build their own stuff.
[00:10:54.000 --> 00:10:58.400]   And then at the end of the day, each team presents what they have been working on.
[00:10:58.400 --> 00:11:01.840]   So it really kind of depends on the session, I guess.
[00:11:01.840 --> 00:11:07.120]   Is there a different kind of culture in Japan than, say, in San Francisco?
[00:11:07.120 --> 00:11:09.320]   Are language barriers an issue at all?
[00:11:09.320 --> 00:11:12.360]   What's it like to be sort of-- I guess I know what it's like to be in San Francisco.
[00:11:12.360 --> 00:11:15.680]   But do you think that there's big differences coming from Japan?
[00:11:15.680 --> 00:11:18.560]   So I don't know San Francisco that well.
[00:11:18.560 --> 00:11:20.560]   So I've been to a few times.
[00:11:20.560 --> 00:11:23.160]   And I went to a lot of meetups, actually.
[00:11:23.160 --> 00:11:24.160]   And they're pretty cool.
[00:11:24.160 --> 00:11:27.820]   I think a lot more things are just happening in San Francisco.
[00:11:27.820 --> 00:11:31.600]   And I think a lot more things are supported probably in SF.
[00:11:31.600 --> 00:11:35.080]   In Japan, language is definitely an issue.
[00:11:35.080 --> 00:11:36.080]   It's a huge barrier.
[00:11:36.080 --> 00:11:39.320]   It is something that I've been constantly thinking about.
[00:11:39.320 --> 00:11:43.760]   In Japan, there are amazing communities in machine learning.
[00:11:43.760 --> 00:11:50.720]   There are two super big machine learning communities, the TensorFlow user group that is very related,
[00:11:50.720 --> 00:11:52.440]   of course, to Google.
[00:11:52.440 --> 00:11:56.120]   And then DeepLab, which is, I think, affiliated with Microsoft.
[00:11:56.120 --> 00:11:57.720]   Those guys are very big.
[00:11:57.720 --> 00:12:00.160]   And they're very, very Japanese.
[00:12:00.160 --> 00:12:03.000]   And everything is in Japanese.
[00:12:03.000 --> 00:12:04.000]   And then there's us.
[00:12:04.000 --> 00:12:07.160]   I think we're similar in size.
[00:12:07.160 --> 00:12:08.240]   We're English speaking.
[00:12:08.240 --> 00:12:14.640]   And yeah, this is one thing that has been bothering me so much because I'm always trying
[00:12:14.640 --> 00:12:19.340]   to find ways how to not have these isolated communities.
[00:12:19.340 --> 00:12:21.160]   So this is a challenge in Japan.
[00:12:21.160 --> 00:12:22.520]   This is definitely a challenge.
[00:12:22.520 --> 00:12:24.800]   And we're working on it.
[00:12:24.800 --> 00:12:28.560]   But other than that, you see that communities are growing.
[00:12:28.560 --> 00:12:32.880]   And that there is a huge demand also for machine learning talent.
[00:12:32.880 --> 00:12:38.480]   So apart from the kind of very Japan-specific problems like language barriers, I think it's
[00:12:38.480 --> 00:12:41.440]   a pretty good and active environment to be in.
[00:12:41.440 --> 00:12:47.200]   Yeah, I remember I went to Japan last year and I've worked off and on with Japan as a
[00:12:47.200 --> 00:12:51.560]   market and I've always been impressed by how excited people are about machine learning.
[00:12:51.560 --> 00:12:56.560]   Even going back like 10, 15 years, it seemed like there's a lot of enthusiasm for it.
[00:12:56.560 --> 00:12:57.880]   And actually, I've been kind of wrestling.
[00:12:57.880 --> 00:13:02.240]   I just would like to find a way to translate our documentation into Japanese and kind of
[00:13:02.240 --> 00:13:03.240]   keep it up to date.
[00:13:03.240 --> 00:13:04.240]   Yeah.
[00:13:04.240 --> 00:13:06.240]   I've been thinking about that lately.
[00:13:06.240 --> 00:13:09.120]   Yeah, I think that would be a good move.
[00:13:09.120 --> 00:13:14.400]   We were also like only focusing on English, but there needs to be like this bridge and
[00:13:14.400 --> 00:13:15.720]   we need to start somewhere.
[00:13:15.720 --> 00:13:18.380]   So we also started translating.
[00:13:18.380 --> 00:13:23.840]   We worked with a TA from Stanford to translate their CS deep learning course material or
[00:13:23.840 --> 00:13:28.800]   course notes into Japanese to make it more accessible to people and have like bilingual
[00:13:28.800 --> 00:13:30.600]   kind of resources for people.
[00:13:30.600 --> 00:13:36.080]   So we're trying also very hard kind of to include as many people as possible.
[00:13:36.080 --> 00:13:37.080]   That's awesome.
[00:13:37.080 --> 00:13:42.600]   Hi, we'd love to take a moment to tell you guys about Weights and Biases.
[00:13:42.600 --> 00:13:48.120]   Weights and Biases is a tool that helps you track and visualize every detail of your machine
[00:13:48.120 --> 00:13:49.120]   learning models.
[00:13:49.120 --> 00:13:53.520]   We help you debug your machine learning models in real time.
[00:13:53.520 --> 00:13:58.120]   Easily and advance the state of the art in machine learning.
[00:13:58.120 --> 00:14:03.320]   You can integrate Weights and Biases into your models with just a few lines of code.
[00:14:03.320 --> 00:14:08.080]   With hyperparameter sweeps, you can find the best set of hyperparameters for your models
[00:14:08.080 --> 00:14:10.020]   automatically.
[00:14:10.020 --> 00:14:15.420]   You can also track and compare how many GPU resources your models are using.
[00:14:15.420 --> 00:14:22.120]   With one line of code, you can visualize model predictions in form of images, videos, audio,
[00:14:22.120 --> 00:14:27.880]   plotly charts, molecular data, segmentation maps, and 3D point clouds.
[00:14:27.880 --> 00:14:33.720]   You can save everything you need to reproduce your models days, weeks, or even months after
[00:14:33.720 --> 00:14:34.720]   training.
[00:14:34.720 --> 00:14:39.840]   Finally, with reports, you can make your models come alive.
[00:14:39.840 --> 00:14:44.840]   Reports are like blog posts in which your readers can interact with your model metrics
[00:14:44.840 --> 00:14:46.640]   and predictions.
[00:14:46.640 --> 00:14:52.840]   Reports serve as a centralized repository of metrics, predictions, hyperparameter stride,
[00:14:52.840 --> 00:14:53.840]   and accompanying notes.
[00:14:53.840 --> 00:15:00.260]   All of this together gives you a bird's eye view of your machine learning workflow.
[00:15:00.260 --> 00:15:05.760]   You can use reports to share your model insights, keep your team on the same page, and collaborate
[00:15:05.760 --> 00:15:06.760]   effectively remotely.
[00:15:06.760 --> 00:15:11.880]   I'll leave a link in the show notes below to help you get started.
[00:15:11.880 --> 00:15:13.840]   And now let's get back to the episode.
[00:15:13.840 --> 00:15:18.640]   I mean, when you think about sort of democratization of AI, what else do you think is important?
[00:15:18.640 --> 00:15:21.040]   Like how do you think about that?
[00:15:21.040 --> 00:15:27.600]   Maybe this is because of my personal background, because I am a domain expert, but I also see
[00:15:27.600 --> 00:15:33.760]   like how important machine learning is and is going to be in the future, in the near
[00:15:33.760 --> 00:15:34.760]   future.
[00:15:34.760 --> 00:15:40.920]   If possible, we should have as many people as possible involved in even technical stuff.
[00:15:40.920 --> 00:15:45.480]   So there have been like a lot of democratization efforts.
[00:15:45.480 --> 00:15:52.380]   If you look at H2O, for example, with AutoML, like making it really very easy to experiment,
[00:15:52.380 --> 00:15:57.180]   but also other, of course, like AutoML platforms from tech giants.
[00:15:57.180 --> 00:16:01.680]   For us, it's like a lot of education that we do.
[00:16:01.680 --> 00:16:03.280]   We work with a lot of universities.
[00:16:03.280 --> 00:16:09.160]   So something that I kind of personally like doing is working with research scientists
[00:16:09.160 --> 00:16:12.000]   or students coming from different backgrounds.
[00:16:12.000 --> 00:16:16.360]   So I think it's machine learning could be super useful for people that work with a lot
[00:16:16.360 --> 00:16:17.440]   of data.
[00:16:17.440 --> 00:16:21.920]   And we worked with a lot of super interesting people.
[00:16:21.920 --> 00:16:27.040]   For example, last year in summer, I think we were at the Tokyo Institute of Technology
[00:16:27.040 --> 00:16:29.440]   where we held a two-day bootcamp for ELSI.
[00:16:29.440 --> 00:16:32.440]   ELSI is the Earth Life Sciences Institute.
[00:16:32.440 --> 00:16:33.920]   And those guys are amazing.
[00:16:33.920 --> 00:16:40.440]   They're astrophysicists, they're planetary sciences, computational biologists, chemists,
[00:16:40.440 --> 00:16:43.160]   like mind-blowing stuff.
[00:16:43.160 --> 00:16:48.040]   And we had a room full of people and they all work with different kinds of data sets
[00:16:48.040 --> 00:16:51.880]   and problem sets and with different tools and techniques.
[00:16:51.880 --> 00:16:56.000]   And machine learning could be one way for them to get new insights and maybe even to
[00:16:56.000 --> 00:16:58.080]   advance science.
[00:16:58.080 --> 00:17:03.000]   So these kinds of things are, I think, for me personally, super exciting.
[00:17:03.000 --> 00:17:08.440]   Getting more domain experts involved into technical stuff, doing open education, doing
[00:17:08.440 --> 00:17:09.440]   open science.
[00:17:09.440 --> 00:17:12.880]   This has been pretty, pretty interesting.
[00:17:12.880 --> 00:17:18.400]   What about people without kind of like a math or programming background?
[00:17:18.400 --> 00:17:21.280]   Do you think there's room for them to contribute too?
[00:17:21.280 --> 00:17:22.660]   Yeah, absolutely.
[00:17:22.660 --> 00:17:25.520]   I think so.
[00:17:25.520 --> 00:17:31.480]   There are Jeremy Howard and Rachel, they've been doing the best job ever into getting
[00:17:31.480 --> 00:17:35.080]   domain experts on board.
[00:17:35.080 --> 00:17:39.240]   You do have to have some coding background, so you should be able to write some Python
[00:17:39.240 --> 00:17:40.240]   code.
[00:17:40.240 --> 00:17:45.720]   But going through fast AI courses, for example, it's a more top-down approach.
[00:17:45.720 --> 00:17:50.640]   And they're exactly democratizing machine learning or making it uncool by having so
[00:17:50.640 --> 00:17:53.200]   much more people just involved.
[00:17:53.200 --> 00:17:58.280]   And this top-down approach allows you to get into deep learning without having to have
[00:17:58.280 --> 00:18:04.400]   a PhD at Stanford in computer science or like a really strong math background.
[00:18:04.400 --> 00:18:05.400]   You build stuff.
[00:18:05.400 --> 00:18:09.920]   So you start with thinking about your problem and your data and to build stuff.
[00:18:09.920 --> 00:18:16.040]   And then afterwards, you start digging deeper into the math, for example, that you might
[00:18:16.040 --> 00:18:19.920]   need for your particular project or problem.
[00:18:19.920 --> 00:18:22.880]   And I think I really like this kind of approach.
[00:18:22.880 --> 00:18:27.440]   That's very similar to what we've been doing with MLT as well.
[00:18:27.440 --> 00:18:31.600]   Even though we also do a lot of fundamental work.
[00:18:31.600 --> 00:18:36.240]   So we also have study sessions for machine learning, math, and other things.
[00:18:36.240 --> 00:18:40.880]   But I think there's definitely a room for people who are coming from different backgrounds.
[00:18:40.880 --> 00:18:47.120]   And I think if they find it even potentially useful, they should look into it.
[00:18:47.120 --> 00:18:54.400]   I mean, you've probably seen people go from novices to knowing a lot about ML.
[00:18:54.400 --> 00:18:59.280]   And people ask me all the time, kind of how do I get into this stuff?
[00:18:59.280 --> 00:19:03.640]   Do you like have any advice from the data that you're seeing on what folks should do
[00:19:03.640 --> 00:19:07.560]   if you have no background and you really want to go deep on this stuff?
[00:19:07.560 --> 00:19:08.920]   Yeah, for sure.
[00:19:08.920 --> 00:19:11.920]   So I think two things are super important.
[00:19:11.920 --> 00:19:15.800]   The first thing is, don't neglect your background.
[00:19:15.800 --> 00:19:22.080]   Don't think that you have to start over from zero and you don't know anything before that.
[00:19:22.080 --> 00:19:25.920]   Leverage your background, leverage your experience, your professional experience, your academic
[00:19:25.920 --> 00:19:32.320]   background, whatever it is that you have been working on in the past years, leverage that.
[00:19:32.320 --> 00:19:34.360]   It's the same.
[00:19:34.360 --> 00:19:36.560]   There are many examples for that.
[00:19:36.560 --> 00:19:41.400]   For example, you could be a hardware engineer and you know a lot about hardware.
[00:19:41.400 --> 00:19:43.720]   And now you're getting into machine learning and deep learning.
[00:19:43.720 --> 00:19:49.080]   Now leverage that background and that expertise and learn about machine learning and how to
[00:19:49.080 --> 00:19:50.840]   combine these two things.
[00:19:50.840 --> 00:19:52.480]   In my case, it's language.
[00:19:52.480 --> 00:19:58.160]   So I've studied language as a system for many, many years and I use machine learning and
[00:19:58.160 --> 00:20:04.160]   the combination of language and machine learning to kind of bring maybe interesting and unique
[00:20:04.160 --> 00:20:08.080]   insights to the particular projects that I'm working on.
[00:20:08.080 --> 00:20:12.600]   I talked to a recruiter here in Japan and I asked him, so what does the market need?
[00:20:12.600 --> 00:20:17.220]   And he said, well, it's here in Japan, it's not enough just to know deep learning.
[00:20:17.220 --> 00:20:19.280]   You have to have some sort of specialization.
[00:20:19.280 --> 00:20:25.960]   You have to have some sort of domain expertise, some way how you can use this kind of deep
[00:20:25.960 --> 00:20:28.760]   learning in combination with something else.
[00:20:28.760 --> 00:20:32.160]   It could be software engineering, it could be hardware, it could be language, it could
[00:20:32.160 --> 00:20:33.640]   be anything.
[00:20:33.640 --> 00:20:34.640]   So this is the one thing.
[00:20:34.640 --> 00:20:37.920]   And the second thing is when you're coming from a different background and you want to
[00:20:37.920 --> 00:20:42.680]   go into machine learning, there's of course like two approaches.
[00:20:42.680 --> 00:20:47.040]   Either you start with the fundamentals, you start with math, or you do what I just earlier
[00:20:47.040 --> 00:20:48.700]   mentioned, top down.
[00:20:48.700 --> 00:20:52.540]   You start with a project and you just write code, build that project, and then figure
[00:20:52.540 --> 00:20:53.540]   out details later.
[00:20:53.540 --> 00:20:59.280]   And I think the most important thing here is to figure out what is interesting to you.
[00:20:59.280 --> 00:21:03.440]   What would be something that really kind of catches your attention and you love working
[00:21:03.440 --> 00:21:07.700]   on and make that decision and then start working on that.
[00:21:07.700 --> 00:21:11.680]   Because the problem here is that there are too many options.
[00:21:11.680 --> 00:21:14.260]   You could do too many things.
[00:21:14.260 --> 00:21:16.080]   Everything seems to be interesting.
[00:21:16.080 --> 00:21:21.080]   But if you spend a little time here, a little time there, you will get maybe some shallow
[00:21:21.080 --> 00:21:25.360]   understanding of a few things, but you'll not advance as quickly as you might want.
[00:21:25.360 --> 00:21:30.040]   So figure out what you want to do and leverage your background is probably my advice.
[00:21:30.040 --> 00:21:35.380]   Do you think that you see people being more successful kind of starting from the fundamentals
[00:21:35.380 --> 00:21:36.380]   or starting with a project?
[00:21:36.380 --> 00:21:40.360]   Because you mentioned those are sort of two different approaches and people gravitate
[00:21:40.360 --> 00:21:41.680]   towards one or the other.
[00:21:41.680 --> 00:21:45.400]   Do you have a preference or can both work?
[00:21:45.400 --> 00:21:46.440]   Both can definitely work.
[00:21:46.440 --> 00:21:52.720]   I think we were just like only talking about domain experts and people coming from different
[00:21:52.720 --> 00:21:53.720]   backgrounds.
[00:21:53.720 --> 00:22:01.120]   But of course, I think what the research, what academia and industry needs just as much
[00:22:01.120 --> 00:22:06.600]   or even more is people with very, very strong CS backgrounds, with very strong math backgrounds
[00:22:06.600 --> 00:22:11.240]   that know how to optimize and know how to work on theoretical things.
[00:22:11.240 --> 00:22:14.160]   So I'm not saying like this is not important.
[00:22:14.160 --> 00:22:15.160]   Not at all.
[00:22:15.160 --> 00:22:19.280]   Of course, this is still the norm and this is what probably employers want to see the
[00:22:19.280 --> 00:22:21.000]   most.
[00:22:21.000 --> 00:22:26.120]   And if you're coming from a strong CS or math background, I think you already have
[00:22:26.120 --> 00:22:30.320]   a strong foundation to go very deep into machine learning and deep learning.
[00:22:30.320 --> 00:22:34.800]   But I just want to say like there's room for other people as well.
[00:22:34.800 --> 00:22:35.800]   Okay.
[00:22:35.800 --> 00:22:40.200]   So this is a little bit outside of the scope maybe of a ML podcast, but I'm just fascinated
[00:22:40.200 --> 00:22:41.200]   by this.
[00:22:41.200 --> 00:22:42.840]   So maybe it is.
[00:22:42.840 --> 00:22:44.760]   What about starting a community?
[00:22:44.760 --> 00:22:49.080]   Like do you have advice on someone in an area like you where they want to find like-minded
[00:22:49.080 --> 00:22:50.080]   people?
[00:22:50.080 --> 00:22:52.040]   I mean, do you have any advice on that?
[00:22:52.040 --> 00:22:57.200]   Like if I'm in a city where there isn't already like an ML group, how would you go about finding
[00:22:57.200 --> 00:22:58.200]   people?
[00:22:58.200 --> 00:22:59.200]   Yeah.
[00:22:59.200 --> 00:23:02.960]   And like so many people write me messages on that.
[00:23:02.960 --> 00:23:04.400]   They're in some...
[00:23:04.400 --> 00:23:05.400]   Yeah.
[00:23:05.400 --> 00:23:06.400]   Yeah.
[00:23:06.400 --> 00:23:07.400]   That's so great.
[00:23:07.400 --> 00:23:11.280]   Either in remote areas or in cities where like literally something like a machine learning
[00:23:11.280 --> 00:23:13.720]   community still doesn't exist.
[00:23:13.720 --> 00:23:17.680]   And I would really suggest, I would always say like, go for it.
[00:23:17.680 --> 00:23:23.560]   If there is no such thing out there, be the first one to do it because MLT has like evolved
[00:23:23.560 --> 00:23:25.440]   into an amazing community.
[00:23:25.440 --> 00:23:32.040]   Like I'm like literally, I'm amazed by how active and how engaged the communities and
[00:23:32.040 --> 00:23:38.560]   all those guys, they have full-time jobs, but they still find kind of time to work on
[00:23:38.560 --> 00:23:42.560]   open source and to teach other people and to do these kinds of workshops.
[00:23:42.560 --> 00:23:44.000]   So it's pretty amazing.
[00:23:44.000 --> 00:23:48.600]   So I would really kind of suggest to think about starting a community wherever you are.
[00:23:48.600 --> 00:23:51.680]   Do you have any practical tips for getting it off the ground?
[00:23:51.680 --> 00:23:55.800]   Because it seems kind of daunting to me to try to start that and keep people engaged.
[00:23:55.800 --> 00:23:58.320]   How do you get people to keep talking?
[00:23:58.320 --> 00:24:02.400]   I think the most important thing is to do something that you are really interested in,
[00:24:02.400 --> 00:24:06.360]   because if you're starting it, a lot of things will depend on you.
[00:24:06.360 --> 00:24:10.960]   And the key is, I think somebody wrote it on Twitter recently, the key also to MLT is
[00:24:10.960 --> 00:24:11.960]   consistency.
[00:24:11.960 --> 00:24:17.920]   Consistently just keep doing stuff that we think is exciting and interesting.
[00:24:17.920 --> 00:24:24.680]   So start from what you're interested in, start from your own problem set or from your own
[00:24:24.680 --> 00:24:28.040]   need and more people will follow.
[00:24:28.040 --> 00:24:33.840]   And then like more practical things, you know, there's always the thing, we started doing
[00:24:33.840 --> 00:24:40.120]   remote meetups so that there is not the kind of burden of having to find a venue and a
[00:24:40.120 --> 00:24:42.200]   sponsor and other things.
[00:24:42.200 --> 00:24:47.200]   So this is an option how to kick things off to find more people who are interested.
[00:24:47.200 --> 00:24:50.240]   That makes it very easy.
[00:24:50.240 --> 00:24:54.120]   There's no easier way probably than to start like remote meetups.
[00:24:54.120 --> 00:24:58.800]   On the other hand, if you want to start something in your city, you might want to check out
[00:24:58.800 --> 00:25:03.920]   like first of all, like form a small peer group around yourself and kind of try to figure
[00:25:03.920 --> 00:25:05.480]   out what you want to do.
[00:25:05.480 --> 00:25:10.280]   And then start to look for a physical place and figure out if you want to do hands on
[00:25:10.280 --> 00:25:15.840]   stuff, if you want to do like more educational stuff, learn together and get it out there.
[00:25:15.840 --> 00:25:18.320]   Like try to reach as many people as possible.
[00:25:18.320 --> 00:25:23.240]   And I think, you know, I just yesterday I talked to someone, a journalist, and he said
[00:25:23.240 --> 00:25:26.520]   to me, wow, there's no such thing for writers out there.
[00:25:26.520 --> 00:25:28.680]   I want to start something for writers out there.
[00:25:28.680 --> 00:25:31.560]   And I think it's kind of the same thing, right?
[00:25:31.560 --> 00:25:35.960]   There's a need for all these niche groups and communities.
[00:25:35.960 --> 00:25:40.680]   So I think if you get it out there, and if you do things that you're very passionate
[00:25:40.680 --> 00:25:42.160]   about, people will follow.
[00:25:42.160 --> 00:25:49.160]   Do you have any thoughts on like diversity and inclusion in ML and in these groups that
[00:25:49.160 --> 00:25:50.160]   you create?
[00:25:50.160 --> 00:25:52.480]   Is that something that is top of mind for you?
[00:25:52.480 --> 00:25:55.080]   Yeah, that's something that is very important to us.
[00:25:55.080 --> 00:26:00.760]   Luckily, within MLT, we're very diverse, kind of four and a half thousand people in
[00:26:00.760 --> 00:26:06.360]   terms of, you know, countries and languages and skill sets and backgrounds and professional
[00:26:06.360 --> 00:26:07.360]   experiences.
[00:26:07.360 --> 00:26:10.440]   So this is really super diverse.
[00:26:10.440 --> 00:26:12.720]   But women are super underrepresented.
[00:26:12.720 --> 00:26:18.040]   I think two years ago, when we started on working on deep learning workshops, we had
[00:26:18.040 --> 00:26:21.000]   60 engineers, and I was the only woman.
[00:26:21.000 --> 00:26:26.080]   So I realized, okay, yeah, we really needed to do something about that.
[00:26:26.080 --> 00:26:32.680]   So we're doing like very specific, not only events, but also projects that support diversity
[00:26:32.680 --> 00:26:33.880]   and inclusion.
[00:26:33.880 --> 00:26:38.440]   We do a lot of women in machine learning events that are supported by Google Japan, Mercury
[00:26:38.440 --> 00:26:41.120]   and other companies.
[00:26:41.120 --> 00:26:46.680]   We also do projects that I just earlier mentioned, where we had one of them was, we had about
[00:26:46.680 --> 00:26:53.560]   12 bilingual engineers that worked on translating some of the Stanford course notes into Japanese
[00:26:53.560 --> 00:26:59.480]   and having this kind of bilingual resources for people, just to be more inclusive in general,
[00:26:59.480 --> 00:27:04.760]   also to the Japanese community, because we are literally in Japan, and we are very diverse.
[00:27:04.760 --> 00:27:10.080]   But it still kind of seems like there's a disconnect between a Japanese community and
[00:27:10.080 --> 00:27:12.280]   an English speaking community.
[00:27:12.280 --> 00:27:14.420]   And I think it has never been more important.
[00:27:14.420 --> 00:27:18.840]   We all know like tech in general is multidisciplinary.
[00:27:18.840 --> 00:27:21.200]   Machine learning should be as well multidisciplinary.
[00:27:21.200 --> 00:27:25.240]   We need people with different skills, with different expertises.
[00:27:25.240 --> 00:27:28.940]   We need people with different backgrounds in general.
[00:27:28.940 --> 00:27:31.720]   So this is something we all have to work on, I think.
[00:27:31.720 --> 00:27:38.040]   Do you have any other suggestions for making a community feel more inclusive?
[00:27:38.040 --> 00:27:47.080]   So in our core team, we decided very early on that we want to create an environment that
[00:27:47.080 --> 00:27:50.660]   is very collaborative, and that is very inclusive.
[00:27:50.660 --> 00:27:58.980]   That means that we really want to don't have this as kind of this elite math machine learning
[00:27:58.980 --> 00:28:00.400]   group.
[00:28:00.400 --> 00:28:03.980]   We want to include as many people as possible.
[00:28:03.980 --> 00:28:08.600]   And we want to have decision processes.
[00:28:08.600 --> 00:28:14.100]   We want to have the community involved in what directions we take, what kind of things
[00:28:14.100 --> 00:28:16.700]   we're tackling next.
[00:28:16.700 --> 00:28:22.780]   And we do like every project that we do, and every workshop, and every study session, we
[00:28:22.780 --> 00:28:24.960]   kind of have that sort of mindset.
[00:28:24.960 --> 00:28:30.460]   So when you look at our math sessions, so last year we started doing remote math reading
[00:28:30.460 --> 00:28:31.460]   sessions.
[00:28:31.460 --> 00:28:38.700]   So this is a book that walks you through some machine learning math.
[00:28:38.700 --> 00:28:42.380]   And so more than 1,000 people signed up from all over the world.
[00:28:42.380 --> 00:28:45.400]   So we have sessions in the Bay Area.
[00:28:45.400 --> 00:28:49.500]   We have sessions in India, in APAC here in Japan.
[00:28:49.500 --> 00:28:56.180]   And the thing is, it is very inclusive because the sessions, the people that join those sessions,
[00:28:56.180 --> 00:28:58.820]   their levels of math are very different.
[00:28:58.820 --> 00:29:00.420]   So we have complete beginners.
[00:29:00.420 --> 00:29:03.460]   We have people that are coming from completely different backgrounds.
[00:29:03.460 --> 00:29:06.740]   But in our Tokyo sessions, we also have mathematicians.
[00:29:06.740 --> 00:29:07.740]   We have experts.
[00:29:07.740 --> 00:29:12.740]   We have PhDs in math, people that have taught math for many years.
[00:29:12.740 --> 00:29:14.580]   And it's pretty amazing.
[00:29:14.580 --> 00:29:19.260]   It's a very interactive-- after the reading, it's a very interactive discussion where people
[00:29:19.260 --> 00:29:20.940]   ask all sorts of questions.
[00:29:20.940 --> 00:29:26.100]   And together, we kind of brainstorm around things and try to-- our experts like Emil
[00:29:26.100 --> 00:29:30.460]   and Jason, they try to explain mathematical concepts.
[00:29:30.460 --> 00:29:31.540]   And it's been pretty amazing.
[00:29:31.540 --> 00:29:36.340]   So I think really having this mindset, whatever you do, that you need this.
[00:29:36.340 --> 00:29:40.300]   It's not like-- it's something that is actually enriching whatever you do.
[00:29:40.300 --> 00:29:41.860]   It's something that is very important.
[00:29:41.860 --> 00:29:45.140]   And having that mindset is probably going to help a lot.
[00:29:45.140 --> 00:29:46.660]   That's super cool.
[00:29:46.660 --> 00:29:47.660]   That sounds really fun.
[00:29:47.660 --> 00:29:48.660]   It is.
[00:29:48.660 --> 00:29:49.660]   I'd love to attend.
[00:29:49.660 --> 00:29:50.660]   It's been pretty fun.
[00:29:50.660 --> 00:29:51.660]   Yeah, yeah.
[00:29:51.660 --> 00:29:53.180]   It's been pretty good.
[00:29:53.180 --> 00:29:57.380]   What is something underrated maybe in machine learning that you think people don't pay enough
[00:29:57.380 --> 00:29:59.460]   attention to?
[00:29:59.460 --> 00:30:03.300]   I think something still underrated in machine learning is data.
[00:30:03.300 --> 00:30:04.300]   Still?
[00:30:04.300 --> 00:30:05.300]   Oh my god.
[00:30:05.300 --> 00:30:06.300]   Yeah, I think so.
[00:30:06.300 --> 00:30:08.420]   It doesn't matter who I talk to.
[00:30:08.420 --> 00:30:14.740]   It's like always-- I feel like there's this kind of-- it's a troublesome thing to do,
[00:30:14.740 --> 00:30:15.740]   right?
[00:30:15.740 --> 00:30:16.740]   You don't want to work with data.
[00:30:16.740 --> 00:30:19.520]   You want to write machine learning algorithms.
[00:30:19.520 --> 00:30:20.980]   You want to train models.
[00:30:20.980 --> 00:30:25.340]   You want to get good accuracy and push accuracy or metric.
[00:30:25.340 --> 00:30:26.380]   It's not about data.
[00:30:26.380 --> 00:30:31.140]   So data is kind of the least that people think about sometimes, or this is at least kind
[00:30:31.140 --> 00:30:35.220]   of my understanding of it.
[00:30:35.220 --> 00:30:42.180]   And I think we should definitely think more about data and put more emphasis on data.
[00:30:42.180 --> 00:30:45.780]   Maybe this is also because of my own background, because I've been working with data pretty
[00:30:45.780 --> 00:30:48.520]   much all my career.
[00:30:48.520 --> 00:30:52.460]   And just three years ago, I started working with machine learning algorithms.
[00:30:52.460 --> 00:30:56.100]   But yeah, it all starts with data, and it all probably ends with data.
[00:30:56.100 --> 00:31:01.720]   I think Chip Hewitt just mentioned recently who owns the data pipeline will own the machine
[00:31:01.720 --> 00:31:05.420]   learning and production or the machine learning system, I guess.
[00:31:05.420 --> 00:31:07.120]   I don't know if it's still that case.
[00:31:07.120 --> 00:31:11.380]   Maybe in SF, maybe in the Bay Area, people think more about data.
[00:31:11.380 --> 00:31:12.380]   I don't know.
[00:31:12.380 --> 00:31:13.380]   I don't know.
[00:31:13.380 --> 00:31:15.300]   I mean, I think my background is similar to yours.
[00:31:15.300 --> 00:31:19.360]   And so I feel like data is so unbelievably important, I guess.
[00:31:19.360 --> 00:31:24.760]   It's not possible for it to be properly rated for its contribution to ML.
[00:31:24.760 --> 00:31:25.760]   Cool.
[00:31:25.760 --> 00:31:31.640]   And then when you think about making machine learning work in the real world for real applications,
[00:31:31.640 --> 00:31:35.320]   what's the hardest part about getting it to work?
[00:31:35.320 --> 00:31:38.560]   So in our case, we love to experiment with new things.
[00:31:38.560 --> 00:31:40.840]   And I think it's difficult.
[00:31:40.840 --> 00:31:44.760]   When you're trying new things, you kind of need to figure out a lot of stuff.
[00:31:44.760 --> 00:31:51.560]   And generally, I think in production environments, there's a lot of experimenting and try to
[00:31:51.560 --> 00:31:52.560]   see what works.
[00:31:52.560 --> 00:31:59.080]   So making a production pipeline work and deploying machine learning for different use cases has
[00:31:59.080 --> 00:32:06.920]   different challenges from data all the way to software engineering to monitoring your
[00:32:06.920 --> 00:32:11.080]   model, like how it changes in different real world scenarios.
[00:32:11.080 --> 00:32:18.240]   So I think we need to, even though things are taking off, there's still a lot of room
[00:32:18.240 --> 00:32:22.480]   to work on these kind of things, infrastructure things, deployment things, finding new use
[00:32:22.480 --> 00:32:27.920]   cases, finding use cases that make a lot of sense for machine learning.
[00:32:27.920 --> 00:32:30.000]   At the same time, I think this is super exciting.
[00:32:30.000 --> 00:32:35.920]   So this is something that really kind of excites me probably the most, is thinking about use
[00:32:35.920 --> 00:32:41.840]   cases and experimenting a lot and trying new things.
[00:32:41.840 --> 00:32:48.600]   We don't work, like at MLT, we're not working on, we do work on production things as well,
[00:32:48.600 --> 00:32:50.040]   but it's not our main thing.
[00:32:50.040 --> 00:32:54.780]   Our main thing is just trying out new things, experimenting and make POCs.
[00:32:54.780 --> 00:33:00.620]   So we don't actually deploy a lot of things on a large scale to production.
[00:33:00.620 --> 00:33:04.560]   So maybe I can't talk about the main challenges here.
[00:33:04.560 --> 00:33:12.200]   But what I can say is that we try, like if we take Edge, for example, we're trying out
[00:33:12.200 --> 00:33:16.600]   a lot of things, we're working with different hardware, we're trying to think about different
[00:33:16.600 --> 00:33:19.800]   use cases where these things can be deployed.
[00:33:19.800 --> 00:33:26.720]   And like a lot of things, you know, just don't work out and fail, but that's totally fine.
[00:33:26.720 --> 00:33:27.720]   That's good as well.
[00:33:27.720 --> 00:33:32.120]   This is something that we kind of also need to grow and to figure out things.
[00:33:32.120 --> 00:33:36.560]   But then at the same time, we also build things that work and that are super interesting.
[00:33:36.560 --> 00:33:39.960]   So yeah, it's a lot of experimenting, I guess.
[00:33:39.960 --> 00:33:40.960]   Yeah.
[00:33:40.960 --> 00:33:41.960]   Makes sense.
[00:33:41.960 --> 00:33:42.960]   Okay.
[00:33:42.960 --> 00:33:49.040]   So my final question, if I am listening to you talk and I get excited about, you know,
[00:33:49.040 --> 00:33:52.880]   joining one of your virtual events or something, how do I find out more and how do I get more
[00:33:52.880 --> 00:33:54.280]   involved with MLT?
[00:33:54.280 --> 00:33:55.280]   Can I do that remotely?
[00:33:55.280 --> 00:33:56.880]   Yes, you can.
[00:33:56.880 --> 00:33:57.880]   Definitely.
[00:33:57.880 --> 00:34:02.280]   So if you, as I mentioned earlier, like on Meetup, you can find all of our events and
[00:34:02.280 --> 00:34:05.080]   a lot of them are actually remote.
[00:34:05.080 --> 00:34:10.040]   So if you want like to be part of an event or a meetup or something like that, you can
[00:34:10.040 --> 00:34:14.320]   just join Meetup and we'll post everything there.
[00:34:14.320 --> 00:34:15.600]   There's also more active things.
[00:34:15.600 --> 00:34:21.640]   So if you would like to work on open source or doing some other things or get more involved
[00:34:21.640 --> 00:34:24.920]   in general, you can join our Slack group.
[00:34:24.920 --> 00:34:28.720]   Because pretty much the whole community there talking about different things.
[00:34:28.720 --> 00:34:33.240]   So in more technical depth, so you can also find people there to work on projects and
[00:34:33.240 --> 00:34:35.080]   do other things.
[00:34:35.080 --> 00:34:39.960]   And so these are kind of the main two things, the Meetup for events and maybe Slack for
[00:34:39.960 --> 00:34:40.960]   projects and other stuff.
[00:34:40.960 --> 00:34:41.960]   Awesome.
[00:34:41.960 --> 00:34:42.960]   Thank you so much.
[00:34:42.960 --> 00:34:43.960]   It was great to talk with you.
[00:34:43.960 --> 00:34:44.960]   Yeah.
[00:34:44.960 --> 00:34:45.960]   Thank you so much for having me.
[00:34:45.960 --> 00:34:46.960]   My pleasure.
[00:34:46.960 --> 00:34:46.960]   Thank you.
[00:34:47.960 --> 00:34:47.960]   Bye.
[00:34:47.960 --> 00:34:52.960]   Bye.
[00:34:52.960 --> 00:34:55.540]   (gentle music)

