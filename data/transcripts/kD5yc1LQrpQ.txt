
[00:00:00.000 --> 00:00:02.800]   The following is a conversation with Michio Kaku.
[00:00:02.800 --> 00:00:05.120]   He's a theoretical physicist, futurist,
[00:00:05.120 --> 00:00:08.320]   and professor at the City College of New York.
[00:00:08.320 --> 00:00:10.760]   He's the author of many fascinating books
[00:00:10.760 --> 00:00:12.840]   that explore the nature of our reality
[00:00:12.840 --> 00:00:15.520]   and the future of our civilization.
[00:00:15.520 --> 00:00:19.200]   They include Einstein's Cosmos, Physics of the Impossible,
[00:00:19.200 --> 00:00:21.600]   Future of the Mind, Parallel Worlds,
[00:00:21.600 --> 00:00:24.240]   and his latest, The Future of Humanity,
[00:00:24.240 --> 00:00:26.640]   Terraforming Mars, Interstellar Travel,
[00:00:26.640 --> 00:00:29.960]   Immortality, and Our Destiny Beyond Earth.
[00:00:29.960 --> 00:00:32.960]   I think it's beautiful and important
[00:00:32.960 --> 00:00:35.760]   when a scientific mind can fearlessly explore
[00:00:35.760 --> 00:00:37.600]   through conversation subjects
[00:00:37.600 --> 00:00:40.200]   just outside of our understanding.
[00:00:40.200 --> 00:00:43.440]   That, to me, is where artificial intelligence is today,
[00:00:43.440 --> 00:00:45.680]   just outside of our understanding,
[00:00:45.680 --> 00:00:47.440]   a place we have to reach for
[00:00:47.440 --> 00:00:50.160]   if we're to uncover the mysteries of the human mind
[00:00:50.160 --> 00:00:53.880]   and build human-level and superhuman-level AI systems
[00:00:53.880 --> 00:00:56.640]   that transform our world for the better.
[00:00:56.640 --> 00:00:59.240]   This is the Artificial Intelligence Podcast.
[00:00:59.240 --> 00:01:01.600]   If you enjoy it, subscribe on YouTube,
[00:01:01.600 --> 00:01:04.640]   give it five stars on iTunes, support it on Patreon,
[00:01:04.640 --> 00:01:06.640]   or simply connect with me on Twitter,
[00:01:06.640 --> 00:01:09.920]   Alex Friedman, spelled F-R-I-D-M-A-N.
[00:01:09.920 --> 00:01:13.720]   And now, here's my conversation with Michio Kaku.
[00:01:13.720 --> 00:01:17.400]   You've mentioned that we just might make contact
[00:01:17.400 --> 00:01:19.640]   with aliens, or at least hear from them,
[00:01:19.640 --> 00:01:21.760]   within this century.
[00:01:21.760 --> 00:01:24.960]   Can you elaborate on your intuition behind that optimism?
[00:01:24.960 --> 00:01:28.160]   - Well, this is pure speculation, of course.
[00:01:28.160 --> 00:01:29.000]   - Of course.
[00:01:29.000 --> 00:01:31.200]   - Given the fact that we've already identified
[00:01:31.200 --> 00:01:34.720]   4,000 exoplanets orbiting other stars,
[00:01:34.720 --> 00:01:37.560]   and we have a census of the Milky Way galaxy
[00:01:37.560 --> 00:01:39.160]   for the first time,
[00:01:39.160 --> 00:01:43.560]   we know that on average, every single star, on average,
[00:01:43.560 --> 00:01:45.640]   has a planet going around it,
[00:01:45.640 --> 00:01:47.720]   and about one-fifth or so of them
[00:01:47.720 --> 00:01:51.240]   have Earth-sized planets going around them.
[00:01:51.240 --> 00:01:52.960]   So just do the math.
[00:01:52.960 --> 00:01:56.160]   We're talking about, out of 100 billion stars
[00:01:56.160 --> 00:01:58.160]   in the Milky Way galaxy,
[00:01:58.160 --> 00:01:59.840]   we're talking about billions
[00:01:59.840 --> 00:02:02.920]   of potential Earth-sized planets.
[00:02:02.920 --> 00:02:05.760]   And to believe that we're the only one
[00:02:05.760 --> 00:02:09.160]   is, I think, rather ridiculous, given the odds.
[00:02:09.160 --> 00:02:11.600]   And how many galaxies are there?
[00:02:11.600 --> 00:02:14.560]   Within sight of the Hubble Space Telescope,
[00:02:14.560 --> 00:02:17.880]   there are about 100 billion galaxies.
[00:02:17.880 --> 00:02:19.680]   So do the math.
[00:02:19.680 --> 00:02:22.480]   How many stars are there in the visible universe?
[00:02:22.480 --> 00:02:27.480]   100 billion galaxies times 100 billion stars per galaxy.
[00:02:28.480 --> 00:02:33.480]   We're talking about a number beyond human imagination.
[00:02:33.480 --> 00:02:35.480]   And to believe that we're the only ones,
[00:02:35.480 --> 00:02:38.200]   I think, is rather ridiculous.
[00:02:38.200 --> 00:02:42.200]   - So you've talked about different types of,
[00:02:42.200 --> 00:02:44.480]   type zero, one, two, three, four, and five,
[00:02:44.480 --> 00:02:46.280]   even, of the Kardashev scale
[00:02:46.280 --> 00:02:49.440]   of the different kind of civilizations.
[00:02:49.440 --> 00:02:52.800]   What do you think it takes,
[00:02:52.800 --> 00:02:54.640]   if it is indeed a ridiculous notion
[00:02:54.640 --> 00:02:56.240]   that we're alone in the universe,
[00:02:56.240 --> 00:02:58.760]   what do you think it takes to reach out,
[00:02:58.760 --> 00:03:02.680]   first to reach out through communication and connect?
[00:03:02.680 --> 00:03:04.360]   - Well, first of all, we have to understand
[00:03:04.360 --> 00:03:08.760]   the level of sophistication of an alien life form
[00:03:08.760 --> 00:03:10.520]   if we make contact with them.
[00:03:10.520 --> 00:03:14.200]   I think in this century, we'll probably pick up signals,
[00:03:14.200 --> 00:03:17.440]   signals from an extraterrestrial civilization.
[00:03:17.440 --> 00:03:19.280]   We'll pick up their "I love Lucy"
[00:03:19.280 --> 00:03:21.320]   and their "Leave it to Beaver,"
[00:03:21.320 --> 00:03:25.640]   just ordinary day-to-day transmissions that they emit.
[00:03:25.640 --> 00:03:27.280]   And the first thing we want to do
[00:03:27.280 --> 00:03:30.240]   is to A, decipher their language, of course,
[00:03:30.240 --> 00:03:33.320]   but B, figure out at what level
[00:03:33.320 --> 00:03:37.040]   they are advanced on the Kardashev scale.
[00:03:37.040 --> 00:03:38.560]   I'm a physicist.
[00:03:38.560 --> 00:03:43.560]   We rank things by two parameters, energy and information.
[00:03:43.560 --> 00:03:45.560]   That's how we rank black holes.
[00:03:45.560 --> 00:03:47.280]   That's how we rank stars.
[00:03:47.280 --> 00:03:50.560]   That's how we rank civilizations in outer space.
[00:03:50.560 --> 00:03:54.880]   So a type one civilization is capable
[00:03:54.880 --> 00:03:57.520]   of harnessing planetary power.
[00:03:57.520 --> 00:04:00.520]   They control the weather, for example, earthquakes,
[00:04:00.520 --> 00:04:04.560]   volcanoes, they can modify the course of geological events,
[00:04:04.560 --> 00:04:08.360]   sort of like Flash Gordon or Buck Rogers.
[00:04:08.360 --> 00:04:11.120]   Type two would be stellar.
[00:04:11.120 --> 00:04:15.600]   They play with stars, entire stars.
[00:04:15.600 --> 00:04:18.400]   They use the entire energy output of a star,
[00:04:18.400 --> 00:04:20.520]   sort of like Star Trek.
[00:04:20.520 --> 00:04:24.600]   The Federation of Planets have colonized the nearby stars.
[00:04:24.600 --> 00:04:29.040]   So a type two would be somewhat similar to Star Trek.
[00:04:29.040 --> 00:04:30.640]   Type three would be galactic.
[00:04:30.640 --> 00:04:33.800]   They roam the galactic space lanes.
[00:04:33.800 --> 00:04:37.680]   And type three would be like Star Wars,
[00:04:37.680 --> 00:04:39.840]   a galactic civilization.
[00:04:39.840 --> 00:04:42.280]   Now, one day I was giving this talk in London
[00:04:42.280 --> 00:04:45.560]   at the planetarium there, and the little boy comes up to me
[00:04:45.560 --> 00:04:48.680]   and he says, "Professor, you're wrong.
[00:04:48.680 --> 00:04:51.000]   "You're wrong, there's type four."
[00:04:51.000 --> 00:04:53.240]   And I told him, "Look, kid,
[00:04:53.240 --> 00:04:56.880]   "there are planets, stars, and galaxies.
[00:04:56.880 --> 00:04:58.680]   "That's it, folks."
[00:04:58.680 --> 00:05:00.760]   And he kept persisting and saying,
[00:05:00.760 --> 00:05:05.760]   "No, there's type four, the power of the continuum."
[00:05:05.760 --> 00:05:08.480]   And I thought about it for a moment, and I said to myself,
[00:05:08.480 --> 00:05:12.080]   "Is there an extra galactic source of energy,
[00:05:12.080 --> 00:05:14.480]   "the continuum of Star Trek?"
[00:05:14.480 --> 00:05:18.040]   And the answer is yes, there could be a type four,
[00:05:18.040 --> 00:05:20.000]   and that's dark energy.
[00:05:20.000 --> 00:05:25.000]   We now know that 73% of the energy of the universe
[00:05:25.000 --> 00:05:27.520]   is dark energy.
[00:05:27.520 --> 00:05:30.600]   Dark matter represents maybe 23% or so,
[00:05:30.600 --> 00:05:33.000]   and we only represent 4%.
[00:05:33.000 --> 00:05:34.560]   We're the oddballs.
[00:05:34.560 --> 00:05:36.360]   And so you begin to realize that, yeah,
[00:05:36.360 --> 00:05:39.720]   there could be type four, maybe even type five.
[00:05:39.720 --> 00:05:43.240]   - So type four, you're saying being able to harness
[00:05:43.240 --> 00:05:45.320]   sort of like dark energy,
[00:05:45.320 --> 00:05:47.120]   something that permeates the entire universe.
[00:05:47.160 --> 00:05:51.000]   So be able to plug into the entire universe
[00:05:51.000 --> 00:05:52.080]   as a source of energy.
[00:05:52.080 --> 00:05:53.840]   - That's right, and dark energy
[00:05:53.840 --> 00:05:55.680]   is the energy of the Big Bang.
[00:05:55.680 --> 00:05:58.920]   It's why the galaxies are being pushed apart.
[00:05:58.920 --> 00:06:00.740]   It's the energy of nothing.
[00:06:00.740 --> 00:06:02.560]   The more nothing you have,
[00:06:02.560 --> 00:06:05.400]   the more dark energy that's repulsive.
[00:06:05.400 --> 00:06:08.960]   And so the acceleration of the universe is accelerating
[00:06:08.960 --> 00:06:12.680]   because the more you have, the more you can have.
[00:06:12.680 --> 00:06:15.800]   And that, of course, is by definition an exponential curve.
[00:06:15.800 --> 00:06:17.760]   It's called a de Sitter expansion,
[00:06:17.760 --> 00:06:20.480]   and that's the current state of the universe.
[00:06:20.480 --> 00:06:25.480]   - And then type five, would that be able to seek
[00:06:25.480 --> 00:06:31.080]   energy sources somehow outside of our universe?
[00:06:31.080 --> 00:06:33.040]   And how crazy is that idea?
[00:06:33.040 --> 00:06:35.400]   - Yeah, type five would be the multiverse.
[00:06:35.400 --> 00:06:36.320]   - Multiverse, okay.
[00:06:36.320 --> 00:06:39.600]   - I'm a quantum physicist, and we quantum physicists
[00:06:39.600 --> 00:06:42.160]   don't believe that the Big Bang happened once.
[00:06:42.160 --> 00:06:45.160]   That would violate the Heisenberg and Sergi principle.
[00:06:45.160 --> 00:06:47.880]   And that means that there could be multiple bangs
[00:06:47.880 --> 00:06:49.360]   happening all the time.
[00:06:49.360 --> 00:06:54.360]   Even as we speak today, universes are being created.
[00:06:54.360 --> 00:06:56.200]   That fits the data.
[00:06:56.200 --> 00:06:59.960]   The inflationary universe is a quantum theory,
[00:06:59.960 --> 00:07:02.060]   so there's a certain finite probability
[00:07:02.060 --> 00:07:05.160]   that universes are being created all the time.
[00:07:05.160 --> 00:07:08.760]   And for me, this is actually rather aesthetically pleasing
[00:07:08.760 --> 00:07:13.200]   because I was raised as a Presbyterian,
[00:07:13.200 --> 00:07:15.920]   but my parents were Buddhists.
[00:07:15.920 --> 00:07:19.520]   And there's two diametrically opposed ideas
[00:07:19.520 --> 00:07:21.080]   about the universe.
[00:07:21.080 --> 00:07:23.240]   In Buddhism, there's only nirvana.
[00:07:23.240 --> 00:07:25.160]   There's no beginning, there's no end,
[00:07:25.160 --> 00:07:26.940]   there's only timelessness.
[00:07:26.940 --> 00:07:29.960]   But in Christianity, there is the instant
[00:07:29.960 --> 00:07:32.760]   when God said, "Let there be light."
[00:07:32.760 --> 00:07:35.320]   In other words, an instant of creation.
[00:07:35.320 --> 00:07:40.120]   So I've had these two mutually exclusive ideas in my head,
[00:07:40.120 --> 00:07:42.760]   and I now realize that it's possible to meld them
[00:07:42.760 --> 00:07:44.060]   into a single theory.
[00:07:44.060 --> 00:07:48.640]   Either the universe had a beginning or it didn't, right?
[00:07:48.640 --> 00:07:49.880]   Wrong.
[00:07:49.880 --> 00:07:53.160]   You see, our universe had a beginning.
[00:07:53.160 --> 00:07:56.160]   Our universe had an instant where somebody might have said,
[00:07:56.160 --> 00:07:57.860]   "Let there be light."
[00:07:57.860 --> 00:08:00.340]   But there are other bubble universes out there
[00:08:00.340 --> 00:08:02.880]   in a bubble bath of universes.
[00:08:02.880 --> 00:08:07.280]   And that means that these universes are expanding
[00:08:07.280 --> 00:08:11.240]   into a dimension beyond our three-dimensional comprehension.
[00:08:11.240 --> 00:08:13.080]   In other words, hyperspace.
[00:08:13.080 --> 00:08:16.360]   In other words, 11-dimensional hyperspace.
[00:08:16.360 --> 00:08:19.480]   So nirvana would be this timeless,
[00:08:19.480 --> 00:08:23.000]   11-dimensional hyperspace where big bangs
[00:08:23.000 --> 00:08:24.860]   are happening all the time.
[00:08:24.860 --> 00:08:28.640]   So we can now combine two mutually exclusive theories
[00:08:28.640 --> 00:08:29.660]   of creation.
[00:08:29.660 --> 00:08:35.320]   And Stephen Hawking, for example, even in his last book,
[00:08:35.320 --> 00:08:37.120]   even said that this is an argument
[00:08:37.120 --> 00:08:39.360]   against the existence of God.
[00:08:39.360 --> 00:08:42.640]   He said there is no God because there was not enough time
[00:08:42.640 --> 00:08:44.280]   for God to create the universe,
[00:08:44.280 --> 00:08:47.780]   'cause the big bang happened in an instant of time.
[00:08:47.780 --> 00:08:50.360]   Therefore, there was no time available
[00:08:50.360 --> 00:08:52.320]   for him to create the universe.
[00:08:52.320 --> 00:08:54.980]   But you see, the multiverse idea means
[00:08:54.980 --> 00:08:58.000]   that there was a time before time.
[00:08:58.000 --> 00:08:59.560]   And there are multiple times.
[00:08:59.560 --> 00:09:02.080]   Each bubble has its own time.
[00:09:02.080 --> 00:09:06.200]   And so it means that there could actually be a universe
[00:09:06.200 --> 00:09:09.600]   before the beginning of our universe.
[00:09:09.600 --> 00:09:12.600]   So if you think of a bubble bath, when two bubbles collide,
[00:09:12.600 --> 00:09:16.760]   or when two bubbles fission to create a baby bubble,
[00:09:16.760 --> 00:09:18.760]   that's called the big bang.
[00:09:18.760 --> 00:09:21.500]   So the big bang is nothing but the collision of universes
[00:09:21.500 --> 00:09:23.680]   or the budding of universes.
[00:09:23.680 --> 00:09:25.040]   - That's such a beautiful picture
[00:09:25.040 --> 00:09:27.960]   of our incredibly mysterious existence.
[00:09:27.960 --> 00:09:31.560]   So is that humbling to you, exciting,
[00:09:31.560 --> 00:09:32.800]   the idea of multiverses?
[00:09:32.800 --> 00:09:34.960]   I don't even know how to even begin
[00:09:36.080 --> 00:09:38.360]   to wrap my mind around it. - Well, it's exciting for me
[00:09:38.360 --> 00:09:41.680]   because what I do for a living is string theory.
[00:09:41.680 --> 00:09:43.040]   That's my day job.
[00:09:43.040 --> 00:09:46.840]   I get paid by the city of New York to work on string theory.
[00:09:46.840 --> 00:09:50.520]   And you see, string theory is a multiverse theory.
[00:09:50.520 --> 00:09:53.400]   So people say, first of all, what is string theory?
[00:09:53.400 --> 00:09:56.080]   String theory simply says that all the particles we see
[00:09:56.080 --> 00:09:58.720]   in nature, the electron, the proton, the quarks,
[00:09:58.720 --> 00:10:01.280]   what have you, are nothing but vibrations
[00:10:01.280 --> 00:10:04.960]   on a musical string, on a tiny, tiny little string.
[00:10:05.920 --> 00:10:07.400]   You know, G. Robert Oppenheimer,
[00:10:07.400 --> 00:10:09.640]   the creator of the atomic bomb,
[00:10:09.640 --> 00:10:12.040]   was so frustrated in the 1950s
[00:10:12.040 --> 00:10:15.200]   with all these subatomic particles being created
[00:10:15.200 --> 00:10:18.240]   in our atom smashers that he announced,
[00:10:18.240 --> 00:10:22.680]   he announced one day that the Nobel Prize in physics
[00:10:22.680 --> 00:10:25.800]   should go to the physicist who does not discover
[00:10:25.800 --> 00:10:28.280]   a new particle that year.
[00:10:28.280 --> 00:10:30.600]   Well, today we think they're nothing but musical notes
[00:10:30.600 --> 00:10:32.960]   on these tiny little vibrating strings.
[00:10:32.960 --> 00:10:34.720]   So what is physics?
[00:10:34.720 --> 00:10:36.800]   Physics is the harmonies you can write
[00:10:36.800 --> 00:10:38.600]   on vibrating strings.
[00:10:38.600 --> 00:10:40.160]   What is chemistry?
[00:10:40.160 --> 00:10:44.880]   Chemistry is the melodies you can play on these strings.
[00:10:44.880 --> 00:10:46.160]   What is the universe?
[00:10:46.160 --> 00:10:50.400]   The universe is a symphony of strings.
[00:10:50.400 --> 00:10:53.200]   And then what is the mind of God
[00:10:53.200 --> 00:10:55.720]   that Albert Einstein so eloquently wrote about
[00:10:55.720 --> 00:10:58.400]   for the last 30 years of his life?
[00:10:58.400 --> 00:11:02.760]   The mind of God would be cosmic music
[00:11:02.760 --> 00:11:06.160]   resonating through 11 dimensional hyperspace.
[00:11:06.160 --> 00:11:07.280]   - So beautifully put.
[00:11:07.280 --> 00:11:11.880]   What do you think is the mind of Einstein's God?
[00:11:11.880 --> 00:11:16.160]   Do you think there's a why that we could untangle
[00:11:16.160 --> 00:11:19.760]   from this universe of strings?
[00:11:19.760 --> 00:11:20.920]   Why are we here?
[00:11:20.920 --> 00:11:22.440]   What is the meaning of it all?
[00:11:22.440 --> 00:11:26.320]   - Well, Steven Weinberg, winner of the Nobel Prize,
[00:11:26.320 --> 00:11:29.760]   once said that the more we learn about the universe,
[00:11:29.760 --> 00:11:32.240]   the more we learn that it's pointless.
[00:11:32.240 --> 00:11:33.720]   (laughing)
[00:11:33.720 --> 00:11:35.640]   - Well, I don't know.
[00:11:35.640 --> 00:11:37.320]   I don't profess to understand
[00:11:37.320 --> 00:11:39.360]   the great secrets of the universe.
[00:11:39.360 --> 00:11:41.160]   However, let me say two things
[00:11:41.160 --> 00:11:43.360]   about what the giants of physics
[00:11:43.360 --> 00:11:45.360]   have said about this question.
[00:11:45.360 --> 00:11:48.520]   Einstein believed in two types of God.
[00:11:48.520 --> 00:11:54.320]   One was the God of the Bible, the personal God,
[00:11:54.320 --> 00:11:56.640]   the God that answers prayers, walks on water,
[00:11:56.640 --> 00:12:00.080]   performs miracles, smites the Philistines.
[00:12:00.080 --> 00:12:02.800]   That's the personal God that he didn't believe in.
[00:12:02.800 --> 00:12:05.520]   He believed in the God of Spinoza,
[00:12:05.520 --> 00:12:10.080]   the God of order, simplicity, harmony, beauty.
[00:12:10.080 --> 00:12:12.840]   The universe could have been ugly.
[00:12:12.840 --> 00:12:15.720]   The universe could have been messy, random,
[00:12:15.720 --> 00:12:17.360]   but it's gorgeous.
[00:12:17.360 --> 00:12:20.000]   It relates on a single sheet of paper.
[00:12:20.000 --> 00:12:23.120]   We can write down all the known laws of the universe.
[00:12:23.120 --> 00:12:23.960]   It's amazing.
[00:12:23.960 --> 00:12:27.840]   On one sheet of paper, Einstein's equation is one inch long.
[00:12:27.840 --> 00:12:30.040]   String theory is a lot longer,
[00:12:30.040 --> 00:12:32.000]   and so is the standard model,
[00:12:32.000 --> 00:12:36.000]   but you could put all these equations on one sheet of paper.
[00:12:36.000 --> 00:12:38.640]   It didn't have to be that way.
[00:12:38.640 --> 00:12:40.240]   It could have been messy.
[00:12:40.240 --> 00:12:43.160]   And so Einstein thought of himself as a young boy
[00:12:43.160 --> 00:12:47.480]   entering this huge library for the first time,
[00:12:47.480 --> 00:12:50.480]   being overwhelmed by the simplicity,
[00:12:50.480 --> 00:12:53.160]   elegance, and beauty of this library,
[00:12:53.160 --> 00:12:56.560]   but all he could do was read the first page
[00:12:56.560 --> 00:12:58.320]   of the first volume.
[00:12:58.320 --> 00:13:00.320]   Well, that library is the universe
[00:13:00.320 --> 00:13:03.240]   with all sorts of mysterious, magical things
[00:13:03.240 --> 00:13:05.280]   that we have yet to find.
[00:13:05.280 --> 00:13:07.920]   And then Galileo was asked about this.
[00:13:07.920 --> 00:13:12.920]   Galileo said that the purpose of science,
[00:13:12.920 --> 00:13:17.680]   the purpose of science is to determine how the heavens go.
[00:13:17.680 --> 00:13:20.680]   The purpose of religion is to determine
[00:13:20.680 --> 00:13:22.400]   how to go to heaven.
[00:13:22.400 --> 00:13:26.600]   So in other words, science is about natural law,
[00:13:27.480 --> 00:13:30.600]   and religion is about ethics,
[00:13:30.600 --> 00:13:33.440]   how to be a good person, how to go to heaven.
[00:13:33.440 --> 00:13:36.080]   As long as we keep these two things apart,
[00:13:36.080 --> 00:13:38.000]   we're in great shape.
[00:13:38.000 --> 00:13:42.200]   The problem occurs when people from the natural sciences
[00:13:42.200 --> 00:13:44.440]   begin to pontificate about ethics,
[00:13:44.440 --> 00:13:47.280]   and people from religion begin to pontificate
[00:13:47.280 --> 00:13:48.920]   about natural law.
[00:13:48.920 --> 00:13:51.800]   That's where we get into big trouble.
[00:13:51.800 --> 00:13:53.760]   - You think they're fundamentally distinct,
[00:13:53.760 --> 00:13:58.400]   morality and ethics and our idea of what is right
[00:13:58.400 --> 00:13:59.400]   and what is wrong.
[00:13:59.400 --> 00:14:02.120]   That's something that's outside the reach
[00:14:02.120 --> 00:14:04.000]   of string theory and physics.
[00:14:04.000 --> 00:14:04.840]   - That's right.
[00:14:04.840 --> 00:14:08.720]   If you talk to a squirrel about what is right
[00:14:08.720 --> 00:14:13.720]   and what is wrong, there's no reference frame for a squirrel.
[00:14:13.720 --> 00:14:16.600]   And realize that aliens from outer space,
[00:14:16.600 --> 00:14:18.240]   if they ever come visit us,
[00:14:18.240 --> 00:14:21.920]   they'll try to talk to us like we talk to squirrels
[00:14:21.920 --> 00:14:24.680]   in the forest, but eventually we get bored
[00:14:24.680 --> 00:14:28.040]   talking to the squirrels because they don't talk back to us.
[00:14:28.040 --> 00:14:30.000]   Same thing with aliens from outer space.
[00:14:30.000 --> 00:14:32.280]   They come down to earth, they'll be curious about us
[00:14:32.280 --> 00:14:35.440]   to a degree, but after a while, they just get bored
[00:14:35.440 --> 00:14:37.920]   'cause we have nothing to offer them.
[00:14:37.920 --> 00:14:40.480]   So our sense of right and wrong,
[00:14:40.480 --> 00:14:43.400]   what does that mean compared to a squirrel's sense
[00:14:43.400 --> 00:14:45.680]   of right and wrong?
[00:14:45.680 --> 00:14:48.720]   Now we, of course, do have an ethics
[00:14:48.760 --> 00:14:51.880]   that keeps civilizations in line,
[00:14:51.880 --> 00:14:56.480]   enriches our life, and makes civilization possible.
[00:14:56.480 --> 00:14:58.040]   And I think that's a good thing,
[00:14:58.040 --> 00:15:01.560]   but it's not mandated by a law of physics.
[00:15:01.560 --> 00:15:06.560]   - So if aliens do, alien species were to make contact,
[00:15:06.560 --> 00:15:10.040]   forgive me for staying on aliens for a bit longer,
[00:15:10.040 --> 00:15:15.640]   do you think they're more likely to be friendly,
[00:15:15.640 --> 00:15:18.700]   to befriend us, or to destroy us?
[00:15:18.700 --> 00:15:20.600]   - Well, I think for the most part,
[00:15:20.600 --> 00:15:22.880]   they'll pretty much ignore us.
[00:15:22.880 --> 00:15:25.960]   If you were a deer in the forest, who do you fear the most?
[00:15:25.960 --> 00:15:30.520]   Do you fear the hunter with his gigantic 16-gauge shotgun?
[00:15:30.520 --> 00:15:35.480]   Or do you fear the guy with the briefcase and glasses?
[00:15:35.480 --> 00:15:39.080]   Well, the guy with the briefcase could be a developer
[00:15:39.080 --> 00:15:42.440]   about to basically flatten the entire forest,
[00:15:42.440 --> 00:15:44.240]   destroying your livelihood.
[00:15:44.240 --> 00:15:47.760]   So instinctively, you may be afraid of the hunter,
[00:15:47.760 --> 00:15:51.380]   but actually, the problem with deers in the forest
[00:15:51.380 --> 00:15:54.220]   is that they should fear developers,
[00:15:54.220 --> 00:15:56.220]   'cause developers look at deer
[00:15:56.220 --> 00:15:58.620]   as simply getting in the way.
[00:15:58.620 --> 00:16:02.580]   I mean, in "War of the Worlds" by H.G. Wells,
[00:16:02.580 --> 00:16:04.780]   the aliens did not hate us.
[00:16:04.780 --> 00:16:07.900]   If you read the book, the aliens did not have
[00:16:07.900 --> 00:16:11.400]   evil intentions toward homo sapiens.
[00:16:11.400 --> 00:16:13.600]   No, we were in the way.
[00:16:14.940 --> 00:16:19.120]   So I think we have to realize that alien civilizations
[00:16:19.120 --> 00:16:20.520]   may view us quite differently
[00:16:20.520 --> 00:16:22.280]   than in science fiction novels.
[00:16:22.280 --> 00:16:24.000]   However, I personally believe,
[00:16:24.000 --> 00:16:25.760]   and I cannot prove any of this,
[00:16:25.760 --> 00:16:27.200]   I personally believe that they're probably
[00:16:27.200 --> 00:16:29.840]   gonna be peaceful because there's nothing
[00:16:29.840 --> 00:16:32.960]   that they want from our world.
[00:16:32.960 --> 00:16:34.520]   I mean, what are they gonna take us?
[00:16:34.520 --> 00:16:36.560]   What are they gonna take us for, gold?
[00:16:36.560 --> 00:16:40.560]   No, gold is a useless metal for the most part.
[00:16:40.560 --> 00:16:43.600]   It's silver, I mean, it's gold in color,
[00:16:43.600 --> 00:16:45.620]   but that only affects homo sapiens.
[00:16:45.620 --> 00:16:47.780]   Squirrels don't care about gold.
[00:16:47.780 --> 00:16:50.580]   And so gold is a rather useless element.
[00:16:50.580 --> 00:16:53.140]   Rare earths, maybe, platinum-based elements,
[00:16:53.140 --> 00:16:55.700]   rare earths for the electronics, yeah, maybe.
[00:16:55.700 --> 00:16:59.300]   But other than that, we have nothing to offer them.
[00:16:59.300 --> 00:17:01.660]   I mean, think about it for a moment.
[00:17:01.660 --> 00:17:06.580]   People love Shakespeare, and they love the arts and poetry,
[00:17:06.580 --> 00:17:10.220]   but outside of the earth, they mean nothing,
[00:17:10.220 --> 00:17:12.340]   absolutely nothing.
[00:17:12.340 --> 00:17:15.840]   I mean, when I write down an equation in string theory,
[00:17:15.840 --> 00:17:19.820]   I would hope that on the other side of the galaxy,
[00:17:19.820 --> 00:17:22.900]   there's an alien writing down that very same equation
[00:17:22.900 --> 00:17:25.740]   in different notation, but that alien
[00:17:25.740 --> 00:17:27.260]   on the other side of the galaxy,
[00:17:27.260 --> 00:17:30.380]   Shakespeare, poetry, Hemingway,
[00:17:30.380 --> 00:17:33.980]   it would mean nothing to him, or her, or it.
[00:17:33.980 --> 00:17:38.100]   - When you think about entities that's out there,
[00:17:38.100 --> 00:17:41.620]   extraterrestrial, do you think
[00:17:41.620 --> 00:17:44.340]   they would naturally look something
[00:17:44.340 --> 00:17:47.980]   that even is recognizable to us as life,
[00:17:47.980 --> 00:17:50.540]   or would they be radically different?
[00:17:50.540 --> 00:17:52.820]   - Well, how did we become intelligent?
[00:17:52.820 --> 00:17:56.140]   Basically, three things made us intelligent.
[00:17:56.140 --> 00:17:59.300]   One is our eyesight, stereo eyesight.
[00:17:59.300 --> 00:18:01.140]   We have the eyes of a hunter,
[00:18:01.140 --> 00:18:04.220]   stereo vision, so we lock in on targets.
[00:18:04.220 --> 00:18:09.220]   And who is smarter, predator or prey?
[00:18:09.220 --> 00:18:11.540]   Predators are smarter than prey.
[00:18:11.540 --> 00:18:13.220]   They have their eyes to the front of their face,
[00:18:13.220 --> 00:18:14.820]   like lions, tigers,
[00:18:14.820 --> 00:18:18.820]   while rabbits have eyes to the side of their face.
[00:18:18.820 --> 00:18:19.860]   Why is that?
[00:18:19.860 --> 00:18:22.740]   Hunters have to zero in on the target.
[00:18:22.740 --> 00:18:24.580]   They have to know how to ambush.
[00:18:24.580 --> 00:18:26.980]   They have to know how to hide, camouflage,
[00:18:26.980 --> 00:18:30.180]   sneak up, stealth, deceit.
[00:18:30.180 --> 00:18:31.980]   That takes a lot of intelligence.
[00:18:31.980 --> 00:18:35.220]   Rabbits, all they have to do is run.
[00:18:35.220 --> 00:18:36.820]   So that's the first criterion,
[00:18:36.820 --> 00:18:39.900]   stereo eyesight of some sort.
[00:18:39.900 --> 00:18:42.780]   Second is the thumb.
[00:18:42.780 --> 00:18:44.660]   The opposable thumb of some sort,
[00:18:44.660 --> 00:18:46.140]   could be a claw or tentacle.
[00:18:46.140 --> 00:18:48.700]   So hand-eye coordination.
[00:18:48.700 --> 00:18:50.300]   Hand-eye coordination is the way
[00:18:50.300 --> 00:18:52.820]   we manipulate the environment.
[00:18:52.820 --> 00:18:55.100]   And then three, language.
[00:18:55.100 --> 00:18:58.220]   Because, you know, Mama Bear never tells Baby Bear
[00:18:58.220 --> 00:19:00.380]   to avoid the human hunter.
[00:19:00.380 --> 00:19:02.380]   Bears just learn by themselves.
[00:19:02.380 --> 00:19:04.060]   They never hand out information
[00:19:04.060 --> 00:19:06.260]   from one generation to the next.
[00:19:06.260 --> 00:19:09.220]   So these are the three basic ingredients of intelligence.
[00:19:10.180 --> 00:19:11.900]   Eyesight of some sort,
[00:19:11.900 --> 00:19:15.060]   an opposable thumb or tentacle or claw of some sort,
[00:19:15.060 --> 00:19:16.620]   and language.
[00:19:16.620 --> 00:19:19.060]   Now ask yourself a simple question.
[00:19:19.060 --> 00:19:22.380]   How many animals have all three?
[00:19:22.380 --> 00:19:23.460]   - Just us.
[00:19:23.460 --> 00:19:25.180]   - It's just us.
[00:19:25.180 --> 00:19:27.980]   I mean, the primates, they have a language.
[00:19:27.980 --> 00:19:30.740]   Yeah, they may get up to maybe 20 words,
[00:19:30.740 --> 00:19:32.700]   but a baby learns a word a day,
[00:19:32.700 --> 00:19:35.140]   several words a day a baby learns.
[00:19:35.140 --> 00:19:40.140]   And a typical adult knows about almost 5,000 words.
[00:19:40.140 --> 00:19:42.820]   While the maximum number of words
[00:19:42.820 --> 00:19:46.620]   that you can teach a gorilla in any language,
[00:19:46.620 --> 00:19:49.700]   including their own language, is about 20 or so.
[00:19:49.700 --> 00:19:53.100]   And so we see the difference in intelligence.
[00:19:53.100 --> 00:19:55.580]   So when we meet aliens from outer space,
[00:19:55.580 --> 00:19:58.060]   chances are they will have been descended
[00:19:58.060 --> 00:20:01.060]   from predators of some sort.
[00:20:01.060 --> 00:20:03.460]   They'll have some way to manipulate the environment
[00:20:03.460 --> 00:20:07.020]   and communicate their knowledge to the next generation.
[00:20:07.020 --> 00:20:09.020]   That's it, folks.
[00:20:09.020 --> 00:20:12.180]   - So functionally, that would be similar.
[00:20:12.180 --> 00:20:15.900]   We would be able to recognize them.
[00:20:15.900 --> 00:20:17.180]   - Well, not necessarily,
[00:20:17.180 --> 00:20:19.580]   because I think even with homo sapiens,
[00:20:19.580 --> 00:20:24.580]   we are eventually going to perhaps become part cybernetic
[00:20:24.580 --> 00:20:26.660]   and genetically enhanced.
[00:20:26.660 --> 00:20:31.500]   Already, robots are getting smarter and smarter.
[00:20:31.500 --> 00:20:35.700]   Right now, robots have the intelligence of a cockroach,
[00:20:35.700 --> 00:20:37.260]   but in the coming years,
[00:20:37.260 --> 00:20:40.460]   our robots will be as smart as a mouse,
[00:20:40.460 --> 00:20:42.820]   then maybe as smart as a rabbit.
[00:20:42.820 --> 00:20:47.140]   If we're lucky, maybe as smart as a cat or a dog.
[00:20:47.140 --> 00:20:50.180]   And by the end of the century, who knows for sure,
[00:20:50.180 --> 00:20:53.660]   our robots will be probably as smart as a monkey.
[00:20:53.660 --> 00:20:56.940]   Now, at that point, of course, they could be dangerous.
[00:20:56.940 --> 00:20:59.700]   You see, monkeys are self-aware.
[00:20:59.700 --> 00:21:03.300]   They know they are monkeys.
[00:21:03.300 --> 00:21:06.140]   They may have a different agenda than us.
[00:21:06.140 --> 00:21:09.540]   While dogs, dogs are confused.
[00:21:09.540 --> 00:21:14.740]   You see, dogs think that we are a dog,
[00:21:14.740 --> 00:21:16.340]   that we're the top dog.
[00:21:16.340 --> 00:21:17.460]   They're the underdog.
[00:21:17.460 --> 00:21:19.620]   That's why they whimper and follow us
[00:21:19.620 --> 00:21:21.300]   and lick us all the time.
[00:21:21.300 --> 00:21:22.900]   We're the top dog.
[00:21:22.900 --> 00:21:25.420]   Monkeys have no illusion at all.
[00:21:25.420 --> 00:21:28.220]   They know we are not monkeys.
[00:21:28.220 --> 00:21:29.900]   And so I think that in the future,
[00:21:29.900 --> 00:21:32.900]   we'll have to put a chip in their brain to shut them off
[00:21:32.900 --> 00:21:35.420]   once our robots have murderous thoughts.
[00:21:35.420 --> 00:21:37.420]   But that's in a hundred years.
[00:21:37.420 --> 00:21:41.460]   In 200 years, the robots will be smart enough
[00:21:41.460 --> 00:21:44.580]   to remove that fail-safe chip in their brain
[00:21:44.580 --> 00:21:46.780]   and then watch out.
[00:21:46.780 --> 00:21:51.780]   At that point, I think rather than compete with our robots,
[00:21:51.780 --> 00:21:53.860]   we should merge with them.
[00:21:53.860 --> 00:21:56.700]   We should become part cybernetic.
[00:21:56.700 --> 00:21:59.380]   So I think when we meet alien life from outer space,
[00:21:59.380 --> 00:22:04.380]   they may be genetically and cybernetically enhanced.
[00:22:04.380 --> 00:22:08.020]   - Genetically and cybernetically enhanced, wow.
[00:22:08.020 --> 00:22:10.940]   So let's talk about that full range.
[00:22:10.940 --> 00:22:13.620]   In the near term and 200 years from now,
[00:22:13.620 --> 00:22:16.860]   how promising in the near term in your view
[00:22:16.860 --> 00:22:18.700]   is brain-machine interfaces?
[00:22:18.700 --> 00:22:21.980]   So starting to allow computers
[00:22:21.980 --> 00:22:24.140]   to talk directly to the brains.
[00:22:24.140 --> 00:22:26.820]   Elon Musk is working on that with Neuralink
[00:22:26.820 --> 00:22:28.940]   and there's other companies working on this idea.
[00:22:28.940 --> 00:22:30.420]   Do you see promise there?
[00:22:30.420 --> 00:22:32.900]   Do you see hope for near term impact?
[00:22:32.900 --> 00:22:36.340]   - Well, every technology has pluses and minuses.
[00:22:36.340 --> 00:22:38.540]   Already we can record memories.
[00:22:38.540 --> 00:22:40.860]   I have a book, "The Future of the Mind"
[00:22:40.860 --> 00:22:42.780]   where I detail some of these breakthroughs.
[00:22:42.780 --> 00:22:46.300]   We can now record simple memories of mice
[00:22:46.300 --> 00:22:49.260]   and send these memories on the internet.
[00:22:49.260 --> 00:22:52.020]   Eventually we're gonna do this with primates
[00:22:52.020 --> 00:22:55.060]   at Wake Forest University and also in Los Angeles.
[00:22:55.060 --> 00:22:57.660]   And then after that,
[00:22:57.660 --> 00:23:00.820]   we'll have a memory chip for Alzheimer's patients.
[00:23:00.820 --> 00:23:02.780]   We'll test it out in Alzheimer's patients
[00:23:02.780 --> 00:23:05.740]   because of course, when Alzheimer's patients
[00:23:05.740 --> 00:23:07.740]   lose their memory, they wander.
[00:23:07.740 --> 00:23:10.100]   They create all sorts of havoc,
[00:23:10.100 --> 00:23:14.500]   wandering around oblivious to their surroundings.
[00:23:14.500 --> 00:23:15.580]   And they'll have a chip.
[00:23:15.580 --> 00:23:18.180]   They'll push the button and memories,
[00:23:18.180 --> 00:23:21.060]   memories will come flooding into their hippocampus
[00:23:21.060 --> 00:23:26.060]   and the chip telling them where they live and who they are.
[00:23:26.060 --> 00:23:29.500]   And so a memory chip is definitely in the cards.
[00:23:29.500 --> 00:23:33.180]   And I think this will eventually affect human civilization.
[00:23:33.180 --> 00:23:35.060]   What is the future of the internet?
[00:23:35.060 --> 00:23:37.660]   The future of the internet is brain net.
[00:23:37.660 --> 00:23:41.620]   Brain net is when we send emotions, feelings,
[00:23:41.620 --> 00:23:44.340]   sensations on the internet.
[00:23:44.340 --> 00:23:46.580]   And we will telepathically communicate
[00:23:46.580 --> 00:23:49.540]   with other humans this way.
[00:23:49.540 --> 00:23:51.100]   This is gonna affect everything.
[00:23:51.100 --> 00:23:52.420]   Look at entertainment.
[00:23:52.420 --> 00:23:54.020]   Remember the silent movies?
[00:23:54.020 --> 00:23:56.180]   Charlie Chaplin was very famous
[00:23:56.180 --> 00:23:57.980]   during the era of silent movies.
[00:23:57.980 --> 00:23:59.900]   But when the talkies came in,
[00:23:59.900 --> 00:24:02.940]   nobody wanted to see Charlie Chaplin anymore
[00:24:02.940 --> 00:24:05.580]   because he never talked in the movies.
[00:24:05.580 --> 00:24:08.860]   And so a whole generation of actors lost their job
[00:24:08.860 --> 00:24:11.340]   and a new series of actors came in.
[00:24:11.340 --> 00:24:16.340]   Next, we're gonna have the movies replaced by brain net
[00:24:16.900 --> 00:24:19.500]   because in the future, people will say,
[00:24:19.500 --> 00:24:23.060]   who wants to see a screen with images?
[00:24:23.060 --> 00:24:27.220]   That's it, sound and image, that's called the movies.
[00:24:27.220 --> 00:24:28.900]   In our entertainment industry,
[00:24:28.900 --> 00:24:30.780]   this multi-billion dollar industry
[00:24:30.780 --> 00:24:34.580]   is based on screens with moving images and sound.
[00:24:34.580 --> 00:24:39.860]   But what happens when emotions, feelings, sensations,
[00:24:39.860 --> 00:24:43.100]   memories can be conveyed on the internet?
[00:24:43.100 --> 00:24:44.700]   It's gonna change everything.
[00:24:44.700 --> 00:24:46.180]   Human relations will change
[00:24:46.180 --> 00:24:47.660]   'cause you'll be able to empathize
[00:24:47.660 --> 00:24:50.180]   and feel the suffering of other people.
[00:24:50.180 --> 00:24:53.180]   We'll be able to communicate telepathically.
[00:24:53.180 --> 00:24:56.100]   And this is coming.
[00:24:56.100 --> 00:24:58.580]   - You described brain net in "Future of the Mind."
[00:24:58.580 --> 00:25:00.860]   This is an interesting concept.
[00:25:00.860 --> 00:25:03.820]   Do you think, so you mentioned entertainment,
[00:25:03.820 --> 00:25:06.100]   but what kind of effect would it have
[00:25:06.100 --> 00:25:08.540]   on our personal relationships?
[00:25:08.540 --> 00:25:10.300]   - Hopefully, it will deepen it.
[00:25:10.300 --> 00:25:13.300]   You realize that for most of human history,
[00:25:13.300 --> 00:25:16.700]   for over 90% of human history,
[00:25:16.700 --> 00:25:21.700]   we only knew maybe 20, 100 people.
[00:25:21.700 --> 00:25:23.460]   That's it, folks.
[00:25:23.460 --> 00:25:24.940]   That was your tribe.
[00:25:24.940 --> 00:25:28.340]   That was everybody you knew in the universe
[00:25:28.340 --> 00:25:31.660]   was only maybe 50 or 100.
[00:25:31.660 --> 00:25:33.140]   With the coming of towns,
[00:25:33.140 --> 00:25:35.540]   of course, it expanded to a few thousand.
[00:25:35.540 --> 00:25:37.380]   With the coming of the telephone,
[00:25:37.380 --> 00:25:40.460]   all of a sudden, you could reach thousands of people
[00:25:40.460 --> 00:25:41.580]   with the telephone.
[00:25:41.580 --> 00:25:42.620]   And now with the internet,
[00:25:42.620 --> 00:25:45.580]   you can reach the entire population of the planet Earth.
[00:25:45.580 --> 00:25:48.300]   And so I think this is a normal progression.
[00:25:48.300 --> 00:25:52.220]   - And you think that kind of sort of connection
[00:25:52.220 --> 00:25:53.820]   to the rest of the world,
[00:25:53.820 --> 00:25:56.540]   and then adding sensations like being able to share
[00:25:56.540 --> 00:25:58.780]   telepathically emotions and so on,
[00:25:58.780 --> 00:26:01.100]   that would just further deepen our connection
[00:26:01.100 --> 00:26:02.820]   to our fellow humans?
[00:26:02.820 --> 00:26:03.660]   - Yeah, that's right.
[00:26:03.660 --> 00:26:07.580]   In fact, I disagree with many scientists on this question.
[00:26:07.580 --> 00:26:11.100]   Most scientists would say that technology is neutral.
[00:26:11.100 --> 00:26:14.340]   A double-edged sword, one side of the sword
[00:26:14.340 --> 00:26:15.860]   can cut against people.
[00:26:15.860 --> 00:26:17.300]   The other side of the sword
[00:26:17.300 --> 00:26:20.780]   can cut against ignorance and disease.
[00:26:20.780 --> 00:26:22.380]   I disagree.
[00:26:22.380 --> 00:26:25.860]   I think technology does have a moral direction.
[00:26:25.860 --> 00:26:27.300]   Look at the internet.
[00:26:27.300 --> 00:26:30.740]   The internet spreads knowledge, awareness,
[00:26:30.740 --> 00:26:32.940]   and that creates empowerment.
[00:26:32.940 --> 00:26:35.340]   People act on knowledge.
[00:26:35.340 --> 00:26:36.660]   When they begin to realize
[00:26:36.660 --> 00:26:38.460]   that they don't have to live that way,
[00:26:38.460 --> 00:26:41.020]   they don't have to suffer under a dictatorship,
[00:26:41.020 --> 00:26:44.500]   that there are other ways of living under freedom,
[00:26:44.500 --> 00:26:47.660]   then they begin to take things, take power.
[00:26:47.660 --> 00:26:49.540]   And that spreads democracy.
[00:26:49.540 --> 00:26:54.180]   And democracies do not war with other democracies.
[00:26:54.180 --> 00:26:55.180]   I'm a scientist.
[00:26:55.180 --> 00:26:57.100]   I believe in data.
[00:26:57.100 --> 00:26:59.020]   So let's take a sheet of paper
[00:26:59.020 --> 00:27:02.580]   and write down every single war
[00:27:02.580 --> 00:27:05.860]   you had to learn since you were in elementary school.
[00:27:05.860 --> 00:27:07.740]   Every single war, hundreds of them,
[00:27:07.740 --> 00:27:11.020]   kings, queens, emperors, dictators,
[00:27:11.020 --> 00:27:13.580]   all these wars were between kings, queens,
[00:27:13.580 --> 00:27:15.220]   emperors, and dictators.
[00:27:15.220 --> 00:27:19.820]   Never between two major democracies.
[00:27:19.820 --> 00:27:22.540]   And so I think with the spread of this technology,
[00:27:22.540 --> 00:27:26.100]   and which would accelerate with the coming of BrainNet,
[00:27:26.100 --> 00:27:28.460]   it means that, well, we will still have wars.
[00:27:28.460 --> 00:27:31.500]   Wars, of course, is politics by other means,
[00:27:31.500 --> 00:27:34.420]   but they'll be less intense and less frequent.
[00:27:35.420 --> 00:27:40.420]   - Do you have worries of longer-term existential risk
[00:27:40.420 --> 00:27:43.420]   from technology, from AI?
[00:27:43.420 --> 00:27:48.100]   So I think that's a wonderful vision of a future
[00:27:48.100 --> 00:27:51.180]   where war is a distant memory,
[00:27:51.180 --> 00:27:54.140]   but now there's another agent,
[00:27:54.140 --> 00:27:57.900]   there's somebody else that's able to create conflict,
[00:27:57.900 --> 00:28:00.860]   that's able to create harm, AI systems.
[00:28:00.860 --> 00:28:03.020]   So do you have worry about such AI systems?
[00:28:03.020 --> 00:28:05.380]   - Well, yes, that is an existential risk,
[00:28:05.380 --> 00:28:07.740]   but again, I think an existential risk,
[00:28:07.740 --> 00:28:09.740]   not for this century.
[00:28:09.740 --> 00:28:12.500]   I think our grandkids are gonna have to confront
[00:28:12.500 --> 00:28:15.140]   this question as robots gradually approach
[00:28:15.140 --> 00:28:17.820]   the intelligence of a dog, a cat,
[00:28:17.820 --> 00:28:20.420]   and finally that of a monkey.
[00:28:20.420 --> 00:28:23.740]   However, I think we will digitize ourselves as well.
[00:28:23.740 --> 00:28:26.100]   Not only are we gonna merge with our technology,
[00:28:26.100 --> 00:28:28.540]   it will also digitize our personality,
[00:28:28.540 --> 00:28:30.660]   our memories, our feelings.
[00:28:30.660 --> 00:28:32.540]   You realize that during the Middle Ages,
[00:28:32.540 --> 00:28:34.660]   there was something called dualism.
[00:28:34.660 --> 00:28:38.180]   Dualism meant that the soul was separate from the body.
[00:28:38.180 --> 00:28:40.900]   When the body died, the soul went to heaven.
[00:28:40.900 --> 00:28:42.420]   That's dualism.
[00:28:42.420 --> 00:28:44.020]   Then in the 20th century,
[00:28:44.020 --> 00:28:47.660]   neuroscience came in and said, bah, humbug.
[00:28:47.660 --> 00:28:50.900]   Every time we look at the brain, it's just neurons.
[00:28:50.900 --> 00:28:54.620]   That's it, folks, period, end of story.
[00:28:54.620 --> 00:28:56.820]   Bunch of neurons firing.
[00:28:56.820 --> 00:28:59.620]   Now we're going back to dualism.
[00:28:59.620 --> 00:29:03.420]   Now we realize that we can digitize human memories,
[00:29:03.420 --> 00:29:05.980]   feelings, sensations,
[00:29:05.980 --> 00:29:09.020]   and create a digital copy of ourselves,
[00:29:09.020 --> 00:29:11.580]   and that's called the Connectome Project.
[00:29:11.580 --> 00:29:14.260]   Billions of dollars are now being spent
[00:29:14.260 --> 00:29:17.300]   to do not just the genome project
[00:29:17.300 --> 00:29:19.620]   of sequencing the genes of our body,
[00:29:19.620 --> 00:29:21.620]   but the Connectome Project,
[00:29:21.620 --> 00:29:26.100]   which is to map the entire connections of the human brain.
[00:29:26.100 --> 00:29:28.900]   And even before then, already in Silicon Valley,
[00:29:28.900 --> 00:29:31.300]   today, at this very moment,
[00:29:31.300 --> 00:29:33.420]   you can contact Silicon Valley companies
[00:29:33.420 --> 00:29:36.780]   that are willing to digitize your relatives,
[00:29:36.780 --> 00:29:39.700]   because some people want to talk to their parents.
[00:29:39.700 --> 00:29:42.380]   There are unresolved issues with their parents,
[00:29:42.380 --> 00:29:45.740]   and one day, yes, firms will digitize people,
[00:29:45.740 --> 00:29:49.260]   and you'll be able to talk to them a reasonable facsimile.
[00:29:49.260 --> 00:29:52.380]   We leave a digital trail.
[00:29:52.380 --> 00:29:54.020]   Our ancestors did not.
[00:29:54.020 --> 00:29:57.580]   Our ancestors were lucky if they had one line,
[00:29:57.580 --> 00:30:00.660]   just one line in a church book,
[00:30:00.660 --> 00:30:04.380]   saying the date they were baptized and the date they died.
[00:30:04.380 --> 00:30:05.260]   That's it.
[00:30:05.260 --> 00:30:08.180]   That was their entire digital memory.
[00:30:08.180 --> 00:30:10.540]   I mean, their entire digital existence
[00:30:10.540 --> 00:30:14.620]   summarized in just a few letters of the alphabet,
[00:30:14.620 --> 00:30:15.940]   a whole life.
[00:30:15.940 --> 00:30:17.940]   Now, we digitize everything.
[00:30:17.940 --> 00:30:20.300]   Every time you sneeze, you digitize it.
[00:30:20.300 --> 00:30:21.700]   You put it on the internet.
[00:30:21.700 --> 00:30:25.420]   And so I think that we are gonna digitize ourselves,
[00:30:25.420 --> 00:30:27.940]   and it'll give us digital immortality.
[00:30:27.940 --> 00:30:31.220]   We'll not only have biologic genetic immortality
[00:30:31.220 --> 00:30:34.940]   of some sort, but also digital immortality.
[00:30:34.940 --> 00:30:37.060]   And what are we gonna do with it?
[00:30:37.060 --> 00:30:39.780]   I think we should send it into outer space.
[00:30:39.780 --> 00:30:43.060]   If you digitize the human brain
[00:30:43.060 --> 00:30:46.580]   and put it on a laser beam and shoot it to the moon,
[00:30:46.580 --> 00:30:48.780]   you're on the moon in one second.
[00:30:48.780 --> 00:30:51.940]   Shoot it to Mars, you're on Mars in 20 minutes.
[00:30:51.940 --> 00:30:54.780]   Shoot it to Pluto, you're on Pluto in eight hours.
[00:30:54.780 --> 00:30:56.140]   Think about it for a moment.
[00:30:56.140 --> 00:30:58.420]   You can have breakfast in New York
[00:30:58.420 --> 00:31:01.940]   and for a morning snack, vacation on the moon,
[00:31:01.940 --> 00:31:05.500]   then zap your way to Mars by noontime,
[00:31:05.500 --> 00:31:08.460]   journey to the asteroid belt in the afternoon,
[00:31:08.460 --> 00:31:11.900]   and then come back for dinner in New York at night.
[00:31:11.900 --> 00:31:16.020]   All in a day's work at the speed of light.
[00:31:16.020 --> 00:31:19.580]   Now, this means that you don't need booster rockets,
[00:31:19.580 --> 00:31:21.660]   you don't need weightlessness problems,
[00:31:21.660 --> 00:31:23.660]   you don't need to worry about meteorites.
[00:31:23.660 --> 00:31:25.260]   And what's on the moon?
[00:31:25.260 --> 00:31:27.300]   On the moon, there is a mainframe
[00:31:27.300 --> 00:31:30.180]   that downloads your laser beam's information.
[00:31:30.180 --> 00:31:33.980]   And where does it download the information into?
[00:31:33.980 --> 00:31:35.740]   An avatar.
[00:31:35.740 --> 00:31:37.740]   And what does that avatar look like?
[00:31:37.740 --> 00:31:40.940]   Anything you want.
[00:31:40.940 --> 00:31:41.860]   Think about it for a moment.
[00:31:41.860 --> 00:31:46.180]   You could be Superman, Superwoman on the moon,
[00:31:46.180 --> 00:31:49.300]   on Mars, traveling throughout the universe
[00:31:49.300 --> 00:31:50.820]   at the speed of light,
[00:31:50.820 --> 00:31:55.220]   downloading your personality into any vehicle you want.
[00:31:55.220 --> 00:31:57.140]   Now, let me stick my neck out.
[00:31:57.140 --> 00:31:58.900]   So far, everything I've been saying
[00:31:58.900 --> 00:32:00.740]   is well within the laws of physics.
[00:32:00.740 --> 00:32:02.420]   Well within the laws of physics.
[00:32:02.420 --> 00:32:04.700]   Now, let me go outside the laws of physics again.
[00:32:04.700 --> 00:32:05.860]   - Here we go.
[00:32:05.860 --> 00:32:08.820]   - I think this already exists.
[00:32:08.820 --> 00:32:10.260]   I think outside the Earth,
[00:32:10.260 --> 00:32:11.820]   there could be a super highway,
[00:32:11.820 --> 00:32:14.740]   a laser highway of laser porting
[00:32:14.740 --> 00:32:17.540]   with billions of souls of aliens
[00:32:17.540 --> 00:32:20.860]   zapping their way across the galaxy.
[00:32:20.860 --> 00:32:22.620]   Now, let me ask you a question.
[00:32:22.620 --> 00:32:25.220]   Are we smart enough to determine
[00:32:25.220 --> 00:32:28.260]   whether such a thing exists or not?
[00:32:28.260 --> 00:32:31.140]   No, this could exist right outside
[00:32:31.140 --> 00:32:32.900]   the orbit of the planet Earth.
[00:32:32.900 --> 00:32:35.620]   And we're too stupid in our technology
[00:32:35.620 --> 00:32:38.700]   to even prove it or disprove it.
[00:32:38.700 --> 00:32:43.460]   We would need the aliens on this laser super highway
[00:32:43.460 --> 00:32:44.540]   to help us out.
[00:32:45.940 --> 00:32:50.620]   To send us a human interpretable signal.
[00:32:50.620 --> 00:32:51.860]   I mean, it ultimately boils down
[00:32:51.860 --> 00:32:53.300]   to the language of communication,
[00:32:53.300 --> 00:32:54.940]   but that's an exciting possibility
[00:32:54.940 --> 00:32:59.100]   that actually the sky is filled with aliens.
[00:32:59.100 --> 00:33:00.700]   - The aliens could already be here.
[00:33:00.700 --> 00:33:03.060]   And we're just so oblivious
[00:33:03.060 --> 00:33:05.300]   that we're too stupid to know it.
[00:33:05.300 --> 00:33:07.220]   See, they don't have to be in alien form
[00:33:07.220 --> 00:33:09.700]   with little green men.
[00:33:09.700 --> 00:33:11.420]   They can be in any form they want,
[00:33:11.420 --> 00:33:13.260]   in an avatar of their creation.
[00:33:13.260 --> 00:33:16.220]   - Well, in fact, they could very well be--
[00:33:16.220 --> 00:33:17.340]   - They could even look like us.
[00:33:17.340 --> 00:33:18.940]   - Exactly. - We'd never know.
[00:33:18.940 --> 00:33:21.260]   - One of us could be an alien.
[00:33:21.260 --> 00:33:22.740]   - You know, in the zoo, did you know
[00:33:22.740 --> 00:33:26.380]   that we sometimes have zookeepers that imitate animals?
[00:33:26.380 --> 00:33:29.260]   We create a fake animal and we put it in
[00:33:29.260 --> 00:33:33.500]   so that the animal is not afraid of this fake animal.
[00:33:33.500 --> 00:33:35.100]   And of course, these animals' brains,
[00:33:35.100 --> 00:33:37.080]   their brain is about as big as a walnut.
[00:33:37.080 --> 00:33:40.660]   They accept these dummies as if they were real.
[00:33:41.660 --> 00:33:44.100]   So an alien civilization in outer space would say,
[00:33:44.100 --> 00:33:46.460]   "Oh yeah, human brains are so tiny.
[00:33:46.460 --> 00:33:49.220]   We could put a dummy on their world, an avatar,
[00:33:49.220 --> 00:33:50.780]   and they'd never know it."
[00:33:50.780 --> 00:33:53.380]   - That would be an entertaining thing to watch
[00:33:53.380 --> 00:33:55.020]   from the alien perspective.
[00:33:55.020 --> 00:33:57.140]   So you kind of implied that
[00:33:57.140 --> 00:34:00.620]   with the digital form of our being,
[00:34:00.620 --> 00:34:02.300]   but also biologically.
[00:34:02.300 --> 00:34:04.540]   Do you think one day technology will allow
[00:34:04.540 --> 00:34:07.600]   individual human beings to become immortal,
[00:34:07.600 --> 00:34:11.580]   besides just through the ability to digitize our essence?
[00:34:11.580 --> 00:34:13.620]   - Yeah, I think that artificial intelligence
[00:34:13.620 --> 00:34:17.180]   will give us the key to genetic immortality.
[00:34:17.180 --> 00:34:18.900]   You see, in the coming decades,
[00:34:18.900 --> 00:34:21.260]   everyone's gonna have their gene sequenced.
[00:34:21.260 --> 00:34:24.160]   We'll have billions of genomes of old people,
[00:34:24.160 --> 00:34:26.740]   billions of genomes of young people.
[00:34:26.740 --> 00:34:28.200]   And what are we gonna do with it?
[00:34:28.200 --> 00:34:30.120]   We're gonna run it through an AI machine,
[00:34:30.120 --> 00:34:31.900]   which has pattern recognition,
[00:34:31.900 --> 00:34:35.100]   to look for the age genes.
[00:34:35.100 --> 00:34:37.540]   In other words, the fountain of youth
[00:34:37.540 --> 00:34:41.020]   that emperors, kings, and queens lusted over
[00:34:41.020 --> 00:34:44.060]   the fountain of youth will be found
[00:34:44.060 --> 00:34:46.180]   by artificial intelligence.
[00:34:46.180 --> 00:34:48.820]   Artificial intelligence will identify
[00:34:48.820 --> 00:34:52.220]   where these age genes are located.
[00:34:52.220 --> 00:34:53.820]   First of all, what is aging?
[00:34:53.820 --> 00:34:55.860]   We now know what aging is.
[00:34:55.860 --> 00:34:59.680]   Aging is the buildup of errors.
[00:34:59.680 --> 00:35:03.560]   That's all aging is, the buildup of genetic errors.
[00:35:03.560 --> 00:35:07.340]   This means that cells eventually become slower, sluggish,
[00:35:07.340 --> 00:35:10.500]   and they go into senescence, and they die.
[00:35:10.500 --> 00:35:13.700]   In fact, that's why we die.
[00:35:13.700 --> 00:35:16.820]   We die because of the buildup of mistakes
[00:35:16.820 --> 00:35:20.700]   in our genome, in our cellular activity.
[00:35:20.700 --> 00:35:22.100]   But you see, in the future, we'll be able
[00:35:22.100 --> 00:35:25.420]   to fix those genes with CRISPR-type technologies,
[00:35:25.420 --> 00:35:27.380]   and perhaps even live forever.
[00:35:27.380 --> 00:35:29.140]   So let me ask you a question.
[00:35:29.140 --> 00:35:32.140]   Where does aging take place in a car?
[00:35:32.140 --> 00:35:34.640]   Given a car, where does aging take place?
[00:35:34.640 --> 00:35:37.500]   Well, it's obvious, the engine, right?
[00:35:37.500 --> 00:35:39.960]   A, that's where you have a lot of moving parts.
[00:35:39.960 --> 00:35:41.740]   B, that's where you have combustion.
[00:35:41.740 --> 00:35:46.740]   Well, where in the cell do we have combustion?
[00:35:46.740 --> 00:35:48.780]   The mitochondria.
[00:35:48.780 --> 00:35:51.980]   We now know where aging takes place.
[00:35:51.980 --> 00:35:54.300]   And if we cure many of the mistakes
[00:35:54.300 --> 00:35:56.740]   that build up in the mitochondria of the cell,
[00:35:56.740 --> 00:35:59.340]   we could become immortal.
[00:35:59.340 --> 00:36:02.120]   - Let me ask you, if you yourself
[00:36:02.120 --> 00:36:04.080]   could become immortal, would you?
[00:36:04.080 --> 00:36:07.140]   - Damn straight.
[00:36:07.140 --> 00:36:08.860]   (laughing)
[00:36:08.860 --> 00:36:10.280]   No, I think about it for a while,
[00:36:10.280 --> 00:36:14.880]   because of course, it depends on how you become immortal.
[00:36:14.880 --> 00:36:17.560]   You know, there's a famous myth of Tithonus.
[00:36:17.560 --> 00:36:21.640]   It turns out that years ago, in the Greeks mythology,
[00:36:21.640 --> 00:36:25.280]   there was the saga of Tithonus and Aurora.
[00:36:25.280 --> 00:36:28.400]   Aurora was the goddess of the dawn,
[00:36:28.400 --> 00:36:30.240]   and she fell in love with a mortal,
[00:36:30.240 --> 00:36:32.320]   a human called Tithonus.
[00:36:32.320 --> 00:36:37.320]   And so Aurora begged Zeus to grant her
[00:36:37.460 --> 00:36:42.280]   the gift of immortality to give to her lover.
[00:36:42.280 --> 00:36:47.120]   So Zeus took pity on Aurora and made Tithonus immortal.
[00:36:47.120 --> 00:36:52.120]   But you see, Aurora made a mistake, a huge mistake.
[00:36:52.120 --> 00:36:54.800]   She asked for immortality,
[00:36:54.800 --> 00:36:58.000]   but she forgot to ask for eternal youth.
[00:36:58.000 --> 00:37:03.520]   So poor Tithonus got older and older and older every year,
[00:37:03.520 --> 00:37:08.520]   decrepit, a bag of bones, but he could never die, never die.
[00:37:08.520 --> 00:37:11.600]   - Quality of life is important.
[00:37:11.600 --> 00:37:14.620]   - So I think immortality is a great idea,
[00:37:14.620 --> 00:37:18.140]   as long as you also have immortal youth as well.
[00:37:18.140 --> 00:37:20.780]   Now I personally believe, and I cannot prove this,
[00:37:20.780 --> 00:37:22.700]   but I personally believe that our grandkids
[00:37:22.700 --> 00:37:26.180]   may have the option of reaching the age of 30
[00:37:26.180 --> 00:37:28.220]   and then stopping.
[00:37:28.220 --> 00:37:32.380]   They may like being age 30, 'cause you have wisdom,
[00:37:32.380 --> 00:37:35.700]   you have all the benefits of age and maturity,
[00:37:35.700 --> 00:37:39.260]   and you still live forever with a healthy body.
[00:37:39.260 --> 00:37:43.260]   Our descendants may like being 30 for several centuries.
[00:37:43.260 --> 00:37:45.300]   - Is there an aspect of human existence
[00:37:45.300 --> 00:37:47.700]   that is meaningful only because we're mortal?
[00:37:47.700 --> 00:37:52.140]   - Well, every waking moment,
[00:37:52.140 --> 00:37:53.900]   we don't think about it this way,
[00:37:53.900 --> 00:37:55.220]   but every waking moment,
[00:37:55.220 --> 00:38:00.220]   actually we are aware of our death and our mortality.
[00:38:00.220 --> 00:38:01.320]   Think about it for a moment.
[00:38:01.320 --> 00:38:03.380]   When you go to college,
[00:38:03.380 --> 00:38:05.900]   you realize that you are in a period of time
[00:38:05.900 --> 00:38:10.360]   where soon you will reach middle age and have a career,
[00:38:10.360 --> 00:38:13.860]   and after that you'll retire and then you'll die.
[00:38:13.860 --> 00:38:17.340]   And so even as a youth, even as a child,
[00:38:17.340 --> 00:38:19.600]   without even thinking about it,
[00:38:19.600 --> 00:38:21.880]   you are aware of your own death,
[00:38:21.880 --> 00:38:24.700]   'cause it sets limits to your lifespan.
[00:38:24.700 --> 00:38:26.260]   I gotta graduate from high school,
[00:38:26.260 --> 00:38:27.860]   I gotta graduate from college.
[00:38:27.860 --> 00:38:28.900]   Why?
[00:38:28.900 --> 00:38:30.380]   Because you're gonna die.
[00:38:30.380 --> 00:38:32.940]   Because unless you graduate from high school,
[00:38:32.940 --> 00:38:34.680]   unless you graduate from college,
[00:38:34.680 --> 00:38:37.300]   you're not gonna enter old age with enough money
[00:38:37.300 --> 00:38:39.500]   to retire and then die.
[00:38:39.500 --> 00:38:42.680]   And so yeah, people think about it unconsciously
[00:38:42.680 --> 00:38:46.940]   because it affects every aspect of your being.
[00:38:46.940 --> 00:38:49.280]   The fact that you go to high school, college,
[00:38:49.280 --> 00:38:52.300]   get married, have kids, there's a clock.
[00:38:52.300 --> 00:38:55.540]   A clock ticking even without your permission.
[00:38:55.540 --> 00:38:58.300]   - It gives a sense of urgency.
[00:38:59.580 --> 00:39:02.420]   Do you yourself, I mean, there's so much excitement
[00:39:02.420 --> 00:39:04.580]   and passion in the way you talk about physics
[00:39:04.580 --> 00:39:07.980]   and the way you talk about technology in the future.
[00:39:07.980 --> 00:39:11.460]   Do you yourself meditate on your own mortality?
[00:39:11.460 --> 00:39:14.620]   Do you think about this clock that's ticking?
[00:39:14.620 --> 00:39:15.820]   - Well, I try not to,
[00:39:15.820 --> 00:39:19.620]   because it then begins to affect your behavior.
[00:39:19.620 --> 00:39:21.980]   You begin to alter your behavior
[00:39:21.980 --> 00:39:26.340]   to match your expectation of when you're gonna die.
[00:39:26.340 --> 00:39:27.900]   So let's talk about youth
[00:39:27.900 --> 00:39:31.100]   and then let's talk about death, okay?
[00:39:31.100 --> 00:39:34.860]   When I interview scientists on radio,
[00:39:34.860 --> 00:39:38.020]   I often ask them, what made the difference?
[00:39:38.020 --> 00:39:39.460]   How old were you?
[00:39:39.460 --> 00:39:41.940]   What changed your life?
[00:39:41.940 --> 00:39:44.140]   And they always say more or less the same thing.
[00:39:44.140 --> 00:39:45.640]   No, these are Nobel Prize winners,
[00:39:45.640 --> 00:39:47.080]   directors of major laboratories,
[00:39:47.080 --> 00:39:48.820]   very distinguished scientists.
[00:39:48.820 --> 00:39:51.900]   They always say, when I was 10.
[00:39:51.900 --> 00:39:55.500]   When I was 10, something happened.
[00:39:55.500 --> 00:39:57.780]   It was a visit to the planetarium.
[00:39:57.780 --> 00:39:59.460]   It was a telescope.
[00:39:59.460 --> 00:40:01.960]   For Steven Weinberg, winner of the Nobel Prize,
[00:40:01.960 --> 00:40:03.900]   it was the chemistry kit.
[00:40:03.900 --> 00:40:07.280]   For Heinz Pagels, it was a visit to the planetarium.
[00:40:07.280 --> 00:40:10.940]   For Isidore Rabi, it was a book about the planets.
[00:40:10.940 --> 00:40:14.140]   For Albert Einstein, it was a compass.
[00:40:14.140 --> 00:40:18.860]   Something happened which gives them this existential shock.
[00:40:18.860 --> 00:40:20.500]   'Cause you see, before the age of 10,
[00:40:20.500 --> 00:40:22.540]   everything is mommy and daddy, mommy and dad.
[00:40:22.540 --> 00:40:25.060]   That's your universe, mommy and daddy.
[00:40:25.060 --> 00:40:27.540]   Around the age of 10, you begin to wonder,
[00:40:27.540 --> 00:40:30.700]   what's beyond mommy and daddy?
[00:40:30.700 --> 00:40:33.620]   And that's when you have this epiphany,
[00:40:33.620 --> 00:40:38.620]   when you realize, oh my God, there's a universe out there,
[00:40:38.620 --> 00:40:40.380]   a universe of discovery.
[00:40:40.380 --> 00:40:45.380]   And that sensation stays with you for the rest of your life.
[00:40:45.380 --> 00:40:49.020]   You still remember that shock that you felt
[00:40:49.020 --> 00:40:50.820]   gazing at the universe.
[00:40:50.820 --> 00:40:55.460]   And then you hit the greatest destroyer of scientists
[00:40:55.460 --> 00:40:57.580]   known to science.
[00:40:57.580 --> 00:41:02.500]   The greatest destroyer of scientists known to science
[00:41:02.500 --> 00:41:03.920]   is junior high school.
[00:41:03.920 --> 00:41:05.600]   (laughing)
[00:41:05.600 --> 00:41:08.900]   When you hit junior high school, folks, it's all over.
[00:41:08.900 --> 00:41:10.780]   It's all over.
[00:41:10.780 --> 00:41:14.660]   Because in junior high school, people say, hey, stupid.
[00:41:14.660 --> 00:41:17.640]   I mean, you like that nerdy stuff,
[00:41:17.640 --> 00:41:19.860]   and your friends shun you.
[00:41:19.860 --> 00:41:22.620]   All of a sudden, people think you're a weirdo,
[00:41:22.620 --> 00:41:25.240]   and science is made boring.
[00:41:25.240 --> 00:41:27.500]   You know, Richard Feynman, the Nobel Prize winner,
[00:41:27.500 --> 00:41:30.140]   when he was a child, his father would take him
[00:41:30.140 --> 00:41:32.820]   into the forest, and the father would teach him
[00:41:32.820 --> 00:41:37.020]   everything about birds, why they're shaped the way they are,
[00:41:37.020 --> 00:41:40.580]   their wings, the coloration, the shape of their beak,
[00:41:40.580 --> 00:41:43.140]   everything about birds.
[00:41:43.140 --> 00:41:45.060]   So one day, a bully comes up to the future
[00:41:45.060 --> 00:41:48.540]   Nobel Prize winner and says, hey, dick,
[00:41:48.540 --> 00:41:50.540]   what's the name of that bird over there?
[00:41:50.540 --> 00:41:53.140]   Well, he didn't know.
[00:41:53.140 --> 00:41:58.140]   He knew everything about that bird except its name.
[00:41:58.140 --> 00:42:01.060]   So he said, I don't know.
[00:42:01.060 --> 00:42:03.140]   And then the bully said, what's the matter, dick,
[00:42:03.140 --> 00:42:05.140]   you stupid or something?
[00:42:05.140 --> 00:42:08.820]   And then in that instant, he got it.
[00:42:08.820 --> 00:42:10.180]   He got it.
[00:42:10.180 --> 00:42:12.100]   He realized that for most people,
[00:42:12.100 --> 00:42:15.040]   science is giving names to birds.
[00:42:15.040 --> 00:42:17.540]   That's what science is.
[00:42:17.540 --> 00:42:19.860]   You know, lots of names of obscure things.
[00:42:19.860 --> 00:42:21.780]   Hey, people say, you're smart.
[00:42:21.780 --> 00:42:22.860]   You're smart.
[00:42:22.860 --> 00:42:24.720]   You know all the names of the dinosaurs.
[00:42:24.720 --> 00:42:26.620]   You know all the names of the plants.
[00:42:26.620 --> 00:42:29.940]   No, that's not science at all.
[00:42:29.940 --> 00:42:34.940]   Science is about principles, concepts, physical pictures.
[00:42:34.940 --> 00:42:38.640]   That's what science is all about.
[00:42:38.640 --> 00:42:41.660]   My favorite quote from Einstein is that,
[00:42:41.660 --> 00:42:44.820]   unless you can explain a theory to a child,
[00:42:44.820 --> 00:42:47.880]   the theory is probably worthless.
[00:42:47.880 --> 00:42:52.820]   Meaning that all great theories are not big words.
[00:42:52.820 --> 00:42:55.800]   All great theories are simple concepts,
[00:42:55.800 --> 00:43:00.340]   principles, basic physical pictures.
[00:43:00.340 --> 00:43:04.580]   Relativity is all about clocks, meter sticks,
[00:43:04.580 --> 00:43:07.220]   rocket ships, and locomotives.
[00:43:07.220 --> 00:43:10.120]   Newton's laws of gravity are all about balls
[00:43:10.120 --> 00:43:13.260]   and spinning wheels and things like that.
[00:43:13.260 --> 00:43:15.840]   That's what physics and science is all about,
[00:43:15.840 --> 00:43:17.540]   not memorizing things.
[00:43:17.540 --> 00:43:20.920]   And that stays with you for the rest of your life.
[00:43:20.920 --> 00:43:22.460]   So even in old age,
[00:43:22.460 --> 00:43:25.940]   I've noticed that these scientists, when they sit back,
[00:43:25.940 --> 00:43:28.080]   they still remember.
[00:43:28.080 --> 00:43:30.580]   They still remember that flush,
[00:43:30.580 --> 00:43:33.080]   that flush of excitement they felt
[00:43:33.080 --> 00:43:34.960]   with that first telescope,
[00:43:34.960 --> 00:43:38.700]   that first moment when they encountered the universe.
[00:43:38.700 --> 00:43:40.140]   That keeps them going.
[00:43:40.140 --> 00:43:41.220]   That keeps them going.
[00:43:42.900 --> 00:43:46.300]   By the way, I should point out that when I was eight,
[00:43:46.300 --> 00:43:49.300]   something happened to me as well.
[00:43:49.300 --> 00:43:51.860]   When I was eight years old,
[00:43:51.860 --> 00:43:53.760]   it was in all the papers
[00:43:53.760 --> 00:43:56.780]   that a great scientist had just died,
[00:43:56.780 --> 00:44:00.820]   and they put a picture of his desk on the front page.
[00:44:00.820 --> 00:44:03.980]   That's it, just a simple picture of the front page
[00:44:03.980 --> 00:44:06.300]   of the newspapers of his desk.
[00:44:06.300 --> 00:44:09.180]   That desk had a book on it, which was opened.
[00:44:09.180 --> 00:44:11.420]   And the caption said, more or less,
[00:44:11.420 --> 00:44:14.260]   "This is the unfinished manuscript
[00:44:14.260 --> 00:44:17.660]   "from the greatest scientists of our time."
[00:44:17.660 --> 00:44:22.300]   So I said to myself, well, why couldn't he finish it?
[00:44:22.300 --> 00:44:25.820]   What's so hard that you can't finish it
[00:44:25.820 --> 00:44:26.980]   if you're a great scientist?
[00:44:26.980 --> 00:44:29.020]   It's a homework problem, right?
[00:44:29.020 --> 00:44:32.160]   You go home, you solve it, or you ask your mom,
[00:44:32.160 --> 00:44:33.820]   why couldn't he solve it?
[00:44:33.820 --> 00:44:35.660]   So to me, this was a murder mystery.
[00:44:35.660 --> 00:44:37.940]   This was greater than any adventure story.
[00:44:37.940 --> 00:44:41.140]   I had to know why the greatest scientists of our time
[00:44:41.140 --> 00:44:43.300]   couldn't finish something.
[00:44:43.300 --> 00:44:44.700]   And then over the years,
[00:44:44.700 --> 00:44:47.900]   I found out the guy had a name, Albert Einstein,
[00:44:47.900 --> 00:44:51.940]   and that book was the theory of everything.
[00:44:51.940 --> 00:44:53.520]   It was unfinished.
[00:44:53.520 --> 00:44:55.260]   Well, today, I can read that book.
[00:44:55.260 --> 00:44:59.780]   I can see all the dead ends and false starts that he made,
[00:44:59.780 --> 00:45:02.580]   and I began to realize that he lost his way
[00:45:02.580 --> 00:45:06.380]   because he didn't have a physical picture
[00:45:06.380 --> 00:45:09.840]   to guide him on the third try.
[00:45:09.840 --> 00:45:13.000]   On the first try, he talked about clocks
[00:45:13.000 --> 00:45:15.480]   and lightning bolts and meter sticks,
[00:45:15.480 --> 00:45:17.740]   and that gave us special relativity,
[00:45:17.740 --> 00:45:20.300]   which gave us the atomic bomb.
[00:45:20.300 --> 00:45:23.460]   The second great picture was gravity
[00:45:23.460 --> 00:45:26.780]   with balls rolling on curved surfaces,
[00:45:26.780 --> 00:45:28.620]   and that gave us the Big Bang,
[00:45:28.620 --> 00:45:31.380]   creation of the universe, black holes.
[00:45:31.380 --> 00:45:34.620]   On the third try, he missed it.
[00:45:34.620 --> 00:45:38.580]   He had no picture at all to guide him.
[00:45:38.580 --> 00:45:40.040]   In fact, there's a quote I have
[00:45:40.040 --> 00:45:42.000]   where he said, "I'm still looking.
[00:45:42.000 --> 00:45:44.700]   "I'm still looking for that picture."
[00:45:44.700 --> 00:45:46.220]   He never found it.
[00:45:46.220 --> 00:45:49.740]   Well, today, we think that picture is string theory.
[00:45:49.740 --> 00:45:52.300]   - So string theory can unify gravity
[00:45:52.300 --> 00:45:54.780]   and this mysterious thing that Einstein didn't like,
[00:45:54.780 --> 00:45:55.900]   which is quantum mechanics,
[00:45:55.900 --> 00:45:59.280]   or couldn't quite pin down and make sense of.
[00:45:59.280 --> 00:46:00.120]   - That's right.
[00:46:00.120 --> 00:46:02.920]   Mother Nature has two hands, a left hand and a right hand.
[00:46:02.920 --> 00:46:05.260]   The left hand is a theory of the small.
[00:46:05.260 --> 00:46:07.780]   The right hand is a theory of the big.
[00:46:07.780 --> 00:46:09.900]   The theory of the small is the quantum theory,
[00:46:09.900 --> 00:46:11.980]   the theory of atoms and quarks.
[00:46:11.980 --> 00:46:14.020]   The theory of the big is relativity,
[00:46:14.020 --> 00:46:16.400]   the theory of black holes, big bangs.
[00:46:16.400 --> 00:46:21.140]   The problem is the left hand does not talk to the right hand.
[00:46:21.140 --> 00:46:24.540]   They hate each other.
[00:46:24.540 --> 00:46:27.420]   The left hand is based on discrete particles.
[00:46:27.420 --> 00:46:31.100]   The right hand is based on smooth surfaces.
[00:46:31.100 --> 00:46:33.260]   How do you put these two things together
[00:46:33.260 --> 00:46:34.300]   into a single theory?
[00:46:34.300 --> 00:46:35.900]   They hate each other.
[00:46:35.900 --> 00:46:38.220]   The greatest minds of our time,
[00:46:38.220 --> 00:46:40.220]   the greatest minds of our time
[00:46:40.220 --> 00:46:43.340]   worked on this problem and failed.
[00:46:43.340 --> 00:46:46.760]   Today, the only theory that has survived
[00:46:46.760 --> 00:46:49.560]   every challenge so far is string theory.
[00:46:49.560 --> 00:46:51.640]   That doesn't mean string theory is correct.
[00:46:51.640 --> 00:46:53.420]   It could very well be wrong.
[00:46:53.420 --> 00:46:56.300]   But right now, it's the only game in town.
[00:46:56.300 --> 00:46:57.820]   Some people come up to me and say,
[00:46:57.820 --> 00:47:00.260]   "Professor, I don't believe in string theory.
[00:47:00.260 --> 00:47:02.760]   Give me an alternative."
[00:47:02.760 --> 00:47:05.820]   And I tell them, "There is none.
[00:47:05.820 --> 00:47:06.660]   Get used to it."
[00:47:06.660 --> 00:47:07.820]   (laughs)
[00:47:07.820 --> 00:47:09.420]   - It's the best theory we got.
[00:47:09.420 --> 00:47:10.940]   - It's the only theory we have.
[00:47:10.940 --> 00:47:13.140]   - It's the only theory we have.
[00:47:13.140 --> 00:47:16.100]   Do you see, you know,
[00:47:16.100 --> 00:47:20.220]   the strings kind of inspire a view,
[00:47:20.220 --> 00:47:23.180]   as did atoms and particles and quarks,
[00:47:23.180 --> 00:47:26.800]   but especially strings inspire a view of a universe
[00:47:26.800 --> 00:47:29.060]   as a kind of information processing system,
[00:47:29.060 --> 00:47:31.620]   as a computer of sorts.
[00:47:31.620 --> 00:47:33.780]   Do you see the universe in this way?
[00:47:33.780 --> 00:47:36.340]   - No. Some people think, in fact,
[00:47:36.340 --> 00:47:39.300]   the whole universe is a computer of some sort.
[00:47:39.300 --> 00:47:40.140]   - Yes.
[00:47:40.140 --> 00:47:42.620]   - And they believe that perhaps everything,
[00:47:42.620 --> 00:47:44.100]   therefore, is a simulation.
[00:47:44.100 --> 00:47:45.080]   - Yes.
[00:47:45.080 --> 00:47:46.380]   - I don't think so.
[00:47:46.380 --> 00:47:49.360]   I don't think that there is a super video game
[00:47:49.360 --> 00:47:52.700]   where we are nothing but puppets dancing on the screen
[00:47:52.700 --> 00:47:54.500]   and somebody hit the play button
[00:47:54.500 --> 00:47:57.620]   and here we are talking about simulations.
[00:47:57.620 --> 00:47:58.520]   No.
[00:47:58.520 --> 00:48:02.820]   Even Newtonian mechanics says that the weather,
[00:48:02.820 --> 00:48:04.860]   the simple weather is so complicated
[00:48:04.860 --> 00:48:07.360]   with trillions upon trillions of atoms
[00:48:07.360 --> 00:48:10.900]   that it cannot be simulated in a finite amount of time.
[00:48:10.900 --> 00:48:13.900]   In other words, the smallest object
[00:48:13.900 --> 00:48:18.660]   which can describe the weather and simulate the weather
[00:48:18.660 --> 00:48:21.420]   is the weather itself.
[00:48:21.420 --> 00:48:24.420]   The smallest object that can simulate a human
[00:48:24.420 --> 00:48:27.020]   is the human itself.
[00:48:27.020 --> 00:48:28.900]   And if you had quantum mechanics,
[00:48:28.900 --> 00:48:32.540]   it becomes almost impossible to simulate it
[00:48:32.540 --> 00:48:34.820]   with a conventional computer.
[00:48:34.820 --> 00:48:38.620]   Because quantum mechanics deals with all possible universes,
[00:48:38.620 --> 00:48:42.440]   parallel universes, a multiverse of universes.
[00:48:42.440 --> 00:48:46.660]   And so the calculation just spirals out of control.
[00:48:46.660 --> 00:48:49.780]   Now, at so far, there's only one way
[00:48:49.780 --> 00:48:52.320]   where you might be able to argue
[00:48:52.320 --> 00:48:54.340]   that the universe is a simulation.
[00:48:54.340 --> 00:48:57.460]   And this is still being debated by quantum physicists.
[00:48:57.460 --> 00:49:00.500]   It turns out that if you throw the encyclopedia
[00:49:00.500 --> 00:49:04.020]   into a black hole, the information is not lost.
[00:49:04.020 --> 00:49:07.620]   Eventually it winds up on the surface of the black hole.
[00:49:07.620 --> 00:49:09.980]   Now the surface of the black hole is finite.
[00:49:09.980 --> 00:49:12.740]   In fact, you can calculate the maximum amount
[00:49:12.740 --> 00:49:15.660]   of information you can store in a black hole.
[00:49:15.660 --> 00:49:17.180]   It's a finite number.
[00:49:17.180 --> 00:49:19.740]   It's a calculable number, believe it or not.
[00:49:19.740 --> 00:49:21.740]   Now, if the universe were made out of black holes,
[00:49:21.740 --> 00:49:24.980]   which is the maximum universe you can conceive of,
[00:49:24.980 --> 00:49:27.140]   each universe, each black hole
[00:49:27.140 --> 00:49:29.620]   has a finite amount of information.
[00:49:29.620 --> 00:49:34.060]   Therefore, ergo, ta-da, ergo,
[00:49:34.060 --> 00:49:38.900]   the total amount of information in a universe is finite.
[00:49:38.900 --> 00:49:40.500]   This is mind-boggling.
[00:49:40.500 --> 00:49:42.980]   This I consider mind-boggling,
[00:49:42.980 --> 00:49:46.620]   that all possible universes are countable,
[00:49:46.620 --> 00:49:50.020]   and all possible universes can be summarized in a number,
[00:49:50.020 --> 00:49:52.020]   a number you can write on a sheet of paper,
[00:49:52.020 --> 00:49:55.160]   all possible universes, and it's a finite number.
[00:49:55.160 --> 00:49:56.620]   Now, it's huge.
[00:49:56.620 --> 00:49:58.660]   It's a number beyond human imagination.
[00:49:59.580 --> 00:50:01.980]   It's a number based on what is called a Planck length,
[00:50:01.980 --> 00:50:03.700]   but it's a number.
[00:50:03.700 --> 00:50:07.540]   And so if a computer could ever simulate that number,
[00:50:07.540 --> 00:50:10.060]   then the universe would be a simulation.
[00:50:10.060 --> 00:50:11.820]   - So theoretically,
[00:50:11.820 --> 00:50:14.780]   because the amount of information is finite,
[00:50:14.780 --> 00:50:19.780]   there necessarily must be able to exist a computer.
[00:50:19.780 --> 00:50:21.860]   It's just, from an engineering perspective,
[00:50:21.860 --> 00:50:24.060]   maybe impossible to build.
[00:50:24.060 --> 00:50:26.920]   - Yes, no computer can build a universe
[00:50:26.920 --> 00:50:29.300]   capable of simulating the entire universe,
[00:50:29.300 --> 00:50:31.020]   except the universe itself.
[00:50:31.020 --> 00:50:32.460]   - So that's your intuition,
[00:50:32.460 --> 00:50:35.340]   that our universe is very efficient,
[00:50:35.340 --> 00:50:37.940]   and so there's no shortcuts.
[00:50:37.940 --> 00:50:39.660]   - Right, two reasons why I believe
[00:50:39.660 --> 00:50:41.340]   the universe is not a simulation.
[00:50:41.340 --> 00:50:44.500]   First, the calculational numbers are just incredible.
[00:50:44.500 --> 00:50:48.340]   No finite Turing machine can simulate the universe.
[00:50:48.340 --> 00:50:52.140]   And second, why would any super intelligent being
[00:50:52.140 --> 00:50:54.380]   simulate humans?
[00:50:54.380 --> 00:50:57.980]   If you think about it, most humans are kind of stupid.
[00:50:57.980 --> 00:51:01.100]   I mean, we do all sorts of crazy, stupid things, right?
[00:51:01.100 --> 00:51:03.900]   And we call it art, we call it humor,
[00:51:03.900 --> 00:51:06.300]   we call it human civilization.
[00:51:06.300 --> 00:51:08.820]   So why should an advanced civilization
[00:51:08.820 --> 00:51:10.340]   go through all that effort
[00:51:10.340 --> 00:51:13.320]   just to simulate a Saturday night live?
[00:51:13.320 --> 00:51:15.420]   - Well, that's a funny idea,
[00:51:15.420 --> 00:51:17.400]   but it's also, do you think it's possible
[00:51:17.400 --> 00:51:22.100]   that the act of creation cannot anticipate humans?
[00:51:22.100 --> 00:51:23.820]   You simply set the initial conditions
[00:51:23.820 --> 00:51:26.020]   and set a bunch of physical laws,
[00:51:26.020 --> 00:51:28.760]   and just for the fun of it, see what happens.
[00:51:28.760 --> 00:51:29.940]   You launch the thing,
[00:51:29.940 --> 00:51:31.700]   so you're not necessarily simulating everything.
[00:51:31.700 --> 00:51:33.860]   You're not simulating every little bit
[00:51:33.860 --> 00:51:37.700]   in the sense that you could predict what's going to happen,
[00:51:37.700 --> 00:51:40.980]   but you set the initial conditions, set the laws,
[00:51:40.980 --> 00:51:43.220]   and see what kind of fun stuff happens.
[00:51:43.220 --> 00:51:46.980]   - Well, in some sense, that's how life got started.
[00:51:46.980 --> 00:51:50.140]   In the 1950s, Stanley did what is called
[00:51:50.140 --> 00:51:51.780]   the Miller experiment.
[00:51:51.780 --> 00:51:55.260]   He put a bunch of hydrogen gas, methane,
[00:51:55.260 --> 00:51:59.980]   toxic gases with liquid and a spark
[00:51:59.980 --> 00:52:02.380]   in a small glass beaker,
[00:52:02.380 --> 00:52:05.100]   and then he just walked away for a few weeks,
[00:52:05.100 --> 00:52:08.480]   came back a few weeks later, and bingo,
[00:52:08.480 --> 00:52:12.820]   out of nothing and chaos came amino acids.
[00:52:12.820 --> 00:52:15.000]   If he had left it there for a few years,
[00:52:15.000 --> 00:52:19.220]   he might've gotten protein, protein molecules for free.
[00:52:19.220 --> 00:52:23.700]   That's probably how life got started, as a accident.
[00:52:23.700 --> 00:52:26.940]   And if he had left it there for perhaps a few million years,
[00:52:26.940 --> 00:52:30.820]   DNA might have formed in that beaker.
[00:52:30.820 --> 00:52:34.100]   And so we think that, yeah, DNA, life, all that
[00:52:34.100 --> 00:52:38.460]   could have been an accident if you wait long enough.
[00:52:38.460 --> 00:52:42.540]   And remember, our universe is roughly 13.8 billion years old.
[00:52:42.540 --> 00:52:46.860]   That's plenty of time for lots of random things to happen,
[00:52:46.860 --> 00:52:49.060]   including life itself.
[00:52:51.380 --> 00:52:56.380]   Yeah, we could be just a beautiful little random moment,
[00:52:56.380 --> 00:53:00.420]   and there could be an infinite number of those
[00:53:00.420 --> 00:53:02.340]   throughout the history of the universe,
[00:53:02.340 --> 00:53:04.700]   many creatures like us.
[00:53:04.700 --> 00:53:06.220]   We perhaps are not the epitome
[00:53:06.220 --> 00:53:08.060]   of what the universe was created for.
[00:53:08.060 --> 00:53:09.940]   - Thank God. (laughs)
[00:53:09.940 --> 00:53:11.660]   Let's hope not. (laughs)
[00:53:11.660 --> 00:53:13.700]   Just look around. - Yeah.
[00:53:13.700 --> 00:53:16.260]   - Look to your left, look to your right.
[00:53:16.260 --> 00:53:20.180]   - When do you think the first human will step foot on Mars?
[00:53:20.180 --> 00:53:23.380]   - I think there's a good chance in the 2030s
[00:53:23.380 --> 00:53:25.380]   that we will be on Mars.
[00:53:25.380 --> 00:53:29.580]   In fact, there's no physics reason why we can't do it.
[00:53:29.580 --> 00:53:31.380]   It's an engineering problem.
[00:53:31.380 --> 00:53:34.580]   It's a very difficult and dangerous engineering problem,
[00:53:34.580 --> 00:53:36.700]   but it is an engineering problem.
[00:53:36.700 --> 00:53:38.660]   And in my book, "Future of Humanity,"
[00:53:38.660 --> 00:53:41.180]   I even speculate beyond that,
[00:53:41.180 --> 00:53:43.300]   that by the end of the century,
[00:53:43.300 --> 00:53:45.820]   we'll probably have the first starships.
[00:53:45.820 --> 00:53:48.220]   The first starships will not look like the Enterprise
[00:53:48.220 --> 00:53:49.180]   at all.
[00:53:49.180 --> 00:53:51.740]   They'll probably be small computer chips
[00:53:51.740 --> 00:53:54.860]   that are fired by laser beams with parachutes.
[00:53:54.860 --> 00:53:58.500]   And like what Stephen Hawking advocated,
[00:53:58.500 --> 00:54:01.540]   the Breakthrough Starshot Program could send ships,
[00:54:01.540 --> 00:54:02.940]   ships to the nearby stars,
[00:54:02.940 --> 00:54:05.460]   traveling at 20% the speed of light,
[00:54:05.460 --> 00:54:09.140]   reaching Alpha Centauri in about 20 years' time.
[00:54:09.140 --> 00:54:12.020]   Beyond that, we should have fusion power.
[00:54:12.020 --> 00:54:15.780]   Fusion power is, in some sense,
[00:54:15.780 --> 00:54:17.980]   one of the ultimate sources of energy,
[00:54:17.980 --> 00:54:19.780]   but it's unstable,
[00:54:19.780 --> 00:54:22.660]   and we don't have fusion power today.
[00:54:22.660 --> 00:54:23.780]   Now, why is that?
[00:54:23.780 --> 00:54:26.260]   First of all, stars form almost for free.
[00:54:26.260 --> 00:54:29.620]   You get a bunch of gas large enough, it becomes a star.
[00:54:29.620 --> 00:54:32.020]   I mean, you don't even have to do anything to it,
[00:54:32.020 --> 00:54:33.540]   and it becomes a star.
[00:54:33.540 --> 00:54:37.460]   Why is fusion so difficult to put on the Earth?
[00:54:37.460 --> 00:54:40.180]   Because in outer space, stars are monopoles.
[00:54:40.180 --> 00:54:42.140]   They are poles, single poles,
[00:54:42.140 --> 00:54:44.780]   that are spherically symmetric,
[00:54:44.780 --> 00:54:46.060]   and it's very easy
[00:54:46.060 --> 00:54:48.940]   to get spherically symmetric configurations of gas
[00:54:48.940 --> 00:54:51.220]   to compress into a star.
[00:54:51.220 --> 00:54:53.820]   It just happens naturally all by itself.
[00:54:53.820 --> 00:54:56.820]   The problem is magnetism is bipolar.
[00:54:56.820 --> 00:54:59.260]   You have a North Pole and a South Pole,
[00:54:59.260 --> 00:55:02.340]   and it's like trying to squeeze a long balloon.
[00:55:02.340 --> 00:55:05.020]   Take a long balloon and try to squeeze it.
[00:55:05.020 --> 00:55:08.260]   You squeeze one side, it bulges out the other side.
[00:55:08.260 --> 00:55:10.580]   Well, that's the problem with fusion machines.
[00:55:10.580 --> 00:55:13.460]   We use magnetism with the North Pole and the South Pole
[00:55:13.460 --> 00:55:17.540]   to squeeze gas, and all sorts of anomalies
[00:55:17.540 --> 00:55:20.260]   and horrible configurations can take place
[00:55:20.260 --> 00:55:23.460]   because we're not squeezing something uniformly,
[00:55:23.460 --> 00:55:24.940]   like in a star.
[00:55:24.940 --> 00:55:27.180]   Stars, in some sense, are for free.
[00:55:27.180 --> 00:55:29.980]   Fusion on the Earth is very difficult.
[00:55:29.980 --> 00:55:32.980]   But I think it's inevitable,
[00:55:32.980 --> 00:55:37.020]   and it'll eventually give us unlimited power from seawater.
[00:55:37.020 --> 00:55:39.900]   So seawater will be the ultimate source of energy
[00:55:39.900 --> 00:55:41.180]   for the planet Earth.
[00:55:41.180 --> 00:55:42.020]   - Why?
[00:55:42.020 --> 00:55:42.860]   What's the intuition there?
[00:55:42.860 --> 00:55:45.540]   - Because we'll extract hydrogen from seawater,
[00:55:45.540 --> 00:55:47.860]   burn hydrogen in a fusion reactor
[00:55:47.860 --> 00:55:52.260]   to give us unlimited energy without the meltdown,
[00:55:52.260 --> 00:55:54.020]   without the nuclear waste.
[00:55:54.020 --> 00:55:55.780]   Why do we have meltdowns?
[00:55:55.780 --> 00:55:57.940]   We have meltdowns because in the fission reactors,
[00:55:57.940 --> 00:55:59.460]   every time you split the uranium atom,
[00:55:59.460 --> 00:56:01.780]   you get nuclear waste, tons of it,
[00:56:01.780 --> 00:56:06.780]   30 tons of nuclear waste per reactor per year.
[00:56:06.780 --> 00:56:08.500]   And it's hot.
[00:56:08.500 --> 00:56:11.260]   It's hot for thousands, millions of years.
[00:56:11.260 --> 00:56:13.260]   That's why we have meltdowns.
[00:56:13.260 --> 00:56:15.700]   But you see, the waste product of a fusion reactor
[00:56:15.700 --> 00:56:17.540]   is helium gas.
[00:56:17.540 --> 00:56:19.940]   Helium gas is actually commercially valuable.
[00:56:19.940 --> 00:56:22.420]   You can make money selling helium gas.
[00:56:22.420 --> 00:56:26.260]   And so the waste product of a fusion reactor is helium,
[00:56:26.260 --> 00:56:30.860]   not nuclear waste that we find in a commercial fission plant.
[00:56:30.860 --> 00:56:34.380]   - And that controlling, mastering and controlling fusion
[00:56:34.380 --> 00:56:38.460]   allows us to, converts us into a type one,
[00:56:38.460 --> 00:56:40.260]   I guess, civilization, right?
[00:56:40.260 --> 00:56:43.340]   - Yeah, probably the backbone of a type one civilization
[00:56:43.340 --> 00:56:45.780]   will be fusion power.
[00:56:45.780 --> 00:56:47.780]   We, by the way, are type zero.
[00:56:47.780 --> 00:56:49.620]   We don't even rate on this scale.
[00:56:49.620 --> 00:56:52.100]   We get our energy from dead plants, for God's sake,
[00:56:52.100 --> 00:56:53.660]   oil and coal.
[00:56:53.660 --> 00:56:56.140]   But we are about 100 years from being type one.
[00:56:56.140 --> 00:56:57.740]   You know, get a calculator.
[00:56:57.740 --> 00:57:01.540]   In fact, Carl Sagan calculated that we are about 0.7,
[00:57:01.540 --> 00:57:05.700]   fairly close to a 1.0.
[00:57:05.700 --> 00:57:08.780]   For example, what is the internet?
[00:57:08.780 --> 00:57:10.860]   The internet is the beginning of the first
[00:57:10.860 --> 00:57:14.140]   type one technology to enter into our century.
[00:57:14.140 --> 00:57:17.460]   The first planetary technology is the internet.
[00:57:17.460 --> 00:57:19.940]   What is the language of type one?
[00:57:19.940 --> 00:57:23.500]   On the internet already, English and Mandarin Chinese
[00:57:23.500 --> 00:57:26.980]   are the most dominant languages on the internet.
[00:57:26.980 --> 00:57:29.420]   And what about the culture?
[00:57:29.420 --> 00:57:34.420]   We're seeing a type one sports, soccer, the Olympics,
[00:57:34.700 --> 00:57:38.980]   a type one music, youth culture, rock and roll, rap music,
[00:57:38.980 --> 00:57:42.940]   type one fashion, Gucci, Chanel, a type one economy,
[00:57:42.940 --> 00:57:45.660]   the European Union, NAFTA, what have you.
[00:57:45.660 --> 00:57:48.580]   So we're beginning to see the beginnings
[00:57:48.580 --> 00:57:52.300]   of a type one culture and a type one civilization.
[00:57:52.300 --> 00:57:56.060]   - And inevitably, it will spread beyond this planet.
[00:57:56.060 --> 00:58:00.780]   So you talked about sending at 20% the speed of light
[00:58:00.780 --> 00:58:03.540]   on a chip into Alpha Centauri.
[00:58:04.380 --> 00:58:07.780]   But in a slightly nearer term,
[00:58:07.780 --> 00:58:08.980]   what do you think about the idea
[00:58:08.980 --> 00:58:13.100]   when we still have to send our biological bodies,
[00:58:13.100 --> 00:58:16.580]   the colonization of planets, colonization of Mars?
[00:58:16.580 --> 00:58:20.580]   Do you see us becoming a two planet species ever
[00:58:20.580 --> 00:58:23.180]   or anytime soon?
[00:58:23.180 --> 00:58:26.380]   - Well, just remember the dinosaurs
[00:58:26.380 --> 00:58:28.660]   did not have a space program.
[00:58:28.660 --> 00:58:30.460]   And that's why they're not here today.
[00:58:30.460 --> 00:58:33.020]   How come there are no dinosaurs in this room today?
[00:58:33.660 --> 00:58:35.940]   Because they didn't have a space program.
[00:58:35.940 --> 00:58:38.060]   We do have a space program,
[00:58:38.060 --> 00:58:40.780]   which means that we have an insurance policy.
[00:58:40.780 --> 00:58:43.060]   Now, I don't think we should bankrupt the Earth
[00:58:43.060 --> 00:58:44.820]   or deplete the Earth to go to Mars.
[00:58:44.820 --> 00:58:47.380]   That's too expensive and not practical.
[00:58:47.380 --> 00:58:50.540]   But we need a settlement, a settlement on Mars
[00:58:50.540 --> 00:58:53.660]   in case something bad happens to the planet Earth.
[00:58:53.660 --> 00:58:56.420]   And that means we have to terraform Mars.
[00:58:56.420 --> 00:58:58.140]   Now, to terraform Mars,
[00:58:58.140 --> 00:59:01.660]   if we could raise the temperature of Mars by six degrees,
[00:59:01.660 --> 00:59:03.580]   six degrees,
[00:59:03.580 --> 00:59:06.060]   then the polar ice caps begin to melt,
[00:59:06.060 --> 00:59:08.500]   releasing water vapor.
[00:59:08.500 --> 00:59:10.620]   Water vapor is the greenhouse gas.
[00:59:10.620 --> 00:59:13.420]   It causes even more melting of the ice caps.
[00:59:13.420 --> 00:59:17.180]   So it becomes a self-fulfilling prophecy.
[00:59:17.180 --> 00:59:18.900]   It feeds on itself.
[00:59:18.900 --> 00:59:21.300]   It becomes autocatalytic.
[00:59:21.300 --> 00:59:23.340]   And so once you hit six degrees,
[00:59:23.340 --> 00:59:26.020]   rising of the temperature on Mars by six degrees,
[00:59:26.020 --> 00:59:27.260]   it takes off.
[00:59:27.260 --> 00:59:29.340]   And we melt the polar ice caps
[00:59:29.340 --> 00:59:33.580]   and liquid water once again flows in the rivers,
[00:59:33.580 --> 00:59:38.460]   the canals, the channels, and the oceans of Mars.
[00:59:38.460 --> 00:59:39.900]   Mars once had an ocean, we think,
[00:59:39.900 --> 00:59:42.140]   about the size of the United States.
[00:59:42.140 --> 00:59:44.300]   And so that is a possibility.
[00:59:44.300 --> 00:59:45.980]   Now, how do we get there?
[00:59:45.980 --> 00:59:48.940]   How do we raise the temperature of Mars by six degrees?
[00:59:48.940 --> 00:59:51.580]   Elon Musk would like to detonate hydrogen warheads
[00:59:51.580 --> 00:59:53.580]   on the polar ice caps.
[00:59:53.580 --> 00:59:55.860]   Well, I'm not sure about that
[00:59:56.860 --> 00:59:59.580]   because we don't know that much about the effects
[00:59:59.580 --> 01:00:03.380]   of detonating hydrogen warheads to melt the polar ice caps.
[01:00:03.380 --> 01:00:05.500]   And who wants to glow in the dark at night
[01:00:05.500 --> 01:00:07.140]   reading the newspaper?
[01:00:07.140 --> 01:00:09.460]   So I think there are other ways to do it
[01:00:09.460 --> 01:00:11.900]   with solar satellites.
[01:00:11.900 --> 01:00:13.820]   You can have satellites orbiting Mars
[01:00:13.820 --> 01:00:17.620]   that beam sunlight onto the polar ice caps,
[01:00:17.620 --> 01:00:19.380]   melting the polar ice caps.
[01:00:19.380 --> 01:00:21.340]   Mars has plenty of water.
[01:00:21.340 --> 01:00:22.900]   It's just frozen.
[01:00:24.100 --> 01:00:26.540]   - I think you paint an inspiring
[01:00:26.540 --> 01:00:28.860]   and a wonderful picture of the future.
[01:00:28.860 --> 01:00:33.860]   I think you've inspired and educated
[01:00:33.860 --> 01:00:36.140]   thousands, if not millions.
[01:00:36.140 --> 01:00:37.340]   Michio, it's been an honor.
[01:00:37.340 --> 01:00:38.940]   Thank you so much for talking today.
[01:00:38.940 --> 01:00:39.780]   - My pleasure.
[01:00:39.820 --> 01:00:42.420]   (upbeat music)
[01:00:42.420 --> 01:00:45.020]   (upbeat music)
[01:00:45.020 --> 01:00:47.620]   (upbeat music)
[01:00:47.620 --> 01:00:50.220]   (upbeat music)
[01:00:50.220 --> 01:00:52.820]   (upbeat music)
[01:00:52.820 --> 01:00:55.420]   (upbeat music)
[01:00:55.420 --> 01:01:05.420]   [BLANK_AUDIO]

