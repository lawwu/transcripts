
[00:00:00.000 --> 00:00:01.160]   Right.
[00:00:01.160 --> 00:00:05.360]   We already have 30 participants who are waiting. Hello, everyone.
[00:00:05.360 --> 00:00:07.920]   We will just start in a few minutes. I'll let people join
[00:00:07.920 --> 00:00:10.440]   in. But please tell us where you're from. Say hello to
[00:00:10.440 --> 00:00:13.560]   Thomas. He's been very kind to join us. If you don't know,
[00:00:13.560 --> 00:00:16.320]   Thomas has written the book literally that he'll be reading.
[00:00:16.320 --> 00:00:21.520]   So I don't I can't think of a better way to kick off a reading
[00:00:21.520 --> 00:00:21.800]   group.
[00:00:21.800 --> 00:00:26.120]   Thanks.
[00:00:26.120 --> 00:00:33.120]   I'll just start in a minute. People are still joining.
[00:00:52.760 --> 00:00:56.240]   Yes, Mathew, we've disabled the chat. I'll quickly point out
[00:00:56.240 --> 00:00:59.920]   we'll be using the forum since I'll elaborate on this a bit.
[00:00:59.920 --> 00:01:02.200]   But people who watch the recording get annoyed because
[00:01:02.200 --> 00:01:04.200]   they can't tell what we're talking about. So we'll be using
[00:01:04.200 --> 00:01:07.000]   the forums instead. I'll share the link to that in a minute.
[00:01:07.000 --> 00:01:12.280]   Awesome, I think we can get started.
[00:01:12.280 --> 00:01:20.640]   So welcome, everyone will be reading the Pytorch for deep
[00:01:20.640 --> 00:01:25.280]   learning with Pytorch book. This is by Eli Stevens, Luca
[00:01:25.280 --> 00:01:28.880]   Antigua and Thomas Freeman. Thomas is in the call and he'll
[00:01:28.880 --> 00:01:33.080]   be teaching us about how to make the most out of the Pytorch
[00:01:33.080 --> 00:01:38.480]   community resources. We're very grateful to have him. It's rare
[00:01:38.480 --> 00:01:42.720]   to start a book reading with with the author. I'll quickly
[00:01:42.720 --> 00:01:46.240]   talk about the agenda, introduce Thomas and then hand it over to
[00:01:46.240 --> 00:01:47.960]   Thomas to be respectful of his time.
[00:01:47.960 --> 00:01:55.960]   So Thomas is the founder of math and inference. Am I saying
[00:01:55.960 --> 00:01:57.000]   that correctly, Thomas?
[00:01:57.000 --> 00:01:59.800]   Yeah.
[00:01:59.800 --> 00:02:03.800]   And he's the co author of the book. Like I mentioned, Thomas
[00:02:03.800 --> 00:02:07.640]   is also a Pytorch co developer. On his website, it says he's a
[00:02:07.640 --> 00:02:10.520]   retired co developer, but I'm sure we'll get to learn a lot
[00:02:10.520 --> 00:02:15.400]   from him. He's Thomas Freeman on Twitter. I would say I would
[00:02:15.400 --> 00:02:18.840]   highly recommend that you follow him because you can get a lot of
[00:02:18.840 --> 00:02:23.200]   Pytorch wisdom from there. Thanks. Thanks again, Thomas,
[00:02:23.200 --> 00:02:23.880]   for joining.
[00:02:23.880 --> 00:02:29.560]   Yeah, thanks for having me. It's such a pleasure.
[00:02:29.560 --> 00:02:33.440]   Super, super excited to dive into this. As you can see, I'm
[00:02:33.440 --> 00:02:36.840]   a little nervous. I'm fumbling with my slides. Hopefully the
[00:02:36.840 --> 00:02:39.480]   nerves will calm down. I was as nervous when I got to interview
[00:02:39.480 --> 00:02:42.920]   as well. So I'm hoping it'll come down in a second as I sip
[00:02:42.920 --> 00:02:46.240]   my tea. So quickly for the audience for the questions, we'll
[00:02:46.240 --> 00:02:50.000]   be using the discourse forums of our community. So if you go on
[00:02:50.000 --> 00:02:54.840]   this link, it should take you here. And you can find all of
[00:02:54.840 --> 00:02:57.040]   the resources here. You can connect with Thomas, you can
[00:02:57.040 --> 00:03:01.000]   find this website, you can purchase the book. And you can
[00:03:01.000 --> 00:03:04.360]   also find my interview with Thomas and the co authors, I
[00:03:04.360 --> 00:03:06.600]   would recommend you read the book instead, because you can
[00:03:06.600 --> 00:03:10.120]   learn much more doing that. If you want to ask questions, you
[00:03:10.120 --> 00:03:20.280]   can just reply here and post them here you can like each
[00:03:20.280 --> 00:03:24.280]   other's questions. The my friends and Manning publication
[00:03:24.280 --> 00:03:28.480]   has sent over one free copy. So the most liked question from
[00:03:28.480 --> 00:03:32.000]   today's session will be getting a free copy. That's an incentive
[00:03:32.000 --> 00:03:34.880]   for you to use this time and really ask questions to Thomas.
[00:03:34.880 --> 00:03:38.960]   So we really want you to make the most of this opportunity.
[00:03:39.960 --> 00:03:43.280]   With that, I'd like to hand it over to Thomas and to us later
[00:03:43.280 --> 00:03:44.840]   and we'll dive into the Q&A.
[00:03:44.840 --> 00:03:53.760]   Okay, so thanks for having me again. And thanks for joining us
[00:03:53.760 --> 00:04:01.120]   here today. It's a it's a really, really great honor. And
[00:04:04.480 --> 00:04:10.080]   yeah, and during practice, it worked to share my screen. And
[00:04:10.080 --> 00:04:13.920]   no, it doesn't. Yeah, I'll try and
[00:04:13.920 --> 00:04:15.080]   we can
[00:04:15.080 --> 00:04:16.720]   no one will learn.
[00:04:16.720 --> 00:04:23.120]   So I know more about Pytorch than sharing my screen. I
[00:04:23.120 --> 00:04:26.000]   promise. Can you see it now?
[00:04:26.000 --> 00:04:28.160]   Yes, yes.
[00:04:28.280 --> 00:04:34.920]   Okay, so, okay, so you already know the book. And in
[00:04:34.920 --> 00:04:39.040]   particular, I'm very, very honored that people took the
[00:04:39.040 --> 00:04:45.360]   time to translate it into Japanese and Chinese. And so
[00:04:45.360 --> 00:04:49.200]   here's something about me that you may know or may not know.
[00:04:49.200 --> 00:04:55.800]   I'm a mathematician by training. I have a PhD in paper
[00:04:55.800 --> 00:05:01.640]   analysis. Keep that in mind when you are looking for at the
[00:05:01.640 --> 00:05:07.000]   formulas in the book. I used to be a Debian developer a long
[00:05:07.000 --> 00:05:11.400]   time ago. And every now and then I managed to send a patch to
[00:05:11.400 --> 00:05:12.440]   LibreOffice.
[00:05:12.440 --> 00:05:21.120]   Centum already mentioned the company I founded a few years
[00:05:21.120 --> 00:05:28.640]   ago. And even earlier, I sent my first Pytorch PR. And that was
[00:05:28.640 --> 00:05:35.080]   four years ago. And now there's, I don't know, 150 features and
[00:05:35.080 --> 00:05:40.440]   bug fixes, and probably some bugs that I sent there. And it's
[00:05:40.440 --> 00:05:43.880]   all over the place from Kudakernels for batch norm and
[00:05:43.880 --> 00:05:51.360]   CTC loss to IonZone and parts of the original JIT fuser. More
[00:05:51.360 --> 00:05:56.920]   recently, I've been developing with my friends and aerobics
[00:05:56.920 --> 00:06:01.680]   with Luca Antiga, who also is one of the co authors. We've
[00:06:01.680 --> 00:06:07.200]   wrote a library TorchDrift that helps detect data drift in
[00:06:07.200 --> 00:06:12.520]   deployment setups. And I was particularly, I'm particularly
[00:06:12.520 --> 00:06:18.960]   fond of that because it got me develop new hypothesis tests. So
[00:06:18.960 --> 00:06:25.160]   I've been back to some pen and paper mathematics too. And,
[00:06:25.160 --> 00:06:30.720]   yeah, I used to do in person training workshops. But yeah,
[00:06:30.720 --> 00:06:35.320]   COVID wrecked that. And then recently, I started my first
[00:06:35.320 --> 00:06:41.520]   online course, which I'm very excited about. Writing, Sanyam
[00:06:41.560 --> 00:06:46.280]   already mentioned it. I, in addition to the book, I keep a
[00:06:46.280 --> 00:06:53.920]   blog, this address, learnupperup.de. Yeah, so enough
[00:06:53.920 --> 00:06:58.400]   about me. I'll say something about how we wrote the book and
[00:06:58.400 --> 00:07:03.000]   something how I look at the book. I'll try to keep it short
[00:07:03.000 --> 00:07:07.720]   to not bore you. But one of the great things about deep learning
[00:07:07.720 --> 00:07:11.760]   to me is that it greatly reduces the amount of programming for
[00:07:11.760 --> 00:07:16.040]   any given task, because you basically use data and the data
[00:07:16.040 --> 00:07:23.360]   will guide how the model works. And I hope you enjoy the book.
[00:07:23.360 --> 00:07:27.600]   From that angle too, even if you haven't been programming that
[00:07:27.600 --> 00:07:33.000]   much, I think it's a very accessible topic. Unless we
[00:07:33.000 --> 00:07:37.640]   scrolled it up in writing the book. And the book was started
[00:07:37.640 --> 00:07:42.000]   by the other two co-authors, Eli Stevens and Luca Antiga. And I
[00:07:42.000 --> 00:07:47.360]   joined a bit later, after joking about a fictional PyTorch book
[00:07:47.360 --> 00:07:53.400]   that I was going to write with Peter Piotr Bialecki, who is of
[00:07:53.400 --> 00:07:58.800]   course, the person with all the good answers on the PyTorch
[00:07:58.800 --> 00:08:05.640]   forums. Yeah, and it's great that you have the reading group.
[00:08:05.640 --> 00:08:10.280]   If people can learn deep learning, I think it's something
[00:08:10.280 --> 00:08:14.640]   that's hugely important. And that will only get better if
[00:08:14.640 --> 00:08:21.080]   many people can have insights about how things work, because
[00:08:21.080 --> 00:08:27.880]   increasingly it influences how our world works too. My personal
[00:08:27.880 --> 00:08:33.280]   philosophy about our book, and this is all my personal take,
[00:08:33.280 --> 00:08:40.400]   and it's not from the co-authors or publishers or so. We try to
[00:08:40.400 --> 00:08:44.760]   present intuition first, and we work very, very hard for that.
[00:08:44.760 --> 00:08:49.640]   We don't have many formulas, but don't take that for an absence
[00:08:49.640 --> 00:08:53.720]   of maths, because usually you have formulas to make the
[00:08:53.720 --> 00:08:59.000]   intuitions precise. And for us, we try to make it precise
[00:08:59.000 --> 00:09:03.440]   through code and save on the formulas through that. I firmly
[00:09:03.440 --> 00:09:08.080]   believe that you can only get better models through more and
[00:09:08.080 --> 00:09:14.480]   more creative mathematics. And there will be things you disagree
[00:09:14.480 --> 00:09:18.480]   with, and that's okay. We try to distinguish between opinion and
[00:09:18.480 --> 00:09:23.360]   style guides and facts. So I don't necessarily want to
[00:09:23.360 --> 00:09:28.720]   undermine batch norm. And if you see the slides, there's a
[00:09:28.720 --> 00:09:35.360]   closed issue report in the book's source code repository.
[00:09:35.360 --> 00:09:42.640]   Yeah, the second part is if you want to embark on a new problem,
[00:09:42.640 --> 00:09:47.160]   one of the things about our book is that it covers one topic in
[00:09:47.160 --> 00:09:55.160]   great detail. So we only do conf nets of our own sorts. If you
[00:09:55.160 --> 00:10:00.000]   want to approach something, a different task, I can warmly
[00:10:00.000 --> 00:10:04.240]   recommend following a structure in your exploration that is
[00:10:04.240 --> 00:10:08.520]   similar to part one. And that is think about the nature of the
[00:10:08.520 --> 00:10:14.160]   data and the data representation first. Then consider the
[00:10:14.160 --> 00:10:18.400]   objectives and metrics for success and loss functions as a
[00:10:18.400 --> 00:10:23.320]   proxy for that. And only then you deal with models and
[00:10:23.320 --> 00:10:28.360]   architectures. At least that would be my advice to get a
[00:10:28.360 --> 00:10:32.680]   structured approach to learning and execution. In particular,
[00:10:32.680 --> 00:10:37.720]   only when you have objectives and measures for success and loss
[00:10:37.720 --> 00:10:41.880]   functions, you can have a structured approach to see what
[00:10:41.880 --> 00:10:47.000]   things work better or not as well. In part two, we show you
[00:10:47.000 --> 00:10:51.120]   some bumps and remedies. And the idea is that you have some idea
[00:10:51.120 --> 00:10:56.280]   when you hit your own problem in your own, own task. And then
[00:10:56.280 --> 00:11:00.560]   you know that, well, yeah, you're not the only one getting
[00:11:00.560 --> 00:11:05.680]   these and maybe you have some ideas. Okay, but I wanted to
[00:11:05.680 --> 00:11:11.160]   talk about community really. I want to share four thoughts on
[00:11:11.160 --> 00:11:17.120]   community with you before I dive into the resources. And so one
[00:11:17.120 --> 00:11:23.240]   thing is community is something with an exchange of things. And
[00:11:23.240 --> 00:11:26.680]   of course, there's developer relations work, and we love the
[00:11:26.680 --> 00:11:33.120]   work that companies put in. And obviously, Weights & Biases
[00:11:33.760 --> 00:11:42.640]   sponsors the reading group. But yeah, it's something where
[00:11:42.640 --> 00:11:46.960]   people obviously put in some work, and they get something out
[00:11:46.960 --> 00:11:51.320]   of it. And while it's not an accounting exercise, you owe me
[00:11:51.320 --> 00:11:57.160]   three answers, because I answered three things. Keep in
[00:11:57.160 --> 00:12:03.040]   mind that it is something that's kind of communal. And at the
[00:12:03.040 --> 00:12:06.080]   same time, we all start by needing more input than we
[00:12:06.080 --> 00:12:11.640]   contribute at first. And I was lucky to have Adam Paszka guide
[00:12:11.640 --> 00:12:16.720]   me through the first few PRs that I sent to PyTorch. And
[00:12:16.720 --> 00:12:23.960]   that's perfectly okay to need input to. I also add that
[00:12:23.960 --> 00:12:30.240]   community is not a service. And so some people help out as part
[00:12:30.240 --> 00:12:35.600]   of the job, but some of them only for their pleasure to. And
[00:12:35.600 --> 00:12:39.880]   they always like the appreciation you can offer for
[00:12:39.880 --> 00:12:44.200]   them helping you. And the people that do that as part of their
[00:12:44.200 --> 00:12:49.960]   job too. And when you contribute yourself, know why and how much
[00:12:49.960 --> 00:12:54.880]   you want to contribute, i.e. have a limit. And to me, that's
[00:12:54.880 --> 00:12:58.160]   very important, because otherwise you hit some burnout
[00:12:58.160 --> 00:13:02.600]   thing, and there will be a negative dynamics for it. And in
[00:13:02.600 --> 00:13:07.120]   a similar vein, don't burden yourself by obligation, by a
[00:13:07.120 --> 00:13:10.560]   sense of obligation that you create for yourself or by people
[00:13:10.560 --> 00:13:16.600]   demanding things if you're only doing this as a volunteer. Yeah,
[00:13:16.600 --> 00:13:22.040]   community resources are best used wisely. So when you ask
[00:13:22.040 --> 00:13:25.600]   questions on the PyTorch forums, and I really recommend these, it
[00:13:25.600 --> 00:13:31.200]   will be in a minute. Try to think about the question, give
[00:13:31.200 --> 00:13:34.600]   some context, maybe a code snippet to make good use of
[00:13:34.600 --> 00:13:38.480]   people's time. So for example, when I answer questions on the
[00:13:38.480 --> 00:13:45.160]   PyTorch forums, I tend to run if there's a code snippet that I
[00:13:45.160 --> 00:13:50.880]   can just paste into Jupyter and run, I'm 10 times more likely to
[00:13:50.880 --> 00:13:56.280]   actually answer. But at the same time, don't be afraid to ask,
[00:13:56.280 --> 00:13:59.960]   there are no stupid questions, right? Or at least every one of
[00:13:59.960 --> 00:14:04.440]   us has asked questions where in hindsight, yeah, I should have
[00:14:04.440 --> 00:14:10.600]   known. But yeah, you can ask to it's perfectly okay. As long as
[00:14:10.600 --> 00:14:13.960]   you don't dominate the forum. If you send like 50 questions in
[00:14:13.960 --> 00:14:19.120]   one hour, then something is not going well. And of course,
[00:14:19.120 --> 00:14:22.640]   community is about people keep it fun for you keep it fun for
[00:14:22.640 --> 00:14:29.840]   others. And my personal favorite tip about making best use of
[00:14:29.840 --> 00:14:35.680]   community is also, I mean, you relate to a lot of people. But
[00:14:35.680 --> 00:14:40.280]   also, if you find someone you'd like to hang out with, even if
[00:14:40.280 --> 00:14:45.160]   it's only online, or to reflect, if you think you want to talk
[00:14:45.160 --> 00:14:49.480]   about something that you think is not so good, and in the wider
[00:14:49.480 --> 00:14:56.560]   community, it's really good if you have like, one or two online
[00:14:56.560 --> 00:15:01.560]   bodies that you have a very good relation, relation with and
[00:15:01.560 --> 00:15:08.520]   I've been very lucky to, to find a few of these very special to
[00:15:08.520 --> 00:15:13.320]   me people in the PyTorch community. I always say I came
[00:15:13.320 --> 00:15:17.760]   for the code and I stayed for the community. Okay, so enough
[00:15:17.760 --> 00:15:23.160]   theory, and I promised to show some community resources. And
[00:15:23.160 --> 00:15:26.400]   this will not be a complete list, just the bits that I'm
[00:15:26.400 --> 00:15:31.680]   aware about, and that I use quite a bit. And so first,
[00:15:31.680 --> 00:15:35.240]   there's the reading group. And reading things with a group is
[00:15:35.240 --> 00:15:39.680]   always nice, because it's easier to keep going and discuss
[00:15:39.680 --> 00:15:42.960]   things where you have questions where you disagree with things.
[00:15:43.400 --> 00:15:47.520]   There might be errors in the book, and people have ideas for
[00:15:47.520 --> 00:15:52.320]   going further and deeper. But obviously, Sanyam is a much
[00:15:52.320 --> 00:15:59.560]   better expert than me on this. Okay, then there's the PyTorch
[00:15:59.560 --> 00:16:04.240]   tutorials. And one thing to know is they come in two different
[00:16:04.240 --> 00:16:08.760]   flavors. Some present an application or a technique like
[00:16:08.760 --> 00:16:13.920]   fine tuning, or fine tuning for images and some introduce a part
[00:16:13.920 --> 00:16:18.600]   of the library, for example, quantization functions are
[00:16:18.600 --> 00:16:21.760]   introduced more than quantization the technique is
[00:16:21.760 --> 00:16:25.520]   introduced. And that makes a subtle difference. But depending
[00:16:25.520 --> 00:16:30.600]   on what you're looking for. That's cool. These tutorials are
[00:16:30.600 --> 00:16:34.520]   typically crisp to their purpose, and not overdoing
[00:16:34.520 --> 00:16:41.120]   contextualizing what they do like background, whether it also
[00:16:41.120 --> 00:16:44.600]   applies to other tasks. And this has advantages and
[00:16:44.600 --> 00:16:49.800]   disadvantages, depending on how you look at it. They're probably
[00:16:49.800 --> 00:16:53.760]   a good reference point when you ask questions, because you have
[00:16:53.760 --> 00:16:58.520]   code snippets that you can talk to. And they can have bugs too,
[00:16:58.520 --> 00:17:06.240]   of course. There was a famous hiccup some a few months ago,
[00:17:06.240 --> 00:17:11.920]   where people ran into trouble with using NumPy random
[00:17:11.920 --> 00:17:18.920]   functions inside data sets. And one of the PyTorch tutorials
[00:17:18.920 --> 00:17:25.760]   has that too. But yeah, code has bugs. The next stop for me and I
[00:17:25.760 --> 00:17:33.200]   use that a lot too, is discuss PyTorch org. And in my
[00:17:33.200 --> 00:17:38.000]   experience for PyTorch questions, you universally get
[00:17:38.000 --> 00:17:44.000]   great answers, unless you're unlucky and I answer. And so
[00:17:44.000 --> 00:17:48.200]   three people that particularly contributed many, many, many
[00:17:48.200 --> 00:17:54.440]   insightful answers in the last three months are Eddie Yang and
[00:17:54.480 --> 00:17:58.160]   Kay Frank, who I don't know the first name of, and of course,
[00:17:58.160 --> 00:18:07.120]   Piotr. And they both had, all three had like three or even
[00:18:07.120 --> 00:18:12.840]   four-figure number of answers in just three months. You get best
[00:18:12.840 --> 00:18:15.480]   answers if you have a simple code snippet, I already
[00:18:15.480 --> 00:18:19.440]   mentioned that. And it's also a nice place to share if you have
[00:18:19.440 --> 00:18:25.720]   built something relating to PyTorch. Yeah, I can, I think
[00:18:25.720 --> 00:18:31.040]   this was my primary discussion for one thing is sharing your
[00:18:31.040 --> 00:18:35.400]   own things. If you build and share fun things, and if it's
[00:18:35.400 --> 00:18:39.320]   code and description of how you made it, what you learned, it's
[00:18:39.320 --> 00:18:44.040]   even more appreciated. And you have better ideas than me, but
[00:18:44.040 --> 00:18:47.680]   you could generate things with a gun and some new type of data,
[00:18:48.080 --> 00:18:53.160]   show something completely new, like gardening neural networks
[00:18:53.160 --> 00:18:57.160]   were a thing a while back, and now we're starting to see
[00:18:57.160 --> 00:19:02.040]   commercial products and explain things better than we do in the
[00:19:02.040 --> 00:19:08.400]   book, probably works for some bits too. But there's any number
[00:19:08.400 --> 00:19:15.920]   of ideas you might have. For the, if you, and I'm going into
[00:19:15.960 --> 00:19:20.920]   a bit more advanced things over time here. And so reading the
[00:19:20.920 --> 00:19:27.560]   source code can be a really good resource too. And so if you
[00:19:27.560 --> 00:19:29.880]   find something that's interesting, and you want to
[00:19:29.880 --> 00:19:33.320]   find out what's going on under the hood, look at cold stacks
[00:19:33.320 --> 00:19:36.960]   and the debugger and see where all the functions are defined.
[00:19:36.960 --> 00:19:40.760]   For example, what happens if you call a given PyTorch function,
[00:19:40.840 --> 00:19:46.120]   right? If you call, like use the app operator for matrix
[00:19:46.120 --> 00:19:51.680]   multiplication, what actually runs the matrix multiplication.
[00:19:51.680 --> 00:19:58.240]   And so there's an oldie but goldie from me. And I made
[00:19:58.240 --> 00:20:02.640]   something more recently that looks at TorchScript functions
[00:20:02.640 --> 00:20:08.600]   in particular, and goes through the JIT runtime for this. And
[00:20:08.640 --> 00:20:14.280]   just today I saw this blog post, a public dissection of the
[00:20:14.280 --> 00:20:21.600]   PyTorch training step by Charles Fry. And I thought that was a
[00:20:21.600 --> 00:20:30.640]   really neat, neat blog post too. Okay, and finally, and this is
[00:20:30.640 --> 00:20:34.680]   something if you want to contribute back, I think
[00:20:34.800 --> 00:20:38.920]   answering question also helps. But of course, when you find a
[00:20:38.920 --> 00:20:41.560]   bug and something that's not quite working, where I
[00:20:41.560 --> 00:20:48.600]   submitting features of bug fixes to PyTorch is a good or one of
[00:20:48.600 --> 00:20:54.600]   the other repos is a good option too. You might ask on the
[00:20:54.600 --> 00:20:59.040]   forums whether that's really a bug you see before providing
[00:20:59.040 --> 00:21:02.320]   the patch and then you get explained that that wasn't
[00:21:02.320 --> 00:21:06.720]   really a bug but intended behavior happened to me a few
[00:21:06.720 --> 00:21:12.080]   times too. So I mentioned it here. And there is, and if you
[00:21:12.080 --> 00:21:15.920]   contribute to one of the other repositories like TorchVision,
[00:21:15.920 --> 00:21:22.280]   TorchAudio, etc, or the examples of tutorials, this can be like
[00:21:22.280 --> 00:21:27.440]   easier just to build and run tests in PyTorch is a bit
[00:21:27.440 --> 00:21:36.320]   tricky, but they have a great document detailing it. But be
[00:21:36.320 --> 00:21:42.320]   prepared unless you have a very recent computer. Building PyTorch
[00:21:42.320 --> 00:21:47.160]   takes quite a while. And this limited my enthusiasm for a while
[00:21:47.160 --> 00:21:53.680]   until I got a new computer. There's an oldest video that
[00:21:53.720 --> 00:21:58.920]   where I show in one hour, I think fixing one PyTorch bug. If
[00:21:58.920 --> 00:22:03.800]   you enjoy this kind of video, you can look at it. Okay, again,
[00:22:03.800 --> 00:22:08.360]   there's many, many, many more resources. But these are my
[00:22:08.360 --> 00:22:12.640]   personal highlights. And of course, if you're on the forums,
[00:22:12.640 --> 00:22:20.440]   you will find more and it's also neat to share the things that
[00:22:20.440 --> 00:22:26.920]   you like with your friends. Okay, so that's what I have
[00:22:26.920 --> 00:22:31.960]   prepared. But obviously, now there's the freestyle. And
[00:22:31.960 --> 00:22:38.000]   again, thanks for having me. Thanks for enjoying. Thanks for
[00:22:38.000 --> 00:22:44.000]   doing this reading group. And now we can we can have some
[00:22:44.000 --> 00:22:49.080]   questions and I'll stop sharing the screen and go back to the
[00:22:49.080 --> 00:22:50.920]   video. Thanks.
[00:22:50.920 --> 00:22:55.120]   Thanks, Thomas. Sorry, please go ahead.
[00:22:55.120 --> 00:22:57.880]   No, no, I wanted to hand back to you.
[00:22:57.880 --> 00:23:02.360]   Thank you. I was going to say, I really loved you came there for
[00:23:02.360 --> 00:23:04.560]   the code and you stayed for the community. It's been my
[00:23:04.560 --> 00:23:07.720]   experience. Although I have just oriented myself to the
[00:23:07.720 --> 00:23:11.600]   community more or less. But it's such a wonderful feeling to
[00:23:11.600 --> 00:23:15.720]   learn with people together. And I've made all of these friends.
[00:23:15.720 --> 00:23:18.680]   I had the chance to know you through zoom when I interviewed
[00:23:18.680 --> 00:23:22.800]   you. And the community is just such a wonderful place. In my
[00:23:22.800 --> 00:23:26.160]   experience, people are really, really nice. And they're really
[00:23:26.160 --> 00:23:29.320]   open to sharing knowledge just like you are. So I really love
[00:23:29.320 --> 00:23:29.960]   that comment.
[00:23:29.960 --> 00:23:38.920]   Right. And obviously, I have lots of good friends. Made lots
[00:23:38.920 --> 00:23:44.000]   of good friends. And that's really what what keeps me doing
[00:23:44.000 --> 00:23:46.120]   doing these things too.
[00:23:47.680 --> 00:23:51.480]   So we've launched the forums a week ago. And this is the most
[00:23:51.480 --> 00:23:55.240]   we've ever seen them. But before we go to the questions, I just
[00:23:55.240 --> 00:23:58.680]   I'll greedily use this time and ask my questions to you first.
[00:23:58.680 --> 00:24:03.440]   So usually when we start or like any beginner starts on the
[00:24:03.440 --> 00:24:07.000]   project, they go to repository, maybe they're able to install
[00:24:07.000 --> 00:24:09.720]   it, maybe they're able to do something. Do you have any
[00:24:09.720 --> 00:24:12.640]   thoughts on how can someone contribute to Pytorch? Because
[00:24:12.640 --> 00:24:16.640]   it's such a daunting task to be able to give back, assuming
[00:24:16.640 --> 00:24:17.920]   it's of interest to someone?
[00:24:17.920 --> 00:24:25.400]   Well, so there's a there's a few ways. And really, the first
[00:24:25.400 --> 00:24:34.920]   thing I'd mention is that there are there are there are bugs.
[00:24:34.920 --> 00:24:37.840]   If you look through the Pytorch bugs, there's an arbitrary
[00:24:37.840 --> 00:24:42.120]   number of them open, if you want to pick one that's already
[00:24:42.120 --> 00:24:45.360]   existing. And there will be bugs that are labeled like
[00:24:45.400 --> 00:24:50.120]   beginner friendly or bootcamp or something like that. And maybe
[00:24:50.120 --> 00:24:54.200]   these are good to work on. The other way would be if you
[00:24:54.200 --> 00:24:57.920]   observe something, right? If you do something with Pytorch, and
[00:24:57.920 --> 00:25:01.400]   something doesn't quite work, right. And that would be a good
[00:25:01.400 --> 00:25:04.880]   starting point, too, because ultimately, this is something
[00:25:04.880 --> 00:25:10.160]   that interests you, right? Because you put a lot of work
[00:25:10.160 --> 00:25:12.720]   eventually. But yeah,
[00:25:13.520 --> 00:25:16.600]   my contribution in that there would be opening up an issue
[00:25:16.600 --> 00:25:19.840]   where the ampere cards weren't supported yet. I got a few
[00:25:19.840 --> 00:25:22.320]   ampere cards, and I was just complaining, please support
[00:25:22.320 --> 00:25:25.440]   them. I can't run on full speed. I don't think that.
[00:25:25.440 --> 00:25:36.320]   Well, I mean, a well done bug report is worth quite a lot,
[00:25:36.320 --> 00:25:40.760]   too. So for example, if you if you observe something that isn't
[00:25:40.760 --> 00:25:45.080]   quite right, and you narrow it down to like just one Pytorch
[00:25:45.080 --> 00:25:51.240]   function call with particular tensors, that usually is that
[00:25:51.240 --> 00:25:58.200]   can be like 80% of the work of fixing the bug, right. And so
[00:25:58.200 --> 00:26:06.160]   really, I mean, I like to also send code. And when I say we I
[00:26:06.160 --> 00:26:11.160]   do a lot of Pytorch, I say I have done Android 50 PRs. But
[00:26:11.160 --> 00:26:16.040]   but all means PRs aren't the only only thing to do, right.
[00:26:16.040 --> 00:26:22.480]   Do you have any suggestions? So as we go through the book, I'm
[00:26:22.480 --> 00:26:25.480]   just curious, what is your development setup like? Because
[00:26:25.480 --> 00:26:29.400]   many of us, at least I remember myself struggling a lot with the
[00:26:29.400 --> 00:26:33.280]   server setups and everything. Any tips for us as we go through
[00:26:33.280 --> 00:26:33.680]   this?
[00:26:33.800 --> 00:26:41.600]   Yeah, I do all my stuff in Jupyter notebooks, if I can. And
[00:26:41.600 --> 00:26:51.400]   I can really recommend that, too. As a thing, I used to
[00:26:51.400 --> 00:26:56.560]   patch Jupyter to, to allow me to reconnect to long running training
[00:26:56.560 --> 00:27:01.640]   jobs. But I'm not sure whether it's still needed at all. I
[00:27:01.640 --> 00:27:11.400]   think the it now works out of the box. But, but so really, I
[00:27:11.400 --> 00:27:17.480]   like this tinkering. And like, if you if you have an example
[00:27:17.480 --> 00:27:22.240]   where you have a data loader, or if you have a well in the book,
[00:27:22.240 --> 00:27:26.120]   we have notebooks that really start from from scratch a lot,
[00:27:26.120 --> 00:27:30.280]   right. But if you if you have intermediate variables, for
[00:27:30.280 --> 00:27:34.920]   example, go look at them, and print them and stuff. And I
[00:27:34.920 --> 00:27:41.560]   really like, like this Jupyter notebooks as an advanced method
[00:27:41.560 --> 00:27:43.440]   of print debugging.
[00:27:43.440 --> 00:27:49.800]   Yeah, the the even the debugger works really nicely in a way. I
[00:27:49.800 --> 00:27:52.920]   like it just because also as an excuse, I don't have to learn
[00:27:52.920 --> 00:27:57.640]   Vim on don't have to settle for VS code. And then I can access
[00:27:57.640 --> 00:28:01.360]   to any server. So minor silly reasons, but I'm also a fan of
[00:28:01.360 --> 00:28:02.760]   Jupyter really.
[00:28:02.760 --> 00:28:04.360]   Right.
[00:28:04.360 --> 00:28:08.600]   Awesome. I'll quickly share my screen and we can start going
[00:28:08.600 --> 00:28:10.800]   to the questions. I don't want to be too greedy with just
[00:28:10.800 --> 00:28:13.920]   asking mine. I'll quickly point out a few things to everyone in
[00:28:13.920 --> 00:28:19.640]   the call. So this is the first special session since Thomas was
[00:28:19.640 --> 00:28:22.560]   kind enough to join us, we might end a little early today. But
[00:28:22.560 --> 00:28:27.620]   starting this Sunday, we'll meet every Sunday at 8am Pacific for
[00:28:27.620 --> 00:28:31.960]   one and a half hour. It can be paced along the books. And I'll
[00:28:31.960 --> 00:28:35.280]   try to do some walkthroughs of different examples and
[00:28:35.280 --> 00:28:38.720]   exercises, maybe also figure out how to integrate a few Kaggle
[00:28:38.720 --> 00:28:42.160]   competitions for all of us to enjoy. So please stay tuned for
[00:28:42.160 --> 00:28:45.600]   that. You don't need to sign up separately. If you're in this
[00:28:45.600 --> 00:28:49.720]   zoom call, you will send your invite by default. If not,
[00:28:49.720 --> 00:28:53.680]   please feel free to share this link. There's no paywall. We're
[00:28:53.680 --> 00:28:57.360]   all here to learn honestly, just from this fantastic book. And
[00:28:57.740 --> 00:29:01.100]   I'm giving a little teaser, but we'll have at least as of now
[00:29:01.100 --> 00:29:04.540]   five guest session with PyTorch developers who've been working
[00:29:04.540 --> 00:29:11.620]   on different frameworks. So I'm pretty excited about that. I'll
[00:29:11.620 --> 00:29:14.900]   also quickly mention the forums that Thomas had mentioned. So
[00:29:14.900 --> 00:29:20.700]   discuss.pytorch.org. Sorry, you can head over here and ask
[00:29:20.700 --> 00:29:25.140]   PyTorchy questions. Usually you get replies very fast. And
[00:29:25.140 --> 00:29:30.180]   that's thanks to Pyotr. He's insanely active. And if you're
[00:29:30.180 --> 00:29:33.380]   from the PyTorch community, you just recognize this name. He's
[00:29:33.380 --> 00:29:37.740]   he's he's honestly a legend and one of the best on the forums. I
[00:29:37.740 --> 00:29:40.980]   would highly recommend that you follow him on Twitter as well.
[00:29:40.980 --> 00:29:45.660]   And I was just going through this, but you mentioned I took
[00:29:45.660 --> 00:29:50.540]   you about 79 days and I just converted to 11,000 minutes.
[00:29:51.540 --> 00:29:57.140]   Sorry, for Pyotr, it was about 79 days of visiting the forums
[00:29:57.140 --> 00:30:02.380]   and reading and that's about 11,000 minutes. So really, this
[00:30:02.380 --> 00:30:03.380]   is what the community...
[00:30:03.380 --> 00:30:12.620]   No, that's 113,000 minutes, right? Or 114. I mean, Pyotr
[00:30:12.620 --> 00:30:18.940]   wrote like, I think 25,000 answers on the PyTorch forums.
[00:30:19.380 --> 00:30:23.820]   So he certainly made it more than 10,000 minutes.
[00:30:23.820 --> 00:30:30.940]   Absolutely. I just wanted to point those things out because
[00:30:30.940 --> 00:30:33.460]   those are incredible. I'll start scrolling through this.
[00:30:45.020 --> 00:30:50.500]   We can start here. Google Jaxx is based on NumPy, which is
[00:30:50.500 --> 00:30:54.660]   similar to PyTorch. Thomas, any thoughts on PyTorch's future
[00:30:54.660 --> 00:30:57.620]   against Jaxx and other languages? Are you excited
[00:30:57.620 --> 00:30:59.060]   about any of the frameworks?
[00:30:59.060 --> 00:31:06.260]   Well, so obviously, I'm most excited about PyTorch and
[00:31:06.260 --> 00:31:15.100]   haven't used the other ones as much. So I think Jaxx has a
[00:31:15.100 --> 00:31:26.020]   different balance of flexibility. Well, it is more
[00:31:26.020 --> 00:31:29.380]   flexible in some aspects and less flexible than PyTorch and
[00:31:29.380 --> 00:31:35.780]   others. But overall, I mean, it started a bit later, actually,
[00:31:35.780 --> 00:31:46.020]   by one of the early PyTorch users is one of the developers
[00:31:46.020 --> 00:31:52.060]   of Jaxx, right? So they made some conscious design choices
[00:31:52.060 --> 00:32:01.300]   to go in places where PyTorch isn't as natural. But yeah,
[00:32:01.340 --> 00:32:08.620]   it's a spectrum. It's similar to if you reach the end of the
[00:32:08.620 --> 00:32:11.780]   book and don't fall asleep before that, you'll find a
[00:32:11.780 --> 00:32:16.260]   discussion of TorchScript, scripting versus tracing. And
[00:32:16.260 --> 00:32:23.140]   it's a bit like this with Jaxx, too, that there are--it's
[00:32:23.140 --> 00:32:26.380]   another framework with advantages and disadvantages.
[00:32:26.380 --> 00:32:30.740]   The one thing is that Google Jaxx doesn't have Pura to
[00:32:30.740 --> 00:32:38.020]   answer questions. But yeah, there's also, I mean, there's
[00:32:38.020 --> 00:32:44.060]   also good things to be said about Julia, who have a vastly
[00:32:44.060 --> 00:32:51.700]   different approach. But so I think it's good to have more
[00:32:51.700 --> 00:32:57.460]   than one framework, too. And personally, I'm using PyTorch
[00:32:57.460 --> 00:33:02.900]   and I've not found a lot of reasons to abandon it. But
[00:33:02.900 --> 00:33:07.580]   yeah, there will be something eventually that does things
[00:33:07.580 --> 00:33:12.660]   differently. And there will be, if you use PyTorch a lot, and
[00:33:12.660 --> 00:33:18.460]   if you can try to venture into more exotic things, you also
[00:33:18.460 --> 00:33:22.580]   find things where the design of PyTorch has shortcomings.
[00:33:22.580 --> 00:33:27.340]   Things like this modular scheme, they are very, very extremely
[00:33:27.340 --> 00:33:35.460]   convenient for some things. But there are other applications
[00:33:35.460 --> 00:33:42.780]   where this isn't as good a fit. And so yeah, I would recommend
[00:33:42.780 --> 00:33:48.420]   to use whatever works best for you. But there's this thing,
[00:33:48.420 --> 00:33:56.060]   it's a bad craftsman who blames his tools, right? I mean,
[00:33:56.380 --> 00:34:00.620]   you're responsible for choosing the tool, but you can write bad
[00:34:00.620 --> 00:34:04.340]   code and good code in any of the libraries, too, probably.
[00:34:04.340 --> 00:34:09.100]   Can I also just add since I'm very early in my journey
[00:34:09.100 --> 00:34:13.100]   compared to you, so if I may share my perspective, I also
[00:34:13.100 --> 00:34:17.740]   got early in my journey, I got excited about Swift as it was
[00:34:17.740 --> 00:34:20.820]   coming out and also Julia and I spent some time learning those.
[00:34:20.820 --> 00:34:24.580]   But it's also about learning the concepts and then mastering the
[00:34:24.580 --> 00:34:28.940]   framework first. So I'm sure as you master PyTorch, you'll
[00:34:28.940 --> 00:34:31.620]   probably stick with it. But different companies have
[00:34:31.620 --> 00:34:33.900]   different requirements. So assuming you transition into a
[00:34:33.900 --> 00:34:36.380]   job and you need to work on TensorFlow, you can pick that up
[00:34:36.380 --> 00:34:40.860]   no problem. And if I may speak about JAX, I gave it a shot. I
[00:34:40.860 --> 00:34:44.300]   tried the few examples that were there, but it's really really
[00:34:44.300 --> 00:34:48.180]   not as straightforward as going around and creating a kernel on
[00:34:48.180 --> 00:34:51.500]   Kaggle for it because there aren't as many resources yet.
[00:34:51.500 --> 00:34:55.500]   Now you could take that time and create those resources, the
[00:34:55.500 --> 00:34:58.260]   community would really appreciate that. Or you could
[00:34:58.260 --> 00:35:01.420]   also spend that time learning PyTorch and mastering that.
[00:35:01.420 --> 00:35:04.380]   That's that's up to you. But again, it's these two different
[00:35:04.380 --> 00:35:05.260]   parts I feel like.
[00:35:05.260 --> 00:35:17.020]   Yeah, and in a way, it's also I mean, to me, I use TensorFlow a
[00:35:17.020 --> 00:35:21.140]   bit before I came to PyTorch and that was very old TensorFlow.
[00:35:21.420 --> 00:35:24.860]   And obviously, PyTorch had some things going for it that
[00:35:24.860 --> 00:35:29.540]   TensorFlow didn't. And so it spoke to me more, I immediately
[00:35:29.540 --> 00:35:36.260]   liked it. But PyTorch was much simpler back then than it is now.
[00:35:36.260 --> 00:35:42.620]   And so I would just use this, if you use it for your own purposes,
[00:35:42.620 --> 00:35:45.980]   just use whatever feels most natural to you.
[00:35:48.420 --> 00:35:52.700]   Hopefully, it'll be PyTorch. I settle on the framework. I
[00:35:52.700 --> 00:35:57.220]   don't think I'm going away. I think we've answered the ones
[00:35:57.220 --> 00:35:59.700]   before this. Matt, it's also great to see you here. Thanks
[00:35:59.700 --> 00:36:04.180]   for joining us. Thomas, how do you recommend working through
[00:36:04.180 --> 00:36:09.820]   the book? If I can start this answer, and I because I've gone
[00:36:09.820 --> 00:36:12.620]   through the book a little bit, everything does build on top of
[00:36:12.620 --> 00:36:16.980]   itself. It starts off by talking about concepts. So it's not as
[00:36:16.980 --> 00:36:19.820]   difficult to get started. One thing if I may share real quick
[00:36:19.820 --> 00:36:23.940]   the diagrams, I was a fan of these because I'm used to taking
[00:36:23.940 --> 00:36:27.340]   notes in the margins. And if you look at the diagrams, these are
[00:36:27.340 --> 00:36:30.780]   completely hand on. So I found myself taking much lesser notes
[00:36:30.780 --> 00:36:35.420]   for some reason. That's such a nerdy detail. But towards the
[00:36:35.420 --> 00:36:39.580]   later end of the book, you do get into a project. And that does
[00:36:39.580 --> 00:36:40.860]   build upon itself.
[00:36:42.260 --> 00:36:48.340]   Yes, so the editors and obviously Eli and Luca did a lot
[00:36:48.340 --> 00:36:55.060]   of great drawings. And I contributed some diagrams, but
[00:36:55.060 --> 00:37:01.260]   the drawings are all somebody else. So we tried to also
[00:37:01.260 --> 00:37:06.740]   provide something that's visual with all of the concepts. And
[00:37:06.740 --> 00:37:11.300]   the editors also pushed us really hard for that. So I would
[00:37:11.300 --> 00:37:20.660]   indeed recommend to work through the book linearly. I mean, you
[00:37:20.660 --> 00:37:25.300]   can safely peek ahead, for example, part three is, or the
[00:37:25.300 --> 00:37:33.580]   three parts are somewhat independent. But so even if
[00:37:33.580 --> 00:37:43.380]   you're like an intermediate user of deep learning, I think you
[00:37:43.380 --> 00:37:49.980]   won't be off words if you also at least take a brief look at
[00:37:49.980 --> 00:37:58.660]   the first part. We do try to put in as much wisdom as we had,
[00:37:58.980 --> 00:38:05.540]   even if it's a beginner's book. And I think there are some bits
[00:38:05.540 --> 00:38:11.980]   where you see that we really, really try to also reflect on
[00:38:11.980 --> 00:38:16.420]   some things that are easily taken for granted if you learn
[00:38:16.420 --> 00:38:24.460]   things off, like 15 minute tutorials in a series. And so in
[00:38:24.460 --> 00:38:29.900]   a way, the book is kind of the first part is, is the slow food
[00:38:29.900 --> 00:38:33.900]   of often of an introduction to PyTorch.
[00:38:33.900 --> 00:38:39.020]   Yeah, someone also mentioned on Twitter, they really like the
[00:38:39.020 --> 00:38:42.260]   humor I did as well. I was I've never found myself smiling as
[00:38:42.260 --> 00:38:44.700]   much. There was some funny.
[00:38:44.700 --> 00:38:54.420]   And I mean, do you need to solidify the concepts before
[00:38:54.420 --> 00:38:58.660]   moving on? You can always go back if you're confused, too.
[00:38:58.660 --> 00:39:05.100]   Right. I tend to, I tend to, to when I learn things, I tend to
[00:39:05.100 --> 00:39:10.380]   try to try both ways. One, understand it really thoroughly.
[00:39:10.380 --> 00:39:14.460]   But at the same time, I will also take a high level view and
[00:39:14.460 --> 00:39:18.620]   think, yeah, I want to get there. Now, what do I need to
[00:39:18.620 --> 00:39:25.580]   learn for that? And both ways are okay. And that's, that's the
[00:39:25.580 --> 00:39:28.700]   advantage. If you have a larger text, you can also search
[00:39:28.700 --> 00:39:32.220]   through the document, or things like that.
[00:39:32.220 --> 00:39:36.700]   How much Cynthia has such a rich mathematical background? Do you
[00:39:36.700 --> 00:39:39.660]   find yourself leaning on that? Or do you think someone who
[00:39:39.660 --> 00:39:43.140]   doesn't have that can also rely on software engineering and go
[00:39:43.140 --> 00:39:43.660]   in the journey?
[00:39:45.420 --> 00:39:56.940]   So I do use it a lot. But so that kind of shapes my intuition,
[00:39:56.940 --> 00:40:05.820]   my way of thinking about these things. But I don't think it's,
[00:40:05.820 --> 00:40:11.500]   it's something that's absolutely necessary. I mean, it will, it
[00:40:11.500 --> 00:40:16.620]   will move the boundary of what's kind of intuitively obvious and
[00:40:16.620 --> 00:40:22.260]   what's very hard. But we all have unique perspectives on
[00:40:22.260 --> 00:40:27.420]   things. And so different things will be will be natural for us.
[00:40:27.420 --> 00:40:34.100]   I'm certainly, I'm certainly not a person who says, well, yeah,
[00:40:34.100 --> 00:40:39.500]   you need to have no category theory or anything. Recently, I
[00:40:39.900 --> 00:40:43.740]   watched a talk where they said, well, yeah, you need to know
[00:40:43.740 --> 00:40:48.060]   differential geometry, you need to know like what a manifold is
[00:40:48.060 --> 00:40:52.100]   and how many folds are parametrized to understand
[00:40:52.100 --> 00:40:55.900]   autograph. And I would respectfully disagree there
[00:40:55.900 --> 00:40:59.780]   because it's, and now I'm the mathematician, I would disagree
[00:40:59.780 --> 00:41:04.740]   because it's all like embedded in a vector space. And so we
[00:41:04.740 --> 00:41:08.420]   only have embedded manifolds. And we don't need the abstract
[00:41:08.420 --> 00:41:11.860]   ones as much, at least for what's currently done in deep
[00:41:11.860 --> 00:41:18.620]   learning. So yeah, mathematics helps, but it shouldn't stop you
[00:41:18.620 --> 00:41:21.900]   you shouldn't have the feeling you need to learn mathematics
[00:41:21.900 --> 00:41:28.540]   first, because it gives you intuition, but it's not
[00:41:28.540 --> 00:41:34.420]   something that you can learn as you go along to the extent that
[00:41:34.420 --> 00:41:35.700]   you want to learn it.
[00:41:35.700 --> 00:41:48.300]   Thanks, thanks for the honest answer. I'll start by answering
[00:41:48.300 --> 00:41:52.100]   this question again, because I've read ahead of it. I think
[00:41:52.100 --> 00:41:55.860]   the book is book is quite dense in not just theory, there are a
[00:41:55.860 --> 00:41:59.020]   good number of examples. So what I like to do is I just read them
[00:41:59.020 --> 00:42:03.540]   first. And I take notes on the side of what is being done in
[00:42:03.540 --> 00:42:07.180]   the code and replicate it from memory. So forced recall, as
[00:42:07.180 --> 00:42:11.420]   they call it helps me understand the concepts a little
[00:42:11.420 --> 00:42:18.260]   better. And I didn't find any shortage of concepts there,
[00:42:18.260 --> 00:42:21.420]   honestly. So I don't think you need to do anything else. But
[00:42:21.420 --> 00:42:24.660]   for this study group, I do plan to walk through the PyTorch
[00:42:24.660 --> 00:42:27.340]   tutorials as well wherever it supplements well.
[00:42:29.940 --> 00:42:36.100]   Yeah, I mean, it, it, I think it depends on on you personally
[00:42:36.100 --> 00:42:41.420]   more and your learning preferences more than on the
[00:42:41.420 --> 00:42:45.140]   book or the content. So if you're a person who needs to see
[00:42:45.140 --> 00:42:50.100]   applications, by all means go through the applications. And
[00:42:50.100 --> 00:42:56.780]   maybe I don't know, go to a GAN a while ago, a long time ago,
[00:42:56.780 --> 00:43:02.100]   there was like, a GAN that generated cat pictures. And so
[00:43:02.100 --> 00:43:07.700]   by all means, go take this example that you like. And then
[00:43:07.700 --> 00:43:12.140]   you can see what parts do I understand what parts do I want
[00:43:12.140 --> 00:43:15.860]   to understand better. And then as you read chapter after
[00:43:15.860 --> 00:43:20.900]   chapter, probably the bits that or hopefully the bits that you
[00:43:20.900 --> 00:43:26.300]   understand well, and that you're comfortable with, will grow
[00:43:26.420 --> 00:43:26.820]   right?
[00:43:26.820 --> 00:43:35.060]   Yeah, absolutely. I think it's the same answer for this, you
[00:43:35.060 --> 00:43:39.700]   don't need to know everything. You do import the NN module, and
[00:43:39.700 --> 00:43:41.660]   you need to understand what's going on there, what's
[00:43:41.660 --> 00:43:45.180]   inheritance. But for that, you don't need to understand the
[00:43:45.180 --> 00:43:47.980]   complete concept of object oriented programming. I don't
[00:43:47.980 --> 00:43:49.020]   think that's necessary.
[00:43:49.020 --> 00:43:55.380]   Yeah, it probably only when you're, and in particular, like
[00:43:55.420 --> 00:44:03.420]   the Python bits are not all that straightforward when it comes to
[00:44:03.420 --> 00:44:08.860]   OOP concepts. For example, the forward methods in an NN module.
[00:44:08.860 --> 00:44:14.740]   Usually, if you have a subclass, you have the guarantee that you
[00:44:14.740 --> 00:44:18.700]   can call all methods with the same signatures as for the
[00:44:18.700 --> 00:44:24.100]   superclass. And this, which is one of the cornerstones of
[00:44:24.460 --> 00:44:28.100]   object oriented programming, this is obviously not true for
[00:44:28.100 --> 00:44:32.780]   PyTorch forward methods, because you might just require different
[00:44:32.780 --> 00:44:38.180]   arguments. And interestingly, this is a bit of a problem when
[00:44:38.180 --> 00:44:44.860]   it comes to the TorchScript system. And also when it comes
[00:44:44.860 --> 00:44:53.140]   to libTorch, the C++ PyTorch implementation. So I probably,
[00:44:53.460 --> 00:44:57.660]   I'd probably not think too much about object oriented
[00:44:57.660 --> 00:45:04.740]   programming. I'd probably recommend to reflect and Jeremy
[00:45:04.740 --> 00:45:08.060]   Howard wrote this tutorial in the PyTorch tutorials, what is
[00:45:08.060 --> 00:45:16.660]   an NN module really. And the main thing to remember is that
[00:45:18.340 --> 00:45:26.620]   the these modules hold the state of the of the model, right. And
[00:45:26.620 --> 00:45:32.540]   this is the one thing you need to know. And also, it should
[00:45:32.540 --> 00:45:38.580]   give you like an opinion. What's, what's the state you need?
[00:45:38.580 --> 00:45:45.340]   And what should not be part of the model state. So for example,
[00:45:45.340 --> 00:45:51.060]   be light in, in the forward, you should usually not assign to
[00:45:51.060 --> 00:45:56.860]   self dot something, because it's not, not, I mean, there are
[00:45:56.860 --> 00:46:00.900]   exceptions like batch norm obviously updates the
[00:46:00.900 --> 00:46:07.540]   statistics. But so in a vanilla module, you wouldn't update the,
[00:46:08.140 --> 00:46:16.460]   the, the things in the in the in self in the module during the
[00:46:16.460 --> 00:46:21.180]   forward. And so I think it's more important to develop this
[00:46:21.180 --> 00:46:25.580]   intuitive style than any formal OOP knowledge.
[00:46:25.580 --> 00:46:31.940]   At least I found in my experience as I was going to the
[00:46:31.940 --> 00:46:35.660]   book and also learning through fast.ai and PyTorch, I, I found
[00:46:35.660 --> 00:46:40.220]   myself looking at the examples a lot. And as I said, over time,
[00:46:40.220 --> 00:46:43.740]   you start understanding what pieces go together. And at least
[00:46:43.740 --> 00:46:46.820]   for me, I'm really happy this mental picture started to form
[00:46:46.820 --> 00:46:51.020]   where I know where the data loaders go and then how things
[00:46:51.020 --> 00:46:54.340]   are placed in a Jupyter notebook. I think it's the most
[00:46:54.340 --> 00:46:56.900]   fulfilling thing when you don't need to look at an example and
[00:46:56.900 --> 00:47:01.180]   you can create an end to end thing. And it does come with
[00:47:01.180 --> 00:47:12.140]   right practice. Our, our group for this question, I point you
[00:47:12.140 --> 00:47:14.860]   to my interview with Thomas question already.
[00:47:14.860 --> 00:47:27.660]   Yeah. I need someone to push me and so this was Eli and Eli and
[00:47:27.700 --> 00:47:34.180]   Luca, obviously, but also the, the excellent team, team at
[00:47:34.180 --> 00:47:41.500]   Manning. They're just very awesome editors who really,
[00:47:41.500 --> 00:47:47.420]   really, really, we had some hard discussions, but they really
[00:47:47.420 --> 00:47:51.500]   made the book better than it would have been otherwise.
[00:47:51.500 --> 00:47:55.740]   We're just grateful it's come together so nicely and we get to
[00:47:55.740 --> 00:48:05.380]   learn. We've already answered these, so I'll skip ahead. So
[00:48:05.380 --> 00:48:08.500]   I'll point this out. I'm not sure if it's intentional, but
[00:48:08.500 --> 00:48:09.620]   the book is still available.
[00:48:09.620 --> 00:48:17.940]   Can I, can I add something to Chetan's question? So if you are
[00:48:17.940 --> 00:48:22.260]   already familiar with TensorFlow, one of the things
[00:48:22.260 --> 00:48:27.580]   you can do obviously is to try to translate something that
[00:48:27.580 --> 00:48:35.740]   exists in TensorFlow to PyTorch. For example, a while ago,
[00:48:35.740 --> 00:48:43.940]   Piotr and I did that for the original StyleGAN. And, and
[00:48:43.940 --> 00:48:47.660]   this will really, you will hit into all the things where two
[00:48:47.660 --> 00:48:51.140]   frameworks differ if you try to translate from one to the other.
[00:48:51.660 --> 00:48:55.860]   And that can be really, really effective to know the
[00:48:55.860 --> 00:48:58.060]   similarities and the differences.
[00:48:58.060 --> 00:49:04.860]   Awesome. Thanks. Coming back to this point, I just wanted to
[00:49:04.860 --> 00:49:07.940]   point out, Thomas had mentioned the book was available for a
[00:49:07.940 --> 00:49:10.300]   while on the PyTorch website. It still is.
[00:49:10.300 --> 00:49:21.180]   Yeah, I, I never know if it is officially. So I try not to talk
[00:49:21.180 --> 00:49:32.020]   about that too much. Yeah, I'm happy that it is. But at the
[00:49:32.020 --> 00:49:35.100]   same time, I would be disappointed if the publisher
[00:49:35.100 --> 00:49:39.700]   decides that the book is too unprofitable to have the next
[00:49:39.700 --> 00:49:43.420]   PyTorch book. And so yeah.
[00:49:43.420 --> 00:49:48.940]   We'll make sure we don't abuse it and only use that system for
[00:49:48.940 --> 00:49:51.860]   learning. So guys, please don't abuse that system.
[00:49:51.860 --> 00:49:59.140]   Yeah, at the same time, I do know that, I mean, the book can
[00:49:59.140 --> 00:50:03.940]   be cheap or expensive depending on, on your income, right? I
[00:50:03.940 --> 00:50:10.900]   mean, for the, for the printed book, you can't really get
[00:50:10.900 --> 00:50:14.660]   discounts if you're not in the US because the shipping will eat
[00:50:14.660 --> 00:50:15.700]   all of the discount.
[00:50:15.700 --> 00:50:18.060]   Yes.
[00:50:18.980 --> 00:50:26.180]   But yeah, but so I mean, if, if you couldn't afford the book, by
[00:50:26.180 --> 00:50:33.260]   all means download it, right? Yeah, this is this is my take on
[00:50:33.260 --> 00:50:33.580]   that.
[00:50:33.580 --> 00:50:37.940]   Thanks. Thanks for that. Just wanted to point out our friends
[00:50:37.940 --> 00:50:40.740]   at Manning have set this code up. So if you'd like to
[00:50:40.740 --> 00:50:43.460]   purchase, they're offering a 40% discount throughout the
[00:50:43.460 --> 00:50:47.500]   website, not just on this book. It's not an affiliate link. I do
[00:50:47.500 --> 00:50:56.260]   this for the community. So I'm not asking them for money. Any
[00:50:56.260 --> 00:50:57.420]   thoughts on this question?
[00:50:57.420 --> 00:51:06.020]   Yeah, I think I think I personally want for interaction
[00:51:06.020 --> 00:51:11.220]   with the real world. So the other day, I wrote a tutorial on
[00:51:11.460 --> 00:51:17.620]   quantization of an audio model, which has appeared on the
[00:51:17.620 --> 00:51:23.820]   Pytorch Lightning developer blog. And this I showed to my
[00:51:23.820 --> 00:51:31.500]   kids and trains and a speech command recognition model, and
[00:51:31.500 --> 00:51:36.180]   it just takes a Pytorch example and floating point, and then
[00:51:36.180 --> 00:51:40.460]   transforms it into a quantized model. And so I ran that on my
[00:51:40.460 --> 00:51:44.300]   Raspberry with a light bulb in the living room. And my kids
[00:51:44.300 --> 00:51:50.060]   would just try to make it do things like up, up, down, down
[00:51:50.060 --> 00:51:57.140]   and make the light go up and down. And, and so find
[00:51:57.140 --> 00:52:04.500]   something where the result interests you and use that as
[00:52:04.500 --> 00:52:10.820]   something, something to look at. So I like tinkering and real
[00:52:10.820 --> 00:52:14.980]   world, real world interactions for computer stuff.
[00:52:14.980 --> 00:52:21.460]   Thanks. I'll just add one thing. I am not as creative with these
[00:52:21.460 --> 00:52:26.340]   ideas. I'm quickly closing my tabs. But for me, what works
[00:52:26.340 --> 00:52:30.820]   really well is going to Kaggle competitions, because someone has
[00:52:30.820 --> 00:52:33.780]   phrased a problem. And there are different problems that you can
[00:52:33.780 --> 00:52:37.060]   pick and choose from. And then I can resonate with things. So
[00:52:37.060 --> 00:52:41.660]   we're also running a Kaggle event or ignore these just join
[00:52:41.660 --> 00:52:44.780]   any competition. If you can't find any idea, those are great.
[00:52:44.780 --> 00:52:55.300]   Yeah. Any, any thoughts on tabular? Deep learning? I think
[00:52:55.300 --> 00:52:57.860]   they're asking about limitations.
[00:52:59.860 --> 00:53:12.980]   Yeah, I think that's a bit how it is framed. Because obviously,
[00:53:12.980 --> 00:53:20.100]   you have recommenders that also involve tabular data sets a lot.
[00:53:20.100 --> 00:53:25.820]   And basically, I think this is something where what is
[00:53:25.820 --> 00:53:30.780]   available publicly, and what is kind of industry practice
[00:53:30.780 --> 00:53:36.460]   differs a lot. And so I think tabular learning isn't hasn't
[00:53:36.460 --> 00:53:42.420]   caught as much attention in the academic, in the academic world,
[00:53:42.420 --> 00:53:48.700]   and you don't see it much in publications. But in the end,
[00:53:48.700 --> 00:53:53.900]   you have you embed your data. And this is one of the things
[00:53:53.900 --> 00:53:57.820]   where especially proud of the structure of our book that we
[00:53:57.820 --> 00:54:01.220]   have very much in the beginning, a chapter on data
[00:54:01.220 --> 00:54:08.660]   representation. And really, tabular data sets pretty much as
[00:54:08.660 --> 00:54:15.060]   data representation plus deep learning like anything else. In
[00:54:15.060 --> 00:54:23.420]   this sense, I think I think tabular learning and deep
[00:54:23.420 --> 00:54:28.900]   learning on tabular data set works quite well, even if it's
[00:54:28.900 --> 00:54:30.700]   not as published.
[00:54:30.700 --> 00:54:36.620]   I want to point out one resource that I know of. So Kaggle is
[00:54:36.620 --> 00:54:39.980]   running these competitions, at least it was I don't think I saw
[00:54:39.980 --> 00:54:45.100]   one this this month, but people are sharing solutions that are
[00:54:45.100 --> 00:54:47.740]   quite creative for deep learning as well. So you can look on
[00:54:47.740 --> 00:54:48.420]   those as well.
[00:54:48.420 --> 00:55:12.340]   Yes, so I used to contribute a lot of patches and I used to be
[00:55:12.380 --> 00:55:22.780]   like a top 30 contributor to pytorch. As it has grown, I've
[00:55:22.780 --> 00:55:31.100]   I've not kept up with the growth. And so at some point, I
[00:55:31.100 --> 00:55:35.540]   was also on the presence of interest list of who makes
[00:55:35.540 --> 00:55:40.980]   pytorch. But at some point, I felt is more honest if I asked
[00:55:40.980 --> 00:55:49.820]   to be removed from that. Because in a way, I, for example, I
[00:55:49.820 --> 00:55:57.500]   don't have any say into what happens in pytorch. Right. So I
[00:55:57.500 --> 00:56:03.860]   still like that a lot. But I don't have an official role with
[00:56:03.860 --> 00:56:04.620]   pytorch.
[00:56:04.620 --> 00:56:07.860]   Thanks for the time, Steven.
[00:56:07.860 --> 00:56:17.780]   And I found Torch Rift, which is my new pet project, of
[00:56:17.780 --> 00:56:18.220]   course.
[00:56:18.220 --> 00:56:24.220]   I plan to invite Luca, I hope he agrees. Even if he doesn't,
[00:56:24.220 --> 00:56:27.620]   I'll just do a presentation. But it's an incredible project. And
[00:56:27.620 --> 00:56:30.620]   we're just starting to talk in my previous job, we just started
[00:56:30.620 --> 00:56:35.140]   to talk about how we should have implemented all of these points
[00:56:35.140 --> 00:56:39.420]   into models that are deployed, drift detection and all those
[00:56:39.420 --> 00:56:39.620]   things.
[00:56:39.620 --> 00:56:48.580]   I mean, one of the things and I once joked on Twitter, I think
[00:56:48.580 --> 00:56:52.860]   that I could write an entire blog post on where does the model
[00:56:52.860 --> 00:56:58.260]   start and end. And so this is a very good question here. How can
[00:56:58.260 --> 00:57:02.460]   new trends like self supervised learning methods affect the
[00:57:02.460 --> 00:57:06.940]   design and implementation of core modules and pytorch? And so
[00:57:06.940 --> 00:57:14.860]   self supervised learning methods don't really have fundamentally
[00:57:14.860 --> 00:57:18.700]   different model architectures. But they raise the question,
[00:57:18.700 --> 00:57:23.020]   where does our model begin? And where does it end? And for
[00:57:23.020 --> 00:57:31.260]   example, we from ImageNet, we're used to having this normalization
[00:57:31.300 --> 00:57:40.100]   of the channels from zero to one valued RGB to mean zeros, unit
[00:57:40.100 --> 00:57:44.460]   standard deviation. You don't have an appointment afterwards,
[00:57:44.460 --> 00:57:44.780]   right?
[00:57:44.780 --> 00:57:46.700]   No, I do not.
[00:57:46.700 --> 00:57:54.820]   Okay, cool. That will just go over time. And so this
[00:57:54.820 --> 00:57:58.740]   normalization used to be part of the part of the data set
[00:57:58.780 --> 00:58:02.780]   traditionally. But fundamentally, I think it's the
[00:58:02.780 --> 00:58:06.740]   first step in the model, because if you do fancy things with the
[00:58:06.740 --> 00:58:10.580]   with the image in terms of augmentation or things like
[00:58:10.580 --> 00:58:15.900]   that, then it's much easier to think about augmentation on the
[00:58:15.900 --> 00:58:22.340]   original RGB space. And things like that, or also where does
[00:58:22.340 --> 00:58:27.180]   the model end? If you if you say, well, yeah, my model ends
[00:58:28.100 --> 00:58:34.620]   with a log softmax or something. So I get log probabilities as
[00:58:34.620 --> 00:58:40.220]   the output. That's probably not the right answer if you have
[00:58:40.220 --> 00:58:43.940]   like self supervised learning, because obviously, you don't
[00:58:43.940 --> 00:58:51.380]   have the classes yet. And so in this sense, I think it changes
[00:58:51.380 --> 00:58:59.020]   how we think about the models, where does the model end? And if
[00:58:59.020 --> 00:59:04.660]   we could make a composable thing, how do we change two
[00:59:04.660 --> 00:59:09.500]   models, have a mathematical theory for that, then it would
[00:59:09.500 --> 00:59:14.220]   be very natural to have self supervised learning. But we
[00:59:14.220 --> 00:59:18.620]   don't really, we don't have a mathematical theory, where we
[00:59:18.620 --> 00:59:24.220]   can take a model, say ResNet, cut it in two parts. And then
[00:59:24.220 --> 00:59:26.580]   we know what happens in the first part of what happens in
[00:59:26.580 --> 00:59:32.780]   the second part. And I think this is this composition of
[00:59:32.780 --> 00:59:39.020]   models is really one of the unsolved problems that people
[00:59:39.020 --> 00:59:43.820]   will have to have new insights into. But it's more on this
[00:59:43.820 --> 00:59:47.100]   insight level than it is on the technical implementation in
[00:59:47.100 --> 00:59:49.260]   quite a way, to my mind.
[00:59:49.260 --> 00:59:55.700]   Sanyam Bhutani: I feel only with someone of your level of
[00:59:55.700 --> 00:59:59.980]   oversight, could have shared that insight. Thomas, if you
[00:59:59.980 --> 01:00:02.100]   don't mind, should we go over the remaining questions? Or would
[01:00:02.100 --> 01:00:03.020]   you like to skip that?
[01:00:03.020 --> 01:00:07.860]   Thomas Levenson: No, we will do two hours if we have to.
[01:00:07.860 --> 01:00:12.020]   Sanyam Bhutani: You're too kind, but I'll try to wrap up
[01:00:12.020 --> 01:00:15.580]   faster. I'll skip this question because I think it's answered in
[01:00:15.580 --> 01:00:19.500]   the book. But if you have anything to add, please feel
[01:00:19.500 --> 01:00:19.660]   free.
[01:00:19.660 --> 01:00:23.100]   Thomas Levenson: Well, obviously, I like to stay in
[01:00:23.100 --> 01:00:28.340]   PyTorch. If anything, it will be a headache in the lifecycle
[01:00:28.340 --> 01:00:34.980]   planning. And I think the production proposition for
[01:00:34.980 --> 01:00:39.540]   PyTorch is not that bad. And it gets better all the time. So you
[01:00:39.540 --> 01:00:43.660]   have Torch serving, but you don't really need Torch serving
[01:00:43.660 --> 01:00:50.820]   necessarily. But you have things like NVIDIA developed a plugin
[01:00:50.820 --> 01:00:58.540]   to PyTorch that offloads parts of things to TensorRT. And
[01:00:58.540 --> 01:01:03.500]   things like that. I think we will see like specialized and
[01:01:03.500 --> 01:01:10.660]   Onyx has that too. There's an Onyx module, I think it was
[01:01:10.660 --> 01:01:16.060]   featured in the PyTorch blog a few weeks ago, where you
[01:01:16.060 --> 01:01:21.380]   transparently offload part of the PyTorch computation into
[01:01:21.380 --> 01:01:26.300]   Onyx. And I think that really goes a long way for deploying
[01:01:26.300 --> 01:01:33.180]   PyTorch models. But so in my courses and workshops, I also
[01:01:33.180 --> 01:01:37.300]   look at things like TVM, for example, which is a great
[01:01:37.300 --> 01:01:41.940]   solution. If it works, it's a great solution for deploying
[01:01:41.940 --> 01:01:42.900]   PyTorch models.
[01:01:42.900 --> 01:01:49.900]   Sanyam Bhutani: And in the last module, I think part three of
[01:01:49.900 --> 01:01:52.540]   the book is where we also learn about deployment. So the book
[01:01:52.540 --> 01:01:57.140]   also does impact, at least cover the concept really well.
[01:01:57.140 --> 01:02:01.980]   Martin Kaninsky: Yeah, I mean, the ecosystem wasn't as
[01:02:01.980 --> 01:02:06.420]   developed when we wrote it. Because this is really something
[01:02:06.420 --> 01:02:12.660]   that I think the things in there are still true. But there are
[01:02:12.660 --> 01:02:20.220]   more tools today that we would have highlighted if we did it
[01:02:20.220 --> 01:02:20.580]   again.
[01:02:20.580 --> 01:02:27.220]   Sanyam Bhutani: How much C++ do we need to know if we're going
[01:02:27.220 --> 01:02:27.980]   to contribute?
[01:02:27.980 --> 01:02:34.660]   Martin Kaninsky: I don't think I don't think you need to know
[01:02:34.660 --> 01:02:38.140]   any if I mean, it depends on what you want to do. If you want
[01:02:38.140 --> 01:02:44.340]   to write CUDA kernels, you need to know some C, C++. But the
[01:02:44.340 --> 01:02:51.260]   explicit goal of PyTorch is to be useful to people who don't do
[01:02:51.260 --> 01:02:57.700]   C++. And I think they're achieving that very well. And so
[01:02:57.700 --> 01:03:02.540]   if you want to dig deep into the source code, you will learn some
[01:03:02.540 --> 01:03:08.780]   C++ along the way if you didn't. And for the most part, I think
[01:03:08.780 --> 01:03:16.900]   PyTorch has reasonably good C++ code too. I used to say it's
[01:03:16.900 --> 01:03:21.260]   the it's, it's awesome code. I think it has grown beyond what I
[01:03:21.260 --> 01:03:23.060]   can certify as awesome code.
[01:03:25.780 --> 01:03:33.700]   But so they have really good C++ code in general. And if you
[01:03:33.700 --> 01:03:38.460]   learn C++ for reading PyTorch source code, I think this will,
[01:03:38.460 --> 01:03:42.980]   will be a great way to not embarrass yourself with C++
[01:03:42.980 --> 01:03:45.300]   with learning obscure C++.
[01:03:45.300 --> 01:03:52.580]   So I didn't know that much C++ when I started out either, but
[01:03:52.580 --> 01:03:55.820]   I just followed along with what I needed.
[01:03:55.820 --> 01:04:01.740]   If I may ask further on that, like, how do you go about that?
[01:04:01.740 --> 01:04:05.660]   Because it's also like, for me, at least it's really
[01:04:05.660 --> 01:04:09.940]   intimidating as like, I'm trying to understand this, this huge
[01:04:09.940 --> 01:04:14.060]   module of code and also in a different language. So any tips
[01:04:14.060 --> 01:04:15.460]   on navigating that?
[01:04:16.700 --> 01:04:25.140]   Yes. So one of the things is if you, if you've, if you're
[01:04:25.140 --> 01:04:29.860]   interested in a particular function, you can try to find
[01:04:29.860 --> 01:04:33.300]   just by using wrap or something, find that function in the
[01:04:33.300 --> 01:04:38.860]   source code, and then try to set a break point on that and look
[01:04:38.860 --> 01:04:43.700]   at the backtrace. It will be a rather large backtrace, but that
[01:04:43.700 --> 01:04:48.580]   would give you an idea kind of how things are called. And the
[01:04:48.580 --> 01:04:53.340]   video of your colleague or also the two blog posts that I showed
[01:04:53.340 --> 01:04:58.140]   in my slides, and I'll put them up so you can link them too.
[01:04:58.140 --> 01:05:09.020]   These, these really take this approach that we go and run some
[01:05:09.020 --> 01:05:13.180]   function, and then we look into what happens under the hood. And
[01:05:13.180 --> 01:05:18.660]   I think that's general, generally a good way to, to dive
[01:05:18.660 --> 01:05:23.820]   into that. There's one thing to be said, and this is also in
[01:05:23.820 --> 01:05:30.420]   this, is there a better framework than PyTorch? One has
[01:05:30.420 --> 01:05:36.260]   to say that Python, to my mind, Python still is unique in that
[01:05:36.260 --> 01:05:40.260]   you can't understand Python and even write Python without
[01:05:40.260 --> 01:05:44.940]   learning it. And that's certainly much less true for C++,
[01:05:44.940 --> 01:05:48.780]   but personally, I think it's also less true for languages
[01:05:48.780 --> 01:05:55.740]   like Julia. So in a way, this is something when you leave Python,
[01:05:55.740 --> 01:05:59.780]   it will be harder to understand what's going on from just
[01:05:59.780 --> 01:06:04.740]   looking at the code. But generally the PyTorch code is
[01:06:05.020 --> 01:06:10.540]   somewhat well commented. And also there's many, many
[01:06:10.540 --> 01:06:16.300]   directories have a readme file inside the source code
[01:06:16.300 --> 01:06:20.260]   directory that will kind of give you a general picture of
[01:06:20.260 --> 01:06:25.740]   what's going on in that part of PyTorch. I am joking with
[01:06:25.740 --> 01:06:31.500]   Pior that I would do a video course where I read, where I
[01:06:31.540 --> 01:06:35.540]   systematically read every part of the of the PyTorch source
[01:06:35.540 --> 01:06:37.420]   code. That might be fun.
[01:06:37.420 --> 01:06:42.460]   Sanyam Bhutani: I'll watch that. I definitely watch that. So you
[01:06:42.460 --> 01:06:46.060]   have at least one, one viewer. I'm sure more will be there.
[01:06:46.060 --> 01:06:47.900]   Right.
[01:06:47.900 --> 01:06:53.700]   I'll, Gautam I'll answer your question after we end the
[01:06:53.700 --> 01:06:59.220]   session. As you can see, I have a big, insane heater behind me.
[01:06:59.460 --> 01:07:04.180]   It works nicely for winters, not for summers. So I'm opening it
[01:07:04.180 --> 01:07:04.580]   today.
[01:07:04.580 --> 01:07:10.780]   Yeah, I think at some point, buying a computer is probably
[01:07:10.780 --> 01:07:13.580]   cheaper than than renting one, right?
[01:07:13.580 --> 01:07:18.340]   You realize that once you leave an instance running, then it
[01:07:18.340 --> 01:07:19.540]   hits you really fast.
[01:07:19.540 --> 01:07:21.060]   Right.
[01:07:21.060 --> 01:07:22.620]   Yeah.
[01:07:26.700 --> 01:07:41.460]   Ah, I think they, I think that that really, PyTorch, the PyTorch
[01:07:41.460 --> 01:07:50.260]   developers, and Sumit gave a great talk on on PyTorch road to
[01:07:50.260 --> 01:07:55.380]   success, or retrospective on PyTorch, on the how PyTorch was
[01:07:55.380 --> 01:07:59.980]   developed at the Julia conference the other day.
[01:07:59.980 --> 01:08:03.420]   Right.
[01:08:03.420 --> 01:08:06.060]   Oh, yes.
[01:08:06.060 --> 01:08:10.340]   Yeah, growing open source, the blog post also works if you if
[01:08:10.340 --> 01:08:15.260]   you're into reading. And I think if you go back to the search,
[01:08:15.260 --> 01:08:22.660]   there's also the blog post has it. Yeah, the top one, right. I
[01:08:22.660 --> 01:08:28.420]   think there are some insights that they really wanted to cater
[01:08:28.420 --> 01:08:35.180]   to the workflow of researchers. And obviously, this also goes a
[01:08:35.180 --> 01:08:39.980]   long way for the for the workflow and corporate research
[01:08:39.980 --> 01:08:40.260]   too.
[01:08:40.260 --> 01:08:48.220]   And I think that along with a with a great sense of style and
[01:08:48.220 --> 01:08:54.540]   the original authors team. That is really what made PyTorch
[01:08:54.540 --> 01:09:00.140]   successful. On any rate, that people like to work with it
[01:09:00.140 --> 01:09:04.980]   because it's less painful than things used to be before
[01:09:04.980 --> 01:09:05.620]   PyTorch.
[01:09:05.620 --> 01:09:07.380]   Yeah.
[01:09:07.380 --> 01:09:17.940]   We've answered this already, you need you need the book and a lot
[01:09:17.940 --> 01:09:20.340]   of practice and some some projects.
[01:09:20.340 --> 01:09:25.540]   Yeah. And obviously, you need to take my commercial courses. But
[01:09:25.540 --> 01:09:27.340]   yeah, no, just
[01:09:27.340 --> 01:09:32.060]   probably work, work hard.
[01:09:32.060 --> 01:09:37.660]   Yeah. And then it'll, it'll come. Don't be don't be
[01:09:37.660 --> 01:09:43.820]   intimidated by I mean, don't compare yourself to Andrej
[01:09:43.820 --> 01:09:51.460]   Kapathie all the time. But yeah, start out with me. And if you
[01:09:51.460 --> 01:09:56.060]   outgrow me, you go to Sanyam and then and then there's still
[01:09:56.060 --> 01:09:57.340]   Kapathie left, right?
[01:09:57.340 --> 01:10:03.220]   You being too kind Thomas, I'm just I'm learning from you
[01:10:03.220 --> 01:10:08.100]   honestly. So month us answering your question. We've done a
[01:10:08.100 --> 01:10:11.060]   study group on the Hugging Face course, you can check that out.
[01:10:11.540 --> 01:10:15.820]   And we'll try to cover this during during the group
[01:10:15.820 --> 01:10:16.340]   assembly.
[01:10:16.340 --> 01:10:24.740]   Saurabh was the one who mentioned about the books humor
[01:10:24.740 --> 01:10:29.740]   that I just brought up a while ago. Morgan is from our team.
[01:10:29.740 --> 01:10:34.860]   Hey, Morgan, any thoughts on if PyTorch on TPUs will match the
[01:10:34.860 --> 01:10:38.940]   performance of JAX on TPUs? And if you can also just share about
[01:10:38.940 --> 01:10:41.900]   how is PyTorch on TPUs today in general?
[01:10:41.900 --> 01:10:49.660]   Well, so PyTorch on TPUs actually goes through XLA, which
[01:10:49.660 --> 01:10:56.540]   is also the backend in JAX, the X in JAX. And so I think that
[01:10:56.540 --> 01:11:03.100]   part will be very similar. The other bit, of course, that you
[01:11:03.100 --> 01:11:07.860]   need is the tooling around the actual model execution, the
[01:11:07.860 --> 01:11:14.180]   pre processing, post processing. And I think it should be
[01:11:14.180 --> 01:11:21.260]   doable. But it might not look exactly like PyTorch datasets in
[01:11:21.260 --> 01:11:21.660]   the end.
[01:11:21.660 --> 01:11:29.540]   I should also mention Hugging Face accelerate, which works
[01:11:29.540 --> 01:11:32.900]   really well. And you can just run it on any platform.
[01:11:36.940 --> 01:11:45.500]   And skip these ones. I can't say your name, but I would I would
[01:11:45.500 --> 01:11:50.140]   recommend that I've, I've gone through the book. And I didn't
[01:11:50.140 --> 01:11:54.140]   feel like there were any hard prerequisites, maybe some Python
[01:11:54.140 --> 01:11:58.900]   experiences useful, but the book starts really at an easy pace.
[01:12:04.900 --> 01:12:08.620]   I think they want more insights on how can someone explore and
[01:12:08.620 --> 01:12:11.260]   understand the internal structure of PyTorch's core
[01:12:11.260 --> 01:12:16.780]   features. I would also add maybe say if this is useful to you,
[01:12:16.780 --> 01:12:19.780]   because if you're trying to learn about deep learning,
[01:12:19.780 --> 01:12:22.860]   because PyTorch is a lot about software engineering as well.
[01:12:22.860 --> 01:12:26.260]   And it's really people who have put in all of these efforts
[01:12:26.260 --> 01:12:30.140]   about creating the framework. So I'd also add that caution there
[01:12:30.140 --> 01:12:32.460]   because you're going in the world of software engineering.
[01:12:33.540 --> 01:12:41.900]   Yeah, I mean, I, it's funny that he mentions Autograd. So I
[01:12:41.900 --> 01:12:44.900]   mentioned that I launched my first course and that's on
[01:12:44.900 --> 01:12:51.420]   Autograd. And so basically, I can now say confidently say that
[01:12:51.420 --> 01:13:00.540]   I can talk for four hours about Autograd without blinking. And
[01:13:00.540 --> 01:13:10.180]   so really, I mean, if you want to understand it really well, I
[01:13:10.180 --> 01:13:13.020]   think the source code and looking at the source code and
[01:13:13.020 --> 01:13:21.900]   what it does is a good way. I found that there's that most
[01:13:21.900 --> 01:13:31.020]   public resources only go so far. And to some extent, that's
[01:13:31.020 --> 01:13:38.700]   understandable too, because it's really, it's a very, at some
[01:13:38.700 --> 01:13:42.580]   point, you get to very special interest topics. And they also
[01:13:42.580 --> 01:13:47.260]   take like a long time to prepare if you wanted to write a blog
[01:13:47.260 --> 01:13:52.620]   post on that. But of course, you could be the one that puts in
[01:13:52.620 --> 01:13:56.700]   the time too. And then it will be a famous and awesome blog
[01:13:56.700 --> 01:13:57.140]   post.
[01:13:57.140 --> 01:14:05.340]   I don't see any other questions. I'll quickly announce
[01:14:05.340 --> 01:14:08.860]   the book winner from today. So I promise anyone who gets the most
[01:14:08.860 --> 01:14:13.060]   liked question today will win a book today, Curtsy of Manning,
[01:14:13.380 --> 01:14:18.260]   the center of the free copy. I'm really quickly scrolling through
[01:14:18.260 --> 01:14:24.460]   all of the questions. And I think it's Delta X, I'll DM you
[01:14:24.460 --> 01:14:26.820]   after the session. But congratulations, I believe you
[01:14:26.820 --> 01:14:31.340]   won the book. If you're watching this DM me or I'll DM you after
[01:14:31.340 --> 01:14:35.620]   the meeting. Thomas, I really quickly want to thank you so
[01:14:35.620 --> 01:14:38.580]   much again for joining us and sharing all of your insights.
[01:14:38.580 --> 01:14:41.980]   And thank you for your contributions and creating the
[01:14:41.980 --> 01:14:46.420]   book. Yeah, thanks for having me. It's always a great honor
[01:14:46.420 --> 01:14:53.260]   and a pleasure. And the other readers, or the other listeners,
[01:14:53.260 --> 01:14:58.860]   don't be afraid. I won't. If you want to say bad things about the
[01:14:58.860 --> 01:15:05.220]   book, I won't. You can do it in the reading group without me
[01:15:05.220 --> 01:15:11.340]   looking at it. But if you have questions or comments, do send
[01:15:11.340 --> 01:15:15.900]   them via email or you have Twitter, Twitter too.
[01:15:15.900 --> 01:15:20.540]   Thank you. Apart from your Twitter, there's your website as
[01:15:20.540 --> 01:15:23.140]   well where people can get in touch to know more about your
[01:15:23.140 --> 01:15:25.620]   courses. Anything else that I should mention?
[01:15:25.620 --> 01:15:30.460]   Right. I think that's cool.
[01:15:30.460 --> 01:15:36.300]   Awesome. Thanks again for your time, Thomas. And thank you to
[01:15:36.300 --> 01:15:40.060]   everyone that joined it. I couldn't have imagined a better
[01:15:40.060 --> 01:15:42.420]   study group and I look forward to seeing you all on Sunday.
[01:15:42.420 --> 01:15:47.540]   Okay, I hope you enjoy the book and the study group. Okay,
[01:15:47.540 --> 01:15:49.620]   thanks for having me. Bye bye.

