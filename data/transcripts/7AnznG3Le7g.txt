
[00:00:00.000 --> 00:00:04.800]   And I'll quickly make sure that we live sometimes there's like a
[00:00:04.800 --> 00:00:08.600]   30 second delay and I'm watching myself cautiously. What's why is
[00:00:08.600 --> 00:00:10.560]   it not going live? What's what's going on here?
[00:00:10.560 --> 00:00:13.720]   Yeah, and I don't know if I'm able to see if people are in or
[00:00:13.720 --> 00:00:16.200]   not. Like with zoom, you can kind of tell like, okay, people
[00:00:16.200 --> 00:00:19.520]   are there. Here. I have no idea. So it could just be me talking
[00:00:19.520 --> 00:00:21.680]   with you for the next hour or so.
[00:00:24.800 --> 00:00:40.840]   So I'm still trying to make sure we're live everywhere. I believe
[00:00:40.840 --> 00:00:43.960]   we're live on YouTube. So I'll quickly introduce Wade and the
[00:00:43.960 --> 00:00:47.400]   session. Hey, everybody. Welcome to the learning group. Hey,
[00:00:47.400 --> 00:00:50.760]   Matteo. Thanks for joining us. We are back with another session
[00:00:50.760 --> 00:00:55.080]   as for thanks for the consent request. So I convinced Wade to
[00:00:55.080 --> 00:00:59.120]   have chai with me again, and teach us more about hugging face
[00:00:59.120 --> 00:01:04.360]   and fast AI. Wade is the real host again, and I'll just be
[00:01:04.360 --> 00:01:08.440]   keeping an eye out for all of the questions. With that, I'll
[00:01:08.440 --> 00:01:11.040]   hand it over to Wade and remind everyone please keep the
[00:01:11.040 --> 00:01:14.560]   questions coming. We'll be actively monitoring the chart
[00:01:14.560 --> 00:01:17.640]   and taking any questions throughout the duration.
[00:01:18.840 --> 00:01:22.160]   Great, thanks. Thanks, Sonja for having me back. You didn't have
[00:01:22.160 --> 00:01:25.120]   to wrestle me that hard. I'm looking forward to getting back
[00:01:25.120 --> 00:01:30.720]   and it feels like forever since we did part one. So I'm glad to
[00:01:30.720 --> 00:01:35.280]   be back and I can't see anybody else out there. But I'm glad to
[00:01:35.280 --> 00:01:37.840]   be with you all again. I'm going to share my screen here real
[00:01:37.840 --> 00:01:51.480]   quick. All right, and we're back. So yes, my name is Wade
[00:01:51.480 --> 00:01:58.480]   Gilliam from omeow.com. And I led the part one study session
[00:01:58.480 --> 00:02:04.320]   that several months back and it was really fun. And again, what
[00:02:04.320 --> 00:02:09.160]   we're doing is looking at the hugging face course, but through
[00:02:09.160 --> 00:02:13.680]   a fast AI lens. And so basically, the study group is
[00:02:13.680 --> 00:02:17.640]   designed to go through the course, but actually focus more
[00:02:17.640 --> 00:02:21.840]   on how fast AI developers can harness some of the things that
[00:02:21.840 --> 00:02:29.360]   are being discussed in building models with fast AI. And so
[00:02:29.360 --> 00:02:34.840]   anyways, this is part two, session one. And we're going to
[00:02:34.840 --> 00:02:39.920]   be looking at data sets pretty much today. And so one thing
[00:02:39.920 --> 00:02:42.200]   you'll notice if you go through the course, and I highly
[00:02:42.200 --> 00:02:44.840]   recommend that as we do the study group, if you haven't done
[00:02:44.840 --> 00:02:49.920]   the course yet, or even if you have is to spend the next week
[00:02:49.920 --> 00:02:55.000]   going back through it because the part two content is much
[00:02:55.000 --> 00:02:59.160]   more dense than the part one content. So with the part one
[00:02:59.160 --> 00:03:02.520]   content, I noticed I can kind of go through most sessions in a
[00:03:02.520 --> 00:03:08.600]   day or two. And with part two, I got into the data sets content
[00:03:08.600 --> 00:03:11.480]   and I was noticing I could go through like one subsection
[00:03:11.480 --> 00:03:16.560]   every, every day, it took me an hour or so to really kind of get
[00:03:16.560 --> 00:03:20.080]   into it and play around with the code. And so make sure you go
[00:03:20.080 --> 00:03:24.320]   through because there's a lot of content in the part two, and
[00:03:24.320 --> 00:03:28.760]   we're not gonna be covering everything I'm kind of hand
[00:03:28.760 --> 00:03:33.240]   picking things that I think will be more applicable to folks
[00:03:33.240 --> 00:03:36.680]   doing fast AI development. If there's things that I don't
[00:03:36.680 --> 00:03:40.760]   cover in the study group that you'd like me to cover in
[00:03:40.760 --> 00:03:47.160]   subsequent weeks, let us know on the events website. But yeah, so
[00:03:47.160 --> 00:03:51.920]   today we're going to be looking at data sets and in particular,
[00:03:51.920 --> 00:03:58.520]   how to load them, how they can be used to perform EDA, how we
[00:03:58.520 --> 00:04:02.160]   can use them for data pre processing. And then also I'm in
[00:04:02.160 --> 00:04:07.880]   the process of updating blur based on some of the things
[00:04:07.880 --> 00:04:14.080]   that I've learned in the part two sessions. And so we'll begin
[00:04:14.080 --> 00:04:17.640]   looking at some of those changes. And we'll look in
[00:04:17.640 --> 00:04:20.680]   particular at some of the pre processing bits I'm adding in
[00:04:20.680 --> 00:04:25.400]   there to the sequence classification process, pre
[00:04:25.400 --> 00:04:29.920]   processing pipeline. And so we'll actually use data sets to
[00:04:29.920 --> 00:04:34.280]   download a model, do some pre processing, prepare it, and then
[00:04:34.280 --> 00:04:38.880]   actually train a sequence classification model. So that's
[00:04:38.880 --> 00:04:42.760]   the goal for today. resources pretty much the same as last
[00:04:42.760 --> 00:04:46.120]   time, the links have changed a little bit. If you have folks
[00:04:46.120 --> 00:04:48.960]   that want to register or you want to discuss what we're
[00:04:48.960 --> 00:04:54.200]   doing, check out the study group registration page. On we have a
[00:04:54.200 --> 00:04:58.520]   fast AI discord, a section specifically for hugging face
[00:04:58.520 --> 00:05:01.960]   and fast AI, the link is right there, if you want to join there
[00:05:01.960 --> 00:05:05.560]   and ask questions on there. And then here's some resources again
[00:05:05.560 --> 00:05:11.360]   for a fast AI, highly recommend the course, I'm not assuming any
[00:05:11.360 --> 00:05:14.200]   level of expertise by the folks here, I have a feeling most
[00:05:14.200 --> 00:05:17.960]   people have done some fast AI. But if you're new to it, don't
[00:05:17.960 --> 00:05:22.360]   worry about easy to get started. And the best place to do that is
[00:05:22.400 --> 00:05:26.680]   at the course website. And of course, there's the fastbook,
[00:05:26.680 --> 00:05:31.680]   which is available online for free via Jupyter notebooks. And
[00:05:31.680 --> 00:05:35.920]   you can purchase it on Amazon and a bunch of other places. And
[00:05:35.920 --> 00:05:39.560]   personally, I like the feel of a real book since seems like
[00:05:39.560 --> 00:05:42.800]   everything is virtual these days. So highly recommend
[00:05:42.800 --> 00:05:47.440]   getting the hard copy. Also, another great resource is Zack
[00:05:47.440 --> 00:05:52.000]   Mueller's walk with fast AI talks about a lot of things. A lot of
[00:05:52.040 --> 00:05:55.880]   a lot of the questions you have, or at least I had after going or
[00:05:55.880 --> 00:05:59.440]   going through the course and fastbook, how to do certain
[00:05:59.440 --> 00:06:03.120]   things, how certain things work, he covers really well in there.
[00:06:03.120 --> 00:06:07.920]   So make sure to check out that resource. And then for fast AI
[00:06:07.920 --> 00:06:14.400]   hugging face libraries. If folks know of other ones, let me know
[00:06:14.400 --> 00:06:18.960]   so I can update the slide. But these are the three that I'm
[00:06:18.960 --> 00:06:24.080]   familiar with. And so there's adapt NLP, which is, again, the
[00:06:24.080 --> 00:06:30.840]   work of Zack fast hugs, which Morgan is over at way some bias
[00:06:30.840 --> 00:06:35.440]   has started and I forget who's taken that over. I'm not sure if
[00:06:35.440 --> 00:06:39.240]   these how active these are. But that was kind of one of the
[00:06:39.240 --> 00:06:42.640]   first kind of integrations between fast and hugging face.
[00:06:42.640 --> 00:06:48.160]   And then there is blur, which is the project I created and is
[00:06:48.160 --> 00:06:53.960]   active. And again, if you go to the GitHub, you'll see that
[00:06:53.960 --> 00:06:58.480]   working on a version two, and adding a bunch of kind of new
[00:06:58.480 --> 00:07:00.640]   things in there, and hopefully some improvements that folks
[00:07:00.640 --> 00:07:05.240]   will like. And then for ML data science in general, check out
[00:07:05.240 --> 00:07:08.200]   the chai time data science podcasts, of course, with a good
[00:07:08.200 --> 00:07:14.960]   cup of coffee. And also check out weights and biases and begin
[00:07:15.000 --> 00:07:19.440]   actually checking that out for using ways devices for any of
[00:07:19.440 --> 00:07:22.800]   your machine learning operations. We'll demo some of
[00:07:22.800 --> 00:07:26.760]   those things and how I use it for hyper params, sweeps and,
[00:07:26.760 --> 00:07:33.320]   and things like that during the course of this study group. So
[00:07:33.320 --> 00:07:39.640]   let's go ahead and start with data sets. And I wanted to go
[00:07:39.680 --> 00:07:57.320]   first to the hub here. Let's see. And I wanted to show you
[00:07:57.320 --> 00:08:05.800]   that it's super easy. Going in there and, and finding a data
[00:08:05.800 --> 00:08:14.400]   set to use here. So depending on what you're, what you're
[00:08:14.400 --> 00:08:17.960]   doing, you can actually come here to the hugging face dot co
[00:08:17.960 --> 00:08:23.880]   data sets. And you can find data sets to use for just about any
[00:08:23.880 --> 00:08:29.560]   task you can imagine. There's a lot here. And it's it, it spans
[00:08:29.560 --> 00:08:33.680]   well beyond just NLP. So there's folks working with like vision
[00:08:33.680 --> 00:08:38.640]   transformers, folks doing speech and audio. And so it's nice
[00:08:38.640 --> 00:08:41.520]   here, you could go ahead and, you know, type of data set that
[00:08:41.520 --> 00:08:47.360]   you know, like blue, for example. And if you're looking
[00:08:47.360 --> 00:08:51.080]   to actually start experimenting with some of the things we're
[00:08:51.080 --> 00:08:54.160]   talking about today and building these models, you could go in
[00:08:54.160 --> 00:08:57.800]   here and like explore the data set. And I like this, I use this
[00:08:57.800 --> 00:09:01.880]   all the time, which is the use in data set library. And
[00:09:01.880 --> 00:09:07.800]   literally, you can just copy this code and into your Jupyter
[00:09:07.800 --> 00:09:13.240]   notebook and get a data set to start training on. So this is
[00:09:13.240 --> 00:09:17.840]   where you go, and you probably are most familiar with that. So
[00:09:17.840 --> 00:09:22.680]   let's go ahead and now look at some of the like the core tasks
[00:09:22.680 --> 00:09:27.320]   that like it as me as a fast ad developer, I want to be able to
[00:09:27.360 --> 00:09:33.400]   not just load data sets from the hub, but I also want to be able
[00:09:33.400 --> 00:09:37.520]   to work with local data. And so when we actually start getting
[00:09:37.520 --> 00:09:42.760]   actually doing like real world work or Kaggle competitions, we
[00:09:42.760 --> 00:09:46.640]   might be downloading data. So how can we use those various
[00:09:46.640 --> 00:09:53.680]   formats, whether it's a CSV file, a tab, delimited, TSV, or
[00:09:53.680 --> 00:09:57.800]   JSON, or whatever, how can we actually pull those into a data
[00:09:57.800 --> 00:10:02.640]   set that so that we can actually use that for model training. So
[00:10:02.640 --> 00:10:06.240]   I've ran this just in case my internet goes down, but I'm
[00:10:06.240 --> 00:10:13.360]   installing data sets and transformers. And just to kind
[00:10:13.360 --> 00:10:16.680]   of get things started, I just copy and pasted that code that I
[00:10:16.680 --> 00:10:22.800]   showed you before for glue. And by calling load data set, you'll
[00:10:22.840 --> 00:10:26.720]   actually get a data set dictionary. And there's a
[00:10:26.720 --> 00:10:30.560]   variety of ways check the documentation to get subsets of
[00:10:30.560 --> 00:10:37.880]   data. So this particular data, data set actually has three or
[00:10:37.880 --> 00:10:41.240]   data set dictionary has three data sets to train validation
[00:10:41.240 --> 00:10:44.680]   and test. But if you look at the documentation, there's also ways
[00:10:44.680 --> 00:10:49.160]   to load these and just get the training set or just get
[00:10:49.160 --> 00:10:54.640]   portions of the training validation and test set. And so
[00:10:54.640 --> 00:10:57.520]   there's all kinds of various options. So check out the data
[00:10:57.520 --> 00:11:00.680]   sets documentation, if you're interested in exploring that,
[00:11:00.680 --> 00:11:05.640]   we'll show some examples of that in just a bit. And also, I have
[00:11:05.640 --> 00:11:09.440]   one general warning when you're doing experimentation with a
[00:11:09.440 --> 00:11:13.360]   subset of data and why you may not want to just get a subset of
[00:11:13.360 --> 00:11:20.400]   like the training set to work with. Once you actually have a
[00:11:20.400 --> 00:11:26.280]   data sets object, you can go ahead and access it just like a
[00:11:26.280 --> 00:11:32.160]   dictionary and look at specific data sets. And once you pull
[00:11:32.160 --> 00:11:36.520]   these up, you'll see that this is the same information as right
[00:11:36.520 --> 00:11:40.040]   here. But there's other cool things you can do, you can
[00:11:40.040 --> 00:11:46.400]   actually look at the the data set here. And you could get
[00:11:46.400 --> 00:11:50.200]   information that you typically see on the model card. And so
[00:11:50.200 --> 00:11:55.880]   if you're actually using the hub CLI to to pull data sets and
[00:11:55.880 --> 00:11:59.920]   look at it, this actually may be helpful in determining whether
[00:11:59.920 --> 00:12:03.640]   or not this is a data set that you should use for your given
[00:12:03.640 --> 00:12:08.280]   task. I've chosen it just because it's a small data set.
[00:12:08.280 --> 00:12:15.480]   So easy to load pretty quickly. Once you have one of these, you
[00:12:15.480 --> 00:12:20.640]   typically want to start looking at what's in it. Because the
[00:12:20.640 --> 00:12:23.120]   data sets are like I said, these, they're not uniform in
[00:12:23.120 --> 00:12:30.040]   exactly how how they look, and how the data is included. And
[00:12:30.040 --> 00:12:34.920]   so typically, what I do is just print out the first or a few
[00:12:34.920 --> 00:12:39.800]   examples from one of the data sets. So you can see here we
[00:12:39.800 --> 00:12:45.480]   have these features right here, and they're included in a JSON
[00:12:45.480 --> 00:12:52.000]   L format. So when you are looking at JSON data, typically
[00:12:52.000 --> 00:12:54.960]   comes in one of two ways, which is kind of standard JSON, where
[00:12:54.960 --> 00:13:00.280]   it looks like a bunch of nested dictionaries. Or what I notice
[00:13:00.360 --> 00:13:05.400]   to be more common is this JSON lines format, where it's a list
[00:13:05.400 --> 00:13:10.280]   of dictionaries. And that's we have here. And then one of the
[00:13:10.280 --> 00:13:15.640]   cool things with using a data set from the data sets library,
[00:13:15.640 --> 00:13:20.600]   is that they often include a lot of information you'd need for
[00:13:20.600 --> 00:13:24.360]   your hugging face objects, your configuration, your tokenizer
[00:13:24.360 --> 00:13:30.800]   and your model object in this dot features property. And so
[00:13:30.800 --> 00:13:34.560]   you can see that once we once we call this, we actually see a
[00:13:34.560 --> 00:13:38.720]   little bit more details about the particular attributes of
[00:13:38.720 --> 00:13:43.920]   each example in the data set. So we see like for sentence one,
[00:13:43.920 --> 00:13:48.560]   sentence two, these are strings. And then really helpful is for
[00:13:48.560 --> 00:13:55.080]   the label attribute, we actually see it's of class label. And it
[00:13:55.080 --> 00:13:58.880]   has two classes. And as you know, when we do sequence
[00:13:58.880 --> 00:14:02.880]   classification, we have to tell our hugging face objects, how
[00:14:02.880 --> 00:14:06.040]   many labels we're trying to predict. And then it also
[00:14:06.040 --> 00:14:14.040]   includes the the names of the labels. And so most hugging face
[00:14:14.040 --> 00:14:16.960]   objects a little bit different than the fast AI data sets,
[00:14:17.360 --> 00:14:24.040]   actually include the numerical indices of whatever you're
[00:14:24.040 --> 00:14:27.760]   trying to predict. So here we have two labels, we're trying to
[00:14:27.760 --> 00:14:32.200]   figure out whether two sentences are saying the same thing,
[00:14:32.200 --> 00:14:35.960]   they're equivalent, not equivalent, but in the data, we
[00:14:35.960 --> 00:14:40.400]   only have like one or zero. So this is helpful information that
[00:14:40.400 --> 00:14:44.680]   we can use in building our data blocks, and also doing our
[00:14:44.680 --> 00:14:50.920]   training. So when I start, those are basically the things as a
[00:14:50.920 --> 00:14:55.240]   fast AI developer, try to find a suitable data set for a task
[00:14:55.240 --> 00:14:59.280]   I'm working with, and explore it, make sure it makes sense.
[00:14:59.280 --> 00:15:01.160]   And I understand, especially if I'm doing something like
[00:15:01.160 --> 00:15:04.440]   sequence classification, or token classification, the number
[00:15:04.440 --> 00:15:08.800]   of labels and what they represent. And then from there,
[00:15:09.000 --> 00:15:17.600]   we want to load the data. So when we load, most folks are
[00:15:17.600 --> 00:15:24.560]   using one of these straight CSV files, JSON data, the dot JSON
[00:15:24.560 --> 00:15:29.000]   now is the JSON lines, which again, is a list of individual
[00:15:29.000 --> 00:15:33.680]   JSON objects. And then for me, I'm much more comfortable
[00:15:33.680 --> 00:15:37.640]   working with pandas. And I typically load everything into
[00:15:37.640 --> 00:15:42.640]   pandas, because in terms of a library, it's the one I'm most
[00:15:42.640 --> 00:15:48.560]   familiar with using to explore the data, but also massage it
[00:15:48.560 --> 00:15:51.960]   and do the feature engineering and, and prepare for machine
[00:15:51.960 --> 00:15:55.880]   learning. And fortunately, the data sets library has a lot of
[00:15:55.880 --> 00:15:59.120]   integration with pandas that we'll look at in just a little
[00:15:59.120 --> 00:16:06.360]   bit. So for working with CSV files, first off, one of the
[00:16:06.360 --> 00:16:12.280]   things is kind of nice with data sets is that it has a very
[00:16:12.280 --> 00:16:17.520]   familiar API if you're used to using pandas. So I can actually
[00:16:17.520 --> 00:16:22.640]   take this data set, the training and the validation, and call to
[00:16:22.640 --> 00:16:27.880]   CSV and actually create a CSV file. In this case, I'm doing it
[00:16:27.880 --> 00:16:30.800]   just for demonstration purposes to show how we can load a CSV
[00:16:30.800 --> 00:16:35.640]   file using data sets. But if you wanted to actually download a
[00:16:35.640 --> 00:16:39.520]   data set from the Hugging Face hub, and store it locally to
[00:16:39.520 --> 00:16:43.720]   work on later, this is how you can do it. But here, I'm just
[00:16:43.720 --> 00:16:49.760]   using it to create a training and validation CSV file. And if
[00:16:49.760 --> 00:16:53.840]   I wanted to load that into an error format, so take advantage
[00:16:53.840 --> 00:17:00.080]   of all the niceties that the data sets library has, it's as
[00:17:00.080 --> 00:17:06.960]   easy as calling load data set, specifying CSV, and then a CSV
[00:17:06.960 --> 00:17:11.600]   file. And then of course, if you have a training and
[00:17:11.600 --> 00:17:17.640]   validation, a test, the data files can be specified as a
[00:17:17.640 --> 00:17:21.160]   dictionary, and you could give it whatever name you want. It's
[00:17:21.160 --> 00:17:23.920]   probably I'm changing it up here a little bit, but it's probably
[00:17:23.920 --> 00:17:28.000]   the stick better to stick with kind of the naming conventions
[00:17:28.080 --> 00:17:33.400]   that most data sets share and use training and validation. But
[00:17:33.400 --> 00:17:37.200]   if you do this, you'll notice you'll get a data set dictionary
[00:17:37.200 --> 00:17:42.640]   with your your train and your validation data set. So really
[00:17:42.640 --> 00:17:48.960]   easy to use with CSV files. With JSON files, again, a little bit
[00:17:48.960 --> 00:17:52.960]   different depending on the format of the JSON you're using.
[00:17:52.960 --> 00:17:57.880]   Here, I'm actually going to save the training and validation.
[00:17:58.320 --> 00:18:01.960]   But I'm not going to save it as JSON lines, that's the default.
[00:18:01.960 --> 00:18:06.000]   And I'm going to save it more like a traditional JSON object.
[00:18:06.000 --> 00:18:12.680]   So at the nested dictionary. And when you do that, you'll see
[00:18:12.680 --> 00:18:17.280]   that at least with these particular attributes, and we
[00:18:17.280 --> 00:18:21.120]   actually pull up the JSON to look at, you can see that it's
[00:18:21.160 --> 00:18:29.680]   actually, we have a couple of keys on the JSON object, and our
[00:18:29.680 --> 00:18:36.880]   data is in the data key. And we can actually pull this up. And
[00:18:36.880 --> 00:18:39.440]   you can see like in this particular case, that actually,
[00:18:39.440 --> 00:18:44.760]   these are essentially JSON L like files, but they're, again,
[00:18:44.760 --> 00:18:48.000]   nested in this data attribute. And when you do that, when you
[00:18:48.000 --> 00:18:50.960]   work with JSON files like this, and one of the common ones that
[00:18:50.960 --> 00:18:55.080]   I can think of that looks like this is SQuAD. So if you're
[00:18:55.080 --> 00:19:01.400]   using SQuAD for building a question answering data set,
[00:19:01.400 --> 00:19:06.640]   you'll want to explore more on like how to, you'll need to
[00:19:06.640 --> 00:19:10.600]   specify this field attribute with where the data is at. And
[00:19:10.600 --> 00:19:12.920]   also, there's a few other things you have to do to be able to
[00:19:12.920 --> 00:19:18.200]   flatten that data to actually build examples that you can use
[00:19:18.240 --> 00:19:22.360]   in Fast.ai. So again, with standard JSON, we just have to
[00:19:22.360 --> 00:19:27.480]   specify this, we can specify one or more data files, and we're
[00:19:27.480 --> 00:19:36.920]   good to go. So with JSON L, again, a little bit more simple.
[00:19:36.920 --> 00:19:40.760]   And here, we're going to go ahead and say things as JSON
[00:19:40.760 --> 00:19:45.600]   lines, which is the default when you use to JSON on a data set
[00:19:45.600 --> 00:19:50.000]   object. And you'll see when we actually look at this, it's
[00:19:50.000 --> 00:19:55.520]   saved these as each example is a dictionary, and it's a single
[00:19:55.520 --> 00:20:00.320]   line in this file. And to load it, we don't need to specify
[00:20:00.320 --> 00:20:05.400]   that field attribute, we just need to go ahead and pass our
[00:20:05.400 --> 00:20:12.120]   data files. And again, we have our data set dictionary. And
[00:20:12.120 --> 00:20:17.360]   then one of the kind of another nice to do, there's all kinds of
[00:20:17.360 --> 00:20:22.120]   ways to specify data files. So they don't have to even be local
[00:20:22.120 --> 00:20:27.760]   resources, they can be remote, remote JSON files, or remote
[00:20:27.760 --> 00:20:34.400]   CSV files. If you have a bunch of them, you can actually use
[00:20:34.400 --> 00:20:39.720]   like the glob syntax here to just pull up all the JSON L
[00:20:39.720 --> 00:20:45.400]   files in a particular directory. You can even specify remote
[00:20:45.400 --> 00:20:50.480]   compressed files that are in gzip, tar, or zip, I believe.
[00:20:50.480 --> 00:20:55.200]   And it will actually do all the work of decompressing the files
[00:20:55.200 --> 00:20:59.240]   and and building your data sets. So there's a lot of like really
[00:20:59.240 --> 00:21:03.000]   cool options for working for data files. And I encourage you
[00:21:03.000 --> 00:21:08.640]   to look at the documentation to see how that all looks and what
[00:21:08.640 --> 00:21:12.640]   you can do with them. So these are the core things. And of
[00:21:12.640 --> 00:21:17.800]   course, there's also data frames. And I'm going to go
[00:21:17.800 --> 00:21:21.480]   ahead and create a data frame, which is as easy as calling two
[00:21:21.480 --> 00:21:24.960]   pandas. And you can see that once we have that, now we can
[00:21:24.960 --> 00:21:29.560]   work with the data frame, and using all the pandas syntax that
[00:21:29.560 --> 00:21:34.600]   most of us are familiar with. And assuming we have data
[00:21:34.600 --> 00:21:39.240]   frames, we can actually convert them to data sets pretty simple
[00:21:39.240 --> 00:21:43.240]   simply by calling data set from pandas and passing the data
[00:21:43.240 --> 00:21:46.080]   frame. And so you can see that that creates a data set object
[00:21:46.080 --> 00:21:49.800]   for us. And so one of the things I find myself doing is
[00:21:49.800 --> 00:21:54.440]   downloading a data set. And when I don't know how to do the
[00:21:54.440 --> 00:22:00.440]   pre processing, using the data sets library, I basically fall
[00:22:00.440 --> 00:22:03.400]   back to creating a data frame, adding columns doing feature
[00:22:03.400 --> 00:22:07.240]   engineering, and then bringing those back into data set
[00:22:07.240 --> 00:22:12.760]   objects for actually doing any further pre processing just
[00:22:12.760 --> 00:22:15.760]   because there's some advantages we'll cover in a little bit to
[00:22:15.760 --> 00:22:19.480]   using data sets, and then using that actually in my fast AI
[00:22:19.480 --> 00:22:26.640]   models. So you can see that pretty easy to go back and forth
[00:22:26.640 --> 00:22:33.280]   with pandas. And then as the course talks about if you pickle
[00:22:33.320 --> 00:22:38.680]   data frame, you can actually use that eventually by passing in
[00:22:38.680 --> 00:22:43.040]   pandas as the first argument to load data set. And again, you'll
[00:22:43.040 --> 00:22:47.720]   get your data set dictionary there. One thing you'll notice
[00:22:47.720 --> 00:22:52.600]   as you go back and forth, remember, the features property
[00:22:52.600 --> 00:22:56.560]   had the information about the labels, the number of labels and
[00:22:56.560 --> 00:23:01.840]   the actual label names. So as you go back and forth, you lose
[00:23:01.840 --> 00:23:07.840]   some of that. There's probably ways to add that back in. But
[00:23:07.840 --> 00:23:11.520]   just be aware of that if you if you call dot features on it, on
[00:23:11.520 --> 00:23:15.600]   your training data set, you may not see all the things that you
[00:23:15.600 --> 00:23:18.080]   saw before when you when you just loaded it straight from the
[00:23:18.080 --> 00:23:24.760]   hub. So that's how you load a data set. Some tips and tricks
[00:23:24.760 --> 00:23:29.960]   is again, the automatic decompression. Most places I
[00:23:29.960 --> 00:23:33.400]   think even you know, the fast AI data data sets are remote and
[00:23:33.400 --> 00:23:38.960]   compressed. And so it's nice to be able to simply point to a
[00:23:38.960 --> 00:23:45.000]   URL with a compressed file and call load data set and have it
[00:23:45.000 --> 00:23:50.080]   again, decompress and bring the data down and create a data set
[00:23:50.080 --> 00:23:54.480]   object for you to start working with. And as I mentioned before,
[00:23:54.480 --> 00:23:59.760]   data files can point to local or remote files, I think for
[00:23:59.780 --> 00:24:03.160]   most of our cases, we're downloading data at some point,
[00:24:03.160 --> 00:24:07.840]   and we'll be mostly working for local with local files. But
[00:24:07.840 --> 00:24:10.680]   again, the remote files is really nice. For big data sets,
[00:24:10.680 --> 00:24:13.200]   you can't store on your machine or don't want to keep on your
[00:24:13.200 --> 00:24:18.920]   machine, or you're experimenting with data sets in fast AI or
[00:24:18.920 --> 00:24:25.000]   hugging face or or anywhere else. And then just the last bit
[00:24:25.080 --> 00:24:29.900]   of advice is that for JSON, this is per the data sets
[00:24:29.900 --> 00:24:33.780]   documentation, the most efficient format is the JSON L
[00:24:33.780 --> 00:24:40.540]   format. So tend to use that if you're serializing your data
[00:24:40.540 --> 00:24:46.700]   locally. Any questions on working with data sets, Sanyam?
[00:24:46.700 --> 00:24:52.620]   I'm quickly scrolling back. This one question, how will we be
[00:24:52.620 --> 00:24:57.420]   using fast AI through this course? And will we be just
[00:24:57.420 --> 00:24:59.740]   using fast data block or beyond that as well?
[00:24:59.740 --> 00:25:06.020]   So watch a run a work through example in just a few minutes of
[00:25:06.020 --> 00:25:08.780]   using a pre process. So we're gonna use the data sets library
[00:25:08.780 --> 00:25:13.180]   to download data set, do some pre processing, and then show you
[00:25:13.180 --> 00:25:18.700]   how you can use that pre process data to train a transformer
[00:25:18.700 --> 00:25:19.700]   model and fast AI.
[00:25:21.220 --> 00:25:24.620]   Awesome. There are no other questions. I quickly want to
[00:25:24.620 --> 00:25:27.540]   point this out. I was trying to debug this issue. We also
[00:25:27.540 --> 00:25:30.620]   requested people to sign up and there's some server issue on
[00:25:30.620 --> 00:25:33.460]   that place. I'm trying to fight that. But if you're watching
[00:25:33.460 --> 00:25:37.020]   the recording, now you know what happened. And right now the
[00:25:37.020 --> 00:25:39.700]   preferred place to ask questions is the YouTube chat. So please
[00:25:39.700 --> 00:25:41.700]   ask them there. I'll keep an eye out.
[00:25:41.700 --> 00:25:49.100]   All right, awesome. All right. Thanks, Sanyam. Okay, so now
[00:25:49.100 --> 00:25:52.980]   let's look at some of the things that you're going to want to do
[00:25:52.980 --> 00:25:59.980]   when you download data. And for me, I'm a big Hobbit Tolkien
[00:25:59.980 --> 00:26:05.820]   fan. So I named this section to data frames and back again. And
[00:26:05.820 --> 00:26:10.540]   this I'm highlighting because I think most folks are familiar
[00:26:10.540 --> 00:26:15.340]   with pandas and with working with data frames. And for
[00:26:15.340 --> 00:26:19.260]   myself, at least it's, it's where I tend to go for doing any
[00:26:19.260 --> 00:26:23.700]   type of analysis of the data. So trying to understand it,
[00:26:23.700 --> 00:26:28.020]   visualize it, and also any really complicated feature
[00:26:28.020 --> 00:26:31.100]   engineering. And a lot of that is that I don't really
[00:26:31.100 --> 00:26:34.860]   understand everything you can do with data sets. If you look at
[00:26:34.860 --> 00:26:38.220]   the documentation, it's pretty amazing. There's, there's a lot
[00:26:38.220 --> 00:26:41.340]   of things you can do. And there's a lot of reasons to work
[00:26:41.340 --> 00:26:45.300]   with a data set object. And so part of it is just me kind of
[00:26:45.300 --> 00:26:50.700]   learning how to do more with the library. And what I and so forth
[00:26:50.700 --> 00:26:54.140]   what I don't know what to do, I typically fall back to building
[00:26:54.140 --> 00:27:01.340]   a data frame. And it's actually really easy. If you pull up a
[00:27:01.340 --> 00:27:08.300]   data set object or a data set dictionary, and you call set
[00:27:08.300 --> 00:27:12.260]   format to pandas, it's not really changing this, these are
[00:27:12.260 --> 00:27:15.420]   arrow files. And we'll talk about that in just a second what
[00:27:15.420 --> 00:27:19.620]   that is and why they're nice to use. It doesn't change the
[00:27:19.620 --> 00:27:23.420]   underlying format of the data set dictionary, it basically
[00:27:23.420 --> 00:27:28.620]   just allows us to access it as if it was a data frame. And so
[00:27:28.620 --> 00:27:33.740]   you can see that once you call set format, if we go back and
[00:27:33.740 --> 00:27:40.460]   pull three examples from the from the training set, that once
[00:27:40.460 --> 00:27:43.100]   we pull these, they act like a data frame. So we could call
[00:27:43.100 --> 00:27:47.860]   like dot head here and actually see the three examples. And
[00:27:47.860 --> 00:27:50.620]   then we can do cool things. So you know, when you get a data
[00:27:50.620 --> 00:27:53.580]   set, one of the things like for sequence classification is you
[00:27:53.580 --> 00:27:56.340]   want to look at the labels. And especially if you're
[00:27:56.340 --> 00:28:00.140]   experimenting, you want to make sure that you have a good set
[00:28:00.140 --> 00:28:06.500]   of, of all the labels that you're trying to predict. And so
[00:28:06.500 --> 00:28:10.180]   you want to do things like be able to call value counts. And
[00:28:10.180 --> 00:28:12.740]   it's really easy. Once you have a data frame, you have to use
[00:28:12.740 --> 00:28:18.540]   the slicing to get the entire data set as a data frame, then
[00:28:18.540 --> 00:28:22.340]   we go to label attribute called value counts and ensure that we
[00:28:22.340 --> 00:28:26.860]   actually have some labels. And if you recall, I told you
[00:28:26.860 --> 00:28:30.300]   there's one thing to be aware of when you're loading a data set
[00:28:30.300 --> 00:28:33.980]   is that there might be a temptation, you can actually
[00:28:33.980 --> 00:28:38.340]   construct a load data set call, so that you only get a subset
[00:28:38.380 --> 00:28:42.540]   of the training set, let's say, which you think that's great for
[00:28:42.540 --> 00:28:46.340]   experimentation, the data downloads faster, you're only
[00:28:46.340 --> 00:28:51.540]   getting maybe, you know, 10% of the examples. But one of the
[00:28:51.540 --> 00:28:55.140]   things that happens a lot is that these data sets, the labels
[00:28:55.140 --> 00:28:58.900]   are ordered. So that if you get a subset of the training set,
[00:28:58.900 --> 00:29:02.940]   let's say, you might actually not get all the labels included
[00:29:02.940 --> 00:29:07.780]   in your data set. And so I'll show you the way that I create
[00:29:07.780 --> 00:29:10.660]   subsets for experimentation, but it's just something to watch,
[00:29:10.660 --> 00:29:15.460]   watch out for. These labels are the examples, in many cases,
[00:29:15.460 --> 00:29:20.460]   aren't randomly placed. And so if you get a small subset, you
[00:29:20.460 --> 00:29:24.020]   actually may miss some of the labels when doing classification
[00:29:24.020 --> 00:29:30.980]   tasks. But yes, once you have it, if you want to do this set
[00:29:30.980 --> 00:29:36.620]   format and slicing in one line, as I showed earlier, you can
[00:29:36.620 --> 00:29:40.780]   just take a data set object called two pandas, and you'll
[00:29:40.780 --> 00:29:45.740]   get a data frame. And again, what I tend to do, since I'm
[00:29:45.740 --> 00:29:50.060]   more comfortable in the data frame world is I do here, I go
[00:29:50.060 --> 00:29:56.140]   here to actually do any type of feature engineering. And you
[00:29:56.140 --> 00:29:59.900]   can see just as an example, if I wanted to add a column, and
[00:29:59.900 --> 00:30:05.460]   then bring this back into a new data set, the new column shows
[00:30:05.460 --> 00:30:11.580]   up here. So really nice interchange with pandas and
[00:30:11.580 --> 00:30:18.660]   data sets. And then after you're done working with a data set in
[00:30:18.660 --> 00:30:22.220]   the pandas format, it's recommended that you call reset
[00:30:22.220 --> 00:30:27.420]   format. If you don't, and you're using the data set map method to
[00:30:27.420 --> 00:30:32.500]   do tokenization, you may run into some issues. So just be
[00:30:32.500 --> 00:30:39.420]   aware to call reset format once you're done with that. And you
[00:30:39.420 --> 00:30:42.420]   might be asking yourself at this point, if you haven't got to the
[00:30:42.420 --> 00:30:49.060]   course, why use data sets. And there's actually two really big
[00:30:49.060 --> 00:30:57.300]   reasons. And I've hit both of them in my work. And, and the
[00:30:57.300 --> 00:31:02.220]   first is that these are in an arrow format. So it's an it's
[00:31:02.220 --> 00:31:05.020]   these data sets are a memory map file, which means that when
[00:31:05.020 --> 00:31:09.100]   you're working with the elements in a data set, you don't have to
[00:31:09.100 --> 00:31:18.020]   load them all into memory. And so you have so and also it
[00:31:18.020 --> 00:31:21.740]   allows you to do multi processing. So if you look at
[00:31:21.740 --> 00:31:26.420]   the data set dot map method, you'll see that we can tokenize
[00:31:26.420 --> 00:31:32.540]   things in batches really quickly. And it's because of how
[00:31:32.540 --> 00:31:37.940]   these data sets are stored. And I and I've actually had issues
[00:31:37.940 --> 00:31:41.660]   where I'm loading data set and I just run out of RAM. And if you
[00:31:41.660 --> 00:31:46.180]   look at the, the course, they actually show you how to look at
[00:31:46.180 --> 00:31:49.140]   how much RAM you're using. And you could play around with
[00:31:49.140 --> 00:31:52.580]   loading a data frame and saying how much RAM that's consuming
[00:31:52.580 --> 00:31:55.700]   versus the data set. And it's really amazing just how
[00:31:55.700 --> 00:32:01.340]   efficient these arrow files are. And again, it's because they're
[00:32:01.340 --> 00:32:05.620]   not loading everything into RAM, they're actually just loading it
[00:32:05.620 --> 00:32:11.100]   as you need it. And so check out some of the blog posts by
[00:32:11.100 --> 00:32:17.860]   deejan simmicks. He has actually a post talking about how the
[00:32:17.860 --> 00:32:22.660]   Apache arrow format works, and how it compares to pandas. And
[00:32:22.660 --> 00:32:28.980]   for anybody that's loaded, big data sets, you'll know how, how
[00:32:28.980 --> 00:32:33.860]   much RAM utilization can skyrocket. And then Westman
[00:32:33.860 --> 00:32:38.940]   Kenny has this rule of thumb that you typically need five to
[00:32:38.940 --> 00:32:43.100]   10 times as much RAM as the size of your data set. And so that's
[00:32:43.100 --> 00:32:47.020]   one of the first reasons to consider using data sets for
[00:32:47.020 --> 00:32:52.820]   pre processing and actually training your models. A second
[00:32:52.820 --> 00:32:58.420]   one, especially if you're building language models, or
[00:32:58.420 --> 00:33:02.820]   just have really just huge data sets for whatever reason, is you
[00:33:02.820 --> 00:33:08.260]   can actually stream these data sets. And not all of them are
[00:33:08.260 --> 00:33:11.860]   streamable. I don't know if there's an easy way to find out
[00:33:11.900 --> 00:33:17.460]   in the hub. But if you add streaming is equals true,
[00:33:17.460 --> 00:33:21.820]   you'll be able to stream it. And you'll access the stream data
[00:33:21.820 --> 00:33:25.060]   set kind of like how you access data loaders by using an
[00:33:25.060 --> 00:33:28.940]   iterator. And so check out the documentation. And of course,
[00:33:28.940 --> 00:33:32.980]   there's actually some examples of not just streaming a single
[00:33:32.980 --> 00:33:36.700]   data set, but combining multiple streams. And if you're working
[00:33:36.700 --> 00:33:40.940]   with really significantly sized data sets, definitely something
[00:33:40.940 --> 00:33:44.860]   to look at. Again, how you access the data and how you
[00:33:44.860 --> 00:33:49.340]   pre process it is a little bit different. So check out the
[00:33:49.340 --> 00:33:53.820]   streaming data set section in the course, if you're interested
[00:33:53.820 --> 00:34:00.100]   in doing that. Any questions on the why of data sets?
[00:34:00.100 --> 00:34:09.140]   There's a general question by Turca. So is Colab good enough
[00:34:09.140 --> 00:34:12.740]   for data sets? Or do you need like a special server? Like, do
[00:34:12.740 --> 00:34:14.980]   you have a rule of thumb for that? When do you use Colab?
[00:34:14.980 --> 00:34:17.020]   And when does that gap out?
[00:34:17.020 --> 00:34:23.020]   So I don't have a good rule of thumb myself. I think if you run
[00:34:23.020 --> 00:34:26.380]   out of space, obviously, that's the time to explore something
[00:34:26.380 --> 00:34:32.500]   else. I typically do a lot of my work in my machine learning
[00:34:32.500 --> 00:34:37.980]   work, and also my development of blur, I have a local DL rig. And
[00:34:38.020 --> 00:34:41.700]   I do most of my work there because I have like a couple
[00:34:41.700 --> 00:34:46.020]   terabytes worth of data. So I can put a lot of, you know, data
[00:34:46.020 --> 00:34:49.780]   on there to work with locally. It's not the most amazing
[00:34:49.780 --> 00:34:54.220]   machines, not one of Sanyam's, you know, amazing GPUs and all
[00:34:54.220 --> 00:34:58.980]   the RGBs. But and I'm using basically I have like a 1080 Ti
[00:34:58.980 --> 00:35:03.580]   that I still train a lot of this stuff on and it works great. I
[00:35:03.580 --> 00:35:07.260]   think if you're comfortable using Colab, use it until you
[00:35:07.260 --> 00:35:10.820]   can't. And that that would probably be my advice. And if
[00:35:10.820 --> 00:35:13.900]   you're getting really big, then you may want to explore, you
[00:35:13.900 --> 00:35:17.300]   know, using some other cloud options or a local DL machine.
[00:35:17.300 --> 00:35:22.140]   Sanyam Bhutani: Awesome. Thanks for that. Yep, this I think this
[00:35:22.140 --> 00:35:25.460]   comes from Jeremy, right? He always tells us advice, just use
[00:35:25.460 --> 00:35:28.100]   whatever you have until you run out of it and then figure out
[00:35:28.100 --> 00:35:31.420]   that but you don't want to be like an IT admin because like
[00:35:31.420 --> 00:35:34.620]   once you have a local rig, half of your job is just to like,
[00:35:34.740 --> 00:35:39.500]   keep it up to whatever. Yeah, version of the framework is out
[00:35:39.500 --> 00:35:39.740]   there.
[00:35:39.740 --> 00:35:41.780]   Jason Tucker: And we're gonna show I'm gonna show you all in a
[00:35:41.780 --> 00:35:45.860]   second how to create subsets for experimentation. So that's another
[00:35:45.860 --> 00:35:49.180]   kind of best practice with just machine learning in general is
[00:35:49.180 --> 00:35:51.940]   don't waste your time downloading these huge data sets
[00:35:51.940 --> 00:35:55.500]   and pre processing them just to find out you're doing it wrong.
[00:35:55.500 --> 00:36:00.700]   It will not be pleasurable. And I see a question about SageMaker
[00:36:00.700 --> 00:36:02.780]   lab. There's actually
[00:36:02.780 --> 00:36:04.340]   Sanyam Bhutani: that was the one I just asked.
[00:36:04.340 --> 00:36:06.780]   Jason Tucker: Okay, yeah, I haven't played with SageMaker
[00:36:06.780 --> 00:36:12.500]   lab yet. There's an article by Benjamin, I forget his last
[00:36:12.500 --> 00:36:16.660]   name. And he compared those maybe I'll find it and share it
[00:36:16.660 --> 00:36:20.460]   on the website, but actually compared his experience using
[00:36:20.460 --> 00:36:25.300]   SageMaker lab with Colab and Colab Pro. And actually using
[00:36:25.300 --> 00:36:30.420]   fast AI and blur with hugging face. So I'll find that we'll
[00:36:30.420 --> 00:36:31.980]   see if we can post that somewhere else.
[00:36:32.980 --> 00:36:35.860]   Sanyam Bhutani: Thank you. I will again email the link to
[00:36:35.860 --> 00:36:38.700]   everyone who's watching right now or we'll just post it on
[00:36:38.700 --> 00:36:42.500]   Twitter. Is it necessary to complete part one of the course?
[00:36:42.500 --> 00:36:45.140]   It's not necessary. You're welcome to join still.
[00:36:45.140 --> 00:36:47.900]   Jason Tucker: Yeah, we won't kick you out. But it would be
[00:36:47.900 --> 00:36:50.780]   helpful probably to get the overview. You're sure.
[00:36:50.780 --> 00:36:55.940]   Sanyam Bhutani: Have you tried using hugging face data sets
[00:36:55.940 --> 00:36:58.540]   with non language data like time series?
[00:36:59.740 --> 00:37:04.740]   Jason Tucker: I haven't done anything outside of NLP tasks.
[00:37:04.740 --> 00:37:09.540]   And I'm not sure if it supports time series tasks. I know it
[00:37:09.540 --> 00:37:15.220]   does with vision and like speech and audio. So the answer is no.
[00:37:15.220 --> 00:37:19.460]   Sanyam Bhutani: Awesome. I want to share another advice. One
[00:37:19.460 --> 00:37:22.020]   thing like I learned the hard way I'm sure people are smarter
[00:37:22.020 --> 00:37:26.460]   than this. But on the rule of thumb of having five times the
[00:37:26.460 --> 00:37:28.900]   memory of your data set. I remember I was working on this
[00:37:28.900 --> 00:37:33.580]   Kaggle competition title, Microsoft malware. And before I
[00:37:33.580 --> 00:37:36.820]   typed a teamed up with like really smart people, I was just
[00:37:36.820 --> 00:37:42.020]   using the default pandas options, whatever they were. And
[00:37:42.020 --> 00:37:46.380]   this was like a small CSV file of I think like half a GB. And I
[00:37:46.380 --> 00:37:51.220]   was running out of swap that was 100 gigs because I wasn't
[00:37:51.220 --> 00:37:58.540]   converting them to I think. So by default, it's float 64. I
[00:37:58.540 --> 00:38:02.660]   wasn't converting them to simple integers. And that was just
[00:38:02.660 --> 00:38:05.300]   making the memory explodes. It's also helpful to do those
[00:38:05.300 --> 00:38:05.980]   conversions.
[00:38:05.980 --> 00:38:08.820]   Jason Tucker: Yeah. And so that's one of the things I
[00:38:08.820 --> 00:38:13.540]   learned really early on with fast AI is that start with small
[00:38:13.540 --> 00:38:17.820]   subsets and get all those things out of the way because I still
[00:38:17.820 --> 00:38:20.860]   make all kinds of dumb mistakes. Because you know, I'm trying to
[00:38:20.860 --> 00:38:24.900]   like do tons of things from full stack web, to building blur to
[00:38:24.900 --> 00:38:28.820]   doing just other machine learning work. So it's amazing
[00:38:28.820 --> 00:38:33.100]   how much I forget I go back to doing things I repeat the same
[00:38:33.100 --> 00:38:38.060]   dumb stuff. And it's a lot more efficient to repeat the dumb
[00:38:38.060 --> 00:38:42.460]   stuff on a small set of data than the whole thing for sure.
[00:38:42.460 --> 00:38:46.660]   Sanyam Bhutani: I'll squeeze in another question. Do you have
[00:38:46.660 --> 00:38:50.340]   any other tricks for reducing training time like when you
[00:38:50.340 --> 00:38:51.780]   try to actively prototype?
[00:38:52.220 --> 00:38:56.020]   Jason Tucker: Sure. So the biggest one is just working with
[00:38:56.020 --> 00:39:00.340]   a subset of data that's fairly representative of the data that
[00:39:00.340 --> 00:39:04.540]   you're going to eventually want to really train your model on.
[00:39:04.540 --> 00:39:08.980]   There's also some callbacks and fast AI. So there's a callback
[00:39:08.980 --> 00:39:12.940]   night, I'm going to get the name wrong, but it's like the short
[00:39:12.940 --> 00:39:17.580]   epoch callback. And essentially, what you can do is start
[00:39:17.580 --> 00:39:21.740]   training an epoch worth of data, and just say, Hey, only train
[00:39:21.740 --> 00:39:27.700]   for 1000 steps or only change for 10 steps or for 5% of the
[00:39:27.700 --> 00:39:32.060]   time. And so when I actually build my tests in blur, and I'm
[00:39:32.060 --> 00:39:36.420]   trying to make blur so it works with the majority, if not all of
[00:39:36.420 --> 00:39:40.860]   the transformer NLP models you see on the hugging face that's
[00:39:40.860 --> 00:39:45.860]   supported by hugging face is I actually use that to iterate and
[00:39:45.860 --> 00:39:49.380]   just make sure that yeah, I can go ahead and train these models
[00:39:49.380 --> 00:39:53.260]   without having to, you know, wait 30 minutes for some of
[00:39:53.260 --> 00:39:57.620]   these bigger models to actually, you know, complete an epoch. So
[00:39:57.620 --> 00:40:01.180]   those are my two probably biggest pieces of advice. And,
[00:40:01.180 --> 00:40:04.780]   and again, we're gonna look at in just a second is actually how
[00:40:04.780 --> 00:40:07.860]   to create a good subset of data to do that.
[00:40:07.860 --> 00:40:11.700]   Sanyam Bhutani: Awesome. I think that was the last question.
[00:40:11.700 --> 00:40:12.420]   So please continue.
[00:40:12.980 --> 00:40:18.660]   Cool. So just want to highlight and these slides in the notebook
[00:40:18.660 --> 00:40:23.580]   will be made available after today's study session. But I
[00:40:23.580 --> 00:40:26.620]   want to highlight some of the things you can do with the data
[00:40:26.620 --> 00:40:30.940]   sets library. And these are things that I find myself doing
[00:40:30.940 --> 00:40:34.260]   all the time. And again, if you look at the documentation,
[00:40:34.260 --> 00:40:38.420]   there's just tons of things that you can do without resorting to
[00:40:38.420 --> 00:40:43.540]   pandas. So I just include some examples about working with
[00:40:43.540 --> 00:40:47.020]   specific rows and data set, you can go ahead and grab specific
[00:40:47.020 --> 00:40:52.220]   indices. If you're renaming and removing columns, and this is a
[00:40:52.220 --> 00:40:55.860]   common practice when you look at the course, because when you
[00:40:55.860 --> 00:41:00.500]   actually feed things into their trainer API, or you create your
[00:41:00.500 --> 00:41:06.140]   own pytorch loop, and or using their accelerator prod product,
[00:41:06.980 --> 00:41:12.220]   you need to remove columns that you don't want to feed into your
[00:41:12.220 --> 00:41:16.060]   model. Whereas with blur, these things are you can keep these
[00:41:16.060 --> 00:41:19.780]   things in your data sets. And they're simply removed when you
[00:41:19.780 --> 00:41:25.620]   actually call the forward method of your model automatically. So
[00:41:25.620 --> 00:41:28.020]   some of these things, when you go through the course, you don't
[00:41:28.020 --> 00:41:32.180]   need to do a lot of the cleanup with blur that you have to do if
[00:41:32.180 --> 00:41:36.940]   you're using the trainer API or your own pytorch training loop.
[00:41:37.780 --> 00:41:42.060]   So anyways, yeah, so there's super easy to rename remove
[00:41:42.060 --> 00:41:48.460]   columns. There's a couple ways to add columns. If you are
[00:41:48.460 --> 00:41:51.780]   actually using the map method, and you're passing in one
[00:41:51.780 --> 00:41:56.500]   example at a time, you can just simply return a dictionary with
[00:41:56.500 --> 00:42:01.940]   the new column, and whatever you want that to be. If you're
[00:42:01.940 --> 00:42:06.620]   working with the Drake, the the data set, and just want to add a
[00:42:06.620 --> 00:42:11.300]   column, then like, one of the things in fast AI, which we'll
[00:42:11.300 --> 00:42:14.740]   see in a second is that fast AI typically wants your training
[00:42:14.740 --> 00:42:20.100]   and validation data and a single data set. And one of the most
[00:42:20.100 --> 00:42:24.380]   common ways to do that and indicate what examples should be
[00:42:24.380 --> 00:42:28.460]   part of your validation versus your training is to simply add a
[00:42:28.460 --> 00:42:34.060]   is valid attribute and set it to true for the training, the I'm
[00:42:34.060 --> 00:42:38.540]   sorry, for the validation set, and false for the training data
[00:42:38.540 --> 00:42:45.140]   set. And you can do that with add column, specify a new key.
[00:42:45.140 --> 00:42:48.940]   And then here, this is just an example. And this should
[00:42:48.940 --> 00:42:53.860]   actually be valid or validation. Yes, I say true times the length
[00:42:53.860 --> 00:42:58.780]   of the data set. And that will create a new attribute in this
[00:42:58.780 --> 00:43:04.220]   data set, where is valid is set to true. So these are really
[00:43:04.220 --> 00:43:08.740]   helpful. For pre processing. Again, a lot of the things that
[00:43:08.740 --> 00:43:13.340]   you can do in pandas, you can do more efficiently in data sets,
[00:43:13.340 --> 00:43:18.860]   because of the arrow format. And here's a few examples of, for
[00:43:18.860 --> 00:43:23.220]   example, if you're normalizing your data, need to remove nulls
[00:43:23.780 --> 00:43:30.420]   need to lowercase all your text. This is a helpful one, if you
[00:43:30.420 --> 00:43:34.340]   need to remove examples that are too small. And so when you're
[00:43:34.340 --> 00:43:38.540]   doing a lot of NLP work, if the text you're looking at, so in
[00:43:38.540 --> 00:43:41.980]   the course they have looking at this data set, they have a
[00:43:41.980 --> 00:43:46.340]   review length attribute. If it's too small, you may want to get
[00:43:46.340 --> 00:43:50.500]   rid of it, because there may not be enough helpful information to
[00:43:50.500 --> 00:43:55.740]   really use in whatever task you're trying to do. And this is
[00:43:55.740 --> 00:43:57.740]   also from the documentation, this is actually a really cool
[00:43:57.740 --> 00:44:03.420]   example of removing HTML. So if we import HTML package and call
[00:44:03.420 --> 00:44:07.820]   an escape, we can go ahead and clean up our reviews. And you'll
[00:44:07.820 --> 00:44:11.100]   see a lot of data sets have a lot of HTML artifacts in there.
[00:44:11.100 --> 00:44:15.260]   And so this is actually a nice little piece of code that I
[00:44:15.260 --> 00:44:19.220]   think you'll find helpful. And then another nice thing when
[00:44:19.220 --> 00:44:24.860]   you're using data sets is this map method, and the ability to
[00:44:24.860 --> 00:44:28.540]   pass your examples into a function, but instead of just
[00:44:28.540 --> 00:44:34.180]   one at a time to pass them in batches. And if you play around
[00:44:34.180 --> 00:44:38.020]   with setting this true or false, you'll see like it makes a
[00:44:38.020 --> 00:44:41.500]   really significant difference in how fast you're pre processing.
[00:44:41.500 --> 00:44:45.980]   And in particular, things like tokenization are when you set
[00:44:45.980 --> 00:44:49.820]   batch equal to true. The only thing to remember is that when
[00:44:49.820 --> 00:44:54.380]   you do that, and so again, we're calling map with batch equal
[00:44:54.380 --> 00:44:58.020]   true, and that's going to call a function is that it's not going
[00:44:58.020 --> 00:45:02.540]   to pass in an example at a time, it's going to pass in a
[00:45:02.540 --> 00:45:07.940]   dictionary. And the dictionary is going to so by default 1000
[00:45:07.940 --> 00:45:11.780]   examples at a time, the dictionary is going to have,
[00:45:11.780 --> 00:45:16.260]   let's say there's three attributes, ID, text and label,
[00:45:16.260 --> 00:45:19.060]   you're going to get a dictionary, and it's going to
[00:45:19.060 --> 00:45:23.500]   have those three keys. And for each key is going to have the
[00:45:23.500 --> 00:45:29.860]   values of all 1000 examples that are passed in there. And so how
[00:45:29.860 --> 00:45:34.100]   you access the examples and work your data is going to be a
[00:45:34.100 --> 00:45:38.540]   little bit different when you use batched equals true. And so
[00:45:38.540 --> 00:45:41.100]   you can see here, assuming that that should equal true in this
[00:45:41.100 --> 00:45:50.020]   example, instead of just setting the value of an example of the
[00:45:50.020 --> 00:45:53.740]   review value, we have to actually iterate over all of the
[00:45:53.740 --> 00:45:58.260]   review values. So this will be all 1000 review values for the
[00:45:58.260 --> 00:46:03.940]   1000 examples that are passed in and call unescape and then set
[00:46:03.940 --> 00:46:07.060]   review equal to that. So it's a little bit different, but
[00:46:07.060 --> 00:46:10.660]   definitely, this is the preferred approach when you're
[00:46:10.660 --> 00:46:15.020]   doing pre processing is to handle the batch fashion as much
[00:46:15.020 --> 00:46:22.460]   as possible. So data frames, we already talked about this at
[00:46:22.460 --> 00:46:25.900]   length. And so I'm not going to spend too much time on this
[00:46:25.900 --> 00:46:30.100]   slide, just be aware that you can dip in and out of using
[00:46:30.100 --> 00:46:36.020]   pandas. And for me, I'm a pandas guy. So I know how to do a lot
[00:46:36.020 --> 00:46:38.500]   there. So I typically go down there. And as I read the
[00:46:38.500 --> 00:46:42.660]   documentation, find out how to do things in data sets, I try to
[00:46:42.660 --> 00:46:46.380]   do more in data sets, but just know you can go back and forth.
[00:46:46.380 --> 00:46:53.340]   Alright, so let's go ahead and look at how to actually use some
[00:46:53.340 --> 00:47:00.980]   of this stuff with fast AI. And let me reconnect. All right.
[00:47:03.860 --> 00:47:07.660]   Okay. So one of the things I mentioned earlier is that I'm
[00:47:07.660 --> 00:47:11.460]   actually working on a version two upgrade of blur that's going
[00:47:11.460 --> 00:47:20.300]   to break some things. So when you are using the the dev 2.0
[00:47:20.300 --> 00:47:25.500]   branch, you can do a pip install in Colab using the syntax, and
[00:47:25.500 --> 00:47:29.300]   just put at and then your branch name. And this will install the
[00:47:29.340 --> 00:47:34.500]   latest build of the version two bits. And it's a work in
[00:47:34.500 --> 00:47:40.900]   progress. So things may break if you're using it for other tasks.
[00:47:40.900 --> 00:47:45.100]   And for folks, if you encounter those things, let me know. If
[00:47:45.100 --> 00:47:48.020]   you want to help contribute and work on some of this stuff, let
[00:47:48.020 --> 00:47:51.980]   me know I would love to help. But for the purpose of this
[00:47:51.980 --> 00:47:57.660]   study group is install the blur bits like this. My goal is at
[00:47:57.660 --> 00:48:02.180]   the conclusion of the course to have a build that is ready for
[00:48:02.180 --> 00:48:07.140]   public release. And then once you install version two of
[00:48:07.140 --> 00:48:11.140]   blurred, we're going to go ahead and import some of the things
[00:48:11.140 --> 00:48:14.740]   that you've probably seen before if you use blurred to train fast
[00:48:14.740 --> 00:48:19.980]   AI models. And again, one of the things we talked about is we
[00:48:19.980 --> 00:48:24.100]   want to create a subset for experimentation. And so I'm going
[00:48:24.100 --> 00:48:28.140]   to go ahead and start with building a simple sequence
[00:48:28.140 --> 00:48:31.740]   classification model for IMDB. So we're just looking at movie
[00:48:31.740 --> 00:48:34.980]   reviews, they're positive or negative. But we're going to
[00:48:34.980 --> 00:48:38.140]   instead of loading this from the fast AI data sets, we're going
[00:48:38.140 --> 00:48:43.180]   to go ahead and load this from the hugging face hub using load
[00:48:43.180 --> 00:48:47.660]   data set. And for this purpose, I'm just going to pull the
[00:48:47.660 --> 00:48:51.380]   training set. So if you look at the documentation, as I
[00:48:51.380 --> 00:48:55.340]   mentioned, there's all kinds of ways to configure what subset
[00:48:55.340 --> 00:48:59.140]   you want and how much you want from each subset. For
[00:48:59.140 --> 00:49:02.780]   experimentation, I find it nice just to be able to get the
[00:49:02.780 --> 00:49:08.460]   training split and work with that until I have something that
[00:49:08.460 --> 00:49:13.540]   I know is working. And so we can see that this gives us this
[00:49:13.540 --> 00:49:17.180]   particular data set notice, because we're getting a specific
[00:49:17.180 --> 00:49:19.660]   split, we're not getting a data set dictionary, we're getting a
[00:49:19.660 --> 00:49:26.580]   data set object. And from here, we can use this train test split
[00:49:26.580 --> 00:49:33.180]   to manufacture a test or validation data set. And it
[00:49:33.180 --> 00:49:37.900]   works very similar to how scikit learns method works. So this
[00:49:37.900 --> 00:49:41.380]   should be fairly familiar to most folks. But you can see by
[00:49:41.380 --> 00:49:45.500]   taking this single data set, I can go ahead and split it into a
[00:49:45.500 --> 00:49:50.700]   train and test. And you can specify the ratio of test
[00:49:50.700 --> 00:49:57.140]   examples to our validation examples to train. And then I'm
[00:49:57.140 --> 00:50:01.980]   going to simply rename the test set validation, just because
[00:50:01.980 --> 00:50:07.060]   that's how I think of these. That's how I think in terms of
[00:50:07.060 --> 00:50:11.820]   how the sets can be used as a validation set, not as a tier
[00:50:11.820 --> 00:50:15.340]   test set, which is a holdout set for after you actually have
[00:50:15.340 --> 00:50:20.220]   trained your model. And then we can actually use the data sets
[00:50:20.220 --> 00:50:26.500]   library to do some interesting things with it. So one thing
[00:50:26.500 --> 00:50:30.420]   since I mentioned in the fast AI world, you typically want to put
[00:50:30.420 --> 00:50:34.620]   your training and validation set into a single data set and have
[00:50:34.620 --> 00:50:39.020]   some indication of which examples are for validation and
[00:50:39.020 --> 00:50:44.860]   which are for train. And you can do that through using indices,
[00:50:44.860 --> 00:50:48.540]   you can use that, you can do that also by adding something
[00:50:48.540 --> 00:50:52.900]   like I'm doing here, which is a is valid attribute. And
[00:50:52.900 --> 00:50:57.940]   essentially, what I want to do is have it so that if the
[00:50:57.940 --> 00:51:01.140]   examples part of the validation set is valid is true, but as
[00:51:01.140 --> 00:51:04.620]   part of the training set is valid is false. So I create this
[00:51:04.620 --> 00:51:07.860]   little method and I have two of them here so that you can go
[00:51:07.860 --> 00:51:11.420]   back to this notebook and see how you should structure things
[00:51:11.420 --> 00:51:14.940]   depending on whether you're going to be using calling this
[00:51:14.940 --> 00:51:18.900]   with map and passing a batch of examples, which is this batch
[00:51:18.900 --> 00:51:22.580]   friendly one, or if you're passing one example at a time.
[00:51:22.580 --> 00:51:25.500]   And I really encourage you to actually explore looking at this
[00:51:25.500 --> 00:51:28.660]   and you'll be able to see the speed difference just visually
[00:51:28.660 --> 00:51:33.660]   in terms of how quickly this one work compared to this one even
[00:51:33.660 --> 00:51:39.100]   for a small, relatively small data set. And so calling map,
[00:51:39.180 --> 00:51:44.340]   also using partial, which is part of the func tools package.
[00:51:44.340 --> 00:51:47.500]   And essentially what you can do with partial if you haven't seen
[00:51:47.500 --> 00:51:52.140]   before really common to see this in the fast AI code is you pass
[00:51:52.140 --> 00:51:58.380]   the name of your method. And then you could go ahead and
[00:51:58.380 --> 00:52:04.020]   specify what the values of the arguments, anyone said that you
[00:52:04.020 --> 00:52:07.540]   want to change using partial, and it returns the function
[00:52:07.540 --> 00:52:11.820]   object. But now is valid is set to false in processing my
[00:52:11.820 --> 00:52:18.140]   training. And it's set to true when processing my validation
[00:52:18.140 --> 00:52:22.460]   data set. So take a look at that. And you can see that once
[00:52:22.460 --> 00:52:25.900]   this runs, it runs really quick. So some use in the batch
[00:52:25.900 --> 00:52:30.060]   friendly approach here. And you can see that now I have a new
[00:52:30.060 --> 00:52:34.060]   feature called is valid in both my training and validation set.
[00:52:35.300 --> 00:52:37.900]   And then I can go ahead and actually pull up an example and
[00:52:37.900 --> 00:52:41.780]   see like, okay, there's that is valid attribute is false. So
[00:52:41.780 --> 00:52:47.860]   everything looks good. So once you have your training and
[00:52:47.860 --> 00:52:53.780]   validation data sets, good to go. Again, you want to be able
[00:52:53.780 --> 00:52:59.540]   to work with a subset of data. And this is just to primarily
[00:52:59.540 --> 00:53:02.340]   for experimentation, or if you're doing a blog post, and
[00:53:02.340 --> 00:53:05.420]   you want to demo something to somebody, so that you're not
[00:53:05.420 --> 00:53:10.260]   waiting around for hours for things to train or hours just to
[00:53:10.260 --> 00:53:14.460]   find out that you're casting, you're trying to cast a string
[00:53:14.460 --> 00:53:19.020]   to a float, and that's not going to work. And so with the
[00:53:19.020 --> 00:53:21.860]   data sets library, some really helpful methods is you can
[00:53:21.860 --> 00:53:26.060]   actually shuffle the data for the validation, I don't really
[00:53:26.060 --> 00:53:31.660]   need to use that here. But we can shuffle the training set.
[00:53:31.660 --> 00:53:37.700]   And I can say, hey, I just want to select the first 1000
[00:53:37.700 --> 00:53:41.740]   examples of the shuffle data set. For validation, I want to
[00:53:41.740 --> 00:53:47.980]   just select the first 200. And if we look at this, and we
[00:53:47.980 --> 00:53:53.180]   create now another data set object, right a sample for
[00:53:53.180 --> 00:53:57.940]   training validation, we can see that we have now a smaller
[00:53:57.940 --> 00:54:02.220]   subset of the data to experiment with. So this is
[00:54:02.220 --> 00:54:08.580]   really, essentially the code you want to use when you're
[00:54:08.580 --> 00:54:12.700]   experimenting and creating a small sample, just to test
[00:54:12.700 --> 00:54:19.220]   things out. And again, we then want to take this training and
[00:54:19.220 --> 00:54:23.380]   validation set and put it into a single data set for us to feed
[00:54:23.380 --> 00:54:30.180]   through our fast AI data and training code. And fortunately,
[00:54:30.180 --> 00:54:33.540]   with Hugging Face, it's really simple, we can go ahead and use
[00:54:33.540 --> 00:54:38.580]   this concatenate data sets, pass a list of the data sets
[00:54:38.580 --> 00:54:42.340]   that we want to put into a single data set. And you can see
[00:54:42.340 --> 00:54:46.060]   that now so we have 1000 training examples, 200
[00:54:46.100 --> 00:54:50.140]   validation examples. Now you can see they're all here in this
[00:54:50.140 --> 00:54:54.260]   proc underscore ds. And now that everything's in a single data
[00:54:54.260 --> 00:55:02.980]   set, we can actually use it for working with fast AI. So one of
[00:55:02.980 --> 00:55:06.820]   the changes that I've made to blur is, as I mentioned earlier
[00:55:06.820 --> 00:55:11.460]   is that with these Hugging Face data set objects, or data sets,
[00:55:11.700 --> 00:55:17.820]   is that the labels are typically the indexes of the names
[00:55:17.820 --> 00:55:22.020]   attribute that we saw. And so when you actually do like show
[00:55:22.020 --> 00:55:27.220]   batch and show results, you see 0123, whatever. So one of the
[00:55:27.220 --> 00:55:31.380]   changes I made in version two of blur is being able to pass the
[00:55:31.380 --> 00:55:37.820]   labels so that when you're showing and predicting things
[00:55:37.820 --> 00:55:41.740]   from your model, you actually can see the friendly label
[00:55:41.740 --> 00:55:46.060]   rather than the unfriendly integer index into the label
[00:55:46.060 --> 00:55:49.940]   names. So we're going to pull these up here. So we do
[00:55:49.940 --> 00:55:55.300]   classification, we need to be able to tell our Hugging Face
[00:55:55.300 --> 00:56:01.060]   configuration and model how many labels it's expected to
[00:56:01.060 --> 00:56:05.300]   predict. And so again, we can use this feature attribute on
[00:56:05.300 --> 00:56:08.060]   labels and get the names. So here we just have negative or
[00:56:08.060 --> 00:56:13.780]   positive. Then I'm going to use blur and if you haven't used
[00:56:13.780 --> 00:56:17.100]   blur before, I hope this is pretty straightforward, you can
[00:56:17.100 --> 00:56:21.820]   check the documentation. There's examples in the documentation
[00:56:21.820 --> 00:56:25.340]   and other people have actually used blur and put it in blog
[00:56:25.340 --> 00:56:30.780]   posts and probably said things a lot more explanatory than I
[00:56:30.780 --> 00:56:35.060]   make them sometimes. But what we can do is use this utility
[00:56:35.100 --> 00:56:39.780]   class, this blur class and call get Hugging Face objects. And
[00:56:39.780 --> 00:56:43.820]   you can pass a bunch of different things to it and get
[00:56:43.820 --> 00:56:50.020]   the architecture of the Hugging Face artifacts you're creating.
[00:56:50.020 --> 00:56:53.260]   So in this case, it would be Roberta since we're using a
[00:56:53.260 --> 00:56:57.260]   checkpoint, this Roberta based checkpoint, we get a Hugging
[00:56:57.260 --> 00:57:01.780]   Face configuration object, tokenizer and model. And also
[00:57:01.780 --> 00:57:03.780]   notice that we're passing in the number of labels, right?
[00:57:03.820 --> 00:57:06.220]   Because we're doing sequence classification, we have to tell
[00:57:06.220 --> 00:57:09.180]   it how many labels we're trying to predict. And we can print
[00:57:09.180 --> 00:57:13.140]   these things out and see, yep, those are exactly the objects
[00:57:13.140 --> 00:57:18.500]   that we expected. So how do we use this pre processed or this
[00:57:18.500 --> 00:57:22.180]   process data set from the data sets library that we just built?
[00:57:22.180 --> 00:57:27.500]   So new in version two is instead of just working with raw data on
[00:57:27.500 --> 00:57:33.260]   the fly, in version two, you can do the tokenization on the fly
[00:57:33.300 --> 00:57:36.540]   as you've done in version one. But you can also work with pre
[00:57:36.540 --> 00:57:39.940]   process data sets, which is kind of the more traditional format.
[00:57:39.940 --> 00:57:42.500]   And when you go through the course, that's typically the
[00:57:42.500 --> 00:57:46.820]   approach that the course takes, and that most folks would go
[00:57:46.820 --> 00:57:51.260]   through. And that means they're going to actually pre tokenize
[00:57:51.260 --> 00:57:56.780]   everything's create their input IDs, and all the other stuff
[00:57:56.780 --> 00:58:01.180]   ahead of time, and then pass that in to the model without the
[00:58:01.180 --> 00:58:05.220]   model having to worry about doing tokenization on the fly.
[00:58:05.220 --> 00:58:09.060]   And so you can do either approach. And so in version two,
[00:58:09.060 --> 00:58:12.420]   we have this pre processor pipeline. And for each task is
[00:58:12.420 --> 00:58:16.340]   going to be a task specific pre processor. And what this is
[00:58:16.340 --> 00:58:20.700]   going to do is based on a bunch of things you can pass to eat to
[00:58:20.700 --> 00:58:23.980]   each of these pre processor, pre processors, and they're
[00:58:23.980 --> 00:58:28.540]   different per task, it's going to actually create either a data
[00:58:28.540 --> 00:58:32.540]   set or a data frame. So you can call process HF data set or
[00:58:32.540 --> 00:58:37.980]   process data frame. And it's going to do the tokenization and
[00:58:37.980 --> 00:58:41.820]   whatever else you want done to the text. So you can do things
[00:58:41.820 --> 00:58:48.540]   like handle long texts by allowing an overflow mapping. So
[00:58:48.540 --> 00:58:52.620]   you can create multiple examples and break longer text and the
[00:58:52.620 --> 00:58:56.380]   model can handle in the chunks is going to handle things like
[00:58:56.380 --> 00:58:59.100]   that. And so you can see that once we run it through this
[00:58:59.100 --> 00:59:03.580]   pre processor, we actually have our input ideas, which is
[00:59:03.580 --> 00:59:09.180]   typically what what we have on the fly with blur one as each
[00:59:09.180 --> 00:59:14.260]   batch is being processed. And so with this pre process data set,
[00:59:14.260 --> 00:59:22.580]   we can actually now use this in a data block. And one of the
[00:59:22.580 --> 00:59:27.060]   things that we're doing with blur is, again, passing in that
[00:59:27.060 --> 00:59:33.300]   labels that we configured up here, so that we have the
[00:59:33.300 --> 00:59:37.700]   friendly label names instead of the ones and zeros when we use
[00:59:37.700 --> 00:59:43.140]   the fast AI show methods. And then also, we can't use the call
[00:59:43.140 --> 00:59:46.020]   splitter because we're using a data set, not a data frame. The
[00:59:46.020 --> 00:59:50.180]   call splitter is allows us to have a data frame with a column
[00:59:50.220 --> 00:59:54.620]   name is valid indicates true or false. But we can use the index
[00:59:54.620 --> 00:59:59.740]   splitter. And so this code right here is simply how I'm iterating
[00:59:59.740 --> 01:00:04.260]   through the data set. And I'm basically setting anything that
[01:00:04.260 --> 01:00:10.820]   is is valid equals to true as one of the validation examples.
[01:00:10.820 --> 01:00:15.820]   And you can see if we look at that we have 1200 examples, the
[01:00:15.820 --> 01:00:19.980]   last 200 are validation set, you can see that as a way for us to
[01:00:19.980 --> 01:00:25.060]   verify it's getting the right indices. And so from there, we
[01:00:25.060 --> 01:00:30.580]   can actually build a data block. And here I'm using item getter.
[01:00:30.580 --> 01:00:33.540]   So remember, we've already pre processed our data, we've
[01:00:33.540 --> 01:00:37.940]   already tokenized it. So we have our input IDs. And I'm going to
[01:00:37.940 --> 01:00:43.620]   pass that as our x, our y is going to be our label, our index
[01:00:43.620 --> 01:00:48.220]   splitter with our validation indexes. There's a lot of
[01:00:48.220 --> 01:00:53.700]   options, things you can do with blur. One of the objects I have
[01:00:53.700 --> 01:00:57.860]   is a text blocks, which will basically do just about
[01:00:57.860 --> 01:01:03.940]   everything to set up your data loaders in a way to be able to
[01:01:03.940 --> 01:01:08.420]   train it with fast AI. And I passing in our hugging face
[01:01:08.420 --> 01:01:13.020]   objects. And then this is a new addition with version two is I'm
[01:01:13.020 --> 01:01:16.900]   passing in pre tokenized. And this is going to tell blur, you
[01:01:16.900 --> 01:01:19.420]   don't need to do the tokenization on the fly, we
[01:01:19.420 --> 01:01:23.300]   already have the input IDs, you're good to go. And again,
[01:01:23.300 --> 01:01:27.980]   I'm passing in labels in my before batch quarks so that I
[01:01:27.980 --> 01:01:33.780]   get prettier show methods. Once you have this, we'll go ahead
[01:01:33.780 --> 01:01:40.260]   and pass our data set to our data block data loaders to get
[01:01:40.260 --> 01:01:44.660]   our data loaders. And you can see that when we call show batch,
[01:01:44.700 --> 01:01:49.300]   we don't get one zeros over here, we now get the actual name
[01:01:49.300 --> 01:01:55.580]   of the index that's included in the raw data. And so you can see
[01:01:55.580 --> 01:02:00.060]   that's all it takes really to build our data block and to get
[01:02:00.060 --> 01:02:05.380]   our data loaders in a format ready for training. And then to
[01:02:05.380 --> 01:02:09.300]   train it. Again, this is code straight from the documentation,
[01:02:09.300 --> 01:02:14.180]   we will go ahead and wrap our hugging face model in this base
[01:02:14.180 --> 01:02:18.140]   model wrapper. And this does a lot of the work of ensuring that
[01:02:18.140 --> 01:02:23.100]   only the things that the transformer model needs get fed
[01:02:23.100 --> 01:02:28.100]   into its forward method. And this again, is pretty much just
[01:02:28.100 --> 01:02:32.300]   straight fast AI code we passed, we use a learner, pass our data
[01:02:32.300 --> 01:02:37.860]   loaders, our model object, which is our wrapped transformer, what
[01:02:37.860 --> 01:02:41.500]   we want to do for optimization loss function metrics, just
[01:02:41.500 --> 01:02:45.940]   going to do accuracy, there's a necessary callback called the
[01:02:45.940 --> 01:02:51.020]   base model callback that knows how to handle the outputs from
[01:02:51.020 --> 01:02:56.740]   the transformer models. And then we also have a default
[01:02:56.740 --> 01:03:00.620]   splitter. And if you look at the documentation, you can see how
[01:03:00.620 --> 01:03:09.060]   that's essentially knows how there's certain ways that most
[01:03:09.060 --> 01:03:12.660]   transformer models are set up. And so based on that, we
[01:03:12.660 --> 01:03:15.220]   actually split those into different groups for
[01:03:15.220 --> 01:03:18.700]   discriminative learning purposes, or discriminative
[01:03:18.700 --> 01:03:22.260]   learning rates, I should say. And so it's going to create
[01:03:22.260 --> 01:03:28.660]   different parameter groups based on the actual architecture of
[01:03:28.660 --> 01:03:32.020]   the model that you're using. And you can see once you so once we
[01:03:32.020 --> 01:03:37.820]   have this, we can also convert this to FP 16, if we wanted to,
[01:03:38.820 --> 01:03:42.140]   but we now have a learner, we can call fit one cycle, we can
[01:03:42.140 --> 01:03:45.300]   use discriminative learning rates and trainless. And you can
[01:03:45.300 --> 01:03:48.780]   see for the subset, we get pretty good results, we can call
[01:03:48.780 --> 01:03:52.540]   show results. And actually, again, we're seeing the friendly
[01:03:52.540 --> 01:03:56.380]   labels because we included that when we created our data block.
[01:03:56.380 --> 01:04:03.380]   And I've cleaned up the blur predict method a bit. And so we
[01:04:03.380 --> 01:04:06.380]   can go ahead and pass in a single string or a list of
[01:04:06.380 --> 01:04:09.340]   strings in this case, and get our predictions shows our
[01:04:09.340 --> 01:04:14.380]   labels, the predicted label index, and then it shows the
[01:04:14.380 --> 01:04:20.620]   probabilities for the zero and one labels. And so this is
[01:04:20.620 --> 01:04:24.300]   basically shows you how you can actually get a data set, create
[01:04:24.300 --> 01:04:28.660]   a subset, build your data blocks, and actually train a
[01:04:28.660 --> 01:04:32.540]   sequence classification model on that subset.
[01:04:35.580 --> 01:04:39.260]   Any questions on all that stuff?
[01:04:39.260 --> 01:04:45.420]   Um, this one question of does blur right now support any NER
[01:04:45.420 --> 01:04:47.940]   named entity recognition capabilities?
[01:04:47.940 --> 01:04:53.700]   Yeah, so most so these are all in process, and some of the
[01:04:53.700 --> 01:04:58.020]   code is really ugly. So don't hate me if you go to it and are
[01:04:58.020 --> 01:05:01.540]   just like, Oh my gosh, this is horrible. My first go around is
[01:05:01.540 --> 01:05:05.340]   to get most of the stuff to work. So token classification.
[01:05:05.340 --> 01:05:08.100]   So if you're doing name entity recognition, that most of the
[01:05:08.100 --> 01:05:12.700]   token classification bits are there. I'm introducing some new
[01:05:12.700 --> 01:05:16.300]   ideas that I don't know will be useful to people, but I have a
[01:05:16.300 --> 01:05:19.900]   way that I'm splitting large documents up, kind of like how
[01:05:19.900 --> 01:05:22.900]   question answering how you would you how you can overflow and
[01:05:22.900 --> 01:05:26.460]   create multiple examples. I'm playing around with ways to do
[01:05:26.460 --> 01:05:29.740]   that with token classification, that ensures words don't get
[01:05:29.740 --> 01:05:34.420]   split up. So you know, word can be tokenized into multiple
[01:05:34.420 --> 01:05:38.660]   tokens. And so some of the stuff is just kind of like,
[01:05:38.660 --> 01:05:41.940]   exploratory this at this point, but the token classification
[01:05:41.940 --> 01:05:45.860]   bits I think will work so you can you can try those out if
[01:05:45.860 --> 01:05:48.500]   you're interested. And I've incorporated a lot of the ideas
[01:05:48.500 --> 01:05:52.180]   from the course into it. So when you look at the course, there's
[01:05:52.180 --> 01:05:55.260]   different ways to aggregate the scores when you do token
[01:05:55.260 --> 01:06:02.420]   classification. Those are now supported in blur. And, and then
[01:06:02.420 --> 01:06:07.100]   also with some of the inference time, so using the actual token
[01:06:07.100 --> 01:06:10.620]   classification models for inference, the results look
[01:06:10.620 --> 01:06:13.660]   more like what you would get out of the hugging face token,
[01:06:13.660 --> 01:06:18.300]   token, token classification pipeline. So hopefully that
[01:06:18.300 --> 01:06:20.100]   will make more, more sense to folks.
[01:06:20.100 --> 01:06:23.660]   Sanyam Bhutani: That's awesome. Thanks. Thanks for sharing that.
[01:06:24.220 --> 01:06:27.140]   I also want to point out you've been pointing towards the dogs.
[01:06:27.140 --> 01:06:30.420]   I think they're quite awesome for even like checking out all
[01:06:30.420 --> 01:06:35.380]   of this stuff with like hugging face. I think we've been around
[01:06:35.380 --> 01:06:38.380]   the hugging face ecosystem long enough, but you recall they did
[01:06:38.380 --> 01:06:41.460]   a nice refactor of their dogs website a while ago. And now
[01:06:41.460 --> 01:06:43.220]   like it's much easier to look up stuff.
[01:06:43.220 --> 01:06:45.460]   Chris Bounds: Yeah, yeah, there's a light mode, dark
[01:06:45.460 --> 01:06:48.260]   modes. You know, they're one of the they're one of the cool kids
[01:06:48.260 --> 01:06:51.620]   on the block. Yeah, there's a lot of stuff. And like I said,
[01:06:51.620 --> 01:06:56.620]   the course is really dense. So I really hope and that's part of
[01:06:56.620 --> 01:07:00.620]   the homework I would give to folks is to go through part five
[01:07:00.620 --> 01:07:03.740]   this next week before we get into tokenization. Because
[01:07:03.740 --> 01:07:06.980]   there's really a lot more that you can do with the data sets
[01:07:06.980 --> 01:07:12.940]   library. And it's almost like I feel like it's, it's like
[01:07:12.940 --> 01:07:16.380]   Excel is to me like, I think I could do a lot with Excel. But
[01:07:16.380 --> 01:07:18.940]   then when I look at the real masters of Excel, I realized I
[01:07:18.940 --> 01:07:23.060]   probably only utilize it like 5%. You know, like, and in the
[01:07:23.060 --> 01:07:26.100]   data sets libraries kind of like that, too. And so really a lot
[01:07:26.100 --> 01:07:27.940]   of really cool things you can do with that.
[01:07:27.940 --> 01:07:31.340]   Sanyam Bhutani: Yeah, it's definitely a lot to unpack.
[01:07:31.340 --> 01:07:34.860]   That was it. I'll hand it back to you.
[01:07:34.860 --> 01:07:40.660]   Chris Bounds: Yeah. So anyway, so for homework, go back through
[01:07:40.660 --> 01:07:45.380]   part five. If you have already if you haven't go through it for
[01:07:45.380 --> 01:07:49.500]   your first time, and spend some time, you know, taking notes,
[01:07:49.500 --> 01:07:54.060]   and each of the pages can be run as a colab. So you can just
[01:07:54.060 --> 01:07:56.740]   click a button at the top right, I think and open up in colab
[01:07:56.740 --> 01:08:02.940]   and run the code and look at it. And then also, just real quickly
[01:08:02.940 --> 01:08:07.020]   looked at some of the new pre processing code and blur. I have
[01:08:07.020 --> 01:08:10.460]   a link exactly to where this pre processing classes I just
[01:08:10.460 --> 01:08:15.620]   showed you for sequence classification is. Check that
[01:08:15.620 --> 01:08:18.460]   out, make sure you can understand it, maybe even try
[01:08:18.460 --> 01:08:24.300]   doing that with something from the data sets from the data set
[01:08:24.300 --> 01:08:27.980]   hub. Try doing that with the data frame, maybe in building
[01:08:27.980 --> 01:08:30.940]   some sequence classification models. And make sure you
[01:08:30.940 --> 01:08:33.940]   understand that if there's questions or problems, I would
[01:08:33.940 --> 01:08:38.740]   love to know about it. And even better, if you submit PRS, then
[01:08:38.740 --> 01:08:41.180]   I don't have to do anything, I just have to hit the approve
[01:08:41.180 --> 01:08:45.620]   button, assuming that they all work. So, so yeah, that's the
[01:08:45.620 --> 01:08:48.220]   homework I would give. And like I said, this is really a core
[01:08:48.220 --> 01:08:50.860]   part of machine learning is being able to, you know, write,
[01:08:50.860 --> 01:08:54.540]   get your data. So really spend some time with this actually was
[01:08:54.540 --> 01:08:57.540]   one of my favorite parts of the part two course was this
[01:08:57.540 --> 01:08:58.540]   particular section.
[01:08:58.540 --> 01:09:05.900]   Awesome. I'm checking to see if there are any questions. So I'll
[01:09:05.900 --> 01:09:10.900]   add another suggested homework from my end. We're also hosting
[01:09:10.900 --> 01:09:14.540]   the Keras reading group where we're going through the Keras
[01:09:14.540 --> 01:09:18.340]   Bible, I would say deep learning with Python. And we are hosting
[01:09:18.340 --> 01:09:22.980]   27 days of Keras where we're giving out swag to people who
[01:09:22.980 --> 01:09:26.780]   submit any blog or any notebook as a way to encourage everyone
[01:09:26.780 --> 01:09:30.460]   to first of all learn Keras and contribute. Data sets is quite
[01:09:30.460 --> 01:09:34.060]   agnostic to both PyTorch and Keras. So that's another
[01:09:34.060 --> 01:09:36.700]   suggestion. If you'd like to win some swag and share your work
[01:09:36.700 --> 01:09:38.780]   with the community, you can join that.
[01:09:38.780 --> 01:09:43.260]   Yeah, and we'll probably I guess have some we have a cup, some
[01:09:43.260 --> 01:09:47.940]   competitions in the study group. So more information to follow,
[01:09:47.940 --> 01:09:52.260]   but the probably with blog posts, and maybe we'll have a
[01:09:52.260 --> 01:09:55.780]   competition data set and see what folks can do in terms of
[01:09:55.780 --> 01:09:59.660]   actually getting results using fast AI to train transformer
[01:09:59.660 --> 01:10:01.060]   model to do something.
[01:10:02.780 --> 01:10:06.340]   Yeah, last time we did this and we got a lot of positive. Yeah,
[01:10:06.340 --> 01:10:08.260]   like so we'll try to bring it back as well.
[01:10:08.260 --> 01:10:09.540]   Cool.
[01:10:09.540 --> 01:10:13.820]   Awesome. Was that the last thing you wanted to share?
[01:10:13.820 --> 01:10:18.780]   No, that's it. If, like I said, we'll get these the resources,
[01:10:18.780 --> 01:10:27.260]   the Google Slides and also the Jupyter Notebook for folks to
[01:10:27.260 --> 01:10:30.100]   play with. And again, I just encourage you to look at the
[01:10:30.100 --> 01:10:34.900]   documentation for blur, and look at some of the new bits of code.
[01:10:34.900 --> 01:10:38.460]   Outside of looking at documentation, looking at code
[01:10:38.460 --> 01:10:41.740]   is typically how I learned how things work and how to how to
[01:10:41.740 --> 01:10:44.380]   work with different libraries. So I just really encourage that
[01:10:44.380 --> 01:10:46.340]   hope and hopefully it all makes sense to folks.
[01:10:46.340 --> 01:10:50.540]   That's a practical advice, very practical advice to wrap up on.
[01:10:50.540 --> 01:10:54.540]   I'd remind everyone to follow Wade on Twitter. As I said, he's
[01:10:54.540 --> 01:10:58.580]   the real host, I was trying to fight an issue. And also
[01:10:58.580 --> 01:11:01.980]   apologies to everyone. This is my job making sure that everyone
[01:11:01.980 --> 01:11:04.940]   has a good learning experience. I know people signed up and they
[01:11:04.940 --> 01:11:08.620]   weren't able to post the live stream there. I try to make we
[01:11:08.620 --> 01:11:11.820]   at Hugging at Wade's and Bias's try to make this a nice
[01:11:11.820 --> 01:11:14.980]   experience for everyone. But sorry about that issue that
[01:11:14.980 --> 01:11:16.740]   won't happen in the future. So if you're watching the
[01:11:16.740 --> 01:11:21.140]   recording, sorry about that. Please follow Wade on Twitter,
[01:11:21.140 --> 01:11:23.900]   please sign up for the group. We look forward to seeing you next
[01:11:24.140 --> 01:11:28.940]   week. And if you share any blog posts, be sure to tag me or
[01:11:28.940 --> 01:11:32.580]   Bateson biases and we would love to amplify your work. And we
[01:11:32.580 --> 01:11:38.340]   would also try to encourage it by sending some swag towards the
[01:11:38.340 --> 01:11:42.060]   submissions or the person's way. So thanks again, Wade. And
[01:11:42.060 --> 01:11:43.380]   thanks, everyone for joining.
[01:11:43.380 --> 01:11:45.700]   Yeah, thanks. See you all next week.
[01:11:45.700 --> 01:11:55.700]   [BLANK_AUDIO]

