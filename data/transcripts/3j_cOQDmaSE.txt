
[00:00:00.000 --> 00:00:04.800]   What general advice would you have then to someone that's trying to get something published? What are
[00:00:04.800 --> 00:00:11.360]   the mistakes that you see first time people or outsiders make and what kind of help do you
[00:00:11.360 --> 00:00:19.760]   typically give to someone? I feel like the thing is that our reward function is delayed. So we go
[00:00:19.760 --> 00:00:26.320]   into ML research liking it because we saw other people in research maybe a few years before us,
[00:00:26.320 --> 00:00:31.440]   and they gained reward out of that. They published a paper and it was so recognized and they have
[00:00:31.440 --> 00:00:36.480]   such a fame and recognition and everything. So we want to do the same thing, but the difference is
[00:00:36.480 --> 00:00:41.600]   we live in a delayed timeline. So when we get into it, the scene already changed, but we don't know.
[00:00:41.600 --> 00:00:47.520]   So I really want to remind everyone that if you're getting into ML research now, publishing is very
[00:00:47.520 --> 00:00:54.320]   different than before. Before, if you have accepted paper at, I don't know, iClear or NeurIPS or CPR,
[00:00:56.080 --> 00:01:01.120]   you're there. You can probably get a job that you would want, get a dream job, get a position
[00:01:01.120 --> 00:01:06.800]   of something, but not anymore. So now I think the next people will be looking at citations. Even if
[00:01:06.800 --> 00:01:11.920]   you get a load of paper published in peer review conferences, people will look at different metrics
[00:01:11.920 --> 00:01:16.320]   now because there are so many papers getting in and so many people having their papers getting in.
[00:01:16.320 --> 00:01:25.040]   So yeah, the basic suggestion or advice is that you should try to adjust your reward system to
[00:01:25.040 --> 00:01:29.200]   be different from where you came in the... Should you adjust it too?
[00:01:29.200 --> 00:01:31.680]   That makes sense. You're saying... I mean,
[00:01:31.680 --> 00:01:35.840]   it just seems like you should just make things even harder for yourself, right? You can't just
[00:01:35.840 --> 00:01:39.040]   publish a paper and have to get citations. Is that a good summary?
[00:01:39.040 --> 00:01:45.040]   Yeah. So no, that's why you should be looking at other things. You should be really just looking
[00:01:45.040 --> 00:01:48.480]   at the love of science. I want to do this for the love of science. I'm not trying to... I do this
[00:01:48.480 --> 00:01:54.400]   piece of work not to... Well, if it gets published, that's a confirmation that is a good science, but
[00:01:54.400 --> 00:01:57.920]   the basic thing that's important is that it's a good piece of science. I think that's what I
[00:01:57.920 --> 00:02:02.560]   want to say. You can do a beautiful work, put it in an archive. Don't worry about whether it gets
[00:02:02.560 --> 00:02:06.240]   accepted or not because there's so many noise in that whole thing, the same as neural network
[00:02:06.240 --> 00:02:10.960]   training. There are so many statistics that the same paper with no change, just so many two or
[00:02:10.960 --> 00:02:15.600]   three conferences get rejected, rejected, accepted because it's just random chance. Every time you're
[00:02:15.600 --> 00:02:20.480]   just drawing a lottery ticket of some sort. So don't care about that. Don't care about really
[00:02:20.480 --> 00:02:25.600]   this true acceptance or not into a conference. Really care about the quality of the science you
[00:02:25.600 --> 00:02:30.880]   put out there because if it's on archive, you have your name on it, that means something.
[00:02:30.880 --> 00:02:35.760]   So change your reward system to really care about the true quality of science and remind yourself
[00:02:35.760 --> 00:02:40.400]   that you're in here for the love of science, not for... Of course, some people are in here for it
[00:02:40.400 --> 00:02:45.600]   too so that it promises a better future and there's nothing wrong with that, but those will probably
[00:02:46.720 --> 00:02:51.920]   stray you a little bit away from the path and maybe make you a little bit miserable.
[00:02:51.920 --> 00:02:57.920]   So what's the key to doing good science as an outsider? How do you do that?
[00:02:57.920 --> 00:03:02.880]   Yeah, that's actually the idea of running ML Collective. I feel like
[00:03:02.880 --> 00:03:08.800]   there's so many problems these days in the world that people don't believe in science. I'm not
[00:03:08.800 --> 00:03:13.920]   saying ML Collective is the way to change that, but I sometimes think if you can get everyone,
[00:03:13.920 --> 00:03:18.800]   not even everyone, the majority of Americans to publish one paper in their life, maybe they'll
[00:03:18.800 --> 00:03:23.200]   just believe in science more. Once they go through that publication process, they see like, "Oh,
[00:03:23.200 --> 00:03:29.600]   to put this statement out, I need to try everything around it, do ablation study,
[00:03:29.600 --> 00:03:34.640]   compare with all the benchmarks." So they will become more careful when they put statements out.
[00:03:34.640 --> 00:03:39.280]   I don't know. This is a weird argument I'm making, but I feel like if I can get more people
[00:03:39.840 --> 00:03:43.280]   to do science, not for life, just publish one paper in their life,
[00:03:43.280 --> 00:03:48.160]   I think everyone's attitude towards science will be better. They will believe it more.
[00:03:48.160 --> 00:03:52.480]   We probably wouldn't have all those problems out there in America that people don't believe in
[00:03:52.480 --> 00:03:55.360]   science and all the things. I don't know. That's my dream, of course.
[00:03:56.320 --> 00:04:00.160]   Thanks for watching this clip. You can see the full episode on our YouTube channel.
[00:04:00.160 --> 00:04:06.720]   And you can join our friendly Slack community with over 4,000 ML engineers to participate in
[00:04:06.720 --> 00:04:11.520]   paper reading groups, AMAs, and other fun events.

