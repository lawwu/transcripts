
[00:00:00.000 --> 00:00:03.400]   [MUSIC PLAYING]
[00:00:03.400 --> 00:00:13.360]   Hopping back in to it directly, a reminder of the overall themes,
[00:00:13.360 --> 00:00:16.720]   structures, goals of this webinar series.
[00:00:16.720 --> 00:00:19.840]   The overall goal is to understand what math
[00:00:19.840 --> 00:00:21.560]   has to do with machine learning.
[00:00:21.560 --> 00:00:25.640]   And even though all programming involves math at some level in some way,
[00:00:25.640 --> 00:00:27.560]   we can always use the tools of mathematics
[00:00:27.560 --> 00:00:30.040]   to understand the programming that we're doing.
[00:00:30.040 --> 00:00:33.480]   Machine learning, because it's programming by optimization,
[00:00:33.480 --> 00:00:39.760]   really benefits from some strong grounding in mathematics.
[00:00:39.760 --> 00:00:43.040]   And so we're using the tools of mathematics
[00:00:43.040 --> 00:00:46.040]   to understand that optimization process that
[00:00:46.040 --> 00:00:47.840]   goes on during machine learning.
[00:00:47.840 --> 00:00:51.560]   There are basically three core ways that optimization and machine learning
[00:00:51.560 --> 00:00:54.400]   intersect in terms of the objects being optimized,
[00:00:54.400 --> 00:00:59.080]   in terms of how we optimize, and in terms of what we optimize.
[00:00:59.080 --> 00:01:01.360]   So we already talked about the objects being optimized
[00:01:01.360 --> 00:01:04.880]   by using linear algebra to understand that data and models are arrays,
[00:01:04.880 --> 00:01:07.920]   and linear operations on arrays is the linear algebra,
[00:01:07.920 --> 00:01:09.960]   and it's a part of the core of machine learning.
[00:01:09.960 --> 00:01:12.800]   Then we understood how we optimized with calculus, which
[00:01:12.800 --> 00:01:15.560]   means we basically make tiny changes using
[00:01:15.560 --> 00:01:18.160]   this framework of linear approximation.
[00:01:18.160 --> 00:01:22.240]   And then finally, now, we're going to understand just what it is exactly
[00:01:22.240 --> 00:01:23.520]   that we are optimizing.
[00:01:23.520 --> 00:01:25.240]   Very loosely up to this point, I've said
[00:01:25.240 --> 00:01:27.840]   that we're improving the performance of our model,
[00:01:27.840 --> 00:01:30.240]   but that's not very quantitative at all.
[00:01:30.240 --> 00:01:33.000]   And so we're going to see that actually what we're optimizing
[00:01:33.000 --> 00:01:37.200]   is we are reducing the surprise or uncertainty of our models
[00:01:37.200 --> 00:01:38.640]   when they're presented with data.
[00:01:38.640 --> 00:01:42.320]   And so the tools of probability and statistics
[00:01:42.320 --> 00:01:45.240]   are going to come in very much handy here.
[00:01:45.240 --> 00:01:48.160]   So let's dive in and talk about probability.
[00:01:48.160 --> 00:01:52.080]   The bad news I have here is that even those first two sections
[00:01:52.080 --> 00:01:54.200]   where we talked about linear algebra and we talked about calculus,
[00:01:54.200 --> 00:01:57.280]   there's, I think, a lot that's intuitive about these ideas.
[00:01:57.280 --> 00:01:59.720]   They're relatively easy to work with.
[00:01:59.720 --> 00:02:02.760]   There's some subtle ideas, but once you wrap your head around core ideas
[00:02:02.760 --> 00:02:06.160]   like arrays and approximation, the world is your oyster.
[00:02:06.160 --> 00:02:10.440]   But probability, on the other hand, is surprisingly subtle in a way that
[00:02:10.440 --> 00:02:11.920]   makes it very difficult to work with.
[00:02:11.920 --> 00:02:15.200]   So Bertrand Russell, who is one of the premier mathematicians
[00:02:15.200 --> 00:02:17.600]   and logicians of the early 20th century,
[00:02:17.600 --> 00:02:21.840]   said that no one has the slightest notion what probability means.
[00:02:21.840 --> 00:02:25.000]   And Bertrand Russell was very fond of paradoxes,
[00:02:25.000 --> 00:02:28.080]   but he liked them to be a little bit neater than the paradoxes
[00:02:28.080 --> 00:02:29.840]   that you find in probability.
[00:02:29.840 --> 00:02:33.600]   Another indication of just how subtle and difficult probability can be
[00:02:33.600 --> 00:02:36.120]   is this quote from Probability, an Introduction,
[00:02:36.120 --> 00:02:38.640]   a textbook by Samuel Goldberg, which notes
[00:02:38.640 --> 00:02:41.240]   that the concept of a random variable, which
[00:02:41.240 --> 00:02:43.520]   is at the very center of probability-- we say,
[00:02:43.520 --> 00:02:45.880]   oh, this is a random variable, that's a random variable--
[00:02:45.880 --> 00:02:48.280]   is actually a tremendous misnomer.
[00:02:48.280 --> 00:02:51.680]   So just like an alligator pair, which is neither an alligator nor a pair,
[00:02:51.680 --> 00:02:54.280]   a random variable is neither random nor a variable.
[00:02:54.280 --> 00:02:56.600]   An alligator pair is actually an avocado.
[00:02:56.600 --> 00:03:00.360]   It's an old name for an avocado, and that's not a type of pair.
[00:03:00.360 --> 00:03:04.080]   And the random variable in probability is actually a deterministic function,
[00:03:04.080 --> 00:03:06.480]   but it's the way things are termed.
[00:03:06.480 --> 00:03:08.960]   And that suggests that it's something we want to treat it
[00:03:08.960 --> 00:03:11.240]   in one particular way, this random variable idea
[00:03:11.240 --> 00:03:12.640]   that we have, this intuitive idea.
[00:03:12.640 --> 00:03:16.040]   When it comes time to turn it into mathematics, things get complicated.
[00:03:16.040 --> 00:03:20.360]   And then finally, I've often, in the last two sections,
[00:03:20.360 --> 00:03:23.960]   mentioned content by 3Blue1Brown, who's one of the premier math
[00:03:23.960 --> 00:03:25.360]   YouTubers these days.
[00:03:25.360 --> 00:03:28.680]   3Blue1Brown attempted to make a probability series
[00:03:28.680 --> 00:03:29.960]   and then eventually gave up.
[00:03:29.960 --> 00:03:30.960]   They were working on it.
[00:03:30.960 --> 00:03:33.440]   They got about halfway through it, and then they realized,
[00:03:33.440 --> 00:03:35.320]   actually, there's a lot of ambiguity in what
[00:03:35.320 --> 00:03:37.700]   people mean when they say they want to learn probability.
[00:03:37.700 --> 00:03:41.120]   And so they gave up on that plan that they had.
[00:03:41.120 --> 00:03:44.920]   Probability is something of a white whale in mathematics,
[00:03:44.920 --> 00:03:46.320]   like in Moby Dick.
[00:03:46.320 --> 00:03:49.320]   It's a difficult idea to try and conquer.
[00:03:49.320 --> 00:03:52.760]   We aren't going to be totally dismayed by this and give up entirely,
[00:03:52.760 --> 00:03:55.720]   but I just want to put that out there just as an indication that this
[00:03:55.720 --> 00:03:58.360]   is the hardest of the three sections.
[00:03:58.360 --> 00:04:01.560]   And so I'm going to try and present as much intuition and ideas
[00:04:01.560 --> 00:04:03.160]   around probability as I can.
[00:04:03.160 --> 00:04:06.120]   But you shouldn't be surprised that this one is a little bit maybe less
[00:04:06.120 --> 00:04:08.240]   satisfying, more difficult in some ways.
[00:04:08.240 --> 00:04:10.480]   When I say probability is surprisingly subtle,
[00:04:10.480 --> 00:04:14.080]   there's some parts of this that go all the way back to, what does it mean?
[00:04:14.080 --> 00:04:16.520]   What are we even trying to mathematically model here
[00:04:16.520 --> 00:04:19.000]   before we go out and write our definitions?
[00:04:19.000 --> 00:04:21.640]   Just as an indication of this difficulty,
[00:04:21.640 --> 00:04:26.640]   let's consider the expression pi of n, which just means the nth digit of pi.
[00:04:26.640 --> 00:04:28.720]   So when I say pi of 1, I mean 3.
[00:04:28.720 --> 00:04:30.640]   When I say pi of 2, I mean 1.
[00:04:30.640 --> 00:04:34.800]   Pi of 3 is 4, and so on, all the way through the digits of pi.
[00:04:34.800 --> 00:04:39.840]   And so the quantity d equals pi of 1, that's just the number 3.
[00:04:39.840 --> 00:04:42.600]   And if I ask you a question, is d even or odd,
[00:04:42.600 --> 00:04:44.800]   it's pretty straightforward to know how to answer it.
[00:04:44.800 --> 00:04:45.720]   d is 3.
[00:04:45.720 --> 00:04:47.080]   That's an odd number.
[00:04:47.080 --> 00:04:49.600]   And if I ask you, what is the probability that d is odd?
[00:04:49.600 --> 00:04:52.520]   Before we dive into definitions and think too hard about this,
[00:04:52.520 --> 00:04:54.960]   you have a clear, intuitive answer in your head.
[00:04:54.960 --> 00:04:55.840]   It's 3.
[00:04:55.840 --> 00:04:56.680]   It's odd.
[00:04:56.680 --> 00:04:58.600]   100% chance that it's odd.
[00:04:58.600 --> 00:05:00.360]   There's no chance that it's not odd.
[00:05:00.360 --> 00:05:02.920]   The difficulty comes in when we do something
[00:05:02.920 --> 00:05:08.400]   like consider the quantity pi of 4.65 times 10 to the 185th.
[00:05:08.400 --> 00:05:11.280]   So this is roughly, if I were to write a single digit of pi
[00:05:11.280 --> 00:05:15.760]   on every single tiny scrap of the universe, every single Planck volume,
[00:05:15.760 --> 00:05:18.240]   this is how many digits of pi I could write out.
[00:05:18.240 --> 00:05:20.960]   So no one will ever be able to write out pi this far,
[00:05:20.960 --> 00:05:23.640]   unlikely anybody will ever be able to calculate it this far.
[00:05:23.640 --> 00:05:25.640]   And we don't know what that number is.
[00:05:25.640 --> 00:05:29.080]   So the question I have for you is, which of the following
[00:05:29.080 --> 00:05:32.480]   would you say is a more correct way of thinking about it?
[00:05:32.480 --> 00:05:35.640]   To say that d is even with probability 0.5,
[00:05:35.640 --> 00:05:37.920]   there's a 50/50 shot that d is even.
[00:05:37.920 --> 00:05:41.680]   Or to say that d is either even with probability 1 or 0,
[00:05:41.680 --> 00:05:44.080]   but you just don't know which of those that is.
[00:05:44.080 --> 00:05:46.560]   And so this one is more of an opinion poll
[00:05:46.560 --> 00:05:48.600]   than it is a mathematics question.
[00:05:48.600 --> 00:05:51.320]   And one thing I'd like to note here is that so far as we can tell,
[00:05:51.320 --> 00:05:54.320]   there is no real pattern to the digits of pi.
[00:05:54.320 --> 00:05:58.360]   Every digit seems to occur with equal probability in the long run.
[00:05:58.360 --> 00:06:01.000]   It looks like a consensus is emerging here.
[00:06:01.000 --> 00:06:04.200]   People are agreeing on one of these two answers.
[00:06:04.200 --> 00:06:06.840]   And one of these is the minority response here.
[00:06:06.840 --> 00:06:09.640]   So let's go ahead and, thanks to everyone who answered,
[00:06:09.640 --> 00:06:12.520]   let's go ahead and reveal what those answers were.
[00:06:12.520 --> 00:06:15.040]   All right, it seems like the most popular choice here
[00:06:15.040 --> 00:06:17.960]   is d is even with probability 0.5.
[00:06:17.960 --> 00:06:21.480]   But there's a strong minority of about a third to about a quarter
[00:06:21.480 --> 00:06:25.920]   who say that actually, no, it's that d is either even with probability 1 or 0,
[00:06:25.920 --> 00:06:27.040]   but I don't know which.
[00:06:27.040 --> 00:06:31.280]   Interestingly, whenever I run this with a different group of students,
[00:06:31.280 --> 00:06:33.600]   I actually get slightly different answers.
[00:06:33.600 --> 00:06:37.480]   So I've sometimes seen people split basically 50/50 down the middle
[00:06:37.480 --> 00:06:38.240]   for both of these.
[00:06:38.240 --> 00:06:40.680]   Sometimes I see a result more like what we're seeing here,
[00:06:40.680 --> 00:06:42.640]   it's 2 to 1 for the first answer.
[00:06:42.640 --> 00:06:45.840]   Essentially, these two different answers come down
[00:06:45.840 --> 00:06:48.120]   to whether you want probability to mean, oh, I
[00:06:48.120 --> 00:06:50.760]   don't know what this value is, and I want
[00:06:50.760 --> 00:06:54.320]   to be able to represent my uncertainty about certain values.
[00:06:54.320 --> 00:06:57.000]   And then that gives you the first answer.
[00:06:57.000 --> 00:06:59.600]   Or whether you want probability to be this mathematically
[00:06:59.600 --> 00:07:01.800]   definable thing about frequencies.
[00:07:01.800 --> 00:07:05.680]   If you really think, OK, probability should represent the frequency
[00:07:05.680 --> 00:07:07.800]   with which events occur, then it doesn't make sense
[00:07:07.800 --> 00:07:10.640]   to say that d is even with probability 0.5.
[00:07:10.640 --> 00:07:13.600]   There's no sense of frequency in which we can generate pi many times
[00:07:13.600 --> 00:07:15.080]   and get different values.
[00:07:15.080 --> 00:07:18.440]   And so that second approach is the frequentist approach to probability,
[00:07:18.440 --> 00:07:21.280]   and the first approach is the Bayesian approach to probability.
[00:07:21.280 --> 00:07:23.840]   The first one is a little bit more popular these days.
[00:07:23.840 --> 00:07:26.080]   It's especially popular in machine learning
[00:07:26.080 --> 00:07:28.680]   and popular among practicing scientists,
[00:07:28.680 --> 00:07:30.880]   but the latter is actually more popular among people
[00:07:30.880 --> 00:07:33.640]   who do probability rigorous mathematics of probability.
[00:07:33.640 --> 00:07:35.840]   So in the end, it's something of a matter of taste.
[00:07:35.840 --> 00:07:38.560]   But the fact that there's a matter of taste at the very beginning
[00:07:38.560 --> 00:07:42.440]   when we define the concept that gives our field its name of probability
[00:07:42.440 --> 00:07:45.520]   theory should suggest some of the complexity and difficulty that
[00:07:45.520 --> 00:07:46.160]   comes in.
[00:07:46.160 --> 00:07:49.320]   But we are not going to be daunted by that complexity and that difficulty.
[00:07:49.320 --> 00:07:53.440]   We're going to proceed forward and just look at what happens
[00:07:53.440 --> 00:07:56.040]   without trying to interpret what probability is,
[00:07:56.040 --> 00:07:57.720]   just looking at turning the crank.
[00:07:57.720 --> 00:07:58.680]   What do we see?
[00:07:58.680 --> 00:08:01.280]   And we're going to have three basic takeaways.
[00:08:01.280 --> 00:08:04.920]   The first is that if we ignore all these questions about what
[00:08:04.920 --> 00:08:07.400]   does probability mean, mathematically, probability
[00:08:07.400 --> 00:08:09.440]   behaves just like mass, which is something
[00:08:09.440 --> 00:08:12.520]   that we don't think of as that paradoxical or that difficult.
[00:08:12.520 --> 00:08:14.680]   But then when it comes time to do machine learning,
[00:08:14.680 --> 00:08:18.360]   a related concept called the surprise shows up more often,
[00:08:18.360 --> 00:08:22.000]   the negative logarithm of the probability rather than the probability
[00:08:22.000 --> 00:08:22.600]   itself.
[00:08:22.600 --> 00:08:26.160]   And then finally, when we want to use probability distributions,
[00:08:26.160 --> 00:08:28.960]   when we want to use probabilities in machine learning,
[00:08:28.960 --> 00:08:33.920]   we most often end up using the Gaussian distribution or the bell curve.
[00:08:33.920 --> 00:08:37.080]   And Gaussians end up actually at the intersection
[00:08:37.080 --> 00:08:40.800]   of all three of the fields we've talked about of probability, linear algebra,
[00:08:40.800 --> 00:08:43.800]   and calculus, but especially at the intersection of probability
[00:08:43.800 --> 00:08:44.840]   and linear algebra.
[00:08:44.840 --> 00:08:47.600]   So we'll talk about Gaussians in detail.
[00:08:47.600 --> 00:08:49.440]   So first, what is probability?
[00:08:49.440 --> 00:08:51.480]   Probability is something like mass.
[00:08:51.480 --> 00:08:53.440]   We use the same mathematical tools that we
[00:08:53.440 --> 00:08:57.480]   would use to work with masses, with objects that have weight.
[00:08:57.480 --> 00:09:01.200]   So consider, to understand this analogy or this relationship,
[00:09:01.200 --> 00:09:04.080]   consider the distribution of mass on two pizzas.
[00:09:04.080 --> 00:09:08.960]   So one pizza is a cheese pizza, and the other pizza is a pepperoni pizza.
[00:09:08.960 --> 00:09:11.920]   If I wanted to tell you where is the mass on this pizza,
[00:09:11.920 --> 00:09:15.160]   well, there's a whole bunch of different points on this pizza.
[00:09:15.160 --> 00:09:18.800]   There's an x and a y-coordinate for every point on this pizza.
[00:09:18.800 --> 00:09:21.400]   At a given point, there really isn't any mass.
[00:09:21.400 --> 00:09:24.840]   If I ask you at the exact center of the pizza how much mass is there,
[00:09:24.840 --> 00:09:27.880]   the answer is basically 0 at a fixed exact point.
[00:09:27.880 --> 00:09:30.680]   If I want to know how much mass there is in a part of the pizza,
[00:09:30.680 --> 00:09:34.080]   what I need to do is I need to integrate over an area.
[00:09:34.080 --> 00:09:36.720]   I need to say, OK, there's a little bit of density here.
[00:09:36.720 --> 00:09:40.240]   There's a certain amount of grams per square centimeter in the center.
[00:09:40.240 --> 00:09:43.400]   There's a certain amount of grams per square centimeter at the edge,
[00:09:43.400 --> 00:09:44.760]   and I need to integrate those.
[00:09:44.760 --> 00:09:48.720]   So I would have some density function for the pizza, a pizza density function
[00:09:48.720 --> 00:09:50.960]   that says at this point, the density is equal to this.
[00:09:50.960 --> 00:09:53.240]   At another point, it's equal to this other value.
[00:09:53.240 --> 00:09:55.280]   And when we work with masses and densities,
[00:09:55.280 --> 00:09:58.280]   especially in a typical educational context,
[00:09:58.280 --> 00:10:01.200]   all the way up to the point where you're maybe in advanced physics
[00:10:01.200 --> 00:10:03.440]   or engineering class, you only work with things
[00:10:03.440 --> 00:10:05.320]   that have an even density function.
[00:10:05.320 --> 00:10:08.080]   So if I want to talk about the mass of this cheese pizza,
[00:10:08.080 --> 00:10:10.040]   it's really simple because it's flat.
[00:10:10.040 --> 00:10:12.960]   And so I don't really need to think explicitly
[00:10:12.960 --> 00:10:14.560]   that what I'm doing is an integral.
[00:10:14.560 --> 00:10:17.640]   I just take the area times some fixed value
[00:10:17.640 --> 00:10:20.640]   that we call the density of the pizza, and that gives me
[00:10:20.640 --> 00:10:22.200]   the mass in any given area.
[00:10:22.200 --> 00:10:25.360]   And so I can answer any questions about the mass of this cheese pizza,
[00:10:25.360 --> 00:10:27.720]   the center of mass, things like that, without having
[00:10:27.720 --> 00:10:29.240]   to think too hard about integrals.
[00:10:29.240 --> 00:10:32.520]   But if I have something like that pepperoni pizza on the right-hand side
[00:10:32.520 --> 00:10:34.720]   here, there's more mass in certain places.
[00:10:34.720 --> 00:10:37.120]   There's a couple of pepperonis overlapping in the middle,
[00:10:37.120 --> 00:10:39.040]   so there's a spike in the density there.
[00:10:39.040 --> 00:10:42.120]   Because if you look at any given point on that pizza right there,
[00:10:42.120 --> 00:10:43.000]   there's more stuff.
[00:10:43.000 --> 00:10:44.960]   There's several overlapping pepperonis.
[00:10:44.960 --> 00:10:47.920]   And then as we go to the edges there, towards the places
[00:10:47.920 --> 00:10:50.480]   where there's only cheese, things flatten back out again.
[00:10:50.480 --> 00:10:53.200]   And so if I want to know how much mass there is in any given point
[00:10:53.200 --> 00:10:56.160]   on this pepperoni pizza, I actually have to think about, OK,
[00:10:56.160 --> 00:11:00.240]   what is my pizza density function, and how much mass is there in this area?
[00:11:00.240 --> 00:11:03.440]   If I want to know the mass of a part that's, say, got a pepperoni on it,
[00:11:03.440 --> 00:11:06.120]   I need to integrate in the area of that pepperoni.
[00:11:06.120 --> 00:11:09.840]   So this is not that dissimilar to the distribution of dart throws
[00:11:09.840 --> 00:11:11.880]   in, let's say, two separate cases.
[00:11:11.880 --> 00:11:15.480]   One is somebody who's been blindfolded throwing darts at a dartboard.
[00:11:15.480 --> 00:11:18.080]   Their darts, let's say, end up everywhere.
[00:11:18.080 --> 00:11:21.960]   So they throw the darts many times, and we look at where the dart ends up.
[00:11:21.960 --> 00:11:25.000]   And there's lots of darts spread throughout the entire dartboard.
[00:11:25.000 --> 00:11:27.880]   But if a pro player throws darts at a board,
[00:11:27.880 --> 00:11:31.240]   and we collect those over time, maybe throughout a whole bunch of games,
[00:11:31.240 --> 00:11:33.720]   we'll see that really often they throw towards the center.
[00:11:33.720 --> 00:11:35.960]   So that's a very common place for the darts to end up.
[00:11:35.960 --> 00:11:38.340]   And then other times, they throw towards different spots.
[00:11:38.340 --> 00:11:39.880]   There's a ring in the dartboard.
[00:11:39.880 --> 00:11:41.880]   There's actually two separate rings of the dartboard
[00:11:41.880 --> 00:11:43.480]   that give different amounts of points.
[00:11:43.480 --> 00:11:46.320]   And sometimes in a game of darts, you really want to hit one of those.
[00:11:46.320 --> 00:11:49.800]   So pro player will have a very complicated distribution
[00:11:49.800 --> 00:11:52.720]   of dart throws, a complicated spread of dart throws.
[00:11:52.720 --> 00:11:55.880]   So if I have them throw darts at the board for a really long time,
[00:11:55.880 --> 00:11:59.200]   then I'll end up with a distribution of darts on that dartboard.
[00:11:59.200 --> 00:12:02.880]   I can imagine, what is the density of darts on this dartboard?
[00:12:02.880 --> 00:12:07.520]   So I think of that, basically, as the chance that any given dart ends up
[00:12:07.520 --> 00:12:09.040]   at any given spot.
[00:12:09.040 --> 00:12:12.760]   And much like there's no mass at any given point on a pizza,
[00:12:12.760 --> 00:12:15.760]   there is no probability at any given point on the dartboard.
[00:12:15.760 --> 00:12:19.480]   Any exact, specific, precise point that you say, oh,
[00:12:19.480 --> 00:12:22.800]   did a dart land here on the dartboard, the answer is 0.
[00:12:22.800 --> 00:12:26.160]   It's only when we integrate over an area that we can actually
[00:12:26.160 --> 00:12:29.720]   get an actual mass in the pizza case or an actual probability
[00:12:29.720 --> 00:12:30.840]   in the probability case.
[00:12:30.840 --> 00:12:33.480]   So what we're mapping here is a density of probability,
[00:12:33.480 --> 00:12:36.760]   how much probability per square centimeter is there.
[00:12:36.760 --> 00:12:39.520]   And when we integrate over squared centimeters, we get probability.
[00:12:39.520 --> 00:12:43.280]   Just as when we integrate a density of grams per square centimeters,
[00:12:43.280 --> 00:12:44.920]   we get grams in the end.
[00:12:44.920 --> 00:12:48.120]   And I think this distinction between probabilities, probability densities,
[00:12:48.120 --> 00:12:51.960]   probability masses, this is something that definitely confuses people.
[00:12:51.960 --> 00:12:54.360]   And I like, whenever I get confused by this, to think, OK,
[00:12:54.360 --> 00:12:56.720]   what if I were just thinking about mass?
[00:12:56.720 --> 00:12:57.640]   How would this look?
[00:12:57.640 --> 00:13:00.000]   So this probability density function that
[00:13:00.000 --> 00:13:03.440]   describes where things are more likely to end up
[00:13:03.440 --> 00:13:07.760]   is the core object that we think about in probability theory, the most
[00:13:07.760 --> 00:13:09.200]   common thing that we think about.
[00:13:09.200 --> 00:13:12.720]   So there's a lot of similarities between mass or density and probability.
[00:13:12.720 --> 00:13:17.240]   We have a density function in the former case that takes a position
[00:13:17.240 --> 00:13:19.560]   and returns a real number that is the density.
[00:13:19.560 --> 00:13:22.720]   And in order to get a final mass, we integrate over an object.
[00:13:22.720 --> 00:13:25.360]   So if I want to know the mass of an object, which might be, say,
[00:13:25.360 --> 00:13:27.840]   a slice of the pizza or an area in the pizza,
[00:13:27.840 --> 00:13:30.520]   I need to integrate the density over that object, which
[00:13:30.520 --> 00:13:32.080]   looks like the thing on the left.
[00:13:32.080 --> 00:13:35.880]   It's maybe an unfamiliar way to present a familiar idea of calculating
[00:13:35.880 --> 00:13:37.720]   or thinking about the mass of an object.
[00:13:37.720 --> 00:13:39.880]   That is transferred directly over to probability.
[00:13:39.880 --> 00:13:43.280]   We have a probability density function that takes in an outcome space
[00:13:43.280 --> 00:13:46.920]   now, rather than spatial coordinates, and returns a real value that
[00:13:46.920 --> 00:13:48.000]   is the probability.
[00:13:48.000 --> 00:13:51.040]   And just like density, actually, probability is non-negative.
[00:13:51.040 --> 00:13:54.520]   You can't have negative mass, and you can't have negative probability.
[00:13:54.520 --> 00:13:56.880]   And when you get the probability of an event,
[00:13:56.880 --> 00:13:59.480]   say the dart lands anywhere in the bullseye,
[00:13:59.480 --> 00:14:01.760]   or the dart lands anywhere in the inner ring,
[00:14:01.760 --> 00:14:05.160]   or the dart doesn't hit the 20-point region,
[00:14:05.160 --> 00:14:09.480]   then you need to integrate that probability density over that event.
[00:14:09.480 --> 00:14:12.120]   So even though there are similarities, and maybe formally
[00:14:12.120 --> 00:14:16.960]   at some galactic level of abstraction, they are the same thing,
[00:14:16.960 --> 00:14:20.600]   to study density and to study probability with one single tool.
[00:14:20.600 --> 00:14:22.480]   But there are some differences in emphasis.
[00:14:22.480 --> 00:14:24.800]   One is that the total probability is always 1.
[00:14:24.800 --> 00:14:27.360]   So if I integrate over the entire dartboard,
[00:14:27.360 --> 00:14:30.080]   the value will always be 1 if I'm integrating the probability.
[00:14:30.080 --> 00:14:33.200]   But a pizza need not weigh the same as another pizza.
[00:14:33.200 --> 00:14:34.720]   There isn't that restriction.
[00:14:34.720 --> 00:14:37.800]   And that becomes very important when we're working with probability.
[00:14:37.800 --> 00:14:40.960]   We also care quite a bit about the concept of independence
[00:14:40.960 --> 00:14:44.240]   in probability, which is to say that if I have some function that
[00:14:44.240 --> 00:14:47.880]   takes two arguments, so a probability of two events maybe,
[00:14:47.880 --> 00:14:51.160]   can I think of that as just the product of the probabilities
[00:14:51.160 --> 00:14:52.280]   of the individual events?
[00:14:52.280 --> 00:14:55.000]   Can I think of these things independently or separately
[00:14:55.000 --> 00:14:55.680]   from one another?
[00:14:55.680 --> 00:14:59.720]   Can I factor p of xy into p of x times p of y?
[00:14:59.720 --> 00:15:01.680]   That comes up all the time in probability,
[00:15:01.680 --> 00:15:04.400]   and very rarely in calculating masses.
[00:15:04.400 --> 00:15:07.800]   Then finally, we care about expectations in probability.
[00:15:07.800 --> 00:15:11.160]   The expectation of a function is to say, OK,
[00:15:11.160 --> 00:15:14.640]   what if I were to take the outputs of that random variable
[00:15:14.640 --> 00:15:16.320]   and I were to put them into a function?
[00:15:16.320 --> 00:15:19.160]   What would the value on average be?
[00:15:19.160 --> 00:15:21.760]   If I take, say, the outputs of a random variable,
[00:15:21.760 --> 00:15:24.640]   I pass them through a function, and I take the mean, 1 over n
[00:15:24.640 --> 00:15:28.480]   times the sum of the values, what should I expect that value to be?
[00:15:28.480 --> 00:15:30.400]   That is the expectation.
[00:15:30.400 --> 00:15:32.600]   So as an example, maybe we want to know
[00:15:32.600 --> 00:15:36.880]   what the average score of a pro player versus a blindfolded individual
[00:15:36.880 --> 00:15:37.880]   is going to be.
[00:15:37.880 --> 00:15:40.920]   So I take the position, that x and y value here,
[00:15:40.920 --> 00:15:44.160]   and then I pass that through the scoring function that says, OK,
[00:15:44.160 --> 00:15:46.000]   what is the score that you get for landing
[00:15:46.000 --> 00:15:47.160]   in that particular spot?
[00:15:47.160 --> 00:15:50.200]   And then we could calculate an average score, again,
[00:15:50.200 --> 00:15:51.920]   by means of an integral.
[00:15:51.920 --> 00:15:55.600]   So this may be heartening to say, oh, masses
[00:15:55.600 --> 00:15:58.760]   are actually something that's pretty easy, relatively straightforward.
[00:15:58.760 --> 00:16:01.480]   So probability should be easy and relatively straightforward.
[00:16:01.480 --> 00:16:03.480]   But the trouble is that actually when you really
[00:16:03.480 --> 00:16:05.600]   start to work with it, the math of distributions
[00:16:05.600 --> 00:16:06.760]   is really gnarly.
[00:16:06.760 --> 00:16:10.200]   This math of distributions is also known as measure theory.
[00:16:10.200 --> 00:16:13.160]   And it's something that even people who do PhDs in statistics
[00:16:13.160 --> 00:16:17.680]   struggle with and find maybe to be an impediment more than a help
[00:16:17.680 --> 00:16:19.800]   to their understanding of probability.
[00:16:19.800 --> 00:16:21.800]   So that's a link there to Andrew Gelman's blog
[00:16:21.800 --> 00:16:24.000]   in a discussion of whether measure theory should even
[00:16:24.000 --> 00:16:25.920]   be taught to stats PhDs.
[00:16:25.920 --> 00:16:29.120]   And one of the fundamental reasons why is that integrals are hard
[00:16:29.120 --> 00:16:31.640]   and derivatives are easy, relatively.
[00:16:31.640 --> 00:16:33.840]   So when I want to calculate an integral of something,
[00:16:33.840 --> 00:16:37.720]   calculating it can be basically infinitely difficult,
[00:16:37.720 --> 00:16:40.680]   whereas derivatives can be done automatically by computers,
[00:16:40.680 --> 00:16:42.400]   as we saw during the calculus section.
[00:16:42.400 --> 00:16:45.400]   And then finally, we have to watch out for paradoxes.
[00:16:45.400 --> 00:16:48.320]   So there's a famous Banach-Tarski paradox,
[00:16:48.320 --> 00:16:50.360]   which is pictured on the right-hand side here,
[00:16:50.360 --> 00:16:53.840]   which is that if you're not careful with defining what it means to measure
[00:16:53.840 --> 00:16:57.680]   something and get its size, then with a just basically intuitive
[00:16:57.680 --> 00:16:59.560]   definition, you might end up with a circle
[00:16:59.560 --> 00:17:01.880]   that you can then break apart into pieces, where
[00:17:01.880 --> 00:17:03.800]   when you combine those pieces back together,
[00:17:03.800 --> 00:17:05.560]   the measure of the total has doubled.
[00:17:05.560 --> 00:17:09.560]   You've got two copies of the original when you combined it back together.
[00:17:09.560 --> 00:17:11.960]   So that's a really gnarly paradox, and people
[00:17:11.960 --> 00:17:15.160]   work really hard in measure theory to avoid things like that.
[00:17:15.160 --> 00:17:17.440]   And this is all separate from those philosophical issues
[00:17:17.440 --> 00:17:19.320]   that I identified at the beginning.
[00:17:19.320 --> 00:17:21.720]   What does it really mean to talk about probability?
[00:17:21.720 --> 00:17:25.080]   Even once you've solved that, you have to solve these more mathematical
[00:17:25.080 --> 00:17:26.320]   paradoxes here.
[00:17:26.320 --> 00:17:27.280]   This is bad news.
[00:17:27.280 --> 00:17:29.480]   It means that it's actually really hard to get
[00:17:29.480 --> 00:17:33.360]   a fully, completely rigorous mathematical accounting of what
[00:17:33.360 --> 00:17:36.400]   is going on when you talk about probabilities, distributions,
[00:17:36.400 --> 00:17:38.080]   expectations, and so on.
[00:17:38.080 --> 00:17:40.120]   You open up a whole big can of worms when
[00:17:40.120 --> 00:17:42.000]   you try and be completely rigorous.
[00:17:42.000 --> 00:17:43.920]   We have to be a little bit more intuitive when
[00:17:43.920 --> 00:17:46.880]   we talk about probability, unless we're willing to really dive in
[00:17:46.880 --> 00:17:51.400]   and understand that measure theory, which is a long and lonesome road.
[00:17:51.400 --> 00:17:53.720]   So we're going to go in an intuitive direction
[00:17:53.720 --> 00:17:58.240]   here and focus on what can we understand without diving into that stuff.
[00:17:58.240 --> 00:18:02.640]   So we're going to focus on the concepts and ideas and probability that
[00:18:02.640 --> 00:18:04.720]   show up the most in machine learning.
[00:18:04.720 --> 00:18:07.280]   And in particular, one that I want to really talk about
[00:18:07.280 --> 00:18:09.320]   is the concept of surprise.
[00:18:09.320 --> 00:18:13.160]   And so surprises show up more often than probabilities in machine learning.
[00:18:13.160 --> 00:18:15.480]   Surprises are inverse probabilities, and they're
[00:18:15.480 --> 00:18:17.520]   at the foundation of information theory.
[00:18:17.520 --> 00:18:20.280]   So at, again, an intuitive level, surprise
[00:18:20.280 --> 00:18:22.000]   is closely related to probability.
[00:18:22.000 --> 00:18:23.840]   If something is a little bit less probable,
[00:18:23.840 --> 00:18:26.320]   it happening is a little bit more surprising.
[00:18:26.320 --> 00:18:29.840]   And if something is certain, then it happening is not at all surprising.
[00:18:29.840 --> 00:18:33.520]   If somebody tells me that 2 plus 2 is 4, then I'm not surprised at all.
[00:18:33.520 --> 00:18:37.440]   We could say that I am zero surprised if we were looking to quantify it.
[00:18:37.440 --> 00:18:39.400]   Whereas if something is impossible, then it
[00:18:39.400 --> 00:18:42.960]   happening is more surprising than literally anything else.
[00:18:42.960 --> 00:18:47.680]   And so if somebody, say, told me that 2 plus 2 was equal to 5,
[00:18:47.680 --> 00:18:51.920]   that would be more surprising than, say, getting 1,000 heads in a row.
[00:18:51.920 --> 00:18:54.240]   That's unlikely, but it's not impossible.
[00:18:54.240 --> 00:18:57.040]   2 plus 2 being equal to 5, that's completely impossible.
[00:18:57.040 --> 00:19:00.280]   So there's infinite surprise when something impossible happens.
[00:19:00.280 --> 00:19:02.520]   There's zero surprise when something certain happens.
[00:19:02.520 --> 00:19:05.440]   And then everything else is in between.
[00:19:05.440 --> 00:19:08.560]   So the difference between probability and surprise,
[00:19:08.560 --> 00:19:10.360]   apart from this sort of flipping around,
[00:19:10.360 --> 00:19:13.360]   is that if two unrelated surprising things happen,
[00:19:13.360 --> 00:19:16.360]   we add the surprises instead of multiplying them.
[00:19:16.360 --> 00:19:19.640]   So the probability of two unrelated surprising things,
[00:19:19.640 --> 00:19:23.400]   say, getting 10 coin flips in a row right now,
[00:19:23.400 --> 00:19:27.640]   and it's snowing in Beijing right now, I would multiply those two
[00:19:27.640 --> 00:19:29.040]   probabilities together.
[00:19:29.040 --> 00:19:33.560]   Whereas if I were to take the quantitative surprises involved
[00:19:33.560 --> 00:19:35.680]   in those two events, I would add them together.
[00:19:35.680 --> 00:19:38.120]   If I take-- just to stick with coin tossing again,
[00:19:38.120 --> 00:19:42.080]   coin flipping and dice rolling was the earliest thing handled by probability
[00:19:42.080 --> 00:19:43.360]   back in the 17th century.
[00:19:43.360 --> 00:19:44.840]   So people like those examples.
[00:19:44.840 --> 00:19:49.600]   If I take the probability of two heads, that's 1/2 times 1/2.
[00:19:49.600 --> 00:19:50.400]   And that's 1/4.
[00:19:50.400 --> 00:19:54.320]   If I take the surprise of two heads, I add those two numbers together.
[00:19:54.320 --> 00:19:58.200]   We'll see in a second that it's one bit of surprise to get one head,
[00:19:58.200 --> 00:19:59.880]   and one bit to get another head.
[00:19:59.880 --> 00:20:01.120]   That's two bits.
[00:20:01.120 --> 00:20:04.240]   So together, those desiderata, or those properties,
[00:20:04.240 --> 00:20:07.560]   define the surprise as a function of the probability.
[00:20:07.560 --> 00:20:10.320]   So the surprise of an event is the logarithm
[00:20:10.320 --> 00:20:12.880]   of 1 over the probability of the event, which
[00:20:12.880 --> 00:20:15.040]   is the same, if you remember your logarithm rules,
[00:20:15.040 --> 00:20:18.200]   as the negative logarithm of the probability of the event.
[00:20:18.200 --> 00:20:20.240]   This is also known as the surprise zoll.
[00:20:20.240 --> 00:20:22.040]   There's a couple of different names for it.
[00:20:22.040 --> 00:20:23.880]   If there is a probability density function,
[00:20:23.880 --> 00:20:25.960]   there is essentially a surprise function
[00:20:25.960 --> 00:20:28.640]   defined on the possible outcomes of our random event.
[00:20:28.640 --> 00:20:31.640]   And we can get it from the probability distribution
[00:20:31.640 --> 00:20:34.000]   just by taking its negative logarithm.
[00:20:34.000 --> 00:20:38.160]   You can also just write down a function subject to a few simple constraints,
[00:20:38.160 --> 00:20:40.480]   and then that will turn into a surprise, which
[00:20:40.480 --> 00:20:43.440]   makes it a little bit easier than writing down a probability distribution.
[00:20:43.440 --> 00:20:46.600]   There's more constraints to write down a probability distribution.
[00:20:46.600 --> 00:20:49.480]   There's a close connection between this surprise function
[00:20:49.480 --> 00:20:53.560]   and the entropy, which is that the entropy, which shows up in information
[00:20:53.560 --> 00:20:56.680]   theory, is the expected value of the surprise.
[00:20:56.680 --> 00:21:00.800]   So if I take the surprise function for a given random variable,
[00:21:00.800 --> 00:21:03.960]   maybe if you wanted to imagine what this would be to simulate,
[00:21:03.960 --> 00:21:07.600]   take a whole bunch of values from this random variable,
[00:21:07.600 --> 00:21:11.440]   calculate the surprise, and then look at that average value at the end,
[00:21:11.440 --> 00:21:12.960]   that will give you the entropy.
[00:21:12.960 --> 00:21:16.640]   So the negative logarithm of the probability weighted by the probability,
[00:21:16.640 --> 00:21:17.720]   that's the entropy.
[00:21:17.720 --> 00:21:20.080]   So surprises are measured in bits, which
[00:21:20.080 --> 00:21:22.520]   means you can rigorously and quantitatively say
[00:21:22.520 --> 00:21:25.080]   that one thing is a bit surprising.
[00:21:25.080 --> 00:21:28.240]   The entropy shows up in information theory.
[00:21:28.240 --> 00:21:30.600]   It tells you a lot of things in information theory.
[00:21:30.600 --> 00:21:36.480]   One of the things it says is how difficult it is to compress something.
[00:21:36.480 --> 00:21:39.520]   And so things that are more surprising that more often produce
[00:21:39.520 --> 00:21:42.800]   surprising values are things that are harder to compress.
[00:21:42.800 --> 00:21:45.800]   That's the core idea at the center of information theory.
[00:21:45.800 --> 00:21:51.040]   From this idea of surprise, we can derive the most common process
[00:21:51.040 --> 00:21:53.720]   for doing machine learning by basically doing a competition
[00:21:53.720 --> 00:21:58.280]   to see who can be the least surprised by an outcome before it happens.
[00:21:58.280 --> 00:22:02.520]   We write down how surprised we would be for each outcome before it happens.
[00:22:02.520 --> 00:22:06.600]   So let's say we're betting on a presidential election, a sports game,
[00:22:06.600 --> 00:22:07.440]   something like that.
[00:22:07.440 --> 00:22:11.000]   We each write down, OK, if this candidate wins, I would be this surprised.
[00:22:11.000 --> 00:22:14.520]   If this candidate wins, I would be this other amount surprised.
[00:22:14.520 --> 00:22:17.560]   If this team scores 100 points, I would be this surprised.
[00:22:17.560 --> 00:22:20.400]   If they score 101 points, I would be even more surprised.
[00:22:20.400 --> 00:22:24.360]   By writing down this surprise number for each outcome,
[00:22:24.360 --> 00:22:27.920]   we've effectively given a model that says this is more likely,
[00:22:27.920 --> 00:22:29.040]   this is less likely.
[00:22:29.040 --> 00:22:32.400]   You're allowed in this competition to pick any number greater than or equal
[00:22:32.400 --> 00:22:33.440]   to 0 that you want.
[00:22:33.440 --> 00:22:35.760]   But it's no fair saying that nothing surprises me
[00:22:35.760 --> 00:22:37.560]   by setting them all equal to 0.
[00:22:37.560 --> 00:22:40.280]   And so whoever is least surprised by the outcome
[00:22:40.280 --> 00:22:42.520]   is the person who has come up with a better model.
[00:22:42.520 --> 00:22:46.840]   And from this, we can derive the KL divergence, or the Kullback-Liberli
[00:22:46.840 --> 00:22:51.080]   divergence, and the maximum likelihood estimator as the winning strategy.
[00:22:51.080 --> 00:22:53.760]   So the idea here is that what we want to do
[00:22:53.760 --> 00:22:56.560]   is if we are given data before we do this competition--
[00:22:56.560 --> 00:22:59.680]   so we're given a bunch of previous observations of, say,
[00:22:59.680 --> 00:23:02.840]   previous sports competitions between these two teams,
[00:23:02.840 --> 00:23:06.000]   or previous outcomes from the flipping of this coin,
[00:23:06.000 --> 00:23:10.280]   previous combinations of, say, pictures, and whether a person labeled
[00:23:10.280 --> 00:23:11.920]   said that this picture contains a dog.
[00:23:11.920 --> 00:23:14.000]   And then what we want to do is we want to come up
[00:23:14.000 --> 00:23:18.720]   with a model that minimizes its surprise on the observed data.
[00:23:18.720 --> 00:23:22.640]   And then that should be the best performing model in this competition.
[00:23:22.640 --> 00:23:25.440]   It should win the competition if it's least surprised by the data.
[00:23:25.440 --> 00:23:28.240]   If that data really reflects what we'll see in the future,
[00:23:28.240 --> 00:23:32.160]   then we should win this competition by minimizing the surprise.
[00:23:32.160 --> 00:23:35.440]   And this is where our machine learning loss functions come from.
[00:23:35.440 --> 00:23:37.920]   So the loss functions in machine learning, those things
[00:23:37.920 --> 00:23:40.920]   that we optimized with calculus in the previous sessions
[00:23:40.920 --> 00:23:43.120]   where we talked about gradient descent and calculus,
[00:23:43.120 --> 00:23:45.320]   come from minimizing surprises of data.
[00:23:45.320 --> 00:23:47.480]   So every time you take a probability distribution,
[00:23:47.480 --> 00:23:51.640]   take its negative logarithm, that gives you a new loss function.
[00:23:51.640 --> 00:23:54.680]   And so people didn't necessarily think this through ahead.
[00:23:54.680 --> 00:23:56.560]   They just said something like, oh, you know what makes sense?
[00:23:56.560 --> 00:23:57.480]   Squared error.
[00:23:57.480 --> 00:23:59.360]   That's a really good way to measure my error.
[00:23:59.360 --> 00:24:02.360]   And then later, it's revealed, oh, actually what's going on here
[00:24:02.360 --> 00:24:04.960]   is that you are maximizing a likelihood or minimizing
[00:24:04.960 --> 00:24:07.400]   a surprise of a model on your data.
[00:24:07.400 --> 00:24:09.200]   There's two equivalent ways of looking at it.
[00:24:09.200 --> 00:24:12.200]   In stats, people think of it as likelihood maximization.
[00:24:12.200 --> 00:24:15.360]   In machine learning, people think of it as minimization
[00:24:15.360 --> 00:24:19.280]   of negative logarithms of likelihood or minimization of surprise.
[00:24:19.280 --> 00:24:22.880]   And so this latter way of thinking about it as a minimization
[00:24:22.880 --> 00:24:24.240]   comes from the optimization.
[00:24:24.240 --> 00:24:26.160]   In optimization, we tend to think of ourselves
[00:24:26.160 --> 00:24:28.880]   as minimizing things rather than maximizing things.
[00:24:28.880 --> 00:24:31.240]   But they're effectively the same idea.
[00:24:31.240 --> 00:24:35.040]   So why do we work with surprises rather than probabilities
[00:24:35.040 --> 00:24:37.040]   if they're, in the end, equivalent?
[00:24:37.040 --> 00:24:39.160]   Mathematically, what I'm saying here on this slide
[00:24:39.160 --> 00:24:42.280]   is that maximizing likelihood is the same as minimizing surprise,
[00:24:42.280 --> 00:24:45.920]   since you're just flipping it around with that negative logarithm.
[00:24:45.920 --> 00:24:47.960]   Why flip it around in this particular way?
[00:24:47.960 --> 00:24:50.160]   The reason why is that lots and lots of densities
[00:24:50.160 --> 00:24:53.080]   actually are very simple when you look at their logarithm.
[00:24:53.080 --> 00:24:56.120]   So for example, the Gaussian distribution, the bell curve,
[00:24:56.120 --> 00:24:58.680]   if you look at its probability density function,
[00:24:58.680 --> 00:25:00.640]   it looks like the function on the left.
[00:25:00.640 --> 00:25:01.560]   It's got an exponent.
[00:25:01.560 --> 00:25:03.200]   It's got a square in that exponent.
[00:25:03.200 --> 00:25:05.440]   It's an important function, this squared exponential.
[00:25:05.440 --> 00:25:08.480]   But it's not something that comes up that often in mathematics.
[00:25:08.480 --> 00:25:11.000]   It's not something you immediately think of as like, oh, yeah,
[00:25:11.000 --> 00:25:12.520]   squared exponentials, common function.
[00:25:12.520 --> 00:25:13.680]   Think about it all the time.
[00:25:13.680 --> 00:25:17.040]   Whereas the surprise, just take the negative logarithm of that value,
[00:25:17.040 --> 00:25:21.920]   is a polynomial, x minus mu squared minus a constant, log z.
[00:25:21.920 --> 00:25:25.280]   z happens to be related to the square root of pi, fun stuff like that.
[00:25:25.280 --> 00:25:28.480]   But the key idea here is that on the right-hand side,
[00:25:28.480 --> 00:25:30.200]   once we've taken the negative logarithm,
[00:25:30.200 --> 00:25:33.600]   we've got a simple expression for the surprise,
[00:25:33.600 --> 00:25:35.240]   a polynomial for the surprise.
[00:25:35.240 --> 00:25:37.120]   Whereas we have something that's a lot harder
[00:25:37.120 --> 00:25:39.800]   to calculate for the probability.
[00:25:39.800 --> 00:25:41.880]   Even though these things are fundamentally--
[00:25:41.880 --> 00:25:44.800]   they can be used in equivalent ways, one is easier to use.
[00:25:44.800 --> 00:25:46.400]   The surprise is easier to use.
[00:25:46.400 --> 00:25:47.480]   And this is really common.
[00:25:47.480 --> 00:25:49.200]   Lots and lots of densities that turn out
[00:25:49.200 --> 00:25:54.640]   to be easy to use and important and relevant for machine learning
[00:25:54.640 --> 00:25:58.120]   and for probability in general have a very simple form in the log.
[00:25:58.120 --> 00:26:01.640]   They're called exponential families or log linear families
[00:26:01.640 --> 00:26:02.560]   of distributions.
[00:26:02.560 --> 00:26:06.320]   And the Gaussian is just maybe the most important log linear families.
[00:26:06.320 --> 00:26:10.440]   The Poisson distribution, the Laplace distribution,
[00:26:10.440 --> 00:26:12.840]   lots of other distributions you may have heard of.
[00:26:12.840 --> 00:26:17.520]   Every discrete distribution, these are all examples of log linear families.
[00:26:17.520 --> 00:26:22.720]   In addition to it being simpler to work with the logarithms of densities,
[00:26:22.720 --> 00:26:25.080]   it's also the case that logarithms of densities
[00:26:25.080 --> 00:26:27.640]   actually focus on the parts of the distribution that
[00:26:27.640 --> 00:26:30.760]   are most important, the parts of the probability that are most important.
[00:26:30.760 --> 00:26:34.280]   The important differences in probability are in the unlikely events.
[00:26:34.280 --> 00:26:38.000]   So consider something like the contemporary pandemic.
[00:26:38.000 --> 00:26:41.400]   It's really important to know whether an outbreak that happened
[00:26:41.400 --> 00:26:46.960]   is a once a year event that happens one in every 365 attempts,
[00:26:46.960 --> 00:26:52.160]   or a once in a millennium event, one that happens once in every 365,000
[00:26:52.160 --> 00:26:52.680]   attempts.
[00:26:52.680 --> 00:26:54.220]   That's a really important difference.
[00:26:54.220 --> 00:26:56.600]   Fundamentally, things that happen once a year
[00:26:56.600 --> 00:26:58.560]   may be treated very differently from things
[00:26:58.560 --> 00:27:00.000]   that happen once a millennium.
[00:27:00.000 --> 00:27:02.280]   But the raw values there are really close.
[00:27:02.280 --> 00:27:05.520]   They differ by only 0.03 or so.
[00:27:05.520 --> 00:27:10.480]   And they're also just as close as, say, something that happens 50% of the time
[00:27:10.480 --> 00:27:14.920]   and something that happens 50.0001% of the time.
[00:27:14.920 --> 00:27:20.120]   That difference there between 50% and 50.001% in raw value
[00:27:20.120 --> 00:27:25.960]   is the same as the difference between 1 divided by 365 and 1 divided by 365,000.
[00:27:25.960 --> 00:27:27.720]   Those raw values are very close.
[00:27:27.720 --> 00:27:29.880]   In the case of the values that are close to 0,
[00:27:29.880 --> 00:27:32.040]   we really want those to be treated very differently.
[00:27:32.040 --> 00:27:33.800]   We want those values to actually be thought
[00:27:33.800 --> 00:27:36.000]   of as very far apart from one another.
[00:27:36.000 --> 00:27:39.800]   And so if we take their logarithm, the logarithm differs by about 3.
[00:27:39.800 --> 00:27:42.640]   If I take the logarithm base 10, these are different by three orders
[00:27:42.640 --> 00:27:43.400]   of magnitude.
[00:27:43.400 --> 00:27:45.680]   And so the logarithm will differ by about 3.
[00:27:45.680 --> 00:27:51.320]   Whereas the logarithm of 50 and 50.0001, those things are almost identical.
[00:27:51.320 --> 00:27:52.680]   And that's exactly the case.
[00:27:52.680 --> 00:27:55.520]   A penny is just so slightly not fair.
[00:27:55.520 --> 00:27:58.600]   The penny coin is more likely to come up tails than heads.
[00:27:58.600 --> 00:28:01.080]   But it's so close to fair that it doesn't really matter.
[00:28:01.080 --> 00:28:03.360]   And so that is something that we don't want
[00:28:03.360 --> 00:28:05.720]   to seem different when we're thinking about probabilities.
[00:28:05.720 --> 00:28:08.760]   But these tail events, these rare events, we
[00:28:08.760 --> 00:28:10.800]   want those to look quite different.
[00:28:10.800 --> 00:28:13.120]   So to demonstrate why this is so important,
[00:28:13.120 --> 00:28:16.520]   we're going to play a little game called Spot the Gaussian.
[00:28:16.520 --> 00:28:21.440]   So to remind, the Gaussian probability distribution looks like this.
[00:28:21.440 --> 00:28:23.560]   It's got this squared exponential form.
[00:28:23.560 --> 00:28:27.920]   Just as a hint, Gaussians are also known as bell curves.
[00:28:27.920 --> 00:28:32.040]   So what I'm going to do is I'm going to show you four distributions.
[00:28:32.040 --> 00:28:35.240]   And I'm going to ask you which of these is the Gaussian,
[00:28:35.240 --> 00:28:38.240]   just based off of this definition of a bell curve,
[00:28:38.240 --> 00:28:41.360]   maybe what you know about Gaussians, things like that.
[00:28:41.360 --> 00:28:44.320]   So here are those four densities.
[00:28:44.320 --> 00:28:47.960]   And I'm opening up the ability to answer this.
[00:28:47.960 --> 00:28:49.920]   And let me know which of these things you
[00:28:49.920 --> 00:28:52.360]   think is the Gaussian distribution.
[00:28:52.360 --> 00:28:53.720]   So there's four options here.
[00:28:53.720 --> 00:28:56.160]   They all kind of look like bell curves to me, right?
[00:28:56.160 --> 00:28:58.360]   So there's low values out at the sides.
[00:28:58.360 --> 00:28:59.920]   There's a high value up at the middle.
[00:28:59.920 --> 00:29:02.600]   When I'm looking at my data, this is kind of what I see.
[00:29:02.600 --> 00:29:05.480]   Pretty often, I see there's a common sort of central value,
[00:29:05.480 --> 00:29:07.480]   and then uncommon values at the edges.
[00:29:07.480 --> 00:29:09.680]   And it looks like we got a lot of answers coming in.
[00:29:09.680 --> 00:29:12.280]   There's a consensus on one of the values.
[00:29:12.280 --> 00:29:14.160]   But there's lots of people who think that it
[00:29:14.160 --> 00:29:15.400]   might be something different.
[00:29:15.400 --> 00:29:16.920]   Let me reveal the answer.
[00:29:16.920 --> 00:29:21.120]   All right, the answer was A. But the most common answer was actually B.
[00:29:21.120 --> 00:29:22.360]   That's interesting.
[00:29:22.360 --> 00:29:25.240]   So that just goes to show you that this is a really hard thing to do,
[00:29:25.240 --> 00:29:28.320]   to just look at a distribution and determine, is this a Gaussian
[00:29:28.320 --> 00:29:29.600]   or is this not a Gaussian?
[00:29:29.600 --> 00:29:32.760]   So this example comes from a blog post by Ryan Moulton.
[00:29:32.760 --> 00:29:35.080]   I would strongly recommend you check that out,
[00:29:35.080 --> 00:29:38.040]   because there's a lot of excellent stuff in that blog post, not just
[00:29:38.040 --> 00:29:38.880]   these two games.
[00:29:38.880 --> 00:29:41.960]   So A, the first one there is the Gaussian.
[00:29:41.960 --> 00:29:43.880]   The one that most people thought was a Gaussian
[00:29:43.880 --> 00:29:47.880]   was this logistic distribution, which is quite similar to a Gaussian.
[00:29:47.880 --> 00:29:50.400]   But it's actually a heavy-tailed distribution,
[00:29:50.400 --> 00:29:52.640]   just like answer C, the Cauchy distribution.
[00:29:52.640 --> 00:29:56.520]   This one has much more mass in the unlikely events than a Gaussian.
[00:29:56.520 --> 00:29:58.800]   So if you watch a Gaussian for a really long time,
[00:29:58.800 --> 00:30:02.000]   you're unlikely to see values very far away from the middle.
[00:30:02.000 --> 00:30:04.040]   But if something is logistically distributed,
[00:30:04.040 --> 00:30:06.040]   you're actually quite likely to see those.
[00:30:06.040 --> 00:30:08.600]   One answer, not a lot of people guessed this one,
[00:30:08.600 --> 00:30:11.320]   but D down there, the bottom right-hand corner,
[00:30:11.320 --> 00:30:15.880]   the beta distribution, this one never produces values outside of minus 4
[00:30:15.880 --> 00:30:16.380]   to 4.
[00:30:16.380 --> 00:30:17.880]   This is a beta distribution.
[00:30:17.880 --> 00:30:21.080]   It has what people call compact or finite support.
[00:30:21.080 --> 00:30:25.000]   It only produces values in a small range, as opposed to the Gaussian,
[00:30:25.000 --> 00:30:27.800]   which can, in principle, with very low probability,
[00:30:27.800 --> 00:30:30.320]   produce values that are arbitrarily large.
[00:30:30.320 --> 00:30:32.560]   So it's a big difference from the beta distribution.
[00:30:32.560 --> 00:30:36.000]   It has zero probability outside of the minus 4 to 4 range.
[00:30:36.000 --> 00:30:38.840]   But it actually does look sufficiently similar to a Gaussian
[00:30:38.840 --> 00:30:40.840]   that you might be confused, and you might
[00:30:40.840 --> 00:30:44.040]   think that it is a Gaussian just looking at that density there.
[00:30:44.040 --> 00:30:47.520]   So now we're going to play spot the Gaussian again.
[00:30:47.520 --> 00:30:49.440]   But we're going to look at the log density.
[00:30:49.440 --> 00:30:52.160]   So just to remind, the surprise of a Gaussian
[00:30:52.160 --> 00:30:54.600]   looks like a polynomial function.
[00:30:54.600 --> 00:30:57.440]   Out of the things I'm about to show you, what I want you to do
[00:30:57.440 --> 00:31:00.680]   is spot the quadratic polynomial.
[00:31:00.680 --> 00:31:05.120]   So out of the four things that I am showing here, which of these
[00:31:05.120 --> 00:31:06.560]   is a Gaussian?
[00:31:06.560 --> 00:31:07.960]   So this is a log density.
[00:31:07.960 --> 00:31:09.880]   So it's actually a negative surprise.
[00:31:09.880 --> 00:31:13.520]   So things go down as they become less likely rather than up.
[00:31:13.520 --> 00:31:15.120]   Just a quick note there.
[00:31:15.120 --> 00:31:17.380]   So I'll wait for folks to get their answers in here.
[00:31:17.380 --> 00:31:19.800]   But just looking at these curves here, which one
[00:31:19.800 --> 00:31:22.400]   looks most like a quadratic polynomial
[00:31:22.400 --> 00:31:26.040]   that you have seen out of all of these possible examples?
[00:31:26.040 --> 00:31:29.960]   So it looks like there is mostly a consensus around one answer.
[00:31:29.960 --> 00:31:32.080]   Let's see what that answer was.
[00:31:32.080 --> 00:31:35.560]   Most folks said D. Let's go to the board.
[00:31:35.560 --> 00:31:38.520]   Yes, that is in fact correct.
[00:31:38.520 --> 00:31:40.520]   It's always-- whenever you do something live,
[00:31:40.520 --> 00:31:42.520]   you always worry a little bit it might not work.
[00:31:42.520 --> 00:31:44.560]   But pretty much every time I've ever run this,
[00:31:44.560 --> 00:31:47.680]   people get it right on the second time and not the first.
[00:31:47.680 --> 00:31:49.840]   The wisdom of crowds at least gets it right.
[00:31:49.840 --> 00:31:52.240]   Let's think again about these distributions here.
[00:31:52.240 --> 00:31:54.240]   The logistic and the Cauchy distribution
[00:31:54.240 --> 00:31:56.120]   are these heavy tail distributions
[00:31:56.120 --> 00:31:59.240]   that are much more likely to produce really large values that
[00:31:59.240 --> 00:32:01.880]   are atypical, far away from the center.
[00:32:01.880 --> 00:32:05.120]   And if we look at the tails here,
[00:32:05.120 --> 00:32:07.920]   as we go to minus 4 to plus 4, we
[00:32:07.920 --> 00:32:11.200]   can see that the surprise of the Cauchy is about minus 4.
[00:32:11.200 --> 00:32:13.360]   The surprise of the logistic is about minus 5.
[00:32:13.360 --> 00:32:16.520]   So that's like a 1 in 10,000 kind of chance
[00:32:16.520 --> 00:32:18.360]   as a density at that specific spot.
[00:32:18.360 --> 00:32:21.080]   For the Gaussian, we're down at 10 to the minus 10.
[00:32:21.080 --> 00:32:23.440]   10 to the minus 9 maybe for minus 4.
[00:32:23.440 --> 00:32:27.520]   So that's 5 orders of magnitude less likely for the Gaussian.
[00:32:27.520 --> 00:32:31.880]   Whereas if we look at just the Cauchy and the logistic at minus 4
[00:32:31.880 --> 00:32:34.760]   here, we can see that this is a little bit higher.
[00:32:34.760 --> 00:32:36.760]   This minus 4 here is a little bit higher
[00:32:36.760 --> 00:32:38.160]   than the value for the Gaussian.
[00:32:38.160 --> 00:32:40.200]   But they're so close to each other.
[00:32:40.200 --> 00:32:42.400]   It's much more difficult to see that difference.
[00:32:42.400 --> 00:32:43.800]   And this does, in fact, show up.
[00:32:43.800 --> 00:32:45.640]   When you sample from a Cauchy and a logistic,
[00:32:45.640 --> 00:32:48.560]   you see really large values very, very often.
[00:32:48.560 --> 00:32:50.040]   And this is actually something that
[00:32:50.040 --> 00:32:53.400]   goes all the way to the point of being important for modeling.
[00:32:53.400 --> 00:32:55.480]   People use Gaussian distributions very often
[00:32:55.480 --> 00:32:56.560]   because they're easy to work with.
[00:32:56.560 --> 00:32:58.800]   But sometimes you need something like the Cauchy
[00:32:58.800 --> 00:33:01.880]   of the logistic function to represent unlikely outcomes.
[00:33:01.880 --> 00:33:06.360]   It's something that 538, a major election and poll and sports
[00:33:06.360 --> 00:33:09.960]   modeling blog, they tend to use these heavy tail distributions
[00:33:09.960 --> 00:33:12.760]   now in order to capture these unlikely events that
[00:33:12.760 --> 00:33:14.880]   happen way more often than if you had a Gaussian.
[00:33:14.880 --> 00:33:16.680]   It's also something in financial modeling.
[00:33:16.680 --> 00:33:19.760]   A lot of people use Gaussian models before the financial crisis.
[00:33:19.760 --> 00:33:22.920]   The financial crisis indicated that there are these unlikely events
[00:33:22.920 --> 00:33:25.000]   that we are underestimating the probability of.
[00:33:25.000 --> 00:33:27.360]   The beta distribution shows something in the opposite direction.
[00:33:27.360 --> 00:33:30.680]   The beta distribution never produces values outside of minus 4 to 4.
[00:33:30.680 --> 00:33:33.320]   And we can see that by the fact that the surprise is zooming off
[00:33:33.320 --> 00:33:36.160]   to infinity as we get close to those boundaries there.
[00:33:36.160 --> 00:33:38.920]   I want to spend a little bit more time talking about the Gaussian
[00:33:38.920 --> 00:33:41.040]   distribution because it's a great distribution
[00:33:41.040 --> 00:33:43.520]   and it shows up all the time in machine learning.
[00:33:43.520 --> 00:33:45.640]   And I want to talk about why that is.
[00:33:45.640 --> 00:33:49.120]   So the fundamental reason why Gaussians show up all the time
[00:33:49.120 --> 00:33:51.040]   is because it's easy to work with them.
[00:33:51.040 --> 00:33:52.640]   So when we're working with probabilities,
[00:33:52.640 --> 00:33:56.800]   as I said at the beginning, when it comes time to calculate things,
[00:33:56.800 --> 00:34:00.520]   in theory, what we need to do is do a whole bunch of integrals.
[00:34:00.520 --> 00:34:03.360]   So if I wanted to know the mass of a part of the pizza,
[00:34:03.360 --> 00:34:07.600]   if I wanted to know the average score of somebody who's throwing darts,
[00:34:07.600 --> 00:34:08.680]   I had to do an integral.
[00:34:08.680 --> 00:34:13.520]   So inference, or doing calculations with probabilities,
[00:34:13.520 --> 00:34:17.960]   involves integrals and can be made effectively arbitrarily hard really easily.
[00:34:17.960 --> 00:34:19.880]   It scales really poorly.
[00:34:19.880 --> 00:34:21.600]   Inference scales poorly.
[00:34:21.600 --> 00:34:25.760]   But if you're working with Gaussians, inference becomes just linear algebra.
[00:34:25.760 --> 00:34:28.000]   So that doesn't mean it's conceptually easy.
[00:34:28.000 --> 00:34:31.080]   That doesn't mean it's conceptually trivial or computationally trivial.
[00:34:31.080 --> 00:34:32.560]   It just means it's possible.
[00:34:32.560 --> 00:34:33.760]   It's tractable.
[00:34:33.760 --> 00:34:34.640]   It can scale.
[00:34:34.640 --> 00:34:38.080]   And now that we have specialized compute for doing linear algebra really fast,
[00:34:38.080 --> 00:34:44.320]   GPUs, TPUs, all these nice chips that we have built in the last 10 to 30 years,
[00:34:44.320 --> 00:34:47.600]   depending on the type of chip, we can do linear algebra really fast
[00:34:47.600 --> 00:34:51.280]   in a numerically stable way to get really good answers quickly.
[00:34:51.280 --> 00:34:54.800]   You can see this a little bit if you take a look at the surprise of a Gaussian.
[00:34:54.800 --> 00:34:58.480]   The full surprise of a Gaussian, if you include both the means
[00:34:58.480 --> 00:35:02.600]   and the standard deviations, and you're looking at a multivariate Gaussian,
[00:35:02.600 --> 00:35:06.200]   so the mean is a vector, the standard deviation is actually a matrix,
[00:35:06.200 --> 00:35:08.760]   a correlation matrix that doesn't just tell you
[00:35:08.760 --> 00:35:13.160]   how spread out any individual value is, but also how they relate to one another.
[00:35:13.160 --> 00:35:16.240]   If I write that out, I end up with this expression
[00:35:16.240 --> 00:35:19.160]   for the surprise that is a quadratic form.
[00:35:19.160 --> 00:35:23.440]   It's a matrix equation of a particular type that happens to come up a lot.
[00:35:23.440 --> 00:35:27.240]   That's the matrix equivalent of a second degree polynomial.
[00:35:27.240 --> 00:35:30.680]   It's basically a system of equations, is one way you might think of it,
[00:35:30.680 --> 00:35:33.280]   a system of second order equations.
[00:35:33.280 --> 00:35:34.960]   Now, that's hard.
[00:35:34.960 --> 00:35:37.200]   Sitting down and calculating it by hand takes a lot of time,
[00:35:37.200 --> 00:35:38.960]   but computers can do it really fast.
[00:35:38.960 --> 00:35:42.400]   Just to see that this is something that's conceptually simple,
[00:35:42.400 --> 00:35:45.840]   if we just set the mean to zero and we pretend there's no correlation
[00:35:45.840 --> 00:35:47.720]   between the values we're observing,
[00:35:47.720 --> 00:35:52.760]   then this expression here just turns into x transpose x plus a constant.
[00:35:52.760 --> 00:35:57.240]   Effectively, in the case of Gaussians, surprises are just distances.
[00:35:57.240 --> 00:35:58.920]   It's literally just a length of a vector.
[00:35:58.920 --> 00:36:00.160]   You just do x transpose x.
[00:36:00.160 --> 00:36:01.600]   It's like calculating the norm.
[00:36:01.600 --> 00:36:02.520]   That's wonderful.
[00:36:02.520 --> 00:36:05.320]   If we generalize it a little bit, then maybe you need to know
[00:36:05.320 --> 00:36:08.120]   the distance from the vector to some other vector.
[00:36:08.120 --> 00:36:09.920]   We need to know what this mu is.
[00:36:09.920 --> 00:36:11.560]   If you generalize it all the way,
[00:36:11.560 --> 00:36:13.640]   then there's this matrix transformation in the middle
[00:36:13.640 --> 00:36:16.440]   that's like a change of coordinates or a change of basis to say,
[00:36:16.440 --> 00:36:18.640]   "Well, actually, I measured things in this way,
[00:36:18.640 --> 00:36:20.120]   but in order to get surprises,
[00:36:20.120 --> 00:36:22.240]   I need to measure them in a slightly different way."
[00:36:22.240 --> 00:36:24.280]   Up to that matrix transformation,
[00:36:24.280 --> 00:36:27.720]   it's just distances from the value to its mean.
[00:36:27.720 --> 00:36:31.160]   That's a huge improvement over what you can possibly need to do
[00:36:31.160 --> 00:36:34.280]   to calculate similar things for other distributions.
[00:36:34.280 --> 00:36:37.000]   In general, solving inference problems,
[00:36:37.000 --> 00:36:40.680]   solving probability problems becomes solving a linear algebra problem.
[00:36:40.680 --> 00:36:44.240]   Linear algebra is already the toolkit that we need to understand
[00:36:44.240 --> 00:36:45.840]   so much else in machine learning,
[00:36:45.840 --> 00:36:47.880]   whether it's our models, our data,
[00:36:47.880 --> 00:36:51.920]   or our optimization process in the form of vector calculus.
[00:36:51.920 --> 00:36:54.400]   There's a unity of tools that comes together
[00:36:54.400 --> 00:36:56.560]   if we end up using Gaussians for our surprise.
[00:36:56.560 --> 00:37:00.720]   This is one reason for the popularity of the squared error as a loss function.
[00:37:00.720 --> 00:37:05.600]   The squared error is exactly the distance between our data and some value,
[00:37:05.600 --> 00:37:06.640]   the value mu there.
[00:37:06.640 --> 00:37:08.840]   Maybe we calculate mu as a function of something else.
[00:37:08.840 --> 00:37:12.080]   The core idea here is that we simplify things down
[00:37:12.080 --> 00:37:14.320]   from all the problems that could arise in probability
[00:37:14.320 --> 00:37:16.520]   down to just linear algebra problems.
[00:37:16.520 --> 00:37:17.920]   That's good news.
[00:37:17.920 --> 00:37:22.000]   It's good news that the Gaussian exists as this option that we have,
[00:37:22.000 --> 00:37:23.640]   but ease of use wouldn't mean that much
[00:37:23.640 --> 00:37:26.160]   if Gaussians didn't actually show up often.
[00:37:26.160 --> 00:37:27.520]   But they actually do,
[00:37:27.520 --> 00:37:30.040]   thanks to the central limit theorem,
[00:37:30.040 --> 00:37:32.760]   this very important limit theorem
[00:37:32.760 --> 00:37:35.440]   that says if many things that are random
[00:37:35.440 --> 00:37:38.440]   interact in a weak way or don't interact at all,
[00:37:38.440 --> 00:37:41.200]   then the distribution of the result is approximately Gaussian.
[00:37:41.200 --> 00:37:44.280]   The more things there are and the weaker the interactions,
[00:37:44.280 --> 00:37:46.840]   the more like a Gaussian this thing becomes.
[00:37:46.840 --> 00:37:47.960]   What that says is,
[00:37:47.960 --> 00:37:50.040]   let's say I'm measuring a couple of things,
[00:37:50.040 --> 00:37:53.360]   like I'm measuring a couple of important relevant variables
[00:37:53.360 --> 00:37:55.080]   for some random phenomenon.
[00:37:55.080 --> 00:37:57.600]   Then there's a whole bunch of other stuff I'm not measuring.
[00:37:57.600 --> 00:38:00.080]   Maybe this is user behavior on a website
[00:38:00.080 --> 00:38:02.960]   and I'm measuring, say, how long it takes them to purchase something.
[00:38:02.960 --> 00:38:05.960]   And I know there's some demographic information that's maybe important.
[00:38:05.960 --> 00:38:08.680]   There's some stuff about their past behavior that's really important.
[00:38:08.680 --> 00:38:11.360]   And on top of that, there's a bunch of things that I can't measure,
[00:38:11.360 --> 00:38:13.520]   like, you know, what they had for breakfast that morning
[00:38:13.520 --> 00:38:15.920]   and maybe whether the doorbell rings
[00:38:15.920 --> 00:38:18.240]   while they're about to complete their transaction.
[00:38:18.240 --> 00:38:20.000]   Those things, there's lots of them.
[00:38:20.000 --> 00:38:20.760]   They're random.
[00:38:20.760 --> 00:38:22.520]   They don't really interact with one another.
[00:38:22.520 --> 00:38:25.400]   That will end up giving a Gaussian distribution
[00:38:25.400 --> 00:38:29.520]   for the time it takes for customers to check out on my website.
[00:38:29.520 --> 00:38:30.760]   There's also examples from science.
[00:38:30.760 --> 00:38:35.360]   But the important takeaway here is that we lucked out in a lot of ways
[00:38:35.360 --> 00:38:39.160]   and that Gaussians do show up a good amount due to the central limit theorem.
[00:38:39.160 --> 00:38:40.520]   And they're easy to work with.
[00:38:40.520 --> 00:38:45.000]   This is one of those rare wins that you get in mathematics and engineering
[00:38:45.000 --> 00:38:47.640]   that what's easy to do and what's the right thing to do
[00:38:47.640 --> 00:38:49.120]   end up aligning pretty nicely.
[00:38:49.120 --> 00:38:52.920]   And for folks who are on the more abstract math side,
[00:38:52.920 --> 00:38:54.560]   there's a nice thing about Gaussians,
[00:38:54.560 --> 00:38:57.880]   which is that everything about them can be derived from one equation,
[00:38:57.880 --> 00:38:59.720]   this differential equation here.
[00:38:59.720 --> 00:39:02.800]   The derivative of that probability density function
[00:39:02.800 --> 00:39:06.960]   is equal to the negative argument times the probability density function.
[00:39:06.960 --> 00:39:09.840]   So this is not that different from, say, the exponential function.
[00:39:09.840 --> 00:39:12.800]   The exponential function is also defined with a differential equation.
[00:39:12.800 --> 00:39:14.640]   Its derivative is equal to itself.
[00:39:14.640 --> 00:39:17.560]   But so this one's a little bit more complicated than that.
[00:39:17.560 --> 00:39:20.240]   There's lots of things that can be defined with differential equations.
[00:39:20.240 --> 00:39:22.080]   The Gaussian family is just one of them.
[00:39:22.080 --> 00:39:24.400]   But all the important properties of the Gaussian family
[00:39:24.400 --> 00:39:27.520]   can be derived without solving for their explicit form
[00:39:27.520 --> 00:39:29.520]   just from this differential equation.
[00:39:29.520 --> 00:39:32.720]   So there's a little blog post with some details about that linked
[00:39:32.720 --> 00:39:34.520]   in the slides if you're curious about that.
[00:39:34.520 --> 00:39:36.400]   But all these things, like the central limit theorem,
[00:39:36.400 --> 00:39:39.320]   actually comes out from thinking about this differential equation
[00:39:39.320 --> 00:39:41.680]   sufficiently, some stuff about Fourier transforms,
[00:39:41.680 --> 00:39:44.720]   the importance of and centrality of Gaussians
[00:39:44.720 --> 00:39:47.280]   as the only isotropic independent distribution.
[00:39:47.280 --> 00:39:50.280]   All this pops right out from a single differential equation, which
[00:39:50.280 --> 00:39:52.040]   is not necessarily useful.
[00:39:52.040 --> 00:39:55.280]   I don't think it really has that great intuition about Gaussians
[00:39:55.280 --> 00:39:56.200]   that comes from this.
[00:39:56.200 --> 00:39:57.360]   But it is very beautiful.
[00:39:57.360 --> 00:40:01.320]   So on that note, I'd like to close out and put everything together.
[00:40:01.320 --> 00:40:03.880]   Just one last time, go through that high-level idea
[00:40:03.880 --> 00:40:07.320]   of what was this course about in terms of mathematics for machine learning
[00:40:07.320 --> 00:40:09.120]   now that we've made it all the way through.
[00:40:09.120 --> 00:40:13.000]   So optimization and machine learning intersect in at least three ways.
[00:40:13.000 --> 00:40:15.760]   Machine learning is programming by optimization.
[00:40:15.760 --> 00:40:19.280]   And linear algebra tells us what objects are being optimized.
[00:40:19.280 --> 00:40:21.800]   Calculus tells us how we do that optimization.
[00:40:21.800 --> 00:40:25.200]   And probability and statistics tells us what we want to optimize.
[00:40:25.200 --> 00:40:29.680]   And so in just a single slide that just has these three ideas written out
[00:40:29.680 --> 00:40:33.920]   in three lines of math, it's that our parameters, theta, are an array.
[00:40:33.920 --> 00:40:35.600]   We update those parameters.
[00:40:35.600 --> 00:40:39.600]   We change them over time by calculating the gradient of a function called
[00:40:39.600 --> 00:40:43.360]   the loss and going down the negative gradient to update theta,
[00:40:43.360 --> 00:40:45.520]   so to minimize this value of the loss.
[00:40:45.520 --> 00:40:46.760]   And what is that loss?
[00:40:46.760 --> 00:40:49.520]   It's the negative log of the probability of the data
[00:40:49.520 --> 00:40:51.320]   as a function of those parameters.
[00:40:51.320 --> 00:40:54.800]   So as I move the parameters around, the probability of the data changes.
[00:40:54.800 --> 00:40:58.120]   And I want to make that probability as high as possible,
[00:40:58.120 --> 00:41:01.600]   or I want to make that surprise as low as possible.
[00:41:01.600 --> 00:41:05.880]   These three statements here are at the sort of core of machine learning.
[00:41:05.880 --> 00:41:07.640]   They are the central ideas.
[00:41:07.640 --> 00:41:10.000]   And in these last couple of sessions, we've
[00:41:10.000 --> 00:41:13.640]   talked about each of them in detail so that you can understand really
[00:41:13.640 --> 00:41:17.760]   what's going on and what's at stake in all three of these lines.
[00:41:17.760 --> 00:41:20.400]   Mathematics is famous for its capacity to compress
[00:41:20.400 --> 00:41:25.720]   a tremendous amount of insight and ideas down into just a few symbols.
[00:41:25.720 --> 00:41:27.720]   To write a mathematics paper is essentially
[00:41:27.720 --> 00:41:30.200]   a compression of the ideas in your head.
[00:41:30.200 --> 00:41:32.320]   And the idea is now you have this tiny nugget here,
[00:41:32.320 --> 00:41:33.800]   and you can expand it out later.
[00:41:33.800 --> 00:41:37.760]   You can unzip it, uncompress it, and think through these ideas
[00:41:37.760 --> 00:41:40.400]   further and understand more and more about machine learning.
[00:41:40.400 --> 00:41:44.960]   So to close out today, I'd like to talk about some additional resources,
[00:41:44.960 --> 00:41:47.280]   as I have done in the previous session.
[00:41:47.280 --> 00:41:50.800]   So first, some stuff about additional resources and probability.
[00:41:50.800 --> 00:41:54.000]   If you really want to dive into those mathematical foundations
[00:41:54.000 --> 00:41:57.080]   of probability, if you want to understand that measure theory,
[00:41:57.080 --> 00:42:00.480]   that theory of distributions of mass and measure,
[00:42:00.480 --> 00:42:03.680]   then the best choice is this analysis measure and probability
[00:42:03.680 --> 00:42:05.200]   book by Marcus Povato.
[00:42:05.200 --> 00:42:06.320]   It's very visual.
[00:42:06.320 --> 00:42:08.200]   There's lots of diagrams in it.
[00:42:08.200 --> 00:42:10.640]   But it's extremely rigorous while providing that degree
[00:42:10.640 --> 00:42:12.360]   of intuition and accessibility.
[00:42:12.360 --> 00:42:14.640]   Though I will say this is a math textbook,
[00:42:14.640 --> 00:42:16.600]   and assumes to read it on your own, you want
[00:42:16.600 --> 00:42:18.520]   to know how to tackle a math textbook.
[00:42:18.520 --> 00:42:21.680]   If you just want a longer explication of these ideas of surprise and entropy
[00:42:21.680 --> 00:42:24.920]   and how they relate to one another, I have a blog post about information
[00:42:24.920 --> 00:42:25.440]   theory.
[00:42:25.440 --> 00:42:28.120]   There's also a great one by Chris Ola that explains
[00:42:28.120 --> 00:42:30.080]   how to visualize information theory.
[00:42:30.080 --> 00:42:32.280]   Those philosophical disputes about probability,
[00:42:32.280 --> 00:42:34.840]   I like chin scratching a little bit about those ideas.
[00:42:34.840 --> 00:42:37.800]   What does it really mean to think about our uncertainty
[00:42:37.800 --> 00:42:39.160]   or to think about frequency?
[00:42:39.160 --> 00:42:42.720]   The Stanford Encyclopedia of Philosophy has a really great review article
[00:42:42.720 --> 00:42:44.200]   on interpretations of probability.
[00:42:44.200 --> 00:42:46.800]   It's helpful for getting your head straight on what they are.
[00:42:46.800 --> 00:42:49.480]   And it's despite the reputation maybe of philosophy,
[00:42:49.480 --> 00:42:52.960]   especially among engineers, as being impenetrable or useless,
[00:42:52.960 --> 00:42:56.320]   this is an extremely clearly written and useful article.
[00:42:56.320 --> 00:42:57.520]   So highly recommended.
[00:42:57.520 --> 00:43:01.720]   If all this stuff about these ideas, this intuition, this deep mathematics
[00:43:01.720 --> 00:43:03.640]   is not that interesting to you, and you really
[00:43:03.640 --> 00:43:05.960]   would rather get cracking on practical problems quickly
[00:43:05.960 --> 00:43:09.360]   with real code on real data, Bayesian Methods for Hackers
[00:43:09.360 --> 00:43:12.480]   is your best option here by Cam Davidson-Pylan.
[00:43:12.480 --> 00:43:15.520]   It's an interactive textbook, basically a GitHub repository
[00:43:15.520 --> 00:43:17.960]   of Jupyter notebooks on Bayesian methods in Python
[00:43:17.960 --> 00:43:20.760]   that's aimed at getting hacking as quickly as possible.
[00:43:20.760 --> 00:43:23.080]   And there's a lot of really great ideas in that.
[00:43:23.080 --> 00:43:27.280]   And the concept of surprise and entropy, these show up very quickly.
[00:43:27.280 --> 00:43:31.160]   So I mentioned that in order to understand that analysis and measure
[00:43:31.160 --> 00:43:34.760]   theory textbook, you would really need to understand how to read a math textbook.
[00:43:34.760 --> 00:43:36.680]   And in general, in order to understand math,
[00:43:36.680 --> 00:43:40.520]   there's no better way than to read the books of math that are out there.
[00:43:40.520 --> 00:43:42.320]   Unfortunately, they're pretty hard to read.
[00:43:42.320 --> 00:43:45.800]   And they use a different set of skills than an engineer or a programmer
[00:43:45.800 --> 00:43:46.920]   is used to using.
[00:43:46.920 --> 00:43:48.400]   There's always a connection.
[00:43:48.400 --> 00:43:50.760]   There's a deep connection always, I think,
[00:43:50.760 --> 00:43:53.320]   between something in mathematics and something in programming.
[00:43:53.320 --> 00:43:54.880]   But it's not always obvious.
[00:43:54.880 --> 00:43:58.040]   And so there's a great blog called The Intersection of Math and Programming
[00:43:58.040 --> 00:44:00.800]   by Jeremy Kuhn that is my recommendation of if you just
[00:44:00.800 --> 00:44:04.920]   want to keep going and dive into math based off of what we've
[00:44:04.920 --> 00:44:06.720]   learned in this course, where should you go?
[00:44:06.720 --> 00:44:07.280]   It's here.
[00:44:07.280 --> 00:44:10.280]   There's a great book, A Programmer's Introduction to Mathematics,
[00:44:10.280 --> 00:44:12.560]   that teaches you how to take the ideas that you've
[00:44:12.560 --> 00:44:15.200]   learned from working with computers and working in engineering
[00:44:15.200 --> 00:44:18.600]   and apply them to mathematics and translate all that intuition,
[00:44:18.600 --> 00:44:21.640]   that way of thinking, that way of approaching new ideas,
[00:44:21.640 --> 00:44:22.920]   and apply it to mathematics.
[00:44:22.920 --> 00:44:24.080]   And it's fabulous.
[00:44:24.080 --> 00:44:25.360]   It's extremely well-written.
[00:44:25.360 --> 00:44:28.240]   It has a clear pedagogical idea behind it.
[00:44:28.240 --> 00:44:29.880]   And it does it extremely well.
[00:44:29.880 --> 00:44:32.960]   So I highly recommend that book, higher than basically
[00:44:32.960 --> 00:44:35.520]   any other piece of writing on mathematics
[00:44:35.520 --> 00:44:39.200]   that I recommend to people who are interested in learning about it.
[00:44:39.200 --> 00:44:39.760]   Hey, friends.
[00:44:39.760 --> 00:44:40.760]   Charles here.
[00:44:40.760 --> 00:44:42.040]   Thanks for watching my video.
[00:44:42.040 --> 00:44:43.960]   If you enjoyed it, give it a like.
[00:44:43.960 --> 00:44:47.320]   If you want more Wits by Seas tutorial and demo content,
[00:44:47.320 --> 00:44:48.680]   subscribe to our channel.
[00:44:48.680 --> 00:44:51.880]   And if you've got any questions, comments, ideas for future videos,
[00:44:51.880 --> 00:44:53.080]   leave a comment below.
[00:44:53.080 --> 00:44:55.240]   We'd love to hear from you.
[00:44:55.240 --> 00:44:58.600]   [MUSIC PLAYING]
[00:44:58.600 --> 00:45:01.960]   [TYPING]
[00:45:01.960 --> 00:45:04.540]   (upbeat music)

