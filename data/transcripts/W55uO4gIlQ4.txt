
[00:00:00.000 --> 00:00:08.560]   If it doesn't actually solve a real problem that a real human is willing to part money
[00:00:08.560 --> 00:00:13.800]   with in order to have that problem solved for them, it doesn't matter how sophisticated
[00:00:13.800 --> 00:00:19.440]   it is, or actually it doesn't matter how much data you have in solving the right problem.
[00:00:19.440 --> 00:00:23.280]   You're listening to Gradient Dissent, a show where we learn about making machine learning
[00:00:23.280 --> 00:00:24.920]   models work in the real world.
[00:00:24.920 --> 00:00:27.160]   I'm your host, Lukas Biewald.
[00:00:27.160 --> 00:00:30.960]   Today I'm talking to Angela Bassa and Danielle Dean.
[00:00:30.960 --> 00:00:36.080]   Angela is an expert in building and leading data teams, and she's the director of data
[00:00:36.080 --> 00:00:38.320]   science at iRobot.
[00:00:38.320 --> 00:00:42.520]   Danielle is the technical director of machine learning at iRobot, previously at Microsoft,
[00:00:42.520 --> 00:00:46.000]   and has a PhD in quantitative psychology from UNC.
[00:00:46.000 --> 00:00:54.400]   All right, so Danielle and Angela, so you are both super technical, but also managers
[00:00:54.400 --> 00:00:55.840]   and leaders of teams.
[00:00:55.840 --> 00:01:01.440]   So I thought we might start out with your thoughts on how you've approached building
[00:01:01.440 --> 00:01:07.600]   a technical team, how you got started, and what you've learned as you've built teams.
[00:01:07.600 --> 00:01:13.280]   Yeah, it's really nice to be here talking with you guys.
[00:01:13.280 --> 00:01:20.720]   So at iRobot, we've had an interesting evolution of how we approach machine learning within
[00:01:20.720 --> 00:01:27.480]   the organization, and it's really quite significant to have this partnership because Danielle
[00:01:27.480 --> 00:01:31.240]   is just amazing, and I really, really, really love working with her.
[00:01:31.240 --> 00:01:36.440]   And so the two of us have a really good complementary style.
[00:01:36.440 --> 00:01:43.600]   So my background is a little bit more towards theoretical and applied math, and I sort of
[00:01:43.600 --> 00:01:51.800]   grew up in modeling of systems, so modeling soybean trade and progression in agricultural
[00:01:51.800 --> 00:01:58.960]   settings, modeling epidemiology processes within certain geographies or disease spaces.
[00:01:58.960 --> 00:02:07.000]   So all of that is very distant from robotics, but it turns out that a lot of the tooling,
[00:02:07.000 --> 00:02:11.360]   and not to bring agriculture again, but there's a lot of cross-pollination that's been really
[00:02:11.360 --> 00:02:12.360]   useful.
[00:02:12.360 --> 00:02:16.320]   And Danielle also has a really different background that I'll let her talk to, which
[00:02:16.320 --> 00:02:19.760]   sort of gives robustness to how we approach these problems.
[00:02:19.760 --> 00:02:24.160]   Yeah, super excited to be here today, and yeah, thanks, Angela, for the introduction.
[00:02:24.160 --> 00:02:28.960]   It's been great working at iRobot and thinking about building the machine learning organization.
[00:02:28.960 --> 00:02:32.480]   I think one thing that's been really great is thinking about how do we bring different
[00:02:32.480 --> 00:02:36.360]   perspectives and different people into the skill set.
[00:02:36.360 --> 00:02:39.600]   So people from computer science background, people from statistics background, people
[00:02:39.600 --> 00:02:44.120]   from geology and biology and chemistry, and people have really different experiences.
[00:02:44.120 --> 00:02:48.840]   And so thinking about building a team that can solve real world problems for our customers
[00:02:48.840 --> 00:02:51.080]   is really exciting.
[00:02:51.080 --> 00:02:56.840]   So like, for example, when you two work together, can you think of a time that you sort of brought
[00:02:56.840 --> 00:02:58.320]   different approaches to a problem?
[00:02:58.320 --> 00:03:02.360]   Or I mean, how would you kind of explain the difference between the way you think through
[00:03:02.360 --> 00:03:03.360]   things?
[00:03:03.360 --> 00:03:11.440]   So I just grew up working in investment banking and strategy consulting, and then marketing
[00:03:11.440 --> 00:03:12.440]   organizations.
[00:03:12.440 --> 00:03:20.680]   So my background is a little bit unorthodox, but sort of very real world oriented, which
[00:03:20.680 --> 00:03:23.560]   is sort of the part that has been helpful.
[00:03:23.560 --> 00:03:30.680]   And one anecdote that I like to sort of highlight to this end isn't my personal one, is another
[00:03:30.680 --> 00:03:35.520]   leader on our team, Teresa Borkwich, who runs the data, who manages the data science team.
[00:03:35.520 --> 00:03:37.720]   And she has a marine biology background.
[00:03:37.720 --> 00:03:46.000]   And so when we have been thinking about how is it that we analyze data that's coming from
[00:03:46.000 --> 00:03:49.840]   teaming missions, so we have robots that can work in tandem, and you know, there's the
[00:03:49.840 --> 00:03:55.440]   mopping robot and the vacuum robot, so you can have the robot vacuum your room and then
[00:03:55.440 --> 00:04:00.720]   go to a different place, and then the mop comes back afterwards and completes the mission.
[00:04:00.720 --> 00:04:05.320]   And so she had a really interesting way of thinking about that problem, because she had
[00:04:05.320 --> 00:04:08.520]   done a lot of research with pods of dolphin.
[00:04:08.520 --> 00:04:12.940]   And so she's looking at the artifacts of that system.
[00:04:12.940 --> 00:04:15.440]   Because dolphin can't tell you what their intent was, they can't tell you what they
[00:04:15.440 --> 00:04:20.480]   were trying to do, but they are acting and through sensors and data collection, you can
[00:04:20.480 --> 00:04:27.440]   sort of get the artifacts of that and then do analysis to try to derive deeper insights.
[00:04:27.440 --> 00:04:31.520]   And she was able to bring all of that knowledge so that literature exists, right, that that
[00:04:31.520 --> 00:04:35.720]   knowledge exists, and she just was able to think about it differently, and really enrich
[00:04:35.720 --> 00:04:38.260]   the way that our team dealt with that.
[00:04:38.260 --> 00:04:45.280]   So we do have sort of a bias towards real world experience and ways in which we understand
[00:04:45.280 --> 00:04:46.760]   that we're looking at fossils.
[00:04:46.760 --> 00:04:51.400]   And so when we project what the dinosaur looks like, our dinosaurs tend to not have cartilage
[00:04:51.400 --> 00:04:56.080]   and feathers, because we wouldn't have known that just from the fossils.
[00:04:56.080 --> 00:05:00.800]   But we know that the real world is richer than what we're looking at.
[00:05:00.800 --> 00:05:06.960]   And I think that allows us to build sort of more solid answers to how we use these ML
[00:05:06.960 --> 00:05:07.960]   applications.
[00:05:07.960 --> 00:05:08.960]   Interesting.
[00:05:08.960 --> 00:05:11.400]   Do you have anything to add?
[00:05:11.400 --> 00:05:12.600]   That was such a good story.
[00:05:12.600 --> 00:05:15.600]   I can't add to that.
[00:05:15.600 --> 00:05:21.560]   It's funny, I mean, just as an aside, I remember I had a, when I, the first machine learning
[00:05:21.560 --> 00:05:27.640]   team I worked on, my boss, Jean-Marc, he always said that he liked to hire biologists because
[00:05:27.640 --> 00:05:32.560]   they look at the specific examples versus, he actually was a physicist, and he's like,
[00:05:32.560 --> 00:05:36.640]   I hate hiring other physicists because they always try to like, kind of look in generalities
[00:05:36.640 --> 00:05:37.640]   instead of the specific.
[00:05:37.640 --> 00:05:42.040]   And he felt like, you know, what the team really needed was more people to kind of just
[00:05:42.040 --> 00:05:46.520]   look at the actual training data, like the specific things that were feeding into the
[00:05:46.520 --> 00:05:47.520]   model.
[00:05:47.520 --> 00:05:50.480]   So it's funny, I haven't thought about that in 15 years, maybe, but he always was, he
[00:05:50.480 --> 00:05:52.480]   was always talking about that.
[00:05:52.480 --> 00:05:53.480]   Yeah.
[00:05:53.480 --> 00:05:59.360]   And it's huge in our domain, because we have these robots deployed literally in every time
[00:05:59.360 --> 00:06:02.320]   zone globally, all across the world.
[00:06:02.320 --> 00:06:06.440]   And you know, I've never lived in every place in the world.
[00:06:06.440 --> 00:06:13.800]   So we will look at data, we will see information, and I will construct a mental model of what
[00:06:13.800 --> 00:06:14.840]   might be happening.
[00:06:14.840 --> 00:06:21.220]   But if we don't have a team that's sort of robust, and can challenge a lot of our heuristics
[00:06:21.220 --> 00:06:24.600]   and baked in assumptions and go, you know, I don't think that means what we think it
[00:06:24.600 --> 00:06:25.640]   means.
[00:06:25.640 --> 00:06:29.000]   And it forces exactly what you're talking about, you know, descending into the particulars
[00:06:29.000 --> 00:06:35.200]   and really examining what is it that the data is telling us, not what we hope it aligns
[00:06:35.200 --> 00:06:41.360]   with, because we have this sort of perfect first principles model of what it should be.
[00:06:41.360 --> 00:06:45.080]   iRobot has been around for a long time, building robots.
[00:06:45.080 --> 00:06:49.680]   And I think robotics, you know, traditionally, you know, didn't do a lot of machine learning.
[00:06:49.680 --> 00:06:54.000]   I mean, always, you know, I think there's always obviously relevant, but it wasn't kind
[00:06:54.000 --> 00:06:57.240]   of machine learning first until, you know, maybe recently.
[00:06:57.240 --> 00:07:01.720]   I'm kind of curious, like the evolution of, if you know it, of iRobot's thinking about
[00:07:01.720 --> 00:07:02.720]   ML.
[00:07:02.720 --> 00:07:06.600]   Like, when did it, like, when did you start to think about, okay, we need to build ML
[00:07:06.600 --> 00:07:08.760]   models and get them in production?
[00:07:08.760 --> 00:07:14.280]   When did you start, you know, kind of building an ML skill set at iRobot?
[00:07:14.280 --> 00:07:18.320]   So I think it's interesting thinking about iRobot's history when they first started over
[00:07:18.320 --> 00:07:20.680]   30 years ago now.
[00:07:20.680 --> 00:07:27.080]   We really, almost every single part of the solution had to be made by iRobot.
[00:07:27.080 --> 00:07:31.440]   Thinking about from the navigation stack to the hardware stack, to all the software pieces,
[00:07:31.440 --> 00:07:36.800]   to how the robot navigates the world and how it uses all that different sensor information.
[00:07:36.800 --> 00:07:42.400]   But as the field has changed a lot, and especially as the AI field has changed and deep learning
[00:07:42.400 --> 00:07:46.040]   has really transformed and the quality of solutions that can come from machine learning
[00:07:46.040 --> 00:07:51.220]   have really transformed, iRobot's looked at, hey, there's solutions out in the industry
[00:07:51.220 --> 00:07:56.840]   that we can leverage and we can improve our products using those skill sets and expertise.
[00:07:56.840 --> 00:08:01.360]   So I think machine learning has been at iRobot for quite a while now.
[00:08:01.360 --> 00:08:06.040]   Mainly started in research areas and thinking about how can we use that research, how can
[00:08:06.040 --> 00:08:10.080]   we start these research projects and think about how we can improve the quality of our
[00:08:10.080 --> 00:08:14.280]   navigation stack, how can we improve the quality of our cleaning solutions, how can we improve
[00:08:14.280 --> 00:08:16.520]   the quality of our robotics overall.
[00:08:16.520 --> 00:08:21.140]   But just recently, the last few years, it's moved from a research stage to actually being
[00:08:21.140 --> 00:08:26.980]   in production solutions, everywhere from improving our digital experiences in the applications
[00:08:26.980 --> 00:08:32.640]   to improving our hardware solutions for things like navigation and cleaning experiences.
[00:08:32.640 --> 00:08:36.440]   So it's been interesting to see the journey and I think machine learning is starting to
[00:08:36.440 --> 00:08:40.860]   be a bigger piece of the iRobot solutions moving forward.
[00:08:40.860 --> 00:08:48.640]   When do you think it first became like a production thing and what was the impetus?
[00:08:48.640 --> 00:08:51.260]   What was the application that sort of drove it?
[00:08:51.260 --> 00:08:59.900]   So initially, I think the first application that we could really call ML, if not ML adjacent,
[00:08:59.900 --> 00:09:09.420]   really ML, is the SLAM, which is the localization and the mapping of how the robot navigates
[00:09:09.420 --> 00:09:10.840]   its space.
[00:09:10.840 --> 00:09:16.180]   And that uses a lot of the same methods and a lot of the same now modern tooling.
[00:09:16.180 --> 00:09:21.100]   Back then, a lot of the tooling had to be invented and had to be invented by iRobot.
[00:09:21.100 --> 00:09:26.620]   And so I think the legacy of ML applications in production at iRobot, if you include the
[00:09:26.620 --> 00:09:30.940]   SLAM component, is actually quite longstanding.
[00:09:30.940 --> 00:09:38.600]   But in terms of the more typically defined ML, I think it really wasn't something that
[00:09:38.600 --> 00:09:46.400]   could have been as important a part of the strategy as it is right now until the robots
[00:09:46.400 --> 00:09:47.820]   became connected.
[00:09:47.820 --> 00:09:53.460]   So for a very long time, these robots were completely self-sufficient closed systems.
[00:09:53.460 --> 00:09:59.160]   They came out of the manufacturing line onto an inventory somewhere into a customer's home.
[00:09:59.160 --> 00:10:04.380]   And then it just worked and there was no way to either collect any information off it or
[00:10:04.380 --> 00:10:08.920]   to send information to it to modify behavior.
[00:10:08.920 --> 00:10:14.680]   In late 2015, when we started having the IoT connection component to the stack, that really
[00:10:14.680 --> 00:10:19.780]   opened the door to improve data collection, which is really the thing without which you
[00:10:19.780 --> 00:10:28.740]   can't have meaningful ML that actually does something that feels automagical to the customer
[00:10:28.740 --> 00:10:29.800]   experience.
[00:10:29.800 --> 00:10:37.120]   So I think that's from a historic perspective where iRobot started using ML in the production
[00:10:37.120 --> 00:10:38.200]   environment.
[00:10:38.200 --> 00:10:43.800]   And I think also one thing that shapes the iRobot story quite deeply is exactly what
[00:10:43.800 --> 00:10:49.480]   Danielle was saying, is that because a lot of the initial tooling was built in-house,
[00:10:49.480 --> 00:10:59.180]   we have had a really interesting blend of standard tool choices versus the deep customization
[00:10:59.180 --> 00:11:03.160]   that's really part of the DNA of the company.
[00:11:03.160 --> 00:11:08.640]   So that's one of the things that has been really interesting over the last two years,
[00:11:08.640 --> 00:11:14.240]   especially once this really proved itself internally and we've been able to show, to
[00:11:14.240 --> 00:11:19.960]   demonstrate just how valuable this is both for our internal use, just to improve our
[00:11:19.960 --> 00:11:27.360]   own software development capability, but also to help shape where the strategic roadmap
[00:11:27.360 --> 00:11:33.360]   might go, as well as all the other ways in which we can use ML answers to improve the
[00:11:33.360 --> 00:11:34.360]   business.
[00:11:34.360 --> 00:11:35.880]   That's so interesting.
[00:11:35.880 --> 00:11:41.240]   So it was really internet connectivity that kind of made ML applications possible.
[00:11:41.240 --> 00:11:48.200]   I'm not sure if it's possible, but it's what finally made the case that even if it had
[00:11:48.200 --> 00:11:53.200]   been possible before, it might've been prohibitive to collect enough training and validation
[00:11:53.200 --> 00:12:00.240]   data for these things to be robust in a way that will work on an apartment in Singapore,
[00:12:00.240 --> 00:12:03.440]   the same way that it will work on a ranch in Texas.
[00:12:03.440 --> 00:12:11.080]   So the ability to really collect the kind of complete picture of what it is that these
[00:12:11.080 --> 00:12:15.920]   machine learning algorithms are going to be interacting with, it really didn't make sense
[00:12:15.920 --> 00:12:21.560]   because we wouldn't have been able to meet the magical, the light expectation that our
[00:12:21.560 --> 00:12:23.640]   global customers might've had.
[00:12:23.640 --> 00:12:24.640]   Cool.
[00:12:24.640 --> 00:12:27.080]   And so tell me about your team.
[00:12:27.080 --> 00:12:32.160]   So what are the different people doing and what are the sort of relative sizes of investment
[00:12:32.160 --> 00:12:35.960]   and the different, the modeling, the deployment?
[00:12:35.960 --> 00:12:38.240]   Are you mostly researchers?
[00:12:38.240 --> 00:12:39.680]   Are you mostly engineers?
[00:12:39.680 --> 00:12:40.680]   How do you think about that?
[00:12:40.680 --> 00:12:44.120]   What are the different functions and how do they all work together?
[00:12:44.120 --> 00:12:45.320]   Yeah.
[00:12:45.320 --> 00:12:50.240]   So the team has changed a lot over the years as we've shifted from more of the research
[00:12:50.240 --> 00:12:54.320]   side of proving concepts of machine learning applications that we can do to thinking about
[00:12:54.320 --> 00:12:55.960]   production applications.
[00:12:55.960 --> 00:13:00.520]   So we have a team that's dedicated to thinking about machine learning algorithms and models,
[00:13:00.520 --> 00:13:04.040]   thinking about how do we develop those models?
[00:13:04.040 --> 00:13:07.280]   What is the appropriate type of data to feed into those models and how do we improve them
[00:13:07.280 --> 00:13:08.280]   over time?
[00:13:08.280 --> 00:13:13.280]   So that team would be essentially like machine learning practitioners?
[00:13:13.280 --> 00:13:14.280]   Yeah.
[00:13:14.280 --> 00:13:18.080]   Is that the team using ML mostly?
[00:13:18.080 --> 00:13:23.280]   Yeah.So this is the only part of the team that will be stereotypical ML.
[00:13:23.280 --> 00:13:27.040]   So I'll talk a little bit more now about the other parts of the team.
[00:13:27.040 --> 00:13:30.160]   So when you talk about a machine learning team, everybody thinks, okay, that's people
[00:13:30.160 --> 00:13:31.160]   doing algorithms.
[00:13:31.160 --> 00:13:32.160]   Right.
[00:13:32.160 --> 00:13:33.640]   So we do have some of those people.
[00:13:33.640 --> 00:13:37.360]   It's like you said a little bit about the relative size of these teams.
[00:13:37.360 --> 00:13:41.080]   I think it's just really interesting that you're in production doing this stuff.
[00:13:41.080 --> 00:13:42.080]   Yeah.
[00:13:42.080 --> 00:13:47.480]   So the modeling team out of the machine learning team all up is actually a small size.
[00:13:47.480 --> 00:13:52.220]   So I think they're about a quarter of the size of the full team.
[00:13:52.220 --> 00:13:57.160]   So the modeling team, they're doing the algorithm development and then there's complimentary
[00:13:57.160 --> 00:13:58.680]   teams that work beside them.
[00:13:58.680 --> 00:14:02.760]   So another team that's working is on more of the integration side.
[00:14:02.760 --> 00:14:06.440]   So how do they take the algorithms and actually deploy them to the robots?
[00:14:06.440 --> 00:14:10.360]   So thinking through what is the supporting infrastructure, what the model conversion
[00:14:10.360 --> 00:14:13.360]   process to run on this limited hardware.
[00:14:13.360 --> 00:14:18.720]   Obviously we need to not use the same types of models that you can do with big GPU machines.
[00:14:18.720 --> 00:14:22.160]   So thinking about the integration of these algorithms onto the robot.
[00:14:22.160 --> 00:14:24.400]   What do you call that team?
[00:14:24.400 --> 00:14:26.560]   Is that like an ops or?
[00:14:26.560 --> 00:14:31.720]   We actually call this an integration team, integrating into the robot software and the
[00:14:31.720 --> 00:14:33.360]   surrounding infrastructure around it.
[00:14:33.360 --> 00:14:38.360]   And are these people kind of hardware-ish people or like what's the sort of...
[00:14:38.360 --> 00:14:42.440]   They're still mostly software, but have an understanding of the hardware too.
[00:14:42.440 --> 00:14:47.920]   And then they can work with folks in hardware on specific applications.
[00:14:47.920 --> 00:14:52.600]   And one interesting part about doing machine learning applications on robots is it's not
[00:14:52.600 --> 00:14:57.260]   just the ML algorithm, but it's how it interacts in the system as a whole.
[00:14:57.260 --> 00:15:01.840]   So these are the folks that really need to think through the end to end solution of what
[00:15:01.840 --> 00:15:03.800]   are the metrics of the system?
[00:15:03.800 --> 00:15:07.440]   How does it affect performance of the robot at the end of the day?
[00:15:07.440 --> 00:15:09.280]   Things like we want cleaning coverage.
[00:15:09.280 --> 00:15:12.320]   We want our robots to clean all parts of their house.
[00:15:12.320 --> 00:15:16.720]   We want to maximize these metrics from the customer's point of view, not the algorithm
[00:15:16.720 --> 00:15:17.720]   point of view.
[00:15:17.720 --> 00:15:20.520]   Are some of these people like more kind of business focused?
[00:15:20.520 --> 00:15:23.920]   They're not, but they're thinking about how to capture the metrics to report to the business
[00:15:23.920 --> 00:15:27.200]   folks and thinking about what those metrics are.
[00:15:27.200 --> 00:15:31.080]   So thinking about the system level metrics rather than just the individual algorithm
[00:15:31.080 --> 00:15:32.720]   metrics.
[00:15:32.720 --> 00:15:35.780]   And just to compliment that, it's really iterative.
[00:15:35.780 --> 00:15:43.060]   So we have sort of an R&D and then a product organization and they're sort of sister organizations.
[00:15:43.060 --> 00:15:49.980]   And so Danielle and I are on the R&D side of the equation and there are the teams that
[00:15:49.980 --> 00:15:51.820]   she's going to continue to talk about.
[00:15:51.820 --> 00:15:54.780]   There's the four teams within the machine learning proper.
[00:15:54.780 --> 00:16:00.600]   And then each one of those has a counterpart within R&D that's attached to a program.
[00:16:00.600 --> 00:16:06.300]   So if it's a specific robot or a specific feature or a specific customer deliverable,
[00:16:06.300 --> 00:16:10.580]   there's somebody that's integrating that machine learning component with all of the other R&D
[00:16:10.580 --> 00:16:16.780]   components that are necessary to deliver the complete sort of final boxed solution, either
[00:16:16.780 --> 00:16:21.500]   as an over the air update, an OTA or either to the manufacturing floor.
[00:16:21.500 --> 00:16:26.600]   And then on the third sort of leg to that milk stall is the product team.
[00:16:26.600 --> 00:16:33.580]   So we have business counterparts who sort of own that product feature deliverable from
[00:16:33.580 --> 00:16:34.860]   the business standpoint.
[00:16:34.860 --> 00:16:41.540]   And so they may not know what's technically feasible or they're actually incredibly robust
[00:16:41.540 --> 00:16:44.740]   at iRobot because we do have a bias for technologists.
[00:16:44.740 --> 00:16:50.620]   So that tends to not really truly be the case, but they have these R&D partners who can help
[00:16:50.620 --> 00:16:53.860]   them sort of iterate on how do we define these metrics, right?
[00:16:53.860 --> 00:16:58.640]   Do we care only about end states and lack of interstitial errors, or do we care about
[00:16:58.640 --> 00:17:03.520]   that within the context of cleaning coverage and cleaning efficiency and all of the other,
[00:17:03.520 --> 00:17:08.160]   you know, low abandonment rates, all of the holistic experience of what this thing is
[00:17:08.160 --> 00:17:09.520]   supposed to deliver.
[00:17:09.520 --> 00:17:12.840]   And so that sort of spans the gamut.
[00:17:12.840 --> 00:17:17.880]   But for instance, on the first team that Danielle was talking about, the modeling team, the
[00:17:17.880 --> 00:17:23.160]   way that they talk to their business counterpart is almost similar to the way that they talk
[00:17:23.160 --> 00:17:24.640]   to the integration team.
[00:17:24.640 --> 00:17:29.160]   So they can write models and write papers and then tell the integration team, this is
[00:17:29.160 --> 00:17:35.640]   the aha, this is the thing, the solution, but they are not as constrained with, you
[00:17:35.640 --> 00:17:40.160]   know, what's the compute accounting, how much budget do we have to be able to run this as
[00:17:40.160 --> 00:17:44.320]   the robot is doing all of these other things that it actually has to do as well.
[00:17:44.320 --> 00:17:49.920]   And so that it truly is a really well integrated and iterative process.
[00:17:49.920 --> 00:17:53.720]   It's not sort of they go into their nerd cave, they come up with a solution, they come out
[00:17:53.720 --> 00:17:55.320]   and toss it over the fence.
[00:17:55.320 --> 00:17:57.320]   Yeah, yeah, definitely.
[00:17:57.320 --> 00:17:59.640]   Good, good compliment, Angela.
[00:17:59.640 --> 00:18:04.040]   So after the integration team, there's a team that's focused on actually what you were mentioning
[00:18:04.040 --> 00:18:07.040]   before, like the platform or an operations team.
[00:18:07.040 --> 00:18:08.600]   So that's separate from the integration team.
[00:18:08.600 --> 00:18:13.120]   And this is the team that is helping with the infrastructure that supports both modeling
[00:18:13.120 --> 00:18:14.960]   and integration work.
[00:18:14.960 --> 00:18:18.040]   So things like what's, how do we scale out our compute?
[00:18:18.040 --> 00:18:21.240]   How do we train our models and store models and things like that?
[00:18:21.240 --> 00:18:28.680]   So how do you think about the different skill set between that team and the integrations
[00:18:28.680 --> 00:18:29.840]   team?
[00:18:29.840 --> 00:18:35.720]   So the integration team is a lot in our case, because we're deploying on a robot.
[00:18:35.720 --> 00:18:41.280]   They also have often C++ knowledge to be able to integrate the models into that environment.
[00:18:41.280 --> 00:18:45.840]   They have build system experience around the robot software.
[00:18:45.840 --> 00:18:50.640]   So the integration team is more focused on how do we make this stuff real on the robot
[00:18:50.640 --> 00:18:55.920]   versus the platform team is how do we build supporting infrastructure to support both
[00:18:55.920 --> 00:18:57.800]   of those other teams.
[00:18:57.800 --> 00:19:02.480]   And the platform team is generally speaking more cloud focused.
[00:19:02.480 --> 00:19:06.240]   We use AWS at iRobot for a majority of our applications.
[00:19:06.240 --> 00:19:14.720]   And so how do we build serverless applications on the cloud to support those different applications?
[00:19:14.720 --> 00:19:20.400]   We found that having an integration team separate from the model and separate from the architecture
[00:19:20.400 --> 00:19:27.040]   and separate from sort of advanced solutions is really important exactly because of this.
[00:19:27.040 --> 00:19:32.640]   The last mile of deploying machine learning to production is really long.
[00:19:32.640 --> 00:19:39.200]   And we have all of the added complexity that our last mile is on an incredibly restricted
[00:19:39.200 --> 00:19:46.240]   automated robotic sensor autonomous platform that's deployed in environments we can't control
[00:19:46.240 --> 00:19:48.760]   and we can't really modify.
[00:19:48.760 --> 00:19:56.120]   So having a team dedicated to focusing on just how hard that last mile is has really
[00:19:56.120 --> 00:20:02.000]   paid off in terms of yes, it's added complexity having a whole nother team, added specialization
[00:20:02.000 --> 00:20:05.060]   like that's not free.
[00:20:05.060 --> 00:20:09.440]   But it's definitely been net positive.
[00:20:09.440 --> 00:20:11.120]   And what's the last team?
[00:20:11.120 --> 00:20:13.640]   So the last team is a reinforcement learning team.
[00:20:13.640 --> 00:20:16.920]   So they're specialized in reinforcement learning applications.
[00:20:16.920 --> 00:20:21.560]   And they work closely with the integration team and the platform team for the same applications
[00:20:21.560 --> 00:20:22.560]   as the modeling team.
[00:20:22.560 --> 00:20:25.880]   Just the modeling team is focused on other applications.
[00:20:25.880 --> 00:20:31.040]   Also, like to like kind of research, researchers, essentially?
[00:20:31.040 --> 00:20:37.480]   Yeah, researchers and making reinforcement learning real for iRobot.
[00:20:37.480 --> 00:20:39.120]   Interesting.
[00:20:39.120 --> 00:20:43.400]   So among those teams, which is the hardest team to hire for?
[00:20:43.400 --> 00:20:46.560]   Oh, that's tough.
[00:20:46.560 --> 00:20:52.600]   So oftentimes, it's these little gaps in between the teams and these things that you don't
[00:20:52.600 --> 00:20:54.340]   expect you need.
[00:20:54.340 --> 00:20:58.400]   And then you find you need in going through a project.
[00:20:58.400 --> 00:21:04.520]   And one often overlooked part is aspects around how do we deal with data?
[00:21:04.520 --> 00:21:06.880]   And how does the data feed the rest of the systems?
[00:21:06.880 --> 00:21:12.160]   So even folks who are supporting the team in how do we use the data?
[00:21:12.160 --> 00:21:17.360]   And how do we curate the data in such a way that our models can improve and our systems
[00:21:17.360 --> 00:21:18.700]   can integrate?
[00:21:18.700 --> 00:21:24.280]   So often, it's the work in between the cracks that you don't that's the hardest to figure
[00:21:24.280 --> 00:21:25.280]   out.
[00:21:25.280 --> 00:21:30.600]   So you have these gaps when there's no clear work that the teams are working towards.
[00:21:30.600 --> 00:21:31.600]   What do you think?
[00:21:31.600 --> 00:21:33.880]   One thing that I will note, though, two things.
[00:21:33.880 --> 00:21:36.000]   We're hiring.
[00:21:36.000 --> 00:21:37.000]   We are hiring.
[00:21:37.000 --> 00:21:43.800]   So if you have experience in embedded systems and machine learning, tool chain, automation,
[00:21:43.800 --> 00:21:44.800]   let me know.
[00:21:44.800 --> 00:21:47.640]   We're very much hiring.
[00:21:47.640 --> 00:21:54.160]   But also, one thing that's amazing about iRobot is that it's actually not that hard to hire.
[00:21:54.160 --> 00:22:00.480]   I mean, yes, it is, because this is a very specialized skill set that we're looking for,
[00:22:00.480 --> 00:22:04.360]   given that we've reached a level of scale where that specialization pays off for us.
[00:22:04.360 --> 00:22:08.680]   But iRobot is really a really cool place that's really well connected.
[00:22:08.680 --> 00:22:14.520]   We got a lot of really smart people working alongside us who have very broad networks.
[00:22:14.520 --> 00:22:20.280]   So it's actually we get a lot of really smart, really competent folks reaching out to us
[00:22:20.280 --> 00:22:26.160]   a lot, which I'm very grateful for, because as you've noted, these tend to be really hard
[00:22:26.160 --> 00:22:27.960]   skill sets to find.
[00:22:27.960 --> 00:22:31.800]   But it's also, everybody six-year-old gets tickled when they get to answer, "What do
[00:22:31.800 --> 00:22:32.800]   you do for a living?"
[00:22:32.800 --> 00:22:33.800]   I built robots.
[00:22:33.800 --> 00:22:34.800]   Totally.
[00:22:34.800 --> 00:22:35.800]   That totally does.
[00:22:35.800 --> 00:22:36.800]   That doesn't suck.
[00:22:36.800 --> 00:22:37.800]   Hi.
[00:22:37.800 --> 00:22:42.200]   We'd love to take a moment to tell you guys about Weights and Biases.
[00:22:42.200 --> 00:22:47.720]   Weights and Biases is a tool that helps you track and visualize every detail of your machine
[00:22:47.720 --> 00:22:48.720]   learning models.
[00:22:48.720 --> 00:22:54.640]   We help you debug your machine learning models in real time, collaborate easily, and advance
[00:22:54.640 --> 00:22:57.740]   the state of the art in machine learning.
[00:22:57.740 --> 00:23:02.920]   You can integrate Weights and Biases into your models with just a few lines of code.
[00:23:02.920 --> 00:23:07.680]   With hyperparameter sweeps, you can find the best set of hyperparameters for your models
[00:23:07.680 --> 00:23:09.620]   automatically.
[00:23:09.620 --> 00:23:15.040]   You can also track and compare how many GPU resources your models are using.
[00:23:15.040 --> 00:23:21.720]   With one line of code, you can visualize model predictions in form of images, videos, audio,
[00:23:21.720 --> 00:23:27.460]   plotly charts, molecular data, segmentation maps, and 3D point clouds.
[00:23:27.460 --> 00:23:33.280]   You can save everything you need to reproduce your models days, weeks, or even months after
[00:23:33.280 --> 00:23:34.280]   training.
[00:23:34.280 --> 00:23:39.440]   Finally, with reports, you can make your models come alive.
[00:23:39.440 --> 00:23:44.440]   Reports are like blog posts in which your readers can interact with your model metrics
[00:23:44.440 --> 00:23:46.240]   and predictions.
[00:23:46.240 --> 00:23:52.440]   Reports serve as a centralized repository of metrics, predictions, hyperparameter strides,
[00:23:52.440 --> 00:23:54.200]   and accompanying notes.
[00:23:54.200 --> 00:23:59.860]   All of this together gives you a bird's eye view of your machine learning workflow.
[00:23:59.860 --> 00:24:05.360]   You can use reports to share your model insights, keep your team on the same page, and collaborate
[00:24:05.360 --> 00:24:06.360]   effectively remotely.
[00:24:06.360 --> 00:24:11.480]   I'll leave a link in the show notes below to help you get started.
[00:24:11.480 --> 00:24:14.200]   And now, let's get back to the episode.
[00:24:14.200 --> 00:24:21.380]   Do you notice that there's any challenges with cultural differences or miscommunications
[00:24:21.380 --> 00:24:22.380]   between these teams?
[00:24:22.380 --> 00:24:26.160]   I think you actually do hire fairly different people.
[00:24:26.160 --> 00:24:30.640]   Has there been any lessons learned from trying to get everyone to work together and build
[00:24:30.640 --> 00:24:31.640]   something?
[00:24:31.640 --> 00:24:32.640]   Yeah.
[00:24:32.640 --> 00:24:36.120]   I think one really important thing in thinking about building machine learning teams, and
[00:24:36.120 --> 00:24:39.840]   especially when you get to the point where you have different specializations and different
[00:24:39.840 --> 00:24:44.440]   goals of these sub-teams, is thinking about where the boundaries are between teams and
[00:24:44.440 --> 00:24:46.760]   how handover happens.
[00:24:46.760 --> 00:24:54.360]   One way that we've tried to address this at iRobot is we have virtual teams that work
[00:24:54.360 --> 00:24:55.720]   across team boundaries.
[00:24:55.720 --> 00:24:59.880]   For a particular application, there's somebody from the modeling team working on it.
[00:24:59.880 --> 00:25:01.640]   There's somebody from the integration team working on it.
[00:25:01.640 --> 00:25:04.480]   There's somebody from the platform team working on it.
[00:25:04.480 --> 00:25:07.480]   They're a virtual team that works across boundaries.
[00:25:07.480 --> 00:25:12.800]   Because I think if you don't, otherwise, there could be some gaps in handover between teams.
[00:25:12.800 --> 00:25:17.640]   So trying to build these integration points between the teams is really helpful in getting
[00:25:17.640 --> 00:25:20.360]   an end application out the door.
[00:25:20.360 --> 00:25:25.880]   And it's really helpful to also have these teams not feel like there are these arbitrary
[00:25:25.880 --> 00:25:27.200]   walls in between them.
[00:25:27.200 --> 00:25:30.960]   So the virtual teaming that Danielle described is one way that we do that.
[00:25:30.960 --> 00:25:40.880]   But making sure that the folks get a lot of time together discussing scientific papers,
[00:25:40.880 --> 00:25:44.960]   getting together and talking about recent developments, attending conferences together,
[00:25:44.960 --> 00:25:50.920]   so that there's really this strong culture that allows for a lot of that connected tissue
[00:25:50.920 --> 00:25:51.920]   to happen.
[00:25:51.920 --> 00:25:53.760]   So that the gaps exist.
[00:25:53.760 --> 00:25:55.880]   Things do fall through the cracks.
[00:25:55.880 --> 00:25:57.240]   There's no way to avoid that.
[00:25:57.240 --> 00:26:02.880]   But the fact that we know it will happen so that we create a culture where folks are attentive
[00:26:02.880 --> 00:26:08.800]   to it and intentional in seeking those things out to catch them, rather than going, well,
[00:26:08.800 --> 00:26:10.280]   it's not my problem.
[00:26:10.280 --> 00:26:16.320]   So I think the fact that Danielle is really intentional about building that kind of cohesiveness,
[00:26:16.320 --> 00:26:20.680]   that I'm really intentional about paying attention to that kind of cohesiveness, is one of the
[00:26:20.680 --> 00:26:26.000]   things that has been paying off in spades for us in terms of the speed with which we
[00:26:26.000 --> 00:26:30.360]   can get these things to happen and not have to constantly sort of two steps forward, one
[00:26:30.360 --> 00:26:36.040]   step back of what didn't make it this last time.
[00:26:36.040 --> 00:26:42.440]   Is it a challenge for you to sort of weigh the priorities of kind of what the company
[00:26:42.440 --> 00:26:47.080]   needs and the models that the company needs versus like paper writing and academic conferences?
[00:26:47.080 --> 00:26:50.680]   Has that been an issue for you?
[00:26:50.680 --> 00:26:51.680]   No.
[00:26:51.680 --> 00:26:52.680]   Imagine.
[00:26:52.680 --> 00:26:57.480]   I mean, that's, but that's been the case for 30 years, right?
[00:26:57.480 --> 00:26:59.640]   Like you hire the best and the brightest.
[00:26:59.640 --> 00:27:02.520]   You hire people with a bias towards nerdery.
[00:27:02.520 --> 00:27:08.040]   And obviously, you know, all of us want to be big, bad nerds.
[00:27:08.040 --> 00:27:10.880]   And big, bad nerdery doesn't necessarily always pay the bills.
[00:27:10.880 --> 00:27:16.200]   So that's why having that iterative component and having a sister organization in the product
[00:27:16.200 --> 00:27:23.640]   team that is really well plugged into what the end goal is.
[00:27:23.640 --> 00:27:30.840]   Because I think once we reframe how the team talks about it and we stop the dichotomy of
[00:27:30.840 --> 00:27:34.440]   are we doing cool research or are we doing boring product work?
[00:27:34.440 --> 00:27:40.160]   But when we reframe it to are we solving a real problem, right?
[00:27:40.160 --> 00:27:45.800]   Not an abstraction, not a theoretical articulation of a problem, but are we actually seeing in
[00:27:45.800 --> 00:27:49.840]   the data that we're collecting back, the telemetry that's aggregated that we can look at, are
[00:27:49.840 --> 00:27:57.640]   we seeing qualitative impacts into how humans behave and how they behave with respect to
[00:27:57.640 --> 00:27:59.560]   the behavior of their robot?
[00:27:59.560 --> 00:28:03.440]   I think getting that and celebrating that and highlighting that, packaging that and
[00:28:03.440 --> 00:28:07.200]   communicating that back to the team so that they get jazzed about the fact that what they're
[00:28:07.200 --> 00:28:14.200]   doing that last long mile, once you cross it, you can actually see a meaningful feedback.
[00:28:14.200 --> 00:28:25.800]   I think that gets the team really excited to be able to play that game of research and
[00:28:25.800 --> 00:28:34.200]   bottom line work in a much lighter way than I had been exposed to previously.
[00:28:34.200 --> 00:28:35.200]   That's cool.
[00:28:35.200 --> 00:28:37.520]   So measuring and communicating.
[00:28:37.520 --> 00:28:44.840]   Yeah, and having dashboards across the office where you can see how things are moving, see
[00:28:44.840 --> 00:28:50.440]   how the models converging both in test, but also whenever it is deployed in production
[00:28:50.440 --> 00:28:56.560]   and seeing the impact on the fleet and communicating that out to everybody else in the company
[00:28:56.560 --> 00:29:02.080]   and hearing all of our partner nerds who nerd on different things celebrate that success.
[00:29:02.080 --> 00:29:06.160]   I think it just becomes this really interesting virtuous circle.
[00:29:06.160 --> 00:29:12.960]   Do you think when you interview ML practitioners and those adjacent, do you think that you
[00:29:12.960 --> 00:29:20.560]   interview for something a little bit different than other companies like Microsoft or Google?
[00:29:20.560 --> 00:29:25.680]   Is it kind of the same stuff or is there something different about iRobot that you look for?
[00:29:25.680 --> 00:29:29.000]   I mean, I do, but I've never hired for Microsoft or Google.
[00:29:29.000 --> 00:29:32.160]   So I don't know if I would have had...
[00:29:32.160 --> 00:29:33.160]   That example?
[00:29:33.160 --> 00:29:39.960]   If I would have had some pushback, but I was already at iRobot when Danielle joined.
[00:29:39.960 --> 00:29:51.560]   So I was really happy to welcome her to the team, but it didn't seem like there were too
[00:29:51.560 --> 00:29:58.520]   many sort of fundamental differences with the way the transition happened.
[00:29:58.520 --> 00:30:00.520]   Is that right?
[00:30:00.520 --> 00:30:01.520]   Yeah.
[00:30:01.520 --> 00:30:06.920]   I can't think of any major differences.
[00:30:06.920 --> 00:30:11.160]   I think a bias towards a love of hardware helps.
[00:30:11.160 --> 00:30:19.440]   I think if you don't love the fact that these things are going to live outside of your own
[00:30:19.440 --> 00:30:26.000]   RAM, it's just not going to be as exciting.
[00:30:26.000 --> 00:30:29.520]   Everybody wants to work with somebody who's excited about what they're doing.
[00:30:29.520 --> 00:30:36.040]   Well, I mean, I think that it does seem like your kind of quality control and testing must
[00:30:36.040 --> 00:30:37.040]   be pretty rigorous, right?
[00:30:37.040 --> 00:30:39.640]   Because it's probably hard to go back and fix things.
[00:30:39.640 --> 00:30:42.720]   Can you say a little bit about how you approach that?
[00:30:42.720 --> 00:30:43.720]   Yeah, definitely.
[00:30:43.720 --> 00:30:48.240]   Model quality control and testing is a huge part of what we do.
[00:30:48.240 --> 00:30:52.760]   And as much as we can, a lot of these different layers we've automated so that when we're
[00:30:52.760 --> 00:30:57.480]   developing software, we have automated tests that run, even automated tests that run on
[00:30:57.480 --> 00:30:58.480]   the robot.
[00:30:58.480 --> 00:31:01.560]   So we think about it at almost every single layer of the system.
[00:31:01.560 --> 00:31:09.080]   So from model algorithm development, thinking about how do we validate our models offline.
[00:31:09.080 --> 00:31:12.160]   And even that very first step is tricky, right?
[00:31:12.160 --> 00:31:18.320]   Because we're building robots that run in the real world across millions of homes, all
[00:31:18.320 --> 00:31:20.340]   the different variety of homes in the world.
[00:31:20.340 --> 00:31:25.000]   So even that first part of how do we test our models offline to make sure that they
[00:31:25.000 --> 00:31:27.400]   actually will work in the real world, even that is tricky.
[00:31:27.400 --> 00:31:31.880]   But after we get over that hurdle, we then think about the next step of deploying on
[00:31:31.880 --> 00:31:35.200]   the robot and making sure all those pieces that we need to do.
[00:31:35.200 --> 00:31:40.720]   So from the model conversion process to what pre-processing happens, to making sure the
[00:31:40.720 --> 00:31:45.880]   hardware that goes into the machine learning algorithms is the same as the applications
[00:31:45.880 --> 00:31:48.720]   that are developed when we develop the machine learning model.
[00:31:48.720 --> 00:31:54.080]   So thinking about all the variety and hardware that goes into the data collection aspects,
[00:31:54.080 --> 00:31:59.360]   and then where the machine learning model is running, that the software is running correctly.
[00:31:59.360 --> 00:32:05.200]   So metrics for offline, metrics for on the robot, and then also once we deploy the model
[00:32:05.200 --> 00:32:11.120]   in production, making sure that we continue to monitor that model and continue to understand
[00:32:11.120 --> 00:32:15.720]   feedback and improvements so that we can also send updates to the model when necessary.
[00:32:15.720 --> 00:32:18.320]   So there's a lot of different layers to that.
[00:32:18.320 --> 00:32:21.760]   And it gets really complicated because we are thinking about how do we generalize to
[00:32:21.760 --> 00:32:25.280]   the real world and the real homes, and there's a lot of variety in that.
[00:32:25.280 --> 00:32:30.520]   And there's a component to testing that goes beyond sort of model quality and model applicability
[00:32:30.520 --> 00:32:34.760]   because these are robots that are in consumers' homes.
[00:32:34.760 --> 00:32:39.400]   So we also have a regulatory and a compliance component to the testing.
[00:32:39.400 --> 00:32:44.560]   So the Roomba, the Brava, they have a set of testing.
[00:32:44.560 --> 00:32:50.480]   But also when you start thinking about things like the Terra, which is the lawnmower, right,
[00:32:50.480 --> 00:32:57.400]   it has a completely different kind of fail-stop mechanism because it's got literal blades
[00:32:57.400 --> 00:33:01.480]   that are cutting grass, and you definitely don't want it going over Fido.
[00:33:01.480 --> 00:33:08.720]   So we have this sort of testing culture and this testing mentality that goes from all
[00:33:08.720 --> 00:33:14.080]   the way to how the hardware works, to how the software works, navigation, and then through
[00:33:14.080 --> 00:33:20.320]   all of this, the machine learning features that are deployed through these products,
[00:33:20.320 --> 00:33:26.880]   be they recommender systems or computer vision types of applications.
[00:33:26.880 --> 00:33:31.640]   Have there been any interesting surprises as you've kind of gone from these specific
[00:33:31.640 --> 00:33:35.960]   unit tests to kind of more bigger picture tests to production?
[00:33:35.960 --> 00:33:41.440]   Have there been any things where you're like, "Woohoo, we didn't see that coming?"
[00:33:41.440 --> 00:33:50.000]   I'd say it is amazing that you continue to find little aspects and you continue to realize
[00:33:50.000 --> 00:33:55.120]   throughout the journey of how important testing is, and not just for finding things, but actually
[00:33:55.120 --> 00:33:56.720]   helping you move more efficiently.
[00:33:56.720 --> 00:34:01.360]   So having checks at that different layer also just helps you debug faster.
[00:34:01.360 --> 00:34:06.640]   So not even knowing that something is going wrong and being proactive, but knowing, "Okay,
[00:34:06.640 --> 00:34:10.120]   we know something's wrong and we know where something is wrong in the system because we
[00:34:10.120 --> 00:34:15.800]   have tests at each layer so that we can really hone into where the problem is."
[00:34:15.800 --> 00:34:21.040]   So I think that's something that I've really enjoyed seeing over time is how building in
[00:34:21.040 --> 00:34:25.600]   these different layers helps us move faster in the long run.
[00:34:25.600 --> 00:34:27.640]   So they've all worked out perfectly to predict...
[00:34:27.640 --> 00:34:28.640]   Definitely not.
[00:34:28.640 --> 00:34:33.680]   So I say we build up tests over time.
[00:34:33.680 --> 00:34:38.120]   But it's really interesting because we've also learned through this process, this sort
[00:34:38.120 --> 00:34:42.720]   of navel-gazing process of how do we test and how do we ensure and how do we root cause?
[00:34:42.720 --> 00:34:47.120]   But we also noticed that across iRobot, our team is also getting called to help those
[00:34:47.120 --> 00:34:53.280]   teams root cause what they're going through because of the way that we interact with data.
[00:34:53.280 --> 00:34:58.400]   We have brilliant technologists, roboticists, algorithmists, but they are not all sort of
[00:34:58.400 --> 00:35:05.360]   trained in the gospel of data and dealing with really large data sets that require imputation,
[00:35:05.360 --> 00:35:10.920]   that are gappy, that aren't necessarily fully representative, comprehensive of what it
[00:35:10.920 --> 00:35:15.960]   is that a software developer has access to when they're looking at how their IDE is responding
[00:35:15.960 --> 00:35:16.960]   to them.
[00:35:16.960 --> 00:35:21.560]   So we are able to sort of bring that and help different teams that sometimes have nothing
[00:35:21.560 --> 00:35:27.520]   to do with machine learning, but to help them look through the information that our robots
[00:35:27.520 --> 00:35:32.760]   are sending back, the telemetry, whatever it be, and then help them build tooling that
[00:35:32.760 --> 00:35:40.920]   looks at fleet data to help them towards their specific scenarios, even completely unrelated
[00:35:40.920 --> 00:35:42.920]   to machine learning altogether.
[00:35:42.920 --> 00:35:49.720]   How do you think about testing models that are sort of inherently maybe non-deterministic
[00:35:49.720 --> 00:35:53.760]   or at least you can't be sure that they're going to be accurate every single time?
[00:35:53.760 --> 00:35:58.120]   Do you have some kind of threshold or do you look for distribution drift or what?
[00:35:58.120 --> 00:35:59.440]   How do you think about that?
[00:35:59.440 --> 00:36:04.160]   Yeah, this is something that we actually think about a lot because our systems, we also have
[00:36:04.160 --> 00:36:08.280]   data deletion requests that come in and obviously we can apply and think about how do we build
[00:36:08.280 --> 00:36:10.920]   in user trust and user privacy into our system.
[00:36:10.920 --> 00:36:15.280]   So we think about this a lot because our data, our source data actually changes as a result
[00:36:15.280 --> 00:36:16.680]   of data deletion requests.
[00:36:16.680 --> 00:36:22.200]   And so thinking about how to build reproducible pipelines that we know what are the components
[00:36:22.200 --> 00:36:26.680]   that went into that pipeline so that we can recreate training data sets based on both
[00:36:26.680 --> 00:36:31.720]   the distribution and based on what data went into that model originally minus the data
[00:36:31.720 --> 00:36:36.480]   that was deleted or things that came into the system and new data that feeds in as well
[00:36:36.480 --> 00:36:40.480]   because we also want to supplement our data sources with any new data so we can improve
[00:36:40.480 --> 00:36:44.080]   over time and get better features in the end.
[00:36:44.080 --> 00:36:47.000]   So we think a lot about how do we create reproducible pipelines?
[00:36:47.000 --> 00:36:48.680]   How do we track what we've done?
[00:36:48.680 --> 00:36:50.360]   Sorry, this is really fascinating.
[00:36:50.360 --> 00:36:54.480]   Okay, so when you say reproducible pipeline but the data is changing, what exactly does
[00:36:54.480 --> 00:36:55.480]   that mean?
[00:36:55.480 --> 00:37:01.280]   So it means understanding exactly what distribution we're pulling from and what sources we're
[00:37:01.280 --> 00:37:06.440]   pulling from and being able to reproduce the processing that pulls and creates that data
[00:37:06.440 --> 00:37:09.080]   set that goes into the model.
[00:37:09.080 --> 00:37:10.800]   The process is reproducible.
[00:37:10.800 --> 00:37:12.600]   Yes, exactly.
[00:37:12.600 --> 00:37:19.920]   But also whenever we do reach some convergent model, the interpretability and the explainability
[00:37:19.920 --> 00:37:28.240]   of that model while all of the training data is still there as intended and as designed
[00:37:28.240 --> 00:37:31.400]   is really important because of the ephemerality of that data.
[00:37:31.400 --> 00:37:37.920]   So the underlying data, the underlying training set does change what it ultimately generated
[00:37:37.920 --> 00:37:44.800]   even if we have to change things in order to be respectful and be sensible stewards
[00:37:44.800 --> 00:37:46.720]   of our customers' data.
[00:37:46.720 --> 00:37:53.160]   We ensure that whenever we do have a model in hand that the learning of it can be re-implemented
[00:37:53.160 --> 00:38:00.760]   in addition to the reproducibility of the pipeline so that we can't have just blind
[00:38:00.760 --> 00:38:07.760]   black boxes that we just retrain at will because of the regulatory and compliance environment
[00:38:07.760 --> 00:38:10.760]   within which we operate.
[00:38:10.760 --> 00:38:11.760]   Yeah.
[00:38:11.760 --> 00:38:16.400]   The reproducible pipelines, we also think about the metrics that come out of those.
[00:38:16.400 --> 00:38:20.360]   So some of the metrics we were talking about earlier of the metrics offline, the metrics
[00:38:20.360 --> 00:38:21.360]   on the robot.
[00:38:21.360 --> 00:38:26.760]   So a lot of those aspects we're working towards full automation so that we can have these
[00:38:26.760 --> 00:38:30.960]   reproducible pipelines and reproducible metrics at each layer of the system.
[00:38:30.960 --> 00:38:34.480]   Sorry, I'm really interested.
[00:38:34.480 --> 00:38:38.840]   So these metrics, when you say these metrics we talked about, you're referring to the sort
[00:38:38.840 --> 00:38:43.960]   of like kind of end-to-end sort of product or business metrics or do you mean something
[00:38:43.960 --> 00:38:46.320]   like specific to that model?
[00:38:46.320 --> 00:38:47.320]   So both.
[00:38:47.320 --> 00:38:54.680]   So with model metrics that come out as well as how that model performs in the bigger system,
[00:38:54.680 --> 00:38:58.960]   which there could be a whole other system that it's interacting with on the robot.
[00:38:58.960 --> 00:39:03.320]   So you need to think through both the model metrics and we might need to actually tune
[00:39:03.320 --> 00:39:06.920]   the model differently in order to optimize the system metrics.
[00:39:06.920 --> 00:39:10.120]   So thinking about those different layers to be able to reproduce.
[00:39:10.120 --> 00:39:14.560]   So capturing metrics and then creating those reproducible pipelines are how we think about
[00:39:14.560 --> 00:39:16.800]   approaching that problem.
[00:39:16.800 --> 00:39:17.800]   Interesting.
[00:39:17.800 --> 00:39:26.560]   And have you seen like modern techniques, I guess, like how much has like modeling improvements
[00:39:26.560 --> 00:39:28.120]   improved these metrics?
[00:39:28.120 --> 00:39:29.120]   Has that been important to you?
[00:39:29.120 --> 00:39:30.920]   I mean, some people say, oh, it's just about the data.
[00:39:30.920 --> 00:39:35.280]   Some people say, well, no, like, you know, deeper, more sophisticated models, they really
[00:39:35.280 --> 00:39:36.280]   matter.
[00:39:36.280 --> 00:39:39.120]   Some people think hyper-prem research is a really good idea and some applications, it
[00:39:39.120 --> 00:39:40.320]   seems like it doesn't help very much.
[00:39:40.320 --> 00:39:43.520]   Like where do you stand on those types of things?
[00:39:43.520 --> 00:39:48.360]   So I'd say data first.
[00:39:48.360 --> 00:39:57.140]   For our use cases, because we're trying to hit all of the houses, be able to generalize
[00:39:57.140 --> 00:40:03.200]   to the world and all the variety of the world, making sure that our data is generalizable
[00:40:03.200 --> 00:40:06.640]   in that way is the most important.
[00:40:06.640 --> 00:40:08.000]   But the physical world.
[00:40:08.000 --> 00:40:09.000]   The physical world.
[00:40:09.000 --> 00:40:10.000]   Yeah.
[00:40:10.000 --> 00:40:14.280]   So thresholds are thresholds between one room and the other.
[00:40:14.280 --> 00:40:21.480]   And the architecture of 1800s Germany is something that you really can't modify.
[00:40:21.480 --> 00:40:24.320]   Like houses in Berlin will be the way that they are.
[00:40:24.320 --> 00:40:32.400]   And so it's really, it's a different world when you're talking about a robot that we're
[00:40:32.400 --> 00:40:33.880]   going to be improving these models.
[00:40:33.880 --> 00:40:38.680]   We're going to be sending new models over an over the air update.
[00:40:38.680 --> 00:40:43.480]   But the compute that that robot has available to it and the environment within which it
[00:40:43.480 --> 00:40:45.920]   operates is static.
[00:40:45.920 --> 00:40:51.080]   And so that's the constraint, which is why we value the data collection so much because
[00:40:51.080 --> 00:40:54.680]   of that sort of constraint, essentially.
[00:40:54.680 --> 00:40:55.680]   Yep.
[00:40:55.680 --> 00:40:56.680]   Absolutely.
[00:40:56.680 --> 00:41:01.280]   And the other aspect is the algorithms that run on low compute.
[00:41:01.280 --> 00:41:06.880]   I think the advancements that happen in that space, there are little things that you can
[00:41:06.880 --> 00:41:09.120]   do that make a big difference.
[00:41:09.120 --> 00:41:16.080]   So thinking about that area, I think there is a lot of room to go in terms of how much
[00:41:16.080 --> 00:41:18.600]   algorithm improvements can make a difference.
[00:41:18.600 --> 00:41:21.280]   Have they mattered to you over the last couple of years?
[00:41:21.280 --> 00:41:24.920]   Like the stuff that's been really meaningful?
[00:41:24.920 --> 00:41:25.920]   Yes.
[00:41:25.920 --> 00:41:26.920]   Yes.
[00:41:26.920 --> 00:41:28.520]   Especially advances in inference time as well.
[00:41:28.520 --> 00:41:32.640]   Because we are running in such constrained compute environments, the small differences
[00:41:32.640 --> 00:41:34.800]   can make a big deal.
[00:41:34.800 --> 00:41:36.320]   And this is beyond the hardware improvements.
[00:41:36.320 --> 00:41:38.600]   This is actual kind of model improvements.
[00:41:38.600 --> 00:41:39.600]   Yep.
[00:41:39.600 --> 00:41:40.600]   Yep.
[00:41:40.600 --> 00:41:41.600]   Cool.
[00:41:41.600 --> 00:41:44.480]   And I mean, actually, I'm just kind of this really specific, but I'm curious when you
[00:41:44.480 --> 00:41:48.680]   think about like hyperparameter searches, that's an AutoML.
[00:41:48.680 --> 00:41:51.560]   Is that something you do a lot of or does that help you much?
[00:41:51.560 --> 00:41:53.120]   I mean, how do you think about that?
[00:41:53.120 --> 00:41:58.200]   Yeah, we definitely leverage hyperparameter search and AutoML type capabilities to see
[00:41:58.200 --> 00:42:03.640]   what the space is out there and see how we can improve.
[00:42:03.640 --> 00:42:09.360]   Data augmentation approaches are also very useful in thinking about how we can supplement
[00:42:09.360 --> 00:42:14.600]   the current data that we have to try to make sure that it is generalizable to the world.
[00:42:14.600 --> 00:42:15.600]   Okay.
[00:42:15.600 --> 00:42:24.440]   So data augmentation approaches versus model architecture, which do you think is more important?
[00:42:24.440 --> 00:42:27.240]   That's a tough one.
[00:42:27.240 --> 00:42:28.240]   Both.
[00:42:28.240 --> 00:42:29.240]   Not obvious.
[00:42:29.240 --> 00:42:30.240]   Okay.
[00:42:30.240 --> 00:42:31.240]   Both.
[00:42:31.240 --> 00:42:32.240]   Fair.
[00:42:32.240 --> 00:42:40.680]   I mean, if we had infinite resources, I would agree, but I think looking back at what we've
[00:42:40.680 --> 00:42:51.200]   actually had to overcome over the last year and a half, I'd say that data augmentation
[00:42:51.200 --> 00:42:57.560]   has been more of a sort of a throttling or a bottleneck to us.
[00:42:57.560 --> 00:43:02.000]   I'm not sure that that is always going to be the case, but specifically.
[00:43:02.000 --> 00:43:05.720]   It's been a problem for you or it's been helpful to you?
[00:43:05.720 --> 00:43:06.720]   It's been helpful.
[00:43:06.720 --> 00:43:11.240]   So it solved a thing that was a real problem for us, a bigger problem.
[00:43:11.240 --> 00:43:20.600]   So the ability to understand every environment from day zero, right?
[00:43:20.600 --> 00:43:27.080]   So once a robot starts going around the space, somebody who just bought it, they don't want
[00:43:27.080 --> 00:43:29.760]   to give that robot a month to get good.
[00:43:29.760 --> 00:43:30.760]   Right?
[00:43:30.760 --> 00:43:34.120]   They want, if you wait a month, they're going to stop using it.
[00:43:34.120 --> 00:43:37.760]   And then you lose the chance of having delighted that customer.
[00:43:37.760 --> 00:43:49.380]   So starting off with a really solid day zero solution was really the big important objective
[00:43:49.380 --> 00:43:50.380]   for us, I think.
[00:43:50.380 --> 00:43:53.600]   But I'm not sure that that is always going to be the case, which is why I think like,
[00:43:53.600 --> 00:43:56.680]   yeah, infinite resources.
[00:43:56.680 --> 00:43:57.680]   It's early 2020.
[00:43:57.680 --> 00:44:02.960]   Things change for sure.
[00:44:02.960 --> 00:44:09.400]   Can you say, I'm always kind of curious, have you focused on kind of one deep learning framework?
[00:44:09.400 --> 00:44:12.960]   Is that like TensorFlow or PyTorch or do you love Scikit?
[00:44:12.960 --> 00:44:14.680]   How do you think about that?
[00:44:14.680 --> 00:44:16.440]   Is it like all of the above?
[00:44:16.440 --> 00:44:18.640]   So it depends on the team, I think.
[00:44:18.640 --> 00:44:23.240]   So when we're talking more about the reinforcement learning team or the modeling team, I think
[00:44:23.240 --> 00:44:29.080]   they get a little bit more leeway in experimenting because that's the role, right?
[00:44:29.080 --> 00:44:35.640]   Like is the stuff that we've settled on continuing to work for what we want and will it pave
[00:44:35.640 --> 00:44:38.220]   the way for what we are going to want?
[00:44:38.220 --> 00:44:46.040]   So those folks test a little bit more, go a little bit more wild into the research and
[00:44:46.040 --> 00:44:51.400]   what's available and what are the state of the art sort of improvements and how can we
[00:44:51.400 --> 00:44:55.200]   make those applicable within the environments that we operate in?
[00:44:55.200 --> 00:45:01.520]   I think when we're talking about the integration and the infrastructure teams, they're focused
[00:45:01.520 --> 00:45:03.640]   on different things.
[00:45:03.640 --> 00:45:13.160]   So they are much more focused on that last mile and so re-architecting all of our tooling
[00:45:13.160 --> 00:45:19.520]   unless there is a really important benefit that we get from that because at that point,
[00:45:19.520 --> 00:45:23.960]   we're impacting all of the platforms that may make use of this one deliverable and a
[00:45:23.960 --> 00:45:26.600]   lot of those platforms are already in homes.
[00:45:26.600 --> 00:45:36.360]   So if we have to re-architect how all of that delivery happens, there are a lot of teams
[00:45:36.360 --> 00:45:39.840]   and there's a lot of integration that needs to take place and so is it worthwhile to spend
[00:45:39.840 --> 00:45:41.080]   those resources?
[00:45:41.080 --> 00:45:51.160]   So the farther into the process we get, the harder it is to stay, to modify and to tinker
[00:45:51.160 --> 00:45:52.440]   with that stuff.
[00:45:52.440 --> 00:45:56.520]   But I think the modeling team, yes and, right?
[00:45:56.520 --> 00:46:03.160]   I think they've done TensorFlow, Scikit-learn is always a favorite of all.
[00:46:03.160 --> 00:46:08.120]   I think we've dabbled in PyTorch and figuring out is it working for us?
[00:46:08.120 --> 00:46:14.400]   And once it gets down farther into the pipeline, it is much more into what's already working
[00:46:14.400 --> 00:46:19.320]   and is it worthwhile to throw a bomb in there?
[00:46:19.320 --> 00:46:22.360]   Can you say what's already working?
[00:46:22.360 --> 00:46:28.040]   Not yet, but we look forward to coming back and sharing a little bit more details on all
[00:46:28.040 --> 00:46:29.040]   of that.
[00:46:29.040 --> 00:46:30.040]   Okay, cool.
[00:46:30.040 --> 00:46:31.040]   Can't wait.
[00:46:31.040 --> 00:46:32.120]   I mean, I want to be respectful of your time.
[00:46:32.120 --> 00:46:34.160]   I think we've gone a little over.
[00:46:34.160 --> 00:46:38.440]   I'm hoping to end with a couple questions, if you don't mind, that we've been asking
[00:46:38.440 --> 00:46:39.440]   everyone.
[00:46:39.440 --> 00:46:44.680]   So, here's my first one, which is, what is the one underrated aspect of machine learning
[00:46:44.680 --> 00:46:47.400]   that you think people should pay more attention to?
[00:46:47.400 --> 00:46:49.720]   Oh, the data.
[00:46:49.720 --> 00:46:55.200]   I know it's still, but it's so true.
[00:46:55.200 --> 00:46:56.200]   It's so true.
[00:46:56.200 --> 00:46:59.400]   The data is so important.
[00:46:59.400 --> 00:47:06.540]   Making sure that it's generalizable, making sure that it actually, figuring out your metrics
[00:47:06.540 --> 00:47:09.760]   are all going to be based on the data that you're using.
[00:47:09.760 --> 00:47:14.040]   And so, how do you know the metrics of the model or the metrics of the system are actually
[00:47:14.040 --> 00:47:17.840]   metrics that you believe are useful to represent things?
[00:47:17.840 --> 00:47:22.080]   Because at the end of the day, it's all about the data that goes into the system.
[00:47:22.080 --> 00:47:23.080]   And it's not just the volume.
[00:47:23.080 --> 00:47:29.060]   I mean, 100%, it's the data, but it's not just the volume or the variety or the velocity
[00:47:29.060 --> 00:47:30.060]   of it, right?
[00:47:30.060 --> 00:47:33.440]   Like the fancy three Bs, but it's the quality of it.
[00:47:33.440 --> 00:47:39.200]   So are we only looking at data that's streaming back from us, from customers who are already
[00:47:39.200 --> 00:47:40.240]   happy?
[00:47:40.240 --> 00:47:43.560]   Which means we're not solving the problem for the folks who aren't already happy to
[00:47:43.560 --> 00:47:44.560]   begin with.
[00:47:44.560 --> 00:47:47.880]   We're not solving the problems for the folks who aren't using the product that they've
[00:47:47.880 --> 00:47:50.400]   already paid for, and we're not delighting them.
[00:47:50.400 --> 00:47:55.040]   So it's not just that we have data, but is that data reflective of the whole?
[00:47:55.040 --> 00:48:02.400]   And how do we ensure that the next thing that we do isn't just improving marginally the
[00:48:02.400 --> 00:48:05.880]   experience of a fraction of our customers?
[00:48:05.880 --> 00:48:08.560]   But yes, data, 100% data, underlying.
[00:48:08.560 --> 00:48:12.640]   Why do you think it's so hard for the industry to realize that?
[00:48:12.640 --> 00:48:14.000]   How could it still be underrated?
[00:48:14.000 --> 00:48:17.000]   It seems so blindingly obvious from where I sit.
[00:48:17.000 --> 00:48:19.400]   I don't think that it's underrated.
[00:48:19.400 --> 00:48:23.520]   I think when you ask this question, you probably get the same answer, which is why we're laughing,
[00:48:23.520 --> 00:48:24.520]   right?
[00:48:24.520 --> 00:48:25.520]   It's not underrated.
[00:48:25.520 --> 00:48:26.520]   It's just hard.
[00:48:26.520 --> 00:48:27.520]   Yeah.
[00:48:27.520 --> 00:48:28.520]   Yeah.
[00:48:28.520 --> 00:48:29.520]   It's known to be valuable.
[00:48:29.520 --> 00:48:31.520]   It's also known to be really hard.
[00:48:31.520 --> 00:48:38.640]   I know a few companies that will collect a high quality data.
[00:48:38.640 --> 00:48:39.640]   No doubt.
[00:48:39.640 --> 00:48:40.640]   All right.
[00:48:40.640 --> 00:48:44.160]   So next question.
[00:48:44.160 --> 00:48:47.920]   What is the biggest challenge in making machine learning actually work in the real world from
[00:48:47.920 --> 00:48:50.480]   where you sit?
[00:48:50.480 --> 00:48:56.000]   So a really tough learning for me was not at iRobot, was at the company that I was at
[00:48:56.000 --> 00:48:57.480]   before.
[00:48:57.480 --> 00:49:01.400]   And we had this amazing solution.
[00:49:01.400 --> 00:49:08.880]   We had this machine learning algorithm that was for energy efficiency.
[00:49:08.880 --> 00:49:14.260]   And it predicted sort of when there might be a spike on the utilization of the energy
[00:49:14.260 --> 00:49:16.400]   grid or something of that nature.
[00:49:16.400 --> 00:49:17.400]   And it worked really well.
[00:49:17.400 --> 00:49:18.400]   It was really fantastic.
[00:49:18.400 --> 00:49:19.400]   We were all proud of it.
[00:49:19.400 --> 00:49:21.160]   And it didn't sell.
[00:49:21.160 --> 00:49:27.360]   And so the really important thing is communicating to the right people what is it that they're
[00:49:27.360 --> 00:49:29.560]   getting and what the value is.
[00:49:29.560 --> 00:49:32.280]   Because I think, and I was blinded by this too.
[00:49:32.280 --> 00:49:35.240]   I'm not saying that I was smart and I knew it and nobody else did.
[00:49:35.240 --> 00:49:36.400]   I wasn't above it.
[00:49:36.400 --> 00:49:46.680]   But I was sort of, I fell for the mirage of how delightful and wonderful and sexy and
[00:49:46.680 --> 00:49:49.680]   how performant and correct it all was.
[00:49:49.680 --> 00:49:50.680]   And that doesn't matter.
[00:49:50.680 --> 00:49:51.680]   Right?
[00:49:51.680 --> 00:49:54.680]   Like if it doesn't actually solve a real problem that a real human is willing to part money
[00:49:54.680 --> 00:49:59.940]   with in order to have that problem solved for them, it doesn't matter how sophisticated
[00:49:59.940 --> 00:50:00.940]   it is.
[00:50:00.940 --> 00:50:01.940]   Or actually it doesn't matter how much data you have.
[00:50:01.940 --> 00:50:02.940]   It's just solving the right problem.
[00:50:02.940 --> 00:50:08.280]   Danielle, I don't know if you have a different anecdote or a different experience.
[00:50:08.280 --> 00:50:09.960]   That's a great answer.
[00:50:09.960 --> 00:50:10.960]   I would hate to follow that.
[00:50:10.960 --> 00:50:11.960]   Yeah, that was a really good answer.
[00:50:11.960 --> 00:50:12.960]   Notice how it wasn't about iRobot though.
[00:50:12.960 --> 00:50:22.400]   Feel free to go to a past life too.
[00:50:22.400 --> 00:50:26.040]   So one of the biggest challenges that I see with machine learning systems in the real
[00:50:26.040 --> 00:50:29.920]   world and getting them out there is just, there's a lot of different pieces that need
[00:50:29.920 --> 00:50:31.400]   to go in to make this right.
[00:50:31.400 --> 00:50:38.440]   With the data collection piece, the training part, the processing, the model serving, the
[00:50:38.440 --> 00:50:41.680]   software pieces, the hardware pieces, the hardware.
[00:50:41.680 --> 00:50:45.440]   In our case, the hardware changes over time and we also need to make sure the data reflects
[00:50:45.440 --> 00:50:47.440]   that hardware changes over time.
[00:50:47.440 --> 00:50:51.160]   There's the different homes, the different customers, making sure that it's actually
[00:50:51.160 --> 00:50:52.160]   generalizable.
[00:50:52.160 --> 00:50:57.400]   So I think there's so many pieces, making sure that you have quality checks in place
[00:50:57.400 --> 00:51:03.400]   on those different pieces so that when things don't work as well in general or for a specific
[00:51:03.400 --> 00:51:07.040]   customer, we have ways to make it better so that the quality at the end of the day is
[00:51:07.040 --> 00:51:08.040]   what the customer is expecting.
[00:51:08.040 --> 00:51:12.000]   So I think that's the biggest challenge is just connecting all those pieces together
[00:51:12.000 --> 00:51:13.560]   and making it real.
[00:51:13.560 --> 00:51:14.560]   Cool.
[00:51:14.560 --> 00:51:17.320]   Okay, well, final question.
[00:51:17.320 --> 00:51:22.640]   If people enjoyed this snippet, a lot of people are really going to enjoy this and they want
[00:51:22.640 --> 00:51:25.480]   to kind of learn more about your work or reach out to you.
[00:51:25.480 --> 00:51:29.880]   Is there anything you'd like to link to or like a Twitter account that you use or anything
[00:51:29.880 --> 00:51:30.880]   like that?
[00:51:30.880 --> 00:51:34.720]   Well, first you should definitely go to LinkedIn and you should look at the iRobot page and
[00:51:34.720 --> 00:51:37.920]   you should apply to come work with us.
[00:51:37.920 --> 00:51:39.680]   That's the number one.
[00:51:39.680 --> 00:51:40.680]   The iRobot.com website also, sorry?
[00:51:40.680 --> 00:51:44.200]   Seems like it'd be really fun to work.
[00:51:44.200 --> 00:51:45.840]   It is going to be super fun.
[00:51:45.840 --> 00:51:50.800]   I am not at all biased because I love the people that I work with and I love the work
[00:51:50.800 --> 00:51:52.560]   that we do.
[00:51:52.560 --> 00:51:53.560]   But that's one place.
[00:51:53.560 --> 00:51:57.440]   The iRobot.com website actually has a lot of things for the consumer, but it also goes
[00:51:57.440 --> 00:52:02.320]   a little bit into what we do and who we are.
[00:52:02.320 --> 00:52:03.320]   So that's useful.
[00:52:03.320 --> 00:52:05.440]   Personally, for me, you can go to my website.
[00:52:05.440 --> 00:52:07.040]   I'm at AngelaBassa.com.
[00:52:07.040 --> 00:52:12.160]   I'm also prolific on Twitter, which is a problem.
[00:52:12.160 --> 00:52:17.880]   And I'm at @AngeBassa.
[00:52:17.880 --> 00:52:20.360]   And I'm on Twitter as well @DanielleOdeen.
[00:52:20.360 --> 00:52:21.360]   Awesome.
[00:52:21.360 --> 00:52:23.600]   Well, thanks so much.
[00:52:23.600 --> 00:52:24.600]   That was super fun.
[00:52:24.600 --> 00:52:25.600]   I really enjoyed it.
[00:52:25.600 --> 00:52:26.600]   Yes, thank you.
[00:52:26.600 --> 00:52:27.600]   It was great talking to you.
[00:52:27.600 --> 00:52:27.600]   It was fun.
[00:52:27.600 --> 00:52:30.360]   (ethereal music)
[00:52:30.360 --> 00:52:33.100]   (ethereal music)
[00:52:33.100 --> 00:52:35.680]   (gentle music)
[00:52:35.680 --> 00:52:37.760]   you

