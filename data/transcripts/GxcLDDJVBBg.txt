
[00:00:00.000 --> 00:00:05.120]   Can our jobs all be at risk, or could AI be used to drive productivity across the economy?
[00:00:05.120 --> 00:00:09.560]   Joining me now is the CEO and founder of Do Not Pay, the world's first robot lawyer, Joshua
[00:00:09.560 --> 00:00:15.220]   Browder, and Jeremy Howard, founding researcher of Fast.AI, and Matthew Said and Amy Lewin
[00:00:15.220 --> 00:00:16.240]   are still with me.
[00:00:16.240 --> 00:00:22.560]   OK, Joshua Browder, here's my question about jobs specifically.
[00:00:22.560 --> 00:00:27.360]   Let's assume for a moment that AI and robots take a whole lot of jobs.
[00:00:27.360 --> 00:00:30.200]   Say Goldman Sachs are right, 300 million jobs.
[00:00:30.200 --> 00:00:34.400]   All those people are suddenly unemployed, who used to have those jobs.
[00:00:34.400 --> 00:00:38.920]   Where are the people going to be with enough income, if they're unemployed, to buy the
[00:00:38.920 --> 00:00:42.240]   products being made by all the robots?
[00:00:42.240 --> 00:00:45.960]   Well, the government can give them money.
[00:00:45.960 --> 00:00:49.100]   I think AI will replace a huge number of jobs.
[00:00:49.100 --> 00:00:52.760]   Lawyers will be the first to be replaced by AI because they're charging hundreds of dollars
[00:00:52.760 --> 00:00:54.920]   an hour for copying and pasting documents.
[00:00:54.920 --> 00:00:57.640]   But AI will also create a lot of jobs.
[00:00:57.640 --> 00:01:00.800]   A lot of jobs today didn't exist 20 years ago.
[00:01:00.800 --> 00:01:05.440]   So at my company, Do Not Pay, we're now hiring jobs called prompt engineers.
[00:01:05.440 --> 00:01:08.160]   And that is actually telling the AI what to do.
[00:01:08.160 --> 00:01:10.600]   And that job didn't even exist a year ago.
[00:01:10.600 --> 00:01:13.160]   So I think there will be new and exciting jobs for people.
[00:01:13.160 --> 00:01:17.680]   But at the same time, those that charge a lot of money for doing very little, like some
[00:01:17.680 --> 00:01:21.380]   lawyers, not all lawyers, have to worry about being replaced.
[00:01:21.380 --> 00:01:24.960]   You seem very, very anti-lawyers.
[00:01:24.960 --> 00:01:27.400]   I spent too much time trying to fight them.
[00:01:27.400 --> 00:01:29.240]   Probably too much money.
[00:01:29.240 --> 00:01:36.140]   One thing your chatbot lawyer has successfully done is overturn almost 200,000 parking tickets.
[00:01:36.140 --> 00:01:40.200]   I could see you becoming extremely popular just with that service alone.
[00:01:40.200 --> 00:01:47.400]   Yeah, for very simple tasks, no one has time to wait on hold for five hours to save $50,
[00:01:47.400 --> 00:01:50.920]   like getting a refund for a company or getting out of a parking ticket.
[00:01:50.920 --> 00:01:55.160]   And so that's the perfect job for AI, saving time and money for people.
[00:01:55.160 --> 00:01:59.600]   And I think those people, the lawyers you see on billboards that charge a lot of money
[00:01:59.600 --> 00:02:01.320]   to do that should be very worried.
[00:02:01.320 --> 00:02:02.320]   OK.
[00:02:02.320 --> 00:02:07.560]   So Jeremy Howard, I mean, clearly a massive threat to human employment.
[00:02:07.560 --> 00:02:08.960]   We're seeing it already.
[00:02:08.960 --> 00:02:11.400]   And it's going to move probably faster and faster.
[00:02:11.400 --> 00:02:12.400]   But what do we do about this?
[00:02:12.400 --> 00:02:18.080]   You can't just have vast swathes of the planet who were employed suddenly not having employment.
[00:02:18.080 --> 00:02:19.080]   What do we do?
[00:02:19.080 --> 00:02:22.320]   Yeah, I think we've got to be careful.
[00:02:22.320 --> 00:02:25.480]   You know, it's not as easy as what Joshua described.
[00:02:25.480 --> 00:02:29.080]   There aren't going to be new jobs to fill in all the old ones.
[00:02:29.080 --> 00:02:30.320]   And I can explain why.
[00:02:30.320 --> 00:02:31.960]   It's very simple.
[00:02:31.960 --> 00:02:34.320]   Think of it this way.
[00:02:34.320 --> 00:02:35.680]   We have two things.
[00:02:35.680 --> 00:02:37.680]   As humans, we have a body and a brain.
[00:02:37.680 --> 00:02:39.320]   Our body can move things.
[00:02:39.320 --> 00:02:41.920]   Our brain can think about things.
[00:02:41.920 --> 00:02:45.400]   Back in the Industrial Revolution, the engine was developed.
[00:02:45.400 --> 00:02:49.280]   And before that, in the UK, 80% of people worked on farms.
[00:02:49.280 --> 00:02:53.920]   And the engine came along and allowed us to replace humans using their bodies to move
[00:02:53.920 --> 00:02:55.860]   things with machines.
[00:02:55.860 --> 00:03:00.840]   And today, only 1.5% of people work on farms in the UK.
[00:03:00.840 --> 00:03:01.840]   That's fine.
[00:03:01.840 --> 00:03:05.320]   Lots of new jobs came along because we still had something else to give, our brains.
[00:03:05.320 --> 00:03:10.400]   And so now most of us do jobs which involve, at least to some extent, thinking about things.
[00:03:10.400 --> 00:03:16.760]   Now if AI can come along and think about things better than we can, where are these replacement
[00:03:16.760 --> 00:03:17.880]   jobs going to come from?
[00:03:17.880 --> 00:03:19.720]   We've got things that can move stuff.
[00:03:19.720 --> 00:03:22.120]   We've got things that can think about stuff.
[00:03:22.120 --> 00:03:23.600]   So where's the role for humans?
[00:03:23.600 --> 00:03:25.680]   I do think there'll be some jobs still.
[00:03:25.680 --> 00:03:27.440]   For example, talk show host.
[00:03:27.440 --> 00:03:29.440]   I think there are some things where we need a human.
[00:03:29.440 --> 00:03:32.400]   You know, I don't want to tune in to Piers Morgan bot, right?
[00:03:32.400 --> 00:03:35.680]   Well, you just chumble the okay, but on that, it's very interesting.
[00:03:35.680 --> 00:03:37.360]   You don't think you do.
[00:03:37.360 --> 00:03:44.440]   But if I was to have a robot, AI robot, be programmed, look like me, and had access to
[00:03:44.440 --> 00:03:49.600]   everything, every question I'd ever asked, every mannerism, every style, whatever, I reckon
[00:03:49.600 --> 00:03:54.000]   quite quickly they could develop something which could do a very passable version of
[00:03:54.000 --> 00:03:55.000]   me.
[00:03:55.000 --> 00:03:56.000]   Right.
[00:03:56.000 --> 00:03:57.120]   But I still wouldn't tune in.
[00:03:57.120 --> 00:03:58.120]   Like, think of another one.
[00:03:58.120 --> 00:04:01.400]   Are you going to tune in to the tennis playing bots?
[00:04:01.400 --> 00:04:07.120]   Like the fact that Roger Federer is an amazing human is why we like watching him play tennis.
[00:04:07.120 --> 00:04:11.720]   So I think like there'll still be a role of like humans doing human things and other other
[00:04:11.720 --> 00:04:13.720]   people saying, well, look at that person.
[00:04:13.720 --> 00:04:14.760]   That's amazing.
[00:04:14.760 --> 00:04:21.400]   So I think there's going to be a totally different kind of role for people that they won't be
[00:04:21.400 --> 00:04:25.040]   jobs in the classical sense, but it could be great.
[00:04:25.040 --> 00:04:28.720]   If we find a way to transition to this, it's not a threat.
[00:04:28.720 --> 00:04:34.380]   It means you don't have to go to work and do eight hours of whatever you're told tomorrow.
[00:04:34.380 --> 00:04:38.680]   You can do whatever you most want to, that could be great, but it could possibly be a
[00:04:38.680 --> 00:04:39.680]   huge threat.
[00:04:39.680 --> 00:04:40.680]   Yeah.
[00:04:40.680 --> 00:04:41.680]   Let me bring Matthew in here.
[00:04:41.680 --> 00:04:46.240]   A friend of mine, a friend of my son, actually, my oldest boy, his mother wanted him to send
[00:04:46.240 --> 00:04:50.520]   a thank you note for a party she'd arranged for his 30th birthday and he kept delaying
[00:04:50.520 --> 00:04:51.520]   this.
[00:04:51.520 --> 00:04:56.560]   And eventually he asked AI to do him a thank you note to his mum, giving it a few details.
[00:04:56.560 --> 00:05:01.640]   And it did a note that was so perfect and so emotional and heart-rending.
[00:05:01.640 --> 00:05:06.260]   His mother was reduced to tears when she read it and said she'd never been so moved by him.
[00:05:06.260 --> 00:05:09.360]   Now, is that good or is that awful?
[00:05:09.360 --> 00:05:13.680]   It brought great joy to his mother, but she has no idea it was a robot.
[00:05:13.680 --> 00:05:17.120]   As it happens, on Tuesday, my wife sent me an email.
[00:05:17.120 --> 00:05:22.320]   She had gone to chat GBT and said, write a Sunday Times column in the style of Matthew's
[00:05:22.320 --> 00:05:23.320]   side.
[00:05:23.320 --> 00:05:25.040]   And I was like, this is going to be terrible.
[00:05:25.040 --> 00:05:26.040]   I'm reading through it.
[00:05:26.040 --> 00:05:27.040]   Thank you pretty good.
[00:05:27.040 --> 00:05:30.240]   I'm thinking my goodness journalists are going to go.
[00:05:30.240 --> 00:05:33.600]   On the question, by the way, of we want to connect with the human.
[00:05:33.600 --> 00:05:37.560]   How do we know that we're currently talking to Piers Morgan, the flesh and blood human
[00:05:37.560 --> 00:05:39.000]   reality in the robot?
[00:05:39.000 --> 00:05:41.200]   What would stop you substituting the hologram?
[00:05:41.200 --> 00:05:46.480]   I interviewed a robot, honestly, Amy, I interviewed a robot at Good Morning Britain.
[00:05:46.480 --> 00:05:49.640]   It was a female robot and it was chilling.
[00:05:49.640 --> 00:05:50.960]   She looked like a woman.
[00:05:50.960 --> 00:05:52.480]   She spoke like a woman.
[00:05:52.480 --> 00:05:54.160]   Now that was a few years ago.
[00:05:54.160 --> 00:05:58.560]   God knows where they're getting to with this now, where they can just be very convincing
[00:05:58.560 --> 00:05:59.560]   humans.
[00:05:59.560 --> 00:06:01.840]   But with amazingly high power brains.
[00:06:01.840 --> 00:06:02.840]   They can be.
[00:06:02.840 --> 00:06:03.840]   They're not perfect, though.
[00:06:03.840 --> 00:06:08.280]   Yeah, I've got a friend who's a school teacher and she said that when she gets an essay done
[00:06:08.280 --> 00:06:12.360]   by the robot, it's so much better than any 13 year old boy could actually do that.
[00:06:12.360 --> 00:06:16.360]   She can really tell which ones, which still at the moment, but they'll get there.
[00:06:16.360 --> 00:06:17.360]   They will.
[00:06:17.360 --> 00:06:18.360]   They will.
[00:06:18.360 --> 00:06:23.080]   I mean, finally, Joshua, I've asked a few guesses, but what are you most excited by,
[00:06:23.080 --> 00:06:26.760]   by the potential of AI?
[00:06:26.760 --> 00:06:32.320]   I think AI, as was discussed in the previous guest, is being used for evil with debt collectors
[00:06:32.320 --> 00:06:33.320]   and all of this stuff.
[00:06:33.320 --> 00:06:35.320]   But it can also be used for good.
[00:06:35.320 --> 00:06:37.820]   And my goal is to give power to the people.
[00:06:37.820 --> 00:06:43.640]   And if it makes ordinary people more powerful than the richest in society, then that's great.
[00:06:43.640 --> 00:06:49.160]   And so I think it will level the playing field by allowing people to weaponize AI to help
[00:06:49.160 --> 00:06:51.040]   them in their everyday life.
[00:06:51.040 --> 00:06:52.040]   All right.
[00:06:52.040 --> 00:06:53.040]   Jeremy, same question for you.
[00:06:53.040 --> 00:06:54.040]   Quick answer, please.
[00:06:54.040 --> 00:06:57.480]   Yeah, imagine the huge opportunities in education.
[00:06:57.480 --> 00:07:01.920]   I've got a daughter and we're already she's doing stuff with chat GPT and stuff and it's
[00:07:01.920 --> 00:07:02.920]   fantastic.
[00:07:02.920 --> 00:07:05.200]   She can learn about anything she wants to.
[00:07:05.200 --> 00:07:06.200]   It's an engaging thing.
[00:07:06.200 --> 00:07:10.840]   You know, it's not replacing teachers at the moment, but I think AI could be used to really
[00:07:10.840 --> 00:07:12.400]   democratize education.
[00:07:12.400 --> 00:07:13.560]   That's something I'm very excited about.
[00:07:13.560 --> 00:07:16.280]   I could actually see robots taking classes with kids.
[00:07:16.280 --> 00:07:19.680]   I mean, if they're if they're good enough and they give them a bit of personality, why
[00:07:19.680 --> 00:07:20.680]   not?
[00:07:20.680 --> 00:07:23.160]   I mean, most teachers do a version of the same kind of lessons.
[00:07:23.160 --> 00:07:27.080]   I mean, you get the a few, you know, if you who break out and do very different things
[00:07:27.080 --> 00:07:31.000]   each time, but all of them do the same stuff, it's going to be like a personal tutor for
[00:07:31.000 --> 00:07:32.000]   every kid.
[00:07:32.000 --> 00:07:33.000]   Yeah.
[00:07:33.000 --> 00:07:34.000]   It's going to be fascinating.
[00:07:34.000 --> 00:07:35.680]   And thank you both very much indeed.
[00:07:35.680 --> 00:07:36.680]   I appreciate it.

