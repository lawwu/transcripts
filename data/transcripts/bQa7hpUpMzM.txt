
[00:00:00.000 --> 00:00:03.220]   The following is a conversation with Vladimir Vapnik,
[00:00:03.220 --> 00:00:07.200]   part two, the second time we spoke on the podcast.
[00:00:07.200 --> 00:00:09.780]   He's the co-inventor of support vector machines,
[00:00:09.780 --> 00:00:12.120]   support vector clustering, VC theory,
[00:00:12.120 --> 00:00:14.960]   and many foundational ideas in statistical learning.
[00:00:14.960 --> 00:00:17.300]   He was born in the Soviet Union,
[00:00:17.300 --> 00:00:20.260]   worked at the Institute of Control Sciences in Moscow,
[00:00:20.260 --> 00:00:24.700]   then in the US, worked at AT&T, NEC Labs,
[00:00:24.700 --> 00:00:26.120]   Facebook AI Research,
[00:00:26.120 --> 00:00:29.400]   and now is a professor at Columbia University.
[00:00:29.400 --> 00:00:33.040]   His work has been cited over 200,000 times.
[00:00:33.040 --> 00:00:34.880]   The first time we spoke on the podcast
[00:00:34.880 --> 00:00:39.000]   was just over a year ago, one of the early episodes.
[00:00:39.000 --> 00:00:41.460]   This time, we spoke after a lecture he gave
[00:00:41.460 --> 00:00:44.440]   titled "Complete Statistical Theory of Learning"
[00:00:44.440 --> 00:00:47.360]   as part of the MIT series of lectures on deep learning
[00:00:47.360 --> 00:00:50.200]   and AI that I organized.
[00:00:50.200 --> 00:00:53.720]   I'll release the video of the lecture in the next few days.
[00:00:53.720 --> 00:00:56.840]   This podcast and the lecture are independent from each other
[00:00:56.840 --> 00:00:59.420]   so you don't need one to understand the other.
[00:00:59.420 --> 00:01:03.100]   The lecture is quite technical and math heavy,
[00:01:03.100 --> 00:01:04.360]   so if you do watch both,
[00:01:04.360 --> 00:01:06.800]   I recommend listening to this podcast first
[00:01:06.800 --> 00:01:10.180]   since the podcast is probably a bit more accessible.
[00:01:10.180 --> 00:01:14.000]   This is the Artificial Intelligence Podcast.
[00:01:14.000 --> 00:01:16.080]   If you enjoy it, subscribe on YouTube,
[00:01:16.080 --> 00:01:17.920]   give it five stars on Apple Podcast,
[00:01:17.920 --> 00:01:19.160]   support it on Patreon,
[00:01:19.160 --> 00:01:21.080]   or simply connect with me on Twitter
[00:01:21.080 --> 00:01:24.760]   at Lex Friedman, spelled F-R-I-D-M-A-N.
[00:01:24.760 --> 00:01:27.880]   As usual, I'll do one or two minutes of ads now
[00:01:27.880 --> 00:01:29.320]   and never any ads in the middle
[00:01:29.320 --> 00:01:31.460]   that can break the flow of the conversation.
[00:01:31.460 --> 00:01:32.880]   I hope that works for you
[00:01:32.880 --> 00:01:35.000]   and doesn't hurt the listening experience.
[00:01:35.000 --> 00:01:38.200]   This show is presented by Cash App,
[00:01:38.200 --> 00:01:40.600]   the number one finance app in the App Store.
[00:01:40.600 --> 00:01:43.800]   When you get it, use code LEXPODCAST.
[00:01:43.800 --> 00:01:45.840]   Cash App lets you send money to friends,
[00:01:45.840 --> 00:01:48.120]   buy Bitcoin, and invest in the stock market
[00:01:48.120 --> 00:01:49.880]   with as little as $1.
[00:01:49.880 --> 00:01:52.640]   Brokerage services are provided by Cash App Investing,
[00:01:52.640 --> 00:01:56.480]   a subsidiary of Square and member SIPC.
[00:01:56.480 --> 00:01:58.000]   Since Cash App allows you to send
[00:01:58.000 --> 00:02:00.520]   and receive money digitally peer-to-peer,
[00:02:00.520 --> 00:02:03.600]   and security in all digital transactions is very important,
[00:02:03.600 --> 00:02:06.760]   let me mention the PCI Data Security Standard,
[00:02:06.760 --> 00:02:11.760]   PCI DSS Level 1, that Cash App is compliant with.
[00:02:11.760 --> 00:02:15.280]   I'm a big fan of standards for safety and security,
[00:02:15.280 --> 00:02:18.940]   and PCI DSS is a good example of that,
[00:02:18.940 --> 00:02:21.020]   where a bunch of competitors got together
[00:02:21.020 --> 00:02:23.480]   and agreed that there needs to be a global standard
[00:02:23.480 --> 00:02:25.800]   around the security of transactions.
[00:02:25.800 --> 00:02:28.880]   Now, we just need to do the same for autonomous vehicles
[00:02:28.880 --> 00:02:30.480]   and AI systems in general.
[00:02:30.480 --> 00:02:33.880]   So again, if you get Cash App from the App Store
[00:02:33.880 --> 00:02:37.280]   or Google Play, and use the code LEXPODCAST,
[00:02:37.280 --> 00:02:41.240]   you get $10, and Cash App will also donate $10 to FIRST,
[00:02:41.240 --> 00:02:43.120]   one of my favorite organizations
[00:02:43.120 --> 00:02:46.420]   that is helping to advance robotics and STEM education
[00:02:46.420 --> 00:02:48.340]   for young people around the world.
[00:02:49.720 --> 00:02:54.140]   And now, here's my conversation with Vladimir Vapnik.
[00:02:54.140 --> 00:02:58.540]   You and I talked about Alan Turing yesterday a little bit.
[00:02:58.540 --> 00:02:59.780]   - Yes.
[00:02:59.780 --> 00:03:02.660]   - And that he, as the father of artificial intelligence,
[00:03:02.660 --> 00:03:05.700]   may have instilled in our field an ethic of engineering,
[00:03:05.700 --> 00:03:09.540]   and not science, seeking more to build intelligence
[00:03:09.540 --> 00:03:11.940]   rather than to understand it.
[00:03:11.940 --> 00:03:13.300]   What do you think is the difference
[00:03:13.300 --> 00:03:17.700]   between these two paths of engineering intelligence
[00:03:17.700 --> 00:03:21.220]   and the science of intelligence?
[00:03:21.220 --> 00:03:23.660]   - It's a completely different story.
[00:03:23.660 --> 00:03:27.620]   Engineering is imitation of human activity.
[00:03:27.620 --> 00:03:33.500]   You have to make a device which behave as human behave,
[00:03:33.500 --> 00:03:39.180]   have all the functions of human.
[00:03:39.180 --> 00:03:40.880]   It does not matter how you do it.
[00:03:40.880 --> 00:03:45.100]   But to understand what is intelligence about
[00:03:46.020 --> 00:03:47.700]   is quite different problem.
[00:03:47.700 --> 00:03:53.880]   So I think, I believe, that it's somehow related
[00:03:53.880 --> 00:03:56.380]   to predicate we talked yesterday about.
[00:03:56.380 --> 00:04:02.860]   Because, look at the Vladimir Probs idea.
[00:04:02.860 --> 00:04:10.740]   He just found 31 here predicates.
[00:04:12.660 --> 00:04:17.660]   He call it units, which can explain human behavior,
[00:04:17.660 --> 00:04:20.780]   at least in Russian tales.
[00:04:20.780 --> 00:04:24.940]   He look at Russian tales and derive from that.
[00:04:24.940 --> 00:04:27.460]   And then people realize that it more wide
[00:04:27.460 --> 00:04:29.580]   than in Russian tales.
[00:04:29.580 --> 00:04:33.940]   It is in TV, in movie serials, and so on and so on.
[00:04:33.940 --> 00:04:37.820]   - So you're talking about Vladimir Probs.
[00:04:37.820 --> 00:04:38.660]   - Right.
[00:04:38.660 --> 00:04:40.020]   - Who in 1928 published a book,
[00:04:40.020 --> 00:04:44.260]   Morphology of the Folk Tale, describing 31 predicates
[00:04:44.260 --> 00:04:48.700]   that have this kind of sequential structure
[00:04:48.700 --> 00:04:52.860]   that a lot of the stories, narratives follow
[00:04:52.860 --> 00:04:55.040]   in Russian folklore and in other content.
[00:04:55.040 --> 00:04:56.100]   We'll talk about it.
[00:04:56.100 --> 00:04:59.180]   I'd like to talk about predicates in a focused way.
[00:04:59.180 --> 00:05:02.180]   But let me, if you'll allow me to stay zoomed out
[00:05:02.180 --> 00:05:03.740]   on our friend Alan Turing.
[00:05:03.740 --> 00:05:09.660]   And he inspired a generation with the imitation game.
[00:05:10.180 --> 00:05:11.660]   - Yes.
[00:05:11.660 --> 00:05:15.220]   - Do you think, if we can linger on that a little bit longer,
[00:05:15.220 --> 00:05:19.620]   do you think we can learn, do you think learning
[00:05:19.620 --> 00:05:22.380]   to imitate intelligence can get us closer
[00:05:22.380 --> 00:05:25.460]   to understanding intelligence?
[00:05:25.460 --> 00:05:30.460]   So why do you think imitation is so far from understanding?
[00:05:30.460 --> 00:05:34.620]   - I think that it is different.
[00:05:34.620 --> 00:05:36.580]   Between you have different goals.
[00:05:37.540 --> 00:05:42.540]   So your goal is to create something, something useful.
[00:05:42.540 --> 00:05:45.980]   And that is great.
[00:05:45.980 --> 00:05:49.740]   And you can see how much things was done
[00:05:49.740 --> 00:05:52.340]   and I believe that it will be done even more.
[00:05:52.340 --> 00:05:56.900]   You have self-driving cars and also this business.
[00:05:56.900 --> 00:05:58.420]   It is great.
[00:05:58.420 --> 00:06:02.080]   And it was inspired by Turing vision.
[00:06:02.080 --> 00:06:05.500]   But understanding is very difficult.
[00:06:05.500 --> 00:06:08.360]   It's more or less philosophical category.
[00:06:08.360 --> 00:06:11.300]   What means understand the world?
[00:06:11.300 --> 00:06:15.820]   I believe in scheme which starts from Plato
[00:06:15.820 --> 00:06:19.220]   that there exists world of ideas.
[00:06:19.220 --> 00:06:22.940]   I believe that intelligence, it is world of ideas.
[00:06:22.940 --> 00:06:25.900]   But it is world of pure ideas.
[00:06:25.900 --> 00:06:30.900]   And when you combine them with reality things,
[00:06:33.220 --> 00:06:36.540]   it creates, as in my case, invariance,
[00:06:36.540 --> 00:06:38.580]   which is very specific.
[00:06:38.580 --> 00:06:43.580]   And that I believe the combination of ideas
[00:06:43.580 --> 00:06:49.820]   in way to constructing invariant is intelligence.
[00:06:49.820 --> 00:06:53.340]   But first of all, predicate.
[00:06:53.340 --> 00:06:56.180]   If you know predicate, and hopefully
[00:06:56.180 --> 00:07:00.820]   then not too much predicate exist.
[00:07:00.820 --> 00:07:04.260]   For example, 31 predicates for human behavior,
[00:07:04.260 --> 00:07:06.060]   it is not a lot.
[00:07:06.060 --> 00:07:08.780]   - Vladimir Propp used 31,
[00:07:08.780 --> 00:07:12.340]   you can even call them predicates,
[00:07:12.340 --> 00:07:17.340]   31 predicates to describe stories, narratives.
[00:07:17.340 --> 00:07:18.380]   - Right.
[00:07:18.380 --> 00:07:19.380]   - So you think human behavior,
[00:07:19.380 --> 00:07:23.100]   how much of human behavior, how much of our world,
[00:07:23.100 --> 00:07:27.540]   our universe, all the things that matter in our existence
[00:07:27.540 --> 00:07:30.860]   can be summarized in predicates of the kind
[00:07:30.860 --> 00:07:32.660]   that Propp was working with?
[00:07:32.660 --> 00:07:36.980]   - I think that we have a lot of formal behavior.
[00:07:36.980 --> 00:07:41.020]   But I think that predicate is much less.
[00:07:41.020 --> 00:07:45.260]   Because even in this example, which I gave you yesterday,
[00:07:45.260 --> 00:07:50.260]   you saw that predicate can be,
[00:07:50.260 --> 00:07:56.700]   one predicate can construct many different invariants,
[00:07:56.700 --> 00:07:59.380]   depending on your data.
[00:07:59.380 --> 00:08:01.620]   They're applying to different data,
[00:08:01.620 --> 00:08:03.740]   and they give different invariants.
[00:08:03.740 --> 00:08:08.660]   But pure ideas, maybe not so much.
[00:08:08.660 --> 00:08:09.940]   - Not so many.
[00:08:09.940 --> 00:08:11.420]   - I don't know about that.
[00:08:11.420 --> 00:08:15.060]   But my guess, I hope, that's why challenge
[00:08:15.060 --> 00:08:18.780]   about digit recognition, how much you need.
[00:08:18.780 --> 00:08:21.900]   - I think we'll talk about computer vision
[00:08:21.900 --> 00:08:24.820]   and 2D images a little bit in your challenge.
[00:08:24.820 --> 00:08:26.780]   - That's exactly about intelligence.
[00:08:26.780 --> 00:08:30.820]   - That's exactly, that's exactly about,
[00:08:30.820 --> 00:08:34.460]   no, that hopes to be exactly about the spirit
[00:08:34.460 --> 00:08:37.540]   of intelligence in the simplest possible way.
[00:08:37.540 --> 00:08:40.380]   - Yeah, absolutely, you should start the simplest way.
[00:08:40.380 --> 00:08:42.700]   Otherwise you will not be able to do it.
[00:08:42.700 --> 00:08:45.540]   - Well, there's an open question whether starting
[00:08:45.540 --> 00:08:49.220]   at the MNIST digit recognition is a step
[00:08:49.220 --> 00:08:52.700]   towards intelligence, or it's an entirely different thing.
[00:08:52.700 --> 00:08:56.820]   I think that to beat records using, say,
[00:08:56.820 --> 00:09:00.700]   100, 200 times less examples, you need intelligence.
[00:09:00.700 --> 00:09:01.540]   - You need intelligence.
[00:09:01.540 --> 00:09:03.780]   So let's, because you use this term,
[00:09:03.780 --> 00:09:07.260]   and it would be nice, I'd like to ask simple,
[00:09:07.260 --> 00:09:09.980]   maybe even dumb questions.
[00:09:09.980 --> 00:09:11.500]   Let's start with a predicate.
[00:09:11.500 --> 00:09:14.940]   In terms of terms and how you think about it,
[00:09:14.940 --> 00:09:16.100]   what is a predicate?
[00:09:16.100 --> 00:09:18.860]   - I don't know.
[00:09:18.860 --> 00:09:22.060]   I have a feeling formulas, they exist.
[00:09:22.860 --> 00:09:27.860]   But I believe that predicate for 2D images,
[00:09:27.860 --> 00:09:32.300]   one of them is symmetry.
[00:09:32.300 --> 00:09:33.520]   - Hold on a second, sorry.
[00:09:33.520 --> 00:09:36.460]   Sorry to interrupt and pull you back.
[00:09:36.460 --> 00:09:40.700]   At the simplest level, we're not being profound currently.
[00:09:40.700 --> 00:09:44.020]   A predicate is a statement of something that is true.
[00:09:44.020 --> 00:09:45.760]   - Yes.
[00:09:45.760 --> 00:09:50.540]   - Do you think of predicates as somehow
[00:09:50.540 --> 00:09:54.700]   probabilistic in nature, or is this binary,
[00:09:54.700 --> 00:09:59.020]   this is truly constraints of logical statements
[00:09:59.020 --> 00:10:00.220]   about the world?
[00:10:00.220 --> 00:10:04.180]   - In my definition, the simplest predicate is function.
[00:10:04.180 --> 00:10:07.580]   Function, and you can use this function
[00:10:07.580 --> 00:10:10.900]   to make inner product, that is predicate.
[00:10:10.900 --> 00:10:14.020]   - What's the input, and what's the output of the function?
[00:10:14.020 --> 00:10:18.660]   - Input is x, something which is input in reality.
[00:10:18.660 --> 00:10:22.460]   Say if you consider digit recognition,
[00:10:22.460 --> 00:10:25.020]   it's pixel space, input.
[00:10:25.020 --> 00:10:29.800]   But it is function which in pixel space.
[00:10:29.800 --> 00:10:34.660]   But it can be any function from pixel space.
[00:10:34.660 --> 00:10:39.500]   And you choose, and I believe that there are
[00:10:39.500 --> 00:10:42.940]   several functions which is important
[00:10:42.940 --> 00:10:46.440]   for understanding of images.
[00:10:46.440 --> 00:10:48.280]   One of them is symmetry.
[00:10:48.280 --> 00:10:50.980]   It's not so simple construction,
[00:10:50.980 --> 00:10:55.020]   as I described with linearity, with all this stuff.
[00:10:55.020 --> 00:10:58.860]   But another, I believe, I don't know how many,
[00:10:58.860 --> 00:11:03.260]   is how well-structurized is picture.
[00:11:03.260 --> 00:11:04.340]   - Structurized?
[00:11:04.340 --> 00:11:05.180]   - Yeah.
[00:11:05.180 --> 00:11:06.980]   - What do you mean by structurized?
[00:11:06.980 --> 00:11:11.660]   - It is formal definition, say something heavy
[00:11:11.660 --> 00:11:16.660]   on the left corner, not so heavy in the middle, and so on.
[00:11:17.060 --> 00:11:21.860]   You describe in general concept of what you assume.
[00:11:21.860 --> 00:11:25.240]   - Concepts, some kind of universal concepts.
[00:11:25.240 --> 00:11:26.700]   - Yeah.
[00:11:26.700 --> 00:11:29.200]   But I don't know how to formalize this.
[00:11:29.200 --> 00:11:31.600]   - Do you, so this is the thing.
[00:11:31.600 --> 00:11:33.640]   There's a million ways we can talk about this.
[00:11:33.640 --> 00:11:34.680]   I'll keep bringing it up.
[00:11:34.680 --> 00:11:38.180]   But we humans have such concepts,
[00:11:38.180 --> 00:11:41.560]   when we look at digits.
[00:11:41.560 --> 00:11:43.900]   But it's hard to put them, just like you're saying now,
[00:11:43.900 --> 00:11:46.000]   it's hard to put them into words.
[00:11:46.000 --> 00:11:47.760]   You know, that is example.
[00:11:47.760 --> 00:11:53.640]   When critics in music, trying to describe music,
[00:11:53.640 --> 00:11:57.100]   they use predicate.
[00:11:57.100 --> 00:12:02.880]   And not too many predicate, but in different combination.
[00:12:02.880 --> 00:12:07.880]   But they have some special words for describing music.
[00:12:07.880 --> 00:12:12.720]   And the same should be for images.
[00:12:12.720 --> 00:12:15.680]   But maybe there are critics who understand
[00:12:15.680 --> 00:12:19.560]   essence of what this image is about.
[00:12:19.560 --> 00:12:23.640]   - Do you think there exists critics
[00:12:23.640 --> 00:12:28.640]   who can summarize the essence of images, human beings?
[00:12:28.640 --> 00:12:31.900]   - I hope so, yes.
[00:12:31.900 --> 00:12:32.740]   But--
[00:12:32.740 --> 00:12:34.960]   - Explicitly state them on paper.
[00:12:34.960 --> 00:12:41.240]   The fundamental question I'm asking is,
[00:12:42.600 --> 00:12:46.240]   do you think there exists a small set of predicates
[00:12:46.240 --> 00:12:48.080]   that will summarize images?
[00:12:48.080 --> 00:12:51.240]   It feels to our mind like it does,
[00:12:51.240 --> 00:12:56.000]   that the concept of what makes a two and a three and a four.
[00:12:56.000 --> 00:12:58.920]   - No, no, no, it's not on this level.
[00:12:58.920 --> 00:13:04.960]   What, it should not describe two, three, four.
[00:13:04.960 --> 00:13:07.680]   It describes some construction
[00:13:07.680 --> 00:13:10.980]   which allow you to create invariance.
[00:13:11.960 --> 00:13:16.160]   - An invariance, sorry to stick on this, but terminology.
[00:13:16.160 --> 00:13:21.160]   - Invariance, it is property of your image.
[00:13:21.160 --> 00:13:31.640]   I can say, looking at my image, it is more or less symmetric.
[00:13:31.640 --> 00:13:34.160]   And I can give you a value of symmetry.
[00:13:34.160 --> 00:13:39.400]   Say, level of symmetry, using this function
[00:13:39.400 --> 00:13:41.240]   which I gave yesterday.
[00:13:42.240 --> 00:13:47.240]   And you can describe that your image
[00:13:47.240 --> 00:13:51.600]   has these characteristics,
[00:13:51.600 --> 00:13:56.600]   exactly in the way how musical critics describe music.
[00:13:56.600 --> 00:14:02.680]   So, but this is invariant applied to specific data,
[00:14:02.680 --> 00:14:06.160]   to specific music, to something.
[00:14:07.720 --> 00:14:12.440]   I strongly believe in this plot ideas
[00:14:12.440 --> 00:14:15.000]   that there exists world of predicate
[00:14:15.000 --> 00:14:18.920]   and world of reality and predicate and reality
[00:14:18.920 --> 00:14:22.480]   is somehow connected and you have to know that.
[00:14:22.480 --> 00:14:24.020]   - Let's talk about Plato a little bit.
[00:14:24.020 --> 00:14:29.020]   So you draw a line from Plato to Hegel to Wigner to today.
[00:14:29.020 --> 00:14:30.280]   - Yes.
[00:14:30.280 --> 00:14:35.280]   - So Plato has forms, the theory of forms.
[00:14:35.560 --> 00:14:38.600]   There's a world of ideas and a world of things
[00:14:38.600 --> 00:14:40.440]   as you talk about and there's a connection.
[00:14:40.440 --> 00:14:44.720]   And presumably the world of ideas is very small
[00:14:44.720 --> 00:14:48.060]   and the world of things is arbitrarily big.
[00:14:48.060 --> 00:14:49.840]   But they're all, what Plato calls them,
[00:14:49.840 --> 00:14:54.040]   like it's a shadow, the real world is a shadow
[00:14:54.040 --> 00:14:54.880]   from the world of forms.
[00:14:54.880 --> 00:14:56.840]   - Yeah, you have projection.
[00:14:56.840 --> 00:14:57.680]   - Projection.
[00:14:57.680 --> 00:14:59.240]   - Of world of idea.
[00:14:59.240 --> 00:15:00.720]   - Yeah, very poetic.
[00:15:00.720 --> 00:15:04.840]   - In reality you can realize this projection
[00:15:04.840 --> 00:15:09.320]   using these invariants because it is projection
[00:15:09.320 --> 00:15:13.680]   for on specific examples which creates specific features
[00:15:13.680 --> 00:15:15.120]   of specific objects.
[00:15:15.120 --> 00:15:22.400]   - So the essence of intelligence is while only being able
[00:15:22.400 --> 00:15:24.720]   to observe the world of things,
[00:15:24.720 --> 00:15:27.040]   try to come up with a world of ideas.
[00:15:27.040 --> 00:15:30.000]   - Exactly, like in this music story.
[00:15:30.000 --> 00:15:33.160]   Intelligent musical critics knows all this world
[00:15:33.160 --> 00:15:34.800]   and have a feeling about what--
[00:15:34.800 --> 00:15:36.360]   - I feel like that's a contradiction,
[00:15:36.360 --> 00:15:39.160]   intelligent music critics.
[00:15:39.160 --> 00:15:42.080]   I think music is to be
[00:15:42.080 --> 00:15:47.720]   enjoyed in all its forms.
[00:15:47.720 --> 00:15:50.040]   The notion of critic like a food critic.
[00:15:50.040 --> 00:15:52.360]   - No, I don't want that emotion.
[00:15:52.360 --> 00:15:53.760]   - That's an interesting question.
[00:15:53.760 --> 00:15:56.720]   Does emotion, there's certain elements
[00:15:56.720 --> 00:16:00.200]   of the human psychology, of the human experience
[00:16:00.200 --> 00:16:05.200]   which seem to almost contradict intelligence and reason.
[00:16:05.200 --> 00:16:10.520]   Like emotion, like fear, like love, all of those things.
[00:16:10.520 --> 00:16:16.440]   Are those not connected in any way to the space of ideas?
[00:16:16.440 --> 00:16:18.760]   - That I don't know.
[00:16:18.760 --> 00:16:25.280]   I just want to be concentrate on very simple story,
[00:16:25.280 --> 00:16:27.960]   on digit recognition.
[00:16:27.960 --> 00:16:30.480]   - So you don't think you have to love and fear death
[00:16:30.480 --> 00:16:32.840]   in order to recognize digits?
[00:16:32.840 --> 00:16:34.560]   - I don't know.
[00:16:34.560 --> 00:16:37.000]   Because it's so complicated.
[00:16:37.000 --> 00:16:41.600]   It involves a lot of stuff which I never consider.
[00:16:41.600 --> 00:16:44.280]   But I know about digit recognition.
[00:16:44.280 --> 00:16:49.320]   And I know that for digit recognition
[00:16:49.320 --> 00:16:55.760]   to get the records from small number of observations,
[00:16:57.360 --> 00:16:59.400]   you need predicate.
[00:16:59.400 --> 00:17:02.760]   But not special predicate for this problem.
[00:17:02.760 --> 00:17:08.600]   But universal predicate which understand world of images.
[00:17:08.600 --> 00:17:09.760]   - Of visual information.
[00:17:09.760 --> 00:17:11.400]   - Visual, yeah.
[00:17:11.400 --> 00:17:15.880]   But on the first step, they understand, say,
[00:17:15.880 --> 00:17:19.800]   world of handwritten digits or characters
[00:17:19.800 --> 00:17:21.640]   or something simple.
[00:17:21.640 --> 00:17:23.680]   - So like you said, symmetry is an interesting one.
[00:17:23.960 --> 00:17:27.560]   - That's what I think one of the predicates
[00:17:27.560 --> 00:17:29.400]   related to symmetry.
[00:17:29.400 --> 00:17:30.960]   The level of symmetry.
[00:17:30.960 --> 00:17:32.160]   - Okay, degree of symmetry.
[00:17:32.160 --> 00:17:37.160]   So you think symmetry at the bottom is a universal notion
[00:17:37.160 --> 00:17:41.520]   and there's degrees of a single kind of symmetry
[00:17:41.520 --> 00:17:44.200]   or is there many kinds of symmetries?
[00:17:44.200 --> 00:17:46.040]   - Many kinds of symmetries.
[00:17:46.040 --> 00:17:50.960]   There is a symmetry, anti-symmetry, say, letter S.
[00:17:52.400 --> 00:17:56.340]   So it has vertical anti-symmetry.
[00:17:56.340 --> 00:18:02.680]   And it could be diagonal symmetry, vertical symmetry.
[00:18:02.680 --> 00:18:07.680]   - So when you cut vertically the letter S.
[00:18:07.680 --> 00:18:12.800]   - Yeah, then the upper part and lower part
[00:18:12.800 --> 00:18:15.720]   in different directions.
[00:18:15.720 --> 00:18:18.960]   - Yeah, inverted along the Y axis.
[00:18:18.960 --> 00:18:21.280]   But that's just like one example of symmetry, right?
[00:18:21.280 --> 00:18:22.120]   Isn't there like--
[00:18:22.120 --> 00:18:26.360]   - Right, but there is a degree of symmetry.
[00:18:26.360 --> 00:18:29.160]   If you play all this derivative stuff
[00:18:29.160 --> 00:18:34.160]   to do tangent distance,
[00:18:34.160 --> 00:18:40.040]   whatever I describe, you can have a degree of symmetry.
[00:18:40.040 --> 00:18:45.480]   And that is what describing reason of image.
[00:18:45.480 --> 00:18:50.920]   It is the same as you will describe this image.
[00:18:51.920 --> 00:18:56.920]   Same about digits, it has anti-symmetry.
[00:18:56.920 --> 00:19:02.920]   Digits three is symmetric, more or less look for symmetry.
[00:19:02.920 --> 00:19:07.840]   - Do you think such concepts like symmetry,
[00:19:07.840 --> 00:19:09.840]   predicates like symmetry,
[00:19:09.840 --> 00:19:14.320]   is it a hierarchical set of concepts?
[00:19:14.320 --> 00:19:19.320]   Or are these independent, distinct predicates
[00:19:20.080 --> 00:19:23.640]   that we want to discover, some set of?
[00:19:23.640 --> 00:19:26.000]   - No, there is a deal of symmetry.
[00:19:26.000 --> 00:19:29.200]   And you can, this idea of symmetry,
[00:19:29.200 --> 00:19:35.240]   make very general, like degree of symmetry.
[00:19:35.240 --> 00:19:40.720]   A degree of symmetry can be zero, no symmetry at all.
[00:19:40.720 --> 00:19:45.720]   Or degree of symmetry, say, more or less symmetrical.
[00:19:47.000 --> 00:19:50.520]   But you have one of these descriptions.
[00:19:50.520 --> 00:19:52.520]   And symmetry can be different.
[00:19:52.520 --> 00:19:56.360]   As I told, horizontal, vertical, diagonal,
[00:19:56.360 --> 00:20:01.360]   and anti-symmetry is also a concept of symmetry.
[00:20:01.360 --> 00:20:03.320]   - What about shape in general?
[00:20:03.320 --> 00:20:05.840]   I mean, symmetry is a fascinating notion, but--
[00:20:05.840 --> 00:20:08.640]   - No, no, I'm talking about digits.
[00:20:08.640 --> 00:20:11.400]   I would like to concentrate on all,
[00:20:11.400 --> 00:20:14.520]   I would like to know predicates for digit recognition.
[00:20:14.520 --> 00:20:17.000]   - Yes, but symmetry is not enough
[00:20:17.000 --> 00:20:19.400]   for digit recognition, right?
[00:20:19.400 --> 00:20:22.560]   - It is not necessarily for digit recognition.
[00:20:22.560 --> 00:20:26.800]   It helps to create invariant,
[00:20:26.800 --> 00:20:31.800]   which you can use when you will have examples
[00:20:31.800 --> 00:20:35.040]   for digit recognition.
[00:20:35.040 --> 00:20:38.320]   You have regular problem of digit recognition,
[00:20:38.320 --> 00:20:41.640]   you have examples of the first class, or second class.
[00:20:41.640 --> 00:20:45.880]   Plus, you know that there exists concept of symmetry.
[00:20:45.880 --> 00:20:50.440]   And you apply when you're looking for decision rule,
[00:20:50.440 --> 00:20:55.440]   you will apply concept of symmetry
[00:20:55.440 --> 00:21:00.160]   of this level of symmetry, which you estimate from.
[00:21:00.160 --> 00:21:05.160]   So let's talk, everything comes from weak convergence.
[00:21:05.160 --> 00:21:09.280]   - What is convergence, what is weak convergence,
[00:21:09.280 --> 00:21:11.440]   what is strong convergence?
[00:21:11.440 --> 00:21:13.400]   I'm sorry, I'm gonna do this to you.
[00:21:13.400 --> 00:21:15.320]   What are we converging from and to?
[00:21:15.320 --> 00:21:20.520]   - You're converging, you would like to have a function.
[00:21:20.520 --> 00:21:23.640]   The function which, say indicator function,
[00:21:23.640 --> 00:21:28.640]   which indicate your digit five, for example.
[00:21:28.640 --> 00:21:31.520]   - A classification task?
[00:21:31.520 --> 00:21:33.800]   - Let's talk only about classification.
[00:21:33.800 --> 00:21:36.880]   - So classification means you will say
[00:21:36.880 --> 00:21:38.640]   whether this is a five or not,
[00:21:38.640 --> 00:21:40.680]   or say which of the 10 digits it is.
[00:21:40.680 --> 00:21:42.160]   - Right, right.
[00:21:42.160 --> 00:21:45.600]   I would like to have these functions.
[00:21:45.600 --> 00:21:51.600]   Then, I have some examples.
[00:21:51.600 --> 00:22:00.240]   I can consider property of these examples.
[00:22:00.240 --> 00:22:04.880]   Say symmetry, and I can measure level of symmetry
[00:22:04.880 --> 00:22:06.620]   for every digit.
[00:22:08.060 --> 00:22:13.060]   And then I can take average from my training data,
[00:22:13.060 --> 00:22:19.660]   and I will consider only functions
[00:22:19.660 --> 00:22:24.020]   of conditional probability,
[00:22:24.020 --> 00:22:26.340]   which I'm looking for my decision rule.
[00:22:26.340 --> 00:22:32.300]   Which applying to digits,
[00:22:36.460 --> 00:22:40.780]   will give me the same average as I observe on training data.
[00:22:40.780 --> 00:22:45.380]   So actually, this is different level
[00:22:45.380 --> 00:22:48.500]   of description of what you want.
[00:22:48.500 --> 00:22:53.500]   You want not just, you show not one digit.
[00:22:53.500 --> 00:22:58.860]   You show this predicate, show general property
[00:22:58.860 --> 00:23:03.740]   of all digits which you have in mind.
[00:23:03.740 --> 00:23:06.080]   If you have in mind digit three,
[00:23:06.080 --> 00:23:10.380]   it gives you property of digit three,
[00:23:10.380 --> 00:23:13.580]   and you select as admissible set of function,
[00:23:13.580 --> 00:23:16.980]   only function, which keeps this property.
[00:23:16.980 --> 00:23:20.760]   You will not consider other functions.
[00:23:20.760 --> 00:23:24.940]   So you're immediately looking for smaller subset of function.
[00:23:24.940 --> 00:23:27.140]   - That's what you mean by admissible functions.
[00:23:27.140 --> 00:23:28.420]   - Admissible function, exactly.
[00:23:28.420 --> 00:23:30.940]   - Which is still a pretty large,
[00:23:30.940 --> 00:23:32.780]   for the number three, it's a large--
[00:23:32.780 --> 00:23:36.600]   - It's pretty large, but if you have one predicate.
[00:23:36.600 --> 00:23:41.600]   But according to, there is a strong and weak convergence.
[00:23:41.600 --> 00:23:45.280]   Strong convergence is convergence in function.
[00:23:45.280 --> 00:23:49.240]   You're looking for the function, on one function,
[00:23:49.240 --> 00:23:51.900]   and you're looking for another function.
[00:23:51.900 --> 00:23:56.900]   And square difference from them should be small.
[00:23:56.900 --> 00:24:01.880]   If you take difference in any points,
[00:24:01.880 --> 00:24:05.640]   make a square, make an integral, and it should be small.
[00:24:05.640 --> 00:24:08.040]   That is convergence in function.
[00:24:08.040 --> 00:24:11.280]   Suppose you have some function, any function.
[00:24:11.280 --> 00:24:15.440]   So I would say, I say that some function
[00:24:15.440 --> 00:24:16.960]   converge to this function.
[00:24:16.960 --> 00:24:22.880]   If integral from square difference between them is small.
[00:24:22.880 --> 00:24:24.800]   - That's the definition of strong convergence.
[00:24:24.800 --> 00:24:25.800]   - That definition of strong convergence.
[00:24:25.800 --> 00:24:28.960]   - Two functions, the integral of the difference is small.
[00:24:28.960 --> 00:24:31.040]   - It is convergence in functions.
[00:24:31.160 --> 00:24:32.320]   - Yeah.
[00:24:32.320 --> 00:24:36.760]   - But you have different convergence in functionals.
[00:24:36.760 --> 00:24:40.120]   You take any function, you take some function, phi,
[00:24:40.120 --> 00:24:45.120]   and take inner product, this function is f function.
[00:24:45.120 --> 00:24:50.360]   F zero function, which you want to find.
[00:24:50.360 --> 00:24:52.000]   And that gives you some value.
[00:24:52.000 --> 00:24:58.000]   So you say that set of functions converge
[00:25:00.080 --> 00:25:03.080]   in inner product to this function,
[00:25:03.080 --> 00:25:08.080]   if this value of inner product converge to value f zero.
[00:25:08.080 --> 00:25:12.520]   That is for one phi.
[00:25:12.520 --> 00:25:15.680]   But weak convergence requires that it converge
[00:25:15.680 --> 00:25:20.680]   for any function of Hilbert space.
[00:25:20.680 --> 00:25:24.280]   If it converge for any function of Hilbert space,
[00:25:24.280 --> 00:25:28.320]   then you will say that this is weak convergence.
[00:25:28.320 --> 00:25:32.240]   You can think that when you take integral,
[00:25:32.240 --> 00:25:36.000]   that is property, integral property of function.
[00:25:36.000 --> 00:25:39.200]   For example, if you will take sine or cosine,
[00:25:39.200 --> 00:25:43.960]   it is coefficient of, say, Fourier expansion.
[00:25:43.960 --> 00:25:50.560]   So if it converge for all coefficients
[00:25:50.560 --> 00:25:54.280]   of Fourier expansion, so under some condition,
[00:25:54.280 --> 00:25:58.160]   it converge to function you're looking for.
[00:25:58.160 --> 00:26:01.240]   But weak convergence means any property.
[00:26:01.240 --> 00:26:05.880]   Convergence not point-wise,
[00:26:05.880 --> 00:26:08.660]   but integral property of function.
[00:26:08.660 --> 00:26:13.880]   So weak convergence means integral property of functions.
[00:26:13.880 --> 00:26:16.120]   When I'm talking about predicate,
[00:26:16.120 --> 00:26:21.120]   I would like to formulate which integral properties
[00:26:21.120 --> 00:26:26.680]   I would like to have for convergence.
[00:26:27.920 --> 00:26:32.920]   So, and if I will take one predicate,
[00:26:32.920 --> 00:26:35.540]   it's function which I measure property.
[00:26:35.540 --> 00:26:40.640]   If I will use one predicate and say,
[00:26:40.640 --> 00:26:44.840]   I will consider only function which give me
[00:26:44.840 --> 00:26:47.960]   the same value as this predicate,
[00:26:47.960 --> 00:26:52.960]   I selecting set of functions from functions
[00:26:52.960 --> 00:26:57.680]   which is admissible in the sense that function
[00:26:57.680 --> 00:27:01.080]   which I looking for in this set of functions.
[00:27:01.080 --> 00:27:06.080]   Because I checking in training data,
[00:27:06.080 --> 00:27:07.620]   it gives the same.
[00:27:07.620 --> 00:27:10.320]   - Yeah, so it always has to be connected
[00:27:10.320 --> 00:27:12.640]   to the training data in terms of--
[00:27:12.640 --> 00:27:17.400]   - Yeah, but property, you can know independent
[00:27:17.400 --> 00:27:18.800]   on training data.
[00:27:18.800 --> 00:27:21.280]   And this guy, prop.
[00:27:21.280 --> 00:27:22.120]   - Yeah.
[00:27:22.120 --> 00:27:24.040]   - So there is formal property.
[00:27:24.040 --> 00:27:25.480]   31 property and--
[00:27:25.480 --> 00:27:27.280]   - Fairy tale, Russian fairy tale.
[00:27:27.280 --> 00:27:30.520]   But Russian fairy tale is not so interesting.
[00:27:30.520 --> 00:27:33.280]   More interesting is that people applied this
[00:27:33.280 --> 00:27:38.280]   to movies, to theater, to different things.
[00:27:38.280 --> 00:27:42.000]   The same works, they're universal.
[00:27:42.000 --> 00:27:44.800]   - Well, so I would argue that there's a little bit
[00:27:44.800 --> 00:27:48.560]   of a difference between the kinds of things
[00:27:48.560 --> 00:27:51.560]   that were applied to which are essentially stories
[00:27:51.560 --> 00:27:53.420]   and digit recognition.
[00:27:53.420 --> 00:27:55.920]   - It is the same story.
[00:27:55.920 --> 00:27:59.720]   You're saying digits, there's a story within the digit.
[00:27:59.720 --> 00:28:00.560]   - Yeah.
[00:28:00.560 --> 00:28:06.480]   But my point is why I hope that it possible
[00:28:06.480 --> 00:28:11.480]   to beat record using not 60,000,
[00:28:11.480 --> 00:28:13.860]   but say 100 times less.
[00:28:13.860 --> 00:28:16.580]   Because instead you will give predicates.
[00:28:16.580 --> 00:28:22.120]   And you will select your decision not from
[00:28:22.120 --> 00:28:25.720]   wide set of function, but from set of function
[00:28:25.720 --> 00:28:28.080]   which keeps its predicates.
[00:28:28.080 --> 00:28:32.840]   But predicates is not related just to digit recognition.
[00:28:32.840 --> 00:28:33.880]   - Right, so--
[00:28:33.880 --> 00:28:35.520]   - Like in Plotter's case.
[00:28:35.520 --> 00:28:37.700]   (laughing)
[00:28:37.700 --> 00:28:40.240]   - Do you think it's possible to automatically
[00:28:40.240 --> 00:28:42.160]   discover the predicates?
[00:28:42.160 --> 00:28:46.620]   So you basically said that the essence of intelligence
[00:28:46.620 --> 00:28:49.680]   is the discovery of good predicates.
[00:28:49.680 --> 00:28:50.500]   - Yeah.
[00:28:50.500 --> 00:28:53.640]   - Now the natural question is,
[00:28:55.200 --> 00:28:58.200]   you know, that's what Einstein was good at doing in physics.
[00:28:58.200 --> 00:29:03.080]   Can we make machines do these kinds of discovery
[00:29:03.080 --> 00:29:04.560]   of good predicates?
[00:29:04.560 --> 00:29:06.840]   Or is this ultimately a human endeavor?
[00:29:06.840 --> 00:29:09.120]   - That I don't know.
[00:29:09.120 --> 00:29:11.440]   I don't think that machine can do.
[00:29:11.440 --> 00:29:16.440]   Because according to theory about weak convergence,
[00:29:16.440 --> 00:29:22.160]   any function from Hilbert space can be predicated.
[00:29:23.200 --> 00:29:27.680]   So you have infinite number of predicate in upper,
[00:29:27.680 --> 00:29:32.680]   and before you don't know which predicate is good and which.
[00:29:32.680 --> 00:29:37.840]   But whatever probe show and why people call it breakthrough,
[00:29:37.840 --> 00:29:44.920]   that there is not too many predicate which cover
[00:29:44.920 --> 00:29:48.720]   most of situation happened in the world.
[00:29:51.360 --> 00:29:53.200]   - So there's a sea of predicates.
[00:29:53.200 --> 00:29:57.800]   And most of the, only a small amount are useful
[00:29:57.800 --> 00:30:00.240]   for the kinds of things that happen in the world.
[00:30:00.240 --> 00:30:06.360]   - I think that I would say only small part of predicate,
[00:30:06.360 --> 00:30:08.720]   very useful.
[00:30:08.720 --> 00:30:11.360]   Useful all of them.
[00:30:11.360 --> 00:30:13.720]   - Only very few are what we should,
[00:30:13.720 --> 00:30:15.480]   let's call them good predicates.
[00:30:15.480 --> 00:30:16.680]   - Very good predicates.
[00:30:16.680 --> 00:30:18.160]   - Very good predicates.
[00:30:18.160 --> 00:30:21.800]   So can we linger on it, what's your intuition,
[00:30:21.800 --> 00:30:26.800]   why is it hard for a machine to discover good predicates?
[00:30:26.800 --> 00:30:30.760]   - Even in my talk described how to do predicate.
[00:30:30.760 --> 00:30:32.720]   How to find new predicate.
[00:30:32.720 --> 00:30:35.000]   I'm not sure that it is very good.
[00:30:35.000 --> 00:30:36.680]   - What did you propose in your talk?
[00:30:36.680 --> 00:30:41.680]   - No, in my talk I gave example for diabetes.
[00:30:41.680 --> 00:30:43.800]   - Diabetes, yeah.
[00:30:43.800 --> 00:30:46.240]   - When we achieve some percent,
[00:30:46.240 --> 00:30:48.440]   so then we're looking for area
[00:30:48.440 --> 00:30:53.760]   where some sort of predicate, which I formulate,
[00:30:53.760 --> 00:30:55.880]   does not,
[00:30:55.880 --> 00:31:01.440]   keeps invariant.
[00:31:01.440 --> 00:31:07.000]   So if it doesn't keep, I retrain my data,
[00:31:07.000 --> 00:31:11.160]   I select only function which keeps it invariant.
[00:31:11.160 --> 00:31:14.500]   And when I did it, I improved my performance.
[00:31:14.500 --> 00:31:16.520]   I can look for this predicate.
[00:31:16.520 --> 00:31:19.560]   I know technically how to do that.
[00:31:19.560 --> 00:31:24.560]   And you can, of course, do it using machine.
[00:31:24.560 --> 00:31:28.880]   But I'm not sure that we will construct
[00:31:28.880 --> 00:31:31.000]   the smartest predicate.
[00:31:31.000 --> 00:31:34.200]   - But this is the, allow me to linger on it,
[00:31:34.200 --> 00:31:36.320]   because that's the essence, that's the challenge,
[00:31:36.320 --> 00:31:40.360]   that is artificial, that's the human level intelligence
[00:31:40.360 --> 00:31:43.840]   that we seek, is the discovery of these good predicates.
[00:31:43.840 --> 00:31:47.520]   You've talked about deep learning as a way to,
[00:31:47.520 --> 00:31:52.520]   the predicates they use and the functions are mediocre.
[00:31:52.520 --> 00:31:55.080]   We can find better ones.
[00:31:55.080 --> 00:31:57.360]   - Let's talk about deep learning.
[00:31:57.360 --> 00:31:58.200]   - Sure, let's do it.
[00:31:58.200 --> 00:32:03.200]   - I know only Janss-Likun, convolutional network.
[00:32:03.200 --> 00:32:05.280]   And what else?
[00:32:05.280 --> 00:32:07.960]   I don't know, and it's a very simple convolution.
[00:32:07.960 --> 00:32:08.800]   - There's not much else to know.
[00:32:08.800 --> 00:32:10.480]   - It's left and right.
[00:32:10.480 --> 00:32:14.120]   I can do it like that, with one predicate.
[00:32:14.120 --> 00:32:14.960]   It is--
[00:32:14.960 --> 00:32:16.640]   - Convolution is a single predicate.
[00:32:16.640 --> 00:32:21.200]   - It's single, it's single predicate.
[00:32:21.200 --> 00:32:22.040]   - Yes, but--
[00:32:22.040 --> 00:32:25.480]   - You know exactly, you take the derivative
[00:32:25.480 --> 00:32:29.940]   for translation and predicate, this should be kept.
[00:32:29.940 --> 00:32:32.480]   - So that's a single predicate,
[00:32:32.480 --> 00:32:35.040]   but humans discovered that one, or at least--
[00:32:35.040 --> 00:32:39.040]   - That is a risk, not too many predicates.
[00:32:39.040 --> 00:32:43.760]   And that is big story because Jan did it 25 years ago
[00:32:43.760 --> 00:32:48.760]   and nothing so clear was added to deep network.
[00:32:48.760 --> 00:32:53.280]   And then I don't understand
[00:32:53.280 --> 00:32:57.440]   why we should talk about deep network
[00:32:57.440 --> 00:33:01.280]   instead of talking about piecewise linear functions
[00:33:01.280 --> 00:33:02.880]   which keeps this predicate.
[00:33:02.880 --> 00:33:06.200]   - Well, a counter argument is
[00:33:07.320 --> 00:33:11.160]   that maybe the amount of predicates necessary
[00:33:11.160 --> 00:33:16.160]   to solve general intelligence, say in the space of images,
[00:33:16.160 --> 00:33:20.600]   doing efficient recognition of handwritten digits
[00:33:20.600 --> 00:33:22.360]   is very small.
[00:33:22.360 --> 00:33:26.000]   And so we shouldn't be so obsessed about finding,
[00:33:26.000 --> 00:33:28.960]   we'll find other good predicates
[00:33:28.960 --> 00:33:30.720]   like convolution, for example.
[00:33:30.720 --> 00:33:33.880]   You know, there has been other advancements
[00:33:33.880 --> 00:33:37.400]   like if you look at the work with attention,
[00:33:37.400 --> 00:33:39.480]   there's attentional mechanisms,
[00:33:39.480 --> 00:33:42.160]   and especially used in natural language,
[00:33:42.160 --> 00:33:44.200]   focusing the network's ability
[00:33:44.200 --> 00:33:47.640]   to learn at which part of the input to look at.
[00:33:47.640 --> 00:33:51.040]   The thing is, there's other things besides predicates
[00:33:51.040 --> 00:33:55.280]   that are important for the actual engineering mechanism
[00:33:55.280 --> 00:33:58.080]   of showing how much you can really do
[00:33:58.080 --> 00:34:00.060]   given such these predicates.
[00:34:02.120 --> 00:34:04.360]   - I mean, that's essentially the work of deep learning
[00:34:04.360 --> 00:34:07.160]   is constructing architectures
[00:34:07.160 --> 00:34:11.400]   that are able to be, given the training data,
[00:34:11.400 --> 00:34:14.720]   to be able to converge towards
[00:34:14.720 --> 00:34:21.340]   a function that can approximate, can generalize well.
[00:34:21.340 --> 00:34:24.400]   It's an engineering problem.
[00:34:24.400 --> 00:34:26.000]   - Yeah, I understand.
[00:34:26.000 --> 00:34:29.880]   But let's talk not on emotional level
[00:34:29.880 --> 00:34:31.880]   but on a mathematical level.
[00:34:31.880 --> 00:34:36.440]   You have set of piecewise linear functions.
[00:34:36.440 --> 00:34:40.140]   It is all possible neural networks.
[00:34:40.140 --> 00:34:44.040]   It's just piecewise linear functions.
[00:34:44.040 --> 00:34:45.360]   There's many, many pieces.
[00:34:45.360 --> 00:34:47.640]   - Large, large number of piecewise linear functions.
[00:34:47.640 --> 00:34:49.440]   - Exactly, but-- - Very large.
[00:34:49.440 --> 00:34:51.280]   - Very large. - Almost feels like
[00:34:51.280 --> 00:34:53.280]   too large. - But it's still simpler
[00:34:53.280 --> 00:34:56.160]   than say convolution,
[00:34:56.160 --> 00:34:58.840]   than reproducing kernel Hilbert space
[00:34:58.840 --> 00:35:00.880]   which have a Hilbert set of functions.
[00:35:00.880 --> 00:35:03.000]   - What's Hilbert space?
[00:35:03.000 --> 00:35:07.160]   - It's space with infinite number of coordinates,
[00:35:07.160 --> 00:35:11.820]   say, or function for expansion, something like that.
[00:35:11.820 --> 00:35:13.460]   So it's much richer.
[00:35:13.460 --> 00:35:17.520]   So when I'm talking about closed form solution,
[00:35:17.520 --> 00:35:20.840]   I'm talking about this set of function,
[00:35:20.840 --> 00:35:25.840]   not piecewise linear set which is particular case.
[00:35:29.560 --> 00:35:30.920]   It is small part--
[00:35:30.920 --> 00:35:33.600]   - So neural networks is a small part of the space
[00:35:33.600 --> 00:35:35.960]   you're talking about, of functions you're talking about.
[00:35:35.960 --> 00:35:39.080]   - Say, small set of functions.
[00:35:39.080 --> 00:35:40.640]   Let me take that.
[00:35:40.640 --> 00:35:42.760]   But it is fine, it is fine.
[00:35:42.760 --> 00:35:46.600]   I don't want to discuss the small or big,
[00:35:46.600 --> 00:35:47.960]   you take advantage.
[00:35:47.960 --> 00:35:50.080]   So you have some set of functions.
[00:35:50.080 --> 00:35:54.360]   So now when you're trying to create architecture,
[00:35:54.360 --> 00:35:59.120]   you would like to create admissible set of functions
[00:35:59.120 --> 00:36:03.360]   all your tricks to use not all functions,
[00:36:03.360 --> 00:36:06.000]   but some subset of this set of functions.
[00:36:06.000 --> 00:36:10.140]   Say, when you're introducing convolutional net,
[00:36:10.140 --> 00:36:15.140]   it is way to make this subset useful for you.
[00:36:15.140 --> 00:36:19.800]   But from my point of view, convolutional,
[00:36:19.800 --> 00:36:24.800]   it is something you want to keep some invariants,
[00:36:24.800 --> 00:36:26.620]   say translation invariants.
[00:36:27.980 --> 00:36:31.840]   But now if you understand this,
[00:36:31.840 --> 00:36:36.840]   and you cannot explain on the level of ideas
[00:36:36.840 --> 00:36:39.740]   what neural network does,
[00:36:39.740 --> 00:36:44.400]   you should agree that it is much better
[00:36:44.400 --> 00:36:46.720]   to have a set of functions.
[00:36:46.720 --> 00:36:51.140]   As I say, this set of functions should be admissible,
[00:36:51.140 --> 00:36:53.640]   it must keep this invariant, this invariant,
[00:36:53.640 --> 00:36:55.260]   and that invariant.
[00:36:55.260 --> 00:36:59.080]   You know that as soon as you incorporate new invariants,
[00:36:59.080 --> 00:37:02.160]   set of function becomes smaller and smaller and smaller.
[00:37:02.160 --> 00:37:05.540]   - But all the invariants are specified by you, the human.
[00:37:05.540 --> 00:37:11.740]   - Yeah, but what I hope that there is a standard predicate,
[00:37:11.740 --> 00:37:14.200]   like probe show,
[00:37:14.200 --> 00:37:19.640]   that what I want to find for digital recognition.
[00:37:19.640 --> 00:37:22.960]   If we start, it is completely new area,
[00:37:22.960 --> 00:37:25.840]   what is intelligence about on the level
[00:37:25.840 --> 00:37:28.640]   starting from Plata's idea,
[00:37:28.640 --> 00:37:30.900]   what is world of ideas.
[00:37:30.900 --> 00:37:34.780]   So, and I believe that it's not too many.
[00:37:34.780 --> 00:37:39.800]   But you know, it is amusing that mathematician
[00:37:39.800 --> 00:37:44.040]   doing something in neural network, in general function,
[00:37:44.040 --> 00:37:47.600]   but people from literature, from art,
[00:37:47.600 --> 00:37:49.480]   they use this all the time.
[00:37:49.480 --> 00:37:50.320]   - That's right.
[00:37:50.320 --> 00:37:53.800]   - New invariants saying, say,
[00:37:53.800 --> 00:37:57.040]   it is great how people describe music,
[00:37:57.040 --> 00:37:58.800]   we should learn from that.
[00:37:58.800 --> 00:38:02.080]   And something on this level,
[00:38:02.080 --> 00:38:04.960]   but so why Vladimir Probe,
[00:38:04.960 --> 00:38:08.200]   who was just theoretical,
[00:38:08.200 --> 00:38:12.280]   who studied theoretical literature, he found that.
[00:38:12.280 --> 00:38:15.240]   - You know what, let me throw that right back at you,
[00:38:15.240 --> 00:38:17.360]   because there's a little bit of a,
[00:38:17.360 --> 00:38:20.080]   that's less mathematical and more emotional,
[00:38:20.080 --> 00:38:22.760]   philosophical, Vladimir Probe.
[00:38:22.760 --> 00:38:25.000]   I mean, he wasn't doing math.
[00:38:25.000 --> 00:38:25.840]   - No.
[00:38:25.840 --> 00:38:30.120]   - And you just said another emotional statement,
[00:38:30.120 --> 00:38:34.000]   which is you believe that this Plato world of ideas
[00:38:34.000 --> 00:38:34.880]   is small.
[00:38:34.880 --> 00:38:37.040]   - I hope.
[00:38:37.040 --> 00:38:37.880]   - I hope.
[00:38:37.880 --> 00:38:43.600]   What's your intuition, though, if we can linger on it?
[00:38:43.600 --> 00:38:48.640]   - You know, it is not just small or big.
[00:38:48.640 --> 00:38:53.000]   I know exactly, then when I introducing
[00:38:53.000 --> 00:38:58.920]   some predicate, I decrease set of functions.
[00:38:58.920 --> 00:39:02.940]   But my goal to decrease set of function much.
[00:39:02.940 --> 00:39:05.040]   - By as much as possible.
[00:39:05.040 --> 00:39:06.520]   - By as much as possible.
[00:39:06.520 --> 00:39:11.120]   Good predicate, which does this.
[00:39:11.120 --> 00:39:13.360]   Then I should choose next predicate,
[00:39:13.360 --> 00:39:17.280]   which decreases as much as possible.
[00:39:17.280 --> 00:39:19.440]   So set of good predicate,
[00:39:19.440 --> 00:39:23.040]   it is such that they decrease
[00:39:23.040 --> 00:39:27.840]   this amount of admissible function.
[00:39:27.840 --> 00:39:31.060]   - So if each good predicate significantly reduces
[00:39:31.060 --> 00:39:32.640]   the set of admissible functions,
[00:39:32.640 --> 00:39:35.600]   that there naturally should not be that many good predicates.
[00:39:35.600 --> 00:39:40.600]   - No, but if you reduce very well the VC dimension
[00:39:40.600 --> 00:39:45.560]   of the function, of admissible set of function,
[00:39:45.560 --> 00:39:49.160]   it's small, and you need not too much
[00:39:49.160 --> 00:39:51.260]   training data to do well.
[00:39:51.260 --> 00:39:55.360]   - And VC dimension, by the way,
[00:39:55.360 --> 00:39:57.760]   is some measure of capacity of this set of functions.
[00:39:57.760 --> 00:39:58.600]   - Right.
[00:39:58.600 --> 00:40:02.000]   Roughly speaking, how many function in this set.
[00:40:02.000 --> 00:40:04.000]   So you're decreasing, decreasing,
[00:40:04.000 --> 00:40:07.720]   and it makes easy for you to find
[00:40:07.720 --> 00:40:09.120]   function you're looking for.
[00:40:09.120 --> 00:40:13.400]   But the most important part to create
[00:40:13.400 --> 00:40:15.800]   good admissible set of functions.
[00:40:15.800 --> 00:40:18.880]   And it probably, there are many ways,
[00:40:18.880 --> 00:40:23.880]   but the good predicate, it's such that can do that.
[00:40:23.880 --> 00:40:30.560]   So for this duck, you should know a little bit about duck,
[00:40:30.560 --> 00:40:31.600]   because--
[00:40:31.600 --> 00:40:35.360]   - What are the three fundamental laws of ducks?
[00:40:35.360 --> 00:40:37.440]   - Looks like a duck, swims like a duck,
[00:40:37.440 --> 00:40:38.400]   and quacks like a duck.
[00:40:38.400 --> 00:40:41.200]   - You should know something about ducks to be able to--
[00:40:41.200 --> 00:40:42.560]   - Not necessarily.
[00:40:42.560 --> 00:40:45.000]   Looks like, say, horse.
[00:40:45.000 --> 00:40:45.840]   It's also good.
[00:40:45.840 --> 00:40:50.000]   - It generalizes from ducks.
[00:40:50.000 --> 00:40:54.400]   - And talk like, and make sound like horse, or something.
[00:40:54.400 --> 00:40:57.380]   And run like horse, and moves like horse.
[00:40:57.380 --> 00:40:58.520]   It is general.
[00:40:58.520 --> 00:41:04.640]   It is general predicate that this applied to duck.
[00:41:04.640 --> 00:41:08.480]   But for duck, you can say, play chess like duck.
[00:41:09.900 --> 00:41:11.620]   - You cannot say, play chess like duck.
[00:41:11.620 --> 00:41:12.680]   - Why not?
[00:41:12.680 --> 00:41:15.800]   - So you're saying you can, but that would not be a good--
[00:41:15.800 --> 00:41:18.240]   - No, you will not reduce a lot of functions.
[00:41:18.240 --> 00:41:20.200]   - You would not do, yeah, you would not reduce
[00:41:20.200 --> 00:41:21.700]   the set of functions.
[00:41:21.700 --> 00:41:25.140]   - So you can, the story is, formal story,
[00:41:25.140 --> 00:41:28.840]   mathematical story, is that you can use any function
[00:41:28.840 --> 00:41:30.340]   you want as a predicate.
[00:41:30.340 --> 00:41:33.200]   But some of them are good, some of them are not,
[00:41:33.200 --> 00:41:36.120]   because some of them reduce a lot of functions
[00:41:36.120 --> 00:41:38.040]   to admissible set.
[00:41:38.040 --> 00:41:39.760]   Some of them--
[00:41:39.760 --> 00:41:42.120]   - But the question is, and I'll probably keep asking
[00:41:42.120 --> 00:41:45.680]   this question, but how do we find such,
[00:41:45.680 --> 00:41:47.400]   what's your intuition?
[00:41:47.400 --> 00:41:51.080]   Handwritten recognition, how do we find
[00:41:51.080 --> 00:41:52.680]   the answer to your challenge?
[00:41:52.680 --> 00:41:55.980]   - Yeah, I understand it like that.
[00:41:55.980 --> 00:41:57.920]   I understand what--
[00:41:57.920 --> 00:41:59.240]   - What defined?
[00:41:59.240 --> 00:42:01.480]   - What it means, a new predicate.
[00:42:01.480 --> 00:42:06.240]   Like, guy who understand music can say this word
[00:42:06.240 --> 00:42:09.640]   which he described when he listened to music.
[00:42:09.640 --> 00:42:11.720]   He understand music.
[00:42:11.720 --> 00:42:15.600]   He use not too many different, or you can do like prop.
[00:42:15.600 --> 00:42:19.320]   You can make collection what he talking about music,
[00:42:19.320 --> 00:42:21.040]   about this, about that.
[00:42:21.040 --> 00:42:25.040]   It's not too many different situation he described.
[00:42:25.040 --> 00:42:26.960]   - Because we mentioned Vladimir Prop a bunch,
[00:42:26.960 --> 00:42:30.200]   let me just mention, there's a sequence of 31
[00:42:30.200 --> 00:42:36.920]   structural notions that are common in stories,
[00:42:36.920 --> 00:42:37.760]   and I think--
[00:42:37.760 --> 00:42:38.600]   - He called units.
[00:42:38.600 --> 00:42:40.480]   - Units, and I think they resonate.
[00:42:40.480 --> 00:42:43.600]   I mean, it starts, just to give an example,
[00:42:43.600 --> 00:42:46.520]   absention, a member of the hero's community or family
[00:42:46.520 --> 00:42:48.920]   leaves the security of the home environment,
[00:42:48.920 --> 00:42:51.040]   then it goes to the interdiction,
[00:42:51.040 --> 00:42:54.520]   a forbidding edict or command is passed upon the hero,
[00:42:54.520 --> 00:42:56.620]   don't go there, don't do this.
[00:42:56.620 --> 00:42:58.680]   The hero's warned against some action.
[00:42:58.680 --> 00:43:03.680]   Then, step three, violation of interdiction.
[00:43:03.680 --> 00:43:07.580]   Break the rules, break out on your own.
[00:43:07.580 --> 00:43:10.400]   Then, reconnaissance, the villain makes an effort
[00:43:10.400 --> 00:43:12.760]   to attain knowledge, needing to fulfill their plot,
[00:43:12.760 --> 00:43:14.240]   so on, it goes on like this,
[00:43:14.240 --> 00:43:19.240]   ends in a wedding, number 31, happily ever after.
[00:43:19.240 --> 00:43:25.640]   - No, he just gave description of all situation.
[00:43:25.640 --> 00:43:28.160]   He understands this world.
[00:43:28.160 --> 00:43:29.280]   - Of folk tales.
[00:43:29.280 --> 00:43:33.160]   - Yeah, not folk, but stories.
[00:43:33.160 --> 00:43:36.560]   And this story's not in just folk tales.
[00:43:36.560 --> 00:43:39.960]   The story's in detective serials as well.
[00:43:39.960 --> 00:43:43.760]   - And probably in our lives, we probably live--
[00:43:43.760 --> 00:43:45.080]   - Read this.
[00:43:45.080 --> 00:43:50.080]   At the end, they wrote that this predicate is good
[00:43:50.080 --> 00:43:56.440]   for different situation, for movie, for theater.
[00:43:56.440 --> 00:44:00.640]   - By the way, there's also criticism, right?
[00:44:00.640 --> 00:44:03.840]   There's another way to interpret narratives
[00:44:03.840 --> 00:44:08.840]   from Claude Lévi-Strauss.
[00:44:08.840 --> 00:44:10.920]   - I don't know.
[00:44:10.920 --> 00:44:12.640]   I am not in this business.
[00:44:12.640 --> 00:44:14.400]   - No, I know, it's theoretical literature,
[00:44:14.400 --> 00:44:17.240]   but it's looking at paradise behind the scenes.
[00:44:17.240 --> 00:44:18.240]   - It's always the--
[00:44:18.240 --> 00:44:20.160]   - Philosophers argue. - Discussion, yeah.
[00:44:20.160 --> 00:44:23.800]   But at least there is units.
[00:44:23.800 --> 00:44:27.200]   It's not too many units that can describe,
[00:44:27.200 --> 00:44:30.880]   but this guy probably gives another units,
[00:44:30.880 --> 00:44:31.760]   or another way of--
[00:44:31.760 --> 00:44:34.440]   - Exactly, another set of units.
[00:44:34.440 --> 00:44:35.960]   - Another set of predicates.
[00:44:35.960 --> 00:44:40.960]   Doesn't matter how, but they exist, probably.
[00:44:40.960 --> 00:44:46.240]   - My question is whether given those units,
[00:44:46.240 --> 00:44:50.360]   whether without our human brains to interpret these units,
[00:44:50.360 --> 00:44:53.480]   they would still hold as much power as they have.
[00:44:53.480 --> 00:44:56.220]   Meaning, are those units enough
[00:44:56.220 --> 00:44:58.880]   when we give them to an alien species?
[00:44:58.880 --> 00:45:00.320]   - Let me ask you.
[00:45:00.320 --> 00:45:05.320]   Do you understand digit images?
[00:45:05.320 --> 00:45:07.720]   - No, I don't understand.
[00:45:07.720 --> 00:45:08.640]   - No, no, no.
[00:45:08.640 --> 00:45:11.000]   When you can recognize these digit images,
[00:45:11.000 --> 00:45:12.480]   it means that you understand.
[00:45:12.480 --> 00:45:14.200]   - Yes, I understand.
[00:45:14.200 --> 00:45:17.280]   - You understand characters, you understand--
[00:45:17.280 --> 00:45:18.920]   - No, no, no, no.
[00:45:18.920 --> 00:45:25.480]   It's the imitation versus understanding question,
[00:45:25.480 --> 00:45:28.360]   because I don't understand the mechanism
[00:45:28.360 --> 00:45:29.200]   by which I understand.
[00:45:29.200 --> 00:45:30.480]   - No, no, I'm not talking about,
[00:45:30.480 --> 00:45:32.800]   I'm talking about predicates.
[00:45:32.800 --> 00:45:35.160]   You understand that it involves symmetry,
[00:45:35.160 --> 00:45:37.440]   maybe structure, maybe something.
[00:45:37.440 --> 00:45:38.720]   I cannot formulate.
[00:45:38.720 --> 00:45:41.840]   I just was able to find symmetries,
[00:45:41.840 --> 00:45:43.680]   so degree of symmetries.
[00:45:43.680 --> 00:45:44.520]   - That's really good.
[00:45:44.520 --> 00:45:46.400]   So this is a good line.
[00:45:46.400 --> 00:45:50.600]   I feel like I understand the basic elements
[00:45:50.600 --> 00:45:54.320]   of what makes a good hand recognition system my own.
[00:45:54.320 --> 00:45:56.440]   Like symmetry connects with me.
[00:45:56.440 --> 00:45:59.160]   It seems like that's a very powerful predicate.
[00:45:59.160 --> 00:46:02.400]   My question is, is there a lot more going on
[00:46:02.400 --> 00:46:04.500]   that we're not able to introspect?
[00:46:04.500 --> 00:46:09.640]   Maybe I need to be able to understand
[00:46:09.640 --> 00:46:13.080]   a huge amount in the world of ideas,
[00:46:13.080 --> 00:46:18.440]   thousands of predicates, millions of predicates,
[00:46:18.440 --> 00:46:20.600]   in order to do hand recognition.
[00:46:20.600 --> 00:46:21.560]   - I don't think so.
[00:46:21.560 --> 00:46:24.840]   - So you're--
[00:46:24.840 --> 00:46:26.560]   - Both your hope and your intuition
[00:46:26.560 --> 00:46:28.960]   are such that-- - No, let me explain.
[00:46:28.960 --> 00:46:33.500]   You're using digits, you're using examples as well.
[00:46:33.500 --> 00:46:37.640]   Theory says that if you will use
[00:46:37.640 --> 00:46:42.480]   all possible functions
[00:46:42.480 --> 00:46:46.320]   from Hilbert space, all possible predicate,
[00:46:46.320 --> 00:46:47.960]   you don't need training data.
[00:46:47.960 --> 00:46:53.800]   You just will have admissible set of functions
[00:46:53.800 --> 00:46:55.200]   which contain one function.
[00:46:55.200 --> 00:46:57.120]   - Yes.
[00:46:57.120 --> 00:47:01.120]   So the trade-off is when you're not using all predicates,
[00:47:01.120 --> 00:47:02.960]   you're only using a few good predicates,
[00:47:02.960 --> 00:47:05.000]   you need to have some training data.
[00:47:05.000 --> 00:47:06.760]   - Yes, exactly.
[00:47:06.760 --> 00:47:08.440]   - The more good predicates you have,
[00:47:08.440 --> 00:47:09.680]   the less training data you need.
[00:47:09.680 --> 00:47:10.960]   - Exactly.
[00:47:10.960 --> 00:47:13.280]   That is intelligent learning.
[00:47:13.280 --> 00:47:14.720]   - Still, okay.
[00:47:14.720 --> 00:47:17.400]   I'm gonna keep asking the same dumb question,
[00:47:17.400 --> 00:47:19.120]   handwritten recognition.
[00:47:19.120 --> 00:47:21.560]   To solve the challenge, you kind of propose a challenge
[00:47:21.560 --> 00:47:24.640]   that says we should be able to get state-of-the-art
[00:47:24.640 --> 00:47:28.800]   MNIST error rates by using very few,
[00:47:28.800 --> 00:47:31.520]   60, maybe fewer examples per digit.
[00:47:31.520 --> 00:47:35.720]   What kind of predicates do you think you'll--
[00:47:35.720 --> 00:47:37.560]   - That is the challenge.
[00:47:37.560 --> 00:47:39.840]   So people who will solve this problem--
[00:47:39.840 --> 00:47:40.680]   - They will answer.
[00:47:40.680 --> 00:47:41.520]   - They will answer.
[00:47:41.520 --> 00:47:44.780]   - Do you think they'll be able to answer it
[00:47:44.780 --> 00:47:46.580]   in a human explainable way?
[00:47:46.580 --> 00:47:50.820]   - They just need to write function, that's it.
[00:47:50.820 --> 00:47:54.320]   - But, so can that function be written, I guess,
[00:47:54.320 --> 00:47:58.740]   by an automated reasoning system?
[00:47:58.740 --> 00:48:01.120]   Whether we're talking about a neural network
[00:48:01.120 --> 00:48:05.080]   learning a particular function, or another mechanism?
[00:48:05.080 --> 00:48:08.560]   - No, I'm not against neural network.
[00:48:08.560 --> 00:48:11.600]   I'm against admissible set of function
[00:48:11.600 --> 00:48:13.720]   which create neural network.
[00:48:13.720 --> 00:48:15.240]   You did it by hand.
[00:48:15.240 --> 00:48:19.880]   You don't do it by invariance,
[00:48:19.880 --> 00:48:23.360]   by predicate, by reason.
[00:48:23.360 --> 00:48:26.380]   - But neural networks can then reverse,
[00:48:26.380 --> 00:48:29.940]   do the reverse step of helping you find a function.
[00:48:29.940 --> 00:48:33.600]   Just, the task of a neural network
[00:48:33.600 --> 00:48:38.180]   is to find a disentangled representation, for example,
[00:48:38.180 --> 00:48:42.100]   that they call, is to find that one predicate function
[00:48:42.100 --> 00:48:45.180]   that really captures some kind of essence.
[00:48:45.180 --> 00:48:46.860]   One, not the entire essence,
[00:48:46.860 --> 00:48:51.860]   but one very useful essence of this particular visual space.
[00:48:51.860 --> 00:48:54.060]   Do you think that's possible?
[00:48:54.060 --> 00:48:58.620]   Listen, I'm grasping, hoping there's an automated way
[00:48:58.620 --> 00:49:00.300]   to find good predicates.
[00:49:00.300 --> 00:49:02.980]   So the question is, what are the mechanisms
[00:49:02.980 --> 00:49:05.740]   of finding good predicates, ideas,
[00:49:05.740 --> 00:49:08.020]   that you think we should pursue?
[00:49:08.020 --> 00:49:10.020]   A young grad student listening right now.
[00:49:10.020 --> 00:49:12.540]   - I gave example.
[00:49:13.420 --> 00:49:18.420]   So find situation where predicate,
[00:49:18.420 --> 00:49:25.000]   which you're suggesting, don't create invariant.
[00:49:25.000 --> 00:49:28.820]   It's like in physics.
[00:49:28.820 --> 00:49:33.820]   Find situation where existing theory cannot explain it.
[00:49:33.820 --> 00:49:39.380]   - Find situation where the existing theory
[00:49:39.380 --> 00:49:40.700]   can't explain it. - Theory cannot explain
[00:49:40.700 --> 00:49:41.580]   this situation. - So you're finding
[00:49:41.580 --> 00:49:42.780]   contradictions.
[00:49:42.780 --> 00:49:46.140]   Find contradiction, and then remove this contradiction.
[00:49:46.140 --> 00:49:48.940]   But in my case, what means contradiction,
[00:49:48.940 --> 00:49:53.500]   you find function, which, if you will use this function,
[00:49:53.500 --> 00:49:55.060]   you're not keeping invariants.
[00:49:55.060 --> 00:50:01.300]   - So it's really the process of discovering contradictions.
[00:50:01.300 --> 00:50:02.140]   - Yeah.
[00:50:02.140 --> 00:50:05.900]   It is like in physics.
[00:50:05.900 --> 00:50:09.820]   Find situation where you have contradiction
[00:50:09.820 --> 00:50:11.960]   for one of the property.
[00:50:12.960 --> 00:50:15.520]   For one of the predicate.
[00:50:15.520 --> 00:50:19.040]   Then include this predicate, making invariants,
[00:50:19.040 --> 00:50:20.480]   and solve again this problem.
[00:50:20.480 --> 00:50:22.120]   Now you don't have contradiction.
[00:50:22.120 --> 00:50:28.320]   But it is not the best way, probably, I don't know,
[00:50:28.320 --> 00:50:32.000]   to looking for predicate.
[00:50:32.000 --> 00:50:33.600]   - It's just one way, okay.
[00:50:33.600 --> 00:50:35.920]   - That, no, no, it is brute force way.
[00:50:35.920 --> 00:50:37.320]   - The brute force way.
[00:50:37.320 --> 00:50:42.280]   What about the ideas of, what,
[00:50:42.280 --> 00:50:44.680]   big umbrella term of symbolic AI.
[00:50:44.680 --> 00:50:48.520]   There's what, in the '80s, with expert systems,
[00:50:48.520 --> 00:50:51.400]   sort of logic, reasoning-based systems.
[00:50:51.400 --> 00:50:55.720]   Is there hope there to find some,
[00:50:55.720 --> 00:51:00.480]   through sort of deductive reasoning,
[00:51:00.480 --> 00:51:04.440]   to find good predicates?
[00:51:04.440 --> 00:51:06.840]   - I don't think so.
[00:51:07.680 --> 00:51:12.000]   I think that just logic is not enough.
[00:51:12.000 --> 00:51:14.400]   - It's kind of a compelling notion, though.
[00:51:14.400 --> 00:51:17.600]   You know, that when smart people sit in a room
[00:51:17.600 --> 00:51:20.360]   and reason through things, it seems compelling.
[00:51:20.360 --> 00:51:23.540]   And making our machines do the same is also compelling.
[00:51:23.540 --> 00:51:27.820]   - So everything is very simple.
[00:51:27.820 --> 00:51:32.880]   When you have infinite number of predicate,
[00:51:34.080 --> 00:51:38.600]   you can choose the function you want.
[00:51:38.600 --> 00:51:42.540]   You have invariants, and you can choose the function you want.
[00:51:42.540 --> 00:51:47.540]   But you have to have not too many invariants
[00:51:47.540 --> 00:51:53.000]   to solve the problem.
[00:51:53.000 --> 00:51:59.940]   So, and how from infinite number of function,
[00:51:59.940 --> 00:52:04.940]   to select finite number, and hopefully small number
[00:52:04.940 --> 00:52:11.080]   of functions, which is good enough
[00:52:11.080 --> 00:52:16.680]   to extract small set of admissible functions.
[00:52:16.680 --> 00:52:19.800]   So they will be admissible, it's for sure,
[00:52:19.800 --> 00:52:23.880]   because every function just decrease set of function
[00:52:23.880 --> 00:52:25.680]   and leaving it admissible.
[00:52:25.680 --> 00:52:27.720]   But it will be small.
[00:52:27.720 --> 00:52:32.720]   - But why do you think logic-based systems can't help?
[00:52:32.720 --> 00:52:35.280]   Intuition, not--
[00:52:35.280 --> 00:52:37.800]   - Because you should know reality.
[00:52:37.800 --> 00:52:39.480]   You should know life.
[00:52:39.480 --> 00:52:44.280]   This guy like Propp, he knows something.
[00:52:44.280 --> 00:52:49.280]   And he tried to put in invariant his understanding.
[00:52:49.280 --> 00:52:51.560]   - But that's the human, yeah, but see,
[00:52:51.560 --> 00:52:54.460]   you're putting too much value into
[00:52:54.460 --> 00:52:57.900]   Vladimir Propp's knowing something.
[00:52:57.900 --> 00:52:59.460]   - No, it is--
[00:52:59.460 --> 00:53:01.100]   - I'm minding the subject.
[00:53:01.100 --> 00:53:02.900]   - What means you know life?
[00:53:02.900 --> 00:53:05.380]   What it means?
[00:53:05.380 --> 00:53:07.020]   - You know common sense.
[00:53:07.020 --> 00:53:08.380]   - No, no.
[00:53:08.380 --> 00:53:10.380]   You know something.
[00:53:10.380 --> 00:53:13.420]   Common sense, it is some rules.
[00:53:13.420 --> 00:53:14.820]   - You think so?
[00:53:14.820 --> 00:53:17.180]   Common sense is simply rules?
[00:53:17.180 --> 00:53:21.820]   Common sense is everything, it's mortality,
[00:53:21.820 --> 00:53:26.820]   it's fear of death, it's love, it's spirituality,
[00:53:26.820 --> 00:53:30.820]   it's happiness and sadness.
[00:53:30.820 --> 00:53:34.420]   All of it is tied up into understanding gravity,
[00:53:34.420 --> 00:53:36.860]   which is what we think of as common sense.
[00:53:36.860 --> 00:53:39.820]   - I don't really to discuss so wide.
[00:53:39.820 --> 00:53:42.400]   I want to discuss, understand,
[00:53:42.400 --> 00:53:45.420]   digital recognition.
[00:53:45.420 --> 00:53:47.660]   - Any time I bring up love and death,
[00:53:47.660 --> 00:53:50.460]   you bring it back to digital recognition.
[00:53:50.460 --> 00:53:52.980]   - Yeah, no, you know, it is durable
[00:53:52.980 --> 00:53:54.900]   because there is a challenge,
[00:53:54.900 --> 00:53:59.260]   which I see how to solve it.
[00:53:59.260 --> 00:54:02.500]   If I will have a student concentrate on this work,
[00:54:02.500 --> 00:54:04.780]   I will suggest something to solve.
[00:54:04.780 --> 00:54:06.860]   - You mean handwritten recognition?
[00:54:06.860 --> 00:54:10.780]   Yeah, it's a beautifully simple, elegant, and yet--
[00:54:10.780 --> 00:54:13.440]   - I think that I know invariants which will solve this.
[00:54:13.440 --> 00:54:14.280]   - You do?
[00:54:14.280 --> 00:54:15.940]   - I think so, yes.
[00:54:15.940 --> 00:54:20.940]   But it is not universal, it is maybe,
[00:54:20.940 --> 00:54:25.060]   I want some universal invariants which are good
[00:54:25.060 --> 00:54:28.540]   not only for digital recognition, for image understanding.
[00:54:28.540 --> 00:54:34.180]   - So let me ask, how hard do you think
[00:54:34.180 --> 00:54:37.100]   is 2D image understanding?
[00:54:37.100 --> 00:54:42.620]   So if we can kind of intuit handwritten recognition,
[00:54:43.820 --> 00:54:48.820]   how big of a step, leap, journey is it from that?
[00:54:48.820 --> 00:54:51.980]   If I gave you good, if I solved your challenge
[00:54:51.980 --> 00:54:53.620]   for handwritten recognition,
[00:54:53.620 --> 00:54:56.520]   how long would my journey then be from that
[00:54:56.520 --> 00:54:59.380]   to understanding more general natural images?
[00:54:59.380 --> 00:55:01.940]   - Immediately, you will understand this
[00:55:01.940 --> 00:55:04.060]   as soon as you will make a record.
[00:55:04.060 --> 00:55:07.740]   Because it is not for free.
[00:55:07.740 --> 00:55:12.740]   As soon as you will create several invariants
[00:55:13.020 --> 00:55:18.020]   which will help you to get the same performance
[00:55:18.020 --> 00:55:22.820]   that the best neural net did,
[00:55:22.820 --> 00:55:27.820]   using 100 times, maybe more than 100 times less examples,
[00:55:27.820 --> 00:55:31.260]   you have to have something smart to do that.
[00:55:31.260 --> 00:55:32.260]   - And you're saying--
[00:55:32.260 --> 00:55:35.220]   - That is invariant, it is predicate.
[00:55:35.220 --> 00:55:38.580]   Because you should put some idea how to do that.
[00:55:39.460 --> 00:55:42.380]   But okay, let me just pause.
[00:55:42.380 --> 00:55:44.500]   Maybe it's a trivial point, maybe not.
[00:55:44.500 --> 00:55:48.820]   But handwritten recognition feels like a 2D,
[00:55:48.820 --> 00:55:50.440]   two-dimensional problem.
[00:55:50.440 --> 00:55:55.340]   And it seems like how much complicated is the fact
[00:55:55.340 --> 00:55:58.020]   that most images are a projection
[00:55:58.020 --> 00:56:03.020]   of a three-dimensional world onto a 2D plane.
[00:56:03.020 --> 00:56:05.900]   It feels like for a three-dimensional world,
[00:56:05.900 --> 00:56:08.660]   we need to start understanding common sense
[00:56:08.660 --> 00:56:10.920]   in order to understand an image.
[00:56:10.920 --> 00:56:16.980]   It's no longer visual shape and symmetry.
[00:56:16.980 --> 00:56:20.740]   It's having to start to understand concepts,
[00:56:20.740 --> 00:56:22.100]   understand life.
[00:56:22.100 --> 00:56:22.940]   - Yeah.
[00:56:22.940 --> 00:56:27.300]   You're talking that there are different invariants.
[00:56:27.300 --> 00:56:28.900]   Different predicates, yeah.
[00:56:28.900 --> 00:56:32.500]   - And potentially much larger number.
[00:56:32.500 --> 00:56:34.340]   - You know, maybe.
[00:56:34.340 --> 00:56:36.340]   But let's start from simple.
[00:56:36.340 --> 00:56:38.020]   - Well, yeah, but you said that it would be--
[00:56:38.020 --> 00:56:41.420]   - But you know, I cannot think about things
[00:56:41.420 --> 00:56:43.300]   which I don't understand.
[00:56:43.300 --> 00:56:44.820]   This I understand.
[00:56:44.820 --> 00:56:48.460]   But I'm sure that I don't understand everything there.
[00:56:48.460 --> 00:56:49.300]   - Yeah, that's the difference.
[00:56:49.300 --> 00:56:53.140]   - It's like in staying, say, do as simple as possible,
[00:56:53.140 --> 00:56:54.380]   but not simpler.
[00:56:54.380 --> 00:56:56.560]   And that is exact case.
[00:56:56.560 --> 00:56:57.400]   - With handwritten recognition.
[00:56:57.400 --> 00:56:58.980]   - With handwritten.
[00:56:58.980 --> 00:57:01.980]   - Yeah, but never, that's the difference between you and I.
[00:57:04.940 --> 00:57:07.940]   I welcome and enjoy thinking about things
[00:57:07.940 --> 00:57:09.900]   I completely don't understand.
[00:57:09.900 --> 00:57:12.380]   Because to me, it's a natural extension
[00:57:12.380 --> 00:57:15.140]   without having solved handwritten recognition
[00:57:15.140 --> 00:57:20.140]   to wonder how difficult is the next step
[00:57:20.140 --> 00:57:25.680]   of understanding 2D, 3D images.
[00:57:25.680 --> 00:57:29.260]   Because ultimately, while the science of intelligence
[00:57:29.260 --> 00:57:31.700]   is fascinating, it's also fascinating to see
[00:57:31.700 --> 00:57:34.700]   how that maps to the engineering of intelligence.
[00:57:34.700 --> 00:57:39.340]   And recognizing handwritten digits is not,
[00:57:39.340 --> 00:57:43.100]   doesn't help you, it might, it may not help you
[00:57:43.100 --> 00:57:46.560]   with the problem of general intelligence.
[00:57:46.560 --> 00:57:47.400]   We don't know.
[00:57:47.400 --> 00:57:49.500]   It'll help you a little bit, we don't know how much.
[00:57:49.500 --> 00:57:50.340]   - It's unclear.
[00:57:50.340 --> 00:57:51.160]   - It's unclear.
[00:57:51.160 --> 00:57:52.000]   - Yeah.
[00:57:52.000 --> 00:57:52.840]   - It might very much.
[00:57:52.840 --> 00:57:53.660]   - But I would like to make a remark.
[00:57:53.660 --> 00:57:54.500]   - Yes.
[00:57:54.500 --> 00:57:58.780]   - I start not from very primitive problem,
[00:57:58.780 --> 00:58:03.100]   make a challenge problem.
[00:58:03.100 --> 00:58:06.800]   I start with very general problem, with Plato.
[00:58:06.800 --> 00:58:10.660]   So you understand, and it comes from Plato
[00:58:10.660 --> 00:58:13.660]   to digit recognition.
[00:58:13.660 --> 00:58:14.500]   So--
[00:58:14.500 --> 00:58:19.140]   - So you basically took Plato and the world of forms
[00:58:19.140 --> 00:58:23.900]   and ideas and mapped and projected into the clearest,
[00:58:23.900 --> 00:58:26.820]   simplest formulation of that big world.
[00:58:26.820 --> 00:58:30.660]   - You know, I would say that I did not understand Plato
[00:58:31.540 --> 00:58:36.540]   until recently, and until I consider weak convergence
[00:58:36.540 --> 00:58:43.380]   and then predicate and then, oh, this is what Plato taught.
[00:58:43.380 --> 00:58:46.300]   - So--
[00:58:46.300 --> 00:58:47.120]   - Can you linger on that?
[00:58:47.120 --> 00:58:50.180]   Like why, how do you think about this world of ideas
[00:58:50.180 --> 00:58:51.980]   and world of things in Plato?
[00:58:51.980 --> 00:58:54.860]   - No, it is metaphor, it is--
[00:58:54.860 --> 00:58:55.820]   - It's a metaphor for sure.
[00:58:55.820 --> 00:58:56.660]   - Yeah.
[00:58:56.660 --> 00:58:57.820]   - It's a poetic and a beautiful metaphor.
[00:58:57.820 --> 00:58:58.740]   - Yeah, yeah, yeah.
[00:58:58.740 --> 00:59:00.540]   - But what, can you--
[00:59:00.540 --> 00:59:04.980]   - But it is a way how you should try to understand
[00:59:04.980 --> 00:59:07.900]   how attack ideas in the world.
[00:59:07.900 --> 00:59:12.900]   So from my point of view, it is very clear,
[00:59:12.900 --> 00:59:14.900]   but it is lying.
[00:59:14.900 --> 00:59:17.540]   All the time people looking for that.
[00:59:17.540 --> 00:59:22.540]   Say, Plato's and Hegel, whatever reasonable it exists,
[00:59:22.540 --> 00:59:26.700]   whatever exists, it is reasonable.
[00:59:26.700 --> 00:59:30.240]   I don't know what he have in mind, reasonable.
[00:59:30.240 --> 00:59:31.580]   - Right, there's philosophers again.
[00:59:31.580 --> 00:59:33.300]   - No, no, no, no, no, no, no, no.
[00:59:33.300 --> 00:59:38.100]   It is next stop of Wigner, that mathematics
[00:59:38.100 --> 00:59:40.740]   understand something of reality.
[00:59:40.740 --> 00:59:42.440]   It is the same Plato line.
[00:59:42.440 --> 00:59:47.100]   And then it comes suddenly to Vladimir Propp.
[00:59:47.100 --> 00:59:52.880]   Look, 31 ideas, 31 units, and describes everything.
[00:59:52.880 --> 00:59:59.340]   - There's abstractions, ideas that represent our world.
[01:00:00.160 --> 01:00:03.320]   And we should always try to reach into that.
[01:00:03.320 --> 01:00:07.520]   - Yeah, but you should make a projection on reality.
[01:00:07.520 --> 01:00:11.820]   But understanding is, it is abstract ideas.
[01:00:11.820 --> 01:00:15.880]   You have in your mind several abstract ideas
[01:00:15.880 --> 01:00:17.800]   which you can apply to reality.
[01:00:17.800 --> 01:00:19.160]   - And reality in this case,
[01:00:19.160 --> 01:00:21.400]   so if you look at machine learning, is data.
[01:00:21.400 --> 01:00:22.720]   - It's example, data.
[01:00:22.720 --> 01:00:24.080]   - Data.
[01:00:24.080 --> 01:00:26.280]   Okay, let me put this on you,
[01:00:26.280 --> 01:00:28.360]   because I'm an emotional creature.
[01:00:28.360 --> 01:00:30.780]   I'm not a mathematical creature like you.
[01:00:30.780 --> 01:00:33.400]   I find compelling the idea,
[01:00:33.400 --> 01:00:36.660]   forget the space, the sea of functions.
[01:00:36.660 --> 01:00:39.520]   There's also a sea of data in the world.
[01:00:39.520 --> 01:00:42.280]   And I find compelling that there might be,
[01:00:42.280 --> 01:00:47.280]   like you said, teacher, small examples of data
[01:00:47.280 --> 01:00:52.620]   that are most useful for discovering good,
[01:00:52.620 --> 01:00:55.540]   whether it's predicates or good functions,
[01:00:55.540 --> 01:01:00.300]   that the selection of data may be a powerful journey,
[01:01:00.300 --> 01:01:03.740]   a useful, you know, coming up with a mechanism
[01:01:03.740 --> 01:01:06.460]   for selecting good data might be useful too.
[01:01:06.460 --> 01:01:12.420]   Do you find this idea of finding the right data set
[01:01:12.420 --> 01:01:13.960]   interesting at all?
[01:01:13.960 --> 01:01:16.680]   Or do you kind of take the data set as a given?
[01:01:16.680 --> 01:01:22.620]   - I think that it is, you know, my scheme is very simple.
[01:01:22.620 --> 01:01:24.880]   You have huge set of functions.
[01:01:25.880 --> 01:01:30.880]   If you will apply, and you have not too many data,
[01:01:30.880 --> 01:01:36.480]   if you pick up function which describes this data,
[01:01:36.480 --> 01:01:39.940]   you will do not very well.
[01:01:39.940 --> 01:01:42.240]   - Like randomly pick up?
[01:01:42.240 --> 01:01:45.440]   - Yeah, you will overfit, it will be overfitting.
[01:01:45.440 --> 01:01:50.160]   So you should decrease set of function
[01:01:50.160 --> 01:01:53.660]   from which you're picking up one.
[01:01:53.660 --> 01:01:58.080]   So you should go somehow to admissible set of function.
[01:01:58.080 --> 01:02:02.360]   And this, what about weak conversions?
[01:02:02.360 --> 01:02:07.240]   So but, from another point of view,
[01:02:07.240 --> 01:02:13.200]   to make admissible set of function,
[01:02:13.200 --> 01:02:15.320]   you need just a data, just function
[01:02:15.320 --> 01:02:19.400]   which you will take in inner product,
[01:02:19.400 --> 01:02:24.400]   which you will measure property of your function.
[01:02:24.400 --> 01:02:31.180]   And that is how it works.
[01:02:31.180 --> 01:02:32.740]   - No, I get it, I get it, I understand it,
[01:02:32.740 --> 01:02:34.980]   but do you, the reality is--
[01:02:34.980 --> 01:02:39.140]   - But let's think about examples.
[01:02:39.140 --> 01:02:41.860]   You have huge set of function,
[01:02:41.860 --> 01:02:44.640]   and you have several examples.
[01:02:44.640 --> 01:02:49.640]   If you just trying to take function
[01:02:49.640 --> 01:02:52.580]   which satisfies these examples,
[01:02:52.580 --> 01:02:55.620]   you still will overfit.
[01:02:55.620 --> 01:02:59.220]   You need decrease, you need admissible set of function.
[01:02:59.220 --> 01:03:00.160]   - Yeah, absolutely.
[01:03:00.160 --> 01:03:05.060]   But what, say you have more data than functions.
[01:03:05.060 --> 01:03:08.300]   So sort of consider the, I mean,
[01:03:08.300 --> 01:03:09.800]   maybe not more data than functions,
[01:03:09.800 --> 01:03:11.300]   'cause that's-- - It's impossible.
[01:03:11.300 --> 01:03:12.140]   - Impossible.
[01:03:12.140 --> 01:03:15.160]   But what, I was trying to be poetic for a second.
[01:03:15.160 --> 01:03:17.200]   I mean, you have a huge amount of data,
[01:03:17.200 --> 01:03:19.880]   a huge amount of examples.
[01:03:19.880 --> 01:03:22.400]   - But amount of function can be even--
[01:03:22.400 --> 01:03:24.360]   - It can get bigger, I understand.
[01:03:24.360 --> 01:03:25.520]   - Everything can--
[01:03:25.520 --> 01:03:27.560]   - There's always a bigger boat.
[01:03:27.560 --> 01:03:29.280]   - Full Hilbert space.
[01:03:29.280 --> 01:03:30.260]   - I gotcha.
[01:03:30.260 --> 01:03:31.840]   But okay.
[01:03:31.840 --> 01:03:35.840]   But you don't find the world of data
[01:03:35.840 --> 01:03:38.760]   to be an interesting optimization space.
[01:03:38.760 --> 01:03:42.280]   Like the optimization should be in the space of functions.
[01:03:42.280 --> 01:03:46.980]   - In creating admissible set of function.
[01:03:46.980 --> 01:03:48.140]   - Admissible set of function.
[01:03:48.140 --> 01:03:52.440]   - No, you know, even from the classical basis theory,
[01:03:52.440 --> 01:03:56.380]   from structure risk minimization,
[01:03:56.380 --> 01:04:01.380]   you should organize function in the way
[01:04:01.380 --> 01:04:06.540]   that they will be useful for you.
[01:04:06.540 --> 01:04:07.540]   - Right.
[01:04:07.540 --> 01:04:10.300]   - And that is admissible set.
[01:04:10.300 --> 01:04:12.620]   - The way you're thinking about useful
[01:04:12.620 --> 01:04:16.940]   is you're given a small set of example.
[01:04:16.940 --> 01:04:17.820]   - Useful small.
[01:04:17.820 --> 01:04:21.820]   Small set of function which contain function by looking for.
[01:04:21.820 --> 01:04:25.300]   - Yeah, but looking for based on
[01:04:25.300 --> 01:04:27.620]   the empirical set of small examples.
[01:04:27.620 --> 01:04:31.180]   - Yeah, but that is another story, I don't touch it.
[01:04:31.180 --> 01:04:35.740]   Because I believe that this small examples
[01:04:35.740 --> 01:04:37.380]   is not too small.
[01:04:37.380 --> 01:04:41.380]   So 60 per class, law of large numbers works.
[01:04:41.380 --> 01:04:43.380]   I don't need uniform law.
[01:04:43.380 --> 01:04:46.740]   The story is that in statistics there are two law.
[01:04:46.740 --> 01:04:51.100]   Law of large numbers and uniform law of large numbers.
[01:04:51.100 --> 01:04:55.060]   So I want to be in situation where I use law
[01:04:55.060 --> 01:04:58.260]   of large numbers but not uniform law of large numbers.
[01:04:58.260 --> 01:05:01.420]   - Right, so 60 is law of large, it's large enough.
[01:05:01.420 --> 01:05:05.580]   - I hope, no, it still need some evaluation,
[01:05:05.580 --> 01:05:10.060]   some bounds, so it's, but the idea is the following.
[01:05:10.060 --> 01:05:16.580]   If you trust that, say, this average gives you
[01:05:16.580 --> 01:05:21.020]   something close to expectation,
[01:05:21.020 --> 01:05:26.020]   so you can talk about that, about this predicate.
[01:05:26.020 --> 01:05:29.800]   And that is basis of human intelligence.
[01:05:29.800 --> 01:05:33.740]   - Good predicates is the, the discovery of good predicates
[01:05:33.740 --> 01:05:34.580]   is the basis of human intelligence.
[01:05:34.580 --> 01:05:39.580]   - No, no, it is discovery of your understanding world.
[01:05:39.580 --> 01:05:43.560]   Of your methodology of understanding world.
[01:05:43.560 --> 01:05:47.260]   Because you have several function
[01:05:47.260 --> 01:05:49.080]   which you will apply to reality.
[01:05:49.080 --> 01:05:52.500]   - Can you say that again?
[01:05:52.500 --> 01:05:54.420]   So you're--
[01:05:54.420 --> 01:05:57.560]   - You have several functions, predicate.
[01:05:57.560 --> 01:05:59.900]   But they're abstract.
[01:05:59.900 --> 01:06:04.340]   Then you will apply them to reality, to your data.
[01:06:04.340 --> 01:06:07.420]   And you will create in this way predicate.
[01:06:07.420 --> 01:06:09.660]   Which is useful for your task.
[01:06:09.660 --> 01:06:16.420]   But predicate are not related specifically to your task,
[01:06:16.420 --> 01:06:20.100]   to this task, it is abstract functions.
[01:06:20.100 --> 01:06:23.260]   Which being applied to--
[01:06:23.260 --> 01:06:25.260]   - Many tasks that you might be interested in.
[01:06:25.260 --> 01:06:27.660]   - It might be many tasks, I don't know.
[01:06:27.660 --> 01:06:28.660]   - Well--
[01:06:28.660 --> 01:06:29.940]   - Different tasks.
[01:06:29.940 --> 01:06:31.660]   - Well they should be many tasks, right?
[01:06:31.660 --> 01:06:35.680]   - I believe like, like in probe case.
[01:06:35.680 --> 01:06:38.540]   It was for fairy tales, but it's happened everywhere.
[01:06:38.540 --> 01:06:42.180]   - Okay, so we talked about images a little bit,
[01:06:42.180 --> 01:06:45.780]   but can we talk about Noam Chomsky for a second?
[01:06:45.780 --> 01:06:49.020]   (laughing)
[01:06:49.020 --> 01:06:54.220]   - I believe I don't know him very well.
[01:06:54.220 --> 01:06:55.660]   - Personally, well--
[01:06:55.660 --> 01:06:58.260]   - Not personally, I don't know his ideas.
[01:06:58.260 --> 01:07:01.020]   - Well let me just say, do you think language,
[01:07:01.020 --> 01:07:05.780]   human language, is essential to expressing ideas,
[01:07:05.780 --> 01:07:08.340]   as Noam Chomsky believes?
[01:07:08.340 --> 01:07:10.140]   So like, language is at the core
[01:07:10.140 --> 01:07:12.920]   of our formation of predicates.
[01:07:12.920 --> 01:07:14.940]   It's like human language--
[01:07:14.940 --> 01:07:18.580]   - For me, language, and all the story of language,
[01:07:18.580 --> 01:07:20.740]   is very complicated.
[01:07:20.740 --> 01:07:25.740]   I don't understand this, and I'm not, I thought about--
[01:07:25.740 --> 01:07:26.560]   - Nobody does.
[01:07:26.560 --> 01:07:30.780]   - I'm not ready to work on that, because it's so huge.
[01:07:30.780 --> 01:07:34.240]   It is not for me, and I believe not for our century.
[01:07:34.240 --> 01:07:37.340]   - The 21st century.
[01:07:37.340 --> 01:07:39.180]   - Not for 21st century.
[01:07:39.180 --> 01:07:40.020]   - So--
[01:07:40.020 --> 01:07:42.180]   - We should learn something, a lot of stuff,
[01:07:42.180 --> 01:07:45.100]   from simple task, like digit recognition.
[01:07:45.100 --> 01:07:49.260]   - So you think, okay, you think digital recognition,
[01:07:49.260 --> 01:07:54.260]   2D image, how would you more abstractly define
[01:07:54.260 --> 01:07:56.460]   digit recognition?
[01:07:56.460 --> 01:08:01.460]   It's 2D image, symbol recognition, essentially?
[01:08:01.460 --> 01:08:08.100]   I mean, I'm trying to get a sense,
[01:08:08.100 --> 01:08:09.700]   sort of thinking about it now,
[01:08:09.700 --> 01:08:12.880]   having worked with MNIST forever,
[01:08:12.880 --> 01:08:16.020]   how small of a subset is this,
[01:08:16.020 --> 01:08:18.580]   of the general vision recognition problem,
[01:08:18.580 --> 01:08:20.460]   and the general intelligence problem?
[01:08:20.460 --> 01:08:26.340]   Is it, yeah, is it a giant subset?
[01:08:26.340 --> 01:08:27.820]   Is it not?
[01:08:27.820 --> 01:08:30.220]   And how far away is language?
[01:08:30.220 --> 01:08:33.420]   - You know, let me refer to Einstein.
[01:08:33.420 --> 01:08:38.300]   Take the simplest problem, as simple as possible,
[01:08:38.300 --> 01:08:41.780]   but not simpler, and this is challenge,
[01:08:41.780 --> 01:08:46.780]   is simple problem, but it's simple by idea,
[01:08:46.780 --> 01:08:50.360]   but not simple to get it.
[01:08:50.360 --> 01:08:55.360]   When you will do this, you will find some predicate,
[01:08:55.900 --> 01:08:57.180]   which helps you to do it.
[01:08:57.180 --> 01:08:59.420]   - Well, yeah, I mean, with Einstein,
[01:08:59.420 --> 01:09:04.140]   you can, you look at general relativity,
[01:09:04.140 --> 01:09:06.580]   but that doesn't help you with quantum mechanics.
[01:09:06.580 --> 01:09:08.740]   - That's another story,
[01:09:08.740 --> 01:09:11.840]   you don't have any universal instrument.
[01:09:11.840 --> 01:09:15.380]   - Yeah, so I'm trying to wonder if,
[01:09:15.380 --> 01:09:17.540]   which space we're in, whether the,
[01:09:17.540 --> 01:09:21.140]   whether handwritten recognition is like general relativity,
[01:09:21.140 --> 01:09:23.140]   and then language is like quantum mechanics,
[01:09:23.140 --> 01:09:26.940]   so you're still gonna have to do a lot of mess
[01:09:26.940 --> 01:09:31.940]   to universalize it, but I'm trying to see,
[01:09:31.940 --> 01:09:39.140]   so what's your intuition why handwritten recognition
[01:09:39.140 --> 01:09:40.900]   is easier than language?
[01:09:40.900 --> 01:09:45.300]   Just, I think a lot of people would agree with that,
[01:09:45.300 --> 01:09:50.160]   but if you could elucidate sort of the intuition of why.
[01:09:51.780 --> 01:09:56.460]   - I don't, no, no, I don't think in this direction.
[01:09:56.460 --> 01:09:59.560]   I just think in the direction that this is problem,
[01:09:59.560 --> 01:10:05.140]   which if you will solve it well,
[01:10:05.140 --> 01:10:12.740]   we will create some abstract understanding of images.
[01:10:12.740 --> 01:10:19.700]   Maybe not all images.
[01:10:19.700 --> 01:10:24.020]   I would like to talk to guys who doing Unreal images
[01:10:24.020 --> 01:10:26.260]   in Columbia University.
[01:10:26.260 --> 01:10:28.420]   - What kind of images, Unreal?
[01:10:28.420 --> 01:10:29.820]   - Unreal images. - Real images.
[01:10:29.820 --> 01:10:32.340]   - Yeah, what their idea is,
[01:10:32.340 --> 01:10:35.140]   the real predicate, what can be predicate.
[01:10:35.140 --> 01:10:40.140]   I still, symmetry will play a role in real life images,
[01:10:40.140 --> 01:10:43.900]   in any real life images, 2D images,
[01:10:43.900 --> 01:10:46.320]   let's talk about 2D images.
[01:10:46.320 --> 01:10:51.320]   Because that's what we know.
[01:10:51.320 --> 01:10:55.940]   A neural network was created for 2D images.
[01:10:55.940 --> 01:10:58.660]   - So the people I know in vision science, for example,
[01:10:58.660 --> 01:11:01.000]   the people who study human vision,
[01:11:01.000 --> 01:11:04.500]   that they usually go to the world of symbols
[01:11:04.500 --> 01:11:06.360]   and like handwritten recognition,
[01:11:06.360 --> 01:11:08.460]   but not really, it's other kinds of symbols
[01:11:08.460 --> 01:11:11.560]   to study our visual perception system.
[01:11:11.560 --> 01:11:15.180]   As far as I know, not much predicate type of thinking
[01:11:15.180 --> 01:11:17.620]   is understood about our vision system.
[01:11:17.620 --> 01:11:19.420]   - They did not think in this direction.
[01:11:19.420 --> 01:11:21.740]   - They don't, yeah, but how do you even begin
[01:11:21.740 --> 01:11:23.500]   to think in that direction?
[01:11:23.500 --> 01:11:26.900]   - That's, I would like to discuss with them.
[01:11:26.900 --> 01:11:27.740]   - Yeah.
[01:11:27.740 --> 01:11:32.740]   - Because if we will be able to show that it is worth working
[01:11:32.740 --> 01:11:40.340]   and theoretical scheme, it's not so bad.
[01:11:40.340 --> 01:11:43.340]   - So the unfortunate, so if we compare to language,
[01:11:43.340 --> 01:11:46.520]   language is like letters, a finite set of letters
[01:11:46.520 --> 01:11:50.500]   and a finite set of ways you can put together those letters,
[01:11:50.500 --> 01:11:53.720]   so it feels more amenable to kind of analysis.
[01:11:53.720 --> 01:11:58.680]   With natural images, there is so many pixels.
[01:11:58.680 --> 01:12:02.020]   - No, no, no, letter, language is much,
[01:12:02.020 --> 01:12:03.660]   much more complicated.
[01:12:03.660 --> 01:12:08.020]   It's involved a lot of different stuff.
[01:12:08.020 --> 01:12:13.020]   It's not just understanding of very simple class of tasks.
[01:12:14.020 --> 01:12:19.020]   I would like to see lists of tasks with language involved.
[01:12:19.020 --> 01:12:23.220]   - Yes, so there's a lot of nice benchmarks now
[01:12:23.220 --> 01:12:26.480]   in natural language processing from the very trivial,
[01:12:26.480 --> 01:12:30.180]   like understanding the elements of a sentence
[01:12:30.180 --> 01:12:33.060]   to question answering to much more complicated
[01:12:33.060 --> 01:12:36.100]   where you talk about open domain dialogue.
[01:12:36.100 --> 01:12:39.240]   The natural question is with handwritten recognition,
[01:12:39.240 --> 01:12:42.960]   it's really the first step of understanding
[01:12:42.960 --> 01:12:44.600]   visual information.
[01:12:44.600 --> 01:12:49.600]   - Right, but even our records show that we go
[01:12:49.600 --> 01:12:56.580]   in the wrong direction because we need 60,000 digits.
[01:12:56.580 --> 01:12:59.660]   - So even this first step, so forget about talking
[01:12:59.660 --> 01:13:02.580]   about the full journey, this first step should be taken
[01:13:02.580 --> 01:13:03.420]   in the right direction.
[01:13:03.420 --> 01:13:04.540]   - No, no, in the wrong direction
[01:13:04.540 --> 01:13:07.180]   because 60,000 is unacceptable.
[01:13:07.180 --> 01:13:11.020]   - No, I'm saying it should be taken in the right direction
[01:13:11.020 --> 01:13:13.660]   because 60,000 is not acceptable.
[01:13:13.660 --> 01:13:18.480]   - If you can talk, it's great, we have half percent of error.
[01:13:18.480 --> 01:13:22.760]   - And hopefully the step from doing hand recognition
[01:13:22.760 --> 01:13:26.840]   using very few examples, the step towards what babies do
[01:13:26.840 --> 01:13:29.240]   when they crawl and understand their physical environment.
[01:13:29.240 --> 01:13:30.200]   - I don't know what babies do.
[01:13:30.200 --> 01:13:31.760]   - I know you don't know about babies.
[01:13:31.760 --> 01:13:36.080]   - If you will do from very small examples,
[01:13:36.080 --> 01:13:39.560]   you will find principles which are different
[01:13:40.560 --> 01:13:43.080]   from what we're using now.
[01:13:43.080 --> 01:13:48.360]   And theoretically it's more or less clear.
[01:13:48.360 --> 01:13:52.280]   That means that you will use weak convergence,
[01:13:52.280 --> 01:13:54.480]   not just strong convergence.
[01:13:54.480 --> 01:13:59.280]   - Do you think these principles will naturally
[01:13:59.280 --> 01:14:01.680]   be human interpretable?
[01:14:01.680 --> 01:14:02.560]   - Oh yeah.
[01:14:02.560 --> 01:14:04.480]   - So like when we'll be able to explain them
[01:14:04.480 --> 01:14:06.240]   and have a nice presentation to show
[01:14:06.240 --> 01:14:07.600]   what those principles are?
[01:14:07.600 --> 01:14:12.600]   Or are they going to be very kind of abstract
[01:14:12.600 --> 01:14:14.440]   kinds of functions?
[01:14:14.440 --> 01:14:17.680]   - For example, I talked yesterday about symmetry.
[01:14:17.680 --> 01:14:18.720]   - Yes.
[01:14:18.720 --> 01:14:20.440]   - And I gave very simple examples.
[01:14:20.440 --> 01:14:22.040]   The same will be like that.
[01:14:22.040 --> 01:14:24.680]   - You gave like a predicate of a basic for--
[01:14:24.680 --> 01:14:25.760]   - For symmetries.
[01:14:25.760 --> 01:14:29.560]   - Yes, for different symmetries and you have for--
[01:14:29.560 --> 01:14:33.680]   - Degree of symmetry, that is important, not just symmetry.
[01:14:33.680 --> 01:14:36.280]   Existence doesn't exist, degree of symmetry.
[01:14:37.280 --> 01:14:40.240]   - Yeah, for handwritten recognition.
[01:14:40.240 --> 01:14:45.160]   - No, it's not for handwritten, it's for images.
[01:14:45.160 --> 01:14:47.720]   But I would like apply to handwritten.
[01:14:47.720 --> 01:14:49.760]   - Right, in theory it's more general.
[01:14:49.760 --> 01:14:50.920]   Okay, okay.
[01:14:50.920 --> 01:14:59.800]   So a lot of the things we've been talking about falls,
[01:14:59.800 --> 01:15:01.840]   we've been talking about philosophy a little bit,
[01:15:01.840 --> 01:15:05.520]   but also about mathematics and statistics.
[01:15:05.520 --> 01:15:08.080]   A lot of it falls into this idea,
[01:15:08.080 --> 01:15:10.740]   a universal idea of statistical theory of learning.
[01:15:10.740 --> 01:15:16.800]   What is the most beautiful and sort of powerful
[01:15:16.800 --> 01:15:19.120]   or essential idea you've come across,
[01:15:19.120 --> 01:15:20.800]   even just for yourself personally,
[01:15:20.800 --> 01:15:25.480]   in the world of statistics or statistic theory of learning?
[01:15:25.480 --> 01:15:29.520]   - Probably uniform convergence, which we did
[01:15:29.520 --> 01:15:33.000]   with Alexei Cherevonenkis.
[01:15:33.000 --> 01:15:35.040]   - Can you describe universal convergence?
[01:15:36.040 --> 01:15:38.980]   - You have law of large numbers.
[01:15:38.980 --> 01:15:44.480]   So for any function, expectation of function,
[01:15:44.480 --> 01:15:48.120]   average of function, converged expectation.
[01:15:48.120 --> 01:15:50.520]   But if you have set of functions,
[01:15:50.520 --> 01:15:52.340]   for any function it is true.
[01:15:52.340 --> 01:15:55.560]   But it should converge simultaneously
[01:15:55.560 --> 01:15:57.500]   for all set of functions.
[01:15:57.500 --> 01:16:03.600]   And for learning, you need,
[01:16:04.960 --> 01:16:08.540]   uniform convergence, just convergence is not enough.
[01:16:08.540 --> 01:16:15.680]   Because when you pick up one which gives minimum,
[01:16:15.680 --> 01:16:21.660]   you can pick up one function which does not converge
[01:16:21.660 --> 01:16:28.020]   and it will give you the best answer for this function.
[01:16:28.020 --> 01:16:34.920]   So you need uniform convergence to guarantee learning.
[01:16:34.920 --> 01:16:39.920]   So learning does not rely on trivial law of large numbers,
[01:16:39.920 --> 01:16:42.060]   it rely on universal.
[01:16:42.060 --> 01:16:47.960]   But idea of the convergence exists
[01:16:47.960 --> 01:16:50.680]   in statistics for a long time.
[01:16:50.680 --> 01:16:56.860]   But it is interesting that,
[01:16:56.860 --> 01:17:03.920]   as I think about myself, how stupid I was 50 years,
[01:17:04.920 --> 01:17:07.320]   I did not see weak convergence.
[01:17:07.320 --> 01:17:10.960]   I work only on strong convergence.
[01:17:10.960 --> 01:17:15.280]   But now I think that most powerful is weak convergence.
[01:17:15.280 --> 01:17:18.880]   Because it makes admissible set of functions.
[01:17:18.880 --> 01:17:22.720]   And even in all proverbs,
[01:17:22.720 --> 01:17:26.440]   when people try to understand recognition
[01:17:26.440 --> 01:17:30.280]   about dog law, looks like a dog and so on,
[01:17:30.280 --> 01:17:32.400]   they use weak convergence.
[01:17:32.400 --> 01:17:34.600]   People in language, they understand this.
[01:17:34.600 --> 01:17:40.840]   But when we're trying to create artificial intelligence,
[01:17:40.840 --> 01:17:45.080]   we want to invent in different way.
[01:17:45.080 --> 01:17:48.780]   We just consider strong convergence.
[01:17:48.780 --> 01:17:52.720]   - So reducing the set of admissible functions,
[01:17:52.720 --> 01:17:57.720]   you think there should be effort put into
[01:17:57.720 --> 01:18:01.280]   understanding the properties of weak convergence?
[01:18:01.280 --> 01:18:04.760]   - You know, in classical mathematics,
[01:18:04.760 --> 01:18:08.800]   in Gilbert space, there are only two ways,
[01:18:08.800 --> 01:18:12.120]   two forms of convergence, strong and weak.
[01:18:12.120 --> 01:18:15.760]   Now we can use both.
[01:18:15.760 --> 01:18:19.600]   That means that we did everything.
[01:18:19.600 --> 01:18:26.180]   And it so happened, when we use Hilbert space,
[01:18:27.800 --> 01:18:32.000]   which is very rich space, space of continuous functions,
[01:18:32.000 --> 01:18:36.880]   which has an integral and square.
[01:18:36.880 --> 01:18:42.400]   So we can apply weak and strong convergence for learning
[01:18:42.400 --> 01:18:44.200]   and have closed form solution.
[01:18:44.200 --> 01:18:47.680]   So for computationally simple.
[01:18:47.680 --> 01:18:51.080]   For me, it is sign that it is right way.
[01:18:51.080 --> 01:18:55.760]   Because you don't need any heuristic here,
[01:18:55.760 --> 01:18:57.720]   yes, whatever you want.
[01:18:57.720 --> 01:19:02.520]   But now, the only what left,
[01:19:02.520 --> 01:19:04.720]   it is concept of what is predicate.
[01:19:04.720 --> 01:19:05.560]   - Of predicate.
[01:19:05.560 --> 01:19:08.000]   - But it is not statistics.
[01:19:08.000 --> 01:19:09.760]   - By the way, I like the fact that you think
[01:19:09.760 --> 01:19:13.280]   that heuristics are a mess that should be removed
[01:19:13.280 --> 01:19:14.920]   from the system.
[01:19:14.920 --> 01:19:18.480]   So closed form solution is the ultimate--
[01:19:18.480 --> 01:19:20.840]   - No, it so happened, that when you're using
[01:19:20.840 --> 01:19:25.440]   right instrument, you have closed form solution.
[01:19:26.280 --> 01:19:31.280]   - Do you think intelligence, human level intelligence,
[01:19:31.280 --> 01:19:35.760]   when we create it, will have something
[01:19:35.760 --> 01:19:41.400]   like a closed form solution?
[01:19:41.400 --> 01:19:46.400]   - You know, now I'm looking on bones,
[01:19:46.400 --> 01:19:49.560]   which I gave bones for convergence.
[01:19:49.560 --> 01:19:53.040]   And when I looking for bones,
[01:19:53.880 --> 01:19:58.880]   I thinking what is the most appropriate kernel
[01:19:58.880 --> 01:20:01.000]   for this bone would be.
[01:20:01.000 --> 01:20:07.480]   So we know that in, say, all our businesses,
[01:20:07.480 --> 01:20:09.720]   we use radial basis function.
[01:20:09.720 --> 01:20:16.120]   But looking on the bone, I think that I start to understand
[01:20:16.120 --> 01:20:18.800]   that maybe we need to make corrections
[01:20:18.800 --> 01:20:22.640]   to radial basis function to be closer
[01:20:23.640 --> 01:20:28.440]   to work better for this bones.
[01:20:28.440 --> 01:20:32.560]   So I'm again trying to understand what type of kernel
[01:20:32.560 --> 01:20:37.560]   have best approximation,
[01:20:37.560 --> 01:20:42.560]   not an approximation, best fit to this bones.
[01:20:42.560 --> 01:20:45.600]   - Sure, so there's a lot of interesting work
[01:20:45.600 --> 01:20:47.840]   that could be done in discovering better function
[01:20:47.840 --> 01:20:50.120]   than radial basis functions for--
[01:20:50.120 --> 01:20:50.960]   - Yeah, but--
[01:20:50.960 --> 01:20:51.800]   - For the bones you find.
[01:20:52.800 --> 01:20:57.800]   - It still comes from, you're looking to mass
[01:20:57.800 --> 01:21:00.240]   and trying to understand what--
[01:21:00.240 --> 01:21:02.240]   - From your own mind, looking at the--
[01:21:02.240 --> 01:21:03.080]   - Yeah, but--
[01:21:03.080 --> 01:21:03.920]   - I don't know--
[01:21:03.920 --> 01:21:08.920]   - Then I trying to understand what will be good for that.
[01:21:08.920 --> 01:21:14.000]   - Yeah, but to me there's still a beauty,
[01:21:14.000 --> 01:21:16.280]   again, maybe I'm a descendant of valentorian,
[01:21:16.280 --> 01:21:18.000]   to heuristics.
[01:21:18.000 --> 01:21:20.880]   To me, ultimately, intelligence will be
[01:21:20.880 --> 01:21:22.340]   a mess of heuristics.
[01:21:22.340 --> 01:21:26.320]   And that's the engineering answer, I guess.
[01:21:26.320 --> 01:21:27.480]   - Absolutely.
[01:21:27.480 --> 01:21:31.080]   When you're doing, say, self-driving cars,
[01:21:31.080 --> 01:21:35.040]   the great guy who will do that.
[01:21:35.040 --> 01:21:38.640]   It does not matter what theory behind that.
[01:21:38.640 --> 01:21:43.800]   Who has a better feeling have to apply it.
[01:21:43.800 --> 01:21:48.800]   But by the way, it is the same story about predicate.
[01:21:50.420 --> 01:21:53.880]   Because you cannot create rule for,
[01:21:53.880 --> 01:21:56.680]   situation is much more than you have rule for that.
[01:21:56.680 --> 01:22:03.520]   But maybe you can have more abstract rule
[01:22:03.520 --> 01:22:07.740]   than it will be less than zero.
[01:22:07.740 --> 01:22:10.800]   It is the same story about ideas
[01:22:10.800 --> 01:22:15.140]   and ideas applied to specific cases.
[01:22:15.140 --> 01:22:17.360]   - But still you should--
[01:22:17.360 --> 01:22:18.920]   - You cannot avoid this.
[01:22:18.920 --> 01:22:20.880]   - Yes, of course, but you should still reach
[01:22:20.880 --> 01:22:22.920]   for the ideas to understand the science.
[01:22:22.920 --> 01:22:25.280]   - Let me kind of ask,
[01:22:25.280 --> 01:22:29.360]   do you think neural networks or functions
[01:22:29.360 --> 01:22:32.660]   can be made to reason?
[01:22:32.660 --> 01:22:35.520]   Sort of what do you think,
[01:22:35.520 --> 01:22:37.120]   been talking about intelligence,
[01:22:37.120 --> 01:22:39.640]   but this idea of reasoning.
[01:22:39.640 --> 01:22:44.540]   There's an element of sequentially disassembling,
[01:22:44.540 --> 01:22:48.420]   interpreting the images.
[01:22:48.420 --> 01:22:51.860]   So when you think of handwritten recognition,
[01:22:51.860 --> 01:22:55.240]   we kind of think that there'll be a single,
[01:22:55.240 --> 01:22:56.920]   there's an input and output.
[01:22:56.920 --> 01:22:58.640]   There's not a recurrence.
[01:22:58.640 --> 01:23:01.080]   - Yeah.
[01:23:01.080 --> 01:23:04.440]   - What do you think about sort of the idea of recurrence,
[01:23:04.440 --> 01:23:07.480]   of going back to memory and thinking through this sort of
[01:23:07.480 --> 01:23:12.480]   sequentially mangling the different representations
[01:23:12.480 --> 01:23:17.400]   over and over until you arrive at a conclusion?
[01:23:17.940 --> 01:23:22.940]   Or is ultimately all that can be wrapped up into a function?
[01:23:22.940 --> 01:23:28.460]   - You're suggesting that let us use this type of algorithm.
[01:23:28.460 --> 01:23:31.060]   When I starting thinking,
[01:23:31.060 --> 01:23:35.180]   I first of all starting to understand what I want.
[01:23:35.180 --> 01:23:39.560]   Can I write down what I want?
[01:23:39.560 --> 01:23:43.980]   And then I trying to formalize.
[01:23:45.020 --> 01:23:49.260]   And when I do that, I think I have to solve this problem.
[01:23:49.260 --> 01:23:52.980]   And
[01:23:52.980 --> 01:24:02.380]   till now I did not see a situation where--
[01:24:02.380 --> 01:24:03.700]   - You need recurrence.
[01:24:03.700 --> 01:24:04.540]   - Recurrence.
[01:24:04.540 --> 01:24:07.860]   - But do you observe human beings?
[01:24:07.860 --> 01:24:08.700]   - Yeah.
[01:24:08.700 --> 01:24:12.420]   - Do you try to, it's the imitation question, right?
[01:24:12.420 --> 01:24:14.900]   It seems that human beings reason
[01:24:14.900 --> 01:24:19.620]   this kind of sequentially sort of,
[01:24:19.620 --> 01:24:24.140]   does that inspire in you a thought that we need to add that
[01:24:24.140 --> 01:24:29.000]   into our intelligent systems?
[01:24:29.000 --> 01:24:34.440]   You're saying, okay, I mean, you've kind of answered saying
[01:24:34.440 --> 01:24:37.040]   until now I haven't seen a need for it.
[01:24:37.040 --> 01:24:38.500]   And so because of that,
[01:24:38.500 --> 01:24:40.980]   you don't see a reason to think about it.
[01:24:41.900 --> 01:24:44.980]   - No, most of things I don't understand.
[01:24:44.980 --> 01:24:50.860]   In reasoning, in human, it is for me too complicated.
[01:24:50.860 --> 01:24:57.740]   For me, the most difficult part is to ask questions,
[01:24:57.740 --> 01:25:03.900]   good questions, how it works,
[01:25:03.900 --> 01:25:06.820]   how people asking questions.
[01:25:06.820 --> 01:25:10.100]   I don't know this.
[01:25:11.720 --> 01:25:13.640]   - You said that machine learning's not only
[01:25:13.640 --> 01:25:16.500]   about technical things, speaking of questions,
[01:25:16.500 --> 01:25:18.220]   but it's also about philosophy.
[01:25:18.220 --> 01:25:23.500]   So what role does philosophy play in machine learning?
[01:25:23.500 --> 01:25:26.860]   We talked about Plato, but generally thinking
[01:25:26.860 --> 01:25:29.980]   in this philosophical way,
[01:25:29.980 --> 01:25:33.860]   does it have, how does philosophy and math
[01:25:33.860 --> 01:25:35.240]   fit together in your mind?
[01:25:35.240 --> 01:25:39.500]   - So studies and then their implementation.
[01:25:39.500 --> 01:25:44.500]   It's like predicate, like say admissible set of functions.
[01:25:44.500 --> 01:25:51.480]   It comes together, everything.
[01:25:51.480 --> 01:25:56.480]   Because the first iteration of theory
[01:25:56.480 --> 01:26:00.400]   was done 50 years ago, it all that, this is theory.
[01:26:00.400 --> 01:26:02.240]   So everything's there.
[01:26:02.240 --> 01:26:06.920]   If you have data, you can, and your set of function
[01:26:08.080 --> 01:26:13.080]   is not, has not big capacity.
[01:26:13.080 --> 01:26:15.760]   So low VC dimension, you can do that.
[01:26:15.760 --> 01:26:19.700]   You can make structural risk minimization, control capacity.
[01:26:19.700 --> 01:26:26.120]   But you was not able to make admissible
[01:26:26.120 --> 01:26:27.980]   set of function good.
[01:26:27.980 --> 01:26:33.680]   Now, when suddenly realize that we did not use
[01:26:33.680 --> 01:26:37.260]   another idea of convergence, which we can,
[01:26:38.260 --> 01:26:41.500]   everything comes together.
[01:26:41.500 --> 01:26:43.340]   - But those are mathematical notions.
[01:26:43.340 --> 01:26:48.020]   Philosophy plays a role of simply saying
[01:26:48.020 --> 01:26:52.100]   that we should be swimming in the space of ideas.
[01:26:52.100 --> 01:26:54.320]   - Let's talk what is philosophy.
[01:26:54.320 --> 01:26:56.860]   Philosophy means understanding of life.
[01:26:56.860 --> 01:27:03.100]   So understanding of life, say people like Plato,
[01:27:03.500 --> 01:27:06.800]   they understand on very high abstract level of life.
[01:27:06.800 --> 01:27:12.660]   So, and whatever I doing, it just implementation
[01:27:12.660 --> 01:27:15.660]   of my understanding of life.
[01:27:15.660 --> 01:27:21.360]   But every new step, it is very difficult.
[01:27:21.360 --> 01:27:27.460]   For example, to find this idea that we need
[01:27:31.580 --> 01:27:36.580]   big convergence was not simple for me.
[01:27:36.580 --> 01:27:43.260]   - So that required thinking about life a little bit.
[01:27:43.260 --> 01:27:48.860]   Hard to trace, but there was some thought process.
[01:27:48.860 --> 01:27:52.980]   - You know, I working, I thinking about the same problem
[01:27:52.980 --> 01:27:55.420]   for 50 years or more.
[01:27:55.420 --> 01:27:58.780]   And again and again and again.
[01:28:00.020 --> 01:28:02.660]   I trying to be honest and that is very important.
[01:28:02.660 --> 01:28:06.340]   Not to be very enthusiastic, but concentrate
[01:28:06.340 --> 01:28:09.460]   on whatever we was not able to achieve.
[01:28:09.460 --> 01:28:10.300]   - Patient.
[01:28:10.300 --> 01:28:11.140]   - Yeah.
[01:28:11.140 --> 01:28:13.360]   And understand why.
[01:28:13.360 --> 01:28:18.900]   And now I understand that because I believe in math,
[01:28:18.900 --> 01:28:23.740]   I believe that in Wigner's idea.
[01:28:23.740 --> 01:28:28.740]   But now when I see that there are only two way
[01:28:28.740 --> 01:28:32.060]   of convergence and we using both,
[01:28:32.060 --> 01:28:37.940]   that means that we must do as well as people doing.
[01:28:37.940 --> 01:28:44.340]   But now exactly in philosophy and what we know
[01:28:44.340 --> 01:28:47.020]   about predicate, how we understand life,
[01:28:47.020 --> 01:28:50.100]   can we describe as a predicate.
[01:28:50.100 --> 01:28:56.420]   I thought about that and that is more or less obvious.
[01:28:57.820 --> 01:28:59.020]   Level of symmetry.
[01:28:59.020 --> 01:29:05.740]   But next, I have a feeling it's something about structures.
[01:29:05.740 --> 01:29:11.820]   But I don't know how to formulate,
[01:29:11.820 --> 01:29:16.180]   how to measure measure of structure and all that stuff.
[01:29:16.180 --> 01:29:21.180]   And the guy who will solve this challenge problem,
[01:29:21.180 --> 01:29:25.340]   then when we will looking how he did it,
[01:29:27.060 --> 01:29:30.340]   probably just only symmetry is not enough.
[01:29:30.340 --> 01:29:34.180]   - But something like symmetry will be there.
[01:29:34.180 --> 01:29:37.580]   - Oh yeah, absolutely, symmetry will be there.
[01:29:37.580 --> 01:29:39.260]   Level of symmetry will be there.
[01:29:39.260 --> 01:29:43.020]   And level of symmetry, anti-symmetry,
[01:29:43.020 --> 01:29:48.020]   diagonal, vertical, I even don't know how you can use
[01:29:48.020 --> 01:29:50.660]   in different direction idea of symmetry,
[01:29:50.660 --> 01:29:52.300]   it's very general.
[01:29:52.300 --> 01:29:53.460]   But it will be there.
[01:29:54.940 --> 01:29:58.580]   I think that people are very sensitive to idea of symmetry.
[01:29:58.580 --> 01:30:02.940]   But there are several ideas like symmetry.
[01:30:02.940 --> 01:30:07.020]   As I would like to learn.
[01:30:07.020 --> 01:30:11.820]   But you cannot learn just thinking about that.
[01:30:11.820 --> 01:30:15.500]   You should do challenging problems and then analyze them,
[01:30:15.500 --> 01:30:20.220]   why it was able to solve them.
[01:30:20.220 --> 01:30:21.380]   And then you will see.
[01:30:22.740 --> 01:30:25.420]   Very simple things, it's not easy to find.
[01:30:25.420 --> 01:30:30.460]   Even with talking about this every time.
[01:30:30.460 --> 01:30:36.340]   I was surprised, I tried to understand.
[01:30:36.340 --> 01:30:41.340]   Is people describe in language strong convergence
[01:30:41.340 --> 01:30:43.260]   mechanism for learning?
[01:30:43.260 --> 01:30:46.660]   I did not see, I don't know.
[01:30:46.660 --> 01:30:50.100]   But weak convergence, this dark story,
[01:30:50.100 --> 01:30:54.700]   and story like that, when you will explain to kid,
[01:30:54.700 --> 01:30:57.620]   you will use weak convergence argument.
[01:30:57.620 --> 01:30:59.420]   It looks like it does like this.
[01:30:59.420 --> 01:31:05.820]   But when you try to formalize, you're just ignoring this.
[01:31:05.820 --> 01:31:10.140]   Why, why 50 years from start of machine learning?
[01:31:10.140 --> 01:31:11.580]   - And that's the role of philosophers.
[01:31:11.580 --> 01:31:16.020]   - I think that might be, I don't know.
[01:31:18.300 --> 01:31:19.980]   Maybe this is serious.
[01:31:19.980 --> 01:31:23.660]   We should blame for that because
[01:31:23.660 --> 01:31:27.740]   empirical risk minimization, and all this stuff.
[01:31:27.740 --> 01:31:32.500]   If you read now textbooks, they just about bound
[01:31:32.500 --> 01:31:34.380]   about empirical risk minimization.
[01:31:34.380 --> 01:31:39.380]   They don't look for another problem like admissible set.
[01:31:39.380 --> 01:31:43.940]   - But on the topic of life,
[01:31:45.060 --> 01:31:50.020]   perhaps we, you could talk in Russian for a little bit.
[01:31:50.020 --> 01:31:53.260]   What's your favorite memory from childhood?
[01:31:53.260 --> 01:31:57.700]   (speaking in foreign language)
[01:31:57.700 --> 01:31:58.540]   - Music.
[01:31:58.540 --> 01:32:02.660]   - How about, can you try to answer in Russian?
[01:32:02.660 --> 01:32:06.580]   (speaking in foreign language)
[01:32:07.580 --> 01:32:11.500]   (speaking in foreign language)
[01:32:11.860 --> 01:32:15.780]   (speaking in foreign language)
[01:32:15.900 --> 01:32:19.820]   (speaking in foreign language)
[01:32:20.660 --> 01:32:24.580]   (speaking in foreign language)
[01:32:24.580 --> 01:32:28.500]   (speaking in foreign language)
[01:32:29.100 --> 01:32:33.020]   (speaking in foreign language)
[01:32:33.020 --> 01:32:36.940]   (speaking in foreign language)
[01:32:37.900 --> 01:32:41.820]   (speaking in foreign language)
[01:33:05.580 --> 01:33:09.500]   (speaking in foreign language)
[01:33:09.500 --> 01:33:13.100]   Now that we're talking about Bach,
[01:33:13.100 --> 01:33:15.700]   let's switch back to English
[01:33:15.700 --> 01:33:17.740]   'cause I like Beethoven and Chopin, so.
[01:33:17.740 --> 01:33:21.340]   - Chopin, it's another music story.
[01:33:21.340 --> 01:33:23.980]   - But Bach, if we talk about predicates,
[01:33:23.980 --> 01:33:28.980]   Bach probably has the most sort of
[01:33:28.980 --> 01:33:31.500]   well-defined predicates and the like.
[01:33:31.500 --> 01:33:35.260]   - You know, it is very interesting to read
[01:33:35.260 --> 01:33:38.740]   what critics writing about Bach,
[01:33:38.740 --> 01:33:40.460]   which words they're using.
[01:33:40.460 --> 01:33:42.860]   They're trying to describe predicates.
[01:33:42.860 --> 01:33:50.820]   And then Chopin, it is very different vocabulary,
[01:33:50.820 --> 01:33:55.140]   very different predicates.
[01:33:55.140 --> 01:34:00.140]   And I think that if you will make collection of that,
[01:34:02.700 --> 01:34:05.860]   so maybe from this you can describe predicates
[01:34:05.860 --> 01:34:07.660]   for digit recognition as well.
[01:34:07.660 --> 01:34:10.420]   - From Bach and Chopin.
[01:34:10.420 --> 01:34:12.500]   - No, no, no, not from Bach and Chopin.
[01:34:12.500 --> 01:34:15.220]   - From the critic interpretation of the music, yeah.
[01:34:15.220 --> 01:34:18.620]   - When they're trying to explain music,
[01:34:18.620 --> 01:34:24.740]   what they use, they describe high-level ideas
[01:34:24.740 --> 01:34:28.860]   of Plato's ideas, what behind this music.
[01:34:28.860 --> 01:34:29.700]   - That's brilliant.
[01:34:29.700 --> 01:34:34.700]   So art is not self-explanatory in some sense.
[01:34:34.700 --> 01:34:39.060]   So you have to try to convert it into ideas.
[01:34:39.060 --> 01:34:40.980]   - It is ill-posed problems.
[01:34:40.980 --> 01:34:45.980]   When you go from ideas to the representation,
[01:34:45.980 --> 01:34:47.580]   it is easy way.
[01:34:47.580 --> 01:34:49.580]   But when you're trying to go back,
[01:34:49.580 --> 01:34:51.420]   it is ill-posed problems.
[01:34:51.420 --> 01:34:55.860]   But nevertheless, I believe that when you're looking
[01:34:55.860 --> 01:35:00.300]   from that, even from art, you will be able to find
[01:35:00.300 --> 01:35:02.060]   predicates for digit recognition.
[01:35:02.060 --> 01:35:07.620]   - That's such a fascinating and powerful notion.
[01:35:07.620 --> 01:35:10.580]   Do you ponder your own mortality?
[01:35:10.580 --> 01:35:13.620]   Do you think about it, do you fear it,
[01:35:13.620 --> 01:35:15.060]   do you draw insight from it?
[01:35:15.060 --> 01:35:18.220]   - About mortality?
[01:35:18.220 --> 01:35:20.620]   No, yeah.
[01:35:20.620 --> 01:35:22.820]   - Are you afraid of death?
[01:35:25.820 --> 01:35:26.900]   - Not too much.
[01:35:26.900 --> 01:35:29.660]   Not too much.
[01:35:29.660 --> 01:35:33.740]   It is pity that I will not be able to do something
[01:35:33.740 --> 01:35:38.740]   which I think I have a feeling to do that.
[01:35:38.740 --> 01:35:44.460]   For example, I will be very happy to work with guys,
[01:35:44.460 --> 01:35:52.060]   theoretician from music, to write this collection
[01:35:52.060 --> 01:35:55.060]   of description, how they describe music,
[01:35:55.060 --> 01:35:56.940]   how they use the predicate.
[01:35:56.940 --> 01:36:01.940]   And from art as well, then take what is in common
[01:36:01.940 --> 01:36:06.180]   and try to understand predicate,
[01:36:06.180 --> 01:36:08.700]   which is absolute for everything.
[01:36:08.700 --> 01:36:10.500]   - And then use that for visual recognition,
[01:36:10.500 --> 01:36:12.620]   see if there is a connection.
[01:36:12.620 --> 01:36:13.580]   - Exactly.
[01:36:13.580 --> 01:36:15.580]   - Ada, there's still time, we got time.
[01:36:15.580 --> 01:36:19.380]   (laughing)
[01:36:19.380 --> 01:36:20.220]   We got time.
[01:36:20.220 --> 01:36:24.060]   - It takes years and years and years.
[01:36:24.060 --> 01:36:25.060]   - I think so.
[01:36:25.060 --> 01:36:26.460]   - It's a long way.
[01:36:26.460 --> 01:36:30.900]   - Well, see, you've got the patient mathematicians mind.
[01:36:30.900 --> 01:36:34.060]   I think it could be done very quickly and very beautifully.
[01:36:34.060 --> 01:36:35.820]   I think it's a really elegant idea.
[01:36:35.820 --> 01:36:36.940]   - Yeah, but also--
[01:36:36.940 --> 01:36:37.780]   - Some of many.
[01:36:37.780 --> 01:36:41.900]   - You know, the most time, it is not to make
[01:36:41.900 --> 01:36:46.260]   this collection, to understand what is common
[01:36:46.260 --> 01:36:49.500]   to think about that once again and again and again.
[01:36:49.500 --> 01:36:52.660]   - Again and again and again, but I think sometimes,
[01:36:52.660 --> 01:36:55.700]   especially just when you say this idea now,
[01:36:55.700 --> 01:36:58.780]   even just putting together the collection
[01:36:58.780 --> 01:37:03.300]   and looking at the different sets of data,
[01:37:03.300 --> 01:37:05.500]   language, trying to interpret music,
[01:37:05.500 --> 01:37:08.740]   criticize music, and images,
[01:37:08.740 --> 01:37:10.940]   I think there'll be sparks of ideas that'll come.
[01:37:10.940 --> 01:37:12.660]   Of course, again and again, you'll come up
[01:37:12.660 --> 01:37:15.820]   with better ideas, but even just that notion
[01:37:15.820 --> 01:37:16.940]   is a beautiful notion.
[01:37:16.940 --> 01:37:19.300]   - I even have some example.
[01:37:21.580 --> 01:37:26.580]   So I have friend who was specialist in Russian poetry.
[01:37:26.580 --> 01:37:35.260]   She is professor of Russian poetry.
[01:37:35.260 --> 01:37:40.260]   He did not write poems, but she know a lot of stuff.
[01:37:40.260 --> 01:37:48.300]   She make book, several books, and one of them
[01:37:49.300 --> 01:37:53.500]   is a collection of Russian poetry.
[01:37:53.500 --> 01:37:57.100]   She have images of Russian poetry.
[01:37:57.100 --> 01:37:59.340]   She collect all images of Russian poetry.
[01:37:59.340 --> 01:38:03.420]   And I ask her to do following.
[01:38:03.420 --> 01:38:08.500]   You have NIPS, digit recognition,
[01:38:08.500 --> 01:38:14.660]   and we get 100 digits, or maybe less than 100.
[01:38:14.660 --> 01:38:17.420]   I don't remember, maybe 50 digits.
[01:38:18.860 --> 01:38:21.660]   And try from poetical point of view,
[01:38:21.660 --> 01:38:25.260]   describe every image which she see,
[01:38:25.260 --> 01:38:30.260]   using only words of images of Russian poetry.
[01:38:30.260 --> 01:38:32.220]   And she did it.
[01:38:32.220 --> 01:38:37.580]   And then we tried to,
[01:38:37.580 --> 01:38:43.620]   I call it learning using privileged information.
[01:38:43.620 --> 01:38:45.900]   I call it privileged information.
[01:38:45.900 --> 01:38:48.060]   You have on two languages.
[01:38:48.060 --> 01:38:53.060]   One language is just image of digit,
[01:38:53.060 --> 01:38:56.620]   and another language poetic description of this image.
[01:38:56.620 --> 01:39:00.060]   And this is privileged information.
[01:39:00.060 --> 01:39:04.500]   And there is a algorithm when you're working
[01:39:04.500 --> 01:39:07.460]   using privileged information, you're doing better.
[01:39:07.460 --> 01:39:10.380]   Much better, so.
[01:39:10.380 --> 01:39:11.580]   - So there's something there.
[01:39:11.580 --> 01:39:12.860]   - Something there.
[01:39:12.860 --> 01:39:15.980]   And there is, and you see,
[01:39:16.980 --> 01:39:19.020]   she unfortunately died.
[01:39:19.020 --> 01:39:25.900]   The collection of digits in poetic descriptions
[01:39:25.900 --> 01:39:27.260]   of these digits.
[01:39:27.260 --> 01:39:32.900]   - So there's something there in that poetic description.
[01:39:32.900 --> 01:39:37.900]   - But I think that there is an abstract ideas
[01:39:37.900 --> 01:39:40.700]   on the plateau level of ideas.
[01:39:40.700 --> 01:39:43.140]   - Yeah, that they're there, that could be discovered.
[01:39:43.140 --> 01:39:44.820]   And music seems to be a good entry point.
[01:39:45.060 --> 01:39:50.060]   - As soon as we start this challenge problem.
[01:39:50.060 --> 01:39:51.180]   - The challenge problem.
[01:39:51.180 --> 01:39:55.420]   - It immediately connected to all this stuff.
[01:39:55.420 --> 01:39:58.060]   - Especially with your talk and this podcast,
[01:39:58.060 --> 01:40:00.100]   and I'll do whatever I can to advertise it.
[01:40:00.100 --> 01:40:03.260]   It's such a clean, beautiful Einstein-like formulation
[01:40:03.260 --> 01:40:05.220]   of the challenge before us.
[01:40:05.220 --> 01:40:06.060]   - Right.
[01:40:06.060 --> 01:40:09.500]   - Let me ask another absurd question.
[01:40:09.500 --> 01:40:12.780]   We talked about mortality.
[01:40:12.780 --> 01:40:14.660]   We talked about philosophy of life.
[01:40:14.660 --> 01:40:16.660]   What do you think is the meaning of life?
[01:40:16.660 --> 01:40:22.540]   What's the predicate for mysterious existence
[01:40:22.540 --> 01:40:23.980]   here on Earth?
[01:40:23.980 --> 01:40:30.580]   - I don't know.
[01:40:30.580 --> 01:40:34.740]   It's very interesting.
[01:40:34.740 --> 01:40:39.980]   We have in Russia, I don't know if you know,
[01:40:39.980 --> 01:40:42.100]   the guy Strugatsky.
[01:40:43.100 --> 01:40:47.860]   They are writing pictures, they're thinking about
[01:40:47.860 --> 01:40:49.740]   human, what's going on.
[01:40:49.740 --> 01:40:56.660]   And they have idea that there are,
[01:40:56.660 --> 01:41:01.860]   they're developing two type of people.
[01:41:01.860 --> 01:41:05.100]   Common people and very smart people.
[01:41:05.100 --> 01:41:06.100]   They just started.
[01:41:06.100 --> 01:41:09.860]   And these two branches of people
[01:41:09.860 --> 01:41:12.180]   will go in different direction very soon.
[01:41:13.180 --> 01:41:15.940]   So that's what they're thinking about.
[01:41:15.940 --> 01:41:18.220]   (laughing)
[01:41:18.220 --> 01:41:23.220]   - So the purpose of life is to create two paths.
[01:41:23.220 --> 01:41:24.660]   - Two paths.
[01:41:24.660 --> 01:41:25.980]   - Of human societies.
[01:41:25.980 --> 01:41:27.020]   - Yes.
[01:41:27.020 --> 01:41:29.980]   Simple people and more complicated people.
[01:41:29.980 --> 01:41:31.540]   - Which do you like best?
[01:41:31.540 --> 01:41:34.500]   The simple people or the complicated ones?
[01:41:34.500 --> 01:41:35.340]   - I don't know.
[01:41:35.340 --> 01:41:38.260]   That is just his fantasy.
[01:41:38.260 --> 01:41:41.700]   But you know, every week we have guy
[01:41:41.700 --> 01:41:46.700]   who is just writer and also
[01:41:46.700 --> 01:41:50.820]   so it's called literature.
[01:41:50.820 --> 01:41:56.580]   And he explain how he understand literature
[01:41:56.580 --> 01:42:00.300]   and human relationship, how he see life.
[01:42:00.300 --> 01:42:05.980]   And I understood that I'm just small kids
[01:42:05.980 --> 01:42:08.100]   comparing to him.
[01:42:09.500 --> 01:42:12.620]   He's very smart guy in understanding life.
[01:42:12.620 --> 01:42:18.860]   He knows this predicate, he knows big blocks of life.
[01:42:18.860 --> 01:42:23.300]   I amused every time when I listen to him.
[01:42:23.300 --> 01:42:27.380]   And he just talking about literature.
[01:42:27.380 --> 01:42:31.380]   And I think that I was surprised.
[01:42:31.380 --> 01:42:38.180]   So the managers in big companies,
[01:42:39.180 --> 01:42:44.180]   most of them are guys who study English language
[01:42:44.180 --> 01:42:50.020]   in English literature.
[01:42:50.020 --> 01:42:52.500]   So why?
[01:42:52.500 --> 01:42:54.820]   Because they understand life.
[01:42:54.820 --> 01:42:57.020]   They understand models.
[01:42:57.020 --> 01:43:01.700]   And among them, maybe many talented critics
[01:43:01.700 --> 01:43:06.660]   which just analyzing this.
[01:43:06.660 --> 01:43:10.500]   And this is big science like probe did.
[01:43:10.500 --> 01:43:12.380]   This is blocks.
[01:43:12.380 --> 01:43:15.340]   Yeah, very smart.
[01:43:15.340 --> 01:43:21.500]   - It amazes me that you are and continue to be humbled
[01:43:21.500 --> 01:43:22.940]   by the brilliance of others.
[01:43:22.940 --> 01:43:25.540]   - I'm very modest about myself.
[01:43:25.540 --> 01:43:28.940]   I see so smart guys around.
[01:43:28.940 --> 01:43:31.740]   - Well, let me be immodest for you.
[01:43:31.740 --> 01:43:33.900]   You're one of the greatest mathematicians,
[01:43:33.900 --> 01:43:35.820]   statisticians of our time.
[01:43:35.820 --> 01:43:36.980]   It's truly an honor.
[01:43:36.980 --> 01:43:38.580]   Thank you for talking again.
[01:43:38.580 --> 01:43:39.500]   And let's talk.
[01:43:39.500 --> 01:43:42.140]   - It is not.
[01:43:42.140 --> 01:43:43.460]   - Yeah, let's talk.
[01:43:43.460 --> 01:43:44.860]   - I know my limits.
[01:43:44.860 --> 01:43:49.140]   - Let's talk again when your challenge is taken on
[01:43:49.140 --> 01:43:51.860]   and solved by grad student.
[01:43:51.860 --> 01:43:53.900]   Especially-- - Let's talk again.
[01:43:53.900 --> 01:43:56.140]   - When they use it. - I hope this happens.
[01:43:56.140 --> 01:43:58.900]   - Maybe music will be involved.
[01:43:58.900 --> 01:43:59.900]   Vladimir, thank you so much.
[01:43:59.900 --> 01:44:02.620]   It's been an honor. - Thank you very much.
[01:44:02.620 --> 01:44:04.220]   - Thanks for listening to this conversation
[01:44:04.220 --> 01:44:05.540]   with Vladimir Vapnik.
[01:44:05.540 --> 01:44:08.780]   And thank you to our presenting sponsor, Cash App.
[01:44:08.780 --> 01:44:11.420]   Download it, use code LEXPODCAST.
[01:44:11.420 --> 01:44:14.340]   You'll get $10 and $10 will go to FIRST,
[01:44:14.340 --> 01:44:17.060]   an organization that inspires and educates young minds
[01:44:17.060 --> 01:44:20.740]   to become science and technology innovators of tomorrow.
[01:44:20.740 --> 01:44:23.500]   If you enjoy this podcast, subscribe on YouTube,
[01:44:23.500 --> 01:44:25.340]   give us five stars on Apple Podcast,
[01:44:25.340 --> 01:44:28.820]   support on Patreon, or simply connect with me on Twitter
[01:44:28.820 --> 01:44:30.300]   at Lex Friedman.
[01:44:30.300 --> 01:44:33.500]   And now let me leave you with some words
[01:44:33.500 --> 01:44:34.860]   from Vladimir Vapnik.
[01:44:35.580 --> 01:44:37.740]   When solving a problem of interest,
[01:44:37.740 --> 01:44:41.660]   do not solve a more general problem as an intermediate step.
[01:44:41.660 --> 01:44:44.340]   Thank you for listening.
[01:44:44.340 --> 01:44:46.220]   I hope to see you next time.
[01:44:46.220 --> 01:44:48.820]   (upbeat music)
[01:44:48.820 --> 01:44:51.420]   (upbeat music)
[01:44:51.420 --> 01:45:01.420]   [BLANK_AUDIO]

