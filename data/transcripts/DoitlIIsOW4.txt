
[00:00:00.000 --> 00:00:07.140]   So the period 1820 to 1900, it only takes 87 years to double GDP.
[00:00:07.140 --> 00:00:10.940]   And then 1900 to 1950, only 60 years.
[00:00:10.940 --> 00:00:18.700]   And by the time you get to the year 2000, we're doubling global GDP every 20 to 30 years.
[00:00:18.700 --> 00:00:37.980]   What have earnings compounded at for tech versus non-tech?
[00:00:37.980 --> 00:00:42.540]   And what have stock prices compounded at at tech versus non-tech?
[00:00:42.540 --> 00:00:45.740]   Technology companies have compounded earnings at 13%.
[00:00:45.740 --> 00:00:48.280]   Their stock prices have compounded at 17%.
[00:00:48.280 --> 00:00:51.540]   So a little bit faster than earnings have compounded.
[00:00:51.540 --> 00:00:56.460]   But if you look at non-tech, they've only compounded earnings at about 6%.
[00:00:56.460 --> 00:01:00.180]   Their stock prices have grown at about 8%.
[00:01:00.180 --> 00:01:06.260]   Technology has gone from 5% of global GDP to 15% over the course of the last 15 years.
[00:01:06.260 --> 00:01:10.460]   When we have this conversation five or 10 years now, is tech going to be more or less
[00:01:10.460 --> 00:01:12.820]   than 15% of global GDP?
[00:01:12.820 --> 00:01:15.380]   By the grace of God, Apple was created here.
[00:01:15.380 --> 00:01:18.580]   Google was created here, Microsoft was created here, Meadow was created here.
[00:01:18.580 --> 00:01:22.100]   It is not a given that in 20 years from now, those companies will be created here.
[00:01:22.100 --> 00:01:26.660]   Why not just like seal that and lock that in as a monopoly and get all of that talent
[00:01:26.660 --> 00:01:27.660]   here?
[00:01:27.660 --> 00:01:32.940]   And the thing that is crazy to me is that US companies are currently employing all of
[00:01:32.940 --> 00:01:34.740]   the people we're talking about moving here.
[00:01:34.740 --> 00:01:36.860]   They're just employing them in a different country.
[00:01:36.860 --> 00:01:42.380]   Would you rather have an assistant with the intelligence of like Einstein, but they have
[00:01:42.380 --> 00:01:46.620]   no access to the internet and they don't know anything about your history?
[00:01:46.620 --> 00:01:51.260]   Or would you like to have an assistant that's just above average intelligence, knows everything
[00:01:51.260 --> 00:01:54.060]   about you, and they can use the internet?
[00:01:54.060 --> 00:01:55.060]   You would choose that.
[00:01:55.060 --> 00:02:00.320]   I think that is another 10x moment that's in front of us, which is we go from answers
[00:02:00.320 --> 00:02:03.260]   where I'm just asking for information to actions.
[00:02:03.260 --> 00:02:09.340]   And once it can start booking my hotel, booking, reserving my restaurant, and then I just say
[00:02:09.340 --> 00:02:11.740]   same thing, do it again.
[00:02:11.740 --> 00:02:16.700]   And over the course of the next four to five years, we'll have 2 trillion of data centers
[00:02:16.700 --> 00:02:22.180]   powering software around the world, and it will all be accelerated compute.
[00:02:22.180 --> 00:02:25.500]   So this is the AI data center build out.
[00:02:25.500 --> 00:02:29.520]   In blue is the new accelerated compute.
[00:02:29.520 --> 00:02:35.780]   In green is the replacement data center that we think will go to accelerated.
[00:02:35.780 --> 00:02:39.560]   And then in gray is the replacement that's non-accelerated compute.
[00:02:39.560 --> 00:02:43.020]   So this would be more like, you know, x86.
[00:02:43.020 --> 00:02:49.900]   I would make the argument that every company in Delaware has to move to a different domicile
[00:02:49.900 --> 00:02:56.300]   because they could be sued in a future derivative law suit for the risk they've taken by staying
[00:02:56.300 --> 00:02:57.300]   in Delaware.
[00:02:57.300 --> 00:02:59.300]   Oh my God, you're so right.
[00:02:59.300 --> 00:03:05.100]   A dollar of stock-based compensation is actually, not only should it not be ignored, it's the
[00:03:05.100 --> 00:03:07.500]   most single valuable expense.
[00:03:07.500 --> 00:03:13.640]   We even have a court criticizing Elon for taking an options package where he made no
[00:03:13.640 --> 00:03:17.220]   money unless he saved the company from bankruptcy.
[00:03:17.220 --> 00:03:22.660]   Meanwhile, the CEO of his arch rival, who created no shareholder value over a period
[00:03:22.660 --> 00:03:27.000]   of five years, is making tens of millions of dollars a year in RSUs.
[00:03:27.000 --> 00:03:33.660]   If you give one share of a restricted stock unit at a value of 20, then the recipient
[00:03:33.660 --> 00:03:36.140]   has $20 of value.
[00:03:36.140 --> 00:03:42.100]   Now if the stock happens to go down by 50%, the employee still has $10 of value.
[00:03:42.100 --> 00:03:47.460]   Whereas in the case of the stock option, if it goes down 1%, yet alone 50, it has zero
[00:03:47.460 --> 00:03:48.460]   value.
[00:03:48.460 --> 00:03:50.420]   I like to take a hot shower.
[00:03:50.420 --> 00:03:57.000]   But if the cost of that was $100,000, right, not many people would take hot showers.
[00:03:57.000 --> 00:04:03.360]   But he's saying that if you drive down the price of the cost of compute, then the reflexivity
[00:04:03.360 --> 00:04:05.940]   is people will consume a lot more of it.
[00:04:05.940 --> 00:04:09.900]   Now, this is also known as the Jevons paradox, right?
[00:04:09.900 --> 00:04:13.660]   As price goes down, we demand more of it.
[00:04:13.660 --> 00:04:20.380]   The aggregate amount of consumed, of the compute consumed, actually goes up, right?
[00:04:20.380 --> 00:04:26.020]   And that's really, you know, just a fancy way of talking about the elasticity of demand.
[00:04:26.020 --> 00:04:32.660]   If you're public with $100 million in revenue and a 10% growth rate, your valuation's not
[00:04:32.660 --> 00:04:33.940]   going to be all that great.
[00:04:33.940 --> 00:04:34.940]   But guess what?
[00:04:34.940 --> 00:04:39.660]   If you're private at $100 million in revenue with a 10% growth rate, it's not like you're
[00:04:39.660 --> 00:04:43.540]   better off, like you're just fooling yourself.
[00:04:43.540 --> 00:04:50.660]   Elon is building a much, much bigger cluster to train a much, much bigger model as is OpenAI,
[00:04:50.660 --> 00:04:51.660]   as is Zuckerberg.
[00:04:51.660 --> 00:04:52.660]   I mean...
[00:04:52.660 --> 00:04:55.100]   What Sam just said, the bigger models aren't the problem.
[00:04:55.100 --> 00:04:58.980]   Well, I mean, he may be doing the same game that everybody else is doing, Bill, and trying
[00:04:58.980 --> 00:05:00.940]   to throw everybody off the scent.
[00:05:00.940 --> 00:05:06.620]   Dario and Sam talk in these high-level platitudes about how this stuff's going to cure cancer
[00:05:06.620 --> 00:05:09.900]   and we're all going to not have to work anymore.
[00:05:09.900 --> 00:05:12.220]   And Zuck was down in the weeds in the meat.
[00:05:12.220 --> 00:05:13.380]   He's in the arena.
[00:05:13.380 --> 00:05:15.420]   Yeah, being super transparent.
[00:05:15.420 --> 00:05:18.940]   And I was just like, holy shit, maybe this guy's in charge now.
[00:05:18.940 --> 00:05:20.900]   Hey, man, great to see you.
[00:05:20.900 --> 00:05:24.860]   That was fun to take some of your money in Vegas this past weekend.
[00:05:24.860 --> 00:05:27.040]   I can't believe you're bringing that up.
[00:05:27.040 --> 00:05:30.540]   This is classic, you know, freshman economics.
[00:05:30.540 --> 00:05:33.940]   If someone's better at doing something than us, we should let them do it.
[00:05:33.940 --> 00:05:36.860]   We should buy it from them and we should send them what we're good at.
[00:05:36.860 --> 00:05:37.860]   It's interesting.
[00:05:37.860 --> 00:05:41.540]   We end up talking about AI every week, but I don't know what there is else to talk about
[00:05:41.540 --> 00:05:43.980]   because that's all anyone's talking about.
[00:05:43.980 --> 00:05:48.620]   And so we're gearing up for a battle royale.
[00:05:48.620 --> 00:05:49.780]   That's what it feels like.
[00:05:49.780 --> 00:05:54.180]   The forecast we have in here is simply the consensus Morgan Stanley and Goldman Sachs
[00:05:54.180 --> 00:05:58.100]   forecast for the balance of the year, which has been pretty accurate.
[00:05:58.100 --> 00:06:02.580]   The backdrop around inflation continues to be constructive.
[00:06:02.580 --> 00:06:05.220]   We had a couple of months in there where I think people got scared.
[00:06:05.220 --> 00:06:09.140]   Larry Summers said maybe the next rate move is up.
[00:06:09.140 --> 00:06:11.140]   Why does that matter so much, Bill?
[00:06:11.140 --> 00:06:14.520]   Just listen to the Berkshire Hathaway annual meeting.
[00:06:14.520 --> 00:06:18.820]   You know, Warren Buffett says, listen, I'm collecting my my interest payments every week.
[00:06:18.820 --> 00:06:22.500]   If I can earn five point four percent taking no risk, why would I take risks?
[00:06:22.500 --> 00:06:27.780]   So, you know, I still am in the camp that, you know, we're on a glide path.
[00:06:27.780 --> 00:06:30.240]   It's going to take a little bit longer.
[00:06:30.240 --> 00:06:32.700]   But I do suspect that rates are going to come down.
[00:06:32.700 --> 00:06:35.940]   Jay Powell said yesterday we're on hold for a couple more months.
[00:06:35.940 --> 00:06:38.640]   I think you're going to get a rate cut before the election.
[00:06:38.640 --> 00:06:42.180]   But I don't think the market actually needs a rate cut, Bill.
[00:06:42.180 --> 00:06:46.180]   What they need to know is that inflation is coming down and the Fed can give us a rate
[00:06:46.180 --> 00:06:47.780]   cut if they want to.
[00:06:47.780 --> 00:06:54.960]   It's very difficult to stay fit and efficient when you have a buffet of all options sitting
[00:06:54.960 --> 00:06:57.340]   in front of you and you can fund all of them.
[00:06:57.340 --> 00:07:01.620]   Scarcity breeds necessity, scarcity breeds innovation.
[00:07:01.620 --> 00:07:06.260]   Elon set out a vision for rockets that could land themselves and auto fleets that would
[00:07:06.260 --> 00:07:08.300]   be replaced by electric cars.
[00:07:08.300 --> 00:07:11.720]   At the time he said these things, they sounded totally outlandish.
[00:07:11.720 --> 00:07:13.100]   You have to will the future.
[00:07:13.100 --> 00:07:14.500]   You have to manifest the future.
[00:07:14.500 --> 00:07:16.020]   You have to describe the future.
[00:07:16.020 --> 00:07:17.860]   You have to motivate your employees.
[00:07:17.860 --> 00:07:21.540]   And importantly, you have to motivate sources of capital.
[00:07:21.540 --> 00:07:23.580]   People talk about the military industrial complex.
[00:07:23.580 --> 00:07:31.940]   We may have created a healthcare industrial complex that really can't stop maximizing
[00:07:31.940 --> 00:07:39.980]   profitability and not focus necessarily on the lowest cost, best, most preventative process.
[00:07:39.980 --> 00:07:42.940]   What do you do for yourself, your friends, and your family?
[00:07:42.940 --> 00:07:48.500]   Just tell me your care, standard of care for yourself, your friends, and your family.
[00:07:48.500 --> 00:07:55.500]   And 100% of them follow the same protocol, which is a calcium CT scan no later than 40.
[00:07:55.500 --> 00:07:59.820]   Five times as many women die of a heart attack each year in this country as die of breast
[00:07:59.820 --> 00:08:00.820]   cancer.
[00:08:00.820 --> 00:08:07.300]   Very, very few women do a calcium CT scan, which I might argue or I've heard argued is
[00:08:07.300 --> 00:08:09.260]   the mammogram for the heart.
[00:08:09.260 --> 00:08:16.300]   And instead of a $250 marginal cost to implement a rural broadband, we're going to get bulldozers
[00:08:16.300 --> 00:08:21.820]   out and drop fiber lines to a ranch in the middle of nowhere.
[00:08:21.820 --> 00:08:23.340]   It's stupid.
[00:08:23.340 --> 00:08:27.340]   That shot fired at Trump was one inch different.
[00:08:27.340 --> 00:08:33.360]   If Trump had been assassinated, can you imagine what would happen to the U.S. markets?
[00:08:33.360 --> 00:08:37.340]   So when markets are at all-time highs and you're just hanging out and there's not a
[00:08:37.340 --> 00:08:41.300]   lot of upside return and you got these other things you're concerned about, you got to
[00:08:41.300 --> 00:08:45.340]   take down those units of risk because there are always things like this that can happen.
[00:08:45.340 --> 00:08:46.700]   Take Tiablo Canyon.
[00:08:46.700 --> 00:08:48.980]   They built two nuclear reactors here.
[00:08:48.980 --> 00:08:53.020]   You know, this site was provisioned for six.
[00:08:53.020 --> 00:08:58.620]   I could imagine if you had four more reactors sitting here, you could have one reactor for
[00:08:58.620 --> 00:09:02.820]   Meta, one for Amazon, one for Microsoft, one for NVIDIA.
[00:09:02.820 --> 00:09:05.340]   You could have the data center sitting right next to them.
[00:09:05.340 --> 00:09:12.980]   I think this anti-Chinese mentality is a little nuts because if you look at low-cost EVs,
[00:09:12.980 --> 00:09:19.380]   if you look at their subway stations, if you look at, they're leading us in many areas.
[00:09:19.380 --> 00:09:24.700]   And we have this holier-than-thou attitude that America is the best and that we're the
[00:09:24.700 --> 00:09:27.060]   leader and we're being passed.
[00:09:27.060 --> 00:09:31.220]   We would all be better off if nuclear energy were cheaper for everyone on the planet.
[00:09:31.220 --> 00:09:34.380]   I'm no longer going to program computers with C++.
[00:09:34.380 --> 00:09:38.460]   I'm going to program AIs with prompting.
[00:09:38.460 --> 00:09:39.460]   Isn't that right?
[00:09:39.460 --> 00:09:42.340]   Now, this is no different than me talking to my, you know, this morning.
[00:09:42.340 --> 00:09:44.340]   I wrote a bunch of emails before I came here.
[00:09:44.340 --> 00:09:47.420]   I was prompting my teams, right?
[00:09:47.420 --> 00:09:49.100]   And I would describe the context.
[00:09:49.100 --> 00:09:54.460]   I would describe the fundamental constraints that I know of, and I would describe the mission
[00:09:54.460 --> 00:09:55.460]   for them.
[00:09:55.460 --> 00:10:00.580]   I would leave it sufficiently, I would be sufficiently directional so that they understand
[00:10:00.580 --> 00:10:01.580]   what I need.
[00:10:01.580 --> 00:10:05.220]   And I want to be clear about what the outcome should be, as clear as I can be.
[00:10:05.220 --> 00:10:09.580]   But I leave enough ambiguous space on, you know, a creativity space so they can surprise
[00:10:09.580 --> 00:10:10.580]   me.
[00:10:10.580 --> 00:10:11.580]   Isn't that right?
[00:10:11.580 --> 00:10:13.180]   Isn't that how I prompt an AI today?
[00:10:13.180 --> 00:10:15.220]   It's exactly how I prompt an AI.
[00:10:15.220 --> 00:10:19.380]   Companies are only limited by the size of the fishpond, you know.
[00:10:19.380 --> 00:10:21.780]   A goldfish can only be so big.
[00:10:21.780 --> 00:10:22.980]   What is our fishpond?
[00:10:22.980 --> 00:10:24.660]   What is our pond?
[00:10:24.660 --> 00:10:26.420]   And that requires a lot of imagination.
[00:10:26.420 --> 00:10:35.180]   And this is the reason why market makers think about that future, creating that new fishpond.
[00:10:35.180 --> 00:10:38.860]   It's hard to figure this out looking backwards and try to take share.
[00:10:38.860 --> 00:10:44.020]   The need to invent a new market to go serve it later is something that's very comfortable
[00:10:44.020 --> 00:10:45.020]   for us.
[00:10:45.020 --> 00:10:46.020]   Exactly, exactly.
[00:10:46.020 --> 00:10:50.700]   I've said before, the data center is now the unit of computing.
[00:10:50.700 --> 00:10:53.820]   To me, when I think about a computer, I'm not thinking about that chip.
[00:10:53.820 --> 00:10:55.020]   I'm thinking about this thing.
[00:10:55.020 --> 00:10:58.820]   That's my mental model and all the software and all the orchestration, all the machinery
[00:10:58.820 --> 00:11:00.620]   that's inside.
[00:11:00.620 --> 00:11:01.620]   That's my computer.
[00:11:01.620 --> 00:11:05.820]   And we're trying to build a new one every year.
[00:11:05.820 --> 00:11:07.100]   That's insane.
[00:11:07.100 --> 00:11:08.100]   Nobody has ever done that before.
[00:11:08.100 --> 00:11:15.580]   You may also be running up against the, even for the Mag7, the size of Capo X deployment
[00:11:15.580 --> 00:11:18.600]   where their CFOs start to talk at higher levels.
[00:11:18.600 --> 00:11:20.740]   You can have a thousand agents working together.
[00:11:20.740 --> 00:11:23.900]   You can have one that's making sure that the credit card charge is not too big.
[00:11:23.900 --> 00:11:26.140]   You can have another one to make sure that the address is right.
[00:11:26.140 --> 00:11:28.460]   You can have another one checking against your calendar.
[00:11:28.460 --> 00:11:29.980]   And so all of that's free.
[00:11:29.980 --> 00:11:33.380]   So I'm on the under and Brad, I'll even go under one year.
[00:11:33.380 --> 00:11:34.380]   Wow.
[00:11:34.380 --> 00:11:35.380]   Yeah.
[00:11:35.380 --> 00:11:36.380]   Wow.
[00:11:36.380 --> 00:11:37.380]   Yeah.
[00:11:37.380 --> 00:11:38.380]   That's crazy, Sonny.
[00:11:38.380 --> 00:11:41.460]   10, 15 years ago, the funds were smaller.
[00:11:41.460 --> 00:11:47.140]   And as a GP, as an investor, you'll make money on that guaranteed portion, but not necessarily
[00:11:47.140 --> 00:11:48.140]   right.
[00:11:48.140 --> 00:11:49.140]   As I call it, get rich money.
[00:11:49.140 --> 00:11:54.060]   Bill, what were you making when you started, per year when you started in the business?
[00:11:54.060 --> 00:11:57.300]   Every founder and every company and every board will tell you, if we raise money, we're not
[00:11:57.300 --> 00:11:58.300]   going to spend it.
[00:11:58.300 --> 00:11:59.420]   We're going to stay frugal.
[00:11:59.420 --> 00:12:00.620]   That never happens.
[00:12:00.620 --> 00:12:03.900]   You might ask a founder, what are the three things that matter most this year that are
[00:12:03.900 --> 00:12:05.580]   critical for your success?
[00:12:05.580 --> 00:12:10.340]   If you only focused on those three things, you might maximize your chance of success.
[00:12:10.340 --> 00:12:13.740]   When you have lots of money, you're going to do six things at once, which means you
[00:12:13.740 --> 00:12:15.740]   are diluting the three things that matter.
[00:12:15.740 --> 00:12:19.020]   I think we're all actors stuck in the game.
[00:12:19.020 --> 00:12:20.020]   Right.
[00:12:20.020 --> 00:12:22.740]   You know, I'm not sure you can escape it.
[00:12:22.740 --> 00:12:24.220]   You know, a couple of observations.
[00:12:24.220 --> 00:12:25.780]   Is that the positive take on it?
[00:12:25.780 --> 00:12:26.780]   No.
[00:12:26.780 --> 00:12:28.060]   I know he wanted one.
[00:12:28.060 --> 00:12:29.060]   I apologize.
[00:12:29.060 --> 00:12:35.380]   If 2024 was the chat GPT moment for full self-driving, Bill, where we started seeing Waymo's on
[00:12:35.380 --> 00:12:40.280]   every street corner in San Francisco, if this was the chat GPT year, I think next year really
[00:12:40.280 --> 00:12:48.460]   is the year of achievement of a safety standard that allows RoboTaxi to go into action.
[00:12:48.460 --> 00:12:54.100]   The Department of Government Efficiency, the unofficial government department, which is
[00:12:54.100 --> 00:13:02.140]   run by Vivek and Elon, and is overseeing trying to reform government spending, government
[00:13:02.140 --> 00:13:08.100]   regulations, frankly, reducing the size of the federal government with the overall objective
[00:13:08.100 --> 00:13:13.100]   of getting control of our national deficit and our national debt, which we all agree
[00:13:13.100 --> 00:13:14.100]   is pretty egregious.
[00:13:14.100 --> 00:13:19.500]   And, you know, if you look at the federal revenues, just over $5 trillion expected this
[00:13:19.500 --> 00:13:22.020]   year, government spending $7 trillion.
[00:13:22.020 --> 00:13:25.020]   So we basically have a $2 trillion deficit.
[00:13:25.020 --> 00:13:29.780]   That spending is up dramatically, by the way, from the $4.5 trillion that we spent in 2019.
[00:13:29.780 --> 00:13:33.260]   So in COVID, we just lost our mind and we've never regained our mind.
[00:13:33.260 --> 00:13:37.940]   If you just grow revenues from here at 3% to 4% over the course of the next four years,
[00:13:37.940 --> 00:13:44.060]   Bill, and you cut costs in the first year by 5%, second year by 5%, third year by 2%,
[00:13:44.060 --> 00:13:50.260]   so all that does is get you back to trend line from 2019, as though we increased spending
[00:13:50.260 --> 00:13:54.860]   3% a year from 2019, the budget balances.
[00:13:54.860 --> 00:13:59.500]   That's tiny, these are tiny changes in costs.
[00:13:59.500 --> 00:14:05.220]   And I shared that with Vivek and Elon, and they both had separate and independent reactions,
[00:14:05.220 --> 00:14:07.900]   which is not nearly ambitious enough.
[00:14:07.900 --> 00:14:12.620]   Invest America, Bill, you know, Invest America is a project and now piece of legislation
[00:14:12.620 --> 00:14:18.080]   that I've been working on for three years, and it's truly gaining a ton of traction.
[00:14:18.080 --> 00:14:23.740]   The federal government would cause to be created 3.7 million investment accounts a year for
[00:14:23.740 --> 00:14:25.860]   every child that's born in America.
[00:14:25.860 --> 00:14:30.380]   They would seed it with a very small amount of money that would be a roundy near to the
[00:14:30.380 --> 00:14:31.380]   federal government.
[00:14:31.380 --> 00:14:38.900]   It has a massive ROI, and we can achieve it while having less government, not more government.
[00:14:38.900 --> 00:14:48.540]   I think the notion that business applications exist, that's probably where they'll all collapse,
[00:14:48.540 --> 00:14:50.100]   right, in the agent era.
[00:14:50.100 --> 00:14:56.500]   Because if you think about it, right, they are essentially CRUD databases with a bunch
[00:14:56.500 --> 00:14:58.820]   of business logic.
[00:14:58.820 --> 00:15:03.980]   The business logic is all going to these agents.
[00:15:03.980 --> 00:15:09.780]   And these agents are going to be multi-repo CRUD, right, so they're not going to discriminate
[00:15:09.780 --> 00:15:12.820]   between what the backend is.
[00:15:12.820 --> 00:15:20.220]   They're going to update multiple databases and all the logic will be in the AI tier,
[00:15:20.220 --> 00:15:21.560]   so to speak.
[00:15:21.560 --> 00:15:27.300]   And once the AI tier becomes the place where all the logic is, then people will start replacing
[00:15:27.300 --> 00:15:28.300]   the backend.
[00:15:28.300 --> 00:15:33.020]   I think the company of this generation has already been created, which is open AI in
[00:15:33.020 --> 00:15:34.700]   some sense.
[00:15:34.700 --> 00:15:40.420]   It's kind of like the Google or the Microsoft or the meta of this era.
[00:15:40.420 --> 00:15:44.940]   I mean, I always say Google makes more money on Windows than all of Microsoft.
[00:15:44.940 --> 00:15:45.940]   I mean, literally.
[00:15:45.940 --> 00:15:47.940]   I mean, and I say, wow.
[00:15:47.940 --> 00:15:50.740]   Very few people could use GPT-2 and 3, right?
[00:15:50.740 --> 00:15:52.780]   A lot of people can use GPT-4.
[00:15:52.780 --> 00:15:57.000]   When we get to that quality of jump that we see for the next generation, the amount of
[00:15:57.000 --> 00:16:01.100]   people that can use it, the tasks that it can do, balloons out, and therefore the amount
[00:16:01.100 --> 00:16:05.380]   of sort of white-collar jobs that it can augment increased productivity on will grow, and therefore
[00:16:05.380 --> 00:16:07.660]   the market clearing price for that token will be very high.
[00:16:07.660 --> 00:16:08.660]   That's super interesting.
[00:16:08.660 --> 00:16:11.220]   If that's going to be dead, then why is Mark Zuckerberg building a two-gigawatt data center
[00:16:11.220 --> 00:16:12.220]   in Louisiana?
[00:16:12.220 --> 00:16:13.220]   Right.
[00:16:13.220 --> 00:16:16.040]   Why is Amazon building these multi-gigawatt data centers?
[00:16:16.040 --> 00:16:21.080]   Why is Google, why is Microsoft building multiple gigawatt data centers, plus buying billions
[00:16:21.080 --> 00:16:24.980]   and billions of dollars of fiber to connect them together because they think, hey, I need
[00:16:24.980 --> 00:16:28.180]   to win on scale, so let me just connect all the data centers together with super high
[00:16:28.180 --> 00:16:32.560]   bandwidth so then I can make them act like one data center, right, towards one job, right?
[00:16:32.560 --> 00:16:38.020]   So this whole, like, is scaling over narrative falls on its face when you see what the people
[00:16:38.020 --> 00:16:39.940]   who know the best are spending on.
[00:16:39.940 --> 00:16:40.940]   Until next year.
[00:16:40.940 --> 00:16:41.940]   Awesome.
[00:16:41.940 --> 00:16:42.940]   Thank you.
[00:16:42.940 --> 00:16:42.940]   Take care.
[00:16:42.940 --> 00:16:55.340]   As a reminder to everybody, just our opinions, not investment advice.

