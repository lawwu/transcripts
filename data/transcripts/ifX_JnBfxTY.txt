
[00:00:00.000 --> 00:00:03.240]   The following is a conversation with Eric Weinstein,
[00:00:03.240 --> 00:00:05.740]   his fourth time on the podcast.
[00:00:05.740 --> 00:00:10.080]   Both sadness and hope run through his heart and his mind,
[00:00:10.080 --> 00:00:13.680]   and the result is a complicated, brilliant human being
[00:00:13.680 --> 00:00:15.980]   who I am fortunate to call a friend.
[00:00:15.980 --> 00:00:18.680]   Quick mention of our sponsors.
[00:00:18.680 --> 00:00:22.460]   Indeed hiring site, Theragun muscle recovery device,
[00:00:22.460 --> 00:00:24.800]   Wine Access online wine store,
[00:00:24.800 --> 00:00:27.940]   and Blinkist app that summarizes books.
[00:00:27.940 --> 00:00:30.120]   Click the sponsor links to get a discount
[00:00:30.120 --> 00:00:32.120]   and to support this podcast.
[00:00:32.120 --> 00:00:35.240]   As a side note, let me ask that whenever we touch
[00:00:35.240 --> 00:00:38.240]   difficult topics in this or other conversations
[00:00:38.240 --> 00:00:40.440]   that you listen with an open mind,
[00:00:40.440 --> 00:00:44.000]   and forgive me or the guest for a misstep
[00:00:44.000 --> 00:00:46.760]   in an imperfectly thought out statement.
[00:00:46.760 --> 00:00:48.320]   To have any chance of truth,
[00:00:48.320 --> 00:00:50.120]   I think we have to take risks
[00:00:50.120 --> 00:00:52.740]   and make mistakes in conversation,
[00:00:52.740 --> 00:00:54.800]   and then learn from those mistakes.
[00:00:54.800 --> 00:00:57.360]   Please try not to close your mind and heart to others
[00:00:57.360 --> 00:01:00.920]   because of a single sentence or an expression of an idea.
[00:01:00.920 --> 00:01:03.440]   Try to assume that the people in this conversation
[00:01:03.440 --> 00:01:06.120]   are just people in general, are good,
[00:01:06.120 --> 00:01:08.680]   but not perfect and far from it,
[00:01:08.680 --> 00:01:11.800]   but always striving to add a bit more love into the world
[00:01:11.800 --> 00:01:13.780]   in whatever way we know how.
[00:01:13.780 --> 00:01:17.000]   If you enjoy this thing, subscribe on YouTube,
[00:01:17.000 --> 00:01:20.000]   review it on Apple Podcasts, follow us on Spotify,
[00:01:20.000 --> 00:01:22.920]   support on Patreon, or connect with me on Twitter
[00:01:22.920 --> 00:01:24.280]   at Lex Friedman.
[00:01:24.280 --> 00:01:28.560]   And now, here's my conversation with Eric Weinstein.
[00:01:28.560 --> 00:01:31.960]   You often talk about getting off this planet,
[00:01:31.960 --> 00:01:37.200]   and I think you don't often talk about
[00:01:37.200 --> 00:01:41.160]   extraterrestrial life, intelligent life out there.
[00:01:41.160 --> 00:01:42.720]   Do you wonder about this kind of thing,
[00:01:42.720 --> 00:01:45.000]   about intelligent civilizations out there?
[00:01:45.000 --> 00:01:47.320]   - I do, but I try to not wonder about it
[00:01:47.320 --> 00:01:48.540]   in a particular way.
[00:01:48.540 --> 00:01:53.040]   In a certain sense, I do find that speculating
[00:01:53.040 --> 00:01:55.840]   about Bigfoot and the Loch Ness Monster and space aliens
[00:01:55.840 --> 00:01:57.800]   is kind of a recreation for when things
[00:01:57.800 --> 00:01:59.080]   aren't going very well.
[00:01:59.080 --> 00:02:03.520]   At least it gives us some meaning and purpose in our lives.
[00:02:03.520 --> 00:02:07.920]   So I worry about, for example, the simulation hypothesis
[00:02:07.920 --> 00:02:09.400]   is taking over from religion.
[00:02:09.400 --> 00:02:12.240]   You can't quite believe enough to go to church or synagogue
[00:02:12.240 --> 00:02:14.280]   or the mosque on the weekend,
[00:02:14.280 --> 00:02:16.160]   so then you just take up an interest
[00:02:16.160 --> 00:02:18.520]   in the simulation theory because that's something
[00:02:18.520 --> 00:02:21.000]   like what you do for your job coding.
[00:02:21.000 --> 00:02:24.360]   I do think that, in some sense, the issue of aliens
[00:02:24.360 --> 00:02:27.560]   is a really interesting one, but it has been spoiled
[00:02:27.560 --> 00:02:31.540]   by too much sort of recreational escapism.
[00:02:31.540 --> 00:02:35.000]   The key question that I find is,
[00:02:35.000 --> 00:02:39.120]   let's assume that it is possible to look out
[00:02:39.120 --> 00:02:42.000]   at the night sky and see all of these distant worlds
[00:02:42.000 --> 00:02:43.700]   and then go visit them.
[00:02:43.700 --> 00:02:46.280]   If that is possible, it's almost certainly possible
[00:02:46.280 --> 00:02:51.280]   through some as yet unknown or not accepted theory
[00:02:51.280 --> 00:02:54.500]   of physics beyond Einstein.
[00:02:54.500 --> 00:02:59.200]   And I mean, it doesn't have to be that way, but probably is.
[00:02:59.200 --> 00:03:04.160]   If that theory exists, there would be a percentage
[00:03:04.160 --> 00:03:06.760]   of the world that have life in sort of a Drake equation
[00:03:06.760 --> 00:03:10.500]   kind of a way that would have encountered the ability
[00:03:10.500 --> 00:03:15.500]   to escape soon enough after unlocking the power
[00:03:15.760 --> 00:03:19.120]   of the atom at a minimum and whatever they have
[00:03:19.120 --> 00:03:24.120]   that is probably analogous to the cell on that world.
[00:03:24.120 --> 00:03:29.000]   So assuming that life is a fairly generic thing
[00:03:29.000 --> 00:03:32.520]   that arises, probably not carbon-based,
[00:03:32.520 --> 00:03:35.660]   probably doesn't have DNA, but that something
[00:03:35.660 --> 00:03:39.720]   that fits the pattern of Darwinian theory,
[00:03:39.720 --> 00:03:44.720]   which is descent with variation, differential success,
[00:03:45.520 --> 00:03:47.400]   and thereby constantly improving and so on,
[00:03:47.400 --> 00:03:50.120]   that through time there'll be a trajectory
[00:03:50.120 --> 00:03:53.200]   where there'll be something increasingly complex
[00:03:53.200 --> 00:03:55.360]   and fascinating and beautiful like us humans,
[00:03:55.360 --> 00:03:56.520]   but much more.
[00:03:56.520 --> 00:03:59.680]   - That can also off-gas whatever entropy it creates
[00:03:59.680 --> 00:04:03.200]   to give an illusion that you're defeating thermodynamics.
[00:04:03.200 --> 00:04:05.760]   So whatever these things are, probably has an analog
[00:04:05.760 --> 00:04:08.640]   of the bilipid layer so that cells can get rid
[00:04:08.640 --> 00:04:11.200]   of the chaos on one side of the barrier
[00:04:11.200 --> 00:04:12.840]   and keep order on the other.
[00:04:12.840 --> 00:04:15.560]   Whatever these things are that create life,
[00:04:15.560 --> 00:04:17.480]   assuming that there is a theory to be found
[00:04:17.480 --> 00:04:21.040]   that allows that civilization to diversify,
[00:04:21.040 --> 00:04:26.320]   we would have to imagine that such a civilization
[00:04:26.320 --> 00:04:29.560]   might have taken an interest in its concept
[00:04:29.560 --> 00:04:31.320]   of the universe and have come here.
[00:04:31.320 --> 00:04:34.000]   - They would come here.
[00:04:34.000 --> 00:04:37.120]   They would have a deep understanding of the physics
[00:04:37.120 --> 00:04:40.920]   of the universe sufficient to have arrived here.
[00:04:40.920 --> 00:04:41.760]   - Well, there's two questions,
[00:04:41.760 --> 00:04:43.200]   whether they could arrive physically
[00:04:43.200 --> 00:04:47.800]   and whether their information could be sent here
[00:04:47.800 --> 00:04:50.440]   and whether they could gain information from us.
[00:04:50.440 --> 00:04:55.280]   It's possible that they would have a way of looking
[00:04:55.280 --> 00:04:57.280]   into our world without actually reaching it.
[00:04:57.280 --> 00:04:58.520]   I don't know.
[00:04:58.520 --> 00:05:03.320]   But yes, if my hope, which is that we can escape this world,
[00:05:03.320 --> 00:05:07.720]   can be realized, if that's feasible,
[00:05:07.720 --> 00:05:10.560]   then you would have to imagine that the reverse is true
[00:05:10.560 --> 00:05:15.000]   and that somebody else should be here.
[00:05:15.000 --> 00:05:17.200]   First of all, I wanna say this.
[00:05:17.200 --> 00:05:19.920]   My purpose when I come on to your show
[00:05:19.920 --> 00:05:24.160]   and I reframe the questions is not to challenge you.
[00:05:24.160 --> 00:05:26.000]   I can sit inside all of those.
[00:05:26.000 --> 00:05:27.680]   It's to give you better audio and video
[00:05:27.680 --> 00:05:29.880]   because I think we've been on an incredible roll.
[00:05:29.880 --> 00:05:31.560]   I really love what you do.
[00:05:31.560 --> 00:05:33.440]   And so I am trying to honor you
[00:05:33.440 --> 00:05:36.560]   by being as disagreeable about frame-breaking as possible.
[00:05:36.560 --> 00:05:38.920]   I think some of your listeners don't understand
[00:05:38.920 --> 00:05:40.520]   that it's actually a sign of respect
[00:05:40.520 --> 00:05:43.280]   as opposed to some sort of a complex dynamic,
[00:05:43.280 --> 00:05:46.800]   which is I think you can play outside of some of the frames
[00:05:46.800 --> 00:05:48.280]   and that these are sort of offerings
[00:05:48.280 --> 00:05:49.640]   to get the conversation started.
[00:05:49.640 --> 00:05:51.160]   So let me try to break that frame
[00:05:51.160 --> 00:05:52.440]   and give you something different.
[00:05:52.440 --> 00:05:53.280]   - Beautiful.
[00:05:53.280 --> 00:05:59.320]   - I think what's going on here is that I can prove
[00:05:59.320 --> 00:06:02.200]   effectively that we're not thinking about this
[00:06:02.200 --> 00:06:03.240]   in very deep terms.
[00:06:03.240 --> 00:06:05.840]   As soon as I say we've gotta get off this planet,
[00:06:05.840 --> 00:06:08.200]   the number of people who assume that I'm talking
[00:06:08.200 --> 00:06:12.720]   about faster than light travel is very high.
[00:06:12.720 --> 00:06:16.200]   And faster than light travel assumes some sort of
[00:06:16.200 --> 00:06:18.680]   Einsteinian paradigm that then is broken
[00:06:18.680 --> 00:06:22.200]   by some small adjustment.
[00:06:22.200 --> 00:06:24.720]   And I think that that's fascinating.
[00:06:24.720 --> 00:06:27.560]   It shows me that our failure to imagine
[00:06:27.560 --> 00:06:30.680]   what could be being said is profound.
[00:06:30.680 --> 00:06:35.680]   We don't have an idea of all of the different ways
[00:06:35.840 --> 00:06:39.680]   in which we might be able to visit distant worlds.
[00:06:39.680 --> 00:06:44.280]   All we think about is, okay, it must be Einsteinian
[00:06:44.280 --> 00:06:48.200]   space times and then some means of exceeding the speed limit.
[00:06:48.200 --> 00:06:50.440]   And it's just, it's fascinating to me
[00:06:50.440 --> 00:06:52.200]   that we don't really have,
[00:06:52.200 --> 00:06:57.640]   we've lost the ability to just realize
[00:06:57.640 --> 00:06:59.560]   we don't know the framework.
[00:06:59.560 --> 00:07:01.360]   And what does it even mean?
[00:07:01.360 --> 00:07:03.160]   So one of the things I think about a lot
[00:07:03.160 --> 00:07:05.660]   is worlds with more than one temporal dimension.
[00:07:05.660 --> 00:07:08.520]   It's very hard to think about
[00:07:08.520 --> 00:07:10.880]   more than one temporal dimension.
[00:07:10.880 --> 00:07:14.800]   - So that's a really strong mental exercise
[00:07:14.800 --> 00:07:17.320]   of breaking the framework in which we think.
[00:07:17.320 --> 00:07:19.260]   'Cause most of the frameworks would have
[00:07:19.260 --> 00:07:20.960]   a single temporal dimension, right?
[00:07:20.960 --> 00:07:22.920]   - Well, first of all, most of the frameworks
[00:07:22.920 --> 00:07:25.040]   in which we think would have no temporal dimension,
[00:07:25.040 --> 00:07:27.040]   would have pure, like in mathematics,
[00:07:27.040 --> 00:07:29.680]   the differential geometry that Riemann
[00:07:29.680 --> 00:07:31.600]   came up with in the 1800s.
[00:07:32.960 --> 00:07:35.240]   We don't usually talk about
[00:07:35.240 --> 00:07:37.960]   what we would call split signature metrics,
[00:07:37.960 --> 00:07:39.960]   or Lorentzian signature.
[00:07:39.960 --> 00:07:41.760]   In fact, if it weren't for relativity,
[00:07:41.760 --> 00:07:45.600]   this would be the most obscure topic out there.
[00:07:45.600 --> 00:07:48.240]   Almost all the work we do is in Euclidean signature,
[00:07:48.240 --> 00:07:50.240]   and then there's this one freakish case
[00:07:50.240 --> 00:07:52.080]   of relativity theory in physics
[00:07:52.080 --> 00:07:55.780]   that uses this one time and the rest spatial dimensions.
[00:07:55.780 --> 00:07:57.880]   Fascinating.
[00:07:57.880 --> 00:08:01.120]   - So it's usually momentary and just looking at space.
[00:08:01.120 --> 00:08:05.400]   - Yes, we have these three kinds of equations
[00:08:05.400 --> 00:08:06.720]   that are very important to us.
[00:08:06.720 --> 00:08:11.360]   We have elliptic, hyperbolic, and parabolic, right?
[00:08:11.360 --> 00:08:15.160]   And so the idea is if I'm chewing gum
[00:08:15.160 --> 00:08:16.780]   after eating garlic bread,
[00:08:16.780 --> 00:08:22.520]   when I open my mouth and I've got chewing gum
[00:08:22.520 --> 00:08:25.400]   between my lips, maybe it's gonna form
[00:08:25.400 --> 00:08:29.080]   an elliptic object called a minimal surface.
[00:08:29.080 --> 00:08:31.280]   Then when I pop that and blow through it,
[00:08:31.280 --> 00:08:33.520]   you're gonna hear a noise that's gonna travel to you
[00:08:33.520 --> 00:08:36.280]   by a wave equation, which is gonna be hyperbolic.
[00:08:36.280 --> 00:08:38.940]   But then the garlic breath is gonna diffuse towards you,
[00:08:38.940 --> 00:08:41.240]   and you're eventually gonna be very upset with me
[00:08:41.240 --> 00:08:44.040]   according to a heat equation, which will be parabolic.
[00:08:44.040 --> 00:08:46.640]   So those are the three basic paradigms
[00:08:46.640 --> 00:08:48.200]   for most of the work that we do.
[00:08:48.200 --> 00:08:52.320]   And a lot of the work that we do in mathematics is elliptic,
[00:08:52.320 --> 00:08:54.700]   whereas the physicists are in the hyperbolic case.
[00:08:54.700 --> 00:08:55.800]   And I don't even know what to do
[00:08:55.800 --> 00:08:57.540]   about more than one temporal dimension
[00:08:57.540 --> 00:08:59.920]   because I think almost no one studies that.
[00:08:59.920 --> 00:09:04.140]   - I can't believe you just captured much of modern physics
[00:09:04.140 --> 00:09:05.820]   in the example of chewing gum.
[00:09:05.820 --> 00:09:06.820]   - Well, I have an off-color one,
[00:09:06.820 --> 00:09:08.060]   which I chose not to share,
[00:09:08.060 --> 00:09:10.240]   but hopefully the kids at home--
[00:09:10.240 --> 00:09:11.140]   - Can imagine.
[00:09:11.140 --> 00:09:12.920]   (laughing)
[00:09:12.920 --> 00:09:16.780]   - Okay, so, okay, that is the place where we come from.
[00:09:16.780 --> 00:09:19.040]   Now, if we want to arrive at a possibility
[00:09:19.040 --> 00:09:22.780]   of breaking the frameworks with two
[00:09:22.780 --> 00:09:25.640]   versus zero temporal dimensions,
[00:09:25.640 --> 00:09:27.140]   how do we even begin to think about that?
[00:09:27.140 --> 00:09:28.840]   Well, let's think about it as you and I
[00:09:28.840 --> 00:09:31.960]   getting together in New York City, okay?
[00:09:31.960 --> 00:09:34.760]   So if you tell me,
[00:09:34.760 --> 00:09:36.600]   "Eric, I want to meet you in New York City.
[00:09:36.600 --> 00:09:39.620]   "Go to the corner of, I don't know,
[00:09:39.620 --> 00:09:42.740]   "34th Street and 3rd Avenue,
[00:09:42.740 --> 00:09:45.260]   "and you'll find a building on the northwest corner
[00:09:45.260 --> 00:09:48.660]   "and go up to the 17th floor," right?
[00:09:48.660 --> 00:09:51.560]   So when we have 3rd Avenue, that's one coordinate,
[00:09:51.560 --> 00:09:53.720]   34th Street, that's a second coordinate,
[00:09:53.720 --> 00:09:55.200]   and go up to the 17th.
[00:09:55.200 --> 00:09:56.120]   And what time is it?
[00:09:56.120 --> 00:09:57.100]   Oh, 12 noon.
[00:09:57.100 --> 00:10:00.880]   All right, well now, imagine that we traded
[00:10:00.880 --> 00:10:03.920]   the ability to get up to a particular height in a building
[00:10:03.920 --> 00:10:05.280]   and it's all flat land,
[00:10:05.280 --> 00:10:07.440]   but I'm gonna give you two temporal coordinates.
[00:10:07.440 --> 00:10:11.400]   So meet me at 5 p.m. and 12 noon
[00:10:11.400 --> 00:10:13.440]   at the corner of 34th and 3rd.
[00:10:13.440 --> 00:10:15.160]   That gets to be too mind-blowing.
[00:10:15.160 --> 00:10:17.320]   I've got two separate watches.
[00:10:17.320 --> 00:10:20.640]   - And presumably that's just specifying a single point
[00:10:20.640 --> 00:10:22.580]   in those two different dimensions,
[00:10:22.580 --> 00:10:25.080]   but then being able to travel along those dimensions.
[00:10:25.080 --> 00:10:27.080]   - Let me see your right hand.
[00:10:27.080 --> 00:10:30.280]   You have no watch on that.
[00:10:30.280 --> 00:10:31.120]   - No.
[00:10:31.120 --> 00:10:32.880]   - Okay, I'm very concerned, Lex,
[00:10:32.880 --> 00:10:36.760]   that you're going through life without a wristwatch.
[00:10:36.760 --> 00:10:39.720]   That is my favorite and most valued wristwatch.
[00:10:39.720 --> 00:10:40.940]   I want you to wear it.
[00:10:40.940 --> 00:10:45.200]   - This guy is funnier than basically any human on Earth.
[00:10:45.200 --> 00:10:48.140]   - Lex, that has been in my family for months.
[00:10:48.140 --> 00:10:51.160]   It's a Fitbit.
[00:10:51.160 --> 00:10:53.560]   Now, what I want you to understand is Lex Fridman
[00:10:53.560 --> 00:10:57.440]   is now in a position to live in two spatial
[00:10:57.440 --> 00:11:00.400]   and two temporal dimensions unlike the rest of us.
[00:11:00.400 --> 00:11:04.760]   I clearly am only fit for four spatial dimensions,
[00:11:04.760 --> 00:11:07.920]   so I'm frozen, whereas you can double move.
[00:11:07.920 --> 00:11:09.640]   - I can double move, which is funny
[00:11:09.640 --> 00:11:12.600]   because this is set in Austin time,
[00:11:12.600 --> 00:11:16.600]   so it's 4 p.m., and this is set in Los Angeles time.
[00:11:16.600 --> 00:11:19.000]   - But that's just with an affine shift in mod 12.
[00:11:19.000 --> 00:11:22.160]   But my point is, wouldn't that be interesting
[00:11:22.160 --> 00:11:23.560]   if there were two separate time scales
[00:11:23.560 --> 00:11:25.720]   and you had to coordinate both of those,
[00:11:25.720 --> 00:11:27.280]   but you didn't have to worry about what floor
[00:11:27.280 --> 00:11:30.400]   of the building because everything was on the ground floor?
[00:11:30.400 --> 00:11:32.860]   That is the confusion that we're having.
[00:11:32.860 --> 00:11:35.560]   And if you do one more show,
[00:11:35.560 --> 00:11:38.120]   then they're gonna put a watch on your ankle,
[00:11:38.120 --> 00:11:40.240]   and you're only gonna have one spatial dimension
[00:11:40.240 --> 00:11:41.120]   that you can move around.
[00:11:41.120 --> 00:11:45.440]   But my claim is that all of these are actually sectors
[00:11:45.440 --> 00:11:48.260]   of my theory in case we're interested in that,
[00:11:48.260 --> 00:11:50.240]   which is geometric unity.
[00:11:50.240 --> 00:11:53.080]   There is a two-two sector, and a three-one,
[00:11:53.080 --> 00:11:55.440]   and a one-three, and a zero-four, and a four-zero.
[00:11:55.440 --> 00:11:58.660]   And all of these sectors have some physical reality.
[00:11:58.660 --> 00:12:01.460]   We happen to live in a one-three sector.
[00:12:01.460 --> 00:12:04.960]   But that's the kind of thinking that we don't do.
[00:12:04.960 --> 00:12:06.680]   When I say we have to get off this planet,
[00:12:06.680 --> 00:12:08.680]   people imagine, oh, okay, it's just Einstein
[00:12:08.680 --> 00:12:11.000]   plus some ability to break the law.
[00:12:11.000 --> 00:12:14.200]   - By the way, even though you did this for humor's sake,
[00:12:14.200 --> 00:12:17.360]   I perhaps am tempted to pull a Putin.
[00:12:19.880 --> 00:12:20.880]   Did it get whacked?
[00:12:20.880 --> 00:12:23.040]   - No, not quite.
[00:12:23.040 --> 00:12:27.640]   But he was given a Super Bowl ring to look at,
[00:12:27.640 --> 00:12:29.960]   and he, instead of just looking at it,
[00:12:29.960 --> 00:12:32.480]   put it on his finger and walked away with it.
[00:12:32.480 --> 00:12:34.120]   - Robert Kraft? - Robert Kraft, that's right.
[00:12:34.120 --> 00:12:38.200]   So in the same way, I will, if you don't mind,
[00:12:38.200 --> 00:12:40.760]   walk away with this Fitbit and taking the entirety
[00:12:40.760 --> 00:12:42.120]   of your life story with it,
[00:12:42.120 --> 00:12:43.920]   because there's all these steps on it.
[00:12:43.920 --> 00:12:45.760]   - Boy, have you lost a lot of weight.
[00:12:45.760 --> 00:12:48.080]   (laughing)
[00:12:48.080 --> 00:12:49.200]   - And where have I been?
[00:12:49.200 --> 00:12:50.040]   - Exactly.
[00:12:50.040 --> 00:12:52.200]   - That's what we're talking about.
[00:12:52.200 --> 00:12:53.800]   We're talking about, you wanna get into aliens,
[00:12:53.800 --> 00:12:55.520]   let's have an interesting alien conversation.
[00:12:55.520 --> 00:12:58.920]   Let's stop having the typical free will conversation,
[00:12:58.920 --> 00:13:00.360]   the typical alien conversation,
[00:13:00.360 --> 00:13:02.840]   the typical AGI morality conversation.
[00:13:02.840 --> 00:13:05.720]   It's like we have to recognize that we're amusing ourselves
[00:13:05.720 --> 00:13:07.600]   because we're not making progress.
[00:13:07.600 --> 00:13:10.400]   Time to have better versions of all these conversations.
[00:13:10.400 --> 00:13:13.000]   - Is there some version of the alien conversation
[00:13:13.000 --> 00:13:15.880]   that could incorporate the breaking of frameworks?
[00:13:15.880 --> 00:13:16.720]   - Well, I think so.
[00:13:16.720 --> 00:13:18.680]   I mean, the key question would be,
[00:13:18.680 --> 00:13:21.640]   we've had the Pentagon release multiple videos
[00:13:21.640 --> 00:13:25.080]   of strange UFOs that undermined a lot of us.
[00:13:25.080 --> 00:13:26.960]   I just think it's also really fascinating
[00:13:26.960 --> 00:13:29.240]   to talk about the fact that those of us
[00:13:29.240 --> 00:13:33.080]   who were trained to call BS on all of this stuff
[00:13:33.080 --> 00:13:35.120]   just had the rug pulled out from under us
[00:13:35.120 --> 00:13:36.720]   by the Pentagon choosing to do this.
[00:13:36.720 --> 00:13:38.400]   And you know what the effect of that is?
[00:13:38.400 --> 00:13:42.400]   You've opened the door for every stupid theory
[00:13:42.400 --> 00:13:44.040]   known to man.
[00:13:44.040 --> 00:13:45.560]   My aunt saw a ghost.
[00:13:46.640 --> 00:13:49.000]   Okay, now we're gonna have to listen to,
[00:13:49.000 --> 00:13:51.000]   well, hey, the Pentagon used to deny it.
[00:13:51.000 --> 00:13:53.040]   Then it turned out there were UFOs, dude.
[00:13:53.040 --> 00:13:57.920]   Whoever is in charge of lying to the public,
[00:13:57.920 --> 00:14:00.960]   they need a cost function that incorporates
[00:14:00.960 --> 00:14:02.880]   the damage and trust.
[00:14:02.880 --> 00:14:05.400]   Because I held this line that this was all garbage
[00:14:05.400 --> 00:14:07.200]   and all BS.
[00:14:07.200 --> 00:14:09.040]   Now I don't know what to think.
[00:14:09.040 --> 00:14:11.480]   - There's a fascinating aspect to this alien discussion,
[00:14:11.480 --> 00:14:12.640]   the breaking of frameworks,
[00:14:12.640 --> 00:14:15.920]   that involves the release of videos from the Pentagon,
[00:14:15.920 --> 00:14:18.240]   which is almost like another dimension
[00:14:18.240 --> 00:14:21.920]   that trust in itself or the nature of truth and information
[00:14:21.920 --> 00:14:24.760]   is a kind of dimension along which we're traveling
[00:14:24.760 --> 00:14:29.280]   constantly that is messing with my head to think about.
[00:14:29.280 --> 00:14:35.880]   Because it almost feels like you need to incorporate that
[00:14:35.880 --> 00:14:38.360]   into your study of the nature of reality.
[00:14:38.360 --> 00:14:43.160]   It's like the constant shifting of the notation,
[00:14:43.160 --> 00:14:45.840]   the tools we use to communicate that reality.
[00:14:45.840 --> 00:14:48.920]   And so what am I supposed to think about these videos?
[00:14:48.920 --> 00:14:51.280]   Is it a complete distraction?
[00:14:51.280 --> 00:14:53.320]   Is it a kind of cosmic joke?
[00:14:53.320 --> 00:14:54.600]   - I don't know, but you know what?
[00:14:54.600 --> 00:14:57.480]   I'm tired of these people, just completely tired of these.
[00:14:57.480 --> 00:14:59.000]   - The people on the Pentagon side
[00:14:59.000 --> 00:15:00.480]   or the people who are interpreting this stuff
[00:15:00.480 --> 00:15:01.320]   on the Pentagon side?
[00:15:01.320 --> 00:15:05.840]   - I'm tired of the authorities playing games
[00:15:05.840 --> 00:15:08.360]   with what we can know.
[00:15:08.360 --> 00:15:09.560]   The fact that you and I don't,
[00:15:09.560 --> 00:15:11.720]   do you have a security clearance?
[00:15:11.720 --> 00:15:13.160]   Some level of it for,
[00:15:13.160 --> 00:15:15.200]   because I was funding for DARPA for a while.
[00:15:15.200 --> 00:15:17.000]   - I don't have a security clearance.
[00:15:17.000 --> 00:15:21.440]   I am going to release whatever theory I have.
[00:15:21.440 --> 00:15:23.960]   And my guess is that there is zero interest
[00:15:23.960 --> 00:15:25.220]   from our own government.
[00:15:25.220 --> 00:15:29.600]   And so the Chinese will find out about it the same time
[00:15:29.600 --> 00:15:30.680]   our government does,
[00:15:30.680 --> 00:15:33.280]   because Lord knows what they do in these buildings.
[00:15:33.280 --> 00:15:36.520]   I watch crazy people walk in and out
[00:15:36.520 --> 00:15:40.000]   of the intelligence community, walk in and out of DARPA.
[00:15:40.000 --> 00:15:43.160]   And I think, wow, you're talking to that person?
[00:15:43.160 --> 00:15:45.240]   That's really fascinating to me.
[00:15:45.240 --> 00:15:49.020]   We don't seem to have a clue as to who might have the ball.
[00:15:49.020 --> 00:15:50.560]   - Complete lack of transparency.
[00:15:50.560 --> 00:15:52.080]   Do you think it's possible there's,
[00:15:52.080 --> 00:15:55.400]   the government is in possession of something
[00:15:55.400 --> 00:15:58.560]   deeply fundamental to our understanding of the world
[00:15:58.560 --> 00:16:00.680]   that they're not releasing?
[00:16:00.680 --> 00:16:05.560]   So this is one of the famous distractions
[00:16:05.560 --> 00:16:07.040]   that people play with, the narrative--
[00:16:07.040 --> 00:16:08.200]   - Assume that that were true.
[00:16:08.200 --> 00:16:12.800]   - Of alien life forms, spacecraft in possession,
[00:16:12.800 --> 00:16:15.120]   that the government is in possession of alien spacecraft.
[00:16:15.120 --> 00:16:16.440]   - Assume that were true. - That's a popular narrative.
[00:16:16.440 --> 00:16:17.640]   - Yeah.
[00:16:17.640 --> 00:16:21.280]   - I don't think the government really exists at the moment.
[00:16:21.280 --> 00:16:24.720]   I believe, and this is not an idea that was original to me.
[00:16:24.720 --> 00:16:26.640]   There was a guy named Michael Teitelbaum
[00:16:26.640 --> 00:16:28.440]   who used to be at the Sloan Foundation.
[00:16:28.440 --> 00:16:31.320]   And at some point I pointed out that the US government
[00:16:31.320 --> 00:16:33.720]   had completely contradictory objectives
[00:16:33.720 --> 00:16:36.240]   when it came to the military and science.
[00:16:36.240 --> 00:16:38.680]   And one branch said this, one branch said that.
[00:16:38.680 --> 00:16:40.760]   I said, "I don't understand which is true.
[00:16:40.760 --> 00:16:41.600]   "What does the government want?"
[00:16:41.600 --> 00:16:43.720]   He said, "You think there's a government?"
[00:16:43.720 --> 00:16:45.360]   And I said, "What do you mean?"
[00:16:45.360 --> 00:16:47.640]   He said, "What makes you think that the people
[00:16:47.640 --> 00:16:50.340]   "in those two offices have ever coordinated?
[00:16:50.340 --> 00:16:54.220]   "What is it that allows each office
[00:16:54.220 --> 00:16:57.720]   "to have a coherent plan with respect to every other office?"
[00:16:57.720 --> 00:16:59.560]   And that's when I first started to understand
[00:16:59.560 --> 00:17:02.480]   that there are periods where the government coheres,
[00:17:02.480 --> 00:17:04.960]   and then there are periods where the coherence just decays.
[00:17:04.960 --> 00:17:07.960]   And I think that that's been going on since 1945,
[00:17:07.960 --> 00:17:09.540]   that there have been a few places
[00:17:09.540 --> 00:17:10.920]   where there's been increased coherence,
[00:17:10.920 --> 00:17:12.640]   but in general everything is just getting
[00:17:12.640 --> 00:17:14.000]   less and less coherent.
[00:17:14.000 --> 00:17:17.240]   And that what war did was focus us on the need
[00:17:17.240 --> 00:17:20.160]   to have a government of people and mission,
[00:17:20.160 --> 00:17:23.880]   capacity, technology, commitment, ideology.
[00:17:23.880 --> 00:17:26.280]   And then as soon as that was gone,
[00:17:26.280 --> 00:17:30.280]   different people, those who'd been through World War II
[00:17:30.280 --> 00:17:31.280]   had one set of beliefs.
[00:17:31.280 --> 00:17:35.400]   Those born in the 1950s or late '40s
[00:17:35.400 --> 00:17:37.080]   by the time they got to Woodstock,
[00:17:37.080 --> 00:17:39.640]   they didn't buy any of that.
[00:17:39.640 --> 00:17:42.800]   - So coherence, is it the complete opposite
[00:17:42.800 --> 00:17:47.800]   of like a bureaucracy being paralyzed by bureaucracy?
[00:17:47.800 --> 00:17:52.520]   So coherence is efficient, functional government?
[00:17:52.520 --> 00:17:54.320]   Because when you say there's no government,
[00:17:54.320 --> 00:17:58.560]   meaning there's no emergent function
[00:17:58.560 --> 00:18:00.120]   from a collection of individuals,
[00:18:00.120 --> 00:18:03.560]   it's just a bunch of individuals stuck in their offices
[00:18:03.560 --> 00:18:05.400]   without any kind of efficient communication
[00:18:05.400 --> 00:18:07.400]   with each other on a single mission.
[00:18:07.400 --> 00:18:12.400]   And so a government that is truly at the epitome
[00:18:12.400 --> 00:18:14.160]   of what a government is supposed to be
[00:18:14.160 --> 00:18:16.200]   is when a bunch of people working together.
[00:18:16.200 --> 00:18:17.040]   - What are we about?
[00:18:17.040 --> 00:18:17.880]   Are we about freedom?
[00:18:17.880 --> 00:18:19.400]   Are we about growth?
[00:18:19.400 --> 00:18:22.120]   Are we about decency and fairness?
[00:18:22.120 --> 00:18:24.920]   Are we about the absence of a national culture
[00:18:24.920 --> 00:18:27.000]   so that we can all just do our own thing?
[00:18:27.000 --> 00:18:28.920]   I've called this thing the USAN,
[00:18:28.920 --> 00:18:31.600]   the United States of Absolutely Nothing.
[00:18:31.600 --> 00:18:35.580]   These are all different visions for our country.
[00:18:35.580 --> 00:18:39.520]   - So it's possible that there's a alien spacecraft somewhere
[00:18:39.520 --> 00:18:42.840]   and there's like 20 people that know about it
[00:18:42.840 --> 00:18:43.960]   and then they're kind of,
[00:18:43.960 --> 00:18:46.080]   it like as you communicate further and further
[00:18:46.080 --> 00:18:48.600]   into the offices, that information dissipates,
[00:18:48.600 --> 00:18:50.360]   it gets distorted in some kind of way
[00:18:50.360 --> 00:18:52.080]   and then it's completely lost,
[00:18:52.080 --> 00:18:54.840]   the power, the possibility of that information is lost.
[00:18:54.840 --> 00:18:57.800]   - We bought a house and I had this idea
[00:18:57.800 --> 00:19:00.240]   that I wanted to find out what all the switches did.
[00:19:00.240 --> 00:19:03.200]   And I quickly found out that your house
[00:19:03.200 --> 00:19:05.680]   doesn't keep updating its plans.
[00:19:05.680 --> 00:19:07.360]   As people do modifications,
[00:19:07.360 --> 00:19:08.820]   they just do the modifications
[00:19:08.820 --> 00:19:11.160]   and they don't actually record why they were doing
[00:19:11.160 --> 00:19:12.800]   what they were doing or what things lead to.
[00:19:12.800 --> 00:19:14.880]   So there are all sorts of bizarre,
[00:19:14.880 --> 00:19:17.480]   like there's a switch in my house that says privacy.
[00:19:17.480 --> 00:19:18.720]   (laughing)
[00:19:18.720 --> 00:19:20.200]   I don't know what privacy is.
[00:19:20.200 --> 00:19:22.280]   Does it turn on an electromagnetic field
[00:19:22.280 --> 00:19:25.740]   that there's some lead shielding go over the house?
[00:19:27.540 --> 00:19:28.560]   That's what we have.
[00:19:28.560 --> 00:19:30.160]   We have a system in which the people
[00:19:30.160 --> 00:19:31.520]   who've inherited these structures
[00:19:31.520 --> 00:19:34.140]   have no idea why their grandparents built them.
[00:19:34.140 --> 00:19:37.040]   - I'd be funny if there's a freedom of speech switch
[00:19:37.040 --> 00:19:38.680]   that you could also control.
[00:19:38.680 --> 00:19:39.920]   Then it would be a perfect metaphor--
[00:19:39.920 --> 00:19:41.000]   - Well, that's different.
[00:19:41.000 --> 00:19:42.920]   Because what they figured out is
[00:19:42.920 --> 00:19:44.480]   is that if they can just make sure
[00:19:44.480 --> 00:19:48.880]   that we don't have any public options for communication,
[00:19:48.880 --> 00:19:52.680]   then hey, every thing that we say to each other
[00:19:52.680 --> 00:19:53.720]   goes through a private company,
[00:19:53.720 --> 00:19:55.360]   private companies can do whatever they want.
[00:19:55.420 --> 00:19:57.620]   And this is like one of the greatest moves
[00:19:57.620 --> 00:19:59.140]   that we didn't really notice.
[00:19:59.140 --> 00:20:01.940]   Electronic and digital speech
[00:20:01.940 --> 00:20:04.220]   makes every other kind of speech irrelevant.
[00:20:04.220 --> 00:20:08.540]   And because there is no public option, guess what?
[00:20:08.540 --> 00:20:12.940]   There's always somebody named Sundar or Jack or Mark
[00:20:12.940 --> 00:20:15.240]   who controls whether or not you can speak
[00:20:15.240 --> 00:20:17.740]   and what it appears to be that is being said
[00:20:17.740 --> 00:20:20.420]   and whose stuff is weighted more highly than others.
[00:20:20.420 --> 00:20:22.220]   It's an absolute nightmare.
[00:20:22.220 --> 00:20:26.660]   And by the way, the Silicon Valley intellectual elite,
[00:20:26.660 --> 00:20:28.180]   Lord knows what is going on.
[00:20:28.180 --> 00:20:30.700]   People are so busy making money
[00:20:30.700 --> 00:20:34.260]   that they are not actually upholding any of the values.
[00:20:34.260 --> 00:20:36.780]   So Silicon Valley is sort of maximally against it.
[00:20:36.780 --> 00:20:41.780]   It has this kind of libertarian, free, progressive sheen
[00:20:41.780 --> 00:20:44.380]   to it when it goes to Burning Man.
[00:20:44.380 --> 00:20:46.500]   And then it quickly just imposes rules
[00:20:46.500 --> 00:20:48.980]   on all of the rest of us as to what we can say to each other
[00:20:48.980 --> 00:20:51.060]   if we're not part of the inner elite.
[00:20:51.060 --> 00:20:53.260]   - So what do you think the ideal
[00:20:53.260 --> 00:20:55.540]   of the freedom of speech means?
[00:20:55.540 --> 00:20:57.300]   - Well, this is very interesting.
[00:20:57.300 --> 00:20:59.380]   I keep getting lectured on social media
[00:20:59.380 --> 00:21:01.620]   by people who have no idea how much power
[00:21:01.620 --> 00:21:04.560]   the Supreme Court has to abstract things.
[00:21:04.560 --> 00:21:07.900]   Right now, you have the concept of the letter of the law
[00:21:07.900 --> 00:21:09.220]   and the spirit of the law.
[00:21:09.220 --> 00:21:12.180]   And the spirit of the law would have to say
[00:21:12.180 --> 00:21:14.660]   that our speech that matters is free,
[00:21:14.660 --> 00:21:16.140]   at least at the level of ideas.
[00:21:16.140 --> 00:21:17.860]   I don't claim that I have the right
[00:21:17.860 --> 00:21:19.660]   to endanger your life with speech
[00:21:19.660 --> 00:21:22.000]   or to reveal your private information.
[00:21:22.000 --> 00:21:25.780]   So I really am not opining about directed speech
[00:21:25.780 --> 00:21:27.220]   intended to smear you.
[00:21:27.220 --> 00:21:30.020]   And that's a different kettle of fish.
[00:21:30.020 --> 00:21:31.540]   And maybe I have some rights to do that,
[00:21:31.540 --> 00:21:33.420]   but I don't think that they're infinite.
[00:21:33.420 --> 00:21:38.420]   What I am saying is that the freedom of speech for ideas
[00:21:38.420 --> 00:21:43.900]   is essential that the court abstract it
[00:21:43.900 --> 00:21:48.140]   and shove it down the throat of Google, Facebook, Twitter,
[00:21:48.140 --> 00:21:52.580]   Amazon, whoever these infrastructure companies are,
[00:21:52.580 --> 00:21:56.260]   because it really matters which abstraction you use.
[00:21:56.260 --> 00:21:59.620]   The case that I really like is search and seizure.
[00:21:59.620 --> 00:22:02.700]   If I have private data that I entered in my house
[00:22:02.700 --> 00:22:04.820]   that is stored on a server that you hold
[00:22:04.820 --> 00:22:08.900]   outside of my house, but I view,
[00:22:08.900 --> 00:22:11.380]   is the abstraction that it's only the perimeter
[00:22:11.380 --> 00:22:13.540]   of my house that I have the right to protect?
[00:22:13.540 --> 00:22:18.540]   Or does my password extend the perimeter of my house
[00:22:18.540 --> 00:22:20.220]   to the data on the server
[00:22:20.220 --> 00:22:22.940]   that is located outside of my house?
[00:22:22.940 --> 00:22:25.940]   These are choices for the court,
[00:22:25.940 --> 00:22:27.440]   and the court is supposed to pretend
[00:22:27.440 --> 00:22:30.680]   that they can divine the true intent of the framers.
[00:22:30.680 --> 00:22:33.620]   But all of the sort of, and I've taken to calling this
[00:22:33.620 --> 00:22:35.240]   the problem of internet hyenas,
[00:22:35.240 --> 00:22:37.900]   people with ready-made answers and LOLs,
[00:22:37.900 --> 00:22:39.940]   and you're such a moron.
[00:22:39.940 --> 00:22:41.660]   These folks love to remind you,
[00:22:41.700 --> 00:22:44.580]   it's a private company, dude, it can do whatever it wants.
[00:22:44.580 --> 00:22:48.540]   No, the court has to figure out what the abstractions are.
[00:22:48.540 --> 00:22:52.860]   And just the way, for example, the Griswold decision
[00:22:52.860 --> 00:22:54.300]   found that there was a penumbra
[00:22:54.300 --> 00:22:56.420]   because there was too little in the Constitution,
[00:22:56.420 --> 00:22:58.380]   therefore there were all sorts of things implied
[00:22:58.380 --> 00:23:00.860]   that couldn't be in the document.
[00:23:00.860 --> 00:23:04.260]   Somebody needs to come up with the abstraction right now
[00:23:04.260 --> 00:23:09.020]   that says Jack cannot do it over he wants.
[00:23:09.020 --> 00:23:11.460]   - It's really, so you say the courts,
[00:23:11.460 --> 00:23:15.460]   but it's also us, people who think about the world, you--
[00:23:15.460 --> 00:23:17.220]   - No, no, no, it's the courts.
[00:23:17.220 --> 00:23:20.680]   If the courts don't do this, we're toast.
[00:23:20.680 --> 00:23:22.420]   - But we can still think about it.
[00:23:22.420 --> 00:23:24.740]   I mean-- - Sure, but I don't feel
[00:23:24.740 --> 00:23:25.740]   like going down the drain.
[00:23:25.740 --> 00:23:26.900]   - Here's what I'm thinking about,
[00:23:26.900 --> 00:23:29.840]   'cause it's tricky how far it should extend.
[00:23:29.840 --> 00:23:31.500]   I mean, that's an ongoing conversation.
[00:23:31.500 --> 00:23:34.300]   Don't you think the interpretation of the law--
[00:23:34.300 --> 00:23:36.260]   - I think I'm trying to say something very simple,
[00:23:36.260 --> 00:23:38.840]   and it's just not gonna be popular for a while.
[00:23:41.220 --> 00:23:45.080]   Tech dwarfs previous forms of communication.
[00:23:45.080 --> 00:23:48.220]   Print or shouting in a public park.
[00:23:48.220 --> 00:23:51.300]   And so I can go to a public park
[00:23:51.300 --> 00:23:53.060]   and I can shout if I get a permit.
[00:23:53.060 --> 00:23:56.400]   Even there, I think it was in the late 1980s in Atlanta,
[00:23:56.400 --> 00:23:58.260]   we came up with free speech zones
[00:23:58.260 --> 00:24:00.100]   where you can't protest at a convention,
[00:24:00.100 --> 00:24:02.460]   but you can go to a park 23 miles out
[00:24:02.460 --> 00:24:04.340]   and they'll fence off a little area
[00:24:04.340 --> 00:24:06.140]   where you can have your free speech.
[00:24:06.140 --> 00:24:09.180]   No, speech is dangerous.
[00:24:09.180 --> 00:24:10.500]   Ideas are dangerous.
[00:24:10.500 --> 00:24:13.780]   We are a country about danger and risk.
[00:24:13.780 --> 00:24:17.120]   And yes, I agree that targeted speech at individuals
[00:24:17.120 --> 00:24:19.980]   trying to reveal their private stuff and all that kind of,
[00:24:19.980 --> 00:24:21.180]   that is very different.
[00:24:21.180 --> 00:24:24.340]   So forget a lot of that stuff.
[00:24:24.340 --> 00:24:27.120]   But free speech for ideas is meant to be dangerous.
[00:24:27.120 --> 00:24:31.940]   And people will die as a result of free speech.
[00:24:31.940 --> 00:24:35.500]   The idea that one life is too much is preposterous.
[00:24:35.500 --> 00:24:38.120]   Like why did we send, if one life is preposterous,
[00:24:38.120 --> 00:24:40.000]   why did we send anyone to the beaches of Normandy?
[00:24:40.000 --> 00:24:41.580]   I just don't get this.
[00:24:41.580 --> 00:24:45.940]   - So one thing that I was clearly bothered by,
[00:24:45.940 --> 00:24:48.220]   and maybe you can be my therapist as well.
[00:24:48.220 --> 00:24:50.700]   - I thought you were mine.
[00:24:50.700 --> 00:24:53.980]   - This is a little bit of a miscommunication
[00:24:53.980 --> 00:24:55.300]   on both of our parts then.
[00:24:55.300 --> 00:24:58.820]   Because who's paying who for this?
[00:24:58.820 --> 00:25:05.760]   I was really bothered by Amazon banning Parler from AWS
[00:25:06.780 --> 00:25:11.240]   because my assumption was that the infrastructure,
[00:25:11.240 --> 00:25:14.320]   I drew a distinction between AWS,
[00:25:14.320 --> 00:25:18.200]   the infrastructure on which competing platforms
[00:25:18.200 --> 00:25:23.200]   could be created is different than the actual platforms.
[00:25:23.200 --> 00:25:27.520]   So the standard of the ideal of freedom of speech,
[00:25:27.520 --> 00:25:31.880]   I in my mind, in a shallow way perhaps,
[00:25:31.880 --> 00:25:35.580]   applied differently to AWS than I did to Twitter.
[00:25:36.680 --> 00:25:41.040]   It felt that we've created a more dangerous world,
[00:25:41.040 --> 00:25:46.040]   that freedoms were violated by banning Parler from AWS,
[00:25:46.040 --> 00:25:48.180]   which I saw as the computing infrastructure
[00:25:48.180 --> 00:25:50.940]   which enables the competition of tools,
[00:25:50.940 --> 00:25:54.960]   the competition of frameworks of communication.
[00:25:54.960 --> 00:25:56.600]   What do you think about this?
[00:25:56.600 --> 00:25:59.940]   - First of all, let me give you the internet hyena answer.
[00:25:59.940 --> 00:26:03.820]   I don't understand, dude, just build your own Amazon.
[00:26:03.820 --> 00:26:04.660]   - Yeah. - Right?
[00:26:04.660 --> 00:26:07.300]   - Yes, well, so that's a very shallow statement,
[00:26:07.300 --> 00:26:10.660]   but it's also one that has some legitimacy.
[00:26:10.660 --> 00:26:12.380]   We can't completely dismiss it
[00:26:12.380 --> 00:26:16.720]   because there's levels to this game.
[00:26:16.720 --> 00:26:19.980]   - Yes and no, but if you really wanted to chase that down,
[00:26:19.980 --> 00:26:22.460]   one of the great things about a person-to-person conversation
[00:26:22.460 --> 00:26:25.740]   as opposed to like, let's have 30 of our closest friends,
[00:26:25.740 --> 00:26:26.740]   whenever we have a conversation
[00:26:26.740 --> 00:26:29.200]   with 30 of our closest friends, you know what happens?
[00:26:29.200 --> 00:26:31.600]   It's like passing light through a prism.
[00:26:31.600 --> 00:26:34.440]   Every person says something interesting.
[00:26:34.440 --> 00:26:36.660]   And as a result, it's always muddled.
[00:26:36.660 --> 00:26:38.440]   Like nothing ever resolves.
[00:26:38.440 --> 00:26:41.500]   - Well, one of my conversational techniques
[00:26:41.500 --> 00:26:44.180]   you mentioned you pushed back is,
[00:26:44.180 --> 00:26:49.180]   first, is childlike naivety and curiosity, but also--
[00:26:49.180 --> 00:26:50.260]   - Real or simulated?
[00:26:50.260 --> 00:26:51.540]   - Real, I'm afraid.
[00:26:51.540 --> 00:26:53.260]   - I would say 80% real.
[00:26:53.260 --> 00:26:56.500]   All right, so in this paradigm,
[00:26:56.500 --> 00:26:58.140]   how could you not see this coming?
[00:26:58.140 --> 00:27:01.820]   I mean, I did a show with Ashley Matthews,
[00:27:01.820 --> 00:27:03.900]   who's the woman behind Riley Reid,
[00:27:03.900 --> 00:27:05.460]   and specifically about this.
[00:27:05.460 --> 00:27:08.740]   It was about the idea that if I move away from politics
[00:27:08.740 --> 00:27:13.180]   and go towards sex, I know that there's always a move
[00:27:13.180 --> 00:27:18.180]   to use the infrastructure to shut down sex workers.
[00:27:18.180 --> 00:27:21.860]   And in this case, we had Operation Chokepoint
[00:27:21.860 --> 00:27:25.060]   under the Obama administration.
[00:27:25.060 --> 00:27:28.520]   We have a positive passion for people
[00:27:28.520 --> 00:27:32.060]   who want to solve problems that they don't like this company,
[00:27:32.060 --> 00:27:33.020]   they don't like that company,
[00:27:33.020 --> 00:27:35.300]   payday loans would be another one.
[00:27:35.300 --> 00:27:38.300]   And so you have legal companies that are harassed
[00:27:38.300 --> 00:27:41.060]   by our financial system that you can't,
[00:27:41.060 --> 00:27:46.820]   as Riley Reid, Ashley couldn't get a MailChimp account,
[00:27:46.820 --> 00:27:49.380]   according to her, if I understand her correctly.
[00:27:49.380 --> 00:27:53.380]   And this idea that you charge these people higher rates
[00:27:53.380 --> 00:27:56.740]   because of supposed chargebacks on credit cards,
[00:27:56.740 --> 00:27:59.060]   even if their chargebacks are low,
[00:27:59.060 --> 00:28:02.820]   yes, we have an unofficial policy of harassment.
[00:28:02.820 --> 00:28:05.980]   There's something about everybody who shows up at Davos,
[00:28:05.980 --> 00:28:09.320]   they get drunk in the Swiss Alps,
[00:28:09.320 --> 00:28:12.640]   and then they come back home and they coordinate,
[00:28:12.640 --> 00:28:15.340]   and they coordinate things like Build Back Better.
[00:28:15.340 --> 00:28:17.100]   We don't really understand what Build Back Better is,
[00:28:17.100 --> 00:28:19.380]   but my guess is that Build Back Better
[00:28:19.380 --> 00:28:21.820]   has to do with extremism in America.
[00:28:21.820 --> 00:28:24.300]   How do we shut down the Republican Party
[00:28:24.300 --> 00:28:26.420]   as the source of extremism?
[00:28:26.420 --> 00:28:28.100]   Now, I do think the Republican Party
[00:28:28.100 --> 00:28:29.900]   was cut very extreme under Trump.
[00:28:29.900 --> 00:28:32.520]   And I do believe that that was responsive
[00:28:32.520 --> 00:28:35.980]   to how extreme the Democratic Party got
[00:28:35.980 --> 00:28:40.980]   under Clinton first, and then Obama, and then Hillary.
[00:28:40.980 --> 00:28:44.940]   And in all of these circumstances,
[00:28:44.940 --> 00:28:46.500]   it's amazing how much we want
[00:28:46.500 --> 00:28:48.780]   to wield these things as weapons.
[00:28:48.780 --> 00:28:50.740]   Well, our extremism is fine,
[00:28:50.740 --> 00:28:53.100]   because we pretend that Antifa doesn't exist,
[00:28:53.100 --> 00:28:55.740]   and we don't report what goes on in Portland.
[00:28:55.740 --> 00:28:59.540]   But your extremism, my God, that's disgusting.
[00:28:59.540 --> 00:29:02.300]   This is the completely ridiculous place that we're in.
[00:29:02.300 --> 00:29:06.120]   And by the way, our friends, in part,
[00:29:06.120 --> 00:29:08.860]   are coked up on tech money,
[00:29:08.860 --> 00:29:12.580]   and they don't appear to hold the courage
[00:29:12.580 --> 00:29:14.460]   of their convictions at a political level,
[00:29:14.460 --> 00:29:18.140]   because it's not in keeping with shareholder value.
[00:29:18.140 --> 00:29:21.180]   At some level, shareholder value is the ultimate shield
[00:29:21.180 --> 00:29:24.840]   with which everyone can cloak themselves.
[00:29:24.840 --> 00:29:29.840]   - Well, on that point, Donald Trump was banned from Twitter,
[00:29:31.060 --> 00:29:33.460]   and I'm not sure it was a good financial decision
[00:29:33.460 --> 00:29:35.140]   for Twitter, right?
[00:29:35.140 --> 00:29:38.900]   Perhaps you can correct me if I'm wrong.
[00:29:38.900 --> 00:29:40.060]   - Well, are you thinking locally,
[00:29:40.060 --> 00:29:41.660]   or are you thinking if Twitter refused to--
[00:29:41.660 --> 00:29:42.500]   - Long term.
[00:29:42.500 --> 00:29:44.900]   - Well, if Twitter refused to ban Donald Trump,
[00:29:44.900 --> 00:29:47.260]   what is the odds that the full force
[00:29:47.260 --> 00:29:49.060]   of the antitrust division might find them?
[00:29:49.060 --> 00:29:50.540]   I don't know. - Oh, I see, I see.
[00:29:50.540 --> 00:29:52.540]   So there's a complicated thing.
[00:29:52.540 --> 00:29:54.900]   - Well, there's a, look, these guys are all having
[00:29:54.900 --> 00:29:57.860]   a discussion in very practical terms.
[00:29:57.860 --> 00:29:58.700]   You know, you can say,
[00:29:58.700 --> 00:30:01.320]   you can imagine the sorts of conversation.
[00:30:01.320 --> 00:30:03.940]   Jack, Mark, Sunder, we're really glad you're all here.
[00:30:03.940 --> 00:30:06.300]   We're all trying to sing from the same hymnal
[00:30:06.300 --> 00:30:08.740]   and row in the same direction.
[00:30:08.740 --> 00:30:09.800]   We understand free speech.
[00:30:09.800 --> 00:30:11.160]   We're completely committed to it,
[00:30:11.160 --> 00:30:13.740]   but we have to draw along with extremism, guys.
[00:30:13.740 --> 00:30:16.220]   We just need, we need to make sure
[00:30:16.220 --> 00:30:17.340]   that we're all on the same page.
[00:30:17.340 --> 00:30:19.340]   - Well, they use the term violence, too,
[00:30:19.340 --> 00:30:21.900]   and they, I think, over-apply it.
[00:30:21.900 --> 00:30:23.500]   So basically, anybody--
[00:30:23.500 --> 00:30:25.740]   (laughing)
[00:30:27.940 --> 00:30:31.060]   - I'm telling you, I say dumb things
[00:30:31.060 --> 00:30:34.340]   to incentivize thoughtful conversation.
[00:30:34.340 --> 00:30:36.180]   - Well, whatever these things are,
[00:30:36.180 --> 00:30:39.740]   there is no trace, like, how old are you, Lex?
[00:30:39.740 --> 00:30:41.260]   You're in your mid-30s?
[00:30:41.260 --> 00:30:43.280]   - Yeah, to late 40s.
[00:30:43.280 --> 00:30:45.540]   - Mid, late 20s to late 40s.
[00:30:45.540 --> 00:30:46.380]   - Yeah. - Somewhere in there.
[00:30:46.380 --> 00:30:47.700]   - That's the demographic, yeah.
[00:30:47.700 --> 00:30:49.580]   - I do think that partially what's happened is
[00:30:49.580 --> 00:30:52.900]   is that your group has never seen functional institutions.
[00:30:52.900 --> 00:30:55.700]   These institutions have been so compromised for so long.
[00:30:56.660 --> 00:30:58.500]   You've probably never seen an adult.
[00:30:58.500 --> 00:31:01.780]   Sometimes I think Elon looks like an adult.
[00:31:01.780 --> 00:31:05.420]   I know that he has a wild lifestyle,
[00:31:05.420 --> 00:31:07.900]   but I also see it looking like an adult.
[00:31:07.900 --> 00:31:09.380]   - What does an adult look like, exactly?
[00:31:09.380 --> 00:31:11.940]   - Oh, you know, somebody who weighs things,
[00:31:11.940 --> 00:31:14.180]   speaks carefully, thinks about the future
[00:31:14.180 --> 00:31:17.220]   beyond their own lifespan.
[00:31:17.220 --> 00:31:19.100]   Somebody who has a pretty good idea
[00:31:19.100 --> 00:31:21.260]   of how to get things done,
[00:31:21.260 --> 00:31:23.940]   isn't wildly caught up in punitive actions,
[00:31:23.940 --> 00:31:26.460]   is more focused on breaking new ground
[00:31:26.460 --> 00:31:29.100]   than playing rent-seeking games.
[00:31:29.100 --> 00:31:31.180]   I mean, I really had a positive,
[00:31:31.180 --> 00:31:34.260]   I was so completely jazzed when Elon Musk
[00:31:34.260 --> 00:31:36.220]   ended up as the world's richest person.
[00:31:36.220 --> 00:31:39.740]   He was like, "Well, that's interesting, back to work."
[00:31:39.740 --> 00:31:42.540]   It's just like, that's what an adult would do.
[00:31:42.540 --> 00:31:43.660]   That's what a grownup would do.
[00:31:43.660 --> 00:31:45.220]   And it just made, you know,
[00:31:45.220 --> 00:31:46.460]   weirdly I said something about,
[00:31:46.460 --> 00:31:49.220]   "Isn't it amazing that the world's richest person
[00:31:49.220 --> 00:31:50.540]   "knows what a Lagrangian is?"
[00:31:50.540 --> 00:31:54.260]   And he made a terrible Lagrange joke about potentials.
[00:31:54.260 --> 00:31:57.180]   But yeah, I mean, I do think that ultimately,
[00:31:57.180 --> 00:32:00.140]   Elon may be one of the closest things we have to an adult.
[00:32:00.140 --> 00:32:02.060]   And I can tell you that the internet hyenas
[00:32:02.060 --> 00:32:05.040]   will immediately descend as to what a fraudster he is
[00:32:05.040 --> 00:32:06.380]   for pumping his stock price,
[00:32:06.380 --> 00:32:08.260]   talking his book and all this stuff.
[00:32:08.260 --> 00:32:09.540]   Shut up.
[00:32:09.540 --> 00:32:12.180]   - So looking at the world seriously and rigorously,
[00:32:12.180 --> 00:32:15.940]   you're saying that the people who are running tech companies
[00:32:15.940 --> 00:32:20.940]   are running the mediums on which we can exercise
[00:32:20.940 --> 00:32:23.860]   the ideal of free speech are not adults.
[00:32:24.540 --> 00:32:25.380]   - I think not.
[00:32:25.380 --> 00:32:26.200]   I think first of all,
[00:32:26.200 --> 00:32:30.620]   a lot of them are Silicon Valley utopian businessmen
[00:32:30.620 --> 00:32:33.660]   where you talk a utopian line and you use it.
[00:32:33.660 --> 00:32:34.980]   You've heard my take,
[00:32:34.980 --> 00:32:38.660]   which is that the idealism of every era
[00:32:38.660 --> 00:32:41.180]   is the cover story of its greatest thefts.
[00:32:41.180 --> 00:32:42.980]   And I believe that in many ways,
[00:32:42.980 --> 00:32:44.420]   the idealism of Silicon Valley,
[00:32:44.420 --> 00:32:46.460]   about connecting the world, a world of abundance,
[00:32:46.460 --> 00:32:47.860]   et cetera, et cetera, et cetera,
[00:32:47.860 --> 00:32:51.900]   is really about the software eating the world
[00:32:51.900 --> 00:32:53.300]   as Marc Andreessen likes to say,
[00:32:53.300 --> 00:32:55.020]   at the role of these legacy properties.
[00:32:55.020 --> 00:32:58.700]   And by simply being a bad tech version
[00:32:58.700 --> 00:33:03.220]   of something that previously existed like a newspaper,
[00:33:03.220 --> 00:33:05.740]   you could immediately start to dwarf that
[00:33:05.740 --> 00:33:08.100]   by aggregating newspapers and their digital versions
[00:33:08.100 --> 00:33:10.420]   because digital is so much more powerful.
[00:33:10.420 --> 00:33:15.060]   As a result, yes, we have lots of man children
[00:33:15.060 --> 00:33:18.100]   wandering around what once was the Bay Area
[00:33:18.100 --> 00:33:20.680]   and is now Austin and Miami and other places,
[00:33:22.100 --> 00:33:27.100]   and maybe Singapore, that all of these people,
[00:33:27.100 --> 00:33:29.740]   these are friends of ours and they're brilliant
[00:33:29.740 --> 00:33:32.380]   with respect to a certain amount of stuff,
[00:33:32.380 --> 00:33:34.360]   but none of them can get off the drip.
[00:33:34.360 --> 00:33:37.220]   It's amazing that none of them have FU money.
[00:33:37.220 --> 00:33:39.820]   We've got billionaires who don't have FU money.
[00:33:39.820 --> 00:33:43.020]   - Okay, I think the argument used by Jack Dorsey
[00:33:43.020 --> 00:33:45.820]   was that there was an incitement of violence,
[00:33:45.820 --> 00:33:48.100]   and not just Jack Dorsey, but everybody
[00:33:48.100 --> 00:33:50.180]   that was banning people.
[00:33:50.180 --> 00:33:52.220]   And then this word violence was used
[00:33:52.220 --> 00:33:56.420]   as a kind of just like extremism and so on
[00:33:56.420 --> 00:33:59.200]   without much reason behind it.
[00:33:59.200 --> 00:34:01.620]   You think it's impossible for Jack Dorsey
[00:34:01.620 --> 00:34:04.180]   or anybody else to be, as you said,
[00:34:04.180 --> 00:34:06.260]   an adult, a grown up and reason--
[00:34:06.260 --> 00:34:07.900]   - Well, Jack is pretty close to being a grown up.
[00:34:07.900 --> 00:34:09.100]   - It seems like he is.
[00:34:09.100 --> 00:34:11.600]   He's-- - But he's under pressures.
[00:34:11.600 --> 00:34:15.080]   - As you've discussed, it seems that he's been
[00:34:15.080 --> 00:34:18.140]   on the verge of almost being quite serious
[00:34:18.140 --> 00:34:18.980]   and transparent and real with people.
[00:34:19.380 --> 00:34:22.300]   - I don't know where the Jack Dorsey that I met went.
[00:34:22.300 --> 00:34:26.660]   And I worry that that must be something
[00:34:26.660 --> 00:34:29.180]   behind the scenes that I can't see.
[00:34:29.180 --> 00:34:32.740]   - From my perspective, what I think is the stress,
[00:34:32.740 --> 00:34:37.420]   the burden of that when people are screaming at you,
[00:34:37.420 --> 00:34:39.580]   it's overwhelming. - Jack is a Zen monk.
[00:34:39.580 --> 00:34:41.400]   He really is.
[00:34:41.400 --> 00:34:45.440]   Jack is an incredibly impressive person,
[00:34:46.340 --> 00:34:49.700]   intellectually, morally, spiritually,
[00:34:49.700 --> 00:34:52.820]   at least for a couple of meetings.
[00:34:52.820 --> 00:34:54.220]   I don't know him very well.
[00:34:54.220 --> 00:34:57.820]   But I'm very impressed by the person I met,
[00:34:57.820 --> 00:34:59.300]   and I don't know where that person is,
[00:34:59.300 --> 00:35:00.520]   and that terrifies me.
[00:35:00.520 --> 00:35:04.620]   - But do you think somebody could step up in that way?
[00:35:04.620 --> 00:35:05.820]   - No.
[00:35:05.820 --> 00:35:09.540]   - So does a human being have the capacity
[00:35:09.540 --> 00:35:14.260]   to be transparent about the reasoning behind the banning?
[00:35:14.260 --> 00:35:16.620]   Or do you think all banning eventually,
[00:35:16.620 --> 00:35:22.500]   all banning of people from mediums of communication
[00:35:22.500 --> 00:35:25.280]   is eventually destructive, or it's impossible
[00:35:25.280 --> 00:35:27.980]   for human beings to reason with ourselves about it?
[00:35:27.980 --> 00:35:31.020]   - Well, let's see what the problem is.
[00:35:31.020 --> 00:35:33.380]   So my phone has been on airplane mode.
[00:35:33.380 --> 00:35:34.440]   I'm gonna unlock it.
[00:35:34.440 --> 00:35:38.520]   I'm gonna take a picture of Lex Fridman.
[00:35:38.520 --> 00:35:43.340]   Now, if I can, I'm gonna tweet that picture out.
[00:35:43.340 --> 00:35:44.180]   - Great.
[00:35:44.180 --> 00:35:45.380]   - But here's the weird part about it.
[00:35:45.380 --> 00:35:46.820]   - Yeah.
[00:35:46.820 --> 00:35:47.820]   - That picture,
[00:35:47.820 --> 00:35:54.180]   sitting with Lex today.
[00:35:54.180 --> 00:35:58.660]   - This, ladies and gentlemen, is how the sausage is made.
[00:35:58.660 --> 00:36:00.420]   - Okay, in so doing,
[00:36:00.420 --> 00:36:06.980]   I have just sent a picture of you
[00:36:06.980 --> 00:36:10.500]   and a tiny piece of text all over the planet
[00:36:10.500 --> 00:36:15.080]   that has arrived at, if statistics tell the truth,
[00:36:15.080 --> 00:36:17.480]   just under half a million different accounts.
[00:36:17.480 --> 00:36:21.820]   - And then more from sharing and so on.
[00:36:21.820 --> 00:36:23.940]   - And we have, well, and some of those accounts are dead.
[00:36:23.940 --> 00:36:25.940]   We don't really know how many places it went.
[00:36:25.940 --> 00:36:27.460]   - Yeah.
[00:36:27.460 --> 00:36:29.840]   - But the key issue with that tweet
[00:36:29.840 --> 00:36:33.700]   is that that is a non-local phenomenon.
[00:36:33.700 --> 00:36:35.620]   - Yes.
[00:36:35.620 --> 00:36:40.500]   - So I just broadcasted to an entire planet.
[00:36:40.500 --> 00:36:42.620]   Somebody in Uganda is reading that
[00:36:42.620 --> 00:36:44.620]   at the same time as somebody in Uruguay.
[00:36:44.620 --> 00:36:51.040]   There is no known solution to have so many people
[00:36:51.040 --> 00:36:55.060]   with the ability to communicate non-locally
[00:36:55.060 --> 00:36:58.500]   because locality was part of the implicit nature of speech
[00:36:58.500 --> 00:36:59.840]   inside of the Constitution.
[00:36:59.840 --> 00:37:01.020]   Friction, locality,
[00:37:01.020 --> 00:37:04.120]   there were all sorts of other aspects to speech.
[00:37:04.120 --> 00:37:06.180]   So if you think about speech as a bundle,
[00:37:06.180 --> 00:37:09.740]   I like this,
[00:37:09.740 --> 00:37:12.820]   then it got unbundled.
[00:37:12.820 --> 00:37:17.020]   And some of those aspects that we were naturally counting on
[00:37:17.020 --> 00:37:22.020]   to retard the impact of speech aren't present.
[00:37:22.020 --> 00:37:23.940]   And we don't have the courage to say,
[00:37:23.940 --> 00:37:26.920]   I wonder if the First Amendment really applies
[00:37:26.920 --> 00:37:28.840]   in the modern era in the same way,
[00:37:28.840 --> 00:37:30.780]   or we have to work through an abstraction.
[00:37:30.780 --> 00:37:33.080]   Either we probably have to amend the Constitution
[00:37:33.080 --> 00:37:34.820]   or we have to abstract it properly.
[00:37:34.820 --> 00:37:40.560]   And that issue is not something we're facing up to.
[00:37:40.560 --> 00:37:44.820]   I watch us constantly look backwards.
[00:37:44.820 --> 00:37:48.800]   We don't seem to try to come up with new ideas
[00:37:48.800 --> 00:37:49.640]   and new theories.
[00:37:49.640 --> 00:37:52.320]   Nobody really imagines that we're going to be able
[00:37:52.320 --> 00:37:54.740]   to wisely amend the Constitution anymore
[00:37:54.740 --> 00:37:56.180]   in the inside of the United States.
[00:37:56.180 --> 00:37:57.760]   Many people abroad will say,
[00:37:57.760 --> 00:37:59.400]   why are these guys talking about the US?
[00:37:59.400 --> 00:38:01.100]   It's a US-centric program.
[00:38:01.100 --> 00:38:04.100]   Well, that's because nobody knows where this program lives.
[00:38:04.100 --> 00:38:06.860]   The fact, by the way, that you and I happen to be
[00:38:06.860 --> 00:38:10.200]   in a physical place together is also bizarre.
[00:38:10.200 --> 00:38:11.040]   It could be anywhere.
[00:38:11.040 --> 00:38:13.740]   It doesn't really matter that it happens to be here.
[00:38:13.740 --> 00:38:16.080]   So the difference between logical and between physical,
[00:38:16.080 --> 00:38:18.820]   local, non-local, frictional, non-frictional,
[00:38:18.820 --> 00:38:21.540]   it's the same thing with firearms.
[00:38:21.540 --> 00:38:25.660]   Nobody imagined that the gatling gun
[00:38:25.660 --> 00:38:28.460]   was going to be present when you had to reload a musket.
[00:38:29.460 --> 00:38:33.460]   - And that's fascinating to think about.
[00:38:33.460 --> 00:38:37.220]   I mean, you're exactly right that the nature
[00:38:37.220 --> 00:38:39.860]   of this particular freedom that seems so foundational
[00:38:39.860 --> 00:38:44.220]   to this nation, to what made this nation great
[00:38:44.220 --> 00:38:47.760]   and perhaps much of the world that is great made it great,
[00:38:47.760 --> 00:38:49.460]   is changing completely.
[00:38:49.460 --> 00:38:52.100]   Can we try to reason through how the ideal freedom
[00:38:52.100 --> 00:38:54.220]   of speech is to be changed?
[00:38:54.220 --> 00:38:57.620]   I mean, I guess I'm struggling.
[00:38:57.620 --> 00:39:00.860]   It feels really wrong, perhaps because I wasn't
[00:39:00.860 --> 00:39:02.740]   paying attention to it, it feels really wrong
[00:39:02.740 --> 00:39:06.900]   to ban Donald Trump from Twitter,
[00:39:06.900 --> 00:39:10.900]   to ban not just the president, that's really wrong to me,
[00:39:10.900 --> 00:39:15.540]   but this particular human for being divisive.
[00:39:15.540 --> 00:39:19.140]   But then when there's an incitement of violence,
[00:39:19.140 --> 00:39:25.420]   that is an overused claim, but perhaps there was
[00:39:26.860 --> 00:39:31.620]   actual brewing of local violence happening.
[00:39:31.620 --> 00:39:34.260]   So one of the things I know was happening on Parlor
[00:39:34.260 --> 00:39:39.260]   is people were scheduling meetings together
[00:39:39.260 --> 00:39:40.420]   in physical space.
[00:39:40.420 --> 00:39:45.420]   So you're now going back from this dynamic,
[00:39:45.420 --> 00:39:48.340]   social, large-scale, people from Uganda,
[00:39:48.340 --> 00:39:51.400]   people from all over the world being able to communicate,
[00:39:51.400 --> 00:39:54.060]   you're now mapping that into now back meeting
[00:39:54.060 --> 00:39:57.300]   in the physical space that is similar
[00:39:57.300 --> 00:39:58.140]   to what the founding of this nation was.
[00:39:58.140 --> 00:40:00.620]   - But if the violence were digital,
[00:40:00.620 --> 00:40:03.520]   if ransomware suddenly was unleashed,
[00:40:03.520 --> 00:40:07.360]   the key issue is the abstractions.
[00:40:07.360 --> 00:40:09.800]   So what was freedom of speech as a bundle?
[00:40:09.800 --> 00:40:12.040]   - And now it's--
[00:40:12.040 --> 00:40:14.540]   - And then how do we abstract the bundle
[00:40:14.540 --> 00:40:16.680]   into the digital era?
[00:40:16.680 --> 00:40:18.500]   - Do you think we just need to raise the question
[00:40:18.500 --> 00:40:19.340]   and talk about it?
[00:40:19.340 --> 00:40:20.540]   Do you have ideas?
[00:40:20.540 --> 00:40:22.980]   - Well, sure I have ideas, but the key point is
[00:40:22.980 --> 00:40:25.440]   that I'm not even welcome in mainstream media.
[00:40:25.440 --> 00:40:28.340]   I've never seen you on mainstream media.
[00:40:28.340 --> 00:40:29.540]   Do you do mainstream media?
[00:40:29.540 --> 00:40:32.460]   So we exist in part of an alternate universe
[00:40:32.460 --> 00:40:34.740]   because the mainstream media is trying
[00:40:34.740 --> 00:40:36.900]   to have a coherent story,
[00:40:36.900 --> 00:40:39.420]   which I've called the gated institutional narrative.
[00:40:39.420 --> 00:40:42.820]   And the institutions pretend that they plug their fingers
[00:40:42.820 --> 00:40:46.100]   in their ears and pretend that nothing exists outside
[00:40:46.100 --> 00:40:49.340]   of MSNBC talking to CNN about what was
[00:40:49.340 --> 00:40:52.820]   in the New York Times as covered by the Washington Post.
[00:40:52.820 --> 00:40:54.180]   And so that's effectively
[00:40:54.180 --> 00:40:57.180]   like a professional wrestling promotion where they,
[00:40:57.180 --> 00:40:59.820]   the Undertaker faces off against Hulk Hogan
[00:40:59.820 --> 00:41:01.820]   and Rowdy Roddy Piper.
[00:41:01.820 --> 00:41:05.900]   Okay, well, that's very different than MMA.
[00:41:05.900 --> 00:41:08.780]   - You've recently been on a Glenn Beck's program.
[00:41:08.780 --> 00:41:09.740]   - Yeah.
[00:41:09.740 --> 00:41:12.860]   - And there was this kind of one of the things
[00:41:12.860 --> 00:41:16.680]   you've talked about is being able to have this conversation.
[00:41:16.680 --> 00:41:20.100]   I don't know if you would put it as a type
[00:41:20.100 --> 00:41:21.740]   of conversation that was happening outside
[00:41:21.740 --> 00:41:22.940]   of the mainstream media,
[00:41:22.940 --> 00:41:27.820]   but a conversation that reaches across different worldviews.
[00:41:27.820 --> 00:41:28.660]   - You're right.
[00:41:28.660 --> 00:41:33.340]   - Having a nuanced or just like a respectful conversation
[00:41:33.340 --> 00:41:35.260]   that's grounded in mutual.
[00:41:35.260 --> 00:41:36.460]   - But we can't have the reality
[00:41:36.460 --> 00:41:41.460]   because the main model is the center, both left and right,
[00:41:41.460 --> 00:41:44.340]   is in the process of stealing all the wealth
[00:41:44.340 --> 00:41:45.280]   that we built up.
[00:41:45.280 --> 00:41:48.900]   And they've organized the extremes
[00:41:48.900 --> 00:41:50.940]   into two LARPing teams that I've called
[00:41:50.940 --> 00:41:53.140]   Magistan and Wokistan.
[00:41:53.140 --> 00:41:56.980]   And then you have everybody who isn't part of that complex,
[00:41:56.980 --> 00:41:58.260]   all seven of us.
[00:41:58.260 --> 00:42:00.780]   The number of us who are able to earn a living,
[00:42:00.780 --> 00:42:04.380]   looking at all of these mad people playing this game.
[00:42:04.380 --> 00:42:09.500]   There's a phrase inside finance when the investment banks
[00:42:09.500 --> 00:42:12.540]   are trying to look at price action.
[00:42:12.540 --> 00:42:14.900]   And somebody says, this doesn't make any sense.
[00:42:14.900 --> 00:42:15.740]   And somebody will say,
[00:42:15.740 --> 00:42:17.780]   it's just the locals stealing from each other.
[00:42:17.780 --> 00:42:20.020]   And that's really what we have.
[00:42:20.020 --> 00:42:22.800]   We've got the leaders of Magistan and Wokistan,
[00:42:22.800 --> 00:42:27.020]   championing these two teams as sponsored by the center
[00:42:27.020 --> 00:42:29.340]   because it's a distraction while they steal all the silver
[00:42:29.340 --> 00:42:31.460]   and cut the paintings out of the frames.
[00:42:31.460 --> 00:42:33.660]   That's what you and I are looking at.
[00:42:33.660 --> 00:42:35.460]   So when you ask me, do you have any ideas
[00:42:35.460 --> 00:42:37.360]   about the abstraction for free speech?
[00:42:37.360 --> 00:42:41.260]   I've never met Mark Zuckerberg.
[00:42:41.260 --> 00:42:43.260]   I've never met Sundar Pichai.
[00:42:43.260 --> 00:42:45.140]   I never met Larry Page.
[00:42:45.140 --> 00:42:47.500]   I was once in a room with Sergey Brin.
[00:42:47.500 --> 00:42:49.600]   I've never spoken to Elon Musk.
[00:42:49.600 --> 00:42:52.140]   I hang out with Peter Thiel,
[00:42:52.140 --> 00:42:54.400]   but we have a very deep relationship,
[00:42:54.400 --> 00:42:58.660]   but I don't really speak to that many other people
[00:42:58.660 --> 00:43:00.380]   sort of at this level.
[00:43:00.380 --> 00:43:04.180]   We're not having any kind of smart conversation
[00:43:04.180 --> 00:43:05.500]   at a national level.
[00:43:05.500 --> 00:43:10.500]   In fact, it's almost as if we've destroyed every sandbox
[00:43:10.500 --> 00:43:13.260]   in which we could play together.
[00:43:13.260 --> 00:43:15.700]   There's no place that we actually talk
[00:43:15.700 --> 00:43:18.140]   except long form podcasting.
[00:43:18.140 --> 00:43:20.240]   And by the way, they've found,
[00:43:20.240 --> 00:43:23.180]   you see what's going on with like Alex Stamos
[00:43:23.180 --> 00:43:25.200]   and the Hoover Institution.
[00:43:25.200 --> 00:43:28.100]   There's a loophole left.
[00:43:28.100 --> 00:43:31.660]   Long form podcasting allows people to speak
[00:43:31.660 --> 00:43:34.220]   at levels above daytime CNN.
[00:43:34.220 --> 00:43:35.880]   It's like, well, why do you think
[00:43:35.880 --> 00:43:37.680]   they're not watching daytime CNN?
[00:43:37.680 --> 00:43:42.180]   - But that's just silly journalism.
[00:43:42.180 --> 00:43:45.900]   They currently have no power to displace podcasting.
[00:43:45.900 --> 00:43:47.740]   That's why it's so powerful, RSS feed.
[00:43:47.740 --> 00:43:50.300]   I mean, that's why the big challenge with Joe Rogan
[00:43:50.300 --> 00:43:52.500]   and Spotify is like there's this dance
[00:43:52.500 --> 00:43:54.220]   that's fascinating to see.
[00:43:54.220 --> 00:43:57.980]   Joe Rogan is now part of the system,
[00:43:57.980 --> 00:44:00.660]   and then he's also uncancellable.
[00:44:00.660 --> 00:44:03.620]   And there's this tension that's happening.
[00:44:03.620 --> 00:44:05.420]   - Well, think about what happened to Howard Stern.
[00:44:05.420 --> 00:44:07.640]   Howard Stern became much less relevant.
[00:44:08.940 --> 00:44:13.220]   So if they can't control Joe by bringing him in-house,
[00:44:13.220 --> 00:44:16.800]   the key question is, is he going to continue?
[00:44:16.800 --> 00:44:20.840]   Joe says this thing about FU money.
[00:44:20.840 --> 00:44:24.380]   Joe's one of the only people with FU money
[00:44:24.380 --> 00:44:26.160]   who's actually said FU.
[00:44:26.160 --> 00:44:30.580]   I don't understand this.
[00:44:30.580 --> 00:44:32.100]   I don't have FU money.
[00:44:32.100 --> 00:44:36.420]   - What exactly is, can we break apart FU money?
[00:44:36.420 --> 00:44:40.460]   Because I always thought I've been fortunate enough
[00:44:40.460 --> 00:44:45.020]   to always have FU money in the sense
[00:44:45.020 --> 00:44:47.020]   that my standards were so low
[00:44:47.020 --> 00:44:49.060]   that a basic salary in the United States--
[00:44:49.060 --> 00:44:50.300]   - This is the stoic point,
[00:44:50.300 --> 00:44:53.020]   which is if you can live on rice and beans,
[00:44:53.020 --> 00:44:54.980]   you're uncancellable because you're always rich
[00:44:54.980 --> 00:44:56.220]   relative to your need side.
[00:44:56.220 --> 00:44:57.940]   - Isn't that FU, fundamental FU money?
[00:44:57.940 --> 00:45:01.540]   Why do you say that tech billionaires don't have FU money?
[00:45:01.540 --> 00:45:03.600]   - When you need to hire private security
[00:45:03.600 --> 00:45:05.080]   to protect your family,
[00:45:05.080 --> 00:45:07.020]   how do you protect your two children?
[00:45:07.020 --> 00:45:08.060]   - I don't have those yet.
[00:45:08.060 --> 00:45:08.900]   - Bingo.
[00:45:08.900 --> 00:45:11.820]   My point is that FU money
[00:45:11.820 --> 00:45:15.480]   insulates everything that you care about.
[00:45:15.480 --> 00:45:17.380]   It's not just about you.
[00:45:17.380 --> 00:45:20.940]   - So you're saying as the level of responsibility grows,
[00:45:20.940 --> 00:45:24.620]   the amount of money required for FU--
[00:45:24.620 --> 00:45:26.060]   - We have a war going on.
[00:45:26.060 --> 00:45:28.660]   The war is on academic freedom.
[00:45:28.660 --> 00:45:31.540]   Academic freedom used to be present in the system
[00:45:31.540 --> 00:45:35.820]   as in terms of the idea we trust our elite.
[00:45:35.820 --> 00:45:39.420]   Now we have an idea like, you wanna be the elite.
[00:45:39.420 --> 00:45:40.980]   You wanna lord above us.
[00:45:40.980 --> 00:45:43.940]   First of all, there's a populist anti-elitist thing.
[00:45:43.940 --> 00:45:45.300]   Then there's the idea that
[00:45:45.300 --> 00:45:48.620]   we're gonna defer tenure for forever.
[00:45:48.620 --> 00:45:50.220]   Then we're gonna tell people stay in your lane.
[00:45:50.220 --> 00:45:51.980]   Your tenure is only good for your own
[00:45:51.980 --> 00:45:54.680]   particular tiny micro subject.
[00:45:54.680 --> 00:45:56.500]   Then we're gonna also control your grants
[00:45:56.500 --> 00:45:59.000]   and we'll be able to load up your teaching load
[00:45:59.000 --> 00:46:00.160]   if we don't like who you are.
[00:46:00.160 --> 00:46:03.480]   We'll make your life absolutely impossible.
[00:46:03.480 --> 00:46:05.280]   We lost academic freedom.
[00:46:05.280 --> 00:46:09.800]   And we ushered in peer review, which was a disaster.
[00:46:09.800 --> 00:46:14.600]   And then we lost funding so that people were confident
[00:46:14.600 --> 00:46:17.280]   that they would have the ability to do research
[00:46:17.280 --> 00:46:18.520]   no matter what they said.
[00:46:18.520 --> 00:46:22.480]   And as a result, what you find is a world
[00:46:22.480 --> 00:46:25.720]   in which there's no ability to get people to say,
[00:46:25.720 --> 00:46:28.480]   no, I'm not gonna sign your diversity and inclusion
[00:46:28.480 --> 00:46:30.320]   forced loyalty oath.
[00:46:30.320 --> 00:46:32.160]   I won't sign any loyalty oath.
[00:46:32.160 --> 00:46:33.680]   Get the hell out of my office.
[00:46:33.680 --> 00:46:36.400]   F you.
[00:46:36.400 --> 00:46:39.160]   - F you, and you're connecting money to that, but--
[00:46:39.160 --> 00:46:42.300]   - Well, my point is that academic freedom is,
[00:46:42.300 --> 00:46:46.320]   the whole idea behind it was that you will have
[00:46:46.320 --> 00:46:50.000]   the freedom of a billionaire on a much smaller salary.
[00:46:50.000 --> 00:46:50.940]   - Right.
[00:46:50.940 --> 00:46:51.780]   - Okay.
[00:46:51.780 --> 00:46:54.120]   - We've lost that.
[00:46:54.120 --> 00:46:58.320]   - Yeah, the only reason in part that I wanted to go into
[00:46:59.320 --> 00:47:04.080]   academics as a profession, as opposed to wanting to do
[00:47:04.080 --> 00:47:06.280]   physical or mathematical research,
[00:47:06.280 --> 00:47:09.560]   the great prize was freedom.
[00:47:09.560 --> 00:47:12.520]   And Ralph Gomory of the Sloan Foundation,
[00:47:12.520 --> 00:47:14.840]   previously of IBM Research, pointed it out.
[00:47:14.840 --> 00:47:18.680]   He says, if you lose freedom, you lose the only thing
[00:47:18.680 --> 00:47:20.440]   we had to offer top minds.
[00:47:20.440 --> 00:47:23.200]   Top minds value their intellectual freedom
[00:47:23.200 --> 00:47:26.140]   and their physical and economic security
[00:47:26.140 --> 00:47:29.240]   at a different level than other human beings.
[00:47:29.240 --> 00:47:33.480]   And so people say, you know, I don't understand, dude,
[00:47:33.480 --> 00:47:36.040]   you have the ability to do X, Y, and Z, what's the problem?
[00:47:36.040 --> 00:47:38.320]   It's like, well, I value my ability to raise
[00:47:38.320 --> 00:47:40.220]   the middle finger as an American,
[00:47:40.220 --> 00:47:43.200]   practically above everything else.
[00:47:43.200 --> 00:47:46.880]   - I wanna talk to you about freedom here
[00:47:46.880 --> 00:47:49.180]   in the context of something you've mentioned,
[00:47:49.180 --> 00:47:53.560]   which one way to take away freedom is to put
[00:47:53.560 --> 00:47:55.640]   a human being into a cage.
[00:47:55.640 --> 00:47:57.380]   So to create constraints.
[00:47:57.380 --> 00:47:59.060]   The other one that worries me is something
[00:47:59.060 --> 00:48:01.900]   that I think you've spoken to Twitter a little bit,
[00:48:01.900 --> 00:48:06.900]   on Twitter, is we bleed freedom
[00:48:06.900 --> 00:48:10.040]   by kind of slowly
[00:48:10.040 --> 00:48:16.620]   scaring you into not doing,
[00:48:16.620 --> 00:48:19.740]   not expressing the full spectrum of opportunities
[00:48:19.740 --> 00:48:20.580]   you can as freedom.
[00:48:20.580 --> 00:48:22.700]   So like, when you ban Donald Trump,
[00:48:24.000 --> 00:48:29.000]   when you ban Parler, you give a little doubt
[00:48:29.000 --> 00:48:31.020]   in the minds of millions, like me,
[00:48:31.020 --> 00:48:34.020]   a person who's a tech person, who's an entrepreneur,
[00:48:34.020 --> 00:48:37.740]   there's a little, that's what I'm afraid of
[00:48:37.740 --> 00:48:39.260]   when I look in the mirror, is there now
[00:48:39.260 --> 00:48:40.700]   a little doubt in there?
[00:48:40.700 --> 00:48:41.540]   - Sure.
[00:48:41.540 --> 00:48:43.780]   - That limits the amount of options I will try.
[00:48:43.780 --> 00:48:47.500]   - How certain are you that the COVID virus
[00:48:47.500 --> 00:48:52.140]   didn't come from the Wuhan lab and is biosafety level four?
[00:48:52.140 --> 00:48:55.880]   - We both know that we're both supposed to robotically say
[00:48:55.880 --> 00:48:59.600]   the idea that the COVID virus came from a lab
[00:48:59.600 --> 00:49:01.500]   is a discredited conspiracy theory.
[00:49:01.500 --> 00:49:03.760]   There is no evidence that suggests that this is true.
[00:49:03.760 --> 00:49:05.920]   The World Health Organization and the CDC
[00:49:05.920 --> 00:49:07.200]   have both opined this.
[00:49:07.200 --> 00:49:09.680]   To say otherwise would be incredibly irresponsible.
[00:49:09.680 --> 00:49:11.920]   - And the threat of that is the thing
[00:49:11.920 --> 00:49:16.780]   that ultimately limits the freedoms we feel.
[00:49:16.780 --> 00:49:19.540]   - I should be tweeting about Jeff Epstein all the time.
[00:49:19.540 --> 00:49:21.840]   - And you're afraid.
[00:49:21.840 --> 00:49:23.500]   - Well, it's also boring.
[00:49:23.500 --> 00:49:25.540]   I mean, I said it in the public.
[00:49:25.540 --> 00:49:26.380]   - Many times.
[00:49:26.380 --> 00:49:28.820]   - Why is it we don't ask where the records are
[00:49:28.820 --> 00:49:29.700]   from Villard House?
[00:49:29.700 --> 00:49:30.860]   Where are the financial records?
[00:49:30.860 --> 00:49:32.980]   Where are the SEC filings?
[00:49:32.980 --> 00:49:35.540]   Where are the questions on the record
[00:49:35.540 --> 00:49:39.220]   to the intelligence agencies?
[00:49:39.220 --> 00:49:42.360]   Was he known to be part of the intelligence community?
[00:49:42.360 --> 00:49:46.060]   So we're not interested in asking questions.
[00:49:46.060 --> 00:49:51.060]   Like, am I gonna die as a result of asking the question,
[00:49:51.180 --> 00:49:53.460]   was Jeff Epstein part of the intelligence community
[00:49:53.460 --> 00:49:54.980]   of any nation?
[00:49:54.980 --> 00:49:56.240]   Is there a reason we're not asking
[00:49:56.240 --> 00:49:58.480]   about the financial records of the supposed hedge fund
[00:49:58.480 --> 00:49:59.440]   that he didn't run?
[00:49:59.440 --> 00:50:02.900]   Just like the Wuhan lab.
[00:50:02.900 --> 00:50:05.580]   - Okay, how do we get to the core of the Jeffrey Epstein,
[00:50:05.580 --> 00:50:08.800]   the truth behind Jeffrey Epstein, in a sense?
[00:50:08.800 --> 00:50:10.860]   I mean, there's some things that are just like
[00:50:10.860 --> 00:50:12.740]   useless conspiracy theories around it,
[00:50:12.740 --> 00:50:13.720]   even if they're true.
[00:50:13.720 --> 00:50:14.560]   There's some things that get--
[00:50:14.560 --> 00:50:17.000]   - I hate to say it, you're not gonna like it.
[00:50:17.000 --> 00:50:20.600]   Look at the 1971 media Pennsylvania break-in
[00:50:20.600 --> 00:50:23.180]   of the Citizens Committee to investigate the FBI.
[00:50:23.180 --> 00:50:27.140]   Those kids, and by the way, they weren't all kids,
[00:50:27.140 --> 00:50:30.360]   did what had to be done.
[00:50:30.360 --> 00:50:33.760]   They broke in, they broke the law.
[00:50:33.760 --> 00:50:36.140]   It was an incredible act of civil disobedience.
[00:50:36.140 --> 00:50:40.240]   And God bless Judy Feingold for taking to her,
[00:50:40.240 --> 00:50:42.520]   she was going to take to her grave
[00:50:42.520 --> 00:50:43.640]   that she'd been part of this.
[00:50:43.640 --> 00:50:45.360]   Like, the coolest thing of all time.
[00:50:45.360 --> 00:50:47.600]   They didn't say anything for forever.
[00:50:47.600 --> 00:50:50.180]   - So civil disobedience, I mean, you have to--
[00:50:50.180 --> 00:50:52.320]   - We are founded on civil disobedience.
[00:50:52.320 --> 00:50:55.020]   Civil disobedience is incredibly,
[00:50:55.020 --> 00:50:59.880]   you screw it up and you're just a vandal.
[00:50:59.880 --> 00:51:01.560]   You screw it up, you're a hooligan.
[00:51:01.560 --> 00:51:02.400]   - Yeah.
[00:51:02.400 --> 00:51:06.260]   - Those cats were so disciplined.
[00:51:06.260 --> 00:51:07.100]   - It's an art form in a sense.
[00:51:07.100 --> 00:51:09.760]   - It was an art form and they risked everything.
[00:51:09.760 --> 00:51:12.680]   They were willing to pay with their freedom.
[00:51:12.680 --> 00:51:17.400]   Those are the sorts of people who earned the right
[00:51:17.400 --> 00:51:18.760]   by putting themselves at risk.
[00:51:18.760 --> 00:51:20.980]   I would not do this.
[00:51:20.980 --> 00:51:25.020]   I am not volunteering to break into anything.
[00:51:25.020 --> 00:51:28.220]   I think it was William Davidon,
[00:51:28.220 --> 00:51:29.460]   who was a student of Murray Gell-Mann
[00:51:29.460 --> 00:51:32.140]   and a physics professor at Haverford,
[00:51:32.140 --> 00:51:36.100]   who corralled these people and led this effort.
[00:51:36.100 --> 00:51:39.900]   And right now, what we need is somebody
[00:51:39.900 --> 00:51:43.160]   to blow the lid off of what is controlling everything.
[00:51:43.160 --> 00:51:47.540]   We have, I'm happy to hear that it's a system
[00:51:47.540 --> 00:51:49.420]   of incentive structures, that it's a system
[00:51:49.420 --> 00:51:50.360]   of selective pressures.
[00:51:50.360 --> 00:51:52.280]   I'm happy to find out that it's emergent.
[00:51:52.280 --> 00:51:54.080]   I'm happy to find that it's partially directed
[00:51:54.080 --> 00:51:56.540]   by our own intelligence community.
[00:51:56.540 --> 00:52:00.180]   I'm happy to hear that, in fact, we've been penetrated
[00:52:00.180 --> 00:52:04.100]   by North Korea, Iran, China, and Russia.
[00:52:04.100 --> 00:52:07.260]   But I need to know why people aren't,
[00:52:07.260 --> 00:52:09.180]   like the firebombing of the courthouse
[00:52:09.180 --> 00:52:11.380]   in Portland, Oregon has no explanation.
[00:52:11.380 --> 00:52:14.100]   And somehow this is normal.
[00:52:14.100 --> 00:52:16.360]   This is not normal to any human being.
[00:52:17.320 --> 00:52:19.360]   We have video that people don't believe.
[00:52:19.360 --> 00:52:23.540]   And I come back to the Shaggy defense of it wasn't me.
[00:52:23.540 --> 00:52:29.700]   You know, it's like, you remember that song?
[00:52:29.700 --> 00:52:33.740]   - Shaggy, yeah, wasn't me, caught you banging
[00:52:33.740 --> 00:52:35.060]   in the shower on the counter.
[00:52:35.060 --> 00:52:36.780]   - Yeah, exactly, wasn't me.
[00:52:36.780 --> 00:52:37.620]   - It wasn't me.
[00:52:37.620 --> 00:52:39.980]   - He says, his friend says, well,
[00:52:39.980 --> 00:52:41.980]   your strategy makes no sense at all.
[00:52:41.980 --> 00:52:42.820]   (laughing)
[00:52:42.820 --> 00:52:44.620]   Well, this is what MSNBC is doing.
[00:52:46.180 --> 00:52:49.240]   You dropped him from the graphic, it wasn't me.
[00:52:49.240 --> 00:52:51.600]   You came up with another Yang, it wasn't me.
[00:52:51.600 --> 00:52:55.520]   - I will never see MSNBC the same again.
[00:52:55.520 --> 00:52:57.760]   So you've spoken about him before.
[00:52:57.760 --> 00:53:00.560]   I think it'd be nice to maybe honor him,
[00:53:00.560 --> 00:53:03.320]   to break it apart a little bit, Aaron Schwartz.
[00:53:03.320 --> 00:53:08.680]   Why was he a special human being in this ilk
[00:53:08.680 --> 00:53:11.760]   of what we're talking about now, civil disobedience?
[00:53:11.760 --> 00:53:15.920]   How do we honor him now moving forward as human beings
[00:53:15.920 --> 00:53:19.080]   who are willing to take risks in this world?
[00:53:19.080 --> 00:53:20.200]   - Well, I don't know.
[00:53:20.200 --> 00:53:23.800]   I mean, are you inspired by Aaron Schwartz?
[00:53:23.800 --> 00:53:24.620]   - I am.
[00:53:24.620 --> 00:53:25.760]   - How do you feel about JSTOR?
[00:53:25.760 --> 00:53:27.440]   Let's talk about JSTOR first.
[00:53:27.440 --> 00:53:30.920]   So let's say what JSTOR is all about, right?
[00:53:30.920 --> 00:53:34.560]   We the taxpayer pay for research,
[00:53:34.560 --> 00:53:39.600]   and then, (laughing)
[00:53:39.600 --> 00:53:41.920]   the people who do the research do all the work
[00:53:41.920 --> 00:53:45.600]   for a bunch of companies who then charge us $30
[00:53:45.600 --> 00:53:48.960]   an article to read what it is that we already paid for.
[00:53:48.960 --> 00:53:51.360]   And if we don't cite these articles,
[00:53:51.360 --> 00:53:53.440]   we're told that we're in violation.
[00:53:53.440 --> 00:53:58.240]   Okay, I almost never call for civil disobedience
[00:53:58.240 --> 00:53:59.680]   because I don't really want to,
[00:53:59.680 --> 00:54:04.680]   but fuck JSTOR, fuck Elsevier, fuck Springer.
[00:54:04.680 --> 00:54:07.400]   Who the fuck are these people?
[00:54:11.400 --> 00:54:15.960]   The smart people need to take the greedy people
[00:54:15.960 --> 00:54:19.720]   behind the woodshed and explain to them what science is.
[00:54:19.720 --> 00:54:23.460]   I have a very old-fashioned idea that's so out of favor
[00:54:23.460 --> 00:54:26.280]   that I will immediately be seen as a knuckle-dragger.
[00:54:26.280 --> 00:54:29.840]   I believe in the great woman theory of history
[00:54:29.840 --> 00:54:31.760]   and the great man theory of history.
[00:54:31.760 --> 00:54:33.500]   Emmy Noether is fantastic.
[00:54:33.500 --> 00:54:37.880]   That's an example.
[00:54:37.880 --> 00:54:41.440]   And I believe in editors over peer reviewers.
[00:54:41.440 --> 00:54:43.280]   And I believe that wrong things
[00:54:43.280 --> 00:54:45.200]   should be allowed into the literature.
[00:54:45.200 --> 00:54:48.360]   And I believe that the gatekeeping should go toward zero
[00:54:48.360 --> 00:54:52.040]   because the costs associated with distribution
[00:54:52.040 --> 00:54:53.320]   are very, very slight.
[00:54:53.320 --> 00:54:57.060]   I believe that we should be looking
[00:54:57.060 --> 00:55:01.200]   at the perverse incentives of sending your paper blindly
[00:55:01.200 --> 00:55:02.660]   into your competitors' clutches,
[00:55:02.660 --> 00:55:04.560]   particularly if you're a young person
[00:55:04.560 --> 00:55:06.540]   being reviewed by an older person.
[00:55:07.520 --> 00:55:10.480]   Are you familiar with the Doit de Signore?
[00:55:10.480 --> 00:55:14.260]   Are you familiar with the legend of the Magnia?
[00:55:14.260 --> 00:55:18.440]   No, the Magnia is the Miller's daughter.
[00:55:18.440 --> 00:55:21.520]   And the largest food fight in the entire universe,
[00:55:21.520 --> 00:55:25.680]   I believe, is held, I think, in Italy.
[00:55:25.680 --> 00:55:27.680]   It's called the Battle of the Oranges.
[00:55:27.680 --> 00:55:31.480]   And it celebrates the Miller's daughter
[00:55:31.480 --> 00:55:34.600]   who had fallen in love with her beloved.
[00:55:34.600 --> 00:55:38.400]   And when it came time for them to marry,
[00:55:38.400 --> 00:55:42.040]   the virginal Magnia was in fact told
[00:55:42.040 --> 00:55:46.080]   that the lord of the land had the right
[00:55:46.080 --> 00:55:48.860]   to have the first night with the bride.
[00:55:48.860 --> 00:55:51.400]   Well, the Magnia had a different idea.
[00:55:51.400 --> 00:55:56.060]   So she seemed to consent to this perhaps mythical right,
[00:55:56.060 --> 00:55:59.280]   also called the prima notte, the first night.
[00:55:59.280 --> 00:56:04.120]   And by legend, she concealed a dagger underneath her robes.
[00:56:05.120 --> 00:56:08.480]   And when it came time for the hated lord of the manor
[00:56:08.480 --> 00:56:11.260]   to extract this right,
[00:56:11.260 --> 00:56:14.560]   she pulled the knife out and killed him.
[00:56:14.560 --> 00:56:16.360]   And I think it also echoes a little bit
[00:56:16.360 --> 00:56:19.300]   of particularly wonderful scene from Game of Thrones.
[00:56:19.300 --> 00:56:23.600]   But that inspired both men and women.
[00:56:23.600 --> 00:56:26.140]   And the Magnia is the legendary hero.
[00:56:26.140 --> 00:56:31.000]   Right now, what we need to do is we need
[00:56:31.000 --> 00:56:36.000]   to resist the prima notte, the right of first look, right?
[00:56:36.000 --> 00:56:38.320]   F you, you don't have the right of first look.
[00:56:38.320 --> 00:56:40.760]   I don't wanna send something blindly to my competitors.
[00:56:40.760 --> 00:56:42.800]   I don't wanna subject myself to you naming
[00:56:42.800 --> 00:56:45.160]   what work I've done.
[00:56:45.160 --> 00:56:48.020]   Why are you in my story?
[00:56:48.020 --> 00:56:48.860]   That's my question.
[00:56:48.860 --> 00:56:50.000]   Get out of my story.
[00:56:50.000 --> 00:56:52.640]   If I do work, and then you have an idea,
[00:56:52.640 --> 00:56:54.400]   oh, well, it's the Matthew principle.
[00:56:54.400 --> 00:56:57.720]   To him who has much more will be given.
[00:56:57.720 --> 00:56:59.640]   I've gone to the National Academy of Sciences
[00:56:59.640 --> 00:57:00.880]   and talked about these things.
[00:57:00.880 --> 00:57:03.720]   And it's funny, I've been laughed at by the older people
[00:57:03.720 --> 00:57:07.080]   who think, well, Eric, you know science proceeds
[00:57:07.080 --> 00:57:08.840]   funeral by funeral, that's Planck.
[00:57:08.840 --> 00:57:11.080]   You know the Matthew principle,
[00:57:11.080 --> 00:57:12.200]   you know the Matilda principle,
[00:57:12.200 --> 00:57:14.540]   that things done by women are attributed to men.
[00:57:14.540 --> 00:57:16.280]   These are not new.
[00:57:16.280 --> 00:57:17.760]   And you guys just live like this?
[00:57:17.760 --> 00:57:18.840]   - Yeah.
[00:57:18.840 --> 00:57:20.920]   So the Revolutionary Act now is to resist
[00:57:20.920 --> 00:57:23.920]   all of these things that, these things that are not new.
[00:57:23.920 --> 00:57:25.360]   - So you asked me about Aaron Schwartz.
[00:57:25.360 --> 00:57:27.200]   Aaron Schwartz was the Magnia.
[00:57:27.200 --> 00:57:29.320]   One of the things you've done very beautifully
[00:57:29.320 --> 00:57:31.840]   is to communicate love.
[00:57:31.840 --> 00:57:35.520]   And I think about some of our conversations.
[00:57:35.520 --> 00:57:36.960]   And you got me to talk a little bit
[00:57:36.960 --> 00:57:41.400]   about my own experiences in 02138 and 039.
[00:57:41.400 --> 00:57:47.700]   We are the product of our trauma.
[00:57:47.700 --> 00:57:51.120]   And what people don't understand is that very often
[00:57:51.120 --> 00:57:54.680]   when you see people taking countermeasures
[00:57:54.680 --> 00:57:57.800]   against what appear to be imaginary forces,
[00:57:57.800 --> 00:57:59.680]   they're really actually replaying things
[00:57:59.680 --> 00:58:01.140]   that really happened to them.
[00:58:01.140 --> 00:58:04.080]   And having been through this system
[00:58:04.080 --> 00:58:06.780]   and watching all of the ways in which
[00:58:06.780 --> 00:58:09.520]   it completely rewrites the lives of the people
[00:58:09.520 --> 00:58:11.680]   who I am counting on to cure our diseases,
[00:58:11.680 --> 00:58:14.320]   build our new industries, keep us safe from our foes,
[00:58:14.320 --> 00:58:18.720]   the amount of pressure the system is putting
[00:58:18.720 --> 00:58:23.300]   on the most hopeful minds is unimaginable.
[00:58:23.300 --> 00:58:26.640]   And so my goal is to empower somebody
[00:58:26.640 --> 00:58:28.560]   like an Aaron Schwartz in memory
[00:58:28.560 --> 00:58:32.320]   and to talk about a Jeffrey Epstein situation.
[00:58:32.320 --> 00:58:36.640]   Do you know that the first person outside of me
[00:58:36.640 --> 00:58:39.900]   to get a look at geometric unity was Jeffrey Epstein?
[00:58:39.900 --> 00:58:44.920]   How did he know I was working on this?
[00:58:44.920 --> 00:58:46.000]   I don't know.
[00:58:46.000 --> 00:58:49.340]   - So your ideas that formed geometric unity
[00:58:49.340 --> 00:58:51.920]   was something that his eyes had seen?
[00:58:51.920 --> 00:58:55.160]   - I was pushed to talk to Jeffrey Epstein
[00:58:55.160 --> 00:58:59.160]   as one of the only people who could help me.
[00:58:59.160 --> 00:59:00.760]   No, no, no, listen to this.
[00:59:00.760 --> 00:59:01.800]   - Yeah, how does this connect?
[00:59:01.800 --> 00:59:06.440]   - Okay, well, first of all, my old synagogue,
[00:59:06.440 --> 00:59:10.040]   my old shul was the conservative minion at Harvard Hillel.
[00:59:10.040 --> 00:59:14.280]   And I believe it's called Wrosowski Hall
[00:59:14.280 --> 00:59:18.360]   after Henry Wrosowski in the economics department
[00:59:18.360 --> 00:59:21.280]   who was a Japan scholar, if I'm correct.
[00:59:21.280 --> 00:59:24.520]   And he became provost or dean of Harvard.
[00:59:25.520 --> 00:59:29.120]   I believe that that was built with Jeffrey Epstein's money.
[00:59:29.120 --> 00:59:33.840]   And I wondered in part whether the Jewish students
[00:59:33.840 --> 00:59:36.640]   at Harvard all sort of passed through a bottleneck
[00:59:36.640 --> 00:59:38.240]   of Harvard Hillel.
[00:59:38.240 --> 00:59:39.960]   So that was something I found very curious,
[00:59:39.960 --> 00:59:42.320]   but I don't know much about it.
[00:59:42.320 --> 00:59:43.800]   I also found that Jeffrey Epstein
[00:59:43.800 --> 00:59:45.020]   hanging around scientists,
[00:59:45.020 --> 00:59:47.400]   I don't think that either you or Joe exactly,
[00:59:47.400 --> 00:59:52.160]   I mean, got me correct in your last interchange.
[00:59:52.160 --> 00:59:53.880]   - For the record, for people who haven't listened
[00:59:53.880 --> 00:59:56.640]   to Joe Rogan program, Joe has claimed that Eric Weinstein
[00:59:56.640 --> 00:59:58.760]   was the only person who has gotten laid.
[00:59:58.760 --> 01:00:00.200]   - Paid.
[01:00:00.200 --> 01:00:01.600]   - Oh, paid.
[01:00:01.600 --> 01:00:05.240]   - And you said you also got paid as a young man, right?
[01:00:05.240 --> 01:00:08.360]   - I believe the word was laid, but allegedly.
[01:00:08.360 --> 01:00:10.520]   - My hearing isn't so good at age 55.
[01:00:10.520 --> 01:00:12.120]   All right, leaving that aside.
[01:00:12.120 --> 01:00:12.960]   - Yes.
[01:00:12.960 --> 01:00:16.080]   - What was Jeffrey Epstein doing
[01:00:16.080 --> 01:00:18.040]   hanging around all of these scientists?
[01:00:18.040 --> 01:00:20.720]   I don't think that was the same program
[01:00:22.160 --> 01:00:24.720]   that was about compromising political leaders
[01:00:24.720 --> 01:00:27.320]   and business people and entertainment figures.
[01:00:27.320 --> 01:00:29.080]   I think these are two different programs
[01:00:29.080 --> 01:00:31.720]   that were being run through one individual.
[01:00:31.720 --> 01:00:33.880]   And Joe seemed to think that,
[01:00:33.880 --> 01:00:35.440]   I didn't think he was smooth.
[01:00:35.440 --> 01:00:36.700]   I thought he was glib.
[01:00:36.700 --> 01:00:39.480]   I think what Joe was really trying to get at
[01:00:39.480 --> 01:00:43.200]   is that I found his mysticism meretricious.
[01:00:43.200 --> 01:00:48.080]   He had an ability to deflect every conversation
[01:00:48.080 --> 01:00:50.120]   that might go towards revealing
[01:00:50.120 --> 01:00:51.600]   that he didn't know what he was talking about.
[01:00:51.600 --> 01:00:54.600]   Every time you started to get close to something
[01:00:54.600 --> 01:00:55.780]   where the rubber hit the road,
[01:00:55.780 --> 01:00:57.440]   the rubber wouldn't hit the road.
[01:00:57.440 --> 01:01:00.880]   - And yet, can you help me untangle
[01:01:00.880 --> 01:01:05.600]   the fact that you thought deeply
[01:01:05.600 --> 01:01:10.480]   about the physics of the nature of our universe
[01:01:10.480 --> 01:01:13.480]   and Jeffrey Epstein was interested?
[01:01:13.480 --> 01:01:14.800]   - How did he know?
[01:01:14.800 --> 01:01:17.380]   I wasn't really talking about this stuff until,
[01:01:17.380 --> 01:01:21.240]   even my close friends didn't really know
[01:01:21.240 --> 01:01:22.240]   what I was up to.
[01:01:22.240 --> 01:01:25.320]   - And yet, you're saying he did not have
[01:01:25.320 --> 01:01:27.520]   sufficient brilliance to understand
[01:01:27.520 --> 01:01:28.640]   when the rubber hit the road.
[01:01:28.640 --> 01:01:33.080]   So why did he have sufficient interest and curiosity?
[01:01:33.080 --> 01:01:34.640]   - I'll tell you what I thought.
[01:01:34.640 --> 01:01:36.160]   I had been waiting to find out,
[01:01:36.160 --> 01:01:38.380]   does my government even know I exist?
[01:01:38.380 --> 01:01:40.960]   - Do you have an answer to that question?
[01:01:40.960 --> 01:01:43.800]   - I have, a couple times,
[01:01:43.800 --> 01:01:45.640]   the government has reached out to me.
[01:01:45.640 --> 01:01:49.640]   In general, there is zero interest in me.
[01:01:49.640 --> 01:01:51.400]   Like, less than zero interest.
[01:01:51.400 --> 01:01:54.440]   I find that fascinating.
[01:01:54.440 --> 01:01:56.080]   - As far as you know, right?
[01:01:56.080 --> 01:01:56.920]   I mean-- - Well, that's what
[01:01:56.920 --> 01:01:57.760]   I'm trying to say.
[01:01:57.760 --> 01:01:59.800]   The question about not being able to see
[01:01:59.800 --> 01:02:01.980]   through a half-silvered mirror,
[01:02:01.980 --> 01:02:03.600]   you don't know what's going on
[01:02:03.600 --> 01:02:04.960]   behind the half-silvered mirror.
[01:02:04.960 --> 01:02:09.120]   To you, it's all you see is your reflection.
[01:02:09.120 --> 01:02:10.920]   - But your intuition still holds.
[01:02:10.920 --> 01:02:12.960]   Like, this is where I've mentioned that I,
[01:02:12.960 --> 01:02:16.200]   this is where I'll say naive, dumb things,
[01:02:16.200 --> 01:02:18.480]   but I still hold onto this intuition
[01:02:18.480 --> 01:02:21.920]   that Jeff, I'm not confident in this,
[01:02:21.920 --> 01:02:25.160]   but I'm lean towards that direction
[01:02:25.160 --> 01:02:27.360]   that Jeffrey Epstein is the source of evil,
[01:02:27.360 --> 01:02:29.760]   not something that's underlying him.
[01:02:29.760 --> 01:02:31.480]   - You have a bias.
[01:02:31.480 --> 01:02:32.760]   It's different than mine.
[01:02:32.760 --> 01:02:35.200]   Our Bayesian priors are tutored
[01:02:35.200 --> 01:02:37.760]   by different life experiences.
[01:02:37.760 --> 01:02:40.160]   If I was mostly concerned,
[01:02:40.160 --> 01:02:42.200]   like Sam Harris is concerned,
[01:02:42.200 --> 01:02:44.360]   that people fill their heads with nonsense,
[01:02:44.360 --> 01:02:47.700]   I would have a very strong sense
[01:02:47.700 --> 01:02:49.380]   that people need order in the world,
[01:02:49.380 --> 01:02:51.700]   that they take mysterious situations,
[01:02:51.700 --> 01:02:53.600]   they build entire castles in the air,
[01:02:53.600 --> 01:02:56.440]   and then they go move in if they really get crazy.
[01:02:56.440 --> 01:02:58.800]   The old saying is that neurotics
[01:02:58.800 --> 01:03:02.600]   build castles in the air and psychotics move in.
[01:03:02.600 --> 01:03:04.960]   Coming from a progressive family,
[01:03:04.960 --> 01:03:06.440]   we had a different experience.
[01:03:06.440 --> 01:03:07.680]   It's really weird when the government
[01:03:07.680 --> 01:03:08.960]   is actually out to get you,
[01:03:08.960 --> 01:03:11.020]   when they actually send a spy,
[01:03:11.020 --> 01:03:13.980]   when they actually engage in disinformation campaigns,
[01:03:13.980 --> 01:03:15.600]   when they smear you.
[01:03:15.600 --> 01:03:18.980]   And if you've ever had that brought to bear on your family,
[01:03:18.980 --> 01:03:22.580]   you have a Howard Zinn sort of understanding of the country,
[01:03:22.580 --> 01:03:25.160]   which is different than having a,
[01:03:25.160 --> 01:03:27.140]   wow, do people believe crazy stuff
[01:03:27.140 --> 01:03:29.780]   because they watch too much TV.
[01:03:29.780 --> 01:03:32.260]   And both of these things have some merit to them,
[01:03:32.260 --> 01:03:34.180]   but it's a question of regulated expression.
[01:03:34.180 --> 01:03:36.420]   When do you want to express more Sam Harris
[01:03:36.420 --> 01:03:39.660]   and when do you want to express more Howard Zinn?
[01:03:39.660 --> 01:03:41.340]   - And you can express both, correct?
[01:03:41.340 --> 01:03:42.780]   One human being can express both?
[01:03:42.780 --> 01:03:44.900]   - Sure, but there's a trade-off between them.
[01:03:44.900 --> 01:03:46.660]   In other words, most people,
[01:03:46.660 --> 01:03:48.100]   like the Michael Shermers of the world
[01:03:48.100 --> 01:03:49.980]   are gonna tilt very strongly to,
[01:03:49.980 --> 01:03:52.380]   extraordinary claims require extraordinary evidence.
[01:03:52.380 --> 01:03:54.300]   You're gonna have that kind of energy.
[01:03:54.300 --> 01:03:55.580]   And then somebody else is gonna say,
[01:03:55.580 --> 01:03:58.180]   how many times do I have to get hit on,
[01:03:58.180 --> 01:03:59.740]   how many times do I have to hammer my own thumb
[01:03:59.740 --> 01:04:02.000]   before I realize that there's a problem?
[01:04:02.000 --> 01:04:04.660]   So my feeling about this is, yes,
[01:04:04.660 --> 01:04:06.480]   people see patterns in clouds.
[01:04:06.480 --> 01:04:09.220]   They see faces and scripture and all sorts of things,
[01:04:09.220 --> 01:04:10.700]   and it's just random cloud patterns.
[01:04:10.700 --> 01:04:13.840]   And it's also the case that there's tremendous pressure
[01:04:13.840 --> 01:04:16.180]   not to see conspiracies when conspiracies
[01:04:16.180 --> 01:04:18.420]   are relatively more common than the people
[01:04:18.420 --> 01:04:21.260]   who shout conspiracy theory will claim.
[01:04:21.260 --> 01:04:22.700]   So both of these things are true.
[01:04:22.700 --> 01:04:25.140]   And you have to ask, when do you express your inner Zinn
[01:04:25.140 --> 01:04:26.900]   and when your inner Harris?
[01:04:26.900 --> 01:04:27.740]   And those are different.
[01:04:27.740 --> 01:04:29.820]   - I wanna find out the difference between you and I,
[01:04:29.820 --> 01:04:33.540]   biases aside, is you've actually met Jeffrey Epstein.
[01:04:33.540 --> 01:04:38.540]   And I'm listening to reverberations years later
[01:04:38.540 --> 01:04:42.940]   of stories and narratives throughout the story.
[01:04:42.940 --> 01:04:44.480]   - I luckily only met him once.
[01:04:44.480 --> 01:04:49.280]   And I think I had one or perhaps two phone conversations
[01:04:49.280 --> 01:04:51.120]   with him other than the one meeting.
[01:04:51.120 --> 01:04:54.400]   - You can learn a lot in just a few words, right,
[01:04:54.400 --> 01:04:55.240]   from a human being.
[01:04:55.240 --> 01:04:56.060]   - Well, that's true.
[01:04:56.060 --> 01:04:59.500]   But I think that the bigger issue was I saw something
[01:04:59.500 --> 01:05:01.240]   that I don't hear much remarked upon,
[01:05:01.240 --> 01:05:05.040]   which is Jeffrey Epstein is all that there is.
[01:05:05.040 --> 01:05:08.760]   In other words, there's the National Science Foundation,
[01:05:08.760 --> 01:05:11.440]   National Institute of Health, Howard Hughes.
[01:05:11.440 --> 01:05:16.280]   There's all this stuff that kind of has the same feel to it,
[01:05:16.280 --> 01:05:18.200]   a little bit of variation and difference,
[01:05:18.200 --> 01:05:19.240]   Department of Energy.
[01:05:19.240 --> 01:05:23.900]   If you fall outside of that, there's just Jeffrey Epstein.
[01:05:23.900 --> 01:05:25.220]   That's what you're told.
[01:05:25.220 --> 01:05:26.060]   - Yes.
[01:05:26.060 --> 01:05:26.880]   - That's not quite true.
[01:05:26.880 --> 01:05:30.000]   There's Kavli, maybe Jim Simons is now in the game.
[01:05:30.000 --> 01:05:32.060]   Peter Thiel has done some stuff.
[01:05:32.060 --> 01:05:35.160]   You had Yuri Milner and Mark Zuckerberg try.
[01:05:35.160 --> 01:05:38.340]   So there is other money running around, Templeton.
[01:05:39.620 --> 01:05:41.980]   But very strongly, there was a belief
[01:05:41.980 --> 01:05:44.060]   that if you're doing something really innovative
[01:05:44.060 --> 01:05:48.220]   and the system can't fund it because we become pussies,
[01:05:48.220 --> 01:05:49.580]   Jeffrey Epstein's your guy.
[01:05:49.580 --> 01:05:51.220]   - So there's that 'cause it's funnel
[01:05:51.220 --> 01:05:53.100]   that you're supposed to go through.
[01:05:53.100 --> 01:05:54.060]   - That's right.
[01:05:54.060 --> 01:05:55.340]   And the idea is that you get called
[01:05:55.340 --> 01:05:59.900]   to the great man's house and the sort of
[01:05:59.900 --> 01:06:06.180]   lubricious version of Ralph Lauren takes you in
[01:06:06.180 --> 01:06:07.940]   and asks you bizarre questions.
[01:06:07.940 --> 01:06:11.020]   And maybe he has an island, maybe he has a plane.
[01:06:11.020 --> 01:06:14.160]   And when you're starved,
[01:06:14.160 --> 01:06:17.580]   somebody showing you a feast
[01:06:17.580 --> 01:06:20.820]   or when you're dehydrated in a death's door
[01:06:20.820 --> 01:06:24.060]   and somebody says, "Oh, I have a well."
[01:06:24.060 --> 01:06:26.780]   (laughing)
[01:06:26.780 --> 01:06:27.860]   That's what it is.
[01:06:27.860 --> 01:06:29.620]   And so the thought is, wow,
[01:06:29.620 --> 01:06:33.860]   can somebody get some effing money into the science system
[01:06:33.860 --> 01:06:36.540]   so that we don't have super creeps
[01:06:36.540 --> 01:06:39.420]   trying to learn all of our secrets ahead of time?
[01:06:39.420 --> 01:06:42.340]   WTF, what is your problem with transparency
[01:06:42.340 --> 01:06:43.400]   and taxpayer dollars?
[01:06:43.400 --> 01:06:46.580]   Just all of you, you wouldn't have a country.
[01:06:46.580 --> 01:06:47.960]   You'd be speaking German.
[01:06:47.960 --> 01:06:51.280]   - So essentially you believe that human beings
[01:06:51.280 --> 01:06:54.940]   would not be able to, when the money's lacking in the system
[01:06:54.940 --> 01:06:55.780]   like in research--
[01:06:55.780 --> 01:06:57.260]   - We produce public goods.
[01:06:57.260 --> 01:07:00.340]   You and I are meant to produce public goods.
[01:07:00.340 --> 01:07:03.340]   Now, I sell Athletic Greens and I sell Theragun
[01:07:03.340 --> 01:07:07.740]   and I sell Unagi scooters and Chili Pad.
[01:07:07.740 --> 01:07:09.660]   I gotta be honest, I love these products.
[01:07:09.660 --> 01:07:14.660]   But I didn't get into this game for the purpose of selling.
[01:07:14.660 --> 01:07:20.620]   I'm trying to figure out how do you have an FU lifestyle?
[01:07:20.620 --> 01:07:22.660]   But you know something, Lex?
[01:07:22.660 --> 01:07:24.340]   I don't know why you built this channel.
[01:07:24.340 --> 01:07:25.420]   It's kind of a mystery.
[01:07:25.420 --> 01:07:26.900]   - Yeah, I don't know why.
[01:07:26.900 --> 01:07:29.100]   - I'll tell you why I built my channel.
[01:07:29.100 --> 01:07:29.940]   - The freedom.
[01:07:29.940 --> 01:07:31.940]   - It's gonna be a lot harder to roll me this time
[01:07:31.940 --> 01:07:33.220]   in an alley.
[01:07:33.220 --> 01:07:34.060]   - Yeah.
[01:07:34.060 --> 01:07:36.980]   - I got rolled multiple times and my point is
[01:07:36.980 --> 01:07:40.060]   I didn't wanna become a celebrity.
[01:07:40.060 --> 01:07:41.900]   I didn't wanna become well-known.
[01:07:41.900 --> 01:07:46.900]   But it's a lot harder to roll somebody who's getting,
[01:07:46.900 --> 01:07:49.780]   you know, I think I'm, I don't know if this is mistaken,
[01:07:49.780 --> 01:07:52.140]   but I think I'm the math PhD with the largest number
[01:07:52.140 --> 01:07:53.400]   of followers on Twitter.
[01:07:53.400 --> 01:07:58.780]   And there was nothing you could do before.
[01:07:58.780 --> 01:08:01.020]   - I mean, again, to put a little responsibility on you,
[01:08:01.020 --> 01:08:03.900]   so you've created something really special
[01:08:03.900 --> 01:08:06.260]   for the distribution of your own ideas.
[01:08:06.260 --> 01:08:11.020]   But because it's not necessarily currently scalable,
[01:08:11.020 --> 01:08:15.700]   you also, perhaps you and I have the responsibility
[01:08:15.700 --> 01:08:19.460]   of giving other people also a chance to spread their ideas.
[01:08:19.460 --> 01:08:21.300]   I mean, Joe Rogan did this very effectively
[01:08:21.300 --> 01:08:23.700]   for a bunch of people that--
[01:08:23.700 --> 01:08:24.660]   - That's why they're angry at him,
[01:08:24.660 --> 01:08:28.100]   because he's a gatekeeper and he let all sorts of people
[01:08:28.100 --> 01:08:32.820]   through that gate, from Roger Penrose to Alex Jones.
[01:08:32.820 --> 01:08:37.220]   - To Jordan Peterson, to, I mean, even,
[01:08:37.220 --> 01:08:39.900]   first of all, to you-- - To Abby Martin.
[01:08:39.900 --> 01:08:42.020]   - To Abby Martin. - To Barry Weiss.
[01:08:42.020 --> 01:08:44.680]   - Yeah. - That's the problem.
[01:08:44.680 --> 01:08:48.940]   - Well, but you have now successfully built up a thing
[01:08:48.940 --> 01:08:50.420]   that allows that to carry that forward.
[01:08:50.420 --> 01:08:51.980]   - Oh, no, no, no, no.
[01:08:51.980 --> 01:08:56.860]   We are all vulnerable to reputational attack,
[01:08:56.860 --> 01:08:59.860]   because what happens, you see, the problem, Lex,
[01:08:59.860 --> 01:09:02.380]   is that you are now an institution at some level.
[01:09:02.380 --> 01:09:06.620]   You walk around with all this equipment in a duffel bag.
[01:09:06.620 --> 01:09:09.740]   - Wearing a suit. - The last suit
[01:09:09.740 --> 01:09:14.220]   you'll ever need, and you have the reach
[01:09:14.220 --> 01:09:17.720]   of something like CNN to people who matter.
[01:09:17.720 --> 01:09:23.540]   Okay, so now the question is, how do we control something
[01:09:23.540 --> 01:09:25.360]   that doesn't have a board, doesn't have shareholders,
[01:09:25.360 --> 01:09:28.460]   doesn't have to make SEC filings, FCC,
[01:09:28.460 --> 01:09:31.420]   so the best answer they have is,
[01:09:31.420 --> 01:09:36.380]   well, we just have to destroy reputations.
[01:09:36.380 --> 01:09:38.420]   All it takes is for us to take something
[01:09:38.420 --> 01:09:40.120]   that gets said or done or alleged,
[01:09:40.120 --> 01:09:43.100]   and I think it's incredibly important.
[01:09:43.100 --> 01:09:45.980]   One of the things people don't understand is that
[01:09:45.980 --> 01:09:49.780]   I'm going to fight general reputational attacks,
[01:09:49.780 --> 01:09:51.540]   not because some people don't deserve
[01:09:51.540 --> 01:09:55.140]   to have their reputations dragged through the mud,
[01:09:55.140 --> 01:09:58.260]   but because it's too powerful of a tool
[01:09:58.260 --> 01:10:02.900]   to hand it to CNN, MSNBC, Princeton, Harvard,
[01:10:02.900 --> 01:10:04.960]   the State Department. - Yes.
[01:10:04.960 --> 01:10:09.060]   But some of it is also-- - J.P. Morgan.
[01:10:09.060 --> 01:10:12.860]   - Muhammad Ali-style being good enough
[01:10:12.860 --> 01:10:17.040]   at doing everything you need to do
[01:10:17.040 --> 01:10:21.660]   without giving enough meat for the reputational attacks.
[01:10:21.660 --> 01:10:25.100]   Not being afraid, but not giving enough meat.
[01:10:25.100 --> 01:10:28.060]   - I don't see why the people who have good ideas
[01:10:28.060 --> 01:10:30.220]   have to lead lives that are that clean.
[01:10:30.220 --> 01:10:32.220]   If you can do it-- - You can be messy, yeah.
[01:10:32.220 --> 01:10:34.020]   You should be able to be messy,
[01:10:34.020 --> 01:10:37.060]   otherwise we're suppressing too many people.
[01:10:37.060 --> 01:10:39.340]   Too many, too brilliant minds, yeah.
[01:10:39.340 --> 01:10:42.740]   - Can you believe Elon Musk smoked a blunt?
[01:10:42.740 --> 01:10:44.400]   - I still, people tell me this.
[01:10:44.400 --> 01:10:48.020]   Okay, I have discussions about Elon and people,
[01:10:48.020 --> 01:10:54.100]   the Avi Loeb, the Harvard scientist
[01:10:54.100 --> 01:10:56.220]   who's talking about a muamua,
[01:10:56.220 --> 01:10:58.540]   that it might be alien technology.
[01:10:58.540 --> 01:11:03.540]   He told me, this outside-the-box thinker,
[01:11:03.540 --> 01:11:08.060]   when speaking to me about Elon,
[01:11:08.060 --> 01:11:13.860]   called him the guy who smoked, he smokes weed.
[01:11:13.860 --> 01:11:14.860]   The blunt. - I love it.
[01:11:14.860 --> 01:11:17.840]   - In a dismissive way, like this guy's crazy
[01:11:17.840 --> 01:11:20.140]   because he smoked some weed.
[01:11:20.140 --> 01:11:21.580]   I was looking at him. - Good God.
[01:11:21.580 --> 01:11:25.140]   - I was like, why, wow, wow.
[01:11:25.140 --> 01:11:26.940]   - I think you should be able to have
[01:11:26.940 --> 01:11:30.300]   consensual drug-filled orgies.
[01:11:30.300 --> 01:11:32.460]   Fuck perfect lives.
[01:11:32.460 --> 01:11:34.340]   - Yeah, you should be allowed to be messy.
[01:11:34.340 --> 01:11:35.980]   You're right, I take back my statement.
[01:11:35.980 --> 01:11:38.180]   I was just saying-- - Respectability
[01:11:38.180 --> 01:11:43.020]   is the unique prison where all of the gates are open
[01:11:43.020 --> 01:11:45.560]   and the inmates beg to stay inside.
[01:11:45.560 --> 01:11:49.780]   It's time to end their prison of respectability
[01:11:49.780 --> 01:11:52.020]   because it's too effective of a means
[01:11:52.020 --> 01:11:54.700]   of sidelining and silencing people,
[01:11:54.700 --> 01:11:58.880]   including it is better that we have bad people
[01:11:58.880 --> 01:12:03.880]   in our system than this idea of no platforming people
[01:12:03.880 --> 01:12:08.180]   who are beyond the pale because it's such a simple technique.
[01:12:08.180 --> 01:12:11.780]   - So how do we, what's the heroic action here on the--
[01:12:11.780 --> 01:12:15.280]   - Well, for example, having Ashley Matthews on my program.
[01:12:15.280 --> 01:12:19.660]   By the way, she was absolutely delightful
[01:12:19.660 --> 01:12:23.860]   as a guest, she is polite in the extreme,
[01:12:23.860 --> 01:12:26.060]   far more polite than I am.
[01:12:26.060 --> 01:12:29.380]   And I had her right after Roger Penrose as a guest
[01:12:29.380 --> 01:12:32.220]   because I wanted to highlight this program can go anywhere.
[01:12:32.220 --> 01:12:33.660]   We can talk to anyone.
[01:12:33.660 --> 01:12:34.620]   - What about social media?
[01:12:34.620 --> 01:12:37.060]   You've started highlighting people being banned
[01:12:37.060 --> 01:12:38.740]   on social media.
[01:12:38.740 --> 01:12:40.460]   How do we fight this?
[01:12:40.460 --> 01:12:42.220]   Like if you get banned from social media,
[01:12:42.220 --> 01:12:44.540]   so you're saying nobody will stand up to me.
[01:12:44.540 --> 01:12:46.460]   - Well, just figure out what your incentive structure
[01:12:46.460 --> 01:12:47.300]   is before.
[01:12:47.300 --> 01:12:49.660]   Assume that I get banned on social media
[01:12:49.660 --> 01:12:51.820]   because somebody wants to make sure that my message
[01:12:51.820 --> 01:12:55.100]   doesn't interfere with the dominant narrative.
[01:12:55.100 --> 01:12:55.940]   Okay.
[01:12:55.940 --> 01:13:00.780]   What will happen, by the way, I'm very glad to be able
[01:13:00.780 --> 01:13:04.220]   to explain this on your show because that video
[01:13:04.220 --> 01:13:07.140]   will presumably be archived and they can't easily make
[01:13:07.140 --> 01:13:08.940]   you take it down.
[01:13:08.940 --> 01:13:11.820]   Okay, so what's gonna happen is that there'll be
[01:13:11.820 --> 01:13:16.820]   a whole bunch of very low quality bot-like accounts
[01:13:16.960 --> 01:13:19.060]   that dog you every time you talk about me.
[01:13:19.060 --> 01:13:22.140]   Dude, it's getting old, it's getting boring.
[01:13:22.140 --> 01:13:23.500]   We already heard you.
[01:13:23.500 --> 01:13:25.860]   Dude, that was like, let it go.
[01:13:25.860 --> 01:13:27.120]   Not a good look.
[01:13:27.120 --> 01:13:29.220]   Not a good look is one of my favorites.
[01:13:29.220 --> 01:13:30.980]   - But what about the high profile ones?
[01:13:30.980 --> 01:13:32.800]   - Well, then you'll get a few high profile ones
[01:13:32.800 --> 01:13:37.100]   and some of the high profile ones command armies.
[01:13:37.100 --> 01:13:41.160]   Like at some point I had 10,000 people using exactly
[01:13:41.160 --> 01:13:43.580]   the same templated tweet, tweeting at me.
[01:13:43.580 --> 01:13:45.980]   It was just actually, it got to the point where it was funny
[01:13:45.980 --> 01:13:48.920]   because everybody said, did you hear that
[01:13:48.920 --> 01:13:49.940]   in Hipster Coffee Shop?
[01:13:49.940 --> 01:13:52.100]   I was like, why are you all suddenly talking
[01:13:52.100 --> 01:13:52.940]   about Hipster Coffee?
[01:13:52.940 --> 01:13:54.160]   It's hilarious.
[01:13:54.160 --> 01:13:58.900]   Those things will cause you to think better of it.
[01:13:58.900 --> 01:14:01.140]   You'll start to see your follower count go down
[01:14:01.140 --> 01:14:04.460]   because it's easy to give you a bunch of bot-like follows
[01:14:04.460 --> 01:14:06.020]   and then just pull them.
[01:14:06.020 --> 01:14:09.660]   So I think that it's pretty well known how,
[01:14:09.660 --> 01:14:11.580]   and then maybe your account will be suspended
[01:14:11.580 --> 01:14:14.380]   and it can't be revoked and et cetera, et cetera,
[01:14:14.380 --> 01:14:17.340]   and then three days later you'll be told it was an error.
[01:14:17.340 --> 01:14:18.280]   - So let me push back.
[01:14:18.280 --> 01:14:20.460]   I just don't see not defending you.
[01:14:20.460 --> 01:14:23.720]   Like, okay, so what are the things you would do
[01:14:23.720 --> 01:14:27.820]   that given that I can actually talk to you offline,
[01:14:27.820 --> 01:14:31.320]   that would make me not defend you?
[01:14:31.320 --> 01:14:34.820]   - Well, first of all--
[01:14:34.820 --> 01:14:37.660]   - I can't, I mean, I can imagine some.
[01:14:37.660 --> 01:14:39.620]   - But all of us have things.
[01:14:39.620 --> 01:14:42.260]   If somebody says, do you hear what your boy Lex said
[01:14:42.260 --> 01:14:43.540]   about you?
[01:14:43.540 --> 01:14:45.620]   What did Lex say about me?
[01:14:45.620 --> 01:14:47.320]   Oh, he said you were flawed, dude.
[01:14:47.320 --> 01:14:49.140]   Oh, shit.
[01:14:49.140 --> 01:14:54.600]   They so distrust because none of us
[01:14:54.600 --> 01:14:57.020]   wanna stand behind flawed people.
[01:14:57.020 --> 01:14:58.740]   That's why you have everybody rushing to say,
[01:14:58.740 --> 01:15:00.060]   I neither condemn nor condone.
[01:15:00.060 --> 01:15:02.740]   I don't condemn nor, you know, what is that?
[01:15:02.740 --> 01:15:03.580]   We're all trying to say--
[01:15:03.580 --> 01:15:04.940]   - By the way, for the record,
[01:15:04.940 --> 01:15:07.300]   I said that Eric is smarter than me
[01:15:07.300 --> 01:15:10.860]   and a brilliant human being, but flawed like all humans are.
[01:15:10.860 --> 01:15:14.140]   My point is, I've now come up with a new policy,
[01:15:14.140 --> 01:15:16.660]   which is I don't care what my friends have done.
[01:15:16.660 --> 01:15:20.020]   I am not disavowing my friends.
[01:15:20.020 --> 01:15:22.060]   Not because they didn't do the wrong thing.
[01:15:22.060 --> 01:15:23.340]   Maybe they did do the wrong thing.
[01:15:23.340 --> 01:15:24.180]   I don't know.
[01:15:24.180 --> 01:15:27.340]   - What's the value of friendship if that's not--
[01:15:27.340 --> 01:15:28.300]   - It's not that.
[01:15:28.300 --> 01:15:29.900]   Like, for example, we've had the situation
[01:15:29.900 --> 01:15:30.840]   with Brian Callan.
[01:15:30.840 --> 01:15:32.580]   Brian Callan was featured recently
[01:15:32.580 --> 01:15:33.980]   in the Los Angeles Times.
[01:15:33.980 --> 01:15:36.900]   I know nothing about the allegations.
[01:15:36.900 --> 01:15:37.740]   I can't.
[01:15:37.740 --> 01:15:39.720]   I didn't even know Brian at the time, right?
[01:15:39.720 --> 01:15:41.380]   I've known him for roughly the time
[01:15:41.380 --> 01:15:44.040]   I've been in Los Angeles, maybe a year and a half.
[01:15:44.040 --> 01:15:46.740]   During that period of time, I've never seen anything wrong.
[01:15:46.740 --> 01:15:50.000]   Now I'm in a situation, well, what do you think he did?
[01:15:50.000 --> 01:15:50.840]   Do you think he didn't?
[01:15:50.840 --> 01:15:52.400]   It's like, you know what?
[01:15:52.400 --> 01:15:53.520]   I don't know.
[01:15:53.520 --> 01:15:54.620]   But I do know this.
[01:15:54.620 --> 01:15:56.840]   Everyone's entitled to have friends
[01:15:56.840 --> 01:15:59.020]   because we can't afford isolated people.
[01:15:59.020 --> 01:16:02.140]   And if your friends do the wrong thing,
[01:16:02.140 --> 01:16:04.220]   they're still your friends.
[01:16:04.220 --> 01:16:06.140]   And if they do terrible, terrible things,
[01:16:06.140 --> 01:16:08.940]   you bring that up with them privately.
[01:16:08.940 --> 01:16:12.260]   And it's not my responsibility to disavow in public.
[01:16:12.260 --> 01:16:15.820]   You know, we've had the situation that I don't like
[01:16:15.820 --> 01:16:19.220]   where particular people that I've been close to,
[01:16:19.220 --> 01:16:21.880]   I'm put under tremendous pressure to disavow them.
[01:16:21.880 --> 01:16:24.140]   What do you think now about your buddy?
[01:16:24.140 --> 01:16:26.020]   - Oh, like Dave Rubin, all that kind of stuff.
[01:16:26.020 --> 01:16:27.020]   - Here's the thing.
[01:16:27.020 --> 01:16:28.960]   My friends are my friends.
[01:16:28.960 --> 01:16:30.740]   I don't disavow my friends.
[01:16:30.740 --> 01:16:34.300]   We all need to make a statement
[01:16:34.300 --> 01:16:36.740]   that we will not be brought under pressure
[01:16:36.740 --> 01:16:40.820]   to disavow our friends, our family members,
[01:16:40.820 --> 01:16:45.820]   because mass murderers are dangerous
[01:16:45.820 --> 01:16:48.140]   the more isolated they become.
[01:16:48.140 --> 01:16:53.140]   It is not a good idea to constantly push to isolate people.
[01:16:53.140 --> 01:16:54.300]   And it's dangerous.
[01:16:54.300 --> 01:16:56.420]   - And it sends a signal to everybody else
[01:16:56.420 --> 01:17:00.660]   to fit in, to be more cynical about the human--
[01:17:00.660 --> 01:17:04.140]   - So my feeling, if I find out you've been selling heroin
[01:17:04.140 --> 01:17:06.480]   to elementary school students,
[01:17:06.480 --> 01:17:09.500]   you're still my friend, and I will not be disavowing you.
[01:17:09.500 --> 01:17:11.820]   And if I have a problem with you selling heroin
[01:17:11.820 --> 01:17:14.900]   to elementary school students during school hours,
[01:17:14.900 --> 01:17:18.860]   I will bring it up with you privately,
[01:17:18.860 --> 01:17:21.540]   because we don't need to hear my voice
[01:17:21.540 --> 01:17:23.020]   added to that condemnation.
[01:17:23.020 --> 01:17:25.020]   Are there things that you could do
[01:17:25.020 --> 01:17:27.900]   that would cause me to say, actually F this guy?
[01:17:27.900 --> 01:17:29.620]   Yeah, above and beyond that.
[01:17:29.620 --> 01:17:32.180]   But simply doing the wrong thing,
[01:17:32.180 --> 01:17:34.780]   I think we've gone down a terrible path.
[01:17:34.780 --> 01:17:37.320]   I think isolated people are about the most dangerous thing
[01:17:37.320 --> 01:17:40.340]   we could have in a heavily armed society.
[01:17:40.340 --> 01:17:43.400]   - So I deeply agree with you on Brian Callahan
[01:17:43.400 --> 01:17:46.220]   and on all these people that quote-unquote got canceled.
[01:17:46.220 --> 01:17:49.120]   - And I'm not saying that they,
[01:17:49.120 --> 01:17:52.080]   I don't know the truth value, because we can't.
[01:17:52.080 --> 01:17:53.780]   And even if I did know the truth value,
[01:17:53.780 --> 01:17:56.840]   I'm not setting up an incentive structure
[01:17:56.840 --> 01:18:00.540]   for the personal destruction as a means
[01:18:00.540 --> 01:18:03.400]   of letting institutions combat the fact
[01:18:03.400 --> 01:18:05.460]   that individuals are the last thing that can say,
[01:18:05.460 --> 01:18:07.060]   none of you guys make any sense.
[01:18:07.060 --> 01:18:09.700]   I don't treat these things like,
[01:18:09.700 --> 01:18:12.380]   I had a conversation where Kevin Spacey
[01:18:12.380 --> 01:18:15.540]   was at the dinner table when I came down from a hotel room.
[01:18:15.540 --> 01:18:18.540]   And I had a very long conversation with Kevin Spacey.
[01:18:18.540 --> 01:18:21.700]   I will not detail, because I don't do that,
[01:18:21.700 --> 01:18:23.520]   as to what we discussed.
[01:18:23.520 --> 01:18:27.020]   But we talked very specifically about him being canceled.
[01:18:27.020 --> 01:18:30.260]   And I don't think that the world has heard that story
[01:18:30.260 --> 01:18:33.760]   in part because there's a very strong sense
[01:18:33.760 --> 01:18:35.720]   that he has to be outgrouped.
[01:18:35.720 --> 01:18:39.200]   And as a result, I mean, do we want,
[01:18:39.200 --> 01:18:42.920]   do we want to disavow the space program
[01:18:42.920 --> 01:18:44.560]   because it touched Wernher von Braun?
[01:18:44.560 --> 01:18:46.180]   Do we want to disavow quantum mechanics
[01:18:46.180 --> 01:18:48.400]   because Pascal Jordan and Werner Heisenberg
[01:18:48.400 --> 01:18:49.400]   passed through it?
[01:18:49.400 --> 01:18:53.040]   Is Ehrenfest's theorem false because he murdered his child?
[01:18:53.040 --> 01:18:55.720]   I mean, at what point do we recognize
[01:18:55.720 --> 01:18:57.800]   that we are the problem?
[01:18:57.800 --> 01:18:58.940]   Humans are humans.
[01:18:58.940 --> 01:19:01.360]   And there is no perfect,
[01:19:01.360 --> 01:19:03.080]   there is no perfect group of people,
[01:19:03.080 --> 01:19:04.920]   even all of the most oppressed people,
[01:19:04.920 --> 01:19:06.640]   the supposed victims of the world,
[01:19:06.640 --> 01:19:08.440]   who we now have fetishized into thinking
[01:19:08.440 --> 01:19:09.520]   that they're all oracles
[01:19:09.520 --> 01:19:12.080]   because their lived experience informs us
[01:19:12.080 --> 01:19:14.920]   and their pain is more salient than everyone else's pain.
[01:19:14.920 --> 01:19:18.400]   Those people aren't necessarily great people.
[01:19:18.400 --> 01:19:24.800]   It's like none of us, we can't do this in this fashion.
[01:19:24.800 --> 01:19:27.640]   - So when we sit down to have a conversation
[01:19:27.640 --> 01:19:29.680]   across the table from somebody,
[01:19:29.680 --> 01:19:31.200]   you should be willing to,
[01:19:31.200 --> 01:19:33.900]   like you should not have NPR in your mind.
[01:19:33.900 --> 01:19:36.660]   You should be willing to take the full risk
[01:19:36.660 --> 01:19:38.660]   and to see the good in the person
[01:19:38.660 --> 01:19:41.940]   with limited information
[01:19:41.940 --> 01:19:44.540]   and to do your best to understand that person.
[01:19:44.540 --> 01:19:47.200]   - Everybody is entitled to a hypocrisy budget.
[01:19:47.200 --> 01:19:51.480]   I don't believe this is of institutions, okay?
[01:19:51.480 --> 01:19:53.820]   Everybody is entitled to a certain amount
[01:19:53.820 --> 01:19:55.200]   of screwing up in life.
[01:19:56.280 --> 01:19:58.760]   You're entitled to a mendacity budget.
[01:19:58.760 --> 01:20:01.860]   You're entitled to an aggression budget.
[01:20:01.860 --> 01:20:04.200]   The idea of getting rid of everybody,
[01:20:04.200 --> 01:20:07.820]   people haven't even blown through their budgets
[01:20:07.820 --> 01:20:08.660]   and we're already--
[01:20:08.660 --> 01:20:12.100]   - Yeah, I think about, for example, one person,
[01:20:12.100 --> 01:20:15.580]   I'd be curious to get your thoughts about Alex Jones.
[01:20:15.580 --> 01:20:17.140]   - Let's not talk about Alex Jones for a second.
[01:20:17.140 --> 01:20:19.620]   Let's talk about the National Enquirer.
[01:20:19.620 --> 01:20:22.180]   Is everything the National Enquirer says false?
[01:20:22.180 --> 01:20:24.460]   - No.
[01:20:25.580 --> 01:20:27.620]   - Do you remember the John Edwards story?
[01:20:27.620 --> 01:20:30.140]   - Did you know his wife?
[01:20:30.140 --> 01:20:30.980]   Sorry, I don't remember.
[01:20:30.980 --> 01:20:33.180]   - He had a child from an extramarital affair.
[01:20:33.180 --> 01:20:34.460]   - Yes.
[01:20:34.460 --> 01:20:37.460]   - I believe that the National Enquirer broke the story.
[01:20:37.460 --> 01:20:41.180]   And then what does the New York Times do?
[01:20:41.180 --> 01:20:43.940]   The New York Times, I think, is allowed to report
[01:20:43.940 --> 01:20:46.300]   that the National Enquirer is making a claim.
[01:20:46.300 --> 01:20:49.080]   That way they don't have to substantiate the story.
[01:20:49.080 --> 01:20:53.580]   So why is the New York Times talking to Mike Cernovich
[01:20:53.580 --> 01:20:56.220]   or using the National Enquirer as a source?
[01:20:56.220 --> 01:20:58.320]   Are they using Alex Jones as a source?
[01:20:58.320 --> 01:21:02.540]   Here's the big problem that we're having.
[01:21:02.540 --> 01:21:05.880]   Why are certain people entitled to talk to everybody
[01:21:05.880 --> 01:21:08.300]   and other people are entitled to talk to no one?
[01:21:08.300 --> 01:21:09.320]   I don't really understand this.
[01:21:09.320 --> 01:21:10.900]   This is an indulgence system.
[01:21:10.900 --> 01:21:13.340]   This is how the Catholic Church used to do things.
[01:21:13.340 --> 01:21:14.620]   - It's hard to fight the system
[01:21:14.620 --> 01:21:16.740]   because the reason you don't talk to Alex Jones
[01:21:16.740 --> 01:21:19.340]   is because the platforms on which we do the communication
[01:21:19.340 --> 01:21:21.940]   will de-platform, will remove you.
[01:21:21.940 --> 01:21:23.200]   - But I'm not platformed.
[01:21:23.200 --> 01:21:27.820]   I used to do NPR and I used to do the News Hour
[01:21:27.820 --> 01:21:29.980]   and I used to provide stories
[01:21:29.980 --> 01:21:32.660]   to Washington Post, New York Times.
[01:21:32.660 --> 01:21:33.900]   That has gone away.
[01:21:33.900 --> 01:21:36.940]   They've circled the wagons closer and closer
[01:21:36.940 --> 01:21:38.860]   and more of us are unacceptable.
[01:21:38.860 --> 01:21:40.500]   And right now I have no question
[01:21:40.500 --> 01:21:44.340]   that they're going through anybody who has a platform
[01:21:44.340 --> 01:21:46.780]   trying to say, okay, what do we have against that person
[01:21:46.780 --> 01:21:48.760]   in case we need to shut that down?
[01:21:48.760 --> 01:21:51.100]   We have to make a different decision, Lex,
[01:21:51.100 --> 01:21:54.320]   and the different decision is that it doesn't matter
[01:21:54.320 --> 01:21:57.620]   how many times Joe said the N word.
[01:21:57.620 --> 01:22:01.420]   It doesn't matter that somebody else,
[01:22:01.420 --> 01:22:05.580]   with mathematical theorems,
[01:22:05.580 --> 01:22:06.940]   if the worst person in the world
[01:22:06.940 --> 01:22:09.620]   proves a mathematical theorem like the Unabomber,
[01:22:09.620 --> 01:22:11.380]   we can't undo the theorem.
[01:22:11.380 --> 01:22:15.700]   And I point out Charles Manson's song,
[01:22:15.700 --> 01:22:18.540]   "Look at Your Game Girl" is an amazing song.
[01:22:18.540 --> 01:22:19.580]   It's a really good song.
[01:22:19.580 --> 01:22:22.140]   I don't think it's one of the greatest songs ever,
[01:22:22.140 --> 01:22:24.380]   but it happens that he wasn't a no talent.
[01:22:24.380 --> 01:22:29.300]   And I don't know how Hitler was as an artist.
[01:22:29.300 --> 01:22:30.780]   - Fiction, not bad.
[01:22:30.780 --> 01:22:33.740]   - Okay, we've got to get past this.
[01:22:33.740 --> 01:22:35.500]   We've got to get past this idea
[01:22:35.500 --> 01:22:37.880]   that we're gonna purge ourselves of our badness
[01:22:37.880 --> 01:22:39.020]   and we're just gonna,
[01:22:39.020 --> 01:22:42.420]   this is like, I've likened it to teenage girls in cutting.
[01:22:42.420 --> 01:22:46.460]   We're just, all we're doing is destroying ourselves
[01:22:46.460 --> 01:22:47.840]   in search of perfection.
[01:22:47.840 --> 01:22:49.980]   And the answer is no, we're not perfect.
[01:22:49.980 --> 01:22:52.180]   We're flawed, we're screwed up.
[01:22:52.180 --> 01:22:53.540]   And we've always been this way.
[01:22:53.540 --> 01:22:55.420]   And we're not going to silence everyone
[01:22:55.420 --> 01:22:57.920]   who you can point a laser beam at and say,
[01:22:57.920 --> 01:23:00.480]   well, that person, look at how bad that person is.
[01:23:00.480 --> 01:23:03.500]   If we do that, kiss the whole thing goodbye.
[01:23:03.500 --> 01:23:05.800]   We might as well just, let's learn Chinese.
[01:23:05.800 --> 01:23:10.500]   - But there is an art to having those messy conversations,
[01:23:10.500 --> 01:23:13.260]   whether with Alex or anybody else.
[01:23:13.260 --> 01:23:15.160]   - Okay, let's talk about Alex.
[01:23:15.160 --> 01:23:17.020]   There's particular stuff that Alex does
[01:23:17.020 --> 01:23:19.180]   that's absolutely nauseating.
[01:23:19.180 --> 01:23:21.020]   And there's other stuff that he's doing that's funny.
[01:23:21.020 --> 01:23:23.220]   - The methodology of the way he carries--
[01:23:23.220 --> 01:23:25.520]   - And sometimes he's talking about the truth.
[01:23:25.520 --> 01:23:27.460]   And sometimes he's talking about a conspiracy.
[01:23:27.460 --> 01:23:30.440]   His variance is incredibly high.
[01:23:30.440 --> 01:23:33.340]   The right way to approach Alex Jones or James O'Keefe
[01:23:33.340 --> 01:23:36.220]   or the National Enquirer or anything you don't like
[01:23:36.220 --> 01:23:38.380]   is to say, great, go long short.
[01:23:38.380 --> 01:23:40.300]   - What's that mean?
[01:23:40.300 --> 01:23:43.900]   - Well, if you invest in a mutual fund,
[01:23:43.900 --> 01:23:46.900]   all the stocks in the mutual fund are held long.
[01:23:46.900 --> 01:23:48.940]   But if you invest in a hedge fund,
[01:23:48.940 --> 01:23:51.220]   you do something called relative value trade.
[01:23:51.220 --> 01:23:54.360]   It's like, well, you long tech or short tech?
[01:23:54.360 --> 01:23:58.220]   Well, actually, I'm long Microsoft and I'm short Google.
[01:23:58.220 --> 01:24:00.300]   Why is that?
[01:24:00.300 --> 01:24:03.780]   Oh, because I believe Google got way too much attention
[01:24:03.780 --> 01:24:06.020]   and that Microsoft has been unfairly maligned.
[01:24:06.020 --> 01:24:08.780]   And so this is really a play on legacy tech
[01:24:08.780 --> 01:24:10.580]   over more modern tech.
[01:24:10.580 --> 01:24:14.540]   Okay, which part of Alex Jones are you long
[01:24:14.540 --> 01:24:15.620]   and which part are you short?
[01:24:15.620 --> 01:24:17.380]   One of the things that should be a requirement
[01:24:17.380 --> 01:24:18.580]   for being a reporter is like,
[01:24:18.580 --> 01:24:21.500]   what did Donald Trump do that was good?
[01:24:21.500 --> 01:24:22.700]   Nothing.
[01:24:22.700 --> 01:24:25.140]   Okay, then you're not a reporter.
[01:24:25.140 --> 01:24:26.780]   What did Hitler do that was good?
[01:24:26.780 --> 01:24:31.420]   The Rosenstrasse of protest.
[01:24:31.420 --> 01:24:37.340]   Non-Jewish women campaign for their Jewish men
[01:24:37.340 --> 01:24:40.820]   to be returned home to them from certain death
[01:24:40.820 --> 01:24:42.580]   almost in death camps.
[01:24:42.580 --> 01:24:45.860]   It should have been that there were no death camps.
[01:24:45.860 --> 01:24:48.780]   It should have been that everybody was returned home.
[01:24:48.780 --> 01:24:50.300]   But you know what?
[01:24:50.300 --> 01:24:53.620]   The fact that the women of the Rosenstrasse protest,
[01:24:53.620 --> 01:24:56.420]   I mean, sorry, I get very emotional about this.
[01:24:56.420 --> 01:24:58.620]   Some of the baddest ass chicks in the world
[01:24:58.620 --> 01:25:02.480]   got their husbands returned to them.
[01:25:03.620 --> 01:25:05.340]   Kolaka vote.
[01:25:05.340 --> 01:25:08.780]   And I'm not celebrating Hitler.
[01:25:08.780 --> 01:25:11.700]   Hitler's the worst of the worst.
[01:25:11.700 --> 01:25:15.620]   But God damn it, this idea that we can just say
[01:25:15.620 --> 01:25:17.780]   everything that person does is a lie,
[01:25:17.780 --> 01:25:19.620]   everything that person does is evil.
[01:25:19.620 --> 01:25:23.340]   This reflects a simplicity of mind
[01:25:23.340 --> 01:25:24.900]   that humanity cannot afford.
[01:25:24.900 --> 01:25:30.700]   Is Google evil because it will sell you Mein Kampf?
[01:25:30.700 --> 01:25:32.980]   Is Amazon evil because it will sell you Mein Kampf?
[01:25:32.980 --> 01:25:34.580]   If you find out that Mein Kampf
[01:25:34.580 --> 01:25:35.740]   rests on somebody's bookshelves,
[01:25:35.740 --> 01:25:37.500]   do you have any idea what it means?
[01:25:37.500 --> 01:25:41.400]   If you find out that a scholar used the N-word,
[01:25:41.400 --> 01:25:43.100]   should that person lose their job?
[01:25:43.100 --> 01:25:47.540]   Come on, grow the hell up.
[01:25:47.540 --> 01:25:50.840]   - I guess our responsibility to lead by example on that
[01:25:50.840 --> 01:25:55.220]   because you have to acknowledge that the current--
[01:25:55.220 --> 01:25:58.340]   - Have somebody on your podcast who you're worried about.
[01:26:01.860 --> 01:26:03.700]   But do it in a principled fashion.
[01:26:03.700 --> 01:26:08.500]   I mean, in other words, I'm not here to whitewash everything.
[01:26:08.500 --> 01:26:13.440]   On the other hand, if somebody makes some allegations,
[01:26:13.440 --> 01:26:16.260]   I don't know that I'm obligated
[01:26:16.260 --> 01:26:19.500]   to treat every set of allegations as if,
[01:26:19.500 --> 01:26:21.620]   how do you defend yourself against, no.
[01:26:21.620 --> 01:26:24.620]   Allegations are so cheap to make at this moment.
[01:26:24.620 --> 01:26:27.100]   - Well, my standard, I don't know,
[01:26:27.100 --> 01:26:29.860]   maybe you could speak to it, is I don't care,
[01:26:29.860 --> 01:26:32.060]   like in the case of Alex Jones, for example,
[01:26:32.060 --> 01:26:36.020]   I'm willing to have a conversation with Alex Jones
[01:26:36.020 --> 01:26:38.620]   and people like him if I know
[01:26:38.620 --> 01:26:40.620]   he's not going to try to manipulate me.
[01:26:40.620 --> 01:26:42.340]   - Assume that he is gonna try to manipulate you.
[01:26:42.340 --> 01:26:45.300]   - I can't, then we're not going to be two humans.
[01:26:45.300 --> 01:26:48.220]   - Okay, but Lex, I want you to think well of me.
[01:26:48.220 --> 01:26:51.480]   I put on a jacket, I don't usually wear a jacket, okay?
[01:26:51.480 --> 01:26:53.320]   - Thank you, Eric.
[01:26:53.320 --> 01:26:55.780]   - All right, I'm trying to manipulate you.
[01:26:55.780 --> 01:26:59.220]   There's an entire field, no, there's an entire field
[01:26:59.220 --> 01:27:01.860]   that says that speech may be best thought of
[01:27:01.860 --> 01:27:04.160]   as an attempt to manipulate each other.
[01:27:04.160 --> 01:27:06.460]   This is too simplistic.
[01:27:06.460 --> 01:27:08.540]   Everything that we keep talking through,
[01:27:08.540 --> 01:27:10.020]   - Yes.
[01:27:10.020 --> 01:27:11.540]   - You know better than this.
[01:27:11.540 --> 01:27:12.380]   - I disagree.
[01:27:12.380 --> 01:27:17.180]   I think there's ways, there's, of course,
[01:27:17.180 --> 01:27:20.540]   it's a gray area, but there is a threshold
[01:27:20.540 --> 01:27:23.380]   where your intent with which you come to a meeting,
[01:27:23.380 --> 01:27:28.340]   to an interaction, is one that is not one
[01:27:28.340 --> 01:27:32.260]   that is grounded in a respect for a common humanity,
[01:27:32.260 --> 01:27:34.540]   like a love for each other, as deeply messy as humans.
[01:27:34.540 --> 01:27:36.660]   - If somebody's doing really bad stuff,
[01:27:36.660 --> 01:27:38.700]   I expect you to try to keep them
[01:27:38.700 --> 01:27:40.700]   from doing really bad stuff.
[01:27:40.700 --> 01:27:44.760]   But just keep in mind that when I was a younger man,
[01:27:44.760 --> 01:27:49.480]   I saw an amazing anti-pornography documentary,
[01:27:49.480 --> 01:27:52.580]   and it was called "Rate It X,"
[01:27:52.580 --> 01:27:54.140]   and I don't know where it went,
[01:27:54.140 --> 01:27:57.280]   but the conceit of it was,
[01:27:57.280 --> 01:27:59.540]   we're going to get some pornographers
[01:27:59.540 --> 01:28:02.060]   in front of a camera because they want to talk,
[01:28:02.060 --> 01:28:04.620]   and we're going to ask them about what they do for a living
[01:28:04.620 --> 01:28:06.360]   and why it's okay.
[01:28:06.360 --> 01:28:09.120]   No commentary.
[01:28:09.120 --> 01:28:13.980]   Okay?
[01:28:13.980 --> 01:28:16.080]   You could potentially,
[01:28:16.080 --> 01:28:18.060]   if you really think Alex Jones is the worst,
[01:28:18.060 --> 01:28:20.700]   and again, I'm not intimately familiar with him,
[01:28:20.700 --> 01:28:24.340]   you could decide to
[01:28:25.180 --> 01:28:29.600]   just let him talk.
[01:28:29.600 --> 01:28:32.820]   Now, I have decided not to do that with particular people.
[01:28:32.820 --> 01:28:35.400]   I've spoken to Stefan Molyneux.
[01:28:35.400 --> 01:28:37.760]   Stefan Molyneux makes many good points,
[01:28:37.760 --> 01:28:39.480]   and makes many bad points,
[01:28:39.480 --> 01:28:42.360]   and he makes many good points in bad ways,
[01:28:42.360 --> 01:28:43.680]   and I worry about it,
[01:28:43.680 --> 01:28:45.320]   and I don't feel that it's,
[01:28:45.320 --> 01:28:47.060]   it's not my obligation to make sure
[01:28:47.060 --> 01:28:49.960]   that Stefan Molyneux has a voice on the portal.
[01:28:49.960 --> 01:28:53.960]   But I did stand up and say,
[01:28:53.960 --> 01:28:56.160]   I didn't want him banned from social media,
[01:28:56.160 --> 01:28:58.900]   and I do think that a lot of the people
[01:28:58.900 --> 01:29:00.580]   who are being banned from social media
[01:29:00.580 --> 01:29:01.780]   were worried that they're right
[01:29:01.780 --> 01:29:03.720]   rather than that they're wrong.
[01:29:03.720 --> 01:29:06.780]   I certainly don't really think that I'm worried
[01:29:06.780 --> 01:29:10.640]   in some sense that some of the really wrong people
[01:29:10.640 --> 01:29:13.080]   are wrong, but if you look at, for example, Curtis Yarvin,
[01:29:13.080 --> 01:29:15.000]   there's a tremendous amount of interest.
[01:29:15.000 --> 01:29:17.500]   Is Eric going to speak to Curtis Yarvin?
[01:29:17.500 --> 01:29:20.160]   Curtis Yarvin says many interesting things,
[01:29:20.160 --> 01:29:21.880]   and he says many horrible, stupid things,
[01:29:21.880 --> 01:29:23.720]   very provocative.
[01:29:23.720 --> 01:29:28.280]   And I don't, I haven't invited him onto the portal,
[01:29:28.280 --> 01:29:32.000]   but I haven't said I will never invite him onto the portal.
[01:29:32.000 --> 01:29:34.960]   We are all in a difficult position.
[01:29:34.960 --> 01:29:35.800]   - That's what I'm saying.
[01:29:35.800 --> 01:29:37.240]   You're making it kind of,
[01:29:37.240 --> 01:29:39.800]   I think it's a much more difficult task that,
[01:29:39.800 --> 01:29:42.980]   and burden, Cary, as people who have conversations,
[01:29:42.980 --> 01:29:46.040]   because Curtis Yarvin is a good example.
[01:29:46.040 --> 01:29:50.040]   How much work do I have to put in reading Curtis's work
[01:29:50.040 --> 01:29:51.360]   to really understand--
[01:29:51.360 --> 01:29:53.040]   - Let's talk about the problem of Curtis Yarvin.
[01:29:53.040 --> 01:29:53.880]   - Yes.
[01:29:53.880 --> 01:29:55.600]   - 'Cause I think it's probably ill-stripped.
[01:29:55.600 --> 01:29:57.740]   There's this big question is why does somebody
[01:29:57.740 --> 01:30:01.880]   who says such stupid-ass things listen to by so many people?
[01:30:01.880 --> 01:30:04.760]   Very smart people, people who are part of our daily lives
[01:30:04.760 --> 01:30:07.480]   discuss Curtis Yarvin in hushed tones.
[01:30:07.480 --> 01:30:09.080]   Now-- - That's a good question.
[01:30:09.080 --> 01:30:12.520]   - My belief is that Curtis Yarvin has made a number
[01:30:12.520 --> 01:30:15.800]   of very interesting, provocative points,
[01:30:15.800 --> 01:30:18.800]   and they associate Curtis Yarvin as the person
[01:30:18.800 --> 01:30:20.480]   who has made these points,
[01:30:20.480 --> 01:30:23.520]   and they treat the completely asinine stuff
[01:30:23.520 --> 01:30:26.680]   that he says that's super dangerous as,
[01:30:26.680 --> 01:30:27.880]   well, that's Curtis.
[01:30:27.880 --> 01:30:30.720]   Right? - Right.
[01:30:30.720 --> 01:30:31.720]   They give him the credit for,
[01:30:31.720 --> 01:30:34.160]   he's a kind of like, sorry to use the term,
[01:30:34.160 --> 01:30:36.360]   first principles deep thinker about--
[01:30:36.360 --> 01:30:38.600]   - In some category. - In some space
[01:30:38.600 --> 01:30:40.280]   about the world.
[01:30:40.280 --> 01:30:43.160]   - But as a result, we don't actually know
[01:30:43.160 --> 01:30:45.860]   why Curtis Yarvin is knocking around
[01:30:46.960 --> 01:30:51.200]   so many Silicon Valley luminaries' lives.
[01:30:51.200 --> 01:30:53.320]   - Well, see, you said that he said a lot
[01:30:53.320 --> 01:30:55.680]   of asinine stupid stuff, and that's a sense I got
[01:30:55.680 --> 01:30:57.920]   from a few things I've read, not just about him.
[01:30:57.920 --> 01:31:00.040]   This is not just Wikipedia stuff.
[01:31:00.040 --> 01:31:03.160]   Is he's a little, like I've said before,
[01:31:03.160 --> 01:31:05.760]   he seems to be careless.
[01:31:05.760 --> 01:31:06.600]   - I don't think he's careless.
[01:31:06.600 --> 01:31:08.000]   No, no, it's like Jim Watson.
[01:31:08.000 --> 01:31:12.360]   Jim Watson wants to say very provocative things
[01:31:12.360 --> 01:31:14.600]   in order to prove that he's free.
[01:31:14.600 --> 01:31:15.840]   It's not a question of careless.
[01:31:15.840 --> 01:31:20.600]   He enjoys the freedom to say these things.
[01:31:20.600 --> 01:31:22.320]   And the key point is that there's,
[01:31:22.320 --> 01:31:25.440]   I expect something more of Curtis.
[01:31:25.440 --> 01:31:27.880]   I expect that if somebody is insightful
[01:31:27.880 --> 01:31:30.180]   about all sorts of things up to that point,
[01:31:30.180 --> 01:31:33.280]   that they're going to have enough care.
[01:31:33.280 --> 01:31:35.400]   Now, I, for example, make this point repeatedly
[01:31:35.400 --> 01:31:38.160]   that vaccines are not 100% safe.
[01:31:38.160 --> 01:31:41.000]   Most people who have an idea that anybody
[01:31:41.000 --> 01:31:43.800]   who's an anti-vaxxer should be silenced
[01:31:43.800 --> 01:31:46.680]   are in a position where they probably don't say
[01:31:46.680 --> 01:31:49.000]   vaccines are 100% safe, but you keep finding
[01:31:49.000 --> 01:31:50.480]   that statement over and over again.
[01:31:50.480 --> 01:31:53.280]   Believe all women, vaccines are 100% safe.
[01:31:53.280 --> 01:31:55.680]   Climate science is settled science.
[01:31:55.680 --> 01:31:57.400]   Whatever this Mont and Bailey is,
[01:31:57.400 --> 01:32:02.400]   where you make extraordinarily vapid blanket claims,
[01:32:02.400 --> 01:32:04.200]   and then you retreat into something.
[01:32:04.200 --> 01:32:07.080]   Well, defund the, we don't want no more police,
[01:32:07.080 --> 01:32:09.880]   actually just means we want the police
[01:32:09.880 --> 01:32:12.780]   to not take on mental health duties.
[01:32:13.780 --> 01:32:17.620]   We've come up with an incredibly disingenuous society.
[01:32:17.620 --> 01:32:21.100]   And what I'm claiming is, is that I might talk
[01:32:21.100 --> 01:32:25.380]   to Curtis Yarvin, but I have really very little interest
[01:32:25.380 --> 01:32:28.260]   to talk to a guy who seems to be kind of giddy
[01:32:28.260 --> 01:32:31.460]   about who makes good slaves and who makes bad slaves.
[01:32:31.460 --> 01:32:34.260]   It's like, why do I want to do that on the portal?
[01:32:34.260 --> 01:32:37.860]   - One, first of all, because just as you said,
[01:32:37.860 --> 01:32:39.660]   that's not Curtis's main thing.
[01:32:39.660 --> 01:32:43.780]   He has a lot of ideas and what I've read of him,
[01:32:43.780 --> 01:32:48.200]   which is not a huge amount, is he's very thoughtful
[01:32:48.200 --> 01:32:50.540]   about the way this world works.
[01:32:50.540 --> 01:32:54.660]   And on top of that, he's an important historical figure
[01:32:54.660 --> 01:32:57.900]   in the birth and the development of the alt-right,
[01:32:57.900 --> 01:32:59.340]   or what would be called the alt-right.
[01:32:59.340 --> 01:33:00.460]   - Or the new reactionary movement.
[01:33:00.460 --> 01:33:05.460]   - Yeah, and there's, so he's just an important intellectual.
[01:33:05.460 --> 01:33:07.460]   And so it makes sense to talk to him.
[01:33:07.460 --> 01:33:10.900]   The question is, how much work do you put in?
[01:33:10.900 --> 01:33:12.780]   - Well, this is the issue of fugu.
[01:33:12.780 --> 01:33:16.500]   I'm not a chef that necessarily can serve that fugu.
[01:33:16.500 --> 01:33:21.600]   So you have a puffer fish, you can eat the puffer fish,
[01:33:21.600 --> 01:33:25.140]   you can get kind of a tingly sensation on your tongue
[01:33:25.140 --> 01:33:27.160]   if you get a little bit of the poison organ.
[01:33:27.160 --> 01:33:30.820]   But my point is, I don't know how to serve Curtis Yarvin
[01:33:30.820 --> 01:33:34.700]   so that, in fact, I'm not worried about what happens.
[01:33:34.700 --> 01:33:37.300]   But I believe that if somebody else was a student
[01:33:37.300 --> 01:33:39.380]   of the new reactionary movement,
[01:33:39.380 --> 01:33:41.440]   that person might be in a better position
[01:33:41.440 --> 01:33:43.020]   to host Curtis Yarvin.
[01:33:43.020 --> 01:33:44.860]   - So somebody, that's a really good example,
[01:33:44.860 --> 01:33:47.700]   somebody I think you've spoken with
[01:33:47.700 --> 01:33:49.940]   that's an intermediary, that's a powerful one,
[01:33:49.940 --> 01:33:52.740]   is Michael Malice, and he's spoken with Curtis Yarvin.
[01:33:52.740 --> 01:33:55.060]   And Michael wrote a book about--
[01:33:55.060 --> 01:33:57.080]   - By the way, Michael somewhat changed my mind
[01:33:57.080 --> 01:33:58.700]   about Michael Malice.
[01:33:58.700 --> 01:33:59.740]   - I'm glad he did.
[01:33:59.740 --> 01:34:02.720]   I think, I would call him a friend,
[01:34:02.720 --> 01:34:05.800]   and I think he's a, underneath it all,
[01:34:05.800 --> 01:34:08.680]   a really kind human being.
[01:34:08.680 --> 01:34:11.080]   And I think your skepticism about him was initially
[01:34:11.080 --> 01:34:13.440]   from a surface level of, what did you call him,
[01:34:13.440 --> 01:34:15.880]   hyenas, the trolls, and so on.
[01:34:15.880 --> 01:34:17.500]   - I'm not happy about his,
[01:34:17.500 --> 01:34:23.180]   it's been so long since I've seen good trolls.
[01:34:23.180 --> 01:34:26.440]   - Yes, so he needs (laughs)
[01:34:26.440 --> 01:34:28.840]   he needs a higher quality of trolling.
[01:34:28.840 --> 01:34:30.320]   But he aspires to that.
[01:34:30.320 --> 01:34:33.840]   I mean, disagree or not,
[01:34:33.840 --> 01:34:38.100]   I really enjoy how much care he puts
[01:34:38.100 --> 01:34:40.680]   into the work he does on North Korea
[01:34:40.680 --> 01:34:42.240]   and the study of the world,
[01:34:42.240 --> 01:34:45.800]   and how much, privately, but also in public,
[01:34:45.800 --> 01:34:50.240]   love he has for people, especially those who are powerless.
[01:34:50.240 --> 01:34:53.200]   Just a genuine admiration for them.
[01:34:53.200 --> 01:34:57.280]   - But I think Curtis actually--
[01:34:57.280 --> 01:34:58.120]   - Does too.
[01:34:58.120 --> 01:34:59.040]   - I don't know.
[01:34:59.040 --> 01:34:59.960]   I mean, you have to appreciate,
[01:34:59.960 --> 01:35:01.640]   the first time I met Curtis,
[01:35:01.640 --> 01:35:02.880]   he introduced me, he says,
[01:35:02.880 --> 01:35:05.560]   "I'm the most right-wing person you've ever met."
[01:35:05.560 --> 01:35:07.440]   I was just like, well, this is a conversation
[01:35:07.440 --> 01:35:09.160]   that's already over.
[01:35:09.160 --> 01:35:12.780]   - It's theatrical in a way that's not conductive
[01:35:12.780 --> 01:35:14.640]   to actually having a real connection.
[01:35:14.640 --> 01:35:18.120]   - It turned me off because it was like,
[01:35:18.120 --> 01:35:19.960]   you need to be the most right-wing person,
[01:35:19.960 --> 01:35:22.520]   and so it's like, I'm a troll, I'm a troll.
[01:35:22.520 --> 01:35:24.340]   Okay, why are we doing this?
[01:35:24.340 --> 01:35:25.960]   But what I'm trying to get at is different.
[01:35:25.960 --> 01:35:29.160]   I'm trying to say that Michael Malice is a friend of yours.
[01:35:29.160 --> 01:35:31.600]   If you found out something terrible,
[01:35:31.600 --> 01:35:34.600]   you should still continue to be his friend.
[01:35:34.600 --> 01:35:36.560]   - And in Michael Malice's case,
[01:35:36.560 --> 01:35:38.680]   it's very likely that we'll find out something terrible.
[01:35:38.680 --> 01:35:40.220]   - Curtis is an acquaintance of mine
[01:35:40.220 --> 01:35:42.660]   because he hangs around with some people that I know.
[01:35:42.660 --> 01:35:44.400]   I did not get it.
[01:35:44.400 --> 01:35:47.420]   I've started to understand why the people in my life,
[01:35:47.420 --> 01:35:51.040]   some of them are Curtis Yarvin fans.
[01:35:51.040 --> 01:35:54.020]   Many of them disregard the stupid stuff,
[01:35:54.020 --> 01:35:58.040]   but my feeling is that too much poison organ,
[01:35:58.040 --> 01:36:00.520]   not enough fish, I don't know how to serve that.
[01:36:00.520 --> 01:36:01.360]   It's too intermingled.
[01:36:01.360 --> 01:36:02.960]   I'm not your chef.
[01:36:02.960 --> 01:36:04.800]   - Speaking for defending your friends,
[01:36:04.800 --> 01:36:06.680]   staying with your friends,
[01:36:06.680 --> 01:36:10.640]   and bringing the old band together again,
[01:36:10.640 --> 01:36:14.380]   you coined the term IDW, Intellectual Dark Web.
[01:36:14.380 --> 01:36:16.520]   I like it.
[01:36:16.520 --> 01:36:19.240]   It represents a certain group of people
[01:36:19.240 --> 01:36:22.040]   that are struggling with,
[01:36:22.040 --> 01:36:26.680]   that are almost like challenged the norms
[01:36:26.680 --> 01:36:31.680]   of social and political discourse from all different angles.
[01:36:31.680 --> 01:36:33.880]   What do you think is the state of the IDW?
[01:36:33.880 --> 01:36:35.600]   What do you think is its future?
[01:36:35.600 --> 01:36:39.080]   Is it still a useful?
[01:36:39.080 --> 01:36:40.160]   - Well, it never exists.
[01:36:40.160 --> 01:36:41.400]   Is it a protocol?
[01:36:41.400 --> 01:36:44.080]   Is it a collection of people featured in an article?
[01:36:44.080 --> 01:36:46.600]   What I learned very clearly is that
[01:36:46.600 --> 01:36:49.080]   there's a tremendous desire in the internet age
[01:36:49.080 --> 01:36:50.160]   to pin people down.
[01:36:50.160 --> 01:36:51.000]   Well, what do you say?
[01:36:51.000 --> 01:36:51.820]   Who's in it?
[01:36:51.820 --> 01:36:53.240]   What are the criterion?
[01:36:53.240 --> 01:36:55.520]   It's like, I understand.
[01:36:55.520 --> 01:36:57.240]   You want to play the demarcation game
[01:36:57.240 --> 01:36:59.760]   and you want to make everything that is demarcated
[01:36:59.760 --> 01:37:01.500]   instantly null and void.
[01:37:01.500 --> 01:37:02.740]   No, thank you.
[01:37:02.740 --> 01:37:06.100]   So I resisted saying who was in it.
[01:37:06.100 --> 01:37:07.760]   I resisted saying what it was.
[01:37:07.760 --> 01:37:10.240]   I resisted saying that Barry Weiss's article
[01:37:10.240 --> 01:37:11.640]   was the definitive thing.
[01:37:11.640 --> 01:37:17.020]   They chose a ridiculous concept for the photographs
[01:37:17.020 --> 01:37:18.320]   that we couldn't get out of.
[01:37:18.320 --> 01:37:20.400]   I did not want those photographs taken.
[01:37:20.400 --> 01:37:23.000]   They decided that the Pulitzer Prize winning photographer
[01:37:23.000 --> 01:37:25.200]   needed to take them all at twilight.
[01:37:25.200 --> 01:37:27.440]   I don't know, some such thing.
[01:37:27.440 --> 01:37:29.840]   I didn't even necessarily want to do the article.
[01:37:29.840 --> 01:37:32.240]   Barry convinced me that it was the right thing to do.
[01:37:32.240 --> 01:37:33.560]   Undoubtedly, Barry was right.
[01:37:33.560 --> 01:37:35.020]   I was wrong.
[01:37:35.020 --> 01:37:40.020]   But the key point is nothing can grow in this environment.
[01:37:40.020 --> 01:37:42.360]   There's a reason we're not building.
[01:37:42.360 --> 01:37:46.040]   It does not appear that we found a way
[01:37:46.040 --> 01:37:49.460]   to grow anything organic and good and decent
[01:37:49.460 --> 01:37:50.960]   that we need right now.
[01:37:50.960 --> 01:37:52.920]   And that's kind of the key issue.
[01:37:52.920 --> 01:37:53.760]   - Who's the we?
[01:37:53.760 --> 01:37:55.240]   You mean us as a society?
[01:37:55.240 --> 01:37:57.600]   - Those of us who wish to have a future
[01:37:57.600 --> 01:37:59.200]   for our great-grandchildren.
[01:37:59.200 --> 01:38:02.560]   Let's take the subset of people who are worried
[01:38:02.560 --> 01:38:04.640]   about things long after their demise.
[01:38:04.640 --> 01:38:09.960]   - But do you think it's useful to have a term like the IDW
[01:38:09.960 --> 01:38:13.120]   to capture some set of people,
[01:38:13.120 --> 01:38:18.120]   some set of ideas or maybe principles
[01:38:18.120 --> 01:38:21.760]   that capture what I think the IDW,
[01:38:21.760 --> 01:38:23.960]   okay, you can say it's not supposed to mean,
[01:38:23.960 --> 01:38:25.720]   it doesn't exist, it doesn't mean anything,
[01:38:25.720 --> 01:38:29.240]   but to the public, to me, okay, I'll just speak to me,
[01:38:29.240 --> 01:38:30.560]   it represented something.
[01:38:30.560 --> 01:38:31.400]   - Yeah.
[01:38:31.400 --> 01:38:34.480]   - It represented, I think I just said this to you,
[01:38:34.480 --> 01:38:38.320]   it's my first attempt to interview
[01:38:38.320 --> 01:38:39.960]   the great Eric Weinstein.
[01:38:39.960 --> 01:38:42.040]   I said that, I spoke this about you,
[01:38:42.040 --> 01:38:44.260]   but IDW in general is trying to point out
[01:38:44.260 --> 01:38:46.720]   the elephant in the room or that the emperor has no clothes,
[01:38:46.720 --> 01:38:49.440]   the set of people that do that in their own way.
[01:38:49.440 --> 01:38:51.740]   - If there are multiple elephants in the room.
[01:38:51.740 --> 01:38:52.580]   - Yes.
[01:38:52.580 --> 01:38:54.600]   - The point is that the IDW is more interested
[01:38:54.600 --> 01:38:56.880]   in seeing the totality of elephants
[01:38:56.880 --> 01:38:59.240]   and trying to figure out how do we move forward
[01:38:59.240 --> 01:39:01.480]   as opposed to saying I can spot the other guy's elephant
[01:39:01.480 --> 01:39:03.720]   in the room, but I can't see my own.
[01:39:03.720 --> 01:39:07.840]   And in large measure, we didn't represent
[01:39:07.840 --> 01:39:10.620]   an institutional base and therefore,
[01:39:10.620 --> 01:39:12.840]   it wasn't maximally important that we look
[01:39:12.840 --> 01:39:15.400]   at our own hypocrisy because we weren't
[01:39:15.400 --> 01:39:18.680]   on the institutional spectrum.
[01:39:18.680 --> 01:39:20.520]   - This is where friendship comes into play
[01:39:20.520 --> 01:39:23.000]   with the different figures that are loosely
[01:39:23.000 --> 01:39:27.500]   associated with IDW is you are somehow responsible
[01:39:27.500 --> 01:39:33.240]   for the exact thing that you said.
[01:39:33.240 --> 01:39:36.400]   Did you hear what, I don't know, I forget,
[01:39:36.400 --> 01:39:39.440]   oh, what Sam Harris said about IDW?
[01:39:39.440 --> 01:39:40.720]   - Yeah.
[01:39:40.720 --> 01:39:41.560]   - That kind of thing.
[01:39:41.560 --> 01:39:42.600]   - I chuckled.
[01:39:42.600 --> 01:39:46.400]   - Lovingly or chuckled like--
[01:39:46.400 --> 01:39:49.400]   - I was angry at some people who had said things
[01:39:49.400 --> 01:39:51.240]   that caused Sam to say what Sam said
[01:39:51.240 --> 01:39:54.120]   about turning his imaginary club membership
[01:39:54.120 --> 01:39:55.880]   into the IDW.
[01:39:55.880 --> 01:39:59.720]   People said very silly things and I think
[01:39:59.720 --> 01:40:04.320]   that there is just this confusion that integrity
[01:40:04.320 --> 01:40:07.640]   means calling out your friends in front of the world.
[01:40:07.640 --> 01:40:12.320]   I've been pretty clear about this.
[01:40:12.320 --> 01:40:13.880]   I try to choose my friends carefully
[01:40:13.880 --> 01:40:16.280]   and if you would like to recuse me
[01:40:16.280 --> 01:40:18.760]   because I'm not a source of reliable information,
[01:40:18.760 --> 01:40:20.600]   people that I know and love the most,
[01:40:20.600 --> 01:40:23.960]   maybe that's reasonable for you.
[01:40:23.960 --> 01:40:25.720]   Maybe you prefer somebody who was willing
[01:40:25.720 --> 01:40:27.480]   to throw a friend under the bus
[01:40:27.480 --> 01:40:29.200]   at the first sign of trouble.
[01:40:29.200 --> 01:40:31.640]   By all means, exit my feed.
[01:40:31.640 --> 01:40:33.040]   You don't have to subscribe to me.
[01:40:33.040 --> 01:40:36.000]   If that's your concept of integrity,
[01:40:36.000 --> 01:40:38.840]   you're barking up the wrong tree.
[01:40:38.840 --> 01:40:40.720]   What I will say is that I knew these people
[01:40:40.720 --> 01:40:43.020]   well enough to know that they're all flawed.
[01:40:43.020 --> 01:40:46.840]   - Thank you for the callback.
[01:40:46.840 --> 01:40:51.840]   - But the issue is that I love people who are flawed
[01:40:51.840 --> 01:40:55.720]   and I love people who have to earn a living
[01:40:55.720 --> 01:40:57.040]   even if you call them a grifter
[01:40:57.040 --> 01:41:01.480]   and I love people who like the fact
[01:41:01.480 --> 01:41:03.520]   that Donald Trump didn't get us into new wars
[01:41:03.520 --> 01:41:05.600]   even if you call them alt-right.
[01:41:05.600 --> 01:41:09.640]   I love the fact that some people believe
[01:41:09.640 --> 01:41:12.520]   in structural oppression and wanna fight it
[01:41:12.520 --> 01:41:15.560]   even if they're not woke because they don't believe
[01:41:15.560 --> 01:41:17.960]   that structural oppression is hiding everywhere.
[01:41:17.960 --> 01:41:21.760]   I care and love different people in different ways
[01:41:21.760 --> 01:41:24.400]   and I think that the overarching thing, Lex,
[01:41:24.400 --> 01:41:27.280]   that we're not getting at is that we were sold a bill
[01:41:27.280 --> 01:41:30.880]   of goods that you can go through life
[01:41:30.880 --> 01:41:35.680]   like an Eliza program with pre-programmed responses.
[01:41:35.680 --> 01:41:39.880]   Well, it's whataboutism, it's both sides-ism,
[01:41:39.880 --> 01:41:42.760]   it's alt-right, it's the loony left,
[01:41:42.760 --> 01:41:44.040]   it's campus madness.
[01:41:44.040 --> 01:41:46.600]   It's like, okay, why don't you just empty
[01:41:46.600 --> 01:41:49.380]   the entire goddamn magazine?
[01:41:49.380 --> 01:41:56.180]   All of those pre-recorded snips,
[01:41:56.180 --> 01:41:59.460]   now that you've done all of that,
[01:41:59.460 --> 01:42:02.240]   now we can have a conversation.
[01:42:02.240 --> 01:42:05.180]   - Your son put it really well,
[01:42:05.180 --> 01:42:09.960]   which is we should in all things resist labels.
[01:42:09.960 --> 01:42:13.000]   - But we can't deal without labels.
[01:42:13.000 --> 01:42:17.680]   We have to generalize, but we also have to keep in mind
[01:42:17.680 --> 01:42:19.560]   that just in the way in science,
[01:42:19.560 --> 01:42:20.880]   you deal with an effective theory
[01:42:20.880 --> 01:42:22.320]   that isn't a fundamental one.
[01:42:22.320 --> 01:42:25.400]   In science, most of our theories
[01:42:25.400 --> 01:42:27.340]   we consider to be effective theories.
[01:42:27.340 --> 01:42:32.040]   If I generalize about Europe, about women,
[01:42:32.040 --> 01:42:37.040]   about Christians, those things have to be understood
[01:42:37.040 --> 01:42:42.400]   to mean something and not to have their definitions
[01:42:42.400 --> 01:42:46.860]   extend so broadly that they mean nothing at all,
[01:42:46.860 --> 01:42:51.240]   nor that they're so rigid that they're claims
[01:42:51.240 --> 01:42:53.180]   that clearly won't bear scrutiny.
[01:42:53.180 --> 01:42:56.560]   Lex, what do you really wanna talk about?
[01:42:56.560 --> 01:42:58.480]   That's always my question to you.
[01:42:58.480 --> 01:42:59.960]   - That always gets me, that's a good,
[01:42:59.960 --> 01:43:02.120]   maybe you are the therapist.
[01:43:02.120 --> 01:43:04.160]   - But you and I could talk about--
[01:43:04.160 --> 01:43:05.800]   - Anything. - People love,
[01:43:05.800 --> 01:43:08.560]   up until now at least, people have loved listening
[01:43:08.560 --> 01:43:10.800]   to the two of us in conversation.
[01:43:10.800 --> 01:43:13.120]   And my feeling is is that we're not talking
[01:43:13.120 --> 01:43:17.600]   about neural nets, and we're not talking
[01:43:17.600 --> 01:43:20.320]   about geometric unity, and we're not talking
[01:43:20.320 --> 01:43:23.600]   about where distributed computing might go.
[01:43:23.600 --> 01:43:25.800]   And I don't think that we're really focused
[01:43:25.800 --> 01:43:29.840]   on some of the most exciting things we could do
[01:43:29.840 --> 01:43:30.960]   to transform education.
[01:43:30.960 --> 01:43:34.520]   We're still caught in this world of other people
[01:43:34.520 --> 01:43:36.040]   that we don't belong in.
[01:43:36.040 --> 01:43:38.480]   I don't belong in the world as it's been created.
[01:43:38.480 --> 01:43:39.820]   I'm trying to build a new world,
[01:43:39.820 --> 01:43:44.120]   and I'm astounded that the people
[01:43:44.120 --> 01:43:46.600]   with the independent means to help build that world
[01:43:46.600 --> 01:43:49.800]   are so demotivated that they don't wanna
[01:43:49.800 --> 01:43:50.980]   build new structures.
[01:43:50.980 --> 01:43:54.360]   And the people who do wanna build new structures
[01:43:54.360 --> 01:43:56.120]   seem to be wild-eyed.
[01:43:56.120 --> 01:43:58.040]   - Wild-eyed, what do you mean by wild-eyed?
[01:43:58.040 --> 01:43:59.080]   They're not--
[01:43:59.080 --> 01:44:01.080]   - I guarantee you that I will get some message
[01:44:01.080 --> 01:44:03.760]   in my DMs that says, "Hey, Eric,
[01:44:03.760 --> 01:44:06.440]   "I'm a third-year chemistry student
[01:44:06.440 --> 01:44:08.760]   "at South Dakota State,
[01:44:08.760 --> 01:44:11.400]   "and I've got a great idea.
[01:44:11.400 --> 01:44:12.400]   "I just need funding.
[01:44:12.400 --> 01:44:13.300]   "I wanna build--"
[01:44:13.300 --> 01:44:14.420]   - They don't have the means.
[01:44:14.420 --> 01:44:16.460]   So the people who have the means--
[01:44:16.460 --> 01:44:18.140]   - Or the sophistication.
[01:44:18.140 --> 01:44:20.300]   It's like you're looking for somebody
[01:44:20.300 --> 01:44:22.700]   who's proven themselves a few times to say,
[01:44:22.700 --> 01:44:27.700]   "I've got $4 billion behind me that's soft-circled.
[01:44:27.700 --> 01:44:30.760]   "I wanna figure out what a new university would be
[01:44:30.760 --> 01:44:33.340]   "and what it would take to protect academic freedom
[01:44:33.340 --> 01:44:34.280]   "and who we would hire,
[01:44:34.280 --> 01:44:36.420]   "and what are the different characteristics?"
[01:44:36.420 --> 01:44:37.980]   Because I can clearly see that everything
[01:44:37.980 --> 01:44:40.060]   following the current model is falling apart.
[01:44:40.060 --> 01:44:43.460]   Nobody, in my understanding, is saying that.
[01:44:43.460 --> 01:44:47.580]   Nobody is saying, "Let's take that
[01:44:47.580 --> 01:44:51.020]   "which is functioning independently
[01:44:51.020 --> 01:44:53.300]   "and make it less vulnerable.
[01:44:53.300 --> 01:44:55.940]   "Let's boost those signals."
[01:44:55.940 --> 01:44:58.980]   - And a critical component as money, you think.
[01:44:58.980 --> 01:45:01.540]   - It's not only that, but it's also a kind of,
[01:45:01.540 --> 01:45:04.060]   "These people are mobbed up, hands off."
[01:45:04.060 --> 01:45:05.840]   Let's imagine for the moment
[01:45:05.840 --> 01:45:10.540]   that Sundar Pichai, Jack Dorsey, and Mark Zuckerberg
[01:45:10.540 --> 01:45:17.820]   founded a university-come-social-media entity.
[01:45:17.820 --> 01:45:22.080]   And they said, "The purpose of this
[01:45:22.080 --> 01:45:23.940]   "is to make sure that academic freedom
[01:45:23.940 --> 01:45:25.360]   "will not perish from this Earth
[01:45:25.360 --> 01:45:28.680]   "because it's necessary to keep us from all going crazy.
[01:45:28.680 --> 01:45:31.680]   "And we are going to lock ourselves out."
[01:45:31.680 --> 01:45:34.480]   We've come up with this governance system.
[01:45:34.480 --> 01:45:36.520]   And the idea is that these people
[01:45:36.520 --> 01:45:39.080]   will be assigned the difficult task
[01:45:39.080 --> 01:45:41.320]   of making sure that society doesn't go crazy
[01:45:41.320 --> 01:45:42.640]   in any particular direction.
[01:45:42.640 --> 01:45:45.560]   That we have a fact-based, reality-based,
[01:45:45.560 --> 01:45:48.400]   feasibility-based understanding.
[01:45:48.400 --> 01:45:51.580]   We can try to figure out where our real opportunities are.
[01:45:51.580 --> 01:45:56.980]   It feels like everybody with the ability
[01:45:56.980 --> 01:45:58.400]   to do something like that,
[01:45:58.400 --> 01:46:01.680]   and with the brains and experience and the resources,
[01:46:03.000 --> 01:46:05.400]   would rather sit in the current system
[01:46:05.400 --> 01:46:08.480]   and hope to figure out where they can flee to
[01:46:08.480 --> 01:46:10.240]   if the whole thing comes apart.
[01:46:10.240 --> 01:46:12.520]   - Well, yeah, and maybe to push back on it a little bit,
[01:46:12.520 --> 01:46:15.520]   I agree with you, but it feels like
[01:46:15.520 --> 01:46:17.580]   some people are trying that.
[01:46:17.580 --> 01:46:21.440]   So for example, Google purchased DeepMind.
[01:46:21.440 --> 01:46:23.640]   DeepMind is a company that kind of represents
[01:46:23.640 --> 01:46:25.400]   a lot of radical ideas.
[01:46:25.400 --> 01:46:27.840]   They've become acceptable, actually.
[01:46:27.840 --> 01:46:30.160]   AGI, Artificial General Intelligence,
[01:46:30.160 --> 01:46:35.160]   used to be really radical of a thing to talk about.
[01:46:35.160 --> 01:46:38.160]   And DeepMind and OpenAI are two places
[01:46:38.160 --> 01:46:39.800]   which has made it more acceptable.
[01:46:39.800 --> 01:46:43.880]   I know you can now start to criticize,
[01:46:43.880 --> 01:46:46.640]   well, they're really, now that it's become acceptable,
[01:46:46.640 --> 01:46:48.000]   they're not taking the further step
[01:46:48.000 --> 01:46:49.240]   of being more and more radical.
[01:46:49.240 --> 01:46:52.040]   But that was an attempt by Google to say
[01:46:52.040 --> 01:46:57.560]   that let's try some wild stuff.
[01:46:57.560 --> 01:46:59.360]   - Sort of like Boston Dynamics.
[01:46:59.360 --> 01:47:01.960]   Boston Dynamics is a really good example
[01:47:01.960 --> 01:47:06.960]   of trying radical ideas for perhaps no purpose whatsoever,
[01:47:06.960 --> 01:47:11.400]   except to try out their ideas.
[01:47:11.400 --> 01:47:14.840]   - Well, the idea is that innovation is like dessert.
[01:47:14.840 --> 01:47:18.400]   You can have dessert after you solve
[01:47:18.400 --> 01:47:19.760]   the problem of the main course,
[01:47:19.760 --> 01:47:22.880]   and the main course is a bunch of insoluble problems.
[01:47:22.880 --> 01:47:25.720]   So the idea is we can get into innovation
[01:47:25.720 --> 01:47:27.760]   once we perfect ourselves.
[01:47:27.760 --> 01:47:30.440]   - And you're saying that we need to make innovation
[01:47:30.440 --> 01:47:31.280]   the main meal.
[01:47:31.280 --> 01:47:34.760]   - Well, I'm saying that there really is structural oppression.
[01:47:34.760 --> 01:47:39.760]   I mean, if you train a deep learning system
[01:47:39.760 --> 01:47:46.240]   on exclusively white faces, it's gonna get confused.
[01:47:46.240 --> 01:47:50.360]   So let's not disagree that there are real issues around this.
[01:47:50.360 --> 01:47:53.480]   In fact, that's an issue of innovation and data.
[01:47:53.480 --> 01:47:55.840]   Your data should be responsive.
[01:47:55.840 --> 01:47:58.440]   On the other hand, there are things we can't do anything
[01:47:58.440 --> 01:48:02.080]   about that are actually fundamental.
[01:48:02.080 --> 01:48:07.080]   And those things may have to do with the fact
[01:48:07.080 --> 01:48:12.200]   that some of us taste cilantro as soap,
[01:48:12.200 --> 01:48:13.800]   and some of us don't.
[01:48:13.800 --> 01:48:15.640]   Like there are differences between people,
[01:48:15.640 --> 01:48:17.480]   and some of them are in the hardware,
[01:48:17.480 --> 01:48:18.560]   some of them are in the firmware,
[01:48:18.560 --> 01:48:22.320]   some of them are in the software that is the human mind.
[01:48:22.320 --> 01:48:27.000]   And this completely simplistic idea
[01:48:27.000 --> 01:48:32.000]   that every failure of an organization
[01:48:32.000 --> 01:48:35.720]   to promote each person who has particular
[01:48:35.720 --> 01:48:37.320]   intersexual characteristics,
[01:48:37.320 --> 01:48:42.480]   we cannot hold progress hostage to that.
[01:48:42.480 --> 01:48:44.200]   - And you've talked about,
[01:48:44.200 --> 01:48:46.680]   perhaps we'll save this for another time
[01:48:46.680 --> 01:48:48.040]   'cause it's such a fascinating conversation.
[01:48:48.040 --> 01:48:51.680]   You talked about this with Glenn Beck,
[01:48:51.680 --> 01:48:53.760]   is the whole sort of stagnation of growth
[01:48:53.760 --> 01:48:54.640]   and all that kind of stuff.
[01:48:54.640 --> 01:48:59.640]   Your idea is that in as much as the current situation
[01:48:59.640 --> 01:49:01.880]   is a kind of Ponzi scheme,
[01:49:01.880 --> 01:49:03.920]   the current situation in the United States
[01:49:03.920 --> 01:49:07.000]   is a kind of Ponzi scheme built on the promise
[01:49:07.000 --> 01:49:10.280]   of constant unending innovation.
[01:49:10.280 --> 01:49:15.280]   We need to fund the true innovators
[01:49:17.240 --> 01:49:22.080]   and encourage them and empower them
[01:49:22.080 --> 01:49:23.880]   and sort of culturally say that this is
[01:49:23.880 --> 01:49:27.560]   what this country is about, is the brilliant minds.
[01:49:27.560 --> 01:49:31.480]   - We're gonna kill each other if we don't grow.
[01:49:31.480 --> 01:49:33.500]   Growth is like an immune system,
[01:49:33.500 --> 01:49:36.760]   and you always have pathogens present.
[01:49:36.760 --> 01:49:37.960]   But if you don't have growth present,
[01:49:37.960 --> 01:49:40.240]   you can't fight the pathogens in your society.
[01:49:40.240 --> 01:49:42.880]   And right now the pathogens are spreading everywhere.
[01:49:42.880 --> 01:49:47.040]   So if we don't get growth into our system fairly quickly,
[01:49:47.040 --> 01:49:49.820]   we are in really seriously bad shape.
[01:49:49.820 --> 01:49:54.720]   So it's very important that if I had a horrible person
[01:49:54.720 --> 01:49:56.640]   who was capable of building something
[01:49:56.640 --> 01:49:59.200]   that would give us all a certain amount
[01:49:59.200 --> 01:50:02.120]   of what I've called financial beta to some new technology
[01:50:02.120 --> 01:50:05.520]   where we all benefit, let's say quantum computing comes in
[01:50:05.520 --> 01:50:07.540]   and everybody, the dry cleaner
[01:50:07.540 --> 01:50:09.960]   has a quantum computing angle, right?
[01:50:09.960 --> 01:50:10.880]   - Yes. - Okay.
[01:50:10.880 --> 01:50:15.740]   That's necessary to keep this system that we built going.
[01:50:15.740 --> 01:50:17.600]   We can try to redesign the system,
[01:50:17.600 --> 01:50:19.440]   but our system expects growth.
[01:50:19.440 --> 01:50:21.340]   And we've starved it for growth.
[01:50:21.340 --> 01:50:23.240]   And the madness that we're seeing
[01:50:23.240 --> 01:50:25.000]   is the failure of our immune system
[01:50:25.000 --> 01:50:26.440]   to be able to handle the pathogens
[01:50:26.440 --> 01:50:28.520]   that have always been present.
[01:50:28.520 --> 01:50:30.680]   So people can say, well, this was always there.
[01:50:30.680 --> 01:50:31.500]   Yes, it was.
[01:50:31.500 --> 01:50:33.280]   What's changed was your immune system.
[01:50:33.280 --> 01:50:38.160]   We have got to make sure that one,
[01:50:38.160 --> 01:50:40.160]   we understand why diversity
[01:50:40.160 --> 01:50:41.960]   is potentially really important.
[01:50:41.960 --> 01:50:45.480]   We have mined certain communities to death.
[01:50:45.480 --> 01:50:47.640]   You and I are Ashkenazi Jews.
[01:50:47.640 --> 01:50:49.760]   Everyone knows that Ashkenazi Jews
[01:50:49.760 --> 01:50:51.220]   are good at technical stuff.
[01:50:51.220 --> 01:50:54.820]   We know that the Chinese are good at technical stuff.
[01:50:54.820 --> 01:50:56.320]   The Indians have many people
[01:50:56.320 --> 01:50:58.840]   who are good at technical stuff as the Japanese.
[01:50:58.840 --> 01:51:03.000]   I also believe that we have communities
[01:51:03.000 --> 01:51:05.520]   where if you think about the Pareto idea
[01:51:05.520 --> 01:51:06.880]   of diminishing returns,
[01:51:06.880 --> 01:51:08.880]   if you've never mined a community,
[01:51:08.880 --> 01:51:11.400]   many of the people you're gonna get at the beginning
[01:51:11.400 --> 01:51:13.880]   are gonna be amazing because that community,
[01:51:13.880 --> 01:51:16.600]   it's like, did you drill for more oil in Texas?
[01:51:16.600 --> 01:51:19.080]   Texas is pretty thoroughly picked over.
[01:51:19.080 --> 01:51:23.040]   Do you find some place that's completely insane?
[01:51:23.040 --> 01:51:24.800]   Maybe there's oil there, who knows?
[01:51:24.800 --> 01:51:29.960]   In particular, I would like to displace our reliance
[01:51:29.960 --> 01:51:32.180]   on our military competitors in Asia
[01:51:32.180 --> 01:51:35.320]   in our scientific laboratories with women,
[01:51:35.320 --> 01:51:37.980]   with African-Americans, with Latinos,
[01:51:37.980 --> 01:51:40.600]   people who are in different categories
[01:51:40.600 --> 01:51:42.000]   than we have traditionally sourced.
[01:51:42.040 --> 01:51:44.120]   And I would like to get them the money
[01:51:44.120 --> 01:51:48.040]   that the market would normally give these fields
[01:51:48.040 --> 01:51:51.160]   were we not using visas in place of payment.
[01:51:51.160 --> 01:51:57.560]   Now, I have a crazy idea, which is that I play,
[01:51:57.560 --> 01:51:59.800]   you and I both play music.
[01:51:59.800 --> 01:52:02.400]   And I find the analytic work that I do
[01:52:02.400 --> 01:52:04.200]   when I'm trying to figure out chord progressions
[01:52:04.200 --> 01:52:06.600]   and symmetries and tritones, all these sorts of things,
[01:52:06.600 --> 01:52:08.080]   to be very similar to the work that I do
[01:52:08.080 --> 01:52:09.380]   when I do physics or math.
[01:52:10.840 --> 01:52:13.800]   I believe that one of the things that is true
[01:52:13.800 --> 01:52:17.600]   is that the analytic contributions of African-Americans
[01:52:17.600 --> 01:52:20.160]   to music are probably fungible to science.
[01:52:20.160 --> 01:52:23.680]   I don't know that that's true.
[01:52:23.680 --> 01:52:26.440]   It's true I haven't done controlled research,
[01:52:26.440 --> 01:52:28.360]   but I believe that it is very important
[01:52:28.360 --> 01:52:31.120]   to let the People's Republic of China know
[01:52:31.120 --> 01:52:34.640]   that they are not staffing our laboratories anymore
[01:52:34.640 --> 01:52:36.880]   and that we need to look to our own people.
[01:52:36.880 --> 01:52:39.920]   And in particular, we are going to get a huge benefit
[01:52:39.920 --> 01:52:44.920]   from making sure that women, Black Americans, Latinos,
[01:52:44.920 --> 01:52:49.520]   are in a position to take over some of these things
[01:52:49.520 --> 01:52:52.800]   because many of these communities have been underutilized.
[01:52:52.800 --> 01:52:55.200]   Now, I don't know if that's an insane idea.
[01:52:55.200 --> 01:52:58.520]   I wanna hear somebody tell me why it's an insane idea.
[01:52:58.520 --> 01:53:00.760]   But I believe that part of what we need to do
[01:53:00.760 --> 01:53:03.920]   is we need to recognize that there are security issues,
[01:53:03.920 --> 01:53:07.320]   there are geopolitical issues with the funding of science.
[01:53:07.320 --> 01:53:10.560]   And that what we've done is we've starved our world
[01:53:10.560 --> 01:53:12.360]   for innovation, and if we don't get back
[01:53:12.360 --> 01:53:13.500]   to the business of innovation,
[01:53:13.500 --> 01:53:15.640]   we should be doing diversity and inclusion
[01:53:15.640 --> 01:53:18.040]   out of greed rather than guilt.
[01:53:18.040 --> 01:53:20.360]   Now, part of the problem with this
[01:53:20.360 --> 01:53:23.900]   is that a lot of the energy behind diversity and inclusion
[01:53:23.900 --> 01:53:26.300]   is based on guilt and accusation.
[01:53:26.300 --> 01:53:30.800]   And what I want is I wanna kick ass.
[01:53:30.800 --> 01:53:33.360]   And my hope is is that diminishing returns
[01:53:33.360 --> 01:53:35.020]   favors mining the communities
[01:53:35.020 --> 01:53:37.640]   that have not been traditionally mined
[01:53:37.640 --> 01:53:41.960]   in order to extract output from those communities,
[01:53:41.960 --> 01:53:43.440]   unless there's a flaw in that plan.
[01:53:43.440 --> 01:53:45.200]   If there's a flaw, somebody needs to tell me.
[01:53:45.200 --> 01:53:48.600]   If there isn't a flaw, we need to get greedy
[01:53:48.600 --> 01:53:51.600]   about innovation rather than guilty about innovation.
[01:53:51.600 --> 01:53:53.400]   - That's really brilliantly put.
[01:53:53.400 --> 01:53:55.320]   My biggest problem with what I see
[01:53:55.320 --> 01:53:57.400]   is it exactly speaks to that
[01:53:57.400 --> 01:53:59.720]   in the discussion of diversity.
[01:53:59.720 --> 01:54:02.200]   It's used, when it's grounded in guilt,
[01:54:02.200 --> 01:54:05.500]   it's then used as a hammer to shame people
[01:54:05.500 --> 01:54:06.900]   that don't care about diversity enough.
[01:54:06.900 --> 01:54:09.500]   - F that shit, okay?
[01:54:09.500 --> 01:54:13.300]   So my point is I'm excited about the idea
[01:54:13.300 --> 01:54:15.860]   of Jimi Hendrix doing quantum field theory.
[01:54:15.860 --> 01:54:19.300]   I'm excited about the idea of Art Tatum
[01:54:19.300 --> 01:54:24.300]   trying to figure out what the neural nets
[01:54:24.300 --> 01:54:26.580]   figured out about protein folding.
[01:54:26.580 --> 01:54:29.220]   I have some idea of the level of intellect
[01:54:29.220 --> 01:54:32.300]   of people who have not found their way into STEM subjects
[01:54:32.300 --> 01:54:35.200]   in incredibly technically demanding areas.
[01:54:35.200 --> 01:54:37.700]   And if there's a flaw in that theory,
[01:54:37.700 --> 01:54:40.060]   I want somebody to present the flaw.
[01:54:40.060 --> 01:54:43.380]   But right now, my belief is that
[01:54:43.380 --> 01:54:45.860]   these things are merit-based.
[01:54:45.860 --> 01:54:48.560]   And if you really believe in structural oppression,
[01:54:48.560 --> 01:54:51.320]   you do not want an affirmative action program.
[01:54:51.320 --> 01:54:53.620]   You wanna make sure that people have huge amounts
[01:54:53.620 --> 01:54:56.640]   of resources to get themselves into position.
[01:54:56.640 --> 01:54:58.120]   I wanna push out,
[01:54:58.120 --> 01:55:00.960]   I just tried this on this Clubhouse application,
[01:55:00.960 --> 01:55:04.520]   I wanna push out Klein bottles as a secret sign
[01:55:04.520 --> 01:55:07.480]   inside of rap videos in hip hop, right?
[01:55:07.480 --> 01:55:10.440]   I want people to have an idea that there's an amazing world.
[01:55:10.440 --> 01:55:12.960]   And I wanna get the people who,
[01:55:12.960 --> 01:55:16.600]   hopefully I'm trying to lure into science and engineering,
[01:55:16.600 --> 01:55:18.160]   I want to get them paid.
[01:55:18.160 --> 01:55:20.800]   I don't want them as the cheap substitutes
[01:55:20.800 --> 01:55:25.400]   for the fleeing white males who've learned
[01:55:25.400 --> 01:55:29.200]   that they can't make any money in science and engineering.
[01:55:29.200 --> 01:55:34.200]   So the problem is that we need to take over the ship, Lex.
[01:55:34.200 --> 01:55:36.160]   And it doesn't need to be you and me,
[01:55:36.160 --> 01:55:38.840]   'cause quite honestly, I have no desire to administer,
[01:55:38.840 --> 01:55:41.160]   I don't wanna be the chief executive officer of anything.
[01:55:41.160 --> 01:55:44.440]   What I do want is I want the baby boomers
[01:55:44.440 --> 01:55:48.440]   who've made this mess and can't see it to be gone.
[01:55:48.440 --> 01:55:51.800]   They had almost all of our universities.
[01:55:51.800 --> 01:55:56.000]   And I want fresh blood, fresh resources,
[01:55:56.000 --> 01:55:58.720]   I want academic freedom, and I want greed
[01:55:58.720 --> 01:56:02.160]   for our country and for the future
[01:56:02.160 --> 01:56:03.800]   to determine diversity and inclusion
[01:56:03.800 --> 01:56:05.080]   as opposed to shame and guilt,
[01:56:05.080 --> 01:56:06.760]   which is destroying our fabric.
[01:56:06.760 --> 01:56:10.520]   - That's as good of a diversity statement
[01:56:10.520 --> 01:56:11.660]   as I've ever heard.
[01:56:11.660 --> 01:56:16.560]   This is a U-turn, but somebody commented
[01:56:16.560 --> 01:56:19.520]   on the tweet you sent that,
[01:56:19.520 --> 01:56:20.880]   as one of the top comments,
[01:56:20.880 --> 01:56:24.160]   they definitely have to ask you about cryptocurrency.
[01:56:24.160 --> 01:56:27.520]   So it's a U-turn, but not really.
[01:56:27.520 --> 01:56:29.960]   Since you're an economist, since you're deep,
[01:56:29.960 --> 01:56:31.800]   not an economist, you.
[01:56:31.800 --> 01:56:33.760]   - I pretend to be an economist,
[01:56:33.760 --> 01:56:36.960]   hoping that the economists will take issue
[01:56:36.960 --> 01:56:39.280]   that I'm not an economist so that I can advance
[01:56:39.280 --> 01:56:41.960]   gauge-theoretic and field-theoretic economics,
[01:56:41.960 --> 01:56:45.520]   which the economics profession has failed to acknowledge
[01:56:45.520 --> 01:56:47.560]   was a major innovation that happened
[01:56:47.560 --> 01:56:49.720]   approximately 25 years ago.
[01:56:49.720 --> 01:56:51.560]   I don't think that economists understand
[01:56:51.560 --> 01:56:53.760]   what a price index is that measures inflation,
[01:56:53.760 --> 01:56:56.180]   nor do I think economists understand
[01:56:56.180 --> 01:57:00.000]   what a growth index or a product,
[01:57:00.000 --> 01:57:04.200]   a quantity index is that measures GDP.
[01:57:04.200 --> 01:57:07.720]   I think that they don't even understand the basics
[01:57:07.720 --> 01:57:10.640]   of price and quantity index construction.
[01:57:10.640 --> 01:57:15.120]   And therefore, they can't possibly review
[01:57:15.120 --> 01:57:17.440]   field-theoretic economics,
[01:57:17.440 --> 01:57:19.720]   they can't review gauge-theoretic economics.
[01:57:19.720 --> 01:57:21.800]   They're intellectually not in a position
[01:57:21.800 --> 01:57:23.200]   to manage their own field.
[01:57:23.200 --> 01:57:25.200]   - You talked about that there's a stagnation
[01:57:25.200 --> 01:57:26.640]   in growth currently.
[01:57:26.640 --> 01:57:29.120]   I looked at, from my microeconomics,
[01:57:29.120 --> 01:57:31.800]   macroeconomics in college perspective,
[01:57:31.800 --> 01:57:36.280]   GDP doesn't seem to capture the productivity,
[01:57:36.280 --> 01:57:41.000]   the full, the spectrum of what I think is
[01:57:41.000 --> 01:57:43.800]   as a functioning, successful society.
[01:57:43.800 --> 01:57:46.720]   What do you think is broken about GDP?
[01:57:46.720 --> 01:57:48.540]   What does it need to include?
[01:57:48.540 --> 01:57:51.480]   These indices, like what--
[01:57:51.480 --> 01:57:53.680]   - Let me explain what they don't understand to begin with.
[01:57:53.680 --> 01:57:54.520]   - Sure.
[01:57:54.520 --> 01:58:00.560]   - Imagine that all prices and all quantities of output
[01:58:00.560 --> 01:58:04.280]   are the same at the end of a year
[01:58:04.280 --> 01:58:05.720]   as they are at the beginning.
[01:58:05.720 --> 01:58:09.020]   And you ask, what happened during that year?
[01:58:09.020 --> 01:58:10.200]   Was there inflation?
[01:58:10.200 --> 01:58:12.760]   They meandered over the course of the year,
[01:58:12.760 --> 01:58:14.760]   but miraculously, they all came back
[01:58:14.760 --> 01:58:16.300]   to exactly their values.
[01:58:16.300 --> 01:58:20.680]   The amount produced at the end of the year
[01:58:20.680 --> 01:58:23.960]   is the same as at the beginning in every single quantity.
[01:58:23.960 --> 01:58:26.080]   Typically, the claim would be that the price index
[01:58:26.080 --> 01:58:30.160]   should be 1.0 and that the quantity index should be 1.0.
[01:58:30.160 --> 01:58:31.340]   That's clearly wrong.
[01:58:31.340 --> 01:58:34.200]   - Why?
[01:58:34.200 --> 01:58:37.860]   - Well, it's much easier to see with,
[01:58:37.860 --> 01:58:41.760]   it speaks to a fundamental confusion that economists have.
[01:58:41.760 --> 01:58:44.180]   They don't understand that the economy is curved
[01:58:44.180 --> 01:58:45.080]   and not flat.
[01:58:45.080 --> 01:58:50.680]   In a curved economy, everything should be path-dependent,
[01:58:50.680 --> 01:58:53.020]   but they view path-dependence as a problem
[01:58:53.020 --> 01:58:55.860]   because they are effectively the flat-earth society
[01:58:55.860 --> 01:58:57.600]   of market analysis.
[01:58:57.600 --> 01:58:59.760]   They don't understand that what they've called,
[01:58:59.760 --> 01:59:02.540]   and they've actually called it the cycling problem,
[01:59:02.540 --> 01:59:04.920]   is exactly what they need to understand
[01:59:04.920 --> 01:59:06.560]   to advance their field.
[01:59:06.560 --> 01:59:09.420]   So I'll give you a very simple example, okay?
[01:59:09.420 --> 01:59:13.400]   Let's imagine that we have Bob and Carol in one hedge fund
[01:59:13.400 --> 01:59:15.020]   and Ted and Alice in another.
[01:59:15.020 --> 01:59:23.060]   In both cases, the females, that is Alice and Carol,
[01:59:23.060 --> 01:59:25.160]   are the chief investment officers,
[01:59:25.160 --> 01:59:29.900]   and Bob and Ted are the chief marketing officers
[01:59:29.900 --> 01:59:32.020]   in charge of trying to get money into the fund
[01:59:32.020 --> 01:59:37.020]   and trying to get people not to, in fact,
[01:59:37.020 --> 01:59:40.140]   remove their money from the funds, okay?
[01:59:41.540 --> 01:59:46.540]   If you, in fact, had Bob and Carol and Ted and Alice,
[01:59:46.540 --> 01:59:51.260]   and both hedge funds were invested in assets
[01:59:51.260 --> 01:59:53.480]   whose prices came back to the same levels
[01:59:53.480 --> 01:59:57.480]   and whose exposures were in the same quantities,
[01:59:57.480 --> 02:00:02.880]   and you wanted to compensate these two hedge funds,
[02:00:02.880 --> 02:00:06.200]   would you compensate them the same necessarily?
[02:00:06.200 --> 02:00:11.200]   What if, for example, Carol was killing it
[02:00:11.640 --> 02:00:12.760]   in terms of investments?
[02:00:12.760 --> 02:00:15.980]   Every time she bought some sort of security,
[02:00:15.980 --> 02:00:20.560]   the price of that security went up, okay?
[02:00:20.560 --> 02:00:25.420]   But Bob was the worst marketing officer,
[02:00:25.420 --> 02:00:26.660]   and as chief marketing officer,
[02:00:26.660 --> 02:00:28.060]   there were tons of redemptions
[02:00:28.060 --> 02:00:30.960]   because Bob was constantly drunk,
[02:00:30.960 --> 02:00:33.780]   Bob was making off-color comments.
[02:00:33.780 --> 02:00:36.500]   Now, as a result, at the end of the year,
[02:00:36.500 --> 02:00:38.540]   the fund hasn't grown in size
[02:00:38.540 --> 02:00:40.800]   because even though Carol was crushing it
[02:00:40.800 --> 02:00:42.980]   in terms of the investments,
[02:00:42.980 --> 02:00:45.180]   Bob was screwing up everything,
[02:00:45.180 --> 02:00:47.500]   and the redemptions were legendary.
[02:00:47.500 --> 02:00:48.660]   So people were making money
[02:00:48.660 --> 02:00:50.500]   and still pulling it out of the fund.
[02:00:50.500 --> 02:00:56.420]   In the other fund, Alice can't seem to buy a base hit.
[02:00:56.420 --> 02:01:00.740]   Every time she gets into a security, the thing plummets.
[02:01:00.740 --> 02:01:03.540]   But Ted's amazing marketing skills
[02:01:03.540 --> 02:01:07.220]   allowed the fund to get all sorts of new subscriptions
[02:01:07.220 --> 02:01:09.780]   and halted the redemptions as people hoped
[02:01:09.780 --> 02:01:12.540]   that the fund would get its act together.
[02:01:12.540 --> 02:01:13.380]   Okay.
[02:01:13.380 --> 02:01:19.940]   Price indices should be how Carol and Alice are compensated.
[02:01:19.940 --> 02:01:27.420]   And quantity indices should be
[02:01:27.420 --> 02:01:31.120]   how Bob and Ted are compensated.
[02:01:31.120 --> 02:01:36.060]   So even though both funds had closed loops
[02:01:36.060 --> 02:01:38.580]   that come back to the original states,
[02:01:38.580 --> 02:01:41.660]   what happened during the period that they were active
[02:01:41.660 --> 02:01:44.260]   tells you how people are supposed to be compensated.
[02:01:44.260 --> 02:01:49.020]   Now, we know that whatever the increase
[02:01:49.020 --> 02:01:50.900]   in the price index is,
[02:01:50.900 --> 02:01:54.940]   is compensated by a decrease in the quantity index,
[02:01:54.940 --> 02:01:58.100]   or conversely, because prices and quantities
[02:01:58.100 --> 02:02:00.140]   return to their original values.
[02:02:00.140 --> 02:02:02.020]   You could have another fund where nothing much happened.
[02:02:02.020 --> 02:02:04.940]   There were no redemptions, no subscriptions.
[02:02:04.940 --> 02:02:08.100]   The fund remained in cash the whole time.
[02:02:08.100 --> 02:02:09.560]   So in that third fund,
[02:02:09.560 --> 02:02:12.740]   let's call that Tristan and Isolde,
[02:02:12.740 --> 02:02:17.060]   that fund should have no bonuses paid
[02:02:17.060 --> 02:02:18.100]   because nobody did anything,
[02:02:18.100 --> 02:02:20.420]   but nobody should be fired either.
[02:02:20.420 --> 02:02:24.340]   Now, the fact that the economists don't even understand
[02:02:24.340 --> 02:02:26.540]   that this is what their price and quantity indices
[02:02:26.540 --> 02:02:28.200]   were intended to do,
[02:02:28.200 --> 02:02:30.740]   that they don't understand that you can actually give
[02:02:30.740 --> 02:02:32.580]   what would be called ordinal agents
[02:02:32.580 --> 02:02:35.180]   the freedom to change their preferences
[02:02:35.180 --> 02:02:37.540]   and still have something defined
[02:02:37.540 --> 02:02:41.220]   as a conus cost of living adjustment,
[02:02:41.220 --> 02:02:43.940]   they don't even understand the mathematics of their field.
[02:02:43.940 --> 02:02:46.020]   - So the indices need to be able to capture
[02:02:46.020 --> 02:02:48.100]   some kind of dynamics that--
[02:02:48.100 --> 02:02:51.200]   - We have had indices that capture these dynamics
[02:02:51.200 --> 02:02:54.260]   due to the work of Francois de Vizia since 1925.
[02:02:54.260 --> 02:02:57.740]   But the economists have not even understood
[02:02:57.740 --> 02:02:59.780]   what de Vizia's index truly represents.
[02:02:59.780 --> 02:03:04.020]   - What do you miss with such crude indices then?
[02:03:04.020 --> 02:03:06.460]   - Well, you miss the fact that you're supposed
[02:03:06.460 --> 02:03:09.260]   to have a field theoretic subject.
[02:03:09.260 --> 02:03:10.660]   The representative consumer
[02:03:10.660 --> 02:03:12.700]   should actually be a probability distribution
[02:03:12.700 --> 02:03:14.880]   on the space of all possible consumers
[02:03:14.880 --> 02:03:17.460]   weighted by the probability of getting any particular pull
[02:03:17.460 --> 02:03:18.760]   from the distribution.
[02:03:18.760 --> 02:03:22.780]   We should not have a single gauge of inflation.
[02:03:22.780 --> 02:03:25.180]   Like what is that in 1973 dollars?
[02:03:25.180 --> 02:03:27.180]   Any more than you should be able to say,
[02:03:27.180 --> 02:03:31.180]   it was 59 degrees Fahrenheit on earth yesterday.
[02:03:32.060 --> 02:03:34.940]   So when we get to the cryptocurrency,
[02:03:34.940 --> 02:03:37.020]   what I'm going to say is that
[02:03:37.020 --> 02:03:39.940]   because we didn't found economic theory
[02:03:39.940 --> 02:03:41.900]   on the proper marginal revolution,
[02:03:41.900 --> 02:03:43.980]   because we missed the major opportunity,
[02:03:43.980 --> 02:03:47.260]   which is that the differential calculus of markets
[02:03:47.260 --> 02:03:48.340]   is gauge theory.
[02:03:48.340 --> 02:03:53.340]   It's not ordinary differential calculus.
[02:03:53.340 --> 02:03:55.540]   We found that out in finance
[02:03:55.540 --> 02:03:58.220]   that it was stochastic differential calculus.
[02:03:58.220 --> 02:04:00.700]   We have the wrong version of the differential calculus
[02:04:00.700 --> 02:04:03.820]   underneath all of modern economic theory.
[02:04:03.820 --> 02:04:06.700]   And part of what I've been pushing for in cryptocurrencies
[02:04:06.700 --> 02:04:08.980]   is the idea that we should be understanding
[02:04:08.980 --> 02:04:11.460]   that gold is a gauge theory,
[02:04:11.460 --> 02:04:13.660]   just as modern economic theory
[02:04:13.660 --> 02:04:15.660]   is supposed to be a gauge theory.
[02:04:15.660 --> 02:04:18.940]   And that we should be looking to liberate cryptocurrencies
[02:04:18.940 --> 02:04:21.140]   and more importantly, distributed computing
[02:04:21.140 --> 02:04:25.620]   from the problem of this unwanted global aspect,
[02:04:25.620 --> 02:04:26.780]   which is the blockchain.
[02:04:26.780 --> 02:04:29.460]   The thing that is most celebrated in some sense
[02:04:29.460 --> 02:04:31.500]   about Bitcoin is in fact the reason
[02:04:31.500 --> 02:04:33.300]   that I'm least enthusiastic about it.
[02:04:33.300 --> 02:04:36.380]   I'm hugely enthusiastic about what Satoshi did,
[02:04:36.380 --> 02:04:40.740]   but it's an intermediate step towards trying to figure out
[02:04:40.740 --> 02:04:43.580]   what should digital gold actually be?
[02:04:43.580 --> 02:04:48.580]   If physical gold is a collection of up quarks and down quarks
[02:04:48.580 --> 02:04:52.500]   in the form of protons and neutrons
[02:04:52.500 --> 02:04:55.100]   held together the quarks by gluons
[02:04:55.100 --> 02:04:57.700]   with electrons orbiting it held together by photons
[02:04:57.700 --> 02:05:00.980]   with the occasional weak interaction beta decay.
[02:05:00.980 --> 02:05:02.660]   All of those are gauge theories.
[02:05:02.660 --> 02:05:06.220]   So gold is actually coming from gauge theory
[02:05:06.220 --> 02:05:08.340]   and markets are coming from gauge theory.
[02:05:08.340 --> 02:05:11.140]   And the opportunity to do locally enforced
[02:05:11.140 --> 02:05:13.060]   conservation laws, which effectively
[02:05:13.060 --> 02:05:15.620]   is what a Bitcoin transaction is,
[02:05:15.620 --> 02:05:19.740]   should theoretically be founded on a different principle
[02:05:19.740 --> 02:05:21.340]   that is not the blockchain.
[02:05:21.340 --> 02:05:23.820]   It should be a gauge theoretic concept
[02:05:23.820 --> 02:05:27.540]   in which effectively the tokens are excitations
[02:05:27.540 --> 02:05:29.620]   on a network of computer nodes.
[02:05:29.620 --> 02:05:34.460]   And the fact that let's imagine that this is some token.
[02:05:34.460 --> 02:05:39.540]   By moving it from my custodianship to your custodianship,
[02:05:39.540 --> 02:05:42.980]   effectively I pushed that glass as a gauge theory
[02:05:42.980 --> 02:05:45.220]   towards your region of the table.
[02:05:45.220 --> 02:05:47.540]   We should be recognizing the gauge theory
[02:05:47.540 --> 02:05:51.340]   is the correct differential calculus for the 21st century.
[02:05:51.340 --> 02:05:53.260]   In fact, it should have been there in the 20th century.
[02:05:53.260 --> 02:05:57.500]   - You're saying it captures these individual dynamics
[02:05:57.500 --> 02:05:58.580]   much richer.
[02:05:58.580 --> 02:06:01.860]   - Why should my giving you a token have to be,
[02:06:01.860 --> 02:06:05.140]   why should we alert the global community
[02:06:05.140 --> 02:06:06.820]   in this token that that occurred?
[02:06:06.820 --> 02:06:08.020]   You can talk about side chains,
[02:06:08.020 --> 02:06:10.020]   you can talk about any means of doing this.
[02:06:10.020 --> 02:06:11.500]   But effectively we have a problem,
[02:06:11.500 --> 02:06:13.900]   which is if I think about this differently,
[02:06:13.900 --> 02:06:16.940]   I have a glass that is extant,
[02:06:16.940 --> 02:06:18.620]   you have a glass that is abstent.
[02:06:18.620 --> 02:06:23.100]   We're supposed to call the constructor method
[02:06:23.100 --> 02:06:24.740]   on your glass at the same moment
[02:06:24.740 --> 02:06:26.860]   we call the destructor method on my glass
[02:06:26.860 --> 02:06:29.300]   in order to have a conservation principle.
[02:06:29.300 --> 02:06:32.100]   It would be far more efficient to do this
[02:06:32.100 --> 02:06:34.740]   with the one system that is known
[02:06:34.740 --> 02:06:37.100]   never to throw an exception, which is nature.
[02:06:37.100 --> 02:06:39.260]   And nature has chosen gauge theory and geometry
[02:06:39.260 --> 02:06:41.460]   for her underlying language.
[02:06:41.460 --> 02:06:44.060]   We now know due to work of Pia Malani
[02:06:44.060 --> 02:06:48.260]   at Harvard in economics in the mid 1990s,
[02:06:48.260 --> 02:06:49.720]   which I was her co-author on.
[02:06:50.860 --> 02:06:55.580]   But I wish to promote her as well as this being my idea.
[02:06:55.580 --> 02:06:59.700]   We know that modern economic theory
[02:06:59.700 --> 02:07:01.900]   is a naturally occurring gauge theory.
[02:07:01.900 --> 02:07:03.500]   And the failure of that community
[02:07:03.500 --> 02:07:05.940]   to acknowledge that that work occurred
[02:07:05.940 --> 02:07:07.540]   and that it was put down for reasons
[02:07:07.540 --> 02:07:12.340]   that make no analytic sense is important in particular
[02:07:12.340 --> 02:07:14.340]   due to the relatively new innovation
[02:07:14.340 --> 02:07:17.580]   of distributed computing and Satoshi's brainchild.
[02:07:17.580 --> 02:07:20.020]   - So you're thinking we need to have the mathematics
[02:07:20.020 --> 02:07:23.180]   that captures, that enforces cryptocurrency
[02:07:23.180 --> 02:07:25.740]   as a distributed system as opposed to a centralized one
[02:07:25.740 --> 02:07:30.220]   where the blockchain says that crypto should be centralized.
[02:07:30.220 --> 02:07:35.020]   - The abundance economy, much discussed in Silicon Valley
[02:07:35.020 --> 02:07:38.940]   or what's left of it, is actually a huge threat
[02:07:38.940 --> 02:07:41.180]   to the planet because what it really is
[02:07:41.180 --> 02:07:43.660]   is that it is what Marc Andreessen has called
[02:07:43.660 --> 02:07:45.540]   software eating the world.
[02:07:45.540 --> 02:07:47.800]   And what that means is that you're gonna push things
[02:07:47.800 --> 02:07:49.360]   from being private goods and services
[02:07:49.360 --> 02:07:50.820]   into public goods and services.
[02:07:50.820 --> 02:07:53.580]   And public goods and services cannot have price
[02:07:53.580 --> 02:07:55.860]   and value tied together.
[02:07:55.860 --> 02:07:59.060]   Ergo, people will produce things of incredible value
[02:07:59.060 --> 02:08:01.860]   to the world that they cannot command a price
[02:08:01.860 --> 02:08:03.740]   and they will not be able to capture the value
[02:08:03.740 --> 02:08:04.860]   that they have created
[02:08:04.860 --> 02:08:07.080]   or a significant enough fraction of it.
[02:08:07.080 --> 02:08:09.820]   The abundance economy is a disaster.
[02:08:09.820 --> 02:08:13.220]   It will lead to a reduction in human freedom.
[02:08:13.220 --> 02:08:16.720]   The great innovation of Satoshi is locally enforced
[02:08:16.720 --> 02:08:20.420]   or semi-locally enforced conservation laws
[02:08:20.420 --> 02:08:22.740]   where the idea is just as gold is hard,
[02:08:22.740 --> 02:08:24.940]   why is gold hard to create or destroy?
[02:08:24.940 --> 02:08:26.700]   It's because it's created not only in stars
[02:08:26.700 --> 02:08:28.680]   but in violent events involving stars
[02:08:28.680 --> 02:08:30.260]   like supernova or collisions.
[02:08:30.260 --> 02:08:35.440]   When gold is created and we transact,
[02:08:35.440 --> 02:08:38.060]   we're using conservation laws.
[02:08:38.060 --> 02:08:41.280]   The physics determines the custodianship,
[02:08:41.280 --> 02:08:42.940]   whatever it is that I don't have,
[02:08:42.940 --> 02:08:45.420]   you now have and conversely.
[02:08:45.420 --> 02:08:48.440]   In such a situation, we should be looking
[02:08:48.440 --> 02:08:51.260]   for the abstraction that most closely matches
[02:08:51.260 --> 02:08:53.140]   the physical world because the physical world
[02:08:53.140 --> 02:08:55.240]   is known not to throw an exception.
[02:08:55.240 --> 02:08:57.200]   The blockchain is a vulnerability.
[02:08:57.200 --> 02:09:00.720]   The idea that the 51% problem isn't solved,
[02:09:00.720 --> 02:09:03.600]   that you could have crazy race conditions,
[02:09:03.600 --> 02:09:06.880]   all of these things, we know that they're solved
[02:09:06.880 --> 02:09:08.920]   inside of gauge theory somehow.
[02:09:08.920 --> 02:09:12.200]   So the important thing is to recognize
[02:09:12.200 --> 02:09:15.140]   that one of the greatest intellectual feats ever
[02:09:15.140 --> 02:09:18.840]   in the history of economic theory took place already
[02:09:18.840 --> 02:09:22.040]   and was essentially instantly buried
[02:09:22.040 --> 02:09:24.120]   and I will stand by those comments.
[02:09:24.120 --> 02:09:28.320]   Satoshi, wherever you are, I probably know you.
[02:09:28.320 --> 02:09:29.420]   - Are you Satoshi?
[02:09:29.420 --> 02:09:30.260]   - No.
[02:09:30.260 --> 02:09:33.000]   No, no, no, I don't have that kind of ability.
[02:09:33.000 --> 02:09:34.360]   I really don't.
[02:09:34.360 --> 02:09:35.260]   I do other things.
[02:09:35.260 --> 02:09:38.520]   - Speaking of Satoshi and gauge theory,
[02:09:38.520 --> 02:09:41.480]   you've mentioned to Brian Keating
[02:09:43.260 --> 02:09:46.860]   that you may be releasing a geometric unity paper
[02:09:46.860 --> 02:09:50.140]   this year, some other form of additional material
[02:09:50.140 --> 02:09:51.100]   on the topic.
[02:09:51.100 --> 02:09:54.100]   What is your thinking around this?
[02:09:54.100 --> 02:09:56.420]   What's the process you're going through now?
[02:09:56.420 --> 02:09:58.180]   - Well, it's very interesting.
[02:09:58.180 --> 02:09:59.260]   - Preparing this.
[02:09:59.260 --> 02:10:02.020]   - I used April 1st to try to start a tradition
[02:10:02.020 --> 02:10:04.860]   which I hope to use to liberate mankind.
[02:10:04.860 --> 02:10:10.180]   The tradition is that at least one day a year,
[02:10:10.180 --> 02:10:13.240]   you should be able to say heretical things
[02:10:13.240 --> 02:10:15.720]   and not have Jack Dorsey boot you off
[02:10:15.720 --> 02:10:18.360]   or Mark Zuckerberg, your provost shouldn't call you up
[02:10:18.360 --> 02:10:19.680]   and say, what did you say?
[02:10:19.680 --> 02:10:23.680]   We need at some level to have a jubilee
[02:10:23.680 --> 02:10:26.600]   from centralized control.
[02:10:26.600 --> 02:10:29.880]   And so my hope is that, you know what a tradition is
[02:10:29.880 --> 02:10:31.000]   in America?
[02:10:31.000 --> 02:10:32.800]   Something a baby boomer did twice.
[02:10:32.800 --> 02:10:36.720]   - Impeachment?
[02:10:36.720 --> 02:10:39.000]   (laughing)
[02:10:39.000 --> 02:10:39.840]   - Very funny.
[02:10:39.840 --> 02:10:45.680]   Anyway, so I'm not a baby boomer, but as an Xer,
[02:10:45.680 --> 02:10:48.820]   I've thought about whether or not April 1st
[02:10:48.820 --> 02:10:52.740]   would be a good date on which to release a printed version
[02:10:52.740 --> 02:10:55.180]   of what I already said in lecture form.
[02:10:55.180 --> 02:10:56.980]   Because I think it's hysterically funny
[02:10:56.980 --> 02:10:59.260]   that the physics community claims
[02:10:59.260 --> 02:11:02.420]   that it can't decode a lecture.
[02:11:02.420 --> 02:11:03.480]   Yeah.
[02:11:03.480 --> 02:11:04.580]   - It must be paper.
[02:11:04.580 --> 02:11:05.700]   - And you know what?
[02:11:05.700 --> 02:11:08.540]   There will be a steady stream of new complaints
[02:11:08.540 --> 02:11:10.140]   up until the point that they fit it
[02:11:10.140 --> 02:11:11.700]   into a narrative that they like.
[02:11:11.700 --> 02:11:16.220]   Yeah, I'm thinking about April 1st
[02:11:16.220 --> 02:11:19.340]   as a date in which to release a document
[02:11:19.340 --> 02:11:21.100]   and it won't be perfectly complete,
[02:11:21.100 --> 02:11:22.980]   but it'll be very complete.
[02:11:22.980 --> 02:11:26.560]   And then they'll try to say, it's wrong
[02:11:26.560 --> 02:11:29.440]   or you already did it or no, that was dumb,
[02:11:29.440 --> 02:11:31.660]   but what we just did on top of it is brilliant
[02:11:31.660 --> 02:11:35.260]   or it doesn't match experiment or who knows what.
[02:11:35.260 --> 02:11:37.620]   They'll go through all of their usual nonsense.
[02:11:38.460 --> 02:11:40.340]   It's time to go.
[02:11:40.340 --> 02:11:43.260]   - Is there still puzzles in your own mind
[02:11:43.260 --> 02:11:44.740]   that need to be figured out for you
[02:11:44.740 --> 02:11:46.140]   to try to put it on paper?
[02:11:46.140 --> 02:11:48.180]   I mean, those are different mediums, right?
[02:11:48.180 --> 02:11:50.260]   - It was a great question.
[02:11:50.260 --> 02:11:53.260]   I did not count on something that turns out to be important.
[02:11:53.260 --> 02:11:57.140]   When you work on your own outside of the system
[02:11:57.140 --> 02:11:59.940]   for a long time, you probably don't think
[02:11:59.940 --> 02:12:03.040]   you're gonna be doing this as a 55 year old man.
[02:12:03.040 --> 02:12:06.060]   And I have been so long outside
[02:12:06.060 --> 02:12:07.420]   of math and physics departments
[02:12:07.420 --> 02:12:09.020]   and I've been occupied with so many other things
[02:12:09.020 --> 02:12:14.020]   as you can see, that the old idea that I had
[02:12:14.020 --> 02:12:16.520]   was if I always did it in little pieces,
[02:12:16.520 --> 02:12:21.480]   then I was always safe because it wouldn't be stealable.
[02:12:21.480 --> 02:12:26.100]   And so now those pieces never got assembled completely.
[02:12:26.100 --> 02:12:29.060]   In essence, I have all the pieces
[02:12:29.060 --> 02:12:32.540]   and I can fit them together,
[02:12:32.540 --> 02:12:35.740]   but there's probably a small amount of glue code.
[02:12:35.740 --> 02:12:37.260]   Like there are a few algebraic things
[02:12:37.260 --> 02:12:38.340]   I've forgotten how to do.
[02:12:38.340 --> 02:12:39.940]   I may or may not figure them out
[02:12:39.940 --> 02:12:43.500]   between now and April 1st, but it's pretty complete.
[02:12:43.500 --> 02:12:46.380]   - But that's the puzzle you're kind of struggling
[02:12:46.380 --> 02:12:49.100]   to now figure out, to get it all on,
[02:12:49.100 --> 02:12:50.820]   in the same, the glue together.
[02:12:50.820 --> 02:12:52.460]   - I can't tell you whether the theory
[02:12:52.460 --> 02:12:54.700]   is correct or incorrect, but like, you know,
[02:12:54.700 --> 02:12:56.380]   for example, there's what's the exact form
[02:12:56.380 --> 02:12:57.860]   of the supersymmetry algebra,
[02:12:57.860 --> 02:13:00.760]   or what's the rule for passing a minus sign
[02:13:00.760 --> 02:13:02.900]   through a particular operator?
[02:13:02.900 --> 02:13:05.820]   And all of that stuff got a lot more difficult
[02:13:05.820 --> 02:13:09.220]   because I didn't do it.
[02:13:09.220 --> 02:13:11.220]   Look, you know, it's a little bit like,
[02:13:11.220 --> 02:13:15.500]   if you're a violinist and you don't touch your violin
[02:13:15.500 --> 02:13:18.500]   regularly for 15 years, you come back to it
[02:13:18.500 --> 02:13:20.340]   and you pretty much know the pieces sort of,
[02:13:20.340 --> 02:13:21.780]   but there's lots of stuff that's missing.
[02:13:21.780 --> 02:13:24.040]   Your tone is off and that kind of stuff.
[02:13:24.040 --> 02:13:27.020]   I would say I'll get the ship to the harbor
[02:13:27.020 --> 02:13:30.260]   and it'll require a tugboat probably to get it in.
[02:13:30.260 --> 02:13:31.760]   And if the tugboat doesn't show up,
[02:13:31.760 --> 02:13:34.540]   then I'll pilot the thing right into the dock myself.
[02:13:34.540 --> 02:13:35.780]   But it's not a big deal.
[02:13:35.780 --> 02:13:38.500]   I think that it is essentially complete.
[02:13:38.500 --> 02:13:41.300]   - Psychologically, just as a human being,
[02:13:41.300 --> 02:13:45.500]   this is, I remember perhaps by accident,
[02:13:45.500 --> 02:13:48.660]   but maybe there's no accidents in the universe.
[02:13:48.660 --> 02:13:51.380]   I was tuned in, I don't remember where,
[02:13:51.380 --> 02:13:56.380]   on April 1st to you, oh, I think on your Discord.
[02:13:56.380 --> 02:14:00.980]   Kind of thinking about, thinking through this release.
[02:14:00.980 --> 02:14:04.040]   I mean, it wasn't like, it wasn't obvious
[02:14:04.040 --> 02:14:04.880]   that you were going to do it.
[02:14:04.880 --> 02:14:05.840]   You were thinking through it.
[02:14:05.840 --> 02:14:08.500]   And I remember there was intellectual,
[02:14:08.500 --> 02:14:10.780]   personal, psychological struggle with this.
[02:14:10.780 --> 02:14:13.260]   - Yeah, well, 'cause I thought it was dangerous.
[02:14:13.260 --> 02:14:14.980]   If this turns out to be right,
[02:14:14.980 --> 02:14:16.500]   I don't know what it unlocks.
[02:14:16.500 --> 02:14:23.180]   If it's wrong, I think I understand where we are.
[02:14:23.180 --> 02:14:28.180]   If it's wrong, it'll be the first fool's gold
[02:14:29.000 --> 02:14:31.340]   that really looks like a theory of everything.
[02:14:31.340 --> 02:14:35.600]   It'll be the iron pyrites of physics.
[02:14:35.600 --> 02:14:38.520]   And we haven't even had fool's gold, in my opinion, yet.
[02:14:38.520 --> 02:14:40.420]   - Got it.
[02:14:40.420 --> 02:14:45.340]   So what is your intuition why this looks right to you?
[02:14:45.340 --> 02:14:48.300]   Like why it feels like it would be,
[02:14:48.300 --> 02:14:49.140]   if wrong, the first fool's gold?
[02:14:49.140 --> 02:14:51.120]   - I can say it very simply.
[02:14:51.120 --> 02:14:53.300]   It's way smarter than I am.
[02:14:53.300 --> 02:14:55.080]   - Can you break that apart a little more?
[02:14:55.080 --> 02:14:56.880]   It's like every time you poke at it,
[02:14:56.880 --> 02:14:58.720]   it's giving you intuitions that follow
[02:14:58.720 --> 02:15:00.400]   with the currently known physics.
[02:15:00.400 --> 02:15:02.400]   - Let's put it in computer science terms.
[02:15:02.400 --> 02:15:03.240]   - Yes, please.
[02:15:03.240 --> 02:15:05.640]   - Okay, there's a concept of technical debt
[02:15:05.640 --> 02:15:08.000]   that computer scientists struggle with.
[02:15:08.000 --> 02:15:10.640]   As you commit crimes, you have to pay those crimes back
[02:15:10.640 --> 02:15:11.580]   at a later date.
[02:15:11.580 --> 02:15:15.440]   In general, most of the problem with physical theories
[02:15:15.440 --> 02:15:20.400]   is that as you try to do something that matches reality,
[02:15:20.400 --> 02:15:23.140]   you usually have to go into some structure
[02:15:23.140 --> 02:15:25.160]   that gets you farther away.
[02:15:25.160 --> 02:15:26.720]   And your hope is is that you're gonna be able
[02:15:26.720 --> 02:15:28.240]   to pay back the technical debt,
[02:15:28.240 --> 02:15:32.120]   and in general, these wind up as check-kiting schemes,
[02:15:32.120 --> 02:15:34.560]   or like you're funding a startup
[02:15:34.560 --> 02:15:37.000]   and there are too many pivots, right?
[02:15:37.000 --> 02:15:39.400]   So you keep adding epicycles in order
[02:15:39.400 --> 02:15:44.000]   to cover things that have gone wrong.
[02:15:44.000 --> 02:15:49.000]   My belief is is that this thing represents something
[02:15:49.000 --> 02:15:54.160]   like a summit to me, and I'm very proud
[02:15:54.160 --> 02:15:57.900]   of having found a route up this summit.
[02:15:57.900 --> 02:16:01.540]   But the route is what's due to me.
[02:16:01.540 --> 02:16:04.300]   The summit can't possibly be due to me.
[02:16:04.300 --> 02:16:09.720]   You know, like Edmund Hillary and Tenzing Norgay
[02:16:09.720 --> 02:16:13.200]   did not create Mount Everest.
[02:16:13.200 --> 02:16:14.440]   They know that they didn't create that.
[02:16:14.440 --> 02:16:18.760]   They figured out a way up.
[02:16:18.760 --> 02:16:21.080]   - You gotta tell me what Mount Everest is
[02:16:21.080 --> 02:16:23.760]   in this metaphor relative, and also connected
[02:16:23.760 --> 02:16:24.600]   to the technical debt.
[02:16:24.600 --> 02:16:26.520]   So technical debt is a negative thing
[02:16:26.520 --> 02:16:30.480]   that it's kinda, you'll eventually have to pay it.
[02:16:30.480 --> 02:16:31.320]   - Absolutely. - Are you saying
[02:16:31.320 --> 02:16:34.760]   in the ascent that you're seeing now,
[02:16:34.760 --> 02:16:37.640]   in the theory, is you do not have much technical debt.
[02:16:37.640 --> 02:16:38.460]   - Well, that's right.
[02:16:38.460 --> 02:16:41.000]   I think that what happens is is that early on,
[02:16:41.000 --> 02:16:44.800]   what I would say is I believe now
[02:16:44.800 --> 02:16:50.640]   that the physics community has said many things incorrectly
[02:16:51.960 --> 02:16:54.600]   about the current state of the universe.
[02:16:54.600 --> 02:16:57.820]   They're not wildly off, which is why,
[02:16:57.820 --> 02:16:59.560]   like for example, the claim is that there are
[02:16:59.560 --> 02:17:01.460]   three generations of matter.
[02:17:01.460 --> 02:17:03.520]   I do not believe that there are three generations of matter.
[02:17:03.520 --> 02:17:05.320]   I believe that there are two generations of matter,
[02:17:05.320 --> 02:17:08.920]   and there is a third collection
[02:17:08.920 --> 02:17:11.840]   that looks like a generation of matter,
[02:17:11.840 --> 02:17:14.260]   as the first two, only at low energy.
[02:17:14.260 --> 02:17:18.400]   Okay, well, that's not a frequent claim.
[02:17:18.400 --> 02:17:19.840]   People imagine that there are three
[02:17:19.840 --> 02:17:21.560]   or more generations of matter.
[02:17:21.560 --> 02:17:23.000]   I would claim that that's false.
[02:17:23.000 --> 02:17:25.120]   People claim that the matter is chiral,
[02:17:25.120 --> 02:17:27.320]   that is, it knows it's left from its right.
[02:17:27.320 --> 02:17:31.100]   I would claim that the chirality is not fundamental,
[02:17:31.100 --> 02:17:32.120]   but it is emergent.
[02:17:32.120 --> 02:17:36.120]   We could keep going at all these sorts of things.
[02:17:36.120 --> 02:17:38.400]   People think that space-time is
[02:17:38.400 --> 02:17:41.200]   the fundamental geometrical construct.
[02:17:41.200 --> 02:17:42.020]   I do not agree.
[02:17:42.020 --> 02:17:45.480]   I think it's something that I've termed the observers.
[02:17:45.480 --> 02:17:50.480]   All of these different things represent a series
[02:17:50.520 --> 02:17:54.200]   of over-interpretations of the world
[02:17:54.200 --> 02:17:56.680]   that preclude progress.
[02:17:56.680 --> 02:18:01.080]   - So you gave, I think you gave some credit
[02:18:01.080 --> 02:18:03.800]   to string theory as, string theory,
[02:18:03.800 --> 02:18:06.840]   I think loop quantum gravity, if I remember correctly,
[02:18:06.840 --> 02:18:11.600]   as like getting close to the fool's gold.
[02:18:11.600 --> 02:18:16.080]   - Well, I said that Garrett Lisey, phenomenologically,
[02:18:16.080 --> 02:18:18.080]   gets a lot of things right.
[02:18:18.080 --> 02:18:20.600]   He's got a reason for chirality,
[02:18:20.600 --> 02:18:23.360]   a reason for uniqueness using E8,
[02:18:23.360 --> 02:18:24.800]   and the fact that E8 uses something
[02:18:24.800 --> 02:18:26.760]   called Weyl fermions, which are chiral.
[02:18:26.760 --> 02:18:30.840]   He has a way of getting geometry
[02:18:30.840 --> 02:18:35.840]   to get Riemann's geometry underneath general relativity
[02:18:35.840 --> 02:18:38.120]   to play with Erisman's geometry,
[02:18:38.120 --> 02:18:39.520]   which is underneath the standard model,
[02:18:39.520 --> 02:18:41.320]   using something called Cartan connections
[02:18:41.320 --> 02:18:42.840]   that are out of favor.
[02:18:42.840 --> 02:18:45.960]   He's figured out something involving super connections
[02:18:45.960 --> 02:18:47.440]   to make sure that the fermion,
[02:18:47.440 --> 02:18:49.920]   the matter in the system isn't quantized
[02:18:49.920 --> 02:18:51.440]   the same way as the bosons were,
[02:18:51.440 --> 02:18:53.840]   which is a problem in his old theory.
[02:18:53.840 --> 02:18:56.360]   He's got something about three generations for triality.
[02:18:56.360 --> 02:18:59.520]   He's got a lot of phenomenological hits.
[02:18:59.520 --> 02:19:01.240]   I don't think Garrett's theory works.
[02:19:01.240 --> 02:19:02.880]   It also has a very simple Lagrangian.
[02:19:02.880 --> 02:19:05.600]   He's basically using the Yang-Mills norm squared,
[02:19:05.600 --> 02:19:08.040]   the same thing you would use as a cost function
[02:19:08.040 --> 02:19:11.800]   if you were doing neural nets, okay?
[02:19:11.800 --> 02:19:16.400]   The string theorists have a different selling point,
[02:19:16.400 --> 02:19:18.040]   which is that they may have gotten
[02:19:18.040 --> 02:19:20.200]   a renormalizable theory of gravity
[02:19:20.200 --> 02:19:22.600]   if quantum gravity was what we were meant to do.
[02:19:22.600 --> 02:19:25.320]   And they've done some stuff with black holes
[02:19:25.320 --> 02:19:29.080]   that they can get some solutions correct.
[02:19:29.080 --> 02:19:30.680]   And then they have lots of agreements
[02:19:30.680 --> 02:19:33.760]   where they show mathematical truths
[02:19:33.760 --> 02:19:35.680]   that mathematicians didn't even know.
[02:19:35.680 --> 02:19:39.720]   I'm very underwhelmed by string theory
[02:19:39.720 --> 02:19:41.920]   based on how many people have worked on it
[02:19:41.920 --> 02:19:44.160]   and how little is supporting the claims
[02:19:44.160 --> 02:19:46.440]   to it being a theory of everything.
[02:19:46.440 --> 02:19:51.040]   But those are the two that I take quite seriously.
[02:19:51.040 --> 02:19:54.000]   I don't yet take Wolfram's quite seriously
[02:19:54.000 --> 02:19:57.960]   because if he really finds one of these cellular automata
[02:19:57.960 --> 02:20:01.800]   that are really distinct and generative, it'll be amazing.
[02:20:01.800 --> 02:20:03.560]   But he's looking for such a thing.
[02:20:03.560 --> 02:20:05.640]   I don't think he's found anything.
[02:20:05.640 --> 02:20:08.440]   Tegmark, I view as a philosopher
[02:20:08.440 --> 02:20:11.440]   who is somehow taking credit for Platonism,
[02:20:11.440 --> 02:20:14.360]   which I don't see any reason for fighting with Max
[02:20:14.360 --> 02:20:17.040]   'cause I like Max, but if it ever comes time,
[02:20:17.040 --> 02:20:19.400]   I'm putting a post-it note that I'm not positive
[02:20:19.400 --> 02:20:23.180]   the mathematical universe hypothesis is really anything new.
[02:20:23.180 --> 02:20:29.200]   And in general, loop quantum gravity really, I think,
[02:20:29.200 --> 02:20:30.400]   grew out of some hopes
[02:20:30.400 --> 02:20:32.440]   that the general relativistic community had
[02:20:32.440 --> 02:20:34.800]   for that they would be able to do particle theory.
[02:20:34.800 --> 02:20:36.560]   I don't think that they've shown
[02:20:36.560 --> 02:20:38.360]   any particle theoretic realism.
[02:20:38.400 --> 02:20:42.740]   So essentially, here's what I really think, Lex.
[02:20:42.740 --> 02:20:47.400]   I think we didn't understand how big the difference
[02:20:47.400 --> 02:20:48.960]   between an effective theory
[02:20:48.960 --> 02:20:51.560]   and a theory of everything is conceptually.
[02:20:51.560 --> 02:20:54.600]   Maybe it's not mathematically that different,
[02:20:54.600 --> 02:20:56.920]   but conceptually, trying to figure out
[02:20:56.920 --> 02:20:58.880]   what a theory of everything, how does the universe,
[02:20:58.880 --> 02:21:01.800]   and I've compared it to Escher's drawing hands,
[02:21:01.800 --> 02:21:05.240]   how do two hands draw themselves into existence?
[02:21:05.240 --> 02:21:09.280]   That's the puzzle that I think has just been wanting,
[02:21:09.280 --> 02:21:12.360]   and I'll be honest, I'm really surprised
[02:21:12.360 --> 02:21:14.680]   that the theoretical physics community
[02:21:14.680 --> 02:21:21.020]   didn't even get up on their high horse
[02:21:21.020 --> 02:21:25.280]   and say this is the most stupid nonsense imaginable
[02:21:25.280 --> 02:21:28.560]   because clearly, I always say I'm not a physicist.
[02:21:28.560 --> 02:21:32.360]   So I'm an amateur with a heart as big as all outdoors.
[02:21:33.880 --> 02:21:36.000]   - So in your journey of releasing this,
[02:21:36.000 --> 02:21:37.440]   and I'm sure that further,
[02:21:37.440 --> 02:21:42.200]   maybe it will be another American tradition on April 1st
[02:21:42.200 --> 02:21:43.640]   that will continue for years to come.
[02:21:43.640 --> 02:21:44.480]   - I hope so.
[02:21:44.480 --> 02:21:53.880]   - There's sort of crumbs along the way
[02:21:53.880 --> 02:21:58.720]   that I'm hoping to collect in my naive view of things
[02:21:58.720 --> 02:22:03.720]   of the beauty that in your geometric view
[02:22:04.040 --> 02:22:05.440]   of the universe.
[02:22:05.440 --> 02:22:10.440]   So one question I'd like to ask is
[02:22:10.440 --> 02:22:15.960]   if you were to challenge me to visualize
[02:22:15.960 --> 02:22:18.640]   something beautiful, something important
[02:22:18.640 --> 02:22:20.640]   about geometric unity in my struggle
[02:22:20.640 --> 02:22:23.420]   to appreciate some of its beauty
[02:22:23.420 --> 02:22:25.680]   from the outsider's perspective,
[02:22:25.680 --> 02:22:27.240]   what would that thing be?
[02:22:27.240 --> 02:22:29.740]   - Interesting question.
[02:22:29.740 --> 02:22:31.880]   - Perhaps we can both have a journey
[02:22:31.880 --> 02:22:33.840]   towards April 1st.
[02:22:33.840 --> 02:22:36.040]   - Take a look at that.
[02:22:36.040 --> 02:22:41.880]   Some kind of a scrunchie that I picked up on Melrose,
[02:22:41.880 --> 02:22:44.680]   not Melrose, Montana in Santa Monica.
[02:22:44.680 --> 02:22:48.760]   Now you'll notice that all of those disks
[02:22:48.760 --> 02:22:51.480]   rotate independently.
[02:22:51.480 --> 02:22:52.320]   - Yes.
[02:22:52.320 --> 02:22:57.600]   - If you rotate groups of those in a way
[02:22:57.600 --> 02:23:01.240]   that is continuous but not uniform everywhere,
[02:23:01.240 --> 02:23:04.760]   what you're doing is a so-called gauge transformation
[02:23:04.760 --> 02:23:09.600]   on the torus seen as a U1 bundle over a U1 spacetime.
[02:23:09.600 --> 02:23:12.920]   So the concept of spacetime here
[02:23:12.920 --> 02:23:16.000]   in a very simplified case isn't four-dimensional
[02:23:16.000 --> 02:23:18.540]   but it's one-dimensional, it's just a circle.
[02:23:18.540 --> 02:23:21.740]   And there's a circle above every point in the circle
[02:23:21.740 --> 02:23:23.600]   represented by those little disks.
[02:23:23.600 --> 02:23:29.840]   Imagine if you will that we took a rubber band
[02:23:30.680 --> 02:23:33.760]   and placed it around here and decided that
[02:23:33.760 --> 02:23:36.800]   that was a function from the circle
[02:23:36.800 --> 02:23:41.800]   into this circle that is representing a Y-axis
[02:23:41.800 --> 02:23:44.240]   that's wrapped around itself.
[02:23:44.240 --> 02:23:46.080]   Well, you would have an idea of what it means
[02:23:46.080 --> 02:23:47.840]   for a function to be constant
[02:23:47.840 --> 02:23:50.200]   if it just went all around the outside.
[02:23:50.200 --> 02:23:53.820]   But what happens if I turn this a little bit?
[02:23:53.820 --> 02:23:55.560]   Then the function would be mostly constant,
[02:23:55.560 --> 02:23:57.160]   it would have a little place where it dipped
[02:23:57.160 --> 02:23:58.440]   and it went back.
[02:23:58.440 --> 02:24:03.400]   It turns out that you can transform that function
[02:24:03.400 --> 02:24:06.080]   and transform the derivative that says
[02:24:06.080 --> 02:24:09.920]   that function is equal to zero when I take its derivative
[02:24:09.920 --> 02:24:11.360]   at the same time.
[02:24:11.360 --> 02:24:14.000]   That's what a gauge transformation is.
[02:24:14.000 --> 02:24:19.000]   Amazing to me that we don't have a simple video
[02:24:19.000 --> 02:24:23.920]   visualizing things that I've already had built
[02:24:23.920 --> 02:24:27.360]   and that I can clearly demonstrate.
[02:24:27.360 --> 02:24:31.040]   When you do that torus, the code of the torus
[02:24:31.040 --> 02:24:33.840]   is itself generating spinning torus.
[02:24:33.840 --> 02:24:34.920]   - Yeah.
[02:24:34.920 --> 02:24:37.520]   - This is a U1 principle bundle.
[02:24:37.520 --> 02:24:39.840]   And the world needs to know what a gauge theory is,
[02:24:39.840 --> 02:24:42.680]   not by analogy, not what Lawrence Krauss saying,
[02:24:42.680 --> 02:24:43.680]   it's like a checkerboard,
[02:24:43.680 --> 02:24:45.280]   if you change some of the colors this way,
[02:24:45.280 --> 02:24:50.280]   not saying that it's a local symmetry involving,
[02:24:50.280 --> 02:24:52.440]   it's none of those things.
[02:24:52.440 --> 02:24:54.460]   It's a theory of differential calculus
[02:24:54.460 --> 02:24:57.360]   where the functions and the derivatives
[02:24:57.360 --> 02:25:00.720]   are both subject to a particular kind of change
[02:25:00.720 --> 02:25:03.760]   so that if a function was constant under one derivative,
[02:25:03.760 --> 02:25:05.920]   then the new function is constant
[02:25:05.920 --> 02:25:09.880]   under the new derivative transformed in the same fashion.
[02:25:09.880 --> 02:25:11.600]   - And would you put that under the category
[02:25:11.600 --> 02:25:13.440]   of just gauge transformations?
[02:25:13.440 --> 02:25:15.600]   - Yes, that would be gauge transformations
[02:25:15.600 --> 02:25:17.560]   applied to sections and connections
[02:25:17.560 --> 02:25:20.160]   where connections are the derivatives in the theory.
[02:25:20.160 --> 02:25:23.720]   This is easily explained.
[02:25:23.720 --> 02:25:27.160]   It is pathological that the community of people
[02:25:27.160 --> 02:25:29.520]   who understand what I'm saying have never bothered
[02:25:29.520 --> 02:25:32.120]   to do this in a clear fashion for the general public.
[02:25:32.120 --> 02:25:35.240]   You and I could visualize this overnight.
[02:25:35.240 --> 02:25:37.520]   This is not hard.
[02:25:37.520 --> 02:25:41.700]   The public needs to know in some sense
[02:25:41.700 --> 02:25:43.920]   that let's say quantum electrodynamics,
[02:25:43.920 --> 02:25:45.640]   the theory of photons and electrons,
[02:25:45.640 --> 02:25:48.120]   more or less electrons are functions
[02:25:48.120 --> 02:25:50.600]   and photons are derivatives.
[02:25:50.600 --> 02:25:53.680]   Now, you can object in some ways,
[02:25:53.680 --> 02:25:55.720]   but basically a gauge theory is the way
[02:25:55.720 --> 02:26:00.160]   in which you can translate a shift
[02:26:00.160 --> 02:26:02.320]   in the definition of the functions
[02:26:02.320 --> 02:26:04.440]   and the shift of the definition of the derivatives
[02:26:04.440 --> 02:26:08.920]   so that the underlying physics is not harmed or changed.
[02:26:08.920 --> 02:26:10.620]   So you have to do both at the same time.
[02:26:10.620 --> 02:26:12.120]   Now, you and I can visualize that.
[02:26:12.120 --> 02:26:14.140]   So if what you wanted to do,
[02:26:14.140 --> 02:26:17.040]   rather than going directly to geometric unity,
[02:26:17.040 --> 02:26:18.760]   is that I could sit down with you
[02:26:18.760 --> 02:26:20.640]   and I could say here are the various components
[02:26:20.640 --> 02:26:22.280]   of geometric unity.
[02:26:22.280 --> 02:26:24.520]   And if the public needs a visualization
[02:26:24.520 --> 02:26:26.160]   in order to play along,
[02:26:26.160 --> 02:26:27.800]   we've got a little over two months
[02:26:27.800 --> 02:26:29.880]   and I'd be happy to work with you.
[02:26:29.880 --> 02:26:32.500]   - I love that as a challenge and I'll take it on
[02:26:32.500 --> 02:26:33.800]   and I hope we do make it happen.
[02:26:33.800 --> 02:26:34.840]   - And David Goggins,
[02:26:34.840 --> 02:26:38.280]   if Lex doesn't do some super macho thing
[02:26:38.280 --> 02:26:42.240]   because he's got to work to get some of this stuff done,
[02:26:42.240 --> 02:26:45.200]   you'll understand he'll be available to you after April.
[02:26:45.200 --> 02:26:47.720]   - Thank you for the escape clause.
[02:26:47.720 --> 02:26:49.280]   I really needed that escape clause.
[02:26:49.280 --> 02:26:50.120]   I'm glad that's on record.
[02:26:50.120 --> 02:26:53.000]   - I'm worried, 48 miles in 48 hours?
[02:26:53.000 --> 02:26:55.440]   By the way, I just want to say how much I admire
[02:26:55.440 --> 02:27:00.220]   your willingness to keep this kind of hardcore attitude.
[02:27:00.220 --> 02:27:03.080]   I know that Russians have it
[02:27:03.080 --> 02:27:04.800]   and Russian Jews have it in spades,
[02:27:04.800 --> 02:27:08.280]   but it's harder to do in a society that's sloppy
[02:27:08.280 --> 02:27:11.040]   and that's weak and that's lazy.
[02:27:11.040 --> 02:27:13.880]   And the fact that you bring so much heart
[02:27:13.880 --> 02:27:16.360]   to saying I'm going to bring this to jujitsu,
[02:27:16.360 --> 02:27:17.800]   I'm going to bring this to guitar,
[02:27:17.800 --> 02:27:18.880]   I'm going to bring this to AI,
[02:27:18.880 --> 02:27:21.200]   I'm going to bring this to podcasting,
[02:27:21.200 --> 02:27:22.640]   it comes through loud and clear.
[02:27:22.640 --> 02:27:25.040]   I just find it completely and utterly inspiring
[02:27:25.040 --> 02:27:28.080]   that you keep this kind of hardcore aspect
[02:27:28.080 --> 02:27:29.280]   at the same time that you're the guy
[02:27:29.280 --> 02:27:31.960]   who's extolling the virtue of love in a modern society
[02:27:31.960 --> 02:27:33.240]   and doing it at scale.
[02:27:33.240 --> 02:27:34.680]   - Thank you, that means a lot.
[02:27:34.680 --> 02:27:36.040]   I don't know why I'm doing it,
[02:27:36.040 --> 02:27:37.800]   but I'm just following my heart on it
[02:27:37.800 --> 02:27:40.080]   and just going with the gut.
[02:27:40.080 --> 02:27:42.280]   It seems to make sense somehow.
[02:27:42.280 --> 02:27:45.840]   - I personally think we better get tougher
[02:27:45.840 --> 02:27:47.920]   or we're going to get in a world of pain.
[02:27:47.920 --> 02:27:51.560]   And I do think that when it comes time to lead,
[02:27:51.560 --> 02:27:53.600]   it's great to have people who you know
[02:27:53.600 --> 02:27:54.960]   don't crack under pressure.
[02:27:54.960 --> 02:27:59.160]   - Do you mind if we talk about love
[02:27:59.160 --> 02:28:01.280]   and what it takes to be a father for a bit?
[02:28:01.280 --> 02:28:02.120]   - Sure.
[02:28:02.120 --> 02:28:03.880]   - Do you mind if Zev joins us?
[02:28:03.880 --> 02:28:04.800]   - I'd be an honor.
[02:28:04.800 --> 02:28:11.520]   - So Eric, I've talked to your son Zev,
[02:28:11.520 --> 02:28:14.040]   who's an incredible human being,
[02:28:14.040 --> 02:28:19.040]   but let me ask you,
[02:28:19.040 --> 02:28:21.040]   this might be difficult
[02:28:21.040 --> 02:28:22.940]   because you're both sitting together.
[02:28:22.940 --> 02:28:27.920]   What advice do you have for him
[02:28:27.920 --> 02:28:31.080]   as he makes his way in this world,
[02:28:31.080 --> 02:28:35.280]   especially given that, as we mentioned before on Joe Rogan,
[02:28:35.280 --> 02:28:38.580]   you're flawed in that just like all humans, you're mortal.
[02:28:39.960 --> 02:28:44.720]   - Well, at some level, I guess one of my issues
[02:28:44.720 --> 02:28:47.320]   is that I've got to stop giving quite so much advice.
[02:28:47.320 --> 02:28:50.560]   Early on, I was very worried
[02:28:50.560 --> 02:28:52.800]   that I could see Zev's abilities
[02:28:52.800 --> 02:28:55.360]   and I could see his challenges
[02:28:55.360 --> 02:28:57.920]   and I saw them in terms of myself.
[02:28:57.920 --> 02:29:00.280]   So a certain amount of Zev rhymes
[02:29:00.280 --> 02:29:02.760]   with whatever I went through as a kid.
[02:29:02.760 --> 02:29:07.080]   And I don't want to doom him to the same outcomes
[02:29:07.080 --> 02:29:09.000]   that sufficed for me.
[02:29:09.000 --> 02:29:11.880]   I think that he's got a much better head on his shoulders
[02:29:11.880 --> 02:29:14.840]   at age 15, he's much better adjusted.
[02:29:14.840 --> 02:29:19.280]   And in part, it's important for me to recognize
[02:29:19.280 --> 02:29:22.680]   that because I think I did a reasonably decent job early on,
[02:29:22.680 --> 02:29:26.440]   I don't need to get this part right.
[02:29:26.440 --> 02:29:31.440]   And I'm looking at Zev's trajectory
[02:29:31.440 --> 02:29:36.200]   and saying, you're gonna need to be incredibly,
[02:29:36.200 --> 02:29:38.920]   even pathologically self-confident
[02:29:38.920 --> 02:29:41.040]   and the antidote for that is gonna be something
[02:29:41.040 --> 02:29:42.360]   you're gonna need to carry on board,
[02:29:42.360 --> 02:29:43.860]   which is radical humility.
[02:29:43.860 --> 02:29:46.600]   And you're gonna have to have those
[02:29:46.600 --> 02:29:49.040]   in a dialectical tension, which is never resolved,
[02:29:49.040 --> 02:29:50.960]   which is a huge burden.
[02:29:50.960 --> 02:29:53.420]   You are going to have to forgive people
[02:29:53.420 --> 02:29:55.480]   who do not appreciate your gifts
[02:29:55.480 --> 02:29:57.540]   because your gifts are clearly evident
[02:29:57.540 --> 02:29:59.860]   and many people will have to pretend not to see them
[02:29:59.860 --> 02:30:02.480]   because if they see your gifts,
[02:30:02.480 --> 02:30:04.520]   then they're gonna have to question their entire approach
[02:30:04.520 --> 02:30:08.820]   to education or employment or critical thinking.
[02:30:08.820 --> 02:30:12.680]   And what my hope is is that you can just forgive those
[02:30:12.680 --> 02:30:14.720]   who don't see them and who complicate
[02:30:14.720 --> 02:30:16.280]   and frustrate your life and realize
[02:30:16.280 --> 02:30:18.400]   that you're gonna have to take care of them too.
[02:30:18.400 --> 02:30:20.440]   - Zev, let me ask you the more challenging question
[02:30:20.440 --> 02:30:22.360]   'cause the guy's sitting right here.
[02:30:22.360 --> 02:30:24.960]   What advice do you have for your dad?
[02:30:24.960 --> 02:30:29.520]   Since after talking to you, I realize you're the more
[02:30:29.520 --> 02:30:34.520]   brilliant aside from the better looking member of the family.
[02:30:37.600 --> 02:30:38.880]   (laughing)
[02:30:38.880 --> 02:30:41.180]   - It's a bit of an odd question.
[02:30:41.180 --> 02:30:43.820]   - Sorry.
[02:30:43.820 --> 02:30:44.640]   - You can say anything you want,
[02:30:44.640 --> 02:30:45.980]   this is the last time we're gonna be seeing this.
[02:30:45.980 --> 02:30:48.100]   (laughing)
[02:30:48.100 --> 02:30:50.100]   - This is gonna be an awkward drive home.
[02:30:50.100 --> 02:30:55.960]   - I think sort of a new perspective I've taken
[02:30:55.960 --> 02:30:59.740]   on parenting is that it is a task
[02:30:59.740 --> 02:31:04.740]   for which no human is really supposed to be prepared.
[02:31:04.960 --> 02:31:08.180]   There are in Jewish tradition, for example,
[02:31:08.180 --> 02:31:12.180]   there are myriad analogies in the Torah
[02:31:12.180 --> 02:31:16.180]   and the Talmud that compare the role of a parent
[02:31:16.180 --> 02:31:18.780]   to the role of a God, right?
[02:31:18.780 --> 02:31:21.540]   And no human is prepared to play God
[02:31:21.540 --> 02:31:23.860]   and create and guide a life,
[02:31:23.860 --> 02:31:27.660]   but somehow we're forced into it as people.
[02:31:27.660 --> 02:31:32.740]   And I think sometimes it's hard for children
[02:31:32.740 --> 02:31:35.940]   to understand that however their parents are failing.
[02:31:35.940 --> 02:31:38.260]   (laughing)
[02:31:38.260 --> 02:31:39.100]   Sort of has to be.
[02:31:39.100 --> 02:31:40.580]   - It's a theme here.
[02:31:40.580 --> 02:31:43.980]   - Is something for which we must budget
[02:31:43.980 --> 02:31:46.580]   because our parents play a role in our lives
[02:31:46.580 --> 02:31:52.060]   of which they're not worthy and they devote themselves to,
[02:31:52.060 --> 02:31:54.480]   regardless, because that becomes who they are
[02:31:54.480 --> 02:31:55.940]   in a certain sense.
[02:31:55.940 --> 02:32:00.120]   So I hope to,
[02:32:00.960 --> 02:32:05.960]   I hope to have realistic expectations of you as a human
[02:32:05.960 --> 02:32:12.000]   because I think too often it's easy
[02:32:12.000 --> 02:32:14.720]   to have godly expectations of people
[02:32:14.720 --> 02:32:18.000]   who are far from such a role.
[02:32:18.000 --> 02:32:22.720]   And I think I'm really happy that you've been as open
[02:32:22.720 --> 02:32:25.560]   as you have with me about the fact that,
[02:32:27.880 --> 02:32:30.120]   you know, you really, you don't pretend to be a God
[02:32:30.120 --> 02:32:30.960]   in my life.
[02:32:30.960 --> 02:32:38.000]   You are a guide who allows me to see myself.
[02:32:38.000 --> 02:32:41.160]   And that's been very important considering the fact
[02:32:41.160 --> 02:32:44.600]   that by your self-teaching paradigm,
[02:32:44.600 --> 02:32:48.840]   I will have to guide myself.
[02:32:48.840 --> 02:32:52.320]   And being able to see it and see myself accurately
[02:32:52.320 --> 02:32:55.660]   has been one of the greatest gifts that you've given me.
[02:32:55.660 --> 02:32:57.760]   So I'm very appreciative.
[02:32:57.760 --> 02:33:02.760]   And I want you to know that I don't buy into the role
[02:33:02.760 --> 02:33:06.120]   that you're supposed to
[02:33:06.120 --> 02:33:15.960]   sort of fake your way through in my life,
[02:33:15.960 --> 02:33:20.960]   but I am unbelievably happy
[02:33:20.960 --> 02:33:25.680]   with a more realistic connection
[02:33:25.680 --> 02:33:29.140]   that we've been able to build in lieu of it.
[02:33:29.140 --> 02:33:31.200]   - I think it's been easier on you actually
[02:33:31.200 --> 02:33:34.040]   as you come to realize what I don't know,
[02:33:34.040 --> 02:33:35.760]   what I can't do.
[02:33:35.760 --> 02:33:37.560]   And that there's been a period of time, I guess,
[02:33:37.560 --> 02:33:42.000]   that's fascinating to me where you're sort of surprised
[02:33:42.000 --> 02:33:45.160]   that I don't know the answer to a certain thing
[02:33:45.160 --> 02:33:46.160]   as well as you do.
[02:33:46.160 --> 02:33:50.200]   And that I remember going through this
[02:33:50.200 --> 02:33:52.440]   with a particular mathematician who I held,
[02:33:52.440 --> 02:33:55.440]   and I still hold in awe, named David Kajdan.
[02:33:55.440 --> 02:33:58.320]   And he famously said to him,
[02:33:58.320 --> 02:34:01.160]   and weirdly our family knew his family in the Soviet Union,
[02:34:01.160 --> 02:34:05.360]   but he said, "You know, Eric,
[02:34:05.360 --> 02:34:07.420]   "I always appreciate you coming to my office
[02:34:07.420 --> 02:34:10.360]   "because I always find what you have to say interesting,
[02:34:10.360 --> 02:34:11.720]   "but you have to realize that in the areas
[02:34:11.720 --> 02:34:13.940]   "that you're talking about, you are no longer the student.
[02:34:13.940 --> 02:34:16.160]   "You are actually my teacher."
[02:34:16.160 --> 02:34:18.880]   And I wasn't prepared to hear that.
[02:34:18.880 --> 02:34:20.420]   And there are many ways in which,
[02:34:20.420 --> 02:34:22.860]   as I was just saying with the Mozart,
[02:34:22.860 --> 02:34:26.520]   I am learning at an incredible rate from you.
[02:34:26.520 --> 02:34:28.920]   I used to learn from you
[02:34:28.920 --> 02:34:30.600]   because I didn't understand what was possible.
[02:34:30.600 --> 02:34:33.840]   You were very much, I mean, this is the weird thing.
[02:34:33.840 --> 02:34:35.400]   There used to be this thing called Harvey,
[02:34:35.400 --> 02:34:36.400]   the invisible rabbit.
[02:34:36.400 --> 02:34:39.000]   This guy had a rabbit that was like six feet tall
[02:34:39.000 --> 02:34:41.700]   that only he could see, maybe he was talking.
[02:34:41.700 --> 02:34:43.600]   And that was like you at age four.
[02:34:43.600 --> 02:34:47.280]   You were saying batches of crazy things
[02:34:47.280 --> 02:34:48.920]   that were all totally sensible
[02:34:48.920 --> 02:34:50.760]   and nobody else could put them together.
[02:34:50.760 --> 02:34:55.340]   And so what's wonderful is that the world hasn't caught on,
[02:34:55.340 --> 02:34:58.560]   but enormous numbers of people are starting to.
[02:34:58.560 --> 02:35:03.560]   And I really do hope that that genuineness of spirit
[02:35:03.560 --> 02:35:08.380]   and that outside the box intellectual commitment
[02:35:08.380 --> 02:35:13.180]   serves you well as the world starts to appreciate
[02:35:13.180 --> 02:35:16.020]   that I think you're a very trustworthy voice.
[02:35:16.020 --> 02:35:17.340]   You don't get everything right,
[02:35:17.340 --> 02:35:20.180]   but the idea that we have somebody at your age
[02:35:20.180 --> 02:35:21.620]   who's embedded in your generation
[02:35:21.620 --> 02:35:23.820]   who can tell us something about what's happening
[02:35:23.820 --> 02:35:25.020]   is really valuable to me.
[02:35:25.020 --> 02:35:28.340]   And I do hope that you'll consider boosting that voice
[02:35:28.340 --> 02:35:30.940]   more than just at the dinner table.
[02:35:30.940 --> 02:35:36.540]   - I apologize for saying this four-letter word,
[02:35:36.540 --> 02:35:39.800]   but do you love Zev?
[02:35:39.800 --> 02:35:43.260]   - I was really worried it was gonna be another
[02:35:43.260 --> 02:35:44.300]   four-letter word.
[02:35:44.300 --> 02:35:46.140]   - There's so many to choose from.
[02:35:46.140 --> 02:35:49.140]   - It doesn't even rise to the level of a question.
[02:35:49.140 --> 02:35:53.820]   I mean, I just, there are a tiny number of people
[02:35:53.820 --> 02:35:56.580]   with whom you share so much life
[02:35:56.580 --> 02:36:01.340]   that you can't even think of yourself in their absence.
[02:36:01.340 --> 02:36:04.560]   And I don't know if Zev would find that,
[02:36:04.560 --> 02:36:08.780]   but you can have a kid
[02:36:08.780 --> 02:36:11.100]   and never make this level of connection.
[02:36:11.100 --> 02:36:14.700]   I think even right down to the fact that
[02:36:15.620 --> 02:36:19.020]   when Zev chooses boogie-woogie piano
[02:36:19.020 --> 02:36:22.420]   for his own set of reasons
[02:36:22.420 --> 02:36:24.060]   why I would choose boogie-woogie piano
[02:36:24.060 --> 02:36:25.620]   if I could play in any style,
[02:36:25.620 --> 02:36:30.820]   it's a question about a decrease in loneliness.
[02:36:30.820 --> 02:36:34.180]   You know, like my grandfather played the mandolin
[02:36:34.180 --> 02:36:35.820]   and I had to learn some mandolin
[02:36:35.820 --> 02:36:38.560]   because otherwise that instrument would go silent.
[02:36:38.560 --> 02:36:42.620]   You don't expect that you get this much of a chance
[02:36:42.620 --> 02:36:45.660]   to leave this much of yourself in another person
[02:36:45.660 --> 02:36:50.580]   who is choosing it and recreating it
[02:36:50.580 --> 02:36:54.040]   rather than it being directly instilled.
[02:36:54.040 --> 02:36:59.820]   And my proudest achievement is in a certain sense
[02:36:59.820 --> 02:37:04.820]   having not taught him and having shared this much.
[02:37:04.820 --> 02:37:09.780]   So, you know, it's not even love, it's like well beyond.
[02:37:09.780 --> 02:37:14.780]   - So you mentioned love for you making a less lonely world.
[02:37:14.780 --> 02:37:19.980]   I think I speak for, I would argue,
[02:37:19.980 --> 02:37:22.820]   probably millions of people that you, Eric,
[02:37:22.820 --> 02:37:24.940]   'cause this is a conversation with you,
[02:37:24.940 --> 02:37:29.940]   have made for many people, for me, a less lonely world.
[02:37:29.940 --> 02:37:35.220]   And I can't wait to see how you Zev develop as an intellect,
[02:37:35.740 --> 02:37:40.740]   but also I'm so heartworn by the optimism
[02:37:40.740 --> 02:37:43.420]   and the hopefulness that was in you
[02:37:43.420 --> 02:37:45.940]   that I hope develops further.
[02:37:45.940 --> 02:37:50.420]   And lastly, I'm deeply thankful that you, Eric,
[02:37:50.420 --> 02:37:53.980]   are my friend and would give me,
[02:37:53.980 --> 02:37:57.580]   would honor me with this watch.
[02:37:57.580 --> 02:38:00.100]   It means more than words can say.
[02:38:00.100 --> 02:38:01.980]   Thanks guys, thanks for talking today.
[02:38:01.980 --> 02:38:03.540]   - Thank you.
[02:38:03.540 --> 02:38:05.100]   - Thanks for listening to this conversation
[02:38:05.100 --> 02:38:08.180]   with Eric Weinstein and thank you to our sponsors.
[02:38:08.180 --> 02:38:12.540]   Indeed hiring site, Theragun muscle recovery device,
[02:38:12.540 --> 02:38:14.860]   Wine Access online wine store,
[02:38:14.860 --> 02:38:17.980]   and Blinkist app that summarizes books.
[02:38:17.980 --> 02:38:20.140]   Click the sponsor links to get a discount
[02:38:20.140 --> 02:38:22.140]   and to support this podcast.
[02:38:22.140 --> 02:38:25.340]   And now let me leave you with some words from Socrates.
[02:38:25.340 --> 02:38:28.240]   To find yourself, think for yourself.
[02:38:28.240 --> 02:38:31.780]   Thanks for listening and hope to see you next time.
[02:38:31.780 --> 02:38:34.360]   (upbeat music)
[02:38:34.360 --> 02:38:36.940]   (upbeat music)
[02:38:36.940 --> 02:38:46.940]   [BLANK_AUDIO]

