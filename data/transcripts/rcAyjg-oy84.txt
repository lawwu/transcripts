
[00:00:00.040 --> 00:00:05.720]   Welcome to the Huberman Lab podcast, where we discuss science and science-based tools for everyday life.
[00:00:05.720 --> 00:00:14.740]   I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine.
[00:00:14.740 --> 00:00:17.240]   My guest today is Dr. Michael Kilgard.
[00:00:17.240 --> 00:00:21.060]   Dr. Michael Kilgard is a professor at the University of Texas at Dallas,
[00:00:21.060 --> 00:00:24.160]   and he is one of the world's leading experts in neuroplasticity,
[00:00:24.160 --> 00:00:27.600]   which is the brain's ability to change in response to experience.
[00:00:27.600 --> 00:00:31.740]   Since the beginning of the field of neuroscience, meaning for well over 100 years,
[00:00:31.740 --> 00:00:34.260]   it was understood that the young brain can change.
[00:00:34.260 --> 00:00:38.240]   Kids can learn things, they can learn languages, new skills, and young adults can learn,
[00:00:38.240 --> 00:00:41.340]   but that the adult brain was less capable of learning.
[00:00:41.340 --> 00:00:45.200]   Then in the late 90s, it was Dr. Kilgard, in collaboration with his colleagues,
[00:00:45.200 --> 00:00:50.540]   that discovered that indeed the adult brain can change massively if the right conditions are set.
[00:00:50.540 --> 00:00:56.540]   His work showed that if specific neuromodulators, meaning acetylcholine, norepinephrine, serotonin, or dopamine,
[00:00:56.880 --> 00:01:03.380]   are triggered to be released in the adult brain, you can achieve massive rewiring of brain circuits and learning, even as an adult.
[00:01:03.380 --> 00:01:08.940]   This opened up an entire new field within neuroscience and, of course, has profound implications for health and disease.
[00:01:08.940 --> 00:01:13.040]   It's also completely changed the way that we think about learning, longevity, and brain health.
[00:01:13.040 --> 00:01:19.980]   More recently, Dr. Kilgard's research has focused on vagus nerve stimulation to precisely control the timing of neuromodulator release.
[00:01:19.980 --> 00:01:24.300]   As you may know, the vagus nerve connects the body with the brain and the brain with the body.
[00:01:24.300 --> 00:01:32.260]   And by stimulating a particular branch of the vagus nerve pathway, his laboratory has shown that people can overcome debilitating conditions such as tinnitus,
[00:01:32.260 --> 00:01:36.340]   stroke, and even restore mobility to people who have suffered spinal cord injuries.
[00:01:36.340 --> 00:01:43.640]   During today's episode, we discussed the specific actionable strategies that you or anyone can use to rewire your brain at any stage of life.
[00:01:43.840 --> 00:01:51.480]   So, as you'll soon see, Dr. Kilgard has an exceptionally clear and practical understanding of how to apply what we know about neuroplasticity
[00:01:51.480 --> 00:01:54.500]   so that you can learn better and improve your brain health.
[00:01:54.500 --> 00:01:59.560]   Before we begin, I'd like to emphasize that this podcast is separate from my teaching and research roles at Stanford.
[00:01:59.560 --> 00:02:06.800]   It is, however, part of my desire and effort to bring zero-cost-to-consumer information about science and science-related tools to the general public.
[00:02:06.800 --> 00:02:10.220]   In keeping with that theme, today's episode does include sponsors.
[00:02:10.220 --> 00:02:15.760]   I have a brief announcement to make about my upcoming book, Protocols, an Operating Manual for the Human Body.
[00:02:16.120 --> 00:02:22.060]   I've completed the book now several times, and yet it's not quite ready for release, and I'll tell you why.
[00:02:22.060 --> 00:02:28.780]   Some years ago, somebody I highly respect in the research science field that I was working with on a project said to us as a group,
[00:02:28.780 --> 00:02:31.980]   if you have the opportunity to make something better, you do it.
[00:02:31.980 --> 00:02:38.060]   Now, I realize that runs counter to what we all so often hear, which is never let perfect get in the way of completed.
[00:02:38.060 --> 00:02:41.200]   But I must say, when it comes to providing the public health protocols,
[00:02:41.200 --> 00:02:46.660]   protocols, I absolutely insist that you have the most up-to-date science and information in the protocols book.
[00:02:46.660 --> 00:02:51.220]   And so that's the reason why I've decided to go through and basically revise each and every chapter,
[00:02:51.220 --> 00:02:55.300]   adding some things based on new research and improving the protocols overall.
[00:02:55.300 --> 00:02:58.960]   I strongly feel that's my obligation to the data and to all of you.
[00:02:58.960 --> 00:03:04.140]   I confess part of the delay is also because I've decided to do all the illustrations for the book myself.
[00:03:04.240 --> 00:03:08.220]   As a consequence, my book is now going to be released in September, 2026.
[00:03:08.220 --> 00:03:12.200]   If you'd like to pre-order the book, it's available in English and other languages.
[00:03:12.200 --> 00:03:14.660]   And yes, it will be available in audio form.
[00:03:14.660 --> 00:03:17.740]   If you'd like to pre-order, go to protocolsbook.com.
[00:03:17.740 --> 00:03:18.880]   Thank you for your patience.
[00:03:18.880 --> 00:03:21.380]   I'm excited to share the book with you next year.
[00:03:21.380 --> 00:03:24.320]   And now for my discussion with Dr. Michael Kilgard.
[00:03:24.320 --> 00:03:26.240]   Dr. Michael Kilgard, welcome.
[00:03:26.240 --> 00:03:27.040]   Nice to be here.
[00:03:27.580 --> 00:03:35.120]   You and I both share a fascination with neuroplasticity, the ability for our nervous system to change itself, for better or worse.
[00:03:35.120 --> 00:03:44.260]   So to start off, let's just talk about plasticity, what it is, how plasticity in childhood differs from plasticity in adulthood.
[00:03:44.260 --> 00:03:45.980]   I know how I think about these topics.
[00:03:45.980 --> 00:03:52.080]   I'd love to know how you think about neuroplasticity and why you've essentially devoted your professional life to studying it.
[00:03:52.080 --> 00:03:52.720]   Yeah.
[00:03:53.040 --> 00:03:58.180]   I mean, I don't love the word plastic makes it seem like something artificial and uninteresting.
[00:03:58.180 --> 00:04:01.640]   But the idea that the brain can change is a new idea.
[00:04:01.640 --> 00:04:04.980]   We used to think everything was hardwired and you are the way they are and nothing can change.
[00:04:04.980 --> 00:04:09.560]   Now we know that you're making new connections every day, every time you learn something new.
[00:04:09.560 --> 00:04:16.440]   And that change in our way of thinking about things has implications up and down the aisle on how we interact and everything we do.
[00:04:16.940 --> 00:04:23.720]   The science of it, oh, it's so exciting, the types of experiments that have been done, the ways that you can literally see these new connections.
[00:04:23.720 --> 00:04:30.960]   Our forefathers 100 years ago could only look at dead tissue and imagine all the changes and excitement that was going on, Ramonica Hall and others.
[00:04:31.520 --> 00:04:39.200]   But now we can real-time watch these new connections and imagine that there's not hundreds of them, there's not thousands of them, there's not millions of them, there's not billions.
[00:04:39.200 --> 00:04:47.460]   But there's trillions of new connections every second of your day are trying to decide, should I strengthen this one, should I weaken this one, or should I leave them the same?
[00:04:48.080 --> 00:04:53.240]   And that idea that your brain is as active as you feel is so different than what we were told.
[00:04:53.240 --> 00:04:57.660]   We were told you've got this brain, it's very dangerous, you should wear a helmet, you should not mess with it.
[00:04:57.660 --> 00:05:06.300]   And the fact that it's alive and moving to me is just much more consistent with my experience with my own inner life and interacting with other people.
[00:05:06.560 --> 00:05:13.580]   So the fact that the science matches the everyday experience, I think is one of the most enlightening parts of those experiments.
[00:05:13.580 --> 00:05:26.580]   So when you think about developmental plasticity, which I have been from birth up to about age 25 is what we always hear, oh, you know, up until age 25, the brain is ultraplastic.
[00:05:26.580 --> 00:05:29.640]   And then after 25, it's much harder to change, but it can be done.
[00:05:29.640 --> 00:05:31.260]   You have kids.
[00:05:32.260 --> 00:05:40.440]   When you were raising your kids, given what you know about neuroplasticity, what were some of the thoughts going on in your mind about things that you should do or shouldn't do?
[00:05:40.440 --> 00:05:44.720]   I know you're not giving parenting instructions, but I think there are many parents out there.
[00:05:44.720 --> 00:05:57.500]   All of us were children once, or perhaps still are, and are curious, like, how does a neuroscientist who works on neuroplasticity think about learning in general and also just passive exposure to life?
[00:05:57.500 --> 00:06:00.800]   Because as a child, every day is new learning.
[00:06:01.400 --> 00:06:03.460]   I mean, they always tell you don't sweat the small stuff.
[00:06:03.460 --> 00:06:06.260]   And then you learn every little thing matters, and you start sweating the small stuff.
[00:06:06.260 --> 00:06:10.960]   You start realizing that the kinds of mobile you got matters, that it's interesting.
[00:06:10.960 --> 00:06:14.400]   We had a mobile, and the mobile would go around in a circle, and it was just boring.
[00:06:14.400 --> 00:06:15.100]   I thought it was uninteresting.
[00:06:15.100 --> 00:06:19.100]   And I'd move it so that it would bump into something and do something a little more interesting from time to time.
[00:06:19.100 --> 00:06:22.460]   My kids spent a lot of time looking out into the natural world.
[00:06:22.460 --> 00:06:27.900]   So there were birds flying and coming and going and not predictable kinds of patterns and, again, tried to avoid some TV.
[00:06:27.900 --> 00:06:30.540]   But the idea that we're kind of in a hurry.
[00:06:30.540 --> 00:06:31.760]   You've got to hook up all these neurons.
[00:06:31.760 --> 00:06:33.620]   Being an adult is going to happen fast.
[00:06:33.620 --> 00:06:35.820]   You've got trillions of connections to make.
[00:06:35.820 --> 00:06:37.920]   Every experience is contributing to that.
[00:06:37.920 --> 00:06:42.220]   So bedtime stories and songs and walks in the park are all making those changes.
[00:06:42.220 --> 00:06:43.640]   That's surprising.
[00:06:43.640 --> 00:06:45.200]   It's surprising that all that stuff matters.
[00:06:45.200 --> 00:06:46.480]   But it does.
[00:06:46.480 --> 00:07:00.920]   And so from my point of view, the fact that the young brain is a sponge and that every little background sound, little clicking sound, road noise, all those things have a potential to impact the way the brain is wired is a cautionary tale.
[00:07:00.920 --> 00:07:04.200]   It makes you worried about having the wrong sounds in the wrong place.
[00:07:04.200 --> 00:07:10.320]   But, of course, you don't really know exactly what the best sounds are going to be, the best sights, the best friendships, and all the rest.
[00:07:11.340 --> 00:07:14.840]   So neuroplasticity is a gift to all of us.
[00:07:14.840 --> 00:07:18.600]   And it makes the point that the details matter.
[00:07:18.600 --> 00:07:21.740]   But it also makes the point that there's lots of details, lots and lots of experiences.
[00:07:21.740 --> 00:07:25.580]   No one formative experience is going to ruin some kid's life.
[00:07:26.060 --> 00:07:27.700]   And I think that's a little bit relieving as well.
[00:07:27.700 --> 00:07:31.560]   Yeah, there's plasticity in both directions, I suppose.
[00:07:31.560 --> 00:07:33.580]   You can wire things in one direction.
[00:07:33.580 --> 00:07:39.320]   And if you don't like it or if your parents don't like it, you can wire it back in another direction.
[00:07:39.320 --> 00:07:42.340]   Although, as we both know, there's a little bit of an asymmetry to that.
[00:07:42.340 --> 00:07:50.520]   It's kind of easier to get negative experiences wired into the brain and a little bit harder or a lot harder, as the case may be, to undo those.
[00:07:51.140 --> 00:07:58.040]   So I guess it was the early 90s when we heard a lot about the so-called first six years.
[00:07:58.040 --> 00:08:04.240]   There was this emphasis on zero to six years of age as being so critical.
[00:08:04.240 --> 00:08:13.380]   And this had parents who understandably were interested and concerned with their kids having the most knowledge, the most capability in life, the best life.
[00:08:13.380 --> 00:08:16.920]   It had parents playing classical music to kids while they were asleep.
[00:08:16.920 --> 00:08:18.720]   It had them doing multiple sports.
[00:08:18.840 --> 00:08:21.760]   There was this idea that you have six years to, like, cram everything in there.
[00:08:21.760 --> 00:08:26.520]   I think we now understand that's not the case, that those first six years are critical.
[00:08:26.520 --> 00:08:29.540]   But there's a long window for plasticity.
[00:08:29.540 --> 00:08:30.360]   Would you agree?
[00:08:30.360 --> 00:08:31.180]   Absolutely.
[00:08:31.180 --> 00:08:33.760]   No, I mean, I think we worry about doors slamming shut.
[00:08:33.760 --> 00:08:39.540]   We worry about every little sight being the thing that's going to define a child for the rest of their lives.
[00:08:39.540 --> 00:08:41.060]   And that's just not the case, right?
[00:08:41.060 --> 00:08:42.280]   Lots and lots of hours.
[00:08:42.280 --> 00:08:44.600]   We always talk about 10,000 hours to be good at anything.
[00:08:44.600 --> 00:08:46.400]   And you realize you get a lot of 10,000 hours.
[00:08:46.520 --> 00:08:48.760]   And you really do, not just your language abilities.
[00:08:48.760 --> 00:08:51.100]   Each person has 100,000 words.
[00:08:51.100 --> 00:08:53.280]   Imagine, you don't have to sit and teach the kids every little word.
[00:08:53.280 --> 00:08:54.180]   They're going to pick them up.
[00:08:54.180 --> 00:08:55.960]   They're just in an environment.
[00:08:55.960 --> 00:09:00.940]   And 100,000 is a lot of words to imagine knowing their definitions, knowing their meanings, and all the rest.
[00:09:00.940 --> 00:09:02.900]   And the same thing of finger movements.
[00:09:02.900 --> 00:09:08.260]   Again, whether they're going to be a violin player or a soccer player, all the dexterous movements that have to go with that.
[00:09:08.800 --> 00:09:12.240]   We as coaches and parents try to train that, but really the kid is training themselves.
[00:09:12.240 --> 00:09:16.160]   They're figuring out how to do all that by practicing, seeing what works and what doesn't work.
[00:09:16.160 --> 00:09:20.400]   We can just set an environment where that's possible and where they can succeed and not quit.
[00:09:21.180 --> 00:09:22.400]   That's really one of the big challenges.
[00:09:22.400 --> 00:09:27.760]   Like I said, a kid gets exposed to food, they get sick, and now their brain has figured out that food might be poison.
[00:09:27.760 --> 00:09:33.920]   But it might be wrong, and they might end up with a plastic event in their brain that turns off a pathway for a long period of time.
[00:09:34.220 --> 00:09:37.260]   And it can really be hard to undo that kind of work.
[00:09:37.260 --> 00:09:41.800]   I'd like to take a quick break and acknowledge our sponsor, 8Sleep.
[00:09:41.800 --> 00:09:46.280]   8Sleep makes smart mattress covers with cooling, heating, and sleep tracking capacity.
[00:09:46.280 --> 00:09:51.840]   One of the best ways to ensure a great night's sleep is to make sure that the temperature of your sleeping environment is correct.
[00:09:51.840 --> 00:09:58.240]   And that's because in order to fall and stay deeply asleep, your body temperature actually has to drop by about 1 to 3 degrees.
[00:09:58.460 --> 00:10:04.820]   And in order to wake up feeling refreshed and energized, your body temperature actually has to increase by about 1 to 3 degrees.
[00:10:04.820 --> 00:10:10.300]   8Sleep automatically regulates the temperature of your bed throughout the night according to your unique needs.
[00:10:10.300 --> 00:10:15.860]   8Sleep has just launched their latest model, the Pod 5, and the Pod 5 has several new important features.
[00:10:15.860 --> 00:10:18.180]   One of these new features is called Autopilot.
[00:10:18.180 --> 00:10:24.940]   Autopilot is an AI engine that learns your sleep patterns to adjust the temperature of your sleeping environment across different sleep stages.
[00:10:24.940 --> 00:10:29.380]   It also elevates your head if you're snoring, and it makes other shifts to optimize your sleep.
[00:10:29.380 --> 00:10:36.600]   The bass on the Pod 5 also has an integrated speaker that syncs to the 8Sleep app and can play audio to support relaxation and recovery.
[00:10:36.600 --> 00:10:42.960]   The audio catalog includes several NSDR, non-sleep deep rest scripts, that I worked on with 8Sleep to record.
[00:10:42.960 --> 00:10:51.820]   If you're not familiar, NSDR involves listening to an audio script that walks you through a deep body relaxation combined with some very simple breathing exercises.
[00:10:51.820 --> 00:10:56.560]   It's an extremely powerful tool that anyone can benefit from the first time and every time.
[00:10:56.560 --> 00:11:03.580]   If you'd like to try 8Sleep, go to 8sleep.com slash Huberman to get up to $350 off the new Pod 5.
[00:11:03.580 --> 00:11:07.640]   8Sleep ships to many countries worldwide, including Mexico and the UAE.
[00:11:07.640 --> 00:11:12.220]   Again, that's 8sleep.com slash Huberman to save up to $350.
[00:11:12.220 --> 00:11:15.380]   Today's episode is also brought to us by Wealthfront.
[00:11:15.380 --> 00:11:20.560]   I've been using Wealthfront for my savings and my investing for nearly a decade, and I absolutely love it.
[00:11:20.560 --> 00:11:26.240]   At the start of every year, I set new goals, and one of my goals for 2025 is to focus on saving money.
[00:11:26.240 --> 00:11:34.400]   Since I have Wealthfront, I'll keep that savings in my Wealthfront cash account, where I'm able to earn 4% annual percentage yield on my deposits, and you can as well.
[00:11:34.400 --> 00:11:41.340]   With Wealthfront, you can earn 4% APY on your cash from partner banks until you're ready to either spend that money or invest it.
[00:11:41.340 --> 00:11:47.000]   With Wealthfront, you also get free instant withdrawals to eligible accounts every day, even on weekends and holidays.
[00:11:47.000 --> 00:11:52.020]   The 4% APY is not a promotional rate, and there's no limit to what you can deposit and earn.
[00:11:52.020 --> 00:11:58.040]   And you can even get protection for up to $8 million through FDIC insurance provided through Wealthfront's partner banks.
[00:11:58.040 --> 00:12:04.400]   Wealthfront gives you free instant withdrawals, where it takes just minutes to transfer your money to eligible external accounts.
[00:12:04.400 --> 00:12:11.880]   It also takes just minutes to transfer your cash from the cash account to any of Wealthfront's automated investment accounts when you're ready to invest.
[00:12:11.880 --> 00:12:17.300]   There are already a million people using Wealthfront to save more, earn more, and build long-term wealth.
[00:12:17.300 --> 00:12:20.020]   Earn 4% APY on your cash today.
[00:12:20.020 --> 00:12:28.960]   If you'd like to try Wealthfront, go to wealthfront.com slash Huberman to receive a free $50 bonus with a $500 deposit into your first cash account.
[00:12:28.960 --> 00:12:32.800]   That's wealthfront.com slash Huberman to get started now.
[00:12:32.800 --> 00:12:35.020]   This has been a paid testimonial of Wealthfront.
[00:12:35.020 --> 00:12:36.960]   Wealthfront brokerage isn't a bank.
[00:12:36.960 --> 00:12:38.840]   The APY is subject to change.
[00:12:38.840 --> 00:12:41.400]   For more information, see the episode description.
[00:12:41.400 --> 00:12:51.480]   What are your thoughts about when a kid has a particular love for one activity, perhaps to the exclusion of everything else because time is limited?
[00:12:51.480 --> 00:13:00.380]   Assuming that activity isn't outwardly destructive, like they're not harming themselves or others, it doesn't involve the use of chemical substances, that kind of thing.
[00:13:00.380 --> 00:13:03.120]   But let's say a kid just loves to read.
[00:13:03.120 --> 00:13:21.700]   And unless forced not to, would just use every possible moment to read or play video games or do any number of different things, then the self-directed learning that they're doing, the plasticity, is being fed by these things that I know we're going to talk a lot about today.
[00:13:22.160 --> 00:13:24.900]   We'll talk a little bit about what you're going to talk a little bit about today.
[00:13:24.900 --> 00:13:25.900]   We're going to talk a little bit about today.
[00:13:25.900 --> 00:13:30.640]   And then we're going to talk a little bit about today.
[00:13:30.640 --> 00:13:30.640]   And then we're going to talk a little bit about today.
[00:13:30.640 --> 00:13:30.640]   We're going to talk a little bit about today.
[00:13:30.640 --> 00:13:31.640]   We're going to talk a little bit about today.
[00:13:31.640 --> 00:13:31.640]   We're going to talk a little bit about today.
[00:13:31.640 --> 00:13:32.640]   We're going to talk a little bit about today.
[00:13:32.640 --> 00:13:32.640]   We're going to talk a little bit about today.
[00:13:32.640 --> 00:13:33.580]   And then we're going to talk a little bit about today.
[00:13:33.580 --> 00:13:33.640]   We're going to talk a little bit about today.
[00:13:33.640 --> 00:13:34.580]   We're going to talk a little bit about today.
[00:13:34.580 --> 00:13:35.640]   We're going to talk a little bit about today.
[00:13:35.640 --> 00:13:59.520]   My kids know that it would depend upon whether I viewed in my judgmental nature the experience as a real experience, an adventure, something that's happening, or an artificial or a fake one.
[00:13:59.520 --> 00:14:06.020]   And my concerns about video games and other things like that are these can be really detrimental because they don't have the statistics of the natural world.
[00:14:06.020 --> 00:14:12.760]   If you're engaged, as my daughter was, with people and you just want to hear people talking, she was infinitely fascinated by what are they talking about?
[00:14:12.760 --> 00:14:13.560]   What are they thinking about?
[00:14:13.560 --> 00:14:16.260]   And there was no end to her interest in people.
[00:14:16.260 --> 00:14:17.540]   People are interesting.
[00:14:17.540 --> 00:14:18.300]   People are complicated.
[00:14:18.300 --> 00:14:28.860]   On the flip side, if you're talking about a video game, I won't name any particular one, where it's an artificial currency where you're sort of constrained to be interested in it, similar to what would happen in Vegas where you'd say,
[00:14:28.920 --> 00:14:34.360]   I'm going to let you win it first so that you can get hooked on it, and then I'm going to adjust it where you're being manipulated actively.
[00:14:34.360 --> 00:14:37.840]   Most experiences kids are interested in, they're not being manipulated.
[00:14:37.840 --> 00:14:38.520]   It's a game.
[00:14:38.520 --> 00:14:41.480]   50% of the time you win, 50% of the time you lose if you're playing football or soccer.
[00:14:41.480 --> 00:14:48.080]   But there are some experiences where someone is actively messing with you in a way that can be negative.
[00:14:48.080 --> 00:14:50.080]   So we would always distinguish between that.
[00:14:50.080 --> 00:14:50.760]   Kids would share.
[00:14:50.760 --> 00:14:53.480]   They had this great experience on a video game or a great video they saw.
[00:14:53.480 --> 00:14:56.300]   And I would just point out that wasn't an experience you actually had.
[00:14:56.540 --> 00:15:00.620]   That was an experience you watched online or something else or that was a video.
[00:15:00.620 --> 00:15:04.840]   And we just kept emphasizing that there's something different about real experiences.
[00:15:04.840 --> 00:15:06.900]   And for me, that's about the statistics.
[00:15:06.900 --> 00:15:08.900]   That's about the pattern in the natural world.
[00:15:08.900 --> 00:15:10.620]   Your work in the visual system.
[00:15:10.620 --> 00:15:12.220]   There's spatial frequencies.
[00:15:12.220 --> 00:15:13.060]   There's distributions.
[00:15:13.060 --> 00:15:16.060]   There's peripheral vision in the auditory system.
[00:15:16.060 --> 00:15:17.080]   There's reverberations.
[00:15:17.200 --> 00:15:21.400]   There's all these things that you can remove if you want to and simplify the world down.
[00:15:21.400 --> 00:15:25.580]   But we evolved in an environment where there were risks.
[00:15:25.580 --> 00:15:26.500]   There were opportunities.
[00:15:26.500 --> 00:15:30.420]   There were ways for us to explore our smell, our touch, our taste.
[00:15:30.420 --> 00:15:31.420]   And they were all integrated together.
[00:15:31.900 --> 00:15:45.200]   When they all get separated and the touch doesn't have anything to do with the sound and the sound doesn't have anything to do with the sight or the smell, there's a potential for them all to sort of drift off on their own and not be integrated in a way that I think is most helpful.
[00:15:45.200 --> 00:15:47.440]   So for me, it was just, is it real?
[00:15:47.440 --> 00:15:50.060]   Would my grandparents recognize this as a good way to spend a day?
[00:15:50.740 --> 00:15:56.960]   And if it wasn't, I'd at least take some time to think about whether or not there might be some negative consequences of that artificial environment.
[00:15:56.960 --> 00:16:09.840]   I think it's really interesting that you say certain experiences aren't really experiences because they don't include the full array or as large an array of the, quote, unquote, statistics of the natural environment.
[00:16:09.840 --> 00:16:14.080]   And I think for us as neuroscientists, we're used to using this language, statistics of the natural environment.
[00:16:14.080 --> 00:16:18.320]   And you pointed this out, but I just want to go into this a little bit more deeply.
[00:16:18.840 --> 00:16:30.660]   You know, in a three-dimensional world like the one we're in now sitting across the table having a conversation or people listening to this and watching it or both, there's a lot of information that we're not aware of.
[00:16:30.660 --> 00:16:34.500]   The depth information, motion information, lack of motion information, right?
[00:16:34.500 --> 00:16:40.160]   If I suddenly start waving my arms around, that's, you know, going to pop out because nothing else really is moving that much.
[00:16:40.160 --> 00:16:50.400]   I think people probably need to hear it from you in order to really appreciate how a developing brain is really a template for wiring all that capability in.
[00:16:50.400 --> 00:16:57.540]   You know, this time from birth until about 25 is really when all the predictions about the world are being formed.
[00:16:57.640 --> 00:17:04.400]   And I think we hear so often about, okay, make sure they learn an instrument, play a sport, they're reading, maybe learn another language.
[00:17:04.400 --> 00:17:06.160]   By the way, learn another language.
[00:17:06.160 --> 00:17:09.460]   You can learn other languages without an accent up until a particular age.
[00:17:09.460 --> 00:17:10.880]   And then it becomes very, very difficult.
[00:17:10.880 --> 00:17:12.840]   I wish I had learned another language.
[00:17:12.840 --> 00:17:13.680]   That's why I say that.
[00:17:14.800 --> 00:17:22.600]   You know, we hear about all the things that ought to make kids more, quote-unquote, functional adults once they get to adulthood.
[00:17:22.600 --> 00:17:35.660]   But what you're describing is a pretty kind of like low-level but foundational aspect to just building a brain that can do a lot of stuff and that wants to forage for interesting real-world experiences as an adult.
[00:17:35.660 --> 00:17:40.600]   So when you were raising your kids, did either of them like video games particularly?
[00:17:40.600 --> 00:17:40.960]   Yeah.
[00:17:40.960 --> 00:17:42.160]   Yes, I don't like video games.
[00:17:42.160 --> 00:17:42.940]   My daughter did not.
[00:17:43.940 --> 00:17:45.740]   It didn't end up becoming a significant problem.
[00:17:45.740 --> 00:17:49.140]   But it was certainly an interesting agility still.
[00:17:49.140 --> 00:17:51.720]   You know, I grew up playing video games as well with one joystick, one button.
[00:17:51.720 --> 00:17:54.020]   Now it's much more complicated and elaborate.
[00:17:54.020 --> 00:17:55.060]   And I appreciate the beauty of it.
[00:17:55.060 --> 00:17:58.220]   I appreciate the finesse, the dexterity, the complexity.
[00:17:58.220 --> 00:17:59.160]   I think it's fantastic.
[00:17:59.160 --> 00:18:08.220]   All the things they can do to be running through a complex environment, navigating a map, looking in a certain direction, walking out, watching out for low-contrast threats and prizes.
[00:18:08.220 --> 00:18:10.800]   So there's a richness to it that is undeniable.
[00:18:10.800 --> 00:18:12.460]   It's really rewarding and satisfying.
[00:18:13.080 --> 00:18:16.880]   The question is just how well does that generalize to other skills you might need in your life?
[00:18:16.880 --> 00:18:18.020]   How well prepared are you?
[00:18:18.380 --> 00:18:26.860]   And are you able to turn that off at the end of the day and go on to study for your tests, you know, do the dishes, mow the lawn, whatever else needs to be done?
[00:18:27.280 --> 00:18:31.540]   And I think there are certain situations where it's really helpful and there are certain situations where it's overblown.
[00:18:31.540 --> 00:18:32.660]   And the same is true of reading.
[00:18:32.660 --> 00:18:39.100]   I mean, I think my grandfather was a head librarian at Arizona State University and it seemed like reading – there's no end to reading.
[00:18:39.100 --> 00:18:40.640]   Couldn't we just all do more reading?
[00:18:40.640 --> 00:18:41.400]   And reading is great.
[00:18:41.480 --> 00:18:44.460]   But there's also restrictions from reading.
[00:18:44.460 --> 00:18:52.380]   Ralph Walden, one of my heroes, he says, you know, books well used are among the best of things and poorly used among the worst.
[00:18:52.880 --> 00:18:59.040]   And the idea is if you could be coming up with your own ideas, maybe you shouldn't need to be following someone else's story and their own adventure.
[00:18:59.040 --> 00:19:00.440]   Maybe you should go out and do your own a little bit.
[00:19:00.440 --> 00:19:02.860]   And the question of proportions is a challenging one.
[00:19:03.240 --> 00:19:06.160]   When it's raining and you can't go outside, maybe that's a good time for reading.
[00:19:06.160 --> 00:19:08.080]   When it's a nice day outside, you could be going outside.
[00:19:08.080 --> 00:19:13.700]   Maybe that's a better time to go find friends and work on dexterity and skills and get some sunlight.
[00:19:13.700 --> 00:19:15.800]   Thanks for mentioning sunlight, by the way.
[00:19:15.800 --> 00:19:18.120]   That's a big theme on this podcast across episodes.
[00:19:18.120 --> 00:19:26.540]   So are you telling me that Emerson himself suggested that the technology of books not be overused?
[00:19:26.540 --> 00:19:27.420]   He did, yeah.
[00:19:27.420 --> 00:19:29.960]   Which is a wild thought in this day and age.
[00:19:29.960 --> 00:19:31.200]   No, it really is.
[00:19:31.280 --> 00:19:35.800]   And I love that that's what I mentioned about sort of our grandfather's wisdom that people knew from a long time ago.
[00:19:35.800 --> 00:19:39.680]   He had an intuition about how we follow into habits.
[00:19:39.680 --> 00:19:42.800]   He would find out that as I walk, I make paths.
[00:19:42.800 --> 00:19:45.480]   And the paths you just see, I keep doing the same way.
[00:19:45.480 --> 00:19:49.700]   And he would look at that and kind of intuit it that that's a habit that I'm forming that may be helpful,
[00:19:49.700 --> 00:19:52.660]   but maybe I should try to take a different way the next day.
[00:19:52.660 --> 00:19:56.100]   Talked about the idea that consistency is overrated.
[00:19:56.100 --> 00:19:58.960]   He had this line from American Scholar.
[00:19:59.820 --> 00:20:05.400]   Consistency is the hobgoblin of little minds, that you feel like whatever I said, I have to keep saying it, keep being right.
[00:20:05.400 --> 00:20:06.940]   And the real world will teach you, no.
[00:20:06.940 --> 00:20:08.540]   If you're wrong, the world will teach you.
[00:20:08.540 --> 00:20:11.120]   If you think you're right about something, all your friends will teach you that you're not.
[00:20:11.120 --> 00:20:16.980]   If you think this is the best way to kick the ball, you'll find out someone else has a different way of doing it or play the instrument or whatever it is.
[00:20:16.980 --> 00:20:28.300]   So I think that idea that there's some humility about there is no optimal, there's no perfect way, there's always some new way of learning is something that I appreciated in reading books.
[00:20:28.300 --> 00:20:33.820]   And it's awkward that here's someone writing a book telling you not to listen to people in books and go out and live the real world.
[00:20:33.880 --> 00:20:37.200]   And I think a lot of us are coming around to that, that we need to have our own real experiences.
[00:20:37.200 --> 00:20:40.160]   And there's value to that, not just reading about someone else's.
[00:20:40.560 --> 00:20:57.060]   I forget where it appeared, but recently there was some photo or article published where an artist had taken images, real world images of humans out in the world, and had deleted the phone from the image in any case where there was a phone in the image.
[00:20:57.060 --> 00:21:00.760]   And what you basically see is that people are out in the world staring at their palms all the time.
[00:21:00.760 --> 00:21:03.800]   And these are images from the last six months or so.
[00:21:03.800 --> 00:21:06.440]   So these aren't paintings, they're not drawings.
[00:21:06.440 --> 00:21:13.020]   And you really get the impression that people are removing themselves from their natural environment almost entirely.
[00:21:13.020 --> 00:21:21.120]   Within the phone, there's something very interesting that I'm curious what you think of for sake of understanding plasticity and what this might be doing to our brains.
[00:21:21.120 --> 00:21:23.700]   A picture is worth a thousand words.
[00:21:23.700 --> 00:21:27.360]   A video is worth a billion pictures.
[00:21:28.100 --> 00:21:44.820]   And I know you're not on social media, but if I scroll through an Instagram feed or a Twitter feed, X feed that is, I can see 50 videos, 100 videos inside of 10 minutes easily.
[00:21:45.660 --> 00:21:52.860]   From disparate contexts, maybe sports, dogs, this, that, something, you know, I mean, and the algorithms obviously deciding what I see.
[00:21:52.860 --> 00:21:58.600]   But I don't think there's ever been an instance in human evolution where that was the case.
[00:21:58.600 --> 00:22:02.420]   I mean, even with television with 200 channels, you can flip between channels.
[00:22:02.420 --> 00:22:05.800]   Okay, I guess you could keep looping, but that doesn't tend to be the case.
[00:22:05.800 --> 00:22:09.160]   People eventually would settle on a show or navigate a menu to a show.
[00:22:09.160 --> 00:22:16.160]   What do you think this means in terms of the processing capacity of young brains in particular?
[00:22:16.160 --> 00:22:23.960]   Like if your son, I don't know how old he is, but if he's still in the developmental window of plasticity, or he was at one point, or your daughter,
[00:22:23.960 --> 00:22:30.720]   if they are seeing 50 videos that are not really linked to one another in any particular way,
[00:22:30.720 --> 00:22:37.600]   that feels like a university experiment where they came into my lab or your lab and we're measuring brain activity
[00:22:37.600 --> 00:22:42.400]   and we're trying to see what random videos presented rapidly does to the brain or something.
[00:22:42.400 --> 00:22:46.740]   It doesn't seem like a healthy thing, and I'm not trying to pass judgment without even understanding what it does.
[00:22:46.740 --> 00:22:50.720]   But this, I can't feel that that would be a good thing for the brain.
[00:22:50.720 --> 00:22:52.980]   The brain's never experienced that before.
[00:22:52.980 --> 00:22:55.120]   Let's talk about what the brain does.
[00:22:55.120 --> 00:22:59.360]   So we know these different areas, which you've talked about, locus aurelius releasing norepinephrine in the brain.
[00:22:59.360 --> 00:23:04.480]   When something new and exciting happens, someone claps their hands or pokes your ear, you know, a bug flies in your face,
[00:23:04.480 --> 00:23:05.320]   the neurons fire.
[00:23:05.320 --> 00:23:06.900]   They're surprised that that happened.
[00:23:07.480 --> 00:23:10.400]   If it keeps happening, then the neurons stop firing.
[00:23:10.400 --> 00:23:15.540]   So one of the things that's most surprising to me and interesting to me is your experiments by Richardson DeLong and others.
[00:23:15.540 --> 00:23:24.320]   Recording from these areas, nucleus basalis releasing acetylcholine, locus aurelius, even dorsal raphe releasing serotonin,
[00:23:24.320 --> 00:23:28.300]   is that they're excited the first time and then they quickly get used to it.
[00:23:28.300 --> 00:23:30.880]   And so they're always waiting for what the new thing is.
[00:23:30.880 --> 00:23:32.420]   What's the thing that's going to be informative?
[00:23:32.420 --> 00:23:35.120]   What's the thing that's going to have the most rewards?
[00:23:35.240 --> 00:23:36.800]   What's the thing that's going to have the most risk?
[00:23:36.800 --> 00:23:45.740]   And the problem is we don't know what the long-term consequences are of having over and over and over activation of that pathway.
[00:23:45.740 --> 00:23:52.060]   We know that if you take a child and just sit in an orphanage for years upon years, they don't come out well.
[00:23:52.060 --> 00:23:55.800]   That's pretty clear with animals or humans that deprivation is not good.
[00:23:55.980 --> 00:23:59.600]   But what happens on the flip side when you stimulate and then you overstimulate?
[00:23:59.600 --> 00:24:00.400]   We don't really know.
[00:24:00.400 --> 00:24:03.200]   At least I don't know of any clear-cut, well-designed experiments.
[00:24:03.200 --> 00:24:08.760]   The suggestion, as you know, is maybe it increases depression and anxiety among adolescents.
[00:24:08.760 --> 00:24:10.320]   That appears to be what's happening.
[00:24:10.320 --> 00:24:13.120]   But there's no causal link because everyone is doing this experiment together.
[00:24:13.120 --> 00:24:16.900]   My children watched lots of videos exposed to lots of things.
[00:24:16.900 --> 00:24:18.620]   It's very difficult to get rid of it.
[00:24:18.620 --> 00:24:19.460]   It's sort of in the water.
[00:24:19.600 --> 00:24:22.320]   It's in the culture having a phone and having that restricted view.
[00:24:22.320 --> 00:24:24.840]   On the flip side, this generation is great.
[00:24:24.840 --> 00:24:33.260]   They've got a million things they know about because they were able to time travel and look at things in the distant past, look at things in the future, look at things in other countries.
[00:24:33.260 --> 00:24:36.460]   Their awareness of people who are different from them is so exciting.
[00:24:36.460 --> 00:24:38.180]   So it's hard to balance those two.
[00:24:38.340 --> 00:24:50.880]   But in general, the concern for me would be if you max out that neuromodulator release, if you do things all the time, including illicit drugs, that push that up, it's intuitive to me that that would then push down all your other experiences.
[00:24:50.880 --> 00:25:00.140]   So I've had the great pleasure of taking my face from the desert world of the Sinai Peninsula and putting it down into the water of the Red Sea.
[00:25:00.140 --> 00:25:01.520]   It's miraculous.
[00:25:01.520 --> 00:25:03.800]   I mean, the level of colors and movement and textures.
[00:25:03.800 --> 00:25:07.060]   And you pull your head back up and you recalibrate it like this is the moon.
[00:25:07.240 --> 00:25:08.620]   There's all this rock.
[00:25:08.620 --> 00:25:09.760]   Put your face back down.
[00:25:09.760 --> 00:25:12.700]   That contrast to me is real and very exciting.
[00:25:12.700 --> 00:25:16.060]   Others have told me that they have taken illicit drugs and had very similar experiences.
[00:25:16.060 --> 00:25:22.920]   And I'm not going to say that my experience of real colors and real life forms and real waves and patterns is superior.
[00:25:22.920 --> 00:25:24.100]   It's just my preference.
[00:25:24.100 --> 00:25:31.840]   And I think we know people for thousands of years have had these kinds of experiences, looking at mountains and streams and groups of people.
[00:25:31.960 --> 00:25:38.940]   What we don't know is what happens when you take a lot of fentanyl, a lot of methamphetamine, a lot of cocaine or even nicotine at high levels.
[00:25:38.940 --> 00:25:39.820]   We don't know.
[00:25:39.820 --> 00:25:42.900]   But the worry is Ben Franklin's all things in moderation.
[00:25:42.900 --> 00:25:47.160]   Probably better to take it slow and make sure you didn't overdo this one.
[00:25:47.520 --> 00:25:52.680]   But I don't know what the negative consequences are going to be other than the potential increase in depression and anxiety.
[00:25:53.880 --> 00:25:56.360]   You were snorkeling on a coral reef in the Dead Sea.
[00:25:56.360 --> 00:25:57.980]   Is that the experience you were describing?
[00:25:57.980 --> 00:25:58.320]   Yeah.
[00:25:58.320 --> 00:25:59.180]   I love aquaria.
[00:25:59.180 --> 00:26:02.960]   I have some at home and I love snorkeling and done some scuba diving.
[00:26:02.960 --> 00:26:03.480]   And I agree.
[00:26:03.480 --> 00:26:11.060]   When you see the richness of a coral reef and then you pop up, it's like the contrast is a big part of that experience.
[00:26:11.060 --> 00:26:11.540]   Yeah.
[00:26:11.580 --> 00:26:12.960]   But it stays with you, right?
[00:26:12.960 --> 00:26:14.940]   I mean, you're out of your element down there.
[00:26:14.940 --> 00:26:17.480]   You know, if you're doing scuba, you're more or less like a fish.
[00:26:17.480 --> 00:26:20.000]   If you're snorkeling, you're a pseudo fish.
[00:26:20.000 --> 00:26:24.960]   But when you come back, those experiences stay with you as an enriching experience.
[00:26:24.960 --> 00:26:30.140]   Watching a video of a coral reef, well, that can be relaxing.
[00:26:30.980 --> 00:26:34.800]   It's a completely different experience, as you pointed out.
[00:26:34.800 --> 00:26:42.120]   I have to be careful because I want – I'm almost 50 and I want to believe that real world experiences are better than virtual ones.
[00:26:42.120 --> 00:26:49.740]   And now with the, you know, the huge arrival of AI, which is only going to expand, everyone's asking the same sorts of questions.
[00:26:49.740 --> 00:26:51.980]   You know, at what point is it true sensory deprivation?
[00:26:51.980 --> 00:26:58.560]   I mean, on the one end of the continuum, as you pointed out, sensory deprivation is bad, especially for a developing brain.
[00:26:59.500 --> 00:27:03.100]   The other end of the continuum, sensory gluttony is also bad.
[00:27:03.100 --> 00:27:04.620]   And we could be talking about food here, right?
[00:27:04.620 --> 00:27:06.380]   Starvation is bad and gluttony is bad.
[00:27:06.380 --> 00:27:07.240]   Both make you sick.
[00:27:07.240 --> 00:27:08.860]   One kills you faster.
[00:27:08.860 --> 00:27:10.680]   Starvation kills you faster.
[00:27:10.680 --> 00:27:23.060]   But as we've now seen with the rates of obesity in this country, you know, gluttony is – I'm not calling people gluttons to be disparaging of them, but let's face it, people are consuming more calories than they burn for whatever reason.
[00:27:23.500 --> 00:27:38.820]   So I think when it comes to sensory input, I have a feeling we're going to arrive at a similar place in a few years where we are going to realize that we need to set upper limits on how much sensory input and set quality standards for sensory input.
[00:27:38.820 --> 00:27:41.220]   Right now we're just kind of drinking from the fire hose.
[00:27:41.380 --> 00:27:47.580]   Well, and how you interact with it and what the ways you interact with it are, if the only way to interact with it is flipping the screen, that's pretty limited.
[00:27:47.580 --> 00:27:49.400]   I mean, the human body does a lot of amazing things.
[00:27:49.400 --> 00:27:55.140]   The way we can navigate, whether it's skateboards or paragliding or whatever, people can do fantastic things with their bodies.
[00:27:55.140 --> 00:27:58.380]   But if you're not required to do it, we know this principle of use it or lose it.
[00:27:58.880 --> 00:28:07.320]   If you don't have that exposure to the sounds of Swedish vowels, when we were born, we could hear all the Swedish vowels, and then we weren't raised in a culture that used them, and they just disappeared.
[00:28:07.320 --> 00:28:16.880]   And the worry is that that ability, the natural predisposition of our brains to handle those kinds of inputs, that over time when we don't use it, we'll say, I guess you don't need this.
[00:28:16.880 --> 00:28:19.580]   I guess swimming is not something that you're going to need to do.
[00:28:19.580 --> 00:28:21.840]   I guess – and a lot of people don't swim, which is fine.
[00:28:22.080 --> 00:28:26.240]   But how many of those experiences get turned off, especially at a young age where they're easier to pick up?
[00:28:26.240 --> 00:28:27.700]   That's one of the big questions.
[00:28:27.700 --> 00:28:28.500]   I don't know.
[00:28:28.500 --> 00:28:37.840]   But it makes sense that the kinds of training, the inputs in, you know, junk in, junk out, we used to think, again, that bodies just grew.
[00:28:37.840 --> 00:28:39.680]   Brains – babies just got bigger.
[00:28:39.680 --> 00:28:40.260]   That's all that happened.
[00:28:40.260 --> 00:28:42.420]   And then we started realizing the things that they saw mattered.
[00:28:42.420 --> 00:28:45.240]   At first we thought, well, let's find what they like.
[00:28:45.240 --> 00:28:46.400]   What do they like the most?
[00:28:46.400 --> 00:28:51.960]   You may remember these old experiments where they found that if you give a baby a face and then you give it a cartoon face,
[00:28:52.280 --> 00:28:55.600]   it will look more strongly at the cartoon face, the exaggerated black and white face.
[00:28:55.600 --> 00:28:58.520]   And some babies had trouble disengaging from it.
[00:28:58.520 --> 00:29:02.440]   The attention mechanisms were so cued to two black circles and a mouth.
[00:29:02.440 --> 00:29:07.980]   And people sold baby mobiles that were these very engaging things that the babies couldn't get their eyes off of.
[00:29:07.980 --> 00:29:10.820]   Now when you go to the Babies R Us or whatever store, you don't see those anymore.
[00:29:10.820 --> 00:29:13.740]   You see much more naturalistic kinds of things.
[00:29:13.740 --> 00:29:17.420]   But there was a moment when we thought, well, if the babies like it, give it to them.
[00:29:18.180 --> 00:29:22.440]   And then we sort of thought, maybe just because they like it is not sufficient.
[00:29:22.440 --> 00:29:28.060]   Maybe we should try to do a longer-term read, not that short-term immediate gratification, but the longer-term.
[00:29:28.060 --> 00:29:33.000]   What does it do that the face I've seen is an extreme face, an exaggerated face?
[00:29:33.340 --> 00:29:40.900]   And again, we think back to individual neurons, whether retinoganglion cells or cells in fusiform face area.
[00:29:40.900 --> 00:29:43.540]   These are parts of the brain that are involved in visual processing.
[00:29:43.540 --> 00:29:49.440]   If those areas are wired normally, appropriately, then we pay attention to the right cues.
[00:29:49.440 --> 00:29:54.920]   It's typical when I'm looking at you, when you're talking, to look at your eyes, not look at your mouth.
[00:29:55.120 --> 00:29:59.680]   But there are a number of people who will be more interested in the movement of the mouth because it's larger than the eye movements.
[00:29:59.680 --> 00:30:04.340]   And that's a less effective way to look, is to look at the mouth instead of looking at the eyes.
[00:30:04.340 --> 00:30:05.760]   These are very subtle things.
[00:30:05.760 --> 00:30:10.960]   But some of the microaggressions, microgestures that are critical, not just in our culture, but in monkeys,
[00:30:10.960 --> 00:30:15.600]   where gritting your teeth might mean one thing and winking or looking away might mean another thing,
[00:30:15.600 --> 00:30:19.280]   we want our children to pick those things up and know about how to interact with humans.
[00:30:19.940 --> 00:30:23.680]   On the flip side, social media and online culture is part of our culture now too.
[00:30:23.680 --> 00:30:30.600]   And so depriving them of that and having them be blocked, deprived of what their culture now is,
[00:30:30.600 --> 00:30:31.620]   is also seemed harmful.
[00:30:31.620 --> 00:30:35.580]   So for me and my wife, thinking about it, I don't want them to know nothing about the internet,
[00:30:35.580 --> 00:30:39.540]   but I don't want them to jump in with both feet and have all of their experiences.
[00:30:39.540 --> 00:30:41.600]   So what proportion is that?
[00:30:41.600 --> 00:30:45.460]   You know, 20% of your day on the internet, that seems reasonable, maybe.
[00:30:45.460 --> 00:30:47.980]   Many people are at 80%, 90% sometimes.
[00:30:48.420 --> 00:30:52.800]   I think it might be better to be at 5% only when you're needing it to reach out or do things.
[00:30:52.800 --> 00:30:54.120]   But I don't know the answer to that.
[00:30:54.120 --> 00:30:55.580]   We're doing this big experiment.
[00:30:55.580 --> 00:30:57.260]   But we've done these experiments before.
[00:30:57.260 --> 00:30:59.740]   We did these experiments, like you said, with television, 200 channels.
[00:30:59.740 --> 00:31:01.620]   We did this experiment with the radio.
[00:31:01.620 --> 00:31:05.080]   We did this experiment with the printing press when suddenly you could go into a library
[00:31:05.080 --> 00:31:06.280]   and just there were books everywhere.
[00:31:06.280 --> 00:31:07.860]   What would that do to people?
[00:31:07.860 --> 00:31:09.420]   And I'm generally an optimist.
[00:31:09.420 --> 00:31:10.160]   You probably already tell.
[00:31:10.160 --> 00:31:11.980]   Humanity's done pretty good so far.
[00:31:11.980 --> 00:31:17.860]   The last 100 technologies didn't end things, whether it was machine guns or nuclear war or weapons.
[00:31:17.860 --> 00:31:21.540]   So I'm cautiously optimistic, but I think we will rebalance.
[00:31:21.540 --> 00:31:23.340]   And it won't necessarily be someone telling us.
[00:31:23.340 --> 00:31:26.260]   It'll be people figuring out, I don't feel good when I use this.
[00:31:26.260 --> 00:31:33.200]   So both my son and daughter routinely mentioned to me when they turn off apps, remove, pick your social media.
[00:31:33.200 --> 00:31:34.100]   They just need a break.
[00:31:34.100 --> 00:31:40.620]   And I think that's, again, a sign that people individually have enough autonomy to figure out for themselves what's working and what's not.
[00:31:40.760 --> 00:31:44.480]   But it would be good to have a body of knowledge to reinforce that and make it feel okay.
[00:31:44.480 --> 00:31:45.600]   You're not missing out.
[00:31:45.600 --> 00:31:48.460]   You're not punished because you turned this off for a few days or weeks.
[00:31:49.160 --> 00:31:53.220]   Yeah, the algorithms punish you for turning it off for a while.
[00:31:53.220 --> 00:31:58.220]   It favors a pretty consistent cadence of posting and interaction.
[00:31:59.300 --> 00:32:06.120]   I'm very surprised that somebody had the good sense to steer parents away from buying mobiles.
[00:32:06.120 --> 00:32:07.060]   We should probably explain.
[00:32:07.060 --> 00:32:11.260]   These are like things that you hang above the baby's crib, of course, and they spin around.
[00:32:11.260 --> 00:32:13.360]   They have kind of like branches on a tree.
[00:32:13.360 --> 00:32:14.860]   They're colorful.
[00:32:14.860 --> 00:32:15.600]   They have motion.
[00:32:15.600 --> 00:32:18.300]   Babies can interact with them safely, this kind of thing.
[00:32:18.700 --> 00:32:30.980]   I'm quite surprised, pleased but surprised to hear that when the ideal mobile for getting babies to attend with just the simple faces was discovered,
[00:32:30.980 --> 00:32:37.600]   that somebody intervened and said, hey, just because they like it doesn't mean it's good for them.
[00:32:37.600 --> 00:32:44.320]   I mean, everything else in sort of a commercial industry runs exactly the opposite way until we discover it's actually harming us.
[00:32:45.140 --> 00:32:47.820]   So I'm positively surprised.
[00:32:47.820 --> 00:32:54.100]   I don't know who made that decision, but I'm relieved to hear that if you go buy a mobile now,
[00:32:54.100 --> 00:32:58.100]   it's not the one that would maximally cause the baby to attend.
[00:32:58.100 --> 00:33:01.660]   It's the one that's best for their development of the visual system.
[00:33:01.660 --> 00:33:03.720]   And I immediately think of iPads.
[00:33:03.720 --> 00:33:09.380]   I mean, you give a baby an iPad, they will just be there all day.
[00:33:09.380 --> 00:33:10.600]   And we think, oh, well, they like it.
[00:33:10.600 --> 00:33:12.260]   We sort of know it's not good for them.
[00:33:12.620 --> 00:33:15.960]   And yet it's become the digital babysitter that the television used to be.
[00:33:15.960 --> 00:33:18.080]   Now, I'm not anti-technology.
[00:33:18.080 --> 00:33:19.920]   I mean, I grew up in Silicon Valley after all.
[00:33:19.920 --> 00:33:22.160]   And I use technology, including social media.
[00:33:22.160 --> 00:33:28.340]   But I guess I'm concerned and struck by, you know, this question of where to draw the line.
[00:33:28.340 --> 00:33:31.740]   So in this instance, somebody had the good sense.
[00:33:31.740 --> 00:33:37.120]   But this is the different – I mean, the food equivalent would be – sure, I'm sure kids prefer ice cream.
[00:33:37.120 --> 00:33:40.140]   They'd eat it all day long as opposed to things that are more nutritious for them.
[00:33:40.140 --> 00:33:41.620]   But someone had to intervene.
[00:33:41.620 --> 00:33:42.340]   Yeah, yeah.
[00:33:42.340 --> 00:33:45.560]   I mean, there's a bunch of things that brings to mind.
[00:33:45.560 --> 00:33:51.280]   One is how studying the brain informs how we should use our brains.
[00:33:51.280 --> 00:33:54.300]   One idea, as you mentioned, was language – early language development.
[00:33:54.300 --> 00:33:58.620]   Allison Gopnik and other people have looked into – there's contrast in sounds that we can't hear.
[00:33:58.620 --> 00:34:00.140]   And so my kids were young.
[00:34:00.140 --> 00:34:01.800]   We said, oh, we should expose them to all those sounds.
[00:34:02.300 --> 00:34:05.740]   There's a company called Baby Einstein and they'd play, you know, Spanish or French.
[00:34:05.740 --> 00:34:12.000]   But we don't really know how much of these languages should they be exposed to.
[00:34:12.000 --> 00:34:20.180]   What is the right mix to make them better world citizens, better learners, smarter, more resistant to neurodegenerative disorders or whatever?
[00:34:20.180 --> 00:34:21.280]   We don't know the answer to that.
[00:34:21.280 --> 00:34:23.300]   So we're just running the natural experiment.
[00:34:23.300 --> 00:34:27.260]   I tell everybody that being a neuroscientist is way easier than being a parent.
[00:34:27.360 --> 00:34:29.320]   There's just too many choices and there's no control group.
[00:34:29.320 --> 00:34:33.020]   There's no way to run it again until you find out the actual answer.
[00:34:33.020 --> 00:34:42.100]   What's interesting was that it turns out exposing people passively, babies passively, to the sounds from other languages really doesn't change very much at all because there's no interaction.
[00:34:42.100 --> 00:34:53.280]   So the Chinese tones or the Swedish vowels, these different sounds, when they're not really interacting with you, when they're just on the screen, you don't pick them up.
[00:34:53.500 --> 00:34:58.460]   Which is really fascinating that your brain already knows that's a TV.
[00:34:58.460 --> 00:34:59.840]   And how does it know that?
[00:34:59.840 --> 00:35:01.840]   It knows it because your interactions with it are so limited.
[00:35:01.840 --> 00:35:08.320]   I took Spanish as a kid and they said you should watch telenovelas and learn Spanish and learn the culture and you'll pick it all up.
[00:35:08.320 --> 00:35:09.200]   You'll get the humor and the jokes.
[00:35:09.200 --> 00:35:11.980]   I didn't learn that much from it because no one was talking to me.
[00:35:11.980 --> 00:35:13.900]   I was watching passively.
[00:35:13.900 --> 00:35:23.280]   And so we now know that when you're actively engaged, you're going to have better neuroplasticity, better generalization, you're going to better connect it than when you just sit back and watch.
[00:35:23.280 --> 00:35:26.240]   Here, swiping is not exactly no interaction.
[00:35:26.240 --> 00:35:28.700]   You have some, but it's pretty impoverished, pretty limited.
[00:35:28.700 --> 00:35:31.360]   So I suspect a lot of it isn't that bad.
[00:35:31.360 --> 00:35:33.500]   It just kind of comes in one ear, goes out the other.
[00:35:33.840 --> 00:35:43.160]   But that also means those hours aren't spent doing something else, playing in the mud, getting your immune system developed, interacting with children, hitting things with a ball.
[00:35:43.160 --> 00:35:44.800]   You may aren't taking as many risks.
[00:35:44.800 --> 00:35:45.880]   Maybe that's a good thing.
[00:35:45.880 --> 00:35:48.120]   Maybe you're not getting as many head injuries as we used to get.
[00:35:48.120 --> 00:35:48.960]   Maybe that's a good thing.
[00:35:48.960 --> 00:35:51.160]   So I think we've got to take the good with the bad.
[00:35:51.300 --> 00:35:58.780]   But in general, the idea that neuroscience is accessible and that we learn that our experiences really matter, I think that's the exciting part.
[00:35:58.780 --> 00:36:01.060]   Why is ChatGPT so smart?
[00:36:01.060 --> 00:36:04.360]   We train it on every word we ever wrote, the whole species.
[00:36:04.360 --> 00:36:07.600]   And then that went into these billions of connections.
[00:36:07.600 --> 00:36:11.680]   And those billions of connections produce something that's relatively sophisticated.
[00:36:11.680 --> 00:36:13.540]   The same thing for a child.
[00:36:13.540 --> 00:36:14.220]   Here's a child.
[00:36:14.220 --> 00:36:15.820]   The experiences they have matter.
[00:36:15.820 --> 00:36:18.780]   All the kids are going to learn to walk, or almost all of them, by a year.
[00:36:18.780 --> 00:36:20.760]   But a lot of things happen during that year.
[00:36:20.760 --> 00:36:23.560]   A lot of falls, a lot of tumbles, a lot of what's, a lot of stares.
[00:36:23.560 --> 00:36:39.900]   And so I think, for me, having those, a large fraction of experiences be what I call real, having the statistics of the natural world, things that our grandparents would have recognized and been familiar, that's likely to be something that's good for your brain, both as a youth as well as a full-grown adult.
[00:36:39.900 --> 00:36:42.000]   Then you ask the question, how about at the end of life?
[00:36:42.000 --> 00:36:43.620]   At the end of life, is it now okay?
[00:36:43.620 --> 00:36:44.380]   My brain's already done.
[00:36:44.380 --> 00:36:45.740]   Can I swipe to my heart's consent?
[00:36:45.740 --> 00:36:48.160]   Can I watch Wheel of Fortune or whatever I want all day long?
[00:36:48.620 --> 00:36:52.060]   The evidence suggests it also causes depression and anxiety.
[00:36:52.060 --> 00:36:57.360]   If your day doesn't involve other people communicating, if there aren't surprises, someone knocks on the door.
[00:36:57.360 --> 00:36:58.840]   When I was a kid, people knocked on the door a lot.
[00:36:58.840 --> 00:36:59.660]   It was a big surprise.
[00:36:59.660 --> 00:37:03.740]   That's not a surprise children have that much anymore, someone just randomly knocking, because they would have texted.
[00:37:04.320 --> 00:37:07.560]   And so the surprises are now coming from the donk, I got a text.
[00:37:07.560 --> 00:37:08.920]   Oh, Bill wants to come over.
[00:37:08.920 --> 00:37:30.240]   As the population ages, many people are likely to find out that having too many experiences that are disconnected from reality, that are just a show that's made to be engaging and interesting, isn't as good as getting on a boat and driving someplace, visiting some location, getting on a bus, driving, flying, wherever it is.
[00:37:30.240 --> 00:37:36.700]   So travel gives you different experiences, you smell different smells, you hear different things, and those engage, again, those neuromodulators.
[00:37:36.700 --> 00:37:42.980]   Those neuromodulators then help make changes, because the vast majority of inputs we take in, we just throw away.
[00:37:42.980 --> 00:37:47.620]   We're not memorizing every place I ever was, every place I ever set my keys, every word everyone ever said to me.
[00:37:47.620 --> 00:37:49.380]   None of us are tape recorders.
[00:37:49.680 --> 00:37:58.480]   We're picking which moments are the moments that are useful, and that's hard to know, because we don't know what the future looks like, but we're making guesses based on what the past looks like.
[00:37:58.480 --> 00:38:08.400]   And so when the past is abnormal, robotic, exaggerated in its novelty, we make changes assuming the future is going to look like that, and the future may not be.
[00:38:08.400 --> 00:38:10.840]   The future may be a job, and it may not be this exciting.
[00:38:11.360 --> 00:38:18.800]   And it may be hard to stay focused for eight hours a day if you're used to something exciting happening every two and a half seconds, and I now have to do a job.
[00:38:18.800 --> 00:38:31.880]   For me, it's writing, where I have to sit and stay focused for hours at a time, trying to put a handful of ideas together in a way that other people don't understand, or try to develop a new treatment for someone who's suffering from a serious neurological psychiatric disorder.
[00:38:31.880 --> 00:38:33.840]   It just takes hours and hours of focus.
[00:38:34.500 --> 00:38:36.220]   And for me, fishing was helpful for that.
[00:38:36.220 --> 00:38:39.200]   Sit there with your dad, and you just fish for hours, and you go, what are you doing?
[00:38:39.200 --> 00:38:41.100]   We're not catching, we're fishing.
[00:38:41.100 --> 00:38:44.580]   It just means we have the line in the water, and there might be a fish, there might not be.
[00:38:44.580 --> 00:38:48.360]   And it may only be 1% of the time you're catching a fish.
[00:38:48.360 --> 00:38:57.840]   It might be one-tenth of a percent of the time you're catching a fish, but that's enough, because the time spent in anticipation and waiting and preparation, those were meaningful times as well.
[00:38:57.840 --> 00:39:01.260]   So I think there's a little bit of a shift toward what are the key parts.
[00:39:01.260 --> 00:39:05.840]   Is it the dopamine hit, the exciting, the novelty part, or is it all that other stuff?
[00:39:05.840 --> 00:39:09.780]   And we're now learning from the training of these networks, all of it matters.
[00:39:09.780 --> 00:39:13.700]   All of those inputs, all those syllables, all the junk words matter.
[00:39:13.700 --> 00:39:21.100]   And so I think that shift toward thinking we know what's important, the stuff we think of as important, that may not be all of it.
[00:39:21.100 --> 00:39:22.860]   All the rest probably plays an important role, too.
[00:39:22.860 --> 00:39:27.980]   I'd like to take a quick break and acknowledge our sponsor, AG1.
[00:39:28.680 --> 00:39:33.700]   AG1 is a vitamin, mineral, probiotic drink that also includes prebiotics and adaptogens.
[00:39:33.700 --> 00:39:43.720]   As somebody who's been involved in research science for almost three decades and in health and fitness for equally as long, I'm constantly looking for the best tools to improve my mental health, physical health, and performance.
[00:39:43.720 --> 00:39:50.740]   I discovered AG1 back in 2012, long before I ever had a podcast, and I've been taking it every day since.
[00:39:50.740 --> 00:39:56.520]   I find it improves all aspects of my health, my energy, my focus, and I simply feel much better when I take it.
[00:39:56.520 --> 00:40:04.000]   AG1 uses the highest quality ingredients in the right combinations, and they're constantly improving their formulas without increasing the cost.
[00:40:04.000 --> 00:40:07.220]   In fact, AG1 just launched their latest formula upgrade.
[00:40:07.260 --> 00:40:22.340]   This next-gen formula is based on exciting new research on the effects of probiotics on the gut microbiome, and it now includes several clinically studied probiotic strains shown to support both digestive health and immune system health, as well as to improve bowel regularity and to reduce bloating.
[00:40:22.740 --> 00:40:28.300]   Whenever I'm asked if I could take just one supplement, what that supplement would be, I always say AG1.
[00:40:28.300 --> 00:40:32.840]   If you'd like to try AG1, you can go to drinkag1.com slash Huberman.
[00:40:32.840 --> 00:40:40.380]   For a limited time, AG1 is giving away a free one-month supply of omega-3 fish oil, along with a bottle of vitamin D3 plus K2.
[00:40:40.380 --> 00:40:51.040]   As I've highlighted before on this podcast, omega-3 fish oil and vitamin D3 K2 have been shown to help with everything from mood and brain health, to heart health, to healthy hormone status, and much more.
[00:40:51.360 --> 00:41:00.800]   Again, that's drinkag1.com slash Huberman to get a free one-month supply of omega-3 fish oil, plus a bottle of vitamin D3 plus K2 with your subscription.
[00:41:00.800 --> 00:41:03.640]   Today's episode is also brought to us by Carbon.
[00:41:03.640 --> 00:41:07.780]   Carbon is a diet coaching app built by nutrition expert, Dr. Lane Norton.
[00:41:07.780 --> 00:41:21.180]   I've used Carbon for more than three years now, and I have to say, it's among the most powerful tools for nutrition coaching and effective weight management that I've ever encountered, especially if your goal is like mine, which is to maintain or build muscle while also losing weight.
[00:41:21.180 --> 00:41:33.020]   Now, I'm turning 50 years old this September, and even though I consider myself in pretty good shape, and I've been training for a long time and trying to eat right, one of my goals is to hit 50 in the absolute best shape of my life.
[00:41:33.020 --> 00:41:41.500]   To do that, I'm dialing in my nutrition using Carbon with the goals of increasing my muscle mass, increasing my strength, while also decreasing my body fat.
[00:41:41.740 --> 00:41:51.340]   I've been raving about the Carbon app to friends and to family and to members of my Huberman Lab team over the last few years, and everyone who's joined me in using it has found it to be tremendously useful.
[00:41:51.340 --> 00:41:57.360]   In fact, some of those people are going to join me in my approaching 50 fitness goals and body composition goals.
[00:41:57.860 --> 00:42:05.560]   My birthday is September 26th, and so I'd like to invite you to join, if you would like to improve your body composition and fitness, to also use the Carbon app.
[00:42:05.560 --> 00:42:13.000]   Now, there are a lot of apps out there that are focused on fitness and nutrition, but what makes Carbon different is that it doesn't just hand you a one-size-fits-all plan.
[00:42:13.240 --> 00:42:18.720]   It actually learns your metabolism over time, and it adapts your program based on your results.
[00:42:18.720 --> 00:42:21.700]   It also allows you total flexibility in how you eat.
[00:42:21.700 --> 00:42:27.940]   So if you're looking to take a smarter, more personalized approach to your nutrition, I can't recommend the Carbon app enough.
[00:42:27.940 --> 00:42:32.180]   To try Carbon, you can go to joincarbon.com slash Huberman.
[00:42:32.180 --> 00:42:39.400]   While Carbon does not typically offer trials or promotions, they've agreed to give a free seven-day trial to all Huberman podcast listeners.
[00:42:39.800 --> 00:42:44.540]   Again, that's joincarbon.com slash Huberman to get a seven-day free trial.
[00:42:44.540 --> 00:42:51.420]   You and I both come from lineages of neuroscientists that focus on neuroplasticity.
[00:42:51.420 --> 00:42:56.980]   My lineage through Huberman and Wiesel, we're really about the developmental plasticity piece.
[00:42:56.980 --> 00:43:02.540]   Your lineage through Mike Merzenich and others, it's really about the adult plasticity piece.
[00:43:02.540 --> 00:43:08.520]   So I'm hoping that as we move forward, you'll be willing to do a little bit of an experiment with me.
[00:43:08.900 --> 00:43:15.560]   As you were talking just now, what I realized is my real wish, not just for this conversation, but in life,
[00:43:15.560 --> 00:43:20.520]   is to come up with some real understanding of what the requirements for plasticity are
[00:43:20.520 --> 00:43:29.280]   in a way that regardless of how the world changes, AI, social media, love scuba diving, snorkeling, etc.,
[00:43:29.280 --> 00:43:33.220]   regardless of the inputs, that we can make the best informed choices.
[00:43:34.100 --> 00:43:36.980]   Understanding, of course, that not all of life is about rewiring ourselves.
[00:43:36.980 --> 00:43:38.760]   Some of life is about enjoying ourselves.
[00:43:38.760 --> 00:43:46.620]   So if I may, I'm going to just put up a couple of things on the non-existent whiteboard here to frame in people's minds.
[00:43:46.620 --> 00:43:52.200]   I think we understand just by observation for thousands of years, but also now from science,
[00:43:52.200 --> 00:43:59.000]   that from the time we're born until about 25, there's a lot of passive experience that helps reorganize the brain.
[00:43:59.220 --> 00:44:04.880]   negative experiences get kind of stamped down that can be undone through work like talk therapy
[00:44:04.880 --> 00:44:07.840]   and maybe some neural augmentation that we'll talk about later for PTSD.
[00:44:07.840 --> 00:44:09.860]   This is also true in adulthood.
[00:44:09.860 --> 00:44:16.900]   But that it's clear that there are at least two things that are required for plasticity at all stages of life.
[00:44:17.100 --> 00:44:20.080]   One is some degree of focus, right?
[00:44:20.080 --> 00:44:21.520]   Just can't be stuff in the room.
[00:44:21.520 --> 00:44:23.180]   Can't be classical music playing in the room.
[00:44:23.180 --> 00:44:28.780]   You're not going to build a Mozart or even somebody that can play even a fraction of an instrument.
[00:44:28.780 --> 00:44:31.540]   But if a kid learns an instrument, they can do it.
[00:44:31.540 --> 00:44:35.180]   If an adult really focuses and tries to learn an instrument, they can do it.
[00:44:35.180 --> 00:44:37.300]   It's just slower in adulthood in most cases.
[00:44:37.840 --> 00:44:43.560]   The other piece that I'm aware of, and tell me if I'm off here, is sleep is required.
[00:44:43.560 --> 00:44:47.640]   A lot of the rewiring of neural connections actually occurs during rapid eye movement sleep and deep sleep.
[00:44:47.640 --> 00:44:50.900]   You can't just focus and just work infinitum.
[00:44:50.900 --> 00:44:52.120]   You need sleep.
[00:44:52.120 --> 00:44:53.640]   You need rest for the rewiring to occur.
[00:44:53.640 --> 00:44:58.500]   But as you're telling me about these experiments, and by the way, I was not aware of this experiment
[00:44:58.500 --> 00:45:02.960]   that kids will attend more to a kind of a cartoon face than to a real face.
[00:45:02.960 --> 00:45:04.000]   I was not aware of that.
[00:45:04.000 --> 00:45:09.700]   As you're telling me about that, or fishing, or we're talking about music learning, or language learning,
[00:45:09.700 --> 00:45:15.220]   I believe the best way to learn a language is to place yourself into an environment where it's critical that you learn it.
[00:45:15.220 --> 00:45:19.960]   Like go to a foreign country, and if you need to learn how to navigate by virtue of understanding
[00:45:19.960 --> 00:45:23.440]   and speaking some remnants of that language, you're going to learn it much more quickly
[00:45:23.440 --> 00:45:26.560]   than sitting in Spanish class back in the United States.
[00:45:27.980 --> 00:45:34.900]   I'm wondering if in my mental model of how to change one's brain, that in addition to focus,
[00:45:34.900 --> 00:45:40.860]   which requires alertness, right, in addition to focus and periods of sleep for the rewiring
[00:45:40.860 --> 00:45:45.480]   to occur, maybe I can, if you have a better word, let me know.
[00:45:45.480 --> 00:45:51.540]   But I want to introduce this, an element of friction, that there needs to be focus and friction, right?
[00:45:51.540 --> 00:45:56.240]   Because with the kid looking at the face, the cartoon face, there's focus, but there's no friction
[00:45:56.240 --> 00:45:56.820]   to get there.
[00:45:57.340 --> 00:46:00.580]   With friction, like there's some element of self-generated work.
[00:46:00.580 --> 00:46:04.300]   Like with the snorkeling, you have to get wet, you have to go under the water,
[00:46:04.300 --> 00:46:05.200]   you have to put the mask on.
[00:46:05.200 --> 00:46:07.600]   It's kind of weird to breathe through a snorkel the first time you do it.
[00:46:07.600 --> 00:46:08.340]   It's kind of uncomfortable.
[00:46:08.340 --> 00:46:13.160]   There are a bunch of things that go with it that make that experience so much more enriching
[00:46:13.160 --> 00:46:14.840]   in terms of how it rewires the brain.
[00:46:15.260 --> 00:46:21.960]   And traumatic events, unfortunately, engage focus and friction.
[00:46:21.960 --> 00:46:23.220]   So it meets this requirement.
[00:46:23.220 --> 00:46:27.100]   So I'm trying to come up with a table here, and as scientists, we should try and disprove
[00:46:27.100 --> 00:46:29.060]   what we're putting up, right?
[00:46:29.060 --> 00:46:35.400]   But I feel like what one wants is just enough friction, a lot of focus, and then a period
[00:46:35.400 --> 00:46:37.400]   of rest in order for plasticity to occur.
[00:46:38.020 --> 00:46:42.720]   And maybe in a video game, there isn't enough friction.
[00:46:42.720 --> 00:46:49.920]   Your daughter being involved in, very interested rather, in real-world human experiences, it's
[00:46:49.920 --> 00:46:51.020]   a pseudo-random walk.
[00:46:51.020 --> 00:46:54.520]   I mean, there's some regularities about how humans interact, but it's kind of a near-infinite
[00:46:54.520 --> 00:46:54.960]   space.
[00:46:54.960 --> 00:46:58.760]   And it certainly is valuable to have social, emotional intelligence.
[00:46:58.760 --> 00:46:59.520]   We know this.
[00:46:59.720 --> 00:47:05.280]   So what are your thoughts about needing to work in addition to focus in order to get
[00:47:05.280 --> 00:47:06.080]   meaningful?
[00:47:06.080 --> 00:47:10.180]   And when I say meaningful, I mean really adaptive plasticity, stuff that makes us smarter, makes
[00:47:10.180 --> 00:47:12.220]   us better people, makes us feel more fulfilled.
[00:47:12.220 --> 00:47:15.380]   I mean, it's not all about test scores.
[00:47:15.380 --> 00:47:22.040]   But a really good life is one in which you feel like the things you're doing have meaning.
[00:47:22.040 --> 00:47:26.360]   You don't look back on the past year and go, yeah, that was just a bunch of schmooey experiences.
[00:47:26.360 --> 00:47:27.320]   Yeah.
[00:47:27.320 --> 00:47:31.240]   I mean, to start on the part you ended on, I mean, I really think reflection on these
[00:47:31.240 --> 00:47:35.460]   topics, this is another one that was a big surprise, is that thinking about it later also
[00:47:35.460 --> 00:47:38.240]   rewires your brain, not just the sleeping part when you're clearly thinking about it
[00:47:38.240 --> 00:47:38.900]   and turning it over in your mind.
[00:47:38.900 --> 00:47:39.480]   That's a very good point.
[00:47:39.480 --> 00:47:45.180]   But as you're on the way home from the game, as you're planning to drive to the game or the
[00:47:45.180 --> 00:47:51.260]   date or the business appointment or whatever it might be, that idea that it's not this
[00:47:51.260 --> 00:47:54.060]   all the learning doesn't happen at this one moment, but there was some preparation that
[00:47:54.060 --> 00:47:54.640]   went into it.
[00:47:54.920 --> 00:47:58.280]   There was the actual event, which often has the friction you're describing, whether some
[00:47:58.280 --> 00:48:03.660]   engagement and decisions are being made, where there's information being transmitted and
[00:48:03.660 --> 00:48:04.780]   information being gained.
[00:48:04.780 --> 00:48:08.540]   And then this period of reflection where you're wondering about it, you're thinking about
[00:48:08.540 --> 00:48:14.140]   for me often looking back over my pictures, either having a child or going on vacation
[00:48:14.140 --> 00:48:16.440]   is helpful in reorganizing it and reframing it.
[00:48:16.440 --> 00:48:18.140]   For me, those are helpful things to do.
[00:48:18.140 --> 00:48:22.000]   But the idea that this is all happening at one snapshot, that's how we used to think of
[00:48:22.000 --> 00:48:25.360]   it. We used to think of it as light bulbs went off, you memorize the picture and you're
[00:48:25.360 --> 00:48:30.740]   done. But that's not how any of the ideas, it's not how math is viewed, it's not how language
[00:48:30.740 --> 00:48:34.320]   is organized in our brain, it's a series of these memorization events.
[00:48:34.320 --> 00:48:36.280]   We're trying to make use of it.
[00:48:36.280 --> 00:48:40.120]   And what's going to be useful is hard to anticipate, hard to predict.
[00:48:40.680 --> 00:48:44.260]   So I like to think of it sort of from an information point of view, how many bits of information?
[00:48:44.260 --> 00:48:46.120]   So a bit of information is just a yes or a no.
[00:48:46.120 --> 00:48:49.880]   And we now live in a world where a floppy drive doesn't have a kilobit.
[00:48:49.880 --> 00:48:51.280]   You know, you're not a megabit.
[00:48:51.280 --> 00:48:54.600]   Some of you won't even know what a floppy drive is, but we're dating ourselves.
[00:48:54.600 --> 00:48:57.960]   Yeah, you could get gigabits, you can get terabits.
[00:48:57.960 --> 00:49:00.780]   So we're talking about billions, trillions of bits.
[00:49:00.780 --> 00:49:04.800]   And you wonder how much did you learn when you were going up to the plate and you were going
[00:49:04.800 --> 00:49:05.200]   to hit the ball?
[00:49:05.200 --> 00:49:10.920]   Well, there's this pitcher makes a particular look when he's going to give a slider.
[00:49:10.920 --> 00:49:15.180]   This person gives a particular glint in their eye when they're about to say something mean.
[00:49:15.180 --> 00:49:19.960]   Each way you watch that person is giving information about what's happening in the future.
[00:49:19.960 --> 00:49:23.680]   But you have to be there and you have to see that person having that experience.
[00:49:23.680 --> 00:49:30.480]   Now, as the ball is traveling down to you, or as the person is about to, you know, pull the
[00:49:30.480 --> 00:49:36.300]   ball away from you in the Charlie Brown analogy, or whatever the experience is, having that
[00:49:36.300 --> 00:49:39.100]   sequence of events, you have a prediction.
[00:49:39.100 --> 00:49:41.800]   It's pretty low reliability that this is going to be a slider.
[00:49:41.800 --> 00:49:44.760]   Then I start to see, hey, it looks like a slider.
[00:49:44.760 --> 00:49:46.360]   Then I swing at it and I miss.
[00:49:46.360 --> 00:49:47.360]   And I say, that was a slider.
[00:49:47.360 --> 00:49:48.460]   I missed that one.
[00:49:48.460 --> 00:49:51.200]   Then I think about it at the end of the day and I go back.
[00:49:51.200 --> 00:49:53.100]   And for many of us, you dream about it.
[00:49:53.100 --> 00:49:55.200]   What is all that about?
[00:49:55.920 --> 00:50:01.180]   My original interest in neuroplasticity actually came because something happened to me, not
[00:50:01.180 --> 00:50:02.260]   something I chose to happen.
[00:50:02.260 --> 00:50:11.480]   I worked in a lab in college squeezing the salivary glands of Drosophila.
[00:50:11.480 --> 00:50:13.700]   So the little maggots and the fruit flies.
[00:50:13.700 --> 00:50:19.500]   If you squeeze them, they have these banded patterns, which were all their DNA and their
[00:50:19.500 --> 00:50:22.800]   chromatin, their organization of the DNA is organized.
[00:50:22.800 --> 00:50:26.220]   And my job was to look and find, it looked like barcodes.
[00:50:26.220 --> 00:50:29.160]   So it would be a thick line, thick line, thin line, thin line, thick line, thick line.
[00:50:29.160 --> 00:50:30.060]   Wait, in the saliva?
[00:50:30.060 --> 00:50:31.940]   It's actually in the cells.
[00:50:31.940 --> 00:50:35.180]   It's a syncytion.
[00:50:35.180 --> 00:50:38.400]   So about 900 cells all fused together to make one cell.
[00:50:38.400 --> 00:50:40.240]   All the DNA then aligns.
[00:50:40.240 --> 00:50:44.040]   And when you stain it, this is in Ron Davis's lab at Baylor College of Medicine.
[00:50:44.040 --> 00:50:47.680]   But when I closed my eyes, I didn't see what I normally saw.
[00:50:47.680 --> 00:50:52.040]   What I saw were these bands because I'd been staring every day at these patterns.
[00:50:52.040 --> 00:50:56.560]   And that happened to me several more times when I spent a lot of time with that focus
[00:50:56.560 --> 00:50:57.960]   and that friction you're talking about.
[00:50:57.960 --> 00:51:00.600]   Suddenly, you start thinking about it differently.
[00:51:00.600 --> 00:51:02.980]   I had a conversation with a young man a few days ago.
[00:51:02.980 --> 00:51:07.320]   His native language is Spanish, but he told me, I think my native language is English because
[00:51:07.320 --> 00:51:08.160]   I only think in English.
[00:51:08.160 --> 00:51:10.060]   And when I talk to my mom, I have to translate.
[00:51:10.060 --> 00:51:14.500]   And they told me when I took Spanish, you'd eventually dream in Spanish.
[00:51:14.500 --> 00:51:17.300]   And I did a few times, but I never quite got good enough.
[00:51:17.460 --> 00:51:22.960]   So that idea that when you have a really significant experience, you can close your eyes and see
[00:51:22.960 --> 00:51:23.120]   it.
[00:51:23.120 --> 00:51:28.620]   I believe that baseball pitchers are seeing the balls being thrown, the signs being given.
[00:51:28.620 --> 00:51:32.520]   I believe that someone who's playing violin really well or a neuroscientist who's doing
[00:51:32.520 --> 00:51:34.280]   surgery, they see those things.
[00:51:34.280 --> 00:51:35.760]   And that's a repetition.
[00:51:36.440 --> 00:51:40.020]   We now know from Olympic skiers that if you do all your time skiing, you're going to
[00:51:40.020 --> 00:51:40.400]   wreck your knees.
[00:51:40.400 --> 00:51:42.480]   So they spend a lot of time in visualization.
[00:51:42.480 --> 00:51:47.340]   They spend a lot of time imagining what's going on, stepping through the motions because
[00:51:47.340 --> 00:51:50.180]   it's too dangerous to go down the hill at that speed too many times.
[00:51:50.180 --> 00:51:51.880]   You'll eventually wreck your knees or break your back.
[00:51:51.880 --> 00:51:54.840]   But practicing it can be done offline.
[00:51:54.840 --> 00:51:57.020]   And that practicing, the neurons don't know.
[00:51:57.780 --> 00:52:01.680]   So long as you're engaged, as long as you're modified by it, that's sufficient.
[00:52:01.680 --> 00:52:03.320]   The problem is you're not learning anything new.
[00:52:03.320 --> 00:52:07.040]   If you're just visualizing it, where's the feedback from the world?
[00:52:07.040 --> 00:52:07.520]   There's not.
[00:52:07.520 --> 00:52:08.960]   But you get the repetitions.
[00:52:08.960 --> 00:52:13.740]   And so that idea that we can combine, and again, many, many traditions for thousands of
[00:52:13.740 --> 00:52:15.580]   years have had these kinds of notions.
[00:52:15.580 --> 00:52:18.720]   You should go back and repeat these aspects to us.
[00:52:18.720 --> 00:52:19.800]   We need that extra benefit.
[00:52:19.800 --> 00:52:21.080]   Certainly that we should sleep.
[00:52:21.080 --> 00:52:22.600]   There are no cultures that say don't sleep.
[00:52:23.320 --> 00:52:25.480]   These are well-received, good ideas.
[00:52:25.480 --> 00:52:27.760]   We're now learning, how does that work?
[00:52:27.760 --> 00:52:31.240]   And I'm personally excited about the idea that it's about the connections.
[00:52:31.240 --> 00:52:34.240]   We had this idea from thousands of years ago.
[00:52:34.240 --> 00:52:37.960]   Four or five things that could be in balance or out of balance.
[00:52:37.960 --> 00:52:42.800]   They were famously blood, phlegm, black bile, and yellow bile.
[00:52:42.800 --> 00:52:44.200]   And they could be in different levels.
[00:52:44.200 --> 00:52:45.600]   And the levels were all that were needed.
[00:52:45.600 --> 00:52:47.380]   And that made a lot of categories.
[00:52:47.380 --> 00:52:51.540]   Because with four things at several different levels, you can make lots of categories.
[00:52:51.900 --> 00:52:53.580]   The Myers-Briggs personality test.
[00:52:53.580 --> 00:52:56.440]   You take a few dimensions, and you can kind of explain anything.
[00:52:56.440 --> 00:53:03.560]   But whether that's really how we work, where we really are too much blood, too much bile,
[00:53:03.560 --> 00:53:07.900]   too much phlegm, or even too much serotonin, too much norepinephrine, too much dopamine.
[00:53:07.900 --> 00:53:09.660]   Maybe there's more to us.
[00:53:09.660 --> 00:53:12.040]   Well, what could it be besides that?
[00:53:12.040 --> 00:53:19.920]   And the answer is, I think the experiments from our forefathers, Ramonica Hall, Emilio Golgi,
[00:53:19.920 --> 00:53:21.320]   said, it's the connections.
[00:53:21.320 --> 00:53:23.900]   And we went, what do you mean connections?
[00:53:23.900 --> 00:53:25.200]   What would the connections do?
[00:53:25.200 --> 00:53:31.680]   And now we know from some beautiful studies come out recently, it's 150 trillion of these things
[00:53:31.680 --> 00:53:35.280]   inside my brain, inside your brain, inside each of our listeners' brains.
[00:53:35.280 --> 00:53:37.660]   And how did they get to be the way they are?
[00:53:37.660 --> 00:53:39.560]   Did the genes make them?
[00:53:39.560 --> 00:53:40.580]   The genes?
[00:53:40.580 --> 00:53:43.120]   There's only 3 billion base pairs in the genes.
[00:53:43.120 --> 00:53:44.580]   Not nearly enough.
[00:53:45.540 --> 00:53:47.360]   We only have 20,000 proteins.
[00:53:47.360 --> 00:53:50.100]   How could 20,000 make 150 trillion?
[00:53:50.100 --> 00:53:51.200]   They couldn't.
[00:53:51.200 --> 00:53:52.280]   Genes are critical.
[00:53:52.280 --> 00:53:53.620]   They set us up to learn.
[00:53:53.620 --> 00:53:57.320]   But they're not enough to tell us how we work.
[00:53:57.320 --> 00:53:58.900]   And I think that's true.
[00:53:58.900 --> 00:54:01.600]   But the genes are interacting with our experiences.
[00:54:01.600 --> 00:54:04.760]   As we listen, as we hear, our brain is being rewired.
[00:54:04.760 --> 00:54:09.680]   Whether it's for Japanese or English or Swedish, whatever it might be, our brains can learn anything.
[00:54:10.000 --> 00:54:10.900]   We can fly the space shuttle.
[00:54:10.900 --> 00:54:12.240]   You and I can fly the space shuttle.
[00:54:12.240 --> 00:54:13.060]   We can do brain surgery.
[00:54:13.060 --> 00:54:13.740]   All of us can.
[00:54:13.740 --> 00:54:15.140]   It just takes practice.
[00:54:15.140 --> 00:54:18.780]   That's the miraculous nature of the way our neurons work.
[00:54:18.780 --> 00:54:23.660]   And what's surprising to me is I think we're close to figuring it out.
[00:54:23.660 --> 00:54:25.380]   How do the neurons work?
[00:54:25.380 --> 00:54:28.680]   1949, this guy Donald Hebb said, fire together, wire together.
[00:54:28.680 --> 00:54:29.160]   That's it.
[00:54:29.160 --> 00:54:32.140]   A lot of us went, does that make any sense?
[00:54:32.140 --> 00:54:35.920]   If all of the neurons who fired all wired together, wouldn't everything just fire together
[00:54:35.920 --> 00:54:37.380]   and everything just wire together and you'd have a seizure?
[00:54:37.380 --> 00:54:39.520]   And the answer is that's exactly what happens.
[00:54:39.520 --> 00:54:45.440]   So his intuition, though, partly right, that the covariance, the co-occurring of these events
[00:54:45.440 --> 00:54:47.900]   is an important aspect of learning.
[00:54:47.900 --> 00:54:49.000]   It's not so simple.
[00:54:49.000 --> 00:54:53.460]   We found out that the neuron that fires a little late, they both fire together, but the neuron
[00:54:53.460 --> 00:54:58.020]   that fires a little bit late, instead of long-term potentiation, strengthening the connection,
[00:54:58.020 --> 00:55:00.500]   we get long-term depression, weakening.
[00:55:00.500 --> 00:55:02.280]   We've been working on the brain 100 years.
[00:55:02.280 --> 00:55:04.400]   We really only figured this out about 25 years ago.
[00:55:05.360 --> 00:55:11.020]   And then the fact that none of that happens, no firing together, wiring together, no out-of-sync,
[00:55:11.020 --> 00:55:14.720]   fail-to-link, none of that happens if the neuromodulators don't arrive.
[00:55:14.720 --> 00:55:18.120]   And the neuromodulators arrive a couple seconds later.
[00:55:18.120 --> 00:55:22.700]   So the timing, whether to strengthen or weaken, is a millisecond, a thousandth of a second.
[00:55:22.700 --> 00:55:24.560]   It says, strong or weak?
[00:55:24.560 --> 00:55:25.680]   Which way should I go with it?
[00:55:26.160 --> 00:55:30.860]   And then I've got this two-second window that says sometime within a couple seconds, did it work?
[00:55:30.860 --> 00:55:32.360]   Was that a win or a loss?
[00:55:32.360 --> 00:55:36.520]   And if nothing happens, if it just wasn't important at all, then it all just gets flushed.
[00:55:36.520 --> 00:55:38.140]   In one ear, out the other, you just forget it.
[00:55:38.140 --> 00:55:42.800]   But when something exciting happens, you get release of acetylcholine, norepinephrine.
[00:55:42.800 --> 00:55:44.520]   These things go into the brain.
[00:55:44.520 --> 00:55:46.040]   They bind to receptors.
[00:55:46.040 --> 00:55:48.340]   They change what's happening inside the cell.
[00:55:48.700 --> 00:55:51.840]   And that computation is really sophisticated.
[00:55:51.840 --> 00:55:55.980]   And we don't have 100 billion things making that computation.
[00:55:55.980 --> 00:55:59.240]   We have 1,000 trillion running that computation.
[00:55:59.240 --> 00:56:05.920]   And that computation is much more sophisticated than the computation that's happening when you train a large language network.
[00:56:05.920 --> 00:56:10.680]   Most of your listeners will have heard of artificial intelligence, machine learning, have some basic idea.
[00:56:10.680 --> 00:56:13.140]   But we know how that works because we built it.
[00:56:13.140 --> 00:56:14.960]   And it doesn't work how you and I work.
[00:56:14.960 --> 00:56:17.800]   It's a big, giant, global learning signal.
[00:56:18.000 --> 00:56:19.780]   And we just keep running around, feeding it back in.
[00:56:19.780 --> 00:56:21.700]   And everybody learns this is the right answer.
[00:56:21.700 --> 00:56:23.280]   And it threads through the entire network.
[00:56:23.280 --> 00:56:26.860]   Right and wrong is told to every single network, neuron in the network.
[00:56:26.860 --> 00:56:28.720]   It's something called gradient descent.
[00:56:28.720 --> 00:56:34.200]   And that process of improving the network, making it better and better and better at predicting,
[00:56:34.200 --> 00:56:37.560]   has led to the revolution we've seen in artificial intelligence.
[00:56:37.560 --> 00:56:39.980]   What's cool is that our network is cooler.
[00:56:39.980 --> 00:56:40.960]   It's way bigger.
[00:56:40.960 --> 00:56:44.160]   ChatGPT is 540 billion weights.
[00:56:44.160 --> 00:56:46.160]   We're 150 trillion.
[00:56:46.580 --> 00:56:52.000]   So that makes us 500 times, each of us, 500 times bigger in scale.
[00:56:52.740 --> 00:56:56.640]   And instead of requiring huge amounts of energy, a light bulb is all it takes.
[00:56:56.640 --> 00:56:57.880]   Eat a hamburger a day.
[00:56:57.880 --> 00:56:58.840]   You have plenty of food.
[00:56:58.840 --> 00:57:01.000]   You can learn all day long with that amount of energy.
[00:57:01.000 --> 00:57:02.300]   It's not that much energy in a hamburger.
[00:57:02.300 --> 00:57:05.120]   And that's miraculous.
[00:57:05.120 --> 00:57:10.520]   And so I think there's a lot of worry that when we learn about the brain, it will devalue humanity.
[00:57:10.520 --> 00:57:11.900]   We'll be less impressive.
[00:57:11.900 --> 00:57:12.740]   We'll be less exciting.
[00:57:12.740 --> 00:57:14.300]   I've just seen the opposite my whole career.
[00:57:14.720 --> 00:57:17.560]   If we were just genes, then you'd have eugenics.
[00:57:17.560 --> 00:57:18.500]   You'd have all these problems.
[00:57:18.500 --> 00:57:20.740]   You'd have people who are valued based on whether their genes are right or wrong.
[00:57:20.740 --> 00:57:23.500]   It turns out the 20,000 genes doesn't explain us.
[00:57:23.500 --> 00:57:26.420]   The hundreds of cell types don't explain us.
[00:57:26.420 --> 00:57:28.020]   It's the synapses.
[00:57:28.020 --> 00:57:31.820]   I think for a long time we were hoping there'd be an easy fix.
[00:57:31.820 --> 00:57:34.400]   If someone had a problem, it'd be nice.
[00:57:34.460 --> 00:57:38.260]   If they just had too much blood, we can give them some leeches, drain the blood out, they'd be back to good, right?
[00:57:38.260 --> 00:57:39.220]   So George Washington died.
[00:57:39.220 --> 00:57:44.600]   But now we're learning most people don't have four or five things that are right or wrong.
[00:57:44.600 --> 00:57:45.600]   They've got billions.
[00:57:45.600 --> 00:57:48.580]   But they're all changeable at any stage in life.
[00:57:48.580 --> 00:57:49.340]   They get really hard.
[00:57:49.340 --> 00:57:53.620]   Don't disagree to lose an accident, for example, or to get over a traumatic event.
[00:57:53.620 --> 00:57:55.060]   It could be really difficult.
[00:57:55.060 --> 00:57:59.060]   But the fact is the brain is plastic until the very day you die.
[00:57:59.740 --> 00:58:04.760]   And that ability now to get our head around what do billions of connections mean?
[00:58:04.760 --> 00:58:06.580]   What is all this information for?
[00:58:06.580 --> 00:58:11.800]   It's informing me, not just to make us better to beat someone else on a test or anything else like that,
[00:58:11.800 --> 00:58:13.340]   but it's just part of who I am.
[00:58:13.340 --> 00:58:15.680]   When I look at a cloud, I've never seen that cloud before.
[00:58:15.680 --> 00:58:21.200]   When I hear a baby coo or a pet a cat, all those experiences are really information rich.
[00:58:21.200 --> 00:58:22.780]   Different cats feel different.
[00:58:22.780 --> 00:58:23.860]   Different clouds look different.
[00:58:23.860 --> 00:58:25.680]   Different babies make different sounds.
[00:58:25.680 --> 00:58:29.460]   And the fact that I get my unique experience, you get your unique experience,
[00:58:29.460 --> 00:58:34.820]   is what our great, great, great, great grandfathers told us, that we were unique and special.
[00:58:34.820 --> 00:58:37.500]   And then a lot of people looked at the clockwork universe and said,
[00:58:37.500 --> 00:58:39.180]   no, no, no, it's all very deterministic.
[00:58:39.180 --> 00:58:40.340]   It's all very fixed.
[00:58:40.340 --> 00:58:41.180]   It's all very rigid.
[00:58:41.180 --> 00:58:42.900]   You're just a machine that does what it's told.
[00:58:42.900 --> 00:58:45.060]   It doesn't really seem right.
[00:58:45.060 --> 00:58:49.740]   The math guys now tell us as soon as you put three things together in a nonlinear way,
[00:58:49.740 --> 00:58:51.040]   it's hard to predict what it's going to do.
[00:58:51.840 --> 00:58:56.160]   And the computer scientists in the world, my brother's one of them, have finally admitted,
[00:58:56.160 --> 00:58:58.040]   we don't fully understand what it's doing.
[00:58:58.040 --> 00:59:00.000]   We don't even know how you could understand it.
[00:59:00.000 --> 00:59:01.240]   It's so rich and complicated.
[00:59:01.240 --> 00:59:02.760]   And we're now OK with that.
[00:59:02.760 --> 00:59:08.460]   That kind of humility about what computers are doing and how they're working can reflect back
[00:59:08.460 --> 00:59:12.120]   on our own bodies where I don't know exactly why I make every decision.
[00:59:12.120 --> 00:59:13.160]   I say lots of things I regret.
[00:59:13.160 --> 00:59:14.140]   No, we shouldn't have said that.
[00:59:14.140 --> 00:59:15.260]   All of us do.
[00:59:16.100 --> 00:59:19.660]   But the idea that I can change it and I can make amends for that, I can say that wasn't
[00:59:19.660 --> 00:59:20.260]   what I meant to say.
[00:59:20.260 --> 00:59:21.220]   I apologize for that.
[00:59:21.220 --> 00:59:24.820]   That's really exciting that there's a biological basis for it.
[00:59:24.820 --> 00:59:31.600]   And it's this four-factor learning rule where there's some proteins, receptors that are having
[00:59:31.600 --> 00:59:36.240]   binding of glutamate, serotonin, and norepinephrine, all these words you've talked about before,
[00:59:36.240 --> 00:59:37.660]   but they add up to something.
[00:59:37.660 --> 00:59:39.420]   They don't eliminate me.
[00:59:39.420 --> 00:59:40.280]   They add up to me.
[00:59:40.280 --> 00:59:42.220]   I think that's something we can really be proud of.
[00:59:42.300 --> 00:59:47.120]   And I think you're getting this information out to audiences is really exciting because
[00:59:47.120 --> 00:59:48.400]   people have the right to know this.
[00:59:48.400 --> 00:59:50.200]   Taxpayer money paid for all this knowledge.
[00:59:50.200 --> 00:59:51.240]   We've learned all this stuff.
[00:59:51.240 --> 00:59:55.580]   And it has real implications, whether it's for how we treat people with disability, how
[00:59:55.580 --> 00:59:58.620]   we treat our elders, how we treat people who've committed crimes.
[00:59:58.620 --> 01:00:02.260]   All these things have implications.
[01:00:02.260 --> 01:00:06.200]   And I'm not saying everyone needs to become a neuroscientist by any means, but it's not
[01:00:06.200 --> 01:00:07.040]   just a curiosity.
[01:00:07.040 --> 01:00:10.320]   It's not just a laboratory trick we wanted to work out.
[01:00:10.660 --> 01:00:12.260]   This understanding has implications.
[01:00:12.260 --> 01:00:17.420]   And we've been building, as our forefathers did in other fields, physics and all the rest,
[01:00:17.420 --> 01:00:20.140]   they've built all the way where their model of physics is pretty good.
[01:00:20.140 --> 01:00:22.480]   Our model of the brain is not there yet.
[01:00:22.480 --> 01:00:25.180]   We're not at that level of understanding everything.
[01:00:25.180 --> 01:00:30.420]   But moving in that direction toward eventually being able to find some child or some older person
[01:00:30.420 --> 01:00:31.280]   who's got a real problem.
[01:00:31.280 --> 01:00:32.940]   They just can't do it.
[01:00:33.500 --> 01:00:39.100]   We can switch from a mode of just labeling them, diagnose and adios, to a new mode of
[01:00:39.100 --> 01:00:40.280]   how can we assist you?
[01:00:40.280 --> 01:00:45.980]   And it might be changing lifestyles, changing diet, changing experiences, changing rhythms,
[01:00:45.980 --> 01:00:46.720]   changing friendships.
[01:00:47.140 --> 01:00:50.360]   But it might also be, in some cases, there's a real problem.
[01:00:50.360 --> 01:00:53.300]   Dopamine cells in the substantia nigra have died.
[01:00:53.300 --> 01:00:54.300]   We're going to need to make this change.
[01:00:54.300 --> 01:00:56.300]   We need to put a stimulating electrode in.
[01:00:56.300 --> 01:00:59.180]   Or if the hair cells in your ears all die, you can't hear.
[01:00:59.180 --> 01:01:00.640]   We now know why that is.
[01:01:00.640 --> 01:01:01.960]   They're not punished by God.
[01:01:01.960 --> 01:01:06.320]   They can't hear because the little vibrations in the air that we can't see aren't getting
[01:01:06.320 --> 01:01:06.940]   into their brain.
[01:01:07.620 --> 01:01:12.120]   So we take a cochlear implant, we take a microphone, we record the vibrations, we put it into the
[01:01:12.120 --> 01:01:15.480]   brain in the right way, and now many people can hear.
[01:01:15.480 --> 01:01:17.580]   That was a miracle not too long ago.
[01:01:17.580 --> 01:01:19.260]   Now it's a technology you can just go by.
[01:01:19.260 --> 01:01:24.640]   And moving that progress of neuroscientists, some things like schizophrenia, we've made very
[01:01:24.640 --> 01:01:25.100]   little progress.
[01:01:25.100 --> 01:01:26.440]   It's very hard to figure out what we do.
[01:01:26.440 --> 01:01:28.740]   But at least we understand the nature of the disease.
[01:01:28.740 --> 01:01:31.680]   It's not that they've got a germ or a bacteria or a virus.
[01:01:31.680 --> 01:01:34.760]   It's not that their one gene is big and bad and broken.
[01:01:34.760 --> 01:01:35.580]   It's not contagious.
[01:01:36.020 --> 01:01:40.920]   But there's some wiring challenges and that most days someone with schizophrenia is perfectly
[01:01:40.920 --> 01:01:41.220]   normal.
[01:01:41.220 --> 01:01:45.280]   Most people with neurological and psychiatric disorders spend large periods of time normal
[01:01:45.280 --> 01:01:48.560]   between periods of migraines or depression.
[01:01:48.560 --> 01:01:50.300]   They are acting totally reasonable.
[01:01:50.300 --> 01:01:55.620]   And we want to spend more time, push them more toward those times of health and satisfaction
[01:01:55.620 --> 01:02:00.200]   and reward and away from those times of disability, engagement, limitations.
[01:02:00.200 --> 01:02:03.920]   And I think we're moving in that direction instead of labeling and putting people off in homes,
[01:02:04.420 --> 01:02:07.080]   more to engaging, understanding, and then eventually intervening.
[01:02:07.080 --> 01:02:10.640]   I agree that progress is happening fast.
[01:02:10.640 --> 01:02:16.900]   And while sometimes it might seem that we're not moving in the right direction, I think neuroscience
[01:02:16.900 --> 01:02:20.320]   in particular is striving very hard.
[01:02:20.320 --> 01:02:30.880]   I say in particular because other fields like immunology in particular and physics have experienced great advances as you've pointed out before over the previous 100 years.
[01:02:30.880 --> 01:02:39.720]   Whereas, you know, anytime there's been a pathogen that we've wanted to deal with and humans have put a lot of time and energy toward it, done a pretty good job of dealing with that pathogen.
[01:02:39.720 --> 01:02:44.820]   The same can't be said for neurologic diseases like Alzheimer's.
[01:02:44.820 --> 01:02:48.980]   I mean, progress is coming, but it's been much more slow and we don't have cures.
[01:02:48.980 --> 01:02:50.240]   We don't have pure solutions.
[01:02:51.600 --> 01:03:06.700]   I want to get into the neuromodulators in some degree of depth as it relates to neuroplasticity and certainly the incredible work that you're doing with devices, vagal nerve stimulation and so forth for treatment of everything from PTSD to tinnitus.
[01:03:07.120 --> 01:03:10.420]   You have a beautiful paper that came out recently in Nature, congratulations.
[01:03:10.420 --> 01:03:17.620]   We'll provide a link to that paper as well as some of the others related to restoration of motor function for people that have restricted motor function for various reasons.
[01:03:17.620 --> 01:03:29.540]   Before I do that, I can't help but raise once again this sort of mental model of plasticity that I'm trying to build out as we go along here, whereby focus and friction seem to be prerequisites.
[01:03:29.540 --> 01:03:30.800]   I mentioned sleep.
[01:03:30.800 --> 01:03:32.060]   You added to that reflection.
[01:03:32.280 --> 01:03:43.260]   And I just really want to underscore that and certainly add it to this list that I'm building here because about six months ago I did an episode on how best to study and learn.
[01:03:43.260 --> 01:03:44.860]   I went into the literature.
[01:03:44.860 --> 01:03:51.280]   I know what my study habits and tools are and what I've used over the years, but I went to the literature, the peer-reviewed literature.
[01:03:51.280 --> 01:04:03.180]   And there were a number of takeaways, but perhaps the most salient one was that students who self-test learn much faster and the information they learn is much more durable over time.
[01:04:03.180 --> 01:04:06.120]   They forget a lot less of it than any other method.
[01:04:06.120 --> 01:04:11.320]   So tests are not just a way for others to evaluate us but for us to evaluate ourselves.
[01:04:12.120 --> 01:04:25.500]   And it created a whole different picture of learning and memory for me because a simple statement made by a psychologist, not a neuroscientist, was when something like, you know, self-testing protects against – it's anti-forgetting.
[01:04:25.920 --> 01:04:29.780]   And most of learning is just intervening in the forgetting process.
[01:04:29.780 --> 01:04:37.840]   Just like there are a number of stimuli in this particular interaction that unfortunately I will forget or fortunately perhaps the irrelevant stimuli I won't remember.
[01:04:37.840 --> 01:04:42.240]   And so, so much of what we learn is really about what we don't forget.
[01:04:42.240 --> 01:04:47.620]   It might seem like a trivial distinction to kind of flip it that way, but self-testing being key.
[01:04:47.660 --> 01:04:51.600]   And I think this element of reflection and a mental rehearsal is so key.
[01:04:51.600 --> 01:05:11.160]   I think, again, I don't want to demonize social media, but I think that one of the downsides of smartphones and social media is that after we leave a lecture or a movie or a social interaction, in the past, prior to 2010, say, the tendency was to walk to one's car, drive home, maybe think about that interaction.
[01:05:11.160 --> 01:05:12.740]   Think about what was good.
[01:05:12.740 --> 01:05:13.540]   Think about what was bad.
[01:05:13.540 --> 01:05:15.440]   Maybe let it kind of stew in us a bit.
[01:05:15.440 --> 01:05:22.400]   And now we tend to look at our phone and start getting additional stimuli that I think collides with and occludes the learning that would have occurred.
[01:05:22.400 --> 01:05:25.060]   So we don't get a lot of opportunity for reflection.
[01:05:25.060 --> 01:05:26.700]   There's a lot of sensory input.
[01:05:26.700 --> 01:05:27.760]   Some of it's deprived.
[01:05:27.760 --> 01:05:28.640]   Some of it's rich.
[01:05:28.640 --> 01:05:31.080]   But there's not a lot of time for reflection.
[01:05:31.080 --> 01:05:37.040]   So reflection and self-testing as kind of falling into the same bin and reinforcing learning and plasticity.
[01:05:37.040 --> 01:05:44.160]   The other one was that you talked about visualization and these skiers who, to avoid harming themselves,
[01:05:44.160 --> 01:05:48.240]   they'd use visualization as opposed to just more and more runs down the slope.
[01:05:48.240 --> 01:05:56.260]   We've heard before, all of us, that, you know, when you imagine an experience, the brain doesn't know the difference between that experience and a real-world experience.
[01:05:56.260 --> 01:05:59.420]   But, of course, a real-world experience includes other things.
[01:05:59.420 --> 01:06:01.600]   There's, you know, vestibular feedback.
[01:06:01.600 --> 01:06:06.120]   There's gravity feedback, you know, feedback with our relationship to gravity, to put it in common terms.
[01:06:06.120 --> 01:06:08.460]   There's all sorts of stuff, the wind in our ears.
[01:06:08.460 --> 01:06:18.840]   And you said, and I find this very interesting and very useful, that visualization and mental rehearsal can be useful for reinforcing things that we've already done in the real world.
[01:06:19.160 --> 01:06:24.080]   But it's probably not the best way to learn new things that we haven't done in the real world.
[01:06:24.080 --> 01:06:29.840]   So we can pick any number of different examples, but I think people are smart enough to just leap to those on their own.
[01:06:29.840 --> 01:06:34.940]   So if they're trying to learn something and they're doing that in the real world, dancing, maybe it's a physical skill.
[01:06:34.940 --> 01:06:35.940]   Maybe it's a cognitive skill.
[01:06:36.000 --> 01:06:37.080]   Maybe it's an emotional skill.
[01:06:37.080 --> 01:06:50.000]   Mental rehearsal is useful, is what I hear you saying, provided that you're rehearsing something that you actually did, as opposed to just imagining something and expecting that you're going to be able to do that something.
[01:06:50.000 --> 01:06:51.040]   Do I have that right?
[01:06:51.040 --> 01:06:51.180]   Yeah.
[01:06:51.180 --> 01:06:52.700]   No, I think that's exactly right.
[01:06:52.700 --> 01:06:56.740]   I mean, if you know you're not going to need it, biology would have said, you don't need this.
[01:06:56.740 --> 01:06:59.020]   It's a leaf that's wiggling in the air.
[01:06:59.020 --> 01:07:00.760]   I don't need to know where that leaf is.
[01:07:00.760 --> 01:07:03.920]   But this is the thing that cues me to where I'm going to find my next meal.
[01:07:04.280 --> 01:07:06.140]   That's going to be something I'm going to be interested in.
[01:07:06.140 --> 01:07:09.560]   If this is going to help me get a mate, I'm going to learn that.
[01:07:09.560 --> 01:07:12.980]   If this is going to be an irrelevant fact about a cloud, I'm not going to.
[01:07:12.980 --> 01:07:14.800]   And I think children have a lot of trouble with that.
[01:07:14.800 --> 01:07:18.920]   There's a stage in childhood where they'll see a plane up there and they'll say, my God, there's a little plane up there.
[01:07:18.920 --> 01:07:20.220]   That plane has no interaction with you at all.
[01:07:20.220 --> 01:07:21.360]   But they're fascinated by it.
[01:07:21.360 --> 01:07:21.920]   They're cued into it.
[01:07:21.920 --> 01:07:22.640]   They're interested in it.
[01:07:22.640 --> 01:07:26.840]   We all the time have to figure out what are the things we're going to be tested on?
[01:07:26.840 --> 01:07:28.560]   What are the things you're going to need to know?
[01:07:28.560 --> 01:07:32.220]   And one of the ways you do that as educators, which we both do, is you give them tests.
[01:07:32.560 --> 01:07:34.800]   And a lot of people say, I can't wait to have the last test.
[01:07:34.800 --> 01:07:35.220]   Really?
[01:07:35.220 --> 01:07:39.100]   You want to have no more time when someone judges and determines, how did you do?
[01:07:39.100 --> 01:07:40.480]   What is your evaluation?
[01:07:40.480 --> 01:07:46.120]   I think a lot of times many of us become lifelong learners and we're comfortable knowing that someone else knows more than me.
[01:07:46.120 --> 01:07:46.720]   I'm not going to win.
[01:07:47.240 --> 01:07:49.880]   But that I'll be able to find out how much did I do.
[01:07:49.880 --> 01:07:51.500]   That I know what's possible.
[01:07:51.500 --> 01:07:54.120]   And testing is good for us.
[01:07:54.120 --> 01:07:58.720]   Educators do it not just to assign and rank and distribute and give B's and C's and D's.
[01:07:58.720 --> 01:08:00.960]   But someone says, you could do better than that.
[01:08:00.960 --> 01:08:02.880]   If you got a D, you could have done better.
[01:08:02.880 --> 01:08:04.380]   I'm not saying you're flawed.
[01:08:04.900 --> 01:08:07.440]   I'm saying you didn't put in whatever was needed.
[01:08:07.440 --> 01:08:11.740]   Now, maybe that person does need to put more work in to get the B or even the A.
[01:08:11.740 --> 01:08:14.720]   But it's not my opinion that they can't get it.
[01:08:14.720 --> 01:08:16.020]   It's that they didn't get it.
[01:08:16.020 --> 01:08:17.220]   Explaining what's real.
[01:08:17.220 --> 01:08:18.620]   What percent did you know?
[01:08:18.620 --> 01:08:19.880]   What did you actually learn?
[01:08:19.880 --> 01:08:25.140]   How good are you at throwing the tomahawk, at shooting the arrow, at doing rock climbing?
[01:08:25.200 --> 01:08:28.740]   The visualization I'm thinking about is like from Free Solo when he's imagining doing this.
[01:08:28.740 --> 01:08:29.800]   He's already done it.
[01:08:29.800 --> 01:08:32.120]   But he's now going through imagining it again.
[01:08:32.120 --> 01:08:33.620]   All of us do that.
[01:08:33.620 --> 01:08:35.720]   My children did martial arts.
[01:08:35.720 --> 01:08:37.080]   They were both black belts in Taekwondo.
[01:08:37.080 --> 01:08:38.880]   And they would practice these forms.
[01:08:38.880 --> 01:08:41.160]   I took it at Berkeley when I was a student there.
[01:08:41.160 --> 01:08:41.980]   I just really enjoyed it.
[01:08:41.980 --> 01:08:43.100]   Is it useful?
[01:08:43.100 --> 01:08:45.000]   I don't – I've never been in a street fight.
[01:08:45.000 --> 01:08:47.220]   I've never needed to apply these skills.
[01:08:47.220 --> 01:08:49.280]   But there was a beauty to it.
[01:08:49.280 --> 01:08:50.240]   There was a usefulness to it.
[01:08:50.240 --> 01:08:51.600]   And someone came and tested me.
[01:08:51.600 --> 01:08:53.100]   I made it a yellow belt, full disclosure.
[01:08:54.340 --> 01:08:55.960]   But I was going to need to know it.
[01:08:55.960 --> 01:09:00.320]   And so I knew I would stand in front of other people and admit I didn't learn it.
[01:09:00.320 --> 01:09:02.500]   I wanted to learn it, but I didn't learn it.
[01:09:02.500 --> 01:09:08.240]   Knowing that someone, a mentor you respect, a peer you value, a spouse who cares about you,
[01:09:08.240 --> 01:09:10.400]   whatever it is, is going to look and see, how did you do?
[01:09:10.400 --> 01:09:13.280]   I don't think that's harmful, judgmental, negative.
[01:09:13.280 --> 01:09:17.180]   It's not part of the culture of exceptionalism and meritocracy.
[01:09:17.180 --> 01:09:18.540]   That's just give me some feedback.
[01:09:18.540 --> 01:09:19.360]   How am I doing?
[01:09:19.360 --> 01:09:24.140]   And a lot of times we can do extraordinary things when people do raise the bar on us a little
[01:09:24.140 --> 01:09:24.420]   bit.
[01:09:24.420 --> 01:09:26.320]   And that can be very self-fulfilling.
[01:09:26.320 --> 01:09:29.060]   Certainly an over-test-focused culture.
[01:09:29.060 --> 01:09:32.840]   My mom was a master primary education educator.
[01:09:32.840 --> 01:09:36.720]   She didn't really care very much for all of the testing-focused stuff.
[01:09:36.720 --> 01:09:40.920]   She thought, I've got to get this kid to learn how to interact well with others and put away
[01:09:40.920 --> 01:09:41.460]   his crayons.
[01:09:41.460 --> 01:09:45.440]   I don't need to worry about these particular flashcard-based skills.
[01:09:45.440 --> 01:09:46.860]   But we go back and forth.
[01:09:46.860 --> 01:09:49.820]   But the times table, is that really important?
[01:09:50.240 --> 01:09:51.560]   Memorizing how multiplication works?
[01:09:51.560 --> 01:09:55.500]   Or should you spend your time with all the states, 50 states, and all their state capitals?
[01:09:55.500 --> 01:09:57.120]   I don't have an answer.
[01:09:57.120 --> 01:09:59.100]   I'm not here to tell you that I know what the right thing to do is.
[01:09:59.100 --> 01:10:00.540]   I don't know all the state capitals.
[01:10:00.540 --> 01:10:01.520]   My children do.
[01:10:01.520 --> 01:10:02.200]   Is that useful?
[01:10:02.200 --> 01:10:04.660]   I don't know whether that's going to come out valuable.
[01:10:04.660 --> 01:10:06.180]   And that's one of the exciting things about life.
[01:10:06.180 --> 01:10:07.580]   You don't know what's going to be helpful.
[01:10:07.580 --> 01:10:10.920]   Maybe playing a lot of video games is going to turn out to be really helpful.
[01:10:10.920 --> 01:10:12.940]   I can't have to have enough humility.
[01:10:12.940 --> 01:10:16.760]   I think certainly one of the things I know you've experienced as a scientist is just the
[01:10:16.760 --> 01:10:22.080]   incredible humility that comes from recognizing this thing is way more complicated than how
[01:10:22.080 --> 01:10:22.700]   I'm thinking about it.
[01:10:22.700 --> 01:10:23.320]   It just is.
[01:10:23.320 --> 01:10:24.540]   We start there.
[01:10:24.540 --> 01:10:25.600]   We know that.
[01:10:25.600 --> 01:10:27.160]   And we're okay with that.
[01:10:27.160 --> 01:10:32.620]   We make our best model, our best explanation we've got, the explanation that fits the data
[01:10:32.620 --> 01:10:35.100]   we have now that's as simple as possible.
[01:10:35.100 --> 01:10:39.680]   And the reason we choose the simplest one is it's the easiest to prove wrong when it's inevitably
[01:10:39.680 --> 01:10:40.080]   wrong.
[01:10:40.080 --> 01:10:42.020]   And we just make this incremental progress.
[01:10:42.480 --> 01:10:43.660]   Life's a lot like that, too.
[01:10:43.660 --> 01:10:45.460]   Certainly parenting is a lot like that.
[01:10:45.460 --> 01:10:46.780]   I think this is going to be good for the kid.
[01:10:46.780 --> 01:10:48.400]   And then, no, this is not good for the kid.
[01:10:48.400 --> 01:10:50.140]   I think this is going to be bad for the kid.
[01:10:50.140 --> 01:10:54.200]   Oh, that turned out to be a really good learning experience when they're in tears and there's
[01:10:54.200 --> 01:10:55.040]   some big crisis.
[01:10:55.040 --> 01:11:01.860]   So understanding that we don't know it all, that things are typically neither as bad as
[01:11:01.860 --> 01:11:05.820]   they seem or as good as they seem, and that maximizing something, that's kind of
[01:11:05.820 --> 01:11:11.460]   one of the key concepts I worry about a little bit, minimizing all the bad things, maximizing
[01:11:11.460 --> 01:11:16.060]   all the good things, assumes you know which things are bad and should be minimized, which
[01:11:16.060 --> 01:11:17.720]   things are good and should be maximized.
[01:11:17.720 --> 01:11:22.400]   And a lot of times we come to recognize later in life, oh, many of those things that I really
[01:11:22.400 --> 01:11:26.620]   worked hard not to have happen, those are really valuable experiences because they taught me
[01:11:26.620 --> 01:11:29.980]   either how to interact with other people who've had those experiences or taught me some skill
[01:11:29.980 --> 01:11:33.380]   that I didn't know I would need to do, how to change a tire or whatever else it is.
[01:11:33.380 --> 01:11:36.120]   You don't want your tire to go flat, but then you learn how to change a tire.
[01:11:36.240 --> 01:11:40.240]   Now you learn how a scissor jack works or whatever thing that later comes in handy.
[01:11:40.240 --> 01:11:46.640]   So to me, it's more the diversity of experiences than the better experiences.
[01:11:46.640 --> 01:11:49.900]   And I think right now we're a little bit at a time where there's enough judgment about
[01:11:49.900 --> 01:11:51.760]   which experiences should you be having.
[01:11:51.760 --> 01:11:56.120]   I just returned from Yellowstone National Park and there's a little platform you can look
[01:11:56.120 --> 01:11:57.600]   down on Grand Prismatic Spring.
[01:11:57.720 --> 01:12:03.660]   And there's people who are just like, you are looking at a 700 foot across hot spring
[01:12:03.660 --> 01:12:09.600]   on top of a super volcano with rings of different colors of thermophilic bacteria and algae.
[01:12:09.600 --> 01:12:11.820]   And you go, take my picture and go.
[01:12:11.820 --> 01:12:17.380]   And it's just difficult to say, stop, look at how big this is.
[01:12:17.380 --> 01:12:18.780]   It will take more time.
[01:12:18.780 --> 01:12:23.060]   So I assume that the time you put into it, this is back to your friction idea, the time you put
[01:12:23.060 --> 01:12:28.160]   into it is probably proportional to the impact, lasting impact it's going to have on your life.
[01:12:28.160 --> 01:12:31.120]   And so when you're checking boxes, looking for things, it's probably not going to have
[01:12:31.120 --> 01:12:31.660]   much impact.
[01:12:31.660 --> 01:12:36.840]   When you're playing violin for the 100th hour, I'm not a violin player, but there's a point
[01:12:36.840 --> 01:12:39.920]   where you eventually have changed who you are.
[01:12:39.920 --> 01:12:40.800]   You're now a violinist.
[01:12:40.800 --> 01:12:42.280]   I'm a neuroscientist.
[01:12:42.280 --> 01:12:43.740]   I don't think it's something that's hard to do.
[01:12:43.740 --> 01:12:44.460]   Anyone can do it.
[01:12:44.460 --> 01:12:45.840]   Just spend all day doing experiments.
[01:12:46.480 --> 01:12:50.360]   And that's what's neat about reading books or being a skier or being a parent.
[01:12:50.360 --> 01:12:53.480]   Everybody can get good at it, but you only have so many hours.
[01:12:53.480 --> 01:12:55.180]   And so I always think about the pie chart.
[01:12:55.180 --> 01:12:56.460]   You only get 100%.
[01:12:56.460 --> 01:12:58.040]   Coaches always say 110%.
[01:12:58.040 --> 01:12:58.880]   There's no 110%.
[01:12:58.880 --> 01:12:59.600]   It's only 100%.
[01:12:59.600 --> 01:13:00.800]   How are you going to spend your time?
[01:13:00.800 --> 01:13:04.560]   Here I'm talking about the waking hours because I'm not going to cut corners on the sleeping
[01:13:04.560 --> 01:13:04.900]   hours.
[01:13:04.900 --> 01:13:06.660]   And so you just look, how am I going to spend it?
[01:13:06.660 --> 01:13:12.080]   Some time spent working, paying the bills, getting the job done, some time in leisure and recreation,
[01:13:12.540 --> 01:13:16.380]   some time with spiritual activities, and trying to make that balance.
[01:13:16.380 --> 01:13:18.840]   I find it looks a lot like it looked for my grandparents.
[01:13:18.840 --> 01:13:23.080]   But the proportions of that pie chart do not look like, I just want to disengage and spend
[01:13:23.080 --> 01:13:25.240]   all my time streaming on social media, just me personally.
[01:13:25.240 --> 01:13:29.780]   People who have done that look a lot like you'd think someone who's addicted would look.
[01:13:29.780 --> 01:13:31.780]   They eventually realize, it's just not doing it for me anymore.
[01:13:31.780 --> 01:13:33.500]   I don't get much satisfaction.
[01:13:33.500 --> 01:13:37.960]   Gilbert at Harvard did this great experiment looking at what made people happy.
[01:13:37.960 --> 01:13:39.940]   Had these little things pop up.
[01:13:39.940 --> 01:13:42.260]   You may know about this experiment and ask, how are you feeling?
[01:13:42.860 --> 01:13:44.840]   And people were happy when they were getting eggs.
[01:13:44.840 --> 01:13:46.360]   It was just like, I'm at the store.
[01:13:46.360 --> 01:13:47.520]   My wife said, get eggs.
[01:13:47.520 --> 01:13:48.280]   I'm getting eggs.
[01:13:48.280 --> 01:13:48.820]   How are you doing?
[01:13:48.820 --> 01:13:49.560]   I'm pretty good.
[01:13:49.560 --> 01:13:50.200]   I got eggs.
[01:13:50.200 --> 01:13:55.720]   That idea that you're happiest when you're accomplishing some simple goal, not some Olympic
[01:13:55.720 --> 01:13:59.300]   level impossible goal, but just some simple thing that needs to be done.
[01:13:59.300 --> 01:14:04.900]   What was surprising from that study was that when people were daydreaming, which for years
[01:14:04.900 --> 01:14:08.820]   we thought the pursuit of happiness, our forefathers thought if you could just sit and contemplate
[01:14:08.820 --> 01:14:12.500]   your navel and have the examined life, you'd be most happy.
[01:14:12.500 --> 01:14:13.340]   Not so.
[01:14:13.340 --> 01:14:17.800]   Oftentimes, contemplating our own life leads us to find someone who's got a better version
[01:14:17.800 --> 01:14:20.660]   of it, leads us to realize we're not accomplishing every goal.
[01:14:20.660 --> 01:14:28.400]   And so maybe humans evolved or created so that they would be actively engaged in doing something
[01:14:28.400 --> 01:14:29.480]   that appears to be the case.
[01:14:29.480 --> 01:14:33.200]   And when we disengage, it appears that things happen that are not good.
[01:14:33.420 --> 01:14:36.660]   What are those typically in psychiatry that are called anxiety and depression are different
[01:14:36.660 --> 01:14:41.980]   things, but there may be very similar sides of a coin where this is not working for me.
[01:14:41.980 --> 01:14:45.800]   And I think we can work back to how about we go to the laundry?
[01:14:45.800 --> 01:14:50.440]   How about we go to the grocery store and find out that that is, in fact, a satisfying activity,
[01:14:50.440 --> 01:14:52.040]   even though it's pedestrian.
[01:14:52.040 --> 01:14:57.020]   It's not something you're going to put an Instagram post on, you know, making a good pancakes.
[01:14:57.020 --> 01:14:57.900]   I'm pretty good at making pancakes.
[01:14:57.900 --> 01:14:58.540]   I flip it over.
[01:14:58.540 --> 01:14:59.860]   It's just brown all along.
[01:14:59.860 --> 01:15:01.180]   That's a good pancake.
[01:15:01.600 --> 01:15:02.440]   Some people are not as good at me.
[01:15:02.440 --> 01:15:04.480]   I take a little pride in that, but I'm not beating them.
[01:15:04.480 --> 01:15:05.660]   I'm not better at pancake making.
[01:15:05.660 --> 01:15:06.220]   I flip it over.
[01:15:06.220 --> 01:15:06.900]   It's a pancake.
[01:15:06.900 --> 01:15:07.520]   I serve it to the kid.
[01:15:07.520 --> 01:15:09.000]   The kid goes, good pancake, dad.
[01:15:09.000 --> 01:15:09.720]   You're sort of done.
[01:15:09.720 --> 01:15:14.500]   I think we devalue that by thinking I could just go to, you know, international house with
[01:15:14.500 --> 01:15:15.560]   a pancake and make a better pancake.
[01:15:15.560 --> 01:15:17.460]   That I did it myself.
[01:15:17.460 --> 01:15:20.040]   A lot of people during COVID found out, make it yourself.
[01:15:20.040 --> 01:15:23.120]   I'd never made a bagel in my life and suddenly we're locked down for two whole weeks.
[01:15:23.120 --> 01:15:25.220]   And it's like, let's go make bagels, kids.
[01:15:25.220 --> 01:15:26.460]   And I went and made a bagel.
[01:15:26.460 --> 01:15:27.420]   It wasn't a good bagel.
[01:15:27.420 --> 01:15:29.620]   I can make it, get a better bagel any place.
[01:15:29.620 --> 01:15:30.820]   But I made that bagel.
[01:15:30.820 --> 01:15:33.880]   I learned a little bit about it and I appreciate better those people who master that.
[01:15:33.880 --> 01:15:38.140]   And now when I taste a bagel, I go, now I see why your bagel is better than my bagel.
[01:15:38.140 --> 01:15:42.140]   And so I think those experiences are all coming into my brain.
[01:15:42.140 --> 01:15:46.640]   I still remember, obviously I wouldn't have mentioned it, this thing six years ago when
[01:15:46.640 --> 01:15:50.340]   I'm sitting in my kitchen with my kids in a pot of water and some flour trying to figure
[01:15:50.340 --> 01:15:51.140]   out what I'm going to do with myself.
[01:15:51.140 --> 01:15:55.680]   I didn't want the whole world shut down, but I got that gift from it that I have that
[01:15:55.680 --> 01:15:57.060]   better appreciation now of bagels.
[01:15:57.260 --> 01:16:01.880]   And I just think that's a world view that we really could have gone down a path where
[01:16:01.880 --> 01:16:04.080]   studying the brain made us unimportant.
[01:16:04.080 --> 01:16:06.280]   It made computers good and humans bad.
[01:16:06.280 --> 01:16:07.540]   I'm not seeing that at all.
[01:16:07.540 --> 01:16:09.380]   I'm super proud of all my friends.
[01:16:09.380 --> 01:16:12.800]   I don't, wouldn't rather hang out with a chat bot than with my friends.
[01:16:12.800 --> 01:16:14.780]   And I think that's going to continue to happen.
[01:16:14.780 --> 01:16:17.760]   I don't expect there's going to be a major revolution in that.
[01:16:17.760 --> 01:16:18.580]   And that's a surprise.
[01:16:19.000 --> 01:16:22.760]   It's a surprise that discovery keeps leading to good things, not bad things.
[01:16:22.760 --> 01:16:27.820]   There are a lot of dangerous things I mentioned, machine guns and nuclear weapons, but we mostly
[01:16:27.820 --> 01:16:28.540]   haven't used those things.
[01:16:28.540 --> 01:16:29.320]   We've met all this good stuff.
[01:16:29.320 --> 01:16:32.160]   So you can see I'm an optimist and it partly comes from studying the brain.
[01:16:32.160 --> 01:16:35.360]   I get to study the brain while it's alive and listen to neurons while they're actually
[01:16:35.360 --> 01:16:35.780]   firing.
[01:16:35.780 --> 01:16:39.820]   Other people looked at it while it was in dead tissue under a microscope, but they were both
[01:16:39.820 --> 01:16:41.880]   able to see this thing is alive.
[01:16:42.320 --> 01:16:47.180]   And that was reflective of how I feel as a live person, not as a machine, not as a pawn,
[01:16:47.180 --> 01:16:52.700]   not as a, you know, one vote in a democracy, but as a real person.
[01:16:52.700 --> 01:16:54.980]   And neuroscience is supporting that.
[01:16:54.980 --> 01:16:56.200]   And that's been the history of science.
[01:16:56.200 --> 01:17:01.200]   We didn't ruin things when we found out that the sun's not revolving around us.
[01:17:01.200 --> 01:17:04.240]   It made it better when we found out we're revolving around the sun.
[01:17:04.240 --> 01:17:05.740]   We're not the only galaxy.
[01:17:05.740 --> 01:17:07.240]   All those things were good for us.
[01:17:07.240 --> 01:17:10.420]   But at first, people were really nervous about having the answer.
[01:17:11.100 --> 01:17:14.520]   I've just been surprised that finding the answer keeps being the good thing.
[01:17:14.520 --> 01:17:15.500]   You'd rather have the answer.
[01:17:15.500 --> 01:17:17.220]   There are no answers we don't want.
[01:17:17.220 --> 01:17:21.360]   That's really surprising to me because it could have turned out we're all bad and there's
[01:17:21.360 --> 01:17:24.460]   nothing here and all the nihilist philosophies and all the rest would be right.
[01:17:24.460 --> 01:17:26.660]   But that doesn't appear to be the case.
[01:17:26.660 --> 01:17:31.900]   And all that comes from this sort of friction, this reflection, all these issues, learning about
[01:17:31.900 --> 01:17:35.720]   how the brain works, all the way down to the biological level, all the way up to societies
[01:17:35.720 --> 01:17:39.960]   and groups of people who continue to be mostly pro-social, mostly taking care of each
[01:17:39.960 --> 01:17:43.280]   other, mostly not destroying the earth, figuring things out, making adjustments.
[01:17:43.280 --> 01:17:44.960]   The ozone layer had a hole in it.
[01:17:44.960 --> 01:17:45.720]   We made some changes.
[01:17:45.720 --> 01:17:47.100]   That seems very reasonable.
[01:17:47.100 --> 01:17:51.520]   We may not be fast about it all the time, but we tend to make the right path, both in science
[01:17:51.520 --> 01:17:52.680]   as well as in our species.
[01:17:52.680 --> 01:17:54.900]   And I think that's because they're both using the same mechanism.
[01:17:54.900 --> 01:17:56.100]   We get feedback from the world.
[01:17:56.100 --> 01:17:58.600]   When we make the wrong choices, we see it.
[01:17:58.600 --> 01:18:00.620]   That's true as a parent, true as a scientist.
[01:18:00.620 --> 01:18:02.720]   When things don't work, you're going to find out.
[01:18:03.400 --> 01:18:05.080]   And I like that feedback from the world.
[01:18:05.080 --> 01:18:09.960]   I'd like to take a quick break and acknowledge one of our sponsors, Function.
[01:18:09.960 --> 01:18:14.500]   Last year, I became a Function member after searching for the most comprehensive approach
[01:18:14.500 --> 01:18:15.320]   to lab testing.
[01:18:15.320 --> 01:18:21.140]   Function provides over 100 advanced lab tests that give you a key snapshot of your entire
[01:18:21.140 --> 01:18:21.900]   bodily health.
[01:18:21.900 --> 01:18:26.740]   This snapshot offers you with insights on your heart health, hormone health, immune functioning,
[01:18:26.740 --> 01:18:28.580]   nutrient levels, and much more.
[01:18:28.720 --> 01:18:33.480]   They've also recently added tests for toxins, such as BPA exposure from harmful plastics,
[01:18:33.480 --> 01:18:36.280]   and tests for PFASs, or forever chemicals.
[01:18:36.280 --> 01:18:40.760]   Function not only provides testing of over 100 biomarkers key to your physical and mental
[01:18:40.760 --> 01:18:45.800]   health, but it also analyzes these results and provides insights from top doctors who are
[01:18:45.800 --> 01:18:47.340]   expert in the relevant areas.
[01:18:47.340 --> 01:18:51.760]   For example, in one of my first tests with Function, I learned that I had elevated levels
[01:18:51.760 --> 01:18:52.880]   of mercury in my blood.
[01:18:52.880 --> 01:18:57.840]   Function not only helped me detect that, but offered insights into how best to reduce my mercury
[01:18:57.840 --> 01:19:02.860]   levels, which included limiting my tuna consumption, I'd been eating a lot of tuna, while also making
[01:19:02.860 --> 01:19:07.400]   an effort to eat more leafy greens and supplementing with NAC and acetylcysteine, both of which can
[01:19:07.400 --> 01:19:09.840]   support glutathione production and detoxification.
[01:19:09.840 --> 01:19:13.600]   And I should say, by taking a second Function test, that approach worked.
[01:19:13.600 --> 01:19:16.180]   Comprehensive blood testing is vitally important.
[01:19:16.180 --> 01:19:20.800]   There's so many things related to your mental and physical health that can only be detected in
[01:19:20.800 --> 01:19:21.400]   a blood test.
[01:19:21.400 --> 01:19:24.940]   The problem is, blood testing has always been very expensive and complicated.
[01:19:24.940 --> 01:19:30.120]   In contrast, I've been super impressed by Function's simplicity and at the level of cost.
[01:19:30.120 --> 01:19:31.180]   It is very affordable.
[01:19:31.180 --> 01:19:35.700]   As a consequence, I decided to join their scientific advisory board, and I'm thrilled that they're
[01:19:35.700 --> 01:19:36.540]   sponsoring the podcast.
[01:19:36.540 --> 01:19:41.180]   If you'd like to try Function, you can go to functionhealth.com slash Huberman.
[01:19:41.180 --> 01:19:46.980]   Function currently has a wait list of over 250,000 people, but they're offering early access to
[01:19:46.980 --> 01:19:48.220]   Huberman podcast listeners.
[01:19:48.220 --> 01:19:53.520]   Again, that's functionhealth.com slash Huberman to get early access to function.
[01:19:53.520 --> 01:19:57.420]   I share and love your sense of optimism.
[01:19:57.420 --> 01:20:05.720]   I was thinking about default settings that we arrive into the world with, and it seems
[01:20:05.720 --> 01:20:09.300]   at least to me that our default setting is to learn.
[01:20:09.300 --> 01:20:10.640]   The young brain is poised to learn.
[01:20:10.640 --> 01:20:15.660]   And then as we learn, perhaps the only thing we need to be cautious of with respect to technology
[01:20:15.660 --> 01:20:22.620]   is how technologies might be kind of nudging our default settings in terms of behavior.
[01:20:22.620 --> 01:20:24.680]   I thought a lot about this recently.
[01:20:24.680 --> 01:20:30.180]   I thought, you know, how much time per day am I on my phone versus working on my book edits
[01:20:30.180 --> 01:20:33.000]   versus, you know, preparing for a solo podcast?
[01:20:33.000 --> 01:20:38.020]   All of which I love preparing for podcasts, and I love being here doing podcasts, and I love
[01:20:38.020 --> 01:20:39.340]   writing.
[01:20:39.580 --> 01:20:45.080]   It's hard, but this focus and friction thing together plus reflection, I'm not trying to
[01:20:45.080 --> 01:20:50.540]   play psychologist here, but in my mind, I have this very simple mathematical formula that
[01:20:50.540 --> 01:20:57.060]   says that, you know, focus plus friction plus reflection and sleep not only give you neuroplasticity,
[01:20:57.060 --> 01:21:02.040]   but those things combined are also what I'm hearing from you is that they contribute to this thing
[01:21:02.040 --> 01:21:02.780]   called meaning.
[01:21:02.780 --> 01:21:08.100]   Like the pancake experience has meaning because there was some friction because it wasn't as
[01:21:08.100 --> 01:21:13.340]   good as perhaps you could go buy from International House of Pancakes, which by the way, their
[01:21:13.340 --> 01:21:14.240]   pancakes are not that good.
[01:21:14.240 --> 01:21:15.340]   I'm just going to put that up here.
[01:21:15.340 --> 01:21:16.580]   Yeah, come after me.
[01:21:16.580 --> 01:21:23.060]   But like the pancakes, they don't taste, they're a deprived pancake experience in my view.
[01:21:23.060 --> 01:21:24.860]   Step it up, guys.
[01:21:24.860 --> 01:21:29.900]   But that friction of the, you know, your bagel, I agree.
[01:21:29.900 --> 01:21:33.100]   The bagel you made, even though I didn't taste it, was probably not as good as the bagel you
[01:21:33.100 --> 01:21:33.940]   can get in Manhattan.
[01:21:33.940 --> 01:21:35.320]   They make pretty good bagels in Manhattan.
[01:21:35.320 --> 01:21:41.000]   But the effort that you put into it and the thought and the fact that it came from a mild
[01:21:41.000 --> 01:21:44.960]   deprivation, you can go out and buy bagels is, you know, that's the friction.
[01:21:44.960 --> 01:21:46.280]   There's some focus.
[01:21:46.280 --> 01:21:47.120]   There's a reflection.
[01:21:47.120 --> 01:21:48.120]   It's still with you.
[01:21:48.120 --> 01:21:54.060]   And there's a, you extract meaning from it one way or the other, or you discard the experience
[01:21:54.060 --> 01:21:54.320]   inside.
[01:21:54.320 --> 01:21:55.240]   There was no meaning there.
[01:21:55.240 --> 01:21:56.580]   And the meaning was no meaning.
[01:21:56.580 --> 01:21:58.100]   Then you just kind of go to the next thing.
[01:21:58.480 --> 01:22:05.020]   But I think that the human brain, as you said, it's interesting earlier, you're talking about
[01:22:05.020 --> 01:22:06.080]   yellow bile, black bile.
[01:22:06.080 --> 01:22:06.760]   What's the other one?
[01:22:06.760 --> 01:22:08.280]   Phlegm and blood.
[01:22:08.280 --> 01:22:12.920]   Those are the four components that for many years people in medicine thought were like the
[01:22:12.920 --> 01:22:17.500]   critical elements of human experience and biology and health or lack of health.
[01:22:17.620 --> 01:22:22.840]   And then we shifted, as you pointed out, to serotonin, norepinephrine, acetylcholine, and
[01:22:22.840 --> 01:22:23.220]   dopamine.
[01:22:23.220 --> 01:22:24.420]   We'll go there in a moment.
[01:22:24.420 --> 01:22:31.220]   But ultimately, those are just the substrates by which we make bagels or we have a lasting
[01:22:31.220 --> 01:22:35.400]   experience of meaning with an advisor or, more importantly, a parent.
[01:22:36.140 --> 01:22:40.500]   This is like the alchemy of life.
[01:22:40.500 --> 01:22:45.320]   And neuroplasticity is really the process, right?
[01:22:45.320 --> 01:22:50.400]   I always have to emphasize to people that these things have names, but they're not nouns.
[01:22:50.400 --> 01:22:51.040]   They're verbs.
[01:22:51.040 --> 01:22:54.260]   Plasticity is a process that brings it together.
[01:22:54.260 --> 01:22:56.220]   That's the cooking of sorts.
[01:22:56.220 --> 01:23:01.080]   So in any case, I'm not trying to do philosophy here, but there's so much richness in what you're
[01:23:01.080 --> 01:23:06.200]   offering in terms of these real world, very basic examples, but they have real meaning
[01:23:06.200 --> 01:23:11.560]   because of what the context was and how you reflect on them now still.
[01:23:11.560 --> 01:23:17.880]   So let's talk about those four elements, not yellow bile, black bile, phlegm, and blood.
[01:23:17.880 --> 01:23:19.980]   Gross.
[01:23:19.980 --> 01:23:23.700]   Bile just sounds gross, even though I'm sure it does useful things.
[01:23:23.700 --> 01:23:25.080]   I know it does useful things.
[01:23:26.520 --> 01:23:34.240]   Let's talk about serotonin, dopamine, norepinephrine, and acetylcholine in particular.
[01:23:34.240 --> 01:23:36.560]   These are neuromodulators.
[01:23:36.560 --> 01:23:39.680]   They modulate the activity of neurons.
[01:23:39.680 --> 01:23:42.640]   They make them typically more active, but sometimes less active.
[01:23:42.640 --> 01:23:47.480]   You mentioned a few of the hubs in the brain that release these different neuromodulators.
[01:23:47.480 --> 01:23:51.360]   I'm familiar with those, but maybe you could step us through the way that you think about
[01:23:51.360 --> 01:23:53.160]   them and educate us on them.
[01:23:53.160 --> 01:23:57.300]   Because I'm learning so much from you already today, and I want to learn how you think about
[01:23:57.300 --> 01:24:03.820]   neuroplasticity and what these four kind of macronutrients of neuroplasticity are.
[01:24:03.820 --> 01:24:04.440]   Yeah.
[01:24:04.440 --> 01:24:10.640]   I mean, they remind me of the sort of four fundamental forces of nature, and then we're looking for
[01:24:10.640 --> 01:24:12.000]   the grand unified theory, right?
[01:24:12.000 --> 01:24:16.180]   So in physics, you've got electromagnetism, gravity, strong, nuclear force, and weak nuclear
[01:24:16.180 --> 01:24:16.400]   force.
[01:24:16.400 --> 01:24:17.480]   We're trying to put them all together.
[01:24:17.480 --> 01:24:19.620]   We know they all exist, but what do they all do individually?
[01:24:19.620 --> 01:24:20.780]   How do they all work together?
[01:24:20.780 --> 01:24:21.640]   They make tables.
[01:24:21.640 --> 01:24:23.280]   I mean, that's what all this stuff does.
[01:24:23.280 --> 01:24:30.720]   For me, those four neurotransmitters began as a simple experiment searching for an explanation.
[01:24:30.720 --> 01:24:34.120]   My story of this is easy in the beginning.
[01:24:34.120 --> 01:24:40.100]   I heard about one experiment done by Greg Regazone in the early 90s, and a monkey is reaching out
[01:24:40.100 --> 01:24:42.020]   and having a vibration on the tip of his finger.
[01:24:42.020 --> 01:24:46.760]   And if he pays attention to it enough, he can double the number of neurons in his brain,
[01:24:46.760 --> 01:24:50.520]   or triple, or sometimes five times more neurons that respond to a touch of the finger.
[01:24:50.520 --> 01:24:51.440]   That's amazing.
[01:24:51.440 --> 01:24:57.280]   That monkey was also listening to a sound that happened just as often, but his auditory cortex
[01:24:57.280 --> 01:25:01.840]   did not change because he wasn't listening to the tone.
[01:25:01.840 --> 01:25:03.380]   What was useful to him was the touch.
[01:25:03.380 --> 01:25:07.600]   He'd pull his hand away and get a pellet reward based on the touch.
[01:25:07.600 --> 01:25:09.520]   And the other, the sound was a distraction.
[01:25:10.040 --> 01:25:12.760]   So his brain learned touch, not sound.
[01:25:12.760 --> 01:25:16.320]   One of the other monkeys was randomized to be in the other group.
[01:25:16.320 --> 01:25:20.860]   That monkey was also getting his finger vibrated, but that vibration was a distraction.
[01:25:20.860 --> 01:25:23.240]   And now the sounds mattered.
[01:25:23.240 --> 01:25:27.060]   When the sound made a tiny change, he had to pull his hand away, not because of the vibration,
[01:25:27.060 --> 01:25:27.740]   but because of the sound.
[01:25:28.280 --> 01:25:33.160]   And that monkey had no change in the way his brain processed the sense of touch on his
[01:25:33.160 --> 01:25:38.180]   finger, but quadrupled the number of neurons in his brain that responded to that particular
[01:25:38.180 --> 01:25:40.580]   pitch, because that particular pitch had information.
[01:25:40.580 --> 01:25:45.640]   At the time, I was a biochemistry major, and I thought, wait, I know the cellular basis of
[01:25:45.640 --> 01:25:45.860]   life.
[01:25:45.860 --> 01:25:46.840]   There's all these cells.
[01:25:46.840 --> 01:25:49.220]   This is kind of a big idea from the last century.
[01:25:49.220 --> 01:25:50.800]   Life is made of cells.
[01:25:50.800 --> 01:25:51.480]   Why?
[01:25:51.480 --> 01:25:51.960]   Who knows?
[01:25:51.960 --> 01:25:53.240]   But that's a core idea, and it's true.
[01:25:54.200 --> 01:25:56.680]   DNA is one of the other core ideas, how proteins work.
[01:25:56.680 --> 01:26:05.060]   But how does a cell, one 100 billionth of me, how does it know, which I'm paying attention
[01:26:05.060 --> 01:26:05.260]   to?
[01:26:05.260 --> 01:26:06.660]   It can't know everything.
[01:26:06.660 --> 01:26:09.000]   With chat GPT, it does know everything.
[01:26:09.000 --> 01:26:10.400]   We send a signal to every cell.
[01:26:10.400 --> 01:26:11.340]   We have a broadcast system.
[01:26:11.340 --> 01:26:12.660]   Every cell knows everything.
[01:26:12.660 --> 01:26:13.320]   That's how it's built.
[01:26:13.320 --> 01:26:15.960]   But with us, a cell, I didn't know of a way.
[01:26:15.960 --> 01:26:22.180]   There was no biology then or now where one cell could know what is happening about everything.
[01:26:23.380 --> 01:26:28.000]   The closest thing that was available was release of acetylcholine.
[01:26:28.000 --> 01:26:32.560]   We knew that if you took a drug for 100 years, we've known, that blocks all the acetylcholine,
[01:26:32.560 --> 01:26:33.580]   you won't remember anything.
[01:26:33.580 --> 01:26:37.200]   Nothing you're hearing on this podcast will be remembered if you took a drug that blocked
[01:26:37.200 --> 01:26:37.560]   acetylcholine.
[01:26:37.560 --> 01:26:38.220]   You just won't remember anything.
[01:26:38.220 --> 01:26:39.220]   It's an amnestic.
[01:26:39.220 --> 01:26:43.400]   People used to give it to patients when they'd have surgery, so they wouldn't remember all
[01:26:43.400 --> 01:26:44.060]   the horrible pain.
[01:26:44.060 --> 01:26:45.060]   What is the drug?
[01:26:45.060 --> 01:26:48.660]   The drugs, anticholinergics like scobalamine, atropine.
[01:26:48.740 --> 01:26:53.860]   These are drugs that block acetylcholine just by preventing the neurotransmitter from binding
[01:26:53.860 --> 01:26:54.520]   the receptor.
[01:26:54.520 --> 01:26:57.520]   These are now date rape drugs, these kinds of things.
[01:26:57.520 --> 01:27:01.300]   They're really bad because they block our memories and we need our memories.
[01:27:01.300 --> 01:27:05.160]   And we knew acetylcholine was responsible, but that doesn't really explain how it works.
[01:27:05.160 --> 01:27:07.240]   The fact that you need it doesn't say what it's doing.
[01:27:07.760 --> 01:27:12.500]   So the hypothesis was, maybe the animal's paying attention doesn't matter.
[01:27:12.500 --> 01:27:14.660]   Maybe it's simpler than that.
[01:27:14.660 --> 01:27:21.380]   And maybe what's really happening is, each time the animal tries, pays attention, focuses
[01:27:21.380 --> 01:27:25.080]   with that friction, with that attention, that at that moment, there's a burst of acetylcholine
[01:27:25.080 --> 01:27:25.580]   being released.
[01:27:25.940 --> 01:27:31.600]   So I mentioned Melon DeLong, recorded from those neurons, and sure enough, when an animal's
[01:27:31.600 --> 01:27:32.920]   doing this task, those neurons fire.
[01:27:32.920 --> 01:27:37.740]   So the question was, if I flipped it around and said, let me put an electrode in those neurons,
[01:27:37.740 --> 01:27:39.160]   now there is no task.
[01:27:39.160 --> 01:27:43.180]   I'm going to activate just those neurons while a tone happens.
[01:27:43.180 --> 01:27:46.440]   Can I also quadruple the number of neurons that respond to that tone?
[01:27:46.440 --> 01:27:48.560]   And it doesn't mean anything to the animal at all.
[01:27:48.560 --> 01:27:50.600]   Like, I know it doesn't mean anything because there is no reward.
[01:27:50.600 --> 01:27:51.540]   The animal's not hungry.
[01:27:51.540 --> 01:27:52.220]   Nothing is happening.
[01:27:52.220 --> 01:27:54.260]   So that was the work I did with Mike Mearsnag.
[01:27:54.560 --> 01:27:56.460]   And the answer is it worked, which was just incredible.
[01:27:56.460 --> 01:28:02.180]   The brain, the proportion of neurons that respond to your finger or to a particular smell or
[01:28:02.180 --> 01:28:07.500]   to a particular orientation of light, all those can be changed based on the relative timing
[01:28:07.500 --> 01:28:12.780]   of the release of neurotransmitters, including acetylcholine, and the activity in your brain,
[01:28:12.780 --> 01:28:16.020]   which is a very rich data source, lots of information about sights and sounds and smells.
[01:28:16.020 --> 01:28:17.980]   It has to happen a lot of times.
[01:28:17.980 --> 01:28:18.940]   How many?
[01:28:18.940 --> 01:28:22.180]   Hundreds of times per day for many, many days.
[01:28:22.640 --> 01:28:24.880]   That's what happened to me when I was squashing those flies.
[01:28:24.880 --> 01:28:28.100]   Every day I'd go in and look at the same pattern and I'd close my eyes and I'd see it.
[01:28:28.100 --> 01:28:29.040]   It didn't happen once.
[01:28:29.040 --> 01:28:32.820]   It required that spaced repetition we know from psychology and neuroscience.
[01:28:32.820 --> 01:28:34.140]   It's required to change the brain.
[01:28:34.140 --> 01:28:37.400]   And so, okay, I can change the brain with this one thing.
[01:28:38.600 --> 01:28:43.140]   Others came along and said, what if instead of doing acetylcholine, I stimulated, instead
[01:28:43.140 --> 01:28:48.220]   of nucleus basalis releasing acetylcholine, I stimulated locus coeruleus releasing norepinephrine.
[01:28:48.220 --> 01:28:49.840]   Same thing happens.
[01:28:49.840 --> 01:28:51.460]   Wait a minute.
[01:28:51.460 --> 01:28:52.300]   It's a totally different brain area.
[01:28:52.300 --> 01:28:53.360]   It doesn't matter.
[01:28:53.360 --> 01:28:55.100]   I release these neurotransmitters.
[01:28:55.100 --> 01:28:56.500]   I also can quadruple it.
[01:28:56.500 --> 01:28:56.960]   All right.
[01:28:56.960 --> 01:28:57.880]   What if I did dopamine?
[01:28:57.880 --> 01:29:00.300]   You also get an increase.
[01:29:00.980 --> 01:29:03.720]   So the idea is I'm just labeling these things.
[01:29:03.720 --> 01:29:05.600]   All these events, I'm awash in information.
[01:29:05.600 --> 01:29:10.420]   Everything I look, every leaf that wiggles, every breath of air, wind against my face, every
[01:29:10.420 --> 01:29:11.340]   bit of my shirt.
[01:29:11.340 --> 01:29:12.920]   Most of it I ignore because it doesn't matter.
[01:29:13.720 --> 01:29:17.060]   But I'm learning what matters and what doesn't matter.
[01:29:17.060 --> 01:29:20.840]   And a baby is doing it by fumbling around with their fingers and hitting themselves and trying
[01:29:20.840 --> 01:29:21.420]   to get the bottle.
[01:29:21.420 --> 01:29:25.100]   We're doing it by trying to figure out what gets us social cues, what gets us reward or
[01:29:25.100 --> 01:29:29.100]   prestige or mating opportunities or safety or security.
[01:29:29.100 --> 01:29:35.360]   And the way the neurons know, the tiny, tiny, tiny fraction of me is this little release.
[01:29:35.360 --> 01:29:36.900]   And this release is very transient.
[01:29:36.900 --> 01:29:38.620]   It's not about how much there is.
[01:29:38.620 --> 01:29:40.680]   It's about the timing of it.
[01:29:40.680 --> 01:29:42.300]   And the psychologists knew this.
[01:29:42.940 --> 01:29:46.360]   You ring a bell, you feed the dog, the dog starts to salivate.
[01:29:46.360 --> 01:29:51.240]   So these classic experiments by Ivan Pavlov simply show that the brain can change.
[01:29:51.240 --> 01:29:53.340]   Why does the salivation change?
[01:29:53.340 --> 01:29:55.240]   Because of a ringing bell.
[01:29:55.240 --> 01:29:58.800]   Because that's the thing that leads to this event being useful.
[01:29:58.800 --> 01:30:02.120]   It's useful to the dog to prepare for this activity.
[01:30:02.120 --> 01:30:06.000]   And so you condition this particular synapse to be strengthened.
[01:30:06.000 --> 01:30:07.860]   Where normally bells just ring.
[01:30:07.860 --> 01:30:08.880]   Dogs don't care about bells.
[01:30:08.880 --> 01:30:09.680]   Bells don't matter.
[01:30:09.680 --> 01:30:10.260]   It's just a church.
[01:30:10.260 --> 01:30:12.060]   It's just the end of the hour.
[01:30:12.520 --> 01:30:12.940]   Ignore it.
[01:30:12.940 --> 01:30:17.480]   But if over time you repeatedly teach, then you make this change.
[01:30:17.480 --> 01:30:21.040]   When we teach undergraduates, what does acetylcholine do?
[01:30:21.040 --> 01:30:24.580]   We will sometimes say it's the memory neurotransmitter.
[01:30:24.580 --> 01:30:26.900]   And when we say, what does norepinephrine do?
[01:30:26.900 --> 01:30:28.760]   We'll sometimes say it's the attention one.
[01:30:28.760 --> 01:30:30.940]   And we say, what does dopamine do?
[01:30:30.940 --> 01:30:32.540]   We'll sometimes say it's the reward one.
[01:30:33.040 --> 01:30:34.920]   And we say, what does serotonin do?
[01:30:34.920 --> 01:30:37.060]   We'll sometimes say it's the mood one.
[01:30:37.060 --> 01:30:38.700]   And there's reasons for that.
[01:30:38.700 --> 01:30:40.640]   And they have a lot to learn.
[01:30:40.640 --> 01:30:42.600]   And making it simple is a good idea.
[01:30:43.660 --> 01:30:52.940]   But the chance that any given word in English has a biological basis, one molecule, one cell type, one rhythm, is zero.
[01:30:53.560 --> 01:30:55.600]   There's an infinite number of words we could have made.
[01:30:55.600 --> 01:30:57.340]   There's a lot of complex biology.
[01:30:57.340 --> 01:31:03.680]   There isn't likely, in my opinion, this is a rare opinion, there isn't likely to be an attention thing.
[01:31:04.740 --> 01:31:06.980]   It's just a word we made up to describe a series of phenomenon.
[01:31:06.980 --> 01:31:08.980]   There doesn't have to be a gene for that.
[01:31:08.980 --> 01:31:10.060]   We think there does.
[01:31:10.060 --> 01:31:11.060]   There's a gene for everything.
[01:31:11.060 --> 01:31:13.040]   There's lots of genes for everything.
[01:31:13.040 --> 01:31:21.940]   So the way it works to bring this all together, these forces all coming together, is called the synaptic eligibility trace.
[01:31:21.940 --> 01:31:24.060]   This is Alfredo Kirkwood's work and many others.
[01:31:24.060 --> 01:31:25.440]   He's at Johns Hopkins.
[01:31:25.440 --> 01:31:26.760]   But many people have contributed to this.
[01:31:26.760 --> 01:31:32.960]   The neuron has learned, the synapse has learned, I need to strengthen long-term potentiation
[01:31:32.960 --> 01:31:39.000]   because there's a pre-synaptic input, releasing typically glutamate, onto the post-synaptic cell,
[01:31:39.000 --> 01:31:40.440]   the cell that's receiving it.
[01:31:40.440 --> 01:31:47.260]   And because the order was right, release glutamate and then respond, I should strengthen.
[01:31:47.260 --> 01:31:51.340]   But 99.99999 times out of 100, I don't do it.
[01:31:51.340 --> 01:31:52.780]   I just let it go.
[01:31:52.780 --> 01:31:55.460]   I was going to strengthen it, but then that wasn't important.
[01:31:55.460 --> 01:31:56.240]   I just let it go.
[01:31:56.240 --> 01:32:02.460]   A handful of seconds each hour matter, and we're trying to pick which ones matter.
[01:32:02.460 --> 01:32:06.960]   Maybe it's 100, but it's not every second matters, some small fraction.
[01:32:06.960 --> 01:32:13.400]   And what we discovered is by triggering this release, we're using the same way biology always works.
[01:32:13.400 --> 01:32:14.500]   It's how you learn to play violin.
[01:32:14.500 --> 01:32:15.300]   I made a squeaky note.
[01:32:15.300 --> 01:32:17.420]   I go, something there was wrong.
[01:32:17.420 --> 01:32:18.060]   I need to make an adjustment.
[01:32:18.060 --> 01:32:22.940]   And what's weird is it's the same cocktail when it's a good thing or a bad thing.
[01:32:22.940 --> 01:32:24.920]   Acetylcholine, norepinephrine, serotonin.
[01:32:24.920 --> 01:32:29.940]   Dopamine, of course, changes negatively when it's bad and positively when it's good.
[01:32:29.940 --> 01:32:33.420]   But all of these things dump onto the cell.
[01:32:33.420 --> 01:32:38.740]   That postsynaptic cell spine is trying to figure out, should I strengthen or weaken?
[01:32:38.740 --> 01:32:45.560]   And they all work together in a very bizarre way to create that spike timing-dependent plasticity.
[01:32:46.320 --> 01:32:52.420]   And so it's a four-factor learning rule, relative timing pre-post, thousandth of a millisecond, is two of them.
[01:32:52.420 --> 01:32:57.240]   Then arrival on two G-protein-coupled receptors.
[01:32:57.240 --> 01:32:58.460]   That's just the name they were given.
[01:32:58.460 --> 01:32:59.720]   That's not a good name, I don't think.
[01:32:59.720 --> 01:33:02.140]   There's not an H-protein-coupled receptor that I know of.
[01:33:02.520 --> 01:33:10.320]   But these G-protein-coupled receptors are running this computation, super sophisticated computation, way better than what AI's got.
[01:33:11.320 --> 01:33:18.720]   And that computation means I can play pool or I can learn to swim or I can learn to walk or I can speak French if I wanted to.
[01:33:18.720 --> 01:33:24.820]   And the fact that these neurotransmitters are working together in consort is a surprise.
[01:33:24.820 --> 01:33:27.660]   It seemed like they would likely do different things.
[01:33:28.480 --> 01:33:35.620]   And my understanding of why we keep thinking that is because when I look inside my car, everything in the car has a different purpose.
[01:33:35.620 --> 01:33:38.680]   The brakes have nothing to do with the transmission.
[01:33:38.680 --> 01:33:42.100]   The transmission has nothing to do with power steering.
[01:33:42.100 --> 01:33:45.120]   The power steering has nothing to do with the muffler.
[01:33:45.120 --> 01:33:47.060]   That's because the human designed it.
[01:33:47.060 --> 01:33:52.580]   And the way we think about things is to make one thing that does one job, one thing that does another job, one thing that does another job.
[01:33:52.580 --> 01:33:55.420]   Biology, evolution, is a tinkerer.
[01:33:56.040 --> 01:33:58.480]   And it just makes up live and die.
[01:33:58.480 --> 01:33:59.440]   Sometimes the wolf lives.
[01:33:59.440 --> 01:34:00.480]   Sometimes the wolf doesn't live.
[01:34:00.480 --> 01:34:06.400]   And we end up with this very messy thing where all these pieces work together really well.
[01:34:06.400 --> 01:34:10.780]   But when we try to give them labels, what is the thing that's causing Alzheimer's?
[01:34:10.780 --> 01:34:12.040]   What's the thing that's causing schizophrenia?
[01:34:12.040 --> 01:34:13.940]   What's the thing that's causing stroke?
[01:34:13.940 --> 01:34:15.000]   Sometimes it's easy.
[01:34:15.000 --> 01:34:16.280]   For stroke, it's a blood clot.
[01:34:16.280 --> 01:34:17.380]   It causes damage to the brain.
[01:34:17.380 --> 01:34:25.520]   But for the vast majority of things, it's a whole bunch of nature-nurture mumbo-jumbo where a bunch of experiences, stress, anxiety,
[01:34:25.960 --> 01:34:27.640]   plus a bunch of genes interacted.
[01:34:27.640 --> 01:34:32.380]   But the part we have control over are these synapses.
[01:34:32.380 --> 01:34:34.740]   The brain, as you know, is mostly not going to get very many new neurons.
[01:34:34.740 --> 01:34:36.100]   You get some new neurons but not very many.
[01:34:36.100 --> 01:34:38.280]   Most of your neurons you've got now you're going to die with.
[01:34:39.280 --> 01:34:44.380]   But all those spines are turning over all the time, just like all those cells in your face are turning over every few weeks.
[01:34:44.380 --> 01:34:48.060]   Those spines are turning over and changing and reprocessing your memories.
[01:34:48.060 --> 01:34:53.680]   And by understanding now how this works, we think we can help people who are stuck.
[01:34:53.680 --> 01:35:04.900]   So there's a large number of people in our society, maybe because of social media, but maybe that happened before social media, who are really broken, have really bad traumatic events, fear of death, and they just can't get over it.
[01:35:05.320 --> 01:35:07.440]   They're stuck in a way that's not helpful.
[01:35:07.440 --> 01:35:08.900]   It's called post-traumatic stress disorder.
[01:35:09.100 --> 01:35:24.940]   And we're now switching this from the exciting knowledge, learning in the lab how fruit flies and worms and sea slugs work, and finding out there's a lot of similarity to how the mouse works, and a lot of similarity to how the monkey works, and a lot of similarity to how we work, mostly the same, the genes.
[01:35:26.400 --> 01:35:29.840]   Certainly the ones we've been talking about so far, all the identical genes in all these species.
[01:35:29.840 --> 01:35:32.160]   Can we then make use of it?
[01:35:32.160 --> 01:35:35.060]   And it's kind of scary because you think, I don't want someone coming around and changing my brain.
[01:35:35.060 --> 01:35:44.960]   But if I asked you and I said I was stuck, just like if I said my bone is broken, of course I want a doctor to put those two bones together, put that cast on, and help the healing process.
[01:35:44.960 --> 01:35:47.560]   Most ways we get injured, we don't need a doctor.
[01:35:47.560 --> 01:35:51.880]   Scratch a wound, get a cold, doctor's not going to help you.
[01:35:51.880 --> 01:35:55.840]   But for many of them, you need someone to set that bone, put it right.
[01:35:56.160 --> 01:36:03.400]   And we're just now moving to this stage where first psychologists and lately now neuroscientists are learning how to reset those.
[01:36:03.400 --> 01:36:07.100]   Many people have a great fear of heights, which is a smart thing to have.
[01:36:07.100 --> 01:36:08.560]   You don't want to fall off a cliff.
[01:36:08.560 --> 01:36:09.260]   It's super bad.
[01:36:09.260 --> 01:36:09.640]   You could die.
[01:36:09.640 --> 01:36:14.180]   But for some people, they can't work at a building they need to work at because their fear is so great.
[01:36:14.180 --> 01:36:24.620]   My psychologist friends who have been mastering this arcane art of cognitive behavioral therapy now claim a 100% cure rate for severe fear of heights.
[01:36:24.620 --> 01:36:25.500]   People really, it's debilitating.
[01:36:25.580 --> 01:36:26.580]   It's not just afraid of heights.
[01:36:26.580 --> 01:36:27.320]   Everyone's afraid of heights.
[01:36:27.320 --> 01:36:27.700]   You should be.
[01:36:27.700 --> 01:36:28.340]   It's a smart thing.
[01:36:28.340 --> 01:36:29.280]   That's adaptive.
[01:36:29.280 --> 01:36:41.860]   But for maladaptive, which is produced by some bad experiences typically, they think, because it's not my field, after decades of research doing it slightly differently, it can make it worse, which you don't want to do.
[01:36:42.160 --> 01:36:45.720]   But they've now found a path to rewire the brain and restore people.
[01:36:45.720 --> 01:36:48.020]   People can now go on an airplane safely if you go get the therapy.
[01:36:48.020 --> 01:36:48.560]   It costs some money.
[01:36:48.560 --> 01:36:49.260]   You've got to work with the therapist.
[01:36:49.260 --> 01:36:51.080]   But you can change your brain back.
[01:36:51.080 --> 01:36:54.280]   And if you don't do it right, you'll have that fear for the rest of your life.
[01:36:54.280 --> 01:36:55.360]   That'll be part of your personality.
[01:36:55.900 --> 01:36:57.580]   Now we learn you can make that change.
[01:36:58.580 --> 01:37:07.820]   For people with post-traumatic stress disorder, a similar therapy, cognitive processing therapy or prolonged exposure therapy, will cure about 40% of people.
[01:37:07.820 --> 01:37:08.820]   That's fantastic.
[01:37:08.820 --> 01:37:12.080]   Sexual assault, a war, go get therapy.
[01:37:12.080 --> 01:37:15.240]   You've got a good chance of being cured and never having this problem again.
[01:37:15.240 --> 01:37:15.920]   That's fantastic.
[01:37:15.920 --> 01:37:16.860]   That didn't used to be the case.
[01:37:16.860 --> 01:37:18.280]   It used to be 20%.
[01:37:18.280 --> 01:37:20.740]   They made some changes and bumped it up to 40%.
[01:37:20.740 --> 01:37:24.280]   For military, it's about 20% chance.
[01:37:24.280 --> 01:37:25.200]   It's a little bit worse.
[01:37:25.200 --> 01:37:28.200]   It works less well in military populations for a reason we don't really understand yet.
[01:37:28.200 --> 01:37:31.720]   But the idea that a cure is possible, that's amazing.
[01:37:31.720 --> 01:37:33.180]   If we could have a cure, that's what people want.
[01:37:33.180 --> 01:37:33.700]   They want cures.
[01:37:33.700 --> 01:37:34.400]   They don't want to be a little better.
[01:37:34.400 --> 01:37:35.500]   They want a cure.
[01:37:35.500 --> 01:37:46.380]   And so for some of the mental health conditions, not the ones we chose necessarily, but some of the ones we stumbled upon, we found that that that rewiring of the brain is so possible that you can take symptoms and push them all the way to zero.
[01:37:47.460 --> 01:37:50.940]   But what happens if you're in that group where you're in the 60%?
[01:37:50.940 --> 01:37:52.400]   You go to the therapy.
[01:37:52.400 --> 01:37:53.520]   You relive.
[01:37:53.520 --> 01:37:54.360]   You work with the therapist.
[01:37:54.360 --> 01:37:55.220]   You go through all this stuff.
[01:37:55.220 --> 01:37:55.840]   You do all the work.
[01:37:55.840 --> 01:37:58.300]   And you still have intrusive nightmares.
[01:37:58.300 --> 01:38:00.700]   You still have great fear of this.
[01:38:00.700 --> 01:38:06.020]   You still have a pounding heart, hypervigilance, avoidant behavior, all the hallmark signs of post-traumatic stress disorder.
[01:38:06.020 --> 01:38:07.180]   What do you do there?
[01:38:07.180 --> 01:38:09.260]   And you can't blame the psychologist.
[01:38:09.260 --> 01:38:10.120]   You can't blame the patient.
[01:38:10.120 --> 01:38:11.280]   They've done what they can do.
[01:38:11.280 --> 01:38:14.720]   We now come to neuroscience and say, well, what are the new avenues?
[01:38:14.720 --> 01:38:15.840]   What do you guys understand?
[01:38:16.240 --> 01:38:17.520]   How could it get stuck?
[01:38:17.520 --> 01:38:18.780]   How could it be broken?
[01:38:18.780 --> 01:38:20.380]   And we used to think it was demons.
[01:38:20.380 --> 01:38:23.480]   Then we thought it was humors that are wrong, high or low.
[01:38:23.480 --> 01:38:24.760]   Now we think it's wires.
[01:38:24.760 --> 01:38:27.100]   And the answer is those wires are hard to change.
[01:38:27.100 --> 01:38:28.460]   Neuronal wires.
[01:38:28.460 --> 01:38:30.380]   The neuronal wires, these synaptic connections.
[01:38:30.380 --> 01:38:31.900]   It's hard to find the right one.
[01:38:31.900 --> 01:38:33.620]   How is that?
[01:38:33.620 --> 01:38:35.360]   There's 150 trillion of them.
[01:38:35.360 --> 01:38:37.960]   Which ones are that sexual assault?
[01:38:37.960 --> 01:38:40.120]   Which ones are that IED attack?
[01:38:40.120 --> 01:38:41.320]   I don't know.
[01:38:41.320 --> 01:38:42.140]   You don't know.
[01:38:42.880 --> 01:38:45.780]   But can we go through and develop a process to help work through?
[01:38:45.780 --> 01:38:58.880]   And that's what we've been doing, developing the tools where we use what we've learned in the lab, not with a deep brain stimulating electrode as I did before, but now switching and saying, is there any other way we can trigger a brief burst?
[01:38:59.160 --> 01:39:01.860]   Not of one neurotransmitter, but of a bunch of neurotransmitters.
[01:39:01.860 --> 01:39:10.940]   And one way we came upon is this way of using an electrode placed on the vagus nerve to trick the brain into thinking you're having a heart attack.
[01:39:10.940 --> 01:39:12.120]   We only activate a few cells.
[01:39:12.120 --> 01:39:13.520]   It's a very tiny current.
[01:39:14.360 --> 01:39:21.180]   But normally your brain receives a signal saying, my heart beat, my heart beat, my heart beat, my heart beat, my lungs expanded, my lungs expanded, my lungs expanded.
[01:39:21.180 --> 01:39:22.820]   And we say, oh, they didn't do that.
[01:39:22.820 --> 01:39:26.240]   It turns out that sends a powerful subconscious.
[01:39:26.240 --> 01:39:27.420]   You're not aware of it when it happens.
[01:39:27.420 --> 01:39:31.260]   But a very transient brief arousal signal.
[01:39:31.260 --> 01:39:33.160]   If you've got sleep apnea, it'll wake you up.
[01:39:33.160 --> 01:39:36.020]   If you're not breathing, someone says, hey, wait, you're not breathing.
[01:39:36.020 --> 01:39:36.840]   We should wake you up.
[01:39:36.840 --> 01:39:39.080]   You can wait for the hypoxia to set in or you can do it quicker.
[01:39:39.080 --> 01:39:41.000]   This is a much faster signal.
[01:39:41.000 --> 01:39:48.520]   And when we trigger a brief burst, just half a second long, that makes three out of four of those neurotransmitters active.
[01:39:48.520 --> 01:39:49.180]   Which ones?
[01:39:49.180 --> 01:39:52.520]   Norepinephrine, acetylcholine, and serotonin are all released.
[01:39:52.520 --> 01:39:54.720]   Interestingly, dopamine is not even activated.
[01:39:54.720 --> 01:39:57.340]   Rats don't like it or avoid it.
[01:39:57.340 --> 01:39:59.080]   Humans don't like it or avoid it.
[01:39:59.080 --> 01:40:01.480]   It just doesn't matter because it's all subconscious.
[01:40:01.480 --> 01:40:03.880]   Knowing what your guts are doing, your heart and lungs, who cares?
[01:40:03.880 --> 01:40:08.580]   So that one is not connected to a rewarding pathway.
[01:40:08.580 --> 01:40:09.640]   We're not aware of it.
[01:40:09.640 --> 01:40:15.260]   But the combination of releasing those three neurotransmitters activates the appropriate chemistry.
[01:40:15.260 --> 01:40:17.520]   It's the signal that the neuron is looking for.
[01:40:17.520 --> 01:40:19.580]   And no, it's not any one signal.
[01:40:19.580 --> 01:40:28.480]   It's a cocktail, as most things in the immune system are, or bone formation, or even regulating your hunger.
[01:40:28.480 --> 01:40:30.120]   There's not one factor for anything.
[01:40:30.120 --> 01:40:31.720]   There's ten factors for everything.
[01:40:32.220 --> 01:40:35.520]   Now that we're learning that and embracing it, we can send this signal in.
[01:40:35.520 --> 01:40:44.000]   And at first, it was just a dumb experiment, repeating the one we had done with deep brain stimulation, showing we could quadruple the number of neurons that produced a response to a given tone.
[01:40:44.700 --> 01:40:47.020]   That's a neat laboratory curiosity, but what's it useful for?
[01:40:47.020 --> 01:40:48.920]   Well, let's take our time.
[01:40:48.920 --> 01:40:52.040]   Can we make neurons have more neurons for a low tone or a high tone?
[01:40:52.040 --> 01:40:52.700]   Yes, we can.
[01:40:52.700 --> 01:40:54.860]   Can we make neurons get faster or slower?
[01:40:54.860 --> 01:40:55.580]   Yes, we can.
[01:40:55.580 --> 01:40:58.640]   We even played speech sounds to rats.
[01:40:58.640 --> 01:40:59.860]   Rats don't care about English.
[01:40:59.860 --> 01:41:00.660]   It doesn't matter to them.
[01:41:00.660 --> 01:41:01.540]   It's not relevant to them.
[01:41:01.900 --> 01:41:11.400]   But if you repeatedly pair the word dad or the word sad, the neurons will shift to favor responding to a human saying dad or a human saying sad.
[01:41:11.400 --> 01:41:11.980]   It just makes sense.
[01:41:11.980 --> 01:41:13.540]   That's the statistical probability.
[01:41:13.540 --> 01:41:14.520]   It matters to them.
[01:41:14.520 --> 01:41:21.580]   My dog understands some English, not all of it, but the ones that are walk and treat and dinner and bed, all those are sit.
[01:41:21.580 --> 01:41:23.100]   Those are all things that she knows.
[01:41:23.100 --> 01:41:25.980]   We saw the neurons making those same changes.
[01:41:25.980 --> 01:41:30.780]   And this began to get us more and more optimistic that you could use it to treat some condition.
[01:41:31.400 --> 01:41:40.180]   We've now shown in humans that you can use physical therapy, occupational therapy, cognitive behavioral therapy, and sensory therapy, all of which activate neurons.
[01:41:40.180 --> 01:41:45.520]   But they don't make enough change to get people to lose their diagnosis.
[01:41:45.520 --> 01:41:54.980]   We're still not there yet, but we've now gone all the way through animal studies showing that animals with stroke benefit from physical therapy, but they don't make a complete recovery.
[01:41:54.980 --> 01:41:58.940]   When we add this brief burst, they make recoveries they couldn't otherwise make.
[01:41:59.480 --> 01:42:01.340]   We did it with hemorrhagic stroke.
[01:42:01.340 --> 01:42:02.480]   We did it with ischemic stroke.
[01:42:02.480 --> 01:42:04.320]   We did it with peripheral nerve injury.
[01:42:04.320 --> 01:42:05.620]   We did it with spinal cord injury.
[01:42:05.620 --> 01:42:11.400]   And we finally said, this is working so well, we should go try this in humans, fully expecting it not to work.
[01:42:11.400 --> 01:42:12.980]   Why would it not work?
[01:42:12.980 --> 01:42:14.280]   Because it usually doesn't work.
[01:42:14.280 --> 01:42:17.240]   Lots of things work under careful laboratory conditions.
[01:42:17.240 --> 01:42:20.700]   And you show up in the real world, and you're stymied.
[01:42:20.700 --> 01:42:21.700]   You can't figure this out.
[01:42:21.920 --> 01:42:28.280]   And one reason for that is because in the lab, we can adjust the condition to be just bad enough, and the treatment can be very powerful, and there's no side effects and all this stuff.
[01:42:28.280 --> 01:42:30.140]   Doctors get patients who show up.
[01:42:30.140 --> 01:42:30.900]   They get the car accident.
[01:42:30.900 --> 01:42:31.520]   They get what they get.
[01:42:31.520 --> 01:42:33.380]   They don't get to make it and adjust it.
[01:42:33.380 --> 01:42:37.680]   So it was very humbling to try to ask the first participants.
[01:42:37.680 --> 01:42:41.300]   The first ones actually had tinnitus or tinnitus, the ringing of the ears.
[01:42:41.300 --> 01:42:45.780]   Later participants had stroke, now spinal cord injury, and post-traumatic stress disorder.
[01:42:46.020 --> 01:42:50.160]   In each case, it's super scary because we start off with a 99% chance of failure.
[01:42:50.160 --> 01:42:52.800]   That's the chance a given new idea in neuroscience works.
[01:42:52.800 --> 01:42:53.800]   Don't worry.
[01:42:53.800 --> 01:42:54.600]   We've got lots of ideas.
[01:42:54.600 --> 01:42:57.060]   So we keep testing them.
[01:42:57.060 --> 01:42:59.860]   And luckily, the public has been very supportive of us.
[01:42:59.860 --> 01:43:00.440]   Just keep trying.
[01:43:00.440 --> 01:43:01.220]   Keep trying.
[01:43:01.220 --> 01:43:02.700]   That amyloid thing is not working so good for you.
[01:43:02.700 --> 01:43:03.420]   Keep trying.
[01:43:03.420 --> 01:43:04.380]   Don't give up.
[01:43:04.380 --> 01:43:05.860]   My grandmother died of Alzheimer's.
[01:43:05.860 --> 01:43:07.760]   So don't give up just because something's not working.
[01:43:07.760 --> 01:43:08.800]   Maybe it's going to work tomorrow.
[01:43:08.800 --> 01:43:10.440]   These are really hard problems.
[01:43:10.840 --> 01:43:16.060]   And now we're at a point with FDA approval three years ago of vagus nerve stimulation for
[01:43:16.060 --> 01:43:20.020]   the treatment of ischemic stroke that people can make gains they couldn't have otherwise made.
[01:43:20.020 --> 01:43:23.660]   They can try all they want, and they just can't get those fingers to work.
[01:43:23.660 --> 01:43:24.920]   Now they make gains.
[01:43:24.920 --> 01:43:25.400]   Are they cured?
[01:43:25.400 --> 01:43:25.820]   No.
[01:43:25.820 --> 01:43:27.840]   You can still tell they've got a stroke.
[01:43:27.840 --> 01:43:31.840]   But what's interesting is the gains they made in a double-blinded placebo-controlled trial
[01:43:31.840 --> 01:43:34.560]   published in Lancet is only in 18 days.
[01:43:34.560 --> 01:43:35.840]   18 days.
[01:43:35.840 --> 01:43:37.560]   You can't play violin very well in 18 days.
[01:43:37.560 --> 01:43:39.100]   You can't bowl very well in 18 days.
[01:43:39.100 --> 01:43:42.080]   In 18 days, they're returning their function of their hand.
[01:43:42.080 --> 01:43:47.660]   And now we send them home, and we enable them to activate their own vagus nerve while they're
[01:43:47.660 --> 01:43:50.860]   doing gardening activities or fishing activities or doing the dishes.
[01:43:50.860 --> 01:43:55.900]   And what we're seeing now is, although it's slower, they're continuing to make progress day
[01:43:55.900 --> 01:44:01.100]   on, day on by activating this network and telling the brain, this is really important.
[01:44:01.100 --> 01:44:02.780]   The answer is it's not really important.
[01:44:02.780 --> 01:44:03.280]   It's just gardening.
[01:44:03.280 --> 01:44:07.440]   But we have to kind of lie to the brain a little bit and say, look, you're never going to get
[01:44:07.440 --> 01:44:10.200]   over this because the brain is very conservative.
[01:44:10.200 --> 01:44:11.740]   It does not want to forget all of your memories.
[01:44:11.740 --> 01:44:14.900]   It doesn't want to forget your childhood.
[01:44:14.900 --> 01:44:16.060]   It doesn't want to forget your language.
[01:44:16.060 --> 01:44:17.120]   It doesn't want to forget all your skills.
[01:44:17.120 --> 01:44:19.380]   So it's very conservative of what it changes.
[01:44:19.380 --> 01:44:23.620]   And after injury, in this case a stroke, there's a hole in your head.
[01:44:23.620 --> 01:44:24.460]   Neurons are dead.
[01:44:24.460 --> 01:44:25.500]   There's a problem.
[01:44:25.500 --> 01:44:26.640]   I got to make big changes.
[01:44:26.640 --> 01:44:31.940]   But I wasn't expecting this because in evolution, if you get a hole in your head, you just die.
[01:44:32.560 --> 01:44:33.400]   There's no ICU.
[01:44:33.400 --> 01:44:34.920]   No one is coming to save you.
[01:44:34.920 --> 01:44:35.620]   You just die.
[01:44:35.620 --> 01:44:39.880]   And so we never had the chance to practice getting good at recovering.
[01:44:39.880 --> 01:44:42.660]   We now know we could make better gains.
[01:44:42.660 --> 01:44:47.940]   And the paper you mentioned in Nature, same thing happened with spinal cord injuries.
[01:44:47.940 --> 01:44:50.880]   People have had years ago spinal cord injuries.
[01:44:50.880 --> 01:44:52.280]   They just, they could barely move it.
[01:44:52.280 --> 01:44:53.740]   We only picked people who have some movement.
[01:44:53.740 --> 01:44:58.540]   If there's no movement, we have nothing to reward, nothing to condition, nothing to strengthen.
[01:44:58.940 --> 01:45:01.740]   So we chose people who had incomplete injuries.
[01:45:01.740 --> 01:45:04.820]   I mean, they still have some function, but they're obviously impaired.
[01:45:04.820 --> 01:45:08.160]   Then we repeatedly paired with the physical therapists.
[01:45:08.160 --> 01:45:09.000]   They're the real experts.
[01:45:09.000 --> 01:45:11.800]   They said, this is the right muscle you should be practicing with.
[01:45:11.800 --> 01:45:13.600]   There's different muscles in your hand that do different things.
[01:45:13.600 --> 01:45:16.580]   They measure what you can't do, but you can kind of do.
[01:45:16.580 --> 01:45:17.580]   And we practiced that.
[01:45:17.580 --> 01:45:20.860]   And then we, the neuroscientists, come in with an engineering approach.
[01:45:20.860 --> 01:45:23.700]   Rob Renecker built the tiny vagus nerve stimulator.
[01:45:23.700 --> 01:45:27.820]   And then we found physicians and clinicians who were like mine and said, let's give this a shot.
[01:45:28.580 --> 01:45:30.160]   And we didn't think it would work.
[01:45:30.160 --> 01:45:32.220]   It happens to have worked.
[01:45:32.220 --> 01:45:33.920]   And now there's a vagus nerve stimulator.
[01:45:33.920 --> 01:45:38.320]   Full disclosure, I'm an inventor of and shareholder.
[01:45:38.320 --> 01:45:40.160]   And my university requires me to disclose that.
[01:45:40.160 --> 01:45:43.220]   So I'll disclose that now in a company called Microtranspond.
[01:45:43.220 --> 01:45:45.760]   A little spinoff from my university, University of Texas at Dallas.
[01:45:45.760 --> 01:45:47.600]   And now you can go to your doctor.
[01:45:47.600 --> 01:45:53.040]   And he can write a prescription for you to get an implant to help your physical therapist do their job.
[01:45:53.040 --> 01:45:55.040]   It's not like the physical therapist wasn't trying.
[01:45:55.040 --> 01:45:55.720]   They were working hard.
[01:45:55.720 --> 01:45:57.420]   It's not like the person didn't want to get better.
[01:45:57.820 --> 01:46:01.440]   But the idea that you could just practice your way out of something, sometimes true.
[01:46:01.440 --> 01:46:03.360]   Many people make a complete recovery from injuries.
[01:46:03.360 --> 01:46:04.540]   But many people don't.
[01:46:04.540 --> 01:46:07.380]   And we now have this little boost, this little tool.
[01:46:07.380 --> 01:46:08.760]   I think of it like a screwdriver.
[01:46:08.760 --> 01:46:10.280]   If you're trying to fix your car, you don't have a screwdriver.
[01:46:10.280 --> 01:46:12.340]   All the knowledge in the world won't do any good.
[01:46:12.340 --> 01:46:13.940]   It doesn't do the fixing.
[01:46:13.940 --> 01:46:16.080]   But it gives you a new tool in the toolbox.
[01:46:16.500 --> 01:46:23.720]   So now physical therapists and occupational therapists can give that extra boost because physical therapy is fundamentally kind of boring.
[01:46:23.720 --> 01:46:26.080]   Move your fingers, move your fingers, move your fingers.
[01:46:26.080 --> 01:46:27.420]   It's not really life or death.
[01:46:27.420 --> 01:46:31.180]   We're adding this boost so that the neurons don't give up on it.
[01:46:31.180 --> 01:46:34.840]   It's going to take thousands of repeats and it needs to feel important.
[01:46:34.840 --> 01:46:37.760]   And when you're learning to ski, if you don't do it right, you're going to go tumble down the mountain.
[01:46:38.180 --> 01:46:40.600]   When you're a baby and you're trying to walk, you're going to hit your face.
[01:46:40.600 --> 01:46:43.060]   We're doing therapy safely.
[01:46:43.060 --> 01:46:45.140]   So no one's actually in any danger.
[01:46:45.140 --> 01:46:50.940]   But by tricking the system, hacking the vagus nerve, just these small number of stretch receptors from the heart and lungs,
[01:46:50.940 --> 01:46:58.660]   activating those which people don't typically feel, by activating those, we send the signal, release this cocktail of these three neurotransmitters.
[01:46:58.660 --> 01:47:06.000]   And now the synaptic eligibility trace, instead of letting that potential strengthening go away, it just keeps building it, building it, building it.
[01:47:06.140 --> 01:47:11.060]   And we're now seeing even years later, after people have been implanted, they're still making continual gains.
[01:47:11.060 --> 01:47:12.760]   And that's surprising.
[01:47:12.760 --> 01:47:16.720]   It seemed like they had a sentence, no more progress, you're an adult, no more plasticity.
[01:47:16.720 --> 01:47:18.520]   But that's inconsistent with what we know.
[01:47:18.520 --> 01:47:19.700]   I can learn new things anytime.
[01:47:19.700 --> 01:47:20.200]   Sure.
[01:47:20.200 --> 01:47:21.680]   But why couldn't you get better from stroke?
[01:47:21.680 --> 01:47:23.080]   The hole in your head was too great.
[01:47:23.080 --> 01:47:25.980]   Evolution didn't prepare you for that kind of injury.
[01:47:25.980 --> 01:47:32.660]   Now we're finding we can make progress, even with stroke, spinal cord injury, tendinous, and post-traumatic stress disorder.
[01:47:32.660 --> 01:47:34.120]   Amazing.
[01:47:34.120 --> 01:47:35.620]   And I have many questions.
[01:47:35.780 --> 01:47:42.740]   So I want to first just briefly rewind to the topic of neuromodulators and just clear one thing up for myself.
[01:47:42.740 --> 01:47:44.240]   It's really a question.
[01:47:44.240 --> 01:47:56.520]   I have to say I'm fascinated and surprised by the fact that whether you stimulate the release of acetylcholine or dopamine or serotonin or norepinephrine,
[01:47:56.520 --> 01:48:03.880]   you get the same effect, which is essentially you get more plasticity from fewer effort trials.
[01:48:04.040 --> 01:48:11.000]   Basically, you get the kind of changes in the brain and learning that would occur over the course of many weeks or months.
[01:48:11.000 --> 01:48:19.460]   You can condense down to days.
[01:48:19.460 --> 01:48:38.260]   And so many favorite papers in your science paper stimulating nucleus basalis while exposing animals to an eight kilohertz tone, I believe it was, and showing this massive rewiring of the adult auditory cortex to overrepresent that tone.
[01:48:38.420 --> 01:48:45.380]   So when I saw those images, I can still see them in my mind, blue and purple, and I know exactly what they look like, and it's just like, wow.
[01:48:45.380 --> 01:48:49.220]   That was – it went against everything we had learned in our neuroscience textbooks.
[01:48:49.220 --> 01:48:51.040]   This wasn't supposed to be possible, right?
[01:48:51.040 --> 01:48:52.380]   Critical periods are over.
[01:48:52.380 --> 01:48:53.660]   These are adult animals.
[01:48:53.660 --> 01:48:54.280]   It shouldn't happen.
[01:48:54.280 --> 01:49:04.540]   And then when I learned about the Reconzone and Merzenich work that you were talking about of whatever the subjects are attending to, either touch or hearing, that's where the plasticity occurred.
[01:49:04.540 --> 01:49:07.040]   And just to this day blows my mind.
[01:49:07.720 --> 01:49:19.260]   I assumed it was all governed by acetylcholine, and I have a bunch of pet theories in my mind now about why nature as a tinkerer might have come up with different circuits that could do that.
[01:49:19.260 --> 01:49:25.340]   But we'll save that for, you know, over a coffee offline discussion because it would just be a wandering discussion.
[01:49:25.340 --> 01:49:43.820]   However, there is this parallel universe to the one that you exist in with neurostimulation, which is that many, many people are interested in taking drugs, prescription or otherwise, that they can use to open the door to and enhance neuroplasticity.
[01:49:43.820 --> 01:49:48.920]   And I've been positively struck by the data on psychedelics.
[01:49:48.920 --> 01:49:58.860]   Traditionally, the psychedelics are LSD, lysergic acid, diethylamide, and psilocybin, both of which augment serotonin, act through specific receptors.
[01:49:58.860 --> 01:50:05.840]   And the data there from the clinical trials speak to pretty impressive results in some trials in relieving major depression.
[01:50:05.840 --> 01:50:10.540]   MDMA, methylene, dioxane, methamphetamine.
[01:50:11.640 --> 01:50:17.400]   Amphetamine, we have to remind people these are illegal drugs, Schedule I drugs, at least currently.
[01:50:17.400 --> 01:50:29.840]   Pretty impressive results for treatment of PTSD, provided in all these cases that you have proper therapeutic support going into these sessions during and afterwards.
[01:50:29.840 --> 01:50:32.180]   We're not talking about people just taking these recreationally.
[01:50:32.180 --> 01:50:39.140]   When I saw those data, I just kind of went, okay, well, it's neuromodulators opening the window to plasticity.
[01:50:40.060 --> 01:50:47.620]   When I think about neurostimulation now, the way you're describing it, I think, okay, it's an electrode or a microelectrode or whatever it is, stimulating plasticity.
[01:50:47.820 --> 01:51:04.580]   And when I think of somebody working as hard as they possibly can without it, ingesting any psychedelics or any neurostimulator in the therapist's office week after week, or these people who have a stroke or a spinal cord injury just doing their physical therapy, just working as hard as they can to try and recover any kind of movement.
[01:51:04.580 --> 01:51:10.980]   I think of the same thing, they're just neuroplasticity, they're trying to get that little squirt of acetylcholine out in their brain.
[01:51:10.980 --> 01:51:20.180]   And then, of course, there's this other parallel universe of people who augment acetylcholine through now oral nicotine, right?
[01:51:20.180 --> 01:51:22.680]   Stimulate nicotinic acetylcholine receptor.
[01:51:24.020 --> 01:51:25.100]   And on and on.
[01:51:25.100 --> 01:51:34.820]   And so it seems to me that the requirements, this is an and gate type arrangement, you need neuromodulator present.
[01:51:35.580 --> 01:51:43.960]   You need a particular pattern of firing in the neurons so that there's a chance that they wire together or wire apart, whatever you're trying to drive the circuit to do.
[01:51:43.960 --> 01:51:46.780]   And you need a strong intention.
[01:51:46.780 --> 01:51:50.480]   You need that friction focus from the person.
[01:51:50.480 --> 01:51:54.020]   So on the one hand, it seems like we need specificity.
[01:51:54.020 --> 01:52:00.900]   And that's where we're going to go next, talking about the vagal stimulators that you work on and are getting such incredible results with.
[01:52:01.440 --> 01:52:06.640]   But on the other side of the coin, it's like you just need these chemicals present.
[01:52:06.640 --> 01:52:18.940]   So, for instance, if I want to learn something and I'm going to focus as hard as I can on it, I will occasionally take, you know, two – these are very low doses – two milligrams of nicotine.
[01:52:18.940 --> 01:52:19.780]   I don't do this lately.
[01:52:19.780 --> 01:52:27.560]   I just did an experiment last year where I was – I didn't like it because it made my throat spasm a little bit when I wasn't taking the gum.
[01:52:27.560 --> 01:52:31.280]   The muscarinic receptor business explains that.
[01:52:31.280 --> 01:52:32.780]   So I stopped.
[01:52:32.780 --> 01:52:35.560]   But, yeah, it provides a stimulant effect.
[01:52:35.560 --> 01:52:37.140]   But here's my question.
[01:52:37.140 --> 01:52:47.860]   If we just globally raise acetylcholine by taking a drug, do you get the opposite effect as you get from globally decreasing acetylcholine activity by taking a drug, which you said makes you forget?
[01:52:47.860 --> 01:52:55.120]   If you just globally raise acetylcholine by taking – I don't know what's a good example of a drug that will do that for an Alzheimer's patient or for –
[01:52:55.120 --> 01:52:56.920]   I mean, all of the drugs of abuse will increase –
[01:52:56.920 --> 01:52:57.320]   Nicotine.
[01:52:57.320 --> 01:52:57.520]   Yeah.
[01:52:57.520 --> 01:53:00.980]   All of the drugs of abuse will increase acetylcholine as well as increasing dopamine.
[01:53:00.980 --> 01:53:02.980]   Or dopamine, apomorphine.
[01:53:02.980 --> 01:53:03.320]   Yep.
[01:53:03.320 --> 01:53:07.800]   Apomorphine, you know, people take apomorphine for various reasons.
[01:53:07.800 --> 01:53:09.220]   It improves the working memory.
[01:53:09.360 --> 01:53:13.100]   We know this, at least in the short term, for people that have modest to low dopamine going in.
[01:53:13.100 --> 01:53:15.020]   If you already have high dopamine, probably not going to do much.
[01:53:15.020 --> 01:53:22.420]   But it sounds like you just need to boost a neuromodulator or some small cocktail of these four neuromodulators.
[01:53:22.420 --> 01:53:29.120]   And the opportunity for plasticity does indeed expand, regardless of the entry point that you take.
[01:53:29.520 --> 01:53:30.840]   Is that your view as well?
[01:53:30.840 --> 01:53:36.500]   Because you're working in an area where – and by the way, I brought along one of these stimulators to this recording.
[01:53:36.500 --> 01:53:39.060]   Michael was kind enough to give me one.
[01:53:39.060 --> 01:53:39.660]   I don't know.
[01:53:39.660 --> 01:53:42.160]   Did you give this to me or are you taking it back to Texas with you?
[01:53:42.160 --> 01:53:42.460]   Okay.
[01:53:42.460 --> 01:53:44.020]   This thing is smaller.
[01:53:44.020 --> 01:53:48.800]   This is a little chip that is smaller than my pinky nail.
[01:53:48.800 --> 01:53:50.980]   I'll hold it up for the camera.
[01:53:50.980 --> 01:53:56.380]   We can provide a link to an image of it in the show note captions for those of you who are listening.
[01:53:56.380 --> 01:53:57.240]   It's tiny, tiny.
[01:53:57.240 --> 01:53:57.660]   Yeah.
[01:53:58.040 --> 01:54:02.520]   This would be inserted about three centimeters deep in an outpatient thing, in and out of the clinic.
[01:54:02.520 --> 01:54:09.040]   Probably less painful than a dental cleaning, especially if you like going to the dentist as little as I do.
[01:54:09.040 --> 01:54:13.720]   This thing is all about specificity.
[01:54:13.720 --> 01:54:15.760]   It's all about not having to take a drug.
[01:54:15.760 --> 01:54:16.300]   Yep.
[01:54:16.300 --> 01:54:17.540]   Where's the tradeoff?
[01:54:17.540 --> 01:54:18.460]   What are the benefits?
[01:54:18.460 --> 01:54:25.520]   What are the drawbacks of going with a microstimulator versus – I don't know.
[01:54:25.660 --> 01:54:28.620]   I'm not saying people should run out and take psilocybin or apomorphine.
[01:54:28.620 --> 01:54:34.020]   But by the logic that you just need an increase in a neuromodulator, it works.
[01:54:34.020 --> 01:54:35.900]   My background was in biochemistry.
[01:54:35.900 --> 01:54:37.640]   My degree from Berkeley is in biochemistry.
[01:54:37.640 --> 01:54:40.040]   I just thought, let's get the biochemistry right and people will get better.
[01:54:40.680 --> 01:54:42.100]   And then I had to learn about the brain.
[01:54:42.100 --> 01:54:44.100]   And the brain says it's the timing.
[01:54:44.100 --> 01:54:49.080]   The psychologists have told us at the very beginning, timing, timing, timing, timing, timing, just back to Pavlov.
[01:54:49.080 --> 01:54:49.900]   You can ring the bell.
[01:54:49.900 --> 01:54:51.340]   You can feed the dog.
[01:54:51.340 --> 01:54:53.060]   But they have to happen at the same time.
[01:54:53.700 --> 01:54:58.140]   And if you just reward everything, that's similar to rewarding nothing.
[01:54:58.140 --> 01:55:05.440]   So the real issue – and I actually spent more than five years of my life trying to do this without a device.
[01:55:05.440 --> 01:55:08.220]   So I had had success using the deep brain stimulator.
[01:55:08.220 --> 01:55:10.000]   I said, I don't want to put deep brain stimulators.
[01:55:10.000 --> 01:55:12.560]   I can't imagine putting hundreds of thousands of people with deep brain stimulators.
[01:55:12.560 --> 01:55:14.000]   It seemed like too much to be true.
[01:55:14.000 --> 01:55:16.300]   Many neurosurgeons say it's safe, no problem.
[01:55:16.300 --> 01:55:18.420]   But I just thought there's got to be an easier way.
[01:55:18.420 --> 01:55:20.000]   And so I did exactly what you said.
[01:55:20.000 --> 01:55:29.480]   I said, what are the ways to increase acetylcholine, norepinephrine, serotonin, microdialysis, made it clear which things do it, amphetamine, of course, nicotine, all these things, very easy, cocaine, all these things do it.
[01:55:29.480 --> 01:55:32.820]   And I did experiment after experiment after experiment after experiment.
[01:55:32.820 --> 01:55:35.720]   I still feel bad for the graduate students who did all of those experiments.
[01:55:35.720 --> 01:55:36.420]   Adderall.
[01:55:36.420 --> 01:55:39.080]   Did Adderall, did all of them, paired with a tone.
[01:55:39.080 --> 01:55:40.980]   And it just didn't change anything.
[01:55:40.980 --> 01:55:44.420]   And that's because the tone only comes on once in a while.
[01:55:45.060 --> 01:55:46.340]   And they're just ongoing activity.
[01:55:46.340 --> 01:55:46.920]   Neurons are firing.
[01:55:46.920 --> 01:55:48.280]   If you record neurons, they're firing all the time.
[01:55:48.280 --> 01:55:51.720]   Only one action potential is the tone exponential.
[01:55:51.720 --> 01:55:57.380]   The neurons firing at 4 or 5 hertz, sometimes 20 hertz, just popping along all the time.
[01:55:57.380 --> 01:56:01.900]   And then you get one more spike when you record these neurons, when a drifting gradient goes by or a scene or whatever.
[01:56:01.900 --> 01:56:02.900]   It's not much more.
[01:56:02.900 --> 01:56:05.380]   Spike is action potential, electrical firing of neurons.
[01:56:05.380 --> 01:56:06.240]   We should just clarify that.
[01:56:06.240 --> 01:56:06.820]   Yeah, thank you.
[01:56:06.820 --> 01:56:10.420]   And so how does the brain know which thing?
[01:56:10.420 --> 01:56:13.140]   There's 150 trillion connections.
[01:56:13.800 --> 01:56:15.420]   Which one am I asking for more of?
[01:56:15.420 --> 01:56:17.420]   You've got to tell me which.
[01:56:17.420 --> 01:56:18.400]   Everything.
[01:56:18.400 --> 01:56:19.800]   Make more of everything.
[01:56:19.800 --> 01:56:21.860]   That doesn't help the network work very well.
[01:56:21.860 --> 01:56:29.100]   So my understanding, the world that I live in, is sort of a post-Aristotle, forhumors idea.
[01:56:29.100 --> 01:56:31.200]   It's not that there's too little or too much of these things.
[01:56:31.200 --> 01:56:32.680]   It's the timing that matters.
[01:56:32.680 --> 01:56:35.560]   And when I watch a really good coach, they're really into that.
[01:56:35.560 --> 01:56:36.780]   They're going, that was it.
[01:56:36.780 --> 01:56:37.880]   That thing right there.
[01:56:37.880 --> 01:56:39.140]   That's what I want you to pay attention to.
[01:56:39.480 --> 01:56:41.740]   And back to the reflection thing, let's think back.
[01:56:41.740 --> 01:56:45.040]   That was the part where you were at ease there or whatever it was.
[01:56:45.040 --> 01:56:46.600]   There were these moments of learning.
[01:56:46.600 --> 01:56:53.400]   And, of course, there's an hour of heavy working out, you know, whatever it is, on Spanish verbs or on rock climbing.
[01:56:53.400 --> 01:56:56.440]   But there's these moments where you're figuring out that was the connection.
[01:56:56.440 --> 01:56:58.040]   We sometimes call them aha moments.
[01:56:58.480 --> 01:57:01.480]   And we think maybe the neuromodulor is being released at that aha moment.
[01:57:01.480 --> 01:57:02.200]   They are.
[01:57:02.200 --> 01:57:03.800]   I can tell you a lot of experiments have been done.
[01:57:03.800 --> 01:57:09.460]   When you're having a, oh, my God, something just happened, those neurons are having exposure to those neurotransmitters.
[01:57:09.460 --> 01:57:17.160]   So then the question is, why doesn't it work that the brain rewires for that particular tone?
[01:57:17.160 --> 01:57:18.480]   It kind of does.
[01:57:18.480 --> 01:57:19.680]   It's not that it doesn't work at all.
[01:57:20.020 --> 01:57:25.280]   And as you said, some conditions are so bad that you can do very non-selective things.
[01:57:25.280 --> 01:57:29.860]   And the classic example would be if you have major depressive disorder and you do electroconvulsive therapy.
[01:57:29.860 --> 01:57:32.540]   We're not pushing your brain toward any particular goal.
[01:57:32.540 --> 01:57:36.040]   We're triggering a seizure in the brain.
[01:57:36.040 --> 01:57:37.520]   It's going to change the brain.
[01:57:37.520 --> 01:57:39.320]   But we're not telling it which way to go.
[01:57:40.000 --> 01:57:47.220]   And somehow people tend to recover from that in a better state than they went into it because it was so bad to begin with.
[01:57:47.220 --> 01:57:49.960]   What are the statistics on electroconvulsive therapy?
[01:57:49.960 --> 01:58:00.320]   I mean, some of us are familiar with the end of, you know, one flew over the cuckoo's nest where Jack Nicholson's getting, you know, he's bite barred into the process and coming out like a vegetable.
[01:58:00.320 --> 01:58:02.200]   That's not what happens, right?
[01:58:02.200 --> 01:58:04.760]   Most people emerge from it pretty intact.
[01:58:04.760 --> 01:58:08.800]   And you're saying much better in terms of their overall mood.
[01:58:09.340 --> 01:58:11.520]   What percentage go into remission?
[01:58:11.520 --> 01:58:13.300]   What percentage feel significantly better?
[01:58:13.300 --> 01:58:18.320]   So we don't know the answer to that because the randomized control trials were not done at that time.
[01:58:18.320 --> 01:58:24.560]   My colleagues who are psychiatrists say it's the most effective thing we have for people who are treatment resistant to all the other treatments.
[01:58:24.560 --> 01:58:26.240]   So I don't have an answer for you.
[01:58:26.240 --> 01:58:27.700]   Normally we do a sham control.
[01:58:27.700 --> 01:58:29.640]   These people are anesthetized when it happens.
[01:58:29.640 --> 01:58:30.780]   So they would never know which one happened.
[01:58:30.780 --> 01:58:31.780]   The study is easy to do.
[01:58:31.780 --> 01:58:34.160]   It's just you can't do it in rats because rats don't have depression.
[01:58:34.160 --> 01:58:36.920]   And right now no one is signing up.
[01:58:37.000 --> 01:58:41.040]   If you have a sign up for actual therapy or a 50% chance of getting a therapy, people tend not to sign up.
[01:58:41.040 --> 01:58:42.380]   So the answer is not known.
[01:58:42.740 --> 01:58:46.420]   If we did, we'd get a responder rate in both groups.
[01:58:46.420 --> 01:58:49.960]   We'd say let's say it's 60% or 50% response rate where they're better.
[01:58:49.960 --> 01:58:51.960]   And we get a sham response rate.
[01:58:51.960 --> 01:58:54.000]   Let's say it's 25% get better even when you don't do it.
[01:58:54.000 --> 01:58:59.760]   You'd subtract those two, which is 25%, take the inverse of that, and you'd get a number needed to treat a four.
[01:59:00.660 --> 01:59:02.520]   That's how we now work on these medications.
[01:59:02.520 --> 01:59:07.200]   We think about what's the difference in the percent that you're going to get better with a double-blinded placebo control.
[01:59:07.200 --> 01:59:08.320]   That data is not available.
[01:59:08.320 --> 01:59:11.980]   But the general idea is the symptoms are clear.
[01:59:11.980 --> 01:59:15.960]   People, the day before that happens, all those memories are gone.
[01:59:15.960 --> 01:59:17.460]   You'll have no memories whatsoever.
[01:59:17.460 --> 01:59:20.060]   So people do this 20 times as they typically do.
[01:59:20.060 --> 01:59:22.580]   They'll lose 20 days of their life, which they never get back.
[01:59:22.820 --> 01:59:24.780]   20 times they have to go through the ECT.
[01:59:24.780 --> 01:59:26.600]   Many people will do it on a regular basis.
[01:59:26.600 --> 01:59:30.240]   As you mean, electric shock therapy, ESG, 20 times?
[01:59:30.240 --> 01:59:30.480]   Yes.
[01:59:30.480 --> 01:59:30.940]   Yeah.
[01:59:30.940 --> 01:59:32.420]   Oh, I thought they'd just go in once.
[01:59:32.420 --> 01:59:34.140]   Typically sessions of three is my understanding.
[01:59:34.140 --> 01:59:38.020]   Again, I'm not a practicing psychiatrist, so take this, talk with your own physician.
[01:59:38.020 --> 01:59:39.600]   Typically you do a sequence of them.
[01:59:39.600 --> 01:59:45.960]   People, as you know, major depression, have sort of a cycling pattern, as most neurological disorders and psychiatric disorders do.
[01:59:45.960 --> 01:59:47.840]   So they'll go in during a time when they're bad.
[01:59:47.840 --> 01:59:51.020]   Now, if you do nothing, they'll tend to be better later because you went in when they were worse.
[01:59:51.860 --> 01:59:56.260]   But the evidence, experience from colleagues I trust is this is really working.
[01:59:56.260 --> 01:59:57.600]   We've tried everything else.
[01:59:57.600 --> 02:00:00.980]   And I don't know because the studies have not been done.
[02:00:00.980 --> 02:00:04.480]   We don't have the answer what the exact probabilities are, unlike the other studies.
[02:00:04.480 --> 02:00:07.900]   We've done lots of randomized controlled trials with cognitive behavioral therapy.
[02:00:07.900 --> 02:00:10.600]   But the idea is you get a benefit.
[02:00:10.600 --> 02:00:11.860]   But it's just suggestive.
[02:00:11.860 --> 02:00:13.360]   This is still a pretty crude technology.
[02:00:13.360 --> 02:00:15.620]   And practitioners of it, they're more than happy to acknowledge that.
[02:00:15.620 --> 02:00:18.520]   They want the seizure to not be too bad because it's too bad.
[02:00:18.520 --> 02:00:20.840]   So they have ways to start the seizure and then stop the seizure.
[02:00:20.960 --> 02:00:24.540]   They've optimized it so it's more effective now than it was in the Jack Nicholson days.
[02:00:24.540 --> 02:00:28.680]   It's not painful anymore because people are anesthetized when it happens.
[02:00:28.680 --> 02:00:29.660]   You don't need to be awake.
[02:00:29.660 --> 02:00:30.560]   You don't need to experience it.
[02:00:30.560 --> 02:00:31.560]   That wasn't an active ingredient.
[02:00:31.560 --> 02:00:35.780]   What was an active ingredient is the seizure, which is a storm of brains.
[02:00:35.780 --> 02:00:39.620]   It's called a brain attack where neurons are firing synchronously all over the brain
[02:00:39.620 --> 02:00:42.360]   and releasing massive amounts of neurotransmitters at the same time.
[02:00:42.360 --> 02:00:44.460]   That's generally something you don't want.
[02:00:44.460 --> 02:00:47.300]   If you had a choice to have a seizure or not to have a seizure, you would choose not to have a seizure.
[02:00:47.740 --> 02:00:49.300]   If you had a child, you'd rather not have a seizure.
[02:00:49.300 --> 02:00:56.540]   But if someone is really stuck in a severe state and they're at risk harming themselves,
[02:00:56.540 --> 02:01:01.260]   it's been determined by powers that be that it's better to try this.
[02:01:01.380 --> 02:01:10.120]   And many people voluntarily do it, lose a few days, get better for months, and then come back and cycle and do it again.
[02:01:10.120 --> 02:01:13.720]   So that idea is not a ringing endorsement.
[02:01:13.720 --> 02:01:16.160]   The fact that if you do it again, it's not a cure.
[02:01:16.160 --> 02:01:18.280]   It wasn't pushing you toward any particular thing.
[02:01:18.280 --> 02:01:22.620]   I've got a number of things in my house that work kind of well.
[02:01:22.620 --> 02:01:24.600]   And if you give them a good whack across the top of it, it will start off.
[02:01:24.600 --> 02:01:25.700]   A motor that kind of sticks.
[02:01:25.700 --> 02:01:26.700]   You give it a kind of whack.
[02:01:26.840 --> 02:01:27.940]   But I'm not really fixing it.
[02:01:27.940 --> 02:01:30.320]   I need to grease some bearing or something.
[02:01:30.320 --> 02:01:31.900]   But whacking it will also work.
[02:01:31.900 --> 02:01:36.880]   So I think of this as, again, the Gilligan's Island, I think a coconut would fall on your head and you'd suddenly be better.
[02:01:36.880 --> 02:01:38.640]   That's the level of sophistication.
[02:01:38.640 --> 02:01:42.700]   But the proof of concept is it's the plasticity that's making them better.
[02:01:42.700 --> 02:01:48.120]   We used to think that selective serotonin reuptake inhibitors worked by increasing serotonin.
[02:01:48.120 --> 02:01:50.200]   Therefore, we concluded people's serotonin was low with depression.
[02:01:50.200 --> 02:01:52.200]   And yet, behold, they don't have low depression.
[02:01:52.200 --> 02:01:53.800]   It's a plasticity tool.
[02:01:53.800 --> 02:01:58.320]   This is so important for people to hear because I think SSRIs have been demonized.
[02:01:58.320 --> 02:02:00.000]   And they do indeed have side effects.
[02:02:00.000 --> 02:02:01.700]   They've also helped a lot of people with OCD.
[02:02:01.700 --> 02:02:05.160]   But they are a tool to induce plasticity.
[02:02:05.160 --> 02:02:11.260]   And then it becomes a question of what other things are you doing to try and promote plasticity in a particular direction?
[02:02:11.600 --> 02:02:18.660]   I actually think it's an unresolved question as to whether or not things like psilocybin and other psychedelics – MDMA is not really a psychedelic.
[02:02:18.660 --> 02:02:19.720]   It's an empathogen.
[02:02:19.720 --> 02:02:32.980]   But whether or not the experience that one has during the so-called journey or trip is actually the source of the change or whether it's the augmentation in serotonin and then the things that happen afterwards.
[02:02:32.980 --> 02:02:38.680]   My guess is it's probably both because those sessions tend to be very emotionally laden.
[02:02:38.680 --> 02:02:46.140]   And so there's a lot of talk therapy work that can be done with a qualified therapist that carries immense emotional load.
[02:02:46.140 --> 02:02:50.260]   And it definitely includes the components of focus and friction.
[02:02:50.260 --> 02:02:53.300]   So in any case –
[02:02:53.300 --> 02:02:55.240]   And reprocessing later, we're talking about that reflection.
[02:02:55.240 --> 02:02:59.240]   I think many people after one of these experiences, they're now thinking about it in a way they weren't.
[02:02:59.240 --> 02:03:01.480]   They're putting it away and we're not talking about that.
[02:03:01.640 --> 02:03:05.440]   So for PTSD in particular, avoidance is a defining hallmark.
[02:03:05.440 --> 02:03:09.300]   It's a criteria you have to have in the manual that defines what this is.
[02:03:09.300 --> 02:03:12.600]   So avoiding it is a problem and now you've freed people from that.
[02:03:12.600 --> 02:03:17.060]   The work though being done, the rewiring is probably really work they're doing.
[02:03:17.060 --> 02:03:19.440]   It's now they're reentering that environment.
[02:03:19.440 --> 02:03:20.820]   They're reengaging that relationship.
[02:03:20.820 --> 02:03:25.980]   They're not avoiding it in part because they believe that they can do it and that it isn't harmful.
[02:03:25.980 --> 02:03:27.120]   That's true.
[02:03:27.120 --> 02:03:27.820]   It isn't harmful.
[02:03:27.820 --> 02:03:30.680]   These are pathological avoidances that people are doing.
[02:03:30.940 --> 02:03:33.220]   The question is can we come up with something better?
[02:03:33.220 --> 02:03:34.800]   What are the active ingredients?
[02:03:34.800 --> 02:03:37.860]   The experiment that's not yet been done is to appropriately blind people.
[02:03:37.860 --> 02:03:40.900]   So there are many drugs that make people have a trip.
[02:03:40.900 --> 02:03:44.880]   It's possible to enroll people who've never had a psychedelic before and then they won't know.
[02:03:44.880 --> 02:03:46.140]   You can give them a lot of caffeine.
[02:03:46.140 --> 02:03:49.100]   They might think, I guess that's what peyote is like.
[02:03:49.100 --> 02:03:49.960]   They wouldn't know.
[02:03:49.960 --> 02:03:51.640]   But that's not yet been done.
[02:03:51.640 --> 02:03:52.520]   I think it can be done.
[02:03:52.780 --> 02:03:57.160]   Usually when people say experiments can't be done properly, I get nervous.
[02:03:57.160 --> 02:03:59.120]   We're too smart for that.
[02:03:59.120 --> 02:03:59.980]   We made it to the moon and back.
[02:03:59.980 --> 02:04:01.620]   We can do an experiment.
[02:04:01.620 --> 02:04:03.640]   So finding out, we'll know the answer.
[02:04:03.640 --> 02:04:08.800]   On stroke, which we talked about before, enhancing plasticity, you mentioned Prozac.
[02:04:08.800 --> 02:04:12.020]   Fluoxetine is the name of the agent.
[02:04:12.500 --> 02:04:18.420]   Selective serotonin reuptake inhibitor increases serotonin and has effects on brain-derived neurotrophic factor and all the rest.
[02:04:18.420 --> 02:04:21.700]   It looked really promising in animals.
[02:04:21.700 --> 02:04:26.280]   Many, many published studies did the same thing we did, which is why we didn't think our thing was going to work.
[02:04:26.280 --> 02:04:29.100]   We took the therapy, which we know is helpful.
[02:04:29.100 --> 02:04:35.060]   Practice using your paw that's injured and then add the selective serotonin reuptake inhibitor and the animals made progress.
[02:04:35.060 --> 02:04:36.900]   And we did it again and again.
[02:04:36.940 --> 02:04:37.560]   We did it in monkeys.
[02:04:37.560 --> 02:04:38.200]   We did it in cats.
[02:04:38.200 --> 02:04:38.940]   We did it in rats.
[02:04:38.940 --> 02:04:39.880]   And then we did it in people.
[02:04:39.880 --> 02:04:41.280]   And lo and behold, the people got better.
[02:04:41.280 --> 02:04:44.260]   And then we did a large-scale randomized trial.
[02:04:44.260 --> 02:04:45.820]   And they didn't do anything.
[02:04:45.820 --> 02:04:49.880]   So it was 1,500 people with stroke.
[02:04:49.880 --> 02:04:51.200]   We gave them Prozac.
[02:04:51.200 --> 02:04:58.300]   And you will not be surprised that the new onset of depression was slightly lower than the group who had active antidepressant.
[02:04:58.300 --> 02:04:58.940]   That makes sense.
[02:04:58.940 --> 02:05:06.360]   You may or may not be surprised that the group who got the Prozac also had more hip fractures because, of course, serotonin is critically involved in laying down bone.
[02:05:06.860 --> 02:05:09.880]   And so this is really bad if you're an old person to have a hip fracture.
[02:05:09.880 --> 02:05:12.880]   So taking Prozac has off-target effects.
[02:05:12.880 --> 02:05:15.520]   I didn't know that it diminishes bone strength.
[02:05:15.520 --> 02:05:16.480]   Yeah, yeah.
[02:05:16.480 --> 02:05:17.800]   So serotonin is really important.
[02:05:17.800 --> 02:05:21.140]   The chondrocytes are the cells in the body that make bone.
[02:05:21.140 --> 02:05:23.980]   And when you mess with serotonin, you mess with those.
[02:05:23.980 --> 02:05:31.220]   This is a newly discovered thing for me I didn't know about is that Ritalin has effects on growth, right?
[02:05:31.220 --> 02:05:35.460]   So most people now are aware if you take Ritalin, you'll end up being about an inch shorter.
[02:05:36.080 --> 02:05:37.260]   This is just an off-target effect.
[02:05:37.260 --> 02:05:41.120]   Many, many positive benefits, but there are some negative, and you have to weigh the pros and cons.
[02:05:41.120 --> 02:05:44.640]   So in this case, we saw all the things we knew that Prozac did, meaning they took the drug.
[02:05:44.640 --> 02:05:49.440]   But their functional ability, their ability to move their hand, which wasn't any different.
[02:05:49.440 --> 02:05:51.240]   And why is that?
[02:05:51.240 --> 02:05:54.760]   It's because the range of problems people have is so diverse.
[02:05:54.760 --> 02:05:56.480]   People have all kinds of other insults.
[02:05:56.480 --> 02:05:58.320]   The rats are all perfectly situated in the cage.
[02:05:58.320 --> 02:05:59.980]   They've got exactly the lesion and all the rest.
[02:06:00.580 --> 02:06:01.980]   Why do the first few trials work?
[02:06:01.980 --> 02:06:07.080]   Because they were small, randomized trials with some confirmation bias or some other things implicit to them.
[02:06:07.080 --> 02:06:09.140]   The Food and Drug Administration is serious.
[02:06:09.140 --> 02:06:11.780]   Will this really work when no one knows?
[02:06:11.780 --> 02:06:13.900]   None of the investigators get to see the data.
[02:06:13.900 --> 02:06:15.160]   No one gets to look at anything.
[02:06:15.160 --> 02:06:18.740]   When you run a phase three pivotal trial, it's no joke.
[02:06:19.220 --> 02:06:24.200]   And we usually fail, and that's sad for us because we want it to work, but it's the truth, and we just accept it.
[02:06:24.200 --> 02:06:27.660]   Sometimes we go back through and say, maybe it worked for a subset, and we're still doing that.
[02:06:27.660 --> 02:06:31.800]   Maybe some people did get a benefit, but if that's true, that means some subset might have gotten worse.
[02:06:31.800 --> 02:06:34.220]   Good, let's select these people.
[02:06:34.220 --> 02:06:39.220]   So I think there's a lot of failed trials we can go back to and try to figure out, maybe we didn't pick the right people.
[02:06:39.220 --> 02:06:42.040]   Drug companies hope that the market is as large as possible.
[02:06:42.040 --> 02:06:45.160]   But what we find in our animal studies is there's a narrow range.
[02:06:45.580 --> 02:06:50.000]   You've done some beautiful experiments looking at how to get retinal ganglion cells to regrow.
[02:06:50.000 --> 02:06:52.980]   And the conditions need to be just right, not too much crush, not too little crush.
[02:06:52.980 --> 02:06:54.340]   You've got to get it just right.
[02:06:54.340 --> 02:06:57.220]   I think there are a lot of things we've found really do work.
[02:06:57.220 --> 02:07:00.760]   It's just we hope they worked as a panacea, and they don't.
[02:07:00.760 --> 02:07:02.100]   They might work for 10%.
[02:07:02.100 --> 02:07:08.080]   The only other therapy for stroke is called constraint-induced motor training, say MT.
[02:07:08.080 --> 02:07:12.440]   And the idea is you just put a glove over the good hand, and you force someone to use their bad hand.
[02:07:12.440 --> 02:07:15.700]   Yeah, this is Timothy Schallert's work from years ago.
[02:07:15.700 --> 02:07:16.000]   Yeah.
[02:07:16.000 --> 02:07:16.380]   Yeah.
[02:07:16.380 --> 02:07:21.480]   I love that work because it fits nicely with what we know about recovery from visual deprivation.
[02:07:21.480 --> 02:07:21.900]   Exactly.
[02:07:21.900 --> 02:07:25.520]   You injure one eye, you lose vision in the pathways that that eye governs.
[02:07:25.520 --> 02:07:28.900]   Once the eye is healthy again, you open it up, but you have to close the other eye.
[02:07:28.900 --> 02:07:34.060]   You can't – recovery from any kind of injury, you have to be careful you don't over-rely on the healthy limb.
[02:07:34.820 --> 02:07:37.040]   So this is also true in the context of stroke?
[02:07:37.040 --> 02:07:37.320]   Yeah.
[02:07:37.320 --> 02:07:39.820]   I love the human weasel experiment.
[02:07:39.820 --> 02:07:43.860]   I think things in neuroscience are only useful if they're counterintuitive.
[02:07:43.860 --> 02:07:45.600]   If they're obvious, why do we need neuroscience?
[02:07:45.600 --> 02:07:51.740]   And the idea that a kid gets a big scrape over his eye, and he's three years old, and he's got a patch on his eye for three weeks.
[02:07:52.280 --> 02:07:59.720]   And after the patch comes off and the eye is fine, you need to tell his mom, hey, mom, what I want you to do is put a patch on the other eye.
[02:07:59.720 --> 02:08:02.600]   She will doubtless say, but that's not the eye that was hurt.
[02:08:02.600 --> 02:08:07.960]   And you'll say, I know, but I have to reverse patch to rebalance the eyes.
[02:08:07.960 --> 02:08:09.140]   That's counterintuitive.
[02:08:09.740 --> 02:08:16.780]   These guys did experiments in cats and monkeys, figured out what it was, and they now have saved untold number of people's vision, at least in one of their eyes.
[02:08:16.780 --> 02:08:18.900]   But it was counterintuitive to do that.
[02:08:18.900 --> 02:08:20.560]   Now we don't reverse patch anymore.
[02:08:20.560 --> 02:08:21.960]   We give some drops.
[02:08:21.960 --> 02:08:23.760]   The eye drops make it a little bit blurry.
[02:08:23.760 --> 02:08:25.400]   You don't have to block the eye entirely.
[02:08:25.400 --> 02:08:29.840]   You can just do a drop that slightly blurs the eye by opening the pupil up.
[02:08:29.840 --> 02:08:35.180]   And now the eye that was sort of behind catches up.
[02:08:35.180 --> 02:08:37.940]   That is super practical, super cost effective.
[02:08:37.940 --> 02:08:39.080]   Atropine costs pennies.
[02:08:39.080 --> 02:08:40.180]   It's super safe.
[02:08:40.180 --> 02:08:41.020]   It's just an eye drop.
[02:08:41.020 --> 02:08:44.800]   Just full disclosure, I had my own amblyopia experience as a kid.
[02:08:44.800 --> 02:08:47.360]   And when I was a very young person, I sat and tried Popsicle sticks.
[02:08:47.360 --> 02:08:48.680]   I had lazy eyes, trabismus.
[02:08:48.680 --> 02:08:52.560]   And then that ended up causing me double vision and trouble reading when I was a very young child.
[02:08:52.560 --> 02:08:54.180]   Your eyes are well aligned now.
[02:08:54.180 --> 02:08:55.240]   My eyes are now well aligned.
[02:08:55.240 --> 02:08:56.320]   I'm sitting across from you, so I know.
[02:08:56.480 --> 02:09:00.760]   It was many, many, from an ophthalmologist, ophthalmology department's point of view.
[02:09:00.760 --> 02:09:05.260]   It's just a little bit telling too much about me, but it's mostly about my mother.
[02:09:05.260 --> 02:09:08.540]   It was originally believed that only adults would go through this much therapy.
[02:09:08.540 --> 02:09:12.980]   There's actually a paper written, I'm told, on me as someone who would go through this therapy and completely resolve it.
[02:09:12.980 --> 02:09:15.100]   Sometimes it just takes a lot of time following Popsicle sticks.
[02:09:15.100 --> 02:09:18.480]   I had little lenses at, I don't know, I guess I was six years old.
[02:09:18.480 --> 02:09:19.540]   I put little lenses in it.
[02:09:19.540 --> 02:09:20.200]   It would make it harder.
[02:09:20.200 --> 02:09:21.600]   It was like eye building for the eye.
[02:09:21.600 --> 02:09:23.980]   The doctor told me, you don't have to do all this.
[02:09:24.580 --> 02:09:28.400]   We could just take your eye out, and we'll stretch one muscle, and we'll strengthen another one, and we'll pop it back in.
[02:09:28.400 --> 02:09:29.720]   And I went, I was six.
[02:09:29.720 --> 02:09:30.540]   I went, I don't think so.
[02:09:30.540 --> 02:09:31.740]   Yeah, that sounds pretty scary.
[02:09:31.740 --> 02:09:32.340]   I'll do this one.
[02:09:32.340 --> 02:09:33.960]   How's your binocular vision now?
[02:09:33.960 --> 02:09:34.640]   Totally fine.
[02:09:34.640 --> 02:09:35.300]   Totally fine.
[02:09:35.300 --> 02:09:37.940]   You were able to play sports requiring depth reception.
[02:09:37.940 --> 02:09:39.300]   Still within the critical period early enough.
[02:09:39.300 --> 02:09:44.920]   Because of those experiments, those handful of animals made the ultimate sacrifice so that we now know how to treat things.
[02:09:45.420 --> 02:09:50.280]   So now getting back to these counterintuitive ideas, how are you going to intervene?
[02:09:50.280 --> 02:09:53.840]   We've got a kid with Down syndrome or someone with Alzheimer's and they're slipping into dementia.
[02:09:53.840 --> 02:09:55.240]   What are you supposed to do?
[02:09:55.240 --> 02:09:56.080]   We don't know.
[02:09:56.080 --> 02:09:58.820]   If psilocybin is the answer, let's use it.
[02:09:58.820 --> 02:09:59.920]   It's certainly counterintuitive.
[02:09:59.920 --> 02:10:01.720]   But it may or may not be.
[02:10:01.720 --> 02:10:03.640]   We've got to run the experiments and find out.
[02:10:03.640 --> 02:10:05.500]   So for fluoxetine, it looked really promising.
[02:10:05.500 --> 02:10:07.620]   There was a big initiative on stem cells.
[02:10:07.620 --> 02:10:09.240]   Stem cells looked incredibly promising.
[02:10:09.240 --> 02:10:09.720]   For stroke.
[02:10:09.720 --> 02:10:10.460]   For stroke.
[02:10:10.460 --> 02:10:10.700]   Yeah.
[02:10:10.700 --> 02:10:11.020]   That's right.
[02:10:11.020 --> 02:10:13.940]   That's a 1,300 person set as a meta-analysis.
[02:10:13.940 --> 02:10:15.180]   It just didn't help or hurt.
[02:10:15.180 --> 02:10:16.040]   It just didn't do anything.
[02:10:16.040 --> 02:10:17.440]   We wanted it to work.
[02:10:17.440 --> 02:10:18.100]   I wanted it to work.
[02:10:18.100 --> 02:10:19.000]   I'm a molecular biologist.
[02:10:19.000 --> 02:10:22.220]   I want the cells to go in there and do the good stuff, release the good juices.
[02:10:22.220 --> 02:10:24.220]   But it's a practical matter.
[02:10:24.220 --> 02:10:26.280]   And that's what I love about working with patients is they're just very practical.
[02:10:26.280 --> 02:10:28.040]   They don't have a dog in the race.
[02:10:28.040 --> 02:10:29.920]   This, that, or the other thing.
[02:10:29.920 --> 02:10:31.760]   What is the pro and con?
[02:10:31.760 --> 02:10:35.940]   And we're now getting to the point where we can, partly because of your work, have people really understand how they work.
[02:10:35.940 --> 02:10:38.560]   Don't take an antidepressant because it's antidepressant.
[02:10:38.560 --> 02:10:39.920]   That's just what we called it.
[02:10:40.420 --> 02:10:42.240]   It doesn't mean that that's what it evolved for.
[02:10:42.240 --> 02:10:43.500]   That's a label.
[02:10:43.500 --> 02:10:48.220]   You can say anti-PTSD and say this must be anti-PTSD because it's called anti-PTSD.
[02:10:48.220 --> 02:10:49.520]   We have to be careful about these labels.
[02:10:49.520 --> 02:10:57.360]   Antidepressants typically are selective serotonin reuptake inhibitors, but some selective norepinephrine reuptake inhibitors.
[02:10:57.360 --> 02:10:58.180]   Some are both.
[02:10:58.180 --> 02:11:00.520]   Some have kind of complex off-target effects.
[02:11:00.520 --> 02:11:02.660]   But they're all lumped because of what they do.
[02:11:02.660 --> 02:11:07.860]   And as you said, whether it's in pathogens or psychedelics, these are given names because of the things we see.
[02:11:07.860 --> 02:11:08.720]   And the things we see are real.
[02:11:09.140 --> 02:11:12.220]   People see them, and this is the effect that they have on mood, on whatever.
[02:11:12.220 --> 02:11:12.920]   They all happen.
[02:11:12.920 --> 02:11:14.740]   The question is a practical one.
[02:11:14.740 --> 02:11:16.660]   What will the long-term outcome be?
[02:11:16.660 --> 02:11:18.100]   And we often don't know that.
[02:11:18.100 --> 02:11:23.340]   For many, many years, we think things that are very valuable initially turn out not to be so valuable.
[02:11:23.340 --> 02:11:33.160]   I always think of the Pope with a flask of God knows what, but I think it was cocaine or Sigmund Freud or whatever else, taking these substances just fully convinced I found the right thing.
[02:11:33.160 --> 02:11:34.500]   Wait, the Pope took cocaine?
[02:11:34.500 --> 02:11:35.480]   It is my understanding.
[02:11:35.480 --> 02:11:38.960]   Again, this is one of the things I learned in Catholic school.
[02:11:39.120 --> 02:11:45.340]   But, yeah, there were many people who thought many of these elixirs were really, really powerful agents that were going to be useful.
[02:11:45.340 --> 02:11:47.880]   And later, people just said, it's not working for me.
[02:11:48.700 --> 02:11:53.420]   Most people learn, yeah, you can drink your way out of a bad relationship, but it's not really going to solve the problem.
[02:11:53.420 --> 02:11:54.400]   I've got to do all the real work.
[02:11:54.400 --> 02:11:56.940]   So there's a lot of short-term solutions is my point.
[02:11:56.940 --> 02:11:59.600]   And the question now is how is it going to work long-term?
[02:11:59.600 --> 02:12:04.040]   If we're getting through a crisis where someone is immediately suicidal, we've got to get them to that point.
[02:12:04.160 --> 02:12:06.100]   And we will do whatever it takes to go through that point.
[02:12:06.100 --> 02:12:08.380]   Now we're in the intermediate phase.
[02:12:08.380 --> 02:12:10.960]   But a year later, how are we doing?
[02:12:10.960 --> 02:12:12.920]   It remains to be seen.
[02:12:12.920 --> 02:12:15.320]   We're not yet years post trying these agents.
[02:12:15.320 --> 02:12:18.500]   We're only now trying them because they're listed as Schedule 1.
[02:12:18.500 --> 02:12:20.820]   They cannot possibly be used because we tried them in the 50s.
[02:12:20.820 --> 02:12:21.720]   You mean the psychedelics?
[02:12:21.720 --> 02:12:22.240]   The psychedelics.
[02:12:22.240 --> 02:12:29.780]   Yeah, I mean, I'm encouraged by the results of the trials on psychedelics and pathogens like psilocybin and MDMA in particular.
[02:12:29.780 --> 02:12:32.480]   I'm not just being politically correct here.
[02:12:32.520 --> 02:12:48.800]   I think people need to be very aware that the therapeutic support going in, the therapeutic support during, and the therapeutic support afterwards, especially for this reflection piece, what's typically called integration in the psychedelic journey space, is vital.
[02:12:48.800 --> 02:12:58.400]   And there are a few or more examples of very high-functioning people who have crashed their mind in their life with psychedelics using them.
[02:12:59.440 --> 02:13:12.080]   I don't know how they were using them, but, you know, in an unguarded way, you know, I think they hold great promise because of their ability to augment neuromodulators.
[02:13:12.080 --> 02:13:13.060]   Yeah, yeah.
[02:13:13.740 --> 02:13:36.020]   Again, the question about what happens in the journey is a separate matter, and I'm not qualified to answer that anyway, but I just find it amazing that these four chemicals, serotonin, dopamine, norepinephrine, and acetylcholine, alone or in combination, are not the only path to plasticity, but they are necessary.
[02:13:36.560 --> 02:13:55.680]   They're not sufficient, but they're necessary, and, you know, if a small little, you know, pinky nail-sized stimulator, I realize I'm holding up something that looks a little bit larger, like the size of a, like a, reminds me of that, like, lip balm stuff that you put on when you go skiing, like that Carmex stuff.
[02:13:55.680 --> 02:14:08.580]   It's about that big, but the chip itself is the size of my pinky nail, and if that can be implanted and it can stimulate my vagus nerve in a way that the brain thinks I'm having a heart attack, I think we might scare people with that discussion.
[02:14:09.060 --> 02:14:11.680]   But as you pointed out, you're not aware of that, right?
[02:14:11.680 --> 02:14:23.040]   Basically, it's taking advantage of a pathway that signals something's going on in the body, but nothing, you're not inducing a heart attack, obviously, and you're getting a burst of neuromodulator release.
[02:14:23.040 --> 02:14:29.300]   And then there's a window that opens where you can learn stuff better, whether or not it's new movement, new knowledge.
[02:14:29.560 --> 02:14:35.620]   How do I, I want to be a subject in an experiment where, obviously, I don't have a stroke.
[02:14:35.620 --> 02:14:43.720]   Well, not, maybe, maybe it's not obvious I don't have a stroke, but I don't want a stroke, but I would love to be in an experiment where you're using this for more rapid learning.
[02:14:43.720 --> 02:14:46.440]   Do you have any intention of doing those kinds of studies?
[02:14:46.440 --> 02:14:48.500]   We have done a bunch of those experiments.
[02:14:48.500 --> 02:14:56.640]   Much of this work is funded by the Defense Advanced Research Projects Agency, DARPA, and they're looking for ways to enhance learning.
[02:14:57.560 --> 02:15:04.660]   That was called the TNT program, I like it to sound exciting, was Targeted Neuroplasticity Training.
[02:15:04.660 --> 02:15:12.180]   And so, under some circumstances, you can improve learning, but under the majority of conditions, you're already so smart.
[02:15:12.180 --> 02:15:16.720]   The rats we studied are already so smart, they just didn't help, didn't help or hurt.
[02:15:16.720 --> 02:15:17.980]   Doesn't it help you focus more?
[02:15:17.980 --> 02:15:21.200]   Didn't help focus more, didn't make it worse, didn't make it better.
[02:15:21.200 --> 02:15:25.060]   Now, you can always wonder, maybe we didn't do the conditions right, we did hundreds and hundreds of experiments.
[02:15:25.480 --> 02:15:35.560]   So, it's possible, though I don't know this, for sure, it's possible this is one of the few technologies that helps those who are least capable among us and does not help those who are most capable.
[02:15:35.560 --> 02:15:38.220]   And the idea is, the way we're activating this is still pretty crude.
[02:15:38.220 --> 02:15:39.960]   Like, I'm blasting this whole thing.
[02:15:39.960 --> 02:15:45.280]   This used to be called the reticular activating system, this arousal network that releases all these neurotransmitters.
[02:15:45.280 --> 02:15:47.140]   It was viewed as one system back in the day.
[02:15:47.440 --> 02:15:52.000]   We later found molecular biology and divided it into these different neurotransmitters, but they all kind of get activated a lot.
[02:15:52.000 --> 02:15:55.980]   They're highly co-varying when they fire in relation to these arousing signals.
[02:15:55.980 --> 02:15:58.480]   But the way we're doing it, it's still pretty crude, right?
[02:15:58.480 --> 02:15:59.880]   I'm not activating individual fibers.
[02:15:59.880 --> 02:16:01.340]   I'm activating the whole kit and kaboom.
[02:16:01.340 --> 02:16:02.360]   Where does it get inserted?
[02:16:02.360 --> 02:16:05.000]   The left vagus nerve on the cervical branch, just right here.
[02:16:05.000 --> 02:16:08.100]   You find a little crease in your skin, open that up, put it in, close it up.
[02:16:08.100 --> 02:16:12.880]   If you feel your jugular, your carotid artery, it's running right there.
[02:16:12.880 --> 02:16:17.320]   How long from when I walk into the clinic to when I walk out with the stimulator?
[02:16:17.320 --> 02:16:18.560]   And again, no wires, right?
[02:16:18.560 --> 02:16:19.280]   It's wireless.
[02:16:19.280 --> 02:16:21.040]   How long is that procedure?
[02:16:21.040 --> 02:16:23.020]   You're anesthetized for 35 minutes.
[02:16:23.020 --> 02:16:25.740]   So from open to close, that part of it is half an hour.
[02:16:25.740 --> 02:16:27.260]   Typically people, you know, you've got to get in anyway.
[02:16:27.260 --> 02:16:27.920]   Shorter than a haircut.
[02:16:27.920 --> 02:16:30.520]   Yeah, is the actual part where you're open.
[02:16:30.520 --> 02:16:32.540]   I have short hair, but yeah, shorter than a haircut.
[02:16:32.540 --> 02:16:32.900]   Right.
[02:16:32.900 --> 02:16:37.100]   But the actual showing up and getting checked in and checked out, it does take two hours or whatever it is.
[02:16:37.100 --> 02:16:37.840]   I don't actually know.
[02:16:37.840 --> 02:16:38.320]   That's a good question.
[02:16:38.320 --> 02:16:39.140]   But you do it once.
[02:16:39.140 --> 02:16:40.280]   You do it once and you're done.
[02:16:40.280 --> 02:16:42.760]   And when it's off, it's off.
[02:16:42.960 --> 02:16:46.020]   Like the medications are maybe lingering in your body, having effects.
[02:16:46.020 --> 02:16:48.640]   It only, you're talking about specificity, which I want to get back to.
[02:16:48.640 --> 02:16:52.520]   The specificity, it doesn't activate any other nerves than the one that it's on.
[02:16:52.520 --> 02:16:53.820]   It's a tiny bit of current.
[02:16:53.820 --> 02:16:55.300]   And how do I activate it?
[02:16:55.300 --> 02:17:01.000]   So we put a band around, you know, it looks like Bose headphones or, you know, Beats headphones around it.
[02:17:01.000 --> 02:17:02.620]   That has got a coil.
[02:17:02.620 --> 02:17:04.320]   There's a coil in that device.
[02:17:04.320 --> 02:17:05.800]   The two coils are aligned, just like your phone.
[02:17:05.800 --> 02:17:06.600]   You put your phone on it.
[02:17:06.600 --> 02:17:07.240]   You don't plug it in.
[02:17:07.240 --> 02:17:08.380]   The coils align.
[02:17:08.660 --> 02:17:11.020]   That now turns it on because the device has no battery.
[02:17:11.020 --> 02:17:16.400]   The next generation, the experimental device, the device that's FDA approved does have a battery and that's how it's powered.
[02:17:16.400 --> 02:17:22.260]   Our new device is much smaller because we're giving it the power and we're also signaling now.
[02:17:22.260 --> 02:17:26.700]   The way we do that is we measure the forces someone's making with their fingers or their hand.
[02:17:26.700 --> 02:17:27.660]   We'll make a handle.
[02:17:27.660 --> 02:17:28.840]   We'll measure the forces.
[02:17:28.840 --> 02:17:29.920]   Every person is different.
[02:17:29.920 --> 02:17:31.300]   You've got to meet them where they are.
[02:17:31.340 --> 02:17:32.300]   Every educator knows this.
[02:17:32.300 --> 02:17:33.300]   Where is this kid?
[02:17:33.300 --> 02:17:35.420]   Let's get them into their best zone.
[02:17:35.420 --> 02:17:37.400]   So if we're taking a person, this is all they can turn.
[02:17:37.400 --> 02:17:40.240]   It's all the rotation they've got of their wrist, five degrees.
[02:17:40.240 --> 02:17:41.180]   That's fine.
[02:17:41.180 --> 02:17:42.720]   I can easily measure five degrees.
[02:17:42.720 --> 02:17:46.380]   You can do 90 degrees, 100 degrees, right?
[02:17:46.380 --> 02:17:48.040]   But they can only do five.
[02:17:48.040 --> 02:17:51.980]   When they're doing five, sometimes they do six, just for whatever reason.
[02:17:51.980 --> 02:17:52.620]   I don't know why.
[02:17:52.620 --> 02:17:54.120]   That's when I hit the stimulator.
[02:17:54.120 --> 02:17:56.140]   Who hits the stimulator?
[02:17:56.140 --> 02:17:57.440]   The computer does it itself.
[02:17:57.440 --> 02:17:59.440]   It's closed loop, just like your air conditioning unit.
[02:17:59.440 --> 02:18:01.420]   When the temperature goes up, it automatically turns it off.
[02:18:01.420 --> 02:18:02.580]   So they can be at home doing this.
[02:18:02.580 --> 02:18:04.860]   They don't need to be walking around with a researcher following them.
[02:18:04.860 --> 02:18:05.180]   That's right.
[02:18:05.180 --> 02:18:08.980]   The nature paper was done in a clinic, supervised, but really the therapy is being delivered by
[02:18:08.980 --> 02:18:13.460]   the computer, measuring their performance, tracking each individual person, looking back
[02:18:13.460 --> 02:18:16.900]   for the last few minutes of their activities, seeing what they can produce, and looking to
[02:18:16.900 --> 02:18:18.380]   see what's in their top 10%.
[02:18:18.380 --> 02:18:20.980]   What about tinnitus?
[02:18:20.980 --> 02:18:24.080]   By the way, is that the way it's pronounced or is it tinnitus?
[02:18:24.080 --> 02:18:28.400]   Most people say tinnitus, emphasizing the itis, the inflammatory part of it.
[02:18:28.400 --> 02:18:29.540]   There's actually nothing inflamed.
[02:18:29.540 --> 02:18:29.960]   Okay.
[02:18:29.960 --> 02:18:30.680]   I like tinnitus.
[02:18:30.680 --> 02:18:31.340]   Tinnitus.
[02:18:31.340 --> 02:18:32.680]   Most often called tinnitus.
[02:18:32.680 --> 02:18:34.940]   I get so many questions about tinnitus.
[02:18:34.940 --> 02:18:35.240]   Yeah.
[02:18:35.240 --> 02:18:37.660]   Clearly people suffer from it when they have it.
[02:18:37.660 --> 02:18:43.300]   And I've seen a few papers out there that maybe low-dose melatonin before sleep can help
[02:18:43.300 --> 02:18:44.860]   a little bit with certain forms of tinnitus.
[02:18:44.860 --> 02:18:47.680]   Maybe it's just the consequence of improved sleep and this kind of thing.
[02:18:49.360 --> 02:18:55.460]   In anticipation of today's discussion, I put out the call for questions about brain stimulation,
[02:18:55.460 --> 02:18:57.540]   tons of questions about tinnitus.
[02:18:57.540 --> 02:19:03.540]   When you treat tinnitus using this little stimulator, how successful is it?
[02:19:03.540 --> 02:19:08.500]   And also how common is tinnitus and how do you do those experiments?
[02:19:08.500 --> 02:19:09.760]   So how common is it?
[02:19:09.760 --> 02:19:13.500]   Because it seems very common based on the number of questions.
[02:19:13.500 --> 02:19:15.260]   How successful is your treatment?
[02:19:15.260 --> 02:19:20.200]   And then what does the experimental manipulation look like?
[02:19:20.200 --> 02:19:22.140]   So how common is it?
[02:19:22.140 --> 02:19:22.660]   Very common.
[02:19:22.660 --> 02:19:24.220]   I mean, hearing loss is common.
[02:19:24.220 --> 02:19:26.940]   It's, of course, highly correlated with growing old, which is a good thing.
[02:19:26.940 --> 02:19:28.080]   Wait, are those the same thing?
[02:19:28.080 --> 02:19:29.960]   No, they're not the same thing.
[02:19:30.320 --> 02:19:35.860]   A lot of things accumulate to cause damage to the hair cells in your ear, taking on antibiotics,
[02:19:35.860 --> 02:19:39.700]   having a viral infection, traumatic insults, all those things.
[02:19:39.700 --> 02:19:41.380]   But the number one is just growing old.
[02:19:41.380 --> 02:19:43.500]   So if you grow old enough, things start falling apart.
[02:19:43.500 --> 02:19:46.980]   And one of the things that falls apart are these hair cells.
[02:19:46.980 --> 02:19:48.220]   These are incredibly precise.
[02:19:48.220 --> 02:19:51.160]   The vibrations these things are doing are the width of one atom.
[02:19:51.160 --> 02:19:53.540]   Like that's how tiny, the smallest vibration you could detect.
[02:19:53.540 --> 02:19:55.940]   The hair cell is only moving back and forth by an atom.
[02:19:55.940 --> 02:19:57.140]   I mean, it's incredibly precise.
[02:19:57.140 --> 02:19:58.640]   And so they get damaged.
[02:19:58.640 --> 02:19:59.700]   They're just super sensitive.
[02:19:59.700 --> 02:20:04.960]   When they get damaged, it's typically the high frequencies that get damaged, whether you're
[02:20:04.960 --> 02:20:10.040]   going to rock concerts or shooting a gun or, you know, playing your horn loud.
[02:20:10.040 --> 02:20:14.360]   It's the high frequencies where the things vibrate the fastest that get most injured.
[02:20:14.360 --> 02:20:18.260]   And people start noticing they can't hear as well in a crowded restaurant or whatever else.
[02:20:18.260 --> 02:20:23.280]   You go and get an audiogram with an audiologist and they'll tell you, yes, above 8 kilohertz
[02:20:23.280 --> 02:20:27.980]   or above 4 kilohertz, you now need 20 times more sound pressure to hear it.
[02:20:28.120 --> 02:20:30.160]   Okay, you can still hear, just not as good.
[02:20:30.160 --> 02:20:34.420]   The thing is the brain is plastic, as we've been saying, is such a good thing.
[02:20:34.420 --> 02:20:41.560]   But the brain being plastic means if nobody high frequency ever happens and low frequency
[02:20:41.560 --> 02:20:46.260]   things keep happening, your brain is going to shift from the high frequencies to the mid frequencies.
[02:20:46.260 --> 02:20:50.220]   And you're now going to end up with too many neurons in the mid frequencies.
[02:20:50.220 --> 02:20:52.700]   Right at the edge of where you can hear, you get too many neurons.
[02:20:52.780 --> 02:20:54.320]   The same thing happens after an amputation.
[02:20:54.320 --> 02:20:58.620]   So you end up with too many neurons responding to the stump because the hand's not there anymore.
[02:20:58.620 --> 02:21:01.980]   So if the hand's not there anymore, I'm not going to keep doing that.
[02:21:01.980 --> 02:21:05.580]   The neurons find something else to do, just like smart little neurons that they are.
[02:21:05.580 --> 02:21:10.420]   The problem is if you exceed some threshold, if I take this microphone and put it next to
[02:21:10.420 --> 02:21:11.520]   a speaker, you'll get feedback.
[02:21:12.080 --> 02:21:16.500]   Because the number one input to neurons in the cortex are other neurons in the cortex,
[02:21:16.500 --> 02:21:18.260]   not the outside world.
[02:21:18.260 --> 02:21:21.420]   Neurons in the brain mostly talk to themselves, not the world.
[02:21:21.420 --> 02:21:23.280]   There's very few neurons in the eye.
[02:21:23.280 --> 02:21:25.080]   You know this, but most people are surprised.
[02:21:25.080 --> 02:21:27.860]   You don't have megapixels of resolution.
[02:21:27.860 --> 02:21:29.500]   You've got kind of a smallish number.
[02:21:29.500 --> 02:21:31.660]   But you're moving around and you're using and sampling.
[02:21:32.240 --> 02:21:38.160]   Here we have a situation where the way the brain is processing is over-focused and you
[02:21:38.160 --> 02:21:39.780]   start to get oscillations.
[02:21:39.780 --> 02:21:41.040]   The neurons start to fire together.
[02:21:41.040 --> 02:21:42.260]   They start to wire together.
[02:21:42.260 --> 02:21:44.400]   Then you start to pay attention to it.
[02:21:44.400 --> 02:21:45.900]   Most of us have heard it.
[02:21:45.900 --> 02:21:47.960]   My advice for everyone is try to ignore it.
[02:21:47.960 --> 02:21:51.400]   Because when you're paying attention to it, you're listening to it, you're fretting about
[02:21:51.400 --> 02:21:52.160]   it, you're worrying about it.
[02:21:52.160 --> 02:21:52.660]   The tinnitus.
[02:21:52.660 --> 02:21:53.920]   You're releasing neurotransmitters.
[02:21:53.920 --> 02:21:54.180]   Yes.
[02:21:54.180 --> 02:21:54.620]   I see.
[02:21:54.620 --> 02:21:58.140]   So people self-amplify their own tinnitus by paying attention to it.
[02:21:58.140 --> 02:21:58.540]   That's right.
[02:21:58.540 --> 02:22:01.280]   And the more anxious they are about it because they think, I'm dying.
[02:22:01.340 --> 02:22:02.360]   I need to go to the doctor, which is smart.
[02:22:02.360 --> 02:22:03.440]   You should look out for new symptoms.
[02:22:03.440 --> 02:22:04.300]   Totally true.
[02:22:04.300 --> 02:22:05.160]   They think they're dying?
[02:22:05.160 --> 02:22:06.340]   They think they've got a brain tumor.
[02:22:06.340 --> 02:22:11.460]   And people are relieved after four months of worrying about it to realize, get a brain
[02:22:11.460 --> 02:22:12.420]   scan, you don't have a brain tumor.
[02:22:12.420 --> 02:22:14.580]   Some people do, but that's pretty rare.
[02:22:14.580 --> 02:22:16.240]   The vast majority don't.
[02:22:16.240 --> 02:22:20.180]   But that worrying is the food to this particular cancer.
[02:22:20.180 --> 02:22:20.760]   Oh, wow.
[02:22:20.760 --> 02:22:26.440]   That worrying, in the same way that avoiding going back to the site of an assault, is the
[02:22:26.440 --> 02:22:28.920]   thing that produces PTSD.
[02:22:29.740 --> 02:22:34.620]   Avoiding peanuts can create a severe allergy, a dangerous allergy to peanuts.
[02:22:34.620 --> 02:22:36.080]   We need the exposure.
[02:22:36.080 --> 02:22:36.900]   We need the diversity.
[02:22:36.900 --> 02:22:38.640]   We need that context.
[02:22:38.640 --> 02:22:40.620]   That information is useful to us.
[02:22:40.620 --> 02:22:45.000]   When we shield ourselves, as we did from peanuts, many people got peanut allergies.
[02:22:45.000 --> 02:22:49.300]   Now that we've gone back to exposing children, you don't have that problem nearly as bad.
[02:22:49.300 --> 02:22:49.980]   I work with Boy Scouts.
[02:22:49.980 --> 02:22:52.660]   And so we have a big, giant peanut allergy warning thing.
[02:22:52.660 --> 02:22:52.900]   Right, right, right.
[02:22:52.900 --> 02:22:53.700]   Don't want someone...
[02:22:53.700 --> 02:22:53.900]   Oh, yeah.
[02:22:53.900 --> 02:22:57.140]   Every time you board a plane now, they tell you, we got one person on here that's peanut
[02:22:57.140 --> 02:22:57.340]   dollars.
[02:22:57.340 --> 02:22:58.800]   Don't eat anything containing peanuts.
[02:22:58.800 --> 02:23:07.920]   Earlier, however, you said that a major reason that PTSD persists is because people avoid reflection.
[02:23:07.920 --> 02:23:14.720]   Here we're saying you want to avoid thinking about the ringing in your ears if you have tinnitus.
[02:23:14.720 --> 02:23:19.020]   Because that will amplify the circuits that underlie tinnitus.
[02:23:19.020 --> 02:23:27.700]   In some cases, you need to go into the event and work with somebody to, you know, parse the event and uncouple the emotional load, such as treatment for PTSD.
[02:23:27.700 --> 02:23:31.900]   In other cases, focusing on the problem more and more becomes an issue.
[02:23:31.900 --> 02:23:35.460]   I guess there's probably also cases of PTSD where people are preoccupied by it.
[02:23:35.460 --> 02:23:37.640]   It's, you know, it's running like a script in the background.
[02:23:37.640 --> 02:23:37.960]   That's right.
[02:23:37.960 --> 02:23:39.400]   Or it just pops up randomly.
[02:23:39.400 --> 02:23:42.960]   So for PTSD, cognitive behavioral therapists do five different things.
[02:23:42.960 --> 02:23:44.980]   Because people say, you're going to expose me to this?
[02:23:44.980 --> 02:23:45.560]   I'm going to get better?
[02:23:45.560 --> 02:23:46.300]   It doesn't make any sense.
[02:23:46.300 --> 02:23:47.140]   I'm already exposed to it.
[02:23:47.140 --> 02:23:47.860]   I think about it all the time.
[02:23:47.860 --> 02:23:49.180]   But they're not thinking about it enough.
[02:23:49.180 --> 02:23:51.480]   They're thinking about it where they're losing control.
[02:23:51.480 --> 02:23:55.080]   So control, as you know, from some classic neuroscience experiments is really important.
[02:23:55.080 --> 02:23:56.980]   Getting shocked is not bad for you.
[02:23:56.980 --> 02:23:59.660]   It's getting shocked in an uncontrollable way where you're not in charge of it.
[02:23:59.660 --> 02:24:04.020]   If you can influence it, have some agency over it, then I can make a story about it.
[02:24:04.020 --> 02:24:06.580]   When I can reflect on it, I know, hey, bad things happen.
[02:24:06.700 --> 02:24:08.020]   But I have a role to play in it.
[02:24:08.020 --> 02:24:11.940]   When I'm living in an abusive home and just random stuff happens, there's no agency.
[02:24:11.940 --> 02:24:12.640]   There's no control.
[02:24:12.640 --> 02:24:13.400]   It's just random.
[02:24:13.400 --> 02:24:16.820]   That is what is most damaging to people, their neurons, and their psyches.
[02:24:16.820 --> 02:24:21.400]   So here we're having a similar situation, whether it's post-traumatic stress disorder,
[02:24:21.400 --> 02:24:22.540]   which is not tenderness, right?
[02:24:22.540 --> 02:24:23.540]   They're totally different things.
[02:24:23.540 --> 02:24:24.840]   But there's a similarity.
[02:24:24.840 --> 02:24:30.640]   There's a commonality to them that your thing that you think is making you better is making
[02:24:30.640 --> 02:24:31.100]   you worse.
[02:24:31.100 --> 02:24:32.740]   And there are many ways.
[02:24:32.740 --> 02:24:34.400]   We call this the prevent defense in football.
[02:24:34.400 --> 02:24:36.060]   I'm from Texas, so we play a lot of that.
[02:24:36.240 --> 02:24:36.880]   Let's make a big change.
[02:24:36.880 --> 02:24:37.460]   We're ahead of the game.
[02:24:37.460 --> 02:24:38.220]   Let's change everything.
[02:24:38.220 --> 02:24:38.940]   Wait a minute.
[02:24:38.940 --> 02:24:39.600]   Bad idea.
[02:24:39.600 --> 02:24:41.620]   Let's just keep playing the game that was working.
[02:24:41.620 --> 02:24:44.360]   Oftentimes, teams will lose because they'll change their strategy.
[02:24:44.360 --> 02:24:49.320]   Here, if you've got pain in your finger, we'll now switch to analogy to chronic pain.
[02:24:49.320 --> 02:24:53.200]   And I'll get back to your question about exactly how we're treating it, what the treatment is.
[02:24:53.200 --> 02:24:55.500]   If your finger hurts, you want to do something about it.
[02:24:55.500 --> 02:24:56.240]   Your mom taught you.
[02:24:56.240 --> 02:24:56.960]   Find things.
[02:24:56.960 --> 02:24:57.640]   Pay attention.
[02:24:57.640 --> 02:24:58.500]   Doctors tell you.
[02:24:58.500 --> 02:24:59.000]   Pay attention.
[02:24:59.000 --> 02:25:00.240]   Let me know what the symptoms are.
[02:25:00.560 --> 02:25:04.520]   But sometimes that paying attention can become part of the cycle where you're feeding that.
[02:25:04.520 --> 02:25:04.960]   Got it.
[02:25:04.960 --> 02:25:09.000]   And that is then this positive feedback loop where it gets worse and worse and all the rest.
[02:25:09.000 --> 02:25:10.800]   I'm not blaming people for paying attention to it.
[02:25:10.800 --> 02:25:13.980]   It is damn near impossible to not pay attention to pain.
[02:25:13.980 --> 02:25:17.340]   It's damn near impossible not to pay attention to ringing sounds.
[02:25:17.340 --> 02:25:18.840]   They don't all sound like sounds.
[02:25:18.900 --> 02:25:23.040]   One woman told me she heard the sounds of a bird chirping in a cave.
[02:25:23.040 --> 02:25:27.320]   That's just a very specific thing that her brain is producing, the pattern of activity.
[02:25:27.320 --> 02:25:28.980]   And it's just super annoying.
[02:25:28.980 --> 02:25:30.040]   Who wouldn't be it?
[02:25:30.040 --> 02:25:31.920]   Easy to say, oh, just ignore it.
[02:25:31.920 --> 02:25:35.160]   I understand how hard that is because our attention goes to that.
[02:25:35.160 --> 02:25:38.080]   We need to make tools to help someone like that.
[02:25:38.080 --> 02:25:39.920]   Some of the people can reach levels.
[02:25:39.920 --> 02:25:43.300]   The commonality is like 10, 20% of people are going to have tenderness.
[02:25:43.300 --> 02:25:44.400]   Almost everyone.
[02:25:44.400 --> 02:25:45.340]   10 to 20%?
[02:25:45.340 --> 02:25:46.460]   That's a huge number of people.
[02:25:46.460 --> 02:25:46.960]   It's a huge number.
[02:25:46.960 --> 02:25:47.640]   It's one of the most common.
[02:25:47.720 --> 02:25:49.460]   This is why I get so many questions about it.
[02:25:49.460 --> 02:25:53.260]   And they're worrying about it and focusing on it is exacerbating it.
[02:25:53.260 --> 02:25:54.860]   It's the number one military disability.
[02:25:54.860 --> 02:25:57.820]   So you get a 10% payment for the rest of your life.
[02:25:57.820 --> 02:26:00.980]   So it's a billion dollars per year we pay for people with tenderness.
[02:26:00.980 --> 02:26:03.260]   You can't measure it objectively, just like chronic pain.
[02:26:03.260 --> 02:26:03.960]   You can't see it.
[02:26:03.960 --> 02:26:04.800]   They don't want it.
[02:26:04.800 --> 02:26:11.480]   But you develop it if you're in an aircraft carrier launching planes or you're blowing doors.
[02:26:11.480 --> 02:26:13.160]   Playing headphones too loud.
[02:26:13.160 --> 02:26:14.140]   Playing headphones too loud.
[02:26:14.140 --> 02:26:15.280]   These things are really a problem.
[02:26:15.280 --> 02:26:16.800]   Those cells will get damaged.
[02:26:16.800 --> 02:26:18.160]   The brain doesn't know.
[02:26:18.160 --> 02:26:20.260]   If you're deaf in the natural world, you just die.
[02:26:20.260 --> 02:26:22.920]   We didn't evolve to get used to loud sounds.
[02:26:22.920 --> 02:26:25.260]   That didn't exist for thousands and thousands of years.
[02:26:25.260 --> 02:26:26.980]   That all came on with the Industrial Revolution.
[02:26:26.980 --> 02:26:29.340]   You know, a thunderclap was like a loud sound.
[02:26:29.340 --> 02:26:34.620]   Nowadays, you can go to a concert and be at 120 decibels, 130 decibels for hours at a time.
[02:26:34.620 --> 02:26:38.060]   Most people, interestingly, don't get tinnitus.
[02:26:38.060 --> 02:26:39.360]   We see the same thing in the rats.
[02:26:39.360 --> 02:26:42.440]   When we produce noise trauma, I can make everybody deaf.
[02:26:42.440 --> 02:26:42.920]   That's easy.
[02:26:43.300 --> 02:26:45.140]   But only half of them show signs of tinnitus.
[02:26:45.140 --> 02:26:53.160]   So the way the brain rewires itself depends upon the specifics of creating that positive feedback loop inside the brain.
[02:26:53.160 --> 02:26:54.440]   Similar things happen.
[02:26:54.440 --> 02:26:56.600]   Charlie Gilbert did these beautiful experiments with the retina.
[02:26:56.660 --> 02:27:00.800]   We make dual lesions in the retina and all the neurons will go, whoop, jump over to some crazy place.
[02:27:00.800 --> 02:27:04.700]   We now have computational models where we understand the neurons have no inputs.
[02:27:04.700 --> 02:27:06.340]   They will tend to do dumb things.
[02:27:06.340 --> 02:27:10.880]   They don't tend to do smart things because you didn't tend to have simultaneously paired retinal lesions.
[02:27:12.200 --> 02:27:14.920]   So trusting the network to do the right thing is a good idea.
[02:27:14.920 --> 02:27:15.540]   Brains are smart.
[02:27:15.540 --> 02:27:19.420]   But in the case of pathology, by definition, it's not doing the right thing or it would have fixed it.
[02:27:19.420 --> 02:27:21.900]   So the same thing is happening with cancer.
[02:27:21.900 --> 02:27:23.920]   We get cancers all the time and we fix them.
[02:27:23.920 --> 02:27:29.780]   What's unique about cancers that cause problems, the two-hit hypothesis, is multiple things have gone wrong.
[02:27:29.780 --> 02:27:32.500]   And the normal tools that eliminate cancer don't work.
[02:27:32.500 --> 02:27:34.300]   Same thing with epilepsy.
[02:27:34.620 --> 02:27:38.460]   Normally, you have a little epileptic circle, fire together, wire together, and then you go, oh, let's get rid of this one.
[02:27:38.460 --> 02:27:40.720]   We make little epileptic foci and get rid of them.
[02:27:40.720 --> 02:27:41.840]   We make little neuroses.
[02:27:41.840 --> 02:27:43.920]   We make little obsessive compulsives all the time.
[02:27:43.920 --> 02:27:46.180]   And then we eliminate them, right?
[02:27:46.180 --> 02:27:48.640]   Just like my daughter is saying, I need to remove TikTok or whatever it is.
[02:27:48.640 --> 02:27:50.260]   We find it to be a problem.
[02:27:50.260 --> 02:27:50.980]   We find a solution.
[02:27:50.980 --> 02:27:52.800]   Sometimes we're aware of it, make a conscious decision.
[02:27:52.800 --> 02:27:54.680]   But more often, our neurons are just doing it.
[02:27:54.680 --> 02:27:57.260]   Our cells are doing it on our behalf behind the scenes.
[02:27:57.260 --> 02:28:01.340]   When you have flagrant cancer, it's going to kill the person.
[02:28:01.340 --> 02:28:04.260]   It's typically because multiple checkpoint inhibitors have been blocked.
[02:28:04.340 --> 02:28:05.000]   There's a lot of problems.
[02:28:05.000 --> 02:28:09.560]   We think the same thing is true of brain diseases, whether it's mental health problems or neurological.
[02:28:09.560 --> 02:28:12.440]   Two things must have gone wrong, at least, not just one thing.
[02:28:12.440 --> 02:28:19.180]   Perhaps this is one of the reasons why more and more we're hearing from people like Chris Palmer out of Harvard and others who are saying,
[02:28:19.180 --> 02:28:25.580]   you know, nutrition and diet that supports metabolic health can help resolve, in some cases, all the symptoms,
[02:28:25.580 --> 02:28:34.600]   but in most cases, some of the symptoms of mental health issues, schizophrenia, bipolar, depression, dementia, things of that sort.
[02:28:34.600 --> 02:28:42.820]   You know, there was even an attempt to create a type 3 diabetes nomenclature for Alzheimer's.
[02:28:42.820 --> 02:28:49.340]   So that didn't really stick because, you know, you can put people on a ketogenic diet, doesn't always improve their Alzheimer's, and it certainly doesn't cure it.
[02:28:49.340 --> 02:28:57.020]   But the notion that you have multiple things going on to give rise to dementia, you have multiple things going on to give rise to any mental health disorder.
[02:28:57.220 --> 02:29:10.900]   And so pushing or pulling on a neuromodulator or changing your metabolic health in the way that neurons can use glucose or rely on ketones for fuel, it all kind of makes sense now that we understand and we're observing this more and more.
[02:29:10.900 --> 02:29:18.740]   Where it gets tricky for me as a neuroscientist is the goal, the hope, was always specificity, right?
[02:29:18.740 --> 02:29:20.280]   The hope was this.
[02:29:20.580 --> 02:29:27.280]   It was a little chip that you could put in that, okay, you have to spend the day at the clinic, but it's not 20 electric shock therapy treatments.
[02:29:27.280 --> 02:29:38.220]   It's not a drug that makes your mood better, but makes you, you know, kind of like raises your levels of apathy or nukes your libido or changes your appetite in a direction you didn't want.
[02:29:38.220 --> 02:29:40.340]   You know, the hope was specificity.
[02:29:40.340 --> 02:29:45.080]   The kind of specificity that we're seeing with, you know, I'm going to get some flack for this.
[02:29:45.080 --> 02:29:46.620]   I don't take these peptides.
[02:29:46.660 --> 02:29:54.280]   But I think a large number of people who could not lose weight any other way are seeing great success by taking a Wagovi and Ozempic and related drugs.
[02:29:54.280 --> 02:29:59.400]   I understand they still have to exercise and some people feel like it's cheating and there's a bunch of issues related to insurance.
[02:29:59.400 --> 02:30:08.500]   But let's face it, you know, sure, there's some nausea, but people who for years and years just struggled with their weight are finally bringing their weight down into a healthier range.
[02:30:08.500 --> 02:30:11.020]   And hopefully they'll do the behavioral things that support them as well.
[02:30:11.020 --> 02:30:14.500]   So as neuroscientists, we always wanted specificity.
[02:30:15.000 --> 02:30:20.540]   So for someone with tinnitus who, you know, is, okay, I'm not going to, I'm going to try not to think about it.
[02:30:20.540 --> 02:30:29.180]   But if I'm hearing birds in caves chirping in the background and I'm just trying to write or read, I mean, it's already hard enough to focus on doing, you know, on focus and friction.
[02:30:29.720 --> 02:30:36.400]   So an impediment like tinnitus is something that one would hope you could just really just, you know, delete out.
[02:30:36.400 --> 02:30:38.640]   Like you put a line of script in a Word document.
[02:30:38.640 --> 02:30:48.040]   So when you stimulate the vagus nerve using this device and you want to get rid of tinnitus, what are the patients doing?
[02:30:48.440 --> 02:30:51.880]   Are they, are you capturing exactly what frequency the sound is?
[02:30:51.880 --> 02:30:52.460]   Yeah.
[02:30:52.460 --> 02:30:54.860]   So we, we ask them what their frequency is.
[02:30:54.860 --> 02:30:55.960]   We can do an audiogram.
[02:30:55.960 --> 02:31:00.740]   We can tell what their frequency, where they've lost are, but we don't know what their brain is required to play in their head.
[02:31:00.740 --> 02:31:03.200]   But they're saying, wait, I hear it at that.
[02:31:03.200 --> 02:31:05.100]   It sounds like you're doing a tone matching.
[02:31:05.100 --> 02:31:05.300]   Yeah.
[02:31:05.300 --> 02:31:05.760]   You do a tone matching.
[02:31:05.760 --> 02:31:10.580]   So you play like a low, medium, high tones, and then they go, wait, that's kind of like the high tone.
[02:31:10.580 --> 02:31:11.620]   Then you dial it in.
[02:31:11.620 --> 02:31:14.300]   You first have to teach them about octave confusion.
[02:31:14.300 --> 02:31:16.140]   If you're a music guy, you know, I'm not a music guy.
[02:31:16.140 --> 02:31:16.920]   I'm not a music guy.
[02:31:16.920 --> 02:31:22.160]   But if you get the wrong octave, you can actually, it's easy to confuse one octave higher than we don't know what tone they're actually hearing.
[02:31:22.160 --> 02:31:28.540]   So it's a little bit, you have to teach them about some tones sound the same, but they're just double the sound is the point.
[02:31:28.540 --> 02:31:33.780]   But once you can figure out what they're hearing, we then want all the other neurons to be important.
[02:31:34.160 --> 02:31:37.020]   So the idea we've talked about is that set of neurons is too important.
[02:31:37.020 --> 02:31:38.360]   It's doing something really important.
[02:31:38.360 --> 02:31:38.640]   Why?
[02:31:38.640 --> 02:31:39.440]   Because you're paying attention to it.
[02:31:39.440 --> 02:31:40.980]   It must be important because you keep paying attention to it.
[02:31:40.980 --> 02:31:43.680]   So I want to reward everybody but this set.
[02:31:43.680 --> 02:31:47.460]   So I play a low tone, lower than the thing, a high tone, higher than it.
[02:31:47.460 --> 02:31:49.640]   I'm trying to strengthen all the other neurons.
[02:31:49.640 --> 02:31:55.460]   Back in that science paper back in the day, by playing multiple different tones, it narrows receptive fields.
[02:31:55.460 --> 02:32:04.140]   So in this nature paper from 2011, which we first treated tinnitus in animals, what we saw that was most correlated was actually receptive fields.
[02:32:04.140 --> 02:32:10.060]   The neurons become non-selective, which means they now all respond to the same input.
[02:32:10.060 --> 02:32:12.980]   If you're really narrow, you only respond to one little bit of the cochlea.
[02:32:12.980 --> 02:32:20.480]   If you're broad, which happens after damage because you're trying to respond to something, now everybody responds to every wiggle and jiggle in the ear.
[02:32:20.920 --> 02:32:22.440]   All these neurons are now amplifying that.
[02:32:22.440 --> 02:32:24.980]   The brain is a massive amplifier and you get feedback.
[02:32:24.980 --> 02:32:29.100]   So what we're trying to do is narrow receptive fields and shift the map.
[02:32:29.100 --> 02:32:32.540]   Instead of having that big blue area where everyone's the same way, let's make diversity.
[02:32:32.540 --> 02:32:35.600]   So you're trying to tune the piano and take out a few keys.
[02:32:35.600 --> 02:32:36.260]   That's right.
[02:32:36.260 --> 02:32:36.780]   That's right.
[02:32:36.780 --> 02:32:41.940]   And this idea of diversity is something we didn't know about back in the day, the optimization and specificity idea.
[02:32:41.940 --> 02:32:45.080]   We had a culture of find the thing and get the thing.
[02:32:45.580 --> 02:32:47.920]   Now, mercifully, we're in a much more diverse idea.
[02:32:47.920 --> 02:32:49.880]   We're learning that the training set matters.
[02:32:49.880 --> 02:32:52.280]   The stimuli are likely to be more complicated.
[02:32:52.280 --> 02:32:56.920]   The idea that we wanted specificity and we wanted treatments and neuroscience hasn't provided that.
[02:32:56.920 --> 02:32:58.140]   I'll take exception with that.
[02:32:58.140 --> 02:33:06.020]   With phenaketonuria, we have every baby born in this country gets a heel stick and you measure the level of phenylalanine hydroxylase.
[02:33:06.460 --> 02:33:09.420]   And if they don't have it, we put them on a special diet.
[02:33:09.420 --> 02:33:12.120]   So they avoid phenylalanine and they don't have severe mental retardation.
[02:33:12.120 --> 02:33:13.020]   Problem solved.
[02:33:13.020 --> 02:33:13.260]   Right.
[02:33:13.260 --> 02:33:20.380]   This is the warning that many people have seen on their diet Coke cans, but they probably haven't explored as to what the meaning is.
[02:33:20.380 --> 02:33:26.340]   That PEA, right, is for us is harmless, maybe even beneficial.
[02:33:26.340 --> 02:33:29.080]   Confession here.
[02:33:29.080 --> 02:33:30.900]   I take 500 milligrams of it every morning.
[02:33:30.900 --> 02:33:31.980]   It makes you feel pretty good.
[02:33:31.980 --> 02:33:33.280]   It's a little mild stimulant.
[02:33:33.520 --> 02:33:39.660]   I've been doing that for years, but if you don't have the enzyme to work with it, it can cause mental retardation.
[02:33:39.660 --> 02:33:40.000]   Right.
[02:33:40.000 --> 02:33:43.320]   And before, we just called everybody retarded, and now we go, hey, there's many different ways.
[02:33:43.320 --> 02:33:48.040]   Now, the fact that we treated one and it was a diet change doesn't mean we treated all of them.
[02:33:48.040 --> 02:33:55.480]   There's many other things that cause severe problems, fragile X syndrome, FMR1, different gene, cause a different set of thing, and you can't change your diet to fix it.
[02:33:55.480 --> 02:33:56.540]   That's not the nature of it.
[02:33:56.540 --> 02:34:03.400]   But the example we used from Human Weasel where you now reverse suture, I've had lots of children just work with kids and point out to their parents,
[02:34:03.400 --> 02:34:04.620]   do you see his eyes don't go right?
[02:34:04.620 --> 02:34:05.880]   I never noticed.
[02:34:05.880 --> 02:34:09.260]   And an ophthalmology professor in neuroscience is going to think, doesn't everybody notice eye movements?
[02:34:09.260 --> 02:34:10.160]   No.
[02:34:10.160 --> 02:34:10.740]   Yeah.
[02:34:10.740 --> 02:34:12.040]   Some people just don't pay attention to that.
[02:34:12.040 --> 02:34:16.460]   You point it out, and they go get treatment, whatever it might be, and they're better.
[02:34:16.700 --> 02:34:21.260]   Yeah, look, we should do a public health service announcement here since we're reaching some people.
[02:34:21.260 --> 02:34:30.140]   If your child, regardless of age, but if your child has a quote-unquote lazy eye or an eye that doesn't seem to align quite the same as the other,
[02:34:30.140 --> 02:34:37.560]   when they're fatigued or just naturally sits that way, it's very important to correct that early.
[02:34:38.020 --> 02:34:43.460]   Once you get out past a certain age, there are components of the brain that can become permanently blind to it,
[02:34:43.460 --> 02:34:45.760]   which doesn't mean they're going to lose more vision.
[02:34:45.760 --> 02:34:50.040]   It just means that they're probably only seen correctly through one eye.
[02:34:50.040 --> 02:34:56.320]   So these, and it's normal for babies actually to, the development of the ocular muscles of the eyes,
[02:34:56.320 --> 02:34:59.360]   they don't always track so well and fixate so well.
[02:34:59.360 --> 02:35:02.880]   Sometimes it's self-correcting, but they should really see a pediatric ophthalmologist.
[02:35:02.880 --> 02:35:04.080]   Sorry, I can't help myself.
[02:35:04.080 --> 02:35:04.740]   No, no, absolutely.
[02:35:04.740 --> 02:35:06.760]   Half of my appointment is in ophthalmology.
[02:35:06.760 --> 02:35:09.500]   So if I don't say this, my colleagues will be angry.
[02:35:09.500 --> 02:35:18.200]   But a lot of vision can be saved by simple patch, or as you put, like eye drop interventions that only have to be done early in development.
[02:35:18.200 --> 02:35:20.300]   I have many friends whose kids have had these issues.
[02:35:20.300 --> 02:35:22.120]   It's amazing how few experiments were done.
[02:35:22.120 --> 02:35:23.900]   I mean, they didn't do thousands of animals.
[02:35:23.900 --> 02:35:24.580]   They did a handful.
[02:35:24.580 --> 02:35:25.480]   It's the smallest number.
[02:35:25.480 --> 02:35:26.540]   It had a very specific question.
[02:35:26.540 --> 02:35:28.040]   It came up with a very specific answer.
[02:35:28.040 --> 02:35:30.720]   So I do think the specificity has worked.
[02:35:30.720 --> 02:35:39.260]   On the molecular side, most people, and I'm not the one first saying this, many people, we looked for psychiatric disorders to mostly be caused by a single solution.
[02:35:39.260 --> 02:35:40.420]   That's the smart thing to do.
[02:35:40.420 --> 02:35:43.060]   If it's something simple, like in your car, it usually is something simple.
[02:35:43.060 --> 02:35:44.480]   When your car is broken, there's usually one problem.
[02:35:44.480 --> 02:35:48.340]   But in an economic system, there's probably 50 problems.
[02:35:48.340 --> 02:35:50.040]   There's probably not one thing that's the bad thing.
[02:35:50.040 --> 02:35:50.920]   You've got to fix a lot of things.
[02:35:51.280 --> 02:35:55.580]   In an ecosystem, maybe somebody removed wolves, and all you've got to do is put wolves back, and it's an easy fix.
[02:35:55.580 --> 02:36:01.300]   But typically, it's some big, messy situation you're trying to better understand.
[02:36:01.300 --> 02:36:04.940]   And I think a biologist, we've talked about that.
[02:36:04.940 --> 02:36:09.560]   I read a book not too long ago on kelp, sea kelp, macrocystis.
[02:36:09.560 --> 02:36:11.800]   And like, why does kelp live where it lives?
[02:36:11.800 --> 02:36:15.280]   It just includes hundreds of grazers, things adding to it.
[02:36:15.280 --> 02:36:18.740]   The story you've heard about sea urchins and otters is way too simple.
[02:36:19.180 --> 02:36:21.180]   But it's okay. It's a way to think about it.
[02:36:21.180 --> 02:36:24.440]   But we just come to understand, to take care of the natural world, it's complicated.
[02:36:24.440 --> 02:36:26.160]   There's not going to be this one silver bullet.
[02:36:26.160 --> 02:36:28.300]   And that's the same of our brain.
[02:36:28.300 --> 02:36:29.780]   And I like that. I'm fine with that.
[02:36:29.780 --> 02:36:31.960]   My health, my diet, my whatever, it's about diversity.
[02:36:31.960 --> 02:36:33.300]   Try to eat a bunch of things.
[02:36:33.300 --> 02:36:38.980]   If someone is just eating potatoes and tater tots and chicken nuggets, that's all they eat.
[02:36:38.980 --> 02:36:42.100]   Yes, you're going to need to supplement something that's going to have problems.
[02:36:42.100 --> 02:36:45.840]   And a lot of people are, because their socioeconomic status is a big one that we don't talk too much about.
[02:36:45.840 --> 02:36:50.900]   Like the neuroscience are trying to understand, if you're poor, what things are worth it and what things aren't.
[02:36:50.900 --> 02:36:54.680]   It's just really hard to make these judgments easy to be a parent when you've got lots of resources.
[02:36:54.680 --> 02:36:59.880]   It's really hard when you're facing latchkey kids and expensive food and all the rest.
[02:37:00.440 --> 02:37:03.000]   So that specificity thing, I think we've nailed it on choline.
[02:37:03.000 --> 02:37:04.780]   I think we've nailed it on a lot of these stories.
[02:37:04.780 --> 02:37:08.880]   But does that mean we've got blanket cures for most neurological and psychiatric disorders?
[02:37:08.880 --> 02:37:09.520]   No.
[02:37:09.520 --> 02:37:12.640]   For 10 of us, we understood, we had a theory of what it was.
[02:37:12.640 --> 02:37:16.060]   We ran animal studies.
[02:37:16.060 --> 02:37:17.280]   We reproduced it in animals.
[02:37:17.280 --> 02:37:18.300]   And then we cured it in animals.
[02:37:18.300 --> 02:37:19.640]   And then we did the next step.
[02:37:19.640 --> 02:37:21.780]   And it was not as successful as we wanted to.
[02:37:22.480 --> 02:37:26.000]   So the answer was 50% of people got 50% better.
[02:37:26.000 --> 02:37:29.540]   That is called 75% of the problem is still there.
[02:37:29.540 --> 02:37:30.600]   Not very good.
[02:37:30.600 --> 02:37:36.340]   In addition, we had something called sequestration when the federal government shut down and a large military trial we were going to run got canceled.
[02:37:36.340 --> 02:37:38.040]   Was that recently?
[02:37:38.040 --> 02:37:38.940]   That was years ago.
[02:37:38.940 --> 02:37:39.300]   Okay.
[02:37:39.300 --> 02:37:40.200]   And we're doing this a long time.
[02:37:40.200 --> 02:37:42.880]   But there's just hiccups along the way, political or whatever else.
[02:37:42.880 --> 02:37:46.580]   Well, we were going to invest in it because it was the number one disability in the military.
[02:37:46.580 --> 02:37:48.640]   So we were going to invest in let's treat it.
[02:37:48.640 --> 02:37:51.020]   And then we got sidelined.
[02:37:51.020 --> 02:37:56.120]   Stroke had the advantage that unlike chronic pain and tenderness, we know exactly what causes it.
[02:37:56.120 --> 02:38:00.800]   So my team switched to stroke because there's no controversy about stroke.
[02:38:00.800 --> 02:38:01.920]   No one's faking it.
[02:38:01.920 --> 02:38:03.740]   I can measure it very easily.
[02:38:03.740 --> 02:38:04.800]   I can see the hole in the head.
[02:38:04.800 --> 02:38:05.940]   I can see their functions.
[02:38:05.940 --> 02:38:08.080]   With tenderness and chronic pain, you can't know.
[02:38:08.080 --> 02:38:10.860]   Spinal cord injury, same thing.
[02:38:10.860 --> 02:38:11.860]   You know what causes spinal cord injury.
[02:38:11.900 --> 02:38:15.000]   They had a fight or car accident or a fall or a boating accident.
[02:38:15.000 --> 02:38:18.880]   For PTSD, it's the only mental illness we know what causes it.
[02:38:18.880 --> 02:38:24.680]   The diagnostic criterion A, trauma, is what causes you to have that thing by definition.
[02:38:24.680 --> 02:38:25.940]   The other is schizophrenia.
[02:38:25.940 --> 02:38:26.520]   We've got theories.
[02:38:26.520 --> 02:38:27.100]   We've got genes.
[02:38:27.100 --> 02:38:27.800]   We've got factors.
[02:38:27.800 --> 02:38:30.220]   So we chose these first three very intentionally.
[02:38:30.220 --> 02:38:35.440]   And we're now sort of working our way back saying if synaptic plasticity,
[02:38:35.440 --> 02:38:38.540]   rewiring of new connections to the brain, if that could be used therapeutically.
[02:38:38.540 --> 02:38:39.480]   And we know it can.
[02:38:39.480 --> 02:38:41.320]   I mean, that's how rehab works.
[02:38:41.780 --> 02:38:45.600]   That's how people get better from drug addiction or cutting or whatever else they're doing.
[02:38:45.600 --> 02:38:46.520]   Someone talks to them.
[02:38:46.520 --> 02:38:47.600]   It's just kind of inefficient.
[02:38:47.600 --> 02:38:49.300]   It takes a lot of time, a lot of money.
[02:38:49.300 --> 02:38:51.120]   Can we help the therapist be better?
[02:38:51.120 --> 02:38:53.140]   Therapists love neuroplasticity.
[02:38:53.140 --> 02:38:54.620]   We haven't talked to therapists about neuroplasticity.
[02:38:54.620 --> 02:38:56.060]   They love them some neuroplasticity.
[02:38:56.060 --> 02:38:59.740]   But then they're disappointed because it's like, but I can't make everybody better.
[02:39:00.300 --> 02:39:03.000]   And I can't make anybody all the way better most of the time.
[02:39:03.000 --> 02:39:04.880]   So how can both be true?
[02:39:04.880 --> 02:39:06.200]   That's just how it is.
[02:39:06.200 --> 02:39:07.680]   It's a hard problem we didn't evolve with.
[02:39:07.680 --> 02:39:09.400]   We don't have a great solution.
[02:39:09.400 --> 02:39:11.040]   But we could do something about it.
[02:39:11.040 --> 02:39:12.940]   This was true of cancer 100 years ago.
[02:39:12.940 --> 02:39:15.620]   We would just say, grandpa died of old age.
[02:39:15.620 --> 02:39:20.480]   We didn't know there were cells ravishing his body, prostate cancer, colon cancer, cervical cancer.
[02:39:20.480 --> 02:39:21.160]   We didn't know that.
[02:39:21.520 --> 02:39:24.080]   We just thought, he got bad, his heart stopped, he died.
[02:39:24.080 --> 02:39:24.780]   That's what happened.
[02:39:24.780 --> 02:39:28.880]   Now we took it apart, but it took decade after decade after decade.
[02:39:28.880 --> 02:39:31.100]   And we first thought there was one cell type.
[02:39:31.100 --> 02:39:35.180]   Now we know it's a whole living ecosystem of cancer cells, feeding each other alive.
[02:39:35.180 --> 02:39:36.280]   And you can't just attack it one way.
[02:39:36.280 --> 02:39:37.340]   You've got to attack it multiple ways.
[02:39:37.340 --> 02:39:40.360]   That's how I'm coming to understand these brain disorders.
[02:39:40.360 --> 02:39:42.060]   They're really tricky bastards.
[02:39:42.060 --> 02:39:45.060]   When you look at HIV, you go, oh, that's a good one.
[02:39:45.060 --> 02:39:46.380]   That's not just some virus.
[02:39:46.380 --> 02:39:49.880]   That's not just some bacteria with some polysaccharide you can attack.
[02:39:50.660 --> 02:39:56.000]   That thing is really, really tricky, which is why we don't have an easy cure for this communicable disease,
[02:39:56.000 --> 02:39:57.900]   which we totally understand, HIV.
[02:39:57.900 --> 02:40:00.180]   It's just a particularly sneaky one.
[02:40:00.180 --> 02:40:06.160]   But the specificity for all kinds of viruses, all kinds of bacteria,
[02:40:06.160 --> 02:40:08.380]   we have an amazing armamentarium.
[02:40:08.380 --> 02:40:10.580]   For the brain, we've got a couple.
[02:40:10.580 --> 02:40:12.000]   I would say Parkinson's disease.
[02:40:12.000 --> 02:40:12.940]   We know what causes it.
[02:40:12.940 --> 02:40:15.640]   And the symptom is you don't have enough output from your motor system,
[02:40:15.640 --> 02:40:19.060]   and so you can disinhibit the system with a deep brain stimulating nucleus.
[02:40:19.380 --> 02:40:20.740]   And people, everyone's seen the videos.
[02:40:20.740 --> 02:40:24.400]   If you haven't, go YouTube, Parkinson's on and off, deep brain stimulator,
[02:40:24.400 --> 02:40:27.520]   and you'll see people who are golfing and then can barely walk.
[02:40:27.520 --> 02:40:32.700]   Now, you and I know, as many people do, those final neurons will eventually die,
[02:40:32.700 --> 02:40:34.020]   and there will eventually be a problem.
[02:40:34.020 --> 02:40:38.340]   You're not changing the death that's happening in a person with Parkinson's,
[02:40:38.340 --> 02:40:40.400]   but you're giving them years of new life.
[02:40:40.500 --> 02:40:43.080]   That's fantastic for relatively cost-effective tools.
[02:40:43.080 --> 02:40:44.720]   Cochlear implants, same thing.
[02:40:44.720 --> 02:40:45.860]   People are stone deaf.
[02:40:45.860 --> 02:40:48.380]   They're not lip reading.
[02:40:48.380 --> 02:40:50.880]   They can pick up a phone, just like you and I, and have a conversation.
[02:40:50.880 --> 02:40:56.320]   They are fully restored to normal hearing and conversation, but it's a small subset.
[02:40:56.320 --> 02:41:02.800]   The list of things we've cured is small, but those are proof of concepts that if we understand it,
[02:41:02.840 --> 02:41:05.840]   we can cure more, not just alleviate, not just treat, but cure.
[02:41:05.840 --> 02:41:10.140]   Well, I hear a couple of things, and I'm in agreement with you.
[02:41:10.140 --> 02:41:16.860]   First, everyone needs to appreciate that brains are made up of circuits and networks and chemicals,
[02:41:16.860 --> 02:41:25.360]   and it's very unlikely, except for rare case conditions, that there will be a one-pill, one-drug type solution
[02:41:25.360 --> 02:41:32.500]   or that there will be a five-pill, five-drug type solution to any neurologic or psychiatric illness.
[02:41:32.500 --> 02:41:34.020]   Sorry, folks.
[02:41:34.020 --> 02:41:35.180]   That's the reality.
[02:41:35.180 --> 02:41:40.140]   I think, you know, the last 50 years of research into these things has revealed that.
[02:41:41.240 --> 02:41:46.240]   I'm also hearing that direct-circuit stimulation holds great promise.
[02:41:46.240 --> 02:41:53.580]   Your work, people with spinal cord injury, tinnitus, enhancement of learning in non-injured people,
[02:41:53.580 --> 02:41:57.760]   some of that work has been done, not as much for obvious reasons.
[02:41:57.760 --> 02:41:59.480]   Treating disease is kind of the priority.
[02:41:59.480 --> 02:42:07.160]   Brain stimulation and neural pathway stimulation from the brain to body, a.k.a. vagus stimulation, works.
[02:42:07.160 --> 02:42:09.680]   But it's not the whole picture.
[02:42:09.680 --> 02:42:16.780]   You also need very targeted training during the stimulation to know exactly what patterns of neural firing
[02:42:16.780 --> 02:42:23.660]   you're trying to notch out, as we say, and which ones you're trying to exacerbate to overtake the neural territory.
[02:42:23.660 --> 02:42:26.520]   And then the third category, which is drugs.
[02:42:26.520 --> 02:42:32.560]   Whether it's through a naturally occurring compound, like a mushroom that grows out of the ground,
[02:42:32.560 --> 02:42:38.160]   or synthetically derives psilocybin, or now a lot of the psychedelics, like LSD,
[02:42:38.160 --> 02:42:45.260]   they're trying to manufacture variations on them that don't carry the hallucinogenic properties,
[02:42:45.260 --> 02:42:53.360]   but perhaps can still work as plasticity agents.
[02:42:53.360 --> 02:42:59.360]   But drugs, I mean, maybe better ways to augment serotonin that are neither psychedelic nor SSRIs.
[02:42:59.360 --> 02:43:03.360]   It seems like the tripartite approach is going to be best.
[02:43:03.360 --> 02:43:13.460]   It's going to be devices plus training plus drugs, so that someone can really boost the plasticity in the areas they want,
[02:43:13.460 --> 02:43:16.380]   and they can suppress neural circuit function in the areas they don't.
[02:43:16.380 --> 02:43:21.460]   And I think when we're talking about this, I think this is going to be in the context of stroke, spinal cord injury, dementia.
[02:43:21.460 --> 02:43:26.380]   Whenever you say autism, I always get a lot of comments saying, wait, why are we trying to cure autism?
[02:43:26.380 --> 02:43:35.040]   We're talking about people with such serious degrees so far on the spectrum that they need constant care from others.
[02:43:35.040 --> 02:43:35.940]   They're not functional.
[02:43:35.940 --> 02:43:36.460]   Self-injurious.
[02:43:36.460 --> 02:43:38.540]   Self-injurious, yeah, this kind of thing.
[02:43:38.540 --> 02:43:41.560]   I'm not talking about people who are on the spectrum and functional.
[02:43:42.560 --> 02:43:46.440]   I know many people, I work with many people that are on the spectrum and functional.
[02:43:46.440 --> 02:43:49.680]   So, and on and on.
[02:43:49.680 --> 02:43:57.000]   So, I think that if I were in charge, and I'm not in charge, but if I were controlling the NIH budget for neuroscience research,
[02:43:57.000 --> 02:44:02.360]   I would be encouraging all three of these areas, as well as trying to parse the various circuitries.
[02:44:02.360 --> 02:44:03.520]   I think it's all essential.
[02:44:03.520 --> 02:44:12.140]   I will say that I've been surprised how long it took for the adult plasticity work that you and Merzenich
[02:44:12.140 --> 02:44:16.560]   and Greg Reckon's own and others did to really make it into medicine.
[02:44:16.560 --> 02:44:19.720]   I feel like it took a while, not because you weren't busy working on it,
[02:44:19.720 --> 02:44:25.080]   but because it didn't seem like there was a big belief in brain-machine interface for a long time.
[02:44:25.080 --> 02:44:26.040]   Now we have Neuralink.
[02:44:26.040 --> 02:44:26.620]   We have you.
[02:44:26.620 --> 02:44:33.020]   We've got folks like our friend Eddie Chang, who's doing remarkable work and taking people out of locked-in syndrome.
[02:44:33.020 --> 02:44:34.980]   I think it's starting to happen.
[02:44:34.980 --> 02:44:36.140]   I'm very encouraged.
[02:44:36.140 --> 02:44:41.660]   I have a new, recently, a new explanation because it was frustrating to me being raised by these
[02:44:41.720 --> 02:44:46.360]   fathers like we both were who studied neuroplasticity and talked about it and trained about it.
[02:44:46.360 --> 02:44:48.960]   It was frustrating to me at first that people didn't get it.
[02:44:48.960 --> 02:44:51.920]   I've come around in my way of thinking about this.
[02:44:51.920 --> 02:44:54.920]   It was smarter to hope that it was going to be simple.
[02:44:54.920 --> 02:44:57.080]   It was smarter to hope that drugs would work.
[02:44:57.080 --> 02:45:00.360]   It was smarter to hope that a stem cell could be added, that there was one cell type.
[02:45:00.740 --> 02:45:02.260]   That's actually not unreasonable.
[02:45:02.260 --> 02:45:04.180]   If your car is broken, hope it's something simple.
[02:45:04.180 --> 02:45:05.940]   Don't start off with a more complicated one.
[02:45:05.940 --> 02:45:08.600]   It's sort of Occam's razor at a societal level.
[02:45:08.600 --> 02:45:10.680]   The question is how long do you keep doing it?
[02:45:10.680 --> 02:45:11.740]   And I think you're making this point.
[02:45:11.740 --> 02:45:18.260]   You've got this one nice paper with adeno-associated virus, gene therapy, changing things.
[02:45:18.260 --> 02:45:19.380]   I mean, these are all on the table.
[02:45:19.380 --> 02:45:20.220]   All of them.
[02:45:20.720 --> 02:45:23.060]   Now, some of them are more safe than others.
[02:45:23.060 --> 02:45:23.760]   Some are more challenging.
[02:45:23.760 --> 02:45:26.620]   But the combination therapy, we have a combination problem.
[02:45:26.620 --> 02:45:30.340]   And it's a pretty big problem, whether it's an obesity problem or degenerative disorders,
[02:45:30.340 --> 02:45:33.680]   neurodevelopmental disorders, anxiety disorders, mood disorders.
[02:45:34.580 --> 02:45:36.240]   But we don't need to medicalize everything.
[02:45:36.240 --> 02:45:37.880]   If you're fine, you're fine.
[02:45:37.880 --> 02:45:40.840]   But if you've got a serious problem, these are not subtle conditions.
[02:45:40.840 --> 02:45:43.120]   These are people who are really, really, really struggling.
[02:45:43.120 --> 02:45:45.480]   They're willing to try anything.
[02:45:45.480 --> 02:45:48.660]   And we have this obligation to sort out what works.
[02:45:48.660 --> 02:45:51.080]   And throwing the kitchen sink at it is not so great.
[02:45:51.080 --> 02:45:54.580]   The FDA is having to wrestle with, what do you mean you're going to do four different therapies?
[02:45:54.580 --> 02:45:56.060]   Let's just take a two-combination therapy.
[02:45:56.060 --> 02:46:01.000]   Do I now have to do a four-arm study where I do one group who gets both, one who gets just this,
[02:46:01.000 --> 02:46:02.500]   one who gets just that, and one who gets neither?
[02:46:03.300 --> 02:46:05.140]   Statistically, that really increases the cost.
[02:46:05.140 --> 02:46:08.980]   So we say, no, let's do it where you do all the things you think are going to need it,
[02:46:08.980 --> 02:46:10.220]   and then none of those things.
[02:46:10.220 --> 02:46:12.900]   So even, are we doing science experiments?
[02:46:12.900 --> 02:46:14.180]   No, we're trying to treat people.
[02:46:14.180 --> 02:46:16.300]   So I think the pieces of the puzzle are there.
[02:46:16.300 --> 02:46:20.840]   And to my mind, the animal literature is clear it's complicated.
[02:46:20.840 --> 02:46:25.740]   I mean, I think about the number of genes that had, for ocular dominance, plasticity,
[02:46:25.740 --> 02:46:27.620]   the change in the visual system with two eyes.
[02:46:27.620 --> 02:46:29.480]   How many genes play a role in that?
[02:46:29.480 --> 02:46:30.200]   Many genes.
[02:46:30.200 --> 02:46:32.920]   Many times one said, here's a new gene that plays a role.
[02:46:32.980 --> 02:46:33.800]   There's a new gene that plays a role.
[02:46:33.800 --> 02:46:34.900]   It's complicated.
[02:46:34.900 --> 02:46:36.280]   We didn't know that.
[02:46:36.280 --> 02:46:41.060]   We really thought it was going to be like our designed world, where there's something simple,
[02:46:41.060 --> 02:46:46.400]   where you fix it, this grindstone isn't working because the water's not flowing in right,
[02:46:46.400 --> 02:46:47.000]   turning this thing.
[02:46:47.000 --> 02:46:49.620]   And when you're fixing a car, cars are complicated.
[02:46:49.620 --> 02:46:51.260]   Apologies to all my friends who are mechanics.
[02:46:51.760 --> 02:46:59.640]   But by comparison to the brain, where you're talking about 20,000 different genes, you're talking about billions of different inputs coming in every hour.
[02:46:59.640 --> 02:47:02.260]   And it's stored in a network of trillions of synapses.
[02:47:02.260 --> 02:47:03.920]   It's just really very complicated.
[02:47:04.640 --> 02:47:06.480]   We didn't have enough humility.
[02:47:06.480 --> 02:47:12.960]   But I now think even if we had the humility, it was still smart to spend 50 years trying what we tried.
[02:47:12.960 --> 02:47:14.420]   It just didn't work.
[02:47:14.420 --> 02:47:16.840]   And now the question is, what do we do next?
[02:47:16.840 --> 02:47:17.960]   And I think there will be investment.
[02:47:17.960 --> 02:47:19.020]   I think people who are enlightened.
[02:47:19.020 --> 02:47:19.720]   And it's interesting.
[02:47:19.820 --> 02:47:21.260]   Patients really like the cochlear implant.
[02:47:21.260 --> 02:47:22.120]   They know how it works.
[02:47:22.120 --> 02:47:23.520]   It's not just take a pill.
[02:47:23.520 --> 02:47:30.280]   It's these, you know, eight or 20 electrodes are on my nerve, which is organized like piano keys.
[02:47:30.280 --> 02:47:31.860]   And each one pushes a different button.
[02:47:31.860 --> 02:47:32.320]   These are highs.
[02:47:32.320 --> 02:47:32.760]   These are lows.
[02:47:32.760 --> 02:47:34.140]   They kind of get it.
[02:47:34.140 --> 02:47:35.220]   They take ownership of it.
[02:47:35.220 --> 02:47:36.660]   And you see kids at the pool now.
[02:47:36.660 --> 02:47:37.880]   I mean, they've got bright pink ones.
[02:47:37.880 --> 02:47:39.500]   They're not bothered by it whatsoever.
[02:47:39.500 --> 02:47:40.540]   That's how I hear.
[02:47:40.540 --> 02:47:44.140]   And so I think that openness, the stigma is now gone.
[02:47:44.140 --> 02:47:46.000]   Before, we had lots of stigma.
[02:47:46.000 --> 02:47:49.620]   And for me, the chemical imbalance thing creates a lot of stigma.
[02:47:50.200 --> 02:47:50.740]   You're broken.
[02:47:50.740 --> 02:47:54.760]   The only person who can fix you is someone who has the ability to prescribe medications.
[02:47:54.760 --> 02:47:56.160]   Doctors don't want that therapy.
[02:47:56.160 --> 02:47:57.520]   They're not looking to be the boss of the world.
[02:47:57.520 --> 02:48:00.880]   They're intimidated, bothered, humbled by it themselves.
[02:48:00.880 --> 02:48:03.460]   But that's the system that we were entertaining.
[02:48:03.460 --> 02:48:06.820]   Now that we have a situation where you're saying, you have a brain.
[02:48:06.820 --> 02:48:08.240]   I'm going to help you with it.
[02:48:08.240 --> 02:48:15.200]   Whether you're a coach, a parent, spiritual guidance person, a therapist, let's work to be who you want to be.
[02:48:15.200 --> 02:48:17.220]   I think that's just a much more healthy way.
[02:48:17.220 --> 02:48:18.240]   I think it's much more accurate.
[02:48:18.660 --> 02:48:21.500]   It's much more how economies, ecosystems work.
[02:48:21.500 --> 02:48:24.920]   These distributed complex networks, there's not usually a one-size-fits-all.
[02:48:24.920 --> 02:48:27.480]   And what's nice is our lived experiences really matter.
[02:48:27.480 --> 02:48:30.480]   What you think is working for you really is valuable.
[02:48:30.480 --> 02:48:31.880]   And we're all really different.
[02:48:31.880 --> 02:48:36.420]   You know, the kinds of fiber supplements someone uses or the kind of sleep regimen someone else needs.
[02:48:36.420 --> 02:48:39.060]   I had someone at UCSF, God, she slept like four hours a night.
[02:48:39.060 --> 02:48:40.260]   I was like, this is impossible.
[02:48:40.260 --> 02:48:42.240]   She made amazing things happen.
[02:48:42.240 --> 02:48:43.320]   I couldn't do it.
[02:48:43.320 --> 02:48:44.040]   She's still alive.
[02:48:44.200 --> 02:48:44.600]   She is.
[02:48:44.600 --> 02:48:45.280]   She's phenomenal.
[02:48:45.280 --> 02:48:47.660]   Some people need very little sleep.
[02:48:47.660 --> 02:48:48.360]   It's amazing to me.
[02:48:48.360 --> 02:48:50.720]   I know some of those or they learn to get by on it.
[02:48:50.720 --> 02:48:54.540]   I must ask because I can't help but ask.
[02:48:54.540 --> 02:49:06.380]   There are a bunch of domains where brain-machine interface is being talked about and used not to cure disease but to increase or accelerate plasticity.
[02:49:06.660 --> 02:49:10.320]   Some years ago there was a device – and I'm not trying to pick on any companies here.
[02:49:10.320 --> 02:49:11.700]   I have no stake in this.
[02:49:11.700 --> 02:49:14.400]   But people were excited about it.
[02:49:14.400 --> 02:49:23.400]   It looked like a headband that you could put over your motor cortex or sensory cortex while you were practicing your golf swing or your baseball swing or studying.
[02:49:24.400 --> 02:49:30.600]   And the idea was that you were going to boost the levels of activity in the neurons sitting below that band.
[02:49:30.600 --> 02:49:38.200]   And the rationale was you're increasing the likelihood that those cells were going to fire together, wire together.
[02:49:38.200 --> 02:49:42.500]   I mean, crudely speaking, the logic was sort of there.
[02:49:42.500 --> 02:49:47.900]   There were a lot of pieces missing like the critical spike timing-dependent plasticity that you were talking about before.
[02:49:48.440 --> 02:49:50.520]   It's unclear if it impacted neuromodulation.
[02:49:50.520 --> 02:49:52.720]   I don't know whatever happened to those sorts of devices.
[02:49:52.720 --> 02:49:55.740]   It seems like it just kind of went the way of nobody uses them anymore.
[02:49:55.740 --> 02:49:57.180]   I certainly don't see people using them.
[02:49:57.180 --> 02:49:59.060]   Nowadays, there are a number of things.
[02:49:59.060 --> 02:50:08.480]   We get sent these from time to time where the idea is that you're going to get vagal stimulation with a cuff that either goes around your midsection.
[02:50:08.480 --> 02:50:13.780]   So these are non-invasive things or an anklet tool that provides feedback by vibration.
[02:50:13.780 --> 02:50:24.000]   I've also recently seen a growing number of companies that are developing visors for enhancing sleep.
[02:50:24.000 --> 02:50:29.940]   There, I actually think there's an opportunity because some of them can engage eye movements.
[02:50:29.940 --> 02:50:37.100]   There's some very interesting literature about specific patterns of eye movements making it easier to fall asleep very quickly.
[02:50:37.380 --> 02:50:38.980]   I'll get to this in a future podcast.
[02:50:38.980 --> 02:50:40.320]   But this is interesting.
[02:50:40.320 --> 02:50:48.040]   But what are your thoughts on non-invasive tools, commercial devices to boost plasticity?
[02:50:48.040 --> 02:50:50.920]   And I'm talking about in the absence of any pharmacology.
[02:50:50.920 --> 02:50:52.820]   Just put this thing over your head.
[02:50:52.820 --> 02:50:54.780]   Put this helmet on.
[02:50:54.780 --> 02:50:57.020]   We're not just going to measure brain activity.
[02:50:57.020 --> 02:50:59.440]   We're going to improve learning and memory.
[02:50:59.440 --> 02:51:00.380]   Yeah.
[02:51:00.380 --> 02:51:02.920]   I mean, the key to the brain is information.
[02:51:03.120 --> 02:51:09.100]   The way ChatGPT got so smart is it knows every word we ever wrote to each other and every great book and all that.
[02:51:09.100 --> 02:51:10.120]   It just had a lot of information.
[02:51:10.120 --> 02:51:14.820]   And so the question is always what information is being added to the network?
[02:51:14.820 --> 02:51:18.600]   And so medications tend not to add a huge amount of information.
[02:51:18.600 --> 02:51:19.280]   They may bias.
[02:51:19.280 --> 02:51:19.900]   They may help.
[02:51:20.460 --> 02:51:24.860]   But experiences you have and you learn to play violin, you did a lot of stuff.
[02:51:24.860 --> 02:51:31.960]   And that richness of information, which we, since the early days of information theory, Claude Shannon, we call it bits.
[02:51:31.960 --> 02:51:33.660]   How many bits of information is it providing?
[02:51:33.660 --> 02:51:37.980]   If something is always on, it can't be providing much information.
[02:51:38.780 --> 02:51:40.360]   So it was a big thing.
[02:51:40.360 --> 02:51:46.480]   It was called transcortical direct, transcranial direct current stimulation, TDCS.
[02:51:46.480 --> 02:51:50.380]   There was transcranial magnetic stimulation, TMS.
[02:51:50.380 --> 02:51:52.840]   Each of these things had lots of great advantages.
[02:51:52.840 --> 02:51:59.280]   But the total amount of information they were providing to the neurons was relatively small compared to listening to my voice.
[02:51:59.280 --> 02:52:02.240]   My voice, if I write this down, you're going to see it's going to be megabytes.
[02:52:02.240 --> 02:52:04.720]   I record 20 minutes worth of me talking.
[02:52:04.720 --> 02:52:08.400]   It's going to take megabytes to write down all the vibrations if you want to hear my pitch intonation.
[02:52:08.820 --> 02:52:10.720]   If you just write down the letters, it could be much smaller.
[02:52:10.720 --> 02:52:12.140]   But there's still a lot of information.
[02:52:12.140 --> 02:52:18.480]   So I think that's the way I think about it is how much information is being provided is the key unit.
[02:52:18.480 --> 02:52:23.080]   So if the thing is on all the time and not really feeding anything back, it's probably not helping much.
[02:52:23.080 --> 02:52:24.320]   It's just like taking nicotine.
[02:52:24.320 --> 02:52:26.420]   It's just like taking some nicotine gum.
[02:52:26.420 --> 02:52:30.540]   It's raising acetylcholine that's increasing the amount of firing, but there's not enough specificity there.
[02:52:30.540 --> 02:52:36.500]   In terms of timing, it sounds like it might slightly bias the probability that a learning event will occur.
[02:52:36.700 --> 02:52:45.980]   But maybe one of the reasons these devices keep surfacing, these commercial devices keep surfacing and then disappearing, is that no one is raving about the results.
[02:52:45.980 --> 02:52:46.320]   That's right.
[02:52:46.320 --> 02:52:50.980]   You would think if something was truly awesome, it would take off.
[02:52:50.980 --> 02:52:52.660]   And that's why FDA decides not to regulate it.
[02:52:52.660 --> 02:52:53.200]   It's not dangerous.
[02:52:53.200 --> 02:53:00.020]   If you want to put a stimulator on that activates your stuff, you want to wear pressure point bands, you want to do copper, these things come, they go.
[02:53:00.020 --> 02:53:01.000]   That's totally fine.
[02:53:01.200 --> 02:53:03.380]   We don't just don't make medical claims.
[02:53:03.380 --> 02:53:05.780]   If you make medical claims, that's crossing a line.
[02:53:05.780 --> 02:53:09.500]   We now have to switch gears and say we're going to have to come down like a ton of bricks on this.
[02:53:09.500 --> 02:53:10.300]   You haven't shown that.
[02:53:10.300 --> 02:53:18.240]   And so there have been claims about video games online and companies have had to pay big fines because they made claims that this video game will fix whatever it is.
[02:53:18.240 --> 02:53:19.400]   Stutter is a big one.
[02:53:19.480 --> 02:53:21.340]   I have a friend down the street who's got a serious study.
[02:53:21.340 --> 02:53:22.960]   He's constantly asking, what can we do?
[02:53:22.960 --> 02:53:23.960]   We have a model.
[02:53:23.960 --> 02:53:25.200]   We think we understand.
[02:53:25.200 --> 02:53:26.400]   But everybody's different, right?
[02:53:26.400 --> 02:53:28.120]   People study for different reasons, different times.
[02:53:28.120 --> 02:53:29.860]   But clearly there's something in the brain.
[02:53:29.860 --> 02:53:30.640]   They'll tell you that.
[02:53:30.640 --> 02:53:31.340]   You ask them that.
[02:53:31.340 --> 02:53:34.500]   They don't think there's too much blood, too much bile, too much phlegm.
[02:53:34.500 --> 02:53:35.780]   That's not the problem.
[02:53:35.780 --> 02:53:37.100]   It's the wiring that's wrong.
[02:53:37.100 --> 02:53:39.000]   And I'm optimistic about that.
[02:53:39.000 --> 02:53:40.680]   That is something you can do something about.
[02:53:40.680 --> 02:53:42.340]   But it is not going to be easy.
[02:53:42.340 --> 02:53:48.340]   So I would say look for things that are closed loop, that connect, that they're providing useful information, that have sensors.
[02:53:48.460 --> 02:53:51.380]   If it sounds too good to be true, it probably is.
[02:53:51.380 --> 02:53:53.700]   I think that's the sort of easiest way to say it.
[02:53:53.700 --> 02:53:58.940]   Electrically activating your skin, providing extra feedback, having a bar.
[02:53:58.940 --> 02:54:00.700]   Let's just take you trying to learn to drive a standard.
[02:54:00.700 --> 02:54:01.460]   You have a tachometer.
[02:54:01.460 --> 02:54:04.600]   Of course it's going to be easier if you can hear the sound of the engine revving.
[02:54:04.600 --> 02:54:05.300]   That's more information.
[02:54:05.300 --> 02:54:07.260]   I know what I'm doing when it stalls.
[02:54:07.260 --> 02:54:11.580]   If I can give someone feedback, how fast was that ball spinning?
[02:54:11.580 --> 02:54:13.020]   I've got a friend who owns a golf shop.
[02:54:13.020 --> 02:54:16.440]   I mean, it's incredible the tools they can give you of what your spin and slice is.
[02:54:16.440 --> 02:54:17.780]   That's really useful information.
[02:54:17.980 --> 02:54:22.200]   If it's providing useful information about what you're doing, that just tends to be helpful.
[02:54:22.200 --> 02:54:25.400]   If it's not, it can be greatly distracting.
[02:54:25.400 --> 02:54:33.800]   And there are certain circumstances where adding extra stimulations, extra sounds, extra buzzers, extra whatever, whether you're trying to be a running app or anything else, it can make you worse.
[02:54:33.900 --> 02:54:38.020]   Because you're now focused on the running app instead of on the, let's just run.
[02:54:38.020 --> 02:54:41.020]   So I think people are trying to figure out when should we instrument it?
[02:54:41.020 --> 02:54:42.320]   When should we add this extra stuff?
[02:54:42.320 --> 02:54:43.740]   When do you need the boost and when do you not?
[02:54:43.740 --> 02:54:46.460]   And I'm frankly pretty impressed by the consumer.
[02:54:46.460 --> 02:54:47.520]   They tend to figure it out.
[02:54:47.520 --> 02:54:49.800]   They tend to be pretty skeptical, as they should be.
[02:54:49.800 --> 02:54:51.280]   And they tend to draw conclusions.
[02:54:51.620 --> 02:54:53.580]   If it's working among a lot of my friends, let's try it.
[02:54:53.580 --> 02:54:54.700]   And they're pretty smart, too.
[02:54:54.700 --> 02:54:55.800]   There's no harm.
[02:54:55.800 --> 02:54:56.320]   Why not try it?
[02:54:56.320 --> 02:54:57.960]   They can tell what's dangerous and what's not.
[02:54:57.960 --> 02:54:59.680]   If it hurts, I probably shouldn't do that.
[02:54:59.680 --> 02:55:01.220]   If it doesn't hurt, I'll try it for a while.
[02:55:01.220 --> 02:55:04.020]   But they tend to end up in their drawer.
[02:55:04.880 --> 02:55:10.300]   But even cochlear or hearing aids, even hearing aids often end up in the drawer because they're not, they didn't get a really good one.
[02:55:10.300 --> 02:55:16.420]   They didn't get a, so technology has to be really quite good to make it to that level of making a clinically detectable difference.
[02:55:16.420 --> 02:55:18.340]   Or habit forming or addictive.
[02:55:18.340 --> 02:55:24.580]   Because in the case of nicotine, I see a lot of people who start with one three milligram pouch or gum per day.
[02:55:24.580 --> 02:55:25.940]   And then pretty soon they're up to six.
[02:55:25.940 --> 02:55:27.920]   And then they're half a canister.
[02:55:28.280 --> 02:55:42.280]   So sometimes in an attempt to get the boost in energy or focus or whatever, or neuroplasticity, people end up simply with a dependence on the tool, even if the tool didn't have much of an effect.
[02:55:42.280 --> 02:55:45.720]   Yeah, we haven't talked about two things just from the evolutionary part.
[02:55:45.720 --> 02:55:47.580]   Why do we get used to everything?
[02:55:47.580 --> 02:55:49.740]   Why if you take morphine, do you just need more morphine?
[02:55:49.740 --> 02:55:51.260]   Why are we so good at that?
[02:55:51.260 --> 02:55:55.080]   Just we live in lots of environments where we're going to expose a lot of things.
[02:55:55.080 --> 02:55:57.840]   Our biology seems to have made us really pretty tough.
[02:55:57.840 --> 02:55:59.120]   We live in all kinds of environments.
[02:55:59.120 --> 02:56:00.100]   People live in Greenland.
[02:56:00.100 --> 02:56:01.940]   They live on, I mean, it's amazing.
[02:56:01.940 --> 02:56:05.160]   It seems like in evolution we were in lots of environments.
[02:56:05.160 --> 02:56:07.820]   And you might have been in an environment where the only thing to eat was poppy flowers.
[02:56:07.820 --> 02:56:12.520]   And so, okay, I'm always surprised how not bad these things are.
[02:56:12.520 --> 02:56:16.580]   I mean, we had the crack epidemic and it was clear that all these babies were going to be just a bunch of wandering zombies.
[02:56:16.580 --> 02:56:22.000]   And then, you know, they were impacted, but not nearly as bad as the worst doomsday scenario.
[02:56:22.000 --> 02:56:24.560]   So I'm always telling parents, babies are tough.
[02:56:24.560 --> 02:56:26.940]   They're not as fragile as you might think.
[02:56:27.180 --> 02:56:29.400]   Things we do to ourselves, not as fragile.
[02:56:29.400 --> 02:56:33.560]   Because evolution has prepared us for all these pushes and pulls, which is a big shock.
[02:56:33.560 --> 02:56:39.460]   You don't want to get a bunch of traumatic brain injuries, but exposure to drugs, it's remarkable what we can tolerate and still be fine.
[02:56:40.500 --> 02:56:43.900]   There's an interesting idea that the psychologists first came up with, but we see this in neuroscience as well.
[02:56:43.900 --> 02:56:47.760]   The inverted U, where you've got to get it just right, not too much.
[02:56:48.180 --> 02:56:53.620]   So more serotonin or norepinephrine enhances memories, but you give more and now it degrades impairments.
[02:56:53.620 --> 02:56:54.560]   Why is that?
[02:56:54.560 --> 02:56:56.280]   I've got a pet theory, no evidence for this whatsoever.
[02:56:56.280 --> 02:57:04.900]   That because we sometimes take an agent, let's say eat some berries or something like that, that then send us over the moon.
[02:57:04.900 --> 02:57:08.680]   We have all these mechanisms that then shut down and say, here are conditions where we don't want to change.
[02:57:09.320 --> 02:57:11.540]   Because rewiring your brain is dangerous, right?
[02:57:11.540 --> 02:57:16.360]   You might live through the food poisoning, but you might now have a rewired brain that would be bad.
[02:57:16.360 --> 02:57:26.400]   So it seems like there's these mechanisms where you want to get, in our case, it's the alpha receptors, the norepinephrine, low affinity receptors, the ones that are easiest to activate, are the alpha receptors.
[02:57:26.400 --> 02:57:32.420]   You want those, but you don't want the beta receptors, and they're not very different.
[02:57:32.420 --> 02:57:39.080]   There's this sweet spot, this Goldilocks zone, and the biology is always pushing us to be right in that, and everybody recognizes that.
[02:57:39.080 --> 02:57:46.920]   People who do meditation, mindfulness, they recognize this, trying to stay in this right sweet spot, which is back to that optimization we've talked a lot about.
[02:57:46.920 --> 02:57:48.520]   Why is that?
[02:57:48.520 --> 02:57:52.920]   That's how you're trying to figure out which is the most important thing, not the max thing.
[02:57:52.920 --> 02:57:55.320]   That might be something that's just pathological and weird.
[02:57:55.440 --> 02:58:00.640]   Not the minimum thing, that's something you can just ignore, but this narrow range of things you're trying to pick out.
[02:58:00.640 --> 02:58:01.120]   It's like shopping.
[02:58:01.120 --> 02:58:02.560]   You don't want to buy all the things in the grocery store.
[02:58:02.560 --> 02:58:04.060]   I'm only looking for certain things.
[02:58:04.060 --> 02:58:09.220]   Well, this is essentially, if we're talking about psychedelics, I mean, you look at the counterculture of the 60s.
[02:58:09.220 --> 02:58:11.700]   And, you know, I grew up hearing stories.
[02:58:11.700 --> 02:58:12.580]   I was born in 75.
[02:58:12.580 --> 02:58:16.620]   I heard stories about, you know, people who took LSD and stared at the sun and, you know, burnt their retinas out.
[02:58:16.620 --> 02:58:18.660]   And I don't know if those stories are true or not.
[02:58:18.660 --> 02:58:20.380]   There was a lot of fear-based messaging.
[02:58:20.380 --> 02:58:24.400]   On the other hand, there were a number of people who took too many drugs.
[02:58:24.480 --> 02:58:29.060]   And there were probably a number of people who should have taken more psychedelics.
[02:58:29.060 --> 02:58:30.160]   Like, we could argue it both ways.
[02:58:30.160 --> 02:58:40.940]   I feel like now that we're sort of returning to this notion that plant-based compounds, in particular psilocybin, MDMA, MDMA is synthesized.
[02:58:40.940 --> 02:58:41.800]   It's not plant-based.
[02:58:41.800 --> 02:58:44.940]   Could potentially be valuable therapeutics for psychiatry.
[02:58:45.600 --> 02:58:49.600]   The idea is not to give people just as much as they want or to give them experiences.
[02:58:49.600 --> 02:58:50.880]   The idea is that it's very targeted.
[02:58:50.880 --> 02:58:52.300]   It's dosage targeted.
[02:58:52.300 --> 02:58:54.380]   It's therapeutically targeted.
[02:58:54.380 --> 02:59:02.160]   And so that getting at that sweet spot, I feel like what I keep hearing from you today is that, you know, there have been enough – by the way, I love your optimism.
[02:59:02.380 --> 02:59:09.260]   You're optimistic even about the mistakes we've made in the past, that they've led us to this place now, that we need to embrace the complexity.
[02:59:09.260 --> 02:59:12.700]   But the tools remain, in my mind, the same.
[02:59:12.700 --> 02:59:20.720]   You've got, in no particular order, you've got devices to measure and devices to alter neural circuits in the brain and body.
[02:59:20.960 --> 02:59:27.040]   You've got pharmacology, drive certain chemicals up and certain chemicals down.
[02:59:27.040 --> 02:59:33.620]   And you've got talking and thinking, reflecting.
[02:59:33.620 --> 02:59:36.660]   I mean, that's basically what we've got.
[02:59:36.660 --> 02:59:37.340]   That's the kit.
[02:59:37.340 --> 02:59:42.780]   And I can't imagine a world where there's an additional tool.
[02:59:42.780 --> 02:59:44.020]   I would just mention gene therapy.
[02:59:44.020 --> 02:59:46.800]   I worked on genes and moved them around a long time ago.
[02:59:46.800 --> 02:59:50.620]   My mom asked me, are you sure we want that gene moved there?
[02:59:51.000 --> 02:59:52.620]   Luckily, we find out genes are moving all the time anyway.
[02:59:52.620 --> 02:59:54.540]   That's not something we're doing that's special.
[02:59:54.540 --> 02:59:58.880]   But whether it's Deschens, muscular dystrophy, or Alzheimer's, if we have to do that, we'll do it.
[02:59:58.880 --> 03:00:03.780]   I mean, if someone is going to lose all their memories, putting in a virus that's been genetically engineered,
[03:00:03.780 --> 03:00:09.200]   if that stops me from losing all my memories and being a burden on society and my wife, I'll do that in a heartbeat.
[03:00:09.200 --> 03:00:12.260]   So the toolbox we've created is just so rich.
[03:00:12.260 --> 03:00:14.600]   I mean, we've got these places like Janelia Farms.
[03:00:14.600 --> 03:00:15.580]   They're just making up new things.
[03:00:15.580 --> 03:00:20.360]   I mean, it's just such a Star Trek world where you can't wait a week.
[03:00:20.460 --> 03:00:21.920]   And someone had invented some new thing.
[03:00:21.920 --> 03:00:23.500]   But how do you use them all together?
[03:00:23.500 --> 03:00:24.480]   That's the problem.
[03:00:24.480 --> 03:00:25.820]   You go look at a mechanic's shop.
[03:00:25.820 --> 03:00:27.000]   They don't have five tools.
[03:00:27.000 --> 03:00:28.580]   They have 500 tools.
[03:00:28.580 --> 03:00:29.020]   I got a friend.
[03:00:29.020 --> 03:00:30.440]   I just, there's so many drawers.
[03:00:30.440 --> 03:00:33.120]   I can't even pull open all the drawers to look.
[03:00:33.120 --> 03:00:34.160]   He's just fixing one car.
[03:00:34.160 --> 03:00:36.200]   How do they have 500 tools?
[03:00:36.200 --> 03:00:39.040]   And we're thinking we're going to need one or two or three or four.
[03:00:39.040 --> 03:00:40.160]   So I think you're right.
[03:00:40.160 --> 03:00:48.160]   Putting the right combinations, having that reflection, having that societal support, knowing when am I going to go into this, helping people make those decisions.
[03:00:48.260 --> 03:00:49.560]   It's just, it's complicated and hard.
[03:00:49.560 --> 03:00:50.880]   We're getting better and better at it.
[03:00:50.880 --> 03:00:51.740]   I really think we are.
[03:00:51.740 --> 03:00:53.160]   Kids get a dog phobia.
[03:00:53.160 --> 03:00:54.980]   Someone says, here's what we should do.
[03:00:54.980 --> 03:00:56.140]   First, lock them away.
[03:00:56.140 --> 03:00:57.020]   Never show them a dog again.
[03:00:57.020 --> 03:00:57.660]   Okay.
[03:00:57.660 --> 03:00:58.420]   We tried that.
[03:00:58.420 --> 03:00:58.980]   Didn't work.
[03:00:58.980 --> 03:01:04.160]   And now your peer group is going to start telling you, if you hide from it, that's not the way to get better from it.
[03:01:04.600 --> 03:01:06.000]   Whether it's abstinence, right?
[03:01:06.000 --> 03:01:08.700]   We had this, people in a lot of pain.
[03:01:08.700 --> 03:01:10.160]   People didn't think that was a good idea.
[03:01:10.160 --> 03:01:13.460]   Doctors at UCSF and other places didn't think it was a good idea for people to be in pain, so they medicated them.
[03:01:13.460 --> 03:01:16.140]   No one knew there would be unintended consequences.
[03:01:16.140 --> 03:01:17.160]   Certainly some people did.
[03:01:17.160 --> 03:01:20.040]   And there's lawsuits and jail time and all the rest for a few people.
[03:01:20.040 --> 03:01:21.420]   But most people are just doing the right thing.
[03:01:21.420 --> 03:01:25.380]   In Catholic school, I also learned that road to hell is paved with good intentions.
[03:01:25.380 --> 03:01:26.700]   We have to own that.
[03:01:26.700 --> 03:01:27.180]   Right?
[03:01:27.420 --> 03:01:32.600]   Amazodamide was a drug we were going to prevent women from having, you know, nausea during first trimester.
[03:01:32.600 --> 03:01:34.260]   We didn't know it was going to cause birth defects.
[03:01:34.260 --> 03:01:36.100]   But we learned that lesson.
[03:01:36.100 --> 03:01:37.060]   We processed it.
[03:01:37.060 --> 03:01:38.620]   We took the humility from that.
[03:01:38.620 --> 03:01:40.420]   You can't just do the easy way out.
[03:01:40.420 --> 03:01:44.200]   The fact that it helps today doesn't mean you aren't going to later look back and regret it.
[03:01:44.200 --> 03:01:47.540]   And so we don't make change fast in our society.
[03:01:47.540 --> 03:01:49.020]   Democracies don't make change fast.
[03:01:49.020 --> 03:01:50.780]   They have all these built-in ways to change slow.
[03:01:50.780 --> 03:01:53.160]   So we've got time to make sure it works.
[03:01:53.160 --> 03:01:57.680]   And I think it's frustrating to a lot of people who say, my son went to war and needs a treatment.
[03:01:57.680 --> 03:01:59.000]   Give him what they need now.
[03:01:59.000 --> 03:02:01.280]   And there's all these people saying, hey, let's hold on.
[03:02:01.280 --> 03:02:02.020]   Let's wait and see.
[03:02:02.020 --> 03:02:03.500]   I'm comfortable with that.
[03:02:03.500 --> 03:02:05.320]   That we're waiting, taking our time.
[03:02:05.320 --> 03:02:06.320]   The process takes loads.
[03:02:06.320 --> 03:02:07.300]   It's frustrating to me.
[03:02:07.300 --> 03:02:09.580]   I'll be honest how slow it is to do clinical trials.
[03:02:09.580 --> 03:02:12.480]   We're running a lot of trials with a lot of people I know with a lot of serious injuries.
[03:02:12.480 --> 03:02:15.920]   And I can't move to the next thing because the work on this one is so slow.
[03:02:15.920 --> 03:02:21.760]   But better to be too slow than to take this lightly and think we're just going to do all these things, changing people's brains.
[03:02:21.760 --> 03:02:23.260]   I mean, this is literally who they are.
[03:02:23.260 --> 03:02:24.880]   This is where their personality resides.
[03:02:24.880 --> 03:02:26.440]   This is their experiences.
[03:02:26.440 --> 03:02:31.700]   So I've been very pleased that the federal government is doing a great job of just saying, let's try all the things.
[03:02:31.700 --> 03:02:33.240]   Like you said, they're not against gene therapy.
[03:02:33.240 --> 03:02:35.260]   They're not against big pharma.
[03:02:35.260 --> 03:02:36.580]   They're not in big pharma's pocket.
[03:02:36.580 --> 03:02:38.220]   They're just saying, look, what's going to work?
[03:02:38.220 --> 03:02:39.060]   We'll know when it works.
[03:02:39.060 --> 03:02:40.320]   We'll all know when it works.
[03:02:40.320 --> 03:02:46.960]   And for the things that has worked, phenoketionuria and cochlear implants, the government paid a ton of money on cochlear implants.
[03:02:46.960 --> 03:02:50.140]   You just do the next thing, next thing, next thing, next thing.
[03:02:50.140 --> 03:02:53.300]   And now there's multiple companies that sell those, and you can have that.
[03:02:53.300 --> 03:02:54.520]   They tried that for the retina.
[03:02:54.520 --> 03:02:57.360]   And so far, correct me if I'm wrong, they're still not an awesome.
[03:02:57.360 --> 03:03:01.380]   One of my first students is at Henry Ford working on the retinal prosthesis.
[03:03:01.380 --> 03:03:02.580]   It's still hard.
[03:03:02.580 --> 03:03:02.920]   Yeah.
[03:03:02.920 --> 03:03:03.700]   They'll get there.
[03:03:03.700 --> 03:03:04.300]   They'll get there.
[03:03:04.300 --> 03:03:18.060]   Don't give up because it's hard.
[03:03:18.060 --> 03:03:19.140]   Just because it's hard doesn't mean we give up.
[03:03:19.140 --> 03:03:19.720]   People are blind.
[03:03:19.820 --> 03:03:20.980]   You know what inputs you need.
[03:03:20.980 --> 03:03:22.560]   You know what's needed in the brain.
[03:03:22.560 --> 03:03:29.160]   I think also I'm encouraged by the fact that some of the smartest people in neuroscience and engineering are working on it.
[03:03:29.160 --> 03:03:29.220]   Yeah.
[03:03:29.220 --> 03:03:32.120]   Certainly at Neuralink, but also in academia.
[03:03:33.800 --> 03:03:36.040]   I mean, these are some of the best minds on the planet.
[03:03:36.040 --> 03:03:42.500]   These are really like the astronauts of science and in lots of fields, but certainly in visual restoration.
[03:03:42.500 --> 03:03:45.360]   The miniaturization, the wireless coding.
[03:03:45.360 --> 03:03:49.560]   I mean, all the problems that we had back in the day, they're sort of just evaporated.
[03:03:49.600 --> 03:03:50.660]   The chips get smaller and smaller.
[03:03:50.660 --> 03:03:51.900]   The power is better and better.
[03:03:51.900 --> 03:03:53.940]   So I, too, am optimistic.
[03:03:53.940 --> 03:03:57.180]   If you were blind today, you'd wish it was ready yesterday.
[03:03:57.180 --> 03:03:57.740]   Sure.
[03:03:57.740 --> 03:04:01.620]   But it's going to take investment and it's a hard problem.
[03:04:01.620 --> 03:04:04.840]   We don't know how long it's going to take, whether it's Alzheimer's or schizophrenia.
[03:04:04.840 --> 03:04:09.420]   We just keep investing and our country keeps giving it to the entire world for free.
[03:04:09.420 --> 03:04:10.500]   We sequenced the entire genome.
[03:04:10.500 --> 03:04:11.180]   We just gave it away.
[03:04:11.180 --> 03:04:12.680]   Who does that?
[03:04:12.680 --> 03:04:13.560]   That's just what we do.
[03:04:13.560 --> 03:04:16.940]   So I think that kind of thing, when I see something like that, we can monetize it.
[03:04:16.940 --> 03:04:17.700]   We can patent it.
[03:04:17.700 --> 03:04:18.900]   We can say you can't use that gene.
[03:04:18.900 --> 03:04:19.620]   You know, I invented that gene.
[03:04:19.620 --> 03:04:21.060]   I said, no, we're not going to do it that way.
[03:04:21.060 --> 03:04:25.640]   So I just think we've learned some good lessons about how to just innovate and share.
[03:04:25.640 --> 03:04:26.520]   Other countries are learning.
[03:04:26.520 --> 03:04:27.140]   Let's do it together.
[03:04:27.140 --> 03:04:29.040]   It's way better together than alone.
[03:04:29.040 --> 03:04:30.280]   So I'm optimistic.
[03:04:30.280 --> 03:04:31.560]   This brings us together.
[03:04:31.560 --> 03:04:31.940]   I'm optimistic.
[03:04:31.940 --> 03:04:33.200]   The problems are not unsolvable.
[03:04:33.200 --> 03:04:37.660]   And once we understand that they're synapses, right, they're just connections, and that those
[03:04:37.660 --> 03:04:38.800]   things evolve to change.
[03:04:38.800 --> 03:04:39.540]   We're not making them change.
[03:04:39.540 --> 03:04:41.060]   I'm not Frankensteining it.
[03:04:41.060 --> 03:04:41.920]   I'm not hacking it.
[03:04:41.920 --> 03:04:43.800]   That's how it was built to do.
[03:04:44.160 --> 03:04:50.820]   If we need gene therapy, drugs, devices, counseling, therapy, if we need five or ten things, that's
[03:04:50.820 --> 03:04:51.600]   how my normal life was.
[03:04:51.600 --> 03:04:54.120]   My childhood was a lot like a lot of factors.
[03:04:54.120 --> 03:04:57.420]   Diet, nutrition, exercise, all those things were shaping who I am.
[03:04:58.000 --> 03:04:59.240]   And we hoped it was simple.
[03:04:59.240 --> 03:05:00.240]   It wasn't simple.
[03:05:00.240 --> 03:05:01.020]   Would have been nice.
[03:05:01.020 --> 03:05:02.100]   And a few things were.
[03:05:02.100 --> 03:05:05.000]   But the vast majority now are complicated.
[03:05:05.000 --> 03:05:09.640]   And it seems like that humility and that working with patients and letting them understand what
[03:05:09.640 --> 03:05:11.860]   are they doing, no one's trying to control anyone's brain.
[03:05:11.860 --> 03:05:15.720]   No one is trying to put in chips and make you do things you don't want to do.
[03:05:15.720 --> 03:05:17.360]   That is not the future of this.
[03:05:17.360 --> 03:05:18.640]   This is not that scary thing.
[03:05:18.640 --> 03:05:20.940]   Find serious problems and see if we can help.
[03:05:21.560 --> 03:05:26.020]   Well, I love your optimism and I'm encouraged by what you've done already.
[03:05:26.020 --> 03:05:30.240]   And I should have known that if I sat down with the author of one of my favorite papers
[03:05:30.240 --> 03:05:35.560]   in science, one of my top ten, maybe even my top five, that it would be a discussion of
[03:05:35.560 --> 03:05:36.420]   the sort we just had.
[03:05:36.420 --> 03:05:37.940]   I learned a ton from you.
[03:05:37.940 --> 03:05:40.300]   I went into this knowing a thing or two about plasticity.
[03:05:40.300 --> 03:05:41.700]   I have some training there indeed.
[03:05:41.700 --> 03:05:43.620]   But I learned so much.
[03:05:43.620 --> 03:05:46.800]   And I'm thinking about it completely differently now, to be honest.
[03:05:47.740 --> 03:05:52.560]   This notion of needing focus and friction, the reflection piece that what mental rehearsal
[03:05:52.560 --> 03:05:58.520]   will and won't do, the value of a small device like this for patients that are struggling
[03:05:58.520 --> 03:06:04.800]   with any number of different conditions when paired with the appropriate training and rewiring
[03:06:04.800 --> 03:06:05.280]   stimuli.
[03:06:05.280 --> 03:06:13.320]   You've also reframed the way I think about drugs that can modify neuromodulators like nicotine.
[03:06:13.320 --> 03:06:16.300]   And of course, everyone should make a choice that's best for them.
[03:06:16.300 --> 03:06:18.200]   But I could go on and on.
[03:06:18.200 --> 03:06:23.920]   But I think it's evident to anyone that's listened to this conversation now that you're
[03:06:23.920 --> 03:06:28.480]   really out there to help us and to build things that are going to help humanity.
[03:06:28.480 --> 03:06:29.680]   And you're doing that.
[03:06:29.680 --> 03:06:35.540]   I'm very excited about the recent paper, getting paralyzed people to access more movement.
[03:06:35.540 --> 03:06:41.480]   Once again, I'll provide links to those and other resources in the show note captions.
[03:06:41.480 --> 03:06:43.660]   I know you have some open clinical trials as well.
[03:06:43.660 --> 03:06:48.080]   Maybe we can direct people to the possibility that they could be subjects if that's appropriate.
[03:06:48.080 --> 03:06:53.340]   I want to thank you for the work that you've done, that you're doing, and that you continue
[03:06:53.340 --> 03:06:57.500]   to do, and for coming here today and to contribute to public science education.
[03:06:57.500 --> 03:06:59.880]   It's been wonderful for me and I know for everyone listening.
[03:06:59.880 --> 03:07:01.300]   So thank you ever so much.
[03:07:01.760 --> 03:07:03.640]   Thanks for helping get this complicated information out to people.
[03:07:03.640 --> 03:07:04.420]   Really appreciate it.
[03:07:04.420 --> 03:07:08.100]   Thank you for joining me for today's discussion with Dr. Michael Kilgard.
[03:07:08.100 --> 03:07:11.620]   To learn more about his work, please see the links in the show note captions.
[03:07:12.260 --> 03:07:15.900]   If you're learning from and or enjoying this podcast, please subscribe to our YouTube channel.
[03:07:15.900 --> 03:07:18.320]   That's a terrific zero-cost way to support us.
[03:07:18.320 --> 03:07:23.380]   In addition, please follow the podcast by clicking the follow button on both Spotify and Apple.
[03:07:23.380 --> 03:07:26.700]   And on both Spotify and Apple, you can leave us up to a five-star review.
[03:07:26.700 --> 03:07:30.240]   And you can now leave us comments at both Spotify and Apple.
[03:07:30.480 --> 03:07:34.020]   Please also check out the sponsors mentioned at the beginning and throughout today's episode.
[03:07:34.020 --> 03:07:36.240]   That's the best way to support this podcast.
[03:07:36.240 --> 03:07:40.980]   If you have questions for me or comments about the podcast or guests or topics that you'd like
[03:07:40.980 --> 03:07:45.160]   me to consider for the Huberman Lab podcast, please put those in the comments section on YouTube.
[03:07:45.160 --> 03:07:46.920]   I do read all the comments.
[03:07:46.920 --> 03:07:49.500]   For those of you that haven't heard, I have a new book coming out.
[03:07:49.500 --> 03:07:50.680]   It's my very first book.
[03:07:50.680 --> 03:07:54.600]   It's entitled Protocols, an Operating Manual for the Human Body.
[03:07:54.600 --> 03:07:57.940]   This is a book that I've been working on for more than five years, and that's based on more
[03:07:57.940 --> 03:08:00.780]   than 30 years of research and experience.
[03:08:00.780 --> 03:08:07.000]   And it covers protocols for everything from sleep to exercise to stress control, protocols
[03:08:07.000 --> 03:08:08.600]   related to focus and motivation.
[03:08:08.600 --> 03:08:14.160]   And of course, I provide the scientific substantiation for the protocols that are included.
[03:08:14.160 --> 03:08:17.880]   The book is now available by presale at protocolsbook.com.
[03:08:17.880 --> 03:08:20.380]   There you can find links to various vendors.
[03:08:20.380 --> 03:08:22.240]   You can pick the one that you like best.
[03:08:22.240 --> 03:08:26.400]   Again, the book is called Protocols, an Operating Manual for the Human Body.
[03:08:26.840 --> 03:08:30.900]   And if you're not already following me on social media, I am Huberman Lab on all social
[03:08:30.900 --> 03:08:31.680]   media platforms.
[03:08:31.680 --> 03:08:35.200]   So that's Instagram, X, Threads, Facebook, and LinkedIn.
[03:08:35.200 --> 03:08:40.180]   And on all those platforms, I discuss science and science-related tools, some of which overlaps
[03:08:40.180 --> 03:08:44.140]   with the content of the Huberman Lab podcast, but much of which is distinct from the information
[03:08:44.140 --> 03:08:45.420]   on the Huberman Lab podcast.
[03:08:45.420 --> 03:08:48.680]   Again, it's Huberman Lab on all social media platforms.
[03:08:49.080 --> 03:08:52.740]   And if you haven't already subscribed to our Neural Network newsletter, the Neural Network
[03:08:52.740 --> 03:08:57.100]   newsletter is a zero-cost monthly newsletter that includes podcast summaries, as well as
[03:08:57.100 --> 03:09:01.840]   what we call protocols in the form of one to three-page PDFs that cover everything from
[03:09:01.840 --> 03:09:05.340]   how to optimize your sleep, how to optimize dopamine, deliberate cold exposure.
[03:09:05.340 --> 03:09:09.720]   We have a foundational fitness protocol that covers cardiovascular training and resistance
[03:09:09.720 --> 03:09:10.160]   training.
[03:09:10.420 --> 03:09:12.840]   All of that is available completely zero cost.
[03:09:12.840 --> 03:09:17.200]   You simply go to HubermanLab.com, go to the menu tab in the top right corner, scroll down
[03:09:17.200 --> 03:09:19.140]   to newsletter, and enter your email.
[03:09:19.140 --> 03:09:22.360]   And I should emphasize that we do not share your email with anybody.
[03:09:22.360 --> 03:09:26.280]   Thank you once again for joining me for today's discussion with Dr. Michael Kilgard.
[03:09:26.280 --> 03:09:30.280]   And last, but certainly not least, thank you for your interest in science.
[03:09:30.280 --> 03:09:32.340]   you
[03:09:32.340 --> 03:09:32.840]   you
[03:09:32.840 --> 03:09:33.340]   you
[03:09:33.340 --> 03:09:33.840]   you
[03:09:33.840 --> 03:09:34.340]   you

