
[00:00:00.000 --> 00:00:05.800]   I work on the robotics team at OpenAI, where we try to build learning-based robots that
[00:00:05.800 --> 00:00:09.200]   can eventually do anything that a human should be able to do.
[00:00:09.200 --> 00:00:14.040]   I work on everything from figuring out the right algorithms to power these robots to
[00:00:14.040 --> 00:00:18.240]   building the equivalent of the sensory systems for these robots.
[00:00:18.240 --> 00:00:23.000]   One of the things we've been working on in the project is to get a robotic hand to manipulate
[00:00:23.000 --> 00:00:24.000]   real objects.
[00:00:24.000 --> 00:00:28.440]   So you can put a block in the hand and it can orient it to any orientation.
[00:00:28.440 --> 00:00:33.040]   And this is kind of a problem that had eluded the robotics community for decades.
[00:00:33.040 --> 00:00:38.640]   What that involves is programming computers such that they learn from the real world,
[00:00:38.640 --> 00:00:44.440]   or say in our case a lot in simulated worlds, just as humans do, you know, as children and
[00:00:44.440 --> 00:00:46.520]   adults do when we want to do new tasks.
[00:00:46.520 --> 00:00:47.520]   There's a learning process.
[00:00:47.520 --> 00:00:49.400]   You won't get everything right on the first try.
[00:00:49.400 --> 00:00:54.920]   Kind of programming robots to have this more human-like learning-based behavior.
[00:00:54.920 --> 00:00:57.840]   Before we started using weights and biases, everybody had kind of their own little setup
[00:00:57.840 --> 00:01:00.240]   of how they would get their results and so on.
[00:01:00.240 --> 00:01:02.120]   Some people would be using TensorFlow.
[00:01:02.120 --> 00:01:06.400]   With TensorBoard, some people would be using their own kind of homebrew version of some
[00:01:06.400 --> 00:01:07.800]   visualization tool and so on.
[00:01:07.800 --> 00:01:10.120]   So everything was very fragile.
[00:01:10.120 --> 00:01:14.400]   Like if I wanted to share a piece of results with somebody else, the best I could usually
[00:01:14.400 --> 00:01:19.400]   hope for was a screenshot of my graph and then paste it and send it to them in some
[00:01:19.400 --> 00:01:20.920]   way over Slack or over email.
[00:01:20.920 --> 00:01:25.400]   What has changed now is that since we have a common place where all our results are,
[00:01:25.400 --> 00:01:29.480]   I can take the results of my colleague Lillian, for example, and I can take whatever she has
[00:01:29.480 --> 00:01:32.240]   trained and I can compare that with what I trained.
[00:01:32.240 --> 00:01:34.000]   We can create a quick report with that.
[00:01:34.000 --> 00:01:36.640]   I can download the model that she had trained.
[00:01:36.640 --> 00:01:40.320]   I can go in and look at other metrics very easily since I have all the raw data.
[00:01:40.320 --> 00:01:43.760]   It's not like I have to ask her to make me a new screenshot.
[00:01:43.760 --> 00:01:49.080]   It's reduced a lot of the overhead in communication to make us really focus on the communication
[00:01:49.080 --> 00:01:53.360]   that really matters about like what should we work on and what are the most important
[00:01:53.360 --> 00:01:56.520]   things now rather than like what did your results look like two weeks ago?
[00:01:56.520 --> 00:01:57.760]   That's a waste of time.
[00:01:57.760 --> 00:02:01.160]   We use Weights and Biases with continuous integration a lot.
[00:02:01.160 --> 00:02:04.080]   It's extremely important to see that your model don't regress.
[00:02:04.080 --> 00:02:08.680]   You know, it gives you a kind of sense of the pulse of the team, of how quickly you're
[00:02:08.680 --> 00:02:10.760]   moving and so on.
[00:02:10.760 --> 00:02:14.640]   But it's also an extremely good way of just having full transparency in the work that
[00:02:14.640 --> 00:02:16.200]   you're doing with other people.
[00:02:16.200 --> 00:02:18.960]   We have like 10 to 20 people working with our code base.
[00:02:18.960 --> 00:02:21.960]   So at any point in time, somebody could commit a change that breaks something.
[00:02:21.960 --> 00:02:25.080]   The worst thing that can happen is that you find out after a few weeks that you have a
[00:02:25.080 --> 00:02:30.120]   regression and then you have like two weeks of commits to go through and figure out what
[00:02:30.120 --> 00:02:31.120]   went wrong.
[00:02:31.120 --> 00:02:33.520]   Then you lose easily a week or two of work.
[00:02:33.520 --> 00:02:36.760]   Thanks to Weights and Biases, I've just saved lots and lots of money.
[00:02:36.760 --> 00:02:41.240]   Just comparing results in general is much faster when I have all the data in one place.
[00:02:41.240 --> 00:02:45.920]   In some ways, it's kind of like a shared logbook for the team of our progress.
[00:02:45.920 --> 00:02:49.920]   We do this a lot in our workflows, comparing against old baselines and so on.
[00:02:49.920 --> 00:02:55.320]   So we can keep on having old runs available and compare against those over and over and
[00:02:55.320 --> 00:02:56.520]   over again.
[00:02:56.520 --> 00:03:02.600]   It's a very transparent way of seeing how much your utilization is of your resources.
[00:03:02.600 --> 00:03:08.480]   Like do you use 10% or 90% of your CPU or GPU?
[00:03:08.480 --> 00:03:12.280]   We want to be at as close to 100% as possible.
[00:03:12.280 --> 00:03:16.680]   So it's been a very, very useful tool for us for just saving money.
[00:03:16.680 --> 00:03:21.360]   You can call out to your friend, like, "Why are you only using 10% of the GPU?
[00:03:21.360 --> 00:03:24.600]   You can be running 10 times as many experiments."
[00:03:24.600 --> 00:03:28.880]   We're trying to build a robot brain, a brain that could work with any robotic incarnation.
[00:03:28.880 --> 00:03:33.280]   So I think it can have an enormous positive impact on the world to build general purpose
[00:03:33.280 --> 00:03:34.280]   robots.
[00:03:34.280 --> 00:03:35.880]   I want to be part of figuring out how to do that.
[00:03:35.880 --> 00:03:49.480]   [MUSIC PLAYING]

