
[00:00:00.000 --> 00:00:04.640]   there is absolutely no doubt in my mind that excess capital
[00:00:04.640 --> 00:00:08.180]   distorts company behavior, okay?
[00:00:08.180 --> 00:00:11.140]   And in particularly these early phases,
[00:00:11.140 --> 00:00:13.560]   it's very difficult, it's not impossible,
[00:00:13.560 --> 00:00:17.480]   but it's very difficult to stay fit and efficient
[00:00:17.480 --> 00:00:20.740]   when you have a buffet of all options
[00:00:20.740 --> 00:00:23.240]   sitting in front of you and you can fund all of them.
[00:00:23.240 --> 00:00:27.740]   Scarcity breeds necessity, scarcity breeds innovation.
[00:00:27.740 --> 00:00:29.400]   So I think if you're on the board of a company
[00:00:29.400 --> 00:00:31.620]   or a founder of a company or CEO of a company,
[00:00:31.620 --> 00:00:35.420]   you have to think long and hard about the negative cultural
[00:00:35.420 --> 00:00:38.540]   and negative fundamental effects to your business
[00:00:38.540 --> 00:00:39.920]   of taking too much capital.
[00:00:39.920 --> 00:00:42.500]   (upbeat music)
[00:00:42.500 --> 00:00:55.060]   - Hey man, good to see you, happy Saturday pod.
[00:00:55.060 --> 00:00:56.440]   - Good to see you, sir.
[00:00:56.440 --> 00:00:57.440]   - What's been on your mind?
[00:00:57.440 --> 00:00:59.400]   - Well, look, I mean, so much has happened
[00:00:59.400 --> 00:01:01.160]   and I think we took a few weeks off.
[00:01:01.160 --> 00:01:05.280]   So like, it almost feels like the world
[00:01:05.280 --> 00:01:08.580]   has changed dramatically from when we last talked.
[00:01:08.580 --> 00:01:10.400]   So there's a bunch of different things on my mind.
[00:01:10.400 --> 00:01:12.560]   I've been thinking a lot about the,
[00:01:12.560 --> 00:01:15.280]   I'll call it the pre-IPO market.
[00:01:15.280 --> 00:01:18.440]   I don't know why I don't wanna call it late stage
[00:01:18.440 --> 00:01:20.040]   'cause I think some of the money has moved down
[00:01:20.040 --> 00:01:21.840]   to companies that are even pre-revenue,
[00:01:21.840 --> 00:01:26.840]   but the pre-IPO market I think is changing dramatically.
[00:01:26.840 --> 00:01:29.320]   I think there's always this interesting question
[00:01:29.320 --> 00:01:34.320]   of where are we in terms of reality and perception
[00:01:34.320 --> 00:01:40.000]   on whatever the newest trend is.
[00:01:40.000 --> 00:01:41.760]   And we've seen that with other things
[00:01:41.760 --> 00:01:42.960]   like crypto and whatnot.
[00:01:42.960 --> 00:01:45.280]   And I think it's interesting to think about that
[00:01:45.280 --> 00:01:46.360]   relative to AI.
[00:01:46.360 --> 00:01:49.080]   And then lastly, one topic I really wanna get
[00:01:49.080 --> 00:01:54.040]   your opinion on, after some of the earnings releases
[00:01:54.040 --> 00:01:56.400]   since we last talked in the software category
[00:01:56.400 --> 00:02:00.560]   particularly, people have thrown out this question,
[00:02:00.560 --> 00:02:03.400]   like is software as we know it dead,
[00:02:03.400 --> 00:02:06.760]   which is obviously overly provocative.
[00:02:06.760 --> 00:02:09.520]   But there are a lot of questions around that
[00:02:09.520 --> 00:02:11.840]   and a few people weighed in and I'd love,
[00:02:11.840 --> 00:02:13.440]   so anyway, I'd love to talk about all three
[00:02:13.440 --> 00:02:15.480]   of those things if you're up for it.
[00:02:15.480 --> 00:02:16.520]   Well, no doubt about it.
[00:02:16.520 --> 00:02:18.400]   And it sounds like we have our agenda,
[00:02:18.400 --> 00:02:21.200]   but before we jump in, I have to say,
[00:02:21.200 --> 00:02:24.800]   I was driving in this morning and I don't know,
[00:02:24.800 --> 00:02:27.000]   I'm just reflected in a reflective place.
[00:02:27.000 --> 00:02:30.600]   I mean, my oldest son, Lincoln turned 16 this week
[00:02:30.600 --> 00:02:33.400]   and my mother turned 88 and it's just a moment,
[00:02:33.400 --> 00:02:34.240]   just a moment.
[00:02:34.240 --> 00:02:36.100]   My mom sent me this note.
[00:02:36.100 --> 00:02:38.800]   Well, she actually sent it to all the kids
[00:02:38.800 --> 00:02:41.520]   and I just, I have to read a bit of it
[00:02:41.520 --> 00:02:44.000]   because it goes to how I'm thinking about things
[00:02:44.000 --> 00:02:45.520]   and she's 88, right?
[00:02:45.520 --> 00:02:50.080]   So she starts by saying, I was born on this day in 1936,
[00:02:50.080 --> 00:02:52.680]   right between the Great Depression and World War II.
[00:02:53.760 --> 00:02:55.800]   Times were tough, we didn't have much,
[00:02:55.800 --> 00:02:58.120]   but we shared what little we had.
[00:02:58.120 --> 00:02:59.060]   Does that sound bad?
[00:02:59.060 --> 00:03:02.360]   Nope, these have been the best 88 years possible
[00:03:02.360 --> 00:03:03.720]   to be alive.
[00:03:03.720 --> 00:03:07.440]   Sure, I've seen lots of bad stuff, assassinations,
[00:03:07.440 --> 00:03:11.040]   bad politicians and wars, lots of wars,
[00:03:11.040 --> 00:03:13.840]   but the good outweighs the bad by a long shot.
[00:03:13.840 --> 00:03:16.000]   Just think about what I've seen.
[00:03:16.000 --> 00:03:19.060]   The first TVs, the first commercial flights,
[00:03:19.060 --> 00:03:23.320]   the first computers, the first mobile phones and Google
[00:03:23.320 --> 00:03:25.260]   and now even chat GPT.
[00:03:25.260 --> 00:03:28.320]   The world's gotten better in almost every way.
[00:03:28.320 --> 00:03:30.460]   We live longer and healthier.
[00:03:30.460 --> 00:03:33.340]   We solve problems we could never have dreamed of
[00:03:33.340 --> 00:03:35.040]   and we're all more connected.
[00:03:35.040 --> 00:03:37.620]   I wish people weren't so negative.
[00:03:37.620 --> 00:03:40.480]   Let me tell you the struggles of no food or housing
[00:03:40.480 --> 00:03:44.400]   in the Great Depression or being shipped off to war at 18,
[00:03:44.400 --> 00:03:47.680]   knowing you wouldn't come home, that is hardship.
[00:03:47.680 --> 00:03:51.640]   But the truth is I understand people feeling overwhelmed
[00:03:51.640 --> 00:03:54.000]   by all the hustle and bustle today.
[00:03:54.000 --> 00:03:58.480]   I too have a love-hate relationship with technology myself.
[00:03:58.480 --> 00:03:59.960]   While I know it's made the world better,
[00:03:59.960 --> 00:04:02.200]   I didn't realize how lucky I was to grow up
[00:04:02.200 --> 00:04:05.280]   in small town America at a quieter time.
[00:04:05.280 --> 00:04:09.400]   It was a simple life, long walks and card games,
[00:04:09.400 --> 00:04:12.460]   fewer friends, but you shared everything.
[00:04:12.460 --> 00:04:13.960]   So enjoy your technology,
[00:04:13.960 --> 00:04:16.360]   but never let it rob you of the personal touch.
[00:04:16.360 --> 00:04:18.280]   It's a tool to use.
[00:04:18.280 --> 00:04:21.480]   You should run it, don't let it run you.
[00:04:21.480 --> 00:04:23.240]   But never turn against progress
[00:04:23.240 --> 00:04:25.080]   because without it, we go backwards.
[00:04:25.080 --> 00:04:27.880]   And personally, I can't wait to see what comes next.
[00:04:27.880 --> 00:04:30.200]   That from like an 88-year-old woman.
[00:04:30.200 --> 00:04:36.240]   I mean, I was so blown away by just that perspective,
[00:04:36.240 --> 00:04:41.400]   her optimism and just like the framing of her life.
[00:04:41.400 --> 00:04:45.480]   It really was like all the innovation we've seen,
[00:04:45.480 --> 00:04:49.040]   like it compressed into such a short period of time.
[00:04:49.040 --> 00:04:52.280]   And so I know today we're gonna talk a bunch
[00:04:52.280 --> 00:04:54.600]   about where markets are going and is software dead
[00:04:54.600 --> 00:04:56.520]   and where are we in the age of AI?
[00:04:56.520 --> 00:04:58.680]   But it just caused me to think we live
[00:04:58.680 --> 00:05:01.960]   at such a unique moment in human history.
[00:05:01.960 --> 00:05:04.160]   I mean, I think you would agree,
[00:05:04.160 --> 00:05:06.960]   just innovation of all sorts,
[00:05:06.960 --> 00:05:11.800]   it's raging at a pace that you and I have never seen.
[00:05:11.800 --> 00:05:13.680]   And it's not an accident.
[00:05:13.680 --> 00:05:16.240]   Like there's been all this attack on capitalism
[00:05:16.240 --> 00:05:19.560]   and free enterprise over the last few years,
[00:05:19.560 --> 00:05:23.120]   but it is in fact that system,
[00:05:23.120 --> 00:05:25.840]   that and a direct result of that system
[00:05:25.840 --> 00:05:29.560]   that inspires and incentivizes people to dream
[00:05:29.560 --> 00:05:30.560]   and to build this stuff.
[00:05:30.560 --> 00:05:34.480]   And I was looking at the Starship launch this week,
[00:05:34.480 --> 00:05:37.320]   which is just this insane feat of human engineering.
[00:05:37.320 --> 00:05:40.000]   I mean, in four launches, right?
[00:05:40.000 --> 00:05:42.720]   We now had a soft landing in the ocean.
[00:05:42.720 --> 00:05:46.480]   This is a ship that nobody thought was ever achievable.
[00:05:46.480 --> 00:05:49.440]   It's gonna make us a multi-planetary species.
[00:05:49.440 --> 00:05:52.480]   And I saw the looks of exhilaration
[00:05:52.480 --> 00:05:57.080]   on the faces of those young people in the control center.
[00:05:57.080 --> 00:05:59.400]   And I just told my kids when we were watching that,
[00:05:59.400 --> 00:06:01.640]   I just said, find something in life
[00:06:01.640 --> 00:06:04.200]   that makes you feel that way, right?
[00:06:04.200 --> 00:06:07.120]   And I think that may be Elon's, frankly,
[00:06:07.120 --> 00:06:12.120]   greatest legacy is just the motivation,
[00:06:12.360 --> 00:06:15.520]   the inspiration he's giving to all the generations
[00:06:15.520 --> 00:06:17.280]   that are coming up, right?
[00:06:17.280 --> 00:06:21.360]   To dream big, to think big, to build stuff that matters.
[00:06:21.360 --> 00:06:23.680]   I think that was only half of your mother's message,
[00:06:23.680 --> 00:06:24.520]   by the way.
[00:06:24.520 --> 00:06:27.480]   Yeah, I mean, like, you know,
[00:06:27.480 --> 00:06:32.280]   I think it was the part to me that really inspires me
[00:06:32.280 --> 00:06:33.560]   and motivates me.
[00:06:33.560 --> 00:06:37.080]   And, you know, I'll get off the soapbox,
[00:06:37.080 --> 00:06:39.960]   but, you know, as we start diving in here,
[00:06:39.960 --> 00:06:42.160]   the one thing I'm just thinking a lot about
[00:06:42.160 --> 00:06:45.760]   is we as a country need to make sure we don't screw this up.
[00:06:45.760 --> 00:06:48.920]   It's the system that's creating all that prosperity.
[00:06:48.920 --> 00:06:52.480]   It's the system that's creating, you know,
[00:06:52.480 --> 00:06:55.240]   the advances in biology, the advances in space,
[00:06:55.240 --> 00:06:57.080]   the advances in AI.
[00:06:57.080 --> 00:06:58.920]   And certainly they'll have challenges,
[00:06:58.920 --> 00:07:01.920]   but it's an extraordinary time to be out here
[00:07:01.920 --> 00:07:03.960]   in Silicon Valley doing what we do, so.
[00:07:03.960 --> 00:07:06.880]   Well, and I, you know, adding on top of that,
[00:07:06.880 --> 00:07:09.320]   something we talked about in one of our first episodes
[00:07:09.320 --> 00:07:11.280]   was that Reagan speech that he gave.
[00:07:11.280 --> 00:07:15.960]   And one of the reasons why the U.S. has been so successful
[00:07:15.960 --> 00:07:18.840]   is open skilled immigration
[00:07:18.840 --> 00:07:21.120]   and getting the best people in the world
[00:07:21.120 --> 00:07:23.960]   to come practice their craft here.
[00:07:23.960 --> 00:07:28.480]   And why we have limited that and not advanced it
[00:07:28.480 --> 00:07:30.760]   is shocking to me.
[00:07:30.760 --> 00:07:32.600]   And there will be ramifications
[00:07:32.600 --> 00:07:35.600]   'cause the technology allows those people
[00:07:35.600 --> 00:07:38.160]   to stay in other places if they so choose.
[00:07:38.160 --> 00:07:40.360]   So you gotta make it easy for 'em.
[00:07:40.360 --> 00:07:42.000]   Yeah, no doubt about it here, here.
[00:07:42.000 --> 00:07:44.640]   Why don't we jump into, I guess, the first topic,
[00:07:44.640 --> 00:07:47.480]   you know, about this new reality in the late stage market.
[00:07:47.480 --> 00:07:49.320]   Why don't you take us through
[00:07:49.320 --> 00:07:51.080]   what's piqued your interest there?
[00:07:51.080 --> 00:07:52.600]   So let me walk you through this.
[00:07:52.600 --> 00:07:54.280]   And you and I have talked about it in the past,
[00:07:54.280 --> 00:07:58.560]   but I think I've come around to a new perspective.
[00:07:58.560 --> 00:08:02.720]   So I've lived through two different major cycles,
[00:08:02.720 --> 00:08:05.760]   venture cycles, and, you know,
[00:08:05.760 --> 00:08:08.680]   I've watched there be high periods of liquidity
[00:08:08.680 --> 00:08:11.960]   where a ton of returns are made in '99,
[00:08:11.960 --> 00:08:16.280]   kind of 2021, even kind of '07, '08.
[00:08:16.280 --> 00:08:19.320]   And then frequently on the downside, like '01,
[00:08:19.320 --> 00:08:21.200]   you just see a washout, right?
[00:08:21.200 --> 00:08:24.280]   And I've seen people completely cleared out.
[00:08:24.280 --> 00:08:28.560]   And I've often thought about there are changes
[00:08:28.560 --> 00:08:30.600]   to the venture industry that are systematic,
[00:08:30.600 --> 00:08:33.720]   like increasing competition has been completely linear
[00:08:33.720 --> 00:08:35.960]   and systematic since I joined,
[00:08:35.960 --> 00:08:38.840]   but other things are cyclical and they come and go.
[00:08:38.840 --> 00:08:41.320]   And I think I had always thought
[00:08:41.320 --> 00:08:44.240]   that the presence of large amounts of money,
[00:08:44.240 --> 00:08:47.680]   presumably easy to get in the private,
[00:08:47.680 --> 00:08:49.480]   in the late, well, we say late stage,
[00:08:49.480 --> 00:08:50.440]   but it's come so early,
[00:08:50.440 --> 00:08:51.800]   I don't think that's the right word,
[00:08:51.800 --> 00:08:56.800]   but the large, let's just say large round private market.
[00:08:56.800 --> 00:09:04.040]   I've come to believe that it may be a systematic trend
[00:09:04.040 --> 00:09:05.680]   and not a cyclical one.
[00:09:05.680 --> 00:09:08.560]   And there was a mini correction.
[00:09:08.560 --> 00:09:10.560]   I think you have to call it a mini correction
[00:09:10.560 --> 00:09:14.760]   in venture in 2022, 2023.
[00:09:14.760 --> 00:09:16.280]   A lot of companies did layoffs.
[00:09:16.280 --> 00:09:17.320]   You had right sizing.
[00:09:17.320 --> 00:09:20.880]   You had a lot of talk about free cash flow and profitability,
[00:09:20.880 --> 00:09:23.120]   but then the AI wave came
[00:09:23.120 --> 00:09:27.200]   and then the AI wave got so big, right?
[00:09:27.200 --> 00:09:30.520]   What's AI as a percentage of venture capital right now?
[00:09:30.520 --> 00:09:32.440]   50% at least.
[00:09:32.440 --> 00:09:33.280]   Yes.
[00:09:33.280 --> 00:09:37.560]   And so, and that market is behaving almost like it was
[00:09:37.560 --> 00:09:40.000]   prior to this mini correction.
[00:09:40.000 --> 00:09:45.000]   And so I look around and at some of these data points.
[00:09:45.000 --> 00:09:49.880]   So there was an FT article since you and I talked last
[00:09:49.880 --> 00:09:53.480]   that someone aggregated the cumulative losses
[00:09:53.480 --> 00:09:56.920]   in the food delivery business at $20 billion.
[00:09:56.920 --> 00:10:00.760]   And that's just not your grandfather's
[00:10:00.760 --> 00:10:02.440]   venture capital industry.
[00:10:02.440 --> 00:10:04.840]   That's something new.
[00:10:04.840 --> 00:10:09.840]   There are four companies in the coding co-pilot space
[00:10:09.840 --> 00:10:12.240]   that are not named Microsoft
[00:10:12.240 --> 00:10:15.200]   that have raised over $200 million each.
[00:10:15.200 --> 00:10:18.080]   And we're just, these companies are all of a year
[00:10:18.080 --> 00:10:19.720]   and a half old, right?
[00:10:19.720 --> 00:10:20.560]   Right.
[00:10:20.560 --> 00:10:22.720]   And so it's just a different world.
[00:10:22.720 --> 00:10:27.160]   I look at someone posted just the investments Sequoia
[00:10:27.160 --> 00:10:29.720]   has made in Elon's companies.
[00:10:29.720 --> 00:10:32.640]   And they were rounds that were in the, you know,
[00:10:32.640 --> 00:10:35.680]   500, $600 million range.
[00:10:35.680 --> 00:10:37.400]   And there were three or four of them.
[00:10:37.400 --> 00:10:42.400]   And once again, just not the historic venture capital model.
[00:10:42.400 --> 00:10:47.640]   Lots of money, lots of, you know, you're in this world.
[00:10:47.640 --> 00:10:50.440]   So don't take this the wrong way,
[00:10:50.440 --> 00:10:53.920]   but like these people are getting two and 20
[00:10:53.920 --> 00:10:56.680]   to write a check for three or $400 million
[00:10:56.680 --> 00:10:58.280]   and not take a board seat.
[00:10:58.280 --> 00:11:01.480]   And for the listeners that may not know
[00:11:01.480 --> 00:11:04.840]   that two represents an annual management fee,
[00:11:04.840 --> 00:11:07.440]   not a one-time management fee.
[00:11:07.440 --> 00:11:10.600]   And it's taken generally over seven, you know,
[00:11:10.600 --> 00:11:11.480]   seven to eight years.
[00:11:11.480 --> 00:11:14.320]   So that could be 10% of that money.
[00:11:14.320 --> 00:11:15.160]   So they're getting-
[00:11:15.160 --> 00:11:16.320]   Although I would point out, Bill,
[00:11:16.320 --> 00:11:18.920]   I think on some of those very large
[00:11:18.920 --> 00:11:20.360]   multi-billion dollar rounds
[00:11:20.360 --> 00:11:22.560]   where the investment size is multi-billions,
[00:11:22.560 --> 00:11:24.800]   I think there are creative fee structures.
[00:11:24.800 --> 00:11:28.080]   I think what's more standard is like
[00:11:28.080 --> 00:11:29.920]   zero and 10 or one and 10.
[00:11:29.920 --> 00:11:33.120]   I've heard those things are changing.
[00:11:33.120 --> 00:11:33.960]   Yeah, yeah, fair enough.
[00:11:33.960 --> 00:11:35.880]   I think that's a fair point.
[00:11:35.880 --> 00:11:38.800]   But I guess my point is,
[00:11:38.800 --> 00:11:40.640]   I think this is more permanent.
[00:11:40.640 --> 00:11:44.760]   I think it would take a massive shake out,
[00:11:44.760 --> 00:11:47.880]   like a gargantuan '01 style
[00:11:47.880 --> 00:11:50.880]   or more to change this at this point.
[00:11:50.880 --> 00:11:53.200]   Well, I mean, listen, I totally agree with you.
[00:11:53.200 --> 00:11:55.440]   In fact, you know, you and I have talked about this
[00:11:55.440 --> 00:11:57.280]   for well over a decade.
[00:11:57.280 --> 00:11:59.840]   You know, in fact, part of the reason I started Altimeter
[00:11:59.840 --> 00:12:01.680]   and part of our thesis in 2005
[00:12:01.680 --> 00:12:03.840]   is we thought companies would stay private longer,
[00:12:03.840 --> 00:12:07.160]   more of the value capture would occur in the private markets
[00:12:07.160 --> 00:12:09.200]   because they would scale faster.
[00:12:09.200 --> 00:12:10.680]   Now, at the time, we thought it was because
[00:12:10.680 --> 00:12:13.360]   they would also be more capital efficient, right?
[00:12:13.360 --> 00:12:16.960]   Think Google raising less than $40 million pre-IPO.
[00:12:16.960 --> 00:12:20.360]   But, you know, I think a lot of this has to do
[00:12:20.360 --> 00:12:22.840]   with the function of changing market structure,
[00:12:22.840 --> 00:12:24.960]   both technology, the way it scales,
[00:12:24.960 --> 00:12:28.200]   regulation, making it less desirable to go public,
[00:12:28.200 --> 00:12:30.480]   and frankly, the development, right?
[00:12:30.480 --> 00:12:32.560]   The market development and responding to that
[00:12:32.560 --> 00:12:36.000]   is just a much deeper and much more liquid pool of capital
[00:12:36.000 --> 00:12:38.080]   for companies that choose to stay private.
[00:12:38.080 --> 00:12:41.960]   So, you know, I pull up a couple of charts here,
[00:12:41.960 --> 00:12:44.160]   but let's ground it in some facts.
[00:12:44.160 --> 00:12:46.360]   Over the last 10 years, there's no doubt
[00:12:46.360 --> 00:12:48.560]   there's been more multistage funds,
[00:12:48.560 --> 00:12:50.880]   larger fund sizes, right?
[00:12:50.880 --> 00:12:52.320]   And this accelerates the trend
[00:12:52.320 --> 00:12:55.320]   because you no longer have to tap the public markets.
[00:12:55.320 --> 00:12:57.320]   So if you look at this chart,
[00:12:57.320 --> 00:12:59.520]   it just shows you the share of private capital
[00:12:59.520 --> 00:13:01.880]   that was raised by the large funds,
[00:13:01.880 --> 00:13:04.760]   and that's just becoming a much, much bigger part
[00:13:04.760 --> 00:13:06.960]   of the total market.
[00:13:06.960 --> 00:13:10.600]   And what I think is particularly interesting about that,
[00:13:10.600 --> 00:13:13.760]   it said through Q2, 2024,
[00:13:13.760 --> 00:13:18.680]   521 private market funds have raised a total of 295 billion
[00:13:18.680 --> 00:13:20.600]   across these asset classes,
[00:13:20.600 --> 00:13:23.800]   but fund counts fell by 45%
[00:13:23.800 --> 00:13:26.280]   during that same period of time, right?
[00:13:26.280 --> 00:13:29.640]   So yes, this is the case that there is a structural
[00:13:29.640 --> 00:13:32.360]   and dynamic change in these markets.
[00:13:32.360 --> 00:13:34.120]   You've got these multistage funds.
[00:13:34.120 --> 00:13:36.000]   You've got funds like Altimeter
[00:13:36.000 --> 00:13:37.680]   that's been doing this for a long time,
[00:13:37.680 --> 00:13:41.880]   where we do early all the way through public markets.
[00:13:41.880 --> 00:13:44.280]   And that's the amount of capital that's been raised.
[00:13:44.280 --> 00:13:46.600]   And then, Bill, if you look at the amount of capital
[00:13:46.600 --> 00:13:50.240]   that's been deployed and where that's coming from,
[00:13:50.240 --> 00:13:52.040]   you can pull up this chart from Crunchbase,
[00:13:52.040 --> 00:13:54.040]   and it also shows you, right,
[00:13:54.040 --> 00:13:56.680]   that you just have a lot of these late-stage dollars.
[00:13:56.680 --> 00:13:58.480]   Now, what this chart doesn't show you
[00:13:58.480 --> 00:14:02.640]   is the valuation of the rounds when they were getting done.
[00:14:02.640 --> 00:14:04.720]   So I think you're exactly right there.
[00:14:04.720 --> 00:14:05.680]   And then, of course,
[00:14:05.680 --> 00:14:08.680]   this isn't just VC and growth funds anymore.
[00:14:08.680 --> 00:14:10.840]   We have world-class sovereigns
[00:14:10.840 --> 00:14:13.080]   that have moved into this domain.
[00:14:13.080 --> 00:14:17.520]   You can see here this new fund out of Abu Dhabi, MGX,
[00:14:17.520 --> 00:14:21.160]   which is run by, frankly, extraordinary investors,
[00:14:21.160 --> 00:14:22.840]   long-term time horizons
[00:14:22.840 --> 00:14:25.520]   aligned with national sovereign interests.
[00:14:25.520 --> 00:14:26.960]   And it's not just them, right?
[00:14:26.960 --> 00:14:29.480]   The Saudis, the Kuwaitis.
[00:14:29.480 --> 00:14:30.560]   And then don't forget,
[00:14:30.560 --> 00:14:33.800]   we've also seen the private wealth,
[00:14:33.800 --> 00:14:36.480]   the high-net-worth platforms move into this space.
[00:14:36.480 --> 00:14:39.800]   So Goldman Sachs, JP Morgan, Morgan Stanley,
[00:14:39.800 --> 00:14:42.120]   those platforms are now aggregating
[00:14:42.120 --> 00:14:44.880]   and put big dollars into this space.
[00:14:44.880 --> 00:14:48.680]   So the most fascinating part of this
[00:14:48.680 --> 00:14:51.240]   is that we do now, in my estimation,
[00:14:51.240 --> 00:14:54.000]   I think this has been the case for quite a long time,
[00:14:54.000 --> 00:14:56.160]   we have the permanent emergence
[00:14:56.160 --> 00:14:59.400]   of what I've been calling the quasi-public market, right?
[00:14:59.400 --> 00:15:01.680]   And the reason I call it the quasi-public market
[00:15:01.680 --> 00:15:06.200]   is because VC has a certain connotation to it, right?
[00:15:06.200 --> 00:15:09.160]   You're taking that first, second, third round of risk
[00:15:09.160 --> 00:15:10.000]   into a company.
[00:15:10.000 --> 00:15:14.400]   You often own somewhere between 7% and 20% of a company.
[00:15:14.400 --> 00:15:16.600]   You take a board seat, you actively engage
[00:15:16.600 --> 00:15:18.600]   and help build that company's success.
[00:15:18.600 --> 00:15:21.880]   That's very different than investing in a company
[00:15:21.880 --> 00:15:25.440]   at 10, 20, $30 billion that frankly
[00:15:25.440 --> 00:15:30.200]   is in a very different place in its life cycle oftentimes.
[00:15:30.200 --> 00:15:31.600]   So, you know, I don't know.
[00:15:31.600 --> 00:15:33.840]   I look at that and if I ask the question,
[00:15:33.840 --> 00:15:35.880]   is that good or bad?
[00:15:35.880 --> 00:15:36.720]   I don't know.
[00:15:36.720 --> 00:15:40.600]   More liquidity allows guys like Elon's to better experiment,
[00:15:40.600 --> 00:15:43.840]   to take bigger swings of the bat.
[00:15:43.840 --> 00:15:46.280]   Maybe it compresses the margins
[00:15:46.280 --> 00:15:48.400]   for those of us in the investing business,
[00:15:48.400 --> 00:15:51.960]   but I think it leads ultimately to a lot more innovation.
[00:15:51.960 --> 00:15:54.960]   Although I'm sensitive to the point you put out there.
[00:15:54.960 --> 00:15:57.160]   You know, it was just two or three years ago
[00:15:57.160 --> 00:15:58.840]   where we were talking about, right?
[00:15:58.840 --> 00:16:03.560]   The soft bank effect, weapons of economic destruction.
[00:16:03.560 --> 00:16:06.320]   You know, we certainly led to excess competition
[00:16:06.320 --> 00:16:08.760]   in the ride-sharing space.
[00:16:08.760 --> 00:16:10.840]   And so what it did is it slowed down
[00:16:10.840 --> 00:16:12.960]   and prevented the natural order of things.
[00:16:12.960 --> 00:16:15.320]   The 80/20, the winner take most
[00:16:15.320 --> 00:16:17.200]   from developing in a profitable way.
[00:16:17.200 --> 00:16:20.960]   And once that capital dried up a bit, Bill,
[00:16:20.960 --> 00:16:24.320]   obviously you saw the profitability of Uber skyrocket
[00:16:24.320 --> 00:16:27.560]   and the natural kind of market structure set in.
[00:16:27.560 --> 00:16:29.960]   So I do think that's a downside of this,
[00:16:29.960 --> 00:16:32.320]   but net-net, I think it's a positive development
[00:16:32.320 --> 00:16:34.040]   for entrepreneurs and innovation.
[00:16:34.040 --> 00:16:37.760]   Yeah, I could certainly express some things
[00:16:37.760 --> 00:16:40.880]   that I worry about that are not necessarily
[00:16:40.880 --> 00:16:45.040]   in the best interest of the entrepreneur or the investor.
[00:16:45.040 --> 00:16:50.040]   So one, just with this much money being pushed upon you,
[00:16:50.040 --> 00:16:54.120]   and if you don't take it, your competitor will take it.
[00:16:54.120 --> 00:16:55.720]   You're forced into the game.
[00:16:55.720 --> 00:16:57.320]   Like you're not allowed to not play.
[00:16:57.320 --> 00:17:01.400]   Is that what you feel like happened between Uber and Lyft?
[00:17:01.400 --> 00:17:03.000]   Sure, sure, absolutely.
[00:17:03.000 --> 00:17:04.440]   But there were many examples.
[00:17:04.480 --> 00:17:09.480]   I mean, I think that a company back on the board of Zillow
[00:17:09.480 --> 00:17:14.120]   was forced into this home purchasing market
[00:17:14.120 --> 00:17:17.640]   because the open door team raised so much money
[00:17:17.640 --> 00:17:19.720]   and was gonna tell the world
[00:17:19.720 --> 00:17:22.560]   that they're gonna be obsolete.
[00:17:22.560 --> 00:17:25.880]   And so if you don't engage,
[00:17:25.880 --> 00:17:28.720]   you could have multiple compression on your head.
[00:17:28.720 --> 00:17:32.800]   It's an interesting dynamic.
[00:17:32.800 --> 00:17:35.280]   Anyway, you're gonna have higher burn rates.
[00:17:35.280 --> 00:17:38.160]   And so you're gonna know less about your unit economics
[00:17:38.160 --> 00:17:40.800]   just by a natural fact 'cause you get further away
[00:17:40.800 --> 00:17:42.440]   when you're operating that way.
[00:17:42.440 --> 00:17:44.120]   And you can't raise $400 million
[00:17:44.120 --> 00:17:45.320]   and not have a high burn rate.
[00:17:45.320 --> 00:17:47.240]   Like there's no point in it
[00:17:47.240 --> 00:17:49.160]   unless you just like interest income.
[00:17:49.160 --> 00:17:54.680]   The staying private longer thing
[00:17:54.680 --> 00:17:57.360]   becomes both the dog and the tail.
[00:17:57.360 --> 00:18:01.000]   Like it's hard to know what's causing which, right?
[00:18:01.000 --> 00:18:03.400]   Because once the investors want,
[00:18:03.400 --> 00:18:05.880]   and this is true of founder liquidity
[00:18:05.880 --> 00:18:08.360]   and employees secondaries also,
[00:18:08.360 --> 00:18:13.360]   once the people want to bring the money to you,
[00:18:13.360 --> 00:18:16.480]   especially preemptive rounds, this kind of thing,
[00:18:16.480 --> 00:18:19.280]   you start searching for ways
[00:18:19.280 --> 00:18:21.960]   to make it easy for that round to take place.
[00:18:21.960 --> 00:18:24.880]   And so you start encouraging staying private longer,
[00:18:24.880 --> 00:18:27.520]   you start encouraging the secondaries.
[00:18:27.520 --> 00:18:30.840]   And that can create a misalignment of interest.
[00:18:30.840 --> 00:18:32.880]   Let us not forget that the Byrd founder
[00:18:32.880 --> 00:18:36.240]   took out 50 million in a private round,
[00:18:36.240 --> 00:18:39.680]   and that company's now bankrupt, right?
[00:18:39.680 --> 00:18:42.160]   Well, I definitely, there are two things,
[00:18:42.160 --> 00:18:44.120]   two features of this that worry me.
[00:18:44.120 --> 00:18:47.640]   There is absolutely no doubt in my mind
[00:18:47.640 --> 00:18:52.640]   that excess capital distorts company behavior, okay?
[00:18:52.640 --> 00:18:56.240]   And in particularly these early phases,
[00:18:56.240 --> 00:18:58.680]   it's very difficult, it's not impossible,
[00:18:58.680 --> 00:19:02.600]   but it's very difficult to stay fit and efficient
[00:19:02.600 --> 00:19:06.920]   when you have a buffet of all options sitting in front of you
[00:19:06.920 --> 00:19:08.360]   and you can fund all of them.
[00:19:08.360 --> 00:19:12.840]   Scarcity breeds necessity, scarcity breeds innovation.
[00:19:12.840 --> 00:19:14.520]   So I think if you're on the board of a company
[00:19:14.520 --> 00:19:16.520]   or a founder of a company or CEO of a company,
[00:19:16.520 --> 00:19:20.320]   you have to think long and hard about the negative cultural
[00:19:20.320 --> 00:19:23.440]   and negative fundamental effects to your business
[00:19:23.440 --> 00:19:24.560]   of taking too much capital.
[00:19:24.560 --> 00:19:27.120]   I mean, we saw this song and verse
[00:19:27.120 --> 00:19:30.720]   over the period 2018 to 2022.
[00:19:30.720 --> 00:19:32.200]   And frankly, we're still moving
[00:19:32.200 --> 00:19:33.720]   through the hangover of it, Bill.
[00:19:33.720 --> 00:19:36.200]   Yeah, and stay private longer
[00:19:36.200 --> 00:19:38.280]   can become stay private forever,
[00:19:38.280 --> 00:19:43.240]   which has a negative impact on IRR and eventual liquidity.
[00:19:43.240 --> 00:19:47.200]   And if you've taken, there's another element of this
[00:19:47.200 --> 00:19:48.880]   that's gonna bring the regulators in
[00:19:48.880 --> 00:19:51.240]   and Lord knows what they'll do,
[00:19:51.240 --> 00:19:52.760]   but it'll probably mess it up,
[00:19:52.760 --> 00:19:57.040]   is that if this sector of growth
[00:19:57.040 --> 00:20:00.160]   has been stolen from the public markets
[00:20:00.160 --> 00:20:03.160]   by the quasi public market, as you call it,
[00:20:03.160 --> 00:20:06.560]   then the people in Congress will cry foul
[00:20:06.560 --> 00:20:08.800]   that the individual investor
[00:20:08.800 --> 00:20:10.800]   doesn't have an opportunity to play.
[00:20:10.800 --> 00:20:13.880]   I'm sympathetic.
[00:20:13.880 --> 00:20:15.560]   And they'll start doing stuff
[00:20:15.560 --> 00:20:20.000]   that will cause more chaos, I'm sure.
[00:20:20.000 --> 00:20:21.680]   Well, I'm sympathetic to the argument.
[00:20:21.680 --> 00:20:23.280]   You and I've discussed this many times,
[00:20:23.280 --> 00:20:26.200]   the number of public companies in the US has collapsed.
[00:20:26.200 --> 00:20:28.440]   The whole idea of accredited investor status
[00:20:28.440 --> 00:20:29.800]   that you have to have a certain amount of money
[00:20:29.800 --> 00:20:34.400]   in order to be deemed worthy to invest in private companies.
[00:20:34.400 --> 00:20:37.600]   And if they stay private until they're worth $100 billion
[00:20:37.600 --> 00:20:40.560]   or take open AI, like there are a lot of retail investors
[00:20:40.560 --> 00:20:42.800]   that would love to buy open AI today.
[00:20:42.800 --> 00:20:45.080]   And the only ones who can fundamentally,
[00:20:45.080 --> 00:20:47.640]   or who can really access it are accredited investors,
[00:20:47.640 --> 00:20:49.160]   high net worth investors.
[00:20:49.160 --> 00:20:50.000]   So it is ironic-
[00:20:50.000 --> 00:20:52.280]   And then you have to know some, like there's no,
[00:20:52.280 --> 00:20:55.520]   and it doesn't matter, but we're making the same point.
[00:20:55.520 --> 00:20:59.080]   But I would say, again,
[00:20:59.080 --> 00:21:01.240]   at least the companies that we're involved in,
[00:21:01.240 --> 00:21:04.880]   we have these conversations very openly with the founders
[00:21:04.880 --> 00:21:06.760]   about the risk reward and the trade-offs.
[00:21:06.760 --> 00:21:09.400]   I do think there is a lot of these pressures
[00:21:09.400 --> 00:21:14.360]   that you rightfully acknowledge.
[00:21:14.360 --> 00:21:18.320]   But ultimately it seems to me like, as to this question,
[00:21:18.320 --> 00:21:21.960]   whether or not this is going to yield good results, right?
[00:21:21.960 --> 00:21:23.200]   I think it's a net, net,
[00:21:23.200 --> 00:21:25.880]   I think it's generally deeper liquid, more liquid markets,
[00:21:25.880 --> 00:21:30.400]   generally a positive for the entrepreneurs and the founders.
[00:21:30.400 --> 00:21:32.600]   And I think for the firms, listen,
[00:21:32.600 --> 00:21:36.320]   late stage private deals,
[00:21:36.320 --> 00:21:38.960]   like let's go back to think Groupon.
[00:21:38.960 --> 00:21:41.720]   I think the last private round there was 19 billion
[00:21:41.720 --> 00:21:44.320]   and two years later, it's worth 1 billion.
[00:21:44.320 --> 00:21:46.240]   This comes down to stock selection.
[00:21:46.240 --> 00:21:47.560]   This comes down to investing.
[00:21:47.560 --> 00:21:48.840]   It comes down to your underwriting.
[00:21:48.840 --> 00:21:50.600]   It comes down to risk reward.
[00:21:50.600 --> 00:21:53.680]   I might think that open AI at $90 billion
[00:21:53.680 --> 00:21:55.440]   is an incredible risk reward
[00:21:55.440 --> 00:21:59.480]   and wish that I had more money in open AI at that valuation.
[00:21:59.480 --> 00:22:01.320]   Others may think that's ludicrous.
[00:22:01.320 --> 00:22:03.320]   That's called a market, right?
[00:22:03.320 --> 00:22:05.520]   And you're going to be proven right or wrong
[00:22:05.520 --> 00:22:06.960]   in the fullness of time.
[00:22:06.960 --> 00:22:09.840]   And frankly, Bill, to your point about two and 20,
[00:22:09.840 --> 00:22:11.520]   LPs get to decide.
[00:22:11.520 --> 00:22:13.640]   If you go out and you want to raise money from them,
[00:22:13.640 --> 00:22:14.760]   you want to raise billions
[00:22:14.760 --> 00:22:16.800]   in order to put billions in open AI,
[00:22:16.800 --> 00:22:20.080]   they get to ultimately decide what they're willing to pay.
[00:22:20.080 --> 00:22:21.640]   And, you know, again,
[00:22:21.640 --> 00:22:23.320]   they're going to probably be held accountable
[00:22:23.320 --> 00:22:24.960]   at some point in time for their returns as well.
[00:22:24.960 --> 00:22:27.560]   Although that can take a very, very long time.
[00:22:27.560 --> 00:22:31.600]   As you know, that could be a 10 to 15 year window before,
[00:22:31.600 --> 00:22:33.800]   like corrections in the LP market
[00:22:33.800 --> 00:22:37.320]   are one of the slowest things that can possibly happen.
[00:22:37.320 --> 00:22:39.360]   And I'll close this part
[00:22:39.360 --> 00:22:41.600]   by acknowledging something that you've said before,
[00:22:41.600 --> 00:22:45.040]   which is, and I've talked about in other places,
[00:22:45.040 --> 00:22:48.600]   but some of this and the reason it's systematic
[00:22:48.600 --> 00:22:51.240]   and not cyclical is just a recognition
[00:22:51.240 --> 00:22:54.640]   that when technology companies gain a foothold
[00:22:54.640 --> 00:22:56.240]   and have positive momentum,
[00:22:56.240 --> 00:22:59.120]   they often go much further and longer and higher
[00:22:59.120 --> 00:23:00.960]   and they have network effects.
[00:23:00.960 --> 00:23:04.080]   And so this is, some of this at least
[00:23:04.080 --> 00:23:07.560]   is the market coming to grips with that
[00:23:07.560 --> 00:23:12.000]   and recognizing that you can pay 30 or 40 times revenue
[00:23:12.000 --> 00:23:13.840]   for something if it's going to hyper growth
[00:23:13.840 --> 00:23:17.000]   for four or five years because of systematic advantages
[00:23:17.000 --> 00:23:20.080]   and adjusting their game on the field as a result.
[00:23:20.080 --> 00:23:21.840]   - I blame a fair bit of that on you.
[00:23:21.840 --> 00:23:25.760]   I mean, you educating everybody on power law
[00:23:25.760 --> 00:23:28.200]   and network effects over the last 15 years
[00:23:28.200 --> 00:23:30.000]   hasn't helped our plight at all.
[00:23:30.000 --> 00:23:31.720]   I mean, the competition is stiff.
[00:23:31.720 --> 00:23:33.280]   I think that the efficiency
[00:23:33.280 --> 00:23:36.000]   of the late stage private market, you know,
[00:23:36.000 --> 00:23:38.800]   it's no longer five or six players in that market.
[00:23:38.800 --> 00:23:42.760]   As you know, you're talking 20, 30, 40 players, you know,
[00:23:42.760 --> 00:23:44.760]   that will show up to these things.
[00:23:44.760 --> 00:23:46.520]   So it's difficult.
[00:23:46.520 --> 00:23:49.440]   And I know, I stress about this all the time.
[00:23:49.440 --> 00:23:52.000]   We're going to be judged ultimately
[00:23:52.000 --> 00:23:54.240]   by the returns on that capital.
[00:23:54.240 --> 00:23:57.480]   And I think the folks who are deploying that capital
[00:23:57.480 --> 00:24:01.120]   for the most part are pretty extraordinary
[00:24:01.120 --> 00:24:02.200]   and worthy competitors.
[00:24:02.200 --> 00:24:04.080]   And we end up, frankly, these big rounds
[00:24:04.080 --> 00:24:06.640]   oftentimes are collaborations between many firms,
[00:24:06.640 --> 00:24:08.640]   much as you've seen in private equity develop
[00:24:08.640 --> 00:24:09.480]   over the years.
[00:24:09.480 --> 00:24:11.240]   But one of the things I did want to touch on,
[00:24:11.240 --> 00:24:13.440]   you raised this question, like how much of this
[00:24:13.440 --> 00:24:15.920]   has gone into, you know, generative AI
[00:24:15.920 --> 00:24:17.960]   and how is this skewing it?
[00:24:17.960 --> 00:24:19.240]   And so we have a couple of charts here.
[00:24:19.240 --> 00:24:21.160]   I think Sapphire Ventures, you know,
[00:24:21.160 --> 00:24:24.960]   put these charts together and it just shows like, you know,
[00:24:24.960 --> 00:24:29.320]   the vast majority of money, I think AI funding in 2023,
[00:24:29.320 --> 00:24:33.800]   Forexed, you know, 28 billion and over 700 deals.
[00:24:33.800 --> 00:24:36.800]   But what was interesting is about 65% of that,
[00:24:36.800 --> 00:24:39.000]   talking about power law, 65% of that,
[00:24:39.000 --> 00:24:42.320]   I think went into five or six companies,
[00:24:42.320 --> 00:24:43.760]   you know, that you know of.
[00:24:43.760 --> 00:24:46.400]   And by the way, those companies need big checks
[00:24:46.400 --> 00:24:50.240]   because they're consuming voracious amounts of capital.
[00:24:50.240 --> 00:24:53.560]   And you know, perhaps that's a jumping off point.
[00:24:53.560 --> 00:24:56.800]   Although some of this may involve these credit deals,
[00:24:56.800 --> 00:24:58.080]   some of this count.
[00:24:58.080 --> 00:24:59.600]   Oh, for sure, for sure.
[00:24:59.600 --> 00:25:02.720]   And listen, that's another thing one has to take into account
[00:25:02.720 --> 00:25:04.520]   when thinking about these valuations.
[00:25:04.520 --> 00:25:06.840]   But I know that you have a little bit of angst
[00:25:06.840 --> 00:25:08.960]   based on prior pattern recognition,
[00:25:08.960 --> 00:25:11.880]   just about, you know, whether this is developing
[00:25:11.880 --> 00:25:13.920]   into a bit of a hype cycle.
[00:25:13.920 --> 00:25:15.640]   So why don't you talk to us about your thoughts
[00:25:15.640 --> 00:25:16.480]   about what's going on.
[00:25:16.480 --> 00:25:20.400]   Look, I think it unquestionably is in a hype cycle.
[00:25:20.400 --> 00:25:23.680]   And by hype, I don't mean negative necessarily,
[00:25:23.680 --> 00:25:26.640]   just that everyone's talking about it.
[00:25:26.640 --> 00:25:31.640]   There's not a CEO or a CIO in the US
[00:25:31.640 --> 00:25:35.200]   or probably around the world that hasn't asked the question,
[00:25:35.200 --> 00:25:36.760]   what are we doing in AI?
[00:25:36.760 --> 00:25:39.280]   You know, how can it impact our business?
[00:25:39.280 --> 00:25:43.920]   Like it is on the tips of everybody's tongues, right?
[00:25:43.920 --> 00:25:47.440]   And so when you get in these situations,
[00:25:47.440 --> 00:25:49.800]   I'm always like, I don't know why,
[00:25:49.800 --> 00:25:53.040]   but I'm always fascinated with what's reality
[00:25:53.040 --> 00:25:55.080]   and whether we might go too far
[00:25:55.080 --> 00:25:59.640]   and what we're promising versus what can actually be done.
[00:25:59.640 --> 00:26:04.640]   I think in this case, because some of the leaders
[00:26:05.200 --> 00:26:08.880]   and I'd say OpenA is probably the strongest,
[00:26:08.880 --> 00:26:11.400]   are willing to spout hyperbole.
[00:26:11.400 --> 00:26:14.320]   And what I mean by hyperbole is they're willing
[00:26:14.320 --> 00:26:18.360]   to just state really vague, broad, big ideas
[00:26:18.360 --> 00:26:20.260]   without much meat on them.
[00:26:20.260 --> 00:26:24.800]   And I think that then creates a situation
[00:26:24.800 --> 00:26:28.680]   where I think you end up having tension in the system
[00:26:28.680 --> 00:26:32.400]   where some people feel like their own business model
[00:26:32.400 --> 00:26:34.200]   is threatened by this notion,
[00:26:34.200 --> 00:26:36.220]   especially if the notion goes too far.
[00:26:36.220 --> 00:26:38.280]   There was a super interesting comment made
[00:26:38.280 --> 00:26:41.160]   by the new chairman of TSMC where he said,
[00:26:41.160 --> 00:26:45.480]   "OpenAI Sam Altman is too aggressive for me to believe."
[00:26:45.480 --> 00:26:48.280]   Now, why would he go out and say that out loud?
[00:26:48.280 --> 00:26:51.260]   Like, you know, what's his incentive?
[00:26:51.260 --> 00:26:54.520]   And I would say his incentive is he's running a business.
[00:26:54.520 --> 00:26:57.280]   He's got people asking him questions all the time
[00:26:57.280 --> 00:27:00.240]   about where this business is going, how's it gonna be.
[00:27:00.240 --> 00:27:04.000]   And there's this other person running around the globe
[00:27:04.000 --> 00:27:07.200]   telling everyone everything, including spreading rumors
[00:27:07.200 --> 00:27:10.280]   that he's gonna spend 100 billion of Microsoft's money
[00:27:10.280 --> 00:27:13.720]   and he's gonna build his own chips and build his own fabs.
[00:27:13.720 --> 00:27:17.600]   And that then starts to be distracting
[00:27:17.600 --> 00:27:18.860]   to a company like TSMC.
[00:27:18.860 --> 00:27:20.520]   Yeah, but hey, you know,
[00:27:20.520 --> 00:27:22.560]   like let me take the other side of it, right?
[00:27:22.560 --> 00:27:24.400]   I'm sure you would.
[00:27:24.400 --> 00:27:27.280]   No, I mean, I'm just saying, you know,
[00:27:27.280 --> 00:27:30.600]   Elon set out a vision for rockets that could land themselves
[00:27:30.600 --> 00:27:33.760]   and auto fleets that would be replaced by electric cars
[00:27:33.760 --> 00:27:35.360]   at the time he said these things,
[00:27:35.360 --> 00:27:37.160]   they sounded totally outlandish.
[00:27:37.160 --> 00:27:39.680]   And by the way, the time took longer
[00:27:39.680 --> 00:27:42.320]   to get to most of these points than Elon envisioned,
[00:27:42.320 --> 00:27:43.960]   but we ultimately got there
[00:27:43.960 --> 00:27:45.800]   and it ultimately blew our socks off.
[00:27:45.800 --> 00:27:48.520]   And I think two of the things you have to do, right?
[00:27:48.520 --> 00:27:49.920]   You have to will the future.
[00:27:49.920 --> 00:27:51.320]   You have to manifest the future.
[00:27:51.320 --> 00:27:52.800]   You have to describe the future.
[00:27:52.800 --> 00:27:54.580]   You have to motivate your employees.
[00:27:54.580 --> 00:27:58.420]   And importantly, you have to motivate sources of capital.
[00:27:58.420 --> 00:27:59.260]   Right?
[00:27:59.260 --> 00:28:02.120]   And so I think in the case of Sam, you know,
[00:28:02.120 --> 00:28:03.480]   he's out there saying these things.
[00:28:03.480 --> 00:28:06.680]   And again, I don't need to come to his defense.
[00:28:06.680 --> 00:28:08.000]   I think he's incredibly thoughtful.
[00:28:08.000 --> 00:28:09.760]   I think he is a true believer.
[00:28:09.760 --> 00:28:11.040]   As I am a believer,
[00:28:11.040 --> 00:28:13.320]   I don't know what the time series is going to be.
[00:28:13.320 --> 00:28:16.560]   And I'm certain all of these experiments will not work.
[00:28:16.560 --> 00:28:19.920]   With that said, if I am the CEO of TSMC,
[00:28:19.920 --> 00:28:21.680]   I would say exactly what he did.
[00:28:21.680 --> 00:28:23.280]   And the reason I would say it
[00:28:23.280 --> 00:28:26.800]   is because if Sam's going to emerge as competition,
[00:28:26.800 --> 00:28:29.320]   build his own fab, build his own chip, et cetera,
[00:28:29.320 --> 00:28:30.200]   what would I want to do?
[00:28:30.200 --> 00:28:32.720]   I would want to undermine the sources of capital
[00:28:32.720 --> 00:28:34.880]   so that he can't become competition.
[00:28:34.880 --> 00:28:37.520]   I would say to the sovereigns
[00:28:37.520 --> 00:28:39.000]   who are thinking about funding him,
[00:28:39.000 --> 00:28:40.760]   whoa, you better be careful
[00:28:40.760 --> 00:28:42.960]   because this guy is too aggressive.
[00:28:42.960 --> 00:28:44.880]   This is part of the war of words
[00:28:44.880 --> 00:28:46.440]   that we see out there all the time.
[00:28:46.440 --> 00:28:48.960]   I mean, Databricks does this and incredibly,
[00:28:48.960 --> 00:28:52.240]   Ali is amazing against Snowflake.
[00:28:52.240 --> 00:28:55.240]   I see this happen in VC land all the time
[00:28:55.240 --> 00:28:56.440]   where people will say something
[00:28:56.440 --> 00:28:58.400]   to try to freeze the markets
[00:28:58.400 --> 00:28:59.920]   so a company doesn't get funded.
[00:28:59.920 --> 00:29:01.760]   - Rarely works, yes, yes, yes.
[00:29:01.760 --> 00:29:03.360]   A company doesn't get funded.
[00:29:03.360 --> 00:29:08.360]   So all I would say is that it may in fact be very shrewd
[00:29:08.360 --> 00:29:12.360]   by Sam to be doing exactly what he's doing.
[00:29:12.360 --> 00:29:14.880]   I don't think that necessarily undermines
[00:29:14.880 --> 00:29:17.800]   the advances that we're making.
[00:29:17.800 --> 00:29:20.840]   Although I would say that we're in the fog of war right now
[00:29:20.840 --> 00:29:23.560]   and it's very hard to know the timescale
[00:29:23.560 --> 00:29:25.160]   that a lot of these things will unfold.
[00:29:25.160 --> 00:29:30.040]   - I would, so you use maybe like Elon and the Tesla example.
[00:29:30.040 --> 00:29:33.440]   I think another example is crypto, right?
[00:29:33.440 --> 00:29:36.400]   And so we went through a phase
[00:29:36.400 --> 00:29:39.040]   where there were very, very smart people
[00:29:39.040 --> 00:29:44.200]   on podcasts like this and around the globe
[00:29:44.200 --> 00:29:46.680]   saying that crypto and blockchain
[00:29:46.680 --> 00:29:48.600]   would replace the corporate entity
[00:29:48.600 --> 00:29:53.200]   and that marketplace companies like Uber wouldn't exist
[00:29:53.200 --> 00:29:54.600]   and all this stuff.
[00:29:54.600 --> 00:29:56.960]   And that just didn't play out
[00:29:56.960 --> 00:29:59.400]   and I don't think it's going to.
[00:30:00.080 --> 00:30:00.920]   - Yeah.
[00:30:00.920 --> 00:30:03.400]   - I'll go out on a limb.
[00:30:03.400 --> 00:30:06.280]   And so, but for a while, we all believed it.
[00:30:06.280 --> 00:30:11.080]   There was a moment in time where the scooter companies
[00:30:11.080 --> 00:30:15.480]   were claiming that they were gonna take 75% of Uber's rides.
[00:30:15.480 --> 00:30:16.840]   That did not happen.
[00:30:16.840 --> 00:30:20.000]   There hardly anyone riding here in Austin.
[00:30:20.000 --> 00:30:23.440]   And so sometimes you're right.
[00:30:23.440 --> 00:30:27.000]   Sometimes you are drawing a picture of the future
[00:30:27.000 --> 00:30:28.640]   that we actually get to.
[00:30:28.640 --> 00:30:30.560]   And sometimes that doesn't play out.
[00:30:30.560 --> 00:30:35.040]   So, you know, there's more meat on the bone here to be fair.
[00:30:35.040 --> 00:30:38.400]   But when you say this stuff will do anything and everything,
[00:30:38.400 --> 00:30:39.440]   when you say-- - Oh, for sure.
[00:30:39.440 --> 00:30:42.760]   - My computer, when it's not summarizing my email,
[00:30:42.760 --> 00:30:44.480]   will be curing cancer.
[00:30:44.480 --> 00:30:47.200]   And when you start talking about UBI
[00:30:47.200 --> 00:30:48.840]   and how no one's gonna work,
[00:30:48.840 --> 00:30:53.080]   like, I just think that's like la la land stuff.
[00:30:53.080 --> 00:30:55.040]   And lots of people are saying it.
[00:30:55.040 --> 00:30:56.640]   Lots of people are saying it.
[00:30:56.640 --> 00:30:59.440]   - No, no, listen, I think here's where I think
[00:30:59.440 --> 00:31:02.120]   your admonition is smart.
[00:31:02.120 --> 00:31:04.080]   And as you know, we've looked at a lot of stuff
[00:31:04.080 --> 00:31:06.000]   at Altimeter in the AI landscape.
[00:31:06.000 --> 00:31:08.200]   You know, enabling technologies, infrastructure,
[00:31:08.200 --> 00:31:10.000]   picks and shovels.
[00:31:10.000 --> 00:31:14.360]   For all the reasons about uncertainty and high valuations,
[00:31:14.360 --> 00:31:17.480]   a lot of valuations reflect or discount
[00:31:17.480 --> 00:31:20.240]   or underwrite high levels of certainty, right?
[00:31:20.240 --> 00:31:22.920]   That I think are hard to peg at this moment in time.
[00:31:22.920 --> 00:31:26.440]   This is what I think happens in the fog of war, right?
[00:31:26.440 --> 00:31:29.960]   And the goal of an analyst is to develop deep conviction
[00:31:29.960 --> 00:31:31.680]   at these moments in time
[00:31:31.680 --> 00:31:34.560]   and be right before everybody else does, right?
[00:31:34.560 --> 00:31:37.160]   I think about this in the internet.
[00:31:37.160 --> 00:31:39.520]   People had deep conviction it was going to be huge,
[00:31:39.520 --> 00:31:41.520]   that search was gonna be important.
[00:31:41.520 --> 00:31:44.280]   But a lot of people ran out and invested in Ash Jeeves
[00:31:44.280 --> 00:31:47.320]   and Alta Vista and Lycos and Excite
[00:31:47.320 --> 00:31:48.640]   and name all the companies
[00:31:48.640 --> 00:31:50.480]   that a few years later would go to zero.
[00:31:50.480 --> 00:31:54.560]   And it's almost certain that that will also happen in AI.
[00:31:54.560 --> 00:31:57.320]   That didn't mean that the internet wasn't going to be huge
[00:31:57.320 --> 00:31:58.760]   or that Google wasn't going to be
[00:31:58.760 --> 00:32:01.120]   a multi-trillion dollar company,
[00:32:01.120 --> 00:32:03.920]   which I also think will happen here.
[00:32:03.920 --> 00:32:05.560]   But the, go ahead.
[00:32:05.560 --> 00:32:06.520]   Well, I just think this is,
[00:32:06.520 --> 00:32:09.760]   so I wanted to do this one before the software one
[00:32:09.760 --> 00:32:11.840]   because I think they're relevant to one another.
[00:32:11.840 --> 00:32:16.840]   So there are people that believe that AI,
[00:32:16.840 --> 00:32:19.280]   and when they say that, I can't,
[00:32:19.280 --> 00:32:22.880]   I never know whether they're talking about AI or LLMs,
[00:32:22.880 --> 00:32:26.040]   which I view as a very small subset of AI,
[00:32:26.040 --> 00:32:30.280]   but we'll just do everything.
[00:32:30.280 --> 00:32:32.120]   It's just gonna do everything.
[00:32:32.120 --> 00:32:36.160]   And so this, our last topic about,
[00:32:36.160 --> 00:32:37.880]   these people have come out and said,
[00:32:37.880 --> 00:32:40.280]   well, because of what you saw in the earnings period
[00:32:40.280 --> 00:32:43.600]   and how the stocks reacted, software is dead.
[00:32:43.600 --> 00:32:46.120]   And so there are people that believe one day
[00:32:46.120 --> 00:32:49.200]   you'll just tell your LLM what you want it to do
[00:32:49.200 --> 00:32:52.480]   and it'll do everything that software did.
[00:32:52.480 --> 00:32:53.520]   - Right.
[00:32:53.520 --> 00:32:55.480]   - That's a pretty strong form of it.
[00:32:55.480 --> 00:32:57.720]   I think there's a lesser strong form of it
[00:32:57.720 --> 00:33:02.720]   that the UI around LLMs are gonna enable
[00:33:02.720 --> 00:33:07.680]   a type of interaction with what we used to think of
[00:33:07.680 --> 00:33:09.680]   as a SaaS application,
[00:33:09.680 --> 00:33:13.320]   that's gonna make the older apps feel tedious
[00:33:13.320 --> 00:33:16.440]   and therefore you end up with a replacement cycle,
[00:33:16.440 --> 00:33:20.080]   maybe as big as SaaS replacing on-prem,
[00:33:21.520 --> 00:33:25.120]   maybe as big as SaaS replacing client server
[00:33:25.120 --> 00:33:28.240]   or whatever came before or many in mainframe.
[00:33:28.240 --> 00:33:30.480]   And if you believe that,
[00:33:30.480 --> 00:33:33.080]   how much of this gets rewritten?
[00:33:33.080 --> 00:33:36.600]   So you've invested in so many software companies,
[00:33:36.600 --> 00:33:38.640]   you guys are deep in your analytics.
[00:33:38.640 --> 00:33:42.840]   What did you see in the past three weeks from earnings
[00:33:42.840 --> 00:33:46.200]   and how do you think about AI as a risk
[00:33:46.200 --> 00:33:50.040]   for multiple compression and disruption
[00:33:50.040 --> 00:33:53.200]   for the software industry writ large?
[00:33:53.200 --> 00:33:55.720]   - Yeah, no, I think it's super important question.
[00:33:55.720 --> 00:33:58.520]   By way of transition to that,
[00:33:58.520 --> 00:34:00.120]   I did wanna say this thing
[00:34:00.120 --> 00:34:02.960]   that not everybody is all in on AI.
[00:34:02.960 --> 00:34:06.760]   I'm going to WWDC at Apple tomorrow
[00:34:06.760 --> 00:34:10.240]   and Apple Intelligence is out this morning
[00:34:10.240 --> 00:34:14.080]   talking about AI service that they're gonna unveil.
[00:34:14.080 --> 00:34:16.360]   They have not spent tens of billions of dollars
[00:34:16.360 --> 00:34:19.600]   building LLMs or frontier models
[00:34:19.600 --> 00:34:22.240]   and there are some people who are critical of that bill.
[00:34:22.240 --> 00:34:24.400]   And I imagine they're looking at it and saying,
[00:34:24.400 --> 00:34:26.200]   "We don't see the industrial logic.
[00:34:26.200 --> 00:34:27.400]   We don't see the return."
[00:34:27.400 --> 00:34:30.680]   It's known to be a very financially
[00:34:30.680 --> 00:34:32.480]   and fiscally conservative company.
[00:34:32.480 --> 00:34:35.440]   And so they'll probably announce a partnership with OpenAI.
[00:34:35.440 --> 00:34:38.080]   My sense is they probably look at that and say,
[00:34:38.080 --> 00:34:39.920]   "Oh, that's a transition for us.
[00:34:39.920 --> 00:34:42.760]   Let them spend all the huge early dollars.
[00:34:42.760 --> 00:34:44.800]   We'll come in and be a late mover.
[00:34:44.800 --> 00:34:46.680]   We'll spend a fraction of the money."
[00:34:46.680 --> 00:34:48.880]   And ultimately we control the platform.
[00:34:48.880 --> 00:34:51.160]   We control the device.
[00:34:51.160 --> 00:34:54.560]   And so we're not at risk of getting disintermediated.
[00:34:54.560 --> 00:34:56.840]   My point is that I think there are different choices
[00:34:56.840 --> 00:34:58.640]   being made by different companies.
[00:34:58.640 --> 00:35:02.520]   But that said, using the Apple example,
[00:35:02.520 --> 00:35:05.160]   I do think that the heat is so loud.
[00:35:05.160 --> 00:35:08.560]   Even on this very podcast, we go on, "What are they doing?
[00:35:08.560 --> 00:35:10.560]   Why haven't they made Siri better?"
[00:35:10.560 --> 00:35:13.200]   And like the drumbeat gets to the point.
[00:35:13.200 --> 00:35:16.480]   If they were to hold that tomorrow and not mention AI,
[00:35:16.480 --> 00:35:18.000]   which they would never do,
[00:35:19.000 --> 00:35:21.560]   it would raise immense questions.
[00:35:21.560 --> 00:35:22.560]   No, that's for sure.
[00:35:22.560 --> 00:35:23.400]   Of course not.
[00:35:23.400 --> 00:35:24.240]   Why would they?
[00:35:24.240 --> 00:35:27.680]   But I think they're going to have a series of announcements
[00:35:27.680 --> 00:35:29.560]   in terms of integrating with OpenAI.
[00:35:29.560 --> 00:35:31.440]   They're gonna make the phone better.
[00:35:31.440 --> 00:35:34.320]   They're gonna say you can only get it on 15 plus or 16.
[00:35:34.320 --> 00:35:38.840]   They'll drive a replacement cycle that begins in 2025,
[00:35:38.840 --> 00:35:42.040]   but they won't spend the dollars to have their own solution
[00:35:42.040 --> 00:35:45.880]   probably until you get in to the release cycle
[00:35:45.880 --> 00:35:47.560]   at the end of '25.
[00:35:47.560 --> 00:35:49.840]   And I think that's a perfectly acceptable solution.
[00:35:49.840 --> 00:35:51.840]   Listen, if everybody was critical of them, Bill,
[00:35:51.840 --> 00:35:53.200]   for not building their own LLM,
[00:35:53.200 --> 00:35:55.160]   everybody knows they have not yet.
[00:35:55.160 --> 00:35:56.560]   And so if people were critical of them,
[00:35:56.560 --> 00:35:59.480]   the stock wouldn't be at 196 bucks a share, right?
[00:35:59.480 --> 00:36:01.280]   People are voting with their wallets and saying,
[00:36:01.280 --> 00:36:03.760]   "Listen, it seems like a pretty good balance
[00:36:03.760 --> 00:36:05.840]   between the choices that you've had."
[00:36:05.840 --> 00:36:08.000]   In fact, I think if people are gonna be critical
[00:36:08.000 --> 00:36:09.760]   of anything, a lot of people are looking
[00:36:09.760 --> 00:36:12.040]   at the total CapEx of the hyperscalers,
[00:36:12.040 --> 00:36:14.560]   now at $200 billion, and saying,
[00:36:14.560 --> 00:36:15.880]   "When are you gonna get a return
[00:36:15.880 --> 00:36:17.680]   on the dollars that you're spending?
[00:36:17.680 --> 00:36:20.560]   And how on earth can you go up from there
[00:36:20.560 --> 00:36:23.160]   and have the industrial logic to earn a return?"
[00:36:23.160 --> 00:36:25.280]   Since you mentioned the hyperscalers,
[00:36:25.280 --> 00:36:30.040]   there was a series of layoffs announced in two of them.
[00:36:30.040 --> 00:36:34.400]   I think it was Google and Azure, was it?
[00:36:34.400 --> 00:36:35.600]   Or Amazon? Yes.
[00:36:35.600 --> 00:36:37.320]   I think they were small targeted.
[00:36:37.320 --> 00:36:41.800]   If you're in just hyper growth mode,
[00:36:41.800 --> 00:36:42.800]   why are you doing layoffs?
[00:36:42.800 --> 00:36:43.640]   I don't understand.
[00:36:43.640 --> 00:36:47.920]   I mean, listen, look at the most recently reported
[00:36:47.920 --> 00:36:49.720]   number of employees at Meta.
[00:36:49.720 --> 00:36:53.120]   Everybody knows that Zuck's in beast mode around AI.
[00:36:53.120 --> 00:36:55.200]   And yet, when he reduced the headcount
[00:36:55.200 --> 00:36:59.000]   from 86,000 to 69,000 a couple years ago,
[00:36:59.000 --> 00:37:00.640]   I think at the end of the most recent quarter,
[00:37:00.640 --> 00:37:03.400]   he still only had 69,400.
[00:37:03.400 --> 00:37:05.880]   There's massive slack in these businesses, Bill,
[00:37:05.880 --> 00:37:07.560]   if they weren't firing people
[00:37:07.560 --> 00:37:08.400]   or encouraging them to turn over.
[00:37:08.400 --> 00:37:11.320]   Yeah, it was just within the unit specific to this,
[00:37:11.320 --> 00:37:12.600]   which was confusing to me.
[00:37:12.600 --> 00:37:15.920]   Anyway, I think it's a good sign out of those guys,
[00:37:15.920 --> 00:37:19.440]   but let's unpack the software stuff that you led us to.
[00:37:19.440 --> 00:37:21.880]   And what I want to start off by saying
[00:37:21.880 --> 00:37:25.840]   is there's a lot to unpack,
[00:37:25.840 --> 00:37:27.400]   but let's start with the obvious, right?
[00:37:27.400 --> 00:37:30.760]   When the future gets less predictable, right?
[00:37:30.760 --> 00:37:35.160]   For any reason, whether it's macro, whether it's micro,
[00:37:35.160 --> 00:37:37.320]   then you have to increase the discount rate
[00:37:37.320 --> 00:37:39.880]   in your free cash flow and your DCF, right?
[00:37:39.880 --> 00:37:42.360]   And that means that multiples go down.
[00:37:42.360 --> 00:37:45.840]   Slowing growth also reduces multiples.
[00:37:45.840 --> 00:37:48.960]   And then we've talked a lot about how high interest rates,
[00:37:48.960 --> 00:37:51.760]   higher than expected, reduces multiples, right?
[00:37:51.760 --> 00:37:53.800]   So this is the triple whammy.
[00:37:53.800 --> 00:37:57.240]   The perfect storm for software multiples is right now
[00:37:57.240 --> 00:37:58.920]   because we've had slowing growth.
[00:37:58.920 --> 00:38:01.200]   We have a lot more uncertainty about the future,
[00:38:01.200 --> 00:38:03.760]   irrespective of what side you're on.
[00:38:03.760 --> 00:38:05.240]   And on top of that,
[00:38:05.240 --> 00:38:08.840]   interest rates have remained higher than expected this year.
[00:38:08.840 --> 00:38:11.680]   And we were starting from historical highs during ZURP.
[00:38:11.680 --> 00:38:13.480]   So let's take a look, right?
[00:38:13.480 --> 00:38:16.080]   This is the chart a lot of people have seen,
[00:38:16.080 --> 00:38:18.760]   and this is made by our team.
[00:38:18.760 --> 00:38:20.520]   And it just shows you where we are
[00:38:20.520 --> 00:38:24.920]   in the historical context of forward revenue multiples, right?
[00:38:24.920 --> 00:38:26.440]   And so we're trading, you know,
[00:38:26.440 --> 00:38:30.600]   about 20% below the 10-year average ex-COVID.
[00:38:30.600 --> 00:38:33.560]   And some people are starting to view that as an opportunity
[00:38:33.560 --> 00:38:37.080]   because when you see headlines that all software is dead,
[00:38:37.080 --> 00:38:39.120]   if you don't believe that to be true
[00:38:39.120 --> 00:38:41.080]   and you see these valuations,
[00:38:41.080 --> 00:38:43.640]   then you say to yourself, "I need to go hunting."
[00:38:43.640 --> 00:38:45.960]   And I'll tell you, there is smart money
[00:38:45.960 --> 00:38:47.960]   that's starting to buy software again.
[00:38:47.960 --> 00:38:51.560]   You see this next chart, which was by Goldman Sachs,
[00:38:51.560 --> 00:38:54.800]   and it just shows us a multiple of free cash flow.
[00:38:54.800 --> 00:38:57.120]   So similar to the chart above.
[00:38:57.120 --> 00:38:59.480]   But what did we hear in the quarter, Bill?
[00:38:59.480 --> 00:39:02.160]   Okay, so UiPath came out
[00:39:02.160 --> 00:39:05.160]   and said their growth slowed down to 6%.
[00:39:05.160 --> 00:39:06.440]   Salesforce came out,
[00:39:06.440 --> 00:39:08.840]   said their growth slowed down to 7%.
[00:39:08.840 --> 00:39:10.880]   And I think for a company like Snowflake,
[00:39:10.880 --> 00:39:13.440]   it came in at 26%.
[00:39:13.440 --> 00:39:16.120]   And Databricks is rumored to still be growing
[00:39:16.120 --> 00:39:18.680]   well in excess of 50%, okay?
[00:39:18.680 --> 00:39:20.320]   But I pulled some snippets
[00:39:20.320 --> 00:39:23.080]   that we could throw up on the screen here
[00:39:23.080 --> 00:39:25.520]   that we got from the commentary, right?
[00:39:25.520 --> 00:39:29.080]   Workday said we saw probably a bit more scrutiny
[00:39:29.080 --> 00:39:31.000]   than we've seen this time last year.
[00:39:31.000 --> 00:39:34.200]   I just think people have taken a little bit of a pause.
[00:39:34.200 --> 00:39:39.200]   Salesforce, the momentum we saw in Q4 moderated in Q1,
[00:39:39.240 --> 00:39:42.600]   and we saw elongated deal cycles, right?
[00:39:42.600 --> 00:39:46.440]   So deal compression and high levels of budget scrutiny.
[00:39:46.440 --> 00:39:47.920]   UiPath, in mid-March,
[00:39:47.920 --> 00:39:50.160]   we began seeing increased deal scrutiny
[00:39:50.160 --> 00:39:54.520]   and longer sales cycle with large multi-year deals, right?
[00:39:54.520 --> 00:39:58.320]   So multiples in all of them have compressed.
[00:39:58.320 --> 00:40:02.120]   And one of the things I think about is public markets,
[00:40:02.120 --> 00:40:03.360]   when they hear things like that,
[00:40:03.360 --> 00:40:05.720]   they shoot now and ask questions later,
[00:40:05.720 --> 00:40:07.480]   or as Druckenmiller likes to say,
[00:40:07.480 --> 00:40:09.400]   invest and then investigate.
[00:40:09.400 --> 00:40:11.320]   And so if you look at
[00:40:11.320 --> 00:40:14.800]   the forward free cashflow multiples on these business,
[00:40:14.800 --> 00:40:18.360]   UiPath is now trading at something like 20 times
[00:40:18.360 --> 00:40:20.800]   and Snowflake at 36 times.
[00:40:20.800 --> 00:40:22.520]   If you look at their revenue multiples,
[00:40:22.520 --> 00:40:26.280]   4X and 9X respectively on 2025.
[00:40:26.280 --> 00:40:27.960]   So those are a hell of a lot lower
[00:40:27.960 --> 00:40:30.520]   than what we saw over the past few years.
[00:40:30.520 --> 00:40:32.760]   But the question really is,
[00:40:32.760 --> 00:40:35.400]   what does this all mean for the future of growth,
[00:40:35.400 --> 00:40:38.440]   for the future of profitability of these businesses?
[00:40:38.440 --> 00:40:40.640]   And can you plausibly see,
[00:40:40.640 --> 00:40:42.840]   is the core business gonna be attacked
[00:40:42.840 --> 00:40:45.320]   or do you see use cases where AI
[00:40:45.320 --> 00:40:49.400]   is actually going to be an accelerant to the business?
[00:40:49.400 --> 00:40:50.600]   Let's take those one at a time.
[00:40:50.600 --> 00:40:55.600]   So I would make the argument that the pressure,
[00:40:55.600 --> 00:41:01.080]   and I say this without judging it as positive or negative,
[00:41:01.080 --> 00:41:05.960]   the pressure to be completely focused on AI
[00:41:05.960 --> 00:41:08.640]   at the CEO level and the CIO level
[00:41:08.640 --> 00:41:12.000]   is so high right now, from everywhere,
[00:41:12.000 --> 00:41:13.880]   picking up the Wall Street Journal and reading it,
[00:41:13.880 --> 00:41:17.120]   watching CNBC, listening to us, whatever,
[00:41:17.120 --> 00:41:20.600]   that they have to spend or they feel they have to spend.
[00:41:20.600 --> 00:41:25.600]   And we'll post a link to the CIO survey
[00:41:25.600 --> 00:41:28.120]   that Battery Ventures published.
[00:41:28.120 --> 00:41:32.760]   But what you see is, I think 8% of CIOs
[00:41:32.760 --> 00:41:35.200]   have a budget increase over 10%.
[00:41:35.200 --> 00:41:37.200]   So 92% don't.
[00:41:37.200 --> 00:41:40.520]   So think near fixed budget.
[00:41:40.520 --> 00:41:43.600]   But 85% of them say they're aggressively increasing
[00:41:43.600 --> 00:41:44.600]   their spend on AI.
[00:41:44.600 --> 00:41:45.440]   - Right.
[00:41:45.440 --> 00:41:49.440]   By definition, it's gotta come out of something.
[00:41:49.440 --> 00:41:51.040]   - It's gotta come from something, right?
[00:41:51.040 --> 00:41:55.520]   And so I think we're at a point where if you're not AI,
[00:41:55.520 --> 00:42:00.120]   you're budget's somewhat at risk in selling into a CIO.
[00:42:00.120 --> 00:42:04.040]   And by the way, one category that almost never gets reduced
[00:42:04.040 --> 00:42:05.520]   is security spend.
[00:42:05.520 --> 00:42:10.520]   So if security spend's not going down and AI's going up,
[00:42:10.520 --> 00:42:16.400]   it's even, you're more, if you're not security or not AI,
[00:42:16.400 --> 00:42:17.960]   I think you're even more at risk
[00:42:17.960 --> 00:42:21.520]   of having trouble with expansion dollars.
[00:42:21.520 --> 00:42:24.240]   - No, there's no doubt about it.
[00:42:24.240 --> 00:42:25.880]   That's what we've seen.
[00:42:25.880 --> 00:42:28.640]   That's why I think you see some of this course slowing.
[00:42:28.640 --> 00:42:30.680]   Then one thing you didn't point out
[00:42:30.680 --> 00:42:34.160]   is when people have questions about the future,
[00:42:34.160 --> 00:42:35.960]   which they do around AI.
[00:42:35.960 --> 00:42:38.400]   So let's say they're spending a bunch of money on Workday,
[00:42:38.400 --> 00:42:40.760]   spending a bunch of money on Salesforce,
[00:42:40.760 --> 00:42:43.160]   spending a bunch of money on Snowflake or Databricks
[00:42:43.160 --> 00:42:44.480]   or you name it.
[00:42:44.480 --> 00:42:47.720]   And now they go in to present their case for this year.
[00:42:47.720 --> 00:42:49.880]   And the first question that's gonna get asked to them
[00:42:49.880 --> 00:42:52.200]   is, well, how are these guys doing with AI?
[00:42:52.200 --> 00:42:53.680]   What are they doing with AI?
[00:42:53.680 --> 00:42:55.960]   Is this the multi-year bet we wanna make?
[00:42:55.960 --> 00:42:57.360]   Or should we be betting on Google?
[00:42:57.360 --> 00:42:59.640]   Or should we be betting on Microsoft Azure?
[00:42:59.640 --> 00:43:00.840]   It just freezes.
[00:43:00.840 --> 00:43:03.080]   It says, go back, do more analysis,
[00:43:03.080 --> 00:43:04.400]   and then come back to me.
[00:43:04.400 --> 00:43:06.920]   And I think that's probably the number one thing
[00:43:06.920 --> 00:43:08.120]   you're seeing here, Bill.
[00:43:08.120 --> 00:43:09.760]   Rather than budget pressures,
[00:43:09.760 --> 00:43:11.400]   what I really think you're seeing
[00:43:11.400 --> 00:43:15.320]   is the slowing down and the elongation of the big commits
[00:43:15.320 --> 00:43:17.480]   because people really need to make sure
[00:43:17.480 --> 00:43:19.680]   that they're betting on the future, not on the past.
[00:43:19.680 --> 00:43:24.680]   - Well, and that becomes especially true in two areas.
[00:43:24.680 --> 00:43:31.360]   One is any area where LLMs are proving to be effective.
[00:43:31.360 --> 00:43:33.520]   And so in the enterprise,
[00:43:33.520 --> 00:43:37.680]   customer support is the one everyone's talking about, right?
[00:43:37.680 --> 00:43:41.040]   So if you sell a system in that space,
[00:43:41.040 --> 00:43:43.760]   and it's gonna cause this freezing
[00:43:43.760 --> 00:43:45.640]   you're talking about writ large,
[00:43:45.640 --> 00:43:48.680]   because this is the area where enterprises
[00:43:48.680 --> 00:43:50.320]   are experimenting the most.
[00:43:50.320 --> 00:43:52.000]   It's where there's the most number
[00:43:52.000 --> 00:43:56.040]   of application-based AI startups.
[00:43:56.040 --> 00:43:57.600]   And it's the one where you're getting
[00:43:57.600 --> 00:44:00.400]   the most reinforcement in the public discourse
[00:44:00.400 --> 00:44:01.400]   about success.
[00:44:01.400 --> 00:44:03.000]   You're hearing people,
[00:44:03.000 --> 00:44:04.520]   I don't know if the clarinet thing's real
[00:44:04.520 --> 00:44:07.240]   where you fire 70% of your workers,
[00:44:07.240 --> 00:44:09.240]   but there's plenty of people that echo something
[00:44:09.240 --> 00:44:12.720]   similar to what you heard about copilot for programmers,
[00:44:12.720 --> 00:44:16.520]   20% gains of efficiency for your workforce,
[00:44:16.520 --> 00:44:17.600]   that kind of thing.
[00:44:17.600 --> 00:44:20.760]   And so those areas are especially true
[00:44:20.760 --> 00:44:21.600]   in what you're talking about.
[00:44:21.600 --> 00:44:25.960]   Another area that you just mentioned in HR,
[00:44:25.960 --> 00:44:30.320]   there are a lot of applications in the hiring process.
[00:44:30.320 --> 00:44:33.040]   I've seen a lot of AI apps in that area.
[00:44:33.040 --> 00:44:35.400]   And so you're gonna freeze,
[00:44:35.400 --> 00:44:37.080]   you're naturally gonna freeze and say,
[00:44:37.080 --> 00:44:40.240]   "Oh shit, I gotta figure out what this is gonna mean."
[00:44:40.240 --> 00:44:42.160]   So there are repercussions.
[00:44:42.160 --> 00:44:44.920]   Now, there's a question like that kind of thing
[00:44:44.920 --> 00:44:45.840]   can go too far.
[00:44:45.840 --> 00:44:48.960]   Like in the example of scooters and Uber,
[00:44:48.960 --> 00:44:52.160]   where everyone thinks that it's gonna be disruptive
[00:44:52.160 --> 00:44:53.080]   and it won't.
[00:44:53.080 --> 00:44:55.200]   And these are hard things to figure out.
[00:44:55.200 --> 00:44:57.520]   The second category where this can happen
[00:44:57.520 --> 00:44:59.760]   is just where LLMs are really good.
[00:44:59.760 --> 00:45:04.760]   UiPath was a company that took a particularly big fall.
[00:45:04.760 --> 00:45:07.960]   And if you study the different uses of RPA,
[00:45:07.960 --> 00:45:09.400]   some of them are form-based,
[00:45:09.400 --> 00:45:11.640]   some of them are ingesting invoices,
[00:45:11.640 --> 00:45:15.000]   some of them, some of those automation processes
[00:45:15.000 --> 00:45:18.120]   are things that LLMs are very, very good at.
[00:45:18.120 --> 00:45:18.960]   Right.
[00:45:18.960 --> 00:45:21.240]   And then that puts you more in the crosshair, right?
[00:45:21.240 --> 00:45:23.280]   Yeah, I think you nailed it.
[00:45:23.280 --> 00:45:26.000]   And listen, lots of people were short UiPath,
[00:45:26.000 --> 00:45:28.280]   lots of people are short these call center
[00:45:28.280 --> 00:45:30.240]   software businesses for all the reason
[00:45:30.240 --> 00:45:31.240]   that you're talking about.
[00:45:31.240 --> 00:45:34.200]   I think our good friend, Aaron Levy,
[00:45:34.200 --> 00:45:38.400]   laid this out pretty well in this tweet here,
[00:45:38.400 --> 00:45:40.760]   where he talks about these three major axes,
[00:45:40.760 --> 00:45:45.040]   the things that are most likely to be replaced.
[00:45:45.040 --> 00:45:47.400]   I mean, it's similar to what you just talked about.
[00:45:47.400 --> 00:45:50.240]   What's the level of automation being applied to the work?
[00:45:50.240 --> 00:45:52.560]   What's the cost of the work that's being automated?
[00:45:52.560 --> 00:45:54.480]   What's the volume or frequency of the work
[00:45:54.480 --> 00:45:55.840]   that's being automated?
[00:45:55.840 --> 00:45:59.000]   So like in the case of UiPath, to your point,
[00:45:59.000 --> 00:46:01.960]   here's a business, think about the setup here, Bill.
[00:46:01.960 --> 00:46:04.320]   It grew only 6% in the quarter.
[00:46:04.320 --> 00:46:06.520]   Most of its free cash flow gets eaten up
[00:46:06.520 --> 00:46:08.120]   by stock-based compensation.
[00:46:08.120 --> 00:46:11.400]   So one might argue that it's not even real free cash flow
[00:46:11.400 --> 00:46:13.080]   on a per share basis.
[00:46:13.080 --> 00:46:15.600]   And it's right in the center of the bullseye
[00:46:15.600 --> 00:46:17.880]   how AI can automate this stuff, which
[00:46:17.880 --> 00:46:20.560]   at a minimum causes a lot of churn, a lot of delay,
[00:46:20.560 --> 00:46:22.560]   and a lot of pricing pressure.
[00:46:22.560 --> 00:46:25.920]   So I think the market's reaction to some of these things
[00:46:25.920 --> 00:46:27.640]   is pretty rational.
[00:46:27.640 --> 00:46:29.960]   Now, take something that's, I think,
[00:46:29.960 --> 00:46:32.240]   a hotter topic among a lot of our friends, which
[00:46:32.240 --> 00:46:33.560]   would be Salesforce.
[00:46:33.560 --> 00:46:37.280]   An incredible founder, CEO, and Mark Benioff.
[00:46:37.280 --> 00:46:40.400]   Mark has been early to get on trends,
[00:46:40.400 --> 00:46:43.120]   whether they're social, whether they're mobile, et cetera.
[00:46:43.120 --> 00:46:45.880]   And he's been all over AI.
[00:46:45.880 --> 00:46:47.640]   But you have a debate.
[00:46:47.640 --> 00:46:51.720]   On the one hand, you have folks like Chamath
[00:46:51.720 --> 00:46:57.080]   saying his company 80/90 can really disrupt them
[00:46:57.080 --> 00:47:02.000]   because you can get 90% of the benefits for 80% of the cost.
[00:47:02.000 --> 00:47:05.000]   Aaron Levy would argue, no way, you can't do that.
[00:47:05.000 --> 00:47:07.680]   People don't want a constellation of services.
[00:47:07.680 --> 00:47:09.480]   All these things exist because this
[00:47:09.480 --> 00:47:13.480]   is what Salesforce customers are demanding of them.
[00:47:13.480 --> 00:47:16.720]   But I think part of the reason Salesforce has recovered well
[00:47:16.720 --> 00:47:20.840]   here, Bill, is this is a company that has gotten fit.
[00:47:20.840 --> 00:47:23.400]   This is a company that is running efficient.
[00:47:23.400 --> 00:47:27.560]   So out of their $13 billion of free cash flow, they convert--
[00:47:27.560 --> 00:47:30.400]   I think they have $2 or $3 billion in SBC.
[00:47:30.400 --> 00:47:33.880]   And so they convert over $10 billion in free cash flow.
[00:47:33.880 --> 00:47:35.800]   So if you look at it for a market leader,
[00:47:35.800 --> 00:47:38.720]   it's not that expensive, even though its growth rate
[00:47:38.720 --> 00:47:40.880]   has slowed way down.
[00:47:40.880 --> 00:47:44.240]   And then I think, listen, you've asked me
[00:47:44.240 --> 00:47:46.520]   a fair bit about Snowflake.
[00:47:46.520 --> 00:47:51.240]   And folks, because we were early investors in that company,
[00:47:51.240 --> 00:47:53.440]   I get questions about Snowflake and Databricks
[00:47:53.440 --> 00:47:55.720]   and these data platforms all the time.
[00:47:55.720 --> 00:47:57.680]   Like, what does it mean for the database?
[00:47:57.680 --> 00:47:59.880]   What does it mean for these data platforms?
[00:47:59.880 --> 00:48:03.880]   So maybe just a second on that.
[00:48:03.880 --> 00:48:07.320]   I think one of the things people question when--
[00:48:07.320 --> 00:48:12.560]   in the case of Snowflake, growth decelerates to 26%.
[00:48:12.560 --> 00:48:16.160]   People are like, OK, yes, the multiple on free cash flow
[00:48:16.160 --> 00:48:17.040]   has come down a lot.
[00:48:17.040 --> 00:48:20.920]   But they still have a lot of SBC.
[00:48:20.920 --> 00:48:23.360]   All that free cash flow gets eaten up by SBC.
[00:48:23.360 --> 00:48:27.120]   So a lot more scrutiny gets put on those free cash flow.
[00:48:27.120 --> 00:48:29.480]   And I think they're going to have to demonstrate
[00:48:29.480 --> 00:48:33.000]   how the growth rate will remain higher for longer
[00:48:33.000 --> 00:48:35.960]   and how they can get more fit around SBC
[00:48:35.960 --> 00:48:40.600]   if they want to maintain or re-expand their multiple.
[00:48:40.600 --> 00:48:44.160]   But when I evaluate them or Databricks
[00:48:44.160 --> 00:48:48.560]   across the three axes that Aaron laid out,
[00:48:48.560 --> 00:48:51.720]   they have a lot of things that they can expand
[00:48:51.720 --> 00:48:54.000]   and are upsides, I think, from AI.
[00:48:54.000 --> 00:48:57.240]   First, I just think the core business of data--
[00:48:57.240 --> 00:48:59.600]   data is a primitive to AI.
[00:48:59.600 --> 00:49:00.960]   You need structured data.
[00:49:00.960 --> 00:49:02.560]   You need unstructured data.
[00:49:02.560 --> 00:49:05.480]   I happened to be at their event last week.
[00:49:05.480 --> 00:49:07.560]   I see the head of data from ExxonMobil
[00:49:07.560 --> 00:49:12.600]   talking about how they're going all in on data engineering
[00:49:12.600 --> 00:49:13.960]   and the data platform there.
[00:49:13.960 --> 00:49:16.440]   And there's a lot more workloads that they're
[00:49:16.440 --> 00:49:17.440]   going to bring to bear.
[00:49:17.440 --> 00:49:21.440]   So I think just the stickiness of enterprise relationships
[00:49:21.440 --> 00:49:24.600]   outside of Silicon Valley, it's deep and it's broad.
[00:49:24.600 --> 00:49:27.240]   And these companies have made long-term commitments
[00:49:27.240 --> 00:49:28.160]   to these platforms.
[00:49:28.160 --> 00:49:30.680]   They're not just going to shift them in a second,
[00:49:30.680 --> 00:49:33.240]   though they may slow down expansions
[00:49:33.240 --> 00:49:34.800]   to the point we just made.
[00:49:34.800 --> 00:49:37.320]   But what are a couple of the easy places
[00:49:37.320 --> 00:49:39.320]   I think that Databricks and Snowflake
[00:49:39.320 --> 00:49:41.000]   can go to automate functions?
[00:49:41.000 --> 00:49:43.240]   One would be transforming data.
[00:49:43.240 --> 00:49:46.280]   So if you have 100 different sources of disparate data,
[00:49:46.280 --> 00:49:49.000]   just think you've got to dedupe that data.
[00:49:49.000 --> 00:49:50.280]   You've got to cleanse that data.
[00:49:50.280 --> 00:49:52.440]   All the things that there used to be a lot of manual
[00:49:52.440 --> 00:49:55.040]   interventions, a lot of workloads in order to do,
[00:49:55.040 --> 00:49:57.560]   I think AI can do that particularly well.
[00:49:57.560 --> 00:50:00.960]   AI infrastructure, training models, building chatbots,
[00:50:00.960 --> 00:50:01.960]   fine tuning.
[00:50:01.960 --> 00:50:03.840]   Again, I think that they can build--
[00:50:03.840 --> 00:50:06.640]   all those guys are building the AI infrastructure to do that.
[00:50:06.640 --> 00:50:08.920]   And then just basic thing, like how do we
[00:50:08.920 --> 00:50:10.920]   extract signal from the data?
[00:50:10.920 --> 00:50:14.280]   So text to SQL, right?
[00:50:14.280 --> 00:50:18.160]   Being allow-- allow somebody to talk to the data
[00:50:18.160 --> 00:50:23.280]   and spin up UIs that really used to be big businesses
[00:50:23.280 --> 00:50:25.680]   unto themselves, business intelligence companies.
[00:50:25.680 --> 00:50:28.680]   So I think that there is an opportunity for that.
[00:50:28.680 --> 00:50:32.320]   And in fact, there was this video,
[00:50:32.320 --> 00:50:34.000]   I think, that one of my analysts posted.
[00:50:34.000 --> 00:50:37.360]   I saw it posted by a few people on Twitter, which is Jensen.
[00:50:37.360 --> 00:50:38.840]   And we'll spin it up here.
[00:50:38.840 --> 00:50:42.240]   So that Snowflake is no longer just a data company,
[00:50:42.240 --> 00:50:46.760]   but they're also a computing company, running Cortex AI.
[00:50:46.760 --> 00:50:48.400]   Big opportunity for Snowflake.
[00:50:48.400 --> 00:50:51.000]   If you guys are watching, if you guys are following Snowflake,
[00:50:51.000 --> 00:50:55.400]   Snowflake just added a new business to themselves.
[00:50:55.400 --> 00:51:00.560]   Not just computing, not just data processing, but computing.
[00:51:00.560 --> 00:51:02.720]   Accelerated computing.
[00:51:02.720 --> 00:51:05.720]   Jensen talking about Snowflake over in Taipei
[00:51:05.720 --> 00:51:08.920]   this week in the context of Cortex AI.
[00:51:08.920 --> 00:51:11.400]   And he said, listen, this is a huge new business
[00:51:11.400 --> 00:51:14.320]   that we've done in partnership with them that is totally
[00:51:14.320 --> 00:51:16.120]   upside to their core business.
[00:51:16.120 --> 00:51:18.040]   Now, whether or not that, in fact, shows up
[00:51:18.040 --> 00:51:21.120]   and the revenue shows up, that's at the heart of the debate
[00:51:21.120 --> 00:51:24.600]   that everybody's having about every one of these platforms
[00:51:24.600 --> 00:51:25.480]   today.
[00:51:25.480 --> 00:51:26.560]   It's interesting.
[00:51:26.560 --> 00:51:29.640]   And ironically, it gets at one of the same things
[00:51:29.640 --> 00:51:32.800]   we've talked about on the consumer side with memory.
[00:51:32.800 --> 00:51:38.920]   And today, the LLM, because it's so text heavy in how it works,
[00:51:38.920 --> 00:51:40.440]   how it was built--
[00:51:40.440 --> 00:51:45.040]   I mean, text is the cornerstone to it, and language.
[00:51:45.040 --> 00:51:50.400]   And as a result, when people use the word hallucination
[00:51:50.400 --> 00:51:53.000]   or whatever, they're talking about errors.
[00:51:53.000 --> 00:51:56.200]   And you can't really rely on a system
[00:51:56.200 --> 00:51:59.080]   to be numeric if it hallucinates.
[00:51:59.080 --> 00:52:04.520]   And so you're not going to run your accounting on an LLM
[00:52:04.520 --> 00:52:05.440]   today.
[00:52:05.440 --> 00:52:08.720]   And I think the interesting--
[00:52:08.720 --> 00:52:10.480]   so today, in the enterprise, you're
[00:52:10.480 --> 00:52:13.320]   seeing a lot of-- we already talked about customer support.
[00:52:13.320 --> 00:52:15.000]   In the database area, we're talking
[00:52:15.000 --> 00:52:19.680]   about having basically language translate
[00:52:19.680 --> 00:52:22.600]   into very complex queries and have
[00:52:22.600 --> 00:52:26.800]   the LLM live between the questioner and the data source
[00:52:26.800 --> 00:52:33.880]   and therefore provide value by being a UI of sorts for input
[00:52:33.880 --> 00:52:34.840]   and output.
[00:52:34.840 --> 00:52:36.360]   Let me give you the example of this.
[00:52:36.360 --> 00:52:39.120]   I mean, how many times have you wished
[00:52:39.120 --> 00:52:43.280]   that a CEO running a business, they
[00:52:43.280 --> 00:52:45.360]   don't want to go to their data analyst
[00:52:45.360 --> 00:52:46.520]   to try to spin something up.
[00:52:46.520 --> 00:52:47.360]   They have a question.
[00:52:47.360 --> 00:52:48.900]   They just want to ask their computer.
[00:52:48.900 --> 00:52:50.960]   Ask Google, and it gives you the freaking answer.
[00:52:50.960 --> 00:52:52.480]   Yes, yes, yes, totally.
[00:52:52.480 --> 00:52:53.200]   I totally get it.
[00:52:53.200 --> 00:52:57.200]   And that's what's happening, and that's what people are doing.
[00:52:57.200 --> 00:52:58.880]   There's a company called Glean that
[00:52:58.880 --> 00:53:01.840]   has a bit of momentum that props up
[00:53:01.840 --> 00:53:06.480]   kind of a universal corporate AI query
[00:53:06.480 --> 00:53:09.200]   against a bunch of different data sources in your business.
[00:53:09.200 --> 00:53:11.960]   And there's authentication and security risk
[00:53:11.960 --> 00:53:15.240]   and all this stuff, and they help you manage all that.
[00:53:15.240 --> 00:53:19.120]   But I think the long-term question about how disruptive
[00:53:19.120 --> 00:53:21.800]   this will be for the app companies
[00:53:21.800 --> 00:53:25.160]   comes down to whether any of the foundational model
[00:53:25.160 --> 00:53:28.280]   companies eventually build in a data store
[00:53:28.280 --> 00:53:32.960]   that is easy to query and is holistic and not lossy.
[00:53:32.960 --> 00:53:35.360]   And that hasn't happened to date,
[00:53:35.360 --> 00:53:37.800]   but I bet you it's something they're thinking about
[00:53:37.800 --> 00:53:41.160]   from a multimodal standpoint, such that a developer--
[00:53:41.160 --> 00:53:44.400]   today, any developer using a foundational model
[00:53:44.400 --> 00:53:47.000]   is using a separate data store, right?
[00:53:47.000 --> 00:53:49.240]   And they're using it for UI.
[00:53:49.240 --> 00:53:53.560]   They're using it potentially for data cleansing or anything
[00:53:53.560 --> 00:53:55.720]   like that, but they're not storing
[00:53:55.720 --> 00:53:57.600]   numeric data inside of it.
[00:53:57.600 --> 00:53:58.920]   So I think that would be something
[00:53:58.920 --> 00:54:01.240]   to watch over a very long time frame
[00:54:01.240 --> 00:54:06.440]   to see if anyone tries to build that into the API, if you will,
[00:54:06.440 --> 00:54:08.520]   on how you use one of these models.
[00:54:08.520 --> 00:54:12.880]   And this really, Bill, is, I think,
[00:54:12.880 --> 00:54:16.760]   what happens at the start of these phase shifts, right?
[00:54:16.760 --> 00:54:19.680]   It is the fog of war, and we get these headlines--
[00:54:19.680 --> 00:54:21.240]   the end of software.
[00:54:21.240 --> 00:54:22.880]   Software is dead.
[00:54:22.880 --> 00:54:28.520]   I will tell you, in technology, you probably
[00:54:28.520 --> 00:54:31.200]   have better opportunities listening
[00:54:31.200 --> 00:54:33.840]   to the wise words of Warren Buffett, which
[00:54:33.840 --> 00:54:36.840]   is, you buy when there's blood in the streets,
[00:54:36.840 --> 00:54:39.720]   and you sell when there are trumpets in the air.
[00:54:39.720 --> 00:54:44.600]   And trumpets were the air in software during 2021, right?
[00:54:44.600 --> 00:54:46.920]   Because people said, these are annuities.
[00:54:46.920 --> 00:54:48.640]   The discount rate should be really low.
[00:54:48.640 --> 00:54:49.880]   They're going to last forever.
[00:54:49.880 --> 00:54:50.920]   They're going to grow to--
[00:54:50.920 --> 00:54:52.840]   They got comfortable with 22x revenue multiples.
[00:54:52.840 --> 00:54:54.400]   Correct, correct.
[00:54:54.400 --> 00:54:56.800]   And now, in a very short period of time,
[00:54:56.800 --> 00:54:58.480]   you had a disruptive force.
[00:54:58.480 --> 00:55:00.120]   We tend to overshoot.
[00:55:00.120 --> 00:55:02.920]   And I suspect that these headlines, the end of software,
[00:55:02.920 --> 00:55:07.520]   the death of software, in, I would argue, less than 24
[00:55:07.520 --> 00:55:09.480]   months, will appear to be silly.
[00:55:09.480 --> 00:55:12.520]   I think there are some really interesting investments
[00:55:12.520 --> 00:55:15.840]   to be made, particularly in the public markets,
[00:55:15.840 --> 00:55:17.880]   because a lot of these incumbents
[00:55:17.880 --> 00:55:19.720]   have incumbent advantages.
[00:55:19.720 --> 00:55:23.560]   And they're going to accelerate when all of this inference
[00:55:23.560 --> 00:55:26.440]   starts coming online in Q3 and Q4.
[00:55:26.440 --> 00:55:29.240]   And remember, they had to invest ahead
[00:55:29.240 --> 00:55:30.800]   of the revenues coming online.
[00:55:30.800 --> 00:55:33.520]   You have to buy that capability and build that capability
[00:55:33.520 --> 00:55:35.400]   and hire those teams now.
[00:55:35.400 --> 00:55:37.440]   My suspicion is you'll start seeing
[00:55:37.440 --> 00:55:42.480]   some of this acceleration late in Q3, Q4 of this year,
[00:55:42.480 --> 00:55:44.080]   heading into next year.
[00:55:44.080 --> 00:55:46.640]   And when that happens, people will say, oh, no.
[00:55:46.640 --> 00:55:48.280]   Software is not dead.
[00:55:48.280 --> 00:55:50.240]   It, in fact, is an accelerant.
[00:55:50.240 --> 00:55:54.080]   But it's not going to be equally good for all companies.
[00:55:54.080 --> 00:55:56.720]   I do think there are companies like UiPath,
[00:55:56.720 --> 00:55:59.480]   where the fundamental value proposition is challenged.
[00:55:59.480 --> 00:56:01.080]   They have to reinvent the model.
[00:56:01.080 --> 00:56:02.960]   And I think there are other businesses that's
[00:56:02.960 --> 00:56:04.960]   going to be an accelerant to the core business.
[00:56:04.960 --> 00:56:10.600]   I will take the other side of this, what you just said,
[00:56:10.600 --> 00:56:13.480]   to a certain extent, which is I don't think you can
[00:56:13.480 --> 00:56:18.600]   simultaneously have people get re-optimistic about software
[00:56:18.600 --> 00:56:22.040]   and the hype cycle of AI to continue at the pace it's been
[00:56:22.040 --> 00:56:24.520]   on, because I think they're at odds with one another.
[00:56:24.520 --> 00:56:30.320]   Because the most glorious statements about what AI is
[00:56:30.320 --> 00:56:33.680]   and can do say it replaces everything.
[00:56:33.680 --> 00:56:37.320]   And as long as that's being trumpeted and believed
[00:56:37.320 --> 00:56:43.400]   by enough people, I think the onus is on--
[00:56:43.400 --> 00:56:46.720]   everything moves from half full to half empty for anyone
[00:56:46.720 --> 00:56:51.240]   that's not holistically AI.
[00:56:51.240 --> 00:56:52.880]   Yeah, we shall see.
[00:56:52.880 --> 00:56:53.960]   That's what makes a market.
[00:56:53.960 --> 00:56:56.160]   That's what makes a podcast.
[00:56:56.160 --> 00:57:00.480]   That's what makes the basis for urinized debates
[00:57:00.480 --> 00:57:01.800]   over the last 20 years.
[00:57:01.800 --> 00:57:04.600]   I mean, if it wasn't AI disrupting something,
[00:57:04.600 --> 00:57:07.320]   it was the mobile phone disrupting desktop search
[00:57:07.320 --> 00:57:10.320]   and whether we could monetize that.
[00:57:10.320 --> 00:57:14.200]   It was the internet disrupting what came before it.
[00:57:14.200 --> 00:57:17.320]   By the way, two quick things before we leave.
[00:57:17.320 --> 00:57:19.480]   One, I look forward to tomorrow.
[00:57:19.480 --> 00:57:20.920]   It's cool you're going to be there.
[00:57:20.920 --> 00:57:22.920]   So you can let us know exactly how it goes.
[00:57:22.920 --> 00:57:24.880]   I think that'll be really interesting.
[00:57:24.880 --> 00:57:30.360]   And then I was really kind of positively moved by this.
[00:57:30.360 --> 00:57:33.720]   We can put it in the thing, but Google, Jim and I
[00:57:33.720 --> 00:57:39.280]   did an ad with Mark Cuban highlighting their enterprise
[00:57:39.280 --> 00:57:42.320]   apps, Docs, Sheets.
[00:57:42.320 --> 00:57:48.440]   And I was compelled.
[00:57:48.440 --> 00:57:51.320]   It's an area where they have not invested a lot.
[00:57:51.320 --> 00:57:53.200]   They've always had Sheets and Docs.
[00:57:53.200 --> 00:57:57.080]   And a lot of the startups in our community live on that stuff.
[00:57:57.080 --> 00:58:00.560]   But it hasn't really competed with the Microsoft stack.
[00:58:00.560 --> 00:58:03.040]   And with Satya's comeback, everyone's
[00:58:03.040 --> 00:58:07.040]   been super excited about what this means for Microsoft.
[00:58:07.040 --> 00:58:10.360]   And if they play their cards right at Google
[00:58:10.360 --> 00:58:13.920]   and tie this into Android even, it
[00:58:13.920 --> 00:58:15.240]   could be a huge win for them.
[00:58:15.240 --> 00:58:16.800]   It's fun to see this thing.
[00:58:16.800 --> 00:58:19.320]   I recommend people check it out.
[00:58:19.320 --> 00:58:23.160]   It's a-- you've got to pay for the price of admission here.
[00:58:23.160 --> 00:58:25.720]   This is an incredible time to be alive.
[00:58:25.720 --> 00:58:29.120]   All this innovation, I certainly know coming out the other end,
[00:58:29.120 --> 00:58:32.240]   it's going to yield a lot of prosperity.
[00:58:32.240 --> 00:58:35.240]   And so who the particular winners or losers are,
[00:58:35.240 --> 00:58:37.080]   what the timescale is, that's what
[00:58:37.080 --> 00:58:39.000]   we get paid to figure out.
[00:58:39.000 --> 00:58:42.240]   But I have no doubt that this is good for all of us.
[00:58:42.240 --> 00:58:43.240]   Bill, I'll see you soon.
[00:58:43.240 --> 00:58:44.040]   Take care, Michael.
[00:58:44.040 --> 00:58:52.440]   [MUSIC PLAYING]
[00:58:52.440 --> 00:58:55.240]   As a reminder to everybody, just our opinions, not
[00:58:55.240 --> 00:58:57.280]   investment advice.

