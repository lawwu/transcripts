
[00:00:00.000 --> 00:00:03.760]   There was a paper published at the Super Compute Show.
[00:00:03.760 --> 00:00:05.840]   It was published by Argonne National Labs,
[00:00:05.840 --> 00:00:10.800]   and it compared us to a 2,000 node A100 cluster
[00:00:10.800 --> 00:00:11.720]   called Polaris.
[00:00:11.720 --> 00:00:13.600]   And the problem was really interesting.
[00:00:13.600 --> 00:00:18.120]   It was to use a large NLP network, a GPTJ-style network,
[00:00:18.120 --> 00:00:21.360]   to predict mutations in the COVID virus.
[00:00:21.360 --> 00:00:22.280]   How cool is that?
[00:00:22.280 --> 00:00:25.440]   What they did is they put the entire genome,
[00:00:25.440 --> 00:00:27.880]   30,000 base pairs, and when encoded,
[00:00:27.880 --> 00:00:31.240]   it was a sequence length of 10,240
[00:00:31.240 --> 00:00:33.960]   in the attention window, in the long sequence window,
[00:00:33.960 --> 00:00:35.840]   the 250 million parameter version.
[00:00:35.840 --> 00:00:40.320]   The 2,000 node cluster couldn't do big parameter size
[00:00:40.320 --> 00:00:42.080]   and long attention sequences.
[00:00:42.080 --> 00:00:46.440]   And we ran it at 2.5 billion and at 25 billion.
[00:00:46.440 --> 00:00:49.520]   Now, this paper won the most prestigious award
[00:00:49.520 --> 00:00:52.680]   in academic computing, the Gordon Bell Prize.
[00:00:52.680 --> 00:00:55.320]   So there was an example where four, eight,
[00:00:55.320 --> 00:00:57.640]   and 16 of our machines could do things
[00:00:57.640 --> 00:00:59.840]   that thousands of GPUs couldn't do.

