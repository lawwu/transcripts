
[00:00:00.000 --> 00:00:02.720]   I really want to do some tutorials on text classification.
[00:00:02.720 --> 00:00:04.520]   It's the thing that students ask about the most.
[00:00:04.520 --> 00:00:10.040]   It's an incredibly useful application of machine learning and deep learning.
[00:00:10.040 --> 00:00:14.480]   But before I get into neural networks applied to text classification,
[00:00:14.480 --> 00:00:17.360]   I really want to start with the more
[00:00:17.360 --> 00:00:20.720]   old-fashioned methods because they're incredibly useful.
[00:00:20.720 --> 00:00:24.620]   If you have less than hundreds of thousands of records of text,
[00:00:24.620 --> 00:00:29.440]   you almost always actually want to be using simpler methods than LSTMs,
[00:00:29.440 --> 00:00:30.760]   and convolutional neural networks,
[00:00:30.760 --> 00:00:33.920]   and the more complicated stuff that people think of these days.
[00:00:33.920 --> 00:00:35.800]   So in this video,
[00:00:35.800 --> 00:00:40.640]   we're going to start with very practical simple methods applied to text classification,
[00:00:40.640 --> 00:00:43.600]   and it'll be a great foundation for when we do a class on
[00:00:43.600 --> 00:00:46.920]   applying LSTMs and CNNs to text classification.
[00:00:46.920 --> 00:00:50.540]   Let's walk through how you'd build a text classifier on a custom dataset.
[00:00:50.540 --> 00:00:53.700]   So if you haven't taken any of my classes before,
[00:00:53.700 --> 00:01:01.740]   then you need to check out my repository at github.com/lucas/ml-class.
[00:01:01.740 --> 00:01:05.780]   Then go into the directory video/text-classifier.
[00:01:05.780 --> 00:01:07.980]   So here's the real-world challenge for today,
[00:01:07.980 --> 00:01:10.980]   and it's a problem that I see all the time that companies want to do.
[00:01:10.980 --> 00:01:16.540]   We want to take tweets about a brand and classify them as positive or negative.
[00:01:16.540 --> 00:01:19.620]   Actually, I have some real-world data here that was
[00:01:19.620 --> 00:01:22.880]   collected by my company Figure Eight about Apple products.
[00:01:22.880 --> 00:01:25.980]   So we have tweets from that conference South by Southwest,
[00:01:25.980 --> 00:01:30.380]   and we have people saying positive things about Apple products and negative things.
[00:01:30.380 --> 00:01:33.260]   From that, we want to build a classifier that can look at
[00:01:33.260 --> 00:01:36.740]   more tweets about Apple products and say if they're positive or negative.
[00:01:36.740 --> 00:01:42.460]   So I have a file with a few thousand tweets of labeled data called tweets.csv.
[00:01:42.460 --> 00:01:44.620]   You can open this thing up in a text editor,
[00:01:44.620 --> 00:01:46.500]   Excel, or any other program.
[00:01:46.500 --> 00:01:48.800]   You can see that there are three columns.
[00:01:48.800 --> 00:01:52.700]   The first column is the text of the tweet itself,
[00:01:52.700 --> 00:01:56.740]   the second column is called emotion and tweet is directed at,
[00:01:56.740 --> 00:02:00.180]   and that's actually which product the tweet is talking about,
[00:02:00.180 --> 00:02:03.240]   and then the third column confusingly titled,
[00:02:03.240 --> 00:02:05.100]   is there an emotion directed at a brand or
[00:02:05.100 --> 00:02:08.860]   product is actually the sentiment of the tweet.
[00:02:08.860 --> 00:02:12.860]   We need to load this data into Python.
[00:02:12.860 --> 00:02:14.980]   So to check out how to do that,
[00:02:14.980 --> 00:02:18.060]   open up load-data.py.
[00:02:18.300 --> 00:02:24.100]   Here, lines 3 and 4 loads of incredibly useful machine learning libraries,
[00:02:24.100 --> 00:02:27.820]   or just numerical computing libraries called pandas and numpy.
[00:02:27.820 --> 00:02:35.220]   Then line 7 uses pandas to read the CSV file into what's called a data frame.
[00:02:35.220 --> 00:02:39.980]   You can think of a data frame as a two-dimensional array with named columns.
[00:02:39.980 --> 00:02:45.300]   Line 10 uses pandas to select a column from the data frame,
[00:02:45.300 --> 00:02:47.180]   and put that in a variable called target.
[00:02:47.180 --> 00:02:49.380]   This is actually the sentiment of the tweet.
[00:02:49.380 --> 00:02:53.980]   Line 13 takes the column that corresponds to the actual text of the tweet,
[00:02:53.980 --> 00:02:58.540]   and puts it into a variable called text.
[00:02:58.540 --> 00:03:02.340]   Line 15 prints out the length of the text,
[00:03:02.340 --> 00:03:04.660]   just to make sure we've loaded the right thing.
[00:03:04.660 --> 00:03:09.300]   Let's give that a try by running Python load-data.
[00:03:09.300 --> 00:03:15.520]   Sure enough, we see that we have 9,093 lines of data here.
[00:03:15.520 --> 00:03:18.100]   Now we have to do something called feature extraction.
[00:03:18.100 --> 00:03:19.940]   What is feature extraction?
[00:03:19.940 --> 00:03:21.700]   As we keep talking about,
[00:03:21.700 --> 00:03:25.780]   machine learning algorithms have a very simple and very constrained API.
[00:03:25.780 --> 00:03:28.260]   They take in a fixed length set of numbers.
[00:03:28.260 --> 00:03:32.260]   They generally don't take text, audio, or images as input.
[00:03:32.260 --> 00:03:37.180]   So we need to turn each one of these tweets into a fixed length set of numbers.
[00:03:37.180 --> 00:03:39.140]   There are many ways to do this,
[00:03:39.140 --> 00:03:43.780]   but a surprisingly powerful way to do it is something called bag of words.
[00:03:43.780 --> 00:03:46.120]   Now let's put this into practice.
[00:03:46.120 --> 00:03:49.560]   I open up feature-extraction-1.py,
[00:03:49.560 --> 00:03:53.480]   and I see that the first five lines of code are the same as my load data script,
[00:03:53.480 --> 00:03:55.020]   and just load in the data.
[00:03:55.020 --> 00:03:56.880]   Now, from scikit-learn,
[00:03:56.880 --> 00:03:59.640]   I import the class count vectorizer.
[00:03:59.640 --> 00:04:01.720]   Count because we're counting words,
[00:04:01.720 --> 00:04:03.640]   and vectorizer because in math,
[00:04:03.640 --> 00:04:06.680]   a fixed length array is also known as a vector.
[00:04:06.680 --> 00:04:09.720]   Line 13 initializes my vectorizer,
[00:04:09.720 --> 00:04:12.120]   and line 14 fits it to my text,
[00:04:12.120 --> 00:04:16.420]   which runs through all my tweets and sets up a column for each word.
[00:04:16.420 --> 00:04:21.580]   Now, let's just run this before we go any further to make sure it works.
[00:04:21.580 --> 00:04:26.020]   Sure enough, we get a strange error message.
[00:04:26.020 --> 00:04:28.980]   One of the really tough things about machine learning,
[00:04:28.980 --> 00:04:31.900]   and I keep talking about this because students are always confused by it,
[00:04:31.900 --> 00:04:35.220]   is the confusing and lack of error messages.
[00:04:35.220 --> 00:04:37.500]   Actually, scikit-learn is probably
[00:04:37.500 --> 00:04:41.380]   the friendliest machine learning library in terms of clear error messages,
[00:04:41.380 --> 00:04:44.260]   but it's such a low bar that with this error message,
[00:04:44.260 --> 00:04:46.700]   I even have trouble with knowing what's going on.
[00:04:46.700 --> 00:04:49.480]   So unlike every other machine learning tutorial,
[00:04:49.480 --> 00:04:50.760]   I want to talk about debugging,
[00:04:50.760 --> 00:04:52.820]   and I want to show you how I actually debug this.
[00:04:52.820 --> 00:04:54.060]   So I look at this,
[00:04:54.060 --> 00:04:56.500]   and I see that it's saying it's an invalid document,
[00:04:56.500 --> 00:05:00.580]   maybe it's a Unicode error or some kind of text encoding error.
[00:05:00.580 --> 00:05:05.020]   What I do is I see if it can load in a subset of my data.
[00:05:05.020 --> 00:05:08.860]   So I open back up feature extraction-1,
[00:05:08.900 --> 00:05:15.380]   and I tell my count vectorizer to maybe just fit the first three lines of text.
[00:05:15.380 --> 00:05:19.660]   Now, that actually works.
[00:05:19.660 --> 00:05:22.740]   So there must be something after the first three lines of text
[00:05:22.740 --> 00:05:26.860]   that's breaking my feature extraction.
[00:05:26.860 --> 00:05:32.140]   So maybe now I try it in the first 100 lines of text.
[00:05:32.140 --> 00:05:38.140]   This breaks. So there's something weird going on in
[00:05:38.140 --> 00:05:40.060]   the first 100 lines of text.
[00:05:40.060 --> 00:05:42.540]   I can either do binary search or I can open up
[00:05:42.540 --> 00:05:46.860]   my file in a program like Excel and see what's actually there.
[00:05:46.860 --> 00:05:55.220]   Now, there's a super suspicious line here,
[00:05:55.220 --> 00:05:57.500]   and that is a blank tweet.
[00:05:57.500 --> 00:06:00.540]   It turns out that this is the issue that we're dealing with.
[00:06:00.540 --> 00:06:05.940]   Scikit is actually throwing up on blank tweets as input.
[00:06:06.300 --> 00:06:09.420]   If you open up feature-extraction-2,
[00:06:09.420 --> 00:06:11.420]   you can see what I did to deal with this.
[00:06:11.420 --> 00:06:14.540]   So here in line 11,
[00:06:14.540 --> 00:06:16.900]   I set fixed text to be text,
[00:06:16.900 --> 00:06:21.900]   and then I use a pandas idiom to remove the values of text that are not null.
[00:06:21.900 --> 00:06:25.900]   So this is going to remove every tweet that doesn't have a null value.
[00:06:25.900 --> 00:06:34.820]   Now, in line 12, I set fixed target to also be the target values where the text is not null.
[00:06:34.820 --> 00:06:38.020]   This kind of data processing and cleanup is where you would really spend
[00:06:38.020 --> 00:06:41.620]   most of your time if you built machine learning classifiers in the real world.
[00:06:41.620 --> 00:06:43.980]   I'll tell you what a lot of students would do at this point,
[00:06:43.980 --> 00:06:46.140]   and actually a lot of colleagues I've had to do at this point,
[00:06:46.140 --> 00:06:48.980]   is instead of removing these values in the code,
[00:06:48.980 --> 00:06:51.180]   they would remove them in the input data.
[00:06:51.180 --> 00:06:53.620]   I strongly recommend not doing that.
[00:06:53.620 --> 00:06:56.060]   Once you start to change the input data,
[00:06:56.060 --> 00:06:58.580]   you can create lots of problems that'll show up in production,
[00:06:58.580 --> 00:07:00.380]   which you wouldn't be aware of.
[00:07:00.380 --> 00:07:02.620]   Now, my fit command works,
[00:07:02.620 --> 00:07:07.020]   and so I can print out the length of the number of words in the vocabulary of the countvec.
[00:07:07.020 --> 00:07:13.140]   So here, count_vec.vocabulary_ in this last line is actually how many columns we have,
[00:07:13.140 --> 00:07:21.220]   which corresponds to the number of words that it sees in all of the training data.
[00:07:21.220 --> 00:07:27.940]   So when I run feature extraction -2, it prints out 9,706.
[00:07:27.940 --> 00:07:30.620]   This is one of the fuzzy things that makes machine learning
[00:07:30.620 --> 00:07:33.020]   a little different from traditional statistics,
[00:07:33.020 --> 00:07:34.740]   even though the line is a little blurry.
[00:07:34.740 --> 00:07:36.700]   With a normal regression problem,
[00:07:36.700 --> 00:07:40.660]   we might have one or two columns of numbers as inputs and thousands of examples.
[00:07:40.660 --> 00:07:46.380]   Here we have 9,706 columns as inputs and a single column as an output.
[00:07:46.380 --> 00:07:50.780]   In fact, we have more columns of data than we have rows of data.
[00:07:50.780 --> 00:07:55.260]   We have more features than we have examples of data to look at.
[00:07:55.260 --> 00:07:57.980]   All fit did was set up the transformation.
[00:07:57.980 --> 00:08:02.180]   Let's actually do the transformation and get this data into this column form.
[00:08:02.180 --> 00:08:08.860]   So open up feature-extraction-3.py and take a look at line 17 here.
[00:08:08.860 --> 00:08:13.340]   So line 17 calls count_vec.transform on the fixed text.
[00:08:13.340 --> 00:08:17.500]   This line actually turns the fixed text into counts.
[00:08:17.500 --> 00:08:21.100]   Note that scikit always separates the fit method,
[00:08:21.100 --> 00:08:23.420]   which should be run once and sets everything up,
[00:08:23.420 --> 00:08:24.900]   and the transform method,
[00:08:24.900 --> 00:08:27.220]   which doesn't change the underlying object,
[00:08:27.220 --> 00:08:29.700]   but turn some data into another type of data.
[00:08:29.700 --> 00:08:31.340]   So it turns the fixed text,
[00:08:31.340 --> 00:08:33.500]   which is a list of tweets,
[00:08:33.500 --> 00:08:36.780]   into counts, which is a matrix where the rows are
[00:08:36.780 --> 00:08:40.700]   individual tweets and the columns are counts of individual words.
[00:08:40.700 --> 00:08:42.500]   We can do this more than once.
[00:08:42.500 --> 00:08:45.180]   So here, just for pedagogical purposes,
[00:08:45.180 --> 00:08:49.140]   in line 19, I set my count equal to count_vec.transform,
[00:08:49.140 --> 00:08:52.260]   and I give it two fake tweets that I pass in,
[00:08:52.260 --> 00:08:54.860]   love that iPhone and hate that iPhone,
[00:08:54.860 --> 00:08:57.100]   and then I print out the values.
[00:08:57.100 --> 00:09:00.660]   So I can run feature-extraction-3
[00:09:00.660 --> 00:09:05.220]   and have the output of love that iPhone and hate that iPhone.
[00:09:05.220 --> 00:09:08.300]   You can see that it outputs six numbers,
[00:09:08.300 --> 00:09:11.300]   and actually this is notation for a sparse matrix.
[00:09:11.300 --> 00:09:15.220]   Really what it should be outputting is tons of zeros and a few ones.
[00:09:15.220 --> 00:09:18.100]   But what it does here is it outputs six ones because it's not
[00:09:18.100 --> 00:09:21.300]   showing me the places where it's a zero.
[00:09:21.300 --> 00:09:24.540]   So what this is saying here is that row zero,
[00:09:24.540 --> 00:09:27.060]   column 4,573 is a one,
[00:09:27.060 --> 00:09:30.020]   and row zero, column 5,169 is a one,
[00:09:30.020 --> 00:09:33.260]   and everything that's not output is actually a zero.
[00:09:33.260 --> 00:09:35.340]   Now that this transformation working,
[00:09:35.340 --> 00:09:37.700]   we're ready to build our algorithm.
[00:09:37.700 --> 00:09:40.620]   I want to note before we move on that we've actually made
[00:09:40.620 --> 00:09:42.940]   our most important choices already,
[00:09:42.940 --> 00:09:45.060]   and there's a lot of implicit choices that we've made.
[00:09:45.060 --> 00:09:49.060]   So for one thing, how do we deal with capital letters versus lowercase letters?
[00:09:49.060 --> 00:09:50.860]   Is the word happy all caps?
[00:09:50.860 --> 00:09:53.500]   Should that be a different column than the word happy lowercase?
[00:09:53.500 --> 00:09:56.380]   The answer is it really depends on what we're doing.
[00:09:56.380 --> 00:09:58.860]   How should we deal with punctuation?
[00:09:58.860 --> 00:10:00.900]   In this case, we're actually removing,
[00:10:00.900 --> 00:10:02.860]   we're stripping all the punctuation,
[00:10:02.860 --> 00:10:06.660]   but with tweets, actually exclamation points, commas, periods,
[00:10:06.660 --> 00:10:10.780]   they really do have some meaning that we'd probably do better to pass through.
[00:10:10.780 --> 00:10:12.900]   There's actually something really,
[00:10:12.900 --> 00:10:15.260]   really important that we're dropping here,
[00:10:15.260 --> 00:10:18.900]   which you really should not drop if you want to have a very good tweet classifier.
[00:10:18.900 --> 00:10:22.820]   I'll give you a second to pause the video and think if you can guess what it is.
[00:10:22.820 --> 00:10:25.940]   Welcome back. What is it?
[00:10:25.940 --> 00:10:28.980]   I think it's n-grams. I think it's the relationship between words,
[00:10:28.980 --> 00:10:32.180]   because you're just storing information about a single word.
[00:10:32.180 --> 00:10:33.740]   Any explanation?
[00:10:33.740 --> 00:10:36.900]   So we have two guesses from our audience here.
[00:10:36.900 --> 00:10:38.980]   So they're similar.
[00:10:38.980 --> 00:10:44.060]   So the guess was maybe it's n-grams or we've dropped actually the order of words.
[00:10:44.060 --> 00:10:46.020]   In English, order of words certainly matters,
[00:10:46.020 --> 00:10:48.100]   and it's a really good observation that
[00:10:48.100 --> 00:10:52.260]   squashing it into these counts of words totally drops the order of words.
[00:10:52.260 --> 00:10:56.420]   Rada pointed out that negation could be a major issue,
[00:10:56.420 --> 00:10:58.620]   because if you say not good,
[00:10:58.620 --> 00:11:01.140]   we're going to count that there's a good and we're going to count there's a not,
[00:11:01.140 --> 00:11:03.500]   but we have no sense that the not happened just before the good.
[00:11:03.500 --> 00:11:06.700]   So negation is going to be a big problem with this algorithm.
[00:11:06.700 --> 00:11:10.260]   There's actually even a more fundamental thing that's maybe
[00:11:10.260 --> 00:11:12.540]   special to Twitter that we're dropping here.
[00:11:12.540 --> 00:11:14.420]   It wouldn't matter in the Wall Street Journal corpus
[00:11:14.420 --> 00:11:16.380]   that linguists are used to dealing with,
[00:11:16.380 --> 00:11:18.180]   but when people do Twitter,
[00:11:18.180 --> 00:11:20.140]   they often forget something.
[00:11:20.140 --> 00:11:22.060]   Hashtags.
[00:11:22.060 --> 00:11:23.060]   Slang.
[00:11:23.060 --> 00:11:25.220]   Hashtags, slang, these are also good guesses.
[00:11:25.220 --> 00:11:26.020]   Emoji.
[00:11:26.020 --> 00:11:28.100]   Emoji. That's the big one.
[00:11:28.100 --> 00:11:32.260]   So actually, this system we have right now is completely stripping out the emoji,
[00:11:32.260 --> 00:11:35.020]   which strips out a lot of meaning from the tweets.
[00:11:35.020 --> 00:11:37.140]   It shows you that if you take
[00:11:37.140 --> 00:11:43.500]   a language processing expert that's used to say books, processing books,
[00:11:43.500 --> 00:11:46.060]   they might struggle in a domain that they're less familiar with,
[00:11:46.060 --> 00:11:47.220]   like tweets.
[00:11:47.220 --> 00:11:51.100]   Setting aside the issues, which are major issues,
[00:11:51.100 --> 00:11:55.140]   we now have our data in a format where we could use a classifier,
[00:11:55.140 --> 00:11:58.260]   and we have a choice that's often very intimidating to students,
[00:11:58.260 --> 00:12:01.060]   which is which algorithm should we choose?
[00:12:01.060 --> 00:12:02.860]   They all have kind of intimidating names.
[00:12:02.860 --> 00:12:05.220]   It's kind of unclear where these different algorithms,
[00:12:05.220 --> 00:12:06.540]   and actually if you ask different people,
[00:12:06.540 --> 00:12:08.260]   they'll tell you different things.
[00:12:08.260 --> 00:12:11.180]   So two approaches that I really like.
[00:12:11.180 --> 00:12:13.420]   One is to look at what other people are doing,
[00:12:13.420 --> 00:12:16.020]   and the website Kaggle actually released a survey
[00:12:16.020 --> 00:12:18.980]   of the machine learning methods that real practitioners used,
[00:12:18.980 --> 00:12:22.220]   and there's quite a number of popular methods for different use cases,
[00:12:22.220 --> 00:12:27.300]   but I think the methods at the top are the ones that we should consider first.
[00:12:27.300 --> 00:12:32.340]   The second method is to look at this excellent flowchart made by Scikit,
[00:12:32.340 --> 00:12:34.700]   and if you really walk through this flowchart,
[00:12:34.700 --> 00:12:37.220]   I think you'll always get to a reasonable conclusion.
[00:12:37.220 --> 00:12:39.220]   Maybe not the very best possible algorithm,
[00:12:39.220 --> 00:12:43.540]   but certainly a reasonable algorithm to start with.
[00:12:43.540 --> 00:12:45.900]   So let's walk through this flowchart together.
[00:12:45.900 --> 00:12:49.500]   We start at the yellow circle, and then it asks us,
[00:12:49.500 --> 00:12:53.380]   do we have greater than 50 samples of training data?
[00:12:53.380 --> 00:12:53.980]   We do.
[00:12:53.980 --> 00:12:55.660]   I think it's kind of funny what it says if we don't.
[00:12:55.660 --> 00:12:57.700]   It says get more data, which I think is good advice.
[00:12:57.700 --> 00:13:00.220]   It doesn't recommend any algorithm, but we do.
[00:13:00.220 --> 00:13:03.580]   So then it says, OK, are you predicting a category?
[00:13:03.580 --> 00:13:04.580]   Are we predicting a category?
[00:13:04.580 --> 00:13:05.700]   What do you guys think?
[00:13:05.700 --> 00:13:07.260]   Yeah?
[00:13:07.260 --> 00:13:09.820]   Sometimes students argue that we're not predicting a category.
[00:13:09.820 --> 00:13:11.460]   Any thoughts on why they might say that?
[00:13:11.460 --> 00:13:16.140]   Because there could be a range of emotions.
[00:13:16.140 --> 00:13:17.100]   Yeah, exactly.
[00:13:17.100 --> 00:13:21.340]   So you could think of it as kind of like a range or a scale of very positive,
[00:13:21.340 --> 00:13:24.660]   somewhat positive, neutral, negative.
[00:13:24.660 --> 00:13:26.500]   So there are two ways to look at it, but I
[00:13:26.500 --> 00:13:29.700]   think category is a little simpler, and it works a little better
[00:13:29.700 --> 00:13:31.700]   with sentiment typically, because in some ways,
[00:13:31.700 --> 00:13:36.180]   positive is closer to negative than positive is closer to neutral,
[00:13:36.180 --> 00:13:38.100]   if that makes sense.
[00:13:38.100 --> 00:13:40.420]   So we'll say we are predicting a category.
[00:13:40.420 --> 00:13:42.980]   And then it asks, do we have labeled data?
[00:13:42.980 --> 00:13:45.660]   And actually, yeah, we do have labeled data here.
[00:13:45.660 --> 00:13:49.500]   And then it says, OK, do you have less than 100,000 samples?
[00:13:49.500 --> 00:13:51.540]   And we do have less than 100,000 samples.
[00:13:51.540 --> 00:13:54.220]   We have, I think, 9,000 samples we saw.
[00:13:54.220 --> 00:13:56.940]   And so then it recommends what's called a linear SVC, which
[00:13:56.940 --> 00:13:59.940]   is another way of saying SVM.
[00:13:59.940 --> 00:14:01.820]   And this is kind of funny, because it actually
[00:14:01.820 --> 00:14:04.700]   has an arrow coming out of that which says not working, question mark.
[00:14:04.700 --> 00:14:08.020]   And I have to say, when I try this with default parameters on this data set,
[00:14:08.020 --> 00:14:09.860]   it actually doesn't work very well.
[00:14:09.860 --> 00:14:12.700]   So this sort of shows how these things are fairly squishy.
[00:14:12.700 --> 00:14:15.540]   And in this case, linear SVC with defaults doesn't work well.
[00:14:15.540 --> 00:14:17.740]   And I kind of know why, but I don't want to get into it.
[00:14:17.740 --> 00:14:18.860]   So let's just follow the not working arrow.
[00:14:18.860 --> 00:14:22.060]   Let's say you didn't know anything, and you tried it, and it didn't work.
[00:14:22.060 --> 00:14:24.700]   And then it says, OK, are you dealing with text data?
[00:14:24.700 --> 00:14:26.500]   And in fact, we are dealing with text data.
[00:14:26.500 --> 00:14:28.580]   It was originally text data, and now it's numbers.
[00:14:28.580 --> 00:14:31.260]   And then it recommends naive Bayes.
[00:14:31.260 --> 00:14:34.220]   So naive Bayes sounds like a simple algorithm,
[00:14:34.220 --> 00:14:35.740]   and it is a simple algorithm.
[00:14:35.740 --> 00:14:38.100]   But it works really well, and it's really fast.
[00:14:38.100 --> 00:14:40.740]   So it's a really fun one to start with.
[00:14:40.740 --> 00:14:44.780]   And actually, if you go to the link, these boxes are clickable,
[00:14:44.780 --> 00:14:48.820]   and it'll give you demo code to actually run each one of these algorithms.
[00:14:48.820 --> 00:14:51.980]   But we can go back into classifier.py, and we
[00:14:51.980 --> 00:14:55.140]   can see where I put in a naive Bayes algorithm.
[00:14:55.140 --> 00:14:59.260]   So on line 24, from sklearn, scikit-learn.naiveBayes,
[00:14:59.260 --> 00:15:05.020]   I import multinomial nb, which is one type of naive Bayes classifier.
[00:15:05.020 --> 00:15:10.260]   And then I make a variable nb that I set equal to multinomial nb.
[00:15:10.260 --> 00:15:15.380]   Then in line 27, I call nb.fit, and I pass in the counts,
[00:15:15.380 --> 00:15:19.860]   which is this matrix of counts of words occurring in tweets,
[00:15:19.860 --> 00:15:22.540]   and then target, which is the thing that we're trying to classify.
[00:15:22.540 --> 00:15:25.140]   So this would be positive sentiment, negative sentiment,
[00:15:25.140 --> 00:15:28.300]   or neutral sentiment.
[00:15:28.300 --> 00:15:31.860]   And then in line 30, I actually try the classifier.
[00:15:31.860 --> 00:15:33.940]   So I call nb.predict.
[00:15:33.940 --> 00:15:35.900]   And now I can't call nb.predict on the text
[00:15:35.900 --> 00:15:39.740]   itself, because this classifier can only run on numbers.
[00:15:39.740 --> 00:15:41.780]   So I actually have to call nb.predict, and then I
[00:15:41.780 --> 00:15:45.780]   have to use that count_vec.transform to turn text into numbers.
[00:15:45.780 --> 00:15:51.260]   And I pass in a string, a sample tweet, which in this case is,
[00:15:51.260 --> 00:15:53.020]   I hate my iPhone.
[00:15:53.020 --> 00:15:56.740]   So let's see if that works.
[00:15:56.740 --> 00:16:00.260]   So I run python classifier.py, and it actually builds a model here,
[00:16:00.260 --> 00:16:03.460]   and actually does predict negative emotion.
[00:16:03.460 --> 00:16:05.660]   So that certainly seems promising.
[00:16:05.660 --> 00:16:09.620]   Or you might think I picked a canned example that would work well.
[00:16:09.620 --> 00:16:12.900]   So we built a simple, fast text classifier.
[00:16:12.900 --> 00:16:15.420]   And there's a whole bunch of awesome places to go from here.
[00:16:15.420 --> 00:16:17.860]   I usually spend a whole day on these classes,
[00:16:17.860 --> 00:16:20.460]   and I can take this in lots of different directions.
[00:16:20.460 --> 00:16:23.140]   I think the next thing that I would recommend someone
[00:16:23.140 --> 00:16:26.420]   to do if they're really trying to make this classifier work in the real world
[00:16:26.420 --> 00:16:27.860]   is measure its performance.
[00:16:27.860 --> 00:16:29.940]   I mean, just because it worked on I hate my iPhone,
[00:16:29.940 --> 00:16:31.900]   and spoiler, it works on I love my iPhone,
[00:16:31.900 --> 00:16:34.820]   doesn't mean that it's really going to work on the real types of tweets
[00:16:34.820 --> 00:16:36.980]   that you actually see in the real world.
[00:16:36.980 --> 00:16:39.900]   And so the best way to deal with that is to build an end-to-end system
[00:16:39.900 --> 00:16:41.340]   to measure performance.
[00:16:41.340 --> 00:16:45.120]   So we can split the data into some test data and some training data,
[00:16:45.120 --> 00:16:48.100]   and see how well this classifier performs.
[00:16:48.100 --> 00:16:50.100]   Once we have a sense of how well it's performing,
[00:16:50.100 --> 00:16:53.020]   then there's lots of things to do to improve this classifier.
[00:16:53.020 --> 00:16:56.100]   There are some suggestions from the audience here on how to improve it,
[00:16:56.100 --> 00:17:00.100]   maybe handle emojis, maybe encode the order of words.
[00:17:00.100 --> 00:17:03.060]   There's fancier things we could do, like make LSTMs or CNNs,
[00:17:03.060 --> 00:17:04.460]   or kind of fancier algorithms.
[00:17:04.460 --> 00:17:06.040]   And there's actually a lot in between.
[00:17:06.040 --> 00:17:07.740]   And there's something called grid search
[00:17:07.740 --> 00:17:11.740]   that you can use to look over lots and lots of different possibilities
[00:17:11.740 --> 00:17:15.420]   and find the thing that's going to work the best on your task.
[00:17:15.420 --> 00:17:19.020]   Scikit-learn has a lot of really excellent built-in methods to do this.
[00:17:19.020 --> 00:17:24.240]   And if you look around in the ML-class repository that I have,
[00:17:24.240 --> 00:17:26.820]   you'll find lots of good examples that you can draw from.
[00:17:26.820 --> 00:17:29.220]   And if you post some comments and request more,
[00:17:29.220 --> 00:17:31.020]   I'm sure we'll make lots of excellent videos
[00:17:31.020 --> 00:17:34.580]   beyond this that'll take you further down the path of text classifying
[00:17:34.580 --> 00:17:35.660]   with machine learning.
[00:17:35.660 --> 00:17:40.260]   Guys, I love feedback, especially positive feedback.
[00:17:40.260 --> 00:17:44.220]   [LAUGHTER]
[00:17:44.220 --> 00:17:48.700]   If you watch these videos and you make anything interesting or cool,
[00:17:48.700 --> 00:17:50.500]   that's really the thing that motivates me.
[00:17:50.500 --> 00:17:51.980]   So tell me about it.
[00:17:51.980 --> 00:17:54.900]   Put it in the comment or message me on Twitter.
[00:17:54.900 --> 00:17:57.420]   I'm @l2k.
[00:17:57.420 --> 00:18:00.760]   [LAUGHTER]

