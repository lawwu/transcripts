
[00:00:00.000 --> 00:00:05.000]   Welcome back to 6S099, Artificial General Intelligence.
[00:00:05.000 --> 00:00:09.600]   Today, we have Mark Raybert.
[00:00:09.600 --> 00:00:13.840]   (audience applauding)
[00:00:13.840 --> 00:00:19.840]   He is the, he really doesn't need an introduction,
[00:00:19.840 --> 00:00:21.760]   but we'll give him one anyway.
[00:00:21.760 --> 00:00:24.820]   He's the founder and CEO of Boston Dynamics.
[00:00:24.820 --> 00:00:27.360]   He founded the CMU Leg Lab in 1980,
[00:00:27.360 --> 00:00:29.720]   the MIT Leg Lab in 1986.
[00:00:29.720 --> 00:00:32.000]   Boston Dynamics in 1992.
[00:00:32.000 --> 00:00:33.920]   He and his team have developed
[00:00:33.920 --> 00:00:36.840]   some of the most amazing robots ever built,
[00:00:36.840 --> 00:00:41.240]   including Big Dog, Atlas, Handle, Spot, Spot Mini.
[00:00:41.240 --> 00:00:43.840]   These robots move with the agility, dexterity,
[00:00:43.840 --> 00:00:45.520]   and even grace that rivals
[00:00:45.520 --> 00:00:48.440]   and often supersedes that of human movement.
[00:00:48.440 --> 00:00:50.120]   He continues to inspire us
[00:00:50.120 --> 00:00:53.120]   with what robots are capable of achieving in the real world
[00:00:53.120 --> 00:00:57.080]   and what physical form future intelligence systems may take
[00:00:57.080 --> 00:00:59.760]   as they become integrated in our daily lives.
[00:00:59.760 --> 00:01:02.480]   So please give Mark a warm welcome.
[00:01:02.480 --> 00:01:03.520]   (audience applauding)
[00:01:03.520 --> 00:01:05.440]   - Thank you, thank you.
[00:01:05.440 --> 00:01:12.640]   This is our grand mission, our aspiration,
[00:01:12.640 --> 00:01:15.320]   which is to make robots that are equal to
[00:01:15.320 --> 00:01:18.680]   or greater than people and animals.
[00:01:18.680 --> 00:01:20.720]   And it's a daunting mission
[00:01:20.720 --> 00:01:24.020]   because we're so good at things.
[00:01:24.020 --> 00:01:26.400]   It seems effortless.
[00:01:26.400 --> 00:01:28.560]   I'm standing here knowing questions
[00:01:28.560 --> 00:01:31.620]   that I could stand here like this, but a lot's going on.
[00:01:31.620 --> 00:01:33.920]   I can manipulate things.
[00:01:33.920 --> 00:01:36.600]   I can pick up this water or I could reach in my pocket
[00:01:36.600 --> 00:01:39.640]   and use my hands with all the sensors in my hands
[00:01:39.640 --> 00:01:41.120]   and coordinate that.
[00:01:41.120 --> 00:01:43.740]   And maybe most of all, our perception systems.
[00:01:43.740 --> 00:01:45.760]   You know, this audience has, what is it,
[00:01:45.760 --> 00:01:47.720]   250 people in it or something?
[00:01:47.720 --> 00:01:51.520]   And I can look out there and see every one of you
[00:01:51.520 --> 00:01:54.240]   stabilized in space even while I'm moving.
[00:01:54.240 --> 00:01:56.240]   It's just astounding.
[00:01:56.240 --> 00:01:59.280]   And robots aren't there yet.
[00:01:59.280 --> 00:02:00.840]   But I think they can be.
[00:02:00.840 --> 00:02:05.840]   And our goal is to keep chipping away to try and get there.
[00:02:05.840 --> 00:02:07.720]   Before I get started, I wanted to say that
[00:02:07.720 --> 00:02:11.560]   I got my start in robotics here at MIT.
[00:02:11.560 --> 00:02:12.800]   I was a graduate student.
[00:02:12.800 --> 00:02:15.800]   I was in what was then called the psychology department,
[00:02:15.800 --> 00:02:17.820]   the brain and cognitive science department.
[00:02:17.820 --> 00:02:20.400]   But I was taking an IAP course, just like you are,
[00:02:20.400 --> 00:02:24.900]   and it might have been exactly this time of year,
[00:02:24.900 --> 00:02:29.100]   when I followed my professor, Bertolt Horn, back.
[00:02:29.100 --> 00:02:32.200]   I was jabbering away at him, asking him some questions
[00:02:32.200 --> 00:02:35.160]   about this or that, and we walked back to Tech Square,
[00:02:35.160 --> 00:02:37.860]   which is where the AI lab was in those days.
[00:02:37.860 --> 00:02:39.960]   And we went up to the ninth floor,
[00:02:39.960 --> 00:02:43.960]   and Russell Novsker, who was a guy working in the lab,
[00:02:43.960 --> 00:02:47.280]   had an arm all taken apart on the table.
[00:02:47.280 --> 00:02:49.200]   It was like 1,000 pieces.
[00:02:49.200 --> 00:02:53.320]   And I was a roboticist from that day on.
[00:02:53.320 --> 00:02:58.320]   I didn't switch my major, but I got Bertolt to be an advisor.
[00:02:58.320 --> 00:03:02.980]   I found a topic that had to do with robotics.
[00:03:02.980 --> 00:03:04.920]   In that time, it was a manipulation thing,
[00:03:04.920 --> 00:03:07.980]   but eventually became a legged thing.
[00:03:07.980 --> 00:03:12.980]   And it was amazing, and I've never looked back.
[00:03:12.980 --> 00:03:16.280]   So here are some animals doing things
[00:03:16.280 --> 00:03:19.140]   that are very exciting, climbing around
[00:03:19.140 --> 00:03:23.280]   on very rough terrain, very short-footed.
[00:03:23.280 --> 00:03:26.960]   Using a mixture of their proprioception and their vision.
[00:03:26.960 --> 00:03:29.160]   And look, there's even a baby that probably
[00:03:29.160 --> 00:03:30.720]   is only a couple of months old,
[00:03:30.720 --> 00:03:34.440]   has no trouble at all doing these things.
[00:03:34.440 --> 00:03:38.320]   And look at the grace and suppleness
[00:03:38.320 --> 00:03:42.340]   and the fearlessness of these animals.
[00:03:42.340 --> 00:03:43.180]   It's amazing.
[00:03:43.180 --> 00:03:47.800]   Here are animals running for their lives.
[00:03:47.800 --> 00:03:50.700]   The gazelle is trying to stay alive
[00:03:50.700 --> 00:03:52.880]   for the next 10 minutes, and the cheetah's
[00:03:52.880 --> 00:03:56.920]   trying to get a meal so that it can stay alive in general.
[00:03:56.920 --> 00:03:57.760]   Sorry.
[00:03:57.760 --> 00:04:04.800]   And even people can do things that are breathtaking.
[00:04:04.800 --> 00:04:06.760]   I assume all of you were out this morning
[00:04:06.760 --> 00:04:08.360]   getting a little exercise, climbing up
[00:04:08.360 --> 00:04:09.840]   the green building that we're in now,
[00:04:09.840 --> 00:04:12.240]   and maybe the other places around here.
[00:04:12.240 --> 00:04:14.520]   It's funny, I bumped into some people
[00:04:14.520 --> 00:04:17.480]   when I came into the room who were climbing the stairways.
[00:04:17.480 --> 00:04:19.380]   I think they were going on a trek up and down them.
[00:04:19.380 --> 00:04:22.840]   But I'd like to see the going outside.
[00:04:22.840 --> 00:04:25.880]   So probably most of you have seen this video.
[00:04:25.880 --> 00:04:30.880]   This is sort of where we were after about 10 years of work
[00:04:30.880 --> 00:04:35.080]   attempting to make machines that could work out
[00:04:35.080 --> 00:04:38.040]   in the real world that were dynamically stabilized.
[00:04:38.040 --> 00:04:42.480]   Dynamics is a big deal for our company and for what we do.
[00:04:42.480 --> 00:04:46.040]   So some active sensing and control
[00:04:46.040 --> 00:04:47.900]   and understanding of the physics.
[00:04:51.600 --> 00:04:54.000]   This robot has all its control on board,
[00:04:54.000 --> 00:04:56.780]   and it has reflexes and sensors.
[00:04:56.780 --> 00:05:00.440]   And this is an extension to a 1,000-pound robot
[00:05:00.440 --> 00:05:03.360]   that could carry about 400 pounds of payload.
[00:05:03.360 --> 00:05:05.120]   And we took it all around the United States
[00:05:05.120 --> 00:05:08.300]   testing it in various situations.
[00:05:08.300 --> 00:05:13.140]   Here we have it in Virginia doing some bushwhacking.
[00:05:13.140 --> 00:05:15.120]   It's actually following a person,
[00:05:15.120 --> 00:05:17.400]   but the person is only in and out of view intermittently,
[00:05:17.400 --> 00:05:20.340]   so it has to be able to keep track of where the person is
[00:05:20.340 --> 00:05:22.040]   and deal with that.
[00:05:22.040 --> 00:05:26.120]   And then back in good old Boston, 10 inches of snow,
[00:05:26.120 --> 00:05:27.720]   just marches right up the hill.
[00:05:27.720 --> 00:05:30.960]   Here's the cheetah.
[00:05:30.960 --> 00:05:33.160]   Now, you know, MIT has its own cheetah.
[00:05:33.160 --> 00:05:34.440]   This is our cheetah.
[00:05:34.440 --> 00:05:40.760]   People know Songbe, who's doing the MIT cheetah.
[00:05:40.760 --> 00:05:46.800]   A very dynamic machine.
[00:05:46.800 --> 00:05:48.640]   And basically an experiment in seeing
[00:05:48.640 --> 00:05:51.480]   how fast we could make something like this run.
[00:05:51.480 --> 00:05:53.540]   Although you notice it's on a parking lot,
[00:05:53.540 --> 00:05:56.180]   so it wasn't doing this on rough terrain.
[00:05:56.180 --> 00:05:59.340]   And getting both the efficiency and the speed
[00:05:59.340 --> 00:06:03.100]   in the context of a machine that also can do rough terrain
[00:06:03.100 --> 00:06:06.300]   is a really big challenge that remains with us.
[00:06:06.300 --> 00:06:11.840]   So this is just a snapshot of most of the robots
[00:06:11.840 --> 00:06:14.320]   we've built at Boston Dynamics over the years.
[00:06:14.320 --> 00:06:16.820]   And I'm not gonna talk about most of them.
[00:06:16.820 --> 00:06:19.640]   I'm just gonna talk about the last four.
[00:06:19.640 --> 00:06:21.940]   These are all robots that we developed
[00:06:21.940 --> 00:06:23.580]   since we've been part of Google,
[00:06:23.580 --> 00:06:25.980]   which has been the last four years.
[00:06:25.980 --> 00:06:28.260]   Spot Mini, there's a Spot Mini on the floor here,
[00:06:28.260 --> 00:06:29.980]   which we'll demo a little later.
[00:06:29.980 --> 00:06:32.860]   Spot, Atlas, the Humanoid.
[00:06:32.860 --> 00:06:34.960]   Some of you may remember the Humanoid
[00:06:34.960 --> 00:06:37.220]   that we used in the DARPA Robotics Challenge.
[00:06:37.220 --> 00:06:38.740]   You have one here.
[00:06:38.740 --> 00:06:41.900]   And then Handle, which is our latest version.
[00:06:41.900 --> 00:06:45.240]   So I'll have a few words to say about each of them.
[00:06:45.240 --> 00:06:48.500]   So we had been developing Big Dog
[00:06:48.500 --> 00:06:50.300]   and those other quadrupeds that I showed you
[00:06:50.300 --> 00:06:52.100]   for quite some number of years.
[00:06:52.100 --> 00:06:54.180]   And it was amazing for us to find out
[00:06:54.180 --> 00:06:57.460]   when we did this project on Spot,
[00:06:57.460 --> 00:06:59.660]   this is the predecessor to that,
[00:06:59.660 --> 00:07:01.480]   that there was still a lot to learn.
[00:07:01.480 --> 00:07:05.200]   And we kind of revolutionized the hardware design
[00:07:05.200 --> 00:07:07.020]   and how the control worked
[00:07:07.020 --> 00:07:11.220]   and got a much higher level of rough terrain performance.
[00:07:11.220 --> 00:07:12.700]   And part of the solution to that
[00:07:12.700 --> 00:07:16.180]   was to be able to decompose the control problem
[00:07:16.180 --> 00:07:19.600]   into many separate controllers
[00:07:19.600 --> 00:07:22.460]   that operated in different regions of state space.
[00:07:22.460 --> 00:07:25.260]   And that allowed us both to have programmers
[00:07:25.260 --> 00:07:27.780]   work on multiple solutions to the problem
[00:07:27.780 --> 00:07:34.300]   and also have the complexity of each controller simplified
[00:07:34.300 --> 00:07:35.900]   by only having to operate
[00:07:35.900 --> 00:07:38.080]   in a small part of the dynamic space.
[00:07:39.100 --> 00:07:41.540]   Here we've added a robot arm
[00:07:41.540 --> 00:07:44.420]   to the previous version of Spot.
[00:07:44.420 --> 00:07:48.540]   And we believe that mobile manipulation,
[00:07:48.540 --> 00:07:51.060]   that is manipulation when you can move the base,
[00:07:51.060 --> 00:07:55.520]   is really a powerful way of doing things.
[00:07:55.520 --> 00:07:58.300]   Now this is probably the most important thing
[00:07:58.300 --> 00:07:59.500]   I wanna show tonight.
[00:07:59.500 --> 00:08:01.580]   And I'll show it three different times.
[00:08:01.580 --> 00:08:03.740]   The idea that we don't build controllers
[00:08:03.740 --> 00:08:06.500]   that just do one particular thing,
[00:08:06.500 --> 00:08:08.340]   but that they can determine where they are
[00:08:08.340 --> 00:08:10.620]   in the execution, here's another version of it,
[00:08:10.620 --> 00:08:12.980]   and then adjust what they're doing
[00:08:12.980 --> 00:08:17.220]   in order to compensate for disturbances in the real world.
[00:08:17.220 --> 00:08:20.940]   I know this class is about AI and probably autonomy.
[00:08:20.940 --> 00:08:26.580]   I think that one of the most important ways
[00:08:26.580 --> 00:08:27.980]   of getting to autonomy
[00:08:27.980 --> 00:08:30.100]   is to have the low-level implementations
[00:08:30.100 --> 00:08:32.440]   very robust to disturbances
[00:08:32.440 --> 00:08:34.780]   so that the planning steps don't have to take care
[00:08:34.780 --> 00:08:38.940]   of all the minutia of the details of the real world.
[00:08:38.940 --> 00:08:42.020]   And that's what we've been trying to do there.
[00:08:42.020 --> 00:08:44.180]   We've been experimenting with doing delivery
[00:08:44.180 --> 00:08:46.260]   of packages to people's houses.
[00:08:46.260 --> 00:08:48.660]   These are all employees of Boston Dynamics,
[00:08:48.660 --> 00:08:52.180]   so we didn't go crashing ordinary people's houses.
[00:08:52.180 --> 00:08:55.860]   And it turns out that there's just lots
[00:08:55.860 --> 00:08:58.680]   of different kinds of stairways and entranceways.
[00:08:58.680 --> 00:09:02.740]   And the robot's doing very well.
[00:09:02.740 --> 00:09:06.020]   We're up to something between 70 and 80%
[00:09:06.020 --> 00:09:11.020]   of the kinds of stairs and access places we encounter
[00:09:11.020 --> 00:09:14.220]   after collecting data
[00:09:14.220 --> 00:09:17.020]   and making improvements and adjustments.
[00:09:17.020 --> 00:09:23.160]   So I'm gonna say a few philosophical things
[00:09:23.160 --> 00:09:24.380]   or approach things.
[00:09:24.380 --> 00:09:29.140]   A lot of people think that this is the model
[00:09:29.140 --> 00:09:33.700]   of how a computer and a robot interact.
[00:09:33.700 --> 00:09:36.080]   That is, there's the robot,
[00:09:36.080 --> 00:09:39.900]   which is hardware and electronics and sensors.
[00:09:39.900 --> 00:09:41.980]   And then there's a computer.
[00:09:41.980 --> 00:09:45.940]   And that the computer listens to the sensors on the robot
[00:09:45.940 --> 00:09:49.100]   and then gives it instructions and tells it what to do.
[00:09:49.100 --> 00:09:52.380]   And while I think that's actually going on,
[00:09:52.380 --> 00:09:54.200]   there's another part to the story,
[00:09:54.200 --> 00:09:55.860]   which is that the physical world
[00:09:55.860 --> 00:09:59.420]   is also giving instructions to the robot.
[00:09:59.420 --> 00:10:02.900]   And that means that the energies stored in the robot,
[00:10:02.900 --> 00:10:07.900]   either in its springs or in its motion,
[00:10:07.900 --> 00:10:09.980]   those are all important determinants
[00:10:09.980 --> 00:10:14.260]   of how the robot's gonna behave in the time coming forward.
[00:10:14.260 --> 00:10:17.140]   And so we like to think in terms of designing
[00:10:17.140 --> 00:10:20.420]   the hardware of the robot, the physical world,
[00:10:20.420 --> 00:10:24.300]   and the computer all as one holistic thing
[00:10:24.300 --> 00:10:27.160]   where we take into account those interactions.
[00:10:27.160 --> 00:10:30.620]   Sometimes we call this a harmony.
[00:10:30.620 --> 00:10:33.740]   A harmonic system is one usually where you have energy
[00:10:33.740 --> 00:10:35.740]   oscillating back and forth.
[00:10:35.740 --> 00:10:38.500]   Almost all legged locomotion has some amount
[00:10:38.500 --> 00:10:43.340]   of harmony going on between potential energy of elevation,
[00:10:43.340 --> 00:10:46.340]   potential energy of elastic deformation,
[00:10:46.340 --> 00:10:48.420]   kinetic energy of motion,
[00:10:48.420 --> 00:10:52.440]   and inverted pendulum things and the like.
[00:10:53.280 --> 00:10:56.920]   Another part of our approach we call
[00:10:56.920 --> 00:10:58.600]   build it, break it, fix it.
[00:10:58.600 --> 00:11:02.800]   Now I have friends who build their robots
[00:11:02.800 --> 00:11:07.800]   and are so into the beauty of what they've created
[00:11:07.800 --> 00:11:10.800]   that they kind of put it on an altar
[00:11:10.800 --> 00:11:14.720]   and afraid of actually hurting it.
[00:11:14.720 --> 00:11:18.060]   So, and in fact, I even have friends here at MIT
[00:11:18.060 --> 00:11:20.700]   that have done that, where they have a gold-plated robot
[00:11:20.700 --> 00:11:23.840]   and they're afraid of taking it out into the world.
[00:11:23.840 --> 00:11:26.080]   I mean, we're just the opposite.
[00:11:26.080 --> 00:11:30.160]   Every one of our robots is designed to get bashed to bits.
[00:11:30.160 --> 00:11:33.040]   We have staff who are there to fix the robot
[00:11:33.040 --> 00:11:35.960]   on a daily basis as we break it.
[00:11:35.960 --> 00:11:38.560]   And I think doing that, build it, break it, fix it,
[00:11:38.560 --> 00:11:40.800]   means that we're able to learn a lot
[00:11:40.800 --> 00:11:44.240]   from the actual physical robot working in the world.
[00:11:44.240 --> 00:11:48.000]   And we can use that knowledge in order to improve the robot,
[00:11:48.000 --> 00:11:50.940]   improve its behavior, and we really like to go around
[00:11:50.940 --> 00:11:55.620]   that loop as quickly as we can, early in the process,
[00:11:55.620 --> 00:12:00.340]   and do it as many times as we can.
[00:12:00.340 --> 00:12:02.940]   So here's what build it, break it, fix it looks like.
[00:12:02.940 --> 00:12:08.180]   This is in Somerville.
[00:12:08.180 --> 00:12:17.700]   Our engineers, this is a Boston driver.
[00:12:18.700 --> 00:12:21.700]   (audience laughing)
[00:12:21.700 --> 00:12:30.140]   Now this robot's supposed to be using its visual system
[00:12:30.140 --> 00:12:32.180]   to avoid the trees.
[00:12:32.180 --> 00:12:40.220]   I think it might have fallen in love with this tree.
[00:12:40.220 --> 00:12:42.060]   We don't purposely give them any emotion,
[00:12:42.060 --> 00:12:45.340]   but boy, it's hard not to see that.
[00:12:45.340 --> 00:12:48.900]   And here's the first time we tested the push response
[00:12:48.900 --> 00:12:49.860]   to this robot.
[00:12:49.860 --> 00:12:55.300]   And you-- - That's your new guy's car.
[00:12:55.300 --> 00:12:56.140]   - Did you hear that?
[00:12:56.140 --> 00:12:57.340]   That's the new guy's car.
[00:12:57.340 --> 00:13:00.760]   So some guy who just started that week, Trent,
[00:13:00.760 --> 00:13:04.780]   had $5,000, which we paid for,
[00:13:04.780 --> 00:13:08.000]   in repairs to his vintage BMW.
[00:13:08.000 --> 00:13:13.660]   So the last thing sort of about philosophy
[00:13:13.660 --> 00:13:15.680]   is long-term versus short-term.
[00:13:15.680 --> 00:13:19.220]   Our company is 25 years old,
[00:13:19.220 --> 00:13:23.660]   and we've mostly been a long-term robotics company.
[00:13:23.660 --> 00:13:27.340]   That is, we're interested in moving the boundary forward
[00:13:27.340 --> 00:13:32.300]   in what robots can do, and we're interested in making it
[00:13:32.300 --> 00:13:35.500]   so robots meet the dream of being the equal
[00:13:35.500 --> 00:13:37.180]   or better than people and animals.
[00:13:37.180 --> 00:13:39.260]   But now we've started--
[00:13:39.260 --> 00:13:42.420]   (microphone thudding)
[00:13:42.420 --> 00:13:45.260]   Malfunction.
[00:13:45.260 --> 00:13:50.060]   (microphone thudding)
[00:13:50.060 --> 00:13:55.420]   Okay.
[00:13:55.420 --> 00:13:56.740]   We still on?
[00:13:56.740 --> 00:13:57.580]   Can you hear me?
[00:13:57.580 --> 00:14:03.340]   But lately, we've started to realize
[00:14:03.340 --> 00:14:06.260]   that some of our robots have enough capability
[00:14:06.260 --> 00:14:08.660]   that maybe it's time to try and productize them,
[00:14:08.660 --> 00:14:10.580]   and we will learn a lot by doing that, too.
[00:14:10.580 --> 00:14:13.500]   One of the things, for instance, that I've always claimed
[00:14:13.500 --> 00:14:17.880]   is that we always spent a lot of money
[00:14:17.880 --> 00:14:20.840]   on building our robots and used that
[00:14:20.840 --> 00:14:22.340]   as a competitive advantage.
[00:14:22.340 --> 00:14:24.860]   That is, DARPA was a frequent funder of us.
[00:14:24.860 --> 00:14:27.460]   DARPA always said, "Let's take money out of the equation
[00:14:27.460 --> 00:14:31.920]   "and just figure out how to get the solution
[00:14:31.920 --> 00:14:34.560]   "and then worry about getting the cost down later."
[00:14:34.560 --> 00:14:36.820]   So I've always assumed and argued
[00:14:36.820 --> 00:14:38.400]   that once we get a robot doing things
[00:14:38.400 --> 00:14:41.060]   that are interesting, then you can go and redesign it
[00:14:41.060 --> 00:14:42.960]   to make it lower cost.
[00:14:42.960 --> 00:14:46.060]   Well, we're gonna test that, because it might not be true.
[00:14:46.060 --> 00:14:47.620]   It might be that we've designed ourselves
[00:14:47.620 --> 00:14:51.900]   into an expensive corner and that it might be too late.
[00:14:51.900 --> 00:14:54.060]   But the robot that we'll show in a little bit
[00:14:54.060 --> 00:14:56.420]   is much significantly cost-reduced
[00:14:56.420 --> 00:14:58.700]   from the prototype of it, and it'll be interesting
[00:14:58.700 --> 00:15:00.260]   to see whether we can get it down
[00:15:00.260 --> 00:15:03.980]   to the kind of prices that are useful.
[00:15:03.980 --> 00:15:05.540]   So this is just a picture, again,
[00:15:05.540 --> 00:15:10.480]   of the idea of aiming long but also aiming short.
[00:15:10.480 --> 00:15:13.400]   And I think it's gonna be a challenge
[00:15:13.400 --> 00:15:16.460]   to see whether we can keep the culture of the company
[00:15:16.460 --> 00:15:18.220]   to support both of these directions,
[00:15:18.220 --> 00:15:20.740]   because people manufacturing stuff
[00:15:20.740 --> 00:15:22.700]   have a different mindset than people trying
[00:15:22.700 --> 00:15:26.260]   to get out to the future horizons,
[00:15:26.260 --> 00:15:28.780]   and it's gonna be a challenge
[00:15:28.780 --> 00:15:31.400]   to keep both those kinds of people happy.
[00:15:34.340 --> 00:15:36.620]   Here's some of the things that,
[00:15:36.620 --> 00:15:39.820]   some of the kinds of applications you can look at
[00:15:39.820 --> 00:15:44.820]   based on modest technical capabilities.
[00:15:44.820 --> 00:15:47.700]   I've shown mobility and manipulation here,
[00:15:47.700 --> 00:15:49.620]   but you could put cost, reliability,
[00:15:49.620 --> 00:15:52.260]   there's many things that could be on these axes.
[00:15:52.260 --> 00:15:55.260]   You know, entertainment, like robots in theme parks
[00:15:55.260 --> 00:15:58.420]   is something that I think we should be able to do.
[00:15:58.420 --> 00:16:00.380]   I already talked about home delivery.
[00:16:00.380 --> 00:16:03.500]   I think home delivery is waiting for self-driving cars
[00:16:03.500 --> 00:16:05.620]   to get all the way there, self-driving trucks,
[00:16:05.620 --> 00:16:08.600]   and once they do, then we will be working
[00:16:08.600 --> 00:16:11.200]   on getting it from the truck to the home.
[00:16:11.200 --> 00:16:17.620]   Logistics, there's about a trillion boxes
[00:16:17.620 --> 00:16:20.480]   moved every year around the world,
[00:16:20.480 --> 00:16:22.720]   and most of it's done by hand,
[00:16:22.720 --> 00:16:24.420]   and so there's really a big opportunity
[00:16:24.420 --> 00:16:28.020]   to having robots help with moving those trillion boxes.
[00:16:28.020 --> 00:16:32.240]   Security, which could mean either commercial security,
[00:16:32.240 --> 00:16:34.900]   like patrolling your shopping center,
[00:16:34.900 --> 00:16:37.540]   or the military type security.
[00:16:37.540 --> 00:16:41.660]   Construction, a lot of people have been coming to us
[00:16:41.660 --> 00:16:45.820]   with their construction applications asking if we can help,
[00:16:45.820 --> 00:16:47.260]   and you know, I'm not gonna talk about it now,
[00:16:47.260 --> 00:16:48.820]   but if afterwards you wanna ask about that,
[00:16:48.820 --> 00:16:51.140]   I can fill you in a little more,
[00:16:51.140 --> 00:16:53.940]   and I think this is really the ultimate
[00:16:53.940 --> 00:16:56.100]   home run application,
[00:16:56.100 --> 00:16:58.300]   care for the elderly and the disabled.
[00:17:00.460 --> 00:17:03.840]   I used to say that I wanted to have robots
[00:17:03.840 --> 00:17:08.840]   that would help me take care of my parents and older people,
[00:17:08.840 --> 00:17:13.180]   but I realize now that it's probably gonna be my children
[00:17:13.180 --> 00:17:15.680]   using them to help take care of me,
[00:17:15.680 --> 00:17:18.540]   but you guys, you're all a little bit younger,
[00:17:18.540 --> 00:17:23.540]   and I think there'll be a time when you could use robots
[00:17:23.540 --> 00:17:26.560]   to help make your parents' lives better.
[00:17:26.560 --> 00:17:28.240]   Now, some of you may think that your parents
[00:17:28.240 --> 00:17:31.720]   don't want that, but I think it's a complex question.
[00:17:31.720 --> 00:17:34.680]   We've seen some surveys that say that, you know,
[00:17:34.680 --> 00:17:37.460]   people aren't totally happy with the idea of their kids
[00:17:37.460 --> 00:17:40.100]   taking care of them on a moment by moment basis,
[00:17:40.100 --> 00:17:41.980]   and I think there's gonna be an opportunity
[00:17:41.980 --> 00:17:43.680]   for doing something, but technically,
[00:17:43.680 --> 00:17:46.400]   this is still a ways off, it's a tough thing.
[00:17:46.400 --> 00:17:49.080]   Okay, let's get back to the robots.
[00:17:49.080 --> 00:17:53.200]   Spot Mini is a robot that weighs about 60 pounds.
[00:17:53.200 --> 00:17:55.720]   That previous Spot weighed about 180 pounds.
[00:17:55.720 --> 00:18:00.720]   This one weighs about 60 pounds, and here's some anatomy.
[00:18:00.720 --> 00:18:04.880]   It's got an arm with five degrees of freedom.
[00:18:04.880 --> 00:18:06.920]   Each leg has three degrees of freedom.
[00:18:06.920 --> 00:18:13.020]   It's got about a 500 watt hour battery.
[00:18:13.020 --> 00:18:15.840]   Batteries for these things are a challenge,
[00:18:15.840 --> 00:18:19.240]   because, you know, you can have consumer products
[00:18:19.240 --> 00:18:22.640]   like electric drills that have relatively small batteries,
[00:18:22.640 --> 00:18:24.960]   and then there's electric cars that have big batteries,
[00:18:24.960 --> 00:18:26.880]   and there's not really much available in between,
[00:18:26.880 --> 00:18:29.560]   so we've done a lot of work on the battery technology
[00:18:29.560 --> 00:18:32.080]   for these things to make them safe and reliable
[00:18:32.080 --> 00:18:34.920]   and hot swappable and things like that.
[00:18:34.920 --> 00:18:36.860]   Then there's radios and computers.
[00:18:36.860 --> 00:18:41.760]   The previous version had three quad core i7s.
[00:18:41.760 --> 00:18:43.080]   This one has two.
[00:18:43.080 --> 00:18:45.660]   We're trying to cut back on the cost.
[00:18:45.660 --> 00:18:50.040]   And then there can be some sensors,
[00:18:50.040 --> 00:18:53.400]   lidars, stereo, and the like.
[00:18:54.400 --> 00:18:57.040]   (audience member speaking faintly)
[00:18:57.040 --> 00:19:00.200]   So you can see, Spot Mini's a little bit smaller than Spot.
[00:19:00.200 --> 00:19:09.360]   This isn't a real house, and those aren't real people.
[00:19:09.360 --> 00:19:10.760]   Those are engineers.
[00:19:10.760 --> 00:19:12.280]   (audience laughing)
[00:19:12.280 --> 00:19:16.120]   This is inside of a warehouse we have out on 128
[00:19:16.120 --> 00:19:17.640]   where we've built a house.
[00:19:17.640 --> 00:19:20.480]   You can see that we don't mind scuffing up the walls here,
[00:19:20.480 --> 00:19:22.960]   and there is a lot of scuffing that happens.
[00:19:22.960 --> 00:19:25.000]   Some of you may recognize Zach Tuchowski,
[00:19:25.000 --> 00:19:29.440]   who's an MIT alum, and he's, again, disturbing the robot.
[00:19:29.440 --> 00:19:31.280]   Here, the robot's using its vision
[00:19:31.280 --> 00:19:35.360]   to do some stepping stone type operations,
[00:19:35.360 --> 00:19:37.260]   and I think Gene is gonna talk a little bit more
[00:19:37.260 --> 00:19:38.960]   about this in a couple of minutes.
[00:19:38.960 --> 00:19:41.960]   And here's a case where it's doing stepping stones
[00:19:41.960 --> 00:19:45.080]   on real stones, and it's keeping its balance,
[00:19:45.080 --> 00:19:46.840]   figuring out where to put the feet.
[00:19:50.720 --> 00:19:54.160]   And again, this robot only has stereo looking out the front,
[00:19:54.160 --> 00:19:57.920]   whereas this one has stereo on all four sides.
[00:19:57.920 --> 00:20:05.800]   Now, one of the cool things about animals
[00:20:05.800 --> 00:20:08.320]   is that they have these stabilization mechanisms
[00:20:08.320 --> 00:20:09.200]   for their sensors.
[00:20:09.200 --> 00:20:10.760]   That was a real chicken.
[00:20:10.760 --> 00:20:12.520]   No robotics involved.
[00:20:12.520 --> 00:20:15.560]   And here's our attempt to show that this robot
[00:20:15.560 --> 00:20:18.040]   can do the same sort of thing.
[00:20:19.120 --> 00:20:21.400]   And if you think about it, when you're manipulating,
[00:20:21.400 --> 00:20:24.080]   you really want the hand to be stabilized in space,
[00:20:24.080 --> 00:20:26.480]   and so you'd like the body to be able
[00:20:26.480 --> 00:20:28.240]   to kind of coordinate with the hand
[00:20:28.240 --> 00:20:33.240]   so that you can concentrate on what the real world task is.
[00:20:33.240 --> 00:20:34.200]   (audience laughing)
[00:20:34.200 --> 00:20:35.720]   Oh, man.
[00:20:35.720 --> 00:20:38.000]   You guys didn't pick up the banana peels, huh?
[00:20:38.000 --> 00:20:41.000]   (audience laughing)
[00:20:41.000 --> 00:20:52.760]   So our concept for the Spot Mini product
[00:20:52.760 --> 00:20:54.280]   is to make a platform.
[00:20:54.280 --> 00:20:56.080]   It's sort of the, we're thinking of it
[00:20:56.080 --> 00:20:58.400]   like the Android of robots.
[00:20:58.400 --> 00:21:01.360]   So with Android, there's a hardware platform,
[00:21:01.360 --> 00:21:04.000]   and then there's a software platform,
[00:21:04.000 --> 00:21:07.440]   and then developers, third party developers,
[00:21:07.440 --> 00:21:10.200]   create their own apps that use the platform.
[00:21:10.200 --> 00:21:14.640]   So we've made this spot so that there's a place
[00:21:14.640 --> 00:21:16.560]   to mount hardware on the robot,
[00:21:16.560 --> 00:21:19.440]   but there's also an API to program it through,
[00:21:19.440 --> 00:21:22.480]   and then there's a facility to have additional computing
[00:21:22.480 --> 00:21:27.040]   external to the robot, and we're working with third parties
[00:21:27.040 --> 00:21:30.780]   to develop their own applications that run on the platform.
[00:21:35.760 --> 00:21:38.660]   This is a video that we haven't been able
[00:21:38.660 --> 00:21:39.940]   to release publicly.
[00:21:39.940 --> 00:21:42.320]   Please don't tape it and show it,
[00:21:42.320 --> 00:21:47.160]   because I'll explain later if you wanna know why not,
[00:21:47.160 --> 00:21:50.000]   but this is just revealing that we do have an arm
[00:21:50.000 --> 00:21:52.120]   on the new version of Spot.
[00:21:52.120 --> 00:21:58.080]   It's using a camera in the hand to find the door handle.
[00:21:58.080 --> 00:22:04.040]   This robot doesn't weigh a lot,
[00:22:04.040 --> 00:22:06.840]   so it has to use tricks to keep the door open,
[00:22:06.840 --> 00:22:09.040]   so that's why it puts its foot in the door.
[00:22:09.040 --> 00:22:12.040]   (audience laughing)
[00:22:12.040 --> 00:22:19.200]   (audience applauding)
[00:22:19.200 --> 00:22:23.800]   And here again, we wanna show that we've made
[00:22:23.800 --> 00:22:26.920]   the solution robust to certain kinds of disturbances.
[00:22:26.920 --> 00:22:29.560]   So Andy there, Andy's sitting over here,
[00:22:29.560 --> 00:22:32.880]   is pushing on the door, pushing on the hand.
[00:22:32.880 --> 00:22:36.840]   The robot keeps track of how much progress it's made
[00:22:36.840 --> 00:22:38.220]   in doing its task.
[00:22:38.220 --> 00:22:45.840]   (audience laughing)
[00:22:45.840 --> 00:22:50.020]   It's so smart, it even kicks that shell out of the way.
[00:22:50.020 --> 00:22:51.880]   No, that was a total accident.
[00:22:51.880 --> 00:22:54.680]   (audience laughing)
[00:22:54.680 --> 00:22:57.600]   And now it's just gone back to try again.
[00:23:02.640 --> 00:23:03.480]   Okay.
[00:23:03.480 --> 00:23:08.680]   And then this is a demo of autonomy.
[00:23:08.680 --> 00:23:13.400]   Here the robot has, in a previous session,
[00:23:13.400 --> 00:23:16.320]   we've taken it around the lab, this is Boston Dynamics,
[00:23:16.320 --> 00:23:19.780]   taken it around the lab and recorded visual data
[00:23:19.780 --> 00:23:21.720]   that could be used for navigation.
[00:23:21.720 --> 00:23:25.020]   And it's using its stereo to match up features
[00:23:25.020 --> 00:23:28.160]   in the environment so that it can navigate
[00:23:28.160 --> 00:23:33.160]   and go where it had gone on the previous path.
[00:23:33.160 --> 00:23:37.760]   So there's no one driving it for this, it's all autonomous.
[00:23:37.760 --> 00:23:42.280]   That was outside my office.
[00:23:42.280 --> 00:23:45.560]   Every day around noon, the robot seems to show up
[00:23:45.560 --> 00:23:47.200]   and I hear it pausing out there.
[00:23:47.200 --> 00:23:53.240]   I don't know why it turned there.
[00:23:53.240 --> 00:23:55.820]   Sometimes it comes up with a solution that isn't,
[00:23:55.820 --> 00:23:57.400]   in here you'll see another one.
[00:23:57.400 --> 00:23:59.600]   It comes up with a solution that isn't quite
[00:23:59.600 --> 00:24:03.360]   what you'd call as an optimization,
[00:24:03.360 --> 00:24:06.500]   but it does get a solution.
[00:24:06.500 --> 00:24:09.280]   So we're pretty excited by this.
[00:24:09.280 --> 00:24:11.480]   We call this Patrol Route and we're working
[00:24:11.480 --> 00:24:13.800]   on developing a lot of software to support it,
[00:24:13.800 --> 00:24:17.600]   to make it so that other people can capture a patrol route
[00:24:17.600 --> 00:24:20.880]   and then execute them on a routine basis,
[00:24:20.880 --> 00:24:24.800]   and then do other tasks while they're on the patrol route.
[00:24:27.320 --> 00:24:29.360]   Seth, you're on.
[00:24:29.360 --> 00:24:32.180]   So now we'll do a demo of Spot Mini.
[00:24:32.180 --> 00:24:44.760]   So for this demo, Seth's got a joystick
[00:24:44.760 --> 00:24:48.080]   and he's telling it the speed to go
[00:24:48.080 --> 00:24:50.720]   in the forward direction and turning,
[00:24:50.720 --> 00:24:55.360]   but the robot's doing all its own gate selection,
[00:24:55.360 --> 00:25:00.360]   coordination of legs, balance obviously.
[00:25:00.360 --> 00:25:04.200]   So the robot has a bunch of different gates.
[00:25:04.200 --> 00:25:05.080]   It can walk.
[00:25:05.080 --> 00:25:09.320]   Here it's doing one leg at a time.
[00:25:09.320 --> 00:25:14.360]   It can trot.
[00:25:14.360 --> 00:25:16.840]   I don't know, you do whatever gates you want, Seth.
[00:25:16.840 --> 00:25:22.000]   He's gotta use a selected egg.
[00:25:22.000 --> 00:25:25.400]   So here's trotting, which is diagonal pairs of legs.
[00:25:25.400 --> 00:25:28.960]   It can do pacing, which is lateral pairs of legs
[00:25:28.960 --> 00:25:30.560]   to get working together.
[00:25:30.560 --> 00:25:33.440]   I have to tell you, in the earliest days
[00:25:33.440 --> 00:25:35.680]   of me being involved in leg and locomotion,
[00:25:35.680 --> 00:25:37.780]   I thought gate was a big deal,
[00:25:37.780 --> 00:25:40.360]   but it's really kind of a small thing.
[00:25:40.360 --> 00:25:43.580]   And I don't think it's central to what matters,
[00:25:43.580 --> 00:25:46.080]   which is support, stability,
[00:25:46.080 --> 00:25:48.940]   propulsion, and things like that.
[00:25:48.940 --> 00:25:50.180]   I'm gonna wrap up shortly.
[00:25:50.180 --> 00:25:51.880]   I just thought I'd say a couple of words
[00:25:51.880 --> 00:25:54.420]   about the mechanical side.
[00:25:54.420 --> 00:25:59.560]   Atlas is a new version of a humanoid.
[00:25:59.560 --> 00:26:00.840]   I know some of you worked
[00:26:00.840 --> 00:26:03.820]   with the DARPA Robotics Challenge humanoid,
[00:26:03.820 --> 00:26:06.160]   which was a big hulking thing that we made,
[00:26:06.160 --> 00:26:08.580]   and this is a much more svelte one.
[00:26:08.580 --> 00:26:13.020]   And the way we got there was to work on
[00:26:13.020 --> 00:26:18.420]   the elements of the mechanical design
[00:26:18.420 --> 00:26:20.600]   to take advantage of 3D printing
[00:26:20.600 --> 00:26:23.620]   and some optimization.
[00:26:23.620 --> 00:26:26.500]   And we focused on two or three different things.
[00:26:26.500 --> 00:26:29.680]   One is making some of the leg parts
[00:26:29.680 --> 00:26:32.260]   where we embed hydraulic pathways,
[00:26:32.260 --> 00:26:35.180]   hydraulic actuators, places for valve mounts
[00:26:35.180 --> 00:26:37.580]   and filters and things like that into the leg.
[00:26:37.580 --> 00:26:39.220]   And this is what that looks like.
[00:26:39.220 --> 00:26:42.300]   There's a single upper leg part
[00:26:42.300 --> 00:26:45.100]   that incorporated about 15 or 20
[00:26:45.100 --> 00:26:47.960]   different separate components in the previous design,
[00:26:47.960 --> 00:26:50.180]   which made it lighter, more compact,
[00:26:50.180 --> 00:26:53.140]   and higher strength to weight ratio.
[00:26:53.140 --> 00:26:56.880]   We also developed a hydraulic power unit,
[00:26:56.880 --> 00:27:00.620]   which takes many components.
[00:27:00.620 --> 00:27:04.420]   The thing on the left are the components as separate ones.
[00:27:04.420 --> 00:27:07.140]   And we were able to print up parts
[00:27:07.140 --> 00:27:10.020]   that integrated them so that there was a motor,
[00:27:10.020 --> 00:27:13.700]   a pump inside of a motor, an accumulator,
[00:27:13.700 --> 00:27:17.460]   a reservoir, valves, filters, and those things.
[00:27:17.460 --> 00:27:20.260]   And we shrunk it down so that the robot
[00:27:20.260 --> 00:27:22.460]   could be smaller and lighter.
[00:27:22.460 --> 00:27:26.060]   And using that approach, we went from
[00:27:26.060 --> 00:27:31.060]   about a 375 pound DRC robot to a 190 pound robot,
[00:27:31.060 --> 00:27:35.560]   and then the current one is about 165 pounds.
[00:27:35.560 --> 00:27:37.480]   Now this picture might lead you to believe
[00:27:37.480 --> 00:27:41.420]   that I'm advertising myself as only weighing 165 pounds.
[00:27:41.420 --> 00:27:45.200]   And unfortunately that's not true, but I'm working on it.
[00:27:45.480 --> 00:27:47.520]   (audience laughing)
[00:27:47.520 --> 00:27:49.440]   But it is close to my size and weight.
[00:27:49.440 --> 00:27:54.120]   And I don't know, I don't think we have this out as a video.
[00:27:54.120 --> 00:27:59.120]   Here's some robot behavior that uses whole body motion,
[00:27:59.120 --> 00:28:05.440]   meaning the mobility base plus the arms plus the torso
[00:28:05.440 --> 00:28:08.960]   are all combining in order to handle these boxes.
[00:28:08.960 --> 00:28:12.560]   It's using vision with the QR codes to simplify the task.
[00:28:12.560 --> 00:28:16.120]   Here we're trying to go at human speeds of operation,
[00:28:16.120 --> 00:28:20.100]   and so the robot searches for a box using its vision.
[00:28:20.100 --> 00:28:23.100]   (audience laughing)
[00:28:23.100 --> 00:28:28.600]   I think that was the only take we ever got
[00:28:28.600 --> 00:28:31.320]   with both robots working together.
[00:28:31.320 --> 00:28:36.800]   And one of the problems with YouTube
[00:28:36.800 --> 00:28:38.680]   is everybody's already seen what you've been up to
[00:28:38.680 --> 00:28:40.920]   by the time you go around to give a talk,
[00:28:40.920 --> 00:28:43.240]   so I imagine most of you have seen this.
[00:28:43.240 --> 00:28:47.840]   But here's a parkour robot we're working on
[00:28:47.840 --> 00:28:50.820]   where we've actually strengthened the hips
[00:28:50.820 --> 00:28:53.320]   so that it can do a little bit more jumping and--
[00:28:53.320 --> 00:28:58.320]   (audience laughing)
[00:28:58.320 --> 00:29:09.800]   And it's kind of interesting that we've been interested
[00:29:10.360 --> 00:29:13.360]   in making a robot a little bit like the humanoid
[00:29:13.360 --> 00:29:15.740]   that has less degrees of freedom,
[00:29:15.740 --> 00:29:17.760]   fewer degrees of freedom and is simpler,
[00:29:17.760 --> 00:29:19.400]   and we designed this robot,
[00:29:19.400 --> 00:29:22.920]   and the ultimate version of this will have about 10 joints,
[00:29:22.920 --> 00:29:25.880]   whereas the humanoid had 28,
[00:29:25.880 --> 00:29:28.860]   and have many of the same capabilities.
[00:29:28.860 --> 00:29:34.040]   We have some use cases for this
[00:29:34.040 --> 00:29:36.320]   that I'm not gonna talk about today,
[00:29:36.320 --> 00:29:39.040]   but this robot can lift heavy loads.
[00:29:39.040 --> 00:29:40.960]   It has a relatively small footprint
[00:29:40.960 --> 00:29:43.420]   given what its strength is.
[00:29:43.420 --> 00:29:46.600]   So the way things are done in logistics now
[00:29:46.600 --> 00:29:48.800]   is to use big robot arms
[00:29:48.800 --> 00:29:52.000]   that take up a lot of floor area or heavy,
[00:29:52.000 --> 00:29:56.040]   and we're looking at ways of using a robot like this one.
[00:29:56.040 --> 00:30:00.100]   Not exactly this, it's sort of an evolution of this design
[00:30:00.100 --> 00:30:02.720]   in order to do logistics operations.
[00:30:02.720 --> 00:30:07.640]   So I wanna make a pitch to you.
[00:30:07.640 --> 00:30:09.440]   Boston Dynamics is hiring,
[00:30:09.440 --> 00:30:13.760]   and I hope some of you will apply for a job there.
[00:30:13.760 --> 00:30:17.440]   These are, how many is it, six times three.
[00:30:17.440 --> 00:30:22.440]   These are 18 MIT alum that currently work at the company,
[00:30:22.440 --> 00:30:26.020]   many of them for many years,
[00:30:26.020 --> 00:30:27.520]   so I'm sort of making the point
[00:30:27.520 --> 00:30:29.240]   that these people are happy there,
[00:30:29.240 --> 00:30:31.740]   just like you could be,
[00:30:31.740 --> 00:30:34.520]   and I hope you'll look at our website
[00:30:34.520 --> 00:30:37.760]   and see what we're looking for and consider it.
[00:30:37.760 --> 00:30:41.360]   So I'm just gonna wrap up by talking about,
[00:30:41.360 --> 00:30:43.440]   you know, I used to be a professor here
[00:30:43.440 --> 00:30:44.760]   and at Carnegie Mellon,
[00:30:44.760 --> 00:30:46.320]   and when I was a professor,
[00:30:46.320 --> 00:30:48.740]   we used to mostly wrote papers,
[00:30:48.740 --> 00:30:53.200]   and we were excited by how many papers we could write
[00:30:53.200 --> 00:30:57.760]   and how many people cited them in their papers,
[00:30:57.760 --> 00:30:59.280]   but as a company guy,
[00:30:59.280 --> 00:31:03.280]   instead of papers, I think we count YouTube hits,
[00:31:04.120 --> 00:31:06.840]   and instead of citations,
[00:31:06.840 --> 00:31:08.720]   here I wanna tell you what this is,
[00:31:08.720 --> 00:31:10.640]   but most of you probably know.
[00:31:10.640 --> 00:31:17.680]   (audience laughing)
[00:31:18.680 --> 00:31:21.680]   (audience laughing)
[00:31:21.680 --> 00:31:40.080]   So now we count spoofs instead of citations,
[00:31:40.080 --> 00:31:42.780]   and I'm happy to say that we're doing great.
[00:31:42.780 --> 00:31:47.780]   We have about two dozen big dog spoofs.
[00:31:47.780 --> 00:31:49.620]   Here's four of them,
[00:31:49.620 --> 00:31:52.580]   and the upper left is in Akihabara, Japan.
[00:31:52.580 --> 00:31:55.860]   The upper right is a Los Angeles online television show.
[00:31:55.860 --> 00:31:58.260]   It's the Netherlands on the lower left,
[00:31:58.260 --> 00:32:00.880]   and I guess that's Appalachia on the right.
[00:32:00.880 --> 00:32:03.900]   The poor kid doesn't even have a friend
[00:32:03.900 --> 00:32:08.900]   to be in his movie. (audience laughing)
[00:32:08.900 --> 00:32:11.600]   Well, what about Atlas?
[00:32:12.040 --> 00:32:15.040]   (audience laughing)
[00:32:15.040 --> 00:32:17.520]   Can you hear that?
[00:32:17.520 --> 00:32:26.680]   I love you, box. (audience laughing)
[00:32:26.680 --> 00:32:28.720]   Goodnight, box. (audience laughing)
[00:32:28.720 --> 00:32:33.720]   Box. (audience laughing)
[00:32:33.720 --> 00:32:36.360]   Hello, box. (audience laughing)
[00:32:36.360 --> 00:32:38.400]   Do it, do it, I love you.
[00:32:38.400 --> 00:32:41.520]   No. (audience laughing)
[00:32:41.520 --> 00:32:43.040]   Here's another one.
[00:32:43.040 --> 00:32:46.040]   (audience laughing)
[00:32:46.040 --> 00:32:56.180]   (dog barking)
[00:32:56.180 --> 00:32:59.180]   (audience laughing)
[00:32:59.180 --> 00:33:05.060]   All right, where do you want to, mother?
[00:33:05.060 --> 00:33:08.060]   (audience laughing)
[00:33:09.500 --> 00:33:12.660]   (audience applauding)
[00:33:12.660 --> 00:33:23.420]   So we have a big crew working on all these projects.
[00:33:23.420 --> 00:33:24.920]   You've gotten to meet a couple of them here,
[00:33:24.920 --> 00:33:26.780]   but it's really quite a team
[00:33:26.780 --> 00:33:29.240]   and an absolute pleasure to work with.
[00:33:29.240 --> 00:33:31.780]   So anyway, thank you. (audience laughing)
[00:33:31.780 --> 00:33:34.940]   (audience applauding)
[00:33:39.440 --> 00:33:42.580]   - Thanks for the presentation, it was amazing.
[00:33:42.580 --> 00:33:46.500]   What sort of physics simulation, if any,
[00:33:46.500 --> 00:33:47.780]   do you have in your robots?
[00:33:47.780 --> 00:33:52.340]   And do you really think that with the current trend
[00:33:52.340 --> 00:33:55.340]   of neural networks, we can just do end-to-end modeling
[00:33:55.340 --> 00:33:58.940]   of these robots without any sort of notion of physics,
[00:33:58.940 --> 00:34:00.400]   but just neural networks?
[00:34:00.400 --> 00:34:04.140]   - So we have simulators that we've worked on
[00:34:04.140 --> 00:34:08.340]   for a long time, very detailed, in some cases validated.
[00:34:08.340 --> 00:34:11.360]   Validated mean compare the behavior of the simulator
[00:34:11.360 --> 00:34:14.460]   to the physics of ground truth.
[00:34:14.460 --> 00:34:17.980]   And I think they're important for our work
[00:34:17.980 --> 00:34:19.540]   and we use them frequently,
[00:34:19.540 --> 00:34:22.580]   but the end-to-end doesn't ring quite true.
[00:34:22.580 --> 00:34:25.040]   Usually when we use simulation,
[00:34:25.040 --> 00:34:28.680]   the user is knowledgeable about the trade-offs
[00:34:28.680 --> 00:34:30.260]   between doing a physical experiment
[00:34:30.260 --> 00:34:32.180]   and doing a simulated experiment.
[00:34:32.180 --> 00:34:37.180]   And they're usually getting at some specific setup question
[00:34:37.580 --> 00:34:40.220]   rather than the idea that you start at one end.
[00:34:40.220 --> 00:34:43.020]   At least in our experience,
[00:34:43.020 --> 00:34:46.540]   trying to simulate all the subtleties
[00:34:46.540 --> 00:34:50.220]   of the hydraulic actuator, backlash in gears,
[00:34:50.220 --> 00:34:54.900]   flexibility, the non-rigidity in the components,
[00:34:54.900 --> 00:34:59.900]   that's a big undertaking and usually so distracting
[00:34:59.900 --> 00:35:02.440]   that you can't really get on with what you're doing.
[00:35:02.440 --> 00:35:05.300]   So I think we use experiment for those subtleties
[00:35:05.300 --> 00:35:09.800]   and we use simulation for bigger level dynamics questions.
[00:35:09.800 --> 00:35:16.620]   - Hey, would you say mechanical concerns
[00:35:16.620 --> 00:35:21.620]   or computational capability is more of a difficulty
[00:35:21.620 --> 00:35:24.220]   in terms of determining how quickly
[00:35:24.220 --> 00:35:26.900]   you can perform tasks with the robots?
[00:35:26.900 --> 00:35:30.860]   - You know, we like to say that they're equally important.
[00:35:30.860 --> 00:35:33.300]   We now, although we didn't start out this way,
[00:35:33.300 --> 00:35:36.780]   we now have equal strength in our groups
[00:35:36.780 --> 00:35:39.500]   in the mechanical design and implementation
[00:35:39.500 --> 00:35:43.620]   and in the software and controls and sensing.
[00:35:43.620 --> 00:35:46.300]   And I think they all matter.
[00:35:46.300 --> 00:35:47.820]   I think if you try and get by
[00:35:47.820 --> 00:35:51.540]   with just marginally designed hardware,
[00:35:51.540 --> 00:35:53.180]   you don't get much experimental time in
[00:35:53.180 --> 00:35:55.540]   because the thing's broken all the time.
[00:35:55.540 --> 00:35:58.180]   So even though we are rough on our machines,
[00:35:58.180 --> 00:36:02.740]   they mostly keep working because we put a lot of attention
[00:36:02.740 --> 00:36:04.440]   to detail in how they're designed.
[00:36:04.440 --> 00:36:09.020]   But there's still, I think perception is still
[00:36:09.020 --> 00:36:11.100]   a tall pole in the tent.
[00:36:11.100 --> 00:36:14.020]   Certainly if you want to rival human perception,
[00:36:14.020 --> 00:36:16.500]   I don't think we're anywhere near there.
[00:36:16.500 --> 00:36:20.160]   I think the self-driving car stuff is helping.
[00:36:20.160 --> 00:36:21.860]   There's a lot of interesting things happen there.
[00:36:21.860 --> 00:36:24.580]   I think specialized hardware is getting
[00:36:24.580 --> 00:36:28.180]   ASICs and things that could help.
[00:36:28.180 --> 00:36:31.400]   But it's all still needed.
[00:36:31.400 --> 00:36:36.400]   - So you guys have developed various components
[00:36:36.400 --> 00:36:43.520]   that all kind of come together to build one robot.
[00:36:43.520 --> 00:36:45.480]   Have you seen applications for any
[00:36:45.480 --> 00:36:47.000]   of these separate components elsewhere?
[00:36:47.000 --> 00:36:50.960]   So organic design, for example, for the Atlas,
[00:36:50.960 --> 00:36:53.800]   maybe prosthetics or hip replacements
[00:36:53.800 --> 00:36:55.720]   or something like that because there seems to be
[00:36:55.720 --> 00:36:58.120]   a lot of development going on individually
[00:36:58.120 --> 00:36:59.640]   as well as in the big picture.
[00:36:59.640 --> 00:37:01.280]   - I mean, you're asking a very good question.
[00:37:01.280 --> 00:37:04.320]   It was a question in case people couldn't hear is,
[00:37:04.320 --> 00:37:07.440]   aside from the value to the whole robot
[00:37:07.440 --> 00:37:09.160]   of the components we're making,
[00:37:09.160 --> 00:37:11.400]   are the components useful some other way?
[00:37:11.400 --> 00:37:15.500]   And the place where we think it's probably most true
[00:37:15.500 --> 00:37:18.440]   is the specialized hydraulic components we've made,
[00:37:18.440 --> 00:37:21.900]   servo valves and the HPU.
[00:37:21.900 --> 00:37:25.880]   I'm sure we could sell them into other industry.
[00:37:25.880 --> 00:37:29.580]   As a company focus question though,
[00:37:30.980 --> 00:37:32.440]   that's really what it comes to.
[00:37:32.440 --> 00:37:33.760]   Do we really wanna be doing that?
[00:37:33.760 --> 00:37:38.440]   Will that absorb too much time and attention and personnel?
[00:37:38.440 --> 00:37:41.880]   Or do we wanna, our heart is really in building
[00:37:41.880 --> 00:37:43.280]   future generations of robots.
[00:37:43.280 --> 00:37:45.920]   So I think we're gonna probably stay there.
[00:37:45.920 --> 00:37:49.760]   - Thanks.
[00:37:49.760 --> 00:37:52.400]   I was wondering, have you done any research
[00:37:52.400 --> 00:37:55.400]   in regards to getting the robots to perform tasks
[00:37:55.400 --> 00:37:57.760]   involving direct physical contact with humans?
[00:38:00.320 --> 00:38:01.160]   - Nope.
[00:38:01.160 --> 00:38:06.120]   The only thing we've done is we've done teleoperation,
[00:38:06.120 --> 00:38:07.600]   which is not what you mean,
[00:38:07.600 --> 00:38:11.620]   where we have a human moving and the robot copying,
[00:38:11.620 --> 00:38:14.820]   which is very interesting because you can see
[00:38:14.820 --> 00:38:18.700]   that that's a way of showing how fast the robot can be
[00:38:18.700 --> 00:38:21.180]   and how coordinated it can be using a human
[00:38:21.180 --> 00:38:22.920]   for part of the computing.
[00:38:22.920 --> 00:38:25.160]   But we don't have them interacting with people.
[00:38:25.160 --> 00:38:27.600]   I guess the closest is we once did a thing
[00:38:27.600 --> 00:38:31.140]   where a person and a robot picked up a stretcher
[00:38:31.140 --> 00:38:33.460]   and worked together to pick up the stretcher,
[00:38:33.460 --> 00:38:34.800]   but they weren't touching each other.
[00:38:34.800 --> 00:38:38.160]   They were going through the stretcher material.
[00:38:38.160 --> 00:38:40.660]   Do we have plans?
[00:38:40.660 --> 00:38:45.760]   We're really, to be honest, we're really struggling
[00:38:45.760 --> 00:38:49.000]   with coming up with some strong concepts for safety
[00:38:49.000 --> 00:38:50.320]   even without doing that.
[00:38:50.320 --> 00:38:56.680]   Robots, people's first reaction to a robot
[00:38:56.680 --> 00:38:57.800]   and people's first reaction
[00:38:57.800 --> 00:39:00.240]   and how you make a robot safe if there's a problem
[00:39:00.240 --> 00:39:01.360]   don't really work very well.
[00:39:01.360 --> 00:39:02.960]   You can't freeze the robot.
[00:39:02.960 --> 00:39:07.400]   You have to find some, you have to keep them going,
[00:39:07.400 --> 00:39:09.900]   find a way to get into a safer state.
[00:39:09.900 --> 00:39:12.040]   So I think having them in contact with people
[00:39:12.040 --> 00:39:14.360]   is just gonna be harder.
[00:39:14.360 --> 00:39:16.240]   So eventually we want to to help,
[00:39:16.240 --> 00:39:18.920]   you know, to carry, lift the elderly and things like that,
[00:39:18.920 --> 00:39:20.280]   but we're not there yet.
[00:39:20.280 --> 00:39:25.460]   - My question's about the relative rates of progress
[00:39:25.460 --> 00:39:28.160]   in robotics and machine intelligence.
[00:39:28.160 --> 00:39:30.160]   So an economist might maybe measure it
[00:39:30.160 --> 00:39:33.320]   by seeing how much money is going into computing hardware
[00:39:33.320 --> 00:39:36.000]   versus arms and legs, sensors and actuators,
[00:39:36.000 --> 00:39:36.960]   that kind of thing.
[00:39:36.960 --> 00:39:41.400]   So in one possible scenario,
[00:39:41.400 --> 00:39:44.800]   the machine intelligence rushes ahead
[00:39:44.800 --> 00:39:48.920]   and the robots are progressing more slowly
[00:39:48.920 --> 00:39:53.080]   because of kind of slow build test cycle, basically.
[00:39:53.080 --> 00:39:54.520]   It's the real world things.
[00:39:54.520 --> 00:39:56.300]   It's not so easy to get a rapid build test cycle
[00:39:56.300 --> 00:39:57.140]   with a robot.
[00:39:57.140 --> 00:40:00.420]   And in the other scenario,
[00:40:00.420 --> 00:40:03.700]   the robots are more advanced than the machine intelligence
[00:40:03.700 --> 00:40:04.820]   'cause machine intelligence
[00:40:04.820 --> 00:40:06.900]   is just such a conceptually difficult problem.
[00:40:06.900 --> 00:40:08.900]   So in one scenario,
[00:40:08.900 --> 00:40:10.740]   the machines are telling the humans what to do.
[00:40:10.740 --> 00:40:11.660]   In the other scenario,
[00:40:11.660 --> 00:40:14.340]   the humans are telling the machines what to do, if you like.
[00:40:14.340 --> 00:40:17.020]   So do you have any kind of perspective on that whole issue
[00:40:17.020 --> 00:40:20.180]   of the machine intelligence folk gonna rush ahead,
[00:40:20.180 --> 00:40:22.380]   being robots, guys struggling behind,
[00:40:22.380 --> 00:40:25.460]   or the robots gonna get there before the massive problem
[00:40:25.460 --> 00:40:28.000]   of machine intelligence gets solved?
[00:40:28.000 --> 00:40:28.840]   Or maybe somewhere in the middle.
[00:40:28.840 --> 00:40:30.280]   - I think, let's see,
[00:40:30.280 --> 00:40:33.000]   I don't know exactly what you mean by machine intelligence.
[00:40:33.000 --> 00:40:37.240]   Are you talking about having Google do better search?
[00:40:37.240 --> 00:40:39.880]   - So computation in general.
[00:40:39.880 --> 00:40:43.800]   So at the start, I talked about economists measuring sensors,
[00:40:43.800 --> 00:40:46.200]   actuators, and compute hardware.
[00:40:46.200 --> 00:40:49.480]   So that's the kind of split I'm thinking about.
[00:40:49.480 --> 00:40:52.660]   Yeah, I think that it's always been a misconception
[00:40:52.660 --> 00:40:55.640]   that the hardware components by themselves
[00:40:55.640 --> 00:41:02.700]   constitute progress in intelligence or in robot behavior.
[00:41:02.700 --> 00:41:07.300]   I think they're important ingredients, but by themselves.
[00:41:07.300 --> 00:41:09.500]   You know, when I was a graduate student here,
[00:41:09.500 --> 00:41:11.700]   I can remember reading an ad
[00:41:11.700 --> 00:41:16.700]   for an optical character recognition system.
[00:41:17.020 --> 00:41:20.880]   And what the ad said was, you know, we have camera,
[00:41:20.880 --> 00:41:23.960]   we have a thing for holding the paper you're looking at,
[00:41:23.960 --> 00:41:25.820]   all you have to do is write the software.
[00:41:25.820 --> 00:41:28.380]   So it was all done except for you had to write the software.
[00:41:28.380 --> 00:41:33.380]   And you know, the whole problem was there.
[00:41:33.380 --> 00:41:37.380]   So I don't know if I'm answering your question.
[00:41:37.380 --> 00:41:40.040]   You know, robotics is hard.
[00:41:40.040 --> 00:41:42.260]   I think it feels like we're making progress.
[00:41:42.260 --> 00:41:44.560]   If you keep pushing, we keep making progress.
[00:41:44.560 --> 00:41:48.500]   It's not like there's a knee in the curve that we've hit.
[00:41:48.500 --> 00:41:50.660]   But I also think that the rest of the AI world
[00:41:50.660 --> 00:41:52.180]   is making good progress too,
[00:41:52.180 --> 00:41:55.640]   and it's fun being a part of it.
[00:41:55.640 --> 00:41:59.460]   - Hi.
[00:41:59.460 --> 00:42:05.420]   My question is mostly related to security.
[00:42:05.420 --> 00:42:09.100]   So since you are productizing your robots now,
[00:42:10.060 --> 00:42:14.760]   there has been research on the lidars mainly,
[00:42:14.760 --> 00:42:16.920]   where you could spoof a lidar
[00:42:16.920 --> 00:42:21.800]   and the sensor basically cannot see anything.
[00:42:21.800 --> 00:42:24.680]   So are you looking into that as well?
[00:42:24.680 --> 00:42:29.760]   Taking into consideration these awesome robots
[00:42:29.760 --> 00:42:32.720]   that you're building could be in, let's say,
[00:42:32.720 --> 00:42:35.000]   defense, working for the defense as well.
[00:42:35.000 --> 00:42:36.920]   So those are like really harsh environments.
[00:42:36.920 --> 00:42:39.520]   - Yeah, I mean, these are very hard problems.
[00:42:39.520 --> 00:42:42.540]   If someone, if an intelligent adversary
[00:42:42.540 --> 00:42:44.460]   wants to trick the robot,
[00:42:44.460 --> 00:42:48.060]   it's not all that hard these days.
[00:42:48.060 --> 00:42:50.100]   You know, we're working probably the other end
[00:42:50.100 --> 00:42:54.340]   of the problem, you know, trying to do the basics right now.
[00:42:54.340 --> 00:42:58.180]   I don't think, you know, I don't think robots
[00:42:58.180 --> 00:43:02.300]   are gonna be as autonomous in a hostile environment
[00:43:02.300 --> 00:43:05.900]   as people either think or fear
[00:43:05.900 --> 00:43:09.440]   because of how frail they'll still be
[00:43:09.440 --> 00:43:10.840]   until we get further along.
[00:43:10.840 --> 00:43:15.880]   - Hi there. - Hey.
[00:43:15.880 --> 00:43:17.560]   - I wanted to ask about two things
[00:43:17.560 --> 00:43:21.200]   that are going to probably play a big role in adoption.
[00:43:21.200 --> 00:43:22.360]   The first is price.
[00:43:22.360 --> 00:43:24.560]   So if you could speak to the current unit price
[00:43:24.560 --> 00:43:25.960]   of a Spot Mini and how that you think
[00:43:25.960 --> 00:43:27.820]   is going to evolve over time.
[00:43:27.820 --> 00:43:31.320]   And the second is sort of consumer psychology.
[00:43:31.320 --> 00:43:35.720]   I felt like when I saw the test at the end
[00:43:35.720 --> 00:43:37.680]   of the robots wearing, my level of comfort
[00:43:37.680 --> 00:43:40.160]   with it being in my house suddenly shot up.
[00:43:40.160 --> 00:43:41.760]   It seemed way more human.
[00:43:41.760 --> 00:43:44.400]   So I was just thinking about what kinds of experiments
[00:43:44.400 --> 00:43:45.820]   you guys have run, what you've thought about
[00:43:45.820 --> 00:43:47.360]   with respect to making people more comfortable
[00:43:47.360 --> 00:43:49.200]   with robots working around them.
[00:43:49.200 --> 00:43:53.800]   - Yeah, in terms of cost, you know,
[00:43:53.800 --> 00:43:56.720]   we're not saying what this thing costs yet,
[00:43:56.720 --> 00:43:58.940]   but we will later in the year.
[00:43:58.940 --> 00:44:02.300]   We have reduced the cost of this by about a factor of 10
[00:44:02.300 --> 00:44:04.600]   from what the first prototypes cost.
[00:44:04.600 --> 00:44:06.000]   So we're making progress.
[00:44:06.000 --> 00:44:10.200]   In terms of the psychology of robots,
[00:44:10.200 --> 00:44:12.080]   it's been very interesting to watch.
[00:44:12.080 --> 00:44:16.880]   You know, we got branded sort of as robot abusers
[00:44:16.880 --> 00:44:18.980]   because we kicked our robot.
[00:44:18.980 --> 00:44:21.880]   Really what we were doing was trying to show
[00:44:21.880 --> 00:44:23.720]   how good they were at balancing.
[00:44:23.720 --> 00:44:26.080]   And we didn't think we were abusing them.
[00:44:26.080 --> 00:44:28.140]   I have video of me pushing on my daughter
[00:44:28.140 --> 00:44:30.800]   when she's one years old and actually knocking her over,
[00:44:30.800 --> 00:44:32.200]   but that wasn't my goal.
[00:44:32.200 --> 00:44:34.640]   I wanted to kind of test out her balance.
[00:44:34.640 --> 00:44:36.400]   (audience laughing)
[00:44:36.400 --> 00:44:38.960]   I bet you, you know, if you guys have kids
[00:44:38.960 --> 00:44:42.040]   or you're at all that, you've done stuff like that.
[00:44:42.040 --> 00:44:45.720]   So, but we have adjusted a little bit.
[00:44:45.720 --> 00:44:49.120]   And so we don't usually push on the robots in our videos,
[00:44:49.120 --> 00:44:54.000]   despite the one we showed with Andy hockey-sticking
[00:44:54.000 --> 00:44:55.560]   the hand on this thing.
[00:44:55.560 --> 00:44:58.360]   That's why we had the banana peels as a way
[00:44:58.360 --> 00:45:00.960]   to have the robot crash without us being,
[00:45:00.960 --> 00:45:02.520]   having our fingerprints on it.
[00:45:02.520 --> 00:45:08.840]   You know, I guess the other data point I have
[00:45:08.840 --> 00:45:11.520]   is that if you look at the likes and dislikes
[00:45:11.520 --> 00:45:15.120]   on our YouTube videos, we found a way to get
[00:45:15.120 --> 00:45:18.520]   the likes to dislikes ratio much higher
[00:45:18.520 --> 00:45:22.200]   by partly probably by not looking like
[00:45:22.200 --> 00:45:25.640]   we're abusing the robots.
[00:45:25.640 --> 00:45:27.080]   There's probably a long way to go
[00:45:27.080 --> 00:45:28.920]   to make these things really friendly.
[00:45:30.240 --> 00:45:34.160]   And I have to admit there's a little spirit
[00:45:34.160 --> 00:45:37.680]   at our company of being kind of,
[00:45:37.680 --> 00:45:40.720]   you know, it's fun being bad boys in terms of,
[00:45:40.720 --> 00:45:42.680]   you know, just make the robot do cool stuff
[00:45:42.680 --> 00:45:46.540]   and leave the emotions to others.
[00:45:46.540 --> 00:45:50.080]   And certainly the social robots that have so much
[00:45:50.080 --> 00:45:54.480]   going into making them cute, I don't know.
[00:45:54.480 --> 00:45:57.760]   I'm sure we'll have marketing people working on that.
[00:45:57.760 --> 00:45:59.160]   I don't know what else to say.
[00:45:59.160 --> 00:46:01.440]   (audience laughing)
[00:46:01.440 --> 00:46:03.560]   - Hi, I have a general question.
[00:46:03.560 --> 00:46:07.680]   So in terms of research purpose or like practical purpose,
[00:46:07.680 --> 00:46:09.280]   so what are the reasons that we choose
[00:46:09.280 --> 00:46:12.640]   to investigate on this humanoid robot?
[00:46:12.640 --> 00:46:16.480]   So it seems like it cannot run as fast as the cheetah
[00:46:16.480 --> 00:46:20.080]   and it also cannot carry as many stuff as the big dog.
[00:46:20.080 --> 00:46:22.640]   Yeah.
[00:46:22.640 --> 00:46:24.920]   - You're basically saying that the humanoids
[00:46:24.920 --> 00:46:27.200]   don't seem to be as practical in terms of functionality?
[00:46:27.200 --> 00:46:28.920]   - Right, so is it more efficient,
[00:46:28.920 --> 00:46:31.760]   like are the humanoid robots more efficient
[00:46:31.760 --> 00:46:34.800]   than these cheetahs and the big dogs?
[00:46:34.800 --> 00:46:39.800]   - Well, you know, the, so I don't have a good answer.
[00:46:39.800 --> 00:46:43.780]   The motivation for the DRC, the DARPA Robotics Challenge,
[00:46:43.780 --> 00:46:46.640]   which was humanoid robots, was to say
[00:46:46.640 --> 00:46:49.480]   that they wanted to use robots that could go to the places
[00:46:49.480 --> 00:46:51.520]   designed for humans.
[00:46:51.520 --> 00:46:54.680]   And so that's why they used the human form.
[00:46:54.680 --> 00:46:57.080]   And I think, you know, there's an argument there.
[00:46:57.680 --> 00:47:01.880]   It is true that the human form has a lot of complexity
[00:47:01.880 --> 00:47:05.800]   to it because you have very complicated legs in the biped
[00:47:05.800 --> 00:47:08.400]   and they're supporting the weight of the body and the arms,
[00:47:08.400 --> 00:47:11.200]   whereas the quadrupeds can spread all that out.
[00:47:11.200 --> 00:47:17.240]   So I'm sympathetic to your question.
[00:47:17.240 --> 00:47:18.680]   I don't really have an answer.
[00:47:18.680 --> 00:47:22.220]   I can tell you that the public's reaction
[00:47:22.220 --> 00:47:25.520]   to a humanoid robot is off the scale
[00:47:25.520 --> 00:47:28.600]   compared to anything we've done with quadruped robots
[00:47:28.600 --> 00:47:30.240]   for what that's worth.
[00:47:30.240 --> 00:47:33.520]   So we always get a lot of viewership
[00:47:33.520 --> 00:47:35.420]   if we show a humanoid doing something.
[00:47:35.420 --> 00:47:39.320]   But I think it's a question that we will keep addressing.
[00:47:39.320 --> 00:47:41.800]   We are gonna keep pushing on getting the humanoid
[00:47:41.800 --> 00:47:45.160]   to do more and more human-like things,
[00:47:45.160 --> 00:47:47.200]   even though we probably won't commercialize them
[00:47:47.200 --> 00:47:49.400]   as soon as we commercialize the other stuff.
[00:47:49.400 --> 00:47:53.840]   - How do you specify goals?
[00:47:53.840 --> 00:47:56.200]   And although you said earlier that it's expensive
[00:47:56.200 --> 00:47:57.720]   to do simulations and stuff,
[00:47:57.720 --> 00:47:59.200]   do you have any intentions
[00:47:59.200 --> 00:48:01.200]   of doing any deep reinforcement learning?
[00:48:01.200 --> 00:48:02.200]   - What was the last thing you said?
[00:48:02.200 --> 00:48:03.040]   - Do you have any intentions
[00:48:03.040 --> 00:48:04.880]   of doing deep reinforcement learning?
[00:48:04.880 --> 00:48:10.280]   - I'll do the last one first.
[00:48:10.280 --> 00:48:15.560]   I'm sure we will use learning before too long.
[00:48:15.560 --> 00:48:18.400]   I'm not sure whether it'll be deep reinforcement learning
[00:48:18.400 --> 00:48:21.400]   or something else, but mostly we're interested
[00:48:21.400 --> 00:48:25.720]   in optimizing the complicated state space
[00:48:25.720 --> 00:48:27.040]   partitioning we do.
[00:48:27.040 --> 00:48:32.960]   Right now we use, people make very simple decisions
[00:48:32.960 --> 00:48:34.560]   as to how to divide up the space,
[00:48:34.560 --> 00:48:36.200]   and we think that these things could probably
[00:48:36.200 --> 00:48:40.720]   be really improved if we use the learning approach.
[00:48:40.720 --> 00:48:42.720]   So that's probably the first place we'll apply it.
[00:48:42.720 --> 00:48:44.500]   We do a little bit of learning here and there,
[00:48:44.500 --> 00:48:46.840]   but not much compared to how much learning
[00:48:46.840 --> 00:48:48.440]   is talked about out there.
[00:48:48.440 --> 00:48:49.840]   What was the other question?
[00:48:50.040 --> 00:48:51.600]   (man speaking off mic)
[00:48:51.600 --> 00:48:53.360]   How do we specify a goal?
[00:48:53.360 --> 00:48:56.160]   You mean to the robot, or how do we decide as a company?
[00:48:56.160 --> 00:49:03.000]   So I don't think there's any across the board answer.
[00:49:03.000 --> 00:49:06.080]   We write applications, for instance,
[00:49:06.080 --> 00:49:07.940]   for each of these uses.
[00:49:07.940 --> 00:49:11.680]   So for instance, where we were doing the patrol route,
[00:49:11.680 --> 00:49:14.120]   we have an application that has a UI
[00:49:14.120 --> 00:49:17.720]   that lets the user tell it the information it needs.
[00:49:17.720 --> 00:49:21.200]   It can tell it to go ahead and start on the patrol,
[00:49:21.200 --> 00:49:22.620]   and things like that.
[00:49:22.620 --> 00:49:28.840]   For the door, I think there's a button on the controller.
[00:49:28.840 --> 00:49:31.800]   We can show you afterwards if you want.
[00:49:31.800 --> 00:49:34.400]   And you walk the robot up to the door,
[00:49:34.400 --> 00:49:37.120]   where you're steering it, and then you press the button,
[00:49:37.120 --> 00:49:38.960]   and then it starts looking for the door handle,
[00:49:38.960 --> 00:49:40.600]   and it goes through the whole, you know,
[00:49:40.600 --> 00:49:41.800]   it goes through the door.
[00:49:41.800 --> 00:49:44.920]   (man speaking off mic)
[00:49:44.920 --> 00:49:46.640]   But I don't think these answers are fundamental.
[00:49:46.640 --> 00:49:48.640]   I think you could do it lots of different ways.
[00:49:48.640 --> 00:49:50.880]   You know, we're working on all the machinery
[00:49:50.880 --> 00:49:54.240]   coming up from the bottom to be able to do these things.
[00:49:54.240 --> 00:49:55.440]   And then, you know, in some case,
[00:49:55.440 --> 00:49:57.600]   you could have it be buttons on a UI.
[00:49:57.600 --> 00:50:00.680]   It could be an API that's accessed
[00:50:00.680 --> 00:50:03.240]   through some higher level AI.
[00:50:03.240 --> 00:50:06.560]   And we just aren't sweating that part of it at this point.
[00:50:06.560 --> 00:50:12.520]   - Hi, so aside from locomotion,
[00:50:12.520 --> 00:50:14.720]   I can use my body for like, you know,
[00:50:14.720 --> 00:50:17.320]   nonverbal communication to communicate my intentions
[00:50:17.320 --> 00:50:20.560]   and other such things, even though I'm not always aware of it.
[00:50:20.560 --> 00:50:23.880]   And I guess I'm wondering if this is something
[00:50:23.880 --> 00:50:26.560]   that you've considered for these robots.
[00:50:26.560 --> 00:50:27.760]   - I think the closest we've come
[00:50:27.760 --> 00:50:30.680]   is having the robot go like this after the flip,
[00:50:30.680 --> 00:50:32.680]   which was a way of communicating.
[00:50:32.680 --> 00:50:36.120]   We really haven't done anything along those lines.
[00:50:36.120 --> 00:50:38.720]   I'll bet you, though, that people writing code
[00:50:38.720 --> 00:50:41.280]   can interpret a lot of the subtleties of what's,
[00:50:41.280 --> 00:50:42.680]   you know, what's working and what isn't
[00:50:42.680 --> 00:50:44.000]   by looking at things like that.
[00:50:44.000 --> 00:50:46.800]   But the robot isn't trying to communicate that way.
[00:50:46.800 --> 00:50:54.680]   - I have two questions.
[00:50:54.680 --> 00:51:01.760]   How do you make the robots really fast?
[00:51:01.760 --> 00:51:03.160]   - How do we make them fast?
[00:51:03.160 --> 00:51:09.440]   - No, my question is, how did you make them fast?
[00:51:10.360 --> 00:51:14.040]   - I mean, like, the time, how?
[00:51:14.040 --> 00:51:18.800]   - We get a lot of people who are really smart
[00:51:18.800 --> 00:51:23.800]   and good at working together with each other at our lab,
[00:51:23.800 --> 00:51:26.240]   and then they make plans,
[00:51:26.240 --> 00:51:30.400]   and everybody tries to stay on the plan,
[00:51:30.400 --> 00:51:33.280]   and then, you know, pull it together.
[00:51:33.280 --> 00:51:36.680]   Sometimes it doesn't go as fast as we'd like,
[00:51:36.680 --> 00:51:39.560]   especially if we have to buy parts from someone else
[00:51:39.560 --> 00:51:40.920]   and they're slow.
[00:51:40.920 --> 00:51:41.880]   That happens a lot.
[00:51:41.880 --> 00:51:43.760]   No, honestly.
[00:51:43.760 --> 00:51:45.080]   Is that what you mean?
[00:51:45.080 --> 00:51:48.600]   So we don't make them that fast.
[00:51:48.600 --> 00:51:49.960]   You know, we're pretty fast,
[00:51:49.960 --> 00:51:53.960]   you know, usually four or five months to build a new robot,
[00:51:53.960 --> 00:51:57.760]   something like that.
[00:51:57.760 --> 00:51:59.920]   But mostly it's getting people to work together.
[00:51:59.920 --> 00:52:01.360]   What's the other question?
[00:52:01.360 --> 00:52:07.800]   - The other question is, why do the people push the robots?
[00:52:07.800 --> 00:52:09.400]   (audience laughing)
[00:52:09.400 --> 00:52:11.000]   - Why do they push?
[00:52:11.000 --> 00:52:11.920]   Why do they push?
[00:52:11.920 --> 00:52:18.080]   The robots are always balancing themselves,
[00:52:18.080 --> 00:52:21.320]   and so we wanna show that they can balance
[00:52:21.320 --> 00:52:24.600]   by showing that when you knock them,
[00:52:24.600 --> 00:52:26.480]   they still, they don't fall over,
[00:52:26.480 --> 00:52:28.080]   they stay up on their feet.
[00:52:28.080 --> 00:52:29.800]   So we're kind of showing off.
[00:52:29.800 --> 00:52:33.280]   (audience laughing)
[00:52:33.280 --> 00:52:34.580]   Are you building anything?
[00:52:34.580 --> 00:52:36.280]   Why not?
[00:52:36.280 --> 00:52:38.080]   - I don't know.
[00:52:38.080 --> 00:52:38.920]   - You should.
[00:52:39.880 --> 00:52:41.200]   - It's way off.
[00:52:41.200 --> 00:52:42.040]   - Why?
[00:52:42.040 --> 00:52:44.000]   - Way off.
[00:52:44.000 --> 00:52:46.400]   - Where?
[00:52:46.400 --> 00:52:47.240]   In the basement?
[00:52:47.240 --> 00:52:48.800]   - I'm not good at building.
[00:52:48.800 --> 00:52:51.040]   - No, yes you are.
[00:52:51.040 --> 00:52:52.160]   You might think you're not.
[00:52:52.160 --> 00:52:53.640]   - Well, in some games they are.
[00:52:53.640 --> 00:52:55.000]   - You oughta give it a try.
[00:52:55.000 --> 00:52:58.680]   And you're the right age to get started.
[00:52:58.680 --> 00:53:00.080]   - I'm six and a half.
[00:53:00.080 --> 00:53:00.920]   - Perfect.
[00:53:00.920 --> 00:53:03.920]   (audience laughing)
[00:53:08.720 --> 00:53:11.280]   - All right, with that, I think,
[00:53:11.280 --> 00:53:13.280]   please give Mark a big hand.
[00:53:13.280 --> 00:53:14.120]   Thank you very much.
[00:53:14.120 --> 00:53:14.960]   - Thank you.
[00:53:14.960 --> 00:53:16.120]   (audience applauding)

