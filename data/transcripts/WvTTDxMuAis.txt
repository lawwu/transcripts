
[00:00:00.000 --> 00:00:04.400]   Hey, everybody, welcome to Episode 125 of the all in
[00:00:04.400 --> 00:00:09.080]   podcast on a historic day we're taping for 20 really excited
[00:00:09.080 --> 00:00:14.800]   that SpaceX was able to launch Starship and it made it off the
[00:00:14.800 --> 00:00:18.800]   launch pad and incredibly successful today. Day today. We
[00:00:18.800 --> 00:00:21.760]   have of course with us the rain man David Sacks, the Sultan of
[00:00:21.760 --> 00:00:24.760]   Science David Friedberg, and of course, the dictator Chamath
[00:00:24.760 --> 00:00:29.040]   polyapathy. But two special guests are here special guests
[00:00:29.060 --> 00:00:34.000]   Gavin Baker from a tradies How do you pronounce it? A tradies
[00:00:34.000 --> 00:00:37.640]   house a tradies house a tradies if you know Dune, and then
[00:00:37.640 --> 00:00:42.320]   SpaceX board member Antonio grassy as one of the first
[00:00:42.320 --> 00:00:46.120]   investors in SpaceX Antonio big day for you. Maybe you could
[00:00:46.120 --> 00:00:50.920]   just tell the audience what happened today. Why that is so
[00:00:50.920 --> 00:00:52.720]   important in the history of this company.
[00:00:52.720 --> 00:00:56.680]   Well, first of all, thank you guys for letting me come on and
[00:00:56.680 --> 00:00:58.000]   have a little chat with you about this.
[00:00:58.740 --> 00:01:01.620]   Today was extraordinarily important for for SpaceX, I
[00:01:01.620 --> 00:01:06.340]   think for America and for humanity. And the Starship is
[00:01:06.340 --> 00:01:10.900]   the realization of the vision had Elon had 20 years ago 25
[00:01:10.900 --> 00:01:15.620]   years ago, even as a child really to go to Mars. And the
[00:01:15.620 --> 00:01:18.420]   engineers here at SpaceX and only entire team working
[00:01:18.420 --> 00:01:21.860]   extremely hard, or really just to get this this vehicle off the
[00:01:21.860 --> 00:01:24.620]   pad is as you know, I said, right, this is a brand new
[00:01:24.620 --> 00:01:28.220]   vehicle. Everything about it is new. So the engines, the
[00:01:28.220 --> 00:01:32.540]   material science, the structure, the design, all of it new. And
[00:01:32.540 --> 00:01:35.180]   the most important thing here was to get off the pad. So we
[00:01:35.180 --> 00:01:38.180]   collect data. And this technology platform is the
[00:01:38.180 --> 00:01:41.940]   platform that allow us to go to Mars. So from a non engineer
[00:01:41.940 --> 00:01:44.740]   standpoint, why this is important is that what we've
[00:01:44.740 --> 00:01:49.260]   proven with this flight, we got past a point called Max Q,
[00:01:49.260 --> 00:01:52.180]   which is the point at which the vehicle takes maximum stress.
[00:01:52.180 --> 00:01:54.340]   That's how I think about it. I'm sure engineers will tell you a
[00:01:54.340 --> 00:01:56.740]   lot more description to it, or David freebird give you a better
[00:01:56.740 --> 00:01:58.780]   script to it, but it's the most amount of stress in the vehicle,
[00:01:58.780 --> 00:02:02.860]   which means this vehicle will get to orbit. And this is the
[00:02:02.860 --> 00:02:06.460]   vehicle that's going to take us to Mars. So today is the day
[00:02:06.460 --> 00:02:10.140]   that all of the hardworking people at SpaceX accomplished a
[00:02:10.140 --> 00:02:14.380]   goal of making the human race spacefaring. When we look back
[00:02:14.380 --> 00:02:17.420]   in history, I believe this will be the day we mark the
[00:02:17.420 --> 00:02:21.260]   technological development that we broke through with the
[00:02:21.260 --> 00:02:23.900]   technology that broke through and built a vehicle that could
[00:02:23.900 --> 00:02:24.940]   actually go to Mars.
[00:02:24.940 --> 00:02:28.700]   Now, when we look at it, obviously, it didn't make it to
[00:02:28.700 --> 00:02:33.100]   orbit. Maybe you can give some context into what is the typical
[00:02:33.100 --> 00:02:36.980]   lifecycle of a new rocket ship coming out the Falcon, the
[00:02:36.980 --> 00:02:42.020]   original one has done I think 224 missions, 222 of them
[00:02:42.020 --> 00:02:46.420]   successful, I think 160 or so actually landed themselves. Yes.
[00:02:46.420 --> 00:02:49.380]   And so you had two or three mulligans, I think in the
[00:02:49.380 --> 00:02:53.100]   maybe two actually. So what can we expect here? Where are they
[00:02:53.100 --> 00:02:56.220]   going to stack and rack and launch the next one? Antonio,
[00:02:56.220 --> 00:02:59.740]   let's see what's the timeline here to getting to orbit? What
[00:02:59.740 --> 00:03:02.140]   would we expect versus some of the other projects that we've
[00:03:02.140 --> 00:03:03.420]   seen like the Russian rockets?
[00:03:03.420 --> 00:03:08.020]   So look, this is a brand new vehicle. And whenever we develop
[00:03:08.020 --> 00:03:11.940]   brand new vehicle, it takes a long time development. You know,
[00:03:11.940 --> 00:03:15.540]   my understanding all this is, as again, a layman and sort of as a
[00:03:15.540 --> 00:03:17.980]   board member, not an executive here is that it'll take at least
[00:03:17.980 --> 00:03:20.100]   called two or three months, two or three months to really get
[00:03:20.100 --> 00:03:22.260]   the pad rebuilt and get another vehicle back on for testing,
[00:03:22.260 --> 00:03:26.340]   maybe longer. But it's really important to note here that
[00:03:26.340 --> 00:03:29.180]   we've gotten sort of used to the idea that SpaceX launches
[00:03:29.180 --> 00:03:31.220]   rockets and all these rockets come back and all those
[00:03:31.220 --> 00:03:33.940]   vehicles are stable, because the Falcon nine and nine heavy are
[00:03:33.940 --> 00:03:36.660]   so stable. And they're so well engineered. And they're amazing
[00:03:36.660 --> 00:03:39.700]   vehicles, the most reliable vehicles on earth in human
[00:03:39.700 --> 00:03:43.540]   history. This is a brand new vehicle. This was a huge win. I
[00:03:43.540 --> 00:03:46.020]   mean, it was an enormous win for the company, enormous win for
[00:03:46.020 --> 00:03:48.860]   the country, just getting it off the pad and collecting the data.
[00:03:48.860 --> 00:03:51.820]   And now we know it works. We just have to get it stable now
[00:03:51.820 --> 00:03:57.260]   get up to orbit. So it's really it's a hard problem. But it's a
[00:03:57.260 --> 00:04:00.940]   solid problem from here. And the learned here is that this
[00:04:00.940 --> 00:04:01.860]   vehicle does work.
[00:04:01.860 --> 00:04:07.060]   Amazing. Can you guys talk about like, the impact of this
[00:04:07.060 --> 00:04:11.060]   vehicle cost to launch payload, like the big metrics that are
[00:04:11.060 --> 00:04:15.100]   that kind of help realize that outcome? Gavin, I think I saw
[00:04:15.100 --> 00:04:17.180]   you did a bunch of really good tweets on this, you shared some
[00:04:17.180 --> 00:04:20.460]   of the metrics that I thought were really succinct and really
[00:04:20.460 --> 00:04:20.860]   helpful.
[00:04:20.860 --> 00:04:25.020]   Yeah, sure. So when this is, I think it's a long road to full
[00:04:25.020 --> 00:04:30.220]   reusability. You know, the first step will be mechazilla, catching
[00:04:30.220 --> 00:04:35.180]   the booster doesn't doesn't have legs like the Falcon nine. And
[00:04:35.180 --> 00:04:37.460]   then the second step will be landing the Starship, which is
[00:04:37.460 --> 00:04:41.900]   really hard. But once you do that, they should be able to
[00:04:41.900 --> 00:04:46.580]   send over 100 metric tons to orbit at a variable cost of
[00:04:46.580 --> 00:04:51.380]   under $2 million per public data. This these are public
[00:04:51.380 --> 00:04:52.180]   statements.
[00:04:52.180 --> 00:04:55.700]   I would never confirm or deny those statements. This is
[00:04:55.700 --> 00:04:56.340]   Gavin's math.
[00:04:56.340 --> 00:05:00.900]   $2 million is the cost to get 100 tons into orbit. That's
[00:05:00.900 --> 00:05:01.940]   that's the metric.
[00:05:01.940 --> 00:05:05.860]   Variable cost, variable cost. So I think the point Gavin is
[00:05:05.860 --> 00:05:08.940]   making if I might just add is that it is a step function
[00:05:08.940 --> 00:05:12.420]   change. It's not like a small change. It's an enormous change.
[00:05:12.420 --> 00:05:14.820]   Right. Can you compare that to the numbers before for folks to
[00:05:14.820 --> 00:05:15.260]   understand?
[00:05:15.260 --> 00:05:24.420]   The Falcon nine mass to useful orbit is 17 metric tons. And the
[00:05:24.420 --> 00:05:29.940]   variable costs that you know, I, I have seen Elon tweet about is
[00:05:29.940 --> 00:05:35.660]   somewhere around $15 million. So you are lifting more than five
[00:05:35.660 --> 00:05:39.860]   times the mass to orbit. And based on other statements, 100
[00:05:39.860 --> 00:05:43.620]   metric tons is a very conservative estimate. And you
[00:05:43.620 --> 00:05:51.580]   are doing it at call it 10 to 15% of the cost. So this is a,
[00:05:51.580 --> 00:05:55.340]   you know, we can all do the math, but we can envelope it,
[00:05:55.340 --> 00:06:00.660]   you know, roughly a 50x huge change. And this, you know,
[00:06:00.660 --> 00:06:03.780]   massively changes unit economics for Starlink for sending
[00:06:03.780 --> 00:06:08.220]   anything into orbit. And as Antonio said, it's, it's great
[00:06:08.220 --> 00:06:12.620]   for SpaceX, it's great for America, and it's great for, for
[00:06:12.620 --> 00:06:14.820]   everyone. It's great for humanity.
[00:06:14.820 --> 00:06:17.780]   Can you explain how that then translates into going to Mars?
[00:06:17.780 --> 00:06:21.100]   So now we can get 100 tons into orbit for $2 million. What
[00:06:21.100 --> 00:06:24.700]   happens next in terms of like, how that payload capacity and
[00:06:24.700 --> 00:06:29.940]   low cost enables, you know, full transport to Mars. And, you
[00:06:29.940 --> 00:06:31.860]   know, I know that the timelines are tough, but it would be super
[00:06:31.860 --> 00:06:35.220]   helpful to just to translate the orbit concept into the let's go
[00:06:35.220 --> 00:06:35.900]   to Mars concept.
[00:06:35.900 --> 00:06:38.300]   It's important to know that like the size of this thing, it gives
[00:06:38.300 --> 00:06:42.580]   us a scale is the interior space of it is the size of the
[00:06:42.580 --> 00:06:46.380]   International Space Station. So it's a huge amount of tonnage,
[00:06:46.380 --> 00:06:48.780]   just think about all that's going to take to get to Mars,
[00:06:48.780 --> 00:06:52.140]   right, you've got to, you'd have to lift payload into orbit, you
[00:06:52.140 --> 00:06:56.180]   have to, you know, create a base here on the moon or in this
[00:06:56.180 --> 00:06:58.540]   orbit in the earth to actually refill ships and send them out
[00:06:58.540 --> 00:07:01.660]   into space. And this same design will scale up to become the
[00:07:01.660 --> 00:07:05.060]   Mars colonial transport or very similar design. That's why it's
[00:07:05.060 --> 00:07:07.780]   important. And look, the timeline that I don't know, I'm
[00:07:07.780 --> 00:07:10.580]   hoping that it will be while I'm still able to go, that would be
[00:07:10.580 --> 00:07:13.460]   great, physically able to go. But that's really why it's
[00:07:13.460 --> 00:07:16.260]   important to give this as a small version of the same
[00:07:16.260 --> 00:07:19.140]   vehicle we will actually use to go to Mars. And then all the
[00:07:19.140 --> 00:07:21.340]   stuff you have to transport to orbit becomes more more
[00:07:21.340 --> 00:07:25.700]   economic. Because as Gavin just said, we've had, you know, 50 x
[00:07:25.700 --> 00:07:26.980]   kind of reduction in cost.
[00:07:26.980 --> 00:07:30.220]   Can I ask you another question? Sorry, I don't mean to
[00:07:30.300 --> 00:07:32.620]   monopolize the questions. But these are things that I think
[00:07:32.620 --> 00:07:34.780]   are like super important questions, but that a lot of
[00:07:34.780 --> 00:07:39.980]   people often ask, or I hear them asking, but what happens with
[00:07:39.980 --> 00:07:43.020]   the space industry in the near term? So there's this great
[00:07:43.020 --> 00:07:45.740]   long term goal get to Mars, that's a that's a big project.
[00:07:45.740 --> 00:07:49.540]   There'll certainly be funding, I'm sure, to run that project.
[00:07:49.540 --> 00:07:53.140]   But what other economies now emerge as this, this cost down
[00:07:53.140 --> 00:07:56.260]   of 50 x happens? And what else do you think happens besides,
[00:07:56.260 --> 00:07:58.700]   you know, communications and Starlink? Obviously, there's,
[00:07:59.020 --> 00:08:01.220]   that's already a pretty scale business, what other markets can
[00:08:01.220 --> 00:08:03.180]   develop here in the near term? What other economies do you see
[00:08:03.180 --> 00:08:03.700]   happening?
[00:08:03.700 --> 00:08:06.060]   As a result of this cost?
[00:08:06.060 --> 00:08:08.820]   Yeah, I mean, look, Gavin could jump in here too. But the
[00:08:08.820 --> 00:08:11.180]   reality is, once you could take that much mass to orbit, you can
[00:08:11.180 --> 00:08:13.380]   move anything around the planet very quickly, you can kind of go
[00:08:13.380 --> 00:08:15.220]   up, but the Earth's been below you and come down. So
[00:08:15.220 --> 00:08:18.580]   transportation generally changes. You know, if you want to
[00:08:18.580 --> 00:08:22.580]   fly to Tokyo from New York City, it goes from being, you know, a
[00:08:22.580 --> 00:08:25.380]   day trip to a matter of hours. It's extraordinary.
[00:08:25.380 --> 00:08:27.500]   Or a container ship in a couple hours,
[00:08:27.540 --> 00:08:29.580]   kind of everything that's rapid transport around the Earth,
[00:08:29.580 --> 00:08:31.340]   even packages around there, everything gets faster.
[00:08:31.340 --> 00:08:31.740]   Gavin?
[00:08:31.740 --> 00:08:36.780]   Yeah, there will be no more trans Pacific or transatlantic
[00:08:36.780 --> 00:08:41.220]   cargo flights, I think in 5, 6, 7, 8, 10 years, you're gonna need
[00:08:41.220 --> 00:08:45.140]   a big starship fleet to accomplish that. But I think the
[00:08:45.140 --> 00:08:50.100]   transatlantic and trans Pacific aerospace cargo routes go away.
[00:08:50.100 --> 00:08:54.540]   So transportation logistics, I think is a fundamental change,
[00:08:54.580 --> 00:08:57.740]   human transport fundamental change. And then there's all the
[00:08:57.740 --> 00:09:00.140]   knock on effects of building this kind of technology. Look,
[00:09:00.140 --> 00:09:02.580]   the space program, the American space program that took us to
[00:09:02.580 --> 00:09:05.460]   the moon, created the cell phones we use, right? And
[00:09:05.460 --> 00:09:08.420]   there's so much this chip designs, all the technology came
[00:09:08.420 --> 00:09:11.100]   off of that, the same kind of effects we believe will happen
[00:09:11.100 --> 00:09:13.900]   here. So it's hard to predict, but it will be a lot of great
[00:09:13.900 --> 00:09:14.140]   stuff.
[00:09:14.140 --> 00:09:16.340]   Well, and that's kind of the point when you can get payload
[00:09:16.340 --> 00:09:20.140]   up there. Now entrepreneurs can think of a million different
[00:09:20.140 --> 00:09:23.220]   crazy ideas, and affordably put something up there, whether they
[00:09:23.220 --> 00:09:27.540]   want to mine an asteroid, or they have a science project. Now,
[00:09:27.540 --> 00:09:31.740]   1000 flowers, a million flowers can bloom and entrepreneurs can
[00:09:31.740 --> 00:09:33.660]   start thinking about it. And that's already happened to a
[00:09:33.660 --> 00:09:36.740]   certain extent with Falcon, yes, that people are able to come up
[00:09:36.740 --> 00:09:38.820]   with great ideas. Well, I have to say,
[00:09:38.820 --> 00:09:42.900]   and inspiration provides, it does. Yeah, isn't it be here and
[00:09:42.900 --> 00:09:45.060]   feel the inspiration and the just the
[00:09:45.060 --> 00:09:47.500]   joy. I think that's what I was gonna ask you about if you know,
[00:09:47.500 --> 00:09:50.940]   as we wrap here with you to if you could, if you could take
[00:09:50.940 --> 00:09:53.980]   people inside mission control, which we're privileged enough to
[00:09:53.980 --> 00:10:00.020]   be in, the sense of history, and the feeling in that room, if you
[00:10:00.020 --> 00:10:03.700]   could describe it for the audience, what those engineers
[00:10:03.700 --> 00:10:07.660]   were feeling, and what you in fact, felt at that moment,
[00:10:07.660 --> 00:10:08.340]   Antonio, and then
[00:10:08.340 --> 00:10:14.020]   so I would start by juxtaposing with Monday. So we were here
[00:10:14.020 --> 00:10:17.900]   Monday, we're here Monday, Monday, and Monday. I think
[00:10:17.900 --> 00:10:20.780]   there was a real sense of concern, you know, the, the
[00:10:20.780 --> 00:10:22.740]   countdown stopped around 10 minutes, the vehicle, we had a
[00:10:22.740 --> 00:10:27.060]   valve failure, and the valve got stuck open, basically. And we
[00:10:27.060 --> 00:10:29.860]   had to stop and kind of regroup. And by the way, from my
[00:10:29.860 --> 00:10:33.860]   perspective, that's like a solid success, because the vehicle
[00:10:33.860 --> 00:10:36.420]   did not get destroyed in the pad, which is like the number
[00:10:36.420 --> 00:10:40.100]   one thing that happened here. So that's the second. And so that
[00:10:40.100 --> 00:10:43.420]   was kind of Monday. And I think Monday was, yeah, caution and
[00:10:43.420 --> 00:10:44.060]   intensity.
[00:10:44.060 --> 00:10:47.260]   It was a very intense, very intense. Like, can this will
[00:10:47.260 --> 00:10:49.780]   this will this ever happen? Yeah, when will it happen?
[00:10:49.780 --> 00:10:56.300]   Yeah. Today, what I felt in that room was a sense of, there was a
[00:10:56.300 --> 00:11:00.900]   high sense of intensity, a high sense of focus, and also a sense
[00:11:00.900 --> 00:11:01.340]   of
[00:11:01.340 --> 00:11:08.100]   people were excited. There was an excitement about it. It felt
[00:11:08.100 --> 00:11:11.700]   different today, it felt more electric today. They were super
[00:11:11.700 --> 00:11:13.740]   focused, but you could feel the excitement in the room, they
[00:11:13.740 --> 00:11:15.420]   believed it was going to happen, they thought it was highly
[00:11:15.420 --> 00:11:19.820]   probable, and that it was going to work. And when it did work, I
[00:11:19.820 --> 00:11:22.820]   would say it was a sense of elation and joy. And just, you
[00:11:22.820 --> 00:11:26.060]   know, this is this is 20 plus years of work. And, you know,
[00:11:26.060 --> 00:11:28.540]   Elon was here in the room with the engineers, and it just
[00:11:28.540 --> 00:11:32.980]   seemed him light up, seeing the joy that he felt seeing the joy
[00:11:32.980 --> 00:11:37.420]   the engineers felt together, for me. And having been a board
[00:11:37.420 --> 00:11:39.020]   member here in investment for a long time, and sort of been
[00:11:39.020 --> 00:11:43.380]   along this company and seeing develop, it brought a real sense
[00:11:43.380 --> 00:11:46.620]   of hope for what's going to happen to this country and
[00:11:46.620 --> 00:11:50.020]   what's happening to humanity. And it's a joy to my heart.
[00:11:50.020 --> 00:11:53.500]   Yeah. Gavin, do you have any emotional feelings there when
[00:11:53.500 --> 00:11:54.540]   you watch it you want to add?
[00:11:54.540 --> 00:11:57.580]   Yeah, well, I think it's also just what I would always
[00:11:57.580 --> 00:12:02.260]   strikes me when I'm here is this is a sandy spit of land. There
[00:12:02.260 --> 00:12:07.060]   was no power, no electricity, no potable water, you know, no
[00:12:07.060 --> 00:12:11.980]   sewage, no utilities, nothing. And out of this, you know, sandy
[00:12:11.980 --> 00:12:17.660]   spit of desert, you know, on the Gulf of Mexico, a extremely
[00:12:17.660 --> 00:12:21.940]   talented group of engineers, the last five years have lived in,
[00:12:21.940 --> 00:12:27.300]   you know, these, these airstreams, you know, a long way
[00:12:27.300 --> 00:12:32.820]   from a major city. And it is, it is just an amazing place to
[00:12:32.820 --> 00:12:36.980]   visit. And, you know, the sense of commitment. And when you talk
[00:12:36.980 --> 00:12:40.380]   to anyone at SpaceX, anyone here at Starbase, you know, what are
[00:12:40.380 --> 00:12:42.980]   you trying to accomplish? Make humanity multi planetary
[00:12:42.980 --> 00:12:48.180]   species, get to Mars. So just the experience of visiting
[00:12:48.180 --> 00:12:51.460]   Starbase is amazing. Second, I would just say launches are very
[00:12:51.460 --> 00:12:54.820]   visceral. It's shocking if you have not experienced one.
[00:12:54.820 --> 00:12:57.780]   The ground shaking.
[00:12:57.780 --> 00:12:59.620]   Yeah, feeling your chest, you feel it in your chest.
[00:12:59.620 --> 00:13:02.900]   You feel the, yeah, you feel your body shaking like an
[00:13:02.900 --> 00:13:05.180]   earthquake. Yeah, but it doesn't stop.
[00:13:05.180 --> 00:13:08.660]   And it's incredibly dramatic. You know, the rocket, it's going
[00:13:08.660 --> 00:13:12.460]   so slow at first, and then it accelerates. And then you hear
[00:13:12.460 --> 00:13:15.540]   this enormous crackling noise that's, you know, louder than
[00:13:15.540 --> 00:13:19.700]   any concert, louder than any, you know, sports stadium, you
[00:13:19.700 --> 00:13:26.300]   then blast of hot air hits you, you feel it. And I would say, a
[00:13:26.300 --> 00:13:28.860]   lot of people at launches cry, it's a very emotional
[00:13:28.860 --> 00:13:31.180]   experience, often for people who are not.
[00:13:31.180 --> 00:13:32.620]   Yeah, it's hard not to get emotional.
[00:13:32.620 --> 00:13:36.300]   I think just that human beings can accomplish something like
[00:13:36.300 --> 00:13:42.180]   this is amazing. And then what I would just say is, you know,
[00:13:42.180 --> 00:13:45.820]   there was the rocket flew for four minutes, and went through
[00:13:45.820 --> 00:13:50.660]   Max Q, it went to 39 kilometers, the Soviet N1, which was
[00:13:50.660 --> 00:13:55.220]   comparable rocket only reached 12 kilometers. Like the team was
[00:13:55.220 --> 00:13:56.220]   ecstatic.
[00:13:56.220 --> 00:13:58.660]   Yeah, the joy on their faces.
[00:13:58.660 --> 00:14:00.540]   Happy, cheering.
[00:14:00.540 --> 00:14:01.620]   Never seen anything like it.
[00:14:01.620 --> 00:14:04.900]   Yeah, it was awesome. It was very inspirational. And I felt
[00:14:04.900 --> 00:14:07.260]   very, very grateful to be there.
[00:14:07.260 --> 00:14:08.660]   Yeah, incredible.
[00:14:08.660 --> 00:14:09.380]   Yeah.
[00:14:09.380 --> 00:14:11.180]   Can I give you one thought of what I'm feeling right now?
[00:14:11.180 --> 00:14:11.540]   Yeah.
[00:14:11.540 --> 00:14:12.340]   The after effect.
[00:14:12.340 --> 00:14:13.580]   The after effect, afterglow.
[00:14:13.580 --> 00:14:17.500]   It's just an extraordinary sense of gratitude. I mean, there has
[00:14:17.500 --> 00:14:20.660]   been so much sacrifice here. And we witnessed it over 20 years
[00:14:20.660 --> 00:14:24.460]   from Elon, of course, and the amount of just, you know,
[00:14:24.460 --> 00:14:26.980]   unbelievable work done from him and the entire team here at
[00:14:26.980 --> 00:14:30.020]   SpaceX, his engineers, everyone who works here. It's been
[00:14:30.020 --> 00:14:32.260]   extraordinary. And it just really, I'm just deeply
[00:14:32.260 --> 00:14:34.860]   grateful. Incredible and grateful to you all for having
[00:14:34.860 --> 00:14:35.420]   us on. Thank you.
[00:14:35.420 --> 00:14:36.540]   Incredible.
[00:14:36.540 --> 00:14:39.060]   It's great to hear that perspective, because you would
[00:14:39.060 --> 00:14:43.740]   not have gotten it from off the Twitter feed. You know, from the
[00:14:43.740 --> 00:14:44.740]   mainstream media.
[00:14:44.740 --> 00:14:46.500]   David, if you'd come here with us, you could have gotten
[00:14:46.500 --> 00:14:48.900]   Yeah, David, you were invited.
[00:14:48.900 --> 00:14:51.580]   You were invited. You almost we almost shanghaied you from
[00:14:51.580 --> 00:14:54.540]   Miami. There's a new term called starship as opposed to
[00:14:54.540 --> 00:14:56.740]   shanghaied. We're gonna shanghaied you from Miami.
[00:14:56.740 --> 00:14:57.460]   We're gonna starship you.
[00:14:57.460 --> 00:14:58.740]   We're gonna starship you next time.
[00:14:58.780 --> 00:15:02.340]   Yeah, I'm bummed I couldn't be there. But I'm excited to see
[00:15:02.340 --> 00:15:05.780]   how excited you guys are. And just the point I was making is
[00:15:05.780 --> 00:15:08.820]   that when I was reading the mainstream media coverage of
[00:15:08.820 --> 00:15:11.300]   this, it was almost like ghoulish. It was like a type of
[00:15:11.300 --> 00:15:12.900]   glee. It was almost
[00:15:12.900 --> 00:15:13.820]   Unbelievable, right?
[00:15:13.820 --> 00:15:17.340]   that the rocket blew up. But they didn't they didn't really
[00:15:17.340 --> 00:15:19.780]   mention any of the things you're mentioning. I mean, from the
[00:15:19.780 --> 00:15:22.940]   point of view of the people who are there, it was a triumph. And
[00:15:22.940 --> 00:15:25.700]   it was exciting because of the data that was collected and the
[00:15:25.700 --> 00:15:29.140]   fact that this rocket even got off the earth and achieved this
[00:15:29.140 --> 00:15:32.140]   triumph for four minutes, but the media never really conveyed
[00:15:32.140 --> 00:15:34.660]   that. So thank you for giving us perspective that you just would
[00:15:34.660 --> 00:15:37.660]   not have gotten today from the New York Times or other
[00:15:37.660 --> 00:15:38.420]   mainstream media.
[00:15:38.420 --> 00:15:41.820]   And just to add to that, just a little bit of context. You know,
[00:15:41.820 --> 00:15:45.060]   this is an iterative design process with rapid improvement.
[00:15:45.060 --> 00:15:49.100]   This starship had 31 engines that were made over the course
[00:15:49.100 --> 00:15:52.180]   of one year had different tolerances behaved
[00:15:52.180 --> 00:15:56.500]   unpredictable, unpredictably. You know, this was far from the
[00:15:56.500 --> 00:15:58.740]   best starship, the one that's going to launch in three months
[00:15:58.740 --> 00:16:01.540]   or two months or four months or five months or whenever it is,
[00:16:01.540 --> 00:16:06.660]   they've already made over 1000 discrete improvements to it. And
[00:16:06.660 --> 00:16:09.580]   that was before they got all the data for today. And then there's
[00:16:09.580 --> 00:16:11.660]   a starship after that. And after that.
[00:16:11.660 --> 00:16:18.340]   So I think it really is a the what the mainstream media just
[00:16:18.340 --> 00:16:21.900]   failed to understand is the process under which a new rocket
[00:16:21.900 --> 00:16:26.740]   platform is deployed, and how revolutionary this is. They are
[00:16:26.740 --> 00:16:30.380]   iterating at a speed here. That's not what I don't think
[00:16:30.380 --> 00:16:31.660]   people can comprehend.
[00:16:31.660 --> 00:16:34.140]   I mean, on this, that's not important. There's, they don't
[00:16:34.140 --> 00:16:37.980]   care. They don't care. And it was a way to paint somebody who
[00:16:37.980 --> 00:16:40.940]   they dislike and they are threatened by the negative light
[00:16:40.940 --> 00:16:43.540]   that the front page of the Wall Street Journal says SpaceX is
[00:16:43.540 --> 00:16:48.100]   starship explodes shortly after launching uncrewed test flight.
[00:16:48.100 --> 00:16:51.020]   If you take Antonio gracias his explanation, which was
[00:16:51.060 --> 00:16:56.220]   articulate, and transparent and fair, and this headline, you
[00:16:56.220 --> 00:17:00.220]   could not be more further apart on the spectrum of truth.
[00:17:00.220 --> 00:17:03.660]   Antonio just said that this is a day just for the audience of
[00:17:03.660 --> 00:17:06.460]   which there are millions of people now. Antonio said, this
[00:17:06.460 --> 00:17:10.860]   is the day that you look back on when we are multi planetary, as
[00:17:10.860 --> 00:17:15.420]   this Cambrian moment, if you will, this incredible point of
[00:17:15.420 --> 00:17:20.380]   innovation and human ingenuity and teamwork and sacrifice. You
[00:17:20.380 --> 00:17:22.580]   know, Gavin said it as well, just giving up five years of
[00:17:22.580 --> 00:17:24.860]   your life to move in the middle of nowhere, live in an
[00:17:24.860 --> 00:17:28.220]   Airstream trailer. And then the Wall Street Journal was
[00:17:28.220 --> 00:17:29.180]   basically perspective.
[00:17:29.180 --> 00:17:30.300]   The rocket goes,
[00:17:30.300 --> 00:17:32.780]   I mean,
[00:17:32.780 --> 00:17:36.140]   it was just fireworks. It was just a firework display.
[00:17:36.140 --> 00:17:39.380]   I sent a note to my own teacher, I just said, I said,
[00:17:39.380 --> 00:17:43.300]   look, ignore, please ignore the news media. Yeah, it's total BS.
[00:17:43.300 --> 00:17:47.620]   This is a huge success news. It's a huge success. And we
[00:17:47.620 --> 00:17:50.340]   should just step back for a second and enjoy success.
[00:17:50.340 --> 00:17:53.140]   Because part of the problem, the news media is, this is a moment
[00:17:53.140 --> 00:17:55.780]   that should galvanize our country. I mean, it's basically
[00:17:55.780 --> 00:17:59.020]   it is about America, this is an American company. This is about
[00:17:59.020 --> 00:17:59.500]   America.
[00:17:59.500 --> 00:18:03.580]   I think they can't see that it galvanizes, potentially
[00:18:03.580 --> 00:18:07.060]   galvanizes support for a human being that they feel deeply
[00:18:07.060 --> 00:18:08.980]   threatened by. And that's what it all comes down to,
[00:18:08.980 --> 00:18:11.780]   ultimately. And that's what you see in the headlines. That's
[00:18:11.780 --> 00:18:15.220]   why what's so interesting about this is that the behavior of the
[00:18:15.220 --> 00:18:18.380]   mainstream media to now paint this as something unsuccessful
[00:18:18.380 --> 00:18:22.060]   or a joke or rocket goes boom or fireworks. When you look back
[00:18:22.060 --> 00:18:25.340]   on something as meaningful as this, it'll just make them even
[00:18:25.340 --> 00:18:27.540]   less credible. That's what that's unfortunately what
[00:18:27.540 --> 00:18:29.500]   they're doing to themselves is shooting themselves in the foot.
[00:18:29.500 --> 00:18:32.780]   It's pretty sad. Yeah. And this was Wall Street Journal, this
[00:18:32.780 --> 00:18:36.300]   is CNN, New York Times, everybody just painted it as a
[00:18:36.300 --> 00:18:39.460]   failure. And it's like, Oh, here's a collection headlines.
[00:18:39.460 --> 00:18:43.220]   Well done, producer. I mean, literally, you would think if
[00:18:43.220 --> 00:18:46.860]   you read the mainstream media that SpaceX failed, and it
[00:18:46.860 --> 00:18:51.620]   really the when I was talking to Elon months ago about this, you
[00:18:51.620 --> 00:18:54.980]   know, he said, Listen, 5050, we get off the launchpad. Yeah, if
[00:18:54.980 --> 00:18:57.820]   we can get off the launchpad, and we don't blow up the
[00:18:57.820 --> 00:19:00.820]   launchpad, that's a huge success. The fact that this
[00:19:00.820 --> 00:19:03.820]   thing got as far as it is in four minutes, and they got all
[00:19:03.820 --> 00:19:07.420]   that data. And they've got when you see the scale of this
[00:19:07.420 --> 00:19:09.820]   factor, and I hope you all get to come down here and all
[00:19:09.820 --> 00:19:13.820]   Americans get to see this, because for me, you know, and
[00:19:13.820 --> 00:19:17.060]   being friends with Elon for as long as I have, and to watch him
[00:19:17.060 --> 00:19:21.860]   go from the idea of this, and he showed me, I went with Elon to
[00:19:21.860 --> 00:19:25.100]   see the the Horton factory when he was considering renting. And
[00:19:25.100 --> 00:19:28.980]   from that moment to now, to see the suffering that he went
[00:19:28.980 --> 00:19:32.540]   through personally to do this, and the team, the amount of
[00:19:32.540 --> 00:19:37.420]   suffering to get to this point has been so tremendous. But when
[00:19:37.420 --> 00:19:40.580]   you go to the giga factory in Texas, when you see what's
[00:19:40.580 --> 00:19:43.660]   happening here at Starbase, it should let you know that this is
[00:19:43.660 --> 00:19:46.580]   still the greatest country in the world with the greatest
[00:19:46.580 --> 00:19:50.020]   entrepreneurs. And he is truly the greatest entrepreneur of our
[00:19:50.020 --> 00:19:52.500]   lifetime. And I'm not just saying that, because he's my
[00:19:52.500 --> 00:19:55.780]   bestie. I'm saying it because it's objectively true. And when
[00:19:55.780 --> 00:19:59.260]   you see headlines in the press, look at what has been
[00:19:59.260 --> 00:20:02.620]   accomplished. Look at the Tesla's on the road. Look at
[00:20:02.620 --> 00:20:06.860]   what happened with this rocket ship and judge the man by what
[00:20:07.060 --> 00:20:10.740]   has been produced to date and understand, he's going to keep
[00:20:10.740 --> 00:20:14.860]   going. And the team he has inspired is relentless. I spoke,
[00:20:14.860 --> 00:20:18.780]   I sat there on the deck, an hour or two after all this went down.
[00:20:18.780 --> 00:20:23.900]   And I just ate some chips and salsa with a half dozen of the
[00:20:23.900 --> 00:20:27.060]   people who were in mission control. They love the podcast,
[00:20:27.060 --> 00:20:30.380]   they listen to every episode of all in I kid you're not. And they
[00:20:30.380 --> 00:20:33.860]   said, Will you talk about this on all in I said, Well, we talk
[00:20:33.860 --> 00:20:36.620]   about an all in. Thank you for what you've done for humanity.
[00:20:36.620 --> 00:20:40.420]   This is the most inspiring thing I've experienced in my life.
[00:20:40.420 --> 00:20:45.540]   We love you guys, SpaceX. Charge ahead, be relentless as you've
[00:20:45.540 --> 00:20:50.300]   been. And know that despite these absolutely insignificant
[00:20:50.300 --> 00:20:54.660]   headlines, what you're doing is so meaningful to every American
[00:20:54.660 --> 00:20:58.780]   and every human on this planet. Don't stop, go faster, go
[00:20:58.780 --> 00:21:02.540]   harder, be more relentless. We're all sharing and we're in
[00:21:02.540 --> 00:21:06.020]   all of you. This is one topic we can all agree on. This is
[00:21:06.020 --> 00:21:08.860]   something that can galvanize America. This should be an
[00:21:08.860 --> 00:21:13.180]   important we are leading the world again. Yes, we're leading
[00:21:13.180 --> 00:21:16.100]   the world in the space race again. We're going to be on the
[00:21:16.100 --> 00:21:19.020]   moon. We're going to be on Mars. What about Uranus?
[00:21:19.020 --> 00:21:21.020]   You know,
[00:21:21.020 --> 00:21:23.340]   free bird keeps
[00:21:23.340 --> 00:21:28.460]   I love you, brother. Thanks for coming on. Give me a hug over
[00:21:28.460 --> 00:21:32.180]   here. Thanks for coming on. Bye guys. Thanks for coming on.
[00:21:32.180 --> 00:21:34.940]   Guys. See you Gavin. Bye Antonio.
[00:21:34.980 --> 00:21:37.780]   That was great. I'm surprised I beat him off to the punch there.
[00:21:37.780 --> 00:21:41.500]   Yeah. Oh, no, we were all queued up. Tamont was having a moment.
[00:21:41.500 --> 00:21:44.540]   He was like daydreaming about the future and not thinking
[00:21:44.540 --> 00:21:47.460]   about the line. I was taking the number of shares of SpaceX I
[00:21:47.460 --> 00:21:49.780]   know and multiplying it by a guild billion trillion
[00:21:49.780 --> 00:21:53.340]   billion trillion dollars.
[00:21:53.340 --> 00:21:56.820]   Yeah, the rest of us are thinking about humanity,
[00:21:56.820 --> 00:22:00.380]   America, inspiring people, and Chamath's got his like little
[00:22:00.380 --> 00:22:03.780]   calculator out. I'm gonna have like a babushka planes a plane.
[00:22:03.780 --> 00:22:04.380]   It's like
[00:22:04.380 --> 00:22:09.580]   right. It ruined the moment. Make it about you.
[00:22:09.580 --> 00:22:31.460]   I did have a business question about how the starship impacts
[00:22:32.020 --> 00:22:35.740]   starlink very simple. There's a graphic online you can find on
[00:22:35.740 --> 00:22:40.180]   the SpaceX YouTube channel. And they show the starship and it
[00:22:40.180 --> 00:22:43.940]   literally looks like a goddamn PEZ dispenser shooting out the
[00:22:43.940 --> 00:22:49.140]   next version of starlink. And these are you know, without I
[00:22:49.140 --> 00:22:51.660]   don't want to speak about any specifics, but you can you can
[00:22:51.660 --> 00:22:55.180]   watch it spit them out. You can put out more, and they're
[00:22:55.180 --> 00:22:59.020]   obviously going to be more powerful. And if you have seen
[00:22:59.020 --> 00:23:02.460]   the size of the satellite, I have starlink at both houses, the
[00:23:02.460 --> 00:23:05.980]   ski house and my main house as a backup. It's getting scary how
[00:23:05.980 --> 00:23:10.620]   good it is. And if you look at the size of them, and I again, I
[00:23:10.620 --> 00:23:13.900]   don't want to speak about any future products. It's not my
[00:23:13.900 --> 00:23:18.100]   place. But if you see the size getting smaller, there's one or
[00:23:18.100 --> 00:23:21.460]   two things that we all know about technology, cheaper,
[00:23:21.460 --> 00:23:25.940]   faster, better, smaller, just so I would just say if you're if
[00:23:25.940 --> 00:23:28.620]   you're a fan of starlink, just keep those words in mind.
[00:23:28.780 --> 00:23:31.660]   Yeah, it's gonna be pretty amazing what starlink is going
[00:23:31.660 --> 00:23:32.340]   to be able to do.
[00:23:32.340 --> 00:23:35.220]   Yeah, I thought that maybe I read this somewhere that
[00:23:35.220 --> 00:23:41.340]   starship can carry 600 plus satellites, whereas the previous
[00:23:41.340 --> 00:23:44.860]   top of the line rocket, the Falcon nine could only carry
[00:23:44.860 --> 00:23:46.700]   was it like 50 or something or
[00:23:46.700 --> 00:23:49.260]   yeah, a little less, yeah, there's like 3040. So
[00:23:49.260 --> 00:23:52.220]   so you're talking about 20 times the number of satellites can go
[00:23:52.220 --> 00:23:53.900]   up. And at a lower expense.
[00:23:53.900 --> 00:23:58.580]   Yeah. And I guess SpaceX has gotten permission from the FCC
[00:23:58.580 --> 00:24:04.740]   to put up about 12,000 starlink satellites. So you could do
[00:24:04.740 --> 00:24:09.380]   that, you know, with, I guess, just just 20, you know, 20
[00:24:09.380 --> 00:24:10.020]   missions,
[00:24:10.020 --> 00:24:13.220]   the big disruption is going to happen by the end of 2026.
[00:24:13.220 --> 00:24:20.180]   Because this next generation set of licenses, spectrum licenses
[00:24:20.180 --> 00:24:24.340]   that the FCC sold came with a condition that you had to launch
[00:24:24.340 --> 00:24:27.500]   satellite capacity by the end of 2026. I think otherwise you
[00:24:27.500 --> 00:24:30.300]   lose it. Or you have to do your first launch, I think by the end
[00:24:30.300 --> 00:24:33.380]   of 20 to any of the point is that the only company that
[00:24:33.380 --> 00:24:36.620]   actually has the capability to build and to launch is SpaceX.
[00:24:36.620 --> 00:24:38.980]   So they have a complete monopoly. And because they're
[00:24:38.980 --> 00:24:43.860]   advantaging their own solution, it puts everybody else behind
[00:24:43.860 --> 00:24:48.260]   the eight ball. So not only will they probably offer the best
[00:24:48.260 --> 00:24:52.140]   global internet connectivity at every single natural point in
[00:24:52.140 --> 00:24:54.420]   the world that you could be, which is going to be a really
[00:24:54.420 --> 00:24:57.100]   big leap. They're going to do it, Jason, as you said, at a
[00:24:57.100 --> 00:25:01.180]   throughput that's going to surprise people. And it's also
[00:25:01.180 --> 00:25:04.940]   going to render every other existing provider in a really
[00:25:04.940 --> 00:25:07.420]   difficult situation who's like, you know, what is their
[00:25:07.420 --> 00:25:09.620]   alternative, you can't launch with ULA, because they're
[00:25:09.620 --> 00:25:13.180]   inconsistent. You can't launch with Blue Origin, because
[00:25:13.180 --> 00:25:16.820]   they're inconsistent. You can't launch with the Europeans in
[00:25:16.820 --> 00:25:19.100]   general, because they're inconsistent. SpaceX is the only
[00:25:19.100 --> 00:25:21.220]   solution, but then SpaceX is just going to advantage
[00:25:21.220 --> 00:25:24.380]   themselves. And there's nothing illegal about that. So you're
[00:25:24.380 --> 00:25:26.300]   going to be left with a bunch of these existing tele
[00:25:26.580 --> 00:25:29.540]   communications companies in a really difficult spot in the
[00:25:29.540 --> 00:25:32.020]   next couple years. So it's going to be really dynamic space, I
[00:25:32.020 --> 00:25:34.420]   think very much worth paying attention to on sentences
[00:25:34.420 --> 00:25:39.180]   regards the all in community. He's taking a nap, man has not
[00:25:39.180 --> 00:25:42.340]   slept in the last couple days. He's taking a well deserved nap
[00:25:42.340 --> 00:25:46.380]   right now. So hopefully, we'll have them on in a future
[00:25:46.380 --> 00:25:48.100]   episode. Very quickly.
[00:25:48.100 --> 00:25:50.580]   Where are you taping from J Cal? Just curious, where are you
[00:25:50.580 --> 00:25:51.340]   taping from there?
[00:25:51.460 --> 00:25:57.300]   I'm at Starbase. And there are little tiny homes and he lent
[00:25:57.300 --> 00:26:01.020]   us one to stay in here. And yeah, it's because it's just
[00:26:01.020 --> 00:26:03.500]   inspiring to be here. It's been it's been a great experience.
[00:26:03.500 --> 00:26:09.300]   And I've been this is I've been here a couple times. And the
[00:26:09.300 --> 00:26:13.340]   scale of the factory, the ships, and just over the last like they
[00:26:13.340 --> 00:26:15.700]   said the last I've been here a couple times, maybe three or
[00:26:15.700 --> 00:26:20.300]   four years ago, it really is growing exponentially. And the
[00:26:20.300 --> 00:26:24.980]   other really positive thing is, people are driving, again, back
[00:26:24.980 --> 00:26:29.060]   to the enthusiasm in the public. And what you don't see mirrored
[00:26:29.060 --> 00:26:33.300]   in the press, which I think was a really astute point, sacks. I
[00:26:33.300 --> 00:26:36.740]   met a guy who gave me a ride in his golf cart. I was I was late
[00:26:36.740 --> 00:26:39.500]   to a meeting guy says, Hey, are you going somewhere? And I said,
[00:26:39.500 --> 00:26:41.300]   Yeah, because I was literally running down the street trying
[00:26:41.300 --> 00:26:44.660]   to get catch a flight. And the guy drives me in his golf cart.
[00:26:44.660 --> 00:26:47.380]   And I say, Hey, he says, Hey, you here for the launch? I said,
[00:26:47.380 --> 00:26:50.020]   Yeah, I'm here for the lunch. He says, So am I say, Can I ask
[00:26:50.020 --> 00:26:53.620]   you? Do you work for SpaceX? He says, No, I'm just a fan of
[00:26:53.620 --> 00:26:56.340]   Elon's. I'm a fan of SpaceX. And I said, Can I ask you a drove
[00:26:56.340 --> 00:26:58.780]   from his I drove 19 hours to somewhere in Texas, Houston or
[00:26:58.780 --> 00:27:01.940]   something. He drove 19 hours to come here to spend the week to
[00:27:01.940 --> 00:27:05.260]   see the launch. And the crowds here have gotten bigger and
[00:27:05.260 --> 00:27:09.380]   bigger. And there's hundreds of people. I think I call San
[00:27:09.380 --> 00:27:13.540]   Padre Island over here, a little beach community, kind of like a
[00:27:13.540 --> 00:27:18.740]   Las Vegas on the beach or Reno or New Orleans. And they're just
[00:27:18.740 --> 00:27:22.700]   lined up there with cameras. These are Americans. Just
[00:27:22.700 --> 00:27:28.380]   Americans in RVs, in cars, setting up cameras to see
[00:27:28.380 --> 00:27:33.420]   history happen. And it really is truly inspiring. These are just
[00:27:33.420 --> 00:27:37.340]   saw to the earth, normal folk, this isn't the media system,
[00:27:37.340 --> 00:27:41.660]   like affluent people are necessarily just Americans who
[00:27:41.660 --> 00:27:45.980]   who are inspired in and that's I think, what all entrepreneurs
[00:27:46.260 --> 00:27:48.780]   who hear these stories about what's going on down here,
[00:27:48.780 --> 00:27:50.700]   you'll overestimate what you can do in a year, you're going to
[00:27:50.700 --> 00:27:53.660]   underestimate what you can do in 10. And I think that's, you
[00:27:53.660 --> 00:27:55.860]   know, we all know Elon pretty well here and have watched this
[00:27:55.860 --> 00:27:59.700]   journey. They're cooking with oil, they're moving fast. And
[00:27:59.700 --> 00:28:03.140]   the iteration process is extraordinary. And they're
[00:28:03.140 --> 00:28:06.100]   making everything here. And it's Americans making everything that
[00:28:06.100 --> 00:28:10.340]   the tiles I remember being here three years ago, and Elon and I
[00:28:10.340 --> 00:28:12.420]   have two in the morning, we're walking through the factory
[00:28:12.420 --> 00:28:14.740]   while where they were working 24 hours a day trying to figure
[00:28:14.740 --> 00:28:19.340]   out the tiles on Starship to get it back in. And they were making
[00:28:19.340 --> 00:28:22.460]   the tiles themselves. And just trying to figure that for me.
[00:28:22.460 --> 00:28:24.700]   That's the level of detail that's occurring here. And as
[00:28:24.700 --> 00:28:29.100]   Gavin said, there's 1000 different things changing on
[00:28:29.100 --> 00:28:33.140]   each iteration of this. So more great stuff to come. I believe.
[00:28:33.140 --> 00:28:33.660]   Yeah.
[00:28:33.660 --> 00:28:37.460]   That's been another episode of Phil Helmuth mentions his
[00:28:37.460 --> 00:28:39.700]   relationship with Elon. Thanks, everybody for tuning in.
[00:28:42.380 --> 00:28:45.140]   No, I mean, what am I supposed to do? You know, like, I'm sorry
[00:28:45.140 --> 00:28:47.940]   that my friend, you know, started a rocket ship company. I
[00:28:47.940 --> 00:28:51.900]   don't apologize for it. You guys doing great stuff in the world
[00:28:51.900 --> 00:28:55.260]   as well. So do we want to talk about AI? Do we want to go to
[00:28:55.260 --> 00:28:57.860]   this tiger marking down their book? Where would you like to go
[00:28:57.860 --> 00:29:02.020]   gentlemen, we can talk about the Fox settlement with dominion.
[00:29:02.020 --> 00:29:04.500]   That was something you and I talked about last week, sex, I'd
[00:29:04.500 --> 00:29:08.740]   love to get your opinion on that they paid $787 million in this
[00:29:08.740 --> 00:29:12.940]   settlement. For defamation. It didn't go to trial. You were
[00:29:12.940 --> 00:29:16.420]   hoping it would go to trial. How do you feel? I mean, and this is
[00:29:16.420 --> 00:29:20.420]   an extraordinarily large settlement. So yeah, but what do
[00:29:20.420 --> 00:29:22.100]   you what are your thoughts on this? You wanted to see this go
[00:29:22.100 --> 00:29:24.220]   to the mat and go to the Supreme Court and maybe see the laws in
[00:29:24.220 --> 00:29:26.980]   the United States change eventually catch us up on your
[00:29:26.980 --> 00:29:30.700]   reaction to this ginormous fine. Yeah. Yeah. It was a big
[00:29:30.700 --> 00:29:31.500]   speeding ticket. Yeah.
[00:29:31.500 --> 00:29:35.340]   Yeah. Well, it's funny. You call it a speeding ticket. Because
[00:29:35.340 --> 00:29:38.220]   when I saw this reminded me of a scene at the beginning of
[00:29:38.220 --> 00:29:42.140]   apocalypse now, where Martin Sheen says that charging a man
[00:29:42.140 --> 00:29:44.220]   with murder in this place is like handing out speeding
[00:29:44.220 --> 00:29:49.380]   tickets at the Indianapolis 500. I mean, the analogy here is that
[00:29:49.380 --> 00:29:53.420]   the media is so dishonest, whether it's CNN or MSNBC, or
[00:29:53.420 --> 00:29:56.820]   the New York Times, I mean, are constantly inaccurate or
[00:29:56.820 --> 00:30:02.300]   whatever. And, you know, so for this one network to get a fine
[00:30:02.300 --> 00:30:06.220]   of like 800 million, it's like pretty, pretty incredible. I
[00:30:06.220 --> 00:30:08.380]   mean, they should be handing out a lot more of these in my in my
[00:30:08.380 --> 00:30:11.540]   view, not just to Fox. But yeah, look, I would like to see to
[00:30:11.540 --> 00:30:15.380]   that end, I would like to see the standard in your times
[00:30:15.380 --> 00:30:18.180]   versus Sullivan revised by the Supreme Court, the standard is
[00:30:18.180 --> 00:30:23.180]   actual malice. So you have to prove not just that the press
[00:30:23.180 --> 00:30:26.700]   told a lie, but that there was malice behind it. And that's
[00:30:26.700 --> 00:30:29.780]   what this trial would have been about. And Fox, so
[00:30:29.780 --> 00:30:34.540]   what should it change to? Yeah. I think that change to what
[00:30:34.540 --> 00:30:36.420]   would be a better standard in your mind?
[00:30:36.420 --> 00:30:41.700]   I think that if the media makes a mistake, they should have to
[00:30:41.700 --> 00:30:44.060]   correct it. And I would say the correction needs to be at the
[00:30:44.060 --> 00:30:48.900]   same level that they publicize the original story. So if they
[00:30:48.900 --> 00:30:51.460]   make a mistake, if it's untruthful, and it damages
[00:30:51.460 --> 00:30:55.660]   someone's reputation, and they refuse to post a correction,
[00:30:55.660 --> 00:30:59.140]   then I think they should be liable. That seems fair to me.
[00:30:59.140 --> 00:31:02.780]   If you were to put something on page a one, if you were to give
[00:31:02.780 --> 00:31:05.900]   it five minutes at the start of a show on whether it's Rachel
[00:31:05.900 --> 00:31:09.620]   matter or Tucker, whoever makes the mistake can be anybody. If
[00:31:09.620 --> 00:31:11.740]   they made the mistake in the first five minutes top of the
[00:31:11.740 --> 00:31:14.020]   show, they don't get to bury it on the website, they don't get
[00:31:14.020 --> 00:31:17.060]   to bury it on page seven. They got to say it up front. Hey,
[00:31:17.060 --> 00:31:18.980]   listen, we made a mistake. Correct. Here's the mistake.
[00:31:18.980 --> 00:31:20.940]   Yeah, I think it's reasonable.
[00:31:20.940 --> 00:31:23.340]   Correction should get same publicity as the original story.
[00:31:23.340 --> 00:31:26.220]   And by the way, if they correct it, that would be like a safe
[00:31:26.220 --> 00:31:30.060]   harbor. But if they refuse, and they publish a lie, and it
[00:31:30.100 --> 00:31:32.460]   damages somebody, then they should be liable for that.
[00:31:32.460 --> 00:31:35.140]   I think there should also be some that's what I think. But
[00:31:35.140 --> 00:31:37.940]   yeah, I'm in agreement with that. Because there is the trick in
[00:31:37.940 --> 00:31:41.780]   journalism to bury the correction. And there's another
[00:31:41.780 --> 00:31:44.300]   trick that I think needs to be looked at. It's a little more
[00:31:44.300 --> 00:31:51.140]   nuanced, which is somebody makes a mistake, or an accusation in a
[00:31:51.140 --> 00:31:54.780]   publication. And then the next publication says, Oh, the New
[00:31:54.780 --> 00:31:58.780]   York Times, Fox News, CNN said this, but they don't check it
[00:31:58.780 --> 00:32:03.020]   themselves. So they're using another publication as like a
[00:32:03.020 --> 00:32:05.700]   proxy to kind of give them some level of protection, I think
[00:32:05.700 --> 00:32:08.140]   they should have to on a first hand basis, right?
[00:32:08.140 --> 00:32:10.820]   No, that's the game they play. You're right. So they start with
[00:32:10.820 --> 00:32:15.340]   a super shady source. Yeah, that, you know, it just
[00:32:15.340 --> 00:32:18.060]   attributes it to some sort of anonymous source, then the
[00:32:18.060 --> 00:32:21.980]   second, most shady publication quotes that one. And then the
[00:32:21.980 --> 00:32:25.260]   third most shady quotes that and then it goes to the whole food
[00:32:25.260 --> 00:32:28.500]   chain. Yeah. So you're right, reposting something in the echo
[00:32:28.500 --> 00:32:30.300]   chamber, because other publications are doing it.
[00:32:30.300 --> 00:32:33.140]   You're right, that should not be protected. They should have to
[00:32:33.140 --> 00:32:34.540]   their own sourcing, basically.
[00:32:34.540 --> 00:32:37.860]   Yeah, or just some base level of fact checking if you and now if
[00:32:37.860 --> 00:32:41.300]   if you called it Fox opinion, that's slightly different than
[00:32:41.300 --> 00:32:43.420]   calling it Fox News. So maybe the part of this is branding
[00:32:43.420 --> 00:32:47.620]   Chamath or freebird. Germany thoughts on this? Just in
[00:32:47.620 --> 00:32:51.100]   general, Fox, I think has only 4 billion of cash. So they just
[00:32:51.100 --> 00:32:55.140]   spent 20 some odd percent of it paying this off. And if I were a
[00:32:55.140 --> 00:32:57.220]   shareholder, the question I would ask is, did we actually
[00:32:57.220 --> 00:32:59.940]   make enough money to justify having to pay almost $800
[00:32:59.940 --> 00:33:03.980]   million of our cash balance? The answer is probably no. And this
[00:33:03.980 --> 00:33:08.300]   is the first of a bunch of lawsuits that they have. The
[00:33:08.300 --> 00:33:11.300]   next one, which is I think, is like smartomatic, which is
[00:33:11.300 --> 00:33:14.580]   another voting machine company. That's an even bigger lawsuit,
[00:33:14.580 --> 00:33:17.780]   actually, that's a two and a half billion dollar lawsuit. And
[00:33:17.780 --> 00:33:22.340]   so it's, could it be the same outcome and another settlement?
[00:33:22.340 --> 00:33:25.620]   And so now all of a sudden, you would deplete half their cash,
[00:33:26.340 --> 00:33:30.260]   all for a lie to do what at some point, some smart business
[00:33:30.260 --> 00:33:33.020]   governance needs to kick in over at Fox, and they need to realize
[00:33:33.020 --> 00:33:37.580]   that this stuff just doesn't make economic sense. Maybe they
[00:33:37.580 --> 00:33:41.460]   thought it made political and ratings sense, but you can't
[00:33:41.460 --> 00:33:42.940]   justify that when it costs $2 billion.
[00:33:42.940 --> 00:33:46.940]   There is a concept here, I think, sex that is particularly
[00:33:46.940 --> 00:33:50.580]   interesting in Finland. When you get a speeding ticket, speaking
[00:33:50.580 --> 00:33:53.260]   of speeding tickets, your speeding ticket is proportional
[00:33:53.260 --> 00:33:57.820]   to your net worth. And so these NHL players who like to speed
[00:33:57.820 --> 00:34:00.740]   and a Nokia executive, it was given the equivalent and this is
[00:34:00.740 --> 00:34:06.020]   a bit excessive of $103,000 fine for going 45 into 30 zone on his
[00:34:06.020 --> 00:34:10.100]   motorcycle. And an NHL player got a $39,000 fine two years
[00:34:10.100 --> 00:34:13.700]   earlier. I think that this is part of the problem is sometimes
[00:34:13.700 --> 00:34:18.060]   fines don't match the crime and or the they're not proportional
[00:34:18.060 --> 00:34:21.140]   enough for the person to feel them. And so then we kind of can
[00:34:21.140 --> 00:34:24.100]   joke that they're speeding tickets. One very rich person
[00:34:24.100 --> 00:34:27.260]   said to me, you know, when they would, they had watched them
[00:34:27.260 --> 00:34:31.540]   parking, you know, incredibly illegally in a small town. And I
[00:34:31.540 --> 00:34:35.020]   said, you're gonna get a pretty serious ticket. That's in some
[00:34:35.020 --> 00:34:37.620]   pretty gnarly spot to be parking. And they said, Oh, you
[00:34:37.620 --> 00:34:41.460]   mean the VIP parking charge? And I was like, yeah, that kind of
[00:34:41.460 --> 00:34:46.740]   sucks, but okay. So there might be some concept here of a
[00:34:46.740 --> 00:34:50.700]   proportional fine. And I think the EU is starting to work on
[00:34:50.700 --> 00:34:55.060]   that as well. Because, you know, big tech was ignoring this is
[00:34:55.060 --> 00:34:58.860]   going to embolden a lot of people to take matters into
[00:34:58.860 --> 00:35:01.460]   their own hands and sue some of these media companies if the lie
[00:35:01.460 --> 00:35:04.700]   is egregious enough, and it negatively impacts them enough,
[00:35:04.700 --> 00:35:08.180]   I think it would embolden a lot of folks. So, Saks is right that
[00:35:08.180 --> 00:35:12.500]   up until now, most folks haven't done anything about this. But if
[00:35:12.500 --> 00:35:14.860]   you feel like the media has really wronged you in a
[00:35:14.860 --> 00:35:22.420]   meaningful way. There's probably also now a lot of private equity
[00:35:22.420 --> 00:35:25.380]   organizations that would do the lawsuit finance or hedge funds
[00:35:25.380 --> 00:35:27.860]   that would do the lawsuit finance. And so now you're
[00:35:27.860 --> 00:35:30.660]   jilted. Yeah, like you're free rolling it, right. So you you
[00:35:30.660 --> 00:35:33.220]   get one of these folks to pay it, they get 50% of the gains,
[00:35:33.220 --> 00:35:37.100]   you get 25%, the lawyers get 25%. And you go and you litigate.
[00:35:37.100 --> 00:35:41.620]   I'm sure that you'll see more not less because this fine is
[00:35:41.620 --> 00:35:44.700]   it's really big. And again, we don't know the end of all of
[00:35:44.700 --> 00:35:48.460]   these 2020 election hoax shenanigans because this is the
[00:35:48.460 --> 00:35:49.980]   first not the last of these.
[00:35:49.980 --> 00:35:53.700]   I do think it's a really big number. I mean, I did. I did
[00:35:53.700 --> 00:35:57.140]   want the the case to go to all these courts so they could
[00:35:57.140 --> 00:36:00.620]   revise New York Times versus Sullivan. But I do wonder about
[00:36:00.620 --> 00:36:02.780]   the size of this settlement here. It's just it seems
[00:36:02.780 --> 00:36:03.460]   extraordinary.
[00:36:03.460 --> 00:36:04.220]   They paid it.
[00:36:04.220 --> 00:36:06.780]   There was a interest. It's a settlement. Yeah, they
[00:36:06.780 --> 00:36:10.940]   voluntarily agreed to do it. Yeah, absolutely. So. So in any
[00:36:10.940 --> 00:36:13.420]   event, look, I hope to mouth is right that this actually
[00:36:13.420 --> 00:36:16.740]   incentivizes more actions against media companies, because
[00:36:16.740 --> 00:36:19.580]   I think their feet need to be held to the fire. And they need
[00:36:19.580 --> 00:36:22.380]   to do a better job publishing the truth. There was an
[00:36:22.380 --> 00:36:29.060]   interesting thread by a Twitter poster called can a coa do I
[00:36:29.060 --> 00:36:33.260]   don't know if you guys saw this, where he posted an hour of
[00:36:33.260 --> 00:36:39.500]   footage by Democrats and Democratic groups and more
[00:36:39.500 --> 00:36:43.220]   Democrat leading political science experts questioning
[00:36:43.220 --> 00:36:47.100]   whether voting machines could be hacked. Basically, this, this
[00:36:47.100 --> 00:36:51.740]   idea that voting machines could be hacked is not it's not an
[00:36:51.740 --> 00:36:56.380]   allegation that is unique to Fox. So apparently, there's
[00:36:56.380 --> 00:36:59.700]   evidence that Fox knew was bogus. So they definitely
[00:36:59.700 --> 00:37:03.740]   should not have run with it. But I do wonder, hey, why? Why
[00:37:03.740 --> 00:37:05.460]   shouldn't other people be liable for this too?
[00:37:05.460 --> 00:37:09.060]   Well, I mean, the question is, I think those internal text
[00:37:09.060 --> 00:37:13.460]   messages between the host who knowingly knew it was false, and
[00:37:13.460 --> 00:37:15.740]   then we're doing it. I think that's why they they took that
[00:37:15.740 --> 00:37:18.940]   settlement, because 800 million or whatever, or so is a lot less
[00:37:18.940 --> 00:37:21.780]   than 1.4 or 1.5. And so there is speculation that maybe
[00:37:21.780 --> 00:37:23.580]   clearly they got some bad discovery. They got some
[00:37:23.580 --> 00:37:26.460]   discovery problems. Yeah, I'm just saying that problems in
[00:37:26.460 --> 00:37:30.020]   these allegations about electronic voting machines being
[00:37:30.020 --> 00:37:33.660]   hackable or rigged. This seems like an allegation that's been
[00:37:33.660 --> 00:37:36.300]   made. That's actually interesting, not just in 2020.
[00:37:36.300 --> 00:37:39.940]   But it's been made multiple times by whichever side loses.
[00:37:39.940 --> 00:37:44.260]   Yes. So I would wonder why more parties aren't liable for this,
[00:37:44.260 --> 00:37:47.580]   by the way, I never I never bought into I never bought into
[00:37:47.580 --> 00:37:50.220]   those allegations. I said so at the time, I thought they were
[00:37:50.220 --> 00:37:52.900]   bogus. I thought the whole Sidney Powell thing, you know,
[00:37:52.900 --> 00:37:55.780]   the release the Kraken or whatever was ridiculous. So I
[00:37:55.780 --> 00:37:59.620]   don't feel too bad for Fox or anything like that. But it seems
[00:37:59.620 --> 00:38:02.340]   to me, like I'm saying, they're, they're not the only one
[00:38:02.340 --> 00:38:04.940]   speeding here. There's a lot of people who need to get speeding
[00:38:04.940 --> 00:38:07.860]   tickets. Yeah, there is a roadmap for the press to learn
[00:38:07.860 --> 00:38:11.620]   from this and to get better, right? Like to maybe take to
[00:38:11.620 --> 00:38:16.140]   heart that maybe the public now is looking at them and assuming
[00:38:16.140 --> 00:38:19.780]   that the trust in media has is at an all time low Alex Jones
[00:38:19.780 --> 00:38:23.100]   got find a billion dollars, right? It's a judgment, judgment,
[00:38:23.100 --> 00:38:25.980]   a judgment, the Fox things a settlement, right? He got a
[00:38:25.980 --> 00:38:29.660]   judgment of over a billion from multiple courts. Yeah, so he
[00:38:29.660 --> 00:38:33.940]   said a bunch of stuff that, you know, was in court provable to
[00:38:33.940 --> 00:38:37.180]   be false. And then he kind of restated it and he got, you
[00:38:37.180 --> 00:38:40.460]   know, this massive fine. I think there's an interesting question
[00:38:40.460 --> 00:38:46.060]   here on how far this goes with respect to, you know, maybe it
[00:38:46.060 --> 00:38:49.820]   invites the lawsuits, like you guys say, where there's things
[00:38:49.820 --> 00:38:52.820]   that are more on the on the line. And then we really start
[00:38:52.820 --> 00:38:56.180]   to have kind of a tough set of conversations that maybe there
[00:38:56.180 --> 00:38:59.220]   are things that are factually debatable, arguable,
[00:38:59.220 --> 00:39:02.100]   opinionated, where they were true at a certain point, and
[00:39:02.100 --> 00:39:04.940]   then you didn't really have evidence to disprove it. What
[00:39:04.940 --> 00:39:06.820]   are you allowed to say? Are you only allowed to say things that
[00:39:06.820 --> 00:39:09.700]   you've proven or things that haven't been disproven? And that
[00:39:09.700 --> 00:39:11.740]   becomes a pretty tough set of conversations. And what I think
[00:39:11.740 --> 00:39:15.340]   might be interesting from here, if so much of media over time
[00:39:15.340 --> 00:39:19.380]   gets replaced by chat and AI aggregating lots of different
[00:39:19.380 --> 00:39:22.540]   information, synthesizing that and making representations back
[00:39:22.540 --> 00:39:25.780]   to us, and that becomes our primary source of call it news,
[00:39:25.780 --> 00:39:31.100]   or quote media in the future. What happens when those models
[00:39:31.140 --> 00:39:34.700]   or the synthesis of data or the source of the data leads to a
[00:39:34.700 --> 00:39:37.740]   statement that has a similar sort of descent around whether
[00:39:37.740 --> 00:39:40.820]   or not it's true or not? And that you really end up kind of
[00:39:40.820 --> 00:39:44.940]   ending up in a pretty cloudy environment. You know, by
[00:39:44.940 --> 00:39:46.380]   starting starting this process,
[00:39:46.380 --> 00:39:48.580]   I think is a very insightful moment, we'll get to in a
[00:39:48.580 --> 00:39:50.980]   minute, I just coming as a coming from a journalism
[00:39:50.980 --> 00:39:54.300]   background myself, and then becoming a commentator, there
[00:39:54.300 --> 00:39:58.420]   really needs to be three or four very simple things that the
[00:39:58.420 --> 00:40:01.460]   media needs to do. Number one, more fact checking. And number
[00:40:01.460 --> 00:40:04.460]   two, less anonymous sources, it's they rely too much on
[00:40:04.460 --> 00:40:07.340]   anonymous sources. And then there needs to be very clear
[00:40:07.340 --> 00:40:11.580]   delineation between what is a fact and what is an opinion. And
[00:40:11.580 --> 00:40:14.380]   the public is trying to sort this out. Is it Fox News is an
[00:40:14.380 --> 00:40:17.140]   opinion? And what you're saying is this an opinion? Or is this a
[00:40:17.140 --> 00:40:20.740]   fact? Did you do journalism? Or did you just have an opinion? Is
[00:40:20.740 --> 00:40:23.500]   Rachel Maddow an opinion? Or did she actually have a journalist
[00:40:23.500 --> 00:40:27.020]   check these facts? And I think this is where self policing and
[00:40:27.020 --> 00:40:30.660]   maybe rebuilding their rebuilding trust is on the
[00:40:30.660 --> 00:40:33.460]   media, it is now the news and the media's job to rebuild
[00:40:33.460 --> 00:40:37.020]   trust. And if not, they're going to get more fines. But let's get
[00:40:37.020 --> 00:40:40.220]   into, I think some of the stuff we're seeing with AI we had
[00:40:40.220 --> 00:40:44.620]   talked on this show before, many times about the corpus of data,
[00:40:44.620 --> 00:40:48.820]   under which these models are being built, or Reddit announced
[00:40:48.820 --> 00:40:51.700]   plans to start charging companies that uses data training
[00:40:51.700 --> 00:40:55.420]   and models. The co founder Steve Huffman, who came back after
[00:40:55.420 --> 00:40:59.460]   condo, NOS, NASA had bought Reddit and then sold it back to
[00:40:59.460 --> 00:41:03.100]   the founders. And paradoxically, I believe Sam Altman has a major
[00:41:03.100 --> 00:41:05.820]   investment in Reddit, he said more than any other place on the
[00:41:05.820 --> 00:41:08.500]   internet, Reddit is a home for authentic conversations. There's
[00:41:08.500 --> 00:41:11.020]   a lot of stuff on the site that you'd only ever say in therapy,
[00:41:11.020 --> 00:41:13.820]   AI or never at all. A lot of people use pseudonyms,
[00:41:13.820 --> 00:41:17.020]   obviously. And the Reddit corpus of data is incredibly valuable,
[00:41:17.020 --> 00:41:22.140]   but we don't need to give all that value to some of the
[00:41:22.140 --> 00:41:25.500]   largest companies in the world for free. Crawling Reddit
[00:41:25.500 --> 00:41:27.860]   generating revenue and not returning any of the value to
[00:41:27.860 --> 00:41:31.020]   our users is something we have a problem with. It's a good time
[00:41:31.020 --> 00:41:35.380]   for us to tighten things up your thoughts shamath on what we
[00:41:35.380 --> 00:41:37.980]   talked about two different episodes, maybe we'll play drop
[00:41:37.980 --> 00:41:40.500]   a clip in here, Nick, if you want to in post, it's going to
[00:41:40.500 --> 00:41:44.060]   be the large data sets, Cora, Yelp, the App Store reviews,
[00:41:44.060 --> 00:41:47.900]   Amazon's reviews. So there are large corpuses of data that you
[00:41:47.900 --> 00:41:50.740]   would need like Craigslist has famously never allowed anybody
[00:41:50.740 --> 00:41:54.380]   to scrape Craigslist. The amount of data inside Craigslist as but
[00:41:54.380 --> 00:41:57.460]   one example of a data set would be extraordinary to build chat
[00:41:57.460 --> 00:42:01.220]   GPT on chat GPT is not allowed to because you as you brought up
[00:42:01.220 --> 00:42:03.940]   robots dot txt last week, there's going to need to be an
[00:42:03.940 --> 00:42:07.580]   AI dot txt Are you allowed to use my data set in AI and under
[00:42:07.580 --> 00:42:12.900]   and how will I be compensated for it? Will the rights to the
[00:42:12.900 --> 00:42:16.700]   data will will Google just state a Cora Hey, we'll give you a
[00:42:16.700 --> 00:42:19.140]   billion dollars a year for this data set if you don't show
[00:42:19.140 --> 00:42:22.180]   anybody else they should come off. Those were our previous
[00:42:22.180 --> 00:42:24.260]   discussions that we just played. What do you think?
[00:42:24.260 --> 00:42:28.860]   It's so incredible. We are witnessing such an important
[00:42:28.860 --> 00:42:33.980]   moment for Silicon Valley, but frankly, how the world works.
[00:42:33.980 --> 00:42:38.260]   And it's just everything is changing. That's what I'm just
[00:42:38.260 --> 00:42:41.540]   in awe about that. You know, we talked about this. And we were
[00:42:41.540 --> 00:42:45.580]   basically spitballing something two or three months ago. And not
[00:42:45.580 --> 00:42:50.900]   but 60 or 90 days later, these things come to pass. Right? We
[00:42:50.900 --> 00:42:53.860]   talked about something in one week. And then, you know, 14
[00:42:53.860 --> 00:42:58.220]   days later, it's completely upended, like how impressed
[00:42:58.220 --> 00:43:01.620]   sacks was about plugins. And then plugins were rendered
[00:43:01.620 --> 00:43:05.780]   useless, and somewhat impotent two weeks later by auto GPT.
[00:43:05.780 --> 00:43:10.860]   It's just so profound, I think what's going on. So Google
[00:43:10.860 --> 00:43:14.020]   today announced that they're going to merge two organizations
[00:43:14.020 --> 00:43:18.260]   that I thought were so orthogonal to each other,
[00:43:18.260 --> 00:43:22.780]   disparate brain and deep mind. The cultures just seem so
[00:43:22.780 --> 00:43:26.220]   totally different. But now they're merging those two things
[00:43:26.220 --> 00:43:28.100]   together, something that I thought would never happen. They
[00:43:28.100 --> 00:43:32.780]   did it. So all these competitive pressures are so real. I was in
[00:43:32.780 --> 00:43:35.940]   LA, for the breakthrough prize, I was flying home with somebody
[00:43:35.940 --> 00:43:40.340]   on Saturday. I won't say who it is. But they are right at the
[00:43:40.340 --> 00:43:44.620]   bleeding edge of a lot of this AI stuff. And they let go a
[00:43:44.620 --> 00:43:49.780]   third of their company replaced it with an agent within six
[00:43:49.780 --> 00:43:55.820]   weeks of training. So how is this not going to affect
[00:43:55.820 --> 00:44:00.180]   everybody else, I guess is maybe the bigger question. And then I
[00:44:00.180 --> 00:44:03.140]   go back to what I said last week, which is that we've talked
[00:44:03.140 --> 00:44:05.100]   about a lot of the positive things. And I think it's
[00:44:05.100 --> 00:44:08.180]   important to make sure that people understand that there are
[00:44:08.180 --> 00:44:11.140]   a bunch of non trivial negative things. And I think I shared one
[00:44:11.140 --> 00:44:13.940]   on Twitter, which was around this company that use an AI model
[00:44:13.940 --> 00:44:17.660]   to build a library of 40,000 toxic compounds that could kill
[00:44:17.660 --> 00:44:21.380]   all kinds of numbers of humans. So there's all kinds of really,
[00:44:21.380 --> 00:44:24.340]   really tough things going on right now that I think, to me
[00:44:24.340 --> 00:44:27.940]   means it's the moment where I have the least sense of how to
[00:44:27.940 --> 00:44:32.820]   do my job. And so I've tried to kind of like put a pin in
[00:44:32.820 --> 00:44:34.620]   everything and just go back to learning mode.
[00:44:34.620 --> 00:44:36.420]   It's a bit humbling is what you're saying, like,
[00:44:36.460 --> 00:44:39.740]   it's incredibly humbling entire rulebook, even for us as capital
[00:44:39.740 --> 00:44:43.860]   allocators, company formation, it's has you it has you come up
[00:44:43.860 --> 00:44:48.460]   wondering even as I do this, as a CEO, I'm like, should I be
[00:44:48.460 --> 00:44:52.540]   using models to do parts of the workflow inside of my business?
[00:44:52.540 --> 00:44:56.940]   Inside the portfolio companies that were invested in? Am I
[00:44:56.940 --> 00:44:59.620]   supposed to go into the board meeting now on Monday and say,
[00:44:59.620 --> 00:45:05.060]   Hey, XYZ person just did one, two and three, and cut off x by
[00:45:05.060 --> 00:45:10.940]   a third? Do I demand the CEO do that? Do I force change if they
[00:45:10.940 --> 00:45:14.700]   don't do it? Do I say, so I don't I don't I don't exactly
[00:45:14.700 --> 00:45:15.500]   know what to do.
[00:45:15.500 --> 00:45:19.580]   The carousel is spinning increasingly faster, and we're
[00:45:19.580 --> 00:45:20.060]   all on it.
[00:45:20.060 --> 00:45:25.300]   I'll just say a general point. Which I kind of made that this
[00:45:25.300 --> 00:45:29.780]   event today. It feels like the pace of change is so high that
[00:45:29.780 --> 00:45:32.060]   you're kind of in a dust storm, you don't really know where
[00:45:32.060 --> 00:45:35.020]   you're going to end up. So it's very hard to sit as an investor
[00:45:35.020 --> 00:45:37.700]   right now and say, I'm going to pick these things because, you
[00:45:37.700 --> 00:45:41.140]   know, two weeks later, you just don't know whether that path
[00:45:41.140 --> 00:45:44.660]   even exists anymore, because the dust storm washes it away, you
[00:45:44.660 --> 00:45:50.620]   know, blows it away. And I think that there will, as a result,
[00:45:50.620 --> 00:45:54.940]   there will be a lot of money lost by investors by companies
[00:45:54.940 --> 00:46:02.180]   building in this space. Net net, the index for investing in like
[00:46:02.180 --> 00:46:06.740]   dot com companies, the majority, a large amount of money was
[00:46:06.740 --> 00:46:12.660]   lost during that era. But from that era also emerged a handful
[00:46:12.660 --> 00:46:15.900]   of winners. And those winners ended up creating extraordinary
[00:46:15.900 --> 00:46:18.460]   value, I think we're at a point in time right now, where we
[00:46:18.460 --> 00:46:21.980]   could see 10 times the value generated in this phase of
[00:46:21.980 --> 00:46:25.540]   technology advancement than we saw during the internet, and the
[00:46:25.540 --> 00:46:29.060]   advancement of the internet. And if if that is true, I think
[00:46:29.060 --> 00:46:31.540]   you'll end up seeing certainly the same thing happen, which is
[00:46:31.540 --> 00:46:35.860]   the index will lose money. But the few winners will accrue such
[00:46:35.860 --> 00:46:39.940]   extraordinary gains. The problem is, you can't deterministically
[00:46:39.940 --> 00:46:42.540]   pick those winners today, totally because of the dust
[00:46:42.540 --> 00:46:45.340]   storm problem, you just don't know the path totally. So if you
[00:46:45.340 --> 00:46:51.180]   were to meet Jeff Bezos versus some CEO of some.com selling pet
[00:46:51.180 --> 00:46:56.460]   stuff, back in 1995 to 9794 to 97, would you have recognized
[00:46:56.460 --> 00:46:59.020]   Jeff Bezos was going to stand out? Would you have recognized
[00:46:59.020 --> 00:47:00.580]   Larry and Sergey, we're gonna stand out? Would you have
[00:47:00.580 --> 00:47:03.860]   recognized Bill Gates was going to stand out or suck? At the end
[00:47:03.860 --> 00:47:07.260]   of the day, this is harder than it has ever been in terms of
[00:47:07.260 --> 00:47:11.580]   predicting a technology cycle. But what we still know to be
[00:47:11.580 --> 00:47:14.980]   true is that the capital will be allocated within a company, the
[00:47:14.980 --> 00:47:18.740]   operations will be run, managed, and driven and led by an
[00:47:18.740 --> 00:47:20.860]   individual or a set of individuals. And that's
[00:47:20.860 --> 00:47:23.460]   effectively what I think a lot of investing in the cycle is
[00:47:23.460 --> 00:47:25.500]   going to come down to, we're all going to sit here and
[00:47:25.500 --> 00:47:28.380]   pontificate and intellectually masturbate ourselves to some,
[00:47:28.660 --> 00:47:31.300]   you know, genius, you know, path that we think is going to evolve.
[00:47:31.300 --> 00:47:33.940]   And at the end of the day, most of it won't turn out to be true.
[00:47:33.940 --> 00:47:36.700]   And that path won't be real. Because this is such a dynamical
[00:47:36.700 --> 00:47:39.660]   system right now, there are so many feedback loops, one thing
[00:47:39.660 --> 00:47:42.620]   makes one step change, and it changes every other step. But
[00:47:42.620 --> 00:47:46.980]   what we still know is that great leaders can lead, you know, and
[00:47:46.980 --> 00:47:50.420]   especially coming out of this, this Elon discussion, and seeing
[00:47:50.420 --> 00:47:53.420]   the extraordinary achievements he he's delivered, particularly
[00:47:53.420 --> 00:47:57.380]   today. I think that's maybe what a lot of early stage venture is
[00:47:57.380 --> 00:48:00.660]   going to shift to an AI, it's really, you know, finding great
[00:48:00.660 --> 00:48:03.780]   people. And I'll tell you one thing for sure. And I was kind
[00:48:03.780 --> 00:48:07.460]   of commenting on this earlier today was, I really think a lot
[00:48:07.460 --> 00:48:10.020]   of series C and later companies, and I know we're going to talk
[00:48:10.020 --> 00:48:13.300]   about this implosion discussion later, so many of those
[00:48:13.300 --> 00:48:15.620]   companies have a valuation that's less than their
[00:48:15.620 --> 00:48:19.820]   preference stack. And as a result, those founders that work
[00:48:19.820 --> 00:48:22.460]   there, and those employees that are there are getting their
[00:48:22.460 --> 00:48:26.060]   equity wiped out, they'll have to get free bird, can you just
[00:48:26.060 --> 00:48:27.900]   explain what that means technically to the audience?
[00:48:27.900 --> 00:48:31.900]   Probably when you when you when you raise money into a startup,
[00:48:31.900 --> 00:48:35.180]   the investors that give you that money that invest that money,
[00:48:35.180 --> 00:48:39.180]   it's effectively a loan, you owe them that money back first,
[00:48:39.180 --> 00:48:43.100]   before your shares get paid out in the future. So if the company
[00:48:43.100 --> 00:48:45.860]   ends up being worth less than the money that they've invested,
[00:48:45.860 --> 00:48:50.420]   they get the money first. And ultimately, if the company goes
[00:48:50.420 --> 00:48:53.660]   public or get sold, they can convert their what are called
[00:48:53.660 --> 00:48:56.820]   preferred shares into common shares and participate. So even
[00:48:56.820 --> 00:49:01.020]   though you only quote, sold 20% of your company, for let's say
[00:49:01.020 --> 00:49:05.140]   $200 million, that $200 million actually has to get paid first.
[00:49:05.140 --> 00:49:09.220]   So now you've raised this $200 million, the investors, the
[00:49:09.220 --> 00:49:12.500]   company is now repriced, because the market has come down by 80%.
[00:49:12.500 --> 00:49:16.020]   And investors are saying, hey, your company is now worth 175
[00:49:16.020 --> 00:49:19.740]   million, your company is now worth less than what you owe the
[00:49:19.740 --> 00:49:22.580]   pre or the private preferred investors. And if it's worth
[00:49:22.580 --> 00:49:26.300]   less than what you owe, which I think is the case for over 70 or
[00:49:26.300 --> 00:49:29.820]   80% of series C and layer companies. You know, we can kind
[00:49:29.820 --> 00:49:33.620]   of Yeah, and this, but this number comes from what I shared
[00:49:33.620 --> 00:49:37.820]   a few months ago, which is that 70% of publicly traded companies
[00:49:37.820 --> 00:49:40.620]   that went public in the last three years, are trading below
[00:49:40.620 --> 00:49:43.580]   the cash that they've raised. So if you translate that on a one
[00:49:43.580 --> 00:49:46.180]   to one basis to the private market, you know, and these, by
[00:49:46.180 --> 00:49:49.060]   the way, were the best companies actually got public. So in the
[00:49:49.060 --> 00:49:51.060]   private market, you've got to assume that something in that
[00:49:51.060 --> 00:49:54.460]   late stage market is on the order of 70 80% trade is worth
[00:49:54.460 --> 00:49:56.820]   less than their preference stack. So a lot of those
[00:49:56.820 --> 00:49:59.420]   employees are going to run. Those founders don't want to go
[00:49:59.420 --> 00:50:02.140]   work for the VCs when they get recapped and get offered a 4%
[00:50:02.140 --> 00:50:04.620]   are they going to go because it looks like they're going to
[00:50:04.620 --> 00:50:07.500]   start AI companies. And I think that's fantastic. And I think
[00:50:07.500 --> 00:50:10.220]   that's what's really shifting it right now. That's kind of a big
[00:50:10.220 --> 00:50:14.420]   dynamic is a lot of these I'm calling them zombie corns are
[00:50:14.420 --> 00:50:18.060]   going to see this kind of mass exodus of talent. And a lot of
[00:50:18.060 --> 00:50:20.380]   the investors that don't know how to price stuff and don't
[00:50:20.380 --> 00:50:22.900]   want to deal with recaps in the late stage, or diverting their
[00:50:22.900 --> 00:50:25.860]   attention to seed and a and early stuff. And so there's
[00:50:25.860 --> 00:50:29.500]   both a rush of talent and a rush of capital to this kind of very
[00:50:29.500 --> 00:50:33.780]   early stage. And so we'll create this massively bubble iffic, you
[00:50:33.780 --> 00:50:38.140]   know, index of AI stuff, but some number of these things with
[00:50:38.140 --> 00:50:41.020]   some great leaders will emerge and will accrue extraordinary
[00:50:41.020 --> 00:50:42.660]   value across many industries.
[00:50:42.660 --> 00:50:46.020]   I really agree with a lot of what you're saying. The thing to
[00:50:46.020 --> 00:50:50.260]   keep in mind is that the problem with the use of auto GPT is as
[00:50:50.260 --> 00:50:53.260]   an example is that the order of magnitude of capital that you
[00:50:53.260 --> 00:50:56.820]   need has now just gone down. Yeah, yeah, instead of a $10
[00:50:56.820 --> 00:51:00.100]   million Series A. So we used to, you know, people in the height,
[00:51:00.100 --> 00:51:05.740]   we're doing 30 and $40 million Series A's into crazy, very
[00:51:05.740 --> 00:51:10.180]   bubblish ideas and NF T's and all this other stuff. That's
[00:51:10.180 --> 00:51:15.500]   idiotic today. Because a two or three person company can now do
[00:51:15.500 --> 00:51:19.540]   the work of 20 to 30 people. And the amount of capital that they
[00:51:19.540 --> 00:51:24.660]   need is really their salaries, plus the cost of renting some
[00:51:24.660 --> 00:51:29.820]   GPUs on your favorite, pick your cloud. And so all of a sudden,
[00:51:29.820 --> 00:51:33.580]   you can get huge amounts of progress in weeks and months,
[00:51:33.580 --> 00:51:37.820]   with hundreds of 1000s or low millions of dollars. So if you've
[00:51:37.820 --> 00:51:42.020]   raised all of a sudden, a $5 billion fund, because you were
[00:51:42.020 --> 00:51:45.540]   trying to do late stage deals. And now all of a sudden said,
[00:51:45.540 --> 00:51:48.900]   Well, wait, we'll just pivot to early stage. But what are you
[00:51:48.900 --> 00:51:51.300]   going to do find the next 30 person company that's not going
[00:51:51.300 --> 00:51:54.820]   to work because you have to know how to write 500,000 to million
[00:51:54.820 --> 00:51:58.660]   dollar checks with two or three people. And I love it really,
[00:51:58.660 --> 00:52:01.860]   and really help them and really understand their technical
[00:52:01.860 --> 00:52:05.900]   ability to execute, right? Yeah. But then it also quickly becomes
[00:52:05.900 --> 00:52:10.020]   a thing where maybe you're better off just doing 500 of
[00:52:10.020 --> 00:52:14.420]   these two and three person teams. We tried this experiment
[00:52:14.420 --> 00:52:17.540]   seven years ago, this thing called capital as a service
[00:52:17.540 --> 00:52:20.140]   where we were doing this automated investing. I don't
[00:52:20.140 --> 00:52:22.300]   know if you guys remember this, but it was like some machine
[00:52:22.300 --> 00:52:25.700]   learning that we did on all of our portfolio companies. And all
[00:52:25.700 --> 00:52:28.900]   somebody had to do was fill out a form and send us some metrics.
[00:52:28.900 --> 00:52:32.060]   And we would have a machined decision, right? So humans would
[00:52:32.060 --> 00:52:35.260]   not be allowed to make the investment decision. The problem
[00:52:35.260 --> 00:52:37.460]   that we ran into was there was a lot of great companies all
[00:52:37.460 --> 00:52:40.580]   around the world. But the administrative burden of
[00:52:40.580 --> 00:52:45.820]   supporting 500 companies was unbelievably large and
[00:52:45.820 --> 00:52:48.220]   complicated. Oh, you have a company in Indonesia. Well,
[00:52:48.220 --> 00:52:51.500]   there's another company in South Korea. And here's a company and
[00:52:51.500 --> 00:52:54.260]   you know, they're raising a new round, they have to get board
[00:52:54.260 --> 00:52:57.020]   approval, they got to do this and signatures. I mean, it's
[00:52:57.020 --> 00:53:01.380]   hard to scale. Yeah. So so the VC, which is a software light
[00:53:01.380 --> 00:53:04.700]   people heavy artisanal business, all of a sudden becomes
[00:53:04.700 --> 00:53:08.260]   misfactured, right? So you actually need to be highly
[00:53:08.260 --> 00:53:11.740]   automated and use software yourself in order to put 500
[00:53:11.740 --> 00:53:16.660]   three person teams on the field. So this is what I mean by it's
[00:53:16.660 --> 00:53:21.060]   really, I think freebergs use of the term dust storm is a really
[00:53:21.060 --> 00:53:24.460]   good one. It's extremely, extremely confusing what to do.
[00:53:24.460 --> 00:53:29.660]   And if you have large amounts of money that may actually now what
[00:53:29.660 --> 00:53:33.020]   used to be a real differentiator, and a key to
[00:53:33.020 --> 00:53:37.540]   success may actually become an impediment, because you get
[00:53:37.540 --> 00:53:41.740]   reversed, you are forced to do business in a classical way.
[00:53:41.740 --> 00:53:45.540]   That has changed, frankly, in the last 90 days. What do you
[00:53:45.540 --> 00:53:48.180]   think, sex? What's the question? Because we're touching a lot
[00:53:48.180 --> 00:53:51.740]   different things here. Do you feel like this is a dust storm?
[00:53:51.740 --> 00:53:54.980]   And it's murky, and it's just hard to place bets as a capital
[00:53:54.980 --> 00:54:00.780]   allocator? Because something comes out the next day, or 48
[00:54:00.780 --> 00:54:03.460]   hours later, or the next week that takes the previous idea and
[00:54:03.460 --> 00:54:07.420]   wipes it out? And then how do you scale and be capital
[00:54:07.420 --> 00:54:07.820]   efficient?
[00:54:07.820 --> 00:54:11.540]   Well, we're at the early stages of a huge new wave. And I think
[00:54:11.540 --> 00:54:14.060]   that creates a lot of opportunity. So yeah, you've
[00:54:14.060 --> 00:54:17.660]   got to basically separate what's really interesting from the
[00:54:17.660 --> 00:54:21.860]   fool's gold, there's definitely gonna be a lot of that. But at
[00:54:21.860 --> 00:54:26.420]   least there's a reason now to believe that, say, dozens of
[00:54:26.420 --> 00:54:29.940]   unicorns could be created in the next couple of years. So before
[00:54:29.940 --> 00:54:32.340]   we were getting kind of long in the tooth on some of these tech
[00:54:32.340 --> 00:54:35.820]   cycles. I mean, cloud, social, mobile, I mean, there was a
[00:54:35.820 --> 00:54:38.780]   reason to believe that those earlier waves that sort of
[00:54:38.780 --> 00:54:41.580]   played out that the big winners already been determined, and
[00:54:41.580 --> 00:54:44.420]   maybe there wouldn't be too many more big winners in those
[00:54:44.420 --> 00:54:49.420]   spaces. But now we have a whole new catalyst for founders to do
[00:54:49.420 --> 00:54:52.460]   all sorts of new things. And so I tend to think that's super
[00:54:52.460 --> 00:54:55.940]   exciting, you know, we're in the early stages. And I do think
[00:54:55.940 --> 00:55:00.780]   there will be dozens of new unicorns minted in various
[00:55:00.780 --> 00:55:05.820]   aspects of AI could be in AI infrastructure. You know,
[00:55:05.820 --> 00:55:07.380]   whether you're seeing now there's a lot of funding that's
[00:55:07.380 --> 00:55:12.460]   gone into vector databases, or platforms for creating agents.
[00:55:12.460 --> 00:55:17.580]   Or it could be in AI co pilots, basically that tackle various
[00:55:17.780 --> 00:55:21.500]   professional categories and create a co pilot for coders or
[00:55:21.500 --> 00:55:25.300]   co pilot for doctors or lawyers, or architects, I think there's
[00:55:25.300 --> 00:55:29.980]   going to be potentially multiple unicorns created in in those
[00:55:29.980 --> 00:55:33.860]   categories. I think there's going to be SAS software
[00:55:33.860 --> 00:55:36.460]   products that were just good before, but now will actually
[00:55:36.460 --> 00:55:41.940]   be great. Because the incorporation of API's from, you
[00:55:41.940 --> 00:55:45.300]   know, AI foundation models, we'll just turbocharge the
[00:55:45.300 --> 00:55:49.540]   capabilities. And so there's a whole bunch of SAS products that
[00:55:49.540 --> 00:55:54.500]   I think become newly interesting and better, they go from being
[00:55:54.500 --> 00:55:57.740]   vitamins to painkillers. So, you know, we're looking at all those
[00:55:57.740 --> 00:56:00.660]   categories, and I think we'll end up making some bets. But
[00:56:00.660 --> 00:56:03.940]   there's also going to be a lot of companies that are flashes in
[00:56:03.940 --> 00:56:07.380]   the pan or get undermined, you know, there'll be SAS companies
[00:56:07.380 --> 00:56:10.620]   that actually become less attractive because of
[00:56:10.620 --> 00:56:14.140]   disruption from AI. But look, I think all of this, this
[00:56:14.140 --> 00:56:17.060]   maelstrom is great for an investor. I mean, if you're
[00:56:17.060 --> 00:56:19.380]   going to spray and pray, it's not good. You got to be
[00:56:19.380 --> 00:56:23.500]   selective about where you take your shots. But I think this is
[00:56:23.500 --> 00:56:27.020]   the most exciting environment we've been in in a number of
[00:56:27.020 --> 00:56:30.980]   years. I mean, it makes me want to go to work every day and see
[00:56:30.980 --> 00:56:31.580]   it's so funny.
[00:56:31.580 --> 00:56:35.340]   You say that sacks because I literally am looking for an
[00:56:35.340 --> 00:56:39.780]   office space in San Mateo to start like doing the incubator
[00:56:39.780 --> 00:56:43.380]   in person again. And on Monday, I'm having 60 companies come to
[00:56:43.380 --> 00:56:46.300]   San Francisco will be at my attorney's office. And we're
[00:56:46.300 --> 00:56:49.620]   having like a founder university with just all these new startups
[00:56:49.620 --> 00:56:53.460]   that we invested in to just hang out for a day. The enthusiasm
[00:56:53.460 --> 00:56:57.780]   right now is amazing. And what's really unique is the developers
[00:56:57.780 --> 00:57:02.140]   who had three out of seven companies they interviewed with
[00:57:02.140 --> 00:57:06.860]   offer them 150 or 250 k packages, RSU is whatever. Now
[00:57:06.860 --> 00:57:09.380]   there's no offer from Facebook, there's no Apple, there's no
[00:57:09.380 --> 00:57:14.620]   Twitter, there's no Google, or Microsoft offer coming in to be
[00:57:14.620 --> 00:57:17.540]   the backstop against starting a company. So what are they doing?
[00:57:17.540 --> 00:57:20.180]   They're saying, you know what, I got two friends who got laid
[00:57:20.180 --> 00:57:22.980]   off, I got one friend who's halfway out the door, let's just
[00:57:22.980 --> 00:57:25.260]   start something, let's just start something who can give me 100
[00:57:25.260 --> 00:57:30.580]   K who can give me 500 k. And it's, it's, it's so invigorating
[00:57:30.580 --> 00:57:35.020]   to see the talented people, not people who've learned how to,
[00:57:35.020 --> 00:57:38.740]   you know, hack a pitch deck together and tell a story, but
[00:57:38.740 --> 00:57:42.980]   people were actually coding and making MVPs. It's truly
[00:57:42.980 --> 00:57:46.020]   exhilarating right now the amount of two and three person
[00:57:46.020 --> 00:57:49.780]   startups I'm seeing. Yeah. And so while you'll have this, and
[00:57:49.780 --> 00:57:52.460]   it's, it's an incredible, I've never seen this amount of
[00:57:52.460 --> 00:57:55.740]   destruction and creation occurring simultaneously. I love
[00:57:55.740 --> 00:57:59.780]   this zombie concept. You have one half of your portfolio
[00:57:59.780 --> 00:58:04.580]   coming apart at the seams, layoffs, reducing their targets,
[00:58:04.580 --> 00:58:07.820]   while people are coming in the door with products that are
[00:58:07.860 --> 00:58:11.220]   absolutely awe inspiring. I just give one example, I had a
[00:58:11.220 --> 00:58:13.980]   company come out of our founder university, I gave them $25,000
[00:58:13.980 --> 00:58:16.540]   to incorporate a developer and his brother who's a screenplay
[00:58:16.540 --> 00:58:18.900]   writer. They're taking screenplay writing software
[00:58:18.900 --> 00:58:21.180]   sacks, you'll appreciate this having produced two amazing
[00:58:21.180 --> 00:58:23.660]   movies. Thank you for smoking and the dolly film is called
[00:58:23.660 --> 00:58:28.620]   Dolly land. Dolly land. Yeah, coming out in two months.
[00:58:28.620 --> 00:58:31.460]   Coming out two months. Congratulations to me award
[00:58:31.460 --> 00:58:34.020]   winning Oscar winning producer is gonna win an Oscar this time.
[00:58:34.540 --> 00:58:39.340]   He's you know, the screenplay writing tools that have existed,
[00:58:39.340 --> 00:58:42.100]   they're like, what word processors with formatting, what
[00:58:42.100 --> 00:58:45.900]   they're doing is they're saying, hey, write some dialogue. And
[00:58:45.900 --> 00:58:48.700]   then you can have dialogue and say, Hey, make it a little
[00:58:48.700 --> 00:58:51.180]   snappier, make it a little Tarantino ish, make it a little
[00:58:51.180 --> 00:58:56.020]   more, you know, sorkin ish, and then make a storyboard with, you
[00:58:56.020 --> 00:58:59.500]   know, stable diffusion. And I was like, well, this is the
[00:58:59.500 --> 00:59:01.820]   genius idea. I mean, it's unbelievable. Of course, I'll
[00:59:01.820 --> 00:59:04.820]   give you $25,000 for your incorporation. And then they're
[00:59:04.820 --> 00:59:08.060]   coming to the excelling and give another 100k. And in every
[00:59:08.060 --> 00:59:09.740]   single piece of software,
[00:59:09.740 --> 00:59:12.860]   well, that company in success ever raised 25 or $30 million.
[00:59:12.860 --> 00:59:13.660]   Do you think?
[00:59:13.660 --> 00:59:15.820]   No, I think there'll be 12 people. I think it'll be 12
[00:59:15.820 --> 00:59:21.060]   people. I'll give them, but the 25 100k and then our industry
[00:59:21.060 --> 00:59:25.020]   raises $100 billion a year on the premise that each company
[00:59:25.020 --> 00:59:28.500]   before they become a unicorn will absorb between 500 and a
[00:59:28.500 --> 00:59:29.420]   billion dollars.
[00:59:29.900 --> 00:59:33.660]   Yeah, I'm gonna own 20% 10 to 20% of the company for low
[00:59:33.660 --> 00:59:35.620]   millions. And, and we'll see
[00:59:35.620 --> 00:59:39.780]   mid journey is 12 people and no, it's totally bootstrapped. Like,
[00:59:39.780 --> 00:59:43.660]   I guess what I'm saying is, because in the world of AI, so
[00:59:43.660 --> 00:59:47.660]   much work is done for you for free. This is why I'm asking,
[00:59:47.660 --> 00:59:50.100]   maybe we will have to change how we do business.
[00:59:50.100 --> 00:59:52.620]   On the Hollywood example, there's about to be a Writers
[00:59:52.620 --> 00:59:55.860]   Guild strike. And they may want to think twice about that.
[00:59:55.860 --> 00:59:58.940]   Because this is not the time where you want to be
[00:59:58.940 --> 01:00:02.300]   encouraging the industry to find alternatives to writers.
[01:00:02.300 --> 01:00:04.700]   You want to get back in the office and you want to say, Hey,
[01:00:04.700 --> 01:00:07.380]   can I could Is there any other work I can do this weekend, boss?
[01:00:07.380 --> 01:00:10.580]   Did you see the news about BuzzFeed today? They had won a
[01:00:10.580 --> 01:00:14.020]   Pulitzer. They just shut down BuzzFeed news, the entire news
[01:00:14.020 --> 01:00:18.900]   division gone. Another 15% gone, the layoffs and then there was a
[01:00:18.900 --> 01:00:21.500]   report this week that Zuckerberg is doing his third round of
[01:00:21.500 --> 01:00:26.660]   layoffs, another 4000 people that puts him at 24,000. Yeah,
[01:00:26.660 --> 01:00:27.980]   with a hiring freeze.
[01:00:28.020 --> 01:00:30.740]   So the way I describe the current funding environment is
[01:00:30.740 --> 01:00:33.420]   it's a tale of two cities. It's the best of times, it's the
[01:00:33.420 --> 01:00:38.660]   worst of times. If you're a hot AI startup that's able to tap
[01:00:38.660 --> 01:00:42.180]   into the zeitgeist, that's doing something that's perceived as
[01:00:42.180 --> 01:00:45.740]   cutting edge or relevant, there's a strong why now and
[01:00:45.740 --> 01:00:48.060]   you're early, you know, you're early stage, you're able to
[01:00:48.060 --> 01:00:50.900]   raise money for that the spigot is turned back on, there's a lot
[01:00:50.900 --> 01:00:54.420]   of funding for those types of early stage startups. But if
[01:00:54.420 --> 01:00:58.380]   you're a series C stage startup, you're a late stage startup with
[01:00:58.380 --> 01:01:02.580]   a it's called a pre AI model. The spigot is just turned off
[01:01:02.580 --> 01:01:06.700]   completely. I mean, let's look at that chart from crunch base
[01:01:06.700 --> 01:01:11.500]   where the amount of series C funding has gone from something
[01:01:11.500 --> 01:01:16.460]   like 10 billion a quarter last year to like zero. I mean, this
[01:01:16.460 --> 01:01:21.140]   is hardly, I thought this was an error in the chart. Look at this
[01:01:21.140 --> 01:01:23.860]   chart, everybody's seriously funding to us companies by
[01:01:23.860 --> 01:01:26.740]   quarter, there is just no growth stage funding is just completely
[01:01:26.740 --> 01:01:28.860]   dried up. I mean, look at that.
[01:01:28.860 --> 01:01:33.660]   I mean, it got cut in a half, and then it got cut in half
[01:01:33.660 --> 01:01:38.540]   again. And then it just flatlined. So this is your
[01:01:38.540 --> 01:01:40.900]   thesis. Let me ask you this. Is your thesis here that people
[01:01:40.900 --> 01:01:43.620]   aren't trying to raise money, and they're just busy cutting
[01:01:43.620 --> 01:01:46.180]   their companies down to a smaller team size, and they'll
[01:01:46.180 --> 01:01:49.820]   come back out in the second half of the year? Or that anybody
[01:01:49.820 --> 01:01:52.340]   with that amount of dry powder is out of the game now?
[01:01:52.420 --> 01:01:57.460]   Yeah, I think that we're in this awkward stage where the, the
[01:01:57.460 --> 01:02:01.740]   companies who raise money and call it 2020 and 2021, all those
[01:02:01.740 --> 01:02:05.900]   valuations are obsolete. And you've had a lot of late stage
[01:02:05.900 --> 01:02:08.980]   players leave the game, or they're in the penalty box or in
[01:02:08.980 --> 01:02:11.660]   timeout. I mean, look at tiger, for example, the single most
[01:02:11.660 --> 01:02:15.540]   active funder at late stage is trying to figure out how much to
[01:02:15.540 --> 01:02:18.740]   mark down his portfolio. So I just think that a lot of the
[01:02:18.740 --> 01:02:20.980]   funding has dried up there. This idea that there's tons of dry
[01:02:20.980 --> 01:02:23.940]   powder sitting out there, I think is a myth. Or maybe it's
[01:02:23.940 --> 01:02:26.300]   there, but there's no willingness to deploy it. The
[01:02:26.300 --> 01:02:31.140]   valuations are all out of whack. And VCs generally would rather
[01:02:31.140 --> 01:02:36.500]   lead around in a new startup with a fresh cap table, then in
[01:02:36.500 --> 01:02:38.620]   a cap table, they got to restructure because no one
[01:02:38.620 --> 01:02:39.420]   really wants to do this.
[01:02:39.420 --> 01:02:42.980]   About a year ago, we talked about a year ago, Jamal, I asked
[01:02:42.980 --> 01:02:47.140]   you point blank, would you if they cut the valuation, and, you
[01:02:47.140 --> 01:02:48.940]   know, they redid everything and said, Hey, listen, we
[01:02:48.940 --> 01:02:51.460]   understand this is reality, would you get involved in cut a
[01:02:51.460 --> 01:02:53.820]   check? And you're like, I don't want to deal with that kind of,
[01:02:53.820 --> 01:02:55.180]   you know, that kind of
[01:02:55.180 --> 01:02:59.180]   too hard, too hard bucket for you. Yeah. And so now once again,
[01:02:59.180 --> 01:03:02.740]   a year, six months or a year after we talk about this, it has
[01:03:02.740 --> 01:03:04.860]   now manifested this is metastasized.
[01:03:04.860 --> 01:03:08.900]   No, no, it hasn't even started. I think we are starting. Okay, I
[01:03:08.900 --> 01:03:11.660]   think I think we're still being really prescient. Like, the
[01:03:11.660 --> 01:03:15.340]   tiger thing was very important, because they are in many ways,
[01:03:15.340 --> 01:03:18.740]   at the front of the line, in terms of the number of companies
[01:03:18.740 --> 01:03:21.740]   they've touched the amount of capital they've written. And
[01:03:21.740 --> 01:03:24.860]   because they're in the middle of a very large fundraise, their
[01:03:24.860 --> 01:03:28.140]   need to mark to market quite accurately so that their
[01:03:28.140 --> 01:03:30.660]   existing LPs know what they're signing up for in this next
[01:03:30.660 --> 01:03:35.500]   fund. So they're the ones that have the most incentive to move
[01:03:35.500 --> 01:03:39.460]   the marks. But it still leaves an entire industry of folks that
[01:03:39.460 --> 01:03:43.540]   don't necessarily need to do that, because they have, whether
[01:03:43.540 --> 01:03:46.420]   it's dry powder, that dry powder is real or not, the point is
[01:03:46.420 --> 01:03:49.100]   that there's a lot of money that hasn't been deployed. And so
[01:03:49.100 --> 01:03:52.220]   again, I've asked this question before, what is their incentive
[01:03:52.220 --> 01:03:55.420]   to really mark their book down 50%? They don't have an
[01:03:55.420 --> 01:03:58.380]   incentive. Why would they do that they would rather let it
[01:03:58.380 --> 01:04:01.420]   decay down naturally. I'll give you an example of this
[01:04:01.420 --> 01:04:04.300]   or do converts that keep it alive that basically allow them
[01:04:04.300 --> 01:04:04.940]   to delay.
[01:04:04.940 --> 01:04:08.100]   Yeah, anybody even the convert market free birth that was hot
[01:04:08.100 --> 01:04:10.980]   for about six months, and then it just, nobody's doing that
[01:04:10.980 --> 01:04:13.340]   stuff either. But I'll give you one example. There's a very good
[01:04:13.340 --> 01:04:19.020]   company that we are investors in, along with every kind of
[01:04:19.020 --> 01:04:22.660]   big blue chip tier one muckety muck organization, we did the A
[01:04:22.660 --> 01:04:27.660]   and they stacked on afterwards. And when we thought about what
[01:04:27.660 --> 01:04:31.020]   our valuation should be, we did something we got to a number
[01:04:31.020 --> 01:04:36.540]   which was a third of what the mark was. And we're like, well,
[01:04:36.540 --> 01:04:39.020]   if we think the price is two thirds off, we should probably
[01:04:39.020 --> 01:04:42.700]   just sell it now. And we actually went and got some term
[01:04:42.700 --> 01:04:46.700]   sheets from some private equity firms to validate it. And what
[01:04:46.700 --> 01:04:49.020]   they were was incredible. They both independently got to that
[01:04:49.020 --> 01:04:52.620]   same number. And so while the deal was closing, we went
[01:04:52.620 --> 01:04:55.740]   through the end of quarter, we moved the mark down and we
[01:04:55.740 --> 01:04:59.860]   pointed to that valuation. And we said, Look, this is what these
[01:04:59.860 --> 01:05:02.260]   two other very well known firms have said this is what we've
[01:05:02.260 --> 01:05:04.780]   said. So this is what our new valuation is. And you know,
[01:05:04.780 --> 01:05:07.460]   we're trying to sell it and we ended up selling it. But every
[01:05:07.460 --> 01:05:09.900]   other organization didn't touch their their valuation, that
[01:05:09.900 --> 01:05:10.420]   valuation,
[01:05:10.460 --> 01:05:12.820]   the private equity folks, maybe you could explain to the
[01:05:12.820 --> 01:05:16.860]   audience why the private equity folks are such a good backstop
[01:05:16.860 --> 01:05:19.180]   in terms of valuation versus a venture capitalist.
[01:05:19.180 --> 01:05:23.300]   Well, I think that venture capitalists, we tend to be
[01:05:23.300 --> 01:05:28.620]   glass half full. And we are conditioned, especially if you
[01:05:28.620 --> 01:05:33.780]   do your job well, to be smart buyers of deep out of the money
[01:05:33.780 --> 01:05:35.700]   options. What does that mean? It's like when you meet an
[01:05:35.700 --> 01:05:38.380]   entrepreneur and you give them three or 4 million bucks or
[01:05:38.380 --> 01:05:43.020]   $500,000, or whatever, at some nominal valuation, you're not
[01:05:43.020 --> 01:05:45.260]   trying to get your money back, you're trying to figure out
[01:05:45.260 --> 01:05:48.460]   whether he is a Zuck or an Elon or Larry Page, and all of a
[01:05:48.460 --> 01:05:51.500]   sudden, you get 1000x on your money back, right. So we are
[01:05:51.500 --> 01:05:54.300]   buying these deep out of the money options, most of them
[01:05:54.300 --> 01:05:58.020]   don't hit. But when they do, they can just have these crazy
[01:05:58.020 --> 01:06:03.940]   statistical outlier outcomes. So we're trying to buy the future.
[01:06:03.940 --> 01:06:07.900]   And we tend to be believers of what can go right. Private
[01:06:07.900 --> 01:06:14.340]   equity has refined a very powerful toolkit of putting two
[01:06:14.340 --> 01:06:16.980]   or three orders of magnitude of the money we put into companies
[01:06:16.980 --> 01:06:21.460]   to work on the premise that the glass is actually half empty. And
[01:06:21.460 --> 01:06:24.900]   what can go wrong? And how do we mitigate that risk? And so they
[01:06:24.900 --> 01:06:28.500]   tend to be much more sober, I think, in my experience dealing
[01:06:28.500 --> 01:06:31.980]   with them, in what is the true valuation of a business? What
[01:06:31.980 --> 01:06:35.100]   are the upsides of a business? What are the warts on a
[01:06:35.100 --> 01:06:37.860]   business, they really kind of see the truth, the ground truth
[01:06:37.860 --> 01:06:40.940]   much better than VCs do in general, because they're closer
[01:06:40.940 --> 01:06:43.420]   to public markets. And they're they flip these things every two
[01:06:43.420 --> 01:06:46.460]   or three years, their margins are much thinner. They're
[01:06:46.460 --> 01:06:50.580]   they're trying to make one to five 1.6 x their money to x is a
[01:06:50.580 --> 01:06:54.580]   huge outcome for them. Yes. So they have a much more sober
[01:06:54.580 --> 01:07:00.940]   version of reality. But as Tiger stuff, yeah, got released. And I
[01:07:00.940 --> 01:07:04.180]   mean, their funds underwater, just like Masi Yoshi sounds fund
[01:07:04.180 --> 01:07:08.260]   is underwater. And it's going to be years of pain and suffering
[01:07:08.260 --> 01:07:11.660]   to get out from under this. And so again, I think sacks nailed
[01:07:11.660 --> 01:07:14.620]   it with tale of two cities. Anybody else want to chime on
[01:07:14.620 --> 01:07:17.340]   this before we talk a little bit about? Well, for our friend of
[01:07:17.340 --> 01:07:18.300]   the pod, Brian Armstrong,
[01:07:18.300 --> 01:07:23.460]   I've been I've been investing off balance sheet since 2018. And
[01:07:23.460 --> 01:07:26.060]   six months ago, we started to explore whether we should raise
[01:07:26.060 --> 01:07:29.780]   a fund. And I think it was like two weeks ago, we brought the
[01:07:29.780 --> 01:07:33.020]   senior partners in me and the five other guys that run our
[01:07:33.020 --> 01:07:38.060]   business. And we said, we're not going to raise a fund. And the
[01:07:38.060 --> 01:07:40.740]   biggest reason is this dynamic, which is that, you know, we
[01:07:40.740 --> 01:07:45.940]   have dollars of private assets, I don't actually know what
[01:07:45.940 --> 01:07:49.260]   they're really worth. But I have a responsibility to try to get
[01:07:49.260 --> 01:07:52.100]   as much of that capital out. And so I thought the best thing to
[01:07:52.100 --> 01:07:57.180]   do is just to take our time and try to figure it out. Because I
[01:07:57.180 --> 01:07:59.740]   have way more questions than answers right now. And that's
[01:07:59.740 --> 01:08:02.300]   really the first time since I've moved to Silicon Valley, where
[01:08:02.300 --> 01:08:07.340]   I've held had that sensation is a sensation humility. I think
[01:08:07.340 --> 01:08:11.220]   it's like, I mean, I'm joking, but it is it is for somebody
[01:08:11.220 --> 01:08:15.180]   like you who has done so well placing bets deeply, deeply. I
[01:08:15.180 --> 01:08:19.100]   mean, I say it as a joke, but I mean it as like a point of self
[01:08:19.100 --> 01:08:22.340]   awareness for you. Because listen, you play some amazing
[01:08:22.340 --> 01:08:24.020]   bets, whether it's the Warriors or Facebook,
[01:08:24.020 --> 01:08:27.340]   or Bitcoin or whatever, or Slack or whatever. I don't know
[01:08:27.340 --> 01:08:31.180]   whether I should be writing $200 million checks or $200,000
[01:08:31.180 --> 01:08:34.500]   checks. And I don't know whether I should be doing that sort of
[01:08:34.500 --> 01:08:39.100]   as an incubator, actually, as an accelerator, what I'm doing, or
[01:08:39.100 --> 01:08:43.020]   actually just as a series a detached investor. So I don't
[01:08:43.020 --> 01:08:45.300]   know, I'm trying to take the time to figure it out. And I and
[01:08:45.300 --> 01:08:47.900]   my thought was, if I raise a fund right now, I could barely
[01:08:47.900 --> 01:08:51.460]   stand the idea of me putting money to work right now of my
[01:08:51.460 --> 01:08:54.460]   own capital without any answers. But then the idea of like having
[01:08:54.460 --> 01:08:57.300]   a bunch of sovereign wealth funds and folks that were ready
[01:08:57.300 --> 01:09:01.980]   to work with us. I don't know, I just I just took the right time.
[01:09:01.980 --> 01:09:05.580]   Just to tell you my fundraising story. I am publicly raising
[01:09:05.580 --> 01:09:10.340]   launch fund for I get over $50 million in just, you know, high
[01:09:10.340 --> 01:09:12.900]   net worth individuals, you know, and family offices who are
[01:09:12.900 --> 01:09:17.500]   interested, immediately close down on 2627 28 of it, and then
[01:09:17.500 --> 01:09:20.020]   I'm going to go out on the road to meet with LPS. And Silicon
[01:09:20.020 --> 01:09:23.300]   Valley Bank blows up. Nobody's can take a meeting that month,
[01:09:23.300 --> 01:09:26.540]   right. And so now, thank the Lord, I said, I'm going to have
[01:09:26.540 --> 01:09:29.860]   a one year window to raise the fund. And I talked to some old
[01:09:29.860 --> 01:09:34.380]   school VCs, Fred Wilson, Bill Gurley, these people would take
[01:09:34.380 --> 01:09:37.900]   a year to raise a fund. It used to be, or I'm sorry, in the
[01:09:37.900 --> 01:09:41.260]   height of this bubble, you tell me a sacks the quickest you
[01:09:41.260 --> 01:09:44.180]   close one of the the crafts funds. But I was hearing people
[01:09:44.180 --> 01:09:46.820]   saying they're closing funds within two or three months. I
[01:09:46.820 --> 01:09:49.140]   think we're back to it's a year on the road to close a fund.
[01:09:49.140 --> 01:09:52.220]   What's your experience accidents and you're an all star. So I'm
[01:09:52.220 --> 01:09:53.980]   curious, the shortest to the reality.
[01:09:54.940 --> 01:09:58.820]   I think it's just depends on your situation, to be honest.
[01:09:58.820 --> 01:10:02.620]   But, but I, I think the important thing for founders to
[01:10:02.620 --> 01:10:06.420]   know is just that the way that late stage financing is dried up
[01:10:06.420 --> 01:10:09.500]   is very real. I'll give you like two data points just this week.
[01:10:09.500 --> 01:10:13.620]   So I got my first notification from a portfolio company. This
[01:10:13.620 --> 01:10:16.740]   is a company I invested in before craft. It's not a craft
[01:10:16.740 --> 01:10:19.740]   investment, or my personal investments. And they're doing a
[01:10:19.740 --> 01:10:21.860]   pay to play round. You know what that is?
[01:10:22.500 --> 01:10:23.860]   That means pain. Yeah.
[01:10:23.860 --> 01:10:27.700]   Yeah. So basically, the way it works is they say they're going
[01:10:27.700 --> 01:10:30.380]   to raise $20 million. Well, by the way, they said they went out
[01:10:30.380 --> 01:10:33.860]   to raise growth funding, weren't able to get a term sheet from
[01:10:33.860 --> 01:10:39.580]   anybody. And no takers, and this is a good product. I mean, a lot
[01:10:39.580 --> 01:10:44.220]   of startups use this product. I think they're ars in the 20
[01:10:44.220 --> 01:10:47.780]   something million, maybe 30 something million. It's not like
[01:10:47.780 --> 01:10:50.100]   doubling year over year, it's growing, like, let's call it 50%
[01:10:50.100 --> 01:10:52.020]   year over year. This is a company that should have been
[01:10:52.020 --> 01:10:54.260]   able to raise money. I don't understand why they weren't,
[01:10:54.260 --> 01:10:57.500]   maybe because they're burning too much money. So instead of
[01:10:57.500 --> 01:10:59.820]   cutting costs the way they should, they're doing like a $20
[01:10:59.820 --> 01:11:02.820]   million pay to play around. And what that means is that
[01:11:02.820 --> 01:11:06.460]   everybody is an investor in the company, you either have to do
[01:11:06.460 --> 01:11:09.500]   your prorated share of the 20 million, or you get diluted 10
[01:11:09.500 --> 01:11:10.020]   to one,
[01:11:10.020 --> 01:11:13.140]   if you had 10% of the company, you have to put in $2 million,
[01:11:13.140 --> 01:11:16.300]   or your 10% of the company is now 1%.
[01:11:16.300 --> 01:11:20.980]   No, it'd be it'd be more because you would look at, let's say 50%
[01:11:20.980 --> 01:11:24.460]   of the company is owned by the investors and the other 50%
[01:11:24.460 --> 01:11:28.180]   common, just to take round numbers. Okay, if you own 10% of
[01:11:28.180 --> 01:11:30.940]   the company, that would actually be 20% of the progress. Yeah,
[01:11:30.940 --> 01:11:33.900]   the employees are not buying shares in this 20% of the of
[01:11:33.900 --> 01:11:35.620]   the of the 20 million,
[01:11:35.620 --> 01:11:38.940]   just 4 million, 4 million. Yeah, exactly. So basically, you have
[01:11:38.940 --> 01:11:39.980]   to own 1%.
[01:11:39.980 --> 01:11:44.420]   Right, right. So basically, it's almost like a capital call,
[01:11:44.420 --> 01:11:48.020]   where you just have to pony up more money in order to preserve
[01:11:48.020 --> 01:11:49.180]   your ownership in the company.
[01:11:49.180 --> 01:11:52.340]   If it is, but
[01:11:52.340 --> 01:11:55.540]   super punitive. I had one of those just happened to me as
[01:11:55.540 --> 01:11:58.300]   well. And I was just like, we'll put in the bare minimum,
[01:11:58.300 --> 01:12:00.260]   because like the thing that it puts you in, it paints you in a
[01:12:00.260 --> 01:12:02.580]   corner where you're like, well, I've been with this thing for
[01:12:02.580 --> 01:12:08.620]   eight or nine years. Is this the moment to basically lose all of
[01:12:08.620 --> 01:12:13.140]   that compounding or value or work that you put in or seen
[01:12:13.140 --> 01:12:15.980]   their team do? And it's just a really tough position.
[01:12:16.500 --> 01:12:19.540]   Right? So look, I'm not on the board. So I don't know what
[01:12:19.540 --> 01:12:23.300]   reasoning went into this. But what they should be sending out
[01:12:23.300 --> 01:12:26.660]   to all the shareholders is look here, all of our metrics. Here's
[01:12:26.660 --> 01:12:29.540]   our burn, you know, here's the steps we took to reduce our
[01:12:29.540 --> 01:12:32.820]   burn. I don't really like the idea of having to do essentially
[01:12:32.820 --> 01:12:35.140]   a capital call from your existing investors, when you
[01:12:35.140 --> 01:12:38.180]   haven't reduced your own burn. I mean, why can't the company
[01:12:38.180 --> 01:12:41.380]   operate at break even if you're at 30 something million of air
[01:12:41.380 --> 01:12:45.020]   are, you should operate, you may not want to operate at break
[01:12:45.020 --> 01:12:46.540]   even, but you should be able to,
[01:12:46.540 --> 01:12:48.940]   but this is what I mean, I'll tell you after we stopped
[01:12:48.940 --> 01:12:52.860]   taping who it was that that told me this about their company, but
[01:12:52.860 --> 01:12:57.020]   they were basically able to let go a third of their workforce by
[01:12:57.020 --> 01:12:58.860]   moving a bunch of work to models.
[01:12:58.860 --> 01:13:02.060]   And let me guess the founders get to keep their shares or they
[01:13:02.060 --> 01:13:04.140]   get reopt in this whole machine gonna
[01:13:04.140 --> 01:13:06.660]   know, but wait, hold on, can we can I just finish? Yeah, please.
[01:13:06.660 --> 01:13:10.220]   So let's go. So the point is, like, if you can cut off x by a
[01:13:10.220 --> 01:13:14.780]   third, by using all of these new AI, you know, models and GPT
[01:13:14.780 --> 01:13:18.260]   and auto GPT. What are you as a board member or shareholder
[01:13:18.260 --> 01:13:23.500]   supposed to do? And also, as a founder, don't you have to go
[01:13:23.500 --> 01:13:27.820]   there first before you start to ask people for more money? And
[01:13:27.820 --> 01:13:30.660]   why aren't people doing that first, much more aggressively?
[01:13:30.660 --> 01:13:32.860]   And so this is what doesn't make any sense to me.
[01:13:32.860 --> 01:13:35.620]   That's exactly my point is what steps were taken to cut costs
[01:13:35.620 --> 01:13:38.700]   before you just went to the investors to pony up more money.
[01:13:38.700 --> 01:13:42.020]   That's what I want to know if they actually did that work, and
[01:13:42.020 --> 01:13:45.460]   this is like the last money they need, okay, then, you know, I'll
[01:13:45.460 --> 01:13:49.260]   pony up my share. And by the way, we need investors. No, we
[01:13:49.260 --> 01:13:51.580]   don't. And we need investors to be much more aggressive in
[01:13:51.580 --> 01:13:55.860]   holding folks accountable, because these examples need to
[01:13:55.860 --> 01:13:59.220]   be better discussed. While effects YZ company was able to
[01:13:59.220 --> 01:14:03.340]   do it, why aren't you able to do it? And if it's because we're
[01:14:03.340 --> 01:14:06.300]   not technically capable, Matt, that's maybe a plausible answer.
[01:14:06.300 --> 01:14:09.260]   But even that reason will go away in a few months, I suspect.
[01:14:09.700 --> 01:14:12.620]   But if it's that we just have such institutional rot, we're
[01:14:12.620 --> 01:14:15.700]   incapable of doing it. Well, then you might as well just not
[01:14:15.700 --> 01:14:17.340]   write the check because that company is going to get
[01:14:17.340 --> 01:14:20.900]   undercut by some new white sheet version of that business that
[01:14:20.900 --> 01:14:23.060]   doesn't have any of these impediments that management has
[01:14:23.060 --> 01:14:26.380]   told you a bunch of agents in a way to Moffett sacks management
[01:14:26.380 --> 01:14:29.500]   has told you they're incapable of running this business, this
[01:14:29.500 --> 01:14:33.380]   concern in a in a thoughtful way. I had this happen to us as
[01:14:33.380 --> 01:14:36.300]   well. And the question I have you sacks is, in these
[01:14:36.300 --> 01:14:39.700]   situations where this pay to play happens, you basically
[01:14:39.700 --> 01:14:44.100]   everybody gets wiped out except those who play. But the founders
[01:14:44.100 --> 01:14:46.540]   and the management team always seem to get re up. And they're
[01:14:46.540 --> 01:14:48.900]   whole because the new investor doesn't want the management team
[01:14:48.900 --> 01:14:53.340]   not incentivized. So in these kinds of situations, it's kind
[01:14:53.340 --> 01:14:56.420]   of like the management team gets to reboot the cap table. And
[01:14:56.420 --> 01:14:57.260]   they don't get penalized.
[01:14:57.260 --> 01:15:00.700]   No, I actually I don't I don't have those details yet. Yeah.
[01:15:00.700 --> 01:15:04.020]   Remember, I didn't lead around. I was just an angel investor in
[01:15:04.020 --> 01:15:07.660]   the company. So I checked with one of the VC firms that led
[01:15:07.660 --> 01:15:10.100]   around and I'm like, Are you going to do this? And they said,
[01:15:10.100 --> 01:15:14.460]   probably not, you know, and so like the round might fail. I
[01:15:14.460 --> 01:15:17.140]   mean, they can make it as punitive as they want. But if
[01:15:17.140 --> 01:15:21.060]   the shareholders don't believe that the company has fixed this
[01:15:21.060 --> 01:15:24.620]   problems, they're not gonna pony up the money. Let's get free
[01:15:24.620 --> 01:15:27.620]   bargain. Yeah, I think one of the problems that a lot of folks
[01:15:27.620 --> 01:15:35.060]   are facing is it becomes less about the fundamental value of a
[01:15:35.060 --> 01:15:37.660]   business in a lot of these conversations, as you guys know,
[01:15:37.660 --> 01:15:41.180]   and it's becoming a lot more about who will fund the next
[01:15:41.180 --> 01:15:44.060]   round if the company is still burning money. And so you're
[01:15:44.060 --> 01:15:48.180]   making a social market bet, not a bet on the team or the
[01:15:48.180 --> 01:15:52.660]   business or the value. It's that there's someone else that's
[01:15:52.660 --> 01:15:55.580]   going to lead the next round. And this is fundamentally why
[01:15:55.620 --> 01:15:58.140]   he's called the greater fool. That's called the greater fool.
[01:15:58.140 --> 01:16:00.780]   Look, I mean, it's historically, we wouldn't call him a fool if
[01:16:00.780 --> 01:16:04.540]   it's just about progress towards profitability. But right now,
[01:16:04.540 --> 01:16:06.780]   there's so much trepidation. It's almost like a self
[01:16:06.780 --> 01:16:09.420]   fulfilling prophecy, that there's so much trepidation and
[01:16:09.420 --> 01:16:12.860]   doing late stage rounds, that no one wants to be the last guy in,
[01:16:12.860 --> 01:16:15.020]   because you're not sure if the next guy is going to be there to
[01:16:15.020 --> 01:16:17.580]   fund the last round to get to profitability. And that's why
[01:16:17.580 --> 01:16:22.020]   half of biotechs that are public are trading below cash. Because
[01:16:22.020 --> 01:16:24.420]   historically, the way biotech companies, which is a really
[01:16:24.420 --> 01:16:27.860]   good pointed example of this, they make progress to hit
[01:16:27.860 --> 01:16:30.300]   milestones, and then the next round of capital comes in, they
[01:16:30.300 --> 01:16:32.820]   make progress hit milestones, next round of capital comes in.
[01:16:32.820 --> 01:16:35.220]   And then eventually you get, you know, phase three approvals, and
[01:16:35.220 --> 01:16:38.340]   you go sell the company or whatever, you get profitable,
[01:16:38.340 --> 01:16:41.260]   and they almost always get acquired. And in the case of
[01:16:41.260 --> 01:16:45.180]   other technology companies, if the business has to do three or
[01:16:45.180 --> 01:16:47.980]   four things, it's got three or four milestones, it has to hit,
[01:16:47.980 --> 01:16:50.140]   in your case, tax, it might be that they got to get to 50
[01:16:50.140 --> 01:16:53.060]   million ARR. And they got to get, you know, the certain cost
[01:16:53.060 --> 01:16:55.300]   function down in the business. And if they can do those two
[01:16:55.300 --> 01:16:57.340]   things, and the business profitable, but it's going to
[01:16:57.340 --> 01:17:00.300]   take us around a 20, we'll get the first chunk down, and then
[01:17:00.300 --> 01:17:02.660]   another round of 30 to get the last chunk done. And no one
[01:17:02.660 --> 01:17:05.780]   knows if the next 30 is going to be there. And that's really where
[01:17:05.780 --> 01:17:08.540]   a lot of these market dynamics are falling apart, that there's
[01:17:08.540 --> 01:17:12.380]   historically been a model in the market of hit milestones, next
[01:17:12.380 --> 01:17:15.700]   round shows up, hit milestones, next round shows up. And now no
[01:17:15.700 --> 01:17:18.700]   one knows if the next round will show up. So no one wants to fund
[01:17:18.700 --> 01:17:22.020]   this round, particularly where there's high burn, it requires a
[01:17:22.020 --> 01:17:24.980]   lot of capital to make that bet. So the social, you know, the
[01:17:24.980 --> 01:17:28.100]   self fulfilling problem, the social market that right now is,
[01:17:28.100 --> 01:17:31.740]   you know, it's self fulfills. And we're, you know, we're
[01:17:31.740 --> 01:17:35.540]   sitting here, kind of spinning our thumbs wondering if the next
[01:17:35.540 --> 01:17:36.100]   guy's gonna fund it.
[01:17:36.100 --> 01:17:43.020]   Do you think that only 10 or 15% of companies have now properly
[01:17:43.020 --> 01:17:46.340]   reset value? Like you said, 70% of these unicorns are actually
[01:17:46.340 --> 01:17:47.140]   zombie horns?
[01:17:47.140 --> 01:17:49.420]   Yeah, that's why I think the number from I don't want to I
[01:17:49.420 --> 01:17:53.500]   don't know tigers book at all. But when I hear numbers like 20%,
[01:17:53.500 --> 01:17:56.860]   for a for a fully invested mature book and invested during
[01:17:56.860 --> 01:18:00.980]   the peak of the cycle, it doesn't sound right that it's 20%.
[01:18:00.980 --> 01:18:04.180]   It sounds like it should be a lot lower.
[01:18:04.180 --> 01:18:08.060]   I think that 20%, by the way, you know, comes after like two
[01:18:08.060 --> 01:18:10.580]   other smaller write down so they might be cumulatively
[01:18:10.580 --> 01:18:12.460]   I don't want to talk about Tiger, I don't want to talk
[01:18:12.460 --> 01:18:15.460]   about Tiger, I think, like, sure, the statistic of 70% of
[01:18:15.460 --> 01:18:18.340]   these public companies trading below their cash, that the cash
[01:18:18.380 --> 01:18:22.660]   that they've burnt that they've raised in their lifetime. And
[01:18:22.660 --> 01:18:25.500]   again, just to for anyone that's an analyst at home trying to
[01:18:25.500 --> 01:18:29.020]   figure out how we get to that number, you look at the retained
[01:18:29.020 --> 01:18:32.060]   earnings on the balance sheet. And so the cumulative retained
[01:18:32.060 --> 01:18:33.860]   earnings tells you if it's negative tells you how much
[01:18:33.860 --> 01:18:36.260]   money they've burnt over their lifetime. And that tells you
[01:18:36.260 --> 01:18:38.580]   effectively how much money has been invested. So when you look
[01:18:38.580 --> 01:18:41.300]   at the enterprise value, which is the market cap, minus the
[01:18:41.300 --> 01:18:43.700]   cash they have today, you get their enterprise value, if their
[01:18:43.700 --> 01:18:45.980]   enterprise value is less than their cumulative retained
[01:18:45.980 --> 01:18:48.740]   earnings, it means that they're currently worth less than the
[01:18:48.740 --> 01:18:52.860]   money they've spent. And that's a statistic that is a fact right
[01:18:52.860 --> 01:18:55.460]   now in public markets in technology gone public in the
[01:18:55.460 --> 01:18:58.260]   last three years. And then you compare that to private markets.
[01:18:58.260 --> 01:19:01.700]   And I don't think we've seen a 70% write down yet. Or, you
[01:19:01.700 --> 01:19:04.700]   know, 70% of these things being worth less than the cash. So
[01:19:04.700 --> 01:19:07.420]   it's, you know, it's still Yeah, I think you're right.
[01:19:07.420 --> 01:19:12.100]   Jamaat is probably another hammer to drop multiple hammers,
[01:19:12.100 --> 01:19:13.580]   multiple hammers,
[01:19:13.660 --> 01:19:16.100]   before we move on to a different topic. So I think one
[01:19:16.100 --> 01:19:19.820]   of the interesting differences in opinion and in Silicon Valley
[01:19:19.820 --> 01:19:23.580]   is the way that founders and VC see the nature of the
[01:19:23.580 --> 01:19:25.940]   relationship. And I've been on both sides of this, I've been on
[01:19:25.940 --> 01:19:29.380]   the side of being a founder. And I've been on the side of being
[01:19:29.380 --> 01:19:33.300]   a VC. And what you'll see is that VCs always talk about it as
[01:19:33.300 --> 01:19:36.260]   a partnership. But a lot of founders will talk about it as
[01:19:36.260 --> 01:19:39.220]   if the money is just a commodity. And frankly, when
[01:19:39.220 --> 01:19:40.980]   everything's up into the right, and everything's going great,
[01:19:40.980 --> 01:19:43.460]   and you're in a bull market, and you can just keep raising money
[01:19:43.500 --> 01:19:45.820]   and definitely because there's always someone willing to lead
[01:19:45.820 --> 01:19:49.500]   the next round, then the money is a commodity. But when you're
[01:19:49.500 --> 01:19:54.060]   in a, in a down market, and all of a sudden, there is no market
[01:19:54.060 --> 01:19:56.580]   like you can't raise your next round, all of a sudden, it is a
[01:19:56.580 --> 01:19:59.900]   partnership, because you've got to go to your investors and ask
[01:19:59.900 --> 01:20:03.460]   them to do something that they may not otherwise want to do is
[01:20:03.460 --> 01:20:07.660]   this was purely a transactional decision, as opposed to a
[01:20:07.660 --> 01:20:10.740]   relationship, they might not want to fund your next round.
[01:20:10.740 --> 01:20:13.300]   And you're asked them to say no, actually, believe in our
[01:20:13.300 --> 01:20:17.540]   long term relationship. And I think that, you know, this is a
[01:20:17.540 --> 01:20:19.500]   type of environment, which you find out it is more of a
[01:20:19.500 --> 01:20:20.180]   partnership.
[01:20:20.180 --> 01:20:23.700]   And it's been it should have always been it should have been
[01:20:23.700 --> 01:20:26.500]   but it but it wasn't. And look, I don't know what happened with
[01:20:26.500 --> 01:20:29.220]   that other company. And all of a sudden, I get a notification
[01:20:29.220 --> 01:20:31.260]   out of the blue. Well, I want to understand the thinking that
[01:20:31.260 --> 01:20:35.500]   went into that. Before, you know, I'm just gonna basically
[01:20:35.500 --> 01:20:39.060]   this is where trust comes in, right. And like, I think in a
[01:20:39.060 --> 01:20:42.620]   zero interest rate environment, you know, there's no need for
[01:20:42.620 --> 01:20:44.900]   trust. You just this cash splashing around, just grab
[01:20:44.900 --> 01:20:47.260]   whoever the latest person in town is who wants to drop a
[01:20:47.260 --> 01:20:49.460]   couple of bags. You just take one of their bags.
[01:20:49.460 --> 01:20:51.820]   The most important thing to me, like what would make it a
[01:20:51.820 --> 01:20:53.980]   partnership is for me to know that the founders have done
[01:20:53.980 --> 01:20:57.980]   everything in their power to reduce costs and put the company
[01:20:57.980 --> 01:21:01.420]   on the right trajectory before going out and basically issuing
[01:21:01.420 --> 01:21:03.300]   capital calls to the investors. I want to know they've done that
[01:21:03.300 --> 01:21:03.660]   work.
[01:21:03.660 --> 01:21:06.300]   All right, listen, freeberg. I know you got to go. Take care
[01:21:06.300 --> 01:21:08.660]   of Sultan of science. I'll just wrap up with the other boys here
[01:21:08.660 --> 01:21:12.220]   with one piece of breaking news stack overflow says they will
[01:21:12.220 --> 01:21:16.220]   join the parade of data providers like Reddit and
[01:21:16.220 --> 01:21:19.100]   Twitter that will require permission and payment to use
[01:21:19.100 --> 01:21:22.460]   their data sets. And stack overflow has a lot of answers to
[01:21:22.460 --> 01:21:25.660]   a lot of developers questions in there. I was just curious to get
[01:21:25.660 --> 01:21:28.860]   your thoughts. SEC obviously sent to wells known as we talked
[01:21:28.860 --> 01:21:32.340]   about this before to Brian Armstrong of Coinbase. He said
[01:21:32.340 --> 01:21:35.980]   he's thinking about or considering relocating out of
[01:21:35.980 --> 01:21:40.100]   the US if the regulatory clarity does not improve crypto is dead
[01:21:40.100 --> 01:21:40.700]   in America.
[01:21:41.300 --> 01:21:44.540]   It is dead in America. Crypto is dead in America. I mean, now
[01:21:44.540 --> 01:21:48.380]   you have a ganzler. You had ganzler even blaming the banking
[01:21:48.380 --> 01:21:53.340]   crisis on crypto. So they've the the United States authorities
[01:21:53.340 --> 01:21:55.540]   have firmly pointed their guns at crypto.
[01:21:55.540 --> 01:22:00.860]   Is it a scapegoat? Or was it a fuck around? Find out moment for
[01:22:00.860 --> 01:22:03.700]   crypto? In your mind? Or a little bit of both?
[01:22:03.700 --> 01:22:07.620]   I don't know. I just think that they were probably the ones that
[01:22:07.620 --> 01:22:10.780]   were the most threatening to the establishment.
[01:22:11.100 --> 01:22:14.660]   Okay. And they were the ones that in fairness to the
[01:22:14.660 --> 01:22:17.060]   regulators did push the boundaries more than any other
[01:22:17.060 --> 01:22:21.660]   sector of the startup economy. And yeah, so now they're paying
[01:22:21.660 --> 01:22:23.540]   the price for that. The bill has come due for them.
[01:22:23.540 --> 01:22:28.300]   sacks? Is it a fuck around? Find out moment? Is it protecting the
[01:22:28.300 --> 01:22:32.420]   American dollar somewhere in between? Or incompetence on
[01:22:32.420 --> 01:22:33.180]   regulators part?
[01:22:33.180 --> 01:22:36.100]   The more I think about it, the more I think it's probably not a
[01:22:36.100 --> 01:22:38.660]   coincidence that you're seeing all these concerns about
[01:22:38.660 --> 01:22:40.900]   de dollarization at the same time they're cracking down on
[01:22:40.900 --> 01:22:44.700]   crypto. So look, there were a bunch of crypto companies that
[01:22:44.700 --> 01:22:47.220]   might have done shady things. But I think we all agree that
[01:22:47.220 --> 01:22:50.260]   Coinbase was not one of them. Coinbase was the gold standard
[01:22:50.260 --> 01:22:52.540]   in terms of doing everything right. And they've just agreed
[01:22:52.540 --> 01:22:55.300]   asked over and over again for a regulatory framework. They're
[01:22:55.300 --> 01:22:59.060]   just like, tell us how to operate and we'll do it. So I
[01:22:59.060 --> 01:23:01.460]   think Jamal is right that they're effectively banning
[01:23:01.460 --> 01:23:03.580]   crypto in the United States, they're going to drive all these
[01:23:03.580 --> 01:23:06.940]   companies overseas, which is terrible for American
[01:23:06.940 --> 01:23:10.220]   innovation. I don't know exactly where blockchain and crypto are
[01:23:10.220 --> 01:23:13.940]   going to go from here. But I think that we should find that
[01:23:13.940 --> 01:23:16.700]   out in America. You know, we don't want that innovation going
[01:23:16.700 --> 01:23:17.260]   offshore.
[01:23:17.260 --> 01:23:22.140]   You bring up a really good point to it's just like Coinbase played
[01:23:22.140 --> 01:23:26.700]   by the rules stood in line, tried to do the right things. It
[01:23:26.700 --> 01:23:29.780]   seems that every step along the way, right, everything from
[01:23:29.780 --> 01:23:34.460]   board composition to executive composition to how they tried to
[01:23:34.460 --> 01:23:37.060]   interact with the regulators, yet, they were probably the
[01:23:37.060 --> 01:23:39.180]   furthest away from getting a license. The one that came the
[01:23:39.180 --> 01:23:41.900]   closest was the one that was the most fraudulent, which is FDF.
[01:23:41.900 --> 01:23:47.300]   Fascinating. How is that even possible? I mean,
[01:23:47.300 --> 01:23:50.180]   because he had skills in gaming the system.
[01:23:50.180 --> 01:23:52.500]   Yeah, he's splashy, cashy, splashy, cashy.
[01:23:52.500 --> 01:23:55.780]   Well, he he probably got large amounts of money because it
[01:23:55.780 --> 01:23:59.220]   wasn't his money. So it was easy for him to make huge donations.
[01:23:59.220 --> 01:24:02.980]   But he knew how to play the game. To quote SPF. He said,
[01:24:02.980 --> 01:24:05.860]   This is the dumb game we woke Westerners play. We say the
[01:24:05.860 --> 01:24:08.740]   right shibboleth so everyone likes us. That's the game he was
[01:24:08.740 --> 01:24:12.100]   playing, which is my whole concern about if we jump the gun
[01:24:12.100 --> 01:24:15.940]   on regulating AI too quickly, it'll turn into another, you
[01:24:15.940 --> 01:24:18.820]   know, woke game that everyone's gonna play.
[01:24:18.820 --> 01:24:23.300]   So here's, here's how the world works. regulate yourself, behave
[01:24:23.300 --> 01:24:28.140]   yourself, act in the interest of consumers, or get regulated or
[01:24:28.140 --> 01:24:31.140]   smashed. And I think we've gone over this. We talked about it.
[01:24:31.140 --> 01:24:34.780]   In fact, last week, whether the movie industry, crypto AI,
[01:24:34.780 --> 01:24:38.180]   regulate yourself, behave properly, don't push the
[01:24:38.180 --> 01:24:41.340]   boundaries too far, you can bend the rules, but you don't want to
[01:24:41.340 --> 01:24:41.860]   break them.
[01:24:41.860 --> 01:24:45.060]   I think the regulate yourself that you use the MPAA. I don't
[01:24:45.060 --> 01:24:46.740]   think that's the right example. I think if you're going to
[01:24:46.740 --> 01:24:51.300]   regulate yourself, look at the tobacco industry. They tried to
[01:24:51.300 --> 01:24:54.780]   regulate themselves. But what they did was just lie to
[01:24:54.780 --> 01:24:59.020]   maximize profit in an area that was much less benign than movies
[01:24:59.020 --> 01:25:02.860]   and content. Maybe you could have some lascivious content in
[01:25:02.860 --> 01:25:06.660]   a movie or a video game or an album. But that was a lot less
[01:25:06.660 --> 01:25:10.420]   harmful than smoking, which not just impacted the smoker, but it
[01:25:10.420 --> 01:25:13.340]   turned out the second hand smoker as well, or the second
[01:25:13.340 --> 01:25:16.180]   hand smoke. So it touched everybody, right? You could be
[01:25:16.180 --> 01:25:19.180]   in a restaurant, not smoke and yet have years of your life
[01:25:19.180 --> 01:25:24.220]   taken. So I think that the self regulation for areas that impact
[01:25:24.220 --> 01:25:27.180]   everybody, independent of whether you participate in the
[01:25:27.180 --> 01:25:30.660]   system or not, is where you have to look for good examples, Jason,
[01:25:30.660 --> 01:25:32.540]   and I'm not sure there are many good examples of separate
[01:25:32.540 --> 01:25:34.100]   allegations, those kinds of systems.
[01:25:34.100 --> 01:25:37.180]   I mean, I like your workshopping it here. I mean, some
[01:25:37.180 --> 01:25:39.700]   restaurants would have a smoking section and non smoking section
[01:25:39.700 --> 01:25:42.500]   before there was regulation, right. And I think if crypto had
[01:25:42.500 --> 01:25:45.340]   just thought had been more thoughtful about hey, which
[01:25:45.340 --> 01:25:48.620]   tokens NFT projects, we're going to support which ones we're not
[01:25:48.620 --> 01:25:51.860]   going to that maybe they would have avoided a little bit of
[01:25:51.860 --> 01:25:54.940]   this. I'm not sure. You know, it's it's it's hindsight 2020
[01:25:54.940 --> 01:25:57.260]   here, but a little more regulation.
[01:25:57.260 --> 01:26:00.180]   I don't think those smoking non smoking sections work too well.
[01:26:00.180 --> 01:26:01.620]   The smoke went all over the place.
[01:26:01.620 --> 01:26:05.420]   Do you remember you remember coming out of a bar and you woke
[01:26:05.420 --> 01:26:08.580]   up the next day and your clothes smell like smoke? You'd have to
[01:26:08.580 --> 01:26:11.340]   take a shower when you went to a bar or a restaurant or a club.
[01:26:11.340 --> 01:26:15.460]   You would have to come home take a shower because your hair and
[01:26:15.460 --> 01:26:19.220]   your clothes smell of smoke goes you can sleep in a bed then your
[01:26:19.220 --> 01:26:21.940]   bed had to get to change your sheets. Discuss remember when
[01:26:21.940 --> 01:26:25.540]   you went on a commercial flight that a smoking section of non
[01:26:25.540 --> 01:26:28.900]   smoking section non smoking. It's a tube the smoke gets all
[01:26:28.900 --> 01:26:29.620]   over the place.
[01:26:29.620 --> 01:26:34.300]   You know you're on the wrong airline when they have the
[01:26:34.300 --> 01:26:39.180]   welded shut. ashtrays they used to have an ashtray in every seat
[01:26:39.180 --> 01:26:41.140]   in but in the armrest was
[01:26:41.140 --> 01:26:44.860]   a friend of mine this is like such a throwback but a friend of
[01:26:44.860 --> 01:26:47.740]   mine well known guy that you know I'll say the name you can
[01:26:47.740 --> 01:26:50.500]   bleep it out. Please
[01:26:51.340 --> 01:26:53.100]   that out please very important we don't want to
[01:26:53.100 --> 01:26:56.180]   is a notorious smoker and so I flown with him.
[01:26:56.180 --> 01:26:57.740]   That's the worst.
[01:26:57.740 --> 01:27:02.180]   And we get in there on his plane and then we he shuts the door
[01:27:02.180 --> 01:27:04.860]   and I'm like, smells a little odd in here smells a little
[01:27:04.860 --> 01:27:05.540]   clovey.
[01:27:05.540 --> 01:27:10.580]   Seven hours I'm gonna have to be in this
[01:27:10.580 --> 01:27:16.820]   to the pilots get hazard pay. I mean, how do you compensate? I
[01:27:16.820 --> 01:27:19.620]   mean, this is not a turbo prop. He's on he can't crack the
[01:27:19.620 --> 01:27:20.180]   window.
[01:27:20.420 --> 01:27:25.580]   No. It was a global, huge global. It was it was three
[01:27:25.580 --> 01:27:28.540]   cabins, you could go to the cabin felt so sick.
[01:27:28.540 --> 01:27:30.140]   It's the worst.
[01:27:30.140 --> 01:27:33.940]   It's the absolute worst worst smoking is the worst.
[01:27:33.940 --> 01:27:37.460]   All right. Well, we didn't so long to the Sultan of silence
[01:27:37.460 --> 01:27:41.300]   as a science rather their polling update here, sex. I
[01:27:41.300 --> 01:27:43.940]   don't mean to poke the bear. I know it's a rough week with the
[01:27:43.940 --> 01:27:45.060]   Fox News news.
[01:27:45.060 --> 01:27:47.940]   Bring it up. Bring it up.
[01:27:47.940 --> 01:27:48.940]   No, go for it.
[01:27:49.300 --> 01:27:53.220]   Quick polling update between putting Ron I'm sorry, to
[01:27:53.220 --> 01:27:54.740]   Santa's and trying to happen.
[01:27:54.740 --> 01:27:56.340]   The Santa's is not happening.
[01:27:56.340 --> 01:28:00.940]   In late March, news of Trump's indictment boosted him over to
[01:28:00.940 --> 01:28:05.340]   Santa's by 26 percentage points among Republicans and
[01:28:05.340 --> 01:28:07.420]   Republican independence. But earlier this week, the same
[01:28:07.420 --> 01:28:11.460]   poll showed that Trump's lead shrunk by 10 points in the last
[01:28:11.460 --> 01:28:14.660]   two weeks to just a 16 point advantage, which is still
[01:28:14.660 --> 01:28:18.740]   significant. But there's more University of New Hampshire
[01:28:18.740 --> 01:28:21.020]   Survey Center poll. I don't know if any of these polls are
[01:28:21.020 --> 01:28:23.540]   reasonable or not. That seems like call people on the phone.
[01:28:23.540 --> 01:28:26.260]   I don't know who's got a landline. Release Wednesday
[01:28:26.260 --> 01:28:31.540]   showed a 20 point to Santa's deficit. What's going on here?
[01:28:31.540 --> 01:28:34.140]   Saks did your boy peak too early?
[01:28:34.140 --> 01:28:37.940]   No, I don't think so. If you if you look at the Republican
[01:28:37.940 --> 01:28:41.460]   primary field, just answers is the only person who's got a
[01:28:41.460 --> 01:28:45.620]   shot other than Trump. You look at Nikki Haley, she's pulling in
[01:28:45.620 --> 01:28:49.940]   the 345% range, all the others are at one or 2%. There's not a
[01:28:49.940 --> 01:28:55.180]   candidate other than to Santa's that has over 5%. So in my view,
[01:28:55.180 --> 01:28:58.820]   this is a Trump to Santa's race. Now what you saw is that when
[01:28:58.820 --> 01:29:03.300]   Alvin Bragg press charges and indicted Trump, it created a lot
[01:29:03.300 --> 01:29:06.620]   of sympathy for Trump among Republicans. Effectively, what
[01:29:06.620 --> 01:29:09.820]   happened is Republicans registered their displeasure
[01:29:09.820 --> 01:29:13.940]   with Alvin Bragg by indicating support for Trump. Let's go. And
[01:29:13.940 --> 01:29:16.460]   that's, that's what you'd expect to happen. And a lot of people
[01:29:16.460 --> 01:29:19.900]   speculated that might be the purpose of Bragg's prosecution
[01:29:19.900 --> 01:29:24.220]   is to make Trump the candidate. So we knew that was happening.
[01:29:24.220 --> 01:29:26.540]   But I think this this new poll that you just mentioned is
[01:29:26.540 --> 01:29:30.340]   really interesting, because it shows that that sugar high of
[01:29:30.340 --> 01:29:34.700]   Trump's poll ratings was a temporary bounce, and it's
[01:29:34.700 --> 01:29:38.820]   coming down somewhat. And so you know, what you saw actually is
[01:29:38.820 --> 01:29:42.380]   that this huge poll bounce that Trump got is somewhat
[01:29:42.660 --> 01:29:47.140]   normalizing. Now, there's no question that this answers is
[01:29:47.140 --> 01:29:49.980]   running behind Trump, and he's got his work cut out for him if
[01:29:49.980 --> 01:29:53.100]   he's going to upset Trump as the nominee. But this thing is just
[01:29:53.100 --> 01:29:56.260]   getting started. I mean, to Santa's isn't even formally
[01:29:56.260 --> 01:29:59.180]   announced yet. And remember, we're still very, very early in
[01:29:59.180 --> 01:30:02.140]   this race, the primary battle that this most reminds me of
[01:30:02.140 --> 01:30:10.060]   would be Obama versus Hillary in 2007. And at this time in 2007,
[01:30:10.460 --> 01:30:14.540]   Hillary had a huge advantage over Obama. She was considered
[01:30:14.540 --> 01:30:18.340]   the favorite, she was considered the one who couldn't lose. And
[01:30:18.340 --> 01:30:21.740]   it was Obama that pulled off a huge upset. And he did it by
[01:30:21.740 --> 01:30:24.620]   out fundraising her out hustling her, especially in
[01:30:24.620 --> 01:30:27.980]   building organization and some of those early primary states.
[01:30:27.980 --> 01:30:31.780]   And then he eventually created a narrative that it was time to
[01:30:31.780 --> 01:30:35.500]   turn the page. But he didn't do that until much later in the
[01:30:35.500 --> 01:30:38.820]   year, much closer to the primary. The first Republican
[01:30:38.820 --> 01:30:41.500]   primary is not till February. So there's plenty of time here.
[01:30:41.500 --> 01:30:43.940]   And I, you know, we'll see what happens.
[01:30:43.940 --> 01:30:45.220]   To my thoughts.
[01:30:45.220 --> 01:30:48.180]   I think Nikki Haley is going to win the Republican nomination.
[01:30:48.180 --> 01:30:53.660]   The more people here, here's the thing. People, the number of
[01:30:53.660 --> 01:30:57.340]   people that have told me the most impressive moment with
[01:30:57.340 --> 01:31:01.660]   DeSantis was before they met him. The second most impressive
[01:31:01.660 --> 01:31:05.140]   moment was their first meeting. And then it just falls off a
[01:31:05.140 --> 01:31:08.300]   cliff where he becomes more and more unimpressive, the more and
[01:31:08.300 --> 01:31:11.380]   more time spent with this guy. Hey, Nikki Haley, come on the
[01:31:11.380 --> 01:31:11.660]   pod.
[01:31:11.660 --> 01:31:12.900]   Nikki Haley is the opposite.
[01:31:12.900 --> 01:31:17.460]   Nikki Haley announced that in all of q1 in all of q1, she
[01:31:17.460 --> 01:31:20.020]   raised $5 million extremely unimpressive. You're probably
[01:31:20.020 --> 01:31:21.260]   20% of that month.
[01:31:21.260 --> 01:31:23.700]   And Nikki Haley, come on the pod. We'll double it.
[01:31:23.700 --> 01:31:26.580]   How much is 5 million was was you?
[01:31:26.580 --> 01:31:33.180]   I can say definitively you said q1 zero.
[01:31:33.180 --> 01:31:35.660]   Zero.
[01:31:35.700 --> 01:31:39.140]   But let me ask a question here. I because I am not informed on
[01:31:39.140 --> 01:31:44.620]   it. But you're a master strategist here. 1600 rated
[01:31:44.620 --> 01:31:45.780]   chess player sacks.
[01:31:45.780 --> 01:31:47.860]   That's not that good.
[01:31:47.860 --> 01:31:51.420]   Well, I mean, it's double 800 where I'm at. You're killing me
[01:31:51.420 --> 01:31:56.460]   in 27 moves on average. DeSantis is fighting with Disney over and
[01:31:56.460 --> 01:32:00.060]   over again. He's getting a little involved in the LG, GPT
[01:32:00.060 --> 01:32:03.220]   q everything and he just seems to be getting involved in the
[01:32:03.220 --> 01:32:07.420]   culture wars. Is that like a primary strategy and then he
[01:32:07.420 --> 01:32:11.260]   moves to the center when he comes to the general or and do
[01:32:11.260 --> 01:32:15.100]   you agree with this general fighting with Disney and the
[01:32:15.100 --> 01:32:19.260]   culture war stuff? Well, he's talking strategically, not your
[01:32:19.260 --> 01:32:20.980]   personal opinion on these issues. I know that you're a
[01:32:20.980 --> 01:32:22.140]   very tolerant person.
[01:32:22.140 --> 01:32:25.020]   Yeah. So I think this is an issue that works for him
[01:32:25.020 --> 01:32:26.980]   certainly in the Republican primary, but I also think it's
[01:32:26.980 --> 01:32:28.980]   gonna work for him in the general and you have to
[01:32:28.980 --> 01:32:32.220]   remember that this bill that they're fighting over was a
[01:32:32.220 --> 01:32:36.060]   parental rights bill, that basically it gave parents the
[01:32:36.060 --> 01:32:40.060]   right to know what their kids were being taught in schools and
[01:32:40.060 --> 01:32:43.820]   it basically prohibited the teaching of this sort of gender
[01:32:43.820 --> 01:32:47.780]   ideology and in schools and I think most parents are on board
[01:32:47.780 --> 01:32:51.580]   with that now. Yeah, he didn't go. Yeah, he didn't go looking
[01:32:51.580 --> 01:32:54.900]   to pick a fight with Disney Disney then got involved and
[01:32:54.900 --> 01:32:58.020]   took the side that calling this a don't say gay bill, which I
[01:32:58.020 --> 01:33:00.940]   think just factually is not true. The bill doesn't mention
[01:33:00.940 --> 01:33:05.060]   you know, gay or homosexuality or anything like that. It was
[01:33:05.060 --> 01:33:09.220]   really about this trans issue. And Disney got involved. And
[01:33:09.220 --> 01:33:13.300]   this was Bob Chaypek and Bob Chaypek lost his job and Iger
[01:33:13.300 --> 01:33:17.580]   came in and Iger has said that he he had basically lectured the
[01:33:17.580 --> 01:33:19.780]   Disney employees saying that we need to stay out of politics.
[01:33:19.780 --> 01:33:22.860]   And we need to respect our audience's views. So I think
[01:33:22.860 --> 01:33:25.420]   that it was Disney who kind of interfered. I think this is
[01:33:25.420 --> 01:33:29.020]   overall played to the census benefit. And look, the problem
[01:33:29.020 --> 01:33:32.180]   for Disney, they may win the battle over this or that tax
[01:33:32.180 --> 01:33:36.460]   benefit that they're fighting over. But they've lost the war
[01:33:36.460 --> 01:33:40.980]   over this issue, because parents used to be able to trust that
[01:33:40.980 --> 01:33:43.860]   they could just pop their kid down in front of a Disney movie
[01:33:43.860 --> 01:33:47.220]   or a Disney show like Disney was like the babysitter. And they
[01:33:47.220 --> 01:33:51.380]   just want 100% absolutely trusted all Disney content. And
[01:33:51.380 --> 01:33:54.340]   if you look at polling now, Disney's brand, it used to have
[01:33:54.340 --> 01:33:58.340]   like an NPS of like in the 50s is now in the single digits
[01:33:58.340 --> 01:34:01.700]   because let's call it half the country's parents, the more
[01:34:01.700 --> 01:34:04.900]   Republican ones don't fully trust Disney's content and
[01:34:04.900 --> 01:34:06.140]   programming anymore. Really?
[01:34:06.140 --> 01:34:11.620]   Yeah, implicitly. What could they ever do that's objectionable?
[01:34:11.620 --> 01:34:13.140]   I've never seen anything objectionable.
[01:34:13.140 --> 01:34:17.580]   A lot of parents are questioning what content Disney might be
[01:34:17.580 --> 01:34:19.860]   putting in there. Their recent programming. Obviously, we're
[01:34:19.860 --> 01:34:23.620]   not talking about the stuff that we grew up on. So look, whether
[01:34:23.660 --> 01:34:27.180]   you believe that is a problem or not, what I'm saying is this has
[01:34:27.180 --> 01:34:30.900]   been a brand disaster for Disney getting involved with to Santa's
[01:34:30.900 --> 01:34:33.820]   this way they should really, I think just try to patch this
[01:34:33.820 --> 01:34:35.540]   thing up. I don't understand the benefit.
[01:34:35.540 --> 01:34:39.020]   For just a bad look for both. It's a bad look for both people.
[01:34:39.020 --> 01:34:39.460]   Yeah.
[01:34:39.460 --> 01:34:42.340]   Well, I think I understand the benefit for to Santa's I don't
[01:34:42.340 --> 01:34:44.300]   understand the benefit for Disney. If I were there, I'd be
[01:34:44.300 --> 01:34:45.860]   trying to patch this up.
[01:34:45.860 --> 01:34:50.220]   I think there's a really valid discussion to be had about
[01:34:50.220 --> 01:34:53.220]   representation in movies and all that stuff. And I'm very pro
[01:34:53.220 --> 01:34:58.260]   that. The thing I think all parents agree is we should just
[01:34:58.260 --> 01:35:00.060]   at least know what's being taught to our kids. And we can
[01:35:00.060 --> 01:35:02.940]   have a thoughtful discussion about it. There seems to be some
[01:35:02.940 --> 01:35:06.980]   small group of people that thinks we should hide from
[01:35:06.980 --> 01:35:10.340]   parents what they're actually getting what's being taught. And
[01:35:10.340 --> 01:35:13.940]   I find that's very strange. I think just a little bit of like
[01:35:13.940 --> 01:35:17.740]   transparency and what's being taught in schools is an obvious
[01:35:17.740 --> 01:35:20.220]   thing that nobody should be disagreeing on it.
[01:35:20.540 --> 01:35:23.820]   To taxes point, I think it was Pew that put out a study
[01:35:23.820 --> 01:35:27.580]   recently, it is the most polarizing issue amongst
[01:35:27.580 --> 01:35:30.580]   Americans where Democrats and Republicans are literally on
[01:35:30.580 --> 01:35:33.660]   opposite sides of the spectrum. It's gonna be a big issue on the
[01:35:33.660 --> 01:35:37.380]   whole trans issue. Now, despite the polarization, in terms of
[01:35:37.380 --> 01:35:40.820]   the quantity of the number of people, it's actually an
[01:35:40.820 --> 01:35:43.860]   important issue for a small percentage of both sides. So
[01:35:43.860 --> 01:35:47.020]   it's a highly complicated political dynamic in America.
[01:35:47.020 --> 01:35:51.900]   Yeah, very. So this is where DeSantis clearly has taken the
[01:35:51.900 --> 01:35:54.820]   approach that not only is this important to the base to win the
[01:35:54.820 --> 01:35:57.420]   nomination, but it's going to scale into the general and it
[01:35:57.420 --> 01:35:59.900]   could very well be but it's a it's a very divisive issue.
[01:35:59.900 --> 01:36:05.540]   Yeah, I wish people were given a little bit more consideration
[01:36:05.540 --> 01:36:10.820]   and maybe they could have I feel like maybe we're covering this
[01:36:10.820 --> 01:36:13.740]   issue too much. I you know, I've heard some other folks in the
[01:36:13.740 --> 01:36:15.980]   community saying like, maybe people could be given a little
[01:36:15.980 --> 01:36:18.180]   bit of their privacy and to handle these things.
[01:36:18.180 --> 01:36:20.260]   I think you're right, Jake out in this sense, I think this
[01:36:20.260 --> 01:36:23.380]   issue has become a lightning rod. And, and whenever you have a
[01:36:23.380 --> 01:36:26.060]   lightning rod issue, the amount of attention paid to it, it
[01:36:26.060 --> 01:36:29.500]   seems disproportionate to the attention on that issue.
[01:36:29.500 --> 01:36:34.140]   However, I would say that this is a lightning rod for a larger
[01:36:34.140 --> 01:36:38.260]   issue, which is the quality of education in this country, which
[01:36:38.260 --> 01:36:43.620]   I think is shockingly bad. And it's bad. Because of the decline
[01:36:43.620 --> 01:36:46.660]   of standards. They're getting rid of advanced math, they're
[01:36:46.660 --> 01:36:47.060]   getting rid of
[01:36:47.060 --> 01:36:47.820]   unions,
[01:36:47.820 --> 01:36:48.740]   asking,
[01:36:48.740 --> 01:36:53.060]   competition, and and the schools are run by these unions who are
[01:36:53.060 --> 01:36:54.860]   managing it for their own benefit, not for the benefit of
[01:36:54.860 --> 01:36:57.580]   the students. And look, there is a significant ideological
[01:36:57.580 --> 01:37:00.540]   component that's crept into these schools as well. So look,
[01:37:00.540 --> 01:37:03.740]   I think that overall, I think that when you get into the
[01:37:03.740 --> 01:37:07.540]   general, you have to up level the issue and talk about it in
[01:37:07.540 --> 01:37:10.940]   broader terms that every kid in our country deserves a high
[01:37:10.980 --> 01:37:14.700]   quality, non ideological education. I think if you can do
[01:37:14.700 --> 01:37:18.780]   that, you will get 70 80% of the public on your side on this
[01:37:18.780 --> 01:37:19.140]   issue.
[01:37:19.140 --> 01:37:23.260]   Yeah, I feel like, yeah, I think that's, yeah, I think we can all
[01:37:23.260 --> 01:37:25.020]   agree on that. Democrats, Republicans, everybody in
[01:37:25.020 --> 01:37:27.500]   between, if you're a parent, you're not looking for an
[01:37:27.500 --> 01:37:30.140]   ideological battle at school, you're looking for math,
[01:37:30.140 --> 01:37:34.220]   science, technology, history, creativity, you know, there's a
[01:37:34.220 --> 01:37:36.620]   whole bunch of other things that we should be really focused on.
[01:37:36.620 --> 01:37:38.940]   Alright, listen, it's been another amazing episode of the
[01:37:38.940 --> 01:37:42.700]   oil and podcast to people going to the episode 125 meetups, you
[01:37:42.700 --> 01:37:46.860]   can type in all in meetups. Our team over there, we have super
[01:37:46.860 --> 01:37:50.820]   fans are doing it in over 50 cities, the day this comes out.
[01:37:50.820 --> 01:37:53.780]   So you may miss it, but you sign up for the next one. I'll be
[01:37:53.780 --> 01:37:57.260]   phoning in and zooming into them. So for the fans, are you
[01:37:57.260 --> 01:38:00.340]   crazy lunatics getting together? Have a great time. Have a great
[01:38:00.340 --> 01:38:04.820]   time and tweet it and mention us on Twitter. For the Sultan of
[01:38:04.820 --> 01:38:08.980]   science, the rain man, the dictator I am the world's
[01:38:08.980 --> 01:38:11.100]   greatest moderator and we'll see you next time. Bye bye. Bye
[01:38:11.100 --> 01:38:11.500]   bye.
[01:38:11.500 --> 01:38:17.340]   All right. Let your winners ride. Rain Man David Sackman.
[01:38:17.340 --> 01:38:23.900]   We open source it to the fans and they've just gone crazy with
[01:38:23.900 --> 01:38:24.700]   it. Love you.
[01:38:24.700 --> 01:38:33.940]   Besties are
[01:38:33.940 --> 01:38:37.260]   dog taking a
[01:38:37.260 --> 01:38:37.940]   driveway.
[01:38:38.940 --> 01:38:39.220]   Oh,
[01:38:39.220 --> 01:38:46.340]   we should all just get a room and just have one big huge orgy
[01:38:46.340 --> 01:38:48.180]   because they're all just useless. It's like this like
[01:38:48.180 --> 01:38:50.460]   sexual tension that they just need to release somehow.
[01:38:50.460 --> 01:38:53.260]   What you're about to be
[01:38:53.260 --> 01:38:55.220]   your feet
[01:38:55.220 --> 01:38:57.620]   waiting to get
[01:38:57.620 --> 01:38:58.460]   merch. He's our
[01:38:58.460 --> 01:39:00.460]   I'm going all in
[01:39:00.460 --> 01:39:08.340]   I'm going all in
[01:39:08.340 --> 01:39:09.580]   (music)
[01:39:09.580 --> 01:39:19.520]   [BLANK_AUDIO]

