
[00:00:00.000 --> 00:00:05.000]   I'm Cal Newport and this is Deep Questions, episode 193.
[00:00:05.000 --> 00:00:16.840]   I'm here in my Deep Work HQ, joined once again
[00:00:16.840 --> 00:00:21.160]   after his well-missed absence by my producer, Jesse.
[00:00:21.160 --> 00:00:22.640]   Jesse, welcome back.
[00:00:22.640 --> 00:00:24.340]   - Thanks, good to be back.
[00:00:24.340 --> 00:00:28.700]   - I hope your tournament, the lacrosse tournament
[00:00:28.700 --> 00:00:31.440]   for the team you helped coach, I hope that all went well.
[00:00:31.440 --> 00:00:33.400]   - Yeah, it went pretty good.
[00:00:33.400 --> 00:00:35.360]   I coached at Gonzaga College High School
[00:00:35.360 --> 00:00:37.800]   down in Washington, D.C., right next to the Capitol.
[00:00:37.800 --> 00:00:39.480]   We had some ups and downs,
[00:00:39.480 --> 00:00:42.980]   but we're trying to play better lacrosse.
[00:00:42.980 --> 00:00:44.120]   - Yeah, I mean, I like to imagine,
[00:00:44.120 --> 00:00:45.840]   I don't know if this is true,
[00:00:45.840 --> 00:00:47.560]   but I get a kick out of imagining
[00:00:47.560 --> 00:00:52.480]   that your coaching philosophy entirely comes out of my books.
[00:00:52.480 --> 00:00:53.320]   - Yeah, pretty much.
[00:00:53.320 --> 00:00:57.280]   - Yeah, that you're out there yelling at your kids.
[00:00:57.280 --> 00:01:01.000]   - Enough with all of this hyperactive hive mind,
[00:01:01.000 --> 00:01:02.680]   ad hoc, back and forth,
[00:01:02.680 --> 00:01:04.440]   unstructured communication on the field.
[00:01:04.440 --> 00:01:07.680]   We need communication protocols
[00:01:07.680 --> 00:01:10.040]   to avoid all of the cognitive capacity hits
[00:01:10.040 --> 00:01:12.000]   from this context switching.
[00:01:12.000 --> 00:01:13.680]   So now here's how it works.
[00:01:13.680 --> 00:01:18.320]   If you wanna make a pass to the player down by the net,
[00:01:18.320 --> 00:01:19.360]   there's a Google Doc.
[00:01:19.360 --> 00:01:22.700]   So you put that in the Google Doc.
[00:01:22.700 --> 00:01:24.720]   We can check that when the player down by the net
[00:01:24.720 --> 00:01:26.080]   is ready to check it.
[00:01:26.080 --> 00:01:28.320]   You're not gonna be able to interrupt them
[00:01:28.320 --> 00:01:30.360]   and create a context shift.
[00:01:30.360 --> 00:01:32.440]   That's the secret to your success, I assume.
[00:01:32.440 --> 00:01:33.700]   But is my terminology right?
[00:01:33.700 --> 00:01:35.040]   The player down by the net,
[00:01:35.040 --> 00:01:36.320]   there's probably a good term.
[00:01:36.320 --> 00:01:37.160]   - Attackman.
[00:01:37.160 --> 00:01:37.980]   - The attackman.
[00:01:37.980 --> 00:01:39.120]   - But especially on defense,
[00:01:39.120 --> 00:01:41.280]   so it either goes really well or it goes really bad.
[00:01:41.280 --> 00:01:43.560]   So the communication is just on point,
[00:01:43.560 --> 00:01:45.800]   don't give up any goals, or we just give up 20.
[00:01:45.800 --> 00:01:47.480]   - Well, that's what, I mean,
[00:01:47.480 --> 00:01:49.840]   I think that's your key, is that's gonna be the secret.
[00:01:49.840 --> 00:01:51.380]   - Especially sometimes if the Google Drive
[00:01:51.380 --> 00:01:54.360]   doesn't refresh when they come over to the sideline.
[00:01:54.360 --> 00:01:55.200]   - Yeah, I mean, look.
[00:01:55.200 --> 00:01:56.680]   - And then they're lost.
[00:01:56.680 --> 00:01:57.920]   - I don't wanna tell you how to do your business,
[00:01:57.920 --> 00:02:01.200]   but I was just scouting St. John's,
[00:02:01.200 --> 00:02:04.200]   what, their number one team in the country this year?
[00:02:04.200 --> 00:02:06.360]   - They are, they're in our league, they're good.
[00:02:06.360 --> 00:02:08.520]   - Yeah, well, look, I don't wanna give away their secrets.
[00:02:08.520 --> 00:02:12.040]   I was scouting them, but I'll give it to you secretly.
[00:02:12.040 --> 00:02:13.060]   Trello boards.
[00:02:13.060 --> 00:02:16.280]   That is how St. John's is dominating.
[00:02:16.280 --> 00:02:19.120]   They are using Trello boards to keep track
[00:02:19.120 --> 00:02:21.300]   of their different obligations on the field
[00:02:21.300 --> 00:02:23.200]   in a way that allows them to attach files
[00:02:23.200 --> 00:02:24.320]   and see context quickly.
[00:02:24.320 --> 00:02:25.960]   So look, I don't wanna speak out of school.
[00:02:25.960 --> 00:02:27.440]   - Probably definitely helps with the recruiting,
[00:02:27.440 --> 00:02:28.280]   I'll tell you that.
[00:02:28.280 --> 00:02:31.080]   - Yeah, they're like, look, you come here to St. John's
[00:02:31.080 --> 00:02:33.960]   and you're not gonna be on Slack.
[00:02:33.960 --> 00:02:36.680]   We're gonna have communication protocols
[00:02:36.680 --> 00:02:38.320]   that minimize context shifting.
[00:02:38.320 --> 00:02:39.400]   They have a giant picture of me,
[00:02:39.400 --> 00:02:41.260]   I don't know if you've seen this in their locker room,
[00:02:41.260 --> 00:02:43.280]   but there's like a giant picture of me
[00:02:43.280 --> 00:02:46.240]   giving double thumbs up and it just says,
[00:02:46.240 --> 00:02:47.720]   do it for Cal today.
[00:02:47.720 --> 00:02:48.560]   - Yeah.
[00:02:48.560 --> 00:02:49.680]   - And they hit it as, you know, like in Notre Dame,
[00:02:49.680 --> 00:02:52.500]   they all hit it as they go out and they get real psyched.
[00:02:52.500 --> 00:02:54.220]   - I'm trying to get Gonzaga to be the only team
[00:02:54.220 --> 00:02:56.720]   in America that doesn't use social media,
[00:02:56.720 --> 00:02:58.280]   but that's kind of hard to do.
[00:02:58.280 --> 00:03:00.160]   So all high school kids, it's hard.
[00:03:00.160 --> 00:03:01.720]   But remember that, there's this thing
[00:03:01.720 --> 00:03:03.720]   that went around for a while.
[00:03:03.720 --> 00:03:05.400]   I mean, or I got it sent a lot.
[00:03:05.400 --> 00:03:06.380]   It was a couple of years ago,
[00:03:06.380 --> 00:03:08.240]   there was one of the college basketball teams,
[00:03:08.240 --> 00:03:09.320]   I think it was Texas Tech.
[00:03:09.320 --> 00:03:11.160]   I think we've talked about this before.
[00:03:11.160 --> 00:03:13.840]   They banned phones on the road.
[00:03:13.840 --> 00:03:16.240]   Like you can't bring your phone with you on the road,
[00:03:16.240 --> 00:03:18.320]   you can't bring it with you into the hotel room.
[00:03:18.320 --> 00:03:19.600]   Like they were like, we wanna just focus.
[00:03:19.600 --> 00:03:21.920]   And the team made like a really deep
[00:03:21.920 --> 00:03:23.160]   March Madness run that year.
[00:03:23.780 --> 00:03:25.020]   There's something to that.
[00:03:25.020 --> 00:03:28.620]   And there's research on that from the NBA,
[00:03:28.620 --> 00:03:32.820]   where they could correlate Twitter usage,
[00:03:32.820 --> 00:03:35.040]   'cause you can see it, there's a record,
[00:03:35.040 --> 00:03:36.460]   with performance.
[00:03:36.460 --> 00:03:38.380]   And it was economists who were doing this.
[00:03:38.380 --> 00:03:41.180]   And they could see, okay, the players on a night
[00:03:41.180 --> 00:03:42.940]   in which they were up doing Twitter,
[00:03:42.940 --> 00:03:44.620]   like they were tweeting, maybe it was Instagram,
[00:03:44.620 --> 00:03:45.580]   I thought it was Twitter,
[00:03:45.580 --> 00:03:48.300]   their performance was under their average the next day.
[00:03:48.300 --> 00:03:49.820]   So there's like, there's these direct connections,
[00:03:49.820 --> 00:03:52.620]   I think, obviously between social media and sports.
[00:03:52.620 --> 00:03:54.260]   'Cause I think it's why some of my stuff,
[00:03:54.260 --> 00:03:56.380]   like digital minimalism is popular
[00:03:56.380 --> 00:03:57.660]   among professional athletes.
[00:03:57.660 --> 00:03:59.460]   Is that like every epsilon matters.
[00:03:59.460 --> 00:04:01.440]   This is a pretty big epsilon.
[00:04:01.440 --> 00:04:04.180]   And people are starting to figure that out.
[00:04:04.180 --> 00:04:07.060]   - Yeah, it all plays into focus, what you talk about.
[00:04:07.060 --> 00:04:09.300]   - Yeah, and when you're in sports, focus.
[00:04:09.300 --> 00:04:10.740]   Focus is everything.
[00:04:10.740 --> 00:04:12.300]   All right, well, speaking of focus,
[00:04:12.300 --> 00:04:14.100]   we have an announcement,
[00:04:14.100 --> 00:04:16.460]   another administrative announcement.
[00:04:16.460 --> 00:04:20.420]   We are for our, what we're gonna call our spring season,
[00:04:20.420 --> 00:04:23.020]   or our summer season, however we wanna call it,
[00:04:23.020 --> 00:04:25.140]   are temporarily dropping down
[00:04:25.140 --> 00:04:30.140]   to a one episode per week format.
[00:04:30.140 --> 00:04:33.580]   So we'll have one episode per week.
[00:04:33.580 --> 00:04:35.820]   The episode will probably be longer
[00:04:35.820 --> 00:04:37.680]   than they had been before.
[00:04:37.680 --> 00:04:40.980]   We're gonna mix in calls with written questions
[00:04:40.980 --> 00:04:42.060]   with various segments.
[00:04:42.060 --> 00:04:45.580]   We'll all get mixed into these longer episodes.
[00:04:45.580 --> 00:04:47.940]   A lot of it will go on YouTube, individual segments.
[00:04:47.940 --> 00:04:51.180]   We're gonna do some straight to YouTube videos as well.
[00:04:51.180 --> 00:04:53.140]   We're kind of messing around with that.
[00:04:53.140 --> 00:04:54.940]   But here's the reason why
[00:04:54.940 --> 00:04:57.100]   we're going through the summer season is we have,
[00:04:57.100 --> 00:04:59.620]   it's good news, but we have grown the show enough
[00:04:59.620 --> 00:05:04.540]   that we can actually satisfy our ad contracts
[00:05:04.540 --> 00:05:06.180]   in one episode per week.
[00:05:06.180 --> 00:05:08.260]   So it used to be the ad contracts we sold,
[00:05:08.260 --> 00:05:10.060]   and we've sold out all of 2022.
[00:05:10.060 --> 00:05:13.620]   We would play each ad on Monday and Thursday
[00:05:14.660 --> 00:05:19.620]   to get to or beyond the number of downloads we had sold.
[00:05:19.620 --> 00:05:22.620]   Now the show is popular enough that in just one episode,
[00:05:22.620 --> 00:05:26.260]   we will hit our obligations for how many downloads
[00:05:26.260 --> 00:05:29.660]   each ad is supposed to be attached to.
[00:05:29.660 --> 00:05:30.860]   So what we could have done is said,
[00:05:30.860 --> 00:05:33.780]   great, we can now double our ad inventory.
[00:05:33.780 --> 00:05:36.620]   So put the ads we sold on Monday's episode,
[00:05:36.620 --> 00:05:38.860]   sell new ads for the episodes on Thursday.
[00:05:38.860 --> 00:05:41.220]   But I wanted to put in the practice what I preach,
[00:05:41.220 --> 00:05:43.260]   the craftsman bucket of the deep life.
[00:05:43.260 --> 00:05:45.580]   I stepped back and said, what I would rather do first
[00:05:45.580 --> 00:05:47.660]   is actually take the time it would free up
[00:05:47.660 --> 00:05:49.660]   to temporarily not record two episodes,
[00:05:49.660 --> 00:05:51.340]   but just record one episode.
[00:05:51.340 --> 00:05:54.340]   Take the time that frees up to improve the show.
[00:05:54.340 --> 00:05:57.860]   To think deeply about what's working, what's not working,
[00:05:57.860 --> 00:05:59.860]   to do more writing before we get on air,
[00:05:59.860 --> 00:06:01.820]   to see how can I make this show,
[00:06:01.820 --> 00:06:05.020]   to use a phrase that you may have heard me say before,
[00:06:05.020 --> 00:06:06.820]   be so good it can't be ignored.
[00:06:06.820 --> 00:06:08.900]   So that's what Jess and I are trying.
[00:06:08.900 --> 00:06:10.100]   We're cutting back to one episode,
[00:06:10.100 --> 00:06:12.340]   we're doubling the amount of time we're spending prepping,
[00:06:12.340 --> 00:06:14.860]   we're gonna be experimenting, we're gonna be tightening,
[00:06:14.860 --> 00:06:16.780]   we're gonna be trying out new segments.
[00:06:16.780 --> 00:06:18.380]   And the hope is we'll come out of the summer
[00:06:18.380 --> 00:06:21.020]   with a even better show.
[00:06:21.020 --> 00:06:24.500]   We'll push the show up to its next level.
[00:06:24.500 --> 00:06:26.460]   With that in mind, we're always happy to hear feedback
[00:06:26.460 --> 00:06:28.380]   on what you like or don't like on the show.
[00:06:28.380 --> 00:06:30.140]   Your best bet's to send that towards Jesse,
[00:06:30.140 --> 00:06:33.500]   jesse@calnewport.com.
[00:06:33.500 --> 00:06:36.740]   He's more likely to see and keep track of that than I am.
[00:06:36.740 --> 00:06:38.100]   And so send your thoughts, what's working,
[00:06:38.100 --> 00:06:41.300]   what's not working to jesse@calnewport.com.
[00:06:41.300 --> 00:06:45.540]   And hopefully you'll like the innovations we attempt
[00:06:45.540 --> 00:06:48.260]   in the weeks and months ahead.
[00:06:48.260 --> 00:06:51.340]   So what do you think, Jesse, one episode a week?
[00:06:51.340 --> 00:06:52.740]   I think it'll be good.
[00:06:52.740 --> 00:06:54.140]   - I think it would be good.
[00:06:54.140 --> 00:06:55.980]   You put a lot of thought into stuff
[00:06:55.980 --> 00:06:57.420]   and you've been thinking about it
[00:06:57.420 --> 00:06:59.260]   and bouncing some ideas off myself.
[00:06:59.260 --> 00:07:01.180]   And I think, like you said,
[00:07:01.180 --> 00:07:03.140]   you can make the show even better.
[00:07:03.140 --> 00:07:05.820]   And I know that your audience likes to hear from you a lot,
[00:07:05.820 --> 00:07:08.900]   but I think that the show is like real solid
[00:07:08.900 --> 00:07:10.460]   with like some really good segments.
[00:07:10.460 --> 00:07:13.300]   - Yeah, and then once you figure out,
[00:07:13.300 --> 00:07:16.460]   once you figure out the format that's really working,
[00:07:16.460 --> 00:07:18.340]   then it can become more efficient to work on it again.
[00:07:18.340 --> 00:07:20.660]   And then we can expand the amount we're producing.
[00:07:20.660 --> 00:07:21.700]   But anyways, it should be fun.
[00:07:21.700 --> 00:07:23.300]   Also, it's the summer and I'm tired
[00:07:23.300 --> 00:07:26.380]   and it's nice to just have a little bit more breathing room.
[00:07:26.380 --> 00:07:28.700]   So, you know, we've definitely, okay, behind the scenes,
[00:07:28.700 --> 00:07:29.620]   Jesse, you will attest to this.
[00:07:29.620 --> 00:07:31.580]   There's definitely, especially during my busy period
[00:07:31.580 --> 00:07:33.580]   in the spring have been times where it's like,
[00:07:33.580 --> 00:07:36.060]   we have this window and there is a lot of recording
[00:07:36.060 --> 00:07:37.300]   that has to be done.
[00:07:37.300 --> 00:07:39.420]   And I'm basically like running into the room,
[00:07:39.420 --> 00:07:41.820]   jumping down, grabbing the mic, let's roll.
[00:07:41.820 --> 00:07:45.660]   Like we've had to do some pretty high intensity,
[00:07:45.660 --> 00:07:48.020]   high stress, rapid recording.
[00:07:48.020 --> 00:07:49.660]   So it's gonna be nice that we can just have
[00:07:49.660 --> 00:07:51.260]   some breathing room around our sessions,
[00:07:51.260 --> 00:07:53.460]   actually kind of enjoy it a little bit more.
[00:07:53.460 --> 00:08:00.060]   All right, well, let us do our first segment.
[00:08:00.060 --> 00:08:03.700]   I have been enjoying doing some of these
[00:08:03.700 --> 00:08:06.380]   news reaction segments.
[00:08:06.380 --> 00:08:07.740]   What I'm really looking for, of course,
[00:08:07.740 --> 00:08:09.340]   is not to just give my opinion on everything
[00:08:09.340 --> 00:08:11.380]   and who cares, but to look at segments in the news
[00:08:11.380 --> 00:08:14.300]   that overlap things that we talk about here on the show
[00:08:14.300 --> 00:08:17.460]   and give me a chance to actually bounce off them
[00:08:17.460 --> 00:08:20.020]   and elaborate some of the theories
[00:08:20.020 --> 00:08:21.300]   I've been developing on the show,
[00:08:21.300 --> 00:08:24.100]   some of the theories that I talk about commonly on the show.
[00:08:24.100 --> 00:08:25.980]   So it's news that's relevant to the show.
[00:08:25.980 --> 00:08:29.260]   And unlike prior Cal Reacts to the News segments,
[00:08:29.260 --> 00:08:32.860]   I actually wanna do several different pieces here.
[00:08:32.860 --> 00:08:36.900]   So I'm gonna start with an article returning
[00:08:36.900 --> 00:08:38.060]   to what we've been discussing,
[00:08:38.060 --> 00:08:43.060]   returning to Elon Musk and his potential takeover of Twitter.
[00:08:43.060 --> 00:08:47.380]   There's an article I read this morning,
[00:08:47.380 --> 00:08:49.580]   it came out the morning I'm recording this,
[00:08:49.580 --> 00:08:52.180]   from the New York Times.
[00:08:52.180 --> 00:08:56.180]   It was titled, "Elon Musk Details His Plan to Pay
[00:08:56.180 --> 00:09:01.060]   for a $46.5 Billion Takeover of Twitter."
[00:09:01.060 --> 00:09:03.420]   And this article starts by noting,
[00:09:03.420 --> 00:09:06.660]   Elon Musk said on Thursday that he had commitments
[00:09:06.660 --> 00:09:11.660]   worth $46.5 billion to finance his proposed bid for Twitter
[00:09:11.660 --> 00:09:14.940]   and was exploring whether to launch a hostile takeover
[00:09:14.940 --> 00:09:17.580]   for the social media company.
[00:09:17.580 --> 00:09:20.740]   Jesse, I think he's beating out the $5,000 bid
[00:09:20.740 --> 00:09:21.620]   that we put in.
[00:09:21.620 --> 00:09:24.460]   I think our vision for Cal Newport Twitter,
[00:09:24.460 --> 00:09:27.380]   look, they haven't said no yet,
[00:09:27.380 --> 00:09:29.540]   but it looks like Elon has the better bid
[00:09:29.540 --> 00:09:31.060]   he's putting together here.
[00:09:31.060 --> 00:09:31.940]   The article goes on to say,
[00:09:31.940 --> 00:09:34.020]   "The financial commitments gathered a week
[00:09:34.020 --> 00:09:37.020]   after Mr. Musk made an unsolicited offer for Twitter,
[00:09:37.020 --> 00:09:38.940]   put pressure on the social media company's board
[00:09:38.940 --> 00:09:41.940]   to take his advances seriously."
[00:09:41.940 --> 00:09:45.060]   "It's serious," Stephen David Solomon,
[00:09:45.060 --> 00:09:46.300]   a professor at the School of Law
[00:09:46.300 --> 00:09:47.700]   at the University of California at Berkeley,
[00:09:47.700 --> 00:09:49.020]   said of the new filing.
[00:09:49.020 --> 00:09:50.540]   "He's getting more professional,
[00:09:50.540 --> 00:09:53.140]   and this is starting to look like a normal hostile bid.
[00:09:53.140 --> 00:09:57.340]   You do not do that unless you are going to launch an offer."
[00:09:57.340 --> 00:10:02.940]   So I was actually, I think I was leaning towards
[00:10:02.940 --> 00:10:07.300]   this was probably not for real until I read this article.
[00:10:07.300 --> 00:10:09.380]   I thought he might've just been messing with people.
[00:10:09.380 --> 00:10:12.260]   This article is seeming to imply
[00:10:12.260 --> 00:10:13.700]   that he is actually serious.
[00:10:13.700 --> 00:10:15.220]   Did you take him seriously, Jesse?
[00:10:15.220 --> 00:10:16.580]   You were never quite sure
[00:10:16.580 --> 00:10:18.140]   if he was actually gonna do this.
[00:10:18.140 --> 00:10:20.780]   - I thought he was serious.
[00:10:20.780 --> 00:10:22.740]   - Okay, so you more understood it.
[00:10:22.740 --> 00:10:25.940]   Now, the breaking news that almost happened this morning
[00:10:25.940 --> 00:10:29.540]   is he tweeted today, the day we're recording this,
[00:10:29.540 --> 00:10:31.020]   what was his exact words here?
[00:10:31.020 --> 00:10:33.820]   It was "moving on..."
[00:10:33.820 --> 00:10:37.540]   Now, this is big news in part
[00:10:37.540 --> 00:10:39.460]   because I never see Twitter breaking news
[00:10:39.460 --> 00:10:41.300]   because I don't use Twitter,
[00:10:41.300 --> 00:10:44.780]   but I had to go on the Twitter to get this tweet thread
[00:10:44.780 --> 00:10:46.140]   I'm gonna talk about for the next story
[00:10:46.140 --> 00:10:49.060]   that a user sent me, and it was popped up.
[00:10:49.060 --> 00:10:50.420]   So I was like, maybe that was must saying
[00:10:50.420 --> 00:10:51.420]   he was moving on from this,
[00:10:51.420 --> 00:10:53.180]   but then he clarified, it was breaking news.
[00:10:53.180 --> 00:10:55.300]   It was 14 minutes before I came over here.
[00:10:55.300 --> 00:10:57.740]   He clarified that when he said "moving on,"
[00:10:57.740 --> 00:10:59.940]   it wasn't about his Twitter takeover bid.
[00:10:59.940 --> 00:11:04.260]   It was him moving on from making fun of Bill Gates
[00:11:04.260 --> 00:11:08.220]   because Bill Gates had shorted Tesla stock
[00:11:08.220 --> 00:11:10.100]   at a time where he was talking a lot about climate change.
[00:11:10.100 --> 00:11:13.660]   So I guess Elon Musk has been dunking on Gates recently
[00:11:13.660 --> 00:11:14.500]   for that.
[00:11:14.500 --> 00:11:17.060]   Captain climate change is shorting Tesla stock.
[00:11:17.060 --> 00:11:18.780]   And so he was moving on from that.
[00:11:18.780 --> 00:11:22.300]   Musk goes on to say on Twitter,
[00:11:22.300 --> 00:11:23.500]   "If our Twitter bid succeeds,
[00:11:23.500 --> 00:11:27.740]   "we will defeat the spam bots or die trying."
[00:11:27.740 --> 00:11:30.900]   So that's interesting because that's a new spin.
[00:11:30.900 --> 00:11:34.940]   I think a lot of the coverage of Musk's plans for Twitter
[00:11:34.940 --> 00:11:36.460]   had to do with content moderation.
[00:11:36.460 --> 00:11:38.540]   We'll get into that more here in a second.
[00:11:38.540 --> 00:11:41.940]   And here he is emphasizing another type of improvement
[00:11:41.940 --> 00:11:45.100]   he would look to do in this case, get rid of spam bots.
[00:11:45.100 --> 00:11:48.460]   That's interesting that he is making that pivot.
[00:11:48.460 --> 00:11:51.100]   The final thing is I would point out
[00:11:51.100 --> 00:11:55.340]   that Morgan Stanley is a big part of the money
[00:11:55.340 --> 00:11:58.220]   he is raising for this takeover bid.
[00:11:58.220 --> 00:12:02.340]   And they quote a lecturer from Cornell University saying,
[00:12:02.340 --> 00:12:04.380]   "There are lots of very senior people at Morgan Stanley
[00:12:04.380 --> 00:12:06.380]   "that are responsible for that brand.
[00:12:06.380 --> 00:12:08.260]   "That in my view would not allow this to happen
[00:12:08.260 --> 00:12:10.460]   "unless there was some level of seriousness behind it."
[00:12:10.460 --> 00:12:15.460]   Okay, so all of the coverage seems to be saying
[00:12:15.460 --> 00:12:17.460]   this is probably serious.
[00:12:17.460 --> 00:12:19.580]   It's probably not Musk.
[00:12:19.580 --> 00:12:21.180]   It's probably not Musk messing with us.
[00:12:21.180 --> 00:12:23.140]   Here's the two thoughts I have about that.
[00:12:23.140 --> 00:12:26.100]   One, it really still could be Musk messing with everyone.
[00:12:26.100 --> 00:12:28.380]   I think he gets enjoyment out of it.
[00:12:28.380 --> 00:12:29.940]   I think he's very persuasive.
[00:12:29.940 --> 00:12:33.140]   I think he could persuade Morgan Stanley to come on board
[00:12:33.140 --> 00:12:35.940]   even if he never actually planned to make the bid.
[00:12:35.940 --> 00:12:38.540]   So I'm still not sure about that.
[00:12:38.540 --> 00:12:40.380]   The other thing I was thinking about this morning
[00:12:40.380 --> 00:12:43.860]   is that there could be a silver lining
[00:12:43.860 --> 00:12:48.660]   to this Musk takeover that isn't really being reported,
[00:12:48.660 --> 00:12:50.780]   but I think it could be good.
[00:12:50.780 --> 00:12:54.540]   And that's the fact that the media for the most part
[00:12:54.540 --> 00:12:58.620]   doesn't like Elon Musk for a lot of complicated reasons,
[00:12:58.620 --> 00:13:00.660]   but of course the fact that he messes with them this way
[00:13:00.660 --> 00:13:02.140]   is probably one of them.
[00:13:02.140 --> 00:13:04.500]   So if he did take over Twitter,
[00:13:04.500 --> 00:13:10.700]   the media might stop using Twitter and focusing on Twitter
[00:13:10.700 --> 00:13:14.620]   and allowing Twitter to influence them as much.
[00:13:14.620 --> 00:13:15.780]   Because on principle, they're like,
[00:13:15.780 --> 00:13:17.220]   "I don't like Elon Musk.
[00:13:17.220 --> 00:13:18.500]   "Twitter is now his.
[00:13:18.500 --> 00:13:20.300]   "I don't wanna use Twitter as much anymore
[00:13:20.300 --> 00:13:22.860]   "as a TV reporter or a newspaper reporter.
[00:13:22.860 --> 00:13:26.220]   "I don't wanna be a part of something that he owns."
[00:13:26.220 --> 00:13:30.180]   And this would be good for the Republic.
[00:13:30.180 --> 00:13:33.500]   I think if reporters and journalists in general
[00:13:33.500 --> 00:13:36.300]   spent less time on Twitter and being influenced by Twitter,
[00:13:36.300 --> 00:13:37.460]   it's probably better for everybody.
[00:13:37.460 --> 00:13:39.140]   So there's a silver lining here.
[00:13:39.140 --> 00:13:42.020]   If Musk continues acting sort of erratically
[00:13:42.020 --> 00:13:43.860]   and the media continues to dislike him
[00:13:43.860 --> 00:13:45.220]   and he takes over Twitter,
[00:13:45.220 --> 00:13:49.180]   maybe it will actually ironically and paradoxically
[00:13:49.180 --> 00:13:52.140]   reduce the impact of Twitter on our culture.
[00:13:52.140 --> 00:13:55.300]   And I think that would be a good thing.
[00:13:55.300 --> 00:13:59.980]   Basically anything that hurts Twitter, I'm kind of a fan of.
[00:13:59.980 --> 00:14:02.220]   All right, so then I had a second article here
[00:14:02.220 --> 00:14:07.060]   that elaborates on what's going on with Musk and Twitter.
[00:14:07.060 --> 00:14:08.860]   And maybe it's not fair to call it an article.
[00:14:08.860 --> 00:14:10.140]   It's a Twitter thread.
[00:14:10.140 --> 00:14:13.580]   So there's all sorts of recursive ironies abounding here.
[00:14:14.620 --> 00:14:19.180]   It's from the former CEO of Reddit, Yisheng Wang,
[00:14:19.180 --> 00:14:23.860]   and hat tip to listener Andy, who emailed this to me.
[00:14:23.860 --> 00:14:26.220]   In general, by the way, if you have tips or articles
[00:14:26.220 --> 00:14:27.580]   you think I would like,
[00:14:27.580 --> 00:14:32.380]   my longtime address for that is interesting@calnewport.com.
[00:14:32.380 --> 00:14:34.980]   That's where Andy sent me this Twitter thread.
[00:14:34.980 --> 00:14:36.300]   And I thought it was quite interesting
[00:14:36.300 --> 00:14:38.740]   as this has gotten quite a lot of play.
[00:14:38.740 --> 00:14:42.180]   Yisheng starts in this thread by saying,
[00:14:42.180 --> 00:14:43.580]   "I've now been asked multiple times
[00:14:43.580 --> 00:14:46.460]   for my take on Elon's offer for Twitter.
[00:14:46.460 --> 00:14:48.820]   So fine, this is what I think about that."
[00:14:48.820 --> 00:14:52.180]   All right, so here's his main point.
[00:14:52.180 --> 00:14:55.980]   If Elon takes over Twitter, he's in for a world of pain.
[00:14:55.980 --> 00:14:58.980]   He has no idea.
[00:14:58.980 --> 00:15:01.900]   I'm gonna summarize, this is a long thread.
[00:15:01.900 --> 00:15:06.140]   But Yisheng says, "There is this old culture of the internet,
[00:15:06.140 --> 00:15:09.780]   roughly Web 1.0 and early Web 2.0,
[00:15:09.780 --> 00:15:13.100]   that had a very strong free speech culture.
[00:15:13.100 --> 00:15:15.260]   This free speech idea arose out of a culture
[00:15:15.260 --> 00:15:17.180]   of late '90s America, where the main people
[00:15:17.180 --> 00:15:18.380]   who were interested in censorship
[00:15:18.380 --> 00:15:19.980]   were religious conservatives.
[00:15:19.980 --> 00:15:22.660]   In practical terms, this meant that they would try to ban porn
[00:15:22.660 --> 00:15:25.260]   or other imagined moral degeneracy on the internet.
[00:15:25.260 --> 00:15:29.300]   Many of the older tech leaders today,"
[00:15:29.300 --> 00:15:32.460]   he points to Elon Musk or Marc Andreessen,
[00:15:32.460 --> 00:15:33.820]   "grew up with that internet.
[00:15:33.820 --> 00:15:36.060]   To them, the internet represented freedom, a new frontier,
[00:15:36.060 --> 00:15:38.060]   a flowering of the human spirit, and a great optimism
[00:15:38.060 --> 00:15:42.220]   that technology could birth a new golden age of mankind."
[00:15:42.220 --> 00:15:43.860]   Skipping ahead here a little bit.
[00:15:43.860 --> 00:15:48.340]   Reddit, which he ran, "was born in this last years
[00:15:48.340 --> 00:15:50.380]   of this old internet when free speech meant freedom
[00:15:50.380 --> 00:15:52.380]   from religious conservatives trying to take down porn
[00:15:52.380 --> 00:15:54.180]   and sometimes first-person shooters.
[00:15:54.180 --> 00:15:55.580]   And so we tried to preserve that ideal,
[00:15:55.580 --> 00:15:59.260]   but this is not what free speech is about today."
[00:15:59.260 --> 00:16:01.980]   He then goes on to argue, "The internet is not a frontier
[00:16:01.980 --> 00:16:03.340]   where people can go to be free.
[00:16:03.340 --> 00:16:04.700]   It's where the entire world is now,
[00:16:04.700 --> 00:16:06.580]   and every culture war is being fought on it.
[00:16:06.580 --> 00:16:09.420]   It's the main battlefield for our culture wars."
[00:16:09.420 --> 00:16:11.260]   And he says, "It means that upholding free speech
[00:16:11.260 --> 00:16:13.100]   means you're not standing up
[00:16:13.100 --> 00:16:14.860]   against some religious conservatives
[00:16:14.860 --> 00:16:16.900]   lobbying to remove Judy Blume books from the library.
[00:16:16.900 --> 00:16:18.540]   It means you're standing up against everyone
[00:16:18.540 --> 00:16:20.180]   because every side is trying to take away
[00:16:20.180 --> 00:16:22.740]   the speech rights of the other side."
[00:16:22.740 --> 00:16:24.340]   And so he goes on to say, for example,
[00:16:24.340 --> 00:16:28.740]   that all of his left-wing woke friends are convinced
[00:16:28.740 --> 00:16:30.500]   that the social media platforms uphold
[00:16:30.500 --> 00:16:32.700]   the white supremacist misogynistic patriarchy,
[00:16:32.700 --> 00:16:34.980]   and they have plenty of screenshots and evidence.
[00:16:34.980 --> 00:16:35.820]   And at the same time,
[00:16:35.820 --> 00:16:38.260]   all of his center-right libertarian friends
[00:16:38.260 --> 00:16:40.420]   are convinced that social media platforms
[00:16:40.420 --> 00:16:43.420]   uphold the woke BLM Marxist LGBTQ agenda,
[00:16:43.420 --> 00:16:45.860]   and they also have plenty of screenshots, blah, blah, blah.
[00:16:45.860 --> 00:16:50.060]   So his point is everyone has their own definition
[00:16:50.060 --> 00:16:51.380]   of free speech.
[00:16:51.380 --> 00:16:54.380]   Everyone wants to stop the other side,
[00:16:54.380 --> 00:16:56.620]   wherever the other team is, from whatever they're doing
[00:16:56.620 --> 00:16:58.660]   to impede their team and to get more freedom
[00:16:58.660 --> 00:17:00.900]   for their own team, that it's a battlefield
[00:17:00.900 --> 00:17:05.100]   where there is no clear sides.
[00:17:05.100 --> 00:17:08.060]   And he says, "Elon Musk doesn't realize this."
[00:17:08.060 --> 00:17:10.460]   He says, "Elon doesn't understand
[00:17:10.460 --> 00:17:12.980]   what has happened to internet culture since 2014.
[00:17:12.980 --> 00:17:16.980]   I know he doesn't because he was late to Bitcoin.
[00:17:16.980 --> 00:17:18.980]   Elon's been too busy doing actual real things
[00:17:18.980 --> 00:17:21.380]   like making electric cars and reusable rockets."
[00:17:21.380 --> 00:17:25.980]   Cutting out some inappropriate language here.
[00:17:25.980 --> 00:17:28.700]   So he has a pretty good excuse for not paying attention,
[00:17:28.700 --> 00:17:30.300]   but this is something that's hard to understand
[00:17:30.300 --> 00:17:32.660]   unless you've run a social network.
[00:17:32.660 --> 00:17:36.060]   All right, I'll call it there.
[00:17:36.060 --> 00:17:36.900]   That's my summary.
[00:17:36.900 --> 00:17:39.780]   Basically what this former Reddit CEO is saying
[00:17:39.780 --> 00:17:42.700]   is that Elon Musk is from an old generation
[00:17:42.700 --> 00:17:44.460]   where free speech was an ideal
[00:17:44.460 --> 00:17:46.100]   that all tech people supported.
[00:17:46.100 --> 00:17:46.980]   It was pretty clear.
[00:17:46.980 --> 00:17:48.540]   It was like the internet is for free speech
[00:17:48.540 --> 00:17:50.700]   and we have to stop Jerry Falwell
[00:17:50.700 --> 00:17:54.180]   from trying to prevent first-person shooters
[00:17:54.180 --> 00:17:57.180]   or Al Gore's wife from preventing first-person shooters
[00:17:57.180 --> 00:17:58.300]   or whatever was going on at the time.
[00:17:58.300 --> 00:18:00.420]   He's like, "Today that's no longer the case.
[00:18:00.420 --> 00:18:02.660]   Free speech means different things for everybody.
[00:18:02.660 --> 00:18:04.740]   There's no solution that's gonna make everyone happy.
[00:18:04.740 --> 00:18:06.980]   What this team wants is completely different
[00:18:06.980 --> 00:18:08.260]   from what this team wants.
[00:18:08.260 --> 00:18:10.420]   And you're gonna have to either pick sides.
[00:18:10.420 --> 00:18:11.740]   And if you don't pick sides,
[00:18:11.740 --> 00:18:12.580]   everyone's gonna hate you.
[00:18:12.580 --> 00:18:15.260]   You're gonna be in a world of pain from all sides."
[00:18:15.260 --> 00:18:19.820]   So this thread has gone somewhat viral.
[00:18:19.820 --> 00:18:22.340]   And I think it is an interesting take.
[00:18:22.340 --> 00:18:24.260]   All right, so here's what I think about that.
[00:18:24.260 --> 00:18:25.540]   Having thought a lot about this
[00:18:25.540 --> 00:18:27.740]   and written a lot about this,
[00:18:27.740 --> 00:18:29.620]   there's some things here I agree with.
[00:18:29.620 --> 00:18:34.180]   Yes, there certainly was an older internet culture.
[00:18:34.180 --> 00:18:35.580]   I think they're often described
[00:18:35.580 --> 00:18:39.300]   as the open culture techno-optimist
[00:18:39.300 --> 00:18:41.460]   that were a big believer in the internet
[00:18:41.460 --> 00:18:44.020]   as bringing openness to everyone.
[00:18:44.020 --> 00:18:46.220]   This is a movement that was really tied to things
[00:18:46.220 --> 00:18:49.780]   like information wants to be free, open source software.
[00:18:49.780 --> 00:18:52.300]   They were very anti-digital rights management.
[00:18:52.300 --> 00:18:55.540]   They thought software and music and text
[00:18:55.540 --> 00:18:57.100]   and everything should just be freely available
[00:18:57.100 --> 00:18:57.940]   on the internet.
[00:18:57.940 --> 00:18:59.540]   And it was a utopian movement.
[00:18:59.540 --> 00:19:02.260]   It came out of California techno-optimist circles.
[00:19:02.260 --> 00:19:03.940]   Kevin Kelly, who I know and respect
[00:19:03.940 --> 00:19:05.060]   was one of the big thinkers of that.
[00:19:05.060 --> 00:19:06.700]   So that movement did exist.
[00:19:06.700 --> 00:19:07.860]   Their version of the internet
[00:19:07.860 --> 00:19:09.820]   is very different than it is today.
[00:19:09.820 --> 00:19:11.940]   A lot of writers have talked about that transition.
[00:19:11.940 --> 00:19:14.460]   I think Jaron Lanier is probably the most eloquent.
[00:19:14.460 --> 00:19:16.340]   He was an open culture techno-optimist
[00:19:16.340 --> 00:19:17.940]   who became decidedly not that
[00:19:17.940 --> 00:19:21.180]   after the internet took a turn in the early 2000s.
[00:19:21.180 --> 00:19:23.660]   So I think that is definitely true.
[00:19:23.660 --> 00:19:26.060]   I think he's also right.
[00:19:26.060 --> 00:19:27.900]   I think we've seen this clearly
[00:19:27.900 --> 00:19:32.500]   that it's also right that there is no obvious solution
[00:19:32.500 --> 00:19:34.060]   that's gonna make most people happy
[00:19:34.060 --> 00:19:36.300]   when it comes to things like content moderation.
[00:19:36.300 --> 00:19:38.260]   The left wants this moderated,
[00:19:38.260 --> 00:19:40.380]   the right wants that moderated.
[00:19:40.380 --> 00:19:43.060]   And then there's other weird, crazy offshoots
[00:19:43.060 --> 00:19:44.340]   of the mainstream left and right
[00:19:44.340 --> 00:19:46.020]   that have all sorts of crazy thoughts
[00:19:46.020 --> 00:19:49.220]   about what should be moderated or not.
[00:19:49.220 --> 00:19:51.260]   And so there's no way to keep everyone happy.
[00:19:51.260 --> 00:19:52.900]   Facebook saw this.
[00:19:52.900 --> 00:19:55.300]   Facebook somehow got everyone,
[00:19:55.300 --> 00:19:56.780]   no matter where they were in the political spectrum,
[00:19:56.780 --> 00:19:58.100]   mad at them.
[00:19:58.100 --> 00:19:59.940]   The right wing got mad that they were being censored.
[00:19:59.940 --> 00:20:01.780]   The left wing got mad they weren't censoring enough.
[00:20:01.780 --> 00:20:04.740]   And so it is a very difficult place to be in.
[00:20:04.740 --> 00:20:06.820]   There is no politically neutral stance
[00:20:06.820 --> 00:20:08.140]   where people will see like you're doing it well.
[00:20:08.140 --> 00:20:10.620]   So I think he's right about that as well.
[00:20:10.620 --> 00:20:13.860]   What I think he's getting wrong though
[00:20:13.860 --> 00:20:16.380]   is this idea that Elon Musk or Marc Andreessen
[00:20:16.380 --> 00:20:18.380]   don't understand that.
[00:20:18.380 --> 00:20:20.940]   Gen X, I think, is too new of a generation.
[00:20:20.940 --> 00:20:24.860]   The sort of middle-aged tech oligarch class,
[00:20:24.860 --> 00:20:28.940]   the Peter Thiel's, Andreessen, Musk.
[00:20:28.940 --> 00:20:32.700]   You might have David Sachs,
[00:20:32.700 --> 00:20:36.820]   the sort of big, made a lot of money, Reid Hoffman.
[00:20:36.820 --> 00:20:39.140]   They were not really from that school
[00:20:39.140 --> 00:20:41.380]   of the original open culture techno optimist.
[00:20:41.380 --> 00:20:42.340]   They're a little bit older.
[00:20:42.340 --> 00:20:43.980]   That's a little bit of an older time.
[00:20:43.980 --> 00:20:45.980]   That's Kevin Kelly, that's Stuart Brand,
[00:20:45.980 --> 00:20:47.260]   that's Jaron Lanier.
[00:20:47.260 --> 00:20:48.940]   That's a slightly older group.
[00:20:48.940 --> 00:20:51.700]   This group came up in the dot-com boom of the '90s.
[00:20:51.700 --> 00:20:53.900]   They're much more money-focused
[00:20:53.900 --> 00:20:55.540]   than the original techno optimist are.
[00:20:55.540 --> 00:20:57.440]   And they know exactly what's going on.
[00:20:58.540 --> 00:21:01.460]   I do not think Elon Musk misunderstands
[00:21:01.460 --> 00:21:05.100]   what's actually happening on Twitter.
[00:21:05.100 --> 00:21:07.180]   I think what's going on when he talks
[00:21:07.180 --> 00:21:09.060]   about content moderation is much simpler.
[00:21:09.060 --> 00:21:11.780]   And I don't know why we don't just simplify this to this.
[00:21:11.780 --> 00:21:16.180]   I think when Elon Musk says, look at my notes here,
[00:21:16.180 --> 00:21:18.060]   but when Elon Musk says basically,
[00:21:18.060 --> 00:21:20.140]   he wants free speech,
[00:21:20.140 --> 00:21:22.100]   I think almost certainly what he means
[00:21:22.100 --> 00:21:25.060]   is he thinks that content moderation
[00:21:25.060 --> 00:21:28.740]   should come more from a centrist position
[00:21:28.740 --> 00:21:30.860]   than from a farther influence
[00:21:30.860 --> 00:21:32.660]   to the farther to the left position.
[00:21:32.660 --> 00:21:35.140]   I think that's all it is.
[00:21:35.140 --> 00:21:37.840]   And I think we see the split.
[00:21:37.840 --> 00:21:43.060]   We saw this split happening in Silicon Valley
[00:21:43.060 --> 00:21:47.260]   where this small group of these tech oligarchs,
[00:21:47.260 --> 00:21:48.820]   especially the ones with brand names,
[00:21:48.820 --> 00:21:51.720]   the people who made a lot of money, were very successful,
[00:21:52.700 --> 00:21:56.620]   had accrued a lot of power in the internet,
[00:21:56.620 --> 00:21:59.020]   out of the internet's growth.
[00:21:59.020 --> 00:22:03.580]   When there was the shift more recently in our culture
[00:22:03.580 --> 00:22:06.060]   towards using postmodern critical theories
[00:22:06.060 --> 00:22:07.300]   as the main perspective through which
[00:22:07.300 --> 00:22:10.140]   we understand the world, that group largely resisted it.
[00:22:10.140 --> 00:22:14.580]   And there might be a bit of a, don't tell me how to think.
[00:22:14.580 --> 00:22:16.540]   Look, I'm used to being the smartest person in the room
[00:22:16.540 --> 00:22:17.900]   and explaining how things work.
[00:22:17.900 --> 00:22:21.340]   And I don't want someone from a university coming along
[00:22:21.340 --> 00:22:22.180]   and telling me how to think.
[00:22:22.180 --> 00:22:23.260]   I don't know what it was.
[00:22:23.260 --> 00:22:26.020]   It could be the antagonism that grew
[00:22:26.020 --> 00:22:27.540]   between the media and these groups.
[00:22:27.540 --> 00:22:31.260]   So as more of the culture, and especially media culture,
[00:22:31.260 --> 00:22:33.280]   shifted to using postmodern critical theories
[00:22:33.280 --> 00:22:35.980]   as their main lens, their treatment
[00:22:35.980 --> 00:22:39.700]   of these tech bro oligarchs got pretty rough.
[00:22:39.700 --> 00:22:42.020]   And there's this whole tension that's not reported a lot,
[00:22:42.020 --> 00:22:44.100]   but basically there's been a complete break
[00:22:44.100 --> 00:22:47.380]   between these Silicon Valley brand name leaders
[00:22:47.380 --> 00:22:48.700]   and the East Coast media,
[00:22:48.700 --> 00:22:50.540]   where they just won't talk to them anymore.
[00:22:50.540 --> 00:22:51.780]   Like every time we talk to you,
[00:22:51.780 --> 00:22:53.180]   you just dunk on us in the piece.
[00:22:53.180 --> 00:22:55.180]   And look, we're just not even gonna do interviews with you.
[00:22:55.180 --> 00:22:57.540]   We'll just talk to people directly through our own podcast
[00:22:57.540 --> 00:22:59.180]   and we'll talk to people through our own websites.
[00:22:59.180 --> 00:23:01.940]   And there's this real tension between the two worlds.
[00:23:01.940 --> 00:23:03.540]   That probably didn't help either.
[00:23:03.540 --> 00:23:05.180]   But I think it's as simple as that.
[00:23:05.180 --> 00:23:08.060]   Elon Musk is from that group of brand name tech oligarchs
[00:23:08.060 --> 00:23:09.540]   that says, I don't know.
[00:23:09.540 --> 00:23:12.020]   I don't wanna re-center all my perspectives
[00:23:12.020 --> 00:23:13.980]   through postmodern critical theories.
[00:23:13.980 --> 00:23:16.060]   I think Twitter does that too much.
[00:23:16.060 --> 00:23:17.220]   I wanted to do it less.
[00:23:17.220 --> 00:23:21.340]   So I don't know why it has to be such a complex analysis
[00:23:21.340 --> 00:23:23.300]   of what's really going on with free speech.
[00:23:23.300 --> 00:23:26.620]   And maybe Musk is from this weird prior time
[00:23:26.620 --> 00:23:29.380]   and we have to understand these complex rules.
[00:23:29.380 --> 00:23:33.900]   I think he just has a different location
[00:23:33.900 --> 00:23:37.100]   on the political spectrum and has a lot of money.
[00:23:37.100 --> 00:23:40.660]   You can put those two things together.
[00:23:40.660 --> 00:23:41.500]   I don't know.
[00:23:41.500 --> 00:23:42.340]   I mean, Jesse, you probably hear this, right?
[00:23:42.340 --> 00:23:44.500]   Like there's a lot of bending over backwards
[00:23:44.500 --> 00:23:46.260]   and complex analysis for some of this stuff.
[00:23:46.260 --> 00:23:47.940]   But I think some of it's like pretty straightforward.
[00:23:47.940 --> 00:23:50.100]   Musk is like, I wanna be more centrist on this.
[00:23:50.100 --> 00:23:51.100]   And I have a lot of money
[00:23:51.100 --> 00:23:53.100]   and I'm kind of screwing with people.
[00:23:53.100 --> 00:23:54.380]   - Yeah.
[00:23:54.380 --> 00:23:56.300]   I do think he has a plan.
[00:23:56.300 --> 00:23:57.120]   - Yeah.
[00:23:57.120 --> 00:23:57.960]   - I'm not exactly sure what it is,
[00:23:57.960 --> 00:24:00.940]   but I do think he knows what's going on.
[00:24:00.940 --> 00:24:02.100]   'Cause he uses Twitter a lot anyway.
[00:24:02.100 --> 00:24:03.700]   He's been using it for years, right?
[00:24:03.700 --> 00:24:04.540]   - Yeah.
[00:24:04.540 --> 00:24:05.620]   He's got 80 something million followers.
[00:24:05.620 --> 00:24:06.460]   - Yeah.
[00:24:06.460 --> 00:24:07.280]   - Yeah.
[00:24:07.280 --> 00:24:09.860]   - So anything he uses that much,
[00:24:09.860 --> 00:24:11.540]   he's obviously thinking a lot about it.
[00:24:11.540 --> 00:24:13.820]   - I mean, this comes back to my bigger point,
[00:24:13.820 --> 00:24:15.420]   which I make often about social media,
[00:24:15.420 --> 00:24:17.220]   which is this is the impossibility
[00:24:17.220 --> 00:24:18.760]   of trying to have universalism.
[00:24:18.760 --> 00:24:21.780]   I just think this model of social media universalism
[00:24:21.780 --> 00:24:24.340]   where everyone uses the same small number of platforms
[00:24:24.340 --> 00:24:26.340]   doesn't make sense.
[00:24:26.340 --> 00:24:28.620]   That's not what the internet was architected for.
[00:24:28.620 --> 00:24:30.000]   Like the whole point of the internet
[00:24:30.000 --> 00:24:33.100]   is now you have potential point to point connections
[00:24:33.100 --> 00:24:35.580]   between everyone in the world.
[00:24:35.580 --> 00:24:37.300]   Meaning that you can put together
[00:24:37.300 --> 00:24:40.580]   any type of communication graph topologies that you want.
[00:24:40.580 --> 00:24:42.260]   Small groups of people,
[00:24:42.260 --> 00:24:44.260]   interesting connections that you surf
[00:24:44.260 --> 00:24:46.100]   to find people you've never known before.
[00:24:46.100 --> 00:24:48.100]   But to go to this broadcast topology,
[00:24:48.100 --> 00:24:49.420]   you say, no, no, no.
[00:24:49.420 --> 00:24:51.700]   Everyone's gonna talk to the same server banks
[00:24:51.700 --> 00:24:52.740]   at the same companies.
[00:24:52.740 --> 00:24:54.460]   And everyone's gonna read the same information
[00:24:54.460 --> 00:24:56.540]   being posted on the same three websites.
[00:24:56.540 --> 00:24:58.060]   Completely gets in the way
[00:24:58.060 --> 00:24:59.580]   and obviates all the advantage of the internet
[00:24:59.580 --> 00:25:00.420]   in the first place.
[00:25:00.420 --> 00:25:01.240]   And it's completely impossible.
[00:25:01.240 --> 00:25:02.900]   And this is really what we're seeing here
[00:25:02.900 --> 00:25:04.040]   in that Twitter thread.
[00:25:04.040 --> 00:25:06.180]   You're never going to make a platform work
[00:25:06.180 --> 00:25:08.740]   where you want it to be the platform everyone uses.
[00:25:08.740 --> 00:25:11.940]   What an impossible task.
[00:25:11.940 --> 00:25:14.480]   You want everyone in the country to use the same platform
[00:25:14.480 --> 00:25:15.700]   with the same interface
[00:25:15.700 --> 00:25:17.420]   and the same content moderation rules.
[00:25:17.420 --> 00:25:19.380]   Of course, that's going to explode.
[00:25:19.380 --> 00:25:20.980]   And it should.
[00:25:20.980 --> 00:25:23.820]   And it's why I'm obviously much more in favor
[00:25:23.820 --> 00:25:25.340]   of social media being,
[00:25:25.340 --> 00:25:26.780]   and by social media I mean,
[00:25:26.780 --> 00:25:29.700]   social interaction on the internet being much more niche,
[00:25:29.700 --> 00:25:31.400]   much more smaller scale.
[00:25:31.400 --> 00:25:35.180]   Do what you wanna do in your particular community.
[00:25:35.180 --> 00:25:38.940]   Let community standards emerge in a grassroots fashion
[00:25:38.940 --> 00:25:40.340]   from the small number of users
[00:25:40.340 --> 00:25:42.540]   that are using each of these particular networks
[00:25:42.540 --> 00:25:44.020]   or groups or however you want to work.
[00:25:44.020 --> 00:25:45.980]   That is where the internet really works.
[00:25:47.060 --> 00:25:49.260]   That people who are into X have a place to go
[00:25:49.260 --> 00:25:50.740]   and hang out with people that are into X.
[00:25:50.740 --> 00:25:52.480]   And the standards for how they talk about things
[00:25:52.480 --> 00:25:54.260]   might be really different than people who are into Y.
[00:25:54.260 --> 00:25:55.660]   And the people who are into Y don't have to know
[00:25:55.660 --> 00:25:57.500]   what the people that are into X are talking about.
[00:25:57.500 --> 00:26:00.920]   And we don't have to have some sort of common set of rules
[00:26:00.920 --> 00:26:04.300]   that the people from X and Y both have to follow.
[00:26:04.300 --> 00:26:06.460]   And so I think the folly here,
[00:26:06.460 --> 00:26:08.940]   the Shakespearean tragedy underlying all this
[00:26:08.940 --> 00:26:13.100]   is this push towards, we need a digital town square.
[00:26:13.100 --> 00:26:15.580]   We need one service that everyone uses.
[00:26:15.580 --> 00:26:20.580]   So look, I don't think Musk doesn't know what's going on.
[00:26:20.580 --> 00:26:23.340]   I don't think he's Kevin Kelly recarnated
[00:26:23.340 --> 00:26:24.820]   and is being too techno optimistic.
[00:26:24.820 --> 00:26:26.060]   He knows what he's doing.
[00:26:26.060 --> 00:26:28.820]   I don't think it's gonna be super successful
[00:26:28.820 --> 00:26:30.220]   because I think this whole project
[00:26:30.220 --> 00:26:32.740]   of having giant platforms everyone uses makes no sense
[00:26:32.740 --> 00:26:34.620]   and is destroying the internet.
[00:26:34.620 --> 00:26:36.900]   But I don't think it's complicated what he's doing.
[00:26:36.900 --> 00:26:38.340]   He likes Twitter.
[00:26:38.340 --> 00:26:39.740]   He doesn't like some of the politics
[00:26:39.740 --> 00:26:41.260]   behind how it's being implemented.
[00:26:41.260 --> 00:26:42.660]   He has money.
[00:26:42.660 --> 00:26:45.220]   So he's like, I'm gonna try to change it.
[00:26:45.220 --> 00:26:47.980]   All right, let's do one more quick article.
[00:26:47.980 --> 00:26:50.420]   So today my theme is social media,
[00:26:50.420 --> 00:26:52.420]   future social media, social media regulation.
[00:26:52.420 --> 00:26:53.900]   It doesn't mean I'm always gonna talk about this,
[00:26:53.900 --> 00:26:56.100]   but just seems to be in the air these days.
[00:26:56.100 --> 00:27:00.060]   So this final one also comes from the Times
[00:27:00.060 --> 00:27:01.900]   from a couple of days ago.
[00:27:01.900 --> 00:27:03.740]   The title of the article is Obama calls
[00:27:03.740 --> 00:27:08.060]   for more regulatory oversight of social media giants.
[00:27:08.060 --> 00:27:12.220]   This is from a talk that Obama gave last week
[00:27:12.220 --> 00:27:14.100]   at the Stanford Cyber Policy Center.
[00:27:14.100 --> 00:27:15.220]   Okay, so the article says,
[00:27:15.220 --> 00:27:17.860]   former President Barack Obama on Thursday
[00:27:17.860 --> 00:27:19.900]   called for greater regulatory oversight
[00:27:19.900 --> 00:27:21.460]   of the country's social media giants,
[00:27:21.460 --> 00:27:23.060]   saying their power to curate the information
[00:27:23.060 --> 00:27:27.460]   that people consume has turbocharged political polarization
[00:27:27.460 --> 00:27:29.780]   and threatened the pillars of democracy.
[00:27:29.780 --> 00:27:31.500]   Waning on the debate over how to address
[00:27:31.500 --> 00:27:33.060]   the spread of disinformation,
[00:27:33.060 --> 00:27:35.420]   he said the companies needed to subject
[00:27:35.420 --> 00:27:36.580]   their proprietary algorithms
[00:27:36.580 --> 00:27:38.340]   to the same kind of regulatory oversight
[00:27:38.340 --> 00:27:40.460]   to ensure the safety of cars, food,
[00:27:40.460 --> 00:27:41.820]   and other consumer products.
[00:27:41.820 --> 00:27:43.420]   Tech companies need to be more transparent
[00:27:43.420 --> 00:27:46.580]   about how they operate, Mr. Obama said.
[00:27:46.580 --> 00:27:50.140]   Well, I mean, there's a lot of things
[00:27:50.140 --> 00:27:51.580]   I agree with the former president on.
[00:27:51.580 --> 00:27:54.420]   I think this take, however, is a little bit out of touch
[00:27:54.420 --> 00:27:56.340]   with the underlying technology.
[00:27:56.340 --> 00:28:00.900]   Social media, quote unquote, algorithms
[00:28:00.900 --> 00:28:05.900]   are not like food safety or car safety,
[00:28:05.900 --> 00:28:10.060]   where, okay, we have data from crash tests
[00:28:10.060 --> 00:28:12.820]   that need to be shared or whatever needs to happen here.
[00:28:12.820 --> 00:28:15.540]   They're very complicated, but they're not just complicated.
[00:28:15.540 --> 00:28:20.540]   They are fundamentally doing something that's ineffable.
[00:28:20.540 --> 00:28:23.900]   So what's actually happening underneath the coverage
[00:28:23.900 --> 00:28:25.020]   of these social media companies,
[00:28:25.020 --> 00:28:28.380]   how, let's say, items are selected to add to the stream
[00:28:28.380 --> 00:28:30.300]   in the timeline that you consume,
[00:28:30.300 --> 00:28:31.900]   in the feed that you can consume.
[00:28:31.900 --> 00:28:34.820]   This is a collection, a complex collection
[00:28:34.820 --> 00:28:37.060]   of complex neural networks
[00:28:37.060 --> 00:28:39.420]   that have been trained in complex ways,
[00:28:39.420 --> 00:28:41.100]   usually with reinforcement mechanisms,
[00:28:41.100 --> 00:28:42.260]   and then they're connected together
[00:28:42.260 --> 00:28:44.620]   in some sort of dynamical way.
[00:28:44.620 --> 00:28:47.420]   You can't look at a complex connections
[00:28:47.420 --> 00:28:49.820]   of neural networks and say, what does this do?
[00:28:49.820 --> 00:28:53.420]   It doesn't work that way.
[00:28:53.420 --> 00:28:56.580]   These networks have learned on their own
[00:28:56.580 --> 00:28:59.300]   through hundreds of millions of trials of training
[00:28:59.300 --> 00:29:01.580]   and back propagation reinforcement.
[00:29:01.580 --> 00:29:05.580]   They have learned patterns, instructions, the information,
[00:29:05.580 --> 00:29:07.620]   what information is more likely to get engagement
[00:29:07.620 --> 00:29:09.420]   from this person versus that person
[00:29:09.420 --> 00:29:11.460]   that cannot be easily reduced
[00:29:11.460 --> 00:29:14.060]   to a human understandable format.
[00:29:14.060 --> 00:29:16.780]   A lot of what's happening here is that the information,
[00:29:16.780 --> 00:29:19.020]   let's say a particular post on Twitter,
[00:29:19.020 --> 00:29:21.700]   is going to exist as a multidimensional vector
[00:29:21.700 --> 00:29:23.740]   of data points, and that these,
[00:29:23.740 --> 00:29:25.220]   any one of these neural networks
[00:29:25.220 --> 00:29:26.500]   in the quote unquote algorithm
[00:29:26.500 --> 00:29:29.100]   is actually creating a multidimensional hyperplane
[00:29:29.100 --> 00:29:30.820]   through which they can actually categorize
[00:29:30.820 --> 00:29:33.140]   a multidimensional location for this point.
[00:29:33.140 --> 00:29:34.820]   And then the user themselves,
[00:29:34.820 --> 00:29:36.060]   they're gonna show this to exist
[00:29:36.060 --> 00:29:37.860]   as their own multidimensional point,
[00:29:37.860 --> 00:29:39.620]   and they can see if they've been segmented
[00:29:39.620 --> 00:29:41.420]   into the same place by this hyperplane,
[00:29:41.420 --> 00:29:43.420]   meaning they're more likely to have an affinity.
[00:29:43.420 --> 00:29:44.740]   All of which I'm trying to say here
[00:29:44.740 --> 00:29:49.140]   is that this is complicated, abstract, multidimensional work
[00:29:49.140 --> 00:29:50.700]   that is happening with these systems.
[00:29:50.700 --> 00:29:54.020]   It is not an algorithm like we would think about it.
[00:29:54.020 --> 00:29:57.940]   It is not a bunch of turbo basic code that says,
[00:29:57.940 --> 00:30:02.940]   you know, if about cats and reader is over 60,
[00:30:05.300 --> 00:30:08.460]   show them this post.
[00:30:08.460 --> 00:30:09.420]   It's not that.
[00:30:09.420 --> 00:30:13.700]   It is vectors of numbers going through
[00:30:13.700 --> 00:30:16.660]   complex linear algebra convolutions
[00:30:16.660 --> 00:30:18.540]   and scores coming out of the other side.
[00:30:18.540 --> 00:30:23.420]   And what happens in between is not understandable by people.
[00:30:23.420 --> 00:30:25.460]   But I think this is an old fashioned view that like,
[00:30:25.460 --> 00:30:27.660]   oh, I think what's happening here is that like someone
[00:30:27.660 --> 00:30:31.140]   who was mustache twisting, you know, mustache twisting,
[00:30:31.140 --> 00:30:34.660]   and was like, hmm, we will get to more views.
[00:30:34.660 --> 00:30:35.980]   I'm looking at this here.
[00:30:35.980 --> 00:30:38.780]   These people like hearing why vaccines are bad.
[00:30:38.780 --> 00:30:40.700]   So let me just type into here,
[00:30:40.700 --> 00:30:44.580]   show articles about vaccines being bad,
[00:30:44.580 --> 00:30:46.140]   because then we will get more money.
[00:30:46.140 --> 00:30:47.700]   And oh, the regulators here.
[00:30:47.700 --> 00:30:49.220]   And he says, don't put that in your algorithm.
[00:30:49.220 --> 00:30:50.980]   So, okay, I'm gonna take that out of my algorithm here.
[00:30:50.980 --> 00:30:51.940]   That's not how it works.
[00:30:51.940 --> 00:30:54.620]   It's these, again, it's incredibly complex and abstract
[00:30:54.620 --> 00:30:57.780]   and you can't break it down into what's really happening.
[00:30:57.780 --> 00:30:59.780]   Now, furthermore, even if you could,
[00:30:59.780 --> 00:31:01.620]   it would be disastrous for these companies
[00:31:01.620 --> 00:31:05.980]   if you could somehow make this algorithm interrogatable.
[00:31:05.980 --> 00:31:07.500]   Right, so maybe you wanna apply
[00:31:07.500 --> 00:31:09.340]   an explainable AI approach here and say,
[00:31:09.340 --> 00:31:11.620]   well, let's just interrogate the algorithms.
[00:31:11.620 --> 00:31:13.460]   See what it says is, you know,
[00:31:13.460 --> 00:31:15.780]   let's put in different things and see which it prefers.
[00:31:15.780 --> 00:31:17.020]   But if you did that,
[00:31:17.020 --> 00:31:20.380]   then everyone would start scamming the system.
[00:31:20.380 --> 00:31:24.860]   Everyone trying to get people to look at their dubious
[00:31:24.860 --> 00:31:26.580]   diet pill site or whatever,
[00:31:26.580 --> 00:31:28.940]   would figure out exactly what to put in their tech
[00:31:28.940 --> 00:31:30.740]   so that it would dominate everything else.
[00:31:30.740 --> 00:31:33.220]   It'd be like showing spammers
[00:31:33.220 --> 00:31:35.660]   the spam filter that Gmail use.
[00:31:35.660 --> 00:31:37.180]   Everything would then slip through the filter
[00:31:37.180 --> 00:31:38.100]   because they could just sit there
[00:31:38.100 --> 00:31:39.060]   and work with it to figure it out.
[00:31:39.060 --> 00:31:40.500]   So you can't really make it clear.
[00:31:40.500 --> 00:31:43.340]   Anyways, again, I respect the former president.
[00:31:43.340 --> 00:31:45.860]   I'm just saying this is out of date
[00:31:45.860 --> 00:31:47.220]   with what's going on with this technology.
[00:31:47.220 --> 00:31:48.060]   It's not so simple.
[00:31:48.060 --> 00:31:50.300]   It's not, you're going in there and turning knobs.
[00:31:50.300 --> 00:31:52.500]   This knob is turned towards bad information.
[00:31:52.500 --> 00:31:54.060]   Let's just turn that down.
[00:31:54.060 --> 00:31:55.780]   And this knob is turned towards good information.
[00:31:55.780 --> 00:31:56.940]   Let's turn it up.
[00:31:56.940 --> 00:32:00.500]   The reality, I think, is much more complicated,
[00:32:00.500 --> 00:32:02.860]   but there's a bigger point here I wanna make,
[00:32:02.860 --> 00:32:04.540]   which is, again, in a lot of discourse,
[00:32:04.540 --> 00:32:06.020]   especially, again, discourse coming out
[00:32:06.020 --> 00:32:08.900]   of more elite circles about social media,
[00:32:08.900 --> 00:32:11.620]   there's this real focus on the problem is
[00:32:11.620 --> 00:32:15.500]   the wrong information is being amplified.
[00:32:15.500 --> 00:32:16.620]   That this is the problem.
[00:32:16.620 --> 00:32:18.660]   It's all about content amplification.
[00:32:18.660 --> 00:32:20.660]   This is bad information.
[00:32:20.660 --> 00:32:23.380]   This platform is sending out this bad information
[00:32:23.380 --> 00:32:25.260]   to a lot of people.
[00:32:25.260 --> 00:32:27.420]   And from the elite perspective, most people are dumb.
[00:32:27.420 --> 00:32:28.260]   So then they get tricked
[00:32:28.260 --> 00:32:29.500]   and then they believe this bad information.
[00:32:29.500 --> 00:32:32.420]   So let's just stop it from spreading out the bad information.
[00:32:32.420 --> 00:32:36.660]   I am more in line right now with John Haidt's latest take
[00:32:36.660 --> 00:32:38.940]   that we talked about last week on the show.
[00:32:38.940 --> 00:32:40.420]   His take from his Big Atlantic article,
[00:32:40.420 --> 00:32:43.900]   which I increasingly think is right.
[00:32:43.900 --> 00:32:46.140]   And I think it gives us a more nuanced understanding
[00:32:46.140 --> 00:32:48.620]   of the issues with social media than simply saying
[00:32:48.620 --> 00:32:51.540]   it pushes the bad information more
[00:32:51.540 --> 00:32:53.140]   than the quote unquote good information.
[00:32:53.140 --> 00:32:54.660]   'Cause if you'll remember from our discussion
[00:32:54.660 --> 00:32:58.140]   of John Haidt's Atlantic article,
[00:32:58.140 --> 00:32:59.540]   what he was arguing is the problem
[00:32:59.540 --> 00:33:00.900]   is not what it does to information,
[00:33:00.900 --> 00:33:03.060]   it's what social media does to the people.
[00:33:03.060 --> 00:33:03.940]   What it does to the people
[00:33:03.940 --> 00:33:05.380]   who are interacting on social media.
[00:33:05.380 --> 00:33:07.340]   And his whole point was,
[00:33:07.340 --> 00:33:11.940]   once these platforms shifted towards viral dynamics,
[00:33:11.940 --> 00:33:14.100]   where something could get a huge amount
[00:33:14.100 --> 00:33:15.900]   of attention right away,
[00:33:15.900 --> 00:33:17.540]   things could blow up really quickly.
[00:33:17.540 --> 00:33:19.100]   He said, this really changed the way
[00:33:19.100 --> 00:33:22.940]   that people use social media.
[00:33:22.940 --> 00:33:24.980]   Three things happened.
[00:33:25.140 --> 00:33:30.140]   One, there became immediate,
[00:33:30.140 --> 00:33:32.540]   there could be immediate consequences.
[00:33:32.540 --> 00:33:34.620]   If you sort of say the wrong thing,
[00:33:34.620 --> 00:33:38.260]   your team could swarm in a way that was breathtaking.
[00:33:38.260 --> 00:33:40.820]   And it became, he called it a vigilante culture,
[00:33:40.820 --> 00:33:43.180]   where out of nowhere, you could have people
[00:33:43.180 --> 00:33:46.780]   just piled on and destroyed.
[00:33:46.780 --> 00:33:48.300]   Two, it created a culture then
[00:33:48.300 --> 00:33:52.340]   where you became very wary of letting the other team,
[00:33:52.340 --> 00:33:53.740]   depending on how you define the other team,
[00:33:53.740 --> 00:33:55.260]   gain any ground.
[00:33:55.260 --> 00:33:57.660]   Can't let the other team gain any ground.
[00:33:57.660 --> 00:34:00.700]   So we gotta like quickly tamp down or attack.
[00:34:00.700 --> 00:34:02.300]   Don't give, we give in on anything,
[00:34:02.300 --> 00:34:03.300]   that might get amplified.
[00:34:03.300 --> 00:34:05.300]   So it created this really tense,
[00:34:05.300 --> 00:34:07.140]   anxious type of environment.
[00:34:07.140 --> 00:34:10.420]   And three, that drove out almost everyone but the extremes.
[00:34:10.420 --> 00:34:11.540]   So as Haidt documents,
[00:34:11.540 --> 00:34:13.060]   you're left with the extremes on the left
[00:34:13.060 --> 00:34:14.740]   and the extremes on the right,
[00:34:14.740 --> 00:34:16.580]   basically fighting back and forth,
[00:34:16.580 --> 00:34:18.620]   desperate to avoid being attacked by their own team,
[00:34:18.620 --> 00:34:20.940]   desperate not to give any ground to the other team.
[00:34:20.940 --> 00:34:24.500]   It became a spectacle of the elite extremist.
[00:34:24.500 --> 00:34:26.660]   That is what is happening on a platform
[00:34:26.660 --> 00:34:27.500]   like Twitter right now.
[00:34:27.500 --> 00:34:30.460]   And it's great entertainment for those groups
[00:34:30.460 --> 00:34:32.140]   and a larger group of adjacent people
[00:34:32.140 --> 00:34:33.740]   that quietly like to watch it,
[00:34:33.740 --> 00:34:36.500]   but it's a terrible environment.
[00:34:36.500 --> 00:34:38.780]   So the incentives there,
[00:34:38.780 --> 00:34:41.740]   our incentives were really wonky information,
[00:34:41.740 --> 00:34:43.780]   really weird, bad information,
[00:34:43.780 --> 00:34:45.100]   can really spread and take hold
[00:34:45.100 --> 00:34:46.660]   because the point there is not,
[00:34:46.660 --> 00:34:48.460]   hey, let's try to spread interesting information,
[00:34:48.460 --> 00:34:49.300]   is we're gonna win,
[00:34:49.300 --> 00:34:52.300]   and I don't wanna get hung by my own team.
[00:34:52.300 --> 00:34:54.180]   So we'll grasp onto something crazy
[00:34:54.180 --> 00:34:56.020]   if that gives us a little advantage.
[00:34:56.020 --> 00:34:58.020]   And we will ignore refuting evidence
[00:34:58.020 --> 00:35:00.700]   about something with a diligence,
[00:35:00.700 --> 00:35:02.020]   with diligent blinders,
[00:35:02.020 --> 00:35:04.460]   if that might lead to an attack,
[00:35:04.460 --> 00:35:05.300]   if I acknowledge it,
[00:35:05.300 --> 00:35:06.940]   or if I might give the other team room.
[00:35:06.940 --> 00:35:09.020]   So Haidt's argument is the problem is not,
[00:35:09.020 --> 00:35:10.940]   what is the social media algorithms,
[00:35:10.940 --> 00:35:11.860]   how do they amplify
[00:35:11.860 --> 00:35:13.380]   or choose what information to amplify?
[00:35:13.380 --> 00:35:15.180]   It's what do they do to the people?
[00:35:15.180 --> 00:35:16.620]   And the viral dynamics turn people
[00:35:16.620 --> 00:35:20.780]   into these weird, obsessive, extreme tribal warriors.
[00:35:20.780 --> 00:35:22.100]   And that is an environment
[00:35:22.100 --> 00:35:25.420]   where really wonky or bad information can spread,
[00:35:25.420 --> 00:35:26.260]   can take hold,
[00:35:26.260 --> 00:35:29.940]   can be really difficult to dislodge.
[00:35:29.940 --> 00:35:35.620]   I mean, I think if there was somehow a way
[00:35:35.620 --> 00:35:39.940]   to really dunk on Trump by believing in flat-earthism,
[00:35:39.940 --> 00:35:41.860]   you would see a lot of flat-earthism.
[00:35:41.860 --> 00:35:43.560]   Other way around,
[00:35:43.560 --> 00:35:45.460]   if there's some way to really,
[00:35:45.460 --> 00:35:47.900]   really get at Biden,
[00:35:47.900 --> 00:35:49.900]   if by believing in lizard people,
[00:35:49.900 --> 00:35:52.620]   lizard people stories are gonna spread really strong
[00:35:52.620 --> 00:35:54.180]   and people are really gonna grasp them.
[00:35:54.180 --> 00:35:57.100]   It's not the information that matters here.
[00:35:57.100 --> 00:35:58.500]   It's the human dynamics.
[00:35:58.500 --> 00:36:01.380]   Social media warps the people
[00:36:01.380 --> 00:36:05.180]   to a mode in which all sorts of crazy stuff
[00:36:05.180 --> 00:36:06.640]   is gonna spread.
[00:36:06.640 --> 00:36:08.380]   So again, so I think the solution is,
[00:36:08.380 --> 00:36:11.540]   we gotta get away from platform universalism.
[00:36:11.540 --> 00:36:13.000]   We gotta get away from this idea
[00:36:13.000 --> 00:36:14.880]   that everyone needs to be on the same platform,
[00:36:14.880 --> 00:36:16.380]   that we need these quote unquote,
[00:36:16.380 --> 00:36:18.360]   what we call digital town halls,
[00:36:18.360 --> 00:36:19.880]   which aren't digital town halls at all.
[00:36:19.880 --> 00:36:21.700]   It's the digital Roman Colosseum.
[00:36:21.700 --> 00:36:25.020]   It's a spectacle for elite extremists doing combat
[00:36:25.020 --> 00:36:27.540]   and the small group of people who like to watch the blood,
[00:36:27.540 --> 00:36:29.540]   but it's a spectacle that has a trickle-down impact
[00:36:29.540 --> 00:36:30.420]   on everyone.
[00:36:30.420 --> 00:36:32.080]   Most people don't use Twitter.
[00:36:32.080 --> 00:36:34.180]   Most people, the vast majority of people
[00:36:34.180 --> 00:36:35.300]   never post anything on Twitter,
[00:36:35.300 --> 00:36:38.300]   but there's huge impacts about what happens in their life
[00:36:38.300 --> 00:36:40.620]   because of what's going on in that elite Colosseum.
[00:36:40.620 --> 00:36:42.420]   And I think Haidt is absolutely right about that.
[00:36:42.420 --> 00:36:43.560]   And the problem is not just,
[00:36:43.560 --> 00:36:45.900]   again, we have to go in there and turn some content knobs.
[00:36:45.900 --> 00:36:47.740]   Don't promote this content, promote that content.
[00:36:47.740 --> 00:36:48.940]   We're way past that.
[00:36:48.940 --> 00:36:52.100]   We gotta stop the impact it has on people.
[00:36:52.100 --> 00:36:53.640]   And I think the way we do that is,
[00:36:53.640 --> 00:36:56.520]   we de-emphasize the importance of these platforms.
[00:36:56.520 --> 00:36:58.300]   Once we recognize it's an elite spectacle,
[00:36:58.300 --> 00:37:01.120]   maybe we'll spend less time paying attention to it.
[00:37:01.120 --> 00:37:02.320]   We'll reduce its impact.
[00:37:02.320 --> 00:37:05.220]   So Obama goes on to say,
[00:37:05.220 --> 00:37:09.100]   one of his proposals was to look at section 230
[00:37:09.100 --> 00:37:10.640]   of the Communications Decency Act,
[00:37:10.640 --> 00:37:12.140]   which protects social media platforms
[00:37:12.140 --> 00:37:14.500]   from liability for content that the users post.
[00:37:14.500 --> 00:37:19.460]   So he is supporting proposals to get rid of that.
[00:37:19.460 --> 00:37:22.160]   That makes companies more liable for what's posted.
[00:37:22.160 --> 00:37:23.620]   And again, I think that's interesting.
[00:37:23.620 --> 00:37:24.820]   230 is complicated.
[00:37:24.820 --> 00:37:27.920]   Like technically 230 is what would give me protection.
[00:37:27.920 --> 00:37:32.920]   If commenters on my blog said something damaging or illegal,
[00:37:32.920 --> 00:37:35.300]   230 would say, well, it's,
[00:37:35.300 --> 00:37:36.580]   I'm not gonna be held responsible
[00:37:36.580 --> 00:37:38.820]   for what other people posted on my platform.
[00:37:38.820 --> 00:37:41.460]   The social media companies are really leaning the 230.
[00:37:41.460 --> 00:37:44.540]   I'm not opposed to the idea of getting rid of 230
[00:37:44.540 --> 00:37:46.100]   to some degree, because I think, again,
[00:37:46.100 --> 00:37:49.420]   anything that might lead to fracturing social media
[00:37:49.420 --> 00:37:52.820]   is probably gonna be better for everyone involved.
[00:37:52.820 --> 00:37:56.540]   I mean, I like a world if like, okay, we drop 230
[00:37:56.540 --> 00:37:58.260]   and maybe I have to turn comment threads off
[00:37:58.260 --> 00:38:00.560]   because like, I don't be liable, sure.
[00:38:00.560 --> 00:38:03.060]   But it means that it's no longer legally viable
[00:38:03.060 --> 00:38:05.100]   to be a massive universal platform.
[00:38:05.100 --> 00:38:07.180]   What you get instead is more of a Reddit type culture
[00:38:07.180 --> 00:38:09.600]   of smaller communities where things are,
[00:38:09.600 --> 00:38:11.980]   there's community moderation and people are responsible
[00:38:11.980 --> 00:38:13.100]   for what's posted on there.
[00:38:13.100 --> 00:38:16.340]   And there's care to how the community interacts
[00:38:16.340 --> 00:38:18.100]   and the people who are really into this
[00:38:18.100 --> 00:38:20.260]   are not talking to the people who are really into that.
[00:38:20.260 --> 00:38:21.580]   That's probably a better world.
[00:38:21.580 --> 00:38:24.180]   So probably from a legal principle,
[00:38:24.180 --> 00:38:26.060]   there's problems with just saying drop 230,
[00:38:26.060 --> 00:38:29.500]   but I like anything that might fracture social media
[00:38:29.500 --> 00:38:32.820]   away from this form it is now,
[00:38:32.820 --> 00:38:35.180]   where we have the spectacle of the elites.
[00:38:35.180 --> 00:38:36.980]   And though most of us don't wanna pay attention to it,
[00:38:36.980 --> 00:38:41.340]   it ends up really affecting, really affecting our life.
[00:38:41.340 --> 00:38:44.920]   So I don't know.
[00:38:44.920 --> 00:38:48.680]   You probably know Twitter better than I do, Jesse.
[00:38:48.680 --> 00:38:49.520]   - I don't think so.
[00:38:49.520 --> 00:38:50.340]   I never know Twitter. - You don't know either?
[00:38:50.340 --> 00:38:51.280]   Yeah, see, that's the thing.
[00:38:51.280 --> 00:38:52.200]   Most people don't.
[00:38:52.200 --> 00:38:54.520]   And yet it has a big impact in all of our life.
[00:38:54.520 --> 00:38:55.640]   Like it could have a big impact
[00:38:55.640 --> 00:38:59.880]   on how our employers operate, the news we receive,
[00:38:59.880 --> 00:39:03.100]   the legislation taken up or not taken up,
[00:39:03.100 --> 00:39:05.200]   what politicians pay attention to.
[00:39:05.200 --> 00:39:07.440]   It's like the Roman Colosseum,
[00:39:07.440 --> 00:39:11.600]   the only people going there are like the elite landowners
[00:39:11.600 --> 00:39:12.520]   because they really like it.
[00:39:12.520 --> 00:39:13.720]   But what's happening in the Colosseum
[00:39:13.720 --> 00:39:15.080]   is completely affecting what happens
[00:39:15.080 --> 00:39:16.640]   to the rest of the Roman citizens
[00:39:16.640 --> 00:39:18.440]   who are just like out there trying to run their farms.
[00:39:18.440 --> 00:39:19.640]   - It's a great analogy.
[00:39:19.640 --> 00:39:23.560]   - Yeah, and I think Haidt actually mentioned
[00:39:23.560 --> 00:39:25.440]   the Roman Colosseum in his Atlantic article.
[00:39:25.440 --> 00:39:29.240]   So I'm sort of taking and running with his perspective,
[00:39:29.240 --> 00:39:31.240]   but it's elite capture.
[00:39:31.240 --> 00:39:33.680]   And I think that's all this stuff is,
[00:39:33.680 --> 00:39:36.240]   that's what keeps capturing me about all of this.
[00:39:36.240 --> 00:39:41.240]   It's, you know, we're in 1750 France
[00:39:41.240 --> 00:39:43.800]   and there's like huge arguments going on
[00:39:43.800 --> 00:39:47.080]   about the Hall of Mirrors at Versailles.
[00:39:47.080 --> 00:39:48.680]   It's like, it's not what most people in France
[00:39:48.680 --> 00:39:50.680]   cared about right then.
[00:39:50.680 --> 00:39:51.920]   And so I think there's more of that going on
[00:39:51.920 --> 00:39:56.200]   with social media than other people are willing to let on.
[00:39:56.200 --> 00:39:57.680]   So there we go.
[00:39:57.680 --> 00:40:00.080]   That's what I think about that.
[00:40:01.960 --> 00:40:04.160]   Let's take a quick break here.
[00:40:04.160 --> 00:40:05.360]   Talk about a couple of sponsors
[00:40:05.360 --> 00:40:07.880]   that make my rants possible.
[00:40:07.880 --> 00:40:10.160]   And I see our sponsors here are,
[00:40:10.160 --> 00:40:12.840]   oh no, it's Twitter and Tesla.
[00:40:12.840 --> 00:40:14.200]   See, we did it again, Jesse.
[00:40:14.200 --> 00:40:17.880]   We didn't check, we didn't check who it was.
[00:40:17.880 --> 00:40:22.280]   And President Obama, oh no, one of our sponsors was,
[00:40:22.280 --> 00:40:24.680]   they were sponsoring President Obama's speech
[00:40:24.680 --> 00:40:26.720]   at the Young Innovators Club or whatever.
[00:40:26.720 --> 00:40:28.160]   We got to check these things.
[00:40:28.160 --> 00:40:31.520]   No, we actually, those are not our sponsors.
[00:40:31.520 --> 00:40:34.440]   We do have a great sponsor, however.
[00:40:34.440 --> 00:40:39.080]   Zocdoc, Z-O-C-D-O-C, which is a free app
[00:40:39.080 --> 00:40:41.600]   that shows you doctors who are patient reviews,
[00:40:41.600 --> 00:40:45.120]   take your insurance and are available when you need them.
[00:40:45.120 --> 00:40:47.920]   So Zocdoc is the way when you need a new doctor,
[00:40:47.920 --> 00:40:51.480]   I need a dentist, I need a new primary care physician,
[00:40:51.480 --> 00:40:54.280]   how do I figure out who to go and sign up for?
[00:40:54.280 --> 00:40:56.200]   This is actually a really hard problem.
[00:40:56.200 --> 00:40:57.840]   I mean, what I've done in the past
[00:40:57.840 --> 00:41:00.120]   is just randomly ask people I know.
[00:41:00.120 --> 00:41:01.520]   Zocdoc makes it easy.
[00:41:01.520 --> 00:41:03.480]   It says, okay, here's dentists, here's doctors,
[00:41:03.480 --> 00:41:05.320]   here's primary care physicians, here's dermatologists,
[00:41:05.320 --> 00:41:07.440]   whoever you're looking for, here they are in your area.
[00:41:07.440 --> 00:41:09.480]   I'll tell you which ones already take your insurance
[00:41:09.480 --> 00:41:11.640]   and are looking for new patients.
[00:41:11.640 --> 00:41:16.320]   Zocdoc also makes it easy to do that patient intake forms.
[00:41:16.320 --> 00:41:18.280]   You can do it right from the app.
[00:41:18.280 --> 00:41:20.200]   I use Zocdoc with my dentist.
[00:41:20.200 --> 00:41:22.640]   It's really great.
[00:41:22.640 --> 00:41:24.400]   I can schedule things real easily.
[00:41:24.400 --> 00:41:28.000]   I do my paperwork on my computer ahead of time.
[00:41:28.000 --> 00:41:29.400]   It has my information saved,
[00:41:29.400 --> 00:41:31.040]   so I don't have to sit there with the clipboard
[00:41:31.040 --> 00:41:32.560]   and feel things out.
[00:41:32.560 --> 00:41:35.600]   It's one of these ideas that once you hear it,
[00:41:35.600 --> 00:41:38.520]   you say, of course, finding doctors,
[00:41:38.520 --> 00:41:41.480]   the right doctors, my area, takes my insurance.
[00:41:41.480 --> 00:41:44.840]   Patient reviews, I also like that about it.
[00:41:44.840 --> 00:41:47.280]   What do other real patients say about it?
[00:41:47.280 --> 00:41:49.440]   It's an app that just makes a lot of sense.
[00:41:49.440 --> 00:41:55.440]   So go to Zocdoc.com, say that four times fast,
[00:41:55.440 --> 00:42:00.040]   Zocdoc.com/deep,
[00:42:00.040 --> 00:42:03.880]   and download the Zocdoc app for free.
[00:42:03.880 --> 00:42:07.320]   Then start your search for a top-rated doctor today,
[00:42:07.320 --> 00:42:10.460]   many of whom will be available in only 24 hours.
[00:42:10.460 --> 00:42:15.460]   That's Z-O-C-D-O-C.com/deep,
[00:42:15.460 --> 00:42:21.600]   Zocdoc.com/deep.
[00:42:22.440 --> 00:42:27.440]   We are also sponsored by Magic Mind.
[00:42:27.440 --> 00:42:29.920]   Jesse, I've told you about Magic Mind,
[00:42:29.920 --> 00:42:31.720]   'cause I did the experiment with it.
[00:42:31.720 --> 00:42:35.240]   A product I needed,
[00:42:35.240 --> 00:42:37.920]   a product I needed because I had been known to drink
[00:42:37.920 --> 00:42:42.360]   what scientists would call an absurd amount of coffee.
[00:42:42.360 --> 00:42:46.680]   Like I think absurd is the official unit of measure.
[00:42:46.680 --> 00:42:48.160]   And when you use Magic Mind,
[00:42:48.160 --> 00:42:52.240]   which is an elixir that makes you focus better,
[00:42:52.240 --> 00:42:54.520]   be more creative and rely less on caffeine,
[00:42:54.520 --> 00:42:58.520]   comes in a shot-like container, so it's not much.
[00:42:58.520 --> 00:43:00.060]   You drink it first thing in the morning
[00:43:00.060 --> 00:43:02.600]   before your first cup of coffee.
[00:43:02.600 --> 00:43:04.840]   You don't need as much coffee throughout the day
[00:43:04.840 --> 00:43:07.080]   to get that focus to fall into your flow state,
[00:43:07.080 --> 00:43:09.120]   especially if, and this is the key thing, you stick with it.
[00:43:09.120 --> 00:43:10.820]   You need to stick with it for at least five days
[00:43:10.820 --> 00:43:12.200]   to get the full effect.
[00:43:12.200 --> 00:43:13.800]   But once you've stuck with it for about five days,
[00:43:13.800 --> 00:43:16.320]   you are gonna find that you're able to focus better
[00:43:16.320 --> 00:43:17.820]   and fall in that flow faster
[00:43:17.820 --> 00:43:20.360]   without having to keep slamming the caffeine.
[00:43:21.240 --> 00:43:24.980]   So it was actually just what I needed.
[00:43:24.980 --> 00:43:29.040]   Drink less coffee, be more creative,
[00:43:29.040 --> 00:43:31.400]   fight off procrastination, fight off brain fog.
[00:43:31.400 --> 00:43:32.800]   It has all sorts of natural ingredients.
[00:43:32.800 --> 00:43:36.480]   It's all natural ingredients, adaptogens, nootropics,
[00:43:36.480 --> 00:43:40.440]   energy boosters, inflammation decreasers.
[00:43:40.440 --> 00:43:42.920]   I don't even know how to say all the scientific names,
[00:43:42.920 --> 00:43:45.320]   but it's all good stuff, all natural ingredients.
[00:43:45.320 --> 00:43:48.240]   It was created by James Bechera, who I spoke with,
[00:43:48.240 --> 00:43:51.680]   who is a Silicon Valley investor and entrepreneur,
[00:43:51.680 --> 00:43:53.600]   who was working on this stuff on his own.
[00:43:53.600 --> 00:43:56.400]   He was mixing his own brews to help him be more productive
[00:43:56.400 --> 00:43:57.400]   and focused in his kitchen.
[00:43:57.400 --> 00:44:02.240]   That's how he got the idea for Magic Mind.
[00:44:02.240 --> 00:44:06.480]   So if, like me, you want to avoid drinking all the coffee
[00:44:06.480 --> 00:44:10.120]   in the world in order to be creative, in order to be focused,
[00:44:10.120 --> 00:44:13.200]   try taking Magic Mind with your morning coffee.
[00:44:13.200 --> 00:44:15.880]   I think you will enjoy it.
[00:44:15.880 --> 00:44:18.400]   So I actually have a special offer for my listeners
[00:44:18.400 --> 00:44:19.600]   from the guys at Magic Mind.
[00:44:19.600 --> 00:44:24.600]   All you have to do is go to magicmind.co/deep.
[00:44:24.600 --> 00:44:29.960]   That's magicmind.co/deep,
[00:44:29.960 --> 00:44:34.960]   and then use the discount code DEEP20 at checkout.
[00:44:34.960 --> 00:44:38.680]   That will give you 20% off your first order.
[00:44:38.680 --> 00:44:40.480]   So that's magicmind.co/deep,
[00:44:40.480 --> 00:44:43.680]   and use that discount code DEEP20
[00:44:43.680 --> 00:44:46.840]   to get 20% off your first order.
[00:44:46.840 --> 00:44:51.360]   I should Magic Mind before each episode,
[00:44:51.360 --> 00:44:52.520]   not just in the morning.
[00:44:52.520 --> 00:44:54.360]   Just put it into my veins.
[00:44:54.360 --> 00:44:56.440]   I just have like a Magic Mind dispenser.
[00:44:56.440 --> 00:44:57.720]   It's like- - Good idea.
[00:44:57.720 --> 00:45:01.240]   - Time to go, especially before these long epic episodes.
[00:45:01.240 --> 00:45:04.240]   So when I have a particularly long and coherent rant,
[00:45:04.240 --> 00:45:07.200]   you'd be like, "Oh, it's a Magic Mind day."
[00:45:07.200 --> 00:45:08.280]   Magic Mind day.
[00:45:08.280 --> 00:45:10.440]   All right, Jesse, I think we should do some questions.
[00:45:10.440 --> 00:45:13.360]   Speaking of coffee.
[00:45:14.320 --> 00:45:18.400]   All right, we got a question here about reading.
[00:45:18.400 --> 00:45:20.080]   I combined two, actually.
[00:45:20.080 --> 00:45:21.400]   We had two questions about reading.
[00:45:21.400 --> 00:45:24.400]   So let's just read both, and I'll answer them together.
[00:45:24.400 --> 00:45:27.120]   So the first of these two combined questions came from Rid,
[00:45:27.120 --> 00:45:30.720]   who said, "How do I get back into reading fiction?
[00:45:30.720 --> 00:45:34.480]   I'm a lawyer and read a lot of cases and briefs all day.
[00:45:34.480 --> 00:45:36.000]   Reading anymore when I'm off the clock
[00:45:36.000 --> 00:45:36.920]   just feels like more work.
[00:45:36.920 --> 00:45:38.920]   How do I revive my love for reading fiction books
[00:45:38.920 --> 00:45:40.800]   without feeling the need to highlight
[00:45:40.800 --> 00:45:43.360]   every other sentence and markup follow-up questions
[00:45:43.360 --> 00:45:44.880]   in the margins?"
[00:45:44.880 --> 00:45:47.000]   Similar question from Tom, who says,
[00:45:47.000 --> 00:45:48.280]   "I have too many books I want to read.
[00:45:48.280 --> 00:45:50.040]   Where do I start?
[00:45:50.040 --> 00:45:51.960]   I don't make time to read with a busy work schedule
[00:45:51.960 --> 00:45:52.800]   and small children.
[00:45:52.800 --> 00:45:56.680]   Any ideas on how to fix this first world problem?"
[00:45:56.680 --> 00:46:01.320]   Well, first of all, let me motivate what you both want to do,
[00:46:01.320 --> 00:46:04.200]   which is cultivating a reading habit.
[00:46:04.200 --> 00:46:07.960]   Definitely, this is worth it.
[00:46:07.960 --> 00:46:09.360]   I'm gonna give you some advice here in a second,
[00:46:09.360 --> 00:46:10.760]   but I just want to start by saying,
[00:46:10.760 --> 00:46:12.560]   definitely, this is worth it.
[00:46:12.560 --> 00:46:14.520]   The reading life is a deep life.
[00:46:14.520 --> 00:46:17.440]   I think it's absolutely fundamental in so many ways.
[00:46:17.440 --> 00:46:20.520]   There's the pragmatic benefits of just what happens
[00:46:20.520 --> 00:46:23.240]   to your ability to focus and think and make connections.
[00:46:23.240 --> 00:46:25.760]   When you spend time in books, it's calisthenics
[00:46:25.760 --> 00:46:28.720]   for the brain, but there is also these more
[00:46:28.720 --> 00:46:32.360]   almost spiritual advantages of being able to get lost
[00:46:32.360 --> 00:46:34.120]   in different worlds, be it a world of fiction
[00:46:34.120 --> 00:46:36.560]   or a world of ideas or a world of history,
[00:46:36.560 --> 00:46:39.200]   to transport your mind to these other places.
[00:46:39.200 --> 00:46:42.000]   It's stress-relieving, it's invigorating,
[00:46:42.000 --> 00:46:44.800]   it allows you to empathetically connect with other people,
[00:46:44.800 --> 00:46:46.280]   with other experiences.
[00:46:46.280 --> 00:46:50.640]   It's like a magic machine for just becoming
[00:46:50.640 --> 00:46:51.480]   a better person.
[00:46:51.480 --> 00:46:56.080]   I am a huge reading booster, and so I'm glad,
[00:46:56.080 --> 00:46:57.760]   Ryd and Tom, that you're trying to focus on this.
[00:46:57.760 --> 00:47:00.200]   And again, that's why I really push this on the show.
[00:47:00.200 --> 00:47:02.000]   Read, read, read.
[00:47:02.000 --> 00:47:03.360]   All right, so how do I do it?
[00:47:03.360 --> 00:47:05.720]   How do I read five books a month?
[00:47:05.720 --> 00:47:07.200]   I'll mention four things here.
[00:47:08.400 --> 00:47:12.320]   One, so morning and meals.
[00:47:12.320 --> 00:47:14.880]   I'm often up early, I'm often up before my kids wake up,
[00:47:14.880 --> 00:47:16.400]   so I'll have a little bit of time in the morning
[00:47:16.400 --> 00:47:18.040]   before the rush begins.
[00:47:18.040 --> 00:47:19.520]   Reading is my activity then.
[00:47:19.520 --> 00:47:23.960]   I've just built an appreciation for, ooh, it's quiet.
[00:47:23.960 --> 00:47:26.680]   What do I do if I have extra time in the morning?
[00:47:26.680 --> 00:47:28.560]   That's what I go to, reading.
[00:47:28.560 --> 00:47:32.560]   Meals are the other time, especially breakfast and lunch.
[00:47:32.560 --> 00:47:34.520]   That's just the default activity.
[00:47:34.520 --> 00:47:35.520]   Ooh, it's eating time.
[00:47:35.520 --> 00:47:36.360]   What do I do?
[00:47:36.360 --> 00:47:37.680]   I read.
[00:47:37.680 --> 00:47:38.520]   I wanna read.
[00:47:38.520 --> 00:47:41.160]   That's a lot of time you build up,
[00:47:41.160 --> 00:47:43.160]   breakfast, lunch, reading.
[00:47:43.160 --> 00:47:47.720]   I make it a default high-quality leisure activity.
[00:47:47.720 --> 00:47:48.560]   This is number two.
[00:47:48.560 --> 00:47:49.600]   So if I have time,
[00:47:49.600 --> 00:47:51.000]   so if it's a night where we have some time,
[00:47:51.000 --> 00:47:55.320]   okay, we got everyone home, dinner's in an hour,
[00:47:55.320 --> 00:47:57.880]   kids are doing their homework.
[00:47:57.880 --> 00:47:59.240]   I'll be like, ooh, what do I wanna do?
[00:47:59.240 --> 00:48:00.640]   I get to read.
[00:48:00.640 --> 00:48:04.240]   I see that as a treat that I'm looking for.
[00:48:04.240 --> 00:48:05.320]   I don't always get to do it,
[00:48:05.320 --> 00:48:07.120]   but when I have time in the evening or the weekends,
[00:48:07.120 --> 00:48:09.240]   that's the high-quality goal that I'm looking for.
[00:48:09.240 --> 00:48:10.960]   Ooh, I can actually sit down and read
[00:48:10.960 --> 00:48:13.120]   and I have a good chair and I bring some tea
[00:48:13.120 --> 00:48:14.440]   or whatever you need to do.
[00:48:14.440 --> 00:48:16.880]   But you make it a default leisure activity.
[00:48:16.880 --> 00:48:19.960]   Three, audiobooks play a big role.
[00:48:19.960 --> 00:48:23.080]   Walking, commuting, chores, kids' sports games.
[00:48:23.080 --> 00:48:25.680]   It's a lot of time, a lot of time.
[00:48:25.680 --> 00:48:26.560]   And if you listen to audiobooks,
[00:48:26.560 --> 00:48:29.960]   you can actually get through quite a bit doing that as well.
[00:48:29.960 --> 00:48:31.240]   So you put those together,
[00:48:31.240 --> 00:48:33.160]   you get closer to how I read five books a month.
[00:48:33.160 --> 00:48:34.480]   But the biggest factor of all,
[00:48:34.480 --> 00:48:35.840]   and I really wanna emphasize this,
[00:48:35.840 --> 00:48:40.440]   is that I do not use my phone for entertainment.
[00:48:40.440 --> 00:48:44.920]   I do not have a habit of, if I'm bored,
[00:48:44.920 --> 00:48:47.240]   looking at this thing is how I become less bored.
[00:48:47.240 --> 00:48:51.320]   I do not have a habit of, if I am tired,
[00:48:51.320 --> 00:48:52.720]   this is where I'm gonna put my attention,
[00:48:52.720 --> 00:48:55.160]   or if I'm anxious, this is what I'm gonna fall into.
[00:48:55.160 --> 00:48:57.080]   I just don't use my phone in that way.
[00:48:57.080 --> 00:49:00.520]   I use my phone in a Steve Jobs 2007 mode,
[00:49:00.520 --> 00:49:04.120]   which is what a great Swiss Army Knife collection of tools
[00:49:04.120 --> 00:49:05.760]   that are all really useful to me.
[00:49:05.920 --> 00:49:08.200]   If I need to look up the weather, it's right here.
[00:49:08.200 --> 00:49:10.240]   If I need to look up directions to where we're going,
[00:49:10.240 --> 00:49:11.080]   it's right here.
[00:49:11.080 --> 00:49:12.840]   If I need to see what the hours are for this restaurant,
[00:49:12.840 --> 00:49:14.600]   I can pull it up right here.
[00:49:14.600 --> 00:49:16.280]   If I need to listen to music or a podcast,
[00:49:16.280 --> 00:49:17.440]   it's just right here.
[00:49:17.440 --> 00:49:19.960]   And I can jump right over to it and listen to it.
[00:49:19.960 --> 00:49:23.480]   So I use my phone like this fantastic Swiss Army Knife
[00:49:23.480 --> 00:49:24.920]   that has all these cool features
[00:49:24.920 --> 00:49:26.760]   and a beautiful interface all in one package.
[00:49:26.760 --> 00:49:28.520]   And I'm so glad that exists.
[00:49:28.520 --> 00:49:31.240]   It makes life easier than before it didn't.
[00:49:31.240 --> 00:49:33.280]   But it's not a source of entertainment for me.
[00:49:33.280 --> 00:49:35.600]   It's not a force of distraction for me.
[00:49:35.600 --> 00:49:37.880]   This makes a huge difference.
[00:49:37.880 --> 00:49:41.200]   I do not think people understand how much time
[00:49:41.200 --> 00:49:45.400]   in their day goes towards looking at their phone.
[00:49:45.400 --> 00:49:46.880]   It's one of the big points I make in my book,
[00:49:46.880 --> 00:49:48.520]   "Digital Minimalism."
[00:49:48.520 --> 00:49:50.600]   This is what was driving people for change
[00:49:50.600 --> 00:49:53.080]   is when they realized just how much time that was taking.
[00:49:53.080 --> 00:49:53.920]   So people are like, "I'm busy.
[00:49:53.920 --> 00:49:55.520]   "I have work, I have my kids.
[00:49:55.520 --> 00:49:56.920]   "I don't seem to have any other time."
[00:49:56.920 --> 00:49:58.260]   And say, "Well, wait a second.
[00:49:58.260 --> 00:50:00.360]   "I went back and checked and you spent three hours
[00:50:00.360 --> 00:50:02.760]   "looking at Twitter and Instagram today.
[00:50:02.760 --> 00:50:03.600]   "There was not time working.
[00:50:03.600 --> 00:50:04.660]   "There was not time with your kids.
[00:50:04.660 --> 00:50:05.500]   "That's three hours.
[00:50:05.500 --> 00:50:07.040]   "If you were reading in that time,
[00:50:07.040 --> 00:50:07.940]   "you'd get through a lot more
[00:50:07.940 --> 00:50:09.360]   "than just five books a month."
[00:50:09.360 --> 00:50:12.000]   So that's probably the biggest thing I can suggest.
[00:50:12.000 --> 00:50:14.040]   Put your phone back to 2007 mode.
[00:50:14.040 --> 00:50:16.840]   Swiss Army knife, great features when I need it.
[00:50:16.840 --> 00:50:18.000]   It's not a source of entertainment.
[00:50:18.000 --> 00:50:19.560]   So if you wanna be entertained,
[00:50:19.560 --> 00:50:22.840]   you can read, you can talk to people,
[00:50:22.840 --> 00:50:24.880]   you can do something productive around the house.
[00:50:24.880 --> 00:50:27.080]   High quality leisure is what is left.
[00:50:27.080 --> 00:50:30.800]   - In the mornings, how much do you usually read for
[00:50:30.800 --> 00:50:31.640]   before breakfast?
[00:50:31.640 --> 00:50:34.000]   - It depends how early I'm up, but it is my default.
[00:50:34.100 --> 00:50:36.960]   I see it as, "Oh, this is great.
[00:50:36.960 --> 00:50:38.740]   "There's some reading time."
[00:50:38.740 --> 00:50:40.860]   And I'll say, the habit builds.
[00:50:40.860 --> 00:50:42.780]   So I probably should have mentioned this to,
[00:50:42.780 --> 00:50:43.980]   I forgot their names.
[00:50:43.980 --> 00:50:46.260]   - Tom and Rid. - Tom and Rid.
[00:50:46.260 --> 00:50:49.500]   Start with, when you're restarting a reading habit,
[00:50:49.500 --> 00:50:51.460]   stuff that you love.
[00:50:51.460 --> 00:50:56.460]   Don't try to go back and buy the 1948 version
[00:50:56.460 --> 00:50:59.540]   of Thomas Merton, which by the way, I finished
[00:50:59.540 --> 00:51:00.380]   and it took forever.
[00:51:00.380 --> 00:51:01.660]   That's a long book.
[00:51:01.660 --> 00:51:05.720]   It took forever and then I picked up another book.
[00:51:05.720 --> 00:51:09.960]   So we're recording this on April, what's this, 24th?
[00:51:09.960 --> 00:51:11.440]   But there's something like this.
[00:51:11.440 --> 00:51:14.760]   But yeah, I hit my five books for April a couple days ago.
[00:51:14.760 --> 00:51:16.620]   But I was a little touch and go for a little bit
[00:51:16.620 --> 00:51:19.600]   because then another book I found in a little free library
[00:51:19.600 --> 00:51:21.240]   near the field where my son plays little league.
[00:51:21.240 --> 00:51:22.400]   And I'm like, "This looks fun."
[00:51:22.400 --> 00:51:24.480]   It was 450 pages too.
[00:51:24.480 --> 00:51:27.480]   And 450 page books are like two normal size books.
[00:51:27.480 --> 00:51:28.880]   They take a long time to read.
[00:51:28.880 --> 00:51:30.680]   So I had some pretty mammoth books.
[00:51:30.680 --> 00:51:32.080]   I had to work on this month.
[00:51:32.080 --> 00:51:36.280]   So you don't have to grab a 450 page book.
[00:51:36.280 --> 00:51:38.040]   You don't have to have Thomas Merton,
[00:51:38.040 --> 00:51:42.520]   getting into Catholic theology for hundreds of pages.
[00:51:42.520 --> 00:51:46.320]   Just get the Project Hail Mary from Andy Weir.
[00:51:46.320 --> 00:51:48.280]   That's like a really fun book to read.
[00:51:48.280 --> 00:51:51.020]   Like I'm going back now and rereading Born Standing Up.
[00:51:51.020 --> 00:51:53.000]   That's like candy to me, Steve Martin's memoir.
[00:51:53.000 --> 00:51:55.640]   Just get a sports book about a sports.
[00:51:55.640 --> 00:51:58.880]   Just get into, get like a advice book
[00:51:58.880 --> 00:52:00.480]   that's just like put it in my veins,
[00:52:00.480 --> 00:52:02.100]   aspirational, not that hard to read.
[00:52:02.100 --> 00:52:04.160]   Just get back in the habit of reading.
[00:52:04.160 --> 00:52:07.120]   And then you begin to have the default, I want to do that.
[00:52:07.120 --> 00:52:08.760]   And then like me, if I have time in the morning,
[00:52:08.760 --> 00:52:10.000]   like this is great, I can read.
[00:52:10.000 --> 00:52:12.440]   Like this morning I'm reading this Daniel Boone book.
[00:52:12.440 --> 00:52:14.920]   I read a bunch of books at the same time.
[00:52:14.920 --> 00:52:17.560]   And that's what I did this morning before my kids woke up.
[00:52:17.560 --> 00:52:18.400]   Like, this is great.
[00:52:18.400 --> 00:52:19.280]   I can get through some of this book.
[00:52:19.280 --> 00:52:22.920]   And you get in that habit by reading stuff you love.
[00:52:22.920 --> 00:52:25.400]   And you're like, this is much better than my phone.
[00:52:25.400 --> 00:52:27.520]   And then it's not so hard to have to convince yourself
[00:52:27.520 --> 00:52:28.360]   to do it.
[00:52:29.360 --> 00:52:30.960]   But yeah, I'm a big reading fan.
[00:52:30.960 --> 00:52:32.760]   I'm a terrible marketer.
[00:52:32.760 --> 00:52:35.200]   I should have told them the secret.
[00:52:35.200 --> 00:52:36.920]   The only way you're going to get a reading habit
[00:52:36.920 --> 00:52:39.320]   is to read through all of my books.
[00:52:39.320 --> 00:52:40.480]   So you got to buy them all.
[00:52:40.480 --> 00:52:42.640]   You need fresh copies of all my books.
[00:52:42.640 --> 00:52:44.000]   And then you'll--
[00:52:44.000 --> 00:52:44.840]   - Hardcover.
[00:52:44.840 --> 00:52:45.660]   - Hardcover.
[00:52:45.660 --> 00:52:47.600]   You got to give them hardcover.
[00:52:47.600 --> 00:52:49.500]   You know, all of my books, since my student books
[00:52:49.500 --> 00:52:53.160]   are in hardcover still, it's kind of rare,
[00:52:53.160 --> 00:52:55.040]   but So Good They Can't Ignore You, Deep Work,
[00:52:55.040 --> 00:52:56.920]   Digital Minimalism, and A World Without Email
[00:52:56.920 --> 00:52:59.760]   are all only in hardcover in the US.
[00:52:59.760 --> 00:53:01.720]   In the UK, there are no hardcovers.
[00:53:01.720 --> 00:53:03.020]   Everything is paperback.
[00:53:03.020 --> 00:53:04.760]   But if you see any of those books advertised
[00:53:04.760 --> 00:53:07.380]   as paperback on Amazon, that's the UK version.
[00:53:07.380 --> 00:53:10.200]   So when you see Deep Work with the lamp on the front,
[00:53:10.200 --> 00:53:11.440]   that's not the US version.
[00:53:11.440 --> 00:53:13.640]   That's the UK and the British Commonwealth version.
[00:53:13.640 --> 00:53:15.920]   It's like what you'll get in Australia.
[00:53:15.920 --> 00:53:18.160]   It's what you'll get in Britain.
[00:53:18.160 --> 00:53:19.800]   And it's also the cover that like most
[00:53:19.800 --> 00:53:21.100]   of the European versions use.
[00:53:21.100 --> 00:53:23.220]   But the US does hardcovers.
[00:53:23.220 --> 00:53:24.680]   All of those books are still in hardcover
[00:53:24.680 --> 00:53:26.480]   because they keep selling.
[00:53:26.480 --> 00:53:27.480]   So I think it's a good thing.
[00:53:27.480 --> 00:53:30.080]   So typically when sales start to fall off,
[00:53:30.080 --> 00:53:31.400]   then you're like, okay, now we're gonna do
[00:53:31.400 --> 00:53:34.320]   a paperback release because A, it gives you a reason
[00:53:34.320 --> 00:53:36.440]   to repromote a book, and B, they're smaller,
[00:53:36.440 --> 00:53:39.120]   so bookstores are more likely to keep a copy on their shelf.
[00:53:39.120 --> 00:53:40.560]   We haven't had to do that yet,
[00:53:40.560 --> 00:53:41.960]   which I think is a good sign.
[00:53:41.960 --> 00:53:44.280]   So if you look at a book in this space
[00:53:44.280 --> 00:53:47.440]   that you can't find in paperback, like Four Hour Workweek,
[00:53:47.440 --> 00:53:49.040]   there's a reason why you can't find it in paperback
[00:53:49.040 --> 00:53:50.740]   because it's twice as much royalty.
[00:53:50.740 --> 00:53:52.360]   They make twice as much on the hardcovers
[00:53:52.360 --> 00:53:53.360]   and they're still selling.
[00:53:53.360 --> 00:53:54.200]   - Wow.
[00:53:54.200 --> 00:53:55.680]   - Or like Greg McKeown's Essentialism.
[00:53:55.680 --> 00:53:57.360]   Why can't you get that in paperback?
[00:53:57.360 --> 00:53:59.080]   The thing is selling.
[00:53:59.080 --> 00:54:01.360]   A lot of Brene Brown still is in,
[00:54:01.360 --> 00:54:03.060]   I mean, some of that's in paperback now,
[00:54:03.060 --> 00:54:06.600]   but still in hardcover because that thing is selling.
[00:54:06.600 --> 00:54:09.880]   You're not gonna find Ryan Holiday's books in paperback.
[00:54:09.880 --> 00:54:10.760]   They're selling.
[00:54:10.760 --> 00:54:12.760]   So a little insider baseball there.
[00:54:12.760 --> 00:54:16.280]   So it's a good sign if your books stay in hardcover.
[00:54:16.280 --> 00:54:19.560]   All right, man, we're only, where are we?
[00:54:19.560 --> 00:54:20.800]   Woo!
[00:54:20.800 --> 00:54:24.060]   We're really leaning into this longer episode.
[00:54:25.200 --> 00:54:26.360]   We're going a little bit too far.
[00:54:26.360 --> 00:54:28.520]   We're on question number two, Jesse.
[00:54:28.520 --> 00:54:30.680]   We're 55 minutes into the show,
[00:54:30.680 --> 00:54:31.960]   but I have good news for you.
[00:54:31.960 --> 00:54:34.720]   The second question, we're doing rapid fire.
[00:54:34.720 --> 00:54:36.280]   So this was one of Jesse's ideas.
[00:54:36.280 --> 00:54:39.080]   I have three questions, quick answers to each.
[00:54:39.080 --> 00:54:41.240]   Let's do this rapid fire.
[00:54:41.240 --> 00:54:43.760]   Question number one comes from Freddie.
[00:54:43.760 --> 00:54:46.120]   "On average, how much does Cal watch TV,
[00:54:46.120 --> 00:54:47.080]   "including TV shows,
[00:54:47.080 --> 00:54:49.720]   "given the fact that reading is his default activity?"
[00:54:49.720 --> 00:54:50.800]   Okay, this is quite relevant
[00:54:50.800 --> 00:54:52.520]   given what we were just talking about.
[00:54:52.520 --> 00:54:54.800]   Freddie, I don't watch a lot of TV.
[00:54:54.800 --> 00:54:57.880]   I would say a normal day, maybe 30 to 45 minutes.
[00:54:57.880 --> 00:54:59.860]   The only time I really watch TV
[00:54:59.860 --> 00:55:02.760]   is in the brief window between my kids,
[00:55:02.760 --> 00:55:05.120]   once I put my kids to bed and before I go to bed,
[00:55:05.120 --> 00:55:06.200]   which is not much later
[00:55:06.200 --> 00:55:08.480]   because I'm just exhausted dealing with them
[00:55:08.480 --> 00:55:09.720]   by the end of the day.
[00:55:09.720 --> 00:55:10.780]   If we have a show,
[00:55:10.780 --> 00:55:14.360]   my wife and I will try to watch it in that little window.
[00:55:14.360 --> 00:55:15.480]   And so we do our best.
[00:55:15.480 --> 00:55:19.360]   Like right now, we've been watching "Slow Horses"
[00:55:19.360 --> 00:55:20.520]   on Apple TV+.
[00:55:20.520 --> 00:55:23.320]   It took us a little while to get into it,
[00:55:23.320 --> 00:55:24.480]   but now it's kind of picking up
[00:55:24.480 --> 00:55:25.360]   and we're enjoying it.
[00:55:25.360 --> 00:55:27.680]   We like shows where it's weekly releases
[00:55:27.680 --> 00:55:28.840]   instead of binging.
[00:55:28.840 --> 00:55:31.840]   We tried that new show "Open Range"
[00:55:31.840 --> 00:55:33.440]   and I didn't think, I don't know.
[00:55:33.440 --> 00:55:34.860]   I had high hopes.
[00:55:34.860 --> 00:55:38.000]   I liked Jeff Brolin and it was like supernatural
[00:55:38.000 --> 00:55:40.660]   and a ranch, but it wasn't quite working for me.
[00:55:40.660 --> 00:55:43.520]   Last night, we started "The Batman"
[00:55:43.520 --> 00:55:45.000]   and then realized it's like,
[00:55:45.000 --> 00:55:47.360]   and I think this is the official running length,
[00:55:47.360 --> 00:55:48.480]   seven hours long.
[00:55:48.480 --> 00:55:50.760]   - 2.30, right? - 2.30, yeah.
[00:55:50.760 --> 00:55:52.920]   Here's the problem about "The Batman."
[00:55:52.920 --> 00:55:53.840]   If I was the mayor,
[00:55:53.840 --> 00:55:55.240]   well, I guess the mayor got killed in the beginning,
[00:55:55.240 --> 00:55:56.560]   but if I was the mayor of Gotham City,
[00:55:56.560 --> 00:55:57.400]   I would say by far,
[00:55:57.400 --> 00:56:00.160]   number one problem is every single light bulb
[00:56:00.160 --> 00:56:02.520]   in this city is flickering and about to go out.
[00:56:02.520 --> 00:56:05.080]   Like, let's solve that problem.
[00:56:05.080 --> 00:56:07.720]   Let's solve that problem
[00:56:07.720 --> 00:56:11.920]   and then solve the problem of we have like a lot of villains.
[00:56:11.920 --> 00:56:13.200]   The other thing about, okay,
[00:56:13.200 --> 00:56:15.080]   we got 50 minutes in and kind of gave up
[00:56:15.080 --> 00:56:16.360]   because I'm not great with superhero movies.
[00:56:16.360 --> 00:56:18.960]   And it was literally just very dark,
[00:56:18.960 --> 00:56:20.720]   but right off the bat,
[00:56:20.720 --> 00:56:23.500]   Cedric Diggory in his full Batman outfit,
[00:56:23.500 --> 00:56:24.760]   it's just like straight face,
[00:56:24.760 --> 00:56:26.480]   just standing around with normal people,
[00:56:26.480 --> 00:56:28.520]   like with detectives having conversations,
[00:56:28.520 --> 00:56:29.360]   like again and again.
[00:56:29.360 --> 00:56:31.560]   And like, people would just say,
[00:56:31.560 --> 00:56:33.560]   "I'm sorry, this is just crazy."
[00:56:33.560 --> 00:56:34.760]   Like you're wearing a costume,
[00:56:34.760 --> 00:56:36.320]   like a really like elaborate costume.
[00:56:36.320 --> 00:56:38.080]   And you're just sitting here like with the detectives
[00:56:38.080 --> 00:56:39.600]   kind of like commenting on evidence
[00:56:39.600 --> 00:56:40.980]   and like talking in a growling voice.
[00:56:40.980 --> 00:56:42.040]   And it's just ridiculous.
[00:56:42.040 --> 00:56:44.720]   And I think people would call it out.
[00:56:44.720 --> 00:56:46.120]   People would call it out as ridiculous.
[00:56:46.120 --> 00:56:48.800]   So anyways, Friday, we don't watch much TV.
[00:56:48.800 --> 00:56:50.960]   All right, Anna asks,
[00:56:50.960 --> 00:56:53.280]   "When should I answer emails and messages?
[00:56:53.280 --> 00:56:54.980]   Most day I start working at eight.
[00:56:54.980 --> 00:56:57.180]   However, my job as a doctor consumes all the time
[00:56:57.180 --> 00:57:00.500]   I have at work, sometimes up to eight."
[00:57:00.500 --> 00:57:01.780]   Anna, in your situation,
[00:57:01.780 --> 00:57:03.080]   there's two things I would suggest.
[00:57:03.080 --> 00:57:05.900]   One, you need to schedule admin time,
[00:57:05.900 --> 00:57:08.520]   including email checks using your appointment system.
[00:57:08.520 --> 00:57:11.300]   So it needs to take the slot of an appointment.
[00:57:11.300 --> 00:57:14.620]   I know there's pressure within medical practices to say,
[00:57:14.620 --> 00:57:18.380]   "Well, in theory, we could have," whatever it is,
[00:57:18.380 --> 00:57:20.500]   "17 appointments per day,"
[00:57:20.500 --> 00:57:22.620]   because we go back to back, they're these long.
[00:57:22.620 --> 00:57:24.200]   We could fit that many in.
[00:57:24.200 --> 00:57:26.640]   And then you adjust to that level and say,
[00:57:26.640 --> 00:57:27.720]   "Well, that's what we need to do."
[00:57:27.720 --> 00:57:29.440]   And I'm saying adjust to a lower level
[00:57:29.440 --> 00:57:32.080]   and do 14 appointments with three blocks
[00:57:32.080 --> 00:57:33.080]   that would be appointment blocks
[00:57:33.080 --> 00:57:35.440]   to keep up with your communication.
[00:57:35.440 --> 00:57:37.440]   Yes, that's a little bit less money going to the practice,
[00:57:37.440 --> 00:57:39.160]   but it keeps the whole thing tractable.
[00:57:39.160 --> 00:57:42.000]   And the dollar amounts are all arbitrary anyways.
[00:57:42.000 --> 00:57:44.000]   The second thing I would say is find ways then
[00:57:44.000 --> 00:57:46.520]   to reduce the number of messages until it's enough.
[00:57:46.520 --> 00:57:48.520]   So schedule time,
[00:57:48.520 --> 00:57:50.440]   like appointments to handle your messages.
[00:57:50.440 --> 00:57:52.520]   If there's still way more messages you can handle,
[00:57:52.520 --> 00:57:54.880]   then you need to change something.
[00:57:54.880 --> 00:57:57.760]   More processes, maybe different ways you interact.
[00:57:57.760 --> 00:57:59.440]   You mentioned in the elaboration,
[00:57:59.440 --> 00:58:01.800]   you had a secretary helping with a lot of things.
[00:58:01.800 --> 00:58:03.680]   You can have more careful processes
[00:58:03.680 --> 00:58:05.880]   that allow his or her to take more of that off your plate,
[00:58:05.880 --> 00:58:07.560]   but your time is your time.
[00:58:07.560 --> 00:58:09.200]   If you've taken a reasonable amount of your time out
[00:58:09.200 --> 00:58:11.560]   to managing your admin, which is good to do,
[00:58:11.560 --> 00:58:12.680]   and you still can't manage it,
[00:58:12.680 --> 00:58:14.040]   then you have to reduce the admin.
[00:58:14.040 --> 00:58:16.380]   And that might require some work.
[00:58:16.380 --> 00:58:20.760]   Finally, Amadeus asks in our rapid fire challenge here,
[00:58:20.760 --> 00:58:23.360]   "Do you practice journaling?"
[00:58:23.360 --> 00:58:27.760]   I don't, not in the classical sense of taking notes
[00:58:27.760 --> 00:58:28.960]   on my thoughts of the day
[00:58:28.960 --> 00:58:31.780]   on some sort of consistent time basis.
[00:58:31.780 --> 00:58:33.800]   However, of course, as I talked about a lot on the show,
[00:58:33.800 --> 00:58:37.200]   I do collect ideas and notes, strategies, and plans
[00:58:37.200 --> 00:58:40.080]   about living a deeper life in my moleskin journal
[00:58:40.080 --> 00:58:42.720]   that I keep with me most places I go.
[00:58:42.720 --> 00:58:44.780]   And I see that as a form of journaling.
[00:58:44.780 --> 00:58:46.560]   It's not as structured or consistent
[00:58:46.560 --> 00:58:48.800]   as I write every morning,
[00:58:48.800 --> 00:58:51.620]   but it is a place where I do end up working out some thoughts
[00:58:51.620 --> 00:58:53.280]   about what's important to me or what's not.
[00:58:53.280 --> 00:58:54.800]   It's where I have self-observations.
[00:58:54.800 --> 00:58:58.140]   It helps me focus my energies on what matters
[00:58:58.140 --> 00:58:58.980]   and what doesn't.
[00:58:58.980 --> 00:59:01.640]   So I don't formally journal,
[00:59:01.640 --> 00:59:06.320]   but having a notebook about deep life thoughts,
[00:59:06.320 --> 00:59:09.480]   I think for me actually satisfies a lot
[00:59:09.480 --> 00:59:11.220]   of the same function.
[00:59:11.220 --> 00:59:13.740]   All right, Jesse.
[00:59:13.740 --> 00:59:15.320]   Well, I think we should try to mix some calls
[00:59:15.320 --> 00:59:17.400]   into what we're doing here.
[00:59:17.400 --> 00:59:18.220]   Looking at my script,
[00:59:18.220 --> 00:59:20.160]   I think we do have a call queued up
[00:59:20.160 --> 00:59:21.400]   that we can jump over to.
[00:59:21.400 --> 00:59:24.080]   - Yep, we do.
[00:59:24.080 --> 00:59:26.100]   We got a question about,
[00:59:26.100 --> 00:59:28.040]   a specific question about weekly planning
[00:59:28.040 --> 00:59:30.600]   and how that interacts with your travel boards.
[00:59:30.600 --> 00:59:32.480]   - All right, let's get in the weeds.
[00:59:32.480 --> 00:59:33.320]   - Hey, Cal.
[00:59:33.320 --> 00:59:35.500]   I have a question about doing weekly planning.
[00:59:35.500 --> 00:59:37.080]   So when I go into my travel board,
[00:59:37.080 --> 00:59:39.900]   I'm adding cards to a this week column
[00:59:39.900 --> 00:59:41.840]   for each of my functional areas.
[00:59:41.840 --> 00:59:43.560]   But what I'm struggling with is,
[00:59:43.560 --> 00:59:45.960]   what's the information that lives in your weekly planning
[00:59:45.960 --> 00:59:48.820]   doc, your weekly planning summary that you're writing out
[00:59:48.820 --> 00:59:51.400]   that doesn't live in that travel board?
[00:59:51.400 --> 00:59:52.660]   Looking for some clarity about this
[00:59:52.660 --> 00:59:55.320]   and also whether the written document
[00:59:55.320 --> 00:59:56.940]   is really a necessary artifact
[00:59:56.940 --> 00:59:59.400]   if your travel board is really well organized
[00:59:59.400 --> 01:00:01.280]   and has clear goals for the week.
[01:00:01.280 --> 01:00:02.560]   Thanks.
[01:00:02.560 --> 01:00:05.580]   - All right, well, Philip, this is a good question.
[01:00:05.580 --> 01:00:08.060]   It's one that I get a fair amount.
[01:00:08.060 --> 01:00:11.440]   I think weekly plans is probably the piece
[01:00:11.440 --> 01:00:15.440]   of my productivity thinking that it gives people
[01:00:15.440 --> 01:00:17.980]   the most room for confusion.
[01:00:17.980 --> 01:00:19.760]   And of course, I now tell people,
[01:00:19.760 --> 01:00:24.720]   if you want the crash course in time management,
[01:00:24.720 --> 01:00:26.680]   I'm trying to be careful these days, by the way,
[01:00:26.680 --> 01:00:29.180]   to separate time management from productivity.
[01:00:29.180 --> 01:00:31.520]   I think of time management about how do you keep track
[01:00:31.520 --> 01:00:32.840]   of what you have to do and figure out
[01:00:32.840 --> 01:00:33.840]   when you're gonna execute it.
[01:00:33.840 --> 01:00:36.200]   I separate that from productivity,
[01:00:36.200 --> 01:00:38.520]   which I feel like is more teleological.
[01:00:38.520 --> 01:00:40.760]   Like what are you trying to do with your work?
[01:00:40.760 --> 01:00:41.800]   How do you measure that?
[01:00:41.800 --> 01:00:44.480]   How do you reshape your work to get towards those goals?
[01:00:44.480 --> 01:00:46.240]   So time management is what I wanna call
[01:00:46.240 --> 01:00:47.720]   what we're talking about here.
[01:00:47.720 --> 01:00:49.880]   We have a video on the YouTube page
[01:00:49.880 --> 01:00:51.360]   called Core Ideas Time Management,
[01:00:51.360 --> 01:00:53.640]   where I talk about my multi-scale time management systems.
[01:00:53.640 --> 01:00:56.560]   That's the primer for everything we're about to say.
[01:00:56.560 --> 01:00:59.160]   All right, Trello versus weekly plans.
[01:00:59.160 --> 01:01:03.020]   Trello is the software I happen to use
[01:01:03.020 --> 01:01:04.800]   to keep track of tasks.
[01:01:04.800 --> 01:01:08.360]   So obligations, things that I am committed to accomplish,
[01:01:08.360 --> 01:01:10.480]   is where I keep track of those things.
[01:01:10.480 --> 01:01:12.020]   I keep track of their status
[01:01:12.020 --> 01:01:14.480]   based on what column I put them in.
[01:01:14.480 --> 01:01:17.180]   I keep track of what role they are related to
[01:01:17.180 --> 01:01:19.240]   by what board I put them on.
[01:01:19.240 --> 01:01:23.080]   So I might have a separate board for my life as a teacher
[01:01:23.080 --> 01:01:24.360]   versus my life as a researcher
[01:01:24.360 --> 01:01:26.880]   versus my life as a writer.
[01:01:26.880 --> 01:01:30.560]   It's also where I can keep information
[01:01:30.560 --> 01:01:31.520]   related to these tasks.
[01:01:31.520 --> 01:01:35.760]   That's why I like Trello, 'cause it's a card metaphor.
[01:01:35.760 --> 01:01:37.720]   And on the back of these virtual cards,
[01:01:37.720 --> 01:01:39.840]   you can attach files or take copious notes.
[01:01:39.840 --> 01:01:43.120]   So I do like consolidating information.
[01:01:43.120 --> 01:01:46.740]   So Trello is what I use to keep track of the tasks
[01:01:46.740 --> 01:01:48.220]   on my plate.
[01:01:48.220 --> 01:01:49.780]   You can use other software,
[01:01:49.780 --> 01:01:51.740]   but that's the goal I use it for.
[01:01:51.740 --> 01:01:54.440]   A weekly plan, by contrast,
[01:01:54.440 --> 01:01:57.380]   is gonna contain potentially many more things.
[01:01:57.380 --> 01:01:59.140]   So here's, I have a list here, I was thinking about it,
[01:01:59.140 --> 01:02:01.940]   of three main things you will often see on a weekly plan.
[01:02:01.940 --> 01:02:07.660]   One is assignment of specific work to specific days.
[01:02:07.660 --> 01:02:10.780]   So that's something that will happen in your weekly plan.
[01:02:10.780 --> 01:02:12.180]   Now, sometimes these are small things
[01:02:12.180 --> 01:02:13.900]   that exist on your Trello board.
[01:02:13.900 --> 01:02:15.960]   So like discrete obligations,
[01:02:15.960 --> 01:02:19.700]   like I need to submit my conflict of interest form.
[01:02:19.700 --> 01:02:20.660]   Right, so sometimes you're saying,
[01:02:20.660 --> 01:02:22.800]   yeah, I'm doing that on Wednesday morning,
[01:02:22.800 --> 01:02:24.940]   I'm doing this on Thursday morning.
[01:02:24.940 --> 01:02:28.260]   It also can assign ongoing efforts to days.
[01:02:28.260 --> 01:02:31.180]   Big ongoing efforts typically wouldn't live in Trello,
[01:02:31.180 --> 01:02:34.540]   those would live in your strategic or quarterly plan.
[01:02:34.540 --> 01:02:36.780]   So like, let's say for example,
[01:02:36.780 --> 01:02:40.020]   this month I'm trying to get two chapters written
[01:02:40.020 --> 01:02:40.860]   in my book.
[01:02:40.860 --> 01:02:43.820]   I would not have a task in my Trello board
[01:02:43.820 --> 01:02:45.140]   that said write two chapters.
[01:02:45.140 --> 01:02:48.300]   I would see that in my quarterly or semester plan.
[01:02:48.300 --> 01:02:50.140]   And then when I was making my weekly plan, say, okay,
[01:02:50.140 --> 01:02:54.540]   when am I gonna have time to work on my book chapter writing?
[01:02:54.540 --> 01:02:55.500]   And that's when I might say, look,
[01:02:55.500 --> 01:02:57.180]   Tuesday morning's open, I'm gonna write then,
[01:02:57.180 --> 01:02:59.140]   or I'm gonna write one hour every morning.
[01:02:59.140 --> 01:03:01.380]   So again, work gets assigned to specific days
[01:03:01.380 --> 01:03:02.260]   in your weekly plan,
[01:03:02.260 --> 01:03:04.820]   and some of that work might not exist on your Trello board,
[01:03:04.820 --> 01:03:07.660]   but might be coming from your semester or quarterly plan.
[01:03:07.660 --> 01:03:10.940]   Another thing that will often find its way
[01:03:10.940 --> 01:03:14.260]   into your weekly plan are schedule highlights.
[01:03:14.260 --> 01:03:17.740]   So I might point out, for example,
[01:03:17.740 --> 01:03:19.380]   Thursday's an early morning,
[01:03:19.380 --> 01:03:21.860]   we got an 8 a.m. meeting, so we have to get up and going,
[01:03:21.860 --> 01:03:25.420]   or look, we're ending early on Friday.
[01:03:25.420 --> 01:03:27.220]   Let's try to end by three on Friday,
[01:03:27.220 --> 01:03:29.440]   or there's a visitor in town Monday through Wednesday.
[01:03:29.440 --> 01:03:31.740]   So keep in mind, we're gonna be escorting that person.
[01:03:31.740 --> 01:03:32.580]   So it's just highlights
[01:03:32.580 --> 01:03:33.620]   about what's happening in your schedule.
[01:03:33.620 --> 01:03:36.180]   Those are largely coming out of your calendar,
[01:03:36.180 --> 01:03:39.100]   or you looking at your calendar and making some ideas
[01:03:39.100 --> 01:03:41.220]   about let's end early on this day, et cetera.
[01:03:41.220 --> 01:03:43.580]   So schedule highlights go in your weekly plan.
[01:03:43.580 --> 01:03:45.660]   And then finally, reminders about habits
[01:03:45.660 --> 01:03:48.960]   or heuristics that you're executing.
[01:03:48.960 --> 01:03:51.340]   So maybe you're trying out something
[01:03:51.340 --> 01:03:53.240]   where you write one hour every morning.
[01:03:53.240 --> 01:03:56.480]   Weekly plan is where you would remind yourself about it.
[01:03:56.480 --> 01:03:59.540]   Maybe you're thinking that your shutdown rituals
[01:03:59.540 --> 01:04:02.380]   have been lacking, so you have a reminder
[01:04:02.380 --> 01:04:04.540]   in your weekly plan, we're gonna do really hard shutdowns,
[01:04:04.540 --> 01:04:05.900]   check it off at our time block plan,
[01:04:05.900 --> 01:04:08.920]   or let's not be lazy about it.
[01:04:08.920 --> 01:04:11.220]   All of that goes into a weekly plan.
[01:04:11.220 --> 01:04:13.060]   And a lot of that has nothing to do
[01:04:13.060 --> 01:04:15.560]   with what you would have stored just in a Trello board.
[01:04:15.560 --> 01:04:18.260]   So good question, Trello's just task storage,
[01:04:18.260 --> 01:04:21.940]   weekly plans can be so much more.
[01:04:21.940 --> 01:04:24.020]   - Do you put any of your exercise stuff
[01:04:24.020 --> 01:04:27.740]   into your weekly plan, or is that just on autopilot?
[01:04:27.740 --> 01:04:31.340]   - It depends what's going on with my schedule.
[01:04:31.340 --> 01:04:32.500]   So yeah, it definitely can.
[01:04:32.500 --> 01:04:34.540]   If I have a complicated schedule,
[01:04:34.540 --> 01:04:36.900]   a weekly plan would be a good place to work out
[01:04:36.900 --> 01:04:38.980]   where exercise is gonna happen that week.
[01:04:38.980 --> 01:04:41.900]   And so I was definitely doing some of that this spring,
[01:04:41.900 --> 01:04:44.700]   keeping in mind on teaching days were pretty complicated,
[01:04:44.700 --> 01:04:46.780]   where was I gonna fit exercise in?
[01:04:46.780 --> 01:04:49.180]   And so then I would use weekly plan.
[01:04:49.180 --> 01:04:50.540]   Sometimes it's, on other parts of the year,
[01:04:50.540 --> 01:04:52.420]   it's just very autopilot.
[01:04:52.420 --> 01:04:54.140]   This is just when I do it.
[01:04:54.140 --> 01:04:58.300]   I've been doing recently, I call them happy hour workouts,
[01:04:58.300 --> 01:05:00.180]   where it's like my happy hours,
[01:05:00.180 --> 01:05:02.420]   that time right before dinner is when I exercise.
[01:05:02.420 --> 01:05:04.500]   Like that's a pretty consistently open time.
[01:05:04.500 --> 01:05:07.140]   And for me, it's also a good transition
[01:05:07.140 --> 01:05:12.140]   from work mindset to family mindset.
[01:05:12.140 --> 01:05:14.580]   And so when I'm doing that, it's just automatic.
[01:05:14.580 --> 01:05:15.860]   Like that's when I work out
[01:05:15.860 --> 01:05:17.380]   and everyone can be on the same page.
[01:05:17.380 --> 01:05:20.460]   And so I probably wouldn't have to remind myself of that
[01:05:20.460 --> 01:05:21.300]   after a while.
[01:05:23.740 --> 01:05:24.700]   All right, so Jesse,
[01:05:24.700 --> 01:05:27.380]   I was thinking about trying a new segment.
[01:05:27.380 --> 01:05:30.700]   It's named, I mean, it's an old name.
[01:05:30.700 --> 01:05:32.540]   We used to call Thursday episodes this,
[01:05:32.540 --> 01:05:36.420]   but I was thinking about calling the segment habit tune up.
[01:05:36.420 --> 01:05:40.140]   And the idea was I just take a piece of advice
[01:05:40.140 --> 01:05:44.260]   from the types of advice I give
[01:05:44.260 --> 01:05:46.100]   and just get into it a little bit.
[01:05:46.100 --> 01:05:47.500]   So let's just take a piece of,
[01:05:47.500 --> 01:05:48.980]   take of advice out of my toolkit
[01:05:48.980 --> 01:05:50.260]   and get into it a little bit,
[01:05:50.260 --> 01:05:52.340]   even without a question to prompt it.
[01:05:53.340 --> 01:05:55.020]   So we're gonna give that a try.
[01:05:55.020 --> 01:05:58.820]   Today's habit tune up is gonna be about
[01:05:58.820 --> 01:06:02.300]   one of my longest running productivity strategies.
[01:06:02.300 --> 01:06:05.780]   So in terms of strategies that I have run in my own life,
[01:06:05.780 --> 01:06:07.940]   this is pretty high up on the list
[01:06:07.940 --> 01:06:11.020]   of things I've been doing for the longest amount of time.
[01:06:11.020 --> 01:06:15.500]   And that is fixed schedule productivity.
[01:06:15.500 --> 01:06:18.660]   All right, so what is fixed schedule productivity?
[01:06:18.660 --> 01:06:20.460]   It's a simple idea where it says,
[01:06:20.460 --> 01:06:25.460]   you fix the hours that you wanna work.
[01:06:25.460 --> 01:06:27.100]   So like on a typical day,
[01:06:27.100 --> 01:06:29.620]   here's the length I want for my workday.
[01:06:29.620 --> 01:06:32.380]   And then you work backwards and do what you have to do
[01:06:32.380 --> 01:06:33.980]   to make the work actually fit.
[01:06:33.980 --> 01:06:37.620]   So that's primary fixed schedule productivity.
[01:06:37.620 --> 01:06:41.100]   I work 8.30 to 4.30, I work nine to five, I work eight to six
[01:06:41.100 --> 01:06:44.180]   you fix the hours and say, that is my line in the sand.
[01:06:44.180 --> 01:06:47.420]   Now I have to do what I can to make that fit.
[01:06:47.420 --> 01:06:49.540]   There's then secondary fixed schedule productivity,
[01:06:49.540 --> 01:06:52.180]   which is where you take specific types of work
[01:06:52.180 --> 01:06:53.140]   you do on a recurring basis
[01:06:53.140 --> 01:06:55.500]   and give that an even smaller boundary.
[01:06:55.500 --> 01:06:58.940]   In our life, my biggest example of that
[01:06:58.940 --> 01:07:00.180]   is probably this podcast.
[01:07:00.180 --> 01:07:04.220]   It exists for me in a half day.
[01:07:04.220 --> 01:07:06.260]   It gets a half day per week.
[01:07:06.260 --> 01:07:09.340]   And as Jesse knows, we will work backwards to fit
[01:07:09.340 --> 01:07:10.660]   whatever it takes, we will work backwards.
[01:07:10.660 --> 01:07:12.860]   And sometimes it takes some scrambling,
[01:07:12.860 --> 01:07:16.180]   but we work backwards to make things fit.
[01:07:16.180 --> 01:07:18.380]   I mean, that's why, for example,
[01:07:18.380 --> 01:07:19.620]   now that we're going down to one episode,
[01:07:19.620 --> 01:07:20.740]   we had to go down to one episode
[01:07:20.740 --> 01:07:22.940]   to spend more time thinking about the show
[01:07:22.940 --> 01:07:25.700]   because the fixed schedule productivity
[01:07:25.700 --> 01:07:27.140]   is secondary fixed schedule productivity.
[01:07:27.140 --> 01:07:29.220]   I'm running here, it says half day for the show.
[01:07:29.220 --> 01:07:30.620]   So if we want to spend more time prepping
[01:07:30.620 --> 01:07:32.700]   and record two shows, we would break that boundary.
[01:07:32.700 --> 01:07:33.780]   So we had to change something else.
[01:07:33.780 --> 01:07:35.340]   So it forced to change.
[01:07:35.340 --> 01:07:38.060]   So this is one of my oldest ideas.
[01:07:38.060 --> 01:07:41.300]   I wrote about this way early in my blog.
[01:07:41.300 --> 01:07:45.100]   I'm thinking back 2007, 2008,
[01:07:45.100 --> 01:07:47.540]   I was writing about this idea.
[01:07:48.540 --> 01:07:53.540]   Now this works for a few reasons.
[01:07:53.540 --> 01:07:57.380]   One is it's, you can consider it a meta productivity
[01:07:57.380 --> 01:07:59.820]   strategy because it is a high level commitment
[01:07:59.820 --> 01:08:04.100]   that's going to induce a lot of low level specific changes.
[01:08:04.100 --> 01:08:07.140]   When you have the boundary, you have to hit.
[01:08:07.140 --> 01:08:12.140]   To hit that boundary, you end up having to do
[01:08:12.140 --> 01:08:15.020]   lots of evidence-based custom fit tactics
[01:08:15.020 --> 01:08:17.980]   that are custom fit to your particular life.
[01:08:17.980 --> 01:08:19.700]   You quickly sort out the stuff that works,
[01:08:19.700 --> 01:08:20.540]   that doesn't work.
[01:08:20.540 --> 01:08:24.460]   It really is a great way of inducing a lot of small changes.
[01:08:24.460 --> 01:08:26.620]   If instead you try to come up with a lot of ideas
[01:08:26.620 --> 01:08:28.580]   from scratch of what you think will help you
[01:08:28.580 --> 01:08:29.940]   manage your time or be more productive,
[01:08:29.940 --> 01:08:30.940]   you're just throwing darts.
[01:08:30.940 --> 01:08:34.420]   So fixed schedule productivity is a meta productivity habit
[01:08:34.420 --> 01:08:37.780]   and it helps lead to good low level tactics.
[01:08:37.780 --> 01:08:39.060]   It's also a forcing function
[01:08:39.060 --> 01:08:40.820]   to help keep your load sustainable.
[01:08:40.820 --> 01:08:43.860]   So it'll enforce better productivity ideas
[01:08:43.860 --> 01:08:45.940]   in the low level, it'll also lead you to say no to more,
[01:08:45.940 --> 01:08:47.660]   get a better sense of what your load is.
[01:08:47.660 --> 01:08:50.740]   When you have these limits, that pushes back
[01:08:50.740 --> 01:08:52.540]   and it keeps you or makes it harder
[01:08:52.540 --> 01:08:53.900]   for you to overload yourself,
[01:08:53.900 --> 01:08:56.400]   which is likely to lead to burnout.
[01:08:56.400 --> 01:09:00.620]   It also helps you better take advantage of seasonality.
[01:09:00.620 --> 01:09:04.180]   So you go through a period where maybe things are lighter,
[01:09:04.180 --> 01:09:05.420]   you're in between jobs,
[01:09:05.420 --> 01:09:07.260]   you're in a quiet season of the job.
[01:09:07.260 --> 01:09:11.020]   With fixed schedule productivity, if you're used to this,
[01:09:11.020 --> 01:09:12.820]   you can take advantage of that situation
[01:09:12.820 --> 01:09:15.860]   by collapsing in your fixed schedule.
[01:09:15.860 --> 01:09:18.660]   Now that you could fit your work in less time
[01:09:18.660 --> 01:09:19.500]   and you get used to fit in the less time
[01:09:19.500 --> 01:09:22.100]   and you can take advantage of the new time that frees up.
[01:09:22.100 --> 01:09:24.260]   It's like me in the summer.
[01:09:24.260 --> 01:09:25.740]   I have less demands because I don't work
[01:09:25.740 --> 01:09:28.580]   for Georgetown in the summer, I'm on my own dime.
[01:09:28.580 --> 01:09:30.580]   So I can bring in my working schedule
[01:09:30.580 --> 01:09:32.740]   and I do to be much smaller.
[01:09:32.740 --> 01:09:34.940]   And because I'm used to fixed schedule productivity,
[01:09:34.940 --> 01:09:36.260]   I do what I need to fit it in there
[01:09:36.260 --> 01:09:37.340]   and I'm able to take advantage
[01:09:37.340 --> 01:09:38.660]   of the extra flexibility in summer.
[01:09:38.660 --> 01:09:41.020]   It is so easy without that to just fill in your time
[01:09:41.020 --> 01:09:42.620]   because there's always more things possible
[01:09:42.620 --> 01:09:45.500]   for you to do, then you have time to accomplish.
[01:09:45.500 --> 01:09:48.380]   So without these boundaries, it is going to fill up.
[01:09:48.380 --> 01:09:51.380]   So here are some innovations that have come out
[01:09:51.380 --> 01:09:54.420]   of my own commitment to fixed schedule productivity.
[01:09:54.420 --> 01:09:57.460]   It's where all of my multi-scale planning ideas were formed.
[01:09:57.460 --> 01:10:00.220]   Semester planning, weekly planning,
[01:10:00.220 --> 01:10:01.820]   daily time block planning.
[01:10:01.820 --> 01:10:04.620]   All of that was forged in the fires
[01:10:04.620 --> 01:10:05.860]   of fixed schedule productivity.
[01:10:05.860 --> 01:10:10.580]   How do I make my 75 jobs fit in the small time I work?
[01:10:10.580 --> 01:10:12.060]   For me, it's roughly nine to five,
[01:10:12.060 --> 01:10:13.740]   nine to 5.30 and Sunday mornings
[01:10:13.740 --> 01:10:16.500]   is roughly my main work blocks.
[01:10:16.500 --> 01:10:18.380]   That's where that came out of is because that's what allowed
[01:10:18.380 --> 01:10:20.980]   me to actually fit a reasonable amount of work in there.
[01:10:20.980 --> 01:10:24.660]   Ruthless quotas and reduction in what's on my plate.
[01:10:24.660 --> 01:10:26.500]   Fixed schedule productivity pushes that for me.
[01:10:26.500 --> 01:10:29.380]   And I think it helps keep me away from burnout.
[01:10:29.380 --> 01:10:30.420]   If I can't make it fit,
[01:10:30.420 --> 01:10:33.140]   even with my good productivity systems, I have to quit.
[01:10:33.140 --> 01:10:34.900]   I can't do this, I need to step away from this,
[01:10:34.900 --> 01:10:36.540]   I need to take a break from that.
[01:10:36.540 --> 01:10:39.100]   I'm much more likely to have a sustainable load of work
[01:10:39.100 --> 01:10:42.500]   because I have this forcing function of it has to fit
[01:10:42.500 --> 01:10:43.780]   during these hours.
[01:10:43.780 --> 01:10:46.700]   It also helped me lead to more efficient processes.
[01:10:46.700 --> 01:10:49.380]   The type of things I talk about in my book,
[01:10:49.380 --> 01:10:53.340]   "A World Without Email" come from the demands of,
[01:10:53.340 --> 01:10:57.580]   I can't just be going back and forth with you all day
[01:10:57.580 --> 01:11:01.580]   on email because my time is really precious.
[01:11:01.580 --> 01:11:03.100]   I have to get a lot in here.
[01:11:03.100 --> 01:11:04.620]   So I have to stop work at 5.30.
[01:11:04.620 --> 01:11:06.300]   So we got to figure out a better way to collaborate.
[01:11:06.300 --> 01:11:10.220]   Again, this back pressure from these boundaries
[01:11:10.220 --> 01:11:11.860]   really causes a lot of good.
[01:11:11.860 --> 01:11:15.420]   All right, so I'm a big fan in working backwards
[01:11:15.420 --> 01:11:18.620]   from the hours, the secondary and tertiary positive
[01:11:18.620 --> 01:11:22.220]   and effects it has on your life can be quite big.
[01:11:22.220 --> 01:11:25.140]   You know, Jesse, I'll have to say,
[01:11:25.140 --> 01:11:29.500]   fixed schedule productivity is at the source
[01:11:29.500 --> 01:11:31.940]   of the amusement and confusion I often get.
[01:11:31.940 --> 01:11:33.340]   And we talk about this sometimes on the show,
[01:11:33.340 --> 01:11:35.940]   but I'm very commonly,
[01:11:35.940 --> 01:11:37.780]   there's a very common critique of me.
[01:11:37.780 --> 01:11:40.140]   When people hear about like the work I do
[01:11:40.140 --> 01:11:41.740]   or the type of things I talk about,
[01:11:41.740 --> 01:11:42.940]   the very common critique where they say,
[01:11:42.940 --> 01:11:45.940]   well, you know, you can do that probably
[01:11:45.940 --> 01:11:47.780]   because of your wife.
[01:11:47.780 --> 01:11:51.820]   There must be some sort of like unusual support,
[01:11:51.820 --> 01:11:54.380]   maybe someone else having to sacrifice
[01:11:54.380 --> 01:11:57.260]   in order for you to work on these different things
[01:11:57.260 --> 01:11:59.900]   and you'll do this deep work.
[01:11:59.900 --> 01:12:01.500]   So this comes up a lot.
[01:12:01.500 --> 01:12:02.780]   Shout out to my friend, Scott,
[01:12:02.780 --> 01:12:05.100]   who likes to collect these references.
[01:12:05.100 --> 01:12:07.180]   There was one this week, I forgot who it was,
[01:12:07.180 --> 01:12:08.220]   but someone on a podcast,
[01:12:08.220 --> 01:12:11.100]   he had collected a new example of someone saying like,
[01:12:11.100 --> 01:12:12.220]   yeah, I like this stuff, but you know,
[01:12:12.220 --> 01:12:14.380]   I think the real hero is probably his wife.
[01:12:14.380 --> 01:12:17.780]   The reason why it always baffles me in the moment
[01:12:17.780 --> 01:12:21.580]   is because since I've been a working adult,
[01:12:21.580 --> 01:12:23.900]   practice fixed schedule productivity,
[01:12:23.900 --> 01:12:26.820]   my work hours are just normal standard,
[01:12:26.820 --> 01:12:29.380]   I'm a government worker, nine to five style work hours,
[01:12:29.380 --> 01:12:31.380]   right, like I just work the same work hours
[01:12:31.380 --> 01:12:33.700]   as like any other normal job.
[01:12:33.700 --> 01:12:36.260]   So it's not like there's some weird Herculean support
[01:12:36.260 --> 01:12:39.180]   I need from other people beyond just the standard
[01:12:39.180 --> 01:12:41.580]   like thing that everyone who works has to do,
[01:12:41.580 --> 01:12:45.540]   like my kids need to be in school and that type of thing.
[01:12:45.540 --> 01:12:47.860]   So I'm always baffled.
[01:12:47.860 --> 01:12:48.700]   It's like, well, what do you mean?
[01:12:48.700 --> 01:12:50.740]   Like I just, I work actually probably less hours
[01:12:50.740 --> 01:12:52.220]   than most people I know.
[01:12:52.220 --> 01:12:55.620]   And what does the fact that during my normal working hours,
[01:12:55.620 --> 01:12:57.460]   I'm very focused, I don't see what that has to do
[01:12:57.460 --> 01:12:58.740]   with needing external support.
[01:12:58.740 --> 01:13:02.660]   But the reason why I think people fall back on that critique
[01:13:02.660 --> 01:13:05.420]   is that most people don't do fixed schedule productivity.
[01:13:05.420 --> 01:13:07.340]   And when you don't do fixed schedule productivity,
[01:13:07.340 --> 01:13:10.140]   the assumption is because it's what you're used to.
[01:13:10.140 --> 01:13:11.980]   It's more things means more time.
[01:13:11.980 --> 01:13:14.180]   And if you're doing like a kind of like an impressive thing
[01:13:14.180 --> 01:13:15.240]   or an impressive number of things,
[01:13:15.240 --> 01:13:17.760]   there must be some impressive time commitment.
[01:13:17.760 --> 01:13:20.620]   You must be Einstein in the 1920s,
[01:13:20.620 --> 01:13:23.580]   disappearing till your office till three in the morning.
[01:13:23.580 --> 01:13:25.200]   But the thing is with fixed schedule productivity,
[01:13:25.200 --> 01:13:26.040]   it does work.
[01:13:26.040 --> 01:13:28.500]   You can actually get a lot of interesting stuff happening
[01:13:28.500 --> 01:13:30.660]   in a very normal, reasonable amount of time
[01:13:30.660 --> 01:13:34.060]   that does not require unusual support,
[01:13:34.060 --> 01:13:36.780]   does not require unusually long working hours.
[01:13:36.780 --> 01:13:38.520]   Fixed schedule productivity does really work
[01:13:38.520 --> 01:13:41.240]   because that back pressure gets you to focus,
[01:13:41.240 --> 01:13:42.940]   it gets you structured, it gets you organized,
[01:13:42.940 --> 01:13:44.220]   it gets you to essentialize.
[01:13:44.220 --> 01:13:46.440]   It really is like a tonic,
[01:13:46.440 --> 01:13:48.220]   really is like a tonic for productivity.
[01:13:48.220 --> 01:13:50.980]   - Do you remember what the podcast replaced
[01:13:50.980 --> 01:13:52.540]   before you did the podcast?
[01:13:52.540 --> 01:13:54.700]   Like that half day, was it just writing or?
[01:13:54.700 --> 01:13:57.740]   - It's a good question because I started it
[01:13:57.740 --> 01:14:00.780]   during the early days of the pandemic.
[01:14:00.780 --> 01:14:02.540]   - Oh, so you weren't going to Georgetown and stuff.
[01:14:02.540 --> 01:14:03.820]   - I wasn't going to Georgetown.
[01:14:03.820 --> 01:14:05.460]   So I didn't, so it's a good point
[01:14:05.460 --> 01:14:07.900]   'cause I didn't have the fixed schedule
[01:14:07.900 --> 01:14:09.060]   around the podcast at first
[01:14:09.060 --> 01:14:12.460]   because I started it during the summer of 2020.
[01:14:12.460 --> 01:14:14.180]   So I had a lot of time.
[01:14:14.180 --> 01:14:16.360]   And we went into the fall, still had a lot of time.
[01:14:16.360 --> 01:14:19.740]   Georgetown was remote and so I wasn't going in.
[01:14:19.740 --> 01:14:24.660]   And then I was on leave that spring,
[01:14:24.660 --> 01:14:25.500]   like my book came out.
[01:14:25.500 --> 01:14:27.100]   So like I had a lot of time.
[01:14:27.100 --> 01:14:31.340]   The half day came in once we got back to the normal schedule
[01:14:31.340 --> 01:14:32.780]   which was like this fall.
[01:14:32.780 --> 01:14:34.180]   Oh, I got to go in, I got to teach,
[01:14:34.180 --> 01:14:35.460]   I'm on committees again.
[01:14:35.460 --> 01:14:36.300]   And that's when I was like, okay,
[01:14:36.300 --> 01:14:39.680]   I have to corral this more.
[01:14:39.680 --> 01:14:43.380]   So yeah, it's a half day of time.
[01:14:43.380 --> 01:14:44.620]   There's a lot of things I could easily spend
[01:14:44.620 --> 01:14:45.460]   a half day of time on.
[01:14:45.460 --> 01:14:48.060]   I think it honestly is, I went on,
[01:14:48.060 --> 01:14:49.700]   after my last book launch, I'm not, as you know,
[01:14:49.700 --> 01:14:52.380]   I'm not doing a bunch of interviews right now.
[01:14:52.380 --> 01:14:53.940]   'Cause I'm not, I'm thinking about all the time
[01:14:53.940 --> 01:14:56.260]   I would be doing podcast interviews or reading interviews.
[01:14:56.260 --> 01:14:57.120]   I do a little bit.
[01:14:57.120 --> 01:15:02.700]   I was on, when you were away last week in Canada,
[01:15:02.700 --> 01:15:08.580]   their main morning radio show on CBC, The Current.
[01:15:08.580 --> 01:15:11.980]   So I did a 30 minute, so I do a few things.
[01:15:11.980 --> 01:15:13.660]   I do a few things.
[01:15:13.660 --> 01:15:14.980]   That's probably where a lot of the time comes from,
[01:15:14.980 --> 01:15:18.020]   is I focused in my writing life to the podcast
[01:15:18.020 --> 01:15:20.460]   as a half day and then on my book and article writing.
[01:15:20.460 --> 01:15:21.700]   - Yep.
[01:15:21.700 --> 01:15:22.540]   - Yep.
[01:15:22.540 --> 01:15:26.180]   All right, so fixed sale productivity, I do recommend it.
[01:15:27.020 --> 01:15:32.020]   Speaking of recommendations, I also recommend our sponsor.
[01:15:32.020 --> 01:15:35.860]   Again, like I like to say, Jesse,
[01:15:35.860 --> 01:15:38.320]   Professional Transitions, it's what I'm about.
[01:15:38.320 --> 01:15:44.860]   Novo, now this is actually relevant to us.
[01:15:44.860 --> 01:15:48.740]   I'm going through a lot of professionalization
[01:15:48.740 --> 01:15:50.340]   of our business here.
[01:15:50.340 --> 01:15:51.620]   I don't know if I've told you about this, Jesse,
[01:15:51.620 --> 01:15:55.160]   but you know, I'm finally forming a company
[01:15:55.160 --> 01:15:57.700]   and with a name and et cetera,
[01:15:57.700 --> 01:15:59.060]   there's a lot of professionalizing
[01:15:59.060 --> 01:16:00.260]   that's actually happening around
[01:16:00.260 --> 01:16:02.940]   our little writing business here.
[01:16:02.940 --> 01:16:05.660]   So I'm exactly the type of person
[01:16:05.660 --> 01:16:08.440]   who'd be interested in Novo,
[01:16:08.440 --> 01:16:13.440]   which provides powerfully simple business checking accounts.
[01:16:13.440 --> 01:16:16.700]   So unlike a traditional banking model,
[01:16:16.700 --> 01:16:19.020]   Novo has no minimum balances, no transaction limits,
[01:16:19.020 --> 01:16:21.140]   no hidden fees, but more importantly,
[01:16:21.140 --> 01:16:24.440]   it is customized to the modern business,
[01:16:24.440 --> 01:16:27.420]   especially small businesses in the digital age.
[01:16:27.420 --> 01:16:29.280]   It has seamless integrations, for example,
[01:16:29.280 --> 01:16:32.860]   into Stripe or Shopify or QuickBooks.
[01:16:32.860 --> 01:16:38.980]   So it's a future-focused online business checking
[01:16:38.980 --> 01:16:41.760]   made for the type of businesses like the business
[01:16:41.760 --> 01:16:45.680]   we are forming here that I still need a name for.
[01:16:45.680 --> 01:16:50.080]   Thinking about Jesse Scarecrow Incorporated.
[01:16:50.080 --> 01:16:52.700]   We'll see if that's been taken.
[01:16:53.980 --> 01:16:55.140]   But it makes a lot of sense.
[01:16:55.140 --> 01:16:56.800]   I think it's a company that makes a lot of sense.
[01:16:56.800 --> 01:17:01.700]   So it's a service that gives you simple business checking
[01:17:01.700 --> 01:17:05.340]   for the type of businesses that people work with today.
[01:17:05.340 --> 01:17:09.700]   So if you sign up for Novo for free,
[01:17:09.700 --> 01:17:12.220]   you will join a community of over 150,000
[01:17:12.220 --> 01:17:14.540]   fearless small businesses who have found
[01:17:14.540 --> 01:17:16.300]   the customizable business checking solution
[01:17:16.300 --> 01:17:21.300]   that admires and supports the brave.
[01:17:21.300 --> 01:17:23.300]   So sign up for your free business checking account
[01:17:23.300 --> 01:17:28.300]   right now at novo.co/deep.
[01:17:28.300 --> 01:17:32.780]   If you do that, as a listener of Deep Questions,
[01:17:32.780 --> 01:17:37.100]   you will get access to over $5,000 in perks and discounts.
[01:17:37.100 --> 01:17:42.100]   So go to novo.co/deep to sign up for free.
[01:17:42.100 --> 01:17:49.780]   novo.co/deep.
[01:17:49.780 --> 01:17:53.020]   Novo Platform Incorporated is a fintech, not a bank,
[01:17:53.020 --> 01:17:55.220]   banking services provided by Middlesex Federal Savings,
[01:17:55.220 --> 01:17:59.960]   FAA member FDIC, terms and conditions apply.
[01:17:59.960 --> 01:18:05.420]   I gotta work on my terms and conditions voice.
[01:18:05.420 --> 01:18:07.500]   This is my first time getting to do the sort of like
[01:18:07.500 --> 01:18:10.740]   radio style, like in the legally required disclaimer
[01:18:10.740 --> 01:18:12.320]   and in the commercial.
[01:18:12.320 --> 01:18:14.900]   I think I need a quicker, deeper voice.
[01:18:14.900 --> 01:18:17.860]   I also wanna talk briefly about Blinkist,
[01:18:17.860 --> 01:18:20.220]   long time friend of the show.
[01:18:20.220 --> 01:18:22.220]   Like if you listen to Deep Questions, you know Blinkist,
[01:18:22.220 --> 01:18:24.620]   you know I am a fan.
[01:18:24.620 --> 01:18:27.620]   It is a subscription service that gives you access
[01:18:27.620 --> 01:18:32.140]   to short 15 minute summaries of thousands,
[01:18:32.140 --> 01:18:34.580]   the most important bestselling nonfiction books.
[01:18:34.580 --> 01:18:38.020]   You can read the summaries or listen to them.
[01:18:38.020 --> 01:18:40.660]   They're called Blinks and quickly figure out
[01:18:40.660 --> 01:18:43.940]   the big ideas from the books.
[01:18:43.940 --> 01:18:47.220]   I think this is a great way to figure out what books to buy
[01:18:47.220 --> 01:18:48.820]   and which books aren't worth it.
[01:18:49.900 --> 01:18:52.620]   Let's say you're curious in "Homo Deus"
[01:18:52.620 --> 01:18:55.700]   or "21 Lessons from the 21st Century" by Yuval Harari.
[01:18:55.700 --> 01:18:57.580]   You wanna know which of those to read.
[01:18:57.580 --> 01:18:58.900]   Listen to or read the Blink.
[01:18:58.900 --> 01:19:00.740]   Big ideas, 15 minutes to make it real clear
[01:19:00.740 --> 01:19:03.260]   which one you're going to prefer.
[01:19:03.260 --> 01:19:04.900]   So it is a great tool for anyone
[01:19:04.900 --> 01:19:07.580]   who embraces the reading life.
[01:19:07.580 --> 01:19:08.660]   Blinkist helps you figure out
[01:19:08.660 --> 01:19:10.580]   what's going on in these books.
[01:19:10.580 --> 01:19:12.200]   Right now Blinkist has a special offer
[01:19:12.200 --> 01:19:13.440]   just for our audience.
[01:19:13.440 --> 01:19:19.460]   Go to blinkist.com/deep to start your free seven day trial
[01:19:19.460 --> 01:19:21.660]   and get 25% off a Blinkist premium membership.
[01:19:21.660 --> 01:19:24.840]   That's Blinkist spelled B-L-I-N-K-I-S-T.
[01:19:24.840 --> 01:19:29.740]   Blinkist.com/deep to get 25% off any seven day free trial.
[01:19:29.740 --> 01:19:33.020]   Blinkist.com/deep.
[01:19:33.020 --> 01:19:39.000]   All right, I'm thinking, Jesse, we should try another call.
[01:19:39.000 --> 01:19:42.160]   - Yep, so we got a call about your thoughts
[01:19:42.160 --> 01:19:44.860]   on how to structure the ideal world to teach
[01:19:44.860 --> 01:19:47.620]   in a university without all the admin work.
[01:19:47.620 --> 01:19:48.460]   - Ooh, I like it.
[01:19:49.140 --> 01:19:51.460]   - Hello, Cal, greetings from Brussels.
[01:19:51.460 --> 01:19:56.460]   My name is Irab and I'm doing a postdoc in computer science.
[01:19:56.460 --> 01:19:59.660]   In your podcast, you sometimes mention
[01:19:59.660 --> 01:20:03.740]   that a modern professor has to do a lot of work
[01:20:03.740 --> 01:20:07.660]   not related to the main job.
[01:20:07.660 --> 01:20:11.100]   Things like participating in different committees
[01:20:11.100 --> 01:20:16.100]   related to teaching, administrating of the university
[01:20:16.260 --> 01:20:21.260]   and more, but someone has to do these things, right?
[01:20:21.260 --> 01:20:27.780]   So what are your thoughts on how university
[01:20:27.780 --> 01:20:29.180]   could be structured?
[01:20:29.180 --> 01:20:33.780]   What is the role of professor there
[01:20:33.780 --> 01:20:38.780]   and other professors specializing in teaching
[01:20:38.780 --> 01:20:42.860]   and those specializing more in research?
[01:20:42.860 --> 01:20:46.620]   Who should develop educational programs?
[01:20:46.620 --> 01:20:49.980]   Shall professor write and compete for grants
[01:20:49.980 --> 01:20:54.060]   or funding money shall be more available?
[01:20:54.060 --> 01:20:57.700]   And who should evaluate those grant proposals?
[01:20:57.700 --> 01:21:02.700]   Professors again, eager to know your thoughts
[01:21:02.700 --> 01:21:07.580]   on things, how to optimize our university system.
[01:21:07.580 --> 01:21:08.420]   Thank you.
[01:21:08.420 --> 01:21:11.020]   - Well, good question.
[01:21:11.020 --> 01:21:13.020]   It's something I think about a lot.
[01:21:13.020 --> 01:21:18.020]   It's on my mind now as the 2021, 2022 academic year
[01:21:18.020 --> 01:21:22.860]   comes to a close, definitely a busy one for me.
[01:21:22.860 --> 01:21:25.260]   I think people will say I'm a reasonable guy.
[01:21:25.260 --> 01:21:29.260]   My proposals for improving the university,
[01:21:29.260 --> 01:21:32.260]   I think are straightforward and practical.
[01:21:32.260 --> 01:21:36.420]   Number one, we need a $2 million a year minimum salary.
[01:21:36.420 --> 01:21:39.420]   Let's just be, again, just reasonable practical advice here.
[01:21:39.420 --> 01:21:44.420]   Number two, I'm thinking one class per two year period
[01:21:44.420 --> 01:21:46.900]   is probably about right.
[01:21:46.900 --> 01:21:48.740]   We should probably do like a one semester
[01:21:48.740 --> 01:21:50.780]   on four semester sabbatical,
[01:21:50.780 --> 01:21:52.980]   one semester on four semester sabbatical.
[01:21:52.980 --> 01:21:55.460]   I think we did those three reasonable things
[01:21:55.460 --> 01:21:59.700]   and we can all agree that that'd be good
[01:21:59.700 --> 01:22:00.540]   for everyone involved.
[01:22:00.540 --> 01:22:03.020]   I'm not quite sure why people aren't doing this.
[01:22:03.020 --> 01:22:06.940]   I'm gonna get yelled at by the Dean again, Jesse,
[01:22:06.940 --> 01:22:08.700]   if I'm not careful.
[01:22:09.540 --> 01:22:11.180]   I'm not careful.
[01:22:11.180 --> 01:22:13.820]   No, okay, I do have some more serious thoughts about it.
[01:22:13.820 --> 01:22:14.980]   There's a lot you had in there,
[01:22:14.980 --> 01:22:17.020]   so I'm gonna pick it apart a little bit
[01:22:17.020 --> 01:22:20.180]   and kind of focus on the areas of academic life
[01:22:20.180 --> 01:22:22.500]   that I have thought about.
[01:22:22.500 --> 01:22:24.900]   So there's two things I think for sure.
[01:22:24.900 --> 01:22:27.660]   A, I'm a big believer in service budgets.
[01:22:27.660 --> 01:22:31.980]   It's an idea I proposed in that article I wrote years ago
[01:22:31.980 --> 01:22:34.060]   for the Chronicle of Higher Education.
[01:22:34.060 --> 01:22:37.660]   It was called, "Is Email-Making Professors Stupid?"
[01:22:38.540 --> 01:22:41.020]   And in that, I argued that we need to be less haphazard
[01:22:41.020 --> 01:22:42.020]   about service.
[01:22:42.020 --> 01:22:44.980]   Service is important.
[01:22:44.980 --> 01:22:46.100]   So for those who don't know,
[01:22:46.100 --> 01:22:49.340]   professors spend some of their time in what's called service,
[01:22:49.340 --> 01:22:51.100]   either to the department or to the university
[01:22:51.100 --> 01:22:52.980]   or the broader academic community.
[01:22:52.980 --> 01:22:55.820]   And it's important for universities to run.
[01:22:55.820 --> 01:22:58.540]   We need professors to sit on tenure committees.
[01:22:58.540 --> 01:23:03.180]   We need professors to be part of the faculty governance.
[01:23:03.180 --> 01:23:05.780]   We need professors to work on, let's say,
[01:23:05.780 --> 01:23:07.740]   overhauling the curriculum for a department.
[01:23:07.740 --> 01:23:10.900]   So part of what professors have to do is service
[01:23:10.900 --> 01:23:12.900]   outside of their core activities,
[01:23:12.900 --> 01:23:15.180]   but it shouldn't be haphazard.
[01:23:15.180 --> 01:23:16.020]   We should figure out,
[01:23:16.020 --> 01:23:18.340]   here's how many hours you should be doing.
[01:23:18.340 --> 01:23:19.980]   It should be negotiated.
[01:23:19.980 --> 01:23:22.780]   It should be tracked, and you can't go beyond it.
[01:23:22.780 --> 01:23:24.620]   People can't put work on your plate beyond it.
[01:23:24.620 --> 01:23:25.460]   If they want to,
[01:23:25.460 --> 01:23:28.220]   there has to be a special sign-off by your dean.
[01:23:28.220 --> 01:23:31.980]   So let's get more transparent about service
[01:23:31.980 --> 01:23:33.660]   so we can keep it both more equitable,
[01:23:33.660 --> 01:23:36.660]   so you don't have nice people doing a lot more than jerks,
[01:23:36.660 --> 01:23:38.260]   and we can be more reasonable
[01:23:38.260 --> 01:23:40.860]   about how much levels people can actually hold.
[01:23:40.860 --> 01:23:43.380]   I think that would create back pressure
[01:23:43.380 --> 01:23:46.620]   that would then maybe call out the amount of service demands
[01:23:46.620 --> 01:23:47.740]   pulling attention from people
[01:23:47.740 --> 01:23:50.860]   when the time is actually a scarce resource.
[01:23:50.860 --> 01:23:53.220]   I think the service commitments that survive
[01:23:53.220 --> 01:23:56.180]   will be of more importance.
[01:23:56.180 --> 01:24:00.100]   Also, we need to focus more on intellectual specialization.
[01:24:00.100 --> 01:24:01.820]   That's actually a term of art
[01:24:01.820 --> 01:24:05.820]   from people that study productivity in the business sector.
[01:24:06.740 --> 01:24:08.940]   So intellectual specialization says
[01:24:08.940 --> 01:24:11.140]   the people you hire, you want them to spend more time
[01:24:11.140 --> 01:24:13.620]   focusing on the specific skills for which you hired them,
[01:24:13.620 --> 01:24:18.300]   the specific skills that create value for your organization
[01:24:18.300 --> 01:24:21.620]   and less time on skills that don't.
[01:24:21.620 --> 01:24:24.420]   So in the life of professors,
[01:24:24.420 --> 01:24:27.460]   what matters is service, teaching, and research.
[01:24:27.460 --> 01:24:29.060]   So we just talked about service.
[01:24:29.060 --> 01:24:32.100]   Then you have teaching and research.
[01:24:32.100 --> 01:24:34.420]   The thing that pulls a lot of professors' time away
[01:24:34.420 --> 01:24:36.900]   is administrative details.
[01:24:36.900 --> 01:24:38.740]   And so there needs to be a real focus, I believe,
[01:24:38.740 --> 01:24:42.300]   in the university to minimize the amount of time
[01:24:42.300 --> 01:24:44.140]   professors need to spend on administrative work.
[01:24:44.140 --> 01:24:46.860]   Now, you just said, well, someone has to do the work,
[01:24:46.860 --> 01:24:47.700]   and that's true,
[01:24:47.700 --> 01:24:49.700]   but that's true about everything at the university.
[01:24:49.700 --> 01:24:52.260]   Someone has to fix the pipes when they leak.
[01:24:52.260 --> 01:24:54.100]   Someone has to fix the HVAC when it doesn't work.
[01:24:54.100 --> 01:24:57.180]   Someone has to actually do the landscaping in the spring.
[01:24:57.180 --> 01:24:59.500]   Someone has to actually run the computer system
[01:24:59.500 --> 01:25:02.220]   that allows the students to register for those courses.
[01:25:02.220 --> 01:25:03.460]   In other words, most of the stuff
[01:25:03.460 --> 01:25:05.420]   that happens on the university,
[01:25:05.420 --> 01:25:06.820]   there's non-professors who do it.
[01:25:06.820 --> 01:25:08.740]   It's just a matter of where we wanna draw that line.
[01:25:08.740 --> 01:25:11.460]   And I think a lot of what happened at some point
[01:25:11.460 --> 01:25:14.420]   is computer systems meant that professors
[01:25:14.420 --> 01:25:16.740]   could technically actually accomplish things
[01:25:16.740 --> 01:25:18.700]   that before would have been too hard
[01:25:18.700 --> 01:25:20.660]   or cumbersome for them to do.
[01:25:20.660 --> 01:25:23.500]   So more work got put on the professors
[01:25:23.500 --> 01:25:26.820]   because in the moment, it seemed like it was cheaper,
[01:25:26.820 --> 01:25:28.620]   and we could have less support staff.
[01:25:28.620 --> 01:25:30.900]   We have this nice, weird intranet
[01:25:31.820 --> 01:25:33.820]   that the professors can go through
[01:25:33.820 --> 01:25:35.500]   these weird arcane interfaces
[01:25:35.500 --> 01:25:37.140]   to enter the reimbursement request.
[01:25:37.140 --> 01:25:40.420]   That allows us to not have this full-time person
[01:25:40.420 --> 01:25:43.820]   that helps actually process reimbursement request
[01:25:43.820 --> 01:25:44.660]   or what have you, right?
[01:25:44.660 --> 01:25:45.500]   So it's short-sighted.
[01:25:45.500 --> 01:25:47.460]   In the short term, like, hey, we can fire this person.
[01:25:47.460 --> 01:25:48.580]   Yay, we've saved money.
[01:25:48.580 --> 01:25:51.420]   But in the long term,
[01:25:51.420 --> 01:25:54.060]   your professors are miserable and half as productive.
[01:25:54.060 --> 01:25:55.260]   So is that really what you're looking for?
[01:25:55.260 --> 01:25:57.860]   So I think we have to focus on intellectual specialization.
[01:25:57.860 --> 01:25:59.620]   Most of that is more admin support.
[01:25:59.620 --> 01:26:01.860]   I think universities do invest much more
[01:26:01.860 --> 01:26:03.180]   in administrative support.
[01:26:03.180 --> 01:26:07.300]   That is what enables professors to do
[01:26:07.300 --> 01:26:09.900]   what you actually have hired professors to do.
[01:26:09.900 --> 01:26:13.100]   Now, I have some more far-out ideas I've talked about
[01:26:13.100 --> 01:26:15.100]   before I'll just mention real quick.
[01:26:15.100 --> 01:26:18.700]   These are blue sky ideas that I don't think they'll happen,
[01:26:18.700 --> 01:26:20.540]   but it'd be kind of cool if they did.
[01:26:20.540 --> 01:26:25.060]   One, I like the idea of broadcast digest.
[01:26:25.060 --> 01:26:29.020]   I can't tell you how much information arrives in my inbox.
[01:26:29.900 --> 01:26:33.220]   At Georgetown from various organizations
[01:26:33.220 --> 01:26:36.740]   and administrators, announcements for this and for that
[01:26:36.740 --> 01:26:38.620]   and this event and this new policy.
[01:26:38.620 --> 01:26:40.140]   And this is what's happening now with COVID.
[01:26:40.140 --> 01:26:43.420]   And a big university just has dozens and dozens
[01:26:43.420 --> 01:26:44.780]   and dozens of different organizations
[01:26:44.780 --> 01:26:47.660]   that might wanna actually send information to,
[01:26:47.660 --> 01:26:49.340]   let's say faculty.
[01:26:49.340 --> 01:26:51.700]   They all can just on their own, just send out messages.
[01:26:51.700 --> 01:26:53.980]   I would love a broadcast digest model
[01:26:53.980 --> 01:26:56.580]   where like all the information you need for the week
[01:26:56.580 --> 01:26:58.620]   comes to editors who put it together
[01:26:58.620 --> 01:27:00.580]   into basically like a broadsheet newspaper.
[01:27:00.580 --> 01:27:02.660]   Like here's news and different types of categories
[01:27:02.660 --> 01:27:04.340]   and here's the things that require requests
[01:27:04.340 --> 01:27:06.020]   and here's all the links for the information.
[01:27:06.020 --> 01:27:08.700]   And this thing gets delivered to you once a week
[01:27:08.700 --> 01:27:10.220]   and you can sit there and you can browse it.
[01:27:10.220 --> 01:27:11.340]   What's relevant, what's not,
[01:27:11.340 --> 01:27:12.940]   what do I need to follow up on?
[01:27:12.940 --> 01:27:16.380]   It seems small, but it really changes the cognitive footprint
[01:27:16.380 --> 01:27:17.460]   of all those requests.
[01:27:17.460 --> 01:27:22.820]   Another far-out idea I had was all interactive admin.
[01:27:22.820 --> 01:27:25.300]   So administrative tasks that require professors
[01:27:25.300 --> 01:27:27.580]   to sort of give information or fill something out
[01:27:27.580 --> 01:27:31.580]   or answer questions, have a two-hour session
[01:27:31.580 --> 01:27:35.540]   once a week for each professor.
[01:27:35.540 --> 01:27:38.460]   And a bunch of professors can do this at the same time.
[01:27:38.460 --> 01:27:40.620]   And whatever admin is working with you
[01:27:40.620 --> 01:27:43.140]   or that particular research group comes in
[01:27:43.140 --> 01:27:46.460]   and just like a chief of staff or the president says,
[01:27:46.460 --> 01:27:49.060]   "All right, I have a stack of things we need to get through
[01:27:49.060 --> 01:27:51.060]   "that's gonna require some interaction from you.
[01:27:51.060 --> 01:27:52.380]   "And I'm just gonna ask you questions
[01:27:52.380 --> 01:27:54.140]   "and get from you the information."
[01:27:54.140 --> 01:27:56.140]   So it's human to human interaction.
[01:27:56.140 --> 01:27:58.780]   All right, so you need to fill out this form.
[01:27:58.780 --> 01:28:00.060]   So I'm just gonna ask you some questions.
[01:28:00.060 --> 01:28:00.900]   What about this?
[01:28:00.900 --> 01:28:01.740]   What about that?
[01:28:01.740 --> 01:28:03.500]   Okay, I'll submit that on your behalf.
[01:28:03.500 --> 01:28:05.660]   I need a yes or no on the following five things.
[01:28:05.660 --> 01:28:07.820]   So you as the professor are not,
[01:28:07.820 --> 01:28:09.500]   okay, these are full obligations on my plate
[01:28:09.500 --> 01:28:11.220]   where I have to navigate ambiguity,
[01:28:11.220 --> 01:28:13.060]   maybe follow up, ask follow-up questions,
[01:28:13.060 --> 01:28:15.420]   figure out how to do these interfaces in two hours.
[01:28:15.420 --> 01:28:17.180]   That's where all the admin work happens.
[01:28:17.180 --> 01:28:18.700]   And if there's more administrative requests
[01:28:18.700 --> 01:28:21.340]   for the professors that can fit into that two hours,
[01:28:21.340 --> 01:28:23.500]   then it'll have to get spread out to a future week.
[01:28:23.500 --> 01:28:25.940]   Again, this would stop so much context shifting.
[01:28:26.780 --> 01:28:28.340]   So now there's no administrative requests
[01:28:28.340 --> 01:28:29.380]   coming to your email.
[01:28:29.380 --> 01:28:31.260]   There's no information broadcast coming to your email.
[01:28:31.260 --> 01:28:33.460]   Think about it, how much you'd be able to focus.
[01:28:33.460 --> 01:28:35.420]   The final thing, and this is only half serious,
[01:28:35.420 --> 01:28:36.820]   is get rid of email.
[01:28:36.820 --> 01:28:39.700]   I've said before, and I think it's true,
[01:28:39.700 --> 01:28:42.100]   if you had an upstart university
[01:28:42.100 --> 01:28:45.740]   and you wanted to hire some of the top people in the world,
[01:28:45.740 --> 01:28:47.460]   the only sales pitch you would have to make
[01:28:47.460 --> 01:28:48.700]   is come to this university,
[01:28:48.700 --> 01:28:50.980]   we will not assign you an email address.
[01:28:50.980 --> 01:28:53.740]   Work out the way, I don't know, how's it gonna work?
[01:28:53.740 --> 01:28:54.620]   Figure everything else out.
[01:28:54.620 --> 01:28:56.180]   So we could do these admin things,
[01:28:56.180 --> 01:28:57.420]   they get rid of admin work,
[01:28:57.420 --> 01:29:00.260]   broadcast could happen in these digests, that would help.
[01:29:00.260 --> 01:29:02.620]   There's just other ways of interacting.
[01:29:02.620 --> 01:29:04.620]   Office hours would obviously be much more important.
[01:29:04.620 --> 01:29:06.780]   You might have multi-typed office hours.
[01:29:06.780 --> 01:29:09.220]   Here's student office hours, here's colleague office hours.
[01:29:09.220 --> 01:29:11.900]   It's daily, I don't know, but you could figure it out.
[01:29:11.900 --> 01:29:12.860]   But if you work backwards
[01:29:12.860 --> 01:29:15.180]   from the challenge of no email addresses here,
[01:29:15.180 --> 01:29:19.460]   you get Nobel Prize winners by the dozens.
[01:29:19.460 --> 01:29:22.060]   Get Fields Medal winners, Turing Award winners.
[01:29:22.060 --> 01:29:23.700]   They would be game.
[01:29:23.700 --> 01:29:25.820]   There's nothing for me to check.
[01:29:25.820 --> 01:29:27.740]   Working on my class, I'm working on my research.
[01:29:27.740 --> 01:29:28.820]   Here's my admin block,
[01:29:28.820 --> 01:29:30.140]   here's when I get the broadcast digest,
[01:29:30.140 --> 01:29:31.380]   here's my office hours.
[01:29:31.380 --> 01:29:35.060]   Everything else, there's literally nothing for me to look at.
[01:29:35.060 --> 01:29:36.940]   That would be the dream.
[01:29:36.940 --> 01:29:38.100]   So there you go.
[01:29:38.100 --> 01:29:41.220]   Those are my thoughts on university.
[01:29:41.220 --> 01:29:45.180]   All right, we're at the 130 mark.
[01:29:45.180 --> 01:29:48.380]   We're going a little long.
[01:29:48.380 --> 01:29:50.140]   Voice is getting a little weak.
[01:29:50.140 --> 01:29:52.060]   But let's try to fit in one other quick question here
[01:29:52.060 --> 01:29:53.740]   before we wrap up this episode.
[01:29:53.740 --> 01:29:58.540]   Comes from Vasilky, who says,
[01:29:58.540 --> 01:30:01.420]   "Do you think a college student should abstain
[01:30:01.420 --> 01:30:04.740]   from social media completely?
[01:30:04.740 --> 01:30:07.260]   Many students communicate with social media.
[01:30:07.260 --> 01:30:09.820]   Completely abstaining has made me feel
[01:30:09.820 --> 01:30:13.060]   like I'm missing out on opportunities to discuss homework.
[01:30:13.060 --> 01:30:14.100]   When I miss a class,
[01:30:14.100 --> 01:30:16.180]   I can ask a friend over Messenger for notes.
[01:30:16.180 --> 01:30:17.300]   Even if I use only email,
[01:30:17.300 --> 01:30:18.500]   other people may feel discouraged
[01:30:18.500 --> 01:30:20.500]   to send you over email notes
[01:30:20.500 --> 01:30:22.780]   because they find Facebook or Discord more easy
[01:30:22.780 --> 01:30:23.740]   to scan with their phones.
[01:30:23.740 --> 01:30:24.700]   I don't live near the campus,
[01:30:24.700 --> 01:30:26.980]   so I can't interact with other students.
[01:30:26.980 --> 01:30:29.860]   What do you advise to give a student to communicate
[01:30:29.860 --> 01:30:31.980]   to their peers that need to abstain from social media,
[01:30:31.980 --> 01:30:33.580]   but to remain in the community?"
[01:30:33.580 --> 01:30:37.540]   Well, short answer, long answer, short answer,
[01:30:37.540 --> 01:30:40.420]   separate communication tools from social media.
[01:30:40.420 --> 01:30:43.340]   What do I mean by social media here?
[01:30:43.340 --> 01:30:45.220]   I mean things where you post information
[01:30:45.220 --> 01:30:46.460]   to people you don't know,
[01:30:46.460 --> 01:30:49.820]   or consume information posted by people you don't know.
[01:30:49.820 --> 01:30:52.820]   Twitter, Instagram, TikTok, Facebook.
[01:30:52.820 --> 01:30:55.460]   Don't do that.
[01:30:55.460 --> 01:30:57.940]   I mean, you can, but I would say, yeah, abstain from that.
[01:30:57.940 --> 01:30:59.340]   I think you have other things
[01:30:59.340 --> 01:31:00.420]   that are more important in college.
[01:31:00.420 --> 01:31:02.340]   That's a distraction.
[01:31:02.340 --> 01:31:04.540]   It's not giving you any benefit.
[01:31:04.540 --> 01:31:06.100]   But separate that from the fact
[01:31:06.100 --> 01:31:08.460]   that you use WhatsApp for your study group.
[01:31:08.460 --> 01:31:12.060]   Separate communication tools from the social media.
[01:31:12.060 --> 01:31:14.300]   The key thing to keep in mind is that latter context,
[01:31:14.300 --> 01:31:15.980]   that the tools where you post information
[01:31:15.980 --> 01:31:16.820]   to people you don't know,
[01:31:16.820 --> 01:31:18.180]   or read information from people you don't know,
[01:31:18.180 --> 01:31:19.540]   that's engineered to be distracting.
[01:31:19.540 --> 01:31:22.020]   That's what you want to stay away from.
[01:31:22.020 --> 01:31:24.300]   Having a study group on WhatsApp,
[01:31:24.300 --> 01:31:26.340]   or having a Facebook group that you're,
[01:31:26.340 --> 01:31:28.660]   you know, whatever club uses.
[01:31:28.660 --> 01:31:29.700]   If you've configured Facebook,
[01:31:29.700 --> 01:31:31.300]   like I talk about in digital minimalisms,
[01:31:31.300 --> 01:31:33.580]   and go straight to the groups and have no newsfeed,
[01:31:33.580 --> 01:31:34.420]   that's fine.
[01:31:34.420 --> 01:31:36.740]   I don't care about communication tools.
[01:31:36.740 --> 01:31:39.380]   But don't use social media tools that are engaged,
[01:31:39.380 --> 01:31:41.660]   I mean, that are engineered to distract.
[01:31:41.660 --> 01:31:42.620]   That's what I would recommend.
[01:31:42.620 --> 01:31:45.660]   And in fact, in general, I think college students,
[01:31:45.660 --> 01:31:49.020]   there's so much intellectually, socially,
[01:31:49.020 --> 01:31:52.100]   just spiritually, philosophically to enjoy
[01:31:52.100 --> 01:31:55.580]   during that period of life that gets leeched away.
[01:31:55.580 --> 01:31:58.820]   If you're looking at TikTok videos
[01:31:58.820 --> 01:32:01.300]   as just a default when you're bored.
[01:32:01.300 --> 01:32:03.380]   I mean, just life is really interesting
[01:32:03.380 --> 01:32:04.260]   and vibrant at that point.
[01:32:04.260 --> 01:32:07.820]   And if you take that out of your life as a college student,
[01:32:07.820 --> 01:32:09.740]   what's left is in technicolor.
[01:32:09.740 --> 01:32:13.700]   It's just like a much more interesting period of time.
[01:32:13.700 --> 01:32:17.020]   My long answer is be wary of the justification game
[01:32:17.020 --> 01:32:18.620]   you're playing.
[01:32:18.620 --> 01:32:20.540]   I get this type of thing all the time,
[01:32:20.540 --> 01:32:22.500]   the little bait and switch.
[01:32:22.500 --> 01:32:24.420]   You find this corner case of technology
[01:32:24.420 --> 01:32:28.220]   that there's no debate you need to use,
[01:32:28.220 --> 01:32:31.100]   then allow that to justify chaos.
[01:32:31.100 --> 01:32:33.620]   I hear this from students a lot, like,
[01:32:33.620 --> 01:32:38.620]   "Look, Cal, my math teacher posts our homework
[01:32:38.620 --> 01:32:40.140]   on the internet.
[01:32:40.140 --> 01:32:43.900]   So I need to use the internet to download my math homework.
[01:32:43.900 --> 01:32:46.380]   So that's why I'm playing Fortnite till 3 a.m."
[01:32:47.340 --> 01:32:49.620]   These are two really separate things.
[01:32:49.620 --> 01:32:52.380]   And I'm seeing this in your answer here.
[01:32:52.380 --> 01:32:54.100]   You're like, "You know, like maybe a friend
[01:32:54.100 --> 01:32:56.420]   doesn't wanna share notes with me over email.
[01:32:56.420 --> 01:33:00.060]   So I'm gonna be on TikTok all day."
[01:33:00.060 --> 01:33:01.260]   Remain specific.
[01:33:01.260 --> 01:33:02.940]   And I think that's at the core of my philosophy
[01:33:02.940 --> 01:33:04.020]   of digital minimalism.
[01:33:04.020 --> 01:33:08.220]   Figure out the life you want, what's important to you.
[01:33:08.220 --> 01:33:10.340]   Figure out what technology will support that
[01:33:10.340 --> 01:33:12.300]   and what rules you wanna use it to get the benefits
[01:33:12.300 --> 01:33:13.900]   and avoid the cost.
[01:33:13.900 --> 01:33:15.060]   And outside of those decisions,
[01:33:15.060 --> 01:33:16.740]   be comfortable missing out on everything else.
[01:33:16.740 --> 01:33:17.940]   So be specific.
[01:33:17.940 --> 01:33:20.580]   Don't just use the term social media
[01:33:20.580 --> 01:33:25.180]   and lump the fact that you ask a question over WhatsApp
[01:33:25.180 --> 01:33:27.540]   with the fact that you're on Instagram all day.
[01:33:27.540 --> 01:33:29.460]   Be specific, work backwards from values.
[01:33:29.460 --> 01:33:30.860]   And yes, is your main question,
[01:33:30.860 --> 01:33:34.380]   should you abstain from the social media that you can?
[01:33:34.380 --> 01:33:36.980]   Almost certainly the answer is probably yes.
[01:33:36.980 --> 01:33:39.060]   I think for almost any college student,
[01:33:39.060 --> 01:33:42.140]   that is gonna make their college life richer.
[01:33:42.140 --> 01:33:45.780]   All right, Jesse, 135.
[01:33:46.780 --> 01:33:49.380]   Got some good legs on this episode.
[01:33:49.380 --> 01:33:50.780]   It's gotta last people a whole week,
[01:33:50.780 --> 01:33:52.020]   so I'm glad we got there.
[01:33:52.020 --> 01:33:57.940]   Thank you everyone who sent in their questions or calls.
[01:33:57.940 --> 01:34:01.700]   If you like what you heard, you will like what you see.
[01:34:01.700 --> 01:34:03.940]   Video of the full episode as well as individual clips
[01:34:03.940 --> 01:34:08.860]   can be found at youtube.com/calnewportmedia.
[01:34:08.860 --> 01:34:11.020]   Soon to be Jesse Scarecrow Incorporated.
[01:34:11.020 --> 01:34:14.780]   I will be back next week,
[01:34:14.780 --> 01:34:16.940]   a whole week from now with a new episode
[01:34:16.940 --> 01:34:18.100]   of the Deep Questions podcast.
[01:34:18.100 --> 01:34:21.060]   And until then, as always, stay deep.
[01:34:21.060 --> 01:34:23.660]   (upbeat music)
[01:34:23.660 --> 01:34:25.340]   (upbeat music)

