
[00:00:00.000 --> 00:00:05.000]   - When you were at Caltech, did you get to interact
[00:00:05.000 --> 00:00:07.240]   with Richard Feynman at all?
[00:00:07.240 --> 00:00:08.880]   Do you have any memories of Richard?
[00:00:08.880 --> 00:00:11.920]   - We worked together quite a bit actually.
[00:00:11.920 --> 00:00:14.960]   In fact, both when I was at Caltech
[00:00:14.960 --> 00:00:18.540]   and after I left Caltech, we were both consultants
[00:00:18.540 --> 00:00:20.600]   at this company called Thinking Machines Corporation,
[00:00:20.600 --> 00:00:23.360]   which was just down the street from here actually.
[00:00:23.360 --> 00:00:25.140]   It was ultimately ill-fated company,
[00:00:25.140 --> 00:00:28.620]   but I used to say this company is not gonna work
[00:00:28.620 --> 00:00:30.760]   with the strategy they have and Dick Feynman always used
[00:00:30.760 --> 00:00:32.920]   to say, "What do we know about running companies?
[00:00:32.920 --> 00:00:34.960]   "Just let them run their company."
[00:00:34.960 --> 00:00:39.960]   But anyway, he was not into that kind of thing
[00:00:39.960 --> 00:00:43.020]   and he always thought that my interest in doing things
[00:00:43.020 --> 00:00:47.080]   like running companies was a distraction so to speak.
[00:00:47.080 --> 00:00:52.080]   And for me, it's a mechanism to have a more effective
[00:00:52.080 --> 00:00:56.660]   machine for actually figuring things out
[00:00:56.660 --> 00:00:57.880]   and getting things to happen.
[00:00:57.880 --> 00:01:01.080]   - Did he think of it 'cause essentially what you used,
[00:01:01.080 --> 00:01:02.840]   you did with the company, I don't know if you were thinking
[00:01:02.840 --> 00:01:06.120]   of it that way, but you're creating tools
[00:01:06.120 --> 00:01:11.120]   to empower the exploration of the university.
[00:01:11.120 --> 00:01:13.480]   Do you think, did he--
[00:01:13.480 --> 00:01:14.960]   - Did he understand that point?
[00:01:14.960 --> 00:01:17.140]   - The point of tools of--
[00:01:17.140 --> 00:01:19.040]   - I think not as well as he might have done.
[00:01:19.040 --> 00:01:23.620]   I mean, I think that, but he was actually my first company,
[00:01:23.620 --> 00:01:27.000]   which was also involved with, well, was involved
[00:01:27.000 --> 00:01:29.700]   with more mathematical computation kinds of things.
[00:01:29.700 --> 00:01:34.240]   He was quite, he had lots of advice
[00:01:34.240 --> 00:01:37.780]   about the technical side of what we should do and so on.
[00:01:37.780 --> 00:01:39.800]   - Do you have examples, memories, or thoughts that--
[00:01:39.800 --> 00:01:41.560]   - Oh yeah, yeah, he had all kinds of,
[00:01:41.560 --> 00:01:45.360]   look, in the business of doing sort of,
[00:01:45.360 --> 00:01:47.200]   one of the hard things in math is doing integrals
[00:01:47.200 --> 00:01:48.240]   and so on, right?
[00:01:48.240 --> 00:01:51.560]   And so he had his own elaborate ways to do integrals
[00:01:51.560 --> 00:01:53.300]   and so on, he had his own ways of thinking about,
[00:01:53.300 --> 00:01:56.400]   sort of getting intuition about how math works.
[00:01:56.400 --> 00:02:00.160]   And so his sort of meta idea was,
[00:02:00.160 --> 00:02:02.760]   take those intuitional methods and make a computer
[00:02:02.760 --> 00:02:04.720]   follow those intuitional methods.
[00:02:04.720 --> 00:02:07.580]   Now it turns out, for the most part,
[00:02:07.580 --> 00:02:09.520]   like when we do integrals and things,
[00:02:09.520 --> 00:02:12.840]   what we do is we build this kind of bizarre industrial
[00:02:12.840 --> 00:02:15.560]   machine that turns every integral into, you know,
[00:02:15.560 --> 00:02:17.960]   products of major G functions and generates
[00:02:17.960 --> 00:02:19.760]   this very elaborate thing.
[00:02:19.760 --> 00:02:22.220]   And actually the big problem is turning the results
[00:02:22.220 --> 00:02:23.800]   into something a human will understand.
[00:02:23.800 --> 00:02:26.080]   It's not, quote, doing the integral.
[00:02:26.080 --> 00:02:28.640]   And actually, Feynman did understand that to some extent.
[00:02:28.640 --> 00:02:32.520]   And I'm embarrassed to say, he once gave me this big pile
[00:02:32.520 --> 00:02:35.560]   of, you know, calculational methods for particle physics
[00:02:35.560 --> 00:02:37.160]   that he worked out in the '50s, and he said,
[00:02:37.160 --> 00:02:39.000]   you know, it's more used to you than to me type thing.
[00:02:39.000 --> 00:02:41.600]   And I was like, I've intended to look at it
[00:02:41.600 --> 00:02:43.760]   and give it back, and it's still in my files now.
[00:02:43.760 --> 00:02:48.160]   So it's, but that's what happens when it's finiteness
[00:02:48.160 --> 00:02:49.120]   of human lives.
[00:02:49.120 --> 00:02:51.880]   It, you know, maybe if he'd lived another 20 years,
[00:02:51.880 --> 00:02:53.660]   I would have remembered to give it back.
[00:02:53.660 --> 00:02:57.960]   But I think it's, you know, that was his attempt
[00:02:57.960 --> 00:03:02.560]   to systematize the ways that one does integrals
[00:03:02.560 --> 00:03:04.340]   that show up in particle physics and so on.
[00:03:04.340 --> 00:03:06.480]   Turns out the way we've actually done it
[00:03:06.480 --> 00:03:08.120]   is very different from that way.
[00:03:08.120 --> 00:03:09.980]   - What do you make of that difference between,
[00:03:09.980 --> 00:03:13.600]   so Feynman was actually quite remarkable at creating
[00:03:13.600 --> 00:03:17.040]   sort of intuitive, like diving in, you know,
[00:03:17.040 --> 00:03:19.400]   creating intuitive frameworks for understanding
[00:03:19.400 --> 00:03:20.840]   difficult concepts.
[00:03:20.840 --> 00:03:21.680]   Is--
[00:03:21.680 --> 00:03:24.260]   - I'm smiling because, you know, the funny thing
[00:03:24.260 --> 00:03:27.300]   about him was that the thing he was really, really,
[00:03:27.300 --> 00:03:29.820]   really good at is calculating stuff.
[00:03:29.820 --> 00:03:31.540]   And, but he thought that was easy
[00:03:31.540 --> 00:03:33.860]   because he was really good at it.
[00:03:33.860 --> 00:03:36.580]   And so he would do these things where he would calculate
[00:03:36.580 --> 00:03:40.060]   some, do some complicated calculation
[00:03:40.060 --> 00:03:41.700]   in quantum field theory, for example,
[00:03:41.700 --> 00:03:43.320]   come out with a result.
[00:03:43.320 --> 00:03:45.380]   Wouldn't tell anybody about the complicated calculation
[00:03:45.380 --> 00:03:46.620]   'cause he thought that was easy.
[00:03:46.620 --> 00:03:48.440]   He thought the really impressive thing
[00:03:48.440 --> 00:03:50.020]   was to have the simple intuition
[00:03:50.020 --> 00:03:52.080]   about how everything works.
[00:03:52.080 --> 00:03:54.360]   So he invented that at the end.
[00:03:54.360 --> 00:03:56.440]   And, you know, because he'd done this calculation
[00:03:56.440 --> 00:03:59.240]   and knew how it worked, it was a lot easier.
[00:03:59.240 --> 00:04:00.920]   It's a lot easier to have good intuition
[00:04:00.920 --> 00:04:02.720]   when you know what the answer is.
[00:04:02.720 --> 00:04:05.000]   And then he would just not tell anybody
[00:04:05.000 --> 00:04:06.000]   about these calculations.
[00:04:06.000 --> 00:04:08.680]   And he wasn't meaning that maliciously, so to speak.
[00:04:08.680 --> 00:04:11.320]   It's just, he thought that was easy.
[00:04:11.320 --> 00:04:13.820]   And that's, you know, that led to areas
[00:04:13.820 --> 00:04:15.600]   where people were just completely mystified
[00:04:15.600 --> 00:04:17.440]   and they kind of followed his intuition,
[00:04:17.440 --> 00:04:19.520]   but nobody could tell why it worked
[00:04:19.520 --> 00:04:21.160]   because actually the reason it worked
[00:04:21.160 --> 00:04:22.580]   was 'cause he'd done all these calculations
[00:04:22.580 --> 00:04:24.460]   and he knew that it would work.
[00:04:24.460 --> 00:04:26.700]   And, you know, when I, he and I worked a bit
[00:04:26.700 --> 00:04:31.200]   on quantum computers actually back in 1980, '81,
[00:04:31.200 --> 00:04:33.580]   but before anybody had heard of those things.
[00:04:33.580 --> 00:04:35.640]   And, you know, the typical mode of,
[00:04:35.640 --> 00:04:38.140]   I mean, he always used to say,
[00:04:38.140 --> 00:04:40.100]   and I now think about this 'cause I'm about the age
[00:04:40.100 --> 00:04:42.340]   that he was when I worked with him.
[00:04:42.340 --> 00:04:44.900]   And, you know, I see that people who are one third my age,
[00:04:44.900 --> 00:04:47.420]   so to speak, and he was always complaining
[00:04:47.420 --> 00:04:48.940]   that I was one third his age.
[00:04:48.940 --> 00:04:50.520]   (both laughing)
[00:04:50.520 --> 00:04:52.940]   Various things, but, you know,
[00:04:52.940 --> 00:04:56.260]   he would do some calculation by hand, you know,
[00:04:56.260 --> 00:04:58.960]   blackboard and things, come up with some answer.
[00:04:58.960 --> 00:05:01.320]   I'd say, "I don't understand this."
[00:05:01.320 --> 00:05:03.480]   You know, I do something with a computer
[00:05:03.480 --> 00:05:07.040]   and he'd say, you know, "I don't understand this."
[00:05:07.040 --> 00:05:09.540]   So there'd be some big argument about what was,
[00:05:09.540 --> 00:05:11.940]   you know, what was going on, but it was always,
[00:05:11.940 --> 00:05:16.340]   and I think actually many of the things
[00:05:16.340 --> 00:05:19.940]   that we sort of realized about quantum computing
[00:05:19.940 --> 00:05:21.780]   that were sort of issues that have to do particularly
[00:05:21.780 --> 00:05:25.540]   with the measurement process are kind of still issues today.
[00:05:25.540 --> 00:05:26.980]   And I kind of find it interesting.
[00:05:26.980 --> 00:05:30.140]   It's a funny thing in science that these, you know,
[00:05:30.140 --> 00:05:33.620]   that there's a remarkable, it happens in technology too,
[00:05:33.620 --> 00:05:36.860]   there's a remarkable sort of repetition of history
[00:05:36.860 --> 00:05:38.580]   that ends up occurring.
[00:05:38.580 --> 00:05:40.760]   Eventually things really get nailed down,
[00:05:40.760 --> 00:05:42.500]   but it often takes a while
[00:05:42.500 --> 00:05:45.060]   and it often things come back decades later.
[00:05:46.020 --> 00:05:48.260]   Well, for example, I could tell a story,
[00:05:48.260 --> 00:05:50.760]   actually happened right down the street from here.
[00:05:50.760 --> 00:05:53.220]   When we were both at Thinking Machines,
[00:05:53.220 --> 00:05:56.820]   I had been working on this particular cellular automaton
[00:05:56.820 --> 00:05:59.400]   called Rule 30 that has this feature that it,
[00:05:59.400 --> 00:06:01.700]   from very simple initial conditions,
[00:06:01.700 --> 00:06:04.440]   it makes really complicated behavior, okay?
[00:06:04.440 --> 00:06:08.780]   So, and actually of all silly physical things,
[00:06:08.780 --> 00:06:11.780]   using this big parallel computer
[00:06:11.780 --> 00:06:15.380]   called the Connection Machine that that company was making,
[00:06:15.380 --> 00:06:19.060]   I generated this giant printout of Rule 30 on very,
[00:06:19.060 --> 00:06:21.760]   on actually on the same kind of printer
[00:06:21.760 --> 00:06:26.760]   that people use to make layouts for microprocessors.
[00:06:26.760 --> 00:06:29.460]   So one of these big, you know,
[00:06:29.460 --> 00:06:33.000]   large format printers with high resolution and so on.
[00:06:33.000 --> 00:06:36.940]   So, okay, so we print this out, lots of very tiny cells.
[00:06:36.940 --> 00:06:39.740]   And so there was sort of a question of how,
[00:06:39.740 --> 00:06:42.620]   some features of that pattern.
[00:06:42.620 --> 00:06:45.500]   And so it was very much a physical, you know,
[00:06:45.500 --> 00:06:46.860]   on the floor with meter rules
[00:06:46.860 --> 00:06:48.820]   trying to measure different things.
[00:06:48.820 --> 00:06:51.860]   So, so Feynman kind of takes me aside.
[00:06:51.860 --> 00:06:53.060]   We've been doing that for a little while
[00:06:53.060 --> 00:06:54.820]   and takes me aside and he says,
[00:06:54.820 --> 00:06:56.300]   "I just wanna know this one thing."
[00:06:56.300 --> 00:06:58.580]   He says, "I wanna know, how did you know
[00:06:58.580 --> 00:07:01.340]   that this Rule 30 thing would produce
[00:07:01.340 --> 00:07:02.660]   all this really complicated behavior
[00:07:02.660 --> 00:07:05.220]   that is so complicated that we're, you know,
[00:07:05.220 --> 00:07:07.580]   going around with this big printout and so on?"
[00:07:07.580 --> 00:07:09.900]   And I said, "Well, I didn't know.
[00:07:09.900 --> 00:07:12.120]   I just enumerated all the possible rules
[00:07:12.120 --> 00:07:14.860]   and then observed that that's what happened."
[00:07:14.860 --> 00:07:17.220]   He said, "Oh, I feel a lot better."
[00:07:17.220 --> 00:07:19.160]   You know, I thought you had some intuition
[00:07:19.160 --> 00:07:21.780]   that he didn't have that would let one.
[00:07:21.780 --> 00:07:23.420]   I said, "No, no, no, no intuition,
[00:07:23.420 --> 00:07:25.300]   just experimental science."
[00:07:25.300 --> 00:07:29.420]   - Oh, that's such a beautiful sort of dichotomy there
[00:07:29.420 --> 00:07:31.060]   of that's exactly what you showed
[00:07:31.060 --> 00:07:33.260]   is you really can't have an intuition
[00:07:33.260 --> 00:07:36.020]   about an irreducible, I mean, you have to run it.
[00:07:36.020 --> 00:07:36.860]   - Yes, that's right.
[00:07:36.860 --> 00:07:38.180]   - That's so hard for us humans
[00:07:38.180 --> 00:07:41.820]   and especially brilliant physicists
[00:07:41.820 --> 00:07:44.640]   like Feynman to say that you can't have
[00:07:44.640 --> 00:07:48.600]   a compressed, clean intuition
[00:07:48.600 --> 00:07:50.600]   about how the whole thing works.
[00:07:50.600 --> 00:07:51.900]   - Yes, yes.
[00:07:51.900 --> 00:07:54.640]   No, he was, I mean, I think he was sort of on the edge
[00:07:54.640 --> 00:07:56.960]   of understanding that point about computation.
[00:07:56.960 --> 00:07:58.640]   And I think he found that,
[00:07:58.640 --> 00:08:01.320]   I think he always found computation interesting.
[00:08:01.320 --> 00:08:03.040]   And I think that was sort of what he was
[00:08:03.040 --> 00:08:04.740]   a little bit poking at.
[00:08:04.740 --> 00:08:07.120]   I mean, that intuition, you know,
[00:08:07.120 --> 00:08:09.640]   the difficulty of discovering things like even you say,
[00:08:09.640 --> 00:08:11.520]   oh, you know, you just enumerate all the cases
[00:08:11.520 --> 00:08:13.220]   and you just find one that does something interesting,
[00:08:13.220 --> 00:08:15.220]   right, sounds very easy.
[00:08:15.220 --> 00:08:18.300]   Turns out like I missed it when I first saw it
[00:08:18.300 --> 00:08:20.300]   because I had kind of an intuition
[00:08:20.300 --> 00:08:21.780]   that said it shouldn't be there.
[00:08:21.780 --> 00:08:23.100]   And so I had kind of arguments,
[00:08:23.100 --> 00:08:25.800]   oh, I'm gonna ignore that case because whatever.
[00:08:25.800 --> 00:08:27.540]   And--
[00:08:27.540 --> 00:08:29.540]   - How did you have an open mind enough?
[00:08:29.540 --> 00:08:31.260]   Because you're essentially the same person
[00:08:31.260 --> 00:08:33.500]   as Richard Feynman, like the same kind of physics
[00:08:33.500 --> 00:08:34.700]   type of thinking.
[00:08:34.700 --> 00:08:38.900]   How did you find yourself having a sufficiently open mind
[00:08:38.900 --> 00:08:43.280]   to be open to watching rules and them revealing complexity?
[00:08:43.280 --> 00:08:44.620]   - Yeah, I think that's an interesting question.
[00:08:44.620 --> 00:08:45.940]   I've wondered about that myself
[00:08:45.940 --> 00:08:47.400]   'cause it's kind of like, you know,
[00:08:47.400 --> 00:08:50.000]   you live through these things and then you say,
[00:08:50.000 --> 00:08:51.600]   what was the historical story?
[00:08:51.600 --> 00:08:53.620]   And sometimes the historical story that you realize
[00:08:53.620 --> 00:08:57.040]   after the fact was not what you lived through, so to speak.
[00:08:57.040 --> 00:09:01.920]   And so, you know, what I realized is I think what happened
[00:09:01.920 --> 00:09:05.760]   is, you know, I did physics kind of like
[00:09:05.760 --> 00:09:08.640]   reductionistic physics where you're throwing the universe
[00:09:08.640 --> 00:09:11.600]   and you're told go figure out what's going on inside it.
[00:09:11.600 --> 00:09:14.600]   And then I started building computer tools
[00:09:14.600 --> 00:09:17.000]   and I started building my first computer language,
[00:09:17.000 --> 00:09:18.160]   for example.
[00:09:18.160 --> 00:09:19.760]   And computer language is not like,
[00:09:19.760 --> 00:09:22.320]   it's sort of like physics in the sense that you have to take
[00:09:22.320 --> 00:09:24.280]   all those computations people want to do
[00:09:24.280 --> 00:09:26.860]   and kind of drill down and find the primitives
[00:09:26.860 --> 00:09:28.640]   that they can all be made of.
[00:09:28.640 --> 00:09:30.320]   But then you do something that's really different
[00:09:30.320 --> 00:09:33.700]   because you're just saying, okay, these are the primitives.
[00:09:33.700 --> 00:09:36.280]   Now, you know, hopefully they'll be useful to people.
[00:09:36.280 --> 00:09:37.700]   Let's build up from there.
[00:09:37.700 --> 00:09:40.660]   So you're essentially building an artificial universe
[00:09:40.660 --> 00:09:42.960]   in a sense where you make this language,
[00:09:42.960 --> 00:09:44.320]   you've got these primitives,
[00:09:44.320 --> 00:09:47.240]   you're just building whatever you feel like building.
[00:09:47.240 --> 00:09:50.080]   And that's, and so it was sort of interesting for me
[00:09:50.080 --> 00:09:52.360]   because from doing science where you're just throwing
[00:09:52.360 --> 00:09:56.760]   the universe as the universe is to then just being told,
[00:09:56.760 --> 00:09:59.480]   you know, you can make up any universe you want.
[00:09:59.480 --> 00:10:03.100]   And so I think that experience of making a computer language,
[00:10:03.100 --> 00:10:05.040]   which is essentially building your own universe,
[00:10:05.040 --> 00:10:09.520]   so to speak, is, you know, that's kind of the,
[00:10:09.520 --> 00:10:12.560]   that's what gave me a somewhat different attitude
[00:10:12.560 --> 00:10:13.960]   towards what might be possible.
[00:10:13.960 --> 00:10:16.200]   It's like, let's just explore what can be done
[00:10:16.200 --> 00:10:18.160]   in these artificial universes,
[00:10:18.160 --> 00:10:21.240]   rather than thinking the natural science way
[00:10:21.240 --> 00:10:23.800]   of let's be constrained by how the universe actually is.
[00:10:23.800 --> 00:10:26.880]   - Yeah, by being able to program, essentially you've,
[00:10:26.880 --> 00:10:31.000]   as opposed to being limited to just your mind and a pen,
[00:10:31.000 --> 00:10:34.360]   you now have, you've basically built another brain
[00:10:34.360 --> 00:10:36.400]   that you can use to explore the universe by,
[00:10:36.400 --> 00:10:39.920]   the computer program, you know, is a kind of a brain.
[00:10:39.920 --> 00:10:42.120]   - Right, and it's, well, it's, or a telescope,
[00:10:42.120 --> 00:10:43.280]   or, you know, it's a tool.
[00:10:43.280 --> 00:10:45.040]   It lets you see stuff.
[00:10:45.040 --> 00:10:46.400]   - But there's something fundamentally different
[00:10:46.400 --> 00:10:47.880]   between a computer and a telescope.
[00:10:47.880 --> 00:10:52.880]   I mean, it just, I'm hoping not to romanticize the notion,
[00:10:52.880 --> 00:10:55.760]   but it's more general, the computer is more general
[00:10:55.760 --> 00:10:56.600]   than the telescope. - It is, it is much more general.
[00:10:56.600 --> 00:10:59.800]   And it's, I think, I mean, this point about,
[00:10:59.800 --> 00:11:04.280]   you know, people say, oh, such and such a thing
[00:11:04.280 --> 00:11:06.840]   was almost discovered at such and such a time.
[00:11:06.840 --> 00:11:09.160]   The distance between, you know,
[00:11:09.160 --> 00:11:10.760]   the building the paradigm that allows you
[00:11:10.760 --> 00:11:12.120]   to actually understand stuff,
[00:11:12.120 --> 00:11:15.120]   or allows one to be open to seeing what's going on,
[00:11:15.120 --> 00:11:16.560]   that's really hard.
[00:11:16.560 --> 00:11:20.760]   And, you know, I think in, I've been fortunate in my life
[00:11:20.760 --> 00:11:22.120]   that I've spent a lot of my time
[00:11:22.120 --> 00:11:24.280]   building computational language,
[00:11:24.280 --> 00:11:28.640]   and that's an activity that in a sense works
[00:11:28.640 --> 00:11:33.400]   by sort of having to kind of create
[00:11:33.400 --> 00:11:35.720]   another level of abstraction and kind of be open
[00:11:35.720 --> 00:11:37.520]   to different kinds of structures.
[00:11:37.520 --> 00:11:41.860]   But, you know, it's always, I mean, I'm fully aware of,
[00:11:41.860 --> 00:11:45.360]   I suppose, the fact that I have seen it a bunch of times
[00:11:45.360 --> 00:11:48.640]   of how easy it is to miss the obvious, so to speak,
[00:11:48.640 --> 00:11:51.640]   that at least is factored into my attempt
[00:11:51.640 --> 00:11:55.200]   to not miss the obvious, although it may not succeed.
[00:11:55.200 --> 00:11:57.520]   (whooshing)
[00:11:57.520 --> 00:11:59.840]   (whooshing)
[00:11:59.840 --> 00:12:02.160]   (whooshing)
[00:12:02.160 --> 00:12:04.480]   (whooshing)
[00:12:04.480 --> 00:12:06.800]   (whooshing)
[00:12:06.800 --> 00:12:09.120]   (whooshing)
[00:12:09.120 --> 00:12:11.440]   (whooshing)
[00:12:11.440 --> 00:12:21.440]   [BLANK_AUDIO]

