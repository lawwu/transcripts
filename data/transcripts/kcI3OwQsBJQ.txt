
[00:00:00.000 --> 00:00:09.900]   For the very first time in human history, we are producing, manufacturing intelligence
[00:00:09.900 --> 00:00:11.540]   like production.
[00:00:11.540 --> 00:00:15.820]   Raw material comes in, a lot of course, a lot of genius goes into that box and what
[00:00:15.820 --> 00:00:19.220]   comes out is intelligence that's refined.
[00:00:19.220 --> 00:00:23.580]   You're listening to Gradient Dissent, a show about machine learning in the real world,
[00:00:23.580 --> 00:00:25.940]   and I'm your host, Lukas Biewald.
[00:00:25.940 --> 00:00:30.340]   Today on Gradient Dissent, I interviewed a guest that I've been looking forward to interviewing
[00:00:30.340 --> 00:00:31.860]   for quite a long time.
[00:00:31.860 --> 00:00:37.740]   This is Jensen Huang, who is the CEO and founder of NVIDIA, which if you've trained a machine
[00:00:37.740 --> 00:00:42.040]   learning model, you've probably trained it on NVIDIA hardware.
[00:00:42.040 --> 00:00:47.360]   We get into machine learning and we talk about his views on what the future holds.
[00:00:47.360 --> 00:00:50.420]   This is a super fun interview and I really hope you enjoy it.
[00:00:50.420 --> 00:00:51.420]   All right.
[00:00:51.420 --> 00:00:53.220]   Well, thanks so much for doing this.
[00:00:53.220 --> 00:00:57.540]   We collected questions from our community, we had a ton, so there's more questions that
[00:00:57.540 --> 00:00:58.700]   I'm sure we can get through.
[00:00:58.700 --> 00:01:02.860]   So I'm going to get in my questions first.
[00:01:02.860 --> 00:01:06.140]   I wanted to start with the number one question I wanted to ask you, which I've always wondered
[00:01:06.140 --> 00:01:14.820]   about, which is, I think almost everyone training machine learning models these days uses NVIDIA.
[00:01:14.820 --> 00:01:20.780]   I was really curious about how conscious of a strategy that was, when you started to think
[00:01:20.780 --> 00:01:26.300]   about it and how you made that happen.
[00:01:26.300 --> 00:01:34.140]   It started when almost simultaneously three different research teams reached out to us
[00:01:34.140 --> 00:01:39.140]   asking us to help them accelerate their neural network models.
[00:01:39.140 --> 00:01:42.500]   And it turned out the reason for that was because they were all trying to submit for
[00:01:42.500 --> 00:01:45.820]   ImageNet, the big competition.
[00:01:45.820 --> 00:01:49.340]   And so deep learning came into our consciousness kind of around that time.
[00:01:49.340 --> 00:01:51.020]   David, what year is this?
[00:01:51.020 --> 00:01:54.220]   This is, when was Alex's ImageNet?
[00:01:54.220 --> 00:01:58.180]   It must have been like 2011, maybe?
[00:01:58.180 --> 00:02:03.780]   Yeah, I was going to say 2012 or 2013, but anyhow, it's something like that.
[00:02:03.780 --> 00:02:07.420]   And so anyways, AlexNet, it was that year.
[00:02:07.420 --> 00:02:10.180]   But it was kind of around our consciousness around that time.
[00:02:10.180 --> 00:02:14.700]   The thing that was really exciting was, we all know that computer vision was hard to
[00:02:14.700 --> 00:02:15.900]   do.
[00:02:15.900 --> 00:02:22.860]   And for Alex to have created a neural network, trained it on a whole bunch of data, and broken
[00:02:22.860 --> 00:02:30.100]   the record of computer vision experts, of which many of them were at NVIDIA trying to
[00:02:30.100 --> 00:02:35.180]   do the same, using human engineered features.
[00:02:35.180 --> 00:02:37.940]   That giant breakthrough caught a lot of our attention.
[00:02:37.940 --> 00:02:42.980]   And so computer vision, as you know, is one of the foundations of artificial intelligence.
[00:02:42.980 --> 00:02:45.940]   And all of a sudden, a giant leap happened.
[00:02:45.940 --> 00:02:50.580]   And when discontinuity happens, it's something that important, it really caught our attention.
[00:02:50.580 --> 00:02:56.660]   I think the difference between what happened around the rest of the world versus us is
[00:02:56.660 --> 00:03:01.780]   we took a step back and we said, what is the implication of this, not just for computer
[00:03:01.780 --> 00:03:06.900]   vision, but ultimately how software is done altogether?
[00:03:06.900 --> 00:03:12.700]   Recognizing that for the very first time, software is not going to be written, predictive
[00:03:12.700 --> 00:03:18.420]   features weren't going to be engineered or created by humans, but somehow automatically
[00:03:18.420 --> 00:03:26.580]   extracted out of data, refined out of data somehow to recognize patterns, relationships,
[00:03:26.580 --> 00:03:32.180]   and somehow learn the representation of some predictive model.
[00:03:32.180 --> 00:03:39.540]   That observation early on caused us to ask the question, how does this affect the future
[00:03:39.540 --> 00:03:43.380]   of software, how does this affect the future of computer science, how does this affect
[00:03:43.380 --> 00:03:45.300]   the future of computing?
[00:03:45.300 --> 00:03:51.060]   How would you change the way a computer, if the way that you write software is different,
[00:03:51.060 --> 00:03:54.260]   then how does it change the way you would design computers?
[00:03:54.260 --> 00:03:58.300]   And if the software that's written is written by a computer versus a human, how does it
[00:03:58.300 --> 00:04:01.340]   affect the type of computers you would design?
[00:04:01.340 --> 00:04:07.660]   And so we had the good sense of thinking about it from first principles, the implications
[00:04:07.660 --> 00:04:13.900]   for the entire field of computer science and the entire field of industry, which ultimately
[00:04:13.900 --> 00:04:19.020]   led to asking the question, what about the implications to all the different industries?
[00:04:19.020 --> 00:04:26.100]   And so I think that the good fortune was we were interested in computer vision.
[00:04:26.100 --> 00:04:30.820]   We saw the gigantic breakthrough from Alex and of course, Jeff Hinton and the folks at
[00:04:30.820 --> 00:04:36.020]   Toronto and we simultaneously were working on it with several other labs at the same
[00:04:36.020 --> 00:04:37.020]   time.
[00:04:37.020 --> 00:04:44.580]   So I think it was partly good fortune, partly having the sense to realize the profound implications
[00:04:44.580 --> 00:04:49.980]   to computer science and then asking ourselves what the implication is for everything.
[00:04:49.980 --> 00:04:55.100]   But I think one of the things that you've done amazingly well is just stayed dominant
[00:04:55.100 --> 00:04:56.100]   in this space.
[00:04:56.100 --> 00:05:00.580]   You might've had a head start, but of course, lots of other people have noticed that this
[00:05:00.580 --> 00:05:02.580]   is a really valuable space.
[00:05:02.580 --> 00:05:09.060]   And I've been hearing since maybe 2014 companies saying, "Hey, we're going to make the next
[00:05:09.060 --> 00:05:14.100]   deep learning training GPU or TP or something like that."
[00:05:14.100 --> 00:05:18.940]   But you've actually really maintained this ubiquity in the market.
[00:05:18.940 --> 00:05:21.780]   And I wonder what you attribute that to.
[00:05:21.780 --> 00:05:26.860]   Is it more the architecture of the chip or is it more the software like CUDA and CUDA
[00:05:26.860 --> 00:05:32.500]   NAND or is it something else that kind of keeps you ahead of the competition?
[00:05:32.500 --> 00:05:41.620]   Well, we're partly because the company was formed properly for this opportunity.
[00:05:41.620 --> 00:05:44.460]   We were always in the field of accelerated computing.
[00:05:44.460 --> 00:05:50.100]   If you go all the way back to computer graphics, all the way since the beginning of our company,
[00:05:50.100 --> 00:05:56.140]   this new way of doing application acceleration, domain specific application acceleration of
[00:05:56.140 --> 00:06:01.380]   which computer graphics is one, scientific computing and physics simulations and others
[00:06:01.380 --> 00:06:03.780]   is kind of another.
[00:06:03.780 --> 00:06:06.340]   Image processing, for example, is another.
[00:06:06.340 --> 00:06:09.540]   You could argue that deep learning is yet another.
[00:06:09.540 --> 00:06:15.300]   And so these different domains of applications, the company was started with that mission
[00:06:15.300 --> 00:06:16.300]   in mind.
[00:06:16.300 --> 00:06:20.940]   Now, in order to do accelerated computing, domain specific accelerated computing, you
[00:06:20.940 --> 00:06:23.420]   really have to be a full stack company.
[00:06:23.420 --> 00:06:26.740]   You have to understand what is the application, the nature of the application you're trying
[00:06:26.740 --> 00:06:28.360]   to accelerate.
[00:06:28.360 --> 00:06:33.340]   You have to redesign the algorithm because the way that you would write an algorithm,
[00:06:33.340 --> 00:06:39.300]   develop an algorithm for sequential processing is radically different than parallel processing.
[00:06:39.300 --> 00:06:46.100]   And so algorithm engineers, our company has a richness of algorithm engineers.
[00:06:46.100 --> 00:06:51.620]   And you have to think about the system software and the systems differently because the workloads
[00:06:51.620 --> 00:06:54.220]   change the bottlenecks.
[00:06:54.220 --> 00:06:56.740]   And so you have to think about system software differently.
[00:06:56.740 --> 00:06:58.100]   You have to think about systems differently.
[00:06:58.100 --> 00:07:00.780]   You have architectures differently.
[00:07:00.780 --> 00:07:05.940]   And so our company is fortunate that we are a full stack company that goes all the way
[00:07:05.940 --> 00:07:09.180]   to the research of algorithms.
[00:07:09.180 --> 00:07:12.620]   And that's what it really takes to be an accelerated computing company.
[00:07:12.620 --> 00:07:17.800]   But I think the advantage that we have is that we've been a full stack computing company
[00:07:17.800 --> 00:07:19.980]   for a very long time.
[00:07:19.980 --> 00:07:27.460]   And we have taken that skill set from computer graphics to imaging to scientific computing.
[00:07:27.460 --> 00:07:32.300]   And then when deep learning came along, it was a problem that our company was very adept
[00:07:32.300 --> 00:07:33.300]   at solving.
[00:07:33.300 --> 00:07:38.460]   That's a good segue into a question a lot of people had that I have also, which is,
[00:07:38.460 --> 00:07:46.460]   is there a lot of tension between the needs of gamers and maybe crypto miners and scientists
[00:07:46.460 --> 00:07:48.780]   and people in deep learning?
[00:07:48.780 --> 00:07:52.500]   How do you trade those off into a single chip?
[00:07:52.500 --> 00:07:54.340]   How do you prioritize the different needs?
[00:07:54.340 --> 00:07:58.540]   Or maybe there's no tension because everyone has to do the same type of workload.
[00:07:58.540 --> 00:08:00.220]   I'm curious how you think about that.
[00:08:00.220 --> 00:08:02.420]   Yeah, there's absolutely a tension.
[00:08:02.420 --> 00:08:11.020]   And for example, scientific computing, because it has a large body of historical code, and
[00:08:11.020 --> 00:08:17.780]   they could be in FP64, whereas for consumer applications, FP32 is just fine.
[00:08:17.780 --> 00:08:24.820]   Whereas for deep learning, it's quite a large amount of different types of formats that
[00:08:24.820 --> 00:08:27.820]   could be used.
[00:08:27.820 --> 00:08:30.280]   The nature of the processing could be a little different.
[00:08:30.280 --> 00:08:33.340]   Sometimes it's very dense computation.
[00:08:33.340 --> 00:08:36.180]   Sometimes it's a little bit more sparse computation.
[00:08:36.180 --> 00:08:39.220]   Ray tracing, for example, is very sparse.
[00:08:39.220 --> 00:08:42.080]   And rasterization, on the other hand, is rather dense.
[00:08:42.080 --> 00:08:45.260]   Image processing is rather dense.
[00:08:45.260 --> 00:08:47.620]   And you have different computation natures.
[00:08:47.620 --> 00:08:49.940]   You have different precision that you have to support.
[00:08:49.940 --> 00:08:55.580]   Each one of the industries have a very large number of applications that are in use that
[00:08:55.580 --> 00:08:58.420]   you want to support and be able to accelerate.
[00:08:58.420 --> 00:09:01.660]   And so each one of these industries are a little different.
[00:09:01.660 --> 00:09:10.140]   We try to build-- we build a GPU that is universal in the sense that all of these applications
[00:09:10.140 --> 00:09:13.100]   can run on any of our GPUs.
[00:09:13.100 --> 00:09:18.780]   And that gives developers a very large install base to target.
[00:09:18.780 --> 00:09:22.820]   They know that when they develop on our architecture, it'll run everywhere.
[00:09:22.820 --> 00:09:29.380]   The only question is, in each one of the processors that they run, is it better for scientific
[00:09:29.380 --> 00:09:34.060]   computing, or is it better for machine learning, or is it better for imaging or computer graphics?
[00:09:34.060 --> 00:09:41.140]   And we shape the size of those capabilities, those functionalities, if you will, for the
[00:09:41.140 --> 00:09:44.140]   different applications, different markets that we serve.
[00:09:44.140 --> 00:09:50.780]   So in the case of GeForce, there is no FP64 richness, although it runs.
[00:09:50.780 --> 00:09:52.880]   It runs rather slowly.
[00:09:52.880 --> 00:09:56.740]   In the case of deep learning chips, it'll run computer graphics, but it'll run less
[00:09:56.740 --> 00:10:00.700]   well than GeForce, and so on and so forth.
[00:10:00.700 --> 00:10:08.180]   And so we adjust the size of the functionality to the market that we serve.
[00:10:08.180 --> 00:10:13.220]   And in combination with the software stack that goes on top of it, we should be able
[00:10:13.220 --> 00:10:15.980]   to bring the best products for the use case.
[00:10:15.980 --> 00:10:20.140]   Otherwise, everything is universal, and everything just kind of works-- computer graphics, scientific
[00:10:20.140 --> 00:10:22.420]   computing, training, inference.
[00:10:22.420 --> 00:10:28.340]   We really believe that developers ought to have the largest possible install base and
[00:10:28.340 --> 00:10:31.700]   not worry about whether the software is going to run or not.
[00:10:31.700 --> 00:10:33.600]   It should always run.
[00:10:33.600 --> 00:10:37.980]   The question is whether it runs to its fullest capability.
[00:10:37.980 --> 00:10:38.980]   I see.
[00:10:38.980 --> 00:10:47.460]   Well, another question along those lines is, do you think radical changes are coming?
[00:10:47.460 --> 00:10:52.380]   In particular, do you think quantum computing is something really relevant to you, like
[00:10:52.380 --> 00:10:58.340]   something that will be a practical reality in the next-- like in our lifetimes or the
[00:10:58.340 --> 00:11:00.820]   next five to 10 years?
[00:11:00.820 --> 00:11:07.300]   It will definitely be in our lifetimes, because Lucas, you and I are still pretty young.
[00:11:07.300 --> 00:11:09.180]   And so we'll definitely see it.
[00:11:09.180 --> 00:11:14.060]   However, it's not likely to be in the next five years to be generally useful.
[00:11:14.060 --> 00:11:20.740]   On the other hand, the important thing is-- and this is really the marvelous thing about
[00:11:20.740 --> 00:11:23.020]   machine learning and deep learning.
[00:11:23.020 --> 00:11:30.340]   We've really, in many of the applications, whether it's drug discovery or large combination
[00:11:30.340 --> 00:11:39.140]   planning and optimizations, pathfinding, for example, traveling salesperson problems, these
[00:11:39.140 --> 00:11:46.140]   type of problems that people have historically thought would need quantum computing, because
[00:11:46.140 --> 00:11:50.580]   of machine learning, because of AI, we've made giant leaps.
[00:11:50.580 --> 00:11:54.980]   I mean, it's not Moore's law type leaps.
[00:11:54.980 --> 00:12:01.260]   If you look at the body of work of your customers and our customers and the scientists that
[00:12:01.260 --> 00:12:08.580]   work in both of our companies, in the last 10 years, where Moore's law was moving at
[00:12:08.580 --> 00:12:14.140]   full rate, would have increased performance by probably 100x.
[00:12:14.140 --> 00:12:18.620]   Many applications, because of machine learning and deep learning, it's improved by a million
[00:12:18.620 --> 00:12:19.620]   x.
[00:12:19.620 --> 00:12:20.620]   Totally.
[00:12:20.620 --> 00:12:23.860]   We've improved performance by a million times.
[00:12:23.860 --> 00:12:31.620]   And over the next 10 years, I fully expect that because of a couple of different innovations
[00:12:31.620 --> 00:12:37.600]   between accelerated computing and the further advances that we're expecting in deep learning,
[00:12:37.600 --> 00:12:43.620]   and this new field called physics-informed neural networks, we're doing some really fantastic
[00:12:43.620 --> 00:12:49.940]   work there, in many areas in scientific discovery, we're going to see probably another million
[00:12:49.940 --> 00:12:50.940]   x.
[00:12:50.940 --> 00:12:59.700]   And so a million x advance is something that's kind of hard to wrap your heads around, but
[00:12:59.700 --> 00:13:03.420]   we're going to see that in so many different fields, whether it's in healthcare or climate
[00:13:03.420 --> 00:13:07.980]   science or other fields of physics that are really important to us.
[00:13:07.980 --> 00:13:13.300]   So are you someone that believes that we'll see AGI in our lifetime?
[00:13:13.300 --> 00:13:18.180]   Do you think the singularity is coming?
[00:13:18.180 --> 00:13:20.180]   I don't know about that.
[00:13:20.180 --> 00:13:27.460]   But if we reframe the problem, if we reframe the question just slightly and say, "Will
[00:13:27.460 --> 00:13:33.140]   AI be able to do things that are much, much better than humans can?"
[00:13:33.140 --> 00:13:38.180]   You and I both know that in fact, if you reframe the question that way, AI in many, many fields
[00:13:38.180 --> 00:13:41.020]   are already superhuman.
[00:13:41.020 --> 00:13:49.180]   And I think the number of superhuman skills that AI will learn over the course of the
[00:13:49.180 --> 00:13:52.580]   next decade is quite extraordinary.
[00:13:52.580 --> 00:13:58.660]   I doubt that there'll be many manipulation tasks that are repetitive, that robotics won't
[00:13:58.660 --> 00:14:04.860]   do better than humans, which is one of the reasons why there's so much work in surgical
[00:14:04.860 --> 00:14:07.460]   robotics.
[00:14:07.460 --> 00:14:09.980]   Their hands will never shake.
[00:14:09.980 --> 00:14:15.980]   They'll be able to make the most minute and the most precise of incisions.
[00:14:15.980 --> 00:14:18.300]   And its perception ability is going to be incredible.
[00:14:18.300 --> 00:14:25.660]   And so I think that the coming years, we're going to see superhuman AIs.
[00:14:25.660 --> 00:14:30.300]   They won't be like us, but in many fields of many domains of activities, they'll be
[00:14:30.300 --> 00:14:31.300]   quite incredible.
[00:14:31.300 --> 00:14:38.700]   But I imagine where you sit, you're watching AI help with chip manufacturing and design
[00:14:38.700 --> 00:14:39.700]   better chips.
[00:14:39.700 --> 00:14:44.300]   And you're probably seeing that have compounding returns, which I think is sort of the thesis
[00:14:44.300 --> 00:14:45.900]   behind the singularity, right?
[00:14:45.900 --> 00:14:48.420]   This sort of AI starts to create AI.
[00:14:48.420 --> 00:14:52.100]   You just see this exponential.
[00:14:52.100 --> 00:14:53.100]   That's exactly right.
[00:14:53.100 --> 00:14:57.820]   Look, we're not going to be able to build next generation chips without AI.
[00:14:57.820 --> 00:15:05.380]   And that's kind of a remarkable statement that all of the chip design process, the architecture
[00:15:05.380 --> 00:15:13.620]   process that today, we have five of the world's top 500 supercomputers in our company, and
[00:15:13.620 --> 00:15:18.900]   we are producing software that gets shipped with all of our AI chips.
[00:15:18.900 --> 00:15:25.380]   And without AI, we can't produce software that runs the AI.
[00:15:25.380 --> 00:15:30.980]   And in the future, without AI, we wouldn't be able to design the chips that we use to
[00:15:30.980 --> 00:15:31.980]   run AI.
[00:15:31.980 --> 00:15:34.180]   And so that's right.
[00:15:34.180 --> 00:15:39.860]   The circular positive feedback system is about to go into turbo charge.
[00:15:39.860 --> 00:15:45.180]   And so I have every confidence that the next 10 years, we're going to see even greater
[00:15:45.180 --> 00:15:54.260]   advances, not necessarily at the transistor level, but absolutely at the computation level.
[00:15:54.260 --> 00:16:02.780]   Do you have any concerns about as compute gets more and more important to advances in
[00:16:02.780 --> 00:16:08.340]   science that there's impact on the climate or even impact on access of who's able to
[00:16:08.340 --> 00:16:14.140]   make scientific discoveries or who's able to kind of make the next really exciting company
[00:16:14.140 --> 00:16:19.100]   if they need a supercomputer to do that?
[00:16:19.100 --> 00:16:26.020]   First of all, one of our greatest contributions to the industry is we democratized scientific
[00:16:26.020 --> 00:16:27.660]   computing.
[00:16:27.660 --> 00:16:33.820]   Because of NVIDIA GPUs, the breakthroughs for AlexNet wasn't a supercomputer in the
[00:16:33.820 --> 00:16:36.940]   cloud, it was a GeForce card.
[00:16:36.940 --> 00:16:42.260]   So simultaneously, researchers around the world were buying GeForce GPUs.
[00:16:42.260 --> 00:16:47.060]   And because architecturally, they're all the same as the supercomputers we're building,
[00:16:47.060 --> 00:16:52.820]   they were able to use that to discover the next, the breakthrough that we're all enjoying
[00:16:52.820 --> 00:16:53.900]   today.
[00:16:53.900 --> 00:16:56.980]   The same thing is happening in so many different fields.
[00:16:56.980 --> 00:17:02.220]   And so I'm really proud of the fact that we've democratized high performance computing.
[00:17:02.220 --> 00:17:04.780]   We put it in the hands of any researcher.
[00:17:04.780 --> 00:17:10.100]   They don't have to go get gigantic funds to be able to do their research.
[00:17:10.100 --> 00:17:15.660]   One of the researchers, scientists that was in quantum chemistry, said to me one day that
[00:17:15.660 --> 00:17:20.340]   he had learned from his son who was working at one of the computer companies here in Silicon
[00:17:20.340 --> 00:17:28.900]   Valley that he should go and buy our gaming cards and download the CUDA SDK and port the
[00:17:28.900 --> 00:17:35.940]   quantum chemistry software that he was running on an IBM supercomputer onto our gaming GPU.
[00:17:35.940 --> 00:17:42.860]   And he was so amazed how fast it was, he had to wait for the rest of the week for the supercomputer
[00:17:42.860 --> 00:17:48.580]   to finish so that he could compare the results that it was the same.
[00:17:48.580 --> 00:17:55.380]   And then he went and bought as many GPUs as he could from the retail stores and made himself
[00:17:55.380 --> 00:17:59.220]   a bespoke, homemade supercomputer.
[00:17:59.220 --> 00:18:00.220]   That's awesome.
[00:18:00.220 --> 00:18:05.860]   And he said to me, "Jensen, because of your work, I'm able to do my life's work in my
[00:18:05.860 --> 00:18:06.860]   lifetime."
[00:18:06.860 --> 00:18:10.300]   And in a lot of ways, we built him a time machine.
[00:18:10.300 --> 00:18:14.080]   And he was able to see the future in a way that otherwise couldn't.
[00:18:14.080 --> 00:18:18.940]   And so I think the first contribution is we democratized scientific computing.
[00:18:18.940 --> 00:18:24.580]   The second thing that we did, because of artificial intelligence and this idea of pre-trained
[00:18:24.580 --> 00:18:32.980]   models and transfer learning, we now have the ability to essentially have large companies
[00:18:32.980 --> 00:18:35.320]   pre-train intelligence.
[00:18:35.320 --> 00:18:40.060]   It's almost like creating a whole bunch of new college grads, super well-educated college
[00:18:40.060 --> 00:18:45.940]   grads that are now going off into the world that people can then adapt to their particular
[00:18:45.940 --> 00:18:46.940]   skills.
[00:18:46.940 --> 00:18:51.940]   So in a lot of ways, Lucas, the work that you do, the work that I do, what we've done
[00:18:51.940 --> 00:18:55.500]   is we've actually lowered the bar.
[00:18:55.500 --> 00:18:57.500]   We've democratized intelligence.
[00:18:57.500 --> 00:19:03.060]   We've democratized computer science so that almost anybody can download a pre-trained
[00:19:03.060 --> 00:19:08.860]   model and perform superhuman capabilities for their application domain by retraining
[00:19:08.860 --> 00:19:14.340]   it, by adapting it, by applying a transfer learning capability to it.
[00:19:14.340 --> 00:19:24.580]   And so I think artificial intelligence is the most powerful force that has come along.
[00:19:24.580 --> 00:19:29.300]   And one of its benefits is going to be to democratize computer science.
[00:19:29.300 --> 00:19:37.080]   Now one of the things that you mentioned earlier about energy, I think that one of the greatest
[00:19:37.080 --> 00:19:43.240]   projects we're working on is this thing called Earth 2, which we're going to try to build
[00:19:43.240 --> 00:19:48.940]   a digital twin to mimic the climate of the Earth.
[00:19:48.940 --> 00:19:55.080]   It's a multi-physics problem, thermodynamics and fluid dynamics and chemistry problem and
[00:19:55.080 --> 00:19:59.760]   a biology problem and a human driver problem and economics problem.
[00:19:59.760 --> 00:20:07.780]   And all of it contributes in this geometry aware, because terrain matters, and multi-physics,
[00:20:07.780 --> 00:20:10.660]   mesophysics, mesoscale problem.
[00:20:10.660 --> 00:20:17.060]   And we finally might have the necessary algorithms to be able to take a swing at this and build
[00:20:17.060 --> 00:20:21.880]   a full scale digital twin of the Earth.
[00:20:21.880 --> 00:20:32.080]   And hopefully inspire us by giving us a model to test our mitigation strategies and our
[00:20:32.080 --> 00:20:38.200]   adaptation strategies and simulate whether the technologies we're going to use to absorb
[00:20:38.200 --> 00:20:48.640]   carbon or reduce carbon emission will have the necessary impact a decade, two decades,
[00:20:48.640 --> 00:20:50.140]   four decades from now.
[00:20:50.140 --> 00:20:55.680]   And so if not for deep learning and the work that we're doing, that wouldn't even be possible.
[00:20:55.680 --> 00:20:57.720]   I wouldn't even imagine doing it.
[00:20:57.720 --> 00:20:58.720]   Cool.
[00:20:58.720 --> 00:21:04.640]   So one of the things I wanted to make sure I asked you on a personal level, I guess,
[00:21:04.640 --> 00:21:09.240]   is I've really admired how you've run the same company for a really long time and it
[00:21:09.240 --> 00:21:11.680]   doesn't look like an easy company to run.
[00:21:11.680 --> 00:21:15.840]   I mean, there's a lot going on and a lot of physical things and it clearly hasn't just
[00:21:15.840 --> 00:21:21.960]   been this sort of like, kind of like rocket ship SaaS startup.
[00:21:21.960 --> 00:21:26.480]   And yet you seem very technically current.
[00:21:26.480 --> 00:21:31.960]   It really does seem like you stay on top of trends and keep a level of technical depth.
[00:21:31.960 --> 00:21:37.120]   And I was wondering how you do that, like how you stay educated about what's going on
[00:21:37.120 --> 00:21:41.640]   in scientific computing and machine learning and other topics.
[00:21:41.640 --> 00:21:50.480]   Well I'm a little sleepy right now because I was up at three o'clock reading and there's
[00:21:50.480 --> 00:21:51.480]   just no other way.
[00:21:51.480 --> 00:21:53.040]   I think you just have to keep on learning.
[00:21:53.040 --> 00:21:55.840]   You're just interested in the topic and you just find time.
[00:21:55.840 --> 00:21:56.840]   I don't know.
[00:21:56.840 --> 00:22:00.240]   I wish, Lucas, I wish it was wisdom to pass.
[00:22:00.240 --> 00:22:02.160]   I paused for a second.
[00:22:02.160 --> 00:22:04.160]   Was there a secret?
[00:22:04.160 --> 00:22:05.160]   Nope.
[00:22:05.160 --> 00:22:12.560]   I think partly, of course, is really where's the energy and the curiosity juice coming
[00:22:12.560 --> 00:22:14.520]   from.
[00:22:14.520 --> 00:22:20.420]   Of course, being surrounded by really bright people, you learn from them, which allows
[00:22:20.420 --> 00:22:24.600]   you to combine a lot of your own understanding.
[00:22:24.600 --> 00:22:30.520]   And when you decode a puzzle or you learn something new, it really gets you fired up.
[00:22:30.520 --> 00:22:39.520]   And so I think one of the most important missions, the purpose of a CEO is to create the conditions
[00:22:39.520 --> 00:22:43.000]   where amazing people could do their life's work.
[00:22:43.000 --> 00:22:49.800]   And I really take that very seriously and I try very hard to create a condition where
[00:22:49.800 --> 00:22:55.160]   amazing people could come and be surrounded by other colleagues that are incredible.
[00:22:55.160 --> 00:22:56.600]   That I think contributes a lot to it.
[00:22:56.600 --> 00:23:02.120]   And then the rest of it, as a CEO of a tech company, you really need to enjoy learning
[00:23:02.120 --> 00:23:08.160]   about what's happening in your company, which is plenty to learn, what's happening around
[00:23:08.160 --> 00:23:15.040]   the industry and see if you could imagine a future that is better for everybody.
[00:23:15.040 --> 00:23:20.600]   I think a big part of my learning process that's hard to do running a company is tinkering
[00:23:20.600 --> 00:23:21.600]   and stuff.
[00:23:21.600 --> 00:23:22.600]   I'm wondering if that's...
[00:23:22.600 --> 00:23:23.600]   I think you're originally an engineer.
[00:23:23.600 --> 00:23:29.400]   Do you find time to ever write a little code or put something together?
[00:23:29.400 --> 00:23:33.640]   Not for a long time, but we get to tinker through other people.
[00:23:33.640 --> 00:23:35.320]   And this is the wonderful thing.
[00:23:35.320 --> 00:23:38.560]   NVIDIA is now 24,000 people.
[00:23:38.560 --> 00:23:43.640]   And if I could tinker a little something with everybody, the amount of tinkering that's
[00:23:43.640 --> 00:23:46.600]   going on in the company is incredible.
[00:23:46.600 --> 00:23:51.320]   There's a phrase that I say, I reach out to my friends and I really see them that way.
[00:23:51.320 --> 00:23:56.920]   I reach out to my friends all over the company and we brainstorm a little something and they
[00:23:56.920 --> 00:24:03.280]   go off and try something and somebody else I'm brainstorming with and they try something.
[00:24:03.280 --> 00:24:07.680]   And that's just, I guess, tinkering at scale.
[00:24:07.680 --> 00:24:08.680]   That's super cool.
[00:24:08.680 --> 00:24:11.840]   I love it.
[00:24:11.840 --> 00:24:13.600]   Another question a lot of people ask.
[00:24:13.600 --> 00:24:15.080]   I'm curious.
[00:24:15.080 --> 00:24:19.360]   I think people originally think of NVIDIA as for games.
[00:24:19.360 --> 00:24:20.360]   Are you a gamer at all?
[00:24:20.360 --> 00:24:23.040]   Do you play video games?
[00:24:23.040 --> 00:24:24.560]   I haven't played much games.
[00:24:24.560 --> 00:24:32.360]   I see almost every game that go by because we get the benefit of some collaboration that
[00:24:32.360 --> 00:24:34.480]   we do with just about every game company in the world.
[00:24:34.480 --> 00:24:40.360]   So when they're in the labs, people will tell me and I'll run down and go check it out and
[00:24:40.360 --> 00:24:42.360]   play with it a bit.
[00:24:42.360 --> 00:24:47.920]   But the last time, probably one of my favorite games was when Battlefield first came out
[00:24:47.920 --> 00:24:58.840]   and my kids were teenagers at home and they were both coming into their gaming age and
[00:24:58.840 --> 00:25:03.040]   just the three of us playing online Battlefield was just incredibly fun.
[00:25:03.040 --> 00:25:06.640]   That was probably some of the funnest memories I've ever had.
[00:25:06.640 --> 00:25:07.640]   That's awesome.
[00:25:07.640 --> 00:25:19.280]   I'm curious, a lot of people have been talking about supply chain issues and a global chip
[00:25:19.280 --> 00:25:20.280]   shortage.
[00:25:20.280 --> 00:25:21.800]   Is that something that's on your mind a lot?
[00:25:21.800 --> 00:25:24.840]   Is that a problem for your company?
[00:25:24.840 --> 00:25:25.840]   Sure.
[00:25:25.840 --> 00:25:26.840]   Yeah, sure.
[00:25:26.840 --> 00:25:34.520]   We build the largest chips in the world and the most complex computers in the world.
[00:25:34.520 --> 00:25:37.960]   And DGX is a few hundred pounds.
[00:25:37.960 --> 00:25:38.960]   It's so heavy.
[00:25:38.960 --> 00:25:41.200]   It's the heaviest computer that's being built today.
[00:25:41.200 --> 00:25:46.800]   It is so heavy that it takes a robot to build it like a car.
[00:25:46.800 --> 00:25:53.080]   Most computers don't have to be built that way, but DGX is a miracle of computing and
[00:25:53.080 --> 00:25:58.200]   we built it completely from a blank sheet of paper, wrote all the software and all the
[00:25:58.200 --> 00:26:00.000]   tools that went on top of it.
[00:26:00.000 --> 00:26:07.040]   There's a lot of components inside, especially something that's a few thousand watts.
[00:26:07.040 --> 00:26:08.040]   It's quite a miracle.
[00:26:08.040 --> 00:26:09.040]   Totally.
[00:26:09.040 --> 00:26:13.400]   And so there are a lot of parts that, and all it takes is one diode or one voltage regulator
[00:26:13.400 --> 00:26:15.920]   to keep it from shipping.
[00:26:15.920 --> 00:26:20.280]   So our Nvidia supply chain is quite an amazing machine.
[00:26:20.280 --> 00:26:29.120]   And we know that artificial intelligence is such an amazing thing because we are producing
[00:26:29.120 --> 00:26:30.280]   intelligence.
[00:26:30.280 --> 00:26:37.920]   For the very first time in human history, we are producing, manufacturing intelligence
[00:26:37.920 --> 00:26:39.880]   like production.
[00:26:39.880 --> 00:26:41.360]   Raw material comes in.
[00:26:41.360 --> 00:26:44.000]   A lot of, of course, a lot of genius goes into that box.
[00:26:44.000 --> 00:26:48.000]   And what comes out is intelligence that's refined.
[00:26:48.000 --> 00:26:51.080]   And so large companies are depending on us.
[00:26:51.080 --> 00:26:55.880]   AI is intelligence being manufactured at large scales.
[00:26:55.880 --> 00:27:01.440]   So the teams are working really, really hard to keep up with demand.
[00:27:01.440 --> 00:27:04.200]   You've been running Nvidia for quite a long time.
[00:27:04.200 --> 00:27:09.000]   I was curious how you feel like you've changed as a leader over the decades of running the
[00:27:09.000 --> 00:27:10.000]   company.
[00:27:10.000 --> 00:27:11.000]   Wow.
[00:27:11.000 --> 00:27:12.000]   Wow.
[00:27:12.000 --> 00:27:16.580]   You're almost asking the wrong person.
[00:27:16.580 --> 00:27:18.720]   You could ask almost anybody else around me.
[00:27:18.720 --> 00:27:19.720]   Fair enough.
[00:27:19.720 --> 00:27:21.640]   How has your experience changed?
[00:27:21.640 --> 00:27:29.480]   Okay, that's an easier question for me.
[00:27:29.480 --> 00:27:33.960]   When I was 30 years old, I didn't know anything about being CEO.
[00:27:33.960 --> 00:27:36.960]   And I did a lot of learning on the job.
[00:27:36.960 --> 00:27:42.360]   There were many management techniques that were just really, really dumb.
[00:27:42.360 --> 00:27:44.560]   And I don't use them anymore.
[00:27:44.560 --> 00:27:45.560]   Like what?
[00:27:45.560 --> 00:27:46.560]   Well, okay.
[00:27:46.560 --> 00:27:47.560]   All right.
[00:27:48.560 --> 00:27:52.360]   So I'll give you a couple.
[00:27:52.360 --> 00:27:53.360]   Awesome.
[00:27:53.360 --> 00:27:54.360]   Thank you.
[00:27:54.360 --> 00:27:57.840]   The list of dumb things that I've done over the years is quite large.
[00:27:57.840 --> 00:27:59.760]   I could write a book.
[00:27:59.760 --> 00:28:06.200]   But for example, I really, really wanted in the early days for the chips to tape out.
[00:28:06.200 --> 00:28:11.160]   And so I thought what we needed to do was motivate the engineers to tape out the chip.
[00:28:11.160 --> 00:28:16.320]   And so we had this thing called a tape out bonus.
[00:28:16.320 --> 00:28:18.640]   And that's a supremely dumb idea.
[00:28:18.640 --> 00:28:23.120]   And the reason for that is because if the engineers could have taped out the chip, they
[00:28:23.120 --> 00:28:25.560]   would have.
[00:28:25.560 --> 00:28:29.560]   And so putting that bonus there is unnecessary.
[00:28:29.560 --> 00:28:33.640]   On the other hand, by definition, they're going to be late.
[00:28:33.640 --> 00:28:37.240]   And when they're late, it becomes a demotivator.
[00:28:37.240 --> 00:28:40.240]   And so because they no longer can earn the bonus.
[00:28:40.240 --> 00:28:46.160]   And so the tape out bonus for all the CEOs that are doing it, it's a demotivator, not
[00:28:46.160 --> 00:28:47.160]   a motivator.
[00:28:47.160 --> 00:28:48.760]   It's a little silly.
[00:28:48.760 --> 00:28:54.440]   And I think the answer is a chip gets taped out when a chip is ready to be taped out.
[00:28:54.440 --> 00:28:58.120]   We can create the conditions by which great work can be done.
[00:28:58.120 --> 00:29:02.060]   We can be good listeners and eliminate obstacles for the team.
[00:29:02.060 --> 00:29:09.760]   We could be part of the solution by highlighting issues, recruiting, all kinds of things we
[00:29:09.760 --> 00:29:16.240]   can do to help them reason about priorities and help them reduce the scope of their work
[00:29:16.240 --> 00:29:22.080]   and try to seek the minimum viable product instead of building some giant things.
[00:29:22.080 --> 00:29:26.760]   And there are a lot of different skills that we could have instilled into the organization.
[00:29:26.760 --> 00:29:32.720]   But the one thing that it doesn't really need is a tape out bonus, an achievement bonus.
[00:29:32.720 --> 00:29:35.120]   And because everybody's trying to do their best.
[00:29:35.120 --> 00:29:37.480]   And so that's one example.
[00:29:37.480 --> 00:29:38.480]   That's a great one.
[00:29:38.480 --> 00:29:39.480]   What else?
[00:29:39.480 --> 00:29:40.480]   I'd love to hear that.
[00:29:40.480 --> 00:29:41.480]   Okay, here's another one.
[00:29:41.480 --> 00:29:42.480]   All right.
[00:29:42.480 --> 00:29:51.840]   Well, I want to be diplomatic as well, because there are so many CEOs that are out there
[00:29:51.840 --> 00:29:57.200]   that could be using some of these techniques and I hate to be critical of them.
[00:29:57.200 --> 00:30:00.620]   So this is not a criticism.
[00:30:00.620 --> 00:30:02.360]   This is just my style.
[00:30:02.360 --> 00:30:05.360]   I tend not to do one-on-ones.
[00:30:05.360 --> 00:30:10.240]   And if there's anything that I need to say, I tend to like to say it to the team and the
[00:30:10.240 --> 00:30:17.560]   group that is working on it so that we're all hearing the same things.
[00:30:17.560 --> 00:30:19.040]   I'm hearing the same things.
[00:30:19.040 --> 00:30:22.160]   Everybody else is hearing the same things instead of being translated.
[00:30:22.160 --> 00:30:23.160]   Interesting.
[00:30:23.160 --> 00:30:25.080]   It's a really unusual perspective.
[00:30:25.080 --> 00:30:28.160]   I think a lot of people think you absolutely must do one-on-one.
[00:30:28.160 --> 00:30:29.920]   Do you do that across the company?
[00:30:29.920 --> 00:30:32.760]   Do you think your reports and their reports?
[00:30:32.760 --> 00:30:33.760]   I don't do it.
[00:30:33.760 --> 00:30:37.160]   I don't do it, but I have many leaders who do.
[00:30:37.160 --> 00:30:38.720]   And I don't criticize them for doing it.
[00:30:38.720 --> 00:30:39.720]   I just don't do it.
[00:30:39.720 --> 00:30:46.800]   And the reason it's probably more important for CEOs not to is because you can't eliminate
[00:30:46.800 --> 00:30:52.760]   it completely, but you want to reduce the amount of "Jensen told me" or "Jensen told
[00:30:52.760 --> 00:31:01.760]   me that" as a way to somehow steer a conversation that otherwise should have been done on merits.
[00:31:01.760 --> 00:31:08.560]   And otherwise, instead of my will somehow being translated and repeated and interpreted
[00:31:08.560 --> 00:31:10.120]   through a chain.
[00:31:10.120 --> 00:31:13.960]   And so if I had a particular objection towards something, I would say it to more than one
[00:31:13.960 --> 00:31:15.520]   person.
[00:31:15.520 --> 00:31:20.360]   And if I believe that in working with the rest of the company, a particular strategy
[00:31:20.360 --> 00:31:24.240]   or direction ought to be taken, I would tell everybody at the same time.
[00:31:24.240 --> 00:31:31.920]   And so I tend, I've worked towards this approach because I feel it's much more transparent.
[00:31:31.920 --> 00:31:39.000]   It puts knowledge and the access to information in the hands of as many people as possible.
[00:31:39.000 --> 00:31:43.920]   And of course, it of course attracts more criticism to myself.
[00:31:43.920 --> 00:31:47.120]   For example, I might say something to 10 people and it's the dumbest thing in the world to
[00:31:47.120 --> 00:31:48.120]   say.
[00:31:48.120 --> 00:31:51.320]   And it was a terrible idea.
[00:31:51.320 --> 00:31:53.440]   Couldn't be the worst possible strategy.
[00:31:53.440 --> 00:31:57.980]   But instead of saying it to one person, I don't get the benefit of refining my ideas
[00:31:57.980 --> 00:32:01.160]   and then broadcasting it and always be a genius.
[00:32:01.160 --> 00:32:07.960]   And so I would therefore in this technique, you need to be a little bit more vulnerable
[00:32:07.960 --> 00:32:13.800]   and you need to be able to deal with the fact that every so often you said something that
[00:32:13.800 --> 00:32:14.800]   wasn't perfect.
[00:32:14.800 --> 00:32:19.780]   And nobody holds me to a standard that needs to be perfect anyhow.
[00:32:19.780 --> 00:32:26.800]   And so after nearly 30 years, I've kind of worked my way past that.
[00:32:26.800 --> 00:32:29.640]   So if I say something dumb, don't hold me to it.
[00:32:29.640 --> 00:32:32.840]   Give me a chance to change my mind.
[00:32:32.840 --> 00:32:39.280]   Is it a different experience running a company where it feels like it's struggling versus
[00:32:39.280 --> 00:32:44.080]   now where the stock seems really high and probably everyone's feeling really good about
[00:32:44.080 --> 00:32:45.080]   the prospects?
[00:32:45.080 --> 00:32:48.960]   Do you have to do different things in those different situations?
[00:32:48.960 --> 00:32:52.360]   I'm never different.
[00:32:52.360 --> 00:32:58.280]   I don't think it's possible to find a correlation between my behavior and the stock price.
[00:32:58.280 --> 00:33:03.960]   And I would say for 29 years, my behavior and the way that I approach problems, the
[00:33:03.960 --> 00:33:10.520]   way I approach people, the way I approach a company or work, exactly the same.
[00:33:10.520 --> 00:33:12.280]   There's no correlation whatsoever.
[00:33:12.280 --> 00:33:15.520]   And you just got to give me a second.
[00:33:15.520 --> 00:33:18.520]   I'll find all kinds of issues to talk about.
[00:33:18.520 --> 00:33:21.080]   So I've got nothing but problems.
[00:33:21.080 --> 00:33:23.520]   CEOs are surrounded by problems, not good news.
[00:33:23.520 --> 00:33:26.120]   And so I happen to enjoy that.
[00:33:26.120 --> 00:33:27.680]   I enjoy solving problems.
[00:33:27.680 --> 00:33:36.160]   And so I completely separate the financial success of the company from the importance
[00:33:36.160 --> 00:33:38.920]   of the work and doing impactful work.
[00:33:38.920 --> 00:33:44.160]   And so I've historically always done that, whether the company is doing well or badly.
[00:33:44.160 --> 00:33:48.600]   When we're doing badly, particularly during the time when we bet the farm on accelerated
[00:33:48.600 --> 00:33:53.000]   computing, we wanted every single chip to have the same architecture that I mentioned
[00:33:53.000 --> 00:33:54.000]   earlier.
[00:33:54.000 --> 00:33:59.320]   The pressure on our financial performance was immense.
[00:33:59.320 --> 00:34:05.280]   But I was equally as enthusiastic then and believed as much in the future as I do today.
[00:34:05.280 --> 00:34:06.280]   That's incredible.
[00:34:06.280 --> 00:34:10.720]   You don't feel the outside pressure at all, or are you able to sort of separate yourself
[00:34:10.720 --> 00:34:11.720]   from it?
[00:34:11.720 --> 00:34:19.160]   No, as a public company, you're going to feel a lot of outside pressure.
[00:34:19.160 --> 00:34:25.080]   And some investors are really artful in expressing this pleasure and criticism.
[00:34:25.080 --> 00:34:30.320]   And some investors are understandably less patient.
[00:34:30.320 --> 00:34:34.800]   But it's our job to express the reason why we're doing what we're doing.
[00:34:34.800 --> 00:34:38.240]   CEOs, we have to be reasoned.
[00:34:38.240 --> 00:34:40.920]   We have to have a purpose by which we're doing something.
[00:34:40.920 --> 00:34:46.120]   If we're clear in expressing why we're doing something and our vision for it, and we genuinely
[00:34:46.120 --> 00:34:48.960]   believe it, we genuinely believe it.
[00:34:48.960 --> 00:34:52.740]   My experience has been that people are willing to give it a shot.
[00:34:52.740 --> 00:34:59.760]   And so when we first started our company, consumer 3D graphics didn't exist.
[00:34:59.760 --> 00:35:01.160]   Even APIs for it didn't exist.
[00:35:01.160 --> 00:35:03.520]   And we had to go evangelize that.
[00:35:03.520 --> 00:35:05.240]   And it took longer than people thought.
[00:35:05.240 --> 00:35:11.000]   When we moved into accelerated computing for about 15 years, it didn't exist.
[00:35:11.000 --> 00:35:12.880]   And so it took longer than I thought.
[00:35:12.880 --> 00:35:17.520]   I thought it was going to take two years, but it took 15.
[00:35:17.520 --> 00:35:19.000]   And AI was the same way.
[00:35:19.000 --> 00:35:24.960]   I spoke endlessly about the importance of machine learning and deep learning.
[00:35:24.960 --> 00:35:30.640]   For the first five, six, seven years, I think people just didn't get it, which is fine.
[00:35:30.640 --> 00:35:36.080]   It's kind of part of building a new market and building a new approach.
[00:35:36.080 --> 00:35:39.840]   You have to recognize that it takes time for people to come along.
[00:35:39.840 --> 00:35:44.720]   So I think the industry has been really patient with us, and our employees have been very
[00:35:44.720 --> 00:35:49.000]   patient with me, and I've really appreciated it.
[00:35:49.000 --> 00:35:51.720]   So what's the thing that really motivates you right now?
[00:35:51.720 --> 00:35:58.760]   What's the purpose that you feel like you're serving at this moment?
[00:35:58.760 --> 00:36:03.720]   The company doesn't have a mission statement, but nobody's confused at our company and what
[00:36:03.720 --> 00:36:05.760]   the mission is.
[00:36:05.760 --> 00:36:14.280]   And it really is as simple as do impactful work that takes a very long time to succeed
[00:36:14.280 --> 00:36:20.480]   because it has to be hard for it to be meaningful for our people, and that we are the best in
[00:36:20.480 --> 00:36:22.580]   the world at solving.
[00:36:22.580 --> 00:36:24.200]   And so we seek those problems.
[00:36:24.200 --> 00:36:26.560]   I seek those problems.
[00:36:26.560 --> 00:36:30.920]   There are two areas that I'm super excited about right now.
[00:36:30.920 --> 00:36:41.000]   One area is recognizing that we, in several domains, have invented the intelligence capability,
[00:36:41.000 --> 00:36:49.160]   the technology of intelligence, whether it's in perception or speech AI or language understanding.
[00:36:49.160 --> 00:36:54.640]   We're now able to have some of these technologies that can do these things.
[00:36:54.640 --> 00:36:58.760]   However, ultimately what's valuable is not intelligence.
[00:36:58.760 --> 00:37:02.060]   Ultimately what's valuable is skills.
[00:37:02.060 --> 00:37:07.000]   We hire new college grads with lots of intelligence, but very few skills.
[00:37:07.000 --> 00:37:11.400]   And then we give them skills by adapting them to domains.
[00:37:11.400 --> 00:37:18.120]   And in a lot of ways, that's essentially what is missing right now is to take the intelligence
[00:37:18.120 --> 00:37:21.960]   technology and translate it into valuable skills.
[00:37:21.960 --> 00:37:30.120]   Valuable skills, whether it's driving autonomous vehicles, valuable skills like customer service
[00:37:30.120 --> 00:37:35.400]   and call centers and such, valuable skills like automated checkout.
[00:37:35.400 --> 00:37:42.680]   It could be automated skills like radiology and put a radiologist right into the instrument.
[00:37:42.680 --> 00:37:48.560]   So there are all kinds of really valuable skills that we can now create.
[00:37:48.560 --> 00:37:53.360]   And so that's a big part of where our energy is right now, is how to take this enabling
[00:37:53.360 --> 00:37:59.720]   technology and translate them into skills that customers in the industry, developers,
[00:37:59.720 --> 00:38:02.000]   could then adapt for all kinds of different domains.
[00:38:02.000 --> 00:38:08.040]   So that's one, the large scale application of artificial intelligence.
[00:38:08.040 --> 00:38:11.480]   Second is the next era of AI.
[00:38:11.480 --> 00:38:16.400]   We've done a really good job with soft AI that's in the cloud and recommending music,
[00:38:16.400 --> 00:38:21.680]   recommending movies and next item in the cart and so on and so forth.
[00:38:21.680 --> 00:38:26.040]   And it's really, really incredible.
[00:38:26.040 --> 00:38:31.840]   The thing that we would really like to do is to, if we want to take AI into the point
[00:38:31.840 --> 00:38:37.760]   of where people are and into this next phase of its journey, AI has to learn the laws of
[00:38:37.760 --> 00:38:39.280]   physics.
[00:38:39.280 --> 00:38:44.400]   And so many of the world's challenges, whether it's climate science or autonomous vehicles
[00:38:44.400 --> 00:38:49.160]   or manufacturing or whatever it is, the AI can't just make a prediction, it has to make
[00:38:49.160 --> 00:38:53.640]   a prediction that obeys the laws of physics and conservation of matter, conservation of
[00:38:53.640 --> 00:38:55.840]   energy and such.
[00:38:55.840 --> 00:38:59.160]   And it has to understand a concept of synchronous time.
[00:38:59.160 --> 00:39:02.560]   It has to be working within our time.
[00:39:02.560 --> 00:39:07.600]   So there are a lot of these types of problems that are really impossible to develop that
[00:39:07.600 --> 00:39:14.200]   AI, unless we have something that is essentially a virtual world that obeys the laws of physics,
[00:39:14.200 --> 00:39:16.400]   which is the reason why we built Omniverse.
[00:39:16.400 --> 00:39:19.720]   We built Omniverse so that several things could happen.
[00:39:19.720 --> 00:39:23.800]   It's physically based, it's distributed, it's very large, it has the ability to support
[00:39:23.800 --> 00:39:26.200]   very large models.
[00:39:26.200 --> 00:39:28.040]   And the goal is several folds.
[00:39:28.040 --> 00:39:34.680]   One, it could teach a robot how to be a well-functioning robot in this physically based environment.
[00:39:34.680 --> 00:39:40.320]   You could connect it to IoT systems, for example, running a robot hardware in a loop.
[00:39:40.320 --> 00:39:47.520]   And so it has the ability to be connected to the physical world and stay synchronized,
[00:39:47.520 --> 00:39:50.280]   meaning to build a digital twin.
[00:39:50.280 --> 00:39:55.320]   The concept of a digital twin has been around for some time, but in combination with artificial
[00:39:55.320 --> 00:40:00.920]   intelligence, the digital twin is going to have a profound impact on the future.
[00:40:00.920 --> 00:40:04.200]   And so I'm super excited about these areas.
[00:40:04.200 --> 00:40:09.160]   One is just the application and then the other is the next phase of AI.
[00:40:09.160 --> 00:40:11.080]   And that's what Omniverse is all about.
[00:40:11.080 --> 00:40:18.200]   Yeah, I totally agree that things like Omniverse are really critical for making robotics work.
[00:40:18.200 --> 00:40:24.400]   It sounds like you're interested in getting yourself, I mean, your company closer to the
[00:40:24.400 --> 00:40:25.880]   applications of AI.
[00:40:25.880 --> 00:40:27.320]   Is that right?
[00:40:27.320 --> 00:40:33.160]   We will stay a couple of clicks away from the actual application.
[00:40:33.160 --> 00:40:38.840]   But what we would do is we would create an application framework for people who are building
[00:40:38.840 --> 00:40:41.960]   applications to build applications.
[00:40:41.960 --> 00:40:46.880]   And one of the application frameworks that I'm really excited about created a little
[00:40:46.880 --> 00:40:50.560]   demo they call Toy Jensen at the last keynote.
[00:40:50.560 --> 00:40:56.640]   And basically it's a robot, but it's a virtual robot, otherwise known as an avatar.
[00:40:56.640 --> 00:41:03.200]   It has computer vision, it does speech AI, it understands language, so on and so forth.
[00:41:03.200 --> 00:41:10.120]   I'm super excited about that because in the future, many applications, we really need
[00:41:10.120 --> 00:41:14.000]   to go into the application to experience it.
[00:41:14.000 --> 00:41:19.440]   Whether it's a virtual factory or virtual hospital or whatnot, it could be for entertainment
[00:41:19.440 --> 00:41:24.240]   like Metaverse and the next era of the internet.
[00:41:24.240 --> 00:41:29.920]   You want to go into that world and the way to go into that world is through a wormhole
[00:41:29.920 --> 00:41:30.920]   called VR.
[00:41:30.920 --> 00:41:32.720]   And so we can go into that world.
[00:41:32.720 --> 00:41:37.520]   Now we could also have those agents come out of that world and to collaborate with us.
[00:41:37.520 --> 00:41:44.040]   And so they would come out through the wormhole called AR and be in our world.
[00:41:44.040 --> 00:41:50.800]   But otherwise, the Metaverse is enjoyed using my favorite display, which is a computer display.
[00:41:50.800 --> 00:41:55.200]   People think that you need to wear head-mount displays for the Metaverse, but it's further
[00:41:55.200 --> 00:41:56.400]   from the truth.
[00:41:56.400 --> 00:41:59.800]   The Metaverse will be enjoyed largely on 2D displays.
[00:41:59.800 --> 00:42:00.800]   Interesting.
[00:42:00.800 --> 00:42:04.840]   Well, look, we always end with two questions and I want to make sure that I get them in.
[00:42:04.840 --> 00:42:08.840]   So the second to last question, and you've touched on some of these topics, but I'm curious
[00:42:08.840 --> 00:42:14.160]   when you look at machine learning, do you feel like there's a question that's underexplored?
[00:42:14.160 --> 00:42:18.960]   You would recommend to a grad student to look into, or if you had more time, you'd like
[00:42:18.960 --> 00:42:21.080]   to spend some more time investigating?
[00:42:21.080 --> 00:42:26.760]   Well, some of the resource work that's being done right now, there's so many smart people
[00:42:26.760 --> 00:42:30.680]   doing this and they're working on it because it's really important.
[00:42:30.680 --> 00:42:36.100]   The self-supervised machine learning approaches that are multi-modality, Lucas, that's going
[00:42:36.100 --> 00:42:40.860]   to drive the living daylights out of both the tools that you're building, the platforms
[00:42:40.860 --> 00:42:43.320]   you're building, and the platforms we're building.
[00:42:43.320 --> 00:42:53.160]   And so multi-modality AI, where you have vision and the vision doesn't have to just be images,
[00:42:53.160 --> 00:43:00.560]   it could be video, it could be speech and natural language, that's going to take perception
[00:43:00.560 --> 00:43:01.960]   to a brand new level.
[00:43:01.960 --> 00:43:03.720]   I'm super excited about that.
[00:43:03.720 --> 00:43:13.720]   I'm excited about zero-shot learning, and to be able to learn from whatever you're trained
[00:43:13.720 --> 00:43:22.880]   on plus the priors that you have is really quite exciting and powerful.
[00:43:22.880 --> 00:43:35.040]   I think that one of the areas that is being explored now is to project the framework of
[00:43:35.040 --> 00:43:40.760]   graphs into the framework of deep learning or graph neural networks.
[00:43:40.760 --> 00:43:47.360]   Graph neural networks, graphs of course, the relationship of things, basically is a structure
[00:43:47.360 --> 00:43:51.920]   that can describe almost everything meaningful in life.
[00:43:51.920 --> 00:43:54.800]   And so that's why it's so useful.
[00:43:54.800 --> 00:44:03.720]   But the processing of graphs is cumbersome and the breakthroughs with DGL and GNN and
[00:44:03.720 --> 00:44:12.160]   geometric and all of that to project the graph into the framework, the constructs of a deep
[00:44:12.160 --> 00:44:20.080]   learning pipeline puts it into our world where deep learning has been so effective.
[00:44:20.080 --> 00:44:25.200]   And so I'm excited about that and I hope that a lot more people does that work.
[00:44:25.200 --> 00:44:35.960]   And then lastly, I think there will be more innovation and more design and more creativity
[00:44:35.960 --> 00:44:44.040]   that's going to be done in the virtual world than all of the creativity and design that
[00:44:44.040 --> 00:44:46.580]   has ever been done in the physical world.
[00:44:46.580 --> 00:44:53.760]   And so what people call the metaverse is going to be just brand new pioneering ground for
[00:44:53.760 --> 00:45:00.200]   manufacturing, for design, for artists, for entertainment of all kinds.
[00:45:00.200 --> 00:45:02.280]   So I'm super excited about that.
[00:45:02.280 --> 00:45:03.800]   There's so many things to work on.
[00:45:03.800 --> 00:45:04.800]   Awesome.
[00:45:04.800 --> 00:45:05.800]   That was a great answer.
[00:45:05.800 --> 00:45:09.680]   I guess our final question in the last few minutes we have, there's kind of this trope
[00:45:09.680 --> 00:45:14.480]   that machine learning, especially deep learning projects almost never see the light of day
[00:45:14.480 --> 00:45:18.560]   that they're way harder to manage than traditional engineering.
[00:45:18.560 --> 00:45:25.040]   I'm curious when you look across your customer base, what are the kind of most common issues
[00:45:25.040 --> 00:45:31.080]   that prevent machine learning from really solving the problems that customers actually
[00:45:31.080 --> 00:45:32.080]   have?
[00:45:32.080 --> 00:45:33.600]   Yeah, this is really great.
[00:45:33.600 --> 00:45:35.320]   And it's a great question.
[00:45:35.320 --> 00:45:43.800]   It's also one of the things I love most about your company and the way you think about this.
[00:45:43.800 --> 00:45:52.240]   You know, there's a fundamental difference between the technology of deep learning and
[00:45:52.240 --> 00:46:00.680]   the harnessing of deep learning and machine learning to write software.
[00:46:00.680 --> 00:46:12.120]   The importance of the methods and the process and the tools, that is so vital.
[00:46:12.120 --> 00:46:16.440]   What could be described as ML ops is so vital.
[00:46:16.440 --> 00:46:22.680]   You have to understand not just the neural network architecture and be able to invent
[00:46:22.680 --> 00:46:28.460]   something that produces excellent results is of course groundbreaking work there already
[00:46:28.460 --> 00:46:29.640]   by itself.
[00:46:29.640 --> 00:46:33.960]   But a company in order to take advantage of this has to realize that in final analysis,
[00:46:33.960 --> 00:46:36.840]   this is a intelligence factory.
[00:46:36.840 --> 00:46:38.840]   You have to think of it kind of like a factory.
[00:46:38.840 --> 00:46:41.240]   That's the reason why the word ops kind of makes sense.
[00:46:41.240 --> 00:46:43.040]   It's a factory.
[00:46:43.040 --> 00:46:46.680]   You have the raw material coming in, which is the data.
[00:46:46.680 --> 00:46:51.320]   It gets transformed in the middle through a lot of stages of very complicated transformation,
[00:46:51.320 --> 00:46:59.220]   as you know, which is one of the reasons why your tools are so popular.
[00:46:59.220 --> 00:47:05.840]   It's really complicated stuff and be able to manage that workflow in a productive way
[00:47:05.840 --> 00:47:13.320]   to transform that raw material into ultimately an output that is neural network or otherwise
[00:47:13.320 --> 00:47:19.920]   intelligence at scale is quite a significant process.
[00:47:19.920 --> 00:47:25.560]   And because it's a fundamentally new way of thinking about computer science, we used to
[00:47:25.560 --> 00:47:28.840]   have just engineers do it.
[00:47:28.840 --> 00:47:32.800]   And I don't mean just in that way, but we had engineers do it.
[00:47:32.800 --> 00:47:39.520]   But now we have engineers backed up by giant supercomputers that are operating these incredible
[00:47:39.520 --> 00:47:44.480]   operations software stack that you build.
[00:47:44.480 --> 00:47:50.480]   And so the refining process, the continuous refining process, the validation process,
[00:47:50.480 --> 00:47:59.280]   the simulation process, that entire process had to be reinvented for machine learning,
[00:47:59.280 --> 00:48:01.280]   reinvented for deep learning.
[00:48:01.280 --> 00:48:06.840]   And this is the reason why your work is so important.
[00:48:06.840 --> 00:48:08.400]   And you guys are doing a great job.
[00:48:08.400 --> 00:48:14.560]   And I really appreciate the work that you do and all the researchers that you support
[00:48:14.560 --> 00:48:16.480]   and all the workflows that you're making possible.
[00:48:16.480 --> 00:48:23.440]   But this is what every company needs to understand, that software development in the future is
[00:48:23.440 --> 00:48:26.160]   a bit of a refinery process.
[00:48:26.160 --> 00:48:27.880]   It's a refinement process.
[00:48:27.880 --> 00:48:29.520]   It's an MLOps process.
[00:48:29.520 --> 00:48:31.560]   It's manufacturing.
[00:48:31.560 --> 00:48:32.960]   Well thanks so much.
[00:48:32.960 --> 00:48:36.000]   That's really kind of you and I'm touched.
[00:48:36.000 --> 00:48:37.000]   I appreciate it.
[00:48:37.000 --> 00:48:39.040]   Keep up the great work.
[00:48:39.040 --> 00:48:43.440]   If you're enjoying these interviews and you want to learn more, please click on the link
[00:48:43.440 --> 00:48:48.160]   to the show notes in the description where you can find links to all the papers that
[00:48:48.160 --> 00:48:52.560]   are mentioned, supplemental material, and a transcription that we work really hard to
[00:48:52.560 --> 00:48:53.560]   produce.
[00:48:53.560 --> 00:48:54.060]   So check it out.

