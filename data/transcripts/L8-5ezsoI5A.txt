
[00:00:00.000 --> 00:00:20.880]   Hello, everyone. My name is Diego Rodriguez. I am co-founder and CTO at CREA. We're building
[00:00:20.880 --> 00:00:24.920]   an AI creative suite. I'm going to tell you three stories and then I'll try to hire you.
[00:00:24.920 --> 00:00:36.680]   So a friend once told me, if you think about it, cars are easy to predict, right? It's like
[00:00:36.680 --> 00:00:40.760]   you get the horse, you have the wheels, you swap the horse, and you put an engine, which was known
[00:00:40.760 --> 00:00:51.160]   at the time, and that's a car. But you know what's really hard to predict? Traffic. So it's my job to
[00:00:51.160 --> 00:00:57.800]   ask, what are the traffic that we're missing, especially with AI? You know, YAML, JSON, MCP,
[00:00:57.800 --> 00:01:05.480]   whatever it is, like, okay, okay, but like, what happens when you generate a million images per day,
[00:01:05.480 --> 00:01:15.240]   like we do for one studio? Where do you find that? Another story, Tower of Babel, we wanted to reach
[00:01:15.240 --> 00:01:23.400]   heaven. God was like, no, created a bunch of languages and basically misunderstanding was like,
[00:01:23.400 --> 00:01:28.120]   nope, we are not going to go there. And it reminds me of stand-up meetings where people are like,
[00:01:28.120 --> 00:01:32.120]   no, it should be React. No, no, no, but like, it should be like JavaScript. I was like, dude,
[00:01:32.120 --> 00:01:49.400]   I'm not going to go there. We're not going to go there. And so this is only like people trying to
[00:01:49.400 --> 00:01:55.080]   convey ideas, and that's what we're trying to tell, just trying to tell stories. The final story is,
[00:01:55.080 --> 00:02:04.920]   I was talking with someone from Netflix, and she was like, what happens when we are making so much
[00:02:04.920 --> 00:02:14.200]   content personalized to each town in India? How do I even find that? Like, right? And then a few days
[00:02:14.200 --> 00:02:22.040]   ago, I just realized that Korea was already being used for broadcasting an ad with Fox to millions of
[00:02:22.040 --> 00:02:26.120]   people. And then I look and they literally signed up two days ago. So we went from sign up to
[00:02:26.120 --> 00:02:30.920]   conversion to payment to broadcast in two days. And then this was the CTO telling me that. I was like,
[00:02:30.920 --> 00:02:32.920]   whoa.
[00:02:32.920 --> 00:02:41.400]   I basically, I'm about to run out of time. So the mandatory slide, a bunch of users, 25 million,
[00:02:41.400 --> 00:02:46.520]   raised a bunch of money. We did this with eight people. Some of the people who are using us, an email
[00:02:46.520 --> 00:02:51.640]   that I created for today that is going to prioritize applications. Thank you.
[00:02:51.640 --> 00:03:03.720]   - All right. Open home. Okay, everybody. The smartphone was the number one best selling consumer
[00:03:03.720 --> 00:03:12.360]   product last year. And the laptop was the second. Pop quiz for all you hear. What was the third?
[00:03:12.360 --> 00:03:21.000]   Apple watch. Wasn't Apple watch. Wasn't the air pod. No, I think I heard it. It was a smart speaker.
[00:03:21.000 --> 00:03:30.600]   500 million smart speakers were sold last year. But why do they still suck? You can barely talk to them.
[00:03:30.600 --> 00:03:37.240]   There's no customization. There's no community. There's nothing. That's why we built Open Home.
[00:03:37.240 --> 00:03:44.200]   The very first AI driven smart speaker. And we're letting you guys build smart speakers too.
[00:03:44.200 --> 00:03:51.080]   And we believe here that the future is talking with AI. You should be able to talk seamlessly,
[00:03:51.080 --> 00:03:56.040]   intuitively. In fact, you shouldn't have to use this really awkward command based language. You should be
[00:03:56.040 --> 00:04:01.800]   able to just chat naturally. So that's what we're building. And we're letting people here today build
[00:04:01.800 --> 00:04:10.200]   their own smart speakers and build them in whatever form that they want. And the key here is developer
[00:04:10.200 --> 00:04:18.040]   ecosystems. And, well, we know developer ecosystems. I started my career as the chief of staff for the
[00:04:18.040 --> 00:04:25.320]   founder of Splunk, a $30 billion big data company. Then I was on the founding team of MakerDAO, a $5
[00:04:25.320 --> 00:04:33.560]   billion developer ecosystem. My co-founder and I raised $50 million for our last business, a big data
[00:04:33.560 --> 00:04:40.280]   privacy tool. And we sold that business. But it all came down to developers and really building what people
[00:04:40.280 --> 00:04:48.120]   actually wanted. And, well, now with Open Home, we have over 10,000 developers building on Open Home.
[00:04:48.120 --> 00:04:52.280]   They're building all kinds of interesting things, all types of different custom smart speakers,
[00:04:52.280 --> 00:04:59.080]   building interesting voice AI applications. Sky's really the limit. And, well, what do developers really
[00:04:59.080 --> 00:05:07.560]   want? They want open source, they want LLM driven, and they want fully jailbroken. They want Open Home,
[00:05:07.560 --> 00:05:13.960]   the AI smart speaker. And now what's really exciting is with voice AI, you can put it on any type of
[00:05:13.960 --> 00:05:20.760]   hardware. We have developers building talking toys, AI robots, AI appliances. You should be able to talk to
[00:05:20.760 --> 00:05:25.720]   the world around you in a much more natural way. And you can do that now with Open Home in AI smart speaker.
[00:05:27.320 --> 00:05:33.160]   Here's our dashboard. We have many, many applications, hundreds of applications that have been built,
[00:05:33.160 --> 00:05:39.320]   games, personalities. We have an editor that you guys can go in and build, and all kinds of interesting things,
[00:05:39.320 --> 00:05:47.400]   home automation tools. And what's really exciting is our last dev kit got booked up within minutes.
[00:05:47.400 --> 00:05:53.560]   And today we have a special announcement for you guys here today. We're releasing the next batch of 500 dev kits
[00:05:53.560 --> 00:05:59.080]   for free for everybody here. If you guys want it, we will ship you a dev kit. It's very cool. You can
[00:05:59.080 --> 00:06:05.240]   build on it. You can talk with AI. You can build your own smart speaker here. And we're doing it today.
[00:06:05.240 --> 00:06:12.680]   Thank you so much. How's it going, y'all? I'm Josh. I'm the founder of a company called CoFrame. The
[00:06:12.680 --> 00:06:19.240]   last company that I started, we scaled to over $2 billion in the course of a couple of years. But when I started to
[00:06:19.240 --> 00:06:27.160]   tinker on using AI to generate code and created one of the actual top autonomous coding agents on GitHub,
[00:06:27.160 --> 00:06:31.640]   was number one on GitHub for a week, I realized it was time to build something bigger.
[00:06:31.640 --> 00:06:40.520]   The internet is dead. It's not adaptive. It's not personal. It's not truly living in a sense. Websites
[00:06:40.520 --> 00:06:48.280]   are all one size fits all. And we're bringing that concept to life. We are giving websites a life of
[00:06:48.280 --> 00:06:55.480]   their own, giving every single customer experience its own AI growth team. But this isn't just a pipe
[00:06:55.480 --> 00:07:03.720]   dream. We made $20 million for Europe's largest travel company in just a few weeks. We increased
[00:07:03.720 --> 00:07:08.920]   click-through rate for India's largest company, a $400 billion enterprise, also in a few weeks.
[00:07:08.920 --> 00:07:14.840]   And how are we doing it? We're working with the best and we have the best. We're the only marketing
[00:07:14.840 --> 00:07:19.320]   tech company that's partnered directly with OpenAI to date. And they actually called our team Cracked,
[00:07:19.320 --> 00:07:23.960]   which is cool. So if you're interested in learning more about this, reach out. Thank you.
[00:07:23.960 --> 00:07:35.400]   Hi. I'm Eugene. I'm sorry. My team is obsoleting all the AI models you see today.
[00:07:35.400 --> 00:07:42.680]   Because you see, my team built CoreKey 72B, the world's largest model without the transformer
[00:07:42.680 --> 00:07:49.320]   attention with only eight GPUs. And this allows us to have a thousand x lower inference on our new
[00:07:49.320 --> 00:07:56.520]   architecture without performing the same. Surprisingly, the technology that we build can
[00:07:56.520 --> 00:08:01.880]   also be applied to existing transformer models through speculative decoding. Nothing too big,
[00:08:01.880 --> 00:08:08.680]   nothing too important. But here's my hot take. Scale is dead. And I'm not saying this just from my own
[00:08:08.680 --> 00:08:15.800]   opinion. Like, we are burning billions into making AI models bigger. But at the same time, the deep mind
[00:08:15.800 --> 00:08:19.880]   founder and CEO is saying compound AI agent errors will take more than 10 years to fix.
[00:08:19.880 --> 00:08:24.840]   Yan Leku is even saying that we need a new AI architecture to push the paradigm forward.
[00:08:24.840 --> 00:08:34.840]   And in production, we see over 90% of AI projects fail. The reason behind this is not something that scale
[00:08:34.840 --> 00:08:44.600]   can fix. The problem is reliability. The thing is, like, would you order and use an app that only succeeds
[00:08:44.600 --> 00:08:52.040]   45% of the time? Would you order DoorDash that way? Of course not. If your order goes missing or you end up
[00:08:52.040 --> 00:08:56.440]   having 100 pizza, you're going to start with customer support screaming down there. It's a frustrating
[00:08:56.440 --> 00:09:01.400]   experience. But that's what AI agents do. When they work, they're awesome. When they don't work,
[00:09:01.400 --> 00:09:06.360]   we are stuck cleaning up the mess. And that's even with frontier models. And here's the thing.
[00:09:07.240 --> 00:09:14.200]   What companies want is not a smarter model that can do PhD-level math. The models are really smart enough.
[00:09:14.200 --> 00:09:19.720]   But what we actually really want is the models reliable enough to book airline tickets, sort out emails,
[00:09:19.720 --> 00:09:26.680]   or file our taxes and invoices. That's what we actually want. And that is what we are building at Federalist AI.
[00:09:26.680 --> 00:09:38.120]   AGI that's made reliable for each one of you. And most recently, we are in our research, that we
[00:09:38.120 --> 00:09:44.280]   actually shown that we build an action R1 agent that beats cloud force on it and Gemini and open AI.
[00:09:44.280 --> 00:09:50.120]   This model is not going to do PhD-level math. But it's going to fill up the form with absolute
[00:09:50.120 --> 00:09:58.040]   reliability better than the frontier. And that's the thing. Like, are we going to burn billions more to
[00:09:58.040 --> 00:10:03.480]   make a smarter model that is just a few percentage points higher IQ? Or are we going to make something
[00:10:03.480 --> 00:10:09.320]   that's 99.9% reliable for the boring things in life? Because this is where the money is for all of you.
[00:10:09.320 --> 00:10:16.760]   Because think of it, as AI engineers, reliability is revenue. For every use case you unlock and find,
[00:10:16.760 --> 00:10:23.880]   you're going to do a billion-dollar app in e-commerce or in B2B sales. And that is something that all of
[00:10:23.880 --> 00:10:29.000]   you can build on, not rocket science. And that's what we are building. And if you're excited about it,
[00:10:29.000 --> 00:10:31.320]   feel free to reach out to us. I'm Eugene at Federalist.com.
[00:10:31.320 --> 00:10:42.200]   My name is Jonas. I'm an engineer. And I like working with data. I love working with data. Actually,
[00:10:42.200 --> 00:10:46.600]   I love it so much. I dropped out of high school when I was 15. I got on a plane.
[00:10:46.600 --> 00:10:50.920]   I moved across the country to California. And I joined a startup called Branch.
[00:10:50.920 --> 00:10:55.000]   You might have heard of it. Anytime you were clicking one of those links on your phone for an app,
[00:10:55.000 --> 00:11:00.600]   that was probably us. I also led a team there that built a search engine that over 100 million people
[00:11:00.600 --> 00:11:07.480]   used every day. And then last year, I left along with one of the founders of Branch to tackle an even
[00:11:07.480 --> 00:11:15.160]   bigger challenge. This is probably what you think your sales and marketing teams are doing with their
[00:11:15.160 --> 00:11:23.560]   budgets. And you wouldn't be entirely wrong. So that's why I co-founded Upside. We do forensic revenue
[00:11:23.560 --> 00:11:29.960]   attribution and intelligence. But what does that actually mean? Well, how many of you have an email
[00:11:29.960 --> 00:11:37.400]   from a salesperson like this sitting in your inbox right now? Uh-huh. And how many of you are actually
[00:11:37.400 --> 00:11:45.560]   going to reply to it? Yeah, I didn't think so. These teams are shouting into the void, hoping something
[00:11:45.560 --> 00:11:51.480]   will work, because they don't actually know what works. Because their data is a mess.
[00:11:51.480 --> 00:11:58.760]   I mean, don't get me wrong. They're data hoarders. They store everything. They stuff it in Salesforce.
[00:11:58.760 --> 00:12:03.160]   They treat it, you know, it's basically a SQL database in a trench coat. But they're not data
[00:12:03.160 --> 00:12:10.280]   practitioners. They don't know what to do with it once they have it. But now we have things like LLMs.
[00:12:10.280 --> 00:12:16.440]   They can help with this. They can take that poor, mishandled, abused email record, and they can pull the
[00:12:16.440 --> 00:12:22.520]   most important details out of it into a structured form. And so just as search engines and web crawlers
[00:12:22.520 --> 00:12:28.680]   learn how to make sense of the unstructured web, Upside is turning raw enterprise data into a highly
[00:12:28.680 --> 00:12:37.080]   structured map of the world and all the interactions that people do in it. So there's hope. We can untangle
[00:12:37.080 --> 00:12:42.760]   this mess and we can create a data command center that these teams can actually use to reach their
[00:12:42.760 --> 00:12:49.720]   customers more effectively. We only just started talking about this publicly a couple weeks ago.
[00:12:49.720 --> 00:12:55.480]   We've been quietly building in the background for the last year or so. And my co-founder decided to make
[00:12:55.480 --> 00:13:00.840]   a small post on her LinkedIn, you know, just to update our network on what we'd been off doing and the
[00:13:00.840 --> 00:13:08.360]   things that we'd been building. And it blew up. Like, there's so much pain people feel around this,
[00:13:08.360 --> 00:13:14.440]   and they're hungry for a solution. We got a whole slew of demo requests coming in from people that want
[00:13:14.440 --> 00:13:20.200]   access to the product. And now we have a bunch of customers lining up that want to get into our
[00:13:20.200 --> 00:13:26.280]   platform. It's a who's who's of companies you've heard of. And we just have a lot of building to do
[00:13:26.280 --> 00:13:34.280]   now. So if you're interested in working on knowledge graphs, on data analytics agents,
[00:13:34.280 --> 00:13:39.400]   on graph analytics and graph learning models, come talk to me. We're hiring.
[00:13:44.600 --> 00:13:50.440]   Hello, everyone. I'm Shijia, the founder of OpenAI. Sorry, I mean, OpenAudio.
[00:13:50.440 --> 00:14:00.040]   Before that, I created something you might be heard of, FishAudio. We have grown from $400K to $5.5 million
[00:14:00.040 --> 00:14:04.920]   annualized revenue in just four months. And we closed our city runs at $100 million valuation.
[00:14:06.680 --> 00:14:14.600]   It all started with my girlfriend. I had a girlfriend for six years, from the beginning of high school
[00:14:14.600 --> 00:14:22.200]   to college. I love her so much, and it was so good, until one day, I found out she cheated.
[00:14:26.280 --> 00:14:35.000]   I wasn't angry, just confused, disappointed. And I asked myself, if this can happen, how can we trust
[00:14:35.000 --> 00:14:44.520]   relationships again? I thought about it for days, all day and all night. And finally, I found my answer.
[00:14:44.520 --> 00:14:54.760]   AI. But nobody can really fall in love with today's AI, right? It's flat, it's emotionless, it's robotic.
[00:14:56.040 --> 00:15:00.520]   So I set her on a mission to build an AI that I could really fall in love with,
[00:15:00.520 --> 00:15:03.240]   starting with her voice.
[00:15:03.240 --> 00:15:10.920]   So we began with open source and crush it. We built Soviet SVC,
[00:15:10.920 --> 00:15:21.160]   and also Fish Speech. Today, actually not today, it's the day before yesterday, I'm excited to introduce
[00:15:21.160 --> 00:15:28.360]   S1. The first ever instructable voice model. It's the only model where you can control not just what
[00:15:28.360 --> 00:15:31.320]   to say, but how to say it. Here's a demo.
[00:15:31.320 --> 00:15:39.480]   You can pinpoint focus or draw closer, even yelling why you betray me like this.
[00:15:41.400 --> 00:15:48.840]   Yeah, you can control whatever you want. And with open audio S1, we have the most expressive voice model in
[00:15:48.840 --> 00:15:58.680]   the world. And most importantly, she will never leave. So we have blown 11 labs out of the water
[00:15:58.680 --> 00:16:05.560]   based on the TTS arena ranking. And they are so hurry and they dropped their latest model today. But
[00:16:05.560 --> 00:16:13.000]   unfortunately, it's just a demo. So try it now. Fish audio is instantly available at fish.audio. Thank you.
[00:16:16.920 --> 00:16:23.560]   Hello, I'm David Vorick, and I'm building Glow. Prior to Glow, I built SiaCoin, a cryptocurrency that
[00:16:23.560 --> 00:16:30.920]   we took from a $10,000 market cap to more than $3 billion. And we think Glow is going to be even bigger.
[00:16:30.920 --> 00:16:38.040]   That's why Framework and USV Union Square Ventures let a $30 million round into our company.
[00:16:40.200 --> 00:16:45.720]   Subsequently, we posted the world record for on-chain D-PIN revenue, doing more than $10 million of
[00:16:45.720 --> 00:16:53.800]   revenue in a single day. What does Glow do? Glow builds solar. Not with shovels, but with incentives.
[00:16:53.800 --> 00:17:01.640]   This is not a stock photo. This is a photograph taken by our team in India of a solar farm that was
[00:17:01.640 --> 00:17:08.520]   constructed for the purpose of mining Glow tokens. A lot of people don't realize, but in the developing world,
[00:17:09.240 --> 00:17:12.040]   rising temperatures and growing populations have strained the grid.
[00:17:12.040 --> 00:17:17.080]   In a lot of cases, people are unable to run their air conditioners during the heat of the day.
[00:17:17.080 --> 00:17:24.600]   This causes people to die of heat stroke. Glow is an incentive protocol that revolutionizes what
[00:17:24.600 --> 00:17:31.000]   governments do and can take the same subsidy and turn it into 10 times as much solar. If you're
[00:17:31.000 --> 00:17:37.960]   interested in working with us, we're currently building incentive projects in India, in Mexico, in Lebanon,
[00:17:38.680 --> 00:17:45.000]   and across the entire world. Bitcoin incentivized the construction of tens of millions of mining
[00:17:45.000 --> 00:17:50.600]   machines. Glow asked, "Why not tens of millions of solar panels?" Thank you.
[00:17:54.120 --> 00:18:02.840]   And my email, David@glowlabs.org. I'd love to be in touch.
[00:18:02.840 --> 00:18:08.920]   Hi. I'm David. I'm an engineer.
[00:18:11.960 --> 00:18:18.920]   I made a social app with 250 million users, making $20 million a year. Everyone thought it was luck,
[00:18:18.920 --> 00:18:27.640]   so I did it again. I'm building Favorited. We built the world's most engaging live app,
[00:18:28.920 --> 00:18:35.240]   and we scaled it from one to $100 million annualized in six months. If you're a cracked engineer that
[00:18:35.240 --> 00:18:39.160]   wants to join the fastest growing company of all time, talk to me.
[00:18:45.560 --> 00:18:51.400]   Alex Atala: Hello. I'm Alex Atala, building OpenRouter, the first and largest LLM marketplace.
[00:18:51.400 --> 00:19:03.640]   Thank you. I want to tell a little bit about how it started. I co-founded OpenSea in 2017,
[00:19:03.640 --> 00:19:09.560]   and at the end of 2022, I really wanted to know if inference was going to be a winner-take-all market,
[00:19:09.560 --> 00:19:15.320]   because the way it looked, this could be the largest market in software that has ever happened before.
[00:19:15.320 --> 00:19:23.000]   And the first experiment that we tried was building a Chrome extension to help you bring your own
[00:19:23.000 --> 00:19:32.360]   language model to any website that supported the protocol. And that eventually evolved into OpenRouter,
[00:19:32.360 --> 00:19:40.360]   a single place and a single API to get all language models with the best prices, best performance,
[00:19:40.360 --> 00:19:47.160]   and highest uptime. And the way it works is you just have a single API, you pay once,
[00:19:47.160 --> 00:19:52.200]   and there's near zero switching costs to move from one model to another. We do all the heavy work to
[00:19:52.200 --> 00:19:57.720]   implement tool calling, edge cases, caching, and give you the best prices and performance possible
[00:19:57.720 --> 00:19:59.880]   for your region or wherever your servers are deployed.
[00:20:01.080 --> 00:20:06.600]   And because inference is so important, remember, this might be the most important software market ever,
[00:20:06.600 --> 00:20:14.600]   it deserves its own marketplace just for language models, optimized for them, including filtering for
[00:20:14.600 --> 00:20:21.160]   context, for features, for tool calling, for structured output, and much more. And so we built that.
[00:20:21.160 --> 00:20:28.840]   And then we built a chat room for you to obviously compare models head-to-head as simply as you do when
[00:20:28.840 --> 00:20:35.480]   chatting with people in iMessage. We built fine-grained privacy settings, including API-level controls.
[00:20:35.480 --> 00:20:53.800]   We built a lot of observability so you could see which models you're using and why. And we built public data in our rankings page, which has become the go-to place for comparing models on the real-world usage and on different categories for the prompts as well.
[00:20:53.800 --> 00:21:03.240]   And this has grown for the last two months, 10 to 100% every single month, or for the last two years, 10 to 100% every single month.
[00:21:03.240 --> 00:21:08.680]   10 to 100% every single month. And scaling it has been a lot of the work that we've done so far.
[00:21:09.400 --> 00:21:17.960]   The fundamental goal here is to make a heterogeneous ecosystem homogeneous, because we believe inference is a commodity.
[00:21:17.960 --> 00:21:27.000]   Claude from Bedrock should be the same as Claude from Vertex, Claude from Anthropic, and we do all the abstraction and heavy work to make it that way for you.
[00:21:27.000 --> 00:21:30.920]   I want to talk a little bit about some of our technical challenges.
[00:21:32.040 --> 00:21:40.520]   We built our own system, our own middleware for doing inference called plugins, which are kind of like MCPs, except a little bit more powerful.
[00:21:40.520 --> 00:21:46.600]   Because you can call MCPs from inside of them, and you can transform the outputs from language models.
[00:21:46.600 --> 00:21:52.760]   A bunch of other tricky problems that we've done to make the fastest routing in the market.
[00:21:52.760 --> 00:22:01.880]   And we're bringing a lot more features in the coming months, including images, enterprise features, prompt observability, and more.
[00:22:01.880 --> 00:22:15.800]   So if you're interested, come find me after, or check out our careers page. Thank you.

