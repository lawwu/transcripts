
[00:00:00.000 --> 00:00:11.240]   When you train a reinforcement learning algorithm from scratch, it has no respect for the delicacy
[00:00:11.240 --> 00:00:14.240]   of the hardware.
[00:00:14.240 --> 00:00:20.800]   It would just push all the motors in the maximum speed in different directions.
[00:00:20.800 --> 00:00:25.080]   We would bring in the manufacturer of the Shadow Hand and show them what we were doing
[00:00:25.080 --> 00:00:28.960]   and they would just watch in horror.
[00:00:28.960 --> 00:00:36.120]   We only run it for five minutes and you have it running all day.
[00:00:36.120 --> 00:00:39.960]   You're listening to Gradient Dissent, a show where we learn about making machine learning
[00:00:39.960 --> 00:00:41.600]   models work in the real world.
[00:00:41.600 --> 00:00:43.800]   I'm your host, Lukas Biewald.
[00:00:43.800 --> 00:00:48.360]   Peter Wellender is a research scientist and robotics lead at OpenAI.
[00:00:48.360 --> 00:00:53.120]   Before that, he was an engineer at Dropbox and ran the machine learning team.
[00:00:53.120 --> 00:00:57.680]   Before that, he co-founded Anchovy Labs, a startup using computer vision to organize
[00:00:57.680 --> 00:00:58.680]   photos.
[00:00:58.680 --> 00:01:02.240]   It was acquired by Dropbox in 2012.
[00:01:02.240 --> 00:01:09.000]   I'm most excited to talk to you about the OpenAI stuff, but I think you've had, maybe
[00:01:09.000 --> 00:01:12.440]   we should start with your career, which I think is pretty interesting.
[00:01:12.440 --> 00:01:19.480]   You've done a startup, you've run machine learning at Dropbox and then gone into OpenAI
[00:01:19.480 --> 00:01:20.480]   as a researcher.
[00:01:20.480 --> 00:01:24.360]   So maybe you can tell us a little bit about how you first got into deep learning.
[00:01:24.360 --> 00:01:26.440]   I think it was the startup, right?
[00:01:26.440 --> 00:01:27.880]   Where you first used this?
[00:01:27.880 --> 00:01:28.880]   Yeah.
[00:01:28.880 --> 00:01:34.480]   So I guess, I mean, I kind of did machine learning in grad school.
[00:01:34.480 --> 00:01:42.600]   So I kind of, I did this thing where I kind of, I didn't really know what I was doing
[00:01:42.600 --> 00:01:43.600]   when I went to grad school.
[00:01:43.600 --> 00:01:48.400]   I kind of knew I wanted to learn about how intelligence worked or like AI.
[00:01:48.400 --> 00:01:54.600]   And the place where I started was kind of in neuroscience.
[00:01:54.600 --> 00:02:01.080]   And so I spent a fair amount of time just kind of doing, sitting in a basement and building
[00:02:01.080 --> 00:02:03.720]   these little micro dives to implant into rats' brains.
[00:02:03.720 --> 00:02:04.720]   Oh, really?
[00:02:04.720 --> 00:02:05.720]   I didn't know that.
[00:02:05.720 --> 00:02:06.720]   Wow.
[00:02:06.720 --> 00:02:07.720]   Yeah.
[00:02:07.720 --> 00:02:11.620]   So I did that for probably like half a year.
[00:02:11.620 --> 00:02:17.000]   And I realized just like how lonely that work was when you're just like, you're spending
[00:02:17.000 --> 00:02:21.400]   like 12 hours a day because you're a grad student and you have to work really hard and
[00:02:21.400 --> 00:02:22.680]   then building this thing.
[00:02:22.680 --> 00:02:26.920]   And then at some point, this whole thing takes like three months to build.
[00:02:26.920 --> 00:02:31.920]   And then at some point you need to make a surgery, implant this into the rat.
[00:02:31.920 --> 00:02:37.040]   And if something happens at that time, you have to kind of go back to, you're all screwed.
[00:02:37.040 --> 00:02:41.680]   You have to go back to square one again and build your thing.
[00:02:41.680 --> 00:02:45.640]   So I realized if you go down this path, it would just take a really, really long time
[00:02:45.640 --> 00:02:47.720]   to go through grad school.
[00:02:47.720 --> 00:02:51.200]   So I realized at that point, neuroscience wasn't really for me.
[00:02:51.200 --> 00:02:57.440]   So then I ended up just, I kind of wanted to focus more on robotics, but robotics has
[00:02:57.440 --> 00:03:02.480]   this similar problem where it's like, everything takes a really long time to do because you
[00:03:02.480 --> 00:03:05.760]   kind of have to first build your robot and get the robot to work.
[00:03:05.760 --> 00:03:10.160]   And that's like, you're probably three quarters of your PhD.
[00:03:10.160 --> 00:03:13.320]   And then you have to kind of do the experiments at that.
[00:03:13.320 --> 00:03:19.400]   So instead I decided like, let's pick one aspect of this instead, which is kind of go
[00:03:19.400 --> 00:03:23.440]   towards something more useful.
[00:03:23.440 --> 00:03:25.760]   And if it aligns with robotics, that's awesome.
[00:03:25.760 --> 00:03:28.960]   But it's great if you can have kind of other applications.
[00:03:28.960 --> 00:03:33.680]   So I ended up doing a lot of computer vision and that's how I got started on my startup,
[00:03:33.680 --> 00:03:39.640]   which was doing kind of image organization, things like finding faces and in photos, finding
[00:03:39.640 --> 00:03:42.120]   what photos are about and stuff like that.
[00:03:42.120 --> 00:03:47.000]   That's how I got started into kind of more machine learning and computer vision and eventually
[00:03:47.000 --> 00:03:51.560]   ended up at Dropbox doing more of that stuff there.
[00:03:51.560 --> 00:03:55.720]   And what were the big problems at Dropbox that you worked on?
[00:03:55.720 --> 00:04:01.160]   So initially, the premise that we had when we started, it was very interesting, which
[00:04:01.160 --> 00:04:11.000]   was this thing that, this was back in 2012 and half of the files in Dropbox were images
[00:04:11.000 --> 00:04:15.320]   and it was like many, many billions of images or photos.
[00:04:15.320 --> 00:04:19.040]   And it was sort of like the dark matter of Dropbox.
[00:04:19.040 --> 00:04:22.720]   It took up all the space, but nobody knew what was in it and it was not useful at all
[00:04:22.720 --> 00:04:23.960]   for users.
[00:04:23.960 --> 00:04:33.680]   So the mission, me and my co-founder after we joined was to see if we could just kind
[00:04:33.680 --> 00:04:37.440]   of start making sense of all that data and actually make it useful for people.
[00:04:37.440 --> 00:04:45.280]   So the first thing, there was a lot of pretty mundane things that you had to kind of, you
[00:04:45.280 --> 00:04:49.760]   know, clear up first, like just being able to sort photos by date, you know, and stuff
[00:04:49.760 --> 00:04:53.000]   like that, like just extracting the metadata from the photos.
[00:04:53.000 --> 00:04:58.940]   So it was a fair amount of time just spending on how do we deal, how do we index these billions
[00:04:58.940 --> 00:05:04.320]   of photos and how do we kind of just do simple things on them, just search by, if you want
[00:05:04.320 --> 00:05:08.840]   to search by GPS or search by timestamp or something like that.
[00:05:08.840 --> 00:05:14.200]   But the idea was that eventually kind of actually start extracting the useful information from
[00:05:14.200 --> 00:05:15.680]   images.
[00:05:15.680 --> 00:05:23.120]   So one thing that we realized through that work and kind of one of the main features
[00:05:23.120 --> 00:05:30.480]   that I worked out while there, at least on photos was it turns out that a lot of people
[00:05:30.480 --> 00:05:37.040]   are using, like people used to use their Dropbox a lot for kind of more kind of say, you know,
[00:05:37.040 --> 00:05:39.480]   their family photos and stuff like that.
[00:05:39.480 --> 00:05:44.600]   And then over time, the use of Dropbox shifted towards more business users.
[00:05:44.600 --> 00:05:47.960]   And it turns out if you're a business user, you can't take a lot of photos of documents.
[00:05:47.960 --> 00:05:50.080]   So like, you know, photos are really, really boring.
[00:05:50.080 --> 00:05:54.600]   They're just like photos of documents, like no, like people are kind of too lazy to put
[00:05:54.600 --> 00:05:55.600]   stuff in a scanner.
[00:05:55.600 --> 00:05:58.360]   So they just like take a photo with their phone and they kind of hope that they will
[00:05:58.360 --> 00:06:01.640]   find this photo somewhere.
[00:06:01.640 --> 00:06:04.760]   You know, as soon as you've taken that photo, like two days later, like it's lost in your
[00:06:04.760 --> 00:06:12.040]   photo library, like with baby photos, photos of food, photos of like all the random crap
[00:06:12.040 --> 00:06:15.560]   you take photos of, you know, like, yeah, you're just taking photos of everything.
[00:06:15.560 --> 00:06:16.560]   Right.
[00:06:16.560 --> 00:06:22.640]   So we built this thing, which first of all, like just finding those photos that had documents
[00:06:22.640 --> 00:06:24.440]   in them.
[00:06:24.440 --> 00:06:31.440]   So, you know, just bringing them up and showing them to the users and then just like doing
[00:06:31.440 --> 00:06:33.040]   more useful things on that.
[00:06:33.040 --> 00:06:36.920]   Like actually kind of extracting the text that was in the documents.
[00:06:36.920 --> 00:06:39.560]   Oh wow, so you would OCR the photos?
[00:06:39.560 --> 00:06:41.880]   That must be such a magical user experience.
[00:06:41.880 --> 00:06:42.880]   Yeah.
[00:06:42.880 --> 00:06:49.120]   That was kind of a really fun thing, actually, because it's like, I honestly use this feature
[00:06:49.120 --> 00:06:52.120]   probably a few times a week still.
[00:06:52.120 --> 00:06:56.160]   I don't know, probably not so many people know about it, but it's actually still there
[00:06:56.160 --> 00:06:58.040]   in the app and I'm very, very proud of that.
[00:06:58.040 --> 00:07:01.840]   You know, you can actually scan your documents using Dropbox as well.
[00:07:01.840 --> 00:07:04.160]   You just take a photo in Dropbox app and scan it.
[00:07:04.160 --> 00:07:05.240]   So that was like the other part of it.
[00:07:05.240 --> 00:07:10.760]   But, you know, even like building that OCR experience was like really, really fun because
[00:07:10.760 --> 00:07:16.920]   this was like, you know, my past in computer vision was like, this was like pre-deep learning,
[00:07:16.920 --> 00:07:20.520]   you know, so this was like the old school computer vision stuff.
[00:07:20.520 --> 00:07:25.600]   And it was like, you know, there was like hog features, pyramid of features or like
[00:07:25.600 --> 00:07:29.640]   a bag of words kind of stuff, you know, all these weird things.
[00:07:29.640 --> 00:07:32.880]   People don't know about them anymore because they don't matter anymore.
[00:07:32.880 --> 00:07:39.000]   But it was like, when I was at Dropbox, that's what really went, I guess, like this whole
[00:07:39.000 --> 00:07:43.380]   deep learning revolution kind of happened.
[00:07:43.380 --> 00:07:50.680]   And it was like kind of mind blowing to work on computer vision problem, like before and
[00:07:50.680 --> 00:07:58.920]   after this, because it's like before it was like, you know, it's kind of, you know, it's
[00:07:58.920 --> 00:08:03.080]   like a little bit like that XKCD comic where like, you know, you want to see if you're
[00:08:03.080 --> 00:08:05.960]   a national park, you know, you just look at the GPS.
[00:08:05.960 --> 00:08:09.720]   But if you want to, you know, take a photo of a bird and recognize its species, then
[00:08:09.720 --> 00:08:12.680]   you see, you know, you need five years in the research team or something like that.
[00:08:12.680 --> 00:08:16.600]   Like it's like that's kind of like, anytime we would like brainstorm about features, it
[00:08:16.600 --> 00:08:23.280]   would be like, yeah, I don't know, like maybe in a decade we can make that work, you know.
[00:08:23.280 --> 00:08:28.880]   And I think like once we kind of started using deep learning for stuff, it was like, you
[00:08:28.880 --> 00:08:33.800]   know, I remember for OCR, like we kind of took the best OCR systems that were out there
[00:08:33.800 --> 00:08:38.640]   and we created kind of a benchmark using those, like using Google's OCR, using what's like
[00:08:38.640 --> 00:08:45.000]   ABI, what's one big kind of OCR, kind of text recognition company.
[00:08:45.000 --> 00:08:50.280]   And you know, we sat down and we just kind of started building our own OCR engine from
[00:08:50.280 --> 00:08:54.840]   scratch where we kind of extracted the text, we did the text recognition, word recognition
[00:08:54.840 --> 00:08:55.840]   and so on.
[00:08:55.840 --> 00:08:59.640]   And like in three months we had like beaten all of the public dataset benchmarks, you
[00:08:59.640 --> 00:09:00.640]   know.
[00:09:00.640 --> 00:09:01.640]   And that was just like mind blowing to me.
[00:09:01.640 --> 00:09:05.560]   Like I wouldn't, like that's the stuff that would have taken so much longer before.
[00:09:05.560 --> 00:09:06.560]   Wow.
[00:09:06.560 --> 00:09:07.560]   That's amazing.
[00:09:07.560 --> 00:09:08.920]   And there was like two or three people working on it.
[00:09:08.920 --> 00:09:09.920]   That's amazing.
[00:09:09.920 --> 00:09:10.920]   What year was that?
[00:09:10.920 --> 00:09:15.920]   That must have been like 2014 or something like that.
[00:09:15.920 --> 00:09:16.920]   Wow.
[00:09:17.600 --> 00:09:18.600]   Wow.
[00:09:18.600 --> 00:09:22.600]   I mean, what, like we're using like CAFE, like what was even the, how did you?
[00:09:22.600 --> 00:09:23.600]   Yeah.
[00:09:23.600 --> 00:09:24.600]   Yeah.
[00:09:24.600 --> 00:09:28.840]   It was also one of those times, like we started on it, like when CAFE was still a thing.
[00:09:28.840 --> 00:09:31.480]   And then by the end of it, like TensorFlow was a thing.
[00:09:31.480 --> 00:09:36.560]   You know, it was like, it was just so much changing from like month to month in terms
[00:09:36.560 --> 00:09:37.560]   of deep learning.
[00:09:37.560 --> 00:09:42.000]   I think we even had like Theano was probably the stuff we started prototyping it in, the
[00:09:42.000 --> 00:09:43.000]   stuff like that.
[00:09:43.000 --> 00:09:44.000]   Nice.
[00:09:44.000 --> 00:09:48.560]   And then the library is just changing every month, you know.
[00:09:48.560 --> 00:09:54.040]   But yeah, I think the first kind of version, which we actually, I think the thing that
[00:09:54.040 --> 00:09:58.040]   we shipped in production initially must have been some part of it was probably in CAFE.
[00:09:58.040 --> 00:10:00.240]   Probably not anymore, but you know.
[00:10:00.240 --> 00:10:05.240]   It must have been a challenge just to like run that in like every document.
[00:10:05.240 --> 00:10:08.640]   I mean, that seems like a huge production challenge.
[00:10:08.640 --> 00:10:09.680]   Yeah.
[00:10:09.680 --> 00:10:16.240]   I think, you know, this is kind of the truth of deploying machine learning systems in general.
[00:10:16.240 --> 00:10:23.440]   It's like, you know, we did that three months where we just kind of created the algorithm
[00:10:23.440 --> 00:10:25.120]   and got it all working.
[00:10:25.120 --> 00:10:29.320]   And then it was like, you know, a year to ship the feature because of all of that stuff,
[00:10:29.320 --> 00:10:35.180]   you know, like actually putting it in production, making sure it's like the errors are not disasters,
[00:10:35.180 --> 00:10:38.440]   but then also just scaling the thing up, you know, and doing it in a way where it's just
[00:10:38.440 --> 00:10:43.600]   like, you know, you take the cost of running it for like phone photo and then you multiply
[00:10:43.600 --> 00:10:46.600]   it by a few billion and then there's like very high numbers.
[00:10:46.600 --> 00:10:50.040]   And then you give that to some finance person and they're like, "Ahh!"
[00:10:50.040 --> 00:10:53.480]   You know, what's the actual value we get out of this?
[00:10:53.480 --> 00:10:57.080]   And, you know, eventually like, so, you know, it's, so there's a lot of kind of fun, like
[00:10:57.080 --> 00:10:58.800]   optimization work and stuff like that.
[00:10:58.800 --> 00:11:02.640]   But we got it down to a place where people were happy with it.
[00:11:02.640 --> 00:11:06.480]   And I think, I don't know what the status is now, but I think like it's probably one
[00:11:06.480 --> 00:11:11.240]   of those things that you still have to actually be a paid user for Dropbox to run this.
[00:11:11.240 --> 00:11:14.640]   I don't think they run it for free users.
[00:11:14.640 --> 00:11:18.720]   Were there some tricks to getting the size down or the cost down?
[00:11:18.720 --> 00:11:21.480]   I'm trying to remember what people did back then.
[00:11:21.480 --> 00:11:25.240]   Did you do like quantization and stuff yet?
[00:11:25.240 --> 00:11:29.880]   I think it was just like, it was very, in the very early stages of that.
[00:11:29.880 --> 00:11:32.320]   So I don't think we did stuff like that.
[00:11:32.320 --> 00:11:36.960]   I think it was mostly, at that point, it was mostly like once you had, we had kind of gotten
[00:11:36.960 --> 00:11:40.440]   everything working, it was like a very manual process of like, can we get away with a smaller
[00:11:40.440 --> 00:11:41.440]   network?
[00:11:41.440 --> 00:11:46.920]   You know, can we have like, you know, five layers instead of six layers, making it like
[00:11:46.920 --> 00:11:52.160]   this, just like finding where everything is, but also like not so, like, I feel like even
[00:11:52.160 --> 00:11:57.640]   that was also pretty early in the state of these neural network libraries.
[00:11:57.640 --> 00:12:03.240]   So even like doing optimizations on those libraries and like doing little optimizations
[00:12:03.240 --> 00:12:08.240]   to just make them run on the particular architectures that we had on the machines, those things
[00:12:08.240 --> 00:12:09.240]   mattered.
[00:12:09.240 --> 00:12:12.920]   Like all of that, it's kind of done automatically for you now, but you know, that was the stuff.
[00:12:12.920 --> 00:12:18.840]   I think we had at least like one or two people who worked full time on this for a few months.
[00:12:18.840 --> 00:12:23.280]   Reduce the speed, reduce the compute footprint for these things.
[00:12:23.280 --> 00:12:24.280]   Cool.
[00:12:24.280 --> 00:12:28.480]   And then you left to go to OpenAI and you work on the robotics team, right?
[00:12:28.480 --> 00:12:29.480]   Yeah, exactly.
[00:12:29.480 --> 00:12:34.320]   So I kind of always wanted to work on robotics since I had been in grad school, you know,
[00:12:34.320 --> 00:12:37.680]   but again, I abandoned it, you know, because I thought there was a little bit too much
[00:12:37.680 --> 00:12:43.080]   work, actually working on the robots and like all of the things in the robotic, kind of
[00:12:43.080 --> 00:12:46.600]   if you build a robot, you have a whole system and all of the things were kind of broken.
[00:12:46.600 --> 00:12:52.880]   So you know, computer vision was the kind of promising part.
[00:12:52.880 --> 00:13:00.120]   And you know, the really cool thing that I had started noticing was that, like that was
[00:13:00.120 --> 00:13:05.120]   kind of when a lot of these results come out where deep learning was kind of doing really
[00:13:05.120 --> 00:13:09.960]   well on simple computer games and so on.
[00:13:09.960 --> 00:13:14.560]   And like deep reinforcement learning in particular was like the thing that people actually started
[00:13:14.560 --> 00:13:16.000]   to get to work.
[00:13:16.000 --> 00:13:21.040]   And you know, I kind of started feeling at that point that computer vision, like deep
[00:13:21.040 --> 00:13:26.920]   learning kind of solve a lot of these kind of perception things in robotics.
[00:13:26.920 --> 00:13:34.080]   And it's like, it's kind of the thing where before deep learning, it kind of felt like
[00:13:34.080 --> 00:13:36.960]   you just didn't know how, if anything was going to ever work.
[00:13:36.960 --> 00:13:40.240]   And after deep learning was like, yeah, it would probably work if we have enough data,
[00:13:40.240 --> 00:13:44.520]   you know, it's like, it's a very different feeling, feeling that you kind of know how
[00:13:44.520 --> 00:13:48.160]   to get there if you just get enough data and you need to like, obviously the data is really
[00:13:48.160 --> 00:13:52.800]   hard, but it's like, it's more of a solvable engineering and like product problem to figure
[00:13:52.800 --> 00:13:54.280]   out how to get data.
[00:13:54.280 --> 00:13:57.720]   But you still have the thing with robotics is that there's this other aspect, which is
[00:13:57.720 --> 00:13:59.240]   the control part.
[00:13:59.240 --> 00:14:01.480]   And like control is also really, really hard.
[00:14:01.480 --> 00:14:07.760]   And what was really promising that those kind of that early deep reinforcement learning
[00:14:07.760 --> 00:14:13.920]   work was that suddenly there was kind of a learning based approach to control that seemed
[00:14:13.920 --> 00:14:18.120]   to kind of scale to kind of more interesting action space.
[00:14:18.120 --> 00:14:22.720]   What I mean by that is just like, you can just like manipulate all the joints on a robot,
[00:14:22.720 --> 00:14:24.720]   for example.
[00:14:24.720 --> 00:14:31.960]   And so I knew some of the people who were working on that at OpenAI and they were just
[00:14:31.960 --> 00:14:33.120]   starting up a robotics team.
[00:14:33.120 --> 00:14:37.720]   So it seemed like a really good time to kind of just get into deep reinforcement learning
[00:14:37.720 --> 00:14:43.280]   and see if we can actually get robots to do much more interesting things using deep learning.
[00:14:43.280 --> 00:14:44.760]   So how has it evolved?
[00:14:44.760 --> 00:14:51.520]   Do you still feel like deep reinforcement learning is as promising as it felt in 2017
[00:14:51.520 --> 00:14:54.400]   or whenever you joined the robotics team?
[00:14:54.400 --> 00:14:59.920]   Yeah, I think at that point I felt like there's a chance that this could work.
[00:14:59.920 --> 00:15:03.720]   Now I feel like this is totally the path.
[00:15:03.720 --> 00:15:05.720]   This should work.
[00:15:05.720 --> 00:15:09.800]   There might be other ways to get there, but it feels like this should work.
[00:15:09.800 --> 00:15:12.200]   In the limit, this will work.
[00:15:12.200 --> 00:15:15.000]   How long it would take to get there, it's really hard to say.
[00:15:15.000 --> 00:15:18.240]   I feel like it's always like one or two years away.
[00:15:18.240 --> 00:15:24.120]   They will probably be one or two years away for more than one or two years.
[00:15:24.120 --> 00:15:29.880]   But I kind of feel like there's something fundamental with deep learning and with deep
[00:15:29.880 --> 00:15:38.240]   reinforcement learning where it really feels like this should be able to solve the problem
[00:15:38.240 --> 00:15:41.560]   relatively far.
[00:15:41.560 --> 00:15:46.000]   By the problem I mean getting to more general purpose robots, robots that can do more of
[00:15:46.000 --> 00:15:52.760]   the things that humans do, actually move around in a home, not be locked into a factory, but
[00:15:52.760 --> 00:15:54.960]   actually deal with all the complexities of the real world.
[00:15:54.960 --> 00:16:04.000]   I very strongly feel like there's something that the way you need to tackle this, just
[00:16:04.000 --> 00:16:07.480]   because of the complexity of the world, is really through learning.
[00:16:07.480 --> 00:16:15.480]   And deep reinforcement learning is just such a simple paradigm where it seems like most
[00:16:15.480 --> 00:16:18.640]   other things are going to be much more complex.
[00:16:18.640 --> 00:16:23.600]   I guess my bias is just complex things that never really work, and it's the simple things
[00:16:23.600 --> 00:16:25.160]   that really, really work.
[00:16:25.160 --> 00:16:27.960]   That's what I saw at Dropbox.
[00:16:27.960 --> 00:16:29.560]   It was always the simplest approach that worked.
[00:16:29.560 --> 00:16:37.560]   If you try to be a little bit clever with the algorithms and stuff, usually you would
[00:16:37.560 --> 00:16:38.560]   end up being disappointed.
[00:16:38.560 --> 00:16:42.120]   And the most important thing was really setting up the data.
[00:16:42.120 --> 00:16:46.520]   And I think that's something very fundamental with deep reinforcement learning that makes
[00:16:46.520 --> 00:16:49.840]   me think that you can push it really far.
[00:16:49.840 --> 00:16:52.520]   We're just getting started.
[00:16:52.520 --> 00:16:59.000]   When you say work or push it really far, what are some of the things that you see so far
[00:16:59.000 --> 00:17:01.280]   that makes you think that it works?
[00:17:01.280 --> 00:17:05.040]   And then what are some of the things that would make you feel like, wow, this is really
[00:17:05.040 --> 00:17:06.040]   successful?
[00:17:06.040 --> 00:17:09.480]   Yeah, that's a good question.
[00:17:09.480 --> 00:17:16.280]   I think, so first of all, I know all the listeners would know what deep reinforcement learning
[00:17:16.280 --> 00:17:17.280]   is.
[00:17:17.280 --> 00:17:19.080]   I can just describe that a little bit more.
[00:17:19.080 --> 00:17:23.440]   So deep reinforcement learning is really about learning from trial and error.
[00:17:23.440 --> 00:17:28.440]   A lot of machine learning is based on supervised learning where you show examples and then
[00:17:28.440 --> 00:17:30.000]   you have a label.
[00:17:30.000 --> 00:17:33.600]   But reinforcement learning is basically trial and error.
[00:17:33.600 --> 00:17:37.280]   You do a series of actions and you get some kind of score at the end.
[00:17:37.280 --> 00:17:40.160]   We call this the reward.
[00:17:40.160 --> 00:17:43.800]   You do something and it gets rewarded or punished at the end.
[00:17:43.800 --> 00:17:45.560]   But usually people talk about reward.
[00:17:45.560 --> 00:17:48.760]   We're all more optimists.
[00:17:48.760 --> 00:17:51.560]   But this is the core algorithm.
[00:17:51.560 --> 00:17:54.320]   So it's very, very simple.
[00:17:54.320 --> 00:18:08.280]   And the reason I feel like it is promising is that the biggest issue around it, the biggest
[00:18:08.280 --> 00:18:14.600]   criticism that reinforcement learning gets is that you just need lots and lots of experience.
[00:18:14.600 --> 00:18:20.960]   You just need to do so many of these trial and errors in order to learn anything.
[00:18:20.960 --> 00:18:26.160]   And so people usually don't like reinforcement learning for robots because you cannot do
[00:18:26.160 --> 00:18:29.520]   that in a real robot.
[00:18:29.520 --> 00:18:33.680]   Because first of all, if you do anything on a real robot and you don't do it very controlled,
[00:18:33.680 --> 00:18:34.680]   you're going to break the robot.
[00:18:34.680 --> 00:18:36.040]   You're going to break the things around the robot.
[00:18:36.040 --> 00:18:38.720]   It's kind of dangerous to do it.
[00:18:38.720 --> 00:18:49.160]   And I think some of that criticism is misplaced because we can just do a lot of that learning
[00:18:49.160 --> 00:18:50.800]   in simulation.
[00:18:50.800 --> 00:18:58.040]   And some of the things that we showed at OpenAI over the past two years has been that we have
[00:18:58.040 --> 00:19:05.080]   really focused on this problem of seeing if we can solve robotics problems in simulation
[00:19:05.080 --> 00:19:10.240]   and taking those agents that we have trained in the simulator and putting them into a real
[00:19:10.240 --> 00:19:14.280]   world robot and seeing if we can do the same thing that we trained it on in the simulator
[00:19:14.280 --> 00:19:16.000]   on the real world robots.
[00:19:16.000 --> 00:19:28.960]   And the hypothesis behind this is that one somewhat controversial hypothesis is that
[00:19:28.960 --> 00:19:31.920]   if you have any problem in a simulator, you can solve it using reinforcement learning
[00:19:31.920 --> 00:19:34.520]   if you just have enough compute.
[00:19:34.520 --> 00:19:46.360]   And you can have really complex problems like Go or like Dota, which is a computer game.
[00:19:46.360 --> 00:19:49.200]   These things require a lot of strategy and so on.
[00:19:49.200 --> 00:19:54.840]   And you can take those and you can still solve them with enough compute.
[00:19:54.840 --> 00:20:03.840]   So what we did at OpenAI, we kind of trained an agent in the simulator to operate a humanoid
[00:20:03.840 --> 00:20:05.360]   robotic hand.
[00:20:05.360 --> 00:20:09.200]   And we got this to solve the Rubik's Cube in a simulator.
[00:20:09.200 --> 00:20:13.280]   And then by setting up the environment in the right way in the simulator and throwing
[00:20:13.280 --> 00:20:17.600]   lots and lots of compute at it, we were able to train a robust enough algorithm to then
[00:20:17.600 --> 00:20:22.640]   put it on a real world robot and have it solve a real world Rubik's Cube.
[00:20:22.640 --> 00:20:32.040]   And I kind of feel like this was a hard enough problem where like a manipulation problem
[00:20:32.040 --> 00:20:36.600]   that's like this is kind of tricky for humans even to do it.
[00:20:36.600 --> 00:20:38.720]   We had one hand and it was kind of fixed to a wall.
[00:20:38.720 --> 00:20:40.960]   You cannot move it very much.
[00:20:40.960 --> 00:20:43.840]   And it can still do this thing.
[00:20:43.840 --> 00:20:45.360]   And so it's a hard manipulation problem.
[00:20:45.360 --> 00:20:47.440]   And still we can solve it using reinforcement learning.
[00:20:47.440 --> 00:20:49.480]   We solve it on a real world robot.
[00:20:49.480 --> 00:20:54.560]   So in some way, that kind of gave me enough confidence where I now feel like there must
[00:20:54.560 --> 00:20:57.160]   be more problems that we can tackle using this approach.
[00:20:57.160 --> 00:20:59.800]   A lot of things will be easier than solving Rubik's Cube.
[00:20:59.800 --> 00:21:06.120]   Hi, we'd love to take a moment to tell you guys about Weights and Biases.
[00:21:06.120 --> 00:21:11.600]   Weights and Biases is a tool that helps you track and visualize every detail of your machine
[00:21:11.600 --> 00:21:12.600]   learning models.
[00:21:12.600 --> 00:21:18.560]   We help you debug your machine learning models in real time, collaborate easily, and advance
[00:21:18.560 --> 00:21:21.640]   the state of the art in machine learning.
[00:21:21.640 --> 00:21:26.840]   You can integrate Weights and Biases into your models with just a few lines of code.
[00:21:26.840 --> 00:21:31.600]   With hyperparameter sweeps, you can find the best set of hyperparameters for your models
[00:21:31.600 --> 00:21:33.520]   automatically.
[00:21:33.520 --> 00:21:38.920]   You can also track and compare how many GPU resources your models are using.
[00:21:38.920 --> 00:21:45.640]   With one line of code, you can visualize model predictions in form of images, videos, audio,
[00:21:45.640 --> 00:21:51.360]   plotly charts, molecular data, segmentation maps, and 3D point clouds.
[00:21:51.360 --> 00:21:57.200]   You can save everything you need to reproduce your models days, weeks, or even months after
[00:21:57.200 --> 00:21:58.200]   training.
[00:21:58.200 --> 00:22:03.320]   Finally, with Reports, you can make your models come alive.
[00:22:03.320 --> 00:22:08.320]   Reports are like blog posts in which your readers can interact with your model metrics
[00:22:08.320 --> 00:22:10.120]   and predictions.
[00:22:10.120 --> 00:22:16.320]   Reports serve as a centralized repository of metrics, predictions, hyperparameter stride,
[00:22:16.320 --> 00:22:18.080]   and accompanying nodes.
[00:22:18.080 --> 00:22:23.760]   All of this together gives you a bird's eye view of your machine learning workflow.
[00:22:23.760 --> 00:22:29.280]   You can use Reports to share your model insights, keep your team on the same page, and collaborate
[00:22:29.280 --> 00:22:30.280]   effectively remotely.
[00:22:30.280 --> 00:22:35.400]   I'll leave a link in the show notes below to help you get started.
[00:22:35.400 --> 00:22:40.440]   And now let's get back to the episode.
[00:22:40.440 --> 00:22:45.120]   So when the robotics team got started, what was its charter?
[00:22:45.120 --> 00:22:47.240]   Did you know that you were going to do simulation?
[00:22:47.240 --> 00:22:51.160]   Did you know that you were going to do reinforcement learning?
[00:22:51.160 --> 00:22:57.240]   I think I would say the short answer is we didn't know at all what we were doing.
[00:22:57.240 --> 00:22:58.240]   We had this goal.
[00:22:58.240 --> 00:23:05.920]   We kind of wanted to build a general purpose robot.
[00:23:05.920 --> 00:23:11.080]   I don't think we had a super clear idea of how to get there.
[00:23:11.080 --> 00:23:19.280]   But I think one core belief we had was that deep learning would be a big part of it.
[00:23:19.280 --> 00:23:23.400]   Reinforcement learning would also probably be a big part of it.
[00:23:23.400 --> 00:23:27.760]   Exactly what kind of different flavors of reinforcement learning is on, that we didn't
[00:23:27.760 --> 00:23:29.840]   really know yet.
[00:23:29.840 --> 00:23:36.280]   So it was all about, there was kind of a philosophy around, can we take some of these approaches
[00:23:36.280 --> 00:23:43.480]   that are pretty simple and by really pushing them super, super, super far, can we solve
[00:23:43.480 --> 00:23:45.440]   really, really hard problems with them?
[00:23:45.440 --> 00:23:49.840]   So I think that was our overall strategy.
[00:23:49.840 --> 00:23:55.600]   So we kind of hoped that just taking pretty simple reinforcement learning algorithms,
[00:23:55.600 --> 00:23:59.400]   but putting them on a really, really hard problem would be successful.
[00:23:59.400 --> 00:24:04.320]   But I think we were somewhat scared for the first two years about, maybe this won't work
[00:24:04.320 --> 00:24:05.320]   out.
[00:24:05.320 --> 00:24:07.920]   It really felt like that a lot of times.
[00:24:07.920 --> 00:24:12.840]   It's just like, every time this robotic hand broke and we had to set it off to for repairs.
[00:24:12.840 --> 00:24:17.040]   And we would have like a month sitting there and thinking about our mistakes, thinking
[00:24:17.040 --> 00:24:18.320]   like, will this ever work?
[00:24:18.320 --> 00:24:22.200]   I'm not sure, this is probably completely the wrong path.
[00:24:22.200 --> 00:24:29.920]   But in the end, now I think we're believing that it's stronger than ever.
[00:24:29.920 --> 00:24:33.320]   Why did you choose to manipulate a hand?
[00:24:33.320 --> 00:24:38.000]   I feel like if I was trying to build a general purpose robot, I might even leave out the
[00:24:38.000 --> 00:24:39.000]   hands.
[00:24:39.000 --> 00:24:42.320]   It seems like the hand has got to be the most complicated thing.
[00:24:42.320 --> 00:24:47.200]   I feel like in the movies, robots don't even always have hands.
[00:24:47.200 --> 00:24:48.800]   Maybe they don't even need them.
[00:24:48.800 --> 00:24:49.800]   I don't know.
[00:24:49.800 --> 00:24:50.800]   Yeah.
[00:24:50.800 --> 00:24:56.760]   It's interesting how that started because the first problems we tackled were, we didn't
[00:24:56.760 --> 00:24:57.760]   use a robotic hand.
[00:24:57.760 --> 00:25:03.760]   We had one of these fetch robots, which is basically a kind of mobile robot with a robotic
[00:25:03.760 --> 00:25:06.360]   arm and a two-finger gripper.
[00:25:06.360 --> 00:25:08.160]   It's super simple of a robot.
[00:25:08.160 --> 00:25:11.560]   And we would even just screw it onto the floor so it couldn't move.
[00:25:11.560 --> 00:25:17.200]   So it was just like a robot arm, basically, a very expensive robot arm.
[00:25:17.200 --> 00:25:19.760]   And so that's how we started it.
[00:25:19.760 --> 00:25:23.920]   But what we realized when we were doing that, we started with the simplest of problems in
[00:25:23.920 --> 00:25:25.560]   robotics, which is block stacking.
[00:25:25.560 --> 00:25:27.640]   Robots have been stacking blocks for 60 years.
[00:25:27.640 --> 00:25:33.600]   There's stuff like from movies from Stanford in the 1950s or 60s where they have robots
[00:25:33.600 --> 00:25:34.600]   stacking blocks.
[00:25:34.600 --> 00:25:37.560]   So, you know, you can start simple.
[00:25:37.560 --> 00:25:41.360]   So that was one of the first things we started doing.
[00:25:41.360 --> 00:25:48.840]   And I think we had this realization that it's just like even the simplest thing of just
[00:25:48.840 --> 00:25:54.080]   picking up the blocks and the manipulation of those blocks was pretty hard.
[00:25:54.080 --> 00:26:02.400]   So then we were like, okay, so we need to kind of solve this problem of just doing manipulation.
[00:26:02.400 --> 00:26:05.640]   And then we were like, okay, but we need to be pretty ambitious about this.
[00:26:05.640 --> 00:26:08.320]   Let's do the hardest thing we can think of.
[00:26:08.320 --> 00:26:11.800]   And let's have a robotic hand.
[00:26:11.800 --> 00:26:15.240]   And there was another thing that we did at the same time, which was basically good.
[00:26:15.240 --> 00:26:16.360]   We went to a robotics conference.
[00:26:16.360 --> 00:26:21.160]   We asked people, what is the hardest thing that you know, like this one, a bunch of roboticists
[00:26:21.160 --> 00:26:23.480]   from across the world.
[00:26:23.480 --> 00:26:27.320]   And we asked them, what is the hardest thing you can imagine doing in robotics right now?
[00:26:27.320 --> 00:26:31.600]   What is it like if we want to pick a really hard problem and where we could show the deep
[00:26:31.600 --> 00:26:35.720]   reinforcement learning work in this, where would you be impressed?
[00:26:35.720 --> 00:26:40.040]   And then all of them would answer, well, the problem I'm working on is really, really hard.
[00:26:40.040 --> 00:26:45.320]   But if you push them enough, two things became clear.
[00:26:45.320 --> 00:26:51.960]   One was high degrees of freedom, like having lots of joints in your robot.
[00:26:51.960 --> 00:26:58.240]   That's kind of hard because a lot of control theoretic approaches, they don't scale very
[00:26:58.240 --> 00:27:01.400]   well with the number of joints on your robot.
[00:27:01.400 --> 00:27:06.040]   So a hand is like, if you have a robotic arm, it's like five robotic arms on your hand.
[00:27:06.040 --> 00:27:07.040]   It's pretty complex.
[00:27:07.040 --> 00:27:10.640]   It doesn't really get more complex than that.
[00:27:10.640 --> 00:27:15.040]   And the other thing people said is like, doing things with contacts is really hard, like
[00:27:15.040 --> 00:27:19.960]   where you're actually manipulating objects.
[00:27:19.960 --> 00:27:26.400]   So that's why we felt like, well, if we really want to convince people that deep reinforcement
[00:27:26.400 --> 00:27:30.120]   learning can solve really complex robotics problems, let's just pick a really, really
[00:27:30.120 --> 00:27:31.320]   hard problem.
[00:27:31.320 --> 00:27:38.440]   And so if we solve that, we feel like a problem where we solve the manipulation problem for
[00:27:38.440 --> 00:27:45.560]   that particular robot, we won't be afraid of manipulation problems anymore in some sense.
[00:27:45.560 --> 00:27:51.600]   So Rubik's Cube was kind of a pretty, once you have the robotic arm, robotic hand, sorry,
[00:27:51.600 --> 00:27:53.240]   then it's like, what do you do with a robotic hand?
[00:27:53.240 --> 00:27:57.000]   Like if it just stuck to the wall, well, you need to kind of put something in the hand
[00:27:57.000 --> 00:27:59.880]   and a ball or something is that it's very exciting.
[00:27:59.880 --> 00:28:02.160]   So what is the most complex object you can think of?
[00:28:02.160 --> 00:28:04.200]   Like a Rubik's Cube is pretty complex.
[00:28:04.200 --> 00:28:07.760]   So that's kind of how we started on the Rubik's Cube in a robotic hand.
[00:28:07.760 --> 00:28:14.040]   And in hindsight, I don't know how smart I was, but it gave us a really tricky problem
[00:28:14.040 --> 00:28:16.040]   to work on.
[00:28:16.040 --> 00:28:17.440]   Interesting.
[00:28:17.440 --> 00:28:21.720]   You would have done something else in hindsight?
[00:28:21.720 --> 00:28:28.480]   I think when we started out with this project, it was kind of pretty crazy.
[00:28:28.480 --> 00:28:32.880]   So we did this thing where we started solving it in a simulator and we thought like, okay,
[00:28:32.880 --> 00:28:36.760]   this is going to maybe take half a year to solve in the simulator.
[00:28:36.760 --> 00:28:40.280]   Like it's going to be tricky to come up with the right reinforcement learning algorithms.
[00:28:40.280 --> 00:28:43.680]   We probably have to iterate on the kind of algorithms and stuff like that.
[00:28:43.680 --> 00:28:44.680]   And then we started on it.
[00:28:44.680 --> 00:28:49.400]   And then within like two or three weeks, we had solved in the simulator.
[00:28:49.400 --> 00:28:53.600]   So we were like, holy shit, that was simple.
[00:28:53.600 --> 00:28:57.000]   So we can probably solve it under the physical hat in like another month or so.
[00:28:57.000 --> 00:28:59.440]   And that was like the famous last words.
[00:28:59.440 --> 00:29:02.680]   So that took like two years from that point.
[00:29:02.680 --> 00:29:10.040]   So I definitely feel like there were certain things we just didn't know about these robotic
[00:29:10.040 --> 00:29:17.960]   hands, like just the fact that nobody had run reinforcement learning algorithms on these
[00:29:17.960 --> 00:29:20.240]   robotic hands before.
[00:29:20.240 --> 00:29:27.600]   And when you train a reinforcement learning algorithm from scratch, and also if you run
[00:29:27.600 --> 00:29:32.240]   it in a simulator, train it in a simulator and deploy it on a real hand, it has no respect
[00:29:32.240 --> 00:29:37.080]   for the delicacy of the hardware.
[00:29:37.080 --> 00:29:42.760]   It would just push all the motors in the maximum speed in different directions.
[00:29:42.760 --> 00:29:48.360]   And we would bring in the manufacturer of this shadow hand and show them what we were
[00:29:48.360 --> 00:29:49.360]   doing.
[00:29:49.360 --> 00:29:52.500]   They would just watch in horror.
[00:29:52.500 --> 00:29:56.760]   We only run it for five minutes and you have it running all day.
[00:29:56.760 --> 00:30:00.160]   And you're running this thing.
[00:30:00.160 --> 00:30:04.880]   Because within an hour, one of the fingers would like the thumb or the little finger
[00:30:04.880 --> 00:30:08.240]   would be loose or like hanging off the thread.
[00:30:08.240 --> 00:30:12.760]   It was like we were completely destroying these robotic hands.
[00:30:12.760 --> 00:30:20.040]   And so I think there was like the iteration time on this hand was just really, really
[00:30:20.040 --> 00:30:21.040]   long.
[00:30:21.040 --> 00:30:25.960]   I definitely feel like it's one of those things like if we had picked a simpler problem, we
[00:30:25.960 --> 00:30:32.600]   would have completed it faster just because the physical aspect of just waiting for repairing
[00:30:32.600 --> 00:30:39.240]   hands and figuring out the dynamics of these really complex hands.
[00:30:39.240 --> 00:30:43.880]   It's definitely easier to tackle a problem if you start from a simpler problem and make
[00:30:43.880 --> 00:30:47.280]   it more advanced than if you pick a really advanced problem and just don't go at it because
[00:30:47.280 --> 00:30:50.520]   then you don't know where the issues are.
[00:30:50.520 --> 00:30:55.760]   And I think this is a little bit like it took us a long time to narrow down and shrink the
[00:30:55.760 --> 00:31:00.560]   complexity to then be able to expand the complexity again as we were solving this task.
[00:31:00.560 --> 00:31:02.400]   So I think this is the main thing.
[00:31:02.400 --> 00:31:08.440]   If it was like a very, if you could buy like super robust, like industrial grade robot
[00:31:08.440 --> 00:31:11.440]   hands, then it might have been different.
[00:31:11.440 --> 00:31:15.440]   But there's basically like two companies in the world that make these very robust hands
[00:31:15.440 --> 00:31:17.800]   because nobody knows how to use them.
[00:31:17.800 --> 00:31:19.640]   I'm surprised there's even two.
[00:31:19.640 --> 00:31:23.600]   I've never seen a robot hand except your robot hand.
[00:31:23.600 --> 00:31:24.600]   Right.
[00:31:24.600 --> 00:31:25.600]   Oh my God.
[00:31:25.600 --> 00:31:31.320]   They sell it to these research institutes and they tell us that they go to these research
[00:31:31.320 --> 00:31:33.240]   institutes and they sell it.
[00:31:33.240 --> 00:31:37.120]   And then like two years later, they visit them and the hand is like in pristine condition.
[00:31:37.120 --> 00:31:42.720]   Nobody dares to touch these robots because they're so complicated.
[00:31:42.720 --> 00:31:43.720]   So anyway.
[00:31:43.720 --> 00:31:47.000]   So tell me about the team.
[00:31:47.000 --> 00:31:51.040]   How big is the team working on this and how do you divide up roles?
[00:31:51.040 --> 00:31:54.800]   How do you even set goals with this?
[00:31:54.800 --> 00:32:00.160]   How do you break apart such a difficult goal that might actually be impossible into smaller
[00:32:00.160 --> 00:32:04.440]   pieces and what does a performance review look like?
[00:32:04.440 --> 00:32:06.400]   Do you actually do that?
[00:32:06.400 --> 00:32:09.080]   Yeah, no, those are good questions.
[00:32:09.080 --> 00:32:14.400]   I think we've learned a lot about this because it's very different from a lot of other situations
[00:32:14.400 --> 00:32:19.760]   where when I was at Dropbox, it's all about like you want to ship a product and you do
[00:32:19.760 --> 00:32:21.080]   everything to ship the product.
[00:32:21.080 --> 00:32:33.880]   And here at OpenAI, we have a pretty ambitious goal of building just more general AI algorithms
[00:32:33.880 --> 00:32:37.040]   and eventually general intelligence.
[00:32:37.040 --> 00:32:40.960]   And so we want to set really ambitious goals for ourselves where we can really feel like
[00:32:40.960 --> 00:32:49.960]   we can push the envelope on what we can do with AI.
[00:32:49.960 --> 00:32:55.640]   And that makes it really tricky to make that into something concrete, especially if you
[00:32:55.640 --> 00:32:56.880]   have lots of people working on it.
[00:32:56.880 --> 00:33:02.880]   Because the other thing that we pretty strongly believe, especially in robotics team, is this
[00:33:02.880 --> 00:33:07.400]   idea of having just more of a team effort to achieve big things.
[00:33:07.400 --> 00:33:11.040]   There's just too many things with robotics, like things that you need to solve, where
[00:33:11.040 --> 00:33:13.480]   you can just have one or two people working on it.
[00:33:13.480 --> 00:33:15.200]   You need a bigger team.
[00:33:15.200 --> 00:33:21.240]   And right now, we found that the sweet spot has been around somewhere between 10 and 20
[00:33:21.240 --> 00:33:22.760]   people in terms of the size of the team.
[00:33:22.760 --> 00:33:28.320]   If you get bigger than that, overhead starts slowing you down quite a bit.
[00:33:28.320 --> 00:33:33.160]   But if you're smaller than 10 people, it's relatively hard to make progress just because
[00:33:33.160 --> 00:33:36.280]   there's just a little bit too many things to do.
[00:33:36.280 --> 00:33:44.400]   So what we try to do is we try to have pretty concrete goals.
[00:33:44.400 --> 00:33:50.360]   So for example, we knew that we were working towards solving RubyScoop for two years.
[00:33:50.360 --> 00:33:53.960]   So this was a very concrete goal.
[00:33:53.960 --> 00:34:03.440]   Once we can see this physical robot solving a real RubyScoop, then we solve this problem.
[00:34:03.440 --> 00:34:10.920]   And having a very concrete goal like that makes it easier to focus and not digress too
[00:34:10.920 --> 00:34:11.920]   much.
[00:34:11.920 --> 00:34:17.720]   So when you're doing research, it's like walking through a forest and you want to get
[00:34:17.720 --> 00:34:23.360]   to the mountain and there's all these nice fruits and berries around.
[00:34:23.360 --> 00:34:25.000]   You just want to say, "Oh, this looks really good.
[00:34:25.000 --> 00:34:29.160]   I want to taste this for a while and see what I can do with it."
[00:34:29.160 --> 00:34:33.120]   It's very tempting at every point in time to just stop and explore for a really, really
[00:34:33.120 --> 00:34:34.120]   long time.
[00:34:34.120 --> 00:34:38.720]   But if you want to solve a really, really big problem, you have to be much more focused
[00:34:38.720 --> 00:34:39.720]   on that.
[00:34:39.720 --> 00:34:50.560]   So seeing this thing in the horizon, this clear goal, it helps a lot.
[00:34:50.560 --> 00:34:54.600]   I think that has been one core component of just how we do things.
[00:34:54.600 --> 00:34:59.600]   It's just clear goals and then having the whole team work towards that.
[00:34:59.600 --> 00:35:10.080]   More in the philosophy of a startup, but less short-term priorities.
[00:35:10.080 --> 00:35:15.960]   We have to try out really ambitious things and things that will fail with very high likelihood.
[00:35:15.960 --> 00:35:20.680]   We want to leapfrog a lot of other approaches with the process we take.
[00:35:20.680 --> 00:35:26.440]   I guess my question is, I'm imagining, and that makes total sense, but what is everyone
[00:35:26.440 --> 00:35:27.440]   doing?
[00:35:27.440 --> 00:35:33.000]   Yeah, it's a good question.
[00:35:33.000 --> 00:35:39.840]   So what is everybody doing?
[00:35:39.840 --> 00:35:44.240]   If you ask anybody at any point in time what they're doing, they're going to tell you,
[00:35:44.240 --> 00:35:45.720]   "Well, I have this bug.
[00:35:45.720 --> 00:35:47.280]   I'm trying to figure out this bug."
[00:35:47.280 --> 00:35:48.280]   It's like any engineer's life.
[00:35:48.280 --> 00:35:52.800]   This is what you're doing almost all of the time.
[00:35:52.800 --> 00:35:55.960]   It's solving, fixing a bug.
[00:35:55.960 --> 00:35:59.000]   But it's different levels of bugs.
[00:35:59.000 --> 00:36:09.040]   And so usually the work is split between doing some kind of engineering towards building
[00:36:09.040 --> 00:36:14.040]   up tooling to understand more of where we're going in terms of our experiments and running
[00:36:14.040 --> 00:36:20.840]   our experiments and so on, or engineering in terms of running our training, training
[00:36:20.840 --> 00:36:28.760]   our models and stuff like that, or a lot of just research on what I mean by research is
[00:36:28.760 --> 00:36:34.840]   kind of more coming up with new algorithms, trying them out, come up with hypotheses,
[00:36:34.840 --> 00:36:40.640]   trying them out, figuring out the best way to set up experiments.
[00:36:40.640 --> 00:36:48.120]   Sometimes that involves doing something that we have come up by ourselves based on where
[00:36:48.120 --> 00:36:49.640]   we are in our research.
[00:36:49.640 --> 00:36:51.560]   That's a new paper that's come out.
[00:36:51.560 --> 00:36:53.400]   We say, "Oh, that might be promising.
[00:36:53.400 --> 00:37:00.200]   Let's reimplement that and see how that compares towards our baseline."
[00:37:00.200 --> 00:37:04.000]   There's just a lot of different things going on, which is really interesting because I
[00:37:04.000 --> 00:37:08.000]   think one thing that's very different from say working at a company where often you're
[00:37:08.000 --> 00:37:13.720]   working on a feature and you're working on that feature for oftentimes at least a quarter,
[00:37:13.720 --> 00:37:17.240]   often many quarters, often a year, you're working on the same thing.
[00:37:17.240 --> 00:37:19.200]   Things switch very quickly.
[00:37:19.200 --> 00:37:22.160]   It's like you're working on one thing for a week, then you work on another thing for
[00:37:22.160 --> 00:37:26.120]   maybe three weeks, and then another thing for a week.
[00:37:26.120 --> 00:37:27.120]   Each project is very different.
[00:37:27.120 --> 00:37:29.560]   It might be like, "Let's make this thing faster.
[00:37:29.560 --> 00:37:34.080]   Let's dig really deep into CUDA optimization for training faster."
[00:37:34.080 --> 00:37:39.200]   And then another day is like, "How do I control this new robot that we got?"
[00:37:39.200 --> 00:37:46.400]   Or then another day is like, "How do I render things really quickly in OpenGL or some Unity
[00:37:46.400 --> 00:37:47.840]   or something like that?"
[00:37:47.840 --> 00:37:50.080]   It's just highly varied work.
[00:37:50.080 --> 00:37:53.320]   Man, that sounds so fun.
[00:37:53.320 --> 00:37:59.520]   I want to work with you.
[00:37:59.520 --> 00:38:01.520]   I could say it's pretty fun.
[00:38:01.520 --> 00:38:05.000]   It's definitely one of those things.
[00:38:05.000 --> 00:38:10.040]   Whenever you get bored, there's another project around the corner that you can jump onto.
[00:38:10.040 --> 00:38:11.040]   You learn a lot.
[00:38:11.040 --> 00:38:12.040]   It's really, really fun.
[00:38:12.040 --> 00:38:13.040]   Nice.
[00:38:13.040 --> 00:38:19.080]   Can I ask you, I don't know if you have thoughts on this, but I was wondering just one really
[00:38:19.080 --> 00:38:20.720]   practical thing I was wondering.
[00:38:20.720 --> 00:38:26.440]   I think when I talked to you maybe a year or two ago, you were completely like, "Hey,
[00:38:26.440 --> 00:38:28.640]   TensorFlow is the best language.
[00:38:28.640 --> 00:38:30.160]   It's clear that that's the thing to use."
[00:38:30.160 --> 00:38:31.640]   And then you guys switched to PyTorch.
[00:38:31.640 --> 00:38:36.760]   And I was wondering why, what happened and how you even...
[00:38:36.760 --> 00:38:44.800]   It seems like switching a framework mid-project sounds unbelievably daunting.
[00:38:44.800 --> 00:38:46.640]   What prompted it?
[00:38:46.640 --> 00:38:51.200]   How did that come about?
[00:38:51.200 --> 00:39:00.280]   I think most of these things have been pretty bottoms up at OpenAI.
[00:39:00.280 --> 00:39:03.840]   Everybody has their main product and one or more side products.
[00:39:03.840 --> 00:39:05.400]   It's just a natural thing.
[00:39:05.400 --> 00:39:09.760]   And then for your side products, you always want to try something, some new tools so you
[00:39:09.760 --> 00:39:11.120]   can learn a little bit more.
[00:39:11.120 --> 00:39:17.360]   So people started playing around with PyTorch for their side projects.
[00:39:17.360 --> 00:39:24.160]   You pretty quickly realize that your code is much, much shorter and much, much more
[00:39:24.160 --> 00:39:29.080]   pleasant to read and much faster to iterate on.
[00:39:29.080 --> 00:39:40.360]   You can just get all the data out in the middle of your computing, your network without running
[00:39:40.360 --> 00:39:45.080]   it through your graph and extracting it from a graph.
[00:39:45.080 --> 00:39:53.080]   It was just a much more pleasant tool to use for people for their own projects.
[00:39:53.080 --> 00:39:55.560]   So then what happens is you have this for your side product.
[00:39:55.560 --> 00:40:08.880]   Then when you start your next project, I think some teams at OpenAI are smaller and they
[00:40:08.880 --> 00:40:12.840]   have a product that runs a month or two and then they try a different product.
[00:40:12.840 --> 00:40:18.000]   Then when you switch products, that's a pretty easy point at which you can switch to a new
[00:40:18.000 --> 00:40:19.000]   tool.
[00:40:19.000 --> 00:40:20.840]   So that's what started happening.
[00:40:20.840 --> 00:40:27.840]   And then some teams started building those tools upon PyTorch and then the other teams
[00:40:27.840 --> 00:40:29.400]   are like, "Oh, that tool looks really nice.
[00:40:29.400 --> 00:40:31.400]   Why don't we switch to PyTorch?"
[00:40:31.400 --> 00:40:38.320]   Suddenly, this FOMO starts growing, growing within the teams and eventually it's too much.
[00:40:38.320 --> 00:40:46.840]   I think we just realized that people just have adopted this tool and we should just
[00:40:46.840 --> 00:40:50.400]   go with the flow and everybody should adopt it.
[00:40:50.400 --> 00:40:54.200]   I think the other thing was just we started building more and more really good tooling
[00:40:54.200 --> 00:40:58.920]   and we wanted the whole company to use that tooling because it just made everybody move
[00:40:58.920 --> 00:40:59.920]   faster.
[00:40:59.920 --> 00:41:05.880]   Luckily for robotics, for example, I think robotics was probably one of the biggest teams
[00:41:05.880 --> 00:41:06.880]   that had to face this switch.
[00:41:06.880 --> 00:41:14.680]   We were pretty lucky in that when we launched this, we released our results with Rubik's
[00:41:14.680 --> 00:41:20.240]   Cube and then we had some time where we could take a step back and do a little bit of a
[00:41:20.240 --> 00:41:23.400]   refactoring of our tooling and change the framework.
[00:41:23.400 --> 00:41:26.160]   I wouldn't have wanted to do this in the middle of a project, as you said.
[00:41:26.160 --> 00:41:31.000]   That seems just a recipe for disaster.
[00:41:31.000 --> 00:41:35.560]   You know, this thing, whenever somebody re-implements a reinforcement learning algorithm, even if
[00:41:35.560 --> 00:41:38.840]   it's the same person that re-implemented last time, it's still going to take them a month
[00:41:38.840 --> 00:41:45.000]   to get it right because it's just so many subtleties.
[00:41:45.000 --> 00:41:48.880]   So what other internal tools are you really proud of?
[00:41:48.880 --> 00:41:49.880]   What stuff have you built?
[00:41:49.880 --> 00:41:53.880]   And do you have plans to open source any of it or make it available to other people or
[00:41:53.880 --> 00:41:55.400]   is it just for OpenAI?
[00:41:55.400 --> 00:41:56.400]   Yeah.
[00:41:56.400 --> 00:42:02.520]   So I think there are a few things that we have released that I think we feel like have
[00:42:02.520 --> 00:42:04.640]   been really useful for ourselves.
[00:42:04.640 --> 00:42:06.640]   And I feel like a lot of people have adopted them.
[00:42:06.640 --> 00:42:09.200]   So that's some recognition that it's been useful for other people.
[00:42:09.200 --> 00:42:12.120]   I think the biggest thing is OpenAI Gym.
[00:42:12.120 --> 00:42:17.480]   It's been there since the beginning of OpenAI, more or less.
[00:42:17.480 --> 00:42:20.480]   It was just one of those things where it was...
[00:42:20.480 --> 00:42:27.360]   That was really when OpenAI got founded was around the time where reinforcement learning
[00:42:27.360 --> 00:42:30.160]   started to work again with deep reinforcement learning.
[00:42:30.160 --> 00:42:34.160]   And people would just re-implement all these very basic environments in which you would
[00:42:34.160 --> 00:42:36.640]   benchmark your algorithms.
[00:42:36.640 --> 00:42:43.160]   And OpenAI built this library called OpenAI Gym, which has all those environments that
[00:42:43.160 --> 00:42:45.320]   people are benchmarking on already implemented.
[00:42:45.320 --> 00:42:46.720]   So people could just use that.
[00:42:46.720 --> 00:42:52.480]   And then it has a really simple abstraction layer and a very simple interface.
[00:42:52.480 --> 00:42:57.240]   So people would just build more and more environments on top of that API.
[00:42:57.240 --> 00:42:58.960]   And so that became really popular.
[00:42:58.960 --> 00:42:59.960]   I think that's a really good one.
[00:42:59.960 --> 00:43:01.800]   I think there are a few others.
[00:43:01.800 --> 00:43:02.800]   We try to...
[00:43:02.800 --> 00:43:09.440]   Whenever we come up with new algorithms that we find that we use ourselves a lot, then
[00:43:09.440 --> 00:43:10.440]   we release them.
[00:43:10.560 --> 00:43:16.560]   So for example, we have this baselines library, which has a lot of implementations of reinforcement
[00:43:16.560 --> 00:43:17.560]   learning algorithms.
[00:43:17.560 --> 00:43:22.640]   And getting those implementations right is really, really hard.
[00:43:22.640 --> 00:43:26.800]   And so releasing that, it's good because it saves people a lot of work.
[00:43:26.800 --> 00:43:27.800]   So we've done that.
[00:43:27.800 --> 00:43:35.280]   I think at Robotics Team in particular, we want to, as soon as we can, separate out some
[00:43:35.280 --> 00:43:36.720]   core component of our workflow.
[00:43:36.720 --> 00:43:37.720]   We try to do that.
[00:43:37.720 --> 00:43:44.640]   So we did this with something called Mojocopi, which is a Python wrapper for a physics simulator
[00:43:44.640 --> 00:43:47.800]   called Mojoco, which we use in all our work.
[00:43:47.800 --> 00:43:48.800]   And so we just released that.
[00:43:48.800 --> 00:43:56.440]   We released it quite a long time ago, but once it was stable enough, we released it.
[00:43:56.440 --> 00:44:00.200]   Similarly, our rendering pipeline, we call it Orb.
[00:44:00.200 --> 00:44:01.200]   We have also released that.
[00:44:01.200 --> 00:44:04.680]   So usually, we try to open source things.
[00:44:04.680 --> 00:44:09.800]   Now, the tricky thing is that we cannot open source all the things we're working on, not
[00:44:09.800 --> 00:44:14.120]   because we don't want to, but because it just would add a lot of overhead.
[00:44:14.120 --> 00:44:20.200]   Because often code in our repositories, it's not very long-lived.
[00:44:20.200 --> 00:44:26.080]   Most of it, I would say 90% is not used after half a year to a year, because it's just like
[00:44:26.080 --> 00:44:29.960]   there are all these hypotheses that we're trying out, and most of them fail.
[00:44:29.960 --> 00:44:34.200]   So it's like you're left with a bunch of code that you basically have to delete because
[00:44:34.200 --> 00:44:35.200]   it doesn't matter.
[00:44:35.200 --> 00:44:41.600]   And we don't want to release stuff just to release it if we don't really believe in it.
[00:44:41.600 --> 00:44:46.000]   So it's really the stuff that survives that we want to release.
[00:44:46.000 --> 00:44:50.120]   And that's kind of the philosophy we have around it.
[00:44:50.120 --> 00:44:54.200]   But when we do have those components, we just try to release it.
[00:44:54.200 --> 00:44:55.200]   Interesting.
[00:44:55.200 --> 00:45:00.120]   I also wanted to ask you, I mean, this is a kind of a loaded question coming from me,
[00:45:00.120 --> 00:45:04.160]   I realize, but I feel really proud that you guys use our product, the Weights and Biases,
[00:45:04.160 --> 00:45:05.160]   or WANDB.
[00:45:05.160 --> 00:45:09.000]   I'm curious if you could say a little bit about how you use it.
[00:45:09.000 --> 00:45:14.760]   I'm not trying to turn this into an infomercial, but I'm genuinely curious what your workflow
[00:45:14.760 --> 00:45:18.720]   is like around it, because I see you using reporting more and more.
[00:45:18.720 --> 00:45:22.880]   And I'm curious how you think about it.
[00:45:22.880 --> 00:45:26.840]   I mean, we have been using it for a while now.
[00:45:26.840 --> 00:45:32.320]   And it's also one of those things, it's like we started using a robotics team because at
[00:45:32.320 --> 00:45:40.200]   some point, as the robotics team grew, we were just sharing a lot of results.
[00:45:40.200 --> 00:45:46.800]   Everybody was running their own TensorBoard graphs on their computers and pieces of graphs
[00:45:46.800 --> 00:45:48.680]   in Slack and sharing with each other.
[00:45:48.680 --> 00:45:51.600]   It's really tricky to keep track of all that stuff.
[00:45:51.600 --> 00:45:56.240]   So then we ended up using it a lot for just tracking our experiments.
[00:45:56.240 --> 00:46:02.440]   And I think that brought us a certain level of sanity in all the chaos that was all of
[00:46:02.440 --> 00:46:05.320]   the research that we were doing as a team grew.
[00:46:05.320 --> 00:46:09.560]   I guess the latest feature that we have now started using quite a lot are these reports.
[00:46:09.560 --> 00:46:14.520]   And this is, I feel like, a pretty pro-user feature in some way.
[00:46:14.520 --> 00:46:19.120]   It's not just plotting the graphs, but it's putting them together in a nice report.
[00:46:19.120 --> 00:46:26.080]   And it's one of those funny things where it's adding a certain level of process and
[00:46:26.080 --> 00:46:28.440]   bureaucracy to have people create these reports.
[00:46:28.440 --> 00:46:32.440]   But we found it to be super useful because when you're a small team, where you're like
[00:46:32.440 --> 00:46:36.400]   two or three people and you're talking all the time about your progress and stuff, everybody
[00:46:36.400 --> 00:46:40.320]   has this mental state of what is happening.
[00:46:40.320 --> 00:46:45.840]   But once you get bigger than maybe five or six people, then giving each other feedback
[00:46:45.840 --> 00:46:48.880]   and understanding what other people are working on and so on, it can be really hard.
[00:46:48.880 --> 00:46:55.240]   And it's like this kind of N-squared problem where you need to talk to everybody and pairwise
[00:46:55.240 --> 00:46:56.800]   little chats going on.
[00:46:56.800 --> 00:47:03.400]   And so figuring out a way to fan out the information from one person to all the others in an efficient
[00:47:03.400 --> 00:47:05.660]   way, it's really, really important.
[00:47:05.660 --> 00:47:14.840]   So the way we use these reports is we're actually pretty strict about it now.
[00:47:14.840 --> 00:47:18.440]   If you're running anything, an experiment, or you have some kind of research hypothesis
[00:47:18.440 --> 00:47:23.280]   that you're going after, and you think it's going to take more than a day or two, we very
[00:47:23.280 --> 00:47:27.160]   strongly push everybody towards writing a report.
[00:47:27.160 --> 00:47:32.400]   And what goes into a report is what are you doing?
[00:47:32.400 --> 00:47:36.480]   What is the experiment that you're going to be running over the next few days?
[00:47:36.480 --> 00:47:40.800]   Because you're probably going to spend thousands of dollars in GPU time and lots of just your
[00:47:40.800 --> 00:47:42.300]   own time on it.
[00:47:42.300 --> 00:47:47.680]   So it's good to spend at least a few minutes justifying for yourself and others what are
[00:47:47.680 --> 00:47:48.680]   you going to do?
[00:47:48.680 --> 00:47:54.120]   And it's not like we're, it's more like, I think we never say like, "No, you shouldn't
[00:47:54.120 --> 00:47:55.120]   do this."
[00:47:55.120 --> 00:47:59.440]   It's more like, we can say like, "Well, I don't know if I believe in that, but okay,
[00:47:59.440 --> 00:48:00.440]   that's fine."
[00:48:00.440 --> 00:48:02.520]   But at least now I understand it.
[00:48:02.520 --> 00:48:05.840]   If you can write down what it is that you're going to do, and we try to make it actually
[00:48:05.840 --> 00:48:12.200]   pretty clear from a just scientific standpoint in terms of like, "Here are my hypotheses,
[00:48:12.200 --> 00:48:15.880]   and here's my plan for proving or disproving these hypotheses."
[00:48:15.880 --> 00:48:21.360]   And then the report is usually a number of graphs and stuff that we have from our training
[00:48:21.360 --> 00:48:26.680]   runs and so on, or example photos that we've generated as part of our evaluation scripts
[00:48:26.680 --> 00:48:28.360]   and so on in these reports.
[00:48:28.360 --> 00:48:34.000]   And we just find it super, super useful because it is a place, it's a little bit of like rubber
[00:48:34.000 --> 00:48:35.000]   ducking.
[00:48:35.000 --> 00:48:37.280]   You're talking to yourself as you're doing this.
[00:48:37.280 --> 00:48:40.560]   It really forces you to clarify your own thoughts.
[00:48:40.560 --> 00:48:49.160]   And it gives a way of having other people learn both from the positive outcomes as well
[00:48:49.160 --> 00:48:51.840]   as the negative outcomes in terms of the experiments you run.
[00:48:51.840 --> 00:48:58.800]   And I think another thing it does is it also forces a reduction in stigma around things
[00:48:58.800 --> 00:49:00.220]   not working out.
[00:49:00.220 --> 00:49:04.440]   Because ultimately, again, in order to do the stuff we're doing, most of the things
[00:49:04.440 --> 00:49:06.200]   are not going to work out.
[00:49:06.200 --> 00:49:10.280]   But if you sweep those things under the rug every time it doesn't work out, then it's
[00:49:10.280 --> 00:49:14.600]   kind of looks like somebody is only doing amazing work and things are just working all
[00:49:14.600 --> 00:49:15.600]   the time.
[00:49:15.600 --> 00:49:18.240]   And you don't hear about all those 90% of the times it didn't work.
[00:49:18.240 --> 00:49:20.560]   And that's usually how it works out in papers and so on.
[00:49:20.560 --> 00:49:24.600]   You see all these papers from people coming out and it's like, everything is working,
[00:49:24.600 --> 00:49:28.200]   but you don't know about all those things they tried that didn't work out.
[00:49:28.200 --> 00:49:33.280]   And what we do internally then is you can look at those things that didn't work out.
[00:49:33.280 --> 00:49:35.440]   You see, okay, other people are actually doing these experiments.
[00:49:35.440 --> 00:49:39.460]   They had this really believed that it would work, but it didn't end up working.
[00:49:39.460 --> 00:49:44.680]   And so you don't feel as afraid yourself to kind of pursue experiments because as long
[00:49:44.680 --> 00:49:49.080]   as you have a good reason for why it would work, it's okay if it didn't work out.
[00:49:49.080 --> 00:49:52.120]   Well, it makes me so proud to hear that.
[00:49:52.120 --> 00:49:54.160]   I'm so glad that it's useful for you.
[00:49:54.160 --> 00:49:55.160]   Yeah, it's awesome.
[00:49:55.160 --> 00:49:58.120]   So we always end with two questions.
[00:49:58.120 --> 00:50:00.680]   I'm wondering how you'll answer these.
[00:50:00.680 --> 00:50:08.440]   So the first one is, what's a topic in machine learning that you feel like people don't talk
[00:50:08.440 --> 00:50:11.720]   about as much as they should, like an underrated topic?
[00:50:11.720 --> 00:50:18.480]   I don't know if it's a thing that people don't talk about, but it's definitely a thing which
[00:50:18.480 --> 00:50:26.280]   we don't understand well enough, which is understanding when our arguments are uncertain
[00:50:26.280 --> 00:50:29.000]   about what they're doing.
[00:50:29.000 --> 00:50:36.920]   It's just like one of those things where for humans, it's very natural.
[00:50:36.920 --> 00:50:42.240]   When you don't know what's going on, you kind of slow down and you are more perceptive,
[00:50:42.240 --> 00:50:44.200]   you think more and so on.
[00:50:44.200 --> 00:50:51.960]   And the algorithms that we have today are very much like they make split decisions all
[00:50:51.960 --> 00:50:52.960]   the time.
[00:50:52.960 --> 00:50:55.160]   They don't think very much at all.
[00:50:55.160 --> 00:50:59.240]   They just open their eyes and see something and just react.
[00:50:59.240 --> 00:51:00.240]   And that's it.
[00:51:00.240 --> 00:51:03.320]   It's like when we're walking into a dark room, it's not good.
[00:51:03.320 --> 00:51:06.120]   We run around and play with our arms.
[00:51:06.120 --> 00:51:07.680]   We feel our way around it.
[00:51:07.680 --> 00:51:08.680]   We take it easy.
[00:51:08.680 --> 00:51:12.080]   And our algorithms don't do that at all.
[00:51:12.080 --> 00:51:24.040]   And so giving them a sense of either self-confidence, it's sort of like my PhD advisor would sometimes
[00:51:24.040 --> 00:51:29.600]   a bit meanly comment on people being high confidence, low confidence.
[00:51:29.600 --> 00:51:37.680]   That's very much how our algorithms are a lot of times.
[00:51:37.680 --> 00:51:44.160]   It should be a little bit lower confidence a lot of times and not try to be as much.
[00:51:44.160 --> 00:51:47.160]   I love it.
[00:51:47.160 --> 00:51:49.320]   All right.
[00:51:49.320 --> 00:51:50.320]   Here's my last question.
[00:51:50.320 --> 00:51:57.760]   So when you look at the projects you've been involved in from conception to deployment,
[00:51:57.760 --> 00:52:02.440]   what's generally been the biggest bottleneck or the thing that makes you the most worried
[00:52:02.440 --> 00:52:09.160]   if you're doing another project where you need to get it deployed?
[00:52:09.160 --> 00:52:13.680]   It sounds like hardware was the biggest issue.
[00:52:13.680 --> 00:52:14.680]   For robotics, totally.
[00:52:14.680 --> 00:52:15.680]   It's definitely one of these things.
[00:52:15.680 --> 00:52:22.520]   If you can get hardware that's really useful, then it's very reliable.
[00:52:22.520 --> 00:52:24.400]   You should pay all the money you can.
[00:52:24.400 --> 00:52:29.880]   I remember when we started OpenAI, we were like, we're going to get by by these $100
[00:52:29.880 --> 00:52:30.880]   webcams and stuff.
[00:52:30.880 --> 00:52:33.880]   I was like, how much is this camera?
[00:52:33.880 --> 00:52:34.880]   $10,000?
[00:52:34.880 --> 00:52:35.880]   It's probably worth it.
[00:52:35.880 --> 00:52:36.880]   This is $10,000 for this camera.
[00:52:36.880 --> 00:52:43.960]   Because it saved me half a year of my misery.
[00:52:43.960 --> 00:52:49.760]   So that's definitely a big thing.
[00:52:49.760 --> 00:52:55.000]   I think one thing that always gets me a little bit worried is when you don't start with the
[00:52:55.000 --> 00:52:56.000]   simplest things.
[00:52:56.000 --> 00:53:00.040]   I really think this is one of the core things.
[00:53:00.040 --> 00:53:07.480]   For every project you start out with, you should start with a strong but simple baseline.
[00:53:07.480 --> 00:53:14.640]   If people don't start in that direction, if you try out more complex methods, they're
[00:53:14.640 --> 00:53:25.200]   often going to be like, in terms of the parameters, exponentially harder to get to work, basically.
[00:53:25.200 --> 00:53:30.400]   And then you're going to do all this work and you're going to make it work in the end.
[00:53:30.400 --> 00:53:34.120]   But then if you try out the simpler approach and that works, you're just going to feel
[00:53:34.120 --> 00:53:35.120]   really embarrassed.
[00:53:35.120 --> 00:53:39.960]   And that just teaches you that you should always start with the simplest thing.
[00:53:39.960 --> 00:53:42.200]   And then you can try these more complicated things.
[00:53:42.200 --> 00:53:47.320]   But if you cannot beat the simple thing, after a while, your warmth for this simple thing
[00:53:47.320 --> 00:53:48.320]   increases.
[00:53:48.320 --> 00:53:51.000]   And you're like, actually, maybe I should just use the simple thing.
[00:53:51.000 --> 00:53:53.200]   And you learn to appreciate the simple things.
[00:53:53.200 --> 00:53:58.400]   I think this is one of the core things I always look for.
[00:53:58.400 --> 00:54:00.320]   Are we trying the simplest thing possible?
[00:54:00.320 --> 00:54:02.720]   Because that's probably the thing that's going to work.
[00:54:02.720 --> 00:54:06.280]   Wow, what a great note to end on.
[00:54:06.280 --> 00:54:07.280]   Thank you so much, Peter.
[00:54:07.280 --> 00:54:08.280]   Thank you so much.
[00:54:08.280 --> 00:54:11.040]   It was great being on your show.
[00:54:11.040 --> 00:54:11.880]   Thank you so much.
[00:54:11.960 --> 00:54:21.960]   [MUSIC PLAYING]

