
[00:00:00.000 --> 00:00:02.800]   The following is a conversation with Colin Angle.
[00:00:02.800 --> 00:00:05.840]   He's the CEO and co-founder of iRobot,
[00:00:05.840 --> 00:00:08.220]   a robotics company that for 29 years
[00:00:08.220 --> 00:00:11.180]   has been creating robots that operate successfully
[00:00:11.180 --> 00:00:12.600]   in the real world.
[00:00:12.600 --> 00:00:15.640]   Not as a demo or on a scale of dozens,
[00:00:15.640 --> 00:00:18.860]   but on a scale of thousands and millions.
[00:00:18.860 --> 00:00:21.900]   As of this year, iRobot has sold more than
[00:00:21.900 --> 00:00:25.700]   25 million robots to consumers,
[00:00:25.700 --> 00:00:28.200]   including the Roomba vacuum cleaning robot,
[00:00:28.200 --> 00:00:30.000]   the Bravo floor mopping robot,
[00:00:30.000 --> 00:00:34.000]   and soon the Terra lawn mowing robot.
[00:00:34.000 --> 00:00:37.660]   29 million robots successfully operating autonomously
[00:00:37.660 --> 00:00:39.620]   in real people's homes,
[00:00:39.620 --> 00:00:42.080]   to me is an incredible accomplishment
[00:00:42.080 --> 00:00:45.080]   of science, engineering, logistics,
[00:00:45.080 --> 00:00:48.760]   and all kinds of general entrepreneurial innovation.
[00:00:48.760 --> 00:00:51.340]   Most robotics companies fail.
[00:00:51.340 --> 00:00:56.900]   iRobot has survived and succeeded for 29 years.
[00:00:56.900 --> 00:00:58.860]   I spent all day at iRobot,
[00:00:58.860 --> 00:01:01.400]   including a long tour and conversation with Colin
[00:01:01.400 --> 00:01:03.520]   about the history of iRobot,
[00:01:03.520 --> 00:01:06.740]   and then sat down for this podcast conversation
[00:01:06.740 --> 00:01:08.540]   that would have been much longer
[00:01:08.540 --> 00:01:10.780]   if I didn't spend all day learning about
[00:01:10.780 --> 00:01:12.320]   and playing with the various robots
[00:01:12.320 --> 00:01:13.960]   and the company's history.
[00:01:13.960 --> 00:01:17.500]   I'll release the video of the tour separately.
[00:01:17.500 --> 00:01:20.720]   Colin, iRobot, its founding team,
[00:01:20.720 --> 00:01:23.220]   its current team, and its mission
[00:01:23.220 --> 00:01:26.220]   has been and continues to be an inspiration to me
[00:01:26.220 --> 00:01:28.880]   and thousands of engineers who are working hard
[00:01:28.880 --> 00:01:33.020]   to create AI systems that help real people.
[00:01:33.020 --> 00:01:35.640]   This is the Artificial Intelligence Podcast.
[00:01:35.640 --> 00:01:38.020]   If you enjoy it, subscribe on YouTube,
[00:01:38.020 --> 00:01:39.780]   give it five stars on iTunes,
[00:01:39.780 --> 00:01:41.280]   support it on Patreon,
[00:01:41.280 --> 00:01:43.280]   or simply connect with me on Twitter
[00:01:43.280 --> 00:01:47.120]   at Lex Friedman, spelled F-R-I-D-M-A-N.
[00:01:47.120 --> 00:01:51.080]   And now, here's my conversation with Colin Engel.
[00:01:51.080 --> 00:01:55.120]   In his 1942 short story, "Runaround,"
[00:01:55.120 --> 00:01:56.960]   from his iRobot collection,
[00:01:56.960 --> 00:02:01.920]   Asimov proposed the three laws of robotics
[00:02:01.920 --> 00:02:06.800]   in order, don't harm humans, obey orders, protect yourself.
[00:02:06.800 --> 00:02:07.680]   So two questions.
[00:02:07.680 --> 00:02:11.640]   First, does the Roomba follow these three laws?
[00:02:11.640 --> 00:02:14.760]   And also, more seriously,
[00:02:14.760 --> 00:02:18.240]   what role do you hope to see robots take in modern society
[00:02:18.240 --> 00:02:20.320]   and in the future world?
[00:02:21.520 --> 00:02:25.760]   - So the three laws are very thought-provoking
[00:02:25.760 --> 00:02:30.760]   and require such a profound understanding
[00:02:30.760 --> 00:02:36.280]   of the world a robot lives in,
[00:02:36.280 --> 00:02:38.400]   the ramifications of its action,
[00:02:38.400 --> 00:02:40.040]   and its own sense of self,
[00:02:40.040 --> 00:02:44.740]   that it's not a relevant bar,
[00:02:44.740 --> 00:02:50.120]   at least it won't be a relevant bar for decades to come.
[00:02:50.120 --> 00:02:54.600]   And so if Roomba follows the three laws,
[00:02:54.600 --> 00:02:56.980]   and I believe it does,
[00:02:56.980 --> 00:03:00.960]   it is designed to help humans, not hurt them,
[00:03:00.960 --> 00:03:03.160]   it's designed to be inherently safe,
[00:03:03.160 --> 00:03:06.040]   and we designed it to last a long time,
[00:03:06.040 --> 00:03:11.640]   it's not through any AI or intent on the robot's part.
[00:03:11.640 --> 00:03:15.000]   It's because following the three laws
[00:03:15.000 --> 00:03:18.220]   is aligned with being a good robot product.
[00:03:19.640 --> 00:03:23.120]   So I guess it does,
[00:03:23.120 --> 00:03:27.240]   but not by explicit design.
[00:03:27.240 --> 00:03:28.800]   - So then the bigger picture,
[00:03:28.800 --> 00:03:33.040]   what role do you hope to see robotics, robots take
[00:03:33.040 --> 00:03:37.360]   in what's currently mostly a world of humans?
[00:03:37.360 --> 00:03:42.360]   - We need robots to help us continue
[00:03:42.360 --> 00:03:45.120]   to improve our standard of living.
[00:03:46.280 --> 00:03:51.280]   We need robots because the average age of humanity
[00:03:51.280 --> 00:03:55.200]   is increasing very quickly,
[00:03:55.200 --> 00:03:59.920]   and simply the number of people young enough
[00:03:59.920 --> 00:04:02.720]   and spry enough to care for the older,
[00:04:02.720 --> 00:04:08.080]   growing demographic is inadequate.
[00:04:08.080 --> 00:04:11.560]   And so what is the role of robots?
[00:04:11.560 --> 00:04:15.080]   Today the role is to make our lives a little easier,
[00:04:15.080 --> 00:04:17.500]   a little cleaner, maybe a little healthier,
[00:04:17.500 --> 00:04:22.280]   but in time, robots are gonna be the difference
[00:04:22.280 --> 00:04:25.840]   between real gut-wrenching declines
[00:04:25.840 --> 00:04:28.280]   in our ability to live independently
[00:04:28.280 --> 00:04:30.440]   and maintain our standard of living,
[00:04:30.440 --> 00:04:35.060]   and a future that is the bright one
[00:04:35.060 --> 00:04:37.640]   where we have more control over our lives,
[00:04:37.640 --> 00:04:42.640]   can spend more of our time focused on activities we choose,
[00:04:44.680 --> 00:04:48.080]   and I'm so honored and excited
[00:04:48.080 --> 00:04:50.520]   to be playing a role in that journey.
[00:04:50.520 --> 00:04:51.840]   - So you give me a tour,
[00:04:51.840 --> 00:04:54.080]   you showed me some of the long histories,
[00:04:54.080 --> 00:04:57.280]   now 29 years that iRobot has been at it,
[00:04:57.280 --> 00:04:59.320]   creating some incredible robots.
[00:04:59.320 --> 00:05:01.280]   You showed me PackBot,
[00:05:01.280 --> 00:05:03.200]   you showed me a bunch of other stuff
[00:05:03.200 --> 00:05:08.200]   that led up to Roomba, that led to Bravo and Terra.
[00:05:08.200 --> 00:05:14.080]   So let's skip that incredible history
[00:05:14.080 --> 00:05:15.040]   in the interest of time,
[00:05:15.040 --> 00:05:16.120]   'cause we already talked about it,
[00:05:16.120 --> 00:05:18.040]   I'll show this incredible footage.
[00:05:18.040 --> 00:05:22.640]   You mentioned elderly, and robotics in society,
[00:05:22.640 --> 00:05:26.260]   I think the home is a fascinating place for robots to be.
[00:05:26.260 --> 00:05:29.800]   So where do you see robots in the home?
[00:05:29.800 --> 00:05:31.640]   Currently, I would say, once again,
[00:05:31.640 --> 00:05:34.520]   probably most homes in the world don't have a robot.
[00:05:34.520 --> 00:05:36.160]   So how do you see that changing?
[00:05:36.160 --> 00:05:39.840]   Where do you think is the big initial value add
[00:05:39.840 --> 00:05:41.920]   that robots can do?
[00:05:41.920 --> 00:05:45.000]   - So iRobot has sort of over the years,
[00:05:45.000 --> 00:05:49.400]   narrowed in on the home, the consumer's home,
[00:05:49.400 --> 00:05:53.160]   as the place where we want to innovate
[00:05:53.160 --> 00:05:58.160]   and deliver tools that will help a home
[00:05:58.160 --> 00:06:04.280]   be a more automatically maintained place,
[00:06:04.280 --> 00:06:06.840]   a healthier place, a safer place,
[00:06:06.840 --> 00:06:11.520]   and perhaps even a more efficient place to be.
[00:06:11.520 --> 00:06:16.520]   And today, vacuum, we mop, soon we'll be mowing your lawn,
[00:06:16.520 --> 00:06:21.480]   but where things are going is,
[00:06:21.480 --> 00:06:27.080]   when do we get to the point where the home,
[00:06:27.080 --> 00:06:29.120]   not just the robots that live in your home,
[00:06:29.120 --> 00:06:32.160]   but the home itself becomes part of a system
[00:06:32.160 --> 00:06:35.960]   that maintains itself and plays an active role
[00:06:35.960 --> 00:06:40.760]   in caring for and helping the people who live in that home.
[00:06:40.760 --> 00:06:43.200]   And I see everything that we're doing
[00:06:43.200 --> 00:06:46.160]   as steps along the path toward that future.
[00:06:46.160 --> 00:06:47.720]   - So what are the steps?
[00:06:47.720 --> 00:06:51.760]   So if we can summarize some of the history of Roomba,
[00:06:51.760 --> 00:06:55.520]   you've mentioned, and maybe you can elaborate on it,
[00:06:55.520 --> 00:06:57.240]   but you mentioned that the early days
[00:06:57.240 --> 00:07:02.240]   were really taking a robot from something that works
[00:07:02.240 --> 00:07:04.880]   either in the lab or something that works in the field
[00:07:04.880 --> 00:07:09.880]   that helps soldiers do the difficult work they do
[00:07:10.200 --> 00:07:12.640]   to actually be in the hands of consumers
[00:07:12.640 --> 00:07:15.640]   and tens of thousands, hundreds of thousands of robots
[00:07:15.640 --> 00:07:18.480]   that don't break down over how much people love them
[00:07:18.480 --> 00:07:21.440]   over months of very extensive use.
[00:07:21.440 --> 00:07:22.840]   So that was the big first step.
[00:07:22.840 --> 00:07:26.000]   And then the second big step was the ability
[00:07:26.000 --> 00:07:29.920]   to sense the environment, to build a map, to localize,
[00:07:29.920 --> 00:07:32.600]   to be able to build a picture of the home
[00:07:32.600 --> 00:07:34.640]   that the human can then attach labels to
[00:07:34.640 --> 00:07:39.120]   in terms of giving some semantic knowledge to the robot
[00:07:39.120 --> 00:07:40.920]   about its environment.
[00:07:40.920 --> 00:07:44.880]   Okay, so that's like a huge, two big, huge steps.
[00:07:44.880 --> 00:07:47.560]   Maybe you can comment on them,
[00:07:47.560 --> 00:07:51.080]   but also what is the next step
[00:07:51.080 --> 00:07:54.760]   of making a robot part of the home?
[00:07:54.760 --> 00:07:55.600]   - Sure.
[00:07:55.600 --> 00:08:00.600]   So the goal is to make a home that takes care of itself,
[00:08:00.600 --> 00:08:03.720]   takes care of the people in the home,
[00:08:03.720 --> 00:08:07.860]   and gives the user an experience of just living their life
[00:08:07.860 --> 00:08:10.880]   in the home is somehow doing the right thing,
[00:08:10.880 --> 00:08:14.160]   turning on and off lights when you leave,
[00:08:14.160 --> 00:08:17.280]   cleaning up the environment.
[00:08:17.280 --> 00:08:22.280]   And we went from robots that were great in the lab,
[00:08:22.280 --> 00:08:30.000]   but were both too expensive and not sufficiently capable
[00:08:30.000 --> 00:08:33.800]   to ever do an acceptable job of anything
[00:08:33.800 --> 00:08:37.360]   other than being a toy or a curio in your home
[00:08:37.360 --> 00:08:42.160]   to something that was both affordable
[00:08:42.160 --> 00:08:45.840]   and sufficiently effective to drive,
[00:08:45.840 --> 00:08:48.520]   be above threshold and drive purchase intent.
[00:08:48.520 --> 00:08:54.400]   Now we've disrupted the entire vacuuming industry.
[00:08:54.400 --> 00:08:59.360]   The number one selling vacuums, for example,
[00:08:59.360 --> 00:09:02.960]   in the US are Roombas, so not robot vacuums, but vacuums.
[00:09:02.960 --> 00:09:04.640]   And that's really crazy and weird.
[00:09:04.640 --> 00:09:06.440]   - Yes, we need to pause it.
[00:09:06.440 --> 00:09:08.080]   I mean, that's incredible.
[00:09:08.080 --> 00:09:13.080]   That's incredible that a robot is the number one selling
[00:09:13.080 --> 00:09:15.560]   thing that does something.
[00:09:15.560 --> 00:09:16.400]   - Yep.
[00:09:16.400 --> 00:09:18.240]   - Something as essential as vacuuming.
[00:09:18.240 --> 00:09:19.080]   - So we're--
[00:09:19.080 --> 00:09:20.080]   - Congratulations.
[00:09:20.080 --> 00:09:20.920]   - Thank you.
[00:09:20.920 --> 00:09:22.440]   It's still kind of fun to say,
[00:09:22.440 --> 00:09:26.600]   but just because this was a crazy idea
[00:09:26.600 --> 00:09:30.920]   that just started in a room here,
[00:09:30.920 --> 00:09:33.700]   we're like, do you think we can do this?
[00:09:33.700 --> 00:09:36.180]   So, hey, let's give it a try.
[00:09:36.180 --> 00:09:40.420]   But now the robots are starting
[00:09:40.420 --> 00:09:42.860]   to understand their environment.
[00:09:42.860 --> 00:09:45.260]   And if you think about the next step,
[00:09:45.260 --> 00:09:47.900]   there's two dimensions.
[00:09:47.900 --> 00:09:53.060]   I've been working so hard since the beginning of iRobot
[00:09:53.060 --> 00:09:55.100]   to make robots are autonomous,
[00:09:55.100 --> 00:09:59.140]   that they're smart enough and understand their task enough
[00:09:59.140 --> 00:10:02.500]   that they can just go do it without human involvement.
[00:10:03.500 --> 00:10:07.460]   Now what I'm really excited and working on
[00:10:07.460 --> 00:10:09.560]   is how do I make them less autonomous?
[00:10:09.560 --> 00:10:15.660]   Meaning that the robot is supposed to be your partner,
[00:10:15.660 --> 00:10:18.300]   not this automaton that just goes and does
[00:10:18.300 --> 00:10:20.220]   what a robot does.
[00:10:20.220 --> 00:10:22.500]   And so that if you tell it,
[00:10:22.500 --> 00:10:27.140]   hey, I just dropped some flour by the fridge in the kitchen.
[00:10:27.140 --> 00:10:28.980]   Can you deal with it?
[00:10:28.980 --> 00:10:31.860]   Wouldn't it be awesome if the right thing just happened
[00:10:32.780 --> 00:10:35.260]   based on that utterance?
[00:10:35.260 --> 00:10:37.980]   And to some extent that's less autonomous
[00:10:37.980 --> 00:10:40.140]   'cause it's actually listening to you,
[00:10:40.140 --> 00:10:44.420]   understanding the context and intent of the sentence,
[00:10:44.420 --> 00:10:49.420]   mapping it against its understanding of the home it lives in
[00:10:49.420 --> 00:10:52.700]   and knowing what to do.
[00:10:52.700 --> 00:10:56.380]   And so that's an area of research.
[00:10:56.380 --> 00:10:59.400]   It's an area where we're starting to roll out features.
[00:10:59.400 --> 00:11:02.900]   You can now tell your robot to clean up the kitchen
[00:11:02.900 --> 00:11:05.900]   and it knows what the kitchen is and can do that.
[00:11:05.900 --> 00:11:09.380]   And that's sort of 1.0 of where we're going.
[00:11:09.380 --> 00:11:13.300]   The other cool thing is that we're starting to know
[00:11:13.300 --> 00:11:16.060]   where stuff is and why is that important?
[00:11:16.060 --> 00:11:21.060]   Well, robots are supposed to have arms, right?
[00:11:21.060 --> 00:11:24.260]   Data had an arm, Rosie had an arm,
[00:11:24.260 --> 00:11:25.300]   Robbie the robot had an arm.
[00:11:25.300 --> 00:11:26.700]   I mean, robots are,
[00:11:26.700 --> 00:11:28.800]   they are physical things that move around
[00:11:28.800 --> 00:11:31.280]   in an environment and they're supposed to do work.
[00:11:31.280 --> 00:11:34.140]   And if you think about it,
[00:11:34.140 --> 00:11:37.240]   if a robot doesn't know where anything is,
[00:11:37.240 --> 00:11:38.800]   why should it have an arm?
[00:11:38.800 --> 00:11:43.800]   But with this new dawn of home understanding
[00:11:43.800 --> 00:11:47.720]   that we're starting to go enjoy,
[00:11:47.720 --> 00:11:49.360]   I know where the kitchen is.
[00:11:49.360 --> 00:11:52.080]   I might in the future know where the refrigerator is.
[00:11:52.080 --> 00:11:55.320]   I might, if I had an arm, be able to find the handle,
[00:11:55.320 --> 00:11:58.540]   open it and even get myself a beer.
[00:11:58.540 --> 00:12:01.980]   Obviously that's one of the true dreams of robotics
[00:12:01.980 --> 00:12:03.580]   is to have robots bringing us a beer
[00:12:03.580 --> 00:12:05.340]   while we watch television.
[00:12:05.340 --> 00:12:10.340]   But I think that that new category of tasks
[00:12:10.340 --> 00:12:14.260]   where physical manipulation, robot arms,
[00:12:14.260 --> 00:12:19.260]   is just a potpourri of new opportunity and excitement.
[00:12:19.260 --> 00:12:23.820]   - And you see humans as a crucial part of that.
[00:12:23.820 --> 00:12:26.320]   So you kind of mentioned that,
[00:12:26.320 --> 00:12:29.000]   and I personally find that a really compelling idea.
[00:12:29.000 --> 00:12:34.000]   I think full autonomy can only take us so far,
[00:12:34.000 --> 00:12:35.360]   especially in the home.
[00:12:35.360 --> 00:12:38.920]   So you see humans as helping the robot understand
[00:12:38.920 --> 00:12:42.580]   or give deeper meaning to this spatial information.
[00:12:42.580 --> 00:12:45.720]   - Right, it's a partnership.
[00:12:45.720 --> 00:12:48.980]   The robot is supposed to operate
[00:12:48.980 --> 00:12:53.980]   according to descriptors that you would use
[00:12:53.980 --> 00:12:55.640]   to describe your own home.
[00:12:55.640 --> 00:13:02.040]   The robot is supposed to, in lieu of better direction,
[00:13:02.040 --> 00:13:03.960]   kind of go about its routine,
[00:13:03.960 --> 00:13:07.660]   which ought to be basically right
[00:13:07.660 --> 00:13:12.340]   and lead to a home maintained
[00:13:12.340 --> 00:13:14.980]   in a way that it's learned you like,
[00:13:14.980 --> 00:13:19.980]   but also be perpetually ready to take direction
[00:13:19.980 --> 00:13:26.560]   that would activate a different set of behaviors or actions
[00:13:26.560 --> 00:13:29.040]   to meet a current need
[00:13:29.040 --> 00:13:32.420]   to the extent it could actually perform that task.
[00:13:32.420 --> 00:13:33.640]   - So I gotta ask you,
[00:13:33.640 --> 00:13:37.040]   I think this is a fundamental and a fascinating question,
[00:13:37.040 --> 00:13:39.860]   because iRobot has been a successful company
[00:13:39.860 --> 00:13:42.400]   and a rare successful robotics company.
[00:13:42.400 --> 00:13:46.820]   So Anki, Jibo, Mayfield Robotics with their Robot Curry,
[00:13:46.820 --> 00:13:49.260]   Sci-Fi Works, Rethink Robotics,
[00:13:49.260 --> 00:13:51.400]   these are robotics companies that were founded
[00:13:51.400 --> 00:13:53.000]   and run by brilliant people.
[00:13:53.000 --> 00:13:59.100]   But all, very unfortunately, at least for us roboticists,
[00:13:59.100 --> 00:14:02.180]   all went out of business recently.
[00:14:02.180 --> 00:14:05.180]   So why do you think they didn't last longer?
[00:14:05.180 --> 00:14:07.020]   Why do you think it is so hard
[00:14:07.020 --> 00:14:10.700]   to keep a robotics company alive?
[00:14:10.700 --> 00:14:14.180]   - You know, I say this only partially in jest
[00:14:14.180 --> 00:14:16.800]   that back in the day before Roomba,
[00:14:16.800 --> 00:14:22.860]   you know, I was a high-tech entrepreneur building robots,
[00:14:22.860 --> 00:14:26.460]   but it wasn't until I became a vacuum cleaner salesman
[00:14:26.460 --> 00:14:28.240]   that we had any success.
[00:14:28.240 --> 00:14:34.220]   So, I mean, the point is technology alone
[00:14:34.220 --> 00:14:36.880]   doesn't equal a successful business.
[00:14:37.720 --> 00:14:42.640]   We need to go and find the compelling need
[00:14:42.640 --> 00:14:45.920]   where the robot that we're creating
[00:14:45.920 --> 00:14:52.640]   can deliver clearly more value
[00:14:52.640 --> 00:14:55.440]   to the end user than it costs.
[00:14:55.440 --> 00:14:59.040]   And this is not a marginal thing
[00:14:59.040 --> 00:15:00.400]   where you're looking at the scale and you're like,
[00:15:00.400 --> 00:15:03.360]   "Eh, it's close, maybe we can hold our breath
[00:15:03.360 --> 00:15:04.380]   "and make it work."
[00:15:04.380 --> 00:15:09.380]   It's clearly more value than the cost of the robot
[00:15:09.380 --> 00:15:13.900]   to bring in the store.
[00:15:13.900 --> 00:15:15.820]   And I think that the challenge has been
[00:15:15.820 --> 00:15:20.820]   finding those businesses
[00:15:20.820 --> 00:15:26.020]   where that's true in a sustainable fashion.
[00:15:26.020 --> 00:15:33.220]   You know, when you get into entertainment style things,
[00:15:34.060 --> 00:15:38.220]   you could be the cat's meow one year,
[00:15:38.220 --> 00:15:42.400]   but 85% of toys, regardless of their merit,
[00:15:42.400 --> 00:15:45.620]   fail to make it to their second season.
[00:15:45.620 --> 00:15:47.720]   It's just super hard to do so.
[00:15:47.720 --> 00:15:53.700]   And so that's just a tough business.
[00:15:53.700 --> 00:15:57.780]   And there's been a lot of experimentation
[00:15:57.780 --> 00:16:02.620]   around what is the right type of social companion?
[00:16:02.620 --> 00:16:05.840]   What is the right robot in the home
[00:16:05.840 --> 00:16:10.840]   that is doing something other than tasks people do
[00:16:10.840 --> 00:16:16.380]   every week that they'd rather not do?
[00:16:16.380 --> 00:16:20.880]   And I'm not sure we've got it all figured out right.
[00:16:20.880 --> 00:16:22.960]   And so that you get brilliant roboticists
[00:16:22.960 --> 00:16:25.660]   with super interesting robots
[00:16:25.660 --> 00:16:29.800]   that ultimately don't quite have
[00:16:29.800 --> 00:16:32.860]   that magical user experience,
[00:16:32.860 --> 00:16:37.860]   and thus that value benefit equation remains ambiguous.
[00:16:37.860 --> 00:16:44.240]   - So you as somebody who dreams of robots
[00:16:44.240 --> 00:16:46.900]   changing the world, what's your estimate?
[00:16:46.900 --> 00:16:53.200]   How big is the space of applications
[00:16:53.200 --> 00:16:55.780]   that fit the criteria that you just described
[00:16:55.780 --> 00:16:58.060]   where you can really demonstrate
[00:16:58.060 --> 00:17:00.480]   an obvious significant value
[00:17:00.480 --> 00:17:04.620]   over the alternative non-robotic solution?
[00:17:04.620 --> 00:17:08.660]   - Well, I think that we're just about none of the way
[00:17:08.660 --> 00:17:13.340]   to achieving the potential of robotics at home.
[00:17:13.340 --> 00:17:18.340]   But we have to do it in a really eyes wide open,
[00:17:18.340 --> 00:17:22.340]   honest fashion.
[00:17:22.340 --> 00:17:25.380]   - Another way to put that is the potential is infinite
[00:17:25.380 --> 00:17:27.020]   because we did take a few steps,
[00:17:27.020 --> 00:17:29.620]   but you're saying those steps are just very initial steps.
[00:17:29.620 --> 00:17:32.540]   So the Roomba is a hugely successful product,
[00:17:32.540 --> 00:17:34.380]   but you're saying that's just the very, very beginning.
[00:17:34.380 --> 00:17:36.500]   - That's just the very, very beginning.
[00:17:36.500 --> 00:17:37.940]   It's the foot in the door.
[00:17:37.940 --> 00:17:42.940]   And I think I was lucky that in the early days of robotics,
[00:17:42.940 --> 00:17:48.380]   people would ask me, "When are you gonna clean my floor?"
[00:17:48.380 --> 00:17:52.240]   It was something that I grew up saying,
[00:17:52.240 --> 00:17:54.780]   "I got all these really good ideas,
[00:17:54.780 --> 00:17:58.060]   but everyone seems to want their floor clean.
[00:17:58.060 --> 00:18:02.260]   And so maybe we should do that."
[00:18:02.260 --> 00:18:03.380]   - Yeah, your good ideas--
[00:18:03.380 --> 00:18:05.820]   - Earn the right to do the next thing after that.
[00:18:05.820 --> 00:18:07.900]   - So the good ideas have to match
[00:18:07.900 --> 00:18:10.140]   with the desire of the people,
[00:18:10.140 --> 00:18:12.580]   and then the actual cost has to,
[00:18:12.580 --> 00:18:16.620]   like the financial aspect has to all match together.
[00:18:16.620 --> 00:18:21.260]   - Yeah, during our partnership back a number of years ago
[00:18:21.260 --> 00:18:24.100]   with Johnson Wax, they would explain to me
[00:18:24.100 --> 00:18:29.100]   that they would go into homes
[00:18:29.100 --> 00:18:32.500]   and just watch how people lived
[00:18:32.500 --> 00:18:35.540]   and try to figure out what were they doing
[00:18:35.540 --> 00:18:39.960]   that they really didn't really like to do,
[00:18:39.960 --> 00:18:42.420]   but they had to do it frequently enough
[00:18:42.420 --> 00:18:47.420]   that it was top of mind and understood as a burden.
[00:18:51.700 --> 00:18:55.860]   Hey, let's make a product or come up with a solution
[00:18:55.860 --> 00:19:00.860]   to make that pain point less challenging.
[00:19:00.860 --> 00:19:07.060]   - And sometimes we do certain burdens so often as a society
[00:19:07.060 --> 00:19:09.420]   that we actually don't even realize,
[00:19:09.420 --> 00:19:11.460]   like it's actually hard to see that that burden
[00:19:11.460 --> 00:19:13.180]   is something that could be removed.
[00:19:13.180 --> 00:19:17.140]   So it does require just going into the home and staring at,
[00:19:17.140 --> 00:19:19.560]   wait, how do I actually live life?
[00:19:19.560 --> 00:19:21.060]   What are the pain points?
[00:19:21.060 --> 00:19:26.060]   - Yeah, and getting those insights is a lot harder
[00:19:26.060 --> 00:19:29.340]   than it would seem it should be in retrospect.
[00:19:29.340 --> 00:19:33.100]   - So how hard on that point,
[00:19:33.100 --> 00:19:37.420]   I mean, one of the big challenges of robotics
[00:19:37.420 --> 00:19:42.220]   is driving the cost down to something
[00:19:42.220 --> 00:19:45.660]   that consumers, people would afford.
[00:19:45.660 --> 00:19:48.860]   So people would be less likely to buy a Roomba
[00:19:48.860 --> 00:19:52.140]   if it costs $500,000, right?
[00:19:52.140 --> 00:19:55.900]   Which is probably sort of what a Roomba would cost
[00:19:55.900 --> 00:19:58.080]   several decades ago.
[00:19:58.080 --> 00:20:02.260]   So how do you drive, which I mentioned is very difficult,
[00:20:02.260 --> 00:20:05.380]   how do you drive the cost of a Roomba or a robot down
[00:20:05.380 --> 00:20:07.960]   such that people would want to buy it?
[00:20:07.960 --> 00:20:09.740]   - When I started building robots,
[00:20:09.740 --> 00:20:12.260]   the cost of the robot had a lot to do
[00:20:12.260 --> 00:20:15.520]   with the amount of time it took to build it.
[00:20:15.520 --> 00:20:18.420]   And so that we would build our robots out of aluminum,
[00:20:18.420 --> 00:20:21.220]   I would go spend my time in the machine shop
[00:20:21.220 --> 00:20:26.220]   on the milling machine, cutting out the parts and so forth.
[00:20:26.220 --> 00:20:29.780]   And then when we got into the toy industry,
[00:20:29.780 --> 00:20:34.580]   I realized that if we were building at scale,
[00:20:34.580 --> 00:20:36.020]   I could determine the cost of the robot
[00:20:36.020 --> 00:20:38.940]   instead of adding up all the hours to mill out the parts,
[00:20:38.940 --> 00:20:40.400]   but by weighing it.
[00:20:40.400 --> 00:20:44.220]   And that's liberating.
[00:20:44.220 --> 00:20:49.220]   You can say, wow, the world has just changed
[00:20:49.220 --> 00:20:53.200]   as I think about construction in a different way.
[00:20:53.200 --> 00:20:56.940]   The 3D CAD tools that are available to us today,
[00:20:56.940 --> 00:21:01.740]   the operating at scale where I can do tooling
[00:21:01.740 --> 00:21:06.740]   and injection mold an arbitrarily complicated part
[00:21:06.740 --> 00:21:10.500]   and the cost is going to be basically the weight
[00:21:10.500 --> 00:21:15.500]   of the plastic in that part is incredibly exciting
[00:21:15.500 --> 00:21:18.580]   and liberating and opens up all sorts of opportunities.
[00:21:18.580 --> 00:21:22.120]   And for the sensing part of it,
[00:21:22.120 --> 00:21:28.140]   where we are today is instead of trying to build skin,
[00:21:28.140 --> 00:21:31.420]   which is like really hard for a long time,
[00:21:31.420 --> 00:21:36.420]   I spent creating strategies and ideas
[00:21:38.260 --> 00:21:42.740]   around how could we duplicate the skin on the human body
[00:21:42.740 --> 00:21:45.440]   because it's such an amazing sensor.
[00:21:45.440 --> 00:21:49.620]   Instead of going down that path,
[00:21:49.620 --> 00:21:53.020]   why don't we focus on vision?
[00:21:53.020 --> 00:21:59.020]   And how many of the problems that face a robot
[00:21:59.020 --> 00:22:04.860]   trying to do real work could be solved
[00:22:04.860 --> 00:22:08.460]   with a cheap camera and a big ass computer.
[00:22:08.460 --> 00:22:09.300]   - Yeah.
[00:22:09.300 --> 00:22:12.460]   - And Moore's law continues to work.
[00:22:12.460 --> 00:22:16.540]   The cell phone industry, the mobile industry
[00:22:16.540 --> 00:22:18.800]   is giving us better and better tools
[00:22:18.800 --> 00:22:21.140]   that can run on these embedded computers.
[00:22:21.140 --> 00:22:26.140]   And I think we passed an important moment,
[00:22:26.140 --> 00:22:29.580]   maybe two years ago,
[00:22:29.580 --> 00:22:34.580]   where you could put machine vision capable processors
[00:22:35.420 --> 00:22:39.620]   on robots at consumer price points.
[00:22:39.620 --> 00:22:43.020]   And I was waiting for it to happen.
[00:22:43.020 --> 00:22:48.020]   We avoided putting lasers on our robots to do navigation
[00:22:48.020 --> 00:22:51.820]   and instead spent years researching
[00:22:51.820 --> 00:22:54.620]   how to do vision based navigation
[00:22:54.620 --> 00:22:58.420]   because you could just see
[00:22:58.420 --> 00:23:01.620]   where these technology trends were going.
[00:23:01.620 --> 00:23:05.860]   And between injection molded plastic
[00:23:05.860 --> 00:23:09.900]   and a camera with a computer capable of running
[00:23:09.900 --> 00:23:12.520]   machine learning and visual object recognition,
[00:23:12.520 --> 00:23:15.520]   I could build an incredibly affordable,
[00:23:15.520 --> 00:23:20.520]   incredibly capable robot and that's gonna be the future.
[00:23:20.520 --> 00:23:23.380]   - So you know, on that point with a small tangent,
[00:23:23.380 --> 00:23:24.980]   but I think an important one,
[00:23:24.980 --> 00:23:27.540]   another industry in which I would say
[00:23:27.540 --> 00:23:29.780]   the only other industry in which
[00:23:29.780 --> 00:23:34.780]   there is automation actually touching people's lives today
[00:23:34.780 --> 00:23:36.500]   is autonomous vehicles.
[00:23:36.500 --> 00:23:42.340]   What the vision you just described of using computer vision
[00:23:42.340 --> 00:23:44.420]   and using cheap camera sensors,
[00:23:44.420 --> 00:23:48.260]   there's a debate on that of LIDAR versus computer vision.
[00:23:48.260 --> 00:23:53.260]   And sort of, Elon Musk famously said
[00:23:53.260 --> 00:23:57.180]   that LIDAR is a crutch that really in camera,
[00:23:57.180 --> 00:24:00.840]   in the longterm camera only is the right solution,
[00:24:00.840 --> 00:24:03.500]   which echoes some of the ideas you're expressing.
[00:24:03.500 --> 00:24:06.780]   Of course, the domain in terms of its safety criticality
[00:24:06.780 --> 00:24:10.660]   is different, but what do you think about that approach
[00:24:10.660 --> 00:24:13.420]   in the autonomous vehicle space?
[00:24:13.420 --> 00:24:15.180]   And in general, do you see a connection
[00:24:15.180 --> 00:24:18.520]   between the incredible real world challenges
[00:24:18.520 --> 00:24:20.780]   you have to solve in the home with Roomba?
[00:24:20.780 --> 00:24:22.940]   And I saw a demonstration of some of them,
[00:24:22.940 --> 00:24:27.880]   corner cases, literally, and autonomous vehicles.
[00:24:27.880 --> 00:24:31.680]   - So there's absolutely a tremendous overlap
[00:24:31.680 --> 00:24:35.460]   between both the problems, you know,
[00:24:35.460 --> 00:24:38.660]   a robot vacuum and autonomous vehicle are trying to solve,
[00:24:38.660 --> 00:24:41.860]   and the tools and the types of sensors
[00:24:41.860 --> 00:24:46.720]   that are being applied in the pursuit of the solutions.
[00:24:48.020 --> 00:24:53.020]   In my world, my environment is actually much harder
[00:24:53.020 --> 00:24:57.320]   than the environment in automobile travels.
[00:24:57.320 --> 00:25:02.320]   We don't have roads, we have t-shirts, we have steps,
[00:25:02.320 --> 00:25:07.420]   we have a near infinite number of patterns and colors
[00:25:07.420 --> 00:25:10.180]   and surface textures on the floor.
[00:25:10.180 --> 00:25:12.540]   - Especially from a visual perspective.
[00:25:12.540 --> 00:25:14.740]   - Yeah, visually it's really tough.
[00:25:14.740 --> 00:25:18.860]   It's infinitely variable.
[00:25:18.860 --> 00:25:22.540]   - On the other hand, safety is way easier on the inside.
[00:25:22.540 --> 00:25:27.540]   My robots, they're not very heavy, they're not very fast.
[00:25:27.540 --> 00:25:31.480]   If they bump into your foot, you think it's funny.
[00:25:31.480 --> 00:25:36.940]   And, you know, and autonomous vehicles
[00:25:36.940 --> 00:25:39.420]   kind of have the inverse problem.
[00:25:39.420 --> 00:25:44.420]   And so that for me saying vision is the future,
[00:25:45.420 --> 00:25:47.780]   I can say that without reservation.
[00:25:47.780 --> 00:25:52.740]   For autonomous vehicles, I think I believe what
[00:25:52.740 --> 00:25:56.900]   Elon's saying about the future
[00:25:56.900 --> 00:25:59.020]   is ultimately going to be vision.
[00:25:59.020 --> 00:26:01.060]   Maybe if we put a cheap lighter on there
[00:26:01.060 --> 00:26:02.260]   as a backup sensor,
[00:26:02.260 --> 00:26:03.820]   it might not be the worst idea in the world.
[00:26:03.820 --> 00:26:05.020]   - So the stakes are much higher.
[00:26:05.020 --> 00:26:05.860]   - The stakes are much higher.
[00:26:05.860 --> 00:26:08.220]   - You have to be much more careful thinking through
[00:26:08.220 --> 00:26:10.740]   how far away that future is, right?
[00:26:10.740 --> 00:26:14.220]   - Right, but I think that the primary
[00:26:14.220 --> 00:26:19.340]   environmental understanding sensor
[00:26:19.340 --> 00:26:21.780]   is going to be a visual system.
[00:26:21.780 --> 00:26:23.020]   - Visual system.
[00:26:23.020 --> 00:26:25.580]   So on that point, well, let me ask,
[00:26:25.580 --> 00:26:28.420]   do you hope there's an iRobot robot
[00:26:28.420 --> 00:26:30.920]   in every home in the world one day?
[00:26:30.920 --> 00:26:34.900]   - I expect there to be at least one iRobot robot
[00:26:34.900 --> 00:26:36.460]   in every home.
[00:26:37.740 --> 00:26:41.180]   You know, we've sold 25 million robots.
[00:26:41.180 --> 00:26:44.620]   So we're in about 10% of US homes,
[00:26:44.620 --> 00:26:45.780]   which is a great start.
[00:26:45.780 --> 00:26:52.140]   But I think that when we think about the numbers of things
[00:26:52.140 --> 00:26:54.300]   that robots can do,
[00:26:54.300 --> 00:26:58.580]   today I can vacuum your floor, mop your floor,
[00:26:58.580 --> 00:27:01.280]   cut your lawn, or soon we'll be able to cut your lawn.
[00:27:01.280 --> 00:27:06.700]   But there are more things that we could do in the home.
[00:27:06.700 --> 00:27:11.500]   And I hope that we continue using the techniques
[00:27:11.500 --> 00:27:14.460]   I described around exploiting computer vision
[00:27:14.460 --> 00:27:18.660]   and low-cost manufacturing that we'll be able
[00:27:18.660 --> 00:27:22.620]   to create these solutions at affordable price points.
[00:27:22.620 --> 00:27:25.580]   - So let me ask, on that point of a robot in every home,
[00:27:25.580 --> 00:27:26.840]   that's my dream as well.
[00:27:26.840 --> 00:27:28.580]   I'd love to see that.
[00:27:28.580 --> 00:27:31.300]   You know, I think the possibilities there
[00:27:31.300 --> 00:27:34.500]   are indeed infinite positive possibilities.
[00:27:34.500 --> 00:27:36.740]   But in our current culture,
[00:27:36.740 --> 00:27:40.500]   no thanks to science fiction and so on,
[00:27:40.500 --> 00:27:44.700]   there's a serious kind of hesitation,
[00:27:44.700 --> 00:27:47.340]   anxiety, concern about robots,
[00:27:47.340 --> 00:27:50.040]   and also a concern about privacy.
[00:27:50.040 --> 00:27:54.080]   And it's a fascinating question to me,
[00:27:54.080 --> 00:27:59.540]   why that concern is amongst a certain group of people
[00:27:59.540 --> 00:28:02.800]   is as intense as it is.
[00:28:02.800 --> 00:28:04.220]   So you have to think about it,
[00:28:04.220 --> 00:28:05.460]   'cause it's a serious concern,
[00:28:05.460 --> 00:28:07.980]   but I wonder how you address it best.
[00:28:07.980 --> 00:28:09.780]   So from a perspective of a vision sensor,
[00:28:09.780 --> 00:28:14.060]   so robots that move about the home and sense the world,
[00:28:14.060 --> 00:28:19.060]   how do you alleviate people's privacy concerns?
[00:28:19.060 --> 00:28:22.820]   How do you make sure that they can trust iRobot
[00:28:22.820 --> 00:28:25.300]   and the robots that they share their home with?
[00:28:25.300 --> 00:28:28.120]   - I think that's a great question.
[00:28:28.120 --> 00:28:33.120]   And we've really leaned way forward on this
[00:28:33.740 --> 00:28:38.740]   because given our vision as to the role the company
[00:28:38.740 --> 00:28:40.700]   intends to play in the home,
[00:28:40.700 --> 00:28:45.460]   really for us, make or break is,
[00:28:45.460 --> 00:28:50.460]   can our approach be trusted to protecting the data
[00:28:50.460 --> 00:28:53.500]   and the privacy of the people who have our robots?
[00:28:53.500 --> 00:28:58.300]   And so we've gone out publicly with a privacy manifesto
[00:28:58.300 --> 00:29:00.400]   stating we'll never sell your data.
[00:29:00.400 --> 00:29:05.400]   We've adopted GDPR, not just where GDPR is required,
[00:29:05.400 --> 00:29:07.560]   but globally.
[00:29:07.560 --> 00:29:14.160]   We have ensured that images don't leave the robot.
[00:29:14.160 --> 00:29:22.060]   So processing data from the visual sensors
[00:29:22.060 --> 00:29:23.660]   happens locally on the robot
[00:29:23.660 --> 00:29:28.660]   and only semantic knowledge of the home
[00:29:29.480 --> 00:29:32.720]   with the consumer's consent is sent up.
[00:29:32.720 --> 00:29:36.280]   We show you what we know and are trying to go
[00:29:36.280 --> 00:29:43.440]   use data as an enabler for the performance of the robots
[00:29:43.440 --> 00:29:49.960]   with the informed consent and understanding
[00:29:49.960 --> 00:29:52.400]   of the people who own those robots.
[00:29:52.400 --> 00:29:56.840]   And we take it very seriously.
[00:29:56.840 --> 00:30:01.840]   And ultimately we think that by showing a customer that,
[00:30:01.840 --> 00:30:07.360]   if you let us build a semantic map of your home
[00:30:07.360 --> 00:30:08.960]   and know where the rooms are,
[00:30:08.960 --> 00:30:11.720]   well then you can say, clean the kitchen.
[00:30:11.720 --> 00:30:13.680]   If you don't want the robot to do that,
[00:30:13.680 --> 00:30:15.800]   don't make the map, it'll do its best job
[00:30:15.800 --> 00:30:18.640]   cleaning your home, but it won't be able to do that.
[00:30:18.640 --> 00:30:20.280]   And if you ever want us to forget
[00:30:20.280 --> 00:30:22.080]   that we know that it's your kitchen,
[00:30:22.080 --> 00:30:26.680]   you can have confidence that we will do that for you.
[00:30:26.680 --> 00:30:30.840]   So we're trying to go and be a sort of a
[00:30:30.840 --> 00:30:37.320]   data 2.0 perspective company where we treat the data
[00:30:37.320 --> 00:30:40.800]   that the robots have of the consumer's home
[00:30:40.800 --> 00:30:43.200]   as if it were the consumer's data
[00:30:43.200 --> 00:30:47.320]   and that they have rights to it.
[00:30:47.320 --> 00:30:50.920]   So we think by being the good guys on this front,
[00:30:50.920 --> 00:30:53.800]   we can build the trust and thus be entrusted
[00:30:55.080 --> 00:31:00.080]   to enable robots to do more things that are thoughtful.
[00:31:00.080 --> 00:31:03.760]   - You think people's worries will diminish over time?
[00:31:03.760 --> 00:31:06.800]   As a society, broadly speaking,
[00:31:06.800 --> 00:31:09.280]   do you think you can win over trust,
[00:31:09.280 --> 00:31:10.600]   not just for the company,
[00:31:10.600 --> 00:31:12.940]   but just the comfort that people have
[00:31:12.940 --> 00:31:17.040]   with AI in their home, enriching their lives in some way?
[00:31:17.040 --> 00:31:19.560]   - I think we're in an interesting place today
[00:31:19.560 --> 00:31:22.400]   where it's less about winning them over
[00:31:22.400 --> 00:31:26.280]   and more about finding a way to talk about privacy
[00:31:26.280 --> 00:31:28.880]   in a way that more people can understand.
[00:31:28.880 --> 00:31:30.960]   I would tell you that today,
[00:31:30.960 --> 00:31:33.360]   when there's a privacy breach,
[00:31:33.360 --> 00:31:37.080]   people get very upset and then go to the store
[00:31:37.080 --> 00:31:38.360]   and buy the cheapest thing,
[00:31:38.360 --> 00:31:41.040]   paying no attention to whether or not the products
[00:31:41.040 --> 00:31:44.680]   that they're buying honor privacy standards or not.
[00:31:44.680 --> 00:31:48.640]   In fact, if I put on the package of my Roomba,
[00:31:50.120 --> 00:31:53.680]   the privacy commitments that we have,
[00:31:53.680 --> 00:31:58.680]   I would sell less than I would if I did nothing at all.
[00:31:58.680 --> 00:32:00.440]   And that needs to change.
[00:32:00.440 --> 00:32:02.920]   So it's not a question about earning trust.
[00:32:02.920 --> 00:32:05.040]   I think that's necessary but not sufficient.
[00:32:05.040 --> 00:32:08.480]   We need to figure out how to have a comfortable set
[00:32:08.480 --> 00:32:13.480]   of what is the grade A meat standard applied to privacy
[00:32:13.480 --> 00:32:18.440]   that customers can trust and understand
[00:32:18.440 --> 00:32:20.520]   and then use in their buying decisions.
[00:32:20.520 --> 00:32:25.520]   That will reward companies for good behavior
[00:32:25.520 --> 00:32:29.880]   and that will ultimately be how this moves forward.
[00:32:29.880 --> 00:32:32.680]   - And maybe be part of the conversation
[00:32:32.680 --> 00:32:34.800]   between regular people about what it means,
[00:32:34.800 --> 00:32:36.280]   what privacy means.
[00:32:36.280 --> 00:32:38.400]   If you have some standards, you can say,
[00:32:38.400 --> 00:32:41.080]   you can start talking about who's following them,
[00:32:41.080 --> 00:32:42.680]   who's not, have more.
[00:32:42.680 --> 00:32:45.440]   'Cause most people are actually quite clueless
[00:32:45.440 --> 00:32:47.320]   about all aspects of artificial intelligence
[00:32:47.320 --> 00:32:48.440]   or data collection and so on.
[00:32:48.440 --> 00:32:51.440]   It would be nice to change that for people to understand
[00:32:51.440 --> 00:32:55.160]   the good that AI can do and it's not some system
[00:32:55.160 --> 00:32:58.240]   that's trying to steal all the most sensitive data.
[00:32:58.240 --> 00:32:59.080]   - Yep.
[00:32:59.080 --> 00:33:02.640]   - Do you think, do you dream of a Roomba
[00:33:02.640 --> 00:33:05.240]   with human level intelligence one day?
[00:33:05.240 --> 00:33:10.240]   So you've mentioned a very successful localization
[00:33:10.240 --> 00:33:11.880]   and mapping of the environment,
[00:33:11.880 --> 00:33:14.340]   being able to do some basic communication
[00:33:14.340 --> 00:33:16.560]   to say go clean the kitchen.
[00:33:16.560 --> 00:33:21.360]   Do you see in your maybe more bored moments,
[00:33:21.360 --> 00:33:27.000]   once you get the beer, to sit back with that beer
[00:33:27.000 --> 00:33:30.760]   and have a chat on a Friday night with a Roomba
[00:33:30.760 --> 00:33:32.080]   about how your day went?
[00:33:32.080 --> 00:33:37.560]   - So to your latter question, absolutely.
[00:33:37.560 --> 00:33:40.760]   To your former question as to whether a robot
[00:33:40.760 --> 00:33:43.680]   can have human level intelligence, not in my lifetime.
[00:33:45.280 --> 00:33:46.120]   - You can have, you--
[00:33:46.120 --> 00:33:48.440]   - I think you can have a great conversation,
[00:33:48.440 --> 00:33:52.000]   a meaningful conversation with a robot
[00:33:52.000 --> 00:33:56.320]   without it having anything that resembles
[00:33:56.320 --> 00:33:57.760]   human level intelligence.
[00:33:57.760 --> 00:34:02.780]   And I think that as long as you realize
[00:34:02.780 --> 00:34:05.280]   that conversation is not about the robot
[00:34:05.280 --> 00:34:08.560]   and making the robot feel good.
[00:34:08.560 --> 00:34:13.560]   That conversation is about you learning interesting things
[00:34:14.840 --> 00:34:18.360]   that make you feel like the conversation
[00:34:18.360 --> 00:34:21.200]   that you had with the robot is
[00:34:21.200 --> 00:34:27.240]   a pretty awesome way of learning something.
[00:34:27.240 --> 00:34:30.880]   And it could be about what kind of day your pet had.
[00:34:30.880 --> 00:34:35.140]   It could be about how can I make my home
[00:34:35.140 --> 00:34:36.240]   more energy efficient?
[00:34:36.240 --> 00:34:40.880]   It could be about if I'm thinking about climbing Mount Everest
[00:34:40.880 --> 00:34:41.840]   what should I know?
[00:34:44.440 --> 00:34:46.560]   And that's a very doable thing.
[00:34:46.560 --> 00:34:51.560]   But if I think that that conversation
[00:34:51.560 --> 00:34:54.640]   I'm gonna have with a robot is I'm gonna be rewarded
[00:34:54.640 --> 00:34:56.880]   by making the robot happy,
[00:34:56.880 --> 00:34:58.760]   well I could just put a button on the robot
[00:34:58.760 --> 00:35:00.320]   that you could push and the robot would smile
[00:35:00.320 --> 00:35:02.160]   and that sort of thing.
[00:35:02.160 --> 00:35:04.440]   So I think you need to think about the question
[00:35:04.440 --> 00:35:09.440]   in the right way and robots can be awesomely effective
[00:35:11.600 --> 00:35:14.440]   at helping people feel less isolated,
[00:35:14.440 --> 00:35:17.560]   learn more about the home that they live in
[00:35:17.560 --> 00:35:21.980]   and fill some of those lonely gaps
[00:35:21.980 --> 00:35:24.880]   that we wish we were engaged learning cool stuff
[00:35:24.880 --> 00:35:25.720]   about our world.
[00:35:25.720 --> 00:35:27.500]   - Last question.
[00:35:27.500 --> 00:35:32.360]   If you could hang out for a day with a robot
[00:35:32.360 --> 00:35:35.800]   from science fiction, movies, books
[00:35:35.800 --> 00:35:40.400]   and safely pick its brain for that day,
[00:35:40.400 --> 00:35:41.400]   who would you pick?
[00:35:42.120 --> 00:35:43.360]   - Data.
[00:35:43.360 --> 00:35:44.200]   - Data.
[00:35:44.200 --> 00:35:45.280]   - From Star Trek.
[00:35:45.280 --> 00:35:49.640]   I think that A, data's really smart.
[00:35:49.640 --> 00:35:53.560]   Data's been through a lot trying to go and save the galaxy
[00:35:53.560 --> 00:35:58.560]   and I'm really interested actually in emotion and robotics
[00:35:58.560 --> 00:36:03.160]   and I think he'd have a lot to say about that
[00:36:03.160 --> 00:36:08.160]   'cause I believe actually that emotion plays
[00:36:08.520 --> 00:36:13.520]   an incredibly useful role in doing reasonable things
[00:36:13.520 --> 00:36:16.880]   in situations where we have imperfect understanding
[00:36:16.880 --> 00:36:18.040]   of what's going on.
[00:36:18.040 --> 00:36:20.800]   - In social situations when there's imperfect information.
[00:36:20.800 --> 00:36:25.520]   - In social situations, also in competitive
[00:36:25.520 --> 00:36:30.520]   or dangerous situations that we have emotion for a reason
[00:36:30.520 --> 00:36:37.080]   and so that ultimately my theory is that
[00:36:37.080 --> 00:36:38.560]   as robots get smarter and smarter,
[00:36:38.560 --> 00:36:40.560]   they're actually gonna get more emotional
[00:36:40.560 --> 00:36:46.440]   because you can't actually survive on pure logic
[00:36:46.440 --> 00:36:53.800]   because only a very tiny fraction of the situations
[00:36:53.800 --> 00:36:57.240]   we find ourselves in can be resolved reasonably with logic
[00:36:57.240 --> 00:36:59.520]   and so I think data would have a lot to say about that
[00:36:59.520 --> 00:37:02.360]   and so I could find out whether he agrees.
[00:37:02.360 --> 00:37:04.800]   - If you could ask data one question
[00:37:04.800 --> 00:37:07.320]   and you would get a deep honest answer to,
[00:37:07.320 --> 00:37:08.600]   what would you ask?
[00:37:08.600 --> 00:37:10.480]   - What's Captain Picard really like?
[00:37:10.480 --> 00:37:12.600]   (laughing)
[00:37:12.600 --> 00:37:14.320]   - Okay, I think that's the perfect way to end it.
[00:37:14.320 --> 00:37:16.000]   Colin, thank you so much for talking today.
[00:37:16.000 --> 00:37:16.960]   I really appreciate it.
[00:37:16.960 --> 00:37:17.800]   - My pleasure.
[00:37:17.800 --> 00:37:20.380]   (upbeat music)
[00:37:20.380 --> 00:37:22.960]   (upbeat music)
[00:37:22.960 --> 00:37:25.540]   (upbeat music)
[00:37:25.540 --> 00:37:28.120]   (upbeat music)
[00:37:28.120 --> 00:37:30.700]   (upbeat music)
[00:37:30.700 --> 00:37:33.280]   (upbeat music)
[00:37:33.280 --> 00:37:43.280]   [BLANK_AUDIO]

