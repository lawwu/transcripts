
[00:00:00.000 --> 00:00:03.240]   - Okay, so welcome back.
[00:00:03.240 --> 00:00:06.020]   The main focus of today is gonna be on research areas,
[00:00:06.020 --> 00:00:10.480]   which we have an amazing guest speaker to talk about.
[00:00:10.480 --> 00:00:13.680]   But before we dive into that, by popular demand,
[00:00:13.680 --> 00:00:14.960]   there was a request to talk a little bit
[00:00:14.960 --> 00:00:16.360]   about machine learning teams.
[00:00:16.360 --> 00:00:18.980]   And so I'm just gonna spend a few minutes on that.
[00:00:18.980 --> 00:00:20.960]   And one of the focuses of this lecture
[00:00:20.960 --> 00:00:24.800]   is on kind of what are jobs like in this field
[00:00:24.800 --> 00:00:27.000]   and what does hiring look like?
[00:00:27.000 --> 00:00:29.120]   So can I just get a quick sense,
[00:00:29.120 --> 00:00:32.360]   show of hands, like how many people are interested
[00:00:32.360 --> 00:00:35.440]   in some way or another in looking at a job
[00:00:35.440 --> 00:00:37.560]   in machine learning engineering at some point,
[00:00:37.560 --> 00:00:39.340]   next year, next six months?
[00:00:39.340 --> 00:00:41.920]   Okay, so a good number.
[00:00:41.920 --> 00:00:44.160]   One thing we're thinking about doing
[00:00:44.160 --> 00:00:48.720]   is bringing in some industry people
[00:00:48.720 --> 00:00:50.640]   who are looking to hire people
[00:00:50.640 --> 00:00:53.240]   to the project presentations at the end of class
[00:00:53.240 --> 00:00:55.840]   to just give kind of short presentations on what they do
[00:00:55.840 --> 00:00:58.540]   and what they're looking for in people on their teams.
[00:00:59.380 --> 00:01:01.380]   How many people would be kind of interested
[00:01:01.380 --> 00:01:03.680]   in hearing those presentations if we did that?
[00:01:03.680 --> 00:01:15.860]   Talking about machine learning teams.
[00:01:15.860 --> 00:01:17.940]   And there's a few topics I wanna cover.
[00:01:17.940 --> 00:01:20.700]   The first is just what's the context
[00:01:20.700 --> 00:01:21.580]   that we're working in here?
[00:01:21.580 --> 00:01:24.500]   And so what's, and the context is mostly defined
[00:01:24.500 --> 00:01:27.000]   by the gap in AI talent.
[00:01:27.000 --> 00:01:29.360]   And then I'll talk about the different roles
[00:01:29.360 --> 00:01:32.940]   related to machine learning that we see in industry often.
[00:01:32.940 --> 00:01:34.420]   And then I'll talk a little bit about
[00:01:34.420 --> 00:01:37.680]   how those roles are typically formed into teams,
[00:01:37.680 --> 00:01:40.180]   and then what the hiring process often looks like.
[00:01:40.180 --> 00:01:42.760]   So the AI talent gap.
[00:01:42.760 --> 00:01:45.520]   One question you might ask is,
[00:01:45.520 --> 00:01:46.720]   how many people are there out there
[00:01:46.720 --> 00:01:51.120]   that know how to build sort of high quality AI systems?
[00:01:51.120 --> 00:01:52.740]   And there are different estimates
[00:01:52.740 --> 00:01:54.460]   that you can find of this.
[00:01:54.460 --> 00:01:56.660]   One estimate, the lowest estimate that I found
[00:01:56.660 --> 00:01:58.000]   was 5,000.
[00:01:58.000 --> 00:02:00.180]   And so that's people who are actively publishing research
[00:02:00.180 --> 00:02:01.700]   according to Element AI.
[00:02:01.700 --> 00:02:03.940]   So that's kind of like a lower bound on the number.
[00:02:03.940 --> 00:02:06.500]   From the same report,
[00:02:06.500 --> 00:02:07.680]   the people with the right skillset,
[00:02:07.680 --> 00:02:10.380]   whether or not they're publishing is more like 10,000.
[00:02:10.380 --> 00:02:14.820]   Bloomberg estimated that there are more like 20,000
[00:02:14.820 --> 00:02:16.820]   PhD educated AI researchers.
[00:02:16.820 --> 00:02:18.340]   Now, not everyone working in AI
[00:02:18.340 --> 00:02:19.820]   needs to have a PhD obviously.
[00:02:19.820 --> 00:02:22.300]   And so you can think about
[00:02:22.300 --> 00:02:23.580]   what's an upper bound on that number.
[00:02:23.580 --> 00:02:26.140]   And Element estimated at 90,000.
[00:02:26.140 --> 00:02:30.120]   And a different report estimated at around 200,000.
[00:02:30.120 --> 00:02:34.740]   But the point I wanna make here is that
[00:02:34.740 --> 00:02:38.100]   comparing this to the numbers for a more mature industry
[00:02:38.100 --> 00:02:39.400]   like software development,
[00:02:39.400 --> 00:02:42.460]   that's more like 3.6 million people.
[00:02:42.460 --> 00:02:46.020]   So there's still a huge gap,
[00:02:46.020 --> 00:02:47.420]   a huge difference between the number of people
[00:02:47.420 --> 00:02:48.260]   that know how to do AI
[00:02:48.260 --> 00:02:51.340]   and the people that know how to do software development.
[00:02:51.340 --> 00:02:52.300]   And that number is even bigger
[00:02:52.300 --> 00:02:53.900]   if you look at the entire world.
[00:02:53.900 --> 00:02:59.020]   So what is the implication of this?
[00:02:59.020 --> 00:03:02.460]   Like what is the shortage in AI developers mean
[00:03:02.460 --> 00:03:04.520]   for AI hiring?
[00:03:04.520 --> 00:03:07.220]   You know, in short,
[00:03:07.220 --> 00:03:09.620]   it comes down to a fierce competition for AI talent.
[00:03:09.620 --> 00:03:12.500]   And this is a quote from Bloomberg.
[00:03:12.500 --> 00:03:14.380]   "Everyone agrees that the competition to hire people
[00:03:14.380 --> 00:03:16.560]   "who know how to build artificial intelligence systems
[00:03:16.560 --> 00:03:17.540]   "is intense.
[00:03:17.540 --> 00:03:20.340]   "It's turned academic conferences
[00:03:20.340 --> 00:03:23.020]   "into frenzied meat markets for corporate recruiters
[00:03:23.020 --> 00:03:24.900]   "and driven the salaries of top researchers
[00:03:24.900 --> 00:03:26.500]   "to seven figures."
[00:03:26.500 --> 00:03:28.140]   Right, and for those of you who have been
[00:03:28.140 --> 00:03:29.180]   to machine learning conferences
[00:03:29.180 --> 00:03:30.820]   in the last couple of years,
[00:03:30.820 --> 00:03:33.420]   you know, I think you would agree that it's like,
[00:03:33.420 --> 00:03:36.140]   there's very much a feel of like massive competition
[00:03:36.140 --> 00:03:37.240]   to get the top people.
[00:03:37.240 --> 00:03:41.260]   So we talked to a couple of people
[00:03:41.260 --> 00:03:43.140]   who were kind of running startups and hiring for them
[00:03:43.140 --> 00:03:44.620]   in the process of, you know,
[00:03:44.620 --> 00:03:48.580]   making the full stack deep learning class that we did.
[00:03:48.580 --> 00:03:50.940]   And a couple of quotes that stood out to me
[00:03:50.940 --> 00:03:53.280]   from a computer vision engineer
[00:03:53.280 --> 00:03:55.140]   at sort of a late stage startup,
[00:03:55.140 --> 00:03:56.940]   you know, "Hiring is crazy.
[00:03:56.940 --> 00:03:58.220]   "ML got popular really quickly.
[00:03:58.220 --> 00:04:00.680]   "There's a ton of demand and not a lot of supply.
[00:04:00.680 --> 00:04:03.820]   "Hiring for ML is really challenging,
[00:04:03.820 --> 00:04:06.520]   "takes way more time and effort than we were expecting.
[00:04:06.520 --> 00:04:08.860]   "You know, we're only able to get a few people per quarter
[00:04:08.860 --> 00:04:10.260]   "despite our best efforts."
[00:04:10.260 --> 00:04:13.180]   And this is just kind of the general story
[00:04:13.180 --> 00:04:15.220]   that we heard from most startup founders
[00:04:15.220 --> 00:04:16.660]   and people in big companies that we talked to.
[00:04:16.660 --> 00:04:19.300]   It's just really, really hard to hire for these positions.
[00:04:19.300 --> 00:04:22.500]   So what are these positions?
[00:04:22.500 --> 00:04:24.860]   The most common roles at companies that we see
[00:04:24.860 --> 00:04:29.280]   that involve machine learning are sort of DevOps engineers,
[00:04:29.280 --> 00:04:31.180]   data engineers, ML engineers,
[00:04:31.180 --> 00:04:33.520]   ML researchers and data scientists, right?
[00:04:33.520 --> 00:04:35.120]   So these are all like these buzzword terms.
[00:04:35.120 --> 00:04:37.020]   And you know, what is the difference between these?
[00:04:37.020 --> 00:04:39.320]   Like what are these actually mean in practice?
[00:04:39.320 --> 00:04:43.160]   And so you can break down each of these jobs
[00:04:43.160 --> 00:04:44.140]   by sort of what the role
[00:04:44.140 --> 00:04:46.040]   that they typically play in teams are.
[00:04:47.040 --> 00:04:49.440]   So DevOps engineers, you know,
[00:04:49.440 --> 00:04:51.000]   their job is really deploying
[00:04:51.000 --> 00:04:52.880]   and monitoring production systems.
[00:04:52.880 --> 00:04:54.560]   And so what they're producing,
[00:04:54.560 --> 00:04:56.840]   like what their work product is, is a deployed product.
[00:04:56.840 --> 00:04:59.480]   So something that's, you know, actually on your phone
[00:04:59.480 --> 00:05:02.580]   or on your computer and is being served to end customers.
[00:05:02.580 --> 00:05:04.320]   And so they're using tools like AWS
[00:05:04.320 --> 00:05:06.400]   to actually serve predictions.
[00:05:06.400 --> 00:05:09.360]   Data engineers are typically focused
[00:05:09.360 --> 00:05:11.400]   on building data pipelines.
[00:05:11.400 --> 00:05:14.100]   So, you know, collecting data, figuring out how to store it,
[00:05:14.100 --> 00:05:15.360]   figuring out how to monitor it,
[00:05:15.360 --> 00:05:19.320]   figuring out how to serve it to machine learning workflows.
[00:05:19.320 --> 00:05:21.680]   And their work product typically looks like, you know,
[00:05:21.680 --> 00:05:24.740]   a Hadoop distributed system or something like that.
[00:05:24.740 --> 00:05:28.500]   Next we have ML engineers.
[00:05:28.500 --> 00:05:30.360]   And, you know, their goal,
[00:05:30.360 --> 00:05:33.320]   like this is sort of a pretty broad role.
[00:05:33.320 --> 00:05:36.640]   And what they're tasked with is most often
[00:05:36.640 --> 00:05:38.380]   training and deploying prediction models.
[00:05:38.380 --> 00:05:42.340]   So their goal is like, often they're given a dataset.
[00:05:42.340 --> 00:05:44.780]   And what they're trying to do is produce a system
[00:05:44.780 --> 00:05:46.640]   that can create predictions
[00:05:46.640 --> 00:05:48.260]   and then either deploy it themselves
[00:05:48.260 --> 00:05:50.460]   or hand it off to someone like a DevOps engineer
[00:05:50.460 --> 00:05:52.140]   to deploy it for them.
[00:05:52.140 --> 00:05:53.880]   And so these are people who are working in, you know,
[00:05:53.880 --> 00:05:57.280]   TensorFlow, but then also tools like Docker,
[00:05:57.280 --> 00:06:00.280]   because they're often pretty close to the actual deployment.
[00:06:00.280 --> 00:06:03.600]   Then you have ML researchers.
[00:06:03.600 --> 00:06:06.160]   And, you know, there's sort of a fuzzy line
[00:06:06.160 --> 00:06:08.280]   between ML researchers and ML engineers.
[00:06:08.280 --> 00:06:12.360]   But ML researchers, the biggest difference is that
[00:06:12.360 --> 00:06:14.120]   often the prediction models that they're training
[00:06:14.120 --> 00:06:15.820]   are not production critical,
[00:06:15.820 --> 00:06:17.580]   or they're not production critical in, you know,
[00:06:17.580 --> 00:06:19.060]   in the short term.
[00:06:19.060 --> 00:06:20.580]   But they're often working on sort of
[00:06:20.580 --> 00:06:23.440]   more speculative products or projects rather
[00:06:23.440 --> 00:06:26.300]   that could make it into the product at some point,
[00:06:26.300 --> 00:06:28.260]   but are not gonna be deployed tomorrow.
[00:06:28.260 --> 00:06:33.220]   And often the work product for these folks looks like,
[00:06:33.220 --> 00:06:36.200]   you know, actually a report that describes what they tried
[00:06:36.200 --> 00:06:38.660]   and, you know, what the results look like.
[00:06:38.660 --> 00:06:40.100]   And that might get picked up
[00:06:40.100 --> 00:06:41.800]   by the rest of the team to deploy.
[00:06:43.320 --> 00:06:44.500]   And then you have data scientists.
[00:06:44.500 --> 00:06:46.540]   And the tricky thing about data scientists is that
[00:06:46.540 --> 00:06:48.720]   this is really a catch all term that can mean
[00:06:48.720 --> 00:06:50.760]   many different things in different organizations.
[00:06:50.760 --> 00:06:53.040]   And so I've heard this used to describe
[00:06:53.040 --> 00:06:54.600]   any of their roles above.
[00:06:54.600 --> 00:06:58.440]   And, you know, in some organizations,
[00:06:58.440 --> 00:07:00.080]   in many organizations, in fact,
[00:07:00.080 --> 00:07:02.520]   data scientists are actually not doing much
[00:07:02.520 --> 00:07:03.880]   machine learning at all.
[00:07:03.880 --> 00:07:05.440]   It's more of an analytics role.
[00:07:05.440 --> 00:07:08.320]   And so this can mean many different things.
[00:07:08.320 --> 00:07:11.960]   And so, you know, what you might ask yourself
[00:07:11.960 --> 00:07:15.020]   if you're on the job market or if you're hiring
[00:07:15.020 --> 00:07:16.480]   for these roles is, you know,
[00:07:16.480 --> 00:07:19.060]   what skills do you need in order to succeed?
[00:07:19.060 --> 00:07:22.140]   And so on this chart, we have sort of the level
[00:07:22.140 --> 00:07:24.360]   of machine learning skill that you need on the bottom
[00:07:24.360 --> 00:07:26.200]   and the level of software engineering skill
[00:07:26.200 --> 00:07:27.740]   that you need on the left side.
[00:07:27.740 --> 00:07:30.320]   And the size of the bottle, the bubble corresponds to,
[00:07:30.320 --> 00:07:31.960]   you know, how well you, how good you are
[00:07:31.960 --> 00:07:34.400]   at communicating and technical writing.
[00:07:34.400 --> 00:07:36.080]   So how good you are at sort of convincing
[00:07:36.080 --> 00:07:37.720]   the organization of your results.
[00:07:37.720 --> 00:07:41.320]   So we're talking about each of these individually.
[00:07:41.320 --> 00:07:44.160]   ML DevOps, high on software engineering,
[00:07:44.160 --> 00:07:46.160]   relatively low on machine learning.
[00:07:46.160 --> 00:07:48.000]   This is primarily a software engineering role.
[00:07:48.000 --> 00:07:50.800]   And oftentimes these folks don't have
[00:07:50.800 --> 00:07:52.020]   any machine learning background at all
[00:07:52.020 --> 00:07:54.900]   or are sort of in the process of learning machine learning
[00:07:54.900 --> 00:07:58.440]   and, you know, wanna work closely with an ML team,
[00:07:58.440 --> 00:08:01.440]   but their skillset is more on the software engineering side.
[00:08:01.440 --> 00:08:05.960]   Data engineer is pretty similar,
[00:08:05.960 --> 00:08:07.240]   mostly software engineering,
[00:08:07.240 --> 00:08:09.760]   but there's often a slightly higher requirement
[00:08:09.760 --> 00:08:12.520]   for ML knowledge because their work product
[00:08:12.520 --> 00:08:15.000]   is so closely tied to what the machine learning team
[00:08:15.000 --> 00:08:15.900]   is actually using.
[00:08:15.900 --> 00:08:21.080]   ML engineers, this is sort of, I think,
[00:08:21.080 --> 00:08:23.200]   like kind of one of the unicorn skillsets
[00:08:23.200 --> 00:08:25.620]   from a lot of companies that we talked to.
[00:08:25.620 --> 00:08:27.280]   A lot of people said that this skillset
[00:08:27.280 --> 00:08:29.040]   is particularly hard to hire for
[00:08:29.040 --> 00:08:30.620]   because it requires sort of a rare mix
[00:08:30.620 --> 00:08:32.520]   of, you know, machine learning skills,
[00:08:32.520 --> 00:08:33.840]   knowledge of algorithms,
[00:08:33.840 --> 00:08:36.360]   but then also software engineering skills.
[00:08:36.360 --> 00:08:39.240]   And so, you know, if you're kind of,
[00:08:39.240 --> 00:08:40.640]   if you're a really good software engineer
[00:08:40.640 --> 00:08:42.280]   and you're also sort of pretty far along
[00:08:42.280 --> 00:08:44.640]   in your learning of machine learning,
[00:08:44.640 --> 00:08:47.520]   this can be a really interesting role to go for.
[00:08:47.520 --> 00:08:52.660]   ML researchers, you know, this is your ML experts.
[00:08:52.660 --> 00:08:54.920]   This is kind of the one role where
[00:08:54.920 --> 00:08:57.600]   still see most people have sort of a master's degree
[00:08:57.600 --> 00:09:00.560]   or a PhD in CS or stats,
[00:09:00.560 --> 00:09:02.160]   or did something like the, you know,
[00:09:02.160 --> 00:09:04.540]   the Google Brain residency.
[00:09:04.540 --> 00:09:06.540]   But, you know, I think this is starting to change,
[00:09:06.540 --> 00:09:07.760]   but, you know, of all of these,
[00:09:07.760 --> 00:09:10.920]   this is the one where kind of academic background
[00:09:10.920 --> 00:09:12.080]   still matters the most.
[00:09:12.080 --> 00:09:15.580]   And then, you know, data scientists,
[00:09:15.580 --> 00:09:18.520]   again, since this is kind of a catch-all term,
[00:09:18.520 --> 00:09:21.600]   it corresponds to a pretty wide range of backgrounds.
[00:09:21.600 --> 00:09:23.160]   One common background that I've seen
[00:09:23.160 --> 00:09:26.640]   is for people who have, you know,
[00:09:26.640 --> 00:09:28.620]   some other sort of science PhD,
[00:09:28.620 --> 00:09:31.320]   like maybe they did a PhD in, you know,
[00:09:31.320 --> 00:09:32.960]   in chemistry or something like that,
[00:09:32.960 --> 00:09:36.960]   and they want to move into the tech world.
[00:09:36.960 --> 00:09:38.000]   This is kind of a common role
[00:09:38.000 --> 00:09:40.080]   that people with that background go into.
[00:09:40.080 --> 00:09:44.640]   Okay, any questions about kind of the landscape
[00:09:44.640 --> 00:09:45.920]   of the roles and the skill sets
[00:09:45.920 --> 00:09:47.420]   that you need for those roles?
[00:09:47.420 --> 00:09:53.800]   All right.
[00:09:53.800 --> 00:09:57.200]   The next thing I want to talk about is,
[00:09:57.200 --> 00:10:00.080]   like, how does this all fit together into teams?
[00:10:00.080 --> 00:10:01.400]   So what do teams look like
[00:10:01.400 --> 00:10:04.520]   that are working on machine learning projects?
[00:10:04.520 --> 00:10:06.560]   And, you know, the main thing that we learned
[00:10:06.560 --> 00:10:08.320]   when we, you know, talked to a bunch of people
[00:10:08.320 --> 00:10:09.520]   about how they're organizing their teams
[00:10:09.520 --> 00:10:11.920]   is that there isn't really a consensus yet
[00:10:11.920 --> 00:10:14.680]   on the right way to structure a team
[00:10:14.680 --> 00:10:16.880]   that's working on machine learning projects.
[00:10:16.880 --> 00:10:21.360]   But there are some lessons that we learned
[00:10:21.360 --> 00:10:23.200]   that I think are worth sharing.
[00:10:23.200 --> 00:10:27.800]   So the first thing is that a lot of the people
[00:10:27.800 --> 00:10:31.660]   that we talked to mentioned that it's really important
[00:10:31.660 --> 00:10:34.640]   to not just have ML teams that only know machine learning.
[00:10:34.640 --> 00:10:35.880]   Like, if they're working on stuff
[00:10:35.880 --> 00:10:37.800]   that's going to be deployed into production,
[00:10:37.800 --> 00:10:39.900]   almost everyone thinks that it's very critical
[00:10:39.900 --> 00:10:42.640]   to have software engineering skills on the team.
[00:10:42.640 --> 00:10:45.680]   Where people didn't agree is whether that can be a mix
[00:10:45.680 --> 00:10:47.440]   of people who are really deep in machine learning
[00:10:47.440 --> 00:10:49.000]   and really deep in software engineering,
[00:10:49.000 --> 00:10:50.980]   or whether everyone on the team needs to have
[00:10:50.980 --> 00:10:52.820]   a mix of both skill sets.
[00:10:52.820 --> 00:10:55.320]   We talked to people who have both of those views.
[00:10:55.320 --> 00:10:59.240]   Different teams had a different view
[00:10:59.240 --> 00:11:01.460]   of machine learning researchers.
[00:11:01.460 --> 00:11:03.680]   So we talked to some people who said,
[00:11:03.680 --> 00:11:06.080]   "Yeah, you know, machine learning research is exciting,
[00:11:06.080 --> 00:11:08.800]   but I don't really like to hire machine learning researchers
[00:11:08.800 --> 00:11:10.360]   because it's just too hard to integrate them
[00:11:10.360 --> 00:11:12.560]   with my software team and my product team.
[00:11:12.560 --> 00:11:15.560]   And so I don't actually get useful work out of them."
[00:11:15.560 --> 00:11:17.000]   Other people who maybe are working
[00:11:17.000 --> 00:11:19.700]   on more frontier technology think that it's actually
[00:11:19.700 --> 00:11:22.080]   really critical to have at least one or two people
[00:11:22.080 --> 00:11:24.360]   on the team who have deep ML expertise
[00:11:24.360 --> 00:11:27.160]   because the field is moving so fast.
[00:11:27.160 --> 00:11:28.960]   You need people who can keep up with it
[00:11:28.960 --> 00:11:30.640]   and make sure that you're always doing things
[00:11:30.640 --> 00:11:31.680]   that are up to date.
[00:11:32.680 --> 00:11:35.440]   There were also differing views on data engineering.
[00:11:35.440 --> 00:11:38.000]   And so this kind of tends to sit in different places
[00:11:38.000 --> 00:11:39.480]   within the organization.
[00:11:39.480 --> 00:11:44.000]   In some organizations, it sits within the ML team.
[00:11:44.000 --> 00:11:45.560]   And so the rationale there is,
[00:11:45.560 --> 00:11:50.160]   you know, the output of this team is the input
[00:11:50.160 --> 00:11:51.080]   for the machine learning team.
[00:11:51.080 --> 00:11:52.600]   And so these two functions should be
[00:11:52.600 --> 00:11:54.280]   as close together as possible, right?
[00:11:54.280 --> 00:11:58.560]   Like the data team's work product is directly used
[00:11:58.560 --> 00:12:00.080]   by the ML team, and so they should be, you know,
[00:12:00.080 --> 00:12:02.120]   their desks should be next to each other.
[00:12:02.120 --> 00:12:05.760]   Other organizations have it as a separate team,
[00:12:05.760 --> 00:12:08.640]   which is often called data warehousing.
[00:12:08.640 --> 00:12:11.920]   And then another thing to note is that a lot
[00:12:11.920 --> 00:12:13.360]   of organizations that we talk to think
[00:12:13.360 --> 00:12:14.640]   that it's important to have people
[00:12:14.640 --> 00:12:16.480]   who are dedicated to data labeling.
[00:12:16.480 --> 00:12:18.440]   And this doesn't necessarily mean people
[00:12:18.440 --> 00:12:20.080]   who are labeling data themselves.
[00:12:20.080 --> 00:12:22.240]   It could just be people who are managing
[00:12:22.240 --> 00:12:24.560]   the outsourced data labeling workflow
[00:12:24.560 --> 00:12:25.800]   because it's such a critical part
[00:12:25.800 --> 00:12:28.880]   of what the ML team needs in order to do their job well.
[00:12:29.880 --> 00:12:32.040]   (silence)
[00:12:32.040 --> 00:12:36.680]   All right, I wanna say a few words
[00:12:36.680 --> 00:12:39.280]   about managing machine learning teams.
[00:12:39.280 --> 00:12:43.120]   And, you know, the point that I wanna make here
[00:12:43.120 --> 00:12:47.120]   is just to point out some of the challenges
[00:12:47.120 --> 00:12:49.560]   of, you know, why this is often more difficult
[00:12:49.560 --> 00:12:51.840]   than managing typical software teams.
[00:12:51.840 --> 00:12:56.000]   And I don't really have all the answers here,
[00:12:56.000 --> 00:12:57.120]   but, you know, I think it's helpful
[00:12:57.120 --> 00:12:59.680]   to sort of understand why this
[00:12:59.680 --> 00:13:01.680]   is a particularly difficult problem.
[00:13:01.680 --> 00:13:03.880]   And, you know, so the first reason is,
[00:13:03.880 --> 00:13:06.240]   it can be really hard to tell in advance,
[00:13:06.240 --> 00:13:07.920]   you know, for this particular problem
[00:13:07.920 --> 00:13:10.240]   that you wanna work on, is this a really hard problem
[00:13:10.240 --> 00:13:11.920]   or is this a really easy problem?
[00:13:11.920 --> 00:13:14.480]   And I imagine some of you are maybe feeling this way
[00:13:14.480 --> 00:13:16.200]   about your projects right now.
[00:13:16.200 --> 00:13:20.120]   Some nods, yeah, okay.
[00:13:20.120 --> 00:13:24.520]   And I like this idea of, you know,
[00:13:24.520 --> 00:13:29.160]   and I like these charts that Lucas already showed you,
[00:13:29.160 --> 00:13:32.680]   but this is from a, I think it was a Kaggle competition
[00:13:32.680 --> 00:13:36.480]   that he ran, where they looked at accuracy of,
[00:13:36.480 --> 00:13:37.800]   you know, a model on some data set
[00:13:37.800 --> 00:13:39.560]   and they looked at how performance
[00:13:39.560 --> 00:13:41.200]   was improving in the first week.
[00:13:41.200 --> 00:13:42.960]   And, you know, it's like, great,
[00:13:42.960 --> 00:13:46.480]   accuracy has gone up from, you know, 35% to 70% in a week.
[00:13:46.480 --> 00:13:48.040]   It looks like this problem is just gonna be solved,
[00:13:48.040 --> 00:13:50.040]   you know, in the next couple of weeks.
[00:13:50.040 --> 00:13:52.040]   But then when they looked at performance
[00:13:52.040 --> 00:13:54.160]   throughout the three months of the project,
[00:13:54.160 --> 00:13:55.200]   it turns out that this, you know,
[00:13:55.200 --> 00:13:56.520]   this really fast growth at the beginning
[00:13:56.520 --> 00:13:59.360]   was actually just ramping up to a plateau.
[00:13:59.360 --> 00:14:01.440]   And the accuracy didn't actually really improve
[00:14:01.440 --> 00:14:02.800]   that much beyond that, you know,
[00:14:02.800 --> 00:14:05.200]   despite the fact that the, you know,
[00:14:05.200 --> 00:14:06.680]   the amount of effort going into it
[00:14:06.680 --> 00:14:09.120]   was increasing dramatically, right?
[00:14:09.120 --> 00:14:11.480]   So you might've seen this first chart in the first week
[00:14:11.480 --> 00:14:13.520]   and thought, hey, this is a pretty easy problem
[00:14:13.520 --> 00:14:15.280]   and we can, you know, we don't really need
[00:14:15.280 --> 00:14:17.800]   to staff up this team too much, you know,
[00:14:17.800 --> 00:14:19.760]   it's just gonna be solved in the next couple of weeks
[00:14:19.760 --> 00:14:21.720]   and then been disappointed three months later.
[00:14:21.720 --> 00:14:24.080]   So it's a tricky situation as a manager.
[00:14:24.080 --> 00:14:29.560]   A related problem I think is that
[00:14:29.560 --> 00:14:32.980]   machine learning projects and the progress on them
[00:14:32.980 --> 00:14:35.000]   tend to be very nonlinear.
[00:14:35.000 --> 00:14:36.920]   And so this is like kind of in stark contrast
[00:14:36.920 --> 00:14:38.280]   to software engineering projects, right?
[00:14:38.280 --> 00:14:41.880]   Where it's, you can generally tell on a week to week basis,
[00:14:41.880 --> 00:14:43.440]   have a reasonable estimate of how much work
[00:14:43.440 --> 00:14:44.820]   you can expect to get done.
[00:14:44.820 --> 00:14:49.520]   But in machine learning projects often stall for weeks.
[00:14:49.520 --> 00:14:53.960]   And it's often kind of very unclear
[00:14:53.960 --> 00:14:56.000]   exactly what things you're gonna need to try
[00:14:56.000 --> 00:14:57.760]   because you haven't hit the roadblocks yet.
[00:14:57.760 --> 00:15:00.600]   So it can be difficult to paralyze things
[00:15:00.600 --> 00:15:01.920]   and estimate project timelines
[00:15:01.920 --> 00:15:03.280]   in the early stages of the project.
[00:15:03.280 --> 00:15:04.880]   Because, you know, you kind of need to just start
[00:15:04.880 --> 00:15:06.120]   trying things and see what works
[00:15:06.120 --> 00:15:09.120]   before you know exactly what you're gonna need to invest in.
[00:15:09.120 --> 00:15:12.720]   And so one way I like to think about this is,
[00:15:12.720 --> 00:15:15.560]   you know, even in applied machine learning
[00:15:15.560 --> 00:15:17.980]   and machine learning that's going into production,
[00:15:17.980 --> 00:15:19.960]   it's still not like, in my opinion,
[00:15:19.960 --> 00:15:21.740]   totally an engineering discipline.
[00:15:21.740 --> 00:15:24.600]   It's still somewhere in between research and engineering.
[00:15:24.600 --> 00:15:30.440]   Another common issue that we've seen
[00:15:30.440 --> 00:15:31.600]   in talking to companies about this
[00:15:31.600 --> 00:15:33.620]   is that there's often a cultural gap
[00:15:33.620 --> 00:15:36.980]   between people whose background is research
[00:15:36.980 --> 00:15:39.000]   and people whose background is engineering.
[00:15:39.000 --> 00:15:41.480]   And this can manifest itself in different ways,
[00:15:41.480 --> 00:15:44.980]   just from, you know, sort of different values,
[00:15:44.980 --> 00:15:47.280]   different kind of outcomes of projects that they care about,
[00:15:47.280 --> 00:15:50.240]   different things they're excited about working on.
[00:15:50.240 --> 00:15:53.620]   And, you know, in like the worst examples of this,
[00:15:53.620 --> 00:15:55.560]   what this can look like is, you know,
[00:15:55.560 --> 00:15:57.360]   either side thinking they're better than the other.
[00:15:57.360 --> 00:15:58.720]   Like research thinking, you know,
[00:15:58.720 --> 00:15:59.680]   oh, we're the ones who are working on
[00:15:59.680 --> 00:16:02.280]   the really challenging part of this problem.
[00:16:02.280 --> 00:16:04.360]   Or engineering thinking like,
[00:16:04.360 --> 00:16:06.000]   oh, we're the ones that are actually building things
[00:16:06.000 --> 00:16:06.840]   that are useful.
[00:16:06.840 --> 00:16:10.160]   And so this is a problem that crops up
[00:16:10.160 --> 00:16:12.720]   in some organizations and it takes conscious effort
[00:16:12.720 --> 00:16:14.720]   in order to make sure it doesn't happen.
[00:16:15.720 --> 00:16:17.560]   And then the last thing I'll point out is
[00:16:17.560 --> 00:16:19.120]   that we've heard from a lot of people actually,
[00:16:19.120 --> 00:16:22.800]   is that, you know, leaders just often in your organization
[00:16:22.800 --> 00:16:24.680]   often just don't get machine learning.
[00:16:24.680 --> 00:16:29.160]   And, you know, and I think this can manifest itself
[00:16:29.160 --> 00:16:32.160]   in them like kind of not understanding the difficulties
[00:16:32.160 --> 00:16:34.000]   that are listed above.
[00:16:34.000 --> 00:16:36.920]   But this is a challenge that a lot of people
[00:16:36.920 --> 00:16:38.840]   who are trying to start machine learning efforts
[00:16:38.840 --> 00:16:41.960]   within larger organizations complain about.
[00:16:41.960 --> 00:16:44.640]   And so I think it's just important to make sure that
[00:16:44.640 --> 00:16:48.040]   leadership understands why the problems
[00:16:48.040 --> 00:16:50.800]   that you're working on are kind of uniquely challenging.
[00:16:50.800 --> 00:16:55.840]   All right.
[00:16:55.840 --> 00:16:58.600]   Any questions about machine learning teams,
[00:16:58.600 --> 00:16:59.440]   managing them?
[00:16:59.440 --> 00:17:01.640]   I think I've like pointed out problems here,
[00:17:01.640 --> 00:17:03.200]   but not suggested solutions.
[00:17:03.200 --> 00:17:05.800]   So also if you have any solutions, I'd love to hear them.
[00:17:05.800 --> 00:17:06.640]   - Yeah.
[00:17:06.640 --> 00:17:08.760]   - Slight solution, just a question.
[00:17:08.760 --> 00:17:10.560]   Could you expand a little bit on the,
[00:17:10.560 --> 00:17:13.480]   could you expand a little bit more about
[00:17:13.480 --> 00:17:17.040]   what software engineering skills can particularly be useful
[00:17:17.040 --> 00:17:18.320]   in a machine learning project?
[00:17:18.320 --> 00:17:21.960]   Because I think for me personally, like trying to learn,
[00:17:21.960 --> 00:17:24.600]   there are limited resources on how you should sort of
[00:17:24.600 --> 00:17:27.400]   do your machine learning project
[00:17:27.400 --> 00:17:29.360]   and how you should do unit testing.
[00:17:29.360 --> 00:17:31.880]   There isn't like a standardized rule standard to.
[00:17:31.880 --> 00:17:33.800]   - Yeah.
[00:17:33.800 --> 00:17:37.360]   I think a lot of the, like much of the standard
[00:17:37.360 --> 00:17:39.400]   software engineering tool set is helpful.
[00:17:39.400 --> 00:17:41.560]   Like I think most machine learning teams
[00:17:41.560 --> 00:17:45.040]   are doing a lot of building their own tools,
[00:17:45.040 --> 00:17:49.680]   and there are companies out there that are trying to
[00:17:49.680 --> 00:17:51.040]   make sure that this doesn't happen anymore,
[00:17:51.040 --> 00:17:52.440]   but the current state is,
[00:17:52.440 --> 00:17:54.520]   many people are still doing this.
[00:17:54.520 --> 00:17:58.320]   And so if you're good at building tools that can be used by
[00:17:58.320 --> 00:18:00.160]   machine learning engineers or machine learning researchers,
[00:18:00.160 --> 00:18:02.200]   that skill will come in handy.
[00:18:02.200 --> 00:18:04.960]   I think the other big thing is like
[00:18:04.960 --> 00:18:07.320]   sort of distributed systems broadly,
[00:18:07.320 --> 00:18:09.800]   like being able to paralyze workflows
[00:18:09.800 --> 00:18:14.160]   and paralyze sort of data pipelines and things like that
[00:18:14.160 --> 00:18:16.240]   is like really deeply useful.
[00:18:16.240 --> 00:18:17.400]   That's like the one particular thing
[00:18:17.400 --> 00:18:18.840]   I think that people look for.
[00:18:18.840 --> 00:18:26.400]   Anyone manage a machine learning team?
[00:18:26.400 --> 00:18:28.520]   Yeah.
[00:18:28.520 --> 00:18:30.840]   How do you deal with these problems?
[00:18:30.840 --> 00:18:32.080]   Like have you seen these?
[00:18:32.080 --> 00:18:34.560]   - Yeah.
[00:18:34.560 --> 00:18:37.480]   (faintly speaking)
[00:18:37.480 --> 00:18:42.680]   - Sorry?
[00:18:42.680 --> 00:18:45.320]   - We're trying to figure out basic data.
[00:18:45.320 --> 00:18:46.400]   - Yeah.
[00:18:46.400 --> 00:18:47.840]   Is there anything in your experience
[00:18:47.840 --> 00:18:49.760]   that's been particularly useful?
[00:18:49.760 --> 00:18:51.480]   - Finding people can help with the
[00:18:51.480 --> 00:18:53.680]   machine learning pipelines very well.
[00:18:53.680 --> 00:18:56.600]   (faintly speaking)
[00:18:56.600 --> 00:19:02.240]   Creating a very reliable machine learning pipeline.
[00:19:02.240 --> 00:19:05.160]   (faintly speaking)
[00:19:05.160 --> 00:19:25.800]   - So finding someone who can bridge the gap
[00:19:25.800 --> 00:19:28.440]   between the technical work and then the business outcomes
[00:19:28.440 --> 00:19:29.440]   that you're trying to get to.
[00:19:29.440 --> 00:19:30.880]   How did you find that person?
[00:19:31.840 --> 00:19:34.760]   (faintly speaking)
[00:19:34.760 --> 00:19:55.480]   - Got it.
[00:19:55.480 --> 00:19:57.360]   So you found someone who understood
[00:19:57.360 --> 00:20:00.000]   the technical challenges from previous life
[00:20:00.000 --> 00:20:02.400]   and then was willing to sort of translate that.
[00:20:02.400 --> 00:20:03.560]   Yeah.
[00:20:03.560 --> 00:20:05.640]   - Storytelling and explaining things
[00:20:05.640 --> 00:20:07.800]   is one of the key points that we felt
[00:20:07.800 --> 00:20:09.800]   made a difference for us.
[00:20:09.800 --> 00:20:15.080]   - And then are there differences
[00:20:15.080 --> 00:20:17.280]   between how you think that works,
[00:20:17.280 --> 00:20:19.200]   how to tell a good story about a machine learning project
[00:20:19.200 --> 00:20:21.480]   versus a general software engineering project?
[00:20:21.480 --> 00:20:28.600]   - No, we didn't find that much of a difference in there.
[00:20:28.600 --> 00:20:30.880]   But you just need to be good at communication
[00:20:30.880 --> 00:20:31.960]   to fix those.
[00:20:31.960 --> 00:20:34.680]   Because many of these problems,
[00:20:34.680 --> 00:20:38.000]   when we say that, hey, for us,
[00:20:38.000 --> 00:20:41.920]   the technical issue was when the prediction
[00:20:41.920 --> 00:20:43.320]   is telling something else,
[00:20:43.320 --> 00:20:46.360]   but the common sense is completely opposite of that.
[00:20:46.360 --> 00:20:49.920]   So it was hard for us to convince our sales team
[00:20:49.920 --> 00:20:51.720]   and our building that they would do
[00:20:51.720 --> 00:20:53.560]   with what we are telling them.
[00:20:53.560 --> 00:20:54.760]   - Convincing them to trust the system.
[00:20:54.760 --> 00:20:55.600]   - Yeah.
[00:20:55.600 --> 00:20:56.440]   - Yeah.
[00:20:56.440 --> 00:21:00.880]   - Any other thoughts on this part?
[00:21:00.880 --> 00:21:03.760]   I think this is like sort of one of the hardest challenges
[00:21:03.760 --> 00:21:07.080]   in building machine learning products right now.
[00:21:07.080 --> 00:21:07.920]   Yeah.
[00:21:07.920 --> 00:21:09.720]   - Can you speak to like project management
[00:21:09.720 --> 00:21:11.560]   of these types of projects?
[00:21:11.560 --> 00:21:13.680]   So I'm a data scientist and I feel like it's really hard
[00:21:13.680 --> 00:21:18.680]   to like make tickets in a classic JIRA style.
[00:21:18.680 --> 00:21:22.840]   Have you worked in any product management style
[00:21:22.840 --> 00:21:25.280]   for a machine learning project that's been helpful?
[00:21:25.280 --> 00:21:26.720]   - Yeah.
[00:21:26.720 --> 00:21:29.200]   We've tried a lot of things at OpenAI
[00:21:29.200 --> 00:21:33.480]   and what's tended to work best is just kind of like
[00:21:33.480 --> 00:21:35.200]   the simplest and lightest weight things.
[00:21:35.200 --> 00:21:37.600]   Like even just a Google Doc where people sort of
[00:21:37.600 --> 00:21:40.480]   talk about what they're planning to work on
[00:21:40.480 --> 00:21:42.440]   like on the timeframe of say a week
[00:21:42.440 --> 00:21:45.600]   and then check in after a week to see how things go.
[00:21:45.600 --> 00:21:47.160]   One of the challenges is that,
[00:21:47.160 --> 00:21:51.160]   is that, you know, I think in a lot of people
[00:21:51.160 --> 00:21:52.880]   who come from software engineering backgrounds
[00:21:52.880 --> 00:21:55.600]   kind of expect if you said you're gonna get something done
[00:21:55.600 --> 00:21:58.360]   this week, then it's gonna get done this week.
[00:21:58.360 --> 00:22:00.600]   And it doesn't, at least in my experience
[00:22:00.600 --> 00:22:01.800]   has not always worked out that way
[00:22:01.800 --> 00:22:03.840]   for machine learning teams because,
[00:22:03.840 --> 00:22:08.800]   and you know, often the thing that you tried doesn't work
[00:22:08.800 --> 00:22:11.520]   or you encounter some difficulty in implementing the thing
[00:22:11.520 --> 00:22:14.920]   that you didn't foresee when you decided to work on it.
[00:22:14.920 --> 00:22:17.880]   And so I think one thing that's like one mindset
[00:22:17.880 --> 00:22:21.680]   that's been helpful has been to think about measuring
[00:22:21.680 --> 00:22:25.000]   people's sort of inputs as opposed to their outputs.
[00:22:25.000 --> 00:22:27.520]   So I think a big driver of how much progress
[00:22:27.520 --> 00:22:29.280]   machine learning organizations are able to make
[00:22:29.280 --> 00:22:31.920]   is just how many ideas they're able to try, right?
[00:22:31.920 --> 00:22:34.880]   Because every idea has like some probability of success.
[00:22:34.880 --> 00:22:37.560]   And like, even, you know, the most brilliant
[00:22:37.560 --> 00:22:39.960]   machine learning researchers like are only right,
[00:22:39.960 --> 00:22:42.600]   you know, I don't know, 50% of the time,
[00:22:42.600 --> 00:22:44.880]   is that maybe that's generous, probably less.
[00:22:44.880 --> 00:22:46.240]   Yeah.
[00:22:46.240 --> 00:22:48.800]   And so, you know, if you're able to try 10 things
[00:22:48.800 --> 00:22:51.200]   in the timeframe that it takes someone else to try
[00:22:51.200 --> 00:22:53.800]   two or three, then that's a huge advantage.
[00:22:53.800 --> 00:22:55.920]   Yeah.
[00:22:55.920 --> 00:23:00.580]   (audience member speaking indistinctly)
[00:23:00.580 --> 00:23:09.720]   Yeah.
[00:23:09.720 --> 00:23:12.560]   So number of ideas that you tried,
[00:23:12.560 --> 00:23:14.560]   I think is a really important one.
[00:23:14.560 --> 00:23:16.600]   I think there's like, there's some timescale,
[00:23:16.600 --> 00:23:18.520]   like under which you have to sort of be able
[00:23:18.520 --> 00:23:20.040]   to make things work.
[00:23:20.040 --> 00:23:21.520]   And I think it depends a little bit on the context
[00:23:21.520 --> 00:23:23.940]   of the organization, how long that is.
[00:23:23.940 --> 00:23:27.820]   So, you know, like I think in most organizations,
[00:23:27.820 --> 00:23:30.080]   if like, if a researcher, for example,
[00:23:30.080 --> 00:23:31.960]   has not tried any ideas that have worked
[00:23:31.960 --> 00:23:34.160]   over the course of, you know, a couple of years,
[00:23:34.160 --> 00:23:36.200]   then it seems like that's probably bad.
[00:23:36.200 --> 00:23:38.320]   But, you know, maybe if it's three months,
[00:23:38.320 --> 00:23:40.420]   then it's like, it's pretty reasonable
[00:23:40.420 --> 00:23:43.680]   to not have any ideas that have worked in that timeframe.
[00:23:43.680 --> 00:23:45.000]   Another thing I think is that's important
[00:23:45.000 --> 00:23:48.080]   is just like how well they're able to sort of
[00:23:48.080 --> 00:23:50.000]   connect their ideas to the rest of the team
[00:23:50.000 --> 00:23:51.080]   in the organization.
[00:23:51.080 --> 00:23:53.600]   So like, I think one failure mode for integrating
[00:23:53.600 --> 00:23:55.340]   researchers with broader teams is that
[00:23:55.340 --> 00:23:56.440]   they kind of work on their own things
[00:23:56.440 --> 00:23:58.440]   and, you know, even their best ideas
[00:23:58.440 --> 00:24:01.280]   never really make it back into the work
[00:24:01.280 --> 00:24:02.320]   that the rest of the team is doing.
[00:24:02.320 --> 00:24:04.080]   So I think having metrics around that
[00:24:04.080 --> 00:24:05.400]   could be valuable as well.
[00:24:05.400 --> 00:24:11.200]   Great.
[00:24:11.200 --> 00:24:13.160]   The last thing I want to talk about a little bit
[00:24:13.160 --> 00:24:14.320]   is just MO hiring.
[00:24:14.320 --> 00:24:17.080]   So, you know, a lot of you are thinking about
[00:24:17.080 --> 00:24:19.640]   looking for jobs in the next year or so.
[00:24:19.640 --> 00:24:21.880]   Some of you maybe are looking to hire people.
[00:24:21.880 --> 00:24:27.400]   So I think a lot of the places to look for
[00:24:27.400 --> 00:24:31.360]   ML and data science jobs are, you know,
[00:24:31.360 --> 00:24:33.380]   just the typical things that you would think of.
[00:24:33.380 --> 00:24:35.440]   So, you know, applying directly to companies
[00:24:35.440 --> 00:24:36.280]   you're interested in.
[00:24:36.280 --> 00:24:37.920]   I think a lot of people in general
[00:24:37.920 --> 00:24:40.120]   think that this doesn't work.
[00:24:40.120 --> 00:24:41.560]   One thing that I've noticed is that
[00:24:41.560 --> 00:24:43.360]   in machine learning, since these roles
[00:24:43.360 --> 00:24:46.300]   are so hard to hire for, sort of the direct approach
[00:24:46.300 --> 00:24:47.840]   can actually work quite well.
[00:24:47.840 --> 00:24:52.160]   You know, if you're in school on campus recruiting,
[00:24:52.160 --> 00:24:55.320]   if you're more experienced LinkedIn recruiters,
[00:24:55.320 --> 00:24:57.580]   ML conferences are great places to go look for jobs.
[00:24:57.580 --> 00:25:00.540]   A lot of the big companies are there kind of with booths
[00:25:00.540 --> 00:25:03.700]   and they're very actively hiring at those events.
[00:25:03.700 --> 00:25:07.540]   And then lastly, you know, as I mentioned,
[00:25:07.540 --> 00:25:09.680]   we're going to bring in some folks
[00:25:09.680 --> 00:25:12.220]   to do some recruit, who are looking to recruit
[00:25:12.220 --> 00:25:14.560]   in the project presentations at the end of the class.
[00:25:14.560 --> 00:25:17.260]   So connecting with those people could be helpful.
[00:25:17.260 --> 00:25:22.040]   So what should you expect in the interview process?
[00:25:22.040 --> 00:25:24.980]   I feel like software engineering interviews
[00:25:24.980 --> 00:25:27.460]   are sort of very well defined at this point.
[00:25:27.460 --> 00:25:30.120]   And you can kind of buy a book that tells you
[00:25:30.120 --> 00:25:32.500]   what types of interview questions to prepare for.
[00:25:32.500 --> 00:25:34.860]   And, you know, you can Google interview questions
[00:25:34.860 --> 00:25:37.260]   and you can figure out exactly the right way to solve them.
[00:25:37.260 --> 00:25:41.480]   The interview process for machine learning roles
[00:25:41.480 --> 00:25:43.480]   is much less well-defined at this point.
[00:25:44.300 --> 00:25:46.940]   There's a lot of types of assessments
[00:25:46.940 --> 00:25:48.940]   that are pretty common, but they are mixed
[00:25:48.940 --> 00:25:50.900]   and matched in different ways.
[00:25:50.900 --> 00:25:52.000]   Here are some of them.
[00:25:52.000 --> 00:25:57.980]   I think the, so the first few of these are,
[00:25:57.980 --> 00:26:02.660]   let's see the first three of these are just sort of
[00:26:02.660 --> 00:26:04.540]   general software engineering interview type questions
[00:26:04.540 --> 00:26:05.820]   that you might get.
[00:26:05.820 --> 00:26:08.260]   In terms of ML specific stuff,
[00:26:08.260 --> 00:26:10.640]   a couple of things that I've seen that are interesting,
[00:26:10.640 --> 00:26:12.740]   pair debugging on ML specific code.
[00:26:12.740 --> 00:26:14.160]   So sort of like the debugging exercise
[00:26:14.160 --> 00:26:15.400]   that we did a few weeks ago.
[00:26:15.400 --> 00:26:17.600]   It's like, hey, here's some buggy code.
[00:26:17.600 --> 00:26:21.000]   Let's sit down together and figure out where the bugs are.
[00:26:21.000 --> 00:26:24.560]   See a lot of math puzzles, a lot of linear algebra puzzles.
[00:26:24.560 --> 00:26:27.340]   Take home ML projects, like here's a data set.
[00:26:27.340 --> 00:26:28.920]   How well can you do on this data set?
[00:26:28.920 --> 00:26:30.120]   Those are pretty common.
[00:26:30.120 --> 00:26:35.500]   Applied ML, so, you know, here's a problem that like
[00:26:35.500 --> 00:26:38.400]   maybe one that's related to what the team is working on.
[00:26:38.400 --> 00:26:40.320]   You know, tell us how you'd approach solving it.
[00:26:40.320 --> 00:26:42.120]   What data would you be looking for?
[00:26:42.120 --> 00:26:44.140]   What type of model would you train?
[00:26:44.140 --> 00:26:46.800]   It's a very common type of question.
[00:26:46.800 --> 00:26:50.240]   People also often like to try to dive deep
[00:26:50.240 --> 00:26:51.660]   into your previous ML projects
[00:26:51.660 --> 00:26:53.860]   and sort of probe at the assumptions you made
[00:26:53.860 --> 00:26:56.860]   and why you made certain decisions about like
[00:26:56.860 --> 00:27:00.140]   what architecture you chose or, you know,
[00:27:00.140 --> 00:27:02.000]   how you know, how you like what your goals were
[00:27:02.000 --> 00:27:03.960]   for the project and things like that.
[00:27:03.960 --> 00:27:06.680]   And then ML theory questions are also very common.
[00:27:06.680 --> 00:27:11.680]   So, you know, explain the bias variance trade off.
[00:27:12.560 --> 00:27:14.360]   What's the difference between overfitting and underfitting?
[00:27:14.360 --> 00:27:17.080]   How do you know whether you're overfitting or underfitting?
[00:27:17.080 --> 00:27:19.400]   You know, asking you to explain specific algorithms
[00:27:19.400 --> 00:27:20.680]   that you're familiar with.
[00:27:20.680 --> 00:27:26.080]   In terms of how to prepare, I think it's especially,
[00:27:26.080 --> 00:27:27.600]   you know, this advice is kind of focused
[00:27:27.600 --> 00:27:30.240]   on the machine learning engineer role.
[00:27:30.240 --> 00:27:32.000]   I think it's still very important to prepare
[00:27:32.000 --> 00:27:34.280]   for a general software engineering interview
[00:27:34.280 --> 00:27:35.600]   'cause it seems like a lot of companies
[00:27:35.600 --> 00:27:37.340]   will ask those types of questions.
[00:27:37.340 --> 00:27:40.840]   You know, make sure that you are sort of brushed up
[00:27:40.840 --> 00:27:42.720]   and ready to talk about previous ML projects
[00:27:42.720 --> 00:27:43.960]   that you've worked on.
[00:27:43.960 --> 00:27:47.240]   And then I think the rest of it is around,
[00:27:47.240 --> 00:27:48.880]   you know, reviewing the basics.
[00:27:48.880 --> 00:27:52.080]   So make sure that you remember how kind of like
[00:27:52.080 --> 00:27:54.520]   even simpler machine learning algorithms work
[00:27:54.520 --> 00:27:57.520]   like linear regression, nearest neighbor,
[00:27:57.520 --> 00:28:00.720]   things like that and you can explain it to someone.
[00:28:00.720 --> 00:28:03.320]   And then, you know, if you're interviewing a company
[00:28:03.320 --> 00:28:04.660]   that does a lot of deep learning,
[00:28:04.660 --> 00:28:08.000]   then, you know, reviewing the Ian Goodfellow's
[00:28:08.000 --> 00:28:09.720]   deep learning book is another really good way
[00:28:09.720 --> 00:28:13.740]   to just make sure that you've covered most of the basics.
[00:28:13.740 --> 00:28:21.680]   Great, any other questions on hiring jobs, teams?
[00:28:21.680 --> 00:28:22.520]   Yeah.
[00:28:22.520 --> 00:28:23.960]   - Sorry, what was that book you said?
[00:28:23.960 --> 00:28:25.860]   - Ian Goodfellow's deep learning book.
[00:28:25.860 --> 00:28:38.760]   - You can also slack it out.
[00:28:38.760 --> 00:28:40.160]   - Yeah, I can slack it out.
[00:28:40.160 --> 00:28:42.600]   If you Google deep learning book,
[00:28:42.600 --> 00:28:44.500]   it's also the one that comes up, yeah.
[00:28:44.500 --> 00:28:49.240]   All right, so that's all that I wanted to cover.
[00:28:49.240 --> 00:28:51.600]   In terms of homework for next week,
[00:28:51.600 --> 00:28:53.600]   there's a lecture that we want you to watch
[00:28:53.600 --> 00:28:55.000]   and I'll post the link to this in Slack
[00:28:55.000 --> 00:28:57.560]   on testing ML code bases
[00:28:57.560 --> 00:28:59.800]   and deploying machine learning systems.
[00:28:59.800 --> 00:29:01.660]   And then the other piece is just continuing
[00:29:01.660 --> 00:29:02.640]   to work on your projects.
[00:29:02.640 --> 00:29:06.080]   And, you know, again, feel free to post updates
[00:29:06.080 --> 00:29:07.040]   and ask questions.
[00:29:07.040 --> 00:29:08.600]   I'm happy to kind of go through those
[00:29:08.600 --> 00:29:12.080]   and make specific suggestions on places you get stuck.
[00:29:12.080 --> 00:29:15.500]   I think we have two weeks left in the course.
[00:29:15.500 --> 00:29:19.740]   And so, you know, if you're at the point
[00:29:19.740 --> 00:29:21.160]   where you're getting close to having something
[00:29:21.160 --> 00:29:23.620]   that you feel like is working, but is not quite there,
[00:29:23.620 --> 00:29:26.680]   then, you know, that seems like right where you should be.
[00:29:26.680 --> 00:29:28.680]   But this is a good time to make like a final push
[00:29:28.680 --> 00:29:31.880]   to have something that's working pretty well for next week.
[00:29:31.880 --> 00:29:32.880]   So you can kind of wrap it up
[00:29:32.880 --> 00:29:35.120]   and make a good presentation the following week.

