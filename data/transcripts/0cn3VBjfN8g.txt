
[00:00:00.000 --> 00:00:03.740]   the person who controls the algorithm controls the world.
[00:00:03.740 --> 00:00:04.580]   Right?
[00:00:04.580 --> 00:00:09.120]   And if you are committed to one specific platform
[00:00:09.120 --> 00:00:11.560]   as your singular source of information
[00:00:11.560 --> 00:00:13.480]   or affiliated platforms,
[00:00:13.480 --> 00:00:15.600]   then whoever controls the algorithm
[00:00:15.600 --> 00:00:17.960]   or the programming there controls you.
[00:00:17.960 --> 00:00:23.160]   - The following is a conversation with Mark Cuban,
[00:00:23.160 --> 00:00:25.000]   a multi-billionaire businessman,
[00:00:25.000 --> 00:00:27.760]   investor and star of the series "Shark Tank,"
[00:00:27.760 --> 00:00:30.360]   longtime principal owner of the Dallas Mavericks,
[00:00:30.360 --> 00:00:33.800]   and is someone who is unafraid
[00:00:33.800 --> 00:00:36.000]   to get into frequent battles on X.
[00:00:36.000 --> 00:00:38.440]   Most recently over topics of DEI,
[00:00:38.440 --> 00:00:41.680]   wokeism, gender, and identity politics
[00:00:41.680 --> 00:00:44.960]   with the likes of Elon Musk and Jordan Peterson.
[00:00:44.960 --> 00:00:47.040]   This is the Lex Friedman Podcast.
[00:00:47.040 --> 00:00:47.880]   To support it,
[00:00:47.880 --> 00:00:50.240]   please check out our sponsors in the description.
[00:00:50.240 --> 00:00:53.800]   And now, dear friends, here's Mark Cuban.
[00:00:53.800 --> 00:00:57.080]   You've started many businesses,
[00:00:57.080 --> 00:00:58.640]   invested in many businesses,
[00:00:58.640 --> 00:01:02.420]   heard a lot of pitches privately and on "Shark Tank."
[00:01:02.420 --> 00:01:04.760]   So you're the perfect person to ask,
[00:01:04.760 --> 00:01:07.360]   what makes a great entrepreneur?
[00:01:07.360 --> 00:01:09.040]   - Somebody who's curious.
[00:01:09.040 --> 00:01:10.040]   They want to keep on learning
[00:01:10.040 --> 00:01:11.440]   'cause business is ever changing.
[00:01:11.440 --> 00:01:13.160]   It's never static.
[00:01:13.160 --> 00:01:15.880]   Somebody who's agile because as you learn new things
[00:01:15.880 --> 00:01:18.660]   and the environment around you changes,
[00:01:18.660 --> 00:01:21.120]   you have to be able to adapt and make the changes.
[00:01:21.120 --> 00:01:23.880]   And somebody who can sell
[00:01:23.920 --> 00:01:27.820]   because no business has ever survived without sales.
[00:01:27.820 --> 00:01:31.040]   And as an entrepreneur who's creating a company,
[00:01:31.040 --> 00:01:32.560]   whatever your product or service is,
[00:01:32.560 --> 00:01:34.280]   if that's not the most important thing
[00:01:34.280 --> 00:01:37.720]   and you're just dying and excited to tell people about it,
[00:01:37.720 --> 00:01:39.000]   then you're not gonna succeed.
[00:01:39.000 --> 00:01:40.240]   - But it's also a skill thing.
[00:01:40.240 --> 00:01:41.400]   How do you sell?
[00:01:41.400 --> 00:01:42.280]   What do you mean by selling?
[00:01:42.280 --> 00:01:43.400]   - Selling is just helping.
[00:01:43.400 --> 00:01:44.320]   I've always looked at it
[00:01:44.320 --> 00:01:48.160]   about putting myself in the shoes of another person
[00:01:48.160 --> 00:01:49.680]   and asking a simple question.
[00:01:49.680 --> 00:01:50.880]   Can I help this person?
[00:01:50.880 --> 00:01:51.720]   Can my product help?
[00:01:51.720 --> 00:01:53.320]   And from the time I was 12 years old,
[00:01:53.320 --> 00:01:54.920]   selling garbage bags door to door
[00:01:54.920 --> 00:01:56.760]   and just asking a simple question.
[00:01:56.760 --> 00:01:58.080]   Do you use garbage bags?
[00:01:58.080 --> 00:01:59.240]   Do you need garbage bags?
[00:01:59.240 --> 00:02:00.760]   Well, let me save you some time.
[00:02:00.760 --> 00:02:04.280]   I'll bring 'em to your house and drop 'em off to streaming.
[00:02:04.280 --> 00:02:07.200]   Why do we need streaming when we have TV and radio?
[00:02:07.200 --> 00:02:09.460]   Well, you can't get access to your TV and radio
[00:02:09.460 --> 00:02:10.680]   everywhere you go.
[00:02:10.680 --> 00:02:14.080]   So we kind of break down geographic and physical barriers
[00:02:14.080 --> 00:02:16.280]   and cost plus drugs.
[00:02:16.280 --> 00:02:18.280]   What's the product that we actually sell?
[00:02:18.280 --> 00:02:19.360]   We sell trust.
[00:02:19.360 --> 00:02:23.120]   In a simplistic approach, we buy drugs and sell drugs,
[00:02:23.120 --> 00:02:24.960]   but we add transparency to it.
[00:02:24.960 --> 00:02:27.720]   And bringing transparency to an industry
[00:02:27.720 --> 00:02:30.600]   is a differentiation and it helps people.
[00:02:30.600 --> 00:02:33.920]   - Trust in an industry that's highly lacking in trust.
[00:02:33.920 --> 00:02:35.080]   - Exactly.
[00:02:35.080 --> 00:02:37.840]   - Okay, so what's the trick to selling garbage bags?
[00:02:37.840 --> 00:02:39.720]   Let's go back there at 12 years old.
[00:02:39.720 --> 00:02:41.640]   I mean, is it just your natural charisma?
[00:02:41.640 --> 00:02:44.280]   I guess a good question to ask, are you born with it
[00:02:44.280 --> 00:02:45.600]   or can you develop it?
[00:02:45.600 --> 00:02:47.360]   - Oh, you can definitely develop it, yeah.
[00:02:47.360 --> 00:02:49.160]   I mean, because selling garbage bags door to door
[00:02:49.160 --> 00:02:50.000]   was easy, right?
[00:02:50.000 --> 00:02:51.160]   It was like, (knocking)
[00:02:51.160 --> 00:02:53.240]   12 year old Mark going, hi, my name is Mark.
[00:02:53.240 --> 00:02:54.880]   Do you use garbage bags?
[00:02:54.880 --> 00:02:56.640]   You know what the answer is going to be, right?
[00:02:56.640 --> 00:02:58.560]   Can I just drop them off for you once a week,
[00:02:58.560 --> 00:02:59.960]   whenever you need them, you just call
[00:02:59.960 --> 00:03:01.680]   and I'll bring them down, sure.
[00:03:01.680 --> 00:03:02.880]   So that was easy.
[00:03:02.880 --> 00:03:04.740]   - But I'm sure you've been rejected.
[00:03:04.740 --> 00:03:05.580]   - Oh yeah, of course.
[00:03:05.580 --> 00:03:06.960]   Not everybody says yes.
[00:03:06.960 --> 00:03:08.240]   - What was your percentage?
[00:03:08.240 --> 00:03:10.640]   - I don't remember, but it's pretty close to 100%.
[00:03:10.640 --> 00:03:11.480]   - Oh, okay.
[00:03:11.480 --> 00:03:12.560]   So that's why you don't remember.
[00:03:12.560 --> 00:03:13.880]   - Yeah, right.
[00:03:13.880 --> 00:03:15.600]   'Cause who's gonna say no to a 12 year old kid
[00:03:15.600 --> 00:03:17.500]   who's gonna save them time and money.
[00:03:17.500 --> 00:03:20.280]   But typically my career where I've started companies,
[00:03:20.280 --> 00:03:23.720]   it's to do something that other people aren't doing,
[00:03:23.720 --> 00:03:27.200]   whether it was connecting PCs and to local area networks
[00:03:27.200 --> 00:03:28.780]   and at micro solutions.
[00:03:28.780 --> 00:03:32.400]   And the salesmanship was walking into a company
[00:03:32.400 --> 00:03:34.800]   and just saying, look, talk to me
[00:03:34.800 --> 00:03:36.640]   and I can help you improve your productivity
[00:03:36.640 --> 00:03:37.860]   and your profitability.
[00:03:37.860 --> 00:03:39.160]   Is that important to you?
[00:03:39.160 --> 00:03:40.720]   And the answer is obviously always yes.
[00:03:40.720 --> 00:03:42.260]   And then the question is, can I do the job
[00:03:42.260 --> 00:03:44.280]   and can I do it cost effectively?
[00:03:44.280 --> 00:03:47.140]   And so you didn't have to be a born salesperson
[00:03:47.140 --> 00:03:49.080]   to be able to ask those questions,
[00:03:49.080 --> 00:03:52.120]   but you have to be able to be willing to put in the time
[00:03:52.120 --> 00:03:53.920]   to learn that business.
[00:03:53.920 --> 00:03:55.440]   And that's the hardest part.
[00:03:55.440 --> 00:03:57.680]   - I'm sure there's a skill thing to it too
[00:03:57.680 --> 00:04:01.320]   in like how you solve the puzzle of communicating
[00:04:01.320 --> 00:04:03.640]   with a person and convincing them.
[00:04:03.640 --> 00:04:05.520]   - Yeah, I mean, there's skill from the perspective
[00:04:05.520 --> 00:04:07.760]   that I read like a maniac.
[00:04:07.760 --> 00:04:10.440]   Then like now you can give me an example
[00:04:10.440 --> 00:04:12.760]   of any type of business and it'll take me two seconds
[00:04:12.760 --> 00:04:14.000]   to figure out how they make money
[00:04:14.000 --> 00:04:16.000]   and how I can make them more productive.
[00:04:16.000 --> 00:04:18.840]   And I think that's probably my biggest skill,
[00:04:18.840 --> 00:04:21.960]   being able to just drill down to what the actual need is,
[00:04:21.960 --> 00:04:25.120]   if any, and then from there being able to say,
[00:04:25.120 --> 00:04:27.560]   well, if this is what this company does
[00:04:27.560 --> 00:04:29.840]   and this is what their goal is,
[00:04:29.840 --> 00:04:31.340]   how can I introduce something new
[00:04:31.340 --> 00:04:32.840]   that they haven't seen before?
[00:04:32.840 --> 00:04:35.680]   And is that a business that I can create and make money from?
[00:04:35.680 --> 00:04:37.720]   - So figure out how this kind of business
[00:04:37.720 --> 00:04:39.880]   makes money in the present and then figure out
[00:04:39.880 --> 00:04:41.840]   is there a way to make more money in the future
[00:04:41.840 --> 00:04:43.720]   by introducing a totally new kind of thing.
[00:04:43.720 --> 00:04:45.240]   - Correct.
[00:04:45.240 --> 00:04:46.500]   - And you can just do that with anything.
[00:04:46.500 --> 00:04:48.040]   - Pretty much, yeah.
[00:04:48.040 --> 00:04:50.240]   - And you think you're born with that?
[00:04:50.240 --> 00:04:52.440]   - No, I worked at it because going back
[00:04:52.440 --> 00:04:54.560]   to what I said earlier about curiosity,
[00:04:54.560 --> 00:04:56.040]   you have to be insanely curious
[00:04:56.040 --> 00:04:57.720]   because the world is always changing.
[00:04:57.720 --> 00:04:59.760]   My dad used to say, "We don't live in the world
[00:04:59.760 --> 00:05:02.560]   "we were born into," which is absolutely true.
[00:05:02.560 --> 00:05:06.840]   If you're not a voracious consumer of information,
[00:05:06.840 --> 00:05:08.520]   then you're not gonna be able to keep up
[00:05:08.520 --> 00:05:11.260]   and no matter what your sales skills or ability are,
[00:05:11.260 --> 00:05:12.760]   they're gonna be useless.
[00:05:12.760 --> 00:05:15.080]   - What'd you learn about life from your dad?
[00:05:15.080 --> 00:05:16.460]   You mentioned your dad.
[00:05:16.460 --> 00:05:18.400]   - My dad did upholstery on cars.
[00:05:18.400 --> 00:05:21.240]   Got up, went to work every morning at seven o'clock,
[00:05:21.240 --> 00:05:24.640]   came back five or six, seven o'clock, exhausted.
[00:05:24.640 --> 00:05:27.440]   And I learned to be nice.
[00:05:27.440 --> 00:05:29.000]   I learned to be caring.
[00:05:29.000 --> 00:05:31.020]   I learned to be accepting.
[00:05:31.020 --> 00:05:35.320]   Just qualities that I think he really tried
[00:05:35.320 --> 00:05:37.720]   to pass on to myself and my two younger brothers
[00:05:37.720 --> 00:05:41.080]   were just be a good human and I think,
[00:05:41.080 --> 00:05:42.240]   he didn't have business experience
[00:05:42.240 --> 00:05:44.520]   so as I got into business, he would just say,
[00:05:44.520 --> 00:05:46.380]   "Sorry, Mark, I can't help you.
[00:05:46.380 --> 00:05:48.120]   "I don't understand what you're doing.
[00:05:48.120 --> 00:05:50.780]   "Neither one of my parents had gone to college.
[00:05:50.780 --> 00:05:52.500]   "You've gotta figure it out for yourself."
[00:05:52.500 --> 00:05:55.560]   But he was also very insistent that,
[00:05:55.560 --> 00:05:57.820]   you know, he worked at a company called Regency Products
[00:05:57.820 --> 00:05:59.920]   where they did upholstery on cars
[00:05:59.920 --> 00:06:01.800]   and he would bring me there to sweep the floors.
[00:06:01.800 --> 00:06:03.640]   Not because he wanted me to learn that business,
[00:06:03.640 --> 00:06:04.840]   because he wanted me to learn
[00:06:04.840 --> 00:06:06.760]   how backbreaking that work was.
[00:06:06.760 --> 00:06:09.220]   I mean, he lost an eye in an accident at work,
[00:06:09.220 --> 00:06:12.880]   a staple broke and the only thing he wanted
[00:06:12.880 --> 00:06:14.800]   from my brothers and I was for us
[00:06:14.800 --> 00:06:16.440]   to never have to work like that,
[00:06:16.440 --> 00:06:18.080]   to go to college, to figure it out.
[00:06:18.080 --> 00:06:19.200]   - You said to be nice.
[00:06:19.200 --> 00:06:21.420]   That said, you also said that you,
[00:06:21.420 --> 00:06:23.180]   when you were first starting a business,
[00:06:23.180 --> 00:06:24.640]   you were a bit more of an asshole
[00:06:24.640 --> 00:06:25.920]   than you wish you would have been.
[00:06:25.920 --> 00:06:27.200]   - Absolutely, yeah, yeah.
[00:06:27.200 --> 00:06:29.120]   Because I was more of a yeller.
[00:06:29.120 --> 00:06:30.840]   I was, you know, I didn't have--
[00:06:30.840 --> 00:06:31.680]   - No, really?
[00:06:31.680 --> 00:06:32.880]   - Yeah. (laughing)
[00:06:32.880 --> 00:06:34.320]   You know, what you see on the sidelines,
[00:06:34.320 --> 00:06:36.240]   you know, with me at a Mavs game, maybe a little bit,
[00:06:36.240 --> 00:06:38.760]   but I also didn't have any patience
[00:06:38.760 --> 00:06:41.360]   for somebody I thought wasn't using
[00:06:41.360 --> 00:06:43.360]   my kind of common sense, right?
[00:06:43.360 --> 00:06:47.120]   Because I was always on the go, go, go, go, go,
[00:06:47.120 --> 00:06:49.040]   when I, particularly when I was younger,
[00:06:49.040 --> 00:06:51.040]   just trying to be successful,
[00:06:51.040 --> 00:06:53.960]   trying to get to the point where I had independence.
[00:06:53.960 --> 00:06:55.500]   And I would tell this to people, you know,
[00:06:55.500 --> 00:06:57.240]   either you're speeding up and getting on the train
[00:06:57.240 --> 00:06:59.440]   or, you know, we'll stop and drop you off
[00:06:59.440 --> 00:07:02.520]   at the next station, but let's go where you go.
[00:07:02.520 --> 00:07:04.120]   - Did you have trouble with the hire fast,
[00:07:04.120 --> 00:07:06.480]   fire fast part of running a business?
[00:07:06.480 --> 00:07:08.400]   - Yeah, always, 'cause I hated firing people,
[00:07:08.400 --> 00:07:09.800]   'cause it meant, one, it was an admission
[00:07:09.800 --> 00:07:12.180]   of a mistake in the hiring, and two,
[00:07:12.180 --> 00:07:15.880]   the salesperson in me always wanted to come out ahead,
[00:07:15.880 --> 00:07:18.360]   and I was always horrible at firing,
[00:07:18.360 --> 00:07:19.560]   but I always partnered with people
[00:07:19.560 --> 00:07:23.400]   who had no problem with it, so I always delegated that.
[00:07:23.400 --> 00:07:24.240]   - Well, that's the tricky thing.
[00:07:24.240 --> 00:07:26.000]   When you're working with somebody
[00:07:26.000 --> 00:07:29.960]   and they're not quite there, and you have to decide,
[00:07:29.960 --> 00:07:32.040]   are they going to step up and grow into the person
[00:07:32.040 --> 00:07:34.840]   that's the right or they're not?
[00:07:34.840 --> 00:07:37.920]   And in that gray area is probably where you have to fire.
[00:07:37.920 --> 00:07:40.240]   - Was hard, yeah, for sure, because, you know,
[00:07:40.240 --> 00:07:43.780]   there is obviously a failure somewhere in the process.
[00:07:43.780 --> 00:07:45.180]   You know, what did we do wrong?
[00:07:45.180 --> 00:07:49.220]   And when I would interview people for jobs,
[00:07:49.220 --> 00:07:52.380]   I think 99% of the people I've ever interviewed
[00:07:52.380 --> 00:07:55.780]   I've wanted to hire, because in my mind it was like,
[00:07:55.780 --> 00:07:58.300]   okay, I can figure out how to make this person work, right?
[00:07:58.300 --> 00:08:00.340]   And then they wouldn't, and then, you know,
[00:08:00.340 --> 00:08:01.500]   people at the company would be like,
[00:08:01.500 --> 00:08:03.500]   Mark, you suck at this, you know?
[00:08:03.500 --> 00:08:06.140]   And so I always delegated the hiring.
[00:08:06.140 --> 00:08:07.740]   - Yeah, I mean, I'm the same.
[00:08:07.740 --> 00:08:08.860]   I see the potential in people.
[00:08:08.860 --> 00:08:11.860]   I see the beauty in people and which is a great way
[00:08:11.860 --> 00:08:13.700]   to live life, but when you're running a company,
[00:08:13.700 --> 00:08:14.540]   it's a different thing.
[00:08:14.540 --> 00:08:16.020]   - It's different, and you got to know what you're good at
[00:08:16.020 --> 00:08:17.340]   and what you're bad at, right?
[00:08:17.340 --> 00:08:21.420]   I was good at, you know, I was a ready, fire, aim guy,
[00:08:21.420 --> 00:08:23.900]   and I always partnered with people who were very anal
[00:08:23.900 --> 00:08:25.980]   and perfectionist, because where I could just go,
[00:08:25.980 --> 00:08:29.220]   go, go, go, go, go, they would keep me inside the baselines.
[00:08:29.220 --> 00:08:31.260]   - They would do the due diligence.
[00:08:31.260 --> 00:08:33.020]   - Yeah, or just, yeah, the detail work,
[00:08:33.020 --> 00:08:34.940]   the dot the I's and the cross the T's.
[00:08:34.940 --> 00:08:37.220]   - What does it take to take that first leap
[00:08:37.220 --> 00:08:38.580]   into starting a business?
[00:08:38.580 --> 00:08:39.620]   - That's the hardest part.
[00:08:39.620 --> 00:08:41.860]   It really depends on your personal circumstances.
[00:08:41.860 --> 00:08:42.820]   Like I got fired.
[00:08:42.820 --> 00:08:44.220]   I mean, I was sleeping on the floor,
[00:08:44.220 --> 00:08:46.220]   six guys in a three-bedroom apartment,
[00:08:46.220 --> 00:08:49.000]   so I couldn't go any lower. (laughs)
[00:08:49.000 --> 00:08:50.880]   So there was no downside. - Started at the bottom.
[00:08:50.880 --> 00:08:53.020]   - Yeah, there was no downside for me starting a business,
[00:08:53.020 --> 00:08:55.660]   and it was just like, you know, I was 25
[00:08:55.660 --> 00:08:58.320]   when we started MicroSolutions, and, you know,
[00:08:58.320 --> 00:09:01.300]   I'd just gotten fired, and it was like, look,
[00:09:01.300 --> 00:09:02.900]   I'm a lousy employee.
[00:09:02.900 --> 00:09:06.540]   I'm gonna just start going to some of my prospects
[00:09:06.540 --> 00:09:10.000]   that I had at my job and ask them to front the money
[00:09:10.000 --> 00:09:12.420]   that I needed to install some software
[00:09:12.420 --> 00:09:14.500]   and found this company, Architectural Lighting,
[00:09:14.500 --> 00:09:16.420]   who put up $500 for me.
[00:09:16.420 --> 00:09:19.620]   That allowed me to buy software and have 50% margins,
[00:09:19.620 --> 00:09:22.140]   and, you know, that's how I started my company.
[00:09:22.140 --> 00:09:23.820]   - But like by way of advice, would you say?
[00:09:23.820 --> 00:09:25.340]   I mean, it's a terrifying thing.
[00:09:25.340 --> 00:09:26.900]   - Yeah, I mean, you've gotta be in a position
[00:09:26.900 --> 00:09:27.880]   where you're confident.
[00:09:27.880 --> 00:09:29.900]   You know, I get emails and approached by people
[00:09:29.900 --> 00:09:32.780]   all the time, you know, what kind of business should I start
[00:09:32.780 --> 00:09:34.900]   that tells me you're not ready to start a business, right?
[00:09:34.900 --> 00:09:37.140]   Either you're prepared and you know it or you don't.
[00:09:37.140 --> 00:09:40.820]   You know, in the United States, with the American Dream,
[00:09:40.820 --> 00:09:44.900]   everybody kind of always looks at themselves and say,
[00:09:44.900 --> 00:09:47.420]   okay, you know, I have this idea, right?
[00:09:47.420 --> 00:09:49.740]   And then you go through this process of saying,
[00:09:49.740 --> 00:09:52.000]   okay, you know, you talk to your friends or family,
[00:09:52.000 --> 00:09:52.840]   what do you think?
[00:09:52.840 --> 00:09:55.000]   And then almost always, oh, it's a great idea, right?
[00:09:55.000 --> 00:09:57.460]   Then you go on Google and you say, oh my God,
[00:09:57.460 --> 00:09:59.860]   no one else is doing it without thinking, you know,
[00:09:59.860 --> 00:10:01.260]   10 companies have gone out of business
[00:10:01.260 --> 00:10:04.020]   trying the same thing, but okay, it's on Google.
[00:10:04.020 --> 00:10:06.300]   And then people stop, right?
[00:10:06.300 --> 00:10:08.940]   Because that next step means, okay,
[00:10:08.940 --> 00:10:11.500]   I have to change what I'm doing in my life.
[00:10:11.500 --> 00:10:14.140]   And that's not easy for 99% of the people.
[00:10:14.140 --> 00:10:15.900]   Some people look at that as an opportunity
[00:10:15.900 --> 00:10:17.220]   and get excited about it.
[00:10:17.220 --> 00:10:20.100]   Some people get terrified because it's,
[00:10:20.100 --> 00:10:24.140]   okay, maybe I'm comfortable, maybe I have responsibilities.
[00:10:24.140 --> 00:10:26.440]   And so whatever your circumstances are,
[00:10:26.440 --> 00:10:28.480]   if you want to take that next step,
[00:10:28.480 --> 00:10:30.900]   you have to be able to deal with the consequences
[00:10:30.900 --> 00:10:32.820]   of changing your circumstances.
[00:10:32.820 --> 00:10:34.940]   And that's the first thing, you know,
[00:10:34.940 --> 00:10:36.780]   do you save money so you have, you know,
[00:10:36.780 --> 00:10:38.740]   if you have a job, do you have a mortgage?
[00:10:38.740 --> 00:10:39.580]   Do you have a family?
[00:10:39.580 --> 00:10:41.580]   You've got to save money, you can't just walk.
[00:10:41.580 --> 00:10:43.140]   You know, I mean, they've got to eat
[00:10:43.140 --> 00:10:44.540]   and they've got to have shelter.
[00:10:44.540 --> 00:10:47.260]   But on the other side of the coin, if you've got nothing,
[00:10:47.260 --> 00:10:49.220]   it's the perfect time to start a business.
[00:10:49.220 --> 00:10:51.020]   - Yeah, desperation is a good catalyst
[00:10:51.020 --> 00:10:52.020]   for starting a business.
[00:10:52.020 --> 00:10:55.320]   But in many cases, the decision, as you're talking about,
[00:10:55.320 --> 00:10:57.620]   you're gonna have to make is to leave a job
[00:10:57.620 --> 00:11:00.580]   that's providing some degree of comfort already.
[00:11:00.580 --> 00:11:03.180]   So I suppose when you're sleeping on the floor
[00:11:03.180 --> 00:11:05.420]   and there's six guys, it's a little bit easier.
[00:11:05.420 --> 00:11:06.380]   - It's really easy, right?
[00:11:06.380 --> 00:11:08.540]   Particularly when you get fired and you don't have a job,
[00:11:08.540 --> 00:11:10.260]   you know, and you're looking at bartending at night
[00:11:10.260 --> 00:11:11.400]   to try to pay the bills.
[00:11:11.400 --> 00:11:15.900]   And so it wasn't hard for me, but to your point,
[00:11:15.900 --> 00:11:18.140]   it really comes down to preparation.
[00:11:18.140 --> 00:11:19.900]   You know, if it's important enough to you,
[00:11:19.900 --> 00:11:22.620]   you'll save the money, you'll give up, you know,
[00:11:22.620 --> 00:11:26.460]   whatever it is you need to give up to put the money aside.
[00:11:26.460 --> 00:11:30.100]   If you have obligations, you'll put in the work
[00:11:30.100 --> 00:11:32.660]   to learn as much as you can about that industry
[00:11:32.660 --> 00:11:35.460]   so that when you start your business, you're prepared.
[00:11:35.460 --> 00:11:38.540]   And you can always, you know, at night, on weekends,
[00:11:38.540 --> 00:11:41.260]   whenever you find time, lunch, start making the calls
[00:11:41.260 --> 00:11:43.620]   to find out if people will write you a check, you know,
[00:11:43.620 --> 00:11:46.500]   transfer you money to buy whatever it is you're selling.
[00:11:46.500 --> 00:11:47.900]   And by doing those things,
[00:11:47.900 --> 00:11:50.060]   you can put yourself in a position to succeed.
[00:11:50.060 --> 00:11:53.380]   It's where people just think, okay, you know, Geronimo,
[00:11:53.380 --> 00:11:55.100]   I'm leafing off the edge of a cliff
[00:11:55.100 --> 00:11:56.420]   and I'm starting a business.
[00:11:56.420 --> 00:11:57.420]   That's tough.
[00:11:57.420 --> 00:11:59.420]   - But sometimes that's like the way you do it though.
[00:11:59.420 --> 00:12:01.820]   - There's always examples of any situation or scenario.
[00:12:01.820 --> 00:12:02.740]   Right, right.
[00:12:02.740 --> 00:12:03.580]   But I mean-
[00:12:03.580 --> 00:12:04.980]   - Anecdotal evidence for everything.
[00:12:04.980 --> 00:12:06.940]   - Yeah, but if you're going into a new business,
[00:12:06.940 --> 00:12:07.900]   you're gonna have competition
[00:12:07.900 --> 00:12:10.060]   unless you're really, really, really, really, really lucky.
[00:12:10.060 --> 00:12:12.360]   And that competition is not gonna just say, okay,
[00:12:12.360 --> 00:12:14.420]   let Lex or Mark just kick our ass.
[00:12:14.420 --> 00:12:15.820]   And so you've gotta be prepared
[00:12:15.820 --> 00:12:18.580]   to how you're gonna deal with that competition.
[00:12:18.580 --> 00:12:21.300]   - What do you think that is about America
[00:12:21.300 --> 00:12:25.140]   that has so many people who have that dream
[00:12:25.140 --> 00:12:28.060]   and act on that dream of starting a business?
[00:12:28.060 --> 00:12:31.980]   - You know, I think we've just got a culture
[00:12:31.980 --> 00:12:35.100]   of consumption and more, you know?
[00:12:35.100 --> 00:12:39.900]   And to get more, you've got to, you know,
[00:12:39.900 --> 00:12:42.460]   creating a business gives you the greatest potential upside
[00:12:42.460 --> 00:12:44.420]   and the greatest leverage on your time.
[00:12:44.420 --> 00:12:47.700]   But it also creates the most risk.
[00:12:47.700 --> 00:12:49.260]   - So that capitalist machine,
[00:12:49.260 --> 00:12:50.300]   there's a lot of elements.
[00:12:50.300 --> 00:12:54.700]   By contrast, the respect for the law,
[00:12:54.700 --> 00:12:56.140]   like an entrepreneur can trust that
[00:12:56.140 --> 00:12:58.780]   if they pull it off, the law will protect them.
[00:12:58.780 --> 00:12:59.620]   There won't be a government.
[00:12:59.620 --> 00:13:01.620]   - Hopefully that's still the case, yeah.
[00:13:01.620 --> 00:13:04.460]   There's always, yeah, us versus other countries.
[00:13:04.460 --> 00:13:06.380]   Right, right, so us versus other countries.
[00:13:06.380 --> 00:13:08.940]   Like Joe Biden, of all people, said to me,
[00:13:08.940 --> 00:13:11.240]   it was at an entrepreneurship conference
[00:13:11.240 --> 00:13:14.060]   that when he was vice president, he had put together.
[00:13:14.060 --> 00:13:17.900]   And we had gone up there, a bunch of us from "Shark Tank"
[00:13:17.900 --> 00:13:20.840]   to talk to young entrepreneurs from around the world.
[00:13:20.840 --> 00:13:22.580]   And he said to me, "Mark, you know,
[00:13:22.580 --> 00:13:23.820]   the one thing that separates,
[00:13:23.820 --> 00:13:25.380]   I've been to every country around the world,
[00:13:25.380 --> 00:13:28.740]   "and the one thing that separates us is entrepreneurship.
[00:13:28.740 --> 00:13:31.300]   "We're the most entrepreneurial country in the world,
[00:13:31.300 --> 00:13:33.300]   "and there's no one else who's even close."
[00:13:33.300 --> 00:13:38.080]   And when you look at the origin of the biggest companies
[00:13:38.080 --> 00:13:39.860]   in the world, for the most part,
[00:13:39.860 --> 00:13:43.100]   there's an American origin story somewhere behind there.
[00:13:43.100 --> 00:13:47.220]   And I think that just gets perpetuated on itself.
[00:13:47.220 --> 00:13:49.640]   We see those Horatio Alger stories.
[00:13:49.640 --> 00:13:53.260]   We see examples of the Jeff Bezos of the world,
[00:13:53.260 --> 00:13:54.340]   the Steve Jobs of the world.
[00:13:54.340 --> 00:13:58.620]   And those are the types of people we want to copy.
[00:13:58.620 --> 00:14:00.040]   - Yeah, we want to be really careful
[00:14:00.040 --> 00:14:02.420]   and try to really figure out what that is,
[00:14:02.420 --> 00:14:04.540]   because we don't want to lose that.
[00:14:04.540 --> 00:14:05.380]   - For sure.
[00:14:05.380 --> 00:14:06.700]   - We want to protect the whatever, you know.
[00:14:06.700 --> 00:14:08.620]   And that's a lot of the discussions
[00:14:08.620 --> 00:14:10.500]   about what's the right way to do government,
[00:14:10.500 --> 00:14:11.780]   big government, small government,
[00:14:11.780 --> 00:14:14.460]   what's the right policies, but also culture,
[00:14:14.460 --> 00:14:15.380]   like who we celebrate.
[00:14:15.380 --> 00:14:17.420]   One of the things that troubles me
[00:14:17.420 --> 00:14:19.500]   is that we don't enough celebrate
[00:14:19.500 --> 00:14:22.620]   the entrepreneurs that take risks
[00:14:22.620 --> 00:14:24.180]   and the entrepreneurs that succeed.
[00:14:24.180 --> 00:14:25.260]   It seems like success,
[00:14:25.260 --> 00:14:27.340]   especially when it comes with wealth,
[00:14:27.340 --> 00:14:31.740]   is immediately matched with distrust and criticism
[00:14:31.740 --> 00:14:32.580]   and all that kind of stuff.
[00:14:32.580 --> 00:14:33.500]   - Yeah, it's changing for sure,
[00:14:33.500 --> 00:14:36.980]   because you can go back just 12 years, right?
[00:14:36.980 --> 00:14:41.620]   Traditional media dominated, let's just say, through 2012.
[00:14:41.620 --> 00:14:44.140]   That was the peak of linear television.
[00:14:44.140 --> 00:14:45.720]   Newspapers weren't as strong,
[00:14:45.720 --> 00:14:48.900]   but they still had some breadth and depth to them.
[00:14:48.900 --> 00:14:50.780]   And then social media comes along,
[00:14:50.780 --> 00:14:53.740]   and everybody gets to play in their own sandbox
[00:14:53.740 --> 00:14:57.100]   and share opinions with people who think just like them.
[00:14:57.100 --> 00:15:00.100]   And it also gives them the opportunity
[00:15:00.100 --> 00:15:02.820]   to amplify those feelings.
[00:15:02.820 --> 00:15:07.140]   And I think that's where celebrating entrepreneurs
[00:15:07.140 --> 00:15:09.420]   really started to subside some.
[00:15:09.420 --> 00:15:11.060]   There were always people who were progressive
[00:15:11.060 --> 00:15:12.700]   that were like, billionaires are bad,
[00:15:12.700 --> 00:15:15.580]   or millionaires are bad, depending on the time period.
[00:15:15.580 --> 00:15:19.600]   But you didn't really see it on an ongoing basis, right?
[00:15:19.600 --> 00:15:21.180]   It wasn't gonna be on the evening news.
[00:15:21.180 --> 00:15:24.900]   It wasn't going to be in the front page of the newspaper.
[00:15:24.900 --> 00:15:26.380]   It was going to be if you read a book
[00:15:26.380 --> 00:15:28.260]   and someone talked about it, or you read a magazine
[00:15:28.260 --> 00:15:31.100]   and there was an article talking about
[00:15:31.100 --> 00:15:32.780]   this progressive movement or that progressive movement,
[00:15:32.780 --> 00:15:36.820]   whatever it may be, or political parties.
[00:15:36.820 --> 00:15:41.820]   But now, all of that is front and center in social media.
[00:15:41.820 --> 00:15:43.060]   - And we're trying to figure it out,
[00:15:43.060 --> 00:15:45.380]   how we deal with the mobs of people
[00:15:45.380 --> 00:15:46.940]   and the virality of it all.
[00:15:46.940 --> 00:15:49.460]   I think we'll find our footing
[00:15:49.460 --> 00:15:51.180]   and start celebrating greatness again.
[00:15:51.180 --> 00:15:52.860]   - Well, I mean, that's the whole reason I do Shark Tank.
[00:15:52.860 --> 00:15:56.260]   - That's true, that show celebrates the entrepreneur.
[00:15:56.260 --> 00:15:58.260]   - It's the only place where every single minute
[00:15:58.260 --> 00:16:02.500]   of every single episode, we celebrate the American dream.
[00:16:02.500 --> 00:16:05.700]   And the reason I do it is we tell the entire country
[00:16:05.700 --> 00:16:07.740]   and it's shown around the world even.
[00:16:07.740 --> 00:16:10.380]   We're amazing advertising for the American dream
[00:16:10.380 --> 00:16:12.620]   in I don't even know how many countries.
[00:16:12.620 --> 00:16:15.260]   But every time somebody walks onto that carpet
[00:16:15.260 --> 00:16:18.220]   from Dubuque, Iowa, or Ketchum, Idaho,
[00:16:19.060 --> 00:16:21.460]   that sends a message to every kid who's watching,
[00:16:21.460 --> 00:16:23.980]   seven, eight, nine, 10, 12 year old kid,
[00:16:23.980 --> 00:16:27.460]   that if they can do it from Ketchum, Idaho, you can do it.
[00:16:27.460 --> 00:16:29.380]   If they can have this idea and get a deal
[00:16:29.380 --> 00:16:30.700]   or even present to the Sharks
[00:16:30.700 --> 00:16:33.340]   and have all of America see it, you can do it.
[00:16:33.340 --> 00:16:36.020]   And that, I mean, I'm proud of that.
[00:16:36.020 --> 00:16:39.740]   The 15 years of that, it's just been insane.
[00:16:39.740 --> 00:16:41.620]   Now, kids walk up to me and go,
[00:16:41.620 --> 00:16:44.660]   "Yeah, I started watching you when I was five or 10
[00:16:44.660 --> 00:16:45.700]   and I started a business
[00:16:45.700 --> 00:16:47.260]   'cause I learned about it from Shark Tank."
[00:16:47.260 --> 00:16:51.460]   And so, I think we're being, it celebrates it
[00:16:51.460 --> 00:16:54.780]   and we convey it and I don't think it's going away,
[00:16:54.780 --> 00:16:56.460]   but there are different battles
[00:16:56.460 --> 00:16:57.900]   we have to fight to support it.
[00:16:57.900 --> 00:16:59.780]   - Yeah, I love even when the business idea
[00:16:59.780 --> 00:17:04.780]   is obviously horrible, just the guts to step up.
[00:17:04.780 --> 00:17:05.620]   - To be there.
[00:17:05.620 --> 00:17:08.260]   - To believe in yourself, to really reach.
[00:17:08.260 --> 00:17:09.540]   I mean, that's what matters.
[00:17:09.540 --> 00:17:12.220]   I mean, 'cause like some of the best business ideas
[00:17:12.220 --> 00:17:17.180]   are probably maybe even you and Shark Tank will laugh at.
[00:17:17.180 --> 00:17:18.420]   - Oh, for sure.
[00:17:18.420 --> 00:17:20.220]   Without question, the good ones,
[00:17:20.220 --> 00:17:21.780]   we're not gonna recognize every good one
[00:17:21.780 --> 00:17:23.540]   and then sometimes we'll just motivate people
[00:17:23.540 --> 00:17:24.940]   to work even harder to get it done
[00:17:24.940 --> 00:17:26.340]   'cause of what we say to them.
[00:17:26.340 --> 00:17:28.020]   And that's fine too.
[00:17:28.020 --> 00:17:30.540]   There's been great success stories that we said no to.
[00:17:30.540 --> 00:17:32.580]   - What stands out as like a memorable business
[00:17:32.580 --> 00:17:35.300]   on you've been pitched on Shark Tank?
[00:17:35.300 --> 00:17:37.220]   What's the best one that stands out in memory?
[00:17:37.220 --> 00:17:38.340]   - There's no best one, right?
[00:17:38.340 --> 00:17:39.580]   They're all different.
[00:17:39.580 --> 00:17:41.380]   They're all best in their own way, I guess.
[00:17:41.380 --> 00:17:46.380]   There's stupid ones and we haven't had any world class
[00:17:47.340 --> 00:17:49.940]   or world changing earth shattering ones, right?
[00:17:49.940 --> 00:17:53.660]   Because those aren't gonna apply to Shark Tank.
[00:17:53.660 --> 00:17:55.660]   They don't need us, right?
[00:17:55.660 --> 00:17:57.740]   So we typically get businesses that need some help
[00:17:57.740 --> 00:17:59.500]   at some level or another.
[00:17:59.500 --> 00:18:01.580]   But there's ones I've passed that I wish like Spike Ball.
[00:18:01.580 --> 00:18:03.020]   Do you know what Spike Ball is?
[00:18:03.020 --> 00:18:06.060]   So it's just rebounding net that you can put on the beach
[00:18:06.060 --> 00:18:08.940]   and you have these yellow balls and you play a game of,
[00:18:08.940 --> 00:18:10.860]   it's just competitive game, but they're killing it.
[00:18:10.860 --> 00:18:14.500]   So if you go to beaches in New York or LA,
[00:18:14.500 --> 00:18:16.140]   you'll see kids playing it all the time.
[00:18:16.140 --> 00:18:20.420]   And it was a fun game that I wish I had done a deal with.
[00:18:20.420 --> 00:18:21.260]   And there's been others.
[00:18:21.260 --> 00:18:22.100]   - And you passed?
[00:18:22.100 --> 00:18:22.940]   - And I passed.
[00:18:22.940 --> 00:18:24.340]   They were getting some traction
[00:18:24.340 --> 00:18:26.820]   and they wanted to create leagues, Spike Ball leagues,
[00:18:26.820 --> 00:18:28.820]   and they wanted me to be the commissioner.
[00:18:28.820 --> 00:18:30.180]   And I don't wanna be a commissioner
[00:18:30.180 --> 00:18:32.540]   of a new Spike Ball league. (laughs)
[00:18:32.540 --> 00:18:35.200]   - So you have to kind of have this gut feeling
[00:18:35.200 --> 00:18:38.540]   of will this scale, will this click with people?
[00:18:38.540 --> 00:18:39.380]   - Of course, yeah.
[00:18:39.380 --> 00:18:40.260]   Can it be protected?
[00:18:40.260 --> 00:18:41.540]   Is it differentiated?
[00:18:41.540 --> 00:18:43.040]   Is it something that makes me think,
[00:18:43.040 --> 00:18:44.940]   why didn't I think of that?
[00:18:44.940 --> 00:18:48.780]   Or is it just a good, solid business
[00:18:48.780 --> 00:18:52.020]   that's gonna pay a return to the founder
[00:18:52.020 --> 00:18:53.640]   and may not be enough of a business
[00:18:53.640 --> 00:18:56.100]   to return to an investor?
[00:18:56.100 --> 00:19:00.260]   - Yeah, and I guess the question you're trying to see,
[00:19:00.260 --> 00:19:03.500]   will this scale, this promise,
[00:19:03.500 --> 00:19:06.540]   will the promise materialize into a big thing?
[00:19:06.540 --> 00:19:07.380]   - Well, see, I don't even care
[00:19:07.380 --> 00:19:09.540]   if it's gonna be a big thing, right?
[00:19:09.540 --> 00:19:11.620]   'Cause it's all relative to the entrepreneur.
[00:19:11.620 --> 00:19:13.820]   We had a 19-year-old from Pittsburgh, Laney,
[00:19:13.820 --> 00:19:16.380]   who came on with this simple sugar scrub.
[00:19:16.380 --> 00:19:19.700]   And there was nothing outrageously special about it.
[00:19:19.700 --> 00:19:22.100]   I didn't see it becoming a $100 million business.
[00:19:22.100 --> 00:19:25.020]   I thought it could become a two, three, $5 million business
[00:19:25.020 --> 00:19:26.500]   that paid the bills for her.
[00:19:26.500 --> 00:19:27.840]   And that was good enough.
[00:19:27.840 --> 00:19:31.580]   And six months after the show aired, she called me up.
[00:19:31.580 --> 00:19:34.720]   She goes, "Mark, I've got a million dollars in the bank.
[00:19:34.720 --> 00:19:36.060]   "What am I gonna do?"
[00:19:36.060 --> 00:19:37.320]   I'm like, "Enjoy it.
[00:19:37.320 --> 00:19:40.940]   "Put aside money for your taxes and go back to work."
[00:19:40.940 --> 00:19:42.660]   And so it doesn't have to be a huge business.
[00:19:42.660 --> 00:19:45.860]   It's just gotta be one that makes the entrepreneur happy.
[00:19:45.860 --> 00:19:47.740]   - But then there's the valuation piece.
[00:19:47.740 --> 00:19:48.700]   - Right.
[00:19:48.700 --> 00:19:51.100]   - Do a lot of the entrepreneurs overvalue business?
[00:19:51.100 --> 00:19:52.100]   - Yeah, of course.
[00:19:52.100 --> 00:19:54.500]   Yeah, I mean, that's the nature of it, right?
[00:19:54.500 --> 00:19:57.020]   I mean, and that's really where the biggest conflicts
[00:19:57.020 --> 00:19:58.180]   in "Shark Tank" happen.
[00:19:58.180 --> 00:19:59.620]   That's in the valuation.
[00:19:59.620 --> 00:20:02.420]   They think this is the best business ever.
[00:20:02.420 --> 00:20:06.480]   We had one lady, a couple that came on,
[00:20:06.480 --> 00:20:10.500]   and they had this scraper for cat's tongues, right?
[00:20:10.500 --> 00:20:11.820]   - Nice. - Bizarre.
[00:20:11.820 --> 00:20:14.060]   The most bizarre pitch ever.
[00:20:14.060 --> 00:20:14.900]   - I love it.
[00:20:14.900 --> 00:20:17.260]   - You know, and they had this insane valuation,
[00:20:17.260 --> 00:20:19.620]   and it was on because it was corny and fun TV,
[00:20:19.620 --> 00:20:20.940]   not because it was a good business.
[00:20:20.940 --> 00:20:21.780]   - Oh, really?
[00:20:21.780 --> 00:20:22.600]   Okay.
[00:20:22.600 --> 00:20:23.440]   You didn't see the potential.
[00:20:23.440 --> 00:20:24.280]   - No.
[00:20:24.280 --> 00:20:25.860]   Yeah, none.
[00:20:25.860 --> 00:20:27.140]   - There's a lot of cats in the world, Mark.
[00:20:27.140 --> 00:20:28.180]   - Yes, there are.
[00:20:28.180 --> 00:20:29.980]   They'll go do very well without me.
[00:20:29.980 --> 00:20:33.580]   - So how do you determine the value of a business,
[00:20:33.580 --> 00:20:35.540]   whether it's on "Shark Tank" or just in general?
[00:20:35.540 --> 00:20:37.200]   - It's actually really easy, right?
[00:20:37.200 --> 00:20:39.620]   So if you take, just to use an example,
[00:20:39.620 --> 00:20:42.260]   a business that's valued at $1 million,
[00:20:42.260 --> 00:20:47.260]   and I want to buy 10% of that company for $100,000,
[00:20:47.260 --> 00:20:51.020]   then in order for me to get my money back,
[00:20:51.020 --> 00:20:53.780]   they've gotta be able to generate $100,000
[00:20:53.780 --> 00:20:57.320]   in after-tax cash flow that they're able to distribute.
[00:20:57.320 --> 00:20:59.500]   Can they do it or can they not, right?
[00:20:59.500 --> 00:21:01.580]   And if it's a $2 million valuation,
[00:21:01.580 --> 00:21:03.220]   whatever the valuation is,
[00:21:03.220 --> 00:21:06.660]   that's how much after-tax cash they have to generate
[00:21:06.660 --> 00:21:09.020]   to return that money to investors.
[00:21:09.020 --> 00:21:12.460]   Or the other option is, do I see this business
[00:21:12.460 --> 00:21:14.300]   potentially having an exit, right?
[00:21:14.300 --> 00:21:15.860]   Do they have some unique technology
[00:21:15.860 --> 00:21:19.060]   or do they have something specific about them
[00:21:19.060 --> 00:21:21.260]   that some other company would want to acquire?
[00:21:21.260 --> 00:21:23.440]   Then the cash flow isn't as,
[00:21:23.440 --> 00:21:26.060]   I don't want to say important,
[00:21:26.060 --> 00:21:28.700]   but isn't going to guide the valuation.
[00:21:28.700 --> 00:21:31.420]   - And how do you know if a company's gonna be acquired?
[00:21:31.420 --> 00:21:33.020]   So it's the technology, like the patents,
[00:21:33.020 --> 00:21:34.140]   but also the team?
[00:21:34.140 --> 00:21:35.660]   - Yeah, it could be any of the above, right?
[00:21:35.660 --> 00:21:38.920]   It could be a super products company
[00:21:38.920 --> 00:21:41.980]   that I think is gonna take off.
[00:21:41.980 --> 00:21:43.980]   - And how do you know if they can generate the money?
[00:21:43.980 --> 00:21:46.340]   You made it sound easy, you know?
[00:21:46.340 --> 00:21:49.260]   - Yeah, I mean, can the person sell, you know?
[00:21:49.260 --> 00:21:50.700]   And if not them, can I do it?
[00:21:50.700 --> 00:21:52.940]   Or someone on my team do it for them?
[00:21:52.940 --> 00:21:54.220]   - So you're looking at the person?
[00:21:54.220 --> 00:21:55.500]   - Yeah, for sure, yeah.
[00:21:55.500 --> 00:21:57.140]   That's where Barbara Corker is the best.
[00:21:57.140 --> 00:21:59.820]   She can look at a person and hear them talk for 20 minutes
[00:21:59.820 --> 00:22:02.660]   and know, can that person do the job and do the work?
[00:22:02.660 --> 00:22:05.560]   - Can you tell if they're full of shit or not?
[00:22:05.560 --> 00:22:07.180]   So one of the things with entrepreneurs,
[00:22:07.180 --> 00:22:09.340]   they're kind of, like we said, overvaluing,
[00:22:09.340 --> 00:22:11.780]   so they're maybe overselling themselves,
[00:22:11.780 --> 00:22:14.860]   but also they might be full of shit
[00:22:14.860 --> 00:22:16.580]   in terms of their understanding of the market
[00:22:16.580 --> 00:22:19.540]   or exaggerating what they're thinking to do,
[00:22:19.540 --> 00:22:20.380]   all that kind of stuff.
[00:22:20.380 --> 00:22:21.200]   Can you see through that?
[00:22:21.200 --> 00:22:23.540]   - Yeah, for sure, just by asking questions.
[00:22:23.540 --> 00:22:28.540]   So if they are delusional at some level
[00:22:28.540 --> 00:22:30.660]   or misleading at another level,
[00:22:30.660 --> 00:22:32.700]   I'm gonna call them on it.
[00:22:32.700 --> 00:22:34.420]   So you get people trying to sell supplements
[00:22:34.420 --> 00:22:36.680]   that come on there and it's a cure for cancer
[00:22:36.680 --> 00:22:37.920]   or whatever it may be,
[00:22:37.920 --> 00:22:42.920]   or there's this latest fad that increases your core strength
[00:22:42.920 --> 00:22:46.140]   without doing any exercises, shit like that,
[00:22:46.140 --> 00:22:48.320]   I'm just gonna bounce, I'm gonna pound on them, right?
[00:22:48.320 --> 00:22:49.240]   - See, I still love that.
[00:22:49.240 --> 00:22:51.840]   I still love the trying, just trying.
[00:22:51.840 --> 00:22:52.840]   - You know, give them credit, right?
[00:22:52.840 --> 00:22:54.720]   Because they know all of America is going to see it
[00:22:54.720 --> 00:22:56.840]   and they've deluded themselves to believe
[00:22:56.840 --> 00:22:58.680]   this story so strongly.
[00:22:58.680 --> 00:23:00.120]   - I mean, there's a delusional aspect
[00:23:00.120 --> 00:23:01.600]   to entrepreneurship, right?
[00:23:01.600 --> 00:23:02.880]   Like you just--
[00:23:02.880 --> 00:23:05.460]   - See, that's a great question.
[00:23:05.460 --> 00:23:10.480]   Do you have to be ambitious and set aside reality
[00:23:10.480 --> 00:23:13.000]   at some level to think that you can create a company
[00:23:13.000 --> 00:23:17.040]   that could be worth 10, 100, a billion dollars, right?
[00:23:17.040 --> 00:23:17.880]   Yeah, at some level.
[00:23:17.880 --> 00:23:19.820]   'Cause you don't know, it's all uncertainty.
[00:23:19.820 --> 00:23:22.960]   But I think if you're delusional, that works against you.
[00:23:22.960 --> 00:23:26.660]   Because everything's grounded in reality.
[00:23:26.660 --> 00:23:30.300]   You've got to execute, you've got to produce.
[00:23:30.300 --> 00:23:32.060]   You can have a vision, right?
[00:23:32.060 --> 00:23:33.980]   And you can say, this is where I want to get to
[00:23:33.980 --> 00:23:36.940]   and that's my mission or this is my driving principle.
[00:23:36.940 --> 00:23:38.640]   But you still got to execute on the business plan
[00:23:38.640 --> 00:23:40.780]   and that's where most people fail.
[00:23:40.780 --> 00:23:42.940]   - Yeah, you have to be kind of two-brained, I guess.
[00:23:42.940 --> 00:23:44.540]   You have to be able to dip into reality
[00:23:44.540 --> 00:23:47.540]   when you're thinking about the specifics of the product,
[00:23:47.540 --> 00:23:50.460]   how to design things, the first principles,
[00:23:50.460 --> 00:23:51.980]   the basics of how to build the thing,
[00:23:51.980 --> 00:23:53.660]   how much it's gonna cost, all of that.
[00:23:53.660 --> 00:23:55.440]   - Yeah, I mean, 'cause if you can't do the basics,
[00:23:55.440 --> 00:23:56.760]   you're not gonna be able to do the bigger things.
[00:23:56.760 --> 00:23:58.860]   And at the same time, you've got to be able...
[00:23:58.860 --> 00:24:00.260]   One of the things that entrepreneurs do
[00:24:00.260 --> 00:24:03.620]   that I always try to remind any that I work with on
[00:24:03.620 --> 00:24:05.740]   is we all tend to lie to ourselves.
[00:24:05.740 --> 00:24:08.580]   Our product is bigger, faster, cheaper, this or that,
[00:24:08.580 --> 00:24:13.020]   as if that is a finite situation
[00:24:13.020 --> 00:24:14.820]   that's never gonna change, right?
[00:24:14.820 --> 00:24:16.660]   And there's always somebody,
[00:24:16.660 --> 00:24:18.960]   I call them leapfrog businesses.
[00:24:18.960 --> 00:24:21.020]   Whoever's competing against you,
[00:24:21.020 --> 00:24:24.300]   if you do A, B or C, they're gonna try to do C, D and E,
[00:24:24.300 --> 00:24:26.580]   right, and you better be prepared for that to come
[00:24:26.580 --> 00:24:28.740]   because otherwise they're out of business too.
[00:24:28.740 --> 00:24:30.260]   So you're never in a vacuum.
[00:24:30.260 --> 00:24:32.500]   You're always competing against sometimes
[00:24:32.500 --> 00:24:34.020]   an unlimited number of entrepreneurs
[00:24:34.020 --> 00:24:35.420]   that you don't even know exist
[00:24:35.420 --> 00:24:36.980]   who are trying to kick your ass.
[00:24:36.980 --> 00:24:38.660]   - And the tricky part of all this too
[00:24:38.660 --> 00:24:42.380]   is you might need to frequently pivot,
[00:24:42.380 --> 00:24:43.860]   especially in the beginning.
[00:24:43.860 --> 00:24:45.100]   - Hopefully not.
[00:24:45.100 --> 00:24:47.540]   - So you think like in the beginning,
[00:24:47.540 --> 00:24:50.020]   the product you have should be the thing
[00:24:50.020 --> 00:24:51.340]   that carries you a long time.
[00:24:51.340 --> 00:24:52.540]   - Yeah, because I mean,
[00:24:52.540 --> 00:24:55.060]   that's your riskiest point in time, right?
[00:24:55.060 --> 00:24:57.740]   And so if you've done your homework,
[00:24:57.740 --> 00:24:59.380]   which includes going out there
[00:24:59.380 --> 00:25:01.740]   and testing product market fit,
[00:25:01.740 --> 00:25:03.820]   you should have confidence
[00:25:03.820 --> 00:25:04.940]   that you're gonna be able to sell it.
[00:25:04.940 --> 00:25:07.060]   Now, if you didn't do your homework
[00:25:07.060 --> 00:25:11.100]   and you go out there and you sell whatever it is,
[00:25:11.100 --> 00:25:14.580]   and you've raised money or whatever,
[00:25:14.580 --> 00:25:17.420]   just to pivot, you've already shown
[00:25:17.420 --> 00:25:19.780]   that you haven't been able to read the market.
[00:25:19.780 --> 00:25:22.020]   And so it's not that pivots can't work
[00:25:22.020 --> 00:25:24.100]   and always don't work, they can,
[00:25:24.100 --> 00:25:25.540]   but more often than not, they don't.
[00:25:25.540 --> 00:25:26.500]   You pivot for a reason,
[00:25:26.500 --> 00:25:28.100]   it's because you made a huge mistake.
[00:25:28.100 --> 00:25:30.780]   - Well, I also mean like the micro pivots,
[00:25:30.780 --> 00:25:32.980]   which is like iterative development of the thing.
[00:25:32.980 --> 00:25:34.300]   - Oh, yeah, oh, yeah, that's not pivot,
[00:25:34.300 --> 00:25:36.260]   yeah, just iterations, yeah.
[00:25:36.260 --> 00:25:38.220]   Entrepreneurship, having any business
[00:25:38.220 --> 00:25:41.100]   is just continuous iteration, continuous.
[00:25:41.100 --> 00:25:44.620]   Your product, your sales pitch, your advertising,
[00:25:44.620 --> 00:25:45.860]   introducing new technology,
[00:25:45.860 --> 00:25:47.940]   how do you use AI or not use AI?
[00:25:47.940 --> 00:25:48.780]   Where do you use it?
[00:25:48.780 --> 00:25:50.500]   What person's the right person?
[00:25:50.500 --> 00:25:53.740]   There's just a million touch points
[00:25:53.740 --> 00:25:57.140]   that you're always reevaluating in real time
[00:25:57.140 --> 00:26:00.580]   that you have to be agile and adapt and change.
[00:26:00.580 --> 00:26:02.860]   - But especially in software,
[00:26:02.860 --> 00:26:05.460]   it feels like business model can evolve really quickly too,
[00:26:05.460 --> 00:26:06.940]   like how are you gonna make money on this?
[00:26:06.940 --> 00:26:08.780]   - Yes, with software for sure,
[00:26:08.780 --> 00:26:10.820]   because anything digital,
[00:26:10.820 --> 00:26:13.060]   because it can change in a millisecond.
[00:26:13.060 --> 00:26:16.540]   - Speaking of which, how did you make your first billion?
[00:26:16.540 --> 00:26:19.260]   - So my partner, Todd Wagner and I
[00:26:19.260 --> 00:26:22.960]   would get together for lunches,
[00:26:22.960 --> 00:26:25.060]   and we were at California Pizza Kitchen
[00:26:25.060 --> 00:26:27.540]   in Preston Hollow in Dallas,
[00:26:27.540 --> 00:26:32.540]   and he was talking about how we could
[00:26:32.540 --> 00:26:34.420]   use this new thing called the internet,
[00:26:34.420 --> 00:26:36.900]   this is late '94, early '95,
[00:26:36.900 --> 00:26:40.020]   to be able to listen to Indiana University basketball games,
[00:26:40.020 --> 00:26:41.980]   'cause that's where we went to school.
[00:26:41.980 --> 00:26:45.500]   And he was like, look, when we would listen to games,
[00:26:45.500 --> 00:26:47.540]   we would have somebody in Bloomington, Indiana
[00:26:47.540 --> 00:26:49.380]   have a speakerphone next to a radio,
[00:26:49.380 --> 00:26:51.380]   and then we would have a speakerphone in Dallas,
[00:26:51.380 --> 00:26:53.520]   and a six-pack or 12-pack of beer,
[00:26:53.520 --> 00:26:55.300]   and we'd sit around listening to the game,
[00:26:55.300 --> 00:26:57.460]   because there was no other way to listen to it.
[00:26:57.460 --> 00:27:00.260]   So I was like, okay, my first company, MicroSolutions,
[00:27:00.260 --> 00:27:02.980]   I'd written software, done network integration,
[00:27:02.980 --> 00:27:05.780]   and so I was comfortable digging into it.
[00:27:05.780 --> 00:27:08.740]   And so I was like, okay, let's give it a try.
[00:27:08.740 --> 00:27:11.200]   So we started this company called AudioNet,
[00:27:11.200 --> 00:27:14.220]   and effectively became the first
[00:27:14.220 --> 00:27:17.220]   streaming content company on the internet.
[00:27:17.220 --> 00:27:20.620]   And we were like, okay, we're not sure
[00:27:20.620 --> 00:27:22.260]   how we're gonna make this work,
[00:27:22.260 --> 00:27:23.940]   but we were able to make it work,
[00:27:23.940 --> 00:27:26.480]   and we started going to radio stations and TV stations
[00:27:26.480 --> 00:27:29.020]   and music labels and everything,
[00:27:29.020 --> 00:27:32.060]   and evolved AudioNet.com,
[00:27:32.060 --> 00:27:33.820]   which was only audio at the beginning,
[00:27:33.820 --> 00:27:38.820]   to Broadcast.com in 1998, which was audio and video,
[00:27:38.820 --> 00:27:42.220]   and became the largest multimedia site on the internet,
[00:27:42.220 --> 00:27:45.700]   took it public in July of 1998.
[00:27:45.700 --> 00:27:47.860]   It had the largest first-day jump
[00:27:47.860 --> 00:27:49.900]   in the history of the stock market at the time.
[00:27:49.900 --> 00:27:52.020]   And then a year later, we sold it to Yahoo
[00:27:52.020 --> 00:27:55.540]   for $5.7 billion in Yahoo stock,
[00:27:55.540 --> 00:28:00.340]   and I owned right around 30% of the company, give or take.
[00:28:00.340 --> 00:28:02.460]   And so after taxes, that's what got me there.
[00:28:02.460 --> 00:28:03.620]   - Well, there's a lot of questions there.
[00:28:03.620 --> 00:28:05.100]   So the technical challenge of that,
[00:28:05.100 --> 00:28:09.660]   you're making it sound easy, but you wrote code,
[00:28:09.660 --> 00:28:12.380]   but still, in the early days of the internet,
[00:28:12.380 --> 00:28:16.340]   how do you figure out how to create this kind of product
[00:28:16.340 --> 00:28:18.900]   of just audio at first and then video at first?
[00:28:18.900 --> 00:28:22.060]   - A lot of iterations, right, like you talked about.
[00:28:22.060 --> 00:28:23.820]   We started in the second bedroom of my house,
[00:28:23.820 --> 00:28:24.860]   set up a server.
[00:28:24.860 --> 00:28:28.340]   I got an ISDN line, which was a 128K line,
[00:28:28.340 --> 00:28:32.980]   and set up, downloaded Netscape server,
[00:28:32.980 --> 00:28:36.580]   and then started using different file formats
[00:28:36.580 --> 00:28:38.540]   that were progressive loading,
[00:28:38.540 --> 00:28:41.580]   and allowing people to connect to the server
[00:28:41.580 --> 00:28:43.180]   and do a progressive download,
[00:28:43.180 --> 00:28:45.660]   so that the audio, you can listen to the audio
[00:28:45.660 --> 00:28:47.380]   while it was downloading onto your PC.
[00:28:47.380 --> 00:28:48.580]   - Yeah, was it super choppy?
[00:28:48.580 --> 00:28:49.420]   So you were trying to figure out how to do it.
[00:28:49.420 --> 00:28:50.260]   - Oh, yeah, for sure, for sure.
[00:28:50.260 --> 00:28:52.540]   It would buffer, it was, yeah, it wasn't good,
[00:28:52.540 --> 00:28:53.380]   but it was a start.
[00:28:53.380 --> 00:28:55.380]   - But it was good enough 'cause it's the first kind of--
[00:28:55.380 --> 00:28:57.340]   - Yeah, because there was no other competition, right?
[00:28:57.340 --> 00:28:58.700]   There was nobody else doing it.
[00:28:58.700 --> 00:29:00.540]   And so it was like, okay, I can get access
[00:29:00.540 --> 00:29:01.540]   to this, this, or this.
[00:29:01.540 --> 00:29:03.860]   And then there were some third-party software companies,
[00:29:03.860 --> 00:29:06.780]   Zing and Progressive Networks and others,
[00:29:06.780 --> 00:29:09.020]   that took it a little bit further.
[00:29:09.020 --> 00:29:10.980]   So we partnered with them,
[00:29:10.980 --> 00:29:14.180]   and I started going to local radio stations
[00:29:14.180 --> 00:29:18.740]   where literally we would set up a server right next to it.
[00:29:18.740 --> 00:29:23.740]   I had a $49 radio, the highest FM radio that I could find.
[00:29:23.740 --> 00:29:27.740]   And we take the output of the audio signal from the radio
[00:29:27.740 --> 00:29:31.300]   with these two analog cables, plug it into the server,
[00:29:31.300 --> 00:29:35.580]   encode it, and make it available from audionet.com.
[00:29:35.580 --> 00:29:37.820]   Then I would go on UUNet bulletin boards.
[00:29:37.820 --> 00:29:39.300]   I would go on CompuServe.
[00:29:39.300 --> 00:29:40.860]   I would go on Prodigy.
[00:29:40.860 --> 00:29:42.460]   I would go on AOL.
[00:29:42.460 --> 00:29:44.340]   I'd go wherever I could find bodies.
[00:29:44.340 --> 00:29:47.260]   And I'd say, okay, we've got this radio station,
[00:29:47.260 --> 00:29:50.060]   KLIF in Dallas, it's got Dallas sports
[00:29:50.060 --> 00:29:52.980]   and Dallas news and politics.
[00:29:52.980 --> 00:29:56.500]   And if you're in an office or you're outside of Dallas,
[00:29:56.500 --> 00:29:58.580]   connect to audionet.com.
[00:29:58.580 --> 00:30:01.580]   And now you can listen to these things on demand.
[00:30:01.580 --> 00:30:03.060]   And that's how we started.
[00:30:03.060 --> 00:30:05.340]   And it started with one radio station,
[00:30:05.340 --> 00:30:06.980]   and then it was five, then it was 10,
[00:30:06.980 --> 00:30:08.380]   then it was video content.
[00:30:08.380 --> 00:30:10.180]   Then the laws were different then,
[00:30:10.180 --> 00:30:13.820]   so we could literally go out and buy CDs and host them
[00:30:13.820 --> 00:30:16.020]   and just let people listen to whatever music.
[00:30:16.020 --> 00:30:21.060]   And we went from 10 users a day to 100 to 1,000
[00:30:21.060 --> 00:30:23.260]   to hundreds of thousands to a million
[00:30:23.260 --> 00:30:25.060]   over those next four years.
[00:30:25.060 --> 00:30:26.300]   - How did you find the users?
[00:30:26.300 --> 00:30:27.140]   Is it word of mouth?
[00:30:27.140 --> 00:30:27.980]   - Word of mouth.
[00:30:27.980 --> 00:30:28.800]   - Just word of mouth.
[00:30:28.800 --> 00:30:29.820]   - Didn't spend a penny on advertising.
[00:30:29.820 --> 00:30:31.140]   - So the thing you were focusing on
[00:30:31.140 --> 00:30:32.500]   is getting the radio stations and all that.
[00:30:32.500 --> 00:30:34.740]   - Well, radio and TV, anything, any content at all.
[00:30:34.740 --> 00:30:37.500]   - To pick up the phone, how'd you--
[00:30:37.500 --> 00:30:39.820]   - Wherever I could, everything that was public domain,
[00:30:39.820 --> 00:30:42.300]   I'd go out and buy a video or a cassette,
[00:30:42.300 --> 00:30:44.220]   whatever it was, you know?
[00:30:44.220 --> 00:30:45.820]   And this was before the DMs,
[00:30:45.820 --> 00:30:48.980]   the Digital Minimum Copyright Act of '90,
[00:30:48.980 --> 00:30:49.820]   whenever it kicked in.
[00:30:49.820 --> 00:30:52.460]   So literally anything that was audio,
[00:30:52.460 --> 00:30:55.020]   we would put online so people could listen to it.
[00:30:55.020 --> 00:30:57.360]   And if you think about somebody at work,
[00:30:57.360 --> 00:30:58.740]   they didn't have a radio most likely,
[00:30:58.740 --> 00:30:59.940]   and if you did, you couldn't get reception.
[00:30:59.940 --> 00:31:03.060]   Definitely didn't have a TV, but you had a PC,
[00:31:03.060 --> 00:31:05.380]   and you had bandwidth available to you,
[00:31:05.380 --> 00:31:08.100]   and the companies weren't up on firewalls
[00:31:08.100 --> 00:31:09.340]   or anything at that point in time.
[00:31:09.340 --> 00:31:12.620]   So our in-office listening during the day
[00:31:12.620 --> 00:31:16.020]   what just exploded because whoever's sitting next to you,
[00:31:16.020 --> 00:31:17.540]   what are you listening to, right?
[00:31:17.540 --> 00:31:18.820]   And that was the start of it.
[00:31:18.820 --> 00:31:23.100]   And then in early '98, we started adding video
[00:31:23.100 --> 00:31:24.180]   and just other things,
[00:31:24.180 --> 00:31:26.900]   and we had ended up with thousands of servers.
[00:31:26.900 --> 00:31:28.980]   There was no cloud back then,
[00:31:28.980 --> 00:31:31.380]   and just pulling together all those pieces to make it work.
[00:31:31.380 --> 00:31:32.820]   But where we really made our money
[00:31:32.820 --> 00:31:37.820]   was by taking that network that we had built
[00:31:38.260 --> 00:31:40.320]   and then going to corporations and saying,
[00:31:40.320 --> 00:31:44.900]   look, it's 1996, '97, '98,
[00:31:44.900 --> 00:31:47.980]   and to communicate with your worldwide employees,
[00:31:47.980 --> 00:31:51.780]   what they would do is they would go to an auditorium
[00:31:51.780 --> 00:31:53.540]   that had a satellite uplink,
[00:31:53.540 --> 00:31:56.900]   and then they would have people go to theaters
[00:31:56.900 --> 00:32:00.820]   or ballrooms and hotels that had satellite downlinks,
[00:32:00.820 --> 00:32:02.180]   and they would broadcast
[00:32:02.180 --> 00:32:04.020]   the product introductions, whatever.
[00:32:04.020 --> 00:32:05.060]   And so we said to them,
[00:32:05.060 --> 00:32:06.380]   look, you're paying millions of dollars
[00:32:06.380 --> 00:32:07.540]   to reach all your employees.
[00:32:07.540 --> 00:32:10.980]   When you can do it, pay us a half a million dollars,
[00:32:10.980 --> 00:32:13.420]   and we'll do it just on their PCs at work.
[00:32:13.420 --> 00:32:17.420]   So we did, when Intel announced the P90 PC,
[00:32:17.420 --> 00:32:20.660]   we charged them $2 million or whatever to do that.
[00:32:20.660 --> 00:32:23.140]   When Motorola announced a new phone or a new product,
[00:32:23.140 --> 00:32:24.140]   we would charge them.
[00:32:24.140 --> 00:32:25.980]   And so we used the consumer side
[00:32:25.980 --> 00:32:29.500]   to do a proof of concept for the network,
[00:32:29.500 --> 00:32:32.380]   and then we would take that knowledge
[00:32:32.380 --> 00:32:33.460]   and go to corporations,
[00:32:33.460 --> 00:32:34.860]   and that's how we made our revenue.
[00:32:34.860 --> 00:32:36.860]   - And there was some selling there with the corporations.
[00:32:36.860 --> 00:32:37.700]   - Yeah, a lot of selling there,
[00:32:37.700 --> 00:32:39.380]   but we were saving them so much money,
[00:32:39.380 --> 00:32:40.740]   and they were technology companies.
[00:32:40.740 --> 00:32:43.300]   They wanted to be perceived as being leading edge,
[00:32:43.300 --> 00:32:44.940]   and so it was win-win.
[00:32:44.940 --> 00:32:47.740]   - How much technical savvy was required?
[00:32:47.740 --> 00:32:49.260]   You said a bunch of servers.
[00:32:49.260 --> 00:32:51.220]   Like at which point do you get more engineers?
[00:32:51.220 --> 00:32:54.540]   How much did you understand could do yourself?
[00:32:54.540 --> 00:32:58.860]   And then also, once you can't do it all yourself,
[00:32:58.860 --> 00:33:00.500]   how much technical savvy is required
[00:33:00.500 --> 00:33:02.080]   to understand enough to hire the right people
[00:33:02.080 --> 00:33:03.500]   to keep building this innovation?
[00:33:03.500 --> 00:33:04.820]   - I did all the technology,
[00:33:04.820 --> 00:33:07.100]   and then we hired engineer after engineer
[00:33:07.100 --> 00:33:09.060]   after engineer to implement it.
[00:33:09.060 --> 00:33:10.340]   And so-- - Wow.
[00:33:10.340 --> 00:33:13.500]   - Yeah, from putting together a multicast network
[00:33:13.500 --> 00:33:17.700]   to software to just all these different things.
[00:33:17.700 --> 00:33:18.900]   - Was this like a scary thing?
[00:33:18.900 --> 00:33:20.680]   - It was terrifying, right?
[00:33:20.680 --> 00:33:23.540]   Because as we were growing, trying to keep up the scale,
[00:33:23.540 --> 00:33:26.420]   and literally we're buying off-the-shelf PCs,
[00:33:26.420 --> 00:33:29.820]   and then server cards as the technology advanced,
[00:33:29.820 --> 00:33:32.100]   and hard drives, and things would fail,
[00:33:32.100 --> 00:33:33.980]   and we would have to, you know,
[00:33:33.980 --> 00:33:35.460]   we didn't have machine learning back then
[00:33:35.460 --> 00:33:40.160]   to do an analysis of how to distribute server resources.
[00:33:40.160 --> 00:33:45.160]   So, like there was a time when Bill Clinton
[00:33:45.160 --> 00:33:48.300]   and all the Monica Lewinsky stuff happened,
[00:33:48.300 --> 00:33:53.140]   they released the audio of their interviews of him
[00:33:53.140 --> 00:33:54.700]   or something like that, right?
[00:33:54.700 --> 00:33:58.220]   And we literally, I knew at that point in time
[00:33:58.220 --> 00:34:00.140]   when that was released, everybody at work
[00:34:00.140 --> 00:34:01.860]   was gonna wanna listen to it, right?
[00:34:01.860 --> 00:34:03.500]   So, we had to take down servers
[00:34:03.500 --> 00:34:06.820]   that were doing Chicago Cubs baseball, right?
[00:34:06.820 --> 00:34:09.020]   You know, and just make all these on-the-fly decisions
[00:34:09.020 --> 00:34:10.780]   because there was no, we didn't have the tools
[00:34:10.780 --> 00:34:12.700]   to analyze or be predictive.
[00:34:12.700 --> 00:34:16.380]   But yeah, it was all technology-driven and marketing.
[00:34:16.380 --> 00:34:20.220]   - The acquisition by Yahoo, can you tell the story of that?
[00:34:20.220 --> 00:34:24.300]   But also in the broader context of this internet bubble.
[00:34:24.300 --> 00:34:27.620]   This is a fascinating part of human history.
[00:34:27.620 --> 00:34:30.020]   - So, on the acquisition side,
[00:34:30.020 --> 00:34:31.860]   we were the largest media site on the internet
[00:34:31.860 --> 00:34:34.140]   and it wasn't close, there was nobody close.
[00:34:34.140 --> 00:34:36.380]   We were YouTube and relatively speaking,
[00:34:36.380 --> 00:34:39.420]   we would be 10X YouTube relative to the competition
[00:34:39.420 --> 00:34:40.860]   'cause there was nobody there.
[00:34:40.860 --> 00:34:45.300]   And so, it became obvious to Yahoo, AOL and others
[00:34:45.300 --> 00:34:47.500]   that they needed a multimedia component.
[00:34:47.500 --> 00:34:50.820]   And we had the infrastructure, sales, all that stuff.
[00:34:50.820 --> 00:34:55.820]   And so, Yahoo, when we went public in '98,
[00:34:55.820 --> 00:34:58.140]   or right before I think it was,
[00:34:58.140 --> 00:35:00.780]   they made an investment of like $2 million
[00:35:00.780 --> 00:35:02.980]   which gave us a connection to them.
[00:35:02.980 --> 00:35:05.460]   And then after we went public,
[00:35:05.460 --> 00:35:07.820]   they decided they needed to have multimedia.
[00:35:07.820 --> 00:35:12.180]   And so, in April of '99, we made a deal
[00:35:12.180 --> 00:35:16.260]   and then July of 2000 is when it closed.
[00:35:16.260 --> 00:35:21.220]   - And can you explain to me the trickiness
[00:35:21.220 --> 00:35:23.020]   of what you did after that?
[00:35:23.020 --> 00:35:25.220]   - Oh, the caller?
[00:35:25.220 --> 00:35:26.060]   - Yeah.
[00:35:26.060 --> 00:35:27.820]   - So, when we sold to Yahoo,
[00:35:27.820 --> 00:35:31.500]   we sold for $5.7 billion in stock, not cash.
[00:35:31.500 --> 00:35:36.500]   And so, I looked at, after microsolutions,
[00:35:36.500 --> 00:35:40.540]   when I sold that, I took that money
[00:35:40.540 --> 00:35:42.100]   and initially, I told my broker,
[00:35:42.100 --> 00:35:44.060]   I wanted to invest like a 60-year-old man
[00:35:44.060 --> 00:35:45.900]   'cause I wanted to protect it.
[00:35:45.900 --> 00:35:48.380]   But then he started asking me all kinds of questions
[00:35:48.380 --> 00:35:51.340]   about all these technologies that I understood
[00:35:51.340 --> 00:35:53.120]   like networks I had installed.
[00:35:53.120 --> 00:35:56.400]   We had become one of the top 20,
[00:35:56.400 --> 00:35:59.480]   let's say, systems integrators in the country.
[00:35:59.480 --> 00:36:00.320]   At one point in time,
[00:36:00.320 --> 00:36:03.660]   we were the largest IBM token ring installer in the country.
[00:36:03.660 --> 00:36:05.040]   It was crazy, right?
[00:36:05.040 --> 00:36:07.520]   Banyan, then Blast from the Past.
[00:36:07.520 --> 00:36:10.720]   I mean, so anyway, so these Wall Street bankers
[00:36:10.720 --> 00:36:14.300]   or analysts rather that were the big analysts of the time
[00:36:14.300 --> 00:36:17.040]   would call me up 'cause they would ask my broker,
[00:36:17.040 --> 00:36:18.560]   what does he know about this product, this product?
[00:36:18.560 --> 00:36:21.240]   And I knew 'em all, what was working and not working, right?
[00:36:21.240 --> 00:36:24.840]   And so the ones that work, I say that it's working.
[00:36:24.840 --> 00:36:27.200]   They say something, the stock would go up 20 bucks, right?
[00:36:27.200 --> 00:36:29.320]   So I'm like, well, and my broker's like,
[00:36:29.320 --> 00:36:31.120]   you need to, you know this better than they do.
[00:36:31.120 --> 00:36:31.940]   You need to invest.
[00:36:31.940 --> 00:36:34.160]   So I started buying and selling stocks
[00:36:34.160 --> 00:36:37.800]   and this was in 1990 and was just killing it.
[00:36:37.800 --> 00:36:42.440]   I was making 80, 90, 100% a year over those next four years
[00:36:42.440 --> 00:36:44.080]   to the point where a guy came in
[00:36:44.080 --> 00:36:49.000]   and asked to use my trading history to start a hedge fund,
[00:36:49.000 --> 00:36:51.360]   which we did and I sold within nine months.
[00:36:51.360 --> 00:36:52.720]   It was great, right?
[00:36:52.720 --> 00:36:54.180]   But the point being as it goes forward,
[00:36:54.180 --> 00:36:56.760]   so when we sold to Yahoo,
[00:36:56.760 --> 00:36:59.400]   I already had a lot of experience trading stocks
[00:36:59.400 --> 00:37:02.520]   and I had seen different bubbles come and go,
[00:37:02.520 --> 00:37:04.680]   a bubble for PC manufacturers,
[00:37:04.680 --> 00:37:07.200]   a bubble for networking manufacturers.
[00:37:07.200 --> 00:37:08.440]   They went up, up, up, up, up,
[00:37:08.440 --> 00:37:11.200]   and then they came straight down after the hype
[00:37:11.200 --> 00:37:14.000]   or somebody just leapfrogged.
[00:37:14.000 --> 00:37:17.680]   And so when we sold to Yahoo, I was like,
[00:37:17.680 --> 00:37:19.480]   I've got a B next to my name.
[00:37:19.480 --> 00:37:21.160]   That's all I need or all I want.
[00:37:21.160 --> 00:37:22.240]   I don't wanna be greedy.
[00:37:22.240 --> 00:37:23.740]   And I'd seen this story before
[00:37:23.740 --> 00:37:27.480]   where stocks get really frothy and go straight down.
[00:37:27.480 --> 00:37:30.880]   And I knew that because all of what I had was in stock,
[00:37:30.880 --> 00:37:33.400]   I needed to find a way to collar it and protect it.
[00:37:33.400 --> 00:37:36.760]   So understanding stocks and trading and options
[00:37:36.760 --> 00:37:38.640]   and all that, my broker and I,
[00:37:38.640 --> 00:37:42.040]   we went and shorted an index that had Yahoo in it.
[00:37:42.040 --> 00:37:45.160]   And so the law at the time was you couldn't short
[00:37:45.160 --> 00:37:48.800]   any indexes that had more than 5% of that stock in it,
[00:37:48.800 --> 00:37:51.880]   that of any one of the Yahoo stock.
[00:37:51.880 --> 00:37:55.600]   And so I took pretty much 20 some million dollars,
[00:37:55.600 --> 00:37:58.320]   everything I had at the time, and I shorted the index.
[00:37:58.320 --> 00:37:59.680]   - This is fascinating, by the way,
[00:37:59.680 --> 00:38:02.640]   'cause it's based on your estimation that this is a bubble.
[00:38:02.640 --> 00:38:04.840]   - Or just my not wanting to be greedy.
[00:38:04.840 --> 00:38:07.120]   - Sure, so the foundation of this kind of thing
[00:38:07.120 --> 00:38:09.160]   is you don't wanna be greedy.
[00:38:09.160 --> 00:38:12.080]   - Yeah, I mean, how much money do I need, right?
[00:38:12.080 --> 00:38:13.120]   Where other people were saying,
[00:38:13.120 --> 00:38:14.720]   oh, I think it can go up higher, higher, higher.
[00:38:14.720 --> 00:38:19.720]   I went on CNBC, and I told 'em what I had done,
[00:38:19.720 --> 00:38:23.360]   and they were like, and Yahoo stock had gone up
[00:38:23.360 --> 00:38:26.200]   significantly from the time I had collared.
[00:38:26.200 --> 00:38:28.200]   And one of the guys, Joe Kernan, was on there.
[00:38:28.200 --> 00:38:31.960]   Don't you feel stupid now that Yahoo stock has gone up
[00:38:31.960 --> 00:38:32.780]   X percent more?
[00:38:32.780 --> 00:38:35.080]   I'm like, yeah, I feel real stupid sitting on my jet.
[00:38:35.080 --> 00:38:36.480]   (laughing)
[00:38:36.480 --> 00:38:39.960]   - But, so, I mean, there is some fundamental way
[00:38:39.960 --> 00:38:42.200]   in which bubbles are based on this greed.
[00:38:42.200 --> 00:38:43.600]   - Oh, for sure, for sure, yeah.
[00:38:43.600 --> 00:38:45.760]   - And I'd seen it before, right, like I just said.
[00:38:45.760 --> 00:38:47.940]   And so what I did was we put together a collar
[00:38:47.940 --> 00:38:50.080]   where I sold calls and bought puts.
[00:38:50.080 --> 00:38:53.360]   And as it turned out, when the market just cratered,
[00:38:53.360 --> 00:38:54.640]   I was protected.
[00:38:54.640 --> 00:38:58.360]   And over the next two, three years, whatever it was,
[00:38:58.360 --> 00:39:01.620]   it converted to cash, paid my taxes, et cetera.
[00:39:01.620 --> 00:39:05.120]   But it protected me, and as it turns out,
[00:39:05.120 --> 00:39:07.640]   it was called one of the top 10 trades of all time.
[00:39:07.640 --> 00:39:11.080]   And what was even more interesting out of that period,
[00:39:11.080 --> 00:39:12.920]   my broker at that time was at Goldman Sachs,
[00:39:12.920 --> 00:39:16.720]   and I had asked him to see if there was a way
[00:39:16.720 --> 00:39:19.800]   to trade the VIX, right, the volatility index.
[00:39:19.800 --> 00:39:21.840]   And there wasn't, right?
[00:39:21.840 --> 00:39:24.920]   And so one of the people at Goldman
[00:39:24.920 --> 00:39:27.440]   that we were working with to try to create this
[00:39:27.440 --> 00:39:29.920]   actually left Goldman and created indexes
[00:39:29.920 --> 00:39:32.720]   that allowed you to trade the VIX.
[00:39:32.720 --> 00:39:35.560]   - Well, it's not trivial to understand that it's a bubble.
[00:39:35.560 --> 00:39:39.240]   I mean, you're kind of lessening your insight
[00:39:39.240 --> 00:39:41.760]   into all this by saying you just didn't wanna be greedy.
[00:39:41.760 --> 00:39:43.640]   But you still have to see that it's a bubble.
[00:39:43.640 --> 00:39:44.960]   - Yeah, I mean, yeah, obviously,
[00:39:44.960 --> 00:39:46.440]   if I thought it was gonna keep on going up
[00:39:46.440 --> 00:39:48.360]   and there was intrinsic value there,
[00:39:48.360 --> 00:39:49.320]   I would have stayed in it.
[00:39:49.320 --> 00:39:53.320]   But it wasn't so much Yahoo, it was just the entire industry.
[00:39:53.320 --> 00:39:56.600]   Back then, like we're looking at the magic seven
[00:39:56.600 --> 00:39:58.040]   or whatever it is stocks now,
[00:39:58.040 --> 00:40:00.240]   and people are asking, is it a bubble?
[00:40:00.240 --> 00:40:03.320]   And when I would get into cabs,
[00:40:03.320 --> 00:40:06.060]   and people would just start talking about internet stocks.
[00:40:06.060 --> 00:40:07.560]   There were people creating companies
[00:40:07.560 --> 00:40:09.680]   with just a website and going public.
[00:40:09.680 --> 00:40:11.120]   You know, that's a bubble, right?
[00:40:11.120 --> 00:40:13.480]   Where there's no intrinsic value at all.
[00:40:13.480 --> 00:40:16.200]   And people aren't even trying to make operating cap profits.
[00:40:16.200 --> 00:40:17.960]   They're just trying to leverage the frothiness
[00:40:17.960 --> 00:40:19.200]   of the stock market.
[00:40:19.200 --> 00:40:20.160]   That's a bubble.
[00:40:20.160 --> 00:40:21.160]   You don't see that right now.
[00:40:21.160 --> 00:40:23.080]   There's not companies, you don't see hardly,
[00:40:23.080 --> 00:40:25.440]   you don't see any IPOs right now for that matter.
[00:40:25.440 --> 00:40:27.560]   So, you know, I don't think we're in a bubble now,
[00:40:27.560 --> 00:40:29.760]   but back then, yes, I thought we were in a bubble,
[00:40:29.760 --> 00:40:32.000]   but that wasn't really the motivating factor.
[00:40:32.000 --> 00:40:33.480]   - Do you think it's possible we're in a bit
[00:40:33.480 --> 00:40:35.880]   of an AI bubble right now?
[00:40:35.880 --> 00:40:39.140]   - No, because we're not seeing funky AI companies
[00:40:39.140 --> 00:40:40.040]   just go public.
[00:40:40.040 --> 00:40:42.600]   If all of a sudden, we see a rush of companies
[00:40:42.600 --> 00:40:45.000]   who are skins on other people's models,
[00:40:45.000 --> 00:40:48.120]   or just creating models to create models
[00:40:48.120 --> 00:40:50.020]   that are going public, then yeah,
[00:40:50.020 --> 00:40:51.920]   that's probably the start of a bubble.
[00:40:51.920 --> 00:40:55.800]   But that said, my 14-year-old was bragging
[00:40:55.800 --> 00:40:58.000]   about buying NVIDIA, you know, with me
[00:40:58.000 --> 00:40:59.560]   in his Robberhood account.
[00:40:59.560 --> 00:41:01.140]   He tells me the order I placed it,
[00:41:01.140 --> 00:41:03.840]   and he was like, "Oh yeah, it's going up, up, up."
[00:41:03.840 --> 00:41:06.200]   And I'm like, yeah, we're not quite there yet,
[00:41:06.200 --> 00:41:08.680]   but that's one thing to pay attention to.
[00:41:08.680 --> 00:41:09.680]   - Yeah, we're flirting with it.
[00:41:09.680 --> 00:41:11.120]   - Yeah.
[00:41:11.120 --> 00:41:14.160]   - You said that becoming a billionaire requires luck.
[00:41:14.160 --> 00:41:15.400]   - Yeah. - Can you explain?
[00:41:15.400 --> 00:41:17.880]   - Yeah, I mean, there's no business plan
[00:41:17.880 --> 00:41:19.280]   where you can just start it and say,
[00:41:19.280 --> 00:41:21.640]   yeah, I'm definitely going to be a billionaire.
[00:41:21.640 --> 00:41:24.160]   You can, you know, if I had to start all over,
[00:41:24.160 --> 00:41:25.840]   could I start a company that made me a millionaire?
[00:41:25.840 --> 00:41:27.880]   Yeah, 'cause I know how to sell, and I know technology,
[00:41:27.880 --> 00:41:30.960]   and I've learned enough over the years to do that.
[00:41:30.960 --> 00:41:31.920]   Could I make 10 million?
[00:41:31.920 --> 00:41:33.080]   Probably, 100 million?
[00:41:33.080 --> 00:41:35.360]   I hope so.
[00:41:35.360 --> 00:41:38.820]   But a billion, just something good has got to happen.
[00:41:38.820 --> 00:41:40.360]   You know? - The timing.
[00:41:40.360 --> 00:41:42.240]   - Timing, you know, the internet stock market
[00:41:42.240 --> 00:41:44.840]   was going nuts right when we started, you know?
[00:41:44.840 --> 00:41:48.520]   And that certainly, I couldn't predict or control.
[00:41:48.520 --> 00:41:52.640]   You know, it's like AI right now.
[00:41:52.640 --> 00:41:55.800]   AI's been around a long, long, long, long time.
[00:41:55.800 --> 00:42:00.800]   And the NVIDIA processors, or GPUs rather,
[00:42:00.800 --> 00:42:02.680]   you couldn't predict that now's the time
[00:42:02.680 --> 00:42:04.860]   that they were going to get to that cost-effectiveness
[00:42:04.860 --> 00:42:08.840]   where, you know, you could create models and train them,
[00:42:08.840 --> 00:42:12.040]   and although it's expensive, it's still doable.
[00:42:12.040 --> 00:42:13.440]   You know, we didn't really even,
[00:42:13.440 --> 00:42:15.880]   we had ASICs, right, for custom applications,
[00:42:15.880 --> 00:42:18.640]   and we had CPUs that were leading the way,
[00:42:18.640 --> 00:42:22.360]   but GPUs were more for gaming and then crypto mining.
[00:42:22.360 --> 00:42:23.840]   And now, then all of a sudden,
[00:42:23.840 --> 00:42:27.000]   they were the foundation for AI models.
[00:42:27.000 --> 00:42:32.000]   - So I think luck being essential to becoming a billionaire
[00:42:32.200 --> 00:42:34.980]   is a beautiful way to see life in general.
[00:42:34.980 --> 00:42:37.660]   First of all, I personally think that everything good
[00:42:37.660 --> 00:42:40.020]   that's ever happened to me is because of luck.
[00:42:40.020 --> 00:42:41.700]   I think that's just a good way of being.
[00:42:41.700 --> 00:42:43.780]   It's like you're grateful.
[00:42:43.780 --> 00:42:46.180]   That said, there's some examples of people
[00:42:46.180 --> 00:42:49.380]   that you're like, they seem to have done a lot of,
[00:42:49.380 --> 00:42:51.500]   they seem to have gotten lucky a lot.
[00:42:51.500 --> 00:42:53.180]   You know, we mentioned Jeff Bezos.
[00:42:53.180 --> 00:42:57.580]   It seems like he did a lot of really interesting,
[00:42:57.580 --> 00:42:59.860]   powerful decisions for many years
[00:42:59.860 --> 00:43:01.660]   with Amazon to make it successful.
[00:43:01.660 --> 00:43:04.640]   But he was really able to raise money, right?
[00:43:04.640 --> 00:43:05.760]   A lot of money.
[00:43:05.760 --> 00:43:08.080]   And people were really dismissive of him
[00:43:08.080 --> 00:43:11.800]   because they weren't making, they weren't profitable.
[00:43:11.800 --> 00:43:13.960]   And we were in an environment
[00:43:13.960 --> 00:43:15.460]   where it was possible to raise all that money.
[00:43:15.460 --> 00:43:16.680]   - It was possible to raise that money.
[00:43:16.680 --> 00:43:20.720]   I mean, what about somebody you get sometimes feisty with
[00:43:20.720 --> 00:43:21.840]   on the internet, Elon?
[00:43:21.840 --> 00:43:24.440]   But we couldn't even look at Zuck and Bill Gates
[00:43:24.440 --> 00:43:25.520]   and Warren Buffett.
[00:43:25.520 --> 00:43:27.880]   - Look, Zuck was just trying to get laid, right?
[00:43:27.880 --> 00:43:29.240]   And it took off, and you rose some good-
[00:43:29.240 --> 00:43:30.080]   - Aren't we all?
[00:43:30.080 --> 00:43:30.920]   - Right, it's that level, right?
[00:43:30.920 --> 00:43:32.840]   - That's the foundation of human civilization.
[00:43:32.840 --> 00:43:35.120]   - But yeah, so more power to him, right?
[00:43:35.120 --> 00:43:36.960]   You can't take anything away from him.
[00:43:36.960 --> 00:43:40.460]   But yeah, Snapchat, same thing, took off.
[00:43:40.460 --> 00:43:43.200]   Apps didn't take off in 2007 when the iPhone came out.
[00:43:43.200 --> 00:43:45.820]   Apps took off in 2011, 2012.
[00:43:45.820 --> 00:43:48.360]   And if you were there with the right app at the right time.
[00:43:48.360 --> 00:43:52.640]   And even Facebook, you know, in 2004,
[00:43:52.640 --> 00:43:55.360]   the bubble had burst and, you know,
[00:43:55.360 --> 00:43:58.060]   the price for computers had fallen enough
[00:43:58.060 --> 00:44:00.640]   and kids in school all needed computers or laptops.
[00:44:00.640 --> 00:44:03.880]   If he had tried to do something like that, you know,
[00:44:03.880 --> 00:44:05.400]   five years earlier, I mean, he was too young,
[00:44:05.400 --> 00:44:08.280]   but, you know, five years earlier or five years later,
[00:44:08.280 --> 00:44:11.200]   you know, or Friendster might have been the ultimate,
[00:44:11.200 --> 00:44:12.480]   or MySpace.
[00:44:12.480 --> 00:44:14.240]   - Friendster, I remember Friendster.
[00:44:14.240 --> 00:44:15.720]   - Or MySpace, I had a MySpace account
[00:44:15.720 --> 00:44:17.880]   and that was before Facebook.
[00:44:17.880 --> 00:44:19.640]   - Yeah, the timing's important,
[00:44:19.640 --> 00:44:22.360]   but there's like the details of how the product is built,
[00:44:22.360 --> 00:44:24.960]   the fundamentals of the product, like what-
[00:44:24.960 --> 00:44:25.800]   - But that's what gets you,
[00:44:25.800 --> 00:44:28.080]   when the opportunity is there, right?
[00:44:28.080 --> 00:44:29.560]   That's what allows you to take advantage
[00:44:29.560 --> 00:44:32.440]   of that opportunity and the kismet of it all, right?
[00:44:32.440 --> 00:44:34.000]   You've gotta be, 'cause it wasn't like
[00:44:34.000 --> 00:44:35.600]   any of the people I mentioned,
[00:44:35.600 --> 00:44:38.160]   there weren't others trying the same thing, right?
[00:44:38.160 --> 00:44:39.680]   You had to be able to see it.
[00:44:39.680 --> 00:44:41.800]   You had to be able to visualize it
[00:44:41.800 --> 00:44:43.800]   and put together a plan of some sort,
[00:44:43.800 --> 00:44:45.360]   or at least have a path.
[00:44:45.360 --> 00:44:47.280]   And then you had to execute on it
[00:44:47.280 --> 00:44:49.760]   and do all those things at the same time
[00:44:49.760 --> 00:44:51.600]   and have the money available to you.
[00:44:51.600 --> 00:44:55.240]   Because it wasn't like, whether it was Google or Facebook,
[00:44:55.240 --> 00:44:57.040]   you know, they raised a shitload of money.
[00:44:57.040 --> 00:44:59.220]   It wasn't bootstrapping it that got them there.
[00:44:59.220 --> 00:45:01.520]   - And raising money is not just about sales,
[00:45:01.520 --> 00:45:05.340]   it's about the general feeling
[00:45:05.340 --> 00:45:07.480]   of the people with money at that time.
[00:45:07.480 --> 00:45:08.400]   - And proximity.
[00:45:08.400 --> 00:45:10.400]   - Oh yeah, sure.
[00:45:10.400 --> 00:45:11.300]   - If Chuck wasn't at Harvard
[00:45:11.300 --> 00:45:13.880]   and he was at Miami of Ohio University,
[00:45:13.880 --> 00:45:16.720]   or he was at Richland Community College,
[00:45:16.720 --> 00:45:20.160]   same idea, same person, same execution and nothing.
[00:45:20.160 --> 00:45:24.320]   - I believe in the power of individuals
[00:45:24.320 --> 00:45:27.760]   to find their, to realize their potential
[00:45:27.760 --> 00:45:29.300]   no matter where they come from.
[00:45:29.300 --> 00:45:30.980]   - I agree 100% with that, right?
[00:45:30.980 --> 00:45:31.900]   - But luck is required.
[00:45:31.900 --> 00:45:34.500]   - Yeah, I mean, scale is, the only delta is scale.
[00:45:34.500 --> 00:45:38.900]   We're not all blessed with the access to the tools
[00:45:38.900 --> 00:45:42.020]   that you need to hit that grand slam.
[00:45:42.020 --> 00:45:43.340]   - But then also, a billion is not
[00:45:43.340 --> 00:45:45.180]   the only measure of success, right?
[00:45:45.180 --> 00:45:46.980]   - Absolutely not, right?
[00:45:46.980 --> 00:45:49.180]   Everybody defines the success in their own way.
[00:45:49.180 --> 00:45:51.900]   - How do you define success, Mark Cuban?
[00:45:51.900 --> 00:45:53.580]   - Waking up every day with a smile,
[00:45:53.580 --> 00:45:54.920]   excited about the day.
[00:45:56.620 --> 00:45:58.680]   People always say, well, when you get that kind of money,
[00:45:58.680 --> 00:46:00.040]   does it make you happy?
[00:46:00.040 --> 00:46:02.480]   And my answer always is,
[00:46:02.480 --> 00:46:04.320]   if you are happy when you were broke,
[00:46:04.320 --> 00:46:06.120]   you're gonna be really, really, really happy
[00:46:06.120 --> 00:46:06.960]   when you're rich.
[00:46:06.960 --> 00:46:08.080]   (laughing)
[00:46:08.080 --> 00:46:10.040]   - But you gotta work on being happy
[00:46:10.040 --> 00:46:11.100]   when you're broke, I guess.
[00:46:11.100 --> 00:46:12.480]   - Well, you're just being happy, right?
[00:46:12.480 --> 00:46:15.720]   If you were miserable in your job before,
[00:46:15.720 --> 00:46:17.480]   there's a good chance you're still gonna be miserable
[00:46:17.480 --> 00:46:19.200]   if that's just who you are.
[00:46:19.200 --> 00:46:21.400]   - That's a pretty good definition of success, by the way.
[00:46:21.400 --> 00:46:22.240]   - Thank you.
[00:46:22.240 --> 00:46:24.040]   - How do you reach that success
[00:46:24.100 --> 00:46:26.780]   by way of advice to people?
[00:46:26.780 --> 00:46:29.300]   - You know, we talked about my dad, my parents.
[00:46:29.300 --> 00:46:32.540]   I never looked at my dad and said,
[00:46:32.540 --> 00:46:34.540]   okay, you're not successful.
[00:46:34.540 --> 00:46:36.900]   He busted his ass, and when he came home,
[00:46:36.900 --> 00:46:43.340]   we enjoyed our time together, right?
[00:46:43.340 --> 00:46:45.340]   There was nothing at any point in time
[00:46:45.340 --> 00:46:47.820]   where I felt like, oh, this is miserable,
[00:46:47.820 --> 00:46:51.060]   we're awful, we don't have this, we don't have that.
[00:46:51.060 --> 00:46:53.420]   You know, we celebrated the things we did have,
[00:46:53.420 --> 00:46:57.220]   and never knew about the things we didn't have, you know?
[00:46:57.220 --> 00:47:01.300]   And so I think, you know, you have to be able
[00:47:01.300 --> 00:47:04.060]   to find your way to whatever it is
[00:47:04.060 --> 00:47:05.700]   that puts a smile on your face every day.
[00:47:05.700 --> 00:47:07.500]   Some people can do it, and some people can't.
[00:47:07.500 --> 00:47:08.940]   - It's not always about the smile,
[00:47:08.940 --> 00:47:10.300]   or the smile on the outside,
[00:47:10.300 --> 00:47:11.460]   it could be a smile on the inside.
[00:47:11.460 --> 00:47:12.300]   - Yeah, whatever it is, right?
[00:47:12.300 --> 00:47:13.500]   Whatever makes you feel good.
[00:47:13.500 --> 00:47:16.420]   - The struggle, even the struggle, like with your dad,
[00:47:16.420 --> 00:47:21.420]   the really, really hard work can be a fulfilling experience,
[00:47:22.380 --> 00:47:27.380]   because the struggle leading up to then seeing your kids.
[00:47:27.380 --> 00:47:28.740]   - Exactly right, right?
[00:47:28.740 --> 00:47:31.700]   Because that was my dad's grand slam, right?
[00:47:31.700 --> 00:47:34.860]   Seeing three kids go to college, be successful,
[00:47:34.860 --> 00:47:37.580]   be able to spend time with them.
[00:47:37.580 --> 00:47:39.460]   And that was the other thing, you know,
[00:47:39.460 --> 00:47:42.780]   he really made me realize is the most valuable asset
[00:47:42.780 --> 00:47:45.140]   isn't the money, it's your time.
[00:47:45.140 --> 00:47:46.580]   That's why, you know, from a young age,
[00:47:46.580 --> 00:47:49.560]   I wanted to retire, because I wanted to experience
[00:47:49.560 --> 00:47:51.820]   everything that I possibly could in this life.
[00:47:51.820 --> 00:47:55.440]   And, you know, he got joy from us, I get joy from my kids.
[00:47:55.440 --> 00:48:00.860]   And that's the most special thing you ever can have.
[00:48:00.860 --> 00:48:02.020]   - Beautifully said.
[00:48:02.020 --> 00:48:05.560]   You have made some mistakes in your life.
[00:48:05.560 --> 00:48:07.380]   - Yeah, a lot of them.
[00:48:07.380 --> 00:48:10.060]   - One of the bigger ones on the financial side,
[00:48:10.060 --> 00:48:12.260]   we could say is Uber.
[00:48:12.260 --> 00:48:13.900]   - Yeah, we call that not doing something.
[00:48:13.900 --> 00:48:15.820]   Yeah, it wasn't a mistake, it was just,
[00:48:15.820 --> 00:48:16.900]   I mean, it was a mistake.
[00:48:16.900 --> 00:48:18.060]   (laughing)
[00:48:18.060 --> 00:48:19.260]   - I like how you tried to--
[00:48:20.020 --> 00:48:21.980]   - You know, I always try to look at mistakes,
[00:48:21.980 --> 00:48:23.380]   the things you did that didn't turn out
[00:48:23.380 --> 00:48:27.220]   as opposed to things you did to, you know, the negative.
[00:48:27.220 --> 00:48:28.660]   - But can you tell the story of that?
[00:48:28.660 --> 00:48:29.900]   And maybe it's just interesting,
[00:48:29.900 --> 00:48:33.460]   'cause it is illustrative of like how to know
[00:48:33.460 --> 00:48:35.740]   when a thing is going to be big and not,
[00:48:35.740 --> 00:48:37.460]   and what are the fundamentals of it,
[00:48:37.460 --> 00:48:39.180]   and how to take the risk and not,
[00:48:39.180 --> 00:48:40.420]   and all this kind of stuff.
[00:48:40.420 --> 00:48:43.020]   - So the backstory of that is Bill Gurley came to me
[00:48:43.020 --> 00:48:46.040]   and said, "Mark, there's this guy, Travis,
[00:48:46.040 --> 00:48:48.500]   "that has this company, Red Swoosh,
[00:48:48.500 --> 00:48:50.780]   "which is a peer-to-peer networking company
[00:48:50.780 --> 00:48:53.660]   "that I think you can help."
[00:48:53.660 --> 00:48:57.820]   And so I invested and spent a lot of time with Travis.
[00:48:57.820 --> 00:49:00.720]   And it's funny, 'cause back then, that was like 2006,
[00:49:00.720 --> 00:49:05.060]   I was an investor at Box.net with Aaron Levy,
[00:49:05.060 --> 00:49:08.060]   and oh, there was one other company,
[00:49:08.060 --> 00:49:10.220]   but there were three of 'em where there'd be emails
[00:49:10.220 --> 00:49:11.900]   between, you know, where I'd introduce 'em,
[00:49:11.900 --> 00:49:13.580]   and we'd all talk in these emails,
[00:49:13.580 --> 00:49:18.000]   and they'd all gone to have astronomical success, right?
[00:49:18.920 --> 00:49:22.120]   But so Red Swoosh had its issues, you know,
[00:49:22.120 --> 00:49:23.760]   'cause I was looking at peer-to-peer
[00:49:23.760 --> 00:49:27.280]   as kind of stealing bandwidth from the internet providers
[00:49:27.280 --> 00:49:30.040]   when bandwidth was a scarce commodity.
[00:49:30.040 --> 00:49:33.640]   And so, you know, what Travis did with that, though,
[00:49:33.640 --> 00:49:36.160]   was great, you know, he convinced gaming companies
[00:49:36.160 --> 00:49:39.960]   who wanted to do downloads of the clients for those games
[00:49:39.960 --> 00:49:41.840]   to use his peer-to-peer on Red Swoosh.
[00:49:41.840 --> 00:49:44.160]   And, you know, he busted his ass,
[00:49:44.160 --> 00:49:46.200]   and I think he sold it for $18 million.
[00:49:46.200 --> 00:49:47.320]   So he did well.
[00:49:47.320 --> 00:49:49.680]   And so it was natural for him to come to me,
[00:49:49.680 --> 00:49:51.560]   and I still have the emails, you know,
[00:49:51.560 --> 00:49:54.280]   and asked me about Uber Cab.
[00:49:54.280 --> 00:49:56.480]   And I thought, okay, this is a great idea.
[00:49:56.480 --> 00:49:58.200]   I really, really like it.
[00:49:58.200 --> 00:50:01.360]   I said, you're gonna, and he showed me his budgets,
[00:50:01.360 --> 00:50:03.320]   and I think they were raising money
[00:50:03.320 --> 00:50:06.280]   at 10 or $15 million or whatever.
[00:50:06.280 --> 00:50:08.980]   And I'm like, your biggest challenge is gonna be
[00:50:08.980 --> 00:50:09.920]   you're gonna have to fight
[00:50:09.920 --> 00:50:11.840]   all the incumbent taxi commissions.
[00:50:11.840 --> 00:50:13.540]   They're gonna wanna put you out of business.
[00:50:13.540 --> 00:50:14.600]   That's gonna be a challenge,
[00:50:14.600 --> 00:50:16.640]   and I think you don't have enough money
[00:50:16.640 --> 00:50:19.520]   designated for marketing to get all that done.
[00:50:19.520 --> 00:50:21.080]   And I said, I'd invest,
[00:50:21.080 --> 00:50:23.720]   but not quite at that valuation, right?
[00:50:23.720 --> 00:50:26.680]   Never came back to me. (laughs)
[00:50:26.680 --> 00:50:28.680]   - Yeah, I mean, there's some lessons there
[00:50:28.680 --> 00:50:30.400]   connected to what you're doing now.
[00:50:30.400 --> 00:50:32.020]   We'll talk about it, Cost Plus Drugs.
[00:50:32.020 --> 00:50:34.080]   It's like looking at an industry
[00:50:34.080 --> 00:50:38.800]   that seems like there's a lot of complexity involved,
[00:50:38.800 --> 00:50:41.400]   but it's like hungry for revolution.
[00:50:41.400 --> 00:50:43.520]   - For sure. - And the cabs are that.
[00:50:43.520 --> 00:50:44.360]   - Yeah, for sure, right?
[00:50:45.000 --> 00:50:47.960]   They were dominated by an insulated few.
[00:50:47.960 --> 00:50:49.320]   They were not very transparent.
[00:50:49.320 --> 00:50:50.840]   You didn't know the intricacies.
[00:50:50.840 --> 00:50:53.800]   They were very politically driven,
[00:50:53.800 --> 00:50:56.140]   and old boy, incestuous network.
[00:50:56.140 --> 00:50:59.320]   And like I told him, Travis,
[00:50:59.320 --> 00:51:01.560]   the best thing about you is you'll run through walls
[00:51:01.560 --> 00:51:02.560]   and break down barriers.
[00:51:02.560 --> 00:51:05.280]   The bad thing about you is you'll run through walls
[00:51:05.280 --> 00:51:07.320]   even if you don't have to.
[00:51:07.320 --> 00:51:09.600]   - Yeah, and there you kind of have to see,
[00:51:09.600 --> 00:51:11.280]   is it possible to raise enough money?
[00:51:11.280 --> 00:51:12.680]   Is it possible to do all this?
[00:51:12.680 --> 00:51:15.040]   Is it possible to break through?
[00:51:15.040 --> 00:51:18.880]   And it's kind of a fascinating success story with Uber is.
[00:51:18.880 --> 00:51:20.360]   - I think he tried to go too big.
[00:51:20.360 --> 00:51:24.240]   He had too big an ambition, which cost him in the end,
[00:51:24.240 --> 00:51:25.480]   not financially and personally,
[00:51:25.480 --> 00:51:28.380]   but just in terms of being able to stick it out with them.
[00:51:28.380 --> 00:51:32.000]   But that's what makes him a great entrepreneur.
[00:51:32.000 --> 00:51:34.000]   - Well, it's a fascinating success story.
[00:51:34.000 --> 00:51:37.160]   You have certain companies like Airbnb
[00:51:37.160 --> 00:51:39.260]   just kind of go into this thing
[00:51:39.260 --> 00:51:41.440]   that we take completely for granted.
[00:51:41.440 --> 00:51:42.280]   - And change it all.
[00:51:42.280 --> 00:51:43.120]   - Just change it all.
[00:51:43.120 --> 00:51:44.360]   - Yeah, yeah, Belinda Johnson,
[00:51:44.360 --> 00:51:47.360]   who worked as our general counsel at Broadcast.com,
[00:51:47.360 --> 00:51:51.440]   was Brian's GC and chief operating officer.
[00:51:51.440 --> 00:51:55.120]   So yeah, they had a smart, smart, smart, smart team.
[00:51:55.120 --> 00:51:56.440]   - And they believed in it.
[00:51:56.440 --> 00:51:59.480]   I mean, it's just, it's a beautiful story
[00:51:59.480 --> 00:52:00.440]   'cause you're like, all right,
[00:52:00.440 --> 00:52:02.480]   all the things that annoy you about this world,
[00:52:02.480 --> 00:52:04.840]   like they're inefficient and just seem like--
[00:52:04.840 --> 00:52:06.560]   - And see, I probably would have said no,
[00:52:06.560 --> 00:52:08.360]   like a lot of people did to Airbnb
[00:52:08.360 --> 00:52:10.400]   because I'm like, I don't want people
[00:52:10.400 --> 00:52:11.960]   sleeping in my bed.
[00:52:11.960 --> 00:52:12.800]   - I would have too.
[00:52:12.800 --> 00:52:14.360]   I was like, this is not gonna work.
[00:52:14.360 --> 00:52:15.840]   I've done like couch surfing and stuff
[00:52:15.840 --> 00:52:18.600]   and it was always, it didn't seem right.
[00:52:18.600 --> 00:52:20.840]   It didn't seem like you could do this at a large scale.
[00:52:20.840 --> 00:52:24.260]   - Monetize it, yeah, but he did, more power to him.
[00:52:24.260 --> 00:52:26.720]   - In 2000, I think January,
[00:52:26.720 --> 00:52:28.200]   you purchased the majority stake
[00:52:28.200 --> 00:52:33.200]   in the NBA team Dallas Mavericks for 285 million.
[00:52:33.200 --> 00:52:38.160]   So at this point, maybe you can correct me,
[00:52:38.160 --> 00:52:40.000]   but it was one of the worst performing teams
[00:52:40.000 --> 00:52:41.480]   in franchise history.
[00:52:41.480 --> 00:52:42.480]   - True.
[00:52:42.480 --> 00:52:46.240]   - How did you help turn it around?
[00:52:46.240 --> 00:52:48.480]   - I had this big tall guy named Dirk Nowitzki
[00:52:48.480 --> 00:52:50.640]   and I let him be Dirk Nowitzki, right?
[00:52:50.640 --> 00:52:52.680]   And I got out of the way.
[00:52:52.680 --> 00:52:54.480]   But I think more than anything else,
[00:52:54.480 --> 00:52:56.720]   there was the turnaround on the business side
[00:52:56.720 --> 00:52:59.880]   and then there was the turnaround on the basketball side.
[00:52:59.880 --> 00:53:00.920]   And on the basketball side,
[00:53:00.920 --> 00:53:02.280]   I just went in there immediately said,
[00:53:02.280 --> 00:53:04.720]   whatever it takes to win, that's what we're going to do.
[00:53:04.720 --> 00:53:08.360]   Back then, they had three or four coaches
[00:53:08.360 --> 00:53:10.200]   that were responsible for everything.
[00:53:10.200 --> 00:53:12.600]   And I was like, okay, we spend more money
[00:53:12.600 --> 00:53:15.400]   training people on PC software
[00:53:15.400 --> 00:53:18.040]   than we do developing the most important assets
[00:53:18.040 --> 00:53:18.880]   of the business.
[00:53:18.880 --> 00:53:20.920]   So I made the decision to go out there
[00:53:20.920 --> 00:53:24.120]   and hire like 15 different development coaches,
[00:53:24.120 --> 00:53:25.600]   one for each player.
[00:53:25.600 --> 00:53:28.120]   And everybody thought I was just insane,
[00:53:28.120 --> 00:53:32.240]   but it sent the message that we were going to do
[00:53:32.240 --> 00:53:33.840]   whatever it took to win.
[00:53:33.840 --> 00:53:38.840]   And once the guys believe that winning was the goal
[00:53:39.800 --> 00:53:42.680]   as opposed to just making money, attitudes change,
[00:53:42.680 --> 00:53:45.400]   effort went up and the rest is history.
[00:53:45.400 --> 00:53:47.520]   - So the assets of the business here are the--
[00:53:47.520 --> 00:53:48.560]   - The players. - The players.
[00:53:48.560 --> 00:53:49.560]   - Yeah, for sure.
[00:53:49.560 --> 00:53:51.160]   And then on the business side,
[00:53:51.160 --> 00:53:54.880]   the first question I asked myself is,
[00:53:54.880 --> 00:53:56.160]   what business are we in?
[00:53:56.160 --> 00:53:58.720]   And I really didn't know the answer immediately,
[00:53:58.720 --> 00:54:00.840]   but within the first few months,
[00:54:00.840 --> 00:54:03.880]   it was obvious that the entire NBA
[00:54:03.880 --> 00:54:06.040]   thought we were in the business of basketball.
[00:54:06.040 --> 00:54:08.440]   We were not, we were in the experience business.
[00:54:08.440 --> 00:54:11.320]   When you think about sporting events that you've been to,
[00:54:11.320 --> 00:54:12.560]   you don't remember the score,
[00:54:12.560 --> 00:54:14.440]   you don't remember the home runs or the dunks,
[00:54:14.440 --> 00:54:15.760]   you remember who you're with.
[00:54:15.760 --> 00:54:17.080]   And you remember why you went.
[00:54:17.080 --> 00:54:19.480]   Oh, it was my first day with a girl who's now my wife,
[00:54:19.480 --> 00:54:21.200]   or I went with my buddies
[00:54:21.200 --> 00:54:23.720]   and he threw up on the person in front of us.
[00:54:23.720 --> 00:54:25.800]   You know, my dad took me, my aunt, my uncle took me.
[00:54:25.800 --> 00:54:27.800]   Those are the experiences you remember.
[00:54:27.800 --> 00:54:31.640]   And once I conveyed to our people
[00:54:31.640 --> 00:54:32.880]   that this is what we were selling,
[00:54:32.880 --> 00:54:35.840]   that what happened in the arena off the court
[00:54:35.840 --> 00:54:37.880]   was just as important as what happened on the court,
[00:54:37.880 --> 00:54:39.120]   if not more so.
[00:54:39.120 --> 00:54:41.600]   Because if mom or dad are bringing the 10-year-old,
[00:54:41.600 --> 00:54:43.080]   you have to keep them occupied
[00:54:43.080 --> 00:54:44.520]   because they have short attention spans.
[00:54:44.520 --> 00:54:47.680]   And so I would get into fights with the NBA,
[00:54:47.680 --> 00:54:48.800]   put aside the refs,
[00:54:48.800 --> 00:54:50.560]   but getting into fights in the NBA,
[00:54:50.560 --> 00:54:53.120]   I would say NBA, nothing but attorneys, right?
[00:54:53.120 --> 00:54:55.240]   Because they had no marketing skills whatsoever.
[00:54:55.240 --> 00:54:58.200]   And to their credit, they realized that was a problem
[00:54:58.200 --> 00:54:59.440]   and started bringing in better and better
[00:54:59.440 --> 00:55:00.560]   and better marketing people.
[00:55:00.560 --> 00:55:03.360]   - So part of the selling is you're selling the team,
[00:55:03.360 --> 00:55:07.320]   selling the sport, selling the people,
[00:55:07.320 --> 00:55:09.200]   the idea, all of it, like just the--
[00:55:09.200 --> 00:55:10.040]   - Well, yeah, the experience.
[00:55:10.040 --> 00:55:12.280]   So have you ever been to an NBA game?
[00:55:12.280 --> 00:55:13.120]   - Miami Heat.
[00:55:13.120 --> 00:55:14.960]   - Do you remember walking into the arena
[00:55:14.960 --> 00:55:17.160]   and you feel the energy, right?
[00:55:17.160 --> 00:55:18.480]   That's what makes it special.
[00:55:18.480 --> 00:55:19.800]   - Yeah, the energy is everything.
[00:55:19.800 --> 00:55:20.840]   Especially playoff games.
[00:55:20.840 --> 00:55:22.000]   - Right, for sure, right?
[00:55:22.000 --> 00:55:23.480]   And even a regular season game, right?
[00:55:23.480 --> 00:55:25.280]   Even against the worst team,
[00:55:25.280 --> 00:55:27.440]   you know, that's where we get,
[00:55:27.440 --> 00:55:29.640]   because the tickets tend to be a little bit cheaper
[00:55:29.640 --> 00:55:30.800]   on the resale market,
[00:55:30.800 --> 00:55:32.320]   that's where parents will bring their kids.
[00:55:32.320 --> 00:55:34.880]   And so you hear kids screaming the entire game.
[00:55:34.880 --> 00:55:36.880]   And the parents are thrilled to death, right?
[00:55:36.880 --> 00:55:38.440]   They got to do something with your kids.
[00:55:38.440 --> 00:55:39.680]   The kids are thrilled to death
[00:55:39.680 --> 00:55:42.240]   because they got to see basketball, an NBA game,
[00:55:42.240 --> 00:55:44.240]   and scream at the top of their lungs.
[00:55:44.240 --> 00:55:46.400]   And you know, if it turns out to be a close game
[00:55:46.400 --> 00:55:47.720]   and that ball is in the air,
[00:55:47.720 --> 00:55:49.800]   and if it goes in, you know,
[00:55:49.800 --> 00:55:51.400]   everybody's hugging and high-fiving people
[00:55:51.400 --> 00:55:53.040]   you've never seen before in your life.
[00:55:53.040 --> 00:55:53.880]   And if it misses,
[00:55:53.880 --> 00:55:55.960]   you're commiserating with people you've never seen before.
[00:55:55.960 --> 00:55:59.200]   That's such a unique experience that's unique to sports.
[00:55:59.200 --> 00:56:00.320]   And we never sold that.
[00:56:00.320 --> 00:56:01.760]   And that's exactly what we started selling.
[00:56:01.760 --> 00:56:03.280]   - I have to say, like, just going to that game
[00:56:03.280 --> 00:56:04.560]   turned me around on basketball
[00:56:04.560 --> 00:56:05.920]   'cause I'm more of a football guy.
[00:56:05.920 --> 00:56:08.320]   So basketball wasn't like the main sport.
[00:56:08.320 --> 00:56:09.600]   And I was like, oh, wow, okay.
[00:56:09.600 --> 00:56:11.600]   - It's fun, and it's different, right?
[00:56:11.600 --> 00:56:14.680]   Yeah, the energy in a stadium is completely different
[00:56:14.680 --> 00:56:16.080]   than the energy in an arena.
[00:56:16.080 --> 00:56:17.960]   You know, in the stadium,
[00:56:17.960 --> 00:56:19.240]   particularly if it doesn't have a roof,
[00:56:19.240 --> 00:56:21.200]   it's hard to bottle that energy.
[00:56:21.200 --> 00:56:23.360]   You feel it and you see, like, I'm from Pittsburgh,
[00:56:23.360 --> 00:56:24.640]   so there's the terrible towels
[00:56:24.640 --> 00:56:26.800]   and people screaming defense and everything
[00:56:26.800 --> 00:56:27.640]   at Steelers games.
[00:56:27.640 --> 00:56:32.640]   But in an arena, the energy level is just indescribable.
[00:56:32.640 --> 00:56:35.160]   - So how much of it is the selling the tickets in person,
[00:56:35.160 --> 00:56:39.680]   but also versus what you see on TV?
[00:56:39.680 --> 00:56:41.320]   So when you're owning a team,
[00:56:41.320 --> 00:56:43.960]   do you get any of the cut for what's shown on TV?
[00:56:43.960 --> 00:56:44.920]   - Yeah, yeah, yeah.
[00:56:44.920 --> 00:56:47.080]   So there's a TV deal that's done
[00:56:47.080 --> 00:56:49.400]   with either a local TV broadcaster,
[00:56:49.400 --> 00:56:50.800]   and we get all of that,
[00:56:50.800 --> 00:56:55.800]   or a network broadcaster like ABCC, ESPN, TNT, whatever.
[00:56:55.800 --> 00:56:58.000]   And then we get 1/30 of that.
[00:56:58.000 --> 00:57:00.880]   - So what role does the TV play in, like,
[00:57:00.880 --> 00:57:02.760]   turning a team around? - It keeps fans connected.
[00:57:02.760 --> 00:57:05.480]   Look, when the team is doing really well, it's easy, right?
[00:57:05.480 --> 00:57:07.720]   There's more viewers, everybody's more excited.
[00:57:07.720 --> 00:57:11.280]   And when you're not, there's still gonna be hardcore fans
[00:57:11.280 --> 00:57:15.800]   and general fans and kids that like to watch the game.
[00:57:15.800 --> 00:57:17.080]   - What about, like, the personality
[00:57:17.080 --> 00:57:19.120]   of the people in the stands?
[00:57:19.120 --> 00:57:23.040]   Like, I mean, clearly, you're part of the legend
[00:57:23.040 --> 00:57:26.680]   of the team because you're literally there going wild.
[00:57:26.680 --> 00:57:28.800]   - Yeah, screaming, yeah, the whole game, right?
[00:57:28.800 --> 00:57:30.440]   Yeah, it's funny.
[00:57:30.560 --> 00:57:33.400]   The way I am here is how I am 24 hours a day
[00:57:33.400 --> 00:57:35.440]   unless there's a Mavs game, you know?
[00:57:35.440 --> 00:57:37.480]   And for whatever reason, that's where I let out
[00:57:37.480 --> 00:57:39.240]   all that stress and frustration.
[00:57:39.240 --> 00:57:42.560]   But yeah, I mean, it's not so, the fans,
[00:57:42.560 --> 00:57:44.000]   you know, the sixth man, right?
[00:57:44.000 --> 00:57:45.840]   We need fans to bring that energy.
[00:57:45.840 --> 00:57:49.580]   And amplifying that as much as we can is important.
[00:57:49.580 --> 00:57:52.760]   - You've had a beef recently on Twitter,
[00:57:52.760 --> 00:57:56.060]   on X with Elon over DEI programs.
[00:57:56.060 --> 00:57:59.720]   What to you is the essence of the disagreement there?
[00:57:59.720 --> 00:58:01.360]   - I wouldn't call it a beef, right?
[00:58:01.360 --> 00:58:03.200]   It's just-- - It's a bit of fun.
[00:58:03.200 --> 00:58:05.040]   - Yeah, it's fun for me, right?
[00:58:05.040 --> 00:58:11.400]   I just, you know, it's his platform.
[00:58:11.400 --> 00:58:12.800]   He gets to run it any way he pleases.
[00:58:12.800 --> 00:58:14.280]   He pays for that, right?
[00:58:14.280 --> 00:58:17.680]   And so I have total respect for whatever choices he makes,
[00:58:17.680 --> 00:58:19.760]   even if I don't agree with him.
[00:58:19.760 --> 00:58:22.720]   But because it's his platform,
[00:58:22.720 --> 00:58:27.720]   people are less likely to disagree with him,
[00:58:27.920 --> 00:58:32.600]   particularly somebody who's got a platform themselves.
[00:58:32.600 --> 00:58:35.240]   And so when we start talking about DEI
[00:58:35.240 --> 00:58:37.960]   and it's just de facto racist and this stuff,
[00:58:37.960 --> 00:58:40.400]   stuff that I just think is nonsense,
[00:58:40.400 --> 00:58:43.100]   I have no problem, you know, sharing my opinion.
[00:58:43.100 --> 00:58:48.920]   And, you know, if he disagrees, okay, he can disagree.
[00:58:48.920 --> 00:58:50.160]   I don't care, you know?
[00:58:50.160 --> 00:58:54.160]   And it's fun to engage, but he doesn't really engage.
[00:58:54.160 --> 00:58:56.080]   You know, he just comes back with snark comments,
[00:58:56.080 --> 00:58:57.880]   which is, you know, his choice.
[00:58:57.880 --> 00:59:00.760]   - Yeah, in your comments, well, you do a bit of snark too,
[00:59:00.760 --> 00:59:02.820]   but- - Yeah, a little bit.
[00:59:02.820 --> 00:59:09.040]   - But you're pretty, let's say, rigorous in your response.
[00:59:09.040 --> 00:59:10.840]   So there is some exchange of ideas.
[00:59:10.840 --> 00:59:12.600]   There's some snark, there's some fun,
[00:59:12.600 --> 00:59:13.440]   all that kind of stuff.
[00:59:13.440 --> 00:59:15.560]   And you do voice the opinion
[00:59:15.560 --> 00:59:18.400]   that represents a large number of people, and it's great.
[00:59:18.400 --> 00:59:20.800]   I mean, that's what's, it's really beautiful.
[00:59:20.800 --> 00:59:24.520]   But just lingering on the topic,
[00:59:24.640 --> 00:59:28.280]   what to you is the good and the bad of DEI programs?
[00:59:28.280 --> 00:59:29.320]   - Really simple, right?
[00:59:29.320 --> 00:59:32.840]   D is diversity, and that means you just expand
[00:59:32.840 --> 00:59:34.480]   your pool of potential applicants
[00:59:34.480 --> 00:59:38.160]   to people who you might not otherwise have access to.
[00:59:38.160 --> 00:59:40.280]   You know, to look where you didn't look before,
[00:59:40.280 --> 00:59:41.800]   to look where other people aren't looking
[00:59:41.800 --> 00:59:43.260]   for quality employees.
[00:59:43.260 --> 00:59:45.840]   That's simple.
[00:59:45.840 --> 00:59:50.480]   And the E in equity means when you hire somebody,
[00:59:50.480 --> 00:59:53.000]   you put them in a position to succeed.
[00:59:53.000 --> 00:59:57.040]   The I in inclusion is when you've hired somebody
[00:59:57.040 --> 01:00:00.680]   and they may not be typical, if you will, right?
[01:00:00.680 --> 01:00:03.040]   You show 'em some love and give 'em the support they need
[01:00:03.040 --> 01:00:04.760]   so they can do their job as best they can
[01:00:04.760 --> 01:00:06.520]   and feel comfortable and confident going to work.
[01:00:06.520 --> 01:00:07.820]   It's that simple.
[01:00:07.820 --> 01:00:10.360]   - So that's a beautiful ideal.
[01:00:10.360 --> 01:00:13.720]   When it's implemented, implemented poorly, perhaps,
[01:00:13.720 --> 01:00:16.240]   or in a way that doesn't reach that ideal,
[01:00:16.240 --> 01:00:20.640]   do you see, maybe when it's quota-based,
[01:00:20.640 --> 01:00:24.640]   do you see that it can result in essentially racism
[01:00:24.640 --> 01:00:27.640]   towards Asian people and white people, for example?
[01:00:27.640 --> 01:00:30.260]   - There's a lot to unpack there, right?
[01:00:30.260 --> 01:00:31.680]   So first, you can't do quotas.
[01:00:31.680 --> 01:00:33.960]   They're illegal unless you're,
[01:00:33.960 --> 01:00:35.240]   and I'm not the lawyer on this subject,
[01:00:35.240 --> 01:00:39.140]   but unless you're trying to repair something
[01:00:39.140 --> 01:00:40.160]   that's happened in the past,
[01:00:40.160 --> 01:00:42.640]   like some discrimination that's happened in the past.
[01:00:42.640 --> 01:00:45.900]   So it's not quota-based, and I think that's really
[01:00:45.900 --> 01:00:50.860]   just kind of a straw man that people put out there.
[01:00:50.860 --> 01:00:53.100]   Now, does that mean that there aren't DEI programs
[01:00:53.100 --> 01:00:53.940]   that are implemented poorly?
[01:00:53.940 --> 01:00:54.760]   Of course not.
[01:00:54.760 --> 01:00:57.260]   There are everything that's implemented poorly
[01:00:57.260 --> 01:00:59.180]   in one company to another, right?
[01:00:59.180 --> 01:01:03.220]   Sales, marketing, human resources.
[01:01:03.220 --> 01:01:05.020]   You can pick any element of business
[01:01:05.020 --> 01:01:07.220]   and find companies that implement it poorly.
[01:01:07.220 --> 01:01:11.760]   But that's the beauty of capitalism in a free market,
[01:01:11.760 --> 01:01:15.300]   or mostly free market, where if you make these choices,
[01:01:15.300 --> 01:01:17.340]   and they are the wrong choices,
[01:01:17.340 --> 01:01:19.200]   you're gonna lose your best people.
[01:01:19.200 --> 01:01:21.420]   You're not gonna be able to hire the best people.
[01:01:21.420 --> 01:01:23.720]   You're not gonna execute on your business plans
[01:01:23.720 --> 01:01:25.340]   in the way that we discussed,
[01:01:25.340 --> 01:01:27.320]   regardless of the size of the company.
[01:01:27.320 --> 01:01:31.180]   And it also, I think, depends on
[01:01:31.180 --> 01:01:33.100]   where you're having the discussion.
[01:01:33.100 --> 01:01:37.020]   So when I'm in a different group of people off of X,
[01:01:37.020 --> 01:01:39.540]   the feedback's completely different, right?
[01:01:41.340 --> 01:01:45.820]   But to your question of reverse racism,
[01:01:45.820 --> 01:01:49.100]   yes, it happens, 'cause people are people.
[01:01:49.100 --> 01:01:54.100]   There's no human being that is 100% objective.
[01:01:54.100 --> 01:02:00.460]   And it's also, there's very, very, very few jobs
[01:02:00.460 --> 01:02:06.060]   that can be determined on a purely quantitative basis.
[01:02:06.060 --> 01:02:11.100]   How do you tell one janitor from the other who's the best?
[01:02:11.100 --> 01:02:13.540]   How do you tell one salesperson that you're hiring
[01:02:13.540 --> 01:02:14.700]   versus another you're hiring?
[01:02:14.700 --> 01:02:15.940]   'Cause they haven't sold your product yet,
[01:02:15.940 --> 01:02:16.780]   so you don't know.
[01:02:16.780 --> 01:02:18.340]   We talked earlier about firing people
[01:02:18.340 --> 01:02:19.780]   'cause you made mistakes.
[01:02:19.780 --> 01:02:24.780]   And yes, there's discrimination against any group,
[01:02:24.780 --> 01:02:29.900]   white, Asian, black, green, orange, whatever it may be.
[01:02:29.900 --> 01:02:33.420]   But I truly believe that there's far more discrimination
[01:02:33.420 --> 01:02:37.060]   against people of color than there are people who are white.
[01:02:37.060 --> 01:02:40.140]   And I think it's become a straw man
[01:02:40.140 --> 01:02:43.820]   that reverse discrimination because of DEI
[01:02:43.820 --> 01:02:46.800]   is prevalent or near ubiquitous.
[01:02:46.800 --> 01:02:50.980]   - Well, much of American history was defined
[01:02:50.980 --> 01:02:55.320]   by intense radical racism and sexism.
[01:02:55.320 --> 01:03:00.420]   But in the recent years, there was a correction,
[01:03:00.420 --> 01:03:02.540]   and I think the nature of the criticism
[01:03:02.540 --> 01:03:04.580]   is that there's an overcorrection
[01:03:04.580 --> 01:03:08.980]   where DEI programs at universities, at companies,
[01:03:08.980 --> 01:03:11.820]   are often, when they're not doing their job well,
[01:03:11.820 --> 01:03:14.340]   are often hard to criticize
[01:03:14.340 --> 01:03:16.740]   because when you criticize them within the company
[01:03:16.740 --> 01:03:21.240]   or so on, they have a very strong immune system.
[01:03:21.240 --> 01:03:25.460]   If you criticize a DEI program,
[01:03:25.460 --> 01:03:27.980]   it seems like it's very easy to be called racist.
[01:03:27.980 --> 01:03:30.860]   And if you're called racist or sexist,
[01:03:30.860 --> 01:03:32.740]   that's a sticky label.
[01:03:32.740 --> 01:03:36.260]   So you're getting into the culture of organizations
[01:03:36.260 --> 01:03:38.820]   and leadership within organizations
[01:03:38.820 --> 01:03:43.820]   and accepting any type of criticism, put aside DEI.
[01:03:43.820 --> 01:03:49.020]   When I criticized the referees at the NBA, I got fined.
[01:03:49.020 --> 01:03:51.060]   That was their option.
[01:03:51.060 --> 01:03:52.740]   I knew what I was getting into.
[01:03:52.740 --> 01:03:54.140]   Not that they're completely analogous,
[01:03:54.140 --> 01:03:56.160]   but it's cause and effect.
[01:03:56.160 --> 01:04:00.260]   If I'm in a major company and I'm publicly criticizing
[01:04:00.260 --> 01:04:05.260]   or even internally criticizing a sales plan or a product,
[01:04:05.260 --> 01:04:07.220]   our product sucks, right?
[01:04:07.220 --> 01:04:09.400]   Or like there was a Google engineer that got fired
[01:04:09.400 --> 01:04:12.300]   for saying Google had AGI, right?
[01:04:12.300 --> 01:04:13.500]   And nobody believed they did,
[01:04:13.500 --> 01:04:15.220]   and they knew that created problems.
[01:04:15.220 --> 01:04:18.940]   Wasn't DEI related, but it was saying something publicly
[01:04:18.940 --> 01:04:21.340]   that was, in the CEO's eyes,
[01:04:21.340 --> 01:04:23.140]   to the detriment of the company, right?
[01:04:23.140 --> 01:04:25.500]   So I think those are all analogous.
[01:04:25.500 --> 01:04:26.980]   If you're trying to accomplish something
[01:04:26.980 --> 01:04:29.900]   within an organization because you think there's a problem
[01:04:29.900 --> 01:04:31.940]   and there's people speaking out, saying,
[01:04:31.940 --> 01:04:34.140]   look, we're getting it wrong.
[01:04:34.140 --> 01:04:36.320]   I think I'm a victim of all this.
[01:04:36.320 --> 01:04:37.960]   And the company's, right?
[01:04:37.960 --> 01:04:40.660]   Then, you know, leadership has got to make a decision.
[01:04:40.660 --> 01:04:42.860]   Do they agree or not agree?
[01:04:42.860 --> 01:04:43.700]   Are they right?
[01:04:43.700 --> 01:04:44.520]   Are they wrong?
[01:04:44.520 --> 01:04:46.780]   Is it to the positive?
[01:04:46.780 --> 01:04:48.460]   Is it positive or negative to the company?
[01:04:48.460 --> 01:04:49.540]   And you decide.
[01:04:49.540 --> 01:04:51.460]   So, you know, this conversation
[01:04:51.460 --> 01:04:56.460]   that conservatives are being silenced in organizations now,
[01:04:58.180 --> 01:05:00.740]   I just, I haven't seen it.
[01:05:00.740 --> 01:05:02.140]   You know, I've talked to,
[01:05:02.140 --> 01:05:03.800]   and then the other side of your question,
[01:05:03.800 --> 01:05:05.540]   I think, I'm packing it,
[01:05:05.540 --> 01:05:10.540]   is what's driving all this?
[01:05:10.540 --> 01:05:14.260]   Put aside universities, for one, in corporate America.
[01:05:14.260 --> 01:05:18.260]   When I talk to people in corporate America about DEI,
[01:05:18.260 --> 01:05:24.520]   they always start talking about ideology, right?
[01:05:24.520 --> 01:05:25.900]   And like, I've talked to Bill Ackman,
[01:05:25.900 --> 01:05:27.260]   who you've had on, right?
[01:05:27.260 --> 01:05:28.940]   And when I asked him,
[01:05:28.940 --> 01:05:30.340]   well, Bill, you run your own companies.
[01:05:30.340 --> 01:05:32.280]   Who's telling you what to do?
[01:05:32.280 --> 01:05:33.860]   They are.
[01:05:33.860 --> 01:05:34.900]   Who's they?
[01:05:34.900 --> 01:05:37.060]   Well, it's the universities, you know,
[01:05:37.060 --> 01:05:40.980]   the people who have this ideology of DEI.
[01:05:40.980 --> 01:05:43.260]   I'm like, did they force you?
[01:05:43.260 --> 01:05:45.240]   Did they coerce you?
[01:05:45.240 --> 01:05:47.600]   Did you lose control of your company?
[01:05:47.600 --> 01:05:48.540]   No, it's not me.
[01:05:48.540 --> 01:05:49.940]   It happens to other people.
[01:05:49.940 --> 01:05:52.520]   Then I talk to other people, same thing.
[01:05:52.520 --> 01:05:55.220]   So I get, you know, try not to go one-on-one
[01:05:55.220 --> 01:05:57.400]   in Twitter conversations on this topic.
[01:05:57.400 --> 01:05:59.740]   So in the DMs, I'll talk to people
[01:05:59.740 --> 01:06:02.020]   who are really conservative,
[01:06:02.020 --> 01:06:04.140]   and I'll ask the same question.
[01:06:04.140 --> 01:06:06.380]   And I'll be like, well, who's forcing you to do this?
[01:06:06.380 --> 01:06:08.020]   Well, it's the ideology that's everywhere.
[01:06:08.020 --> 01:06:10.340]   You see it, don't, didn't you see the Harvard thing,
[01:06:10.340 --> 01:06:12.060]   you know, in University of North Carolina?
[01:06:12.060 --> 01:06:14.300]   I'm like, I've never had anybody try to push me
[01:06:14.300 --> 01:06:15.780]   in this direction to do this.
[01:06:15.780 --> 01:06:17.340]   This was my business choice.
[01:06:17.340 --> 01:06:20.220]   I'm not trying to tell other people you have to do this.
[01:06:20.220 --> 01:06:22.340]   You make your own business choices.
[01:06:22.340 --> 01:06:25.300]   And so where companies have made their business choices,
[01:06:25.300 --> 01:06:26.920]   and if somebody doesn't feel confident
[01:06:26.920 --> 01:06:28.500]   or comfortable with it,
[01:06:28.500 --> 01:06:30.900]   they may feel they're being discriminated against.
[01:06:30.900 --> 01:06:33.080]   There was something I just read in the Wall Street Journal
[01:06:33.080 --> 01:06:34.660]   where the Wall Street Journal
[01:06:34.660 --> 01:06:38.700]   had a company interview 2 million people, right?
[01:06:38.700 --> 01:06:40.380]   And the difficulty in firing
[01:06:40.380 --> 01:06:42.980]   and how people, when they were fired,
[01:06:42.980 --> 01:06:46.340]   40% of the people who were fired
[01:06:46.340 --> 01:06:50.220]   felt like it was wrong that they were doing a great job.
[01:06:50.220 --> 01:06:53.420]   Yet, then it talked about the HR person
[01:06:53.420 --> 01:06:56.780]   going through the hassle of trying to explain to this person
[01:06:56.780 --> 01:06:58.420]   through performance reviews
[01:06:58.420 --> 01:07:00.180]   that they weren't doing a good job,
[01:07:00.180 --> 01:07:02.340]   yet the people still thought they were doing a great job
[01:07:02.340 --> 01:07:04.740]   despite being told they're not doing a good job, right?
[01:07:04.740 --> 01:07:07.380]   So I see that as being an analogous to all this,
[01:07:07.380 --> 01:07:09.420]   you know, this huffing and puffing
[01:07:09.420 --> 01:07:12.060]   about reverse discriminations
[01:07:12.060 --> 01:07:14.460]   and conservatives not being able to speak up
[01:07:14.460 --> 01:07:18.580]   because at 40% of people who have been fired
[01:07:18.580 --> 01:07:20.500]   don't believe they should have been fired.
[01:07:20.500 --> 01:07:22.460]   There's a disconnect somewhere
[01:07:22.460 --> 01:07:24.540]   in how you think you're doing your job.
[01:07:24.540 --> 01:07:29.540]   And if you just feel like I can't speak up because of it,
[01:07:29.540 --> 01:07:31.700]   because you're white
[01:07:31.700 --> 01:07:35.340]   and that doesn't comport well with DEI programs,
[01:07:35.340 --> 01:07:39.740]   a lot of things are gonna happen, right?
[01:07:39.740 --> 01:07:43.100]   Either that's gonna come up in your performance review,
[01:07:43.100 --> 01:07:46.940]   HR or your boss is going to have to address it in some way.
[01:07:46.940 --> 01:07:48.780]   It's gonna get to HR at some level
[01:07:48.780 --> 01:07:51.500]   and then decisions are going to have to be made.
[01:07:51.500 --> 01:07:52.780]   And you can't just fire somebody
[01:07:52.780 --> 01:07:55.140]   because they spoke up, right?
[01:07:55.140 --> 01:07:56.860]   Somebody is gonna have to communicate with you.
[01:07:56.860 --> 01:07:58.540]   And so I think a lot of,
[01:07:58.540 --> 01:08:03.740]   I just don't trust the supposed volume
[01:08:03.740 --> 01:08:06.340]   that people say it's happening at
[01:08:06.340 --> 01:08:07.900]   versus everything I've read and seen.
[01:08:07.900 --> 01:08:10.180]   And when I talk to people in positions of authority
[01:08:10.180 --> 01:08:13.860]   within organizations and ask them who's forcing them
[01:08:13.860 --> 01:08:15.700]   to implement these ideologies,
[01:08:15.700 --> 01:08:19.720]   nobody says yes, that there is somebody.
[01:08:19.720 --> 01:08:22.060]   But on Twitter, it sounds great.
[01:08:22.060 --> 01:08:24.620]   - It is true for conservatives, but in general,
[01:08:24.620 --> 01:08:27.060]   you could sell books, you can get likes
[01:08:27.060 --> 01:08:29.060]   when you talk about this ideology.
[01:08:29.060 --> 01:08:32.500]   And there's a degree to which is this woke ideology
[01:08:32.500 --> 01:08:34.140]   in the room with us right now?
[01:08:34.140 --> 01:08:37.580]   Meaning like it's this boogie monster
[01:08:37.580 --> 01:08:38.820]   that we're all kind of--
[01:08:38.820 --> 01:08:40.300]   - Or is it a positive?
[01:08:40.300 --> 01:08:42.020]   - I guess another way to say that
[01:08:42.020 --> 01:08:44.340]   is they don't highlight a lot of the positive progress
[01:08:44.340 --> 01:08:48.300]   that's been made in the positive version of the word woke
[01:08:48.300 --> 01:08:51.820]   in terms of correcting some of the wrongs done in the past.
[01:08:51.820 --> 01:08:55.740]   But that said, if you ask people in Russia,
[01:08:55.740 --> 01:08:58.860]   a lot of them will say, there's no propaganda here,
[01:08:58.860 --> 01:09:01.220]   there's no censorship and all that kind of stuff.
[01:09:01.220 --> 01:09:03.980]   It's sometimes hard to see when you're in it
[01:09:03.980 --> 01:09:06.460]   that this kind of stuff is happening.
[01:09:06.460 --> 01:09:11.460]   It does seem difficult to criticize DEI programs,
[01:09:11.500 --> 01:09:14.600]   not horribly difficult, terrible.
[01:09:14.600 --> 01:09:17.060]   They're this monster that infiltrates everything.
[01:09:17.060 --> 01:09:20.000]   But it is difficult and it requires great leadership.
[01:09:20.000 --> 01:09:23.580]   - So where have you criticized it and been condemned?
[01:09:23.580 --> 01:09:25.900]   Academic or-- - Academic, yeah.
[01:09:25.900 --> 01:09:28.260]   - Academic, let's, two different worlds.
[01:09:28.260 --> 01:09:29.460]   - Companies and academic, yeah.
[01:09:29.460 --> 01:09:30.300]   - Two different worlds.
[01:09:30.300 --> 01:09:31.780]   - But I also think it's not,
[01:09:31.780 --> 01:09:36.660]   I really wanna point my finger at the failure of leadership
[01:09:36.660 --> 01:09:41.120]   of basically firing mediocre people,
[01:09:41.120 --> 01:09:43.540]   like people that are not good at their job.
[01:09:43.540 --> 01:09:48.540]   The problem to me is DEI's defense mechanism,
[01:09:48.540 --> 01:09:51.900]   like immune system is so strong
[01:09:51.900 --> 01:09:55.580]   that the shitty people don't get fired.
[01:09:55.580 --> 01:09:59.420]   So the vision, the ideal of DEI is a beautiful ideal.
[01:09:59.420 --> 01:10:01.100]   It's just like--
[01:10:01.100 --> 01:10:02.500]   - Well, maybe it's 'cause I'm an entrepreneur
[01:10:02.500 --> 01:10:05.460]   when I see an ideal that you try to implement it
[01:10:05.460 --> 01:10:07.580]   and support it and get to that point.
[01:10:07.580 --> 01:10:10.320]   But universities and companies
[01:10:10.320 --> 01:10:11.920]   are night and day different, right?
[01:10:11.920 --> 01:10:14.480]   I can see an argument for the ideology in a university.
[01:10:14.480 --> 01:10:18.280]   I can see, you look at the amount of money spent on it.
[01:10:18.280 --> 01:10:20.760]   And so while the goal is right,
[01:10:20.760 --> 01:10:25.240]   the way they implement it in universities,
[01:10:25.240 --> 01:10:26.560]   the way they implement most things
[01:10:26.560 --> 01:10:28.400]   in universities is wrong, right?
[01:10:28.400 --> 01:10:31.440]   There's a reason why tuition has gone up,
[01:10:31.440 --> 01:10:35.920]   a multitude of, or a multiple of inflation
[01:10:36.580 --> 01:10:40.540]   that they're not well-run organizations across the board.
[01:10:40.540 --> 01:10:42.180]   So I'm not gonna argue with that at all.
[01:10:42.180 --> 01:10:44.060]   So when you've seen me argue with DEI,
[01:10:44.060 --> 01:10:46.500]   I haven't waded into DEI in universities at all.
[01:10:46.500 --> 01:10:47.820]   - So it's mostly focused on companies.
[01:10:47.820 --> 01:10:50.220]   - 100%, right, because that's where I exist.
[01:10:50.220 --> 01:10:53.020]   But at the same time, like I read Christopher Ruffro's book
[01:10:53.020 --> 01:10:57.060]   where he talks about the genealogy of wokeism and ideology,
[01:10:57.060 --> 01:10:58.180]   but then he gets to the point,
[01:10:58.180 --> 01:11:00.100]   and I hope I'm remembering this right,
[01:11:00.100 --> 01:11:03.740]   where he says that the response to it
[01:11:03.740 --> 01:11:07.340]   is decentralized activism, if you will,
[01:11:07.340 --> 01:11:12.340]   that's not the word he used, to try to counter that DEI.
[01:11:12.340 --> 01:11:16.720]   And that seems to me to be counter
[01:11:16.720 --> 01:11:19.280]   to the whole conservative movement right now, right?
[01:11:19.280 --> 01:11:21.520]   Other than school boards, right?
[01:11:21.520 --> 01:11:25.840]   Where it's centralized and the Republican candidate
[01:11:25.840 --> 01:11:28.400]   is all about centralized power in him.
[01:11:28.400 --> 01:11:32.080]   And to me, that's just a conflict
[01:11:32.080 --> 01:11:36.920]   and a lot of the underpinning of the whole DEI conversation
[01:11:36.920 --> 01:11:39.560]   that a lot of which goes through
[01:11:39.560 --> 01:11:41.560]   Christopher Ruffro right now.
[01:11:41.560 --> 01:11:42.840]   - Let's continue on a theme
[01:11:42.840 --> 01:11:45.400]   of fun exchanges on the internet.
[01:11:45.400 --> 01:11:49.320]   So Elon tweeted, "The fundamental axiomatic flaw
[01:11:49.320 --> 01:11:51.320]   "of the woke mind virus
[01:11:51.320 --> 01:11:54.860]   "is that the weaker parties always right, in parentheses,
[01:11:54.860 --> 01:11:57.680]   "even if they want you to die."
[01:11:57.680 --> 01:12:01.140]   And you responded at length, but the beginning is,
[01:12:01.140 --> 01:12:04.960]   "The fundamental axiomatic flaw of the anti-woke mind
[01:12:04.960 --> 01:12:07.360]   "is that it allows groups with historical power
[01:12:07.360 --> 01:12:10.720]   "to play the victim by taking anecdotal examples
[01:12:10.720 --> 01:12:14.580]   "and packaging them into conjured conspiratorial ideology
[01:12:14.580 --> 01:12:17.420]   "that threatens to up and the power structures
[01:12:17.420 --> 01:12:19.540]   "they have been depending on."
[01:12:19.540 --> 01:12:22.960]   So-- - He says it all, right?
[01:12:22.960 --> 01:12:24.120]   (laughing)
[01:12:24.120 --> 01:12:26.280]   - Well, there's a tension there.
[01:12:26.280 --> 01:12:31.280]   So, yes, but both can be abused, right?
[01:12:31.280 --> 01:12:35.660]   Both positions of power can be abused.
[01:12:35.660 --> 01:12:40.660]   There's power in DEI and there's shitty people
[01:12:40.660 --> 01:12:42.940]   that can crave power and hold on to power
[01:12:42.940 --> 01:12:45.060]   and sacrifice their ideals.
[01:12:45.060 --> 01:12:47.120]   - Okay, put aside universities, okay?
[01:12:47.120 --> 01:12:48.220]   Damn it.
[01:12:48.220 --> 01:12:49.780]   - Yeah, I mean-- - Because I'm not gonna argue
[01:12:49.780 --> 01:12:52.300]   that universities implement DEI well, right?
[01:12:52.300 --> 01:12:57.300]   And I'm not gonna tell you that they need to be spending
[01:12:57.300 --> 01:13:02.120]   20 some million dollars a year on DEI positions.
[01:13:02.120 --> 01:13:03.220]   To me, that's insane.
[01:13:03.220 --> 01:13:09.480]   Do I look at the Harvard and North Carolina decision
[01:13:09.480 --> 01:13:11.140]   and say it was a great decision?
[01:13:11.140 --> 01:13:15.800]   No, because I think having a diverse student body
[01:13:15.800 --> 01:13:20.120]   helps make for kids who are better prepared
[01:13:20.120 --> 01:13:21.480]   for the real world.
[01:13:21.480 --> 01:13:24.360]   But I'm not running a university so it's not my choice.
[01:13:24.360 --> 01:13:27.820]   Maybe at some point in the future I will, but not now.
[01:13:27.820 --> 01:13:32.820]   And in terms of the corporate side of it,
[01:13:32.820 --> 01:13:35.780]   who's telling anybody what to do?
[01:13:35.780 --> 01:13:41.480]   - Well, maybe you can give me some help.
[01:13:41.480 --> 01:13:43.440]   - Sure, I'm here to help you, Lex.
[01:13:43.440 --> 01:13:47.280]   - There's an example in the AI world
[01:13:47.280 --> 01:13:51.280]   of a system called Gemini 1.5.
[01:13:51.280 --> 01:13:53.520]   - Yeah, I mean, everybody was black or whatever,
[01:13:53.520 --> 01:13:54.360]   people of color.
[01:13:54.360 --> 01:13:57.600]   - George Washington was black, Nazis were black.
[01:13:57.600 --> 01:14:00.920]   - So why is it when that came out, it was a big uproar,
[01:14:00.920 --> 01:14:04.700]   but when somebody, so who was it?
[01:14:04.700 --> 01:14:07.040]   One of the people who are trying to fuck with me.
[01:14:07.040 --> 01:14:09.840]   I forget which one.
[01:14:09.840 --> 01:14:10.680]   - There's so many.
[01:14:10.680 --> 01:14:15.680]   - Yeah, but he pointed out to Elon that Grok,
[01:14:16.360 --> 01:14:21.320]   Elon's AI was woke when it answered certain questions.
[01:14:21.320 --> 01:14:24.280]   And other people have pointed out other things to Elon
[01:14:24.280 --> 01:14:26.980]   about Grok, whatever, however it's pronounced,
[01:14:26.980 --> 01:14:31.800]   that was leaning left or woke, right?
[01:14:31.800 --> 01:14:34.040]   And Elon's response was, oh, it'll change,
[01:14:34.040 --> 01:14:36.300]   it's a mistake, we're fixing it.
[01:14:36.300 --> 01:14:38.720]   When it happens to Gemini and Google,
[01:14:38.720 --> 01:14:39.920]   it's the end of the world.
[01:14:39.920 --> 01:14:41.600]   Look how woke they are and it's a reflection
[01:14:41.600 --> 01:14:42.560]   of all their culture.
[01:14:42.560 --> 01:14:44.320]   Now Google comes out and says it's a mistake
[01:14:44.320 --> 01:14:48.160]   and then they dox the guy who was the product manager
[01:14:48.160 --> 01:14:51.600]   or whatever of AI of that product who,
[01:14:51.600 --> 01:14:54.020]   and then they go back and look at his old tweets, right?
[01:14:54.020 --> 01:14:56.680]   And show that he's very left-leaning
[01:14:56.680 --> 01:15:01.200]   and very DEI supportive and that's the end of the world.
[01:15:01.200 --> 01:15:02.240]   - It's not the end of the world,
[01:15:02.240 --> 01:15:07.240]   but Google's so much dependent on trust,
[01:15:07.240 --> 01:15:13.000]   that trust that Google search has as objective as possible
[01:15:13.400 --> 01:15:17.240]   a channel into the world of information.
[01:15:17.240 --> 01:15:18.880]   And so that brand is really important.
[01:15:18.880 --> 01:15:22.640]   - Yeah, see, you're over, you're giving them too much power.
[01:15:22.640 --> 01:15:25.360]   And maybe I'm not recognizing the power, right?
[01:15:25.360 --> 01:15:27.680]   So I'll tell you a personal experience.
[01:15:27.680 --> 01:15:33.320]   Up until a month ago maybe,
[01:15:33.320 --> 01:15:38.320]   if you put in keto gummies, Shark Tank keto gummies,
[01:15:39.500 --> 01:15:44.500]   into Google, it would show up with scammy ads,
[01:15:44.500 --> 01:15:45.740]   scam ad after scam ad.
[01:15:45.740 --> 01:15:48.980]   And I would get emails up until a month ago
[01:15:48.980 --> 01:15:53.980]   from elderly people asking me why the gummies weren't working
[01:15:53.980 --> 01:15:58.140]   and why the companies were charging all this money
[01:15:58.140 --> 01:16:00.460]   on a month-by-month basis when they tried to cancel.
[01:16:00.460 --> 01:16:03.000]   And they said it was the number one deal
[01:16:03.000 --> 01:16:04.820]   on Shark Tank of all time, right?
[01:16:04.820 --> 01:16:07.860]   And all Shark, it was a mistake.
[01:16:07.860 --> 01:16:10.380]   - Well, there's fraud, there's mistakes,
[01:16:10.380 --> 01:16:12.600]   but the mistakes--
[01:16:12.600 --> 01:16:14.780]   - No, but why didn't Google fix it, right?
[01:16:14.780 --> 01:16:16.920]   The distance didn't happen once over one week,
[01:16:16.920 --> 01:16:18.260]   over two weeks, right?
[01:16:18.260 --> 01:16:20.300]   And because it was hard to fix.
[01:16:20.300 --> 01:16:22.520]   As it turns out, I was working with them
[01:16:22.520 --> 01:16:23.900]   to try to find a fix.
[01:16:23.900 --> 01:16:26.460]   And we would both look at the same page.
[01:16:26.460 --> 01:16:29.140]   And if you were inside of Google
[01:16:29.140 --> 01:16:32.980]   within the google.com domain, it would show one page.
[01:16:32.980 --> 01:16:34.980]   If you were outside of Google, it would show another.
[01:16:34.980 --> 01:16:37.000]   And it took us looking at it at the same time
[01:16:37.000 --> 01:16:38.680]   for anybody to realize it.
[01:16:38.680 --> 01:16:40.500]   Meaning that there's a lot of technology problems
[01:16:40.500 --> 01:16:41.460]   that are hard to fix.
[01:16:41.460 --> 01:16:43.860]   - They're super complex, and we could talk about it forever
[01:16:43.860 --> 01:16:45.420]   with social media.
[01:16:45.420 --> 01:16:48.000]   The criticism towards Google, towards other companies,
[01:16:48.000 --> 01:16:49.980]   when they're based in Silicon Valley,
[01:16:49.980 --> 01:16:51.780]   there could be an ideological drift
[01:16:51.780 --> 01:16:55.740]   into a ideological bubble
[01:16:55.740 --> 01:16:57.340]   out of which the technology is created,
[01:16:57.340 --> 01:17:00.380]   and they could be blind to the obvious bias
[01:17:00.380 --> 01:17:02.340]   that comes inherent to them.
[01:17:02.340 --> 01:17:03.740]   - Yeah, but they've got billions of customers
[01:17:03.740 --> 01:17:05.700]   who are not gonna, so what you're saying is
[01:17:05.700 --> 01:17:08.820]   the free market stops with artificial intelligence,
[01:17:08.820 --> 01:17:12.000]   that people don't pay attention and respond,
[01:17:12.000 --> 01:17:14.460]   that Google doesn't listen to the responses,
[01:17:14.460 --> 01:17:15.880]   that people inside of Google
[01:17:15.880 --> 01:17:18.760]   will ignore their own best financial interest,
[01:17:18.760 --> 01:17:20.760]   and even their own best personal interest,
[01:17:20.760 --> 01:17:22.480]   'cause they know they're gonna get doxed now
[01:17:22.480 --> 01:17:24.680]   on by Elon and others.
[01:17:24.680 --> 01:17:26.960]   And so I just don't see that.
[01:17:26.960 --> 01:17:29.320]   And Elon's not allowed to make those same mistakes,
[01:17:29.320 --> 01:17:30.160]   but-- - No, no, no, no.
[01:17:30.160 --> 01:17:32.200]   - Elon is allowed to make those mistakes,
[01:17:32.200 --> 01:17:33.040]   but Google isn't.
[01:17:33.040 --> 01:17:36.340]   - Oh, no, Elon is 100%, should be criticized
[01:17:36.340 --> 01:17:38.820]   for the ridiculousness of overstatements
[01:17:38.820 --> 01:17:41.540]   that he makes about various products.
[01:17:41.540 --> 01:17:43.740]   He's having a bit of fun, like you are also.
[01:17:43.740 --> 01:17:46.980]   But, and I also believe in the free market,
[01:17:46.980 --> 01:17:49.660]   but it's not always efficient.
[01:17:49.660 --> 01:17:50.500]   There's like a delay.
[01:17:50.500 --> 01:17:52.240]   - Just takes time, yeah, it's fine.
[01:17:52.240 --> 01:17:53.820]   - So which is why Elon is important.
[01:17:53.820 --> 01:17:55.100]   We're calling out, I think,
[01:17:55.100 --> 01:17:57.220]   overstating the criticism of Gemini,
[01:17:57.220 --> 01:17:58.820]   but Elon and others are just--
[01:17:58.820 --> 01:17:59.660]   - Gemini wasn't even
[01:17:59.680 --> 01:18:03.120]   a fully available public product yet.
[01:18:03.120 --> 01:18:06.160]   - It's still a bias that resonates with people--
[01:18:06.160 --> 01:18:08.440]   - That's the way neural networks work, though, right?
[01:18:08.440 --> 01:18:10.140]   That's why there'll be millions of models,
[01:18:10.140 --> 01:18:13.480]   because weights and biases, (laughs)
[01:18:13.480 --> 01:18:15.880]   putting together a neural network.
[01:18:15.880 --> 01:18:20.880]   - But, well, no, so like the black George Washington
[01:18:20.880 --> 01:18:25.920]   is a correction on top of the foundation model
[01:18:25.920 --> 01:18:28.260]   to keep it, quote, unquote, sort of safe.
[01:18:28.260 --> 01:18:32.440]   One of the big criticisms of all of the models, frankly,
[01:18:32.440 --> 01:18:34.880]   probably even Grok, a little bit less so,
[01:18:34.880 --> 01:18:38.160]   is they're like trying to be really conservative
[01:18:38.160 --> 01:18:41.240]   in the sense of trying to be careful
[01:18:41.240 --> 01:18:42.640]   not to say crazy shit.
[01:18:42.640 --> 01:18:43.480]   - Of course.
[01:18:43.480 --> 01:18:44.320]   - Because we don't know how the thing--
[01:18:44.320 --> 01:18:46.960]   - It's brand new, and we know what happens, right?
[01:18:46.960 --> 01:18:49.200]   And they do it on the front end with prompts,
[01:18:49.200 --> 01:18:50.640]   and they try to do it on the back end
[01:18:50.640 --> 01:18:53.920]   with the neural networks that are underneath them, right?
[01:18:53.920 --> 01:18:55.620]   And it doesn't always work,
[01:18:55.620 --> 01:18:57.700]   and that's why there's gonna be millions of models
[01:18:57.700 --> 01:19:00.560]   rather than just four foundational models
[01:19:00.560 --> 01:19:02.760]   or five that everybody uses.
[01:19:02.760 --> 01:19:04.480]   - Well, I guess the main criticism
[01:19:04.480 --> 01:19:06.560]   is you want to have some transparency
[01:19:06.560 --> 01:19:07.920]   of all the teams that are involved
[01:19:07.920 --> 01:19:10.480]   and that this kind of, to the degree
[01:19:10.480 --> 01:19:15.280]   there's a left-leaning ideology within the companies,
[01:19:15.280 --> 01:19:16.640]   it doesn't affect the product.
[01:19:16.640 --> 01:19:17.760]   - But that's the beauty of--
[01:19:17.760 --> 01:19:18.600]   - The free market.
[01:19:18.600 --> 01:19:20.960]   - Yeah, that's where the market corrects it, right?
[01:19:20.960 --> 01:19:23.520]   And not only from the outside,
[01:19:23.520 --> 01:19:25.920]   because everybody you know is going to test it.
[01:19:25.920 --> 01:19:27.760]   Like when YouTube first came out,
[01:19:27.760 --> 01:19:30.380]   well, not first came out, after Google bought them,
[01:19:30.380 --> 01:19:34.760]   there used to be different commands you could give it,
[01:19:34.760 --> 01:19:38.360]   right, there were prompt commands that you could give it,
[01:19:38.360 --> 01:19:40.840]   and you could find all the nasty porn
[01:19:40.840 --> 01:19:44.860]   that got loaded before they kicked it off, right?
[01:19:44.860 --> 01:19:47.400]   And it was just the nastiest shit ever,
[01:19:47.400 --> 01:19:49.000]   and even now to this day,
[01:19:49.000 --> 01:19:51.200]   if there's some horrific, tragic event,
[01:19:51.200 --> 01:19:53.360]   somebody's loading it up, right?
[01:19:53.360 --> 01:19:55.560]   Now, I know that's not direct to your point
[01:19:55.560 --> 01:19:58.800]   of internal influence to the output, right?
[01:19:58.800 --> 01:20:01.560]   But people on the outside are gonna check for that now,
[01:20:01.560 --> 01:20:04.080]   right, it's almost like the new bug contest, right,
[01:20:04.080 --> 01:20:06.040]   to try to find bugs in software.
[01:20:06.040 --> 01:20:09.260]   And then on the inside, if it's all left-leaning
[01:20:09.260 --> 01:20:11.440]   and all you have is left-leaning employees
[01:20:11.440 --> 01:20:14.920]   because most conservatives won't wanna work there then,
[01:20:14.920 --> 01:20:16.640]   again, that's self-correcting as well.
[01:20:16.640 --> 01:20:19.120]   - That's the hope, but it can self-correct
[01:20:19.120 --> 01:20:20.040]   in different kinds of ways.
[01:20:20.040 --> 01:20:22.680]   You can have a different company that competes
[01:20:22.680 --> 01:20:23.720]   and becomes more conservative.
[01:20:23.880 --> 01:20:27.040]   My worry is that it kind of becomes like two different worlds
[01:20:27.040 --> 01:20:28.960]   where there's like-- - It already is.
[01:20:28.960 --> 01:20:30.560]   - No, come on.
[01:20:30.560 --> 01:20:31.600]   - Don't give up.
[01:20:31.600 --> 01:20:32.920]   - Oh, I'm not giving up.
[01:20:32.920 --> 01:20:35.840]   So where does this go is the question, right?
[01:20:35.840 --> 01:20:37.840]   What happens next?
[01:20:37.840 --> 01:20:39.980]   And I mean, going back, I mean,
[01:20:39.980 --> 01:20:44.120]   I've been in so many PC revolutions, right, or evolutions
[01:20:44.120 --> 01:20:48.440]   where porn was the big issue, right?
[01:20:48.440 --> 01:20:50.240]   Now we don't even talk about porn being an issue
[01:20:50.240 --> 01:20:54.120]   even though every post on Twitter now
[01:20:54.120 --> 01:20:59.120]   has link in bio for a porn post, right?
[01:20:59.120 --> 01:21:01.220]   We don't even think that's a negative anymore.
[01:21:01.220 --> 01:21:02.840]   That's just an accepted thing.
[01:21:02.840 --> 01:21:07.840]   And now it's become very where your politics on Twitter.
[01:21:07.840 --> 01:21:12.840]   But again, as you extend that and things grow,
[01:21:12.840 --> 01:21:18.600]   as AI models become more efficient and trainable
[01:21:18.600 --> 01:21:20.440]   on less, for a lot less money,
[01:21:20.440 --> 01:21:22.880]   or even locally on a PC or a phone,
[01:21:22.880 --> 01:21:24.600]   we're all gonna have our own models.
[01:21:24.600 --> 01:21:27.000]   And there's gonna be millions and millions
[01:21:27.000 --> 01:21:29.640]   and millions of models and not just foundational models.
[01:21:29.640 --> 01:21:32.120]   Now maybe they're built some on open source,
[01:21:32.120 --> 01:21:36.480]   maybe it'll be copy-pasta where you can just cut and paste
[01:21:36.480 --> 01:21:39.720]   and create your own model and train it yourself.
[01:21:39.720 --> 01:21:41.560]   Maybe it'll be mixture of experts
[01:21:41.560 --> 01:21:43.560]   where maybe it'll be a meta front end
[01:21:43.560 --> 01:21:45.160]   like we're working on a project
[01:21:45.160 --> 01:21:48.120]   where we take 30 different AI models
[01:21:48.120 --> 01:21:50.040]   and there's just a meta search engine
[01:21:50.040 --> 01:21:51.680]   where it searches all of them
[01:21:51.680 --> 01:21:53.480]   and you can compare all the outputs
[01:21:53.480 --> 01:21:55.160]   and see what you think is the best,
[01:21:55.160 --> 01:21:56.760]   kind of like a search engine, right?
[01:21:56.760 --> 01:22:00.520]   Because you might get, is DEI good, right?
[01:22:00.520 --> 01:22:02.760]   Is the COVID vaccine good, right?
[01:22:02.760 --> 01:22:06.880]   You're gonna get a variety of outputs
[01:22:06.880 --> 01:22:09.640]   and you have to make that decision yourself.
[01:22:09.640 --> 01:22:11.500]   That's what I think is gonna happen with AI as well,
[01:22:11.500 --> 01:22:14.680]   because I think brands, there's no way the Mayo Clinic
[01:22:14.680 --> 01:22:17.560]   and the Harvard Medical School
[01:22:17.560 --> 01:22:19.800]   are just going to contribute all their IP
[01:22:19.800 --> 01:22:23.960]   to CHAP-GPT or Gemini or whatever.
[01:22:23.960 --> 01:22:25.080]   It's gonna have to be licensed
[01:22:25.080 --> 01:22:26.860]   or they're gonna do their own.
[01:22:26.860 --> 01:22:29.080]   - Yeah, I mean, that's a very hopeful message,
[01:22:29.080 --> 01:22:34.080]   but that said, human history
[01:22:34.080 --> 01:22:36.720]   doesn't always autocorrect really quickly,
[01:22:36.720 --> 01:22:38.280]   self-correct really quickly.
[01:22:38.280 --> 01:22:41.320]   Sometimes you get into this very painful things.
[01:22:41.320 --> 01:22:45.400]   You have Stalin, you have Hitler.
[01:22:45.400 --> 01:22:47.400]   You can get to places very quickly
[01:22:47.400 --> 01:22:49.920]   where the ideological thing just builds on itself.
[01:22:49.920 --> 01:22:52.920]   - But Twitter is not real world.
[01:22:52.920 --> 01:22:55.480]   You know, there's 27. - Twitter is not real world,
[01:22:55.480 --> 01:22:56.720]   that's true, yes.
[01:22:56.720 --> 01:23:00.720]   But you could still have a nation captured by an ideology.
[01:23:00.720 --> 01:23:03.880]   I think America has been really good
[01:23:03.880 --> 01:23:06.520]   at having these two blue and red
[01:23:06.520 --> 01:23:10.560]   always at tension with each other, dividing the populace.
[01:23:10.560 --> 01:23:14.240]   And in the process of doing that, figuring stuff out.
[01:23:14.240 --> 01:23:16.720]   Like almost like playing devil's advocate,
[01:23:16.720 --> 01:23:18.280]   but like in real life.
[01:23:18.280 --> 01:23:20.560]   - You know, and that's fair and that's right.
[01:23:20.560 --> 01:23:21.720]   You know, as opposed to Pravda
[01:23:21.720 --> 01:23:23.360]   telling you everything you wanna know, right?
[01:23:23.360 --> 01:23:24.640]   And everybody believing it
[01:23:24.640 --> 01:23:26.680]   'cause there's control of everything, right?
[01:23:26.680 --> 01:23:28.840]   And so going back to what you said earlier,
[01:23:28.840 --> 01:23:31.480]   people in Russia don't think invading Ukraine,
[01:23:31.480 --> 01:23:35.720]   a lot of them see it as a positive, right?
[01:23:35.720 --> 01:23:37.360]   I'm sure you have relatives and friends
[01:23:37.360 --> 01:23:40.400]   who think it's the best thing that ever happened, right?
[01:23:40.400 --> 01:23:42.480]   'Cause they believe in Putin.
[01:23:42.480 --> 01:23:44.280]   - They're denazifying Ukraine,
[01:23:44.280 --> 01:23:45.880]   they're removing the Nazis from Ukraine.
[01:23:45.880 --> 01:23:48.280]   - Right, right, 'cause that's exactly what Putin said.
[01:23:48.280 --> 01:23:53.280]   And you know, we don't have one uniform media outlet,
[01:23:53.280 --> 01:23:56.440]   that's the difference.
[01:23:56.440 --> 01:23:58.960]   Even though people like to talk about mainstream media
[01:23:58.960 --> 01:24:01.000]   as being the source of a lot of the friction,
[01:24:01.000 --> 01:24:03.360]   there is no such thing as mainstream media anymore.
[01:24:03.360 --> 01:24:07.840]   You know, Fox is the biggest cable news channel
[01:24:07.840 --> 01:24:09.720]   with the biggest audience,
[01:24:09.720 --> 01:24:12.280]   and they call everybody else mainstream media.
[01:24:12.280 --> 01:24:14.960]   You know, it's insane the things that we accept
[01:24:14.960 --> 01:24:16.720]   from our sources of information.
[01:24:16.720 --> 01:24:18.720]   To me, that's the bigger problem.
[01:24:18.720 --> 01:24:21.640]   The bigger problem is trying to figure out
[01:24:21.640 --> 01:24:22.760]   what is free speech
[01:24:22.760 --> 01:24:25.640]   and what is the line of tolerance for free speech.
[01:24:25.640 --> 01:24:28.400]   And at what point does hateful free speech
[01:24:28.400 --> 01:24:30.880]   crowd out other people, right?
[01:24:30.880 --> 01:24:32.360]   Putin's the master of that.
[01:24:32.360 --> 01:24:34.280]   You're going to jail or you're gonna be dead
[01:24:34.280 --> 01:24:35.800]   if you disagree, right?
[01:24:35.800 --> 01:24:38.960]   Now, God help us if we ever get to that point here,
[01:24:38.960 --> 01:24:41.880]   but the person who controls the algorithm
[01:24:41.880 --> 01:24:44.080]   controls the world, right?
[01:24:44.080 --> 01:24:48.840]   And if you are committed to one specific platform
[01:24:48.840 --> 01:24:51.280]   as your singular source of information
[01:24:51.280 --> 01:24:53.200]   or affiliated platforms,
[01:24:53.200 --> 01:24:56.720]   then whoever controls the algorithm or the programming there
[01:24:56.720 --> 01:24:59.040]   controls you in a lot of respects.
[01:24:59.040 --> 01:25:01.560]   And I think that's where our biggest problem has been.
[01:25:01.560 --> 01:25:05.480]   We get people attached to specific platforms
[01:25:05.480 --> 01:25:09.000]   and apps and media outlets,
[01:25:09.000 --> 01:25:11.920]   and they become part of that team
[01:25:11.920 --> 01:25:14.280]   and they identify as such,
[01:25:14.280 --> 01:25:16.880]   and either you're part of the team or you're not.
[01:25:16.880 --> 01:25:18.840]   And that to me is the fundamental problem.
[01:25:18.840 --> 01:25:22.400]   It's not woke ideology because I never felt any pressure
[01:25:22.400 --> 01:25:25.000]   to make the choices that I've chosen,
[01:25:25.000 --> 01:25:28.320]   and, you know, including diversity, equity, and inclusion.
[01:25:28.320 --> 01:25:31.480]   And I've never forced anybody or told anybody to do it.
[01:25:31.480 --> 01:25:33.280]   I just said, here's my experiences.
[01:25:33.280 --> 01:25:34.280]   Whenever I've talked to people
[01:25:34.280 --> 01:25:36.280]   and talk about the woke ideology,
[01:25:36.280 --> 01:25:37.280]   no one ever got forced.
[01:25:37.280 --> 01:25:41.180]   I mean, if you look at Dylan McDermott, right?
[01:25:41.180 --> 01:25:44.800]   If there was a way to gauge the number of impressions
[01:25:44.800 --> 01:25:48.560]   that she had, right, and where they sourced from,
[01:25:48.560 --> 01:25:50.080]   I'd be willing to bet any amount of money
[01:25:50.080 --> 01:25:53.720]   that 90% plus of the impressions and discussions
[01:25:53.720 --> 01:25:57.200]   of Dylan McDermott were on right-leaning media.
[01:25:57.200 --> 01:25:59.860]   - Several things, actually, let's even go there.
[01:25:59.860 --> 01:26:02.080]   You've gotten a bit of a beef with, again,
[01:26:02.080 --> 01:26:03.760]   fun with Jordan Peterson about this.
[01:26:03.760 --> 01:26:05.680]   - That's a guy whose name I couldn't think of, yeah.
[01:26:05.680 --> 01:26:08.760]   - So the topic there was the gender transition
[01:26:08.760 --> 01:26:10.400]   and Dylan Mulvaney.
[01:26:10.400 --> 01:26:12.560]   Hugh, can you explain the nature of the beef?
[01:26:12.560 --> 01:26:14.600]   I mean, it's an interesting claim you're making
[01:26:14.600 --> 01:26:18.480]   that most of the people who are concerned
[01:26:18.480 --> 01:26:20.360]   about this are conservatives.
[01:26:20.360 --> 01:26:24.320]   - Yeah, just the point is that if you looked at impressions,
[01:26:24.320 --> 01:26:25.240]   like when you run an ad,
[01:26:25.240 --> 01:26:28.600]   you're curious about impressions and who sees them, right?
[01:26:28.600 --> 01:26:29.800]   But if you look at the impressions
[01:26:29.800 --> 01:26:31.480]   related to Dylan McDermott,
[01:26:33.160 --> 01:26:34.360]   I would, like I just said,
[01:26:34.360 --> 01:26:37.720]   I'd bet 90% or more were in conservative media.
[01:26:37.720 --> 01:26:40.240]   And I don't know how many followers.
[01:26:40.240 --> 01:26:42.200]   She had 250,000 followers or whatever
[01:26:42.200 --> 01:26:44.020]   when the Bud Light ad came out.
[01:26:44.020 --> 01:26:49.020]   And if it weren't for Kid Rock shooting at Dylan McDermott
[01:26:49.020 --> 01:26:53.160]   Bud Light cans, she'd be long forgotten.
[01:26:53.160 --> 01:26:56.160]   - Yeah, but most of the people that care about censorship
[01:26:56.160 --> 01:26:57.520]   are gonna be free speech advocates.
[01:26:57.520 --> 01:27:02.000]   So most people that care about Putin suppressing speech
[01:27:02.000 --> 01:27:03.320]   or anybody else suppressing speech
[01:27:03.320 --> 01:27:05.520]   are going to be like libertarians.
[01:27:05.520 --> 01:27:08.840]   So there's probably an explanation to that.
[01:27:08.840 --> 01:27:12.560]   The criticism that Jordan Peterson could provide,
[01:27:12.560 --> 01:27:16.560]   I guess he said that Dylan Mulvaney popularized
[01:27:16.560 --> 01:27:21.240]   the kind of mutilation, right, in his view.
[01:27:21.240 --> 01:27:26.000]   They can affect, there's a very serious life-changing process
[01:27:26.000 --> 01:27:27.720]   that a person goes through.
[01:27:27.720 --> 01:27:29.960]   And when that's applied to a child,
[01:27:29.960 --> 01:27:31.680]   it can do a lot of harm to a person
[01:27:31.680 --> 01:27:34.320]   if- - But my point still holds.
[01:27:34.320 --> 01:27:36.720]   I don't know how many kids were following,
[01:27:36.720 --> 01:27:38.160]   and you can look at the followers list.
[01:27:38.160 --> 01:27:39.660]   It's not like it's hidden, right?
[01:27:39.660 --> 01:27:41.640]   Back then, if they had 250,000 followers,
[01:27:41.640 --> 01:27:42.840]   and now we're on TikTok,
[01:27:42.840 --> 01:27:47.920]   where he might get 50 some thousand views or likes, right?
[01:27:47.920 --> 01:27:50.680]   I don't know how many views, but likes.
[01:27:50.680 --> 01:27:54.800]   I've never seen any evidence that Dylan McDermott
[01:27:54.800 --> 01:27:58.360]   influenced people to transition their gender.
[01:27:58.360 --> 01:28:01.960]   As he transitioned to her, it was documented on TikTok
[01:28:01.960 --> 01:28:03.840]   over the course of a year.
[01:28:03.840 --> 01:28:07.300]   And again, when you go back and look at the views
[01:28:07.300 --> 01:28:12.300]   on those TikToks, it wasn't like enormous.
[01:28:12.300 --> 01:28:16.520]   - Yeah, but the trends start, right?
[01:28:16.520 --> 01:28:21.520]   It could be, whereas people, for young kids,
[01:28:21.520 --> 01:28:25.480]   there to be a trend of, especially when you feel
[01:28:25.480 --> 01:28:27.880]   like an outsider, you feel not yourself,
[01:28:27.880 --> 01:28:29.560]   less than yourself, all this kind of stuff
[01:28:29.560 --> 01:28:33.240]   that kids feel like, that if it's,
[01:28:33.240 --> 01:28:35.560]   because popular enough as a trend,
[01:28:35.560 --> 01:28:40.560]   you would gender transition without meaning to do that.
[01:28:40.560 --> 01:28:42.840]   It's just part of a trend.
[01:28:42.840 --> 01:28:44.120]   That's the worry they have. - Yeah, but that's
[01:28:44.120 --> 01:28:45.680]   a big stretch, right?
[01:28:45.680 --> 01:28:49.800]   To think that all the things that have to happen
[01:28:49.800 --> 01:28:52.360]   before you transition gender, right?
[01:28:52.360 --> 01:28:56.360]   And I'm not saying kids might identify,
[01:28:56.360 --> 01:29:01.360]   find it cool, or in the moment, expedient, if you will,
[01:29:01.360 --> 01:29:03.440]   to dress up as the other gender.
[01:29:03.440 --> 01:29:05.120]   Great, who cares, right?
[01:29:05.120 --> 01:29:08.440]   But to go through the actual physical transition,
[01:29:08.440 --> 01:29:11.160]   I don't remember what the numbers were that I read,
[01:29:11.160 --> 01:29:14.000]   but I do remember that the latest numbers
[01:29:14.000 --> 01:29:16.360]   that came out in terms of transitioning
[01:29:16.360 --> 01:29:19.720]   were from JAMA, which is a medical association,
[01:29:19.720 --> 01:29:24.720]   that said from 2021 to 2022, the numbers
[01:29:25.560 --> 01:29:29.520]   went down, but the bigger point is there are no numbers
[01:29:29.520 --> 01:29:32.480]   for 2023 when post-Dylan McDermott,
[01:29:32.480 --> 01:29:36.000]   so there's no way to know if the assertion is true,
[01:29:36.000 --> 01:29:37.280]   even marginally true.
[01:29:37.280 --> 01:29:41.000]   Now, you can easily suggest it, right?
[01:29:41.000 --> 01:29:44.360]   But you can say that about any social media influencer,
[01:29:44.360 --> 01:29:49.240]   right, you know, people are, kids are dying because,
[01:29:49.240 --> 01:29:51.800]   you know, I mean, it's just like when people
[01:29:51.800 --> 01:29:55.360]   accuse Trump of potentially influencing people
[01:29:55.360 --> 01:29:58.240]   to, you know, inject bleach into their veins.
[01:29:58.240 --> 01:30:01.880]   You can't, you know, that's a big old leap
[01:30:01.880 --> 01:30:04.200]   to say that because, you know, Trump says it,
[01:30:04.200 --> 01:30:06.680]   that people are gonna start injecting,
[01:30:06.680 --> 01:30:08.760]   and then they find somebody who actually did,
[01:30:08.760 --> 01:30:10.800]   and it's like, oh, it must be true, you know,
[01:30:10.800 --> 01:30:12.600]   this is a trend now.
[01:30:12.600 --> 01:30:15.840]   I just, I'm just not buying it that there aren't
[01:30:15.840 --> 01:30:18.600]   enough roadblocks in the way.
[01:30:18.600 --> 01:30:20.760]   Now, I'm not saying it never happens, right?
[01:30:20.760 --> 01:30:24.560]   And I, and for me, to me, you should have to wait
[01:30:24.560 --> 01:30:27.960]   until you're 18 to actually have any surgery to transition,
[01:30:27.960 --> 01:30:31.520]   and if your parents approve it earlier,
[01:30:31.520 --> 01:30:33.680]   then you can have a conversation with your doctor.
[01:30:33.680 --> 01:30:38.040]   But you're suggesting that everybody in that process
[01:30:38.040 --> 01:30:42.480]   to go to transition, a minor, is corrupt,
[01:30:42.480 --> 01:30:45.800]   that the doctor, the sociologist, the psychologist,
[01:30:45.800 --> 01:30:48.640]   all the people involved, the hospital where the surgery
[01:30:48.640 --> 01:30:52.000]   is happening, the insurance company that's paying for it,
[01:30:52.000 --> 01:30:54.160]   they all have been corrupted by this trend.
[01:30:54.160 --> 01:30:55.360]   I just don't see that.
[01:30:55.360 --> 01:30:57.560]   - Well, not corrupted, but you know, people,
[01:30:57.560 --> 01:31:00.480]   it's back to the DEI thing.
[01:31:00.480 --> 01:31:02.720]   There could be pressure, and we are--
[01:31:02.720 --> 01:31:05.160]   - Pressure to operate, so think about all the people
[01:31:05.160 --> 01:31:07.720]   who have to be complicit to do an operation.
[01:31:07.720 --> 01:31:09.840]   - It's not complicit like evil complicit, it's more--
[01:31:09.840 --> 01:31:11.440]   - No, it is evil complicit, right?
[01:31:11.440 --> 01:31:15.720]   Because somebody, in hospitals right now,
[01:31:15.720 --> 01:31:18.880]   they won't perform abortions because of state law.
[01:31:18.880 --> 01:31:22.840]   In Alabama, they stopped IVF treatment immediately
[01:31:22.840 --> 01:31:25.800]   after that ruling by that judge, right?
[01:31:25.800 --> 01:31:27.280]   The QAnon judge.
[01:31:27.280 --> 01:31:30.440]   To think that they're not gonna pay attention
[01:31:30.440 --> 01:31:33.320]   to the possible consequences of being the hospital
[01:31:33.320 --> 01:31:37.080]   that does transgender, that gives doctors
[01:31:37.080 --> 01:31:40.920]   operating rights there, and not be aware of the risks
[01:31:40.920 --> 01:31:42.920]   associated with it and double-check,
[01:31:42.920 --> 01:31:44.000]   to me, that's just insane.
[01:31:44.000 --> 01:31:46.600]   They're risking their entire business and livelihood
[01:31:46.600 --> 01:31:49.800]   and personal relationships for not checking
[01:31:49.800 --> 01:31:53.720]   that this 14-year-old boy who wants to be a girl
[01:31:53.720 --> 01:31:57.560]   or vice versa is there waiting for surgery.
[01:31:57.560 --> 01:31:58.400]   I just don't see that.
[01:31:58.400 --> 01:32:02.200]   - In America, yes, but if we look at humans in general,
[01:32:02.200 --> 01:32:05.880]   and Jordan Peterson, I think,
[01:32:05.880 --> 01:32:08.840]   unjustly, incorrectly brought up Auschwitz.
[01:32:08.840 --> 01:32:10.520]   - Yeah, that was ridiculous.
[01:32:10.520 --> 01:32:15.240]   - But if we look, to me, World War II
[01:32:15.240 --> 01:32:16.760]   is a very interesting time.
[01:32:16.760 --> 01:32:19.440]   It does reveal a lot about human nature
[01:32:19.440 --> 01:32:22.760]   and that humans are able to commit atrocities
[01:32:22.760 --> 01:32:24.400]   without really speaking up.
[01:32:24.400 --> 01:32:27.800]   The point I wanna make is that when you're
[01:32:27.800 --> 01:32:31.920]   in this situation where everybody around you
[01:32:31.920 --> 01:32:35.040]   is committing an atrocity, you can be sort of
[01:32:35.040 --> 01:32:40.040]   the good German, and human nature is such that you can--
[01:32:40.240 --> 01:32:43.560]   - But that is in a time of war.
[01:32:43.560 --> 01:32:46.480]   - Yeah, but it's still human nature.
[01:32:46.480 --> 01:32:47.320]   It's interesting to remember that.
[01:32:47.320 --> 01:32:49.120]   - It's in a time of war.
[01:32:49.120 --> 01:32:52.080]   When you feel like there's nationalism, patriotism,
[01:32:52.080 --> 01:32:53.320]   everything that comes up.
[01:32:53.320 --> 01:32:54.160]   Russia, right?
[01:32:54.160 --> 01:32:59.600]   The moms of the kids sent to Ukraine who didn't come back
[01:32:59.600 --> 01:33:01.040]   in Russia feel certainly different
[01:33:01.040 --> 01:33:04.600]   than the everyday Russian who's just taking
[01:33:04.600 --> 01:33:06.000]   whatever information that's available
[01:33:06.000 --> 01:33:07.920]   from a unified, controlled media.
[01:33:07.920 --> 01:33:11.520]   - Yeah, but we should remember human nature.
[01:33:11.520 --> 01:33:12.360]   It's interesting.
[01:33:12.360 --> 01:33:13.720]   - I'm not dismissing human nature at all,
[01:33:13.720 --> 01:33:15.680]   but there's a difference.
[01:33:15.680 --> 01:33:18.560]   I think that human nature, self-preservation,
[01:33:18.560 --> 01:33:20.000]   influences those decisions.
[01:33:20.000 --> 01:33:22.120]   There's nothing about self-preservation
[01:33:22.120 --> 01:33:26.740]   involved in DEI, wokeness, transgenderism
[01:33:26.740 --> 01:33:28.360]   to compare it to Auschwitz.
[01:33:28.360 --> 01:33:29.640]   That's insane.
[01:33:29.640 --> 01:33:32.360]   - Yeah, well, that comparison is almost always,
[01:33:32.360 --> 01:33:34.080]   probably always is insane.
[01:33:34.080 --> 01:33:37.040]   Comparison between anything and the Holocaust.
[01:33:37.040 --> 01:33:37.880]   - I agree.
[01:33:37.880 --> 01:33:39.080]   - There's a name for that rule,
[01:33:39.080 --> 01:33:43.080]   but once you bring up Hitler, the conversation ends.
[01:33:43.080 --> 01:33:44.920]   I do appreciate you bringing up Trump
[01:33:44.920 --> 01:33:46.420]   and bleach as an example.
[01:33:46.420 --> 01:33:51.400]   So continuing on fun exchanges between you and Elon,
[01:33:51.400 --> 01:33:54.480]   you said if they were having Biden's last wake
[01:33:54.480 --> 01:33:56.360]   and it was him versus Trump
[01:33:56.360 --> 01:33:58.600]   and he was being given last rights,
[01:33:58.600 --> 01:34:00.360]   I would still vote for Biden.
[01:34:00.360 --> 01:34:03.920]   To which Elon replied, caricaturing you,
[01:34:03.920 --> 01:34:06.280]   if Biden were a flesh-eating zombie
[01:34:06.280 --> 01:34:10.440]   with five seconds to live or upon being reelected,
[01:34:10.440 --> 01:34:13.480]   Earth would plunge into a 1,000 years of darkness,
[01:34:13.480 --> 01:34:15.020]   I would still vote for him.
[01:34:15.020 --> 01:34:20.000]   That's basically quoting you, but in a caricature.
[01:34:20.000 --> 01:34:21.000]   And you responded,
[01:34:21.000 --> 01:34:25.480]   while I have your attention, wanted to say thank you.
[01:34:25.480 --> 01:34:27.320]   Your consultants at Tesla followed up
[01:34:27.320 --> 01:34:30.680]   about using cost-plus drugs,
[01:34:30.680 --> 01:34:32.000]   about which we'll talk about,
[01:34:32.000 --> 01:34:33.480]   to save the company money.
[01:34:33.480 --> 01:34:35.040]   Truly appreciate it.
[01:34:35.040 --> 01:34:39.680]   And in parentheses, my limit is 300 years of darkness.
[01:34:39.680 --> 01:34:41.720]   Very well done, Mark.
[01:34:41.720 --> 01:34:42.760]   What's your intuition,
[01:34:42.760 --> 01:34:45.760]   if we just stick on Biden and Trump for a sec,
[01:34:45.760 --> 01:34:47.080]   what's your intuition why Biden
[01:34:47.080 --> 01:34:48.800]   would make a better president than Trump?
[01:34:48.800 --> 01:34:51.040]   - Look at the basics, right?
[01:34:51.040 --> 01:34:52.880]   If you look at the people he's hired,
[01:34:52.880 --> 01:34:58.480]   there hasn't been any turnover in his cabinet at all.
[01:34:58.480 --> 01:35:01.000]   If you look at the people he's hired
[01:35:01.000 --> 01:35:02.960]   over the course of his career,
[01:35:02.960 --> 01:35:05.440]   or while he was vice president in particular,
[01:35:05.440 --> 01:35:07.240]   there's nobody who's turned on him
[01:35:07.240 --> 01:35:09.000]   and came out and written books
[01:35:09.000 --> 01:35:10.680]   and made public statements
[01:35:10.680 --> 01:35:12.800]   about how he's bad for the country.
[01:35:12.800 --> 01:35:14.920]   Now compare that to Trump.
[01:35:14.920 --> 01:35:16.500]   The people closest to him,
[01:35:16.500 --> 01:35:20.160]   almost all of them turn,
[01:35:20.160 --> 01:35:23.200]   unless there's a financial relationship involved.
[01:35:23.200 --> 01:35:26.040]   And to me, that says everything.
[01:35:26.040 --> 01:35:27.880]   - The dynamics of the team is important to you.
[01:35:27.880 --> 01:35:30.120]   - If you're gonna be the most powerful person in the world,
[01:35:30.120 --> 01:35:32.600]   you better know how to manage and lead.
[01:35:32.600 --> 01:35:37.600]   And that's not to say Biden hasn't made a lot of mistakes.
[01:35:37.600 --> 01:35:41.060]   I mean, immigration, the border, is a horrific mistake.
[01:35:41.060 --> 01:35:44.560]   And hopefully he recognizes that.
[01:35:44.560 --> 01:35:46.920]   And I don't like the fact that he doesn't admit his mistakes
[01:35:46.920 --> 01:35:48.760]   and just say, "Okay, I gotta fix it,"
[01:35:48.760 --> 01:35:50.000]   or, "I made a mistake in Afghanistan,"
[01:35:50.000 --> 01:35:51.600]   whatever it may be, right?
[01:35:51.600 --> 01:35:57.400]   The position of commander in chief and president,
[01:35:57.400 --> 01:35:59.560]   you're gonna make mistakes.
[01:35:59.560 --> 01:36:01.360]   Then I look at the other guy,
[01:36:01.360 --> 01:36:04.600]   never miss a mistake, and the list is long.
[01:36:04.600 --> 01:36:06.600]   - What do you think about the immigration situation?
[01:36:06.600 --> 01:36:08.840]   A lot of conservatives are using that,
[01:36:08.840 --> 01:36:15.320]   sort of the theory is that the reason it's happening
[01:36:15.320 --> 01:36:19.640]   is because they would be able to illegally vote.
[01:36:19.640 --> 01:36:20.480]   - That's insane.
[01:36:20.480 --> 01:36:21.300]   - For Biden.
[01:36:21.300 --> 01:36:24.160]   - Yeah, you can't be an illegal immigrant and vote.
[01:36:24.160 --> 01:36:26.980]   And now, in a lot of states, because of the conservatives,
[01:36:26.980 --> 01:36:29.280]   they've passed laws saying you have to show identification.
[01:36:29.280 --> 01:36:30.640]   When I voted in Texas,
[01:36:30.640 --> 01:36:34.600]   you had to show state identification.
[01:36:34.600 --> 01:36:35.440]   They can't vote.
[01:36:35.440 --> 01:36:37.000]   You can't register as an illegal alien
[01:36:37.000 --> 01:36:39.240]   that I'm aware of to vote.
[01:36:39.240 --> 01:36:42.240]   - Yeah, but of course, that story really worries me,
[01:36:42.240 --> 01:36:46.280]   enables or serves as a catalyst
[01:36:46.280 --> 01:36:49.360]   for questioning the legitimacy of an election.
[01:36:49.360 --> 01:36:53.640]   - I remember going to the debate with Trump in 2016,
[01:36:53.640 --> 01:36:55.080]   and he was debating Clinton,
[01:36:55.080 --> 01:36:57.680]   and one of the things he said was,
[01:36:57.680 --> 01:36:59.680]   "We don't even know if this election
[01:36:59.680 --> 01:37:01.560]   will be legitimate if I lose."
[01:37:01.560 --> 01:37:04.720]   This was in 2016 before he was even elected,
[01:37:04.720 --> 01:37:06.320]   and that was where he was going.
[01:37:06.320 --> 01:37:07.800]   That's just what he does.
[01:37:07.800 --> 01:37:09.640]   He's never admitted a mistake.
[01:37:09.640 --> 01:37:11.120]   The guy's failed a zillion times.
[01:37:11.120 --> 01:37:13.320]   Most people say, "Okay, I learned from him."
[01:37:13.320 --> 01:37:16.080]   I read a book about Roy Cohn,
[01:37:16.080 --> 01:37:19.440]   and Roy Cohn was the ultimate deny, deny, deny,
[01:37:19.440 --> 01:37:21.280]   and that was one of Trump's mentors.
[01:37:21.280 --> 01:37:25.240]   And you can see almost everything Roy Cohn ever did
[01:37:25.240 --> 01:37:27.720]   in the same way that Donald Trump approaches things.
[01:37:27.720 --> 01:37:30.820]   - But given how drastic the immigration situation is,
[01:37:30.820 --> 01:37:33.400]   that story becomes more believable.
[01:37:33.400 --> 01:37:34.400]   - Yeah, of course it does, right?
[01:37:34.400 --> 01:37:36.600]   But the facts are still the facts, right?
[01:37:36.600 --> 01:37:40.680]   And in red states, they're gonna be checking every ID.
[01:37:40.680 --> 01:37:42.800]   They're gonna be making sure that's not the case,
[01:37:42.800 --> 01:37:44.960]   and you can also make the argument,
[01:37:44.960 --> 01:37:46.200]   well, in a blue state, it doesn't matter.
[01:37:46.200 --> 01:37:49.040]   In the swing states, they're still gonna be checking
[01:37:49.040 --> 01:37:50.960]   'cause they know Trump is gonna sue the shit out of him
[01:37:50.960 --> 01:37:52.640]   when he loses, you know?
[01:37:52.640 --> 01:37:56.720]   And so, again, that's where, you know,
[01:37:56.720 --> 01:37:59.880]   people will take those self-preservation steps
[01:37:59.880 --> 01:38:01.520]   to keep their job and do the right thing.
[01:38:01.520 --> 01:38:04.720]   There's still enough people who believe in this country
[01:38:04.720 --> 01:38:07.440]   and how amazing it is to do the right thing.
[01:38:07.440 --> 01:38:08.560]   And a lot of the premises
[01:38:08.560 --> 01:38:12.360]   of what some conservatives are saying and doing,
[01:38:12.360 --> 01:38:15.960]   the underpinning of it is that their fellow citizens
[01:38:15.960 --> 01:38:18.920]   will not do anything, not some things,
[01:38:18.920 --> 01:38:22.720]   anything that serves the best interest of this country.
[01:38:22.720 --> 01:38:24.480]   And to me, that's just wrong.
[01:38:24.480 --> 01:38:27.120]   You know, that is just misleading and wrong.
[01:38:27.120 --> 01:38:30.960]   - I just worry about, I don't care about Trump or Biden.
[01:38:30.960 --> 01:38:33.200]   I care about democracy.
[01:38:33.200 --> 01:38:34.480]   I just worry.
[01:38:34.480 --> 01:38:36.920]   I worry about the viral nature of the idea
[01:38:36.920 --> 01:38:38.600]   of this illegal immigrants.
[01:38:38.600 --> 01:38:41.800]   - But it's just, it's very functional, right?
[01:38:41.800 --> 01:38:46.080]   Either they get across, there's 1,000 different ways to,
[01:38:46.080 --> 01:38:47.320]   an unlimited number of ways
[01:38:47.320 --> 01:38:50.320]   to enter the United States of America undetected, right?
[01:38:50.320 --> 01:38:53.080]   And the South border where it's the easiest and the worst.
[01:38:53.080 --> 01:38:55.520]   And Biden needs to take steps to reduce that.
[01:38:55.520 --> 01:38:57.560]   Remember, when Biden was vice president
[01:38:57.560 --> 01:38:59.940]   and Obama was president,
[01:38:59.940 --> 01:39:02.920]   they called Obama the deporter-in-chief.
[01:39:02.920 --> 01:39:05.480]   He had no problem deporting people.
[01:39:05.480 --> 01:39:08.800]   And I think if I had to guess, and this is just a guess,
[01:39:08.800 --> 01:39:11.480]   that when they looked at the initial statistics
[01:39:11.480 --> 01:39:13.600]   for immigration when Biden took over,
[01:39:13.600 --> 01:39:16.200]   they thought there was room for more immigrants,
[01:39:16.200 --> 01:39:17.680]   not because they would vote,
[01:39:17.680 --> 01:39:20.520]   but you can make a fiscal argument
[01:39:20.520 --> 01:39:25.520]   that in a world where the birth rate is flat to declining,
[01:39:25.520 --> 01:39:29.040]   we need immigrants, right?
[01:39:29.040 --> 01:39:34.040]   And immigrants typically don't have a higher crime rate
[01:39:34.040 --> 01:39:37.800]   or anything than indigenous American citizens.
[01:39:37.800 --> 01:39:40.500]   Indigenous isn't the right word, but American citizens.
[01:39:40.500 --> 01:39:44.440]   And so they made a calculated mistake.
[01:39:44.440 --> 01:39:45.680]   They made a decision that was wrong.
[01:39:45.680 --> 01:39:47.080]   And now they have to fix it
[01:39:47.080 --> 01:39:48.320]   or it's gonna hurt them severely.
[01:39:48.320 --> 01:39:51.160]   But I don't buy what Elon's pushing,
[01:39:51.160 --> 01:39:55.440]   that the whole reason is they are voters
[01:39:55.440 --> 01:39:57.040]   and will become voters.
[01:39:57.040 --> 01:40:00.280]   - And we should say the obvious.
[01:40:00.280 --> 01:40:01.920]   You're a descendant of immigrants.
[01:40:01.920 --> 01:40:02.760]   - Yeah, for sure.
[01:40:02.760 --> 01:40:05.640]   - And the immigrants is what makes this country great
[01:40:05.640 --> 01:40:07.960]   in many parts, the diversity of this nation.
[01:40:07.960 --> 01:40:09.400]   And we should probably keep the people
[01:40:09.400 --> 01:40:12.440]   that are already been in this country for a while
[01:40:12.440 --> 01:40:16.200]   and are killing it, like PhD students and all this.
[01:40:16.200 --> 01:40:17.800]   - That's not what Donald Trump wants, though.
[01:40:17.800 --> 01:40:20.000]   He wants to ship them all out, right?
[01:40:20.000 --> 01:40:21.880]   There's just a whole lot of hyperbole
[01:40:21.880 --> 01:40:25.080]   when it comes to talking about all of these things
[01:40:25.080 --> 01:40:25.960]   we're talking about.
[01:40:25.960 --> 01:40:30.400]   When it's right versus left, my team versus your team,
[01:40:30.400 --> 01:40:32.240]   my tribe versus your tribe,
[01:40:32.240 --> 01:40:34.440]   the only way to stand out is hyperbole.
[01:40:34.440 --> 01:40:36.600]   The hard part, and why I like this conversation,
[01:40:36.600 --> 01:40:40.240]   is how do you distinguish hyperbole versus reality?
[01:40:40.240 --> 01:40:41.840]   And I get where you're going, Lex,
[01:40:41.840 --> 01:40:46.840]   where it's like the smallest spark sometimes
[01:40:46.840 --> 01:40:50.760]   can cause people to change,
[01:40:50.760 --> 01:40:52.520]   and then that spark becomes bigger,
[01:40:52.520 --> 01:40:56.000]   and then it becomes more widespread.
[01:40:56.000 --> 01:40:58.400]   And then all of a sudden, your country has changed.
[01:40:58.400 --> 01:40:59.960]   It's not what you thought it was.
[01:40:59.960 --> 01:41:01.680]   I get that completely, right?
[01:41:01.680 --> 01:41:05.480]   And yes, you always have to be on top of that to make sure.
[01:41:05.480 --> 01:41:08.120]   But a lot of that comes from lack of leadership, right?
[01:41:08.120 --> 01:41:09.280]   And lack of trust.
[01:41:09.320 --> 01:41:11.840]   Because there's nobody who's saying,
[01:41:11.840 --> 01:41:14.680]   "All right, Republicans, that's all hyperbole,
[01:41:14.680 --> 01:41:15.840]   "and you're wrong for that.
[01:41:15.840 --> 01:41:18.760]   "Democrats, you fucked up on immigration, right?
[01:41:18.760 --> 01:41:21.080]   "You fucked up in Afghanistan, right?
[01:41:21.080 --> 01:41:23.520]   "Here's where you made these mistakes, own it."
[01:41:23.520 --> 01:41:24.760]   There's nobody who says,
[01:41:24.760 --> 01:41:28.360]   "We're not gonna just bring in Republicans
[01:41:28.360 --> 01:41:29.680]   "if the Republicans win."
[01:41:29.680 --> 01:41:31.480]   And then, you know, and there's nobody who says,
[01:41:31.480 --> 01:41:33.040]   "We're not gonna just bring in Democrats.
[01:41:33.040 --> 01:41:34.720]   "We're gonna bring in a mix, right?
[01:41:34.720 --> 01:41:37.280]   "We're gonna try to get balance on the Supreme Court."
[01:41:37.280 --> 01:41:39.480]   There's just, there's no leadership that's doing it.
[01:41:39.480 --> 01:41:41.200]   That's the fundamental problem.
[01:41:41.200 --> 01:41:43.760]   It's not about the ideology of woke, it's not the,
[01:41:43.760 --> 01:41:45.160]   no leadership.
[01:41:45.160 --> 01:41:48.200]   - Yeah, leadership, and yeah, there's just,
[01:41:48.200 --> 01:41:50.080]   whatever systems we've created,
[01:41:50.080 --> 01:41:53.520]   it's really frustrating that if you don't like Trump,
[01:41:53.520 --> 01:41:55.840]   it really is Trump derangement syndrome.
[01:41:55.840 --> 01:41:58.320]   Like, he's definitely Hitler.
[01:41:58.320 --> 01:42:01.720]   If you don't like Biden, he's senile lizard person.
[01:42:01.720 --> 01:42:02.560]   - Right.
[01:42:02.560 --> 01:42:06.040]   Everybody gets labeled, right?
[01:42:06.040 --> 01:42:07.840]   Because that works on social media.
[01:42:07.840 --> 01:42:11.360]   That, look, if Elon changed the algorithm
[01:42:11.360 --> 01:42:14.920]   just by taking himself out of it,
[01:42:14.920 --> 01:42:16.720]   seriously, I'm not saying don't post, right?
[01:42:16.720 --> 01:42:18.080]   Post all you want.
[01:42:18.080 --> 01:42:20.880]   But he, you know, if you look at his followers,
[01:42:20.880 --> 01:42:24.000]   they're almost all right-leaning.
[01:42:24.000 --> 01:42:26.560]   If you look at the people he engages with positively,
[01:42:26.560 --> 01:42:28.520]   they're almost all right-leaning.
[01:42:28.520 --> 01:42:29.360]   And if you look at the people
[01:42:29.360 --> 01:42:32.440]   he engages with negatively, like me, right?
[01:42:32.440 --> 01:42:34.440]   I consider myself an independent,
[01:42:34.440 --> 01:42:37.760]   but I lean left on the DEI topic, right?
[01:42:37.760 --> 01:42:40.640]   That influences the algorithm.
[01:42:40.640 --> 01:42:44.160]   And so you see what you see because of what he says.
[01:42:44.160 --> 01:42:46.360]   - Yeah, well, I mean, for sure,
[01:42:46.360 --> 01:42:51.320]   but there could be a lot of influential people on Twitter
[01:42:51.320 --> 01:42:53.720]   that influence the algorithm and all that kind of stuff.
[01:42:53.720 --> 01:42:57.320]   I do feel it's not even about ideology or where you lean.
[01:42:57.320 --> 01:43:01.360]   It's about, like, the algorithm not prioritizing drama.
[01:43:02.520 --> 01:43:07.440]   The attention-grabbing thing
[01:43:07.440 --> 01:43:09.920]   or the lower lizard version of that
[01:43:09.920 --> 01:43:11.800]   where, like, people just want the drama.
[01:43:11.800 --> 01:43:13.240]   They want to check it out.
[01:43:13.240 --> 01:43:15.520]   - When I last read through all the stuff
[01:43:15.520 --> 01:43:16.480]   on their algorithm, right?
[01:43:16.480 --> 01:43:17.720]   Maybe it's changed.
[01:43:17.720 --> 01:43:20.320]   Whoever has the biggest account
[01:43:20.320 --> 01:43:23.520]   and gets engagement on that account
[01:43:23.520 --> 01:43:26.660]   influences what people see the most.
[01:43:26.660 --> 01:43:27.600]   - Yeah, I mean, that's interesting.
[01:43:27.600 --> 01:43:29.500]   I don't know if that's, to the degree that's true,
[01:43:29.500 --> 01:43:30.340]   they've-
[01:43:30.340 --> 01:43:32.440]   - For sure, it's still the case.
[01:43:32.440 --> 01:43:34.660]   - Pretty rigorous description of what's,
[01:43:34.660 --> 01:43:37.480]   of the way the algorithm works.
[01:43:37.480 --> 01:43:38.680]   It's actually kind of fascinating.
[01:43:38.680 --> 01:43:41.040]   There's a clustering of people based on interest.
[01:43:41.040 --> 01:43:41.880]   - Right, but I think they call it
[01:43:41.880 --> 01:43:43.920]   the nearest neighbor approach,
[01:43:43.920 --> 01:43:44.920]   and I think that's what they do.
[01:43:44.920 --> 01:43:47.320]   And so whoever has the biggest account
[01:43:47.320 --> 01:43:49.520]   has the most neighbors who, in turn, have their neighbors
[01:43:49.520 --> 01:43:50.880]   who, in turn, have their neighbors,
[01:43:50.880 --> 01:43:53.520]   and that's how they discern what comes next.
[01:43:53.520 --> 01:43:54.800]   - But there's a clustering still.
[01:43:54.800 --> 01:43:57.440]   So, like, if you don't give a shit about Elon,
[01:43:57.440 --> 01:43:58.720]   you're not gonna- - And you're not following him.
[01:43:58.720 --> 01:43:59.560]   Yeah, you're not following him.
[01:43:59.560 --> 01:44:00.640]   - You're not gonna have an influence.
[01:44:00.640 --> 01:44:02.320]   He's not gonna have an influence.
[01:44:02.320 --> 01:44:04.520]   When you get a break, just create a Burner account
[01:44:04.520 --> 01:44:07.120]   on Twitter and see who they recommend to you.
[01:44:07.120 --> 01:44:08.160]   - Elon.
[01:44:08.160 --> 01:44:09.600]   - And not just Elon.
[01:44:09.600 --> 01:44:11.880]   I mean, the people that Elon likes.
[01:44:11.880 --> 01:44:13.920]   And I'm saying that's not Elon saying,
[01:44:13.920 --> 01:44:15.160]   add this person, add this person,
[01:44:15.160 --> 01:44:17.640]   and suggest this person, this person, and this person.
[01:44:17.640 --> 01:44:19.840]   I'm saying that's what the algorithm is.
[01:44:19.840 --> 01:44:21.680]   - Yeah, there should be transparency around that, for sure.
[01:44:21.680 --> 01:44:22.520]   - There is.
[01:44:22.520 --> 01:44:23.880]   There is, and that's the whole point, right?
[01:44:23.880 --> 01:44:26.480]   He knows there's transparency, and he knows the impact.
[01:44:26.480 --> 01:44:29.600]   That's why when I say take yourself out of the algorithm,
[01:44:29.600 --> 01:44:31.480]   right, don't include his account,
[01:44:31.480 --> 01:44:34.280]   that changes, I think, the output of the algorithm.
[01:44:34.280 --> 01:44:36.080]   - Well, when he wasn't owning Twitter,
[01:44:36.080 --> 01:44:37.400]   he was one of the biggest accounts,
[01:44:37.400 --> 01:44:39.080]   if not the biggest account already.
[01:44:39.080 --> 01:44:41.160]   - He wasn't, but still, like even like the Kim,
[01:44:41.160 --> 01:44:43.880]   well, the Kim Kardashian accounts, whatever, right?
[01:44:43.880 --> 01:44:48.280]   I don't, it wasn't open source to Elon's credit.
[01:44:48.280 --> 01:44:50.960]   It is now, so I couldn't see it to know, right?
[01:44:50.960 --> 01:44:52.640]   So I didn't get the sense one way or the other
[01:44:52.640 --> 01:44:55.560]   of one element being dominant over the other.
[01:44:55.560 --> 01:44:56.880]   But obviously conservatives felt
[01:44:56.880 --> 01:45:00.000]   that left-leaning was more dominant back then.
[01:45:00.000 --> 01:45:01.240]   - Yeah, I would love to see numbers
[01:45:01.240 --> 01:45:02.200]   on all of this.
[01:45:02.200 --> 01:45:04.080]   - Yeah, you'll be fun.
[01:45:04.080 --> 01:45:06.560]   - DEI, everything like this.
[01:45:06.560 --> 01:45:09.600]   Sometimes anecdotal data really frustrates me.
[01:45:09.600 --> 01:45:13.600]   It frustrates me primarily because of how sexy it is.
[01:45:13.600 --> 01:45:14.440]   People just love--
[01:45:14.440 --> 01:45:15.600]   - That's a great way to describe it, yeah.
[01:45:15.600 --> 01:45:17.840]   - Love a story, and I'm like goddammit,
[01:45:17.840 --> 01:45:20.240]   this is not science, this is--
[01:45:20.240 --> 01:45:21.960]   - It's not even common sense.
[01:45:21.960 --> 01:45:24.800]   - Well, no, I think anecdotal stories
[01:45:24.800 --> 01:45:27.120]   often have a wisdom in them.
[01:45:27.120 --> 01:45:28.160]   - No doubt, right.
[01:45:28.160 --> 01:45:30.320]   There's something to be gained from seeing them.
[01:45:30.320 --> 01:45:33.240]   There's a signal there, but how representative
[01:45:33.240 --> 01:45:35.040]   is that signal of the broader thing?
[01:45:35.040 --> 01:45:36.080]   - There's a whole lot more noise
[01:45:36.080 --> 01:45:37.440]   than signal more often than not.
[01:45:37.440 --> 01:45:40.960]   - All right, so as I mentioned, cost plus drugs.
[01:45:40.960 --> 01:45:42.440]   There's so many questions I can ask here,
[01:45:42.440 --> 01:45:45.400]   but what's the big question?
[01:45:45.400 --> 01:45:47.680]   What's broken about our healthcare system?
[01:45:47.680 --> 01:45:49.480]   - There's no transparency.
[01:45:49.480 --> 01:45:52.520]   And lack of transparency leads to lack of trust.
[01:45:52.520 --> 01:45:54.760]   And when you can't trust the healthcare system
[01:45:54.760 --> 01:45:58.240]   other than maybe your doctor, that's a broken system.
[01:45:58.240 --> 01:46:02.400]   - So what aspect of this system,
[01:46:02.400 --> 01:46:04.320]   this cost plus drugs is trying to solve?
[01:46:04.320 --> 01:46:07.680]   - So the thing we're trying to solve for is trust.
[01:46:07.680 --> 01:46:09.160]   And the way we feel we get there
[01:46:09.160 --> 01:46:11.080]   is through complete transparency.
[01:46:11.080 --> 01:46:13.120]   So when you go to costplusdrugs.com
[01:46:13.120 --> 01:46:14.740]   and you put in the name of the medication,
[01:46:14.740 --> 01:46:17.920]   if it's one of the 2,500 and growing that we carry,
[01:46:17.920 --> 01:46:21.800]   we will first show you our cost, what we actually pay for it,
[01:46:21.800 --> 01:46:24.000]   then we'll show you our 15% markup,
[01:46:24.000 --> 01:46:26.760]   then we'll show the pharmacy fill fee and shipping,
[01:46:26.760 --> 01:46:28.560]   and that's your total price.
[01:46:28.560 --> 01:46:31.920]   And that alone, that transparency alone
[01:46:31.920 --> 01:46:34.040]   is completely revolutionizing
[01:46:34.040 --> 01:46:37.200]   how drugs are priced in America today.
[01:46:37.200 --> 01:46:41.120]   And it's led to research being done
[01:46:41.120 --> 01:46:46.120]   comparing our pricing to CMS and ours being cheaper,
[01:46:46.120 --> 01:46:48.920]   then even the government is negotiating,
[01:46:48.920 --> 01:46:50.280]   et cetera, et cetera, et cetera.
[01:46:50.280 --> 01:46:55.280]   And so just that transparency alone has had an impact
[01:46:55.800 --> 01:46:57.840]   and saved millions of people
[01:46:57.840 --> 01:46:59.440]   hundreds of millions of dollars or more.
[01:46:59.440 --> 01:47:01.400]   - And maybe it results in more transparency
[01:47:01.400 --> 01:47:03.080]   in other parts of the system, too,
[01:47:03.080 --> 01:47:04.320]   seeing the business of it.
[01:47:04.320 --> 01:47:08.400]   But what do the so-called middlemen companies,
[01:47:08.400 --> 01:47:09.680]   so the PBMs--
[01:47:09.680 --> 01:47:10.920]   - The Pharmacy Benefit Managers.
[01:47:10.920 --> 01:47:12.420]   - Thank you.
[01:47:12.420 --> 01:47:15.280]   CVS Caremark, Cigna's Express Scripps,
[01:47:15.280 --> 01:47:19.080]   and UnitedHealth's OptumRx,
[01:47:19.080 --> 01:47:21.400]   they control majority of the market.
[01:47:21.400 --> 01:47:22.440]   What do they do wrong?
[01:47:22.440 --> 01:47:24.440]   - They put profits over everything, right?
[01:47:24.440 --> 01:47:29.040]   And they know in an industry that's completely opaque,
[01:47:29.040 --> 01:47:31.080]   they can pretty much do what they want
[01:47:31.080 --> 01:47:34.240]   and nobody gets to see what they're doing in detail.
[01:47:34.240 --> 01:47:39.240]   And so the first thing when you sign a contract
[01:47:39.240 --> 01:47:41.640]   with one of those big PBMs,
[01:47:41.640 --> 01:47:44.760]   it says you can't disclose any of this.
[01:47:44.760 --> 01:47:46.480]   And the fact that you can't be disclosed
[01:47:46.480 --> 01:47:49.380]   means they could tell Lex's company
[01:47:49.380 --> 01:47:53.280]   that they're getting a great price
[01:47:53.280 --> 01:47:55.120]   and they're only being charged X,
[01:47:55.120 --> 01:47:57.040]   and they can tell Mark's company,
[01:47:57.040 --> 01:47:58.240]   oh, you're getting a great price
[01:47:58.240 --> 01:48:00.520]   and we're charging Mark X plus, right?
[01:48:00.520 --> 01:48:02.360]   But Mark doesn't know any better
[01:48:02.360 --> 01:48:03.360]   'cause there's no way to know.
[01:48:03.360 --> 01:48:05.320]   - The markup is not transparent.
[01:48:05.320 --> 01:48:08.160]   - The cost isn't transparent, the markup isn't transparent.
[01:48:08.160 --> 01:48:10.680]   And there's different things.
[01:48:10.680 --> 01:48:12.640]   I was just talking to a company
[01:48:12.640 --> 01:48:14.720]   in a presentation a couple days ago
[01:48:14.720 --> 01:48:19.200]   and they took the step to leave the big three PBMs
[01:48:19.200 --> 01:48:21.540]   to go to a rebate-free PBM that was smaller.
[01:48:22.520 --> 01:48:25.160]   And what they said led to the decision.
[01:48:25.160 --> 01:48:26.800]   They had a contract with the PBM
[01:48:26.800 --> 01:48:28.600]   for these things called rebates, right?
[01:48:28.600 --> 01:48:30.980]   Where depending on the volume of medications you buy,
[01:48:30.980 --> 01:48:34.240]   they'll kick back to you a percentage of them.
[01:48:34.240 --> 01:48:35.720]   And as it turns out,
[01:48:35.720 --> 01:48:37.800]   when they compared what was contracted for
[01:48:37.800 --> 01:48:39.360]   to what they actually got,
[01:48:39.360 --> 01:48:41.720]   they were getting underpaid every single year.
[01:48:41.720 --> 01:48:43.960]   They just don't care, right?
[01:48:43.960 --> 01:48:45.200]   They'll take products.
[01:48:45.200 --> 01:48:47.480]   There's a drug called Humira, right?
[01:48:47.480 --> 01:48:52.340]   And it is the number one revenue drug in the country.
[01:48:52.340 --> 01:48:55.120]   And there's also a biosimilar, multiple biosimilars,
[01:48:55.120 --> 01:48:57.840]   but one we carry called Usimri.
[01:48:57.840 --> 01:49:02.720]   And Humira, the pre-rebate price
[01:49:02.720 --> 01:49:04.660]   is about $8,000 per month.
[01:49:04.660 --> 01:49:08.080]   And after rebates, depending on the size of the company,
[01:49:08.080 --> 01:49:11.360]   it'll be anywhere from three to $6,000 a month.
[01:49:11.360 --> 01:49:13.000]   You can go to get your doctor
[01:49:13.000 --> 01:49:16.960]   to prescribe that biosimilar Usimri and you pay $594.
[01:49:16.960 --> 01:49:20.600]   But those big three PBMs won't allow their clients
[01:49:20.600 --> 01:49:25.600]   to get Usimri because they don't get a rebate on Usimri.
[01:49:25.600 --> 01:49:29.280]   So they'd rather keep a drug on their formulary,
[01:49:29.280 --> 01:49:32.400]   even though their patients would save,
[01:49:32.400 --> 01:49:34.380]   their customers would save a lot of money,
[01:49:34.380 --> 01:49:37.340]   they'd rather keep a drug and exclude another
[01:49:37.340 --> 01:49:39.220]   because they'll make a lot more money.
[01:49:39.220 --> 01:49:42.740]   - So the CVS Caremark spokesperson,
[01:49:42.740 --> 01:49:46.460]   I think responded to you, Phil Blandeau,
[01:49:46.460 --> 01:49:51.280]   with the usual language that so deeply exhausts me,
[01:49:51.280 --> 01:49:55.800]   but I was wondering if there's any truth to it.
[01:49:55.800 --> 01:49:58.800]   Employers, unions, health plans, and government programs
[01:49:58.800 --> 01:50:03.040]   work with CVS Caremark precisely because we deliver for them
[01:50:03.040 --> 01:50:06.000]   lower drug costs, better health outcomes,
[01:50:06.000 --> 01:50:10.080]   and broad pharmacy access through our true cost,
[01:50:10.080 --> 01:50:14.560]   cost vantage, and choice formulary initiatives.
[01:50:14.560 --> 01:50:16.620]   We are the leading agent of change,
[01:50:16.620 --> 01:50:18.740]   innovation, and transparency in the market.
[01:50:18.740 --> 01:50:20.260]   - That's a whole lot of nothing.
[01:50:20.260 --> 01:50:22.940]   - So they are not transparent.
[01:50:22.940 --> 01:50:23.780]   - No, no.
[01:50:23.780 --> 01:50:26.020]   Call them up, you go to Cost Plus Drugs,
[01:50:26.020 --> 01:50:29.380]   we'll give you our price list of all 2,500 plus drugs.
[01:50:29.380 --> 01:50:30.200]   - The actual cost.
[01:50:30.200 --> 01:50:32.540]   - The actual cost and what we sell it for
[01:50:32.540 --> 01:50:34.340]   because it's just a plus 15%.
[01:50:34.340 --> 01:50:36.180]   Call up any of the big three companies
[01:50:36.180 --> 01:50:37.880]   and ask them for the same thing.
[01:50:37.880 --> 01:50:38.860]   They're gonna laugh at you.
[01:50:38.860 --> 01:50:41.980]   It's so bad, in fact, if you do business with them right now
[01:50:41.980 --> 01:50:44.940]   and you just ask for your claims data,
[01:50:44.940 --> 01:50:47.580]   meaning how many people use Humira that we're paying,
[01:50:47.580 --> 01:50:49.140]   what are we paying for it?
[01:50:49.140 --> 01:50:50.500]   They won't even give it to you
[01:50:50.500 --> 01:50:52.460]   unless you really, really scream and yell at them
[01:50:52.460 --> 01:50:54.580]   and then they'll charge you and take six months to get it.
[01:50:54.580 --> 01:50:56.780]   So like when we moved away from them,
[01:50:56.780 --> 01:50:58.500]   we wanted to get what our claims data was
[01:50:58.500 --> 01:51:01.360]   to understand what we were gonna be facing.
[01:51:01.360 --> 01:51:04.420]   They wouldn't give it to us until like six months later,
[01:51:04.420 --> 01:51:05.500]   I forget the exact amount,
[01:51:05.500 --> 01:51:08.860]   but and then they charge us for it as well, our own data.
[01:51:08.860 --> 01:51:10.020]   - On the CEO front,
[01:51:10.020 --> 01:51:13.500]   you've said that CEOs don't understand healthcare coverage
[01:51:13.500 --> 01:51:14.640]   and it's costing them big.
[01:51:14.640 --> 01:51:17.500]   What's the connection between
[01:51:17.500 --> 01:51:19.700]   all Cost Plus drugs and companies?
[01:51:19.700 --> 01:51:21.660]   - So I can speak for my own companies
[01:51:21.660 --> 01:51:24.260]   and this applies to all companies,
[01:51:24.260 --> 01:51:27.100]   bigger companies that self-insure 'cause we self-insured.
[01:51:27.100 --> 01:51:30.420]   When I finally, when we started Cost Plus,
[01:51:30.420 --> 01:51:32.340]   I finally said, okay, it's time for me to understand
[01:51:32.340 --> 01:51:33.900]   how I'm paying for my healthcare,
[01:51:33.900 --> 01:51:35.820]   for my employees and their families.
[01:51:35.820 --> 01:51:37.680]   And the first thing I looked at was
[01:51:37.680 --> 01:51:40.620]   a lot of these companies use employee benefits consultants.
[01:51:40.620 --> 01:51:42.460]   And turns out I was getting,
[01:51:42.460 --> 01:51:46.060]   I was paying $30 per employee per month,
[01:51:46.060 --> 01:51:48.700]   which was millions of dollars a year.
[01:51:48.700 --> 01:51:52.220]   And they were just sending us to the companies
[01:51:52.220 --> 01:51:54.300]   that paid them the biggest commissions.
[01:51:54.300 --> 01:51:57.940]   I'm like, how fucking dumb am I, right?
[01:51:57.940 --> 01:51:59.580]   So I'm like, okay, we're cutting that.
[01:51:59.580 --> 01:52:03.460]   And then I looked at our medication,
[01:52:03.460 --> 01:52:06.260]   our prescription deal that goes through the PBMs
[01:52:06.260 --> 01:52:07.540]   that we were using.
[01:52:07.540 --> 01:52:09.860]   And that the consultant connected us with.
[01:52:09.860 --> 01:52:14.260]   And I took a list of, this was early on in Cost Plus drugs,
[01:52:14.260 --> 01:52:16.460]   list of the generic drugs that we sold
[01:52:16.460 --> 01:52:17.980]   that cost more than $30
[01:52:17.980 --> 01:52:20.340]   that the Mavericks also had purchased, right?
[01:52:20.340 --> 01:52:22.220]   We were able to get that claims data.
[01:52:22.220 --> 01:52:27.220]   And it turns out we spent $169,000 with that PBM,
[01:52:27.220 --> 01:52:29.220]   one of the big three PBMs.
[01:52:29.220 --> 01:52:30.460]   And it would have cost us buying
[01:52:30.460 --> 01:52:32.500]   from Cost Plus drugs $19,000.
[01:52:32.500 --> 01:52:36.060]   And that's just a simple example.
[01:52:36.060 --> 01:52:38.260]   Then I looked at the insurance side of things, right?
[01:52:38.260 --> 01:52:41.500]   We self-insure, so there weren't premiums per se.
[01:52:41.500 --> 01:52:45.900]   But we were getting charged $17.15 per employee per month
[01:52:45.900 --> 01:52:49.460]   just to use the network that they put together for us,
[01:52:49.460 --> 01:52:51.420]   providers, hospitals, whatever.
[01:52:51.420 --> 01:52:53.020]   And I'm like, all right, are there companies
[01:52:53.020 --> 01:52:55.380]   that won't charge us to put together these networks?
[01:52:55.380 --> 01:52:57.080]   Turns out there's a lot of them.
[01:52:57.080 --> 01:53:00.780]   And those insurance companies and those PBMs
[01:53:00.780 --> 01:53:04.420]   are also responsible for determining what claims,
[01:53:04.420 --> 01:53:09.420]   what to authorize and what to deny, right?
[01:53:09.420 --> 01:53:12.000]   So for a drug, it may be, all right,
[01:53:12.000 --> 01:53:13.600]   this is an expensive drug,
[01:53:13.600 --> 01:53:17.540]   but before they'll say they'll pay for the drug
[01:53:17.540 --> 01:53:19.380]   that your doctor wants to prescribe for you,
[01:53:19.380 --> 01:53:20.820]   you have to try these three other drugs
[01:53:20.820 --> 01:53:22.620]   in what's called step-up therapy, right?
[01:53:22.620 --> 01:53:24.480]   To see if these other cheaper drugs work,
[01:53:24.480 --> 01:53:26.340]   or they're not even necessarily cheaper.
[01:53:26.340 --> 01:53:28.980]   They may be being pushed
[01:53:28.980 --> 01:53:31.860]   because they're getting a higher rebate.
[01:53:31.860 --> 01:53:33.700]   And so I'm like, that's insane.
[01:53:33.700 --> 01:53:36.420]   I want my employees to get the medication
[01:53:36.420 --> 01:53:39.100]   that the doctors say is best.
[01:53:39.100 --> 01:53:42.940]   And so I didn't realize those were the intricacies
[01:53:42.940 --> 01:53:46.680]   of how my health or where my healthcare dollars went.
[01:53:46.680 --> 01:53:48.860]   There's not a single CEO who does
[01:53:48.860 --> 01:53:51.020]   because that's not a core competency that they need.
[01:53:51.020 --> 01:53:53.820]   And the CFOs, that's not their core competency.
[01:53:53.820 --> 01:53:56.340]   And the HR people, they contribute
[01:53:56.340 --> 01:53:57.460]   and they understand it some
[01:53:57.460 --> 01:53:59.000]   because they're dealing with the claims,
[01:53:59.000 --> 01:54:02.040]   but they spend most of their prescription drug-related time
[01:54:02.040 --> 01:54:03.420]   or healthcare-related times
[01:54:03.420 --> 01:54:06.220]   trying to get pre-authorizations approved.
[01:54:06.220 --> 01:54:10.300]   So your kid breaks their arm or you get sick
[01:54:10.300 --> 01:54:11.920]   and you go to the doctor,
[01:54:11.920 --> 01:54:15.560]   and before the doctor will do a surgery or do whatever,
[01:54:15.560 --> 01:54:17.020]   they have to go to the insurance company
[01:54:17.020 --> 01:54:18.460]   and get pre-authorized.
[01:54:18.460 --> 01:54:20.660]   And then they always say no, right?
[01:54:20.660 --> 01:54:21.700]   And then you have to go back
[01:54:21.700 --> 01:54:23.020]   and somebody has to argue for you.
[01:54:23.020 --> 01:54:24.700]   And that just eats up employee time
[01:54:24.700 --> 01:54:27.000]   because I'm sick or my kid's sick
[01:54:27.000 --> 01:54:28.020]   and you're wasting my time.
[01:54:28.020 --> 01:54:29.300]   Eats up HR time.
[01:54:29.300 --> 01:54:31.820]   The CEOs don't know any of this, right?
[01:54:31.820 --> 01:54:33.980]   So what I'm saying is, one,
[01:54:33.980 --> 01:54:34.820]   the smartest thing to do
[01:54:34.820 --> 01:54:36.860]   is to get a healthcare CEO at every company
[01:54:36.860 --> 01:54:38.940]   with over, let's say, 500 employees
[01:54:38.940 --> 01:54:40.540]   that focuses on all these things.
[01:54:40.540 --> 01:54:42.300]   You'd save a shitload of money.
[01:54:42.300 --> 01:54:45.420]   And two, healthcare is your second largest
[01:54:45.420 --> 01:54:48.060]   line-item expense after payroll.
[01:54:48.060 --> 01:54:49.860]   And in some companies,
[01:54:49.860 --> 01:54:52.540]   it's hundreds, billions of dollars, right?
[01:54:52.540 --> 01:54:53.820]   And you don't understand it
[01:54:53.820 --> 01:54:55.940]   and you're letting these guys rip you off.
[01:54:55.940 --> 01:54:59.120]   And it's because these big CEOs don't understand it
[01:54:59.120 --> 01:55:00.740]   and are getting ripped off
[01:55:00.740 --> 01:55:03.580]   that the industry is the way it is
[01:55:03.580 --> 01:55:07.540]   because that allows the opacity to continue.
[01:55:07.540 --> 01:55:08.820]   - That's fascinating.
[01:55:08.820 --> 01:55:13.820]   So most companies outsource, offload
[01:55:13.820 --> 01:55:17.060]   the expertise on the healthcare side
[01:55:17.060 --> 01:55:18.460]   when they really should be internally,
[01:55:18.460 --> 01:55:19.300]   there should be an expert--
[01:55:19.300 --> 01:55:21.660]   - Yes, because it's the wellness of your employees
[01:55:21.660 --> 01:55:22.500]   and their families.
[01:55:22.500 --> 01:55:24.100]   - And it costs a lot of money.
[01:55:24.100 --> 01:55:25.720]   - Yeah, but if your employees aren't healthy
[01:55:25.720 --> 01:55:27.540]   or if they're worried about their kids,
[01:55:27.540 --> 01:55:30.820]   and what is more worrisome and detrimental
[01:55:30.820 --> 01:55:34.060]   to the performance of a company, right?
[01:55:34.060 --> 01:55:39.060]   A DEI program or having to go to HR
[01:55:39.060 --> 01:55:41.300]   and scream and yell and explain,
[01:55:41.300 --> 01:55:44.100]   and your doctor wasting their time doing the same thing
[01:55:44.100 --> 01:55:48.140]   to get authorization for a surgery or a medication.
[01:55:48.140 --> 01:55:48.980]   It's insane.
[01:55:48.980 --> 01:55:52.460]   - What made you decide to step into this cartel-like
[01:55:52.460 --> 01:55:56.220]   situation where so much is opaque?
[01:55:56.220 --> 01:55:59.140]   - So I got a cold email from a Dr. Alex Hosch-Miyansky,
[01:55:59.140 --> 01:55:59.980]   who's my co-founder.
[01:55:59.980 --> 01:56:02.220]   He's a radiologist by trade and a physicist
[01:56:02.220 --> 01:56:03.620]   and a smart motherfucker.
[01:56:03.620 --> 01:56:06.700]   And he had a pharmacy that he wanted
[01:56:06.700 --> 01:56:08.460]   to create a compounding pharmacy
[01:56:08.460 --> 01:56:10.460]   that would manufacture generic drugs
[01:56:10.460 --> 01:56:11.900]   that were in short supply
[01:56:11.900 --> 01:56:15.140]   because it happens all the time that things aren't available.
[01:56:15.140 --> 01:56:16.560]   I'm like, you're thinking too small.
[01:56:16.560 --> 01:56:19.020]   We should do something on a much bigger scale.
[01:56:19.020 --> 01:56:20.540]   And then it was right around the time
[01:56:20.540 --> 01:56:21.900]   they were sending the pharmacy bro,
[01:56:21.900 --> 01:56:23.740]   Martin Shkreli to jail.
[01:56:23.740 --> 01:56:25.620]   And so I was reading up on that
[01:56:25.620 --> 01:56:29.100]   and he increased the price of this drug Daraprim.
[01:56:29.100 --> 01:56:31.740]   I think it was like 7,500% or increased
[01:56:31.740 --> 01:56:34.180]   a low cost drug to $7,500, one of those.
[01:56:34.180 --> 01:56:35.900]   And I'm like, well, if he can just jack up
[01:56:35.900 --> 01:56:38.420]   the price of this drug and charge more
[01:56:38.420 --> 01:56:39.400]   and get away with it,
[01:56:39.400 --> 01:56:41.800]   this has to be an incredibly inefficient market.
[01:56:41.800 --> 01:56:45.820]   And so the question is, why is he able to do it?
[01:56:45.820 --> 01:56:47.480]   And it was immediately apparent
[01:56:47.480 --> 01:56:49.380]   that it was a lack of transparency.
[01:56:49.380 --> 01:56:52.100]   And so can we start a company that is fully transparent
[01:56:52.100 --> 01:56:55.300]   with our costs, our markup and our selling price?
[01:56:55.300 --> 01:56:57.140]   And see if it works.
[01:56:57.140 --> 01:56:59.920]   And so we went for it and it took off immediately.
[01:56:59.920 --> 01:57:03.820]   I mean, you read a press release from a company saying,
[01:57:03.820 --> 01:57:05.860]   they were creating a cost advantage program,
[01:57:05.860 --> 01:57:08.180]   basically pretending to replicate us.
[01:57:08.180 --> 01:57:09.140]   - Yeah.
[01:57:09.140 --> 01:57:11.140]   - We haven't been in business two years.
[01:57:11.140 --> 01:57:13.500]   How insane is that?
[01:57:13.500 --> 01:57:14.580]   - Did you get a lot of pressure?
[01:57:14.580 --> 01:57:17.460]   I mean, I'm sure they're very good at playing games.
[01:57:17.460 --> 01:57:20.340]   So cartel type situations, they protect.
[01:57:20.340 --> 01:57:21.900]   It feels like healthcare,
[01:57:21.900 --> 01:57:23.580]   it's very difficult to get in there.
[01:57:23.580 --> 01:57:24.420]   - Yeah, it does.
[01:57:24.420 --> 01:57:26.340]   - I mean, and the whole industry is an arbitrage,
[01:57:26.340 --> 01:57:27.700]   but we don't work inside the system,
[01:57:27.700 --> 01:57:29.300]   we work outside the system.
[01:57:29.300 --> 01:57:31.140]   And so we don't work with those biggest companies.
[01:57:31.140 --> 01:57:33.900]   The biggest companies with the most dominant control,
[01:57:33.900 --> 01:57:36.900]   it's very insulated and very controlled, like you said.
[01:57:36.900 --> 01:57:39.100]   We work outside them, we won't work with them.
[01:57:39.100 --> 01:57:40.620]   And so because of that,
[01:57:40.620 --> 01:57:42.660]   we don't have access to every medication
[01:57:42.660 --> 01:57:46.240]   because they've told a lot of the big brand manufacturers
[01:57:46.240 --> 01:57:47.460]   that if they work with us,
[01:57:47.460 --> 01:57:49.340]   they'll take them off their formularies
[01:57:49.340 --> 01:57:51.180]   or change the rebate structure
[01:57:51.180 --> 01:57:53.020]   so that they won't be prescribed as much.
[01:57:53.020 --> 01:57:55.260]   - Yeah, it is dark, but we'll get past that, right?
[01:57:55.260 --> 01:57:58.060]   Because there's a downstream impact of all this
[01:57:58.060 --> 01:58:02.100]   in the rebates and the greediness of those big three PBMs.
[01:58:02.100 --> 01:58:05.980]   When you go to a local pharmacy here in Austin, right?
[01:58:05.980 --> 01:58:09.100]   And let's just say you have a friend here, right?
[01:58:09.100 --> 01:58:11.380]   That is on Medicare or Medicare Advantage,
[01:58:11.380 --> 01:58:13.100]   and they go to a local pharmacy
[01:58:13.100 --> 01:58:16.460]   and they get a drug that costs $600.
[01:58:16.460 --> 01:58:20.540]   Well, an insurance company, that's $600.
[01:58:20.540 --> 01:58:24.180]   The pharmacy first buys that drug for probably that price,
[01:58:24.180 --> 01:58:26.900]   minus 5%, so $570.
[01:58:26.900 --> 01:58:29.220]   Then there's probably a copay by the patient,
[01:58:29.220 --> 01:58:30.380]   and that's probably $20.
[01:58:30.380 --> 01:58:33.900]   So now the net investment that the pharmacy,
[01:58:33.900 --> 01:58:38.720]   the local pharmacy has for that brand medication is $550.
[01:58:38.720 --> 01:58:44.980]   Where it gets really fucked up is those big three PBMs,
[01:58:44.980 --> 01:58:49.260]   they're not reimbursing them $550 or more.
[01:58:49.260 --> 01:58:53.700]   They're reimbursing them $500 or less.
[01:58:53.700 --> 01:58:56.340]   And literally those community pharmacies
[01:58:56.340 --> 01:58:58.900]   are eating that loss.
[01:58:58.900 --> 01:58:59.980]   And as a result,
[01:58:59.980 --> 01:59:01.780]   they're going out of business left and right.
[01:59:01.780 --> 01:59:04.480]   And the most insane part of it is,
[01:59:04.480 --> 01:59:08.580]   yes, with corporate employer insurance, that happens,
[01:59:08.580 --> 01:59:10.660]   but it happens more with Medicare Part D
[01:59:10.660 --> 01:59:11.940]   and Medicare Advantage.
[01:59:11.940 --> 01:59:14.860]   It happens all the time with those, almost with every script.
[01:59:14.860 --> 01:59:17.340]   So the government is complicit
[01:59:17.340 --> 01:59:20.340]   in these community pharmacies going out of business.
[01:59:20.340 --> 01:59:23.940]   So how does that connect to Cost Plus Drugs
[01:59:23.940 --> 01:59:26.040]   and what we're doing and the big brands?
[01:59:26.040 --> 01:59:27.820]   The big brands know that
[01:59:27.820 --> 01:59:30.420]   if all these community pharmacies are going,
[01:59:30.420 --> 01:59:32.700]   tens of thousands of them are going to go out of business
[01:59:32.700 --> 01:59:34.600]   because of the way this pricing is,
[01:59:34.600 --> 01:59:36.680]   they're gonna lose a connection
[01:59:36.680 --> 01:59:38.820]   between their brand medications
[01:59:38.820 --> 01:59:41.260]   and grandma and grandpa and aunt Sally.
[01:59:41.260 --> 01:59:43.540]   And all that business is gonna get transferred
[01:59:43.540 --> 01:59:44.860]   to the big companies.
[01:59:44.860 --> 01:59:46.680]   And they're gonna have even less leverage.
[01:59:46.680 --> 01:59:49.180]   So they're working with us to come up with programs
[01:59:49.180 --> 01:59:52.160]   that are very supportive of independent pharmacies.
[01:59:52.160 --> 01:59:55.260]   And that's gonna allow us to break the cartel
[01:59:55.260 --> 01:59:56.800]   because it's in their best interest
[01:59:56.800 --> 01:59:59.540]   not to allow them to be so vertically integrated
[01:59:59.540 --> 02:00:01.660]   that they destroy the entire community
[02:00:01.660 --> 02:00:03.640]   and independent pharmacy industry.
[02:00:03.640 --> 02:00:05.560]   - Is there other aspects of the healthcare industry
[02:00:05.560 --> 02:00:10.560]   that could use this kind of transparency and revolutionizing?
[02:00:10.560 --> 02:00:13.580]   - Yeah, so what we're gonna do with our own healthcare,
[02:00:13.580 --> 02:00:15.260]   right, we're not gonna be in the business
[02:00:15.260 --> 02:00:17.580]   of selling healthcare or anything like that or operating.
[02:00:17.580 --> 02:00:20.740]   But the things we do for my companies,
[02:00:20.740 --> 02:00:23.660]   we're only gonna do deals with providers,
[02:00:23.660 --> 02:00:24.760]   healthcare providers,
[02:00:24.760 --> 02:00:27.140]   that allow us to be completely transparent.
[02:00:27.140 --> 02:00:28.820]   So that whatever contracts we do,
[02:00:28.820 --> 02:00:29.700]   we're gonna post them all.
[02:00:29.700 --> 02:00:31.940]   Whatever pricing we get, we're gonna post them all.
[02:00:31.940 --> 02:00:35.220]   So that every company who's our size or even bigger
[02:00:35.220 --> 02:00:37.560]   will have a template that they can work on,
[02:00:37.560 --> 02:00:39.460]   which will take it away from
[02:00:39.460 --> 02:00:44.160]   the big three insurance companies and the big three PBMs.
[02:00:44.160 --> 02:00:46.500]   Because now, without that transparency,
[02:00:46.500 --> 02:00:48.500]   they have to use consultants who are getting paid
[02:00:48.500 --> 02:00:50.860]   by those big three, you know, those big companies,
[02:00:50.860 --> 02:00:54.300]   and aren't giving them the best response.
[02:00:54.300 --> 02:00:56.740]   And so now that transparency will overcome that.
[02:00:56.740 --> 02:00:59.860]   - And you're using your, how should I say it,
[02:00:59.860 --> 02:01:02.620]   celebrity, your name, to kind of push this forward.
[02:01:02.620 --> 02:01:04.060]   - Yeah, it's the only company I've ever put my name on.
[02:01:04.060 --> 02:01:06.820]   - It's weird that people aren't getting into the space.
[02:01:06.820 --> 02:01:09.900]   Like, public people, you know, like big,
[02:01:09.900 --> 02:01:12.580]   there's not like a big, you know, you look at tech,
[02:01:12.580 --> 02:01:17.080]   there's like these, like, CEOs are open and public
[02:01:17.080 --> 02:01:18.720]   and public, and they're pushing the company,
[02:01:18.720 --> 02:01:20.360]   and they're selling everything.
[02:01:20.360 --> 02:01:22.220]   It's like all transparent.
[02:01:22.220 --> 02:01:25.480]   But you don't see that in healthcare.
[02:01:25.480 --> 02:01:28.320]   - No, because it's a big business, and most people,
[02:01:28.320 --> 02:01:30.240]   like if I was 25 trying to start a company,
[02:01:30.240 --> 02:01:31.280]   I'd work in the system.
[02:01:31.280 --> 02:01:32.760]   'Cause if I can build it up big enough,
[02:01:32.760 --> 02:01:34.240]   they would just buy me.
[02:01:34.240 --> 02:01:36.520]   And I'd make, you know, money and buy a sports team.
[02:01:36.520 --> 02:01:38.560]   But I don't need that money now.
[02:01:38.560 --> 02:01:39.600]   - Let me ask you about AI.
[02:01:39.600 --> 02:01:43.700]   You've gotten a little bit of an argument about open source.
[02:01:43.700 --> 02:01:46.520]   I think you stepped in between Vinod Khosla
[02:01:46.520 --> 02:01:47.980]   and Mark Andreessen.
[02:01:47.980 --> 02:01:50.140]   You think AI should be open sourced?
[02:01:50.140 --> 02:01:51.620]   - Yeah, for sure.
[02:01:51.620 --> 02:01:53.580]   - So like all that discussion we've been having
[02:01:53.580 --> 02:01:55.460]   about like Google and so on, one of the solutions-
[02:01:55.460 --> 02:01:56.580]   - Well, okay, two different things.
[02:01:56.580 --> 02:02:00.500]   Meaning that Meta's doing open source, right?
[02:02:00.500 --> 02:02:01.540]   That's a good choice for them.
[02:02:01.540 --> 02:02:03.400]   I think that's a smart choice, right?
[02:02:03.400 --> 02:02:05.420]   But it's just a business decision for everybody else.
[02:02:05.420 --> 02:02:07.100]   I don't think it should be forced.
[02:02:07.100 --> 02:02:07.940]   - Forced, yes, yeah.
[02:02:08.280 --> 02:02:12.120]   - Right, and even Google's open sourcing some of the models.
[02:02:12.120 --> 02:02:15.120]   - Because they're all, that's a very incestuous industry
[02:02:15.120 --> 02:02:18.700]   where, you know, the people all work together at some level.
[02:02:18.700 --> 02:02:20.120]   They read the same papers.
[02:02:20.120 --> 02:02:21.800]   They go to the same conferences.
[02:02:21.800 --> 02:02:23.660]   You know, it's like the early days of streaming
[02:02:23.660 --> 02:02:25.200]   and the internet where people used
[02:02:25.200 --> 02:02:26.920]   the same technology everywhere.
[02:02:26.920 --> 02:02:28.320]   And now they just try different things
[02:02:28.320 --> 02:02:30.680]   and you get one smart or two, a couple smart people
[02:02:30.680 --> 02:02:33.320]   in one company like Anthropic, right?
[02:02:33.320 --> 02:02:34.520]   And they do things a little bit better
[02:02:34.520 --> 02:02:36.720]   and model efficiency gets better.
[02:02:36.720 --> 02:02:38.780]   So, you know, it's just a business choice
[02:02:38.780 --> 02:02:40.140]   but I don't think it should be forced
[02:02:40.140 --> 02:02:42.300]   but I think it's a smart business decision.
[02:02:42.300 --> 02:02:43.920]   - Open sourcing is a smart business decision.
[02:02:43.920 --> 02:02:44.820]   - Yeah.
[02:02:44.820 --> 02:02:45.780]   - It's a tricky one.
[02:02:45.780 --> 02:02:48.660]   I mean, Google's pioneering that with TensorFlow
[02:02:48.660 --> 02:02:50.500]   in the AI space.
[02:02:50.500 --> 02:02:51.340]   That's a tricky decision to get.
[02:02:51.340 --> 02:02:52.620]   - It really, really is, right?
[02:02:52.620 --> 02:02:55.260]   But go back to historically, you know,
[02:02:55.260 --> 02:02:58.700]   there was digital computing which was a dominant player
[02:02:58.700 --> 02:03:02.280]   and they thought, and IBM to a certain extent,
[02:03:02.280 --> 02:03:06.500]   thought that they wouldn't be subject to a problem
[02:03:06.500 --> 02:03:08.020]   with the PC industry.
[02:03:08.020 --> 02:03:09.500]   And then all of a sudden,
[02:03:09.500 --> 02:03:13.060]   with their mainframes and everything,
[02:03:13.060 --> 02:03:14.800]   they had captive software,
[02:03:14.800 --> 02:03:17.380]   they wouldn't use off the shelf software, right?
[02:03:17.380 --> 02:03:21.020]   So for a digital equipment mainframe or an IBM mainframe,
[02:03:21.020 --> 02:03:22.780]   you needed software that was written for it.
[02:03:22.780 --> 02:03:23.940]   There was nothing off the shelf.
[02:03:23.940 --> 02:03:26.260]   And when the PC industry came along,
[02:03:26.260 --> 02:03:27.720]   it was the exact opposite.
[02:03:27.720 --> 02:03:29.980]   There was, you know, MS-DOS and then Windows,
[02:03:29.980 --> 02:03:32.300]   things that were off the shelf that every PC could use.
[02:03:32.300 --> 02:03:34.940]   And that changed how people thought about software.
[02:03:34.940 --> 02:03:36.740]   And I think the same thing will happen here
[02:03:36.740 --> 02:03:41.500]   where it's going to be as models become more efficient
[02:03:41.500 --> 02:03:44.700]   and easier and less expensive to train,
[02:03:44.700 --> 02:03:49.100]   I think there'll be more reasons to open source.
[02:03:49.100 --> 02:03:50.140]   - Yeah, that's the hope.
[02:03:50.140 --> 02:03:51.300]   It creates more competition
[02:03:51.300 --> 02:03:54.780]   and a lot of different diversity of approaches
[02:03:54.780 --> 02:03:57.340]   in how they're implemented, deployed,
[02:03:57.340 --> 02:03:59.700]   what kind of products they create, all of that.
[02:03:59.700 --> 02:04:03.980]   Vinod compared the danger of that to the Manhattan Project.
[02:04:03.980 --> 02:04:06.340]   - Yeah, yeah, I'm not buying that at all.
[02:04:06.340 --> 02:04:07.180]   - You don't see the parallels
[02:04:07.180 --> 02:04:08.820]   between nuclear weapons and AI.
[02:04:08.820 --> 02:04:13.500]   - No, no, I think I'm not an AI fatalist at all, right?
[02:04:13.500 --> 02:04:15.580]   I'm an AI optimist.
[02:04:15.580 --> 02:04:19.140]   And, but it's not to say that there isn't a lot
[02:04:19.140 --> 02:04:20.940]   of scary shit that can happen with it.
[02:04:20.940 --> 02:04:21.780]   - Yeah.
[02:04:21.780 --> 02:04:25.060]   - Militarily, you know, like I said earlier,
[02:04:25.060 --> 02:04:28.020]   I'm a big believer that there's going to be millions
[02:04:28.020 --> 02:04:29.980]   and tens of millions of models
[02:04:29.980 --> 02:04:33.940]   and people will take their expertise
[02:04:33.940 --> 02:04:37.700]   and either get hired for it and contribute
[02:04:37.700 --> 02:04:40.780]   or create their own models and license.
[02:04:40.780 --> 02:04:42.620]   So that, you know, you see now
[02:04:42.620 --> 02:04:44.780]   with this thing called mixture of experts, right?
[02:04:44.780 --> 02:04:49.780]   Where you connect things and people can take their expertise
[02:04:49.780 --> 02:04:52.860]   and we'll be able to take that expertise
[02:04:52.860 --> 02:04:56.420]   and retain it in a way that they want to retain it.
[02:04:56.420 --> 02:04:58.460]   So, you know, I don't think there's gonna be
[02:04:58.460 --> 02:04:59.460]   one medical database.
[02:04:59.460 --> 02:05:01.780]   And I told this to people at a couple of big companies
[02:05:01.780 --> 02:05:04.060]   that were doing healthcare initiatives.
[02:05:04.060 --> 02:05:08.580]   Branding is so important in the healthcare space,
[02:05:08.580 --> 02:05:11.340]   if, you know, for hospitals, you know, the Mayo Clinics,
[02:05:11.340 --> 02:05:13.780]   the MD Andersons, they're huge brands.
[02:05:13.780 --> 02:05:16.220]   And I don't think they're just gonna give up their expertise
[02:05:16.220 --> 02:05:20.540]   to some, you know, main singular model, you know,
[02:05:20.540 --> 02:05:23.780]   and say, okay, you know, whatever expertise we have
[02:05:23.780 --> 02:05:26.900]   is available to you in Gemini or ChatGPT
[02:05:26.900 --> 02:05:30.420]   or, you know, so-and-so's version of Med is open source.
[02:05:30.420 --> 02:05:33.420]   I just don't, there's just, that would be business suicide.
[02:05:33.420 --> 02:05:36.580]   And so I think you're gonna see each of them
[02:05:36.580 --> 02:05:39.220]   have their own models and update them as they go
[02:05:39.220 --> 02:05:40.380]   and license them.
[02:05:40.380 --> 02:05:43.100]   - Yeah, and yeah, make money from the expertise.
[02:05:43.100 --> 02:05:43.940]   - You have to. - Don't give away the expertise.
[02:05:43.940 --> 02:05:46.140]   - You have to. - Yeah, yeah, yeah.
[02:05:46.140 --> 02:05:47.620]   And the expertise evolves and grows
[02:05:47.620 --> 02:05:50.820]   and all that kind of stuff and you want to own that growth.
[02:05:50.820 --> 02:05:53.100]   What advice would you give to young people?
[02:05:53.100 --> 02:05:55.260]   You have an exceptionally successful career.
[02:05:55.260 --> 02:05:57.780]   You came from little, made a lot.
[02:05:57.780 --> 02:05:59.620]   What advice would you give them?
[02:05:59.620 --> 02:06:01.020]   - Love your life, right?
[02:06:01.020 --> 02:06:03.540]   You know, find the things that you can enjoy.
[02:06:03.540 --> 02:06:04.940]   Be curious.
[02:06:04.940 --> 02:06:07.100]   You don't have to have all the answers
[02:06:07.100 --> 02:06:09.040]   when you're 12, 15.
[02:06:09.040 --> 02:06:11.700]   I get emails from 13, 15-year-old kids, right?
[02:06:11.700 --> 02:06:13.620]   - What do I do? - What do I do, right?
[02:06:13.620 --> 02:06:15.740]   You know, I feel like I'm being held back.
[02:06:15.740 --> 02:06:19.100]   I'm like a 15, you feel like you're being held back.
[02:06:19.100 --> 02:06:21.620]   But just be curious 'cause you don't have to have the answers.
[02:06:21.620 --> 02:06:22.700]   You don't have to know what you're gonna be
[02:06:22.700 --> 02:06:24.060]   when you grow up.
[02:06:24.060 --> 02:06:28.980]   I'm a hardcore believer that everybody has something
[02:06:28.980 --> 02:06:31.980]   that they're really, really, really good at
[02:06:31.980 --> 02:06:33.460]   that could be world-class great,
[02:06:33.460 --> 02:06:35.500]   every single human being on this planet.
[02:06:35.500 --> 02:06:38.100]   And the hard part is just finding what that is
[02:06:38.100 --> 02:06:41.300]   and in some places having resources to enable it.
[02:06:41.300 --> 02:06:45.300]   But be curious so you can find out what it is.
[02:06:45.300 --> 02:06:46.580]   I didn't take a technology,
[02:06:46.580 --> 02:06:50.040]   I took one technology class in college
[02:06:50.040 --> 02:06:52.740]   for TRAN programming and I cheated on it, right?
[02:06:52.740 --> 02:06:55.580]   I mean, it wasn't until I got a job at Mellon Bank
[02:06:55.580 --> 02:06:56.980]   and I started learning how to program
[02:06:56.980 --> 02:06:58.460]   in this thing called Ramus,
[02:06:58.460 --> 02:07:00.460]   this scripting computing language,
[02:07:00.460 --> 02:07:02.140]   that I realized, oh, this is interesting to me
[02:07:02.140 --> 02:07:02.980]   and I like it.
[02:07:02.980 --> 02:07:05.620]   And that's what got me a job selling software
[02:07:05.620 --> 02:07:08.380]   and going on from there.
[02:07:08.380 --> 02:07:10.460]   You just don't know what that's going to be
[02:07:10.460 --> 02:07:12.500]   until you go out and experience different things.
[02:07:12.500 --> 02:07:14.740]   So for anybody young out there listening,
[02:07:14.740 --> 02:07:18.460]   enjoy your life, find things to smile about,
[02:07:18.540 --> 02:07:22.860]   be curious, read, watch, expose yourself
[02:07:22.860 --> 02:07:25.580]   to as many different ideas as you can
[02:07:25.580 --> 02:07:27.460]   because something's gonna click at some point.
[02:07:27.460 --> 02:07:31.220]   You may be 15, you may be 25, you may be 55,
[02:07:31.220 --> 02:07:33.060]   but it can happen.
[02:07:33.060 --> 02:07:35.700]   - One thing to mention is sometimes it's difficult
[02:07:35.700 --> 02:07:38.580]   where your parents, people around you
[02:07:38.580 --> 02:07:42.300]   might not be conducive or might not be of help
[02:07:42.300 --> 02:07:45.900]   in finding the thing you're good at.
[02:07:45.900 --> 02:07:49.460]   In fact, in my own life, the society was such
[02:07:49.460 --> 02:07:52.500]   that I don't know if they've helped much
[02:07:52.500 --> 02:07:54.540]   at the thing I was good at.
[02:07:54.540 --> 02:07:56.220]   I'm still not sure what that is.
[02:07:56.220 --> 02:07:57.060]   But I think--
[02:07:57.060 --> 02:07:58.580]   - I think interviewing done pretty well for you.
[02:07:58.580 --> 02:07:59.660]   - Well, it's not even,
[02:07:59.660 --> 02:08:05.580]   there was a thing where I saw the beauty in people.
[02:08:05.580 --> 02:08:07.780]   It varied intensely.
[02:08:07.780 --> 02:08:10.540]   So you can call it empathy, all that kind of stuff.
[02:08:10.540 --> 02:08:11.900]   - I would call it wokeness.
[02:08:11.900 --> 02:08:14.300]   - Super woke.
[02:08:14.300 --> 02:08:16.780]   I guess you could say just super woke.
[02:08:16.780 --> 02:08:17.620]   That's me.
[02:08:17.620 --> 02:08:23.140]   But in the education system I came up in,
[02:08:23.140 --> 02:08:27.100]   it was a very hard mathematics, science, and so on.
[02:08:27.100 --> 02:08:30.700]   And I didn't notice that, whatever that was in me.
[02:08:30.700 --> 02:08:32.780]   But you have to keep the flame going.
[02:08:32.780 --> 02:08:35.460]   You have to try to find your way and see what that's useful.
[02:08:35.460 --> 02:08:38.660]   And others around you might not always notice it,
[02:08:38.660 --> 02:08:39.540]   so it might take time.
[02:08:39.540 --> 02:08:41.460]   So it could be lonely.
[02:08:41.460 --> 02:08:43.860]   You can really have to find the strength
[02:08:43.860 --> 02:08:44.900]   to believe in yourself.
[02:08:44.900 --> 02:08:46.100]   - Oh, for sure.
[02:08:46.100 --> 02:08:48.220]   And I'll tell you one quick story.
[02:08:48.220 --> 02:08:51.820]   1992, I went to Moscow State University
[02:08:51.820 --> 02:08:56.220]   to teach kids how to start businesses.
[02:08:56.220 --> 02:08:57.060]   - Wow.
[02:08:57.060 --> 02:09:01.140]   - 'Cause I had sold microsolutions and I wanted to travel.
[02:09:01.140 --> 02:09:02.940]   And I took Russian in high school.
[02:09:02.940 --> 02:09:05.140]   My Russian is like not so good.
[02:09:05.140 --> 02:09:07.860]   (laughing)
[02:09:07.860 --> 02:09:09.060]   - Good enough to remember that.
[02:09:09.060 --> 02:09:10.860]   - Yeah, right, yeah.
[02:09:10.860 --> 02:09:12.980]   But it was interesting to me and I bring it up
[02:09:12.980 --> 02:09:17.980]   because they didn't know what the word profit meant, right?
[02:09:17.980 --> 02:09:23.780]   But at the same time, I would go around and meet people
[02:09:23.780 --> 02:09:27.420]   and it was this entrepreneurial,
[02:09:27.420 --> 02:09:30.380]   like right after the Soviet Union fell,
[02:09:30.380 --> 02:09:32.020]   entrepreneurship went through the roof.
[02:09:32.020 --> 02:09:33.940]   I mean, a lot of it was mafia-driven,
[02:09:33.940 --> 02:09:37.940]   but people found that spark
[02:09:37.940 --> 02:09:39.820]   because I think that is natural.
[02:09:40.940 --> 02:09:43.980]   And so you just never know when and how and when
[02:09:43.980 --> 02:09:46.100]   the circumstances will come together
[02:09:46.100 --> 02:09:48.060]   for you to be able to take advantage.
[02:09:48.060 --> 02:09:50.180]   - That spark is really important to comment on
[02:09:50.180 --> 02:09:52.240]   is in Russia and Ukraine,
[02:09:52.240 --> 02:09:57.580]   I think the system kind of suppresses that spark somehow.
[02:09:57.580 --> 02:10:00.420]   As you said, you saw the natural entrepreneurship,
[02:10:00.420 --> 02:10:04.180]   but there's not the entrepreneurial spirit
[02:10:04.180 --> 02:10:06.740]   once you grow up in both of the nations I mentioned.
[02:10:06.740 --> 02:10:07.980]   There is.
[02:10:07.980 --> 02:10:08.820]   - No, I believe it, right?
[02:10:08.820 --> 02:10:09.660]   I mean- - Especially in Ukraine.
[02:10:09.660 --> 02:10:10.660]   But there's something about the system
[02:10:10.660 --> 02:10:12.420]   that kind of- - Without question.
[02:10:12.420 --> 02:10:14.820]   - Be reasonable, be secure, be safe.
[02:10:14.820 --> 02:10:16.100]   - There would have been no reason for me to go over
[02:10:16.100 --> 02:10:18.780]   to do what I was doing if it was otherwise.
[02:10:18.780 --> 02:10:19.620]   - But that's the thing
[02:10:19.620 --> 02:10:22.540]   that really can help a country flourish.
[02:10:22.540 --> 02:10:23.940]   - You know, it's gonna be interesting with Ukraine
[02:10:23.940 --> 02:10:25.940]   if they're able to survive this, right?
[02:10:25.940 --> 02:10:28.660]   Because as horrific as it is,
[02:10:28.660 --> 02:10:31.020]   as you saw across Europe after World War II,
[02:10:31.020 --> 02:10:35.380]   the rebuilding creates opportunities.
[02:10:35.380 --> 02:10:37.000]   - Rebuilding creates opportunities,
[02:10:37.000 --> 02:10:39.660]   but first the war has to end, how that ends-
[02:10:39.660 --> 02:10:40.500]   - I don't know either.
[02:10:40.500 --> 02:10:42.580]   - Is a really complex path.
[02:10:42.580 --> 02:10:45.220]   What gives you hope about the future of humanity?
[02:10:45.220 --> 02:10:48.820]   - Just looking in my kids' eyes,
[02:10:48.820 --> 02:10:53.300]   just talking to them and seeing their spirit,
[02:10:53.300 --> 02:10:54.660]   their friend spirit.
[02:10:54.660 --> 02:10:56.720]   And obviously we're blessed as can be, right?
[02:10:56.720 --> 02:10:58.380]   And it's not the same for every kid,
[02:10:58.380 --> 02:11:01.100]   but I do, I get emails that I respond,
[02:11:01.100 --> 02:11:02.040]   don't respond to all of them,
[02:11:02.040 --> 02:11:05.940]   but from 13, 14, 15-year-old kids around the world,
[02:11:05.940 --> 02:11:08.020]   'cause Shark Tank's shown everywhere,
[02:11:08.020 --> 02:11:09.620]   asking me business questions.
[02:11:09.620 --> 02:11:12.780]   And it's just like, they took the time.
[02:11:12.780 --> 02:11:14.940]   They were that curious and that interested.
[02:11:14.940 --> 02:11:18.020]   And I see it when I talk to schools,
[02:11:18.020 --> 02:11:21.300]   you know, when I go to different groups
[02:11:21.300 --> 02:11:26.660]   that spark in kids' eyes that there's something bigger
[02:11:26.660 --> 02:11:28.260]   and better and exciting out there.
[02:11:28.260 --> 02:11:30.100]   And that's not to say there's not fear,
[02:11:30.100 --> 02:11:33.860]   you know, climate and any other number of things,
[02:11:33.860 --> 02:11:35.900]   but that's the beauty of kids.
[02:11:35.900 --> 02:11:40.900]   And I think Gen Z really embodies that.
[02:11:40.900 --> 02:11:43.820]   And to me, that's just really exciting.
[02:11:43.820 --> 02:11:45.700]   - They dream, they dream big.
[02:11:45.700 --> 02:11:48.380]   They see the opportunity for making the world better.
[02:11:48.380 --> 02:11:49.220]   That's cool.
[02:11:49.220 --> 02:11:53.020]   It's cool to see young people in their eyes, that dream.
[02:11:53.020 --> 02:11:55.580]   And I could be the one to do it too,
[02:11:55.580 --> 02:11:56.620]   which is a super powerful thing.
[02:11:56.620 --> 02:11:58.340]   - It's funny, 'cause when I go talk
[02:11:58.340 --> 02:12:01.020]   to like elementary school kids, right?
[02:12:01.020 --> 02:12:03.820]   One of the things I do, I said, okay, let's look around.
[02:12:03.820 --> 02:12:05.180]   You see that light there?
[02:12:05.180 --> 02:12:06.940]   One day that light didn't exist.
[02:12:06.940 --> 02:12:08.460]   Then somebody had the idea.
[02:12:08.460 --> 02:12:10.260]   Then somebody created a product of it.
[02:12:10.260 --> 02:12:11.760]   And now your school bought that.
[02:12:11.760 --> 02:12:13.300]   You see that chair?
[02:12:13.300 --> 02:12:14.700]   Chairs didn't always look like that.
[02:12:14.700 --> 02:12:16.620]   Somebody had that idea.
[02:12:16.620 --> 02:12:17.500]   Why not you?
[02:12:17.500 --> 02:12:20.760]   So when you walk out and when I make them do, ask yourself,
[02:12:20.760 --> 02:12:21.800]   why not me?
[02:12:21.800 --> 02:12:24.300]   Why can't I be the one to change the world?
[02:12:24.300 --> 02:12:26.740]   - Thank you for that beautiful, hopeful message.
[02:12:26.740 --> 02:12:28.260]   And thank you for talking today, Mark.
[02:12:28.260 --> 02:12:31.700]   You're fun to follow.
[02:12:31.700 --> 02:12:32.940]   I'm a big fan of yours,
[02:12:32.940 --> 02:12:35.220]   but you're also an important person in this world.
[02:12:35.220 --> 02:12:36.780]   I really appreciate everything you do.
[02:12:36.780 --> 02:12:37.620]   - Well, I appreciate it.
[02:12:37.620 --> 02:12:38.540]   Thanks for saying that, Lexan.
[02:12:38.540 --> 02:12:39.380]   Keep on doing what you're doing.
[02:12:39.380 --> 02:12:40.220]   This was great.
[02:12:40.220 --> 02:12:41.820]   I really enjoyed this.
[02:12:41.820 --> 02:12:43.340]   - Thanks for listening to this conversation
[02:12:43.340 --> 02:12:44.580]   with Mark Cuban.
[02:12:44.580 --> 02:12:45.660]   To support this podcast,
[02:12:45.660 --> 02:12:48.220]   please check out our sponsors in the description.
[02:12:48.220 --> 02:12:51.820]   And now let me leave you with some words from Oscar Wilde.
[02:12:51.820 --> 02:12:53.700]   Imagination was given to man
[02:12:53.700 --> 02:12:56.820]   to compensate him for what he is not.
[02:12:56.820 --> 02:12:59.500]   And a sense of humor was provided
[02:12:59.500 --> 02:13:01.940]   to console him for what he is.
[02:13:02.900 --> 02:13:06.100]   Thank you for listening and hope to see you next time.
[02:13:06.100 --> 02:13:08.680]   (upbeat music)
[02:13:08.680 --> 02:13:11.260]   (upbeat music)
[02:13:11.260 --> 02:13:21.260]   [BLANK_AUDIO]

