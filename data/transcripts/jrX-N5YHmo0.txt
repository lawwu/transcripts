
[00:00:00.000 --> 00:00:01.920]   Wait to hear the echo while I do that.
[00:00:01.920 --> 00:00:03.840]   It always takes a minute.
[00:00:03.840 --> 00:00:13.040]   Awesome.
[00:00:13.040 --> 00:00:14.040]   I can hear the echo.
[00:00:14.040 --> 00:00:20.140]   Uh, I just, we're six weeks into it and I still do that just for my own, uh,
[00:00:20.140 --> 00:00:24.440]   assurance because I don't want to talk for one and a half hours and realize,
[00:00:24.440 --> 00:00:26.040]   Oh, it wasn't recorded.
[00:00:26.040 --> 00:00:29.000]   So I take my time there.
[00:00:29.160 --> 00:00:31.800]   Uh, just give me one minute while I bring all the links up
[00:00:31.800 --> 00:00:32.800]   and paste them in the chat.
[00:00:32.800 --> 00:00:42.080]   Let me pin this comment in the YouTube chart so that people
[00:00:42.080 --> 00:00:43.560]   know where to ask the questions.
[00:00:43.560 --> 00:00:47.440]   Um, and I had to drop the same one in the zoom chart as well.
[00:00:47.440 --> 00:00:56.160]   Oh, uh, you've already pasted it.
[00:00:56.160 --> 00:00:56.440]   Thanks.
[00:00:56.440 --> 00:01:03.160]   So Raj we're probably at the point where the people in the zoom call.
[00:01:03.160 --> 00:01:07.440]   Uh, so people watching on YouTube, this also gets live streamed.
[00:01:07.440 --> 00:01:10.760]   Uh, sorry, this is also a zoom call and the people in the zoom call
[00:01:10.760 --> 00:01:14.120]   probably can teach the session better than me at that point.
[00:01:14.120 --> 00:01:16.760]   Um, awesome.
[00:01:16.760 --> 00:01:20.520]   I'm super excited to welcome you all back to the Pytorch deep learning
[00:01:20.520 --> 00:01:24.840]   with Pytorch group where, uh, last time we crossed over the middle part of the book.
[00:01:25.080 --> 00:01:26.760]   So we're officially into part two.
[00:01:26.760 --> 00:01:28.960]   We're continuing that journey.
[00:01:28.960 --> 00:01:30.120]   I'm not sharing my screen yet.
[00:01:30.120 --> 00:01:31.280]   I'm just giving an overview.
[00:01:31.280 --> 00:01:34.800]   So we learned a lot about Pytorch basics and these were
[00:01:34.800 --> 00:01:36.840]   like the true ground basics.
[00:01:36.840 --> 00:01:39.160]   So what are the different functions?
[00:01:39.160 --> 00:01:40.960]   What are data sets?
[00:01:40.960 --> 00:01:42.240]   What are data loaders?
[00:01:42.240 --> 00:01:44.400]   Uh, what is a tensor?
[00:01:44.400 --> 00:01:45.800]   How do you work with those?
[00:01:45.800 --> 00:01:47.200]   What is transfer learning?
[00:01:47.200 --> 00:01:49.160]   What are CNNs?
[00:01:49.160 --> 00:01:53.440]   And we've built up to this point where we're ready to take on a project.
[00:01:53.600 --> 00:01:55.440]   Now there are different types of books.
[00:01:55.440 --> 00:01:57.000]   I've enjoyed a lot of them.
[00:01:57.000 --> 00:02:01.720]   This is the kind where the authors pick one project and
[00:02:01.720 --> 00:02:03.560]   cover it in depth thoroughly.
[00:02:03.560 --> 00:02:06.520]   And since we all are following this, that's what we're going to do.
[00:02:06.520 --> 00:02:08.920]   So we'll be learning about CT scans.
[00:02:08.920 --> 00:02:10.000]   We learned a little.
[00:02:10.000 --> 00:02:14.160]   So we got a few highlights last week and the dataset we're working
[00:02:14.160 --> 00:02:15.480]   with is called Luna 16.
[00:02:15.480 --> 00:02:18.160]   So we'll continue working on that every week.
[00:02:18.160 --> 00:02:22.680]   Uh, we're at the point where we're just reading code now.
[00:02:22.680 --> 00:02:26.760]   So a lot of time will be spent reading code and these are
[00:02:26.760 --> 00:02:29.120]   code, uh, this is code from the authors.
[00:02:29.120 --> 00:02:34.040]   The one thing I would request you all this time strongly is to maybe spend
[00:02:34.040 --> 00:02:36.120]   some hours ahead of time doing that.
[00:02:36.120 --> 00:02:38.920]   It's okay if you cannot, but that'll be more beneficial.
[00:02:38.920 --> 00:02:43.840]   I do spend a lot of time as I prepare for these sessions, but now we're at the
[00:02:43.840 --> 00:02:48.960]   point where one complete hour, we'll just be discussing one Python file.
[00:02:48.960 --> 00:02:53.640]   So, uh, you might learn more if you play around with it ahead of time.
[00:02:53.640 --> 00:02:56.000]   Uh, it'll still be covered nevertheless.
[00:02:56.000 --> 00:02:59.720]   Uh, so that's just a small suggestion so that you all can walk away with more.
[00:02:59.720 --> 00:03:11.240]   Let me share my screen and I see when I is there in this room, call it me, ask
[00:03:11.240 --> 00:03:13.800]   him if he'd like to start the presentation.
[00:03:17.800 --> 00:03:20.560]   So last week we wanted when I had to present, but he was facing some
[00:03:20.560 --> 00:03:23.680]   difficulties, uh, he's here.
[00:03:23.680 --> 00:03:26.560]   Uh, Vinayak I'll invite you as a panelist so that you can present.
[00:03:26.560 --> 00:03:37.840]   I'll give them a minute to rejoin.
[00:03:37.840 --> 00:03:41.480]   So zoom makes you rejoin the call as soon as you get promoted to a panelist.
[00:03:47.200 --> 00:03:49.760]   Yes, it's, it's a little quiet.
[00:03:49.760 --> 00:03:56.120]   Uh, could you please speak up a bit?
[00:03:56.120 --> 00:03:57.280]   It's still a little quiet.
[00:03:57.280 --> 00:04:02.440]   Yep.
[00:04:02.440 --> 00:04:03.360]   That's that's better.
[00:04:03.360 --> 00:04:06.400]   Awesome.
[00:04:06.400 --> 00:04:10.920]   So to give everyone some context, uh, Vinayak has been an amazing
[00:04:10.920 --> 00:04:15.320]   contributor to the group and, uh, I really wanted to invite him to just
[00:04:15.320 --> 00:04:20.040]   share his journey and tell us how he's been approaching writing blog posts
[00:04:20.040 --> 00:04:21.080]   and attending the session.
[00:04:21.080 --> 00:04:24.120]   So that's what we'll kick today's session off with.
[00:04:24.120 --> 00:04:25.160]   Uh, Vinayak, over to you.
[00:04:25.160 --> 00:04:26.680]   Thanks.
[00:04:26.680 --> 00:04:27.040]   Thanks.
[00:04:27.040 --> 00:04:32.000]   Say, thanks a lot for this opportunity and sorry, due to technical issues last
[00:04:32.000 --> 00:04:35.480]   week, I couldn't present my stuff.
[00:04:35.480 --> 00:04:37.760]   Say, you might can't share my screen.
[00:04:37.760 --> 00:04:38.880]   I'm sorry.
[00:04:38.880 --> 00:04:39.680]   I'll make you co-host.
[00:04:39.680 --> 00:04:40.720]   You should be able to now.
[00:04:40.720 --> 00:04:44.320]   Yes.
[00:04:44.320 --> 00:04:45.080]   Yes.
[00:04:45.400 --> 00:04:46.160]   Now I'm able to.
[00:04:46.160 --> 00:04:50.600]   So without any further ado, let me start.
[00:04:50.600 --> 00:04:52.520]   Uh, yeah.
[00:04:52.520 --> 00:04:53.360]   Hello everyone.
[00:04:53.360 --> 00:04:59.640]   So I'm Vinayak and, uh, I've been on this journey of Fastbook and PyTorch
[00:04:59.640 --> 00:05:05.560]   reading since it started and it's been really, it's like this initiative by
[00:05:05.560 --> 00:05:11.640]   Wadhi, Sanyam and Aman and Angelica and so many other people who have made this
[00:05:11.640 --> 00:05:12.000]   happen.
[00:05:12.000 --> 00:05:14.320]   This is a really great initiative.
[00:05:14.360 --> 00:05:16.320]   And I've learned a lot through it.
[00:05:16.320 --> 00:05:24.240]   So about me, uh, I am basically a mechanical engineer, uh, who, uh, I
[00:05:24.240 --> 00:05:33.160]   graduated in 2017 and then in 2019, I pursued a course in data science and then
[00:05:33.160 --> 00:05:37.920]   I started working at a fashion retail startup immediately after that.
[00:05:37.920 --> 00:05:44.160]   And, uh, the place I work, they use fast AI and that to very extensively.
[00:05:44.160 --> 00:05:50.120]   So that's when I was introduced to the course, uh, which Jeremy Howard has,
[00:05:50.120 --> 00:05:55.760]   uh, very generously made available on YouTube and all the sessions are really
[00:05:55.760 --> 00:05:56.120]   great.
[00:05:56.120 --> 00:06:03.440]   However, uh, like in that particular atmosphere, like, uh, what happened is I
[00:06:03.440 --> 00:06:06.600]   started my fast book journey, fast AI journey.
[00:06:06.600 --> 00:06:09.640]   And, uh, I did convolution.
[00:06:09.680 --> 00:06:14.960]   I did image classification, image regression, and then, uh, I kind of
[00:06:14.960 --> 00:06:15.520]   stopped it.
[00:06:15.520 --> 00:06:16.520]   It came to a halt.
[00:06:16.520 --> 00:06:24.200]   Uh, but now these courses are really good in terms of having a community of people
[00:06:24.200 --> 00:06:27.760]   who are keeping you accountable and like doing so much more.
[00:06:27.760 --> 00:06:33.600]   And it's always great to learn with, uh, like learn with the community.
[00:06:33.600 --> 00:06:38.760]   And so I want to mention, I first of all, I want to thank all of you.
[00:06:39.160 --> 00:06:45.280]   Like, uh, I, uh, those who do, for those who don't know, there was also a fast AI
[00:06:45.280 --> 00:06:49.440]   and hugging face, uh, course, which was conducted by Siam and William.
[00:06:49.440 --> 00:06:54.240]   Uh, like there are just at this point, I was like, there are just so many courses.
[00:06:54.240 --> 00:06:59.360]   I can't keep up with the pace of the number of courses that are coming out, but I try
[00:06:59.360 --> 00:07:05.200]   to, uh, keep going through the videos afterwards and keep learning through them.
[00:07:05.200 --> 00:07:06.760]   They are really good.
[00:07:06.760 --> 00:07:09.080]   Those four sessions, it was a really good intro.
[00:07:09.800 --> 00:07:15.240]   And, uh, for those who don't know, like fast book is also one more session, which
[00:07:15.240 --> 00:07:21.880]   Aman Arora conducted for 15 long weeks where he went right from the basics of fast
[00:07:21.880 --> 00:07:29.600]   AI and deep learning, uh, to making us really good with CNNs and, uh, like any, uh,
[00:07:29.600 --> 00:07:31.520]   all the image based tasks.
[00:07:31.520 --> 00:07:38.960]   Uh, and now we have taken a hiatus and I hope like the sessions continue at
[00:07:38.960 --> 00:07:40.720]   a further point in the future.
[00:07:40.720 --> 00:07:47.680]   So, and also I would like to point out some people who have been really like
[00:07:47.680 --> 00:07:54.360]   really great co-learners who helped me keep up, like, keep me accountable for
[00:07:54.360 --> 00:08:00.600]   what I'm doing and like, uh, I'm sorry, I'm not able to put all of them onto the
[00:08:00.600 --> 00:08:04.640]   panel, like, but these are some who have been very consistent and they have been
[00:08:04.640 --> 00:08:09.240]   writing blog posts, they have been talking about their journey, uh, responding on
[00:08:09.240 --> 00:08:11.560]   the forums, helping everyone out.
[00:08:11.560 --> 00:08:19.760]   So Ravi Mashroor, Ravi Chandra, Roo, Sai and Kurian and Maria and so many other
[00:08:19.760 --> 00:08:24.760]   people who are just doing amazing work out there, writing blog posts, helping
[00:08:24.760 --> 00:08:28.080]   people like who are posting questions out.
[00:08:28.080 --> 00:08:31.040]   And it's just, it's just great.
[00:08:32.640 --> 00:08:40.040]   Uh, then, uh, I remember that, uh, in the first session, uh, like common and even
[00:08:40.040 --> 00:08:46.640]   in the practical deep learning for coders, first session, Jeremy talks about, uh,
[00:08:46.640 --> 00:08:52.720]   why one should write a blog and it is because it is like, this has been like a
[00:08:52.720 --> 00:08:54.600]   really good journey for me.
[00:08:54.920 --> 00:09:03.160]   And, uh, like it forces me to think, uh, type into code and understand theory as
[00:09:03.160 --> 00:09:09.880]   well as code, and then try to break it down so that, uh, like when you're on this
[00:09:09.880 --> 00:09:16.400]   process of, uh, understanding something, and especially from the point of view of
[00:09:16.400 --> 00:09:20.560]   like, you want to teach it to somebody, there are a lot of things and nuances that
[00:09:20.560 --> 00:09:26.200]   you come across and you want to be sure about, and that strengthens the learning
[00:09:26.200 --> 00:09:27.480]   aspect a lot more.
[00:09:27.480 --> 00:09:34.200]   So like I've been personally blogging about things and it has really helped me
[00:09:34.200 --> 00:09:34.960]   with my studies.
[00:09:34.960 --> 00:09:40.240]   And, uh, particularly since we are also learning on a virtual medium, there is no
[00:09:40.240 --> 00:09:47.240]   strict assignments or, uh, coursework in, uh, that aspect when you are blogging, it
[00:09:47.240 --> 00:09:52.760]   is like, uh, it is like a homework that you are doing and you are trying to be
[00:09:52.760 --> 00:10:00.320]   like inculcate all the subject matter or the content which has been provided in the
[00:10:00.320 --> 00:10:01.000]   past week.
[00:10:01.000 --> 00:10:04.640]   And thereby it really is a really great learning.
[00:10:04.640 --> 00:10:12.360]   Uh, that's like also like, these are some resources which have personally helped me
[00:10:12.360 --> 00:10:12.680]   a lot.
[00:10:13.200 --> 00:10:18.800]   The past AI forums where there is Zach, there is Sayam, there is Aman and so many
[00:10:18.800 --> 00:10:24.000]   more, there's Tanishq and there's so many more, uh, awesome people who are always
[00:10:24.000 --> 00:10:29.040]   putting stuff up there and helping people with their doubts and questions.
[00:10:29.040 --> 00:10:34.840]   There's WANP forums, which is where the chat is currently like, uh, which is where
[00:10:34.840 --> 00:10:39.200]   the questions that have been, that are, that we are supposed to ask, like Sayam has
[00:10:39.200 --> 00:10:45.040]   already posted a link in the zoom and well, and, uh, in the YouTube link as well.
[00:10:45.040 --> 00:10:46.600]   And there's PyTorch forums.
[00:10:46.600 --> 00:10:53.720]   And I would say Twitter has been a very instrumental social media platform, which
[00:10:53.720 --> 00:10:59.440]   has kind of helped me, uh, keep up to pace with whatever is happening in the deep
[00:10:59.440 --> 00:11:00.720]   learning and machine learning world.
[00:11:00.720 --> 00:11:07.480]   And it gives you so much connectivity that you can just ask people who have written
[00:11:07.480 --> 00:11:12.960]   the paper and like, they are generous enough to come back and reply to you as
[00:11:12.960 --> 00:11:18.280]   well as, uh, if you look at some chapters in past book, Jeremy Howard himself has
[00:11:18.280 --> 00:11:26.000]   mentioned that he had posted, like he had posted to, uh, posted about, posted a tweet
[00:11:26.000 --> 00:11:31.520]   about some of the basics of convolution and Jan Likun and these guys who are regarded
[00:11:31.520 --> 00:11:36.200]   as a father of deep learning came and really they increased the engagement.
[00:11:36.200 --> 00:11:41.280]   So like, to me, it's personally, like, if you can learn from the father of deep
[00:11:41.280 --> 00:11:42.520]   learning, what more do you need?
[00:11:42.520 --> 00:11:48.680]   So in that case, Twitter has really, uh, helped in the democratization of AI.
[00:11:48.680 --> 00:11:54.960]   Uh, then this is an awesome blog again, machine learning mastery, which is, uh,
[00:11:54.960 --> 00:12:00.600]   hosted by Jason Brownlee, who is a PhD in data science and like, uh, operates out of
[00:12:00.600 --> 00:12:01.240]   Australia.
[00:12:01.360 --> 00:12:07.240]   Pi with search by Adrian Rosebrock is also a very good resource, particularly for the
[00:12:07.240 --> 00:12:14.840]   traditional machine learning algorithms, like, uh, like applying Gaussian filters or
[00:12:14.840 --> 00:12:19.360]   edge detection filters for image retrieval or all these things.
[00:12:19.360 --> 00:12:23.520]   Like there is people who are doing these things even before deep learning.
[00:12:23.520 --> 00:12:28.200]   And it is really good to see, like, it gives you a holistic picture of how deep
[00:12:28.200 --> 00:12:34.040]   learning has helped and also it helps to appreciate the fact that there are also
[00:12:34.040 --> 00:12:37.360]   simple algorithms which can be used.
[00:12:37.360 --> 00:12:44.200]   Uh, and yeah, then there is obviously the data science podcast, which is hosted by
[00:12:44.200 --> 00:12:45.080]   Siam himself.
[00:12:45.080 --> 00:12:52.440]   And like, it is a really great, great initiative because it helps us give a direct
[00:12:52.440 --> 00:12:57.040]   peek into the world of people who are actually doing data science.
[00:12:57.040 --> 00:13:01.160]   Now with the gradient descent podcast, which is hosted by Bond B, that is also a
[00:13:01.160 --> 00:13:07.720]   great medium, but I think CTDS was one of, one of the first few things which were like,
[00:13:07.720 --> 00:13:13.920]   where you directly could see Jeremy Howard engage in a casual conversation with Siam
[00:13:13.920 --> 00:13:17.680]   and talk about his journey or Adrian Rosebrock for that matter.
[00:13:17.680 --> 00:13:21.280]   And that was a really great initiative as well.
[00:13:21.880 --> 00:13:27.480]   So yeah, I hope you had fun and like, this is where I would like to end.
[00:13:27.480 --> 00:13:29.660]   Yeah.
[00:13:29.660 --> 00:13:33.880]   I feel you, you mentioned there's no homework for blogging and anything.
[00:13:33.880 --> 00:13:35.760]   Maybe I need to be more strict with the homework.
[00:13:35.760 --> 00:13:41.840]   I strongly announce the blogs, but Vinayak you've been, you've been putting out
[00:13:41.840 --> 00:13:46.680]   amazing blog posts and even resources for that matter.
[00:13:46.720 --> 00:13:52.640]   What was the most useful thing for you as you like, you also come from a non coding
[00:13:52.640 --> 00:13:54.440]   background being a mechanical engineer.
[00:13:54.440 --> 00:13:56.360]   How, how do you practice this?
[00:13:56.360 --> 00:13:58.560]   What, what do you suggest to all of us?
[00:13:58.560 --> 00:14:06.880]   So I suggest that like, the thing which I would suggest is blogging is really good.
[00:14:06.880 --> 00:14:12.520]   Then this top down approach, which Jeremy Howard has introduced is really a great,
[00:14:12.560 --> 00:14:17.960]   great approach because like I was intimidated when I looked at the research
[00:14:17.960 --> 00:14:25.200]   people and so much math there and like all these CY by DX terms and like,
[00:14:25.200 --> 00:14:33.320]   do Y by do XL partial derivatives is that, but if you really try to quote them, like
[00:14:33.320 --> 00:14:41.080]   this is what I also bought from a man in another group that he, another paper
[00:14:41.080 --> 00:14:46.560]   reading group, which he conducts where he mentions that if you try to take the
[00:14:46.560 --> 00:14:54.080]   essence of what is there in the formulas and try to build or code it into Python,
[00:14:54.080 --> 00:14:58.720]   that gives you a very good, you know, understanding of what it's about.
[00:14:58.720 --> 00:15:03.600]   So like this top down approach and code first approach is really something which
[00:15:03.600 --> 00:15:06.560]   has helped me understand and decode a lot of things.
[00:15:06.560 --> 00:15:10.840]   Yeah, that's what I would suggest.
[00:15:11.160 --> 00:15:17.720]   Everyone who is trying to like get into deep learning that start top down to
[00:15:17.720 --> 00:15:24.040]   code first and look at awesome resources which have which have been put on
[00:15:24.040 --> 00:15:30.160]   YouTube on like on practical deep learning for coders or on one PV session.
[00:15:30.160 --> 00:15:33.360]   So yeah, that would be my two cents.
[00:15:33.360 --> 00:15:35.200]   Awesome. Thanks.
[00:15:35.200 --> 00:15:39.040]   And also thanks for all the shout outs to our study groups and also the podcast.
[00:15:39.880 --> 00:15:43.720]   I requested you to present the time series one but in interest of time.
[00:15:43.720 --> 00:15:46.200]   Can we delay that?
[00:15:46.200 --> 00:15:48.000]   Yes, yes. Yes, certainly.
[00:15:48.000 --> 00:15:49.560]   Thanks.
[00:15:49.560 --> 00:15:51.080]   Stop. Yeah.
[00:15:51.080 --> 00:15:53.680]   Thanks. Thanks again.
[00:15:53.680 --> 00:16:00.640]   Thanks a lot for helping me present this and like, for giving the exposure to
[00:16:00.640 --> 00:16:06.760]   Ravi, to me, to so many other people and to do this like absolutely free of cost
[00:16:06.760 --> 00:16:09.880]   without like, that is really, really a great thing.
[00:16:09.880 --> 00:16:17.080]   At Bits and Biases, we are quite committed to the community and I'm just
[00:16:17.080 --> 00:16:17.920]   part of the team.
[00:16:17.920 --> 00:16:19.560]   So it's it's been a complete team effort.
[00:16:19.560 --> 00:16:21.600]   I'm just copying Aman's style.
[00:16:21.600 --> 00:16:25.360]   We're just trying to do this as a community and for the community and we
[00:16:25.360 --> 00:16:32.520]   really want to learn from people like you and it's like incredible that you, Ravi,
[00:16:32.520 --> 00:16:34.840]   both Ravi's, Adil for that matter.
[00:16:35.000 --> 00:16:40.200]   All of you just have been contributing so much and that just means that some maybe
[00:16:40.200 --> 00:16:41.320]   this process is working.
[00:16:41.320 --> 00:16:43.120]   So I really wanted to learn from you.
[00:16:43.120 --> 00:16:45.880]   But what's been your journey like and thanks.
[00:16:45.880 --> 00:16:46.680]   Thanks for presenting.
[00:16:46.680 --> 00:16:48.160]   Thank you.
[00:16:48.160 --> 00:16:54.640]   Awesome. I'll go back to presenting.
[00:16:59.000 --> 00:17:07.640]   And Vinayak, I'll try to remove you as a co-host so that it doesn't, I don't think
[00:17:07.640 --> 00:17:11.440]   it would show up the YouTube video.
[00:17:11.440 --> 00:17:11.880]   I'm sorry.
[00:17:11.880 --> 00:17:13.200]   This is the first time I'm doing this.
[00:17:13.200 --> 00:17:17.160]   I just request you to not turn on your video or mic because then YouTube gets
[00:17:17.160 --> 00:17:17.600]   confused.
[00:17:17.600 --> 00:17:18.040]   Thanks.
[00:17:18.040 --> 00:17:24.760]   All right, let me share my screen and get back to today's session.
[00:17:24.760 --> 00:17:26.160]   Thanks again, Vinayak.
[00:17:26.760 --> 00:17:32.240]   So today we're going to learn how can we work with CT scan data in PyTorch.
[00:17:32.240 --> 00:17:36.760]   And I think we might not be able to get to classifying tumors.
[00:17:36.760 --> 00:17:38.400]   I wanted to do that.
[00:17:38.400 --> 00:17:44.440]   But again, in interest of time, I want to cover concepts really well instead of just
[00:17:44.440 --> 00:17:45.240]   covering concepts.
[00:17:45.240 --> 00:17:48.080]   Let me take off my headphones since I don't need to hear anything now.
[00:17:48.080 --> 00:17:54.600]   The issue with my microphone is it gives me an echo and I can hear myself talk.
[00:17:54.920 --> 00:17:57.960]   So it, it, it gets a little annoying sometimes.
[00:17:57.960 --> 00:18:01.080]   Awesome.
[00:18:01.080 --> 00:18:02.640]   Let's let's continue.
[00:18:02.640 --> 00:18:06.080]   Last week we had learned a lot about CT scans.
[00:18:06.080 --> 00:18:09.960]   We're going to continue that quickly recap and continue that further.
[00:18:09.960 --> 00:18:15.360]   But before that, I also want to give a mention to two talks that happened this
[00:18:15.360 --> 00:18:17.600]   week, sorry, one talk that happened this week.
[00:18:17.600 --> 00:18:20.840]   So Chai Time Kaggle Talk with Grandmaster Indrada.
[00:18:21.600 --> 00:18:26.400]   Indrada is really one of the best storytellers worldwide.
[00:18:26.400 --> 00:18:31.560]   One of the best Kagglers who've been, who's been consistently putting out
[00:18:31.560 --> 00:18:32.560]   Kaggle kernels.
[00:18:32.560 --> 00:18:38.240]   And I just wanted to mention this session because at the end of, you know, hosting
[00:18:38.240 --> 00:18:42.600]   these study groups or anything that you join for that matter, the end goal for,
[00:18:42.600 --> 00:18:47.560]   I'm assuming you are for us is just to become a better practitioner, right?
[00:18:47.560 --> 00:18:49.240]   And that's why I wanted to learn from Vinayak.
[00:18:49.240 --> 00:18:51.280]   That's why we're hosting these sessions also.
[00:18:51.760 --> 00:18:54.440]   And this is part of Chai Time Data Science 2.0.
[00:18:54.440 --> 00:18:58.920]   Indrada shared a lot of tips about how she approaches ADA, which is one of the
[00:18:58.920 --> 00:19:04.640]   most important steps in the data science pipeline, in the deep learning pipeline
[00:19:04.640 --> 00:19:07.080]   or any part of machine learning for that matter.
[00:19:07.080 --> 00:19:09.440]   So I would encourage you to check that out.
[00:19:09.440 --> 00:19:13.280]   It's again, part of this playlist that's there on a YouTube channel.
[00:19:13.280 --> 00:19:17.960]   These are quite, I would say detail oriented.
[00:19:18.000 --> 00:19:23.120]   And the only reason for hosting these is so that everyone can learn from these
[00:19:23.120 --> 00:19:27.160]   little tricks that no one really discusses outside of Kaggle.
[00:19:27.160 --> 00:19:28.920]   We really try to bring those out.
[00:19:28.920 --> 00:19:33.720]   So as a reminder this was the homework, which I'm really
[00:19:33.720 --> 00:19:35.400]   happy Vinayak got to this week.
[00:19:35.400 --> 00:19:39.160]   So one of those was strike on 1D for some time series data set.
[00:19:39.160 --> 00:19:43.680]   I didn't mention which I left that for any of you to figure out, finish all
[00:19:43.680 --> 00:19:46.520]   previous chapters and I'd suggest just starting reading ahead.
[00:19:47.440 --> 00:19:52.680]   Vinayak created this incredible thread and at the end of it, you can find this
[00:19:52.680 --> 00:19:57.520]   blog post I'll post that in the community shortly, but this talks about time series
[00:19:57.520 --> 00:20:03.520]   analysis with CNNs and I really like how he's first of all introduced the theory.
[00:20:03.520 --> 00:20:06.720]   That's another thing we can learn from good blog posts.
[00:20:06.720 --> 00:20:09.280]   What do they do better and what can we follow or not?
[00:20:09.280 --> 00:20:15.040]   And Vinayak has introduced the theory first.
[00:20:15.040 --> 00:20:19.320]   So one thing we all can learn from here is whenever you're introducing a concept
[00:20:19.320 --> 00:20:22.520]   or whenever you're talking about it, please know your target audience, please
[00:20:22.520 --> 00:20:27.920]   introduce the concepts and please cover them like your target audience would want
[00:20:27.920 --> 00:20:28.480]   them covered.
[00:20:28.480 --> 00:20:31.040]   So it was a really nice blog post.
[00:20:31.040 --> 00:20:34.840]   I want to mention another one by Girijesh.
[00:20:34.840 --> 00:20:40.280]   Girijesh has also been incredibly consistent with his blog posts.
[00:20:40.280 --> 00:20:42.360]   This time we got a chapter six summary.
[00:20:43.040 --> 00:20:50.720]   I really like how he's involved all of these images from the book and also kept
[00:20:50.720 --> 00:20:53.680]   some code in there while explaining pretty much everything.
[00:20:53.680 --> 00:20:56.160]   So this is again, something that we all can learn from.
[00:20:56.160 --> 00:21:00.640]   Please feel free to post this in the community thread if you like.
[00:21:00.640 --> 00:21:06.640]   I would just have one small bit of suggestion for you Girijesh if you could
[00:21:06.640 --> 00:21:08.360]   please credit these images.
[00:21:08.360 --> 00:21:12.640]   It's always a good idea to credit any bit of knowledge wherever you take that from.
[00:21:12.640 --> 00:21:17.520]   So I don't think I saw it, but it might be nice to just mention that these come
[00:21:17.520 --> 00:21:18.160]   from the book.
[00:21:18.160 --> 00:21:28.520]   So as a reminder, we discuss questions and answers in the discourse forum.
[00:21:28.520 --> 00:21:35.280]   If you head over to this link, it should take you to the discussion and you can
[00:21:35.280 --> 00:21:38.640]   see some chat going on here already.
[00:21:38.640 --> 00:21:41.400]   I'm just like trying to read and mention things.
[00:21:42.400 --> 00:21:47.640]   Yeah, Prabhav has been pointing things out about Kaggle.
[00:21:47.640 --> 00:21:48.680]   So that's really good to know.
[00:21:48.680 --> 00:21:53.520]   But ask any questions here and I'll answer them.
[00:21:53.520 --> 00:22:01.920]   As a reminder, I look out on here instead of the YouTube chat and the Zoom chat,
[00:22:01.920 --> 00:22:05.200]   just because it's really difficult to keep an eye out on both of them.
[00:22:05.200 --> 00:22:07.760]   So from time to time, I'll keep looking here.
[00:22:11.000 --> 00:22:16.040]   So continuing further, we're talking about CT scans and datasets.
[00:22:16.040 --> 00:22:22.480]   As I mentioned, we'll just look at this dataset called Luna 16 dataset, also
[00:22:22.480 --> 00:22:24.040]   part of a Kaggle competition.
[00:22:24.040 --> 00:22:27.640]   And today we learn how to set up the dataset for it.
[00:22:27.640 --> 00:22:32.160]   I'll also try to ask a few questions and try to keep it as interactive
[00:22:32.160 --> 00:22:33.520]   as possible for all of you.
[00:22:33.520 --> 00:22:38.360]   Here's the agenda from today.
[00:22:38.960 --> 00:22:43.640]   I'll try to recap what we started last week, maybe a little bit in more depth.
[00:22:43.640 --> 00:22:45.560]   I think it's going to happen naturally.
[00:22:45.560 --> 00:22:50.840]   The interesting challenge or the interesting bit that happens with deep
[00:22:50.840 --> 00:22:55.040]   learning, I know Jeremy has mentioned this in fast day also, as you try to,
[00:22:55.040 --> 00:23:00.160]   so deep learning by itself, no, no spoilers here is just a bunch of matrix
[00:23:00.160 --> 00:23:00.800]   math, right?
[00:23:00.800 --> 00:23:05.120]   Like with some interesting math techniques that are applied in a few
[00:23:05.120 --> 00:23:06.360]   different ways.
[00:23:07.120 --> 00:23:08.960]   It's about where you apply it.
[00:23:08.960 --> 00:23:14.320]   So with CT scans, we of course need to know what they are about.
[00:23:14.320 --> 00:23:15.680]   We get some domain knowledge.
[00:23:15.680 --> 00:23:19.960]   And Jeremy said, whenever you're applying this to some, some domain, right?
[00:23:19.960 --> 00:23:21.880]   You walk away with a lot more knowledge.
[00:23:21.880 --> 00:23:26.040]   It's also helpful to just know about things as we'll find out today.
[00:23:26.040 --> 00:23:28.720]   So I'll also try to introduce those concepts.
[00:23:28.720 --> 00:23:32.200]   It's nothing that I'm coming up with.
[00:23:32.200 --> 00:23:34.760]   It's already there in the book, but I'm just trying to summarize the
[00:23:34.760 --> 00:23:36.520]   bits that I feel are quite important.
[00:23:37.040 --> 00:23:40.800]   So that when you study or if you've studied, it's important for it's easy.
[00:23:40.800 --> 00:23:45.720]   It's easy for you to remember this stuff as a reminder, please post all
[00:23:45.720 --> 00:23:49.120]   questions here and I'll keep, keep an eye out on the forum thread.
[00:23:49.120 --> 00:24:00.320]   So, uh, I again, want to go back to fast AI and the top-down learning
[00:24:00.320 --> 00:24:03.720]   approach and start by talking about one thing that's important.
[00:24:03.720 --> 00:24:08.600]   I was having this discussion just before we went live on YouTube and it's
[00:24:08.600 --> 00:24:10.680]   about GPU and the environment setup.
[00:24:10.680 --> 00:24:15.520]   And this will be more of just practical advice, things I've learned the
[00:24:15.520 --> 00:24:20.080]   hard way, the real hard way it's, it's been really annoying, but, uh, we're
[00:24:20.080 --> 00:24:24.440]   at the point I stopped sharing my screen and I just want to speak to the camera.
[00:24:24.440 --> 00:24:28.600]   We're at the point where we really need to experiment.
[00:24:29.160 --> 00:24:32.640]   And I know there are a huge number of options.
[00:24:32.640 --> 00:24:36.320]   You could use AWS, you could use GCP, you could use Google
[00:24:36.320 --> 00:24:38.160]   Colab, you could use Kaggle kernels.
[00:24:38.160 --> 00:24:43.560]   The point I'm trying to make here is the main differentiating factor for all of
[00:24:43.560 --> 00:24:50.800]   these discussion really becomes, uh, how expensive is it and should be how easy it
[00:24:50.800 --> 00:24:51.080]   is.
[00:24:51.080 --> 00:24:56.160]   So personally, it's my opinion and I would give a soft suggestion,
[00:24:56.160 --> 00:24:57.720]   maybe not a strong one for this.
[00:24:58.400 --> 00:25:03.720]   Uh, but please don't get too bogged down with comparing the prices.
[00:25:03.720 --> 00:25:07.120]   It's good to compare, you know, if you can get something at half of the price
[00:25:07.120 --> 00:25:12.760]   of what a major service offers, but remember the second point, it should be
[00:25:12.760 --> 00:25:13.800]   easy to work with.
[00:25:13.800 --> 00:25:16.920]   So if you can get something for really cheap and you know, it really works
[00:25:16.920 --> 00:25:20.520]   between 2am to 5am this, there's no point in that.
[00:25:20.520 --> 00:25:25.160]   Uh, what I'm trying to remind you through that is, uh, hopefully all of us will be
[00:25:25.160 --> 00:25:32.120]   working in deep learning at some point or another in our lives and really spending
[00:25:32.120 --> 00:25:40.040]   a hundred, $200 a month on that is, is, is not a huge expense.
[00:25:40.040 --> 00:25:45.240]   It's, it's much smaller than a tuition fee, right?
[00:25:45.240 --> 00:25:50.200]   At this point, personally, I spend more than my university fees on graphic cards.
[00:25:50.200 --> 00:25:53.680]   I absolutely don't encourage that, but I would say this.
[00:25:54.680 --> 00:25:57.720]   If you can get something for $20, that works really well.
[00:25:57.720 --> 00:26:02.000]   Please don't fight over saving those $10 for something that
[00:26:02.000 --> 00:26:03.840]   really adds in headache for you.
[00:26:03.840 --> 00:26:05.760]   I'm not going to name any services.
[00:26:05.760 --> 00:26:06.440]   It's for you.
[00:26:06.440 --> 00:26:09.720]   We're quite advanced at this point where you can figure those services out.
[00:26:09.720 --> 00:26:10.680]   You can use them.
[00:26:10.680 --> 00:26:15.320]   I think Kaggle kernels are really incredible and I would maybe
[00:26:15.320 --> 00:26:16.720]   give a soft solution for that.
[00:26:16.720 --> 00:26:23.600]   So, you know, please, as a reminder, use the easiest option.
[00:26:23.800 --> 00:26:29.920]   Uh, my, my joke that I keep telling everyone is I joined deep learning
[00:26:29.920 --> 00:26:31.720]   to become a deep learning practitioner.
[00:26:31.720 --> 00:26:34.880]   And now I've become a full-time IT administrator because of my box.
[00:26:34.880 --> 00:26:38.800]   There are these insane number of setup steps involved.
[00:26:38.800 --> 00:26:40.680]   You don't want to deal with that.
[00:26:40.680 --> 00:26:42.400]   You just want to learn these techniques.
[00:26:42.400 --> 00:26:44.240]   You want to train models.
[00:26:44.240 --> 00:26:45.640]   So focus on that, please.
[00:26:45.640 --> 00:26:49.960]   And don't spend too much time comparing the charges.
[00:26:49.960 --> 00:26:51.880]   Uh, look out for the good options.
[00:26:51.880 --> 00:26:53.120]   See what works well for you.
[00:26:53.680 --> 00:26:56.360]   And ensure your setup is flawless.
[00:26:56.360 --> 00:27:00.560]   So when you get an idea or when you want to try an idea, all of us are
[00:27:00.560 --> 00:27:04.640]   reading this book by giving it a few hours of our week, not the entire week.
[00:27:04.640 --> 00:27:09.920]   So when you get those few hours, make sure those are spent on running the
[00:27:09.920 --> 00:27:16.280]   experiments on understanding things and not, not figuring out how to install a
[00:27:16.280 --> 00:27:19.640]   library, you have to do that once, but not every single day, please.
[00:27:19.640 --> 00:27:21.360]   So please don't spend time there.
[00:27:22.640 --> 00:27:24.360]   I'll probably mention Kaggle here.
[00:27:24.360 --> 00:27:28.520]   So the nice thing about Kaggle is there are all of these competition where all
[00:27:28.520 --> 00:27:30.200]   of this code has already been put out.
[00:27:30.200 --> 00:27:33.960]   I'm pointing to this competition because we'll come back and talk a bit about it.
[00:27:33.960 --> 00:27:36.760]   Uh, yes, we'll, we'll start talking about Kaggle also.
[00:27:36.760 --> 00:27:42.920]   We're at that point, but if you just head over to Kaggle, uh, and you go to the
[00:27:42.920 --> 00:27:48.080]   code tab, you can simply create a notebook on here.
[00:27:48.840 --> 00:27:52.720]   And the nice thing about Kaggle is first of all, you get around 40 hours
[00:27:52.720 --> 00:27:54.440]   of GPU quota every single week.
[00:27:54.440 --> 00:28:01.040]   Secondly, you can find pretty much any single dataset that you would
[00:28:01.040 --> 00:28:04.640]   ever require for your purposes.
[00:28:04.640 --> 00:28:07.360]   So see, we already have Luna 16 dataset.
[00:28:07.360 --> 00:28:13.720]   It's always a good practice to upvote things that you use and give credit.
[00:28:13.720 --> 00:28:15.160]   Please always give credit.
[00:28:15.160 --> 00:28:16.520]   I can't emphasize this enough.
[00:28:17.160 --> 00:28:21.480]   Whenever you're working with anything at all, uh, give credit.
[00:28:21.480 --> 00:28:22.560]   It's, it's not that hard.
[00:28:22.560 --> 00:28:24.520]   It's nothing out of the world.
[00:28:24.520 --> 00:28:26.640]   Make sure you do that.
[00:28:26.640 --> 00:28:30.720]   So Kaggle has datasets, has everything installed, has GPU.
[00:28:30.720 --> 00:28:31.640]   Just use that.
[00:28:31.640 --> 00:28:34.840]   Once you're at the point where it's really slow, then consider
[00:28:34.840 --> 00:28:35.920]   investing into hardware.
[00:28:35.920 --> 00:28:39.320]   Uh, that's another conversation we can save for later.
[00:28:39.320 --> 00:28:40.880]   What is my setup?
[00:28:40.880 --> 00:28:45.240]   So I have a local box that's sitting right behind me here.
[00:28:45.280 --> 00:28:47.480]   This is the box that I SSH into.
[00:28:47.480 --> 00:28:51.640]   And whenever you see me sharing my Jupyter notebook, it's running on local
[00:28:51.640 --> 00:28:54.200]   host, which means I have SSH into it.
[00:28:54.200 --> 00:28:58.320]   And the Jupyter notebook you see on your screens right now is
[00:28:58.320 --> 00:28:59.720]   running on the server behind me.
[00:28:59.720 --> 00:29:05.800]   This is again, pretty common with people who run a lot of code, deep learning
[00:29:05.800 --> 00:29:07.200]   code and train a lot of models.
[00:29:07.200 --> 00:29:09.000]   Uh, not that I'm the best one of them.
[00:29:09.000 --> 00:29:11.040]   I just train a lot of models that fail.
[00:29:11.040 --> 00:29:13.880]   So to save my cloud costs, I invest a lot in hardware.
[00:29:14.880 --> 00:29:18.960]   But I really, again, wanted to spend five minutes emphasizing on the
[00:29:18.960 --> 00:29:21.280]   fact that please get your setup, right?
[00:29:21.280 --> 00:29:24.480]   Uh, this is what Jeremy Howard strongly says.
[00:29:24.480 --> 00:29:24.800]   Yes.
[00:29:24.800 --> 00:29:27.440]   And one thing I've learned is again, you want to be a deep learning
[00:29:27.440 --> 00:29:29.480]   practitioner and not an IT administrator.
[00:29:29.480 --> 00:29:31.840]   So spend your time wisely.
[00:29:31.840 --> 00:29:33.920]   Awesome.
[00:29:33.920 --> 00:29:37.360]   So to recap chapter nine, we understood what CT scans were.
[00:29:37.360 --> 00:29:40.200]   Uh, we learned why are there such a hard problem.
[00:29:40.200 --> 00:29:44.920]   And that's because it's such a big scan where we create up
[00:29:44.920 --> 00:29:47.160]   sometimes even hundreds of slices.
[00:29:47.160 --> 00:29:51.480]   Uh, it's like a needle in a haystack problem.
[00:29:51.480 --> 00:29:55.360]   Most of the tumors also are not cancerous.
[00:29:55.360 --> 00:29:59.720]   Most of their volume is not cancerous and which is trying to predict
[00:29:59.720 --> 00:30:02.480]   cancer here based on those 3d images.
[00:30:02.480 --> 00:30:05.720]   So that's what makes it an incredibly hard problem.
[00:30:05.720 --> 00:30:08.560]   We try to understand the data set a bit.
[00:30:08.840 --> 00:30:14.920]   And I last time claimed, and I backed the claim with a proof why
[00:30:14.920 --> 00:30:16.400]   these I learned for this paperwork.
[00:30:16.400 --> 00:30:24.360]   So again, I'd asked this question last week, Pytorch to fight cancer.
[00:30:24.360 --> 00:30:26.680]   What would be the steps of the Luna 16 dataset?
[00:30:26.680 --> 00:30:30.160]   Uh, we will be looking at the first part today.
[00:30:30.160 --> 00:30:32.880]   So we'll be looking at how to perform data loading.
[00:30:32.880 --> 00:30:36.120]   And I'll probably again, ask this question.
[00:30:36.120 --> 00:30:39.600]   So let me maybe pull up the dataset here.
[00:30:39.600 --> 00:30:45.800]   I should probably open a terminal.
[00:30:45.800 --> 00:30:52.680]   New terminal.
[00:30:52.680 --> 00:31:01.720]   So this is how I like to structure my own projects.
[00:31:01.800 --> 00:31:06.400]   Uh, not that you need to follow this, but usually this is my PC.
[00:31:06.400 --> 00:31:07.920]   I call it proton super.
[00:31:07.920 --> 00:31:12.120]   It's a long story, but I have a data folder inside of which all of
[00:31:12.120 --> 00:31:14.800]   the data files that I work with, uh, live.
[00:31:14.800 --> 00:31:18.280]   So right now, as you can see, I'm working with these following datasets.
[00:31:18.280 --> 00:31:21.200]   Not that I'm, I'm doing anything interesting on them, but these are
[00:31:21.200 --> 00:31:22.800]   the ones I work with every day.
[00:31:22.800 --> 00:31:24.360]   And these live here.
[00:31:24.360 --> 00:31:31.480]   I have also invested a good amount in, uh, SSDs and making sure it's all accessible.
[00:31:31.480 --> 00:31:35.280]   So I have a decent hard drive, actually a 10 terabyte one
[00:31:35.280 --> 00:31:36.800]   that stores all of my datasets.
[00:31:36.800 --> 00:31:41.920]   Uh, you figure those problems as you approach enough things in deep learning.
[00:31:41.920 --> 00:31:46.600]   For here, uh, we're looking at the data folder inside of that.
[00:31:46.600 --> 00:31:47.720]   We have the Luna file.
[00:31:47.720 --> 00:31:52.720]   So this further has different subsets.
[00:31:52.720 --> 00:31:57.160]   Now, this is also an incredible problem of its own, right?
[00:31:57.160 --> 00:32:00.640]   If you have a own rig, you need to download this data.
[00:32:00.640 --> 00:32:06.600]   You need to ensure that your internet works properly.
[00:32:06.600 --> 00:32:09.400]   When you downloaded the file, shouldn't be corrupt and your
[00:32:09.400 --> 00:32:10.800]   disk should be able to host them.
[00:32:10.800 --> 00:32:14.960]   That's why starting with Kaggle is a really good option.
[00:32:14.960 --> 00:32:20.240]   So again, this dataset that I had opened up Luna 16, I'll just post this.
[00:32:20.240 --> 00:32:21.560]   That's what we're working with.
[00:32:21.560 --> 00:32:25.280]   Let me close everything that we're not looking at.
[00:32:30.240 --> 00:32:31.680]   Thanks for posting the slides on that.
[00:32:31.680 --> 00:32:38.360]   So I want to point this data set out, uh, just because I think
[00:32:38.360 --> 00:32:40.120]   this is a good starting point.
[00:32:40.120 --> 00:32:43.360]   If you don't have the dataset with you locally, which most of you wouldn't,
[00:32:43.360 --> 00:32:46.440]   you can just click new notebook and start working from there.
[00:32:46.440 --> 00:32:49.440]   I'm not going to do that because that takes like one minute to three minutes.
[00:32:49.440 --> 00:32:50.680]   I don't want to waste our time.
[00:32:50.680 --> 00:32:55.000]   Uh, but it looks like there are subsets zero to four and all
[00:32:55.000 --> 00:32:56.200]   of the other files are there.
[00:32:56.200 --> 00:32:58.720]   So you can work with a smaller subset.
[00:32:59.120 --> 00:33:05.760]   Another practical advice I want to give here, start with a subset of the data,
[00:33:05.760 --> 00:33:11.000]   especially with images, I can't emphasize this enough start with one
[00:33:11.000 --> 00:33:16.200]   tens, one hundred of the data are to get things working instead of the complete
[00:33:16.200 --> 00:33:16.720]   dataset.
[00:33:16.720 --> 00:33:20.360]   So, uh, it's, it's probably good to just grab the full subset.
[00:33:20.360 --> 00:33:27.680]   Closing this tab again.
[00:33:27.680 --> 00:33:34.120]   And close this one.
[00:33:34.120 --> 00:33:34.880]   I'm sorry.
[00:33:34.880 --> 00:33:38.280]   I just have a lot of tabs open today and zoom is coming in the way.
[00:33:38.280 --> 00:33:39.800]   So let me move this out.
[00:33:39.800 --> 00:33:41.240]   Perfect.
[00:33:41.240 --> 00:33:50.880]   So the thing I want to look at would be candidates.csv.
[00:33:50.880 --> 00:33:57.440]   So we have about, I just printed out the number of lines in it.
[00:33:58.440 --> 00:34:02.960]   We have about 50,000, uh, example in candidates.
[00:34:02.960 --> 00:34:07.800]   So it's CSV and there should be another file here called annotations.
[00:34:07.800 --> 00:34:17.080]   So that has about 1100 annotations and let's look at, is it head?
[00:34:17.080 --> 00:34:21.160]   Uh, yes.
[00:34:21.160 --> 00:34:23.960]   Uh, so these are bash commands.
[00:34:23.960 --> 00:34:26.360]   This is just a terminal I'm running inside of Jupiter.
[00:34:26.360 --> 00:34:29.760]   If you click new, you can create a new notebook or text file
[00:34:29.760 --> 00:34:31.000]   or folder or a terminal.
[00:34:31.000 --> 00:34:36.000]   I clicked on terminal because as, as I said, I have SSH into this box and I
[00:34:36.000 --> 00:34:39.000]   don't want to switch to sharing my terminal that takes two minutes.
[00:34:39.000 --> 00:34:43.000]   Uh, even though I spoke for two minutes, but still I wanted to
[00:34:43.000 --> 00:34:44.840]   say in the same browser window.
[00:34:44.840 --> 00:34:52.440]   So we can see series ID, coordinate X, coordinate Y, Z and class.
[00:34:53.080 --> 00:34:57.120]   Uh, classes are zero or one, because remember we're trying to predict
[00:34:57.120 --> 00:34:59.120]   if the tumor is malignant or benign.
[00:34:59.120 --> 00:35:04.760]   Sorry, if the tumor is cancerous or not, and this is essentially a
[00:35:04.760 --> 00:35:08.720]   Boolean variable, uh, specifying that.
[00:35:08.720 --> 00:35:13.680]   And let's look at annotations.csv.
[00:35:13.680 --> 00:35:20.120]   So this time we get series ID, um, coordinate X, coordinate Y,
[00:35:20.120 --> 00:35:22.800]   coordinate Z and the diameter.
[00:35:23.760 --> 00:35:24.360]   Interesting.
[00:35:24.360 --> 00:35:27.800]   So we have all of these series IDs.
[00:35:27.800 --> 00:35:31.360]   You have the coordinates and the diameters.
[00:35:31.360 --> 00:35:34.400]   Now, what does a subset have?
[00:35:34.400 --> 00:35:35.720]   Let's let's look at that.
[00:35:35.720 --> 00:35:39.400]   Let's let's say go into subset one.
[00:35:39.400 --> 00:35:43.920]   And it has all of these MST files, these raw files.
[00:35:43.920 --> 00:35:47.960]   And if you look closely, uh, I've actually done that already.
[00:35:47.960 --> 00:35:52.160]   So you can't like figure that out in a minute, but let's go back.
[00:35:52.320 --> 00:36:01.560]   So the dot dot, and let's again, print out the head of let's say candidates.
[00:36:01.560 --> 00:36:04.120]   What CSV.
[00:36:04.120 --> 00:36:11.080]   So these IDs appear to be somewhat similar, right?
[00:36:11.080 --> 00:36:15.880]   The series ID, the last one, uh, is a little different.
[00:36:15.880 --> 00:36:17.720]   So that's just specifying the details.
[00:36:17.720 --> 00:36:19.520]   Now there are two things here.
[00:36:21.240 --> 00:36:24.160]   There's one MST file and one daughter or file.
[00:36:24.160 --> 00:36:26.400]   So let's see what is an MST file.
[00:36:26.400 --> 00:36:35.600]   And we see there's an, uh, package called simple ITK that we can use with trusting.
[00:36:35.600 --> 00:36:38.400]   Let's look at what is simple MST.
[00:36:38.400 --> 00:36:39.640]   Uh, this should be good.
[00:36:39.640 --> 00:36:44.760]   Meta image, medical format, file extension.
[00:36:44.760 --> 00:36:49.720]   MSD seems to be mostly related to metamid format, a text based tag
[00:36:49.720 --> 00:36:51.880]   file format for medical images.
[00:36:51.880 --> 00:36:57.520]   It is a special picture format used in insight segmentation, registration
[00:36:57.520 --> 00:37:00.880]   toolkit, probably other graphic visualization softwares.
[00:37:00.880 --> 00:37:02.240]   I just clicked on a random link.
[00:37:02.240 --> 00:37:03.240]   This is not pre-planned.
[00:37:03.240 --> 00:37:06.240]   I'm just trying to Google stuff up on the fly also.
[00:37:06.240 --> 00:37:09.760]   Uh, let's look at meta documentation.
[00:37:09.760 --> 00:37:17.400]   So remember when I said, uh, when working with a target problem, you will learn a
[00:37:17.400 --> 00:37:22.360]   lot and this is, this is the background research you will be forced to do.
[00:37:22.360 --> 00:37:26.960]   So I just like looking at the dataset and seeing what it is all about.
[00:37:26.960 --> 00:37:28.680]   And as well, there are MSD files in it.
[00:37:28.680 --> 00:37:29.180]   Right.
[00:37:29.180 --> 00:37:32.600]   So I'm just like trying to understand what, what is this all about?
[00:37:32.600 --> 00:37:34.320]   And let's see, like, how can we work with them?
[00:37:34.320 --> 00:37:40.140]   And ideally, like you would have a business problem in deep learning
[00:37:40.140 --> 00:37:41.160]   that you're trying to solve.
[00:37:41.160 --> 00:37:44.120]   And you would just be thrown like a ton of zip files.
[00:37:44.120 --> 00:37:46.120]   Actually, it wouldn't be thrown a ton of zip files.
[00:37:46.120 --> 00:37:50.680]   You'd have to like fight departments, legal, uh, all of those fights
[00:37:50.680 --> 00:37:52.480]   that'll go on for a few weeks.
[00:37:52.480 --> 00:37:56.680]   Maybe then you get a file that is like partially correct.
[00:37:56.680 --> 00:37:58.680]   And then you start working with it.
[00:37:58.680 --> 00:38:03.320]   Uh, not trying to make fun of any, any industry, but it takes a good amount
[00:38:03.320 --> 00:38:05.000]   of time just to get the data itself.
[00:38:05.000 --> 00:38:06.320]   And then you start working with it.
[00:38:06.320 --> 00:38:11.040]   So what we want to do here is first of all, understand the data that was there
[00:38:11.040 --> 00:38:15.720]   in those zip files that we down that I downloaded off of Luna 16's website.
[00:38:16.400 --> 00:38:18.320]   And then let's see, like, what can we work with?
[00:38:18.320 --> 00:38:22.840]   What should we work with here to classify tumors?
[00:38:22.840 --> 00:38:29.920]   Now our goal here is to classify is a tumor cancerous or not from a chest CT scan.
[00:38:29.920 --> 00:38:32.560]   And this is the data set we've been provided with.
[00:38:32.560 --> 00:38:38.080]   So the business problem here becomes data scientist, I am, or let's say data
[00:38:38.080 --> 00:38:41.400]   scientist, because he's a better data scientist, data scientist, when I
[00:38:41.520 --> 00:38:47.040]   needs to create the state of the art, uh, cancer detector for the stakeholders.
[00:38:47.040 --> 00:38:49.360]   And he's been given the zip file with zero context.
[00:38:49.360 --> 00:38:50.440]   So now we're looking at that.
[00:38:50.440 --> 00:38:57.560]   So my time is, is it text-based tag file format for medical emerges?
[00:38:57.560 --> 00:39:02.680]   Uh, that supports a variety of objects that occur in medicine, blah, blah, blah.
[00:39:02.680 --> 00:39:06.400]   Um, what I'm trying to find here is what can I use?
[00:39:06.400 --> 00:39:10.640]   MSD file read Python.
[00:39:11.240 --> 00:39:11.240]   Okay.
[00:39:11.240 --> 00:39:18.240]   My prototype is I never even look at the question.
[00:39:18.240 --> 00:39:20.720]   I just scroll to the answer, copy, paste it.
[00:39:20.720 --> 00:39:22.400]   Uh, it doesn't work.
[00:39:22.400 --> 00:39:24.520]   Five minutes later, I come back, read the question.
[00:39:24.520 --> 00:39:26.400]   And then I realized I was looking at the wrong question.
[00:39:26.400 --> 00:39:31.280]   So can anyone please tell me, uh, the way I can read a data set
[00:39:31.280 --> 00:39:33.040]   containing dot MSD dot profiles.
[00:39:33.040 --> 00:39:34.080]   Uh, we found gold.
[00:39:34.080 --> 00:39:35.400]   So like we're on the right path.
[00:39:36.080 --> 00:39:43.240]   The easiest way is to install simple ITK and, uh, we can use
[00:39:43.240 --> 00:39:45.040]   this code from Kaggle incredible.
[00:39:45.040 --> 00:39:48.800]   So we have a load ITK method that reads in the image.
[00:39:48.800 --> 00:39:51.360]   We can get an array from an image.
[00:39:51.360 --> 00:39:53.160]   We can convert it.
[00:39:53.160 --> 00:39:59.880]   So read the origin of the CT scan, uh, from world to Voxel and vice versa.
[00:39:59.880 --> 00:40:00.760]   Let's see what that is.
[00:40:00.760 --> 00:40:05.160]   So what is Voxel and read spacing along the dimensions, and then
[00:40:05.160 --> 00:40:06.480]   we can return all of these things.
[00:40:06.480 --> 00:40:08.520]   We can also use SK image.
[00:40:08.520 --> 00:40:12.760]   Uh, but if you're a real coder, you know, you never scroll down and
[00:40:12.760 --> 00:40:14.240]   you just copy the first thing, right?
[00:40:14.240 --> 00:40:17.560]   So let's say we've already copy pasted this and let's look at
[00:40:17.560 --> 00:40:19.560]   the simple ITK package first.
[00:40:19.560 --> 00:40:24.720]   A simplified part to insight open source, multi-dimensional
[00:40:24.720 --> 00:40:26.520]   image analysis in Python.
[00:40:26.520 --> 00:40:29.240]   Um, let's look at the online tutorial.
[00:40:29.240 --> 00:40:34.400]   Oh, incredible.
[00:40:34.400 --> 00:40:36.920]   They have notebooks as well as presentation.
[00:40:36.920 --> 00:40:38.000]   So this is really neat.
[00:40:38.000 --> 00:40:44.640]   Um, but from what it looks like, we going to be using this package to
[00:40:44.640 --> 00:40:49.680]   read in the dot MST file and daughter of five, what is dot MST dot MST stands
[00:40:49.680 --> 00:40:55.400]   for I've written it down, I think, uh, meta header data and raw files.
[00:40:55.400 --> 00:40:56.800]   This contains the raw scan.
[00:40:56.800 --> 00:41:00.520]   So we need to read in those, but problems come up with that.
[00:41:00.520 --> 00:41:01.920]   And let's, let's discuss those.
[00:41:03.000 --> 00:41:05.760]   So let me switch sharing.
[00:41:05.760 --> 00:41:08.800]   Actually, let me quickly look if there are any questions.
[00:41:08.800 --> 00:41:28.000]   Awesome.
[00:41:28.000 --> 00:41:29.000]   I don't see any questions.
[00:41:29.000 --> 00:41:29.880]   I can continue.
[00:41:29.880 --> 00:41:39.760]   So we're at this point, let me make this full screen and zoom in a bit.
[00:41:39.760 --> 00:41:43.920]   I'm sharing my one note, which is looking at the book chapter.
[00:41:43.920 --> 00:41:50.920]   Um, so we're laser focused on the first step, which is loading the data.
[00:41:50.920 --> 00:41:52.760]   We know it has some dot MSD files.
[00:41:52.760 --> 00:41:54.240]   We know it has some raw files.
[00:41:54.240 --> 00:41:58.200]   There are more details to it in annotations and candidates.
[00:41:58.560 --> 00:42:04.800]   So the candidates and annotation both have the series UID, which
[00:42:04.800 --> 00:42:07.000]   refers to the patient details.
[00:42:07.000 --> 00:42:08.800]   So that's what connects them.
[00:42:08.800 --> 00:42:14.960]   And inside of the subsets, we have the actual scans, which are
[00:42:14.960 --> 00:42:16.640]   in dot MSG and daughter of files.
[00:42:16.640 --> 00:42:19.040]   So that is the actual CT data.
[00:42:19.040 --> 00:42:23.480]   This is the step that we'll spend the entire discussion around.
[00:42:23.480 --> 00:42:26.280]   So you can imagine it to be quite serious.
[00:42:27.440 --> 00:42:33.760]   Now, um, we have these two files that we need to figure out
[00:42:33.760 --> 00:42:35.640]   to come, how to combine somehow.
[00:42:35.640 --> 00:42:42.160]   And we also have the CT array, but the problem here is these are
[00:42:42.160 --> 00:42:45.240]   in the patient coordinate system.
[00:42:45.240 --> 00:42:51.120]   And we need to convert this into index row column, IRC notation.
[00:42:51.120 --> 00:42:53.920]   So for that, we perform a bunch of transforms.
[00:42:54.080 --> 00:42:57.520]   Uh, and at this point, you shouldn't be scared of transforms because as
[00:42:57.520 --> 00:43:02.960]   you can imagine, they're just, they're just, uh, matrices that we multiply with.
[00:43:02.960 --> 00:43:08.440]   And that gives us a few more details.
[00:43:08.440 --> 00:43:10.920]   This time we'd also like to grab the series UID.
[00:43:10.920 --> 00:43:13.160]   So that's what distinguishes between things.
[00:43:13.160 --> 00:43:17.320]   We also want to probably know if it's a nodule or not.
[00:43:17.320 --> 00:43:20.120]   And that gives us a sample tuple.
[00:43:22.320 --> 00:43:25.440]   So I'll ask this question to keep things interactive.
[00:43:25.440 --> 00:43:30.200]   Uh, what do you think are those steps that we also need to like
[00:43:30.200 --> 00:43:32.080]   apply to get the right data here?
[00:43:32.080 --> 00:43:39.800]   So what other things can we do as we grab the data to make things interesting?
[00:43:39.800 --> 00:43:45.760]   So we have the entire chest CT scan, which is this huge image.
[00:43:45.760 --> 00:43:49.240]   What other things should be applied to that?
[00:43:49.240 --> 00:43:54.400]   Should we like, maybe again, it's like a black and white image, a 3d image.
[00:43:54.400 --> 00:43:58.800]   So how can we make it easier for the model to learn about it?
[00:43:58.800 --> 00:44:04.800]   And I'll wait for your answers or I'll come back to the answer maybe later.
[00:44:04.800 --> 00:44:11.600]   Um, so the question again is once we have the CT scans in our memory, we've
[00:44:11.600 --> 00:44:17.680]   downloaded it, what should we be applying to, uh, that data?
[00:44:17.680 --> 00:44:23.000]   Vinayak is answering the question.
[00:44:23.000 --> 00:44:23.840]   So that's awesome.
[00:44:23.840 --> 00:44:29.880]   Um, and I can probably also speak about this using another example, right?
[00:44:29.880 --> 00:44:33.600]   Like now, right now, if you look on the upper right corner, if I stop sharing
[00:44:33.600 --> 00:44:35.760]   my screen, you're looking at my complete image.
[00:44:35.760 --> 00:44:42.000]   And if you want to just like detect me out of the image, uh, deep learning
[00:44:42.000 --> 00:44:45.640]   models work fairly well, but you can always provide some usefulness to it.
[00:44:45.640 --> 00:44:45.960]   Right.
[00:44:46.360 --> 00:44:50.400]   So let's say if you're again, going back to the most stupid possible task you
[00:44:50.400 --> 00:44:57.200]   could do, which is to find me in an image, uh, you can probably crop around me.
[00:44:57.200 --> 00:44:57.800]   Right.
[00:44:57.800 --> 00:44:59.840]   You don't want all of these things going around.
[00:44:59.840 --> 00:45:04.920]   I mean, this particular instance is a solved problem because I'm, I'm inside
[00:45:04.920 --> 00:45:06.640]   my child studio, things are nice.
[00:45:06.640 --> 00:45:07.400]   It's just me.
[00:45:07.400 --> 00:45:08.920]   There are no more humans around.
[00:45:08.920 --> 00:45:14.680]   Ideally, if it's like a lot of objects that would cause confusion, you'd want
[00:45:14.680 --> 00:45:16.880]   to just like zoom in on that particular thing.
[00:45:16.880 --> 00:45:19.520]   So that's, that's one of the hints I could give.
[00:45:19.520 --> 00:45:23.880]   Let me see.
[00:45:23.880 --> 00:45:27.880]   So you've Raj has given an advanced answer that we can expect from him since
[00:45:27.880 --> 00:45:31.440]   he knows a lot of deep learning now, data augmentation to increase the size
[00:45:31.440 --> 00:45:32.560]   and add more variations.
[00:45:32.560 --> 00:45:33.560]   That's absolutely correct.
[00:45:33.560 --> 00:45:34.520]   You could totally do that.
[00:45:34.520 --> 00:45:40.360]   Uh, Vinayak also again, within advanced answer, we could normalize the data.
[00:45:40.360 --> 00:45:41.040]   Yes.
[00:45:41.040 --> 00:45:43.560]   We could crop into the regions of interest.
[00:45:43.560 --> 00:45:44.360]   Absolutely.
[00:45:44.480 --> 00:45:46.640]   And we could use a fine augmentations.
[00:45:46.640 --> 00:45:47.960]   Uh, sure.
[00:45:47.960 --> 00:45:54.400]   And I let my team answer also, but, uh, combining your Raj and Vinayak's
[00:45:54.400 --> 00:45:57.200]   answer, so first of all, we need to normalize the data.
[00:45:57.200 --> 00:45:59.520]   What does that mean?
[00:45:59.520 --> 00:46:01.920]   Our data needs to be consistent all across.
[00:46:01.920 --> 00:46:05.840]   It usually needs to be between, uh, the values that work really well for
[00:46:05.840 --> 00:46:07.480]   not making our gradients explode.
[00:46:07.480 --> 00:46:11.200]   And since this is a different type of problem, we need to like make
[00:46:11.200 --> 00:46:12.520]   sure it's between that number.
[00:46:12.520 --> 00:46:15.080]   So we need to figure out what is that for CT scans.
[00:46:15.080 --> 00:46:16.560]   We haven't even looked at them yet.
[00:46:16.560 --> 00:46:20.240]   We could crop into regions of interest.
[00:46:20.240 --> 00:46:23.840]   I really want to emphasize on this.
[00:46:23.840 --> 00:46:30.800]   So here, like if you've gone ahead and run the code or if I can, actually,
[00:46:30.800 --> 00:46:34.720]   I'm not going to scroll through the book, but if you looked at the CT scan, right.
[00:46:34.720 --> 00:46:37.800]   It's, it's just black and white things.
[00:46:39.680 --> 00:46:42.880]   It's really hard as a human to also like observe what's going on.
[00:46:42.880 --> 00:46:46.680]   Deep learning models work well, work better with those.
[00:46:46.680 --> 00:46:55.880]   But if we can just crop around the tumor that's of interest, that
[00:46:55.880 --> 00:46:57.560]   should help things a lot.
[00:46:57.560 --> 00:47:03.680]   So let me find these, these coordinates we've printed out, right?
[00:47:04.640 --> 00:47:09.400]   Our coordinates to the tumor of interest or to the node of interest.
[00:47:09.400 --> 00:47:10.080]   What is a node?
[00:47:10.080 --> 00:47:11.800]   I told that in a previous session.
[00:47:11.800 --> 00:47:17.240]   If you don't remember that I did cover it, so you weren't paying attention then.
[00:47:17.240 --> 00:47:18.360]   But okay.
[00:47:18.360 --> 00:47:21.120]   Notice the mass that we're interested in.
[00:47:21.120 --> 00:47:24.120]   And these are the coordinates to that.
[00:47:24.120 --> 00:47:27.920]   Now that that is like the main point of interest for us.
[00:47:27.920 --> 00:47:30.400]   So ideally crop into that.
[00:47:30.400 --> 00:47:34.080]   So that our model has less of other details to focus on.
[00:47:34.480 --> 00:47:34.760]   Okay.
[00:47:34.760 --> 00:47:41.360]   The important part here becomes if you're specializing your model
[00:47:41.360 --> 00:47:45.640]   towards working such things, it should represent the real world.
[00:47:45.640 --> 00:47:50.440]   So if you're working with chest X-ray data, right, you can't like
[00:47:50.440 --> 00:47:56.480]   throw that model and expect it to work with brain X-ray, sorry, brain
[00:47:56.480 --> 00:48:00.280]   CT scans or CT scans that are completely different.
[00:48:00.840 --> 00:48:05.560]   So be cognizant of the processes you apply, but here it's like an
[00:48:05.560 --> 00:48:10.880]   absolute valid argument that if we, you know just crop around, let's
[00:48:10.880 --> 00:48:16.080]   say these coordinates, maybe like some space around it, if that makes
[00:48:16.080 --> 00:48:18.440]   sense, the model should work well, right?
[00:48:18.440 --> 00:48:20.880]   Because now we're just focusing it on that part.
[00:48:20.880 --> 00:48:25.120]   Like if you want just to classify my head, like cropping around
[00:48:25.120 --> 00:48:27.680]   this area should help, right?
[00:48:28.200 --> 00:48:31.680]   There are no false positives in the background in this scenario, but
[00:48:31.680 --> 00:48:34.120]   when they are with CT scans, that is helpful.
[00:48:34.120 --> 00:48:39.440]   Awesome.
[00:48:39.440 --> 00:48:41.360]   I think everyone knows the answers already.
[00:48:41.360 --> 00:48:43.120]   So that's, that's really great.
[00:48:43.120 --> 00:48:44.400]   Thanks Sumanthanh and Matteo.
[00:48:44.400 --> 00:48:46.280]   These are also the right answers.
[00:48:46.280 --> 00:48:49.040]   So that's what we would do.
[00:48:49.040 --> 00:48:52.920]   Crop into the areas of interest.
[00:48:56.840 --> 00:49:00.160]   And I see a few questions coming in through the YouTube chat also, please
[00:49:00.160 --> 00:49:02.440]   ask the questions on the forum threads.
[00:49:02.440 --> 00:49:06.000]   It's hard for me to catch the comments coming in there and I
[00:49:06.000 --> 00:49:07.400]   don't want to upset anyone.
[00:49:07.400 --> 00:49:11.360]   I just saw your message, but if you could please post that on there, that should be
[00:49:11.360 --> 00:49:11.760]   awesome.
[00:49:11.760 --> 00:49:18.800]   So now we have another problem.
[00:49:23.280 --> 00:49:29.840]   Which is we want these coordinates to be in IRC figures and not the XYZ.
[00:49:29.840 --> 00:49:34.840]   So we just looked at coordinates XYZ and these are the standard ways of
[00:49:34.840 --> 00:49:39.080]   working with DICOM files or the MST files.
[00:49:39.080 --> 00:49:40.520]   You just get those.
[00:49:40.520 --> 00:49:45.680]   But how do we convert that into something the model can work with?
[00:49:45.680 --> 00:49:51.280]   So first of all, we read in the annotations and get in the coordinate
[00:49:51.280 --> 00:49:57.360]   system and also grab the series ID and the is nodule while we're at it.
[00:49:57.360 --> 00:49:59.080]   So is nodule is nothing.
[00:49:59.080 --> 00:50:02.480]   It's just, I should grab a pen and on right with my trackpad.
[00:50:02.480 --> 00:50:03.120]   Sorry.
[00:50:03.120 --> 00:50:08.160]   It's just zero or one at this point.
[00:50:08.160 --> 00:50:10.720]   Oops.
[00:50:10.720 --> 00:50:11.800]   I grabbed the zoom window.
[00:50:11.800 --> 00:50:12.200]   Sorry.
[00:50:12.200 --> 00:50:14.200]   Zero or one.
[00:50:14.200 --> 00:50:15.040]   Uh, so true.
[00:50:15.040 --> 00:50:17.600]   True is one, zero is false.
[00:50:17.600 --> 00:50:17.800]   Sorry.
[00:50:17.800 --> 00:50:18.840]   It should be one and zero.
[00:50:19.840 --> 00:50:20.040]   Okay.
[00:50:20.040 --> 00:50:35.280]   So what the authors have done here is they've pulled up an annotations file
[00:50:35.280 --> 00:50:43.200]   and candidates file that corresponds to the exact same number for this particular
[00:50:43.200 --> 00:50:43.600]   scan.
[00:50:44.080 --> 00:50:50.040]   So, uh, remember series ID is one dot one dot let's say one dot X or Y dot Z.
[00:50:50.040 --> 00:50:52.360]   This is that scan ID.
[00:50:52.360 --> 00:50:54.080]   So this is the unique number.
[00:50:54.080 --> 00:50:57.440]   And we're trying to compare those the point being made here.
[00:50:57.440 --> 00:51:01.440]   And this is why I pointed you to the EDA session, because these are
[00:51:01.440 --> 00:51:03.080]   the things you learn in EDA.
[00:51:03.080 --> 00:51:10.080]   So the authors performed some EDA and they learned that these should be the same, right?
[00:51:10.080 --> 00:51:13.760]   This number should be the same, but it's not.
[00:51:14.760 --> 00:51:20.880]   So, uh, you could find interesting ways to work with it, or you could just totally
[00:51:20.880 --> 00:51:23.080]   discard the cases where this, this is happening.
[00:51:23.080 --> 00:51:24.600]   So you could totally make an argument.
[00:51:24.600 --> 00:51:30.880]   Oh, uh, these are annotations by two different medical experts.
[00:51:30.880 --> 00:51:31.760]   They disagree.
[00:51:31.760 --> 00:51:33.960]   And this could cause problems for my model.
[00:51:33.960 --> 00:51:35.960]   So maybe let's not just use the setup.
[00:51:35.960 --> 00:51:36.720]   Sure.
[00:51:36.720 --> 00:51:40.720]   Uh, you could try that approach or maybe you could take the average of these.
[00:51:40.720 --> 00:51:50.000]   So both of these points actually point to the center of the nodule.
[00:51:50.000 --> 00:51:58.400]   Nodule again is the mass that is of interest to us, but it's up to you.
[00:51:58.400 --> 00:51:59.560]   How do you deal with that?
[00:51:59.560 --> 00:52:03.520]   And you take the average of these, do you just add them and like divided
[00:52:03.520 --> 00:52:05.040]   by two use that as a point?
[00:52:05.040 --> 00:52:05.640]   Sure.
[00:52:05.640 --> 00:52:06.520]   That could work.
[00:52:07.440 --> 00:52:10.080]   Maybe, maybe somehow you find out that, okay.
[00:52:10.080 --> 00:52:17.320]   Annotations or CSV was done with a practitioner whose readings
[00:52:17.320 --> 00:52:18.480]   you find more consistent.
[00:52:18.480 --> 00:52:21.360]   So let's just rely on these and not use candidates.
[00:52:21.360 --> 00:52:22.120]   So CSV.
[00:52:22.120 --> 00:52:23.160]   Sure.
[00:52:23.160 --> 00:52:27.720]   But again, these are real problems that you always end up
[00:52:27.720 --> 00:52:29.200]   facing while working with data.
[00:52:29.200 --> 00:52:31.600]   And you'll have to deal with those.
[00:52:33.040 --> 00:52:38.040]   So the next step here again becomes now we have this, uh, let
[00:52:38.040 --> 00:52:39.320]   me just write in the margin.
[00:52:39.320 --> 00:52:43.080]   So we have our candidates.csv.
[00:52:43.080 --> 00:52:46.720]   We have our annotations.csv.
[00:52:46.720 --> 00:52:56.560]   We have a subset folder inside of which we have msd files and .raw files.
[00:52:56.560 --> 00:53:00.160]   Now, what is our end goal here?
[00:53:00.160 --> 00:53:07.560]   Again, it's to classify if a given 3d scan known as CT scan, if the given 3d
[00:53:07.560 --> 00:53:14.400]   image has cancer, rust nodules in it or not for that, we are given this
[00:53:14.400 --> 00:53:18.360]   subset that is like, so, and we need to load this into the memory so that
[00:53:18.360 --> 00:53:22.800]   PyTorch our lovely framework that we all are here to learn can work with it.
[00:53:22.800 --> 00:53:24.960]   So we're going to find ways to do that.
[00:53:24.960 --> 00:53:26.200]   How do we do that?
[00:53:26.200 --> 00:53:28.680]   We create a dataset class, right?
[00:53:29.280 --> 00:53:32.960]   Pretty simple, pretty straightforward.
[00:53:32.960 --> 00:53:36.400]   Or we can just like create a training loop where we work with it.
[00:53:36.400 --> 00:53:42.360]   And we can look into these things, but the problem here becomes, if you
[00:53:42.360 --> 00:53:48.360]   looked at it, first of all, there are like 55,000, uh, lines in this CSV
[00:53:48.360 --> 00:53:54.600]   file, and there are a few thousand, uh, 11, uh, sorry, 1,351
[00:53:54.600 --> 00:53:56.960]   candidates that are cancerous.
[00:53:57.800 --> 00:53:59.320]   The code will get messy.
[00:53:59.320 --> 00:54:02.720]   So ideally there's another practical advice coming up.
[00:54:02.720 --> 00:54:05.920]   You would, I talked about this, but first of all, you would
[00:54:05.920 --> 00:54:07.320]   like to have a data folder.
[00:54:07.320 --> 00:54:13.160]   So this is your, let me switch over to a new notebook, but let's
[00:54:13.160 --> 00:54:18.880]   talk about organizing ML projects.
[00:54:22.400 --> 00:54:26.120]   So the problem is things are fine.
[00:54:26.120 --> 00:54:27.040]   Things are well and good.
[00:54:27.040 --> 00:54:30.520]   As long as you're working with toy datasets that work really well with
[00:54:30.520 --> 00:54:32.240]   PyTorch, right?
[00:54:32.240 --> 00:54:38.080]   But as soon as you go beyond that, it's impossible to keep a track of things.
[00:54:38.080 --> 00:54:43.080]   So, uh, full disclosure, as you all already know, I work at Weights and Biases,
[00:54:43.080 --> 00:54:45.560]   but it's one of the tools that makes your life really easy.
[00:54:45.560 --> 00:54:48.720]   I'll be talking about that more next week, but it makes sense.
[00:54:49.320 --> 00:54:53.720]   Uh, I would encourage you all to check that out for really keeping
[00:54:53.720 --> 00:54:55.160]   a track of your experiments.
[00:54:55.160 --> 00:55:00.680]   But even before that, you need to understand how to structure your.
[00:55:00.680 --> 00:55:03.200]   Hold it.
[00:55:03.200 --> 00:55:03.400]   Right.
[00:55:03.400 --> 00:55:04.520]   So this is what I do.
[00:55:04.520 --> 00:55:08.680]   And I think I found this through Abhishek Thakur's video and I did a few
[00:55:08.680 --> 00:55:12.880]   modifications to his approach, but, uh, here's what I like to do.
[00:55:12.880 --> 00:55:17.120]   So there's a folder called data inside of which I have every single data
[00:55:17.120 --> 00:55:18.960]   file that I'm working with currently.
[00:55:19.960 --> 00:55:24.120]   And there's a separate code repo where things exist for the code I'm working
[00:55:24.120 --> 00:55:28.520]   with inside of the project repo.
[00:55:28.520 --> 00:55:33.920]   So inside of this code repo, I have all of my repositories, uh, basically
[00:55:33.920 --> 00:55:38.040]   my local GitHub setup inside of the project.
[00:55:38.040 --> 00:55:41.120]   Uh, usually there are utilities.
[00:55:41.120 --> 00:55:43.880]   There's a dset.py.
[00:55:43.880 --> 00:55:45.520]   So dataset.
[00:55:45.520 --> 00:55:48.880]   That's what we're looking at today.
[00:55:49.880 --> 00:55:51.680]   Um, there's a train.py.
[00:55:51.680 --> 00:56:00.640]   A bunch of more files that I don't think are important to discuss right
[00:56:00.640 --> 00:56:02.480]   now, and also one temp folder.
[00:56:02.480 --> 00:56:06.840]   And always, always, I forget this and get complaints, but I
[00:56:06.840 --> 00:56:08.120]   add this to my gitignore.
[00:56:08.120 --> 00:56:15.720]   And here you would like to store things, uh, that are just cached.
[00:56:16.160 --> 00:56:20.360]   So today we learn as we load this dataset into the memory, right?
[00:56:20.360 --> 00:56:23.600]   It's quite intense and we would want it cached.
[00:56:23.600 --> 00:56:25.240]   So what are we going to do?
[00:56:25.240 --> 00:56:28.560]   We're going to just use a few function that just cache it in memory.
[00:56:28.560 --> 00:56:33.640]   And for that, we store them in temp.
[00:56:33.640 --> 00:56:38.440]   So whenever you load something that, you know, takes like 15 to 15 minutes,
[00:56:38.440 --> 00:56:44.400]   one hour to pre-process and you apply a bunch of operations to it, look,
[00:56:44.400 --> 00:56:48.520]   honestly, you'll get one hour every day or since your time to work with deep
[00:56:48.520 --> 00:56:54.280]   learning, you want every day to be like spent learning something new.
[00:56:54.280 --> 00:56:58.680]   So since you've already done those processes and you don't want to repeat
[00:56:58.680 --> 00:57:01.160]   them, write them to your temp folder.
[00:57:01.160 --> 00:57:08.640]   So let's say we load our, why can't I scroll?
[00:57:08.640 --> 00:57:09.480]   This is annoying.
[00:57:09.480 --> 00:57:14.080]   I'll just, I'll just write around it.
[00:57:14.320 --> 00:57:17.640]   Um, as you can see, it's, it's quite a clunky set of that.
[00:57:17.640 --> 00:57:24.240]   I'm still learning how to navigate, but, um, my point being, so we have our CSV
[00:57:24.240 --> 00:57:26.360]   files, we have our MST files.
[00:57:26.360 --> 00:57:29.880]   We apply a few pre-processing techniques to it.
[00:57:29.880 --> 00:57:33.200]   We crop.
[00:57:33.200 --> 00:57:39.960]   We let's say augment, we normalize.
[00:57:42.680 --> 00:57:47.400]   Now, if you can figure out how to do it on the fly and that works well, totally
[00:57:47.400 --> 00:57:51.400]   good, you don't have to worry about things, but if it takes like a ton of
[00:57:51.400 --> 00:57:55.840]   time to pre-process and a ton of time is time that you can't spend coding.
[00:57:55.840 --> 00:58:07.320]   Once you've done this, just write it to a NumPy object or something like that
[00:58:07.320 --> 00:58:12.120]   and dump it to the temp folder so that the next day when you come back or let's
[00:58:12.120 --> 00:58:16.680]   say overnight leave things running, it does all of these processes
[00:58:16.680 --> 00:58:19.040]   and they're dumped to temp.
[00:58:19.040 --> 00:58:23.920]   So the next day you come back, you can just work with train.py and work with temp.
[00:58:23.920 --> 00:58:28.840]   I wasted your 10 minutes talking about this stupid setup that all of you
[00:58:28.840 --> 00:58:30.520]   are probably already familiar with.
[00:58:30.520 --> 00:58:36.680]   If you're not, this is quite hard to always sincerely follow in practice.
[00:58:38.120 --> 00:58:42.280]   And it really makes a difference in terms of productivity or in terms
[00:58:42.280 --> 00:58:47.040]   of your project usefulness, especially like if you're just new to this study
[00:58:47.040 --> 00:58:51.800]   group and if you've not worked with multiple collaborators, even in an
[00:58:51.800 --> 00:58:57.040]   open source environment, so even not at work, it makes a huge amount of
[00:58:57.040 --> 00:59:01.560]   difference how these files are structured for their collaborators or for anyone
[00:59:01.560 --> 00:59:03.840]   else coming in to read your code.
[00:59:05.120 --> 00:59:09.400]   Code is meant to be read by humans and compiled by computers.
[00:59:09.400 --> 00:59:14.480]   So make sure you follow these steps and structure your project.
[00:59:14.480 --> 00:59:19.520]   You can totally ignore my suggestions, work with ways that work better for you.
[00:59:19.520 --> 00:59:26.800]   But this is one of the ways where you can just employ and work with the dataset.
[00:59:26.800 --> 00:59:32.320]   So coming back to the problem, we now have this weird way of annotations
[00:59:32.320 --> 00:59:36.160]   that we somehow need to convert into a way that works with PyTorch.
[00:59:36.160 --> 00:59:41.360]   And I think this is a good part where I can switch over to Jupyter and
[00:59:41.360 --> 00:59:43.200]   start talking about the code first.
[00:59:43.200 --> 00:59:45.560]   Let's see if there are any questions.
[00:59:45.560 --> 00:59:48.240]   Okay.
[00:59:48.240 --> 00:59:50.520]   It seems like I'm telling you all the things that you already know.
[00:59:50.520 --> 00:59:53.400]   So that means I'll, I'll glance over things really fast.
[00:59:53.400 --> 00:59:57.720]   But one thing I like to do here, again, I'm just trying to share practical tips.
[00:59:57.720 --> 01:00:01.480]   I'm sure you all already know this, but in case it's helpful, I'd still.
[01:00:02.480 --> 01:00:03.800]   Spend time sharing these.
[01:00:03.800 --> 01:00:06.480]   One thing I like to do, I've just created this new notebook called
[01:00:06.480 --> 01:00:16.320]   desets and the file we're looking at today is inside of P2CH10, desets.py.
[01:00:16.320 --> 01:00:21.640]   So what I like to do is, and this is also one of my pro tips
[01:00:21.640 --> 01:00:23.080]   for anyone new to the field.
[01:00:23.080 --> 01:00:29.360]   Just take some code that works and annotate it from the top to bottom
[01:00:29.520 --> 01:00:32.920]   with as many comments as you can, and that'll help you understand things.
[01:00:32.920 --> 01:00:39.120]   I'll take a 30 second break as a sip water, but I'm happy to answer questions.
[01:00:39.120 --> 01:00:57.720]   Nothing coming in, which means I'm explaining pretty basic stuff.
[01:00:57.720 --> 01:00:58.680]   Sorry about that guys.
[01:00:58.680 --> 01:01:01.240]   I'm, I'm sure all of you are familiar with these things.
[01:01:01.240 --> 01:01:05.800]   So, uh, I just want to make sure it's covered for people who are new to the field.
[01:01:05.800 --> 01:01:13.280]   So what I like to do is I copy paste everything and explain it to myself.
[01:01:13.280 --> 01:01:19.240]   Also comment it out, comment every single, sorry, not commented.
[01:01:19.240 --> 01:01:22.000]   How would comment every single line now?
[01:01:22.000 --> 01:01:24.200]   Jupiter has this nice feature.
[01:01:24.200 --> 01:01:29.240]   So I pressed escape, which goes into command mode and now I can glance over cell.
[01:01:29.240 --> 01:01:34.120]   If I press enter, this thing turns green, which means I'm in code mode.
[01:01:34.120 --> 01:01:37.280]   If I press escape again, I'm in command mode for Jupiter.
[01:01:37.280 --> 01:01:43.880]   And if I press escape a from command mode, it adds a cell on top.
[01:01:43.880 --> 01:01:46.880]   If I press DD, it deletes that cell.
[01:01:46.880 --> 01:01:48.200]   So that's what I'm doing.
[01:01:48.200 --> 01:01:51.720]   And if I press M this gets converted to Markdown.
[01:01:53.320 --> 01:01:57.200]   Uh, you could do this with clicking, uh, but keeping your hands on the keyboard
[01:01:57.200 --> 01:02:00.920]   is as you know, a programmer stream and you can continue that.
[01:02:00.920 --> 01:02:09.280]   So ideally you want to, not most of the times, but, uh, we're doing
[01:02:09.280 --> 01:02:10.560]   something counterintuitive here.
[01:02:10.560 --> 01:02:13.840]   First of all, this is supposed to be a Python file and I'm doing
[01:02:13.840 --> 01:02:16.440]   the most stupid thing, uh, not necessarily.
[01:02:16.440 --> 01:02:16.680]   Okay.
[01:02:16.680 --> 01:02:19.320]   I'm doing something that's of no use.
[01:02:19.320 --> 01:02:22.840]   I'm taking this code and pasting it line by line in a Jupiter notebook.
[01:02:23.000 --> 01:02:26.180]   As I tried to explain this to you and also as an example of how you
[01:02:26.180 --> 01:02:29.880]   should understand code files, this is just a tip from my end.
[01:02:29.880 --> 01:02:34.120]   Most of you could possibly just read this from the top to bottom
[01:02:34.120 --> 01:02:35.160]   and understand the code.
[01:02:35.160 --> 01:02:36.840]   It's been quite well written also.
[01:02:36.840 --> 01:02:41.040]   So that's totally valid, but in interest of explaining this today and in
[01:02:41.040 --> 01:02:45.000]   interest of just having this advice out there, I'd like to do this.
[01:02:45.000 --> 01:02:51.040]   I create a Jupiter notebook where I copy line by line, add these
[01:02:51.040 --> 01:02:59.640]   markdown cells and just comment things out, import, copy, blah,
[01:02:59.640 --> 01:03:01.480]   blah, blah, all of those things.
[01:03:01.480 --> 01:03:02.000]   Right.
[01:03:02.000 --> 01:03:10.440]   Once I'm done, I delete the cell and leave these, leave the cells empty,
[01:03:10.440 --> 01:03:13.480]   sleep on it, come back to it two days after.
[01:03:13.480 --> 01:03:15.540]   Nothing happens.
[01:03:15.540 --> 01:03:17.240]   I can't remember anything at all.
[01:03:17.240 --> 01:03:18.440]   Full honest disclosure.
[01:03:18.440 --> 01:03:19.520]   I cheat.
[01:03:20.480 --> 01:03:25.760]   I look at this file and then I go back again, tell myself, yes, I
[01:03:25.760 --> 01:03:27.360]   remember it and type the code.
[01:03:27.360 --> 01:03:30.520]   Ideally you should minimize this cheating.
[01:03:30.520 --> 01:03:33.480]   I call it cheating because ideally you should be able to
[01:03:33.480 --> 01:03:34.680]   write without looking there.
[01:03:34.680 --> 01:03:36.680]   You're allowed to Google.
[01:03:36.680 --> 01:03:41.480]   So this is again a homework or how I like to like evaluate myself.
[01:03:41.480 --> 01:03:45.120]   I'm allowed to Google here, but I'm not allowed to look at this code.
[01:03:47.240 --> 01:03:50.960]   And at the end of this process, I should have the same working code file.
[01:03:50.960 --> 01:03:54.440]   A little different is fine, but it should work as the original file.
[01:03:54.440 --> 01:04:01.720]   So what we're going to do today is copy line by line of functions that are
[01:04:01.720 --> 01:04:03.680]   supposed to work and just explain them.
[01:04:03.680 --> 01:04:06.160]   So we haven't done anything important so far.
[01:04:06.160 --> 01:04:09.240]   We've just imported, these are the utility functions.
[01:04:09.240 --> 01:04:12.640]   We imported name tuple from collection.
[01:04:12.640 --> 01:04:13.960]   We look at that.
[01:04:15.240 --> 01:04:18.280]   If you remember why computer scientists always emphasize
[01:04:18.280 --> 01:04:19.800]   data structures are important.
[01:04:19.800 --> 01:04:22.800]   This is one of those areas where it's of some importance.
[01:04:22.800 --> 01:04:28.080]   We're going to create a custom name tuple as a dataset of
[01:04:28.080 --> 01:04:31.960]   working with the CT scan files.
[01:04:31.960 --> 01:04:34.080]   So that's one thing we learned.
[01:04:34.080 --> 01:04:38.040]   I sort of planted the head Google search.
[01:04:38.040 --> 01:04:42.280]   I looked up how can we read in MSD file, simple IT came up.
[01:04:42.840 --> 01:04:46.320]   Uh, you might have to install this on Kaggle also, if I remember correctly,
[01:04:46.320 --> 01:04:50.440]   but we're going to import that and we're going to import the usual thought stuff.
[01:04:50.440 --> 01:04:52.760]   We're also importing something from util.
[01:04:52.760 --> 01:04:53.400]   What is that?
[01:04:53.400 --> 01:04:56.160]   Let's let's head back to the Jupyter server.
[01:04:56.160 --> 01:04:59.280]   Oh, I don't see util here.
[01:04:59.280 --> 01:05:01.120]   So it's not in p2 CS 10.
[01:05:01.120 --> 01:05:04.080]   Oh, it's, it's a separate folder.
[01:05:04.080 --> 01:05:08.560]   So remember when I spoke about the structure of code, util folders
[01:05:08.560 --> 01:05:11.720]   generally has utility functions that are used everywhere.
[01:05:12.480 --> 01:05:14.240]   And what are we importing again?
[01:05:14.240 --> 01:05:19.080]   We are importing this util and log conf.
[01:05:19.080 --> 01:05:20.280]   So we're logging functions.
[01:05:20.280 --> 01:05:24.520]   We're doing a few things and we've imported the utility functions for that
[01:05:24.520 --> 01:05:30.840]   from the util folders, which have these individual files for working with them.
[01:05:30.840 --> 01:05:34.440]   We're not going to look at those today because again, it's not that important.
[01:05:34.440 --> 01:05:39.040]   And we're loading in the cache file.
[01:05:39.440 --> 01:05:42.560]   I also remember the file that we never add to GitHub.
[01:05:42.560 --> 01:05:47.880]   We're also pointing get cash to it.
[01:05:47.880 --> 01:05:51.120]   Continuing further.
[01:05:51.120 --> 01:05:58.880]   So we want to work with this dataset and the things of interest to
[01:05:58.880 --> 01:06:03.680]   our, to us are, uh, is the nodule cancerous?
[01:06:03.680 --> 01:06:04.360]   No, sorry.
[01:06:04.360 --> 01:06:05.120]   Sorry.
[01:06:05.120 --> 01:06:06.440]   First of all, is it a nodule?
[01:06:06.440 --> 01:06:07.040]   Yes or no.
[01:06:08.880 --> 01:06:13.360]   How much is the diameter it's ID and it's center.
[01:06:13.360 --> 01:06:17.800]   So we create a candidate info tuple.
[01:06:17.800 --> 01:06:21.280]   This is a dataset of sort that we've created, right?
[01:06:21.280 --> 01:06:22.440]   We're not storing anything.
[01:06:22.440 --> 01:06:28.200]   So this is a template, a custom dataset of name tuple type that can
[01:06:28.200 --> 01:06:29.480]   store all of these things.
[01:06:29.480 --> 01:06:30.280]   Incredible.
[01:06:30.280 --> 01:06:32.600]   Now we can just throw this into Python.
[01:06:32.600 --> 01:06:33.880]   So we're going to figure that out.
[01:06:33.880 --> 01:06:38.080]   How do we like create a dataset file that can just work with this?
[01:06:39.080 --> 01:06:40.680]   So I pressed escape.
[01:06:40.680 --> 01:06:41.840]   Let's be again to add that.
[01:06:41.840 --> 01:06:47.040]   Let me copy this complete code function.
[01:06:47.040 --> 01:06:57.080]   What I'm trying to do here guys is just explain the code line by line.
[01:06:57.080 --> 01:07:00.840]   Literally the complete chapter just explains the code file.
[01:07:00.840 --> 01:07:02.760]   And I'm just trying to iterate over that.
[01:07:02.760 --> 01:07:06.960]   So if it feels rushed, uh, please ask the questions.
[01:07:06.960 --> 01:07:08.040]   Happy to answer those.
[01:07:08.040 --> 01:07:09.680]   A few things are obvious to me.
[01:07:09.680 --> 01:07:14.280]   If it feels slow, I'm sorry, but I feel it's important to cover a few things.
[01:07:14.280 --> 01:07:15.920]   I've covered both sides of the argument.
[01:07:15.920 --> 01:07:17.640]   I'm totally safe now.
[01:07:17.640 --> 01:07:19.720]   Uh, let's continue.
[01:07:19.720 --> 01:07:21.880]   We want to cache this function.
[01:07:21.880 --> 01:07:24.960]   It's always a good idea to cache the function that you're
[01:07:24.960 --> 01:07:26.400]   working with repeatedly.
[01:07:26.400 --> 01:07:30.560]   Uh, towards the later end of the book, we'll work at a work with.
[01:07:30.560 --> 01:07:35.120]   Something known as JIT.
[01:07:35.920 --> 01:07:36.920]   So PyTorch JIT.
[01:07:36.920 --> 01:07:43.960]   Kaggle double grandmaster CPMP, one of the wisest Kagglers, if I may, one
[01:07:43.960 --> 01:07:46.400]   of the most well-known discussion.
[01:07:46.400 --> 01:07:49.000]   Grandmaster is an expert in optimization.
[01:07:49.000 --> 01:07:52.680]   He used to share a lot of tips in discussions.
[01:07:52.680 --> 01:07:54.480]   Why am I bringing this up?
[01:07:54.480 --> 01:07:56.600]   Since I just mentioned caching, right?
[01:07:56.600 --> 01:07:59.800]   He shared some interesting tips and solutions here and there.
[01:07:59.800 --> 01:08:03.440]   Please click on the discussion tab and the notebooks tab
[01:08:03.440 --> 01:08:05.000]   and start going through those.
[01:08:05.600 --> 01:08:09.400]   Uh, so I'll slowly, slowly try to convince you all to spend more time on
[01:08:09.400 --> 01:08:11.760]   Kaggle and this is my approach to it.
[01:08:11.760 --> 01:08:14.920]   So I'm going to paste CMP MP profile here.
[01:08:14.920 --> 01:08:19.800]   Uh, please.
[01:08:19.800 --> 01:08:24.160]   I would say even instead of watching my interview with him, read his
[01:08:24.160 --> 01:08:25.880]   discussion posts, you'll learn much more.
[01:08:25.880 --> 01:08:28.280]   Through my interview, you'll learn about his journey.
[01:08:28.280 --> 01:08:29.760]   That's also quite interesting.
[01:08:29.760 --> 01:08:33.560]   Uh, it's, it's, he's one of the best Kagglers, but really learn, learn
[01:08:33.560 --> 01:08:35.840]   from his discussion posts and learn from his kernels.
[01:08:35.840 --> 01:08:43.280]   So we are caching this function because we need to get a lot of
[01:08:43.280 --> 01:08:45.240]   info on different candidates, right?
[01:08:45.240 --> 01:08:46.760]   What is a candidate?
[01:08:46.760 --> 01:08:51.960]   One individual, uh, ID is an individual candidate.
[01:08:51.960 --> 01:08:58.160]   So we need to run this many, many times, which is why we're
[01:08:58.160 --> 01:08:59.720]   putting it in memory cache.
[01:09:00.680 --> 01:09:01.920]   There's one caveat here.
[01:09:01.920 --> 01:09:08.040]   If you are working actively on this and in my free time, I did individually
[01:09:08.040 --> 01:09:10.000]   try to replicate all of these lines.
[01:09:10.000 --> 01:09:14.000]   Uh, and then things wouldn't work as I was working on them.
[01:09:14.000 --> 01:09:17.120]   And the, then I later learned the authors have already
[01:09:17.120 --> 01:09:18.160]   mentioned this in the book.
[01:09:18.160 --> 01:09:19.800]   What was going on?
[01:09:19.800 --> 01:09:24.760]   If you cache a function and if you change the function, you
[01:09:24.760 --> 01:09:26.240]   need to update the cache also.
[01:09:26.240 --> 01:09:28.840]   Otherwise the older function definition gets cached.
[01:09:29.320 --> 01:09:33.640]   And as you run the expectedly changed version, it's not changed because
[01:09:33.640 --> 01:09:36.080]   well, it's not cached and the older version is saved.
[01:09:36.080 --> 01:09:39.600]   So whenever you cache anything, it gets saved in the active
[01:09:39.600 --> 01:09:41.600]   memory and not on the disk.
[01:09:41.600 --> 01:09:43.760]   So active memory means RAM.
[01:09:43.760 --> 01:09:48.320]   And if you change what's already in the memory, or if you expect it to be
[01:09:48.320 --> 01:09:50.240]   changed to make sure it's changed.
[01:09:50.240 --> 01:09:52.760]   If that makes sense.
[01:09:52.760 --> 01:09:58.800]   Uh, so if you change this function definition, make sure you
[01:09:58.800 --> 01:09:59.880]   again, cache it in memory.
[01:09:59.880 --> 01:10:01.320]   That's, that's what I was trying to say.
[01:10:01.320 --> 01:10:07.440]   So now we need the list first of all of all of the MHT files.
[01:10:07.440 --> 01:10:11.520]   Uh, and we only bother about those that are on disk.
[01:10:11.520 --> 01:10:17.200]   So we get the last, uh, sorry, the four things that we are interested in.
[01:10:17.200 --> 01:10:21.600]   And if he looked at the files, uh, let's go back to those.
[01:10:21.600 --> 01:10:24.680]   Let's look at our MHT file.
[01:10:25.400 --> 01:10:29.680]   So we are interested in these four numbers.
[01:10:29.680 --> 01:10:36.960]   So we're just picking those up and we create a dictionary of the annotations
[01:10:36.960 --> 01:10:42.800]   where we read in the file and we read in the annotation center, the diameter
[01:10:42.800 --> 01:10:46.080]   and keep appending those.
[01:10:46.080 --> 01:10:53.680]   Now we also want to create a detailed list of the based on the tuple.
[01:10:54.400 --> 01:10:58.440]   And for that, I want to point this particular function out
[01:10:58.440 --> 01:11:00.400]   and I'll ask this as a question.
[01:11:00.400 --> 01:11:04.560]   So we're dividing Delta MM by four.
[01:11:04.560 --> 01:11:08.920]   Can anyone explain why are we dividing by four?
[01:11:08.920 --> 01:11:13.920]   Because the thing of interest to us here is the center of the nodule.
[01:11:13.920 --> 01:11:22.600]   So if we have the XYZ coordinates, why are we dividing by four to get the center?
[01:11:22.600 --> 01:11:34.000]   So if he, I'll explain this, uh, in a few minutes, but the question to
[01:11:34.000 --> 01:11:38.840]   everyone on the discourse forums is why are we dividing by four in this function?
[01:11:38.840 --> 01:11:44.000]   So we're looking at Delta MM and we're dividing by four.
[01:11:44.000 --> 01:11:45.640]   Why are we doing that?
[01:11:45.640 --> 01:12:08.720]   So what's going on here while Vinayak answers that question?
[01:12:08.720 --> 01:12:14.560]   Uh, we, we, we are first of all checking if the Delta MM is greater than
[01:12:14.560 --> 01:12:21.280]   the annotation diameter and what is Delta MM Delta MM is the difference
[01:12:21.280 --> 01:12:23.880]   between candidate center and annotation center.
[01:12:23.880 --> 01:12:30.400]   So remember when I pointed out that you could totally discard this, but if, uh,
[01:12:30.400 --> 01:12:36.280]   this is greater than the annotation diameter divided by four, why are
[01:12:36.280 --> 01:12:38.120]   we doing this is the question.
[01:12:38.120 --> 01:12:47.520]   I know it takes a minute as I speak these questions out.
[01:12:47.520 --> 01:12:53.320]   Uh, sometimes luckily a few people answer, uh, it takes a minute for them to answer.
[01:12:53.320 --> 01:12:56.640]   And so that's where it's an awkward few moments of silence.
[01:12:56.640 --> 01:13:00.720]   Is it to check and show the radius is not off by a lot?
[01:13:00.720 --> 01:13:01.960]   Yes, that's, that's correct.
[01:13:01.960 --> 01:13:03.120]   That's partly correct.
[01:13:03.120 --> 01:13:06.800]   Um, I don't see anyone else typing, so I'll read it off the book.
[01:13:07.640 --> 01:13:09.640]   It divides the diameter by two.
[01:13:09.640 --> 01:13:20.400]   So we divide first of all, the diameter by two and then the radius by two, so that
[01:13:20.400 --> 01:13:23.080]   we can ensure that the two nodules are not off.
[01:13:23.080 --> 01:13:28.600]   So Delta MM is the diameter.
[01:13:28.600 --> 01:13:33.600]   And then we make sure it's not too off of the annotation diameter
[01:13:34.200 --> 01:13:38.880]   divided by four, which arguably is the center, right?
[01:13:38.880 --> 01:13:43.160]   So let's, let's, let's look on that argument and explain why
[01:13:43.160 --> 01:13:44.640]   is that arguably the center?
[01:13:44.640 --> 01:13:56.440]   So let's say you have a white colored pen, first of all.
[01:13:56.440 --> 01:13:59.560]   So let's say you have an audio.
[01:13:59.920 --> 01:14:05.920]   Uh, you know, we are doing it was it's a cubic.
[01:14:05.920 --> 01:14:09.040]   It should have been as fair.
[01:14:09.040 --> 01:14:13.040]   That would have made my life easy, but let's say it's, it's a cubic, um,
[01:14:13.040 --> 01:14:16.360]   not you and we want to find the center.
[01:14:16.360 --> 01:14:23.360]   So you have the diameter and if you divide the diameter by two, you'll get the radius.
[01:14:23.360 --> 01:14:26.880]   So this is the radius, right?
[01:14:28.080 --> 01:14:35.720]   And if you divide the radius by two, you get somewhere at this point, uh, get
[01:14:35.720 --> 01:14:40.360]   close to somewhere along this point, right?
[01:14:40.360 --> 01:14:51.440]   Now, since this complete thing, this complete thing is so small, this
[01:14:51.440 --> 01:14:53.680]   possibly is really the center of it.
[01:14:53.680 --> 01:14:56.680]   If that made sense.
[01:14:58.040 --> 01:15:00.720]   Also, this image is not an ideal representation.
[01:15:00.720 --> 01:15:03.640]   It's it's never a cube.
[01:15:03.640 --> 01:15:06.400]   It's, it's a different representation.
[01:15:06.400 --> 01:15:10.880]   Most of the times it's, it's weird shapes that you're looking at weird mask lobules.
[01:15:10.880 --> 01:15:17.000]   In that case, radius divided by two should get you to the center of it.
[01:15:17.000 --> 01:15:19.440]   So that's why we divide by four.
[01:15:27.600 --> 01:15:33.000]   Now we can safely append to the candidate info list and we can
[01:15:33.000 --> 01:15:35.240]   sort these and return this list.
[01:15:35.240 --> 01:15:39.880]   So now we have a list of all of the candidates we are making progress.
[01:15:39.880 --> 01:15:43.960]   Uh, we're able to grab the dataset and load it into memory and we
[01:15:43.960 --> 01:15:45.320]   can continue working from there.
[01:15:45.320 --> 01:15:54.000]   So now we clear this class called CT and we can define the init function
[01:15:54.000 --> 01:15:58.160]   that pick up the MST files and we're using SITK to read in the
[01:15:58.160 --> 01:16:00.240]   images by passing the file path.
[01:16:00.240 --> 01:16:07.720]   So we create two CT scan files for CT, MSD and CTA, and we can
[01:16:07.720 --> 01:16:09.400]   grab these area files also.
[01:16:09.400 --> 01:16:14.080]   And we are doing something known as CTA dot clip.
[01:16:14.080 --> 01:16:19.520]   So what does CT first of all, it's through a SITK read image and
[01:16:19.520 --> 01:16:21.540]   this would be a SITK clip function.
[01:16:21.540 --> 01:16:23.200]   So let's look at what is that function.
[01:16:24.200 --> 01:16:24.200]   Okay.
[01:16:24.200 --> 01:16:37.080]   Uh, this is the first time I'm looking at the documentation and it
[01:16:37.080 --> 01:16:40.160]   appears to be in C plus plus, which is absolutely terrifying me so
[01:16:40.160 --> 01:16:41.480]   much that I want to go back.
[01:16:41.480 --> 01:16:42.680]   So I'll do that.
[01:16:42.680 --> 01:16:46.000]   And let's, let's look at the docs argument.
[01:16:46.000 --> 01:16:49.000]   Uh, this, this looks much more Pythonic.
[01:16:49.000 --> 01:16:49.920]   So I'll, I'll stick here.
[01:16:51.640 --> 01:16:54.360]   I want clip function, please.
[01:16:54.360 --> 01:17:02.120]   Okay.
[01:17:02.120 --> 01:17:03.160]   This is the older version.
[01:17:03.160 --> 01:17:05.680]   For some reason it wasn't appearing in the Google search.
[01:17:05.680 --> 01:17:07.200]   Let's try again.
[01:17:07.200 --> 01:17:11.160]   Um, clip function.
[01:17:11.160 --> 01:17:17.800]   Nope.
[01:17:17.800 --> 01:17:19.760]   I don't want to know about Eclipse.
[01:17:20.760 --> 01:17:21.040]   Okay.
[01:17:21.040 --> 01:17:22.160]   Uh, it's taking too long.
[01:17:22.160 --> 01:17:23.360]   So I'll just explain it.
[01:17:23.360 --> 01:17:26.840]   Um, I'll stop sharing and talk about this.
[01:17:26.840 --> 01:17:33.440]   So there are known, there's something known as HU.
[01:17:33.440 --> 01:17:38.280]   Uh, I want to read this on the book because I don't want to mess it up.
[01:17:38.280 --> 01:17:41.920]   HU is the unit code as Hounsfield units.
[01:17:41.920 --> 01:17:46.080]   And this is how we measure the density of different things in a CT scan.
[01:17:46.920 --> 01:17:54.120]   Here is minus 1000 water is zero and bone is at least plus 1000.
[01:17:54.120 --> 01:17:58.120]   That's, that's quite, quite the weird scale, right?
[01:17:58.120 --> 01:18:02.160]   Uh, and that's been decided in the MST files.
[01:18:02.160 --> 01:18:04.760]   So we're not going to bother with the reasoning behind it.
[01:18:04.760 --> 01:18:10.000]   What we are interested in is again, just finding the values
[01:18:10.000 --> 01:18:12.480]   between minus 1000 and thousand.
[01:18:13.960 --> 01:18:14.440]   Okay.
[01:18:14.440 --> 01:18:19.640]   So we're going to clip our annotation file to that.
[01:18:19.640 --> 01:18:27.480]   And we're just instantiating all of these other variables that we'll work with.
[01:18:27.480 --> 01:18:30.480]   Next thing we want to do is get the raw candidate.
[01:18:30.480 --> 01:18:32.680]   So in that we need the center.
[01:18:32.680 --> 01:18:34.760]   We need the width in IRC files.
[01:18:34.760 --> 01:18:43.240]   Uh, now if you remember the CT scans are in an XYZ coordinate system, right?
[01:18:43.880 --> 01:18:45.120]   I explained this last week.
[01:18:45.120 --> 01:18:48.160]   So I'm not going to do that again in interest of time, but
[01:18:48.160 --> 01:18:50.200]   we need to convert this into IRC.
[01:18:50.200 --> 01:18:59.080]   So, uh, we need to define functions for, for being able to do that.
[01:18:59.080 --> 01:19:03.960]   And also going back to XYZ, this is quite common in deep learning.
[01:19:03.960 --> 01:19:06.920]   So that's what the following functions do.
[01:19:06.920 --> 01:19:11.640]   And I'm trying to glance over the details that aren't important.
[01:19:12.640 --> 01:19:12.640]   Okay.
[01:19:12.640 --> 01:19:28.240]   I'll skip over these functions because these are pretty straightforward, but
[01:19:28.240 --> 01:19:31.120]   now we can subset into the dataset file.
[01:19:31.120 --> 01:19:36.560]   Sorry, the dataset class of Pytorch and create lunar dataset.
[01:19:37.640 --> 01:19:42.720]   So, uh, by definition, whenever we subset into that, we need to define a few things
[01:19:42.720 --> 01:19:46.920]   and we also need to define length and get item.
[01:19:46.920 --> 01:19:48.920]   So this is the most important thing.
[01:19:48.920 --> 01:19:52.960]   Whenever you create a dataset file, you need to return the length.
[01:19:52.960 --> 01:19:54.520]   You need to return get item.
[01:19:54.520 --> 01:19:59.160]   Uh, I'm explaining this code in a different way.
[01:19:59.160 --> 01:20:01.240]   Ideally you work your way backwards.
[01:20:01.240 --> 01:20:06.160]   So our broad goal here is to be able to work with this dataset in Pytorch.
[01:20:06.160 --> 01:20:07.480]   How do we do that?
[01:20:07.520 --> 01:20:08.720]   We load that for that.
[01:20:08.720 --> 01:20:09.680]   We need a dataset.
[01:20:09.680 --> 01:20:10.920]   What does a dataset need?
[01:20:10.920 --> 01:20:14.200]   It needs to be able to return these two things.
[01:20:14.200 --> 01:20:15.760]   How do we create these two things?
[01:20:15.760 --> 01:20:18.200]   Well, let's look at the data and see how can we do that.
[01:20:18.200 --> 01:20:22.520]   So I've been doing the opposite approach, but ideally when you've been given a zip
[01:20:22.520 --> 01:20:26.680]   file, you look at the zip file, you'll figure out how do you create the dataset
[01:20:26.680 --> 01:20:29.480]   function and then define these functions.
[01:20:29.480 --> 01:20:30.240]   Right?
[01:20:30.240 --> 01:20:36.560]   So we initialize all of the different things that are of important to us.
[01:20:36.880 --> 01:20:41.520]   One cool trick I found here is, uh, the author set of validation stride.
[01:20:41.520 --> 01:20:45.640]   So they want 10% of the dataset to be the validation dataset.
[01:20:45.640 --> 01:20:52.760]   So, uh, whenever we cross that particular 10th instance that gets
[01:20:52.760 --> 01:20:57.160]   passed into the validation list and the Boolean flag gets reset.
[01:20:57.160 --> 01:20:59.900]   So we iterate over nine elements.
[01:20:59.900 --> 01:21:04.040]   Every 10th elements gets added to a validation dataset.
[01:21:04.360 --> 01:21:07.160]   And then we repeat this process to be able to create it.
[01:21:07.160 --> 01:21:13.440]   So returning the length is pretty straightforward.
[01:21:13.440 --> 01:21:16.000]   We return self.candidateInfoList.
[01:21:16.000 --> 01:21:19.200]   What is candidateInfoList?
[01:21:19.200 --> 01:21:21.200]   Uh, I'm really happy you asked that question.
[01:21:21.200 --> 01:21:22.240]   Let's see.
[01:21:22.240 --> 01:21:39.920]   Remember we created this name tuple called candidateInfoTuple that gets
[01:21:39.920 --> 01:21:42.600]   constructed with getCandidateInfoList.
[01:21:42.600 --> 01:21:44.560]   That's where this comes from.
[01:21:49.640 --> 01:21:57.880]   So we grab that tuple and we find the candidate A and center in IRC
[01:21:57.880 --> 01:22:01.480]   coordinates, which is index row column coordinates.
[01:22:01.480 --> 01:22:05.160]   And we do that using this function we had just defined.
[01:22:05.160 --> 01:22:18.800]   And from there we can create candidate T and we can move this to a torch tensor.
[01:22:19.640 --> 01:22:21.760]   We can create a batch out of it.
[01:22:21.760 --> 01:22:25.320]   We'll look at more about this particular dimension next week
[01:22:25.320 --> 01:22:26.640]   as we continue working with it.
[01:22:26.640 --> 01:22:36.000]   And then we learn about if it's a nodule or not.
[01:22:36.000 --> 01:22:43.200]   And then we return all of these things whenever someone asks for the item.
[01:22:43.200 --> 01:22:46.640]   So for the item, they'll ask for the end index.
[01:22:47.000 --> 01:22:53.120]   Uh, this is one of the way of writing it another ways writing IDX, but for the
[01:22:53.120 --> 01:22:56.520]   Nth element, we do all of these conversions.
[01:22:56.520 --> 01:23:00.720]   So we grab the info tuple.
[01:23:00.720 --> 01:23:03.720]   We define this with function.
[01:23:03.720 --> 01:23:08.480]   We get the candidate A and center in IRC.
[01:23:08.480 --> 01:23:14.160]   We move the candidate tensor onto a torch tensor, create a batch out of it.
[01:23:16.600 --> 01:23:18.880]   And return the candidate tensor.
[01:23:18.880 --> 01:23:26.320]   The torch tensor contains the information if it's a nodule or not.
[01:23:26.320 --> 01:23:31.240]   We return it series ID and it's center.
[01:23:31.240 --> 01:23:35.800]   So whenever we want to grab an item, right, we want the details
[01:23:35.800 --> 01:23:37.400]   that are important to the dataset.
[01:23:37.400 --> 01:23:40.640]   These are the four things that are important to the dataset, right?
[01:23:40.640 --> 01:23:46.120]   So we return these and for length, you can just return the candidate info list length.
[01:23:46.120 --> 01:23:54.680]   And now you have a fully baked in datasets by file, which takes in these
[01:23:54.680 --> 01:23:58.440]   weird MSD files that up until now we haven't looked at unless you've been
[01:23:58.440 --> 01:24:02.080]   cackling on the side and not telling us if you have, that's awesome.
[01:24:02.080 --> 01:24:03.000]   Please do tell us though.
[01:24:03.000 --> 01:24:12.600]   Um, we take these weird files, read in the annotation, read in the candidates,
[01:24:13.960 --> 01:24:17.520]   create a custom dataset, uh, sorry, a custom data type.
[01:24:17.520 --> 01:24:18.240]   I'm really sorry.
[01:24:18.240 --> 01:24:21.480]   We create a custom data type to work with them.
[01:24:21.480 --> 01:24:26.840]   Where we create, uh, this data sector that has all of these
[01:24:26.840 --> 01:24:28.560]   things that are of importance to us.
[01:24:28.560 --> 01:24:31.720]   We get the candidate info list.
[01:24:31.720 --> 01:24:41.280]   We define a class CT, uh, where we can grab the raw candidate, grab
[01:24:41.280 --> 01:24:46.920]   the data set center, all of those details, get the CT scan, get the CT raw candidate.
[01:24:46.920 --> 01:24:53.560]   Finally, in lunar dataset class, we're able to return the length and get item.
[01:24:53.560 --> 01:24:56.040]   Why did we go through all of this pain?
[01:24:56.040 --> 01:24:58.520]   We want to work in PyTorch for that.
[01:24:58.520 --> 01:24:59.720]   We need a dataset class.
[01:24:59.720 --> 01:25:04.640]   A dataset class needs to be able to return the length and item details to
[01:25:04.640 --> 01:25:07.000]   return these details and to work with the dataset.
[01:25:07.000 --> 01:25:10.440]   We defined all of these things to make things work.
[01:25:11.440 --> 01:25:11.440]   Okay.
[01:25:11.440 --> 01:25:16.320]   So there's the top down attempt of explaining things.
[01:25:16.320 --> 01:25:21.600]   Um, I think we're at the end of the chapter and we have five minutes to go.
[01:25:21.600 --> 01:25:23.640]   So I'm happy to take any questions at this point.
[01:25:23.640 --> 01:25:34.280]   Sorting should be based on radius.
[01:25:34.280 --> 01:25:34.960]   I think.
[01:25:38.960 --> 01:25:40.480]   Oh, clip is a function from NumPy.
[01:25:40.480 --> 01:25:41.600]   Thanks for pointing that out.
[01:25:41.600 --> 01:25:50.360]   What am I doing?
[01:25:50.360 --> 01:25:52.040]   I'm searching for clip.
[01:25:52.040 --> 01:25:59.160]   CT read image, SITK read image.
[01:25:59.160 --> 01:26:02.160]   So Vinayak, thanks for pointing that out.
[01:26:02.200 --> 01:26:09.920]   I'm trying to look at the documentation and see if this actually returns NumPy
[01:26:09.920 --> 01:26:11.280]   array, which I think it does.
[01:26:11.280 --> 01:26:14.520]   So API version 2.1.
[01:26:14.520 --> 01:26:19.000]   I want to be able to search this.
[01:26:19.000 --> 01:26:20.160]   Why is that so hard?
[01:26:20.160 --> 01:26:23.440]   Um,
[01:26:23.440 --> 01:26:31.440]   function.
[01:26:31.440 --> 01:26:31.840]   Okay.
[01:26:31.840 --> 01:26:59.480]   Okay.
[01:26:59.480 --> 01:27:01.800]   We're back in C++, which is terrifying me.
[01:27:01.800 --> 01:27:06.880]   Um, I'm trying to understand if this returns NumPy arrays.
[01:27:06.880 --> 01:27:12.880]   I suspect it does, but I'm not 100% sure, but I think Vinayak is right.
[01:27:12.880 --> 01:27:15.080]   So that's why we are able to use clip function.
[01:27:15.080 --> 01:27:17.720]   Sure.
[01:27:17.720 --> 01:27:19.880]   Uh, to see if I'm happy to explain that.
[01:27:19.880 --> 01:27:22.480]   So why is the function for caching required?
[01:27:22.480 --> 01:27:26.960]   Uh, we're working with a lot of candidates, right?
[01:27:28.760 --> 01:27:32.040]   I scrolled through a lot of them and that's just one subset.
[01:27:32.040 --> 01:27:38.400]   So when you're working with that, um, you need to call this function
[01:27:38.400 --> 01:27:40.320]   many, many, many, many, many times.
[01:27:40.320 --> 01:27:46.680]   At that point, it's a good idea to cache this in memory so that it doesn't take
[01:27:46.680 --> 01:27:48.360]   too long to compute every single time.
[01:27:48.360 --> 01:27:51.320]   I hope that's helpful.
[01:27:51.320 --> 01:27:55.200]   Uh, please feel free to follow up if that's not explaining.
[01:27:55.200 --> 01:28:03.760]   Vinayak says it's been cast to a NumPy array.
[01:28:03.760 --> 01:28:08.080]   I should have read the next line.
[01:28:08.080 --> 01:28:09.600]   I'm so, I'm so sorry, guys.
[01:28:09.600 --> 01:28:12.920]   Uh, we cast it to a NumPy array.
[01:28:12.920 --> 01:28:22.040]   As you can see, uh, I have quite the focus so intense that I can't read line 90.
[01:28:22.560 --> 01:28:26.880]   Uh, but we're able to perform the clipping function coming from NumPy
[01:28:26.880 --> 01:28:28.440]   because it's a NumPy array now.
[01:28:28.440 --> 01:28:30.960]   NumPy docs.
[01:28:30.960 --> 01:28:33.000]   Thank you so much Vinayak for pointing that out.
[01:28:33.000 --> 01:28:42.880]   I really move for Vinayak to host the next sessions, uh, since he's more
[01:28:42.880 --> 01:28:46.320]   knowledgeable than me now, and I tend to mess up much more.
[01:28:46.320 --> 01:28:49.000]   Um, we found the functions on NumPy.clip.
[01:28:49.960 --> 01:28:53.840]   Given an interval of values outside the interval are
[01:28:53.840 --> 01:28:55.600]   clipped to the interval ages.
[01:28:55.600 --> 01:28:58.600]   So we just chop off the values that are outside of this interval.
[01:28:58.600 --> 01:29:03.600]   We don't care about the values earlier than one minus 1000 beyond 1000.
[01:29:03.600 --> 01:29:10.440]   Um, the lower bound gets rid of any negative density stuff, upper
[01:29:10.440 --> 01:29:14.200]   bound nukes, any weird hotspots and clamps.
[01:29:15.880 --> 01:29:18.520]   So basically they're, they're trying to point out any metal
[01:29:18.520 --> 01:29:21.640]   or if your stuff gets removed.
[01:29:21.640 --> 01:29:24.520]   Uh, that's what, so this is the density number.
[01:29:24.520 --> 01:29:27.560]   This is the HU density, and we don't care for those values.
[01:29:27.560 --> 01:29:35.960]   Okay.
[01:29:35.960 --> 01:29:38.140]   I'll wait another minute to take any questions.
[01:29:38.140 --> 01:29:40.960]   If not, I'm happy to conclude here.
[01:29:40.960 --> 01:29:43.960]   Uh, let's go back to my presentation.
[01:29:44.960 --> 01:29:46.480]   And give you some more homework.
[01:29:46.480 --> 01:29:49.840]   So the homework is start getting a feel for Kaggle.
[01:29:49.840 --> 01:29:56.000]   Pick your favorite notebook from DSP 2017 and translate a
[01:29:56.000 --> 01:29:57.520]   notebook from TensorFlow to Torch.
[01:29:57.520 --> 01:29:58.640]   Let me grab my headphones.
[01:29:58.640 --> 01:30:08.320]   Awesome.
[01:30:08.320 --> 01:30:10.640]   So what is DSP 2017?
[01:30:10.640 --> 01:30:12.240]   Uh, there are other tabs.
[01:30:13.240 --> 01:30:15.160]   Data Science Bowl 2017.
[01:30:15.160 --> 01:30:20.040]   The dataset here was Luna 16 dataset.
[01:30:20.040 --> 01:30:21.480]   Incredible, right?
[01:30:21.480 --> 01:30:23.360]   Uh, what a coincidence.
[01:30:23.360 --> 01:30:26.680]   I actually searched for it and found the competition first.
[01:30:26.680 --> 01:30:30.680]   Uh, I don't think I took part in this competition, uh, or
[01:30:30.680 --> 01:30:32.040]   followed Kaggle at that point.
[01:30:32.040 --> 01:30:32.880]   I was a Kaggle loom.
[01:30:32.880 --> 01:30:38.560]   One of the good things to do on Kaggle, uh, is sort by most words.
[01:30:40.720 --> 01:30:43.560]   Best case scenario, you get a notebook that's quite comprehensive.
[01:30:43.560 --> 01:30:47.520]   Uh, hopefully that's not always true.
[01:30:47.520 --> 01:30:50.520]   So not always you get the best notebook.
[01:30:50.520 --> 01:30:54.720]   The best notebook might not always have the most number of words for the sake of
[01:30:54.720 --> 01:30:55.200]   argument.
[01:30:55.200 --> 01:30:58.840]   Uh, let's, let's look at this full pre-processing tutorial or anything.
[01:30:58.840 --> 01:31:06.040]   And with time you build these biases, you know, I know Anoka's, uh, he's a 19 year
[01:31:06.040 --> 01:31:08.800]   old Kaggle grandmaster has incredible stuff all the time.
[01:31:08.800 --> 01:31:09.680]   We know Sendex.
[01:31:09.680 --> 01:31:14.000]   Uh, you might be inclined towards reading the notebooks just because you trust it.
[01:31:14.000 --> 01:31:25.880]   The homework I want to leave you all with is take these notebooks or code from here.
[01:31:25.880 --> 01:31:28.280]   That's using Keras, right?
[01:31:28.280 --> 01:31:30.920]   So again, I have this strong bias for ZF Turbo.
[01:31:30.920 --> 01:31:36.080]   He is a Kaggle grandmaster who has incredible, incredible results
[01:31:36.080 --> 01:31:37.960]   across any competition he enters.
[01:31:38.640 --> 01:31:40.680]   He peaked on rank four worldwide.
[01:31:40.680 --> 01:31:48.400]   So the homework is pick any notebook that's in Keras, start
[01:31:48.400 --> 01:31:51.400]   translating it to PyTorch.
[01:31:51.400 --> 01:31:57.080]   Just take every single function and convert it into PyTorch.
[01:31:57.080 --> 01:32:00.440]   Comment out things a lot.
[01:32:00.440 --> 01:32:04.240]   That's what I was trying to do as I started to rush through
[01:32:04.240 --> 01:32:05.440]   things in the interest of time.
[01:32:06.440 --> 01:32:09.040]   But comment things, convert them.
[01:32:09.040 --> 01:32:12.080]   And this becomes a blog post as a homework.
[01:32:12.080 --> 01:32:15.080]   I really like blogging and I would enforce that towards everyone.
[01:32:15.080 --> 01:32:20.120]   So, uh, not just this notebook, but really go and search for any
[01:32:20.120 --> 01:32:21.600]   notebook and start doing that.
[01:32:21.600 --> 01:32:25.080]   I have posted the link to the dataset.
[01:32:25.080 --> 01:32:28.280]   So if you just search for Luna 16, you'll find two or three different
[01:32:28.280 --> 01:32:33.120]   datasets, just load those into your notebooks.
[01:32:33.120 --> 01:32:35.320]   If you can't just ask the question.
[01:32:35.320 --> 01:32:40.960]   If you can't just ask the question and start converting these notebooks.
[01:32:40.960 --> 01:32:48.720]   Strong reminder, please, please, please give references when
[01:32:48.720 --> 01:32:49.840]   you copy someone's stuff.
[01:32:49.840 --> 01:32:54.240]   So you are translating stuff here and not coming up with stuff on your own.
[01:32:54.240 --> 01:32:58.840]   So even in your blog, please give due credit to ZF Turbo.
[01:32:58.840 --> 01:33:04.800]   If you copy their kernel, upvote their kernel, if you use it and
[01:33:04.800 --> 01:33:08.240]   don't plagiarize stuff, which means if you're using someone's stuff,
[01:33:08.240 --> 01:33:11.960]   give due credit, give links to them, give a link to their profile.
[01:33:11.960 --> 01:33:13.800]   Always do that.
[01:33:13.800 --> 01:33:18.040]   So the homework is use this dataset.
[01:33:18.040 --> 01:33:22.200]   Click new notebook that should create a new notebook.
[01:33:22.200 --> 01:33:27.680]   Take any notebook from the competition where people have created amazing
[01:33:27.680 --> 01:33:32.640]   resources and start translating that into PyTorch, uh, share what you
[01:33:32.640 --> 01:33:43.640]   learned in a blog post or just as a Twitter thread also, okay.
[01:33:43.640 --> 01:33:44.600]   I don't see any questions.
[01:33:44.600 --> 01:33:46.520]   So I'll end the call here.
[01:33:46.520 --> 01:33:48.800]   Thanks so much everyone for joining.
[01:33:48.800 --> 01:33:51.200]   Tauseef, no, I won't share the slides.
[01:33:51.200 --> 01:33:53.280]   It's just screenshots from the book.
[01:33:53.280 --> 01:33:57.000]   So I would rather you spend time coding than going through this.
[01:33:57.000 --> 01:34:02.120]   Uh, and again, thanks again, Vinayak for being the silent co-host
[01:34:02.120 --> 01:34:04.680]   for all of this time and also sharing your journey with us.
[01:34:04.680 --> 01:34:07.320]   It was really incredible to learn more about your journey.
[01:34:07.720 --> 01:34:07.840]   Bye.
[01:34:08.560 --> 01:34:08.560]   Bye.
[01:34:09.480 --> 01:34:09.480]   Bye.
[01:34:09.760 --> 01:34:09.960]   Okay.
[01:34:10.960 --> 01:34:11.040]   Bye.
[01:34:11.800 --> 01:34:11.880]   Bye.
[01:34:11.880 --> 01:34:41.880]   Bye.

