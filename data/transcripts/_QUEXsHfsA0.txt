
[00:00:00.000 --> 00:00:06.580]   So, hello everybody, and welcome to Deep Learning for Coders, lesson one.
[00:00:06.580 --> 00:00:16.060]   This is the fourth year that we've done this, but it's a very different and very special
[00:00:16.060 --> 00:00:17.900]   version for a number of reasons.
[00:00:17.900 --> 00:00:23.220]   The first reason it's different is because we are bringing it to you live from day number
[00:00:23.220 --> 00:00:27.520]   one of a complete shutdown, or not complete shutdown, but nearly complete shutdown of
[00:00:27.520 --> 00:00:28.520]   San Francisco.
[00:00:28.520 --> 00:00:34.400]   We're going to be recording it over the next two months in the midst of this global pandemic.
[00:00:34.400 --> 00:00:40.860]   So if things seem a little crazy sometimes in this course, I apologize, but that's why
[00:00:40.860 --> 00:00:43.400]   this is happening.
[00:00:43.400 --> 00:00:51.840]   The other reason it's special is because we're trying to make this our kind of definitive
[00:00:51.840 --> 00:00:54.400]   version, right?
[00:00:54.400 --> 00:00:57.940]   Since we've been doing this for a while now, we've actually finally gotten to the point
[00:00:57.940 --> 00:01:01.400]   where we almost feel like we know what we're talking about.
[00:01:01.400 --> 00:01:07.660]   To the point that Sylvain and I have actually written a book, and we've actually written
[00:01:07.660 --> 00:01:12.200]   a piece of software from scratch called the FastAI Library Version 2.
[00:01:12.200 --> 00:01:18.200]   We've written a peer-reviewed paper about this library.
[00:01:18.200 --> 00:01:24.700]   So this is kind of designed to be like the version of the course that is hopefully going
[00:01:24.700 --> 00:01:27.720]   to last a while.
[00:01:27.720 --> 00:01:32.300]   The syllabus is based very closely on this book, right?
[00:01:32.300 --> 00:01:38.800]   So if you want to read along properly as you go, please buy it.
[00:01:38.800 --> 00:01:44.000]   And I say please buy it because actually the whole thing is also available for free in
[00:01:44.000 --> 00:01:45.760]   the form of Jupyter Notebooks.
[00:01:45.760 --> 00:01:54.640]   And that is thanks to the huge generosity of O'Reilly Media who have let us do that.
[00:01:54.640 --> 00:02:03.440]   So you'll be able to see on the website for the course how to kind of access all this.
[00:02:03.440 --> 00:02:12.480]   But here is the fast book repo where you can read the whole damn thing.
[00:02:12.480 --> 00:02:18.520]   At the moment, as you see, it's a draft, but by the time you see this, it won't be.
[00:02:18.520 --> 00:02:25.760]   So we have a big request here, which is the deal is this.
[00:02:25.760 --> 00:02:31.600]   You can read this thing for free as Jupyter Notebooks, but that is not as convenient as
[00:02:31.600 --> 00:02:36.400]   reading it on a Kindle or, you know, in a paper book or whatever.
[00:02:36.400 --> 00:02:39.740]   So please don't turn this into a PDF, right?
[00:02:39.740 --> 00:02:46.400]   Please don't turn it into a form designed more for reading because kind of the whole
[00:02:46.400 --> 00:02:50.360]   point is that we hope, you know, that you'll buy it.
[00:02:50.360 --> 00:02:59.080]   Don't take advantage of O'Reilly's generosity by creating the thing that, you know, they're
[00:02:59.080 --> 00:03:00.700]   not giving you for free.
[00:03:00.700 --> 00:03:05.400]   And that's actually explicitly the license under which we're providing this as well.
[00:03:05.400 --> 00:03:10.520]   So that's a, you know, it's mainly a request to being a decent human being.
[00:03:10.520 --> 00:03:14.660]   If you see somebody else not being a decent human being and stealing the book version
[00:03:14.660 --> 00:03:17.120]   of the book, please tell them, please don't do that.
[00:03:17.120 --> 00:03:21.800]   It's not nice and don't be that person.
[00:03:21.800 --> 00:03:29.040]   So either way, you can read along with the syllabus in the book.
[00:03:29.040 --> 00:03:38.600]   There's a couple of different versions of these notebooks, right?
[00:03:38.600 --> 00:03:47.520]   Is the full notebook that has the entire prose, pictures, everything.
[00:03:47.520 --> 00:03:55.840]   Now we actually wrote a system to turn notebooks into a printed book, and sometimes that looks
[00:03:55.840 --> 00:03:57.040]   kind of weird.
[00:03:57.040 --> 00:04:05.840]   For example, here's a weird-looking table, and if you look in the actual book, it actually
[00:04:05.840 --> 00:04:07.920]   looks like a proper table, right?
[00:04:07.920 --> 00:04:12.160]   So sometimes you'll see like little weird bits, okay?
[00:04:12.160 --> 00:04:13.160]   They're not mistakes.
[00:04:13.160 --> 00:04:17.680]   They're bits where we kind of add information to help our book turn into a proper, nice
[00:04:17.680 --> 00:04:18.680]   book.
[00:04:18.680 --> 00:04:21.520]   So just, just ignore them.
[00:04:21.520 --> 00:04:23.480]   Now when I say "we", who is "we"?
[00:04:23.480 --> 00:04:30.840]   Well, I mentioned one important part of the "we" is Sylvain.
[00:04:30.840 --> 00:04:36.080]   Sylvain is my co-author of the book and the FastAI version 2 library.
[00:04:36.080 --> 00:04:39.400]   So he is my partner in crime here.
[00:04:39.400 --> 00:04:45.680]   The other key "we" here is Rachel Thomas.
[00:04:45.680 --> 00:04:48.680]   And so maybe Rachel, you can come and say hello.
[00:04:48.680 --> 00:04:50.680]   She's the co-founder of FastAI.
[00:04:50.680 --> 00:04:51.680]   Hello.
[00:04:51.680 --> 00:04:54.880]   Yes, I'm the co-founder of FastAI.
[00:04:54.880 --> 00:05:00.360]   I'm also lower, sorry, taller than Jeremy.
[00:05:00.360 --> 00:05:04.280]   And I'm the founding director of the Center for Applied Data Ethics at the University
[00:05:04.280 --> 00:05:05.280]   of San Francisco.
[00:05:05.280 --> 00:05:09.880]   I'm really excited to be a part of this course, and I'll be the voice you hear asking questions
[00:05:09.880 --> 00:05:15.320]   from the forums.
[00:05:15.320 --> 00:05:19.000]   Rachel and Sylvain are also the people in this group who actually understand math.
[00:05:19.000 --> 00:05:22.080]   I am a mere philosophy graduate.
[00:05:22.080 --> 00:05:23.400]   Rachel has a PhD.
[00:05:23.400 --> 00:05:27.040]   Sylvain has written 10 books about math.
[00:05:27.040 --> 00:05:33.320]   So if math questions come along, it's possible I may pass them along, but it's very nice
[00:05:33.320 --> 00:05:37.520]   to have an opportunity to work with people who understand this topic so well.
[00:05:37.520 --> 00:05:38.520]   Yes, Rachel.
[00:05:38.520 --> 00:05:39.520]   Sure.
[00:05:39.520 --> 00:05:40.520]   Thank you.
[00:05:40.520 --> 00:05:53.360]   And as Rachel mentioned, the other area where she has real world-class expertise is data
[00:05:53.360 --> 00:05:54.360]   ethics.
[00:05:54.360 --> 00:05:59.800]   She is the founding director of the Center for Applied Data Ethics at the University
[00:05:59.800 --> 00:06:00.800]   of San Francisco.
[00:06:00.800 --> 00:06:01.800]   Thank you.
[00:06:01.800 --> 00:06:08.120]   We're going to be talking about data ethics throughout the course, because, well, we happen
[00:06:08.120 --> 00:06:10.240]   to think it's very important.
[00:06:10.240 --> 00:06:14.880]   So for those parts, although I'll generally be presenting them, they will be on the whole
[00:06:14.880 --> 00:06:21.880]   based on Rachel's work, because she actually knows what she's talking about.
[00:06:21.880 --> 00:06:26.240]   Although thanks to her, I kind of know a bit about what I'm talking about, too.
[00:06:26.240 --> 00:06:27.240]   Right.
[00:06:27.240 --> 00:06:31.400]   So that's that.
[00:06:31.400 --> 00:06:34.160]   So should you be here?
[00:06:34.160 --> 00:06:41.040]   Is there any point you're attempting to understand – let me press the right button – understand
[00:06:41.040 --> 00:06:43.640]   deep learning?
[00:06:43.640 --> 00:06:45.640]   Okay.
[00:06:45.640 --> 00:06:49.080]   So what do you – should you be here?
[00:06:49.080 --> 00:06:55.520]   Is there any point you're attempting to learn deep learning, or are you too stupid, or you
[00:06:55.520 --> 00:06:59.400]   don't have enough vast resources, or whatever?
[00:06:59.400 --> 00:07:01.360]   Because that's what a lot of people are telling us.
[00:07:01.360 --> 00:07:07.720]   They're saying, you know, teams of PhDs and massive data centers full of GPUs, otherwise
[00:07:07.720 --> 00:07:08.720]   it's pointless.
[00:07:08.720 --> 00:07:11.720]   Don't worry, that is not at all true.
[00:07:11.720 --> 00:07:14.200]   It couldn't be further from the truth.
[00:07:14.200 --> 00:07:21.900]   In fact, the vast majority – so a lot of world-class research and world-class industry
[00:07:21.900 --> 00:07:33.760]   projects have come out of fast AI alumni and fast AI library-based projects, and elsewhere,
[00:07:33.760 --> 00:07:42.760]   which are created on a single GPU using a few dozen or a few hundred data points from
[00:07:42.760 --> 00:07:51.560]   people that have no graduate-level technical expertise, or in my case, I have no undergraduate-level
[00:07:51.560 --> 00:07:55.080]   technical expertise, I'm just a philosophy major.
[00:07:55.080 --> 00:07:59.600]   So there is – and we'll see it throughout the course – but there is lots and lots
[00:07:59.600 --> 00:08:03.560]   and lots of clear empirical evidence that you don't need lots of math, you don't need
[00:08:03.560 --> 00:08:08.240]   lots of data, you don't need lots of expensive computers to do great stuff with deep learning.
[00:08:08.240 --> 00:08:12.240]   So just bear with us, you'll be fine.
[00:08:12.240 --> 00:08:15.240]   To do this course, you do need to code.
[00:08:15.240 --> 00:08:20.840]   Preferably, you know how to code in Python, but if you've done other languages, you can
[00:08:20.840 --> 00:08:21.840]   learn Python.
[00:08:21.840 --> 00:08:26.480]   If the only languages you've done is something like Matlab, where you've used it more of
[00:08:26.480 --> 00:08:30.840]   kind of like a scripty kind of thing, you might find it a bit – you will find it a
[00:08:30.840 --> 00:08:40.960]   bit heavier going, but that's okay, stick with it, you can learn Python as you go.
[00:08:40.960 --> 00:08:46.180]   Is there any point learning, deep learning, is it any good at stuff?
[00:08:46.180 --> 00:08:53.880]   If you are hoping to build a brain that is an AGI, I cannot promise we're going to help
[00:08:53.880 --> 00:08:55.760]   you with that.
[00:08:55.760 --> 00:08:58.960]   And AGI stands for artificial general intelligence.
[00:08:58.960 --> 00:08:59.960]   Thank you.
[00:08:59.960 --> 00:09:06.160]   What I can tell you though is that in all of these areas, deep learning is the best
[00:09:06.160 --> 00:09:12.720]   known approach to at least many versions of all of these things.
[00:09:12.720 --> 00:09:17.920]   So it is not speculative at this point whether this is a useful tool.
[00:09:17.920 --> 00:09:23.120]   It's a useful tool in lots and lots and lots of places, extremely useful tool.
[00:09:23.120 --> 00:09:29.360]   And in many of these cases, it is equivalent to or better than human performance, at least
[00:09:29.360 --> 00:09:34.040]   according to some particular kind of narrow definition of things that humans do in these
[00:09:34.040 --> 00:09:36.200]   kinds of areas.
[00:09:36.200 --> 00:09:42.000]   So deep learning is pretty amazing, and if you kind of want to pause the video here and
[00:09:42.000 --> 00:09:46.120]   have a look through and try and pick some things out that you think might look interesting,
[00:09:46.120 --> 00:09:51.000]   then type that keyword and deep learning into Google and you'll find lots of papers and
[00:09:51.000 --> 00:09:55.320]   examples and stuff like that.
[00:09:55.320 --> 00:10:01.440]   Deep learning comes from a background of neural networks, as you'll see, deep learning is
[00:10:01.440 --> 00:10:08.020]   just a type of neural network learning, a deep one, we'll describe exactly what that
[00:10:08.020 --> 00:10:09.020]   means later.
[00:10:09.020 --> 00:10:13.920]   And neural networks are certainly not a new thing, they go back at least in 1943 when
[00:10:13.920 --> 00:10:19.640]   McCulloch and Pitts created a mathematical model of an artificial neuron and got very
[00:10:19.640 --> 00:10:23.600]   excited about where that could get to.
[00:10:23.600 --> 00:10:31.800]   And then in the 50s, Frank Rosenblatt then built on top of that, he basically created
[00:10:31.800 --> 00:10:37.980]   some subtle changes to that mathematical model, and he thought that with these subtle changes
[00:10:37.980 --> 00:10:42.480]   we could witness the birth of a machine that is capable of perceiving, recognizing, and
[00:10:42.480 --> 00:10:46.720]   identifying its surroundings without any human training or control.
[00:10:46.720 --> 00:10:56.700]   And he oversaw the building of this extraordinary thing, the Mach 1 Perceptron at Cornell.
[00:10:56.700 --> 00:11:00.400]   So that was I think this picture was 1961.
[00:11:00.400 --> 00:11:04.320]   Thankfully nowadays we don't have to build neural networks by running the damn wires
[00:11:04.320 --> 00:11:08.080]   shown here on to neuron, artificial neuron to artificial neuron, but you can kind of
[00:11:08.080 --> 00:11:12.480]   see the idea, a lot of connections going on, and you'll hear the word connection a lot
[00:11:12.480 --> 00:11:16.840]   in this course because that's what it's all about.
[00:11:16.840 --> 00:11:22.360]   Then we had the first AI winter as it was known, which really to a strong degree happened
[00:11:22.360 --> 00:11:29.400]   because an MIT professor named Marvin Minsky and Papert wrote a book called Perceptrons
[00:11:29.400 --> 00:11:35.680]   about Rosenblatt's invention, in which they pointed out that a single layer of these artificial
[00:11:35.680 --> 00:11:41.680]   neuron devices actually couldn't learn some critical things, it was like impossible for
[00:11:41.680 --> 00:11:47.000]   them to learn something as simple as the Boolean XOR operator.
[00:11:47.000 --> 00:11:51.560]   In the same book, they showed that using multiple layers of the devices actually would fix the
[00:11:51.560 --> 00:11:52.560]   problem.
[00:11:52.560 --> 00:11:58.800]   People didn't notice that part of the book and only noticed the limitation, and people
[00:11:58.800 --> 00:12:04.400]   basically decided that neural networks were going to go nowhere, and they kind of largely
[00:12:04.400 --> 00:12:12.240]   disappeared for decades until, in some ways, 1986, a lot happened in the meantime, but there
[00:12:12.240 --> 00:12:19.560]   was a big thing in 1986 which is MIT released a thing called a book, a series of two volumes
[00:12:19.560 --> 00:12:25.800]   of book called parallel distributed processing, in which they described this thing they call
[00:12:25.800 --> 00:12:31.480]   parallel distributed processing, where you have a bunch of processing units that have
[00:12:31.480 --> 00:12:39.440]   some state of activation and some output function and some pattern of connectivity and some
[00:12:39.440 --> 00:12:44.880]   propagation rule and some activation rule and some learning rule operating in an environment,
[00:12:44.880 --> 00:12:50.520]   and then they described how things that met these requirements could, in theory, do all
[00:12:50.520 --> 00:12:52.440]   kinds of amazing work.
[00:12:52.440 --> 00:12:57.960]   And this was the result of many, many researchers working together, the whole group involved
[00:12:57.960 --> 00:13:03.320]   in this project which resulted in this very, very important book.
[00:13:03.320 --> 00:13:09.240]   And so the interesting thing here to me is that as you go through this course, come back
[00:13:09.240 --> 00:13:15.400]   and have a look at this picture and you'll see we are doing exactly these things.
[00:13:15.400 --> 00:13:22.840]   Something we're learning about really is how do you do each of these eight things, right?
[00:13:22.840 --> 00:13:25.400]   And it's interesting that they include the environment, because that's something which
[00:13:25.400 --> 00:13:30.640]   very often data scientists ignore, which is you build a model, you've trained it, it's
[00:13:30.640 --> 00:13:33.520]   learned something, what's the context it works in.
[00:13:33.520 --> 00:13:40.080]   We'll be talking about that quite a bit over the next couple of lessons as well.
[00:13:40.080 --> 00:13:46.800]   So in the 80s, you know, during and after this was released, people started building
[00:13:46.800 --> 00:13:51.620]   in this second layer of neurons avoiding Minsky's problem.
[00:13:51.620 --> 00:13:59.800]   And in fact, it was shown that it was mathematically provable that by adding that one extra layer
[00:13:59.800 --> 00:14:07.600]   of neurons, it was enough to allow any mathematical model to be approximated to any level of accuracy
[00:14:07.600 --> 00:14:10.120]   with these neural networks.
[00:14:10.120 --> 00:14:13.760]   And so that was like the exact opposite of the Minsky thing.
[00:14:13.760 --> 00:14:19.240]   That was like, hey, you know, there's nothing we can't do, provably there's nothing we can't
[00:14:19.240 --> 00:14:20.240]   do.
[00:14:20.240 --> 00:14:23.480]   And so that was kind of when I started getting involved in neural networks.
[00:14:23.480 --> 00:14:28.840]   So I was, a little bit later, I guess I was getting involved in the early 90s and they
[00:14:28.840 --> 00:14:30.760]   were very widely used in industry.
[00:14:30.760 --> 00:14:35.160]   I was using them for the very boring things like targeted marketing for retail banks.
[00:14:35.160 --> 00:14:40.280]   You know, it tended to be big companies with lots of money that were using them.
[00:14:40.280 --> 00:14:47.040]   And it certainly though was true that often the networks were too big or slow to be useful.
[00:14:47.040 --> 00:14:51.800]   They were certainly useful for some things, but they, you know, they never felt to me
[00:14:51.800 --> 00:14:55.760]   like they were living up to the promise for some reason.
[00:14:55.760 --> 00:15:02.040]   Now what I didn't know, and nobody I personally met knew, was that actually there were researchers
[00:15:02.040 --> 00:15:08.560]   that had showed 30 years ago that to get practical good performance, you need more layers of neurons.
[00:15:08.560 --> 00:15:14.400]   Even though mathematically, theoretically, you can get as accurate as you want with just
[00:15:14.400 --> 00:15:20.820]   one extra layer, to do it with good performance, you need more layers.
[00:15:20.820 --> 00:15:26.060]   So when you add more layers to a neural network, you get deep learning.
[00:15:26.060 --> 00:15:29.440]   So deep doesn't mean anything like mystical.
[00:15:29.440 --> 00:15:35.760]   It just means more layers, more layers than just adding the one extra one.
[00:15:35.760 --> 00:15:40.440]   So thanks to that, neural nets are now living up to their potential as we saw in that like
[00:15:40.440 --> 00:15:42.640]   what's deep learning good at thing.
[00:15:42.640 --> 00:15:46.320]   So we could now say that Rosenblatt was right.
[00:15:46.320 --> 00:15:52.680]   We have a machine that's capable of perceiving, recognizing and identifying its surroundings
[00:15:52.680 --> 00:15:54.680]   without any human training or control.
[00:15:54.680 --> 00:15:56.440]   That is, that's definitely true.
[00:15:56.440 --> 00:15:59.720]   I don't think there's anything controversial about that statement based on the current
[00:15:59.720 --> 00:16:01.440]   technology.
[00:16:01.440 --> 00:16:04.920]   So we're going to be learning how to do that.
[00:16:04.920 --> 00:16:09.240]   We're going to be learning how to do that in exactly the opposite way of probably all
[00:16:09.240 --> 00:16:13.740]   of the other math and technical education you've had.
[00:16:13.740 --> 00:16:24.280]   We are not going to start with a two-hour lesson about the sigmoid function, or a study
[00:16:24.280 --> 00:16:29.720]   of linear algebra, or a refresher course on calculus.
[00:16:29.720 --> 00:16:37.640]   And the reason for that is that people who study how to teach and learn have found that
[00:16:37.640 --> 00:16:41.600]   is not the right way to do it for most people.
[00:16:41.600 --> 00:16:50.880]   For most people, so we work a lot based on the work of Professor David Perkins from Harvard
[00:16:50.880 --> 00:16:56.480]   and others who work at similar things, who talk about this idea of playing the whole
[00:16:56.480 --> 00:16:57.480]   game.
[00:16:57.480 --> 00:17:00.960]   And so playing the whole game is based on the sports analogy.
[00:17:00.960 --> 00:17:08.320]   If you're going to teach somebody baseball, you don't take them out into a classroom and
[00:17:08.320 --> 00:17:17.560]   start teaching them about the physics of a parabola and how to stitch a ball and a three-part
[00:17:17.560 --> 00:17:21.000]   history of a hundred years of baseball politics.
[00:17:21.000 --> 00:17:24.300]   And then ten years later, you let them watch a game.
[00:17:24.300 --> 00:17:27.080]   And then twenty years later, you let them play a game.
[00:17:27.080 --> 00:17:31.560]   Which is kind of like how math education is being done.
[00:17:31.560 --> 00:17:37.240]   Instead, with baseball, step one is to say, "Hey, let's go and watch some baseball."
[00:17:37.240 --> 00:17:38.240]   What do you think?
[00:17:38.240 --> 00:17:39.240]   That was fun, right?
[00:17:39.240 --> 00:17:40.240]   See that guy there?
[00:17:40.240 --> 00:17:41.840]   He's trying to run there before the other guy throws a ball over there?
[00:17:41.840 --> 00:17:43.760]   "Hey, you want to try having a hit?"
[00:17:43.760 --> 00:17:47.160]   "Okay, so you're going to hit the ball, and then I have to try and catch it, and then
[00:17:47.160 --> 00:17:48.820]   you have to run over there?"
[00:17:48.820 --> 00:17:52.680]   And so from step one, you are playing the whole game.
[00:17:52.680 --> 00:17:58.560]   Yeah, and just to add to that, when people start, they're often may not have a full team
[00:17:58.560 --> 00:18:03.280]   or be playing a full nine innings, but they still have a sense of what the game is and
[00:18:03.280 --> 00:18:05.360]   kind of the big picture idea.
[00:18:05.360 --> 00:18:06.360]   Yeah.
[00:18:06.360 --> 00:18:11.960]   So there's lots and lots of reasons that this helps most human beings.
[00:18:11.960 --> 00:18:14.040]   Not everybody, right?
[00:18:14.040 --> 00:18:19.440]   There's a small percentage of people who like to build things up from the foundations and
[00:18:19.440 --> 00:18:23.920]   the principles, and not surprisingly, they are massively overrepresented in a university
[00:18:23.920 --> 00:18:30.680]   setting because the people who get to be academics are the people who thrive with the kind of,
[00:18:30.680 --> 00:18:33.560]   to me, upside-down way that things are taught.
[00:18:33.560 --> 00:18:40.440]   But outside of universities, most people learn best in this top-down way, where you start
[00:18:40.440 --> 00:18:42.400]   with the full context.
[00:18:42.400 --> 00:18:47.480]   So step number two in the seven principles, I'm only going to mention the first three,
[00:18:47.480 --> 00:18:51.960]   is to make the game worth playing, which is like, if you're playing baseball, you have
[00:18:51.960 --> 00:19:00.160]   a competition, you score, you try and win, you bring together teams from around the community
[00:19:00.160 --> 00:19:04.960]   and have people try to beat each other, and you have leaderboards of who's got the highest
[00:19:04.960 --> 00:19:08.640]   number of runs or whatever, right?
[00:19:08.640 --> 00:19:15.000]   So this is all about making sure that the thing you're doing, you're doing it properly,
[00:19:15.000 --> 00:19:16.000]   you know?
[00:19:16.000 --> 00:19:22.960]   You're making it the whole thing, you're providing the context and the interest.
[00:19:22.960 --> 00:19:30.480]   So for the fast AI approach to learning deep learning, what this means is that today we're
[00:19:30.480 --> 00:19:36.200]   going to train models end-to-end, we're going to actually train models, right?
[00:19:36.200 --> 00:19:42.640]   And they won't just be crappy models, they will be state-of-the-art world-class models
[00:19:42.640 --> 00:19:43.640]   from today.
[00:19:43.640 --> 00:19:48.800]   And we're going to try to have you build your own state-of-the-art world-class models from
[00:19:48.800 --> 00:19:53.760]   either today or next lesson, depending on how things go.
[00:19:53.760 --> 00:19:59.560]   Then number three in the seven principles from Harvard is work on the hard parts, which
[00:19:59.560 --> 00:20:07.160]   is kind of like this idea of practice.
[00:20:07.160 --> 00:20:10.040]   Yeah, deliberate practice, right?
[00:20:10.040 --> 00:20:19.680]   Work on the hard parts means that you don't just swing a bat at a ball every time you
[00:20:19.680 --> 00:20:23.920]   go out and just muck around, but you train properly.
[00:20:23.920 --> 00:20:28.600]   You find the bit that you're the least good at, you figure out where the problems are,
[00:20:28.600 --> 00:20:30.920]   you work damn hard at it, right?
[00:20:30.920 --> 00:20:40.440]   So in the deep learning context that means that we do not dumb things down, right?
[00:20:40.440 --> 00:20:47.400]   By the end of the course you will have done the calculus, you have done the linear algebra,
[00:20:47.400 --> 00:20:54.360]   you will have done the software engineering of the code, right?
[00:20:54.360 --> 00:21:04.280]   You will be practicing these things which are hard, so it requires tenacity and commitment,
[00:21:04.280 --> 00:21:11.280]   but hopefully you'll understand why it matters because before you start practicing something
[00:21:11.280 --> 00:21:15.520]   you'll know why you need that thing because you'll be using it, like to make your model
[00:21:15.520 --> 00:21:19.400]   better you'll have to understand that concept first.
[00:21:19.400 --> 00:21:24.440]   So for those of you used to a traditional university environment, this is going to feel
[00:21:24.440 --> 00:21:30.840]   pretty weird and a lot of people say that they regret at, you know, after a year of
[00:21:30.840 --> 00:21:37.040]   studying fast AI that they spent too much time studying theory and not enough time training
[00:21:37.040 --> 00:21:39.440]   models and writing code.
[00:21:39.440 --> 00:21:43.240]   That's the kind of like the number one piece of feedback we get of people who say I wish
[00:21:43.240 --> 00:21:45.720]   I had done things differently, it's that.
[00:21:45.720 --> 00:21:54.720]   So please try to as best as you can, since you're here, follow along with this approach.
[00:21:54.720 --> 00:21:59.880]   We are going to be using a kind of a software stack, sorry Victoria.
[00:21:59.880 --> 00:22:02.560]   I just want to say one more thing about the approach.
[00:22:02.560 --> 00:22:06.960]   I think since so many of us spent so many years kind of with a traditional educational
[00:22:06.960 --> 00:22:13.240]   approach of bottom up that this can feel very uncomfortable at first, I still feel uncomfortable
[00:22:13.240 --> 00:22:18.400]   with it sometimes even though I'm committed to the idea and that some of it is also kind
[00:22:18.400 --> 00:22:23.600]   of having to catch yourself and be okay with not knowing the details which I think can
[00:22:23.600 --> 00:22:29.160]   feel very unfamiliar or even wrong when you're kind of new to that of like oh wait I'm using
[00:22:29.160 --> 00:22:33.900]   something and I don't understand every underlying detail but you kind of have to trust that
[00:22:33.900 --> 00:22:36.400]   we're going to get to those details later.
[00:22:36.400 --> 00:22:40.240]   So I can't empathize because I did not spend lots of time doing that but I will tell you
[00:22:40.240 --> 00:22:44.520]   this, teaching this way is very, very, very hard.
[00:22:44.520 --> 00:22:49.440]   You know I very often find myself jumping back into a foundation's first approach because
[00:22:49.440 --> 00:22:52.480]   it's just so easy to be like oh you need to know this, you need to know this, you need
[00:22:52.480 --> 00:22:55.160]   to do this and then you can know this.
[00:22:55.160 --> 00:23:00.240]   That's so much easier to teach so I do find this much, much more challenging to teach
[00:23:00.240 --> 00:23:01.800]   but hopefully it's worth it.
[00:23:01.800 --> 00:23:07.720]   We've spent a long, long time figuring out how to get deep learning into this format.
[00:23:07.720 --> 00:23:11.640]   One of the things that helps us here is the software we have available.
[00:23:11.640 --> 00:23:23.000]   If you haven't used Python before it's ridiculously flexible and expressive and easy to use language.
[00:23:23.000 --> 00:23:28.200]   We have plenty of bits about it we don't love but on the whole we love the overall thing
[00:23:28.200 --> 00:23:34.400]   and we think it's, most importantly the vast, vast, vast majority of deep learning practitioners
[00:23:34.400 --> 00:23:38.000]   and researchers are using Python.
[00:23:38.000 --> 00:23:45.480]   On top of Python there are two libraries that most folks are using today PyTorch and TensorFlow.
[00:23:45.480 --> 00:23:50.280]   There's been a very rapid change here, TensorFlow was what we were teaching until a couple of
[00:23:50.280 --> 00:23:56.240]   years ago, it's what everyone was using until a couple of years ago.
[00:23:56.240 --> 00:24:00.640]   It got super bogged down, basically TensorFlow got super bogged down.
[00:24:00.640 --> 00:24:04.880]   There's other software called PyTorch came along that was much easier to use and much
[00:24:04.880 --> 00:24:13.600]   more useful to researchers and within the last 12 months the number, the percentage
[00:24:13.600 --> 00:24:21.020]   of papers at major conferences that uses PyTorch has gone from 20% to 80% and vice versa.
[00:24:21.020 --> 00:24:24.960]   Those that use TensorFlow have gone from 80% to 20%.
[00:24:24.960 --> 00:24:28.920]   So basically all the folks that are actually building the technology we're all using are
[00:24:28.920 --> 00:24:35.760]   now using PyTorch and industry moves a bit more slowly but in the next year or two you'll
[00:24:35.760 --> 00:24:38.720]   probably see a similar thing in industry.
[00:24:38.720 --> 00:24:45.180]   Now the thing about PyTorch is it's super, super flexible and really is designed for
[00:24:45.180 --> 00:24:52.600]   flexibility and developer-friendliness, certainly not designed for beginner-friendliness and
[00:24:52.600 --> 00:24:57.120]   it's not designed for what we would say, it doesn't have like higher level APIs by which
[00:24:57.120 --> 00:25:05.760]   I mean there isn't really things to make it easy to build stuff quickly using PyTorch.
[00:25:05.760 --> 00:25:13.400]   So to deal with that issue we have a library called FastAI that sits on top of PyTorch.
[00:25:13.400 --> 00:25:23.760]   FastAI is the most popular higher level API for PyTorch.
[00:25:23.760 --> 00:25:29.940]   That's how courses are so popular, some people are under the mistaken impression that FastAI
[00:25:29.940 --> 00:25:35.120]   is designed for beginners or for teaching.
[00:25:35.120 --> 00:25:43.840]   It is designed for beginners and teaching as well as practitioners in industry and researchers.
[00:25:43.840 --> 00:25:52.480]   The way we do this, make sure that it's the best API for all of those people, is we use
[00:25:52.480 --> 00:26:00.280]   something called a layered API and so there's a peer-reviewed paper that Sylvain and I wrote
[00:26:00.280 --> 00:26:04.760]   that described how we did that and for those of you that are software engineers it will
[00:26:04.760 --> 00:26:10.320]   not be at all unusual or surprising, it's just totally standard software engineering
[00:26:10.320 --> 00:26:15.440]   practices but they were practices that were not followed in any deep learning library
[00:26:15.440 --> 00:26:22.640]   we had seen, just you know basically lots of refactoring and decoupling.
[00:26:22.640 --> 00:26:28.200]   And so by using that approach it's allowed us to build something which you can do super
[00:26:28.200 --> 00:26:37.680]   low-level research, you can do state-of-the-art production models and you can do kind of super
[00:26:37.680 --> 00:26:43.820]   easy beginner but beginner world-class models.
[00:26:43.820 --> 00:26:47.180]   So that's the basic software stack, there's other pieces of software we'll be learning
[00:26:47.180 --> 00:26:54.540]   about along the way but the main thing I think to mention here is it actually doesn't matter.
[00:26:54.540 --> 00:27:00.580]   If you learn this software stack and then at work you need to use TensorFlow and Keras
[00:27:00.580 --> 00:27:08.860]   say you'll be able to switch in less than a week, lots and lots of students have done
[00:27:08.860 --> 00:27:17.520]   that, it's never been a problem, the important thing is to learn the concepts and so we're
[00:27:17.520 --> 00:27:26.520]   going to focus on those concepts and by using an API which minimizes the amount of boilerplate
[00:27:26.520 --> 00:27:30.320]   you have to use it means you can focus on the bits that are important, the actual lines
[00:27:30.320 --> 00:27:39.120]   of code will correspond much more to the actual concepts you're implementing.
[00:27:39.120 --> 00:27:46.360]   You are going to need a GPU machine, a GPU is a graphics processing unit and specifically
[00:27:46.360 --> 00:27:53.240]   you need an Nvidia GPU, other brands of GPU just aren't well supported by any deep learning
[00:27:53.240 --> 00:27:55.480]   libraries.
[00:27:55.480 --> 00:28:00.080]   Please don't buy one, even if you already have one you probably shouldn't use it, instead
[00:28:00.080 --> 00:28:05.340]   you should use one of the platforms that we have already got set up for you.
[00:28:05.340 --> 00:28:10.360]   It's just a huge distraction to be spending your time doing like system administration
[00:28:10.360 --> 00:28:18.880]   on a GPU machine and installing drivers and blah blah blah right and run it on Linux please,
[00:28:18.880 --> 00:28:22.220]   that's what everybody's doing not just us, everybody's running it on Linux.
[00:28:22.220 --> 00:28:25.860]   Make life easy for yourself, it's hard enough to learn deep learning without having to do
[00:28:25.860 --> 00:28:33.000]   it in a way that you're learning all kinds of arcane hardware support issues.
[00:28:33.000 --> 00:28:43.440]   There's a lot of free options available and so please use them.
[00:28:43.440 --> 00:28:48.240]   If you're using an option that's not free don't forget to shut down your instance.
[00:28:48.240 --> 00:28:51.340]   So what's going to be happening is you're going to be spinning up a server that lives
[00:28:51.340 --> 00:28:56.460]   somewhere else in the world and you're going to be connecting to it from your computer
[00:28:56.460 --> 00:29:01.480]   and training and running and building models.
[00:29:01.480 --> 00:29:05.940]   Just because you close your browser window doesn't mean your server stops running on
[00:29:05.940 --> 00:29:12.480]   the whole, so don't forget to shut it down because otherwise you're paying for it.
[00:29:12.480 --> 00:29:19.000]   Colab is a great system which is free, there's also a paid subscription version of it.
[00:29:19.000 --> 00:29:26.160]   Be careful with Colab, most of the other systems we recommend save your work for you automatically
[00:29:26.160 --> 00:29:29.120]   and you can come back to it anytime, Colab doesn't.
[00:29:29.120 --> 00:29:37.680]   So be sure to check out the Colab platform thread on the forums to learn about that.
[00:29:37.680 --> 00:29:49.840]   So I mentioned the forums, the forums are really really important because that is where
[00:29:49.840 --> 00:29:54.000]   all of the discussion and setup and everything happens.
[00:29:54.000 --> 00:29:58.760]   So for example if you want help with setup here you know there's a setup help thread
[00:29:58.760 --> 00:30:06.200]   and you can find out you know how to best setup Colab and you can see discussions about
[00:30:06.200 --> 00:30:12.000]   it and you can ask questions and please remember to search before you ask your question right
[00:30:12.000 --> 00:30:18.920]   because it's probably been asked before unless you're one of the very very earliest people
[00:30:18.920 --> 00:30:21.800]   who are doing the course.
[00:30:21.800 --> 00:30:32.020]   So step one is to get your server setup by just following the instructions from the forums
[00:30:32.020 --> 00:30:37.960]   or from the course website and the course website will have lots of step-by-step instructions
[00:30:37.960 --> 00:30:42.920]   for each platform, they will vary in price, they will vary in speed, they will vary in
[00:30:42.920 --> 00:30:46.360]   availability and so forth.
[00:30:46.360 --> 00:30:52.440]   Once you have finished following those instructions the last step of those instructions will end
[00:30:52.440 --> 00:31:01.040]   up showing you something like this, the course v4 folder, so version 4 of our course and
[00:31:01.040 --> 00:31:04.640]   by the time you see this video this is likely to have more stuff in it but it will have
[00:31:04.640 --> 00:31:12.680]   an nbs standing for notebooks folder so you can click on that and that will show you all
[00:31:12.680 --> 00:31:15.400]   of the notebooks for the course.
[00:31:15.400 --> 00:31:21.120]   What I want you to do is scroll to the bottom and find the one called AppJupiter and click
[00:31:21.120 --> 00:31:28.200]   on that and this is where you can start learning about Jupyter Notebook.
[00:31:28.200 --> 00:31:30.000]   What is Jupyter Notebook?
[00:31:30.000 --> 00:31:39.680]   Jupyter Notebook is something where you can start typing things and press Shift Enter and
[00:31:39.680 --> 00:31:45.020]   it will give you an answer and so the thing you're typing is Python code and the thing
[00:31:45.020 --> 00:31:52.680]   that comes out is the result of that code and so you can put in anything in Python x
[00:31:52.680 --> 00:32:03.080]   equals 3 times 4 x plus 1 and as you can see it displays the result anytime there's a result
[00:32:03.080 --> 00:32:05.200]   to display.
[00:32:05.200 --> 00:32:10.560]   So for those of you that have done a bit of coding before you will recognize this as a
[00:32:10.560 --> 00:32:16.340]   REPL, R-E-P-L, read, evaluate, print, look.
[00:32:16.340 --> 00:32:18.960]   Most languages have some kind of REPL.
[00:32:18.960 --> 00:32:28.960]   The Jupyter Notebook REPL is particularly interesting because it has things like headings,
[00:32:28.960 --> 00:32:37.640]   graphical outputs, interactive multimedia, it's a really astonishing piece of software.
[00:32:37.640 --> 00:32:44.720]   It's won some really big awards, you know I would have thought the most widely used
[00:32:44.720 --> 00:32:48.920]   REPL outside of shells like bash.
[00:32:48.920 --> 00:32:53.460]   It's a very powerful system, we love it, we've written our whole book in it, we've written
[00:32:53.460 --> 00:32:58.960]   the entire fastai library with it, we do all our teaching with it.
[00:32:58.960 --> 00:33:06.760]   It's extremely unfamiliar to people who have done most of their work in IDE.
[00:33:06.760 --> 00:33:11.040]   You should expect it to feel as awkward as perhaps the first time you moved from a GUI
[00:33:11.040 --> 00:33:13.440]   to a command line.
[00:33:13.440 --> 00:33:17.440]   It's different, right, so if you're not familiar with kind of REPL based systems it's going
[00:33:17.440 --> 00:33:25.560]   to feel super weird, but stick with it because it really is great.
[00:33:25.560 --> 00:33:32.540]   The model going on here is that this web page I'm looking at is letting me type in things
[00:33:32.540 --> 00:33:37.440]   for a server to do and show me the results of computations the server is doing.
[00:33:37.440 --> 00:33:42.160]   So the server is off somewhere else, it's not running on my computer, right?
[00:33:42.160 --> 00:33:45.800]   The only thing running on the computer is this web page.
[00:33:45.800 --> 00:33:56.360]   But as I do things, so for example if I say x=x*3, this is updating the server's state.
[00:33:56.360 --> 00:34:02.120]   There's this state, it's like what's currently the value of x, and so I can find out now x
[00:34:02.120 --> 00:34:03.120]   is something different.
[00:34:03.120 --> 00:34:09.640]   So you can see when I did this line here it didn't change the earlier x+1, right?
[00:34:09.640 --> 00:34:14.080]   So that means that when you look at a Jupyter notebook, it's not showing you the current
[00:34:14.080 --> 00:34:20.440]   state of your server, it's just showing you what that state was at the time that you printed
[00:34:20.440 --> 00:34:21.440]   that thing out.
[00:34:21.440 --> 00:34:28.600]   It's just like if you use a shell like bash, and you type ls, and then you delete a file,
[00:34:28.600 --> 00:34:31.960]   that earlier ls you printed doesn't go back and change, right?
[00:34:31.960 --> 00:34:39.520]   That's kind of how REPLs generally work, including this one.
[00:34:39.520 --> 00:34:43.240]   Jupyter notebook has two modes.
[00:34:43.240 --> 00:34:48.680]   One is edit mode, which is when I click in a cell, and I get a flashing cursor, and I
[00:34:48.680 --> 00:34:53.360]   can move left and right and type, right?
[00:34:53.360 --> 00:34:55.700]   There's not very many keyboard shortcuts in this mode.
[00:34:55.700 --> 00:35:01.680]   One useful one is control or command slash, which will comment and uncomment.
[00:35:01.680 --> 00:35:07.460]   The main one to know is shift enter to actually run the cell.
[00:35:07.460 --> 00:35:11.920]   At that point, there's no flashing cursor anymore, and that means that I'm now in command
[00:35:11.920 --> 00:35:13.600]   mode, not edit mode.
[00:35:13.600 --> 00:35:17.420]   So as I go up and down, I'm selecting different cells.
[00:35:17.420 --> 00:35:24.700]   So in command mode, as we move around, we're now selecting cells, and there are now lots
[00:35:24.700 --> 00:35:26.800]   of keyboard shortcuts you can use.
[00:35:26.800 --> 00:35:33.200]   So if you hit H, you can get a list of them for example, and you'll see that they're not
[00:35:33.200 --> 00:35:37.920]   on the whole like control or command with something, they're just a letter on its own.
[00:35:37.920 --> 00:35:41.760]   So if you use like vim, you'll be more familiar with this idea.
[00:35:41.760 --> 00:35:48.840]   So for example, if I hit C to copy, and V to paste, then it copies the cell, or X to
[00:35:48.840 --> 00:35:58.120]   cut it, A to add a new cell above, and then I can press the various number keys to create
[00:35:58.120 --> 00:35:59.120]   a heading.
[00:35:59.120 --> 00:36:01.840]   So number two will create a heading level two.
[00:36:01.840 --> 00:36:08.360]   And as you can see, I can actually type formatted text, not just code.
[00:36:08.360 --> 00:36:20.120]   The formatted text I type is in Markdown, like so.
[00:36:20.120 --> 00:36:27.840]   And my numbered one work, there you go.
[00:36:27.840 --> 00:36:28.840]   So that's in Markdown.
[00:36:28.840 --> 00:36:34.920]   If you haven't used Markdown before, it's a super, super useful way to write formatted
[00:36:34.920 --> 00:36:38.320]   text that is used very, very, very widely.
[00:36:38.320 --> 00:36:46.460]   So learn it because it's super handy, and you need it for Jupiter.
[00:36:46.460 --> 00:36:55.560]   So when you look at our book notebooks, for example, you can see an example of all the
[00:36:55.560 --> 00:36:58.800]   kinds of formatting and code and stuff here.
[00:36:58.800 --> 00:37:05.200]   So you should go ahead and yeah, go through the app Jupiter.
[00:37:05.200 --> 00:37:10.760]   And you can see here how you can create plots, for example, and create lists of things and
[00:37:10.760 --> 00:37:18.440]   import libraries and display pictures and so forth.
[00:37:18.440 --> 00:37:26.000]   If you want to create a new notebook, you can just go new Python 3, and that creates
[00:37:26.000 --> 00:37:35.040]   a new notebook, which by default is just called untitled, so you can then rename it to give
[00:37:35.040 --> 00:37:38.440]   it whatever name you like.
[00:37:38.440 --> 00:37:45.440]   And so then you'll now see that in the list here, new name.
[00:37:45.440 --> 00:37:50.360]   The other thing to know about Jupiter is that it's a nice, easy way to jump into a terminal.
[00:37:50.360 --> 00:37:54.100]   If you know how to use a terminal, you certainly don't have to for this course, at least for
[00:37:54.100 --> 00:37:55.100]   the first bit.
[00:37:55.100 --> 00:38:08.240]   If I go new terminal, you can see here I have a terminal.
[00:38:08.240 --> 00:38:19.120]   One thing to note is for the notebooks are attached to a GitHub repository.
[00:38:19.120 --> 00:38:21.920]   If you haven't used GitHub before, that's fine.
[00:38:21.920 --> 00:38:27.240]   But basically they're attached to a server where from time to time we will update the
[00:38:27.240 --> 00:38:29.440]   notebooks on that server.
[00:38:29.440 --> 00:38:33.600]   And you'll see on the course website in the forum, we tell you how to make sure you have
[00:38:33.600 --> 00:38:35.840]   the most recent versions.
[00:38:35.840 --> 00:38:40.040]   When you grab our most recent version, you don't want it to conflict with or overwrite
[00:38:40.040 --> 00:38:41.560]   your changes.
[00:38:41.560 --> 00:38:50.280]   So as you start experimenting, it's not a bad idea to select a notebook and click duplicate
[00:38:50.280 --> 00:38:52.460]   and then start doing your work in the copy.
[00:38:52.460 --> 00:38:57.960]   And that way when you get an update of our latest course materials, it's not going to
[00:38:57.960 --> 00:39:06.120]   interfere with the experiments that you've been running.
[00:39:06.120 --> 00:39:09.440]   So there's two important repositories to know about.
[00:39:09.440 --> 00:39:20.060]   One is the fastbook repository, which we saw earlier, which is kind of the full book with
[00:39:20.060 --> 00:39:26.060]   all the outputs and pros and everything.
[00:39:26.060 --> 00:39:30.340]   And then the other one is the course v4 repository.
[00:39:30.340 --> 00:39:34.660]   And here is the exact same notebook from the course v4 repository.
[00:39:34.660 --> 00:39:42.080]   And for this one, we remove all of the pros and all of the pictures and all of the outputs
[00:39:42.080 --> 00:39:46.640]   and just leave behind the headings and the code.
[00:39:46.640 --> 00:39:49.200]   In this case, you can see some outputs because I just ran that code.
[00:39:49.200 --> 00:39:56.280]   But for most of it, there won't be any, oh no, I guess we have left the outputs.
[00:39:56.280 --> 00:39:58.000]   I'm not sure if we'll keep that or not.
[00:39:58.000 --> 00:40:01.840]   So you may or may not see the outputs.
[00:40:01.840 --> 00:40:08.920]   So the idea with this is, this is probably the version that you want to be experimenting
[00:40:08.920 --> 00:40:14.400]   with because it kind of forces you to think about like what's going on as you do each
[00:40:14.400 --> 00:40:18.840]   step, you know, rather than just reading it and running it without thinking.
[00:40:18.840 --> 00:40:23.340]   They kind of want you to do it in this more bare environment in which you're thinking
[00:40:23.340 --> 00:40:25.680]   about like, oh, what did the book say?
[00:40:25.680 --> 00:40:27.600]   Why was this happening?
[00:40:27.600 --> 00:40:31.320]   And if you forget, then you can kind of go back to the book.
[00:40:31.320 --> 00:40:36.920]   The other thing to mention is both the course v4 version and the fastbook version at the
[00:40:36.920 --> 00:40:42.000]   end have a questionnaire.
[00:40:42.000 --> 00:40:46.520]   And quite a few folks have told us that, you know, amongst the reviewers and stuff that
[00:40:46.520 --> 00:40:49.960]   they actually read the questionnaire first.
[00:40:49.960 --> 00:40:57.840]   We spent many, many weeks writing the questionnaires, Sylvain and I.
[00:40:57.840 --> 00:41:04.360]   And the reason for that is because we tried to think about like, what do we want you to
[00:41:04.360 --> 00:41:07.640]   take away from each notebook?
[00:41:07.640 --> 00:41:11.760]   So if you kind of read the questionnaire first, you can find out what are the things we think
[00:41:11.760 --> 00:41:12.760]   are important.
[00:41:12.760 --> 00:41:14.880]   What are the things that you should know before you move on?
[00:41:14.880 --> 00:41:18.640]   So rather than having like a summary section at the end saying at the end of this, you
[00:41:18.640 --> 00:41:23.720]   should know, blah, blah, blah, we instead have a questionnaire to do the same thing.
[00:41:23.720 --> 00:41:27.680]   So please make sure you do the questionnaire before you move on to the next chapter.
[00:41:27.680 --> 00:41:29.780]   You don't have to get everything right.
[00:41:29.780 --> 00:41:33.280]   And most of the time answering the questions is as simple as going back to that part of
[00:41:33.280 --> 00:41:37.640]   the notebook and reading the prose.
[00:41:37.640 --> 00:41:42.360]   But if you've missed something, like do go back and read it because we're assuming these
[00:41:42.360 --> 00:41:44.940]   are the things we're assuming you know.
[00:41:44.940 --> 00:41:50.400]   So if you don't know these things before you move on, it could get frustrating.
[00:41:50.400 --> 00:41:56.520]   Having said that, if you get stuck after trying a couple of times, do move on to the next
[00:41:56.520 --> 00:41:58.080]   chapter.
[00:41:58.080 --> 00:42:00.960]   Do two or three more chapters and then come back.
[00:42:00.960 --> 00:42:04.680]   Maybe by the time you've done a couple more chapters, you know, you'll get some more perspective.
[00:42:04.680 --> 00:42:10.620]   We try to re-explain things multiple times in different ways.
[00:42:10.620 --> 00:42:17.160]   So yeah, it's okay if you've tried and you get stuck, then you can try moving on.
[00:42:17.160 --> 00:42:26.460]   All right, so let's try running the first part of the notebook.
[00:42:26.460 --> 00:42:31.720]   So here we are in 01 intro.
[00:42:31.720 --> 00:42:38.280]   So this is chapter one and here is our first cell.
[00:42:38.280 --> 00:42:45.360]   So I click on the cell and by default actually there will be a header and a toolbar.
[00:42:45.360 --> 00:42:46.760]   As you can see, you can turn the one on and off.
[00:42:46.760 --> 00:42:48.720]   I always leave them off myself.
[00:42:48.720 --> 00:42:55.080]   And so to run this cell, you can either click on the play, you know, the run button, or as
[00:42:55.080 --> 00:42:57.080]   I mentioned, you can hit shift enter.
[00:42:57.080 --> 00:43:00.820]   So for this one I'll just click.
[00:43:00.820 --> 00:43:05.280]   And as you can see, this star appears, so this says I'm running and now you can see a progress
[00:43:05.280 --> 00:43:09.760]   bar popping up. That's going to take a few seconds.
[00:43:09.760 --> 00:43:15.640]   And so as it runs, it's going to print out some results.
[00:43:15.640 --> 00:43:18.960]   Don't expect to get exactly the same results as us.
[00:43:18.960 --> 00:43:23.760]   There's some randomness involved in training a model and that's okay.
[00:43:23.760 --> 00:43:26.520]   Don't expect to get exactly the same time as us.
[00:43:26.520 --> 00:43:32.400]   If this first cell takes more than five minutes, unless you have a really old GPU, that's probably
[00:43:32.400 --> 00:43:33.400]   a bad sign.
[00:43:33.400 --> 00:43:38.360]   You want to hop on the forums and figure out what's going wrong, or maybe you're trying
[00:43:38.360 --> 00:43:43.360]   to use Windows, which really doesn't work very well for this at the moment.
[00:43:43.360 --> 00:43:45.340]   Don't worry that we don't know what all the code does yet.
[00:43:45.340 --> 00:43:50.320]   We're just making sure that we can train a model.
[00:43:50.320 --> 00:43:51.320]   So here we are.
[00:43:51.320 --> 00:43:52.400]   It's finished running.
[00:43:52.400 --> 00:43:58.040]   And so as you can see, it's printed out some information and in this case, it's showing
[00:43:58.040 --> 00:44:05.240]   me that there's an error rate of 0.005 at doing something.
[00:44:05.240 --> 00:44:06.480]   What is the something it's doing?
[00:44:06.480 --> 00:44:11.860]   Well, what it's doing here is it's actually grabbing a dataset.
[00:44:11.860 --> 00:44:18.800]   We call the pets dataset, which is a dataset of pictures of cats and dogs.
[00:44:18.800 --> 00:44:26.200]   And it's trying to figure out which ones are cats and which ones are dogs.
[00:44:26.200 --> 00:44:32.360]   And as you can see, after about well less than a minute, it's able to do that with a
[00:44:32.360 --> 00:44:34.760]   0.5% error rate.
[00:44:34.760 --> 00:44:37.560]   So it can do it pretty much perfectly.
[00:44:37.560 --> 00:44:39.480]   So we've trained our first model.
[00:44:39.480 --> 00:44:44.520]   We have no idea how, we don't know what we were doing, but we have indeed trained a model.
[00:44:44.520 --> 00:44:46.520]   So that's a good start.
[00:44:46.520 --> 00:44:52.980]   And as you can see, we can train models pretty quickly on a single computer, many of which
[00:44:52.980 --> 00:44:56.480]   you can get for free.
[00:44:56.480 --> 00:45:00.840]   One more thing to mention is if you have a Mac, it doesn't matter whether you have Windows
[00:45:00.840 --> 00:45:05.040]   or Mac or Linux in terms of what's running in the browser.
[00:45:05.040 --> 00:45:11.440]   But if you have a Mac, please don't try to use that GPU.
[00:45:11.440 --> 00:45:16.120]   Macs actually, Apple doesn't even support Nvidia GPUs anymore.
[00:45:16.120 --> 00:45:19.440]   So that's really not going to be a great option.
[00:45:19.440 --> 00:45:20.840]   So stick with Linux.
[00:45:20.840 --> 00:45:24.760]   It'll make life much easier for you.
[00:45:24.760 --> 00:45:30.360]   Well, actually, the first thing we should do is actually try it out.
[00:45:30.360 --> 00:45:34.700]   So I claim we've trained a model that can pick cats from dogs.
[00:45:34.700 --> 00:45:37.700]   Let's make sure we can.
[00:45:37.700 --> 00:45:41.880]   So let's check out this cell.
[00:45:41.880 --> 00:45:43.160]   This is interesting, right?
[00:45:43.160 --> 00:45:48.120]   We've created a widgets.file_upload object and displayed it.
[00:45:48.120 --> 00:45:50.640]   And this is actually showing us a clickable button.
[00:45:50.640 --> 00:45:52.580]   So as I mentioned, this is an unusual REPL.
[00:45:52.580 --> 00:45:55.280]   We can even create GUIs in this REPL.
[00:45:55.280 --> 00:46:04.080]   So if I click on this file upload, and I can pick cat, there we go.
[00:46:04.080 --> 00:46:12.920]   And I can now turn that uploaded data into an image.
[00:46:12.920 --> 00:46:26.360]   It's a cat, and now I can do predict, and it's a cat with a 99.96% probability.
[00:46:26.360 --> 00:46:29.860]   So we can see we have just uploaded an image that we've picked out.
[00:46:29.860 --> 00:46:31.480]   So you should try this, right?
[00:46:31.480 --> 00:46:34.720]   Grab a picture of a cat, find one from the internet, or go and take a picture of one
[00:46:34.720 --> 00:46:39.000]   yourself and make sure that you get a picture of a cat.
[00:46:39.000 --> 00:46:43.620]   This is something which can recognize photos of cats, not line drawings of cats.
[00:46:43.620 --> 00:46:50.160]   And so as we'll see in this course, these kinds of models could only learn from the
[00:46:50.160 --> 00:46:52.000]   kinds of information you give it.
[00:46:52.000 --> 00:46:59.040]   And so far we've only given it, as you'll discover, photos of cats, not anime cats,
[00:46:59.040 --> 00:47:06.680]   not drawn cats, not abstract representations of cats, but just photos.
[00:47:06.680 --> 00:47:11.440]   So we're now going to look at what's actually happened here.
[00:47:11.440 --> 00:47:15.900]   And you'll see at the moment, I'm not getting some great information here.
[00:47:15.900 --> 00:47:26.240]   If you see this in your notebooks, you have to go file, trust notebook.
[00:47:26.240 --> 00:47:30.520]   And that just tells Jupyter that it's allowed to run the code necessary to display things
[00:47:30.520 --> 00:47:33.480]   to make sure that there isn't any security problems.
[00:47:33.480 --> 00:47:35.840]   And so you'll now see the outputs.
[00:47:35.840 --> 00:47:39.840]   Sometimes you'll actually see some weird code like this.
[00:47:39.840 --> 00:47:43.840]   This is code that actually creates outputs.
[00:47:43.840 --> 00:47:46.920]   So sometimes we hide that code.
[00:47:46.920 --> 00:47:47.920]   Sometimes we show it.
[00:47:47.920 --> 00:47:51.900]   So generally speaking, you can just ignore the stuff like that and focus on what comes
[00:47:51.900 --> 00:47:52.900]   out.
[00:47:52.900 --> 00:47:54.280]   So I'm not going to go through these.
[00:47:54.280 --> 00:48:00.620]   Instead I'm going to have a look at it, the same thing over here on the slides.
[00:48:00.620 --> 00:48:05.160]   So what we're doing here is we're doing machine learning.
[00:48:05.160 --> 00:48:07.720]   Machine learning is a kind of machine learning.
[00:48:07.720 --> 00:48:09.120]   What is machine learning?
[00:48:09.120 --> 00:48:12.160]   Machine learning is just like regular programming.
[00:48:12.160 --> 00:48:16.020]   It's a way to get computers to do something.
[00:48:16.020 --> 00:48:21.340]   But in this case, like it's pretty hard to understand how you would use regular programming
[00:48:21.340 --> 00:48:23.960]   to recognize dog photos from cat photos.
[00:48:23.960 --> 00:48:28.280]   How do you kind of create the loops and the variable assignments and the conditionals
[00:48:28.280 --> 00:48:32.280]   to create a program that recognizes dogs versus cats in photos?
[00:48:32.280 --> 00:48:34.500]   It's super hard, super, super hard.
[00:48:34.500 --> 00:48:41.380]   So hard that until kind of the deep learning era, nobody really had a model that was remotely
[00:48:41.380 --> 00:48:43.840]   accurate at this apparently easy task.
[00:48:43.840 --> 00:48:46.920]   Because we can't write down the steps necessary.
[00:48:46.920 --> 00:48:51.720]   So normally we write down a function that takes some imports and goes through our program
[00:48:51.720 --> 00:48:55.640]   and gives us some results.
[00:48:55.640 --> 00:49:02.500]   So this general idea where the program is something that we write the steps doesn't
[00:49:02.500 --> 00:49:07.020]   seem to work great for things like recognizing pictures.
[00:49:07.020 --> 00:49:12.440]   So back in 1949, somebody named Arthur Samuel started trying to figure out a way to solve
[00:49:12.440 --> 00:49:16.280]   problems like recognizing pictures of cats and dogs.
[00:49:16.280 --> 00:49:21.720]   And in 1962, he described a way of doing this.
[00:49:21.720 --> 00:49:24.880]   Well, first of all, he described the problem.
[00:49:24.880 --> 00:49:31.300]   Programming a computer for these kinds of computations is at best a difficult task.
[00:49:31.300 --> 00:49:37.560]   Because of the need to spell at every minute step of the process in exasperating detail.
[00:49:37.560 --> 00:49:42.320]   Computers are giant morons, which all of us coders totally recognize.
[00:49:42.320 --> 00:49:46.720]   So he said, okay, let's not tell the computer the exact steps, but let's give it examples
[00:49:46.720 --> 00:49:50.560]   of a problem to solve and figure out how to solve it itself.
[00:49:50.560 --> 00:49:56.220]   And so by 1961, he had built a checkers program that had beaten the Connecticut state champion,
[00:49:56.220 --> 00:50:03.280]   not by telling it the steps to take to play checkers, but instead by doing this, which
[00:50:03.280 --> 00:50:09.960]   is a range for an automatic means of testing the effectiveness of a weight assignment in
[00:50:09.960 --> 00:50:15.640]   terms of actual performance and a mechanism for altering the weight assignment so as to
[00:50:15.640 --> 00:50:18.980]   maximize performance.
[00:50:18.980 --> 00:50:21.640]   This sentence is the key thing.
[00:50:21.640 --> 00:50:24.400]   And it's a pretty tricky sentence, so we can spend some time on it.
[00:50:24.400 --> 00:50:32.160]   The basic idea is this, instead of saying inputs to a program and then outputs, let's
[00:50:32.160 --> 00:50:38.100]   have inputs to a, let's call the program now model, but it's the same basic idea, inputs
[00:50:38.100 --> 00:50:40.300]   to a model and results.
[00:50:40.300 --> 00:50:43.720]   And then we're going to have a second thing called weights.
[00:50:43.720 --> 00:50:50.160]   And so the basic idea is that this model is something that creates outputs based not only
[00:50:50.160 --> 00:50:58.400]   on, for example, the state of a checkers board, but also based on some set of weights or parameters
[00:50:58.400 --> 00:51:02.280]   that describe how that model is going to work.
[00:51:02.280 --> 00:51:09.000]   So the idea is if we could like enumerate all the possible ways of playing checkers
[00:51:09.000 --> 00:51:13.440]   and then kind of describe each of those ways using some set of parameters or what other
[00:51:13.440 --> 00:51:20.280]   the Samuel Porter weights, then if we had a way of checking how effective a current weight
[00:51:20.280 --> 00:51:26.320]   assignment is in terms of actual performance, in other words, does that particular enumeration
[00:51:26.320 --> 00:51:31.400]   of a strategy for playing checkers end up winning or losing games, right?
[00:51:31.400 --> 00:51:35.560]   And then a way to alter the weight assignment so as to maximize the performance.
[00:51:35.560 --> 00:51:40.680]   So then, oh, let's try increasing or decreasing each one of those weights one at a time to
[00:51:40.680 --> 00:51:45.140]   find out if there's a slightly better way of playing checkers and then do that lots
[00:51:45.140 --> 00:51:51.740]   of lots of times, then eventually such a procedure could be made entirely automatic.
[00:51:51.740 --> 00:51:55.900]   And then the machine so programmed wouldn't learn from its experience.
[00:51:55.900 --> 00:52:00.160]   So this little paragraph is, it's the thing.
[00:52:00.160 --> 00:52:01.800]   This is machine one, right?
[00:52:01.800 --> 00:52:11.400]   A way of creating programs such that they learn rather than they're programmed.
[00:52:11.400 --> 00:52:16.800]   So if we had such a thing, then we would basically now have something that looks like this.
[00:52:16.800 --> 00:52:22.640]   You have inputs and weights again, going into a model, creating results, i.e. you won or
[00:52:22.640 --> 00:52:26.720]   you're lost and then a measurement of performance.
[00:52:26.720 --> 00:52:30.320]   So remember that was this key step and then the second key step is a way to update the
[00:52:30.320 --> 00:52:32.960]   weights based on the measure of performance.
[00:52:32.960 --> 00:52:40.100]   And then you could loop through this process and create a train a machine learning model.
[00:52:40.100 --> 00:52:43.480]   So this is the abstract idea.
[00:52:43.480 --> 00:52:47.240]   So after we've run that for a while, right?
[00:52:47.240 --> 00:52:50.780]   It's come up with a set of weights that's pretty good, right?
[00:52:50.780 --> 00:52:58.880]   We can now forget the way it was trained and we have something that's just like this, right?
[00:52:58.880 --> 00:53:02.400]   The word program is now replaced with the word model.
[00:53:02.400 --> 00:53:07.200]   So a trained model can be used just like any other computer program.
[00:53:07.200 --> 00:53:13.760]   So the idea is we're building a computer program not by putting out the steps necessary to
[00:53:13.760 --> 00:53:19.560]   do the task, but by training it to learn to do the task at the end of which it's just
[00:53:19.560 --> 00:53:21.280]   another program.
[00:53:21.280 --> 00:53:24.560]   And so this is what's called inference, right?
[00:53:24.560 --> 00:53:33.320]   It's using a trained model as a program to do a task such as playing checkers.
[00:53:33.320 --> 00:53:40.840]   So machine learning is training programs developed by allowing a computer to learn from its experience
[00:53:40.840 --> 00:53:44.120]   rather than through manually coding.
[00:53:44.120 --> 00:53:50.080]   Okay, how would you do this for image recognition?
[00:53:50.080 --> 00:53:56.720]   What is that model and that set of weights such that as we vary them, it could get better
[00:53:56.720 --> 00:54:00.480]   and better at recognizing cats versus dogs.
[00:54:00.480 --> 00:54:05.920]   I mean, for checkers, it's not too hard to imagine how you could kind of enumerate like
[00:54:05.920 --> 00:54:10.560]   depending on different kinds of how far away the opponent's piece is from your piece, what
[00:54:10.560 --> 00:54:12.200]   should you do in that situation?
[00:54:12.200 --> 00:54:16.800]   How should you weight defensive versus aggressive strategies, blah, blah, blah.
[00:54:16.800 --> 00:54:20.440]   Not at all obvious how you would do that for image recognition.
[00:54:20.440 --> 00:54:29.200]   So what we really want is some function in here which is so flexible that there's a set
[00:54:29.200 --> 00:54:37.640]   of weights that could cause it to do anything, like the world's most flexible possible function.
[00:54:37.640 --> 00:54:41.960]   And it turns out that there is such a thing.
[00:54:41.960 --> 00:54:44.240]   It's a neural network.
[00:54:44.240 --> 00:54:52.080]   So we'll be describing exactly what that mathematical function is in the coming lessons.
[00:54:52.080 --> 00:54:56.120]   To use it, it actually doesn't really matter what the mathematical function is.
[00:54:56.120 --> 00:55:04.520]   It's a function which is we say parameterized by some set of weights by which I mean as
[00:55:04.520 --> 00:55:12.200]   I give it a different set of weights, it does a different task and it can actually do any
[00:55:12.200 --> 00:55:13.600]   possible task.
[00:55:13.600 --> 00:55:18.880]   Something called the Universal Approximation Theorem tells us that mathematically provable,
[00:55:18.880 --> 00:55:26.160]   provably, this functional form can solve any problem that is solvable to any level of accuracy
[00:55:26.160 --> 00:55:30.960]   if you just find the right set of weights, which is kind of restating what we described
[00:55:30.960 --> 00:55:36.240]   earlier in that like, oh, how do we deal with the Minsky, the Marvin Minsky problem?
[00:55:36.240 --> 00:55:41.280]   So neural networks are so flexible that if you could find the right set of weights, they
[00:55:41.280 --> 00:55:46.360]   can solve any problem, including is this a cat or is it a dog?
[00:55:46.360 --> 00:55:51.680]   So that means you need to focus your effort on the process of training them, that is finding
[00:55:51.680 --> 00:55:57.080]   good weights, good weight assignments to use after Samuel's terminology.
[00:55:57.080 --> 00:55:59.760]   So how do you do that?
[00:55:59.760 --> 00:56:08.600]   We want a completely general way to do this, to update the weights based on some measure
[00:56:08.600 --> 00:56:14.160]   of performance, such as how good is it at recognizing cats versus dogs?
[00:56:14.160 --> 00:56:19.680]   And luckily it turns out such a thing exists, and that thing is called Stochastic Gradient
[00:56:19.680 --> 00:56:21.280]   Reset or SGD.
[00:56:21.280 --> 00:56:26.080]   Again, we'll look at exactly how it works, we'll build it from ourselves and scratch,
[00:56:26.080 --> 00:56:28.320]   but for now we don't have to worry about it.
[00:56:28.320 --> 00:56:35.360]   I will tell you this though, neither SGD nor neural nets are at all mathematically complex,
[00:56:35.360 --> 00:56:39.600]   they nearly entirely are addition and multiplication.
[00:56:39.600 --> 00:56:44.640]   The trick is it just does a lot of them, like billions of them, so many more than we can
[00:56:44.640 --> 00:56:51.800]   like intuitively grasp, but they can do extraordinarily powerful things, but they're not rocket
[00:56:51.800 --> 00:56:58.600]   science at all, they're not complex things, then we'll see exactly how they work.
[00:56:58.600 --> 00:57:05.200]   So that's the Arthur Samuel version, nowadays we don't use quite the same terminology.
[00:57:05.200 --> 00:57:08.600]   But we use exactly the same idea.
[00:57:08.600 --> 00:57:14.480]   So that function that sits in the middle, we call an architecture.
[00:57:14.480 --> 00:57:20.160]   An architecture is the function that we're adjusting the weights to get it to do something,
[00:57:20.160 --> 00:57:24.120]   so that's the architecture, that's the functional form of the model.
[00:57:24.120 --> 00:57:28.960]   Sometimes people say model to mean architecture, so don't let that confuse you too much, but
[00:57:28.960 --> 00:57:31.480]   really the right word is architecture.
[00:57:31.480 --> 00:57:34.560]   We don't call them weights, we call them parameters.
[00:57:34.560 --> 00:57:40.360]   That has a specific meaning, it's quite a particular kind of parameter.
[00:57:40.360 --> 00:57:46.520]   The things that come out of the model, the architecture with the parameters, we call
[00:57:46.520 --> 00:57:49.720]   them predictions.
[00:57:49.720 --> 00:57:55.040]   And the predictions are based on two kinds of inputs, independent variables, that's the
[00:57:55.040 --> 00:58:01.360]   data, like the pictures of the cats and the dogs, and dependent variables, also known
[00:58:01.360 --> 00:58:08.160]   as labels, which is like the thing saying, this is a cat, this is a dog, this is a cat.
[00:58:08.160 --> 00:58:10.640]   So that's your inputs.
[00:58:10.640 --> 00:58:12.920]   So the results are predictions.
[00:58:12.920 --> 00:58:19.400]   The measure of performance, to use Arthur Samuel's word, is known as the loss, so the
[00:58:19.400 --> 00:58:23.640]   loss has been calculated from the labels and the predictions.
[00:58:23.640 --> 00:58:28.640]   And then there's the update back to the parameters.
[00:58:28.640 --> 00:58:35.040]   So this is the same picture as we saw, but just putting in the words that we use today.
[00:58:35.040 --> 00:58:39.880]   So this picture, if you forget, if I say these are the parameters of this, you know, used
[00:58:39.880 --> 00:58:43.800]   for this architecture to create a model, you can go back and remind yourself, what did
[00:58:43.800 --> 00:58:44.800]   I mean?
[00:58:44.800 --> 00:58:45.800]   What are the parameters?
[00:58:45.800 --> 00:58:46.800]   What are the predictions?
[00:58:46.800 --> 00:58:47.800]   What is the loss?
[00:58:47.800 --> 00:58:53.720]   Okay, the loss is some function that measures the performance of the model in such a way
[00:58:53.720 --> 00:58:57.960]   that we can update the parameters.
[00:58:57.960 --> 00:59:06.240]   So it's important to note that deep learning and machine learning are not magic, right?
[00:59:06.240 --> 00:59:13.400]   The model can only be created where you have data showing you examples of the thing that
[00:59:13.400 --> 00:59:15.440]   you're trying to learn about.
[00:59:15.440 --> 00:59:20.760]   It can only learn to operate on the patterns that you've seen in the input used to train
[00:59:20.760 --> 00:59:22.360]   it, right?
[00:59:22.360 --> 00:59:27.600]   So if we don't have any line drawings of cats and dogs, then there's never going to be an
[00:59:27.600 --> 00:59:33.000]   update to the parameters that makes the architecture, and so the architecture and the parameters
[00:59:33.000 --> 00:59:38.640]   together is the model, so to say the model, that makes the model better at predicting
[00:59:38.640 --> 00:59:42.680]   line drawings of cats and dogs because they just, they never received those weight updates
[00:59:42.680 --> 00:59:46.680]   because they'd never received those inputs.
[00:59:46.680 --> 00:59:51.240]   Notice also that this learning approach only ever creates predictions.
[00:59:51.240 --> 00:59:55.640]   It doesn't tell you what to do about it, and that's going to be very important when we
[00:59:55.640 --> 01:00:01.400]   think about things like a recommendation system of like, what product do we recommend to somebody?
[01:00:01.400 --> 01:00:04.960]   Well, I don't know, we don't do that, right?
[01:00:04.960 --> 01:00:09.480]   We can predict what somebody will say about a product after we've shown them, but we're
[01:00:09.480 --> 01:00:12.320]   not creating actions, we're creating predictions.
[01:00:12.320 --> 01:00:17.680]   That's a super important difference to recognize.
[01:00:17.680 --> 01:00:22.920]   It's not enough just to have examples of input data like pictures of dogs and cats.
[01:00:22.920 --> 01:00:29.360]   We can't do anything without labels, and so very often organizations say we don't have
[01:00:29.360 --> 01:00:31.360]   enough data.
[01:00:31.360 --> 01:00:36.200]   Most of the time they mean we don't have enough labeled data because if a company is trying
[01:00:36.200 --> 01:00:40.740]   to do something with deep learning, often it's because they're trying to automate or
[01:00:40.740 --> 01:00:46.480]   improve something they're already doing, which means by definition they have data about that
[01:00:46.480 --> 01:00:51.440]   thing or a way to capture data about that thing because they're doing it, right?
[01:00:51.440 --> 01:00:55.080]   But often the tricky part is labeling it.
[01:00:55.080 --> 01:01:01.240]   So for example, in medicine, if you're trying to build a model for radiology, you can almost
[01:01:01.240 --> 01:01:07.120]   certainly get lots of medical images about just about anything you can think of, but
[01:01:07.120 --> 01:01:12.100]   it might be very hard to label them according to malignancy of a tumor or according to whether
[01:01:12.100 --> 01:01:18.520]   or not meningioma is present or whatever because these kinds of labels are not necessarily
[01:01:18.520 --> 01:01:24.680]   captured in a structured way, at least in the US medical system.
[01:01:24.680 --> 01:01:31.800]   So that's an important distinction that really impacts your kind of strategy here.
[01:01:31.800 --> 01:01:41.960]   So then a model, as we saw from the PDP book, a model operates in an environment, right?
[01:01:41.960 --> 01:01:44.380]   You roll it out and you do something with it.
[01:01:44.380 --> 01:01:50.360]   And so then this piece of that kind of PDP framework is super important, right?
[01:01:50.360 --> 01:01:55.400]   You have a model that's actually doing something, for example, you've built a predictive policing
[01:01:55.400 --> 01:02:02.840]   model that predicts, doesn't recommend actions, it predicts where an arrest might be made.
[01:02:02.840 --> 01:02:07.140]   This is something a lot of jurisdictions in the US are using.
[01:02:07.140 --> 01:02:10.760]   Now it's predicting that based on data and based on labeled data.
[01:02:10.760 --> 01:02:16.280]   And in this case, it's actually going to be using in the US, for example, data where I
[01:02:16.280 --> 01:02:24.560]   think depending on whether you're black or white, black people in the US, I think, get
[01:02:24.560 --> 01:02:31.120]   arrested something like seven times more often for say marijuana possession than whites,
[01:02:31.120 --> 01:02:37.320]   even though the actual underlying amount of marijuana use is about the same in the two
[01:02:37.320 --> 01:02:38.320]   populations.
[01:02:38.320 --> 01:02:43.040]   So you start with biased data and you build a predictive policing model, its prediction
[01:02:43.040 --> 01:02:50.360]   will say, oh, you will find somebody you can arrest here based on some biased data.
[01:02:50.360 --> 01:02:56.120]   So then law enforcement officers might decide to focus their police activity on the areas
[01:02:56.120 --> 01:03:00.320]   where those predictions are happening as a result of which they'll find more people to
[01:03:00.320 --> 01:03:01.900]   arrest.
[01:03:01.900 --> 01:03:06.440]   And then they'll use that to put it back into the model, which will now find, oh, there's
[01:03:06.440 --> 01:03:12.600]   even more people we should be arresting in the black neighborhoods and thus it continues.
[01:03:12.600 --> 01:03:17.200]   So this would be an example of modeling interacting with its environment to create something called
[01:03:17.200 --> 01:03:23.120]   a positive feedback loop, where the more a model is used, the more biased the data becomes,
[01:03:23.120 --> 01:03:26.520]   making the model even more biased and so forth.
[01:03:26.520 --> 01:03:33.120]   So one of the things to be super careful about with machine learning is recognizing how that
[01:03:33.120 --> 01:03:42.440]   model is actually being used and what kinds of things might happen as a result of that.
[01:03:42.440 --> 01:03:47.920]   I was just going to add that this is also an example of proxies because here arrest is
[01:03:47.920 --> 01:03:51.000]   being used as a proxy for crime.
[01:03:51.000 --> 01:03:57.200]   And I think that pretty much in all cases, the data that you actually have is a proxy
[01:03:57.200 --> 01:04:01.560]   for some value that you truly care about and that difference between the proxy and the
[01:04:01.560 --> 01:04:10.200]   actual value often ends up being significant.
[01:04:10.200 --> 01:04:13.480]   Thanks Rachel, that's a really important point.
[01:04:13.480 --> 01:04:24.280]   Okay, so let's finish off by looking at what's going on with this code.
[01:04:24.280 --> 01:04:34.980]   So the code we ran is basically one, two, three, four, five, six lines of code.
[01:04:34.980 --> 01:04:39.800]   So the first line of code is an import line.
[01:04:39.800 --> 01:04:47.400]   So in Python, you can't use an external library until you import from it.
[01:04:47.400 --> 01:04:55.000]   Only in Python, people import just the functions and classes that they need from a library.
[01:04:55.000 --> 01:05:01.880]   But Python does provide a convenient facility where you can import everything from a module
[01:05:01.880 --> 01:05:04.400]   which is by putting a star there.
[01:05:04.400 --> 01:05:10.560]   Most of the time, this is a bad idea because by default, the way Python works is that if
[01:05:10.560 --> 01:05:15.560]   you say import star, it doesn't only import the things that are interesting and important
[01:05:15.560 --> 01:05:20.320]   in the library you're trying to get something from, but it also imports things from all
[01:05:20.320 --> 01:05:24.480]   the libraries it used and all the libraries they used and you end up kind of exploding
[01:05:24.480 --> 01:05:29.760]   your namespace in horrible ways and causing all kinds of bugs.
[01:05:29.760 --> 01:05:36.400]   Because fast.ai is designed to be used in this REPL environment where you want to be
[01:05:36.400 --> 01:05:41.760]   able to do a lot of quick rapid prototyping, we actually spent a lot of time figuring out
[01:05:41.760 --> 01:05:45.520]   how to avoid that problem so that you can import star safely.
[01:05:45.520 --> 01:05:51.520]   So whether you do this or not is entirely up to you, but rest assured that if you import
[01:05:51.520 --> 01:05:57.720]   star from a fast.ai library, it's actually been explicitly designed in a way that you
[01:05:57.720 --> 01:06:01.960]   only get the bits that you actually need.
[01:06:01.960 --> 01:06:05.760]   One thing to mention is in the video, you see it's called fast.ai2.
[01:06:05.760 --> 01:06:09.920]   That's because we're recording this video using a pre-release version.
[01:06:09.920 --> 01:06:19.000]   By the time you're watching the online MOOC version of this, the two will be gone.
[01:06:19.000 --> 01:06:25.560]   Something else to mention is there are, as I speak, four main predefined applications
[01:06:25.560 --> 01:06:31.680]   in fast.ai, being vision, text, tabular and collaborative filtering, we'll be learning
[01:06:31.680 --> 01:06:35.120]   about all of them and a lot more.
[01:06:35.120 --> 01:06:41.840]   For each one, say here's vision, you can import from the .all kind of meta module, I guess
[01:06:41.840 --> 01:06:46.880]   we could call it, and that will give you all the stuff that you need for most common vision
[01:06:46.880 --> 01:06:48.720]   applications.
[01:06:48.720 --> 01:06:55.720]   So if you're using a REPL system like Jupyter Notebook, it's going to give you all the stuff
[01:06:55.720 --> 01:07:01.800]   right there that you need without having to go back and figure it out.
[01:07:01.800 --> 01:07:09.640]   One of the issues with this is a lot of Python users don't, if they look at something like
[01:07:09.640 --> 01:07:14.160]   untar data, they would figure out where it comes from by looking at the import line,
[01:07:14.160 --> 01:07:17.080]   and so if you import star, you can't do that anymore.
[01:07:17.080 --> 01:07:19.760]   But the good news is in a REPL you don't have to.
[01:07:19.760 --> 01:07:27.200]   You can literally just type the symbol, press shift enter, and it will tell you exactly
[01:07:27.200 --> 01:07:29.880]   where it came from, as you can see.
[01:07:29.880 --> 01:07:33.520]   So that's super handy.
[01:07:33.520 --> 01:07:40.840]   So in this case, for example, to do the actual building the dataset, we call image data loaders
[01:07:40.840 --> 01:07:43.720]   from namefunk.
[01:07:43.720 --> 01:07:51.120]   And I can actually call this special doc function to get the documentation for that.
[01:07:51.120 --> 01:07:57.280]   And as you can see, it tells me exactly everything to pass in, what all the defaults are, and
[01:07:57.280 --> 01:08:07.800]   most importantly, not only what it does, but show in docs pops me over to the full documentation,
[01:08:07.800 --> 01:08:11.160]   including an example.
[01:08:11.160 --> 01:08:17.160]   Everything in the fast.ai documentation has an example, and the cool thing is the entire
[01:08:17.160 --> 01:08:20.760]   documentation is written in Jupyter Notebooks.
[01:08:20.760 --> 01:08:25.520]   So that means you can actually open the Jupyter Notebook for this documentation and run the
[01:08:25.520 --> 01:08:33.240]   line of code yourself and see it actually working and look at the outputs and so forth.
[01:08:33.240 --> 01:08:36.320]   Also in the documentation, you will find there's a bunch of tutorials.
[01:08:36.320 --> 01:08:40.100]   So, for example, if you look at the vision tutorial, it'll cover lots of things.
[01:08:40.100 --> 01:08:44.360]   But one of the things it'll cover is, as you can see in this case, pretty much the same
[01:08:44.360 --> 01:08:47.680]   kind of stuff we're actually looking at in Lesson 1.
[01:08:47.680 --> 01:08:52.960]   So there's a lot of documentation in fast.ai and taking advantage of it is a very good
[01:08:52.960 --> 01:08:55.760]   idea and it is fully searchable.
[01:08:55.760 --> 01:09:00.520]   And as I mentioned, perhaps most importantly, that every one of these documentation pages
[01:09:00.520 --> 01:09:05.800]   is also a fully interactive Jupyter Notebook.
[01:09:05.800 --> 01:09:14.160]   So looking through more of this code, the first line after the import is something that uses
[01:09:14.160 --> 01:09:20.440]   untar data that will download a dataset, decompress it and put it on your computer.
[01:09:20.440 --> 01:09:22.840]   If it's already downloaded, it won't download it again.
[01:09:22.840 --> 01:09:25.680]   If it's already decompressed, it won't decompress it again.
[01:09:25.680 --> 01:09:32.400]   And as you can see, fast.ai already has predefined access to a number of really useful datasets
[01:09:32.400 --> 01:09:36.160]   such as this PETS dataset.
[01:09:36.160 --> 01:09:39.880]   Datasets are a super important part, as you can imagine, of deep learning.
[01:09:39.880 --> 01:09:46.200]   We'll be seeing lots of them and these are created by lots of heroes who basically spend
[01:09:46.200 --> 01:09:53.920]   months or years collating data that we can use to build these models.
[01:09:53.920 --> 01:10:00.200]   The next step is to tell fast.ai what this data is and we'll be learning a lot about
[01:10:00.200 --> 01:10:01.200]   that.
[01:10:01.200 --> 01:10:05.520]   But in this case, we're basically saying, okay, it contains images.
[01:10:05.520 --> 01:10:07.360]   It contains images that are in this path.
[01:10:07.360 --> 01:10:15.200]   So untar data returns the path that is whereabouts it's been decompressed to or if it's already
[01:10:15.200 --> 01:10:18.860]   decompressed, it tells us where it was previously decompressed to.
[01:10:18.860 --> 01:10:24.780]   We have to tell it things like, okay, what images are actually in that path.
[01:10:24.780 --> 01:10:27.140]   One of the really interesting ones is label function.
[01:10:27.140 --> 01:10:33.560]   How do you tell for each file, whether it's a cat or a dog?
[01:10:33.560 --> 01:10:37.280]   And if you actually look at the README for the original dataset, it uses a slightly quirky
[01:10:37.280 --> 01:10:43.720]   thing which is they said, oh, anything where the first letter of the file name is an uppercase
[01:10:43.720 --> 01:10:44.960]   is a cat.
[01:10:44.960 --> 01:10:46.400]   That's what they decided.
[01:10:46.400 --> 01:10:51.120]   So we just created a little function here called isCat that returns the first letter.
[01:10:51.120 --> 01:10:52.440]   Is it uppercase or not?
[01:10:52.440 --> 01:10:58.680]   And we tell fast.ai, that's how you tell if it's a cat.
[01:10:58.680 --> 01:11:01.220]   We'll come back to these two in a moment.
[01:11:01.220 --> 01:11:04.600]   So the next thing, so now we've told it what the data is.
[01:11:04.600 --> 01:11:06.480]   We then have to create something called a learner.
[01:11:06.480 --> 01:11:10.140]   A learner is the thing that learns, it does the training.
[01:11:10.140 --> 01:11:12.760]   So you have to tell it what data to use.
[01:11:12.760 --> 01:11:16.160]   Then you have to tell it what architecture to use.
[01:11:16.160 --> 01:11:22.240]   I'll be talking a lot about this in the course, but basically there's a lot of predefined
[01:11:22.240 --> 01:11:26.800]   neural network architectures that have certain pros and cons.
[01:11:26.800 --> 01:11:31.560]   And for computer vision, the architecture is called ResNet, just a super great starting
[01:11:31.560 --> 01:11:32.560]   point.
[01:11:32.560 --> 01:11:35.880]   And so we're just going to use a reasonably small one of them.
[01:11:35.880 --> 01:11:39.680]   So these are all predefined and set up for you.
[01:11:39.680 --> 01:11:43.480]   And then you can tell fast.ai what things you want to print out as it's training.
[01:11:43.480 --> 01:11:47.700]   In this case, it's saying, oh, tell us the error, please, as you train.
[01:11:47.700 --> 01:11:51.160]   So then we can call this really important method called fine tune that we'll be learning
[01:11:51.160 --> 01:11:56.880]   about in the next lesson, which actually does the training.
[01:11:56.880 --> 01:12:00.680]   Valid percent does something very important.
[01:12:00.680 --> 01:12:08.120]   It grabs, in this case, 20% of the data, 0.2 proportion, and does not use it for training
[01:12:08.120 --> 01:12:09.840]   a model.
[01:12:09.840 --> 01:12:12.760]   Instead it uses for telling you the error rate of the model.
[01:12:12.760 --> 01:12:19.480]   So always in fast.ai, this metric, the error rate, will always be calculated on a part
[01:12:19.480 --> 01:12:22.840]   of the data, which has not been trained with.
[01:12:22.840 --> 01:12:28.200]   And the idea here, and we'll talk a lot more about this in future lessons, but the basic
[01:12:28.200 --> 01:12:31.080]   idea here is we want to make sure that we're not overfitting.
[01:12:31.080 --> 01:12:33.520]   Let me explain.
[01:12:33.520 --> 01:12:35.080]   Overfitting looks like this.
[01:12:35.080 --> 01:12:38.880]   Let's say you're trying to create a function that fits all these dots, right?
[01:12:38.880 --> 01:12:44.040]   A nice function would look like that, right?
[01:12:44.040 --> 01:12:47.760]   But you could also fit, you could actually fit it much more precisely with this function.
[01:12:47.760 --> 01:12:51.480]   Look, this is going much closer to all the dots than this one is, right?
[01:12:51.480 --> 01:12:56.320]   So this is obviously a better function, except as soon as you get outside where the dots
[01:12:56.320 --> 01:13:01.960]   are, especially if you go off the edges, it obviously doesn't make any sense.
[01:13:01.960 --> 01:13:06.440]   So this is what you'd call an overfit function.
[01:13:06.440 --> 01:13:08.800]   So overfitting happens for all kinds of reasons.
[01:13:08.800 --> 01:13:13.120]   We use a model that's too big, or we use not enough data, we'll be, we'll be talking all
[01:13:13.120 --> 01:13:14.680]   about it, right?
[01:13:14.680 --> 01:13:22.360]   But really, the, the craft of deep learning is all about creating a model that has a proper
[01:13:22.360 --> 01:13:23.360]   fit.
[01:13:23.360 --> 01:13:27.480]   And the only way you know if a model has a proper fit is by seeing whether it works well
[01:13:27.480 --> 01:13:31.620]   on data that was not used to train it.
[01:13:31.620 --> 01:13:37.040]   And so we always set aside some of the data to create something called a validation set.
[01:13:37.040 --> 01:13:41.280]   The validation set is the data that we use not to touch it at all when we're training
[01:13:41.280 --> 01:13:47.040]   a model, but we're only using it to figure out whether the model's actually working or
[01:13:47.040 --> 01:13:51.120]   not.
[01:13:51.120 --> 01:13:57.120]   One thing that Sylvain mentioned in the book is that one of the interesting things about
[01:13:57.120 --> 01:14:05.600]   studying fast AI is you learn a lot of interesting programming practices.
[01:14:05.600 --> 01:14:11.000]   So I've been programming, I mean, since I was a kid, so like 40 years.
[01:14:11.000 --> 01:14:18.060]   And Sylvain and I both work really, really hard to make Python do a lot of work for us
[01:14:18.060 --> 01:14:22.960]   and to use, you know, programming practices, which make us very productive and allow us
[01:14:22.960 --> 01:14:27.100]   to come back to our code years later and still understand it.
[01:14:27.100 --> 01:14:34.840]   And so you'll see in our code, we'll often do things that you might not have seen before.
[01:14:34.840 --> 01:14:39.240]   And so we a lot of students who have gone through previous courses say they learned
[01:14:39.240 --> 01:14:45.560]   a lot about coding and Python coding and software engineering from the course.
[01:14:45.560 --> 01:14:48.840]   So yeah, check, you know, when you see something new, check it out and feel free to ask on
[01:14:48.840 --> 01:14:53.380]   the forums if you're curious about why something was done that way.
[01:14:53.380 --> 01:14:58.440]   One thing to mention is, just like I mentioned, like import star is something most Python
[01:14:58.440 --> 01:15:05.860]   programmers don't do because most libraries don't support doing it properly.
[01:15:05.860 --> 01:15:07.120]   We do a lot of things like that.
[01:15:07.120 --> 01:15:12.720]   We do a lot of things where we don't follow a traditional approach to Python programming
[01:15:12.720 --> 01:15:16.400]   because I've used so many languages over the years.
[01:15:16.400 --> 01:15:22.720]   I code not in a way that's specifically Pythonic, but incorporates like ideas from lots of other
[01:15:22.720 --> 01:15:30.200]   languages and lots of other notations and heavily customize our approach to Python programming
[01:15:30.200 --> 01:15:33.960]   based on what works well for data science.
[01:15:33.960 --> 01:15:40.000]   That means that the code you see in fast.ai is not probably not going to fit with the
[01:15:40.000 --> 01:15:45.960]   kind of style guides and normal approaches at your workplace if you use Python there.
[01:15:45.960 --> 01:15:52.480]   So obviously you should make sure that you fit in with your organization's programming
[01:15:52.480 --> 01:15:58.600]   practices rather than following hours, but perhaps in your own hobby work you can follow
[01:15:58.600 --> 01:16:03.720]   hours and see if you find that interesting and helpful or even experiment with that in
[01:16:03.720 --> 01:16:09.240]   your company if you're a manager and you're interested in doing so.
[01:16:09.240 --> 01:16:19.240]   Okay, so to finish I'm going to show you something pretty interesting, which is have a look at
[01:16:19.240 --> 01:16:28.880]   this code untar data image data loaders from name func learner fine-tune untar data segmentation
[01:16:28.880 --> 01:16:35.720]   data loaders from label func learner fine-tune almost the same code and this has built a
[01:16:35.720 --> 01:16:42.480]   model that does something whoa totally different it's something which has taken images this
[01:16:42.480 --> 01:16:48.560]   is on the left this is the label data it's got images with color codes to tell you whether
[01:16:48.560 --> 01:16:55.240]   it's a car or a tree or a building or a sky or a line marking or a road and on the right
[01:16:55.240 --> 01:17:00.960]   is our model and our model has successfully figured out for each pixel is that a car a
[01:17:00.960 --> 01:17:07.620]   line marking a road now it's only done it in under 20 seconds right so it's a very small
[01:17:07.620 --> 01:17:12.480]   quick model so it's made some mistakes like it's missing this line marking and some of
[01:17:12.480 --> 01:17:19.440]   these cars it thinks is house right but you can see so if you train this for a few minutes
[01:17:19.440 --> 01:17:25.720]   it's nearly perfect but you can see the basic idea is that we can very rapidly with almost
[01:17:25.720 --> 01:17:31.000]   exactly the same code create something not that classifies cats and dogs but does what's
[01:17:31.000 --> 01:17:36.840]   called segmentation figures out what every pixel image is look here's the same thing
[01:17:36.840 --> 01:17:45.080]   from import star text loaders from folder learner learn fine-tune same basic code this
[01:17:45.080 --> 01:17:49.840]   is now something where we can give it a sentence and it can figure out whether that is expressing
[01:17:49.840 --> 01:17:55.800]   a positive or negative sentiment and this is actually giving a 93% accuracy on that
[01:17:55.800 --> 01:18:04.400]   task in about 15 minutes on the IMDB data set which contains thousands of full length
[01:18:04.400 --> 01:18:10.760]   movie reviews like 1000 to 3000 word movie reviews and this number here that we got with
[01:18:10.760 --> 01:18:16.040]   the same three lines of code would have been the best in the world for this task in a very
[01:18:16.040 --> 01:18:23.560]   very very popular academic status set in like 2015 I think so we are creating world-class
[01:18:23.560 --> 01:18:33.520]   models in our browser using the same basic code here's the same basic steps again from
[01:18:33.520 --> 01:18:41.920]   import star untied data tabular data loaders from CSV learner fit this is now building
[01:18:41.920 --> 01:18:51.760]   a model that is predicting let's find out salary based on a CSV table containing these
[01:18:51.760 --> 01:18:59.560]   columns so this is tabular data here's the same basic steps from import star untied data
[01:18:59.560 --> 01:19:06.620]   collab data loaders from CSV learner learn fine-tune this is now building something which
[01:19:06.620 --> 01:19:13.840]   predicts for each combination of a user and a movie what rating do we think that user
[01:19:13.840 --> 01:19:19.200]   will give that movie based on what other movies they watched and liked in the past this is
[01:19:19.200 --> 01:19:24.800]   called collaborative filtering and used recommendation systems so here you've seen some examples
[01:19:24.800 --> 01:19:31.360]   of each of the four applications in fast AI and as you'll see throughout this course the
[01:19:31.360 --> 01:19:38.400]   same basic code and also the same basic mathematical and software engineering concepts allow us
[01:19:38.400 --> 01:19:45.800]   to do vastly different things using the same basic approach and the reason why is because
[01:19:45.800 --> 01:19:54.600]   of Arthur Samuel it's because of this basic description of what it is you can do if only
[01:19:54.600 --> 01:20:00.160]   you have a way to parameterize a model and you have an update procedure which can update
[01:20:00.160 --> 01:20:08.440]   the weights to make you better at your loss function and in this case we can use neural
[01:20:08.440 --> 01:20:18.280]   networks which are totally flexible functions so that's it for this first lesson it's a
[01:20:18.280 --> 01:20:24.120]   little bit shorter than other lessons going to be and the reason for that is that we are
[01:20:24.120 --> 01:20:30.240]   as I mentioned at the start of a global pandemic here or at least in the West in other countries
[01:20:30.240 --> 01:20:34.680]   they are much further into it so we spend some time talking about that at the start
[01:20:34.680 --> 01:20:42.240]   of the course and you can find that video elsewhere so in future lessons there will
[01:20:42.240 --> 01:20:51.560]   be more time on deep learning so what I suggest you do over the next week before you work
[01:20:51.560 --> 01:20:57.040]   on the next lesson is just make sure that you can spin up a GPU server you can shut
[01:20:57.040 --> 01:21:03.240]   it down when it's finished that you can run all of the code here and as you go through
[01:21:03.240 --> 01:21:09.760]   it see you know is this using Python in a way you recognize use the documentation use
[01:21:09.760 --> 01:21:16.960]   that doc function do some searching of the fast AI doc see what it does see if you can
[01:21:16.960 --> 01:21:24.120]   actually grab the fast AI documentation notebooks themselves and run them just try to get comfortable
[01:21:24.120 --> 01:21:28.240]   that you kind of can know your way around because the most important thing to do with
[01:21:28.240 --> 01:21:32.400]   this style of learning this top-down learning is to be able to run experiments and that
[01:21:32.400 --> 01:21:38.120]   means you need to be able to run code so my recommendation is don't move on until you
[01:21:38.120 --> 01:21:48.040]   can run the code read the chapter of the book and then go through the questionnaire we still
[01:21:48.040 --> 01:21:52.840]   got some more work some more stuff to do about validation sets and test sets and transfer
[01:21:52.840 --> 01:21:56.880]   learning so you won't be able to do all of it yet but try to do all the parts that you
[01:21:56.880 --> 01:22:03.480]   can based on what we've seen in the course so far Rachel anything you wanted to add before
[01:22:03.480 --> 01:22:08.240]   we go okay so thanks very much for joining us so lesson one everybody and really looking
[01:22:08.240 --> 01:22:14.800]   forward to seeing you next time where we will learn about transfer learning and then we
[01:22:14.800 --> 01:22:22.120]   will move on to creating a actual production version of an application that we can actually
[01:22:22.120 --> 01:22:27.480]   put out on the internet and you can start building apps that you can show your friends
[01:22:27.480 --> 01:22:30.480]   and they can start playing with all right bye everybody

