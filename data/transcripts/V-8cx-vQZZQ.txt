
[00:00:00.000 --> 00:00:05.000]   Google announced with their work in the paper
[00:00:05.000 --> 00:00:09.160]   in Nature with quantum supremacy.
[00:00:09.160 --> 00:00:11.900]   Can you describe, again, back to the basic,
[00:00:11.900 --> 00:00:16.000]   what is, perhaps not so basic, what is quantum supremacy?
[00:00:16.000 --> 00:00:17.080]   - Absolutely.
[00:00:17.080 --> 00:00:21.120]   So quantum supremacy is a term that was coined by,
[00:00:21.120 --> 00:00:24.640]   again, by John Preskill in 2012.
[00:00:24.640 --> 00:00:27.940]   Not everyone likes the name, you know,
[00:00:27.940 --> 00:00:31.080]   but you know, it sort of stuck.
[00:00:31.080 --> 00:00:35.040]   You know, we don't, we sort of haven't found
[00:00:35.040 --> 00:00:36.240]   a better alternative.
[00:00:36.240 --> 00:00:38.480]   - It's technically quantum computational supremacy.
[00:00:38.480 --> 00:00:40.640]   - Yeah, yeah, supremacy, that's right, that's right.
[00:00:40.640 --> 00:00:43.440]   But the basic idea is actually one that goes
[00:00:43.440 --> 00:00:46.560]   all the way back to the beginnings of quantum computing
[00:00:46.560 --> 00:00:49.520]   when Richard Feynman and David Deutch, people like that,
[00:00:49.520 --> 00:00:51.560]   were talking about it in the early '80s.
[00:00:51.560 --> 00:00:56.560]   And quantum supremacy just refers to sort of the point
[00:00:56.640 --> 00:01:00.460]   in history when you can first use a quantum computer
[00:01:00.460 --> 00:01:04.500]   to do some well-defined task much faster
[00:01:04.500 --> 00:01:07.300]   than any known algorithm running on any
[00:01:07.300 --> 00:01:09.660]   of the classical computers that are available.
[00:01:09.660 --> 00:01:12.300]   Okay, so you know, notice that I did not say
[00:01:12.300 --> 00:01:14.300]   a useful task, okay?
[00:01:14.300 --> 00:01:17.060]   You know, it could be something completely artificial,
[00:01:17.060 --> 00:01:19.860]   but it's important that the task be well-defined.
[00:01:19.860 --> 00:01:21.620]   So in other words, you know, there is,
[00:01:21.620 --> 00:01:24.540]   it is something that has right and wrong answers,
[00:01:24.540 --> 00:01:28.240]   you know, that are knowable independently of this device,
[00:01:28.240 --> 00:01:30.480]   right, and we can then, you know, run the device,
[00:01:30.480 --> 00:01:32.440]   see if it gets the right answer or not.
[00:01:32.440 --> 00:01:34.040]   - Can you clarify a small point?
[00:01:34.040 --> 00:01:37.520]   You said much faster than the classical implementation.
[00:01:37.520 --> 00:01:40.800]   What about, sort of what about the space
[00:01:40.800 --> 00:01:43.200]   with where the class, there's no, there's not,
[00:01:43.200 --> 00:01:45.880]   it doesn't even exist a classical algorithm to--
[00:01:45.880 --> 00:01:49.860]   - So maybe I should clarify, everything that a quantum
[00:01:49.860 --> 00:01:52.280]   computer can do, a classical computer
[00:01:52.280 --> 00:01:54.700]   can also eventually do, okay?
[00:01:54.700 --> 00:01:57.340]   And the reason why we know that is that
[00:01:57.340 --> 00:02:00.300]   a classical computer could always, you know,
[00:02:00.300 --> 00:02:03.560]   if it had no limits of time and memory,
[00:02:03.560 --> 00:02:07.260]   it could always just store the entire quantum state,
[00:02:07.260 --> 00:02:09.300]   you know, of your, you know, of the quantum,
[00:02:09.300 --> 00:02:12.900]   right, store a list of all the amplitudes,
[00:02:12.900 --> 00:02:15.300]   you know, in the state of the quantum computer,
[00:02:15.300 --> 00:02:18.140]   and then just, you know, do some linear algebra
[00:02:18.140 --> 00:02:20.220]   to just update that state, right?
[00:02:20.220 --> 00:02:23.480]   And so, so anything that quantum computers can do
[00:02:23.480 --> 00:02:26.360]   can also be done by classical computers,
[00:02:26.360 --> 00:02:28.680]   albeit exponentially slower in some cases.
[00:02:28.680 --> 00:02:31.800]   - So quantum computers don't go into some magical place
[00:02:31.800 --> 00:02:34.720]   outside of Alan Turing's definition of computation.
[00:02:34.720 --> 00:02:38.000]   - Precisely, they do not solve the halting problem.
[00:02:38.000 --> 00:02:40.760]   They cannot solve anything that is uncomputable
[00:02:40.760 --> 00:02:42.440]   in Alan Turing's sense.
[00:02:42.440 --> 00:02:44.720]   What they, what we think they do change
[00:02:44.720 --> 00:02:47.320]   is what is efficiently computable, okay?
[00:02:47.320 --> 00:02:50.380]   And, you know, since the 1960s, you know,
[00:02:50.380 --> 00:02:52.140]   the word efficiently, you know,
[00:02:52.140 --> 00:02:54.980]   as well as been a central word in computer science,
[00:02:54.980 --> 00:02:58.040]   but it's sort of a code word for something technical,
[00:02:58.040 --> 00:03:01.840]   which is basically with polynomial scaling, you know,
[00:03:01.840 --> 00:03:04.820]   that as you get to larger and larger inputs,
[00:03:04.820 --> 00:03:07.780]   you would like an algorithm that uses an amount of time
[00:03:07.780 --> 00:03:10.360]   that scales only like the size of the input
[00:03:10.360 --> 00:03:13.240]   raised to some power, and not exponentially
[00:03:13.240 --> 00:03:15.340]   with the size of the input, right?
[00:03:15.340 --> 00:03:17.820]   - Yeah, so I do hope we get to talk again,
[00:03:17.820 --> 00:03:20.640]   because one of the many topics
[00:03:20.640 --> 00:03:23.920]   that there's probably several hours worth of conversation on
[00:03:23.920 --> 00:03:26.360]   is complexity, which we probably won't even get a chance
[00:03:26.360 --> 00:03:30.640]   to touch today, but you briefly mentioned it.
[00:03:30.640 --> 00:03:33.300]   But let's maybe try to continue.
[00:03:33.300 --> 00:03:36.620]   So you said the definition of quantum supremacy
[00:03:36.620 --> 00:03:40.400]   is basically design, is achieving a place
[00:03:40.400 --> 00:03:43.080]   where much faster on a formal,
[00:03:43.080 --> 00:03:44.500]   that quantum computer is much faster
[00:03:44.500 --> 00:03:47.380]   on a formal, well-defined problem
[00:03:47.380 --> 00:03:49.140]   that is or isn't useful.
[00:03:49.140 --> 00:03:50.340]   - Yeah, yeah, yeah, right, right.
[00:03:50.340 --> 00:03:53.300]   And I would say that we really want three things, right?
[00:03:53.300 --> 00:03:55.980]   We want, first of all, the quantum computer
[00:03:55.980 --> 00:03:58.580]   to be much faster, just in the literal sense
[00:03:58.580 --> 00:04:01.340]   of like number of seconds, you know,
[00:04:01.340 --> 00:04:04.860]   at just solving this, you know, well-defined problem.
[00:04:04.860 --> 00:04:08.560]   Secondly, we want it to be sort of, you know,
[00:04:08.560 --> 00:04:10.820]   for a problem where we really believe
[00:04:10.820 --> 00:04:14.020]   that a quantum computer has better scaling behavior, right?
[00:04:14.020 --> 00:04:16.740]   So it's not just an incidental, you know,
[00:04:16.740 --> 00:04:19.160]   matter of hardware, but it's that, you know,
[00:04:19.160 --> 00:04:22.240]   as you went to larger and larger inputs, you know,
[00:04:22.240 --> 00:04:25.280]   the classical scaling would be exponential
[00:04:25.280 --> 00:04:27.760]   and the scaling for the quantum algorithm
[00:04:27.760 --> 00:04:29.600]   would only be polynomial.
[00:04:29.600 --> 00:04:32.120]   And then thirdly, we want the first thing,
[00:04:32.120 --> 00:04:36.080]   the actual observed speed up to only be explainable
[00:04:36.080 --> 00:04:38.640]   in terms of the scaling behavior, right?
[00:04:38.640 --> 00:04:41.900]   So, you know, I want, you know, a real world,
[00:04:41.900 --> 00:04:44.540]   you know, a real problem to get solved,
[00:04:44.540 --> 00:04:48.540]   let's say by a quantum computer with 50 qubits or so,
[00:04:48.540 --> 00:04:51.580]   and for no one to be able to explain that in any way
[00:04:51.580 --> 00:04:54.320]   other than, well, you know, to,
[00:04:54.320 --> 00:04:58.340]   this computer involved a quantum state
[00:04:58.340 --> 00:05:01.180]   with two to the 50th power amplitudes.
[00:05:01.180 --> 00:05:03.180]   And, you know, a classical simulation,
[00:05:03.180 --> 00:05:05.080]   at least any that we know today,
[00:05:05.080 --> 00:05:08.460]   would require keeping track of two to the 50th numbers.
[00:05:08.460 --> 00:05:10.440]   And this is the reason why it was faster.
[00:05:10.440 --> 00:05:13.120]   - So the intuition is that then if you demonstrate
[00:05:13.120 --> 00:05:16.380]   on 50 qubits, then once you get to 100 qubits,
[00:05:16.380 --> 00:05:18.760]   then it'll be even much more faster.
[00:05:18.760 --> 00:05:20.460]   - Precisely, precisely.
[00:05:20.460 --> 00:05:23.020]   Yeah, and, you know, and quantum supremacy
[00:05:23.020 --> 00:05:25.200]   does not require error correction, right?
[00:05:25.200 --> 00:05:26.520]   We don't, you know, we don't have,
[00:05:26.520 --> 00:05:28.700]   you could say true scalability yet,
[00:05:28.700 --> 00:05:32.620]   or true, you know, error correction yet,
[00:05:32.620 --> 00:05:34.580]   but you could say quantum supremacy
[00:05:34.580 --> 00:05:36.920]   is already enough by itself
[00:05:36.920 --> 00:05:40.200]   to refute the skeptics who said a quantum computer
[00:05:40.200 --> 00:05:43.200]   will never outperform a classical computer for anything.
[00:05:43.200 --> 00:05:48.200]   - But one, how do you demonstrate quantum supremacy?
[00:05:48.200 --> 00:05:51.840]   And two, what's up with these news articles
[00:05:51.840 --> 00:05:53.840]   I'm reading that Google did so?
[00:05:53.840 --> 00:05:54.680]   - Yeah, all right, well--
[00:05:54.680 --> 00:05:56.080]   - What did they actually do?
[00:05:56.080 --> 00:05:59.100]   - Great questions, 'cause now you get into,
[00:05:59.100 --> 00:06:01.920]   actually, you know, a lot of the work that I've,
[00:06:01.920 --> 00:06:03.720]   you know, I and my students have been doing
[00:06:03.720 --> 00:06:05.040]   for the last decade,
[00:06:05.080 --> 00:06:09.160]   which was precisely about how do you demonstrate
[00:06:09.160 --> 00:06:11.760]   quantum supremacy using technologies
[00:06:11.760 --> 00:06:13.880]   that, you know, we thought would be available
[00:06:13.880 --> 00:06:15.180]   in the near future?
[00:06:15.180 --> 00:06:20.000]   And so one of the main things that we realized
[00:06:20.000 --> 00:06:24.640]   around 2011, and this was me and my student,
[00:06:24.640 --> 00:06:27.900]   Alex Arkhipov at MIT at the time,
[00:06:27.900 --> 00:06:31.240]   and independently of some others,
[00:06:31.240 --> 00:06:34.280]   including Bremner, Josa, and Shepard, okay?
[00:06:34.280 --> 00:06:38.280]   And the realization that we came to
[00:06:38.280 --> 00:06:41.080]   was that if you just want to prove
[00:06:41.080 --> 00:06:43.200]   that a quantum computer is faster, you know,
[00:06:43.200 --> 00:06:45.280]   and not do something useful with it,
[00:06:45.280 --> 00:06:47.840]   then there are huge advantages to sort of
[00:06:47.840 --> 00:06:50.400]   switching your attention from problems
[00:06:50.400 --> 00:06:54.120]   like factoring numbers that have a single right answer
[00:06:54.120 --> 00:06:56.680]   to what we call sampling problems.
[00:06:56.680 --> 00:06:59.000]   So these are problems where the goal
[00:06:59.000 --> 00:07:01.080]   is just to output a sample
[00:07:01.080 --> 00:07:03.500]   from some probability distribution,
[00:07:03.500 --> 00:07:06.160]   let's say over strings of 50 bits, right?
[00:07:06.160 --> 00:07:08.500]   So there are, you know, many, many, many
[00:07:08.500 --> 00:07:10.200]   possible valid outputs.
[00:07:10.200 --> 00:07:11.680]   You know, your computer will probably
[00:07:11.680 --> 00:07:14.400]   never even produce the same output twice,
[00:07:14.400 --> 00:07:16.320]   you know, if it's running as,
[00:07:16.320 --> 00:07:20.920]   even, you know, assuming it's running perfectly, okay?
[00:07:20.920 --> 00:07:23.260]   But the key is that some outputs
[00:07:23.260 --> 00:07:25.760]   are supposed to be likelier than other ones.
[00:07:25.760 --> 00:07:27.780]   - So, sorry, to clarify,
[00:07:27.780 --> 00:07:30.640]   is there a set of outputs that are valid
[00:07:30.640 --> 00:07:31.840]   and a set that are not?
[00:07:31.840 --> 00:07:36.020]   Or is it more that the distribution
[00:07:36.020 --> 00:07:39.260]   of a particular kind of output is more,
[00:07:39.260 --> 00:07:41.380]   is there's a specific distribution
[00:07:41.380 --> 00:07:42.220]   of a particular kind of output?
[00:07:42.220 --> 00:07:44.700]   - Yeah, there's a specific distribution
[00:07:44.700 --> 00:07:46.080]   that you're trying to hit, right?
[00:07:46.080 --> 00:07:48.080]   Or, you know, that you're trying to sample from.
[00:07:48.080 --> 00:07:50.620]   Now, there are a lot of questions about this.
[00:07:50.620 --> 00:07:52.620]   You know, how do you do that, right?
[00:07:52.620 --> 00:07:55.740]   Now, how you do it, you know,
[00:07:55.740 --> 00:07:58.280]   it turns out that with a quantum computer,
[00:07:58.280 --> 00:08:00.340]   even with the noisy quantum computers
[00:08:00.340 --> 00:08:02.900]   that we have now, that we have today,
[00:08:02.900 --> 00:08:05.020]   what you can do is basically just apply
[00:08:05.020 --> 00:08:08.340]   a randomly chosen sequence of operations, right?
[00:08:08.340 --> 00:08:10.460]   So we, you know, we, in some of those, you know,
[00:08:10.460 --> 00:08:12.700]   that part is almost trivial, right?
[00:08:12.700 --> 00:08:15.400]   We just sort of get the qubits to interact
[00:08:15.400 --> 00:08:17.620]   in some random way, although a sort of
[00:08:17.620 --> 00:08:19.740]   precisely specified random way,
[00:08:19.740 --> 00:08:22.180]   so we can repeat the exact same
[00:08:22.180 --> 00:08:24.580]   random sequence of interactions again
[00:08:24.580 --> 00:08:27.640]   and get another sample from that same distribution.
[00:08:27.640 --> 00:08:29.980]   And what this does is it basically,
[00:08:29.980 --> 00:08:32.260]   well, it creates a lot of garbage,
[00:08:32.260 --> 00:08:34.700]   but, you know, very specific garbage, right?
[00:08:34.700 --> 00:08:37.260]   So, you know, of all of the,
[00:08:37.260 --> 00:08:39.500]   so if we're going to talk about Google's device,
[00:08:39.500 --> 00:08:42.180]   there were 53 qubits there, okay?
[00:08:42.180 --> 00:08:46.140]   And so there were two to the 53 power possible outputs.
[00:08:46.140 --> 00:08:48.460]   Now, for some of those outputs, you know,
[00:08:48.460 --> 00:08:52.340]   there was a little bit more destructive interference
[00:08:52.340 --> 00:08:53.780]   in their amplitude, okay?
[00:08:53.780 --> 00:08:56.140]   So their amplitudes were a little bit smaller.
[00:08:56.140 --> 00:08:57.540]   And for others, there was a little more
[00:08:57.540 --> 00:08:59.320]   constructive interference.
[00:08:59.320 --> 00:09:01.600]   You know, the amplitudes were a little bit more aligned
[00:09:01.600 --> 00:09:04.380]   with each other, you know, and so those,
[00:09:04.380 --> 00:09:06.940]   those that were a little bit likelier, okay?
[00:09:06.940 --> 00:09:10.300]   All of the outputs are exponentially unlikely,
[00:09:10.300 --> 00:09:13.500]   but some are, let's say, two times or three times,
[00:09:13.500 --> 00:09:15.820]   you know, unlikelier than others, okay?
[00:09:15.820 --> 00:09:18.860]   And so you can define, you know,
[00:09:18.860 --> 00:09:21.660]   this sequence of operations that gives rise
[00:09:21.660 --> 00:09:23.780]   to this probability distribution.
[00:09:23.780 --> 00:09:26.820]   Okay, now, the next question would be,
[00:09:26.820 --> 00:09:29.140]   well, how do you, you know, even if you're sampling from it,
[00:09:29.140 --> 00:09:30.360]   how do you verify that?
[00:09:30.360 --> 00:09:32.160]   - Right, exactly. - How do you know?
[00:09:32.160 --> 00:09:37.160]   And so my students and I, and also the people at Google
[00:09:37.160 --> 00:09:41.120]   were doing the experiment, came up with statistical tests
[00:09:41.120 --> 00:09:44.960]   that you can apply to the outputs in order to
[00:09:44.960 --> 00:09:49.480]   try to verify, you know, what is, you know,
[00:09:49.480 --> 00:09:53.920]   that at least that some hard problem is being solved.
[00:09:53.920 --> 00:09:56.720]   The test that Google ended up using
[00:09:56.720 --> 00:09:57.900]   was something that they called
[00:09:57.900 --> 00:10:00.880]   the linear cross-entropy benchmark, okay?
[00:10:00.880 --> 00:10:04.360]   And it's basically, you know, so the drawback of this test
[00:10:04.360 --> 00:10:07.320]   is that it requires, like, it requires you
[00:10:07.320 --> 00:10:11.120]   to do a two to the 53 time calculation
[00:10:11.120 --> 00:10:12.960]   with your classical computer, okay?
[00:10:12.960 --> 00:10:15.800]   So it's very expensive to do the test
[00:10:15.800 --> 00:10:17.320]   on a classical computer. - Yeah.
[00:10:17.320 --> 00:10:18.800]   - The good news is-- - How big of a number
[00:10:18.800 --> 00:10:21.680]   is two to the 53? - It's about nine quadrillion.
[00:10:21.680 --> 00:10:23.200]   - Okay. - That doesn't help.
[00:10:23.200 --> 00:10:25.040]   - Well, you know, it's, you want it
[00:10:25.040 --> 00:10:26.680]   in like scientific notation-- - No, no, no, no.
[00:10:26.680 --> 00:10:29.080]   - What I mean is-- - Yeah, it is, it is,
[00:10:29.080 --> 00:10:30.120]   it is just-- - Is it impossible
[00:10:30.120 --> 00:10:32.360]   to run on a-- - Yeah, so we will come
[00:10:32.360 --> 00:10:33.200]   back to that.
[00:10:33.200 --> 00:10:35.920]   It is just barely possible to run, we think,
[00:10:35.920 --> 00:10:39.160]   on the largest supercomputer that currently exists on Earth,
[00:10:39.160 --> 00:10:42.440]   which is called Summit at Oak Ridge National Lab, okay?
[00:10:42.440 --> 00:10:43.440]   (laughing)
[00:10:43.440 --> 00:10:44.920]   - Great, this is exciting.
[00:10:44.920 --> 00:10:46.280]   - That's the short answer.
[00:10:46.280 --> 00:10:50.000]   So ironically, for this type of experiment,
[00:10:50.000 --> 00:10:52.400]   we don't want 100 qubits, okay?
[00:10:52.400 --> 00:10:55.040]   Because with 100 qubits, even if it works,
[00:10:55.040 --> 00:10:57.640]   we don't know how to verify the results, okay?
[00:10:57.640 --> 00:11:00.800]   So we want a number of qubits that is enough
[00:11:00.800 --> 00:11:04.440]   that the biggest classical computers on Earth
[00:11:04.440 --> 00:11:08.560]   will have to sweat and will just barely be able
[00:11:08.560 --> 00:11:11.160]   to keep up with the quantum computer,
[00:11:11.160 --> 00:11:14.680]   using much more time, but they will still be able to do it
[00:11:14.680 --> 00:11:16.440]   in order that we can verify the results.
[00:11:16.440 --> 00:11:18.200]   - Which is where the 53 comes from,
[00:11:18.200 --> 00:11:19.280]   for the number of qubits. - Basically, well,
[00:11:19.280 --> 00:11:22.200]   I mean, that's also, that's sort of,
[00:11:23.560 --> 00:11:26.920]   I mean, that's sort of where they are now,
[00:11:26.920 --> 00:11:28.480]   in terms of scaling, you know?
[00:11:28.480 --> 00:11:29.800]   And then, you know, soon, you know,
[00:11:29.800 --> 00:11:31.720]   that point will be passed.
[00:11:31.720 --> 00:11:34.880]   And then when you get to larger numbers of qubits,
[00:11:34.880 --> 00:11:38.200]   then, you know, these types of sampling experiments
[00:11:38.200 --> 00:11:40.240]   will no longer be so interesting,
[00:11:40.240 --> 00:11:43.000]   because we won't even be able to verify the results,
[00:11:43.000 --> 00:11:45.800]   and we'll have to switch to other types of computation.
[00:11:45.800 --> 00:11:48.120]   So with the sampling thing, you know,
[00:11:48.120 --> 00:11:50.600]   so the test that Google applied,
[00:11:50.600 --> 00:11:52.800]   with this linear cross-entropy benchmark,
[00:11:52.800 --> 00:11:56.480]   is basically just take the samples that were generated,
[00:11:56.480 --> 00:11:58.920]   which are, you know, a very small subset
[00:11:58.920 --> 00:12:01.120]   of all the possible samples that there are,
[00:12:01.120 --> 00:12:04.680]   but for those, you calculate, with your classical computer,
[00:12:04.680 --> 00:12:07.640]   the probabilities that they should have been output.
[00:12:07.640 --> 00:12:09.640]   And you see, are those probabilities,
[00:12:09.640 --> 00:12:11.160]   like, larger than the mean?
[00:12:11.160 --> 00:12:13.400]   You know, so is the quantum computer biased
[00:12:13.400 --> 00:12:16.240]   toward outputting the strings that it's, you know,
[00:12:16.240 --> 00:12:18.400]   that you want it to be biased toward?
[00:12:18.400 --> 00:12:22.360]   Okay, and then, finally, we come to a very crucial question,
[00:12:22.360 --> 00:12:24.320]   which is supposing that it does that,
[00:12:24.320 --> 00:12:26.520]   well, how do we know that a classical computer
[00:12:26.520 --> 00:12:29.360]   could not have quickly done the same thing, right?
[00:12:29.360 --> 00:12:30.480]   How do we know that, you know,
[00:12:30.480 --> 00:12:33.360]   this couldn't have been spoofed by a classical computer,
[00:12:33.360 --> 00:12:36.960]   right, and so, well, the first answer is we don't know,
[00:12:36.960 --> 00:12:38.560]   for sure, because, you know,
[00:12:38.560 --> 00:12:41.840]   this takes us into questions of complexity theory,
[00:12:41.840 --> 00:12:44.720]   you know, I mean, questions on the,
[00:12:44.720 --> 00:12:47.560]   of the magnitude of the P versus NP question,
[00:12:47.560 --> 00:12:48.400]   and things like that, right?
[00:12:48.400 --> 00:12:51.640]   You know, we don't know how to rule out definitively
[00:12:51.640 --> 00:12:55.000]   that there could be fast classical algorithms for,
[00:12:55.000 --> 00:12:57.080]   you know, even simulating quantum mechanics,
[00:12:57.080 --> 00:13:00.440]   and for, you know, simulating experiments like these,
[00:13:00.440 --> 00:13:04.280]   but we can give some evidence against that possibility,
[00:13:04.280 --> 00:13:06.120]   and that was sort of the, you know,
[00:13:06.120 --> 00:13:08.280]   the main thrust of a lot of the work
[00:13:08.280 --> 00:13:10.680]   that my colleagues and I did, you know,
[00:13:10.680 --> 00:13:13.280]   over the last decade, which is then sort of in,
[00:13:13.280 --> 00:13:16.320]   around 2015 or so, what led to Google
[00:13:16.320 --> 00:13:18.040]   deciding to do this experiment.
[00:13:18.040 --> 00:13:20.640]   - So is the kind of evidence you,
[00:13:20.640 --> 00:13:23.920]   first of all, the hard P equals NP problem that you mentioned
[00:13:23.920 --> 00:13:26.360]   and the kind of evidence that you're,
[00:13:26.360 --> 00:13:30.520]   were looking at, is that something you come to
[00:13:30.520 --> 00:13:33.720]   on a sheet of paper, or is this something,
[00:13:33.720 --> 00:13:35.480]   are these empirical experiments?
[00:13:35.480 --> 00:13:37.640]   - It's math, for the most part.
[00:13:37.640 --> 00:13:40.840]   I mean, you know, it's also, you know,
[00:13:40.840 --> 00:13:44.440]   we have a bunch of methods that are known
[00:13:44.440 --> 00:13:48.120]   for simulating quantum circuits,
[00:13:48.280 --> 00:13:51.600]   you know, quantum computations with classical computers,
[00:13:51.600 --> 00:13:53.400]   and so we have to try them all out
[00:13:53.400 --> 00:13:55.600]   and make sure that, you know, they don't work,
[00:13:55.600 --> 00:13:58.320]   you know, make sure that they have exponential scaling
[00:13:58.320 --> 00:14:00.800]   on, you know, these problems,
[00:14:00.800 --> 00:14:02.240]   and not just theoretically,
[00:14:02.240 --> 00:14:04.440]   but with the actual range of parameters
[00:14:04.440 --> 00:14:08.400]   that are actually, you know, arising in Google's experiment.
[00:14:08.400 --> 00:14:11.440]   Okay, so there is an empirical component to it, right?
[00:14:11.440 --> 00:14:15.200]   But now, on the theoretical side,
[00:14:15.200 --> 00:14:17.800]   you know, basically what we know how to do
[00:14:17.800 --> 00:14:21.560]   in theoretical computer science and computational complexity
[00:14:21.560 --> 00:14:24.160]   is, you know, we don't know how to prove
[00:14:24.160 --> 00:14:26.880]   that most of the problems we care about are hard,
[00:14:26.880 --> 00:14:29.840]   but we know how to pass the blame to someone else.
[00:14:29.840 --> 00:14:32.040]   Okay, we know how to say, well, look, you know,
[00:14:32.040 --> 00:14:34.440]   I can't prove that this problem is hard,
[00:14:34.440 --> 00:14:36.960]   but if it is easy, then all these other things
[00:14:36.960 --> 00:14:41.120]   that, you know, you probably were much more confident
[00:14:41.120 --> 00:14:44.800]   or were hard, then those would be easy as well, okay?
[00:14:44.800 --> 00:14:47.780]   So we can give what are called reductions.
[00:14:47.780 --> 00:14:50.720]   And this has been the basic strategy in, you know,
[00:14:50.720 --> 00:14:52.640]   NP completeness, right,
[00:14:52.640 --> 00:14:56.800]   in all of theoretical computer science and cryptography
[00:14:56.800 --> 00:14:59.060]   since the 1970s, really.
[00:14:59.060 --> 00:15:02.260]   And so we were able to give some reduction evidence
[00:15:02.260 --> 00:15:07.260]   for the hardness of simulating these sampling experiments,
[00:15:07.260 --> 00:15:11.280]   these sampling-based quantum supremacy experiments.
[00:15:11.280 --> 00:15:14.200]   The reduction evidence is not as satisfactory
[00:15:14.200 --> 00:15:15.380]   as it should be.
[00:15:15.380 --> 00:15:17.960]   One of the biggest open problems in this area
[00:15:17.960 --> 00:15:19.480]   is to make it better.
[00:15:19.480 --> 00:15:21.380]   But, you know, we can do something.
[00:15:21.380 --> 00:15:24.780]   You know, certainly we can say that, you know,
[00:15:24.780 --> 00:15:27.460]   if there is a fast classical algorithm
[00:15:27.460 --> 00:15:29.240]   to spoof these experiments,
[00:15:29.240 --> 00:15:31.220]   then it has to be very, very unlike
[00:15:31.220 --> 00:15:32.980]   any of the algorithms that we know.
[00:15:32.980 --> 00:15:38.240]   - Which is kind of in the same kind of space of reasoning
[00:15:38.240 --> 00:15:41.200]   that people say P not equals NP.
[00:15:41.200 --> 00:15:43.500]   - Yeah, it's in the same spirit.
[00:15:43.580 --> 00:15:45.740]   (silence)
[00:15:45.740 --> 00:15:47.900]   (silence)
[00:15:47.900 --> 00:15:50.060]   (silence)
[00:15:50.060 --> 00:15:52.220]   (silence)
[00:15:52.220 --> 00:15:54.380]   (silence)
[00:15:54.380 --> 00:15:56.540]   (silence)
[00:15:56.540 --> 00:15:58.700]   (silence)
[00:15:58.700 --> 00:16:08.700]   [BLANK_AUDIO]

