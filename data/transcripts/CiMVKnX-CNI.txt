
[00:00:00.000 --> 00:00:21.240]   I think we've all noticed tools like vZero getting pretty good at generative UI and creating
[00:00:21.240 --> 00:00:28.920]   good-looking things as well as Claude code being able to let us run things more complicated locally
[00:00:28.920 --> 00:00:36.180]   and build on those things so I think the the thing that comes out of this is designers product people
[00:00:36.180 --> 00:00:39.960]   and engineers all building together and I'm really excited about that because I've never loved the
[00:00:39.960 --> 00:00:47.280]   the divides and between these things so this really lets us get rid of in my mind get rid of
[00:00:47.280 --> 00:00:54.420]   mock-ups get rid of the click-through prototypes and all the hand-wringing about whether the thing
[00:00:54.420 --> 00:01:00.900]   that we're building is worth the engineering effort so as we as we go into this it's time for us to
[00:01:00.900 --> 00:01:06.300]   jump in and feel the material that we're working with and see what emerges so I'll give you a super
[00:01:06.300 --> 00:01:13.740]   quick overview of flat files AI stack this is not an official diagram but it's how I see it and we
[00:01:13.740 --> 00:01:21.420]   migrate data big if you need to move a lot of data between systems frequently you use our developer
[00:01:21.420 --> 00:01:26.100]   platform and since we're a developer platform LMs are good at writing code makes it the perfect place
[00:01:26.100 --> 00:01:33.060]   for a lot of AI at the bottom here we have our customers flat file applications that they deploy to
[00:01:33.060 --> 00:01:39.360]   our infrastructure then there's this like real-time context which is the data and the validation outcome
[00:01:39.360 --> 00:01:44.820]   so what are the errors and warnings and things that are in that that data that dirty data and then our
[00:01:44.820 --> 00:01:51.960]   AI agents the tools they have and the jobs that they can run and then what gets shown to users so I see it
[00:01:51.960 --> 00:01:57.840]   as four buckets here there's more there's invisible so it's kind of like the ghost in the machine almost
[00:01:57.840 --> 00:02:03.840]   called called that ghost ambient so it's kind of happening in the space but you're not directly
[00:02:03.840 --> 00:02:09.960]   working with it in line so it's actually in your work in your workflow and then conversational the ones
[00:02:09.960 --> 00:02:16.560]   that were I guess all arguing about I think that's what I learned being here at this conference here's
[00:02:16.560 --> 00:02:22.740]   an example of invisible so when you start if you sign up for a flat file we go in the background we take
[00:02:22.740 --> 00:02:27.960]   your email address you find the company you work for we look it up and in the background the AI agents
[00:02:27.960 --> 00:02:33.060]   are writing a flat file application so they're writing code and essentially sending you up a demo
[00:02:33.060 --> 00:02:38.340]   that is perfect for your use case so if you come in you're from an HR company you're gonna get an HR
[00:02:38.340 --> 00:02:44.340]   demo and while that's running you don't need to know that AI is working on it so that I'd say is like
[00:02:44.340 --> 00:02:49.800]   it's working in the background here's something working more ambiently it's a very initial take on
[00:02:49.800 --> 00:02:55.740]   this but you can see there's something an agent analyzing the data in the background this is a tool
[00:02:55.740 --> 00:03:03.180]   actually I lead this team for AI transformation and you can see the little sparkles pop up on the columns
[00:03:03.180 --> 00:03:09.900]   when it finds opportunities to fix it so that's ambient this is in line so you're busy working in the data
[00:03:09.900 --> 00:03:17.800]   and the AI is able you're able to use the AI I'm directly in line here to fix the data these agents are
[00:03:17.800 --> 00:03:23.740]   writing code that then gets run on this data set so you could have a million rows and 50 columns or
[00:03:23.740 --> 00:03:30.340]   whatever you want and that code will run really fast which is pretty cool and then finally the
[00:03:30.340 --> 00:03:37.180]   conversational ones we're all used to so this is build mode it's the no code low code agentic system
[00:03:37.180 --> 00:03:43.120]   that writes flat file apps now so before you would probably have to have had a engineer at the company
[00:03:43.120 --> 00:03:49.060]   building these applications now it can all be built up so that's pretty cool
[00:03:49.060 --> 00:03:56.060]   um and that's that's kind of the the general surfaces I think about um I listened to um Amanda
[00:03:56.060 --> 00:04:02.940]   Askell um from Anthropic talking to Lex Friedman about um building um Claude's character and in that moment I
[00:04:02.940 --> 00:04:08.940]   realized I'd been doing something a little silly I'd been giving engineers feedback on our agents like oh it
[00:04:08.940 --> 00:04:14.880]   shouldn't start saying this and it shouldn't use these words and and why should it do this and I realized I was I was doing
[00:04:14.880 --> 00:04:23.820]   like I would do design copy right I was I was I'm in my my my normal instinct and when I heard her talk I realized I needed to go from
[00:04:23.820 --> 00:04:30.820]   controlling um to being a character coach and and and actually building out um the the nature that I wanted
[00:04:30.820 --> 00:04:42.860]   so this is a v0 I hope have you most of you used v0 from Vercel before um yeah um so this is a v0 I built one of my early ones and it was um I
[00:04:42.860 --> 00:04:48.540]   called it a chat tuner it doesn't look like much but that wasn't the focus um but I could essentially um put our
[00:04:48.540 --> 00:04:55.980]   orchestrators so the system prompt for our ai orchestrator for build mode um in here and then I can modify it I can say what is it
[00:04:55.980 --> 00:05:04.020]   like if I tell Claude to be more friendly versus more balanced versus more concise what what does more cautious mean to
[00:05:04.020 --> 00:05:12.020]   this model um and the point of me showing this is just to say like the design of the final thing is always a
[00:05:12.020 --> 00:05:20.180]   tempting thing to design to um but now we can actually go and build tools to help us to design that um and this
[00:05:20.180 --> 00:05:25.740]   brings me to like uh I have like three themes um the first theme which is feeling the material I'm a
[00:05:25.740 --> 00:05:31.660]   woodworker so you'll have to forgive the analogies to physical material but if you're going to uh design
[00:05:31.660 --> 00:05:36.700]   something with a physical material you have to feel it right you have to what are the properties of it
[00:05:36.700 --> 00:05:43.260]   and you need to understand it and so I feel like before with design we were kind of looking at everything
[00:05:43.260 --> 00:05:48.940]   through like layers right mock-ups and prototypes and and kind of trying to see what was going to work
[00:05:48.940 --> 00:05:54.460]   and what wasn't what we need to do now is go feel the material feel feel how these models work
[00:05:55.500 --> 00:06:03.260]   my new north star is like creating an environment for these llms to shine right what's what's this form
[00:06:03.260 --> 00:06:09.420]   factor that can help them nail their assignment stay aligned and grow as the models get better
[00:06:09.420 --> 00:06:15.180]   right that's that's my new goal um we're basically anything we do with an llm I feel like we're putting
[00:06:15.180 --> 00:06:22.540]   it in a box um and that's you also hear people say that llms are like interns like oh it's an intern with
[00:06:22.540 --> 00:06:28.860]   a phd and so I try think now if you're putting an intern with a phd in a box like it better be a good
[00:06:28.860 --> 00:06:36.700]   box um and so we need to put effort in um this was a conversation we were having about what tools does this
[00:06:36.700 --> 00:06:42.140]   uh co-worker this new form factor this new model like what tools do we give it when it shows up for work
[00:06:42.140 --> 00:06:47.660]   um and I got fixated on this idea of cursors I was like oh what happens if we just had a mouse or a
[00:06:47.660 --> 00:06:53.740]   trackpad I'm a trackpad person um so that's probably controversial but uh essentially what happens if we
[00:06:53.740 --> 00:07:01.900]   gave the AI um those tools and so I I created this v0 and they moved it into cursor um and I was like well
[00:07:01.900 --> 00:07:07.500]   I work in design tools a lot so I don't migrate a lot of data so this is the best place for me to feel this
[00:07:07.500 --> 00:07:13.580]   right to feel this material so I created a canvas um and I could give it orders and be like hey and
[00:07:13.580 --> 00:07:19.820]   honestly I was I was very enthusiastic about this um for like a few seconds it felt like I was touching
[00:07:19.820 --> 00:07:25.740]   the AGI a little bit but I also very quickly started feeling like I was putting a Formula One driver in a
[00:07:25.740 --> 00:07:31.900]   Prius it just it felt like I was constraining it and controlling it um it could only move one thing at a
[00:07:31.900 --> 00:07:41.420]   time um but so so learning from that um was uh something like this was also um a v0 um that I
[00:07:41.420 --> 00:07:46.780]   used Claude code on eventually and this is a new uh product that we're working on which brings like the
[00:07:46.780 --> 00:07:53.020]   all the stuff we've learned about uh migrating data to consumers to let them work on their data
[00:07:53.020 --> 00:07:59.820]   um but you can see the AI is is operating in the space um and it's it's got presence and so it's
[00:07:59.820 --> 00:08:05.740]   it's able to read multiple files while writing into another one um it's not like me who can only focus
[00:08:05.740 --> 00:08:12.860]   on one thing at a time even though I think I can focus on more um it's not true and so this is us moving
[00:08:12.860 --> 00:08:21.660]   from determinism to inference and figuring out what this material feels like and so um that's feeling
[00:08:21.660 --> 00:08:26.940]   the material right like working with the model getting it into your space understanding how it feels
[00:08:26.940 --> 00:08:32.300]   to work alongside of what's it capable of and then the form factors that we're putting on them actually
[00:08:32.300 --> 00:08:38.860]   actually you can now go build it and play with it um and feel it um the next material analogy I have
[00:08:38.860 --> 00:08:43.660]   which is finding the grain once you've got the characteristics of the material you understand it
[00:08:43.660 --> 00:08:48.620]   usually the piece of material that you're building with and you're creating with might have its own
[00:08:48.620 --> 00:08:53.980]   characteristics and so as we're creating these form factors uh finding the grain is about feeling it
[00:08:53.980 --> 00:09:00.540]   out where is it smooth and rough um where is it weak where is it strong um and we'll have to remain
[00:09:00.540 --> 00:09:06.140]   humble here because um things are going to change and are changing so quickly that whatever we
[00:09:06.140 --> 00:09:12.540]   rebuild is going to most likely need to be rebuilt this was an example of that build mode agent I asked
[00:09:12.540 --> 00:09:18.140]   it to do one thing which was enable the auto map plugin so it's just automatically maps data from
[00:09:18.140 --> 00:09:25.500]   the source data to the target data and I get a wall of text and it's not bad because this went and I
[00:09:25.500 --> 00:09:29.900]   saved me probably a week of work um I didn't have to have a product manager write a prd send it to an engineer
[00:09:30.460 --> 00:09:36.380]   get the in the road map get the engineer to write it qa this was all just done right all that code was
[00:09:36.380 --> 00:09:44.460]   written but the noise gets in the way and so this was a v0 of of kind of rethinking the tool ux what could
[00:09:44.460 --> 00:09:50.860]   it be like and so um the way I thought about this was if you're designing for a if you're if you're going
[00:09:50.860 --> 00:09:54.940]   to a co-worker and you're going to do something complicated for them and you want to communicate you
[00:09:54.940 --> 00:10:00.220]   think okay I'm going to choose my words carefully I'm going to communicate visually I'm going to stop
[00:10:00.220 --> 00:10:06.300]   and check whether whether it's right and so I wanted this to feel similar and so you can see here split
[00:10:06.300 --> 00:10:11.820]   personal details it's visually telling you what's doing saying hey is this right then it's saying I'm
[00:10:11.820 --> 00:10:17.820]   aligned I took a snapshot you can roll back I'm holding you accountable you approved this and then
[00:10:17.820 --> 00:10:22.780]   telling you what you can do next we also wanted to it to be able to express itself so if something went
[00:10:22.780 --> 00:10:27.180]   wrong and I'm shaking its head and a little bit of frustration which is probably what the user is
[00:10:27.180 --> 00:10:35.260]   feeling too when something goes wrong and then finally it can back off when it gets something wrong
[00:10:35.260 --> 00:10:41.580]   and sort of say okay I'm handing control back over to you and that's a lot more intro that feels a lot
[00:10:41.580 --> 00:10:47.820]   better and it felt like we had found the grain and found the right place to put this this material
[00:10:48.780 --> 00:10:54.220]   with this and so what's really cool about this one is that as we're implementing it we've realized that
[00:10:54.220 --> 00:11:02.700]   it can you can fit in other places so not just in conversational flow it can fit in line and this
[00:11:02.700 --> 00:11:07.180]   is going to be in our kind of like inline transform functionality really soon
[00:11:09.420 --> 00:11:15.980]   so I think like as we as we find a new technology and work with it we run the risk of just automating
[00:11:15.980 --> 00:11:20.220]   the tedious things and I was so excited about those previous two talks because there's kind of like
[00:11:20.220 --> 00:11:24.220]   some emergence in there right like something interesting that we wouldn't be able to do before
[00:11:24.220 --> 00:11:32.540]   and I'm most excited about those things like what what emerges from from playing we stopped playing for a
[00:11:32.540 --> 00:11:37.900]   few years um when we were kind of got the internet and we were like really excited and css3 came out
[00:11:37.900 --> 00:11:43.900]   and then like html5 we were playing a lot um now I feel like we're all playing again and so that's really
[00:11:43.900 --> 00:11:53.340]   exciting for me um this is an example of me playing um I created this v0 and I I we've been in search of this
[00:11:53.340 --> 00:11:59.740]   characteristic of an agent that is that feels forward leaning and what I mean by that is it's an agent that's
[00:11:59.740 --> 00:12:07.100]   curious and it's excitable um but it likes getting done um and it's very focused um so not going crazy
[00:12:07.100 --> 00:12:12.540]   right like we've all seen the lms kind of go too far when you give it a task and that doesn't feel good
[00:12:12.540 --> 00:12:20.060]   um so here I dropped a json file and a csv file um and the agent decided um you know what would be good to
[00:12:20.060 --> 00:12:26.540]   do is combine those two things because the data look pretty similar um and so here we can see it's it's
[00:12:26.540 --> 00:12:32.220]   combined the the file the two files into one um that's a good thing that it did I didn't have to
[00:12:32.220 --> 00:12:39.420]   ask it to do that um it picked up on it um and then after that it wrote a report so it told us what it
[00:12:39.420 --> 00:12:44.700]   was doing said hey I found some duplicates this is probably what you need to do next and so it built up
[00:12:44.700 --> 00:12:50.940]   context um and I was actually just trying to play with Claude 4 here and feel the material and kind of see how
[00:12:50.940 --> 00:12:58.860]   it would be but I realized um I'd kind of come across this nature that we were after um it made some
[00:12:58.860 --> 00:13:05.660]   suggestions and generated slide deck which I I asked it for um so within just dropping two files um it's
[00:13:05.660 --> 00:13:13.820]   it's done something emergent um and now we're baking this into our our new product called obvious which
[00:13:13.820 --> 00:13:20.220]   is coming soon another one was we had this idea of giving our agents a knowledge base so all the
[00:13:20.220 --> 00:13:25.580]   customer calls we'd had with them were all recorded and transcribed like most of ours are um and we had
[00:13:25.580 --> 00:13:31.500]   documentation from the customer and so we put it in into knowledge base and then when we analyzed all of
[00:13:31.500 --> 00:13:36.780]   this customer data we surfaced up um suggestions based off that I was fully expecting better
[00:13:36.780 --> 00:13:44.620]   suggestions I was fully expecting more suggestions got those but then here um the the agent decided
[00:13:44.620 --> 00:13:49.740]   I can't fix this but I know how to fix it and so I'm going to tell you how to fix it and so it suggests
[00:13:49.740 --> 00:13:56.140]   here that the user actually goes to HR and gets them to generate the missing employee IDs and what emerged
[00:13:56.140 --> 00:14:01.180]   here was something I wasn't expecting maybe you look at this and say that makes a lot of obvious sense but
[00:14:01.180 --> 00:14:06.460]   to me I wasn't expecting it to be able to help the human to go and do the job um where it couldn't
[00:14:06.460 --> 00:14:12.380]   um so that was really exciting I don't think I would be able to get to that without um playing and and
[00:14:12.380 --> 00:14:19.420]   being curious um and then the last thing I want to talk a little bit about is eyes on the future and we
[00:14:19.420 --> 00:14:25.820]   all have our eyes on the future because how can you not there's always something new now um with models um
[00:14:26.620 --> 00:14:33.580]   so I I like to think about it as like what's your pelican on a bicycle um and one of my pelican on a
[00:14:33.580 --> 00:14:38.940]   bicycles is order complete I'm super excited about it's probably a bad idea um actually to use an LLM for
[00:14:38.940 --> 00:14:44.940]   this but I'm like I want to make an order complete that is backed by an LLM and so this one has a hundred
[00:14:44.940 --> 00:14:51.260]   suggestions for fixing some data um and it's kind of like a bake-off um between these two things I'm yet to
[00:14:51.260 --> 00:14:59.420]   find um a model that is both very fast and very good at this problem um but this is a a benchmark
[00:14:59.420 --> 00:15:04.060]   or something that I've created just for myself to be able to feel the materials um that we're getting
[00:15:04.620 --> 00:15:09.740]   and so I think about that for my design practice now like what are the things I care about and can I
[00:15:09.740 --> 00:15:15.100]   like design into the future and start to think about the form factors I want and then build an
[00:15:15.100 --> 00:15:21.820]   application that can actually test that so yeah that's all I have for you today I I'm very excited to
[00:15:21.820 --> 00:15:34.540]   see all the new form factors um that we build um with our new tools thank you

