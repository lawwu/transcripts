
[00:00:00.500 --> 00:00:03.200]   NICHIL CHOI:
[00:00:03.200 --> 00:00:16.640]   Hey, everyone, I'm NICHIL.
[00:00:16.640 --> 00:00:19.360]   I'm the co-founder and CEO of Cloud Chef.
[00:00:19.360 --> 00:00:21.240]   Today I'm going to tell you guys how
[00:00:21.240 --> 00:00:25.400]   we took a general purpose robot that was not meant for cooking.
[00:00:25.400 --> 00:00:27.880]   It was just a robot with two hands,
[00:00:27.880 --> 00:00:30.320]   how we trained it or put it through culinary school.
[00:00:30.320 --> 00:00:32.200]   And it's now a professional chef that's
[00:00:32.200 --> 00:00:34.240]   working in various different kitchens
[00:00:34.240 --> 00:00:38.560]   doing actual real work like a chef.
[00:00:38.560 --> 00:00:41.880]   So before we get into that, a quick thing about Cloud Chef.
[00:00:41.880 --> 00:00:46.120]   Our mission basically is to make high-quality, nutritious food
[00:00:46.120 --> 00:00:47.760]   affordable to everyone.
[00:00:47.760 --> 00:00:49.840]   And the only way we know how to do it at this point
[00:00:49.840 --> 00:00:53.160]   is by automating all commercial labor or all commercial kitchen
[00:00:53.160 --> 00:00:56.080]   labor with what we call culinary intelligent robots,
[00:00:56.080 --> 00:00:58.720]   robots that can act, sense, and reason,
[00:00:58.720 --> 00:01:02.120]   and behave in the real world like a chef.
[00:01:02.120 --> 00:01:07.040]   So you guys probably all have seen the Tesla Optimus dancing.
[00:01:07.040 --> 00:01:08.520]   And I've seen it, too.
[00:01:08.520 --> 00:01:11.760]   And the immediate question that comes to mind is,
[00:01:11.760 --> 00:01:14.600]   maybe this is how a robot chef will be.
[00:01:14.600 --> 00:01:17.240]   where, you know, it's in the kitchen,
[00:01:17.240 --> 00:01:21.520]   it's beating down equipment, whatnot, right?
[00:01:21.520 --> 00:01:24.560]   But it turns out that those guys are a little too expensive.
[00:01:24.560 --> 00:01:25.920]   They're not really there yet.
[00:01:25.920 --> 00:01:27.920]   There are lots of problems with humanoids.
[00:01:27.920 --> 00:01:30.520]   But on the other hand, if you look at form factors like these,
[00:01:30.520 --> 00:01:32.160]   they're also general purpose.
[00:01:32.160 --> 00:01:34.600]   They're basically just two hands on a mobile base that
[00:01:34.600 --> 00:01:40.200]   can move around and actually do all the work that a regular chef
[00:01:40.200 --> 00:01:44.560]   would be able to do and as compared to humanoids,
[00:01:44.560 --> 00:01:47.960]   these are now way cheaper than human labor.
[00:01:47.960 --> 00:01:50.520]   Like, humanoids, if you plot them on this curve,
[00:01:50.520 --> 00:01:52.240]   you'll probably not even see them at this point
[00:01:52.240 --> 00:01:54.120]   because of, like, how unreliable they are,
[00:01:54.120 --> 00:01:55.720]   how much maintenance it requires.
[00:01:55.720 --> 00:01:59.840]   But these wheeled robots with two hands, no problem.
[00:01:59.840 --> 00:02:04.440]   Way cheaper than a human, way cheaper than any human chef.
[00:02:04.440 --> 00:02:08.960]   But what's missing is actually, you know, software.
[00:02:08.960 --> 00:02:11.520]   And what we did was we took that, we took this robot,
[00:02:11.520 --> 00:02:13.120]   like I said, we put it through culinary school,
[00:02:13.120 --> 00:02:15.920]   and now we have chef-like robot labor.
[00:02:15.920 --> 00:02:19.960]   So commercial facilities can hire this robot,
[00:02:19.960 --> 00:02:22.320]   pay it hourly wages like $12 an hour.
[00:02:22.320 --> 00:02:23.240]   It'll always show up.
[00:02:23.240 --> 00:02:27.000]   No overtime, no turnover, no calling in sick.
[00:02:27.000 --> 00:02:30.040]   And just, or even better than a human,
[00:02:30.040 --> 00:02:33.360]   it plugs in place into any arbitrary novel kitchen.
[00:02:33.360 --> 00:02:36.200]   So it learns new recipes from one expert demonstration,
[00:02:36.200 --> 00:02:40.120]   and it is robust to ingredient variation, appliance variation,
[00:02:40.120 --> 00:02:42.800]   and can cook on arbitrary portion sizes.
[00:02:42.800 --> 00:02:46.320]   This is actually a task that's actually harder for humans to do, too.
[00:02:46.320 --> 00:02:49.240]   Like, when I say we put these robots through culinary school,
[00:02:49.240 --> 00:02:53.000]   what we actually do is, like, what is culinary school for a robot?
[00:02:53.000 --> 00:02:55.960]   It needs to learn all the motion primitives that come with human beings.
[00:02:55.960 --> 00:02:57.880]   So how do you pick something?
[00:02:57.880 --> 00:02:59.360]   How do you stir a pot?
[00:02:59.360 --> 00:03:02.560]   And to do that, we have these robot foundation models that we fine-tune.
[00:03:02.560 --> 00:03:07.520]   We have tele-operation to fall back for all these edge cases.
[00:03:07.520 --> 00:03:08.440]   But that's not enough.
[00:03:08.440 --> 00:03:11.320]   Like, you still need the robot to understand food.
[00:03:11.320 --> 00:03:12.920]   Like, are the onions brown enough?
[00:03:12.920 --> 00:03:16.000]   Are the onions brown enough if you're cooking steak?
[00:03:16.000 --> 00:03:18.960]   Is it, like, shrinking well enough if you're cooking shrimp?
[00:03:18.960 --> 00:03:21.480]   Do you-- can you sense when the shrimp is done?
[00:03:21.480 --> 00:03:25.000]   And these are, like, ingredients that vary seasonally, daily.
[00:03:25.000 --> 00:03:27.280]   Like, onions today might require seven minutes to saute.
[00:03:27.280 --> 00:03:29.640]   It'll require, like, nine minutes to saute tomorrow.
[00:03:29.640 --> 00:03:36.080]   And we basically have thermal and visual embeddings that are specific to cooking that help us reason
[00:03:36.080 --> 00:03:38.520]   through these, like, unseen environments.
[00:03:38.520 --> 00:03:44.600]   And we've basically modeled recipes as state machines based on these embedding models at the core.
[00:03:44.600 --> 00:03:51.040]   And now, even if-- even after you have this, the next thing that you need is--
[00:03:51.040 --> 00:03:54.320]   it needs to adapt to any new kitchen that it has never seen before.
[00:03:54.320 --> 00:04:01.240]   So it needs to be able to see a recipe once, understand what to do, and interact with real humans
[00:04:01.240 --> 00:04:04.640]   in a workflow and actually do work.
[00:04:04.640 --> 00:04:08.920]   So we put our culinary understanding to the test.
[00:04:08.920 --> 00:04:15.760]   And we, at this point, do better than even expert chefs in their cuisine of training.
[00:04:15.760 --> 00:04:21.400]   And, like, if you take-- so basically, we evolved more than 1,000 recipes across a mix of cuisines.
[00:04:21.400 --> 00:04:29.280]   We got given-- the task was given live cooking data, an expert demonstration, and a text recipe.
[00:04:29.280 --> 00:04:31.600]   Can you estimate where in the cooking process you are?
[00:04:31.600 --> 00:04:34.920]   Can you track progress like a human being?
[00:04:34.920 --> 00:04:41.920]   We put it through this expert human chefs who get paid more than $150,000 a year still perform worse than our tiny model
[00:04:41.920 --> 00:04:44.480]   that's doing perception in this case.
[00:04:44.480 --> 00:04:49.120]   And, in fact, when we put, like, state-of-the-art models like Gemini 2.5 or O3,
[00:04:49.120 --> 00:04:52.120]   they actually perform way worse than our own models.
[00:04:52.120 --> 00:04:56.400]   And that's partly because they don't have any thermal modality.
[00:04:56.400 --> 00:05:00.040]   And the thing is, thermal modality does not have internet-scale data.
[00:05:00.040 --> 00:05:18.040]   So what we did is we went and installed sensors in active commercial kitchens, collected hundreds of thousands of-- collected data worth hundreds of thousands of live cooked meals in various kitchen environments across various different recipes, cuisines, and seasons.
[00:05:18.040 --> 00:05:26.720]   So we collected this private data, we trained a model, we scraped a bunch of public data, trained some self-supervised models on that.
[00:05:26.720 --> 00:05:31.480]   And a combination of this is basically what our culinary system banks on.
[00:05:31.480 --> 00:05:38.800]   And it is what, like I said, is now way better than human chefs at just decision-making during cooking.
[00:05:38.800 --> 00:05:43.640]   But motor skills, on the other hand, it's not as good as a human, but it is getting there.
[00:05:43.640 --> 00:05:48.160]   So we, again, put it through all these different evals, sauteing.
[00:05:48.160 --> 00:05:53.600]   It's almost as fast as the human cook, picking and pouring, slightly less fast, grilling, stirring.
[00:05:53.600 --> 00:05:56.680]   So it's all a bunch of evals that we did on top of motor skills.
[00:05:56.680 --> 00:06:03.480]   And this is how-- in fact, our system is right now about 95% autonomous, 5% teleoperated.
[00:06:03.480 --> 00:06:09.960]   And it's way faster and way more reliable than just teleop or just foundation models.
[00:06:09.960 --> 00:06:16.200]   And basically, the robot comes into a kitchen, like I said, looks at a recipe once from a chef,
[00:06:16.200 --> 00:06:17.480]   and it's just able to do it.
[00:06:17.480 --> 00:06:23.400]   So for example, here, it's cooking a recipe from a two Michelin star chef who is based out of San Francisco.
[00:06:23.400 --> 00:06:28.320]   And basically, while it's cooking, it's looking at how the onions are browning.
[00:06:28.320 --> 00:06:31.320]   It's comparing it to how brown the onions were getting when the chef was cooking it.
[00:06:31.320 --> 00:06:33.800]   It takes it to the right amount of brownness.
[00:06:33.800 --> 00:06:38.600]   It knows exactly what to do for the next recipe, where the ingredients are kept.
[00:06:38.600 --> 00:06:46.920]   It's not preprogrammed to know where the ingredients are, what kind of variation you'll find.
[00:06:46.920 --> 00:06:51.160]   It is doing all that reasoning within the system itself.
[00:06:51.160 --> 00:07:00.840]   So if we go further under the recipe, we'll see how it's cooking the chicken.
[00:07:00.840 --> 00:07:05.640]   It's basically getting clean readings every single-- every few minutes.
[00:07:05.640 --> 00:07:11.640]   And at the end of it, I will basically show you what happens.
[00:07:11.640 --> 00:07:20.760]   And at the end of it, you have actual-- so these are actually recipes that go into the stomachs
[00:07:20.760 --> 00:07:21.960]   of actual real customers.
[00:07:21.960 --> 00:07:25.240]   So the robot's cooking at various different facilities at this point.
[00:07:25.240 --> 00:07:30.120]   It's deployed in the real world.
[00:07:30.120 --> 00:07:33.800]   And yeah, so it's deployed in the real world.
[00:07:33.800 --> 00:07:37.320]   It's being used in all these sorts of kitchens.
[00:07:37.320 --> 00:07:40.040]   On the right, you can see it cook recipes.
[00:07:40.040 --> 00:07:45.960]   And our in-house kitchen on the left, it's also like CCTV footage of the robot doing some operation.
[00:07:46.600 --> 00:07:47.960]   I'm not even sure.
[00:07:47.960 --> 00:07:52.840]   I just pulled it off of the CCTV before getting on stage and just pulled it up here.
[00:07:52.840 --> 00:08:01.240]   And this is video from a couple of months ago where the robot's doing regular cooking like a human being.
[00:08:01.240 --> 00:08:09.320]   And outside of our own facilities, this is how, for example, the robot's working at one of our customer's facilities,
[00:08:09.320 --> 00:08:10.760]   doing chicken wings.
[00:08:10.760 --> 00:08:15.720]   It's basically fetching the chicken wings from some place kept to the side,
[00:08:15.720 --> 00:08:18.200]   it waits for the cook to be done.
[00:08:18.200 --> 00:08:27.960]   Now it'll basically collect the cooked chicken, put it inside a bowl, and goes ahead, sauces it,
[00:08:27.960 --> 00:08:30.440]   and mixes it like a human being.
[00:08:30.440 --> 00:08:36.280]   And while doing this, a robot has-- a robot is practically a weighing scale itself.
[00:08:36.280 --> 00:08:39.640]   So it knows exactly what amount of ingredients it has put in.
[00:08:39.640 --> 00:08:41.080]   It knows how much it has stirred.
[00:08:41.080 --> 00:08:44.760]   And yeah, so basically, we are Cloud Chef.
[00:08:44.760 --> 00:08:48.440]   Like I said, at this point, we are hiring-- we are a very small team.
[00:08:48.440 --> 00:08:49.800]   We are growing super fast.
[00:08:49.800 --> 00:08:53.240]   And we are looking for people in software, ML, and robotics.
[00:08:53.240 --> 00:08:55.880]   If you know anyone, please reach out to me.
[00:08:55.880 --> 00:08:58.360]   My email address is nikio@cloudchef.co.
[00:08:58.920 --> 00:09:00.120]   And yeah, thank you.
[00:09:00.120 --> 00:09:03.000]   If any of you have any questions, I'm happy to take it.
[00:09:03.000 --> 00:09:05.320]   Thank you.
[00:09:05.320 --> 00:09:17.640]   So for us, success means two things.
[00:09:17.640 --> 00:09:21.240]   One is, how good is the robot at understanding what's happening in the cooking process?
[00:09:21.240 --> 00:09:28.840]   So a very simple intuition for that is, OK, if you give the entire cooking feed to a human being,
[00:09:28.840 --> 00:09:36.280]   and if you give the entire cooking video and infrared feed to our system, which estimates state better?
[00:09:36.280 --> 00:09:40.920]   Because once you have a cooked recipe, you can use that as labeled data to understand,
[00:09:40.920 --> 00:09:47.720]   OK, if the system predicts that this is 40% done, was it actually 40% done or was it actually 50% done?
[00:09:47.720 --> 00:09:56.760]   That's actually a supervised learning signal that we can get after we have data from recreations.
[00:09:56.760 --> 00:10:02.280]   Like any food recreation from any chef with thermal and RGB footage, we're able to do that.
[00:10:02.280 --> 00:10:07.320]   The other part is motions, like how fast is the robot able to do physical motions as
[00:10:07.320 --> 00:10:11.400]   compared to a human being, which I said, we are not as good as human beings yet.
[00:10:11.400 --> 00:10:13.240]   It's basically a data problem.
[00:10:13.240 --> 00:10:22.040]   The more data we get, the better and faster we get at doing any individual task inside the kitchen.
[00:10:22.040 --> 00:10:23.640]   Does that answer your question?
[00:10:32.200 --> 00:10:38.520]   Yeah, so for the end taste, so the thing that we realized is, as a professional,
[00:10:38.520 --> 00:10:45.720]   no professional chef is cooking to chemical, to consistency that can be measured in any chemical
[00:10:45.720 --> 00:10:52.840]   way. So our competition is not getting chemical level consistency every single time. It's about,
[00:10:52.840 --> 00:10:58.920]   it's about getting consistency to a degree that is better than a chef can do a second time. So a common
[00:10:58.920 --> 00:11:02.120]   benchmark that we do is we get a chef to cook a recipe once and then we get our
[00:11:02.120 --> 00:11:08.280]   our system, we get our robot recreated that recipe a couple of times and then we do blind taste tests.
[00:11:08.280 --> 00:11:13.480]   And so those are more unscalable evals that we do in-house, which act as a higher signal to,
[00:11:13.480 --> 00:11:22.440]   okay, actually the end product that we get is better than what chefs are able to do.
[00:11:22.440 --> 00:11:30.600]   No, it's basically just hand, uh, two hands on a mobile base, uh, with some cameras and stuff on it. It shows up at the kitchen. You basically interact with it like a human being and that's,
[00:11:30.600 --> 00:11:38.760]   the form factor. There's no additional screens, et cetera. Those are just for video's sake.
[00:11:38.760 --> 00:11:44.920]   Uh, it depends. Uh, ideally humans don't need to, but today in some deployments,
[00:11:44.920 --> 00:11:49.080]   humans do end up doing it. But our idea is that because the robot,
[00:11:49.080 --> 00:11:51.080]   we, because we have joint work,
[00:11:51.080 --> 00:11:55.240]   we, because we have joint work data from like all the different motors from the robot,
[00:11:55.240 --> 00:12:09.400]   the robot itself is a weighing scale. So when it picks up something, it already knows how heavy it is.
[00:12:09.400 --> 00:12:31.560]   So that is one thing that we've worked a lot, uh, uh, worked on a lot, uh, worked on a lot when we are able to work on arbitrary unseen appliances because our sensing stack is so good and we're able to work on it, and we're able to work on arbitrary unseen appliances because our sensing stack is so good.
[00:12:31.560 --> 00:12:39.400]   So that is one thing that we've worked a lot, uh, worked on a lot when we are able to work on arbitrary unseen appliances because our sensing stack is so good.
[00:12:39.400 --> 00:12:53.400]   And, uh, uh, the other thing is almost all appliances inside kitchens are controlled using knobs. So the motion primitive that the robot needs is to know how to turn a knob and then, uh, our control systems take care from there.
[00:12:53.400 --> 00:12:54.560]   Yeah, sir.
[00:12:54.560 --> 00:12:57.560]   That is how it is where it can move automatically.
[00:12:57.560 --> 00:12:58.560]   Yes.
[00:12:58.560 --> 00:12:59.560]   Yeah.
[00:12:59.560 --> 00:13:21.560]   So, uh, right now for most motions, we are anywhere between like 80 to 95% the speed of a human being and ideally there's nothing stopping robots from being even faster than human beings.
[00:13:21.560 --> 00:13:35.560]   It's mostly just a data problem. Right now, the reason why it's not as fast as human beings is because the data that we collect on these robots are done by human beings who teleoperate the robot.
[00:13:35.560 --> 00:13:41.560]   And because human beings teleoperating the robot are not as intuitive at teleoperating the robot as their own bodies, they're not as fast as so the data is kind of slow.
[00:13:41.560 --> 00:13:43.560]   And then over time we expect with RL and stuff, it will be faster.
[00:13:43.560 --> 00:13:57.560]   Yeah. So, uh, there's nothing stopping a robot from doing that either. It's just, we don't have data. We haven't gone out, collected data for those tasks yet. So it's just something on our roadmap. We're very much blank to that.
[00:13:57.560 --> 00:13:59.560]   Where can we eat this?
[00:13:59.560 --> 00:14:21.560]   Oh, you can eat this in Palo Alto. So if you're in San Francisco, if you order from Wingstar, that's a customer of ours who uses it. So you'll get it from there. If you're in Palo Alto, you can order from India's top 20 and you can eat it from there as well. Or if you're in Menlo Park, you can go to that.
[00:14:21.560 --> 00:14:37.560]   Uh, high-end Indian restaurant called Elan and some of the food there is also cooked by it.
[00:14:37.560 --> 00:14:50.560]   We've, uh, we've asked questions around like, uh, chopping and food preparation and whatnot and like, uh, speed of the robot. But in terms of, uh, throughput in the actual process, uh, how much of that even matters?
[00:14:50.560 --> 00:14:59.560]   Like, uh, you know, how much of the energy already goes in, you know, throughout the day into prep versus the like, uh, 90%, you know, percent or 80%.
[00:14:59.560 --> 00:15:09.560]   Like, does that matter? This is not a manufacturing facility. Uh, when it comes to servicing, like how much of the economic value is already taken care of because you have the tele operator in the back to make sure things are insured.
[00:15:09.560 --> 00:15:16.560]   Have you guys found that meaningful or is that not a big deal at all and not a, like, is that trivial essentially at this point?
[00:15:16.560 --> 00:15:24.560]   Great question. So basically what, uh, the quick answer to that is about 50% of the labor costs inside any kitchen is line cooking labor.
[00:15:24.560 --> 00:15:41.560]   And that's where we are going at first. And the advantage there, I mean, uh, speed does play a factor, but there's another, uh, variable that we have in our control, which is, we are able to speed up recipes, uh, more than any human being is able to do.
[00:15:41.560 --> 00:15:46.560]   Because we know exactly like we've had several instances where we've recorded risk.
[00:15:46.560 --> 00:15:51.560]   Like we've observed the chef in motion and realized that, Oh, this process that takes them 20 minutes to do can actually be done in 14 minutes.
[00:15:51.560 --> 00:15:56.560]   So if the robot does even like 10% slower, it doesn't really matter. That's how it works.
[00:15:56.560 --> 00:15:57.560]   Yeah.
[00:15:57.560 --> 00:16:06.560]   Unlike a human being who, uh, after working 40 hours a week, uh, goes into overtime treasury, robot can work for like one minute.
[00:16:06.560 --> 00:16:16.560]   168 hours. Like there's nothing stopping robot from working for 24 seven.
[00:16:16.560 --> 00:16:20.560]   The practical constraint is most facilities don't operate 24 hours.
[00:16:20.560 --> 00:16:25.560]   So the robot will operate as long as the facility is operating. And then there are some tasks that you can do overnight.
[00:16:25.560 --> 00:16:30.560]   So once we get into cutting, chopping, et cetera, the robot will just be doing that overnight before the actual stuff comes in.
[00:16:30.560 --> 00:16:40.560]   Sorry, mine was kind of related to before. So did this, did you find new bottlenecks and things like dishwashing or cross contamination stuff that you maybe weren't expecting to deal with this process?
[00:16:40.560 --> 00:16:55.560]   So dish washing, et cetera, not that much. And even for things that cross contamination, we just put small gloves on the robot and then like our customers switch that out every day.
[00:16:55.560 --> 00:16:58.560]   They were these are washable, small silicone.
[00:16:58.560 --> 00:17:20.560]   I can pull up the video on that. But basically that's how we take care of it. And then, uh, for things like dishwashing, those are not tasks that we are envisioning doing in the short term.
[00:17:20.560 --> 00:17:27.560]   We want to do more of the tasks that actually add to the quality of the food that's being put out.
[00:17:27.560 --> 00:17:34.560]   So that's why we are mostly focused on line cooking for now, maybe sometime later, like prepping, chopping, et cetera.
[00:17:34.560 --> 00:17:35.560]   Last question.
[00:17:35.560 --> 00:17:38.560]   Oh, yeah. Sorry.
[00:17:38.560 --> 00:17:43.560]   Um, so there was, uh, it learns from chefs, right? The recipes from chefs.
[00:17:43.560 --> 00:17:48.560]   Is it able to modify steps of a recipe to cook things faster?
[00:17:48.560 --> 00:17:56.560]   So that is still an experimental phase. There are cuisines in which we are able to do this really well, but we aren't yet able to do this across all cuisines.
[00:17:56.560 --> 00:18:03.560]   So for cuisines for the thermodynamics modeling of what's happening in the process is straightforward.
[00:18:03.560 --> 00:18:12.560]   It is much more easier to, uh, basically like, uh, uh, like speed recipes up, uh, do minor variations, et cetera.
[00:18:12.560 --> 00:18:20.560]   And there are some cases where it's not that easy. It's a little, it, it is still like experimental territory. We're still working on that.
[00:18:20.560 --> 00:18:43.560]   Uh, uh, in the current version, it alerts somebody in the facility that the robot needs ingredients to work and then they, they take care of it.
[00:18:43.560 --> 00:18:52.560]   Hopefully once there are enough robots in the facility, they'll just talk to each other and, uh, uh, thank you so much.
[00:18:52.560 --> 00:18:53.560]   We'll see you next time.
[00:18:53.560 --> 00:18:53.560]   We'll see you next time.
[00:18:53.560 --> 00:18:53.560]   Bye.
[00:18:53.560 --> 00:18:54.560]   Bye.
[00:18:54.560 --> 00:18:57.680]   We'll be right back.

