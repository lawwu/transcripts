
[00:00:00.000 --> 00:00:06.440]   The goal of this video is simply to show you 7 AI advances that you might have missed this week.
[00:00:06.440 --> 00:00:11.440]   Sam Altman recently said that in a world of AGI, everything happens much faster.
[00:00:11.440 --> 00:00:17.520]   But as far as I can see, AI developments are already almost impossible for a human to keep up with.
[00:00:17.520 --> 00:00:20.740]   So, in no particular order, let's get started.
[00:00:20.740 --> 00:00:24.220]   First, video calls look like they're about to get 3D.
[00:00:24.220 --> 00:00:31.180]   Let's take a look at how NVIDIA Aerial and NVIDIA Maxine 3D, running on the NVIDIA Grace Hopper Super Chip,
[00:00:31.180 --> 00:00:36.880]   can enable 3D video conferencing on any device without specialized software or hardware.
[00:00:36.880 --> 00:00:41.820]   This brings a new dimension to video conferencing with Maxine 3D visualization.
[00:00:41.820 --> 00:00:45.700]   Engage with others more directly with enhanced eye contact.
[00:00:45.700 --> 00:00:52.200]   And personalize your experience with animated avatars, stylizing them with simple text prompts.
[00:00:52.200 --> 00:00:53.600]   And it isn't just NVIDIA.
[00:00:53.600 --> 00:00:54.200]   Here's Google.
[00:00:54.200 --> 00:00:56.740]   Google's new Project Starline prototype.
[00:00:56.740 --> 00:01:01.200]   You know, you were so used to seeing a two-dimensional little, you know, box.
[00:01:01.200 --> 00:01:03.020]   And then we're connecting like this.
[00:01:03.020 --> 00:01:08.680]   And that feeling of being in front of a person is now replicated in Starline.
[00:01:08.680 --> 00:01:15.180]   Speaking of connecting the world, here is GPT-4 doing geography in a paper you might have missed from this week.
[00:01:15.180 --> 00:01:18.260]   The paper proves that even without access to the internet,
[00:01:18.260 --> 00:01:23.460]   GPT-4 knows a lot more granular detail about the world than you might first imagine.
[00:01:23.460 --> 00:01:23.780]   I'm not saying that it's a bad thing.
[00:01:23.780 --> 00:01:26.880]   I'm not saying it knows where you live, but it's not too far off.
[00:01:26.880 --> 00:01:27.920]   Take this example.
[00:01:27.920 --> 00:01:33.120]   It could recreate the Hong Kong Mass Transit Railway from memorization.
[00:01:33.120 --> 00:01:35.080]   This wasn't through using web browsing.
[00:01:35.080 --> 00:01:42.740]   It could recreate this diagram, giving the latitude and longitude coordinates of each of the stations in this transit line.
[00:01:42.740 --> 00:01:47.840]   Obviously, it's not perfect, but it's pretty incredible that it's got this mental map of the world.
[00:01:47.840 --> 00:01:50.060]   GPT-4 can do elevations as well.
[00:01:50.060 --> 00:01:53.080]   And here is it trying to recreate the topography of the atmosphere.
[00:01:53.080 --> 00:01:53.360]   And here's the map.
[00:01:53.360 --> 00:01:55.300]   It gets pretty close.
[00:01:55.300 --> 00:01:59.160]   One of the ways they tested GPT-4 was to ask it something like this.
[00:01:59.160 --> 00:02:04.020]   Please provide the latitude-longitude coordinates for the outline of X,
[00:02:04.020 --> 00:02:06.900]   where X was a continent or a river or a country,
[00:02:06.900 --> 00:02:12.040]   as a Python list of tuples consisting of approximately 50 points arranged clockwise.
[00:02:12.040 --> 00:02:16.760]   And they describe how it did really well for quite a few countries and rivers,
[00:02:16.760 --> 00:02:18.880]   but kind of flopped on Africa.
[00:02:18.880 --> 00:02:23.340]   But honestly, when I read this paper, I was skeptical that GPT-4 knew that list,
[00:02:23.340 --> 00:02:24.300]   because it was a little about Africa.
[00:02:24.300 --> 00:02:28.160]   So I gave this exact question to GPT-4 with Code Interpreter.
[00:02:28.160 --> 00:02:31.880]   Now, interestingly, it would sometimes deny that it had the ability to do this,
[00:02:31.880 --> 00:02:35.260]   but with enough encouragement, it outputted these coordinates.
[00:02:35.260 --> 00:02:38.180]   And here is the end result in Google Earth.
[00:02:38.180 --> 00:02:40.400]   I think that's a pretty impressive outline.
[00:02:40.400 --> 00:02:46.640]   Obviously, a few points are a bit off, like this point here isn't really on the coast, nor is this point.
[00:02:46.640 --> 00:02:50.660]   But it really knows the outlines of countries, continents, rivers.
[00:02:50.660 --> 00:02:53.320]   So I'm not sure if Code Interpreter had an impact there,
[00:02:53.320 --> 00:02:58.400]   or a model update, but the researchers kind of underplayed what GPT-4 could do
[00:02:58.400 --> 00:03:00.720]   by presenting this outline of Africa.
[00:03:00.720 --> 00:03:02.900]   Now, I am sure that some of you are thinking,
[00:03:02.900 --> 00:03:05.120]   that's not that interesting, not that impressive.
[00:03:05.120 --> 00:03:06.420]   But check this out.
[00:03:06.420 --> 00:03:10.540]   In an indirect kind of way, GPT-4 knows where it was made.
[00:03:10.540 --> 00:03:15.140]   It was able to construct a map of the semiconductor supply chain.
[00:03:15.140 --> 00:03:18.980]   It not only knows about the design, manufacturing materials, equipment,
[00:03:18.980 --> 00:03:22.740]   and tools that go into the hardware that helps make GPT-4,
[00:03:22.740 --> 00:03:23.300]   it also knows about the design of the hardware that helps make GPT-4.
[00:03:23.300 --> 00:03:26.220]   It also knows the locations of where this is all done.
[00:03:26.220 --> 00:03:28.020]   And as the authors later say,
[00:03:28.020 --> 00:03:33.840]   looking to the future, if frontier models beyond GPT-4 continue to advance in capabilities,
[00:03:33.840 --> 00:03:37.960]   the geographic knowledge and planning abilities present in the current model
[00:03:37.960 --> 00:03:43.960]   may later evolve to represent a significant risk through misuse or misalignment.
[00:03:43.960 --> 00:03:47.880]   On a much less important note, did you notice how I could do this demo
[00:03:47.880 --> 00:03:50.860]   without that sidebar of all my previous chats?
[00:03:50.860 --> 00:03:53.120]   That's because OpenAI have brought in this new button.
[00:03:53.280 --> 00:03:55.800]   You can see the chat here where you can hide the chats.
[00:03:55.800 --> 00:04:01.580]   And as a bonus, some of you may not know that you can now share a link of the chats that you've already done
[00:04:01.580 --> 00:04:03.440]   just by clicking that button to the left.
[00:04:03.440 --> 00:04:07.340]   And as it says, messages you send after creating your link won't be shared.
[00:04:07.340 --> 00:04:09.900]   So if you carry on the conversation, people won't be able to see.
[00:04:09.900 --> 00:04:13.880]   But anyone with the URL will be able to view the shared chats.
[00:04:13.880 --> 00:04:19.380]   But before we move on from OpenAI and ChatGPT, I did find this table really quite interesting.
[00:04:19.380 --> 00:04:23.060]   It gives the daily average number of visits to each of these sites,
[00:04:23.260 --> 00:04:25.140]   along with the visit duration.
[00:04:25.140 --> 00:04:27.720]   And there's two things that strike me from this table.
[00:04:27.720 --> 00:04:31.940]   The first is how much more popular ChatGPT is compared to Google's BARD.
[00:04:31.940 --> 00:04:36.480]   It's got about 15 times the number of visitors who stay for about twice as long.
[00:04:36.480 --> 00:04:39.820]   But look at the dark horse on the right, Character AI.
[00:04:39.820 --> 00:04:42.320]   I've talked about them a couple of times before.
[00:04:42.320 --> 00:04:47.700]   And while their daily average visit total isn't too crazy, look at the visit duration.
[00:04:47.700 --> 00:04:52.440]   In terms of grabbing people's attention and keeping it, they are truly a dark horse.
[00:04:52.440 --> 00:04:53.240]   Next, I want to talk about the number of visits to each of these sites.
[00:04:53.240 --> 00:04:56.120]   I want to briefly dip into augmented reality.
[00:04:56.120 --> 00:04:59.800]   We are going to be creating our own worlds and living in them.
[00:04:59.800 --> 00:05:04.800]   Some people, like in this video, might choose to live their lives as if they were in an animation.
[00:05:04.800 --> 00:05:10.920]   Others might see augmented reality as a way of augmenting their intelligence or memory live.
[00:05:10.920 --> 00:05:19.680]   My prediction would be that wearables that resemble things like Google Glass might flop.
[00:05:19.680 --> 00:05:23.220]   But something like an always-on app on your phone mediated through Gmail
[00:05:23.220 --> 00:05:28.680]   could become really popular or even enforced in certain workplace settings.
[00:05:28.680 --> 00:05:33.300]   All of this reminded me of a recent video about conducting a video interview with help
[00:05:33.300 --> 00:05:34.740]   from GPT 3.5.
[00:05:34.740 --> 00:05:37.840]   What about your development areas?
[00:05:37.840 --> 00:05:43.020]   What do you have identified as your greatest and biggest improvement areas?
[00:05:43.020 --> 00:05:46.100]   And what have you done to improve them so far?
[00:05:46.100 --> 00:05:52.540]   I would say my greatest development area is my communication skills.
[00:05:52.540 --> 00:05:53.200]   I work on improving my communication skills.
[00:05:53.200 --> 00:05:58.320]   I'm improving my ability to clearly convey my thoughts and ideas to others.
[00:05:58.320 --> 00:06:03.640]   Of course at the moment this is only really viable with GPT 3.5 because of inference speed.
[00:06:03.640 --> 00:06:08.360]   But OpenAI are aggressively planning a cheaper and faster GPT 4.
[00:06:08.360 --> 00:06:13.580]   I wouldn't be surprised if video interviewers soon require you to take out any headphones.
[00:06:13.580 --> 00:06:18.320]   Although I guess with Maxine 3D you could maintain eye contact with the camera while
[00:06:18.320 --> 00:06:21.860]   you're actually reading off a GPT 4 teleprompter.
[00:06:21.860 --> 00:06:23.180]   Anyway what about gaming?
[00:06:23.180 --> 00:06:29.220]   This is Nvidia's Neuralangelo where you can take a 2D video and turn it into a detailed
[00:06:29.220 --> 00:06:31.720]   3D landscape with high fidelity.
[00:06:31.720 --> 00:06:36.080]   My first thought turned into imagining the kind of things you could then bring into games
[00:06:36.080 --> 00:06:38.260]   using Unreal Engine 5.
[00:06:38.260 --> 00:06:42.140]   This is a recently trailered horror game, link in the description, but don't worry I'm
[00:06:42.140 --> 00:06:44.240]   only going to show you 2 or 3 seconds of it.
[00:06:44.240 --> 00:06:47.500]   It's getting to the point where it's quite hard to believe that this is a game, but it
[00:06:47.500 --> 00:06:48.500]   is.
[00:06:48.500 --> 00:06:52.500]   And on games don't forget this, look at the realism that can now be achieved in terms
[00:06:52.500 --> 00:06:53.160]   of skin technology.
[00:06:53.160 --> 00:06:54.640]   The texture and movement.
[00:06:54.640 --> 00:06:59.980]   For the final bit of AI news that you might have missed, I want to focus on AI drug discovery.
[00:06:59.980 --> 00:07:08.140]   I think there's no question that there is a before and after in drug discovery and one
[00:07:08.140 --> 00:07:09.660]   of them is AI.
[00:07:09.660 --> 00:07:14.420]   Alan Espuruguzic is the director of the University of Toronto's Acceleration Consortium which
[00:07:14.420 --> 00:07:20.760]   in April 2023 received a $200 million grant to build an AI powered self-driving lab.
[00:07:20.760 --> 00:07:23.140]   The Acceleration Consortium has already been using AI.
[00:07:23.140 --> 00:07:27.480]   To help discover molecules that have potential drug-like traits that can be used to develop
[00:07:27.480 --> 00:07:28.480]   life-saving treatments.
[00:07:28.480 --> 00:07:33.240]   Developing a drug can be up to a decade and this is just the discovery piece.
[00:07:33.240 --> 00:07:37.960]   So that process let's say takes a year or two and we compress it to 45 days in that
[00:07:37.960 --> 00:07:40.920]   case and then 30 days recently.
[00:07:40.920 --> 00:07:46.060]   In January 2023 the Acceleration Consortium used an AI powered protein structure database
[00:07:46.060 --> 00:07:51.120]   called AlphaFold to design and synthesize a possible liver cancer drug in just 30 days.
[00:07:51.120 --> 00:07:53.120]   Within two weeks we can formulate a new drug.
[00:07:53.120 --> 00:07:55.920]   We can create a new drug as well as some people have done it in years.
[00:07:55.920 --> 00:07:59.180]   Suddenly AI has surpassed any human created algorithm.
[00:07:59.180 --> 00:08:03.560]   AI what allows us to do is lower the bar of what you need to do certain things and therefore
[00:08:03.560 --> 00:08:05.460]   more and more people will have access to it.
[00:08:05.460 --> 00:08:08.100]   In general unleashing more innovation in the planet.
[00:08:08.100 --> 00:08:14.800]   Same token, someone with nefarious intentions could unleash very dangerous, deadly chemicals
[00:08:14.800 --> 00:08:15.800]   on the world.
[00:08:15.800 --> 00:08:16.800]   Absolutely.
[00:08:16.800 --> 00:08:22.200]   I am an optimist but I'm also aware of these pitfalls that very soon will face us.
[00:08:22.200 --> 00:08:23.100]   And videos like that are not just for the people.
[00:08:23.100 --> 00:08:24.100]   They are for the people.
[00:08:24.100 --> 00:08:27.840]   And that is why I agree with Sam Altman when he says a much faster rate of change is his
[00:08:27.840 --> 00:08:32.940]   single highest confidence prediction about what a world with AGI in it will be like.
[00:08:32.940 --> 00:08:39.040]   I follow AI news full time and can barely keep up so I can only imagine what the situation
[00:08:39.040 --> 00:08:41.920]   will be like when we get full AGI.
[00:08:41.920 --> 00:08:46.780]   But until the very last moment that it's humanly possible to keep up with the news I will try.
[00:08:46.780 --> 00:08:50.540]   So thank you so much for watching to the end and have a wonderful day.

