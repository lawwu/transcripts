
[00:00:00.000 --> 00:00:03.120]   If you have a democratic style of governance,
[00:00:03.120 --> 00:00:06.720]   you are entrusting people with one of the most awesome
[00:00:06.720 --> 00:00:08.360]   and radical of responsibilities.
[00:00:08.360 --> 00:00:10.400]   And that's saying that you're going to pick the people
[00:00:10.400 --> 00:00:11.960]   that are gonna make some of the hardest decisions
[00:00:11.960 --> 00:00:13.220]   in all of human history.
[00:00:13.220 --> 00:00:15.960]   If you're gonna trust people to vote correctly,
[00:00:15.960 --> 00:00:17.200]   you have to be able to trust them
[00:00:17.200 --> 00:00:19.020]   to have open and honest dialogue with each other.
[00:00:19.020 --> 00:00:22.720]   Whether that's Nazis or KKK people or whoever talking,
[00:00:22.720 --> 00:00:24.720]   you have to believe that your people
[00:00:24.720 --> 00:00:26.080]   are going to be able to rise above
[00:00:26.080 --> 00:00:27.580]   and make the correct determinations
[00:00:27.580 --> 00:00:29.360]   when they hear these types of speeches.
[00:00:29.360 --> 00:00:32.040]   And if you're so worried that somebody is gonna hear
[00:00:32.040 --> 00:00:33.120]   a certain political figure
[00:00:33.120 --> 00:00:35.280]   and they're gonna be completely radicalized instantly,
[00:00:35.280 --> 00:00:36.120]   then what that tells me
[00:00:36.120 --> 00:00:38.120]   is that you don't have enough faith in humans
[00:00:38.120 --> 00:00:41.000]   for democracy to be a viable institution, which is fine.
[00:00:41.000 --> 00:00:42.320]   You can be anti-democratic,
[00:00:42.320 --> 00:00:44.160]   but I don't think you can be pro-democracy
[00:00:44.160 --> 00:00:45.520]   and anti-free speech.
[00:00:45.520 --> 00:00:51.360]   - The following is a conversation with Stephen Bunnell,
[00:00:51.360 --> 00:00:53.560]   also known online as Destiny.
[00:00:53.560 --> 00:00:56.720]   He's a video game streamer and political commentator,
[00:00:56.720 --> 00:00:58.040]   one of the early pioneers
[00:00:58.040 --> 00:00:59.680]   of both live streaming in general
[00:00:59.680 --> 00:01:02.720]   and live streamed political debate and discourse.
[00:01:02.720 --> 00:01:05.220]   Politically, he is a progressive,
[00:01:05.220 --> 00:01:08.040]   identifying as either left or far left,
[00:01:08.040 --> 00:01:10.020]   depending on your perspective.
[00:01:10.020 --> 00:01:12.880]   There are many reasons I wanted to talk to Stephen.
[00:01:12.880 --> 00:01:14.920]   First, I just talked to Ben Shapiro
[00:01:14.920 --> 00:01:16.600]   and many people have told me
[00:01:16.600 --> 00:01:20.360]   that Stephen is the Ben Shapiro of the left
[00:01:20.360 --> 00:01:22.040]   in terms of political perspective
[00:01:22.040 --> 00:01:24.920]   and exceptional debate skills.
[00:01:24.920 --> 00:01:28.000]   Second reason is he skillfully defends
[00:01:28.000 --> 00:01:31.040]   some nuanced non-standard views,
[00:01:31.040 --> 00:01:33.360]   at the same time being pro-establishment,
[00:01:33.360 --> 00:01:35.640]   pro-institutions and pro-Biden,
[00:01:35.640 --> 00:01:39.460]   while also being pro-capitalism and pro-free speech.
[00:01:39.460 --> 00:01:43.380]   Third reason is he has been there at the beginning
[00:01:43.380 --> 00:01:45.560]   and throughout the meteoric rise
[00:01:45.560 --> 00:01:48.080]   of the video game live streaming community.
[00:01:48.080 --> 00:01:50.040]   In some mainstream circles,
[00:01:50.040 --> 00:01:52.700]   this community is not taken seriously,
[00:01:52.700 --> 00:01:55.720]   perhaps because of its demographic distribution
[00:01:55.720 --> 00:01:56.920]   skewing young,
[00:01:56.920 --> 00:01:59.840]   or perhaps because of the sometimes harsh style
[00:01:59.840 --> 00:02:01.600]   of communication.
[00:02:01.600 --> 00:02:05.280]   But I think this community should be taken seriously
[00:02:05.280 --> 00:02:07.200]   and shown respect.
[00:02:07.200 --> 00:02:08.840]   Millions of young minds tune in
[00:02:08.840 --> 00:02:11.480]   to live streams like Destiny's to question
[00:02:11.480 --> 00:02:14.280]   and to try to understand what is going on with the world,
[00:02:14.280 --> 00:02:18.180]   often exploring challenging, even controversial ideas.
[00:02:18.180 --> 00:02:19.940]   The language is sometimes harsher
[00:02:19.940 --> 00:02:22.880]   and the humor sometimes meaner than I would prefer.
[00:02:22.880 --> 00:02:27.380]   But I, Grandpa Lex, put on my rain boots
[00:02:27.380 --> 00:02:29.540]   and went into the beautiful chaotic muck
[00:02:29.540 --> 00:02:31.160]   of online discourse,
[00:02:31.160 --> 00:02:34.120]   and have so far survived to tell the tale,
[00:02:34.120 --> 00:02:37.960]   with a smile and even more love in my heart than before.
[00:02:37.960 --> 00:02:40.640]   On top of all this,
[00:02:40.640 --> 00:02:43.480]   we were lucky to have Malina Gorinson,
[00:02:43.480 --> 00:02:45.880]   a popular streamer and world traveler,
[00:02:45.880 --> 00:02:48.040]   join us at the end of the conversation.
[00:02:48.040 --> 00:02:52.100]   You can check out her channel on twitch.tv/malina,
[00:02:52.100 --> 00:02:54.180]   and you can check out Stephen's channel
[00:02:54.180 --> 00:02:57.100]   on youtube.com/destiny.
[00:02:57.100 --> 00:02:59.140]   This is the Lex Friedman Podcast.
[00:02:59.140 --> 00:02:59.980]   To support it,
[00:02:59.980 --> 00:03:02.460]   please check out our sponsors in the description.
[00:03:02.460 --> 00:03:05.200]   And now, dear friends, here's Destiny.
[00:03:05.200 --> 00:03:08.020]   - I don't know if you watched me watching your
[00:03:08.020 --> 00:03:09.300]   yay interview.
[00:03:09.300 --> 00:03:10.820]   - Yeah, thank you so much for-
[00:03:10.820 --> 00:03:11.700]   - I'm so curious,
[00:03:11.700 --> 00:03:14.500]   when you're navigating a conversation like that,
[00:03:14.500 --> 00:03:16.740]   are you, how intentional is the thought process
[00:03:16.740 --> 00:03:19.520]   between building rapport and pushing
[00:03:19.520 --> 00:03:21.160]   and giving a little and letting-
[00:03:21.160 --> 00:03:23.180]   - Zero, zero intention.
[00:03:23.180 --> 00:03:24.680]   I was watching, and thank you so much.
[00:03:24.680 --> 00:03:26.960]   It was very kind for you to review that conversation.
[00:03:26.960 --> 00:03:30.280]   It meant a lot that you were complimentary in parts,
[00:03:30.280 --> 00:03:32.240]   on the technical aspects of the conversation,
[00:03:32.240 --> 00:03:33.360]   but no, zero.
[00:03:33.360 --> 00:03:37.560]   And I'm actually deliberately trying to avoid,
[00:03:37.560 --> 00:03:39.460]   I think you've called it debate brain,
[00:03:39.460 --> 00:03:45.560]   which is just another flavor of thinking about
[00:03:45.800 --> 00:03:47.180]   like the meta conversation,
[00:03:47.180 --> 00:03:50.440]   trying to optimize how should this conversation go?
[00:03:50.440 --> 00:03:53.620]   Because I feel like the more you do that,
[00:03:53.620 --> 00:03:55.620]   the better you get at that,
[00:03:55.620 --> 00:03:57.780]   the less human connection you have.
[00:03:57.780 --> 00:03:59.980]   Like the less genuinely you're actually sitting there
[00:03:59.980 --> 00:04:01.820]   in the moment and listening to the person,
[00:04:01.820 --> 00:04:04.300]   you're more like calculating what's the right thing to say,
[00:04:04.300 --> 00:04:08.180]   versus like feeling what is that person feeling right now?
[00:04:08.180 --> 00:04:09.260]   What are they thinking?
[00:04:09.260 --> 00:04:10.180]   That's what I'm trying to do,
[00:04:10.180 --> 00:04:13.780]   is like putting myself in their mind and thinking,
[00:04:13.780 --> 00:04:15.580]   what does the world look like to them?
[00:04:15.580 --> 00:04:17.920]   What does the world feel like to them?
[00:04:17.920 --> 00:04:20.440]   And so from that, I truly try to listen.
[00:04:20.440 --> 00:04:22.280]   Now I'm also learning,
[00:04:22.280 --> 00:04:25.200]   especially 'cause Rogan and others have been giving me shit
[00:04:25.200 --> 00:04:26.960]   for not pushing back.
[00:04:26.960 --> 00:04:28.580]   It's good sometimes to say,
[00:04:28.580 --> 00:04:32.600]   from a place of care for the other human being,
[00:04:32.600 --> 00:04:33.840]   to say stop.
[00:04:33.840 --> 00:04:36.160]   What did you just say?
[00:04:36.160 --> 00:04:39.400]   I don't think that represents who you are,
[00:04:39.400 --> 00:04:40.760]   and what you really mean.
[00:04:40.760 --> 00:04:45.460]   Or maybe if it does at that time represents who they are,
[00:04:45.460 --> 00:04:48.560]   I can see a better world
[00:04:48.560 --> 00:04:50.120]   if they grow into a different direction,
[00:04:50.120 --> 00:04:52.160]   try to point that direction out to them.
[00:04:52.160 --> 00:04:53.640]   - There's a really complicated dance
[00:04:53.640 --> 00:04:56.620]   between letting somebody share their full story,
[00:04:56.620 --> 00:04:58.080]   versus letting somebody like,
[00:04:58.080 --> 00:05:00.560]   essentially I guess like proselytize your audience.
[00:05:00.560 --> 00:05:02.640]   And it's like, okay, hold on, let's take him in here.
[00:05:02.640 --> 00:05:06.200]   But yeah, I used to be four or five years ago,
[00:05:06.200 --> 00:05:08.040]   it was attack, attack, attack, attack, attack,
[00:05:08.040 --> 00:05:09.080]   whatever you said.
[00:05:09.080 --> 00:05:10.960]   And now I'm leaning way more towards the like,
[00:05:10.960 --> 00:05:12.560]   okay, well, tell me how you feel about everything,
[00:05:12.560 --> 00:05:13.400]   and then we'll go from there.
[00:05:13.400 --> 00:05:15.360]   So a lot of people like my new approach,
[00:05:15.360 --> 00:05:16.760]   some older fans will watch and they're like,
[00:05:16.760 --> 00:05:18.140]   why are you letting this guy just ramble on?
[00:05:18.140 --> 00:05:20.020]   You know he said like five or six wrong things,
[00:05:20.020 --> 00:05:21.340]   and you're only gonna call him out on two of them.
[00:05:21.340 --> 00:05:23.720]   And it's like, it's just different styles of conversation.
[00:05:23.720 --> 00:05:24.560]   But yeah.
[00:05:24.560 --> 00:05:26.320]   - Do you do a lot of research beforehand too?
[00:05:26.320 --> 00:05:27.540]   - Depending on the conversation, yeah.
[00:05:27.540 --> 00:05:29.120]   So if we're gonna talk like vaccines and stuff,
[00:05:29.120 --> 00:05:30.940]   yeah, that's a ton of reading and stuff
[00:05:30.940 --> 00:05:33.680]   that I never thought I'd know going into it.
[00:05:33.680 --> 00:05:34.520]   If it's a more personal,
[00:05:34.520 --> 00:05:36.200]   like political philosophy conversation,
[00:05:36.200 --> 00:05:37.320]   there's not as much you can prepare for,
[00:05:37.320 --> 00:05:39.320]   just it truly depends on the conversation.
[00:05:39.320 --> 00:05:42.080]   - How much are you actually listening to the other person?
[00:05:42.080 --> 00:05:43.440]   - I'm always listening, you have to listen.
[00:05:43.440 --> 00:05:44.440]   'Cause as soon as you stop listening,
[00:05:44.440 --> 00:05:46.320]   the quality of everything falls apart.
[00:05:46.320 --> 00:05:47.200]   The connection disappears,
[00:05:47.200 --> 00:05:49.080]   the quality of the conversation disappears.
[00:05:49.080 --> 00:05:52.360]   But my natural inclination is to just be way more aggressive
[00:05:52.360 --> 00:05:54.520]   than normal, so I have to constantly remind myself,
[00:05:54.520 --> 00:05:55.960]   I guess you would call it a meta conversation,
[00:05:55.960 --> 00:05:56.800]   where you're like, okay,
[00:05:56.800 --> 00:05:58.160]   he's probably saying this because of that,
[00:05:58.160 --> 00:06:00.220]   or we'll let him go here and then we'll stop later.
[00:06:00.220 --> 00:06:03.440]   But yeah, 'cause my preferred style of conversation
[00:06:03.440 --> 00:06:04.520]   is like, I'm gonna talk,
[00:06:04.520 --> 00:06:06.280]   and the second I say something you disagree with,
[00:06:06.280 --> 00:06:08.440]   then let's iron it out, right?
[00:06:08.440 --> 00:06:10.120]   I got like, I think I'm like syllogisms,
[00:06:10.120 --> 00:06:13.200]   like, okay, here's premise A, good, okay.
[00:06:13.200 --> 00:06:15.320]   Premise B, okay, and then conclusion.
[00:06:15.320 --> 00:06:17.300]   And then as long as we're both deductively sound,
[00:06:17.300 --> 00:06:18.680]   we're not crazy, no psychosis,
[00:06:18.680 --> 00:06:20.320]   then we're gonna agree on everything.
[00:06:20.320 --> 00:06:21.440]   Whereas other people like to,
[00:06:21.440 --> 00:06:23.480]   most people think in stories, like narratives,
[00:06:23.480 --> 00:06:25.060]   like a whole, there's a whole narrative,
[00:06:25.060 --> 00:06:27.280]   and the individual facts don't matter as much,
[00:06:27.280 --> 00:06:28.520]   'cause they'll pick and choose what they want.
[00:06:28.520 --> 00:06:31.080]   And it's really hard, 'cause everybody thinks narratives
[00:06:31.080 --> 00:06:32.680]   have to function in that world.
[00:06:32.680 --> 00:06:34.800]   But it's frustrating for me sometimes.
[00:06:34.800 --> 00:06:37.720]   - Well, I've seen, you've had a lot of excellent debates.
[00:06:37.720 --> 00:06:39.680]   One of them I just recently, last night,
[00:06:39.680 --> 00:06:42.680]   watched is on systemic racism.
[00:06:42.680 --> 00:06:44.920]   And it's the first time I've seen you
[00:06:44.920 --> 00:06:46.360]   completely lose your shit.
[00:06:46.360 --> 00:06:47.800]   - Oh, shoot, who was that against?
[00:06:47.800 --> 00:06:50.360]   - I'm not sure exactly, but you were just very frustrated.
[00:06:50.360 --> 00:06:52.440]   Sorry, not lose your shit, but you were frustrated,
[00:06:52.440 --> 00:06:55.000]   constantly, because of the thing, let's lay out one, two,
[00:06:55.000 --> 00:06:57.880]   three, and every time you try to lay it out,
[00:06:57.880 --> 00:06:59.300]   it would falter.
[00:06:59.300 --> 00:07:01.160]   I think it had to do with sort of,
[00:07:01.160 --> 00:07:03.560]   can you use data to make an argument,
[00:07:03.560 --> 00:07:04.920]   or do you need to use a study
[00:07:04.920 --> 00:07:07.320]   that does an interpretation of that data?
[00:07:07.320 --> 00:07:09.200]   And then there's like this tension between,
[00:07:09.200 --> 00:07:11.000]   I think this is a behavioral economist
[00:07:11.000 --> 00:07:12.360]   that you were talking to.
[00:07:12.360 --> 00:07:14.800]   The point is, you do this kind of nice layout
[00:07:14.800 --> 00:07:16.400]   that the whole point of behavioral economics,
[00:07:16.400 --> 00:07:19.080]   it says there's more to it than just the data.
[00:07:19.080 --> 00:07:22.240]   You have to give a context and do the rich,
[00:07:22.240 --> 00:07:24.520]   rigorous interpretation in the context
[00:07:24.520 --> 00:07:26.120]   of the full human story.
[00:07:26.120 --> 00:07:27.800]   And then there was like a dance back and forth.
[00:07:27.800 --> 00:07:29.440]   Sometimes you use data, sometimes not,
[00:07:29.440 --> 00:07:32.480]   and you were getting really frustrated and shutting down.
[00:07:32.480 --> 00:07:34.600]   And so that felt like a failure mode.
[00:07:34.600 --> 00:07:37.560]   I've seen Sam Harris have similar sticking points.
[00:07:37.560 --> 00:07:40.880]   Like if we can't agree on the terminology, we can't go on.
[00:07:40.880 --> 00:07:43.000]   To me, I feel like,
[00:07:43.000 --> 00:07:47.760]   the Wittgenstein perspective is like,
[00:07:47.760 --> 00:07:51.240]   I think if you get stuck on any one thing,
[00:07:51.240 --> 00:07:52.480]   you're just not gonna make progress.
[00:07:52.480 --> 00:07:55.840]   You have to, part of the conversation has to be
[00:07:55.840 --> 00:08:00.520]   about doing a good dance together
[00:08:00.520 --> 00:08:05.840]   versus being dogmatically stuck on the path to truth.
[00:08:05.840 --> 00:08:08.560]   - I think the true challenge is identifying
[00:08:08.560 --> 00:08:10.880]   what of those sticking points are important
[00:08:10.880 --> 00:08:14.840]   versus what is not important.
[00:08:14.840 --> 00:08:16.200]   It's like if I'm having an argument with somebody
[00:08:16.200 --> 00:08:18.840]   about Jewish representation in media,
[00:08:18.840 --> 00:08:21.240]   it might be a big conversation
[00:08:21.240 --> 00:08:23.000]   and they might say a couple things.
[00:08:23.000 --> 00:08:24.360]   Like I think Jewish people,
[00:08:24.360 --> 00:08:25.640]   they tend to help their own or whatever.
[00:08:25.640 --> 00:08:26.800]   And it's like, "Yeah, okay."
[00:08:26.800 --> 00:08:28.280]   But for the purpose of the conversation,
[00:08:28.280 --> 00:08:29.320]   we can keep moving.
[00:08:29.320 --> 00:08:31.160]   But if they casually drop, "Yeah,
[00:08:31.160 --> 00:08:32.960]   "and I think that's why the Holocaust numbers
[00:08:32.960 --> 00:08:35.080]   "were blown up from 100,000 to 6 million."
[00:08:35.080 --> 00:08:36.280]   And it's like, "Okay, well, hold on, wait, wait.
[00:08:36.280 --> 00:08:37.920]   "If you think this, we have to stop here
[00:08:37.920 --> 00:08:39.880]   "because this is gonna be,
[00:08:39.880 --> 00:08:41.440]   "it's not just a language game in this part.
[00:08:41.440 --> 00:08:42.960]   "If you really believe this fact,
[00:08:42.960 --> 00:08:44.360]   "then the whole rest of the conversation
[00:08:44.360 --> 00:08:46.800]   "is gonna be informed by that belief."
[00:08:46.800 --> 00:08:47.800]   - And it has to be something
[00:08:47.800 --> 00:08:50.640]   that doesn't bother you personally.
[00:08:50.640 --> 00:08:53.000]   You have to step outside your own ego.
[00:08:53.000 --> 00:08:54.880]   So Holocaust denial is somebody
[00:08:54.880 --> 00:08:56.640]   that would bother a lot of people.
[00:08:56.640 --> 00:08:59.900]   And there's some things, just observing you,
[00:08:59.900 --> 00:09:02.300]   I feel like when you get really good at conversation,
[00:09:02.300 --> 00:09:05.720]   you can become a stickler to,
[00:09:05.720 --> 00:09:07.560]   you might have your favorite terms
[00:09:07.560 --> 00:09:09.760]   that really bothers you if people don't agree
[00:09:09.760 --> 00:09:10.600]   on those terms.
[00:09:10.600 --> 00:09:12.800]   - Begs the question, you mean raising the question.
[00:09:12.800 --> 00:09:13.640]   Yeah, I usually just want,
[00:09:13.640 --> 00:09:16.280]   if people say stuff, I just let it slide, yeah.
[00:09:16.280 --> 00:09:17.480]   'Cause if you fight,
[00:09:17.480 --> 00:09:19.000]   when you're having a conversation with somebody
[00:09:19.000 --> 00:09:20.560]   and you're talking to their audience at the same time,
[00:09:20.560 --> 00:09:21.920]   'cause that's really what's happening,
[00:09:21.920 --> 00:09:23.640]   you never wanna come off as overcombative
[00:09:23.640 --> 00:09:26.320]   or overaggressive because it puts people in like,
[00:09:26.320 --> 00:09:28.000]   there's like a trigger in your brain,
[00:09:28.000 --> 00:09:30.040]   and this is true of relationships or friendships
[00:09:30.040 --> 00:09:31.560]   of persuasive rhetoric or whatever,
[00:09:31.560 --> 00:09:32.400]   there's a trigger in the brain.
[00:09:32.400 --> 00:09:34.680]   And as soon as that defensive trigger gets like flipped on,
[00:09:34.680 --> 00:09:37.240]   everything is over, you've lost the ability to persuade
[00:09:37.240 --> 00:09:39.600]   because everything becomes a fight at that point, yeah.
[00:09:39.600 --> 00:09:41.080]   - Well, I wanted to talk to you
[00:09:41.080 --> 00:09:44.280]   'cause I heard somewhere that you were referred to
[00:09:44.280 --> 00:09:45.520]   as the Ben Shapiro of the left,
[00:09:45.520 --> 00:09:48.440]   and since I'm talking with Ben as well,
[00:09:48.440 --> 00:09:51.360]   I wanted to sort of complete spiritually
[00:09:51.360 --> 00:09:55.160]   this platonic political philosophy puzzle in my head.
[00:09:55.160 --> 00:09:57.080]   You are a progressive,
[00:09:57.080 --> 00:10:00.280]   but a progressive with many nonstandard progressive views,
[00:10:00.280 --> 00:10:02.280]   and you had a heck of a fascinating journey
[00:10:02.280 --> 00:10:03.120]   through all of that.
[00:10:03.120 --> 00:10:07.160]   And like I said, I think you argue with passion sometimes
[00:10:07.160 --> 00:10:09.400]   with excessive amounts of passion, but almost--
[00:10:09.400 --> 00:10:11.200]   - That's a really polite way of saying that.
[00:10:11.200 --> 00:10:13.920]   - Almost always with good faith
[00:10:13.920 --> 00:10:16.240]   and with rigor, with seriousness.
[00:10:16.240 --> 00:10:18.880]   I asked on your subreddit, which is an excellent subreddit,
[00:10:18.880 --> 00:10:22.080]   shout out to the Destiny subreddit,
[00:10:22.080 --> 00:10:25.040]   so much, at least for that particular post.
[00:10:25.040 --> 00:10:27.880]   What I really loved is when I asked for questions for you,
[00:10:27.880 --> 00:10:29.680]   they were like, holy shit, there's adults in there,
[00:10:29.680 --> 00:10:30.880]   let's all behave.
[00:10:30.880 --> 00:10:32.640]   - Yeah. - Like, nobody say incest.
[00:10:32.640 --> 00:10:33.480]   I was like, what?
[00:10:33.480 --> 00:10:35.160]   What's going on here?
[00:10:35.160 --> 00:10:37.960]   But actually, the questions that rose to the top
[00:10:37.960 --> 00:10:38.800]   were really good.
[00:10:38.800 --> 00:10:40.880]   So somebody said that Destiny was,
[00:10:40.880 --> 00:10:43.200]   speaking of your journey,
[00:10:43.200 --> 00:10:45.920]   was a conservative in his early teens,
[00:10:45.920 --> 00:10:48.120]   then he became a libertarian,
[00:10:48.120 --> 00:10:50.640]   then he became a left-wing social justice warrior,
[00:10:50.640 --> 00:10:53.000]   then he flirted with socialism,
[00:10:53.000 --> 00:10:55.800]   and now he is a social democrat liberal.
[00:10:55.800 --> 00:10:59.760]   I've also heard you refer to yourself as a far-left person.
[00:10:59.760 --> 00:11:02.280]   So to the degree there's truth to that journey,
[00:11:02.280 --> 00:11:04.880]   can you take me through your evolution
[00:11:04.880 --> 00:11:07.760]   through the landscape of political ideologies
[00:11:07.760 --> 00:11:08.600]   that you went through?
[00:11:08.600 --> 00:11:11.440]   - So my dad comes from Kentucky,
[00:11:11.440 --> 00:11:14.800]   and my mom is a Cuban immigrant.
[00:11:14.800 --> 00:11:17.520]   Cubans are notorious for being very conservative
[00:11:17.520 --> 00:11:18.920]   in the United States,
[00:11:18.920 --> 00:11:21.280]   for historical reasons and for other reasons,
[00:11:21.280 --> 00:11:24.760]   but my upbringing was a very Republican one.
[00:11:24.760 --> 00:11:28.160]   I grew up listening to Rush Limbaugh, Glenn Beck,
[00:11:28.160 --> 00:11:32.360]   Michael Savage, on the radio, Billy Cunningham,
[00:11:32.360 --> 00:11:34.360]   I think Sean Hannity a little bit later on,
[00:11:34.360 --> 00:11:36.480]   that was my whole upbringing politically.
[00:11:36.480 --> 00:11:38.440]   I remember I was writing,
[00:11:38.440 --> 00:11:40.240]   I'd written articles for the school journal
[00:11:40.240 --> 00:11:42.680]   in favor of defending the war in Iraq
[00:11:42.680 --> 00:11:45.040]   and defending Bush from all the criticism, et cetera.
[00:11:45.040 --> 00:11:47.600]   So that was my upbringing.
[00:11:47.600 --> 00:11:50.120]   I think once I hit high school, college,
[00:11:50.120 --> 00:11:53.340]   I had my edgy libertarian-esque high school phase
[00:11:53.340 --> 00:11:57.160]   of reading Ayn Rand, of figuring out that,
[00:11:57.160 --> 00:11:58.600]   oh my God, nothing in life matters
[00:11:58.600 --> 00:11:59.680]   except for class and money,
[00:11:59.680 --> 00:12:01.000]   that's actually the answer to everything.
[00:12:02.000 --> 00:12:04.600]   I got to college, I became a Ron Paul fan,
[00:12:04.600 --> 00:12:06.200]   very big Ron Paul fan,
[00:12:06.200 --> 00:12:11.200]   and then from there, I kind of work, do life, life happens.
[00:12:11.200 --> 00:12:13.560]   At the kind of the lowest point of my life
[00:12:13.560 --> 00:12:14.560]   in terms of where I'm working,
[00:12:14.560 --> 00:12:16.400]   financially everything is kind of in ruin in my life,
[00:12:16.400 --> 00:12:18.120]   there's just a whole bunch of dumb stuff that's happened.
[00:12:18.120 --> 00:12:19.800]   Probably my most conservative point,
[00:12:19.800 --> 00:12:21.880]   I don't know what it is about being poor
[00:12:21.880 --> 00:12:23.480]   and thinking you can work your way out of it,
[00:12:23.480 --> 00:12:24.320]   you can do whatever,
[00:12:24.320 --> 00:12:25.480]   it's just my upbringing is always just like,
[00:12:25.480 --> 00:12:28.160]   if you're not having financial success,
[00:12:28.160 --> 00:12:30.420]   just work, work, work, work, work.
[00:12:30.420 --> 00:12:32.560]   And then I got into streaming, very, very lucky break,
[00:12:32.560 --> 00:12:33.880]   everything just lined up at the right time.
[00:12:33.880 --> 00:12:35.680]   And then as I've progressed through streaming,
[00:12:35.680 --> 00:12:36.640]   I would say through the years,
[00:12:36.640 --> 00:12:38.920]   I've gradually fallen more and more to the left,
[00:12:38.920 --> 00:12:42.280]   especially once my kid turned four, five, six years old,
[00:12:42.280 --> 00:12:45.440]   and I started to see how much different his life was
[00:12:45.440 --> 00:12:47.000]   just because of the financial opportunities
[00:12:47.000 --> 00:12:48.240]   that I was able to provide for him
[00:12:48.240 --> 00:12:49.720]   through no merit of his own,
[00:12:49.720 --> 00:12:51.200]   and that started to radically change
[00:12:51.200 --> 00:12:52.600]   how I viewed the world in a lot of ways.
[00:12:52.600 --> 00:12:55.840]   - So actually, let's linger on that low point.
[00:12:55.840 --> 00:12:59.920]   You worked at McDonald's, you worked at a casino,
[00:12:59.920 --> 00:13:03.960]   you did carpet cleaning, what was the lowest point?
[00:13:03.960 --> 00:13:05.560]   - Definitely the carpet cleaning.
[00:13:05.560 --> 00:13:07.080]   - Really? - Absolutely.
[00:13:07.080 --> 00:13:08.680]   - Why was it the lowest point?
[00:13:08.680 --> 00:13:11.960]   That's when you were just flirting with starting streaming?
[00:13:11.960 --> 00:13:14.160]   - My whole life has been a series of lucky breaks,
[00:13:14.160 --> 00:13:15.280]   really, truly.
[00:13:15.280 --> 00:13:17.520]   I grew up playing a lot of video games,
[00:13:17.520 --> 00:13:21.240]   but back in my day, our day, you had to read.
[00:13:21.240 --> 00:13:22.440]   There was a lot of text on the screen.
[00:13:22.440 --> 00:13:24.280]   - Back in my day, we used to play--
[00:13:24.280 --> 00:13:25.360]   - They didn't all talk to you.
[00:13:25.360 --> 00:13:27.160]   Yeah, 'cause nowadays everything's voice acted,
[00:13:27.160 --> 00:13:28.700]   but back then you had to read a lot.
[00:13:28.700 --> 00:13:29.840]   I was a really good reader,
[00:13:29.840 --> 00:13:30.880]   I had a really good vocabulary.
[00:13:30.880 --> 00:13:32.040]   - Yeah, I've heard you actually say that.
[00:13:32.040 --> 00:13:33.440]   What games are we talking about?
[00:13:33.440 --> 00:13:35.080]   What do you mean, just reading?
[00:13:35.080 --> 00:13:36.080]   You're talking about RPGs?
[00:13:36.080 --> 00:13:38.000]   - Yeah, JRPGs, so like Final Fantasy games,
[00:13:38.000 --> 00:13:39.480]   Fantasy Stars, like all of these,
[00:13:39.480 --> 00:13:41.760]   like any RPG that would have been on the SNES,
[00:13:41.760 --> 00:13:43.840]   Sega, PlayStation, these are the things that I'm--
[00:13:43.840 --> 00:13:44.840]   - Let's pause on that.
[00:13:44.840 --> 00:13:45.680]   - Okay.
[00:13:45.680 --> 00:13:47.200]   - I just talked to Todd Howard,
[00:13:47.200 --> 00:13:50.840]   who's of the Elder Scrolls fame
[00:13:50.840 --> 00:13:54.320]   and the Fallout fame and beyond.
[00:13:54.320 --> 00:13:56.520]   What's your thoughts on Elder Scrolls?
[00:13:56.520 --> 00:13:59.440]   Why is Skyrim the greatest RPG of all time?
[00:13:59.440 --> 00:14:02.200]   - Man, I really don't like Skyrim or Fallout.
[00:14:02.200 --> 00:14:03.160]   - You don't love it? - Or those types of games.
[00:14:03.160 --> 00:14:04.480]   - Oh, really? - No, not at all.
[00:14:04.480 --> 00:14:05.640]   - Why do you hate Skyrim?
[00:14:05.640 --> 00:14:07.920]   - Yeah, so I really like characters
[00:14:07.920 --> 00:14:09.440]   and like compelling stories and narrators
[00:14:09.440 --> 00:14:10.480]   around those characters.
[00:14:10.480 --> 00:14:12.280]   And I like to see them kind of like grow and change,
[00:14:12.280 --> 00:14:14.000]   kind of like a movie or a story.
[00:14:14.000 --> 00:14:17.400]   So in your like Final Fantasy games, you've got characters.
[00:14:17.400 --> 00:14:20.600]   There are a lot of like classical tropes
[00:14:20.600 --> 00:14:23.260]   of like a character starts off kind of like edgy, angsty,
[00:14:23.260 --> 00:14:24.100]   all on their own.
[00:14:24.100 --> 00:14:25.600]   They develop relationships, friendships.
[00:14:25.600 --> 00:14:27.880]   They realize that the life is more about themselves
[00:14:27.880 --> 00:14:28.720]   and they do that.
[00:14:28.720 --> 00:14:29.800]   So I like that growth.
[00:14:29.800 --> 00:14:30.640]   That's kind of what you see
[00:14:30.640 --> 00:14:32.560]   in all of those old role-playing games.
[00:14:32.560 --> 00:14:34.200]   I didn't like the open world ones as much
[00:14:34.200 --> 00:14:35.880]   'cause your main character is just like a blank slate,
[00:14:35.880 --> 00:14:36.720]   never talks.
[00:14:36.720 --> 00:14:38.200]   It's for you to like project onto,
[00:14:38.200 --> 00:14:40.880]   but there's not the same like linear narrative
[00:14:40.880 --> 00:14:41.720]   of like growth for the character.
[00:14:41.720 --> 00:14:42.560]   - Oh, that's fascinating.
[00:14:42.560 --> 00:14:45.360]   There's an actual story arc to the character
[00:14:45.360 --> 00:14:47.640]   that's more crafted in a beautiful way
[00:14:47.640 --> 00:14:48.800]   by the designers of the game.
[00:14:48.800 --> 00:14:49.640]   Yeah, that's okay. - I don't think one
[00:14:49.640 --> 00:14:50.480]   is better or worse.
[00:14:50.480 --> 00:14:52.360]   I tend towards like I wanna hear a compelling story
[00:14:52.360 --> 00:14:53.600]   around like a set of characters
[00:14:53.600 --> 00:14:54.720]   that like grow and change as the game goes on.
[00:14:54.720 --> 00:14:55.880]   - Oh, that's beautifully put then.
[00:14:55.880 --> 00:15:00.040]   Yeah, I just really loved being able to leave the town.
[00:15:00.040 --> 00:15:02.240]   You go outside the town and you look outside,
[00:15:02.240 --> 00:15:05.160]   it's nature and the world of possibilities is before you.
[00:15:05.160 --> 00:15:07.040]   You can do whatever the fuck you want.
[00:15:07.040 --> 00:15:10.440]   I mean, that immensity of just being lost in the world
[00:15:10.440 --> 00:15:11.500]   is really immersive for me.
[00:15:11.500 --> 00:15:12.340]   But yeah, you're right.
[00:15:12.340 --> 00:15:14.640]   Whatever attracts you about a world.
[00:15:14.640 --> 00:15:19.120]   So you were just starting to play video games.
[00:15:19.120 --> 00:15:20.240]   You grew up playing video games.
[00:15:20.240 --> 00:15:22.160]   That's one of your lucky breaks.
[00:15:22.160 --> 00:15:24.040]   - There's just like a lot of random skills you pick up
[00:15:24.040 --> 00:15:25.720]   depending on the type of game you play.
[00:15:25.720 --> 00:15:27.880]   I played a lot of text-based games on the computer.
[00:15:27.880 --> 00:15:29.600]   So I was a very fast typer.
[00:15:29.600 --> 00:15:31.000]   I'm still a very fast typer.
[00:15:31.000 --> 00:15:34.600]   Read a lot, learned weird kind of math stuff
[00:15:34.600 --> 00:15:36.700]   for some of the calculations, some of the games.
[00:15:36.700 --> 00:15:39.520]   I think I'm pretty good at getting information,
[00:15:39.520 --> 00:15:42.240]   figuring stuff out, learning patterns, all of that.
[00:15:42.240 --> 00:15:44.400]   And then that plus the reading and everything
[00:15:44.400 --> 00:15:45.960]   with the games meant that I,
[00:15:45.960 --> 00:15:47.440]   I don't wanna say I excelled in school
[00:15:47.440 --> 00:15:48.960]   'cause my grades were pretty bad,
[00:15:48.960 --> 00:15:51.560]   but I was in like all honors, all AP classes or whatever.
[00:15:51.560 --> 00:15:52.680]   A lot of dual enrollment,
[00:15:52.680 --> 00:15:54.080]   a lot of AP credit going into college.
[00:15:54.080 --> 00:15:55.920]   So I did pretty well in school,
[00:15:55.920 --> 00:15:56.920]   probably better than I should have,
[00:15:56.920 --> 00:15:58.220]   but it was because I had the game stuff
[00:15:58.220 --> 00:16:00.400]   that was like really powering a lot of my brain there
[00:16:00.400 --> 00:16:02.400]   while I was trying to sleep through class.
[00:16:02.400 --> 00:16:04.200]   - So you're able to soak in information,
[00:16:04.200 --> 00:16:06.640]   integrate it, quickly take notes.
[00:16:06.640 --> 00:16:08.480]   - Generally, I think I'm pretty good at that, yeah.
[00:16:08.480 --> 00:16:10.280]   - What, you do this a lot when you stream,
[00:16:10.280 --> 00:16:11.200]   you're typing stuff.
[00:16:11.200 --> 00:16:13.480]   Is there a system in that note-taking?
[00:16:13.480 --> 00:16:16.480]   And what note, what do you use for note-taking?
[00:16:16.480 --> 00:16:17.320]   Does it matter?
[00:16:17.320 --> 00:16:19.240]   - I use a notepad.
[00:16:19.240 --> 00:16:20.880]   - Like notepad.exe notepad?
[00:16:20.880 --> 00:16:23.440]   - Yep, notepad.exe, not the plus plus, not.
[00:16:23.440 --> 00:16:26.320]   - Is there genius to the madness behind that,
[00:16:26.320 --> 00:16:27.640]   or you just don't give a shit?
[00:16:27.640 --> 00:16:29.480]   - No, I mean like, it's gonna depend
[00:16:29.480 --> 00:16:30.820]   on the style of conversation.
[00:16:30.820 --> 00:16:33.400]   If I'm with somebody that is very meticulously organized
[00:16:33.400 --> 00:16:35.640]   their thoughts and they're a,
[00:16:35.640 --> 00:16:36.920]   find a better word here for rambler,
[00:16:36.920 --> 00:16:38.560]   you can edit that in, better word for rambler.
[00:16:38.560 --> 00:16:39.840]   Somebody that talks a lot and a lot,
[00:16:39.840 --> 00:16:42.280]   I'll start like taking notes, bullet points,
[00:16:42.280 --> 00:16:43.880]   like this, this, this, this, this, this, this,
[00:16:43.880 --> 00:16:45.960]   because there's a style of conversation
[00:16:45.960 --> 00:16:47.960]   where I say seven or eight different things,
[00:16:47.960 --> 00:16:49.720]   and then when you go to respond to everything I said,
[00:16:49.720 --> 00:16:51.960]   I cut you off immediately and we argue that point.
[00:16:51.960 --> 00:16:52.800]   But if somebody's gonna do that,
[00:16:52.800 --> 00:16:54.960]   I usually say, "Hold on, you just said these eight things,
[00:16:54.960 --> 00:16:56.520]   "I'm gonna respond to every single one.
[00:16:56.520 --> 00:16:57.560]   "I've written them all down."
[00:16:57.560 --> 00:16:58.380]   And then you can go,
[00:16:58.380 --> 00:16:59.700]   if you wanna go point by point, we can,
[00:16:59.700 --> 00:17:00.960]   but you just said all this and I wrote it down,
[00:17:00.960 --> 00:17:01.800]   so now we're gonna go.
[00:17:01.800 --> 00:17:02.640]   - So what are you actually writing down,
[00:17:02.640 --> 00:17:05.400]   like a couple of words per point they left?
[00:17:05.400 --> 00:17:07.040]   - Honestly, like there are very few
[00:17:07.040 --> 00:17:08.600]   unique conversations in politics.
[00:17:08.600 --> 00:17:10.280]   Like a lot of them are kind of retreading old ground.
[00:17:10.280 --> 00:17:12.780]   So if we're having a debate on abortion,
[00:17:12.780 --> 00:17:13.760]   somebody might say like,
[00:17:13.760 --> 00:17:15.700]   "Oh, well, I believe this thing about viability,
[00:17:15.700 --> 00:17:17.000]   "and I believe this thing about, you know,
[00:17:17.000 --> 00:17:18.600]   "when they're a fetus versus a human."
[00:17:18.600 --> 00:17:19.920]   And I'll just write down like those points
[00:17:19.920 --> 00:17:20.760]   so that when I go to respond,
[00:17:20.760 --> 00:17:22.240]   I kind of have like a, like note cards,
[00:17:22.240 --> 00:17:23.160]   like a guiding thing there
[00:17:23.160 --> 00:17:25.440]   to keep me centered on my response.
[00:17:25.440 --> 00:17:26.800]   - Political discourse is a kind of tree
[00:17:26.800 --> 00:17:27.640]   you're walking down, I got it.
[00:17:27.640 --> 00:17:29.120]   And you're like taking--
[00:17:29.120 --> 00:17:31.200]   - Just to keep my focus guided,
[00:17:31.200 --> 00:17:32.920]   so I'm not like running off on a weird tangent
[00:17:32.920 --> 00:17:34.520]   or responding to something I didn't say or something.
[00:17:34.520 --> 00:17:36.320]   - What about like doing research?
[00:17:36.320 --> 00:17:38.960]   It's just, is there a system to your note taking?
[00:17:38.960 --> 00:17:40.960]   Because mentally you seem to be
[00:17:40.960 --> 00:17:43.040]   one of the most organized people I've listened to.
[00:17:43.040 --> 00:17:45.500]   So is there, is it in your mind,
[00:17:45.500 --> 00:17:47.640]   or is there a system that's on paper?
[00:17:47.640 --> 00:17:48.840]   - A little of both.
[00:17:48.840 --> 00:17:51.600]   I feel like the human mind is a beautiful thing
[00:17:51.600 --> 00:17:53.720]   if you have interest in an area.
[00:17:53.720 --> 00:17:55.760]   So like what I'll tell people is,
[00:17:55.760 --> 00:17:57.400]   let's say there's like a totally new topic
[00:17:57.400 --> 00:17:58.680]   that I'm researching, I don't know anything.
[00:17:58.680 --> 00:18:00.120]   And I'll do a couple of these on stream.
[00:18:00.120 --> 00:18:01.760]   I think they're boring, but people watch it.
[00:18:01.760 --> 00:18:04.000]   I might open a Wikipedia article and I'll read,
[00:18:04.000 --> 00:18:05.040]   and I hit something I don't know,
[00:18:05.040 --> 00:18:06.640]   and then I open the next Wikipedia article
[00:18:06.640 --> 00:18:08.860]   and I'll read it, and then I might have like seven tabs open
[00:18:08.860 --> 00:18:11.160]   and I'll read and I'll read and I'll read.
[00:18:11.160 --> 00:18:12.000]   And I'll read a ton of stuff,
[00:18:12.000 --> 00:18:14.240]   maybe for hour two, three, four hours of stuff.
[00:18:14.240 --> 00:18:15.080]   And then by the end, you know,
[00:18:15.080 --> 00:18:16.040]   someone in chat will ask me like,
[00:18:16.040 --> 00:18:18.320]   "Do you even remember like this particular thing?"
[00:18:18.320 --> 00:18:21.080]   And I'll say, "Not really, no, not too much."
[00:18:21.080 --> 00:18:23.380]   But what happens is, as long as you've seen it once,
[00:18:23.380 --> 00:18:25.160]   what will happen is like the next day, the day after,
[00:18:25.160 --> 00:18:26.440]   we'll read something else and we'll be like,
[00:18:26.440 --> 00:18:28.880]   "Oh, I remember that thing from this thing.
[00:18:28.880 --> 00:18:30.080]   I remember like vaguely that."
[00:18:30.080 --> 00:18:31.480]   And then if you see it like a third time, you're like,
[00:18:31.480 --> 00:18:32.820]   "Oh, this makes sense."
[00:18:32.820 --> 00:18:35.280]   Because especially when it comes to,
[00:18:35.280 --> 00:18:37.120]   oh, here's like a little trick on stuff.
[00:18:37.120 --> 00:18:38.800]   If you're ever reading any news
[00:18:38.800 --> 00:18:40.640]   and there's a place that pops up,
[00:18:40.640 --> 00:18:41.920]   always look at it on a map
[00:18:41.920 --> 00:18:44.280]   because so much of history is like on a map.
[00:18:44.280 --> 00:18:45.920]   It's so important to like know the geography.
[00:18:45.920 --> 00:18:47.960]   It makes things make so much more sense.
[00:18:48.560 --> 00:18:51.080]   But yeah, once I start to see stuff over and over again,
[00:18:51.080 --> 00:18:52.760]   just because I've like read it a few times,
[00:18:52.760 --> 00:18:54.400]   stuff will start to kind of connect to my mind.
[00:18:54.400 --> 00:18:55.560]   And I'm like, "Oh yeah, well, this makes sense.
[00:18:55.560 --> 00:18:57.760]   Of course, these people believe this because of this."
[00:18:57.760 --> 00:18:59.060]   Or of course, like this happened here.
[00:18:59.060 --> 00:19:01.160]   It's because, you know, that happened there.
[00:19:01.160 --> 00:19:02.240]   So yeah, it's a lot of that.
[00:19:02.240 --> 00:19:03.080]   If there's like a topic
[00:19:03.080 --> 00:19:05.760]   that I'm doing specific research for,
[00:19:05.760 --> 00:19:08.200]   so like vaccine-related stuff is a big one.
[00:19:08.200 --> 00:19:10.240]   The Ukrainian-Russian conflict is a big one.
[00:19:10.240 --> 00:19:12.020]   That I'll break out a note.
[00:19:12.020 --> 00:19:13.300]   I'll probably get like a Google doc
[00:19:13.300 --> 00:19:14.900]   and I'll just start like writing like an outline
[00:19:14.900 --> 00:19:16.560]   of kind of the rough points of everything
[00:19:16.560 --> 00:19:18.960]   just to organize my thoughts around different topics, yeah.
[00:19:18.960 --> 00:19:20.760]   - We're just gonna go on tangent upon a tangent
[00:19:20.760 --> 00:19:21.600]   upon a tangent.
[00:19:21.600 --> 00:19:24.320]   We'll return to the low point of your life at some point.
[00:19:24.320 --> 00:19:26.480]   Always returning from the philosophy to the psychology.
[00:19:26.480 --> 00:19:29.460]   So you did the Ukraine topic.
[00:19:29.460 --> 00:19:35.360]   One question is, what role does US play in this war?
[00:19:35.360 --> 00:19:40.240]   Could they have done something to avoid the war?
[00:19:40.240 --> 00:19:42.640]   Did they have a role to play
[00:19:42.640 --> 00:19:45.640]   in forcing Vladimir Putin's hand?
[00:19:45.640 --> 00:19:47.360]   Do they have a role to play
[00:19:47.360 --> 00:19:51.840]   in de-escalating the war towards a peace agreement
[00:19:51.840 --> 00:19:53.000]   and the opposite?
[00:19:53.000 --> 00:19:56.400]   If it does escalate towards something like
[00:19:56.400 --> 00:19:58.520]   the use of a tactical nuclear weapon,
[00:19:58.520 --> 00:19:59.480]   are they to blame?
[00:19:59.480 --> 00:20:01.280]   Are we to blame?
[00:20:01.280 --> 00:20:03.080]   - Oh man, somebody sent me an email a while ago
[00:20:03.080 --> 00:20:04.420]   with great words.
[00:20:04.420 --> 00:20:07.560]   There's a specific way to navigate a conversation
[00:20:07.560 --> 00:20:10.840]   where you can kind of like contribute to a negative event,
[00:20:10.840 --> 00:20:13.640]   but you're not really the one responsible for it.
[00:20:13.640 --> 00:20:15.040]   Like the classic example is,
[00:20:15.040 --> 00:20:16.240]   a woman goes out late at night,
[00:20:16.240 --> 00:20:17.240]   gets a little bit too drunk,
[00:20:17.240 --> 00:20:18.440]   and then something happens.
[00:20:18.440 --> 00:20:20.100]   And it's like, while there might've been steps
[00:20:20.100 --> 00:20:22.300]   she could have taken to mitigate the risk,
[00:20:22.300 --> 00:20:24.060]   it's not her fault of what happened
[00:20:24.060 --> 00:20:26.440]   because the responsibility rests
[00:20:26.440 --> 00:20:28.520]   on the agent making the choice, right?
[00:20:28.520 --> 00:20:30.260]   There's a chooser at some point
[00:20:30.260 --> 00:20:32.840]   that is choosing to do wrong or evil.
[00:20:32.840 --> 00:20:35.200]   I don't believe in any of the arguments
[00:20:35.200 --> 00:20:36.960]   that say the United States has contributed
[00:20:36.960 --> 00:20:39.140]   to Russia's position on Ukraine
[00:20:39.140 --> 00:20:41.440]   or the actions that they've taken on Ukraine.
[00:20:41.440 --> 00:20:44.120]   There are several arguments that some people,
[00:20:45.080 --> 00:20:47.440]   some even political scholars are putting out there
[00:20:47.440 --> 00:20:48.740]   to say that the United States is to blame,
[00:20:48.740 --> 00:20:50.880]   but I find them completely unconvincing.
[00:20:50.880 --> 00:20:52.720]   I think that when you ask the question of like,
[00:20:52.720 --> 00:20:55.680]   what is the United States role or what has our role been?
[00:20:55.680 --> 00:20:57.000]   I think it's really important for us.
[00:20:57.000 --> 00:20:58.120]   I don't think we even agree as a country
[00:20:58.120 --> 00:20:59.180]   on what our role should be,
[00:20:59.180 --> 00:21:00.020]   which I think is a hard one
[00:21:00.020 --> 00:21:01.340]   because you've got this kind of,
[00:21:01.340 --> 00:21:04.400]   there's this growing populist movement in the United States.
[00:21:04.400 --> 00:21:05.960]   It might be the far left and the far right.
[00:21:05.960 --> 00:21:07.240]   And I think populists tend to have
[00:21:07.240 --> 00:21:09.920]   this kind of isolationist view of the world
[00:21:09.920 --> 00:21:11.920]   where the United States should just be our own thing.
[00:21:11.920 --> 00:21:13.920]   We shouldn't be telling anybody what to do.
[00:21:13.920 --> 00:21:15.120]   We shouldn't be the world police.
[00:21:15.120 --> 00:21:16.520]   And then kind of more in these
[00:21:16.520 --> 00:21:17.960]   like center left, center right positions.
[00:21:17.960 --> 00:21:20.280]   And then across a lot of Europe, you've got, well, okay.
[00:21:20.280 --> 00:21:22.840]   The United States is kind of like the big kid on the block.
[00:21:22.840 --> 00:21:25.040]   Like we're looking to them for guidance and leadership
[00:21:25.040 --> 00:21:27.740]   on situations like what's going on in Ukraine.
[00:21:27.740 --> 00:21:31.000]   So insofar as the original question is like,
[00:21:31.000 --> 00:21:32.880]   what is like the United States responsibility?
[00:21:32.880 --> 00:21:35.140]   I think we have a responsibility to ensure
[00:21:35.140 --> 00:21:36.960]   the relative like freedom,
[00:21:36.960 --> 00:21:39.200]   prosperity and stability across Europe.
[00:21:39.200 --> 00:21:41.360]   I think that defending Ukraine's sovereignty
[00:21:41.360 --> 00:21:43.600]   and right to their borders is a part of that.
[00:21:43.600 --> 00:21:47.720]   And I don't believe that prior to the invasion in 2022,
[00:21:47.720 --> 00:21:49.520]   I don't think the United States was contributing
[00:21:49.520 --> 00:21:51.560]   to Russia invading that country.
[00:21:51.560 --> 00:21:53.680]   I know there are arguments given that like
[00:21:53.680 --> 00:21:55.320]   the expansion of NATO,
[00:21:55.320 --> 00:21:57.700]   has something that's been threatening to Russia,
[00:21:57.700 --> 00:21:58.760]   but the Baltics joined
[00:21:58.760 --> 00:22:00.660]   and Russia didn't do anything about it.
[00:22:00.660 --> 00:22:02.940]   The invasion to Crimea was very clearly a response
[00:22:02.940 --> 00:22:04.800]   to the revolution in 2014.
[00:22:04.800 --> 00:22:07.200]   The invasion on the borders is clearly a response
[00:22:07.200 --> 00:22:10.760]   to Ukraine winning that civil war in the Southeast
[00:22:10.760 --> 00:22:13.160]   and the Donbass and Russia becoming more aggressive.
[00:22:13.160 --> 00:22:14.480]   I don't think that you can blame any of that
[00:22:14.480 --> 00:22:15.720]   on NATO expansion.
[00:22:15.720 --> 00:22:17.520]   There's no NATO countries that are threatening Russia
[00:22:17.520 --> 00:22:18.780]   or debating Russia.
[00:22:18.780 --> 00:22:21.200]   - Do you think there is a nuclear threat?
[00:22:21.200 --> 00:22:23.160]   Do you think about this?
[00:22:23.160 --> 00:22:24.080]   Do you worry about this,
[00:22:24.080 --> 00:22:26.640]   that there is a threat of a tactical nuclear weapon
[00:22:26.640 --> 00:22:27.640]   being dropped?
[00:22:27.640 --> 00:22:29.160]   - I think that possibility exists either way.
[00:22:29.160 --> 00:22:31.640]   And I think the responsibility for that is on Russia
[00:22:31.640 --> 00:22:33.640]   because it just can't be the case
[00:22:33.640 --> 00:22:34.520]   that if you have nukes,
[00:22:34.520 --> 00:22:36.600]   you're allowed to invade countries and take their land.
[00:22:36.600 --> 00:22:37.440]   Because if anything,
[00:22:37.440 --> 00:22:40.160]   I think that that down the road also increases
[00:22:40.160 --> 00:22:43.040]   the potential for nuclear problems in the future, right?
[00:22:43.040 --> 00:22:43.880]   Because at that point,
[00:22:43.880 --> 00:22:45.560]   either every single country has to acquire
[00:22:45.560 --> 00:22:46.520]   their own nuclear weapons,
[00:22:46.520 --> 00:22:47.360]   'cause if you don't,
[00:22:47.360 --> 00:22:48.440]   Russia's gonna mess with you,
[00:22:48.440 --> 00:22:50.480]   or every single country has to join NATO.
[00:22:50.480 --> 00:22:51.320]   And now what?
[00:22:51.320 --> 00:22:53.160]   We're back at square zero, ground zero, square one,
[00:22:53.160 --> 00:22:54.000]   where people are like,
[00:22:54.000 --> 00:22:54.960]   "Oh, well look, all these countries joining NATO
[00:22:54.960 --> 00:22:55.960]   is aggressive towards Russia."
[00:22:55.960 --> 00:22:57.720]   Like, what are you gonna do?
[00:22:57.720 --> 00:23:02.120]   - Yeah, you've mentioned that there's a complicated calculus
[00:23:02.120 --> 00:23:06.200]   going on with the countries that have nuclear weapons.
[00:23:06.200 --> 00:23:08.440]   And what's our responsibility?
[00:23:08.440 --> 00:23:10.040]   Are you allowed to do anything you want
[00:23:10.040 --> 00:23:12.280]   to countries that don't have nuclear weapons?
[00:23:13.160 --> 00:23:15.360]   - That's a really tricky discussion.
[00:23:15.360 --> 00:23:16.200]   - For sure.
[00:23:16.200 --> 00:23:17.640]   - Because what is US supposed to do
[00:23:17.640 --> 00:23:20.360]   if Russia drops a tactical nuclear weapon?
[00:23:20.360 --> 00:23:21.880]   There's a set of options,
[00:23:21.880 --> 00:23:25.360]   none of which are good.
[00:23:25.360 --> 00:23:29.320]   And it's such a tricky moment right now
[00:23:29.320 --> 00:23:34.320]   because the things that Biden and other public figures say,
[00:23:34.320 --> 00:23:37.040]   I feel like has a significant impact
[00:23:37.040 --> 00:23:38.360]   on the way this game turns out.
[00:23:38.360 --> 00:23:40.040]   'Cause I think mutually assured destruction
[00:23:40.040 --> 00:23:43.720]   is partially a game of words.
[00:23:43.720 --> 00:23:44.560]   - Yeah.
[00:23:44.560 --> 00:23:47.560]   - Like, I mean, I believe in the power of conversation,
[00:23:47.560 --> 00:23:50.480]   of leaders talking to each other.
[00:23:50.480 --> 00:23:53.480]   I feel like you have to have a balance
[00:23:53.480 --> 00:23:57.240]   between threat and compromise,
[00:23:57.240 --> 00:24:01.120]   and like empathy for the needs,
[00:24:01.120 --> 00:24:04.400]   the geopolitical, the economic needs of a nation,
[00:24:05.320 --> 00:24:10.320]   but also sort of respect and represent your own interests.
[00:24:10.320 --> 00:24:11.880]   So it's a tricky one.
[00:24:11.880 --> 00:24:14.960]   Like, how do you play the hand?
[00:24:14.960 --> 00:24:17.000]   - It reminds me of, I don't know if you've ever heard
[00:24:17.000 --> 00:24:19.000]   in like evolutionary psychology or evolutionary biology,
[00:24:19.000 --> 00:24:21.440]   there are things called tit for tat strategies.
[00:24:21.440 --> 00:24:22.400]   It kind of reminds me of that,
[00:24:22.400 --> 00:24:23.720]   where it's like if, like,
[00:24:23.720 --> 00:24:25.720]   there are a whole bunch of these little biological mechanisms
[00:24:25.720 --> 00:24:26.720]   where creatures will develop,
[00:24:26.720 --> 00:24:28.160]   like socializing, like tit for tat.
[00:24:28.160 --> 00:24:29.480]   If you do something bad to me,
[00:24:29.480 --> 00:24:30.920]   I'm gonna do something bad for you.
[00:24:30.920 --> 00:24:32.880]   And then more complicated schemes will come out
[00:24:32.880 --> 00:24:35.240]   where it'll be like tit, tit for tat,
[00:24:35.240 --> 00:24:36.880]   where it's like, you can make one mistake,
[00:24:36.880 --> 00:24:38.280]   and then I'm gonna get you if you do a second one,
[00:24:38.280 --> 00:24:39.600]   or it could be tit, tit, tit for tat,
[00:24:39.600 --> 00:24:41.280]   or there could be tit for tat, tat for tit.
[00:24:41.280 --> 00:24:43.040]   There's like all these like back and forths
[00:24:43.040 --> 00:24:44.800]   where creatures kind of optimize themselves.
[00:24:44.800 --> 00:24:47.760]   And yeah, I think something the United States
[00:24:47.760 --> 00:24:49.240]   did really well in terms of that kind
[00:24:49.240 --> 00:24:50.440]   of conversational strategy,
[00:24:50.440 --> 00:24:52.280]   and I approved of this in the beginning,
[00:24:52.280 --> 00:24:54.640]   was Biden was very clear about setting out
[00:24:54.640 --> 00:24:57.560]   like the exact level of US involvement for the war.
[00:24:57.560 --> 00:24:59.120]   We're not gonna do a no fly zone.
[00:24:59.120 --> 00:25:01.080]   There's not gonna be US troops on the ground in Ukraine,
[00:25:01.080 --> 00:25:02.640]   but we are gonna send a whole bunch of money
[00:25:02.640 --> 00:25:04.960]   and a whole bunch of arms and a whole bunch of intel to them.
[00:25:04.960 --> 00:25:06.360]   And I thought he did a good job at laying out
[00:25:06.360 --> 00:25:08.040]   like the limitation of the US involvement
[00:25:08.040 --> 00:25:09.720]   while opening as much as we could
[00:25:09.720 --> 00:25:11.160]   in the ways that we could help.
[00:25:11.160 --> 00:25:13.160]   But yeah, that looming threat
[00:25:13.160 --> 00:25:15.200]   of some sort of tactical nuclear weapon,
[00:25:15.200 --> 00:25:16.480]   I think on the table right now is like,
[00:25:16.480 --> 00:25:17.600]   it's gonna be the annihilation
[00:25:17.600 --> 00:25:19.360]   of like Russian sea forces and everything.
[00:25:19.360 --> 00:25:22.720]   But you know, what happens if it continues to escalate?
[00:25:22.720 --> 00:25:26.760]   That's like a world that nobody wants to be in, yeah.
[00:25:26.760 --> 00:25:29.040]   - So we talked about difficult conversations.
[00:25:29.040 --> 00:25:30.080]   And again, thank you so much
[00:25:30.080 --> 00:25:32.040]   for reviewing the yay conversation.
[00:25:32.040 --> 00:25:34.360]   Let me ask you about Putin.
[00:25:34.480 --> 00:25:35.320]   - Mm-hmm.
[00:25:35.320 --> 00:25:37.840]   - Speaking of difficult conversations.
[00:25:37.840 --> 00:25:38.960]   So if you sit down,
[00:25:38.960 --> 00:25:41.640]   if I sit down with somebody like Vladimir Putin
[00:25:41.640 --> 00:25:43.800]   or Vladimir Zelensky,
[00:25:43.800 --> 00:25:45.520]   what's the right way to have that conversation?
[00:25:45.520 --> 00:25:46.960]   - Oh man. - We can talk about that one
[00:25:46.960 --> 00:25:51.960]   or we could talk about somebody more well understood
[00:25:51.960 --> 00:25:56.800]   through history, like Stalin or Hitler,
[00:25:56.800 --> 00:25:57.680]   something like that.
[00:25:57.680 --> 00:26:00.520]   Maybe that's an easier example to illustrate
[00:26:00.520 --> 00:26:04.200]   how to handle extremely difficult conversations.
[00:26:04.200 --> 00:26:06.000]   - Yeah, I mean, I can handle really difficult conversations
[00:26:06.000 --> 00:26:09.440]   between like two people, leaders of countries though.
[00:26:09.440 --> 00:26:11.680]   There's so much that you are representing
[00:26:11.680 --> 00:26:13.360]   in that conversation.
[00:26:13.360 --> 00:26:16.160]   I guess the thing that would be interesting to me
[00:26:16.160 --> 00:26:19.520]   would be like, what is Vladimir Putin's interest?
[00:26:19.520 --> 00:26:21.640]   Like what is the genuine interest
[00:26:21.640 --> 00:26:23.640]   that he has in the conflict?
[00:26:23.640 --> 00:26:25.480]   'Cause I think finding out like, what is your buy-in
[00:26:25.480 --> 00:26:27.840]   or what is the driving force keeping you here
[00:26:27.840 --> 00:26:29.840]   is probably the most important thing.
[00:26:29.840 --> 00:26:30.680]   I think for Zelensky,
[00:26:30.680 --> 00:26:32.280]   I think it's quite a bit more simpler
[00:26:32.280 --> 00:26:34.160]   'cause he's on the defense.
[00:26:34.160 --> 00:26:36.720]   So it's defending his country and his people.
[00:26:36.720 --> 00:26:39.120]   For Putin, I've heard all sorts of things.
[00:26:39.120 --> 00:26:42.520]   Dugin has his writings on like the East versus the West,
[00:26:42.520 --> 00:26:44.000]   the collapse of the West in the face
[00:26:44.000 --> 00:26:45.640]   of like all of the liberalism
[00:26:45.640 --> 00:26:48.080]   and the weird LGBT stuff that they criticize.
[00:26:48.080 --> 00:26:50.000]   You've got the desire to like return
[00:26:50.000 --> 00:26:52.040]   to this like former Soviet Union-esque thing.
[00:26:52.040 --> 00:26:54.440]   You've got Putin's quotes that collapse of the Soviet Union
[00:26:54.440 --> 00:26:58.160]   was the biggest geopolitical disaster of 20th century.
[00:26:58.160 --> 00:27:00.280]   And I guess figuring out like, what is Putin after?
[00:27:00.280 --> 00:27:01.120]   I'm not actually sure.
[00:27:01.120 --> 00:27:01.960]   I don't know the answer to that question.
[00:27:01.960 --> 00:27:03.160]   I know a lot of people write about it, but yeah.
[00:27:03.160 --> 00:27:04.880]   - Well, there's a lot of answers to that question.
[00:27:04.880 --> 00:27:07.040]   There's a lot of answers that he can give to that question.
[00:27:07.040 --> 00:27:10.960]   So say I sit down with him for three hours and talk about it.
[00:27:10.960 --> 00:27:14.120]   I think this is a really interesting distinction
[00:27:14.120 --> 00:27:17.140]   because you do do difficult conversations
[00:27:17.140 --> 00:27:20.080]   in the space of ideas, but also in your stream,
[00:27:20.080 --> 00:27:22.040]   you have, I mean, there's a bunch of drama going on.
[00:27:22.040 --> 00:27:24.480]   There's a human psychology is laid out
[00:27:24.480 --> 00:27:27.640]   in its full richness before you.
[00:27:27.640 --> 00:27:29.440]   So to me with leaders,
[00:27:29.440 --> 00:27:32.500]   I think a part of the conversation has to be
[00:27:32.500 --> 00:27:34.240]   about the human psychology.
[00:27:34.240 --> 00:27:36.680]   Not like a meta conversation,
[00:27:36.680 --> 00:27:40.720]   but like really understand what they feel,
[00:27:40.720 --> 00:27:43.560]   what they fear, who they are as a human being.
[00:27:43.560 --> 00:27:48.560]   Like as a family man, as a person proud of their country,
[00:27:48.560 --> 00:27:53.360]   as a person with an ego, as a person who's been affected,
[00:27:53.360 --> 00:27:58.360]   if not corrupted by powers, all of us can be and likely are.
[00:27:58.360 --> 00:28:01.920]   So all of that, that gives context to then
[00:28:01.920 --> 00:28:04.480]   the answers about what do you want in this war.
[00:28:04.480 --> 00:28:07.800]   Is that the answers about what you want in this war
[00:28:07.800 --> 00:28:10.040]   will be political answers.
[00:28:10.040 --> 00:28:13.120]   It's like a game that's being played again with words
[00:28:13.120 --> 00:28:16.160]   and politicians are incredibly good at playing that game.
[00:28:16.160 --> 00:28:19.540]   I think the deeper truth comes from understanding
[00:28:19.540 --> 00:28:22.320]   the human being from which those words come.
[00:28:22.320 --> 00:28:24.420]   And I think that's what you do.
[00:28:24.420 --> 00:28:26.560]   I don't know if you do those kinds of conversations where--
[00:28:26.560 --> 00:28:28.480]   - Never talked to any country leader, so.
[00:28:28.480 --> 00:28:29.860]   - No, not a country leader,
[00:28:29.860 --> 00:28:32.440]   but say a controversial figure or somebody
[00:28:32.440 --> 00:28:34.140]   that represents a certain idea.
[00:28:34.140 --> 00:28:37.880]   Don't just talk in the space of ideas or challenge the ideas
[00:28:37.880 --> 00:28:39.780]   but understand who is this person,
[00:28:39.780 --> 00:28:41.840]   how did you come to those ideas?
[00:28:41.840 --> 00:28:43.480]   - Oh yeah, when I've had, there've been a couple
[00:28:43.480 --> 00:28:47.320]   of very controversial right-leaning figures.
[00:28:47.320 --> 00:28:48.720]   So the two, obviously the mainstreamers for me
[00:28:48.720 --> 00:28:51.120]   are Lauren Southern and Nick Fuentes.
[00:28:51.120 --> 00:28:54.260]   And those types of conversations initially
[00:28:54.260 --> 00:28:55.600]   aren't very political at all.
[00:28:55.600 --> 00:28:57.880]   Yeah, it's more like, obviously we believe
[00:28:57.880 --> 00:28:59.600]   in very, very, very different things,
[00:28:59.600 --> 00:29:01.280]   but like beliefs don't happen accidentally.
[00:29:01.280 --> 00:29:02.860]   So how did you get to where you are?
[00:29:02.860 --> 00:29:05.200]   Those are way more personal conversations, that's true.
[00:29:05.200 --> 00:29:08.480]   - Is there things you regret about those conversations
[00:29:08.480 --> 00:29:09.520]   where you failed?
[00:29:09.520 --> 00:29:12.200]   Is there things you're proud of where you succeeded?
[00:29:12.200 --> 00:29:13.880]   - For things that I'm proud of,
[00:29:13.880 --> 00:29:17.080]   I feel like I'm really good at attempting
[00:29:17.080 --> 00:29:19.280]   to understand people without judgment.
[00:29:19.280 --> 00:29:20.400]   That I think a lot of people feel like
[00:29:20.400 --> 00:29:21.460]   they can have conversations with me
[00:29:21.460 --> 00:29:22.760]   where they can share a lot
[00:29:22.760 --> 00:29:24.180]   and I'm not gonna jump down their throat
[00:29:24.180 --> 00:29:27.440]   for them having a politically incorrect observation
[00:29:27.440 --> 00:29:29.600]   or for them being judgmental of somebody else
[00:29:29.600 --> 00:29:31.820]   or having like a feeling that's maybe not something
[00:29:31.820 --> 00:29:33.400]   they should have, something they're embarrassed about.
[00:29:33.400 --> 00:29:35.000]   So I think I do a really good job at that.
[00:29:35.000 --> 00:29:36.560]   And then by extension of that,
[00:29:36.560 --> 00:29:38.360]   I've gotten the ability to hear perspectives
[00:29:38.360 --> 00:29:39.400]   from so many different people
[00:29:39.400 --> 00:29:40.300]   that I think I can understand
[00:29:40.300 --> 00:29:42.680]   a lot of different perspectives.
[00:29:42.680 --> 00:29:46.600]   For failures of mine, I mean, it's always gonna be,
[00:29:46.600 --> 00:29:48.920]   on stream it'll be like, I didn't push back hard enough
[00:29:48.920 --> 00:29:51.900]   or I didn't know like a certain fact for a conversation.
[00:29:51.900 --> 00:29:53.640]   These are usually the, they're gonna be on these
[00:29:53.640 --> 00:29:55.720]   like very technical grounds generally.
[00:29:55.720 --> 00:29:57.080]   I'm pretty happy with like the direction
[00:29:57.080 --> 00:29:59.360]   my conversations have gone recently,
[00:29:59.360 --> 00:30:01.000]   especially over like the past six months.
[00:30:01.000 --> 00:30:04.120]   - So your goal is to de-radicalize
[00:30:04.120 --> 00:30:06.680]   the audience of those folks.
[00:30:06.680 --> 00:30:08.780]   - So that used to be my goal.
[00:30:08.780 --> 00:30:10.800]   My goal was de-radicalization.
[00:30:10.800 --> 00:30:13.200]   Now I'm kind of hoping that that's just the by-product.
[00:30:13.200 --> 00:30:15.240]   So the goal I think is to talk to somebody
[00:30:15.240 --> 00:30:18.400]   and to show they believe this because of these reasons.
[00:30:18.400 --> 00:30:19.980]   And if you wanna change people's beliefs,
[00:30:19.980 --> 00:30:21.640]   we have to talk about the underlying reasons
[00:30:21.640 --> 00:30:23.580]   for why they think the things they think.
[00:30:23.580 --> 00:30:26.000]   It's not enough to just say like that belief is bad
[00:30:26.000 --> 00:30:27.120]   'cause it's like, well, they believe it
[00:30:27.120 --> 00:30:28.660]   for a whole bunch of things that are true and real
[00:30:28.660 --> 00:30:29.760]   to them at least.
[00:30:29.760 --> 00:30:32.680]   So you have to address all of the underlying things
[00:30:32.680 --> 00:30:33.760]   that they believe before you can change
[00:30:33.760 --> 00:30:35.360]   the overlying belief.
[00:30:35.360 --> 00:30:37.060]   So if I'm having a conversation with somebody,
[00:30:37.060 --> 00:30:39.240]   it'll be like, okay, why do you feel this about that,
[00:30:39.240 --> 00:30:40.160]   that and that?
[00:30:40.160 --> 00:30:41.560]   Okay, I understand that.
[00:30:41.560 --> 00:30:43.840]   Maybe like a better way to solve that would be like
[00:30:43.840 --> 00:30:45.800]   this or that instead of this thing.
[00:30:45.800 --> 00:30:48.200]   - So to what degree do you have to empathize
[00:30:48.200 --> 00:30:52.000]   with the person's worldview versus pushback?
[00:30:52.000 --> 00:30:53.940]   - That's always the hard one.
[00:30:53.940 --> 00:30:55.940]   When I'm talking to other people,
[00:30:55.940 --> 00:30:59.260]   it's almost always me stepping as much inside their bubble
[00:30:59.260 --> 00:31:00.100]   as I can.
[00:31:00.100 --> 00:31:01.580]   I have to like live and breathe their worldview
[00:31:01.580 --> 00:31:03.380]   and be able to speak their worldview
[00:31:03.380 --> 00:31:05.480]   in order to like navigate their thoughts
[00:31:05.480 --> 00:31:07.780]   because my worldview is,
[00:31:07.780 --> 00:31:09.620]   I'm not even using this as an insult.
[00:31:09.620 --> 00:31:11.620]   I don't know if I am a little bit autistic or something,
[00:31:11.620 --> 00:31:13.260]   but when I break apart things,
[00:31:13.260 --> 00:31:15.460]   I just wanna see like study, study, study, fact, fact, fact.
[00:31:15.460 --> 00:31:17.140]   That's how my mind works for everything.
[00:31:17.140 --> 00:31:18.180]   That's what I like to see.
[00:31:18.180 --> 00:31:20.300]   Like personal stories don't do much for me.
[00:31:20.300 --> 00:31:21.140]   Narratives don't do much for me.
[00:31:21.140 --> 00:31:23.060]   They show me like the data and the studies or whatever.
[00:31:23.060 --> 00:31:24.100]   But for other people,
[00:31:24.100 --> 00:31:26.040]   I think most brains are more human than that.
[00:31:26.040 --> 00:31:28.680]   And they tend to see things that more kind of like
[00:31:28.680 --> 00:31:30.360]   surreal pictures that are kind of painted
[00:31:30.360 --> 00:31:32.080]   and the brushstrokes are way broader.
[00:31:32.080 --> 00:31:35.240]   And they don't care about the itty bitty tiny fact.
[00:31:35.240 --> 00:31:36.360]   So if I'm talking to somebody else
[00:31:36.360 --> 00:31:38.160]   and I'm trying to get into their head
[00:31:38.160 --> 00:31:40.040]   and I'm trying to change their mind on things,
[00:31:40.040 --> 00:31:42.720]   I'm gonna be stepping into their world
[00:31:42.720 --> 00:31:45.000]   and I'm gonna try to be working through that framework.
[00:31:45.000 --> 00:31:46.600]   Really good example might be,
[00:31:46.600 --> 00:31:49.960]   we'll say like when it comes to trans issues for minors,
[00:31:49.960 --> 00:31:52.980]   okay, 16 or 17 year old needs to get on puberty blockers.
[00:31:52.980 --> 00:31:54.940]   The way that I want that debate to play out
[00:31:54.940 --> 00:31:57.180]   is let's look at all the data.
[00:31:57.180 --> 00:31:58.940]   Let's see what are the outcomes.
[00:31:58.940 --> 00:32:00.860]   Let's see what are the processes for getting a medication.
[00:32:00.860 --> 00:32:01.980]   And then we'll evaluate all of that
[00:32:01.980 --> 00:32:04.820]   and then we'll go in whatever like points more favorably.
[00:32:04.820 --> 00:32:07.020]   But that's wholly unconvincing to most people, right?
[00:32:07.020 --> 00:32:07.920]   So as a parent,
[00:32:07.920 --> 00:32:09.800]   if I'm having that conversation with another parent,
[00:32:09.800 --> 00:32:11.580]   the easiest way for me to have that conversation is like,
[00:32:11.580 --> 00:32:13.420]   hey, we both have kids.
[00:32:13.420 --> 00:32:14.660]   Imagine how horrible it would be
[00:32:14.660 --> 00:32:16.420]   if we felt like our kids needed help
[00:32:16.420 --> 00:32:18.540]   and the government was trying to get between us
[00:32:18.540 --> 00:32:20.560]   and their doctor in that conversation.
[00:32:20.560 --> 00:32:21.760]   That might be how that talk plays out,
[00:32:21.760 --> 00:32:23.880]   which I don't even think that's a really good argument.
[00:32:23.880 --> 00:32:24.720]   'Cause I think there probably are times
[00:32:24.720 --> 00:32:25.760]   when the government should get in between,
[00:32:25.760 --> 00:32:26.760]   but I'll have that conversation
[00:32:26.760 --> 00:32:28.320]   because now I'm in a world
[00:32:28.320 --> 00:32:29.560]   where they understand what I'm saying.
[00:32:29.560 --> 00:32:32.200]   I am resonating with the way that they feel about things
[00:32:32.200 --> 00:32:33.480]   and then I can make progress
[00:32:33.480 --> 00:32:35.200]   with the way that they're kind of viewing the world
[00:32:35.200 --> 00:32:37.240]   because I'm talking in a language they understand.
[00:32:37.240 --> 00:32:40.440]   - So on this particular topic of trans issues,
[00:32:40.440 --> 00:32:42.600]   is that the reason you were banned from Twitch?
[00:32:42.600 --> 00:32:45.000]   - I'm not sure, I don't know.
[00:32:45.000 --> 00:32:45.920]   They just said hate speech,
[00:32:45.920 --> 00:32:47.280]   but I don't use like slurs or anything.
[00:32:47.280 --> 00:32:48.780]   So it's hard to know exactly.
[00:32:48.780 --> 00:32:50.360]   - So I think you made the claim
[00:32:50.360 --> 00:32:53.100]   that trans women shouldn't compete with cis women
[00:32:53.100 --> 00:32:54.800]   in the women's athletics.
[00:32:54.800 --> 00:32:58.340]   Can you make this case
[00:32:58.340 --> 00:33:00.500]   and can you steel man the case against it?
[00:33:00.500 --> 00:33:01.740]   I think in your community,
[00:33:01.740 --> 00:33:04.700]   there's a lot of trans folks who love you
[00:33:04.700 --> 00:33:06.460]   and there's a lot who hate you.
[00:33:06.460 --> 00:33:07.300]   - Yeah.
[00:33:07.300 --> 00:33:11.260]   - And so if you can walk the tightrope of this conversation
[00:33:11.260 --> 00:33:13.220]   to try to steel man both sides.
[00:33:13.220 --> 00:33:14.780]   - One of the argumentative strategies I say
[00:33:14.780 --> 00:33:16.340]   is that like anytime you have a conversation,
[00:33:16.340 --> 00:33:17.520]   you should be able to argue both sides
[00:33:17.520 --> 00:33:19.320]   better than anybody else.
[00:33:19.320 --> 00:33:22.860]   So for my side, the genuine belief side,
[00:33:22.860 --> 00:33:26.200]   it feels like overwhelmingly,
[00:33:26.200 --> 00:33:28.980]   all of the data is showing that trans,
[00:33:28.980 --> 00:33:32.640]   mostly trans women, even after I think three years
[00:33:32.640 --> 00:33:37.360]   on some sort of like HRT or estrogen stuff,
[00:33:37.360 --> 00:33:39.440]   they're still maintaining these advantages
[00:33:39.440 --> 00:33:42.700]   from their male puberty over cisgender women.
[00:33:42.700 --> 00:33:43.920]   And if that is the case,
[00:33:43.920 --> 00:33:45.780]   if we are gonna draw these distinctions
[00:33:45.780 --> 00:33:48.380]   around our sports between women and men,
[00:33:48.380 --> 00:33:51.840]   it feels unfair to have a category inside the women's sports
[00:33:51.840 --> 00:33:53.640]   that are maintaining advantages
[00:33:53.640 --> 00:33:55.840]   that are coming from a male puberty,
[00:33:55.840 --> 00:33:57.480]   regardless of the amount of time they've spent
[00:33:57.480 --> 00:34:00.280]   on hormone replacement therapy.
[00:34:00.280 --> 00:34:02.320]   So that would be my argument on that side.
[00:34:02.320 --> 00:34:06.460]   - So it's unfair from a performance enhancement aspect.
[00:34:06.460 --> 00:34:11.180]   So the same way we ban performance enhancing drugs
[00:34:11.180 --> 00:34:14.140]   that involve increasing of testosterone
[00:34:14.140 --> 00:34:15.760]   in that same way would be unfair.
[00:34:15.760 --> 00:34:16.600]   - Essentially, yeah.
[00:34:16.600 --> 00:34:20.000]   - So what's the case against?
[00:34:20.000 --> 00:34:22.680]   - Yeah, so the case in favor of them competing together
[00:34:22.680 --> 00:34:24.400]   is that realistically,
[00:34:24.400 --> 00:34:27.940]   there's not gonna be a trans sports category.
[00:34:27.940 --> 00:34:30.380]   Realistically, trans women aren't gonna be competitive
[00:34:30.380 --> 00:34:33.080]   with cis men because they've gone through these huge,
[00:34:33.080 --> 00:34:34.540]   you know, like hormone changes
[00:34:34.540 --> 00:34:36.640]   by the medication they're taking.
[00:34:36.640 --> 00:34:40.360]   And that when we look at how sports are kind of done anyway,
[00:34:40.360 --> 00:34:42.760]   there's a whole bunch of biological differences
[00:34:42.760 --> 00:34:44.860]   between people within sports categories
[00:34:44.860 --> 00:34:46.360]   that are determining their placement
[00:34:46.360 --> 00:34:48.100]   in the professional world.
[00:34:48.100 --> 00:34:50.460]   So for instance, somebody like me
[00:34:50.460 --> 00:34:51.980]   is probably never gonna go far in the NBA
[00:34:51.980 --> 00:34:53.420]   because I'm not tall enough.
[00:34:53.420 --> 00:34:54.740]   I think the average height in the NBA--
[00:34:54.740 --> 00:34:55.620]   - Don't doubt yourself.
[00:34:55.620 --> 00:34:56.460]   - Don't doubt myself, yeah.
[00:34:56.460 --> 00:34:58.100]   I wanna say it's like six or something.
[00:34:58.100 --> 00:34:59.900]   They're huge people.
[00:34:59.900 --> 00:35:02.660]   Or, you know, you look at like Michael Phelps
[00:35:02.660 --> 00:35:05.620]   as a classic example of a guy whose torso is like so long,
[00:35:05.620 --> 00:35:07.460]   his body is built for swimming.
[00:35:07.460 --> 00:35:09.100]   And I think there are some trans people
[00:35:09.100 --> 00:35:09.940]   that will look at that
[00:35:09.940 --> 00:35:11.380]   or somebody advocating for this position,
[00:35:11.380 --> 00:35:12.220]   they'll look at that and they'll go,
[00:35:12.220 --> 00:35:15.140]   "Okay, realistically, the way that Michael Phelps' body
[00:35:15.140 --> 00:35:16.380]   processes lactic acid,
[00:35:16.380 --> 00:35:18.280]   the shape physiologically of his body
[00:35:18.280 --> 00:35:20.420]   is gonna put him in a level of competition
[00:35:20.420 --> 00:35:22.060]   that so many men are never gonna reach
[00:35:22.060 --> 00:35:23.660]   just because of biology.
[00:35:23.660 --> 00:35:26.300]   How is it fair that you can have these biological outliers
[00:35:26.300 --> 00:35:27.780]   competing in these categories,
[00:35:27.780 --> 00:35:29.540]   but then when we come to like sports categories
[00:35:29.540 --> 00:35:30.660]   with trans and cis women,
[00:35:30.660 --> 00:35:31.740]   you're gonna take trans women
[00:35:31.740 --> 00:35:33.500]   and say that they can't compete against cis women.
[00:35:33.500 --> 00:35:34.700]   Can't you also just say that they have
[00:35:34.700 --> 00:35:37.060]   some level of biological difference there?
[00:35:37.060 --> 00:35:38.880]   Like, is it really gonna be that great of a difference
[00:35:38.880 --> 00:35:41.240]   than what Michael Phelps has versus the average swimmer
[00:35:41.240 --> 00:35:44.040]   or an NBA player has versus like the average height male?
[00:35:44.040 --> 00:35:46.340]   - Yeah.
[00:35:46.340 --> 00:35:47.460]   Do you think we're gonna get into
[00:35:47.460 --> 00:35:49.500]   some tricky ethical territory
[00:35:49.500 --> 00:35:51.380]   as we start to be able to,
[00:35:51.380 --> 00:35:54.940]   through biology and genetics, modify the human body?
[00:35:54.940 --> 00:35:56.380]   - Absolutely.
[00:35:56.380 --> 00:35:58.620]   I feel like those things are coming sooner
[00:35:58.620 --> 00:36:00.780]   than we wanted them to.
[00:36:00.780 --> 00:36:03.780]   Oh man, have you seen the AI art?
[00:36:03.780 --> 00:36:04.620]   - Yes.
[00:36:04.620 --> 00:36:05.440]   - That's a--
[00:36:05.440 --> 00:36:06.540]   - Of course, I'm an AI person.
[00:36:06.540 --> 00:36:07.980]   - Oh, okay, then yeah, yeah.
[00:36:07.980 --> 00:36:09.980]   That's always been like,
[00:36:09.980 --> 00:36:12.520]   what's gonna happen when robots can do art
[00:36:12.520 --> 00:36:13.920]   better than humans, LOL?
[00:36:13.920 --> 00:36:15.360]   Like, well, we'll see in 20 years,
[00:36:15.360 --> 00:36:16.600]   in 20 years, in 20 years.
[00:36:16.600 --> 00:36:19.360]   And now you have AI art winning competitions.
[00:36:19.360 --> 00:36:24.040]   And it's funny because robots are essentially--
[00:36:24.040 --> 00:36:25.400]   - There's a robot behind you, by the way.
[00:36:25.400 --> 00:36:26.680]   - A robot behind me.
[00:36:26.680 --> 00:36:27.520]   Oh, nice.
[00:36:27.520 --> 00:36:29.800]   Robots are really good--
[00:36:29.800 --> 00:36:30.640]   - Careful what you say.
[00:36:30.640 --> 00:36:32.360]   - Yeah, oh God, I'll be careful.
[00:36:32.360 --> 00:36:33.560]   That's not like one of the Chinese ones
[00:36:33.560 --> 00:36:34.400]   with a gun on it, right?
[00:36:34.400 --> 00:36:35.220]   Oh, okay.
[00:36:35.220 --> 00:36:37.680]   Hopefully not.
[00:36:37.680 --> 00:36:39.280]   - We'll see, depending on what you say, yeah.
[00:36:39.280 --> 00:36:40.120]   - Okay.
[00:36:40.120 --> 00:36:43.360]   Robots are really good at showing the limitations
[00:36:43.360 --> 00:36:46.120]   of the human mind in categories
[00:36:46.120 --> 00:36:48.560]   that we didn't believe we were limited before.
[00:36:48.560 --> 00:36:51.820]   I think that humans have this idea intrinsically
[00:36:51.820 --> 00:36:56.820]   that we have some type of innovative, creative drive
[00:36:56.820 --> 00:37:00.940]   that is just outside of the bounds of physical understanding.
[00:37:00.940 --> 00:37:03.480]   And with a sophisticated enough program,
[00:37:03.480 --> 00:37:05.520]   we see that maybe that's not actually true.
[00:37:05.520 --> 00:37:07.460]   And that's a really scary thing,
[00:37:07.460 --> 00:37:08.900]   philosophically, to deal with.
[00:37:08.900 --> 00:37:10.360]   Because we feel like we're very special, right?
[00:37:10.360 --> 00:37:12.680]   We own the planet, we make computers,
[00:37:12.680 --> 00:37:14.480]   and the idea that you can start to get these robots
[00:37:14.480 --> 00:37:17.280]   that can do things that's like, okay, you can do math, fine.
[00:37:17.280 --> 00:37:19.240]   Okay, you can do calculations, fine.
[00:37:19.240 --> 00:37:20.240]   But you can't do art.
[00:37:20.240 --> 00:37:21.760]   That's the human stuff.
[00:37:21.760 --> 00:37:23.920]   And then when they start to do that, it's like, oh, shoot.
[00:37:23.920 --> 00:37:25.440]   - And that terrifies you a little bit?
[00:37:25.440 --> 00:37:28.800]   Like the human species losing control
[00:37:28.800 --> 00:37:31.040]   of our dominance over this earth?
[00:37:31.040 --> 00:37:32.200]   - I don't think it's necessarily losing control
[00:37:32.200 --> 00:37:33.040]   of our dominance.
[00:37:33.040 --> 00:37:34.240]   I mean, I guess like a Skynet thing
[00:37:34.240 --> 00:37:35.760]   could come in at some point.
[00:37:35.760 --> 00:37:39.660]   But I think it brings us to this really fundamental level
[00:37:39.660 --> 00:37:41.500]   of like, what does it mean to be human?
[00:37:41.500 --> 00:37:43.460]   What is it that we're good at?
[00:37:43.460 --> 00:37:45.100]   What should we be doing with technology?
[00:37:45.100 --> 00:37:47.060]   We never really ask that question in the Western world.
[00:37:47.060 --> 00:37:50.000]   It's always the technology is like normative
[00:37:50.000 --> 00:37:51.940]   in that technology equals good
[00:37:51.940 --> 00:37:53.380]   and more technology equals better.
[00:37:53.380 --> 00:37:54.940]   That's been like the default assumption.
[00:37:54.940 --> 00:37:56.420]   In fact, if you ask a lot of people,
[00:37:56.420 --> 00:37:58.060]   how do you know if civilization has progressed
[00:37:58.060 --> 00:37:59.740]   over the past 100 or 200 years,
[00:37:59.740 --> 00:38:01.740]   they don't say we have better relationships,
[00:38:01.740 --> 00:38:04.660]   we have longer marriages, blah, blah, blah.
[00:38:04.660 --> 00:38:05.700]   They'll say technology has improved.
[00:38:05.700 --> 00:38:07.700]   We've got crazy phones, we've got crazy computers.
[00:38:07.700 --> 00:38:10.420]   And the idea that more technology might be bad
[00:38:10.420 --> 00:38:11.840]   has never even crossed somebody's mind,
[00:38:11.840 --> 00:38:13.980]   unless it's used for like a really bad thing.
[00:38:13.980 --> 00:38:15.080]   - Well, it's interesting.
[00:38:15.080 --> 00:38:18.080]   We kind of think as more and more automation is happening,
[00:38:18.080 --> 00:38:20.000]   we're going to get more and more meaning
[00:38:20.000 --> 00:38:23.740]   from things like being artists and doing creative pursuits.
[00:38:23.740 --> 00:38:27.220]   And here's like, oh shit, if the art,
[00:38:27.220 --> 00:38:29.460]   if the creative pursuits are also being automated,
[00:38:29.460 --> 00:38:31.300]   then what are we gonna gain meaning from?
[00:38:31.300 --> 00:38:33.540]   What are the activities from which you'll gain meaning?
[00:38:33.540 --> 00:38:35.120]   You know, my whole life I've been working
[00:38:35.120 --> 00:38:36.700]   on artificial intelligence systems.
[00:38:36.700 --> 00:38:38.260]   There's been different revolutions.
[00:38:38.260 --> 00:38:40.980]   One of them is the machine learning revolution.
[00:38:40.980 --> 00:38:44.220]   And it's interesting to build up intuition
[00:38:44.220 --> 00:38:48.340]   and destroy that intuition about what is
[00:38:48.340 --> 00:38:50.580]   and isn't solvable by machines.
[00:38:50.580 --> 00:38:54.140]   I think for the longest time, I grew up thinking
[00:38:54.140 --> 00:38:57.100]   Go is not, the game of Go is not solvable.
[00:38:57.100 --> 00:39:01.180]   Because my understanding of AI systems
[00:39:01.180 --> 00:39:06.180]   is ultimately this, is fundamentally a search mechanism
[00:39:06.180 --> 00:39:09.240]   that is fundamentally going to be brute force.
[00:39:09.240 --> 00:39:10.400]   There's no shortcuts.
[00:39:10.400 --> 00:39:11.240]   - Sure.
[00:39:11.240 --> 00:39:13.600]   Like if it can't solve the traveling salesman problem,
[00:39:13.600 --> 00:39:15.760]   it's not even gonna be able to give you an approximation.
[00:39:15.760 --> 00:39:17.240]   - So most interesting problems
[00:39:17.240 --> 00:39:19.200]   are giant travel salesman problem.
[00:39:19.200 --> 00:39:21.640]   And then, so of course, it's not gonna be able to solve that.
[00:39:21.640 --> 00:39:25.160]   And then you, then the deep learning revolution
[00:39:25.160 --> 00:39:27.520]   made you realize, holy shit, these large neural networks
[00:39:27.520 --> 00:39:29.760]   with a giant number of knobs is able
[00:39:29.760 --> 00:39:34.760]   to actually somehow estimate functions
[00:39:34.760 --> 00:39:38.160]   that can do a pretty good job
[00:39:38.160 --> 00:39:41.200]   of understanding deep representation of a thing.
[00:39:41.200 --> 00:39:42.940]   Whether that's a game of Go,
[00:39:42.940 --> 00:39:46.120]   or whether it's the human natural language,
[00:39:46.120 --> 00:39:50.120]   or if it's images and video or audio,
[00:39:50.120 --> 00:39:52.320]   and even actions in different video games
[00:39:52.320 --> 00:39:54.820]   and actions of robotics and so on.
[00:39:54.820 --> 00:39:57.260]   And then you realize with diffusion models
[00:39:57.260 --> 00:39:59.840]   and different generative models,
[00:39:59.840 --> 00:40:01.100]   you start to realize, holy shit,
[00:40:01.100 --> 00:40:06.100]   it can actually generate not just interesting representations
[00:40:06.100 --> 00:40:10.920]   or interesting manifestations
[00:40:10.920 --> 00:40:12.720]   of the representations of forms,
[00:40:12.720 --> 00:40:13.880]   but it's able to do something
[00:40:13.880 --> 00:40:16.660]   that impresses humans in its creativity.
[00:40:16.660 --> 00:40:19.640]   It's beautiful in the way we think of art as beautiful.
[00:40:19.640 --> 00:40:21.640]   Like it surprises us and makes us chuckle,
[00:40:21.640 --> 00:40:25.360]   it makes us sit back in awe and all those kinds of things.
[00:40:25.360 --> 00:40:28.140]   And yet the thing that it seems to struggle with the most
[00:40:28.140 --> 00:40:30.380]   is the physical world currently.
[00:40:30.380 --> 00:40:31.780]   So that's counterintuitive.
[00:40:31.780 --> 00:40:35.260]   We humans think that it's pretty trivial,
[00:40:35.260 --> 00:40:38.100]   the being able to pick up a cup,
[00:40:38.100 --> 00:40:40.060]   being able to write with a pen,
[00:40:40.060 --> 00:40:42.940]   like in the physical space, we think that's trivial.
[00:40:42.940 --> 00:40:45.180]   We give ourselves respect for being great artists
[00:40:45.180 --> 00:40:47.860]   and great mathematicians and all that kind of stuff,
[00:40:47.860 --> 00:40:51.100]   and that seems to be much easier than the physical space.
[00:40:51.100 --> 00:40:52.500]   - Bodies are really cool.
[00:40:52.500 --> 00:40:54.420]   - Yeah. - There is a, I don't know,
[00:40:54.420 --> 00:40:55.440]   it's probably Asimov or somebody,
[00:40:55.440 --> 00:40:56.600]   there was some science fiction writer
[00:40:56.600 --> 00:40:58.360]   that had a short story and it was like an alien
[00:40:58.360 --> 00:41:00.640]   that had landed on earth and it was describing our bodies
[00:41:00.640 --> 00:41:02.480]   from a totally alien perspective.
[00:41:02.480 --> 00:41:04.440]   And when you think about all the things we can do,
[00:41:04.440 --> 00:41:05.280]   it's pretty cool.
[00:41:05.280 --> 00:41:08.880]   We can climb through a whole multitude of environments,
[00:41:08.880 --> 00:41:10.860]   we can exist in a multitude of temperatures,
[00:41:10.860 --> 00:41:14.840]   we can manipulate things just with our hands
[00:41:14.840 --> 00:41:17.160]   and the way that we can interact with things around us.
[00:41:17.160 --> 00:41:19.440]   And yeah, we're very capable on like a physical level,
[00:41:19.440 --> 00:41:21.080]   even though, like you said, we think about ourselves like,
[00:41:21.080 --> 00:41:23.160]   oh, well, human beings have really big brains and we do,
[00:41:23.160 --> 00:41:24.160]   we're really intelligent as well,
[00:41:24.160 --> 00:41:26.380]   but yeah, our bodies are pretty cool too.
[00:41:26.380 --> 00:41:30.640]   - And it's a fascinating hierarchical biological system.
[00:41:30.640 --> 00:41:34.080]   Like we're made up of a bunch of different
[00:41:34.080 --> 00:41:38.000]   like living organisms that all don't know
[00:41:38.000 --> 00:41:40.880]   about the big picture of our body.
[00:41:40.880 --> 00:41:42.920]   And it's all functioning in its own little local world
[00:41:42.920 --> 00:41:46.400]   and it's doing its thing, but together it has,
[00:41:46.400 --> 00:41:48.940]   it forms a super resilient system.
[00:41:48.940 --> 00:41:52.800]   All of that comes from a very
[00:41:53.880 --> 00:41:57.200]   compressed encoding of what makes a human.
[00:41:57.200 --> 00:41:59.120]   You start with the DNA and it builds up
[00:41:59.120 --> 00:42:01.700]   from a single cell to a giant organism.
[00:42:01.700 --> 00:42:05.600]   I mean, and because of the DNA,
[00:42:05.600 --> 00:42:06.780]   through the evolution process,
[00:42:06.780 --> 00:42:09.240]   you can constantly create new humans
[00:42:09.240 --> 00:42:12.080]   and new living organisms that adapt to the environment.
[00:42:12.080 --> 00:42:15.120]   Like that resilience to the physical world,
[00:42:15.120 --> 00:42:19.060]   it seems like running the whole earth over again,
[00:42:19.060 --> 00:42:21.240]   the whole evolutionary process over again
[00:42:22.480 --> 00:42:25.240]   might be the only way to do it.
[00:42:25.240 --> 00:42:27.920]   So to create a robot that actually adapts,
[00:42:27.920 --> 00:42:32.060]   is as resilient to the dynamic world,
[00:42:32.060 --> 00:42:34.360]   might be a really difficult problem.
[00:42:34.360 --> 00:42:35.400]   - Possibly.
[00:42:35.400 --> 00:42:37.000]   Well, I was gonna say like in a programming environment,
[00:42:37.000 --> 00:42:38.660]   you can do things on timescales
[00:42:38.660 --> 00:42:41.040]   that are impossible in the real world, right?
[00:42:41.040 --> 00:42:43.440]   Like the benefit to AI and computers is computationally,
[00:42:43.440 --> 00:42:45.960]   they can compute so much data so quickly.
[00:42:45.960 --> 00:42:48.280]   Whereas on human timetables, we have to wait.
[00:42:48.280 --> 00:42:50.000]   When you talk about evolution,
[00:42:50.000 --> 00:42:53.160]   you know, it's generation after generation after generation.
[00:42:53.160 --> 00:42:55.720]   Maybe in a virtual environment that could be simulated
[00:42:55.720 --> 00:42:57.400]   and then those changes could happen a lot quicker.
[00:42:57.400 --> 00:42:58.720]   - Well, that's on a human timescale,
[00:42:58.720 --> 00:43:00.960]   but you have to look at earth
[00:43:00.960 --> 00:43:03.260]   as a quantum mechanical system,
[00:43:03.260 --> 00:43:05.240]   the computation is happening super fast.
[00:43:05.240 --> 00:43:08.140]   This is a giant computer doing a giant simulation.
[00:43:08.140 --> 00:43:10.720]   So just 'cause for us humans, it's slow,
[00:43:10.720 --> 00:43:13.720]   there's like trillions of organisms involved in you,
[00:43:13.720 --> 00:43:15.480]   destiny being you.
[00:43:15.480 --> 00:43:19.480]   - Sure, but the next iteration of like from human to human,
[00:43:19.480 --> 00:43:21.080]   even if on the quantum level, there's a lot of stuff
[00:43:21.080 --> 00:43:23.560]   going on, you talk about like changes in DNA,
[00:43:23.560 --> 00:43:24.680]   for instance, right?
[00:43:24.680 --> 00:43:26.760]   Like that's happening from a generation
[00:43:26.760 --> 00:43:27.920]   to generation timescale.
[00:43:27.920 --> 00:43:28.880]   Like in a virtual environment,
[00:43:28.880 --> 00:43:30.280]   that could theoretically happen.
[00:43:30.280 --> 00:43:32.160]   Well, it already is, there's like protein folding,
[00:43:32.160 --> 00:43:35.000]   like huge cloud computing, probably ML stuff
[00:43:35.000 --> 00:43:36.320]   that's like working on doing all of that stuff.
[00:43:36.320 --> 00:43:38.400]   And it'll run like trillions and trillions of simulations,
[00:43:38.400 --> 00:43:40.440]   you know, every second and stuff, maybe not every second,
[00:43:40.440 --> 00:43:41.960]   but-- - Still slower
[00:43:41.960 --> 00:43:44.200]   than the actual protein folding, much slower.
[00:43:45.520 --> 00:43:49.680]   That's for the problem of solving protein folding
[00:43:49.680 --> 00:43:52.360]   to estimate the 3D structure, but the actual body
[00:43:52.360 --> 00:43:54.960]   does the actual protein folding way faster.
[00:43:54.960 --> 00:43:58.040]   So like we're, the question is, can we shortcut
[00:43:58.040 --> 00:44:00.840]   the simulation of human evolution,
[00:44:00.840 --> 00:44:03.040]   try to figure out how to build up an organism
[00:44:03.040 --> 00:44:05.360]   without simulating all the details?
[00:44:05.360 --> 00:44:07.960]   'Cause we have to simulate all the details of biology
[00:44:07.960 --> 00:44:09.600]   where we're screwed, we don't have--
[00:44:09.600 --> 00:44:11.200]   - Oh, true, we'd have to put something in a pond
[00:44:11.200 --> 00:44:12.280]   and then watch it for a billion years.
[00:44:12.280 --> 00:44:14.040]   - That might be the most efficient way to do it.
[00:44:14.040 --> 00:44:15.760]   - Sure. - That's what the universe
[00:44:15.760 --> 00:44:18.720]   most likely is, is a kind of simulation created
[00:44:18.720 --> 00:44:22.620]   by a teenager in their basement to try to see what happens.
[00:44:22.620 --> 00:44:24.480]   It's a computer game.
[00:44:24.480 --> 00:44:25.840]   That might be the most efficient way
[00:44:25.840 --> 00:44:28.200]   to create interesting organisms.
[00:44:28.200 --> 00:44:31.280]   But within the system, it's perhaps possible
[00:44:31.280 --> 00:44:36.280]   to create other robots that will be of use
[00:44:36.280 --> 00:44:38.800]   and will entertain us in the way
[00:44:38.800 --> 00:44:40.680]   that other humans entertain us.
[00:44:40.680 --> 00:44:42.920]   And that's a really interesting, of course, problem.
[00:44:42.920 --> 00:44:46.120]   But it's surprising how difficult it has been
[00:44:46.120 --> 00:44:49.920]   to create systems that operate in the physical world
[00:44:49.920 --> 00:44:51.240]   and operate in that physical world
[00:44:51.240 --> 00:44:55.640]   in a way that's safe to humans and interesting to humans.
[00:44:55.640 --> 00:44:57.160]   'Cause there's also the human factor,
[00:44:57.160 --> 00:44:58.520]   the human-robot interaction.
[00:44:58.520 --> 00:45:00.680]   To me, that's the most interesting problem,
[00:45:00.680 --> 00:45:02.680]   to figure out how to do that well.
[00:45:02.680 --> 00:45:07.120]   And so Elon Musk and others, Boston Dynamics
[00:45:07.120 --> 00:45:08.320]   have worked on legged robots,
[00:45:08.320 --> 00:45:11.120]   so I really care about legged robots.
[00:45:11.120 --> 00:45:12.800]   Those are super interesting.
[00:45:12.800 --> 00:45:16.360]   How to make them such that they're able
[00:45:16.360 --> 00:45:18.840]   to operate successfully in a dynamic environment.
[00:45:18.840 --> 00:45:20.080]   It's super tricky.
[00:45:20.080 --> 00:45:23.120]   They're like the dumbest of dogs,
[00:45:23.120 --> 00:45:25.520]   speaking of which, there's a dog barking outside.
[00:45:25.520 --> 00:45:29.080]   It's really tricky to create those kinds of organisms
[00:45:29.080 --> 00:45:31.680]   that live in the human world.
[00:45:31.680 --> 00:45:35.720]   Then again, if more and more of us move
[00:45:35.720 --> 00:45:39.880]   into the digital world, so you stream a lot,
[00:45:39.880 --> 00:45:44.880]   like part of who you are exists in the digital space.
[00:45:44.880 --> 00:45:48.520]   The fact that you have a physical representation also,
[00:45:48.520 --> 00:45:51.580]   maybe more and more will become not important.
[00:45:51.580 --> 00:45:53.440]   - I hope that's the case,
[00:45:53.440 --> 00:45:54.680]   'cause I bought a lot of stock in Meta,
[00:45:54.680 --> 00:45:57.080]   and man, it's down a lot.
[00:45:57.080 --> 00:45:59.000]   - Meta the company?
[00:45:59.000 --> 00:46:02.360]   Is there some degree, can you look at yourself,
[00:46:02.360 --> 00:46:05.000]   like Steven, the physical meat vehicle,
[00:46:05.000 --> 00:46:07.820]   and then the destiny, this digital space,
[00:46:07.820 --> 00:46:12.780]   like digital avatar, do you sense that in a certain way
[00:46:12.780 --> 00:46:14.740]   you're the digital avatar?
[00:46:14.740 --> 00:46:16.740]   - I've always tried to keep my on-stream personality
[00:46:16.740 --> 00:46:19.440]   as genuine as possible, so they're one and the same to me.
[00:46:19.440 --> 00:46:21.740]   I don't really view them as two separate entities,
[00:46:21.740 --> 00:46:23.780]   but I mean, I always view myself as Steven,
[00:46:23.780 --> 00:46:25.260]   the real-life person.
[00:46:25.260 --> 00:46:26.900]   Destiny's my online name, but--
[00:46:26.900 --> 00:46:29.420]   - No, but because your social network
[00:46:29.420 --> 00:46:31.020]   is established in the digital space,
[00:46:31.020 --> 00:46:33.460]   so many people know you through the digital space.
[00:46:33.460 --> 00:46:37.180]   Can we swap out another person that looks like you?
[00:46:37.180 --> 00:46:40.100]   In like an AI system, and then that entity
[00:46:40.100 --> 00:46:42.140]   known as destiny will continue existing.
[00:46:42.140 --> 00:46:45.460]   - I mean, there must be some level of sophistication
[00:46:45.460 --> 00:46:48.260]   that could emulate a human brain, I would imagine, right?
[00:46:48.260 --> 00:46:50.820]   Probably the tech's not there yet, but--
[00:46:50.820 --> 00:46:53.820]   - Well, the question is, what's the level of sophistication
[00:46:53.820 --> 00:46:55.580]   of the audience that would recognize
[00:46:55.580 --> 00:46:56.940]   that something has changed?
[00:46:56.940 --> 00:47:00.340]   It's the Turing test.
[00:47:00.340 --> 00:47:03.500]   How hard is it to trick your audience,
[00:47:03.500 --> 00:47:07.460]   your large audience of fans that watch your streams,
[00:47:07.460 --> 00:47:11.220]   that when you swap out an AI that emulates you,
[00:47:11.220 --> 00:47:13.180]   that nothing has changed?
[00:47:13.180 --> 00:47:16.180]   And the question is, do you have to really simulate
[00:47:16.180 --> 00:47:18.020]   so much of the human brain for that?
[00:47:18.020 --> 00:47:19.180]   I don't think so.
[00:47:19.180 --> 00:47:20.940]   - Probably not.
[00:47:20.940 --> 00:47:25.420]   - So, I mean, like you said, a lot of political discourse
[00:47:25.420 --> 00:47:27.740]   is just walking down the tree together,
[00:47:27.740 --> 00:47:30.380]   so you can probably emulate a lot of that discussion.
[00:47:30.380 --> 00:47:32.620]   - Yeah, it would depend on if you're doing old data sets
[00:47:32.620 --> 00:47:33.500]   and you're training on that,
[00:47:33.500 --> 00:47:35.300]   and I'm having conversations about abortion
[00:47:35.300 --> 00:47:36.300]   and you're creating vaccines,
[00:47:36.300 --> 00:47:38.060]   I imagine it could do it for quite a while.
[00:47:38.060 --> 00:47:38.900]   The only thing that would be weird
[00:47:38.900 --> 00:47:40.420]   is when novel issues pop up.
[00:47:40.420 --> 00:47:43.380]   Then you probably need a more sophisticated resemblance
[00:47:43.380 --> 00:47:44.220]   of the inner brain, right?
[00:47:44.220 --> 00:47:46.340]   - You have to keep training on the internet,
[00:47:46.340 --> 00:47:47.500]   so how the language models,
[00:47:47.500 --> 00:47:49.140]   and that's the most incredible breakthrough,
[00:47:49.140 --> 00:47:50.380]   is just the language models.
[00:47:50.380 --> 00:47:54.220]   You just have to keep retraining the system on Reddit,
[00:47:54.220 --> 00:47:56.260]   which is actually what a lot of it is trained on,
[00:47:56.260 --> 00:47:57.380]   which is hilarious.
[00:47:57.380 --> 00:47:58.580]   - I do think it's really interesting
[00:47:58.580 --> 00:48:01.140]   that funny problems, like the trolley problem,
[00:48:01.140 --> 00:48:02.540]   that we can kind of work through our
[00:48:02.540 --> 00:48:03.740]   normative ethical systems on,
[00:48:03.740 --> 00:48:05.820]   are now like real questions.
[00:48:05.820 --> 00:48:07.540]   If you're driving a Tesla and it's on autopilot
[00:48:07.540 --> 00:48:08.380]   and you're gonna hit somebody,
[00:48:08.380 --> 00:48:10.100]   but it can swerve and hit somebody else,
[00:48:10.100 --> 00:48:11.940]   what ought the system do?
[00:48:11.940 --> 00:48:15.980]   We went very quickly from fun project in philosophy class
[00:48:15.980 --> 00:48:18.580]   to we need to solve this for insurance purposes
[00:48:18.580 --> 00:48:19.580]   as quickly as possible.
[00:48:19.580 --> 00:48:21.100]   It's kind of interesting to think about.
[00:48:21.100 --> 00:48:22.700]   - Well, I actually have,
[00:48:22.700 --> 00:48:25.100]   I'll bring up the trolley problem with you later.
[00:48:25.100 --> 00:48:28.260]   There's a fascinating version of it that I find hilarious.
[00:48:28.260 --> 00:48:30.940]   Okay, let's return to your low point.
[00:48:30.940 --> 00:48:31.780]   - Oh yeah.
[00:48:31.780 --> 00:48:34.220]   - You started playing video games.
[00:48:34.220 --> 00:48:36.100]   That was a lucky break.
[00:48:36.100 --> 00:48:37.300]   You did text-based ones.
[00:48:37.300 --> 00:48:38.140]   That was a lucky break
[00:48:38.140 --> 00:48:40.380]   'cause you've gotten to be pretty good at learning.
[00:48:40.380 --> 00:48:43.180]   And then you started thinking about going to college
[00:48:43.180 --> 00:48:44.020]   and so on.
[00:48:44.020 --> 00:48:44.860]   What happened next?
[00:48:44.860 --> 00:48:46.260]   - I mean, I went to like a prep school.
[00:48:46.260 --> 00:48:47.940]   So you kind of have to go to college after.
[00:48:47.940 --> 00:48:48.780]   That's like the point, right?
[00:48:48.780 --> 00:48:50.020]   I was also a millennial.
[00:48:50.020 --> 00:48:51.020]   All of us had to go to college.
[00:48:51.020 --> 00:48:52.060]   That's always what they told us.
[00:48:52.060 --> 00:48:54.820]   So my life was kind of,
[00:48:54.820 --> 00:48:57.300]   it's hard to describe.
[00:48:57.300 --> 00:48:58.780]   I didn't really think much of the future.
[00:48:58.780 --> 00:49:00.340]   I was just kind of enjoying the day-to-day
[00:49:00.340 --> 00:49:02.340]   'cause everything in my life was pretty weird.
[00:49:02.340 --> 00:49:04.260]   Both my parents had moved to Florida
[00:49:04.260 --> 00:49:05.860]   by the time I was 16, 17.
[00:49:05.860 --> 00:49:06.700]   I was living with my grandma.
[00:49:06.700 --> 00:49:07.820]   I was working.
[00:49:07.820 --> 00:49:09.980]   I had a girlfriend, moved out.
[00:49:09.980 --> 00:49:11.560]   We got a place, did college.
[00:49:11.560 --> 00:49:13.820]   By the time I got into college,
[00:49:13.820 --> 00:49:16.340]   I had transitioned from working at McDonald's
[00:49:16.340 --> 00:49:19.260]   to I was like working in a casino restaurant basically.
[00:49:19.260 --> 00:49:21.020]   And I was really good at that job.
[00:49:21.020 --> 00:49:24.700]   So high level of patience for drunk people and sane people.
[00:49:24.700 --> 00:49:26.700]   And I was doing music in school
[00:49:26.700 --> 00:49:28.140]   'cause I'd really grown to love music.
[00:49:28.140 --> 00:49:30.380]   And my kind of thought process was,
[00:49:30.380 --> 00:49:33.260]   my thought process was I can do music as a hobby, I guess,
[00:49:33.260 --> 00:49:34.100]   unless I get really good
[00:49:34.100 --> 00:49:35.260]   and maybe I can make money with that.
[00:49:35.260 --> 00:49:36.420]   But otherwise I love music.
[00:49:36.420 --> 00:49:38.220]   I'm okay going to school for music, getting good at it.
[00:49:38.220 --> 00:49:39.580]   And then just doing that on the side.
[00:49:39.580 --> 00:49:40.580]   And then my main job would kind of be
[00:49:40.580 --> 00:49:43.420]   this career I was building at the casino.
[00:49:43.420 --> 00:49:47.040]   And basically the trying to balance personal life
[00:49:47.040 --> 00:49:49.540]   plus graveyard shift, six to eight weeks at a casino,
[00:49:49.540 --> 00:49:52.340]   and then a full-time music degree was not possible for me.
[00:49:52.340 --> 00:49:53.840]   And eventually I had to drop school
[00:49:53.840 --> 00:49:55.860]   after I think it was like three years.
[00:49:55.860 --> 00:49:59.220]   And after I dropped school to maintain my casino job,
[00:49:59.220 --> 00:50:02.220]   after a few months, I got fired from my casino job.
[00:50:02.220 --> 00:50:03.260]   So I'd essentially just thrown away
[00:50:03.260 --> 00:50:05.900]   like the past like three or four years of my life.
[00:50:05.900 --> 00:50:07.740]   - Why'd you get fired from the casino job?
[00:50:07.740 --> 00:50:09.180]   I heard there's a story behind that.
[00:50:09.180 --> 00:50:10.060]   - Yeah, there's a story.
[00:50:10.060 --> 00:50:11.420]   Basically I was just really dumb
[00:50:11.420 --> 00:50:13.180]   when it came to understanding corporate politics.
[00:50:13.180 --> 00:50:14.700]   And this is funny 'cause the same attitude
[00:50:14.700 --> 00:50:17.180]   kind of followed me into the streaming world.
[00:50:17.180 --> 00:50:19.220]   My thought process has kind of always been
[00:50:19.220 --> 00:50:21.760]   that like as long as I'm really good at what I do,
[00:50:21.760 --> 00:50:22.860]   I should be untouchable.
[00:50:22.860 --> 00:50:24.420]   If I'm really good, you can't do anything to me.
[00:50:24.420 --> 00:50:26.660]   I don't have to play any dumb games or whatever.
[00:50:26.660 --> 00:50:29.660]   And at the casino, I think I was the youngest.
[00:50:29.660 --> 00:50:30.740]   It was originally shiftly
[00:50:30.740 --> 00:50:33.340]   than supervisor position at the casino.
[00:50:33.340 --> 00:50:35.900]   And when I started to get my own shifts,
[00:50:35.900 --> 00:50:38.160]   there were problems that I would run into on graveyard shift
[00:50:38.160 --> 00:50:40.500]   because of carryover from the swing shift.
[00:50:40.500 --> 00:50:41.400]   I remember one of these problems
[00:50:41.400 --> 00:50:42.700]   was underneath the soda machine,
[00:50:42.700 --> 00:50:43.780]   they weren't cleaning it properly
[00:50:43.780 --> 00:50:45.500]   and fruit flies were showing up.
[00:50:45.500 --> 00:50:48.700]   And the manager came in one morning and she was like,
[00:50:48.700 --> 00:50:50.780]   "Hey, what's going on with the machine?"
[00:50:50.780 --> 00:50:51.620]   And I told her, I was like,
[00:50:51.620 --> 00:50:54.460]   "I'm done, I can't take everything from swing shift
[00:50:54.460 --> 00:50:55.980]   and do everything at grave shift, I can't do this.
[00:50:55.980 --> 00:50:57.340]   They need to figure out their stuff better
[00:50:57.340 --> 00:50:59.460]   or I need more employees, it's not possible for me."
[00:50:59.460 --> 00:51:00.740]   And she's like, "What did you tell anybody else?"
[00:51:00.740 --> 00:51:02.740]   I was like, "Yeah, I complained to the supervisor
[00:51:02.740 --> 00:51:04.340]   on the swing shift all the time."
[00:51:04.340 --> 00:51:06.840]   And she told me, "If you're not getting the answer
[00:51:06.840 --> 00:51:08.900]   that you like, then it's your responsibility
[00:51:08.900 --> 00:51:11.100]   to email the next person up."
[00:51:11.100 --> 00:51:13.220]   And I was like, "Oh, okay, that's interesting."
[00:51:13.220 --> 00:51:16.020]   And some months went on and I ran into more problems
[00:51:16.020 --> 00:51:18.080]   because on graveyard, here's how,
[00:51:18.080 --> 00:51:19.020]   I don't know if it's everywhere,
[00:51:19.020 --> 00:51:20.820]   but morning shift is the easiest
[00:51:20.820 --> 00:51:22.060]   and that's when you're the most overstaffed
[00:51:22.060 --> 00:51:23.420]   because that's when all the VPs are in
[00:51:23.420 --> 00:51:24.660]   and that's when all the managers are there
[00:51:24.660 --> 00:51:25.620]   and everybody blah, blah, blah.
[00:51:25.620 --> 00:51:27.460]   Swing shift is the most challenging,
[00:51:27.460 --> 00:51:29.620]   that's where your highest flow of customers is.
[00:51:29.620 --> 00:51:30.800]   You're also decently staffed there,
[00:51:30.800 --> 00:51:32.020]   but there's a lot of stuff going on.
[00:51:32.020 --> 00:51:34.540]   And graveyard, nobody cares at all about you.
[00:51:34.540 --> 00:51:35.900]   They don't give you any employees.
[00:51:35.900 --> 00:51:37.780]   You might get swamped, you might not, who cares?
[00:51:37.780 --> 00:51:38.860]   Make sure it's clean for day shift,
[00:51:38.860 --> 00:51:39.780]   that's the only thing that matters.
[00:51:39.780 --> 00:51:41.500]   - A quick question, first of all, clarification.
[00:51:41.500 --> 00:51:43.740]   So this is 24 hour?
[00:51:43.740 --> 00:51:45.420]   - 24 hour diner, yeah, inside the casino, yeah.
[00:51:45.420 --> 00:51:47.020]   - So it's a diner in a casino.
[00:51:47.020 --> 00:51:48.820]   Oh, by the way, I had an amazing moment
[00:51:48.820 --> 00:51:50.580]   at a diner in a casino recently.
[00:51:50.580 --> 00:51:51.860]   It's a special place.
[00:51:51.860 --> 00:51:54.140]   A diner in a casino is a place of magic.
[00:51:54.140 --> 00:51:56.220]   - There's a lot of, I don't know if I'd say magic,
[00:51:56.220 --> 00:51:57.860]   but there's a lot of other worldly stuff going on.
[00:51:57.860 --> 00:51:59.540]   - There's characters, there's,
[00:51:59.540 --> 00:52:01.980]   and I had an interaction with a waitress
[00:52:01.980 --> 00:52:03.980]   that was the sweetest waitress in the world.
[00:52:03.980 --> 00:52:05.580]   And it was just like, I don't know,
[00:52:05.580 --> 00:52:09.620]   made me feel less alone in this cruel world of ours.
[00:52:09.620 --> 00:52:11.580]   So graveyard begins when?
[00:52:11.580 --> 00:52:13.900]   - For me, my shift was 10 p.m. to 6 a.m.
[00:52:13.900 --> 00:52:15.060]   Or sometimes I got called in early,
[00:52:15.060 --> 00:52:16.740]   so it'd be 8 p.m. to 6 a.m.
[00:52:16.740 --> 00:52:19.620]   - That's no love for that shift.
[00:52:19.620 --> 00:52:21.380]   - No, especially not trying to do school at the same time.
[00:52:21.380 --> 00:52:22.260]   Absolutely not.
[00:52:22.260 --> 00:52:24.600]   But yeah, basically, long story short,
[00:52:24.600 --> 00:52:25.700]   I ran into a problem with my,
[00:52:25.700 --> 00:52:28.020]   where I didn't have enough employees on my shift.
[00:52:28.020 --> 00:52:29.220]   VPs were coming in in the morning,
[00:52:29.220 --> 00:52:31.020]   and they're just like, "Hey, the diner's kind of dirty."
[00:52:31.020 --> 00:52:33.100]   And I'm like, "You've cut all my employees past 4 a.m."
[00:52:33.100 --> 00:52:34.580]   Like on some nights, I'm literally cooking
[00:52:34.580 --> 00:52:36.500]   and doing front of house, like all on my own.
[00:52:36.500 --> 00:52:37.820]   Like, I can't do this.
[00:52:37.820 --> 00:52:39.980]   And my manager, Pam, told me,
[00:52:39.980 --> 00:52:41.340]   "Well, you've got to figure it out."
[00:52:41.340 --> 00:52:43.260]   And so I remembered her advice.
[00:52:43.260 --> 00:52:45.940]   So I emailed the VP of food and beverage, and I CC'd her.
[00:52:45.940 --> 00:52:46.980]   And I said, "I'm not getting the help
[00:52:46.980 --> 00:52:48.020]   "I need on my restaurant."
[00:52:48.020 --> 00:52:48.980]   Now, I didn't know at the time
[00:52:48.980 --> 00:52:51.380]   that I was basically completely throwing her under the bus
[00:52:51.380 --> 00:52:52.740]   because of that email.
[00:52:52.740 --> 00:52:55.900]   But retroactively, when I look back on things,
[00:52:55.900 --> 00:52:58.140]   or retrospectively, I see that was the moment
[00:52:58.140 --> 00:53:00.140]   that I got marked for deletion.
[00:53:00.140 --> 00:53:01.500]   And I didn't really understand it,
[00:53:01.500 --> 00:53:02.980]   even though I'd heard terminology
[00:53:02.980 --> 00:53:04.340]   for papering somebody out the door.
[00:53:04.340 --> 00:53:06.140]   But after that point, I started to get written up
[00:53:06.140 --> 00:53:07.900]   for a lot of little, random things.
[00:53:07.900 --> 00:53:10.140]   Like, I'd missed one day of work
[00:53:10.140 --> 00:53:11.940]   in my three years at the casino.
[00:53:11.940 --> 00:53:13.220]   And I started to get written up
[00:53:13.220 --> 00:53:14.980]   for showing up one or two minutes late.
[00:53:14.980 --> 00:53:16.900]   That's kind of weird, I don't know, that's whatever.
[00:53:16.900 --> 00:53:19.140]   Or written up for random ways about filing paperwork.
[00:53:19.140 --> 00:53:20.860]   And then eventually there came a situation
[00:53:20.860 --> 00:53:23.340]   with another employee where they were,
[00:53:23.340 --> 00:53:24.820]   it's complicated, it has to do with call-out stuff.
[00:53:24.820 --> 00:53:27.460]   But basically, they wanted to call out,
[00:53:27.460 --> 00:53:28.620]   and I told them that if they called out,
[00:53:28.620 --> 00:53:31.580]   they were gonna get fired because they were at 10 points.
[00:53:31.580 --> 00:53:32.740]   They were at nine points and 10 points
[00:53:32.740 --> 00:53:33.740]   of the firing, blah, blah, blah.
[00:53:33.740 --> 00:53:35.220]   Pam told me, "You can tell her
[00:53:35.220 --> 00:53:36.060]   "that she's gonna get a point,
[00:53:36.060 --> 00:53:37.460]   "but you can't tell her she's gonna get fired."
[00:53:37.460 --> 00:53:38.420]   I don't know what that meant.
[00:53:38.420 --> 00:53:39.980]   And then I told her that if you call out,
[00:53:39.980 --> 00:53:42.060]   you're fucked, you're gonna get fired,
[00:53:42.060 --> 00:53:43.460]   or you're gonna be at 10 points.
[00:53:43.460 --> 00:53:45.740]   And then I got called in early, like three days later,
[00:53:45.740 --> 00:53:47.900]   and Pam was like, "You inappropriately communicated
[00:53:47.900 --> 00:53:49.540]   "with an employee because you said the F word
[00:53:49.540 --> 00:53:50.420]   "in a text message."
[00:53:50.420 --> 00:53:51.260]   And I'm like, "Really?
[00:53:51.260 --> 00:53:52.260]   "There's no shot."
[00:53:52.260 --> 00:53:53.980]   And she's like, "Well, you also tried to fire the employee."
[00:53:53.980 --> 00:53:54.800]   And I was like, "No, I told her
[00:53:54.800 --> 00:53:55.940]   "she was gonna get 10 points."
[00:53:55.940 --> 00:53:57.060]   She's like, "Well, you used the F word."
[00:53:57.060 --> 00:53:58.580]   I'm like, "This is insane."
[00:53:58.580 --> 00:54:01.140]   And I didn't, just 'cause I was such a high-performing
[00:54:01.140 --> 00:54:02.500]   employee, I was like, "There's no way I'm getting fired."
[00:54:02.500 --> 00:54:04.500]   And then I did, and I was like, "Yeah."
[00:54:04.500 --> 00:54:07.020]   Cashed out my 401(k) and moped for like three months
[00:54:07.020 --> 00:54:09.780]   'cause I had thrown away school for this casino job.
[00:54:09.780 --> 00:54:11.860]   And then I got fired from this job that, yeah,
[00:54:11.860 --> 00:54:13.260]   nobody believed I got fired.
[00:54:13.260 --> 00:54:14.460]   It was just insane.
[00:54:14.460 --> 00:54:16.460]   - So if you look back, if you were allowed to not just
[00:54:16.460 --> 00:54:20.020]   to look back to your own memory, but actually watch yourself,
[00:54:20.020 --> 00:54:22.660]   like somebody recorded a video that whole time,
[00:54:22.660 --> 00:54:24.360]   do you think you would be surprised,
[00:54:24.360 --> 00:54:26.860]   you would notice some things, like potentially,
[00:54:26.860 --> 00:54:30.620]   of not having a self-awareness, not having social,
[00:54:30.620 --> 00:54:33.340]   like a civility and social etiquette that's played
[00:54:33.340 --> 00:54:34.860]   in the human relations?
[00:54:34.860 --> 00:54:35.860]   - Yeah, absolutely.
[00:54:35.860 --> 00:54:39.340]   - So is that at the core of it, essentially?
[00:54:39.340 --> 00:54:40.180]   - Yeah, I think so.
[00:54:40.180 --> 00:54:41.780]   I mean, it follows me even to this day.
[00:54:41.780 --> 00:54:44.380]   There's a lot of, I don't know if you're recording or not,
[00:54:44.380 --> 00:54:46.420]   but when we spoke earlier about like meta conversations,
[00:54:46.420 --> 00:54:48.620]   I have to think a lot sometimes about meta conversations
[00:54:48.620 --> 00:54:50.460]   'cause the way that I wanna drive a conversation
[00:54:50.460 --> 00:54:52.620]   will sometimes be way different than what is like
[00:54:52.620 --> 00:54:54.460]   the best way to have a conversation.
[00:54:54.460 --> 00:54:56.380]   Whereas I just wanna like go really hard
[00:54:56.380 --> 00:54:59.020]   on like some itty-bitty, like some idiosyncrasy,
[00:54:59.020 --> 00:55:00.420]   some factor, figure, whatever,
[00:55:00.420 --> 00:55:03.260]   but that's not like the human conversation I need to have.
[00:55:03.260 --> 00:55:07.580]   - So you got fired/left that job,
[00:55:07.580 --> 00:55:11.300]   and that took you to the job that would be the lowest point.
[00:55:11.300 --> 00:55:12.140]   - Yeah.
[00:55:12.140 --> 00:55:12.960]   (Lex laughing)
[00:55:12.960 --> 00:55:15.340]   'Cause there was a huge downgrade in pay.
[00:55:15.340 --> 00:55:17.660]   I went from getting like, I think at the casino,
[00:55:17.660 --> 00:55:18.860]   'cause I worked so much overtime,
[00:55:18.860 --> 00:55:21.140]   I was getting like 20 to 50 an hour on all my overtime.
[00:55:21.140 --> 00:55:25.060]   And this was back in 2008, 2009, as like a college student.
[00:55:25.060 --> 00:55:26.500]   Like it was amazing pay.
[00:55:26.500 --> 00:55:29.260]   The guy had benefits, like everything was good.
[00:55:29.260 --> 00:55:30.940]   And then the carpet cleaning was like,
[00:55:30.940 --> 00:55:33.700]   I was probably getting my paycheck like every other week
[00:55:33.700 --> 00:55:36.780]   was maybe 1,500 bucks or $1,000.
[00:55:36.780 --> 00:55:39.220]   And I'm working like 13 day stretches.
[00:55:39.220 --> 00:55:42.260]   Like I have every other Sunday off, and it's so many hours.
[00:55:42.260 --> 00:55:44.620]   Like I have to show up at the shop at like seven or six,
[00:55:44.620 --> 00:55:46.700]   and then I go home at like eight or nine,
[00:55:46.700 --> 00:55:48.340]   depending on when my jobs are throughout the day.
[00:55:48.340 --> 00:55:50.620]   - You doing businesses or residential,
[00:55:50.620 --> 00:55:51.460]   or what are you doing?
[00:55:51.460 --> 00:55:52.280]   - Everything.
[00:55:52.280 --> 00:55:53.120]   - Everything.
[00:55:53.120 --> 00:55:55.060]   Are you working for a company that does carpet cleaning?
[00:55:55.060 --> 00:55:56.100]   - Yeah.
[00:55:56.100 --> 00:55:57.940]   - Okay, and so like there's a schedule thing,
[00:55:57.940 --> 00:55:59.260]   you have to go to it and so on.
[00:55:59.260 --> 00:56:01.460]   - Yeah, but so like this is why the schedule would suck.
[00:56:01.460 --> 00:56:03.500]   'Cause sometimes I'd show up at,
[00:56:03.500 --> 00:56:04.900]   I think we had to be in the shop at,
[00:56:04.900 --> 00:56:06.020]   I think it was 7 a.m.
[00:56:06.020 --> 00:56:07.540]   We show up at the shop at 7 a.m.
[00:56:07.540 --> 00:56:09.140]   First job might be at eight or nine,
[00:56:09.140 --> 00:56:10.800]   but that job might be like a one hour job.
[00:56:10.800 --> 00:56:11.780]   So I might show up at 7 a.m.
[00:56:11.780 --> 00:56:13.340]   and have a job from 8.30 to 9.30.
[00:56:13.340 --> 00:56:15.100]   Then my next job might not be from,
[00:56:15.100 --> 00:56:16.260]   until like say 11.
[00:56:16.260 --> 00:56:18.420]   So from 8.30 to 9.30 I'll do one job.
[00:56:18.420 --> 00:56:21.740]   And then I've got a job from like 11 to 12 or something.
[00:56:21.740 --> 00:56:24.900]   Then I might have like a decent job from like five to eight.
[00:56:24.900 --> 00:56:26.700]   But like my whole day is destroyed.
[00:56:26.700 --> 00:56:30.340]   And I'm doing like three smallest jobs.
[00:56:30.340 --> 00:56:33.300]   So I'm getting like 30 bucks maybe for being in the shop,
[00:56:33.300 --> 00:56:35.420]   or you know, my job for like 10 or 11 hours.
[00:56:35.420 --> 00:56:36.980]   It's just like horrible.
[00:56:36.980 --> 00:56:39.580]   - So you're somebody that seems to be extremely good
[00:56:39.580 --> 00:56:41.460]   at thinking and conversation.
[00:56:41.460 --> 00:56:44.860]   And so have a bit of an ego perhaps,
[00:56:44.860 --> 00:56:48.300]   in both the negative and the positive sense of that word.
[00:56:48.300 --> 00:56:52.220]   Was there some aspect of working at McDonald's
[00:56:52.220 --> 00:56:53.900]   and then working at the casino
[00:56:53.900 --> 00:56:57.580]   and then working as a carpet cleaner that was humbling?
[00:56:57.580 --> 00:56:58.840]   - No, never.
[00:56:58.840 --> 00:57:00.780]   I had a--
[00:57:00.780 --> 00:57:02.420]   - The ego burned bright through it all.
[00:57:04.180 --> 00:57:06.020]   Or no, you can push back on the ego.
[00:57:06.020 --> 00:57:06.900]   - Yeah, no, I understand.
[00:57:06.900 --> 00:57:08.140]   I totally get what you mean.
[00:57:08.140 --> 00:57:11.020]   I had a really close friend growing up whose name was Chris.
[00:57:11.020 --> 00:57:12.460]   And I think we probably met when he was,
[00:57:12.460 --> 00:57:13.900]   we were like four or five, I think.
[00:57:13.900 --> 00:57:15.060]   He lived behind me.
[00:57:15.060 --> 00:57:16.260]   And I grew up with him
[00:57:16.260 --> 00:57:18.360]   and I'd always been kind of an outsider
[00:57:18.360 --> 00:57:20.580]   to the world that I was in
[00:57:20.580 --> 00:57:22.540]   once I got to high school for sure.
[00:57:22.540 --> 00:57:25.020]   Because all of those kids were incredibly wealthy,
[00:57:25.020 --> 00:57:27.560]   you know, Corvettes and Mustangs when they turned 16.
[00:57:27.560 --> 00:57:28.660]   It was a prep school.
[00:57:28.660 --> 00:57:29.980]   And I was doing the,
[00:57:29.980 --> 00:57:31.380]   they had like a work study program there
[00:57:31.380 --> 00:57:33.820]   where you could stay after school from 2.30 to five
[00:57:33.820 --> 00:57:36.340]   every day to kind of like work to pay for your tuition.
[00:57:36.340 --> 00:57:39.020]   So I'd been working like throughout all of high school.
[00:57:39.020 --> 00:57:41.220]   I got another job at McDonald's when I was 18,
[00:57:41.220 --> 00:57:42.060]   worked at the casino.
[00:57:42.060 --> 00:57:43.620]   Like I'd always been doing that kind of work.
[00:57:43.620 --> 00:57:45.580]   I never really viewed it as like beneath me or anything.
[00:57:45.580 --> 00:57:47.420]   It's not like I don't have like a family of doctors
[00:57:47.420 --> 00:57:48.460]   or lawyers or anything.
[00:57:48.460 --> 00:57:50.140]   And then me and my other friend, Chris guy,
[00:57:50.140 --> 00:57:51.460]   we'd always make fun of everybody else
[00:57:51.460 --> 00:57:52.840]   for being kind of like, you know,
[00:57:52.840 --> 00:57:54.780]   like preppy kids and everything, so.
[00:57:54.780 --> 00:57:56.340]   - So there is a,
[00:57:56.340 --> 00:57:59.400]   there's some pride to that sort of hard work.
[00:57:59.400 --> 00:58:00.580]   - Yeah, I guess a little bit, yeah.
[00:58:00.580 --> 00:58:02.140]   'Cause, you know, looking especially at my dad,
[00:58:02.140 --> 00:58:03.140]   like the solution to every problem
[00:58:03.140 --> 00:58:05.140]   was just throw more hours of work at it basically.
[00:58:05.140 --> 00:58:07.260]   So that was always my, yeah, go-to.
[00:58:07.260 --> 00:58:08.100]   And I never, yeah.
[00:58:08.100 --> 00:58:10.940]   - So what was psychologically the low point?
[00:58:10.940 --> 00:58:13.460]   - I think psychologically the low point was that
[00:58:13.460 --> 00:58:15.400]   as I'm doing this carpet cleaning job,
[00:58:15.400 --> 00:58:20.120]   driving around my city, there's like this feeling of,
[00:58:20.120 --> 00:58:23.460]   I guess for a lot of people it's probably college,
[00:58:23.460 --> 00:58:25.820]   but there's a feeling when you're in high school
[00:58:25.820 --> 00:58:28.060]   that everything is like so exciting
[00:58:28.060 --> 00:58:30.460]   and the whole world is kind of in front of you
[00:58:30.460 --> 00:58:32.980]   and there are a trillion, trillion
[00:58:32.980 --> 00:58:35.320]   different branching paths of possibilities.
[00:58:35.320 --> 00:58:36.660]   And, you know, even through high school,
[00:58:36.660 --> 00:58:39.140]   you're thinking like, am I gonna be a doctor or a lawyer
[00:58:39.140 --> 00:58:41.420]   or can I join the NBA or can I do this or that?
[00:58:41.420 --> 00:58:43.660]   There's all these things in front of you.
[00:58:43.660 --> 00:58:45.980]   And when I especially felt it
[00:58:45.980 --> 00:58:47.500]   when I was doing these carpet cleaning jobs
[00:58:47.500 --> 00:58:49.860]   and I think it was in the fall,
[00:58:49.860 --> 00:58:51.160]   I'd be outside some of these houses
[00:58:51.160 --> 00:58:52.340]   and I just kind of look around
[00:58:52.340 --> 00:58:53.780]   and I'd recognize a lot of these neighborhoods
[00:58:53.780 --> 00:58:55.580]   that I'd drive around with friends in
[00:58:55.580 --> 00:58:56.860]   or I'd, you know, be walking through.
[00:58:56.860 --> 00:58:57.940]   I did, I ran cross country.
[00:58:57.940 --> 00:58:59.860]   Some of them I'd be running through these neighborhoods
[00:58:59.860 --> 00:59:01.780]   and it was just kind of like this feeling of looking around
[00:59:01.780 --> 00:59:04.620]   and it was like, when I was here in the past,
[00:59:04.620 --> 00:59:07.100]   this was like kind of like a transitionary phase of my life
[00:59:07.100 --> 00:59:09.380]   where I'm doing this and it's so fun and exciting
[00:59:09.380 --> 00:59:10.660]   and then I'm gonna move on to something else
[00:59:10.660 --> 00:59:12.540]   and it's gonna be fun and exciting and awesome.
[00:59:12.540 --> 00:59:14.980]   And then like, you know, two years later,
[00:59:14.980 --> 00:59:16.940]   my whole life has collapsed.
[00:59:16.940 --> 00:59:18.840]   Like I'm in a house that I can't afford anymore.
[00:59:18.840 --> 00:59:22.100]   My ex that I hate is pregnant with my kid
[00:59:22.100 --> 00:59:24.220]   and I have no money.
[00:59:24.220 --> 00:59:25.700]   I've got no upward mobility.
[00:59:25.700 --> 00:59:27.500]   I failed college.
[00:59:27.500 --> 00:59:28.900]   My job is horrible.
[00:59:28.900 --> 00:59:31.900]   Like just every single, like this is like my,
[00:59:31.900 --> 00:59:35.060]   all of those, the way function had collapsed into one thing
[00:59:35.060 --> 00:59:36.500]   and that one thing was the worst thing
[00:59:36.500 --> 00:59:38.740]   that it could have possibly been at the time for me.
[00:59:38.740 --> 00:59:40.140]   Yeah, like everything was gone and horrible.
[00:59:40.140 --> 00:59:41.820]   So yeah, that was the feeling I had at the time.
[00:59:41.820 --> 00:59:43.740]   - Do you ever contemplate suicide?
[00:59:43.740 --> 00:59:46.100]   - I thought about thinking about it,
[00:59:46.100 --> 00:59:48.300]   but I've just never been that kind of person, so.
[00:59:48.300 --> 00:59:50.900]   - I mean, basically as a way to escape from the hardship.
[00:59:50.900 --> 00:59:53.340]   - Something that I'm so incredibly lucky,
[00:59:53.340 --> 00:59:54.580]   I don't know why or how,
[00:59:54.580 --> 00:59:56.140]   I'm just gonna chalk it up to biology.
[00:59:56.140 --> 00:59:59.460]   I've always had really high mental baseline.
[00:59:59.460 --> 01:00:01.300]   I've like depression and all of that.
[01:00:01.300 --> 01:00:03.620]   There've been a few short stints I've dealt with it past 30
[01:00:03.620 --> 01:00:04.940]   because I did a lot of drugs.
[01:00:04.940 --> 01:00:08.260]   But other than that, my mental baseline is just so high.
[01:00:08.260 --> 01:00:10.380]   And even in the carpet cleaning days,
[01:00:10.380 --> 01:00:12.820]   like if you, man, the videos might still be there.
[01:00:12.820 --> 01:00:14.700]   I think on my old YouTube channel,
[01:00:14.700 --> 01:00:15.900]   where I'll be like playing StarCraft
[01:00:15.900 --> 01:00:17.340]   when I first started getting into streaming
[01:00:17.340 --> 01:00:18.580]   and I'll be calling up customers like,
[01:00:18.580 --> 01:00:19.780]   this is Steve from Guaranteed Clean.
[01:00:19.780 --> 01:00:21.380]   We had to move your job back one hour.
[01:00:21.380 --> 01:00:22.700]   Is it okay if I show up instead of 2.30?
[01:00:22.700 --> 01:00:23.940]   And then I hang up, it's like, all right guys,
[01:00:23.940 --> 01:00:25.540]   we've got three more games and it's like, let's go.
[01:00:25.540 --> 01:00:26.380]   Like stuff like that.
[01:00:26.380 --> 01:00:28.060]   So my baseline has always been like really high
[01:00:28.060 --> 01:00:28.900]   for mental function.
[01:00:28.900 --> 01:00:31.260]   - So even in low point, you had strength.
[01:00:31.260 --> 01:00:34.500]   Is there anything you can give by way of advice
[01:00:34.500 --> 01:00:37.900]   from people that, for whom the wave function collapses,
[01:00:37.900 --> 01:00:39.820]   as it does for many of us?
[01:00:39.820 --> 01:00:43.380]   Like, holy fuck, the world is not full of opportunity
[01:00:43.380 --> 01:00:45.180]   and you're kind of a failure.
[01:00:45.180 --> 01:00:47.260]   And like, I've been there.
[01:00:47.260 --> 01:00:48.100]   - Yeah, I don't know.
[01:00:48.100 --> 01:00:51.580]   It's rough because like, I usually ask for compassion
[01:00:51.580 --> 01:00:53.660]   from people that have it better off.
[01:00:53.660 --> 01:00:55.180]   Because like, once you're down there,
[01:00:55.180 --> 01:00:57.260]   like the only reason, I say I got lucky,
[01:00:57.260 --> 01:00:59.980]   but it wasn't even really lucky.
[01:00:59.980 --> 01:01:01.340]   Or it was lucky, but it was more lucky.
[01:01:01.340 --> 01:01:03.020]   It wasn't just lucky that I got into streaming.
[01:01:03.020 --> 01:01:05.260]   It was lucky that I was into computers at an early age.
[01:01:05.260 --> 01:01:07.100]   It was lucky that I played video games at an early age.
[01:01:07.100 --> 01:01:08.540]   It was lucky that all the tech came up
[01:01:08.540 --> 01:01:10.420]   at exactly that right point in time.
[01:01:10.420 --> 01:01:12.060]   Like I was a pretty smart guy,
[01:01:12.060 --> 01:01:15.180]   but it was definitely preparation meets opportunity.
[01:01:15.180 --> 01:01:16.340]   And that opportunity was like
[01:01:16.340 --> 01:01:18.380]   at the exact precise moment of my life.
[01:01:18.380 --> 01:01:19.620]   If anything had gone differently,
[01:01:19.620 --> 01:01:22.140]   then I would just be cleaning carpets today, so.
[01:01:22.140 --> 01:01:25.060]   - So in the many worlds interpretation of quantum mechanics,
[01:01:25.060 --> 01:01:27.420]   this is like one out of like.
[01:01:27.420 --> 01:01:29.660]   - There's many, many Stevens
[01:01:29.660 --> 01:01:32.220]   that are just still carpet cleaning
[01:01:32.220 --> 01:01:34.580]   and they're full of pain and resentment.
[01:01:34.580 --> 01:01:37.140]   - Yeah, the one piece of advice that I give,
[01:01:37.140 --> 01:01:38.420]   I hate that I have to push back against
[01:01:38.420 --> 01:01:40.180]   all these crypto bros and everybody online.
[01:01:40.180 --> 01:01:42.460]   For decently intelligent people that are successful,
[01:01:42.460 --> 01:01:45.020]   I've never heard anybody give a contradiction to this.
[01:01:45.020 --> 01:01:47.540]   Maybe you will, you can tell me if you disagree.
[01:01:47.540 --> 01:01:49.780]   I always look at kids in high school
[01:01:49.780 --> 01:01:51.580]   and I'm like, just try a little bit harder.
[01:01:51.580 --> 01:01:53.340]   Like 30 minutes a night, if you don't study,
[01:01:53.340 --> 01:01:56.020]   just do 30 minutes, just do a little bit more.
[01:01:56.020 --> 01:01:58.660]   It is, you're laying the foundation for the rest of your life
[01:01:58.660 --> 01:02:01.140]   and you can't appreciate it in high school and college.
[01:02:01.140 --> 01:02:03.220]   But oh my God, when you get out,
[01:02:03.220 --> 01:02:05.080]   everything in your life is so much easier.
[01:02:05.080 --> 01:02:07.300]   You have probably more responsibility
[01:02:07.300 --> 01:02:08.460]   over the direction of your life
[01:02:08.460 --> 01:02:10.580]   when you're like 13, 14 years old
[01:02:10.580 --> 01:02:12.860]   than you ever will once you're like 25 and older.
[01:02:12.860 --> 01:02:14.700]   Because this is like when you're determining
[01:02:14.700 --> 01:02:16.180]   the foundations that everything's gonna be built on.
[01:02:16.180 --> 01:02:17.700]   - Yeah, 100%.
[01:02:17.700 --> 01:02:20.460]   So first of all, it does seem that
[01:02:21.380 --> 01:02:23.740]   the liberating aspect of being young
[01:02:23.740 --> 01:02:26.940]   is like anything you learn.
[01:02:26.940 --> 01:02:30.620]   So working hard at learning something will pay off
[01:02:30.620 --> 01:02:33.140]   in nonlinear ways, like you said with video games.
[01:02:33.140 --> 01:02:36.140]   I feel like, so people who are like, I hate school.
[01:02:36.140 --> 01:02:39.640]   All right, well, fine, but find something
[01:02:39.640 --> 01:02:41.020]   where you're challenging yourself,
[01:02:41.020 --> 01:02:43.380]   you're growing, you're learning, you're learning a skill,
[01:02:43.380 --> 01:02:44.880]   you're learning about a thing.
[01:02:44.880 --> 01:02:47.860]   Of course, you could push back and say,
[01:02:47.860 --> 01:02:50.260]   well, there's some trajectories that might not be productive
[01:02:50.260 --> 01:02:52.940]   if you spend the entirety of your teen years
[01:02:52.940 --> 01:02:54.780]   playing, I don't know, League of Legends,
[01:02:54.780 --> 01:02:57.980]   your game you have a love and hate relationship with.
[01:02:57.980 --> 01:02:59.100]   - No, just a hate and hate relationship.
[01:02:59.100 --> 01:03:01.020]   - Okay, well, we'll talk about,
[01:03:01.020 --> 01:03:02.980]   I think you have a love-hate relationship
[01:03:02.980 --> 01:03:03.900]   with hate in general.
[01:03:03.900 --> 01:03:06.420]   We'll just talk about it in love.
[01:03:06.420 --> 01:03:08.580]   We'll try to de-complexify that one.
[01:03:08.580 --> 01:03:12.180]   I think in general, just investing yourself
[01:03:12.180 --> 01:03:15.380]   fully with passion really does pay off.
[01:03:15.380 --> 01:03:18.380]   But that said, also school,
[01:03:18.380 --> 01:03:21.740]   I feel like doesn't get enough credit,
[01:03:21.740 --> 01:03:23.260]   like high school in particular,
[01:03:23.260 --> 01:03:24.740]   middle school and high school,
[01:03:24.740 --> 01:03:26.840]   because it's general education.
[01:03:26.840 --> 01:03:31.980]   I think if you're, especially if you're lucky
[01:03:31.980 --> 01:03:35.740]   to have good teachers, but honestly, I haven't mostly.
[01:03:35.740 --> 01:03:38.180]   The textbooks themselves with good teachers,
[01:03:38.180 --> 01:03:40.740]   it's a one chance in life you have to
[01:03:40.740 --> 01:03:43.480]   really explore a subject.
[01:03:43.480 --> 01:03:45.620]   Fuck grades, like getting good grades
[01:03:46.860 --> 01:03:49.500]   is at tension, I would say, with actual learning.
[01:03:49.500 --> 01:03:50.520]   That is true.
[01:03:50.520 --> 01:03:53.320]   But just get a biology textbook
[01:03:53.320 --> 01:03:55.340]   and to explore ideas in biology
[01:03:55.340 --> 01:03:59.420]   and allowing yourself to be inspired
[01:03:59.420 --> 01:04:00.940]   by the beauty of it.
[01:04:00.940 --> 01:04:04.700]   Yeah, I don't know, I think that really, really,
[01:04:04.700 --> 01:04:06.460]   really pays off and you never get a chance
[01:04:06.460 --> 01:04:07.300]   to do that again.
[01:04:07.300 --> 01:04:10.840]   And maybe not even textbooks, like reading,
[01:04:10.840 --> 01:04:12.020]   straight up reading.
[01:04:12.020 --> 01:04:14.900]   I think if you read, this is a one time in life
[01:04:14.900 --> 01:04:16.700]   you get a chance to read.
[01:04:16.700 --> 01:04:20.020]   Really read, like read a book a day, read.
[01:04:20.020 --> 01:04:24.740]   You can really invest, you can really grow by reading.
[01:04:24.740 --> 01:04:27.500]   I mean, Elon Musk, all those guys talk about it.
[01:04:27.500 --> 01:04:28.820]   - It's very, very rare that you meet
[01:04:28.820 --> 01:04:30.540]   like a dumb person who reads a lot.
[01:04:30.540 --> 01:04:32.620]   I don't know if that's ever happened in my life.
[01:04:32.620 --> 01:04:33.460]   Yeah.
[01:04:33.460 --> 01:04:34.300]   - Dumb or not successful.
[01:04:34.300 --> 01:04:38.020]   And the cool thing is, it seems like the reading,
[01:04:38.020 --> 01:04:40.880]   it's like investment, the reading you do early on
[01:04:40.880 --> 01:04:42.900]   in high school pays off way more
[01:04:42.900 --> 01:04:45.100]   than the reading you do later.
[01:04:45.100 --> 01:04:48.700]   So like the really influential reading
[01:04:48.700 --> 01:04:52.340]   is during those high school years.
[01:04:52.340 --> 01:04:55.100]   Because you're basically learning from others
[01:04:55.100 --> 01:04:59.020]   the mistakes they've made, the solutions to problems.
[01:04:59.020 --> 01:05:02.100]   You're basically learning the shortcuts to life.
[01:05:02.100 --> 01:05:03.180]   Like whatever the hell you wanna do,
[01:05:03.180 --> 01:05:05.500]   music, read from the best people,
[01:05:05.500 --> 01:05:08.500]   the music theory, like learn music theory.
[01:05:08.500 --> 01:05:11.860]   Learn, read biographies about jazz musicians,
[01:05:11.860 --> 01:05:14.700]   blues musicians, see all the mistakes,
[01:05:14.700 --> 01:05:16.380]   see what they did, see the shortcuts.
[01:05:16.380 --> 01:05:18.380]   If you wanna do podcasting, read about other podcasts.
[01:05:18.380 --> 01:05:21.140]   If you wanna do streaming, read about other streamers,
[01:05:21.140 --> 01:05:22.580]   physicists and so on.
[01:05:22.580 --> 01:05:24.740]   And I feel like you figure out all the mistakes
[01:05:24.740 --> 01:05:26.620]   and you get to shortcut through life.
[01:05:26.620 --> 01:05:28.380]   Because most people show up to college
[01:05:28.380 --> 01:05:29.820]   without having done that.
[01:05:29.820 --> 01:05:33.180]   And now you get a chance to shortcut your way past them.
[01:05:33.180 --> 01:05:35.340]   Yeah, 100%.
[01:05:35.340 --> 01:05:37.240]   But nobody really teaches you that.
[01:05:37.240 --> 01:05:42.240]   They're like, go to school, from this time to that time.
[01:05:42.500 --> 01:05:46.020]   Shut up, this is just what you do, eat your broccoli.
[01:05:46.020 --> 01:05:47.340]   - I think there's two huge problems.
[01:05:47.340 --> 01:05:50.100]   One is now that I'm older,
[01:05:50.100 --> 01:05:51.700]   'cause you don't know anything as a kid.
[01:05:51.700 --> 01:05:53.260]   You can't really criticize adults as a kid.
[01:05:53.260 --> 01:05:54.100]   'Cause you're a kid.
[01:05:54.100 --> 01:05:55.740]   - You're ageist, if I may say so.
[01:05:55.740 --> 01:05:56.580]   - I am, I am super ageist.
[01:05:56.580 --> 01:05:59.940]   And as I get older, I get even more ageist.
[01:05:59.940 --> 01:06:00.780]   There are a lot of people where I argue with them,
[01:06:00.780 --> 01:06:02.980]   I was like, man, dude, you're really 22, aren't you?
[01:06:02.980 --> 01:06:05.060]   I can tell every word you say.
[01:06:05.060 --> 01:06:07.220]   There's seeps of like 22 year old-ness.
[01:06:07.220 --> 01:06:08.940]   But that's okay, I love that for you.
[01:06:08.940 --> 01:06:11.580]   - I could just say, 'cause you mentioned this,
[01:06:11.580 --> 01:06:14.020]   your wife is a fellow streamer, Melina.
[01:06:14.020 --> 01:06:16.500]   You mentioned that this is a source of fights
[01:06:16.500 --> 01:06:19.940]   for the two of you that, and I could just feel that.
[01:06:19.940 --> 01:06:22.700]   There is truth to what you're saying, which is like,
[01:06:22.700 --> 01:06:25.220]   all right, you're saying that because you're 22.
[01:06:25.220 --> 01:06:26.860]   Just wait until you're 25,
[01:06:26.860 --> 01:06:28.560]   and you won't be saying that anymore.
[01:06:28.560 --> 01:06:31.460]   Now, that is the most annoying thing for people to hear.
[01:06:31.460 --> 01:06:32.620]   - Yeah, you can't ever say that, of course.
[01:06:32.620 --> 01:06:35.100]   - Because it's actually usually true.
[01:06:35.100 --> 01:06:39.740]   Because we do go through phases in life.
[01:06:39.740 --> 01:06:42.260]   And you can understand that most things are phases.
[01:06:42.260 --> 01:06:46.500]   So just in general, you can say, just wait, just wait.
[01:06:46.500 --> 01:06:49.140]   You won't feel this way again.
[01:06:49.140 --> 01:06:51.460]   I could say that to you, you could say that to yourself.
[01:06:51.460 --> 01:06:53.980]   Just wait, whatever you're feeling like, just wait.
[01:06:53.980 --> 01:06:56.140]   In five, 10 years, you'll be a different person,
[01:06:56.140 --> 01:06:59.460]   and you will laugh at the things you take seriously now
[01:06:59.460 --> 01:07:02.080]   that are causing you pain now, all that kind of stuff.
[01:07:02.080 --> 01:07:03.860]   But people hate hearing that.
[01:07:03.860 --> 01:07:05.340]   Anyway. - Absolutely.
[01:07:05.340 --> 01:07:06.700]   I think the joke that I always say is that like,
[01:07:06.700 --> 01:07:09.060]   if I could literally step into a time machine,
[01:07:09.060 --> 01:07:12.060]   and I could come back out and see myself as a 17-year-old,
[01:07:12.060 --> 01:07:14.500]   and I could say, "Hey, I am literally you from the future.
[01:07:14.500 --> 01:07:15.740]   "You see the time machine."
[01:07:15.740 --> 01:07:17.740]   And I would look at me, and I would see the time machine.
[01:07:17.740 --> 01:07:20.460]   And I would give myself the best advice in the world,
[01:07:20.460 --> 01:07:21.860]   to be the most successful person.
[01:07:21.860 --> 01:07:24.260]   I would ignore all of it, even knowing it came from myself.
[01:07:24.260 --> 01:07:25.280]   I'd be like, "This guy sold out.
[01:07:25.280 --> 01:07:26.620]   "This dude doesn't know what the fuck he's talking about.
[01:07:26.620 --> 01:07:27.780]   "Like, nah, I'll figure it out better.
[01:07:27.780 --> 01:07:28.800]   "Like, he must've made some mis..."
[01:07:28.800 --> 01:07:29.640]   That's what I would think as a 17-year-old.
[01:07:29.640 --> 01:07:30.980]   Even if I knew it was myself from the future,
[01:07:30.980 --> 01:07:33.180]   I would just 100% never believe it.
[01:07:33.180 --> 01:07:34.460]   And knowing that is very frustrating.
[01:07:34.460 --> 01:07:36.020]   But I keep that in mind when I deal with younger people.
[01:07:36.020 --> 01:07:37.740]   That's why I never, I always say on stream
[01:07:37.740 --> 01:07:40.500]   when I'm talking to, there's been stuff with Sneako.
[01:07:40.500 --> 01:07:41.860]   There's another girl on my stream called Lab.
[01:07:41.860 --> 01:07:44.260]   Like, when I see the way, I see the mistakes they're making.
[01:07:44.260 --> 01:07:46.460]   Oftentimes, because I've made all of these mistakes,
[01:07:46.460 --> 01:07:49.480]   sometimes in the most public and horrible fashion ever.
[01:07:49.480 --> 01:07:50.500]   But I'm never like a mentor.
[01:07:50.500 --> 01:07:51.660]   I'm not gonna sit there and tell you,
[01:07:51.660 --> 01:07:52.780]   oh, do this or that or that or that.
[01:07:52.780 --> 01:07:54.460]   'Cause I don't know if you're gonna listen to me,
[01:07:54.460 --> 01:07:55.780]   and I don't wanna condescend to you.
[01:07:55.780 --> 01:07:56.860]   And you figure stuff out,
[01:07:56.860 --> 01:07:57.860]   and I'll be here if you wanna talk about it.
[01:07:57.860 --> 01:07:58.940]   But yeah.
[01:07:58.940 --> 01:08:00.380]   There was one of the stories,
[01:08:00.380 --> 01:08:02.580]   there was a company that didn't work with me,
[01:08:02.580 --> 01:08:05.380]   because I was very adamant on defending
[01:08:05.380 --> 01:08:07.300]   very radical notions about language
[01:08:07.300 --> 01:08:08.220]   and racial slurs and everything
[01:08:08.220 --> 01:08:09.940]   when I was like 22 or whatever.
[01:08:09.940 --> 01:08:10.940]   And there was a company, and they said,
[01:08:10.940 --> 01:08:12.720]   well, we don't wanna work with this guy for an event.
[01:08:12.720 --> 01:08:14.140]   And after they'd said that,
[01:08:14.140 --> 01:08:15.820]   I had written an article on my website
[01:08:15.820 --> 01:08:18.000]   called, the company was Gigabyte, they make motherboards.
[01:08:18.000 --> 01:08:19.320]   I said, fuck Gigabyte in the ass.
[01:08:19.320 --> 01:08:20.940]   That was the title to my article.
[01:08:20.940 --> 01:08:22.280]   And it was like, well, if they don't wanna work with me,
[01:08:22.280 --> 01:08:23.120]   I'm gonna blow them up
[01:08:23.120 --> 01:08:25.180]   and never do anything ever with them again.
[01:08:25.180 --> 01:08:27.260]   And it was just like, looking back on it now,
[01:08:27.260 --> 01:08:28.780]   obviously, as an older person, I'm like,
[01:08:28.780 --> 01:08:30.620]   hey, you need to pump the brakes and chill.
[01:08:30.620 --> 01:08:32.000]   You're destroying yourself.
[01:08:32.000 --> 01:08:33.500]   But yeah, as a young person, it's like,
[01:08:33.500 --> 01:08:34.900]   yeah, you're 22, of course you think
[01:08:34.900 --> 01:08:36.420]   that you can say whatever and do whatever.
[01:08:36.420 --> 01:08:37.620]   And as long as you're good at what you're doing,
[01:08:37.620 --> 01:08:38.660]   you've got the whole world behind you.
[01:08:38.660 --> 01:08:40.380]   And yeah, geez.
[01:08:40.380 --> 01:08:41.280]   - Well, let's go there.
[01:08:41.280 --> 01:08:43.980]   You have a history of using offensive language,
[01:08:43.980 --> 01:08:47.180]   like the R word, the N word,
[01:08:47.180 --> 01:08:49.580]   including the N word with a hard R,
[01:08:49.580 --> 01:08:53.100]   calling women bitches,
[01:08:53.100 --> 01:08:56.640]   talking about rape in a nonchalant way.
[01:08:56.640 --> 01:09:01.460]   What part of that do you regret?
[01:09:01.460 --> 01:09:03.260]   And what part of that do you not?
[01:09:03.260 --> 01:09:04.860]   - Language is very complicated.
[01:09:04.860 --> 01:09:08.300]   When it comes to stuff relating to slurs,
[01:09:08.300 --> 01:09:11.980]   there's been like a whole trajectory of feelings
[01:09:11.980 --> 01:09:14.540]   on everything related to language.
[01:09:14.540 --> 01:09:15.380]   So my--
[01:09:15.380 --> 01:09:17.100]   - For you personally and for the internet as a whole.
[01:09:17.100 --> 01:09:18.100]   - Yeah, I don't care about the internet,
[01:09:18.100 --> 01:09:19.500]   almost for me personally.
[01:09:19.500 --> 01:09:22.900]   In my early 20s, I'll say like 22, 23,
[01:09:22.900 --> 01:09:24.660]   I think probably when I first started streaming,
[01:09:24.660 --> 01:09:27.860]   my feeling is that any word is just a word.
[01:09:27.860 --> 01:09:29.420]   And if it hurts you, that's your fault.
[01:09:29.420 --> 01:09:31.580]   Take responsibility for yourself.
[01:09:31.580 --> 01:09:32.780]   This probably came from my background
[01:09:32.780 --> 01:09:34.140]   of being like a really independent person.
[01:09:34.140 --> 01:09:35.220]   So that's just kind of like the mind
[01:09:35.220 --> 01:09:36.780]   that I had for everything.
[01:09:36.780 --> 01:09:38.620]   And there were basically,
[01:09:38.620 --> 01:09:41.000]   there were like a collection of experiences that I had,
[01:09:41.000 --> 01:09:43.820]   that as I grew, I started to realize like, okay,
[01:09:43.820 --> 01:09:45.940]   well, I feel differently about some of these words,
[01:09:45.940 --> 01:09:46.980]   depending on the context,
[01:09:46.980 --> 01:09:48.540]   and I can see how they can affect other people,
[01:09:48.540 --> 01:09:49.900]   depending on the context.
[01:09:49.900 --> 01:09:51.740]   So as I've kind of like grown,
[01:09:51.740 --> 01:09:54.020]   I think I've developed a more sophisticated understanding
[01:09:54.020 --> 01:09:55.900]   of how different words are used
[01:09:55.900 --> 01:09:56.940]   and how they affect people,
[01:09:56.940 --> 01:09:58.000]   whether they like it or not.
[01:09:58.000 --> 01:09:59.780]   And more importantly, whether I like it or not.
[01:09:59.780 --> 01:10:02.780]   And that words can, even if I don't want it to be,
[01:10:02.780 --> 01:10:05.900]   they can be a vehicle for emboldening certain types of ideas
[01:10:05.900 --> 01:10:07.420]   that I don't wanna embolden.
[01:10:07.420 --> 01:10:09.780]   And yeah, that's kind of been the whole like growth.
[01:10:09.780 --> 01:10:11.140]   I've been lucky that in the time
[01:10:11.140 --> 01:10:12.260]   that I came up on the internet,
[01:10:12.260 --> 01:10:13.840]   I was able to learn these lessons,
[01:10:13.840 --> 01:10:15.460]   because if I was trying to learn those same lessons today,
[01:10:15.460 --> 01:10:17.200]   I would have been completely destroyed
[01:10:17.200 --> 01:10:20.120]   'cause I had insane views on language like 10 years ago.
[01:10:20.120 --> 01:10:21.140]   - We could talk about the past,
[01:10:21.140 --> 01:10:22.180]   we could talk about the present.
[01:10:22.180 --> 01:10:23.220]   Let's talk about the past first.
[01:10:23.220 --> 01:10:25.020]   So how do you deal with the fact
[01:10:25.020 --> 01:10:30.020]   that there's videos of you in the past saying the N word,
[01:10:30.020 --> 01:10:32.120]   including the N word with a hard R?
[01:10:32.120 --> 01:10:32.960]   - So generally-
[01:10:32.960 --> 01:10:34.080]   - And what's the context?
[01:10:34.080 --> 01:10:35.000]   Can you give me like,
[01:10:35.000 --> 01:10:37.560]   give me a memory, what would be the context usually?
[01:10:37.560 --> 01:10:39.560]   - When I lay out this defense,
[01:10:39.560 --> 01:10:42.080]   it's not because I wouldn't have used the N word.
[01:10:42.080 --> 01:10:43.360]   Generally, whenever I said the N word,
[01:10:43.360 --> 01:10:44.800]   it was usually in an example of like,
[01:10:44.800 --> 01:10:47.160]   this is something that like a racist person would say.
[01:10:47.160 --> 01:10:49.200]   I don't think I've ever on the internet,
[01:10:49.200 --> 01:10:50.440]   I don't think I've ever called anybody
[01:10:50.440 --> 01:10:52.360]   like the N word with a hard R.
[01:10:52.360 --> 01:10:53.360]   Not because I wouldn't have,
[01:10:53.360 --> 01:10:55.180]   but just because it wasn't in my vocabulary.
[01:10:55.180 --> 01:10:57.900]   I played RTS, real-time strategy,
[01:10:57.900 --> 01:11:00.500]   and we used the F slur for gay people.
[01:11:00.500 --> 01:11:01.980]   That's the one, and I use that one a ton.
[01:11:01.980 --> 01:11:04.420]   I've called people that a ton in the past.
[01:11:04.420 --> 01:11:06.780]   - So I should actually just as a small tangent.
[01:11:06.780 --> 01:11:07.660]   - Yeah, go for it.
[01:11:07.660 --> 01:11:10.360]   - And this is what I'd like to explore with you.
[01:11:10.360 --> 01:11:16.460]   There's a ruthlessness to the language in the gaming world.
[01:11:16.460 --> 01:11:17.340]   - Yeah.
[01:11:17.340 --> 01:11:18.740]   - And there's different communities,
[01:11:18.740 --> 01:11:22.300]   they have different flavors of language.
[01:11:22.300 --> 01:11:23.180]   - Of hate speech, yeah.
[01:11:23.180 --> 01:11:25.140]   - Of hate speech, essentially.
[01:11:25.140 --> 01:11:27.880]   And there's also a humor to it,
[01:11:27.880 --> 01:11:34.200]   which really bothers me in a dark way
[01:11:34.200 --> 01:11:37.280]   that I haven't been able to really think through,
[01:11:37.280 --> 01:11:41.520]   because humor seems to be a kind of catalyst for hate.
[01:11:41.520 --> 01:11:44.120]   It seems to normalize hate.
[01:11:44.120 --> 01:11:48.080]   Like you say, basically it's like Louis C.K.
[01:11:48.080 --> 01:11:50.120]   says a lot of edgy things,
[01:11:50.120 --> 01:11:52.500]   but you take something Louis C.K. says
[01:11:52.500 --> 01:11:53.920]   and do it in a non-funny way,
[01:11:53.920 --> 01:11:55.120]   and do it over and over and over,
[01:11:55.120 --> 01:12:00.120]   and keep increasing the hatefulness of it, the vitriol.
[01:12:00.120 --> 01:12:04.360]   And somehow you find yourself like Alice in Wonderland
[01:12:04.360 --> 01:12:07.600]   in a world full of hate, where there's no good and evil,
[01:12:07.600 --> 01:12:08.600]   it's all the same.
[01:12:08.600 --> 01:12:11.480]   In fact, the good is to be mocked,
[01:12:11.480 --> 01:12:14.800]   and the evil is to be celebrated for the humor of it.
[01:12:14.800 --> 01:12:18.560]   Basically not taking the ideas of evil seriously.
[01:12:18.560 --> 01:12:19.720]   And I don't know what it,
[01:12:19.720 --> 01:12:21.440]   it reveals something about human nature
[01:12:21.440 --> 01:12:22.860]   that you can let go.
[01:12:22.860 --> 01:12:25.820]   The moral relativism that can happen
[01:12:25.820 --> 01:12:27.020]   when you do that kind of stuff.
[01:12:27.020 --> 01:12:32.020]   At the same time, I'm a fan of dark humor, when done well.
[01:12:32.020 --> 01:12:34.380]   Anyway, for people who are not familiar,
[01:12:34.380 --> 01:12:39.380]   I just wanted to mention that some of the worst hate speech
[01:12:39.380 --> 01:12:44.120]   that ends in LOL happens in gaming communities.
[01:12:44.120 --> 01:12:45.080]   - Yeah.
[01:12:45.080 --> 01:12:47.320]   - And that's where you come from in a certain part.
[01:12:47.320 --> 01:12:48.980]   - So a lot of people don't remember this,
[01:12:48.980 --> 01:12:50.120]   or don't know this 'cause they're younger,
[01:12:50.120 --> 01:12:54.040]   but way back in the day, in the late 90s,
[01:12:54.040 --> 01:12:55.840]   early mid 2000s of the internet,
[01:12:55.840 --> 01:12:58.440]   the way that online kind of like shit talk worked
[01:12:58.440 --> 01:13:00.320]   was you were just trying to ramp up
[01:13:00.320 --> 01:13:04.300]   to the most insanely edgy, crazy stuff you could say
[01:13:04.300 --> 01:13:06.520]   to like provoke a reaction.
[01:13:06.520 --> 01:13:09.280]   Have you ever heard of something called the aristocrats?
[01:13:09.280 --> 01:13:11.080]   That it's like a joke, the joke?
[01:13:11.080 --> 01:13:13.240]   - Oh yeah, the joke, yeah, there's a movie on it, yeah.
[01:13:13.240 --> 01:13:16.040]   - Okay, basically every single like shit talk
[01:13:16.040 --> 01:13:17.420]   back in the internet was like that.
[01:13:17.420 --> 01:13:19.720]   Like what is the most increasingly depraved,
[01:13:19.720 --> 01:13:22.440]   and back then you didn't get banned for slurs or anything
[01:13:22.440 --> 01:13:23.400]   on any of these chat rooms,
[01:13:23.400 --> 01:13:25.880]   so it was just like insane world to walk into.
[01:13:25.880 --> 01:13:29.640]   And I was fully 100% a part of, a product of,
[01:13:29.640 --> 01:13:31.320]   and a contributor to that world.
[01:13:31.320 --> 01:13:34.040]   - So that probably still goes on on the internet in some way
[01:13:34.040 --> 01:13:36.200]   and that probably still goes on in the internet
[01:13:36.200 --> 01:13:39.280]   in a maybe more pacified way.
[01:13:39.280 --> 01:13:40.840]   - Only in darker parts of the internet.
[01:13:40.840 --> 01:13:42.400]   I'd say for the most part, most,
[01:13:42.400 --> 01:13:44.600]   well compared to back then, compared to 20 years ago,
[01:13:44.600 --> 01:13:46.160]   the internet is way cleaned up now.
[01:13:46.160 --> 01:13:47.760]   There are still gonna be boards you can go on
[01:13:47.760 --> 01:13:49.840]   or parts of the internet where you see that type of humor,
[01:13:49.840 --> 01:13:51.680]   but not, nowhere near as mainstream.
[01:13:51.680 --> 01:13:54.400]   Like back then you could open your mic on Xbox Live
[01:13:54.400 --> 01:13:56.720]   and hear some insane stuff when that first started,
[01:13:56.720 --> 01:13:58.720]   nowhere near what you hear today, although it's, yeah.
[01:13:58.720 --> 01:14:01.280]   - There's still elements of escalation that happen
[01:14:01.280 --> 01:14:04.860]   that just seems to be part of human nature on the internet.
[01:14:04.860 --> 01:14:06.040]   Because we don't get the feedback
[01:14:06.040 --> 01:14:08.240]   of actually hurting people directly.
[01:14:08.240 --> 01:14:11.760]   So the trolling, like for the lulz,
[01:14:11.760 --> 01:14:15.280]   you'll do like whatever, like you will still escalate.
[01:14:15.280 --> 01:14:17.080]   Within the bounds, you're just saying
[01:14:17.080 --> 01:14:18.200]   that there's more bounds now.
[01:14:18.200 --> 01:14:20.400]   On Reddit, there's more bounds and so on.
[01:14:20.400 --> 01:14:23.800]   So there's moderators that kind of yell at you,
[01:14:23.800 --> 01:14:26.520]   that ban you and so on if you cross those bounds.
[01:14:26.520 --> 01:14:29.900]   But overall, that basic human instinct to escalate,
[01:14:29.900 --> 01:14:34.080]   especially under the veil of anonymity is still there.
[01:14:34.080 --> 01:14:35.480]   I don't know, it's dark, it's dark.
[01:14:35.480 --> 01:14:37.560]   - Yeah, just there's a lot of different ways to look at it
[01:14:37.560 --> 01:14:39.000]   and there's different ways you can break that arc.
[01:14:39.000 --> 01:14:41.000]   Like for instance, like you mentioned dark humor
[01:14:41.000 --> 01:14:44.920]   and you say that like, sometimes dark humor is funny
[01:14:44.920 --> 01:14:46.320]   and sometimes it's not.
[01:14:46.320 --> 01:14:48.080]   I think that it's really important to dig into
[01:14:48.080 --> 01:14:50.320]   and figure out like why certain things are funny
[01:14:50.320 --> 01:14:51.320]   and why certain things-- - Can I give you an example?
[01:14:51.320 --> 01:14:52.860]   - Yeah, go. - It's from your subreddit.
[01:14:52.860 --> 01:14:53.920]   - Oh boy. (laughs)
[01:14:53.920 --> 01:14:56.080]   - No, that made me laugh and I felt wrong about it.
[01:14:56.080 --> 01:14:58.280]   - (laughs) Oh no.
[01:14:58.280 --> 01:15:00.360]   - So this is-- (laughs)
[01:15:00.360 --> 01:15:02.400]   - I already know what this is, yeah.
[01:15:02.400 --> 01:15:04.680]   - Yeah, so this is a trolley problem.
[01:15:04.680 --> 01:15:07.800]   To me, it connects because I think about the,
[01:15:07.800 --> 01:15:10.040]   it keeps, 'cause I worked on autonomous vehicles,
[01:15:10.040 --> 01:15:12.840]   the trolley problem, the philosophical thought experiment
[01:15:12.840 --> 01:15:14.360]   keeps brought up a lot.
[01:15:14.360 --> 01:15:16.800]   You know, when AI is part of making the decision,
[01:15:16.800 --> 01:15:19.960]   do I kill three people here or five people here
[01:15:19.960 --> 01:15:22.760]   and AI makes that decision, how do you do that calculus?
[01:15:22.760 --> 01:15:27.320]   And this particular, there's a deep,
[01:15:27.320 --> 01:15:31.180]   so it's satire that reveals some kind of flaw in society.
[01:15:31.180 --> 01:15:33.600]   I feel like that's why-- - That's what dark humor does?
[01:15:33.600 --> 01:15:35.200]   - Successful dark humor does.
[01:15:35.200 --> 01:15:36.960]   And I don't know if this-- - And it reveals a flaw.
[01:15:36.960 --> 01:15:39.840]   I feel like there's a certain brand of dark humor
[01:15:39.840 --> 01:15:43.760]   and I think the reason, I think the reason is why it's good
[01:15:43.760 --> 01:15:46.000]   or why it is good humor, I think it's because it,
[01:15:46.000 --> 01:15:47.240]   I don't think it necessarily reveals a flaw.
[01:15:47.240 --> 01:15:49.800]   Sometimes I feel like it reveals a kind of virtue, I think.
[01:15:49.800 --> 01:15:52.520]   Like, if you look at this particular thing--
[01:15:52.520 --> 01:15:53.840]   - Can I explain what we're-- - Yeah, go for it.
[01:15:53.840 --> 01:15:55.880]   Oh yeah, sure. - We're just listening.
[01:15:55.880 --> 01:15:59.440]   The title of the Reddit post is "You Know What to Pick"
[01:15:59.440 --> 01:16:03.360]   and it says, "Five people are going to die either way,
[01:16:03.360 --> 01:16:05.200]   "but if you flip the lever,
[01:16:05.200 --> 01:16:08.940]   "the trolley will do a sick fucking loop first."
[01:16:08.940 --> 01:16:13.940]   And also the top comment is a question saying,
[01:16:13.940 --> 01:16:16.500]   which I think is also part of the dark humor
[01:16:16.500 --> 01:16:18.740]   that's successful, "Can I get the gender
[01:16:18.740 --> 01:16:21.560]   "and ethnic backgrounds of the groups first?"
[01:16:21.560 --> 01:16:24.700]   And the top answer is, "Both groups are each comprised
[01:16:24.700 --> 01:16:29.700]   "of five white, orphaned, cis male, heavy meth users
[01:16:29.700 --> 01:16:34.360]   "who are consistently in and out of drug rehab,
[01:16:34.360 --> 01:16:37.060]   "all who identify as right-wing extremists."
[01:16:37.060 --> 01:16:40.100]   Humor is such a sophisticated thing that we engage in.
[01:16:40.100 --> 01:16:42.380]   Humor is really complicated.
[01:16:42.380 --> 01:16:45.080]   But I would argue that hopefully the humor here
[01:16:45.080 --> 01:16:48.660]   shows the virtue of this is obviously horrible,
[01:16:48.660 --> 01:16:50.020]   but that's kind of why it's funny.
[01:16:50.020 --> 01:16:52.580]   It's funny because it's such a horrible question to ask.
[01:16:52.580 --> 01:16:54.180]   Do we kill five people in a boring way
[01:16:54.180 --> 01:16:55.340]   or in a really entertaining way?
[01:16:55.340 --> 01:16:57.180]   And it's like, that's really, that's really,
[01:16:57.180 --> 01:16:58.340]   and then when you ask even more,
[01:16:58.340 --> 01:16:59.500]   what are the ethnic backgrounds?
[01:16:59.500 --> 01:17:01.540]   That's even worse to say that.
[01:17:01.540 --> 01:17:03.260]   So I feel like that's the type of,
[01:17:03.260 --> 01:17:04.900]   there's a way that you can engage with dark humor
[01:17:04.900 --> 01:17:06.380]   where it's like, oof.
[01:17:06.380 --> 01:17:08.820]   It's funny because it's so wrong and so taboo.
[01:17:08.820 --> 01:17:10.220]   And we all know that it's wrong and taboo,
[01:17:10.220 --> 01:17:11.940]   and that's kind of where the shared laugh comes from.
[01:17:11.940 --> 01:17:16.580]   - So for me, the question, asking the diversity question
[01:17:16.580 --> 01:17:19.340]   is a sophisticated way of revealing the absurdity
[01:17:19.340 --> 01:17:22.500]   of asking about diversity when it's talking about human life.
[01:17:22.500 --> 01:17:25.120]   - Oh, interesting, 'cause the way that I took that was,
[01:17:25.120 --> 01:17:27.400]   I think it reveals the absurdity
[01:17:27.400 --> 01:17:29.540]   of how people will weigh different ethnic backgrounds
[01:17:29.540 --> 01:17:31.900]   so differently when it comes to value of human life.
[01:17:31.900 --> 01:17:33.700]   Like, I'm actually thinking of that in terms of like
[01:17:33.700 --> 01:17:35.740]   an immigration-related question,
[01:17:35.740 --> 01:17:38.300]   where people are really keen and quick to dehumanize
[01:17:38.300 --> 01:17:39.980]   like black or brown people.
[01:17:39.980 --> 01:17:40.820]   So like the question is like,
[01:17:40.820 --> 01:17:42.460]   well, if five of them are brown and five are white,
[01:17:42.460 --> 01:17:44.740]   well, I know which one I'm gonna pull the lever for.
[01:17:44.740 --> 01:17:45.580]   That's how I read that.
[01:17:45.580 --> 01:17:46.740]   - But it's satirizing that aspect.
[01:17:46.740 --> 01:17:47.580]   - Yeah, exactly, yes, of course, yeah.
[01:17:47.580 --> 01:17:50.060]   - But that's what I mean, that that's the flaw.
[01:17:50.060 --> 01:17:55.060]   To me, at least, it showed that humanity
[01:17:55.060 --> 01:17:59.100]   or social networks that are easy to be outraged
[01:17:59.100 --> 01:18:01.920]   and love the outrage and the chaos,
[01:18:02.820 --> 01:18:06.200]   that Twitter and social networks will pull that lever.
[01:18:06.200 --> 01:18:10.420]   Like they would always try to maximize the fun.
[01:18:10.420 --> 01:18:14.620]   And there's a sick aspect to all the atrocities,
[01:18:14.620 --> 01:18:16.780]   all the tragedies that happen in the world
[01:18:16.780 --> 01:18:18.780]   that we kind of always lean towards
[01:18:18.780 --> 01:18:23.220]   the outrageous narrative weaved around it.
[01:18:23.220 --> 01:18:28.380]   Yeah, the one that leads to sort of the most clicks,
[01:18:28.380 --> 01:18:32.140]   to the most attention, to the most outrage,
[01:18:32.140 --> 01:18:33.700]   to all that kind of stuff.
[01:18:33.700 --> 01:18:37.740]   So that's almost like a satire of society.
[01:18:37.740 --> 01:18:42.580]   When they are faced with tragedy, they will maximize.
[01:18:42.580 --> 01:18:46.160]   I'm trying to think of a word that's not fun, but--
[01:18:46.160 --> 01:18:47.060]   - Entertainment.
[01:18:47.060 --> 01:18:49.100]   - Maximize the entertainment, yeah.
[01:18:49.100 --> 01:18:50.420]   - This is a big criticism I give,
[01:18:50.420 --> 01:18:52.420]   especially to conservative crowds.
[01:18:52.420 --> 01:18:54.660]   Left-leaning people, everybody does it.
[01:18:54.660 --> 01:18:56.380]   I don't like when people blame the media
[01:18:56.380 --> 01:18:58.020]   for the state of the media today.
[01:18:58.020 --> 01:19:00.300]   I very much believe that everything in society
[01:19:00.300 --> 01:19:02.740]   is a feedback loop, and that if you're really unhappy
[01:19:02.740 --> 01:19:03.600]   with the state of the media,
[01:19:03.600 --> 01:19:05.060]   I think that the media is a good reflection
[01:19:05.060 --> 01:19:06.220]   for what people wanna see.
[01:19:06.220 --> 01:19:08.380]   Because there is a room right now in the United States
[01:19:08.380 --> 01:19:09.500]   where somebody could start a company
[01:19:09.500 --> 01:19:12.460]   where all they do is completely factual reporting,
[01:19:12.460 --> 01:19:13.740]   they don't have a political slant,
[01:19:13.740 --> 01:19:15.700]   and they're not giving you these sensationalist narratives
[01:19:15.700 --> 01:19:18.100]   or stories, and that media company would fail in two weeks,
[01:19:18.100 --> 01:19:19.140]   because people don't wanna see that.
[01:19:19.140 --> 01:19:20.860]   Generally, people really wanna see the,
[01:19:20.860 --> 01:19:22.860]   show me the guy that really believes in what I say,
[01:19:22.860 --> 01:19:24.020]   that calls the other guy an idiot,
[01:19:24.020 --> 01:19:25.820]   the guy that are screaming on TV or on the radio,
[01:19:25.820 --> 01:19:27.660]   like this is what I really want.
[01:19:27.660 --> 01:19:29.060]   And people will engage in that,
[01:19:29.060 --> 01:19:32.140]   and that feedback loop will continue for generations,
[01:19:32.140 --> 01:19:33.140]   and then all of a sudden people are like,
[01:19:33.140 --> 01:19:34.580]   why is the media so biased?
[01:19:34.580 --> 01:19:36.380]   Why is the media driving so many narratives?
[01:19:36.380 --> 01:19:37.200]   And it's like, well, what do you mean?
[01:19:37.200 --> 01:19:39.060]   This is exactly what you wanna see.
[01:19:39.060 --> 01:19:40.780]   And that's frustrating for me.
[01:19:40.780 --> 01:19:43.080]   That's one of my big kind of when I defend establishments,
[01:19:43.080 --> 01:19:45.820]   or when I talk about the interplay between citizen
[01:19:45.820 --> 01:19:48.660]   and all these institutions we have,
[01:19:48.660 --> 01:19:51.180]   that the institutions are very much a reflection
[01:19:51.180 --> 01:19:54.340]   of the population, at least in democratic societies.
[01:19:54.340 --> 01:19:56.300]   And I think that people very much try to elude
[01:19:56.300 --> 01:19:57.780]   the personal responsibility
[01:19:57.780 --> 01:19:59.700]   or the country's responsibility
[01:19:59.700 --> 01:20:02.000]   to why some of them look the way that they do.
[01:20:02.000 --> 01:20:05.900]   - But that takes us back to the N word with a hard R.
[01:20:05.900 --> 01:20:07.700]   - Sure. - Why?
[01:20:07.700 --> 01:20:09.660]   - For the particular examples that I was given,
[01:20:09.660 --> 01:20:11.900]   or for the particular conversations that I was having,
[01:20:11.900 --> 01:20:13.740]   if you're gonna have challenging conversations
[01:20:13.740 --> 01:20:14.900]   around certain words,
[01:20:14.900 --> 01:20:16.540]   I think you should probably be able to say them,
[01:20:16.540 --> 01:20:18.580]   otherwise it feels really ridiculous to me.
[01:20:18.580 --> 01:20:20.780]   That's like my-- - Do you still believe that?
[01:20:20.780 --> 01:20:22.020]   - For, yes.
[01:20:22.020 --> 01:20:23.800]   And not like calling people those words,
[01:20:23.800 --> 01:20:25.620]   but in having conversations about those words,
[01:20:25.620 --> 01:20:27.100]   I would say that I still believe that, yeah.
[01:20:27.100 --> 01:20:29.060]   - But don't you think, as you said,
[01:20:29.060 --> 01:20:30.620]   that using those words
[01:20:30.620 --> 01:20:35.460]   actually gives motivation and strength
[01:20:35.460 --> 01:20:38.100]   to people who have hate in their hearts?
[01:20:38.100 --> 01:20:41.820]   - I think depending on the context of what's going on,
[01:20:41.820 --> 01:20:43.420]   I think that that's gonna be a big driver
[01:20:43.420 --> 01:20:46.300]   in terms of how people are going to perceive or take it.
[01:20:46.300 --> 01:20:48.500]   So in a conversation about the N word,
[01:20:48.500 --> 01:20:49.900]   I don't think I would normally say the N word,
[01:20:49.900 --> 01:20:51.660]   we would just talk about the word,
[01:20:51.660 --> 01:20:53.900]   much the same way that, say, like in a movie,
[01:20:53.900 --> 01:20:55.860]   like in "Django," people use the N word.
[01:20:55.860 --> 01:20:57.460]   Should that be censored in that movie?
[01:20:57.460 --> 01:20:58.860]   Or in the context of that movie,
[01:20:58.860 --> 01:21:01.100]   is it being employed in a way where these aren't good people,
[01:21:01.100 --> 01:21:02.020]   you're not supposed to like them,
[01:21:02.020 --> 01:21:04.340]   and that's what the audience walks away with.
[01:21:04.340 --> 01:21:06.380]   - Yeah, but that context is different in the conversation.
[01:21:06.380 --> 01:21:08.720]   It feels like in conversation,
[01:21:08.720 --> 01:21:11.900]   you using that word normalizes it.
[01:21:11.900 --> 01:21:15.340]   And normalizing that word is going to make it easier
[01:21:15.340 --> 01:21:19.380]   for people who use that word in a hateful way to use it.
[01:21:19.380 --> 01:21:23.460]   Same with the F word, the F slur.
[01:21:23.460 --> 01:21:27.640]   If you use that casually and normalize it
[01:21:27.640 --> 01:21:30.700]   in a way that's not hateful,
[01:21:30.700 --> 01:21:32.780]   you use it in a way that's not hateful,
[01:21:32.780 --> 01:21:35.580]   but the side effect is that it normalizes it,
[01:21:35.580 --> 01:21:38.460]   then people who do use it in a hateful way
[01:21:38.460 --> 01:21:40.260]   will be more likely to use it.
[01:21:40.260 --> 01:21:43.660]   Therefore, mathematically looking at the equation
[01:21:43.660 --> 01:21:46.900]   of the number of times the N word or the F word
[01:21:46.900 --> 01:21:48.580]   is used throughout the world,
[01:21:48.580 --> 01:21:51.340]   it increases the number of times it's used in a hateful way.
[01:21:51.340 --> 01:21:52.180]   - Yeah, I think that human beings--
[01:21:52.180 --> 01:21:54.460]   - And you're part of that problem, Steven.
[01:21:54.460 --> 01:21:55.340]   - I don't agree.
[01:21:55.340 --> 01:21:57.980]   I understand the thought process,
[01:21:57.980 --> 01:22:00.760]   but I don't know if using certain words
[01:22:00.760 --> 01:22:04.780]   within different contexts is going to necessarily normalize
[01:22:04.780 --> 01:22:06.220]   the hateful use of that word.
[01:22:06.220 --> 01:22:09.700]   That is an argument that I've heard people use.
[01:22:09.700 --> 01:22:11.060]   Somebody will say, "Okay, well, hold on.
[01:22:11.060 --> 01:22:12.500]   "That should never be used ever,"
[01:22:12.500 --> 01:22:14.800]   because by virtue of you normalizing it,
[01:22:14.800 --> 01:22:16.740]   even in an inoffensive environment,
[01:22:16.740 --> 01:22:18.700]   you increase the proclivity for people to use it
[01:22:18.700 --> 01:22:20.620]   in a potentially more offensive environment.
[01:22:20.620 --> 01:22:21.900]   And my argument is always that,
[01:22:21.900 --> 01:22:23.500]   "No, I don't think that crossover exists."
[01:22:23.500 --> 01:22:25.100]   But if you did wanna take that argument,
[01:22:25.100 --> 01:22:26.460]   and maybe you do feel this way,
[01:22:26.460 --> 01:22:27.820]   I think that you get really problematic
[01:22:27.820 --> 01:22:30.040]   when you run into communities that do use certain words
[01:22:30.040 --> 01:22:31.100]   that people would say, "Well, they should be allowed
[01:22:31.100 --> 01:22:31.940]   "to do it."
[01:22:31.940 --> 01:22:33.500]   So, for instance, if you think that any utterance
[01:22:33.500 --> 01:22:35.260]   of the N word at all is highly problematic
[01:22:35.260 --> 01:22:36.540]   and might increase hatred,
[01:22:36.540 --> 01:22:38.820]   then the entire rap industry has to dramatically change
[01:22:38.820 --> 01:22:40.340]   the way that they engage with the N word.
[01:22:40.340 --> 01:22:42.120]   And obviously, a lot of people that criticize
[01:22:42.120 --> 01:22:44.260]   people's use of the N word are gonna turn to rappers
[01:22:44.260 --> 01:22:45.900]   and say, "Well, you guys can't say it either."
[01:22:45.900 --> 01:22:48.780]   - No, it's who uses the N word.
[01:22:48.780 --> 01:22:50.980]   So, it's not just the word.
[01:22:50.980 --> 01:22:55.760]   It's the, it is context dependent.
[01:22:55.760 --> 01:23:00.380]   But I would say that you, as a white person,
[01:23:00.380 --> 01:23:05.380]   having conversations, the context there is the kind
[01:23:05.380 --> 01:23:07.300]   that would lead to an increase in hate.
[01:23:07.300 --> 01:23:08.460]   - Do you think the N word should be censored
[01:23:08.460 --> 01:23:09.460]   in the dictionary?
[01:23:09.460 --> 01:23:10.300]   - No.
[01:23:10.300 --> 01:23:12.540]   And I believe there's a Wikipedia page on it,
[01:23:12.540 --> 01:23:13.700]   and it's not censored.
[01:23:13.700 --> 01:23:16.300]   Yeah, I think it should be in the dictionary.
[01:23:16.300 --> 01:23:20.120]   I think the context of casual conversation,
[01:23:20.120 --> 01:23:23.060]   like I said, I just believe that on the internet,
[01:23:23.060 --> 01:23:28.300]   having humor, having fun conversations as you have
[01:23:28.300 --> 01:23:32.660]   on your streams, that leads to the normalization
[01:23:32.660 --> 01:23:35.180]   of the word without any educational value.
[01:23:35.180 --> 01:23:36.020]   Without significant educational value.
[01:23:36.020 --> 01:23:37.060]   - Yeah, I would agree with that.
[01:23:37.060 --> 01:23:37.900]   I think I would agree with that.
[01:23:37.900 --> 01:23:41.140]   - No, sorry, so there's a difference between F slur
[01:23:41.140 --> 01:23:45.060]   and N word, and both, I think, should not be used
[01:23:45.060 --> 01:23:48.300]   in a fun way, but the F word was used in a fun way
[01:23:48.300 --> 01:23:49.180]   for the longest time.
[01:23:49.180 --> 01:23:50.020]   - For sure.
[01:23:50.020 --> 01:23:52.360]   - And I'll tell you something that bothers me
[01:23:52.360 --> 01:23:55.440]   about your streams, not your streams,
[01:23:55.440 --> 01:23:58.440]   your streams and basically every other stream,
[01:23:58.440 --> 01:24:00.920]   is the casual use of the R word.
[01:24:00.920 --> 01:24:02.580]   - Oh, the ableism, yeah.
[01:24:02.580 --> 01:24:04.160]   - I don't know if it's about the able,
[01:24:04.160 --> 01:24:07.280]   I don't even know, listen, it's complicated.
[01:24:07.280 --> 01:24:08.840]   I'm not like virtue signaling here.
[01:24:08.840 --> 01:24:10.520]   - No, ableism isn't virtue signaling.
[01:24:10.520 --> 01:24:12.320]   I mean, it's a legitimate, yeah.
[01:24:12.320 --> 01:24:13.920]   Like I get emails from fans that say like,
[01:24:13.920 --> 01:24:16.660]   "Hey, I deal with this particular issue.
[01:24:16.660 --> 01:24:17.880]   "Every time you use this word,
[01:24:17.880 --> 01:24:19.160]   "it kind of feels like you're attacking me."
[01:24:19.160 --> 01:24:21.980]   Like just like, so it's a valid concept, yeah.
[01:24:21.980 --> 01:24:24.180]   - It's just something cuts wrong for me.
[01:24:24.180 --> 01:24:26.660]   Like for example, I'm not bothered by,
[01:24:26.660 --> 01:24:29.540]   I am bothered by the excessive use of the word fuck.
[01:24:29.540 --> 01:24:30.380]   - Okay.
[01:24:30.380 --> 01:24:31.660]   - But not--
[01:24:31.660 --> 01:24:32.500]   - In the same way that--
[01:24:32.500 --> 01:24:35.300]   - Moderate use of the word fuck.
[01:24:35.300 --> 01:24:36.180]   - What is it I'm curious in?
[01:24:36.180 --> 01:24:38.420]   When somebody calls somebody an R word,
[01:24:38.420 --> 01:24:40.180]   what is it that, what is the feeling that you get
[01:24:40.180 --> 01:24:42.440]   that makes you feel bad about it?
[01:24:42.440 --> 01:24:47.440]   - It signals to me that you don't give a damn about,
[01:24:47.440 --> 01:24:49.440]   (sighs)
[01:24:49.440 --> 01:24:54.480]   people who are struggling in ways
[01:24:54.480 --> 01:24:56.080]   that you are not struggling.
[01:24:56.080 --> 01:25:01.080]   Like that signals to me, like about the experience of others.
[01:25:01.080 --> 01:25:04.040]   - Do you think that there are other words also
[01:25:04.040 --> 01:25:06.480]   that could convey like a similar feeling to you?
[01:25:06.480 --> 01:25:07.320]   'Cause it feels like you've drawn
[01:25:07.320 --> 01:25:09.360]   a pretty special circle around,
[01:25:09.360 --> 01:25:11.000]   'cause like I imagine, I go, "Oh, this guy's,
[01:25:11.000 --> 01:25:13.640]   "you're an uneducated dumb fuck," or, "You're a nitwicker."
[01:25:13.640 --> 01:25:15.440]   Like, do those words--
[01:25:15.440 --> 01:25:17.920]   - Well, that circle keeps changing.
[01:25:17.920 --> 01:25:18.760]   - Which it can, which is fine, it does.
[01:25:18.760 --> 01:25:21.320]   - And I think that's what the whole point with the culture.
[01:25:21.320 --> 01:25:25.280]   So I'm trying to feel, my feeling is a kind of,
[01:25:25.280 --> 01:25:27.560]   I'm a human being that exists in a social context
[01:25:27.560 --> 01:25:30.320]   that we're all evolving that language together
[01:25:30.320 --> 01:25:31.160]   and just feels wrong.
[01:25:31.160 --> 01:25:34.840]   Like, the word bitch, for example, it really,
[01:25:34.840 --> 01:25:37.560]   like I've heard on your streams and in general,
[01:25:37.560 --> 01:25:42.560]   calling a woman a stupid bitch really bothers me.
[01:25:42.560 --> 01:25:45.240]   But it's not just the word bitch, it's context.
[01:25:45.240 --> 01:25:47.440]   Like, for example, me personally,
[01:25:47.440 --> 01:25:48.800]   I'm speaking to me personally,
[01:25:48.800 --> 01:25:53.480]   like badass bitch is different than stupid bitch.
[01:25:53.480 --> 01:25:55.280]   - Sure, like a bad bitch or something is different than,
[01:25:55.280 --> 01:25:56.960]   yeah, of course. - Way different.
[01:25:56.960 --> 01:26:00.840]   I think it speaks to a bigger sense of civility
[01:26:00.840 --> 01:26:04.680]   and respect for human beings that are not like you.
[01:26:04.680 --> 01:26:07.720]   That's the feeling that I'm bothered.
[01:26:07.720 --> 01:26:10.480]   So I guess what I'm trying to say here is
[01:26:12.520 --> 01:26:16.800]   just because people speak in this kind of way
[01:26:16.800 --> 01:26:19.680]   in the gaming world and in streams
[01:26:19.680 --> 01:26:23.720]   doesn't mean that you, like a lot of people look up to you.
[01:26:23.720 --> 01:26:26.920]   It doesn't mean, young people especially,
[01:26:26.920 --> 01:26:28.860]   doesn't mean that you don't have the responsibility
[01:26:28.860 --> 01:26:31.080]   to sort of stand alone from the crowd.
[01:26:31.080 --> 01:26:32.640]   'Cause you're somebody that values
[01:26:32.640 --> 01:26:35.180]   the power of effective discourse.
[01:26:35.180 --> 01:26:40.240]   And to be effective discourse,
[01:26:40.240 --> 01:26:41.840]   there's some level of civility.
[01:26:41.840 --> 01:26:44.520]   So you can be the sort of the beacon of civility
[01:26:44.520 --> 01:26:49.520]   in that world versus giving in to the derogatory words.
[01:26:49.520 --> 01:26:55.120]   'Cause you have to lift people out of that world,
[01:26:55.120 --> 01:27:00.120]   out of the muck of, what I would say is like drama
[01:27:00.120 --> 01:27:02.320]   in effective discourse.
[01:27:02.320 --> 01:27:04.180]   I think that's one of your missions, right?
[01:27:04.180 --> 01:27:07.480]   Is like to inspire the world through conversation,
[01:27:07.480 --> 01:27:09.960]   through debate, through effective discourse.
[01:27:09.960 --> 01:27:11.640]   So I guess I'm just calling you out
[01:27:11.640 --> 01:27:14.600]   that I think using our word, for me personally,
[01:27:14.600 --> 01:27:18.600]   as a fan that believes in your mission,
[01:27:18.600 --> 01:27:22.080]   it just makes you look ineffective and bad
[01:27:22.080 --> 01:27:24.960]   and uninspiring to young people that look up to you.
[01:27:24.960 --> 01:27:27.440]   'Cause those young people are going to use those words
[01:27:27.440 --> 01:27:30.760]   that you're using and they'll do it much less effectively.
[01:27:30.760 --> 01:27:32.280]   - Sure. - That's the problem.
[01:27:32.280 --> 01:27:33.320]   - Yeah, I guess the challenge is always
[01:27:33.320 --> 01:27:34.720]   just like finding the line.
[01:27:34.720 --> 01:27:38.160]   Like my vocabulary shifted dramatically from,
[01:27:38.160 --> 01:27:39.720]   even from like two or three years ago,
[01:27:39.720 --> 01:27:41.760]   I think my vocabulary shifted quite a bit
[01:27:41.760 --> 01:27:43.760]   as we've like, we've kind of gotten rid of some words
[01:27:43.760 --> 01:27:46.280]   and some things are kind of coming out.
[01:27:46.280 --> 01:27:48.400]   The R word is one that has kind of gone out and come back
[01:27:48.400 --> 01:27:49.760]   and gone out and come back.
[01:27:49.760 --> 01:27:51.440]   That one we've definitely gone back and forth on.
[01:27:51.440 --> 01:27:52.640]   I know there are different thoughts about it
[01:27:52.640 --> 01:27:54.200]   in different communities on the internet.
[01:27:54.200 --> 01:27:55.040]   - This is interesting.
[01:27:55.040 --> 01:27:59.440]   I mean, I'm just telling you, for me, it cuts,
[01:27:59.440 --> 01:28:01.920]   and I'm not a social justice warrior type,
[01:28:01.920 --> 01:28:03.760]   it cuts pretty hard.
[01:28:03.760 --> 01:28:05.440]   - What you're saying is I'm gonna lose a subscriber
[01:28:05.440 --> 01:28:08.120]   if I'm-- - No, it's not a subscriber.
[01:28:08.120 --> 01:28:09.880]   I know what you mean. - I actually have
[01:28:09.880 --> 01:28:12.280]   to empathize harder because I'm like,
[01:28:12.280 --> 01:28:14.100]   maybe this is not a very good person.
[01:28:14.100 --> 01:28:15.280]   That's what I feel.
[01:28:15.280 --> 01:28:18.240]   Like if you're so carelessly using that word,
[01:28:18.240 --> 01:28:20.080]   then maybe you're not actually thinking deeply
[01:28:20.080 --> 01:28:22.600]   about the suffering in the world.
[01:28:22.600 --> 01:28:24.740]   Like to be a student of human nature,
[01:28:24.740 --> 01:28:26.360]   you really have to think about other humans
[01:28:26.360 --> 01:28:28.280]   and other experiences that are unlike your own.
[01:28:28.280 --> 01:28:29.120]   - Yeah, of course.
[01:28:29.120 --> 01:28:30.000]   - And so that's the sense I get.
[01:28:30.000 --> 01:28:34.160]   But at the same time, you're also like the grandpa,
[01:28:34.160 --> 01:28:36.880]   I mean, ageist, who's trying to be cool with the young kids.
[01:28:36.880 --> 01:28:40.200]   A lot of the reason young kids look up to you
[01:28:40.200 --> 01:28:42.920]   is like you also know the language of the internet.
[01:28:42.920 --> 01:28:44.600]   - Yeah, but I mean, that's not an excuse
[01:28:44.600 --> 01:28:46.720]   to use words that we think shouldn't be used.
[01:28:46.720 --> 01:28:48.360]   I guess the question that I would have,
[01:28:48.360 --> 01:28:49.240]   'cause it's always a struggle,
[01:28:49.240 --> 01:28:50.960]   and to some extent it's kind of happened,
[01:28:50.960 --> 01:28:53.720]   is let's say that like three years ago,
[01:28:53.720 --> 01:28:55.840]   I would have said I'm no longer saying the R word,
[01:28:55.840 --> 01:28:58.320]   that's just, I'm just gonna get rid of that in my vocabulary.
[01:28:58.320 --> 01:29:00.240]   Like is there a chance that today,
[01:29:00.240 --> 01:29:01.840]   we would be having a conversation about like,
[01:29:01.840 --> 01:29:04.040]   why do you call people dumb fucks?
[01:29:04.040 --> 01:29:05.160]   Like is that really appropriate?
[01:29:05.160 --> 01:29:07.640]   Like does this attack at the core of like somebody's like,
[01:29:07.640 --> 01:29:10.320]   level of intelligence, education, opportunities in life,
[01:29:10.320 --> 01:29:11.640]   like is that worthy?
[01:29:11.640 --> 01:29:12.720]   You don't think so?
[01:29:12.720 --> 01:29:15.520]   - I think that's a, as the kids say, cope.
[01:29:15.520 --> 01:29:16.360]   - You really think so?
[01:29:16.360 --> 01:29:17.560]   - I think that's-- - Because the words
[01:29:17.560 --> 01:29:19.600]   have definitely moved in a way where it's like,
[01:29:19.600 --> 01:29:21.440]   this was okay, now it's not, this is okay, now it's not.
[01:29:21.440 --> 01:29:23.160]   - So you're standing your ground by using,
[01:29:23.160 --> 01:29:28.160]   listen, you could, you could, but I think it's better
[01:29:28.160 --> 01:29:32.280]   to use those words, if you want to defend the ground
[01:29:32.280 --> 01:29:36.320]   words stand on, to use them rarely and deliberately,
[01:29:36.320 --> 01:29:38.760]   versus how you currently use them,
[01:29:38.760 --> 01:29:43.760]   which is to express an emotion, like you,
[01:29:43.760 --> 01:29:45.920]   I'm going to be honest, you use R word,
[01:29:45.920 --> 01:29:47.640]   not when you're at your best.
[01:29:47.640 --> 01:29:48.480]   (laughing)
[01:29:48.480 --> 01:29:49.320]   - True.
[01:29:49.320 --> 01:29:50.440]   - And so that's not--
[01:29:50.440 --> 01:29:51.400]   - That's generally, that could be true
[01:29:51.400 --> 01:29:53.200]   for a lot of swearing too, but yeah, I know what you mean.
[01:29:53.200 --> 01:29:55.960]   - No, but like, you know that R word is offensive,
[01:29:55.960 --> 01:29:58.020]   you know, and there's part of it is like,
[01:29:59.400 --> 01:30:03.600]   you tell yourself that like, you're still kind of
[01:30:03.600 --> 01:30:06.640]   fighting political correctness by using it a little bit
[01:30:06.640 --> 01:30:07.580]   when you say it?
[01:30:07.580 --> 01:30:09.680]   - No, I don't think so, I think, I'm trying to think
[01:30:09.680 --> 01:30:11.400]   in terms of like, where is the virtue,
[01:30:11.400 --> 01:30:12.840]   where like, there's a whole bunch of arguments
[01:30:12.840 --> 01:30:14.720]   for why some words are okay, some words aren't okay,
[01:30:14.720 --> 01:30:16.560]   or whatever, and I try to like, think more along
[01:30:16.560 --> 01:30:19.000]   those lines rather than, but like, there's going to be
[01:30:19.000 --> 01:30:21.680]   like a lot of phrases where like, if the R word
[01:30:21.680 --> 01:30:23.600]   has come out, the conversation is over,
[01:30:23.600 --> 01:30:25.600]   like I know that, like things, my brain is shut down,
[01:30:25.600 --> 01:30:27.240]   the person I'm talking to is, but there's like,
[01:30:27.240 --> 01:30:29.440]   there's a lot of words also in terms of like,
[01:30:29.440 --> 01:30:32.000]   if you ever hear me say like, fucking moron in a debate,
[01:30:32.000 --> 01:30:33.980]   it's like, it's done, like this conversation is over,
[01:30:33.980 --> 01:30:35.600]   there's no way that anything productive
[01:30:35.600 --> 01:30:37.000]   is happening past that point.
[01:30:37.000 --> 01:30:40.180]   - I think fucking moron is not, I think it's ineffective,
[01:30:40.180 --> 01:30:43.560]   it's not civil, but it's not, it doesn't bother me
[01:30:43.560 --> 01:30:47.720]   in a way, it's basically when you speak in a way
[01:30:47.720 --> 01:30:51.360]   that I know there's a group that's going to be hurt by that,
[01:30:51.360 --> 01:30:54.000]   not only do I think about the hurt that group experiences,
[01:30:54.000 --> 01:30:57.800]   I think of you as a lesser intellectual,
[01:30:57.800 --> 01:31:00.560]   like as a lesser person who's thinking about the world.
[01:31:00.560 --> 01:31:05.560]   What bothers me the most is just what kind of mindset
[01:31:05.560 --> 01:31:08.920]   that inspires in young people, especially when you're
[01:31:08.920 --> 01:31:11.440]   a public figure and a lot of people look up to you.
[01:31:11.440 --> 01:31:15.120]   So I definitely don't think sort of this idea,
[01:31:15.120 --> 01:31:19.100]   the R word is not the battleground of expanding
[01:31:19.100 --> 01:31:22.560]   the Overton window of discourse, okay?
[01:31:22.560 --> 01:31:27.560]   Like I don't think it'll lead to dumb fuck being canceled
[01:31:27.560 --> 01:31:33.800]   two years later, unless that word is hurting
[01:31:33.800 --> 01:31:37.880]   people's experience, which I don't foresee that happening.
[01:31:37.880 --> 01:31:42.000]   I think legitimately, R word and F slur
[01:31:42.000 --> 01:31:47.000]   and calling women bitches, context matters here too,
[01:31:47.000 --> 01:31:50.760]   like of course, but just the way I've heard you use it,
[01:31:50.760 --> 01:31:54.280]   it is not, it's from emotion and it's from frustration
[01:31:54.280 --> 01:31:57.280]   and it ultimately is rooted in disrespect.
[01:31:57.280 --> 01:31:59.440]   I don't, I think it's ineffective.
[01:31:59.440 --> 01:32:02.880]   And of course, like who gets to say, I don't know,
[01:32:02.880 --> 01:32:06.880]   but I'm saying somebody who, like I admire
[01:32:06.880 --> 01:32:11.280]   effective conversations and I admire great humor,
[01:32:11.280 --> 01:32:13.140]   dark humor, wit.
[01:32:13.140 --> 01:32:18.200]   To me, oftentimes the use of the R word
[01:32:18.200 --> 01:32:20.240]   in the way you've used it and the way I see the community
[01:32:20.240 --> 01:32:22.200]   use it is none of those things.
[01:32:22.200 --> 01:32:24.920]   It contributes not at all to the humor and so on.
[01:32:24.920 --> 01:32:28.920]   Now I could see it might contribute to the camaraderie
[01:32:28.920 --> 01:32:32.320]   of that particular group, especially when they normalize
[01:32:32.320 --> 01:32:34.040]   the use of that word.
[01:32:34.040 --> 01:32:36.240]   You kind of take some of the edge off,
[01:32:36.240 --> 01:32:40.960]   but you forget that there's a large number of other people
[01:32:40.960 --> 01:32:45.360]   that don't have the chemistry, that don't hear the music
[01:32:45.360 --> 01:32:47.920]   of the friendship that you have, the relationship you have,
[01:32:47.920 --> 01:32:51.320]   and instead they hear the normalization of a hateful word
[01:32:51.320 --> 01:32:53.880]   and it ultimately has an impact that's hateful.
[01:32:53.880 --> 01:32:56.000]   And then people like me who show up,
[01:32:56.000 --> 01:32:58.160]   I haven't watched much of your stuff.
[01:32:58.160 --> 01:33:01.840]   It turns me off from, a couple of times your content
[01:33:01.840 --> 01:33:05.440]   came before me and I listened to it a little bit,
[01:33:05.440 --> 01:33:06.340]   it turned me off completely.
[01:33:06.340 --> 01:33:09.340]   I didn't understand how good your heart is.
[01:33:09.340 --> 01:33:13.080]   I didn't understand how your mission of actually
[01:33:14.480 --> 01:33:19.000]   de-radicalize people, help people, and increase the level
[01:33:19.000 --> 01:33:21.440]   of good faith discourse in the world.
[01:33:21.440 --> 01:33:22.720]   I didn't understand any of that,
[01:33:22.720 --> 01:33:25.000]   'cause what I was hearing is pretty rough,
[01:33:25.000 --> 01:33:27.080]   the R word type of stuff.
[01:33:27.080 --> 01:33:29.440]   And I just feel like the benefit-cost analysis
[01:33:29.440 --> 01:33:31.000]   is heavy on the cost.
[01:33:31.000 --> 01:33:31.840]   - Gotcha.
[01:33:31.840 --> 01:33:34.080]   - So I just have to sort of call this out.
[01:33:34.080 --> 01:33:37.840]   And I straight up think it's wrong.
[01:33:37.840 --> 01:33:41.360]   - Why do you think it's wrong?
[01:33:41.360 --> 01:33:43.760]   - 'Cause it's hurting people without any benefit
[01:33:43.760 --> 01:33:45.040]   to you whatsoever.
[01:33:45.040 --> 01:33:46.040]   - When you say hurting people,
[01:33:46.040 --> 01:33:47.120]   do you mean the person I'm using it at,
[01:33:47.120 --> 01:33:47.960]   or do you think there's like the--
[01:33:47.960 --> 01:33:48.780]   - No, no, no, no, we're listening.
[01:33:48.780 --> 01:33:49.620]   - We're talking about the affected third group.
[01:33:49.620 --> 01:33:51.240]   - The third group.
[01:33:51.240 --> 01:33:52.120]   - It's good feedback, right?
[01:33:52.120 --> 01:33:53.600]   I always consider everything, especially,
[01:33:53.600 --> 01:33:55.640]   I respect you a lot, you're a really smart guy.
[01:33:55.640 --> 01:33:58.360]   Something that I always kind of like,
[01:33:58.360 --> 01:34:01.500]   fight over in terms of like language,
[01:34:01.500 --> 01:34:03.760]   or like who to attack, or what to attack, or what to do,
[01:34:03.760 --> 01:34:07.840]   is that it's very hard to draw like what boxes
[01:34:07.840 --> 01:34:11.080]   are okay to insult people on versus what aren't.
[01:34:11.080 --> 01:34:13.800]   So for instance, if I call somebody like a Nazi
[01:34:13.800 --> 01:34:18.120]   with a lot of vitriol, I'm okay with every single Nazi
[01:34:18.120 --> 01:34:19.960]   being negatively affected by that,
[01:34:19.960 --> 01:34:23.960]   because that category intrinsically calls upon it
[01:34:23.960 --> 01:34:26.000]   some level of more condemnation for me, right?
[01:34:26.000 --> 01:34:27.560]   Whereas like if I'm out there,
[01:34:27.560 --> 01:34:29.440]   I try not to do like image-related jokes, right?
[01:34:29.440 --> 01:34:30.280]   I don't wanna call you like,
[01:34:30.280 --> 01:34:31.520]   oh, you're a fat fucking loser,
[01:34:31.520 --> 01:34:33.000]   because there's a lot of people that are fat,
[01:34:33.000 --> 01:34:34.800]   that are overweight, where I don't want them to feel bad.
[01:34:34.800 --> 01:34:36.360]   I don't want them, I'm not trying to call you out
[01:34:36.360 --> 01:34:37.560]   or like insult you.
[01:34:37.560 --> 01:34:40.400]   So there's like a lot of, you say cost benefit,
[01:34:40.400 --> 01:34:42.720]   I like a lot of collateral damage from a word like that,
[01:34:42.720 --> 01:34:45.200]   where there's no purpose in doing that.
[01:34:45.200 --> 01:34:46.920]   So certain words are easy to get rid of,
[01:34:46.920 --> 01:34:48.120]   they're off the table, right?
[01:34:48.120 --> 01:34:51.160]   F slur, N word, like these are not words you call people,
[01:34:51.160 --> 01:34:53.880]   because there's so much collateral, it's not worth it.
[01:34:53.880 --> 01:34:56.200]   We've got some words where it's like,
[01:34:56.200 --> 01:34:58.360]   if you have some form of like mental thing,
[01:34:58.360 --> 01:35:00.200]   it is a bad thing, you're not a bad person,
[01:35:00.200 --> 01:35:01.840]   but just using that word could feel like
[01:35:01.840 --> 01:35:04.480]   a collateral damage to those people.
[01:35:04.480 --> 01:35:05.880]   And then there's other categories of words.
[01:35:05.880 --> 01:35:07.720]   So like, if I say that like,
[01:35:07.720 --> 01:35:10.840]   this person is like, it's a stupid fucking Republican,
[01:35:10.840 --> 01:35:14.360]   right, there's probably some Republicans that aren't dumb,
[01:35:14.360 --> 01:35:16.100]   that I don't wanna feel called out by that.
[01:35:16.100 --> 01:35:17.960]   Like, are those types of phrases that you think
[01:35:17.960 --> 01:35:19.240]   should be completely removed as well?
[01:35:19.240 --> 01:35:20.760]   Or I'm kind of curious.
[01:35:20.760 --> 01:35:24.040]   - This completely removed, just so we're clear.
[01:35:24.040 --> 01:35:24.860]   - Yeah.
[01:35:24.860 --> 01:35:26.600]   - I'm not referring to censorship.
[01:35:26.600 --> 01:35:27.440]   - Oh no, I'm not even talking about,
[01:35:27.440 --> 01:35:29.320]   I'm just a person like emotionally like--
[01:35:29.320 --> 01:35:30.680]   - Removed is the wrong word though.
[01:35:30.680 --> 01:35:35.040]   Like I care about, like, I'm not trying to listen
[01:35:35.040 --> 01:35:36.240]   to people on the internet saying
[01:35:36.240 --> 01:35:38.280]   like you shouldn't say that word, that's not good.
[01:35:38.280 --> 01:35:43.280]   I mean, I'm trying to look to your mind and heart.
[01:35:43.280 --> 01:35:45.160]   The reason we're talking today
[01:35:45.160 --> 01:35:48.260]   is you're betraying your gift.
[01:35:48.260 --> 01:35:49.880]   You're better than this.
[01:35:49.880 --> 01:35:51.040]   - You think it's indicative of like
[01:35:51.040 --> 01:35:52.480]   a more flippant thought process,
[01:35:52.480 --> 01:35:54.080]   where it's like the only way you can say that word
[01:35:54.080 --> 01:35:56.680]   is if you're ignoring the hurt and suffering of those people.
[01:35:56.680 --> 01:35:57.520]   And if you're somebody that says--
[01:35:57.520 --> 01:36:00.400]   - Not even those people, you're ignoring
[01:36:00.400 --> 01:36:03.380]   the state of language.
[01:36:03.380 --> 01:36:04.840]   'Cause I think you're getting to the point,
[01:36:04.840 --> 01:36:06.400]   'cause it's not about a single word.
[01:36:06.400 --> 01:36:08.960]   It's about like, it's music.
[01:36:08.960 --> 01:36:10.640]   And I just feel like there is--
[01:36:10.640 --> 01:36:13.280]   - Very strong note.
[01:36:13.280 --> 01:36:15.760]   - It's a strong note that ruins the melody.
[01:36:15.760 --> 01:36:16.600]   - Gotcha.
[01:36:16.600 --> 01:36:17.960]   - And I don't think I can say, you know,
[01:36:17.960 --> 01:36:19.920]   you shouldn't use the R word or whatever.
[01:36:19.920 --> 01:36:22.560]   I'm just speaking to, I'm just listening to music
[01:36:22.560 --> 01:36:24.780]   and reviewing the final result.
[01:36:24.780 --> 01:36:28.840]   It's not necessarily, 'cause maybe one use of the R word
[01:36:28.840 --> 01:36:32.200]   strategically or part of an actual,
[01:36:32.200 --> 01:36:35.200]   like when you've built up a camaraderie
[01:36:35.200 --> 01:36:38.960]   that's sandwiched in like some love,
[01:36:38.960 --> 01:36:40.800]   but then you try to reveal their,
[01:36:40.800 --> 01:36:42.040]   'cause you're talking about a lot of,
[01:36:42.040 --> 01:36:44.900]   there's a bunch of drama, you have friends
[01:36:44.900 --> 01:36:46.680]   with whom you're worrying and stuff,
[01:36:46.680 --> 01:36:50.800]   and they're all a little bit beautifully insane.
[01:36:50.800 --> 01:36:53.320]   And you've said that you are becoming more and more insane.
[01:36:53.320 --> 01:36:54.200]   It's beautiful to watch,
[01:36:54.200 --> 01:36:56.200]   it's the human condition laid before us.
[01:36:56.200 --> 01:36:58.640]   Wonderful, and some of that is swearing and so on.
[01:36:58.640 --> 01:37:00.320]   So it's a tricky thing.
[01:37:00.320 --> 01:37:04.840]   But the whole skill of discourse,
[01:37:04.840 --> 01:37:07.200]   just like it is with dark humor, is walking that line.
[01:37:07.200 --> 01:37:11.680]   I just feel like it's overuse of the R word.
[01:37:11.680 --> 01:37:13.200]   And I don't wanna die in that ground,
[01:37:13.200 --> 01:37:15.360]   'cause I don't think it's that representative.
[01:37:15.360 --> 01:37:17.920]   Like there's certain things like that,
[01:37:17.920 --> 01:37:20.080]   it feels like it ruins the music.
[01:37:20.080 --> 01:37:20.920]   - Gotcha.
[01:37:20.920 --> 01:37:21.740]   - And I don't, you know, it's the same,
[01:37:21.740 --> 01:37:24.880]   like a dumb Republican or a dumb Democrat, I don't,
[01:37:24.880 --> 01:37:26.680]   yeah, that ruins it too a little bit.
[01:37:26.680 --> 01:37:28.760]   Depends on how you use it.
[01:37:28.760 --> 01:37:30.240]   You can be lazy with that.
[01:37:30.240 --> 01:37:31.080]   - Yeah.
[01:37:31.080 --> 01:37:32.440]   - You know, like even overuse of the word,
[01:37:32.440 --> 01:37:34.360]   I think bots is what's used for people
[01:37:34.360 --> 01:37:35.600]   who don't think or something.
[01:37:35.600 --> 01:37:37.360]   I don't actually know the definition.
[01:37:37.360 --> 01:37:39.540]   I'm offended on behalf of robots.
[01:37:39.540 --> 01:37:42.600]   - That might be a compliment soon.
[01:37:42.600 --> 01:37:43.440]   (laughs)
[01:37:43.440 --> 01:37:44.280]   - Right, exactly.
[01:37:44.280 --> 01:37:46.280]   But I guess bot means you don't think.
[01:37:46.280 --> 01:37:48.640]   - Yeah, you're like an NPC, you just copy everybody else.
[01:37:48.640 --> 01:37:50.520]   - Again, I'm offended on behalf of NPCs,
[01:37:50.520 --> 01:37:52.000]   I count myself as one.
[01:37:52.000 --> 01:37:55.880]   But there's a sense if you say bots too much
[01:37:55.880 --> 01:37:58.120]   that you're just dismissing people.
[01:37:58.120 --> 01:38:01.360]   Like everything I say is right,
[01:38:01.360 --> 01:38:03.640]   and anyone that disagrees with me is a bot.
[01:38:03.640 --> 01:38:05.720]   That's lazy too.
[01:38:05.720 --> 01:38:08.840]   Sometimes it's funny, sometimes it's effective.
[01:38:08.840 --> 01:38:11.240]   Basically saying a lot of people in the mainstream media
[01:38:11.240 --> 01:38:12.180]   or something like that are bots.
[01:38:12.180 --> 01:38:15.280]   Okay, that's, a little bit of that is effective.
[01:38:15.280 --> 01:38:18.240]   But too much, it becomes ineffective.
[01:38:18.240 --> 01:38:19.800]   And I'm trying to speak to that.
[01:38:19.800 --> 01:38:20.640]   - Yeah, I understand.
[01:38:20.640 --> 01:38:22.160]   - And I'm just, the reason we're highlighting
[01:38:22.160 --> 01:38:25.320]   clear examples, like the N word.
[01:38:26.440 --> 01:38:28.240]   Joe Rogan had to contend with that.
[01:38:28.240 --> 01:38:29.800]   - Oh yeah, the, yeah.
[01:38:29.800 --> 01:38:30.960]   - I think it's ineffective.
[01:38:30.960 --> 01:38:33.000]   It makes you less effective at discourse.
[01:38:33.000 --> 01:38:35.760]   But like you've talked about many times,
[01:38:35.760 --> 01:38:37.640]   language is a tricky one.
[01:38:37.640 --> 01:38:38.840]   - It's always hard 'cause you talk about
[01:38:38.840 --> 01:38:40.040]   constructing a melody.
[01:38:40.040 --> 01:38:42.840]   There's not one melody that sounds good to everyone.
[01:38:42.840 --> 01:38:44.680]   But there are probably certain notes that like,
[01:38:44.680 --> 01:38:46.320]   if you got rid of them,
[01:38:46.320 --> 01:38:48.080]   everybody's still gonna like it about as much,
[01:38:48.080 --> 01:38:49.000]   and you don't really lose anything.
[01:38:49.000 --> 01:38:50.280]   There's a whole other part of an audience
[01:38:50.280 --> 01:38:52.520]   that might be more willing to listen, of course.
[01:38:52.520 --> 01:38:55.160]   - And it's not about losing the magic of that melody.
[01:38:55.160 --> 01:38:56.620]   You don't wanna be vanilla.
[01:38:56.620 --> 01:38:58.880]   I just feel like there's stuff
[01:38:58.880 --> 01:39:00.320]   that doesn't need to be there.
[01:39:00.320 --> 01:39:01.160]   - Yeah, for sure.
[01:39:01.160 --> 01:39:02.200]   - It's fat.
[01:39:02.200 --> 01:39:03.440]   But then again, you're,
[01:39:03.440 --> 01:39:06.080]   the other thing that people should understand
[01:39:06.080 --> 01:39:07.440]   that might be listening to this,
[01:39:07.440 --> 01:39:11.480]   you're streaming many hours a day for many years.
[01:39:11.480 --> 01:39:12.320]   I don't know, it's a--
[01:39:12.320 --> 01:39:13.520]   - 11 or 12, I think, yeah.
[01:39:13.520 --> 01:39:14.360]   Started in 2010.
[01:39:14.360 --> 01:39:16.200]   - And so one of the things that people can do
[01:39:16.200 --> 01:39:18.240]   is just clip out anything.
[01:39:18.240 --> 01:39:21.880]   You're going through the full human experience of emotion.
[01:39:21.880 --> 01:39:25.640]   Anger, fear, frustration, all of it.
[01:39:25.640 --> 01:39:27.600]   So of course, there's going to be moments
[01:39:27.600 --> 01:39:29.840]   when you're not the best version of yourself.
[01:39:29.840 --> 01:39:33.160]   Anything else to say about the language?
[01:39:33.160 --> 01:39:34.520]   - It's complicated.
[01:39:34.520 --> 01:39:36.200]   I'm still always trying to figure it out.
[01:39:36.200 --> 01:39:37.360]   There are opinions that I have
[01:39:37.360 --> 01:39:38.920]   that have changed throughout the years.
[01:39:38.920 --> 01:39:40.880]   It's possible that the R word has always been
[01:39:40.880 --> 01:39:42.200]   the next one on the chopping block
[01:39:42.200 --> 01:39:43.080]   that we're all kinda looking at,
[01:39:43.080 --> 01:39:45.120]   but people are always worried about that treadmill.
[01:39:45.120 --> 01:39:46.080]   But it's possible in a year or two,
[01:39:46.080 --> 01:39:47.120]   I'll have a different view on it,
[01:39:47.120 --> 01:39:50.360]   or I'll have changed away some of the words I use.
[01:39:50.360 --> 01:39:51.400]   Yeah, it's definitely like a,
[01:39:51.400 --> 01:39:52.520]   it's always like a work in progress.
[01:39:52.520 --> 01:39:53.680]   There's always like different communities
[01:39:53.680 --> 01:39:56.120]   that feel different ways about different words, yeah.
[01:39:56.120 --> 01:39:59.040]   - Yeah, but do you acknowledge that there's people out there
[01:39:59.040 --> 01:40:00.680]   that are never gonna talk to you?
[01:40:00.680 --> 01:40:05.800]   They're never gonna think of you as a good man
[01:40:05.800 --> 01:40:09.200]   because you used the N word with a hard R publicly.
[01:40:09.200 --> 01:40:10.200]   - In the past?
[01:40:10.200 --> 01:40:11.560]   I mean, yeah, those people exist,
[01:40:11.560 --> 01:40:16.160]   but I mean, there are some people that are beyond my reach,
[01:40:16.160 --> 01:40:17.260]   which I'm okay with.
[01:40:17.260 --> 01:40:18.160]   Like, there's gonna be some people
[01:40:18.160 --> 01:40:19.080]   because of things that have been involved,
[01:40:19.080 --> 01:40:20.640]   or even ideas that I have now
[01:40:20.640 --> 01:40:23.140]   that might make them beyond my reach.
[01:40:23.140 --> 01:40:25.520]   Something you said earlier was very true.
[01:40:25.520 --> 01:40:27.160]   I think the goal is to identify
[01:40:27.160 --> 01:40:29.120]   what are the elements that you can cut out
[01:40:29.120 --> 01:40:30.900]   that aren't integral to your message,
[01:40:30.900 --> 01:40:34.200]   but could be alienating to more people,
[01:40:34.200 --> 01:40:35.740]   and those are probably the things that you identify.
[01:40:35.740 --> 01:40:38.160]   But I think that you can get lost in yourself,
[01:40:38.160 --> 01:40:39.400]   or lost in the internet,
[01:40:39.400 --> 01:40:42.360]   or lost in the outside of yourself
[01:40:42.360 --> 01:40:44.200]   if you're trying to appeal to every single person.
[01:40:44.200 --> 01:40:45.840]   It's just never gonna be the case.
[01:40:45.840 --> 01:40:47.480]   And for, I actually,
[01:40:47.480 --> 01:40:49.200]   I like that I've had the journey
[01:40:49.200 --> 01:40:50.200]   that I've had on the internet,
[01:40:50.200 --> 01:40:52.080]   that you can find me saying and defending
[01:40:52.080 --> 01:40:53.960]   a lot of insane stuff 10 years ago,
[01:40:53.960 --> 01:40:55.760]   because I think it shows a level of progress.
[01:40:55.760 --> 01:40:57.240]   And I think I do get a lot of respect
[01:40:57.240 --> 01:40:58.800]   and buy-in to certain communities,
[01:40:58.800 --> 01:41:00.800]   where it's like, I'm not just some random dude
[01:41:00.800 --> 01:41:02.700]   telling you that, oh, you shouldn't say
[01:41:02.700 --> 01:41:03.920]   the F word or the N word.
[01:41:03.920 --> 01:41:05.480]   I'm a guy that's been there, that's done it,
[01:41:05.480 --> 01:41:07.240]   that's defended it, and you can see my whole past,
[01:41:07.240 --> 01:41:08.840]   my whole history is laid bare for you
[01:41:08.840 --> 01:41:12.100]   to watch every, thousands of hours of it.
[01:41:12.100 --> 01:41:13.360]   But I can show that there's growth,
[01:41:13.360 --> 01:41:15.480]   and evolution, and change that can happen in a person.
[01:41:15.480 --> 01:41:18.340]   - Yeah, and you're honest about that growth.
[01:41:18.340 --> 01:41:21.080]   It's a tricky thing, 'cause people just call,
[01:41:21.080 --> 01:41:23.160]   bring up stuff from your past.
[01:41:23.160 --> 01:41:24.060]   - For sure.
[01:41:24.060 --> 01:41:27.000]   - I hope we figure out, as a civilization,
[01:41:27.000 --> 01:41:31.640]   a mechanism to clearly say, this was me two years ago,
[01:41:31.640 --> 01:41:34.780]   this was me five years ago, I'm a different person.
[01:41:34.780 --> 01:41:38.640]   Because Twitter doesn't care about that.
[01:41:38.640 --> 01:41:40.680]   These social mechanisms that bring stuff up
[01:41:40.680 --> 01:41:42.200]   doesn't care about that.
[01:41:42.200 --> 01:41:44.680]   It's like, one stupid thing you say,
[01:41:44.680 --> 01:41:46.760]   it becomes like a scarlet letter.
[01:41:46.760 --> 01:41:47.960]   And I don't know how to fight that.
[01:41:47.960 --> 01:41:49.240]   It's tricky to fight that.
[01:41:49.240 --> 01:41:50.960]   - Have you ever seen Men in Black?
[01:41:50.960 --> 01:41:51.800]   - Yes.
[01:41:51.800 --> 01:41:53.240]   - When KJ on the bench, and he says,
[01:41:53.240 --> 01:41:55.520]   a person is smart, but people are stupid,
[01:41:55.520 --> 01:41:57.480]   dumb, finicky animals, or whatever,
[01:41:57.480 --> 01:41:59.880]   there's something that changes for human dynamics
[01:41:59.880 --> 01:42:01.880]   when there is a group of people
[01:42:01.880 --> 01:42:03.160]   that make it so hard to control.
[01:42:03.160 --> 01:42:05.720]   Like, I think one-on-one, anybody can sit across
[01:42:05.720 --> 01:42:07.920]   from somebody and admit to some horrible stuff.
[01:42:07.920 --> 01:42:11.960]   I used to be, I abused my husband when I was 20,
[01:42:11.960 --> 01:42:14.000]   and now I'm 35, and I see it's wrong, or I did this,
[01:42:14.000 --> 01:42:16.200]   I was addicted to whatever, and I made these mistakes.
[01:42:16.200 --> 01:42:17.680]   One-on-one, it's always easy.
[01:42:17.680 --> 01:42:20.880]   But in group environments, that in-group, out-group,
[01:42:20.880 --> 01:42:22.960]   tribalistic thing of identifying one thing
[01:42:22.960 --> 01:42:24.560]   and then coming to destroy a person's life
[01:42:24.560 --> 01:42:27.900]   is such a huge impulse we have.
[01:42:27.900 --> 01:42:30.400]   And I think, probably when we were hunter-gatherers
[01:42:30.400 --> 01:42:31.920]   in the forest, probably good,
[01:42:31.920 --> 01:42:34.080]   'cause you really wanna push weird people out
[01:42:34.080 --> 01:42:34.920]   or anything like that.
[01:42:34.920 --> 01:42:36.760]   But now on the internet, when we can hunt
[01:42:36.760 --> 01:42:38.880]   for any dissenting opinion, and just,
[01:42:38.880 --> 01:42:41.560]   with ruthless precision, destroy somebody's life over it,
[01:42:41.560 --> 01:42:43.400]   it's a pretty scary dynamic.
[01:42:43.400 --> 01:42:45.980]   - I think one of the mechanisms that could fix it
[01:42:45.980 --> 01:42:49.280]   is make it super easy for each individual person
[01:42:49.280 --> 01:42:51.920]   to analyze all the stupid shit they themselves have said
[01:42:51.920 --> 01:42:54.300]   in the past, like a full recording.
[01:42:54.300 --> 01:42:58.440]   Because I think people are just honestly,
[01:42:58.440 --> 01:43:00.720]   paint a very rosy picture to their own brain
[01:43:00.720 --> 01:43:03.440]   of who they have been in the past.
[01:43:03.440 --> 01:43:04.280]   - Yeah, of course.
[01:43:04.280 --> 01:43:05.920]   - If we can have empathy for the fact
[01:43:05.920 --> 01:43:08.840]   that we've said stupid shit, or we're drunk,
[01:43:08.840 --> 01:43:10.480]   the ridiculous things you say,
[01:43:10.480 --> 01:43:12.360]   the offensive things you might have said,
[01:43:12.360 --> 01:43:13.680]   the offensive things you might have done,
[01:43:13.680 --> 01:43:18.680]   I just feel like that would give us the ammunition
[01:43:18.680 --> 01:43:21.320]   to have empathy for others that are like,
[01:43:21.320 --> 01:43:23.880]   okay, yeah, this guy five years ago said this.
[01:43:23.880 --> 01:43:27.640]   Maybe that doesn't represent who they are
[01:43:27.640 --> 01:43:30.000]   any more than stuff I said five years ago
[01:43:30.000 --> 01:43:32.420]   represents who I am today.
[01:43:32.420 --> 01:43:34.800]   I feel like technology can actually enable that.
[01:43:34.800 --> 01:43:37.400]   - Maybe, although you're talking about more recording
[01:43:37.400 --> 01:43:39.440]   and more stuff, which people are already wary of.
[01:43:39.440 --> 01:43:42.100]   - It's a double-edged sword.
[01:43:42.100 --> 01:43:44.480]   I think there is going to be more and more recording.
[01:43:44.480 --> 01:43:45.680]   We have to figure out how to do that
[01:43:45.680 --> 01:43:47.840]   in the way that respects people's privacy
[01:43:47.840 --> 01:43:49.880]   and gives them ownership of their data and so on.
[01:43:49.880 --> 01:43:52.840]   I've looked at the search history I've done on Google,
[01:43:52.840 --> 01:43:54.560]   which for most people is available,
[01:43:54.560 --> 01:43:56.360]   like your Google search history,
[01:43:56.360 --> 01:43:57.840]   and it's fascinating to watch the evolution
[01:43:57.840 --> 01:43:58.800]   of a human being.
[01:43:58.800 --> 01:44:01.440]   It doesn't seem like the same person.
[01:44:01.440 --> 01:44:02.440]   It's like a different person.
[01:44:02.440 --> 01:44:03.440]   - For sure.
[01:44:03.440 --> 01:44:04.280]   - It's weird.
[01:44:04.280 --> 01:44:05.880]   - It's also hard too with the internet today.
[01:44:05.880 --> 01:44:07.280]   I'm gonna be ageist again,
[01:44:07.280 --> 01:44:09.920]   but now all of the people are thrown together,
[01:44:09.920 --> 01:44:13.340]   whereas I don't want a 27-year-old judging
[01:44:13.340 --> 01:44:15.540]   the image of a 15 or 16-year-old.
[01:44:15.540 --> 01:44:16.980]   Obviously, he's in high school.
[01:44:16.980 --> 01:44:18.500]   There was that story that came out of the,
[01:44:18.500 --> 01:44:20.700]   there was a kid that saved a recording of,
[01:44:20.700 --> 01:44:22.140]   I think it was some white girl.
[01:44:22.140 --> 01:44:23.820]   I think that she got her driver's license
[01:44:23.820 --> 01:44:25.900]   and she was like, "I can drive now, N-words,"
[01:44:25.900 --> 01:44:26.820]   with the A or whatever.
[01:44:26.820 --> 01:44:27.820]   It was dumb, she shouldn't have said it,
[01:44:27.820 --> 01:44:29.220]   but I think she was 15 or 16
[01:44:29.220 --> 01:44:31.020]   when she TikTok'd this or whatever.
[01:44:31.020 --> 01:44:33.020]   And he held onto that recording until she applied
[01:44:33.020 --> 01:44:35.120]   and got accepted to college three years later,
[01:44:35.120 --> 01:44:37.180]   and then he released it to get her kicked out of college.
[01:44:37.180 --> 01:44:39.220]   And I'm like, "Damn."
[01:44:39.220 --> 01:44:40.840]   If everything that I had ever said
[01:44:40.840 --> 01:44:44.520]   as a 15, 16-year-old was immortalized on the internet,
[01:44:44.520 --> 01:44:47.140]   my life wouldn't have even begun. (laughs)
[01:44:47.140 --> 01:44:50.400]   'Cause those are insanely high standards to hold people to.
[01:44:50.400 --> 01:44:53.480]   Not that, obviously, you shouldn't be saying those,
[01:44:53.480 --> 01:44:54.800]   you shouldn't be saying certain words or whatever,
[01:44:54.800 --> 01:44:57.840]   but you have to be able to make mistakes in adolescence.
[01:44:57.840 --> 01:44:59.200]   Everybody does, we all did.
[01:44:59.200 --> 01:45:00.600]   Everybody did it growing up.
[01:45:00.600 --> 01:45:03.920]   - Why do you think there is so much misogyny
[01:45:03.920 --> 01:45:06.120]   in the streaming community?
[01:45:06.120 --> 01:45:07.680]   And how can you fight it?
[01:45:07.680 --> 01:45:11.840]   'Cause you've shown a lot of interest in fighting it,
[01:45:11.840 --> 01:45:14.560]   trying to decrease or eliminate misogyny
[01:45:14.560 --> 01:45:15.960]   from your community.
[01:45:15.960 --> 01:45:17.640]   - I think it's really difficult.
[01:45:17.640 --> 01:45:19.000]   I think that eliminating racism
[01:45:19.000 --> 01:45:21.520]   is easier than eliminating misogyny.
[01:45:21.520 --> 01:45:22.720]   - On the internet, you mean?
[01:45:22.720 --> 01:45:24.160]   - On anywhere.
[01:45:24.160 --> 01:45:25.400]   'Cause I think fundamentally,
[01:45:25.400 --> 01:45:26.320]   I don't think there's that much difference
[01:45:26.320 --> 01:45:27.960]   between white people and black people
[01:45:27.960 --> 01:45:30.280]   and brown people and Asian people or whatever.
[01:45:30.280 --> 01:45:31.320]   We have different cultures and stuff,
[01:45:31.320 --> 01:45:33.400]   but at the end of the day, we're all people.
[01:45:33.400 --> 01:45:36.360]   But I think there are differences between men and women,
[01:45:36.360 --> 01:45:38.920]   like throughout all of history and time,
[01:45:38.920 --> 01:45:40.800]   and then even today in every culture.
[01:45:40.800 --> 01:45:42.960]   And when real differences do exist,
[01:45:42.960 --> 01:45:44.600]   it's harder to account for them in a way
[01:45:44.600 --> 01:45:46.560]   that can we have conversations with each other
[01:45:46.560 --> 01:45:49.680]   without it becoming very gendered in a negative way, right?
[01:45:49.680 --> 01:45:51.000]   Negative way of gendering something
[01:45:51.000 --> 01:45:52.920]   would be like a misogynistic way of doing it.
[01:45:52.920 --> 01:45:57.440]   - Of course, it's unclear to me that it's so difficult
[01:45:57.440 --> 01:46:02.360]   to avoid the negative gendering versus the positive,
[01:46:02.360 --> 01:46:04.640]   'cause there's a lot of positive to the tension,
[01:46:04.640 --> 01:46:06.640]   the dance between the different genders and so on.
[01:46:06.640 --> 01:46:09.840]   Maybe in this particular moment in history, it's not.
[01:46:09.840 --> 01:46:12.000]   But it's not trivial to me that racism
[01:46:12.000 --> 01:46:13.080]   is easier to eliminate.
[01:46:13.080 --> 01:46:14.960]   It's an interesting hypothesis,
[01:46:14.960 --> 01:46:17.400]   just because there's more biological difference
[01:46:17.400 --> 01:46:18.680]   between men and women.
[01:46:18.680 --> 01:46:20.760]   That means it's harder to eliminate, but.
[01:46:20.760 --> 01:46:21.600]   - I don't know if this is true.
[01:46:21.600 --> 01:46:22.420]   I hear this a lot.
[01:46:22.420 --> 01:46:23.260]   I feel like I read this somewhere,
[01:46:23.260 --> 01:46:24.080]   but I need to get a better source
[01:46:24.080 --> 01:46:24.920]   before I repeat it everywhere.
[01:46:24.920 --> 01:46:27.160]   But I've heard that in the US military, for instance,
[01:46:27.160 --> 01:46:29.220]   they've gotten exceedingly well,
[01:46:29.220 --> 01:46:30.640]   they do an exceedingly good job
[01:46:30.640 --> 01:46:33.640]   at getting different people of different races to integrate.
[01:46:33.640 --> 01:46:35.200]   And it's not a huge problem
[01:46:35.200 --> 01:46:36.800]   once you're through basic training,
[01:46:36.800 --> 01:46:38.200]   all the training, everything.
[01:46:38.200 --> 01:46:39.440]   But for different sexes,
[01:46:39.440 --> 01:46:41.120]   it still represents a significant problem
[01:46:41.120 --> 01:46:42.640]   that the military hasn't figured out.
[01:46:42.640 --> 01:46:43.480]   And I actually looked at like,
[01:46:43.480 --> 01:46:44.400]   well, what's the military doing?
[01:46:44.400 --> 01:46:45.800]   'Cause if something was solvable,
[01:46:45.800 --> 01:46:47.800]   like can we sleep for four hours a night and be healthy?
[01:46:47.800 --> 01:46:49.440]   If we could, I bet the military would know.
[01:46:49.440 --> 01:46:50.440]   So I kind of look sometimes to them
[01:46:50.440 --> 01:46:51.280]   to see their integration.
[01:46:51.280 --> 01:46:52.980]   But it might be that there are other issues there
[01:46:52.980 --> 01:46:53.820]   that make it kind of--
[01:46:53.820 --> 01:46:54.880]   - Yeah, it feels like the military
[01:46:54.880 --> 01:46:55.720]   is a very particular kind of--
[01:46:55.720 --> 01:46:56.640]   - For sure, yeah, it could be.
[01:46:56.640 --> 01:47:01.600]   - The actual task at hand might bias
[01:47:01.600 --> 01:47:03.280]   the difficulty of the process.
[01:47:03.280 --> 01:47:04.440]   - Potentially, yeah.
[01:47:04.440 --> 01:47:06.840]   There's been a lot of interesting talk
[01:47:06.840 --> 01:47:10.800]   about like women integrating into male groups.
[01:47:10.800 --> 01:47:12.720]   And how do you do this in a way
[01:47:12.720 --> 01:47:15.240]   where everybody is happy with the outcome
[01:47:15.240 --> 01:47:18.080]   and there's not like issues.
[01:47:18.080 --> 01:47:19.960]   I think Jordan Peterson spoke about this a little bit.
[01:47:19.960 --> 01:47:22.320]   And then Workplace Culture speaks about this a bit.
[01:47:22.320 --> 01:47:24.280]   Would you happen to remember,
[01:47:24.280 --> 01:47:26.240]   I wanna say it was like five or 10 years ago,
[01:47:26.240 --> 01:47:27.920]   there was a big tech conference
[01:47:27.920 --> 01:47:29.480]   and there were two guys behind a woman
[01:47:29.480 --> 01:47:32.200]   and they made a joke about like a USB dongle,
[01:47:32.200 --> 01:47:33.600]   like dongle was a dick.
[01:47:33.600 --> 01:47:34.640]   And this woman turned around,
[01:47:34.640 --> 01:47:35.960]   she tweeted pictures of them,
[01:47:35.960 --> 01:47:37.240]   spoke about like misogyny.
[01:47:37.240 --> 01:47:41.560]   And then that blew up into a huge ordeal that like, yeah.
[01:47:41.560 --> 01:47:43.700]   There was this interesting phenomenon
[01:47:43.700 --> 01:47:47.520]   that in a less misogynistic
[01:47:47.520 --> 01:47:50.080]   and more inclusive workplace environment,
[01:47:50.080 --> 01:47:53.360]   some women might end up feeling worse
[01:47:53.360 --> 01:47:54.920]   because in a more misogynistic environment,
[01:47:54.920 --> 01:47:56.660]   you're thinking like, okay, that's a woman,
[01:47:56.660 --> 01:47:57.640]   she doesn't get our humor.
[01:47:57.640 --> 01:48:00.360]   I'm gonna treat her in a very indifferent,
[01:48:00.360 --> 01:48:02.320]   very dispassionate, cold way and whatever.
[01:48:02.320 --> 01:48:04.160]   And then I'm gonna have my boys over here.
[01:48:04.160 --> 01:48:05.560]   And then you've got like these environments
[01:48:05.560 --> 01:48:06.560]   where they're a little bit more warmer
[01:48:06.560 --> 01:48:07.520]   and it's like, oh, cool,
[01:48:07.520 --> 01:48:09.000]   we're gonna bring this woman into our environment
[01:48:09.000 --> 01:48:10.200]   and we're gonna make all the same types
[01:48:10.200 --> 01:48:11.960]   of like crass jokes we did before.
[01:48:11.960 --> 01:48:13.080]   And it's actually worse now.
[01:48:13.080 --> 01:48:14.520]   Now the woman feels even more otherwise
[01:48:14.520 --> 01:48:16.600]   'cause like, oh my God, why do you talk like this?
[01:48:16.600 --> 01:48:18.000]   I think that internet communities,
[01:48:18.000 --> 01:48:20.480]   especially online ones that do like political debate
[01:48:20.480 --> 01:48:23.600]   and video games are very much like big boys clubs.
[01:48:23.600 --> 01:48:25.360]   So it's not enough to just say,
[01:48:25.360 --> 01:48:27.860]   you can't be misogynistic to get rid of misogyny.
[01:48:27.860 --> 01:48:30.040]   There's always gonna be an othering effect on women.
[01:48:30.040 --> 01:48:32.560]   There's a lot of like behaviors that are unintuitive
[01:48:32.560 --> 01:48:33.560]   that you have to account for
[01:48:33.560 --> 01:48:35.520]   and you've gotta try to like push that back.
[01:48:35.520 --> 01:48:38.760]   And that's just a very, very, very challenging thing to do.
[01:48:38.760 --> 01:48:40.880]   So I like to deal with concrete examples more.
[01:48:40.880 --> 01:48:42.240]   So here's a concrete example.
[01:48:42.240 --> 01:48:44.080]   And this is like a recent initiative in my community
[01:48:44.080 --> 01:48:45.200]   'cause I'm trying to like be,
[01:48:45.200 --> 01:48:47.000]   'cause misogyny hasn't been fixed anywhere on the internet.
[01:48:47.000 --> 01:48:47.840]   I'm curious, well, there are ways
[01:48:47.840 --> 01:48:50.360]   that I can push my community to do this.
[01:48:50.360 --> 01:48:52.040]   I don't think you should almost ever make a comment
[01:48:52.040 --> 01:48:53.440]   on a woman's appearance ever,
[01:48:53.440 --> 01:48:55.040]   if they're appearing in like some political
[01:48:55.040 --> 01:48:56.240]   or professional manner.
[01:48:56.240 --> 01:48:57.680]   Even if it's a positive comment,
[01:48:57.680 --> 01:48:59.600]   I think it's equally bad to a negative comment.
[01:48:59.600 --> 01:49:01.160]   It's just never good to do.
[01:49:01.160 --> 01:49:02.440]   And that's kind of an unintuitive thing
[01:49:02.440 --> 01:49:04.000]   'cause it's like, well, a woman appears,
[01:49:04.000 --> 01:49:05.320]   wow, she's really cute.
[01:49:05.320 --> 01:49:06.240]   It seems like a nice comment.
[01:49:06.240 --> 01:49:07.720]   You're being nice, you know, she looks cute or whatever,
[01:49:07.720 --> 01:49:09.680]   but it's like, it's not at all the point of why she's there.
[01:49:09.680 --> 01:49:10.900]   And just by saying that,
[01:49:10.900 --> 01:49:12.760]   you're kind of like otherizing her as like a person
[01:49:12.760 --> 01:49:14.480]   to like think she looks good
[01:49:14.480 --> 01:49:17.120]   rather than listening to anything she has to say, you know?
[01:49:17.120 --> 01:49:20.000]   - Well, there's a lot of stuff that you're saying
[01:49:20.000 --> 01:49:26.080]   that is a part of misogyny that's almost like obvious.
[01:49:26.080 --> 01:49:27.680]   Like any woman will tell you that.
[01:49:27.680 --> 01:49:29.400]   - Woman will, yeah, but they're not in these spaces
[01:49:29.400 --> 01:49:30.240]   and a lot of the guys don't know.
[01:49:30.240 --> 01:49:34.760]   - But I think what that requires is just empathy.
[01:49:34.760 --> 01:49:40.320]   You need to consider the female experience.
[01:49:40.320 --> 01:49:41.160]   That's it.
[01:49:41.160 --> 01:49:44.120]   Like you have to either read about or talk with women.
[01:49:44.120 --> 01:49:47.440]   You learn, like the low-hanging fruit is very easy to learn.
[01:49:47.440 --> 01:49:49.640]   It feels like just the level of social skill
[01:49:49.640 --> 01:49:54.240]   oftentimes in internet communities is quite low.
[01:49:54.240 --> 01:49:55.080]   - I disagree.
[01:49:55.080 --> 01:49:57.600]   I don't like to say, here's the problem with empathy
[01:49:57.600 --> 01:50:00.160]   is it's very hard to have empathy for experiences
[01:50:00.160 --> 01:50:02.440]   that are so outside of your own.
[01:50:02.440 --> 01:50:03.500]   Well, maybe some people,
[01:50:03.500 --> 01:50:05.260]   there might be some people that can do it, I can't.
[01:50:05.260 --> 01:50:07.080]   There's a lot of stuff that I had to learn.
[01:50:07.080 --> 01:50:08.800]   - Women are half the population.
[01:50:08.800 --> 01:50:09.800]   - But they're women.
[01:50:09.800 --> 01:50:12.000]   They're totally different.
[01:50:12.000 --> 01:50:14.520]   - They're totally different.
[01:50:14.520 --> 01:50:16.800]   We'll talk about it right though.
[01:50:16.800 --> 01:50:18.360]   They're not totally different.
[01:50:18.360 --> 01:50:19.640]   - So here's an example, okay?
[01:50:19.640 --> 01:50:22.360]   So especially for me,
[01:50:22.360 --> 01:50:26.240]   my archetype makes up a lot of the internet, white man.
[01:50:27.040 --> 01:50:28.280]   There's never been a point--
[01:50:28.280 --> 01:50:29.880]   - The name of a beautiful woman.
[01:50:29.880 --> 01:50:30.920]   - Who might be a dancer.
[01:50:30.920 --> 01:50:33.240]   - What's the backstory, from New Orleans or from--
[01:50:33.240 --> 01:50:35.160]   - I haven't thought that through yet.
[01:50:35.160 --> 01:50:36.400]   It's ambiguous, okay?
[01:50:36.400 --> 01:50:37.600]   - Like an open world--
[01:50:37.600 --> 01:50:39.920]   - Open world, I want you to project wherever you want
[01:50:39.920 --> 01:50:42.320]   destiny of the dancer to be from, that's in your mind, okay?
[01:50:42.320 --> 01:50:44.160]   - All right, I'll save that for later tonight.
[01:50:44.160 --> 01:50:45.000]   - Yeah, okay.
[01:50:45.000 --> 01:50:49.540]   As a white guy, I don't know if there's ever been a spot
[01:50:49.540 --> 01:50:51.840]   that I've been in where I've been made to feel like
[01:50:51.840 --> 01:50:54.400]   I don't belong there just by virtue of who I am.
[01:50:54.400 --> 01:50:57.440]   I actually don't, it's impossible for me to empathize that
[01:50:57.440 --> 01:50:59.840]   'cause I don't even have that experience.
[01:50:59.840 --> 01:51:01.880]   If you go back eight, nine years,
[01:51:01.880 --> 01:51:03.320]   one of the big issues that came up
[01:51:03.320 --> 01:51:05.600]   was harassment in gaming against women.
[01:51:05.600 --> 01:51:08.220]   And I was one of the big debaters against that,
[01:51:08.220 --> 01:51:10.980]   saying that like, sure, women might get harassment,
[01:51:10.980 --> 01:51:12.560]   but everybody gets harassment.
[01:51:12.560 --> 01:51:15.200]   If you're a woman and you're in gaming and you get harassed,
[01:51:15.200 --> 01:51:16.920]   congratulations, you're being treated like a man.
[01:51:16.920 --> 01:51:18.280]   What you're actually asking for
[01:51:18.280 --> 01:51:19.640]   is for us to actually treat you differently.
[01:51:19.640 --> 01:51:21.040]   You don't wanna be insulted.
[01:51:21.040 --> 01:51:22.240]   You don't wanna be treated like a man.
[01:51:22.240 --> 01:51:23.520]   And that's actually misogyny
[01:51:23.520 --> 01:51:24.720]   is women making that argument.
[01:51:24.720 --> 01:51:26.280]   - Do you still stand by that?
[01:51:26.280 --> 01:51:27.980]   - Is that a problem if I do?
[01:51:27.980 --> 01:51:29.280]   No, I'm just kidding.
[01:51:29.280 --> 01:51:30.640]   Okay, hold on.
[01:51:30.640 --> 01:51:31.480]   So a little while after--
[01:51:31.480 --> 01:51:32.600]   - I disagree with it.
[01:51:32.600 --> 01:51:34.320]   - Sure, okay, that's good, you should.
[01:51:34.320 --> 01:51:37.240]   A little while later, I had a friend, Jessica,
[01:51:37.240 --> 01:51:38.280]   super cool girl.
[01:51:38.280 --> 01:51:39.360]   We go to play games.
[01:51:39.360 --> 01:51:40.600]   She was between jobs and she's like,
[01:51:40.600 --> 01:51:42.800]   "I've got like two months and we're gonna grind CSGO."
[01:51:42.800 --> 01:51:45.040]   And I'm like, "Okay, this is awesome, let's do it."
[01:51:45.040 --> 01:51:47.200]   CSGO, Counter-Strike, Global Offensive,
[01:51:47.200 --> 01:51:49.740]   shooter game, FPS, microphones.
[01:51:49.740 --> 01:51:50.920]   First day we start playing, okay?
[01:51:50.920 --> 01:51:52.280]   Hop into our first game.
[01:51:52.280 --> 01:51:53.960]   Obviously she talks, everybody's making,
[01:51:53.960 --> 01:51:55.000]   "Is that a 12 year old boy?
[01:51:55.000 --> 01:51:56.160]   "Why aren't you making sandwiches?"
[01:51:56.160 --> 01:51:57.520]   Blah, blah, blah, yeah, okay, whatever.
[01:51:57.520 --> 01:52:00.040]   Play our first game, play our second game, same jokes.
[01:52:00.040 --> 01:52:01.240]   Third game, fourth game.
[01:52:01.240 --> 01:52:03.240]   By like the fourth or fifth game,
[01:52:03.240 --> 01:52:04.720]   I was actually starting to feel triggered.
[01:52:04.720 --> 01:52:06.100]   Like every time the game started, I was like,
[01:52:06.100 --> 01:52:07.720]   "Can you just like talk so we can get over
[01:52:07.720 --> 01:52:10.560]   "like the stupid fucking jokes, it's so fucking stupid."
[01:52:10.560 --> 01:52:13.680]   And you hear the same fucking joke every single time.
[01:52:13.680 --> 01:52:16.120]   And it took one day of that experience
[01:52:16.120 --> 01:52:19.020]   for me to realize it's not about being insulted.
[01:52:19.020 --> 01:52:21.400]   It's like this othering feeling that you don't belong.
[01:52:21.400 --> 01:52:23.760]   And I've never felt that because I'm a white guy.
[01:52:23.760 --> 01:52:24.960]   Not to be like virtue signaling,
[01:52:24.960 --> 01:52:26.400]   but like there's no places where it's like,
[01:52:26.400 --> 01:52:27.400]   "You're white, you don't belong here.
[01:52:27.400 --> 01:52:29.200]   "You're a guy, you don't belong here."
[01:52:29.200 --> 01:52:31.040]   Like I've never felt that non-inclusion.
[01:52:31.040 --> 01:52:34.400]   And playing with her, there's a different feeling
[01:52:34.400 --> 01:52:36.400]   when it's the same types of jokes
[01:52:36.400 --> 01:52:37.480]   coming from a group of people
[01:52:37.480 --> 01:52:39.680]   to make you feel like you don't belong there.
[01:52:39.680 --> 01:52:42.520]   Where I was like, "Damn, this actually feels really bad."
[01:52:42.520 --> 01:52:43.880]   And it feels bad in a different way
[01:52:43.880 --> 01:52:46.480]   where it's like if you call me like an F slur
[01:52:46.480 --> 01:52:49.040]   or any other type of swear word or insult,
[01:52:49.040 --> 01:52:50.100]   like yeah, you can call me that,
[01:52:50.100 --> 01:52:51.920]   but at the end of the day, we're all kind of the same.
[01:52:51.920 --> 01:52:53.680]   We're all white dudes and we call each other names.
[01:52:53.680 --> 01:52:56.200]   But like, this is a woman and this is not her place
[01:52:56.200 --> 01:52:58.160]   and she doesn't belong here.
[01:52:58.160 --> 01:53:00.000]   Kind of the analogy that I would make,
[01:53:00.000 --> 01:53:01.560]   'cause after getting these experiences,
[01:53:01.560 --> 01:53:03.280]   I would learn this afterwards.
[01:53:03.280 --> 01:53:05.820]   If I tell you that there's another guy in a room
[01:53:05.820 --> 01:53:07.720]   and you need to think of the worst insults ever
[01:53:07.720 --> 01:53:09.760]   for that person without ever knowing anything about them
[01:53:09.760 --> 01:53:11.280]   or meeting them, if I tell you
[01:53:11.280 --> 01:53:12.760]   that it's like a white straight guy
[01:53:12.760 --> 01:53:15.160]   and you have to write insults, you're fucked.
[01:53:15.160 --> 01:53:16.760]   Maybe you can do like school shooter,
[01:53:16.760 --> 01:53:18.360]   but there's not really much you can say
[01:53:18.360 --> 01:53:19.400]   at the end of the day.
[01:53:19.400 --> 01:53:21.060]   But if I tell you it's a woman,
[01:53:21.060 --> 01:53:23.040]   we could, there are so many different jokes you can write.
[01:53:23.040 --> 01:53:24.100]   If it's a black person,
[01:53:24.100 --> 01:53:25.900]   so many different racist things we can say.
[01:53:25.900 --> 01:53:26.740]   - Are you sure?
[01:53:26.740 --> 01:53:28.860]   I can come up with a lot of stuff for a white guy.
[01:53:28.860 --> 01:53:30.420]   - In terms of stuff that is just intrinsic
[01:53:30.420 --> 01:53:31.780]   to him being a white guy?
[01:53:31.780 --> 01:53:33.420]   - Yeah, like there's--
[01:53:33.420 --> 01:53:34.260]   - Really?
[01:53:34.260 --> 01:53:36.080]   - Wait a minute, what are you talking about?
[01:53:36.080 --> 01:53:39.520]   There's a lot, the internet has sharpened that sword.
[01:53:39.520 --> 01:53:42.620]   - In terms of like jokes that are targeted at his sex--
[01:53:42.620 --> 01:53:46.620]   - Incel, virgin, weak.
[01:53:46.620 --> 01:53:48.340]   - Some of the incel, virgin, maybe.
[01:53:48.340 --> 01:53:49.580]   - Yeah, that's getting there, sure.
[01:53:49.580 --> 01:53:50.420]   That's for sure.
[01:53:50.420 --> 01:53:52.980]   That's recent though, sorry, I'm older on the internet.
[01:53:52.980 --> 01:53:54.420]   We didn't have those words way back then.
[01:53:54.420 --> 01:53:55.260]   - That wasn't--
[01:53:55.260 --> 01:53:56.140]   - When I was making these analogies,
[01:53:56.140 --> 01:53:56.980]   that incel and virgin--
[01:53:56.980 --> 01:53:58.460]   - Back in my day, we didn't have general--
[01:53:58.460 --> 01:53:59.940]   - There were no incels back then.
[01:53:59.940 --> 01:54:01.280]   None of us had sex, we just accepted it.
[01:54:01.280 --> 01:54:02.420]   We were all computer gamers.
[01:54:02.420 --> 01:54:04.500]   Nobody had sex to play video games back then, okay?
[01:54:04.500 --> 01:54:05.340]   People don't remember that.
[01:54:05.340 --> 01:54:06.460]   There wasn't the Big Bang Theory.
[01:54:06.460 --> 01:54:07.820]   You were just a loser that was stuck in--
[01:54:07.820 --> 01:54:09.340]   - You guys didn't even know sex existed
[01:54:09.340 --> 01:54:10.180]   so you could use it as an incel.
[01:54:10.180 --> 01:54:11.000]   - Exactly, yeah.
[01:54:11.000 --> 01:54:12.780]   We had to download sexual pictures and it took two minutes
[01:54:12.780 --> 01:54:13.780]   and you didn't even know if you were gonna get
[01:54:13.780 --> 01:54:15.420]   the right thing by the time it finished loading.
[01:54:15.420 --> 01:54:17.180]   But what I'm saying is that, okay,
[01:54:17.180 --> 01:54:19.780]   I think you agree that if somebody gives you a race,
[01:54:19.780 --> 01:54:21.420]   like a black person who's a woman,
[01:54:21.420 --> 01:54:24.340]   we can write very cutting, scathing insults
[01:54:24.340 --> 01:54:26.220]   for that person that are very otherizing.
[01:54:26.220 --> 01:54:28.180]   - Or words that would really hurt if they're spoken to.
[01:54:28.180 --> 01:54:30.100]   - Yeah, that are very cutting to the person.
[01:54:30.100 --> 01:54:33.120]   But for a white guy, it's kinda hard
[01:54:33.120 --> 01:54:34.500]   because that's the default.
[01:54:34.500 --> 01:54:36.460]   There's not as much otherizing of those people.
[01:54:36.460 --> 01:54:37.300]   Yeah, that's kind of the point.
[01:54:37.300 --> 01:54:40.060]   - So the insults you have from white guy to white guy,
[01:54:40.060 --> 01:54:41.780]   the insults are much harsher.
[01:54:41.780 --> 01:54:44.060]   So when you start to apply the same kind of harshness
[01:54:44.060 --> 01:54:45.300]   to other groups--
[01:54:45.300 --> 01:54:47.580]   - You can make them feel like they really don't belong.
[01:54:47.580 --> 01:54:49.460]   And that otherizing effect is something
[01:54:49.460 --> 01:54:50.420]   that's very hard for me.
[01:54:50.420 --> 01:54:52.380]   I can't really empathize with it 'cause I've never felt it.
[01:54:52.380 --> 01:54:54.660]   So I have to intellectualize it and then sympathize with it.
[01:54:54.660 --> 01:54:56.260]   It's like a whole process I have to go through.
[01:54:56.260 --> 01:54:58.100]   And then I try to walk other people through that
[01:54:58.100 --> 01:54:59.640]   'cause if you're a white guy on the internet,
[01:54:59.640 --> 01:55:00.560]   which is a lot of the internet,
[01:55:00.560 --> 01:55:01.700]   you really don't know what that feels like.
[01:55:01.700 --> 01:55:02.980]   You've never felt like that before.
[01:55:02.980 --> 01:55:05.620]   - Well, so you're now in a leadership position,
[01:55:05.620 --> 01:55:10.320]   Grandpa Destiny, so that's, a lot of people look up to you
[01:55:10.320 --> 01:55:14.260]   for that, for that sort of pathway to empathy.
[01:55:14.260 --> 01:55:15.460]   - Yeah.
[01:55:15.460 --> 01:55:17.420]   - How not to otherize.
[01:55:17.420 --> 01:55:18.940]   I mean, you have felt otherizing.
[01:55:18.940 --> 01:55:22.460]   You mentioned high school people not being--
[01:55:22.460 --> 01:55:24.380]   - Yeah, but those were always for things that,
[01:55:24.380 --> 01:55:25.820]   it's different to insult somebody
[01:55:25.820 --> 01:55:27.700]   for a non-immutable characteristic.
[01:55:27.700 --> 01:55:29.160]   Like, okay, you think poorly about me
[01:55:29.160 --> 01:55:31.220]   because I'm not enough money or I don't have money,
[01:55:31.220 --> 01:55:33.020]   but I could get more money and I could change that.
[01:55:33.020 --> 01:55:34.740]   But it's different for somebody to really attack you
[01:55:34.740 --> 01:55:37.940]   for your gender or attack you for your race.
[01:55:37.940 --> 01:55:39.700]   - A lot of the attacks that hit the hardest
[01:55:39.700 --> 01:55:40.900]   is not about gender.
[01:55:40.900 --> 01:55:44.880]   I do think that they're,
[01:55:44.880 --> 01:55:47.920]   the way women are attacked on the internet,
[01:55:47.920 --> 01:55:50.000]   it's the same kind of attacks you would do
[01:55:50.000 --> 01:55:52.560]   towards other guys, but you go harsher.
[01:55:52.560 --> 01:55:54.520]   - I feel like they're fundamentally different.
[01:55:54.520 --> 01:55:56.420]   I feel like when we're attacking guys,
[01:55:56.420 --> 01:55:58.520]   I'm not usually attacking you
[01:55:58.520 --> 01:56:02.720]   on the virtue of you being a guy,
[01:56:02.720 --> 01:56:04.600]   but if it's a woman and she's typing something,
[01:56:04.600 --> 01:56:06.400]   like, oh, did your boyfriend type that for you?
[01:56:06.400 --> 01:56:07.880]   Or like, what are you even doing here?
[01:56:07.880 --> 01:56:09.700]   Shouldn't you be trying to find a husband?
[01:56:09.700 --> 01:56:11.220]   Or like, oh, you're like a stupid,
[01:56:11.220 --> 01:56:12.060]   go start an OnlyFans or whatever.
[01:56:12.060 --> 01:56:13.180]   - No, but the stupidity,
[01:56:13.180 --> 01:56:15.140]   the intelligence aspect is what's attacked.
[01:56:15.140 --> 01:56:16.260]   - Yeah, but it's so much different.
[01:56:16.260 --> 01:56:17.740]   Like, you can call a guy stupid,
[01:56:17.740 --> 01:56:19.520]   but that's because he's a guy that's being stupid.
[01:56:19.520 --> 01:56:20.620]   But when you call a woman stupid,
[01:56:20.620 --> 01:56:21.980]   she's stupid because she's a woman.
[01:56:21.980 --> 01:56:24.220]   - Yeah, but I honestly think that women
[01:56:24.220 --> 01:56:27.820]   are called stupid more than men on the internet.
[01:56:27.820 --> 01:56:32.300]   It's nothing to do, like, the attack is not gendered.
[01:56:32.300 --> 01:56:37.300]   It's the gender inspires an increased level of attack.
[01:56:37.300 --> 01:56:38.820]   I feel like it is gendered.
[01:56:38.820 --> 01:56:40.740]   - I wish we had data on this.
[01:56:40.740 --> 01:56:42.680]   - Have you ever heard of the XKCD comics?
[01:56:42.680 --> 01:56:43.520]   - Yes.
[01:56:43.520 --> 01:56:44.560]   - It's a really good comic where,
[01:56:44.560 --> 01:56:45.860]   and this is something that I've dealt
[01:56:45.860 --> 01:56:47.700]   with a lot in my community, okay?
[01:56:47.700 --> 01:56:51.060]   There's a guy at a board and he fucks up a math equation,
[01:56:51.060 --> 01:56:52.940]   and it's like, wow, you suck at math.
[01:56:52.940 --> 01:56:55.100]   And then the next panelist, there's a girl that does it,
[01:56:55.100 --> 01:56:56.460]   and she fucks it up, and it's like, wow,
[01:56:56.460 --> 01:56:57.940]   women suck at math.
[01:56:57.940 --> 01:56:59.540]   And there's like that feeling that happens
[01:56:59.540 --> 01:57:02.680]   where when I bring on, I won't use names,
[01:57:02.680 --> 01:57:04.160]   but there are like YouTube people that I've brought on
[01:57:04.160 --> 01:57:05.740]   that have crazy opinions.
[01:57:05.740 --> 01:57:08.180]   And when they're men, that person is crazy.
[01:57:08.180 --> 01:57:09.840]   Oh my God, he said the crazy stuff.
[01:57:09.840 --> 01:57:11.940]   He's so dumb, he's so crazy, he's so stupid.
[01:57:11.940 --> 01:57:14.100]   But when it's a woman, it's like, oh my God,
[01:57:14.100 --> 01:57:15.400]   why do you always bring dumb women here?
[01:57:15.400 --> 01:57:17.540]   Why do so many women on the internet have crazy opinions?
[01:57:17.540 --> 01:57:19.220]   There's a different minority character
[01:57:19.220 --> 01:57:23.300]   that has to stand it and represent their whole group
[01:57:23.300 --> 01:57:25.420]   where white men don't typically have to.
[01:57:25.420 --> 01:57:27.820]   - Speaking of groups versus individuals, yes.
[01:57:27.820 --> 01:57:31.820]   But then what I feel happens is then another person
[01:57:31.820 --> 01:57:34.200]   from that group comes, another woman comes,
[01:57:34.200 --> 01:57:37.120]   and people before she says anything
[01:57:37.120 --> 01:57:41.100]   will already feel like they're ready with that attack.
[01:57:41.100 --> 01:57:41.940]   - For sure.
[01:57:41.940 --> 01:57:43.740]   But they're ready for the attack 'cause she's a woman.
[01:57:43.740 --> 01:57:45.420]   They're gonna call her, she's stupid because she's a woman,
[01:57:45.420 --> 01:57:46.260]   not because she says something,
[01:57:46.260 --> 01:57:48.420]   but just 'cause she's a woman.
[01:57:48.420 --> 01:57:52.420]   - So like the group in their brain
[01:57:52.420 --> 01:57:54.820]   accumulates all the negative characteristics
[01:57:54.820 --> 01:57:56.420]   of the individuals they've met.
[01:57:56.420 --> 01:57:57.820]   Not the positive, the negative.
[01:57:57.820 --> 01:58:00.100]   And it becomes like this ball of stickiness.
[01:58:00.100 --> 01:58:03.140]   And then that becomes the bias for their judgment
[01:58:03.140 --> 01:58:04.980]   of a new person that comes.
[01:58:04.980 --> 01:58:07.420]   With white men, there's more of a blank slate
[01:58:07.420 --> 01:58:09.980]   in terms of bias of how they analyze the person.
[01:58:09.980 --> 01:58:12.300]   With any of the minority group,
[01:58:12.300 --> 01:58:14.780]   they're basically make a judgment
[01:58:14.780 --> 01:58:16.540]   based on the negative characteristics
[01:58:16.540 --> 01:58:18.420]   of the individuals they've met in the past.
[01:58:18.420 --> 01:58:22.100]   That leads to a system where you're just harsher
[01:58:22.100 --> 01:58:24.700]   towards minority groups and towards women.
[01:58:24.700 --> 01:58:26.060]   How do you solve that?
[01:58:26.060 --> 01:58:27.840]   - The most important thing for any problem ever
[01:58:27.840 --> 01:58:29.420]   is step one is to be aware of it.
[01:58:29.420 --> 01:58:30.640]   If you're not aware of it,
[01:58:30.640 --> 01:58:33.220]   then you're hopelessly lost at sea.
[01:58:33.220 --> 01:58:34.460]   But yeah, the first thing I like to say,
[01:58:34.460 --> 01:58:35.300]   she's like, be aware of it.
[01:58:35.300 --> 01:58:37.380]   Like I've had, there's a girl that I've had on recently
[01:58:37.380 --> 01:58:40.080]   and she says a lot of, in my opinion, kind of crazy things,
[01:58:40.080 --> 01:58:41.400]   but people will use her as like,
[01:58:41.400 --> 01:58:42.660]   this is why women shouldn't be here.
[01:58:42.660 --> 01:58:44.640]   This is like, she's crazy and she's a woman and blah, blah,
[01:58:44.640 --> 01:58:45.480]   blah.
[01:58:45.480 --> 01:58:47.120]   But I can bring on a guy who says similarly dumb things
[01:58:47.120 --> 01:58:50.760]   and he's evaluated on his own merits 'cause it's a guy.
[01:58:50.760 --> 01:58:52.380]   There's never, ever, ever been a case
[01:58:52.380 --> 01:58:53.960]   where I brought a stupid guy on stream
[01:58:53.960 --> 01:58:56.160]   and everybody's been like, this guy makes me hate men.
[01:58:56.160 --> 01:58:57.400]   This guy makes me hate white people.
[01:58:57.400 --> 01:58:58.640]   That has never happened.
[01:58:58.640 --> 01:59:00.240]   But then there's like other women that come on
[01:59:00.240 --> 01:59:02.080]   and it's like, now I know why incels exist
[01:59:02.080 --> 01:59:04.680]   or I totally understand where red pill ideology comes from.
[01:59:04.680 --> 01:59:06.760]   And even if the statements are kind of true,
[01:59:06.760 --> 01:59:08.440]   when you're making these observations over and over
[01:59:08.440 --> 01:59:09.280]   and over and over again,
[01:59:09.280 --> 01:59:12.800]   it damages your ability to individually perceive somebody.
[01:59:12.800 --> 01:59:14.580]   And then two people that make the same statements,
[01:59:14.580 --> 01:59:16.240]   one can be perceived more harshly
[01:59:16.240 --> 01:59:18.360]   just because of that like group bias you've got built up.
[01:59:18.360 --> 01:59:19.760]   - I think there's something about streaming
[01:59:19.760 --> 01:59:21.120]   that just brings that out of people.
[01:59:21.120 --> 01:59:23.480]   Like, 'cause you have to talk for like seven hours.
[01:59:23.480 --> 01:59:24.520]   So you're like, all right,
[01:59:24.520 --> 01:59:28.040]   well, whatever psychological issues and complexities I have,
[01:59:28.040 --> 01:59:28.880]   I'm going to explore them.
[01:59:28.880 --> 01:59:31.240]   - They're gonna be magnified. - Magnified.
[01:59:31.240 --> 01:59:33.400]   And then it's the, as you talked about,
[01:59:33.400 --> 01:59:37.320]   the mimetic theories or Girardian,
[01:59:37.320 --> 01:59:40.360]   like whatever the things that are very similar
[01:59:40.360 --> 01:59:43.200]   and you're going to magnify the conflicts that you have
[01:59:43.200 --> 01:59:46.080]   and you're going to explore all the different perspectives
[01:59:46.080 --> 01:59:47.440]   on those different conflicts.
[01:59:47.440 --> 01:59:50.120]   And I mean, I don't know if it's just anecdotal,
[01:59:50.120 --> 01:59:52.760]   but it's nice to have women on stream.
[01:59:52.760 --> 01:59:57.520]   I think the dynamic that you guys have is wonderful.
[01:59:57.520 --> 01:59:58.920]   It's really interesting.
[01:59:58.920 --> 02:00:01.160]   So it's just the female voice in general.
[02:00:01.160 --> 02:00:03.720]   I love having women on the podcast.
[02:00:03.720 --> 02:00:07.560]   The female voice, I feel like is under heard on the internet.
[02:00:07.560 --> 02:00:08.400]   - For sure.
[02:00:08.400 --> 02:00:10.360]   - And I would love the internet to be a place
[02:00:10.360 --> 02:00:12.960]   where women feel safe to speak.
[02:00:12.960 --> 02:00:15.040]   All right, given that you're,
[02:00:15.040 --> 02:00:17.120]   like we talked about a progressive
[02:00:17.120 --> 02:00:19.760]   with nonstandard progressive views.
[02:00:19.760 --> 02:00:24.560]   So you're very pro-free speech, pro-capitalism.
[02:00:24.560 --> 02:00:26.040]   So given that, it's very interesting
[02:00:26.040 --> 02:00:30.240]   that you're also pro-establishment and pro-institutions.
[02:00:30.240 --> 02:00:32.840]   So right now, if you look at the world,
[02:00:32.840 --> 02:00:36.000]   there's a significant distrust of institutions,
[02:00:36.000 --> 02:00:39.400]   at least in sort of public intellectual discourse.
[02:00:39.400 --> 02:00:41.200]   What is the nature of your support
[02:00:41.200 --> 02:00:42.800]   for government and institutions?
[02:00:42.800 --> 02:00:45.300]   Can you make the case for and against them?
[02:00:45.300 --> 02:00:51.440]   - Broadly speaking, there is a synergistic effect
[02:00:51.440 --> 02:00:53.440]   when two humans come together.
[02:00:53.440 --> 02:00:56.800]   If I can speak very broadly in terms of,
[02:00:56.800 --> 02:00:58.680]   we'll say utility, okay?
[02:00:58.680 --> 02:01:01.680]   My happiness with one person might be 10.
[02:01:01.680 --> 02:01:03.600]   The happiness with another person might be 10.
[02:01:03.600 --> 02:01:05.720]   When they come together, it's like 50
[02:01:05.720 --> 02:01:06.560]   between the two of them.
[02:01:06.560 --> 02:01:07.960]   There's like this synergistic effect
[02:01:07.960 --> 02:01:11.320]   when humans work together that the sum is greater
[02:01:11.320 --> 02:01:12.720]   than all the individual parts or whatever.
[02:01:12.720 --> 02:01:14.640]   There's like an emergent thing that happens there.
[02:01:14.640 --> 02:01:17.200]   - There's a capacity, there's a possibility of that.
[02:01:17.200 --> 02:01:18.320]   - Yeah, a possibility, sure.
[02:01:18.320 --> 02:01:19.400]   Things could go really wrong.
[02:01:19.400 --> 02:01:20.600]   There could be a cannibalistic tribe
[02:01:20.600 --> 02:01:21.960]   that all eats each other, sure.
[02:01:21.960 --> 02:01:23.120]   But for the purpose of this--
[02:01:23.120 --> 02:01:25.120]   - There's other failure modes, but yes.
[02:01:25.120 --> 02:01:26.680]   - Okay, sure, yeah.
[02:01:26.680 --> 02:01:28.720]   But I think broadly speaking,
[02:01:28.720 --> 02:01:30.280]   are you gonna be the well actually guy?
[02:01:30.280 --> 02:01:31.320]   Okay, if you wanna, okay.
[02:01:31.320 --> 02:01:32.160]   - Well actually.
[02:01:32.160 --> 02:01:33.000]   - Well actually, sometimes--
[02:01:33.000 --> 02:01:36.080]   - Sometimes cannibalism is actually good for both.
[02:01:36.080 --> 02:01:37.960]   - True, yeah, sometimes things do go wrong.
[02:01:37.960 --> 02:01:39.080]   But I think broadly speaking,
[02:01:39.080 --> 02:01:40.920]   the fact that you're sitting here in clothing
[02:01:40.920 --> 02:01:42.320]   that you didn't make and I'm sitting here
[02:01:42.320 --> 02:01:45.000]   on an airplane that I don't know how to fly or build.
[02:01:45.000 --> 02:01:46.440]   There's a lot of cool stuff that happens
[02:01:46.440 --> 02:01:49.800]   when people come together and they make civilizations.
[02:01:49.800 --> 02:01:52.620]   And part of that civilization building
[02:01:52.620 --> 02:01:54.960]   is the fact that we can specialize
[02:01:54.960 --> 02:01:57.000]   and it's the fact that we can offload
[02:01:57.000 --> 02:01:59.520]   a bunch of trust onto third parties
[02:01:59.520 --> 02:02:02.680]   that we delegate the power to make important decisions
[02:02:02.680 --> 02:02:03.960]   about our lives, right?
[02:02:03.960 --> 02:02:06.880]   I don't know anything about how to build
[02:02:06.880 --> 02:02:08.320]   like a combustion engine,
[02:02:08.320 --> 02:02:09.800]   but I know that when I push the button on my car,
[02:02:09.800 --> 02:02:12.180]   it's gonna drive around and the fumes aren't gonna kill me
[02:02:12.180 --> 02:02:13.440]   and I can park it in garages
[02:02:13.440 --> 02:02:14.720]   and the building's not gonna collapse.
[02:02:14.720 --> 02:02:16.440]   And the only reason all of this works
[02:02:16.440 --> 02:02:17.880]   is because I've offloaded a lot of trust
[02:02:17.880 --> 02:02:19.600]   onto these third party things.
[02:02:19.600 --> 02:02:20.800]   And I would say that the pillars
[02:02:20.820 --> 02:02:22.860]   of these third party things that society is built on
[02:02:22.860 --> 02:02:25.360]   are roughly speaking institutions.
[02:02:25.360 --> 02:02:27.940]   So that might be the institution of peer review
[02:02:27.940 --> 02:02:29.740]   for scientific articles.
[02:02:29.740 --> 02:02:33.700]   It might be the institution of voting for government, right?
[02:02:33.700 --> 02:02:37.020]   Or the ability for us to vote in that whole process.
[02:02:37.020 --> 02:02:38.420]   It might, yeah, the FDA,
[02:02:38.420 --> 02:02:39.760]   like all of these institutions are things
[02:02:39.760 --> 02:02:42.880]   that they need to exist because we don't have the time
[02:02:42.880 --> 02:02:44.820]   or the capability to individually sort
[02:02:44.820 --> 02:02:47.100]   through all of these things individually.
[02:02:47.100 --> 02:02:49.660]   We have to rely on some third party to do it.
[02:02:49.660 --> 02:02:53.800]   - Okay, so you believe at scale,
[02:02:53.800 --> 02:02:55.800]   when we're together, we're greater
[02:02:55.800 --> 02:02:57.040]   than the sum of our parts.
[02:02:57.040 --> 02:02:58.680]   That's the case for institutions.
[02:02:58.680 --> 02:02:59.600]   - Absolutely.
[02:02:59.600 --> 02:03:02.800]   - What about the inefficiencies of bureaucracy?
[02:03:02.800 --> 02:03:05.440]   Is there some aspect when at scale,
[02:03:05.440 --> 02:03:07.980]   different dynamics come into play
[02:03:07.980 --> 02:03:10.160]   than they do when there's two people together?
[02:03:10.160 --> 02:03:13.400]   Two people that love each other, the birds and the bees.
[02:03:13.400 --> 02:03:15.520]   Is there some aspect that leads more
[02:03:15.520 --> 02:03:17.240]   to cannibalism at scale?
[02:03:17.240 --> 02:03:19.200]   So like corruption, inefficiencies
[02:03:19.200 --> 02:03:21.220]   that due to bureaucracy and so on.
[02:03:21.220 --> 02:03:23.500]   - Bureaucracy, which is not,
[02:03:23.500 --> 02:03:26.020]   I hate it when people try to say bureaucracy is government
[02:03:26.020 --> 02:03:27.620]   because bureaucracy exists a ton
[02:03:27.620 --> 02:03:29.220]   in private environments as well, right?
[02:03:29.220 --> 02:03:30.660]   In businesses and everything.
[02:03:30.660 --> 02:03:33.460]   Bureaucracy introduces its own set of problems,
[02:03:33.460 --> 02:03:35.700]   but I mean, a bureaucracy is necessary
[02:03:35.700 --> 02:03:38.220]   because it's coordinating all of the underlying things
[02:03:38.220 --> 02:03:40.300]   in order to create something that's greater
[02:03:40.300 --> 02:03:42.280]   than the sum of its parts, right?
[02:03:42.280 --> 02:03:44.620]   Like all of the software developers in the world
[02:03:44.620 --> 02:03:46.680]   are useless without being paired with good designers
[02:03:46.680 --> 02:03:48.660]   in order to make their products usable by a person.
[02:03:48.660 --> 02:03:50.300]   And the coordination of those people
[02:03:50.300 --> 02:03:52.180]   and the coordination of increasingly more and more things
[02:03:52.180 --> 02:03:54.500]   necessitate some level of bureaucracy.
[02:03:54.500 --> 02:03:57.100]   I think we always say bureaucracy when it's like a bad,
[02:03:57.100 --> 02:03:57.980]   it's like a slur almost,
[02:03:57.980 --> 02:03:59.900]   like you're a bureaucrat, you're bureaucratic.
[02:03:59.900 --> 02:04:01.140]   The bureaucracy is slowing everything down.
[02:04:01.140 --> 02:04:03.320]   It's like, sure, the bureaucracy slows things down,
[02:04:03.320 --> 02:04:06.020]   but bureaucracy also gives us things like safe medicine
[02:04:06.020 --> 02:04:08.180]   and safe water to drink for most of the US
[02:04:08.180 --> 02:04:11.240]   or safe buildings to live in or safe cars to drive, so.
[02:04:11.240 --> 02:04:13.260]   - So the managers in institution
[02:04:13.260 --> 02:04:16.100]   versus like the software developers and the designers,
[02:04:16.100 --> 02:04:18.140]   the managers is the bureaucracy.
[02:04:18.140 --> 02:04:21.260]   The reason bureaucracy is used as a slur
[02:04:21.260 --> 02:04:23.980]   is that something about human nature
[02:04:23.980 --> 02:04:27.420]   leads to bureaucracy often growing,
[02:04:27.420 --> 02:04:30.300]   growing indefinitely.
[02:04:30.300 --> 02:04:31.140]   - Sometimes. - And becoming
[02:04:31.140 --> 02:04:32.340]   less and less efficient.
[02:04:32.340 --> 02:04:35.620]   Without, I mean, this is where capitalism can come in,
[02:04:35.620 --> 02:04:39.620]   that capitalism puts a pressure on the bureaucracy
[02:04:39.620 --> 02:04:43.180]   not to grow too much because you want the bureaucracy
[02:04:43.180 --> 02:04:47.180]   to be useful, but not large.
[02:04:47.180 --> 02:04:49.300]   - Yeah, to be a certain size, yeah, of course.
[02:04:49.300 --> 02:04:53.100]   - To be the minimum size to get the job done.
[02:04:53.100 --> 02:04:55.840]   And so capitalism provides that mechanism.
[02:04:55.840 --> 02:05:00.900]   Government does not always.
[02:05:00.900 --> 02:05:02.660]   And so that's the criticism of government,
[02:05:02.660 --> 02:05:04.980]   of institutions where it can grow
[02:05:04.980 --> 02:05:07.540]   without a significant mechanism that says,
[02:05:07.540 --> 02:05:09.340]   there's a cost to bureaucracy
[02:05:09.340 --> 02:05:11.140]   that's not being accounted for here.
[02:05:11.140 --> 02:05:15.020]   We're just paying for the increasing size of government
[02:05:15.020 --> 02:05:16.860]   without the benefit.
[02:05:16.860 --> 02:05:18.700]   - Yeah, government is a special institution
[02:05:18.700 --> 02:05:20.500]   because it doesn't have to show itself
[02:05:20.500 --> 02:05:22.140]   to be financially viable.
[02:05:22.140 --> 02:05:23.700]   And we kind of live in a capitalist economy
[02:05:23.700 --> 02:05:25.020]   where that's generally the case.
[02:05:25.020 --> 02:05:27.780]   So government gets its powers from votes from the people,
[02:05:27.780 --> 02:05:30.660]   which introduces a whole new set of possible positives
[02:05:30.660 --> 02:05:32.180]   and possible negatives, right?
[02:05:32.180 --> 02:05:33.340]   Having something, for instance,
[02:05:33.340 --> 02:05:35.900]   that gives food or shelter to homeless people,
[02:05:35.900 --> 02:05:38.740]   maybe you don't want that to have to run at a profit.
[02:05:38.740 --> 02:05:41.460]   But giving an organization that can self-justify
[02:05:41.460 --> 02:05:43.660]   its budgets perpetually and indefinitely growing,
[02:05:43.660 --> 02:05:45.220]   maybe that's not the best thing.
[02:05:45.220 --> 02:05:46.460]   Yeah, we always have to figure out
[02:05:46.460 --> 02:05:48.220]   how to do the constraints there.
[02:05:48.220 --> 02:05:52.420]   - What about the corrupting nature of power?
[02:05:52.420 --> 02:05:54.460]   That comes with institutions as well.
[02:05:54.460 --> 02:05:55.300]   - Absolutely.
[02:05:55.300 --> 02:05:57.300]   So then you better pick your style
[02:05:57.300 --> 02:05:58.780]   of institution very carefully.
[02:05:58.780 --> 02:06:00.780]   I think that the democratic institution
[02:06:00.780 --> 02:06:02.100]   we have in the United States today,
[02:06:02.100 --> 02:06:03.820]   I think works very well.
[02:06:03.820 --> 02:06:05.100]   But I mean, there are other styles of government
[02:06:05.100 --> 02:06:05.940]   that have been tried in the past
[02:06:05.940 --> 02:06:08.140]   that I think lend themselves more to corruption.
[02:06:08.140 --> 02:06:08.980]   Not to say that, by the way,
[02:06:08.980 --> 02:06:10.260]   there's not corruption in the United States.
[02:06:10.260 --> 02:06:12.420]   Of course, there's gonna be varying levels of corruption
[02:06:12.420 --> 02:06:15.060]   at like all levels.
[02:06:15.060 --> 02:06:17.580]   But you ran into this interesting problem
[02:06:17.580 --> 02:06:20.100]   where authoritarian regimes can act
[02:06:20.100 --> 02:06:22.580]   with ruthless precision and swiftness
[02:06:22.580 --> 02:06:24.060]   because they don't have to ask any questions.
[02:06:24.060 --> 02:06:26.660]   They just do, do, do, do, do, and that's it.
[02:06:26.660 --> 02:06:28.820]   But the problem is, it's an authoritarian regime.
[02:06:28.820 --> 02:06:30.380]   They're prone to missteps.
[02:06:30.380 --> 02:06:33.420]   They're slow to respond to changing or evolving needs.
[02:06:33.420 --> 02:06:35.140]   There was an interesting study that was put out a while ago
[02:06:35.140 --> 02:06:37.020]   that showed that every single famine
[02:06:37.020 --> 02:06:38.100]   that happened around the world,
[02:06:38.100 --> 02:06:41.900]   almost like 98% of them happened under authoritarian regimes
[02:06:41.900 --> 02:06:43.380]   where freedom of speech is very limited.
[02:06:43.380 --> 02:06:46.300]   It's very rare for a famine to happen under a democracy
[02:06:46.300 --> 02:06:47.460]   because press and everything
[02:06:47.460 --> 02:06:48.660]   makes the government more responsive
[02:06:48.660 --> 02:06:49.940]   to the needs of the people.
[02:06:49.940 --> 02:06:51.880]   Power can corrupt, there are levels of corruption,
[02:06:51.880 --> 02:06:53.900]   but you have to have like a system of checks and balances
[02:06:53.900 --> 02:06:55.180]   on all of those different levels
[02:06:55.180 --> 02:06:57.060]   to make sure it doesn't run off the rails, I guess,
[02:06:57.060 --> 02:06:58.180]   and do a sick loop-de-loop
[02:06:58.180 --> 02:06:59.980]   and half the population gets.
[02:06:59.980 --> 02:07:01.820]   - Nice callback.
[02:07:01.820 --> 02:07:03.860]   There's a lot of people that will listen to you
[02:07:03.860 --> 02:07:06.300]   say that the democracy in the United States
[02:07:06.300 --> 02:07:07.540]   is working pretty damn well
[02:07:07.540 --> 02:07:09.540]   and they will spit out the drink
[02:07:09.540 --> 02:07:13.260]   if they're drinking a drink and be very upset.
[02:07:13.260 --> 02:07:16.220]   Can you make the case that they're right and you're wrong?
[02:07:16.220 --> 02:07:17.820]   - Can I make the case-- - Can you steel man?
[02:07:17.820 --> 02:07:18.660]   - They're right, yeah.
[02:07:18.660 --> 02:07:20.140]   Well, the steel man for them
[02:07:20.140 --> 02:07:22.660]   is that people have a lot of problems on the day-to-day
[02:07:22.660 --> 02:07:25.620]   and when they look and they see what government is doing,
[02:07:25.620 --> 02:07:29.020]   they might see potholes outside their house,
[02:07:29.020 --> 02:07:31.580]   homeless people all over their downtown,
[02:07:31.580 --> 02:07:33.120]   and the United States just approved
[02:07:33.120 --> 02:07:36.140]   another X billion amount of dollars for Ukraine.
[02:07:36.140 --> 02:07:37.980]   Or they might be living in a city
[02:07:37.980 --> 02:07:39.960]   where half the factories are shut down,
[02:07:39.960 --> 02:07:41.540]   a lot of their people are out of work,
[02:07:41.540 --> 02:07:43.780]   but the president is on the TV talking about
[02:07:43.780 --> 02:07:46.460]   how to find jobs for immigrants coming in from Mexico.
[02:07:46.460 --> 02:07:47.420]   And for these people,
[02:07:47.420 --> 02:07:49.980]   they have problems that exist in their lives.
[02:07:49.980 --> 02:07:52.700]   Some of them are paying taxes to alleviate these problems.
[02:07:52.700 --> 02:07:55.340]   And then when they listen to the government talk,
[02:07:55.340 --> 02:07:56.860]   it feels like the government is not responding
[02:07:56.860 --> 02:07:58.260]   to the needs that they have.
[02:07:58.260 --> 02:07:59.540]   And then that's one problem.
[02:07:59.540 --> 02:08:00.620]   Then on top of that,
[02:08:00.620 --> 02:08:02.580]   you've got all of these people working in alternative media
[02:08:02.580 --> 02:08:04.180]   that can show you, well, look at this politician
[02:08:04.180 --> 02:08:05.180]   wasting this much money,
[02:08:05.180 --> 02:08:07.140]   or look at him double speaking here or there.
[02:08:07.140 --> 02:08:09.300]   Look at Hillary Clinton saying she's got a private position
[02:08:09.300 --> 02:08:10.340]   and a public position.
[02:08:10.340 --> 02:08:12.720]   Look at how all of these politicians have family members
[02:08:12.720 --> 02:08:13.560]   that are getting rich
[02:08:13.560 --> 02:08:15.420]   because of their relationships with people in Congress.
[02:08:15.420 --> 02:08:16.500]   Look at the revolving door
[02:08:16.500 --> 02:08:19.420]   between capitalist companies and the government.
[02:08:19.420 --> 02:08:21.140]   How can you look at all of that,
[02:08:21.140 --> 02:08:22.140]   take into account that the government's
[02:08:22.140 --> 02:08:23.380]   not responding to your needs,
[02:08:23.380 --> 02:08:25.000]   and then really feel like it's a government
[02:08:25.000 --> 02:08:26.260]   by the people and for the people?
[02:08:26.260 --> 02:08:27.660]   - Yeah, this was very good.
[02:08:27.660 --> 02:08:30.360]   Good steel, man, and good question.
[02:08:30.360 --> 02:08:31.200]   How can you?
[02:08:31.200 --> 02:08:34.060]   How can you tell that they're not just politicians
[02:08:34.060 --> 02:08:37.540]   that care more about continuously winning the elections
[02:08:37.540 --> 02:08:40.660]   versus running government effectively?
[02:08:40.660 --> 02:08:41.980]   - They should care about winning the elections.
[02:08:41.980 --> 02:08:43.060]   That's the first misconception.
[02:08:43.060 --> 02:08:43.900]   A lot of people say,
[02:08:43.900 --> 02:08:45.580]   "This guy only cares about getting voted in.
[02:08:45.580 --> 02:08:49.220]   "This guy, he doesn't even believe in fracking or abortion.
[02:08:49.220 --> 02:08:51.160]   "He just changes his opinion to get voted in."
[02:08:51.160 --> 02:08:52.940]   Anytime somebody says that, you should say,
[02:08:52.940 --> 02:08:53.940]   "That's really good."
[02:08:53.940 --> 02:08:55.820]   You want them to change their opinion so they get voted in.
[02:08:55.820 --> 02:08:57.220]   That's the whole point of a democracy.
[02:08:57.220 --> 02:08:58.660]   You don't want them to remain obstinate.
[02:08:58.660 --> 02:08:59.500]   You don't want them to say,
[02:08:59.500 --> 02:09:00.860]   "I'm not changing my opinion no matter what the people want."
[02:09:00.860 --> 02:09:02.940]   You want them to evolve and adopt new opinions
[02:09:02.940 --> 02:09:04.280]   based on what the population,
[02:09:04.280 --> 02:09:05.500]   their constituents are voting for.
[02:09:05.500 --> 02:09:08.260]   - Yeah, but the cynical take is that they're,
[02:09:08.260 --> 02:09:10.220]   on the surface, they're changing their opinion,
[02:09:10.220 --> 02:09:13.420]   but that there's a boys club, or boys means the elite,
[02:09:13.420 --> 02:09:17.320]   that under, in the smoke-filled rooms,
[02:09:17.320 --> 02:09:20.540]   in secret, they actually have their own agenda
[02:09:20.540 --> 02:09:21.820]   and they're following that agenda,
[02:09:21.820 --> 02:09:24.180]   and they're just saying anything publicly
[02:09:24.180 --> 02:09:29.180]   to placate the public based on whatever the new trends are.
[02:09:29.180 --> 02:09:31.420]   So here's-- - It's a cynical take
[02:09:31.420 --> 02:09:33.100]   upon the question. - Yeah, I understand.
[02:09:33.100 --> 02:09:35.860]   Somebody asked me this question and it flipped,
[02:09:35.860 --> 02:09:37.900]   I 180'd completely.
[02:09:37.900 --> 02:09:39.580]   I was a Bernie Sanders supporter in 2016,
[02:09:39.580 --> 02:09:44.040]   and my single issue voting thing was lobbying.
[02:09:44.040 --> 02:09:45.780]   I thought that lobbying, the government was corrupt,
[02:09:45.780 --> 02:09:46.700]   they weren't responding to the needs of people,
[02:09:46.700 --> 02:09:50.420]   it completely destroyed my faith in government and everything
[02:09:50.420 --> 02:09:52.660]   and I had one question posed to me by a conservative
[02:09:52.660 --> 02:09:53.700]   that used to come on my stream and shout at me,
[02:09:53.700 --> 02:09:55.760]   and he said, and then he asked me,
[02:09:55.760 --> 02:09:59.500]   "Can you think of any popular opinion
[02:09:59.500 --> 02:10:01.020]   "that the American public has
[02:10:01.020 --> 02:10:02.480]   "that the government is unresponsive to?
[02:10:02.480 --> 02:10:03.900]   "Is there some big piece of legislation
[02:10:03.900 --> 02:10:05.660]   "or policy or whatever that people want
[02:10:05.660 --> 02:10:08.020]   "that the government isn't doing?"
[02:10:08.020 --> 02:10:09.460]   And he asked me that, I couldn't think
[02:10:09.460 --> 02:10:12.060]   of a single good answer, and I'm like, oh, geez.
[02:10:12.060 --> 02:10:13.260]   - There's a good answer. - There's not.
[02:10:13.260 --> 02:10:15.260]   - Drugs. - There's not.
[02:10:15.260 --> 02:10:16.100]   - Legalization. - And that thing.
[02:10:16.100 --> 02:10:17.740]   - Legalization or drugs, hold on a sec.
[02:10:17.740 --> 02:10:18.700]   - Yeah, go for it. - All right, well--
[02:10:18.700 --> 02:10:20.140]   - Oh, shoot, you're doing the Joe Rogan thing,
[02:10:20.140 --> 02:10:23.180]   you're pushing back 'cause I brought up weed, go ahead.
[02:10:23.180 --> 02:10:25.600]   I'm sorry. - I have become meme.
[02:10:25.600 --> 02:10:30.340]   I don't even, I don't wanna interrupt your--
[02:10:30.340 --> 02:10:31.180]   - No, you're good. - 'Cause there's
[02:10:31.180 --> 02:10:33.240]   memes upon memes upon memes I can go with here.
[02:10:33.240 --> 02:10:37.160]   But no, 'cause people bring up, okay, there's no issues,
[02:10:37.160 --> 02:10:38.480]   there's no issues that the government
[02:10:38.480 --> 02:10:40.880]   is not representing of the public.
[02:10:40.880 --> 02:10:42.480]   - So here's the issue, so somebody will bring up,
[02:10:42.480 --> 02:10:45.440]   like, well, what about the legalization of drugs, okay?
[02:10:45.440 --> 02:10:46.960]   The first issue people have is, one,
[02:10:46.960 --> 02:10:48.580]   they look at national polling.
[02:10:48.580 --> 02:10:50.920]   Very few things are decided on a national level,
[02:10:50.920 --> 02:10:52.760]   so that's the first huge mistake.
[02:10:52.760 --> 02:10:55.800]   Arguably, a lot of BLM made mistakes in this arena
[02:10:55.800 --> 02:10:57.280]   where they're saying, like, why isn't the government
[02:10:57.280 --> 02:10:58.720]   doing anything about policing?
[02:10:58.720 --> 02:11:00.040]   Federal government can't do anything about policing,
[02:11:00.040 --> 02:11:01.720]   that's gonna be your, sometimes it's gonna be your state,
[02:11:01.720 --> 02:11:03.080]   sometimes it's your local city government.
[02:11:03.080 --> 02:11:05.140]   The people that like your chief of police,
[02:11:05.140 --> 02:11:08.260]   your police commissioner, that's coming from your mayor.
[02:11:08.260 --> 02:11:09.900]   So you've got people looking, one,
[02:11:09.900 --> 02:11:11.340]   at the wrong parts of the government
[02:11:11.340 --> 02:11:12.760]   to even figure out the solution to the problem.
[02:11:12.760 --> 02:11:16.980]   Two, oftentimes for polling, the questions are vague enough
[02:11:16.980 --> 02:11:18.860]   that you can poll very high, but when you get into
[02:11:18.860 --> 02:11:21.140]   the weeds on things, no pun intended,
[02:11:21.140 --> 02:11:23.020]   you start to realize, like, oh, shoot,
[02:11:23.020 --> 02:11:24.540]   this is more complicated than I thought.
[02:11:24.540 --> 02:11:25.940]   I don't know the numbers in particular
[02:11:25.940 --> 02:11:27.780]   for legalization of marijuana,
[02:11:27.780 --> 02:11:29.220]   but this is what I'm gonna guess is the case.
[02:11:29.220 --> 02:11:32.380]   If you poll and you say, should we legalize marijuana,
[02:11:32.380 --> 02:11:36.260]   that number might poll at like 65, 70%,
[02:11:36.260 --> 02:11:37.100]   but that's including people
[02:11:37.100 --> 02:11:38.500]   that are in favor of medical marijuana.
[02:11:38.500 --> 02:11:42.260]   If you were to poll, like, should we decriminalize
[02:11:42.260 --> 02:11:43.980]   recreational use of marijuana,
[02:11:43.980 --> 02:11:46.180]   that number might drop to like 52%.
[02:11:46.180 --> 02:11:48.580]   And then if you poll, like, should we completely legalize,
[02:11:48.580 --> 02:11:50.060]   not just decriminalize, but completely legalize
[02:11:50.060 --> 02:11:51.260]   recreational use of marijuana,
[02:11:51.260 --> 02:11:53.020]   that number might drop to like 40%.
[02:11:53.020 --> 02:11:54.140]   There's like all these different ways
[02:11:54.140 --> 02:11:55.300]   you can poll around issues where people are like,
[02:11:55.300 --> 02:11:57.700]   oh no, we broadly agree on this topic,
[02:11:57.700 --> 02:11:59.040]   but when you really figure out, well, do you,
[02:11:59.040 --> 02:12:01.260]   do we really agree, or is there just like broad consensus
[02:12:01.260 --> 02:12:02.460]   around a thing that's never gonna show up,
[02:12:02.460 --> 02:12:03.980]   like in a piece of legislation?
[02:12:03.980 --> 02:12:05.500]   A really good example, one example I do know
[02:12:05.500 --> 02:12:07.240]   was socialized healthcare.
[02:12:07.240 --> 02:12:10.020]   I think if you poll, there was a time a few years ago
[02:12:10.020 --> 02:12:11.540]   where if you poll America,
[02:12:11.540 --> 02:12:14.060]   do you think every American citizen should have access
[02:12:14.060 --> 02:12:15.840]   to like free healthcare?
[02:12:15.840 --> 02:12:19.420]   I think that answer, that poll, like 74% yes.
[02:12:19.420 --> 02:12:21.340]   But when you asked, should the government
[02:12:21.340 --> 02:12:22.980]   be the sole provider of healthcare,
[02:12:22.980 --> 02:12:26.300]   it dropped to like 26%, dropped 50 points.
[02:12:26.300 --> 02:12:28.060]   And you could see it was both asking questions
[02:12:28.060 --> 02:12:29.980]   about single payer, but the way that it was asked
[02:12:29.980 --> 02:12:31.680]   was so different that even if you all,
[02:12:31.680 --> 02:12:33.080]   looks like there's consensus,
[02:12:33.080 --> 02:12:34.480]   there's not nearly as much consensus
[02:12:34.480 --> 02:12:36.660]   as people think around certain ideas.
[02:12:36.660 --> 02:12:37.500]   Yeah, go, we can argue any political--
[02:12:37.500 --> 02:12:40.920]   - You're right, you're right, you're right, you're right.
[02:12:40.920 --> 02:12:44.560]   That polls, the way you ask the polls really matters.
[02:12:44.560 --> 02:12:47.440]   When you ask, should the government be in charge of a thing,
[02:12:47.440 --> 02:12:50.360]   that also biases the answer, right?
[02:12:50.360 --> 02:12:54.040]   Like, because there's such a negative experience
[02:12:54.040 --> 02:12:57.160]   with government creating a .gov site that runs the thing.
[02:12:57.160 --> 02:12:58.500]   But sometimes.
[02:12:58.500 --> 02:12:59.340]   - Sometimes.
[02:12:59.340 --> 02:13:02.580]   I think if you dig in, if you have a one hour conversation
[02:13:02.580 --> 02:13:04.240]   with each individual citizen,
[02:13:04.240 --> 02:13:05.200]   - Sure.
[02:13:05.200 --> 02:13:07.060]   - I think you will understand that yes,
[02:13:07.060 --> 02:13:09.360]   there is support for socialized medicine.
[02:13:09.360 --> 02:13:10.460]   Like it's not--
[02:13:10.460 --> 02:13:12.660]   - The argument has to be made though, yeah.
[02:13:12.660 --> 02:13:14.060]   - What do you mean, the argument has to be made?
[02:13:14.060 --> 02:13:15.520]   - Like if you just ask a conservative,
[02:13:15.520 --> 02:13:16.620]   like what about single payer?
[02:13:16.620 --> 02:13:17.540]   They're gonna tell you no.
[02:13:17.540 --> 02:13:19.260]   You might be able to build up to an argument for it,
[02:13:19.260 --> 02:13:20.660]   but you're gonna have to make the case for it.
[02:13:20.660 --> 02:13:23.280]   - No, but I thought we're talking about
[02:13:23.280 --> 02:13:26.380]   the feeling deep inside your mind and heart,
[02:13:26.380 --> 02:13:28.300]   does the government represent that?
[02:13:28.300 --> 02:13:29.140]   - Oh.
[02:13:29.140 --> 02:13:31.260]   - So it's not like some shallow,
[02:13:31.260 --> 02:13:34.300]   surface layer public opinion.
[02:13:34.300 --> 02:13:36.940]   Does the government effectively represent
[02:13:36.940 --> 02:13:38.760]   what the people want?
[02:13:38.760 --> 02:13:41.940]   Not a shallow survey, but deeply what they want.
[02:13:41.940 --> 02:13:43.340]   I'm not actually that familiar
[02:13:43.340 --> 02:13:45.100]   with the debates over healthcare,
[02:13:45.100 --> 02:13:47.300]   but let's maybe look at an easier one.
[02:13:47.300 --> 02:13:48.140]   - Sure.
[02:13:48.140 --> 02:13:50.420]   - Maybe you'll say it's harder, war.
[02:13:50.420 --> 02:13:52.460]   - War is a really good example where the government
[02:13:52.460 --> 02:13:55.060]   was very responsive, I think, to the people.
[02:13:55.060 --> 02:13:55.900]   - You think so?
[02:13:55.900 --> 02:13:58.420]   - So Iraq, Afghanistan,
[02:13:58.420 --> 02:14:01.980]   the government didn't manipulate public opinion.
[02:14:01.980 --> 02:14:04.340]   - There's an argument to be made that they did
[02:14:04.340 --> 02:14:06.180]   in terms of like WMD and everything,
[02:14:06.180 --> 02:14:09.500]   but after 9/11, were you in the United States after 9/11?
[02:14:09.500 --> 02:14:11.180]   After 9/11, I legitimately--
[02:14:11.180 --> 02:14:12.460]   - That seems accusatory.
[02:14:12.460 --> 02:14:13.860]   Like where were you on 9/11?
[02:14:13.860 --> 02:14:15.460]   (laughing)
[02:14:15.460 --> 02:14:16.300]   - Just checking, okay?
[02:14:16.300 --> 02:14:17.540]   - All right, cool.
[02:14:17.540 --> 02:14:20.220]   I have evidence and witnesses.
[02:14:20.220 --> 02:14:21.060]   No, okay, all right.
[02:14:21.060 --> 02:14:22.820]   I'm very defensive right now.
[02:14:22.820 --> 02:14:23.780]   It's very strange.
[02:14:23.780 --> 02:14:25.420]   Look into it.
[02:14:25.420 --> 02:14:26.260]   - Al Jones.
[02:14:26.260 --> 02:14:27.540]   - Yeah, but I think after 9/11,
[02:14:27.540 --> 02:14:30.980]   we could have gone to war with any country in the world.
[02:14:30.980 --> 02:14:33.900]   We were ready because all of America was like, oh my God,
[02:14:33.900 --> 02:14:35.180]   and they pointed to Iraq,
[02:14:35.180 --> 02:14:37.800]   and the reasons for the WMDs was kind of dumb,
[02:14:37.800 --> 02:14:39.940]   but I don't think we even needed WMDs to go to Iraq.
[02:14:39.940 --> 02:14:41.700]   We could have just said Saddam Hussein
[02:14:41.700 --> 02:14:45.140]   was giving medical aid to Taliban, Al-Qaeda, Iraq, let's go,
[02:14:45.140 --> 02:14:46.620]   and we would have gone for it.
[02:14:46.620 --> 02:14:50.140]   But post-Iraq, Iraq was for a while popular
[02:14:50.140 --> 02:14:52.060]   and then became obviously deeply unpopular,
[02:14:52.060 --> 02:14:53.300]   Iraq and Afghanistan,
[02:14:53.300 --> 02:14:54.740]   and I think you could see that influence
[02:14:54.740 --> 02:14:56.700]   in other foreign policy that the United States had.
[02:14:56.700 --> 02:14:59.420]   For instance, we opted more towards drone warfare
[02:14:59.420 --> 02:15:01.900]   than troops on the ground for places like Yemen.
[02:15:01.900 --> 02:15:04.180]   We opted more towards sending money and help
[02:15:04.180 --> 02:15:06.660]   instead of boots on the ground for places like Syria,
[02:15:06.660 --> 02:15:08.860]   and I think that a lot of that was kind of in response
[02:15:08.860 --> 02:15:11.380]   to how unpopular the Iraq stuff had became.
[02:15:11.380 --> 02:15:13.220]   And when you looked at a lot of elections afterwards,
[02:15:13.220 --> 02:15:14.820]   even for Obama,
[02:15:14.820 --> 02:15:17.200]   one of the defining characteristics of a lot of campaigns
[02:15:17.200 --> 02:15:19.080]   were like, I'm gonna close Guantanamo Bay,
[02:15:19.080 --> 02:15:21.420]   I'm gonna get us out of foreign wars, even up to Trump.
[02:15:21.420 --> 02:15:23.340]   I'm going into, I'm not gonna stop
[02:15:23.340 --> 02:15:25.060]   doing all this weird stuff in the Middle East.
[02:15:25.060 --> 02:15:27.060]   - But they didn't still withdraw from Afghanistan.
[02:15:27.060 --> 02:15:29.420]   - They didn't withdraw, but they definitely tapered off
[02:15:29.420 --> 02:15:31.940]   and weren't as aggressively pushing those types of conflicts
[02:15:31.940 --> 02:15:33.020]   'cause they knew it was unpopular.
[02:15:33.020 --> 02:15:36.460]   - But I think if you also consider perfect information
[02:15:36.460 --> 02:15:40.100]   or good information, if you ask a lot of people,
[02:15:40.100 --> 02:15:45.980]   are you okay spending this amount of money for this purpose,
[02:15:45.980 --> 02:15:48.420]   so a military conflict in Iraq and Afghanistan,
[02:15:48.420 --> 02:15:51.500]   I think almost from the very beginning, they would say no.
[02:15:51.500 --> 02:15:52.700]   - After 9/11, I feel like--
[02:15:52.700 --> 02:15:54.700]   - Maybe like a few days after 9/11.
[02:15:54.700 --> 02:15:56.900]   - I remember Freedom Prize.
[02:15:56.900 --> 02:15:58.220]   We were so mad at--
[02:15:58.220 --> 02:15:59.820]   - There's some memes and so on, yes.
[02:15:59.820 --> 02:16:02.960]   But the nature of the public support for the war,
[02:16:02.960 --> 02:16:06.660]   was there public support in 2003,
[02:16:06.660 --> 02:16:08.940]   which is when the invasion happened?
[02:16:08.940 --> 02:16:10.300]   - I feel like initially there was a lot.
[02:16:10.300 --> 02:16:11.120]   I remember seeing it on,
[02:16:11.120 --> 02:16:12.540]   but then I also lived in a Republican household
[02:16:12.540 --> 02:16:14.100]   and I was not very media savvy at the time.
[02:16:14.100 --> 02:16:14.940]   So my parents--
[02:16:14.940 --> 02:16:16.260]   - And I don't know if the nature of that public support
[02:16:16.260 --> 02:16:19.400]   had to do with WMDs or with 9/11.
[02:16:19.400 --> 02:16:20.240]   'Cause the weird--
[02:16:20.240 --> 02:16:21.660]   - It became about WMDs.
[02:16:21.660 --> 02:16:23.060]   - But I wonder what is the,
[02:16:23.060 --> 02:16:26.360]   if you were to poll people and let's say hypothetically,
[02:16:26.360 --> 02:16:29.300]   there was above 50% support for the war,
[02:16:29.300 --> 02:16:31.700]   what would be the nature of that support?
[02:16:31.700 --> 02:16:34.460]   And to what degree is the government
[02:16:34.460 --> 02:16:37.240]   actually representing the will of the people
[02:16:37.240 --> 02:16:41.020]   versus some complex mechanism
[02:16:41.020 --> 02:16:43.080]   like the military industrial complex
[02:16:43.080 --> 02:16:44.700]   is manipulating the narrative
[02:16:44.700 --> 02:16:47.240]   that's controlling public opinion?
[02:16:47.240 --> 02:16:51.380]   And then there's the media that gets a lot of attention
[02:16:51.380 --> 02:16:54.820]   by being divided in how they're shaping the narrative
[02:16:54.820 --> 02:16:56.900]   through the mechanism of division.
[02:16:56.900 --> 02:16:58.180]   So what--
[02:16:58.180 --> 02:16:59.900]   - There's a lot of complicated things out there.
[02:16:59.900 --> 02:17:02.040]   It's not just like the people and then the government.
[02:17:02.040 --> 02:17:03.700]   And that's, yeah, for sure I agree
[02:17:03.700 --> 02:17:05.580]   that there are gonna be different elements at play.
[02:17:05.580 --> 02:17:10.420]   - And how much of those elements that lead us astray
[02:17:10.420 --> 02:17:12.700]   can be attributed to the largeness
[02:17:12.700 --> 02:17:16.660]   of the different systems and the different institutions,
[02:17:16.660 --> 02:17:21.180]   like the media institutions and government.
[02:17:21.180 --> 02:17:23.700]   The institutions that have a monopoly on violence,
[02:17:23.700 --> 02:17:24.780]   let's put it this way,
[02:17:24.780 --> 02:17:26.940]   which is one way to define government.
[02:17:26.940 --> 02:17:28.860]   - Sure, it's complicated.
[02:17:28.860 --> 02:17:30.980]   There's definitely gonna be different institutions at play.
[02:17:30.980 --> 02:17:32.580]   But I think that like,
[02:17:32.580 --> 02:17:34.660]   all I would say is like in reverence to my original point,
[02:17:34.660 --> 02:17:37.300]   when there becomes like broad consensus around a thing,
[02:17:37.300 --> 02:17:38.780]   I think the government will usually follow.
[02:17:38.780 --> 02:17:39.620]   It's not gonna fight.
[02:17:39.620 --> 02:17:41.980]   It's gonna follow more often than not.
[02:17:41.980 --> 02:17:44.180]   But I think that a lot of times I think Americans
[02:17:44.180 --> 02:17:46.660]   think that there's more consensus around certain issues
[02:17:46.660 --> 02:17:48.100]   than there actually are.
[02:17:48.100 --> 02:17:48.940]   So like a really good example,
[02:17:48.940 --> 02:17:50.340]   we're on that war point too.
[02:17:51.340 --> 02:17:55.420]   What caused like the lowest dip in Biden's approval rating?
[02:17:55.420 --> 02:17:56.460]   I'm pretty sure it was right after
[02:17:56.460 --> 02:17:58.060]   we pulled out of Afghanistan,
[02:17:58.060 --> 02:18:01.580]   which I think if I would have asked people like a year before
[02:18:01.580 --> 02:18:04.780]   like, let's assume that we could pull out of Afghanistan.
[02:18:04.780 --> 02:18:06.580]   The government's probably gonna collapse after we leave
[02:18:06.580 --> 02:18:08.020]   because they just don't have the will to fight.
[02:18:08.020 --> 02:18:09.220]   They don't have the support, they don't, whatever.
[02:18:09.220 --> 02:18:10.180]   That's just not gonna work.
[02:18:10.180 --> 02:18:12.100]   But like no Americans are gonna die.
[02:18:12.100 --> 02:18:12.940]   There might be a couple of other people,
[02:18:12.940 --> 02:18:13.780]   but like no Americans are gonna die
[02:18:13.780 --> 02:18:14.620]   when we get out of Afghanistan.
[02:18:14.620 --> 02:18:15.460]   Would you support that?
[02:18:15.460 --> 02:18:17.100]   I think broadly speaking,
[02:18:17.100 --> 02:18:19.900]   I think like more than 60 or 70% of Americans are like,
[02:18:19.900 --> 02:18:21.260]   "Yeah, that would be fine."
[02:18:21.260 --> 02:18:22.780]   But then when it actually plays on TV,
[02:18:22.780 --> 02:18:24.260]   when we see the people hanging onto the planes,
[02:18:24.260 --> 02:18:26.100]   when we see like helicopter embassies,
[02:18:26.100 --> 02:18:27.460]   some of the courts and politicians,
[02:18:27.460 --> 02:18:29.180]   well now it's like, "Oh my God, this was horrible
[02:18:29.180 --> 02:18:30.860]   and it was so botched and it was so like,
[02:18:30.860 --> 02:18:31.700]   it could have gone so much better."
[02:18:31.700 --> 02:18:32.740]   It's like, "Well, could it have gone better?"
[02:18:32.740 --> 02:18:34.100]   Like maybe, maybe not.
[02:18:34.100 --> 02:18:36.540]   But I mean, it seems like you can have consensus
[02:18:36.540 --> 02:18:37.580]   around a certain opinion,
[02:18:37.580 --> 02:18:39.580]   but the way that things play out
[02:18:39.580 --> 02:18:41.060]   and the way that people actually feel,
[02:18:41.060 --> 02:18:43.260]   it's actually way, way, way more complicated
[02:18:43.260 --> 02:18:46.460]   and there's not usually this broad consensus opinion.
[02:18:46.460 --> 02:18:47.300]   All right, yeah, go ahead.
[02:18:47.300 --> 02:18:48.340]   - I'd like to believe that.
[02:18:48.340 --> 02:18:52.100]   I mean, just to lay my cards on the table,
[02:18:52.100 --> 02:18:58.900]   I have faith in the power of effective government.
[02:18:58.900 --> 02:19:05.100]   I just have a lot of concern about what happens
[02:19:05.100 --> 02:19:07.540]   as institutions grow in size.
[02:19:07.540 --> 02:19:08.380]   - For sure.
[02:19:08.380 --> 02:19:09.420]   - And I just have a lot of worry
[02:19:09.420 --> 02:19:13.420]   about the natural corrupting influence on the individuals
[02:19:13.420 --> 02:19:15.660]   and on the system as a whole,
[02:19:15.660 --> 02:19:17.820]   like the boys club nature of it.
[02:19:17.820 --> 02:19:19.420]   I don't know, there must be a better term,
[02:19:19.420 --> 02:19:22.420]   but basically they agree to the game
[02:19:22.420 --> 02:19:23.460]   and they play the game
[02:19:23.460 --> 02:19:27.940]   and there's a generational aspect, momentum to the game.
[02:19:27.940 --> 02:19:30.300]   And they more and more stop being responsive
[02:19:30.300 --> 02:19:32.860]   to the people that they represent.
[02:19:32.860 --> 02:19:35.060]   I just feel like there is that mechanism.
[02:19:35.060 --> 02:19:37.740]   And I think the nice thing,
[02:19:37.740 --> 02:19:40.340]   democracy elections are resistance
[02:19:40.340 --> 02:19:41.980]   to that natural human mechanism.
[02:19:41.980 --> 02:19:44.220]   Also the balances of power
[02:19:44.220 --> 02:19:46.020]   is a resistance to that mechanism.
[02:19:46.020 --> 02:19:48.740]   In some ways, the media that reveals the bullshit
[02:19:48.740 --> 02:19:52.300]   of politicians is also a resistance to that mechanism.
[02:19:52.300 --> 02:19:54.780]   It's hard to be full of shit as a politician
[02:19:54.780 --> 02:19:56.620]   'cause people will try to catch you on it.
[02:19:56.620 --> 02:20:00.940]   So there's a honesty method there that keeps you honest.
[02:20:00.940 --> 02:20:04.480]   It's to some degree, but it still feels like,
[02:20:04.480 --> 02:20:10.380]   it still feels like politicians are gonna politician.
[02:20:10.380 --> 02:20:12.020]   - Yeah, they definitely play their games.
[02:20:12.020 --> 02:20:13.300]   That is true.
[02:20:13.300 --> 02:20:15.620]   There's probably always gonna be that meta narrative
[02:20:15.620 --> 02:20:18.500]   over like governance that just develops
[02:20:18.500 --> 02:20:20.860]   as like you have to form relationships and play games
[02:20:20.860 --> 02:20:22.980]   to get legislation passed and everything.
[02:20:22.980 --> 02:20:24.860]   The only reason why I don't like it
[02:20:24.860 --> 02:20:27.240]   when people attack institutions is because one,
[02:20:27.240 --> 02:20:29.860]   institutions are incredibly important, arguably paramount.
[02:20:29.860 --> 02:20:32.020]   No, they are to keeping society running.
[02:20:32.020 --> 02:20:34.420]   And two, I think sometimes when we shift the blame
[02:20:34.420 --> 02:20:36.240]   onto institutions too much,
[02:20:36.240 --> 02:20:38.540]   I think that we lose sight of what the real problems are.
[02:20:38.540 --> 02:20:40.860]   So for instance, in the United States today,
[02:20:40.860 --> 02:20:42.540]   people might be very critical of the government
[02:20:42.540 --> 02:20:44.060]   not getting much done,
[02:20:44.060 --> 02:20:45.780]   but then everybody turns their eyes to the government
[02:20:45.780 --> 02:20:47.100]   for being ineffective.
[02:20:47.100 --> 02:20:48.860]   But what I would argue is I would say the government
[02:20:48.860 --> 02:20:51.060]   is actually incredibly effective
[02:20:51.060 --> 02:20:53.180]   and it's showcasing the will of the American people
[02:20:53.180 --> 02:20:54.140]   really well right now,
[02:20:54.140 --> 02:20:56.460]   which is we are historically more divided
[02:20:56.460 --> 02:20:57.900]   than we have ever been.
[02:20:57.900 --> 02:20:59.360]   And if I were to just look at the people
[02:20:59.360 --> 02:21:01.940]   and I were to say, we have a historic divide
[02:21:01.940 --> 02:21:04.220]   that is getting like rapidly blown apart
[02:21:04.220 --> 02:21:06.180]   by things like the internet and the media, right?
[02:21:06.180 --> 02:21:07.580]   If that exists, well, what would I expect
[02:21:07.580 --> 02:21:08.700]   that government to look like?
[02:21:08.700 --> 02:21:09.540]   I wouldn't expect the government
[02:21:09.540 --> 02:21:10.620]   to be governing very effective.
[02:21:10.620 --> 02:21:12.300]   I would expect that government to show
[02:21:12.300 --> 02:21:14.420]   that legitimate divide in people.
[02:21:14.420 --> 02:21:15.740]   - Do you think that divide,
[02:21:15.740 --> 02:21:18.140]   we have a perception of a large divide
[02:21:18.140 --> 02:21:19.940]   between left and right.
[02:21:19.940 --> 02:21:22.220]   Do you think that's a real divide that's in this country?
[02:21:22.220 --> 02:21:23.140]   - Narrow the language.
[02:21:23.140 --> 02:21:25.420]   What do you mean by real divide?
[02:21:25.420 --> 02:21:28.420]   - Do you think there is that divide in ideology,
[02:21:28.420 --> 02:21:29.500]   that there's a large number of people
[02:21:29.500 --> 02:21:30.980]   that believe a certain set of policies
[02:21:30.980 --> 02:21:32.940]   and the different set of policies?
[02:21:32.940 --> 02:21:35.660]   Or is it just the perception on Twitter?
[02:21:35.660 --> 02:21:37.660]   - No, I think there is a large divide in terms of belief.
[02:21:37.660 --> 02:21:39.660]   I don't think there's very much divide between any people
[02:21:39.660 --> 02:21:40.860]   in terms of like what they,
[02:21:40.860 --> 02:21:43.140]   like on the most fundamental levels want
[02:21:43.140 --> 02:21:44.500]   in terms of like human beings.
[02:21:44.500 --> 02:21:46.860]   But in terms of like Democrat versus Republican right now,
[02:21:46.860 --> 02:21:48.460]   I think there is a huge divide
[02:21:48.460 --> 02:21:50.460]   in terms of the direction they wanna see the country go
[02:21:50.460 --> 02:21:51.860]   and what they believe really
[02:21:51.860 --> 02:21:53.500]   and what they even believe is reality, right?
[02:21:53.500 --> 02:21:55.940]   Unfortunately, that's where we've gotten to.
[02:21:55.940 --> 02:21:57.380]   - Can I just speak about the mechanism
[02:21:57.380 --> 02:21:58.980]   of the left and right here,
[02:21:58.980 --> 02:22:01.780]   maybe on the mimetic rivalry aspect?
[02:22:01.780 --> 02:22:03.740]   Is there some aspect to the left
[02:22:03.740 --> 02:22:06.180]   on which you're a part of that attacks their own
[02:22:06.180 --> 02:22:10.560]   for ideological impurity more than the right does?
[02:22:10.560 --> 02:22:12.780]   Is it the bigotry of small differences?
[02:22:12.780 --> 02:22:17.260]   There's a concept where when you're near somebody
[02:22:17.260 --> 02:22:18.620]   who is very slightly different than you,
[02:22:18.620 --> 02:22:19.620]   you wanna destroy it.
[02:22:19.620 --> 02:22:20.460]   But when you're with somebody
[02:22:20.460 --> 02:22:22.420]   that's way different than you, you don't.
[02:22:22.420 --> 02:22:24.460]   I think the left does it,
[02:22:24.460 --> 02:22:25.620]   but I think the right does it too.
[02:22:25.620 --> 02:22:27.200]   I didn't realize it until I started dipping more
[02:22:27.200 --> 02:22:29.420]   into conservative communities, but oh my God,
[02:22:29.420 --> 02:22:30.660]   the people from the Daily Wire
[02:22:30.660 --> 02:22:33.620]   and the people from Turning Point and the America First,
[02:22:33.620 --> 02:22:36.100]   but all these different groups of people hate each other
[02:22:36.100 --> 02:22:37.380]   and they fight each other so much.
[02:22:37.380 --> 02:22:39.540]   They hire and fire sometimes employees.
[02:22:39.540 --> 02:22:41.720]   They talk smack about each other.
[02:22:41.720 --> 02:22:42.920]   I think there's a lot of political division
[02:22:42.920 --> 02:22:43.760]   between both sides.
[02:22:43.760 --> 02:22:45.840]   I think that the left just kind of gets highlighted more
[02:22:45.840 --> 02:22:46.760]   because it's like the internet
[02:22:46.760 --> 02:22:47.920]   and a lot of the internet spaces
[02:22:47.920 --> 02:22:48.960]   have a lot of left-leaning people.
[02:22:48.960 --> 02:22:50.640]   So you see like the crazy communists
[02:22:50.640 --> 02:22:52.080]   and the crazy progressives
[02:22:52.080 --> 02:22:53.840]   and the crazy center-left liberals
[02:22:53.840 --> 02:22:54.960]   and the crazy blah, blah, blah.
[02:22:54.960 --> 02:22:56.240]   Whereas like a lot of the right-leaning people
[02:22:56.240 --> 02:22:58.160]   have kind of been pushed off of the main areas
[02:22:58.160 --> 02:22:59.520]   of the internet now.
[02:22:59.520 --> 02:23:00.360]   - Interesting.
[02:23:00.360 --> 02:23:04.000]   My sense was that it's hard to exist on the center-left,
[02:23:04.000 --> 02:23:07.600]   but maybe because I just don't have the full spectrum view
[02:23:07.600 --> 02:23:08.600]   of the political divide.
[02:23:08.600 --> 02:23:10.660]   It felt like center-left is a difficult position
[02:23:10.660 --> 02:23:11.500]   to occupy.
[02:23:11.500 --> 02:23:12.820]   - Yeah, I would definitely say so, yeah.
[02:23:12.820 --> 02:23:15.420]   - I don't know if it's that difficult to be center-right.
[02:23:15.420 --> 02:23:17.180]   - It's very difficult to be center-right.
[02:23:17.180 --> 02:23:19.460]   I think actually maybe even more difficult
[02:23:19.460 --> 02:23:21.180]   because a center-right person might be somebody
[02:23:21.180 --> 02:23:24.060]   who's like conservative, but not a fan of Trump.
[02:23:24.060 --> 02:23:25.940]   And you're like over.
[02:23:25.940 --> 02:23:27.220]   Like look at like Liz Cheney, right?
[02:23:27.220 --> 02:23:28.780]   You've had politicians that are just like,
[02:23:28.780 --> 02:23:30.540]   they didn't back the Trump stuff and now they're gone.
[02:23:30.540 --> 02:23:32.020]   Or you might be like center-right,
[02:23:32.020 --> 02:23:33.900]   but like you don't think the election was stolen.
[02:23:33.900 --> 02:23:36.180]   And now you're like half the Republican Party
[02:23:36.180 --> 02:23:38.380]   is looking at you like you're crazy, you know?
[02:23:38.380 --> 02:23:39.440]   - That's true, that's true.
[02:23:39.440 --> 02:23:42.920]   I think there's a Ben Shapiro, who I'm talking with,
[02:23:42.920 --> 02:23:46.360]   I think he publicly spoke against Trump, right?
[02:23:46.360 --> 02:23:47.920]   - He did initially, but I felt like he softened
[02:23:47.920 --> 02:23:49.760]   his language up on him pretty significantly.
[02:23:49.760 --> 02:23:51.960]   - So there's a significant pressure to kind of
[02:23:51.960 --> 02:23:53.880]   cop out a certain kind of messaging.
[02:23:53.880 --> 02:23:55.960]   - Which the whole Republican Party is feeling right now.
[02:23:55.960 --> 02:23:59.280]   Geez, two years from now, that election is gonna be insane.
[02:23:59.280 --> 02:24:00.200]   - It's just hard, okay.
[02:24:00.200 --> 02:24:02.360]   So to generalize, it's hard to be in the center,
[02:24:02.360 --> 02:24:03.200]   it feels like.
[02:24:03.200 --> 02:24:04.020]   - For sure.
[02:24:04.020 --> 02:24:06.840]   - To center and then like do like a random walk
[02:24:08.000 --> 02:24:10.400]   among the policies around that.
[02:24:10.400 --> 02:24:12.120]   I don't know what that mechanism is.
[02:24:12.120 --> 02:24:15.880]   I mean, it makes people like me not feel good
[02:24:15.880 --> 02:24:17.360]   being in the center.
[02:24:17.360 --> 02:24:19.480]   It seems like people are just not nice
[02:24:19.480 --> 02:24:21.000]   to people in the center.
[02:24:21.000 --> 02:24:24.960]   Like the public, the Twitter machine is not nice
[02:24:24.960 --> 02:24:27.760]   to the people who are open-minded in the center.
[02:24:27.760 --> 02:24:29.420]   Is there some truth to that?
[02:24:29.420 --> 02:24:30.560]   - Two reasons for that.
[02:24:30.560 --> 02:24:32.080]   One is because I think a lot of people
[02:24:32.080 --> 02:24:33.440]   that market themselves as center
[02:24:33.440 --> 02:24:35.420]   are legitimately spineless cowards
[02:24:35.420 --> 02:24:36.880]   and deserve to be called out.
[02:24:37.880 --> 02:24:40.720]   I've never killed a man, but today might be my first.
[02:24:40.720 --> 02:24:41.560]   - Oh no.
[02:24:41.560 --> 02:24:45.520]   - Like I told you, I'll take over your stream.
[02:24:45.520 --> 02:24:47.280]   - With AI, we'll see.
[02:24:47.280 --> 02:24:48.960]   Is that guy gonna be streaming in the background?
[02:24:48.960 --> 02:24:49.800]   - Hey fellas.
[02:24:49.800 --> 02:24:53.720]   - Okay, gotcha, gotcha, gotcha, gotcha.
[02:24:53.720 --> 02:24:55.160]   Lots of gotchas, lots of gotchas.
[02:24:55.160 --> 02:24:56.480]   Okay, gotcha.
[02:24:56.480 --> 02:24:57.720]   - And decrease the amount,
[02:24:57.720 --> 02:25:01.200]   which already is a pretty low level of emotion.
[02:25:01.200 --> 02:25:02.700]   Just decrease it completely.
[02:25:02.700 --> 02:25:05.960]   When people are screaming at you and accusing stuff,
[02:25:05.960 --> 02:25:07.320]   just remain calm.
[02:25:07.320 --> 02:25:08.160]   - Absolutely.
[02:25:08.160 --> 02:25:08.980]   - Emotionless.
[02:25:08.980 --> 02:25:10.000]   - The gaslighter strategy.
[02:25:10.000 --> 02:25:10.840]   - Yeah.
[02:25:10.840 --> 02:25:12.400]   Okay, so what were we talking about?
[02:25:12.400 --> 02:25:14.600]   So I don't--
[02:25:14.600 --> 02:25:16.720]   - I don't even, I don't ever identify as center anything
[02:25:16.720 --> 02:25:18.360]   because it's got such a bad reputation because--
[02:25:18.360 --> 02:25:22.040]   - Fuck that, I stand center with a spine.
[02:25:22.040 --> 02:25:23.320]   It's called being open-minded.
[02:25:23.320 --> 02:25:26.280]   And it's not center left and right, those are just labels.
[02:25:26.280 --> 02:25:28.240]   - Here's a really good quote my mom said to me
[02:25:28.240 --> 02:25:29.080]   when I was really young.
[02:25:29.080 --> 02:25:31.560]   She said, "Stevie, don't ever let your mind be so open
[02:25:31.560 --> 02:25:32.960]   "that your brain falls out."
[02:25:32.960 --> 02:25:34.800]   And that's what I find that a lot of center people do.
[02:25:34.800 --> 02:25:36.920]   - That's not what she told me last night.
[02:25:36.920 --> 02:25:38.080]   Why are you like this?
[02:25:38.080 --> 02:25:39.480]   (laughing)
[02:25:39.480 --> 02:25:40.680]   - I'm sorry, man.
[02:25:40.680 --> 02:25:42.560]   - Okay, I'm glad I can bring that.
[02:25:42.560 --> 02:25:43.760]   I'm glad you feel like this is a safe space.
[02:25:43.760 --> 02:25:45.360]   Like I said, people, non-judgmental.
[02:25:45.360 --> 02:25:46.640]   If you wanna talk about fucking my mom,
[02:25:46.640 --> 02:25:48.040]   you know what, you're totally within your rights.
[02:25:48.040 --> 02:25:49.400]   - I didn't say that, you said that.
[02:25:49.400 --> 02:25:50.960]   - That's totally great, I support that.
[02:25:50.960 --> 02:25:52.240]   She's a beautiful woman.
[02:25:52.240 --> 02:25:53.580]   Her husband probably wouldn't be too happy about it,
[02:25:53.580 --> 02:25:54.560]   but you know.
[02:25:54.560 --> 02:25:56.520]   - I didn't say there was any sexual relations.
[02:25:56.520 --> 02:25:59.120]   It was just that having a conversation with her.
[02:25:59.120 --> 02:26:02.040]   You projected that, that says more about you than me.
[02:26:02.040 --> 02:26:04.480]   Anyway, go ahead about spineless center.
[02:26:04.480 --> 02:26:05.720]   - Spineless center.
[02:26:05.720 --> 02:26:09.040]   There is some aspect to that which is amorphous.
[02:26:09.040 --> 02:26:13.080]   To me, center means you think freely
[02:26:13.080 --> 02:26:16.320]   about each individual policy without being stuck to a--
[02:26:16.320 --> 02:26:18.240]   - Some ideal, yeah, but a lot of people don't do that.
[02:26:18.240 --> 02:26:19.320]   They call themselves centrist,
[02:26:19.320 --> 02:26:21.020]   but then they're anti-establishment,
[02:26:21.020 --> 02:26:22.320]   essentially, on everything.
[02:26:22.320 --> 02:26:25.520]   I don't know your position on the vaccines or anything,
[02:26:25.520 --> 02:26:27.400]   but I met a lot of free and open thinkers
[02:26:27.400 --> 02:26:29.640]   who were like, you know what, I am open to everything,
[02:26:29.640 --> 02:26:31.040]   and it's an experimental vaccine,
[02:26:31.040 --> 02:26:33.160]   and I'm gonna eat hydroxychloroquine and ivermectin
[02:26:33.160 --> 02:26:34.360]   because that's what the institutions
[02:26:34.360 --> 02:26:35.560]   are telling me not to take,
[02:26:35.560 --> 02:26:37.960]   and I think Fauci got too much money from that company,
[02:26:37.960 --> 02:26:39.560]   and these are, but I'm an open thinker,
[02:26:39.560 --> 02:26:41.160]   and what open thinker becomes--
[02:26:41.160 --> 02:26:42.000]   - I'm at MIT.
[02:26:42.000 --> 02:26:44.640]   What do you think my position on vaccines is exactly?
[02:26:44.640 --> 02:26:46.200]   - I hear a lot of crazy things from a lot of people, okay?
[02:26:46.200 --> 02:26:48.240]   You might be from MIT, but I know you from the internet,
[02:26:48.240 --> 02:26:50.560]   okay, and people from the internet are weird and crazy, so.
[02:26:50.560 --> 02:26:51.880]   - Yeah. (laughs)
[02:26:51.880 --> 02:26:53.640]   Well, I-- - Who knows?
[02:26:53.640 --> 02:26:55.000]   - I don't like arrogance,
[02:26:55.000 --> 02:26:58.480]   and I have criticized scientists during COVID,
[02:26:58.480 --> 02:27:00.200]   a lot of people, but scientists included,
[02:27:00.200 --> 02:27:01.960]   having arrogance. - Which is fair.
[02:27:01.960 --> 02:27:03.160]   - But-- - And I think there's
[02:27:03.160 --> 02:27:05.400]   a lot of good criticism to be made
[02:27:05.400 --> 02:27:08.520]   of different scientific and medical establishments
[02:27:08.520 --> 02:27:10.460]   over a lot of stuff,
[02:27:10.460 --> 02:27:12.560]   but nobody can make those good criticisms
[02:27:12.560 --> 02:27:14.240]   because they're too obsessed
[02:27:14.240 --> 02:27:17.360]   over just trying to have the anti-establishment answer,
[02:27:17.360 --> 02:27:19.440]   and that is what is upsetting me the most.
[02:27:19.440 --> 02:27:22.160]   I think there are good conversations to be had
[02:27:22.160 --> 02:27:24.280]   about a lot of stuff related to
[02:27:24.280 --> 02:27:26.120]   how we handled the coronavirus.
[02:27:26.120 --> 02:27:27.240]   Were lockdowns effective?
[02:27:27.240 --> 02:27:30.920]   Was there enough data to support the huge measures we took?
[02:27:30.920 --> 02:27:33.040]   Why didn't we have the option to show,
[02:27:33.040 --> 02:27:34.440]   I was infected a month ago,
[02:27:34.440 --> 02:27:35.720]   why do I need to be vaccinated?
[02:27:35.720 --> 02:27:37.320]   Why wasn't that option ever a thing in the United States?
[02:27:37.320 --> 02:27:38.440]   I don't think it was.
[02:27:38.440 --> 02:27:41.120]   There are really good questions to be asked there,
[02:27:41.120 --> 02:27:42.800]   but all the people asking the questions
[02:27:42.800 --> 02:27:44.320]   are also trying to tell you that ivermectin
[02:27:44.320 --> 02:27:46.600]   and monoclonal antibodies are the way to go for everything,
[02:27:46.600 --> 02:27:47.840]   and the vaccine is evil,
[02:27:47.840 --> 02:27:49.600]   and it's gonna turn you gay like the frogs,
[02:27:49.600 --> 02:27:51.400]   and it's like, Jesus,
[02:27:51.400 --> 02:27:54.240]   there's no place to reasonably criticize from
[02:27:54.240 --> 02:27:55.940]   because all of the people that are criticizing
[02:27:55.940 --> 02:27:57.360]   aren't doing it with an open mind,
[02:27:57.360 --> 02:27:59.800]   or they're not reading studies or doing anything.
[02:27:59.800 --> 02:28:01.060]   They're saying, "I do my own research,"
[02:28:01.060 --> 02:28:02.360]   which means they listened to
[02:28:02.360 --> 02:28:03.640]   whatever the last guy on Joe Rogan said,
[02:28:03.640 --> 02:28:05.040]   and now they are parroting that opinion 100%.
[02:28:05.040 --> 02:28:06.680]   - Easy now, easy now, bros.
[02:28:06.680 --> 02:28:08.200]   - The last guy on Joe Rogan, not Joe Rogan, okay.
[02:28:08.200 --> 02:28:09.800]   That Robert Malone guy on Joe Rogan
[02:28:09.800 --> 02:28:11.320]   got me real fired up. - That's one guest.
[02:28:11.320 --> 02:28:14.320]   - People see him as the father of mRNA technology.
[02:28:14.320 --> 02:28:16.080]   He published one paper, okay?
[02:28:16.080 --> 02:28:17.200]   - What do you mean people?
[02:28:17.200 --> 02:28:19.080]   Which people think that?
[02:28:19.080 --> 02:28:19.920]   - Joe Rogan fans.
[02:28:19.920 --> 02:28:21.400]   I run into these people.
[02:28:21.400 --> 02:28:22.220]   I start arguing with people,
[02:28:22.220 --> 02:28:23.060]   and they start saying to me, "Well, what about--"
[02:28:23.060 --> 02:28:26.560]   - I'm a Joe Rogan fan, and I appreciate the vaccine.
[02:28:26.560 --> 02:28:27.760]   - That's good, I'm glad you do.
[02:28:27.760 --> 02:28:28.600]   But there's definitely--
[02:28:28.600 --> 02:28:30.960]   - Sorry, but you said there's a type.
[02:28:30.960 --> 02:28:33.120]   What's the type of Joe Rogan fan?
[02:28:33.120 --> 02:28:34.880]   - Anti-establishment.
[02:28:34.880 --> 02:28:36.040]   - I think that's not Joe Rogan.
[02:28:36.040 --> 02:28:37.960]   That's a general public discourse.
[02:28:37.960 --> 02:28:40.680]   There's a default anti-establishment.
[02:28:40.680 --> 02:28:42.440]   On the right and the left,
[02:28:42.440 --> 02:28:45.160]   that's the default easy thing to go to.
[02:28:45.160 --> 02:28:46.360]   - I think Joe Rogan fans are definitely
[02:28:46.360 --> 02:28:48.280]   a certain type of anti-establishment, though.
[02:28:48.280 --> 02:28:50.280]   Like, I could guess the Joe Rogan fan.
[02:28:50.280 --> 02:28:52.240]   Like, if I were to do general population
[02:28:52.240 --> 02:28:53.080]   versus Joe Rogan fan,
[02:28:53.080 --> 02:28:55.640]   who do you think is more likely to be anti-vaccine?
[02:28:55.640 --> 02:28:57.280]   - Do you have data on this?
[02:28:57.280 --> 02:28:58.520]   Or are you just guessing? - You're gonna do that to me?
[02:28:58.520 --> 02:28:59.480]   - Yeah. - Just guessing.
[02:28:59.480 --> 02:29:01.720]   - Yeah, I think you are actually judging.
[02:29:01.720 --> 02:29:02.540]   - I am, yeah.
[02:29:02.540 --> 02:29:03.380]   - You're judging.
[02:29:03.380 --> 02:29:04.920]   'Cause I think you're also,
[02:29:04.920 --> 02:29:08.000]   the beautiful thing about podcasting,
[02:29:08.000 --> 02:29:09.520]   this could be similar to streaming,
[02:29:09.520 --> 02:29:13.000]   is there's a large number of people that just listen.
[02:29:13.000 --> 02:29:15.560]   Like, what does it mean to be a Joe Rogan fan?
[02:29:15.560 --> 02:29:16.600]   - I don't think you just listen.
[02:29:16.600 --> 02:29:19.360]   I think people listen and absorb the information.
[02:29:19.360 --> 02:29:21.640]   - I would say that the Joe Rogan fan base
[02:29:21.640 --> 02:29:24.600]   is as divided in the vaccine as the general public.
[02:29:24.600 --> 02:29:25.440]   - Gotcha.
[02:29:25.440 --> 02:29:26.800]   Man, I'm gonna look for polling data on that.
[02:29:26.800 --> 02:29:28.760]   I'm sure somebody's gotta have done it out there, but--
[02:29:28.760 --> 02:29:30.720]   - No, but you're basically revealing
[02:29:30.720 --> 02:29:31.760]   the fact they have no data.
[02:29:31.760 --> 02:29:33.200]   You're using your own judgment.
[02:29:33.200 --> 02:29:34.400]   - For sure.
[02:29:34.400 --> 02:29:35.880]   Based on how he's had conversations
[02:29:35.880 --> 02:29:37.720]   about his experience with the coronavirus,
[02:29:37.720 --> 02:29:39.760]   and then based on the guests that have come on
[02:29:39.760 --> 02:29:42.200]   that have talked and echoed a lot of anti-vax talking points
[02:29:42.200 --> 02:29:43.720]   and been completely unchallenged,
[02:29:43.720 --> 02:29:45.240]   and then based on statements he's made
[02:29:45.240 --> 02:29:47.960]   about myocarditis and the vaccine and everything as well.
[02:29:47.960 --> 02:29:50.840]   - So it's the level of challenge or not that he's doing.
[02:29:50.840 --> 02:29:52.560]   - Well, yeah, and then what his true positions are,
[02:29:52.560 --> 02:29:54.280]   and then the types of guests he typically chooses
[02:29:54.280 --> 02:29:56.080]   to bring on to talk about the vaccines, yeah.
[02:29:56.080 --> 02:29:58.300]   - Okay, but that represents somehow
[02:29:58.300 --> 02:30:01.720]   a deep anti-establishment feeling versus--
[02:30:01.720 --> 02:30:02.760]   - Versus just the vaccine.
[02:30:02.760 --> 02:30:04.600]   I mean, I've seen the vaccine and other things
[02:30:04.600 --> 02:30:07.640]   being a thing that broke people.
[02:30:07.640 --> 02:30:08.800]   They seem to-- - I think all the coronavirus,
[02:30:08.800 --> 02:30:12.080]   that whole one or two years broke a lot of people.
[02:30:12.080 --> 02:30:13.080]   - 'Cause there's a lot of emotion,
[02:30:13.080 --> 02:30:17.120]   and that emotion quickly solidified into an opinion
[02:30:17.120 --> 02:30:20.880]   that almost had nothing to do with thinking through
[02:30:20.880 --> 02:30:22.800]   and updating your knowledge and so on.
[02:30:22.800 --> 02:30:24.480]   You just made up your mind.
[02:30:24.480 --> 02:30:25.640]   - Yeah, but I think a lot of it comes
[02:30:25.640 --> 02:30:27.200]   from that anti-establishment place.
[02:30:27.200 --> 02:30:30.340]   The vaccine represents the ultimate of establishment.
[02:30:30.340 --> 02:30:33.080]   It was a huge private company
[02:30:33.080 --> 02:30:36.200]   backed by a huge public government,
[02:30:36.200 --> 02:30:40.080]   and there's Fauci, and there's Biden, and there's Pfizer,
[02:30:40.080 --> 02:30:42.480]   and there's all these countries locking us up in our homes,
[02:30:42.480 --> 02:30:43.560]   telling us to do a thing.
[02:30:43.560 --> 02:30:47.280]   The vaccine was the ultimate submission tool
[02:30:47.280 --> 02:30:48.800]   to show you that the government owns you.
[02:30:48.800 --> 02:30:51.200]   Not only do you have to get injected once, it's a series,
[02:30:51.200 --> 02:30:52.480]   and then you gotta get boosters,
[02:30:52.480 --> 02:30:54.040]   and it's like they're trying to keep you under their thumb,
[02:30:54.040 --> 02:30:55.800]   and that's the control.
[02:30:55.800 --> 02:30:56.760]   I feel like that vaccine
[02:30:56.760 --> 02:30:58.440]   became the ultimate rallying cry between,
[02:30:58.440 --> 02:30:59.920]   do you support, are you a sellout
[02:30:59.920 --> 02:31:01.520]   that is gonna believe whatever the government
[02:31:01.520 --> 02:31:02.720]   tells the sheep to take,
[02:31:02.720 --> 02:31:03.720]   or are you gonna be like the guy
[02:31:03.720 --> 02:31:06.600]   that stands against the crowd and gets fired from his job
[02:31:06.600 --> 02:31:07.760]   and pulls his kids from school
[02:31:07.760 --> 02:31:09.960]   because they're not gonna let the evil Fauci medicine
[02:31:09.960 --> 02:31:11.160]   jab them in the arm?
[02:31:11.160 --> 02:31:14.600]   - And the funny thing is the crowd that stands against
[02:31:14.600 --> 02:31:18.120]   the institution is not larger than the crowd of sheep.
[02:31:18.120 --> 02:31:19.760]   There's like one sheep standing there.
[02:31:19.760 --> 02:31:21.600]   - Sure, yeah, or it feels that way sometimes.
[02:31:21.600 --> 02:31:23.280]   - One vaccinated sheep.
[02:31:23.280 --> 02:31:26.080]   Well, okay, what's the defense of institutions?
[02:31:26.080 --> 02:31:28.080]   How do you regain the trust of institutions?
[02:31:28.080 --> 02:31:31.200]   Like, first of all, do you think that there's ways
[02:31:31.200 --> 02:31:34.800]   in which WHO, CDC failed,
[02:31:34.800 --> 02:31:37.600]   and do you think there's criticism towards Pfizer
[02:31:37.600 --> 02:31:40.080]   and the big pharma companies that's deserved?
[02:31:40.080 --> 02:31:42.520]   - Damn, it's the pharma companies, I'm not sure.
[02:31:42.520 --> 02:31:45.640]   For CDC and WHO, so here's a criticism that I have
[02:31:45.640 --> 02:31:47.080]   of all of academia,
[02:31:47.080 --> 02:31:49.600]   and I feel it stronger and stronger every day.
[02:31:49.600 --> 02:31:52.720]   I don't think it's enough to be a researcher
[02:31:52.720 --> 02:31:54.440]   or to be correct about issues.
[02:31:54.440 --> 02:31:58.560]   Academia needs to increase its ability to communicate.
[02:31:58.560 --> 02:32:03.400]   It is just an unbelievable, unmitigated failure
[02:32:03.400 --> 02:32:06.080]   that academics are unwilling to wade
[02:32:06.080 --> 02:32:09.200]   into the complicated topics that exist today
[02:32:09.200 --> 02:32:10.800]   because other people are, you know?
[02:32:10.800 --> 02:32:12.320]   - First you call me spineless,
[02:32:12.320 --> 02:32:14.280]   and then you call me a bad communicator.
[02:32:14.280 --> 02:32:15.360]   - But no, look, you're here, you're doing it,
[02:32:15.360 --> 02:32:16.600]   so you get props for me, okay?
[02:32:16.600 --> 02:32:17.440]   Good job.
[02:32:17.440 --> 02:32:18.280]   - That motherfucker.
[02:32:18.280 --> 02:32:19.520]   - But there are like so many, but I'm sure you've,
[02:32:19.520 --> 02:32:24.520]   I'm sure that you must have heard another fellow academic,
[02:32:24.520 --> 02:32:27.680]   a fellow colleague express some amount of frustration
[02:32:27.680 --> 02:32:30.320]   about like in their specific discipline,
[02:32:30.320 --> 02:32:31.440]   they know something to be true,
[02:32:31.440 --> 02:32:33.320]   and they know that like a lot of the messaging
[02:32:33.320 --> 02:32:35.120]   is like wrong or bad in the public about it,
[02:32:35.120 --> 02:32:36.520]   but they're never gonna step out and say anything
[02:32:36.520 --> 02:32:38.400]   because either one, they're very measured
[02:32:38.400 --> 02:32:39.280]   and careful with their tech,
[02:32:39.280 --> 02:32:40.440]   which they feel is incompatible
[02:32:40.440 --> 02:32:41.560]   with what people wanna hear,
[02:32:41.560 --> 02:32:43.280]   or two, they're really worried
[02:32:43.280 --> 02:32:44.240]   that they might be incorrect,
[02:32:44.240 --> 02:32:45.200]   so they're gonna be cautious
[02:32:45.200 --> 02:32:46.400]   while everybody else is going out
[02:32:46.400 --> 02:32:47.360]   and like hard-courting their--
[02:32:47.360 --> 02:32:49.320]   - And they also don't have the support of institutions
[02:32:49.320 --> 02:32:50.560]   for them to go out on a limb.
[02:32:50.560 --> 02:32:51.400]   - Yeah, that too.
[02:32:51.400 --> 02:32:52.760]   - So like to take risks, for example,
[02:32:52.760 --> 02:32:55.880]   I've heard that with lab leak theory.
[02:32:55.880 --> 02:32:58.120]   I've had a lot of biologists, virologists, friends
[02:32:58.120 --> 02:33:01.520]   that are like, yeah, it's obviously leaked from a lab.
[02:33:01.520 --> 02:33:02.920]   Like early on.
[02:33:02.920 --> 02:33:04.040]   - Oh, maybe, okay.
[02:33:04.040 --> 02:33:05.400]   We can fight over this one, but sorry, go ahead.
[02:33:05.400 --> 02:33:06.240]   - Let's fight.
[02:33:06.240 --> 02:33:07.080]   - No, no, keep talking.
[02:33:07.080 --> 02:33:07.900]   - We can fight over this.
[02:33:07.900 --> 02:33:11.120]   Well, like they, okay, I should sort of backstep
[02:33:11.120 --> 02:33:13.680]   and say like that's like you talk about shooting the shit,
[02:33:13.680 --> 02:33:15.960]   you haven't really investigated, but it's your gut.
[02:33:15.960 --> 02:33:17.680]   Like this doesn't make any sense.
[02:33:17.680 --> 02:33:18.960]   They would never say that publicly.
[02:33:18.960 --> 02:33:19.920]   - Of course.
[02:33:19.920 --> 02:33:23.320]   - Mostly because you're saying like what they would all say
[02:33:23.320 --> 02:33:24.960]   is like, we want to see data.
[02:33:24.960 --> 02:33:26.640]   - Yeah, which would be good, which is fine.
[02:33:26.640 --> 02:33:27.800]   - So they're going with like,
[02:33:27.800 --> 02:33:30.160]   like this is too many coincidences in the same place.
[02:33:30.160 --> 02:33:32.860]   That's the logic, but they don't want to say anything
[02:33:32.860 --> 02:33:33.720]   because there's no data.
[02:33:33.720 --> 02:33:34.880]   You need to have evidence.
[02:33:34.880 --> 02:33:36.040]   You need to have actual evidence
[02:33:36.040 --> 02:33:37.480]   to say one way or the other.
[02:33:37.480 --> 02:33:40.140]   There's that, but there's also just like you said,
[02:33:40.140 --> 02:33:42.880]   I mean, effective communication.
[02:33:42.880 --> 02:33:44.360]   You're a fan of Sean Carroll.
[02:33:44.360 --> 02:33:45.520]   - Oh, yes.
[02:33:45.520 --> 02:33:47.880]   He's like one of the only people in this whole planet
[02:33:47.880 --> 02:33:49.000]   that I like besides you.
[02:33:49.000 --> 02:33:50.480]   I love Sean Carroll.
[02:33:50.480 --> 02:33:53.640]   - Anytime Sean Carroll is brought up as evidence,
[02:33:53.640 --> 02:33:56.120]   there's a smile that comes over your face.
[02:33:56.120 --> 02:33:56.960]   - I love it.
[02:33:56.960 --> 02:33:58.800]   - Of like joy of like a little kid
[02:33:58.800 --> 02:34:00.320]   thinking about Santa Claus.
[02:34:00.320 --> 02:34:01.800]   Okay, I love Sean Carroll too.
[02:34:01.800 --> 02:34:02.920]   People should listen to this podcast.
[02:34:02.920 --> 02:34:06.160]   - I love Sean Carroll because I hate this divide
[02:34:06.160 --> 02:34:08.200]   between like you're either STEM
[02:34:08.200 --> 02:34:10.200]   or you're like philosophy, arts, and all that other stuff.
[02:34:10.200 --> 02:34:11.200]   And the two worlds kind of across.
[02:34:11.200 --> 02:34:13.180]   And I love that he was so good at physics,
[02:34:13.180 --> 02:34:14.680]   but like explores and pays attention
[02:34:14.680 --> 02:34:16.520]   to all of the like sociological stuff too.
[02:34:16.520 --> 02:34:18.480]   It's so rare to find that quality in a person.
[02:34:18.480 --> 02:34:20.500]   - He's legit one of the really, really, really
[02:34:20.500 --> 02:34:22.360]   special minds, but you don't have to be a Sean Carroll.
[02:34:22.360 --> 02:34:24.720]   You can be just a little better at educating.
[02:34:24.720 --> 02:34:28.000]   Another person in the medical and the health space
[02:34:28.000 --> 02:34:29.720]   is somebody named Andrew Huberman,
[02:34:29.720 --> 02:34:31.820]   a friend of mine from Stanford.
[02:34:31.820 --> 02:34:33.920]   He's an incredible educator.
[02:34:33.920 --> 02:34:36.220]   There's the kind of process in science
[02:34:36.220 --> 02:34:38.720]   they usually call like review or survey papers
[02:34:38.720 --> 02:34:42.160]   where you basically summarize all that's going on,
[02:34:42.160 --> 02:34:44.280]   integrate it, and like draw wisdom from it,
[02:34:44.280 --> 02:34:47.080]   and also project like where's the discipline headed.
[02:34:47.080 --> 02:34:49.880]   And Andrew does that basically on all these subcomponents
[02:34:49.880 --> 02:34:52.520]   of the different stuff going on in neuroscience,
[02:34:52.520 --> 02:34:54.440]   and biology, neurobiology, all of that.
[02:34:54.440 --> 02:34:58.140]   He's able to, he does a podcast called Huberman Lab
[02:34:58.140 --> 02:35:01.000]   where he just summarizes all and is able to explain
[02:35:01.000 --> 02:35:04.240]   like what does that actually mean for your life
[02:35:04.240 --> 02:35:07.040]   in terms of protocols of how to make your life better.
[02:35:07.040 --> 02:35:09.360]   I feel like people should be able to do that more and more.
[02:35:09.360 --> 02:35:14.140]   But with virology, and oh boy, that's a tricky one.
[02:35:14.140 --> 02:35:15.600]   That's a really tricky one.
[02:35:15.600 --> 02:35:18.080]   - I wish that people could have honest conversations.
[02:35:18.080 --> 02:35:19.400]   Like I attack a lot of people
[02:35:19.400 --> 02:35:20.880]   that do the lab leak theory stuff,
[02:35:20.880 --> 02:35:22.560]   but truly we should be able
[02:35:22.560 --> 02:35:24.280]   to have that conversation publicly.
[02:35:24.280 --> 02:35:25.120]   It just, it always feels like
[02:35:25.120 --> 02:35:26.440]   the people that are having the conversation
[02:35:26.440 --> 02:35:28.040]   don't ever really wanna have the conversation.
[02:35:28.040 --> 02:35:28.880]   They're not being honest.
[02:35:28.880 --> 02:35:32.000]   Like I'm a guy that like does his own research,
[02:35:32.000 --> 02:35:34.360]   and it's so boring reading studies,
[02:35:34.360 --> 02:35:36.200]   and a lot of it I can only do abstracts,
[02:35:36.200 --> 02:35:38.400]   and like it's so much work,
[02:35:38.400 --> 02:35:40.280]   but I'll never ever say that about myself.
[02:35:40.280 --> 02:35:41.400]   I'm a guy that does his own research
[02:35:41.400 --> 02:35:43.320]   because every time I hear somebody say that,
[02:35:43.320 --> 02:35:44.460]   they don't do any research.
[02:35:44.460 --> 02:35:45.540]   When they say they do their own research,
[02:35:45.540 --> 02:35:46.900]   what they mean is they've seen one podcast,
[02:35:46.900 --> 02:35:47.740]   and their opinion on it is completely--
[02:35:47.740 --> 02:35:48.900]   - What podcast is that?
[02:35:48.900 --> 02:35:50.220]   - Definitely not mine, 'cause if it was mine,
[02:35:50.220 --> 02:35:52.700]   I wouldn't be criticizing anything they say.
[02:35:52.700 --> 02:35:54.180]   But yeah, so like lab leak is another one,
[02:35:54.180 --> 02:35:56.100]   where it's like, well, how do you know it's lab leak?
[02:35:56.100 --> 02:35:57.600]   How do I know it's lab leak?
[02:35:57.600 --> 02:36:00.580]   Because Fauci lied, and Hunter Biden lapped up,
[02:36:00.580 --> 02:36:01.420]   and it's like, okay, come on,
[02:36:01.420 --> 02:36:02.300]   you haven't engaged with it at all.
[02:36:02.300 --> 02:36:03.940]   There's really interesting research
[02:36:03.940 --> 02:36:05.540]   that shows there's a really strong study
[02:36:05.540 --> 02:36:08.180]   that shows that there's like a high degree of certainty
[02:36:08.180 --> 02:36:10.060]   that it came from the wet markets.
[02:36:10.060 --> 02:36:11.820]   Very, very high degree of certainty.
[02:36:11.820 --> 02:36:13.320]   And there was an article that came out recently
[02:36:13.320 --> 02:36:15.600]   where it's like, Senate concludes that virus
[02:36:15.600 --> 02:36:18.880]   actually came from the Wuhan virology lab or whatever.
[02:36:18.880 --> 02:36:20.800]   And that whole article, if you actually read it,
[02:36:20.800 --> 02:36:21.960]   it never says that in the article.
[02:36:21.960 --> 02:36:24.480]   I don't know why they tweeted it with that headline.
[02:36:24.480 --> 02:36:26.480]   But yeah, to back up, I'm sorry.
[02:36:26.480 --> 02:36:27.920]   I think we should have good--
[02:36:27.920 --> 02:36:28.920]   - You should be sorry.
[02:36:28.920 --> 02:36:31.000]   - Yeah, I'm not sorry, actually.
[02:36:31.000 --> 02:36:32.360]   I get to ramble here, okay?
[02:36:32.360 --> 02:36:33.420]   I'm here for a long time.
[02:36:33.420 --> 02:36:35.360]   I rescind my apology, okay?
[02:36:35.360 --> 02:36:36.860]   I actually rescind my apology.
[02:36:36.860 --> 02:36:38.720]   We should be able to have
[02:36:38.720 --> 02:36:39.600]   challenging conversations about things,
[02:36:39.600 --> 02:36:41.440]   but you gotta, man, be well read on both sides.
[02:36:41.440 --> 02:36:43.380]   Not this like, I do my own research,
[02:36:43.380 --> 02:36:44.860]   so I don't believe anything that Fauci says.
[02:36:44.860 --> 02:36:45.700]   Like, come on, dude.
[02:36:45.700 --> 02:36:46.700]   Dude, you can do better than that.
[02:36:46.700 --> 02:36:48.060]   Not you personally, but.
[02:36:48.060 --> 02:36:49.620]   - Gotcha.
[02:36:49.620 --> 02:36:50.720]   How does that feel?
[02:36:50.720 --> 02:36:52.820]   - Feels great.
[02:36:52.820 --> 02:36:53.640]   - So for people who don't know--
[02:36:53.640 --> 02:36:54.480]   - Feel understood.
[02:36:54.480 --> 02:36:55.740]   - That's the catchphrase.
[02:36:55.740 --> 02:36:56.580]   Gotcha.
[02:36:56.580 --> 02:36:58.980]   Through all tragedy and triumph,
[02:36:58.980 --> 02:37:01.420]   through all the rollercoaster of life,
[02:37:01.420 --> 02:37:03.180]   your response to it is gotcha.
[02:37:03.180 --> 02:37:06.940]   It's, well, actually, let me jump to that
[02:37:06.940 --> 02:37:10.960]   before I continue with political discourse.
[02:37:11.900 --> 02:37:15.580]   Psychologically, you are in a lot of heated debates,
[02:37:15.580 --> 02:37:18.380]   and you're usually super calm under fire until you're not.
[02:37:18.380 --> 02:37:20.580]   Sometimes you lose your temper completely.
[02:37:20.580 --> 02:37:21.860]   - Very rarely, but.
[02:37:21.860 --> 02:37:23.580]   - That's like your opinion, man.
[02:37:23.580 --> 02:37:24.980]   Let me ask about your psychology.
[02:37:24.980 --> 02:37:27.460]   What are psychologically your strengths and weaknesses
[02:37:27.460 --> 02:37:29.100]   that you're self-aware about?
[02:37:29.100 --> 02:37:30.440]   - I think I'm very nonjudgmental,
[02:37:30.440 --> 02:37:32.620]   so I can entertain a lot of different thoughts
[02:37:32.620 --> 02:37:34.740]   without agreeing with them or condoning them.
[02:37:34.740 --> 02:37:37.540]   I think that's a really big benefit to me.
[02:37:37.540 --> 02:37:40.960]   For whatever reason, I seem to be pretty calm
[02:37:40.960 --> 02:37:43.440]   in dealing with annoying people.
[02:37:43.440 --> 02:37:45.080]   It's why I got promoted at the casino so fast.
[02:37:45.080 --> 02:37:46.840]   I could deal with drunks or whatever.
[02:37:46.840 --> 02:37:48.360]   It just didn't affect me that much.
[02:37:48.360 --> 02:37:51.080]   - What percent of the population is annoying?
[02:37:51.080 --> 02:37:53.700]   - Depends on how you're engaging with them.
[02:37:53.700 --> 02:37:55.520]   Most people aren't really annoying ever.
[02:37:55.520 --> 02:37:56.360]   - That's what I mean.
[02:37:56.360 --> 02:37:57.960]   - But if you're doing political debate,
[02:37:57.960 --> 02:37:59.160]   what percentage is annoying?
[02:37:59.160 --> 02:38:00.280]   I guess it depends on who I'm debating
[02:38:00.280 --> 02:38:01.120]   and what the topic is.
[02:38:01.120 --> 02:38:03.400]   - Well, I guess I'm trying to point out the fact
[02:38:03.400 --> 02:38:08.020]   that sometimes you can say that reveals something about you
[02:38:08.020 --> 02:38:10.260]   if you think a large percent of people are annoying.
[02:38:10.260 --> 02:38:11.780]   - Well, I would say working graveyard shift
[02:38:11.780 --> 02:38:12.940]   when alcohol is involved,
[02:38:12.940 --> 02:38:15.580]   that percentage of people goes very, very, very high.
[02:38:15.580 --> 02:38:16.860]   Or to be more fair, actually,
[02:38:16.860 --> 02:38:18.540]   it's not a high percentage, truly,
[02:38:18.540 --> 02:38:19.820]   but if you're a server,
[02:38:19.820 --> 02:38:22.340]   one bad customer can ruin the rest of your shift.
[02:38:22.340 --> 02:38:24.580]   So you only need one or two people acting in that manner
[02:38:24.580 --> 02:38:26.260]   to just totally throw you off.
[02:38:26.260 --> 02:38:29.380]   - And you're able to, at least these days,
[02:38:29.380 --> 02:38:32.460]   not allow that one customer to throw you off,
[02:38:32.460 --> 02:38:33.300]   quote, unquote.
[02:38:33.300 --> 02:38:34.240]   - It's pretty much like a,
[02:38:34.240 --> 02:38:36.440]   I noticed this especially after having a son,
[02:38:36.440 --> 02:38:39.200]   there's something about six-year-old kids or whatever
[02:38:39.200 --> 02:38:40.720]   where it's like, if they get mad,
[02:38:40.720 --> 02:38:41.960]   they're never gonna be mad for that long.
[02:38:41.960 --> 02:38:42.800]   They'll move on.
[02:38:42.800 --> 02:38:43.640]   That's my mentality.
[02:38:43.640 --> 02:38:44.840]   I'm a six-year-old kid.
[02:38:44.840 --> 02:38:45.680]   I might be mad about something,
[02:38:45.680 --> 02:38:47.600]   but I'll get over it in 30 minutes or an hour.
[02:38:47.600 --> 02:38:50.240]   I'm pretty good about not carrying that through.
[02:38:50.240 --> 02:38:52.760]   It's very rare that I'll hold a grudge against anybody
[02:38:52.760 --> 02:38:54.680]   or be angry about something
[02:38:54.680 --> 02:38:56.800]   or really disaffected by something over the long term.
[02:38:56.800 --> 02:38:58.480]   That almost never happens to me.
[02:38:58.480 --> 02:39:01.240]   - What are your weaknesses psychologically, could you say?
[02:39:01.240 --> 02:39:04.420]   - I still have a problem with projecting.
[02:39:04.420 --> 02:39:05.260]   I think we all probably do,
[02:39:05.260 --> 02:39:06.620]   but my mind onto others.
[02:39:06.620 --> 02:39:08.620]   It's like, if I understand this and I've said this,
[02:39:08.620 --> 02:39:09.500]   you should understand it.
[02:39:09.500 --> 02:39:11.080]   And if you're not, you're dumb.
[02:39:11.080 --> 02:39:12.540]   That's an issue that I,
[02:39:12.540 --> 02:39:14.660]   I still have that where I project too much.
[02:39:14.660 --> 02:39:16.760]   - What about holding grudges and stuff like that?
[02:39:16.760 --> 02:39:17.860]   - I never hold grudges.
[02:39:17.860 --> 02:39:19.500]   I'm the least grudgy person ever.
[02:39:19.500 --> 02:39:20.540]   It's kind of a meme in my community
[02:39:20.540 --> 02:39:22.980]   'cause anybody can always come back
[02:39:22.980 --> 02:39:24.100]   as long as they're acting different.
[02:39:24.100 --> 02:39:24.940]   - What about the,
[02:39:24.940 --> 02:39:25.860]   (laughs)
[02:39:25.860 --> 02:39:27.220]   as long as they're acting different.
[02:39:27.220 --> 02:39:28.060]   - As long as they're acting different.
[02:39:28.060 --> 02:39:29.040]   - See, I mean, all right.
[02:39:29.040 --> 02:39:30.460]   - The reason why I say that is because,
[02:39:30.460 --> 02:39:31.980]   so for instance, nobody likes this,
[02:39:31.980 --> 02:39:33.740]   but I have a strong stance on apologies
[02:39:33.740 --> 02:39:34.580]   and that I hate them.
[02:39:34.580 --> 02:39:35.620]   I don't ever want to hear an apology.
[02:39:35.620 --> 02:39:36.900]   I don't care about them ever.
[02:39:36.900 --> 02:39:38.040]   They don't mean anything to me.
[02:39:38.040 --> 02:39:39.340]   If you did something bad,
[02:39:39.340 --> 02:39:40.880]   as long as you've fixed the behavior
[02:39:40.880 --> 02:39:41.780]   and you're not doing that thing,
[02:39:41.780 --> 02:39:42.740]   then we're generally chill.
[02:39:42.740 --> 02:39:43.580]   So there's been a lot of people
[02:39:43.580 --> 02:39:44.840]   that have been involved in weird stuff with me,
[02:39:44.840 --> 02:39:46.620]   but then they go off to do their thing
[02:39:46.620 --> 02:39:48.180]   and they come back and it's like, okay, cool.
[02:39:48.180 --> 02:39:49.580]   As long as you don't do it again, we're fine.
[02:39:49.580 --> 02:39:50.420]   It's all good.
[02:39:50.420 --> 02:39:53.060]   - I'm sorry you feel that way.
[02:39:53.060 --> 02:39:55.380]   It's not your fault, Steven.
[02:39:55.380 --> 02:39:56.340]   It's not your fault.
[02:39:56.340 --> 02:39:57.580]   - Okay, gotcha.
[02:39:57.580 --> 02:40:00.180]   - You've said plenty of negative stuff.
[02:40:00.180 --> 02:40:03.180]   Positive stuff and negative stuff about Hassan.
[02:40:03.180 --> 02:40:04.340]   This is my podcast.
[02:40:04.340 --> 02:40:07.020]   I get to get you to force you to say positive things.
[02:40:07.020 --> 02:40:08.620]   What do you love?
[02:40:08.620 --> 02:40:10.260]   I'm all about love.
[02:40:10.260 --> 02:40:12.140]   - Let's go back to grilling me on the R word stuff.
[02:40:12.140 --> 02:40:13.540]   You're gonna make me compliment Hassan?
[02:40:13.540 --> 02:40:15.340]   This is gonna be a harder conversation than that.
[02:40:15.340 --> 02:40:16.180]   - All right.
[02:40:16.180 --> 02:40:19.960]   We're gonna get you to feel emotions.
[02:40:19.960 --> 02:40:22.620]   So he's, for people who don't know,
[02:40:22.620 --> 02:40:25.100]   he's another popular political streamer.
[02:40:25.100 --> 02:40:27.860]   I think you had, as the kids call it,
[02:40:27.860 --> 02:40:30.140]   a bridge burning over Bernie Sanders.
[02:40:30.140 --> 02:40:30.980]   I don't know.
[02:40:30.980 --> 02:40:32.620]   My research is very limited on this.
[02:40:32.620 --> 02:40:37.300]   But what do you respect and love most about Hassan?
[02:40:37.300 --> 02:40:38.820]   - He puts in a lot of work.
[02:40:38.820 --> 02:40:40.260]   When he was growing his stream
[02:40:40.260 --> 02:40:42.420]   from 2,000 concurrent viewers to 15,000,
[02:40:42.420 --> 02:40:44.780]   he was streaming, it was like 12 hours a day,
[02:40:44.780 --> 02:40:46.860]   like every single day.
[02:40:46.860 --> 02:40:47.700]   So that was admirable.
[02:40:47.700 --> 02:40:49.100]   He did a lot of work.
[02:40:49.100 --> 02:40:51.100]   He does seem to be pretty good at networking
[02:40:51.100 --> 02:40:53.260]   and socializing and making the correct friends
[02:40:53.260 --> 02:40:55.020]   and connections to continue to build his business.
[02:40:55.020 --> 02:40:56.900]   - What about him as a political thinker?
[02:40:56.900 --> 02:40:59.780]   I know you don't think highly of him on that regard,
[02:40:59.780 --> 02:41:01.300]   but I think that's unfair.
[02:41:01.300 --> 02:41:02.140]   - Oh, man.
[02:41:02.140 --> 02:41:02.960]   - I think that's unfair.
[02:41:02.960 --> 02:41:04.940]   I honestly wanna push back on that because--
[02:41:04.940 --> 02:41:05.860]   - Okay.
[02:41:05.860 --> 02:41:08.740]   I have zero respect for him as a political thinker.
[02:41:08.740 --> 02:41:10.420]   Or there's not gonna be almost anything.
[02:41:10.420 --> 02:41:11.620]   So you can't-- - Oh, I will say,
[02:41:11.620 --> 02:41:16.300]   I admire the fact that through no actual capability
[02:41:16.300 --> 02:41:18.260]   or ability of his own, he manages to wind up
[02:41:18.260 --> 02:41:19.380]   at some of the correct answers
[02:41:19.380 --> 02:41:20.380]   just 'cause he's towing the line.
[02:41:20.380 --> 02:41:22.260]   So good job for him on that.
[02:41:22.260 --> 02:41:23.460]   He's got a lot of correct opinions,
[02:41:23.460 --> 02:41:25.140]   just he has no idea why, so.
[02:41:25.140 --> 02:41:26.220]   - I think that's undeserved.
[02:41:26.220 --> 02:41:27.420]   I think that's too harsh, man.
[02:41:27.420 --> 02:41:28.260]   - Okay.
[02:41:28.260 --> 02:41:29.420]   - The reason I bring that up is I feel like
[02:41:29.420 --> 02:41:33.020]   there is a deep grudge in there somehow.
[02:41:33.020 --> 02:41:36.660]   So you're the father now, so since you're so old,
[02:41:36.660 --> 02:41:41.220]   the grandfather of the political debate on stream,
[02:41:41.220 --> 02:41:43.280]   on livestream political debater.
[02:41:43.280 --> 02:41:47.740]   So there could be some grudge about that split
[02:41:47.740 --> 02:41:49.820]   that happened or not enough credit given
[02:41:49.820 --> 02:41:50.900]   or all that kind of stuff.
[02:41:50.900 --> 02:41:55.900]   I just think he's somebody that has a left-leaning ideology
[02:41:56.340 --> 02:41:57.180]   that's different than yours.
[02:41:57.180 --> 02:41:58.740]   He was a Bernie supporter, right?
[02:41:58.740 --> 02:42:00.620]   And I guess you were not.
[02:42:00.620 --> 02:42:02.980]   Can you explain to me what the division is?
[02:42:02.980 --> 02:42:05.540]   - He exemplifies everything that I absolutely hate
[02:42:05.540 --> 02:42:07.100]   about politics. - Which is what?
[02:42:07.100 --> 02:42:09.700]   - Which is shallow engagement,
[02:42:09.700 --> 02:42:11.820]   heavily ideologically driven.
[02:42:11.820 --> 02:42:13.580]   - And you're not ideologically different, right?
[02:42:13.580 --> 02:42:14.660]   - Absolutely not.
[02:42:14.660 --> 02:42:16.420]   Free of ideology. - That's what we're talking
[02:42:16.420 --> 02:42:18.700]   about, like the free thinker in the real meaning
[02:42:18.700 --> 02:42:19.540]   of that word.
[02:42:19.540 --> 02:42:20.860]   - Yeah, so the way, let me qualify--
[02:42:20.860 --> 02:42:21.900]   - It's your body, it's your thinking.
[02:42:21.900 --> 02:42:24.220]   - Let me qualify what I mean when I say that.
[02:42:24.220 --> 02:42:26.220]   I spent a lot of time, unfortunate time,
[02:42:26.220 --> 02:42:28.100]   delving into the boring world of philosophy.
[02:42:28.100 --> 02:42:30.020]   I spent a lot of time thinking about
[02:42:30.020 --> 02:42:31.700]   what are my ethical positions?
[02:42:31.700 --> 02:42:34.820]   How do I feel about myself, the people around me,
[02:42:34.820 --> 02:42:36.300]   and how that relates to the world around me?
[02:42:36.300 --> 02:42:38.020]   And then from all of these positions,
[02:42:38.020 --> 02:42:39.060]   I think you might have used the phrase
[02:42:39.060 --> 02:42:40.860]   first principles earlier.
[02:42:40.860 --> 02:42:42.660]   From these kind of first principles,
[02:42:42.660 --> 02:42:45.180]   out of that is where all of my political positions
[02:42:45.180 --> 02:42:47.300]   are built out of, like full stop.
[02:42:47.300 --> 02:42:48.780]   So if you ask me a question like,
[02:42:48.780 --> 02:42:50.940]   how do you feel about the right to own a firearm
[02:42:50.940 --> 02:42:52.740]   or how do you feel about social healthcare?
[02:42:52.740 --> 02:42:55.100]   We can walk through, well, this is how I feel about it
[02:42:55.100 --> 02:42:56.660]   as like a thing from the government.
[02:42:56.660 --> 02:42:58.360]   This is where the government gets its power.
[02:42:58.360 --> 02:43:00.140]   This is ethically how groups of people
[02:43:00.140 --> 02:43:01.200]   are supposed to function.
[02:43:01.200 --> 02:43:02.980]   This is morally how we relate to each other.
[02:43:02.980 --> 02:43:04.180]   And personally, this is how I feel about it.
[02:43:04.180 --> 02:43:05.220]   Like I'll be able to do every single
[02:43:05.220 --> 02:43:06.460]   political belief back there.
[02:43:06.460 --> 02:43:07.860]   It's not like I'm telling you,
[02:43:07.860 --> 02:43:10.180]   like if I were to ask Hasan,
[02:43:10.180 --> 02:43:11.640]   what do you feel about this political topic?
[02:43:11.640 --> 02:43:13.700]   He's gonna tell me what progressives are supposed to say.
[02:43:13.700 --> 02:43:14.580]   I don't know what he thinks about it.
[02:43:14.580 --> 02:43:15.420]   I don't know if he thinks about it.
[02:43:15.420 --> 02:43:16.460]   - Don't you think that's a cynical take?
[02:43:16.460 --> 02:43:19.740]   Why is he, just because his views coincide
[02:43:19.740 --> 02:43:21.580]   with the mainstream narrative,
[02:43:21.580 --> 02:43:24.220]   mainstream viewpoints of progressive thinkers,
[02:43:24.220 --> 02:43:27.500]   I mean, why does that mean he's not thinking?
[02:43:27.500 --> 02:43:29.180]   - Because his engagement with every subject
[02:43:29.180 --> 02:43:32.060]   is incredibly shallow, 100% predictable.
[02:43:32.060 --> 02:43:33.940]   Like I could write like a,
[02:43:33.940 --> 02:43:35.420]   I could probably program a script
[02:43:35.420 --> 02:43:37.260]   to like give you every single potential answer
[02:43:37.260 --> 02:43:39.260]   you could have to any single question you could give him.
[02:43:39.260 --> 02:43:41.220]   - Again, I think that's pretty cynical take.
[02:43:41.220 --> 02:43:42.740]   - Okay, it could be the case that his brain
[02:43:42.740 --> 02:43:44.340]   perfectly aligns with every single mainstream--
[02:43:44.340 --> 02:43:47.060]   - No, but I don't know if you know it is perfectly aligns
[02:43:47.060 --> 02:43:48.900]   'cause I think you're just taking a very select,
[02:43:48.900 --> 02:43:51.020]   just like streamers do of each other,
[02:43:51.020 --> 02:43:55.940]   a very select slice that represents the perfect alignment
[02:43:55.940 --> 02:43:58.340]   as opposed to looking at a person struggling with ideas
[02:43:58.340 --> 02:44:01.060]   and thinking through ideas and then giving them a pass
[02:44:01.060 --> 02:44:03.820]   like a lot of people, like I give you a pass
[02:44:03.820 --> 02:44:07.460]   on just the fact that you say a lot of crazy shit
[02:44:07.460 --> 02:44:09.780]   on stream for drama, like which is--
[02:44:09.780 --> 02:44:11.140]   - I don't say things for drama.
[02:44:11.140 --> 02:44:13.100]   It might be dramatic, but.
[02:44:13.100 --> 02:44:17.020]   - I mean, you've evolved as a fish evolves legs.
[02:44:17.020 --> 02:44:20.540]   You've evolved a mechanism which creates controversy.
[02:44:20.540 --> 02:44:21.380]   - Sure.
[02:44:21.380 --> 02:44:24.100]   - That you could say it's not intention, but it happens.
[02:44:24.100 --> 02:44:27.420]   I think the extremists kind of learn that kind of thing.
[02:44:27.420 --> 02:44:30.380]   And so I'm sure Hasan does the same kind of stuff.
[02:44:30.380 --> 02:44:33.180]   And so like underneath it, there's still a thinking being
[02:44:33.180 --> 02:44:36.300]   that's contending with political ideas.
[02:44:36.300 --> 02:44:37.140]   You don't think so.
[02:44:37.140 --> 02:44:38.620]   - He does a really good job of hiding it.
[02:44:38.620 --> 02:44:41.180]   There are other political figures that I really don't like
[02:44:41.180 --> 02:44:42.300]   that I wouldn't say the same thing about.
[02:44:42.300 --> 02:44:44.060]   So like, I don't know if you have Vosch written in there.
[02:44:44.060 --> 02:44:45.660]   I'm like, okay, that's a person that--
[02:44:45.660 --> 02:44:46.500]   - That's Vosch.
[02:44:46.500 --> 02:44:48.020]   - That also split out of my community
[02:44:48.020 --> 02:44:48.860]   and grew up to something.
[02:44:48.860 --> 02:44:50.740]   And now he hates me and he's an anti-fan community
[02:44:50.740 --> 02:44:51.580]   and they all hate him.
[02:44:51.580 --> 02:44:53.140]   - Okay, tell me something you love about Vosch.
[02:44:53.140 --> 02:44:54.620]   - I can tell you a lot of things about Vosch.
[02:44:54.620 --> 02:44:56.340]   I think Vosch legitimately thinks through a lot
[02:44:56.340 --> 02:44:58.020]   of his political positions.
[02:44:58.020 --> 02:45:01.280]   I admire or did admire that he has like his own like
[02:45:01.280 --> 02:45:02.700]   positions that he would take sometimes contrary
[02:45:02.700 --> 02:45:04.460]   to people further left than him.
[02:45:04.460 --> 02:45:06.660]   He's got some positions that don't fit his ideology
[02:45:06.660 --> 02:45:07.500]   kind of at all.
[02:45:07.500 --> 02:45:08.620]   Like he's his own intimate thinker.
[02:45:08.620 --> 02:45:10.220]   Rhetorically, he's very effective.
[02:45:10.220 --> 02:45:12.300]   He was willing to sit down and do research
[02:45:12.300 --> 02:45:14.340]   for like his debates and everything.
[02:45:14.340 --> 02:45:15.840]   He would spend a lot of time practicing
[02:45:15.840 --> 02:45:17.260]   like his rhetorical effectiveness
[02:45:17.260 --> 02:45:19.140]   and navigating conversations.
[02:45:19.140 --> 02:45:21.300]   He intentionally and purposefully built like a community
[02:45:21.300 --> 02:45:23.260]   that exemplified his values.
[02:45:23.260 --> 02:45:24.100]   Yeah, I've got a lot.
[02:45:24.100 --> 02:45:27.020]   I don't, we are completely split and hate each other now.
[02:45:27.020 --> 02:45:27.860]   But like I have a lot of--
[02:45:27.860 --> 02:45:28.900]   - Why, why, why?
[02:45:28.900 --> 02:45:31.580]   First of all, hate is a strong, why the hate?
[02:45:31.580 --> 02:45:33.460]   - Okay, I don't hate him, but he hates me
[02:45:33.460 --> 02:45:35.220]   because we had a couple of really big debates.
[02:45:35.220 --> 02:45:36.060]   - What happened?
[02:45:36.060 --> 02:45:37.500]   - Well, one had to do with whether or not
[02:45:37.500 --> 02:45:39.060]   you should live your values.
[02:45:39.060 --> 02:45:40.780]   - And can you give me the story
[02:45:40.780 --> 02:45:42.420]   that's a charitable interpretation?
[02:45:42.420 --> 02:45:43.660]   - I always give charitable interpretation.
[02:45:43.660 --> 02:45:44.500]   - You don't.
[02:45:44.500 --> 02:45:45.700]   - I absolutely do.
[02:45:45.700 --> 02:45:46.540]   - You don't.
[02:45:46.540 --> 02:45:47.640]   - Wait, name one time it happened.
[02:45:47.640 --> 02:45:49.540]   - Five minutes ago, you talking about Hasan.
[02:45:49.540 --> 02:45:50.740]   - Everything I said about Hasan is true.
[02:45:50.740 --> 02:45:52.180]   There is no steel man there, okay?
[02:45:52.180 --> 02:45:53.220]   - That's not charitable.
[02:45:53.220 --> 02:45:54.380]   (laughing)
[02:45:54.380 --> 02:45:56.500]   - I'm sorry, if you can prove me wrong,
[02:45:56.500 --> 02:45:57.860]   I would love for you to do it, okay?
[02:45:57.860 --> 02:45:59.540]   - I'm using my gut instinct.
[02:45:59.540 --> 02:46:02.340]   Usually when somebody feels strongly
[02:46:02.340 --> 02:46:04.180]   about another person in that way,
[02:46:04.180 --> 02:46:06.700]   it's not coming from a place of data and reason.
[02:46:06.700 --> 02:46:09.160]   It's coming from a place of emotion.
[02:46:09.160 --> 02:46:11.580]   It's coming from a place of resentment
[02:46:11.580 --> 02:46:13.140]   and grudge and all that kind of stuff.
[02:46:13.140 --> 02:46:14.140]   - Yeah, I understand.
[02:46:14.140 --> 02:46:15.620]   - There's emotions deep in there.
[02:46:15.620 --> 02:46:17.380]   So the gotcha is hiding,
[02:46:17.380 --> 02:46:21.220]   the gotcha is a surface of an iceberg
[02:46:21.220 --> 02:46:22.900]   and there's a deep ocean underneath
[02:46:22.900 --> 02:46:24.460]   that you yourself have not explored.
[02:46:24.460 --> 02:46:25.940]   - I disagree, but I understand what you're saying.
[02:46:25.940 --> 02:46:27.740]   - And love is actually a doorway,
[02:46:27.740 --> 02:46:31.260]   the young love is a doorway for you to explore
[02:46:31.260 --> 02:46:32.100]   the depths of your--
[02:46:32.100 --> 02:46:33.260]   - Yeah, get into that ocean to find my fish,
[02:46:33.260 --> 02:46:34.460]   my pre-evolved form.
[02:46:34.460 --> 02:46:35.420]   - Yeah.
[02:46:35.420 --> 02:46:36.780]   - I understand why you think the way you do,
[02:46:36.780 --> 02:46:38.260]   and you should, you shouldn't believe me.
[02:46:38.260 --> 02:46:39.520]   And I understand that,
[02:46:39.520 --> 02:46:40.780]   because if somebody told me the same thing,
[02:46:40.780 --> 02:46:42.340]   I'd think you probably just really don't like this person
[02:46:42.340 --> 02:46:43.300]   for a reason or two.
[02:46:43.300 --> 02:46:45.060]   I understand why you think that way, okay?
[02:46:45.060 --> 02:46:46.060]   The reality is though,
[02:46:46.060 --> 02:46:47.780]   for any political person that I disagree with,
[02:46:47.780 --> 02:46:49.140]   like I can give them a fair shake.
[02:46:49.140 --> 02:46:50.820]   It's one of the few things I think I do
[02:46:50.820 --> 02:46:52.300]   exceedingly well on my stream.
[02:46:52.300 --> 02:46:53.580]   Even with Hasan, there's been drama
[02:46:53.580 --> 02:46:54.660]   that he's been involved in,
[02:46:54.660 --> 02:46:56.780]   and I've like very, when I'm involved in drama,
[02:46:56.780 --> 02:46:57.980]   he'll always throw me under the bus.
[02:46:57.980 --> 02:46:59.460]   But when he's involved in stuff, I'll always say like,
[02:46:59.460 --> 02:47:01.140]   "Oh, like I think Hasan was right here,"
[02:47:01.140 --> 02:47:03.300]   or "I think that he meant this."
[02:47:03.300 --> 02:47:05.740]   There was a thing that came up once we're on,
[02:47:05.740 --> 02:47:07.060]   livestream fail, he was getting roasted
[02:47:07.060 --> 02:47:08.820]   because he referred to somebody,
[02:47:08.820 --> 02:47:10.740]   he used the expression "shit skin"
[02:47:10.740 --> 02:47:13.260]   to refer to somebody's, like the way they looked.
[02:47:13.260 --> 02:47:15.820]   And I have only ever heard that
[02:47:15.820 --> 02:47:17.140]   in the context of 4chan people
[02:47:17.140 --> 02:47:19.540]   talking about like Indians or like black people.
[02:47:19.540 --> 02:47:21.100]   Like it's a racial thing.
[02:47:21.100 --> 02:47:23.300]   But I could tell the context
[02:47:23.300 --> 02:47:24.620]   and everything that he was saying.
[02:47:24.620 --> 02:47:25.900]   He was insulting some guy,
[02:47:25.900 --> 02:47:27.220]   I think it was kind of like Ensel Virch or whatever.
[02:47:27.220 --> 02:47:28.980]   He was going for like acne skin.
[02:47:28.980 --> 02:47:30.300]   I think that's what he meant when he said it.
[02:47:30.300 --> 02:47:31.220]   And there were a whole bunch of people
[02:47:31.220 --> 02:47:32.060]   that were insulting, like,
[02:47:32.060 --> 02:47:33.140]   "Oh my God, did he just say racist term?"
[02:47:33.140 --> 02:47:34.300]   I was like, "No, I don't think he was racist."
[02:47:34.300 --> 02:47:35.860]   I think he was like, he was just reaching for words,
[02:47:35.860 --> 02:47:37.460]   and that's what came out.
[02:47:37.460 --> 02:47:39.820]   So like that's an example of me being charitable.
[02:47:39.820 --> 02:47:41.940]   - Okay, but didn't you criticize him for something?
[02:47:41.940 --> 02:47:43.820]   I was trying to, I like Googled
[02:47:43.820 --> 02:47:45.140]   why the hell you guys split up,
[02:47:45.140 --> 02:47:46.300]   'cause I thought your friends,
[02:47:46.300 --> 02:47:47.140]   you should be like-
[02:47:47.140 --> 02:47:48.620]   - It's a little bit of a Kamala Harris video,
[02:47:48.620 --> 02:47:49.460]   but go ahead, what were you-
[02:47:49.460 --> 02:47:51.620]   - Is that why, is that the,
[02:47:51.620 --> 02:47:54.620]   I feel like you criticized him over something.
[02:47:54.620 --> 02:47:56.700]   And I, okay, this is very vague memory,
[02:47:56.700 --> 02:47:58.660]   but you criticized him over something,
[02:47:58.660 --> 02:48:00.980]   and I felt that criticism wasn't charitable.
[02:48:00.980 --> 02:48:02.220]   - Was it Pete Buttigieg's stuff?
[02:48:02.220 --> 02:48:03.940]   - Yeah, Pete Buttigieg, yes, yes, yes, yes, yes.
[02:48:03.940 --> 02:48:06.060]   - Yeah, so I've said this a million times,
[02:48:06.060 --> 02:48:08.320]   but no amount of context or no amount of nuances
[02:48:08.320 --> 02:48:09.460]   is ever acceptable to people.
[02:48:09.460 --> 02:48:11.980]   I don't think Hasan is homophobic,
[02:48:11.980 --> 02:48:14.580]   but I think the comments made about Pete Buttigieg
[02:48:14.580 --> 02:48:15.420]   were really homophobic.
[02:48:15.420 --> 02:48:16.380]   - That's what he said, right?
[02:48:16.380 --> 02:48:18.260]   - Yeah, and there were a lot of people
[02:48:18.260 --> 02:48:21.660]   making a lot of comments that made me really uncomfortable
[02:48:21.660 --> 02:48:24.900]   about Pete Buttigieg, that was insane to me.
[02:48:24.900 --> 02:48:27.580]   - Spurred by the comments of Hasan?
[02:48:27.580 --> 02:48:30.340]   - No, but it was an environment of progressives,
[02:48:30.340 --> 02:48:32.460]   all the progressives were attacking Pete,
[02:48:32.460 --> 02:48:36.300]   and I felt like his gayness became like the subject
[02:48:36.300 --> 02:48:37.140]   of a lot of attack. - Yeah, but why,
[02:48:37.140 --> 02:48:38.940]   why throw Hasan under the bus for that?
[02:48:38.940 --> 02:48:39.980]   - 'Cause he was jumping along
[02:48:39.980 --> 02:48:42.180]   with all of those types of insults.
[02:48:42.180 --> 02:48:44.020]   - You don't think you've done the same kind of stuff?
[02:48:44.020 --> 02:48:44.860]   - If I do, call me on it,
[02:48:44.860 --> 02:48:46.180]   and I'll probably say I shouldn't have done it.
[02:48:46.180 --> 02:48:47.780]   - That's what the R word was about.
[02:48:47.780 --> 02:48:49.180]   - That's fine, that's a good call-out.
[02:48:49.180 --> 02:48:51.660]   - No, but your friend, you should privately tell him,
[02:48:51.660 --> 02:48:53.220]   right, like, hey-- - Well, no, by then
[02:48:53.220 --> 02:48:54.740]   we were sworn enemies, so.
[02:48:54.740 --> 02:48:55.860]   - So that wasn't the reason you--
[02:48:55.860 --> 02:48:57.380]   - No, no, no, it was over a Kamala Harris video.
[02:48:57.380 --> 02:48:59.060]   - Sworn enemies. - Yeah.
[02:48:59.060 --> 02:49:01.140]   - He hates me, what am I supposed, listen,
[02:49:01.140 --> 02:49:02.820]   for all of these people, I will accept them
[02:49:02.820 --> 02:49:04.540]   back into my life if they ever wanna come back in
[02:49:04.540 --> 02:49:06.020]   at any point in time, but usually they're the ones
[02:49:06.020 --> 02:49:07.060]   that are saying like-- - If they correct
[02:49:07.060 --> 02:49:08.740]   themselves, right?
[02:49:08.740 --> 02:49:10.540]   - No, I'm not expecting anybody to,
[02:49:10.540 --> 02:49:11.860]   so here's the deal with Vosh and Hasan,
[02:49:11.860 --> 02:49:14.420]   these are like the three, we're the three guys online,
[02:49:14.420 --> 02:49:16.220]   none of us will talk to each other.
[02:49:16.220 --> 02:49:17.660]   Hasan because he won't give clout to anybody,
[02:49:17.660 --> 02:49:20.380]   and Vosh because he thinks I'm bad faith,
[02:49:20.380 --> 02:49:21.540]   and then neither of them will talk to me
[02:49:21.540 --> 02:49:22.740]   because they both hate me.
[02:49:22.740 --> 02:49:25.100]   - You guys should go on a camping trip together.
[02:49:25.100 --> 02:49:27.340]   It's like Brokeback Mountain, but three-way,
[02:49:27.340 --> 02:49:29.420]   and just like rejoin, refine--
[02:49:29.420 --> 02:49:30.260]   - Yeah, that could be a thing.
[02:49:30.260 --> 02:49:31.180]   - Refine the patient for each other.
[02:49:31.180 --> 02:49:32.820]   Honestly, just from the internet perspective,
[02:49:32.820 --> 02:49:35.280]   for me as just stepping into this world,
[02:49:35.720 --> 02:49:40.440]   there's some aspect to which you have a responsibility,
[02:49:40.440 --> 02:49:41.720]   I hate that word.
[02:49:41.720 --> 02:49:43.000]   - Good word, don't run from it.
[02:49:43.000 --> 02:49:45.240]   - You have an opportunity, I wish you guys
[02:49:45.240 --> 02:49:48.760]   would kind of be the beacon of forgiveness
[02:49:48.760 --> 02:49:50.600]   and friendship and camaraderie and that kind of stuff.
[02:49:50.600 --> 02:49:52.280]   - Yeah, I agree, and even if we disagree,
[02:49:52.280 --> 02:49:53.880]   it would be really good content for us to argue.
[02:49:53.880 --> 02:49:56.200]   - Yeah, like shit talk, like friends shit talk,
[02:49:56.200 --> 02:49:58.120]   versus not, like the fact that you guys
[02:49:58.120 --> 02:50:00.780]   don't talk to each other.
[02:50:00.780 --> 02:50:03.480]   Like I would love for you to shit talk publicly,
[02:50:03.480 --> 02:50:04.840]   with a camaraderie always there.
[02:50:04.840 --> 02:50:07.400]   Like there's love in the beginning, love in the end,
[02:50:07.400 --> 02:50:09.200]   but you beat the shit out of each other in the middle,
[02:50:09.200 --> 02:50:10.880]   and that's what live streaming is for,
[02:50:10.880 --> 02:50:14.200]   the political discourse, that's great political discourse.
[02:50:14.200 --> 02:50:16.680]   Versus, I think what underlies it,
[02:50:16.680 --> 02:50:19.180]   some jealousy and so on, with this,
[02:50:19.180 --> 02:50:20.680]   you get this many followers.
[02:50:20.680 --> 02:50:22.400]   (laughing)
[02:50:22.400 --> 02:50:23.360]   - I just wanna make sure you're clear to your audience.
[02:50:23.360 --> 02:50:26.200]   - Everybody has, to your audience.
[02:50:26.200 --> 02:50:28.720]   I'm sure you have flaws, and I'm just not,
[02:50:28.720 --> 02:50:29.560]   in this dynamic--
[02:50:29.560 --> 02:50:30.760]   - Hard to find, you know, 'cause I'm--
[02:50:30.760 --> 02:50:33.520]   - Your only flaw is you're too modest, yeah.
[02:50:33.520 --> 02:50:34.880]   - So why did you guys split up?
[02:50:34.880 --> 02:50:36.520]   Because I would love it, honestly,
[02:50:36.520 --> 02:50:38.560]   just let me just put that idea out there,
[02:50:38.560 --> 02:50:41.200]   for you guys to make up.
[02:50:41.200 --> 02:50:42.280]   - Yeah, it's out there, of course,
[02:50:42.280 --> 02:50:44.000]   as everybody talks, me, Vash, and Hasan.
[02:50:44.000 --> 02:50:45.480]   It's crazy that like the three largest,
[02:50:45.480 --> 02:50:48.600]   like political debate, left leaning people online,
[02:50:48.600 --> 02:50:51.520]   like can't do any type of content or collaboration at all.
[02:50:51.520 --> 02:50:52.600]   It's so stupid.
[02:50:52.600 --> 02:50:53.440]   - Yeah, it's strange.
[02:50:53.440 --> 02:50:55.880]   What was the reason you guys split up, the Kamala Harris?
[02:50:55.880 --> 02:50:58.240]   - So, Hasan's entry into kind of like
[02:50:58.240 --> 02:51:01.800]   the Twitch political debate world was in, I think 2018.
[02:51:01.800 --> 02:51:03.960]   And I think he did a debate with Charlie Kirk.
[02:51:03.960 --> 02:51:06.960]   And he reached out to me to kind of like review that debate,
[02:51:06.960 --> 02:51:08.920]   to like go over it on stream.
[02:51:08.920 --> 02:51:10.280]   And he came on, we went over it,
[02:51:10.280 --> 02:51:11.880]   and then we kind of, a friendship developed.
[02:51:11.880 --> 02:51:12.800]   We hung out in real life.
[02:51:12.800 --> 02:51:14.720]   I think when I came to LA, I think I slept on his couch,
[02:51:14.720 --> 02:51:17.200]   we played with his dog, we were like kind of friends.
[02:51:17.200 --> 02:51:21.960]   And as time went on, I think he was a little bit more,
[02:51:21.960 --> 02:51:25.120]   he was farther left than he let on.
[02:51:25.120 --> 02:51:27.480]   So like I was a social Democrat, he was a social Democrat.
[02:51:27.480 --> 02:51:29.520]   But back in those days, like 2018,
[02:51:29.520 --> 02:51:30.880]   when people said they were a social Democrat,
[02:51:30.880 --> 02:51:31.760]   they really meant socialist,
[02:51:31.760 --> 02:51:32.760]   but they just didn't wanna say it.
[02:51:32.760 --> 02:51:33.840]   So he was farther left than me.
[02:51:33.840 --> 02:51:36.280]   And we had a lot of deep divides
[02:51:36.280 --> 02:51:38.440]   in our approach to politics.
[02:51:38.440 --> 02:51:41.000]   Whereas like I was very much like a first principles,
[02:51:41.000 --> 02:51:42.360]   this is my whole political position.
[02:51:42.360 --> 02:51:44.200]   And he was very much kind of like a,
[02:51:44.200 --> 02:51:46.200]   this is like the political ideology I'm involved in.
[02:51:46.200 --> 02:51:47.200]   And this is kind of like the field
[02:51:47.200 --> 02:51:48.680]   that I kind of like navigate in.
[02:51:48.680 --> 02:51:51.360]   So there were a couple instances where these divides
[02:51:51.360 --> 02:51:53.080]   would be laid very bare.
[02:51:53.080 --> 02:51:56.680]   One was when, it was either him or the Young Turks.
[02:51:56.680 --> 02:51:58.400]   I think it was him.
[02:51:58.400 --> 02:52:00.080]   There was a shooting in a neighborhood
[02:52:00.080 --> 02:52:03.640]   where very young black child gets killed by a white shooter.
[02:52:03.640 --> 02:52:06.000]   And they did a video about like hate crimes
[02:52:06.000 --> 02:52:07.720]   and how hate crimes are on the rise
[02:52:07.720 --> 02:52:09.960]   between races and white people are evil and blah, blah, blah.
[02:52:09.960 --> 02:52:11.720]   Not that, but like white people committing hate crimes
[02:52:11.720 --> 02:52:12.800]   against black people.
[02:52:12.800 --> 02:52:14.760]   And I remember saying to him, I was like,
[02:52:14.760 --> 02:52:17.560]   "Hey, we don't have all the data yet for this.
[02:52:17.560 --> 02:52:20.560]   "It feels really bad to make videos about this beforehand
[02:52:20.560 --> 02:52:21.600]   "'cause it's the same type of shit
[02:52:21.600 --> 02:52:23.620]   "that happens at airports.
[02:52:23.620 --> 02:52:24.640]   "Is there a thing going on?
[02:52:24.640 --> 02:52:25.520]   "Was it a brown person?
[02:52:25.520 --> 02:52:26.360]   "Are they Muslim?
[02:52:26.360 --> 02:52:27.360]   "It's Islamic extremism."
[02:52:27.360 --> 02:52:29.160]   We see this played out so many times.
[02:52:29.160 --> 02:52:31.080]   In recent history, probably not a good idea
[02:52:31.080 --> 02:52:32.120]   to jump to conclusions.
[02:52:32.120 --> 02:52:33.560]   And he's like, "Well, no, you don't understand.
[02:52:33.560 --> 02:52:34.920]   "It's not that big a deal, whatever."
[02:52:34.920 --> 02:52:36.400]   And obviously as the story goes,
[02:52:36.400 --> 02:52:38.160]   tale as old as time, the data comes out.
[02:52:38.160 --> 02:52:39.640]   It was just an errant shot.
[02:52:39.640 --> 02:52:40.800]   There was like gang violence,
[02:52:40.800 --> 02:52:42.480]   shot goes out of nowhere, hits a kid in the car.
[02:52:42.480 --> 02:52:43.400]   It wasn't like a hate crime.
[02:52:43.400 --> 02:52:44.520]   The guy was trying to kill a kid.
[02:52:44.520 --> 02:52:46.920]   But yeah, we basically, we bump up against a few
[02:52:46.920 --> 02:52:49.160]   kind of political disagreements like this.
[02:52:49.160 --> 02:52:51.320]   And an annoying thing is happening in my community
[02:52:51.320 --> 02:52:53.360]   where Hasan is like the serious political figure
[02:52:53.360 --> 02:52:54.520]   'cause he's from the Young Turks.
[02:52:54.520 --> 02:52:56.880]   And I'm just kind of like, I do politics, but I also game.
[02:52:56.880 --> 02:52:59.280]   And anytime I criticize Hasan, people like Destiny,
[02:52:59.280 --> 02:53:00.240]   you need to be more respectful.
[02:53:00.240 --> 02:53:01.360]   He does this full time.
[02:53:01.360 --> 02:53:02.400]   If you're gonna bring criticisms,
[02:53:02.400 --> 02:53:04.000]   you need to be like really well read and researched
[02:53:04.000 --> 02:53:06.200]   because he's got a more serious, whatever,
[02:53:06.200 --> 02:53:07.040]   which I thought was ridiculous.
[02:53:07.040 --> 02:53:08.580]   - So by the way, if people don't know,
[02:53:08.580 --> 02:53:11.240]   he worked at the Young Turks, which is--
[02:53:11.240 --> 02:53:13.080]   - Like the largest left-leaning YouTube channel probably.
[02:53:13.080 --> 02:53:14.520]   - At least at the time, yeah.
[02:53:14.520 --> 02:53:18.320]   - So finally, he did a video on,
[02:53:18.320 --> 02:53:19.920]   we skip ahead to some more minor disagreements.
[02:53:19.920 --> 02:53:21.400]   He does a video on Kamala Harris.
[02:53:21.400 --> 02:53:22.880]   He calls it "Katmala Harris."
[02:53:22.880 --> 02:53:24.640]   And it's like seven or eight horrible things
[02:53:24.640 --> 02:53:25.480]   about Kamala Harris.
[02:53:25.480 --> 02:53:27.240]   And I'm like, okay, I know at least one or two
[02:53:27.240 --> 02:53:28.560]   of these things are not fully accurate.
[02:53:28.560 --> 02:53:30.520]   So I'm gonna do all the research.
[02:53:30.520 --> 02:53:31.560]   I'm gonna have all the sources
[02:53:31.560 --> 02:53:32.920]   and we're gonna have a long conversation about it
[02:53:32.920 --> 02:53:34.980]   so that now when I provide criticism to him,
[02:53:34.980 --> 02:53:37.080]   it's not gonna be like this horrible,
[02:53:37.080 --> 02:53:39.280]   like just me saying something flippantly or whatever.
[02:53:39.280 --> 02:53:41.080]   It's gonna be like substantial criticism.
[02:53:41.080 --> 02:53:45.960]   So I was on a plane ride, JFK to Orlando, whatever,
[02:53:45.960 --> 02:53:48.020]   flying to Sweden to visit my wife.
[02:53:48.020 --> 02:53:50.920]   And on the plane, I review all of the video,
[02:53:50.920 --> 02:53:52.680]   all the data, do all the research and I write everything.
[02:53:52.680 --> 02:53:57.680]   It's like, okay, I get to my wife's dad's house
[02:53:57.680 --> 02:53:59.560]   and I'm at the table.
[02:53:59.560 --> 02:54:00.560]   We're having a conversation like,
[02:54:00.560 --> 02:54:03.600]   hey, we should talk about the Kamala Harris stuff.
[02:54:03.600 --> 02:54:05.000]   And he's like, okay, well, let's do it.
[02:54:05.000 --> 02:54:09.000]   And we go over it and I'll leave to the audience
[02:54:09.000 --> 02:54:10.080]   to watch the video.
[02:54:10.080 --> 02:54:10.900]   Enough people have said this,
[02:54:10.900 --> 02:54:12.080]   I feel pretty confident in saying this.
[02:54:12.080 --> 02:54:13.920]   I was pretty reasonable, pretty measured,
[02:54:13.920 --> 02:54:15.040]   pretty calm the whole time.
[02:54:15.040 --> 02:54:17.180]   And I think he started to get increasingly irritated
[02:54:17.180 --> 02:54:20.200]   that I was levying like more and more serious criticisms
[02:54:20.200 --> 02:54:22.440]   at like the quality of work that he did.
[02:54:22.440 --> 02:54:24.260]   Probably because he felt a little bit intimidated,
[02:54:24.260 --> 02:54:26.440]   I think by my willingness to like dive
[02:54:26.440 --> 02:54:27.680]   through political stuff.
[02:54:27.680 --> 02:54:30.280]   There'd been a couple of awkward blowups where like on,
[02:54:30.280 --> 02:54:32.220]   there's like a show called the Raj Royale
[02:54:32.220 --> 02:54:34.400]   where sometimes politics would come up
[02:54:34.400 --> 02:54:36.240]   and Hassan would kind of try to explain something.
[02:54:36.240 --> 02:54:37.720]   And there was another person one time on the show
[02:54:37.720 --> 02:54:38.560]   that made the joke.
[02:54:38.560 --> 02:54:39.840]   It was like, instead of Hassan taking 10 minutes
[02:54:39.840 --> 02:54:41.160]   to explain this, can Destiny just come here
[02:54:41.160 --> 02:54:42.320]   and explain it in 30 seconds?
[02:54:42.320 --> 02:54:43.440]   And he like exploded at that.
[02:54:43.440 --> 02:54:46.040]   He got so fucking mad at that.
[02:54:46.040 --> 02:54:48.100]   So yeah, I think that when I made that kind of call out
[02:54:48.100 --> 02:54:49.960]   or critique of him over the Kamala Harris stuff,
[02:54:49.960 --> 02:54:51.960]   he's probably feeling like increasingly irritated,
[02:54:51.960 --> 02:54:52.920]   threatened, agitated.
[02:54:52.920 --> 02:54:56.000]   And then that's kind of what began the huge split from ours.
[02:54:56.000 --> 02:54:58.080]   - So you don't think you were a dick at all?
[02:54:58.080 --> 02:55:00.000]   - I don't think so in that conversation.
[02:55:00.000 --> 02:55:02.240]   Especially given that like at that point,
[02:55:02.240 --> 02:55:06.000]   'cause this is still 2018 or 20, this might be 2019.
[02:55:06.000 --> 02:55:09.280]   I'm still known at that point as being very aggressive
[02:55:09.280 --> 02:55:11.240]   towards conservatives or all writers.
[02:55:11.240 --> 02:55:12.080]   - Oh, gotcha.
[02:55:12.080 --> 02:55:14.000]   - Yeah, so, and with lefties is what I call them.
[02:55:14.000 --> 02:55:15.680]   I think I'm being like very gentle.
[02:55:15.680 --> 02:55:17.240]   Like my conversation I'll start with conservatives
[02:55:17.240 --> 02:55:18.920]   like you're a fuck idiot, you're so dumb.
[02:55:18.920 --> 02:55:19.960]   Like that's how I'm like doing.
[02:55:19.960 --> 02:55:20.920]   So like with him, I'm like,
[02:55:20.920 --> 02:55:22.000]   well, don't you think that like,
[02:55:22.000 --> 02:55:24.160]   this is like a little bit of like an inconsistent
[02:55:24.160 --> 02:55:26.000]   presentation about like, I feel like I'm being nice.
[02:55:26.000 --> 02:55:27.200]   But I always leave to the audience,
[02:55:27.200 --> 02:55:29.160]   they can go and watch that Kamala video,
[02:55:29.160 --> 02:55:30.560]   Kamala Harris video, "Destiny of Son"
[02:55:30.560 --> 02:55:31.920]   if they think that I was being a dick.
[02:55:31.920 --> 02:55:32.840]   But a lot of people watching said
[02:55:32.840 --> 02:55:33.840]   I was being pretty gentle.
[02:55:33.840 --> 02:55:37.320]   - Well, let me say as a new fan of this space,
[02:55:37.320 --> 02:55:41.080]   I hope you guys make up and I hope you guys fight it out
[02:55:41.080 --> 02:55:43.040]   in the space of discourse and ideas.
[02:55:43.040 --> 02:55:43.880]   - Me too.
[02:55:43.880 --> 02:55:45.680]   - And also with empathy, understanding what the strength
[02:55:45.680 --> 02:55:48.120]   of the other person is, what their buttons are.
[02:55:48.120 --> 02:55:51.240]   And there's like an unspoken rule
[02:55:51.240 --> 02:55:54.720]   that you don't press the buttons that you need to,
[02:55:54.720 --> 02:55:57.160]   unless you're doing it mutually and it's fun,
[02:55:57.160 --> 02:55:58.880]   'cause it's fun to piss each other off.
[02:55:58.880 --> 02:56:01.000]   So that's kind of like what friends do,
[02:56:01.000 --> 02:56:03.080]   you don't cross a certain line.
[02:56:03.080 --> 02:56:05.400]   But then other than that, you fight it out.
[02:56:05.400 --> 02:56:06.840]   Okay, let's step back.
[02:56:06.840 --> 02:56:10.240]   One other super interesting aspect of your worldview
[02:56:10.240 --> 02:56:13.560]   is you're a big supporter of Biden.
[02:56:13.560 --> 02:56:15.560]   Can you explain what you love about Biden?
[02:56:15.560 --> 02:56:18.480]   Do you love Biden more than Sean Carroll or less?
[02:56:18.480 --> 02:56:22.640]   - Sean Carroll is just like in another world of admiration.
[02:56:22.640 --> 02:56:24.960]   - I feel like I'm culturally appropriating you
[02:56:24.960 --> 02:56:27.840]   by saying gotcha now, but it's so convenient.
[02:56:27.840 --> 02:56:29.520]   - It's an easy word, you're just,
[02:56:29.520 --> 02:56:30.800]   we're on the same wavelength, okay?
[02:56:30.800 --> 02:56:32.280]   We're synchronizing, that's good.
[02:56:32.280 --> 02:56:33.640]   - I mean, it is really interesting
[02:56:33.640 --> 02:56:35.400]   because even the people that support Biden
[02:56:35.400 --> 02:56:37.560]   usually don't say they love,
[02:56:37.560 --> 02:56:39.720]   sort of they don't support it strongly.
[02:56:39.720 --> 02:56:41.920]   - Ideologically, philosophically,
[02:56:41.920 --> 02:56:44.600]   the reason why I like Biden is 'cause he's really committed
[02:56:44.600 --> 02:56:46.640]   to this bringing the left and right together,
[02:56:46.640 --> 02:56:49.360]   which is something we so desperately need in the country.
[02:56:49.360 --> 02:56:52.480]   And his statements over and over again of like,
[02:56:52.480 --> 02:56:54.960]   I'm not the Democrat president or the Republican president,
[02:56:54.960 --> 02:56:56.520]   I'm the president of the United States.
[02:56:56.520 --> 02:56:58.920]   His desire to bring Republicans together
[02:56:58.920 --> 02:57:01.440]   to work on things like the infrastructure bill,
[02:57:01.440 --> 02:57:03.560]   that's so incredibly needed.
[02:57:03.560 --> 02:57:06.520]   And I have a huge amount of respect and admiration for him
[02:57:06.520 --> 02:57:08.560]   for trying to push through on that message.
[02:57:08.560 --> 02:57:10.400]   - Do you think then it's unfortunate
[02:57:10.400 --> 02:57:12.400]   that he made that comment about MAGA?
[02:57:12.400 --> 02:57:13.240]   - MAGA Republicans?
[02:57:13.240 --> 02:57:15.160]   - Yeah, I mean, I forget what the comment was,
[02:57:15.160 --> 02:57:18.440]   but MAGA Republicans are not good people kind of thing.
[02:57:18.440 --> 02:57:21.680]   - I watched the full video and he's right.
[02:57:21.680 --> 02:57:24.440]   There is this toxic aspect and it's hard to call out
[02:57:24.440 --> 02:57:25.680]   because they're always gonna spend like,
[02:57:25.680 --> 02:57:26.880]   oh, he hates our Republicans, he's not.
[02:57:26.880 --> 02:57:29.400]   If you watch the quote, he's very specifically calling out
[02:57:29.400 --> 02:57:31.000]   like this group of people
[02:57:31.000 --> 02:57:33.120]   that think that the election was fraudulent.
[02:57:33.120 --> 02:57:35.600]   - Is it clear that's what he meant by--
[02:57:35.600 --> 02:57:36.960]   - We can bring it up.
[02:57:36.960 --> 02:57:37.800]   - All right, this is--
[02:57:37.800 --> 02:57:39.200]   - Oh no, uh-oh.
[02:57:39.200 --> 02:57:40.040]   But I remember watching it on stream,
[02:57:40.040 --> 02:57:41.360]   it was like, if he said it, yeah, that's bad.
[02:57:41.360 --> 02:57:43.920]   You can probably like YouTube MAGA Republicans Biden.
[02:57:43.920 --> 02:57:44.920]   But like, it feels like it's pretty clear
[02:57:44.920 --> 02:57:46.120]   he's talking about the people that are like,
[02:57:46.120 --> 02:57:47.840]   election denying.
[02:57:47.840 --> 02:57:50.400]   - Too much of what's happening in our country today
[02:57:50.400 --> 02:57:52.360]   is not normal.
[02:57:52.360 --> 02:57:56.600]   Donald Trump and the MAGA Republicans
[02:57:56.600 --> 02:57:59.200]   represent an extremism that threatens
[02:57:59.200 --> 02:58:02.240]   the very foundations of our republic.
[02:58:02.240 --> 02:58:05.400]   Now I wanna be very clear.
[02:58:05.400 --> 02:58:07.440]   - Listen to this part. - Very clear up front.
[02:58:08.960 --> 02:58:11.760]   - Not every Republican, not even the majority of Republicans
[02:58:11.760 --> 02:58:13.200]   are MAGA Republicans.
[02:58:13.200 --> 02:58:18.040]   Not every Republican embraces their extreme ideology.
[02:58:18.040 --> 02:58:20.640]   I know, 'cause I've been able to work
[02:58:20.640 --> 02:58:22.600]   with these mainstream Republicans.
[02:58:22.600 --> 02:58:27.000]   But there's no question that the Republican Party today
[02:58:27.000 --> 02:58:30.320]   is dominated, driven, and intimidated
[02:58:30.320 --> 02:58:32.760]   by Donald Trump and the MAGA Republicans.
[02:58:32.760 --> 02:58:36.640]   And that is a threat to this country.
[02:58:36.640 --> 02:58:37.600]   - I disagree with that, man.
[02:58:37.600 --> 02:58:41.680]   He didn't clearly say extremist ideology.
[02:58:41.680 --> 02:58:44.200]   He didn't say the people that doubt
[02:58:44.200 --> 02:58:45.560]   the validity of the election.
[02:58:45.560 --> 02:58:47.040]   - I mean, that's Donald Trump.
[02:58:47.040 --> 02:58:48.400]   - No, but there's--
[02:58:48.400 --> 02:58:50.360]   - That's all the candidates that Donald Trump is supporting.
[02:58:50.360 --> 02:58:51.720]   How many, what is it, like 40, 50,
[02:58:51.720 --> 02:58:54.160]   how many candidates right now that are MAGA candidates
[02:58:54.160 --> 02:58:55.040]   are election deniers?
[02:58:55.040 --> 02:58:58.120]   - No, but there's 80 million or whatever people
[02:58:58.120 --> 02:58:59.560]   voted for Donald Trump.
[02:58:59.560 --> 02:59:02.320]   You could say that's the MAGA Republicans.
[02:59:02.320 --> 02:59:06.320]   So to me, it sounded like he was referring
[02:59:06.320 --> 02:59:08.520]   to not even the majority.
[02:59:08.520 --> 02:59:12.840]   I mean, that's one nice, helpful, clarifying statement.
[02:59:12.840 --> 02:59:15.160]   But it's basically there's the mainstream Republicans,
[02:59:15.160 --> 02:59:17.380]   and then there's those that voted for Donald Trump.
[02:59:17.380 --> 02:59:18.640]   That's the way I heard it.
[02:59:18.640 --> 02:59:19.480]   - Okay.
[02:59:19.480 --> 02:59:20.320]   - And it's like, so--
[02:59:20.320 --> 02:59:22.160]   - Maybe he should've done a better job at clarifying, but.
[02:59:22.160 --> 02:59:23.000]   - Yeah, I--
[02:59:23.000 --> 02:59:24.040]   - I feel like there's like a clear,
[02:59:24.040 --> 02:59:27.280]   there is a huge problem with this group of Americans
[02:59:27.280 --> 02:59:28.520]   that think that the election is stolen.
[02:59:28.520 --> 02:59:29.360]   I feel like that's what he's trying to call it.
[02:59:29.360 --> 02:59:33.760]   - No matter if that's what he meant,
[02:59:33.760 --> 02:59:37.080]   even flirting with that line is not a person
[02:59:37.080 --> 02:59:39.180]   who's bringing people together.
[02:59:39.180 --> 02:59:41.200]   - I feel like the extending a hand to the,
[02:59:41.200 --> 02:59:43.560]   like most, I've worked with Republicans in Congress,
[02:59:43.560 --> 02:59:46.800]   not even a majority of Republicans are like this.
[02:59:46.800 --> 02:59:49.240]   - No, but why say not the majority of Republicans
[02:59:49.240 --> 02:59:50.060]   are like this?
[02:59:50.060 --> 02:59:53.640]   Say like we are, like we're one country.
[02:59:53.640 --> 02:59:54.520]   We believe the same thing.
[02:59:54.520 --> 02:59:57.280]   So like focus on the uniting part versus saying--
[02:59:57.280 --> 02:59:58.120]   - He does before and after.
[02:59:58.120 --> 02:59:59.080]   That was 50 seconds, okay?
[02:59:59.080 --> 03:00:00.800]   - But that, you never,
[03:00:00.800 --> 03:00:02.600]   the point is you never say something like that.
[03:00:02.600 --> 03:00:05.560]   Listen, like that, you've spoken about the Bosnia speech,
[03:00:05.560 --> 03:00:07.080]   which is your favorite of his.
[03:00:07.080 --> 03:00:07.920]   - Yeah.
[03:00:07.920 --> 03:00:09.200]   - I went back to it and listened to it.
[03:00:09.200 --> 03:00:10.560]   - Before I move to that, just on this,
[03:00:10.560 --> 03:00:12.800]   it's really hard for him to call out that group
[03:00:12.800 --> 03:00:14.120]   of like election deniers, I think,
[03:00:14.120 --> 03:00:14.960]   without it always feeling like--
[03:00:14.960 --> 03:00:16.640]   - Well, why call them out?
[03:00:16.640 --> 03:00:19.240]   - Because it's arguably one of the most destructive forces
[03:00:19.240 --> 03:00:21.120]   that exist in this country today.
[03:00:21.120 --> 03:00:22.920]   - Did it destroy anything?
[03:00:22.920 --> 03:00:24.280]   - They were trying to.
[03:00:24.280 --> 03:00:25.940]   - Did it, though?
[03:00:25.940 --> 03:00:27.280]   It didn't, did it?
[03:00:27.280 --> 03:00:28.600]   - So does that mean we don't call it out?
[03:00:28.600 --> 03:00:29.520]   We wait till next time?
[03:00:29.640 --> 03:00:34.200]   - Because calling it out is giving fuel to the division.
[03:00:34.200 --> 03:00:38.080]   Like the people that doubted the validity of the election,
[03:00:38.080 --> 03:00:40.880]   that's anger, that's frustration with the other side.
[03:00:40.880 --> 03:00:44.160]   You heal that as opposed to saying all those people
[03:00:44.160 --> 03:00:47.640]   that believed that at any time are idiots.
[03:00:47.640 --> 03:00:49.140]   They're un-American.
[03:00:49.140 --> 03:00:50.720]   - I mean, they don't think the election was real.
[03:00:50.720 --> 03:00:52.940]   I don't know if Biden has the ears of these people at all.
[03:00:52.940 --> 03:00:55.020]   I don't know what he can do for--
[03:00:55.020 --> 03:00:57.960]   - There's people that believe the same thing in 2016
[03:00:57.960 --> 03:00:59.640]   with the Russian hacking, right?
[03:00:59.640 --> 03:01:01.360]   - Hold on.
[03:01:01.360 --> 03:01:02.600]   - Yes.
[03:01:02.600 --> 03:01:04.500]   - That is a super not fair comparison.
[03:01:04.500 --> 03:01:08.940]   There were definitely, the mainstream Democrat opinion
[03:01:08.940 --> 03:01:13.880]   was that Russian intrusion in terms of like social media
[03:01:13.880 --> 03:01:15.880]   and stuff happened, but there was never a claim
[03:01:15.880 --> 03:01:17.480]   that like the election was stolen.
[03:01:17.480 --> 03:01:19.880]   No main, or at least I don't know of any mainstream Democrat
[03:01:19.880 --> 03:01:20.760]   that supported that.
[03:01:20.760 --> 03:01:22.000]   Donald Trump is not just saying
[03:01:22.000 --> 03:01:23.200]   there was interference, blah, blah, blah.
[03:01:23.200 --> 03:01:24.320]   Donald Trump is literally saying
[03:01:24.320 --> 03:01:26.360]   the election was literally stolen.
[03:01:26.360 --> 03:01:28.720]   Vote boxes were, ballot boxes were hidden,
[03:01:28.720 --> 03:01:30.640]   that vote tallies were manipulated.
[03:01:30.640 --> 03:01:32.640]   I think the claim is there's a huge gulf
[03:01:32.640 --> 03:01:33.960]   of difference between the two.
[03:01:33.960 --> 03:01:36.480]   - So you can attack Donald Trump for that.
[03:01:36.480 --> 03:01:37.520]   - Yeah.
[03:01:37.520 --> 03:01:40.280]   - I believe it's not the words of a uniter
[03:01:40.280 --> 03:01:43.940]   to attack people that believe that.
[03:01:43.940 --> 03:01:47.200]   You could argue maybe it's okay,
[03:01:47.200 --> 03:01:49.980]   but especially not being super clear about that,
[03:01:49.980 --> 03:01:52.920]   about who you're referring to when you say MAGA Republicans.
[03:01:52.920 --> 03:01:57.920]   'Cause MAGA is a hat and a slogan
[03:01:57.920 --> 03:02:02.720]   that refers to whatever the number is,
[03:02:02.720 --> 03:02:05.840]   70 million people, whoever, that voted for Donald Trump.
[03:02:05.840 --> 03:02:06.680]   Like--
[03:02:06.680 --> 03:02:07.520]   - Of all the Republicans that consider themselves
[03:02:07.520 --> 03:02:09.940]   MAGA Republicans, what percentage of them do you think
[03:02:09.940 --> 03:02:12.320]   believe the election was stolen?
[03:02:12.320 --> 03:02:13.640]   I feel like that number is, I don't have the poll,
[03:02:13.640 --> 03:02:17.080]   but I feel like that number is like probably more than 70%.
[03:02:17.080 --> 03:02:18.680]   - What's a MAGA Republican?
[03:02:18.680 --> 03:02:19.520]   Maybe I'm not familiar--
[03:02:19.520 --> 03:02:21.480]   - Like a Trump supporting Republican, a MAGA Republican.
[03:02:21.480 --> 03:02:23.200]   They're there for Trump.
[03:02:23.200 --> 03:02:24.320]   - What's the difference between somebody
[03:02:24.320 --> 03:02:26.120]   that voted for Trump and a--
[03:02:26.120 --> 03:02:26.960]   - MAGA Republican?
[03:02:26.960 --> 03:02:27.880]   - And a MAGA Republican.
[03:02:27.880 --> 03:02:30.680]   - So my mom is a MAGA Republican.
[03:02:30.680 --> 03:02:33.480]   If Trump ran independently and DeSantis ran
[03:02:33.480 --> 03:02:36.080]   under the Republican ticket, my mom would vote for Trump.
[03:02:36.080 --> 03:02:37.520]   She'll follow him to the end of the earth.
[03:02:37.520 --> 03:02:38.880]   That's like a MAGA Republican.
[03:02:38.880 --> 03:02:42.160]   - I think it's easy to mistake that distinction
[03:02:42.160 --> 03:02:44.080]   in these kinds of political speeches.
[03:02:44.080 --> 03:02:46.700]   'Cause to me, anybody who voted for Trump
[03:02:46.700 --> 03:02:49.140]   can easily in the context of the speech
[03:02:49.140 --> 03:02:51.800]   be interpreted as a MAGA Republican.
[03:02:51.800 --> 03:02:52.640]   - Gotcha.
[03:02:52.640 --> 03:02:56.080]   I understand what you're saying.
[03:02:56.080 --> 03:02:56.960]   Maybe you could have been more clear,
[03:02:56.960 --> 03:02:58.560]   but I think in listening to that,
[03:02:58.560 --> 03:03:01.420]   I think it's pretty obvious who he's talking about.
[03:03:01.420 --> 03:03:03.360]   But I guess if you have an emotional response to it,
[03:03:03.360 --> 03:03:04.440]   I can understand the emotional response.
[03:03:04.440 --> 03:03:05.280]   But there's a lot of people that--
[03:03:05.280 --> 03:03:06.640]   - I don't have an emotional response.
[03:03:06.640 --> 03:03:09.880]   I just don't like, I think I'm with, what is it?
[03:03:09.880 --> 03:03:13.320]   Michelle Obama, they go low, we go high.
[03:03:13.320 --> 03:03:17.480]   Meaning like, to me, a uniter doesn't participate
[03:03:17.480 --> 03:03:18.480]   in derision.
[03:03:18.480 --> 03:03:19.420]   - Sure, a uniter might not,
[03:03:19.420 --> 03:03:21.680]   but a leader has to be able to accurately assess
[03:03:21.680 --> 03:03:23.080]   the situation before him
[03:03:23.080 --> 03:03:24.240]   and make people aware of what's going on.
[03:03:24.240 --> 03:03:26.120]   - You mean all the impeachment trials,
[03:03:26.120 --> 03:03:28.640]   all the censoring from social media,
[03:03:28.640 --> 03:03:30.360]   all of that didn't do the job?
[03:03:30.360 --> 03:03:31.480]   - That's not his job.
[03:03:31.480 --> 03:03:32.320]   I don't know about censoring any of that.
[03:03:32.320 --> 03:03:33.480]   - No, but that mechanism,
[03:03:33.480 --> 03:03:36.760]   his job is to inspire a nation to unite a nation.
[03:03:36.760 --> 03:03:37.840]   - How can he do that when half the people
[03:03:37.840 --> 03:03:40.200]   don't believe that he was even legitimately elected?
[03:03:40.200 --> 03:03:41.080]   Like, I think he's done a good job
[03:03:41.080 --> 03:03:42.800]   at working on legislation and doing stuff
[03:03:42.800 --> 03:03:44.360]   that hopefully benefits all Americans.
[03:03:44.360 --> 03:03:45.820]   But I think it's important to recognize
[03:03:45.820 --> 03:03:47.680]   that there is a contingent of Americans
[03:03:47.680 --> 03:03:49.760]   that don't even believe, like, this is really crazy.
[03:03:49.760 --> 03:03:51.840]   - There are plenty of people that recognize that
[03:03:51.840 --> 03:03:53.360]   and are fighting that and are constantly
[03:03:53.360 --> 03:03:55.200]   screaming that from the rooftops.
[03:03:55.200 --> 03:03:59.520]   His job is to be the inspiring figure
[03:03:59.520 --> 03:04:02.440]   that makes the majority of Americans be proud
[03:04:02.440 --> 03:04:05.920]   for him to be a president of the nation they love.
[03:04:05.920 --> 03:04:08.680]   And that's what the uniting aspect is,
[03:04:08.680 --> 03:04:12.120]   is you remind people that we are one
[03:04:12.120 --> 03:04:13.160]   and we love this country,
[03:04:13.160 --> 03:04:14.840]   we love the ideas that it represents.
[03:04:14.840 --> 03:04:16.200]   - He does that in other parts of that speech.
[03:04:16.200 --> 03:04:17.480]   It's like a 20 minute speech, isn't it?
[03:04:17.480 --> 03:04:19.080]   But that's a fuck up.
[03:04:19.080 --> 03:04:21.560]   You just don't participate in that division.
[03:04:21.560 --> 03:04:24.460]   Anyway, I understand, I understand.
[03:04:24.460 --> 03:04:26.240]   I just wanted to push back on the saying,
[03:04:26.240 --> 03:04:30.520]   one of his strengths is that he's uniting.
[03:04:30.520 --> 03:04:35.520]   But yes, that is an ideal, that is a goal, is a great one.
[03:04:35.520 --> 03:04:40.120]   And he is one that espoused that goal for a long time.
[03:04:40.120 --> 03:04:42.320]   Do you think, what else?
[03:04:42.320 --> 03:04:44.520]   So from a policy perspective and so on.
[03:04:44.520 --> 03:04:45.920]   - I thought the way he's handled Ukraine and everything
[03:04:45.920 --> 03:04:47.600]   thus far has been almost perfect.
[03:04:47.600 --> 03:04:49.280]   I think he did a really good job.
[03:04:49.280 --> 03:04:51.080]   And at the political maneuvering
[03:04:51.080 --> 03:04:52.640]   of bringing other countries into the fold,
[03:04:52.640 --> 03:04:54.720]   at establishing clearly what our mission was
[03:04:54.720 --> 03:04:57.240]   in relation to Ukraine, I thought he did a good job there.
[03:04:57.240 --> 03:04:59.040]   I admire him for pulling out of Afghanistan.
[03:04:59.040 --> 03:05:01.080]   Even if it was a little bit rough around the edges,
[03:05:01.080 --> 03:05:03.880]   we got out and we're gone, no American lives were lost.
[03:05:03.880 --> 03:05:08.000]   The domestic policy, he's passed more major legislation
[03:05:08.000 --> 03:05:10.280]   than I think anybody thought possible.
[03:05:10.280 --> 03:05:11.880]   The green energy stuff with the last bill,
[03:05:11.880 --> 03:05:13.720]   the infrastructure bill.
[03:05:13.720 --> 03:05:15.640]   A lot of the coronavirus relief I thought was really good,
[03:05:15.640 --> 03:05:18.160]   especially the expansion of the child tax credit.
[03:05:18.160 --> 03:05:20.520]   So from a policy perspective, foreign and domestic,
[03:05:20.520 --> 03:05:21.640]   I think he's been successful.
[03:05:21.640 --> 03:05:24.240]   Rhetorically, I think he's generally been above board
[03:05:24.240 --> 03:05:26.800]   in terms of not attacking people or being too divisive.
[03:05:26.800 --> 03:05:28.840]   He's trying to bring people together and work on them.
[03:05:28.840 --> 03:05:32.240]   - What do you think about the sort of popular in the media
[03:05:32.240 --> 03:05:34.340]   criticism of his mental decline?
[03:05:34.340 --> 03:05:35.180]   Do you think he's experiencing mental decline?
[03:05:35.180 --> 03:05:37.360]   - You know, he's an old guy.
[03:05:37.360 --> 03:05:40.040]   - But do you think, I mean, do you?
[03:05:40.040 --> 03:05:41.240]   - Yeah, maybe a little bit,
[03:05:41.240 --> 03:05:43.320]   but he's still doing a good job, so you know.
[03:05:43.320 --> 03:05:44.520]   - Not from a speech perspective,
[03:05:44.520 --> 03:05:45.720]   you mean from a policy perspective?
[03:05:45.720 --> 03:05:47.440]   - Yeah, I'm analyzing it as a job, yeah.
[03:05:47.440 --> 03:05:49.400]   From a speech perspective, maybe not the greatest,
[03:05:49.400 --> 03:05:51.800]   but yeah, I mean, he's definitely, what is he, like 80, 81?
[03:05:51.800 --> 03:05:52.640]   How old is he?
[03:05:52.640 --> 03:05:54.360]   - I lose track after so many years.
[03:05:54.360 --> 03:05:55.200]   - Yeah.
[03:05:55.200 --> 03:05:59.600]   - But you did say that he's probably going to run in 2024
[03:05:59.600 --> 03:06:01.160]   and he's probably going to win.
[03:06:01.160 --> 03:06:02.680]   - Did I say that, that he's probably gonna win?
[03:06:02.680 --> 03:06:03.520]   No way did I say that.
[03:06:03.520 --> 03:06:04.340]   - I heard that somewhere.
[03:06:04.340 --> 03:06:05.180]   - He's probably gonna run.
[03:06:05.180 --> 03:06:06.020]   - Okay.
[03:06:06.020 --> 03:06:06.840]   - Who knows who will win?
[03:06:06.840 --> 03:06:08.880]   But I think, I feel like the incumbent advantage
[03:06:08.880 --> 03:06:09.720]   is so strong.
[03:06:09.720 --> 03:06:10.540]   Are you really gonna throw that away?
[03:06:10.540 --> 03:06:12.240]   Like, there's been like one or two times in history
[03:06:12.240 --> 03:06:14.440]   in the US, right, where like the non-incumbent,
[03:06:14.440 --> 03:06:16.200]   the parties put somebody else up?
[03:06:16.200 --> 03:06:18.960]   - Yeah, I mean, the concern is like the,
[03:06:18.960 --> 03:06:21.980]   just the age and the mental decline,
[03:06:21.980 --> 03:06:26.040]   just the wear and tear of the campaign,
[03:06:26.040 --> 03:06:26.880]   all of that kind of stuff.
[03:06:26.880 --> 03:06:28.120]   All of the speech you have to make,
[03:06:28.120 --> 03:06:29.600]   the debates and all that kind of stuff.
[03:06:29.600 --> 03:06:31.040]   - Yeah, I guess we'll see what happens.
[03:06:31.040 --> 03:06:32.480]   (laughing)
[03:06:32.480 --> 03:06:33.320]   What?
[03:06:33.320 --> 03:06:34.920]   - The least excited.
[03:06:34.920 --> 03:06:36.560]   - I mean, two years from now is a long time.
[03:06:36.560 --> 03:06:39.920]   At his current mental state, he could run and do it.
[03:06:39.920 --> 03:06:40.840]   He could do a possible job.
[03:06:40.840 --> 03:06:42.520]   In two years, man, I don't know.
[03:06:42.520 --> 03:06:43.880]   I've seen videos of Bill Clinton recently.
[03:06:43.880 --> 03:06:45.180]   He's looking pretty rough.
[03:06:45.180 --> 03:06:48.280]   You know, if Biden is looking a lot more rough,
[03:06:48.280 --> 03:06:49.360]   worse for wear in two years,
[03:06:49.360 --> 03:06:53.520]   then maybe they actually do have to dig out another person
[03:06:53.520 --> 03:06:54.680]   for running, who knows?
[03:06:54.680 --> 03:06:58.920]   - What do you think about Trump?
[03:06:58.920 --> 03:07:03.920]   When he won in 2016, I think is when you came to fruition,
[03:07:03.920 --> 03:07:05.720]   politically speaking.
[03:07:05.720 --> 03:07:07.320]   So what do you think his winning
[03:07:07.320 --> 03:07:11.320]   the 2016 election represents?
[03:07:11.320 --> 03:07:16.160]   - So for me, the reason why I got into politics
[03:07:16.160 --> 03:07:20.160]   was Trump was like this new epistemic force
[03:07:20.160 --> 03:07:24.540]   in American politics that you kind of have to flirt
[03:07:24.540 --> 03:07:27.040]   with facts before, even if you wanted to be non-factual.
[03:07:27.040 --> 03:07:28.880]   He super didn't care.
[03:07:28.880 --> 03:07:30.560]   Lying was like a first language to him,
[03:07:30.560 --> 03:07:32.600]   just like in speaking in terms of like,
[03:07:32.600 --> 03:07:35.420]   the way that he used language to just say to you
[03:07:35.420 --> 03:07:37.920]   what he felt like you needed to hear to support him
[03:07:37.920 --> 03:07:40.400]   and not care at all about what is going on,
[03:07:40.400 --> 03:07:43.840]   about, yeah, that's what Trump represented to me
[03:07:43.840 --> 03:07:46.240]   in terms of like things that I cared about.
[03:07:46.240 --> 03:07:47.680]   He also represents a lot more, obviously,
[03:07:47.680 --> 03:07:49.760]   that there was this undercurrent of American opinion
[03:07:49.760 --> 03:07:51.720]   that a lot of people didn't know still existed,
[03:07:51.720 --> 03:07:53.720]   and it did, he got elected.
[03:07:53.720 --> 03:07:55.420]   That the Overton window was misidentified
[03:07:55.420 --> 03:07:57.480]   by even a large amount of the Republican Party.
[03:07:57.480 --> 03:07:59.280]   That populism was a lot more popular
[03:07:59.280 --> 03:08:01.280]   than a lot of people figured, you know?
[03:08:01.280 --> 03:08:03.080]   Yeah, there's a lot that I guess he represented.
[03:08:03.080 --> 03:08:06.320]   - Do you think Trump should have been banned from Twitter?
[03:08:06.320 --> 03:08:08.040]   Can you make the case for and against it?
[03:08:08.040 --> 03:08:10.240]   So you're a big supporter of free speech.
[03:08:10.240 --> 03:08:13.080]   - Yeah, so the case in favor of it.
[03:08:13.080 --> 03:08:16.800]   - Do you think he should be brought back as Elon tweeted?
[03:08:16.800 --> 03:08:17.640]   - Yeah, because if he gets brought back,
[03:08:17.640 --> 03:08:19.120]   there's a higher chance that I'll be brought back.
[03:08:19.120 --> 03:08:20.680]   So I'm supporting that all the way.
[03:08:20.680 --> 03:08:22.680]   Thank you, Elon, unban my account.
[03:08:22.680 --> 03:08:26.640]   - So because you called me weak spine,
[03:08:26.640 --> 03:08:28.200]   I'm gonna have to message Elon.
[03:08:28.200 --> 03:08:30.760]   - Okay, @OmniDestiny, it was a verified Twitter account.
[03:08:30.760 --> 03:08:32.840]   - OmniDestiny. - No, no, I'm just kidding.
[03:08:32.840 --> 03:08:34.560]   - Why'd you get banned from Twitter, Destiny?
[03:08:34.560 --> 03:08:37.240]   - I don't know. - I'll add that to Elon.
[03:08:37.240 --> 03:08:40.400]   - I saw that there was a screenshot of you
[03:08:40.400 --> 03:08:43.960]   referring to the rape of somebody.
[03:08:43.960 --> 03:08:45.640]   - Okay, that was on an older Twitter account,
[03:08:45.640 --> 03:08:46.680]   and that was a bad tweet.
[03:08:46.680 --> 03:08:48.520]   - You have multiple Twitter accounts,
[03:08:48.520 --> 03:08:51.360]   so you're trying to go around the bans
[03:08:51.360 --> 03:08:52.360]   that you keep getting.
[03:08:52.360 --> 03:08:53.520]   - Okay, hold on.
[03:08:53.520 --> 03:08:55.440]   You're slandering me a lot right now.
[03:08:55.440 --> 03:08:57.000]   Let's get the facts straight, okay?
[03:08:57.000 --> 03:08:59.000]   I don't even remember why my first account got banned,
[03:08:59.000 --> 03:09:00.280]   but it was a wild account.
[03:09:00.280 --> 03:09:02.400]   I tweeted some wildly inappropriate things.
[03:09:02.400 --> 03:09:03.880]   - You regret? - I don't like that word.
[03:09:03.880 --> 03:09:05.080]   I'm gonna give the answer that most people give.
[03:09:05.080 --> 03:09:06.760]   It's like, I don't regret it 'cause I learned a lot.
[03:09:06.760 --> 03:09:08.360]   So I'm glad I had the bad experiences that I did.
[03:09:08.360 --> 03:09:10.120]   - Why don't you like the word regret?
[03:09:10.120 --> 03:09:13.720]   - I think if we look at where we are,
[03:09:13.720 --> 03:09:15.640]   how do you feel about determinism?
[03:09:15.640 --> 03:09:18.080]   (Lex laughing)
[03:09:18.080 --> 03:09:20.320]   I believe in the hardest of determinism.
[03:09:20.320 --> 03:09:21.520]   That's who I am, okay?
[03:09:21.520 --> 03:09:24.120]   So who I am today is the culmination
[03:09:24.120 --> 03:09:25.400]   of everything that's occurred in the past.
[03:09:25.400 --> 03:09:28.240]   - But I believe you speaking, sorry to interrupt.
[03:09:28.240 --> 03:09:31.360]   I believe in you speaking about regret
[03:09:31.360 --> 03:09:33.800]   is a nice way to communicate
[03:09:33.800 --> 03:09:35.780]   that in this deterministic world,
[03:09:35.780 --> 03:09:38.160]   you've analyzed the acts of the past
[03:09:38.160 --> 03:09:39.800]   and you're no longer that person.
[03:09:39.800 --> 03:09:40.880]   - Yeah, of course, for sure.
[03:09:40.880 --> 03:09:43.120]   - That's what regret usually means.
[03:09:43.120 --> 03:09:44.800]   - Okay, thanks for giving me the human explanation.
[03:09:44.800 --> 03:09:45.640]   Okay, true.
[03:09:45.640 --> 03:09:46.880]   So in that sense, there's a lot of things I've done
[03:09:46.880 --> 03:09:48.000]   that I regret.
[03:09:48.000 --> 03:09:48.920]   - Oh, what are you?
[03:09:48.920 --> 03:09:50.440]   You're not human, you're a bot?
[03:09:50.440 --> 03:09:54.040]   - NPC is my preferred term. - Okay, all right.
[03:09:54.040 --> 03:09:56.600]   - I wish I would have been smart enough at the time
[03:09:56.600 --> 03:09:58.840]   to not have to have had made those mistakes.
[03:09:58.840 --> 03:09:59.680]   - Okay. - There you go.
[03:09:59.680 --> 03:10:00.760]   - Good job.
[03:10:00.760 --> 03:10:02.240]   - But yeah, obviously really dumb,
[03:10:02.240 --> 03:10:04.400]   really crazy off the wall tweets.
[03:10:04.400 --> 03:10:05.240]   But that account got banned.
[03:10:05.240 --> 03:10:08.840]   And then I made another account called,
[03:10:08.840 --> 03:10:09.680]   I can't believe I'm giving you a history
[03:10:09.680 --> 03:10:10.520]   of my Twitter accounts,
[03:10:10.520 --> 03:10:11.600]   but another account called Omni Destiny.
[03:10:11.600 --> 03:10:12.440]   - It's an honor.
[03:10:12.440 --> 03:10:14.560]   - And that was my, I got verified.
[03:10:14.560 --> 03:10:16.280]   I was cool, they let me have that account
[03:10:16.280 --> 03:10:17.760]   'cause originally they banned it and I said appeal
[03:10:17.760 --> 03:10:18.960]   and I was like, oh, let me have one more.
[03:10:18.960 --> 03:10:20.240]   And back then Twitter was cool
[03:10:20.240 --> 03:10:21.540]   and they're like, okay, go for it.
[03:10:21.540 --> 03:10:23.040]   And that account last for a long time.
[03:10:23.040 --> 03:10:27.580]   And I don't actually know 100% why that account got banned.
[03:10:27.580 --> 03:10:31.400]   I believe that the tweet that showed up in the final,
[03:10:31.400 --> 03:10:33.360]   I got banned for hate speech.
[03:10:33.360 --> 03:10:34.920]   And it was because I was,
[03:10:34.920 --> 03:10:36.480]   there was a picture that I tweeted
[03:10:36.480 --> 03:10:38.140]   with three different alt writers
[03:10:38.140 --> 03:10:39.520]   that are kind of like neo-Nazi people.
[03:10:39.520 --> 03:10:42.020]   And they were all like mixed race people.
[03:10:42.020 --> 03:10:43.360]   And I said like the new alt right looks
[03:10:43.360 --> 03:10:45.200]   like a Disney Channel original movie
[03:10:45.200 --> 03:10:46.520]   in terms of racial composition.
[03:10:46.520 --> 03:10:50.200]   And somehow they got flagged for instigating violence
[03:10:50.200 --> 03:10:51.480]   against minorities I think.
[03:10:51.480 --> 03:10:53.280]   And I think that's the tweet that got me banned
[03:10:53.280 --> 03:10:54.880]   'cause I think that's what showed up in the final report.
[03:10:54.880 --> 03:10:56.480]   But I don't know, maybe there were other reasons
[03:10:56.480 --> 03:10:57.460]   'cause nobody ever communicates.
[03:10:57.460 --> 03:10:59.520]   But ever since that account went under,
[03:10:59.520 --> 03:11:02.160]   it's just been ban evading ever since so.
[03:11:02.160 --> 03:11:04.120]   - Oh, ban evading ever since.
[03:11:04.120 --> 03:11:05.240]   - So all my new accounts that I've got banned
[03:11:05.240 --> 03:11:06.800]   just get banned 'cause they finally figured out it's me
[03:11:06.800 --> 03:11:07.640]   and then they ban evade.
[03:11:07.640 --> 03:11:08.920]   There's like one dude at Twitter HQ
[03:11:08.920 --> 03:11:12.160]   who's like constantly looking for my new accounts
[03:11:12.160 --> 03:11:13.200]   and they get me, yeah.
[03:11:13.200 --> 03:11:14.240]   - Yeah.
[03:11:14.240 --> 03:11:15.400]   - Anyway, yeah.
[03:11:15.400 --> 03:11:17.200]   - So post.
[03:11:17.200 --> 03:11:19.080]   - Post Trump world.
[03:11:19.080 --> 03:11:20.560]   - Do you think, okay, I mean this.
[03:11:20.560 --> 03:11:21.400]   - Oh, should he be banned?
[03:11:21.400 --> 03:11:23.120]   Oh, you asked me to make both cases.
[03:11:23.120 --> 03:11:25.200]   Should he be banned?
[03:11:25.200 --> 03:11:26.920]   I mean, damn dude, when you're tweeting out shit
[03:11:26.920 --> 03:11:29.060]   that's arguably leading to stuff like January 6th,
[03:11:29.060 --> 03:11:30.780]   I can understand why.
[03:11:30.780 --> 03:11:32.320]   Because it's like, what else is this wild dude
[03:11:32.320 --> 03:11:33.160]   gonna tweet out?
[03:11:33.160 --> 03:11:34.760]   Like is he gonna start instigating other violent events?
[03:11:34.760 --> 03:11:35.960]   So I'm sympathetic towards the like,
[03:11:35.960 --> 03:11:38.360]   okay, well he can't just be here saying stuff like this.
[03:11:38.360 --> 03:11:40.120]   That's insane, we're gonna ban him.
[03:11:40.120 --> 03:11:40.960]   I'm sympathetic.
[03:11:40.960 --> 03:11:44.320]   - Because it's instigating actual physical violence
[03:11:44.320 --> 03:11:45.560]   in the physical world.
[03:11:45.560 --> 03:11:46.960]   - Yeah, like if I were to tweet stuff like that,
[03:11:46.960 --> 03:11:48.720]   I would get banned probably.
[03:11:48.720 --> 03:11:51.400]   On the flip side, this is the President of the United States.
[03:11:51.400 --> 03:11:53.560]   It seems like he's like doing presidential decree
[03:11:53.560 --> 03:11:55.200]   by social media sometimes.
[03:11:55.200 --> 03:11:58.120]   Like is it really right that one public or private,
[03:11:58.120 --> 03:12:01.620]   I should say, one private company can like erase
[03:12:01.620 --> 03:12:03.220]   the President of the United States words
[03:12:03.220 --> 03:12:04.740]   from the eyes of a lot of Americans
[03:12:04.740 --> 03:12:06.940]   that are using these social media feeds?
[03:12:06.940 --> 03:12:10.860]   - And one big one, which I for sure am against,
[03:12:10.860 --> 03:12:12.660]   is the permanent ban.
[03:12:12.660 --> 03:12:13.960]   - Yeah, I don't like that, I hate that.
[03:12:13.960 --> 03:12:15.620]   Even in my community, if somebody comes back
[03:12:15.620 --> 03:12:17.580]   after like a year, like I mean--
[03:12:17.580 --> 03:12:18.580]   - Did you just compare yourself
[03:12:18.580 --> 03:12:19.940]   to the President of the United States?
[03:12:19.940 --> 03:12:20.820]   - No, I compare myself to Twitter
[03:12:20.820 --> 03:12:22.140]   banning the President of the United States.
[03:12:22.140 --> 03:12:23.660]   Let me put it this way, if I ban Donald Trump
[03:12:23.660 --> 03:12:26.100]   in my chat room, I'd unban him in a year.
[03:12:26.100 --> 03:12:27.300]   - A year? - Yeah.
[03:12:27.300 --> 03:12:29.520]   - What's the process for unbanning Donald Trump?
[03:12:29.520 --> 03:12:31.000]   What would he have to do?
[03:12:31.000 --> 03:12:32.120]   - Usually people send me an email,
[03:12:32.120 --> 03:12:33.420]   and they're like, "Listen, I did this stuff.
[03:12:33.420 --> 03:12:34.460]   "I'm sorry I was dumb.
[03:12:34.460 --> 03:12:35.680]   "I'll give him another chance."
[03:12:35.680 --> 03:12:38.620]   - But a year, what if they send an email a month later?
[03:12:38.620 --> 03:12:39.740]   - Usually I'll unban him.
[03:12:39.740 --> 03:12:40.580]   That's usually my policy.
[03:12:40.580 --> 03:12:41.620]   I ban pretty quickly in my community,
[03:12:41.620 --> 03:12:42.460]   but if you ever ask me to come back--
[03:12:42.460 --> 03:12:43.460]   - You're a big softie.
[03:12:43.460 --> 03:12:45.080]   - Yeah, I usually let him back, yeah.
[03:12:45.080 --> 03:12:47.160]   Well, because I used to be the worst type
[03:12:47.160 --> 03:12:49.600]   of internet person, and I think I'm a little bit better
[03:12:49.600 --> 03:12:50.440]   than I used to be, so.
[03:12:50.440 --> 03:12:51.340]   - Now that you're older.
[03:12:51.340 --> 03:12:53.680]   - Yeah, now that I've matured, yeah, of course.
[03:12:53.680 --> 03:12:56.660]   Age bestows a wisdom that just can't be gotten any other way.
[03:12:56.660 --> 03:12:57.860]   - What's your sense in general?
[03:12:57.860 --> 03:12:59.460]   Is there something interesting you could say
[03:12:59.460 --> 03:13:01.240]   about your view on free speech?
[03:13:01.240 --> 03:13:02.500]   It seems like one of those terms
[03:13:02.500 --> 03:13:05.780]   that's also overused to mean a lot of different things.
[03:13:05.780 --> 03:13:06.860]   What does it mean to you?
[03:13:06.860 --> 03:13:09.980]   - If you have a democratic style of governance,
[03:13:09.980 --> 03:13:13.540]   you are entrusting people with one of the most awesome
[03:13:13.540 --> 03:13:15.180]   and radical of responsibilities,
[03:13:15.180 --> 03:13:17.220]   and that's saying that you're going to pick the people
[03:13:17.220 --> 03:13:18.820]   that are gonna make some of the hardest decisions
[03:13:18.820 --> 03:13:20.060]   in all of human history.
[03:13:20.060 --> 03:13:22.780]   If you're gonna trust people to vote correctly,
[03:13:22.780 --> 03:13:24.040]   you have to be able to trust them
[03:13:24.040 --> 03:13:25.860]   to have open and honest dialogue with each other.
[03:13:25.860 --> 03:13:29.560]   Whether that's Nazis or KKK people or whoever talking,
[03:13:29.560 --> 03:13:31.540]   you have to believe that your people
[03:13:31.540 --> 03:13:32.920]   are going to be able to rise above
[03:13:32.920 --> 03:13:34.420]   and make the correct determinations
[03:13:34.420 --> 03:13:36.180]   when they hear these types of speeches.
[03:13:36.180 --> 03:13:38.840]   And if you're so worried that somebody's gonna hear
[03:13:38.840 --> 03:13:39.940]   a certain political figure,
[03:13:39.940 --> 03:13:42.100]   and they're gonna be completely radicalized instantly,
[03:13:42.100 --> 03:13:44.200]   then what that tells me is that you don't have enough faith
[03:13:44.200 --> 03:13:46.820]   in humans for democracy to be a viable institution,
[03:13:46.820 --> 03:13:47.800]   which is fine.
[03:13:47.800 --> 03:13:49.140]   You can be anti-democratic,
[03:13:49.140 --> 03:13:50.980]   but I don't think you can be pro-democracy
[03:13:50.980 --> 03:13:52.720]   and anti-free speech.
[03:13:52.720 --> 03:13:53.900]   Within reason.
[03:13:53.900 --> 03:13:55.420]   - So what's the within reason?
[03:13:55.420 --> 03:13:57.300]   - So I mean, you can't post like child porn
[03:13:57.300 --> 03:13:58.140]   or something on Twitter
[03:13:58.140 --> 03:13:59.460]   or people try to get you on that stuff.
[03:13:59.460 --> 03:14:01.540]   Or like direct calls to violence are probably not,
[03:14:01.540 --> 03:14:02.380]   you shouldn't be tweeting out like,
[03:14:02.380 --> 03:14:03.940]   "We're gonna meet up tomorrow and go bomb, blah, blah, blah."
[03:14:03.940 --> 03:14:04.780]   Probably not.
[03:14:04.780 --> 03:14:06.300]   - So do you think it's okay to allow racism
[03:14:06.300 --> 03:14:09.700]   and antisemitism and hate speech?
[03:14:09.700 --> 03:14:12.660]   - Hate speech, yes,
[03:14:12.660 --> 03:14:15.300]   because that can be very broadly defined.
[03:14:15.300 --> 03:14:17.700]   I can understand there being some basic rules
[03:14:17.700 --> 03:14:20.300]   of like no slurs on like a platform
[03:14:20.300 --> 03:14:22.580]   that gets into like acceptable forms of moderation
[03:14:22.580 --> 03:14:24.440]   or like excessive harassment and bullying,
[03:14:24.440 --> 03:14:25.860]   I can understand.
[03:14:25.860 --> 03:14:29.940]   But past that, when the moderation becomes ideological,
[03:14:29.940 --> 03:14:31.080]   I get a little bit nervous
[03:14:31.080 --> 03:14:33.900]   because there's a whole other host.
[03:14:33.900 --> 03:14:36.080]   - Yeah, of course it's all a gray area,
[03:14:36.080 --> 03:14:38.460]   but when it feels like ideology
[03:14:38.460 --> 03:14:40.880]   has seeped into the censorship, not good.
[03:14:40.880 --> 03:14:43.880]   Yeah, which it's so fascinating to think,
[03:14:43.880 --> 03:14:45.640]   especially now that Elon bought Twitter,
[03:14:45.640 --> 03:14:48.600]   how do you engineer a system
[03:14:48.600 --> 03:14:52.200]   that prevents ideology from seeping in
[03:14:52.200 --> 03:14:55.600]   and nevertheless is able to create a platform
[03:14:55.600 --> 03:14:57.480]   that has healthy conversations?
[03:14:57.480 --> 03:14:58.360]   'Cause if you have one guy
[03:14:58.360 --> 03:15:00.680]   who's just screaming nonsense nonstop,
[03:15:00.680 --> 03:15:04.340]   it has this effect where the quiet voices
[03:15:04.340 --> 03:15:06.480]   at the back of the room are silenced.
[03:15:06.480 --> 03:15:09.040]   So like, that's what you usually don't talk about.
[03:15:09.040 --> 03:15:12.200]   Like if you let one annoying, loud person in,
[03:15:12.200 --> 03:15:14.360]   that's actually censoring the voice of a lot of people
[03:15:14.360 --> 03:15:16.420]   that would like to speak, but they don't get a chance.
[03:15:16.420 --> 03:15:17.260]   - That's one of the things,
[03:15:17.260 --> 03:15:18.920]   especially around like trans discourse,
[03:15:18.920 --> 03:15:21.800]   I have to constantly do that like reminder for my audience
[03:15:21.800 --> 03:15:23.560]   is like when I'm dealing with these types of people
[03:15:23.560 --> 03:15:25.520]   on the internet, a lot of them might seem really crazy.
[03:15:25.520 --> 03:15:27.040]   A lot of these types of people might seem insane,
[03:15:27.040 --> 03:15:28.160]   but like in the real world,
[03:15:28.160 --> 03:15:30.400]   outside of like the crazy Twitter activist world,
[03:15:30.400 --> 03:15:32.400]   like the vast majority of people you're meeting
[03:15:32.400 --> 03:15:34.400]   from LGBT communities are like the coolest,
[03:15:34.400 --> 03:15:35.280]   normalest people.
[03:15:35.280 --> 03:15:37.080]   All they want is the like right to live their life
[03:15:37.080 --> 03:15:39.040]   in the way they want to and to be like unobstructed
[03:15:39.040 --> 03:15:40.040]   and like, yeah.
[03:15:40.040 --> 03:15:41.440]   But people will get this impression
[03:15:41.440 --> 03:15:42.760]   of like an online activist,
[03:15:42.760 --> 03:15:45.320]   like a vegan or LGBT person or whatever.
[03:15:45.320 --> 03:15:46.720]   And then they think that every single person
[03:15:46.720 --> 03:15:47.640]   in real life is like that
[03:15:47.640 --> 03:15:49.920]   and it's a really negative stereotype.
[03:15:49.920 --> 03:15:52.360]   And then even the other people in that group.
[03:15:52.360 --> 03:15:53.720]   - Oh, is Melina coming over?
[03:15:53.720 --> 03:15:55.400]   - Oh yeah, I asked her, I don't know if that's her.
[03:15:55.400 --> 03:15:57.400]   - Okay, Melina just joined us.
[03:15:57.400 --> 03:15:58.760]   What were we talking about?
[03:15:58.760 --> 03:15:59.680]   Was it interesting?
[03:15:59.680 --> 03:16:02.400]   - You were saying that you were gonna talk to Elon
[03:16:02.400 --> 03:16:04.080]   about getting @OmniDestiny,
[03:16:04.080 --> 03:16:05.360]   the verified Twitter account unbanned.
[03:16:05.360 --> 03:16:06.180]   I said, that's so-
[03:16:06.180 --> 03:16:07.020]   - That sounds like a lie.
[03:16:07.020 --> 03:16:07.840]   - That's so gracious of you.
[03:16:07.840 --> 03:16:09.640]   I can't even believe you would do that for me.
[03:16:09.640 --> 03:16:12.120]   - And then you admitted that you tried to evade the ban
[03:16:12.120 --> 03:16:15.320]   multiple times, which I'm sure would be very looked upon.
[03:16:15.320 --> 03:16:16.600]   - You know, I heard that in Norway,
[03:16:16.600 --> 03:16:17.520]   in their prison system,
[03:16:17.520 --> 03:16:19.320]   they don't actually punish you for trying to escape jail
[03:16:19.320 --> 03:16:20.880]   'cause that's like the natural human thing to do.
[03:16:20.880 --> 03:16:21.720]   - They hug you?
[03:16:21.720 --> 03:16:22.540]   What do they do?
[03:16:22.540 --> 03:16:23.380]   - I don't know if they, but they don't punish you
[03:16:23.380 --> 03:16:24.480]   'cause of course you're trying to be free.
[03:16:24.480 --> 03:16:25.680]   That's all I'm trying to be on Twitter.
[03:16:25.680 --> 03:16:26.520]   I'm just trying to be free.
[03:16:26.520 --> 03:16:27.960]   - Oh, that's the natural humanistic-
[03:16:27.960 --> 03:16:30.120]   - Yeah, that's the natural, of course, it's the banning of it.
[03:16:30.120 --> 03:16:31.560]   - You're not a destructive force, you're just-
[03:16:31.560 --> 03:16:33.200]   - No, I'm a force for good.
[03:16:33.200 --> 03:16:34.280]   That's why all my accounts only get banned
[03:16:34.280 --> 03:16:35.120]   for banning and evading.
[03:16:35.120 --> 03:16:36.320]   I don't get banned for doing bad things.
[03:16:36.320 --> 03:16:37.440]   And I'm a progressive show.
[03:16:37.440 --> 03:16:38.740]   I'm like far left.
[03:16:38.740 --> 03:16:40.840]   I love like progressive causes.
[03:16:40.840 --> 03:16:43.760]   - I thought this is what you criticized Hasan for being.
[03:16:43.760 --> 03:16:45.640]   - I show them from a place of first principles,
[03:16:45.640 --> 03:16:48.640]   not from a mindless AI echoing kind of thing.
[03:16:48.640 --> 03:16:50.840]   - Okay, so you're a free thinking bot.
[03:16:50.840 --> 03:16:51.920]   - Yeah, exactly.
[03:16:51.920 --> 03:16:52.920]   - All right, cool.
[03:16:52.920 --> 03:16:54.560]   Well, I'm sure we'll return to some politics.
[03:16:54.560 --> 03:16:55.520]   That was beautiful.
[03:16:55.520 --> 03:16:59.280]   Malia, can you tell us about yourself?
[03:16:59.280 --> 03:17:00.760]   You're also a fellow streamer.
[03:17:00.760 --> 03:17:01.600]   - Yes. - What's your story?
[03:17:01.600 --> 03:17:03.040]   - I stream and I started streaming
[03:17:03.040 --> 03:17:05.400]   because I met him basically, kind of,
[03:17:05.400 --> 03:17:06.840]   but I don't do the politics.
[03:17:06.840 --> 03:17:10.000]   I do like travels or talk about relationships,
[03:17:10.000 --> 03:17:12.480]   talk to my audience basically.
[03:17:12.480 --> 03:17:14.040]   - You're from that part of the world, right?
[03:17:14.040 --> 03:17:14.880]   Sweden? - Yeah, exactly.
[03:17:14.880 --> 03:17:17.120]   - So did you escape from prison and they didn't?
[03:17:17.120 --> 03:17:17.960]   - That was Norway.
[03:17:17.960 --> 03:17:19.160]   You just went to Norway.
[03:17:19.160 --> 03:17:20.000]   - It's different?
[03:17:20.000 --> 03:17:20.840]   - It's a different.
[03:17:20.840 --> 03:17:22.840]   - I actually really, I've been to Sweden a bunch of times.
[03:17:22.840 --> 03:17:23.680]   I love it.
[03:17:23.680 --> 03:17:26.760]   There's a tech sector there that's really like flourishing.
[03:17:26.760 --> 03:17:27.680]   - Where did you go?
[03:17:27.680 --> 03:17:28.520]   Which city?
[03:17:28.520 --> 03:17:29.440]   - I went to Stockholm.
[03:17:29.440 --> 03:17:30.860]   I think I gave a few lectures there.
[03:17:30.860 --> 03:17:33.040]   There's a vibrant tech sector, it was cool.
[03:17:33.040 --> 03:17:34.920]   And people are super nice.
[03:17:34.920 --> 03:17:36.640]   - Yeah, we're friendly.
[03:17:36.640 --> 03:17:37.960]   We're not like very deep.
[03:17:37.960 --> 03:17:39.720]   Like we don't really have much deep conversation.
[03:17:39.720 --> 03:17:40.720]   It's like a meta conversation.
[03:17:40.720 --> 03:17:43.480]   - Oh, there's not many intellectuals that come from Sweden?
[03:17:43.480 --> 03:17:45.120]   - We don't really speak very highly of ourselves.
[03:17:45.120 --> 03:17:46.920]   We're kind of like just chill all the time.
[03:17:46.920 --> 03:17:47.920]   We don't make a scene.
[03:17:47.920 --> 03:17:50.560]   We don't, we're just like, you know.
[03:17:50.560 --> 03:17:51.560]   - Do you know what the name for that is?
[03:17:51.560 --> 03:17:52.880]   There's a specific name for it.
[03:17:52.880 --> 03:17:53.840]   - Jantelagen.
[03:17:53.840 --> 03:17:54.680]   - Yeah, Jantelagen.
[03:17:54.680 --> 03:17:55.840]   - Yeah, Jantelagen, yeah.
[03:17:55.840 --> 03:17:57.320]   - Oh, there's a philosophy behind it.
[03:17:57.320 --> 03:17:58.920]   - When you're part of like Sweden or Norway,
[03:17:58.920 --> 03:18:00.720]   you don't talk too highly of yourself
[03:18:00.720 --> 03:18:01.960]   'cause it's seen as kind of like rude.
[03:18:01.960 --> 03:18:04.240]   Like think of like America, except the exact opposite.
[03:18:04.240 --> 03:18:05.160]   - You don't even really wanna like,
[03:18:05.160 --> 03:18:07.120]   you don't wanna make yourself into a victim too much.
[03:18:07.120 --> 03:18:08.440]   You don't wanna be too much of anything.
[03:18:08.440 --> 03:18:10.480]   You're just like sticking to the group.
[03:18:10.480 --> 03:18:12.880]   Don't make big scene about yourself.
[03:18:12.880 --> 03:18:16.160]   - But that said, you came here and you were,
[03:18:16.160 --> 03:18:18.720]   you put yourself in front of a camera and became a streamer.
[03:18:18.720 --> 03:18:19.880]   - Yeah, do you understand how weird that is
[03:18:19.880 --> 03:18:21.840]   for my friends in Sweden?
[03:18:21.840 --> 03:18:22.680]   - Do you have anxiety?
[03:18:22.680 --> 03:18:23.840]   - I just didn't talk about myself
[03:18:23.840 --> 03:18:25.640]   and just like make a big deal about myself
[03:18:25.640 --> 03:18:26.480]   for hours every day.
[03:18:26.480 --> 03:18:27.560]   - Was that like terrifying?
[03:18:27.560 --> 03:18:28.760]   Did you have anxiety about that?
[03:18:28.760 --> 03:18:30.000]   - No, 'cause I don't see them,
[03:18:30.000 --> 03:18:31.800]   but then I come back and I'm like, ooh.
[03:18:31.800 --> 03:18:32.640]   (laughs)
[03:18:32.640 --> 03:18:34.720]   - Also, what do you feel like when you're actually streaming?
[03:18:34.720 --> 03:18:37.080]   You feel like you're just alone in a room?
[03:18:37.080 --> 03:18:37.920]   One-on-one type thing?
[03:18:37.920 --> 03:18:40.040]   - No, I see Chad and I'm thinking,
[03:18:40.040 --> 03:18:41.120]   oh, they're like little fairies.
[03:18:41.120 --> 03:18:41.960]   They're not really real.
[03:18:41.960 --> 03:18:42.780]   They're just like out there.
[03:18:42.780 --> 03:18:43.620]   I don't know what they look like.
[03:18:43.620 --> 03:18:46.080]   I just see little names and they're just cute.
[03:18:46.080 --> 03:18:46.920]   Colors, you know?
[03:18:46.920 --> 03:18:48.520]   - You're talking to little fairies inside your head.
[03:18:48.520 --> 03:18:49.360]   - Yes, I do.
[03:18:49.360 --> 03:18:50.680]   - Is that how you feel about Chad?
[03:18:50.680 --> 03:18:51.640]   - They're demons for me.
[03:18:51.640 --> 03:18:52.480]   - They're demons?
[03:18:52.480 --> 03:18:54.080]   Okay, my Anna fairies.
[03:18:54.080 --> 03:18:56.440]   - Are they, so is Chad a source of stress or happiness?
[03:18:56.440 --> 03:18:57.280]   Like, is there a--
[03:18:57.280 --> 03:18:58.840]   - No, for me, it's a source of happiness.
[03:18:58.840 --> 03:19:01.080]   I've been very intentional with like the construction
[03:19:01.080 --> 03:19:03.360]   of my community, so I'm really happy with where it's at.
[03:19:03.360 --> 03:19:06.040]   - How are you able to actually have deep political discourse
[03:19:06.040 --> 03:19:08.240]   while playing a video game at the same time?
[03:19:08.240 --> 03:19:10.120]   - I have a really good chat room
[03:19:10.120 --> 03:19:10.960]   in terms of like the way
[03:19:10.960 --> 03:19:12.200]   that people engage in conversations.
[03:19:12.200 --> 03:19:14.100]   Like, I was one of the earliest people
[03:19:14.100 --> 03:19:16.560]   to embrace the philosophy of like,
[03:19:16.560 --> 03:19:19.620]   I am in total control of what people watch me think,
[03:19:19.620 --> 03:19:22.120]   that like I have a high level of responsibility
[03:19:22.120 --> 03:19:23.520]   for how they conduct themselves,
[03:19:23.520 --> 03:19:25.120]   and that if I conduct myself in a certain way,
[03:19:25.120 --> 03:19:26.880]   I can expect a certain level of conduct from them.
[03:19:26.880 --> 03:19:28.240]   And for the most part, it's like worked pretty well
[03:19:28.240 --> 03:19:30.920]   for the past, you know, nine or 10 years, yeah.
[03:19:30.920 --> 03:19:32.760]   - What about the actual playing of the game?
[03:19:32.760 --> 03:19:35.640]   Like, you're able to parallelize the brain, like--
[03:19:35.640 --> 03:19:36.480]   - Oh.
[03:19:36.480 --> 03:19:37.840]   - Like it seems, like "Factory" seems
[03:19:37.840 --> 03:19:39.120]   like a super complex game.
[03:19:39.120 --> 03:19:40.560]   - Yeah, I don't actually think that's possible.
[03:19:40.560 --> 03:19:43.320]   I don't think multitasking for a human brain is possible.
[03:19:43.320 --> 03:19:44.680]   If you see me playing a game,
[03:19:44.680 --> 03:19:47.020]   usually what's happening is the conversation is like,
[03:19:47.020 --> 03:19:48.880]   I've had it a million times, so I'm not thinking about it.
[03:19:48.880 --> 03:19:49.860]   I've automated that.
[03:19:49.860 --> 03:19:52.360]   Or if the conversation is very challenging,
[03:19:52.360 --> 03:19:53.200]   then if you watch me,
[03:19:53.200 --> 03:19:54.320]   if you really watch what's happening,
[03:19:54.320 --> 03:19:55.360]   I'm probably just running around in circles
[03:19:55.360 --> 03:19:56.800]   'cause I have to think about the conversation.
[03:19:56.800 --> 03:19:58.320]   - Okay, because with "Factory,"
[03:19:58.320 --> 03:19:59.760]   it looks like a lot of stuff is going on.
[03:19:59.760 --> 03:20:00.600]   - Sometimes, yeah.
[03:20:00.600 --> 03:20:03.920]   - So it's hard for a person who hasn't played the game
[03:20:03.920 --> 03:20:04.760]   to detect that you're not actually--
[03:20:04.760 --> 03:20:05.680]   - Does that come off as like,
[03:20:05.680 --> 03:20:07.360]   you're super intelligent and multitask?
[03:20:07.360 --> 03:20:08.520]   Or does it come off as like,
[03:20:08.520 --> 03:20:10.520]   he's not interested in this conversation at all?
[03:20:10.520 --> 03:20:11.360]   - Yeah.
[03:20:11.360 --> 03:20:12.600]   - Yeah, there's a coolness to it,
[03:20:12.600 --> 03:20:14.160]   like when you're not paying attention.
[03:20:14.160 --> 03:20:17.120]   Like, if you're looking elsewhere,
[03:20:17.120 --> 03:20:18.180]   like you're checking your phone,
[03:20:18.180 --> 03:20:19.560]   you're too cool for this conversation.
[03:20:19.560 --> 03:20:20.400]   There is a sense like that.
[03:20:20.400 --> 03:20:22.280]   - Yeah, the reality is though, is if you watch,
[03:20:22.280 --> 03:20:23.760]   it was easier to see in "Minecraft,"
[03:20:23.760 --> 03:20:24.580]   'cause in "Minecraft,"
[03:20:24.580 --> 03:20:25.640]   when there was a challenging conversation,
[03:20:25.640 --> 03:20:26.480]   if you watch me play,
[03:20:26.480 --> 03:20:28.240]   I'm literally just running around and jumping in circles
[03:20:28.240 --> 03:20:30.040]   'cause I have to think about the conversation 100%.
[03:20:30.040 --> 03:20:31.280]   I can't do a complicated task
[03:20:31.280 --> 03:20:32.780]   and think about the conversation.
[03:20:32.780 --> 03:20:34.420]   Or like, the people always joke in my chat,
[03:20:34.420 --> 03:20:35.960]   like, oh no, the notepad came out.
[03:20:35.960 --> 03:20:37.440]   If it's a really challenging conversation,
[03:20:37.440 --> 03:20:39.280]   I'll get rid of the game and I'll bring out a notepad
[03:20:39.280 --> 03:20:40.200]   and I'll start writing stuff down
[03:20:40.200 --> 03:20:42.160]   to keep track of what's going on, yeah.
[03:20:42.160 --> 03:20:44.080]   - So what kind of stuff do you stream?
[03:20:44.080 --> 03:20:45.560]   So advice, you talk about--
[03:20:45.560 --> 03:20:46.800]   - Yeah, like either I talk to chat
[03:20:46.800 --> 03:20:48.920]   or I travel around, basically.
[03:20:48.920 --> 03:20:52.960]   Like, have conversations or we like, go to countries.
[03:20:52.960 --> 03:20:54.080]   I've been to like Italy.
[03:20:54.080 --> 03:20:56.480]   I was in Italy for like one and a half months,
[03:20:56.480 --> 03:20:58.320]   just like traveling around alone,
[03:20:58.320 --> 03:21:01.560]   going to cities, like having like my camera with me
[03:21:01.560 --> 03:21:03.740]   and like streaming for hours.
[03:21:03.740 --> 03:21:06.080]   - Where's the coolest place you've been to?
[03:21:06.080 --> 03:21:06.920]   - Ever?
[03:21:06.920 --> 03:21:08.160]   It's probably New Zealand.
[03:21:08.160 --> 03:21:09.000]   - New Zealand?
[03:21:09.000 --> 03:21:09.840]   - I think so.
[03:21:09.840 --> 03:21:11.600]   After that, it's probably gonna be Italy, I think.
[03:21:11.600 --> 03:21:13.320]   Because I like history and yeah.
[03:21:13.320 --> 03:21:16.640]   - Oh, so both history, 'cause New Zealand is also beautiful.
[03:21:16.640 --> 03:21:19.760]   So it's both natural beauty and historical beauty.
[03:21:19.760 --> 03:21:21.120]   - Yeah, for sure.
[03:21:21.120 --> 03:21:23.840]   I think I just really like the Polynesian sort of culture.
[03:21:23.840 --> 03:21:25.120]   I think it's very interesting.
[03:21:25.120 --> 03:21:27.720]   Like the ocean people and it's just really beautiful.
[03:21:27.720 --> 03:21:28.880]   People are very relaxed, chill.
[03:21:28.880 --> 03:21:31.800]   They're very far away, which is interesting as well
[03:21:31.800 --> 03:21:33.480]   'cause whenever they talk about politics
[03:21:33.480 --> 03:21:36.720]   or they talk about just like the world,
[03:21:36.720 --> 03:21:38.560]   it feels really far away.
[03:21:38.560 --> 03:21:39.680]   - So where's home for you?
[03:21:39.680 --> 03:21:40.640]   Is Austin home?
[03:21:40.640 --> 03:21:43.160]   - It's home for me.
[03:21:43.160 --> 03:21:45.080]   - So a human being is home?
[03:21:45.080 --> 03:21:45.920]   - Yeah.
[03:21:45.920 --> 03:21:47.000]   - We've lived in a lot of different places
[03:21:47.000 --> 03:21:47.840]   and traveled around a lot.
[03:21:47.840 --> 03:21:50.160]   So that's what you think of home is like humans?
[03:21:50.160 --> 03:21:52.000]   - I think so, yeah.
[03:21:52.000 --> 03:21:53.840]   I mean, if there's gonna be a place,
[03:21:53.840 --> 03:21:57.200]   it's probably gonna be like my childhood places probably.
[03:21:57.200 --> 03:21:58.040]   - Yeah.
[03:21:58.040 --> 03:21:59.560]   - Like my old country house or something like that.
[03:21:59.560 --> 03:22:00.400]   We don't have it anymore,
[03:22:00.400 --> 03:22:03.240]   but like that's like home for me, I guess.
[03:22:03.240 --> 03:22:05.080]   - So how'd you guys meet each other?
[03:22:05.080 --> 03:22:06.520]   You're currently married.
[03:22:06.520 --> 03:22:07.520]   - Yes.
[03:22:07.520 --> 03:22:08.360]   - To each other, yeah.
[03:22:08.360 --> 03:22:09.200]   - Yeah.
[03:22:09.200 --> 03:22:10.020]   - To each other.
[03:22:10.020 --> 03:22:11.880]   (laughing)
[03:22:11.880 --> 03:22:13.560]   - Just making sure we're on the same page.
[03:22:13.560 --> 03:22:14.520]   - All right, cool.
[03:22:14.520 --> 03:22:15.880]   How'd you guys meet?
[03:22:15.880 --> 03:22:19.840]   - I was watching his YouTube stuff like 2018, I think,
[03:22:19.840 --> 03:22:21.940]   like because it was the Swedish election around that time
[03:22:21.940 --> 03:22:23.680]   and I was interested in politics.
[03:22:23.680 --> 03:22:27.400]   And then I think he said in one of his videos
[03:22:27.400 --> 03:22:28.880]   that he had an Instagram
[03:22:28.880 --> 03:22:31.360]   and that he needed people to stop DMing him
[03:22:31.360 --> 03:22:32.640]   that wasn't PewDiePie's.
[03:22:32.640 --> 03:22:34.080]   And then I messaged him and said,
[03:22:34.080 --> 03:22:35.360]   "Am I PewDiePie?"
[03:22:35.360 --> 03:22:38.080]   And then you replied in like two minutes.
[03:22:38.080 --> 03:22:41.360]   And then that's when I was in New Zealand.
[03:22:41.360 --> 03:22:44.440]   And I guess you wanted to escape America
[03:22:44.440 --> 03:22:48.240]   or like LA for a little bit and then flew to New Zealand.
[03:22:48.240 --> 03:22:50.680]   - Where were you mentally there?
[03:22:50.680 --> 03:22:52.560]   'Cause we've talked through this timeline.
[03:22:52.560 --> 03:22:54.120]   Where's 2018?
[03:22:54.120 --> 03:22:55.800]   - Was it 18, 19?
[03:22:55.800 --> 03:22:57.520]   - Where was the low point?
[03:22:57.520 --> 03:22:58.560]   Or that was way earlier?
[03:22:58.560 --> 03:23:02.000]   - Low point, carpet cleaning, that was like 2010.
[03:23:02.000 --> 03:23:02.840]   - Oh, okay.
[03:23:02.840 --> 03:23:04.280]   - 2018 was probably your peak.
[03:23:04.280 --> 03:23:06.520]   - Every day now is my peak.
[03:23:06.520 --> 03:23:07.360]   What do you mean?
[03:23:07.360 --> 03:23:08.180]   That was my peak.
[03:23:08.180 --> 03:23:09.020]   Why would you say that?
[03:23:09.020 --> 03:23:09.840]   - You've been through that, okay?
[03:23:09.840 --> 03:23:11.840]   - Nobody ever admits being past their prime.
[03:23:11.840 --> 03:23:13.040]   Just so you know.
[03:23:13.040 --> 03:23:15.000]   - Well, I mean, my prime is still coming up.
[03:23:15.000 --> 03:23:16.240]   - It was probably around the time
[03:23:16.240 --> 03:23:18.720]   where you were getting a lot of lefties through your community
[03:23:18.720 --> 03:23:20.240]   and you were really like thinking about
[03:23:20.240 --> 03:23:21.400]   that they would go too far.
[03:23:21.400 --> 03:23:22.240]   - Maybe.
[03:23:22.240 --> 03:23:23.480]   I think that was still when Hasan and Vosh
[03:23:23.480 --> 03:23:24.440]   were both in my community.
[03:23:24.440 --> 03:23:25.280]   - Exactly.
[03:23:25.280 --> 03:23:27.360]   So I would say it feels like there was not really
[03:23:27.360 --> 03:23:30.240]   like much issues when it comes to your stuff
[03:23:30.240 --> 03:23:31.640]   or like your work stuff back then.
[03:23:31.640 --> 03:23:33.520]   - Oh, something we didn't talk about is that like,
[03:23:33.520 --> 03:23:34.840]   there were no politics on Twitch.
[03:23:34.840 --> 03:23:37.600]   I exclusively inhabited that place for like two years
[03:23:37.600 --> 03:23:38.420]   'cause nobody else did it.
[03:23:38.420 --> 03:23:40.160]   'Cause it was a really toxic environment for politics.
[03:23:40.160 --> 03:23:42.120]   So for a couple of years as it grew,
[03:23:42.120 --> 03:23:43.800]   like I kind of grew the whole space
[03:23:43.800 --> 03:23:44.960]   'cause it wasn't, nobody was doing it yet.
[03:23:44.960 --> 03:23:45.800]   - What did that look like?
[03:23:45.800 --> 03:23:49.840]   You're having like political debates, political discourse.
[03:23:49.840 --> 03:23:51.880]   - Yeah, mainly like going into YouTube people
[03:23:51.880 --> 03:23:54.080]   to try to argue with them or just doing politics on stream,
[03:23:54.080 --> 03:23:55.560]   like reading stories, researching stuff,
[03:23:55.560 --> 03:23:56.520]   talking about stuff.
[03:23:56.520 --> 03:23:57.960]   But there's not like other people on Twitch
[03:23:57.960 --> 03:24:00.120]   to debate about politics 'cause there was no politics.
[03:24:00.120 --> 03:24:01.000]   It was, yeah.
[03:24:01.000 --> 03:24:04.000]   - Was there a debate in the space of communism,
[03:24:04.000 --> 03:24:07.360]   socialism, social Democrats, kind of like this?
[03:24:07.360 --> 03:24:09.000]   Are you trying to outline your own position
[03:24:09.000 --> 03:24:09.840]   during that time?
[03:24:09.840 --> 03:24:11.960]   - I think it was mainly me fighting against conservatives
[03:24:11.960 --> 03:24:13.200]   'cause it was like Trump stuff.
[03:24:13.200 --> 03:24:14.860]   And then it was coming off the back of like,
[03:24:14.860 --> 03:24:16.400]   there was this movement called Gamergate
[03:24:16.400 --> 03:24:18.760]   and there was all this anti-SJW stuff on the internet.
[03:24:18.760 --> 03:24:21.000]   And I was like the SJW, like the progressive
[03:24:21.000 --> 03:24:22.920]   that was fighting on the progressive side of things.
[03:24:22.920 --> 03:24:24.080]   So I think that's what I was known for.
[03:24:24.080 --> 03:24:25.540]   But I was fighting with people off of Twitch
[03:24:25.540 --> 03:24:26.380]   'cause on Twitch,
[03:24:26.380 --> 03:24:28.240]   there weren't very many political discussions happening.
[03:24:28.240 --> 03:24:30.880]   - So you were holding the SJW flag.
[03:24:30.880 --> 03:24:31.720]   - Yeah.
[03:24:31.720 --> 03:24:34.360]   - To what degree do you still hold it?
[03:24:34.360 --> 03:24:37.240]   Like what's the best, what's the steel man case for SJW?
[03:24:37.240 --> 03:24:40.680]   - I mean, like I'm still very much that SJW from 2018, 2019,
[03:24:40.680 --> 03:24:42.880]   but the positions have moved so much farther left
[03:24:42.880 --> 03:24:45.080]   that some people might not call me that anymore.
[03:24:45.080 --> 03:24:45.900]   I'm not sure.
[03:24:45.900 --> 03:24:46.740]   It depends on who I'm talking to.
[03:24:46.740 --> 03:24:48.800]   - So it's basically, what is social justice?
[03:24:48.800 --> 03:24:51.840]   Were you like being sensitive to the experience of others?
[03:24:51.840 --> 03:24:53.280]   - Yeah, being sensitive and empathetic
[03:24:53.280 --> 03:24:54.220]   towards the experience of others
[03:24:54.220 --> 03:24:55.400]   and then trying to build a better world
[03:24:55.400 --> 03:24:57.000]   that like suits as many different types of people
[03:24:57.000 --> 03:24:59.840]   as possible while being like aware of like their needs.
[03:24:59.840 --> 03:25:00.680]   - Okay.
[03:25:00.680 --> 03:25:04.200]   So you guys met, what's from your perspective?
[03:25:04.200 --> 03:25:06.440]   Is that, is she telling lies?
[03:25:06.440 --> 03:25:07.280]   Is it accurate?
[03:25:07.280 --> 03:25:08.880]   - No, it's pretty accurate.
[03:25:08.880 --> 03:25:11.080]   - Okay, when'd you guys actually meet?
[03:25:11.080 --> 03:25:14.000]   - I flew out in 2019.
[03:25:14.000 --> 03:25:15.400]   - 19, yeah, in like in February.
[03:25:15.400 --> 03:25:17.760]   - Yeah, basically there was like weird stuff happening in LA.
[03:25:17.760 --> 03:25:19.160]   I just come off of kind of a weird,
[03:25:19.160 --> 03:25:21.080]   not kind of sort of relationship.
[03:25:21.080 --> 03:25:22.960]   And I just wanted to like go away for a while.
[03:25:22.960 --> 03:25:24.360]   Another company reached out to me
[03:25:24.360 --> 03:25:25.820]   and they had like a fun streaming device.
[03:25:25.820 --> 03:25:27.400]   And they said they'd sponsor a trip if I went somewhere.
[03:25:27.400 --> 03:25:28.600]   And I was like, oh, well, I know this person.
[03:25:28.600 --> 03:25:30.120]   I know a couple of people in New Zealand.
[03:25:30.120 --> 03:25:30.960]   Melina's one of them.
[03:25:30.960 --> 03:25:31.780]   It's like, I'll go to New Zealand.
[03:25:31.780 --> 03:25:33.000]   New Zealand, it'll be fun.
[03:25:33.000 --> 03:25:34.600]   And yeah, I did that for two weeks.
[03:25:34.600 --> 03:25:36.320]   - Do you guys believe in love?
[03:25:36.320 --> 03:25:41.400]   I feel like you lack the gotcha got us into this.
[03:25:41.400 --> 03:25:44.000]   I'm not sure to the degree to which you have human emotions.
[03:25:44.000 --> 03:25:45.200]   - I have quite a few.
[03:25:45.200 --> 03:25:46.280]   - Okay.
[03:25:46.280 --> 03:25:49.600]   From your perspective, when did you fall in love with Melina?
[03:25:49.600 --> 03:25:52.320]   - When did you fall in love with Meli Mel?
[03:25:52.320 --> 03:25:53.600]   - The minute I saw her.
[03:25:53.600 --> 03:25:57.120]   I don't know, our first two weeks together
[03:25:57.120 --> 03:25:57.960]   were a lot of fun.
[03:25:57.960 --> 03:26:00.440]   We had a lot of chemistry in person.
[03:26:00.440 --> 03:26:02.560]   - I was kind of shocked that I wasn't thinking about it.
[03:26:02.560 --> 03:26:04.440]   'Cause it was like, we spent like a week together
[03:26:04.440 --> 03:26:06.400]   and you said, I really want to tell you something.
[03:26:06.400 --> 03:26:09.120]   And you were like stalling that for the longest time.
[03:26:09.120 --> 03:26:12.200]   - I think she was, oh, she said like, I love you?
[03:26:12.200 --> 03:26:14.400]   - No, he basically just said like,
[03:26:14.400 --> 03:26:16.080]   I really like you and it never really happens.
[03:26:16.080 --> 03:26:16.920]   That's what he said.
[03:26:16.920 --> 03:26:19.840]   And I was like, oh, and I thought, hey, I thought.
[03:26:19.840 --> 03:26:23.480]   - So let's still run, we said Trump getting banned
[03:26:23.480 --> 03:26:25.820]   from Twitter, is that what we were talking about before?
[03:26:25.820 --> 03:26:26.660]   - Oh yeah.
[03:26:26.660 --> 03:26:28.060]   - So you agreed to me coming on here.
[03:26:28.060 --> 03:26:30.400]   Of course I'm gonna be doing this to you.
[03:26:30.400 --> 03:26:32.400]   - So how long did that take, two weeks you said?
[03:26:32.400 --> 03:26:33.240]   - That took like a week.
[03:26:33.240 --> 03:26:34.700]   No, I don't know, I think it was just like.
[03:26:34.700 --> 03:26:37.260]   - Thing is my mind processes like information so quickly.
[03:26:37.260 --> 03:26:40.260]   Two weeks to somebody like you is actually like years for me.
[03:26:40.260 --> 03:26:41.660]   - Oh, like me, yeah.
[03:26:41.660 --> 03:26:44.420]   So there was like a lot of like factorial type
[03:26:44.420 --> 03:26:45.260]   of strategic thinking.
[03:26:45.260 --> 03:26:46.260]   - Yeah, going on.
[03:26:46.260 --> 03:26:48.220]   I was seeing like all the events,
[03:26:48.220 --> 03:26:50.460]   like Dr. Strange or whatever in the Avengers
[03:26:50.460 --> 03:26:51.300]   when he's like seeing into all the futures.
[03:26:51.300 --> 03:26:53.580]   - When you saw me, you just saw the future.
[03:26:53.580 --> 03:26:55.300]   - Yeah, I was looking at all of them, yeah.
[03:26:55.300 --> 03:26:57.660]   - So you're doing like some game theoretic simulation
[03:26:57.660 --> 03:26:58.940]   of all the possible outcomes.
[03:26:58.940 --> 03:26:59.980]   - Yeah, exactly.
[03:26:59.980 --> 03:27:01.300]   - Okay.
[03:27:01.300 --> 03:27:02.900]   - But no, yeah, it was probably pretty soon I realized
[03:27:02.900 --> 03:27:03.740]   that we had a lot of chemistry.
[03:27:03.740 --> 03:27:05.900]   I think before I left after my two weeks there,
[03:27:05.900 --> 03:27:07.500]   I was like, we need to make sure you get like a ticket
[03:27:07.500 --> 03:27:08.700]   to come visit me in the United States
[03:27:08.700 --> 03:27:09.540]   'cause it'll be fun and everything.
[03:27:09.540 --> 03:27:11.860]   - And I kind of decided that last minute too.
[03:27:11.860 --> 03:27:14.620]   It was like really like five hours before your flight back.
[03:27:14.620 --> 03:27:17.100]   We kind of realized because it was kind of like men
[03:27:17.100 --> 03:27:19.540]   is just like a one time thing and then that was it.
[03:27:19.540 --> 03:27:20.860]   But we're like, oh no, this is a lot of fun.
[03:27:20.860 --> 03:27:21.700]   We should probably hang out again.
[03:27:21.700 --> 03:27:24.540]   - Oh, so you realized you would miss each other.
[03:27:24.540 --> 03:27:25.380]   - Yeah.
[03:27:25.380 --> 03:27:26.220]   - Yeah, yeah.
[03:27:26.220 --> 03:27:27.040]   - This was a one time thing.
[03:27:27.040 --> 03:27:27.880]   The melancholy side of love.
[03:27:27.880 --> 03:27:29.700]   Okay, when did you fall in love with Steven?
[03:27:29.700 --> 03:27:30.980]   - I thought he like hated me.
[03:27:30.980 --> 03:27:32.780]   I don't know, I thought, not hated me.
[03:27:32.780 --> 03:27:33.620]   - She still thinks I hate her.
[03:27:33.620 --> 03:27:37.420]   - But no, no, I remember like when he said
[03:27:37.420 --> 03:27:39.940]   that he really liked me, I was a little shocked about that
[03:27:39.940 --> 03:27:42.900]   'cause I don't know, there was a lot of like random things
[03:27:42.900 --> 03:27:43.740]   happening in New Zealand.
[03:27:43.740 --> 03:27:45.460]   It was a lot of fun, but it was definitely
[03:27:45.460 --> 03:27:48.300]   like very interesting like things that happened
[03:27:48.300 --> 03:27:50.820]   because I was like around a lot of other people as well.
[03:27:50.820 --> 03:27:53.500]   So I thought he might've had like a really bad time.
[03:27:53.500 --> 03:27:55.300]   But when he said that, I was thinking about it more
[03:27:55.300 --> 03:27:57.540]   and then we spent like more time together
[03:27:57.540 --> 03:27:59.460]   like a week after that and then it felt like
[03:27:59.460 --> 03:28:00.780]   that was more like real.
[03:28:00.780 --> 03:28:02.620]   And I think when he was about to leave,
[03:28:02.620 --> 03:28:04.660]   I kind of realized like, no, I really like him.
[03:28:04.660 --> 03:28:07.460]   - Do you guys ever say love to each other?
[03:28:07.460 --> 03:28:08.580]   Like, I love you?
[03:28:08.580 --> 03:28:09.420]   - Yeah, of course, yeah.
[03:28:09.420 --> 03:28:10.660]   - Okay, all right.
[03:28:10.660 --> 03:28:11.500]   I wasn't sure.
[03:28:11.500 --> 03:28:12.320]   - Why would you ask that?
[03:28:12.320 --> 03:28:13.160]   What has he said before?
[03:28:13.160 --> 03:28:16.140]   - 'Cause I haven't, I don't think I've heard you speak.
[03:28:16.140 --> 03:28:18.220]   The only time I've heard Steven talk about love
[03:28:18.220 --> 03:28:21.460]   is when you're like criticizing the Red Pill community
[03:28:21.460 --> 03:28:24.220]   saying they don't ever talk about love in relationships.
[03:28:24.220 --> 03:28:26.260]   - Almost all the time I'm giving criticism to people.
[03:28:26.260 --> 03:28:27.580]   Like I said, I'm kind of stepping in.
[03:28:27.580 --> 03:28:29.460]   I'm very disconnected from my own emotional experience
[03:28:29.460 --> 03:28:31.340]   'cause I'm trying to talk within there.
[03:28:31.340 --> 03:28:32.700]   So it's pretty rare that I'll talk about my--
[03:28:32.700 --> 03:28:35.300]   - What is your own emotional experience exactly?
[03:28:35.300 --> 03:28:36.620]   - Highly blunted, I guess.
[03:28:36.620 --> 03:28:37.460]   - There's a lot, okay.
[03:28:37.460 --> 03:28:39.380]   - What does that mean?
[03:28:39.380 --> 03:28:42.260]   - I mean, what's deep in there?
[03:28:42.260 --> 03:28:43.660]   Is this just who you are genetically
[03:28:43.660 --> 03:28:45.540]   or are you running from something?
[03:28:45.540 --> 03:28:46.940]   - I think I have a pretty good understanding of myself.
[03:28:46.940 --> 03:28:48.460]   A lot of people make that accusation to me,
[03:28:48.460 --> 03:28:49.620]   but I don't think I am.
[03:28:49.620 --> 03:28:51.220]   - Okay, this is just who you are?
[03:28:51.220 --> 03:28:52.300]   - It's just who I am, yeah.
[03:28:52.300 --> 03:28:55.260]   - Okay, this is not childhood stuff like trauma?
[03:28:55.260 --> 03:28:57.420]   - It's all sort of done.
[03:28:57.420 --> 03:28:58.460]   - You figured it all out?
[03:28:58.460 --> 03:28:59.300]   - Yeah.
[03:28:59.300 --> 03:29:00.300]   - In your old age?
[03:29:00.300 --> 03:29:02.220]   - As I grow every year, I figure out more and more.
[03:29:02.220 --> 03:29:04.180]   - He did mention, I think I heard this somewhere,
[03:29:04.180 --> 03:29:05.820]   that this is a source of fights
[03:29:05.820 --> 03:29:07.540]   for the two of you, the age thing.
[03:29:07.540 --> 03:29:10.180]   I felt the ageism throughout this whole conversation.
[03:29:10.180 --> 03:29:14.260]   - He's basically, he's saying that he gambles with time.
[03:29:14.260 --> 03:29:16.500]   He's just like, "I think she will be good later."
[03:29:16.500 --> 03:29:17.340]   And then just like--
[03:29:17.340 --> 03:29:18.180]   - It's like an investment, yeah.
[03:29:18.180 --> 03:29:20.380]   - Yeah, it's like what he's doing.
[03:29:20.380 --> 03:29:22.020]   When this treasury bond matures,
[03:29:22.020 --> 03:29:22.860]   I'm gonna be able to cash out for a good--
[03:29:22.860 --> 03:29:23.700]   - What do you think so far?
[03:29:23.700 --> 03:29:25.980]   Is the stocks going up or?
[03:29:25.980 --> 03:29:27.020]   - It's tumultuous.
[03:29:27.020 --> 03:29:27.860]   - What's that mean?
[03:29:27.860 --> 03:29:28.700]   - It's like Bitcoin?
[03:29:28.700 --> 03:29:29.540]   - A lot of up and down.
[03:29:29.540 --> 03:29:30.380]   - Oh my God.
[03:29:30.380 --> 03:29:31.900]   - Yeah, like Bitcoin, crypto mill.
[03:29:31.900 --> 03:29:34.140]   - All right, if you guys don't mind,
[03:29:34.140 --> 03:29:36.100]   one interesting aspect of your relationship
[03:29:36.100 --> 03:29:38.420]   is you're in an open relationship.
[03:29:38.420 --> 03:29:39.700]   What's that like?
[03:29:39.700 --> 03:29:41.900]   From a game theoretic simulation perspective,
[03:29:41.900 --> 03:29:43.980]   what went into that calculation?
[03:29:43.980 --> 03:29:45.140]   And how does that--
[03:29:45.140 --> 03:29:46.300]   - Like how that started or?
[03:29:46.300 --> 03:29:47.820]   - Yeah, how did that start, sure.
[03:29:47.820 --> 03:29:49.340]   - The only relationships I've ever done
[03:29:49.340 --> 03:29:52.260]   has been open relationships since I was in high school.
[03:29:52.260 --> 03:29:53.940]   'Cause I didn't really understand
[03:29:53.940 --> 03:29:56.700]   why wouldn't you be able to do other things
[03:29:56.700 --> 03:29:57.540]   with other people,
[03:29:57.540 --> 03:29:59.580]   but then just have your main partner basically.
[03:29:59.580 --> 03:30:02.460]   - So what is an open relationship, generally speaking?
[03:30:02.460 --> 03:30:04.140]   That means you have one main partner?
[03:30:04.140 --> 03:30:05.700]   - Not a monogamous relationship.
[03:30:05.700 --> 03:30:09.100]   You're somehow allowed in different ways.
[03:30:09.100 --> 03:30:11.060]   You can see other people sexually.
[03:30:11.060 --> 03:30:14.580]   - Sexually, but there's one main station.
[03:30:14.580 --> 03:30:16.140]   - It doesn't have to be there for some people,
[03:30:16.140 --> 03:30:18.180]   but I think it's probably easier
[03:30:18.180 --> 03:30:19.620]   when we probably don't really have time
[03:30:19.620 --> 03:30:23.180]   or the energy for more than one person
[03:30:23.180 --> 03:30:24.660]   to really focus on.
[03:30:24.660 --> 03:30:26.820]   - What about emotional?
[03:30:26.820 --> 03:30:27.660]   - It's really complicated.
[03:30:27.660 --> 03:30:29.260]   There's a lot of complicated stuff going on
[03:30:29.260 --> 03:30:30.300]   under the hood there.
[03:30:30.300 --> 03:30:33.020]   I think broadly speaking,
[03:30:33.020 --> 03:30:35.100]   you've got polyamorous relationships
[03:30:35.100 --> 03:30:36.540]   and you've got open relationships,
[03:30:36.540 --> 03:30:38.060]   where polyamorous is like,
[03:30:38.060 --> 03:30:40.020]   oh, I've got three different girlfriends
[03:30:40.020 --> 03:30:41.900]   and we all hang out or sometimes even live together
[03:30:41.900 --> 03:30:43.060]   or three boyfriends, whatever.
[03:30:43.060 --> 03:30:44.340]   And then you've got open relationships,
[03:30:44.340 --> 03:30:46.220]   which is like, oh, you can basically hook up
[03:30:46.220 --> 03:30:47.060]   with other people.
[03:30:47.060 --> 03:30:49.340]   And then you've got your main relationship and that's it.
[03:30:49.340 --> 03:30:52.140]   I think ours is probably somewhere in the middle of that,
[03:30:52.140 --> 03:30:53.740]   to where we've got long-term friends,
[03:30:53.740 --> 03:30:54.860]   some of them we hook up with,
[03:30:54.860 --> 03:30:56.420]   and that's kind of how we, yeah.
[03:30:56.420 --> 03:30:59.420]   It's a delicate dance that explodes
[03:30:59.420 --> 03:31:00.260]   every six months on itself.
[03:31:00.260 --> 03:31:02.380]   - So it does explode, you guys fight over it?
[03:31:02.380 --> 03:31:04.380]   - We fight over some things, yeah.
[03:31:04.380 --> 03:31:05.220]   It things happen, yeah.
[03:31:05.220 --> 03:31:08.180]   - I think it's mostly because a lot of people can't handle it
[03:31:08.180 --> 03:31:09.620]   and they agree to something
[03:31:09.620 --> 03:31:11.420]   and then they realize that we're way too cool.
[03:31:11.420 --> 03:31:12.980]   And then they get really obsessed
[03:31:12.980 --> 03:31:14.900]   and they think that they can get in there
[03:31:14.900 --> 03:31:16.500]   and then it gets really dramatic.
[03:31:16.500 --> 03:31:17.860]   - Have you figured it out?
[03:31:17.860 --> 03:31:22.180]   - I feel like we figure out things more and more
[03:31:22.180 --> 03:31:24.580]   when it comes to what's a good person for us to hang out
[03:31:24.580 --> 03:31:27.980]   and what's not a good person for us to hang out with.
[03:31:27.980 --> 03:31:30.540]   I probably have more opinions on who he hangs out with
[03:31:30.540 --> 03:31:32.340]   because he likes the fucking psychos.
[03:31:32.340 --> 03:31:33.300]   (laughs)
[03:31:33.300 --> 03:31:35.060]   - Yeah, so you like the surrounding?
[03:31:35.060 --> 03:31:38.740]   - He likes the crazy ones, the baby trap sort of women.
[03:31:38.740 --> 03:31:39.940]   That's the ones.
[03:31:39.940 --> 03:31:42.140]   And I don't like that 'cause that affects me.
[03:31:42.140 --> 03:31:43.660]   (laughs)
[03:31:43.660 --> 03:31:45.380]   - That affects your game theoretical relation.
[03:31:45.380 --> 03:31:46.220]   - Yeah, obviously, yeah.
[03:31:46.220 --> 03:31:48.460]   - Okay, you like to surround yourself,
[03:31:48.460 --> 03:31:51.700]   like in general, you've talked about with crazy people.
[03:31:51.700 --> 03:31:53.180]   - I say crazy and I really shouldn't.
[03:31:53.180 --> 03:31:54.020]   - It's a humorous way.
[03:31:54.020 --> 03:31:54.860]   - It's like, yeah.
[03:31:54.860 --> 03:31:55.780]   - They're very unstable.
[03:31:55.780 --> 03:31:58.820]   - Very, can be unstable, but people that are very unique.
[03:31:58.820 --> 03:32:00.780]   Like when I meet this person, that's like--
[03:32:00.780 --> 03:32:01.620]   - Not boring.
[03:32:01.620 --> 03:32:03.180]   - Yeah, not boring, yeah.
[03:32:03.180 --> 03:32:05.940]   - And you said that you're progressively becoming
[03:32:05.940 --> 03:32:07.460]   not boring yourself.
[03:32:07.460 --> 03:32:08.660]   - No, I think I'm pretty stable.
[03:32:08.660 --> 03:32:10.220]   I don't let them affect me much, but.
[03:32:10.220 --> 03:32:11.780]   - So you don't think they affect your--
[03:32:11.780 --> 03:32:13.460]   - No, if I've said that, I said it jokingly.
[03:32:13.460 --> 03:32:15.780]   I think I've got my stuff really well figured out.
[03:32:15.780 --> 03:32:17.540]   It's what allows me to engage with people like this
[03:32:17.540 --> 03:32:19.180]   so easily because I can engage,
[03:32:19.180 --> 03:32:20.380]   I can make them feel seen and heard.
[03:32:20.380 --> 03:32:22.060]   And then if it gets insane, I can cut off
[03:32:22.060 --> 03:32:23.060]   and I can be chill.
[03:32:23.060 --> 03:32:25.060]   Like very few things affect me in the longterm.
[03:32:25.060 --> 03:32:27.540]   - Do you guys experience jealousy?
[03:32:27.540 --> 03:32:30.180]   - Usually, like whenever I feel like he's not spending
[03:32:30.180 --> 03:32:32.140]   the like the amount of time that I'm asking for
[03:32:32.140 --> 03:32:35.100]   and he spends it on his video games or his stream
[03:32:35.100 --> 03:32:38.220]   or like he sees someone else like more than he sees me
[03:32:38.220 --> 03:32:40.300]   or something like that, that would like not be good.
[03:32:40.300 --> 03:32:42.540]   'Cause then it affects like our relationship.
[03:32:42.540 --> 03:32:44.260]   - Do you have a good sense of like,
[03:32:44.260 --> 03:32:49.180]   is it literally time or is it the energy put into the--
[03:32:49.180 --> 03:32:52.340]   - It's probably like if he's with me,
[03:32:52.340 --> 03:32:53.780]   that like the attention in the time,
[03:32:53.780 --> 03:32:54.780]   like when he hangs out with me
[03:32:54.780 --> 03:32:56.180]   and then there's also probably the time.
[03:32:56.180 --> 03:32:58.620]   So if I feel like something else is distracting too much,
[03:32:58.620 --> 03:33:00.380]   like it could be work or it could be a friend
[03:33:00.380 --> 03:33:01.660]   or it could be anything.
[03:33:01.660 --> 03:33:04.860]   Like if I feel like it starts to take away from like me,
[03:33:04.860 --> 03:33:06.500]   then I'm having an issue with it.
[03:33:06.500 --> 03:33:08.140]   I don't think he really cares much.
[03:33:08.140 --> 03:33:09.580]   I guess the only jealousy you experience
[03:33:09.580 --> 03:33:11.140]   is probably when you feel like,
[03:33:12.140 --> 03:33:15.780]   like if I get upset about him seeing someone too much
[03:33:15.780 --> 03:33:17.980]   and then I go see someone more and then he's like,
[03:33:17.980 --> 03:33:20.540]   why can't I go see my friend more, like as much as you?
[03:33:20.540 --> 03:33:22.340]   So like, that's the sort of like thing
[03:33:22.340 --> 03:33:24.440]   that we're trying to navigate on, I guess.
[03:33:24.440 --> 03:33:28.700]   - I think we are like diametrically opposed sometimes
[03:33:28.700 --> 03:33:30.620]   in terms of how we view like engagement with people
[03:33:30.620 --> 03:33:32.300]   or engagement with the world sometimes.
[03:33:32.300 --> 03:33:34.060]   So like on her end of the spectrum,
[03:33:34.060 --> 03:33:39.060]   like a perfect week for her might be like being in a cabin,
[03:33:39.820 --> 03:33:41.620]   watching like fireflies at night,
[03:33:41.620 --> 03:33:44.080]   going hiking every morning, going swimming at the beach,
[03:33:44.080 --> 03:33:45.520]   because it's like, you're taking in like
[03:33:45.520 --> 03:33:46.660]   the grandeur of nature.
[03:33:46.660 --> 03:33:47.980]   You're like connected with yourself.
[03:33:47.980 --> 03:33:48.980]   You're like very at peace.
[03:33:48.980 --> 03:33:50.220]   Everything is like chill and cool.
[03:33:50.220 --> 03:33:51.900]   There's the wind, the feeling of nature, everything.
[03:33:51.900 --> 03:33:53.620]   That's like her peak living experience.
[03:33:53.620 --> 03:33:54.620]   - I like being present.
[03:33:54.620 --> 03:33:57.060]   - Yeah, and like my peak experiences are like
[03:33:57.060 --> 03:33:58.420]   people trying to destroy my life,
[03:33:58.420 --> 03:33:59.820]   like the challenge of like navigating
[03:33:59.820 --> 03:34:01.700]   really complicated discussion,
[03:34:01.700 --> 03:34:04.220]   like several different dramatic events unfolding
[03:34:04.220 --> 03:34:05.060]   that might end my career.
[03:34:05.060 --> 03:34:05.940]   Like these things are like very,
[03:34:05.940 --> 03:34:08.260]   I like the stress and the action and the entertainment
[03:34:08.260 --> 03:34:09.900]   and everything's like very cool for me.
[03:34:09.900 --> 03:34:11.020]   So when we're together,
[03:34:11.020 --> 03:34:12.980]   she generally wants me to be like more chill.
[03:34:12.980 --> 03:34:15.300]   But if I don't feel like I'm being like stimulated a lot,
[03:34:15.300 --> 03:34:16.780]   then it's easy for like my mind to wander.
[03:34:16.780 --> 03:34:18.420]   - To wander somewhere else.
[03:34:18.420 --> 03:34:19.260]   - That's kind of the issue.
[03:34:19.260 --> 03:34:20.740]   We have a very different way of like engaging with the world.
[03:34:20.740 --> 03:34:24.100]   - So how can you find happiness in the stillness?
[03:34:24.100 --> 03:34:26.300]   - I feel like if we're just like aware of it
[03:34:26.300 --> 03:34:27.460]   and we're trying our best,
[03:34:27.460 --> 03:34:29.380]   like whenever we like we're supposed to do this one thing.
[03:34:29.380 --> 03:34:31.020]   So let's say that we wanna go to New York
[03:34:31.020 --> 03:34:32.500]   and I'm like, we should just like go out
[03:34:32.500 --> 03:34:33.780]   and do this one specific thing.
[03:34:33.780 --> 03:34:35.860]   We try to find something that he enjoys doing.
[03:34:35.860 --> 03:34:37.700]   Like now that we're in Texas,
[03:34:37.700 --> 03:34:40.260]   we can go shooting or do something fun that he enjoys
[03:34:40.260 --> 03:34:41.180]   then we can do it.
[03:34:41.180 --> 03:34:44.100]   And then I think like,
[03:34:44.100 --> 03:34:46.540]   just like for me also to be aware
[03:34:46.540 --> 03:34:48.620]   that like when he spends a lot of time on crazy people,
[03:34:48.620 --> 03:34:50.820]   it's not because he like loves them or wants to be with them.
[03:34:50.820 --> 03:34:52.380]   It's just because he likes being like,
[03:34:52.380 --> 03:34:54.500]   having his life destroyed.
[03:34:54.500 --> 03:34:56.380]   Like you said, which I don't really do.
[03:34:56.380 --> 03:34:57.580]   It's just a completely different thing.
[03:34:57.580 --> 03:35:00.700]   So like for me to like understand more like how he's thinking
[03:35:00.700 --> 03:35:02.300]   because it's so different from mine
[03:35:02.300 --> 03:35:04.500]   and for him to understand how I'm thinking about things
[03:35:04.500 --> 03:35:06.700]   and like what I prioritize in my life.
[03:35:06.700 --> 03:35:08.300]   I think that's like how we navigate.
[03:35:08.300 --> 03:35:09.140]   But I think it's good.
[03:35:09.140 --> 03:35:10.660]   I think the differences can be good.
[03:35:10.660 --> 03:35:12.420]   Like when we're finding a way, yeah.
[03:35:12.420 --> 03:35:15.700]   - Well, I think you're relatable.
[03:35:15.700 --> 03:35:17.220]   (laughing)
[03:35:17.220 --> 03:35:18.060]   - More of a human, you're an AI.
[03:35:18.060 --> 03:35:19.740]   - No, I'm definitely very difficult to get along with.
[03:35:19.740 --> 03:35:20.580]   Like I always tell people that,
[03:35:20.580 --> 03:35:22.580]   that like if you're dating me for like more than a few years,
[03:35:22.580 --> 03:35:23.420]   like you get like an award for that.
[03:35:23.420 --> 03:35:25.580]   - It's like a war zone that you've survived.
[03:35:25.580 --> 03:35:26.420]   - Did you say that? - Absolutely.
[03:35:26.420 --> 03:35:29.300]   - That you're like a veteran, you get medals and stuff.
[03:35:29.300 --> 03:35:30.140]   - And it's always like,
[03:35:30.140 --> 03:35:31.540]   I think there's probably been like six different,
[03:35:31.540 --> 03:35:32.740]   I don't think she says it anymore,
[03:35:32.740 --> 03:35:34.180]   but there were like six different times in our relationship
[03:35:34.180 --> 03:35:35.700]   where she's like, is it always like this?
[03:35:35.700 --> 03:35:36.660]   Is this actually right?
[03:35:36.660 --> 03:35:37.500]   - Yeah. - And like every next year--
[03:35:37.500 --> 03:35:39.380]   - You lied in the beginning of it.
[03:35:39.380 --> 03:35:40.700]   Like you were lying about that.
[03:35:40.700 --> 03:35:42.300]   - Well, it got worse.
[03:35:42.300 --> 03:35:43.940]   - You were like, no, it's just like right now,
[03:35:43.940 --> 03:35:46.140]   I'm having a huge argument online
[03:35:46.140 --> 03:35:47.580]   about saying the N-word in private.
[03:35:47.580 --> 03:35:48.540]   It's just gonna be like this
[03:35:48.540 --> 03:35:51.140]   and I'm gonna be streaming 24 hours a day.
[03:35:51.140 --> 03:35:52.940]   And I'm like, when are you gonna go to bed?
[03:35:52.940 --> 03:35:53.780]   It's been a week.
[03:35:53.780 --> 03:35:58.380]   - Did playing league come into this?
[03:35:58.380 --> 03:35:59.580]   - A little bit, but I'm clean.
[03:35:59.580 --> 03:36:01.140]   I'm clean of league like six months right now.
[03:36:01.140 --> 03:36:03.380]   - Yeah, what do you hate about legally?
[03:36:03.380 --> 03:36:04.980]   - I never got-- - The humans.
[03:36:04.980 --> 03:36:06.300]   (laughing)
[03:36:06.300 --> 03:36:08.180]   - Well, speaking of which,
[03:36:08.180 --> 03:36:10.820]   my participation in league involved on the robot side.
[03:36:10.820 --> 03:36:11.660]   - Good.
[03:36:11.660 --> 03:36:12.540]   - 'Cause there's--
[03:36:12.540 --> 03:36:13.940]   - That's an improvement.
[03:36:13.940 --> 03:36:18.180]   - 'Cause both with Starcraft II and League of Legends,
[03:36:18.180 --> 03:36:21.220]   'cause OpenAI and DeepMind both participate
[03:36:21.220 --> 03:36:22.380]   in creating bots in those.
[03:36:22.380 --> 03:36:23.780]   - I was a professional Starcraft II player,
[03:36:23.780 --> 03:36:25.940]   so I remember when the AI started to play.
[03:36:25.940 --> 03:36:27.740]   It's interesting the types of restrictions
[03:36:27.740 --> 03:36:29.580]   that you would have to put on like a gaming robot
[03:36:29.580 --> 03:36:30.740]   to make it like functional
[03:36:30.740 --> 03:36:33.340]   and not totally unfair to the other side.
[03:36:33.340 --> 03:36:34.660]   - Yeah, to make it human-like.
[03:36:34.660 --> 03:36:35.940]   Yeah, was that interesting to you,
[03:36:35.940 --> 03:36:38.740]   to see AI be able to play those video games?
[03:36:38.740 --> 03:36:39.580]   - I think in some ways,
[03:36:39.580 --> 03:36:40.700]   people think things are more complicated
[03:36:40.700 --> 03:36:41.860]   than they actually are.
[03:36:41.860 --> 03:36:43.380]   And I think video games is one of those things
[03:36:43.380 --> 03:36:44.220]   where we're like, oh my God,
[03:36:44.220 --> 03:36:46.660]   there's like a million possibilities at every second
[03:36:46.660 --> 03:36:47.500]   and who knows?
[03:36:47.500 --> 03:36:48.620]   And it's like, no, there's like three or four things
[03:36:48.620 --> 03:36:49.580]   going on at any point in time.
[03:36:49.580 --> 03:36:50.860]   And I'm willing to bet that like an AI
[03:36:50.860 --> 03:36:53.740]   could probably solve some of these games like pretty easily,
[03:36:53.740 --> 03:36:55.100]   especially if there are no constraints
[03:36:55.100 --> 03:36:56.820]   on how they can learn, yeah.
[03:36:56.820 --> 03:36:59.060]   - Can I talk to you about relationships?
[03:36:59.060 --> 03:37:00.300]   - Yeah. - Yeah, we already have.
[03:37:00.300 --> 03:37:02.180]   - Yeah, I know, but more generally speaking,
[03:37:02.180 --> 03:37:03.860]   we didn't get a chance to talk
[03:37:03.860 --> 03:37:05.820]   about the Red Pill community.
[03:37:05.820 --> 03:37:06.660]   - Oh, sure.
[03:37:06.660 --> 03:37:08.380]   - Well, first of all, what is the Red Pill community,
[03:37:08.380 --> 03:37:09.780]   the metasphere in general?
[03:37:09.780 --> 03:37:11.700]   I'd love to get both of your opinions on this.
[03:37:11.700 --> 03:37:12.980]   - Sure.
[03:37:12.980 --> 03:37:17.380]   - I know you're probably not as opinionated on that whole--
[03:37:17.380 --> 03:37:19.060]   - I'd say, do you think I am then?
[03:37:19.060 --> 03:37:21.060]   Like probably not as much as you,
[03:37:21.060 --> 03:37:22.500]   but I do have opinions.
[03:37:22.500 --> 03:37:23.340]   - You do, okay.
[03:37:23.340 --> 03:37:25.420]   - I usually don't like speak out too much on it
[03:37:25.420 --> 03:37:28.020]   because I feel like there's like a language barrier.
[03:37:28.020 --> 03:37:29.380]   That's why I don't really do politics
[03:37:29.380 --> 03:37:31.220]   because this is my second language, yeah.
[03:37:31.220 --> 03:37:33.300]   - That's right, you have to know the--
[03:37:33.300 --> 03:37:34.140]   - A little bit like that, yeah.
[03:37:34.140 --> 03:37:38.700]   - You know how to use derogatory terms every other sentence
[03:37:38.700 --> 03:37:40.020]   so they understand you, right?
[03:37:40.020 --> 03:37:40.860]   - Exactly.
[03:37:40.860 --> 03:37:41.700]   - I don't know anything about that.
[03:37:41.700 --> 03:37:42.540]   - It's the only thing I've talked about.
[03:37:42.540 --> 03:37:45.780]   - You need to be able to speak really well
[03:37:45.780 --> 03:37:48.300]   for people to take you seriously, I think.
[03:37:48.300 --> 03:37:51.260]   And that's the thing, if I don't have the words
[03:37:51.260 --> 03:37:54.060]   and I can't pronounce things correctly,
[03:37:54.060 --> 03:37:54.900]   then people are not gonna say--
[03:37:54.900 --> 03:37:56.740]   - The ESL person searching for words looks stupid,
[03:37:56.740 --> 03:37:58.300]   essentially, that's how people view it, yeah.
[03:37:58.300 --> 03:38:00.260]   - Tell me about it, I have a podcast
[03:38:00.260 --> 03:38:03.500]   that a bunch of people listen to and I mumble and they,
[03:38:03.500 --> 03:38:04.340]   yeah.
[03:38:04.340 --> 03:38:06.220]   - Wait, what's your first language?
[03:38:06.220 --> 03:38:07.060]   - Russian.
[03:38:07.060 --> 03:38:07.880]   - Oh, okay.
[03:38:07.880 --> 03:38:09.540]   - But I speak both languages horribly.
[03:38:09.540 --> 03:38:12.300]   I'm just not, I'm not like,
[03:38:12.300 --> 03:38:14.380]   there is definitely a big disconnect
[03:38:14.380 --> 03:38:17.220]   between my brain and my mouth module.
[03:38:17.220 --> 03:38:20.740]   Like, I'm not able to generate the thoughts efficiently.
[03:38:20.740 --> 03:38:21.940]   Like the things you're able to do,
[03:38:21.940 --> 03:38:25.180]   like the da-da-da-da-da, like speak like that, I'm not.
[03:38:25.180 --> 03:38:26.140]   It's very, very tough.
[03:38:26.140 --> 03:38:27.900]   Plus there's a huge amount of anxiety
[03:38:27.900 --> 03:38:29.480]   and social interaction that I have,
[03:38:29.480 --> 03:38:31.340]   which makes speaking even harder.
[03:38:31.340 --> 03:38:32.180]   - Gotcha.
[03:38:32.180 --> 03:38:34.140]   - Yeah, yeah, yeah, it's tough.
[03:38:34.140 --> 03:38:34.980]   - I understand.
[03:38:34.980 --> 03:38:35.800]   - Gotcha.
[03:38:35.800 --> 03:38:37.340]   - Makes sense.
[03:38:37.340 --> 03:38:42.340]   - Yeah, the gotcha is both a symbol of compassion
[03:38:42.340 --> 03:38:44.100]   and derision at once.
[03:38:44.100 --> 03:38:45.540]   - I'm just letting you know, I understand what you're saying.
[03:38:45.540 --> 03:38:46.820]   I'm just gonna sit there and stare at you in silence.
[03:38:46.820 --> 03:38:48.780]   - No, you can just say like, yeah, I get it.
[03:38:48.780 --> 03:38:49.620]   Like, yeah.
[03:38:49.620 --> 03:38:50.820]   - I get it, gotcha.
[03:38:50.820 --> 03:38:55.060]   - No, no, gotcha sounds, no, it's so short.
[03:38:55.060 --> 03:38:57.900]   It's like, say a longer sentence,
[03:38:57.900 --> 03:38:59.260]   but that means the same thing.
[03:38:59.260 --> 03:39:00.600]   - I understand you.
[03:39:00.600 --> 03:39:01.600]   - Yeah, good, that's good.
[03:39:01.600 --> 03:39:04.200]   That's like, not chills, you know?
[03:39:04.200 --> 03:39:06.360]   You get chills, so you understand me.
[03:39:06.360 --> 03:39:07.240]   - Yeah, it feels good.
[03:39:07.240 --> 03:39:08.080]   - Yeah.
[03:39:08.080 --> 03:39:08.900]   - I hear you.
[03:39:08.900 --> 03:39:09.740]   - I hear you.
[03:39:09.740 --> 03:39:11.320]   - And like, if you just like hold the other person's hand,
[03:39:11.320 --> 03:39:12.160]   that's even better.
[03:39:12.160 --> 03:39:13.520]   - You gotta put in some emotion there, okay?
[03:39:13.520 --> 03:39:14.720]   Show that you have some.
[03:39:14.720 --> 03:39:15.560]   - I understand.
[03:39:15.560 --> 03:39:18.360]   What do you think about, gotcha.
[03:39:18.360 --> 03:39:20.320]   What do you think about Red Pill?
[03:39:20.320 --> 03:39:22.360]   What, sorry, what is it, first of all,
[03:39:22.360 --> 03:39:23.440]   for people who don't know?
[03:39:23.440 --> 03:39:25.000]   - Yeah, the Red Pill community,
[03:39:25.000 --> 03:39:26.480]   obviously it's the Matrix reference.
[03:39:26.480 --> 03:39:28.640]   The Red Pill that you take is when you realize
[03:39:28.640 --> 03:39:31.440]   what dating standards and norms really are in the world.
[03:39:31.440 --> 03:39:34.620]   That men are providers and have to become some great thing
[03:39:34.620 --> 03:39:37.640]   to hunt and attract the woman who are just kind of there
[03:39:37.640 --> 03:39:38.860]   floating around looking for people
[03:39:38.860 --> 03:39:40.160]   to give them the most resources.
[03:39:40.160 --> 03:39:42.260]   And it's like coming to a realization
[03:39:42.260 --> 03:39:43.760]   of what the world of dating really is,
[03:39:43.760 --> 03:39:45.560]   broken away from the Hollywood standards
[03:39:45.560 --> 03:39:47.160]   and the romantic stuff that they try to sell you
[03:39:47.160 --> 03:39:48.220]   in the stores.
[03:39:48.220 --> 03:39:49.800]   - So there was kind of,
[03:39:49.800 --> 03:39:51.880]   maybe you can kind of educate me on this,
[03:39:51.880 --> 03:39:55.340]   but Red Pill used to be associated with just
[03:39:57.240 --> 03:39:59.320]   maybe anti-establishment views, I don't know.
[03:39:59.320 --> 03:40:01.400]   Maybe Republican conservative viewpoints,
[03:40:01.400 --> 03:40:02.340]   maybe alt-right. - People use,
[03:40:02.340 --> 03:40:04.800]   yeah, they use Red Pill a lot in different communities.
[03:40:04.800 --> 03:40:06.480]   When you say the Red Pill community--
[03:40:06.480 --> 03:40:07.960]   - Yeah, that usually means dating.
[03:40:07.960 --> 03:40:08.800]   - The dating thing.
[03:40:08.800 --> 03:40:09.640]   But a lot of people say, "Oh, Trump voters,
[03:40:09.640 --> 03:40:10.460]   "they're Red Pilled."
[03:40:10.460 --> 03:40:11.800]   Are you Red Pilled on politics or whatever?
[03:40:11.800 --> 03:40:13.120]   People will say stuff like that, yeah.
[03:40:13.120 --> 03:40:13.960]   - Okay. - Cool.
[03:40:13.960 --> 03:40:15.760]   - And then there's the Manosphere,
[03:40:15.760 --> 03:40:17.160]   all the similar type of stuff.
[03:40:17.160 --> 03:40:19.440]   And Andrew Tate is somebody that represents
[03:40:19.440 --> 03:40:21.560]   kind of the figurehead.
[03:40:21.560 --> 03:40:23.320]   - Of the Manosphere, of the Red Pill stuff,
[03:40:23.320 --> 03:40:24.160]   yeah, I would say so.
[03:40:24.160 --> 03:40:25.000]   I'm pretty sure, yeah.
[03:40:25.000 --> 03:40:25.820]   - Okay.
[03:40:25.820 --> 03:40:26.660]   All right, cool.
[03:40:26.660 --> 03:40:29.560]   Well, what are some ideas that they represent
[03:40:29.560 --> 03:40:30.680]   and what do you think about them?
[03:40:30.680 --> 03:40:32.720]   - I think they do a good job at speaking
[03:40:32.720 --> 03:40:34.880]   to disaffected young men who feel like
[03:40:34.880 --> 03:40:36.600]   the rest of the world has kind of left them behind
[03:40:36.600 --> 03:40:38.360]   or isn't willing to speak to them.
[03:40:38.360 --> 03:40:41.520]   And they do identify some true and real problems.
[03:40:41.520 --> 03:40:43.420]   Feels like on the left, we have a really hard time
[03:40:43.420 --> 03:40:45.560]   doing self-improvement or telling people
[03:40:45.560 --> 03:40:46.460]   how to better themselves.
[03:40:46.460 --> 03:40:48.880]   We focus too much on structural or systemic issues
[03:40:48.880 --> 03:40:50.400]   rather than what can an individual do
[03:40:50.400 --> 03:40:52.240]   to uplift or empower themselves.
[03:40:52.240 --> 03:40:54.000]   And it also feels like they do a good job
[03:40:54.000 --> 03:40:56.220]   at speaking to some of the positive aspects
[03:40:56.220 --> 03:40:58.920]   of masculinity, that it's okay to be strong
[03:40:58.920 --> 03:41:01.440]   and brave and a soldier and a warrior
[03:41:01.440 --> 03:41:03.840]   and provide for your family and blah, blah, blah.
[03:41:03.840 --> 03:41:05.480]   So I would say those are positive messages,
[03:41:05.480 --> 03:41:06.760]   like self-improvement and everything
[03:41:06.760 --> 03:41:08.640]   that come from the Red Pill community.
[03:41:08.640 --> 03:41:09.800]   - What's the negative?
[03:41:09.800 --> 03:41:13.960]   - I think the analysis on how men and women interact
[03:41:13.960 --> 03:41:16.040]   is way too transactional.
[03:41:16.040 --> 03:41:18.300]   All of the romanticism and love and chemistry
[03:41:18.300 --> 03:41:19.740]   is totally sucked out of it.
[03:41:19.740 --> 03:41:22.040]   Everything is very sex-based,
[03:41:22.040 --> 03:41:23.440]   like how do you basically have sex
[03:41:23.440 --> 03:41:24.840]   with the most amount of women possible
[03:41:24.840 --> 03:41:26.340]   and that's gonna make you happy?
[03:41:26.340 --> 03:41:28.660]   And then I think people's motivations sometimes
[03:41:28.660 --> 03:41:31.620]   are just spoken about in such a shallow derogatory way
[03:41:31.620 --> 03:41:33.620]   that I don't think is always reflective of reality.
[03:41:33.620 --> 03:41:34.820]   Like a woman only wants you
[03:41:34.820 --> 03:41:36.620]   because you make six figures and you're tall
[03:41:36.620 --> 03:41:37.460]   and a guy only wants you
[03:41:37.460 --> 03:41:38.860]   'cause he wants to have sex with you and blah, blah.
[03:41:38.860 --> 03:41:41.420]   Like it feels like there's a lot of that going on a lot.
[03:41:41.420 --> 03:41:43.980]   - Yeah, and that misses some fundamental aspects
[03:41:43.980 --> 03:41:46.420]   about relationships, about meaningful relationships
[03:41:46.420 --> 03:41:47.260]   and so on.
[03:41:47.260 --> 03:41:48.660]   - I don't think I've never heard Red Pill people
[03:41:48.660 --> 03:41:50.980]   ever, ever talk about meaningful relationships.
[03:41:50.980 --> 03:41:52.060]   It's always just how to get in one
[03:41:52.060 --> 03:41:53.880]   or how to have sex, really.
[03:41:53.880 --> 03:41:57.260]   - Mel, what bothers you about some of that philosophy?
[03:41:57.260 --> 03:41:59.620]   - I feel like the people that are like the Red Pill people,
[03:41:59.620 --> 03:42:01.580]   I feel like their solution is something
[03:42:01.580 --> 03:42:03.520]   that doesn't actually work out.
[03:42:03.520 --> 03:42:06.700]   Or it works out for some people,
[03:42:06.700 --> 03:42:07.780]   people that makes a lot of money
[03:42:07.780 --> 03:42:10.100]   and is really successful in that sort of way,
[03:42:10.100 --> 03:42:12.980]   but it's not gonna help most men out there.
[03:42:12.980 --> 03:42:15.700]   So I feel like it's just a pointless speech
[03:42:15.700 --> 03:42:18.060]   to give to these really lost guys.
[03:42:18.060 --> 03:42:21.060]   And they really do believe that they can become successful,
[03:42:21.060 --> 03:42:24.680]   they can get money and when they get all these things,
[03:42:24.680 --> 03:42:25.600]   they can get girls,
[03:42:25.600 --> 03:42:28.440]   but most of them is not gonna achieve that ever.
[03:42:28.440 --> 03:42:30.440]   - To get the money part or become successful.
[03:42:30.440 --> 03:42:31.840]   - Just become a billionaire, you know?
[03:42:31.840 --> 03:42:33.640]   And you will get all the girls, which is true,
[03:42:33.640 --> 03:42:34.680]   but not everyone can do that.
[03:42:34.680 --> 03:42:38.000]   So I feel like when these guys are speaking to these men
[03:42:38.000 --> 03:42:38.820]   and they're just like,
[03:42:38.820 --> 03:42:40.520]   "We just care about these men out there.
[03:42:40.520 --> 03:42:41.720]   They need to hear this."
[03:42:41.720 --> 03:42:43.520]   It doesn't really help a lot of them.
[03:42:43.520 --> 03:42:48.520]   - And it doesn't inspire them to develop compassion
[03:42:48.520 --> 03:42:49.920]   towards the opposite sex,
[03:42:49.920 --> 03:42:51.460]   which is probably something required
[03:42:51.460 --> 03:42:52.920]   to have a meaningful relationship.
[03:42:52.920 --> 03:42:56.640]   - And also they seem to complain a lot about women,
[03:42:56.640 --> 03:42:59.380]   like only wanting men that have money and that's tall
[03:42:59.380 --> 03:43:01.880]   and that's muscular or whatever, all those things.
[03:43:01.880 --> 03:43:04.660]   But they complain about that,
[03:43:04.660 --> 03:43:08.740]   but that's also kind of what they're trying to make the men
[03:43:08.740 --> 03:43:10.260]   try to do for themselves.
[03:43:10.260 --> 03:43:12.900]   So they kind of fall into the same sort of behavior.
[03:43:12.900 --> 03:43:16.060]   And it seems like they're kind of unaware of that as well.
[03:43:16.060 --> 03:43:17.380]   They're just playing a part of the game
[03:43:17.380 --> 03:43:19.280]   instead of trying to find a woman
[03:43:19.280 --> 03:43:20.940]   that doesn't look for those things
[03:43:20.940 --> 03:43:24.260]   and that are looking for not those things.
[03:43:24.260 --> 03:43:27.700]   - I actually would love to have straight up data
[03:43:27.700 --> 03:43:31.900]   on people in that world versus not in that world,
[03:43:31.900 --> 03:43:33.220]   how often they get laid.
[03:43:33.220 --> 03:43:39.420]   Like literally, so I think for sure people in that world
[03:43:39.420 --> 03:43:44.460]   have fewer meaningful long-term relationships
[03:43:44.460 --> 03:43:45.460]   that are fulfilling,
[03:43:45.460 --> 03:43:47.540]   that actually helped them succeed in life,
[03:43:47.540 --> 03:43:49.020]   that helped them be happy and content
[03:43:49.020 --> 03:43:50.300]   and all that kind of stuff.
[03:43:50.300 --> 03:43:51.620]   But just even the straight up,
[03:43:51.620 --> 03:43:56.540]   the shallow goal of getting laid, I wonder.
[03:43:56.540 --> 03:43:59.460]   Because it's very possible that like just the roughness
[03:43:59.460 --> 03:44:03.420]   with which they treat intellectually women,
[03:44:03.420 --> 03:44:06.660]   that might lead to lower success, not higher success.
[03:44:06.660 --> 03:44:08.100]   - It's very adversarial,
[03:44:08.100 --> 03:44:09.220]   which I think is always disappointing.
[03:44:09.220 --> 03:44:10.500]   Anything that talks about men and women,
[03:44:10.500 --> 03:44:12.340]   I think it's good to acknowledge differences,
[03:44:12.340 --> 03:44:13.980]   but when it becomes like adversarial,
[03:44:13.980 --> 03:44:15.340]   especially when you talk about sex,
[03:44:15.340 --> 03:44:16.820]   sex is something that men are getting
[03:44:16.820 --> 03:44:18.180]   and it's something that women are giving
[03:44:18.180 --> 03:44:19.340]   and that type of like trade off
[03:44:19.340 --> 03:44:20.620]   and the way they talk about it is like,
[03:44:20.620 --> 03:44:22.260]   yeah, it sets people against each other
[03:44:22.260 --> 03:44:23.820]   in a really toxic way, I think.
[03:44:23.820 --> 03:44:27.180]   - How do you talk to people from that world,
[03:44:27.180 --> 03:44:28.500]   from the red pill world?
[03:44:28.500 --> 03:44:31.020]   Like would you ever talk to like somebody like Andrew Tate?
[03:44:31.020 --> 03:44:32.220]   - Oh yeah, if I had the chance to.
[03:44:32.220 --> 03:44:34.260]   I've been on the Fresh and Fit podcast a few times
[03:44:34.260 --> 03:44:35.580]   and then I've got a friend, Sneeko,
[03:44:35.580 --> 03:44:37.700]   who's like very red pill, that stuff.
[03:44:37.700 --> 03:44:40.460]   If I'm trying to talk to them,
[03:44:40.460 --> 03:44:44.060]   usually it's kind of like approaching it like a scared cat.
[03:44:44.060 --> 03:44:45.820]   The first thing you have to do is like be very gentle
[03:44:45.820 --> 03:44:47.180]   and say like, I understand your issues,
[03:44:47.180 --> 03:44:48.060]   I understand your complaints,
[03:44:48.060 --> 03:44:49.980]   I know that I'm scary because you think I'm gonna say
[03:44:49.980 --> 03:44:51.820]   like toxic masculinity and feminism
[03:44:51.820 --> 03:44:54.020]   and all these scary words at you.
[03:44:54.020 --> 03:44:55.580]   So the first thing is always to recognize it.
[03:44:55.580 --> 03:44:56.980]   Like a lot of what they talk about,
[03:44:56.980 --> 03:44:59.340]   there are like true aspects to what they're talking about
[03:44:59.340 --> 03:45:01.140]   that people on the left won't recognize.
[03:45:01.140 --> 03:45:03.900]   So I think it's good to acknowledge those things
[03:45:03.900 --> 03:45:05.820]   that like men and women are kind of different.
[03:45:05.820 --> 03:45:07.220]   We do look for different things in general
[03:45:07.220 --> 03:45:08.060]   when it comes to relationships.
[03:45:08.060 --> 03:45:10.420]   It's okay to say that, there's nothing bad there.
[03:45:10.500 --> 03:45:11.500]   And then it'll usually be like,
[03:45:11.500 --> 03:45:13.700]   once I've got your trust and I'm in your bubble,
[03:45:13.700 --> 03:45:15.780]   like let's talk about the things that you want
[03:45:15.780 --> 03:45:17.980]   and maybe some of the strategies that you're employing
[03:45:17.980 --> 03:45:19.140]   aren't necessarily gonna get you
[03:45:19.140 --> 03:45:20.340]   some of the things that you want.
[03:45:20.340 --> 03:45:21.580]   So for instance, if you're really worried
[03:45:21.580 --> 03:45:23.820]   about like shallow girls ruining your life,
[03:45:23.820 --> 03:45:26.100]   like Melina said, it's probably not best
[03:45:26.100 --> 03:45:27.140]   to build your entire worldview
[03:45:27.140 --> 03:45:28.340]   around trying to get shallow girls
[03:45:28.340 --> 03:45:29.540]   that are gonna ruin your life.
[03:45:29.540 --> 03:45:30.820]   Like if your way of attracting a girl
[03:45:30.820 --> 03:45:32.500]   is to go to the gym, get a whole bunch of money
[03:45:32.500 --> 03:45:34.740]   and try to like flaunt your wealth as much as possible,
[03:45:34.740 --> 03:45:36.380]   you're gonna be attracting the very same type of women
[03:45:36.380 --> 03:45:38.660]   that you're here like decrying on your stream.
[03:45:38.660 --> 03:45:40.100]   - Yeah, I think we talked about that on the podcast.
[03:45:40.100 --> 03:45:41.660]   Like you probably wanna have a woman
[03:45:41.660 --> 03:45:43.420]   that's gonna be there if you lose your job,
[03:45:43.420 --> 03:45:44.260]   it's still there.
[03:45:44.260 --> 03:45:47.020]   Like that cares about the things that's not just your job.
[03:45:47.020 --> 03:45:47.980]   - Yeah.
[03:45:47.980 --> 03:45:48.940]   - It's more stable.
[03:45:48.940 --> 03:45:52.020]   - And also I don't help you become a great man
[03:45:52.020 --> 03:45:54.260]   or a great like grow.
[03:45:54.260 --> 03:45:57.100]   Like I feel like a great friendship and a partnership,
[03:45:57.100 --> 03:45:58.900]   like it helps you make you a better person.
[03:45:58.900 --> 03:46:00.420]   Some of the most successful people I know,
[03:46:00.420 --> 03:46:01.500]   I mean, they have families
[03:46:01.500 --> 03:46:03.140]   and there's clearly a dynamic there
[03:46:03.140 --> 03:46:05.020]   that's like that makes them,
[03:46:05.020 --> 03:46:06.460]   they wouldn't be that without.
[03:46:06.460 --> 03:46:07.500]   - They're not an island, yeah.
[03:46:07.500 --> 03:46:10.180]   - Yeah, and the kids actually a big part of that too.
[03:46:10.180 --> 03:46:12.860]   Like for most people, if you're like a good parent,
[03:46:12.860 --> 03:46:15.260]   they make you step up somehow in life.
[03:46:15.260 --> 03:46:16.500]   You have to take responsibility
[03:46:16.500 --> 03:46:18.580]   for getting your shit together
[03:46:18.580 --> 03:46:23.580]   and excelling in ways that I guess the philosophy
[03:46:23.580 --> 03:46:25.140]   of the Red Bull does not quite get to.
[03:46:25.140 --> 03:46:26.100]   - That's always an interesting,
[03:46:26.100 --> 03:46:27.220]   I think I've asked that a couple of times
[03:46:27.220 --> 03:46:30.460]   where it's like, would you let your daughter
[03:46:30.460 --> 03:46:31.820]   date Andrew Tate?
[03:46:31.820 --> 03:46:32.860]   And it's always funny to watch them
[03:46:32.860 --> 03:46:35.260]   kind of like squirm around those answers sometimes.
[03:46:35.260 --> 03:46:37.260]   - But see if they don't have a daughter,
[03:46:37.260 --> 03:46:39.340]   like I don't have a daughter.
[03:46:39.340 --> 03:46:41.340]   I think your whole philosophy changes
[03:46:41.340 --> 03:46:42.380]   once you have a daughter.
[03:46:42.380 --> 03:46:43.220]   - Sure.
[03:46:43.220 --> 03:46:44.060]   - Like you can feel a solid--
[03:46:44.060 --> 03:46:44.880]   - Well, but even at that,
[03:46:44.880 --> 03:46:45.720]   like they know that what they're answering,
[03:46:45.720 --> 03:46:46.820]   they feel a little bit weird about it.
[03:46:46.820 --> 03:46:47.660]   It's funny to watch them.
[03:46:47.660 --> 03:46:49.900]   Like even they know, it's like, ah, fuck, you know.
[03:46:49.900 --> 03:46:51.140]   - Well, they might say like,
[03:46:51.140 --> 03:46:54.540]   I want my daughter to date like a high value male
[03:46:54.540 --> 03:46:57.260]   to the degree that he's a high value male, yes.
[03:46:57.260 --> 03:46:59.120]   But like, I don't think you'll feel that way.
[03:46:59.120 --> 03:47:01.500]   The definition of high value changes completely.
[03:47:01.500 --> 03:47:02.340]   - For sure.
[03:47:02.340 --> 03:47:05.220]   - Certainly the stereotypical measures of value
[03:47:05.220 --> 03:47:06.560]   contribute to the calculation,
[03:47:06.560 --> 03:47:07.860]   but it's so much more than that.
[03:47:07.860 --> 03:47:11.140]   I think the chemistry of the whole thing is bigger.
[03:47:11.140 --> 03:47:13.780]   You've also mentioned about body count.
[03:47:13.780 --> 03:47:16.700]   You guys both have a high body count.
[03:47:16.700 --> 03:47:18.060]   Does body count matter?
[03:47:18.060 --> 03:47:19.780]   Or it depends, like you said,
[03:47:19.780 --> 03:47:21.620]   it's low in some people's eyes,
[03:47:21.620 --> 03:47:23.160]   it's high in other people's eyes.
[03:47:23.160 --> 03:47:24.900]   Does body count matter in relationships?
[03:47:24.900 --> 03:47:26.660]   Does the past matter?
[03:47:26.660 --> 03:47:27.900]   - Well, the past matters.
[03:47:27.900 --> 03:47:29.900]   I don't think body count, not to me, I don't really care.
[03:47:29.900 --> 03:47:31.220]   - Not just as it is, no.
[03:47:31.220 --> 03:47:33.220]   - I mean, it could be.
[03:47:33.220 --> 03:47:34.040]   - What the past does.
[03:47:34.040 --> 03:47:34.880]   - Yeah.
[03:47:34.880 --> 03:47:36.100]   - Well, the past is who you are, right?
[03:47:36.100 --> 03:47:38.220]   But if somebody tells me they have a 200 body count
[03:47:38.220 --> 03:47:39.300]   and they're 16,
[03:47:39.300 --> 03:47:41.260]   something's probably going on there that's not good.
[03:47:41.260 --> 03:47:42.100]   - I was thinking about that too.
[03:47:42.100 --> 03:47:43.900]   'Cause it could be really young people
[03:47:43.900 --> 03:47:47.460]   that are having some sort of mental problems going on.
[03:47:47.460 --> 03:47:50.340]   - Or somebody's 45 and they've never had sex before.
[03:47:50.340 --> 03:47:51.620]   There's probably something going on, right?
[03:47:51.620 --> 03:47:52.460]   So it could be indicative.
[03:47:52.460 --> 03:47:54.260]   But if somebody's in their 20s and they've had sex
[03:47:54.260 --> 03:47:57.140]   with 100 people or 50 people, whatever, it's whatever.
[03:47:57.140 --> 03:47:59.420]   - It's more experience, which can be good.
[03:47:59.420 --> 03:48:00.260]   - Sure.
[03:48:00.260 --> 03:48:03.420]   - Okay, so that just represents you're sexually open
[03:48:03.420 --> 03:48:06.460]   and so it doesn't really necessarily mean any kind of,
[03:48:06.460 --> 03:48:07.940]   not necessarily, it could though.
[03:48:07.940 --> 03:48:09.940]   The number alone doesn't mean anything.
[03:48:09.940 --> 03:48:10.780]   - Yeah.
[03:48:10.780 --> 03:48:11.600]   - Okay.
[03:48:11.600 --> 03:48:12.860]   - Well, you could meet a guy that's like,
[03:48:12.860 --> 03:48:14.900]   I just really, really want to fuck a lot of people
[03:48:14.900 --> 03:48:16.820]   because it makes me so cool.
[03:48:16.820 --> 03:48:18.940]   You can meet someone like that, which is like, maybe.
[03:48:18.940 --> 03:48:19.860]   - So the body count doesn't matter,
[03:48:19.860 --> 03:48:21.140]   but where it comes from.
[03:48:21.140 --> 03:48:23.500]   - Yeah, like why have you slept with the people
[03:48:23.500 --> 03:48:24.580]   you slept with?
[03:48:24.580 --> 03:48:26.900]   - Does it hurt the romantic aspect of the relationship,
[03:48:26.900 --> 03:48:29.380]   knowing that there's a lot of people in the past?
[03:48:29.380 --> 03:48:30.220]   - I don't know.
[03:48:30.220 --> 03:48:31.180]   - Not for us, no.
[03:48:31.180 --> 03:48:34.060]   - Is the part of the relationship fundamentally romantic?
[03:48:34.060 --> 03:48:34.900]   - For us, yeah, I'd say so, yeah.
[03:48:34.900 --> 03:48:36.180]   - For us, yeah, pretty soon.
[03:48:36.180 --> 03:48:37.020]   - Okay.
[03:48:37.020 --> 03:48:37.860]   (laughing)
[03:48:37.860 --> 03:48:39.260]   - What?
[03:48:39.260 --> 03:48:40.900]   - You come off as such a cold person.
[03:48:40.900 --> 03:48:42.140]   - No, I was just in my head thinking,
[03:48:42.140 --> 03:48:44.260]   I wanted to just say gotcha right there.
[03:48:44.260 --> 03:48:45.100]   - Oh, nice.
[03:48:45.100 --> 03:48:45.940]   (laughing)
[03:48:45.940 --> 03:48:47.100]   - It's so judgmental.
[03:48:47.100 --> 03:48:48.440]   - I think when it comes to the sex thing,
[03:48:48.440 --> 03:48:50.040]   there's always like, the way that I explain it is,
[03:48:50.040 --> 03:48:52.460]   and I understand, like, I have to say this
[03:48:52.460 --> 03:48:54.760]   'cause I don't advocate for what I do for everybody
[03:48:54.760 --> 03:48:55.840]   or what she does for everybody,
[03:48:55.840 --> 03:48:58.160]   'cause obviously there's a whole bunch of natural feelings
[03:48:58.160 --> 03:49:00.340]   of jealousy that pop up for a lot of people.
[03:49:00.340 --> 03:49:01.880]   But when people ask me, it's always like,
[03:49:01.880 --> 03:49:04.240]   oh, isn't this horrible that you guys are doing this
[03:49:04.240 --> 03:49:05.520]   and you don't love each other?
[03:49:05.520 --> 03:49:08.600]   From my perspective, I can have sex with any person
[03:49:08.600 --> 03:49:09.480]   and it can be sex.
[03:49:09.480 --> 03:49:12.040]   That's not a special thing between two people, in my eyes.
[03:49:12.040 --> 03:49:13.440]   It's like anybody can have sex.
[03:49:13.440 --> 03:49:15.960]   But there are certain activities and ways
[03:49:15.960 --> 03:49:17.440]   you can spend time with each other
[03:49:17.440 --> 03:49:19.440]   where you're carving out these precious little moments
[03:49:19.440 --> 03:49:21.280]   in time with a certain person that can do things
[03:49:21.280 --> 03:49:22.760]   that are special to that person.
[03:49:22.760 --> 03:49:24.320]   And those are the kind of events
[03:49:24.320 --> 03:49:26.480]   that I remember more than anything else.
[03:49:26.480 --> 03:49:29.680]   So the idea of like, oh, wow, I had sex with a person
[03:49:29.680 --> 03:49:31.940]   that was so special doesn't mean as much as like,
[03:49:31.940 --> 03:49:34.300]   you know, us traveling to like New Zealand
[03:49:34.300 --> 03:49:35.500]   or sharing some special moment,
[03:49:35.500 --> 03:49:37.820]   doing like some really fun activity or event or whatever.
[03:49:37.820 --> 03:49:39.540]   That's usually how I like it, yeah.
[03:49:39.540 --> 03:49:41.300]   - So a shared intimate moment.
[03:49:41.300 --> 03:49:42.140]   - Yeah.
[03:49:42.140 --> 03:49:42.960]   - I kind of agree,
[03:49:42.960 --> 03:49:44.900]   but I can definitely connect the romance with sex.
[03:49:44.900 --> 03:49:45.740]   - Boring.
[03:49:45.740 --> 03:49:46.580]   (laughing)
[03:49:46.580 --> 03:49:47.400]   - I'm curious why you can't do that.
[03:49:47.400 --> 03:49:48.240]   - That's 'cause she's a woman.
[03:49:48.240 --> 03:49:49.060]   See, that's where the red pill's right.
[03:49:49.060 --> 03:49:49.900]   That's exactly what you can't.
[03:49:49.900 --> 03:49:51.900]   - We also talked about misogyny,
[03:49:51.900 --> 03:49:54.380]   which is clearly the embodiment of that.
[03:49:54.380 --> 03:49:55.580]   What were you saying?
[03:49:55.580 --> 03:49:58.020]   So there's a connection between romance and sex?
[03:49:58.020 --> 03:49:59.380]   - Yeah, I think it is.
[03:49:59.380 --> 03:50:02.740]   Because I think sex could be a lot of things, right?
[03:50:02.740 --> 03:50:06.740]   It's some sort of bonding, I'd say, in some way.
[03:50:06.740 --> 03:50:08.900]   Let's say that you really like BDSM.
[03:50:08.900 --> 03:50:11.360]   You kind of like, you become submissive to someone
[03:50:11.360 --> 03:50:12.620]   or you take control over someone.
[03:50:12.620 --> 03:50:16.340]   It's like a very bonding, like intimate moment, I'd say.
[03:50:16.340 --> 03:50:17.180]   - And that's romantic.
[03:50:17.180 --> 03:50:18.020]   The intimacy is romantic.
[03:50:18.020 --> 03:50:19.060]   - I think it is.
[03:50:19.060 --> 03:50:21.820]   If you can show yourself as really submissive or like weak,
[03:50:21.820 --> 03:50:23.920]   or you have like absolutely no control over yourself
[03:50:23.920 --> 03:50:25.380]   and you let someone else do it,
[03:50:25.380 --> 03:50:27.000]   or you are the one being that,
[03:50:27.000 --> 03:50:28.620]   like you are the dominant force of someone.
[03:50:28.620 --> 03:50:30.420]   I think that's a really like intimate thing.
[03:50:30.420 --> 03:50:34.060]   'Cause you show like the weakest part of yourself, kind of.
[03:50:34.060 --> 03:50:35.740]   - I just feel like I personally,
[03:50:35.740 --> 03:50:39.340]   to me, some component of romantic,
[03:50:39.340 --> 03:50:40.960]   but to me, this is not judging to others.
[03:50:40.960 --> 03:50:43.060]   To me, maybe it's how I was brought up,
[03:50:43.060 --> 03:50:49.460]   the romance increases if the number of intimate interactions
[03:50:49.460 --> 03:50:51.580]   are limited to one person.
[03:50:51.580 --> 03:50:56.340]   For me, for some reason, spreading it out
[03:50:57.700 --> 03:51:02.700]   decreases exponentially the feeling of romance you feel.
[03:51:02.700 --> 03:51:07.860]   That could be just like sort of having grown up
[03:51:07.860 --> 03:51:11.620]   in the Soviet Union, there's the fairy tale stories
[03:51:11.620 --> 03:51:14.660]   and you're kind of maybe living through them.
[03:51:14.660 --> 03:51:15.500]   - Yeah, I mean, I think what you're saying
[03:51:15.500 --> 03:51:16.460]   is like really normal.
[03:51:16.460 --> 03:51:18.700]   Like most people probably feel that way, yeah.
[03:51:18.700 --> 03:51:21.220]   - But because you guys are able to successfully not do that,
[03:51:21.220 --> 03:51:24.320]   I just wanna question my own understanding of it.
[03:51:24.320 --> 03:51:26.420]   - Like why is that?
[03:51:26.420 --> 03:51:27.260]   - Why is that?
[03:51:27.260 --> 03:51:30.820]   - Like am I being very jealous for no reason?
[03:51:30.820 --> 03:51:33.820]   Maybe you can maximize the number of intimate experiences
[03:51:33.820 --> 03:51:37.100]   if you just open up and let go of the jealousy, essentially.
[03:51:37.100 --> 03:51:39.100]   - I feel like in Sweden, like in Scandinavia,
[03:51:39.100 --> 03:51:42.060]   we're extremely just sexually open, in general.
[03:51:42.060 --> 03:51:44.180]   We're not super religious either.
[03:51:44.180 --> 03:51:45.780]   We're very relaxed.
[03:51:45.780 --> 03:51:48.740]   We don't feel bad about ourselves.
[03:51:48.740 --> 03:51:49.940]   It's just like a different sort of thing.
[03:51:49.940 --> 03:51:51.980]   And I would say we're more progressive
[03:51:51.980 --> 03:51:53.700]   when it comes to feminism and stuff.
[03:51:53.700 --> 03:51:55.980]   So it's more common that you will meet women
[03:51:55.980 --> 03:51:57.660]   with a higher body count than like,
[03:51:57.660 --> 03:51:59.020]   when I meet like American girls,
[03:51:59.020 --> 03:52:00.540]   all of them have like vaginismus,
[03:52:00.540 --> 03:52:02.220]   like super suppressed sexually.
[03:52:02.220 --> 03:52:03.060]   And they have like-
[03:52:03.060 --> 03:52:04.340]   - What did you just use?
[03:52:04.340 --> 03:52:06.360]   - They have like issues to like,
[03:52:06.360 --> 03:52:08.700]   they can't relax during sex, which just hurts for them.
[03:52:08.700 --> 03:52:09.860]   - Vaginismus. - So they get really nervous.
[03:52:09.860 --> 03:52:10.940]   Vaginismus, is that what it's called?
[03:52:10.940 --> 03:52:12.380]   Yeah.
[03:52:12.380 --> 03:52:13.820]   So like I meet so many girls
[03:52:13.820 --> 03:52:16.660]   that are having like a lot of issues with sex
[03:52:16.660 --> 03:52:18.220]   and they have like a very low body count
[03:52:18.220 --> 03:52:19.980]   because they just can't relax.
[03:52:19.980 --> 03:52:22.620]   Yeah, and usually they come
[03:52:22.620 --> 03:52:24.720]   from like a very religious background.
[03:52:24.720 --> 03:52:26.820]   So they have just been told like, you cannot wear that.
[03:52:26.820 --> 03:52:27.900]   You cannot be like that.
[03:52:27.900 --> 03:52:29.340]   You can't like, you know.
[03:52:29.340 --> 03:52:32.540]   And like where I grew up, it wasn't like that at all.
[03:52:32.540 --> 03:52:35.100]   We just see it as more like a casual thing.
[03:52:35.100 --> 03:52:36.980]   - So then you can just maximize
[03:52:36.980 --> 03:52:39.900]   the awesomeness of the experience.
[03:52:39.900 --> 03:52:40.740]   - Yeah, I guess.
[03:52:40.740 --> 03:52:41.560]   I don't like how I go. - You don't have to
[03:52:41.560 --> 03:52:42.380]   trauma over it. - Exactly, yeah.
[03:52:42.380 --> 03:52:43.740]   - I think the important thing I think
[03:52:43.740 --> 03:52:44.700]   for everybody to realize
[03:52:44.700 --> 03:52:46.740]   is there's always pros and cons to everything.
[03:52:46.740 --> 03:52:48.380]   Like my lifestyle,
[03:52:48.380 --> 03:52:50.180]   like obviously I get to have a lot of fun experiences.
[03:52:50.180 --> 03:52:52.180]   That's like a huge pro and that's super cool.
[03:52:52.180 --> 03:52:54.300]   And if you're like a more monogamy brain person,
[03:52:54.300 --> 03:52:55.680]   you're not gonna get those experiences.
[03:52:55.680 --> 03:52:57.280]   But if you're a monogamy brain person,
[03:52:57.280 --> 03:52:58.760]   like when you're sharing that special moment
[03:52:58.760 --> 03:52:59.760]   in time with somebody else,
[03:52:59.760 --> 03:53:01.960]   like that moment can be really, really, really special
[03:53:01.960 --> 03:53:03.920]   because now it's the thing that you're showing yourself
[03:53:03.920 --> 03:53:05.220]   and open yourself up to another person
[03:53:05.220 --> 03:53:06.760]   and they're only trusting you to do that.
[03:53:06.760 --> 03:53:08.000]   And that's like a really special thing
[03:53:08.000 --> 03:53:09.980]   that only the two of you are sharing with each other.
[03:53:09.980 --> 03:53:11.400]   So, I mean like there's always like pros and cons
[03:53:11.400 --> 03:53:12.240]   to everything.
[03:53:12.240 --> 03:53:13.600]   - Like I think we both would say like,
[03:53:13.600 --> 03:53:15.600]   like doing an open relationship is probably not,
[03:53:15.600 --> 03:53:17.600]   like we would not recommend it.
[03:53:17.600 --> 03:53:20.080]   - Yeah, no, of course not. - I don't think we would, no.
[03:53:20.080 --> 03:53:22.240]   - Yeah, I recently fasted for three days
[03:53:22.240 --> 03:53:24.420]   and I ate a chicken breast at the end of that.
[03:53:24.420 --> 03:53:27.180]   And it was like the most delicious food I've ever eaten.
[03:53:27.180 --> 03:53:28.020]   - True.
[03:53:28.020 --> 03:53:30.340]   - So like there's some aspect of fasting and scarcity
[03:53:30.340 --> 03:53:31.180]   and so on that like,
[03:53:31.180 --> 03:53:33.620]   and you have to figure out what for your own psyche,
[03:53:33.620 --> 03:53:34.460]   what works the best.
[03:53:34.460 --> 03:53:36.780]   - It's good to be a little bored or like not do something
[03:53:36.780 --> 03:53:39.500]   or like work because you can just enjoy the time
[03:53:39.500 --> 03:53:41.020]   when you're doing something really fun.
[03:53:41.020 --> 03:53:42.980]   It's more fun, otherwise you're just gonna get numb
[03:53:42.980 --> 03:53:44.820]   in general with everything, yeah.
[03:53:44.820 --> 03:53:46.720]   - Yeah, I personally just never get bored.
[03:53:46.720 --> 03:53:49.820]   Like I guess the boring thing is exciting to me.
[03:53:49.820 --> 03:53:50.660]   Though it's just like--
[03:53:50.660 --> 03:53:51.700]   - Are you like me?
[03:53:51.700 --> 03:53:54.940]   'Cause everything I like is boring.
[03:53:54.940 --> 03:53:56.980]   - I gotta ask you, we talked about massaging
[03:53:56.980 --> 03:53:59.740]   and he's trying to battle it out on the internet.
[03:53:59.740 --> 03:54:04.740]   What's your sense as a woman about the level of massaging
[03:54:04.740 --> 03:54:07.180]   and the internet and the streaming community
[03:54:07.180 --> 03:54:08.820]   and how to fight it?
[03:54:08.820 --> 03:54:12.860]   - For me, 'cause I guess I get it every single day somehow.
[03:54:12.860 --> 03:54:14.260]   Like, because I have an online,
[03:54:14.260 --> 03:54:16.380]   like I have a chat that's live, right?
[03:54:16.380 --> 03:54:19.100]   But I have like mods moderating that all the time
[03:54:19.100 --> 03:54:20.540]   so I don't really need to see much of it.
[03:54:20.540 --> 03:54:22.100]   I think it's just pretty annoying
[03:54:22.100 --> 03:54:25.080]   because you get to like see it all the time.
[03:54:25.080 --> 03:54:28.380]   - So it's become like background noise?
[03:54:28.380 --> 03:54:30.700]   - Yeah, a little bit and it's like the same comms
[03:54:30.700 --> 03:54:31.900]   over and over again.
[03:54:31.900 --> 03:54:34.980]   But it's usually for me, I don't personally care that much.
[03:54:34.980 --> 03:54:36.180]   I understand that other people do,
[03:54:36.180 --> 03:54:37.900]   especially when it comes into like,
[03:54:37.900 --> 03:54:40.100]   when there's like a lot of sexism and stuff
[03:54:40.100 --> 03:54:42.340]   and when there's a lot of like men
[03:54:42.340 --> 03:54:43.420]   not taking women seriously.
[03:54:43.420 --> 03:54:45.700]   Like I definitely get that and I used to get that even more
[03:54:45.700 --> 03:54:48.340]   like a few years ago with my accent and everything
[03:54:48.340 --> 03:54:50.500]   and like I used to be blonde as well like a few months ago.
[03:54:50.500 --> 03:54:52.220]   So I feel like people wouldn't take me seriously
[03:54:52.220 --> 03:54:53.460]   because of that.
[03:54:53.460 --> 03:54:57.180]   That's a bit annoying, but I feel like it's pretty easy
[03:54:57.180 --> 03:54:59.020]   to like see through when someone acts that way.
[03:54:59.020 --> 03:55:00.620]   And for me personally, I don't really care.
[03:55:00.620 --> 03:55:03.700]   But it's a bit annoying, like being online
[03:55:03.700 --> 03:55:05.700]   and like getting stuff every single day.
[03:55:05.700 --> 03:55:08.560]   I would say like probably the worst thing is
[03:55:08.560 --> 03:55:10.500]   when you feel like you put in a lot of effort
[03:55:10.500 --> 03:55:13.500]   into some sort of work, everyone is just gonna say,
[03:55:13.500 --> 03:55:15.460]   you just got that because you're a woman
[03:55:15.460 --> 03:55:16.380]   and you're attractive.
[03:55:16.380 --> 03:55:18.740]   And that's probably like the worst thing.
[03:55:18.740 --> 03:55:20.500]   - Is there a way to fight that you think?
[03:55:20.500 --> 03:55:21.460]   - Yeah, I don't think you can.
[03:55:21.460 --> 03:55:22.820]   I think it just comes up all the time.
[03:55:22.820 --> 03:55:24.900]   It's just like, it is what it is, I guess.
[03:55:24.900 --> 03:55:26.300]   You just gotta keep doing whatever you do
[03:55:26.300 --> 03:55:28.980]   and like not let it like emotionally control you somehow.
[03:55:28.980 --> 03:55:31.060]   - I think having more women in those spaces is always good.
[03:55:31.060 --> 03:55:31.900]   - It's probably good, yeah.
[03:55:31.900 --> 03:55:33.220]   - Like a lot of the guys you can tell online
[03:55:33.220 --> 03:55:34.060]   that they don't ever--
[03:55:34.060 --> 03:55:35.860]   - Don't bring on the worst ones then, Stephen.
[03:55:35.860 --> 03:55:37.740]   - See, she just did it.
[03:55:37.740 --> 03:55:39.700]   She did the misogyny thing.
[03:55:39.700 --> 03:55:42.380]   By having some bad women on, she's saying all women, see?
[03:55:42.380 --> 03:55:46.060]   - Well, you know it's true, right?
[03:55:46.060 --> 03:55:48.700]   - See, I disagree with you and I'm older than both of you.
[03:55:48.700 --> 03:55:50.340]   And therefore wiser, right?
[03:55:50.340 --> 03:55:51.180]   So--
[03:55:51.180 --> 03:55:52.020]   - Well, combined, we're older than you.
[03:55:52.020 --> 03:55:52.860]   - I think we're--
[03:55:52.860 --> 03:55:53.700]   - So, careful.
[03:55:53.700 --> 03:55:55.020]   - We're one only metronomy.
[03:55:55.020 --> 03:55:56.460]   Yeah, we've got combined age.
[03:55:56.460 --> 03:55:59.420]   - Or it could be the same thing as like,
[03:55:59.420 --> 03:56:01.300]   also the age thing and like the woman thing.
[03:56:01.300 --> 03:56:02.700]   A lot of people think that I'm just copying
[03:56:02.700 --> 03:56:04.180]   every single thing that he says,
[03:56:04.180 --> 03:56:05.420]   which I think is a bit annoying as well.
[03:56:05.420 --> 03:56:06.580]   So I can never really like--
[03:56:06.580 --> 03:56:07.660]   - Hassan accused her of that one time.
[03:56:07.660 --> 03:56:08.980]   - Yeah, which is a bit annoying.
[03:56:08.980 --> 03:56:10.580]   - I don't really like so much, you know?
[03:56:10.580 --> 03:56:11.980]   - It was about the defunding police.
[03:56:11.980 --> 03:56:12.820]   Like my dad is a cop.
[03:56:12.820 --> 03:56:16.260]   - I like friendship, camaraderie, and love and respect,
[03:56:16.260 --> 03:56:20.100]   which you both have had for a time and have lost.
[03:56:20.100 --> 03:56:22.060]   And I would like you to regain it.
[03:56:22.060 --> 03:56:23.820]   Let's try to increase, not decrease,
[03:56:23.820 --> 03:56:25.140]   the amount of love in this space.
[03:56:25.140 --> 03:56:26.980]   What do you think about some of the harshness
[03:56:26.980 --> 03:56:29.420]   of his language, which we talked about?
[03:56:29.420 --> 03:56:33.860]   R-word in the past, when you used N-word,
[03:56:33.860 --> 03:56:34.700]   all of that kind of stuff.
[03:56:34.700 --> 03:56:36.100]   - When he, what he used to do?
[03:56:36.100 --> 03:56:37.020]   I mean, I just--
[03:56:37.020 --> 03:56:37.860]   - No, like, what do you think about it?
[03:56:37.860 --> 03:56:39.300]   Like, do you give him advice?
[03:56:39.300 --> 03:56:41.220]   - To not speak a certain way?
[03:56:41.220 --> 03:56:43.100]   - No, like a little more civility?
[03:56:43.100 --> 03:56:44.980]   I was just trying to get a second opinion on this.
[03:56:44.980 --> 03:56:45.820]   - Second opinion about--
[03:56:45.820 --> 03:56:47.140]   - Normie people, non-internet people,
[03:56:47.140 --> 03:56:48.820]   are way more extreme than--
[03:56:48.820 --> 03:56:49.660]   - Yeah, yeah.
[03:56:49.660 --> 03:56:50.660]   - She's way more extreme.
[03:56:50.660 --> 03:56:52.100]   - No, that's not true.
[03:56:52.100 --> 03:56:54.500]   Okay, so here's the thing for me, okay?
[03:56:54.500 --> 03:56:57.740]   I was not online until three years ago, at all.
[03:56:57.740 --> 03:56:58.980]   Like, I would watch YouTube.
[03:56:58.980 --> 03:57:00.580]   That's pretty much all I would do.
[03:57:00.580 --> 03:57:02.020]   I wouldn't do anything else, really.
[03:57:02.020 --> 03:57:04.740]   I didn't grow up playing video games or anything.
[03:57:04.740 --> 03:57:06.740]   So I'm like extremely new to everything.
[03:57:06.740 --> 03:57:10.340]   So when I came into this world
[03:57:10.340 --> 03:57:12.860]   and I started seeing clips from him in the past,
[03:57:12.860 --> 03:57:14.420]   I don't think I really had much of an opinion
[03:57:14.420 --> 03:57:15.460]   because it just sounded like
[03:57:15.460 --> 03:57:17.300]   it was just a different words that we're using,
[03:57:17.300 --> 03:57:18.700]   but it didn't mean anything.
[03:57:18.700 --> 03:57:19.540]   That's what it feels like.
[03:57:19.540 --> 03:57:21.660]   It was just like, if you're saying the R word,
[03:57:21.660 --> 03:57:23.220]   it's because you just want to call someone stupid,
[03:57:23.220 --> 03:57:25.300]   but you want to do it a little bit more.
[03:57:25.300 --> 03:57:27.860]   But it's not like, it didn't feel like it was a,
[03:57:27.860 --> 03:57:29.060]   it's not like racist more like--
[03:57:29.060 --> 03:57:32.780]   - Yeah, but I'm not getting an agreement on this side here.
[03:57:32.780 --> 03:57:34.500]   - So like, if he was saying the F word
[03:57:34.500 --> 03:57:37.780]   because it was just like a word to insult someone
[03:57:37.780 --> 03:57:39.660]   and he wasn't, like, I don't think he was ever,
[03:57:39.660 --> 03:57:41.580]   I don't think you were ever homophobic back in the day
[03:57:41.580 --> 03:57:42.420]   or anything like that.
[03:57:42.420 --> 03:57:45.300]   I think it was just like a way to express yourself
[03:57:45.300 --> 03:57:46.140]   maybe back then.
[03:57:46.140 --> 03:57:47.020]   I don't know, I didn't do it.
[03:57:47.020 --> 03:57:48.260]   There's no videos of me or anything
[03:57:48.260 --> 03:57:49.540]   'cause I wasn't even online back then.
[03:57:49.540 --> 03:57:51.180]   - Yeah, so my case was,
[03:57:51.180 --> 03:57:54.460]   I definitely don't think Stephen is homophobic,
[03:57:54.460 --> 03:57:55.740]   or racist, or any of those, obviously.
[03:57:55.740 --> 03:57:59.300]   So there's a good heart there and a good mind.
[03:57:59.300 --> 03:58:00.140]   I was just saying--
[03:58:00.140 --> 03:58:02.220]   - He just likes being mean, I think.
[03:58:02.220 --> 03:58:04.300]   - Well, there is some, you lose yourself
[03:58:04.300 --> 03:58:05.540]   and forget the bigger picture
[03:58:05.540 --> 03:58:09.180]   that he's pushing for more effective discourse
[03:58:09.180 --> 03:58:10.020]   on the internet.
[03:58:10.020 --> 03:58:11.420]   He's like an inspiration to a lot of people,
[03:58:11.420 --> 03:58:14.860]   especially now, of how you can use effective conversation
[03:58:14.860 --> 03:58:18.260]   to make for a better world, to radicalize people,
[03:58:18.260 --> 03:58:19.080]   and so on.
[03:58:19.080 --> 03:58:21.020]   And then you lose some of that power
[03:58:21.020 --> 03:58:24.940]   by losing yourself in the language,
[03:58:24.940 --> 03:58:26.500]   just more language of emotion
[03:58:26.500 --> 03:58:28.460]   versus effective communication.
[03:58:28.460 --> 03:58:30.460]   - I would say-- - But it's a gray area.
[03:58:30.460 --> 03:58:32.420]   - I would say something that is probably recently done
[03:58:32.420 --> 03:58:35.540]   in that case, because he's been joking about women a lot.
[03:58:35.540 --> 03:58:37.820]   Like, it's women's fault, they're bad.
[03:58:37.820 --> 03:58:40.380]   It's been a lot of jokes when it comes to misogyny,
[03:58:40.380 --> 03:58:41.700]   I guess, in your community.
[03:58:41.700 --> 03:58:43.340]   And I think it's actually turned people
[03:58:43.340 --> 03:58:44.180]   a little bit that way.
[03:58:44.180 --> 03:58:45.580]   - That's why we've done the recent misogyny.
[03:58:45.580 --> 03:58:47.980]   - Yes, so I guess that's actually true,
[03:58:47.980 --> 03:58:50.940]   because I don't think it was clear enough.
[03:58:50.940 --> 03:58:51.940]   I don't think it actually was.
[03:58:51.940 --> 03:58:53.580]   I think you did that mistake.
[03:58:53.580 --> 03:58:56.100]   But I think back then I was even saying,
[03:58:56.100 --> 03:58:57.300]   like, hey, you should probably not,
[03:58:57.300 --> 03:59:00.260]   like, you probably should not do that.
[03:59:00.260 --> 03:59:01.620]   'Cause it actually is pretty hard for me,
[03:59:01.620 --> 03:59:04.200]   'cause whenever I come into his community, like his chat,
[03:59:04.200 --> 03:59:06.020]   people are just gonna spam, it's like a woman moment.
[03:59:06.020 --> 03:59:07.580]   It's a woman moment whenever I say something,
[03:59:07.580 --> 03:59:10.020]   and it's kind of like, yeah, it's getting pretty annoying,
[03:59:10.020 --> 03:59:11.180]   as I said, it's just annoying
[03:59:11.180 --> 03:59:12.820]   when you see it every single day.
[03:59:12.820 --> 03:59:17.060]   - There you go, wisdom from somebody younger than you.
[03:59:17.060 --> 03:59:19.260]   - Wisdom can come from all kind of people.
[03:59:19.260 --> 03:59:21.580]   Yeah, of course, just sometimes in very limited quantities,
[03:59:21.580 --> 03:59:22.420]   depends on the age.
[03:59:22.420 --> 03:59:23.260]   - Oh boy.
[03:59:23.260 --> 03:59:25.220]   - You can learn something from anybody.
[03:59:25.220 --> 03:59:27.540]   - What advice would you give to young people,
[03:59:27.540 --> 03:59:31.580]   the both of you, that you have both audiences
[03:59:31.580 --> 03:59:33.420]   where young people look up to you?
[03:59:33.420 --> 03:59:35.260]   In general, if you were to give advice
[03:59:35.260 --> 03:59:39.560]   to somebody in high school, like how to create a life
[03:59:39.560 --> 03:59:41.560]   they can be proud of, what would you say?
[03:59:41.560 --> 03:59:44.860]   - The most important thing that I've learned
[03:59:44.860 --> 03:59:48.620]   is to view people as different and not better or worse.
[03:59:48.620 --> 03:59:49.780]   And when you view people as different
[03:59:49.780 --> 03:59:50.940]   instead of better or worse,
[03:59:50.940 --> 03:59:52.900]   you learn that there's almost something
[03:59:52.900 --> 03:59:54.780]   that you can learn from anybody.
[03:59:54.780 --> 03:59:55.900]   Like be open and empathetic
[03:59:55.900 --> 03:59:57.440]   towards other people's experiences.
[03:59:57.440 --> 04:00:00.060]   Nobody does anything by random choice.
[04:00:00.060 --> 04:00:02.340]   Like there's always reasons why people act the way they do.
[04:00:02.340 --> 04:00:04.600]   And as long as you're willing to kind of like be open
[04:00:04.600 --> 04:00:07.280]   and receptive to the lived experiences of other people,
[04:00:07.280 --> 04:00:09.020]   you're gonna be able to gather information
[04:00:09.020 --> 04:00:11.460]   and create like a more cohesive and better view of the world
[04:00:11.460 --> 04:00:13.660]   than any of your peers will.
[04:00:13.660 --> 04:00:15.300]   - Do you have any kind of advice
[04:00:15.300 --> 04:00:16.940]   you can give to young folks?
[04:00:16.940 --> 04:00:18.200]   - I feel like something that I see,
[04:00:18.200 --> 04:00:19.540]   especially in America a lot,
[04:00:19.540 --> 04:00:23.020]   is that a lot of people kind of get told what to do
[04:00:23.020 --> 04:00:24.660]   early on, like in high school.
[04:00:24.660 --> 04:00:26.980]   They're supposed to become this thing,
[04:00:26.980 --> 04:00:28.700]   like education-wise, like they're supposed to like
[04:00:28.700 --> 04:00:30.620]   become a doctor or this thing or whatever.
[04:00:30.620 --> 04:00:32.020]   And then they kind of just like give up on things
[04:00:32.020 --> 04:00:33.480]   that they're actually passionate about.
[04:00:33.480 --> 04:00:35.880]   So I think a lot of teenagers get really confused.
[04:00:35.880 --> 04:00:38.380]   They get an education and then they get that job
[04:00:38.380 --> 04:00:39.300]   and they hate everything.
[04:00:39.300 --> 04:00:42.260]   And they think that when they're reaching the job,
[04:00:42.260 --> 04:00:43.340]   when they're reaching like the journey,
[04:00:43.340 --> 04:00:44.180]   they're gonna get happy.
[04:00:44.180 --> 04:00:45.620]   That's like where the happiness is gonna be.
[04:00:45.620 --> 04:00:47.500]   But then when they get to there,
[04:00:47.500 --> 04:00:48.660]   they just hate everything.
[04:00:48.660 --> 04:00:50.420]   And then they become really depressed.
[04:00:50.420 --> 04:00:51.960]   And I've seen this so much.
[04:00:51.960 --> 04:00:53.500]   Like I've seen this all the time.
[04:00:53.500 --> 04:00:57.040]   And it's pretty sad to me to see so many people
[04:00:57.040 --> 04:00:58.260]   that are just wasting time.
[04:00:58.260 --> 04:01:00.020]   And then they just get really confused.
[04:01:00.020 --> 04:01:03.300]   And I don't know, it's the same thing with relationships too.
[04:01:03.300 --> 04:01:05.060]   No one really knows what they want anymore.
[04:01:05.060 --> 04:01:07.100]   I feel like everyone is just kind of doing whatever
[04:01:07.100 --> 04:01:08.820]   like society is saying or the parents are saying
[04:01:08.820 --> 04:01:10.220]   or their friends are saying.
[04:01:10.220 --> 04:01:12.980]   And they're never really doing anything
[04:01:12.980 --> 04:01:14.460]   that's super meaningful anymore.
[04:01:14.460 --> 04:01:17.100]   And like they don't, so what I would say is like,
[04:01:17.100 --> 04:01:19.860]   try to find something that is important to you.
[04:01:19.860 --> 04:01:22.540]   It could be anything really, like some sort of passion,
[04:01:22.540 --> 04:01:25.940]   maybe like your friends, maybe like what matters to you.
[04:01:25.940 --> 04:01:27.420]   Like figuring those things out,
[04:01:27.420 --> 04:01:28.260]   I think is really important.
[04:01:28.260 --> 04:01:30.060]   - And that comes from being able to listen
[04:01:30.060 --> 04:01:31.420]   to like some inner voice.
[04:01:31.420 --> 04:01:32.260]   So it's not gonna come from elsewhere.
[04:01:32.260 --> 04:01:33.100]   - Yeah, I guess.
[04:01:33.100 --> 04:01:34.940]   It's really hard because you're living the life
[04:01:34.940 --> 04:01:36.460]   and like there's things happening around you
[04:01:36.460 --> 04:01:39.060]   and people tell you what to do and what not to do.
[04:01:39.060 --> 04:01:40.660]   No one really has like their own opinions.
[04:01:40.660 --> 04:01:42.820]   Everyone is just kind of like listening
[04:01:42.820 --> 04:01:45.340]   to the cooler thing or, you know.
[04:01:45.340 --> 04:01:47.500]   - Except Steven, he seems to stand on his own.
[04:01:47.500 --> 04:01:48.340]   - True. - Yeah, I guess.
[04:01:48.340 --> 04:01:49.340]   - Free thinking. - Yeah, I'd say so.
[04:01:49.340 --> 04:01:50.260]   - High hashtag.
[04:01:50.260 --> 04:01:51.700]   - Like something I realized too,
[04:01:51.700 --> 04:01:52.940]   'cause we just went to TwitchCon
[04:01:52.940 --> 04:01:54.700]   and we were talking to a lot of streamers.
[04:01:54.700 --> 04:01:56.100]   - How was that?
[04:01:56.100 --> 04:01:56.940]   - It was interesting.
[04:01:56.940 --> 04:02:00.020]   I thought it was interesting because the few people
[04:02:00.020 --> 04:02:01.900]   that I feel like that seem really cool
[04:02:01.900 --> 04:02:04.300]   and that I look up to like in the streaming world,
[04:02:04.300 --> 04:02:06.420]   all of them wants to quit streaming.
[04:02:06.420 --> 04:02:07.300]   All of them wants to do it.
[04:02:07.300 --> 04:02:08.780]   No one wants, like no one likes it.
[04:02:08.780 --> 04:02:10.620]   And they're so successful.
[04:02:10.620 --> 04:02:13.220]   Like they are around successful people.
[04:02:13.220 --> 04:02:15.300]   They're working every single day.
[04:02:15.300 --> 04:02:16.140]   They're working hard.
[04:02:16.140 --> 04:02:17.460]   They're making so much money.
[04:02:17.460 --> 04:02:19.540]   And everyone is just complaining.
[04:02:19.540 --> 04:02:23.140]   And like, they're complaining about like not being able
[04:02:23.140 --> 04:02:25.780]   to see their partner or, you know,
[04:02:25.780 --> 04:02:27.260]   because they need to live somewhere else.
[04:02:27.260 --> 04:02:31.220]   Because I see these things and they seem extremely unhappy.
[04:02:31.220 --> 04:02:33.060]   But it's so hard for them to just like cut
[04:02:33.060 --> 04:02:35.060]   all this successful stuff off
[04:02:35.060 --> 04:02:38.500]   because that's like what you, you know, learn to do.
[04:02:38.500 --> 04:02:40.500]   And that's like supposed to be like your happiness,
[04:02:40.500 --> 04:02:41.340]   but it isn't.
[04:02:41.340 --> 04:02:42.380]   Everyone is really unhappy.
[04:02:42.380 --> 04:02:43.540]   - Yeah, there's something about,
[04:02:43.540 --> 04:02:44.980]   maybe streaming is different,
[04:02:44.980 --> 04:02:47.620]   but YouTube folks too, I've interacted with a few.
[04:02:47.620 --> 04:02:50.980]   And even in podcasting space,
[04:02:50.980 --> 04:02:53.660]   people become obsessed about the views and numbers
[04:02:53.660 --> 04:02:55.460]   and subscribers and stuff like that.
[04:02:55.460 --> 04:02:59.020]   So I turn, I never talk about that.
[04:02:59.020 --> 04:03:00.780]   I don't pay attention to that.
[04:03:02.060 --> 04:03:06.900]   I feel like that's a drug that destroys your mind.
[04:03:06.900 --> 04:03:08.460]   Your mind as an artist,
[04:03:08.460 --> 04:03:12.020]   ability to create truly unique things.
[04:03:12.020 --> 04:03:14.020]   Also your mind in terms of the anxiety,
[04:03:14.020 --> 04:03:18.060]   the ups and downs of the attention mechanism.
[04:03:18.060 --> 04:03:20.940]   And then also being just,
[04:03:20.940 --> 04:03:23.540]   if something that you make is not popular,
[04:03:23.540 --> 04:03:24.940]   but it meant a lot to you,
[04:03:24.940 --> 04:03:28.380]   you will think of it less because it's not popular.
[04:03:28.380 --> 04:03:29.620]   That's a really dangerous thing.
[04:03:29.620 --> 04:03:32.740]   And because everyone around you is reinforcing,
[04:03:32.740 --> 04:03:34.700]   like I'll get messages like,
[04:03:34.700 --> 04:03:38.500]   "Wow, this thing got this many views or something.
[04:03:38.500 --> 04:03:39.660]   Great job."
[04:03:39.660 --> 04:03:41.980]   It's like, no, you don't get it.
[04:03:41.980 --> 04:03:44.140]   Like that's not, that's not,
[04:03:44.140 --> 04:03:45.540]   everyone is enforcing this,
[04:03:45.540 --> 04:03:48.980]   like this language of views and likes and so on.
[04:03:48.980 --> 04:03:51.100]   And it's correlated of course,
[04:03:51.100 --> 04:03:52.340]   'cause truly impactful things
[04:03:52.340 --> 04:03:55.020]   will get a lot of attention often,
[04:03:55.020 --> 04:03:59.300]   but it's not on the individual local scale,
[04:03:59.300 --> 04:04:00.780]   like temporarily is,
[04:04:00.780 --> 04:04:03.740]   it can really fuck with your mind.
[04:04:03.740 --> 04:04:05.620]   And I see that in the creators,
[04:04:05.620 --> 04:04:09.580]   they become addicts to the algorithm.
[04:04:09.580 --> 04:04:10.900]   - Lost in chasing views.
[04:04:10.900 --> 04:04:12.140]   Like we know friends that,
[04:04:12.140 --> 04:04:13.820]   we know cool people and then they start streaming
[04:04:13.820 --> 04:04:16.900]   and eventually they're like chasing the dragon of like.
[04:04:16.900 --> 04:04:18.900]   - And they change, yeah.
[04:04:18.900 --> 04:04:19.740]   It's like hard to engage for them anymore.
[04:04:19.740 --> 04:04:20.580]   - They change who they are completely.
[04:04:20.580 --> 04:04:22.100]   And there's like, this is something I've always said
[04:04:22.100 --> 04:04:23.980]   that like one of the biggest blessings
[04:04:23.980 --> 04:04:25.340]   and biggest curses of humanity
[04:04:25.340 --> 04:04:27.060]   is we are very good at acclimating.
[04:04:27.060 --> 04:04:28.340]   Like you can become paralyzed,
[04:04:28.340 --> 04:04:29.740]   you can have all sorts of horrible things happen to you
[04:04:29.740 --> 04:04:31.100]   and you'll get used to it and you'll be okay.
[04:04:31.100 --> 04:04:32.500]   You're gonna have like a good baseline,
[04:04:32.500 --> 04:04:33.500]   but it works the other way too.
[04:04:33.500 --> 04:04:35.260]   And that you can get more and more and more and more
[04:04:35.260 --> 04:04:37.260]   and you acclimate to it almost immediately.
[04:04:37.260 --> 04:04:39.540]   There's like, this is a phenomenon that I bet it happens
[04:04:39.540 --> 04:04:40.380]   in the YouTube world,
[04:04:40.380 --> 04:04:41.260]   but I know what happens in the streaming world
[04:04:41.260 --> 04:04:44.100]   where you're streaming 1000 viewers every day,
[04:04:44.100 --> 04:04:45.820]   huge event happens and you blow up
[04:04:45.820 --> 04:04:48.420]   and you got like 15,000 viewers for a day or two.
[04:04:48.420 --> 04:04:50.140]   And then it starts to go down and down and down
[04:04:50.140 --> 04:04:50.980]   and down and down.
[04:04:50.980 --> 04:04:52.500]   And then after all the drama stayed off,
[04:04:52.500 --> 04:04:54.900]   you're at like 3000 concurrent viewers.
[04:04:54.900 --> 04:04:57.660]   Now in the macro, you went from 1000 to 3000.
[04:04:57.660 --> 04:04:58.740]   That feels awesome.
[04:04:58.740 --> 04:05:00.380]   But you actually feel like shit the whole time
[04:05:00.380 --> 04:05:02.220]   'cause you're remembering when you had 10 or 15,000
[04:05:02.220 --> 04:05:03.780]   and now everything feels horrible.
[04:05:03.780 --> 04:05:05.420]   And you'll see people climb over time.
[04:05:05.420 --> 04:05:06.420]   They're like, fuck, like, but whatever
[04:05:06.420 --> 04:05:07.340]   that one huge stream I had,
[04:05:07.340 --> 04:05:08.700]   like I've never been able to,
[04:05:08.700 --> 04:05:10.300]   and it's like, dude, you're doing great.
[04:05:10.300 --> 04:05:11.660]   Yeah, that happens a lot.
[04:05:11.660 --> 04:05:12.740]   - There's so many people that we know
[04:05:12.740 --> 04:05:14.300]   that we find super, super cool.
[04:05:14.300 --> 04:05:15.620]   They're passionate about things.
[04:05:15.620 --> 04:05:17.260]   They have so much interest
[04:05:17.260 --> 04:05:19.500]   and then they just get like so addicted to these numbers.
[04:05:19.500 --> 04:05:21.900]   And like all the, everything is just ruined.
[04:05:21.900 --> 04:05:23.420]   Like all the cool things about them is ruined
[04:05:23.420 --> 04:05:24.580]   because they stopped doing the things
[04:05:24.580 --> 04:05:27.260]   that they actually like to do something else
[04:05:27.260 --> 04:05:28.820]   that gives them more viewers and more money.
[04:05:28.820 --> 04:05:30.660]   And it's really sad to see.
[04:05:30.660 --> 04:05:35.020]   - Yeah, that temporary sacrifice that seems temporary
[04:05:35.020 --> 04:05:37.620]   is that it actually destroys you.
[04:05:37.620 --> 04:05:39.500]   Like for one time making a choice,
[04:05:39.500 --> 04:05:41.420]   'cause I come across those choices often.
[04:05:41.420 --> 04:05:42.580]   Like I can do this.
[04:05:42.580 --> 04:05:46.060]   You can kind of know what's gonna be popular and not.
[04:05:46.060 --> 04:05:47.740]   And you have to ask yourself that question.
[04:05:47.740 --> 04:05:49.860]   Like, is this gonna sacrifice?
[04:05:49.860 --> 04:05:51.460]   - 'Cause if people are sacrificing
[04:05:51.460 --> 04:05:53.340]   like intimate relationships,
[04:05:53.340 --> 04:05:55.220]   they're sacrificing time with their family.
[04:05:55.220 --> 04:05:57.460]   They're sacrificing time with the things
[04:05:57.460 --> 04:06:00.180]   that they feel good about and that they like.
[04:06:00.180 --> 04:06:03.180]   And that's something I kind of realized last year
[04:06:03.180 --> 04:06:04.460]   'cause I was working so much
[04:06:04.460 --> 04:06:05.980]   and I was just grinding, grinding, grinding
[04:06:05.980 --> 04:06:07.340]   because it was kind of new for me.
[04:06:07.340 --> 04:06:09.580]   And then new years came by and I was like,
[04:06:09.580 --> 04:06:11.980]   wait, what did I even do like the entire year?
[04:06:11.980 --> 04:06:13.820]   Like I traveled to a bunch of places,
[04:06:13.820 --> 04:06:15.580]   but nothing actually really meant anything to me
[04:06:15.580 --> 04:06:17.620]   because I felt like I was just working the entire time.
[04:06:17.620 --> 04:06:19.780]   I felt like I was just numb through the entire year.
[04:06:19.780 --> 04:06:20.940]   And I was really scary.
[04:06:23.100 --> 04:06:26.380]   I rented a super pretty house for a week
[04:06:26.380 --> 04:06:27.740]   with my dad and my sister
[04:06:27.740 --> 04:06:29.580]   'cause I wanted to spend time with them.
[04:06:29.580 --> 04:06:32.540]   But the entire time I was just streaming
[04:06:32.540 --> 04:06:34.780]   and I actually didn't ever like calm down
[04:06:34.780 --> 04:06:36.220]   and just like chill with them.
[04:06:36.220 --> 04:06:38.820]   And that's like time I'll never get back.
[04:06:38.820 --> 04:06:41.100]   I don't give a shit about the money that I made that week,
[04:06:41.100 --> 04:06:43.100]   but I lost the time.
[04:06:43.100 --> 04:06:45.460]   And like, that is really important to me.
[04:06:45.460 --> 04:06:47.860]   And yeah, and a lot of people are doing that.
[04:06:47.860 --> 04:06:49.220]   And I feel like, as you said,
[04:06:49.220 --> 04:06:51.860]   you can definitely see that in like artists for sure.
[04:06:51.860 --> 04:06:53.500]   I feel like if you look at like artists
[04:06:53.500 --> 04:06:55.500]   like back in the 60s or 70s,
[04:06:55.500 --> 04:06:57.740]   I feel like things were just so much better back then.
[04:06:57.740 --> 04:07:00.220]   And it feels like they were actually making music
[04:07:00.220 --> 04:07:01.700]   that meant something to them.
[04:07:01.700 --> 04:07:03.460]   They were actually making art.
[04:07:03.460 --> 04:07:05.740]   And I feel like today everything is just kind of like
[04:07:05.740 --> 04:07:07.340]   whatever is cool, whatever sells,
[04:07:07.340 --> 04:07:09.060]   whatever sounds in a certain way,
[04:07:09.060 --> 04:07:10.900]   everything is kind of the same thing.
[04:07:10.900 --> 04:07:13.460]   And everything that is very artistic and very cool
[04:07:13.460 --> 04:07:16.180]   is actually not that popular at all.
[04:07:16.180 --> 04:07:18.100]   And that's kind of sad, I think.
[04:07:18.100 --> 04:07:20.180]   - Yeah, of course there's now bigger mechanisms
[04:07:20.180 --> 04:07:23.820]   and platforms to spread stuff, music.
[04:07:23.820 --> 04:07:27.300]   So as long as you can be content with not being popular,
[04:07:27.300 --> 04:07:28.140]   I think you can still create art.
[04:07:28.140 --> 04:07:30.660]   - Yeah, but not like when people get a little popular,
[04:07:30.660 --> 04:07:32.140]   they get addicted to that so fast.
[04:07:32.140 --> 04:07:33.700]   - Yeah, it's weird.
[04:07:33.700 --> 04:07:35.820]   You have been somewhat good,
[04:07:35.820 --> 04:07:37.820]   at least from my outsider perspective,
[04:07:37.820 --> 04:07:41.060]   because I think you, I can at least imagine
[04:07:41.060 --> 04:07:43.620]   you making choices that could make you more popular
[04:07:43.620 --> 04:07:45.860]   and you don't seem to make those choices.
[04:07:45.860 --> 04:07:49.620]   - Like having an orbital problem.
[04:07:49.620 --> 04:07:51.580]   But it is very intentional, like you said.
[04:07:51.580 --> 04:07:54.420]   And I made that choice at every single stage of my life.
[04:07:54.420 --> 04:07:56.060]   One is because from the perspective
[04:07:56.060 --> 04:07:56.900]   of being a carpet cleaner,
[04:07:56.900 --> 04:07:59.980]   my life is way better than that was or ever would have been.
[04:07:59.980 --> 04:08:01.620]   So I'm already doing way better than I ever thought
[04:08:01.620 --> 04:08:03.360]   somebody like me ever could be.
[04:08:03.360 --> 04:08:06.400]   But then two, I super love my job.
[04:08:06.400 --> 04:08:07.300]   Every time I wake up,
[04:08:07.300 --> 04:08:08.940]   every time I fly to a place to do a podcast,
[04:08:08.940 --> 04:08:10.180]   every time I get to talk to really cool people,
[04:08:10.180 --> 04:08:12.060]   every single part about my job, I super like.
[04:08:12.060 --> 04:08:13.060]   If there's something I don't like,
[04:08:13.060 --> 04:08:14.260]   I just cut it off because I don't care.
[04:08:14.260 --> 04:08:16.060]   'Cause I'm already making plenty of money doing what I do.
[04:08:16.060 --> 04:08:18.260]   And why would I ever wake up and not like what I'm doing
[04:08:18.260 --> 04:08:19.540]   when I can like what I'm doing?
[04:08:19.540 --> 04:08:21.300]   - How do you guys find through that,
[04:08:21.300 --> 04:08:23.580]   given that you love it
[04:08:23.580 --> 04:08:26.020]   and you sometimes maybe lose yourself in the drug of it,
[04:08:26.020 --> 04:08:29.180]   how do you find like work-life balance together
[04:08:29.180 --> 04:08:30.940]   inside a relationship?
[04:08:30.940 --> 04:08:32.660]   Like time for each other?
[04:08:32.660 --> 04:08:34.940]   - I don't at all, so I'm not a good person to ask.
[04:08:34.940 --> 04:08:38.180]   - What do you love more, Mel or Factor?
[04:08:38.180 --> 04:08:39.060]   (laughing)
[04:08:39.060 --> 04:08:40.520]   - Factor is a really good game.
[04:08:40.520 --> 04:08:41.980]   That's like not a fair comparison, okay?
[04:08:41.980 --> 04:08:44.060]   You're talking about one of the best, cleanest games,
[04:08:44.060 --> 04:08:46.900]   best support ever made, cleanest code base.
[04:08:46.900 --> 04:08:48.820]   - I think I'm just saying all this for other reasons.
[04:08:48.820 --> 04:08:49.660]   - Yeah.
[04:08:49.660 --> 04:08:50.700]   - It's more Factor time for me.
[04:08:50.700 --> 04:08:52.020]   (laughing)
[04:08:52.020 --> 04:08:53.900]   - Starting to understand where the misogyny comes from.
[04:08:53.900 --> 04:08:57.220]   By the way, is Factor legit a really good game?
[04:08:57.220 --> 04:08:58.060]   - Yeah, of course, yeah.
[04:08:58.060 --> 04:08:58.900]   - Okay.
[04:08:58.900 --> 04:09:00.860]   - If you're like, do you enjoy programming?
[04:09:00.860 --> 04:09:01.820]   - Of course, that's all I do.
[04:09:01.820 --> 04:09:02.660]   That's all.
[04:09:02.660 --> 04:09:03.500]   - Okay.
[04:09:03.500 --> 04:09:06.180]   - To me, programming is the game in itself
[04:09:06.180 --> 04:09:08.340]   that I enjoy probably more than anything else, but yeah.
[04:09:08.340 --> 04:09:09.700]   - It's very much a game like that.
[04:09:09.700 --> 04:09:10.860]   If you're into stuff like that,
[04:09:10.860 --> 04:09:13.180]   like you can lose hundreds of hours very quickly
[04:09:13.180 --> 04:09:16.260]   to like you have a problem and then you think of a solution
[04:09:16.260 --> 04:09:18.180]   and then you iterate on that over and over and over again
[04:09:18.180 --> 04:09:19.260]   in larger, larger schemes.
[04:09:19.260 --> 04:09:20.420]   Sometimes you gotta redesign stuff.
[04:09:20.420 --> 04:09:22.140]   Sometimes you got like, it's a very much like that kind of game.
[04:09:22.140 --> 04:09:23.980]   - So you're essentially building a factory, like what,
[04:09:23.980 --> 04:09:26.140]   on a foreign planet or something like that?
[04:09:26.140 --> 04:09:27.140]   - Basically, it's like a bunch of,
[04:09:27.140 --> 04:09:28.820]   you're trying to automate different problems
[04:09:28.820 --> 04:09:30.260]   so that you can build bigger things,
[04:09:30.260 --> 04:09:31.660]   so that you can automate bigger problems,
[04:09:31.660 --> 04:09:32.500]   so you can build bigger things
[04:09:32.500 --> 04:09:33.340]   and automate bigger problems, yeah.
[04:09:33.340 --> 04:09:36.260]   - So it's more complicated than like a city building game,
[04:09:36.260 --> 04:09:38.300]   like some city type of thing?
[04:09:38.300 --> 04:09:39.620]   - I wouldn't say it's more complicated.
[04:09:39.620 --> 04:09:43.120]   It's more, like, Factor is like a game of like logic,
[04:09:43.120 --> 04:09:44.620]   like strictly like logic.
[04:09:44.620 --> 04:09:46.740]   - Oh, so you're almost like building a circuit or something.
[04:09:46.740 --> 04:09:48.380]   - Yes, yeah, there's like, there's circuitry
[04:09:48.380 --> 04:09:49.820]   and you've got your N-ORGs, ORG-ATs,
[04:09:49.820 --> 04:09:50.820]   like there's stuff like that.
[04:09:50.820 --> 04:09:51.660]   It's very much like that, like problems.
[04:09:51.660 --> 04:09:53.220]   - What are the enemies in the game?
[04:09:53.220 --> 04:09:54.060]   Like what, what's something attacking?
[04:09:54.060 --> 04:09:56.020]   - They're like bugs that try to bite you
[04:09:56.020 --> 04:09:57.860]   and you can get guns and shoot and kill them, but it's like-
[04:09:57.860 --> 04:09:59.540]   - 'Cause I saw there's like shooting going on.
[04:09:59.540 --> 04:10:00.500]   - Yeah, but that's like a minor,
[04:10:00.500 --> 04:10:01.500]   it's just like another problem to solve
[04:10:01.500 --> 04:10:02.460]   in the game, basically, yeah.
[04:10:02.460 --> 04:10:03.780]   - Okay, all right.
[04:10:03.780 --> 04:10:04.820]   So you see what we did there?
[04:10:04.820 --> 04:10:07.580]   We just started talking about the game as we're trying.
[04:10:07.580 --> 04:10:08.420]   Oh my God, that's like a-
[04:10:08.420 --> 04:10:09.740]   - That's a really good game, okay.
[04:10:09.740 --> 04:10:10.620]   - That's horrible.
[04:10:10.620 --> 04:10:13.500]   Anyway, is there, is that basically the struggle,
[04:10:13.500 --> 04:10:18.500]   not a struggle, how to get human, like intimate human time?
[04:10:18.500 --> 04:10:21.100]   - I feel like it was like that a little bit more
[04:10:21.100 --> 04:10:21.940]   in the past.
[04:10:21.940 --> 04:10:24.800]   I feel like it's been better lately,
[04:10:24.800 --> 04:10:27.580]   but I think it's because when we started dating,
[04:10:27.580 --> 04:10:30.420]   I wasn't streaming and I kind of just like gave up
[04:10:30.420 --> 04:10:32.220]   like my trip in New Zealand.
[04:10:32.220 --> 04:10:35.540]   I give up like, like I left Sweden.
[04:10:35.540 --> 04:10:38.860]   So I was just like in LA, which I hate, I hate LA.
[04:10:38.860 --> 04:10:40.580]   I don't like LA at all.
[04:10:40.580 --> 04:10:43.580]   It's hard to make friends that are like real,
[04:10:43.580 --> 04:10:45.460]   that are into the same stuff as you.
[04:10:45.460 --> 04:10:47.660]   It was just really hard for me to connect with anyone,
[04:10:47.660 --> 04:10:49.780]   especially also like being a European
[04:10:49.780 --> 04:10:52.180]   and like being around Americans was very strange.
[04:10:52.180 --> 04:10:56.140]   So the only thing I had when I came here was him.
[04:10:56.140 --> 04:10:58.380]   And I didn't expect-
[04:10:58.380 --> 04:10:59.220]   - Bad situation.
[04:10:59.220 --> 04:11:01.940]   - Because yeah, because we had like two weeks
[04:11:01.940 --> 04:11:03.640]   of hanging out and like he would be on his computer
[04:11:03.640 --> 04:11:05.280]   sometimes and like do emails and stuff,
[04:11:05.280 --> 04:11:07.220]   but I wasn't thinking that he would stream
[04:11:07.220 --> 04:11:08.060]   like 12 hours a day.
[04:11:08.060 --> 04:11:09.600]   And it was pretty, like it was pretty intense,
[04:11:09.600 --> 04:11:10.780]   like in the beginning of it as well.
[04:11:10.780 --> 04:11:13.740]   And I realized it was really hard to like get attention
[04:11:13.740 --> 04:11:18.020]   or get time because his like love meter would be like full
[04:11:18.020 --> 04:11:19.260]   if I was just in the house.
[04:11:19.260 --> 04:11:20.860]   And that's just kind of like the way he is.
[04:11:20.860 --> 04:11:23.860]   And for me back then when I didn't have anything else to do,
[04:11:23.860 --> 04:11:28.100]   was kind of like a, it was kind of crazy for me.
[04:11:28.100 --> 04:11:30.460]   I feel like right now, because I do work as well
[04:11:30.460 --> 04:11:32.900]   and I have things going for me
[04:11:32.900 --> 04:11:35.880]   and I have other friends now that I made,
[04:11:35.880 --> 04:11:37.280]   I feel like it's a lot easier.
[04:11:37.280 --> 04:11:39.120]   'Cause, and I can definitely like enjoy
[04:11:39.120 --> 04:11:40.680]   just like being in separate rooms
[04:11:40.680 --> 04:11:42.520]   and just like hearing him in the background is really nice.
[04:11:42.520 --> 04:11:45.320]   So I can sit and paint and like in my room
[04:11:45.320 --> 04:11:47.160]   and I will do that for hours while I'm just like hearing
[04:11:47.160 --> 04:11:48.000]   a scream in the background.
[04:11:48.000 --> 04:11:50.600]   It's kind of like comforting that he's just there.
[04:11:50.600 --> 04:11:51.420]   It feels nice.
[04:11:51.420 --> 04:11:52.260]   I like it.
[04:11:52.260 --> 04:11:53.800]   - 'Cause to you that's the sound of happiness.
[04:11:53.800 --> 04:11:55.240]   - Yes, because I know he's right there.
[04:11:55.240 --> 04:11:56.080]   Yeah, it's nice.
[04:11:56.080 --> 04:11:57.400]   And they'll come in and check on me sometimes.
[04:11:57.400 --> 04:11:59.360]   And it's kind of like, it's actually very comforting.
[04:11:59.360 --> 04:12:00.200]   It's very nice.
[04:12:00.200 --> 04:12:01.240]   I like it.
[04:12:01.240 --> 04:12:03.640]   - Yeah, I think that's kind of what a relationship is.
[04:12:03.640 --> 04:12:04.960]   Like you do fun things together
[04:12:04.960 --> 04:12:06.760]   and you share moments together,
[04:12:06.760 --> 04:12:08.880]   but also just like having someone like around you
[04:12:08.880 --> 04:12:10.400]   is really, really nice.
[04:12:10.400 --> 04:12:13.780]   And I think that's probably, maybe it's me growing up.
[04:12:13.780 --> 04:12:15.840]   Maybe that's what it is.
[04:12:15.840 --> 04:12:17.820]   And like, I start liking like the kind of,
[04:12:17.820 --> 04:12:19.240]   I feel like we're like an old couple,
[04:12:19.240 --> 04:12:21.400]   like we're like 80 and we're just like around.
[04:12:21.400 --> 04:12:22.840]   We don't really have to talk much.
[04:12:22.840 --> 04:12:23.680]   It's nice to just do that.
[04:12:23.680 --> 04:12:25.880]   - And that fills your love meter?
[04:12:25.880 --> 04:12:28.680]   I like this terminology, love meter.
[04:12:28.680 --> 04:12:29.520]   - I need both.
[04:12:29.880 --> 04:12:32.440]   - Okay, you're making it sound like
[04:12:32.440 --> 04:12:34.600]   that I'm like craving like crazy time.
[04:12:34.600 --> 04:12:35.440]   - I'm not saying anything.
[04:12:35.440 --> 04:12:36.280]   I haven't said a single thing at all.
[04:12:36.280 --> 04:12:37.360]   - You're making faces right now.
[04:12:37.360 --> 04:12:38.200]   I know exactly what you're thinking.
[04:12:38.200 --> 04:12:40.000]   - There's so much judging going on.
[04:12:40.000 --> 04:12:41.120]   - There's no judging at all.
[04:12:41.120 --> 04:12:44.640]   - No, but like, I think whenever we do plan something out,
[04:12:44.640 --> 04:12:47.040]   like if we go on a trip like every other month
[04:12:47.040 --> 04:12:51.120]   or once a month, I feel like usually like that's enough
[04:12:51.120 --> 04:12:54.040]   as long as he's not playing Factorio the entire time.
[04:12:54.040 --> 04:12:56.560]   Like if I feel like he's going on these trips for me
[04:12:56.560 --> 04:12:58.920]   and he's not like doing things for me
[04:12:58.920 --> 04:13:01.200]   or he's not interested in like spending time
[04:13:01.200 --> 04:13:02.680]   or like being present with me,
[04:13:02.680 --> 04:13:03.520]   then I'll feel like,
[04:13:03.520 --> 04:13:05.040]   I just feel like I'm just wasting time right now
[04:13:05.040 --> 04:13:06.640]   and then I get kind of disappointed.
[04:13:06.640 --> 04:13:08.920]   But otherwise I think this, like, this is fun.
[04:13:08.920 --> 04:13:10.760]   I think this is like spending time together
[04:13:10.760 --> 04:13:11.960]   'cause we're like doing something together.
[04:13:11.960 --> 04:13:14.120]   Yeah, it's fun, yeah.
[04:13:14.120 --> 04:13:15.880]   - My love meter is full.
[04:13:15.880 --> 04:13:17.400]   - Your love meter is full.
[04:13:17.400 --> 04:13:18.400]   - It's my social life.
[04:13:18.400 --> 04:13:19.240]   Otherwise it's fine.
[04:13:19.240 --> 04:13:20.680]   - We like to think about it that way,
[04:13:20.680 --> 04:13:22.400]   that like I need like a little bit more of like
[04:13:22.400 --> 04:13:24.280]   this one thing, like quality time.
[04:13:24.280 --> 04:13:27.000]   And he needs like almost zero quality time.
[04:13:27.000 --> 04:13:29.360]   But like, let's say that we took away like physical touch,
[04:13:29.360 --> 04:13:31.680]   you would probably not be very happy.
[04:13:31.680 --> 04:13:32.880]   - So you need physical touch.
[04:13:32.880 --> 04:13:34.160]   So it's not just Factorio, huh?
[04:13:34.160 --> 04:13:35.280]   - No, I'm a very cuddly person.
[04:13:35.280 --> 04:13:36.520]   - Yeah, like cuddly.
[04:13:36.520 --> 04:13:38.440]   And then you're like, I guess like acts of service.
[04:13:38.440 --> 04:13:40.280]   Like if I do something for you, you get really happy.
[04:13:40.280 --> 04:13:41.120]   - Like hot chocolate.
[04:13:41.120 --> 04:13:43.280]   - Yeah, like if I give him hot chocolate in the morning,
[04:13:43.280 --> 04:13:44.640]   he gets really happy, so.
[04:13:44.640 --> 04:13:46.720]   - The actual, it's not the hot chocolate,
[04:13:46.720 --> 04:13:48.080]   it's the giving of the hot chocolate.
[04:13:48.080 --> 04:13:49.720]   - No, it's just the hot chocolate.
[04:13:49.720 --> 04:13:50.640]   But if she gives it to me,
[04:13:50.640 --> 04:13:51.480]   I didn't have to get it myself.
[04:13:51.480 --> 04:13:52.480]   - It's just physical touch that you like.
[04:13:52.480 --> 04:13:54.320]   - That's really nice.
[04:13:54.320 --> 04:13:55.560]   - All right, well, if you have to choose
[04:13:55.560 --> 04:14:00.120]   between Factorio and the drama or political discourse.
[04:14:00.120 --> 04:14:02.400]   - Probably political discourse, probably my calling.
[04:14:02.400 --> 04:14:04.200]   But I am a good Factorio player.
[04:14:04.200 --> 04:14:07.840]   - But what role exactly does Factorio play
[04:14:07.840 --> 04:14:10.000]   in your streaming life?
[04:14:10.000 --> 04:14:11.120]   - Oh, well, right now it's just,
[04:14:11.120 --> 04:14:12.360]   usually there are like these games
[04:14:12.360 --> 04:14:14.040]   that I play in the background as I have conversations,
[04:14:14.040 --> 04:14:15.320]   'cause it's hard for me to just sit on the computer
[04:14:15.320 --> 04:14:17.560]   and just talk and not like be playing a game
[04:14:17.560 --> 04:14:18.400]   at the same time.
[04:14:18.400 --> 04:14:19.920]   So it's just something to keep me kind of like occupied.
[04:14:19.920 --> 04:14:20.760]   You know, I was gonna be able to buy
[04:14:20.760 --> 04:14:22.000]   like little like widget things, I guess.
[04:14:22.000 --> 04:14:22.840]   - Yeah, that's what yours is.
[04:14:22.840 --> 04:14:23.680]   - Yeah, basically, yeah.
[04:14:23.680 --> 04:14:26.000]   - So I'm just like Minecraft or Factorio for me.
[04:14:26.000 --> 04:14:30.400]   - All right, well, my love meter is full from this.
[04:14:30.400 --> 04:14:32.320]   Mel, thank you so much for joining us.
[04:14:32.320 --> 04:14:33.240]   - Thank you for having me.
[04:14:33.240 --> 04:14:34.440]   - This was really fun.
[04:14:34.440 --> 04:14:36.880]   You guys are fascinating human beings.
[04:14:36.880 --> 04:14:38.560]   Thank you for existing.
[04:14:38.560 --> 04:14:40.680]   I'm glad to live in a world where you exist.
[04:14:40.680 --> 04:14:44.160]   I can't wait to see what kind of beautiful thing
[04:14:44.160 --> 04:14:48.560]   you create next and the crazy kind of art that you create
[04:14:48.560 --> 04:14:50.640]   through the different people you interact with.
[04:14:50.640 --> 04:14:52.440]   Destiny, Steven, you're an amazing human.
[04:14:52.440 --> 04:14:53.680]   Thank you so much for talking to me.
[04:14:53.680 --> 04:14:54.520]   It's an honor.
[04:14:54.520 --> 04:14:55.840]   Hope to talk with you again.
[04:14:55.840 --> 04:14:57.000]   I'm talking to Ben Shapiro.
[04:14:57.000 --> 04:14:59.080]   You've given me a lot of inspiration.
[04:14:59.080 --> 04:15:01.760]   It's an honor to talk to the Ben Shapiro of the left.
[04:15:01.760 --> 04:15:03.040]   - Yeah, well, thanks a lot for having me.
[04:15:03.040 --> 04:15:03.880]   I appreciate it.
[04:15:03.880 --> 04:15:04.720]   - Thank you, guys. - It's been fun.
[04:15:04.720 --> 04:15:06.040]   - Thank you.
[04:15:06.040 --> 04:15:08.720]   - Thanks for listening to this conversation with Destiny.
[04:15:08.720 --> 04:15:09.880]   To support this podcast,
[04:15:09.880 --> 04:15:12.600]   please check out our sponsors in the description.
[04:15:12.600 --> 04:15:16.000]   And now let me leave you with some words from Lewis Carroll.
[04:15:16.000 --> 04:15:18.800]   "It's no use going back to yesterday
[04:15:18.800 --> 04:15:20.840]   "because I was a different person then."
[04:15:22.000 --> 04:15:25.400]   Thank you for listening and hope to see you next time.
[04:15:25.400 --> 04:15:28.000]   (upbeat music)
[04:15:28.000 --> 04:15:30.600]   (upbeat music)
[04:15:30.600 --> 04:15:36.100]   Thanks for watching.

