
[00:00:00.000 --> 00:00:02.120]   Just continuing with this.
[00:00:02.120 --> 00:00:03.320]   OK, great.
[00:00:03.320 --> 00:00:05.720]   Yeah.
[00:00:05.720 --> 00:00:07.400]   Any other new faces today?
[00:00:07.400 --> 00:00:11.960]   Ali, have you been here before?
[00:00:11.960 --> 00:00:13.400]   I don't remember seeing you.
[00:00:13.400 --> 00:00:14.280]   Maybe you've been quiet.
[00:00:14.280 --> 00:00:15.160]   I've been here.
[00:00:15.160 --> 00:00:17.560]   I don't think I've had the camera on.
[00:00:17.560 --> 00:00:19.400]   OK, yeah.
[00:00:19.400 --> 00:00:21.280]   Nice to meet you.
[00:00:21.280 --> 00:00:26.040]   And Nick is back from his tour of Tropical Islands.
[00:00:26.040 --> 00:00:26.680]   Hi, Nick.
[00:00:26.680 --> 00:00:28.720]   Yes, yep.
[00:00:28.720 --> 00:00:31.000]   Not so far away, though. Still pretty close.
[00:00:31.000 --> 00:00:31.600]   Yeah.
[00:00:31.600 --> 00:00:34.920]   Well, when you're at Queensland, Tropical Islands are easy.
[00:00:34.920 --> 00:00:37.120]   By default.
[00:00:37.120 --> 00:00:37.800]   Hi, Marie.
[00:00:37.800 --> 00:00:39.200]   Nice to see you.
[00:00:39.200 --> 00:00:42.320]   Where are you joining us from?
[00:00:42.320 --> 00:00:43.280]   Hello, can you hear me?
[00:00:43.280 --> 00:00:45.360]   Hi, absolutely.
[00:00:45.360 --> 00:00:47.720]   I'm Joni from South Bank of Brisbane.
[00:00:47.720 --> 00:00:48.680]   Uh-huh.
[00:00:48.680 --> 00:00:52.040]   Yeah, I'm at the Children's Health Queensland Hospital
[00:00:52.040 --> 00:00:52.760]   building.
[00:00:52.760 --> 00:00:53.760]   Ah, yes.
[00:00:53.760 --> 00:00:55.040]   OK, great.
[00:00:58.240 --> 00:01:00.920]   Anybody got anything they wanted to talk about or ask about
[00:01:00.920 --> 00:01:02.000]   before we dive in?
[00:01:02.000 --> 00:01:03.840]   Because I've got some good news, which
[00:01:03.840 --> 00:01:07.720]   is I've made things much easier in the horrible direction
[00:01:07.720 --> 00:01:08.600]   we went last time.
[00:01:08.600 --> 00:01:14.000]   All right, sounds like I should dive in then.
[00:01:14.000 --> 00:01:22.960]   I know there was, like, as I rather expected,
[00:01:22.960 --> 00:01:26.000]   and quite fair enough, some concern on the forum
[00:01:26.000 --> 00:01:31.880]   about how complicated and weird this all is, which is partly
[00:01:31.880 --> 00:01:34.040]   because we're kind of, like, jumping into stuff we'd normally
[00:01:34.040 --> 00:01:35.000]   do in part two.
[00:01:35.000 --> 00:01:41.160]   And so we haven't quite got all the necessary background here.
[00:01:41.160 --> 00:01:49.480]   And so, yeah, don't worry if you're feeling a little at sea.
[00:01:49.480 --> 00:01:51.040]   But it's a good way to, like, I don't know,
[00:01:51.040 --> 00:01:54.440]   start to see, like, some stuff you could look into
[00:01:54.440 --> 00:01:55.760]   after the course is finished.
[00:01:55.760 --> 00:02:02.760]   All right, so let me just--
[00:02:02.760 --> 00:02:03.400]   Jeremy.
[00:02:03.400 --> 00:02:03.760]   Yes.
[00:02:03.760 --> 00:02:05.720]   Sorry, just not mentioning part two.
[00:02:05.720 --> 00:02:09.480]   Are you planning a part two this year?
[00:02:09.480 --> 00:02:11.360]   Planning would be too strong a word.
[00:02:11.360 --> 00:02:14.000]   But as much as I ever plan anything--
[00:02:14.000 --> 00:02:15.120]   Thinking about?
[00:02:15.120 --> 00:02:18.120]   Yes, I would absolutely like to do a part two this year.
[00:02:18.120 --> 00:02:18.720]   Awesome.
[00:02:18.720 --> 00:02:20.600]   And the fact that you're asking that question
[00:02:20.600 --> 00:02:23.560]   means that you are not up to date on our Discord.
[00:02:23.560 --> 00:02:25.720]   So you should definitely join our Discord channel
[00:02:25.720 --> 00:02:27.200]   because we've actually been talking
[00:02:27.200 --> 00:02:32.240]   about doing a conference, or an unconference,
[00:02:32.240 --> 00:02:38.400]   to go with part two at the end of the year in Queensland.
[00:02:38.400 --> 00:02:43.000]   And a lot of folks from places that are not in Australia
[00:02:43.000 --> 00:02:48.080]   are saying they would be up for coming here for that.
[00:02:48.080 --> 00:02:52.280]   Partly a kind of a social thing, and also
[00:02:52.280 --> 00:02:56.080]   trying to do it all in a very COVID-safe way of outdoor,
[00:02:56.080 --> 00:03:02.080]   and masked, and people tested ahead of time, and stuff.
[00:03:02.080 --> 00:03:04.920]   Yeah, so that's--
[00:03:04.920 --> 00:03:06.520]   yeah, so nothing's planned.
[00:03:06.520 --> 00:03:09.200]   We don't have dates, or a syllabus, or anything
[00:03:09.200 --> 00:03:11.440]   like that, but we absolutely hope
[00:03:11.440 --> 00:03:19.920]   to have something awesome maybe towards the end of the year
[00:03:19.920 --> 00:03:23.320]   where we can get to know each other a bit better,
[00:03:23.320 --> 00:03:27.560]   and get to know fast AI and deep learning a bit better.
[00:03:27.560 --> 00:03:31.520]   Jeremy, can I ask you, are you going
[00:03:31.520 --> 00:03:34.440]   to continue this work for next week
[00:03:34.440 --> 00:03:36.320]   because I know that the class is going
[00:03:36.320 --> 00:03:38.280]   to be shown next Tuesday?
[00:03:38.280 --> 00:03:42.160]   Yeah, I think so.
[00:03:42.160 --> 00:03:45.640]   The fact that I'm doing it this week is interesting
[00:03:45.640 --> 00:03:51.920]   because, yeah, it has meant I've got less time to actually work
[00:03:51.920 --> 00:03:55.440]   on the course, but I also feel like the stuff we're doing,
[00:03:55.440 --> 00:03:57.840]   perhaps, is stuff I can use in the next lesson,
[00:03:57.840 --> 00:03:59.080]   depending on where we get to.
[00:03:59.080 --> 00:04:03.520]   So yeah, so I think we'll do it next week.
[00:04:03.520 --> 00:04:04.720]   We'll see how things go.
[00:04:04.720 --> 00:04:07.760]   If I get really behind, then maybe not.
[00:04:07.760 --> 00:04:11.560]   But then I certainly plan to continue doing them
[00:04:11.560 --> 00:04:16.560]   after the last class until--
[00:04:16.560 --> 00:04:17.240]   I don't know.
[00:04:17.240 --> 00:04:21.040]   We all know everything, I guess, and then we'll stop.
[00:04:21.040 --> 00:04:24.120]   At which point, there'll be more things to know, so yeah.
[00:04:24.120 --> 00:04:25.200]   OK.
[00:04:25.200 --> 00:04:27.160]   We don't have to stop, necessarily.
[00:04:27.160 --> 00:04:30.120]   There's just so much to learn.
[00:04:30.120 --> 00:04:32.120]   The only problem is that it's obviously
[00:04:32.120 --> 00:04:34.960]   a burden on your time, but it's--
[00:04:34.960 --> 00:04:35.920]   I enjoy it.
[00:04:35.920 --> 00:04:37.000]   I enjoy it.
[00:04:37.000 --> 00:04:39.120]   My issue is, what about when we get to the point
[00:04:39.120 --> 00:04:40.880]   where there's nothing left to learn, Radek?
[00:04:40.880 --> 00:04:42.680]   What do we do then?
[00:04:42.680 --> 00:04:45.800]   Well, is there such a point?
[00:04:45.800 --> 00:04:48.120]   Sure, there must--
[00:04:48.120 --> 00:04:50.520]   But then we just start doing it all in a different language.
[00:04:50.520 --> 00:04:52.560]   We start doing it all in R or Julia.
[00:04:52.560 --> 00:04:55.120]   Yeah, correct.
[00:04:55.120 --> 00:04:57.760]   C plus plus, that would keep us busy.
[00:04:57.760 --> 00:05:01.280]   I think this is my fifth year of doing fast AI courses,
[00:05:01.280 --> 00:05:06.000]   and I'm still trying to complete the part one.
[00:05:06.000 --> 00:05:08.640]   Are you too monostatic?
[00:05:08.640 --> 00:05:11.280]   That's true.
[00:05:11.280 --> 00:05:12.040]   All right.
[00:05:12.040 --> 00:05:12.720]   Let me see.
[00:05:12.720 --> 00:05:15.560]   So multitask.
[00:05:15.560 --> 00:05:21.400]   All right.
[00:05:21.400 --> 00:05:26.240]   I am just so happy about how this worked out, to be honest.
[00:05:26.240 --> 00:05:31.080]   Although, spoiler alert, it didn't turn out to help our score.
[00:05:31.080 --> 00:05:34.680]   The score was about the same.
[00:05:34.680 --> 00:05:38.920]   But I was so happy at how the whole process turned out.
[00:05:38.920 --> 00:05:42.760]   But I kind of want to show you how I got there, as well as
[00:05:42.760 --> 00:05:45.880]   where we ended up.
[00:05:45.880 --> 00:05:50.680]   And yeah, as soon as I kind of turned off Zoom last time,
[00:05:50.680 --> 00:05:53.520]   and I went for a walk, and then as soon as I did that,
[00:05:53.520 --> 00:05:56.200]   I was like, oh, no, of course I know how we should do this.
[00:05:56.200 --> 00:06:00.280]   And really, so there's quite a few--
[00:06:00.280 --> 00:06:02.160]   we can make this much, much simpler.
[00:06:02.160 --> 00:06:05.680]   So let me explain what we're going to try to do.
[00:06:05.680 --> 00:06:20.120]   We are going to try to predict two things, the disease
[00:06:20.120 --> 00:06:23.600]   and the variety for each image.
[00:06:23.600 --> 00:06:29.040]   And the first thing will be to create a pair of data loaders
[00:06:29.040 --> 00:06:29.920]   that look like this.
[00:06:29.920 --> 00:06:33.800]   For each image, they will have connected two things to them,
[00:06:33.800 --> 00:06:37.760]   the disease and the type of race.
[00:06:37.760 --> 00:06:39.320]   So this is going to be step one.
[00:06:39.320 --> 00:06:44.400]   So let me kind of show you how I got to that step.
[00:06:44.400 --> 00:06:48.120]   So the step one that I took was to, first of all,
[00:06:48.120 --> 00:06:53.400]   try to replicate what we've already had before.
[00:06:53.400 --> 00:06:56.320]   So patty's ball.
[00:06:56.320 --> 00:06:58.600]   But before, I used image data loaders,
[00:06:58.600 --> 00:07:03.640]   which is the highest level least flexible function.
[00:07:03.640 --> 00:07:05.800]   We can do all the data processing
[00:07:05.800 --> 00:07:08.080]   of a single line of code, but only
[00:07:08.080 --> 00:07:10.200]   if we want to do something really standard.
[00:07:10.200 --> 00:07:14.840]   And trying to predict two things is not standard enough for it.
[00:07:14.840 --> 00:07:18.040]   So we now need to go one layer down.
[00:07:18.040 --> 00:07:27.600]   And there's a lot of really good tutorials on docs.fast.ai.
[00:07:27.600 --> 00:07:30.120]   And because it's been ages since I've done any of this,
[00:07:30.120 --> 00:07:32.920]   I'd forgotten entirely how fast.ai worked,
[00:07:32.920 --> 00:07:36.080]   so I used them very heavily to remind myself
[00:07:36.080 --> 00:07:37.960]   of what's going on.
[00:07:37.960 --> 00:07:41.560]   But for example, there is a data block tutorial.
[00:07:41.560 --> 00:07:45.560]   This pat's tutorial is great.
[00:07:45.560 --> 00:07:47.960]   It goes through all the layers of different ways
[00:07:47.960 --> 00:07:53.760]   of doing things with fast.ai preprocessing.
[00:07:53.760 --> 00:07:56.440]   This Siamese tutorial is another really good one.
[00:07:56.440 --> 00:07:58.560]   So these are some of the things I looked at.
[00:07:58.560 --> 00:08:02.760]   And the other thing that I looked at was the actual API docs.
[00:08:02.760 --> 00:08:06.120]   So if I click here on data block,
[00:08:06.120 --> 00:08:09.360]   this is actually probably what I found the most useful
[00:08:09.360 --> 00:08:11.640]   in the end.
[00:08:11.640 --> 00:08:14.120]   There's lots of great examples in the documentation.
[00:08:14.120 --> 00:08:17.040]   So yeah, as I kind of like--
[00:08:17.040 --> 00:08:19.560]   you know how it is, you come back to something a couple
[00:08:19.560 --> 00:08:22.240]   of years after you built it, and you're now
[00:08:22.240 --> 00:08:24.200]   kind of the customer of your documentation.
[00:08:24.200 --> 00:08:27.000]   And so my experience as a customer of my documentation
[00:08:27.000 --> 00:08:28.800]   was I was really delighted by it.
[00:08:28.800 --> 00:08:33.280]   So I can definitely suggest checking all that out.
[00:08:33.280 --> 00:08:37.000]   So what you can do--
[00:08:37.000 --> 00:08:40.080]   before, we were using image data loaders.from folder.
[00:08:40.080 --> 00:08:42.080]   So if we just do the double question mark trick,
[00:08:42.080 --> 00:08:45.040]   we can see the source code for it.
[00:08:45.040 --> 00:08:47.560]   And it's the normal size of fast.ai things.
[00:08:47.560 --> 00:08:49.320]   It's very small.
[00:08:49.320 --> 00:08:51.840]   And you can see that actually all the work's
[00:08:51.840 --> 00:08:53.800]   being done by data block.
[00:08:53.800 --> 00:08:59.000]   So data block is the still high level API,
[00:08:59.000 --> 00:09:01.320]   but not as high level.
[00:09:01.320 --> 00:09:02.760]   It's actually very flexible.
[00:09:02.760 --> 00:09:04.240]   And so we're going to--
[00:09:04.240 --> 00:09:08.680]   step one that I did was to replicate exactly what we had
[00:09:08.680 --> 00:09:13.040]   before about using data blocks.
[00:09:13.040 --> 00:09:19.360]   And for this, there's actually so many good examples
[00:09:19.360 --> 00:09:21.120]   in the tutorials and in the book.
[00:09:21.120 --> 00:09:22.280]   You've seen them all before.
[00:09:22.280 --> 00:09:25.480]   We don't need to talk about it too much.
[00:09:25.480 --> 00:09:29.000]   We can basically say, OK, for the data block,
[00:09:29.000 --> 00:09:30.200]   the input will be an image.
[00:09:30.200 --> 00:09:32.640]   The output will be a category.
[00:09:32.640 --> 00:09:35.080]   This is just to do disease prediction.
[00:09:35.080 --> 00:09:48.200]   The labeling function will be the parent folder.
[00:09:50.920 --> 00:09:53.440]   Parent label.
[00:09:53.440 --> 00:09:55.360]   Do a random split.
[00:09:55.360 --> 00:09:57.200]   The item and batch transforms, we
[00:09:57.200 --> 00:10:00.480]   can copy and paste from what we had before.
[00:10:00.480 --> 00:10:06.760]   And that creates a data block.
[00:10:06.760 --> 00:10:11.000]   So data loaders is then a data block.data loaders.
[00:10:11.000 --> 00:10:15.160]   And you then have to pass in a source.
[00:10:15.160 --> 00:10:20.080]   So the source is basically anything
[00:10:20.080 --> 00:10:24.880]   that you can iterate through or index
[00:10:24.880 --> 00:10:30.080]   into to grab the things that will be passed to these blocks
[00:10:30.080 --> 00:10:30.960]   and to this function.
[00:10:30.960 --> 00:10:35.800]   So for this, it's going to be a path.
[00:10:35.800 --> 00:10:48.000]   And then we also need to get items.
[00:10:48.000 --> 00:10:50.400]   And so when we get a path, we're going
[00:10:50.400 --> 00:10:54.200]   to pass that path into the getImageFiles function,
[00:10:54.200 --> 00:10:55.800]   because that's the thing that returns
[00:10:55.800 --> 00:10:57.520]   a list of all of the images in a path.
[00:10:57.520 --> 00:11:03.920]   And let's see if that works.
[00:11:03.920 --> 00:11:09.680]   How do you know that--
[00:11:09.680 --> 00:11:14.200]   OK, so the block, you have an image block, category block.
[00:11:14.200 --> 00:11:21.400]   How do you know that the getImageFiles
[00:11:21.400 --> 00:11:26.680]   is going to be able to feed both those blocks?
[00:11:26.680 --> 00:11:32.000]   So I guess the short answer would
[00:11:32.000 --> 00:11:35.680]   be to read the documentation about those blocks
[00:11:35.680 --> 00:11:40.480]   to see what they take and what they do,
[00:11:40.480 --> 00:11:42.560]   or any of the tutorials that use them.
[00:11:42.560 --> 00:11:44.720]   As you can see, they're used all over the place, right?
[00:11:44.720 --> 00:11:48.360]   So you can start with this tutorial, or this tutorial,
[00:11:48.360 --> 00:11:49.040]   or this tutorial.
[00:11:49.040 --> 00:11:55.080]   So any of those would show you what it does.
[00:11:55.080 --> 00:12:03.280]   Yeah, the actual-- sorry, this is not good documentation.
[00:12:03.280 --> 00:12:05.240]   I really never bothered to look at this,
[00:12:05.240 --> 00:12:12.880]   because it's basically all it does, because we should fix
[00:12:12.880 --> 00:12:16.840]   that, I guess, because there's so many tutorials.
[00:12:16.840 --> 00:12:19.680]   I mean, as you can see, I guess the reason I never really
[00:12:19.680 --> 00:12:22.240]   wrote drops, right, is that it's literally a single line of code.
[00:12:22.240 --> 00:12:23.120]   So that's like--
[00:12:23.120 --> 00:12:30.040]   yeah, so maybe looking at the code
[00:12:30.040 --> 00:12:31.560]   is actually interesting in this case.
[00:12:31.560 --> 00:12:36.120]   So an image block is something which
[00:12:36.120 --> 00:12:42.440]   calls class.create, where class is P-I-L image.
[00:12:42.440 --> 00:12:44.920]   So it's going to call P-I-L image.create.
[00:12:44.920 --> 00:12:49.600]   So to find out what's actually going to be called by it,
[00:12:49.600 --> 00:12:59.520]   you can go P-I-L image.create, and you can see
[00:12:59.520 --> 00:13:01.640]   it's going to get passed a file name, which
[00:13:01.640 --> 00:13:05.280]   can be a path, or a string, or various other things.
[00:13:05.280 --> 00:13:09.680]   So get image files, then, obviously, you
[00:13:09.680 --> 00:13:11.880]   can either run it to see what it comes out with,
[00:13:11.880 --> 00:13:16.000]   or let's do that so we could just run get image files,
[00:13:16.000 --> 00:13:20.760]   passing in the thing it's going to be given, which is the path.
[00:13:20.760 --> 00:13:23.640]   And so as you can see, it's a bunch of paths.
[00:13:23.640 --> 00:13:28.080]   And so we could pass one of those--
[00:13:28.080 --> 00:13:31.240]   copy that, and it's going to be passed into this function.
[00:13:31.240 --> 00:13:35.800]   So we've now just replicated exactly
[00:13:35.800 --> 00:13:37.240]   what's happening in the code.
[00:13:37.240 --> 00:13:43.400]   Yeah, but for this, I generally just
[00:13:43.400 --> 00:13:47.240]   look at the tutorials, which tell you what to do.
[00:13:47.240 --> 00:13:50.200]   Could you have two different get items
[00:13:50.200 --> 00:13:52.720]   that feed different blocks?
[00:13:52.720 --> 00:13:54.680]   We're going to come to that.
[00:13:54.680 --> 00:13:57.720]   OK, so park that.
[00:13:57.720 --> 00:14:02.920]   So yeah, so--
[00:14:02.920 --> 00:14:05.160]   There was also a batch transform,
[00:14:05.160 --> 00:14:08.880]   like it gets transformed later after reading, right?
[00:14:08.880 --> 00:14:12.440]   Yeah, here we've got the batch transform, yeah.
[00:14:12.440 --> 00:14:15.920]   But in the image block, because right now, we
[00:14:15.920 --> 00:14:18.440]   have a build image, or something,
[00:14:18.440 --> 00:14:21.120]   and it needs to become a tensor, right?
[00:14:21.120 --> 00:14:22.200]   Yeah, that's right.
[00:14:22.200 --> 00:14:25.600]   It gets changed from an int tensor to a float tensor
[00:14:25.600 --> 00:14:26.520]   later on.
[00:14:26.520 --> 00:14:27.520]   That's right.
[00:14:27.520 --> 00:14:32.760]   Yeah, that's a fairly subtle thing, but that's right.
[00:14:32.760 --> 00:14:39.720]   We stick that in something.
[00:14:39.720 --> 00:14:47.480]   Image equals-- and we look at, like, np.array image.
[00:14:47.480 --> 00:14:51.480]   It's actually stored as bytes, or UN8, as they call it,
[00:14:51.480 --> 00:14:54.440]   in PyTorch.
[00:14:54.440 --> 00:15:00.200]   So yes, this is going to add a batch transform that's
[00:15:00.200 --> 00:15:02.320]   going to turn that into a float tensor, which
[00:15:02.320 --> 00:15:06.040]   we can see what that's going to look like.
[00:15:06.040 --> 00:15:10.760]   We could run it here, I expect, to float tensor.
[00:15:10.760 --> 00:15:17.840]   The transformation that we're applying
[00:15:17.840 --> 00:15:21.720]   is 224, which is like a square image, correct?
[00:15:21.720 --> 00:15:24.200]   A 224 by 224?
[00:15:24.200 --> 00:15:26.120]   This one here?
[00:15:26.120 --> 00:15:26.920]   Yes.
[00:15:26.920 --> 00:15:29.680]   Yeah, so this is doing data augmentation
[00:15:29.680 --> 00:15:31.360]   of lots of different kinds.
[00:15:31.360 --> 00:15:43.560]   So let's copy doc paste.
[00:15:43.560 --> 00:15:48.760]   And if we show--
[00:15:48.760 --> 00:15:50.800]   for data augmentation, looking at the docs
[00:15:50.800 --> 00:15:52.720]   is particularly important, because you
[00:15:52.720 --> 00:15:55.760]   can see examples of the augmentations it does.
[00:15:55.760 --> 00:15:57.680]   So it tells you a list of all the augmentations
[00:15:57.680 --> 00:15:58.760]   and how you can change them.
[00:15:58.760 --> 00:16:02.480]   And here's some examples of what they look like.
[00:16:02.480 --> 00:16:02.960]   And--
[00:16:02.960 --> 00:16:06.520]   These augmentations would happen after the integer float
[00:16:06.520 --> 00:16:08.800]   tensor, right?
[00:16:08.800 --> 00:16:10.040]   Yes, that's correct.
[00:16:10.040 --> 00:16:13.080]   And some data augmentations, they
[00:16:13.080 --> 00:16:15.600]   operate on the entire batch, and some operate
[00:16:15.600 --> 00:16:17.320]   with a single example.
[00:16:17.320 --> 00:16:18.240]   Yeah, that's right.
[00:16:18.240 --> 00:16:20.720]   So the ones in batch transforms operate on the whole batch,
[00:16:20.720 --> 00:16:22.520]   and the ones in item transforms operate
[00:16:22.520 --> 00:16:23.960]   on a single item.
[00:16:23.960 --> 00:16:27.880]   And so batch transforms operate--
[00:16:27.880 --> 00:16:31.160]   because they operate on a batch, before you get there,
[00:16:31.160 --> 00:16:33.000]   everything has to be the same shape.
[00:16:33.000 --> 00:16:34.800]   So it can be turned into a batch.
[00:16:34.800 --> 00:16:38.680]   So this resizes everything to the same shape.
[00:16:38.680 --> 00:16:42.480]   And then this does these various different types of data
[00:16:42.480 --> 00:16:44.160]   augmentation.
[00:16:44.160 --> 00:16:47.440]   And one of the key pieces of data augmentation it does
[00:16:47.440 --> 00:16:51.760]   is to randomly zoom into a subset of the image,
[00:16:51.760 --> 00:16:55.360]   as you can see in these various examples here.
[00:16:55.360 --> 00:17:03.840]   And this data block API, can you also
[00:17:03.840 --> 00:17:05.920]   use it with data frames, where you
[00:17:05.920 --> 00:17:08.320]   would be reading your images from a data frame?
[00:17:08.320 --> 00:17:08.960]   We are going to do that.
[00:17:08.960 --> 00:17:10.480]   We're going to do that in a moment, yes.
[00:17:10.480 --> 00:17:11.280]   OK, cool.
[00:17:11.280 --> 00:17:14.400]   Absolutely.
[00:17:14.400 --> 00:17:17.360]   So yeah, I'm kind of skipping over quite a bit of this,
[00:17:17.360 --> 00:17:22.040]   because it's super well covered in the tutorials.
[00:17:22.040 --> 00:17:24.680]   So I don't want to say stuff that you can very easily read.
[00:17:24.680 --> 00:17:26.040]   Whereas the stuff I'm about to show you
[00:17:26.040 --> 00:17:28.880]   isn't as well covered in the tutorials, and it's kind of new.
[00:17:28.880 --> 00:17:33.880]   But yeah, feel free to keep asking questions
[00:17:33.880 --> 00:17:36.360]   about anything you see.
[00:17:36.360 --> 00:17:39.840]   So basically, yeah, so all we've done
[00:17:39.840 --> 00:17:43.880]   is this is just the same thing that we have in lesson one.
[00:17:43.880 --> 00:17:51.760]   And it's doing exactly the same thing as my image data
[00:17:51.760 --> 00:17:54.240]   loaders.from folder, but just turn it into data block.
[00:17:54.240 --> 00:17:56.920]   And so this is what I did, just to show you
[00:17:56.920 --> 00:17:57.880]   through my process.
[00:17:57.880 --> 00:17:59.760]   But step one was to get this working,
[00:17:59.760 --> 00:18:05.200]   and then I passed that into a learner.
[00:18:05.200 --> 00:18:14.040]   And so let's go copy, and I want this all to run as fast as
[00:18:14.040 --> 00:18:15.520]   possible.
[00:18:15.520 --> 00:18:17.560]   So I would use the fastest--
[00:18:17.560 --> 00:18:27.520]   Do you-- when you make this data loader thing,
[00:18:27.520 --> 00:18:31.560]   do you try to make sure that the shape that it's outputting
[00:18:31.560 --> 00:18:34.720]   is what you need for your model, or that's later?
[00:18:34.720 --> 00:18:37.960]   Well, I generally use models which
[00:18:37.960 --> 00:18:41.720]   don't care what size they get.
[00:18:41.720 --> 00:18:44.840]   So yeah, that's one of my tricks.
[00:18:44.840 --> 00:18:48.640]   So ResNet18 is happy with any size.
[00:18:48.640 --> 00:18:50.160]   So actually, for my testing, I'm going
[00:18:50.160 --> 00:18:53.920]   to bring this back down to 128, so it's super fast.
[00:18:53.920 --> 00:19:00.720]   And so I just want to get the maximum iteration speed here.
[00:19:00.720 --> 00:19:07.400]   And so now, I can call learn.fit1cycle.
[00:19:07.400 --> 00:19:09.400]   And let's do one epoch.
[00:19:09.400 --> 00:19:21.120]   OK, so this is going to run in under 20 seconds, which
[00:19:21.120 --> 00:19:22.320]   is kind of what you want, right?
[00:19:22.320 --> 00:19:24.920]   You want something that you can test in under about 20 seconds,
[00:19:24.920 --> 00:19:27.200]   so that way, you can just quickly try things
[00:19:27.200 --> 00:19:29.760]   and make sure that end-to-end, it's working.
[00:19:29.760 --> 00:19:33.880]   Yep, the error rate is down to 30%.
[00:19:33.880 --> 00:19:38.600]   So that's a good sign.
[00:19:38.600 --> 00:19:40.920]   I guess one correlated question is, OK,
[00:19:40.920 --> 00:19:43.200]   I understand the input size, but what
[00:19:43.200 --> 00:19:45.680]   about the output size of your data block?
[00:19:45.680 --> 00:19:48.120]   You know that this is what you need for that model.
[00:19:48.120 --> 00:19:49.920]   Let's not say the model doesn't care.
[00:19:49.920 --> 00:19:52.360]   The model's happy with any size.
[00:19:52.360 --> 00:19:55.640]   I mean, the targets, or whatever.
[00:19:55.640 --> 00:19:57.120]   You're talking about the labels?
[00:19:57.120 --> 00:19:58.000]   Yeah, the labels.
[00:19:58.000 --> 00:19:59.800]   I mean, labels don't have sizes.
[00:19:59.800 --> 00:20:01.120]   The labels are strings.
[00:20:01.120 --> 00:20:02.680]   Or just the shape of that.
[00:20:02.680 --> 00:20:05.080]   Like, hey, is it--
[00:20:05.080 --> 00:20:07.600]   because maybe different models are kind of trying
[00:20:07.600 --> 00:20:10.600]   to predict different types of stuff, potentially?
[00:20:10.600 --> 00:20:13.360]   I don't know.
[00:20:13.360 --> 00:20:16.360]   Like, some might have the shape of the target.
[00:20:16.360 --> 00:20:18.760]   A vision learner is--
[00:20:18.760 --> 00:20:24.320]   I suspect the thing you're kind of asking
[00:20:24.320 --> 00:20:26.560]   is the thing that we're going to be covering in a moment.
[00:20:26.560 --> 00:20:28.640]   So maybe put that on hold, and then tell me
[00:20:28.640 --> 00:20:30.040]   if it doesn't make sense.
[00:20:30.040 --> 00:20:30.520]   OK.
[00:20:30.520 --> 00:20:32.760]   OK.
[00:20:32.760 --> 00:20:37.120]   Before-- I have a question.
[00:20:37.120 --> 00:20:44.560]   On the data block, you randomly select the amount of records
[00:20:44.560 --> 00:20:49.120]   or the amount of the batch size that you're going to process.
[00:20:49.120 --> 00:20:51.360]   I don't randomly pick the batch size, no.
[00:20:51.360 --> 00:20:55.160]   The batch size is actually selected in the .dataLetters
[00:20:55.160 --> 00:20:58.200]   call and it take off to 64.
[00:20:58.200 --> 00:20:59.400]   64.
[00:20:59.400 --> 00:21:02.760]   So what is the guarantee that every single one
[00:21:02.760 --> 00:21:05.000]   of the images in this particular case
[00:21:05.000 --> 00:21:09.400]   will be selected, or there's no way to know?
[00:21:09.400 --> 00:21:12.520]   Is there any way to know that every single one will be--
[00:21:12.520 --> 00:21:13.720]   Yes.
[00:21:13.720 --> 00:21:16.760]   I mean, well, yes, except that we're randomly
[00:21:16.760 --> 00:21:21.880]   selecting 20% to be a validation set.
[00:21:21.880 --> 00:21:26.200]   But every single one will go through the learner.
[00:21:26.200 --> 00:21:29.080]   Of the 80% that aren't in there, everyone
[00:21:29.080 --> 00:21:31.960]   will go through our learner because we randomly shuffle them
[00:21:31.960 --> 00:21:35.400]   and then we iterate through the whole lot.
[00:21:35.400 --> 00:21:38.760]   So in a single epoch, the model is
[00:21:38.760 --> 00:21:44.040]   guaranteed to see every example that is trained just once.
[00:21:44.040 --> 00:21:46.040]   Yeah.
[00:21:46.040 --> 00:21:47.480]   Yeah, and that's what this one means.
[00:21:47.480 --> 00:21:50.280]   That's what one epoch means, is look at everything once.
[00:21:50.280 --> 00:21:52.680]   And so if we put two there, it would look at everything twice.
[00:21:52.680 --> 00:21:54.360]   But each time it randomly shuffles it,
[00:21:54.360 --> 00:21:56.920]   so it does it in a different random order.
[00:21:56.920 --> 00:21:59.600]   I have a quick question.
[00:21:59.600 --> 00:22:03.080]   I guess this is PyTorch data loader stuff,
[00:22:03.080 --> 00:22:06.280]   but what actually happens for the last batch?
[00:22:06.280 --> 00:22:08.360]   The last batch, it depends.
[00:22:08.360 --> 00:22:10.840]   And this is actually not the PyTorch data loader,
[00:22:10.840 --> 00:22:12.680]   it's actually fast.ai's data loader.
[00:22:12.680 --> 00:22:16.120]   So we have our own data loader, although in the next version,
[00:22:16.120 --> 00:22:19.080]   we're likely to replace it with the fast.ai one.
[00:22:19.080 --> 00:22:20.760]   So it depends what drop last is.
[00:22:20.760 --> 00:22:24.920]   If drop last is true, then it deletes the last batch.
[00:22:24.920 --> 00:22:27.560]   And if it's false, then it includes the last batch.
[00:22:27.560 --> 00:22:30.040]   And the reason that's interesting is that the last batch may not
[00:22:30.040 --> 00:22:32.920]   be of size 64.
[00:22:32.920 --> 00:22:34.920]   Yeah.
[00:22:34.920 --> 00:22:39.080]   For the validation set, it always keeps the last batch.
[00:22:39.080 --> 00:22:42.040]   It's super important to shuffle the transfer.
[00:22:42.040 --> 00:22:44.560]   The fast.ai does it for you, but if you
[00:22:44.560 --> 00:22:47.520]   will mess around with the data loaders or do something
[00:22:47.520 --> 00:22:49.960]   yourself, if you don't shuffle the transfer,
[00:22:49.960 --> 00:22:53.560]   you might get very poor training performance.
[00:22:53.560 --> 00:22:55.160]   When we used to use Keras, I used
[00:22:55.160 --> 00:22:57.960]   to mess all this stuff up all the time.
[00:22:57.960 --> 00:22:59.560]   Yeah, trying to get all those details, right?
[00:22:59.560 --> 00:23:00.400]   It's really annoying.
[00:23:00.400 --> 00:23:02.080]   Just to make sure on something you said,
[00:23:02.080 --> 00:23:03.600]   you said in the next iteration, you're
[00:23:03.600 --> 00:23:05.760]   going to replace it with the PyTorch data loaders?
[00:23:05.760 --> 00:23:07.240]   Yeah, probably.
[00:23:07.240 --> 00:23:08.400]   OK.
[00:23:08.400 --> 00:23:10.440]   You said fast.ai, so I got confused.
[00:23:10.440 --> 00:23:11.680]   Oh, did I?
[00:23:11.680 --> 00:23:13.880]   That is confusing.
[00:23:13.880 --> 00:23:15.720]   Thanks.
[00:23:15.720 --> 00:23:17.360]   OK, so that was my step one.
[00:23:17.360 --> 00:23:20.120]   Is to just get it working exactly like before.
[00:23:20.120 --> 00:23:25.000]   And then I ran it in the background
[00:23:25.000 --> 00:23:27.320]   on the same architecture for the same epochs
[00:23:27.320 --> 00:23:29.760]   to make sure I got about the same error rate, and I did.
[00:23:29.760 --> 00:23:33.960]   So then I was happy that, OK, I'm matching what we had before.
[00:23:33.960 --> 00:23:38.440]   So then step two was to try to make it
[00:23:38.440 --> 00:23:41.440]   so that the data block spits out three things, which
[00:23:41.440 --> 00:23:44.480]   would be one image and two categories.
[00:23:44.480 --> 00:23:50.000]   The category of disease and the category of rice type.
[00:23:50.000 --> 00:23:53.160]   So to get it to spit out an image and two categories,
[00:23:53.160 --> 00:23:54.840]   hopefully you wouldn't be surprised to hear
[00:23:54.840 --> 00:23:57.920]   that we just do that.
[00:23:57.920 --> 00:24:01.000]   We say we want three blocks, an image, and two categories.
[00:24:01.000 --> 00:24:07.280]   Now, this variety, we did some way
[00:24:07.280 --> 00:24:13.160]   of getting that given an image ID.
[00:24:13.160 --> 00:24:16.680]   And actually, the way I did it was a bit ugly.
[00:24:16.680 --> 00:24:19.160]   And since then, I thought of a better way of doing it,
[00:24:19.160 --> 00:24:20.560]   which is what I think we should do
[00:24:20.560 --> 00:24:25.520]   is we should create a dict that maps from image ID to variety.
[00:24:25.520 --> 00:24:29.560]   And then our function will just be to look that up, right?
[00:24:29.560 --> 00:24:36.800]   So let's call this image to variety equals--
[00:24:36.800 --> 00:24:40.800]   OK, and it's going to be a dict comprehension.
[00:24:40.800 --> 00:25:00.400]   So we're going to loop through the rows in df dot iter items.
[00:25:00.400 --> 00:25:04.760]   Now, I always forget what these differences are.
[00:25:04.760 --> 00:25:08.360]   Column name comma series pair, returning a tuple
[00:25:08.360 --> 00:25:11.160]   with the column name.
[00:25:11.160 --> 00:25:13.000]   OK, that's not what I want.
[00:25:13.000 --> 00:25:14.560]   >> Yeah, like iter rows, yeah.
[00:25:14.560 --> 00:25:21.000]   >> Yeah, iter rows, index comma series.
[00:25:21.000 --> 00:25:22.520]   OK, cool.
[00:25:22.520 --> 00:25:28.480]   I think like this iter tuples is the fastest one.
[00:25:28.480 --> 00:25:32.720]   But this is not very big, so let's keep it simple.
[00:25:32.720 --> 00:25:35.320]   OK, so this is going to iterate over rows
[00:25:35.320 --> 00:25:39.360]   and return index comma series.
[00:25:39.360 --> 00:25:42.120]   OK, so we don't really care about the index.
[00:25:42.120 --> 00:25:50.840]   Another thing we could do is make the image ID the index,
[00:25:50.840 --> 00:25:54.400]   and then you could actually jump straight into it.
[00:25:54.400 --> 00:25:56.760]   But I think I'd rather not use pandas features.
[00:25:56.760 --> 00:25:59.160]   I'd rather use more pure Python-y things,
[00:25:59.160 --> 00:26:03.000]   because I think that'll make the explanation a little clearer.
[00:26:03.000 --> 00:26:04.200]   So we're going to loop through.
[00:26:04.200 --> 00:26:08.720]   It's going to give us the index and the row.
[00:26:08.720 --> 00:26:16.440]   And so what we want is the key will be the row's image ID,
[00:26:16.440 --> 00:26:20.080]   and the value will be the row's variety.
[00:26:20.080 --> 00:26:27.920]   OK, that looks good.
[00:26:27.920 --> 00:26:32.800]   So then there's a couple of ways we
[00:26:32.800 --> 00:26:36.000]   could turn this into a function.
[00:26:36.000 --> 00:26:39.240]   And I'm just going to show you a little neat trick, which
[00:26:39.240 --> 00:26:40.760]   is when you go like the--
[00:26:40.760 --> 00:26:42.000]   let's pick out something.
[00:26:42.000 --> 00:26:45.440]   Let's say we're going to grab this one.
[00:26:45.440 --> 00:26:51.080]   When you go like this, behind the scenes,
[00:26:51.080 --> 00:26:53.480]   that square bracket thing is actually
[00:26:53.480 --> 00:26:58.600]   calling a special magic method in Python called
[00:26:58.600 --> 00:27:03.600]   Dunder getItem, which is a function.
[00:27:03.600 --> 00:27:05.200]   This is the cool thing about Python.
[00:27:05.200 --> 00:27:09.160]   It's so dynamic and flexible, like all the syntax sugar
[00:27:09.160 --> 00:27:12.240]   is like behind the scenes just calling functions, basically.
[00:27:12.240 --> 00:27:15.200]   That's exactly the same thing.
[00:27:15.200 --> 00:27:18.880]   And so that means that this function here,
[00:27:18.880 --> 00:27:21.040]   imageToVariety.Dunder getItem, is
[00:27:21.040 --> 00:27:27.760]   a function that converts a file name into a variety.
[00:27:27.760 --> 00:27:29.320]   So here's the cool thing.
[00:27:29.320 --> 00:27:35.200]   Forget why you can pass it an array,
[00:27:35.200 --> 00:27:41.840]   and it's going to call each of those functions, which
[00:27:41.840 --> 00:27:42.880]   I think is rather nice.
[00:27:42.880 --> 00:27:52.360]   So another thing I find helpful--
[00:27:52.360 --> 00:27:53.560]   OK, cool.
[00:27:53.560 --> 00:27:56.680]   So when I call that, it complains.
[00:27:56.680 --> 00:27:59.440]   And it says, oh, getY contains two functions,
[00:27:59.440 --> 00:28:01.640]   but it should contain one, one for each target.
[00:28:01.640 --> 00:28:04.160]   It thinks that there's only one target.
[00:28:04.160 --> 00:28:05.320]   Why is that?
[00:28:05.320 --> 00:28:07.840]   Well, if you think about it, we've said there's three blocks,
[00:28:07.840 --> 00:28:10.200]   but we haven't told it how many of those blocks
[00:28:10.200 --> 00:28:12.040]   are for the independent variable and how many
[00:28:12.040 --> 00:28:14.000]   are for the dependent variable.
[00:28:14.000 --> 00:28:15.600]   And so we have to tell it.
[00:28:15.600 --> 00:28:19.200]   And the way we do that is to say the number of inputs equals--
[00:28:19.200 --> 00:28:20.840]   and so it's one.
[00:28:20.840 --> 00:28:25.120]   We have one input, and then the rest will be outputs.
[00:28:25.120 --> 00:28:31.120]   So when we do that, it's now happy, OK?
[00:28:31.120 --> 00:28:33.880]   And personally, before I jump to data loaders,
[00:28:33.880 --> 00:28:37.360]   I first create data sets just to make sure they work.
[00:28:37.360 --> 00:28:41.040]   So data sets are things where you just
[00:28:41.040 --> 00:28:42.160]   grab one thing at a time.
[00:28:42.160 --> 00:28:44.000]   There's no mini-batches to worry about.
[00:28:44.000 --> 00:28:47.080]   So data sets are easier to debug than data loaders.
[00:28:47.080 --> 00:28:49.440]   So you can create data sets using
[00:28:49.440 --> 00:28:54.600]   exactly the same approach, OK?
[00:28:54.600 --> 00:28:57.560]   And so-- all right, so we've got an error.
[00:28:57.560 --> 00:29:04.360]   OK, so here's the problem.
[00:29:04.360 --> 00:29:09.040]   It tried to look up our function.
[00:29:09.040 --> 00:29:12.640]   And in fact, it's not indexed.
[00:29:12.640 --> 00:29:17.440]   It's not passing in the string of the name.
[00:29:17.440 --> 00:29:21.160]   It's actually passing in the path.
[00:29:21.160 --> 00:29:22.920]   And so that's why we've got a key error.
[00:29:22.920 --> 00:29:27.640]   This path does not exist as a key in this dictionary,
[00:29:27.640 --> 00:29:29.240]   which is quite true, right?
[00:29:29.240 --> 00:29:30.480]   It doesn't.
[00:29:30.480 --> 00:29:36.360]   So what I think we should do is fix this up
[00:29:36.360 --> 00:29:40.520]   so that we've got train images, bacterial leaf streak,
[00:29:40.520 --> 00:29:42.640]   blah, blah, blah, OK.
[00:29:42.640 --> 00:29:46.200]   The get files function, the output of that
[00:29:46.200 --> 00:29:51.040]   is being passed to the get items is being passed to get y.
[00:29:51.040 --> 00:29:54.000]   So get image files.
[00:29:54.000 --> 00:29:56.560]   Yeah, so we haven't kind of gone into the details of exactly
[00:29:56.560 --> 00:29:59.240]   what's going on behind the scenes, Hamill.
[00:29:59.240 --> 00:30:02.040]   Let's do that in a moment.
[00:30:02.040 --> 00:30:04.200]   I kind of like the way you're wanting
[00:30:04.200 --> 00:30:08.360]   to jump into the nitty gritty, but it's a little bit--
[00:30:08.360 --> 00:30:09.200]   It's a problem that I have.
[00:30:09.200 --> 00:30:11.000]   I'm trying to do more top down, right?
[00:30:11.000 --> 00:30:13.120]   So I've got to get to your bottom up.
[00:30:13.120 --> 00:30:15.280]   We'll meet in the middle, OK?
[00:30:15.280 --> 00:30:16.640]   OK, fair enough, fair enough.
[00:30:16.640 --> 00:30:18.080]   By the way, your video is not on.
[00:30:18.080 --> 00:30:18.800]   That's fine.
[00:30:18.800 --> 00:30:20.000]   I just don't know if it's intentional.
[00:30:20.000 --> 00:30:23.640]   I always like to see people when they're, you know, seeable.
[00:30:23.640 --> 00:30:25.520]   Hello.
[00:30:25.520 --> 00:30:29.320]   OK, so we're not going to use this trick after all.
[00:30:29.320 --> 00:30:36.920]   We're going to create a function called get variety.
[00:30:36.920 --> 00:30:37.760]   Actually, no.
[00:30:37.760 --> 00:30:41.160]   Yeah, let's create a function called get variety.
[00:30:41.160 --> 00:30:47.560]   And so it's going to get past a path, OK?
[00:30:47.560 --> 00:30:55.160]   And so we're going to return image to variety.
[00:30:55.160 --> 00:30:59.400]   And we're going to return image to variety
[00:30:59.400 --> 00:31:03.840]   with the name of the file.
[00:31:03.840 --> 00:31:08.600]   So the name of the file is the string.
[00:31:08.600 --> 00:31:12.880]   Wait, we need image to variety, the dunder thing?
[00:31:12.880 --> 00:31:15.800]   Oh, yeah, I'll just grab a bracket, actually, yes.
[00:31:15.800 --> 00:31:16.600]   OK.
[00:31:16.600 --> 00:31:22.520]   Oh, and then we need to use that.
[00:31:22.520 --> 00:31:43.640]   OK, so DSS contains a dot train data set.
[00:31:43.640 --> 00:31:48.400]   OK, and it also contains a dot valid data set.
[00:31:48.400 --> 00:31:54.360]   OK, and so we can look at the zeroth thing in the training
[00:31:54.360 --> 00:31:56.720]   data set, which is a single thing, right?
[00:31:56.720 --> 00:31:58.240]   So we can have a look now.
[00:31:58.240 --> 00:32:02.160]   There's image and Y1 and Y2.
[00:32:02.160 --> 00:32:09.000]   And so then we can look at the image, for example.
[00:32:09.000 --> 00:32:13.240]   OK, so what's happened here is that get image files returned
[00:32:13.240 --> 00:32:15.400]   to a list of paths.
[00:32:15.400 --> 00:32:19.680]   The first one got passed to image block, which,
[00:32:19.680 --> 00:32:23.320]   as we saw earlier, got passed to pyo image dot create.
[00:32:23.320 --> 00:32:26.720]   And here it is.
[00:32:26.720 --> 00:32:30.800]   And that path name also got passed to a function
[00:32:30.800 --> 00:32:31.880]   called parent label.
[00:32:31.880 --> 00:32:33.480]   In fact, let's do it, right?
[00:32:33.480 --> 00:32:39.680]   So let's say file name equals get image files.
[00:32:39.680 --> 00:32:43.400]   And then the thing that we passed in, training path,
[00:32:43.400 --> 00:32:45.600]   and let's just get the zeroth one.
[00:32:45.600 --> 00:32:50.040]   OK, and so there it is, right?
[00:32:50.040 --> 00:33:00.040]   So it ended up calling pyo image dot create with that file name.
[00:33:00.040 --> 00:33:05.080]   OK, it also called parent label with that file name.
[00:33:05.080 --> 00:33:10.080]   Parent label, OK.
[00:33:10.080 --> 00:33:12.760]   And it also called get variety with that file name.
[00:33:12.760 --> 00:33:18.960]   Jeremy, can we look at get variety one more time?
[00:33:18.960 --> 00:33:22.960]   I'm just curious how you build the path.
[00:33:22.960 --> 00:33:23.640]   I didn't.
[00:33:23.640 --> 00:33:24.680]   I removed the path.
[00:33:24.680 --> 00:33:25.600]   I called dot no.
[00:33:25.600 --> 00:33:28.720]   OK, OK.
[00:33:28.720 --> 00:33:29.920]   I see.
[00:33:29.920 --> 00:33:32.240]   Yeah, in my original version of this,
[00:33:32.240 --> 00:33:35.280]   I did it the other way around, of building back up the path,
[00:33:35.280 --> 00:33:38.280]   and then realized that that was kind of stupid.
[00:33:38.280 --> 00:33:42.320]   Yeah, it's unique, so that works.
[00:33:42.320 --> 00:33:44.200]   One question.
[00:33:44.200 --> 00:33:51.720]   OK, this could be too low level, but just let me know.
[00:33:51.720 --> 00:33:54.240]   Can you have multiple get items?
[00:33:54.240 --> 00:33:55.640]   Is this the right place to ask that?
[00:33:55.640 --> 00:33:59.720]   So it wouldn't make sense to have multiple get items, right?
[00:33:59.720 --> 00:34:02.960]   Like, get item returns a single thing,
[00:34:02.960 --> 00:34:04.360]   but it could be anything you like, right?
[00:34:04.360 --> 00:34:07.200]   It could be it could return a tuple, or a list, or an object,
[00:34:07.200 --> 00:34:09.200]   or whatever, right?
[00:34:09.200 --> 00:34:11.040]   And so, or dict.
[00:34:11.040 --> 00:34:14.920]   And then get y and get x, then the thing's
[00:34:14.920 --> 00:34:16.960]   responsible for pulling out the bit that you
[00:34:16.960 --> 00:34:19.400]   need to pass to your blocks.
[00:34:19.400 --> 00:34:23.960]   Now, we don't need to get x, because image blocks just
[00:34:23.960 --> 00:34:26.520]   take paths directly.
[00:34:26.520 --> 00:34:31.040]   If I needed something a bit more like I wanted to put more things
[00:34:31.040 --> 00:34:33.680]   and get image files, like have it emit a tuple,
[00:34:33.680 --> 00:34:36.840]   then would I have to make my own image block to ignore?
[00:34:36.840 --> 00:34:38.000]   No, not your own image block.
[00:34:38.000 --> 00:34:40.000]   You would write your own function,
[00:34:40.000 --> 00:34:43.280]   just like get image files, that returns
[00:34:43.280 --> 00:34:45.800]   the list of all of the objects you want,
[00:34:45.800 --> 00:34:48.520]   which have all the information you need.
[00:34:48.520 --> 00:34:50.160]   OK, and then--
[00:34:50.160 --> 00:34:51.320]   It almost never happens.
[00:34:51.320 --> 00:34:53.000]   I don't think that's ever happened to me,
[00:34:53.000 --> 00:34:56.400]   because nearly always there's a row of a database
[00:34:56.400 --> 00:35:01.240]   table, or a path, or something has all the information
[00:35:01.240 --> 00:35:05.480]   you need to go out and get the stuff with your get x's
[00:35:05.480 --> 00:35:07.920]   and get y's.
[00:35:07.920 --> 00:35:11.280]   That's like the central piece of information for each row.
[00:35:11.280 --> 00:35:14.000]   And based on this information, you can read in text,
[00:35:14.000 --> 00:35:18.640]   you can read in images, but specific to that one row.
[00:35:18.640 --> 00:35:21.360]   Actually, let me show you my hacky version,
[00:35:21.360 --> 00:35:24.400]   because this is the version that uses a data frame.
[00:35:24.400 --> 00:35:27.480]   So this is-- so the version that uses data frame--
[00:35:27.480 --> 00:35:35.760]   let's see.
[00:35:35.760 --> 00:35:39.880]   Is it right to think, get x's?
[00:35:39.880 --> 00:35:41.520]   Yeah, and that's interesting.
[00:35:41.520 --> 00:35:43.680]   Let me just do this, and let me come to your question.
[00:35:43.680 --> 00:35:52.160]   OK, so in this data block, I started out with a data frame,
[00:35:52.160 --> 00:35:53.680]   like so, right?
[00:35:53.680 --> 00:35:57.720]   And so by passing into data block.dataload,
[00:35:57.720 --> 00:36:03.360]   as I passed in the data frame, it's going to get each row.
[00:36:03.360 --> 00:36:08.920]   And so then get y becomes colreader 1,
[00:36:08.920 --> 00:36:11.320]   which is just a function which--
[00:36:11.320 --> 00:36:14.680]   I mean, let's look at it.
[00:36:14.680 --> 00:36:15.760]   That doesn't do much.
[00:36:15.760 --> 00:36:21.560]   Let's see what it does.
[00:36:21.560 --> 00:36:24.280]   So it's done as an object, because you
[00:36:24.280 --> 00:36:27.680]   can do things like add in a prefix path and a suffix path,
[00:36:27.680 --> 00:36:30.240]   and you can split it with a label delimiter and whatever.
[00:36:30.240 --> 00:36:36.000]   But basically, all it's basically doing, OK,
[00:36:36.000 --> 00:36:38.680]   and it checks what kind of thing you're passing in.
[00:36:38.680 --> 00:36:49.760]   Basically, all it does is it calls getAtra to grab
[00:36:49.760 --> 00:36:54.480]   the column and we--
[00:36:54.480 --> 00:37:01.880]   colreader for context, like reading data frames.
[00:37:01.880 --> 00:37:03.120]   Sorry?
[00:37:03.120 --> 00:37:08.000]   Is this colreader function specifically for data frames?
[00:37:08.000 --> 00:37:11.120]   I mean, it can work with anything, basically,
[00:37:11.120 --> 00:37:15.920]   that you're-- so what it's doing here is it's saying,
[00:37:15.920 --> 00:37:19.680]   grab that column.
[00:37:19.680 --> 00:37:20.760]   But it's really--
[00:37:20.760 --> 00:37:22.560]   I've only really used it for data frames,
[00:37:22.560 --> 00:37:24.600]   but you could use it for anything.
[00:37:24.600 --> 00:37:27.280]   But yeah, so basically here, getY is saying, OK, well,
[00:37:27.280 --> 00:37:31.120]   let's return the index 1 field and the index 2 field.
[00:37:31.120 --> 00:37:40.680]   What's up with getX?
[00:37:40.680 --> 00:37:42.680]   So because now we're being passed--
[00:37:42.680 --> 00:37:48.840]   so you can't pass a row of a database table to pailimage.create.
[00:37:48.840 --> 00:37:55.360]   So getX is this function, which basically is going,
[00:37:55.360 --> 00:37:59.400]   oh, it's going to be in the training path slash disease
[00:37:59.400 --> 00:38:04.120]   name slash image name.
[00:38:04.120 --> 00:38:09.240]   So that's-- and then there's a special case for the test set,
[00:38:09.240 --> 00:38:13.400]   because the test set things are not stored in subfolders
[00:38:13.400 --> 00:38:15.640]   according to label, because we don't know the label.
[00:38:15.640 --> 00:38:18.440]   So it's just directly in the test path.
[00:38:18.440 --> 00:38:21.760]   So that's the-- as I said, this was more hacky.
[00:38:21.760 --> 00:38:22.360]   I don't--
[00:38:22.360 --> 00:38:23.840]   [INTERPOSING VOICES]
[00:38:23.840 --> 00:38:25.080]   This really helps.
[00:38:25.080 --> 00:38:27.120]   So getX is kind of like getY.
[00:38:27.120 --> 00:38:28.760]   You can have a list in there.
[00:38:28.760 --> 00:38:30.120]   It's like from--
[00:38:30.120 --> 00:38:32.240]   Yeah, you can have-- yeah, it's totally flexible.
[00:38:32.240 --> 00:38:37.200]   And I mean, seriously, Hamel, we have so many examples
[00:38:37.200 --> 00:38:42.920]   of all of these patterns in the docs in the tutorials.
[00:38:42.920 --> 00:38:45.000]   So like this exact pattern--
[00:38:45.000 --> 00:38:48.600]   let's take a look at one, right, docs.faster.ai.
[00:38:48.600 --> 00:38:58.160]   So tutorials-- let's do data block tutorial.
[00:38:58.160 --> 00:39:00.240]   Right here, look, multi-label.
[00:39:00.240 --> 00:39:03.120]   So here's one.
[00:39:03.120 --> 00:39:05.840]   And yeah, you can see here, this is even
[00:39:05.840 --> 00:39:08.680]   splitting based on columns in the database table.
[00:39:08.680 --> 00:39:11.480]   And here's the co-reader using prefix.
[00:39:11.480 --> 00:39:14.240]   And here's a co-reader using a label delimiter.
[00:39:14.240 --> 00:39:16.040]   And here's the examples coming out.
[00:39:16.040 --> 00:39:18.000]   Yeah, so there's--
[00:39:18.000 --> 00:39:22.320]   yeah, lots of examples you can check out
[00:39:22.320 --> 00:39:23.560]   to see how to do all this.
[00:39:23.560 --> 00:39:28.840]   Yeah, so I think I'm at a point now where I actually
[00:39:28.840 --> 00:39:30.440]   do want to go into the weeds.
[00:39:30.440 --> 00:39:32.240]   So Hamel, you're now, after this,
[00:39:32.240 --> 00:39:37.120]   totally free to ask any super-weedy questions.
[00:39:37.120 --> 00:39:40.320]   The most basic kind of data block
[00:39:40.320 --> 00:39:41.840]   is called the transform block.
[00:39:41.840 --> 00:39:54.600]   And the transform block, basically,
[00:39:54.600 --> 00:39:56.880]   it's going to store a bunch of things you pass in.
[00:39:56.880 --> 00:39:58.920]   It's going to store things called type transforms.
[00:39:58.920 --> 00:40:00.800]   It's going to store things called item transforms.
[00:40:00.800 --> 00:40:04.320]   It's going to store things called batch transforms.
[00:40:04.320 --> 00:40:06.680]   And also, it always adds one thing,
[00:40:06.680 --> 00:40:10.480]   which is to tensor, because PyTorch means tensors.
[00:40:10.480 --> 00:40:15.280]   If you look at the image block, we
[00:40:15.280 --> 00:40:19.200]   saw that that's defined as a transform block where
[00:40:19.200 --> 00:40:23.800]   the type transforms is this and the batch transforms is this.
[00:40:23.800 --> 00:40:25.360]   So now's a good time to talk about how
[00:40:25.360 --> 00:40:27.720]   this all works, what this does.
[00:40:27.720 --> 00:40:33.720]   So if I pass in here transform block
[00:40:33.720 --> 00:40:37.600]   and don't pass any transforms, it won't do anything.
[00:40:37.600 --> 00:40:50.800]   So let's get rid of pretty much everything.
[00:40:56.320 --> 00:41:00.680]   Let's do that separate cell so it gets a little bit easier
[00:41:00.680 --> 00:41:01.160]   to read.
[00:41:01.160 --> 00:41:08.480]   OK.
[00:41:08.480 --> 00:41:12.680]   Here is the world's simplest data block.
[00:41:12.680 --> 00:41:14.040]   OK.
[00:41:14.040 --> 00:41:26.160]   So if we call that, as you can see,
[00:41:26.160 --> 00:41:31.960]   all it does is it takes the output of get image file 0
[00:41:31.960 --> 00:41:35.440]   and turns it into a tuple containing one thing, which
[00:41:35.440 --> 00:41:37.920]   is the thing itself.
[00:41:37.920 --> 00:41:43.360]   If we have two transform blocks, it
[00:41:43.360 --> 00:41:46.880]   returns a tuple with two things in it.
[00:41:46.880 --> 00:41:49.200]   So and the reason it's returning tuples
[00:41:49.200 --> 00:41:51.480]   is because this is what we want.
[00:41:51.480 --> 00:41:59.480]   When we train, we have batches containing inputs and outputs,
[00:41:59.480 --> 00:42:02.200]   potentially multiple inputs and potentially multiple outputs.
[00:42:02.200 --> 00:42:08.520]   So that's why indexing into this gives you back a tuple.
[00:42:08.520 --> 00:42:14.160]   My question, the blocks can either be a list or a tuple?
[00:42:14.160 --> 00:42:16.120]   I don't know, probably.
[00:42:16.120 --> 00:42:17.440]   Yes.
[00:42:17.440 --> 00:42:19.440]   OK.
[00:42:19.440 --> 00:42:21.840]   I have no idea.
[00:42:21.840 --> 00:42:25.840]   OK.
[00:42:25.840 --> 00:42:26.340]   OK.
[00:42:26.340 --> 00:42:41.160]   So then we can do stuff to the first thing in the tuple.
[00:42:44.160 --> 00:42:56.560]   So get x equals-- say let's get a lambda o dot name.
[00:42:56.560 --> 00:43:09.540]   Hello.
[00:43:09.540 --> 00:43:16.980]   Hey, what are you doing?
[00:43:16.980 --> 00:43:17.480]   Oh.
[00:43:17.480 --> 00:43:26.060]   Something to do with lambda, right?
[00:43:26.060 --> 00:43:27.780]   Does name have to be call?
[00:43:27.780 --> 00:43:28.280]   No.
[00:43:37.220 --> 00:43:39.380]   Maybe it's notebook restart time.
[00:43:39.380 --> 00:43:42.820]   It's my notebook restart time.
[00:43:42.820 --> 00:43:48.260]   Oh, that's-- oh.
[00:43:48.260 --> 00:43:53.780]   I wonder if something happened to my GPU server.
[00:43:53.780 --> 00:43:59.220]   I mean, something has happened to my GPU server, clearly.
[00:43:59.220 --> 00:44:00.100]   Never happened before.
[00:44:05.500 --> 00:44:07.700]   Oh, it looks like it's back.
[00:44:07.700 --> 00:44:09.060]   Oh, OK.
[00:44:09.060 --> 00:44:10.980]   It just recognized that it disappeared.
[00:44:10.980 --> 00:44:19.380]   That's wild.
[00:44:19.380 --> 00:44:20.380]   Oh, OK.
[00:44:20.380 --> 00:44:28.700]   I'm very-- oh, I don't know what just happened.
[00:44:28.700 --> 00:44:41.300]   I guess it doesn't really matter.
[00:44:41.300 --> 00:44:42.900]   What are you doing right now?
[00:44:42.900 --> 00:44:45.380]   I'm just looking at the log, see if anything just happened.
[00:44:50.620 --> 00:44:58.980]   Who knows?
[00:44:58.980 --> 00:44:59.480]   OK.
[00:44:59.480 --> 00:45:02.220]   All right.
[00:45:02.220 --> 00:45:09.140]   OK.
[00:45:09.140 --> 00:45:18.500]   So you see what happened here is we got the first thing
[00:45:18.500 --> 00:45:26.540]   from image files, which was this, and get x got its name.
[00:45:26.540 --> 00:45:36.780]   So we could also do get y equals lambda o o dot parent, say.
[00:45:36.780 --> 00:45:40.500]   OK.
[00:45:40.500 --> 00:45:42.500]   So--
[00:45:42.500 --> 00:45:51.460]   It first went-- first, the thing went to the transform block,
[00:45:51.460 --> 00:45:52.300]   get items.
[00:45:52.300 --> 00:45:52.820]   Yes.
[00:45:52.820 --> 00:45:56.660]   So whatever get items got went to transform blocks.
[00:45:56.660 --> 00:46:00.060]   And then it went to get x and get y.
[00:46:00.060 --> 00:46:04.020]   Well, transform block doesn't do anything, right, at all,
[00:46:04.020 --> 00:46:05.980]   unless you pass the transforms.
[00:46:05.980 --> 00:46:07.140]   So yeah.
[00:46:07.140 --> 00:46:11.500]   So it's basically-- but the number of them you have
[00:46:11.500 --> 00:46:15.420]   is the number of pipelines it's going to create.
[00:46:15.420 --> 00:46:18.660]   So if we created another one--
[00:46:18.660 --> 00:46:21.020]   But generally, if you have an image block,
[00:46:21.020 --> 00:46:22.220]   it would do something.
[00:46:22.220 --> 00:46:23.580]   So the order is--
[00:46:23.580 --> 00:46:24.860]   We're going to get to that, yeah.
[00:46:24.860 --> 00:46:26.700]   So here, look, we've now got--
[00:46:26.700 --> 00:46:27.740]   --the order.
[00:46:27.740 --> 00:46:30.300]   We're not quite there yet, right?
[00:46:30.300 --> 00:46:32.700]   So let's get to that.
[00:46:32.700 --> 00:46:35.780]   And it's not quite the mental model you've got, I think.
[00:46:35.780 --> 00:46:38.340]   Now that I've got three transform blocks,
[00:46:38.340 --> 00:46:42.660]   I only have things to create two of them.
[00:46:42.660 --> 00:46:45.860]   So it's sad, right?
[00:46:45.860 --> 00:46:59.580]   And so we could put them here, for instance.
[00:46:59.580 --> 00:47:00.420]   And that would be--
[00:47:00.420 --> 00:47:01.020]   [INAUDIBLE]
[00:47:01.020 --> 00:47:03.340]   Last one is the y in the first two or the x.
[00:47:03.340 --> 00:47:04.140]   Correct.
[00:47:04.140 --> 00:47:11.660]   Unless we say number of inputs equals 1, in which case
[00:47:11.660 --> 00:47:16.740]   now we get x is just going to have to return one thing.
[00:47:16.740 --> 00:47:18.820]   There's going to be one function.
[00:47:18.820 --> 00:47:20.580]   And get y will be two things.
[00:47:28.180 --> 00:47:43.620]   So you could even put it here instead, right?
[00:47:43.620 --> 00:47:45.460]   So you could say, oh, well, this is actually--
[00:47:45.460 --> 00:47:52.380]   let's move it.
[00:47:56.540 --> 00:47:59.140]   We could put it here.
[00:47:59.140 --> 00:48:03.300]   Item transforms equals--
[00:48:03.300 --> 00:48:06.340]   And so the transform block is stuff
[00:48:06.340 --> 00:48:09.700]   that is applied for that transform.
[00:48:09.700 --> 00:48:14.780]   How is that not working?
[00:48:14.780 --> 00:48:21.020]   That's slightly surprising to me.
[00:48:21.020 --> 00:48:37.900]  , it needs to be a type transform.
[00:48:37.900 --> 00:48:39.060]   OK, type transform.
[00:48:39.060 --> 00:48:44.260]   So it's now converted to the type it's meant to be.
[00:48:44.260 --> 00:48:49.180]   So Radek, you were asking about image block.
[00:48:49.180 --> 00:48:53.820]   I'm just curious how all the pieces interact.
[00:48:53.820 --> 00:48:55.580]   [INTERPOSING VOICES]
[00:48:55.580 --> 00:48:57.260]   Let me show you.
[00:48:57.260 --> 00:48:58.340]   Let me show you.
[00:48:58.340 --> 00:49:01.260]   So let's do it manually.
[00:49:01.260 --> 00:49:04.220]   So image block is just this, OK?
[00:49:04.220 --> 00:49:05.820]   So let's not use image block.
[00:49:05.820 --> 00:49:07.220]   Let's instead--
[00:49:07.220 --> 00:49:09.540]   Why didn't the item transform work?
[00:49:09.540 --> 00:49:11.140]   Let's figure that out later.
[00:49:11.140 --> 00:49:13.380]   Yeah, why don't we figure out what's going on here,
[00:49:13.380 --> 00:49:14.700]   and then we'll debug it.
[00:49:14.700 --> 00:49:19.700]   OK, so now we've got three transform blocks, two of them
[00:49:19.700 --> 00:49:22.380]   which do nothing, and the first one of which
[00:49:22.380 --> 00:49:25.740]   is going to call something.create.
[00:49:25.740 --> 00:49:27.500]   That was period image.create.
[00:49:27.500 --> 00:49:34.500]   So transform blocks don't--
[00:49:34.500 --> 00:49:39.420]   if you look at the code of them, transform blocks
[00:49:39.420 --> 00:49:43.100]   don't do anything at all.
[00:49:43.100 --> 00:49:47.940]   They actually-- they only store things.
[00:49:47.940 --> 00:49:51.540]   There's no done to call.
[00:49:51.540 --> 00:49:53.060]   There's no forward.
[00:49:53.060 --> 00:49:55.020]   There's nothing.
[00:49:55.020 --> 00:49:56.620]   Transform blocks don't do anything.
[00:49:56.620 --> 00:49:59.140]   They just store stuff.
[00:49:59.140 --> 00:50:01.980]   The data block is the thing that then going to go through
[00:50:01.980 --> 00:50:05.700]   and say, OK, for each thing, call its type transforms,
[00:50:05.700 --> 00:50:08.580]   and then call to tensor, and then call its item transforms,
[00:50:08.580 --> 00:50:12.980]   and then data load of time, call its batch transforms.
[00:50:12.980 --> 00:50:16.140]   So does that help answer your question, Hamill?
[00:50:16.140 --> 00:50:20.460]   It's not that a transform block doesn't get called.
[00:50:20.460 --> 00:50:22.460]   It just stores the list of things
[00:50:22.460 --> 00:50:25.300]   that will get called at each of these times.
[00:50:25.300 --> 00:50:27.740]   The first thing that gets called is type transforms.
[00:50:27.740 --> 00:50:33.580]   Wait, is that right?
[00:50:33.580 --> 00:50:35.660]   Let me think.
[00:50:35.660 --> 00:50:37.100]   No, that's not correct.
[00:50:37.100 --> 00:50:40.100]   The first thing that gets called is get x and get y,
[00:50:40.100 --> 00:50:44.580]   and then the result of that is passed into type transforms.
[00:50:44.580 --> 00:50:47.020]   And so get x and get y--
[00:50:47.020 --> 00:50:49.580]   so get x would be responsible for making sure
[00:50:49.580 --> 00:50:54.780]   that you have a path that you can pass to pio-image.create.
[00:50:54.780 --> 00:50:55.460]   That's the order.
[00:50:55.460 --> 00:50:58.740]   So this whole path of what happens in a sequence
[00:50:58.740 --> 00:51:00.380]   that lives in a data block.
[00:51:00.380 --> 00:51:01.940]   That lives in data block, exactly.
[00:51:01.940 --> 00:51:05.380]   Now, the data block code is, frankly, hairy,
[00:51:05.380 --> 00:51:09.420]   and it could do with some simplifying and documenting
[00:51:09.420 --> 00:51:11.260]   and refactoring.
[00:51:11.260 --> 00:51:12.380]   It's not long.
[00:51:12.380 --> 00:51:16.580]   It's about 50 or 60 lines of code.
[00:51:16.580 --> 00:51:21.060]   In fact, it's almost all here.
[00:51:21.060 --> 00:51:27.980]   But basically, when you call .datasets, really,
[00:51:27.980 --> 00:51:31.380]   all it's doing is it creates a data sets
[00:51:31.380 --> 00:51:38.340]   object passing in all of the type transforms to it.
[00:51:38.340 --> 00:51:39.980]   And the answer to your question, Hamill,
[00:51:39.980 --> 00:51:42.100]   why didn't the item transforms get done,
[00:51:42.100 --> 00:51:43.740]   is because item transforms actually
[00:51:43.740 --> 00:51:47.860]   get done by the data loader, not by the data sets.
[00:51:47.860 --> 00:51:51.780]   So data sets only use the type transforms.
[00:51:51.780 --> 00:51:55.180]   And basically, the only reason there's quite a bit of code
[00:51:55.180 --> 00:52:00.820]   in here is we try to make sure that if two different things
[00:52:00.820 --> 00:52:05.340]   have the same type transforms, we merge them together
[00:52:05.340 --> 00:52:06.580]   in a sensible way.
[00:52:06.580 --> 00:52:10.900]   So there's some stuff to try to make sure this all just works.
[00:52:10.900 --> 00:52:15.260]   I was going to assume the type transforms
[00:52:15.260 --> 00:52:16.820]   are separate from the items transforms
[00:52:16.820 --> 00:52:21.300]   because of some optimization you can do with the type transforms?
[00:52:21.300 --> 00:52:26.100]   Because the type transforms, they're happening earlier.
[00:52:26.100 --> 00:52:31.020]   They're happening before data loaders time.
[00:52:31.020 --> 00:52:34.460]   So data loaders are the things that
[00:52:34.460 --> 00:52:42.540]   are going to take tensors, or at least things that
[00:52:42.540 --> 00:52:45.340]   can be converted into tensors.
[00:52:45.340 --> 00:52:48.780]   So yeah, so type transforms are the things
[00:52:48.780 --> 00:52:51.420]   that are going to create your data sets for you.
[00:52:51.420 --> 00:52:53.060]   And they're going to spit out things
[00:52:53.060 --> 00:52:56.380]   which need to be convertible into tensors.
[00:52:56.380 --> 00:53:01.220]   And then data loaders has item transforms,
[00:53:01.220 --> 00:53:04.180]   which are things like reshaping everything to the same size.
[00:53:04.180 --> 00:53:09.580]   And batch transforms, which are things like data augmentation.
[00:53:09.580 --> 00:53:13.420]   But you can have an item transform run on the GPU
[00:53:13.420 --> 00:53:14.820]   or not on the GPU, right?
[00:53:14.820 --> 00:53:16.100]   It depends on the ordering.
[00:53:16.100 --> 00:53:23.260]   I don't think an item transform is generally
[00:53:23.260 --> 00:53:27.020]   going to run on the GPU because it's not a batch yet.
[00:53:27.020 --> 00:53:29.100]   I mean, maybe it's theoretically possible,
[00:53:29.100 --> 00:53:32.060]   but that would be pretty weird because you really
[00:53:32.060 --> 00:53:34.380]   don't need things to be in a batch before the GPU can
[00:53:34.380 --> 00:53:37.820]   be optimizing it effectively.
[00:53:37.820 --> 00:53:39.700]   And everything in batch transforms
[00:53:39.700 --> 00:53:43.420]   will run on the GPU.
[00:53:43.420 --> 00:53:48.500]   Assuming that you're using a GPU, I mean, this is OK.
[00:53:48.500 --> 00:53:50.060]   This is some part of the code base
[00:53:50.060 --> 00:53:51.060]   we're not looking at today.
[00:53:51.060 --> 00:53:54.420]   But I can't remember.
[00:53:54.420 --> 00:53:57.820]   I think this might be a callback which sticks things on the GPU.
[00:53:57.820 --> 00:54:00.340]   So it just depends on whether things are before or after
[00:54:00.340 --> 00:54:02.820]   that callback.
[00:54:02.820 --> 00:54:05.380]   Yeah, that's probably a bit of a distraction.
[00:54:05.380 --> 00:54:08.780]   So let's skip that bit for now.
[00:54:08.780 --> 00:54:13.140]   To kind of revise the difference between data set and data loader,
[00:54:13.140 --> 00:54:16.900]   is it best to revisit the PyTorch documentation and kind of--
[00:54:16.900 --> 00:54:17.860]   Yeah, pretty much.
[00:54:17.860 --> 00:54:19.500]   We have our own implementation of them.
[00:54:19.500 --> 00:54:21.180]   But our implementation of data loader
[00:54:21.180 --> 00:54:24.380]   is a superset of PyTorches.
[00:54:24.380 --> 00:54:29.380]   And PyTorches data set is like literally it's an abstract class.
[00:54:29.380 --> 00:54:31.740]   It doesn't do anything at all.
[00:54:31.740 --> 00:54:35.300]   So a data set is something that you can index into.
[00:54:35.300 --> 00:54:39.540]   And it returns a single tuple of your independent and dependent
[00:54:39.540 --> 00:54:40.140]   variables.
[00:54:40.140 --> 00:54:44.660]   That's what a data set is defined as by PyTorch.
[00:54:44.660 --> 00:54:48.260]   And therefore, that's what we do as well.
[00:54:48.260 --> 00:54:51.860]   A data loader, you can't index into it.
[00:54:51.860 --> 00:54:54.220]   The only thing you can do is iterate through it.
[00:54:54.220 --> 00:54:55.660]   You can grab the next one.
[00:54:55.660 --> 00:55:00.180]   And it gives you a mini-batch, which is a tensor.
[00:55:00.180 --> 00:55:01.220]   So that's the difference.
[00:55:01.220 --> 00:55:04.140]   But yeah, that's a PyTorch concept.
[00:55:04.140 --> 00:55:09.340]   I guess I'm trying to understand the type transform thing,
[00:55:09.340 --> 00:55:13.420]   why it has to be done in the data set before the data loader.
[00:55:13.420 --> 00:55:14.540]   Well, it doesn't have to be.
[00:55:14.540 --> 00:55:17.220]   But it's like we want data sets.
[00:55:17.220 --> 00:55:19.780]   Data sets are a very convenient thing
[00:55:19.780 --> 00:55:24.700]   to have to have something you can go into and grab items,
[00:55:24.700 --> 00:55:26.940]   numbered x, y, or z.
[00:55:26.940 --> 00:55:30.660]   That's the basic foundation of the PyTorch data model,
[00:55:30.660 --> 00:55:34.020]   is that there's things you can index into.
[00:55:34.020 --> 00:55:36.460]   The type transform aspect of it.
[00:55:36.460 --> 00:55:39.700]   Yeah, so you need something that converts
[00:55:39.700 --> 00:55:43.580]   the output of get image files into what
[00:55:43.580 --> 00:55:45.780]   you want in your data set.
[00:55:45.780 --> 00:55:47.180]   And that thing needs a name.
[00:55:47.180 --> 00:55:49.020]   And the name we gave it was type transforms.
[00:55:52.740 --> 00:55:57.140]   OK, I think I understand.
[00:55:57.140 --> 00:55:59.860]   This is not the only way you could do this, right?
[00:55:59.860 --> 00:56:02.540]   But it's our way that's really nice
[00:56:02.540 --> 00:56:05.220]   because we now have this thing that you can say like,
[00:56:05.220 --> 00:56:09.260]   oh, Hamill, can you show me the 14th image and its label?
[00:56:09.260 --> 00:56:10.940]   And you can say, yes, no problem, Jeremy.
[00:56:10.940 --> 00:56:14.820]   You can type DSS dot train bracket 13.
[00:56:14.820 --> 00:56:17.020]   And there it is, right?
[00:56:17.020 --> 00:56:23.900]   So yes, that's just a convenient thing, basically.
[00:56:23.900 --> 00:56:26.100]   So I guess a question around that
[00:56:26.100 --> 00:56:29.340]   is that if we did not have type transforms,
[00:56:29.340 --> 00:56:33.580]   then it would just be one more step in the item transforms,
[00:56:33.580 --> 00:56:34.300]   right?
[00:56:34.300 --> 00:56:36.020]   Yeah, I think so.
[00:56:36.020 --> 00:56:38.180]   So it is just separating those things out.
[00:56:38.180 --> 00:56:42.300]   Yeah, your data sets would always just return a single thing,
[00:56:42.300 --> 00:56:46.540]   or maybe two things, the get x and get y results.
[00:56:46.540 --> 00:56:50.860]   And then your data loader would have to do more work, basically.
[00:56:50.860 --> 00:56:51.380]   Exactly.
[00:56:51.380 --> 00:56:52.260]   Yeah, yeah.
[00:56:52.260 --> 00:56:56.220]   Which would be a perfectly OK way to do things as far as I
[00:56:56.220 --> 00:56:59.740]   can tell that I think would be a little harder to debug
[00:56:59.740 --> 00:57:05.140]   and work with and keep things decoupled.
[00:57:05.140 --> 00:57:07.860]   Yeah, I think that's a reasonable comment.
[00:57:07.860 --> 00:57:11.300]   Is it like anything you want to do up front that
[00:57:11.300 --> 00:57:13.540]   is like kind of uniform across your whole data set,
[00:57:13.540 --> 00:57:15.460]   maybe put it in the type transform
[00:57:15.460 --> 00:57:18.860]   that you don't need to change at training time?
[00:57:18.860 --> 00:57:23.660]   Basically, like anything that you
[00:57:23.660 --> 00:57:28.340]   want to be able to index into it and look at that thing, really.
[00:57:28.340 --> 00:57:33.660]   If you're not sure where to put it,
[00:57:33.660 --> 00:57:35.860]   I'd say just chuck it somewhere and don't worry about it.
[00:57:35.860 --> 00:57:41.300]   You know, we kind of put--
[00:57:41.300 --> 00:57:47.180]   the rule is that you need something that
[00:57:47.180 --> 00:57:48.900]   can be turned into a tensor.
[00:57:48.900 --> 00:57:52.100]   Like that's the way fast AI does it.
[00:57:52.100 --> 00:57:55.860]   So you need to make sure that your type transform, when
[00:57:55.860 --> 00:57:57.780]   you're working with fast AI, returns something
[00:57:57.780 --> 00:58:02.100]   that is a tensor or going to be turned into a tensor.
[00:58:02.100 --> 00:58:06.780]   Which PIL image can be, for example?
[00:58:06.780 --> 00:58:08.820]   OK.
[00:58:08.820 --> 00:58:09.700]   I think I understand.
[00:58:09.700 --> 00:58:12.500]   It's kind of like you want to make sure
[00:58:12.500 --> 00:58:16.300]   it's a convenient thing that you understand to look at.
[00:58:16.300 --> 00:58:17.860]   Yeah.
[00:58:17.860 --> 00:58:18.900]   OK.
[00:58:18.900 --> 00:58:20.700]   Yeah.
[00:58:20.700 --> 00:58:22.660]   OK, so then like--
[00:58:22.660 --> 00:58:26.500]   OK, so I can remove all that.
[00:58:26.500 --> 00:58:29.100]   This is the definition of image block.
[00:58:29.100 --> 00:58:31.580]   So let's replace it with the word image block.
[00:58:31.580 --> 00:58:33.420]   OK.
[00:58:33.420 --> 00:58:47.420]   And then let's change-- OK, let me think.
[00:58:47.420 --> 00:58:55.460]   OK, so let's put a dot name here.
[00:59:01.340 --> 00:59:04.180]   Here's kind of something we want as our label, right?
[00:59:04.180 --> 00:59:05.940]   That's one of our labels.
[00:59:05.940 --> 00:59:09.900]   And then the other label we wanted
[00:59:09.900 --> 00:59:21.740]   was the function called get variety, right?
[00:59:21.740 --> 00:59:24.260]   Now we can't-- this breaks our rule.
[00:59:24.260 --> 00:59:29.540]   This can't be turned into a tensor because it's a string.
[00:59:29.540 --> 00:59:34.060]   So what do we do about that?
[00:59:34.060 --> 00:59:35.780]   You might remember from a previous lesson
[00:59:35.780 --> 00:59:39.580]   we learned that what we do is we replace strings with integers
[00:59:39.580 --> 00:59:42.660]   where that integer is a lookup into a vocabulary.
[00:59:42.660 --> 00:59:45.500]   It's a list of all of the possible options.
[00:59:45.500 --> 00:59:55.860]   So if we change this to category block,
[00:59:55.860 --> 01:00:04.380]   that is exactly what category block will do, right?
[01:00:04.380 --> 01:00:15.580]   And so category block, it's got a type transform
[01:00:15.580 --> 01:00:19.380]   categorize, which I'm not going to go into because it's not
[01:00:19.380 --> 01:00:21.620]   particularly exciting.
[01:00:21.620 --> 01:00:25.180]   But if you look up the documentation for categories,
[01:00:25.180 --> 01:00:27.140]   you can see how it does that.
[01:00:27.140 --> 01:00:29.500]   So basically, internally now, you'll
[01:00:29.500 --> 01:00:35.380]   find that the vocab is stored for these things.
[01:00:35.380 --> 01:00:39.900]   So if we look at this at a high level, get items, get--
[01:00:39.900 --> 01:00:42.140]   By the way, just a moment, here's the vocab, right?
[01:00:42.140 --> 01:00:43.420]   It's got two things.
[01:00:43.420 --> 01:00:45.260]   It's got the vocab for the diseases
[01:00:45.260 --> 01:00:47.260]   and the vocab for the varieties.
[01:00:47.260 --> 01:00:48.540]   Yeah, sorry, Radek.
[01:00:48.540 --> 01:00:49.540]   No worries.
[01:00:49.540 --> 01:00:53.940]   So get items gets us the rows or the examples
[01:00:53.940 --> 01:00:55.660]   or whatever allows us to--
[01:00:55.660 --> 01:00:59.140]   and then the core for a single example.
[01:00:59.140 --> 01:01:03.820]   And then from get items, we use get y or get x
[01:01:03.820 --> 01:01:07.220]   to transform it somehow so that we can pass it
[01:01:07.220 --> 01:01:08.340]   into those blocks.
[01:01:08.340 --> 01:01:10.820]   Correct, specifically pass it into the type
[01:01:10.820 --> 01:01:12.500]   transforms of those blocks.
[01:01:12.500 --> 01:01:13.700]   Into type transforms.
[01:01:13.700 --> 01:01:19.700]   And type transforms are things that can get triggered, right?
[01:01:19.700 --> 01:01:23.460]   So they're doing a little bit something similar to get y,
[01:01:23.460 --> 01:01:25.780]   but are building on what get y does.
[01:01:25.780 --> 01:01:26.980]   Correct, exactly.
[01:01:26.980 --> 01:01:31.340]   Because these are very general things, right?
[01:01:31.340 --> 01:01:32.980]   And so I didn't want you guys to have
[01:01:32.980 --> 01:01:34.940]   to write your own every time.
[01:01:34.940 --> 01:01:38.860]   So these basically say, this says,
[01:01:38.860 --> 01:01:42.540]   I will work if you can pass me a path to an image.
[01:01:42.540 --> 01:01:45.620]   And this says, I will work if you pass me a string.
[01:01:45.620 --> 01:01:48.980]   And so get x and get y then are responsible for ensuring
[01:01:48.980 --> 01:01:53.500]   that you pass them a path and pass this one a string.
[01:01:53.500 --> 01:01:56.060]   And get image files is already returning paths,
[01:01:56.060 --> 01:02:00.380]   so we don't need to get x for this guy.
[01:02:00.380 --> 01:02:02.340]   But it's not returning strings, so we
[01:02:02.340 --> 01:02:04.060]   do need to get y for these guys.
[01:02:04.060 --> 01:02:11.060]   OK, so I'm going to finish--
[01:02:11.060 --> 01:02:14.900]   I'm going to run it slightly over time.
[01:02:14.900 --> 01:02:26.060]   But let's have a look at-- so this is exactly the same.
[01:02:26.060 --> 01:02:30.620]   OK, so this is exactly the same as what we just had, right?
[01:02:30.620 --> 01:02:33.020]   And so then we can also then add the two things, which
[01:02:33.020 --> 01:02:35.020]   is the item transforms and the batch transforms.
[01:02:35.020 --> 01:02:38.100]   Some other time, we will talk about how it is that--
[01:02:38.100 --> 01:02:40.820]   how come this is not being applied to the categories?
[01:02:40.820 --> 01:02:43.380]   It's only being applied to the images.
[01:02:43.380 --> 01:02:45.500]   For those of you interested in skipping ahead,
[01:02:45.500 --> 01:02:49.220]   the secret is using fast calls type dispatch functionality.
[01:02:49.220 --> 01:02:55.460]   Anyway, so that's why we're getting
[01:02:55.460 --> 01:02:58.140]   these three different things-- image, we've got y1.
[01:02:58.140 --> 01:03:01.580]   So Jeremy, if we had an image, if we had an image block
[01:03:01.580 --> 01:03:04.900]   in our--
[01:03:04.900 --> 01:03:08.860]   for our y's, for our targets, then item transform
[01:03:08.860 --> 01:03:10.820]   would get applied.
[01:03:10.820 --> 01:03:11.940]   Correct.
[01:03:11.940 --> 01:03:13.260]   Oh, wow.
[01:03:13.260 --> 01:03:17.220]   And there's a-- have a look at the Siamese tutorial
[01:03:17.220 --> 01:03:22.380]   on the fast.ai docs, because that has two images.
[01:03:22.380 --> 01:03:22.900]   Yeah.
[01:03:22.900 --> 01:03:25.780]   And if you think about it, any time we do segmentation,
[01:03:25.780 --> 01:03:27.340]   that's exactly what's happening, right?
[01:03:27.340 --> 01:03:29.580]   The data augmentation is happening to x and y.
[01:03:29.580 --> 01:03:32.300]   And this is really unusual.
[01:03:32.300 --> 01:03:33.980]   I don't know of any other libraries
[01:03:33.980 --> 01:03:36.700]   that have this kind of totally transparent ability
[01:03:36.700 --> 01:03:42.380]   to do bounding boxes, segmentation, point clouds,
[01:03:42.380 --> 01:03:45.220]   whatever as dependent variables, and have it all
[01:03:45.220 --> 01:03:49.420]   happen in unison very, very automatically.
[01:03:49.420 --> 01:03:51.060]   Well, at least it didn't used to be.
[01:03:51.060 --> 01:03:51.940]   Maybe there is now.
[01:03:51.940 --> 01:04:04.940]   OK, so now I can create data loaders from that.
[01:04:04.940 --> 01:04:12.100]   And thanks to the magic of fast.ai, this is so cool.
[01:04:12.100 --> 01:04:12.700]   Check this out.
[01:04:12.700 --> 01:04:16.620]   It's actually auto labeling it with each of our categories.
[01:04:16.620 --> 01:04:20.860]   So thanks to stuff we'll discuss later, basically this stuff
[01:04:20.860 --> 01:04:26.340]   called type dispatch, fast.ai does a lot of things
[01:04:26.340 --> 01:04:29.140]   automatically, even though I don't think I've ever explicitly
[01:04:29.140 --> 01:04:31.060]   coded this to work.
[01:04:31.060 --> 01:04:35.780]   It just does because of how the API is designed.
[01:04:35.780 --> 01:04:37.340]   So we now have something which can
[01:04:37.340 --> 01:04:40.700]   create batches of pictures and two
[01:04:40.700 --> 01:04:43.540]   different dependent variables, each one of which
[01:04:43.540 --> 01:04:44.020]   has a category.
[01:04:44.020 --> 01:04:58.900]   And so what we will get to next time
[01:04:58.900 --> 01:05:02.780]   is it actually turns out--
[01:05:02.780 --> 01:05:05.580]   well, I briefly mentioned it now, actually.
[01:05:05.580 --> 01:05:07.660]   All that stuff I did last time about messing around
[01:05:07.660 --> 01:05:09.940]   with multiple different heads and all that
[01:05:09.940 --> 01:05:12.180]   is actually totally unnecessary.
[01:05:12.180 --> 01:05:15.140]   All we need to do when we create our vision learner
[01:05:15.140 --> 01:05:17.860]   is tell it we don't want 10 outputs,
[01:05:17.860 --> 01:05:20.020]   but we don't want 20 outputs.
[01:05:20.020 --> 01:05:21.860]   So normally it automatically figures out
[01:05:21.860 --> 01:05:24.940]   how many outputs you want by how many levels are
[01:05:24.940 --> 01:05:27.380]   in your categorical dependent variable.
[01:05:27.380 --> 01:05:29.420]   But in this case, we've got something custom, right,
[01:05:29.420 --> 01:05:32.060]   which is we've got a tuple of outputs.
[01:05:32.060 --> 01:05:32.940]   So we have to tell it.
[01:05:32.940 --> 01:05:34.380]   We want 20 outputs.
[01:05:34.380 --> 01:05:38.540]   That's going to make the final matrix that it multiplies by
[01:05:38.540 --> 01:05:41.060]   have 20 outputs.
[01:05:41.060 --> 01:05:46.740]   Now, then you basically need to tell it what loss function
[01:05:46.740 --> 01:05:48.540]   to use.
[01:05:48.540 --> 01:05:50.540]   And so if you look it up, it turns out
[01:05:50.540 --> 01:05:52.460]   we used to use a loss function for this called
[01:05:52.460 --> 01:05:54.300]   cross-entropy_loss_flat.
[01:05:54.300 --> 01:05:56.620]   So we're going to call that exact loss function
[01:05:56.620 --> 01:06:00.740]   on the first 10 items.
[01:06:00.740 --> 01:06:05.860]   And we're going to compare that to the disease probabilities.
[01:06:05.860 --> 01:06:08.500]   And then the second 10, we're going
[01:06:08.500 --> 01:06:11.660]   to compare to the variety probabilities.
[01:06:11.660 --> 01:06:14.940]   And we'll do the same thing for having an error rate, which
[01:06:14.940 --> 01:06:18.340]   just looks at the first 10, the error rate for disease,
[01:06:18.340 --> 01:06:19.980]   and the same thing for variety.
[01:06:19.980 --> 01:06:22.460]   Look at the second 10, the variety.
[01:06:22.460 --> 01:06:25.700]   And so basically then, if you train that,
[01:06:25.700 --> 01:06:29.300]   it's going to print out the disease and the variety error.
[01:06:29.300 --> 01:06:31.500]   And the loss function will be the loss function
[01:06:31.500 --> 01:06:35.500]   on both of the two halves.
[01:06:35.500 --> 01:06:42.100]   And interestingly, for this single model,
[01:06:42.100 --> 01:06:44.820]   this 2.3% disease error is the best I'd ever
[01:06:44.820 --> 01:06:47.580]   got for this architecture.
[01:06:47.580 --> 01:06:50.100]   So at least for this single model case,
[01:06:50.100 --> 01:06:56.580]   this was better than training something that
[01:06:56.580 --> 01:06:57.940]   only predicts disease.
[01:06:57.940 --> 01:06:59.620]   Anyway, we can talk about that more later,
[01:06:59.620 --> 01:07:01.460]   because we kind of spent more time on it.
[01:07:01.460 --> 01:07:02.580]   I have a quick question.
[01:07:02.580 --> 01:07:03.580]   Yeah.
[01:07:03.580 --> 01:07:09.540]   The last layer, it's a flat 20 output layer.
[01:07:09.540 --> 01:07:12.780]   Does this mean at inference time that we
[01:07:12.780 --> 01:07:16.460]   would have to do the softmax plus--
[01:07:16.460 --> 01:07:17.340]   what would it be?
[01:07:17.340 --> 01:07:18.060]   I can't remember.
[01:07:18.060 --> 01:07:20.380]   No, firstly, I handled all that for you automatically.
[01:07:20.380 --> 01:07:21.180]   All right.
[01:07:21.180 --> 01:07:21.660]   Yeah.
[01:07:21.660 --> 01:07:28.260]   Great.
[01:07:28.260 --> 01:07:28.740]   All right.
[01:07:28.740 --> 01:07:31.620]   And by the way, in the inference functions,
[01:07:31.620 --> 01:07:34.900]   you'll see there's always a rule in options
[01:07:34.900 --> 01:07:37.140]   as to whether to decode it and whether to put
[01:07:37.140 --> 01:07:39.740]   the final activation function on it and stuff like that.
[01:07:39.740 --> 01:07:42.740]   So actually, now I think about it.
[01:07:42.740 --> 01:07:46.180]   In this case, because we used a custom loss function,
[01:07:46.180 --> 01:07:48.700]   I think that would have broken its ability
[01:07:48.700 --> 01:07:49.780]   to do it automatically.
[01:07:49.780 --> 01:07:51.540]   So yeah, OK, I'm going to say actually,
[01:07:51.540 --> 01:07:55.820]   you would need to add a softmax if you wanted to.
[01:07:55.820 --> 01:07:59.620]   Although you actually don't need to,
[01:07:59.620 --> 01:08:03.260]   because at least for the Kaggle competition,
[01:08:03.260 --> 01:08:09.260]   I just needed which disease had the highest prediction.
[01:08:09.260 --> 01:08:11.420]   And whether it's softmax or not, it's
[01:08:11.420 --> 01:08:18.460]   going to be the same because that's a monotonic function.
[01:08:18.460 --> 01:08:20.380]   So it depends whether you actually
[01:08:20.380 --> 01:08:22.860]   need probabilities or not.
[01:08:22.860 --> 01:08:26.540]   In my case, I didn't have to do this.
[01:08:26.540 --> 01:08:29.300]   Yeah, but you would only look at the first 10
[01:08:29.300 --> 01:08:31.620]   or the second, I guess, the first ones.
[01:08:31.620 --> 01:08:33.180]   Yeah, so you just--
[01:08:33.180 --> 01:08:33.780]   You can see it.
[01:08:33.780 --> 01:08:36.740]   Because otherwise, yeah.
[01:08:36.740 --> 01:08:41.540]   So I was using TTA to do test plan augmentation.
[01:08:41.540 --> 01:08:44.460]   And I stacked up and I did an ensemble of TTA.
[01:08:44.460 --> 01:08:49.380]   And then I just did an argmax on the first 10.
[01:08:49.380 --> 01:08:51.420]   Yeah, all right.
[01:08:51.420 --> 01:08:52.500]   All right.
[01:08:52.500 --> 01:08:54.100]   Just hold up.
[01:08:54.100 --> 01:08:55.380]   OK, sure.
[01:08:55.380 --> 01:09:03.300]   In the architecture, you selected for ResNet 18, 128.
[01:09:03.300 --> 01:09:06.220]   Is there any programmatic way to find out
[01:09:06.220 --> 01:09:10.100]   the size or the input size of the models
[01:09:10.100 --> 01:09:12.260]   that you are trying to use?
[01:09:12.260 --> 01:09:15.660]   These models handle any input size.
[01:09:15.660 --> 01:09:17.500]   All right.
[01:09:17.500 --> 01:09:17.980]   Yeah.
[01:09:17.980 --> 01:09:18.620]   All right.
[01:09:18.620 --> 01:09:20.180]   All right.
[01:09:20.180 --> 01:09:22.220]   All the ResNets and all the ConfNecks
[01:09:22.220 --> 01:09:24.580]   handle any input size.
[01:09:24.580 --> 01:09:25.540]   All right.
[01:09:25.540 --> 01:09:26.060]   Thank you.
[01:09:26.060 --> 01:09:28.740]   It's only the transformer models.
[01:09:28.740 --> 01:09:30.620]   That also tripped me up in the beginning.
[01:09:30.620 --> 01:09:32.620]   But there's a lot of interesting stuff there
[01:09:32.620 --> 01:09:36.180]   that might take a whole lecture to understand.
[01:09:36.180 --> 01:09:38.500]   All right, again, all that stuff, yeah.
[01:09:38.500 --> 01:09:39.460]   Thanks, gang.
[01:09:39.460 --> 01:09:40.340]   See you.
[01:09:40.340 --> 01:09:40.860]   Thank you.
[01:09:40.860 --> 01:09:42.420]   Thank you.
[01:09:42.420 --> 01:09:52.420]   [BLANK_AUDIO]

