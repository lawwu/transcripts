
[00:00:00.000 --> 00:00:01.900]   is scaling dead, then why is Mark Zuckerberg
[00:00:01.900 --> 00:00:04.140]   building a two gigawatt data center in Louisiana?
[00:00:04.140 --> 00:00:07.900]   Why is Amazon building these multi-gigawatt data centers?
[00:00:07.900 --> 00:00:09.140]   Why is Google, why is Microsoft
[00:00:09.140 --> 00:00:10.820]   building multiple gigawatt data centers,
[00:00:10.820 --> 00:00:14.600]   plus buying billions and billions of dollars of fiber
[00:00:14.600 --> 00:00:16.100]   to connect them together because they think,
[00:00:16.100 --> 00:00:17.860]   hey, I need to win on scale,
[00:00:17.860 --> 00:00:19.580]   so let me just connect all the data centers together
[00:00:19.580 --> 00:00:20.580]   with super high bandwidth
[00:00:20.580 --> 00:00:23.140]   so then I can make them act like one data center, right?
[00:00:23.140 --> 00:00:24.380]   Towards one job, right?
[00:00:24.380 --> 00:00:28.020]   So this whole, like, is scaling over narrative
[00:00:28.020 --> 00:00:30.060]   falls on its face when you see
[00:00:30.060 --> 00:00:32.840]   what the people who know the best are spending on.
[00:00:32.840 --> 00:00:35.420]   (upbeat music)
[00:00:35.420 --> 00:00:45.640]   - Great to be here.
[00:00:45.640 --> 00:00:47.860]   Psyched you both are in the shop today.
[00:00:47.860 --> 00:00:49.940]   Dylan, this is one of the things
[00:00:49.940 --> 00:00:51.080]   we've been talking about all year,
[00:00:51.080 --> 00:00:51.920]   which is, you know,
[00:00:51.920 --> 00:00:53.940]   how the world of compute is radically changing.
[00:00:53.940 --> 00:00:55.940]   So Bill, why don't you tell folks
[00:00:55.940 --> 00:00:59.300]   who Dylan is, and let's get started.
[00:00:59.300 --> 00:01:01.340]   - Yeah, we're thrilled to have Dylan Patel with us
[00:01:01.340 --> 00:01:02.460]   from Semi-Analysis.
[00:01:02.460 --> 00:01:05.140]   Dylan has quickly built,
[00:01:05.140 --> 00:01:07.740]   I think, the most respected research group
[00:01:07.740 --> 00:01:09.700]   on global semiconductor industry.
[00:01:09.700 --> 00:01:11.940]   And so what we thought we'd do today
[00:01:11.940 --> 00:01:15.700]   is dive deep on the intersection, I think,
[00:01:15.700 --> 00:01:17.900]   between everything Dylan knows
[00:01:17.900 --> 00:01:20.480]   from a technical perspective about the architectures
[00:01:20.480 --> 00:01:22.540]   that are out there, about the scaling,
[00:01:22.540 --> 00:01:25.220]   about the key players in the market globally,
[00:01:25.220 --> 00:01:28.180]   the supply chain, and the best and the brightest
[00:01:28.180 --> 00:01:30.420]   of people we know are all listening
[00:01:30.420 --> 00:01:32.160]   and reading Dylan's work.
[00:01:32.160 --> 00:01:34.940]   And then connect it to some of the business issues
[00:01:34.940 --> 00:01:36.900]   that our audience cares about,
[00:01:36.900 --> 00:01:38.820]   and see where it comes out.
[00:01:38.820 --> 00:01:42.780]   What I was hoping to do is kind of get a moment in time
[00:01:42.780 --> 00:01:46.080]   snapshot of all the semiconductor activity
[00:01:46.080 --> 00:01:48.540]   that relates to this big AI wave,
[00:01:48.540 --> 00:01:50.600]   and try and put it in perspective.
[00:01:50.600 --> 00:01:52.900]   - Dylan, how'd you get into this?
[00:01:52.900 --> 00:01:54.620]   - So when I was eight, my Xbox broke,
[00:01:54.620 --> 00:01:56.220]   and I have immigrant parents.
[00:01:56.220 --> 00:01:57.860]   I grew up in rural Georgia,
[00:01:57.860 --> 00:02:00.940]   so I didn't have much to do besides be a nerd,
[00:02:00.940 --> 00:02:03.000]   and I couldn't tell them I broke my Xbox.
[00:02:03.000 --> 00:02:05.300]   I had to open it up, short the temperature sensor,
[00:02:05.300 --> 00:02:06.500]   and fix it, and that was the way to fix it.
[00:02:06.500 --> 00:02:08.100]   I didn't know what I was doing at the time,
[00:02:08.100 --> 00:02:09.580]   but then I stayed on those forums.
[00:02:09.580 --> 00:02:11.220]   And then I became a forum warrior, right?
[00:02:11.220 --> 00:02:12.840]   You know, you see those people in the comments
[00:02:12.840 --> 00:02:14.540]   always yelling at you, Brad.
[00:02:14.540 --> 00:02:17.140]   You know, it's like, that was me, right?
[00:02:17.140 --> 00:02:18.980]   As a child, and you didn't know I was a child then,
[00:02:18.980 --> 00:02:21.660]   but you know, it was just like, you know,
[00:02:21.660 --> 00:02:23.380]   arguing with people online as a child,
[00:02:23.380 --> 00:02:25.460]   and then being passionate.
[00:02:25.460 --> 00:02:26.420]   As soon as I started making money,
[00:02:26.420 --> 00:02:28.220]   I was reading earnings from semiconductor companies,
[00:02:28.220 --> 00:02:30.900]   and investing in them, you know, with my internship money,
[00:02:30.900 --> 00:02:34.740]   and yeah, reading technical stuff as well, of course,
[00:02:34.740 --> 00:02:36.620]   and then working a little bit, and then, yeah.
[00:02:36.620 --> 00:02:38.740]   - And just tell us, give us a quick thumbnail
[00:02:38.740 --> 00:02:40.260]   on semi-analysis today.
[00:02:40.260 --> 00:02:41.420]   Like, what is the business?
[00:02:41.420 --> 00:02:44.460]   - Yeah, so today we are a semiconductor research firm,
[00:02:44.460 --> 00:02:45.420]   AI research firm.
[00:02:45.420 --> 00:02:46.960]   We service companies.
[00:02:46.960 --> 00:02:49.060]   Our biggest customers are all hyperscalers,
[00:02:49.060 --> 00:02:51.100]   the largest semiconductor companies,
[00:02:51.100 --> 00:02:52.660]   private equity, as well as hedge funds,
[00:02:52.660 --> 00:02:55.300]   and we sell data around where every data center
[00:02:55.300 --> 00:02:57.580]   in the world is, what the power is in each quarter,
[00:02:57.580 --> 00:02:59.460]   how the build-outs are going.
[00:02:59.460 --> 00:03:01.180]   We sell data around fabs.
[00:03:01.180 --> 00:03:03.100]   We track all 1,500 fabs in the world.
[00:03:03.100 --> 00:03:04.740]   For your purposes, only 50 of them matter,
[00:03:04.740 --> 00:03:07.140]   but like, you know, all 1,500 fabs around the world.
[00:03:07.140 --> 00:03:09.460]   Same thing with the supply chain of like,
[00:03:09.460 --> 00:03:12.660]   whether it be cables, or servers, or boards,
[00:03:12.660 --> 00:03:14.740]   or transformer substation equipment.
[00:03:14.740 --> 00:03:17.740]   We try and track all of this on a very number-driven basis,
[00:03:17.740 --> 00:03:19.300]   as well as forecasting.
[00:03:19.300 --> 00:03:21.220]   And then we do consulting around those areas.
[00:03:21.220 --> 00:03:23.260]   - Yeah, so I mean, you know, Bill,
[00:03:23.260 --> 00:03:24.980]   you and I just talked about this.
[00:03:24.980 --> 00:03:27.100]   I mean, for Altimeter,
[00:03:27.100 --> 00:03:29.980]   our team talks with Dylan and Dylan's team all the time.
[00:03:29.980 --> 00:03:31.620]   I think you're right.
[00:03:31.620 --> 00:03:35.020]   He's quickly emerged, really just through hustle, hard work,
[00:03:35.020 --> 00:03:38.300]   doing the grindy stuff that matters,
[00:03:38.300 --> 00:03:40.260]   I think is, you know, a benchmark
[00:03:40.260 --> 00:03:42.460]   for what's going on in the semiconductor industry.
[00:03:42.460 --> 00:03:44.500]   We're at this, you know, I suggested,
[00:03:44.500 --> 00:03:47.380]   we're two years into this, maybe, you know, this build-out,
[00:03:47.380 --> 00:03:49.700]   and it's been hyper-kinetic.
[00:03:49.700 --> 00:03:51.740]   And one of the things Bill and I are talking about
[00:03:51.740 --> 00:03:56.300]   is we enter the end of 2024 taking a deep breath,
[00:03:56.300 --> 00:03:59.020]   thinking about '25, '26, and beyond,
[00:03:59.020 --> 00:04:00.620]   because a lot of things are changing,
[00:04:00.620 --> 00:04:02.220]   and there's a lot of debates.
[00:04:02.220 --> 00:04:05.300]   And it's gonna have consequence for trillions of dollars
[00:04:05.300 --> 00:04:09.020]   of value in the public markets, in the private markets,
[00:04:09.020 --> 00:04:11.420]   how the hyperscalers are investing,
[00:04:11.420 --> 00:04:12.380]   and where we go from here.
[00:04:12.380 --> 00:04:15.140]   So Bill, why don't you take us a little bit
[00:04:15.140 --> 00:04:17.260]   through the start of the questions?
[00:04:17.260 --> 00:04:19.740]   - Well, so I think if you're gonna talk about AI
[00:04:19.740 --> 00:04:21.900]   and semiconductors, there's only one place to start,
[00:04:21.900 --> 00:04:25.420]   which is to talk about NVIDIA broadly.
[00:04:25.420 --> 00:04:28.660]   Dylan, what percentage of global AI workloads
[00:04:28.660 --> 00:04:31.460]   do you think are on NVIDIA chips right now?
[00:04:31.460 --> 00:04:35.860]   - So I would say if you ignored Google, it'd be over 98%.
[00:04:35.860 --> 00:04:37.500]   But then when you bring Google into the mix,
[00:04:37.500 --> 00:04:40.820]   it's actually more like 70, 'cause Google is really
[00:04:40.820 --> 00:04:43.300]   that large a percentage of AI workloads,
[00:04:43.300 --> 00:04:45.340]   especially production workloads.
[00:04:45.340 --> 00:04:46.180]   You know, they have less--
[00:04:46.180 --> 00:04:48.820]   - Production, you mean in-house workloads for Google?
[00:04:48.820 --> 00:04:51.020]   - Production as in things that are making money.
[00:04:51.020 --> 00:04:52.820]   Things that are making money, they're actually probably,
[00:04:52.820 --> 00:04:54.420]   it's probably even less than 70%, right?
[00:04:54.420 --> 00:04:56.700]   'Cause you think about Google Search and Google Ads
[00:04:56.700 --> 00:04:58.380]   are the two largest, you know,
[00:04:58.380 --> 00:05:02.020]   two of the largest AI-driven businesses in the world, right?
[00:05:02.020 --> 00:05:03.620]   You know, the only things that are even comparable
[00:05:03.620 --> 00:05:06.780]   are like TikTok and Metas, right?
[00:05:06.780 --> 00:05:09.260]   - And those Google workloads, I think it's important
[00:05:09.260 --> 00:05:12.980]   just to kind of frame this, those are running
[00:05:12.980 --> 00:05:15.900]   on Google's proprietary chips.
[00:05:15.900 --> 00:05:20.460]   They're non-LLM workloads, correct?
[00:05:20.460 --> 00:05:25.460]   - So Google's production workloads for non-LLM and LLM
[00:05:25.460 --> 00:05:27.940]   run on their internal silicon.
[00:05:27.940 --> 00:05:30.260]   And I think one of the interesting things is, yes,
[00:05:30.260 --> 00:05:32.100]   you know, everyone will say Google dropped the ball
[00:05:32.100 --> 00:05:33.900]   on transformers and LLMs, right?
[00:05:33.900 --> 00:05:35.860]   How did OpenAI do GPT, right?
[00:05:35.860 --> 00:05:39.060]   And not Google, but Google was running transformers
[00:05:39.060 --> 00:05:42.820]   even in their search workload since 2018, 2019.
[00:05:42.820 --> 00:05:46.580]   The advent of BERT, which was one of the most well-known,
[00:05:46.580 --> 00:05:50.100]   most popular transformers before we got to the GPT madness,
[00:05:50.100 --> 00:05:54.780]   has been in their production search workloads for years.
[00:05:54.780 --> 00:05:56.980]   So they run transformers on their own
[00:05:56.980 --> 00:05:59.020]   in their search and ads business as well.
[00:05:59.020 --> 00:06:03.860]   - Going back to this number, you'd use 98%.
[00:06:03.860 --> 00:06:07.540]   If you just look at, I guess, workloads people
[00:06:07.540 --> 00:06:09.660]   are purchasing to do work on their own.
[00:06:09.660 --> 00:06:12.900]   So you take the captives out, you're at 98, right?
[00:06:12.900 --> 00:06:17.700]   This is a dominant landslide at this moment in time.
[00:06:17.700 --> 00:06:18.700]   - Back to Google for a second.
[00:06:18.700 --> 00:06:21.260]   They also are one of the big customers of Nvidia.
[00:06:21.260 --> 00:06:24.580]   - They do buy a number of GPUs.
[00:06:24.580 --> 00:06:25.820]   They buy some for, you know,
[00:06:25.820 --> 00:06:27.460]   some YouTube video-related workloads,
[00:06:27.460 --> 00:06:28.300]   internal workload, right?
[00:06:28.300 --> 00:06:33.300]   So not everything internal is like, is a GPU, right?
[00:06:33.300 --> 00:06:35.780]   They do buy some for some other internal workloads,
[00:06:35.780 --> 00:06:40.020]   but by and large, their GPU purchases are for Google Cloud
[00:06:40.020 --> 00:06:42.220]   to then rent out to customers.
[00:06:42.220 --> 00:06:45.300]   Because they are, while they do have some customers
[00:06:45.300 --> 00:06:49.460]   for their internal silicon externally, such as Apple,
[00:06:49.460 --> 00:06:53.980]   the vast majority of their external rental business for AI
[00:06:53.980 --> 00:06:55.940]   in terms of cloud business is still GPUs.
[00:06:55.940 --> 00:06:57.740]   - And that's the Nvidia GPUs.
[00:06:57.740 --> 00:06:59.020]   - Correct, Nvidia GPUs.
[00:06:59.020 --> 00:07:00.780]   - Why are they so dominant?
[00:07:00.780 --> 00:07:03.140]   Why is Nvidia so dominant?
[00:07:03.140 --> 00:07:06.100]   - So I like to think of it as like a three-headed dragon,
[00:07:06.100 --> 00:07:06.940]   right?
[00:07:06.940 --> 00:07:10.340]   I would say every semiconductor company in the world
[00:07:10.340 --> 00:07:12.180]   sucks at software except for Nvidia, right?
[00:07:12.180 --> 00:07:13.020]   So there's software.
[00:07:13.020 --> 00:07:14.500]   There's of course hardware.
[00:07:14.500 --> 00:07:17.060]   People don't realize that Nvidia is actually just much better
[00:07:17.060 --> 00:07:18.580]   at hardware than most people.
[00:07:18.580 --> 00:07:20.700]   They get to the newest technologies first and fastest
[00:07:20.700 --> 00:07:23.540]   because they drive like crazy
[00:07:23.540 --> 00:07:25.860]   towards hitting certain production goals, targets.
[00:07:25.860 --> 00:07:28.060]   They get chips out faster than other people
[00:07:28.060 --> 00:07:31.540]   from thought, design to deployed.
[00:07:31.540 --> 00:07:33.700]   And then the networking side of things, right?
[00:07:33.700 --> 00:07:35.860]   They bought Mellanox and they've driven really hard
[00:07:35.860 --> 00:07:38.580]   with the networking side of things.
[00:07:38.580 --> 00:07:40.460]   So those three things kind of combined
[00:07:40.460 --> 00:07:42.020]   to make a three-headed dragon
[00:07:42.020 --> 00:07:45.100]   that no other semiconductor company can do alone.
[00:07:45.100 --> 00:07:47.180]   - Yeah, I'd call out a piece you did, Dylan,
[00:07:47.180 --> 00:07:50.660]   where you helped everyone visualize the complexity
[00:07:50.660 --> 00:07:54.660]   of one of these modern cutting edge Nvidia deployments
[00:07:54.660 --> 00:07:58.380]   that involves the racks, the memory, the networking,
[00:07:58.380 --> 00:08:01.220]   the size of its scale of the whole thing.
[00:08:01.220 --> 00:08:02.100]   Super helpful.
[00:08:02.100 --> 00:08:05.380]   - I mean, there's this comparison oftentimes
[00:08:05.380 --> 00:08:08.420]   between companies that are truly standalone chip companies.
[00:08:08.420 --> 00:08:09.900]   They're not systems companies.
[00:08:09.900 --> 00:08:13.100]   They're not infrastructure companies and Nvidia.
[00:08:13.100 --> 00:08:15.900]   But I think one of the things that's deeply underappreciated
[00:08:15.900 --> 00:08:19.580]   is the level of competitive moats that Nvidia has.
[00:08:19.580 --> 00:08:23.620]   You know, software is becoming a bigger and bigger component
[00:08:23.620 --> 00:08:25.660]   of squeezing efficiencies and, you know,
[00:08:25.660 --> 00:08:29.020]   total cost of operation out of these infrastructures.
[00:08:29.020 --> 00:08:32.300]   So talk to us a little bit about that schema, you know,
[00:08:32.300 --> 00:08:33.860]   that Bill's referring to,
[00:08:33.860 --> 00:08:37.340]   like there are many different layers of systems architecture
[00:08:37.340 --> 00:08:40.220]   and how that's differentiated from maybe, you know,
[00:08:40.220 --> 00:08:43.220]   a custom ASIC or an AMD.
[00:08:43.220 --> 00:08:46.900]   - Right, so when you look broadly at the GPU, right,
[00:08:46.900 --> 00:08:50.660]   no one buys one chip for running an AI workload, right?
[00:08:50.660 --> 00:08:53.700]   Models have far exceeded that, right?
[00:08:53.700 --> 00:08:57.140]   You look at, you know, today's leading edge models
[00:08:57.140 --> 00:08:59.140]   like GPT-4 was, you know,
[00:08:59.140 --> 00:09:00.900]   over a trillion parameters, right?
[00:09:00.900 --> 00:09:04.420]   A trillion parameters is over a terabyte of memory.
[00:09:04.420 --> 00:09:07.180]   You can't get a chip with that capacity.
[00:09:07.180 --> 00:09:09.340]   A chip can't have enough performance to serve that model,
[00:09:09.340 --> 00:09:11.340]   even if it had enough memory capacity.
[00:09:11.340 --> 00:09:14.780]   So therefore you must tie together many chips together.
[00:09:14.780 --> 00:09:19.020]   And so what's interesting is that Nvidia has seen that
[00:09:19.020 --> 00:09:21.740]   and built an architecture that has many chips networked
[00:09:21.740 --> 00:09:24.100]   together really well called NVLink.
[00:09:24.100 --> 00:09:27.060]   But funnily enough and the thing that many ignore
[00:09:27.060 --> 00:09:30.660]   is that Google actually did this alongside Broadcom,
[00:09:30.660 --> 00:09:33.020]   you know, and they did it before Nvidia, right?
[00:09:33.020 --> 00:09:34.660]   You know, today everyone's freaking out about,
[00:09:34.660 --> 00:09:35.500]   or not freaking out,
[00:09:35.500 --> 00:09:36.780]   but like everyone's like very excited
[00:09:36.780 --> 00:09:38.740]   about Nvidia's Blackwell system, right?
[00:09:38.740 --> 00:09:40.740]   It is a rack of GPUs.
[00:09:40.740 --> 00:09:41.980]   That is the purchased unit, right?
[00:09:41.980 --> 00:09:44.300]   It's not one server, it's not one chip, it's a rack.
[00:09:44.300 --> 00:09:46.060]   And this rack, it weighs three tons
[00:09:46.060 --> 00:09:48.180]   and it has thousands and thousands of cables
[00:09:48.180 --> 00:09:49.820]   and all these things that Jensen will probably tell you,
[00:09:49.820 --> 00:09:52.220]   right, extremely complex.
[00:09:52.220 --> 00:09:55.420]   Interestingly, Google did something very similar in 2018,
[00:09:55.420 --> 00:09:57.140]   right, with the TPU.
[00:09:57.140 --> 00:09:58.380]   Now they couldn't do it alone, right?
[00:09:58.380 --> 00:09:59.860]   They know the software.
[00:09:59.860 --> 00:10:02.140]   They know what the compute element needs to be,
[00:10:02.140 --> 00:10:02.980]   but they didn't know anything.
[00:10:02.980 --> 00:10:05.460]   They can't do a lot of the other difficult things
[00:10:05.460 --> 00:10:08.180]   like package design, like networking.
[00:10:08.180 --> 00:10:10.060]   And so they had to work with other vendors
[00:10:10.060 --> 00:10:11.940]   like Broadcom to do this.
[00:10:11.940 --> 00:10:14.540]   And because Google had such a unified vision
[00:10:14.540 --> 00:10:16.340]   of where AI models were headed,
[00:10:16.340 --> 00:10:18.980]   they actually were able to build this system,
[00:10:18.980 --> 00:10:22.460]   this system architecture that was optimized for AI, right?
[00:10:22.460 --> 00:10:24.260]   Whereas at the time, NVIDIA was like,
[00:10:24.260 --> 00:10:26.580]   "Well, how big do we go?"
[00:10:26.580 --> 00:10:28.140]   I'm sure they could have tried to scale up bigger,
[00:10:28.140 --> 00:10:30.140]   but what they saw as the primary workloads
[00:10:30.140 --> 00:10:32.720]   didn't require scaling to that degree, right?
[00:10:32.720 --> 00:10:34.140]   Now everyone sort of sees this
[00:10:34.140 --> 00:10:35.340]   and they're running towards it,
[00:10:35.340 --> 00:10:37.980]   but NVIDIA has got Blackwell coming now.
[00:10:37.980 --> 00:10:40.180]   Competitors like AMD and others
[00:10:40.180 --> 00:10:42.140]   have to make an acquisition recently
[00:10:42.140 --> 00:10:44.260]   to help them get into the system design, right?
[00:10:44.260 --> 00:10:46.900]   Because building a chip is one thing,
[00:10:46.900 --> 00:10:49.260]   but building many chips that connect together,
[00:10:49.260 --> 00:10:51.660]   cooling them appropriately, networking them together,
[00:10:51.660 --> 00:10:54.100]   making sure that it's reliable at that scale
[00:10:54.100 --> 00:10:55.660]   is a whole host of problems
[00:10:55.660 --> 00:10:59.140]   that semiconductor companies don't have the engineers for.
[00:10:59.140 --> 00:11:02.660]   - Where would you say NVIDIA has been investing the most
[00:11:02.660 --> 00:11:05.600]   in incremental differentiation?
[00:11:05.600 --> 00:11:08.860]   - I would say for differentiating,
[00:11:08.860 --> 00:11:13.860]   NVIDIA has primarily focused on supply chain things,
[00:11:13.860 --> 00:11:15.380]   which might sound like,
[00:11:15.380 --> 00:11:17.180]   "Oh, well like, yeah, they're just like ordering stuff."
[00:11:17.180 --> 00:11:18.020]   No, no, no, no.
[00:11:18.020 --> 00:11:19.940]   You have to work deeply with the supply chain
[00:11:19.940 --> 00:11:22.700]   to build the next generation technology
[00:11:22.700 --> 00:11:24.020]   so that you can bring it to market
[00:11:24.020 --> 00:11:25.740]   before anyone else does, right?
[00:11:25.740 --> 00:11:27.580]   Because if NVIDIA stands still,
[00:11:27.580 --> 00:11:29.740]   they will be eaten up, right?
[00:11:29.740 --> 00:11:32.220]   They're sort of the Andy Grove,
[00:11:32.220 --> 00:11:33.900]   only the paranoid will survive.
[00:11:33.900 --> 00:11:37.100]   Jensen is probably the most paranoid man in the world, right?
[00:11:37.100 --> 00:11:39.260]   He's known for many years,
[00:11:39.260 --> 00:11:41.340]   since before the LLM craze,
[00:11:41.340 --> 00:11:43.900]   all of his biggest customers were building AI chips, right?
[00:11:43.900 --> 00:11:46.660]   Before the LLM craze, his main competitors were like,
[00:11:46.660 --> 00:11:48.500]   "Oh, we should make GPUs."
[00:11:48.500 --> 00:11:50.340]   And yet he stays on top
[00:11:50.340 --> 00:11:54.220]   because he's bringing to market technologies at volume
[00:11:54.220 --> 00:11:56.380]   that no one else can, right?
[00:11:56.380 --> 00:11:58.000]   And so whether it be in networking,
[00:11:58.000 --> 00:11:59.700]   whether it be in optics,
[00:11:59.700 --> 00:12:02.480]   whether it be in water cooling, right?
[00:12:02.480 --> 00:12:05.940]   Whether it be in all sorts of other power delivery,
[00:12:05.940 --> 00:12:08.400]   all these things, he's bringing to market technologies
[00:12:08.400 --> 00:12:09.700]   that no one else has,
[00:12:09.700 --> 00:12:11.580]   and he has to work with the supply chain
[00:12:11.580 --> 00:12:13.360]   and teach those supply chain companies,
[00:12:13.360 --> 00:12:14.380]   and they're helping, obviously,
[00:12:14.380 --> 00:12:15.540]   they have their own capabilities,
[00:12:15.540 --> 00:12:17.740]   to build things that don't exist today.
[00:12:17.740 --> 00:12:20.900]   And NVIDIA is trying to do this on an annual cadence now.
[00:12:20.900 --> 00:12:21.740]   - That's incredible, yeah.
[00:12:21.740 --> 00:12:23.580]   - Blackwell, Blackwell Ultra, Rubin, Rubin Ultra,
[00:12:23.580 --> 00:12:25.180]   they're going so fast,
[00:12:25.180 --> 00:12:27.700]   they're driving so many changes every year.
[00:12:27.700 --> 00:12:28.520]   Of course, people are gonna be like,
[00:12:28.520 --> 00:12:30.580]   "Oh, no, there are some delays in Blackwell."
[00:12:30.580 --> 00:12:31.940]   Yeah, of course, look how hard
[00:12:31.940 --> 00:12:33.540]   you're driving the supply chain.
[00:12:33.540 --> 00:12:35.620]   - Is that part, like how big a part
[00:12:35.620 --> 00:12:37.580]   of the competitive advantage
[00:12:37.580 --> 00:12:40.860]   is the fact that they're now on this annual cadence, right?
[00:12:40.860 --> 00:12:43.100]   Because it seems like by going there,
[00:12:43.100 --> 00:12:46.740]   it almost precludes their competitors from catching up,
[00:12:46.740 --> 00:12:49.580]   because even if you skate to where Blackwell is, right,
[00:12:49.580 --> 00:12:52.540]   you're already on next generation within 12 months.
[00:12:52.540 --> 00:12:55.060]   He's already planning two or three generations ahead
[00:12:55.060 --> 00:12:57.560]   because it's only two to three years ahead.
[00:12:57.560 --> 00:12:59.700]   - Well, the funny thing is a lot of people at NVIDIA
[00:12:59.700 --> 00:13:01.780]   will say Jensen doesn't plan more than a year,
[00:13:01.780 --> 00:13:02.780]   year and a half out,
[00:13:02.780 --> 00:13:05.160]   because they change things
[00:13:05.160 --> 00:13:07.460]   and they'll deploy them out that fast, right?
[00:13:07.460 --> 00:13:10.500]   Every other semiconductor company takes years to deploy,
[00:13:10.500 --> 00:13:12.420]   you know, make architecture changes,
[00:13:12.420 --> 00:13:13.260]   but-
[00:13:13.260 --> 00:13:14.740]   - You said if they stand still there,
[00:13:14.740 --> 00:13:16.940]   they would have competition,
[00:13:16.940 --> 00:13:21.740]   like what would be their area of vulnerability
[00:13:21.740 --> 00:13:24.580]   or what would have to play out in the market
[00:13:24.580 --> 00:13:29.420]   for other alternatives to take more share of the workload?
[00:13:29.420 --> 00:13:33.020]   - Yeah, so the main thing for NVIDIA is, you know,
[00:13:33.020 --> 00:13:35.100]   "Hey, this workload is this big," right?
[00:13:35.100 --> 00:13:38.980]   It's well over a hundred billion dollars of spend
[00:13:38.980 --> 00:13:39.960]   for the biggest customers.
[00:13:39.960 --> 00:13:40.820]   They have multiple customers
[00:13:40.820 --> 00:13:42.820]   that are spending billions of dollars.
[00:13:42.820 --> 00:13:46.260]   I can hire enough engineers to figure out
[00:13:46.260 --> 00:13:48.680]   how to run my model on other hardware, right?
[00:13:48.680 --> 00:13:49.860]   Now, maybe I can't figure out how to train
[00:13:49.860 --> 00:13:50.820]   on other hardware, but I can figure out
[00:13:50.820 --> 00:13:52.980]   how to run it for inference on other hardware.
[00:13:52.980 --> 00:13:55.340]   So NVIDIA's moat in inference
[00:13:55.340 --> 00:13:58.780]   is actually a lot smaller on software,
[00:13:58.780 --> 00:13:59.940]   but it's a lot bigger on,
[00:13:59.940 --> 00:14:01.260]   "Hey, they just have the best hardware."
[00:14:01.260 --> 00:14:02.540]   Now, what does the best hardware mean?
[00:14:02.540 --> 00:14:04.740]   It means capital costs and it means operation costs
[00:14:04.740 --> 00:14:05.980]   and then it means performance, right?
[00:14:05.980 --> 00:14:08.060]   Performance, TCO.
[00:14:08.060 --> 00:14:11.460]   And NVIDIA's whole moat here is,
[00:14:11.460 --> 00:14:14.720]   if they stand still, their performance TCO doesn't grow.
[00:14:14.720 --> 00:14:16.020]   But interestingly, they are, right?
[00:14:16.020 --> 00:14:19.620]   Like with Blackwell, not only is it way, way, way faster,
[00:14:19.620 --> 00:14:20.940]   anywhere from 10 to 15 times
[00:14:20.940 --> 00:14:22.740]   on really large models for inference,
[00:14:22.740 --> 00:14:25.760]   because they've optimized it for very large language models,
[00:14:25.760 --> 00:14:26.920]   they've also decided,
[00:14:26.920 --> 00:14:28.940]   "Hey, we're going to cut our margin too somewhat
[00:14:28.940 --> 00:14:32.340]   because I'm competing with Amazon's, you know,
[00:14:32.340 --> 00:14:35.060]   chip and TPU and AMD and all these things."
[00:14:35.060 --> 00:14:36.720]   They've decided to cut their margin too.
[00:14:36.720 --> 00:14:38.140]   So, between all these things,
[00:14:38.140 --> 00:14:41.820]   they've decided that they need to push performance TCO,
[00:14:41.820 --> 00:14:43.980]   not 2X every two years, right?
[00:14:43.980 --> 00:14:45.620]   You know, Moore's law, right?
[00:14:45.620 --> 00:14:49.960]   They've decided they need to push performance TCO 5X,
[00:14:49.960 --> 00:14:51.220]   maybe every year, right?
[00:14:51.220 --> 00:14:52.380]   At least that's what Blackwell is
[00:14:52.380 --> 00:14:53.580]   and we'll see what Rubin does.
[00:14:53.580 --> 00:14:56.020]   But, you know, 5X plus in a single year
[00:14:56.020 --> 00:14:59.780]   for performance TCO is an insane pace, right?
[00:14:59.780 --> 00:15:01.300]   And then you stack on top, like,
[00:15:01.300 --> 00:15:03.260]   "Hey, AI models are actually getting a lot better
[00:15:03.260 --> 00:15:04.420]   for the same size."
[00:15:04.420 --> 00:15:07.240]   The cost for delivering LLMs is tanking,
[00:15:07.240 --> 00:15:09.440]   which is going to induce demand, right?
[00:15:09.440 --> 00:15:11.840]   - So, just to clarify one thing you said,
[00:15:11.840 --> 00:15:14.160]   or at least restate it to make sure,
[00:15:14.160 --> 00:15:16.720]   I think when you said the software is more important
[00:15:16.720 --> 00:15:20.680]   for training, you meant CUDA is more of a differentiator
[00:15:20.680 --> 00:15:22.680]   on training than it is on inference.
[00:15:22.680 --> 00:15:25.120]   - So, I think a lot of people in the investor community,
[00:15:25.120 --> 00:15:27.560]   you know, call CUDA, which is just like one layer
[00:15:27.560 --> 00:15:28.880]   for all of NVIDIA software.
[00:15:28.880 --> 00:15:30.520]   There's a lot of layers of software,
[00:15:30.520 --> 00:15:32.720]   but for simplicity's sake, you know,
[00:15:32.720 --> 00:15:35.300]   regarding networking or what runs on switches
[00:15:35.300 --> 00:15:37.580]   or what runs on, you know, all sorts of things,
[00:15:37.580 --> 00:15:39.020]   fleet management stuff, all sorts of stuff
[00:15:39.020 --> 00:15:41.180]   that NVIDIA makes that we'll just call CUDA
[00:15:41.180 --> 00:15:43.020]   for simplicity's sake.
[00:15:43.020 --> 00:15:47.180]   But all of this software is stupendously difficult
[00:15:47.180 --> 00:15:48.020]   to replicate.
[00:15:48.020 --> 00:15:51.220]   In fact, no one else has deployments to do that
[00:15:51.220 --> 00:15:52.780]   besides the hyperscalers, right?
[00:15:52.780 --> 00:15:55.020]   And a few thousand GPUs is like a Microsoft
[00:15:55.020 --> 00:15:55.940]   inference cluster, right?
[00:15:55.940 --> 00:15:57.860]   It's not a training cluster.
[00:15:57.860 --> 00:16:01.460]   So, when you talk about, "Hey, what is the difficulty here?"
[00:16:01.460 --> 00:16:05.400]   On training, this is users constantly experimenting, right?
[00:16:05.400 --> 00:16:07.000]   Researchers saying, "Hey, let's try this.
[00:16:07.000 --> 00:16:07.840]   Let's try that.
[00:16:07.840 --> 00:16:08.660]   Let's try this.
[00:16:08.660 --> 00:16:09.500]   Let's try that."
[00:16:09.500 --> 00:16:10.640]   I don't have time to optimize
[00:16:10.640 --> 00:16:12.160]   and hand wring out the performance.
[00:16:12.160 --> 00:16:15.160]   I rely on NVIDIA's performance to be quite good
[00:16:15.160 --> 00:16:19.120]   with existing software stacks or very little effort, right?
[00:16:19.120 --> 00:16:21.000]   But when I go to inference,
[00:16:21.000 --> 00:16:24.240]   Microsoft is deploying five, six models
[00:16:24.240 --> 00:16:26.760]   across how many billions of revenue, right?
[00:16:26.760 --> 00:16:28.200]   So, all of OpenAI's revenue,
[00:16:28.200 --> 00:16:30.080]   plus whatever they have on copilot and all that.
[00:16:30.080 --> 00:16:31.380]   - 10 billion of inference revenue.
[00:16:31.380 --> 00:16:34.020]   - Yeah, so they have $10 billion of revenue here
[00:16:34.020 --> 00:16:35.820]   and they're deploying five models, right?
[00:16:35.820 --> 00:16:39.540]   GPT-4, 4.0, you know, 4.0 mini,
[00:16:39.540 --> 00:16:41.340]   and now, you know, the reasoning model.
[00:16:41.340 --> 00:16:44.100]   Yeah, the reasoning models, 0.1 and yeah.
[00:16:44.100 --> 00:16:46.620]   So, it's like they're deploying very few models
[00:16:46.620 --> 00:16:49.260]   and those change, what, every six months, right?
[00:16:49.260 --> 00:16:51.460]   So, every six months they get a new model
[00:16:51.460 --> 00:16:52.300]   and they deploy that.
[00:16:52.300 --> 00:16:53.380]   So, within that timeframe,
[00:16:53.380 --> 00:16:55.140]   you can hand wring out the performance.
[00:16:55.140 --> 00:16:58.860]   And so, Microsoft has deployed GPT-style models
[00:16:58.860 --> 00:17:02.440]   on other competitors' hardware, such as AMD,
[00:17:02.440 --> 00:17:04.840]   and some of their own, but mostly AMD.
[00:17:04.840 --> 00:17:06.920]   And so, they can wring that out with software
[00:17:06.920 --> 00:17:09.560]   because they can spend hundreds of engineers,
[00:17:09.560 --> 00:17:11.400]   dozens of engineers' hours,
[00:17:11.400 --> 00:17:12.520]   hundreds of engineer hours,
[00:17:12.520 --> 00:17:14.640]   or thousands of engineer hours on working this out
[00:17:14.640 --> 00:17:18.600]   because it's such a unified sort of workload, right?
[00:17:18.600 --> 00:17:20.440]   - I wanna get you to comment on this chart.
[00:17:20.440 --> 00:17:23.320]   This is a chart we showed earlier in the year
[00:17:23.320 --> 00:17:28.000]   that I think was kind of a moment for me with Jensen
[00:17:28.000 --> 00:17:30.640]   when he was in, I think, the Middle East.
[00:17:30.640 --> 00:17:32.680]   And for the first time he said,
[00:17:32.680 --> 00:17:34.840]   not only are we gonna have a trillion dollars
[00:17:34.840 --> 00:17:38.880]   of new AI workloads over the course of the next four years,
[00:17:38.880 --> 00:17:42.200]   he said, but we're also going to have a trillion dollars
[00:17:42.200 --> 00:17:47.040]   of CPU replacement, of data center replacement workloads
[00:17:47.040 --> 00:17:48.420]   over the course of the next four years.
[00:17:48.420 --> 00:17:49.960]   So, that's an effort to model it out.
[00:17:49.960 --> 00:17:53.560]   And I, you know, we referenced it on the pod with him
[00:17:53.560 --> 00:17:55.160]   and he seemed to indicate
[00:17:55.160 --> 00:17:56.800]   that it was directionally correct, right?
[00:17:56.800 --> 00:18:00.400]   That he still believes that it's not just about,
[00:18:00.400 --> 00:18:03.400]   because there's a lot of fuss in the world about,
[00:18:03.400 --> 00:18:05.720]   you know, pre-training and what if pre-training
[00:18:05.720 --> 00:18:07.360]   doesn't continue apace.
[00:18:07.360 --> 00:18:12.080]   And it seemed to suggest that there was a lot of AI workloads
[00:18:12.080 --> 00:18:14.160]   that had nothing to do with pre-training
[00:18:14.160 --> 00:18:15.000]   that they're working on,
[00:18:15.000 --> 00:18:17.880]   but also that they had all of this data center replacement.
[00:18:17.880 --> 00:18:18.700]   Do you buy that?
[00:18:18.700 --> 00:18:20.280]   I've heard a lot of people push back
[00:18:20.280 --> 00:18:22.040]   on the data center replacement and say,
[00:18:22.040 --> 00:18:23.960]   there's no way people are gonna, you know,
[00:18:23.960 --> 00:18:27.720]   rebuild a CPU data center with a bunch of NVIDIA GPUs.
[00:18:27.720 --> 00:18:29.440]   It just doesn't make any sense.
[00:18:29.440 --> 00:18:32.920]   But his argument is that an increasing number
[00:18:32.920 --> 00:18:35.360]   of these applications, even things like Excel
[00:18:35.360 --> 00:18:39.240]   and PowerPoint are becoming machine learning applications
[00:18:39.240 --> 00:18:41.720]   and require accelerated compute.
[00:18:41.720 --> 00:18:43.880]   NVIDIA has been pushing non AI workloads
[00:18:43.880 --> 00:18:46.180]   for accelerators for a very long time, right?
[00:18:46.180 --> 00:18:48.000]   Professional visualization, right?
[00:18:48.000 --> 00:18:49.600]   Pixar uses a ton of GPUs, right?
[00:18:49.600 --> 00:18:51.800]   To make every movie, you know,
[00:18:51.800 --> 00:18:54.200]   all these Siemens engineering applications, right?
[00:18:54.200 --> 00:18:56.800]   All these things do use GPUs, right?
[00:18:56.800 --> 00:18:59.360]   I would say they're a drop in the bucket
[00:18:59.360 --> 00:19:01.960]   compared to, you know, AI.
[00:19:01.960 --> 00:19:03.880]   The other aspect I would say is,
[00:19:03.880 --> 00:19:05.200]   and this is sort of a bit contentious
[00:19:05.200 --> 00:19:06.160]   with your chart, I think,
[00:19:06.160 --> 00:19:09.480]   but IBM mainframes sell more volume
[00:19:09.480 --> 00:19:11.880]   and revenue every single cycle, right?
[00:19:11.880 --> 00:19:14.640]   So, you know, yes, no one in the bay uses mainframes
[00:19:14.640 --> 00:19:18.960]   or talks about mainframes, but they're still growing, right?
[00:19:18.960 --> 00:19:23.320]   And so, like, I would say the same applies to CPUs, right?
[00:19:23.320 --> 00:19:24.760]   To classic workloads.
[00:19:24.760 --> 00:19:26.280]   Just because, you know, AI is here
[00:19:26.280 --> 00:19:28.060]   doesn't mean web serving is like gonna slow down
[00:19:28.060 --> 00:19:29.560]   or databasing is gonna slow down.
[00:19:29.560 --> 00:19:33.680]   Now, what does happen is that line is like this
[00:19:33.680 --> 00:19:35.920]   and the AI line is like this.
[00:19:35.920 --> 00:19:38.000]   And furthermore, right?
[00:19:38.000 --> 00:19:40.080]   Like when you talk about what, you know,
[00:19:40.080 --> 00:19:42.040]   hey, these applications, they're now AI, right?
[00:19:42.040 --> 00:19:44.200]   You know, Excel with Copilot or Word with Copilot,
[00:19:44.200 --> 00:19:45.680]   or whatever, right?
[00:19:45.680 --> 00:19:46.520]   There's, they're gonna be,
[00:19:46.520 --> 00:19:48.320]   they're still gonna have all of those classic operations.
[00:19:48.320 --> 00:19:50.680]   You don't get rid of what you used to have, right?
[00:19:50.680 --> 00:19:52.560]   Southwest doesn't stop booking flights.
[00:19:52.560 --> 00:19:54.440]   They just run AI analytics on top of their flights
[00:19:54.440 --> 00:19:57.200]   to maybe, you know, do pricing better or whatever, right?
[00:19:57.200 --> 00:19:59.240]   So I would say that still happens,
[00:19:59.240 --> 00:20:01.300]   but there is an element of replacement
[00:20:01.300 --> 00:20:03.480]   that is sort of misunderstood, right?
[00:20:03.480 --> 00:20:06.520]   Which is given how much people are deploying,
[00:20:06.520 --> 00:20:10.160]   how tight the supply chains for data centers are.
[00:20:10.160 --> 00:20:11.360]   Data centers take longer,
[00:20:11.360 --> 00:20:14.360]   they're longer time supply chains, unfortunately, right?
[00:20:14.360 --> 00:20:16.440]   Which is why you see things like what Elon's doing.
[00:20:16.440 --> 00:20:18.040]   But when you, when you think about that,
[00:20:18.040 --> 00:20:19.920]   well, how can I get power then, right?
[00:20:19.920 --> 00:20:21.680]   So you can do what CoreWeave is doing
[00:20:21.680 --> 00:20:23.220]   and go to crypto mining companies
[00:20:23.220 --> 00:20:24.360]   and just like clear them out
[00:20:24.360 --> 00:20:26.280]   and put a bunch of GPUs in them, right?
[00:20:26.280 --> 00:20:27.120]   Retrofit the data center,
[00:20:27.120 --> 00:20:30.160]   put GPUs in them like they're doing in Texas.
[00:20:30.160 --> 00:20:32.860]   Or you can do what some of these other folks are doing,
[00:20:32.860 --> 00:20:37.340]   which is, hey, well, my depreciation for CPU servers
[00:20:37.340 --> 00:20:39.240]   has gone from three years to six years
[00:20:39.240 --> 00:20:41.360]   in just a handful of years, why?
[00:20:41.360 --> 00:20:43.480]   Because Intel's progress has been this, right?
[00:20:43.480 --> 00:20:45.280]   So in reality, like the old Intel CPU
[00:20:45.280 --> 00:20:46.120]   is not that much better.
[00:20:46.120 --> 00:20:48.440]   But all of a sudden over the last couple of years,
[00:20:48.440 --> 00:20:50.160]   AMD's burst onto the scene,
[00:20:50.160 --> 00:20:52.360]   ARM CPUs have burst onto the scene,
[00:20:52.360 --> 00:20:54.480]   Intel's started to right the ship.
[00:20:54.480 --> 00:20:57.100]   Now I can upgrade the most,
[00:20:57.100 --> 00:21:00.340]   the plurality of Amazon CPUs in their data centers
[00:21:00.340 --> 00:21:03.600]   are 24 core Intel CPUs from,
[00:21:03.600 --> 00:21:06.280]   that were manufactured from 2015 to 2020.
[00:21:06.280 --> 00:21:08.360]   Same, more or less the same architecture.
[00:21:08.360 --> 00:21:09.700]   There's 24 core CPU.
[00:21:09.700 --> 00:21:14.880]   I can buy 128 or 192 core CPU now today
[00:21:14.880 --> 00:21:17.720]   where each CPU core is higher performance.
[00:21:17.720 --> 00:21:21.600]   And well, if I just replace like six servers with one,
[00:21:21.600 --> 00:21:24.300]   I've basically invented power out of thin air, right?
[00:21:24.300 --> 00:21:25.680]   I mean, like, you know, in effect,
[00:21:25.680 --> 00:21:28.520]   because these old servers, which are six plus years old,
[00:21:28.520 --> 00:21:31.680]   or even, you know, they can just be deprecated and put.
[00:21:31.680 --> 00:21:34.500]   So with CapEx of new servers,
[00:21:34.500 --> 00:21:35.960]   I can replace these old servers.
[00:21:35.960 --> 00:21:37.960]   And now, you know, every time I do that,
[00:21:37.960 --> 00:21:39.760]   I can throw another AI server in there, right?
[00:21:39.760 --> 00:21:42.320]   So this is sort of the, yes, there is some replacement.
[00:21:42.320 --> 00:21:44.160]   I still need more total capacity,
[00:21:44.160 --> 00:21:47.200]   but that total capacity can be served by fewer machines,
[00:21:47.200 --> 00:21:49.560]   maybe, if I buy new ones.
[00:21:49.560 --> 00:21:51.160]   And generally the market is not gonna shrink,
[00:21:51.160 --> 00:21:53.800]   it's still gonna grow, just nowhere close to what AI is.
[00:21:53.800 --> 00:21:56.240]   And AI is causing this behavior of,
[00:21:56.240 --> 00:21:58.320]   I need to replace so I can get power.
[00:21:58.320 --> 00:22:01.400]   - Okay, Bill, this reminds me of a point Satya made
[00:22:01.400 --> 00:22:03.400]   on the pod last week that I've seen replayed
[00:22:03.400 --> 00:22:06.880]   a bunch of times, and I think is fairly misunderstood.
[00:22:06.880 --> 00:22:08.720]   He said last week on the pod
[00:22:08.720 --> 00:22:11.560]   that he was power and data center constrained,
[00:22:11.560 --> 00:22:13.080]   not chip constrained.
[00:22:13.080 --> 00:22:16.560]   What I think it was, was more a assessment
[00:22:16.560 --> 00:22:20.480]   on the real bottleneck, which is data centers and power,
[00:22:20.480 --> 00:22:24.480]   as opposed to GPUs, because GPUs have come online.
[00:22:24.480 --> 00:22:27.960]   And so I think the case you just made,
[00:22:27.960 --> 00:22:29.920]   I think helps to clarify that.
[00:22:29.920 --> 00:22:33.400]   - Well, before we dive into the alternatives to NVIDIA,
[00:22:33.400 --> 00:22:38.400]   I thought we would hit on this pre-training scaling debate
[00:22:38.400 --> 00:22:41.080]   that you wrote about in your last piece, Dylan,
[00:22:41.080 --> 00:22:43.520]   and we've already talked about quite a bit,
[00:22:43.520 --> 00:22:46.440]   but why don't you give us your view
[00:22:46.440 --> 00:22:47.840]   of what's going on there.
[00:22:47.840 --> 00:22:51.040]   I think Ilya was the one, the most credible
[00:22:51.040 --> 00:22:55.440]   AI specialists that brought this up,
[00:22:55.440 --> 00:22:59.040]   and then it got repeated and cross-analyzed quite a bit.
[00:22:59.040 --> 00:23:02.000]   - And Bill, just to repeat what it is,
[00:23:02.000 --> 00:23:06.880]   I think Ilya said, data's the fossil fuel of AI,
[00:23:06.880 --> 00:23:09.160]   that we've consumed all the fossil fuel
[00:23:09.160 --> 00:23:11.840]   because we only have but one internet.
[00:23:11.840 --> 00:23:14.920]   And so the huge gains we got from pre-training
[00:23:14.920 --> 00:23:16.240]   are not gonna be repeated.
[00:23:16.240 --> 00:23:19.840]   - And some experts had predicted that data,
[00:23:19.840 --> 00:23:23.720]   that data would run out a year or two ago.
[00:23:23.720 --> 00:23:27.680]   So it wasn't like out of nowhere
[00:23:27.680 --> 00:23:29.280]   that that argument came to light.
[00:23:29.280 --> 00:23:31.240]   Anyway, let's hear what Dylan has to say.
[00:23:31.240 --> 00:23:34.760]   - So pre-training scaling laws are pretty simple, right?
[00:23:34.760 --> 00:23:37.240]   You get more compute, and then I throw it at a model,
[00:23:37.240 --> 00:23:38.120]   and it'll get better.
[00:23:38.120 --> 00:23:38.960]   Now what is that?
[00:23:38.960 --> 00:23:40.360]   That breaks out into two axes, right?
[00:23:40.360 --> 00:23:42.280]   Data and parameters, right?
[00:23:42.280 --> 00:23:44.320]   The bigger the model, the more data, the better.
[00:23:44.320 --> 00:23:46.120]   And there's actually an optimal ratio, right?
[00:23:46.120 --> 00:23:48.840]   So Google published a paper called Chinchilla,
[00:23:48.840 --> 00:23:53.240]   which says the optimal ratio of data to parameter,
[00:23:53.240 --> 00:23:55.280]   model size, and that's the scaling thing.
[00:23:55.280 --> 00:23:56.720]   Now what happens when the data runs out?
[00:23:56.720 --> 00:23:59.600]   Well, I don't really get much more data,
[00:23:59.600 --> 00:24:01.120]   but I keep growing the size of the model
[00:24:01.120 --> 00:24:03.960]   because my budget for compute keeps growing.
[00:24:03.960 --> 00:24:06.320]   This is a bit not fair, though, right?
[00:24:06.320 --> 00:24:10.800]   We have barely, barely, barely tapped video data, right?
[00:24:10.800 --> 00:24:13.000]   So there is a significant amount of data that's not tapped.
[00:24:13.000 --> 00:24:17.200]   It's just video data is so much more information
[00:24:17.200 --> 00:24:19.160]   than written data, right?
[00:24:19.160 --> 00:24:20.400]   And so therefore, you're throwing that away.
[00:24:20.400 --> 00:24:23.280]   But I think that's part of the,
[00:24:23.280 --> 00:24:24.960]   there's a bit of misunderstanding there.
[00:24:24.960 --> 00:24:28.200]   But more importantly, text is the most efficient domain,
[00:24:28.200 --> 00:24:29.040]   right?
[00:24:29.040 --> 00:24:32.040]   Humans generally, yes, a picture paints a thousand words,
[00:24:32.040 --> 00:24:33.920]   but if I write a hundred words,
[00:24:33.920 --> 00:24:35.760]   I can probably, you can tell, figure out faster, right?
[00:24:35.760 --> 00:24:38.760]   - And the transcripts of most of those videos were already.
[00:24:38.760 --> 00:24:40.440]   - Yeah, the transcripts of many of those videos
[00:24:40.440 --> 00:24:43.040]   are in there already.
[00:24:43.040 --> 00:24:47.040]   But regardless, the data is like a big axis.
[00:24:47.040 --> 00:24:50.240]   Now, the problem is this is only pre-training, right?
[00:24:50.240 --> 00:24:51.920]   Quote, pre.
[00:24:51.920 --> 00:24:54.760]   Training a model is more than just the pre-training, right?
[00:24:54.760 --> 00:24:56.600]   There's many elements of it.
[00:24:56.600 --> 00:24:57.920]   And so people have been talking about,
[00:24:57.920 --> 00:24:59.480]   hey, inference time compute.
[00:24:59.480 --> 00:25:00.480]   Yeah, that's important, right?
[00:25:00.480 --> 00:25:01.640]   You can continue to scale models
[00:25:01.640 --> 00:25:03.240]   if you figure out how to make them think
[00:25:03.240 --> 00:25:05.240]   and recursively be like, oh, that's not right.
[00:25:05.240 --> 00:25:06.080]   Let me think this way.
[00:25:06.080 --> 00:25:06.920]   Oh, that's not right.
[00:25:06.920 --> 00:25:08.560]   That, let me, you know, much like, you know,
[00:25:08.560 --> 00:25:10.240]   you don't hire an intern and say,
[00:25:10.240 --> 00:25:11.840]   hey, what's the answer to X?
[00:25:11.840 --> 00:25:12.800]   Or you don't hire a PhD and say,
[00:25:12.800 --> 00:25:13.800]   hey, what's the answer to X?
[00:25:13.800 --> 00:25:14.920]   You're like, go work on this.
[00:25:14.920 --> 00:25:16.320]   And then they come back and bring something to you.
[00:25:16.320 --> 00:25:18.120]   So inference time compute is important,
[00:25:18.120 --> 00:25:20.040]   but really what's more important is,
[00:25:20.040 --> 00:25:22.400]   as we continue to get more and more compute,
[00:25:22.400 --> 00:25:24.760]   can we improve models if data is run out?
[00:25:24.760 --> 00:25:27.040]   And the answer is you can create data
[00:25:27.040 --> 00:25:29.440]   out of thin air almost, right?
[00:25:29.440 --> 00:25:31.040]   In certain domains, right?
[00:25:31.040 --> 00:25:32.440]   And so this is the whole,
[00:25:32.480 --> 00:25:34.480]   the debate around scaling laws is
[00:25:34.480 --> 00:25:37.440]   how can we create data, right?
[00:25:37.440 --> 00:25:40.040]   And so what is Ilya's company doing?
[00:25:40.040 --> 00:25:40.880]   Most likely.
[00:25:40.880 --> 00:25:42.320]   What is Mira's company doing?
[00:25:42.320 --> 00:25:43.160]   Most likely.
[00:25:43.160 --> 00:25:46.720]   Mira Murady, CTO of OpenAI.
[00:25:46.720 --> 00:25:49.680]   What are, you know, all these companies focused on?
[00:25:49.680 --> 00:25:51.040]   OpenAI.
[00:25:51.040 --> 00:25:52.200]   What are all these companies focused?
[00:25:52.200 --> 00:25:53.040]   They have Noam Brown,
[00:25:53.040 --> 00:25:54.880]   who's like sort of one of the big reasoning people
[00:25:54.880 --> 00:25:56.960]   on roadshows, just going and speaking everywhere,
[00:25:56.960 --> 00:25:57.880]   basically, right?
[00:25:57.880 --> 00:25:59.880]   What are they doing, right?
[00:25:59.880 --> 00:26:02.480]   They're saying, hey, we can still improve these models.
[00:26:02.480 --> 00:26:04.840]   Yes, spending compute at inference time is important,
[00:26:04.840 --> 00:26:06.640]   but what do we do at training time?
[00:26:06.640 --> 00:26:08.000]   'Cause you can't just tell a model,
[00:26:08.000 --> 00:26:09.040]   think more and it gets better.
[00:26:09.040 --> 00:26:10.520]   You have to do a lot at training time.
[00:26:10.520 --> 00:26:13.280]   And so what that is, is I take the model,
[00:26:13.280 --> 00:26:15.880]   I take an objective function I have, right?
[00:26:15.880 --> 00:26:18.600]   What is the square root of 81, right?
[00:26:18.600 --> 00:26:19.720]   Now, if I told you the square,
[00:26:19.720 --> 00:26:21.960]   ask many people what's the square root of 81,
[00:26:21.960 --> 00:26:23.000]   many could answer,
[00:26:23.000 --> 00:26:24.720]   but I bet many people could answer
[00:26:24.720 --> 00:26:25.680]   if they thought about it more,
[00:26:25.680 --> 00:26:27.440]   like almost, you know, a lot more people, right?
[00:26:27.440 --> 00:26:28.840]   Maybe it's a simplistic problem.
[00:26:28.840 --> 00:26:31.280]   But you say, hey, let's have the existing model do that.
[00:26:31.280 --> 00:26:34.200]   Let's have it just run every possible,
[00:26:34.200 --> 00:26:35.040]   you know, not every possible,
[00:26:35.040 --> 00:26:36.960]   many permutations of this.
[00:26:36.960 --> 00:26:38.200]   Start off with say five,
[00:26:38.200 --> 00:26:40.600]   and then anytime it's unsure branch into multiple.
[00:26:40.600 --> 00:26:41.440]   So you start out,
[00:26:41.440 --> 00:26:45.120]   you have hundreds of quote unquote rollouts or trajectories
[00:26:45.120 --> 00:26:46.120]   of generated data.
[00:26:46.120 --> 00:26:48.360]   Most of this is garbage, right?
[00:26:48.360 --> 00:26:49.640]   You prune it down to,
[00:26:49.640 --> 00:26:52.080]   hey, only these paths got to the right answer.
[00:26:52.080 --> 00:26:55.040]   Okay, now I feed that and that is now new training data.
[00:26:55.040 --> 00:26:57.640]   And so I do this with every possible area
[00:26:57.640 --> 00:26:59.640]   where I can do functional verification.
[00:26:59.640 --> 00:27:01.240]   Functional verification, i.e.,
[00:27:01.240 --> 00:27:02.560]   hey, this code compiles.
[00:27:02.560 --> 00:27:05.720]   Hey, this unit test that I have in my code base,
[00:27:05.720 --> 00:27:07.080]   how can I generate the solution?
[00:27:07.080 --> 00:27:08.200]   How can I generate the function?
[00:27:08.200 --> 00:27:10.600]   Okay, now, and you do this over,
[00:27:10.600 --> 00:27:12.160]   and over, and over, and over again,
[00:27:12.160 --> 00:27:14.160]   across many, many, many different domains
[00:27:14.160 --> 00:27:16.320]   where you can functionally prove it's real.
[00:27:16.320 --> 00:27:17.320]   You generate all this data,
[00:27:17.320 --> 00:27:19.360]   you throw away the vast, vast majority of it,
[00:27:19.360 --> 00:27:22.600]   but you now have some chains of thought
[00:27:22.600 --> 00:27:24.160]   that you can train the model on,
[00:27:24.160 --> 00:27:26.720]   which then it will learn how to do that more effectively,
[00:27:26.720 --> 00:27:28.520]   and it generalizes outside of it, right?
[00:27:28.520 --> 00:27:29.880]   And so this is the whole domain.
[00:27:29.880 --> 00:27:32.600]   Now, when you talk about scaling laws,
[00:27:32.600 --> 00:27:34.640]   it's point of diminishing returns
[00:27:34.640 --> 00:27:38.040]   is kind of not proven yet, by the way, right?
[00:27:38.040 --> 00:27:39.440]   Because it's more so,
[00:27:39.440 --> 00:27:41.920]   hey, the scaling laws are a log-log axis.
[00:27:41.920 --> 00:27:44.240]   A log, i.e., it takes 10x more investment
[00:27:44.240 --> 00:27:45.800]   to get the next iteration.
[00:27:45.800 --> 00:27:47.680]   Well, 10x more investment, you know,
[00:27:47.680 --> 00:27:50.840]   going from 30 million to 300 million,
[00:27:50.840 --> 00:27:52.800]   300 million to 3 billion is relevant,
[00:27:52.800 --> 00:27:56.320]   but when Sam wants to go from 3 billion to 30 billion,
[00:27:56.320 --> 00:27:58.680]   it's a little difficult to raise that money, right?
[00:27:58.680 --> 00:28:00.400]   That's why, you know, the most recent rounds
[00:28:00.400 --> 00:28:01.920]   are a bit like, ooh, crap,
[00:28:01.920 --> 00:28:04.520]   we can't spend 30 billion on the next run.
[00:28:04.520 --> 00:28:07.640]   And so the question is, well, that's just one axis.
[00:28:07.640 --> 00:28:09.480]   Where have we gone on synthetic data?
[00:28:09.480 --> 00:28:11.720]   Oh, we're still like very early days, right?
[00:28:11.720 --> 00:28:14.280]   We've spent tens of millions of dollars, maybe,
[00:28:14.280 --> 00:28:15.400]   on synthetic data.
[00:28:15.400 --> 00:28:18.080]   - With synthetic data,
[00:28:18.080 --> 00:28:20.840]   you used a qualifier in certain domains.
[00:28:20.840 --> 00:28:22.560]   When they released O1,
[00:28:22.560 --> 00:28:26.240]   it also had a qualifier like that in certain domains.
[00:28:26.240 --> 00:28:28.760]   I'm just saying those two scaling axis
[00:28:28.760 --> 00:28:30.400]   do better in certain domains
[00:28:30.400 --> 00:28:32.200]   and aren't as applicable in others,
[00:28:32.200 --> 00:28:33.600]   and we have to figure that out.
[00:28:33.600 --> 00:28:35.880]   - Yeah, I think one of the interesting things about AI
[00:28:35.880 --> 00:28:39.960]   is that first in 2022, 2023,
[00:28:39.960 --> 00:28:41.720]   with the release of diffusion models,
[00:28:41.720 --> 00:28:43.040]   with the release of text models, people were like,
[00:28:43.040 --> 00:28:45.000]   oh, wow, artists are the one that are the most,
[00:28:45.000 --> 00:28:47.840]   you know, out of luck, not technical jobs.
[00:28:47.840 --> 00:28:49.720]   Actually, these things suck at technical jobs.
[00:28:49.720 --> 00:28:53.680]   But with this new axis of synthetic data
[00:28:53.680 --> 00:28:55.520]   and test-time compute,
[00:28:55.520 --> 00:28:57.960]   actually, where are the areas where we can teach the model?
[00:28:57.960 --> 00:29:00.360]   We can't teach it what good art is
[00:29:00.360 --> 00:29:02.800]   because we have no way to functionally prove
[00:29:02.800 --> 00:29:03.640]   what good art is.
[00:29:03.640 --> 00:29:06.360]   We can teach it to write really good software.
[00:29:06.360 --> 00:29:09.040]   We can teach it how to do mathematical proofs.
[00:29:09.040 --> 00:29:11.080]   We can teach it how to engineer systems
[00:29:11.080 --> 00:29:13.400]   because there are, while there are trade-offs,
[00:29:13.400 --> 00:29:15.880]   and this is not like, it's not just a one-zero thing,
[00:29:15.880 --> 00:29:17.440]   especially on engineering systems,
[00:29:17.440 --> 00:29:19.280]   this is something you can functionally verify.
[00:29:19.280 --> 00:29:20.360]   Is this works or not?
[00:29:20.360 --> 00:29:21.200]   Or this is correct or not?
[00:29:21.200 --> 00:29:22.040]   - You grade the output
[00:29:22.040 --> 00:29:24.240]   and then the model can iterate more often.
[00:29:24.240 --> 00:29:25.080]   - Exactly.
[00:29:25.080 --> 00:29:26.960]   - Which goes back to the AlphaGo thing
[00:29:26.960 --> 00:29:30.600]   and why that was a sandbox that could allow
[00:29:30.600 --> 00:29:35.320]   for novel moves and plays
[00:29:35.320 --> 00:29:39.280]   'cause you could traverse it and run synthetically.
[00:29:39.280 --> 00:29:42.000]   You could just let it create and create and create.
[00:29:42.000 --> 00:29:46.200]   - Putting on my investor hat, public investor hat here,
[00:29:46.200 --> 00:29:48.800]   there is a lot of tension in the world
[00:29:48.800 --> 00:29:53.120]   over NVIDIA as we look forward at 2025
[00:29:53.120 --> 00:29:56.520]   and this question of pre-training, right?
[00:29:56.520 --> 00:29:59.440]   And if in fact, we've seen,
[00:29:59.440 --> 00:30:01.840]   we plucked 90% of the low-hanging fruit
[00:30:01.840 --> 00:30:03.240]   that comes from pre-training,
[00:30:03.240 --> 00:30:05.360]   then do people really need to buy bigger clusters?
[00:30:05.360 --> 00:30:07.160]   And I think there's a view in the world,
[00:30:07.160 --> 00:30:09.480]   particularly post Ilya's comments,
[00:30:09.480 --> 00:30:13.520]   that, no, the 90% benefit of pre-training is gone.
[00:30:13.520 --> 00:30:16.920]   But then I look at the comments out of Hock Tan this week,
[00:30:18.400 --> 00:30:19.480]   during their earnings call,
[00:30:19.480 --> 00:30:21.360]   that all the hyperscalers are building
[00:30:21.360 --> 00:30:24.280]   these million XPU clusters.
[00:30:24.280 --> 00:30:27.560]   I look at the commentary out of X.AI
[00:30:27.560 --> 00:30:31.960]   that they're gonna build 200 or 300,000 GPU clusters,
[00:30:31.960 --> 00:30:34.880]   Meta reportedly building much bigger clusters,
[00:30:34.880 --> 00:30:37.000]   Microsoft building much bigger clusters.
[00:30:37.000 --> 00:30:39.440]   How do you square those two things, right?
[00:30:39.440 --> 00:30:42.080]   If everybody's right and pre-training's dead,
[00:30:42.080 --> 00:30:44.920]   then why is everybody building much bigger clusters?
[00:30:44.920 --> 00:30:48.000]   - So the scaling, right, goes back to
[00:30:48.000 --> 00:30:49.240]   what's the optimal ratio?
[00:30:49.240 --> 00:30:50.880]   What's the, how do we continue to grow, right?
[00:30:50.880 --> 00:30:52.720]   Just blindly growing parameter count
[00:30:52.720 --> 00:30:54.040]   when we don't have any more data,
[00:30:54.040 --> 00:30:55.560]   or the data is very hard to get at,
[00:30:55.560 --> 00:30:57.960]   i.e. because it's video data,
[00:30:57.960 --> 00:30:59.720]   wouldn't give you so many gains.
[00:30:59.720 --> 00:31:01.720]   And then there's also the access if it's a log chart, right?
[00:31:01.720 --> 00:31:04.000]   You need 10X more to get the next job, right?
[00:31:04.000 --> 00:31:05.760]   So when you look at both of those,
[00:31:05.760 --> 00:31:07.880]   oh, crap, like I need to invest 10X more.
[00:31:07.880 --> 00:31:09.480]   And I might not get the full gain
[00:31:09.480 --> 00:31:10.480]   because I don't have the data.
[00:31:10.480 --> 00:31:13.080]   But the data generation side,
[00:31:13.080 --> 00:31:15.240]   we are so early days with this, right?
[00:31:15.240 --> 00:31:18.760]   - So the point is I'm still gonna squeak out enough gain
[00:31:18.760 --> 00:31:20.840]   that it's a positive return,
[00:31:20.840 --> 00:31:24.480]   particularly when you look at the competitive dynamic,
[00:31:24.480 --> 00:31:26.760]   you know, our models versus our competitor models.
[00:31:26.760 --> 00:31:28.800]   So it's a rational decision
[00:31:28.800 --> 00:31:32.040]   to go from 100,000 to 200,000 or 300,000,
[00:31:32.040 --> 00:31:35.040]   even if, you know, the kind of big one-time gain
[00:31:35.040 --> 00:31:36.800]   in pre-training is behind us.
[00:31:36.800 --> 00:31:38.560]   - Or rather it's exponentially more,
[00:31:38.560 --> 00:31:40.600]   it's logarithmically more expensive to do that gain.
[00:31:40.600 --> 00:31:41.440]   - Correct. - Right?
[00:31:41.440 --> 00:31:42.280]   So it's still there.
[00:31:42.280 --> 00:31:43.120]   Like the gain is still there,
[00:31:43.120 --> 00:31:46.000]   but like the sort of whole, like Orion has failed
[00:31:46.000 --> 00:31:48.880]   sort of narrative around OpenAI's model
[00:31:48.880 --> 00:31:50.280]   and they didn't release Orion, right?
[00:31:50.280 --> 00:31:53.360]   They released O1, which is sort of a different axis.
[00:31:53.360 --> 00:31:55.680]   It's partially because, hey, this is, you know,
[00:31:55.680 --> 00:31:57.040]   because of these like data issues,
[00:31:57.040 --> 00:31:59.920]   but it's partially because they did not scale 10X, right?
[00:31:59.920 --> 00:32:03.720]   'Cause scaling 10X from four to this is actually was like-
[00:32:03.720 --> 00:32:05.520]   - I think this is Gavin's point, right?
[00:32:05.520 --> 00:32:07.760]   - Well, I would also, let's go to Gavin a second.
[00:32:07.760 --> 00:32:11.120]   One of the reasons this became controversial, I think,
[00:32:11.120 --> 00:32:16.120]   is Dario and Sam had prior to this moment,
[00:32:16.120 --> 00:32:22.800]   at least the way I heard them,
[00:32:22.800 --> 00:32:25.400]   made it sound like they were just gonna build
[00:32:25.400 --> 00:32:29.240]   the next biggest thing and get the same amount of gain.
[00:32:29.240 --> 00:32:31.320]   They had left that impression.
[00:32:31.320 --> 00:32:33.760]   And so we get to this place, as you described it,
[00:32:33.760 --> 00:32:35.320]   it's not quite like that.
[00:32:35.320 --> 00:32:36.880]   And then people go, "Oh, what does that mean?"
[00:32:36.880 --> 00:32:38.600]   Like it causes them to raise their head up.
[00:32:38.600 --> 00:32:42.640]   - I think they have never said the chinchilla scaling laws
[00:32:42.640 --> 00:32:45.560]   were what delivers us, you know, AGI, right?
[00:32:45.560 --> 00:32:46.440]   They've had scaling.
[00:32:46.440 --> 00:32:48.840]   Scaling is, you need a lot of compute.
[00:32:48.840 --> 00:32:49.760]   And guess what?
[00:32:49.760 --> 00:32:53.080]   If you have to generate a ton of data
[00:32:53.080 --> 00:32:54.640]   and throw away most of it because,
[00:32:54.640 --> 00:32:56.680]   hey, only some of the paths are good,
[00:32:56.680 --> 00:32:59.800]   you're spending a ton of compute at train time, right?
[00:32:59.800 --> 00:33:01.840]   And this is sort of the axis that is like,
[00:33:01.840 --> 00:33:04.520]   we may actually see models improve faster
[00:33:04.520 --> 00:33:06.120]   in the next six months to a year
[00:33:06.120 --> 00:33:07.880]   than we saw them improve in the last year.
[00:33:07.880 --> 00:33:11.960]   Because there's this new axis of synthetic data generation
[00:33:11.960 --> 00:33:14.640]   and the amount of compute we can throw at it is,
[00:33:14.640 --> 00:33:17.200]   we're still right here in the scaling law, right?
[00:33:17.200 --> 00:33:18.040]   We're not here.
[00:33:18.040 --> 00:33:20.400]   We haven't pushed it to billions of dollars
[00:33:20.400 --> 00:33:22.680]   spent on synthetic data generation,
[00:33:22.680 --> 00:33:24.600]   functional verification, reasoning training.
[00:33:24.600 --> 00:33:27.240]   We've only spent millions, tens of millions of dollars,
[00:33:27.240 --> 00:33:28.080]   right?
[00:33:28.080 --> 00:33:29.040]   So what happens when we scale that up?
[00:33:29.040 --> 00:33:31.720]   So there is a new axis of spending money.
[00:33:31.720 --> 00:33:33.560]   And then there's, of course, test time compute as well,
[00:33:33.560 --> 00:33:36.000]   i.e. spending time at inference to get better and better.
[00:33:36.000 --> 00:33:37.440]   So it's possible.
[00:33:37.440 --> 00:33:39.760]   And in fact, many people at these labs believe
[00:33:39.760 --> 00:33:40.800]   that the next year of gains
[00:33:40.800 --> 00:33:42.880]   or the next six months of gains will be faster
[00:33:42.880 --> 00:33:44.960]   because they've unlocked this new axis
[00:33:44.960 --> 00:33:47.520]   through a new methodology, right?
[00:33:47.520 --> 00:33:49.160]   And it's still scale, right?
[00:33:49.160 --> 00:33:51.880]   Because this requires stupendous amounts of compute.
[00:33:51.880 --> 00:33:54.920]   You're generating so much more data than exist on the web,
[00:33:54.920 --> 00:33:56.240]   and then you're throwing away most of it,
[00:33:56.240 --> 00:33:57.920]   but you're generating so much data
[00:33:57.920 --> 00:34:00.760]   that you have to run the model constantly, right?
[00:34:00.760 --> 00:34:05.720]   - What domains do you think are most applicable
[00:34:05.720 --> 00:34:06.840]   with this approach?
[00:34:06.840 --> 00:34:11.680]   Like where were synthetic data be most effective?
[00:34:11.680 --> 00:34:16.200]   And maybe you could do both a pro and a con,
[00:34:16.200 --> 00:34:18.560]   like a scenario where it's gonna be really good
[00:34:18.560 --> 00:34:20.240]   and one where it wouldn't work as well.
[00:34:20.240 --> 00:34:23.280]   - Yeah, so I think that goes back to the point around
[00:34:23.280 --> 00:34:26.160]   what can we functionally verify is true or not?
[00:34:26.160 --> 00:34:28.480]   What can I grade and it's not subjective?
[00:34:28.480 --> 00:34:31.360]   What class can you take in college
[00:34:31.360 --> 00:34:33.520]   and you get the card, you get the thing back
[00:34:33.520 --> 00:34:34.920]   and you're like, "Oh, this is BS."
[00:34:34.920 --> 00:34:36.560]   Or you're like, "Dang, I messed that up," right?
[00:34:36.560 --> 00:34:37.400]   There's certain classes where you can-
[00:34:37.400 --> 00:34:42.240]   - There's like a determinism of grading the output.
[00:34:42.240 --> 00:34:43.080]   - Right, exactly.
[00:34:43.080 --> 00:34:46.400]   So if it can be functionally verified, amazing.
[00:34:46.400 --> 00:34:47.720]   If it has to be judged, right?
[00:34:47.720 --> 00:34:49.880]   So there's sort of two ways to judge an output, right?
[00:34:49.880 --> 00:34:52.320]   There is, without using humans, right?
[00:34:52.320 --> 00:34:54.640]   This is sort of the whole scale AI, right?
[00:34:54.640 --> 00:34:56.240]   What were they initially doing?
[00:34:56.240 --> 00:34:59.000]   They were using a ton of manpower
[00:34:59.000 --> 00:35:01.000]   to create good data, right?
[00:35:01.000 --> 00:35:01.840]   Label data.
[00:35:01.880 --> 00:35:05.280]   But now, humans don't scale for this level of data, right?
[00:35:05.280 --> 00:35:06.640]   Humans post on the internet every day
[00:35:06.640 --> 00:35:08.000]   and we've already tapped that out, right?
[00:35:08.000 --> 00:35:09.600]   Kind of more or less on a text domain.
[00:35:09.600 --> 00:35:11.360]   - So what are domains that work?
[00:35:11.360 --> 00:35:14.840]   - So these are domains where, hey, in Google,
[00:35:14.840 --> 00:35:17.920]   when they push data to any of their services,
[00:35:17.920 --> 00:35:19.360]   they have tons of unit tests.
[00:35:19.360 --> 00:35:21.360]   These unit tests make sure everything's working.
[00:35:21.360 --> 00:35:23.520]   Well, why can't I have the LLM
[00:35:23.520 --> 00:35:25.160]   just generate a ton of outputs
[00:35:25.160 --> 00:35:27.520]   and then use those unit tests to grade those outputs, right?
[00:35:27.520 --> 00:35:28.880]   Because it's pass or fail, right?
[00:35:28.880 --> 00:35:30.040]   It's not.
[00:35:30.040 --> 00:35:31.920]   And then you can also grade these outputs in other ways.
[00:35:31.920 --> 00:35:33.120]   Like, oh, it takes this long to run
[00:35:33.120 --> 00:35:33.960]   versus this long to run.
[00:35:33.960 --> 00:35:34.960]   So then you have various,
[00:35:34.960 --> 00:35:37.960]   there's other areas such as like, hey, image generation.
[00:35:37.960 --> 00:35:39.160]   Well, actually it's harder to say
[00:35:39.160 --> 00:35:42.720]   which image looks more beautiful to you versus me.
[00:35:42.720 --> 00:35:45.880]   I might like some sunsets and flowers
[00:35:45.880 --> 00:35:47.280]   and you might like the beach, right?
[00:35:47.280 --> 00:35:49.600]   You can't really argue what is good there.
[00:35:49.600 --> 00:35:51.480]   So there's no functional verification.
[00:35:51.480 --> 00:35:53.880]   There is only subjective, right?
[00:35:53.880 --> 00:35:55.840]   So the objective nature of this is where,
[00:35:55.840 --> 00:35:57.960]   so where do we have objective grading, right?
[00:35:57.960 --> 00:35:58.800]   We have that in code.
[00:35:58.800 --> 00:35:59.640]   We have that in math.
[00:35:59.640 --> 00:36:01.040]   We have that in engineering.
[00:36:01.040 --> 00:36:04.400]   And while these can be complex, like, hey,
[00:36:04.400 --> 00:36:06.400]   engineering is not just, this is the best solution.
[00:36:06.400 --> 00:36:08.400]   It's, hey, given all the resources we've had
[00:36:08.400 --> 00:36:09.360]   and given all these trade-offs,
[00:36:09.360 --> 00:36:11.040]   we think this is the best trade-off, right?
[00:36:11.040 --> 00:36:13.080]   That's usually what engineering ends up being.
[00:36:13.080 --> 00:36:16.920]   Well, I can still look at all these axes, right?
[00:36:16.920 --> 00:36:19.560]   Whereas in subjective things, right?
[00:36:19.560 --> 00:36:22.000]   Like, hey, what's the best way to write this email
[00:36:22.000 --> 00:36:24.080]   or what's the best way to negotiate with this person?
[00:36:24.080 --> 00:36:25.520]   That's difficult, right?
[00:36:25.520 --> 00:36:26.920]   That's not something that is objective.
[00:36:26.920 --> 00:36:28.480]   - What are you hearing from the hyperscalers?
[00:36:28.480 --> 00:36:29.680]   I mean, they're all out there saying,
[00:36:29.680 --> 00:36:31.120]   our CapEx is going up next year.
[00:36:31.120 --> 00:36:32.680]   We're building larger clusters.
[00:36:32.680 --> 00:36:35.320]   You know, is that in fact happening?
[00:36:35.320 --> 00:36:37.040]   Like, what's happening out there?
[00:36:37.040 --> 00:36:38.800]   - Yeah, so I think when you look
[00:36:38.800 --> 00:36:40.520]   at the streets estimates for CapEx,
[00:36:40.520 --> 00:36:42.720]   they're all far too low, you know,
[00:36:42.720 --> 00:36:45.080]   based on a few factors, right?
[00:36:45.080 --> 00:36:46.960]   So when we track every data center in the world
[00:36:46.960 --> 00:36:51.120]   and it's insane how much, especially Microsoft
[00:36:51.120 --> 00:36:54.800]   and now Meta and Amazon and, you know, and many others,
[00:36:54.800 --> 00:36:57.640]   right, but those guys specifically are spending
[00:36:57.640 --> 00:36:58.680]   on data center capacity.
[00:36:58.680 --> 00:36:59.960]   And as that power comes online,
[00:36:59.960 --> 00:37:00.920]   which you can track pretty easily
[00:37:00.920 --> 00:37:03.840]   if you look at all of the different regulatory filings
[00:37:03.840 --> 00:37:06.040]   and use satellite imagery, all these things that we do,
[00:37:06.040 --> 00:37:07.720]   you can see that, hey, they're going to have
[00:37:07.720 --> 00:37:09.840]   this much data center capacity, right?
[00:37:09.840 --> 00:37:10.680]   - Right.
[00:37:10.680 --> 00:37:12.760]   So it's accelerating.
[00:37:12.760 --> 00:37:14.480]   - What are you going to fill in there, right?
[00:37:14.480 --> 00:37:17.080]   It turns out you have to fill, to fill it up, you know,
[00:37:17.080 --> 00:37:18.640]   you can make some estimates around how much power
[00:37:18.640 --> 00:37:21.240]   is each GPU, all in, everything, right?
[00:37:21.240 --> 00:37:22.960]   Satya said he's going to slow down that a little bit,
[00:37:22.960 --> 00:37:25.360]   but they've signed deals for next year rentals, right?
[00:37:25.360 --> 00:37:27.040]   For some, in some of these cases, right?
[00:37:27.040 --> 00:37:29.440]   - And it's part of the reason he said is he expects
[00:37:29.440 --> 00:37:31.160]   his cloud revenue in the first half of next year
[00:37:31.160 --> 00:37:32.680]   to accelerate, because he said we're going to have
[00:37:32.680 --> 00:37:34.160]   a lot more data center capacity
[00:37:34.160 --> 00:37:36.000]   and we're currently capacity constrained.
[00:37:36.000 --> 00:37:37.960]   So, you know, what they're, you know, like again,
[00:37:37.960 --> 00:37:39.480]   going back to the, is scaling dead?
[00:37:39.480 --> 00:37:40.800]   Then why is Mark Zuckerberg building
[00:37:40.800 --> 00:37:42.520]   a two gigawatt data center in Louisiana?
[00:37:42.520 --> 00:37:43.360]   - Right.
[00:37:43.360 --> 00:37:45.360]   - Why is, why is Amazon building
[00:37:45.360 --> 00:37:46.560]   these multi gigawatt data centers?
[00:37:46.560 --> 00:37:48.280]   Why is Google, why is Microsoft building
[00:37:48.280 --> 00:37:49.480]   multiple gigawatt data centers,
[00:37:49.480 --> 00:37:53.280]   plus buying billions and billions of dollars of fiber
[00:37:53.280 --> 00:37:54.760]   to connect them together because they think,
[00:37:54.760 --> 00:37:56.520]   hey, I need to win on scale.
[00:37:56.520 --> 00:37:58.240]   So let me just connect all the data centers together
[00:37:58.240 --> 00:37:59.240]   with super high bandwidth.
[00:37:59.240 --> 00:38:01.680]   So then I can make them act like one data center, right?
[00:38:01.680 --> 00:38:02.520]   - Right.
[00:38:02.520 --> 00:38:03.360]   - Towards one job, right?
[00:38:03.360 --> 00:38:05.040]   So this is, this, this whole like,
[00:38:05.040 --> 00:38:08.080]   is scaling over narrative falls on its face
[00:38:08.080 --> 00:38:10.480]   when you see what the people who know the best
[00:38:10.480 --> 00:38:12.400]   are spending on, right?
[00:38:12.400 --> 00:38:13.560]   - You talked a lot at the beginning
[00:38:13.560 --> 00:38:15.360]   about NVIDIA's differentiation
[00:38:15.360 --> 00:38:17.960]   around these large coherent clusters
[00:38:17.960 --> 00:38:20.440]   that are used in pre-training.
[00:38:20.440 --> 00:38:23.640]   Can you see anything, like, I guess one,
[00:38:23.640 --> 00:38:25.840]   someone might be super bullish on inference
[00:38:25.840 --> 00:38:28.040]   and keep building out a data center,
[00:38:28.040 --> 00:38:31.600]   but they might have thought they were gonna go
[00:38:31.600 --> 00:38:34.840]   from 100,000 nodes to 200 to 400
[00:38:34.840 --> 00:38:37.040]   and might not be doing that right now
[00:38:37.040 --> 00:38:39.560]   if this pre-training thing is real.
[00:38:39.560 --> 00:38:41.840]   Are you seeing anything that gives you
[00:38:41.840 --> 00:38:44.240]   any visibility on that dimension?
[00:38:44.240 --> 00:38:47.160]   - So when you think about training a neural network, right,
[00:38:47.160 --> 00:38:49.560]   it is doing a forwards pass and a backwards pass, right?
[00:38:49.560 --> 00:38:52.240]   Forwards pass is generating the data, basically,
[00:38:52.240 --> 00:38:54.840]   and it's half as much compute as the backwards pass,
[00:38:54.840 --> 00:38:56.920]   which is updating the weights.
[00:38:56.920 --> 00:38:58.520]   When you look at this new paradigm
[00:38:58.520 --> 00:39:00.640]   of synthetic data generation,
[00:39:00.640 --> 00:39:03.400]   grading the outputs, and then training the model,
[00:39:03.400 --> 00:39:05.960]   you are going to do many, many, many forward passes
[00:39:05.960 --> 00:39:06.920]   before you do a backwards pass.
[00:39:06.920 --> 00:39:07.920]   What is serving a user?
[00:39:07.920 --> 00:39:09.600]   That's also just a forwards pass.
[00:39:09.600 --> 00:39:13.240]   So it turns out that there is a lot of inference
[00:39:13.240 --> 00:39:14.440]   in training, right?
[00:39:14.440 --> 00:39:16.560]   In fact, there's more inference in training
[00:39:16.560 --> 00:39:18.480]   than there is updating the model weights
[00:39:18.480 --> 00:39:21.800]   because you have to generate hundreds of possibilities
[00:39:21.800 --> 00:39:24.200]   and then, oh, you only train on a couple of them, right?
[00:39:24.200 --> 00:39:27.560]   So there is, that paradigm is very relevant.
[00:39:27.560 --> 00:39:29.400]   The other paradigm I would say that is very relevant
[00:39:29.400 --> 00:39:33.760]   is when you're training a model,
[00:39:33.760 --> 00:39:36.560]   do you necessarily need to be co-located
[00:39:36.560 --> 00:39:38.880]   for every single aspect of it, right?
[00:39:38.880 --> 00:39:40.560]   And this is-- - And what's the answer?
[00:39:40.560 --> 00:39:42.680]   - The answer is, depends on what you're doing.
[00:39:42.680 --> 00:39:44.600]   If you're in the pre-training paradigm,
[00:39:44.600 --> 00:39:46.000]   then maybe you don't, yeah,
[00:39:46.000 --> 00:39:48.160]   you need it to be co-located, right?
[00:39:48.160 --> 00:39:49.960]   You need everything to be in one spot.
[00:39:49.960 --> 00:39:52.640]   Yeah, why did Microsoft in Q1 and Q2
[00:39:52.640 --> 00:39:54.760]   sign these massive fiber deals, right?
[00:39:54.760 --> 00:39:57.920]   And why are they building multiple similar-sized
[00:39:57.920 --> 00:40:01.080]   data centers in Wisconsin and Atlanta and Texas
[00:40:01.080 --> 00:40:02.920]   and so on and so forth, right, and Arizona?
[00:40:02.920 --> 00:40:03.920]   Why are they doing that?
[00:40:03.920 --> 00:40:06.400]   Because they already see the research is there
[00:40:06.400 --> 00:40:08.920]   for being able to split the workload more appropriately,
[00:40:08.920 --> 00:40:11.680]   which is, hey, this data center, it's not serving users.
[00:40:11.680 --> 00:40:12.520]   It's running inference.
[00:40:12.520 --> 00:40:13.840]   It's just running inference
[00:40:13.840 --> 00:40:15.720]   and then throwing away most of the output
[00:40:15.720 --> 00:40:18.040]   because some of the output is good
[00:40:18.040 --> 00:40:19.000]   because I'm grading it, right?
[00:40:19.000 --> 00:40:20.320]   And it's doing, they're doing this
[00:40:20.320 --> 00:40:22.200]   while they're also updating the model in other areas.
[00:40:22.200 --> 00:40:25.640]   So the whole paradigm of training,
[00:40:25.640 --> 00:40:27.640]   pre-training is not slowing down.
[00:40:27.640 --> 00:40:30.480]   It's just, it's logarithmically more expensive
[00:40:30.480 --> 00:40:32.240]   for each generation, for each incremental improvement.
[00:40:32.240 --> 00:40:33.840]   - So people are finding other ways to--
[00:40:33.840 --> 00:40:36.840]   - But there's other ways to not just continue this,
[00:40:36.840 --> 00:40:40.480]   but hey, I don't need a logarithmic increase in spend
[00:40:40.480 --> 00:40:42.440]   to get the next generation of improvement.
[00:40:42.440 --> 00:40:46.560]   In fact, through this reasoning, training, and inference,
[00:40:46.560 --> 00:40:48.960]   I can get that logarithmic improvement in the model
[00:40:48.960 --> 00:40:50.880]   without ever spending that.
[00:40:50.880 --> 00:40:52.640]   Now I'm gonna do both, right?
[00:40:52.640 --> 00:40:55.280]   Because this is, because each model jump
[00:40:55.280 --> 00:40:57.080]   has unlocked huge value, right?
[00:40:57.080 --> 00:40:59.840]   - I mean, the, you know, the thing that I think
[00:40:59.840 --> 00:41:02.440]   so interesting, you know, I hear Kramer on CNBC
[00:41:02.440 --> 00:41:04.760]   this morning, you know, and they're talking about,
[00:41:04.760 --> 00:41:06.840]   is this Cisco from 2000?
[00:41:06.840 --> 00:41:10.200]   I was in Omaha, Bill, Sunday night for dinner.
[00:41:10.200 --> 00:41:13.040]   You know, they're obviously big investors and utilities
[00:41:13.040 --> 00:41:14.640]   and they're watching what's going on
[00:41:14.640 --> 00:41:15.880]   in the data center build out.
[00:41:15.880 --> 00:41:18.400]   And they're like, is this Cisco from 2000?
[00:41:18.400 --> 00:41:22.400]   So I had my team pull up a chart for Cisco, you know, 2000,
[00:41:22.400 --> 00:41:24.120]   and we'll show it on the pod.
[00:41:24.120 --> 00:41:29.000]   But, you know, they peaked at like 120 PE, right?
[00:41:29.000 --> 00:41:31.760]   And, you know, if you look at the fall off
[00:41:31.760 --> 00:41:34.640]   that occurred in revenue and in EBITDA, you know,
[00:41:34.640 --> 00:41:36.640]   and then it adds 70% compression
[00:41:36.640 --> 00:41:39.000]   in the price to earnings multiple, right?
[00:41:39.000 --> 00:41:41.320]   So the price to earnings multiple went from 120
[00:41:41.320 --> 00:41:43.480]   down to something closer to 30.
[00:41:43.480 --> 00:41:47.120]   And so I said to, you know, in this dinner conversation,
[00:41:47.120 --> 00:41:51.600]   I said, well, NVIDIA's, you know, PE today is 30.
[00:41:51.600 --> 00:41:53.400]   It's not 120, right?
[00:41:53.400 --> 00:41:56.360]   So you would have to think that there would be 70% PE
[00:41:56.360 --> 00:41:58.600]   compression from here or that their revenue
[00:41:58.600 --> 00:42:01.040]   was gonna fall by 70% or that their earnings
[00:42:01.040 --> 00:42:03.120]   were gonna fall by 70%, you know,
[00:42:03.120 --> 00:42:05.280]   in order to have a Cisco-like event,
[00:42:05.280 --> 00:42:07.200]   we all have post-traumatic stress about that.
[00:42:07.200 --> 00:42:09.560]   I mean, hell, you know, I lived through that too.
[00:42:09.560 --> 00:42:11.200]   Nobody wants to repeat that.
[00:42:11.200 --> 00:42:12.840]   But when people make that comparison,
[00:42:12.840 --> 00:42:15.640]   it strikes me as uninformed, right?
[00:42:15.640 --> 00:42:17.800]   It's not to say that there can't be a pullback,
[00:42:17.800 --> 00:42:19.320]   but given what you just told us
[00:42:19.320 --> 00:42:21.120]   about the build-out next year,
[00:42:21.120 --> 00:42:23.960]   given what you told us about scaling laws continuing,
[00:42:23.960 --> 00:42:27.520]   you know, what do you think when you hear, you know,
[00:42:27.520 --> 00:42:30.840]   the Cisco comparison when people are talking about NVIDIA?
[00:42:30.840 --> 00:42:33.720]   - Yeah, so I think there's a couple of things
[00:42:33.720 --> 00:42:34.680]   that are not fair, right?
[00:42:34.680 --> 00:42:37.240]   Cisco's revenue, a lot of it was funded
[00:42:37.240 --> 00:42:41.040]   through private/credit investments
[00:42:41.040 --> 00:42:44.040]   into building out telecom infrastructure, right?
[00:42:44.040 --> 00:42:46.760]   When we look at NVIDIA's revenue sources,
[00:42:46.760 --> 00:42:49.800]   very little of it is private/credit, right?
[00:42:49.800 --> 00:42:51.840]   And in some cases, yes, it's private/credit,
[00:42:51.840 --> 00:42:53.520]   like CoreWeave, right?
[00:42:53.520 --> 00:42:55.360]   But CoreWeave is just backstopped by Microsoft.
[00:42:55.360 --> 00:42:57.480]   There is significant amounts of, like, difference
[00:42:57.480 --> 00:42:59.680]   in, like, what is the source of the capital, right?
[00:42:59.680 --> 00:43:02.160]   The other thing is, at the peak of the dot-com,
[00:43:02.160 --> 00:43:04.640]   you know, especially once you inflation-adjust it,
[00:43:04.640 --> 00:43:08.240]   the private capital entering the space
[00:43:08.240 --> 00:43:11.720]   was much larger than it is today, right?
[00:43:11.720 --> 00:43:14.000]   As much as people say the venture markets are going crazy,
[00:43:14.000 --> 00:43:16.400]   throwing these huge valuations at, you know,
[00:43:16.400 --> 00:43:18.560]   all these companies, and we were just talking about this
[00:43:18.560 --> 00:43:21.960]   before the show, but, like, hey, the venture markets,
[00:43:21.960 --> 00:43:24.280]   the private markets, have not even tapped in, right?
[00:43:24.280 --> 00:43:25.120]   Guess what?
[00:43:25.120 --> 00:43:27.080]   Private market money, like in the Middle East,
[00:43:27.080 --> 00:43:29.600]   in these sovereign wealth funds, it's not coming in yet.
[00:43:29.600 --> 00:43:31.160]   Has barely come in, right?
[00:43:31.160 --> 00:43:33.560]   Why wouldn't there be a lot more spend
[00:43:33.560 --> 00:43:35.280]   from them as well, right?
[00:43:35.280 --> 00:43:37.800]   And so there is a significant amount of,
[00:43:37.800 --> 00:43:41.000]   the difference of capital, the source is positive cash flows
[00:43:41.000 --> 00:43:43.120]   of the most profitable companies that have ever lived
[00:43:43.120 --> 00:43:44.880]   or ever existed in humanity
[00:43:44.880 --> 00:43:47.920]   versus credit speculatively spent, right?
[00:43:47.920 --> 00:43:50.080]   So I think that is like a big aspect.
[00:43:50.080 --> 00:43:52.200]   That also gives it a bit of a knob, right?
[00:43:52.200 --> 00:43:53.520]   These companies that are profitable
[00:43:53.520 --> 00:43:55.760]   will be a bit more rational.
[00:43:55.760 --> 00:43:59.000]   - I think corporate America is investing more in AI
[00:43:59.000 --> 00:44:01.480]   and with more conviction than they did
[00:44:01.480 --> 00:44:03.480]   even in the internet wave also.
[00:44:03.480 --> 00:44:04.800]   - Maybe we can switch a little bit.
[00:44:04.800 --> 00:44:08.560]   You've mentioned inference time reasoning a few times now.
[00:44:08.560 --> 00:44:11.800]   It's clearly a new vector of scaling intelligence.
[00:44:11.800 --> 00:44:14.400]   And I read some of your analysis recently
[00:44:14.400 --> 00:44:17.040]   about how inference time reasoning
[00:44:17.040 --> 00:44:20.120]   is way more compute intensive, right?
[00:44:20.120 --> 00:44:23.360]   Than simply pre-train, you know, scaling pre-training.
[00:44:23.360 --> 00:44:24.600]   Why don't you walk us through,
[00:44:24.600 --> 00:44:26.680]   we have a really interesting graph here
[00:44:26.680 --> 00:44:30.600]   about why that's the case that we'll post as well.
[00:44:30.600 --> 00:44:32.320]   But why don't you walk us through first,
[00:44:32.320 --> 00:44:34.800]   just kind of what inference time reasoning is
[00:44:34.800 --> 00:44:37.720]   from the perspective of compute consumption,
[00:44:37.720 --> 00:44:40.240]   why it's so much more compute intensive.
[00:44:40.240 --> 00:44:42.360]   And so leading to the conclusion
[00:44:42.360 --> 00:44:46.080]   that if this is in fact going to continue to scale
[00:44:46.080 --> 00:44:50.240]   as a new vector of intelligence,
[00:44:50.240 --> 00:44:52.720]   it looks like it's gonna be even more compute intensive
[00:44:52.720 --> 00:44:54.480]   than what came before it.
[00:44:54.480 --> 00:44:56.200]   - Yeah, so pre-training may be slowing out
[00:44:56.200 --> 00:44:57.560]   or it's too expensive,
[00:44:57.560 --> 00:44:59.680]   but there's these other aspects of synthetic data generation
[00:44:59.680 --> 00:45:01.040]   and inference time compute.
[00:45:01.040 --> 00:45:03.440]   Inference time compute is,
[00:45:03.440 --> 00:45:05.520]   on the surface sounds amazing, right?
[00:45:05.520 --> 00:45:07.400]   I don't need to spend more training a model.
[00:45:07.400 --> 00:45:09.720]   But when you think about it for a second,
[00:45:09.720 --> 00:45:12.320]   this is actually very, very,
[00:45:12.320 --> 00:45:13.760]   this is not the way you want to scale.
[00:45:13.760 --> 00:45:16.240]   You only do that because you have to, right?
[00:45:16.240 --> 00:45:17.840]   The way, because, all right, think about it.
[00:45:17.840 --> 00:45:21.280]   GPT-4 was trained with hundreds of billions of dollars
[00:45:21.280 --> 00:45:24.320]   and it's generating billions of dollars of revenue.
[00:45:24.320 --> 00:45:25.600]   - Hundreds of millions of dollars.
[00:45:25.600 --> 00:45:27.720]   - Hundreds of millions of dollars to train GPT-4.
[00:45:27.720 --> 00:45:29.800]   And it's generating billions of dollars of revenue.
[00:45:29.800 --> 00:45:32.560]   So when you say like, "Hey, Microsoft's CapEx is nuts."
[00:45:32.560 --> 00:45:37.320]   Sure, but their spend on GPT-4 was very reasonable
[00:45:37.320 --> 00:45:39.880]   relative to the ROI they're getting out of it, right?
[00:45:39.880 --> 00:45:42.440]   Now, when you say, "Hey, I want the next gain."
[00:45:42.440 --> 00:45:47.080]   If I just spend sort of a large amount of capital
[00:45:47.080 --> 00:45:48.760]   and train a better model, awesome.
[00:45:48.760 --> 00:45:51.360]   But if I don't have to spend that large amount of capital
[00:45:51.360 --> 00:45:54.840]   and I deploy this better model without,
[00:45:54.840 --> 00:45:56.560]   at the time of revenue generation,
[00:45:56.560 --> 00:45:58.720]   rather than ahead of time when I'm training the model,
[00:45:58.720 --> 00:46:00.360]   this also sounds awesome.
[00:46:00.360 --> 00:46:03.880]   But this comes with this big trade-off, right?
[00:46:03.880 --> 00:46:05.720]   When you're running reasoning, right?
[00:46:05.720 --> 00:46:09.320]   You're having the model generate a lot.
[00:46:09.320 --> 00:46:11.400]   And then the answer is only a portion of that, right?
[00:46:11.400 --> 00:46:15.400]   Today, when you open up chat GPT, use GPT-4, 4.0,
[00:46:15.400 --> 00:46:17.440]   you say something, you get a response.
[00:46:17.440 --> 00:46:20.760]   You send something, you get a response, whatever it is, right?
[00:46:20.760 --> 00:46:22.480]   All of the stuff that's being generated
[00:46:22.480 --> 00:46:23.640]   is being sent to you.
[00:46:23.640 --> 00:46:26.040]   Now you're having this reasoning phase, right?
[00:46:26.040 --> 00:46:27.600]   And OpenAI doesn't wanna show you,
[00:46:27.600 --> 00:46:29.480]   but there's some open source Chinese models
[00:46:29.480 --> 00:46:31.720]   like Alibaba and DeepSeek.
[00:46:31.720 --> 00:46:33.000]   They've released some open source models,
[00:46:33.000 --> 00:46:34.480]   which are not quite as good as OpenAI, of course,
[00:46:34.480 --> 00:46:37.160]   but they show you what that reasoning looks like
[00:46:37.160 --> 00:46:38.000]   if you want to.
[00:46:38.000 --> 00:46:39.080]   And OpenAI has released some examples.
[00:46:39.080 --> 00:46:40.520]   It generates tons of things.
[00:46:40.520 --> 00:46:42.200]   It's like, it sometimes switches
[00:46:42.200 --> 00:46:43.520]   between Chinese and English, right?
[00:46:43.520 --> 00:46:45.360]   Like whatever it is, it's thinking, right?
[00:46:45.360 --> 00:46:46.200]   It's churning.
[00:46:46.200 --> 00:46:47.160]   It's like this, this, this, this.
[00:46:47.160 --> 00:46:48.000]   Oh, should I do it this way?
[00:46:48.000 --> 00:46:49.440]   Should I break it down in these steps?
[00:46:49.440 --> 00:46:51.520]   And then it comes out with an answer, right?
[00:46:51.520 --> 00:46:53.280]   Now, on the surface, awesome.
[00:46:53.280 --> 00:46:56.880]   I didn't have to spend any more on R&D or capital, right?
[00:46:56.880 --> 00:46:57.960]   I'm saying this in the loose terms.
[00:46:57.960 --> 00:47:01.600]   They don't treat training models as R&D,
[00:47:01.600 --> 00:47:03.420]   I think on Microsoft on a financial basis.
[00:47:03.420 --> 00:47:05.320]   But they don't have to treat this,
[00:47:05.320 --> 00:47:07.800]   they don't have this R&D ahead of time, right?
[00:47:07.800 --> 00:47:09.000]   You get it at spend time.
[00:47:09.000 --> 00:47:11.840]   But think about what that means, right?
[00:47:11.840 --> 00:47:13.400]   If for you, right, for example,
[00:47:13.400 --> 00:47:16.620]   one simple thing that we've done a lot of tests on is,
[00:47:16.620 --> 00:47:19.460]   hey, generate me this code, right?
[00:47:19.460 --> 00:47:21.040]   Like make this function.
[00:47:21.040 --> 00:47:21.880]   Great.
[00:47:21.880 --> 00:47:24.660]   I describe the function and a few hundred words.
[00:47:24.660 --> 00:47:27.640]   I get back a response that's a thousand words.
[00:47:27.640 --> 00:47:28.960]   Awesome.
[00:47:28.960 --> 00:47:30.560]   And I'm paying per token.
[00:47:30.560 --> 00:47:33.460]   When I do this with O1 or any other reasoning model,
[00:47:33.460 --> 00:47:35.740]   I'm sending the same response, right?
[00:47:35.740 --> 00:47:36.580]   A few hundred tokens.
[00:47:36.580 --> 00:47:37.500]   I'm paying for that.
[00:47:37.500 --> 00:47:40.060]   I'm getting the same response, roughly a thousand tokens.
[00:47:40.060 --> 00:47:43.180]   But in the middle, there was 10,000 tokens of it thinking.
[00:47:43.180 --> 00:47:46.620]   Now, what does that 10,000 tokens of thinking actually mean?
[00:47:46.620 --> 00:47:47.980]   It means, well, the model's spitting out
[00:47:47.980 --> 00:47:49.260]   10 times as many tokens.
[00:47:49.260 --> 00:47:51.020]   Well, if Microsoft's generating,
[00:47:51.020 --> 00:47:53.180]   call it $10 billion of inference revenue,
[00:47:53.180 --> 00:47:55.580]   and their margins on that are good.
[00:47:55.580 --> 00:47:56.980]   They've stated this, right?
[00:47:56.980 --> 00:47:59.820]   They're anywhere from 50 to 70%,
[00:47:59.820 --> 00:48:03.040]   depending on how you count the OpenAI profit share.
[00:48:03.040 --> 00:48:05.440]   You know, anywhere from 50 to 70% gross margins.
[00:48:05.440 --> 00:48:07.840]   Their cost for that is a few billion dollars
[00:48:07.840 --> 00:48:09.040]   for $10 billion of revenue.
[00:48:09.040 --> 00:48:09.880]   - Right.
[00:48:09.880 --> 00:48:11.960]   - If, now, obviously the better model
[00:48:11.960 --> 00:48:13.240]   gets to charge more, right?
[00:48:13.240 --> 00:48:14.880]   So O1 does charge a lot more,
[00:48:14.880 --> 00:48:17.320]   but you're now increasing your cost from,
[00:48:17.320 --> 00:48:18.680]   hey, I outputted a thousand tokens
[00:48:18.680 --> 00:48:20.740]   to I outputted 11,000 tokens.
[00:48:20.740 --> 00:48:23.780]   I've 10X'd my spend to generate,
[00:48:23.780 --> 00:48:24.840]   now, not the same thing, right?
[00:48:24.840 --> 00:48:25.680]   It's higher quality.
[00:48:25.680 --> 00:48:26.960]   - Correct.
[00:48:26.960 --> 00:48:29.200]   - And that's only part of it.
[00:48:29.200 --> 00:48:30.320]   That's deceptively simple.
[00:48:30.320 --> 00:48:31.640]   It's not just 10X, right?
[00:48:31.640 --> 00:48:32.720]   Because if you go look at O1,
[00:48:32.720 --> 00:48:37.080]   despite it being the same model architecture as GPD 4.0,
[00:48:37.080 --> 00:48:39.880]   it actually costs significantly more per token as well.
[00:48:39.880 --> 00:48:41.040]   And that's because of, you know,
[00:48:41.040 --> 00:48:43.020]   sort of this chart that we're looking at here, right?
[00:48:43.020 --> 00:48:43.860]   - Right.
[00:48:43.860 --> 00:48:46.300]   - And this chart shows, hey, what is GPD 4.0, right?
[00:48:46.300 --> 00:48:48.680]   If I'm generating, you know, call it a thousand tokens,
[00:48:48.680 --> 00:48:51.420]   right, and that's what GPD 4.0 on the bottom right is,
[00:48:51.420 --> 00:48:53.560]   of LLAMA 405B, this is an open model,
[00:48:53.560 --> 00:48:55.400]   so it's easier to simulate, you know,
[00:48:55.400 --> 00:48:56.920]   the exact metrics of it.
[00:48:56.920 --> 00:48:58.360]   But, you know, if I'm doing that,
[00:48:58.360 --> 00:49:00.820]   I'm keeping my users, you know,
[00:49:00.820 --> 00:49:03.240]   experience of the model constant,
[00:49:03.240 --> 00:49:05.520]   i.e. the number of tokens they're getting at the speed,
[00:49:05.520 --> 00:49:07.400]   then, you know, when I ask it a question,
[00:49:07.400 --> 00:49:10.040]   it generates the unit, it generates the code,
[00:49:10.040 --> 00:49:14.640]   whatever it is, I can group together many users' requests.
[00:49:14.640 --> 00:49:18.160]   I can group together over 256 users' requests
[00:49:18.160 --> 00:49:21.800]   on one server for LLAMA 405B of NVIDIA server, right?
[00:49:21.800 --> 00:49:23.740]   Like, you know, $300,000 server or so.
[00:49:23.740 --> 00:49:26.080]   When I do this with O1, right,
[00:49:26.080 --> 00:49:28.920]   because it's doing that thinking phase of 10,000, right,
[00:49:28.920 --> 00:49:31.000]   this is basically the whole context length thing.
[00:49:31.000 --> 00:49:32.920]   Context length is not free, right?
[00:49:32.920 --> 00:49:34.360]   Context length or sequence length
[00:49:34.360 --> 00:49:36.280]   means that it has to calculate attention,
[00:49:36.280 --> 00:49:38.900]   the attention mechanism, i.e. it spends a lot of memory
[00:49:38.900 --> 00:49:40.760]   on generating this KB cache
[00:49:40.760 --> 00:49:42.660]   and reading this KB cache constantly.
[00:49:42.660 --> 00:49:46.880]   Now the maximum batch size, i.e. concurrent users I can have
[00:49:46.880 --> 00:49:50.800]   is a fraction of that, one-fourth to one-fifth
[00:49:50.800 --> 00:49:52.960]   the number of users can currently use the server.
[00:49:52.960 --> 00:49:55.860]   So not only do I need to generate 10X as many tokens,
[00:49:55.860 --> 00:50:01.840]   each token that's generated is four to five X less users.
[00:50:01.840 --> 00:50:04.840]   So the cost increase is stupendous
[00:50:04.840 --> 00:50:06.480]   when you think about a single user.
[00:50:06.480 --> 00:50:08.080]   Cost increase for a single token
[00:50:08.080 --> 00:50:09.560]   to be generated is four to five X,
[00:50:09.560 --> 00:50:11.160]   but then I'm generating 10X as many tokens.
[00:50:11.160 --> 00:50:13.880]   So you could argue the cost increase is 50X
[00:50:13.880 --> 00:50:17.240]   for an O1 style model on input to output.
[00:50:17.240 --> 00:50:20.120]   - I know it's a 10X 'cause it was on the original O1 release
[00:50:20.120 --> 00:50:21.960]   but with the log scale, but I didn't know.
[00:50:21.960 --> 00:50:24.840]   - And it just requires you to have,
[00:50:24.840 --> 00:50:27.800]   again, to service the same number of customers,
[00:50:27.800 --> 00:50:30.560]   you have to have multiples more compute.
[00:50:30.560 --> 00:50:32.960]   - Well, there's good news and bad news here, Brad,
[00:50:32.960 --> 00:50:35.320]   which I think is what Dylan's telling us.
[00:50:35.320 --> 00:50:37.680]   If you're just selling NVIDIA hardware
[00:50:37.680 --> 00:50:39.400]   and they remain the architecture
[00:50:39.400 --> 00:50:41.240]   and this is our scaling path,
[00:50:41.240 --> 00:50:43.020]   you're gonna consume way more of it.
[00:50:43.020 --> 00:50:45.480]   - Correct, but the margins for the people
[00:50:45.480 --> 00:50:47.360]   who are generating on the other end,
[00:50:47.360 --> 00:50:49.800]   unless they can pass it on to the end consumer
[00:50:49.800 --> 00:50:51.520]   are gonna compress.
[00:50:51.520 --> 00:50:53.960]   And the thing is you can pass it on to the end consumer
[00:50:53.960 --> 00:50:56.560]   because, hey, it's not really like,
[00:50:56.560 --> 00:50:58.480]   oh, it's X percent better on this benchmark.
[00:50:58.480 --> 00:51:01.280]   It's, it literally could not do this before
[00:51:01.280 --> 00:51:03.040]   and now it can, right?
[00:51:03.040 --> 00:51:03.860]   And so--
[00:51:03.860 --> 00:51:04.700]   - And they're running a test right now
[00:51:04.700 --> 00:51:06.880]   where they're 10X-ing what they're charging,
[00:51:06.880 --> 00:51:08.120]   the end consumer, you know.
[00:51:08.120 --> 00:51:10.280]   - And it's 10X per token, right?
[00:51:10.280 --> 00:51:12.600]   Remember, they're also paying for 10X as many tokens, right?
[00:51:12.600 --> 00:51:13.880]   So it's actually, you know,
[00:51:13.880 --> 00:51:17.640]   the consumer is paying 50X more per query,
[00:51:17.640 --> 00:51:19.080]   but they're getting value out of it
[00:51:19.080 --> 00:51:20.560]   because now all of a sudden,
[00:51:20.560 --> 00:51:23.640]   it can pass certain benchmarks like SWEbench, right?
[00:51:23.640 --> 00:51:25.440]   Software Engineering Benchmark, right?
[00:51:25.440 --> 00:51:26.960]   Which is just a benchmark for generating,
[00:51:26.960 --> 00:51:28.940]   like, you know, decent code, right?
[00:51:28.940 --> 00:51:30.340]   There's front-end web development, right?
[00:51:30.340 --> 00:51:32.120]   What do you pay front-end web developers?
[00:51:32.120 --> 00:51:34.460]   What do you pay back-end developers?
[00:51:34.460 --> 00:51:36.560]   Versus, hey, what if they use O1?
[00:51:36.560 --> 00:51:37.960]   How much more code can they output?
[00:51:37.960 --> 00:51:39.120]   How much more can they output?
[00:51:39.120 --> 00:51:40.800]   Yes, the queries are expensive,
[00:51:40.800 --> 00:51:42.840]   but they're nothing close to the human, right?
[00:51:42.840 --> 00:51:45.720]   And so each level of productivity gain I get,
[00:51:45.720 --> 00:51:47.320]   each level of capabilities jump
[00:51:47.320 --> 00:51:50.600]   is a whole new class of tasks that it can do, right?
[00:51:50.600 --> 00:51:52.360]   And therefore, I can charge for that, right?
[00:51:52.360 --> 00:51:54.600]   So this is the whole, like, axes of,
[00:51:54.600 --> 00:51:57.200]   yes, I spend a lot more to get the same output,
[00:51:57.200 --> 00:51:59.520]   but you're not getting the same output with this model.
[00:51:59.520 --> 00:52:02.560]   - Are we overestimating or underestimating
[00:52:02.560 --> 00:52:06.920]   end-demand enterprise-level demand for the O1 model?
[00:52:06.920 --> 00:52:07.760]   What are you hearing?
[00:52:07.760 --> 00:52:11.440]   - So I would say the O1 style model is so early days,
[00:52:11.440 --> 00:52:12.920]   people don't even, like, get it, right?
[00:52:12.920 --> 00:52:15.880]   O1 is like, they just crack the code and they're doing it,
[00:52:15.880 --> 00:52:16.720]   but guess what?
[00:52:16.720 --> 00:52:20.360]   Right now on, you know, some of the anonymous benchmarks,
[00:52:20.360 --> 00:52:22.040]   there are, you know, it's called LLM SIS,
[00:52:22.040 --> 00:52:24.120]   which is like an arena where different LLMs
[00:52:24.120 --> 00:52:27.360]   get to, like, compete, sort of, and people vote on them.
[00:52:27.360 --> 00:52:30.720]   There's a Google model that is doing reasoning right now,
[00:52:30.720 --> 00:52:31.920]   and it's not released yet,
[00:52:31.920 --> 00:52:34.240]   but it's going to be released soon enough, right?
[00:52:34.240 --> 00:52:36.520]   Anthropic is going to release a reasoning model.
[00:52:36.520 --> 00:52:38.080]   These people are going to one-up each other,
[00:52:38.080 --> 00:52:39.880]   and also they've spent so little compute
[00:52:39.880 --> 00:52:42.320]   on reasoning right now in terms of training time.
[00:52:42.320 --> 00:52:45.700]   And they see a very clear path to spending a lot more,
[00:52:45.700 --> 00:52:47.640]   i.e. jumping up the scaling laws.
[00:52:47.640 --> 00:52:49.200]   Oh, I only spent $10 million.
[00:52:49.200 --> 00:52:50.760]   Well, wait, that means I can jump up
[00:52:50.760 --> 00:52:53.620]   two to three logarithms in scaling like that,
[00:52:53.620 --> 00:52:55.720]   because I've already got the compute.
[00:52:55.720 --> 00:52:57.840]   You know, I can go from $10 million to $100 billion
[00:52:57.840 --> 00:53:01.160]   to $10 billion on reasoning in such a quick succession.
[00:53:01.160 --> 00:53:03.760]   And so the performance improvements
[00:53:03.760 --> 00:53:06.720]   we'll get out of these models is humongous, right?
[00:53:06.720 --> 00:53:09.320]   In the coming, you know, six months to a year
[00:53:09.320 --> 00:53:12.200]   in certain benchmarks where you have functional verifiers.
[00:53:13.080 --> 00:53:15.100]   - Quick question, and we promised
[00:53:15.100 --> 00:53:16.260]   we'd go to these alternatives,
[00:53:16.260 --> 00:53:17.660]   so we'll have to get there eventually.
[00:53:17.660 --> 00:53:22.180]   But if you go back, we've used this internet wave
[00:53:22.180 --> 00:53:24.360]   comparison multiple times.
[00:53:24.360 --> 00:53:26.980]   When all of the venture-backed companies
[00:53:26.980 --> 00:53:28.180]   got started on the internet,
[00:53:28.180 --> 00:53:30.900]   they were all on Oracle and Sun.
[00:53:30.900 --> 00:53:34.140]   And five years later, they weren't on Oracle or Sun.
[00:53:34.140 --> 00:53:37.700]   And some have argued it went from a development sandbox
[00:53:37.700 --> 00:53:40.580]   world to a optimization world.
[00:53:40.580 --> 00:53:42.220]   Is that likely to happen?
[00:53:42.220 --> 00:53:44.820]   Is there an equivalency here or not?
[00:53:44.820 --> 00:53:49.820]   And if you could touch on why the backend
[00:53:49.820 --> 00:53:52.980]   is so steep and cheap, like, you know,
[00:53:52.980 --> 00:53:56.180]   just you go a model, you know, behind,
[00:53:56.180 --> 00:53:59.860]   or you, like, the price you can save
[00:53:59.860 --> 00:54:03.300]   by just backing up a little bit is nutty.
[00:54:03.300 --> 00:54:05.820]   - Yeah, yeah, so today, right,
[00:54:05.820 --> 00:54:07.740]   like O1 is stupendously expensive.
[00:54:07.740 --> 00:54:09.380]   You drop down to 4.0, it's a lot cheaper.
[00:54:09.380 --> 00:54:11.260]   You jump down to 4.0 mini, it's so cheap.
[00:54:11.260 --> 00:54:13.740]   Why, because now I'm, with 4.0 mini,
[00:54:13.740 --> 00:54:15.420]   I'm competing against Lama,
[00:54:15.420 --> 00:54:16.740]   and I'm competing against DeepSeek,
[00:54:16.740 --> 00:54:17.940]   I'm competing against Mistral,
[00:54:17.940 --> 00:54:19.420]   I'm competing against Alibaba,
[00:54:19.420 --> 00:54:21.100]   and I'm competing against tons of companies.
[00:54:21.100 --> 00:54:23.620]   - So you think those are market-clearing prices?
[00:54:23.620 --> 00:54:26.020]   - I think, and in addition, right,
[00:54:26.020 --> 00:54:28.100]   there is also the problem of inferencing
[00:54:28.100 --> 00:54:30.620]   a small model is quite easy, right?
[00:54:30.620 --> 00:54:34.380]   I can run Lama70B on one AMD GPU.
[00:54:34.380 --> 00:54:37.820]   I can run Lama70B on one Nvidia GPU,
[00:54:37.820 --> 00:54:38.860]   and soon enough there'll be,
[00:54:38.860 --> 00:54:41.620]   on one set of Amazon's Neutranium, right?
[00:54:41.620 --> 00:54:44.100]   I can sort of run this model on a single chip.
[00:54:44.100 --> 00:54:46.340]   This is a very easy, I won't say very easy problem,
[00:54:46.340 --> 00:54:49.060]   it's still hard, but it's quite a bit easier problem
[00:54:49.060 --> 00:54:50.980]   than running this complex reasoning
[00:54:50.980 --> 00:54:52.780]   or this very large model, right?
[00:54:52.780 --> 00:54:54.980]   And so there is that difference, right?
[00:54:54.980 --> 00:54:56.420]   There's also the fact that, hey,
[00:54:56.420 --> 00:54:59.460]   there's literally 15 different companies out there
[00:54:59.460 --> 00:55:02.780]   offering API inferences, inference APIs,
[00:55:02.780 --> 00:55:05.140]   on Lama, and Alibaba, and DeepSeek, and Mistral,
[00:55:05.140 --> 00:55:06.460]   like these different models, right?
[00:55:06.460 --> 00:55:08.220]   - You're talking about Cerebrus, and Grok,
[00:55:08.220 --> 00:55:10.340]   and, you know, Fireworks, and all these others.
[00:55:10.340 --> 00:55:12.740]   - Yeah, Fireworks together, you know,
[00:55:12.740 --> 00:55:14.740]   all the companies that aren't using their own hardware.
[00:55:14.740 --> 00:55:15.780]   Now, of course, Grok and Cerebrus
[00:55:15.780 --> 00:55:17.540]   are doing their own hardware and doing this as well.
[00:55:17.540 --> 00:55:22.300]   But the market, the margins here are bad, right?
[00:55:22.300 --> 00:55:23.740]   You know, sort of, we had this whole thing
[00:55:23.740 --> 00:55:25.380]   about the inference race to the bottom
[00:55:25.380 --> 00:55:27.540]   when Mistral released their Mistral model,
[00:55:27.540 --> 00:55:30.440]   which was like very revolutionary, sort of late last year,
[00:55:30.440 --> 00:55:33.780]   because it was such a level of performance
[00:55:33.780 --> 00:55:36.260]   that didn't exist in the open source,
[00:55:36.260 --> 00:55:39.380]   that it drove pricing down so fast, right?
[00:55:39.380 --> 00:55:41.100]   Because everyone's competing for API.
[00:55:41.100 --> 00:55:43.900]   What am I, as an API provider, providing you,
[00:55:43.900 --> 00:55:46.220]   like, why don't you switch from mine to his, why?
[00:55:46.220 --> 00:55:48.820]   Because, well, there's no, it's pretty fungible, right?
[00:55:48.820 --> 00:55:50.580]   I'm still getting the same tokens on the same model.
[00:55:50.580 --> 00:55:52.820]   And so, the margins for these guys is much lower.
[00:55:52.820 --> 00:55:55.860]   So, Microsoft's earning 50 to 70% gross margins
[00:55:55.860 --> 00:55:58.060]   on OpenAI models, and that's with the profit share
[00:55:58.060 --> 00:56:00.580]   they get to get, or the share that they give OpenAI, right?
[00:56:00.580 --> 00:56:02.540]   Or, you know, Anthropic, similarly,
[00:56:02.540 --> 00:56:03.380]   in their most recent round,
[00:56:03.380 --> 00:56:05.980]   they were showing, like, 70% gross margins.
[00:56:05.980 --> 00:56:07.900]   But that's because they have this model.
[00:56:07.900 --> 00:56:12.580]   You step down to here, no one uses this model from,
[00:56:12.580 --> 00:56:15.260]   you know, a lot less people use it from OpenAI or Anthropic,
[00:56:15.260 --> 00:56:19.380]   because they can just, like, take the weights from Llama,
[00:56:19.380 --> 00:56:21.060]   put it on their own server, or vice versa.
[00:56:21.060 --> 00:56:23.620]   Go to one of the many competitive API providers,
[00:56:23.620 --> 00:56:24.900]   some of them being venture-funded,
[00:56:24.900 --> 00:56:27.180]   some of them, you know, and losing money, right?
[00:56:27.180 --> 00:56:28.780]   So, there's all this competition here.
[00:56:28.780 --> 00:56:31.300]   So, not only are you saying, I'm taking a step back,
[00:56:31.300 --> 00:56:33.700]   and it's an easier problem, and so, therefore,
[00:56:33.700 --> 00:56:35.220]   like, if the model's 10x smaller,
[00:56:35.220 --> 00:56:37.220]   it's, like, 15x cheaper to run.
[00:56:37.220 --> 00:56:39.700]   On top of that, I'm removing that gross margin.
[00:56:39.700 --> 00:56:41.620]   And so, it's not 15x cheaper to run,
[00:56:41.620 --> 00:56:43.140]   it's 30x cheaper to run.
[00:56:43.140 --> 00:56:45.660]   And so, this is sort of the beauty of, like,
[00:56:45.660 --> 00:56:47.140]   well, is everything commodity?
[00:56:47.140 --> 00:56:50.140]   No, but, like, there is a huge chase to, like,
[00:56:50.140 --> 00:56:51.580]   if you're deploying it in services,
[00:56:51.580 --> 00:56:53.740]   that's gonna be, this is great for you, A.
[00:56:53.740 --> 00:56:56.620]   B, you have to have the best model,
[00:56:56.620 --> 00:56:58.580]   or you're no one if you're one of the labs, right?
[00:56:58.580 --> 00:57:00.980]   And so, you see a lot of struggles for the companies
[00:57:00.980 --> 00:57:03.060]   that were trying to build the best models, but failing.
[00:57:03.060 --> 00:57:05.420]   - And arguably, not only do you have to have the best model,
[00:57:05.420 --> 00:57:08.420]   you actually have to have an enterprise or a consumer
[00:57:08.420 --> 00:57:10.660]   willing to pay for the best model, right?
[00:57:10.660 --> 00:57:12.540]   Because at the end of the day, you know,
[00:57:12.540 --> 00:57:14.980]   the best model implies that somebody's willing to pay you
[00:57:14.980 --> 00:57:16.460]   these high margins, right?
[00:57:16.460 --> 00:57:18.340]   And that's either an enterprise or a consumer.
[00:57:18.340 --> 00:57:21.860]   So, I think, you know, you're quickly narrowing down
[00:57:21.860 --> 00:57:25.060]   to just a handful of folks who will be able to compete,
[00:57:25.060 --> 00:57:26.020]   you know, in that market.
[00:57:26.020 --> 00:57:27.340]   - I think on the model side, yes.
[00:57:27.340 --> 00:57:31.180]   I think on the who's willing to pay for these models is,
[00:57:31.180 --> 00:57:34.460]   I think a lot more people will pay for the best model, right?
[00:57:34.460 --> 00:57:36.060]   When we use models internally, right?
[00:57:36.060 --> 00:57:39.060]   We have language models go through every regulatory,
[00:57:39.060 --> 00:57:41.180]   filing, and permit to look at data center stuff
[00:57:41.180 --> 00:57:42.540]   and pull that out and tell us where to look
[00:57:42.540 --> 00:57:43.540]   and where to not to.
[00:57:43.540 --> 00:57:47.260]   And we just use the best model because it's so cheap, right?
[00:57:47.260 --> 00:57:48.900]   Like, the data that I'm getting out of it,
[00:57:48.900 --> 00:57:50.860]   the value I'm getting out of it is so much higher.
[00:57:50.860 --> 00:57:52.140]   - What model are you using?
[00:57:52.140 --> 00:57:53.580]   - We're using Anthropic, actually, right now,
[00:57:53.580 --> 00:57:56.660]   Cloud 3.5, Sunet, and you, Sonnet.
[00:57:56.660 --> 00:58:00.220]   And so, just because O1 is a lot better on certain tasks,
[00:58:00.220 --> 00:58:02.820]   but not necessarily regulatory filings and permitting
[00:58:02.820 --> 00:58:03.780]   and things like that,
[00:58:03.780 --> 00:58:06.060]   because the cost of errors is so much higher, right?
[00:58:06.060 --> 00:58:07.980]   Same with a developer, right?
[00:58:07.980 --> 00:58:09.180]   If I can increase a developer
[00:58:09.180 --> 00:58:12.820]   who makes $300,000 a year here in the Bay by 20%,
[00:58:12.820 --> 00:58:13.660]   that's a lot.
[00:58:13.660 --> 00:58:16.340]   If I can take a team of 100 developers
[00:58:16.340 --> 00:58:19.380]   and use 75 or 50 to do the same job,
[00:58:19.380 --> 00:58:21.380]   or I can ship twice as much code,
[00:58:21.380 --> 00:58:23.700]   this is so worth using the most expensive model
[00:58:23.700 --> 00:58:27.420]   because O1, as expensive it is relative to 4.0,
[00:58:27.420 --> 00:58:29.380]   it's still super cheap, right?
[00:58:29.380 --> 00:58:32.860]   The cost for intelligence is so high in society, right?
[00:58:32.860 --> 00:58:36.380]   That's why intelligent jobs are the most high-paying jobs.
[00:58:36.380 --> 00:58:38.220]   White-collar jobs, right, are the most high-paying jobs.
[00:58:38.220 --> 00:58:40.580]   If you can bring down the cost of intelligence
[00:58:40.580 --> 00:58:42.140]   or augment intelligence,
[00:58:42.140 --> 00:58:44.060]   then there's a high market clearing price for that,
[00:58:44.060 --> 00:58:46.300]   which is why I think that sort of the,
[00:58:46.300 --> 00:58:47.980]   oh, yes, O1 is expensive,
[00:58:47.980 --> 00:58:49.820]   and people will always gravitate to
[00:58:49.820 --> 00:58:52.060]   what's the cheapest thing at a certain level of intelligence,
[00:58:52.060 --> 00:58:54.100]   but each time we break a new level of intelligence,
[00:58:54.100 --> 00:58:57.580]   it's not just, oh, we've got a few more tasks we can do.
[00:58:57.580 --> 00:58:59.100]   I think it grows the mode of tasks
[00:58:59.100 --> 00:59:00.700]   that can be done dramatically.
[00:59:00.700 --> 00:59:03.860]   Very few people could use GPT-2 and 3, right?
[00:59:03.860 --> 00:59:05.740]   A lot of people can use GPT-4.
[00:59:05.740 --> 00:59:07.500]   When we get to that quality of jump
[00:59:07.500 --> 00:59:09.260]   that we see for the next generation,
[00:59:09.260 --> 00:59:11.020]   the amount of people that can use it,
[00:59:11.020 --> 00:59:13.420]   the tasks that it can do, balloons out,
[00:59:13.420 --> 00:59:15.740]   and therefore the amount of sort of white-collar jobs
[00:59:15.740 --> 00:59:18.220]   that it can augment increased productivity on will grow,
[00:59:18.220 --> 00:59:20.020]   and therefore the market clearing price for that token
[00:59:20.020 --> 00:59:20.860]   will be very high.
[00:59:20.860 --> 00:59:21.700]   - That's super interesting.
[00:59:21.700 --> 00:59:22.540]   I could make the other argument
[00:59:22.540 --> 00:59:25.380]   that someone that's in a high-volume,
[00:59:25.380 --> 00:59:28.660]   you know, just replacing tons of customer service calls
[00:59:28.660 --> 00:59:33.660]   or whatever might be tempted to minimize the spend--
[00:59:33.660 --> 00:59:35.980]   - Absolutely.
[00:59:35.980 --> 00:59:37.980]   - And maximize the amount of value add
[00:59:37.980 --> 00:59:40.020]   they build around this thing,
[00:59:40.020 --> 00:59:41.580]   database writes and reads.
[00:59:41.580 --> 00:59:42.420]   - Absolutely.
[00:59:42.420 --> 00:59:43.860]   So one of the funny things I like to,
[00:59:43.860 --> 00:59:45.460]   the calculations we did is,
[00:59:45.460 --> 00:59:47.700]   if you take one quarter of NVIDIA shipments,
[00:59:47.700 --> 00:59:50.980]   and you said all of them are gonna inference LLAMA 7B,
[00:59:50.980 --> 00:59:53.340]   you can give every single person on Earth
[00:59:53.340 --> 00:59:56.660]   100 tokens per minute, right?
[00:59:56.660 --> 00:59:58.300]   Or sorry, 100 tokens per second.
[00:59:58.300 --> 00:59:59.620]   You can give every single person on Earth
[00:59:59.620 --> 01:00:00.900]   100 tokens per second,
[01:00:00.900 --> 01:00:02.500]   which is like absurd.
[01:00:02.500 --> 01:00:03.340]   - Yeah.
[01:00:03.340 --> 01:00:04.180]   - You know, so like,
[01:00:04.180 --> 01:00:07.500]   if we're just deploying LLAMA 7B quality models,
[01:00:07.500 --> 01:00:10.500]   we've so overbuilt, it's not even funny.
[01:00:10.500 --> 01:00:13.260]   Now, if we're deploying things that can like augment
[01:00:13.260 --> 01:00:16.780]   engineers and increase productivity
[01:00:16.780 --> 01:00:20.180]   and help us build robotics or AV or whatever else faster,
[01:00:21.020 --> 01:00:24.140]   then that's a very different like calculation, right?
[01:00:24.140 --> 01:00:25.380]   And so that's sort of the whole thing.
[01:00:25.380 --> 01:00:26.620]   Like, yes, small models are there,
[01:00:26.620 --> 01:00:27.860]   but like, they're so easy to run.
[01:00:27.860 --> 01:00:30.700]   - And it may just, both these things may be true.
[01:00:30.700 --> 01:00:32.100]   - Right, we're gonna have tons of small models
[01:00:32.100 --> 01:00:34.020]   running everywhere, but the compute cost of them is so low.
[01:00:34.020 --> 01:00:34.980]   - Yeah, fair enough.
[01:00:34.980 --> 01:00:36.540]   - Bill and I were talking about this earlier
[01:00:36.540 --> 01:00:38.580]   with respect to the hard drives,
[01:00:38.580 --> 01:00:39.980]   you know, that you used to cover.
[01:00:39.980 --> 01:00:41.540]   But if you look at the memory market,
[01:00:41.540 --> 01:00:43.740]   it's been one of these boom or bust markets.
[01:00:43.740 --> 01:00:45.700]   The idea was you would always, you know,
[01:00:45.700 --> 01:00:48.340]   sell these things when they're nearing peak.
[01:00:48.340 --> 01:00:49.860]   You know, you always buy them at trough.
[01:00:49.860 --> 01:00:52.900]   You don't own them anywhere, you know, in between.
[01:00:52.900 --> 01:00:55.300]   They trade at very low earnings multiples.
[01:00:55.300 --> 01:00:57.580]   I'm talking about Hynex and I'm talking about,
[01:00:57.580 --> 01:00:58.740]   you know, Micron.
[01:00:58.740 --> 01:01:01.820]   As you think about the shift toward inference time compute,
[01:01:01.820 --> 01:01:05.060]   it seems that the memory demanded of these chips,
[01:01:05.060 --> 01:01:07.260]   and Jensen has talked a lot about this,
[01:01:07.260 --> 01:01:11.060]   just is on a secular shift higher, right?
[01:01:11.060 --> 01:01:13.940]   Because if they're doing these passes, you know,
[01:01:13.940 --> 01:01:15.300]   and you're running, like you said,
[01:01:15.300 --> 01:01:17.660]   10 or a hundred or a thousand passes
[01:01:17.660 --> 01:01:19.260]   for inference time reasoning,
[01:01:19.260 --> 01:01:20.900]   you just have to have more and more memory
[01:01:20.900 --> 01:01:23.020]   as this context length expands.
[01:01:23.020 --> 01:01:25.820]   So, you know, talk to us a little bit about, you know,
[01:01:25.820 --> 01:01:27.620]   kind of how you think about the memory market.
[01:01:27.620 --> 01:01:30.820]   - Yeah, so, you know, to sort of like set the stage
[01:01:30.820 --> 01:01:34.580]   a little bit more is reasoning models
[01:01:34.580 --> 01:01:36.900]   output thousands and thousands of tokens.
[01:01:36.900 --> 01:01:40.540]   And when we're looking at transformers,
[01:01:40.540 --> 01:01:43.460]   attention, right, like holy grail of transformers,
[01:01:43.460 --> 01:01:46.980]   i.e. how it like understands the entire context
[01:01:46.980 --> 01:01:49.460]   grows dramatically and the KV cache,
[01:01:49.460 --> 01:01:53.020]   i.e. the memory that is keeping track
[01:01:53.020 --> 01:01:55.540]   of how, what this like context means
[01:01:55.540 --> 01:01:57.780]   is growing quadratically, right?
[01:01:57.780 --> 01:02:01.340]   And therefore, if I go from a context length of 10 to 100,
[01:02:01.340 --> 01:02:03.260]   it's not just a 10X, it's much more, right?
[01:02:03.260 --> 01:02:05.020]   And so you treat that, right?
[01:02:05.020 --> 01:02:06.500]   Like today's reasoning models,
[01:02:06.500 --> 01:02:09.460]   they'll think 10,000 tokens, 20,000 tokens.
[01:02:09.460 --> 01:02:10.700]   When we get to, hey,
[01:02:10.700 --> 01:02:12.380]   what is complex reasoning gonna look like?
[01:02:12.380 --> 01:02:13.980]   Models are going to get to the point
[01:02:13.980 --> 01:02:16.500]   where they're thinking for hundreds of thousands of tokens.
[01:02:16.500 --> 01:02:18.580]   And then this is all one chain of thought
[01:02:18.580 --> 01:02:19.700]   or it might be some search,
[01:02:19.700 --> 01:02:21.660]   but it's gonna be thinking a lot
[01:02:21.660 --> 01:02:24.020]   and this KV cache is gonna balloon, right?
[01:02:24.020 --> 01:02:26.700]   - You're saying memory could grow faster than GPU cache.
[01:02:26.700 --> 01:02:28.460]   - And it objectively is when you look
[01:02:28.460 --> 01:02:32.100]   at the cost of goods sold of NVIDIA,
[01:02:32.100 --> 01:02:34.460]   their highest cost of goods sold is not TSMC,
[01:02:34.460 --> 01:02:36.620]   which is a thing that people don't realize.
[01:02:36.620 --> 01:02:39.180]   It's actually HBM memory, primarily SK Hynix.
[01:02:39.180 --> 01:02:40.980]   - That may be a for now also, but.
[01:02:40.980 --> 01:02:43.620]   - Yeah, so there's three memory companies out there, right?
[01:02:43.620 --> 01:02:46.540]   There's Samsung, SK Hynix, and Micron.
[01:02:46.540 --> 01:02:48.900]   NVIDIA has majority used SK Hynix.
[01:02:48.900 --> 01:02:51.540]   And this is like a big shift in the memory market as a whole
[01:02:51.540 --> 01:02:53.980]   'cause historically it has been a commodity, right?
[01:02:53.980 --> 01:02:55.980]   I.e. it's fungible.
[01:02:55.980 --> 01:02:58.540]   Whether I buy from Samsung or SK Hynix or Micron or.
[01:02:58.540 --> 01:03:00.340]   - Is the socket replaceable?
[01:03:00.340 --> 01:03:02.300]   - Yeah, and even now,
[01:03:02.300 --> 01:03:04.180]   Samsung is getting really, really hit hard
[01:03:04.180 --> 01:03:07.980]   because there's a Chinese memory maker, CXMT,
[01:03:07.980 --> 01:03:10.220]   and their memory is not as good as the last, but it's fine.
[01:03:10.220 --> 01:03:12.780]   And in low end memory, it's fungible.
[01:03:12.780 --> 01:03:14.280]   And therefore, the price of low end memory
[01:03:14.280 --> 01:03:15.940]   has fallen a lot. - Right.
[01:03:15.940 --> 01:03:19.660]   - In HBM, Samsung has almost no share, right?
[01:03:19.660 --> 01:03:21.460]   Especially at NVIDIA.
[01:03:21.460 --> 01:03:25.060]   And so this is hitting Samsung really hard, right?
[01:03:25.060 --> 01:03:28.260]   Despite them being the largest memory maker in the world,
[01:03:28.260 --> 01:03:29.500]   everyone's always like, if you said memory,
[01:03:29.500 --> 01:03:31.260]   it's like, yeah, Samsung's a little bit ahead in tech
[01:03:31.260 --> 01:03:32.940]   and their margins are a little bit better
[01:03:32.940 --> 01:03:33.820]   and they're killing it, right?
[01:03:33.820 --> 01:03:35.020]   But now it's quite not the case
[01:03:35.020 --> 01:03:36.780]   because on the low end, they're getting a little bit hit.
[01:03:36.780 --> 01:03:38.380]   And on the high end, they can't break in
[01:03:38.380 --> 01:03:40.960]   or they keep trying, but they keep failing.
[01:03:40.960 --> 01:03:43.500]   On the flip side, you have companies like SK Hynix
[01:03:43.500 --> 01:03:47.380]   and Micron who are converting significant amounts
[01:03:47.380 --> 01:03:50.940]   of their capacity of sort of commodity DRAM to HBM.
[01:03:50.940 --> 01:03:52.960]   Now, HBM is still fungible, right?
[01:03:52.960 --> 01:03:56.260]   In that if someone hits a certain level of technology,
[01:03:56.260 --> 01:03:58.080]   they can swap out Micron to Hynix, right?
[01:03:58.080 --> 01:04:00.180]   So it's fungible in that sense, right?
[01:04:00.180 --> 01:04:01.300]   It's a commodity in that sense,
[01:04:01.300 --> 01:04:04.980]   but because reasoning requires so much more memory
[01:04:04.980 --> 01:04:08.000]   and the cost of goods sold of an H100 to Blackwell,
[01:04:08.000 --> 01:04:11.860]   the percentage of costs to HBM has grown faster
[01:04:11.860 --> 01:04:15.640]   than the percentage of costs to leading edge silicon.
[01:04:15.640 --> 01:04:18.380]   You've got this big shift or dynamic going on.
[01:04:18.380 --> 01:04:20.900]   And this applies not just to NVIDIA's GPUs,
[01:04:20.900 --> 01:04:23.740]   but it applies to the hyperscalers GPUs as well, right?
[01:04:23.740 --> 01:04:26.780]   Or accelerators like the TPU, Amazon Tranium, et cetera.
[01:04:26.780 --> 01:04:29.340]   - And SK has higher gross margins
[01:04:29.340 --> 01:04:31.300]   than memory companies have this year.
[01:04:31.300 --> 01:04:32.140]   - Correct, correct.
[01:04:32.140 --> 01:04:34.300]   If you listen to Jensen at least describe it,
[01:04:34.300 --> 01:04:37.740]   it's not all memory is created equal, right?
[01:04:37.740 --> 01:04:39.860]   And so it's not only that the product
[01:04:39.860 --> 01:04:41.100]   is more differentiated today,
[01:04:41.100 --> 01:04:43.460]   there's more software associated with the product today,
[01:04:43.460 --> 01:04:47.800]   but it's also how it's integrated into the overall system,
[01:04:47.800 --> 01:04:48.640]   right?
[01:04:48.640 --> 01:04:50.480]   And going back to the supply chain question,
[01:04:50.480 --> 01:04:52.420]   it sounds like it's all commodity.
[01:04:52.420 --> 01:04:54.060]   It just seems to me that at least
[01:04:54.060 --> 01:04:55.500]   there's a question out there.
[01:04:55.500 --> 01:04:56.860]   Is it structurally changing?
[01:04:56.860 --> 01:04:59.580]   We know the secular curve is up and to the right.
[01:04:59.580 --> 01:05:00.740]   - I'm hearing you say maybe.
[01:05:00.740 --> 01:05:03.420]   It may be differentiated enough to not be a commodity.
[01:05:03.420 --> 01:05:04.260]   - It may be.
[01:05:04.260 --> 01:05:06.380]   And I think another thing to point out is
[01:05:07.380 --> 01:05:09.900]   funnily enough, the gross margins on HBM
[01:05:09.900 --> 01:05:11.260]   have not been fantastic.
[01:05:11.260 --> 01:05:12.100]   - Right.
[01:05:12.100 --> 01:05:13.580]   - They've been good, but they haven't been fantastic.
[01:05:13.580 --> 01:05:16.540]   Actually, regular memory, high-end like server memory
[01:05:16.540 --> 01:05:19.020]   that is not HBM is actually higher gross margin than HBM.
[01:05:19.020 --> 01:05:20.780]   And the reason for this is because
[01:05:20.780 --> 01:05:23.660]   NVIDIA is pushing the memory makers so hard, right?
[01:05:23.660 --> 01:05:25.580]   They want the faster, newer generation of memory,
[01:05:25.580 --> 01:05:28.100]   faster and faster and faster for HBM,
[01:05:28.100 --> 01:05:30.260]   but not necessarily like everyone else for servers.
[01:05:30.260 --> 01:05:32.140]   Now, what is this like meant?
[01:05:32.140 --> 01:05:35.580]   Is that, hey, even though Samsung may achieve level four,
[01:05:35.580 --> 01:05:37.660]   right, or level three or whatever that they had previously,
[01:05:37.660 --> 01:05:39.620]   they can't reach what Hynix is at now.
[01:05:39.620 --> 01:05:41.020]   What are the competitors doing, right?
[01:05:41.020 --> 01:05:42.900]   What is AMD and Amazon saying?
[01:05:42.900 --> 01:05:46.820]   AMD explicitly has a better inference GPU
[01:05:46.820 --> 01:05:48.980]   because they give you more memory, right?
[01:05:48.980 --> 01:05:50.580]   They give you more memory and more memory bandwidth.
[01:05:50.580 --> 01:05:52.580]   That's literally the only reason AMD's GPU
[01:05:52.580 --> 01:05:53.940]   is even considered better.
[01:05:53.940 --> 01:05:55.060]   - On chip?
[01:05:55.060 --> 01:05:55.900]   - HBM memory.
[01:05:55.900 --> 01:05:56.740]   - Okay.
[01:05:56.740 --> 01:05:57.560]   - Which is on package.
[01:05:57.560 --> 01:05:58.400]   - Okay.
[01:05:58.400 --> 01:05:59.220]   - Right?
[01:05:59.220 --> 01:06:00.060]   Specifically, yeah.
[01:06:00.060 --> 01:06:02.460]   And then when we look at Amazon,
[01:06:02.460 --> 01:06:03.900]   their whole thing at reInvent,
[01:06:03.900 --> 01:06:05.140]   if you really talk to them,
[01:06:05.140 --> 01:06:06.260]   when they were announced Trinium 2,
[01:06:06.260 --> 01:06:08.060]   and our whole post about it and our analysis of it
[01:06:08.060 --> 01:06:09.900]   is like supply chain wise,
[01:06:09.900 --> 01:06:11.780]   this is, you squint your eyes,
[01:06:11.780 --> 01:06:14.260]   this looks like an Amazon Basics TPU, right?
[01:06:14.260 --> 01:06:15.460]   It's decent, right?
[01:06:15.460 --> 01:06:17.060]   But it's really cheap, A.
[01:06:17.060 --> 01:06:20.700]   And B, it gives you the most HBM capacity per dollar
[01:06:20.700 --> 01:06:22.860]   and most HBM memory bandwidth per dollar
[01:06:22.860 --> 01:06:24.300]   of any chip on the market.
[01:06:24.300 --> 01:06:25.900]   And therefore, it actually makes sense
[01:06:25.900 --> 01:06:27.700]   for certain applications to use.
[01:06:27.700 --> 01:06:29.660]   And so this is like a real, real shift.
[01:06:29.660 --> 01:06:33.080]   Like, hey, we maybe can't design as well as NVIDIA,
[01:06:33.080 --> 01:06:34.740]   but we can put more memory on the package, right?
[01:06:34.740 --> 01:06:36.700]   Now, this is just only one vector of like,
[01:06:36.700 --> 01:06:38.300]   there's a multi-vector problem here.
[01:06:38.300 --> 01:06:39.780]   They don't have the networking nearly as good.
[01:06:39.780 --> 01:06:41.260]   They don't have the software nearly as good.
[01:06:41.260 --> 01:06:43.640]   Their compute elements are not nearly as good.
[01:06:43.640 --> 01:06:46.540]   By golly, they've got more memory bandwidth per dollar.
[01:06:46.540 --> 01:06:47.980]   - Well, this is where we wanted to go
[01:06:47.980 --> 01:06:49.100]   before we run out of time,
[01:06:49.100 --> 01:06:50.820]   is just to talk about these alternatives,
[01:06:50.820 --> 01:06:52.380]   which you just started doing.
[01:06:52.380 --> 01:06:55.540]   So despite all the amazing reasons
[01:06:55.540 --> 01:07:00.220]   why no one would seemingly wanna pick a fight with NVIDIA,
[01:07:00.220 --> 01:07:02.020]   many are trying, right?
[01:07:02.020 --> 01:07:04.520]   And I even hear people talk about trying
[01:07:04.520 --> 01:07:05.480]   that haven't tried yet.
[01:07:05.480 --> 01:07:08.420]   Like OpenAI is constantly talking about their own chip.
[01:07:08.420 --> 01:07:11.760]   How are these other players doing?
[01:07:11.760 --> 01:07:12.920]   Like, how would you handicap?
[01:07:12.920 --> 01:07:15.920]   Let's start with AMD just because they're a standalone
[01:07:15.920 --> 01:07:18.200]   company, and then we'll go to some of the internal program.
[01:07:18.200 --> 01:07:20.840]   - Yeah, so AMD is competing well
[01:07:20.840 --> 01:07:24.140]   because silicon engineering-wise, they're amazing, right?
[01:07:24.140 --> 01:07:25.600]   They're competitive, potentially.
[01:07:25.600 --> 01:07:26.520]   - They kicked Intel's ass.
[01:07:26.520 --> 01:07:28.080]   - But, yeah, they kicked Intel's ass,
[01:07:28.080 --> 01:07:30.360]   but that's like, you know, stealing candy from a baby.
[01:07:30.360 --> 01:07:32.700]   - They started way down here.
[01:07:32.700 --> 01:07:35.600]   Over a 20-year period, it was pretty (beep) amazing.
[01:07:35.600 --> 01:07:38.100]   - So AMD is really good, but they're missing software.
[01:07:38.100 --> 01:07:40.500]   AMD has no clue how to do software, I think.
[01:07:40.500 --> 01:07:42.780]   They've got very few developers on it.
[01:07:42.780 --> 01:07:46.340]   They won't spend the money to build a GPU cluster
[01:07:46.340 --> 01:07:50.440]   for themselves so that they can develop software, right?
[01:07:50.440 --> 01:07:51.540]   Which is like insane, right?
[01:07:51.540 --> 01:07:54.860]   Like NVIDIA, you know, the top 500 supercomputer list
[01:07:54.860 --> 01:07:57.420]   is not relevant because most of the biggest supercomputers
[01:07:57.420 --> 01:07:59.460]   like Elon's and Microsoft's and so on and so forth,
[01:07:59.460 --> 01:08:00.700]   they're not on there.
[01:08:00.700 --> 01:08:03.440]   But NVIDIA has multiple supercomputers
[01:08:03.440 --> 01:08:05.640]   on the top 500 supercomputer list.
[01:08:05.640 --> 01:08:07.380]   And they use them fully internally
[01:08:07.380 --> 01:08:09.180]   to develop software, network software,
[01:08:09.180 --> 01:08:10.780]   whether it be network software or compute software,
[01:08:10.780 --> 01:08:12.700]   inference software, all these things.
[01:08:12.700 --> 01:08:14.660]   You know, test all these changes they make.
[01:08:14.660 --> 01:08:16.740]   And then roll out pushes, you know,
[01:08:16.740 --> 01:08:19.660]   where if XAI is mad because of, you know,
[01:08:19.660 --> 01:08:22.020]   software's not working, NVIDIA will push it the next day
[01:08:22.020 --> 01:08:24.840]   or two days later, like clockwork, right?
[01:08:24.840 --> 01:08:26.440]   Because there's tons of things that break constantly
[01:08:26.440 --> 01:08:27.840]   when you're training models.
[01:08:28.820 --> 01:08:30.020]   AMD doesn't do that, right?
[01:08:30.020 --> 01:08:31.500]   And I don't know why they won't spend the money
[01:08:31.500 --> 01:08:33.460]   on a big cluster.
[01:08:33.460 --> 01:08:34.780]   The other thing is they have no idea
[01:08:34.780 --> 01:08:36.060]   how to do system level design.
[01:08:36.060 --> 01:08:38.020]   They've always lived in the world of,
[01:08:38.020 --> 01:08:39.060]   I'm competing with Intel,
[01:08:39.060 --> 01:08:41.480]   so if I make a better chip than Intel, then I'm great.
[01:08:41.480 --> 01:08:45.460]   Because software, x86, it's x86, everything's fungible.
[01:08:45.460 --> 01:08:47.220]   - I mean, NVIDIA doesn't keep it a secret
[01:08:47.220 --> 01:08:48.460]   that they're a systems company.
[01:08:48.460 --> 01:08:50.260]   So presumably they've read that in their--
[01:08:50.260 --> 01:08:52.020]   - Yeah, and so they bought this systems company
[01:08:52.020 --> 01:08:53.180]   called ZT Systems.
[01:08:53.180 --> 01:08:57.180]   But they're, you know, the whole rack scale architecture,
[01:08:57.180 --> 01:09:00.420]   which Google deployed in 2018 with the TPU v3.
[01:09:00.420 --> 01:09:04.680]   - Are there any hyperscalers that are so interested
[01:09:04.680 --> 01:09:07.460]   in AMD being successful that they're co-developing
[01:09:07.460 --> 01:09:08.300]   with them?
[01:09:08.300 --> 01:09:11.100]   - So the hyperscalers all have their own custom
[01:09:11.100 --> 01:09:14.020]   silicon efforts, but they also are helping AMD
[01:09:14.020 --> 01:09:15.060]   a lot in different ways, right?
[01:09:15.060 --> 01:09:18.500]   So Meta and Microsoft are helping them with software, right?
[01:09:18.500 --> 01:09:20.700]   Not enough that like AMD is like caught up
[01:09:20.700 --> 01:09:21.900]   or anything close to it.
[01:09:21.900 --> 01:09:22.900]   They're helping AMD a lot
[01:09:22.900 --> 01:09:24.240]   with what they should even do, right?
[01:09:24.240 --> 01:09:26.820]   So the other thing that people recognize is,
[01:09:26.820 --> 01:09:28.620]   if I have the best engineering team in the world,
[01:09:28.620 --> 01:09:30.380]   that doesn't tell me what the problem is, right?
[01:09:30.380 --> 01:09:32.220]   The problem has this, this, this, this.
[01:09:32.220 --> 01:09:33.620]   It's got these trade-offs.
[01:09:33.620 --> 01:09:35.260]   AMD doesn't know software development.
[01:09:35.260 --> 01:09:36.540]   It doesn't know model development.
[01:09:36.540 --> 01:09:39.260]   It doesn't know what inference economics look like.
[01:09:39.260 --> 01:09:41.340]   And so how do they know what trade-offs to make?
[01:09:41.340 --> 01:09:43.500]   Do I push this lever on the chip a bit harder,
[01:09:43.500 --> 01:09:45.260]   which then makes me have to back off on this?
[01:09:45.260 --> 01:09:47.580]   Or what exactly do I do, right?
[01:09:47.580 --> 01:09:48.700]   The hyperscalers are helping,
[01:09:48.700 --> 01:09:52.580]   but not enough that AMD is on the same timelines as NVIDIA.
[01:09:52.580 --> 01:09:56.980]   - How successful will AMD be in the next year on AI revenue
[01:09:56.980 --> 01:10:00.620]   and what kind of sockets might they succeed in?
[01:10:00.620 --> 01:10:03.580]   - Yes, I think they'll have a lot less success
[01:10:03.580 --> 01:10:05.520]   with Microsoft than they did this year.
[01:10:05.520 --> 01:10:10.660]   And they'll have less success than they did with Meta
[01:10:10.660 --> 01:10:11.500]   than they did this year.
[01:10:11.500 --> 01:10:13.860]   And it's because like the regulations make it so
[01:10:13.860 --> 01:10:16.580]   actually AMD's GPU is like quite good for China
[01:10:16.580 --> 01:10:18.260]   because of the way they shaped it.
[01:10:18.260 --> 01:10:21.580]   But generally I think AMD will do okay.
[01:10:21.580 --> 01:10:23.500]   They'll profit from the market.
[01:10:23.500 --> 01:10:26.740]   They just won't like go gangbusters like people are hoping.
[01:10:26.740 --> 01:10:28.620]   And they won't be a,
[01:10:28.620 --> 01:10:31.300]   their share of total revenue will fall next year.
[01:10:31.300 --> 01:10:32.260]   - Okay.
[01:10:32.260 --> 01:10:33.620]   - But they will still do really well, right?
[01:10:33.620 --> 01:10:35.820]   Billions of dollars of revenue is not nothing to stop at.
[01:10:35.820 --> 01:10:37.260]   - Let's go with the Google TPU.
[01:10:37.260 --> 01:10:42.260]   You earlier stated that it's got the second most workloads.
[01:10:42.260 --> 01:10:46.420]   It seems like by a lot, like it's firmly in second place.
[01:10:46.420 --> 01:10:49.080]   - Yeah, so this is where the whole systems
[01:10:49.080 --> 01:10:51.920]   and infrastructure thing matters a lot more.
[01:10:51.920 --> 01:10:55.360]   Each individual TPU is not that impressive.
[01:10:55.360 --> 01:10:56.520]   It's impressive, right?
[01:10:56.520 --> 01:10:57.420]   It's got good networking.
[01:10:57.420 --> 01:11:00.000]   It's got good, you know, architecture, et cetera.
[01:11:00.000 --> 01:11:01.320]   It's got okay memory, right?
[01:11:01.320 --> 01:11:03.540]   Like it's not that impressive on its own.
[01:11:03.540 --> 01:11:07.280]   But when you say, hey, if I'm spending X amount of money
[01:11:07.280 --> 01:11:10.280]   and then what's my system, Google's TPU looks amazing, right?
[01:11:10.280 --> 01:11:11.560]   So Google's engineered it for things
[01:11:11.560 --> 01:11:14.800]   that Nvidia maybe has not focused on as much, right?
[01:11:14.800 --> 01:11:17.240]   So actually their interconnects between chips
[01:11:17.240 --> 01:11:20.440]   is arguably competitive, if not better in certain aspects,
[01:11:20.440 --> 01:11:22.000]   worse in other aspects than Nvidia's.
[01:11:22.000 --> 01:11:23.680]   Because they've been doing this with Broadcom,
[01:11:23.680 --> 01:11:26.040]   you know, the world leader in networking,
[01:11:26.040 --> 01:11:27.640]   you know, building a chip with them.
[01:11:27.640 --> 01:11:30.120]   And since 2018, they've had this scale up, right?
[01:11:30.120 --> 01:11:33.360]   Nvidia's talking about GB200, NVL72,
[01:11:33.360 --> 01:11:36.640]   TPUs go to 8,000 today, right?
[01:11:36.640 --> 01:11:39.320]   And while it's not a switch, it's a point to point,
[01:11:39.320 --> 01:11:40.360]   you know, it's a little bit,
[01:11:40.360 --> 01:11:42.440]   there's some technical nuances there.
[01:11:42.440 --> 01:11:44.120]   So it's not just like those numbers
[01:11:44.120 --> 01:11:46.720]   are not all you should look at, but this is important.
[01:11:46.720 --> 01:11:47.800]   The other aspect is,
[01:11:47.800 --> 01:11:50.800]   Google's brought in water cooling for years, right?
[01:11:50.800 --> 01:11:51.760]   Nvidia only just realized
[01:11:51.760 --> 01:11:53.560]   they needed water cooling on this generation.
[01:11:53.560 --> 01:11:58.000]   And Google's brought in a level of reliability
[01:11:58.000 --> 01:12:00.360]   that Nvidia GPUs don't have.
[01:12:00.360 --> 01:12:02.120]   You know, the dirty secret is to go ask people
[01:12:02.120 --> 01:12:04.800]   what the reliability rate of GPUs is in the cloud
[01:12:04.800 --> 01:12:05.800]   or in a deployment.
[01:12:05.800 --> 01:12:08.960]   It's like, oh God, it's not, they're reliable-ish,
[01:12:08.960 --> 01:12:10.520]   like, but like, especially initially,
[01:12:10.520 --> 01:12:12.560]   you have to pull out like 5% of them.
[01:12:12.560 --> 01:12:15.400]   - Why has TPU not been more commercially successful
[01:12:15.400 --> 01:12:16.360]   outside of Google?
[01:12:16.360 --> 01:12:21.200]   - I think Google keeps a lot of their software internal
[01:12:21.200 --> 01:12:22.720]   when they should just have it be open,
[01:12:22.720 --> 01:12:23.920]   'cause like, who cares?
[01:12:23.920 --> 01:12:26.840]   You know, like that's one aspect of it.
[01:12:26.840 --> 01:12:28.840]   You know, there's a lot of software that DeepMind uses
[01:12:28.840 --> 01:12:31.600]   that just is not available to Google Cloud.
[01:12:31.600 --> 01:12:32.840]   Two-
[01:12:32.840 --> 01:12:36.000]   - Even their Google Cloud offering relative to AWS
[01:12:36.000 --> 01:12:37.400]   had that bias.
[01:12:37.400 --> 01:12:39.240]   - Yeah, yeah.
[01:12:39.240 --> 01:12:42.560]   Number two, the pricing of it is sort of,
[01:12:43.680 --> 01:12:46.480]   it's not that it's egregious on list price,
[01:12:46.480 --> 01:12:51.160]   like list price of a GPU at Google Cloud is also egregious.
[01:12:51.160 --> 01:12:55.040]   But you as a person know when I go rent a GPU,
[01:12:55.040 --> 01:12:56.600]   you know, I tell Google like, hey, like, you know,
[01:12:56.600 --> 01:12:57.760]   blah, blah, blah, you're like, okay,
[01:12:57.760 --> 01:12:59.440]   you can get around the first round of negotiations,
[01:12:59.440 --> 01:13:00.280]   get both down.
[01:13:00.280 --> 01:13:02.320]   But then you're like, well, look at this offer from Oracle
[01:13:02.320 --> 01:13:05.080]   or from Microsoft or from Amazon or from CoreWeave
[01:13:05.080 --> 01:13:07.880]   or one of the 80 Neo clouds that exist.
[01:13:07.880 --> 01:13:10.200]   And Google might not match like many of these companies,
[01:13:10.200 --> 01:13:11.720]   but like, they'll go down because they, you know,
[01:13:11.720 --> 01:13:13.160]   and then you're like, oh, well, like,
[01:13:13.160 --> 01:13:14.720]   what's the market clearing price for a,
[01:13:14.720 --> 01:13:18.320]   if I wanted an H100 for two years or a year,
[01:13:18.320 --> 01:13:19.760]   oh yeah, I could get it for like two bucks.
[01:13:19.760 --> 01:13:20.600]   - Right.
[01:13:20.600 --> 01:13:23.440]   - A little bit over versus like the $4 quoted, right?
[01:13:23.440 --> 01:13:24.760]   Whereas a TPU it's here,
[01:13:24.760 --> 01:13:26.200]   you don't know that you can get here.
[01:13:26.200 --> 01:13:28.520]   And so people see the list price and they're like, eh.
[01:13:28.520 --> 01:13:30.120]   - Do you think that'll change?
[01:13:30.120 --> 01:13:32.240]   - I don't see any reason why it would.
[01:13:32.240 --> 01:13:34.400]   And so number three is sort of,
[01:13:34.400 --> 01:13:37.280]   Google is better off using all of their TPUs internally.
[01:13:37.280 --> 01:13:40.120]   Microsoft rents very few GPUs by the way, right?
[01:13:40.120 --> 01:13:42.440]   They actually get far more profit
[01:13:42.440 --> 01:13:44.560]   from using their GPUs for internal workloads
[01:13:44.560 --> 01:13:46.160]   or using them for inference
[01:13:46.160 --> 01:13:49.920]   because the gross margin on selling tokens is 50 to 70%.
[01:13:49.920 --> 01:13:50.760]   Right?
[01:13:50.760 --> 01:13:52.520]   The gross margin on selling a GPU server
[01:13:52.520 --> 01:13:53.880]   is lower than that, right?
[01:13:53.880 --> 01:13:55.400]   So while it is like good gross margin,
[01:13:55.400 --> 01:13:56.680]   it's like, you know, it's--
[01:13:56.680 --> 01:13:59.000]   - And they've said out of the 10 billion that they've quoted,
[01:13:59.000 --> 01:14:02.360]   none of that's coming from external renting of GPUs.
[01:14:02.360 --> 01:14:07.360]   - If Gemini becomes hyper competitive as an API,
[01:14:08.120 --> 01:14:11.360]   then you indirectly will have third parties
[01:14:11.360 --> 01:14:13.800]   using the Google TPU, is that accurate?
[01:14:13.800 --> 01:14:14.640]   - Yeah, absolutely.
[01:14:14.640 --> 01:14:18.640]   Ads, search, Gemini applications,
[01:14:18.640 --> 01:14:20.200]   all of these things use TPUs.
[01:14:20.200 --> 01:14:22.640]   So it's not that like, you know, that you're not using,
[01:14:22.640 --> 01:14:25.200]   every YouTube video you upload is going through a TPU, right?
[01:14:25.200 --> 01:14:27.480]   Like, you know, it goes through other chips as well
[01:14:27.480 --> 01:14:29.160]   that they've made themselves custom chips for YouTube.
[01:14:29.160 --> 01:14:31.600]   But like, there's so much that touches a TPU,
[01:14:31.600 --> 01:14:35.440]   but you indirectly would never rent it, right?
[01:14:35.440 --> 01:14:36.840]   And that's therefore like,
[01:14:36.840 --> 01:14:38.800]   when you look at the market of renters,
[01:14:38.800 --> 01:14:41.720]   there's only one company accounts for over 70%
[01:14:41.720 --> 01:14:43.840]   of Google's revenue from TPUs as far as I understand,
[01:14:43.840 --> 01:14:45.000]   and that's Apple, right?
[01:14:45.000 --> 01:14:46.520]   And I think there's a whole long story
[01:14:46.520 --> 01:14:48.000]   around why Apple hates Nvidia.
[01:14:48.000 --> 01:14:51.920]   But, you know, that may be a story for another time, but--
[01:14:51.920 --> 01:14:55.080]   - You just did a super deep piece on Tranium.
[01:14:55.080 --> 01:14:58.320]   Why don't you do the Amazon version
[01:14:58.320 --> 01:14:59.960]   of what you just did with Google?
[01:14:59.960 --> 01:15:03.760]   - Yeah, so funnily enough, Amazon's chip is the Amazon,
[01:15:03.760 --> 01:15:06.840]   I call it the Amazon's basics TPU, right?
[01:15:06.840 --> 01:15:08.800]   And the reason I call it that is because,
[01:15:08.800 --> 01:15:11.760]   yes, it uses more silicon, yes, it uses more memory,
[01:15:11.760 --> 01:15:15.760]   yes, the network is like somewhat comparable to TPUs,
[01:15:15.760 --> 01:15:18.160]   right, it's a four by four by four Taurus.
[01:15:18.160 --> 01:15:23.160]   They just do it in a less efficient way in terms of,
[01:15:23.160 --> 01:15:25.360]   you know, hey, they're spending a lot more
[01:15:25.360 --> 01:15:27.120]   on active cables, right?
[01:15:27.120 --> 01:15:30.200]   Because they're working with Marvell and L-chip
[01:15:30.200 --> 01:15:32.320]   on their own chips versus working with Broadcom,
[01:15:32.320 --> 01:15:34.760]   the leader in networking, who then can use passive cables,
[01:15:34.760 --> 01:15:37.000]   right, 'cause their SERTIs are so strong.
[01:15:37.000 --> 01:15:40.280]   Like there's other things here, their SERTI speed is lower,
[01:15:40.280 --> 01:15:42.760]   they spend more silicon area, like there's all these things
[01:15:42.760 --> 01:15:45.880]   about the Tranium that are, you know,
[01:15:45.880 --> 01:15:47.000]   you could look at it and be like, wow,
[01:15:47.000 --> 01:15:48.800]   this would suck if it was a merchant silicon thing,
[01:15:48.800 --> 01:15:52.200]   but it doesn't because Amazon's
[01:15:52.200 --> 01:15:53.760]   not paying Broadcom margins, right?
[01:15:53.760 --> 01:15:55.800]   They're paying lower margins.
[01:15:55.800 --> 01:15:58.080]   They're not paying the margins on the HPM,
[01:15:58.080 --> 01:16:01.040]   they're paying lower margins in general, right?
[01:16:01.040 --> 01:16:03.240]   They're paying the margins to Marvell on HPM.
[01:16:03.240 --> 01:16:04.720]   You know, there's all these different things they do
[01:16:04.720 --> 01:16:08.920]   to crush the price down to where their AmazonBasics TPU,
[01:16:08.920 --> 01:16:12.280]   the Tranium 2, right, is very, very cost-effective
[01:16:12.280 --> 01:16:14.040]   to the end customer and themselves
[01:16:14.040 --> 01:16:16.840]   in terms of HBM per dollar, memory bandwidth per dollar,
[01:16:16.840 --> 01:16:19.040]   and it has this world size of 64.
[01:16:19.040 --> 01:16:21.040]   Now, Amazon can't do it in one rack,
[01:16:21.040 --> 01:16:23.400]   it actually requires them two racks to do 64,
[01:16:23.400 --> 01:16:24.680]   and the bandwidth between each chip
[01:16:24.680 --> 01:16:26.480]   is much slower than Nvidia's rack,
[01:16:26.480 --> 01:16:29.920]   and their memory per chip is lower than Nvidia's,
[01:16:29.920 --> 01:16:32.040]   and their memory bandwidth per chip is lower than Nvidia,
[01:16:32.040 --> 01:16:37.040]   but you're not paying north of $40,000 per chip
[01:16:37.040 --> 01:16:40.360]   for the server, you're paying significantly less, right?
[01:16:40.360 --> 01:16:41.840]   $5,000 per chip, right?
[01:16:41.840 --> 01:16:44.440]   Like, you know, it's like such a gulf, right, for Amazon,
[01:16:44.440 --> 01:16:45.720]   and then they pass that on to the customer, right,
[01:16:45.720 --> 01:16:46.960]   'cause when you buy an Nvidia GPU.
[01:16:46.960 --> 01:16:50.400]   So there is legitimate use cases,
[01:16:50.400 --> 01:16:53.000]   and because of this, right, Amazon and Anthropic
[01:16:53.000 --> 01:16:58.000]   have decided to make a 400,000 Tranium supercomputer, right?
[01:16:58.200 --> 01:16:59.960]   400,000 chips, right, going back to the whole
[01:16:59.960 --> 01:17:01.480]   of scaling laws dead, no,
[01:17:01.480 --> 01:17:04.240]   they're making a 400,000 chip system
[01:17:04.240 --> 01:17:06.520]   because they truly believe in this, right?
[01:17:06.520 --> 01:17:08.840]   And 400,000 chips in one location
[01:17:08.840 --> 01:17:11.980]   is not useful for serving inference, right?
[01:17:11.980 --> 01:17:14.040]   It's useful for making better models, right?
[01:17:14.040 --> 01:17:16.880]   You want your inference to be more distributed than that.
[01:17:16.880 --> 01:17:20.600]   So this is a huge, huge investment for them,
[01:17:20.600 --> 01:17:25.120]   and while technically it's not that impressive,
[01:17:25.120 --> 01:17:26.300]   there are some impressive aspects
[01:17:26.300 --> 01:17:28.200]   that I kind of glossed over,
[01:17:28.200 --> 01:17:30.240]   it is so cheap and so cost-effective
[01:17:30.240 --> 01:17:33.560]   that I think it's a decent play for Amazon.
[01:17:33.560 --> 01:17:35.040]   - Maybe just wrapping this up,
[01:17:35.040 --> 01:17:36.880]   I wanna shift a little bit
[01:17:36.880 --> 01:17:41.040]   to kind of what you see happening in 25 and 26, right?
[01:17:41.040 --> 01:17:43.940]   For example, over the last 30 days, right,
[01:17:43.940 --> 01:17:46.920]   we've seen Broadcom, you know, explode higher,
[01:17:46.920 --> 01:17:49.240]   Nvidia trade off a lot.
[01:17:49.240 --> 01:17:51.320]   I think there's about a 40% separation
[01:17:51.320 --> 01:17:53.120]   over the last 30 days, you know,
[01:17:53.120 --> 01:17:55.840]   with Broadcom being this play on custom ASICs,
[01:17:55.840 --> 01:17:57.760]   you know, people questioning whether or not
[01:17:57.760 --> 01:18:01.400]   Nvidia's got a lot of new competition, pre-training,
[01:18:01.400 --> 01:18:04.940]   you know, not improving at the rate that it was before.
[01:18:04.940 --> 01:18:08.100]   Look into your crystal ball for 25, 26.
[01:18:08.100 --> 01:18:10.080]   What are you talking to clients about,
[01:18:10.080 --> 01:18:13.440]   you know, in terms of what you think are
[01:18:13.440 --> 01:18:15.520]   kind of the things that are most misunderstood,
[01:18:15.520 --> 01:18:20.320]   best ideas, you know, in the spaces that you cover?
[01:18:20.320 --> 01:18:23.200]   - So I think a couple of the things are, you know,
[01:18:23.200 --> 01:18:26.000]   hey, Broadcom does have multiple custom ASIC wins, right?
[01:18:26.000 --> 01:18:27.760]   It's not just Google here.
[01:18:27.760 --> 01:18:30.840]   Meta's ramping up mostly still for recommendation systems,
[01:18:30.840 --> 01:18:33.400]   but their custom chips are gonna get better.
[01:18:33.400 --> 01:18:36.720]   You know, there's other players like OpenAI
[01:18:36.720 --> 01:18:38.840]   who are making a chip, right?
[01:18:38.840 --> 01:18:40.720]   You know, there's Apple who are not quite making
[01:18:40.720 --> 01:18:42.720]   the whole chip with Broadcom,
[01:18:42.720 --> 01:18:45.440]   but a small portion of it will be made with Broadcom, right?
[01:18:45.440 --> 01:18:47.660]   You know, there's a lot of wins they have, right?
[01:18:47.660 --> 01:18:50.040]   Now, these all won't hit in 25.
[01:18:50.040 --> 01:18:51.560]   Some of them will hit in 26.
[01:18:51.560 --> 01:18:53.360]   And it's, you know, it's a custom ASIC,
[01:18:53.360 --> 01:18:56.120]   so like it could be a failure and not be good,
[01:18:56.120 --> 01:18:58.280]   like Microsoft's and therefore never ramp,
[01:18:58.280 --> 01:19:00.480]   or it could be really good and like,
[01:19:00.480 --> 01:19:03.320]   or at least, you know, good price to performance
[01:19:03.320 --> 01:19:05.040]   like Amazon's and it could ramp a lot, right?
[01:19:05.040 --> 01:19:07.000]   So there are risks here,
[01:19:07.000 --> 01:19:10.040]   but Broadcom has that custom ASIC business, one.
[01:19:10.040 --> 01:19:11.880]   And two, really importantly,
[01:19:11.880 --> 01:19:14.240]   the networking side is so, so important, right?
[01:19:14.240 --> 01:19:16.920]   Yes, NVIDIA is selling a lot of networking equipment,
[01:19:16.920 --> 01:19:20.960]   but when people make their own ASIC,
[01:19:20.960 --> 01:19:21.920]   what are they gonna do, right?
[01:19:21.920 --> 01:19:23.600]   Yes, they could go to Amazon or not,
[01:19:23.600 --> 01:19:25.600]   but they could also, they also need to network
[01:19:25.600 --> 01:19:27.520]   many of these chips together.
[01:19:27.520 --> 01:19:29.760]   Or sorry, to Broadcom or not.
[01:19:29.760 --> 01:19:31.840]   They could go to Marvell or many other competitors
[01:19:31.840 --> 01:19:34.240]   out there like Alchip or NGUC.
[01:19:34.240 --> 01:19:35.920]   Like you could, you can, you,
[01:19:35.920 --> 01:19:38.680]   Broadcom is really well positioned
[01:19:38.680 --> 01:19:40.600]   to make the competitor to NVSwitch,
[01:19:40.600 --> 01:19:43.080]   which many would argue is one of NVIDIA's
[01:19:43.080 --> 01:19:45.520]   biggest competitive advantages on a hardware basis
[01:19:45.520 --> 01:19:46.840]   versus everyone else.
[01:19:46.840 --> 01:19:49.680]   And Broadcom is making a competitor to that,
[01:19:49.680 --> 01:19:51.480]   that they will seed to the market, right?
[01:19:51.480 --> 01:19:53.360]   Multiple companies will be using that.
[01:19:53.360 --> 01:19:57.080]   Not just, AMD will be using that competitor to NVSwitch,
[01:19:57.080 --> 01:19:58.080]   but they're not making it themselves
[01:19:58.080 --> 01:19:59.640]   'cause they don't have the skills, right?
[01:19:59.640 --> 01:20:01.520]   They're going to Broadcom to get it made, right?
[01:20:01.520 --> 01:20:03.680]   - So make a call for us
[01:20:03.680 --> 01:20:07.000]   as you think about the semis market today.
[01:20:07.000 --> 01:20:09.720]   You've got ARM, Broadcom, you've got NVIDIA,
[01:20:09.720 --> 01:20:11.680]   you've got AMD, et cetera.
[01:20:11.680 --> 01:20:13.840]   Does the whole market continue to elevate
[01:20:13.840 --> 01:20:16.200]   as we head into 25 and 26?
[01:20:16.200 --> 01:20:19.720]   Who's best positioned from current levels to do well?
[01:20:19.720 --> 01:20:22.000]   Who's most, you know, overestimated?
[01:20:22.000 --> 01:20:24.840]   Who's least, who's most underestimated?
[01:20:24.840 --> 01:20:28.160]   - I think, I bought Broadcom long-term,
[01:20:28.160 --> 01:20:30.200]   but like in the next six months,
[01:20:30.200 --> 01:20:32.600]   there is a bit of a slowdown in Google TPU purchases
[01:20:32.600 --> 01:20:34.000]   because they have no data center space.
[01:20:34.000 --> 01:20:34.840]   They want more.
[01:20:34.840 --> 01:20:36.760]   They just literally have no data center space to put them.
[01:20:36.760 --> 01:20:39.600]   So we actually like, you know, can see how they're like,
[01:20:39.600 --> 01:20:42.880]   there's a bit of a pause, but people may look past that.
[01:20:42.880 --> 01:20:44.600]   Beyond that, right, it's the question is like,
[01:20:44.600 --> 01:20:46.800]   who wins what custom ASIC deals, right?
[01:20:46.800 --> 01:20:48.960]   Is Marvell going to win future generations?
[01:20:48.960 --> 01:20:51.040]   Is Broadcom going to win future generations?
[01:20:51.040 --> 01:20:52.840]   How big are these generations going to be?
[01:20:52.840 --> 01:20:54.720]   Are the hyperscalers going to be able to internalize
[01:20:54.720 --> 01:20:56.040]   more and more of this or no, right?
[01:20:56.040 --> 01:20:58.920]   Like it's no secret Google's trying to leave Broadcom.
[01:20:58.920 --> 01:21:02.260]   They could succeed or they could fail, right?
[01:21:02.260 --> 01:21:03.100]   It's not just like--
[01:21:03.100 --> 01:21:04.800]   - Broaden out beyond Broadcom.
[01:21:04.800 --> 01:21:06.520]   I'm talking NVIDIA and everybody else.
[01:21:06.520 --> 01:21:10.280]   Like, you know, we've had these two massive years, right,
[01:21:10.280 --> 01:21:12.420]   of tailwinds behind this sector.
[01:21:12.420 --> 01:21:15.680]   Is 2025 a year of consolidation?
[01:21:15.680 --> 01:21:18.980]   Do you think it's another year that the sector does well?
[01:21:18.980 --> 01:21:20.040]   Just kind of--
[01:21:20.040 --> 01:21:22.360]   - Yeah, I think the plans for hyperscalers
[01:21:22.360 --> 01:21:24.640]   are pretty firm on,
[01:21:24.640 --> 01:21:26.760]   they're going to spend a crapload more next year, right?
[01:21:26.760 --> 01:21:29.560]   And therefore the ecosystem of networking players,
[01:21:29.560 --> 01:21:33.560]   of ASIC vendors, of systems vendors is going to do well,
[01:21:33.560 --> 01:21:36.320]   whether it be NVIDIA or Marvell or Broadcom or AMD,
[01:21:36.320 --> 01:21:39.020]   or, you know, generally, you know, some better than others.
[01:21:39.020 --> 01:21:41.420]   The real question that people should be looking out to
[01:21:41.420 --> 01:21:45.000]   is 2026, does the spend continue, right?
[01:21:45.000 --> 01:21:45.840]   We are not good.
[01:21:45.840 --> 01:21:46.900]   The growth rate for NVIDIA
[01:21:46.900 --> 01:21:48.560]   is going to be stupendous next year, right?
[01:21:48.560 --> 01:21:51.000]   And that's going to drag the entire component supply chain up.
[01:21:51.000 --> 01:21:52.840]   It's going to bring so many people with them.
[01:21:52.840 --> 01:21:55.800]   But 2026 is like where the reckoning comes, right?
[01:21:55.800 --> 01:22:00.280]   You know, will people keep spending like this?
[01:22:00.280 --> 01:22:01.960]   And it's all points to where,
[01:22:01.960 --> 01:22:03.560]   will the models continue to get better?
[01:22:03.560 --> 01:22:05.200]   Because if they don't continue to get better,
[01:22:05.200 --> 01:22:07.920]   in my opinion, we'll get better faster, in fact, next year,
[01:22:07.920 --> 01:22:09.580]   then there will be a big, you know,
[01:22:09.580 --> 01:22:11.620]   sort of clearing event, right?
[01:22:11.620 --> 01:22:13.420]   But that's not next year, right?
[01:22:13.420 --> 01:22:14.660]   You know, the other aspect I would say
[01:22:14.660 --> 01:22:17.700]   is there is consolidation in the Neo cloud market, right?
[01:22:17.700 --> 01:22:19.580]   There are 80 Neo clouds that we're tracking,
[01:22:19.580 --> 01:22:23.300]   that we talk to, that we see how many GPUs they have, right?
[01:22:23.300 --> 01:22:25.400]   The problem is nowadays,
[01:22:25.400 --> 01:22:27.700]   if you look at rental prices for H100s,
[01:22:27.700 --> 01:22:29.180]   they're tanking, right?
[01:22:29.180 --> 01:22:31.060]   Not just at these Neo clouds, right?
[01:22:31.060 --> 01:22:32.820]   Where you can, you used to have to pay, you know,
[01:22:32.820 --> 01:22:35.420]   do four-year deals and prepay 25%.
[01:22:35.420 --> 01:22:38.320]   You'd sign a venture ground and you'd buy a cluster
[01:22:38.320 --> 01:22:39.160]   and that's about it, right?
[01:22:39.160 --> 01:22:40.400]   You'd rent one cluster, right?
[01:22:40.400 --> 01:22:43.320]   Nowadays, you can get three-month, six-month deals
[01:22:43.320 --> 01:22:45.480]   at way better pricing than even the four-month
[01:22:45.480 --> 01:22:47.000]   or the four-year, three-year deals
[01:22:47.000 --> 01:22:49.160]   that you used to have for Hopper, right?
[01:22:49.160 --> 01:22:51.520]   And on top of that, it's not just through the Neo clouds,
[01:22:51.520 --> 01:22:54.480]   Amazon's pricing for, you know, on-demand GPUs is falling.
[01:22:54.480 --> 01:22:56.480]   Now it's still over, it's like still really expensive,
[01:22:56.480 --> 01:22:59.420]   relatively, but like pricing is falling really fast.
[01:22:59.420 --> 01:23:01.560]   80 Neo clouds are not gonna survive.
[01:23:01.560 --> 01:23:04.160]   Maybe five to 10 will.
[01:23:04.160 --> 01:23:07.420]   And that's because five of those are sovereign, right?
[01:23:07.420 --> 01:23:08.860]   And then the other five are like actually
[01:23:08.860 --> 01:23:09.700]   like market competitive.
[01:23:09.700 --> 01:23:13.260]   - What percentage of the industry AI revenues
[01:23:13.260 --> 01:23:16.140]   have come from those Neo clouds that may not survive?
[01:23:16.140 --> 01:23:19.040]   - Yeah, so roughly you can say hyperscalers
[01:23:19.040 --> 01:23:22.620]   are 50-ish percent of revenue, 50 to 60%.
[01:23:22.620 --> 01:23:26.360]   And the rest of it is Neo cloud/sovereign AI
[01:23:26.360 --> 01:23:28.860]   because enterprises purchases of GPU clusters
[01:23:28.860 --> 01:23:31.460]   is still quite low and it ends up being better for them
[01:23:31.460 --> 01:23:33.940]   to just like outsource it to Neo clouds.
[01:23:33.940 --> 01:23:35.860]   When they can like get through the security,
[01:23:35.860 --> 01:23:37.160]   which they can for certain companies,
[01:23:37.160 --> 01:23:38.600]   like Corby even.
[01:23:38.600 --> 01:23:42.400]   - Is there a scenario where in 2026,
[01:23:42.400 --> 01:23:47.400]   where you see industry volumes actually down versus 2025
[01:23:47.400 --> 01:23:55.200]   or Nvidia volumes actually down meaningfully from 2025?
[01:23:55.200 --> 01:23:59.180]   - So when you look at custom ASIC designs that are coming,
[01:23:59.180 --> 01:24:01.960]   as well as Nvidia's chips that are coming,
[01:24:01.960 --> 01:24:06.960]   the revenue, the content in each chip is exploding.
[01:24:06.960 --> 01:24:09.960]   The cost to make Blackwell is North of 2X
[01:24:09.960 --> 01:24:11.720]   that of the cost to make Hopper, right?
[01:24:11.720 --> 01:24:13.560]   So Nvidia can make the same,
[01:24:13.560 --> 01:24:15.120]   obviously they're cutting margins a little bit,
[01:24:15.120 --> 01:24:17.240]   but Nvidia can ship the same volumes
[01:24:17.240 --> 01:24:18.680]   and still grow a ton, right?
[01:24:18.680 --> 01:24:20.920]   - So rather than unit volumes,
[01:24:20.920 --> 01:24:25.800]   is there a scenario where industry revenues are down in '26
[01:24:25.800 --> 01:24:28.920]   or Nvidia revenues are down in '26?
[01:24:28.920 --> 01:24:32.600]   - The reckoning is do models continue
[01:24:32.600 --> 01:24:34.200]   to get much faster, better?
[01:24:34.200 --> 01:24:36.720]   And will hyperscalers,
[01:24:36.720 --> 01:24:38.600]   are they okay with taking their free cash flow to zero?
[01:24:38.600 --> 01:24:40.600]   I think they are, by the way.
[01:24:40.600 --> 01:24:42.920]   I think Meta and Microsoft may even take
[01:24:42.920 --> 01:24:46.700]   their free cash flows close to zero and just spent.
[01:24:46.700 --> 01:24:49.320]   But then that's only if models continue to get better,
[01:24:49.320 --> 01:24:50.160]   that's A.
[01:24:50.160 --> 01:24:52.400]   And then B, are we going to have this huge influx
[01:24:52.400 --> 01:24:55.000]   of capital from people we haven't had it yet from?
[01:24:55.000 --> 01:24:57.960]   The Middle East, the sovereign wealth funds in Singapore
[01:24:57.960 --> 01:25:01.800]   and Nordics and Canadian pension fund and all these folks,
[01:25:01.800 --> 01:25:04.160]   they can write really big checks.
[01:25:04.160 --> 01:25:06.200]   They haven't, but they could.
[01:25:06.200 --> 01:25:09.060]   And if things continue to get better,
[01:25:09.060 --> 01:25:13.680]   I truly do believe that OpenAI and XAI and Anthropic
[01:25:13.680 --> 01:25:15.560]   will continue to raise more and more money
[01:25:15.560 --> 01:25:17.920]   and keep this game going of not just,
[01:25:17.920 --> 01:25:19.960]   "Hey, where's the revenue for OpenAI?
[01:25:19.960 --> 01:25:22.160]   Well, it's 8 billion and it might double or whatever,
[01:25:22.160 --> 01:25:23.840]   or even more next year."
[01:25:23.840 --> 01:25:25.160]   And that's their spend, no, no, no.
[01:25:25.160 --> 01:25:26.360]   Like they have to raise more money
[01:25:26.360 --> 01:25:28.040]   to spend significantly more.
[01:25:28.040 --> 01:25:29.240]   And that keeps the engine rolling
[01:25:29.240 --> 01:25:31.040]   because once one of them spends,
[01:25:31.040 --> 01:25:33.660]   Elon is forcing everyone to spend more actually, right?
[01:25:33.660 --> 01:25:36.680]   With his cluster because, and his plans,
[01:25:36.680 --> 01:25:38.480]   because everybody's like, "Well, we can't get outscaled
[01:25:38.480 --> 01:25:40.400]   by Elon, we have to spend more."
[01:25:40.400 --> 01:25:41.240]   Right?
[01:25:41.240 --> 01:25:42.280]   And so there's sort of a game of chicken there too.
[01:25:42.280 --> 01:25:44.360]   We're like, "Oh, they're buying this?
[01:25:44.360 --> 01:25:46.060]   We have to match them or go bigger
[01:25:46.060 --> 01:25:47.360]   because it is a game of scale."
[01:25:47.360 --> 01:25:50.760]   So, you know, in sort of Pascal's wager sense, right?
[01:25:50.760 --> 01:25:53.400]   If I underspend, that's just the worst scenario ever.
[01:25:53.400 --> 01:25:54.760]   And I'm like the worst CEO ever
[01:25:54.760 --> 01:25:56.200]   of the most profitable business ever.
[01:25:56.200 --> 01:25:59.360]   But if I overspend, yeah, shareholders will be mad,
[01:25:59.360 --> 01:26:00.440]   but it's fine, right?
[01:26:00.440 --> 01:26:02.400]   It's, you know, $20 billion, $50 billion.
[01:26:02.400 --> 01:26:03.760]   You can paint that either way though,
[01:26:03.760 --> 01:26:06.320]   'cause if that becomes the reasoning for doing it,
[01:26:06.320 --> 01:26:10.240]   you're more, the probability of overshooting goes up.
[01:26:10.240 --> 01:26:11.080]   For sure.
[01:26:11.080 --> 01:26:12.840]   And every bubble ever we overshoot.
[01:26:12.840 --> 01:26:16.320]   And you know, to me, it, you know,
[01:26:16.320 --> 01:26:20.200]   you said it all hangs on models improving.
[01:26:20.200 --> 01:26:22.600]   I would take it a step further, you know,
[01:26:22.600 --> 01:26:26.320]   and go back to what Satya said to us last week.
[01:26:26.320 --> 01:26:29.560]   It all comes down ultimately to the revenues
[01:26:29.560 --> 01:26:31.240]   that are generated by the people
[01:26:31.240 --> 01:26:34.400]   who are making the purchases of the GPUs, right?
[01:26:34.400 --> 01:26:36.360]   Like he said last week,
[01:26:36.360 --> 01:26:40.200]   I'm gonna buy a certain amount every single year,
[01:26:40.200 --> 01:26:42.520]   and it's going to be related to the revenues
[01:26:42.520 --> 01:26:45.080]   that I'm able to generate in that year
[01:26:45.080 --> 01:26:46.280]   or the next couple of years.
[01:26:46.280 --> 01:26:49.400]   So like, they're not gonna spend way ahead
[01:26:49.400 --> 01:26:51.120]   of where those revenues are.
[01:26:51.120 --> 01:26:52.840]   So he's looking at what, you know,
[01:26:52.840 --> 01:26:55.080]   he had 10 billion in revenues this year.
[01:26:55.080 --> 01:26:57.080]   He knows the growth rate associated
[01:26:57.080 --> 01:26:58.520]   with those inference revenues,
[01:26:58.520 --> 01:27:01.480]   and they're making, he and Amy are making some forecast
[01:27:01.480 --> 01:27:03.040]   as to what they can afford to spend.
[01:27:03.040 --> 01:27:04.880]   I think Zuckerberg's doing the same thing.
[01:27:04.880 --> 01:27:07.000]   I think Sundar's doing the same thing.
[01:27:07.000 --> 01:27:09.560]   And so if you assume they're acting rationally,
[01:27:09.560 --> 01:27:11.840]   it's not just the models improving,
[01:27:11.840 --> 01:27:15.080]   it's also the rate of adoption of the underlying,
[01:27:15.080 --> 01:27:17.640]   you know, enterprises who are using their services.
[01:27:17.640 --> 01:27:19.640]   It's the rate of adoption of consumers
[01:27:19.640 --> 01:27:21.680]   and what consumers are willing to pay
[01:27:21.680 --> 01:27:24.720]   to use ChatGPT or to use Claude
[01:27:24.720 --> 01:27:26.520]   or to use these other services.
[01:27:26.520 --> 01:27:30.120]   So, you know, if you think that infrastructure expenses
[01:27:30.120 --> 01:27:32.320]   are going to grow at 30% a year,
[01:27:32.320 --> 01:27:33.880]   then I think you have to believe
[01:27:33.880 --> 01:27:36.600]   that the underlying inference revenues, right,
[01:27:36.600 --> 01:27:38.880]   both on the consumer side and the enterprise side
[01:27:38.880 --> 01:27:41.760]   are gonna grow somewhere in that range as well.
[01:27:41.760 --> 01:27:43.640]   - There is definitely an element of spend ahead though,
[01:27:43.640 --> 01:27:44.480]   right? - For sure.
[01:27:44.480 --> 01:27:46.320]   - And it's point in time spend versus, you know,
[01:27:46.320 --> 01:27:47.800]   what do I think revenue will be
[01:27:47.800 --> 01:27:49.640]   for the next five years for the server, right?
[01:27:49.640 --> 01:27:51.480]   So I think there is an element of that for sure,
[01:27:51.480 --> 01:27:53.080]   but absolutely, right?
[01:27:53.080 --> 01:27:56.120]   Models, the whole point is models getting better
[01:27:56.120 --> 01:27:58.120]   is what generates more revenue, right?
[01:27:58.120 --> 01:27:59.080]   And it gets deployed.
[01:27:59.080 --> 01:28:00.880]   So I think that's, I'm in agreement,
[01:28:00.880 --> 01:28:05.600]   but people are definitely spending ahead of what's charted.
[01:28:05.600 --> 01:28:06.440]   - Fair enough. - Well, that's what
[01:28:06.440 --> 01:28:08.040]   makes it spicy.
[01:28:08.040 --> 01:28:09.720]   You know, it's fun to have you here.
[01:28:09.720 --> 01:28:12.000]   I mean, you know, a fellow analyst,
[01:28:12.000 --> 01:28:13.840]   you guys do a lot of digging.
[01:28:13.840 --> 01:28:17.120]   Congratulations on the success of your business.
[01:28:17.120 --> 01:28:21.560]   You know, I think you add a lot of important information
[01:28:21.560 --> 01:28:22.920]   to the entire ecosystem.
[01:28:22.920 --> 01:28:24.080]   You know, one of the things I think
[01:28:24.080 --> 01:28:25.720]   about the wall of worry, Bill,
[01:28:25.720 --> 01:28:27.600]   is the fact that we're all talking about
[01:28:27.600 --> 01:28:29.920]   and looking for, right, the bubble.
[01:28:29.920 --> 01:28:31.720]   Sometimes that's what prevents the bubble
[01:28:31.720 --> 01:28:32.880]   from actually happening.
[01:28:32.880 --> 01:28:36.800]   But, you know, as both an investor and an analyst,
[01:28:36.800 --> 01:28:39.120]   you know, I look at this and I say,
[01:28:39.120 --> 01:28:41.920]   there are definitely people out there who are spending
[01:28:41.920 --> 01:28:45.120]   who don't have commensurate revenues, to your point.
[01:28:45.120 --> 01:28:47.880]   They're spending way ahead.
[01:28:47.880 --> 01:28:50.240]   On the other hand, and frankly, you know,
[01:28:50.240 --> 01:28:51.640]   we heard that from Satya last week.
[01:28:51.640 --> 01:28:53.640]   He said, listen, I've got the revenues.
[01:28:53.640 --> 01:28:55.480]   I've said what my revenues are.
[01:28:55.480 --> 01:28:58.280]   I haven't heard that from everybody else, right?
[01:28:58.280 --> 01:29:02.680]   And so it'll be interesting to see in 2025
[01:29:02.680 --> 01:29:04.080]   who shows up with the revenues.
[01:29:04.080 --> 01:29:06.720]   I think you already see some of these smaller
[01:29:06.720 --> 01:29:09.800]   second and third tier models, changing business model,
[01:29:09.800 --> 01:29:14.120]   falling aside, no longer engaged in the arms race,
[01:29:14.120 --> 01:29:16.120]   you know, of investment here.
[01:29:16.120 --> 01:29:19.040]   I think that's part of the creative destructive process,
[01:29:19.040 --> 01:29:20.640]   but it's been fun having you on.
[01:29:20.640 --> 01:29:21.720]   - Yeah, thank you so much, Dale.
[01:29:21.720 --> 01:29:22.560]   I really appreciate it.
[01:29:22.560 --> 01:29:25.240]   - Yeah, fun having you here in person, Bill.
[01:29:25.240 --> 01:29:27.320]   And until next year.
[01:29:27.320 --> 01:29:28.160]   - Awesome, thank you.
[01:29:28.160 --> 01:29:29.000]   - Take care.
[01:29:29.000 --> 01:29:31.560]   (upbeat music)
[01:29:31.560 --> 01:29:39.480]   - As a reminder to everybody,
[01:29:39.480 --> 01:29:41.720]   just our opinions, not investment advice.

