
[00:00:00.000 --> 00:00:03.280]   And I wonder for people in their 20s, if they like shouldn't go to San Francisco.
[00:00:03.280 --> 00:00:07.520]   The entrepreneurs are held in excessively high regard, in my view,
[00:00:07.520 --> 00:00:12.400]   and San Francisco doesn't really encourage the pursuit of really deep technical depth.
[00:00:12.400 --> 00:00:18.000]   I guess my general view is most products and most businesses, things can just be done much better.
[00:00:18.000 --> 00:00:21.920]   And I think moats are typically kind of overrated.
[00:00:21.920 --> 00:00:28.080]   The businesses that we serve, which is in rough terms, 1% of the global economy.
[00:00:28.080 --> 00:00:30.080]   I mean, that's about a trillion dollars a year.
[00:00:30.080 --> 00:00:32.960]   That then makes us like really terrified of outages.
[00:00:32.960 --> 00:00:37.840]   We're all trying to impress upon people at Stripe the importance of multi-decadal abstractions.
[00:00:37.840 --> 00:00:42.160]   I think people sometimes respond to that thinking that that's implausibly ambitious.
[00:00:42.160 --> 00:00:45.840]   But no, I think that's actually just what happens when you get this stuff right.
[00:00:45.840 --> 00:00:52.160]   Okay, today I have the pleasure of speaking with Patrick Collison, CEO of Stripe.
[00:00:52.160 --> 00:00:54.320]   Patrick, first question.
[00:00:54.320 --> 00:00:58.800]   You have an excellent compilation of advice on your blog for people 10 to 20.
[00:00:58.800 --> 00:01:03.200]   And you say there that once you turn 35, you'll write some for people in their 20s.
[00:01:03.200 --> 00:01:06.400]   What advice do you have for us now, the people in our 20s now?
[00:01:06.400 --> 00:01:08.640]   When's it coming?
[00:01:08.640 --> 00:01:10.400]   I haven't really thought about that.
[00:01:10.400 --> 00:01:14.640]   The one I've been wondering about recently is,
[00:01:14.640 --> 00:01:23.280]   you know, I said for that advice for people in their teens, they should go to San Francisco.
[00:01:23.600 --> 00:01:28.160]   And I wonder for people in their 20s, if they like shouldn't go to San Francisco.
[00:01:28.160 --> 00:01:30.240]   And I mean, glib.
[00:01:30.240 --> 00:01:33.920]   And I think there's a significant set of people who should, in fact, go to San Francisco.
[00:01:33.920 --> 00:01:43.760]   But the thing that I wonder about is, there is a set of career paths that I think some
[00:01:43.760 --> 00:01:50.400]   set of people ought to pursue and would derive most fulfillment from pursuing.
[00:01:51.440 --> 00:02:00.560]   And that are really valuable for the world, if pursued, that require accumulating a lot
[00:02:00.560 --> 00:02:07.600]   of expertise and really studying a domain in tremendous depth.
[00:02:07.600 --> 00:02:13.360]   And I think San Francisco valorizes, and look, this is also San Francisco's great virtue.
[00:02:13.360 --> 00:02:19.760]   San Francisco valorizes a kind of striking out on your own, iconoclastically dismissing
[00:02:19.760 --> 00:02:28.720]   the sort of received wisdom and the founding archetypes and lore of the Steve Jobs and
[00:02:28.720 --> 00:02:30.400]   the Bill Gates and all the rest.
[00:02:30.400 --> 00:02:33.040]   And I'm way less successful than those people.
[00:02:33.040 --> 00:02:37.120]   But to some extent, Stripe, as much as it fits a pattern, is an instance of that pattern.
[00:02:37.120 --> 00:02:39.920]   And look, that's great.
[00:02:39.920 --> 00:02:42.400]   And I'm kind of happy that that phenomenon exists in the world.
[00:02:42.400 --> 00:02:50.480]   But I don't think that-- the world needs lots of other things, right?
[00:02:50.480 --> 00:02:55.280]   And I don't think San Francisco particularly-- I mean, I'm, again, using San Francisco as
[00:02:55.280 --> 00:02:58.320]   a kind of metonym for a cultural orientation.
[00:02:58.320 --> 00:03:06.720]   But I think that San Francisco doesn't really encourage, yeah, the pursuit of really deep
[00:03:06.720 --> 00:03:08.480]   technical depth.
[00:03:09.040 --> 00:03:12.160]   And we're recording this in South San Francisco.
[00:03:12.160 --> 00:03:19.440]   And South San Francisco is most noteworthy in the corporate world for, of course, being
[00:03:19.440 --> 00:03:21.840]   the headquarters of Genentech.
[00:03:21.840 --> 00:03:28.160]   And Genentech was co-founded by Bob Swanson and Herb Boyer.
[00:03:28.160 --> 00:03:33.040]   And they produced cheap insulin for the first time with recombinant DNA.
[00:03:34.240 --> 00:03:38.160]   Like, Herb Boyer couldn't have done that at age 23.
[00:03:38.160 --> 00:03:44.960]   Herb Boyer first had to accumulate all of the knowledge and the skills required to be
[00:03:44.960 --> 00:03:48.000]   able to invent that over the course of a multi-decade career.
[00:03:48.000 --> 00:03:52.160]   And then, I don't know what age he was when he finally went and invented it.
[00:03:52.160 --> 00:03:53.520]   But he was not in his 20s.
[00:03:53.520 --> 00:04:02.800]   And I feel San Francisco perhaps doesn't culturally encourage one to become Herb Boyer.
[00:04:02.800 --> 00:04:07.440]   Or yesterday at the time of recording this podcast, Patrick Hsu, one of the co-founders
[00:04:07.440 --> 00:04:11.360]   of ARC, which maybe we'll speak about later in the show.
[00:04:11.360 --> 00:04:14.720]   This is a biomedical research organization we started a few years ago.
[00:04:14.720 --> 00:04:25.440]   He announced this new phenomenon of bridge editing, which is a new recombinase where
[00:04:25.440 --> 00:04:29.360]   you can insert DNA into a genome.
[00:04:29.360 --> 00:04:33.040]   And it's pretty early, but it might turn out to be quite consequential.
[00:04:33.040 --> 00:04:40.960]   And in order to do something like that, you have to study for a long time and just acquire
[00:04:40.960 --> 00:04:45.680]   a lot of basic and not so basic technical skills.
[00:04:45.680 --> 00:04:48.320]   And so the thing-- and I don't quite know how to synthesize it yet.
[00:04:48.320 --> 00:04:54.080]   But as I think about advice for people in their 20s, look, I'm not going to normatively
[00:04:54.080 --> 00:05:01.200]   pretend or presume to know in which direction one should go in one's life.
[00:05:01.200 --> 00:05:05.040]   And obviously, there are successful examples of basically every strategy.
[00:05:05.040 --> 00:05:07.120]   And I'm really glad you're doing what you're doing.
[00:05:07.120 --> 00:05:08.080]   At what age?
[00:05:08.080 --> 00:05:08.560]   23.
[00:05:08.560 --> 00:05:09.040]   23.
[00:05:09.040 --> 00:05:10.560]   So that's--
[00:05:10.560 --> 00:05:11.920]   Quite a podcast, isn't it?
[00:05:11.920 --> 00:05:13.520]   I'm not inventing recombinant DNA here.
[00:05:13.520 --> 00:05:21.200]   But look, I think information dissemination is a really valuable thing in the world.
[00:05:21.200 --> 00:05:34.000]   And the guy who last I heard was in the lead for Nat's Scroll Prize, Nash told me, learned
[00:05:34.000 --> 00:05:37.520]   about the Scroll Prize listening to your podcast, right?
[00:05:37.520 --> 00:05:43.040]   So I think increasing the catalytic surface area of certain kinds of information is a
[00:05:43.040 --> 00:05:43.760]   valuable thing in the world.
[00:05:43.760 --> 00:05:46.400]   So I'm very glad you're presenting the podcast.
[00:05:46.400 --> 00:05:49.840]   Anyway, I don't presume to know what people should do with their lives, obviously.
[00:05:49.840 --> 00:05:55.120]   But I wonder, in as much as I'm trying to give advice, and especially maybe if they're
[00:05:55.120 --> 00:05:59.680]   reading my advice and not someone else's advice, maybe they're thinking about career paths
[00:05:59.680 --> 00:06:05.120]   that look directionally like mine, I think my advice might be, maybe you should do something
[00:06:05.120 --> 00:06:08.640]   like what I did or I'm trying to do.
[00:06:08.640 --> 00:06:10.560]   But there are other paths as well.
[00:06:10.560 --> 00:06:14.400]   And I think a lot of really important invention in the world and a lot of the things that
[00:06:14.400 --> 00:06:19.680]   I'm most happy are happening actually require a very different trajectory.
[00:06:19.680 --> 00:06:25.840]   And I think there are counterfactual versions of my life where I pursued that path and,
[00:06:25.840 --> 00:06:27.200]   well, who knows how well it would have worked.
[00:06:27.200 --> 00:06:31.040]   And anyway, last point in this.
[00:06:31.040 --> 00:06:33.680]   And San Francisco is just very status-oriented, I feel, in this way.
[00:06:33.680 --> 00:06:37.920]   I mean, everything is status-oriented, so that's kind of tautological.
[00:06:37.920 --> 00:06:46.960]   But maybe really what I'm saying is, I feel San Francisco, the entrepreneurs are held
[00:06:46.960 --> 00:06:49.280]   in excessively high regard, in my view.
[00:06:49.280 --> 00:06:52.160]   And look, I guess I like entrepreneurs.
[00:06:52.160 --> 00:07:01.520]   And I think entrepreneurs as an aggregate group in the world, all the companies built
[00:07:01.520 --> 00:07:03.520]   in Stripe, I think are great.
[00:07:03.520 --> 00:07:12.880]   But there's just a strange version of it in San Francisco that I think should not be
[00:07:12.880 --> 00:07:14.000]   people's only fixation.
[00:07:14.000 --> 00:07:14.240]   Yeah.
[00:07:14.240 --> 00:07:17.040]   I mean, what I like about this and what I like about you is just you have this sort
[00:07:17.040 --> 00:07:20.720]   of sense of contrarianism of the things people are expecting to hear from you in any given
[00:07:20.720 --> 00:07:23.520]   moment, you just really want to just tell them the opposite.
[00:07:23.520 --> 00:07:28.480]   I don't even know, I feel like when EA was a little bit more popular, you were like,
[00:07:28.480 --> 00:07:30.160]   "Here's the problems, here's why progress is important."
[00:07:30.160 --> 00:07:32.960]   And when it was down in its depths, like, "Hey, guys, pay attention."
[00:07:32.960 --> 00:07:35.680]   But on this particular piece of advice...
[00:07:35.680 --> 00:07:41.920]   Well, Michael Nielsen says that every field in science has way too many adherents or way
[00:07:41.920 --> 00:07:46.560]   too few, but the market is almost never in the right equilibrium.
[00:07:46.560 --> 00:07:47.760]   And I think something like that might be...
[00:07:47.760 --> 00:07:49.840]   I mean, I think the reflexive...
[00:07:49.840 --> 00:07:52.720]   In a contrarian way, I'll say that.
[00:07:52.720 --> 00:07:57.120]   I think reflexive contrarianism, for the sake of it, is also tired.
[00:07:57.120 --> 00:08:04.480]   And if you're just contrarian to the prevailing mood, then you're just following the prevailing
[00:08:04.480 --> 00:08:07.360]   mood, but with a sign bit inversion or something.
[00:08:07.360 --> 00:08:08.800]   So I don't endorse that either.
[00:08:08.800 --> 00:08:13.040]   But I think the herd is a really powerful phenomenon.
[00:08:13.040 --> 00:08:16.800]   Actually, one of the learnings of my adult life has been that it's very...
[00:08:16.800 --> 00:08:22.000]   I mean, everyone knows and kind of says or frequently hears that you should be very wary
[00:08:22.000 --> 00:08:26.640]   of following the prevailing tides and moods and winds and everything.
[00:08:26.640 --> 00:08:28.160]   But it's freaking hard to do in practice.
[00:08:28.160 --> 00:08:32.800]   So what practically does that look like to hone your craft in any of these disciplines
[00:08:32.800 --> 00:08:33.840]   that take a long time?
[00:08:33.840 --> 00:08:37.680]   I mean, you've spoken and tweeted about some of the problems with modern universities.
[00:08:37.680 --> 00:08:42.000]   Is that still the de facto path if you want to be the great biologist that Ark hires or
[00:08:42.000 --> 00:08:42.400]   something?
[00:08:42.400 --> 00:08:43.920]   Yeah.
[00:08:43.920 --> 00:08:47.920]   I mean, well, in many domains, I don't know, right?
[00:08:47.920 --> 00:08:54.160]   So in hardware, which is not a small domain, most things in the world involve stuff and
[00:08:54.160 --> 00:08:58.560]   things, and I just have no facility with or experience with doing things in hardware.
[00:08:58.560 --> 00:09:04.640]   And so if you wanted to become a super skilled practitioner there, what's the best career
[00:09:04.640 --> 00:09:04.880]   path?
[00:09:04.880 --> 00:09:05.600]   I don't know.
[00:09:05.600 --> 00:09:11.360]   Maybe it's to drop out and join SpaceX or something.
[00:09:11.360 --> 00:09:19.760]   I'm not necessarily endorsing just pursuing the most establishment and credential-oriented
[00:09:19.760 --> 00:09:20.000]   path.
[00:09:22.000 --> 00:09:25.600]   I think people should try to find the gradient of maximal learning in whatever it is they
[00:09:25.600 --> 00:09:26.320]   care most about.
[00:09:26.320 --> 00:09:32.240]   And yeah, the question then is what that is.
[00:09:32.240 --> 00:09:40.480]   For biology, look, not that I'm a biologist, but it is very clear that in order to do really
[00:09:40.480 --> 00:09:43.520]   good work, there are a lot of bench skills.
[00:09:43.520 --> 00:09:49.840]   Well, there are a lot of bench skills one has to acquire, and then there just is a lot
[00:09:49.840 --> 00:09:59.680]   of actual specific knowledge where the body, well, any kind of life wasn't designed with
[00:09:59.680 --> 00:10:03.440]   neat fundamental principles the way that maybe physics was.
[00:10:03.440 --> 00:10:08.640]   A lot of it is obviously evolved and contingent and messy and complicated and all the rest.
[00:10:08.640 --> 00:10:11.760]   And so there is a lot of just specific factual stuff to learn.
[00:10:11.760 --> 00:10:21.440]   And I think for those two reasons, I think there are very few successful, pure autodidacts
[00:10:21.440 --> 00:10:28.480]   in biology where you, at some point, in virtually every case that I'm aware of, have to have
[00:10:28.480 --> 00:10:37.920]   had direct experience in and with a top lab where you're seeing how people actually do
[00:10:37.920 --> 00:10:39.760]   it in practice.
[00:10:39.760 --> 00:10:44.160]   And actually, maybe this also ties back to some of what we were discussing previously,
[00:10:44.160 --> 00:10:48.240]   where to your question about the founders and what they learn from each other and so
[00:10:48.240 --> 00:10:48.880]   on.
[00:10:48.880 --> 00:10:56.560]   I think there's an interesting book, Apprentice to Genius, that follows, I think it's three
[00:10:56.560 --> 00:10:57.120]   or four.
[00:10:57.120 --> 00:10:59.280]   It's three generations of scientists.
[00:10:59.280 --> 00:11:03.280]   So someone who mentored somebody else, who in turn mentored another scientist.
[00:11:03.280 --> 00:11:05.600]   And they were all extremely successful.
[00:11:06.160 --> 00:11:14.160]   And the book is kind of this description of what they all did, but also this kind of reflection
[00:11:14.160 --> 00:11:16.480]   on what is it that was transferred?
[00:11:16.480 --> 00:11:24.320]   And for example, one thing it describes is, well, one of the most important and subtle
[00:11:24.320 --> 00:11:26.560]   questions in science is problem selection.
[00:11:26.560 --> 00:11:27.760]   Just how do you choose what to work on?
[00:11:27.760 --> 00:11:29.760]   No one tells you what to do.
[00:11:29.760 --> 00:11:32.960]   And you do have to answer this question multiple times.
[00:11:33.040 --> 00:11:36.480]   With a company, in some sense, you just have to decide once.
[00:11:36.480 --> 00:11:39.840]   And then it's kind of, well, maybe it's an iterative process from there.
[00:11:39.840 --> 00:11:42.800]   Whereas in science, you're frequently pursuing completely new problems.
[00:11:42.800 --> 00:11:48.480]   And of course, you need to choose something that's sufficiently important and hard that
[00:11:48.480 --> 00:11:50.080]   it would be important if you succeeded.
[00:11:50.080 --> 00:11:54.640]   But also that it's not so intractable that you can't actually make any progress.
[00:11:54.640 --> 00:12:01.360]   And so the book describes how this is part of what the mentees describe that they learn
[00:12:01.360 --> 00:12:02.160]   from their mentors.
[00:12:02.720 --> 00:12:09.680]   Another thing they talk about is just learning about high standards and what high standards
[00:12:09.680 --> 00:12:10.400]   actually are.
[00:12:10.400 --> 00:12:16.880]   And when I talk to people in other domains, this is so frequently the thing that I hear
[00:12:16.880 --> 00:12:25.360]   from them, that when they worked with X person or Y organization or in Z environment or whatever,
[00:12:25.360 --> 00:12:28.320]   that they learned what great actually is.
[00:12:28.320 --> 00:12:34.240]   And that just permanently changed their sense for what their own standard for their work
[00:12:34.240 --> 00:12:34.720]   ought to be.
[00:12:34.720 --> 00:12:47.120]   And so maybe one version of what people in their 20s should do is get some ideas to domains
[00:12:47.120 --> 00:12:48.560]   you're interested in or care about.
[00:12:48.560 --> 00:12:52.240]   But then figure out where can you learn the highest standards?
[00:12:52.240 --> 00:12:53.760]   Where are the highest standards embodied?
[00:12:53.760 --> 00:12:57.600]   And where can you go and experience that firsthand?
[00:12:57.600 --> 00:13:01.360]   Before we get back to Stripe and ARC Institute and everything, I want to just touch on the
[00:13:01.360 --> 00:13:02.480]   progress study stuff for a second.
[00:13:02.480 --> 00:13:09.840]   So there's a view that says, "Listen, if we improve the NIH 10% or whatever percent, are
[00:13:09.840 --> 00:13:12.800]   we really making a dent in the fact that ideas are getting harder to find over time?
[00:13:12.800 --> 00:13:16.400]   And how much of a difference do institutions make anyways?
[00:13:16.400 --> 00:13:20.080]   If it's just about a number of researchers and how many people in your society you can
[00:13:20.080 --> 00:13:23.760]   put into research, it's not like Singapore can have a much more effective scientific
[00:13:23.760 --> 00:13:27.360]   institution that lets it compete with America in science or something like that.
[00:13:27.360 --> 00:13:29.360]   What's wrong with that intuition?
[00:13:29.360 --> 00:13:36.400]   Noah Smith and others have talked about, I can't remember the term he used, something
[00:13:36.400 --> 00:13:37.920]   like moneyism.
[00:13:37.920 --> 00:13:41.200]   He had a funny phrase.
[00:13:41.200 --> 00:13:50.240]   But sort of this idea that we assume there is some kind of constant elasticity between
[00:13:50.240 --> 00:13:54.240]   investment in some particular outcome, like building a semiconductor factory in Arizona
[00:13:54.240 --> 00:13:55.600]   or a new bridge or whatever.
[00:13:55.600 --> 00:13:58.640]   And the outcome of the factory or the bridge.
[00:13:58.640 --> 00:14:08.400]   And one, the conversion rate between those inputs and the output is not a cosmological
[00:14:08.400 --> 00:14:09.040]   constant.
[00:14:09.040 --> 00:14:13.840]   Like maybe any of these things could be done for a half or a 10th or whatever of the cost.
[00:14:13.840 --> 00:14:21.760]   But two, there are even deeper questions as to like, is it possible at all?
[00:14:21.760 --> 00:14:25.680]   Or what else would have to change for it to be possible?
[00:14:25.680 --> 00:14:27.120]   And what are the other constraints?
[00:14:27.120 --> 00:14:30.800]   Like by kind of just talking about these things in funding and dollar terms, you're kind of
[00:14:30.800 --> 00:14:34.720]   making the implicit assumption that the only relevant constraint is the financial one,
[00:14:34.720 --> 00:14:40.160]   where in practice, maybe it's permits or it's labor shortages or it's other things.
[00:14:40.160 --> 00:14:49.440]   Anyway, in the context of the NIH and science and R&D, I'm really skeptical of this same
[00:14:49.440 --> 00:14:56.560]   approach being brought to bear where we can just talk about the amount that we're spending
[00:14:56.560 --> 00:15:01.680]   on R&D and think that that's implicitly a useful measure of the output.
[00:15:01.680 --> 00:15:09.920]   And to a fairly close approximation, there were around 1% as many practicing professional
[00:15:09.920 --> 00:15:14.000]   scientists in the US pre-World War II as post-World War II.
[00:15:15.520 --> 00:15:20.240]   And or say even 1950.
[00:15:20.240 --> 00:15:27.840]   And the other kind of epiphenomena in papers or patents and so forth, it tends to follow
[00:15:27.840 --> 00:15:28.720]   pretty similar ratios.
[00:15:28.720 --> 00:15:36.080]   And we got a lot of pretty good stuff in the first half of the century.
[00:15:36.080 --> 00:15:45.280]   And despite increasing the amount that we spend by between two and maybe slightly
[00:15:45.280 --> 00:15:51.760]   more than two orders of magnitude, not quite three, it's not clear to me that there is
[00:15:51.760 --> 00:15:53.040]   a direct linear relationship.
[00:15:53.040 --> 00:16:00.720]   And so when analyzing the NIH or how we should pursue any of this stuff, I'm inclined to
[00:16:00.720 --> 00:16:08.320]   try to get way more, I guess, concrete and tactile and try to think, OK, what would success
[00:16:08.320 --> 00:16:12.400]   here look like at, well, what is happening today at the micro scale?
[00:16:12.400 --> 00:16:16.160]   And what are the actual problems?
[00:16:16.160 --> 00:16:19.280]   And then what could success look like at the micro scale?
[00:16:19.280 --> 00:16:22.640]   And then what might it look like to scale that up?
[00:16:22.640 --> 00:16:27.520]   And just to give one kind of pointed example of that, we ran a survey of the FAST grants
[00:16:27.520 --> 00:16:33.040]   grant recipients after FAST grants asking about their normal work and not about anything
[00:16:33.040 --> 00:16:34.400]   to do with FAST grants itself.
[00:16:34.400 --> 00:16:39.840]   And we asked them if they had flexible funding, that is to say if they could spend their research
[00:16:39.840 --> 00:16:42.640]   dollars, their current research dollars, however they wanted.
[00:16:42.640 --> 00:16:48.800]   So not if they had more research dollars, just if they could direct their current dollars
[00:16:48.800 --> 00:16:51.680]   however they wanted, how much their associated research program would change.
[00:16:51.680 --> 00:16:55.440]   And we gave them three options, not much, a little, and a lot.
[00:16:55.440 --> 00:16:57.440]   Seventy nine percent said a lot.
[00:16:57.440 --> 00:17:03.760]   So four out of five said that their research agenda would change a lot if this constraint
[00:17:03.760 --> 00:17:04.720]   was removed.
[00:17:04.720 --> 00:17:11.360]   And so should the NIH funding level be x or 1.1x or 1.2x or whatever?
[00:17:11.360 --> 00:17:14.960]   That seems to me like a bad way to analyze this question as compared to, for example,
[00:17:14.960 --> 00:17:21.520]   perhaps, how bound and constrained should an NIH grantee be in choosing their research
[00:17:21.520 --> 00:17:22.020]   agenda?
[00:17:22.020 --> 00:17:28.160]   Maybe if their judgment was way better than that of the committees, not saying it is,
[00:17:28.160 --> 00:17:29.280]   but maybe it is, who knows?
[00:17:29.600 --> 00:17:34.400]   Maybe there's a 5x improvement to be generated just by making that one switch.
[00:17:34.400 --> 00:17:40.720]   So yeah, I'm very skeptical of these financially oriented frameworks.
[00:17:40.720 --> 00:17:46.320]   I mean, maybe the financial is not the right word for it, but just trying to map inputs
[00:17:46.320 --> 00:17:52.320]   to outputs is the framing which you're using to compare the pre-World War II inputs to
[00:17:52.320 --> 00:17:53.760]   what's happening now.
[00:17:53.760 --> 00:17:58.000]   And if it was particular to the scientific institutions, you'd expect, for example, that
[00:17:58.000 --> 00:18:03.120]   things that are disconnected from the NIH-specific structures, obviously, you've talked a lot
[00:18:03.120 --> 00:18:05.440]   about it's getting harder to find paper.
[00:18:05.440 --> 00:18:10.400]   And sector through sector, it's not like NIH is running Moore's Law progress, right?
[00:18:10.400 --> 00:18:13.840]   But even there, you see you need exponentially more researchers to keep up the same level
[00:18:13.840 --> 00:18:14.400]   of progress.
[00:18:14.400 --> 00:18:20.400]   So it does seem important to have these level effects that are one-time in the case of something
[00:18:20.400 --> 00:18:22.880]   like COVID, where, yeah, we need that level effect right now.
[00:18:22.880 --> 00:18:27.280]   But if we're framing it in terms of hundreds of years from now, we're going to be
[00:18:27.920 --> 00:18:32.000]   this is going to be the thing that increases growth rates, which is a sort of framing that
[00:18:32.000 --> 00:18:35.120]   is also supplied when talking about these progress studies things.
[00:18:35.120 --> 00:18:38.960]   Does that make sense in that context, when all these sectors are seeing these slowdowns,
[00:18:38.960 --> 00:18:43.360]   which seem consistent with just, yeah, this is how the economy and science progresses
[00:18:43.360 --> 00:18:43.860]   over time?
[00:18:43.860 --> 00:18:45.760]   I don't know is the short answer.
[00:18:45.760 --> 00:18:46.880]   I think it's really puzzling.
[00:18:46.880 --> 00:18:55.920]   I think the constancy of U.S. GDP growth is, I think, just one of the weirdest things.
[00:18:55.920 --> 00:18:57.120]   And I don't know if we've got an explanation for it.
[00:18:57.120 --> 00:19:02.480]   But also, I don't think that it's-- or an obvious thing to do would be to shrug and
[00:19:02.480 --> 00:19:05.280]   say, OK, well, just it's overdetermined or something.
[00:19:05.280 --> 00:19:06.880]   And that's just how countries work.
[00:19:06.880 --> 00:19:10.400]   But you can look at other countries where it's obviously manifestly not the case.
[00:19:10.400 --> 00:19:12.880]   And so what is it that's weird and special about the U.S.?
[00:19:12.880 --> 00:19:18.000]   The thing that I wonder about in a lot of these cases is you could get many of the observed
[00:19:19.040 --> 00:19:26.080]   system phenomenon characteristics if we weren't actually adding productive capacity.
[00:19:26.080 --> 00:19:28.800]   That's a simple way to explain a lot of it.
[00:19:28.800 --> 00:19:36.160]   And that if you're just adding exponentially more unproductive capacity, then on a stylized
[00:19:36.160 --> 00:19:38.080]   level, a lot of this stuff would just fall out of it.
[00:19:38.080 --> 00:19:40.960]   Now, I'm not saying that we're necessarily doing that.
[00:19:42.720 --> 00:19:52.080]   But it could be that maybe we're making them-- well, there's lots of ways where that could
[00:19:52.080 --> 00:19:59.520]   be what's effectively going on, even if it's not the case that the marginal people or things
[00:19:59.520 --> 00:20:01.200]   or organizations themselves are bad.
[00:20:01.200 --> 00:20:03.840]   It's just somehow how the components interact.
[00:20:03.840 --> 00:20:10.720]   But the fact that you could get these exponentially diminishing returns through the addition of
[00:20:11.920 --> 00:20:18.880]   ever more nonproductive capacity makes me not persuaded that the low-hanging case is
[00:20:18.880 --> 00:20:26.560]   necessarily true and give some weight to the prospect that, yeah, it's fundamentally structural,
[00:20:26.560 --> 00:20:29.520]   cultural, or organizational.
[00:20:30.240 --> 00:20:42.800]   And just to give a micro example there-- and it's a very basic and an obvious one.
[00:20:42.800 --> 00:20:48.800]   But I think it's interesting to compare the SpaceX R&D budget and the NASA R&D budget
[00:20:48.800 --> 00:20:52.640]   and to actually look at those two time series together.
[00:20:52.640 --> 00:21:01.200]   And maybe we're just returning to the financial point again.
[00:21:01.200 --> 00:21:14.640]   But it seems pretty clear that the trajectory of NASA's efficacy has not fully followed
[00:21:14.640 --> 00:21:16.080]   the trajectory of its inputs.
[00:21:16.080 --> 00:21:16.800]   Yeah, yeah.
[00:21:16.800 --> 00:21:23.280]   Although the point about the marginal inputs we put into science have not been as highly
[00:21:23.280 --> 00:21:26.160]   effectively used or as high quality as what was before.
[00:21:26.160 --> 00:21:28.720]   The 1x is a much higher quality 1x than 100x.
[00:21:28.720 --> 00:21:31.680]   It's not clear what you do to fix that.
[00:21:31.680 --> 00:21:34.880]   If it's just the case that there's a limited amount of John von Neumanns in your society
[00:21:34.880 --> 00:21:40.480]   that are part of the pre-World War II 1x, it's not like we can just put 100x more John
[00:21:40.480 --> 00:21:43.120]   von Neumann-type physicists into science.
[00:21:43.120 --> 00:21:48.320]   If the binding constraint is the number of John von Neumanns, then yes, that's bad news,
[00:21:48.320 --> 00:21:49.040]   I guess.
[00:21:49.040 --> 00:21:51.120]   There's not a lot we can do on the margin.
[00:21:51.120 --> 00:21:52.480]   But I'm not sure that it is.
[00:21:52.480 --> 00:21:57.680]   I guess I keep going back to the cultural and the sociological point.
[00:21:57.680 --> 00:22:04.960]   So Gertie and Carl Corey, they ran a lab at the University of Washington, St. Louis.
[00:22:04.960 --> 00:22:09.600]   And six of their students, if I recall correctly, went on to win Nobel Prizes.
[00:22:10.400 --> 00:22:14.720]   And they had a well-known lab, and they got good students.
[00:22:14.720 --> 00:22:16.800]   But they weren't the most prestigious lab in the world.
[00:22:16.800 --> 00:22:20.560]   It's not like they got to cherry pick every year the single most promising person.
[00:22:20.560 --> 00:22:24.720]   And so something was going on there.
[00:22:24.720 --> 00:22:29.120]   And there's a book about it, and it tries to get into this a little bit.
[00:22:29.120 --> 00:22:32.240]   And I don't know that I can figure out quite what it was.
[00:22:32.240 --> 00:22:36.320]   And there was also some good fortune where they got into molecular biology at a good time.
[00:22:38.080 --> 00:22:42.160]   But I think there were these hopeful data points where, again, they were obviously
[00:22:42.160 --> 00:22:43.280]   extremely brilliant people.
[00:22:43.280 --> 00:22:46.240]   But I think that the thing that distinguished them and their students
[00:22:46.240 --> 00:22:50.240]   was not that they were these seven sigma Martians.
[00:22:50.240 --> 00:22:56.240]   I think rather that they found organizational structures and cultural practices that really
[00:22:56.240 --> 00:22:56.720]   worked.
[00:22:56.720 --> 00:22:59.360]   I think those are at least in principle more replicable.
[00:22:59.360 --> 00:23:01.600]   Now, you might still say, OK, fine, in theory.
[00:23:01.600 --> 00:23:02.880]   But how do you actually do that?
[00:23:02.880 --> 00:23:07.520]   And I think that's the big open question.
[00:23:07.520 --> 00:23:10.400]   OK, I think that's a great that's a great point to talk about our constitute.
[00:23:10.400 --> 00:23:14.160]   So, yeah, I mean, I think you just kind of answer this question, basically.
[00:23:14.160 --> 00:23:20.240]   But it's not exactly like biology research is something that society has neglected.
[00:23:20.240 --> 00:23:21.840]   So what's the theory of change here?
[00:23:21.840 --> 00:23:25.680]   Is it just a story similar to Stripe in that if you get the right people, even though there's
[00:23:25.680 --> 00:23:29.360]   like tens of billions of dollars of biology funding, getting the right people and the
[00:23:29.360 --> 00:23:32.160]   right culture and right dedication is what it takes.
[00:23:32.160 --> 00:23:37.440]   Even though there are lots of scientists and lots of lots of universities, there's a lot
[00:23:37.440 --> 00:23:44.400]   of homogeneity today in how science and in particular, how biomedical science is pursued
[00:23:44.400 --> 00:23:51.040]   where a kind of basic research in an academic context before there's any commercialization
[00:23:51.040 --> 00:23:52.160]   or prospect of it in sight.
[00:23:52.160 --> 00:23:56.720]   And I don't know that the model is necessarily a bad one.
[00:23:56.720 --> 00:23:59.040]   Certainly, we're not particularly claiming that it's a bad one.
[00:23:59.040 --> 00:24:05.040]   But sort of the construct of universities, labs, PI, a principal investigator running
[00:24:05.040 --> 00:24:12.560]   the lab, that person applies for grants primarily to the NIH, maybe supplemented by other sources
[00:24:12.560 --> 00:24:20.400]   and grants reviewed by committees with pretty study sections, as they call them, with kind
[00:24:20.400 --> 00:24:22.400]   of pretty rigid scoring criteria and so on.
[00:24:22.400 --> 00:24:23.760]   Like, that's the structure.
[00:24:23.760 --> 00:24:28.560]   And it just seems suboptimal to me.
[00:24:28.560 --> 00:24:33.840]   I mean, homogeneity is bad in basically any ecosystem, especially ecosystems where you're
[00:24:34.560 --> 00:24:39.520]   producing or, excuse me, where you're seeking tail outcomes.
[00:24:39.520 --> 00:24:46.560]   And we thought that for a variety of reasons, like, well, from first principles, that other
[00:24:46.560 --> 00:24:47.760]   models should be possible.
[00:24:47.760 --> 00:24:54.080]   And that we had specific ideas as to how one particular model might be a good idea and
[00:24:54.080 --> 00:24:56.800]   complementary to the status quo in very short terms.
[00:24:58.000 --> 00:25:04.720]   What's different about AHRQ is, one, scientists are funded themselves to pursue whatever they
[00:25:04.720 --> 00:25:05.040]   want.
[00:25:05.040 --> 00:25:10.240]   So it's curiosity during research, whereas NIH grants are given for projects.
[00:25:10.240 --> 00:25:15.920]   Second, we build a lot of in-house infrastructure so that scientists can draw upon other platforms
[00:25:15.920 --> 00:25:19.600]   and other capabilities that they don't have to go and build and maintain themselves.
[00:25:19.600 --> 00:25:26.000]   Whereas, again, in the kind of standard university academic context, scientists would virtually
[00:25:26.000 --> 00:25:27.440]   always have to do that in-house.
[00:25:27.440 --> 00:25:32.560]   And because of the natural skill constraints in any given lab, that effectively circumscribes
[00:25:32.560 --> 00:25:35.200]   the ambition of a possible research program.
[00:25:35.200 --> 00:25:42.080]   And then thirdly, we try to provide career paths for people to remain in science if they
[00:25:42.080 --> 00:25:48.640]   don't want to become principal investigators, where the university structure kind of co-mingles
[00:25:48.640 --> 00:25:57.840]   the training purpose of academia with the execution, where the people who are doing
[00:25:57.840 --> 00:26:03.520]   the work are typically the grad students and the postdocs, who are both themselves, at
[00:26:03.520 --> 00:26:08.000]   least nominally, on the career path of themselves eventually becoming principal investigators.
[00:26:08.000 --> 00:26:16.000]   And there are lots of people who, for all sorts of different, very valid reasons, love
[00:26:16.000 --> 00:26:20.800]   science and love the pursuit of research, but don't want to be a manager running a
[00:26:20.800 --> 00:26:26.320]   lab, choosing their own research programs, and dealing with all of the overhead and typically
[00:26:26.320 --> 00:26:28.960]   grant applications that are concomitant with that.
[00:26:28.960 --> 00:26:34.800]   And so with AHRQ, we have a real emphasis on hiring scientists who have finished their
[00:26:34.800 --> 00:26:37.920]   postdocs, finished grad school, and just like, that's what they want to do in their lives.
[00:26:37.920 --> 00:26:40.560]   And there, again, isn't really a career path for them today.
[00:26:40.560 --> 00:26:44.400]   And one of the things that's actually really exciting about the discovery that we mentioned
[00:26:44.400 --> 00:26:48.960]   that came out yesterday, this new bridge editing technology, is that work was led by one of
[00:26:48.960 --> 00:26:53.120]   these senior scientists who had finished his postdoc.
[00:26:53.120 --> 00:27:02.640]   And it's not clear to me that he wanted to go on to become a PI, but he loves science
[00:27:02.640 --> 00:27:04.080]   and he's an amazing researcher, clearly.
[00:27:04.080 --> 00:27:09.280]   And so he's able to go on to have that career at AHRQ.
[00:27:09.920 --> 00:27:20.560]   And in addition, the prospect of these mobile elements being usable in this way for this
[00:27:20.560 --> 00:27:23.920]   like genomic insertion, whatever, that's a pretty speculative out there thing.
[00:27:23.920 --> 00:27:27.280]   And had he applied to the NIH to go and pursue that?
[00:27:27.280 --> 00:27:30.160]   I mean, he didn't, so I don't know what the outcome would have been.
[00:27:30.160 --> 00:27:39.120]   But Jennifer Doudna's work was, if I recall correctly, funded by DARPA because her CRISPR
[00:27:39.600 --> 00:27:42.640]   and NIH applications were rejected.
[00:27:42.640 --> 00:27:49.280]   And of course, Carolyn Kuriko's NIH applications for mRNA vaccine work were famously rejected.
[00:27:49.280 --> 00:27:54.560]   So it at least seems very plausible that it wouldn't have worked out.
[00:27:54.560 --> 00:28:01.600]   And so, look, all these things are random and I can't make any definitive claims about
[00:28:01.600 --> 00:28:04.080]   what would have counterfactually happened.
[00:28:04.080 --> 00:28:07.840]   But it seems plausible to me that this thing announced yesterday wouldn't have happened
[00:28:08.480 --> 00:28:11.920]   or would've been less likely to happen in a different environment.
[00:28:11.920 --> 00:28:21.280]   When we think forward 10 years or 20 years, this specific line of research where you understand
[00:28:21.280 --> 00:28:28.400]   the effects of genetic architecture on different traits, and also you can edit, invert, insert,
[00:28:28.400 --> 00:28:34.560]   whatever, the DNA arbitrarily, you saw a little cell anemia, you've done the obvious things.
[00:28:34.560 --> 00:28:35.280]   What does that lead to?
[00:28:35.280 --> 00:28:36.560]   What are you excited about?
[00:28:36.560 --> 00:28:41.760]   Well, the thing that I think is really interesting about it is using it as a new kind of telescope,
[00:28:41.760 --> 00:28:50.800]   by which I mean, when people hear about CRISPR, there's an obvious excitement and legitimate
[00:28:50.800 --> 00:28:55.280]   excitement around using this to cure things directly in the body, using it as a kind of
[00:28:55.280 --> 00:28:55.840]   therapeutic.
[00:28:55.840 --> 00:29:03.920]   But you can also use CRISPR to try to figure out what's going on in cells and in cell cultures
[00:29:03.920 --> 00:29:06.160]   in a kind of structured way.
[00:29:06.160 --> 00:29:15.600]   And so the body is interesting in that it has this switchboard of the DJs, I guess,
[00:29:15.600 --> 00:29:22.880]   at the fancy mixing sets of 20,000 genes.
[00:29:22.880 --> 00:29:27.760]   And with CRISPR, you can systematically go and perturb each gene one by one, like mashing
[00:29:27.760 --> 00:29:32.720]   all the keys in sequence and try to figure out, well, what the effects of perturbing
[00:29:32.720 --> 00:29:33.520]   this versus that are.
[00:29:34.320 --> 00:29:40.160]   And if you do that in a cell culture where you can subject the cells to some stressor
[00:29:40.160 --> 00:29:45.680]   or some treatment or whatever, you can kind of see differentially how different perturbations
[00:29:45.680 --> 00:29:47.040]   affect different cell outcomes.
[00:29:47.040 --> 00:29:52.960]   Or you can just kind of use it for synthetic data generation more broadly, where you could
[00:29:52.960 --> 00:29:56.080]   perform all these perturbations and then sequence and kind of see what's happening in the cells
[00:29:56.080 --> 00:29:56.960]   and so forth.
[00:29:56.960 --> 00:29:58.880]   And single cell sequencing has come a long way.
[00:29:58.880 --> 00:30:06.560]   Anyway, point is, there's a lot you can do with all this gene editing stuff for discovery
[00:30:06.560 --> 00:30:09.520]   and for data generation in the broadest sense.
[00:30:09.520 --> 00:30:20.240]   And that's really compelling because for a lot of diseases, they're complex in the sort
[00:30:20.240 --> 00:30:23.280]   of fields jargon, meaning, I mean, yes, they're complex in the colloquial sense, but they're
[00:30:23.280 --> 00:30:27.120]   specifically complex in that they're not infectious.
[00:30:27.120 --> 00:30:30.480]   Not just like some pathogen getting into you.
[00:30:30.480 --> 00:30:34.080]   And they're not monogenic, like Huntington's, where it's like one specific mutation.
[00:30:34.080 --> 00:30:38.560]   Instead, it's like some combination of environmental factors, but maybe some genetic factors as
[00:30:38.560 --> 00:30:38.800]   well.
[00:30:38.800 --> 00:30:40.800]   And it's somewhere in between.
[00:30:40.800 --> 00:30:50.560]   And by figuring out-- and that includes most autoimmune diseases, most cancers, to some
[00:30:50.560 --> 00:30:54.640]   extent cardiovascular disease and neurodegenerative disease, like the big ones we haven't yet
[00:30:54.640 --> 00:30:55.040]   solved.
[00:30:55.040 --> 00:31:01.760]   And so then coming back to these functional genomics technologies, what's interesting,
[00:31:01.760 --> 00:31:09.680]   I think, is trying to figure out how it is that the genetic component of those diseases
[00:31:09.680 --> 00:31:11.280]   happens and works and so on.
[00:31:11.280 --> 00:31:15.200]   And even if that's only a small contributor, it can potentially shine light on just like
[00:31:15.200 --> 00:31:17.200]   what the general pathway is.
[00:31:17.200 --> 00:31:19.520]   And so the question would be-- and look, this is speculative.
[00:31:19.520 --> 00:31:20.720]   None of this has actually happened.
[00:31:20.720 --> 00:31:28.080]   But by figuring out the genetic interactions between genes and, say, Alzheimer's, can you
[00:31:28.080 --> 00:31:32.800]   figure out how Alzheimer's arises, which we don't understand today?
[00:31:32.800 --> 00:31:37.520]   And then once you understand how Alzheimer's arises, maybe you can use kind of conventional
[00:31:37.520 --> 00:31:45.760]   technologies and targeting to figure out how to inhibit that or to sort of modulate those
[00:31:45.760 --> 00:31:48.400]   pathways.
[00:31:48.400 --> 00:31:52.560]   And so, yeah, that's what we're really excited about from a functional genomics standpoint.
[00:31:52.560 --> 00:31:55.760]   And there's kind of an AI angle as well that we could hook up if you want.
[00:31:55.760 --> 00:32:01.760]   How do you think about the dual-use possibilities of biotech?
[00:32:01.760 --> 00:32:05.200]   I am sympathetic with the idea that if you think of prior technology, just like Google
[00:32:05.200 --> 00:32:10.320]   Search or even just the computer itself, you could forecast in advance, oh, this has all
[00:32:10.320 --> 00:32:11.120]   this dual-use stuff.
[00:32:12.240 --> 00:32:17.200]   But for some reason, history has been kind to us, and maybe we should just-- Chesterton's
[00:32:17.200 --> 00:32:18.880]   meta-fence here is keep doing science.
[00:32:18.880 --> 00:32:24.000]   But with biotech, there's-- we don't want to go into specifics here, but there's specific
[00:32:24.000 --> 00:32:27.760]   things you can think of with this specific technology where you could imagine some nefarious
[00:32:27.760 --> 00:32:28.560]   things.
[00:32:28.560 --> 00:32:35.040]   How do you think about-- why not just focus, let's say, on ameliorating the risks first
[00:32:35.040 --> 00:32:36.160]   or something like that?
[00:32:36.160 --> 00:32:46.960]   Well, I don't think that-- I don't think the binding constraint on harmful use of biotechnology
[00:32:46.960 --> 00:32:50.960]   or bioweapons today is pure biological capabilities.
[00:32:50.960 --> 00:32:56.720]   Like, if some set of incredibly capable, intelligent people wanted to, you know, cause tremendous
[00:32:56.720 --> 00:33:02.720]   harm with, well, presumably with pathogens, but with something biological, you know, they
[00:33:02.720 --> 00:33:04.720]   wouldn't necessarily need to invent anything new.
[00:33:04.720 --> 00:33:09.440]   They would just need to apply currently known techniques in kind of a malevolently directed
[00:33:09.440 --> 00:33:09.840]   fashion.
[00:33:09.840 --> 00:33:16.880]   I think there are some concerns and some risks there with respect to things that don't invent
[00:33:16.880 --> 00:33:20.880]   new technologies, but do make them more accessible.
[00:33:20.880 --> 00:33:30.000]   And so, I mean, I think the question is, you know, what would the effect on the world be
[00:33:30.000 --> 00:33:36.960]   if there was a sufficiently sophisticated LLM that, you know, it could help anybody,
[00:33:36.960 --> 00:33:39.520]   you know, synthesize and disperse smallpox?
[00:33:39.520 --> 00:33:43.600]   Like, I don't know that the laws of physics prohibit such an LLM existing.
[00:33:43.600 --> 00:33:44.480]   I presume they don't.
[00:33:44.480 --> 00:33:49.440]   And would the world be fine if such an LLM was, you know, widely distributed?
[00:33:49.440 --> 00:33:51.920]   Like, maybe, but, you know, maybe not, right?
[00:33:51.920 --> 00:33:54.320]   So I think there is that kind of threat factor.
[00:33:54.320 --> 00:34:00.880]   But my point is I don't think knowledge at the frontier of biology is the relevant margin
[00:34:00.880 --> 00:34:01.360]   here.
[00:34:01.360 --> 00:34:09.760]   And if we take seriously what, you know, that this is, I mean, we don't need crazy AI risk
[00:34:09.760 --> 00:34:14.320]   to motivate this, you know, where the world is perfectly capable of originating, you know,
[00:34:14.320 --> 00:34:19.120]   really severe pandemics and pathogens itself, plus all the other diseases that are not pathogenic.
[00:34:19.120 --> 00:34:21.040]   So, you know, we got other problems.
[00:34:21.040 --> 00:34:25.760]   But, you know, whether we care about the possible, you know, kind of dual use harms you just
[00:34:25.760 --> 00:34:30.000]   mentioned, or we just care about the things that already exist, to ameliorate both of
[00:34:30.000 --> 00:34:33.360]   those, we do need enhancement of our capabilities.
[00:34:33.360 --> 00:34:39.840]   And like we, there are a lot of biological problems that we don't today know how to solve.
[00:34:39.840 --> 00:34:45.440]   And so I think in that respect, if one were to do what you're proposing and try to advance
[00:34:45.440 --> 00:34:52.560]   the defensive side of this, I don't know that what one would do would necessarily be that
[00:34:52.560 --> 00:34:58.560]   different, because there are just fundamental capabilities that we would presumably need
[00:34:58.560 --> 00:35:00.880]   to have, that we don't today have.
[00:35:00.880 --> 00:35:08.160]   And by trying to solve current human diseases, I think you're probably also pursuing something
[00:35:08.160 --> 00:35:12.800]   pretty close to the best steps to solve the potential diseases that, you know, malicious
[00:35:12.800 --> 00:35:13.760]   actors could cause in the future.
[00:35:13.760 --> 00:35:14.400]   That makes sense.
[00:35:14.400 --> 00:35:20.480]   I mean, zooming out from bio-risk in particular, just like, how are you thinking about AI these
[00:35:20.480 --> 00:35:20.980]   days?
[00:35:20.980 --> 00:35:29.280]   Well, you know, I think everyone has to be sort of high perplexity in the sense that,
[00:35:29.280 --> 00:35:35.920]   I mean, the verdict that one might have given at the beginning, you know, we're recording
[00:35:35.920 --> 00:35:38.400]   this here, pretty close to the beginning of 2024.
[00:35:38.400 --> 00:35:42.240]   The verdict one might have given at the beginning of, you know, '23, '22, '21, you know, back
[00:35:42.240 --> 00:35:46.400]   say the last eight years, those would all, I think, have looked pretty different.
[00:35:46.400 --> 00:35:54.800]   I mean, maybe Guern might have scored the best from 2019 or something onwards, but broadly
[00:35:54.800 --> 00:35:57.760]   speaking, it's been pretty difficult, I think, to forecast.
[00:35:57.760 --> 00:36:04.160]   And so I think the basic position to a first order has to be one of, you know, some degree
[00:36:04.160 --> 00:36:04.880]   of humility.
[00:36:04.880 --> 00:36:10.560]   I think as your blog post identifies, the big question right now is, you know, to what
[00:36:10.560 --> 00:36:14.400]   degree, to what degree scaling laws hold?
[00:36:14.400 --> 00:36:22.000]   And I guess if they hold, then, you know, what exactly is it that we're, well, asymptoting
[00:36:22.000 --> 00:36:25.520]   is maybe a presumptuous word, but it's not an asymptote, but like, what is it that we're
[00:36:25.520 --> 00:36:25.920]   approaching?
[00:36:25.920 --> 00:36:29.840]   You know, it's not, we don't necessarily know the shape of that thing, whatever it is.
[00:36:29.840 --> 00:36:37.840]   And yeah, I think, I think it's a lot of, yeah, I think, I think how one should feel
[00:36:38.720 --> 00:36:44.320]   needs to be, or ought to be very sensitive to like the exact parameters of, you know,
[00:36:44.320 --> 00:36:45.040]   those curves.
[00:36:45.040 --> 00:36:51.280]   And I just don't think anyone, anyone knows what, like the true value of those parameters
[00:36:51.280 --> 00:36:51.760]   actually are.
[00:36:51.760 --> 00:36:58.240]   So, you know, it's clearly going to be important, is already important today, and it has a pretty
[00:36:58.240 --> 00:37:03.920]   central bearing on, you know, both Stripe and Arc, and we'll see.
[00:37:03.920 --> 00:37:04.480]   Yeah.
[00:37:04.480 --> 00:37:08.640]   I wonder if the meta lesson here, and I totally agree with that sort of general sentiment,
[00:37:08.640 --> 00:37:12.320]   but I wonder if the meta lesson that we got from COVID, for example, and with things like
[00:37:12.320 --> 00:37:17.760]   fast grants was, you obviously can't predict these things in advance, but the most important
[00:37:17.760 --> 00:37:21.360]   thing, even in addition to these like specific sort of countermeasures trying to come up
[00:37:21.360 --> 00:37:27.600]   in advance is like, when the thing is happening, having competent individuals who can synthesize
[00:37:27.600 --> 00:37:32.160]   and organize information, and also having these like new initiatives and institutions
[00:37:32.160 --> 00:37:34.960]   to get the right thing done.
[00:37:34.960 --> 00:37:38.560]   Yes, the adaptability premium is probably going to go way up over the next decade.
[00:37:38.560 --> 00:37:38.880]   Yeah.
[00:37:38.880 --> 00:37:43.840]   And with that in mind, and I know you have already a couple of day jobs, but yeah, I
[00:37:43.840 --> 00:37:46.960]   feel like something like fast grants, like when the time comes down to it, like, I don't
[00:37:46.960 --> 00:37:51.120]   know, you're like, it should be like, you know, you'd be like one of the top people
[00:37:51.120 --> 00:37:54.640]   you could think of in terms of having expertise and respect in a wide range of domains and
[00:37:54.640 --> 00:37:55.680]   competency as a leader.
[00:37:55.680 --> 00:37:59.920]   I don't know, just like keep it in the back of your mind, or maybe in the middle of your
[00:37:59.920 --> 00:38:02.640]   mind, given how far we are into the transition.
[00:38:02.640 --> 00:38:11.840]   Well, fast grants was three beloved squirrels in a trench coat, or I guess, well, I was
[00:38:11.840 --> 00:38:16.480]   one of the squirrels, so I don't know, I'm still full of it, but it was also a Tyler
[00:38:16.480 --> 00:38:19.200]   Cohen, who's an amazing person and a great friend.
[00:38:19.200 --> 00:38:23.120]   And then my wife, who's also one of ARC's co-founders.
[00:38:23.120 --> 00:38:26.320]   And so, you know, fast grants was not this like giant, you know, impressive edifice
[00:38:26.320 --> 00:38:28.880]   that would qualify me for anything at all.
[00:38:29.680 --> 00:38:31.840]   But it doesn't have to be giant, right, to have that kind of bigger impact?
[00:38:31.840 --> 00:38:36.000]   Yeah, I guess as an objective matter, that's true.
[00:38:36.000 --> 00:38:42.160]   I mean, look, John and I try to be very self-aware of the limits of our expertise, which are
[00:38:42.160 --> 00:38:45.680]   very proximate to us.
[00:38:45.680 --> 00:38:50.000]   And I'm sure if something like that was necessary, that'd be.
[00:38:50.000 --> 00:38:52.880]   I mean, look at Operation Warp Speed.
[00:38:52.880 --> 00:38:58.480]   They chose a super effective domain expert, Monsef Slaoui, to run that, and it was just
[00:38:58.480 --> 00:39:02.560]   like monstrously successful, like truly remarkable.
[00:39:02.560 --> 00:39:07.520]   And I don't know who the Monsef Slaoui of, I guess it would depend on whatever the problem
[00:39:07.520 --> 00:39:10.800]   in question is, but I think my recommendation would be like, figure out who Monsef is and
[00:39:10.800 --> 00:39:11.840]   like, go hire Monsef.
[00:39:11.840 --> 00:39:16.560]   And I think it is extremely unlikely.
[00:39:16.560 --> 00:39:21.600]   I think anybody who deemed me the Monsef of that thing, you know, is probably mistaken.
[00:39:21.600 --> 00:39:22.720]   I don't think you're being too humble.
[00:39:22.720 --> 00:39:28.480]   But staying on fast grants, you know, now we have the retrospective of how effective
[00:39:28.480 --> 00:39:32.400]   the fast grants recipients were compared to the other grants that were given out by, let's
[00:39:32.400 --> 00:39:33.760]   say, the NIH or NSF.
[00:39:33.760 --> 00:39:41.040]   To your knowledge, what has been the reaction of these institutions to the discrepancy between
[00:39:41.040 --> 00:39:42.400]   the speed and effectiveness of fast grants?
[00:39:42.400 --> 00:39:45.280]   Have they like analyzed their protocols and like what happened during COVID?
[00:39:45.280 --> 00:39:48.000]   Is there any sort of retrospective there on their part?
[00:39:49.360 --> 00:39:53.360]   Not to my knowledge, but I don't want that to sound like an indictment.
[00:39:53.360 --> 00:39:57.600]   Like maybe they've done a lot of reflection and, you know, I just don't know about it.
[00:39:57.600 --> 00:40:00.720]   Like I don't think I would know about it, even if it had happened.
[00:40:00.720 --> 00:40:02.640]   So I don't know.
[00:40:02.640 --> 00:40:17.360]   I mean, look, most, well, I don't know anything about the response at CDC or FDA or NIH or
[00:40:17.360 --> 00:40:21.200]   NSF or any of the relevant organizations or their international equivalents.
[00:40:21.200 --> 00:40:26.800]   And so none of what I'm saying should be taken as like specifically, not only not critical
[00:40:26.800 --> 00:40:28.240]   of them, but not even a comment to them.
[00:40:28.240 --> 00:40:29.360]   I just like don't know what they did.
[00:40:29.360 --> 00:40:36.560]   But in general, organizations are, you know, not awesome at self-reflection.
[00:40:36.560 --> 00:40:41.680]   And I think, I assume as a default prior that some of the dynamics we discussed at the beginning
[00:40:41.680 --> 00:40:47.440]   of this are rooted there where none of the people who started those organizations are
[00:40:47.440 --> 00:40:48.080]   there today.
[00:40:48.080 --> 00:40:53.680]   And so, you know, what exactly are the incentives of those leaders?
[00:40:53.680 --> 00:41:08.080]   And, you know, I haven't, yeah, it's not clear to me who would have the incentive to, you
[00:41:08.080 --> 00:41:13.920]   know, really take stock in a fully objective and self-critical way to figure out, you know,
[00:41:13.920 --> 00:41:15.760]   what was done well and what was done poorly.
[00:41:15.760 --> 00:41:18.800]   I promise not to be too myopic about AI, but one more question.
[00:41:18.800 --> 00:41:23.440]   Long-term we can forecast, maybe even medium-term we can't, but near-term it looks like, you
[00:41:23.440 --> 00:41:27.760]   know, we might have things that look like AI agents and they might need to trade.
[00:41:27.760 --> 00:41:31.200]   What does the financial infrastructure for AI agents look like?
[00:41:31.200 --> 00:41:33.040]   Yeah, I think that's a really interesting question.
[00:41:33.760 --> 00:41:46.720]   And I think automated or autonomous transactions, I mean, they already exist to some extent
[00:41:46.720 --> 00:41:46.960]   today.
[00:41:46.960 --> 00:41:50.960]   I mean, you know, lots of services have usage-based billing, right?
[00:41:50.960 --> 00:41:56.640]   And a lot of the expenses being incurred are, you know, autonomously incurred.
[00:41:56.640 --> 00:42:00.800]   Like no human is pushing a button when Stripe does most of what it does, you know, with
[00:42:00.800 --> 00:42:03.840]   cloud computing and incurs, you know, some costs with some cloud service.
[00:42:03.840 --> 00:42:08.320]   So it's in some kind of extremely primitive way happening today.
[00:42:08.320 --> 00:42:16.400]   And I assume it will follow some gradient where some of those decisions are either directly
[00:42:16.400 --> 00:42:20.080]   or indirectly being made by an LLM or some LLM equivalent or, you know, whatever.
[00:42:20.080 --> 00:42:26.640]   And I think there'll be some, yeah, some almost unnoticeably smooth continuum up to, you know,
[00:42:26.640 --> 00:42:28.560]   very considerable degrees of autonomy.
[00:42:28.560 --> 00:42:31.360]   But it's not that we're going to like wake up some month and be like, oh my God, you
[00:42:31.360 --> 00:42:34.800]   know, suddenly the bots have been unleashed.
[00:42:34.800 --> 00:42:40.080]   And I think there'll be interesting questions there around, I mean, this will now sound
[00:42:40.080 --> 00:42:47.600]   very kind of parochial and kind of, and maybe getting excessively tactical or something.
[00:42:47.600 --> 00:42:51.280]   But I think it'll be very interesting questions around the legality of those in terms of like,
[00:42:51.280 --> 00:42:55.760]   are these treated as the responsibility of the owner?
[00:42:55.760 --> 00:42:59.200]   Or is there any degree of kind of independence granted?
[00:42:59.200 --> 00:43:00.960]   How does liability work?
[00:43:00.960 --> 00:43:05.360]   How, yeah, which rails are best suited?
[00:43:05.360 --> 00:43:07.520]   What kind of transaction velocities are we talking about here?
[00:43:07.520 --> 00:43:11.920]   Because if it's, you know, a billion transactions a second, then the properties of that system
[00:43:11.920 --> 00:43:15.360]   should look very different to is it, you know, one giant tiering transaction every day.
[00:43:15.360 --> 00:43:21.280]   And again, if we just use the analogy of the usage-based services, those tend to incur
[00:43:21.280 --> 00:43:27.200]   liabilities, you know, in kind of tiny increments, but then to kind of to settle like on a monthly
[00:43:27.200 --> 00:43:28.480]   basis when you pay your bill.
[00:43:28.480 --> 00:43:33.120]   And so maybe these agent transactions will have that character.
[00:43:33.120 --> 00:43:37.440]   So I think there were a lot, excuse me, a lot of practical applied questions, but I
[00:43:37.440 --> 00:43:42.960]   think what you're saying around these autonomous transactions conceivably being an important
[00:43:42.960 --> 00:43:45.120]   dimension is very true and real.
[00:43:45.120 --> 00:43:50.240]   And is, you know, one of the ways in which the, one of the interesting ways in which
[00:43:50.240 --> 00:43:53.600]   the economy, you know, might change and expand over the next decade.
[00:43:53.600 --> 00:43:59.520]   And I think it's possible that the crypto plays some role here where, you know, it's,
[00:43:59.520 --> 00:44:12.320]   if we take KYC and AML very seriously for humans, and we want to know the human that
[00:44:12.320 --> 00:44:17.520]   is associated with some particular financial activity, obviously that's a murkier question
[00:44:17.520 --> 00:44:19.600]   in the context of some AI agent.
[00:44:19.600 --> 00:44:25.120]   And, you know, if we, in some blurry sense, look at crypto as the part of financial services
[00:44:25.120 --> 00:44:32.640]   that is de facto exempt from AML by design, then yeah, maybe that plays a role.
[00:44:32.640 --> 00:44:36.720]   How long before Stripe was founded, do you think a product like Stripe could have been
[00:44:36.720 --> 00:44:37.200]   invented?
[00:44:37.200 --> 00:44:38.720]   That's a good question.
[00:44:40.880 --> 00:44:50.160]   Well, in, you know, depending on what exactly you define Stripe as being, I think conceivably
[00:44:50.160 --> 00:44:54.480]   decades earlier in that, I mean, on some level PayPal is a kind of Stripe.
[00:44:54.480 --> 00:45:02.400]   And, you know, there were many payments companies before PayPal and, you know, you could go
[00:45:02.400 --> 00:45:04.960]   all the way back to, you know, cash registers or something, right?
[00:45:04.960 --> 00:45:08.000]   So, so it depends on, on, yeah, these definitional questions.
[00:45:09.040 --> 00:45:14.720]   I mean, the particular secular tailwinds that we benefited from around the rise of app stores
[00:45:14.720 --> 00:45:20.960]   and, you know, the on-demand economy and maybe the startup boom post, you know, YC and after
[00:45:20.960 --> 00:45:24.560]   the financial crisis, you know, those, those particular tailwinds were idiosyncratic and
[00:45:24.560 --> 00:45:25.200]   specific to Stripe.
[00:45:25.200 --> 00:45:30.080]   And I guess the GFC was a way to nine and Stripe was founded in 2010.
[00:45:30.080 --> 00:45:35.200]   And so, you know, in as much as you define those as being a core then not that much earlier,
[00:45:35.200 --> 00:45:39.760]   but, but mostly my story of Stripe is one of, is one of market inefficiency.
[00:45:39.760 --> 00:45:44.320]   And I do wonder, yeah, why, why much of this didn't happen sooner?
[00:45:44.320 --> 00:45:44.820]   Yeah.
[00:45:44.820 --> 00:45:49.760]   I always find it really interesting when there's these cases where it wasn't even the case
[00:45:49.760 --> 00:45:52.160]   that like, well, it could have been started sooner, but there was nobody in the market.
[00:45:52.160 --> 00:45:54.240]   There were like many people in the market and they weren't just like random people.
[00:45:54.240 --> 00:45:57.280]   There were technology companies headquartered in San Francisco who were in the market.
[00:45:57.280 --> 00:46:00.800]   Do you have some explanation for why it didn't occur to them?
[00:46:01.760 --> 00:46:07.840]   I'm hesitant to generalize too much because, well, I only have maybe, you know, N equals
[00:46:07.840 --> 00:46:08.560]   one experience.
[00:46:08.560 --> 00:46:11.120]   And so I think it's, it's dangerous to over-extrapolate from that.
[00:46:11.120 --> 00:46:15.440]   Maybe N equals two now with Arc as a, I mean, a very different kind of organization, but,
[00:46:15.440 --> 00:46:16.800]   but an organization nonetheless.
[00:46:16.800 --> 00:46:20.240]   Or if you include all the features of Stripe, N equals like 10, 20 something.
[00:46:20.240 --> 00:46:20.740]   Okay.
[00:46:20.740 --> 00:46:23.760]   So, so yes, depending on your definition, maybe, maybe there's some kind of samples
[00:46:23.760 --> 00:46:24.260]   out there.
[00:46:24.260 --> 00:46:31.600]   I guess my general view is most products and most businesses, like things can just be
[00:46:31.600 --> 00:46:32.480]   done much better.
[00:46:32.480 --> 00:46:38.960]   And I think, I think moats are, are typically kind of overrated.
[00:46:38.960 --> 00:46:43.200]   And I mean, the payments are a great example of a domain where on a logical basis, you
[00:46:43.200 --> 00:46:47.040]   would say that there are so many sources of defensibility where there's, there's, you
[00:46:47.040 --> 00:46:51.840]   know, the network effects of the account holders and there's the data network effects slash
[00:46:51.840 --> 00:46:54.240]   economy of scale, you know, for fraud and so forth.
[00:46:54.240 --> 00:46:59.280]   And there are regulatory moats and barriers, you know, and, and, and, you know, and yet,
[00:47:00.160 --> 00:47:03.200]   you know, not, not only does Stripe exist, but there are lots of other, I mean, there's
[00:47:03.200 --> 00:47:04.480]   a whole FinTech ecosystem today.
[00:47:04.480 --> 00:47:04.980]   Right.
[00:47:04.980 --> 00:47:11.040]   So yeah, I, I think it gets down to, you know, kind of deep questions of, you know, what
[00:47:11.040 --> 00:47:15.040]   are the, what's the binding constraint on just the number of effective organizations
[00:47:15.040 --> 00:47:15.920]   that exist in the world.
[00:47:15.920 --> 00:47:18.960]   And, you know, for any given sector, why is it that number of companies, you know, rather
[00:47:18.960 --> 00:47:20.960]   than twice that number of companies and so on.
[00:47:20.960 --> 00:47:25.840]   I think it's about, I don't know, motivation and ideas and people's, you know, willingness
[00:47:25.840 --> 00:47:30.800]   and determination to organize talent and so forth, but, but, but these kinds of more sociocultural
[00:47:30.800 --> 00:47:38.080]   explanations rather than, I mean, Hamilton Helmer is probably the leading scholar of
[00:47:38.080 --> 00:47:41.360]   some of the, the sources of defensibility for businesses.
[00:47:41.360 --> 00:47:49.200]   And he has this, you know, kind of niche, but very well known in the niche book called
[00:47:49.200 --> 00:47:49.920]   seven powers.
[00:47:50.800 --> 00:47:55.600]   And it, it, it kind of tends to disaggregate all the various sources of, of market power
[00:47:55.600 --> 00:47:56.640]   in this respect.
[00:47:56.640 --> 00:48:00.560]   And, you know, I think that is true and important insofar as it goes.
[00:48:00.560 --> 00:48:05.920]   But nonetheless, it's kind of strange to me that nobody had done Stripe before Stripe.
[00:48:05.920 --> 00:48:10.880]   When you think about the, the fact that most are overrated and just like doing the thing
[00:48:10.880 --> 00:48:11.920]   is underrated.
[00:48:11.920 --> 00:48:14.640]   Does that like, what is Stripe's mode in that context?
[00:48:14.640 --> 00:48:17.600]   Does that make you, you know, think differently about Stripe's mode?
[00:48:18.640 --> 00:48:19.440]   Yes, one.
[00:48:19.440 --> 00:48:33.520]   And I guess I, I guess I do think that, that one can have organizational and cultural modes.
[00:48:33.520 --> 00:48:38.160]   And maybe this contradicts what I was just saying, or maybe it's consistent with it in
[00:48:38.160 --> 00:48:39.920]   the sense that it's a kind of cultural explanation.
[00:48:39.920 --> 00:48:47.760]   And I think that in as much as we have a mode, it's because we have a very good understanding
[00:48:47.760 --> 00:48:54.000]   of our domain and a set of people who actually care about solving the problems and who are,
[00:48:54.000 --> 00:48:57.920]   I don't know, continually paranoid at the prospect that we might be forgetting something
[00:48:57.920 --> 00:49:01.600]   important and sort of trying to figure out what the important thing that could supplant
[00:49:01.600 --> 00:49:04.880]   Stripe's approaches is and making sure that we build those first and so forth.
[00:49:04.880 --> 00:49:12.800]   I think, I think organizations that are, I mean, there's, you're familiar with conquest
[00:49:12.800 --> 00:49:18.560]   laws and there's conquest's third law, I guess, which is that one should model organizations
[00:49:18.560 --> 00:49:20.720]   as if they're run by a cabal of their enemies.
[00:49:20.720 --> 00:49:24.880]   And, you know, obviously it's, or presumably it's tongue in cheek.
[00:49:24.880 --> 00:49:27.840]   But, you know, it's interesting to try to think about like, well, kind of what is the
[00:49:27.840 --> 00:49:29.920]   kernel of truth in that and why would it be there?
[00:49:29.920 --> 00:49:34.800]   And I think what's going on is that I think most organizations, when they start out, are
[00:49:34.800 --> 00:49:36.800]   actually trying to achieve their stated goals.
[00:49:36.800 --> 00:49:41.600]   Like somebody started the organization for a reason and probably it was for the stated
[00:49:41.600 --> 00:49:47.600]   reason, but then over time, you know, that person and that, you know, set of people who
[00:49:47.600 --> 00:49:53.440]   initially populate the organization depart and some set of new people come to, you know,
[00:49:53.440 --> 00:49:54.000]   take their place.
[00:49:54.000 --> 00:49:57.200]   And there's, there's multiple versions of that, there's generational turnover on a
[00:49:57.200 --> 00:49:57.920]   continuous basis.
[00:49:57.920 --> 00:50:01.680]   But say for the fifth generation, like why are they there?
[00:50:01.680 --> 00:50:06.960]   And to what degree do kind of their particular specific local incentives align with the nominal,
[00:50:06.960 --> 00:50:08.960]   originally stated goals of the organization?
[00:50:08.960 --> 00:50:11.360]   And I think there can be a lot of misalignment there, right?
[00:50:11.360 --> 00:50:17.680]   Where they're following a local path and, and conceivably even the leader of the organization,
[00:50:17.680 --> 00:50:23.760]   not even through any like fault of their own per se necessarily, just that they're a human
[00:50:23.760 --> 00:50:24.880]   and they have their own incentives.
[00:50:24.880 --> 00:50:29.280]   And again, the original kind of constitutional incentives of the, of the organization might
[00:50:29.280 --> 00:50:29.920]   be quite different.
[00:50:29.920 --> 00:50:35.920]   And so I think this, I think this phenomenon is, is kind of a fact of life.
[00:50:35.920 --> 00:50:43.680]   And, and I think these kinds of explanations for me are, are much more explanatory in trying
[00:50:43.680 --> 00:50:46.000]   to figure out sort of why some of these things either happen or don't.
[00:50:46.000 --> 00:50:50.480]   And to your question, like in as much as Stripe has a moat, what is it?
[00:50:50.480 --> 00:50:55.920]   I think it's that, I mean, others can judge to what degree it's actually, you know,
[00:50:55.920 --> 00:50:57.280]   manifested and rooted in practice.
[00:50:57.280 --> 00:51:00.960]   I think it is, but you know, I'm a biased observer, but I think it would be that people
[00:51:00.960 --> 00:51:05.680]   at Stripe really care about solving the problems that we say we are trying to solve.
[00:51:06.000 --> 00:51:06.800]   Mm.
[00:51:06.800 --> 00:51:07.360]   Yeah.
[00:51:07.360 --> 00:51:11.600]   The, the, the point about the misalignment over generations or over time is interesting.
[00:51:11.600 --> 00:51:17.280]   And actually, do you have examples of institutions which have for decades or hundreds of years
[00:51:17.280 --> 00:51:23.600]   managed to keep their original, not only mission statement, but the organizational competence?
[00:51:23.600 --> 00:51:27.200]   Because you think of tech companies, even the oldest tech companies have not been around
[00:51:27.200 --> 00:51:27.760]   that long.
[00:51:27.760 --> 00:51:28.320]   Right.
[00:51:28.320 --> 00:51:29.920]   And they're some of the biggest tech companies in the world.
[00:51:29.920 --> 00:51:32.240]   And the median age of the corporation is like famously low.
[00:51:32.240 --> 00:51:34.480]   What is a good example here?
[00:51:35.360 --> 00:51:40.160]   I think some of the explanations around the effects of shareholder capitalism and sort
[00:51:40.160 --> 00:51:48.320]   of the idea that shareholder capitalism as a mechanism does in fact have, you know, has
[00:51:48.320 --> 00:51:54.000]   some consequence with respect to the incentives of organizations and their long-term fates.
[00:51:54.000 --> 00:51:56.240]   I think those theories have some credibility.
[00:51:56.240 --> 00:52:03.200]   And I think it is very plausible that shareholder capitalism even attenuates the duration of
[00:52:03.200 --> 00:52:04.080]   some of these organizations.
[00:52:04.080 --> 00:52:07.680]   I'm not saying that's definitively true, but I find it incredible, the idea that it is.
[00:52:07.680 --> 00:52:11.120]   It's not clear to me that that's necessarily bad, even if it is true.
[00:52:11.120 --> 00:52:11.520]   Right.
[00:52:11.520 --> 00:52:15.680]   In that, are we on the side of the humans or of the kind of aggregate innovation in the
[00:52:15.680 --> 00:52:20.160]   world or on the side of like the corporations, you know, qua legal entities?
[00:52:20.160 --> 00:52:22.960]   And, you know, yeah, it's not clear to me the answer.
[00:52:22.960 --> 00:52:23.600]   It should be the third.
[00:52:23.600 --> 00:52:30.320]   At the same time, or maybe in fact consistent with that, you know, if you look at say Europe
[00:52:30.320 --> 00:52:38.080]   or, you know, some other places like, you know, in Denmark, there's, for reasons related
[00:52:38.080 --> 00:52:43.040]   to the tax code there, a lot of organizations are either controlled by or, you know, very
[00:52:43.040 --> 00:52:47.600]   substantially held by non-profit foundations.
[00:52:47.600 --> 00:52:53.280]   And so Novo Nordisk, for example, you know, the GLP company, but Maersk, the shipping
[00:52:53.280 --> 00:52:59.680]   company, I believe also Lego, a lot of these corporations are controlled by, and again,
[00:52:59.680 --> 00:53:03.040]   usually have a lot of their stock held by foundations.
[00:53:03.040 --> 00:53:08.640]   That has the secondary effect in many cases where they actually do embed in a legally
[00:53:08.640 --> 00:53:10.240]   binding constitution their mission.
[00:53:10.240 --> 00:53:16.320]   And so, you know, I'm not an expert on Novo Nordisk, but I happened to get a book about
[00:53:16.320 --> 00:53:17.040]   it over Thanksgiving.
[00:53:17.040 --> 00:53:22.000]   And my, and actually there's also a book on the Danish industrial foundations.
[00:53:22.000 --> 00:53:27.520]   But it's enshrined in their constitution that they have to make insulin, you know,
[00:53:27.520 --> 00:53:31.360]   broadly available really cheaply, or at least cheaply in Scandinavian countries.
[00:53:31.360 --> 00:53:33.040]   And I think they're allowed to charge market prices elsewhere.
[00:53:33.040 --> 00:53:40.960]   And I think that, and then the rest of their profits, they have to, they're again, legally
[00:53:40.960 --> 00:53:43.280]   obligated to reinvest in R&D.
[00:53:43.280 --> 00:53:47.760]   You know, is that somehow causal in the fact that they then invented, you know, one of
[00:53:47.760 --> 00:53:53.600]   the most remarkable pharmacological discoveries of the last 20 years in these, you know, GLP
[00:53:53.600 --> 00:53:54.960]   one agonists?
[00:53:54.960 --> 00:53:56.480]   I mean, you know, plausibly.
[00:53:56.480 --> 00:54:03.120]   And, and so I think, yeah, I think, I think these questions around, you know, the, you
[00:54:03.120 --> 00:54:09.520]   know, why it is that the median age of organizations and corporations is what it is, are definitely
[00:54:09.520 --> 00:54:10.000]   interesting.
[00:54:10.000 --> 00:54:16.560]   And I suspect it's a somewhat contingent aspect of how we've chosen to organize large
[00:54:16.560 --> 00:54:18.160]   corporations, you know, in the US today.
[00:54:18.160 --> 00:54:22.080]   The thing you're mentioning about this firm seems very similar to the export-led growth
[00:54:22.080 --> 00:54:22.480]   in Asian.
[00:54:22.480 --> 00:54:23.920]   Totally, 100%.
[00:54:23.920 --> 00:54:24.640]   Right.
[00:54:24.640 --> 00:54:25.520]   You have tariffs.
[00:54:25.520 --> 00:54:28.320]   This one company, you're tasked with making the cars, but you better make the cars good.
[00:54:28.320 --> 00:54:31.520]   You have no competition, but you had to invent the best car in the world.
[00:54:31.520 --> 00:54:32.480]   Yes, yes, yes.
[00:54:32.480 --> 00:54:38.000]   And I think, I mean, you know, we are all fans of, you know, Smith and Ricardo and,
[00:54:38.000 --> 00:54:39.360]   you know, all these characters.
[00:54:39.360 --> 00:54:46.160]   And, and, you know, even they, I think, are sort of less dogmatically attached to free
[00:54:46.160 --> 00:54:49.200]   trade than perhaps, you know, people today interpret them as being.
[00:54:49.200 --> 00:54:52.800]   But, but I think people like, you know, Friedrich List and, you know, those other, not quite
[00:54:52.800 --> 00:54:58.240]   contemporaries, but, you know, quasi contemporaries, you know, are maybe on a relative basis underrated.
[00:54:58.240 --> 00:55:02.080]   And I do think, I mean, in as much as you believe the kind of sociological, cultural
[00:55:02.080 --> 00:55:09.040]   skill, whatever, even vague alignment, not in the AI sense, but in the more kind of interpersonal
[00:55:09.040 --> 00:55:14.000]   sense, in as much as you think these are important and explanatory, then, then yeah, I think,
[00:55:14.000 --> 00:55:18.160]   you know, you, you end up thinking about some of the things, the things you just raised.
[00:55:18.160 --> 00:55:21.200]   That's really interesting to hear you say that, because if you think about Stripe's
[00:55:21.200 --> 00:55:26.800]   mission, right, it's to facilitate global trade, to make sure that some firm from India
[00:55:26.800 --> 00:55:29.200]   can compete with any firm in Nigeria, whatever.
[00:55:29.200 --> 00:55:34.560]   So like the, the, the room for you to have this sort of learning curve where you're less
[00:55:34.560 --> 00:55:37.440]   efficient than the global competition should be less if Stripe exists, right?
[00:55:37.440 --> 00:55:38.080]   Yes.
[00:55:38.080 --> 00:55:40.160]   Isn't Stripe the anti-List company?
[00:55:40.160 --> 00:55:42.640]   Well, it depends which, which version of List.
[00:55:42.640 --> 00:55:47.200]   And, you know, I mean, and to be clear, I'm not sort of specifically endorsing these,
[00:55:47.200 --> 00:55:49.440]   these, you know, tariffs and, and trade barriers.
[00:55:49.440 --> 00:55:53.520]   I think the history associated with them is checkered at best.
[00:55:53.520 --> 00:56:01.360]   Look, I think it's possible that if you have a like a specific sector where you have, where
[00:56:01.360 --> 00:56:08.560]   you have, you know, clear goals and a credible path to actually achieving some substantial
[00:56:08.560 --> 00:56:12.640]   degree of success there, you know, and, and, and probably some more kind of conjoined propositions,
[00:56:12.640 --> 00:56:20.480]   then maybe some degree of, of, of activists trade policy, you know, might be on net the,
[00:56:20.480 --> 00:56:23.280]   the, the beneficial thing to do.
[00:56:23.280 --> 00:56:28.480]   I don't think that that describes most sectors in most countries at most times.
[00:56:28.480 --> 00:56:30.400]   And yeah.
[00:56:30.400 --> 00:56:31.280]   Hi, that's so interesting.
[00:56:31.280 --> 00:56:37.040]   Is I'm trying to, I think there's an interesting thread here and how it relates to Stripe climate
[00:56:37.040 --> 00:56:40.800]   in that you're, I don't know, like subsidizing these learning curves that these East Asian
[00:56:40.800 --> 00:56:42.560]   countries did for their own internal companies.
[00:56:42.560 --> 00:56:46.400]   I mean, you, you haven't picked out like a specific company that's going to necessarily
[00:56:46.400 --> 00:56:50.560]   be the key of carbon sequestration, but yeah.
[00:56:50.560 --> 00:56:51.200]   How do you think about this?
[00:56:51.200 --> 00:56:55.680]   Well, maybe a way to unify the, the, the, the two points and I'll speak up Stripe time
[00:56:55.680 --> 00:57:02.080]   in a second is that I think, I guess it's, it's Say's law about, you know, demand.
[00:57:02.080 --> 00:57:02.480]   Right.
[00:57:02.480 --> 00:57:03.600]   Creating supply.
[00:57:03.600 --> 00:57:07.840]   And in as much as Stripe aggregates more and more global demand, I guess part of the, I
[00:57:07.840 --> 00:57:12.400]   don't know, it seems to self-aggrandizing to call it, you know, the, the theory of Stripe,
[00:57:12.400 --> 00:57:16.480]   but you know, some, some vague hunch in Stripe is that, that, that, that that aggregation
[00:57:16.480 --> 00:57:20.880]   of demand can have important expansionary effects with respect to the ensuing supply.
[00:57:20.880 --> 00:57:25.040]   And yeah, Stripe climate is, is some version of this, you know, hypothesis applied in a
[00:57:25.040 --> 00:57:29.360]   much smaller scale than Stripe itself, but, but, but still, you know, real and, and well,
[00:57:29.360 --> 00:57:30.320]   we'll see maybe important.
[00:57:30.320 --> 00:57:33.680]   And the, the, the basic idea just for, for folks who aren't familiar, which I assume
[00:57:33.680 --> 00:57:34.400]   is most of your audience.
[00:57:35.600 --> 00:57:40.960]   So we, we, we observed in 2018, I guess that, that everyone seems to agree that carbon removal
[00:57:40.960 --> 00:57:42.320]   will be very important.
[00:57:42.320 --> 00:57:47.600]   And you know, even if we decarbonize the economy and the kind of timescale that optimistic
[00:57:47.600 --> 00:57:53.520]   people you know, on the most optimistic timeframes, there'll still be, you know, an accumulated
[00:57:53.520 --> 00:57:55.360]   stock of carbon that is a problem.
[00:57:55.360 --> 00:57:57.600]   It sounded pretty weird.
[00:57:57.600 --> 00:58:02.320]   There were, there were virtually no carbon removal companies in the world in 2018, maybe
[00:58:02.320 --> 00:58:03.680]   there were two or three or something.
[00:58:04.320 --> 00:58:07.040]   No companies had ever purchased from a carbon removal company.
[00:58:07.040 --> 00:58:08.640]   These were, these were really sort of science projects.
[00:58:08.640 --> 00:58:14.240]   And so we thought, well, you know, somebody's got to start and it might be valuable to,
[00:58:14.240 --> 00:58:17.440]   you know, not only transfer some dollars, but to kind of confer some credibility on
[00:58:17.440 --> 00:58:18.000]   this sector.
[00:58:18.000 --> 00:58:21.120]   Not that Stripe is the world's most credible company, but you know, it's better than nothing.
[00:58:21.120 --> 00:58:25.440]   And so we started contracting with some of these carbon removal companies that went pretty
[00:58:25.440 --> 00:58:27.600]   well and, and they seemed kind of appreciative of us.
[00:58:27.600 --> 00:58:29.440]   And so we thought somewhat more about this.
[00:58:29.440 --> 00:58:36.480]   And we then in 2021 formed Frontier, which is an AMC, an advanced market commitment.
[00:58:36.480 --> 00:58:45.360]   So inspired by the first AMC, which was a pre-commitment to purchase vaccines for developing
[00:58:45.360 --> 00:58:50.480]   world countries for diseases that, I mean, well, either were kind of market failures
[00:58:50.480 --> 00:58:53.600]   where pharma companies hadn't pursued the vaccines or, or were just like the profits
[00:58:53.600 --> 00:58:55.360]   weren't sufficient to pay for the program.
[00:58:55.360 --> 00:58:58.480]   So we said to the, for carbon removal, we raised a billion dollars.
[00:58:58.480 --> 00:59:03.120]   Stripe was the, you know, the, the, the first investor.
[00:59:03.120 --> 00:59:03.920]   We're not actually investing.
[00:59:03.920 --> 00:59:04.480]   We're just buying.
[00:59:04.480 --> 00:59:10.160]   So the first company to commit, but then we're joined by Shopify and Alphabet and Meta and
[00:59:10.160 --> 00:59:12.320]   JP Morgan and a bunch of other companies.
[00:59:12.320 --> 00:59:18.560]   And now there's, now there's like a fairly active sector of carbon removal companies.
[00:59:18.560 --> 00:59:25.520]   There, I think Frontier has contracted with 40, between 40 and 50 companies.
[00:59:25.520 --> 00:59:29.520]   And the overwhelming majority of which didn't exist when we start, start out with this.
[00:59:29.520 --> 00:59:34.320]   And actually we ran an anonymous survey back the end of last year.
[00:59:34.320 --> 00:59:38.800]   And, you know, we asked them to what degree was, was the existence of Frontier, you know,
[00:59:38.800 --> 00:59:42.080]   somewhat causal and, you know, they're selling the company in the first place.
[00:59:42.080 --> 00:59:43.760]   And again, there's an anonymous survey.
[00:59:43.760 --> 00:59:49.360]   And I think it was 70, 74% of the companies said that Frontier, you know, played a causal
[00:59:49.360 --> 00:59:51.120]   role in their selling the company.
[00:59:51.120 --> 00:59:56.960]   So yeah, I think I think this, these inducement effects can be pretty significant.
[00:59:56.960 --> 00:59:58.080]   Yeah, that's huge.
[00:59:58.080 --> 01:00:01.360]   Well, what are other ideas you've come across where an AMC would be an effective
[01:00:01.360 --> 01:00:03.120]   instrument of moving forward with the tech?
[01:00:03.120 --> 01:00:03.520]   Hmm.
[01:00:03.520 --> 01:00:04.160]   That's a good question.
[01:00:04.160 --> 01:00:06.800]   But we've actually been having some of that discussion internally.
[01:00:06.800 --> 01:00:12.240]   Just, it's not that we plan on doing it ourselves necessarily, but I'm just wondering,
[01:00:12.240 --> 01:00:17.360]   are there, you know, are there, are there people we should share our technology with?
[01:00:17.360 --> 01:00:21.200]   Not that it's even technology per se, but, but share our experience with or something
[01:00:21.200 --> 01:00:22.080]   and try to help along.
[01:00:22.080 --> 01:00:29.840]   I mean, there's still, I think there's still a lot of stuff in, in, in the biomedical fields.
[01:00:29.840 --> 01:00:38.640]   And I mean, patents are, you know, patents are pretty useful insofar as they go.
[01:00:38.640 --> 01:00:43.520]   But, you know, there's a lot of, there's a lot of innovation that seems like it would be,
[01:00:43.520 --> 01:00:50.000]   you know, socially beneficial that patents don't provide a way to cover the cost of.
[01:00:50.000 --> 01:00:55.200]   And so, you know, there was some excitement a few years ago about
[01:00:55.200 --> 01:00:58.880]   mannose, which is a, it's a sugar.
[01:00:58.880 --> 01:01:06.560]   And there was one paper that, or maybe a few papers, I can't remember, that suggests that
[01:01:06.560 --> 01:01:12.080]   maybe, maybe tumors will selectively take up mannose rather than glucose, but they can't
[01:01:12.080 --> 01:01:14.320]   actually metabolize it properly until they just die.
[01:01:14.320 --> 01:01:21.280]   And so, you know, maybe this could be an effective, you know, onco treatment of, of some sort.
[01:01:21.280 --> 01:01:25.360]   But mannose is, is like, it's a, it's a, it's a generic sugar.
[01:01:25.360 --> 01:01:29.360]   It's been, you know, understood for, I guess, more than a century.
[01:01:29.360 --> 01:01:31.760]   And you couldn't patent it, importantly.
[01:01:31.760 --> 01:01:37.360]   And so it's not clear who has the incentive to even, you know, fund the work to test,
[01:01:37.360 --> 01:01:39.600]   you know, whether or not this would actually work in practice.
[01:01:39.600 --> 01:01:43.520]   And, you know, this is not an endorsement of mannose, but just there are things of this
[01:01:43.520 --> 01:01:46.800]   shape where there's something where you can clearly see, wow, that, that might be very
[01:01:46.800 --> 01:01:50.080]   beneficial, but it's not totally clear how the kind of economic structure of the market
[01:01:50.080 --> 01:01:50.880]   can, can make it possible.
[01:01:50.880 --> 01:01:53.840]   So I think there are still a lot of those across the biomedical landscape.
[01:01:53.840 --> 01:01:57.520]   I mean, look, there are still a lot of vaccines that, you know, could in principle exist that
[01:01:57.520 --> 01:01:57.760]   don't.
[01:01:57.760 --> 01:02:03.120]   I mean, Lyme disease, you know, there's no, there's, there's one vaccine that, that was
[01:02:03.120 --> 01:02:06.640]   withdrawn from the market over some safety concerns that I think were misplaced, but,
[01:02:06.640 --> 01:02:08.240]   you know, it's still no vaccine.
[01:02:08.240 --> 01:02:11.760]   And it's not even that well understood, right?
[01:02:11.760 --> 01:02:13.120]   Like people have chronic Lyme disease.
[01:02:13.120 --> 01:02:14.640]   We don't know like if it's legit or not.
[01:02:14.640 --> 01:02:15.040]   Exactly.
[01:02:15.040 --> 01:02:15.840]   Yes, yes, yes.
[01:02:15.840 --> 01:02:19.280]   And, but it's a good question.
[01:02:19.280 --> 01:02:22.560]   I mean, look, maybe some of your listeners will know, yeah, we'll have ideas for, for
[01:02:22.560 --> 01:02:24.960]   fields for, you know, we, we sorely need an AMC.
[01:02:24.960 --> 01:02:25.520]   Hmm.
[01:02:25.520 --> 01:02:26.020]   Yeah.
[01:02:26.020 --> 01:02:28.240]   I want to go back to Stripe for a second.
[01:02:28.240 --> 01:02:34.960]   So you're famously, you know, appreciative of craft and beauty, but also you appreciate
[01:02:34.960 --> 01:02:36.880]   the power of scale and growth.
[01:02:36.880 --> 01:02:39.040]   Is there a type of speed?
[01:02:39.040 --> 01:02:39.600]   Oh, interesting.
[01:02:39.600 --> 01:02:39.840]   Okay.
[01:02:39.840 --> 01:02:40.340]   Yeah.
[01:02:40.340 --> 01:02:46.080]   But is there a type of craft that is just not amenable to speed, growth, scale?
[01:02:46.080 --> 01:02:49.680]   If you think like a Japanese chef, he's like learning to cook rice for, you know, a decade
[01:02:49.680 --> 01:02:51.760]   and then he can move on to the sushi or something.
[01:02:51.760 --> 01:02:54.000]   Is that just not competitive in the modern world?
[01:02:54.560 --> 01:02:59.680]   Craft, scale and, and speed.
[01:02:59.680 --> 01:03:03.280]   I don't know, they're strictly necessarily intention in every case, but they're definitely
[01:03:03.280 --> 01:03:04.320]   frequently intention.
[01:03:04.320 --> 01:03:07.680]   So just yes, I think is kind of one short answer to that.
[01:03:07.680 --> 01:03:16.400]   At the same time, a lot of the most successful companies are those that I think are distinguished
[01:03:16.400 --> 01:03:25.840]   by the extent to which they, they exhibit appreciation for and like skill in realizing
[01:03:25.840 --> 01:03:28.240]   craft and, and beauty.
[01:03:28.240 --> 01:03:31.440]   And so LVMH is one of the largest companies in the world and like that's literally their
[01:03:31.440 --> 01:03:31.940]   business.
[01:03:31.940 --> 01:03:34.400]   I mean, I think Tesla is pretty good at this.
[01:03:34.400 --> 01:03:39.120]   I mean, they're good at many things, but including this, obviously there's Apple.
[01:03:40.320 --> 01:03:47.120]   I mean, TSMC is a kind of, you know, it's not the Japanese sushi chef you mentioned,
[01:03:47.120 --> 01:03:53.360]   but it's the TSMC chip sushi chef in Taiwan.
[01:03:53.360 --> 01:03:58.960]   And so much, again, tacit knowledge and, you know, difficult to transfer skills.
[01:03:58.960 --> 01:04:09.600]   So I think it might be the case that craft and the pursuit of it is as important as
[01:04:10.160 --> 01:04:10.960]   as it's ever been.
[01:04:10.960 --> 01:04:20.800]   And, and certainly as, as Stripe has gotten larger, I think we ourselves have come to
[01:04:20.800 --> 01:04:27.760]   greater conviction in this where I think part of what's interesting about these aesthetic
[01:04:27.760 --> 01:04:31.440]   qualities is they're generally speaking unquantifiable.
[01:04:31.440 --> 01:04:34.000]   I don't know if they're intrinsically unquantifiable, like maybe you could like train a model to
[01:04:34.000 --> 01:04:39.200]   do so or something, but today they're, they're broadly speaking unquantifiable and yet they
[01:04:39.200 --> 01:04:44.320]   are actually, you know, they, they influence people in significant ways.
[01:04:44.320 --> 01:04:49.520]   People very demonstrably care about aesthetics and they care about, you know, if they're
[01:04:49.520 --> 01:04:53.600]   a company, they care about the aesthetic characteristics of the products that they produce,
[01:04:53.600 --> 01:04:56.240]   just like on an intuitive level, people know that that's true.
[01:04:56.240 --> 01:05:03.600]   But, you know, yeah, it's, it's, it's difficult to manage that at an organizational level
[01:05:03.600 --> 01:05:05.920]   where there isn't a P and L associated with it.
[01:05:05.920 --> 01:05:10.400]   And if you're screwing it up, you, you don't see a neat time series decline.
[01:05:10.400 --> 01:05:16.720]   But over the 14 years of Stripe, you know, we have, I guess, through a kind of not exactly
[01:05:16.720 --> 01:05:20.880]   trial and error, but just by studying cases where things worked well at Stripe and cases
[01:05:20.880 --> 01:05:24.880]   where things worked less well and what customers responded well to and so on.
[01:05:24.880 --> 01:05:30.400]   It really seems clear to us that even in a domain like ours, where we are selling primarily
[01:05:30.400 --> 01:05:34.960]   to businesses, that this is something that's, that's truly important.
[01:05:34.960 --> 01:05:40.880]   And also that in as much as, you know, getting back to what we were discussing previously,
[01:05:40.880 --> 01:05:48.800]   you want, in as much as the, the sociology and the kind of cultural explanations of
[01:05:48.800 --> 01:05:54.320]   defensibility are real, the best people, you know, consider themselves craftspeople in
[01:05:54.320 --> 01:06:00.160]   their domain, and they really above almost all else want to work with the best other
[01:06:00.160 --> 01:06:01.040]   people.
[01:06:01.040 --> 01:06:07.680]   And so I think it's, it may almost be true that even if from a customer facing standpoint,
[01:06:07.680 --> 01:06:12.720]   craft was not valued by the market, you actually might still want to build an organization
[01:06:12.720 --> 01:06:18.240]   that indexes very heavily on this because you just want the best people for other reasons.
[01:06:18.240 --> 01:06:20.640]   And now as it happens, I think customers do in fact value it.
[01:06:20.640 --> 01:06:22.880]   And I think the evidence is broadly consistent with that.
[01:06:22.880 --> 01:06:29.840]   But, but yeah, I think, I think it's very hard to assemble groups of the best people
[01:06:29.840 --> 01:06:32.080]   if you don't take the practice of the work super seriously.
[01:06:32.080 --> 01:06:38.800]   What kind of beauty or craft or simplicity is more important, interface or implementation?
[01:06:38.800 --> 01:06:42.240]   There's famously that essay that Unix is successful because the implementation is
[01:06:42.240 --> 01:06:43.840]   simple and not the interface.
[01:06:43.840 --> 01:06:49.120]   Yeah, I guess the interface is kind of simple, but it, there's a lot of like asterisks and
[01:06:49.120 --> 01:06:52.720]   caveats and edge cases that I guess Unix doesn't handle for you.
[01:06:52.720 --> 01:06:56.560]   But Stripe does, right?
[01:06:56.560 --> 01:06:59.520]   And presumably it depends what you're, what you're building, right?
[01:06:59.520 --> 01:07:02.800]   For, for TikTok, it's probably more important that their interface is simple.
[01:07:02.800 --> 01:07:05.600]   And even if their implementation is a mess, you know, that's, that's probably okay.
[01:07:05.600 --> 01:07:06.720]   Nothing it is, I have no idea.
[01:07:06.720 --> 01:07:15.280]   Whereas for Stripe, yeah, people are, people are on some level purchasing our architecture
[01:07:15.280 --> 01:07:19.440]   or, you know, purchasing their ability to do certain things and some set of things rather
[01:07:19.440 --> 01:07:22.960]   than some different set of things, you know, because of what our architecture makes easy
[01:07:22.960 --> 01:07:24.640]   and what, and, and makes possible.
[01:07:24.640 --> 01:07:29.520]   Now, I don't think, I mean, if by interface, you mean the visual, you know, GUI interface,
[01:07:29.520 --> 01:07:33.920]   then, you know, maybe we can draw some separation there, but I guess we, we don't really draw that
[01:07:33.920 --> 01:07:34.320]   distinction.
[01:07:34.320 --> 01:07:37.600]   Like we think of the interface to Stripe as being the architecture.
[01:07:37.600 --> 01:07:38.080]   Right.
[01:07:38.080 --> 01:07:43.920]   We're, we're, we're selling, you know, no one else seems to agree with me, but I often think
[01:07:43.920 --> 01:07:52.960]   of Stripe in the, as similar to Mathematica, where we're selling kind of a, a, a self-contained
[01:07:52.960 --> 01:07:59.680]   universe to model whatever it is, is of interest to you and that, that, you know, you care about.
[01:07:59.680 --> 01:08:05.520]   And we're providing some primitives and some, some, yes, kind of interfaces and tools and
[01:08:05.520 --> 01:08:07.680]   so forth to enable your modeling.
[01:08:07.680 --> 01:08:11.680]   But fundamentally we're helping you do something in your own terms.
[01:08:12.480 --> 01:08:15.760]   And, you know, in that sense, I don't think kind of the architecture and the, and the
[01:08:15.760 --> 01:08:18.080]   interface are, are necessarily that separable.
[01:08:18.080 --> 01:08:19.200]   That's really interesting analogy.
[01:08:19.200 --> 01:08:24.640]   Although, I mean, if you think of Mathematica, the, the, like the entry that that's giving
[01:08:24.640 --> 01:08:27.920]   you to is, you know, just like the platonic objects of math.
[01:08:27.920 --> 01:08:28.320]   Right.
[01:08:28.320 --> 01:08:32.000]   Whereas for you guys, it's like the entries that's like visa error codes, right?
[01:08:32.000 --> 01:08:32.880]   Right, right, right, right.
[01:08:32.880 --> 01:08:35.760]   Like the, the end object is not the, you know, the platonic.
[01:08:35.760 --> 01:08:39.200]   That's, that's true though in, in, in both cases.
[01:08:39.200 --> 01:08:41.120]   Yeah, I think, yes.
[01:08:41.120 --> 01:08:43.520]   So, so the analogy falls down in, in a few respects.
[01:08:43.520 --> 01:08:50.880]   But, but look, I mean, the idea of a transaction is pretty fundamental and is, you know, roughly
[01:08:50.880 --> 01:08:55.040]   as old as, you know, the, the quadratic equation or something, I guess the transaction is older.
[01:08:55.040 --> 01:09:01.680]   And, and Mathematica, especially today, excuse me, today now supports all kinds of, I mean,
[01:09:01.680 --> 01:09:06.000]   to a very impressive extent, supports all kinds of like crazy arcane stuff.
[01:09:06.000 --> 01:09:09.120]   Like if you go through the more obscure packages in Mathematica, you can definitely find things
[01:09:09.120 --> 01:09:14.480]   that are, I think, much less broadly employed and, and understood even than, than visa error
[01:09:14.480 --> 01:09:15.200]   codes or something.
[01:09:15.200 --> 01:09:16.960]   So, but, but yes, look, these are not the same.
[01:09:16.960 --> 01:09:20.400]   It's more today, I, I find it to be a kind of a, an interesting source of intuition.
[01:09:20.400 --> 01:09:23.280]   And I think what, what Wolfram has done with Mathematica is pretty amazing.
[01:09:23.280 --> 01:09:23.920]   Yeah.
[01:09:23.920 --> 01:09:27.280]   Another way in which I'm curious, how you think about this?
[01:09:27.280 --> 01:09:31.120]   One way in which Mathematica maybe differs is if they had to make a change in Mathematica,
[01:09:31.120 --> 01:09:33.120]   like big deal, somebody has to learn new syntax.
[01:09:33.120 --> 01:09:36.320]   If you make a change, you know, it's like billions of dollars of,
[01:09:36.320 --> 01:09:38.340]   Yeah.
[01:09:38.720 --> 01:09:39.920]   Transactions don't happen.
[01:09:39.920 --> 01:09:40.420]   Right.
[01:09:40.420 --> 01:09:45.120]   Like what, how does that change the way you think about the initial architecture and just
[01:09:45.120 --> 01:09:45.840]   the stakes?
[01:09:45.840 --> 01:09:46.340]   Yeah.
[01:09:46.340 --> 01:09:47.440]   It's a good question.
[01:09:47.440 --> 01:09:54.400]   Well, actually, first the point on just beauty with respect to architecture, then I'll answer
[01:09:54.400 --> 01:09:54.800]   that one.
[01:09:54.800 --> 01:10:00.480]   So just as a side note, I guess, I think it's interesting that API design in general doesn't
[01:10:00.480 --> 01:10:03.040]   get more study as a discipline and as a practice.
[01:10:03.040 --> 01:10:08.560]   I think it, I think it plays a significant role in the fate of platforms.
[01:10:09.520 --> 01:10:12.080]   Or can, I'm not saying it's always the determinative thing.
[01:10:12.080 --> 01:10:18.480]   And if you get it right, you know, there can be compounding positive benefits, you know,
[01:10:18.480 --> 01:10:19.280]   and the converse.
[01:10:19.280 --> 01:10:25.200]   And I think it's really striking that with, say with, you know, mobile app development,
[01:10:25.200 --> 01:10:30.640]   which was one of the most dynamic and fast moving ecosystems of the past 10 or 15 years,
[01:10:30.640 --> 01:10:36.880]   that, you know, so many of the objects and the classes, say in iOS development are prefixed
[01:10:36.880 --> 01:10:41.760]   with NS, less so now with Swift, but, you know, for much of the iPhone's history.
[01:10:41.760 --> 01:10:46.160]   And, you know, the NS of course refers to next step, you know, back from next in the
[01:10:46.160 --> 01:10:46.800]   90s.
[01:10:46.800 --> 01:10:54.480]   But then when you get API design and architecture right, it can be so enduring over literally
[01:10:54.480 --> 01:10:55.440]   multiple decades.
[01:10:55.440 --> 01:11:03.440]   And, you know, even the face of what are otherwise kind of frenzied evolutions in everything
[01:11:03.440 --> 01:11:04.000]   around it.
[01:11:04.560 --> 01:11:10.480]   And Unix, of course, is kind of another example of this where, yes, Unix has tons of shortcomings,
[01:11:10.480 --> 01:11:15.440]   but like the architecture has basically worked for now, you know, more than, I guess, around
[01:11:15.440 --> 01:11:16.160]   half a century.
[01:11:16.160 --> 01:11:22.400]   And so, you know, we're all trying to impress upon people at Stripe the importance of multi
[01:11:22.400 --> 01:11:24.000]   decadal abstractions.
[01:11:24.000 --> 01:11:31.440]   And I think people sometimes respond to that thinking that that's some insanely lofty,
[01:11:31.440 --> 01:11:36.640]   kind of implausibly ambitious, I don't know, hyperbole.
[01:11:36.640 --> 01:11:41.200]   But no, I think that's actually just what happens when you get this stuff right.
[01:11:41.200 --> 01:11:50.320]   And if, in fact, you get it right, you can just reap these, or really the people building
[01:11:50.320 --> 01:11:53.840]   on your platform can reap these incredible benefits for a very long time.
[01:11:53.840 --> 01:11:59.600]   To the Mathematica point, they, I know, take backwards compatibility really seriously,
[01:12:00.240 --> 01:12:08.080]   where you can run programs, you know, written 20 years ago, unchanged in today's Mathematica.
[01:12:08.080 --> 01:12:12.640]   That really raises the stakes in API design for sort of obvious reasons.
[01:12:12.640 --> 01:12:16.640]   And we have that same problem ourselves, where when we think about introducing something
[01:12:16.640 --> 01:12:20.960]   new, it's not just, does this like exigently address the particular need that's motivating
[01:12:20.960 --> 01:12:21.440]   it today?
[01:12:21.440 --> 01:12:26.160]   But, you know, do we think we can stand behind this, you know, in 2044?
[01:12:27.040 --> 01:12:32.960]   And how do we think the world might evolve around us such that it all remains coherent?
[01:12:32.960 --> 01:12:35.040]   And we certainly don't always get that right.
[01:12:35.040 --> 01:12:37.520]   But that's on some of what we're trying to do.
[01:12:37.520 --> 01:12:39.360]   Is vZenit an example of this?
[01:12:39.360 --> 01:12:43.840]   And one might even say that one of the downsides of being able to use implementation for many
[01:12:43.840 --> 01:12:47.920]   decades in the future is, even if it's self-sustainable, and you have this ecosystem
[01:12:47.920 --> 01:12:54.400]   and equilibrium set around it, if you, you know, can't modify it, just because of people's
[01:12:54.400 --> 01:12:58.160]   local incentives, you get stuck in this equilibrium that's worse than it could be otherwise.
[01:12:58.160 --> 01:12:58.720]   I see, I see.
[01:12:58.720 --> 01:13:06.720]   I think the card networks generally, Visa and MasterCard, are, you know, are pretty
[01:13:06.720 --> 01:13:07.520]   good at equilibrium.
[01:13:07.520 --> 01:13:14.240]   Where it's easy to judge today with, you know, the world as it exists in 2024.
[01:13:14.240 --> 01:13:18.080]   But I think you have to look at the world as it was when they started out, and the particular
[01:13:18.080 --> 01:13:19.360]   problems that they're solving.
[01:13:19.360 --> 01:13:25.200]   I think when you compare the financial landscape in the US or in the Western world to those
[01:13:25.200 --> 01:13:30.800]   in other places, it's certainly not clear to me that the US has gotten, you know, a
[01:13:30.800 --> 01:13:33.920]   bad hand, so to speak, or is somehow stuck in any meaningful way.
[01:13:33.920 --> 01:13:38.480]   So, you know, the card networks do a couple of things.
[01:13:38.480 --> 01:13:45.520]   They, originally, they were designed to replace store credit.
[01:13:46.160 --> 01:13:50.320]   And to, I mean, it was a credit card originally, not a debit card, right?
[01:13:50.320 --> 01:13:52.560]   And that was important.
[01:13:52.560 --> 01:13:56.320]   And, you know, the availability of structured consumer credit, I think, is actually a pretty
[01:13:56.320 --> 01:14:00.640]   big deal, and pretty beneficial, and especially beneficial, typically, for lower income people.
[01:14:00.640 --> 01:14:07.600]   And then, you know, with the advent, I guess, of jet travel and, you know, mass market tourism
[01:14:07.600 --> 01:14:13.200]   and so forth, then, you know, they helped supplant traveler's checks and, you know,
[01:14:13.200 --> 01:14:16.640]   various worse alternatives, like carrying, you know, cash around in your little bag.
[01:14:16.640 --> 01:14:20.720]   And then with the internet, you know, they were substantially involved in enabling online
[01:14:20.720 --> 01:14:21.280]   transactions.
[01:14:21.280 --> 01:14:27.280]   And, you know, I think that the fact that they got the architecture so right, that so
[01:14:27.280 --> 01:14:32.160]   much of this, you know, so many of these different use cases were able to be addressed by their
[01:14:32.160 --> 01:14:34.160]   core design, is just really impressive.
[01:14:34.160 --> 01:14:38.640]   And, like, the guy who designed all this, D. Hawk, I think is, I mean, he was just,
[01:14:38.640 --> 01:14:40.080]   he was a remarkable person.
[01:14:40.080 --> 01:14:45.600]   And even, I mean, people complain about interchange, and I mean, lest I sound like a defender of,
[01:14:45.600 --> 01:14:47.360]   you know, the card ecosystem.
[01:14:47.360 --> 01:14:52.080]   I mean, like, Stripe is on the, well, it depends, you could look at multiple ways, but, like,
[01:14:52.080 --> 01:14:58.480]   many people consider Stripe to be on the wrong side of the interchange cost equation, in
[01:14:58.480 --> 01:15:02.960]   the sense that, you know, we're giving away the interchange revenue to other companies.
[01:15:02.960 --> 01:15:07.680]   And so, I don't think I'm structurally biased in favor of interchange.
[01:15:08.320 --> 01:15:12.160]   And yet, I will say, I think it's pretty interesting what interchange made possible, where
[01:15:12.160 --> 01:15:20.000]   it's a distribution incentive fee, where you're paying other entities to go and, like, do
[01:15:20.000 --> 01:15:24.080]   the work of recruiting these customers and convincing them to get a card and, you know,
[01:15:24.080 --> 01:15:27.840]   getting them to maintain the card and to pay it off at the end of the month and, like,
[01:15:27.840 --> 01:15:28.640]   all this stuff.
[01:15:28.640 --> 01:15:30.400]   So, you're paying for that, just the pure distribution.
[01:15:30.400 --> 01:15:33.920]   Like, there's a person at the end of the flight telling you, "Hey, sign up for the United
[01:15:33.920 --> 01:15:36.560]   credit card," or whatever, but, like, you know, that's what interchange is paying for.
[01:15:36.560 --> 01:15:37.920]   That kind of annoys me.
[01:15:37.920 --> 01:15:42.240]   Well, we'll get to the counterfactuals in a second.
[01:15:42.240 --> 01:15:43.840]   So, there's that.
[01:15:43.840 --> 01:15:46.640]   There's, you know, paying for the actual credit issuance itself.
[01:15:46.640 --> 01:15:50.560]   And then, there's, you know, the customer support and, you know, all the ancillary things
[01:15:50.560 --> 01:15:52.480]   around the dispute handling and so forth.
[01:15:52.480 --> 01:15:56.960]   And then, I think it is interesting to look at the cases where, for whatever contingent
[01:15:56.960 --> 01:15:59.440]   reason, you know, the card networks didn't rise.
[01:15:59.440 --> 01:16:02.000]   So, Germany is, you know, one of the classic ones.
[01:16:02.000 --> 01:16:05.120]   And, like, dealing with the, I mean, from our vantage point, at least, dealing with
[01:16:05.120 --> 01:16:09.040]   the online economy in Germany as compared to the US is so much worse.
[01:16:09.040 --> 01:16:13.040]   Like, if Strike could push a button and have, you know, really broadly adopted cards in
[01:16:13.040 --> 01:16:16.080]   Germany, ally the US, we would, like, push the hell out of that button, right?
[01:16:16.080 --> 01:16:25.920]   You can look at China, which, on the one hand, does have, you know, Alipay and WePay or,
[01:16:25.920 --> 01:16:28.720]   you know, WeChat payments are really ubiquitous.
[01:16:28.720 --> 01:16:33.360]   And so, in that sense, they're very digitally enabled from a transactional standpoint.
[01:16:33.360 --> 01:16:38.240]   But those products don't tend to be as sophisticated with consumer credit.
[01:16:38.240 --> 01:16:42.240]   And so, yes, the kind of the transaction fees for transferring money that you, in fact,
[01:16:42.240 --> 01:16:44.720]   already have are, you know, that's super cheap.
[01:16:44.720 --> 01:16:48.080]   But I think you need to look at it on kind of a fully loaded basis where, okay, but what
[01:16:48.080 --> 01:16:51.120]   about the cost of actually getting the credit to make the purchase in the first place, you
[01:16:51.120 --> 01:16:52.720]   know, as a credit card would enable?
[01:16:52.720 --> 01:16:56.960]   And I think as you look at these other counterfactuals in other places, one feels a kind
[01:16:56.960 --> 01:17:02.960]   of, you know, gratitude for what it is that DHOC and, you know, and Visa and MasterCard
[01:17:02.960 --> 01:17:04.160]   and the card networks made possible.
[01:17:04.160 --> 01:17:10.240]   And look, I'm not saying they're perfect or anything, but I think that I'm most interested
[01:17:10.240 --> 01:17:11.040]   in critiques.
[01:17:11.040 --> 01:17:15.040]   I'm not saying, again, that one can't make them, but just I'm most interested in critiques
[01:17:15.040 --> 01:17:19.600]   from people who've really studied the ecosystems of other countries, because I think it's easy
[01:17:19.600 --> 01:17:25.360]   to underestimate what we got in their invention.
[01:17:25.920 --> 01:17:29.520]   Maybe there's a sort of Chester James Fenns kind of thing going on here.
[01:17:29.520 --> 01:17:34.720]   If you had to design payments from first principles now, does it make sense that, you know, all
[01:17:34.720 --> 01:17:40.240]   these things you mentioned, taking on credit risk, the chance of fraud, dispute adjudication,
[01:17:40.240 --> 01:17:44.880]   should that cost like 2%, 3% of each transaction that happens in the economy?
[01:17:44.880 --> 01:17:48.640]   What would payments look like if you had to design that from first principles?
[01:17:48.640 --> 01:17:55.680]   Well, we're seeing a live version of this experiment play out for the first time in
[01:17:55.680 --> 01:17:59.840]   many years in a number of countries today, where central banks are becoming more active
[01:17:59.840 --> 01:18:02.000]   in designing national payment schemes.
[01:18:02.000 --> 01:18:07.200]   And so PIX in Brazil launched in late 2020, I think.
[01:18:07.200 --> 01:18:12.960]   But I'm sure you've heard of UPI, the central bank.
[01:18:12.960 --> 01:18:18.320]   UPI was kind of the instigator here, where it's the central bank payment system in India.
[01:18:18.320 --> 01:18:21.680]   And it was tied up with Aadhaar and their national identity system and so on.
[01:18:21.680 --> 01:18:24.960]   But that inspired a lot of central bankers in other countries to go and build their own
[01:18:24.960 --> 01:18:25.600]   UPIs.
[01:18:25.600 --> 01:18:28.160]   And so, yeah, PIX in Brazil launched in 2020.
[01:18:28.160 --> 01:18:34.400]   And now a significant majority of all Brazilian adults are like weekly active users of PIX,
[01:18:34.400 --> 01:18:36.080]   again, even though it launched in 2020.
[01:18:36.080 --> 01:18:40.560]   So it just had this incredibly rapid adoption curve.
[01:18:40.560 --> 01:18:42.480]   You have Swish in Sweden.
[01:18:42.480 --> 01:18:49.600]   You've, you know, there's, I mean, across East Asia, Japan, Thailand, Switzerland, you
[01:18:49.600 --> 01:18:53.040]   know, central bank after central bank are deciding, hey, you know, we should have our
[01:18:53.040 --> 01:18:53.760]   version of this.
[01:18:53.760 --> 01:18:57.520]   And so this is a kind of reinvention of the payment system from scratch.
[01:18:57.520 --> 01:19:04.560]   For kind of hard to understand reasons, yeah, things typically seem like once you layer
[01:19:04.560 --> 01:19:10.960]   in the customer support and the consumer protection and the fraud prevention and the anti-money
[01:19:10.960 --> 01:19:16.160]   laundering controls and the credit, you know, the thing just for some weird reasons seemed
[01:19:16.160 --> 01:19:18.640]   to asymptote it around, you know, two or three percent.
[01:19:18.640 --> 01:19:22.000]   It's important to also note that a lot of the two or three percent, you know, beyond
[01:19:22.000 --> 01:19:28.240]   just covering the costs, much of the surplus ends up getting remitted to consumers in the
[01:19:28.240 --> 01:19:31.440]   form of rewards, not in every country, but in many countries.
[01:19:31.440 --> 01:19:41.920]   And if you look at the public reports from various banks in the US, like their interchange
[01:19:41.920 --> 01:19:45.920]   revenue where, you know, they're getting these delicious fees on every transaction,
[01:19:45.920 --> 01:19:48.720]   you know, as you put it, like a lot of that is going straight back out the door to the
[01:19:48.720 --> 01:19:49.760]   consumers themselves and so on.
[01:19:49.760 --> 01:19:53.440]   So anyway, it's not clear how exactly one should think about the economics, like if
[01:19:53.440 --> 01:19:56.400]   it's going back to the consumer, should you include that as a transaction tax or is it
[01:19:56.400 --> 01:19:58.880]   just like a weird sort of a weird circular relationship?
[01:19:58.880 --> 01:20:07.200]   I've not seen any evidence to suggest that the two percent or thereabouts is massively
[01:20:07.200 --> 01:20:09.440]   inefficient in the scheme of things.
[01:20:09.440 --> 01:20:14.320]   Not saying it's the optimal level, maybe one percent would be better, but, you know, within
[01:20:14.320 --> 01:20:17.440]   some range of one to three percent, it's probably reasonable.
[01:20:19.120 --> 01:20:29.680]   The, I mean, as we think about some of these, I don't know, these ad valorem fees and, you
[01:20:29.680 --> 01:20:36.960]   know, figures, I think the place where there's even more change at the moment that we find
[01:20:36.960 --> 01:20:41.680]   ourselves thinking more about is actually the changing structure of global tax, where,
[01:20:43.680 --> 01:20:50.080]   you know, the idea of there's been a reasonable amount of innovation, I guess, in the tax
[01:20:50.080 --> 01:20:55.680]   domain over the last century, where, you know, income taxes got pretty high, value added
[01:20:55.680 --> 01:20:56.560]   taxes and so on.
[01:20:56.560 --> 01:21:06.720]   Like the new thing, at least, you know, in the online context is jurisdictions remitting
[01:21:07.600 --> 01:21:13.280]   or, excuse me, are imposing sales taxes on businesses that don't have any kind of locus
[01:21:13.280 --> 01:21:14.560]   in the jurisdiction in question.
[01:21:14.560 --> 01:21:21.920]   So you're a, you know, you're a podcaster in the Bay Area and, you know, the Dworkesh
[01:21:21.920 --> 01:21:29.920]   merch store, you know, will have to pay, you know, the town of Uppsala in Sweden will have
[01:21:29.920 --> 01:21:32.800]   a special tax on baseball caps.
[01:21:32.800 --> 01:21:37.280]   And, you know, you will need to know about that particular tax on baseball caps and any
[01:21:37.280 --> 01:21:40.800]   baseball caps that you are selling to the Uppsalans, you know, you'll have to collect
[01:21:40.800 --> 01:21:48.080]   that amount from the buyer and report to Uppsala and then eventually figure out how you're
[01:21:48.080 --> 01:21:49.280]   going to, like, get that money to Uppsala.
[01:21:49.280 --> 01:21:52.720]   And obviously, it's this, like, combinatoric problem of, you know, buyer jurisdictions
[01:21:52.720 --> 01:21:58.400]   and, you know, product types and then all the different jurisdictions that you have
[01:21:58.400 --> 01:22:00.160]   to remit the money to.
[01:22:01.200 --> 01:22:06.640]   And, you know, those amounts, you know, we're not talking, you know, three basis points,
[01:22:06.640 --> 01:22:10.400]   you know, the taxes in question are often, you know, 5% or 10% or something.
[01:22:10.400 --> 01:22:11.520]   So it's not trivial.
[01:22:11.520 --> 01:22:18.480]   And so just as I think about sort of the funds flows on the internet and, like, how all that's
[01:22:18.480 --> 01:22:23.040]   evolving and unfolding, I think changes in tax law are actually a much bigger deal than
[01:22:23.040 --> 01:22:24.480]   anything about the transactional economics.
[01:22:24.480 --> 01:22:25.120]   Yeah, yeah.
[01:22:25.120 --> 01:22:28.320]   But by the way, it's not the Dworkesh podcast, it's Lunar Society podcast LLC, registered
[01:22:28.320 --> 01:22:31.280]   on Stripe Atlas.
[01:22:31.280 --> 01:22:34.240]   Any merchandise I sell in the future, Stripe will take care of that.
[01:22:34.240 --> 01:22:34.560]   Yes.
[01:22:34.560 --> 01:22:36.400]   OK, well, if there's ever any Stripe complaints, we...
[01:22:36.400 --> 01:22:37.840]   No, it's great.
[01:22:37.840 --> 01:22:38.800]   It's been super useful, honestly.
[01:22:38.800 --> 01:22:41.840]   Like, it would have been much more difficult to get business operations going.
[01:22:41.840 --> 01:22:46.800]   Do you think, sorry, I know you're supposed to be interviewing me, but did Stripe play
[01:22:46.800 --> 01:22:51.520]   any, like, even on the margins counterfactual role in you charging for anything?
[01:22:51.520 --> 01:22:53.840]   Because this is the thing we're always interested in, like, when we talk about sort of growing
[01:22:53.840 --> 01:22:57.680]   the GDP of the internet, it's not like, get the existing GDP onto our rails, it's sort
[01:22:57.680 --> 01:23:02.800]   of, you know, where on the margin can we cause there to be economic activity that isn't already
[01:23:02.800 --> 01:23:03.280]   occurring?
[01:23:03.280 --> 01:23:10.640]   So, yeah, like, you did, in fact, start the podcast, you know, before incorporating, but,
[01:23:10.640 --> 01:23:16.320]   you know, were we, you know, causal in any fashion in, like, the merch or anything of
[01:23:16.320 --> 01:23:16.800]   that nature?
[01:23:16.800 --> 01:23:23.360]   I, like, to the extent that, like, Substack would not be a convenient place to get payments
[01:23:23.360 --> 01:23:26.240]   from to begin with, that's, like, definitely a thing.
[01:23:26.240 --> 01:23:29.520]   And also, you know, you wouldn't charge for the newsletter if Substack hadn't made it
[01:23:29.520 --> 01:23:30.160]   super easy.
[01:23:30.160 --> 01:23:30.480]   Yeah.
[01:23:30.480 --> 01:23:33.440]   And also, if I do, like, an ad or something, it's just, like, I wouldn't even know how
[01:23:33.440 --> 01:23:39.040]   to begin with getting the money if I didn't already have an LLC through Stripe that, with
[01:23:39.040 --> 01:23:40.720]   an associated bank account that I can get money through.
[01:23:40.720 --> 01:23:45.840]   So, yeah, probably counterfactually responsible for a lot of the monetization.
[01:23:45.840 --> 01:23:46.720]   Ah, that's cool.
[01:23:46.720 --> 01:23:47.220]   Yeah, yeah, yeah.
[01:23:47.220 --> 01:23:49.440]   Appreciate it.
[01:23:52.080 --> 01:23:56.880]   So what are some unexpected compliments to payment processing you see in the future?
[01:23:56.880 --> 01:24:03.840]   So, you know, all this stuff, Atlas, identity fraud, detection, you know, in retrospect,
[01:24:03.840 --> 01:24:07.680]   it might not have been obvious back then there was a good compliment.
[01:24:07.680 --> 01:24:08.560]   Now it does seem that way.
[01:24:08.560 --> 01:24:10.320]   What would be like this in 5, 10 years?
[01:24:10.320 --> 01:24:20.320]   Honestly, our problem ends up being that, you know, too many things, you know, more
[01:24:20.320 --> 01:24:23.440]   things that we can possibly pursue look like compliments, right?
[01:24:23.440 --> 01:24:30.000]   In that, you know, every business almost by definition has revenue.
[01:24:30.000 --> 01:24:35.360]   And so we obviously want to help them generate and accept and manage and orchestrate, you
[01:24:35.360 --> 01:24:36.800]   know, everything pertaining to that revenue.
[01:24:36.800 --> 01:24:40.800]   But once you're, you know, once you're in that flow and you kind of just go through
[01:24:40.800 --> 01:24:48.400]   the steps of running a business, yeah, a lot else looks relevant and somehow connects quite
[01:24:48.400 --> 01:24:57.520]   directly, you know, we're not, I mean, when Stripe started out, Stripe seemed like it
[01:24:57.520 --> 01:24:58.560]   definitely wasn't cool.
[01:24:58.560 --> 01:25:02.560]   It was sort of the opposite for just a couple of us.
[01:25:02.560 --> 01:25:06.320]   And we thought that we could make this the superior payments API.
[01:25:06.320 --> 01:25:13.520]   And for the vast majority of its history, Stripe has, I think, attracted people who
[01:25:13.520 --> 01:25:19.520]   are drawn to unglamorous infrastructure challenges and problems.
[01:25:19.520 --> 01:25:26.800]   And, you know, we're not a company that specializes in, you know, making beautiful cars.
[01:25:26.800 --> 01:25:28.080]   We make roads.
[01:25:28.080 --> 01:25:36.480]   And I bring all of that up because I think it's relevant to this kind of compliment question
[01:25:36.480 --> 01:25:42.960]   where, you know, in our discussions internally, a lot of it and by the significant majority
[01:25:42.960 --> 01:25:48.880]   of it is still about, okay, where are there actual practical shortcomings and limitations
[01:25:48.880 --> 01:25:50.800]   in even our core bread and butter?
[01:25:50.800 --> 01:25:55.120]   And that's not, I mean, payment processing might be a slightly too limited term to use
[01:25:55.120 --> 01:25:55.920]   for it.
[01:25:55.920 --> 01:26:03.680]   Maybe it's more about just global programmable money orchestration, which, yes, is consumer
[01:26:03.680 --> 01:26:06.560]   to business payments, you know, the sort that we were just discussing in, say, the context
[01:26:06.560 --> 01:26:09.040]   of your sub-stack, but it's also business to business payments.
[01:26:09.680 --> 01:26:13.920]   It's also payments for those credit or lending involved.
[01:26:13.920 --> 01:26:16.320]   It's also how you hold money.
[01:26:16.320 --> 01:26:18.640]   It's how you convert money between different currencies.
[01:26:18.640 --> 01:26:25.760]   It's how you represent money that's held by different legal entities and how we make it
[01:26:25.760 --> 01:26:32.160]   possible for even individuals or small businesses to act as kind of micro multinationals and
[01:26:32.160 --> 01:26:33.040]   all this kind of stuff.
[01:26:33.040 --> 01:26:38.560]   But those problems that we just skimmed over are all, even though they all directly pertain
[01:26:38.560 --> 01:26:40.720]   to the movement of money, they're not small.
[01:26:40.720 --> 01:26:49.360]   And if we could just solve those really, really effectively, then, you know, Stripe will be
[01:26:49.360 --> 01:26:53.920]   a very consequential organization and I think force in the world.
[01:26:53.920 --> 01:26:58.160]   And, you know, I think the counterfactual importance of building some of this stuff
[01:26:58.160 --> 01:27:03.920]   as we go to newer markets that are on a relative basis more poorly served is actually increasing
[01:27:03.920 --> 01:27:04.720]   rather than shrinking.
[01:27:05.200 --> 01:27:08.640]   In the US, there were payments companies before Stripe, and maybe if Stripe had never done
[01:27:08.640 --> 01:27:13.840]   its thing, eventually you'd have found some way to monetize a newsletter or something
[01:27:13.840 --> 01:27:14.240]   like that.
[01:27:14.240 --> 01:27:26.240]   But if you're in Albania, the set of options available to you is far more restricted.
[01:27:26.240 --> 01:27:31.200]   And so I think that the marginal impact as we expand globally increases quite a bit.
[01:27:31.760 --> 01:27:37.280]   So that's all to say that even though we are interested in and do today pursue some of
[01:27:37.280 --> 01:27:43.920]   these direct adjacencies, I think that the core problem of global sort of money orchestration
[01:27:43.920 --> 01:27:48.720]   remains a really big and unsolved problem.
[01:27:48.720 --> 01:27:53.760]   Does that look like being a better interface for all these complexities and glossing them
[01:27:53.760 --> 01:27:55.760]   over under the seven lines of code?
[01:27:55.760 --> 01:28:00.320]   Or does that look like actually replacing the rails and the infrastructure to make all
[01:28:00.320 --> 01:28:02.080]   this more efficient and effective?
[01:28:02.080 --> 01:28:03.360]   The former, the former.
[01:28:03.360 --> 01:28:09.600]   Like it's just not that useful to build financial ecosystems that are self-contained, right?
[01:28:09.600 --> 01:28:12.320]   A financial island is not that helpful.
[01:28:12.320 --> 01:28:19.360]   It's much more valuable to build, I don't know, a financial, this is mixing metaphors,
[01:28:19.360 --> 01:28:25.280]   but a financial air network or something.
[01:28:25.280 --> 01:28:31.840]   But I think we would much prefer that Stripe plugged into every existing system and rail
[01:28:31.840 --> 01:28:40.000]   and domestic organization rather than that we tried to come along and supplant them.
[01:28:40.000 --> 01:28:46.000]   And this has been Stripe's strategy very deliberately from the beginning, where there were lots
[01:28:46.000 --> 01:28:50.160]   of companies when Stripe started out that were trying to do their own thing and go their
[01:28:50.160 --> 01:28:50.960]   own way.
[01:28:50.960 --> 01:28:55.600]   Whereas our belief was you got these, I mean, it's classic, I guess, Metcalfe law stuff
[01:28:55.600 --> 01:29:02.240]   of by enhancing the capabilities of an existing ecosystem, you create quite a bit more value.
[01:29:02.240 --> 01:29:03.360]   Okay, let's go back to Stripe.
[01:29:03.360 --> 01:29:07.360]   Is Stripe a writing culture for the benefit of the writer or the reader?
[01:29:07.360 --> 01:29:08.960]   It can be both.
[01:29:08.960 --> 01:29:11.840]   But which one's the more so?
[01:29:11.840 --> 01:29:16.720]   I think they're actually really considerable benefits on both sides because for the reader,
[01:29:16.720 --> 01:29:20.480]   it's not just that it's maybe more efficient to communicate stuff through text though,
[01:29:20.480 --> 01:29:21.440]   in many cases it is.
[01:29:21.440 --> 01:29:26.720]   But also there's this intertemporal benefit where future readers can try to understand
[01:29:26.720 --> 01:29:30.800]   the through line and the thought process that led us to this point.
[01:29:30.800 --> 01:29:34.160]   And I think that's very considerable.
[01:29:34.160 --> 01:29:39.040]   But it's also true that I think that, I mean, I write things and lots of people write things
[01:29:39.040 --> 01:29:40.880]   in order to organize one's own thoughts.
[01:29:40.880 --> 01:29:46.720]   And if that ability was taken away from me, I think I'd be meaningfully less effective.
[01:29:46.720 --> 01:29:50.160]   So how exactly those balance out is hard to say.
[01:29:50.160 --> 01:29:58.560]   Maybe the, I mean, they're not actually separable.
[01:29:58.560 --> 01:29:59.200]   That's my answer.
[01:29:59.200 --> 01:30:04.160]   Literate cultures are just a different thing.
[01:30:04.160 --> 01:30:06.800]   And I don't mean literate in some kind of faux intellectual way.
[01:30:06.800 --> 01:30:18.480]   I just mean, maybe textual cultures is a better term here, where, you know, Bruno Latour spoke
[01:30:18.480 --> 01:30:27.200]   about how, you know, he thinks part of how the printing revolution, like Gutenberg's,
[01:30:27.200 --> 01:30:33.840]   caused the scientific revolution was by making knowledge more rigid.
[01:30:33.840 --> 01:30:38.240]   Where before, if some observation didn't match, you know, some claim, you can always
[01:30:38.240 --> 01:30:41.040]   kind of shrug and be like, well, I guess the person who transcribed that thing, you know,
[01:30:41.040 --> 01:30:42.560]   just like made a mistake or whatever.
[01:30:42.560 --> 01:30:45.360]   And so by making things more rigid, it's easier to break them.
[01:30:45.360 --> 01:30:50.000]   And, you know, then you can notice discrepancies between, I guess, the theory or the claim
[01:30:50.000 --> 01:30:52.000]   or whatever, and, you know, the actual reality.
[01:30:52.000 --> 01:30:55.280]   And I think there's some version that organizationally where, I mean, I'm not drawing
[01:30:55.280 --> 01:31:00.560]   like that precise parallel, but there are analogous dynamics where the nature of oral
[01:31:00.560 --> 01:31:04.960]   cultures and textual cultures are just quite different.
[01:31:04.960 --> 01:31:13.840]   And, you know, so the kinds of collaboration that are possible and the kinds of consistency
[01:31:13.840 --> 01:31:16.800]   that can be achieved, like it is just fundamentally different.
[01:31:16.800 --> 01:31:25.760]   And, you know, is the, you know, front or rear wheel of the bicycle more valuable?
[01:31:25.760 --> 01:31:29.760]   And I guess theoretically you can unicycle, but like as a practical matter, you do just
[01:31:29.760 --> 01:31:31.520]   need both.
[01:31:31.520 --> 01:31:35.040]   I said, I know I said no more AI questions, but on this particular point, it actually
[01:31:35.040 --> 01:31:40.080]   seems very legitimate to me that you might expect firms that have a lot of writing to
[01:31:40.080 --> 01:31:44.720]   be the first to experience the productivity gains of AI, because there's all this context
[01:31:44.720 --> 01:31:46.720]   that the model doesn't have available readily.
[01:31:46.720 --> 01:31:48.240]   I don't know if that's something you anticipate.
[01:31:48.240 --> 01:31:50.320]   I think that's probably true.
[01:31:50.320 --> 01:31:51.920]   Yeah, I don't know.
[01:31:51.920 --> 01:31:55.040]   And if the model is really good, maybe it should be able to pick stuff up quickly.
[01:31:55.040 --> 01:32:01.520]   But I think most organizations are not recording all of their meetings for a variety of reasons.
[01:32:01.520 --> 01:32:04.800]   And if they're not, then yeah, there is this question of what is the corpus?
[01:32:04.800 --> 01:32:05.680]   How do you get up to speed?
[01:32:05.680 --> 01:32:07.840]   So yeah, my guess is that'll be true.
[01:32:07.840 --> 01:32:10.160]   Tell me about the internal LLM you built.
[01:32:10.160 --> 01:32:14.400]   Oh, we didn't build an internal LLM.
[01:32:14.400 --> 01:32:21.680]   We built an internal LLM tool for making it very easy for people to integrate LLMs into
[01:32:23.440 --> 01:32:28.960]   production services, but also into their regular workflows as humans.
[01:32:28.960 --> 01:32:36.880]   So the ability to work directly, I guess, with the LLM as a standard chat agent, as
[01:32:36.880 --> 01:32:42.640]   lots of people have built, but then also to integrate that with some of our tools for
[01:32:42.640 --> 01:32:49.360]   querying and accessing data, or maybe most interestingly, with sharing prompts across
[01:32:49.360 --> 01:32:50.720]   different people.
[01:32:51.600 --> 01:32:56.400]   And so somebody might discover-- I mean, one of my favorite examples, actually, is somebody
[01:32:56.400 --> 01:32:59.680]   put together a prompt for optimizing SQL queries.
[01:32:59.680 --> 01:33:05.280]   And no, it doesn't always work, but sometimes it does.
[01:33:05.280 --> 01:33:09.840]   And it's very cheap to ask us, got any ideas for optimizing the SQL query?
[01:33:09.840 --> 01:33:13.200]   And sometimes it'll come up with some good stuff.
[01:33:15.840 --> 01:33:23.600]   And so the collaborative abilities there have proven surprisingly high return.
[01:33:23.600 --> 01:33:26.800]   And then having just-- I mean, lots of organizations have this.
[01:33:26.800 --> 01:33:34.400]   We're not claiming that it's very novel or anything, but having a central bus through
[01:33:34.400 --> 01:33:40.400]   which to route all access to these LLMs, such that we can experiment with different models
[01:33:40.400 --> 01:33:48.000]   and have some degree of observability into the respective performance trends and the
[01:33:48.000 --> 01:33:50.560]   usage of different cases and so forth.
[01:33:50.560 --> 01:33:56.960]   We have found building a fairly significant amount of production infrastructure around
[01:33:56.960 --> 01:33:58.800]   LLMs to be valuable.
[01:33:58.800 --> 01:34:05.200]   And now, given the proliferation of LLMs themselves with all of the obvious contenders, this is
[01:34:05.200 --> 01:34:09.040]   proving quite valuable, because we're able to try to figure out for different use cases
[01:34:09.040 --> 01:34:13.840]   which models, self-assertive models, who knows, are most effective.
[01:34:13.840 --> 01:34:21.120]   And I don't know what the total number of invocations is, but I think we're making millions
[01:34:21.120 --> 01:34:23.040]   of invocations per day now.
[01:34:23.040 --> 01:34:28.320]   There are just dozens of dozens of actual production use cases across Stripe and all
[01:34:28.320 --> 01:34:35.360]   sorts of really-- I mean, the financial services ecosystem is in some way a giant analog to
[01:34:35.360 --> 01:34:44.800]   digital exercise, because humans are analog, and intentions and identities and all these
[01:34:44.800 --> 01:34:52.560]   things have-- there's always some degree of uncertainty around them and some noise, but
[01:34:52.560 --> 01:34:54.880]   then transactions are digital, right?
[01:34:54.880 --> 01:35:00.880]   And we often find in these analog to digital conversions that LLMs can be a surprisingly
[01:35:00.880 --> 01:35:02.800]   interesting augmenting tool.
[01:35:03.600 --> 01:35:12.640]   And actually, on that point about the flexibility and the edge cases in the way humans interact
[01:35:12.640 --> 01:35:18.000]   with these systems, in some sense, Stripe is like a really high-stakes bug bounty program,
[01:35:18.000 --> 01:35:18.500]   right?
[01:35:18.500 --> 01:35:26.320]   If somebody hacks it, not only the financial services, obviously, like money's in play,
[01:35:26.320 --> 01:35:30.640]   but if there's reliability issues, not just because of a hack, but because you deployed
[01:35:30.640 --> 01:35:35.040]   the wrong way, a significant percentage of world GDP would grind to a halt, at least
[01:35:35.040 --> 01:35:35.600]   while it's down.
[01:35:35.600 --> 01:35:39.920]   What-- I mean, how do you deal with that kind of responsibility?
[01:35:39.920 --> 01:35:44.960]   Like, how do you keep the uptime and keep the reliability while deploying fast?
[01:35:44.960 --> 01:35:48.320]   Yeah, this is one of the things we've spent the most time on.
[01:35:48.320 --> 01:35:53.680]   And I mean, back to this point about wanting to be the place with the best people, and
[01:35:53.680 --> 01:36:01.120]   if you-- and the value of focusing on craft so that you can have the best people, in the
[01:36:01.120 --> 01:36:07.600]   context of software development, one of the things that developers really hate is-- well,
[01:36:07.600 --> 01:36:12.560]   actually, two things that developers hate-- slow development cycles, and it'll ship in
[01:36:12.560 --> 01:36:16.080]   the next release in a month, and that kind of thinking.
[01:36:16.080 --> 01:36:18.880]   Developers also hate being paged at 2 AM, for instance.
[01:36:20.000 --> 01:36:30.400]   And so, yeah, given the criticality of the businesses that we serve, which is, in rough
[01:36:30.400 --> 01:36:36.800]   terms, 1% of the global economy, I mean, that's-- it's not totally clear how to measure this,
[01:36:36.800 --> 01:36:43.280]   because we're measuring-- we're not measuring-- GDP is defined as final goods, and Stripe
[01:36:43.280 --> 01:36:45.280]   is not only selling final goods.
[01:36:45.280 --> 01:36:47.840]   And so, in theory, there could be a bit of double counting.
[01:36:47.840 --> 01:36:49.840]   But Stripe is mostly selling final goods.
[01:36:49.840 --> 01:36:56.480]   Like, we're not used for, by and large, for giant supply chain shipments.
[01:36:56.480 --> 01:37:02.960]   So I think maybe there's a mismeasurement of 10% or 20% or something, but long story
[01:37:02.960 --> 01:37:05.440]   short, I think it works out to about 1% of global GDP.
[01:37:05.440 --> 01:37:06.960]   It's about a trillion dollars a year.
[01:37:06.960 --> 01:37:11.600]   And as you say, that then makes us really terrified of outages.
[01:37:11.600 --> 01:37:18.240]   And so we work so hard to enable fast iteration and development cycles without having outages.
[01:37:18.240 --> 01:37:24.240]   And just to kind of put some numbers on it, we deploy production services that are in
[01:37:24.240 --> 01:37:28.720]   kind of the core charge flow around 1,000 times a day.
[01:37:28.720 --> 01:37:33.760]   Like, most of these services are automatically deployed.
[01:37:33.760 --> 01:37:38.240]   So when anybody makes any production-ready change, it just, like, goes into production.
[01:37:38.240 --> 01:37:44.320]   And it's kind of meticulously and carefully orchestrated so that it first is just running
[01:37:44.320 --> 01:37:48.240]   some small sliver of traffic, and then incrementally more traffic until it's everything.
[01:37:48.240 --> 01:37:57.040]   So about 1,000 deploys per day at roughly, or somewhat in excess of, 5 and 1/2 nines,
[01:37:57.040 --> 01:38:05.360]   like 99.995% reliability, which works out to about, I think, about 100 and-- yeah,
[01:38:05.360 --> 01:38:08.560]   2, 2 and 1/2 minutes of unavailability per year.
[01:38:08.560 --> 01:38:11.680]   It's not that we have, obviously, 2 and 1/2 contiguous minutes of unavailability.
[01:38:11.680 --> 01:38:15.120]   But that's what I kind of-- that's what it approximates.
[01:38:15.120 --> 01:38:18.960]   Even though it tends to happen as kind of background radiation throughout the year.
[01:38:18.960 --> 01:38:25.840]   And getting to that point, yeah, just takes a huge amount of investment in-- and then
[01:38:25.840 --> 01:38:32.000]   there's security properties that are less readily measured, but analogous to those figures.
[01:38:33.040 --> 01:38:40.960]   And I guess Silicon Valley doesn't tend to-- I'm perhaps being now unfair and kind of attributing
[01:38:40.960 --> 01:38:41.680]   things to Silicon Valley.
[01:38:41.680 --> 01:38:47.600]   But maybe a lot of the tech industry doesn't place a lot of value on process and operational
[01:38:47.600 --> 01:38:48.480]   excellence.
[01:38:48.480 --> 01:38:55.440]   We kind of culturally value the spontaneous, and the creative, and the iconoclastic, and
[01:38:55.440 --> 01:39:07.600]   the path-breaking, but building mechanisms that can enable the very reliable provision
[01:39:07.600 --> 01:39:17.520]   of important services at scale, and removing the sources of variability that can really
[01:39:17.520 --> 01:39:19.840]   cause a bad day for a very large number of people.
[01:39:19.840 --> 01:39:23.040]   I don't think they get quite as much cultural credit.
[01:39:23.840 --> 01:39:33.200]   But yeah, we've adopted all sorts of-- for example, we found that there's kind of a core
[01:39:33.200 --> 01:39:40.000]   feedback loop around-- none of this sounds like rocket science, but defining what it
[01:39:40.000 --> 01:39:44.480]   is that we care about, and then building automated measuring systems to measure to what degree
[01:39:44.480 --> 01:39:47.760]   it's actually happening in practice, and then to sort of try to figure out, well, in the
[01:39:47.760 --> 01:39:50.080]   cases where we're not living up to that, what is the reason?
[01:39:50.880 --> 01:39:56.640]   And then to actually intervene and to improve the system so that that's not happening.
[01:39:56.640 --> 01:40:03.760]   And then importantly, to build kind of secondary controls that detect instances of deviation
[01:40:03.760 --> 01:40:10.400]   long before they actually cause a production problem or anything, but just where we understand
[01:40:10.400 --> 01:40:14.400]   the behavior of the system in sufficient detail that we can instrument it in some upstream
[01:40:14.400 --> 01:40:14.640]   way.
[01:40:15.920 --> 01:40:21.120]   Most of what I said there, I think, was well understood by production engineers in 1930.
[01:40:21.120 --> 01:40:23.920]   So again, I'm not claiming that it's any kind of radical breakthrough.
[01:40:23.920 --> 01:40:30.400]   But we have found that the adoption of these practices in really kind of tenacious multi-year
[01:40:30.400 --> 01:40:35.760]   form just yields really high returns.
[01:40:35.760 --> 01:40:43.440]   And there may be other organizations that both ship at that rate and kind of maintain
[01:40:43.440 --> 01:40:51.120]   that sort of developer velocity at this kind of combination of scale and reliability and
[01:40:51.120 --> 01:40:51.680]   security.
[01:40:51.680 --> 01:40:54.000]   But I don't think there were that many.
[01:40:54.000 --> 01:41:00.160]   And I think it's a real testament to the remarkable folks at Stripe who made it happen.
[01:41:00.160 --> 01:41:02.640]   Last AI point.
[01:41:02.640 --> 01:41:08.720]   But actually, the fact that you have this huge internal tooling and testing is, once
[01:41:08.720 --> 01:41:12.400]   you get the AI engineers, they can just push the commits, and you have the infrastructure
[01:41:12.400 --> 01:41:14.960]   set up that it can be readily evaluated.
[01:41:14.960 --> 01:41:25.440]   Across the board, I think so much comes back to what has to be true for us actually to
[01:41:25.440 --> 01:41:31.440]   be able to build and to kind of take seriously this goal of building the best software.
[01:41:31.440 --> 01:41:38.720]   And it's easy to say that as some lofty, vague, hand-wavy aspirational statement.
[01:41:38.720 --> 01:41:43.280]   But if you sort of take that seriously as a goal, and if you think, well, what would
[01:41:43.280 --> 01:41:47.760]   you have to measure if you were actually going to pursue it in earnest?
[01:41:47.760 --> 01:41:51.440]   And what are the characteristics of organizations that do produce it?
[01:41:51.440 --> 01:41:54.880]   I mean, you get down to, well, customers have to really like your stuff.
[01:41:54.880 --> 01:41:58.080]   And so, OK, well, how can we measure that?
[01:41:58.080 --> 01:42:01.600]   And how can we systematize the process of making sure that there aren't regressions
[01:42:01.600 --> 01:42:01.840]   there?
[01:42:01.840 --> 01:42:05.760]   And so we have this concept of experience journeys, which are sort of pathways through
[01:42:05.760 --> 01:42:11.520]   Stripe that we really care are always implemented at a really high quality level.
[01:42:11.520 --> 01:42:14.960]   And it has to be true that developers can iterate very quickly.
[01:42:14.960 --> 01:42:18.240]   And we just kind of spoke about how to make that happen, you know, and, and, and.
[01:42:18.240 --> 01:42:23.440]   And so I feel like maybe a kind of a theme through everything we've talked about is
[01:42:23.440 --> 01:42:27.040]   actually taking the goal seriously.
[01:42:27.040 --> 01:42:33.360]   And I feel like a lot of what we do at Stripe is, again, I disclaim any sort of genius in
[01:42:33.360 --> 01:42:33.680]   it.
[01:42:33.680 --> 01:42:40.480]   I think it's just the very earnest, repeated, serious, and long-term application of taking
[01:42:40.480 --> 01:42:41.120]   the goal seriously.
[01:42:41.120 --> 01:42:42.800]   A few more Stripe questions.
[01:42:42.800 --> 01:42:47.840]   1% of global GDP is such a staggering number.
[01:42:47.840 --> 01:42:53.680]   When you think about where further growth for Stripe comes from, does it come from the
[01:42:53.680 --> 01:42:55.040]   internet economy expanding?
[01:42:55.040 --> 01:42:58.960]   Or does it come from Stripe becoming a larger share of the internet economy?
[01:42:58.960 --> 01:43:03.520]   And to the extent that Stripe is growing faster than the internet, if we consider
[01:43:03.520 --> 01:43:06.880]   that the beta in your case, where is that alpha coming from?
[01:43:06.880 --> 01:43:08.560]   That's a good question.
[01:43:08.560 --> 01:43:18.320]   Well, the, the, the customers that Stripe serves are outgrowing the internet, the internet
[01:43:18.320 --> 01:43:20.960]   economy as a whole, like an aggregate.
[01:43:20.960 --> 01:43:26.240]   Now, at some point those have to converge for kind of obvious mathematical reasons,
[01:43:26.240 --> 01:43:29.040]   but, but, you know, we're, we're 14 years in and they haven't converged yet.
[01:43:29.040 --> 01:43:32.320]   So I think there's, I think there's a lot of headroom there and, you know, say Stripe
[01:43:32.320 --> 01:43:34.000]   is handling around a trillion dollars a year.
[01:43:34.000 --> 01:43:39.520]   And when Stripe started out, the global economy was 60 to 70 trillion ish.
[01:43:39.520 --> 01:43:41.840]   The global economy is now around a hundred trillion.
[01:43:41.840 --> 01:43:46.800]   And so, you know, we still have quite a bit of headroom before the, like, you know, the,
[01:43:46.800 --> 01:43:51.440]   the, the amount of activity that is coming out to Stripe is like really butting up against
[01:43:51.440 --> 01:43:53.360]   the ceiling of, of global economic growth.
[01:43:53.360 --> 01:43:57.440]   And of course it's not like there's no ceiling on global economic growth and, you know, for
[01:43:57.440 --> 01:44:02.080]   all sorts of, of reasons, you know, it could be vastly higher than it is.
[01:44:02.080 --> 01:44:06.960]   And I don't even mean new technologies or AIs or whatever, but just, yeah, obviously
[01:44:06.960 --> 01:44:10.640]   all the kind of basic per capita math you can do around, you know, what if everybody
[01:44:10.640 --> 01:44:14.640]   had a, you know, an income on par with the US and, you know, I think it is.
[01:44:14.640 --> 01:44:19.760]   And like, one of the reasons I, I'm so interested in working on Stripe is I think it's, you
[01:44:19.760 --> 01:44:24.160]   know, it's the, the, the old line, the, the Lucas line about how, when you start thinking
[01:44:24.160 --> 01:44:28.880]   about differential rates of development in countries, like it's hard to think about anything
[01:44:28.880 --> 01:44:32.720]   else, you know, why does Brazil have the particular income and GDP level that it does?
[01:44:32.720 --> 01:44:34.640]   Why does Poland have the level that it does?
[01:44:34.640 --> 01:44:37.360]   Why does, why did Ireland have the trajectory that it did?
[01:44:37.360 --> 01:44:41.680]   Where we went from being the kind of the sick man of Europe to, to now one of the wealthiest
[01:44:41.680 --> 01:44:42.320]   countries there.
[01:44:42.320 --> 01:44:46.160]   And I feel like Stripe is some applied version of this question in practice where you're
[01:44:46.160 --> 01:44:52.560]   kind of building software products, but in some sense connected to, or, you know, touching
[01:44:52.560 --> 01:44:56.320]   upon these questions of, well, why aren't there more country, excuse me, why aren't
[01:44:56.320 --> 01:44:59.520]   there more, why aren't there more companies?
[01:44:59.520 --> 01:45:02.480]   And what determines the growth rate of a company?
[01:45:02.480 --> 01:45:10.400]   Like why, you know, when, when you start the merch store, like why, why does it have, you
[01:45:10.400 --> 01:45:13.200]   know, X level of buyers rather than, you know, two X?
[01:45:13.200 --> 01:45:21.760]   And I, I actually think those questions, you know, I, I think those remain fruitful questions.
[01:45:21.760 --> 01:45:29.360]   We actually haven't optimized the meta system of business to any particularly great extent
[01:45:29.360 --> 01:45:30.720]   for the vast majority of business.
[01:45:30.720 --> 01:45:37.440]   Businesses have been offline, inefficient, you know, analog, everything.
[01:45:37.440 --> 01:45:44.000]   And it's really only over the last, you know, two, one to two decades that a significant
[01:45:44.000 --> 01:45:47.040]   share of this has been meaningfully digitized.
[01:45:47.600 --> 01:45:53.200]   And the prospects for efficiency gains and optimizations there are still pretty significantly
[01:45:53.200 --> 01:45:54.320]   underexplored.
[01:45:54.320 --> 01:46:00.560]   And we find incredibly basic things like just, you know, just extending capital to businesses.
[01:46:00.560 --> 01:46:06.320]   I mean, the reason we do that is not to generate profit from the loans, but because we find
[01:46:06.320 --> 01:46:10.800]   that the businesses whom we extend the capital, then just grow faster on a, on a sort of persistent
[01:46:11.680 --> 01:46:18.880]   subsequent basis, or, you know, trying to figure out how, how does a business decide
[01:46:18.880 --> 01:46:20.880]   which countries it sells in?
[01:46:20.880 --> 01:46:25.520]   And you'll find even the smallest business through to some of the largest businesses
[01:46:25.520 --> 01:46:31.840]   in the world, that these are very kind of ad hoc and not particularly deeply thought
[01:46:31.840 --> 01:46:34.640]   through questions like, you know, why don't you sell in Mexico and Brazil or wherever?
[01:46:34.640 --> 01:46:36.800]   It's like, well, it seemed kind of complicated.
[01:46:36.800 --> 01:46:38.720]   And so we didn't quite get around to it and so forth.
[01:46:38.720 --> 01:46:45.120]   And so I think there's to your question about like, you know, where, where does the growth
[01:46:45.120 --> 01:46:45.600]   come from?
[01:46:45.600 --> 01:46:49.600]   I think that there's still an awful lot of low-hanging fruit and just asking some of
[01:46:49.600 --> 01:46:51.680]   these incredibly basic questions.
[01:46:51.680 --> 01:46:58.480]   So when we think about the way in which Stripe will continue to grow in the future, in some
[01:46:58.480 --> 01:47:03.680]   sense, it'll obviously involve a lot of big businesses and, you know, you've now processing
[01:47:03.680 --> 01:47:05.360]   a significant amount of Amazon volume.
[01:47:05.360 --> 01:47:07.120]   There's other businesses you're doing deals with.
[01:47:07.920 --> 01:47:12.720]   First, tell me how you think it kind of makes sense how an exponentially growing startup
[01:47:12.720 --> 01:47:15.680]   would contribute to exponentially growing growth for Stripe.
[01:47:15.680 --> 01:47:20.800]   How does like the Stripe keep growing in the same trajectory when it's existing big businesses
[01:47:20.800 --> 01:47:22.400]   that you're partnering with?
[01:47:22.400 --> 01:47:27.120]   And just second, like also like the case for why these startups matter is like so compelling,
[01:47:27.120 --> 01:47:27.280]   right?
[01:47:27.280 --> 01:47:30.240]   Like a new thing is coming into this world and we should really support it and make sure
[01:47:30.240 --> 01:47:30.640]   it happens.
[01:47:30.640 --> 01:47:36.720]   Why is it compelling that like Amazon can fulfill orders more efficiently or something?
[01:47:36.720 --> 01:47:40.080]   Yeah, those are very good questions.
[01:47:40.080 --> 01:47:46.800]   So on the first one, you're right.
[01:47:46.800 --> 01:47:57.200]   It's, you know, Stripe is doomed to eventually grow at the rate of the economy.
[01:47:57.200 --> 01:48:01.840]   And there's just a question of, you know, how long it takes to get that right.
[01:48:01.840 --> 01:48:07.680]   Now, the good news is I think it can be a very long time because there's, as we just
[01:48:07.680 --> 01:48:13.840]   discussed, there's so much low-hanging fruit around, you know, different optimizations
[01:48:13.840 --> 01:48:16.720]   and improvements that are possible.
[01:48:16.720 --> 01:48:20.080]   And so I think it would be many decades before that happens.
[01:48:20.080 --> 01:48:22.720]   But it's true that will eventually occur.
[01:48:23.760 --> 01:48:31.840]   On the second question about, yeah, what's the, like, it's obviously virtuous or compelling
[01:48:31.840 --> 01:48:36.560]   or exciting to foster all these nascent startups and to kind of be an anti-incumbency force.
[01:48:36.560 --> 01:48:41.200]   But what's the case for supporting established businesses?
[01:48:41.200 --> 01:48:47.440]   I think we will misunderstand where a small business typically, not in every case, but
[01:48:47.440 --> 01:48:51.280]   at least in the cases where we denote them startups, there's usually an embedded innovation.
[01:48:51.280 --> 01:48:55.600]   And the innovation is kind of all that the company is like they have a new idea and they're
[01:48:55.600 --> 01:48:57.760]   going to do something better or different or, you know, whatever.
[01:48:57.760 --> 01:48:59.840]   And so generally speaking, we like innovation.
[01:48:59.840 --> 01:49:02.240]   And so we've, you know, positive sentiments towards that startup.
[01:49:02.240 --> 01:49:06.880]   But there's a lot of innovation that comes from large established businesses.
[01:49:06.880 --> 01:49:08.400]   That's not all they do.
[01:49:08.400 --> 01:49:10.400]   You know, there's also just running the existing thing.
[01:49:10.400 --> 01:49:16.800]   And so maybe it's a smaller share, but the aggregate fraction of innovation that comes
[01:49:16.800 --> 01:49:19.920]   from established businesses is really large.
[01:49:19.920 --> 01:49:26.880]   And, you know, we have to be cognizant of the cognitive bias of the startups perhaps
[01:49:26.880 --> 01:49:32.240]   being somewhat more conspicuous and maybe on a relative basis, the improvements in turbine
[01:49:32.240 --> 01:49:40.640]   technology or in fab technology or in insulation technology that come from established businesses.
[01:49:42.400 --> 01:49:47.920]   Or choose any sector of the economy and a significant fraction of the important, you
[01:49:47.920 --> 01:49:52.880]   know, inventions that occurred over the last 10 or 20 years will have come from the incumbents.
[01:49:52.880 --> 01:49:58.320]   And so I think as a general class, and, you know, Tyler, of course, wrote a book on this,
[01:49:58.320 --> 01:50:01.200]   I think big business is underrated.
[01:50:01.200 --> 01:50:07.040]   And, you know, if you look at the survey data, people tend to have very positive sentiments,
[01:50:07.040 --> 01:50:09.280]   not only towards startups, but towards small business as a class.
[01:50:10.080 --> 01:50:15.360]   Whereas if you, even though they've negative sentiments or relatively negative sentiments
[01:50:15.360 --> 01:50:19.440]   towards big business, not that bad on an absolute basis, but not as favorable.
[01:50:19.440 --> 01:50:23.600]   I think it's true that established businesses tend to pay better.
[01:50:23.600 --> 01:50:25.360]   They tend to be more efficient.
[01:50:25.360 --> 01:50:27.440]   More of the innovation in our economy comes from them.
[01:50:27.440 --> 01:50:31.280]   And they produce a lot of consumer surplus.
[01:50:31.280 --> 01:50:36.000]   I think the specific case for Stripe working with them is typically they're coming to us
[01:50:36.000 --> 01:50:40.720]   not because they want to, you know, take the thing that they're already doing and just,
[01:50:40.720 --> 01:50:47.600]   you know, go to all the work of transposing it to Stripe, but because either they want
[01:50:47.600 --> 01:50:50.480]   to do a new thing that they're just not doing today.
[01:50:50.480 --> 01:50:55.360]   And so it's associated with some new business line or some new innovation or invention or,
[01:50:55.360 --> 01:50:56.000]   you know, whatever.
[01:50:56.000 --> 01:51:03.840]   Or they've spotted the opportunity to, I guess, to maybe not produce a new product,
[01:51:03.840 --> 01:51:07.440]   but to meaningfully change how they provide an existing one in a fashion that, again,
[01:51:07.440 --> 01:51:08.720]   yields consumer surplus.
[01:51:08.720 --> 01:51:13.120]   And that sounds very abstract and theoretical, but in practice, what it tends to mean is
[01:51:13.120 --> 01:51:17.280]   they want to take this thing they're selling in this market and sell it in many more markets.
[01:51:17.280 --> 01:51:20.880]   Or they've realized that they're selling it in this kind of modality, and they should
[01:51:20.880 --> 01:51:23.200]   sell it in other more convenient ways.
[01:51:23.200 --> 01:51:25.360]   Like they should sell it on mobile or something.
[01:51:25.360 --> 01:51:30.080]   And each of those, if it's successful, if people actually buy it in any significant
[01:51:30.080 --> 01:51:33.840]   numbers, you know, I guess we're getting this decentralized signal from the economy that
[01:51:33.840 --> 01:51:38.240]   there's now something of value being provided that wasn't here before.
[01:51:38.240 --> 01:51:47.520]   And as I take stock of the businesses, like the enterprises that are in the process of
[01:51:47.520 --> 01:51:52.560]   migrating to Stripe or that did so over the last year, you know, whether it's the large
[01:51:52.560 --> 01:51:58.960]   retailers or the large global manufacturing firms or shipping companies, things like this,
[01:51:58.960 --> 01:52:03.040]   it typically has one of those two patterns.
[01:52:03.040 --> 01:52:07.280]   New product or current product sold to people who weren't buying it before.
[01:52:07.280 --> 01:52:08.720]   Yeah, yeah.
[01:52:08.720 --> 01:52:11.600]   I mean, if you think about just like the big trends in society that are needed to solve
[01:52:11.600 --> 01:52:12.320]   our big problems, right?
[01:52:12.320 --> 01:52:14.720]   Like Moore's law or the cost of solar or something.
[01:52:14.720 --> 01:52:20.560]   These are just, you have marginal improvements over many decades that, you know, the big
[01:52:20.560 --> 01:52:23.680]   tech or big companies are just able to invest a lot of money into doing the R&D here.
[01:52:23.680 --> 01:52:26.480]   Relentless iterative improvement, yes, is underrated.
[01:52:26.480 --> 01:52:27.680]   Can I ask about John for a second?
[01:52:27.680 --> 01:52:28.400]   Sure.
[01:52:28.400 --> 01:52:33.360]   So you guys recently published Poor Charlie Zalmanak and subsequently Charlie Munger
[01:52:33.360 --> 01:52:34.000]   has passed away.
[01:52:34.000 --> 01:52:40.240]   Did you ever, did Munger ever comment on your relationship and if or whether it reminded
[01:52:40.240 --> 01:52:42.160]   him of his and Buffett's?
[01:52:42.160 --> 01:52:46.240]   Not to me, but he knew John better.
[01:52:46.240 --> 01:52:48.960]   And so it's possible that he did to John.
[01:52:48.960 --> 01:52:52.880]   Yeah, I don't know.
[01:52:52.880 --> 01:52:55.840]   What have you learned about marriage from John?
[01:52:55.840 --> 01:53:01.600]   I mean, this sort of like co-equal, intense, lengthy partnership is like the closest thing
[01:53:01.600 --> 01:53:02.720]   that you have is marriage, right?
[01:53:02.720 --> 01:53:06.160]   Well, I'm relatively new to the practice of marriage.
[01:53:06.160 --> 01:53:11.840]   So I, you know, maybe in a decade I'll be able to kind of extract the generalizable
[01:53:11.840 --> 01:53:12.640]   commonalities.
[01:53:12.640 --> 01:53:20.960]   I suppose the general thing I would say is, I think working with people you're close to
[01:53:20.960 --> 01:53:21.680]   is underrated.
[01:53:22.720 --> 01:53:31.040]   And, you know, I'm doing ARC with Patrick Su and Silvana.
[01:53:31.040 --> 01:53:34.400]   Fast Grands was with Tyler and Silvana.
[01:53:34.400 --> 01:53:37.600]   Stripes obviously with John.
[01:53:37.600 --> 01:53:42.320]   And actually John was also, I should mention, instrumentally involved in ARC's formation.
[01:53:42.320 --> 01:53:44.080]   Like it would not have happened without John.
[01:53:46.400 --> 01:53:53.520]   And, you know, could give more examples, but I feel like for all the ventures of any significance
[01:53:53.520 --> 01:53:58.240]   in my life, they've like not only been with others, but been with other people that I'm
[01:53:58.240 --> 01:54:05.120]   very close to and where I had and would like to have an enduring relationship that outlives
[01:54:05.120 --> 01:54:05.360]   them.
[01:54:05.360 --> 01:54:08.880]   And, you know, sometimes one hears the advice that, you know, you shouldn't work with friends
[01:54:08.880 --> 01:54:12.480]   or maybe you shouldn't work with your partner or something like that.
[01:54:12.480 --> 01:54:19.360]   And look, all these things are idiosyncratic and there are instances of every possible
[01:54:19.360 --> 01:54:25.360]   permutation, but for me, it's been a really rewarding experience.
[01:54:25.360 --> 01:54:34.080]   And yeah, I think John and I can work together for, you never know life, but I think we'll
[01:54:34.080 --> 01:54:35.520]   probably work together for decades.
[01:54:35.520 --> 01:54:45.840]   And for us, it's been a really, both an important source of just meaning and again, fulfillment,
[01:54:45.840 --> 01:54:48.720]   but also I think there's a real complementarity.
[01:54:48.720 --> 01:54:54.640]   And I think that Stripe would be a less effective company, you know, without either of us.
[01:54:54.640 --> 01:54:57.520]   I don't know if you mean from like a bandwidth standpoint or something, but I think we both
[01:54:57.520 --> 01:54:59.040]   bring different things to bear.
[01:54:59.040 --> 01:55:01.200]   Patrick, I think this is a great place to leave it.
[01:55:01.200 --> 01:55:02.800]   Thank you so much for coming on the podcast.
[01:55:02.800 --> 01:55:03.120]   Thank you.
[01:55:05.040 --> 01:55:06.080]   Hey, everybody.
[01:55:06.080 --> 01:55:07.440]   I hope you enjoyed that episode.
[01:55:07.440 --> 01:55:12.720]   As always, the most helpful thing you can do is to share the podcast, send it to people
[01:55:12.720 --> 01:55:15.920]   you think might enjoy it, put it in Twitter, your group chats, et cetera.
[01:55:15.920 --> 01:55:16.800]   Just splits the world.
[01:55:16.800 --> 01:55:18.960]   Appreciate you listening.
[01:55:18.960 --> 01:55:20.160]   I'll see you next time.
[01:55:20.160 --> 01:55:25.360]   Cheers.
[01:55:25.360 --> 01:55:31.280]   [Music]

