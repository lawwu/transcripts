
[00:00:00.000 --> 00:00:02.540]   There's a picture you can look up that's kind of disgusting,
[00:00:02.540 --> 00:00:03.820]   so people may not want to.
[00:00:03.820 --> 00:00:08.460]   But there's this thing called a gavage tube, which is what
[00:00:08.460 --> 00:00:09.940]   they use to make foie gras.
[00:00:09.940 --> 00:00:14.380]   It's how they force feed the geese to get them just super
[00:00:14.380 --> 00:00:14.860]   fat.
[00:00:14.860 --> 00:00:17.380]   And that's the image I have in my mind,
[00:00:17.380 --> 00:00:20.220]   like are we overfeeding these startups?
[00:00:20.220 --> 00:00:23.580]   [MUSIC PLAYING]
[00:00:23.580 --> 00:00:32.680]   [KNOCKING]
[00:00:32.680 --> 00:00:33.180]   Hey, Bill.
[00:00:33.180 --> 00:00:34.380]   Great to see you.
[00:00:34.380 --> 00:00:35.660]   Good to see you, Brent.
[00:00:35.660 --> 00:00:39.220]   Man, that was an amazing pod at Diablo Canyon.
[00:00:39.220 --> 00:00:42.900]   The inbound regarding just nuclear
[00:00:42.900 --> 00:00:46.700]   has been off the charts from literally senior policymakers,
[00:00:46.700 --> 00:00:49.260]   senators, and House members on both sides of the aisle.
[00:00:49.260 --> 00:00:52.580]   It really feels like the dam is broke.
[00:00:52.580 --> 00:00:55.440]   We half-joked, Bill, that Microsoft--
[00:00:55.440 --> 00:00:58.260]   when we were down there, we discovered
[00:00:58.260 --> 00:01:02.860]   that there were four unbuilt nuclear reactors that are all
[00:01:02.860 --> 00:01:05.420]   already plotted on the site.
[00:01:05.420 --> 00:01:08.940]   And we half-joked that NVIDIA and Microsoft and Oracle
[00:01:08.940 --> 00:01:11.420]   could come sponsor these reactors
[00:01:11.420 --> 00:01:13.300]   and that they could have a new type
[00:01:13.300 --> 00:01:15.660]   of public-private partnership with the government
[00:01:15.660 --> 00:01:18.340]   and build data centers right next to them.
[00:01:18.340 --> 00:01:20.280]   And it turns out it wasn't so far out there.
[00:01:20.280 --> 00:01:23.340]   I mean, Oracle has announced that they may do some things
[00:01:23.340 --> 00:01:25.380]   with small nuclear reactors.
[00:01:25.380 --> 00:01:29.220]   Amazon is buying this nuclear-powered Talon data
[00:01:29.220 --> 00:01:30.180]   center facility.
[00:01:30.180 --> 00:01:33.500]   And now Microsoft this week announces with CEG
[00:01:33.500 --> 00:01:36.480]   that they're going to bring Three Mile Island out
[00:01:36.480 --> 00:01:37.740]   of retirement.
[00:01:37.740 --> 00:01:40.020]   It's incredible to see the beginnings of what
[00:01:40.020 --> 00:01:42.940]   may be a US nuclear renaissance.
[00:01:42.940 --> 00:01:45.660]   Certainly, the momentum has--
[00:01:45.660 --> 00:01:48.660]   if maybe it was headed up and then it's kind of reached
[00:01:48.660 --> 00:01:51.020]   an apex and kind of fallen over.
[00:01:51.020 --> 00:01:54.220]   The FT article yesterday or today
[00:01:54.220 --> 00:01:57.860]   highlighting that 14 different banks have shown up
[00:01:57.860 --> 00:02:01.900]   at a climate conference with a confirmation of a willingness
[00:02:01.900 --> 00:02:03.460]   to invest is just huge.
[00:02:03.460 --> 00:02:07.700]   And I think there are two things that are big takeaways for me.
[00:02:07.700 --> 00:02:11.420]   One, we were talking about one of the limits on SMR
[00:02:11.420 --> 00:02:14.220]   and on any new innovation in the space
[00:02:14.220 --> 00:02:18.100]   was that utility companies are traditionally very conservative.
[00:02:18.100 --> 00:02:20.620]   And I like to think about it in the framework of crossing
[00:02:20.620 --> 00:02:21.580]   the chasm.
[00:02:21.580 --> 00:02:24.180]   You basically are selling only to laggards.
[00:02:24.180 --> 00:02:27.100]   And that's very difficult, especially
[00:02:27.100 --> 00:02:30.900]   for a capital-intensive startup, to be selling only to laggards.
[00:02:30.900 --> 00:02:36.260]   And what may have transpired literally in the past month
[00:02:36.260 --> 00:02:38.500]   is the hyperscalers--
[00:02:38.500 --> 00:02:40.240]   and this may have started before then
[00:02:40.240 --> 00:02:43.740]   because Amazon did the deal with CEG a little while back.
[00:02:43.740 --> 00:02:47.180]   But if the hyperscalers become part
[00:02:47.180 --> 00:02:51.300]   of the customer set for the nuclear startups,
[00:02:51.300 --> 00:02:55.900]   that may be 10x better than selling just to utilities
[00:02:55.900 --> 00:02:56.740]   alone.
[00:02:56.740 --> 00:02:59.540]   You may have brought innovators to the table
[00:02:59.540 --> 00:03:02.300]   on the purchasing side that may be more open-minded,
[00:03:02.300 --> 00:03:04.620]   that may be more understanding, may be more
[00:03:04.620 --> 00:03:06.540]   willing to share risk, which could be
[00:03:06.540 --> 00:03:09.220]   very positive for the SMR market.
[00:03:09.220 --> 00:03:11.300]   So that'd be my one big takeaway.
[00:03:11.300 --> 00:03:15.500]   And the second one is just that a lot of times,
[00:03:15.500 --> 00:03:18.940]   I think people look at big, big problems
[00:03:18.940 --> 00:03:20.700]   and think they're insurmountable.
[00:03:20.700 --> 00:03:24.260]   And I remember actually in the past two years
[00:03:24.260 --> 00:03:28.740]   being at a off-site conference at a think tank
[00:03:28.740 --> 00:03:31.620]   where we were talking about climate change.
[00:03:31.620 --> 00:03:35.420]   And about 80% of the way in, someone raised their hand
[00:03:35.420 --> 00:03:37.300]   and said, why aren't we talking about nuclear?
[00:03:37.300 --> 00:03:40.540]   And all the scientists in the room said, oh, no,
[00:03:40.540 --> 00:03:43.060]   we're not going to put that back on the table.
[00:03:43.060 --> 00:03:44.860]   That's too far gone.
[00:03:44.860 --> 00:03:46.020]   That's past.
[00:03:46.020 --> 00:03:48.620]   And it turned out that wasn't true.
[00:03:48.620 --> 00:03:51.260]   It turned out there was an opportunity
[00:03:51.260 --> 00:03:53.420]   to get a renaissance in thinking about this.
[00:03:53.420 --> 00:03:56.900]   And it started, I think, with people like Steven Pinker, who
[00:03:56.900 --> 00:03:59.460]   are wildly regarded scientists, saying, no, this
[00:03:59.460 --> 00:04:01.300]   is our best path out.
[00:04:01.300 --> 00:04:04.060]   But then we talked about Patrick Collison.
[00:04:04.060 --> 00:04:06.180]   And others kind of jumped on the bandwagon.
[00:04:06.180 --> 00:04:10.020]   And then there were plenty of pro-nuclear advocates
[00:04:10.020 --> 00:04:11.460]   that were sticking their neck out.
[00:04:11.460 --> 00:04:13.780]   And then Elon gets in the game.
[00:04:13.780 --> 00:04:15.460]   And then this data center thing may
[00:04:15.460 --> 00:04:18.020]   have been just the impetus you needed
[00:04:18.020 --> 00:04:20.020]   to get people over the top.
[00:04:20.020 --> 00:04:23.020]   And we were lucky enough to kind of time our thing
[00:04:23.020 --> 00:04:25.660]   as this transition was happening.
[00:04:25.660 --> 00:04:30.820]   But it is possible to create kind of wholesale change
[00:04:30.820 --> 00:04:32.500]   in how people think about something.
[00:04:32.500 --> 00:04:34.820]   But it takes a lot of work by a lot of people.
[00:04:34.820 --> 00:04:38.060]   And everyone that kind of stuck their neck out early.
[00:04:38.060 --> 00:04:40.540]   Josh Wolf was another one that was sticking his neck out
[00:04:40.540 --> 00:04:41.340]   on this topic.
[00:04:41.340 --> 00:04:44.020]   So I congratulate all of them.
[00:04:44.020 --> 00:04:46.340]   And it feels like the momentum's now behind us.
[00:04:46.340 --> 00:04:53.420]   And I literally feel bad for the citizens of Germany.
[00:04:53.420 --> 00:04:58.420]   One thing that is very apparent is that the easiest thing to do
[00:04:58.420 --> 00:04:59.620]   is bring--
[00:04:59.620 --> 00:05:02.060]   well, start with don't decommission
[00:05:02.060 --> 00:05:03.220]   any of these things.
[00:05:03.220 --> 00:05:06.820]   But second, if any have been decommissioned recently,
[00:05:06.820 --> 00:05:08.340]   try and bring them back.
[00:05:08.340 --> 00:05:11.940]   And I hope there are some sane minds in Germany
[00:05:11.940 --> 00:05:13.100]   that are watching all this.
[00:05:13.100 --> 00:05:14.820]   Because I think the world would benefit
[00:05:14.820 --> 00:05:17.620]   from them reversing that decision
[00:05:17.620 --> 00:05:19.380]   and running back at this.
[00:05:19.380 --> 00:05:21.100]   One of the things I learned as well--
[00:05:21.100 --> 00:05:23.220]   because you and I talked a lot just about how do they
[00:05:23.220 --> 00:05:24.580]   underwrite--
[00:05:24.580 --> 00:05:27.220]   how would the hyperscalers underwrite building out
[00:05:27.220 --> 00:05:28.820]   those nuclear reactors?
[00:05:28.820 --> 00:05:31.620]   And one of the things I learned after our pod
[00:05:31.620 --> 00:05:36.020]   was that these companies that are considering nuclear,
[00:05:36.020 --> 00:05:38.540]   they are spending billions of dollars a year
[00:05:38.540 --> 00:05:39.820]   on carbon offsets.
[00:05:39.820 --> 00:05:42.260]   And you know there's a lot of criticism about these carbon
[00:05:42.260 --> 00:05:43.460]   offset markets.
[00:05:43.460 --> 00:05:45.660]   But I dug up some data.
[00:05:45.660 --> 00:05:49.220]   In 2020, Morgan Stanley estimates
[00:05:49.220 --> 00:05:52.900]   that about $2 billion was spent on the carbon offset market.
[00:05:52.900 --> 00:05:56.140]   And by 2030, they expect that to be $100 billion
[00:05:56.140 --> 00:05:59.780]   by these large hyperscalers that have to buy
[00:05:59.780 --> 00:06:01.460]   these massive carbon offsets.
[00:06:01.460 --> 00:06:05.580]   Now, if instead you're investing in nuclear clean energy,
[00:06:05.580 --> 00:06:08.740]   if the source of the energy that is powering your data centers
[00:06:08.740 --> 00:06:12.020]   is clean, then you actually have to get to buy
[00:06:12.020 --> 00:06:13.900]   fewer of the carbon offsets.
[00:06:13.900 --> 00:06:17.020]   So that may make it easier, again,
[00:06:17.020 --> 00:06:18.380]   for them to pencil out the math.
[00:06:18.380 --> 00:06:20.860]   That may be what we're seeing some of the dam break.
[00:06:20.860 --> 00:06:24.340]   I think a huge part of this is just the public consensus.
[00:06:24.340 --> 00:06:26.060]   Nobody wants to invest in something
[00:06:26.060 --> 00:06:28.740]   that all your customers are against.
[00:06:28.740 --> 00:06:30.700]   And we know, we've shown the data here,
[00:06:30.700 --> 00:06:33.700]   that this is now popular again among consumers
[00:06:33.700 --> 00:06:37.540]   because they understand it's clean, it's carbon-free.
[00:06:37.540 --> 00:06:40.300]   The other data point that broke since we did that
[00:06:40.300 --> 00:06:42.740]   was the Three Mile Island restart.
[00:06:42.740 --> 00:06:45.860]   I think there were rumors of it before we did the podcast
[00:06:45.860 --> 00:06:48.540]   with CEG, with Constellation Energy Group.
[00:06:48.540 --> 00:06:51.220]   And there were quotes in these articles
[00:06:51.220 --> 00:06:56.060]   about a survey of the Pittsburgh residents.
[00:06:56.060 --> 00:06:59.980]   And they were supportive of Philadelphia.
[00:06:59.980 --> 00:07:03.220]   And what that says to me--
[00:07:03.220 --> 00:07:07.460]   and look, this is knowing that the customer is really Amazon
[00:07:07.460 --> 00:07:09.380]   and not the citizenry.
[00:07:09.380 --> 00:07:11.060]   And I was just shocked by that.
[00:07:11.060 --> 00:07:15.260]   And so we all know that one of the reasons this happened
[00:07:15.260 --> 00:07:19.540]   was that there was an irrational public response
[00:07:19.540 --> 00:07:24.380]   to the negative risk of these solutions.
[00:07:24.380 --> 00:07:31.020]   And it is super unfortunate that that takes so long to heal.
[00:07:31.020 --> 00:07:35.020]   But time is the best way to get past something like that.
[00:07:35.020 --> 00:07:36.220]   And it's been a long time.
[00:07:36.220 --> 00:07:38.420]   And I think people have a lot more data.
[00:07:38.420 --> 00:07:39.380]   We're not there yet.
[00:07:39.380 --> 00:07:41.140]   We need to keep the pressure on.
[00:07:41.140 --> 00:07:45.100]   We said we'd like to see Gavin Newsom extend Diablo
[00:07:45.100 --> 00:07:46.460]   by another 15 years.
[00:07:46.460 --> 00:07:48.620]   That's on his desk right now.
[00:07:48.620 --> 00:07:51.660]   That facility has at least another 40 years left in it.
[00:07:51.660 --> 00:07:54.020]   So I think we all need to keep the pressure on.
[00:07:54.020 --> 00:07:57.460]   But the nice thing is there's good bipartisan support.
[00:07:57.460 --> 00:08:01.420]   People view nuclear as not only a matter of climate security,
[00:08:01.420 --> 00:08:03.980]   but now it's a matter of national security
[00:08:03.980 --> 00:08:06.860]   because it's the primitive to all of AI.
[00:08:06.860 --> 00:08:08.780]   And so I'm excited for the momentum.
[00:08:08.780 --> 00:08:13.020]   But speaking of the exploding need for more baseload power
[00:08:13.020 --> 00:08:17.060]   to feed the AI beast, let's talk about our first topic
[00:08:17.060 --> 00:08:19.820]   and where things currently stand in AI.
[00:08:19.820 --> 00:08:22.660]   And I think since we last talked,
[00:08:22.660 --> 00:08:25.780]   people have continued to climb, build this wall of worry,
[00:08:25.780 --> 00:08:28.820]   like whether AI is in a bubble or not.
[00:08:28.820 --> 00:08:32.460]   Of course, last week, OpenAI was rumored
[00:08:32.460 --> 00:08:34.740]   or is now well-known to be raising capital
[00:08:34.740 --> 00:08:36.820]   at $150 billion valuation,
[00:08:36.820 --> 00:08:39.540]   or at least that's the Bloomberg headline.
[00:08:39.540 --> 00:08:42.060]   I can confirm that Altimeter is talking with the company.
[00:08:42.060 --> 00:08:43.660]   So of course, there's some things I can share
[00:08:43.660 --> 00:08:45.540]   and things I can't share.
[00:08:45.540 --> 00:08:47.940]   But you had Kevin Scott, the CTO of Microsoft,
[00:08:47.940 --> 00:08:50.100]   say demand for AI infrastructure
[00:08:50.100 --> 00:08:53.580]   is materially outpacing our ability to supply it,
[00:08:53.580 --> 00:08:57.780]   even as we are building at a pace unseen.
[00:08:57.780 --> 00:09:00.380]   Jensen said at the Goldman Sachs conference
[00:09:00.380 --> 00:09:03.140]   that they will be under-supplied not only this year,
[00:09:03.140 --> 00:09:04.700]   but for a while to come.
[00:09:04.700 --> 00:09:06.420]   So where do you come down on this, Bill?
[00:09:06.420 --> 00:09:09.140]   Let's just start with the demand for training
[00:09:09.140 --> 00:09:12.180]   and inference and data centers and power.
[00:09:12.180 --> 00:09:14.940]   Do you think we're headed for a glut?
[00:09:14.940 --> 00:09:16.820]   Before I answer that question,
[00:09:17.820 --> 00:09:20.140]   which we've talked about many times before,
[00:09:20.140 --> 00:09:24.900]   I will state that since two podcasts ago,
[00:09:24.900 --> 00:09:27.820]   'cause we focused on Diablo and didn't talk about this.
[00:09:27.820 --> 00:09:30.860]   So you go back, I guess, probably four or five weeks.
[00:09:30.860 --> 00:09:34.860]   If anything, the balance of enthusiasm
[00:09:34.860 --> 00:09:41.380]   and willingness of individuals to commit capital
[00:09:41.380 --> 00:09:44.500]   has gone up, not down.
[00:09:44.500 --> 00:09:45.940]   If you go back maybe a year,
[00:09:45.940 --> 00:09:48.780]   I don't know that Oracle was really in this discussion
[00:09:48.780 --> 00:09:52.660]   from a spin standpoint, right, on scaling things out.
[00:09:52.660 --> 00:09:54.420]   And clearly they are now.
[00:09:54.420 --> 00:09:55.260]   They're at the table.
[00:09:55.260 --> 00:09:58.620]   They want to be considered like one of the hyperscalers.
[00:09:58.620 --> 00:10:01.020]   So in addition to Oracle kind of stepping up
[00:10:01.020 --> 00:10:02.100]   and being a big player,
[00:10:02.100 --> 00:10:06.100]   we get an announcement that BlackRock and Microsoft
[00:10:06.100 --> 00:10:08.740]   are teaming up to raise a fund
[00:10:08.740 --> 00:10:11.060]   that would be 30 to a hundred billion dollars
[00:10:11.060 --> 00:10:12.620]   just to finance data centers.
[00:10:12.620 --> 00:10:14.380]   They also mentioned energy.
[00:10:14.380 --> 00:10:16.180]   But Microsoft was already building their owns
[00:10:16.180 --> 00:10:17.980]   and already supporting CoreWeave.
[00:10:17.980 --> 00:10:21.300]   And so this is just more and more commitment
[00:10:21.300 --> 00:10:23.300]   to rolling out more infrastructure.
[00:10:23.300 --> 00:10:25.260]   I think the Middle East is involved
[00:10:25.260 --> 00:10:26.460]   in this announcement as well.
[00:10:26.460 --> 00:10:28.180]   And there's been a lot of talk of,
[00:10:28.180 --> 00:10:31.260]   and there's a lot of companies like G42
[00:10:31.260 --> 00:10:34.820]   that are pushing for even more spend in the Middle East.
[00:10:34.820 --> 00:10:39.820]   So everything screams even more demand.
[00:10:39.820 --> 00:10:41.820]   You and I have argued or talked about
[00:10:41.820 --> 00:10:43.780]   whether this is really supply or demand,
[00:10:43.780 --> 00:10:46.860]   but presumably these people aren't acting irrationally.
[00:10:46.860 --> 00:10:49.260]   So since we talked last,
[00:10:49.260 --> 00:10:53.100]   I would say the world's gotten more enthusiastic
[00:10:53.100 --> 00:10:55.780]   about AI than it was five or six weeks ago.
[00:10:55.780 --> 00:10:56.620]   Right, right.
[00:10:56.620 --> 00:10:58.380]   And I agree with you.
[00:10:58.380 --> 00:11:00.180]   I think you said something really important,
[00:11:00.180 --> 00:11:03.700]   which is when you're planning out three to five years
[00:11:03.700 --> 00:11:06.620]   and we're talking about tens of billions of dollars,
[00:11:06.620 --> 00:11:11.620]   one has to assume that Sachin, Jensen and Oracle
[00:11:11.660 --> 00:11:14.380]   and then Amazon, et cetera, that what they're seeing
[00:11:14.380 --> 00:11:15.740]   justifies the spend.
[00:11:15.740 --> 00:11:18.100]   And one of the things driving the debate
[00:11:18.100 --> 00:11:20.940]   over that demand bill is all these new models
[00:11:20.940 --> 00:11:21.900]   that have been popping out.
[00:11:21.900 --> 00:11:26.340]   We finally saw Strawberry, the O1 preview model,
[00:11:26.340 --> 00:11:29.700]   whole new vector of scaling around inference time reasoning
[00:11:29.700 --> 00:11:32.140]   out of open AI, which is exciting.
[00:11:32.140 --> 00:11:34.300]   There's a new Anthropic Opus model,
[00:11:34.300 --> 00:11:36.740]   3.5 that's expected to drop this week.
[00:11:36.740 --> 00:11:39.900]   MetaConnect is in a couple of days, I'll be there.
[00:11:39.900 --> 00:11:42.260]   And Mark Zuckerberg is expected
[00:11:42.260 --> 00:11:44.060]   to announce several new models there,
[00:11:44.060 --> 00:11:47.060]   smaller models and larger models.
[00:11:47.060 --> 00:11:50.060]   And so despite the improvements
[00:11:50.060 --> 00:11:52.260]   in model training efficiency,
[00:11:52.260 --> 00:11:55.020]   the aggregate training and the velocity
[00:11:55.020 --> 00:11:59.060]   seems to continue to grind a lot higher.
[00:11:59.060 --> 00:12:01.660]   We were lucky to have Noam Brown,
[00:12:01.660 --> 00:12:05.340]   who's the inventor and the leader of the O1 preview.
[00:12:05.340 --> 00:12:07.860]   So remember, we talked about Noam before.
[00:12:07.860 --> 00:12:10.780]   He was at Meta and did Pluribus and Liberatus,
[00:12:10.780 --> 00:12:13.380]   won the game of six-handed poker.
[00:12:13.380 --> 00:12:15.060]   He spent a lot of time thinking
[00:12:15.060 --> 00:12:17.420]   about this inference time reasoning.
[00:12:17.420 --> 00:12:21.060]   And we're really early in this journey,
[00:12:21.060 --> 00:12:24.220]   but it's already kind of a big wow, right?
[00:12:24.220 --> 00:12:27.140]   This idea that in addition to pre-training,
[00:12:27.140 --> 00:12:31.340]   we're now going to allow models to reason and think
[00:12:31.340 --> 00:12:34.620]   as part of the response process to the prompt.
[00:12:34.620 --> 00:12:37.060]   I don't know if you looked at any of these tweets
[00:12:37.060 --> 00:12:40.420]   out of Noam Brown or others about the O1 preview,
[00:12:40.420 --> 00:12:43.380]   but just curious if you had any thoughts or reaction.
[00:12:43.380 --> 00:12:45.780]   I know you were blown away by the voice model.
[00:12:45.780 --> 00:12:48.100]   It's been slow in dropping,
[00:12:48.100 --> 00:12:49.900]   but I don't know if you've played with the O1 preview.
[00:12:49.900 --> 00:12:51.780]   Well, yeah, and on the voice thing,
[00:12:51.780 --> 00:12:54.740]   I think they may have been focusing
[00:12:54.740 --> 00:12:56.100]   on their enterprise customers.
[00:12:56.100 --> 00:12:58.820]   I've talked to some enterprise customers
[00:12:58.820 --> 00:13:00.540]   who have that product in-house
[00:13:00.540 --> 00:13:01.980]   and they're very excited about it.
[00:13:01.980 --> 00:13:04.980]   And let me just say quickly on voice,
[00:13:04.980 --> 00:13:08.620]   one thought I had when you think about it being delivered
[00:13:08.620 --> 00:13:11.900]   as an API and not just as a consumer product,
[00:13:11.900 --> 00:13:13.540]   there is this question is,
[00:13:13.540 --> 00:13:17.860]   does the input to the computer become voice
[00:13:17.860 --> 00:13:18.740]   for the first time?
[00:13:18.740 --> 00:13:23.660]   Microsoft was talking about that maybe two decades ago
[00:13:23.660 --> 00:13:26.460]   and Gates was super excited about it.
[00:13:26.460 --> 00:13:29.860]   Yeah, tell me, we were big in tell me,
[00:13:29.860 --> 00:13:32.420]   but if it gets so good,
[00:13:32.420 --> 00:13:36.900]   and this becomes the way you talk to your computer.
[00:13:36.900 --> 00:13:40.260]   And another thing I would say is talk to websites.
[00:13:40.260 --> 00:13:44.780]   Like, could you imagine you walk up to a kayak
[00:13:44.780 --> 00:13:48.740]   or on the website and you just start talking,
[00:13:48.740 --> 00:13:52.660]   that'll be a radical new dimension
[00:13:52.660 --> 00:13:54.740]   for how we use our computers.
[00:13:54.740 --> 00:13:56.900]   So I'm excited to see how that plays out.
[00:13:56.900 --> 00:13:58.700]   On the strawberry release,
[00:14:00.580 --> 00:14:02.620]   the one thing that I think is important
[00:14:02.620 --> 00:14:05.820]   for people to realize is the graphs that were shown,
[00:14:05.820 --> 00:14:07.940]   and we can certainly put some links in the show notes,
[00:14:07.940 --> 00:14:09.500]   but I think everyone's seen it.
[00:14:09.500 --> 00:14:13.020]   The access was logarithmic.
[00:14:13.020 --> 00:14:16.620]   The implication being in order to get linear improvement,
[00:14:16.620 --> 00:14:21.260]   you have to do maybe 10X the amount of processing.
[00:14:21.260 --> 00:14:22.700]   And this is all inference.
[00:14:22.700 --> 00:14:25.100]   So what are the implications of that?
[00:14:25.100 --> 00:14:28.980]   Well, one, you have to figure out what problem cases
[00:14:28.980 --> 00:14:33.980]   are good scenarios for being willing to spend 10X
[00:14:33.980 --> 00:14:41.340]   or 100X as much on inference to get to a better solution.
[00:14:41.340 --> 00:14:42.860]   I don't think it's all of them,
[00:14:42.860 --> 00:14:45.780]   but many people believe it's a lot of them.
[00:14:45.780 --> 00:14:48.340]   And then the second thing that comes out of that is
[00:14:48.340 --> 00:14:52.740]   if there are a lot of them that are willing to pay
[00:14:52.740 --> 00:14:57.220]   10 to 100X on inference to get linear improvements,
[00:14:57.220 --> 00:15:00.220]   then the percentage of compute,
[00:15:00.220 --> 00:15:04.140]   and you need to run math models
[00:15:04.140 --> 00:15:05.220]   I don't have in front of me now,
[00:15:05.220 --> 00:15:06.980]   but maybe the dollars of compute
[00:15:06.980 --> 00:15:10.100]   are gonna move more towards inference than training
[00:15:10.100 --> 00:15:11.820]   as we move forward.
[00:15:11.820 --> 00:15:13.940]   - I think there's no doubt.
[00:15:13.940 --> 00:15:15.860]   So there's a video of Jensen out there
[00:15:15.860 --> 00:15:17.500]   that we'll put in here.
[00:15:17.500 --> 00:15:22.500]   - One of the things that Sam introduced recently,
[00:15:22.500 --> 00:15:25.580]   the reasoning capability of these AIs
[00:15:25.580 --> 00:15:28.180]   are gonna be so much smarter,
[00:15:28.180 --> 00:15:31.180]   but it's gonna require so much more computation.
[00:15:31.180 --> 00:15:34.620]   And so whereas each one of the prompts today
[00:15:34.620 --> 00:15:37.100]   into ChatGPT is a one pass,
[00:15:37.100 --> 00:15:39.860]   in the future it's going to be hundreds of passes inside.
[00:15:39.860 --> 00:15:40.780]   It's gonna be reasoning.
[00:15:40.780 --> 00:15:42.260]   It's gonna be doing reinforcement learning.
[00:15:42.260 --> 00:15:43.860]   It's gonna be trying to figure out
[00:15:43.860 --> 00:15:45.140]   how to create a better answer,
[00:15:45.140 --> 00:15:47.020]   reason a better answer for you.
[00:15:47.020 --> 00:15:48.860]   - When you use a model like Strawberry,
[00:15:48.860 --> 00:15:51.660]   you're likely to see 100X more inference, right?
[00:15:51.660 --> 00:15:53.940]   Because rather than single shot prompting,
[00:15:53.940 --> 00:15:56.460]   there's a lot of recycling that's going on
[00:15:56.460 --> 00:15:58.500]   as part of the reasoning process.
[00:15:58.500 --> 00:16:02.140]   Just mathematically, we know that's going to lead
[00:16:02.140 --> 00:16:04.340]   to a massive explosion in inference.
[00:16:04.340 --> 00:16:08.580]   Now, if you look at these GB200s that NVIDIA is selling,
[00:16:08.580 --> 00:16:10.660]   the cost or the improvement in inference,
[00:16:10.660 --> 00:16:14.740]   I mean, NVIDIA says it's a 50X improvement in inference.
[00:16:14.740 --> 00:16:17.420]   Other people say it's a 3X improvement in inference,
[00:16:17.420 --> 00:16:19.780]   but there's clearly a lot of focus on inference.
[00:16:19.780 --> 00:16:21.980]   I think the world is inference constrained.
[00:16:21.980 --> 00:16:24.260]   I think part of the reason for that
[00:16:24.260 --> 00:16:28.020]   is that you have new models emerging like this
[00:16:28.020 --> 00:16:30.020]   that are gonna have machines talking to machines,
[00:16:30.020 --> 00:16:32.580]   lots of inference going on in the background.
[00:16:32.580 --> 00:16:34.900]   Of course, you have companies like Grok and Cerebus
[00:16:34.900 --> 00:16:37.700]   that are bringing really fast inferencing to the table.
[00:16:37.700 --> 00:16:39.980]   But again, I think we're talking about
[00:16:39.980 --> 00:16:42.460]   many orders of magnitude increase
[00:16:42.460 --> 00:16:44.020]   to the amount of inference,
[00:16:44.020 --> 00:16:47.380]   which is going to be needed in the future.
[00:16:47.380 --> 00:16:49.620]   And if you're building a data center,
[00:16:49.620 --> 00:16:51.380]   think about this, Bill.
[00:16:51.380 --> 00:16:53.780]   If I'm making a $10 billion investment
[00:16:53.780 --> 00:16:55.700]   in a 300-megawatt data center,
[00:16:55.700 --> 00:16:57.940]   I wanna be able to use that for both training
[00:16:57.940 --> 00:17:01.540]   and for inference when my training run is not happening.
[00:17:01.540 --> 00:17:03.900]   So when you look at the total cost of operation
[00:17:03.900 --> 00:17:05.780]   in one of these data centers,
[00:17:05.780 --> 00:17:07.220]   you're gonna see a lot more activity.
[00:17:07.220 --> 00:17:09.540]   And my hunch is part of the reason
[00:17:09.540 --> 00:17:12.020]   that voice hasn't dropped, Bill,
[00:17:12.020 --> 00:17:15.380]   is that they've all said it.
[00:17:15.380 --> 00:17:19.020]   I think that OpenAI and Microsoft and others
[00:17:19.020 --> 00:17:21.860]   are inference-constrained at the moment
[00:17:21.860 --> 00:17:24.100]   in terms of the demand on these systems.
[00:17:24.100 --> 00:17:26.500]   I think the systems will also get more intelligent
[00:17:26.500 --> 00:17:30.820]   where they'll route the request to the simplest models
[00:17:30.820 --> 00:17:32.820]   to answer the particular question.
[00:17:32.820 --> 00:17:37.820]   So you don't need O1 for really basic questions.
[00:17:37.820 --> 00:17:39.940]   That you might be able to route, in fact,
[00:17:39.940 --> 00:17:41.980]   to a GPT-3-like model.
[00:17:41.980 --> 00:17:44.380]   But having intelligent layering of these models,
[00:17:44.380 --> 00:17:47.340]   an ensemble of models put together
[00:17:47.340 --> 00:17:50.660]   so that you get the answers in the fastest amount of time,
[00:17:50.660 --> 00:17:52.140]   and it's gonna be different models
[00:17:52.140 --> 00:17:54.260]   for different sorts of questions.
[00:17:54.260 --> 00:17:58.820]   Yeah, and whether or not the engine can interpret
[00:17:58.820 --> 00:18:00.660]   which of those it is will be important.
[00:18:00.660 --> 00:18:02.940]   I would go back and highlight
[00:18:02.940 --> 00:18:06.460]   that even in the announcements from OpenAI on Strawberry,
[00:18:06.460 --> 00:18:12.740]   they admit or they disclose or qualify
[00:18:12.740 --> 00:18:15.180]   that there are many instances
[00:18:15.180 --> 00:18:19.180]   where the extra iteration led to worse results.
[00:18:19.180 --> 00:18:22.420]   So you really do need to be able to figure out
[00:18:22.420 --> 00:18:25.140]   the type of problem and whether or not
[00:18:25.140 --> 00:18:28.020]   you're gonna get improvement from that effort.
[00:18:28.020 --> 00:18:32.300]   And I personally don't think we know enough yet
[00:18:32.300 --> 00:18:35.900]   to know which problems fit in there or not.
[00:18:35.900 --> 00:18:39.180]   But I do think people are super excited
[00:18:39.180 --> 00:18:42.900]   about what's possible on that front.
[00:18:42.900 --> 00:18:45.140]   My biggest thing about it is like, listen,
[00:18:45.140 --> 00:18:47.060]   we've been talking about bigger models,
[00:18:47.060 --> 00:18:48.420]   more parameters, all of this.
[00:18:48.420 --> 00:18:51.780]   That's basically been the exclusive vector of conversation
[00:18:51.780 --> 00:18:53.100]   for scaling intelligence.
[00:18:53.100 --> 00:18:54.940]   This is a totally new vector.
[00:18:54.940 --> 00:18:58.220]   And now you have the compounding benefit,
[00:18:58.220 --> 00:19:00.820]   two different ways to scale intelligence
[00:19:00.820 --> 00:19:02.180]   that I think is super exciting.
[00:19:02.180 --> 00:19:03.580]   And just real quick,
[00:19:03.580 --> 00:19:06.220]   I had a second thing before you move forward.
[00:19:06.220 --> 00:19:10.140]   I could restate when you use the phrase
[00:19:10.140 --> 00:19:11.580]   inference constraint,
[00:19:11.580 --> 00:19:14.140]   that may be a financial problem too.
[00:19:14.140 --> 00:19:17.380]   Like it may be super expensive to run advanced voice
[00:19:17.380 --> 00:19:19.780]   relative to what you're charging for.
[00:19:19.780 --> 00:19:23.340]   And so especially when you talk about
[00:19:23.340 --> 00:19:26.100]   logarithmic increase in spend,
[00:19:26.100 --> 00:19:29.220]   I think these companies develop these breakthroughs
[00:19:29.220 --> 00:19:30.900]   and they're eager to share them with the world.
[00:19:30.900 --> 00:19:34.060]   And so they put them out there maybe in a freemium
[00:19:34.060 --> 00:19:37.100]   or maybe in a kind of early test thing.
[00:19:37.100 --> 00:19:40.700]   But if some of them do have much higher underlying costs,
[00:19:40.700 --> 00:19:43.020]   we do need to figure out,
[00:19:43.020 --> 00:19:45.380]   what are the business models for these things?
[00:19:45.380 --> 00:19:46.980]   How much are people willing to pay?
[00:19:46.980 --> 00:19:49.580]   I've heard people on other podcasts say,
[00:19:49.580 --> 00:19:53.420]   well, for a perfect assistant, I might pay 10 grand a year,
[00:19:53.420 --> 00:19:56.460]   but no one has that product on the market right now.
[00:19:56.460 --> 00:20:00.060]   And so I think there's a lot of experimentation
[00:20:00.060 --> 00:20:02.820]   with business models that's gonna have to happen as well.
[00:20:02.820 --> 00:20:03.740]   I couldn't agree more.
[00:20:03.740 --> 00:20:05.100]   I think there's gonna have to be,
[00:20:05.100 --> 00:20:06.220]   I mean, think about this.
[00:20:06.220 --> 00:20:08.340]   There's gonna be massive price discrimination.
[00:20:08.340 --> 00:20:09.700]   You can't charge in the Philippines,
[00:20:09.700 --> 00:20:11.500]   what you're gonna be able to charge in the United States.
[00:20:11.500 --> 00:20:13.140]   You can't charge to the tail end,
[00:20:13.140 --> 00:20:14.980]   what you're gonna be able to charge to the head end.
[00:20:14.980 --> 00:20:19.980]   But one thing that is true is it looks like OpenAI
[00:20:19.980 --> 00:20:24.940]   has something like 200 million weekly MAUs.
[00:20:24.940 --> 00:20:26.540]   That's a number widely reported.
[00:20:26.540 --> 00:20:30.940]   It's a huge, huge number with little to no advertising.
[00:20:30.940 --> 00:20:31.860]   And it seems to me,
[00:20:31.860 --> 00:20:35.060]   this is really this benefit of going first, Bill.
[00:20:35.060 --> 00:20:37.420]   Billions of free ad impressions.
[00:20:37.420 --> 00:20:39.180]   It continues to grow.
[00:20:39.180 --> 00:20:41.580]   And so I asked the team to just to take a look
[00:20:41.580 --> 00:20:44.540]   at the time to reach a hundred million MAUs,
[00:20:44.540 --> 00:20:47.500]   and you could see this chart just,
[00:20:47.500 --> 00:20:51.300]   it took Chachapiti a fraction of the time
[00:20:51.300 --> 00:20:55.220]   that it took YouTube or Instagram or Facebook
[00:20:55.220 --> 00:20:56.220]   to get to the same place.
[00:20:56.220 --> 00:20:58.500]   It took Facebook about five years.
[00:20:58.500 --> 00:21:02.220]   Now that obviously has continued to go up.
[00:21:02.220 --> 00:21:04.940]   Weekly average users are 200 million.
[00:21:04.940 --> 00:21:06.660]   It's pretty extraordinary.
[00:21:06.660 --> 00:21:07.740]   And even by country,
[00:21:07.740 --> 00:21:09.540]   if you look at the spread of Chachapiti,
[00:21:09.540 --> 00:21:12.220]   it's clearly spreading on a global basis.
[00:21:12.220 --> 00:21:15.340]   And then finally this tweet by Vivek Goyal on my team,
[00:21:15.340 --> 00:21:19.140]   it shows just like Chachapiti beginning to run away with it,
[00:21:19.140 --> 00:21:24.140]   Gemini, Meta AI, Claude really are not even keeping up.
[00:21:24.140 --> 00:21:29.500]   So just if you set aside valuation for a second here, Bill,
[00:21:30.620 --> 00:21:32.820]   why do you think the game on the field
[00:21:32.820 --> 00:21:36.380]   as to consumer has changed so much?
[00:21:36.380 --> 00:21:40.380]   Is Chachapiti now in a flywheel?
[00:21:40.380 --> 00:21:41.980]   Have they broken out of the pack?
[00:21:41.980 --> 00:21:46.220]   Do you think they're gonna be the winner in consumer AI?
[00:21:46.220 --> 00:21:49.980]   A couple of things that we've talked about in the past.
[00:21:49.980 --> 00:21:52.860]   So I think everything you said is true.
[00:21:52.860 --> 00:21:55.180]   I do think voice and memory
[00:21:55.180 --> 00:21:59.060]   are areas where you could really run.
[00:21:59.060 --> 00:22:02.940]   And so people are super excited about advanced voice.
[00:22:02.940 --> 00:22:04.380]   People that have it, love it.
[00:22:04.380 --> 00:22:08.860]   Especially when I'm driving in a car,
[00:22:08.860 --> 00:22:12.620]   I'll have long conversations with Chachapiti.
[00:22:12.620 --> 00:22:16.020]   And if the advanced mode makes that even easier,
[00:22:16.020 --> 00:22:18.700]   I think that's very, very reinforcing.
[00:22:18.700 --> 00:22:20.940]   And anyone that wants to compete
[00:22:20.940 --> 00:22:24.060]   would need to catch up on that front fast.
[00:22:24.060 --> 00:22:26.020]   And then the second thing is memory.
[00:22:26.020 --> 00:22:29.100]   And I would just say,
[00:22:29.100 --> 00:22:31.140]   based on all the tools that are out there,
[00:22:31.140 --> 00:22:34.540]   they appear to be experimenting with it more than others.
[00:22:34.540 --> 00:22:36.700]   And we've talked about this over and over,
[00:22:36.700 --> 00:22:38.500]   but you can go into Chachapiti
[00:22:38.500 --> 00:22:41.860]   and look at what it's remembered on your behalf.
[00:22:41.860 --> 00:22:44.940]   I think that's big, really big,
[00:22:44.940 --> 00:22:48.180]   which would be another vector for them to break through on.
[00:22:48.180 --> 00:22:51.820]   You know, another one I feel like is worth mentioning
[00:22:51.820 --> 00:22:56.820]   is Sam Altman just continues to do extraordinary things.
[00:22:56.820 --> 00:23:02.540]   Like he's just surviving the whole board thing
[00:23:02.540 --> 00:23:05.860]   was something most humans couldn't do.
[00:23:05.860 --> 00:23:11.020]   He seems to have remarkable touch in Washington and access,
[00:23:11.020 --> 00:23:15.780]   which regulation appears to be coming at us fast and furious.
[00:23:15.780 --> 00:23:18.900]   And I've often said that could be used
[00:23:18.900 --> 00:23:20.700]   to help reinforce lock-in.
[00:23:20.700 --> 00:23:24.940]   And him having that access and control is super valuable.
[00:23:24.940 --> 00:23:28.260]   And we continue to just hear about new initiatives
[00:23:28.260 --> 00:23:29.380]   or new programs.
[00:23:29.380 --> 00:23:31.060]   You know, he's traveling around the globe.
[00:23:31.060 --> 00:23:32.580]   He's got everyone's ear.
[00:23:32.580 --> 00:23:35.500]   And he appears to be remarkably ambitious
[00:23:35.500 --> 00:23:39.500]   and successful at what he's trying to convey
[00:23:39.500 --> 00:23:41.500]   and talking to people into doing things
[00:23:41.500 --> 00:23:44.060]   they wouldn't do for any other partner, you know?
[00:23:44.060 --> 00:23:47.980]   - Yeah, it's pretty extraordinary, the pace and velocity.
[00:23:47.980 --> 00:23:51.100]   And frankly, we see that on the team side as well.
[00:23:51.100 --> 00:23:52.380]   Just extraordinary team.
[00:23:52.380 --> 00:23:55.500]   The best people continue to appear to go there.
[00:23:55.500 --> 00:23:57.500]   You know, everybody asked me a year ago,
[00:23:57.500 --> 00:23:58.940]   they said, "Oh, Gemini's coming.
[00:23:58.940 --> 00:24:00.060]   Gemini's gonna go first."
[00:24:00.060 --> 00:24:01.180]   But the fact of the matter is,
[00:24:01.180 --> 00:24:03.980]   right through the chaos of the moment, Bill,
[00:24:03.980 --> 00:24:05.380]   everybody's responding to them.
[00:24:05.380 --> 00:24:07.700]   They launched Strawberry in '01 preview first.
[00:24:07.700 --> 00:24:09.900]   They launched Advanced Voice first.
[00:24:09.900 --> 00:24:11.620]   So you gotta give them some credit for that.
[00:24:11.620 --> 00:24:15.020]   But when it comes to 200 million weekly miles
[00:24:15.020 --> 00:24:16.140]   that's reported out there,
[00:24:16.140 --> 00:24:17.980]   I would also make this argument, you know,
[00:24:17.980 --> 00:24:19.700]   and the team's made a chart on this,
[00:24:19.700 --> 00:24:23.180]   and I'm really curious of your thoughts.
[00:24:23.180 --> 00:24:26.300]   So it appears to me that open AI is seeing
[00:24:26.300 --> 00:24:28.460]   more and more of a network effect
[00:24:28.460 --> 00:24:30.780]   as well as scale advantages, right?
[00:24:30.780 --> 00:24:34.660]   So, you know, you've talked a lot about network effects,
[00:24:34.660 --> 00:24:36.340]   but there's been debate as to whether or not
[00:24:36.340 --> 00:24:37.500]   they exist here.
[00:24:37.500 --> 00:24:39.100]   But here's the argument that I would make.
[00:24:39.100 --> 00:24:41.340]   On the network effects side,
[00:24:41.340 --> 00:24:45.940]   it seems like more users is leading to better data,
[00:24:45.940 --> 00:24:49.300]   the data coming from the interactions with those users.
[00:24:49.300 --> 00:24:53.260]   And that's leading to better models and cheaper models,
[00:24:53.260 --> 00:24:56.180]   because you can do more of the work in post-training,
[00:24:56.180 --> 00:24:59.460]   which then leads to more users, right?
[00:24:59.460 --> 00:25:03.860]   And so, you know, here's the chart that we made on it.
[00:25:03.860 --> 00:25:08.460]   Do you buy the network effects argument, that flywheel?
[00:25:08.460 --> 00:25:11.580]   Because if that's in place,
[00:25:11.580 --> 00:25:14.340]   then it, to me, explains why we're seeing them
[00:25:14.340 --> 00:25:17.780]   break away from the pack when it comes to consumer AI.
[00:25:17.780 --> 00:25:19.420]   - Yeah, I don't know.
[00:25:19.420 --> 00:25:21.180]   I mean, I hate for that to be my answer,
[00:25:21.180 --> 00:25:25.700]   but I don't know the material impact
[00:25:25.700 --> 00:25:29.620]   of the users translating into data.
[00:25:29.620 --> 00:25:31.860]   You've likely seen, I've seen, you know,
[00:25:31.860 --> 00:25:36.540]   occasionally maybe one in 20 prompts that I do into open AI
[00:25:36.540 --> 00:25:38.460]   I'll get two results, and it'll ask me
[00:25:38.460 --> 00:25:39.620]   which one I like better.
[00:25:39.620 --> 00:25:42.340]   So that's the kind of thing you're talking about.
[00:25:42.340 --> 00:25:46.180]   And I just don't know if that makes the model 10% better,
[00:25:46.180 --> 00:25:47.980]   20, or 50, or 100.
[00:25:47.980 --> 00:25:52.100]   There's certainly data that suggests the other models
[00:25:52.100 --> 00:25:55.860]   are right on their heels if you only look at test scores
[00:25:55.860 --> 00:25:58.140]   and, you know, the type of benchmarks.
[00:25:58.140 --> 00:26:01.060]   So that would suggest this isn't true.
[00:26:01.060 --> 00:26:03.580]   You know, the memory side, you know,
[00:26:03.580 --> 00:26:05.700]   the switching costs go through the roof
[00:26:05.700 --> 00:26:06.700]   if you get that right.
[00:26:06.700 --> 00:26:07.980]   - For sure, for sure.
[00:26:07.980 --> 00:26:10.340]   - Now, the one thing we've talked about
[00:26:10.340 --> 00:26:13.980]   that is also at play is that the memory
[00:26:13.980 --> 00:26:17.500]   you'd really like to have is on email and chat
[00:26:17.500 --> 00:26:21.940]   and all the data sources that already exist in your life.
[00:26:21.940 --> 00:26:26.660]   And how open AI would get inside of those systems
[00:26:26.660 --> 00:26:28.540]   is less clear to me.
[00:26:28.540 --> 00:26:29.500]   - Yep.
[00:26:29.500 --> 00:26:31.780]   - It's not impossible, it's just less clear.
[00:26:31.780 --> 00:26:34.780]   And that's where Microsoft and Google have some advantages
[00:26:34.780 --> 00:26:36.540]   and maybe Apple as well.
[00:26:36.540 --> 00:26:40.180]   And so it'll be fun to watch that fight
[00:26:40.180 --> 00:26:42.820]   and how those sources of data,
[00:26:42.820 --> 00:26:45.780]   because I think that's where you get the real lock-in.
[00:26:45.780 --> 00:26:50.300]   If I have an AI partner where I can simply say,
[00:26:50.300 --> 00:26:52.220]   "Who did I send that email to?"
[00:26:52.220 --> 00:26:55.020]   Like, that's really, really powerful.
[00:26:55.020 --> 00:26:58.420]   And I think the switching costs are insurmountable
[00:26:58.420 --> 00:27:00.540]   if someone gets to that place first.
[00:27:00.540 --> 00:27:01.660]   - The data on the field,
[00:27:01.660 --> 00:27:03.740]   and I'm just looking at the data on the field,
[00:27:03.740 --> 00:27:07.420]   I'm looking at the number of users and meta AI, et cetera.
[00:27:07.420 --> 00:27:10.460]   It looks to me like among the new consumer entrants,
[00:27:10.460 --> 00:27:13.580]   and I like the guys a lot at Perplexity, as you know,
[00:27:13.580 --> 00:27:15.980]   and I know lots of people like that product,
[00:27:15.980 --> 00:27:18.060]   but just from a usage perspective,
[00:27:18.060 --> 00:27:20.780]   among the new entrants who have the capital,
[00:27:20.780 --> 00:27:22.740]   who have the surface area to compete,
[00:27:22.740 --> 00:27:27.380]   it looks to me like Chat GPT has now clearly broken away.
[00:27:27.380 --> 00:27:29.580]   And there's gonna be a game between them.
[00:27:29.580 --> 00:27:31.980]   Meta, I think, is probably in the second best position.
[00:27:31.980 --> 00:27:34.900]   Google probably can't be underestimated.
[00:27:34.900 --> 00:27:38.700]   Obviously, Satya has consumer co-pilot with Mustafa there,
[00:27:38.700 --> 00:27:40.940]   but it's really interesting to see that game.
[00:27:40.940 --> 00:27:43.220]   The other vector here that's interesting is,
[00:27:43.220 --> 00:27:45.460]   you know, there's a lot of rumors out there
[00:27:45.460 --> 00:27:49.220]   about open AI's revenue, Bill, you know,
[00:27:49.220 --> 00:27:50.900]   and we'll post some of these, you know,
[00:27:50.900 --> 00:27:52.460]   four or five billion in revenue-
[00:27:52.460 --> 00:27:54.020]   - That's what I've heard, yeah.
[00:27:54.020 --> 00:27:55.820]   - Growing at over 100% a year.
[00:27:55.820 --> 00:27:58.580]   So I'm just intrigued by that.
[00:27:58.580 --> 00:28:01.380]   If that trajectory were to continue, right,
[00:28:01.380 --> 00:28:04.340]   that'd give you like roughly 10 billion next year.
[00:28:04.820 --> 00:28:08.460]   And the round's rumored to be at $150 billion.
[00:28:08.460 --> 00:28:11.900]   So that's about 15 times forward revenue.
[00:28:11.900 --> 00:28:13.340]   So I asked the team two things.
[00:28:13.340 --> 00:28:16.700]   I asked them to compare that to other companies,
[00:28:16.700 --> 00:28:18.700]   namely Google and Meta,
[00:28:18.700 --> 00:28:22.660]   both in terms of the pace to get to five billion in revenue
[00:28:22.660 --> 00:28:25.460]   and the valuations once they got there.
[00:28:25.460 --> 00:28:27.820]   And so this first chart just shows
[00:28:27.820 --> 00:28:32.260]   that open AI was able to get there roughly in, you know,
[00:28:32.260 --> 00:28:35.260]   in two years from the launch of the chat GPT
[00:28:35.260 --> 00:28:36.940]   in November of '22.
[00:28:36.940 --> 00:28:40.020]   You know, it took Google about two or three more years
[00:28:40.020 --> 00:28:41.060]   than that to get there.
[00:28:41.060 --> 00:28:45.100]   It took Meta almost six or seven years to get there.
[00:28:45.100 --> 00:28:46.660]   And what was interesting,
[00:28:46.660 --> 00:28:49.020]   so they got there a lot faster to five billion.
[00:28:49.020 --> 00:28:51.100]   We can agree on that.
[00:28:51.100 --> 00:28:52.260]   But then I asked,
[00:28:52.260 --> 00:28:55.460]   what were the multiples at that point in time?
[00:28:55.460 --> 00:28:58.060]   Because I remember when I bought the Google IPO,
[00:28:58.060 --> 00:28:59.820]   everybody said it's overpriced.
[00:28:59.820 --> 00:29:01.540]   When Microsoft invested in Meta,
[00:29:01.540 --> 00:29:02.900]   everybody said it's overpriced.
[00:29:02.900 --> 00:29:05.900]   But what's interesting is Google IPO-ed in 2004
[00:29:05.900 --> 00:29:08.660]   at about 10 times forward revenue, right?
[00:29:08.660 --> 00:29:11.340]   Microsoft invested in Meta at 2007
[00:29:11.340 --> 00:29:13.700]   at about 50 times revenue.
[00:29:13.700 --> 00:29:18.060]   And then Meta IPO-ed in 2012 at about 13 times revenue.
[00:29:18.060 --> 00:29:20.020]   And now again, if all these rumors are correct,
[00:29:20.020 --> 00:29:22.140]   you're talking 15 times revenue.
[00:29:22.140 --> 00:29:25.980]   So it's basically in a valuation zip code
[00:29:25.980 --> 00:29:27.500]   that is, you know, again,
[00:29:27.500 --> 00:29:30.140]   if you accept the trajectory
[00:29:30.140 --> 00:29:32.620]   that's similar to those other companies.
[00:29:32.620 --> 00:29:35.500]   And I know you have some real thoughts about margin here
[00:29:35.500 --> 00:29:37.580]   and whether or not the quality of those revenues
[00:29:37.580 --> 00:29:38.420]   are the same.
[00:29:38.420 --> 00:29:41.460]   So I thought I'd just throw that out there and ask you.
[00:29:41.460 --> 00:29:46.340]   Yeah, well, look, I think your analysis is exactly correct.
[00:29:46.340 --> 00:29:49.460]   And the only area of risk is what you just said.
[00:29:49.460 --> 00:29:51.740]   And I wrote a blog post years ago
[00:29:51.740 --> 00:29:54.140]   called "All Revenue Is Not Created Equal,"
[00:29:54.140 --> 00:29:57.260]   which we could put a link in for people wanna look at.
[00:29:57.260 --> 00:30:01.060]   But I think the one question I would have in this case,
[00:30:01.060 --> 00:30:04.620]   which is a data point I don't have, is gross margin.
[00:30:04.620 --> 00:30:08.300]   And there, everything we talked about,
[00:30:08.300 --> 00:30:11.860]   you know, the high cost of maybe the GPU usage
[00:30:11.860 --> 00:30:13.380]   to get advanced voice, right?
[00:30:13.380 --> 00:30:17.940]   Like there's a chance that open AI
[00:30:17.940 --> 00:30:20.220]   or anyone else in this field's gross margins
[00:30:20.220 --> 00:30:22.620]   are more in the 10 or 20% range
[00:30:22.620 --> 00:30:26.580]   versus the 57 and 81 that you have here in your charts.
[00:30:26.580 --> 00:30:29.180]   And that would be the one thing that might trip it up.
[00:30:29.180 --> 00:30:32.740]   And how those scale over time is tied exactly
[00:30:32.740 --> 00:30:34.740]   to all the things that we just talked about
[00:30:34.740 --> 00:30:37.380]   in the pricing model and the business model.
[00:30:37.380 --> 00:30:40.900]   So yeah, I think you could come to the conclusion
[00:30:40.900 --> 00:30:45.060]   you just made, but still have exposure in this one area.
[00:30:45.060 --> 00:30:46.420]   Yeah, and I think, you know,
[00:30:46.420 --> 00:30:49.540]   I think it's such an important point to make, right?
[00:30:49.540 --> 00:30:51.540]   Like when you're investing in a company,
[00:30:51.540 --> 00:30:54.300]   you gotta get the top line.
[00:30:54.300 --> 00:30:55.740]   Like who's gonna be the winner?
[00:30:55.740 --> 00:30:58.140]   And then you need to be able to forecast that top line,
[00:30:58.140 --> 00:31:01.180]   but that's not ultimately what drives valuation, right?
[00:31:01.180 --> 00:31:04.580]   What drives valuation as we've often talked about here
[00:31:04.580 --> 00:31:07.420]   is the future cash flows that those revenues can produce.
[00:31:07.420 --> 00:31:09.700]   And there's a real question on the table here
[00:31:09.700 --> 00:31:12.820]   that you've articulated well, which is, you know,
[00:31:12.820 --> 00:31:16.460]   is there going to be a layer, a tax here, right?
[00:31:16.460 --> 00:31:19.580]   That Nvidia and the cost of inference
[00:31:19.580 --> 00:31:23.060]   and the cost of training imposes in perpetuity
[00:31:23.060 --> 00:31:26.180]   on these companies such that it's going
[00:31:26.180 --> 00:31:29.020]   to always be a less profitable business
[00:31:29.020 --> 00:31:32.580]   than a Meta or Google on the consumer side,
[00:31:32.580 --> 00:31:37.380]   or an AWS and, you know, and a Google Cloud
[00:31:37.380 --> 00:31:41.060]   or Microsoft Azure on the enterprise side.
[00:31:41.060 --> 00:31:43.540]   I certainly think you're right
[00:31:43.540 --> 00:31:46.380]   that at the start of the super cycle,
[00:31:46.380 --> 00:31:48.820]   like if you go back to the start of AWS,
[00:31:48.820 --> 00:31:52.180]   remember the debates then, Bill, in 2009, 2010,
[00:31:52.180 --> 00:31:53.580]   can it ever make money?
[00:31:53.580 --> 00:31:55.380]   Can it ever make money, right?
[00:31:55.380 --> 00:31:58.660]   Because they had to get to massive scale
[00:31:58.660 --> 00:32:02.780]   and the cost of delivering that scale had to come down.
[00:32:02.780 --> 00:32:05.020]   So you're betting on two things, I think,
[00:32:05.020 --> 00:32:07.460]   with OpenAI with respect to margins.
[00:32:07.460 --> 00:32:09.540]   The first thing you're betting on is that they can get
[00:32:09.540 --> 00:32:12.820]   to scale because this is clearly a scale business.
[00:32:12.820 --> 00:32:15.980]   The second thing you're betting on is you have to believe
[00:32:15.980 --> 00:32:19.020]   that the cost of inference is going to come down
[00:32:19.020 --> 00:32:22.300]   meaningfully over time, and that the cost of training
[00:32:22.300 --> 00:32:23.940]   will come down meaningfully over time.
[00:32:23.940 --> 00:32:26.540]   Now, we already know the cost of inference has come down
[00:32:26.540 --> 00:32:30.780]   by over 90% over the course of the last 18 months.
[00:32:30.780 --> 00:32:32.340]   And our friend, Sonny, over the weekend,
[00:32:32.340 --> 00:32:34.180]   when we were in our group chat, you know,
[00:32:34.180 --> 00:32:37.460]   said he expects it to come down by another 90%
[00:32:37.460 --> 00:32:39.620]   over the course of the next several years.
[00:32:39.620 --> 00:32:41.540]   So, but those are the types of things
[00:32:41.540 --> 00:32:43.100]   you're going to need to be true
[00:32:43.100 --> 00:32:47.420]   in order to have a margin structure that is consistent
[00:32:47.420 --> 00:32:51.380]   with those legendary businesses like Google and Meta.
[00:32:51.380 --> 00:32:53.820]   - Yeah, and yeah, to be fair,
[00:32:53.820 --> 00:32:55.500]   your analysis had Google and Meta,
[00:32:55.500 --> 00:32:59.900]   but when you make AWS, the comparison that suggests
[00:32:59.900 --> 00:33:03.580]   that Amazon might be a better proxy,
[00:33:03.580 --> 00:33:06.220]   which, you know, trades at three times.
[00:33:06.220 --> 00:33:08.940]   - Certainly for the enterprise side of OpenAI's business,
[00:33:08.940 --> 00:33:11.940]   I think the comp would much more be AWS,
[00:33:11.940 --> 00:33:13.900]   but on the consumer side of their business,
[00:33:13.900 --> 00:33:15.900]   I think the comp is fairer to be somebody
[00:33:15.900 --> 00:33:19.420]   like Google or Meta, but in both instances,
[00:33:19.420 --> 00:33:22.260]   you have to assume that the cost of delivering, right?
[00:33:22.260 --> 00:33:26.500]   Let's be clear, AI and AI inference
[00:33:26.500 --> 00:33:29.900]   is a much, much more compute-intensive activity
[00:33:29.900 --> 00:33:33.900]   than retrieval, which was the business of search, right?
[00:33:33.900 --> 00:33:36.820]   And so, like, we just have to see technology
[00:33:36.820 --> 00:33:38.580]   ultimately drive that cost down,
[00:33:38.580 --> 00:33:39.980]   or there's going to be a higher tax
[00:33:39.980 --> 00:33:41.620]   and it will be a lower margin business.
[00:33:41.620 --> 00:33:43.500]   It doesn't mean that it won't be a great business
[00:33:43.500 --> 00:33:45.860]   or even a good return, but, you know,
[00:33:45.860 --> 00:33:48.540]   to achieve those margins, you got to see the cost of,
[00:33:48.540 --> 00:33:50.780]   you know, delivering the product go down.
[00:33:50.780 --> 00:33:53.380]   - You know, there've been statements along this journey
[00:33:53.380 --> 00:33:56.300]   from both Jensen and Sam Altman
[00:33:56.300 --> 00:33:59.820]   that the input to this thing is compute
[00:33:59.820 --> 00:34:01.980]   and you're going to need tokens.
[00:34:01.980 --> 00:34:05.820]   And those sound like variable cost inputs.
[00:34:05.820 --> 00:34:09.140]   That's, you know, and I guess in the worst case scenario,
[00:34:09.140 --> 00:34:12.980]   it's like an airline where fuel costs are just, you know,
[00:34:12.980 --> 00:34:16.860]   a big part of what drives the incremental profitability.
[00:34:16.860 --> 00:34:19.140]   And so the thing I don't know,
[00:34:19.140 --> 00:34:21.580]   and so I'm not suggesting this is absolutely true,
[00:34:21.580 --> 00:34:26.580]   is, is an AI business inherently a 20% margin business?
[00:34:26.580 --> 00:34:33.700]   You know, AWS is at 30 and Amazon Commerce was at five
[00:34:33.700 --> 00:34:36.820]   until they added, you know, whatever, added advertising,
[00:34:36.820 --> 00:34:39.940]   like, or can it be like Google or Meta?
[00:34:39.940 --> 00:34:43.100]   And I think until one of these things gets public
[00:34:43.100 --> 00:34:47.180]   and we can look at data a little more detail, we don't know.
[00:34:47.180 --> 00:34:49.740]   - Well, it's going to be interesting to watch it unfold,
[00:34:49.740 --> 00:34:52.220]   but, you know, there's certainly a related topic,
[00:34:52.220 --> 00:34:54.900]   one that I know you're amped up about
[00:34:54.900 --> 00:34:57.340]   and is probably even more amped up
[00:34:57.340 --> 00:35:00.420]   given this rumored open AI deal,
[00:35:00.420 --> 00:35:03.460]   is how the venture model is changing
[00:35:03.460 --> 00:35:06.700]   and whether these structural changes are good or bad,
[00:35:06.700 --> 00:35:08.260]   whether they're good or bad for LPs,
[00:35:08.260 --> 00:35:11.220]   whether they're good or bad for GPs and founders.
[00:35:11.220 --> 00:35:14.060]   So why don't you lead us in a discussion on that topic,
[00:35:14.060 --> 00:35:19.660]   you know, on the challenges to venture today?
[00:35:19.660 --> 00:35:22.980]   - Yeah, and two things that I would encourage people
[00:35:22.980 --> 00:35:25.940]   to check out, our friends at All In
[00:35:25.940 --> 00:35:29.180]   talked about this a little bit on their pod last Friday.
[00:35:29.180 --> 00:35:30.900]   And then at their conference,
[00:35:30.900 --> 00:35:34.900]   Thomas Lafon of Co2 had a long presentation
[00:35:34.900 --> 00:35:37.580]   that I think is where everyone worth looking at.
[00:35:37.580 --> 00:35:38.940]   They kind of sets this up,
[00:35:38.940 --> 00:35:43.940]   but despite our massive enthusiasm for AI
[00:35:43.940 --> 00:35:49.100]   and I'd say the entire community's enthusiasm,
[00:35:49.100 --> 00:35:54.100]   you know, we are at a seemingly problematic place
[00:35:54.100 --> 00:35:57.140]   in the venture capital industry
[00:35:57.140 --> 00:36:00.900]   with regard to how much cash is coming out of the system
[00:36:00.900 --> 00:36:02.940]   versus how much is going in.
[00:36:02.940 --> 00:36:06.700]   And everyone seems to be hyper aware
[00:36:06.700 --> 00:36:11.540]   that it's a historically low number of IPOs.
[00:36:11.540 --> 00:36:14.140]   It's like single digits where the average,
[00:36:14.140 --> 00:36:18.540]   even in subpar years has been closer to 70 or 80.
[00:36:18.540 --> 00:36:23.220]   M&A has had quite a hiatus,
[00:36:23.220 --> 00:36:27.780]   partially driven by the restrictions on the Magnificent 7,
[00:36:27.780 --> 00:36:29.900]   although they're finding ways around that.
[00:36:29.900 --> 00:36:32.340]   And so, you know, what's going wrong?
[00:36:32.340 --> 00:36:37.100]   You know, the capital markets seem to be doing just fine
[00:36:37.100 --> 00:36:40.380]   in terms of how well the S&P is performing.
[00:36:40.380 --> 00:36:42.140]   And so why isn't this happening?
[00:36:42.140 --> 00:36:45.460]   And so I would offer a couple of thoughts.
[00:36:45.460 --> 00:36:49.060]   One, I think everyone now believes in power laws,
[00:36:49.060 --> 00:36:51.460]   network effects, scaling laws, that kind of thing.
[00:36:51.460 --> 00:36:53.140]   I think all the investors do.
[00:36:53.140 --> 00:36:55.420]   When I entered the venture industry,
[00:36:55.420 --> 00:36:59.620]   I think it was a competitive advantage to believe in them
[00:36:59.620 --> 00:37:03.220]   when people didn't and you could, you know,
[00:37:03.220 --> 00:37:06.300]   find a way to take advantage of that and make money.
[00:37:06.300 --> 00:37:08.740]   But today I think everyone gets it.
[00:37:08.740 --> 00:37:12.260]   And so the other thing that's happened, I believe,
[00:37:12.260 --> 00:37:16.540]   is many of investors have decided late stage investing
[00:37:16.540 --> 00:37:18.180]   is better than early stage.
[00:37:18.180 --> 00:37:20.740]   And I'm primarily respond, you know,
[00:37:20.740 --> 00:37:23.700]   talking about the venture firms that have gone
[00:37:23.700 --> 00:37:26.140]   from being mostly early stage venture,
[00:37:26.140 --> 00:37:30.500]   traditional venture to having 10 billion or more, you know,
[00:37:30.500 --> 00:37:32.820]   AUM and willing to write checks
[00:37:32.820 --> 00:37:34.660]   in the hundreds of millions of dollars,
[00:37:34.660 --> 00:37:37.580]   which didn't happen a decade ago, right?
[00:37:37.580 --> 00:37:41.020]   And for those type people, you know,
[00:37:41.020 --> 00:37:43.540]   the management fee is on a much bigger, you know,
[00:37:43.540 --> 00:37:46.700]   you get the same percentage on whether you're deploying it
[00:37:46.700 --> 00:37:50.940]   at $5 million a piece or $200 million a piece,
[00:37:50.940 --> 00:37:53.300]   and you get way more dollars deployed.
[00:37:53.300 --> 00:37:55.500]   You don't take board seats, so the work's less.
[00:37:55.500 --> 00:37:58.300]   And the fees are massively bigger.
[00:37:58.300 --> 00:38:02.260]   And I think that for reasons that are just competitive,
[00:38:02.260 --> 00:38:07.020]   our whole world's kind of felt this gravity
[00:38:07.020 --> 00:38:08.900]   pulling them to that place.
[00:38:08.900 --> 00:38:12.860]   And despite the fact that we had this mini correction,
[00:38:12.860 --> 00:38:14.700]   I call it mini 'cause that's what it feels like
[00:38:14.700 --> 00:38:18.460]   now that AI kind of just brought the sunlight out again,
[00:38:18.460 --> 00:38:21.740]   these firms have not had problems raising those dollars.
[00:38:21.740 --> 00:38:25.180]   And so despite the fact that a large number
[00:38:25.180 --> 00:38:27.460]   of the unicorns are still private
[00:38:27.460 --> 00:38:30.100]   from the previous investment cycle,
[00:38:30.100 --> 00:38:32.460]   this kind of behavior continues.
[00:38:32.460 --> 00:38:35.580]   And all of these firms wanna be in the hottest deals.
[00:38:35.580 --> 00:38:36.980]   You know this, you're on this field,
[00:38:36.980 --> 00:38:39.460]   you're a participant in this world.
[00:38:39.460 --> 00:38:41.940]   If there's an interesting company out there,
[00:38:41.940 --> 00:38:45.180]   it's very likely that they're gonna be approached
[00:38:45.180 --> 00:38:48.220]   preemptively and told to take more money.
[00:38:48.220 --> 00:38:51.780]   And so I think you're gonna, until this change,
[00:38:51.780 --> 00:38:53.860]   I think you're gonna have very few companies
[00:38:53.860 --> 00:38:57.020]   that are considered to be doing well
[00:38:57.020 --> 00:38:59.860]   that aren't asked by the industry
[00:38:59.860 --> 00:39:02.580]   to raise $500 million or more.
[00:39:02.580 --> 00:39:07.580]   And that in and of itself is a very unusual,
[00:39:07.580 --> 00:39:12.380]   compared to the traditional venture model from years ago,
[00:39:12.380 --> 00:39:15.860]   it's just super unusual because, I'm almost done,
[00:39:15.860 --> 00:39:19.940]   because this thing is so competitive
[00:39:19.940 --> 00:39:24.060]   and everyone is trying to get in the hottest deals.
[00:39:24.060 --> 00:39:27.260]   The best way to achieve that is to be founder friendly.
[00:39:27.260 --> 00:39:31.660]   And I think we talked about the profile that Thrive had,
[00:39:31.660 --> 00:39:33.100]   I think on the cover of Fortune.
[00:39:33.100 --> 00:39:35.580]   I would encourage people to read that 'cause that's,
[00:39:35.580 --> 00:39:39.500]   it was almost, I would call it almost PR perfection
[00:39:39.500 --> 00:39:43.100]   for Josh and his team in terms of coming,
[00:39:43.100 --> 00:39:47.020]   people vouching for them being founder friendly.
[00:39:47.020 --> 00:39:49.340]   And if you're gonna be founder friendly
[00:39:49.340 --> 00:39:50.900]   and write big checks, guess what?
[00:39:50.900 --> 00:39:53.580]   You're gonna be supportive of founder secondary
[00:39:53.580 --> 00:39:56.300]   and you're gonna be supportive
[00:39:56.300 --> 00:39:58.740]   of broad-based employee secondary.
[00:39:58.740 --> 00:40:03.020]   When you do those things, you are taking away
[00:40:03.020 --> 00:40:07.060]   probably the strongest motivating factor
[00:40:07.060 --> 00:40:08.780]   that pushed people to go public,
[00:40:08.780 --> 00:40:11.860]   that pushed founders and their teams to wanna be public,
[00:40:11.860 --> 00:40:13.260]   which was liquidity.
[00:40:13.260 --> 00:40:15.700]   And so with that off the table, for me,
[00:40:15.700 --> 00:40:18.500]   there's no surprise that IPOs are happening
[00:40:18.500 --> 00:40:20.340]   or not happening or not happening
[00:40:20.340 --> 00:40:24.740]   because there's no incentive for them to go out.
[00:40:24.740 --> 00:40:28.180]   And it's a weird place for me
[00:40:28.180 --> 00:40:30.660]   when I look at the venture industry writ large,
[00:40:30.660 --> 00:40:33.580]   which is what's gonna drive people to go public?
[00:40:33.580 --> 00:40:36.340]   How do large institutions get liquidity?
[00:40:36.340 --> 00:40:39.740]   I don't think large institutions can realistically
[00:40:39.740 --> 00:40:42.140]   get liquidity to the secondary market,
[00:40:42.140 --> 00:40:44.260]   certainly not at a good price.
[00:40:44.260 --> 00:40:48.500]   But my biggest, in addition to all those things,
[00:40:48.500 --> 00:40:53.380]   one thing I would raise provocatively is,
[00:40:53.380 --> 00:40:56.340]   does overfeeding these companies with cash
[00:40:56.340 --> 00:40:58.860]   lead to non-optimal execution?
[00:40:58.860 --> 00:41:03.860]   And you and I were deeply involved in the Uber situation,
[00:41:03.860 --> 00:41:07.660]   but when you start losing a billion dollars a year,
[00:41:07.660 --> 00:41:11.380]   or even I would say $20 million a month,
[00:41:11.380 --> 00:41:15.020]   you're very far away from profitability.
[00:41:15.020 --> 00:41:19.140]   And we talk a lot about focus and constraints
[00:41:19.140 --> 00:41:21.540]   and how that leads to better decision-making.
[00:41:21.540 --> 00:41:24.420]   That's hard to do when you're spending 20 million a month.
[00:41:24.420 --> 00:41:26.740]   And the other thing that's hard to do
[00:41:26.740 --> 00:41:29.820]   is raise $500 million and not spend it.
[00:41:29.820 --> 00:41:33.060]   And so I do propose the question
[00:41:33.060 --> 00:41:37.300]   that maybe one of the things that's a problem
[00:41:37.300 --> 00:41:39.980]   with that previous generation of unicorns
[00:41:39.980 --> 00:41:42.740]   is they were overfed.
[00:41:42.740 --> 00:41:44.660]   There's a picture you can look up
[00:41:44.660 --> 00:41:47.060]   that's kind of disgusting, so people may not want to,
[00:41:47.060 --> 00:41:50.500]   but there's this thing called a gavage tube,
[00:41:50.500 --> 00:41:53.180]   which is what they use to make foie gras.
[00:41:53.180 --> 00:41:55.820]   It's how they force feed the geese
[00:41:55.820 --> 00:41:58.140]   to get 'em just super fat.
[00:41:58.140 --> 00:42:00.620]   And that's the image I have in my mind.
[00:42:00.620 --> 00:42:03.820]   Like, are we overfeeding these startups?
[00:42:03.820 --> 00:42:07.180]   And then they get so far away from profitability,
[00:42:07.180 --> 00:42:09.420]   they're spending on projects
[00:42:09.420 --> 00:42:11.540]   that if they were trying to get to profitability,
[00:42:11.540 --> 00:42:14.060]   they wouldn't spend on that are lower return.
[00:42:14.060 --> 00:42:17.260]   And then maybe they get stuck.
[00:42:17.260 --> 00:42:19.140]   This is my last point.
[00:42:19.140 --> 00:42:21.060]   When I entered the venture business,
[00:42:21.060 --> 00:42:23.500]   one of the things I thought was an advantage I had
[00:42:23.500 --> 00:42:26.860]   coming from Wall Street is I knew what Wall Street wanted.
[00:42:26.860 --> 00:42:30.700]   They were the customer for the venture capital company
[00:42:30.700 --> 00:42:34.100]   that would eventually IPO and trade in their markets.
[00:42:34.100 --> 00:42:37.340]   And there's an interesting dichotomy right now.
[00:42:37.340 --> 00:42:39.900]   If you look at the public markets,
[00:42:39.900 --> 00:42:41.940]   which have become much more sane,
[00:42:41.940 --> 00:42:43.860]   you would know this better than me,
[00:42:43.860 --> 00:42:46.060]   relative to where they were three years ago,
[00:42:46.060 --> 00:42:51.700]   there's a high expectation for profitability.
[00:42:51.700 --> 00:42:55.180]   And so I think there's this incredible mismatch
[00:42:55.180 --> 00:42:58.660]   between what Wall Street wants to see
[00:42:58.660 --> 00:43:03.660]   and the state that a company is forced to be in
[00:43:04.340 --> 00:43:08.180]   as a result of this hyper competitive investment market.
[00:43:08.180 --> 00:43:09.660]   Yeah, no, I mean, listen,
[00:43:09.660 --> 00:43:12.660]   I think that it's a great analysis
[00:43:12.660 --> 00:43:16.260]   and framing really of the issue.
[00:43:16.260 --> 00:43:18.020]   And you bring up a lot of great questions
[00:43:18.020 --> 00:43:19.100]   and I think the right concerns.
[00:43:19.100 --> 00:43:20.260]   So let's try to break them down
[00:43:20.260 --> 00:43:24.420]   because I think they fall into roughly like three buckets.
[00:43:24.420 --> 00:43:25.860]   Let's start first with the question,
[00:43:25.860 --> 00:43:27.540]   just some more dollars, bigger funds,
[00:43:27.540 --> 00:43:30.420]   more competition and higher valuations.
[00:43:30.420 --> 00:43:33.540]   There's no doubt that VC has grown
[00:43:33.540 --> 00:43:35.260]   from 100 billion 10 years ago
[00:43:35.260 --> 00:43:38.420]   to 300 billion over the last 10 years.
[00:43:38.420 --> 00:43:40.780]   If you set aside the COVID period
[00:43:40.780 --> 00:43:43.500]   where we all know because of ZURP,
[00:43:43.500 --> 00:43:45.020]   public markets lost their minds,
[00:43:45.020 --> 00:43:47.980]   venture markets went to high levels,
[00:43:47.980 --> 00:43:50.900]   we're back to kind of this $300 billion level,
[00:43:50.900 --> 00:43:52.460]   which was pre-COVID.
[00:43:52.460 --> 00:43:55.860]   And so while we call all of this venture bill,
[00:43:55.860 --> 00:43:58.580]   one of the big differences I have here,
[00:43:58.580 --> 00:44:00.540]   and I've said many times,
[00:44:00.540 --> 00:44:04.220]   is that the venture market really hasn't grown that much.
[00:44:04.220 --> 00:44:07.780]   Much of the investment that we're counting as venture,
[00:44:07.780 --> 00:44:10.540]   when you look at all these data sources that we pull
[00:44:10.540 --> 00:44:12.460]   is into companies that are higher
[00:44:12.460 --> 00:44:14.700]   than $10 billion in valuation,
[00:44:14.700 --> 00:44:17.540]   with huge revenues that would have been before
[00:44:17.540 --> 00:44:20.020]   captured by public market investors.
[00:44:20.020 --> 00:44:21.940]   And so I think it's important as an industry
[00:44:21.940 --> 00:44:25.820]   that we start thinking about these things as different.
[00:44:25.820 --> 00:44:28.260]   I call them internally and to our LPs,
[00:44:28.260 --> 00:44:30.860]   I call those quasi-public companies,
[00:44:30.860 --> 00:44:34.500]   companies like Databricks, Stripe, OpenAI.
[00:44:34.500 --> 00:44:36.900]   I think it's silly to call them venture at this stage
[00:44:36.900 --> 00:44:40.580]   when they have 5 billion in revenues growing 100% a year.
[00:44:40.580 --> 00:44:43.300]   So yes, I would say this,
[00:44:43.300 --> 00:44:48.300]   the late stage quasi-public market is much more competitive,
[00:44:48.300 --> 00:44:51.700]   just like the public market is more competitive,
[00:44:51.700 --> 00:44:54.580]   because it leads to better price discovery,
[00:44:54.580 --> 00:44:57.820]   but it also means that there's less arbitrage
[00:44:57.820 --> 00:45:01.740]   and returns are more dependent upon long-term compounding
[00:45:01.740 --> 00:45:04.780]   than some misinformation in the market, right?
[00:45:04.780 --> 00:45:06.860]   And as we saw in '20 and '21,
[00:45:06.860 --> 00:45:09.300]   the public market's corrected.
[00:45:09.300 --> 00:45:12.660]   In fact, a lot of the IPOs that happened during that period
[00:45:12.660 --> 00:45:16.100]   are still down over 50%, right?
[00:45:16.100 --> 00:45:20.020]   So the public market's corrected, just did it quicker.
[00:45:20.020 --> 00:45:21.940]   In the quasi-public markets,
[00:45:21.940 --> 00:45:24.660]   we've seen a lot of these companies shut down,
[00:45:24.660 --> 00:45:28.940]   sell, and still down over 50% from the high.
[00:45:28.940 --> 00:45:31.220]   So I don't think there's a lot of difference there.
[00:45:31.220 --> 00:45:34.540]   And when I look at the early stage venture markets, Bill,
[00:45:34.540 --> 00:45:35.820]   I would agree with you,
[00:45:35.820 --> 00:45:37.660]   there's a lot of excitement around AI,
[00:45:37.660 --> 00:45:41.620]   but outside of AI, you look at Series A follow-on rounds
[00:45:41.620 --> 00:45:43.340]   or Series B follow-on rounds,
[00:45:43.340 --> 00:45:45.100]   I mean, they're down dramatically.
[00:45:45.100 --> 00:45:47.380]   If you look at the number of first-time funds
[00:45:47.380 --> 00:45:49.660]   that are getting funded as second-time funds,
[00:45:49.660 --> 00:45:51.460]   those are down dramatically.
[00:45:51.460 --> 00:45:54.820]   So I see a lot of reversion to the mean happening
[00:45:54.820 --> 00:45:56.300]   rather than structural change.
[00:45:56.300 --> 00:45:58.620]   I think the big structural change
[00:45:58.620 --> 00:46:00.980]   that this data leads me to conclude
[00:46:00.980 --> 00:46:04.740]   is that because of the regulatory burdens of going public,
[00:46:04.740 --> 00:46:08.100]   because of the change in Silicon Valley around sentiment,
[00:46:08.100 --> 00:46:10.060]   because of the ability to get liquid
[00:46:10.060 --> 00:46:11.980]   in secondary transactions,
[00:46:11.980 --> 00:46:13.380]   because of the liquidity
[00:46:13.380 --> 00:46:15.580]   of this late-stage quasi-public market
[00:46:15.580 --> 00:46:17.700]   where institutions like Altimeter
[00:46:17.700 --> 00:46:21.780]   or the CO2s of the world or Fidelity's or Thrive's
[00:46:21.780 --> 00:46:25.260]   or whatever that we're here to provide that liquidity,
[00:46:25.260 --> 00:46:28.940]   I agree with you that there's a lot more money there
[00:46:28.940 --> 00:46:31.340]   because those companies are choosing to stay private,
[00:46:31.340 --> 00:46:32.820]   but we should think about these
[00:46:32.820 --> 00:46:36.100]   and compare them to their public company competitors,
[00:46:36.100 --> 00:46:39.420]   not to what's happening in the Series A market.
[00:46:39.420 --> 00:46:40.340]   Two things I would highlight.
[00:46:40.340 --> 00:46:43.940]   One, when you call it quasi-public,
[00:46:43.940 --> 00:46:46.060]   I think you're talking about it
[00:46:46.060 --> 00:46:49.020]   primarily from a input point of view.
[00:46:49.020 --> 00:46:52.300]   In other words, it looks public relative
[00:46:52.300 --> 00:46:54.780]   to how Altimeter would invest
[00:46:54.780 --> 00:46:57.740]   or other late-stage players would invest.
[00:46:57.740 --> 00:47:02.380]   But, and maybe this is where the word quasi comes in,
[00:47:02.380 --> 00:47:05.980]   but if you think about it from an output perspective,
[00:47:05.980 --> 00:47:08.460]   there's no liquidity for anybody.
[00:47:08.460 --> 00:47:11.580]   So you've taken a portion of the market
[00:47:11.580 --> 00:47:15.060]   that used to serve multiple purposes
[00:47:15.060 --> 00:47:17.580]   and now one of those purposes is gone.
[00:47:17.580 --> 00:47:20.780]   If we're saying there's a permanent shift
[00:47:20.780 --> 00:47:21.860]   from one place to the other.
[00:47:21.860 --> 00:47:25.100]   Two, there are these regulatory things that come up
[00:47:25.100 --> 00:47:29.460]   because many people believe that one of the SEC's goal
[00:47:29.460 --> 00:47:32.260]   is to make sure all investors can participate in that.
[00:47:32.260 --> 00:47:33.780]   Now, that's off the table.
[00:47:33.780 --> 00:47:35.220]   I mean, listen, listen.
[00:47:35.220 --> 00:47:37.900]   I've said publicly many, many times,
[00:47:37.900 --> 00:47:40.500]   we should get these companies public faster.
[00:47:40.500 --> 00:47:41.900]   I wanna see Stripe public.
[00:47:41.900 --> 00:47:43.340]   I wanna see Databricks public.
[00:47:43.340 --> 00:47:44.940]   I think it's better for the companies.
[00:47:44.940 --> 00:47:48.540]   I think it's better for the investing public writ large.
[00:47:48.540 --> 00:47:51.460]   I'm just trying to explain the game on the field and-
[00:47:51.460 --> 00:47:52.700]   - I understand.
[00:47:52.700 --> 00:47:53.540]   - Go ahead.
[00:47:53.540 --> 00:47:55.620]   - And that's the third point I was gonna make is
[00:47:55.620 --> 00:47:58.740]   quasi public isn't the same as public
[00:47:58.740 --> 00:48:03.180]   in terms of how the public markets might shape
[00:48:03.180 --> 00:48:06.660]   the motivation and execution of the team.
[00:48:06.660 --> 00:48:07.500]   - 100%.
[00:48:07.500 --> 00:48:10.420]   - We go back to the meta example where they went public,
[00:48:10.420 --> 00:48:12.380]   stock went down, Wall Street says,
[00:48:12.380 --> 00:48:14.060]   "You're not ready for mobile."
[00:48:14.060 --> 00:48:15.260]   You know, and Zuck later said,
[00:48:15.260 --> 00:48:18.180]   "Shit, that actually kicked me into gear."
[00:48:18.180 --> 00:48:21.340]   Those things don't exist when this isn't here.
[00:48:21.340 --> 00:48:22.580]   And I agree with you.
[00:48:22.580 --> 00:48:24.780]   You know, this is playing the game on the field
[00:48:24.780 --> 00:48:26.460]   and I'm not blaming anyone.
[00:48:26.460 --> 00:48:30.020]   I'm just highlighting this is where we've matriculated to.
[00:48:30.020 --> 00:48:31.940]   You know, this is where we stand today.
[00:48:31.940 --> 00:48:32.820]   - I think it's right.
[00:48:32.820 --> 00:48:34.380]   So let's move to the second big point,
[00:48:34.380 --> 00:48:36.100]   which is this liquidity IPOs.
[00:48:36.100 --> 00:48:40.540]   And I think it is true the number of IPOs has been anemic
[00:48:40.540 --> 00:48:42.820]   and the exit amount is now in venture
[00:48:42.820 --> 00:48:45.540]   is now at about $100 billion a year.
[00:48:45.540 --> 00:48:50.300]   While down a ton from the $700 billion peak
[00:48:50.300 --> 00:48:53.100]   in Zerp in 2021, you know,
[00:48:53.100 --> 00:48:54.980]   which was really a one-time COVID high,
[00:48:54.980 --> 00:48:58.020]   we're basically back at the same exit level
[00:48:58.020 --> 00:49:00.780]   for venture that we were pre-COVID.
[00:49:00.780 --> 00:49:03.020]   Lots of people talk about the zombie corns, right?
[00:49:03.020 --> 00:49:06.260]   We have a thousand companies that were unicorns.
[00:49:06.260 --> 00:49:07.860]   A lot of those will never get back there.
[00:49:07.860 --> 00:49:11.180]   I've said 80% of those companies will never get back there.
[00:49:11.180 --> 00:49:13.060]   Those companies need to get, you know,
[00:49:13.060 --> 00:49:15.260]   merged into other companies, need to get sold,
[00:49:15.260 --> 00:49:17.500]   need to get shut down, whatever the case may be,
[00:49:17.500 --> 00:49:20.100]   or do down round IPOs like Instacart did,
[00:49:20.100 --> 00:49:24.420]   which is now off to the races under some great leadership.
[00:49:24.420 --> 00:49:26.540]   But I look at just our pipeline build,
[00:49:26.540 --> 00:49:29.660]   just to give you a counter example here.
[00:49:29.660 --> 00:49:32.020]   I think we may have four IPOs in the pipeline
[00:49:32.020 --> 00:49:33.860]   in the next four to six months.
[00:49:33.860 --> 00:49:36.260]   The rumors out there around companies like Cerebris
[00:49:36.260 --> 00:49:37.660]   and CoreWeave and Databricks,
[00:49:37.660 --> 00:49:39.500]   those are all in our portfolios.
[00:49:39.500 --> 00:49:42.380]   And on top of that, you know, we recently sold Tabular
[00:49:42.380 --> 00:49:44.020]   to Databricks, you know,
[00:49:44.020 --> 00:49:46.340]   that had a price rumored to be $2 billion.
[00:49:46.340 --> 00:49:48.340]   So exits are increasing.
[00:49:48.340 --> 00:49:49.940]   Interest rates are coming down,
[00:49:49.940 --> 00:49:51.740]   which I think will lead to more of that.
[00:49:51.740 --> 00:49:53.460]   The world is healing.
[00:49:53.460 --> 00:49:55.900]   And so again, I'm not so sure this is,
[00:49:55.900 --> 00:49:58.180]   I do think there are some things that are structural.
[00:49:58.180 --> 00:50:00.300]   The regulatory things are structural.
[00:50:00.300 --> 00:50:03.340]   The more dollars in quasi-public is structural,
[00:50:03.340 --> 00:50:05.660]   but there is still enough incentive.
[00:50:05.660 --> 00:50:07.820]   These companies want and have boards
[00:50:07.820 --> 00:50:08.860]   that will get them public.
[00:50:08.860 --> 00:50:12.420]   I just think they may come public a lot longer
[00:50:12.420 --> 00:50:15.060]   when they're at 10 or $50 billion valuations,
[00:50:15.060 --> 00:50:18.500]   rather than they're at a $2 billion valuation.
[00:50:18.500 --> 00:50:20.780]   But, you know, as far as the companies I'm involved with,
[00:50:20.780 --> 00:50:23.260]   I'm pushing for them to come public sooner,
[00:50:23.260 --> 00:50:24.980]   or at least when they're ready.
[00:50:24.980 --> 00:50:28.140]   And I think a lot of that pressure is off.
[00:50:28.140 --> 00:50:31.820]   And I think the number of board members
[00:50:31.820 --> 00:50:34.020]   that are actually willing to push for that,
[00:50:34.020 --> 00:50:35.540]   and Chamath talks about this a lot,
[00:50:35.540 --> 00:50:36.980]   I think is actually few.
[00:50:36.980 --> 00:50:38.780]   You might be one of a few,
[00:50:38.780 --> 00:50:41.500]   but I think most of them don't
[00:50:41.500 --> 00:50:44.860]   because they've been trained to applaud,
[00:50:44.860 --> 00:50:46.820]   and that's what they do.
[00:50:46.820 --> 00:50:47.660]   Well, I mean-
[00:50:47.660 --> 00:50:49.980]   And it's partially just driven by competition.
[00:50:49.980 --> 00:50:51.420]   Once again, I'm not,
[00:50:51.420 --> 00:50:53.500]   I'm trying to give you my best view of-
[00:50:53.500 --> 00:50:55.460]   Yeah, no, I think it's an important,
[00:50:55.460 --> 00:50:57.940]   it's a super important conversation.
[00:50:57.940 --> 00:50:59.540]   And by the way, you talk,
[00:50:59.540 --> 00:51:02.340]   if 80% of the zombie corns are never gonna get out
[00:51:02.340 --> 00:51:04.180]   or are gonna get out at reduced prices,
[00:51:04.180 --> 00:51:06.860]   I'm telling you flat out,
[00:51:06.860 --> 00:51:11.860]   those are being held on the large endowments as LPs
[00:51:11.860 --> 00:51:16.940]   at unrealistically high prices across the board.
[00:51:16.940 --> 00:51:18.220]   I would say yes and no.
[00:51:18.220 --> 00:51:20.860]   So let me just give you a couple of different examples.
[00:51:20.860 --> 00:51:23.060]   I mentioned we have a lot of good things in the portfolio,
[00:51:23.060 --> 00:51:25.300]   but we had a company that wasn't performing
[00:51:25.300 --> 00:51:28.420]   at the levels that it previously had been.
[00:51:28.420 --> 00:51:31.340]   It had been priced at many billions of dollars
[00:51:31.340 --> 00:51:34.180]   at the peak of ZERP in 2021, a company called Lacework.
[00:51:34.180 --> 00:51:35.420]   And we ultimately,
[00:51:35.420 --> 00:51:37.500]   we pushed to sell that company to Fortinet
[00:51:37.500 --> 00:51:39.660]   while we still had hundreds of millions of dollars
[00:51:39.660 --> 00:51:40.740]   of cash on the balance sheet.
[00:51:40.740 --> 00:51:43.740]   It's a great acquisition for that company,
[00:51:43.740 --> 00:51:45.020]   but it's out of the system.
[00:51:45.020 --> 00:51:45.860]   It's marked.
[00:51:45.860 --> 00:51:47.740]   We've distributed the cash to our shareholders.
[00:51:47.740 --> 00:51:49.660]   So we're distributing, okay?
[00:51:49.660 --> 00:51:52.620]   So I'm just saying that this is happening.
[00:51:52.620 --> 00:51:54.900]   And we have other companies in those portfolios
[00:51:54.900 --> 00:51:57.100]   that were marked really high in '21, right?
[00:51:57.100 --> 00:52:01.020]   One is company you and I are both invested in, Clickhouse,
[00:52:01.020 --> 00:52:03.420]   which is growing through those valuations, right?
[00:52:03.420 --> 00:52:05.580]   Or a company like Sigma Computing that we're in,
[00:52:05.580 --> 00:52:07.580]   which is growing through those high valuations.
[00:52:07.580 --> 00:52:09.780]   So you just have to break it down
[00:52:09.780 --> 00:52:11.540]   and look at these one by one.
[00:52:11.540 --> 00:52:14.260]   I think that there are definitely things in there
[00:52:14.260 --> 00:52:16.340]   that are held at too high a valuation,
[00:52:16.340 --> 00:52:18.100]   and LPs should scrutinize that.
[00:52:18.100 --> 00:52:19.460]   But there are other things that are healing.
[00:52:19.460 --> 00:52:21.700]   Let's just, I really want to talk about this question
[00:52:21.700 --> 00:52:24.180]   that I think is the most important one, Bill.
[00:52:24.180 --> 00:52:25.020]   Great.
[00:52:25.020 --> 00:52:28.780]   Which is, does excess capital lead to companies
[00:52:28.780 --> 00:52:32.820]   being overfed, which leads to poorer outcomes
[00:52:32.820 --> 00:52:33.660]   for innovation?
[00:52:33.660 --> 00:52:35.780]   Because I think the potential for that,
[00:52:35.780 --> 00:52:37.540]   like, at the end of the day,
[00:52:37.540 --> 00:52:39.500]   that would be the worst thing, right?
[00:52:39.500 --> 00:52:43.220]   And I think you and I have a lot of shared belief
[00:52:43.220 --> 00:52:47.380]   that too much capital does ruin corporate culture.
[00:52:47.380 --> 00:52:49.260]   It does lead to higher burn rates.
[00:52:49.260 --> 00:52:51.580]   It does lead to lower financial returns.
[00:52:51.580 --> 00:52:54.620]   And it does lead to less innovation, right?
[00:52:54.620 --> 00:52:56.340]   I pounded the table on this topic,
[00:52:56.340 --> 00:52:58.180]   you know, the time to get fit.
[00:52:58.180 --> 00:53:01.300]   And I applaud Mark Zuckerberg.
[00:53:01.300 --> 00:53:05.580]   I mean, him stepping out in February of 2023
[00:53:05.580 --> 00:53:08.380]   and writing a letter called the year of efficiency.
[00:53:08.380 --> 00:53:11.060]   And he said, we started doing this,
[00:53:11.060 --> 00:53:13.780]   just thinking that it was about getting back to the office.
[00:53:13.780 --> 00:53:18.780]   But what we discovered was that smaller is better, right?
[00:53:18.780 --> 00:53:22.540]   He said, flatter is faster and leaner is better.
[00:53:22.540 --> 00:53:25.540]   And what he meant is the cycle time on innovation,
[00:53:25.540 --> 00:53:27.500]   de-layering the organization,
[00:53:27.500 --> 00:53:30.940]   getting rid of layers of VPs, right?
[00:53:30.940 --> 00:53:33.780]   Like really getting the organization tight and fit
[00:53:33.780 --> 00:53:38.780]   was better for the future growth and future profitability
[00:53:38.780 --> 00:53:40.540]   and future innovation of the business.
[00:53:40.540 --> 00:53:43.140]   So I tweeted over the weekend,
[00:53:43.140 --> 00:53:46.140]   it's great news that I saw that Zoom
[00:53:46.140 --> 00:53:47.860]   and Salesforce and Workdays,
[00:53:47.860 --> 00:53:50.700]   they're starting to get sober about stock-based compensation.
[00:53:50.700 --> 00:53:55.220]   That is another component of too much capital,
[00:53:55.220 --> 00:53:58.740]   too many people leads to excessive SBC,
[00:53:58.740 --> 00:54:00.780]   which you and I have talked a lot about.
[00:54:00.780 --> 00:54:03.860]   So I think just because you raise a lot of money
[00:54:03.860 --> 00:54:06.940]   doesn't necessarily mean you're unfit, right?
[00:54:06.940 --> 00:54:11.580]   Remember, OpenAI is not really a VC company at this stage.
[00:54:11.580 --> 00:54:15.140]   Google went public on 2 billion of trailing revenues.
[00:54:15.140 --> 00:54:18.140]   These guys are rumored to have 5 billion already.
[00:54:18.140 --> 00:54:20.500]   So 3X that amount.
[00:54:20.500 --> 00:54:22.860]   And we've talked about building AI
[00:54:22.860 --> 00:54:24.700]   is just a lot more expensive
[00:54:24.700 --> 00:54:26.940]   than building the things that came before it.
[00:54:26.940 --> 00:54:28.900]   So I just think we need to have an apples
[00:54:28.900 --> 00:54:29.980]   for apples comparison.
[00:54:29.980 --> 00:54:32.180]   But if you want a champion to stand with you
[00:54:32.180 --> 00:54:36.420]   on this issue of companies raising too much,
[00:54:36.420 --> 00:54:39.700]   spending too much, they gotta be really careful.
[00:54:39.700 --> 00:54:41.580]   And so I gave some advice
[00:54:41.580 --> 00:54:43.540]   to one of our fellow founders the other day.
[00:54:43.540 --> 00:54:46.340]   He's got money coming in over the bow
[00:54:46.340 --> 00:54:48.420]   at a multi-billion dollar valuation.
[00:54:48.420 --> 00:54:49.980]   And he's like, "We don't need it.
[00:54:49.980 --> 00:54:52.180]   "We already have hundreds of millions on the balance sheet.
[00:54:52.180 --> 00:54:53.580]   "Should we raise it?"
[00:54:53.580 --> 00:54:56.700]   And I said, "Here are all the downsides of raising it.
[00:54:56.700 --> 00:54:58.980]   "You can't go raise another 500 million
[00:54:58.980 --> 00:55:01.300]   "and not have pressure from all your employees
[00:55:01.300 --> 00:55:02.980]   "for employees secondary,
[00:55:02.980 --> 00:55:05.620]   "for spending more money on more projects, et cetera.
[00:55:05.620 --> 00:55:08.980]   "And the NPV on those other activities will be lower.
[00:55:08.980 --> 00:55:12.180]   "And the incentive your employees have to stay with you
[00:55:12.180 --> 00:55:15.260]   "once they sell 10 or $20 million worth of stock
[00:55:15.260 --> 00:55:16.220]   "is gonna be less."
[00:55:16.220 --> 00:55:18.100]   And so finding that balance,
[00:55:18.100 --> 00:55:20.300]   I think is a critical function
[00:55:20.300 --> 00:55:22.660]   of leadership of these companies.
[00:55:22.660 --> 00:55:24.660]   - Yeah, and I would just say to that, Brad,
[00:55:24.660 --> 00:55:27.300]   I do think this is a huge dichotomy.
[00:55:27.300 --> 00:55:32.300]   Like for the, I do believe that the hyper competition
[00:55:32.300 --> 00:55:37.460]   in late stage market leads to incredibly large number
[00:55:37.460 --> 00:55:40.220]   of preemptive rounds where hundreds of million dollars
[00:55:40.220 --> 00:55:42.720]   are being force-fed to a company.
[00:55:42.720 --> 00:55:45.660]   And if you're spending 20 million a month,
[00:55:45.660 --> 00:55:49.360]   you're burning 240 million a year.
[00:55:49.360 --> 00:55:53.420]   If these companies in AI are 50% gross margin or whatever,
[00:55:53.420 --> 00:55:57.060]   that you gotta get revenue to twice that.
[00:55:57.060 --> 00:56:00.340]   You're right at that 500 million run rate
[00:56:00.340 --> 00:56:03.020]   before you could think about being profitable.
[00:56:03.020 --> 00:56:05.820]   And once you've gone to that place,
[00:56:05.820 --> 00:56:09.020]   which is ironically the same number, I think,
[00:56:09.020 --> 00:56:10.300]   where Philippe Lafont said,
[00:56:10.300 --> 00:56:12.560]   "You gotta be to go public these days."
[00:56:12.560 --> 00:56:17.140]   And the thing I would say to you, if that becomes true,
[00:56:17.140 --> 00:56:20.340]   if that kind of path dependency
[00:56:20.340 --> 00:56:25.340]   is cast upon every venture capital company that comes along,
[00:56:26.500 --> 00:56:30.380]   you're gonna end up with an excessive amount of zombie corns
[00:56:30.380 --> 00:56:35.380]   because previous to this evolution
[00:56:35.380 --> 00:56:40.020]   in the late stage markets, plenty of companies,
[00:56:40.020 --> 00:56:41.880]   either were bought at 300 million
[00:56:41.880 --> 00:56:45.540]   or went public at 250 or 500 million
[00:56:45.540 --> 00:56:48.180]   and created positive returns
[00:56:48.180 --> 00:56:51.060]   for their early venture capital investors.
[00:56:51.060 --> 00:56:56.060]   And if it's really 500 million in revenue
[00:56:56.460 --> 00:57:00.620]   or bust, I think there's gonna be a lot more bust
[00:57:00.620 --> 00:57:01.600]   than we've traditionally had.
[00:57:01.600 --> 00:57:05.100]   Yeah, no, net-net, I agree with you.
[00:57:05.100 --> 00:57:06.820]   VC is harder, it's more competitive,
[00:57:06.820 --> 00:57:10.020]   but I think the structural changes that we're seeing
[00:57:10.020 --> 00:57:14.380]   are more reversion to the mean than VC is forever bad.
[00:57:14.380 --> 00:57:15.540]   I think it's, you know, listen,
[00:57:15.540 --> 00:57:18.100]   this has always been a hard investment category.
[00:57:18.100 --> 00:57:20.500]   And I think if you're not backing a VC
[00:57:20.500 --> 00:57:22.640]   who has a right and a process
[00:57:22.640 --> 00:57:25.220]   that gets them into the top decile, right,
[00:57:25.220 --> 00:57:26.940]   then returns are not gonna be great.
[00:57:26.940 --> 00:57:28.060]   It's a power law business,
[00:57:28.060 --> 00:57:29.700]   always been a power law business.
[00:57:29.700 --> 00:57:31.580]   I think these are super important issues,
[00:57:31.580 --> 00:57:33.420]   but why don't we, just in the spirit of time-
[00:57:33.420 --> 00:57:34.540]   Wait, wait, wait, wait.
[00:57:34.540 --> 00:57:35.500]   Oh, here you go, here you go.
[00:57:35.500 --> 00:57:37.100]   I have to have one response.
[00:57:37.100 --> 00:57:41.580]   I would encourage our listener base to look up,
[00:57:41.580 --> 00:57:43.420]   there's a piece of research
[00:57:43.420 --> 00:57:46.060]   that's called the observer effect.
[00:57:46.060 --> 00:57:50.740]   And it started in physics, but it's used more broadly.
[00:57:50.740 --> 00:57:53.340]   And the observer effect is the idea
[00:57:53.340 --> 00:57:57.260]   that observing a phenomena or situation changes it.
[00:57:57.260 --> 00:58:00.140]   And that's really the point I'm making here
[00:58:00.140 --> 00:58:02.500]   is that I think prior to now,
[00:58:02.500 --> 00:58:05.580]   the investor and how they behave
[00:58:05.580 --> 00:58:10.340]   didn't actually impact the situation on the field
[00:58:10.340 --> 00:58:15.340]   in terms of like changing the game and how it's played.
[00:58:15.340 --> 00:58:20.580]   And to me, the way the competition that's evolved
[00:58:20.580 --> 00:58:23.780]   in the venture industry is actually perturbing
[00:58:23.780 --> 00:58:25.700]   and affecting the situation.
[00:58:25.700 --> 00:58:27.060]   So anyway, I'll leave it at that.
[00:58:27.060 --> 00:58:29.340]   No, I think it's another way of saying that
[00:58:29.340 --> 00:58:31.980]   is negative reflexivity, right?
[00:58:31.980 --> 00:58:33.540]   That when dollars come in,
[00:58:33.540 --> 00:58:35.500]   it actually leads to poor behavior.
[00:58:35.500 --> 00:58:37.860]   We'll take a deeper dive on that sometime
[00:58:37.860 --> 00:58:39.740]   because I also wanna get your thoughts
[00:58:39.740 --> 00:58:41.340]   on how that might change.
[00:58:41.340 --> 00:58:43.660]   But why don't we finish just in the spirit of time
[00:58:43.660 --> 00:58:46.940]   with a quick tech check like we always do?
[00:58:46.940 --> 00:58:47.780]   Awesome.
[00:58:47.780 --> 00:58:49.220]   So the big, big event,
[00:58:49.220 --> 00:58:51.620]   and this macro world is more you than me,
[00:58:51.620 --> 00:58:55.060]   but the big event obviously was the Fed decision
[00:58:55.060 --> 00:58:57.740]   to lower by 50 basis points.
[00:58:57.740 --> 00:58:59.620]   What's the impact from your point of view?
[00:58:59.620 --> 00:59:03.340]   Yeah, I mean, you and I talked a bunch about this
[00:59:03.340 --> 00:59:05.740]   along with our friends at All In.
[00:59:05.740 --> 00:59:08.020]   I mean, Goolsby had signaled this, right?
[00:59:08.020 --> 00:59:13.020]   That really we were in historically restrictive territory.
[00:59:13.020 --> 00:59:14.580]   And what that means is basically
[00:59:14.580 --> 00:59:16.660]   we just have a little bit of the emergency break
[00:59:16.660 --> 00:59:17.820]   in the economy.
[00:59:17.820 --> 00:59:20.340]   And so once they were convinced
[00:59:20.340 --> 00:59:22.300]   that inflation was gonna have a two-handle,
[00:59:22.300 --> 00:59:23.740]   which it now has,
[00:59:23.740 --> 00:59:27.220]   and that they were starting to see some slowdown
[00:59:27.220 --> 00:59:28.420]   in the jobs market,
[00:59:28.420 --> 00:59:32.380]   what we did is we wanna take a jumpstart
[00:59:32.380 --> 00:59:34.500]   to reducing the restrictiveness of the economy.
[00:59:34.500 --> 00:59:36.500]   I thought that was a smart thing to do.
[00:59:36.500 --> 00:59:38.500]   I think it's just getting back on side.
[00:59:38.500 --> 00:59:40.820]   I don't think they were seeing anything other
[00:59:40.820 --> 00:59:43.340]   than what we're seeing in the economy.
[00:59:43.340 --> 00:59:46.020]   But it's incredibly significant to the markets
[00:59:46.020 --> 00:59:47.460]   that we're now on our way down.
[00:59:47.460 --> 00:59:50.020]   Remember, we had two plus years
[00:59:50.020 --> 00:59:53.420]   of historically steep rise in interest rates
[00:59:53.420 --> 00:59:55.780]   coming out of COVID.
[00:59:55.780 --> 00:59:57.420]   And so this gives predictability
[00:59:57.420 --> 00:59:59.780]   as companies enter their budget cycles this year, right?
[00:59:59.780 --> 01:00:01.620]   Every company right now is thinking,
[01:00:01.620 --> 01:00:04.540]   what can I invest into AI infrastructure next year?
[01:00:04.540 --> 01:00:06.940]   And so knowing that interest rates are not going up
[01:00:06.940 --> 01:00:10.220]   is a super, super important input
[01:00:10.220 --> 01:00:13.820]   into those pieces of analysis.
[01:00:13.820 --> 01:00:14.820]   But the debate remains.
[01:00:14.820 --> 01:00:15.940]   I mean, I think it's interesting.
[01:00:15.940 --> 01:00:19.020]   You had Jamie Dimon and Gunlach come out and say,
[01:00:19.020 --> 01:00:21.260]   "Hey, this battle with inflation is not over,
[01:00:21.260 --> 01:00:23.340]   deglobalization, all these other things."
[01:00:23.340 --> 01:00:24.380]   So they're suggesting
[01:00:24.380 --> 01:00:26.900]   that you could actually see inflation kick back up.
[01:00:26.900 --> 01:00:28.700]   That would be a negative surprise.
[01:00:28.700 --> 01:00:29.620]   And others are saying
[01:00:29.620 --> 01:00:31.300]   that the Fed's already behind the curve
[01:00:31.300 --> 01:00:33.580]   and needs to go faster
[01:00:33.580 --> 01:00:35.340]   with respect to the slowing economy.
[01:00:35.340 --> 01:00:36.180]   So-
[01:00:36.180 --> 01:00:37.260]   - Where do you come out on that?
[01:00:37.260 --> 01:00:39.060]   - That's the debate that's in the market.
[01:00:39.060 --> 01:00:42.300]   Well, I'll just tell you where we are today.
[01:00:42.300 --> 01:00:44.780]   We talked about taking a bunch of units of risk off,
[01:00:44.780 --> 01:00:47.900]   which we did in June and July.
[01:00:47.900 --> 01:00:49.940]   And as we were heading into these rate cuts,
[01:00:49.940 --> 01:00:53.060]   we're back at average levels of exposure today.
[01:00:53.060 --> 01:00:54.620]   And that's because we saw a lot
[01:00:54.620 --> 01:00:56.540]   of really positive statements coming out
[01:00:56.540 --> 01:00:58.180]   of the earnings this summer.
[01:00:58.180 --> 01:01:01.460]   And the economic data continued to be constructed.
[01:01:01.460 --> 01:01:03.620]   We expected a 50 basis point rate cut,
[01:01:03.620 --> 01:01:05.140]   which I had been sharing with you
[01:01:05.140 --> 01:01:07.860]   and folks on this pod for some time.
[01:01:07.860 --> 01:01:10.340]   And so we think that's a good setup heading into the fall.
[01:01:10.340 --> 01:01:13.060]   Now we have an election we got to work our way through
[01:01:13.060 --> 01:01:14.980]   and we got a lot of other question marks,
[01:01:14.980 --> 01:01:18.380]   but you got to take those data points as you get them.
[01:01:18.380 --> 01:01:20.060]   - Your team is listening
[01:01:20.060 --> 01:01:22.620]   to so many different earnings calls and whatnot.
[01:01:22.620 --> 01:01:26.260]   What's your take on the consumer
[01:01:26.260 --> 01:01:30.500]   and that side of the demand equation,
[01:01:30.500 --> 01:01:34.780]   like irrespective of inflation,
[01:01:34.780 --> 01:01:36.420]   is there a mini recession
[01:01:36.420 --> 01:01:39.420]   or have we literally landed the soft landing
[01:01:39.420 --> 01:01:40.620]   or do we not know yet?
[01:01:40.620 --> 01:01:42.020]   - Listen, I think behind the scenes
[01:01:42.020 --> 01:01:44.580]   we've been going through many recessions
[01:01:44.580 --> 01:01:45.940]   in a bunch of different industries.
[01:01:45.940 --> 01:01:48.740]   Like for example, housing went through a mini recession.
[01:01:48.740 --> 01:01:52.060]   I think things like home renovation
[01:01:52.060 --> 01:01:54.020]   went through a mini recession.
[01:01:54.020 --> 01:01:56.940]   The entire supply chain about that happened.
[01:01:56.940 --> 01:01:58.700]   The S&P we talked about,
[01:01:58.700 --> 01:02:00.700]   the S&P has continued to outperform,
[01:02:00.700 --> 01:02:03.540]   but if you take out the 10 best performers from the S&P
[01:02:03.540 --> 01:02:04.740]   up until a couple of weeks ago,
[01:02:04.740 --> 01:02:06.780]   it was actually down on the year.
[01:02:06.780 --> 01:02:10.300]   So this has been a period of haves and have nots.
[01:02:10.300 --> 01:02:13.740]   I think the economy writ large is pretty stable,
[01:02:13.740 --> 01:02:16.100]   but let's just look at multiples here for a second,
[01:02:16.100 --> 01:02:18.020]   because I think for tech investors
[01:02:18.020 --> 01:02:19.500]   it's really what it comes down to.
[01:02:19.500 --> 01:02:21.940]   So this first chart just shows you
[01:02:21.940 --> 01:02:25.180]   that multiples for these big tech companies
[01:02:25.180 --> 01:02:26.340]   have come up quite a bit,
[01:02:26.340 --> 01:02:29.100]   certainly off of the January 23 lows.
[01:02:29.100 --> 01:02:31.660]   We were trading about 21 times, right?
[01:02:31.660 --> 01:02:34.540]   This is forward PE for these companies.
[01:02:34.540 --> 01:02:35.460]   - For the mag seven,
[01:02:35.460 --> 01:02:37.540]   you're showing forward PE for the mag seven.
[01:02:37.540 --> 01:02:38.980]   - Forward PE for the mag seven.
[01:02:38.980 --> 01:02:41.820]   So if you look at the 10-year average of this,
[01:02:41.820 --> 01:02:43.900]   it's about 25 times.
[01:02:43.900 --> 01:02:46.180]   In January 23, when we're all talking about
[01:02:46.180 --> 01:02:47.820]   Mike Wilson's hard landing,
[01:02:47.820 --> 01:02:50.540]   the economy's gonna crash, like all this stuff,
[01:02:50.540 --> 01:02:53.060]   people have post-traumatic stress from 2022,
[01:02:53.060 --> 01:02:54.860]   we got as low as 21 times.
[01:02:54.860 --> 01:02:59.540]   So now we've run up to 31 times on the forward PE.
[01:02:59.540 --> 01:03:01.020]   So on that dimension,
[01:03:01.020 --> 01:03:03.500]   you would say that looks pretty darn expensive.
[01:03:03.500 --> 01:03:05.100]   But if you go to the next chart, Bill,
[01:03:05.100 --> 01:03:06.660]   which I think is an important one,
[01:03:06.660 --> 01:03:10.860]   which is this is the PE ratio divided by growth, right?
[01:03:10.860 --> 01:03:14.260]   So this is the expected growth rate of these companies.
[01:03:14.260 --> 01:03:16.900]   You can see one of the reasons people are excited
[01:03:16.900 --> 01:03:18.500]   is because they expect a lot of growth.
[01:03:18.500 --> 01:03:22.540]   So on that dimension, it's below the 10-year average.
[01:03:22.540 --> 01:03:25.860]   And so what's my conclusion based on that?
[01:03:25.860 --> 01:03:29.420]   You know, that it looks cheap if you expect,
[01:03:29.420 --> 01:03:31.100]   if you believe in those growth rates,
[01:03:31.100 --> 01:03:34.340]   but if those growth rates don't show up for Microsoft,
[01:03:34.340 --> 01:03:37.060]   for Amazon, for Google, et cetera, next year,
[01:03:37.060 --> 01:03:39.540]   then you can expect that these companies are gonna,
[01:03:39.540 --> 01:03:42.620]   their stocks are gonna go sideways to down, right?
[01:03:42.620 --> 01:03:46.300]   Because the valuations are much more full.
[01:03:46.300 --> 01:03:49.900]   And so I think that that's really the debate, you know, now.
[01:03:49.900 --> 01:03:52.300]   And I think it's a stock picker's market from here.
[01:03:52.300 --> 01:03:54.220]   We have average levels of exposure.
[01:03:54.220 --> 01:03:55.780]   I think, for example,
[01:03:55.780 --> 01:03:59.220]   we think the entire NVIDIA
[01:03:59.220 --> 01:04:01.140]   and AI infrastructure supply chain
[01:04:01.140 --> 01:04:04.020]   is gonna continue to be undersupplied.
[01:04:04.020 --> 01:04:06.820]   So NVIDIA has come off from 140 to 115.
[01:04:06.820 --> 01:04:08.180]   There's a lot of debate in the world.
[01:04:08.180 --> 01:04:09.900]   A lot of people think, you know,
[01:04:09.900 --> 01:04:12.380]   that they're not gonna hit the numbers.
[01:04:12.380 --> 01:04:14.500]   You know, we're kind of at, you know,
[01:04:14.500 --> 01:04:16.500]   6 million GPUs for next year.
[01:04:16.500 --> 01:04:19.340]   The bearish people are at like 4 1/2 million.
[01:04:19.340 --> 01:04:21.460]   Like the numbers will ultimately tell.
[01:04:21.460 --> 01:04:24.020]   If they do 6 million next year, the stock's going higher.
[01:04:24.020 --> 01:04:26.940]   If they do 4 1/2 million, the stock's going lower.
[01:04:26.940 --> 01:04:29.460]   That's the way this business works, right?
[01:04:29.460 --> 01:04:32.580]   And so we're just out there trying to collect all our data.
[01:04:32.580 --> 01:04:35.020]   In fact, Clark's over in Taipei right now,
[01:04:35.020 --> 01:04:36.940]   talking, you know, meeting with the supply chain,
[01:04:36.940 --> 01:04:38.500]   understanding what's really going on.
[01:04:38.500 --> 01:04:41.300]   And I think, you know, in January '23,
[01:04:41.300 --> 01:04:42.940]   you had a huge margin of safety.
[01:04:42.940 --> 01:04:45.180]   All you had to believe is that the world wasn't ending
[01:04:45.180 --> 01:04:47.260]   and that we're in the start of a new super cycle
[01:04:47.260 --> 01:04:49.420]   and you push chips onto the table, right?
[01:04:49.420 --> 01:04:52.860]   If you understood that, you had pocket kings or pocket aces.
[01:04:52.860 --> 01:04:54.820]   As we sit here today,
[01:04:54.820 --> 01:04:58.300]   the world is much more bowled up, right?
[01:04:58.300 --> 01:05:01.420]   So, you know, even if you have a differentiated point of view,
[01:05:01.420 --> 01:05:04.140]   it's more like sitting on pocket nines,
[01:05:04.140 --> 01:05:05.660]   you know, not like pocket kings.
[01:05:05.660 --> 01:05:08.660]   I think you got to take a more measured view of the market
[01:05:08.660 --> 01:05:11.780]   and think about this distribution of probabilities.
[01:05:11.780 --> 01:05:14.300]   There's certainly we could see the economy slow.
[01:05:14.300 --> 01:05:16.340]   Certainly we could see Blackwell
[01:05:16.340 --> 01:05:17.940]   doesn't get his production levels up.
[01:05:17.940 --> 01:05:19.540]   That would be, you know, a challenge
[01:05:19.540 --> 01:05:21.140]   for the entire ecosystem.
[01:05:21.140 --> 01:05:23.500]   So it's an exciting time.
[01:05:23.500 --> 01:05:25.820]   I don't think there are any no-brainers in the market,
[01:05:25.820 --> 01:05:27.700]   but I can also see how, you know,
[01:05:27.700 --> 01:05:30.260]   when I look at the tailwinds behind tech right now,
[01:05:30.260 --> 01:05:32.660]   both in the private and the public markets,
[01:05:32.660 --> 01:05:35.220]   I couldn't be more excited about the next five years.
[01:05:35.220 --> 01:05:37.540]   It'll be volatile as they always are,
[01:05:37.540 --> 01:05:38.940]   but there's no doubt there are going to be
[01:05:38.940 --> 01:05:42.620]   some big winners produced, you know, in this cycle.
[01:05:42.620 --> 01:05:43.860]   Let's wrap it there.
[01:05:43.860 --> 01:05:44.900]   It's good to see you.
[01:05:44.900 --> 01:05:45.740]   Let's do it.
[01:05:45.740 --> 01:05:46.580]   It's good to see you too.
[01:05:46.580 --> 01:05:47.420]   Look forward to seeing you next time.
[01:05:47.420 --> 01:05:48.700]   No, I'm going to be down in Austin soon.
[01:05:48.700 --> 01:05:50.620]   Let's get a poker game going.
[01:05:50.620 --> 01:05:51.700]   All right, man.
[01:05:51.700 --> 01:05:52.540]   Take care.
[01:05:52.540 --> 01:05:55.140]   (upbeat music)
[01:05:55.140 --> 01:05:57.740]   (upbeat music)
[01:05:57.740 --> 01:06:03.580]   As a reminder to everybody,
[01:06:03.580 --> 01:06:05.820]   just our opinions, not investment advice.

