
[00:00:00.000 --> 00:00:02.760]   The following is a conversation with Roger Penrose,
[00:00:02.760 --> 00:00:05.320]   physicist, mathematician, and philosopher
[00:00:05.320 --> 00:00:07.040]   at University of Oxford.
[00:00:07.040 --> 00:00:10.840]   He has made fundamental contributions in many disciplines
[00:00:10.840 --> 00:00:13.320]   from the mathematical physics of general relativity
[00:00:13.320 --> 00:00:15.800]   and cosmology to the limitations
[00:00:15.800 --> 00:00:18.680]   of a computational view of consciousness.
[00:00:18.680 --> 00:00:20.840]   In his book, "The Emperor's New Mind,"
[00:00:20.840 --> 00:00:22.840]   Roger writes that, quote,
[00:00:22.840 --> 00:00:26.080]   "Children are not afraid to pose basic questions
[00:00:26.080 --> 00:00:29.900]   "that may embarrass us as adults to ask."
[00:00:29.900 --> 00:00:32.000]   In many ways, my goal with this podcast
[00:00:32.000 --> 00:00:33.680]   is to embrace the inner child
[00:00:33.680 --> 00:00:36.520]   that is not constrained by how one should behave,
[00:00:36.520 --> 00:00:40.120]   speak, and think in the adult world.
[00:00:40.120 --> 00:00:44.760]   Roger is one of the most important minds of our time,
[00:00:44.760 --> 00:00:48.300]   so it's truly a pleasure and an honor to talk with him.
[00:00:48.300 --> 00:00:50.600]   This conversation was recorded
[00:00:50.600 --> 00:00:52.920]   before the outbreak of the pandemic.
[00:00:52.920 --> 00:00:55.800]   For everyone feeling the medical, psychological,
[00:00:55.800 --> 00:00:57.740]   and financial burden of the crisis,
[00:00:57.740 --> 00:00:59.760]   I'm sending love your way.
[00:00:59.760 --> 00:01:00.840]   Stay strong.
[00:01:00.840 --> 00:01:02.080]   We're in this together.
[00:01:02.080 --> 00:01:03.180]   We'll beat this thing.
[00:01:03.180 --> 00:01:06.660]   This is the Artificial Intelligence Podcast.
[00:01:06.660 --> 00:01:08.840]   If you enjoy it, subscribe on YouTube,
[00:01:08.840 --> 00:01:11.200]   review it with the five stars on Apple Podcast,
[00:01:11.200 --> 00:01:12.600]   support it on Patreon,
[00:01:12.600 --> 00:01:16.040]   or simply connect with me on Twitter @LexFriedman,
[00:01:16.040 --> 00:01:18.760]   spelled F-R-I-D-M-A-N.
[00:01:18.760 --> 00:01:21.180]   As usual, I'll do a few minutes of ads now
[00:01:21.180 --> 00:01:22.360]   and never any ads in the middle
[00:01:22.360 --> 00:01:24.580]   that can break the flow of the conversation.
[00:01:24.580 --> 00:01:25.720]   I hope that works for you
[00:01:25.720 --> 00:01:27.880]   and doesn't hurt the listening experience.
[00:01:27.880 --> 00:01:29.360]   Quick summary of the ads.
[00:01:29.360 --> 00:01:33.400]   To sponsors, ExpressVPN and Cash App.
[00:01:33.400 --> 00:01:35.520]   Please consider supporting the podcast
[00:01:35.520 --> 00:01:40.520]   by getting ExpressVPN at expressvpn.com/lexpod
[00:01:40.520 --> 00:01:45.920]   and downloading Cash App and using code LEXPODCAST.
[00:01:45.920 --> 00:01:48.280]   This show is presented by Cash App,
[00:01:48.280 --> 00:01:50.440]   the number one finance app in the App Store.
[00:01:50.440 --> 00:01:53.520]   When you get it, use code LEXPODCAST.
[00:01:53.520 --> 00:01:55.660]   Cash App lets you send money to friends,
[00:01:55.660 --> 00:01:58.000]   buy Bitcoin, and invest in the stock market
[00:01:58.000 --> 00:01:59.920]   with as little as $1.
[00:01:59.920 --> 00:02:02.200]   Since Cash App does fractional share trading,
[00:02:02.200 --> 00:02:05.080]   let me mention that the order execution algorithm
[00:02:05.080 --> 00:02:06.780]   that works behind the scenes
[00:02:06.780 --> 00:02:09.440]   to create the abstraction of the fractional orders
[00:02:09.440 --> 00:02:11.240]   is an algorithmic marvel.
[00:02:11.240 --> 00:02:13.720]   So big props to the Cash App engineers
[00:02:13.720 --> 00:02:16.460]   for solving a hard problem that in the end
[00:02:16.460 --> 00:02:19.520]   provides an easy interface that takes a step up
[00:02:19.520 --> 00:02:22.980]   to the next layer of abstraction over the stock market,
[00:02:22.980 --> 00:02:25.460]   making trading more accessible for new investors
[00:02:25.460 --> 00:02:28.480]   and diversification much easier.
[00:02:28.480 --> 00:02:30.880]   So again, if you get Cash App from the App Store
[00:02:30.880 --> 00:02:34.360]   or Google Play and use the code LEXPODCAST,
[00:02:34.360 --> 00:02:38.520]   you get $10 and Cash App will also donate $10 to FIRST,
[00:02:38.520 --> 00:02:41.160]   an organization that is helping to advance robotics
[00:02:41.160 --> 00:02:44.260]   and STEM education for young people around the world.
[00:02:44.260 --> 00:02:47.720]   This show is sponsored by ExpressVPN.
[00:02:47.720 --> 00:02:52.560]   Get it at expressvpn.com/lexpod
[00:02:52.560 --> 00:02:55.620]   to get a discount and to support this podcast.
[00:02:55.620 --> 00:02:58.300]   I've been using ExpressVPN for many years.
[00:02:58.300 --> 00:02:59.300]   I love it.
[00:02:59.300 --> 00:03:00.780]   It's easy to use.
[00:03:00.780 --> 00:03:04.900]   Press the big power on button and your privacy is protected.
[00:03:04.900 --> 00:03:08.340]   And if you like, you can make it look like your location
[00:03:08.340 --> 00:03:10.100]   is anywhere else in the world.
[00:03:10.100 --> 00:03:13.020]   I might be in Boston now, but I can make it look
[00:03:13.020 --> 00:03:17.720]   like I'm in New York, London, Paris, or anywhere else.
[00:03:17.720 --> 00:03:20.380]   This has a large number of obvious benefits.
[00:03:20.380 --> 00:03:23.280]   Certainly, it allows you to access international versions
[00:03:23.280 --> 00:03:26.120]   of streaming websites like the Japanese Netflix
[00:03:26.120 --> 00:03:28.120]   or the UK Hulu.
[00:03:28.120 --> 00:03:31.640]   ExpressVPN works on any device you can imagine.
[00:03:31.640 --> 00:03:36.320]   I use it on Linux, shout out to Ubuntu, Windows, Android,
[00:03:36.320 --> 00:03:38.640]   but it's available everywhere else too.
[00:03:38.640 --> 00:03:43.380]   Once again, get it at expressvpn.com/lexpod
[00:03:43.380 --> 00:03:46.440]   to get a discount and to support this podcast.
[00:03:46.440 --> 00:03:50.660]   And now, here's my conversation with Roger Penrose.
[00:03:50.660 --> 00:03:54.240]   You mentioned in conversation with Eric Weinstein
[00:03:54.240 --> 00:03:57.620]   on the Portal podcast that 2001 Space Odyssey
[00:03:57.620 --> 00:03:58.980]   is your favorite movie.
[00:03:58.980 --> 00:04:02.100]   Which aspect, if you could mention,
[00:04:02.100 --> 00:04:05.100]   of its representation of artificial intelligence,
[00:04:05.100 --> 00:04:07.740]   science, engineering connected with you?
[00:04:07.740 --> 00:04:11.460]   - There are all sorts of scenes there which are so amazing.
[00:04:11.460 --> 00:04:14.820]   And how they, science was so well done.
[00:04:14.820 --> 00:04:16.900]   I mean, people say, oh no, Interstellar,
[00:04:16.900 --> 00:04:21.700]   it's this amazing movie which is the most scientific movie.
[00:04:21.700 --> 00:04:23.780]   I thought it's not a patch on 2001.
[00:04:23.780 --> 00:04:29.260]   I mean, 2001, they really went into all sorts of details.
[00:04:29.260 --> 00:04:33.200]   And they're getting the free fall well done and everything.
[00:04:33.200 --> 00:04:35.940]   I thought it was extremely well done.
[00:04:35.940 --> 00:04:38.900]   - So just the details were mesmerizing in terms of--
[00:04:38.900 --> 00:04:43.180]   - And also things like the scene where at the beginning
[00:04:43.180 --> 00:04:45.700]   they have these sort of human ancestors
[00:04:45.700 --> 00:04:49.540]   which are sort of apes becoming humans.
[00:04:49.540 --> 00:04:50.820]   - The monolith.
[00:04:50.820 --> 00:04:53.880]   - Yes, and well, it's the one where he throws the bone
[00:04:53.880 --> 00:04:56.300]   up into the air and then it becomes this,
[00:04:56.300 --> 00:05:00.140]   I mean, that's an amazing sequence there.
[00:05:00.140 --> 00:05:01.860]   - What do you make of the monolith?
[00:05:01.860 --> 00:05:06.140]   Does it have any scientific or philosophical meaning to you,
[00:05:06.140 --> 00:05:08.220]   this kind of thing that sparks innovation?
[00:05:08.220 --> 00:05:10.160]   - Not really. (laughs)
[00:05:10.160 --> 00:05:12.260]   That comes from Arthur C. Clarke.
[00:05:12.260 --> 00:05:14.260]   I was always a great fan of Arthur C. Clarke.
[00:05:14.260 --> 00:05:16.020]   - So it's just a nice plot device.
[00:05:16.020 --> 00:05:18.140]   - Yeah, oh, that plot is excellent, yes.
[00:05:18.140 --> 00:05:22.020]   - So Hal 9000 decides to get rid of the astronauts
[00:05:22.020 --> 00:05:26.900]   because he, it, she, believes that they will interfere
[00:05:26.900 --> 00:05:27.740]   with the mission.
[00:05:27.740 --> 00:05:28.560]   - That's right.
[00:05:28.560 --> 00:05:30.360]   No, well, there you are, it's this view.
[00:05:30.360 --> 00:05:31.580]   I don't know whether I disagree with it,
[00:05:31.580 --> 00:05:34.340]   'cause in a certain sense it was telling you it's wrong.
[00:05:34.340 --> 00:05:39.460]   See, the machine seemed to think it was superior
[00:05:39.460 --> 00:05:44.260]   to the human, and so it was entitled
[00:05:44.260 --> 00:05:47.380]   to get rid of the human beings and run the show itself.
[00:05:47.380 --> 00:05:49.460]   - Well, do you think Hal did the right thing?
[00:05:49.460 --> 00:05:52.020]   Do you think Hal's flawed, evil?
[00:05:52.020 --> 00:05:55.340]   Or if we think about systems like Hal,
[00:05:55.340 --> 00:05:58.020]   would we want Hal to do the same thing in the future?
[00:05:58.020 --> 00:05:58.940]   What was the flaw there?
[00:05:58.940 --> 00:06:02.260]   - Well, you're basically touching on questions, you see.
[00:06:02.260 --> 00:06:06.400]   Is one supposed to believe that Hal was actually conscious?
[00:06:07.660 --> 00:06:10.180]   I mean, it was played rather that way,
[00:06:10.180 --> 00:06:13.540]   as though Hal was a conscious being.
[00:06:13.540 --> 00:06:18.540]   - Because Hal showed some pain, some,
[00:06:18.540 --> 00:06:23.780]   Hal appeared to be cognizant of what it means to die.
[00:06:23.780 --> 00:06:26.060]   - Yes, yes. - And therefore had that.
[00:06:26.060 --> 00:06:27.180]   - That's true, yes.
[00:06:27.180 --> 00:06:28.260]   - An inkling of consciousness.
[00:06:28.260 --> 00:06:31.220]   - Yeah, I mean, I'm not sure that aspect of it
[00:06:31.220 --> 00:06:34.060]   was made completely clear, whether Hal was really
[00:06:34.060 --> 00:06:37.160]   just a very sophisticated computer,
[00:06:37.160 --> 00:06:39.340]   which really didn't actually have these feelings
[00:06:39.340 --> 00:06:42.220]   and somehow, but you're right,
[00:06:42.220 --> 00:06:44.700]   it didn't like the idea of being turned off.
[00:06:44.700 --> 00:06:48.820]   - How does it change things if Hal was or wasn't conscious?
[00:06:48.820 --> 00:06:53.140]   - Well, it might say that it would be wrong to turn it off
[00:06:53.140 --> 00:06:55.220]   if it was actually conscious.
[00:06:55.220 --> 00:06:57.380]   I mean, these questions arise if you think,
[00:06:57.380 --> 00:07:02.780]   I mean, AI, one of the ideas,
[00:07:02.780 --> 00:07:05.300]   it's sort of a mixture in a sense, you say.
[00:07:05.300 --> 00:07:08.160]   If it's trying to do everything a human can do
[00:07:08.160 --> 00:07:11.520]   and if you take the view that consciousness
[00:07:11.520 --> 00:07:13.400]   is something which would come along
[00:07:13.400 --> 00:07:16.200]   when the computer is sufficiently complicated,
[00:07:16.200 --> 00:07:19.280]   sufficiently whatever criterion you use
[00:07:19.280 --> 00:07:23.680]   to characterize its consciousness
[00:07:23.680 --> 00:07:28.640]   in terms of some computational criterion.
[00:07:28.640 --> 00:07:33.600]   - So how does consciousness change our evaluation
[00:07:33.600 --> 00:07:35.820]   of the decision that Hal made?
[00:07:35.820 --> 00:07:36.780]   - Well, I guess I was trying to say
[00:07:36.780 --> 00:07:38.940]   that people are a bit confused about this
[00:07:38.940 --> 00:07:42.100]   because if they say these machines will become conscious,
[00:07:42.100 --> 00:07:45.300]   but just simply because it's a degree of computation
[00:07:45.300 --> 00:07:48.260]   and when you get beyond that certain degree of computation,
[00:07:48.260 --> 00:07:49.420]   it will become conscious,
[00:07:49.420 --> 00:07:52.340]   then of course you have all these problems.
[00:07:52.340 --> 00:07:54.020]   I mean, you might say, well, one of the reasons
[00:07:54.020 --> 00:07:56.500]   you're doing AI is because you understand
[00:07:56.500 --> 00:07:59.040]   a device out to some distant planet
[00:07:59.040 --> 00:08:01.140]   and you don't want to send a human out there
[00:08:01.140 --> 00:08:02.780]   'cause then you'd have to bring it back again
[00:08:02.780 --> 00:08:05.860]   and that costs you far more than just sending it there
[00:08:05.860 --> 00:08:07.060]   and leaving it there.
[00:08:07.060 --> 00:08:10.020]   But if this device is actually a conscious entity,
[00:08:10.020 --> 00:08:13.060]   then you have to face up to the fact that that's immoral.
[00:08:13.060 --> 00:08:17.780]   And so the mere fact that you're making some AI device
[00:08:17.780 --> 00:08:24.060]   and thinking that removes your responsibility to it
[00:08:24.060 --> 00:08:25.820]   would be incorrect.
[00:08:25.820 --> 00:08:29.700]   And so this is a sound flaw in that kind of viewpoint.
[00:08:29.700 --> 00:08:34.200]   I'm not sure how people who take it very seriously,
[00:08:34.200 --> 00:08:37.700]   I mean, I had this curious conversation with,
[00:08:37.700 --> 00:08:40.780]   I'm going to forget names, I'm afraid,
[00:08:40.780 --> 00:08:43.860]   because this is what happens to me at the wrong moment,
[00:08:43.860 --> 00:08:45.820]   Hofstadter, Douglas Hofstadter.
[00:08:45.820 --> 00:08:46.660]   - Douglas Hofstadter, yeah.
[00:08:46.660 --> 00:08:48.860]   - And he'd written this book.
[00:08:48.860 --> 00:08:49.700]   - God Aleshapak.
[00:08:49.700 --> 00:08:50.520]   - God Aleshapak, which I liked,
[00:08:50.520 --> 00:08:52.300]   I thought it was a fantastic book.
[00:08:52.300 --> 00:08:55.700]   But I didn't agree with his conclusion
[00:08:55.700 --> 00:08:58.580]   from Godel's theorem, I think he got it wrong, you see.
[00:08:58.580 --> 00:09:01.220]   Well, I'll just tell you my story, you see,
[00:09:01.220 --> 00:09:02.700]   'cause I'd never met him.
[00:09:02.700 --> 00:09:04.700]   And then I knew I was going to meet him,
[00:09:04.700 --> 00:09:06.860]   the occasion I realized he was coming in,
[00:09:06.860 --> 00:09:09.140]   he wanted to talk to me, and I said, "That's fine."
[00:09:09.140 --> 00:09:10.340]   And I thought in my mind,
[00:09:10.340 --> 00:09:12.580]   "Well, I'm going to paint him into a corner," you see,
[00:09:12.580 --> 00:09:15.760]   'cause I'll use his arguments to convince him
[00:09:15.760 --> 00:09:19.180]   that certain numbers are conscious.
[00:09:19.180 --> 00:09:21.140]   You know, some integers, large enough integers
[00:09:21.140 --> 00:09:22.620]   are actually conscious.
[00:09:22.620 --> 00:09:25.380]   And this was going to be my reductio ad absurdum.
[00:09:25.380 --> 00:09:26.900]   And so I started having this argument with him,
[00:09:26.900 --> 00:09:28.700]   and he simply leapt into the corner.
[00:09:28.700 --> 00:09:31.060]   He didn't even need to be painted into it.
[00:09:31.060 --> 00:09:33.900]   He took the view that certain numbers were conscious.
[00:09:33.900 --> 00:09:35.820]   I thought that was a reductio ad absurdum,
[00:09:35.820 --> 00:09:37.180]   but he seemed to think it was
[00:09:37.180 --> 00:09:38.900]   a perfectly reasonable point of view.
[00:09:38.900 --> 00:09:40.660]   - Without the absurdum there.
[00:09:40.660 --> 00:09:41.580]   - Yes.
[00:09:41.580 --> 00:09:44.620]   - Interesting, but the thing you mentioned about Hal
[00:09:44.620 --> 00:09:46.980]   is the intuition that a lot of the people,
[00:09:46.980 --> 00:09:48.920]   at least in the artificial intelligence world,
[00:09:48.920 --> 00:09:51.540]   had and have, I think.
[00:09:51.540 --> 00:09:52.740]   They don't make it explicit,
[00:09:52.740 --> 00:09:56.860]   but that if you increase the power of computation,
[00:09:56.860 --> 00:09:58.980]   naturally consciousness will emerge.
[00:09:58.980 --> 00:10:00.340]   - Yes, I think that's what they think.
[00:10:00.340 --> 00:10:01.860]   But basically that's 'cause they can't think
[00:10:01.860 --> 00:10:02.780]   of anything else.
[00:10:02.780 --> 00:10:03.600]   - Well, that's right.
[00:10:03.600 --> 00:10:05.340]   - And so it's a reasonable thing.
[00:10:05.340 --> 00:10:06.580]   I mean, you think, "What does the brain do?"
[00:10:06.580 --> 00:10:09.180]   Well, it does do a lot of computation.
[00:10:09.180 --> 00:10:11.540]   I think most of what you actually call computation
[00:10:11.540 --> 00:10:13.300]   is done by the cerebellum.
[00:10:13.300 --> 00:10:15.680]   I mean, this is one of the things
[00:10:15.680 --> 00:10:17.900]   that people don't much mention.
[00:10:17.900 --> 00:10:19.820]   I mean, I come to this subject from the outside,
[00:10:19.820 --> 00:10:21.940]   and certain things strike me,
[00:10:21.940 --> 00:10:24.760]   which you hardly ever hear mentioned.
[00:10:24.760 --> 00:10:28.460]   I mean, you hear mentioned about the left-right business,
[00:10:28.460 --> 00:10:30.360]   the move your right arm,
[00:10:30.360 --> 00:10:33.100]   that's the left side of the brain, and so on,
[00:10:33.100 --> 00:10:34.980]   and all that sort of stuff.
[00:10:34.980 --> 00:10:36.820]   And it's more than that.
[00:10:36.820 --> 00:10:40.500]   If you have these plots of different parts of the brain,
[00:10:40.500 --> 00:10:41.340]   there are two of these,
[00:10:41.340 --> 00:10:43.360]   these things called the homunculi,
[00:10:43.360 --> 00:10:47.540]   which you see these pictures of a distorted human figure
[00:10:47.540 --> 00:10:51.500]   and showing different parts of the brain
[00:10:51.500 --> 00:10:53.180]   controlling different parts of the body.
[00:10:53.180 --> 00:10:55.940]   And it's not simply things like,
[00:10:55.940 --> 00:10:58.080]   okay, the right hand is controlled
[00:10:58.080 --> 00:11:03.080]   and both sensory and motor on the left side,
[00:11:03.080 --> 00:11:04.880]   left hand on the right side.
[00:11:04.880 --> 00:11:06.000]   It's more than that.
[00:11:06.000 --> 00:11:08.660]   Vision is at the back, basically.
[00:11:08.660 --> 00:11:10.180]   Your feet at the top.
[00:11:10.180 --> 00:11:13.100]   And it's as though it's about the worst organization
[00:11:13.100 --> 00:11:13.940]   you could imagine.
[00:11:13.940 --> 00:11:14.880]   - Right, yeah.
[00:11:14.880 --> 00:11:17.580]   - So it can't just be a mistake in nature.
[00:11:17.580 --> 00:11:19.520]   There's something going on there.
[00:11:19.520 --> 00:11:22.700]   And this is made more pronounced
[00:11:22.700 --> 00:11:24.340]   when you think of the cerebellum.
[00:11:24.340 --> 00:11:27.600]   The cerebellum has,
[00:11:27.600 --> 00:11:29.400]   when I was first thinking about these things,
[00:11:29.400 --> 00:11:32.060]   I was told that it had half as many neurons
[00:11:32.060 --> 00:11:33.980]   or something like that, comparable.
[00:11:33.980 --> 00:11:36.540]   And now they tell me it's got far more neurons
[00:11:36.540 --> 00:11:38.260]   than the cerebrum.
[00:11:38.260 --> 00:11:41.000]   The cerebrum is this sort of convoluted thing at the top
[00:11:41.000 --> 00:11:42.060]   people always talk about.
[00:11:42.060 --> 00:11:43.540]   Cerebellum is this thing
[00:11:43.540 --> 00:11:45.420]   just looks a bit like a ball of wool
[00:11:45.420 --> 00:11:47.140]   right at the back underneath.
[00:11:47.140 --> 00:11:47.980]   - Yeah.
[00:11:47.980 --> 00:11:49.500]   - It's got more neurons.
[00:11:49.500 --> 00:11:51.660]   It's got more connections.
[00:11:51.660 --> 00:11:55.140]   Computationally, it's got much more going on
[00:11:55.140 --> 00:11:57.140]   than the cerebrum.
[00:11:57.140 --> 00:12:01.420]   But as far as we know, although it's slightly controversial,
[00:12:01.420 --> 00:12:04.860]   the cerebellum is entirely unconscious.
[00:12:04.860 --> 00:12:07.340]   So the actions, you have a pianist
[00:12:07.340 --> 00:12:09.060]   who plays an incredible piece of music
[00:12:09.060 --> 00:12:10.900]   and you think of,
[00:12:10.900 --> 00:12:13.580]   and he moves his little finger into this little key
[00:12:13.580 --> 00:12:15.940]   to get it hit it just the right moment.
[00:12:15.940 --> 00:12:20.800]   Does he or she consciously will that movement?
[00:12:20.800 --> 00:12:21.640]   No.
[00:12:21.640 --> 00:12:24.700]   Okay, the consciousness is coming in.
[00:12:24.700 --> 00:12:26.100]   It's probably to do with the feeling
[00:12:26.100 --> 00:12:28.820]   of the piece of music that's being performed
[00:12:28.820 --> 00:12:31.260]   and that sort of thing, which is going on.
[00:12:31.260 --> 00:12:34.140]   But the details of what's going on are controlled.
[00:12:34.140 --> 00:12:37.560]   I would think almost entirely by the cerebellum.
[00:12:37.560 --> 00:12:40.380]   That's where you have this precision
[00:12:40.380 --> 00:12:44.060]   and the really detailed.
[00:12:44.060 --> 00:12:47.260]   Once you get, I mean, you think of a tennis player
[00:12:47.260 --> 00:12:50.260]   or something, does that tennis player think exactly how to,
[00:12:50.260 --> 00:12:52.640]   which muscles should be moved in what direction?
[00:12:52.640 --> 00:12:54.380]   And so, no, of course not.
[00:12:54.380 --> 00:12:56.240]   But he or she will maybe think,
[00:12:56.240 --> 00:12:59.340]   well, if the ball is angled in such a way in that corner,
[00:12:59.340 --> 00:13:02.020]   that will be tricky for the opponent.
[00:13:02.020 --> 00:13:07.020]   And the details of that are all done largely
[00:13:07.020 --> 00:13:08.740]   with the cerebellum.
[00:13:08.740 --> 00:13:13.060]   That's where all the precise motions, but it's unconscious.
[00:13:13.060 --> 00:13:14.420]   - So why is it interesting to you
[00:13:14.420 --> 00:13:17.940]   that so much computation is done in the cerebellum
[00:13:17.940 --> 00:13:19.340]   and yet it is unconscious?
[00:13:19.340 --> 00:13:24.340]   - Because it's the view that somehow it's computation,
[00:13:24.340 --> 00:13:27.340]   which is producing the consciousness.
[00:13:27.340 --> 00:13:30.740]   And here you have an incredible amount
[00:13:30.740 --> 00:13:32.100]   of computation going on.
[00:13:32.100 --> 00:13:35.820]   And as far as we know, it's completely unconscious.
[00:13:35.820 --> 00:13:39.460]   So why, what's the difference?
[00:13:39.460 --> 00:13:41.860]   And I think it's an important thing.
[00:13:41.860 --> 00:13:42.960]   What's the difference?
[00:13:42.960 --> 00:13:47.620]   Why is the cerebrum, all this very peculiar stuff
[00:13:47.620 --> 00:13:51.300]   that very hard to see on a computational perspective,
[00:13:51.300 --> 00:13:53.980]   like having everything have to cross over
[00:13:53.980 --> 00:13:55.620]   onto the other side and do something
[00:13:55.620 --> 00:13:57.380]   which looks completely inefficient.
[00:13:57.380 --> 00:14:01.540]   And you've got funny things like the frontal lobe
[00:14:01.540 --> 00:14:04.680]   and the, what do we call the lobes?
[00:14:04.680 --> 00:14:06.640]   And the place where they come together,
[00:14:06.640 --> 00:14:12.340]   you have the different parts, the control,
[00:14:12.340 --> 00:14:13.740]   you see one to do with motor
[00:14:13.740 --> 00:14:15.380]   and the other to do with sensory.
[00:14:16.360 --> 00:14:17.920]   And they're sort of opposite each other
[00:14:17.920 --> 00:14:19.460]   rather than being connected by,
[00:14:19.460 --> 00:14:23.480]   it's not as though you've got electrical circuits.
[00:14:23.480 --> 00:14:25.380]   There's something else going on there.
[00:14:25.380 --> 00:14:30.280]   So it's just the idea that it's like a complicated computer
[00:14:30.280 --> 00:14:34.600]   just seems to me to be completely missing the point.
[00:14:34.600 --> 00:14:37.400]   There must be a lot of computation going on,
[00:14:37.400 --> 00:14:40.320]   but the cerebellum seems to be much better at doing that
[00:14:40.320 --> 00:14:41.520]   than the cerebrum is.
[00:14:41.520 --> 00:14:45.460]   - So for sure, I think what explains it,
[00:14:45.460 --> 00:14:49.720]   it's like half hope and half we don't know what's going on
[00:14:49.720 --> 00:14:52.440]   and therefore from the computer science perspective,
[00:14:52.440 --> 00:14:56.360]   you hope that a Turing machine can be perfectly,
[00:14:56.360 --> 00:14:58.040]   can achieve general intelligence.
[00:14:58.040 --> 00:15:02.240]   - Well, you have this wonderful thing about Turing
[00:15:02.240 --> 00:15:07.240]   and Godel and Kirch and Currie and various people,
[00:15:07.240 --> 00:15:11.680]   particularly Turing and I guess Post was the other one.
[00:15:11.680 --> 00:15:14.360]   These people who developed the idea
[00:15:14.360 --> 00:15:15.900]   of what a computation is.
[00:15:15.900 --> 00:15:19.880]   And there were different ideas of what a computer,
[00:15:19.880 --> 00:15:20.720]   developed differently.
[00:15:20.720 --> 00:15:21.840]   I mean, Church's way of doing it
[00:15:21.840 --> 00:15:24.620]   was very different from Turing's,
[00:15:24.620 --> 00:15:26.800]   but then they were shown to be equivalent.
[00:15:26.800 --> 00:15:30.840]   And so the view emerged that what we mean by computation
[00:15:30.840 --> 00:15:33.860]   is a very clear concept.
[00:15:33.860 --> 00:15:37.860]   And one of the wonderful things that Turing did
[00:15:37.860 --> 00:15:40.180]   was to show that you could have
[00:15:40.180 --> 00:15:43.240]   what we call the universal Turing machine.
[00:15:43.240 --> 00:15:46.320]   It's you just have to have a certain finite device.
[00:15:46.320 --> 00:15:48.600]   Okay, it has to have an unlimited storage space,
[00:15:48.600 --> 00:15:50.180]   which is accessible to it.
[00:15:50.180 --> 00:15:51.960]   But the actual computation, if you like,
[00:15:51.960 --> 00:15:55.980]   is performed by this one universal device.
[00:15:55.980 --> 00:15:57.720]   And so the view comes away,
[00:15:57.720 --> 00:16:01.320]   well, you have this universal Turing machine
[00:16:01.320 --> 00:16:03.840]   and maybe the brain is something like that,
[00:16:03.840 --> 00:16:05.160]   a universal Turing machine.
[00:16:05.160 --> 00:16:08.600]   And it's got maybe not unlimited storage,
[00:16:08.600 --> 00:16:12.680]   but a huge storage accessible to it.
[00:16:12.680 --> 00:16:14.400]   And this model is one,
[00:16:14.400 --> 00:16:17.400]   which is what's used in ordinary computation.
[00:16:17.400 --> 00:16:19.280]   It's a very powerful model.
[00:16:19.280 --> 00:16:24.280]   And the universalness of computation is very useful.
[00:16:24.280 --> 00:16:26.160]   You could have some problem
[00:16:26.160 --> 00:16:27.560]   and you may not see immediately
[00:16:27.560 --> 00:16:29.120]   how to put it onto a computer,
[00:16:29.120 --> 00:16:32.200]   but if it is something of that nature,
[00:16:32.200 --> 00:16:36.200]   then there are all sorts of sub-programs
[00:16:36.200 --> 00:16:37.600]   and sub-routines when all the,
[00:16:37.600 --> 00:16:39.000]   I mean, I learned a little bit of computing
[00:16:39.000 --> 00:16:42.560]   when I was a student, but not very much.
[00:16:42.560 --> 00:16:45.080]   But it was enough to get the general ideas.
[00:16:45.080 --> 00:16:46.480]   - And there's something really pleasant
[00:16:46.480 --> 00:16:49.240]   about a formal system like that,
[00:16:49.240 --> 00:16:51.440]   where you can start discussing about what's provable,
[00:16:51.440 --> 00:16:52.760]   what's not, these kinds of things.
[00:16:52.760 --> 00:16:55.320]   - And you've got a notion, which is an absolute notion,
[00:16:55.320 --> 00:16:56.800]   this notion of computability.
[00:16:56.800 --> 00:17:00.240]   And you can address when things are,
[00:17:00.240 --> 00:17:02.800]   mathematical problems are computably solvable
[00:17:02.800 --> 00:17:04.120]   and which aren't.
[00:17:04.120 --> 00:17:06.720]   And it's a very beautiful area of mathematics
[00:17:06.720 --> 00:17:09.680]   and it's a very powerful area of mathematics.
[00:17:09.680 --> 00:17:13.600]   And it underlies the whole sort of,
[00:17:13.600 --> 00:17:15.440]   what would one say,
[00:17:15.440 --> 00:17:19.680]   the principles of computing machines that we have today.
[00:17:19.680 --> 00:17:22.800]   - Could you say what is Gato's incompleteness theorem
[00:17:22.800 --> 00:17:24.880]   and how does it, maybe also say,
[00:17:24.880 --> 00:17:26.500]   is it heartbreaking to you?
[00:17:26.500 --> 00:17:31.080]   And how does it interfere with this notion of computation
[00:17:31.080 --> 00:17:32.680]   and consciousness?
[00:17:32.680 --> 00:17:33.520]   - Sure.
[00:17:33.520 --> 00:17:35.400]   Well, the ideas, basically,
[00:17:35.400 --> 00:17:39.120]   ideas which I formulated in my first year
[00:17:39.120 --> 00:17:41.560]   as a graduate student in Cambridge.
[00:17:41.560 --> 00:17:44.680]   I did my undergraduate work in mathematics in London
[00:17:44.680 --> 00:17:47.460]   and I had a colleague, Ian Percival.
[00:17:47.460 --> 00:17:49.760]   We used to discuss things like computational
[00:17:49.760 --> 00:17:52.280]   and logical systems quite a lot.
[00:17:52.280 --> 00:17:53.680]   I'd heard about Godel's theorem.
[00:17:53.680 --> 00:17:55.880]   I was a bit worried by the idea that it seemed to say
[00:17:55.880 --> 00:17:59.640]   there were things in mathematics that you could never prove.
[00:17:59.640 --> 00:18:03.140]   And so when I went to Cambridge as a graduate student,
[00:18:03.140 --> 00:18:06.040]   I went to various courses.
[00:18:06.040 --> 00:18:08.540]   You see, I was doing pure mathematics.
[00:18:08.540 --> 00:18:11.960]   I was doing algebraic geometry of a sort,
[00:18:11.960 --> 00:18:15.280]   little bit different from what my supervisor and people,
[00:18:15.280 --> 00:18:17.480]   but it was algebraic geometry.
[00:18:17.480 --> 00:18:20.240]   And I was interested,
[00:18:20.240 --> 00:18:24.840]   I got particularly interested in three lecture courses
[00:18:24.840 --> 00:18:27.000]   that were nothing to do with what I was supposed
[00:18:27.000 --> 00:18:28.200]   to be doing.
[00:18:28.200 --> 00:18:30.520]   One was a course by Herman Bondi
[00:18:30.520 --> 00:18:33.440]   on Einstein's general theory of relativity,
[00:18:33.440 --> 00:18:34.600]   which was a beautiful course.
[00:18:34.600 --> 00:18:37.480]   He was an amazing lecturer,
[00:18:37.480 --> 00:18:40.240]   brought these things alive, absolutely.
[00:18:40.240 --> 00:18:43.340]   Another was a course on quantum mechanics
[00:18:43.340 --> 00:18:46.500]   given by the great physicist, Paul Dirac.
[00:18:46.500 --> 00:18:50.540]   Very beautiful course in a completely different way.
[00:18:50.540 --> 00:18:52.420]   It was very kind of organized
[00:18:52.420 --> 00:18:56.380]   and never got excited about anything seemingly.
[00:18:56.380 --> 00:19:00.620]   But it was extremely well put together
[00:19:00.620 --> 00:19:03.300]   and I found that amazing too.
[00:19:03.300 --> 00:19:04.740]   Third course that was nothing to do
[00:19:04.740 --> 00:19:05.860]   with what I should be doing
[00:19:05.860 --> 00:19:08.100]   was a course on mathematical logic.
[00:19:08.100 --> 00:19:10.020]   I got excited, as I say,
[00:19:10.020 --> 00:19:12.860]   my discussions with Ian Percival.
[00:19:12.860 --> 00:19:15.980]   - Was the incompleteness theorem already deeply
[00:19:15.980 --> 00:19:18.740]   within mathematical logic space?
[00:19:18.740 --> 00:19:20.220]   Were you introduced to it?
[00:19:20.220 --> 00:19:23.880]   - I was introduced to it in detail by the course by Steen.
[00:19:23.880 --> 00:19:27.820]   And he, it was two things he described
[00:19:27.820 --> 00:19:31.040]   which were very fundamental to my understanding.
[00:19:31.040 --> 00:19:33.540]   One was Turing machines
[00:19:33.540 --> 00:19:35.820]   and the whole idea of computability and all that.
[00:19:35.820 --> 00:19:38.260]   So that was all very much part of the course.
[00:19:38.260 --> 00:19:41.420]   The other one was the Godel theorem.
[00:19:41.420 --> 00:19:43.500]   And it wasn't what I was afraid it was
[00:19:43.500 --> 00:19:45.180]   to tell you there were things in mathematics
[00:19:45.180 --> 00:19:46.180]   you couldn't prove.
[00:19:46.180 --> 00:19:49.940]   It was basically,
[00:19:49.940 --> 00:19:53.100]   and he phrased it in a way which often people didn't.
[00:19:53.100 --> 00:19:54.860]   And if you read Douglas Hofstadter's book,
[00:19:54.860 --> 00:19:56.420]   he doesn't, you see.
[00:19:56.420 --> 00:19:58.220]   But Steen made it very clear.
[00:19:58.220 --> 00:20:01.140]   And also in a sort of public lecture
[00:20:01.140 --> 00:20:02.900]   that he gave to a mathematical,
[00:20:02.900 --> 00:20:04.340]   I think it may be the Adams Society,
[00:20:04.340 --> 00:20:07.180]   one of the mathematical undergraduate societies.
[00:20:07.180 --> 00:20:09.500]   And he made this point again very clearly.
[00:20:09.500 --> 00:20:11.820]   That if you've got a formal system of proof,
[00:20:11.820 --> 00:20:15.180]   so suppose what you mean by proof
[00:20:15.180 --> 00:20:19.180]   is something which you could check with a computer.
[00:20:19.180 --> 00:20:21.260]   So to say whether you've got it right or not,
[00:20:21.260 --> 00:20:22.380]   you've got a lot of steps.
[00:20:22.380 --> 00:20:25.980]   Have you carried this computational procedure?
[00:20:25.980 --> 00:20:30.560]   Well, following the proof, steps of the proof correctly,
[00:20:30.560 --> 00:20:33.900]   that can be checked by an algorithm,
[00:20:33.900 --> 00:20:35.460]   by a computer.
[00:20:35.460 --> 00:20:38.820]   So that's the key thing.
[00:20:38.820 --> 00:20:40.740]   Now what you have to,
[00:20:40.740 --> 00:20:44.440]   now you see, is this any good?
[00:20:44.440 --> 00:20:47.300]   If you've got an algorithmic system
[00:20:47.300 --> 00:20:49.980]   which claims to say, yes, this is right,
[00:20:49.980 --> 00:20:52.660]   this you've proved it correctly, this is true.
[00:20:52.660 --> 00:20:54.860]   If you've proved it, if you made a mistake,
[00:20:54.860 --> 00:20:56.020]   it doesn't say it's true or false,
[00:20:56.020 --> 00:20:57.980]   but if you've done it right,
[00:20:57.980 --> 00:21:02.020]   then the conclusion you've come to is correct.
[00:21:02.020 --> 00:21:03.900]   Now you say, why do you believe it's correct?
[00:21:03.900 --> 00:21:05.460]   Because you've looked at the rules and you said,
[00:21:05.460 --> 00:21:06.780]   well, okay, that one's all right,
[00:21:06.780 --> 00:21:07.620]   yeah, that one's all right.
[00:21:07.620 --> 00:21:08.700]   What about, oh, I'm not sure.
[00:21:08.700 --> 00:21:10.100]   Yeah, I see, I see why it's all right.
[00:21:10.100 --> 00:21:12.020]   Okay, you go through all the rules.
[00:21:12.020 --> 00:21:13.840]   You say, yes, following those rules,
[00:21:13.840 --> 00:21:16.940]   if it says, yes, it's true, it is true.
[00:21:16.940 --> 00:21:19.940]   So you've got to make sure that these rules
[00:21:19.940 --> 00:21:21.980]   are ones that you trust.
[00:21:21.980 --> 00:21:25.020]   If you follow the rules and it says it's a proof,
[00:21:25.020 --> 00:21:27.620]   is the result actually true?
[00:21:27.620 --> 00:21:29.680]   And that your belief that it's true
[00:21:29.680 --> 00:21:31.780]   depends upon looking at the rules
[00:21:31.780 --> 00:21:33.120]   and understanding them.
[00:21:33.120 --> 00:21:38.500]   Now, what GÃ¶del shows, that if you have such a system,
[00:21:38.500 --> 00:21:41.420]   then you can construct a statement
[00:21:41.420 --> 00:21:43.820]   of the very kind that it's supposed to look at,
[00:21:43.820 --> 00:21:45.700]   a mathematical statement,
[00:21:45.700 --> 00:21:48.960]   and you can see by the way it's constructed
[00:21:48.960 --> 00:21:52.480]   and what it means that it's true,
[00:21:52.480 --> 00:21:57.940]   but not provable by the rules that you've been given.
[00:21:57.940 --> 00:22:00.900]   And it depends on your trust in the rules.
[00:22:00.900 --> 00:22:03.260]   Do you believe that the rules only give you truths?
[00:22:03.260 --> 00:22:05.200]   If you believe the rules only give you truths,
[00:22:05.200 --> 00:22:08.540]   then you believe this other statement is also true.
[00:22:08.540 --> 00:22:10.820]   I found this absolutely mind-blowing.
[00:22:10.820 --> 00:22:13.620]   When I saw this, it blew my mind.
[00:22:13.620 --> 00:22:17.900]   I thought, my God, you can see that this statement is true.
[00:22:17.900 --> 00:22:19.820]   It's as good as any proof
[00:22:19.820 --> 00:22:22.660]   because it only depends on your belief
[00:22:22.660 --> 00:22:25.140]   in the reliability of the proof procedure,
[00:22:25.140 --> 00:22:26.540]   that's all it is,
[00:22:26.540 --> 00:22:30.100]   and understanding that the coding is done correctly,
[00:22:30.100 --> 00:22:32.920]   and it enables you to transcend that system.
[00:22:32.920 --> 00:22:36.260]   So whatever system you have,
[00:22:36.260 --> 00:22:39.020]   as long as you can understand what it's doing
[00:22:39.020 --> 00:22:41.980]   and why you believe it only gives you truths,
[00:22:41.980 --> 00:22:43.780]   then you can see beyond that system.
[00:22:43.780 --> 00:22:46.220]   Now, how do you see beyond it?
[00:22:46.220 --> 00:22:51.220]   What is it that enables you to transcend that system?
[00:22:51.220 --> 00:22:53.260]   Well, it's your understanding
[00:22:53.260 --> 00:22:55.740]   of what the system is actually saying
[00:22:55.740 --> 00:22:57.640]   and what the statement that you've constructed
[00:22:57.640 --> 00:22:59.460]   is actually saying.
[00:22:59.460 --> 00:23:03.140]   So it's this quality of understanding, whatever it is,
[00:23:03.140 --> 00:23:05.540]   which is not governed by rules.
[00:23:05.540 --> 00:23:07.420]   It's not a computational procedure.
[00:23:07.420 --> 00:23:08.820]   - So this idea of understanding
[00:23:08.820 --> 00:23:10.700]   is not going to be within the rules
[00:23:10.700 --> 00:23:13.420]   of the formal system.
[00:23:13.420 --> 00:23:15.940]   - Yes, you're only using those rules anyway
[00:23:15.940 --> 00:23:18.340]   because you have understood them to be rules
[00:23:18.340 --> 00:23:20.260]   which only give you truths.
[00:23:20.260 --> 00:23:22.260]   There'd be no point in it otherwise.
[00:23:22.260 --> 00:23:23.700]   I mean, people say, well, okay,
[00:23:23.700 --> 00:23:28.060]   this is one set of rules as good as any other.
[00:23:28.060 --> 00:23:28.900]   Well, it's not true.
[00:23:28.900 --> 00:23:31.620]   You have to understand what the rules mean.
[00:23:31.620 --> 00:23:33.580]   And why does that understanding of the mean
[00:23:33.580 --> 00:23:36.340]   give you something beyond the rules themselves?
[00:23:36.340 --> 00:23:37.380]   And that's what it was.
[00:23:37.380 --> 00:23:38.660]   That's what blew my mind.
[00:23:38.660 --> 00:23:43.660]   It's somehow understanding why the rules give you truths
[00:23:43.660 --> 00:23:45.940]   enables you to transcend the rules.
[00:23:45.940 --> 00:23:48.100]   - So that's where, I mean, even at that time,
[00:23:48.100 --> 00:23:50.940]   that's already where the thought entered your mind
[00:23:50.940 --> 00:23:54.000]   that the idea of understanding,
[00:23:54.000 --> 00:23:56.820]   or we can start calling it things like intelligence
[00:23:56.820 --> 00:23:59.700]   or even consciousness, is outside the rules.
[00:23:59.700 --> 00:24:02.940]   - Yes, see, I've always concentrated on understanding.
[00:24:02.940 --> 00:24:04.380]   You know, people say, people,
[00:24:04.380 --> 00:24:05.340]   somebody's pointing out things.
[00:24:05.340 --> 00:24:07.180]   Well, we know about creativity.
[00:24:07.180 --> 00:24:09.140]   That's something a machine can't do, is create.
[00:24:09.140 --> 00:24:09.960]   Well, I don't know.
[00:24:09.960 --> 00:24:11.280]   What is creativity?
[00:24:11.280 --> 00:24:12.120]   And I don't know.
[00:24:12.120 --> 00:24:13.880]   I mean, you know, somebody can put some funny things
[00:24:13.880 --> 00:24:15.660]   on a piece of paper and say that's creative,
[00:24:15.660 --> 00:24:16.940]   and you could make a machine do that.
[00:24:16.940 --> 00:24:18.140]   Is it really creative?
[00:24:18.140 --> 00:24:18.980]   I don't know.
[00:24:18.980 --> 00:24:20.580]   You see, I worry about that one.
[00:24:20.580 --> 00:24:22.900]   I sort of agree with it in a sense,
[00:24:22.900 --> 00:24:25.500]   but it's so hard to do anything with that statement.
[00:24:25.500 --> 00:24:27.780]   But understanding, yes, you can.
[00:24:27.780 --> 00:24:32.620]   You can make, go see that understanding, whatever it is,
[00:24:32.620 --> 00:24:34.340]   and it's very hard to put your finger on it.
[00:24:34.340 --> 00:24:35.780]   That's absolutely true.
[00:24:35.780 --> 00:24:39.660]   - Can you try to define or maybe dance around
[00:24:39.660 --> 00:24:42.020]   a definition of understanding?
[00:24:42.020 --> 00:24:44.140]   - To some degree, but I don't,
[00:24:44.140 --> 00:24:46.000]   I'm often wondered about this,
[00:24:46.000 --> 00:24:48.960]   but there is something there which is very slippery.
[00:24:48.960 --> 00:24:52.700]   It's something like standing back,
[00:24:52.700 --> 00:24:54.160]   and it's got to be something, you see,
[00:24:54.160 --> 00:24:56.940]   it's also got to be something which was of value
[00:24:56.940 --> 00:24:58.900]   to our remote ancestors.
[00:24:58.900 --> 00:25:00.620]   - Right. - Because sometimes,
[00:25:00.620 --> 00:25:03.100]   there's a cartoon which I drew sometimes
[00:25:03.100 --> 00:25:04.940]   showing you how all these,
[00:25:04.940 --> 00:25:07.140]   there's in the foreground, you see this mathematician
[00:25:07.140 --> 00:25:08.860]   just doing some mathematical theorem.
[00:25:08.860 --> 00:25:10.500]   There's a little bit of a joke in that theorem,
[00:25:10.500 --> 00:25:12.300]   but let's not go into that.
[00:25:12.300 --> 00:25:14.420]   He's trying to prove some theorem,
[00:25:14.420 --> 00:25:17.780]   and he's about to be eaten by a saber-toothed tiger
[00:25:17.780 --> 00:25:21.100]   who's hiding in the undergrowth, you see.
[00:25:21.100 --> 00:25:24.320]   And in the distance, you see his cousins
[00:25:24.320 --> 00:25:29.080]   building, growing crops, building shelters,
[00:25:29.080 --> 00:25:31.920]   domesticating animals, and in the slight foreground,
[00:25:31.920 --> 00:25:33.280]   you see they built a mammoth trap,
[00:25:33.280 --> 00:25:36.620]   and this poor old mammoth is falling into a pit, you see,
[00:25:36.620 --> 00:25:39.520]   and all these people around him are about to grab him,
[00:25:39.520 --> 00:25:43.200]   you see, and well, you see, those are the ones who,
[00:25:43.200 --> 00:25:47.280]   the quality of understanding which goes with all,
[00:25:47.280 --> 00:25:50.760]   it's not just the mathematician doing his mathematics.
[00:25:50.760 --> 00:25:53.660]   This understanding quality is something else
[00:25:53.660 --> 00:25:58.140]   which has been a tremendous advantage to us,
[00:25:58.140 --> 00:25:59.700]   not just to us.
[00:25:59.700 --> 00:26:03.700]   See, I don't think consciousness is limited to humans.
[00:26:03.700 --> 00:26:04.900]   - Yeah, that's the interesting question,
[00:26:04.900 --> 00:26:07.400]   at which point, if it is indeed connected
[00:26:07.400 --> 00:26:09.160]   to the evolutionary process,
[00:26:09.160 --> 00:26:11.460]   at which point did we pick up this--
[00:26:11.460 --> 00:26:12.660]   - A very hard question.
[00:26:12.660 --> 00:26:15.940]   It's certainly, I don't think it's primates.
[00:26:15.940 --> 00:26:20.400]   You see these pictures of African hunting dogs
[00:26:20.400 --> 00:26:22.800]   and how they can plan amongst themselves
[00:26:22.800 --> 00:26:24.380]   how to catch the antelopes.
[00:26:24.380 --> 00:26:27.540]   Some of these David Attenborough films,
[00:26:27.540 --> 00:26:29.180]   I think this probably was one of them,
[00:26:29.180 --> 00:26:31.740]   and you can see the hunting dogs,
[00:26:31.740 --> 00:26:34.300]   and they divide themselves into two groups,
[00:26:34.300 --> 00:26:36.820]   and they go in two routes, two different routes.
[00:26:36.820 --> 00:26:39.660]   One of them goes and they sort of hide next to the river,
[00:26:39.660 --> 00:26:42.420]   and the other group goes around
[00:26:42.420 --> 00:26:45.840]   and they start yelping at these.
[00:26:45.840 --> 00:26:48.960]   They don't bark, I guess, whatever noise hunting dogs do,
[00:26:48.960 --> 00:26:51.020]   the antelopes, and they sort of round them up
[00:26:51.020 --> 00:26:54.580]   and they chase them in the direction of the river.
[00:26:54.580 --> 00:26:56.580]   And they're the other ones just waiting for them,
[00:26:56.580 --> 00:26:58.900]   just to get, because when they get to the river,
[00:26:58.900 --> 00:27:02.060]   it slows them down, and so they pounce on them.
[00:27:02.060 --> 00:27:05.460]   So they've obviously planned this all out somehow.
[00:27:05.460 --> 00:27:06.760]   I have no idea how.
[00:27:06.760 --> 00:27:11.460]   And there is some element of conscious planning,
[00:27:11.460 --> 00:27:12.280]   as far as I can see.
[00:27:12.280 --> 00:27:14.280]   I don't think it's just some kind of,
[00:27:14.280 --> 00:27:18.500]   so much of AI these days is done,
[00:27:18.500 --> 00:27:21.040]   what do they call it, bottom-up systems, is it?
[00:27:21.040 --> 00:27:23.640]   Yeah, where you have neural networks
[00:27:23.640 --> 00:27:27.420]   and you give them a zillion different things to look at,
[00:27:27.420 --> 00:27:32.420]   and then they sort of can choose one thing over another,
[00:27:32.420 --> 00:27:35.400]   just because it's seen so many examples
[00:27:35.400 --> 00:27:38.320]   and picks up on little signals,
[00:27:38.320 --> 00:27:41.520]   which one may not even be conscious of.
[00:27:41.520 --> 00:27:43.080]   - And that doesn't feel like understanding.
[00:27:43.080 --> 00:27:46.080]   - There's no understanding in that whatsoever.
[00:27:46.080 --> 00:27:48.400]   - Well, you're being a little bit human-centric,
[00:27:48.400 --> 00:27:50.580]   so I think I would expect--
[00:27:50.580 --> 00:27:51.420]   - Well, I'm talking about,
[00:27:51.420 --> 00:27:52.600]   I'm not with the dogs, am I?
[00:27:52.600 --> 00:27:53.440]   'Cause the dogs-- - No, you're not.
[00:27:53.440 --> 00:27:56.680]   Sorry, not human-centric, but I misspoke.
[00:27:56.680 --> 00:27:59.300]   Biology-centric.
[00:27:59.300 --> 00:28:00.920]   Is it possible that consciousness
[00:28:00.920 --> 00:28:03.160]   would just look slightly different?
[00:28:03.160 --> 00:28:04.680]   - Well, I'm not saying it's biological,
[00:28:04.680 --> 00:28:06.120]   'cause we don't know.
[00:28:06.120 --> 00:28:06.960]   - Right.
[00:28:06.960 --> 00:28:07.800]   - I think other examples,
[00:28:07.800 --> 00:28:09.880]   the elephants is a wonderful example, too.
[00:28:09.880 --> 00:28:13.940]   I think this was an Attenborough one,
[00:28:13.940 --> 00:28:16.040]   where the elephants have to go from,
[00:28:16.040 --> 00:28:20.080]   the troop of them have to go long distances.
[00:28:20.080 --> 00:28:21.600]   And the leader of a troop is a female,
[00:28:21.600 --> 00:28:23.440]   they all are, apparently.
[00:28:23.440 --> 00:28:26.760]   And this female, she had to go all the way
[00:28:26.760 --> 00:28:30.040]   from one part of the country to another.
[00:28:30.040 --> 00:28:32.440]   And at a certain point, she made a detour.
[00:28:32.440 --> 00:28:35.000]   And they went off in this big detour.
[00:28:35.000 --> 00:28:37.080]   All the troop came with her.
[00:28:37.080 --> 00:28:39.560]   And this was where her sister had died.
[00:28:39.560 --> 00:28:41.520]   And there were her bones lying around,
[00:28:41.520 --> 00:28:42.840]   and they go and pick up the bones,
[00:28:42.840 --> 00:28:45.760]   and they hand it around, and they caress the bones.
[00:28:45.760 --> 00:28:48.560]   And then they put them back, and they go back again.
[00:28:48.560 --> 00:28:49.920]   What in the hell are they doing?
[00:28:49.920 --> 00:28:51.320]   (laughs)
[00:28:51.320 --> 00:28:52.240]   - That's so interesting.
[00:28:52.240 --> 00:28:54.520]   - I mean, there's something going on.
[00:28:54.520 --> 00:28:58.500]   There's no clear connection with natural selection.
[00:28:58.500 --> 00:29:03.080]   There's just some deep feeling going on there,
[00:29:03.080 --> 00:29:05.680]   which has to do with their conscious experience.
[00:29:05.680 --> 00:29:12.000]   And I think it's something that overall is advantageous.
[00:29:13.640 --> 00:29:16.000]   By natural selection, but not directly
[00:29:16.000 --> 00:29:17.440]   to do with natural selection.
[00:29:17.440 --> 00:29:22.560]   - I like that, there's something going on there.
[00:29:22.560 --> 00:29:25.840]   Like I told you, I'm Russian, so I tend to romanticize
[00:29:25.840 --> 00:29:28.200]   all things of this nature.
[00:29:28.200 --> 00:29:33.200]   That it's not merely cold, hard computation.
[00:29:33.200 --> 00:29:35.680]   - Perhaps I could just slightly answer your question.
[00:29:35.680 --> 00:29:38.640]   You were asking me, what is it?
[00:29:38.640 --> 00:29:41.840]   There's something about sort of standing back
[00:29:41.840 --> 00:29:44.800]   and thinking about your own thought processes.
[00:29:44.800 --> 00:29:47.760]   I mean, there is something like that in the Godel thing.
[00:29:47.760 --> 00:29:50.280]   'Cause you're not following the rules,
[00:29:50.280 --> 00:29:53.480]   you're standing back and thinking about the rules.
[00:29:53.480 --> 00:29:56.940]   And so there is something that you might say,
[00:29:56.940 --> 00:29:58.200]   you think about you're doing something,
[00:29:58.200 --> 00:30:00.160]   and you think, what the hell am I doing?
[00:30:00.160 --> 00:30:02.760]   And you sort of stand back and think about what it is
[00:30:02.760 --> 00:30:05.440]   that's making you think in such a way.
[00:30:05.440 --> 00:30:08.520]   - Take a step back outside the game you've been playing.
[00:30:08.520 --> 00:30:10.680]   - Yeah, you back up, and you think about,
[00:30:10.680 --> 00:30:12.600]   you're just not playing the game anymore.
[00:30:12.600 --> 00:30:14.680]   You're thinking about what the hell you're doing
[00:30:14.680 --> 00:30:16.080]   in playing this game.
[00:30:16.080 --> 00:30:20.560]   - And that's somehow, it's not a very precise description,
[00:30:20.560 --> 00:30:22.320]   but somehow it feels very true
[00:30:22.320 --> 00:30:24.400]   that that's somehow understanding.
[00:30:24.400 --> 00:30:26.440]   So this kind of reflection.
[00:30:26.440 --> 00:30:27.720]   - A reflection, yes.
[00:30:27.720 --> 00:30:30.560]   Yeah, it's a bit hard to put your finger on,
[00:30:30.560 --> 00:30:32.960]   but there is something there which I think maybe
[00:30:32.960 --> 00:30:34.400]   could be unearthed at some point,
[00:30:34.400 --> 00:30:36.840]   and see this is really what's going on.
[00:30:36.840 --> 00:30:40.080]   Why conscious beings have this advantage.
[00:30:40.080 --> 00:30:42.720]   What it is that gives them an advantage.
[00:30:42.720 --> 00:30:44.200]   And I think it goes way back.
[00:30:44.200 --> 00:30:46.760]   I don't think, we're talking about the hunting dogs
[00:30:46.760 --> 00:30:47.660]   and the elephants.
[00:30:47.660 --> 00:30:50.440]   That's pretty clear that octopuses
[00:30:50.440 --> 00:30:53.320]   have the same sort of quality.
[00:30:53.320 --> 00:30:54.400]   And we call it consciousness?
[00:30:54.400 --> 00:30:55.680]   Yeah, I think so.
[00:30:55.680 --> 00:30:58.760]   Seen enough examples of the way that they behave,
[00:30:58.760 --> 00:31:02.520]   and the evolution route is completely different.
[00:31:02.520 --> 00:31:05.880]   Does it go way back to some common ancestor,
[00:31:05.880 --> 00:31:07.600]   or did it come separately?
[00:31:07.600 --> 00:31:09.360]   - My hope is it's something simple,
[00:31:09.360 --> 00:31:13.440]   but the hard question if there's a hardware prerequisite.
[00:31:13.440 --> 00:31:17.800]   We have to develop some kind of hardware mechanisms
[00:31:17.800 --> 00:31:19.160]   in our computers.
[00:31:19.160 --> 00:31:21.120]   Like basically, as you suggest,
[00:31:21.120 --> 00:31:22.560]   and we'll get to in a second,
[00:31:22.560 --> 00:31:24.440]   we kind of have to throw away the computer
[00:31:24.440 --> 00:31:26.080]   as we know it today.
[00:31:26.080 --> 00:31:28.320]   The deterministic machines we know today
[00:31:28.320 --> 00:31:29.720]   to try to create it.
[00:31:29.720 --> 00:31:33.180]   I mean, my hope of course is not, but.
[00:31:33.180 --> 00:31:37.720]   - Well, I should go really back to the story,
[00:31:37.720 --> 00:31:39.880]   which in a sense I haven't finished.
[00:31:39.880 --> 00:31:41.800]   Because I went to these three courses, you see,
[00:31:41.800 --> 00:31:43.920]   when I was a graduate student.
[00:31:43.920 --> 00:31:46.960]   And so I started to think, well I'm really,
[00:31:46.960 --> 00:31:49.640]   I'm a pretty, what you might call a materialist
[00:31:49.640 --> 00:31:53.640]   in the sense of thinking that there's no kind of mystical
[00:31:53.640 --> 00:31:56.000]   or something or other which comes in from who knows where.
[00:31:56.000 --> 00:31:56.840]   - You still that?
[00:31:56.840 --> 00:31:58.600]   Are you still throughout your life been a materialist?
[00:31:58.600 --> 00:32:00.080]   - I don't like the word materialist
[00:32:00.080 --> 00:32:02.840]   because it suggests we know what material is.
[00:32:02.840 --> 00:32:06.120]   And that is a bad word because--
[00:32:06.120 --> 00:32:07.640]   - But there's no mystical.
[00:32:07.640 --> 00:32:09.200]   - It's not some mystical something
[00:32:09.200 --> 00:32:11.800]   which is not treatable by science.
[00:32:11.800 --> 00:32:12.720]   - That's so beautifully put,
[00:32:12.720 --> 00:32:14.320]   just to pause on that for a second.
[00:32:14.320 --> 00:32:17.040]   You're a materialist but you acknowledge
[00:32:17.040 --> 00:32:19.160]   that we don't really know what the material is.
[00:32:19.160 --> 00:32:20.000]   - That's right.
[00:32:20.000 --> 00:32:24.280]   I mean, I like to call myself a scientist I suppose.
[00:32:24.280 --> 00:32:28.360]   But it means that, yes, well you see,
[00:32:28.360 --> 00:32:29.640]   the question goes on here.
[00:32:29.640 --> 00:32:33.200]   So I began thinking, okay, if consciousness
[00:32:33.200 --> 00:32:35.920]   or understanding is something
[00:32:35.920 --> 00:32:40.040]   which is not a computational process, what can it be?
[00:32:40.040 --> 00:32:42.280]   And I knew enough from my undergraduate work,
[00:32:42.280 --> 00:32:44.480]   I knew about Newtonian mechanics
[00:32:44.480 --> 00:32:48.840]   and I knew how basically you could put it on a computer.
[00:32:48.840 --> 00:32:53.200]   There is a fundamental issue which is it important or not
[00:32:53.200 --> 00:32:59.160]   that computation depends upon discrete things,
[00:32:59.160 --> 00:33:02.280]   so using discrete elements,
[00:33:02.280 --> 00:33:06.240]   whereas the physical laws depend on the continuum.
[00:33:06.240 --> 00:33:09.640]   Now is this something to do with it?
[00:33:09.640 --> 00:33:12.800]   Is it the fact that we use the continuum in our physics
[00:33:12.800 --> 00:33:15.240]   and if we model our physical system,
[00:33:15.240 --> 00:33:17.920]   we use discrete systems like ordinary computers?
[00:33:17.920 --> 00:33:22.080]   I came to the view that that's probably not it.
[00:33:22.080 --> 00:33:24.840]   I might have to retract on that someday,
[00:33:24.840 --> 00:33:28.360]   but the view was no, you can get close enough.
[00:33:28.360 --> 00:33:30.880]   It's not altogether clear, I have to say,
[00:33:30.880 --> 00:33:32.960]   but you can get close enough.
[00:33:32.960 --> 00:33:37.000]   And I went to this course by Bondy on general relativity
[00:33:37.000 --> 00:33:39.480]   and I thought, well, you can put that on a computer.
[00:33:39.480 --> 00:33:42.800]   Of course, that was a long time before people,
[00:33:42.800 --> 00:33:44.000]   and I've sort of grown up with this,
[00:33:44.000 --> 00:33:46.200]   how people have done better and better calculations
[00:33:46.200 --> 00:33:48.280]   and they could work out black holes
[00:33:48.280 --> 00:33:50.400]   and they can then work out how black holes
[00:33:50.400 --> 00:33:51.920]   can interact with each other,
[00:33:51.920 --> 00:33:55.040]   spiral around and what kind of gravitational waves can add.
[00:33:55.040 --> 00:33:58.640]   And it's a very impressive piece of computational work,
[00:33:58.640 --> 00:34:01.920]   how you can actually work out the shapes of those signals.
[00:34:01.920 --> 00:34:04.040]   Now we have LIGO seeing these signals
[00:34:04.040 --> 00:34:05.640]   and they say, yeah, there's a black hole
[00:34:05.640 --> 00:34:07.400]   spiraling into each other.
[00:34:07.400 --> 00:34:11.760]   This is just a vindication of the power of computation
[00:34:11.760 --> 00:34:16.080]   in describing Einstein's general relativity.
[00:34:16.080 --> 00:34:17.980]   - So in that case, we can get close.
[00:34:17.980 --> 00:34:22.120]   With computation, we can get close
[00:34:22.120 --> 00:34:23.400]   to our understanding of the physics.
[00:34:23.400 --> 00:34:24.640]   - You can get very, very close.
[00:34:24.640 --> 00:34:26.960]   Now, is that close enough, you see?
[00:34:26.960 --> 00:34:29.680]   And then I went to this course by Dirac.
[00:34:29.680 --> 00:34:32.560]   Now you see, I think it was the very first lecture
[00:34:32.560 --> 00:34:35.120]   that he gave and he was talking
[00:34:35.120 --> 00:34:37.520]   about the superposition principle.
[00:34:37.520 --> 00:34:39.920]   And he said, if you have a particle,
[00:34:39.920 --> 00:34:43.040]   you usually think of particle can be over here or over there,
[00:34:43.040 --> 00:34:45.240]   but in quantum mechanics, it can be over here
[00:34:45.240 --> 00:34:48.080]   and over there at the same time.
[00:34:48.080 --> 00:34:51.480]   And you have these states which involve a superposition
[00:34:51.480 --> 00:34:56.480]   in some sense of it different locations for that particle.
[00:34:56.680 --> 00:34:58.560]   And then he got out his piece of chalk.
[00:34:58.560 --> 00:35:00.000]   Some people say he broke it in two
[00:35:00.000 --> 00:35:03.000]   as a kind of illustration of how the piece of chalk
[00:35:03.000 --> 00:35:05.800]   might be over here and over there at the same time.
[00:35:05.800 --> 00:35:10.880]   And he was talking about this and my mind wandered.
[00:35:10.880 --> 00:35:13.320]   I don't remember what he said.
[00:35:13.320 --> 00:35:16.480]   All I can remember, he's just moved on to the next topic
[00:35:16.480 --> 00:35:18.560]   and something about energy he'd mentioned,
[00:35:18.560 --> 00:35:21.000]   which I had no idea what had to do with anything.
[00:35:21.000 --> 00:35:22.880]   And so I'd been struck with this
[00:35:22.880 --> 00:35:25.240]   and worried about it ever since.
[00:35:25.240 --> 00:35:27.760]   It's probably just as well I didn't hear his explanation
[00:35:27.760 --> 00:35:29.360]   because it was probably one of these things
[00:35:29.360 --> 00:35:32.080]   to calm me down and not worry about it anymore.
[00:35:32.080 --> 00:35:35.880]   Whereas in my case, I've worried about it ever since.
[00:35:35.880 --> 00:35:38.440]   So I thought maybe that's the catch.
[00:35:38.440 --> 00:35:41.200]   There is something in quantum mechanics
[00:35:41.200 --> 00:35:45.040]   where the superpositions become one or the other.
[00:35:45.040 --> 00:35:47.800]   And that's not part of quantum mechanics.
[00:35:47.800 --> 00:35:50.020]   There's something missing in the theory.
[00:35:50.020 --> 00:35:51.600]   The theory is incomplete.
[00:35:51.600 --> 00:35:52.560]   It's not just incomplete.
[00:35:52.560 --> 00:35:54.920]   It's in a certain sense, not quite right
[00:35:54.920 --> 00:35:57.480]   because if you follow the equation,
[00:35:57.480 --> 00:35:59.320]   the basic equation of quantum mechanics,
[00:35:59.320 --> 00:36:01.200]   that's the Schrodinger equation,
[00:36:01.200 --> 00:36:02.680]   you could put that on a computer too.
[00:36:02.680 --> 00:36:04.800]   There are lots of difficulties about how many parameters
[00:36:04.800 --> 00:36:06.160]   you have to put in and so on.
[00:36:06.160 --> 00:36:07.480]   That can be very tricky,
[00:36:07.480 --> 00:36:10.880]   but nevertheless, it is a computational process.
[00:36:10.880 --> 00:36:14.960]   Modulo this question about the continuum as before,
[00:36:14.960 --> 00:36:16.920]   but it's not clear that makes any difference.
[00:36:16.920 --> 00:36:18.920]   - So our theories of quantum mechanics
[00:36:18.920 --> 00:36:20.960]   may be missing the same element
[00:36:20.960 --> 00:36:24.340]   that the universal Turing machine is missing
[00:36:24.340 --> 00:36:25.480]   about consciousness.
[00:36:25.480 --> 00:36:26.400]   - Yes, yes.
[00:36:26.400 --> 00:36:29.680]   Yeah, this is the view I held is that you need a theory
[00:36:29.680 --> 00:36:33.560]   and that that, what people call the reduction of the state
[00:36:33.560 --> 00:36:35.760]   or the collapse of the wave function,
[00:36:35.760 --> 00:36:36.760]   which you have to have,
[00:36:36.760 --> 00:36:38.500]   otherwise quantum mechanics doesn't relate
[00:36:38.500 --> 00:36:39.920]   to the world we see.
[00:36:39.920 --> 00:36:41.440]   To make it relate to the world we see,
[00:36:41.440 --> 00:36:45.160]   you've got to break the Schrodinger equation.
[00:36:45.160 --> 00:36:49.240]   Schrodinger himself was absolutely appalled by this idea,
[00:36:49.240 --> 00:36:50.880]   his own equation.
[00:36:50.880 --> 00:36:54.580]   I mean, that's why he introduced this famous Schrodinger's cat
[00:36:54.580 --> 00:36:56.340]   as a thought experiment.
[00:36:56.340 --> 00:36:57.180]   He's really saying, look,
[00:36:57.180 --> 00:36:59.620]   this is where my equation leads you into it.
[00:36:59.620 --> 00:37:02.660]   There's something wrong, something we haven't understood,
[00:37:02.660 --> 00:37:05.300]   which is basically fundamental.
[00:37:05.300 --> 00:37:07.880]   And so I was trying to put all these things together
[00:37:07.880 --> 00:37:10.580]   and said, well, it's got to be the non-computability
[00:37:10.580 --> 00:37:11.900]   comes in there.
[00:37:11.900 --> 00:37:14.820]   And I also can't quite remember when I thought this,
[00:37:14.820 --> 00:37:18.140]   but it's when gravity is involved in quantum mechanics.
[00:37:18.140 --> 00:37:19.860]   It's the combination of those two.
[00:37:19.860 --> 00:37:24.860]   And it's that point when you have good reasons to believe,
[00:37:24.860 --> 00:37:27.620]   this came much later,
[00:37:27.620 --> 00:37:29.900]   but I have good reason to believe
[00:37:29.900 --> 00:37:32.900]   that the principles of general relativity
[00:37:32.900 --> 00:37:34.220]   and those of quantum mechanics,
[00:37:34.220 --> 00:37:39.220]   most particularly it's the basic principle of equivalence,
[00:37:39.220 --> 00:37:41.380]   which goes back to Galileo.
[00:37:41.380 --> 00:37:46.380]   If you fall freely, you eliminate the gravitational field.
[00:37:46.460 --> 00:37:50.740]   So you imagine Galileo dropping his big rock
[00:37:50.740 --> 00:37:52.620]   and his little rock from the leaning tower,
[00:37:52.620 --> 00:37:54.140]   whether he actually ever did that or not,
[00:37:54.140 --> 00:37:55.740]   it's pretty irrelevant.
[00:37:55.740 --> 00:37:57.780]   And as the rocks fall to the ground,
[00:37:57.780 --> 00:37:59.820]   you have a little insect sitting on one of them
[00:37:59.820 --> 00:38:01.380]   looking at the other one.
[00:38:01.380 --> 00:38:04.220]   And it seems to think, oh, there's no gravity here.
[00:38:04.220 --> 00:38:05.340]   Of course it hits the ground
[00:38:05.340 --> 00:38:07.900]   and then you realize something's different is going on.
[00:38:07.900 --> 00:38:11.980]   But when it's in free fall, the gravity is being eliminated.
[00:38:11.980 --> 00:38:15.420]   Galileo understood that very beautifully.
[00:38:15.420 --> 00:38:18.540]   He gives these wonderful examples of fireworks
[00:38:18.540 --> 00:38:20.380]   and you see the fireworks and explode
[00:38:20.380 --> 00:38:23.460]   and you see this sphere of sparkling fireworks.
[00:38:23.460 --> 00:38:26.820]   It remains a sphere as it falls down,
[00:38:26.820 --> 00:38:29.220]   as though there were no gravity.
[00:38:29.220 --> 00:38:31.260]   So he understood that principle,
[00:38:31.260 --> 00:38:33.540]   but he couldn't make a theory out of it.
[00:38:33.540 --> 00:38:36.740]   Einstein came along, used exactly the same principle.
[00:38:36.740 --> 00:38:38.020]   And that's the basis
[00:38:38.020 --> 00:38:40.420]   of Einstein's general theory of relativity.
[00:38:40.420 --> 00:38:43.540]   Now, there is a conflict.
[00:38:43.540 --> 00:38:45.220]   This is something I did much, much later.
[00:38:45.220 --> 00:38:48.900]   So this wasn't those days, much, much later.
[00:38:48.900 --> 00:38:51.420]   You can see there is a basic conflict
[00:38:51.420 --> 00:38:54.340]   between the principle of superposition,
[00:38:54.340 --> 00:38:56.340]   the thing that Dirac was talking about,
[00:38:56.340 --> 00:38:58.700]   and the principle of general covariance.
[00:38:58.700 --> 00:39:01.020]   Well, principle of equivalence.
[00:39:01.020 --> 00:39:03.700]   Gravitational field is equivalent to an acceleration.
[00:39:03.700 --> 00:39:04.700]   - Can you pause for a second?
[00:39:04.700 --> 00:39:06.860]   What is the principle of equivalence?
[00:39:06.860 --> 00:39:08.260]   - It's this Galileo principle
[00:39:08.260 --> 00:39:11.560]   that you can eliminate, at least locally.
[00:39:11.560 --> 00:39:13.540]   You have to be in a small neighborhood
[00:39:13.540 --> 00:39:16.420]   because if you have people dropping rocks
[00:39:16.420 --> 00:39:18.060]   all around the world somewhere,
[00:39:18.060 --> 00:39:19.900]   you can't get rid of it all at once.
[00:39:19.900 --> 00:39:22.060]   But in the local neighborhood,
[00:39:22.060 --> 00:39:24.220]   you can eliminate the gravitational field
[00:39:24.220 --> 00:39:26.740]   by falling freely with it.
[00:39:26.740 --> 00:39:28.460]   And we now see that with astronauts,
[00:39:28.460 --> 00:39:30.660]   and they don't, you know, the Earth is right there.
[00:39:30.660 --> 00:39:32.500]   You can see the great globe of the Earth
[00:39:32.500 --> 00:39:35.020]   right beneath them, but they don't care about it.
[00:39:35.020 --> 00:39:37.780]   They, as far as they're concerned, there's no gravity.
[00:39:37.780 --> 00:39:42.060]   They fall freely in the gravitational field,
[00:39:42.060 --> 00:39:45.060]   and that gets rid of the gravitational field.
[00:39:45.060 --> 00:39:46.660]   And that's the principle of equivalence.
[00:39:46.660 --> 00:39:48.900]   - So what's the contradiction?
[00:39:48.900 --> 00:39:50.460]   What's the tension with superposition?
[00:39:50.460 --> 00:39:52.580]   - Ah, well, that's technical. (laughs)
[00:39:52.580 --> 00:39:55.100]   - Well, so we, just to backtrack for a second,
[00:39:55.100 --> 00:39:57.980]   just to see if we can weave a thread through it all.
[00:39:57.980 --> 00:40:02.340]   So we started to think about consciousness
[00:40:02.340 --> 00:40:06.760]   as potentially needing some of the same,
[00:40:06.760 --> 00:40:08.740]   not mystical, but some of the same magic.
[00:40:08.740 --> 00:40:10.620]   - You see, it is a complicated story.
[00:40:10.620 --> 00:40:12.660]   So, you know, people think, oh, I'm drifting away
[00:40:12.660 --> 00:40:14.220]   from the point or something.
[00:40:14.220 --> 00:40:16.740]   But I think it is a complicated story.
[00:40:16.740 --> 00:40:18.180]   So what I'm trying to say, I mean,
[00:40:18.180 --> 00:40:20.740]   I tried to put it in a nutshell, but it's not so easy.
[00:40:20.740 --> 00:40:24.940]   I'm trying to say that whatever consciousness is,
[00:40:24.940 --> 00:40:26.780]   it's not a computation.
[00:40:26.780 --> 00:40:27.620]   - Yes.
[00:40:27.620 --> 00:40:29.300]   - Or it's not a physical process
[00:40:29.300 --> 00:40:33.380]   which can be described by computation.
[00:40:33.380 --> 00:40:34.900]   - But it nevertheless could be,
[00:40:34.900 --> 00:40:39.900]   so one of the interesting models that you've proposed
[00:40:39.900 --> 00:40:42.020]   is the orchestrated objective reduction, which is--
[00:40:42.020 --> 00:40:44.700]   - Yeah, well, you see, that's going from there, you see.
[00:40:44.700 --> 00:40:46.780]   So I say I have no idea.
[00:40:46.780 --> 00:40:50.360]   So I wrote this book through my scientific career.
[00:40:50.360 --> 00:40:52.700]   I thought, you know, when I'm retired,
[00:40:52.700 --> 00:40:55.800]   I'll have enough time to write a sort of a popularish book,
[00:40:55.800 --> 00:41:01.200]   which I will explain my ideas and puzzles,
[00:41:01.200 --> 00:41:04.180]   what I like, beautiful things about physics and mathematics,
[00:41:04.180 --> 00:41:07.500]   and this puzzle about computability
[00:41:07.500 --> 00:41:09.580]   and consciousness and so on.
[00:41:09.580 --> 00:41:13.100]   And in the process of writing this book,
[00:41:13.100 --> 00:41:14.460]   well, I thought I'd do it when I was retired.
[00:41:14.460 --> 00:41:15.300]   I didn't, actually.
[00:41:15.300 --> 00:41:19.420]   I didn't wait that long because there was a radio discussion
[00:41:19.420 --> 00:41:24.180]   between Edward Fredkin and Marvin Minsky,
[00:41:24.180 --> 00:41:28.220]   and they were talking about what computers could do,
[00:41:28.220 --> 00:41:30.660]   and they were entering a big room.
[00:41:30.660 --> 00:41:32.020]   They imagined entering this big room,
[00:41:32.020 --> 00:41:33.820]   where at the other end of the room,
[00:41:33.820 --> 00:41:36.900]   two computers were talking to each other.
[00:41:36.900 --> 00:41:39.260]   And as you walk up to the computers,
[00:41:39.260 --> 00:41:41.740]   they will have communicated to each other
[00:41:41.740 --> 00:41:45.100]   more ideas, concepts, things,
[00:41:45.100 --> 00:41:48.140]   than the entire human race had ever done.
[00:41:48.140 --> 00:41:51.620]   So I thought, well, I know where you're coming from,
[00:41:51.620 --> 00:41:53.620]   but I just don't believe you.
[00:41:53.620 --> 00:41:54.920]   There's something missing.
[00:41:54.920 --> 00:41:59.220]   So I thought, well, I should write my book.
[00:41:59.220 --> 00:42:01.620]   And so I did.
[00:42:01.620 --> 00:42:04.060]   It was at roughly the same time Stephen Hawking
[00:42:04.060 --> 00:42:07.820]   was writing his "Brief History of Time."
[00:42:09.060 --> 00:42:11.300]   - '80s at some point.
[00:42:11.300 --> 00:42:12.900]   The book you're talking about is "The Emperor's New Mind."
[00:42:12.900 --> 00:42:14.100]   - "The Emperor's New Mind," that's right.
[00:42:14.100 --> 00:42:16.140]   - And both are incredible books,
[00:42:16.140 --> 00:42:18.580]   "The Brief History of Time" and "The Emperor's New Mind."
[00:42:18.580 --> 00:42:19.980]   - Yes, it was quite interesting,
[00:42:19.980 --> 00:42:23.540]   'cause he told me he'd got Carl Sagan, I think,
[00:42:23.540 --> 00:42:25.060]   to write a forward.
[00:42:25.060 --> 00:42:25.900]   - It's a good get.
[00:42:25.900 --> 00:42:26.740]   - To the book, you see.
[00:42:26.740 --> 00:42:28.300]   So I thought, gosh, what am I gonna do?
[00:42:28.300 --> 00:42:31.180]   I'm not gonna get anywhere unless I get somebody.
[00:42:31.180 --> 00:42:32.780]   So I said, well, I know Martin Gardner,
[00:42:32.780 --> 00:42:34.500]   so I wonder if he'd do it.
[00:42:34.500 --> 00:42:36.740]   So he did, and he did a very nice forward.
[00:42:36.740 --> 00:42:38.340]   - So that's an incredible book,
[00:42:38.340 --> 00:42:40.460]   and some of the same people you mentioned,
[00:42:40.460 --> 00:42:44.660]   Ed Franken, which I guess of expert systems fame,
[00:42:44.660 --> 00:42:47.020]   and Minsky, of course, people know in the AI world,
[00:42:47.020 --> 00:42:48.980]   but they represent the artificial intelligence world.
[00:42:48.980 --> 00:42:49.820]   - Absolutely, that's right.
[00:42:49.820 --> 00:42:53.340]   - That do hope and dream that AI's intelligence is--
[00:42:53.340 --> 00:42:54.180]   - That's right.
[00:42:54.180 --> 00:42:55.000]   Well, you see, it was my thinking,
[00:42:55.000 --> 00:42:57.060]   well, you know, I see where they're coming from,
[00:42:57.060 --> 00:42:57.900]   and from that perspective--
[00:42:57.900 --> 00:42:58.740]   - I disagree.
[00:42:58.740 --> 00:43:01.660]   - Yeah, you're right, but that's not my perspective.
[00:43:01.660 --> 00:43:03.460]   So I thought I had to say it.
[00:43:03.460 --> 00:43:05.100]   And as I was writing my book, you see,
[00:43:05.100 --> 00:43:06.740]   I thought, well, I don't really know anything
[00:43:06.740 --> 00:43:09.220]   about neurophysiology, what am I doing writing this book?
[00:43:09.220 --> 00:43:12.140]   So I started reading up about neurophysiology,
[00:43:12.140 --> 00:43:13.980]   and I read up, and I think, I'm trying to find out
[00:43:13.980 --> 00:43:16.460]   how it is that nerve signals could possibly
[00:43:16.460 --> 00:43:18.380]   preserve quantum coherence.
[00:43:18.380 --> 00:43:20.940]   And all I read is that the electrical signals
[00:43:20.940 --> 00:43:25.580]   which go along the nerves create effects through the brain,
[00:43:25.580 --> 00:43:28.260]   there's no chance you can isolate it.
[00:43:28.260 --> 00:43:29.900]   So this is hopeless.
[00:43:29.900 --> 00:43:31.700]   So I come to the end of the book,
[00:43:31.700 --> 00:43:33.620]   and I more or less give up.
[00:43:33.620 --> 00:43:36.220]   I just think of something which I didn't believe in,
[00:43:36.220 --> 00:43:38.460]   as maybe this is the way around it, but no.
[00:43:38.460 --> 00:43:41.620]   And then you see, I thought, well, maybe this book
[00:43:41.620 --> 00:43:43.420]   will at least stimulate young people
[00:43:43.420 --> 00:43:46.340]   to do science or something, and I got all these letters
[00:43:46.340 --> 00:43:48.460]   from old, retired people instead.
[00:43:48.460 --> 00:43:51.220]   These are the only people who had time to read my book.
[00:43:51.220 --> 00:43:53.180]   - So, I mean--
[00:43:53.180 --> 00:43:54.980]   - Except for Stuart Hameroff.
[00:43:54.980 --> 00:43:56.460]   - Except for Stuart Hameroff.
[00:43:56.460 --> 00:43:58.500]   - Stuart Hameroff wrote to me, and he said,
[00:43:58.500 --> 00:44:00.140]   I think you're missing something.
[00:44:00.140 --> 00:44:03.420]   You don't know about microtubules, do you?
[00:44:03.420 --> 00:44:04.860]   He didn't put it quite like that,
[00:44:04.860 --> 00:44:05.980]   but that was more or less it.
[00:44:05.980 --> 00:44:08.900]   And he said, this is what you really need to consider.
[00:44:08.900 --> 00:44:10.660]   So I thought, my God, yes,
[00:44:10.660 --> 00:44:12.980]   that's a much more promising structure.
[00:44:12.980 --> 00:44:16.380]   - So, I mean, fundamentally, you were searching
[00:44:16.380 --> 00:44:21.380]   for the source of, non-computable source of consciousness
[00:44:21.380 --> 00:44:25.100]   within the human brain, in the biology.
[00:44:25.100 --> 00:44:30.100]   And so, what are, if I may ask, what are microtubules?
[00:44:30.100 --> 00:44:33.940]   - Well, you see, I was ignorant in what I'd read.
[00:44:33.940 --> 00:44:37.740]   I never came across them in the books I looked at.
[00:44:37.740 --> 00:44:40.900]   Perhaps I only read rather superficially, which is true.
[00:44:40.900 --> 00:44:43.140]   But I didn't know about microtubules.
[00:44:43.140 --> 00:44:45.300]   Stuart, I think one of the things
[00:44:45.300 --> 00:44:47.100]   that impressed him about them is
[00:44:47.100 --> 00:44:48.900]   when you see pictures of mitosis,
[00:44:48.900 --> 00:44:53.340]   that's a cell dividing, and you see all the chromosomes,
[00:44:53.340 --> 00:44:55.740]   and the chromosomes, they all get lined up,
[00:44:55.740 --> 00:44:58.020]   and then they get pulled apart.
[00:44:58.020 --> 00:45:01.660]   And so, as the cell divides, half the chromosomes go,
[00:45:01.660 --> 00:45:04.980]   you know, they divide into the two parts,
[00:45:04.980 --> 00:45:07.460]   and they go two different ways.
[00:45:07.460 --> 00:45:09.860]   And what is it that's pulling them apart?
[00:45:09.860 --> 00:45:12.940]   Well, those are these little things called microtubules.
[00:45:12.940 --> 00:45:15.620]   And so he started to get interested in them.
[00:45:15.620 --> 00:45:18.940]   And he formed the view, well, he was,
[00:45:18.940 --> 00:45:21.140]   his day job or night job, or whatever you call it,
[00:45:21.140 --> 00:45:23.100]   is to put people to sleep,
[00:45:23.100 --> 00:45:24.740]   except he doesn't like calling it sleep
[00:45:24.740 --> 00:45:25.860]   because it's different,
[00:45:25.860 --> 00:45:29.340]   general anesthetics, in a reversible way.
[00:45:29.340 --> 00:45:33.020]   So you want to make sure that they don't experience the pain
[00:45:33.020 --> 00:45:36.820]   that would otherwise be something that they feel.
[00:45:36.820 --> 00:45:40.380]   And consciousness is turned off for a while,
[00:45:40.380 --> 00:45:41.940]   and it can be turned back on again.
[00:45:41.940 --> 00:45:44.980]   So it's crucial that you can turn it off and turn it on.
[00:45:44.980 --> 00:45:47.500]   And what do you do when you're doing that?
[00:45:47.500 --> 00:45:49.740]   What do general anesthetic gases do?
[00:45:49.740 --> 00:45:53.340]   And see, he formed the view
[00:45:53.340 --> 00:45:55.980]   that it's the microtubules that they affect.
[00:45:56.940 --> 00:46:00.020]   And the details of why he formed that view
[00:46:00.020 --> 00:46:02.380]   is not all that clear to me,
[00:46:02.380 --> 00:46:05.700]   but there's an interesting story he keeps talking about.
[00:46:05.700 --> 00:46:08.540]   But I found this very exciting
[00:46:08.540 --> 00:46:11.540]   because I thought these structures,
[00:46:11.540 --> 00:46:15.460]   these little tubes which inhabit pretty well all cells,
[00:46:15.460 --> 00:46:16.820]   it's not just neurons,
[00:46:16.820 --> 00:46:20.620]   apart from red blood cells,
[00:46:20.620 --> 00:46:23.980]   they inhabit pretty well all the other cells in the body.
[00:46:23.980 --> 00:46:25.420]   But they're not all the same kind.
[00:46:25.420 --> 00:46:28.060]   You get different kinds of microtubules.
[00:46:28.060 --> 00:46:31.780]   And the ones that excited me the most,
[00:46:31.780 --> 00:46:34.540]   this may still not be totally clear,
[00:46:34.540 --> 00:46:36.220]   but the ones that excited me most
[00:46:36.220 --> 00:46:39.340]   were the only ones that I knew about at the time,
[00:46:39.340 --> 00:46:43.300]   because they're very, very symmetrical structures.
[00:46:43.300 --> 00:46:45.660]   And I had reason to believe
[00:46:45.660 --> 00:46:48.140]   that these very symmetrical structures
[00:46:48.140 --> 00:46:52.180]   would be much better at preserving a quantum state,
[00:46:52.180 --> 00:46:53.140]   quantum coherence,
[00:46:53.140 --> 00:46:54.780]   preserving the thing without,
[00:46:54.780 --> 00:46:58.840]   you just need to preserve certain degrees of freedom
[00:46:58.840 --> 00:47:01.140]   without them leaking into the environment.
[00:47:01.140 --> 00:47:03.460]   Once they leak into the environment, you're lost.
[00:47:03.460 --> 00:47:08.180]   So you've got to preserve these quantum states at a level
[00:47:08.180 --> 00:47:12.460]   which the state reduction process comes in,
[00:47:12.460 --> 00:47:16.280]   and that's where I think the non-computability comes in.
[00:47:16.280 --> 00:47:19.740]   And it's the measurement process in quantum mechanics,
[00:47:19.740 --> 00:47:20.900]   what's going on.
[00:47:20.900 --> 00:47:23.660]   - So something about the measurement process
[00:47:23.660 --> 00:47:24.500]   and what's going on,
[00:47:24.500 --> 00:47:27.220]   something about the structure of the microtubules,
[00:47:27.220 --> 00:47:29.620]   your intuition says, maybe there's something here.
[00:47:29.620 --> 00:47:32.580]   Maybe this kind of structure allows
[00:47:32.580 --> 00:47:35.580]   for the mystery of the quantum mechanics.
[00:47:35.580 --> 00:47:37.340]   - There was a much better chance, yes.
[00:47:37.340 --> 00:47:40.860]   It just struck me that partly it was the symmetry,
[00:47:40.860 --> 00:47:43.260]   because there is a feature of symmetry.
[00:47:43.260 --> 00:47:46.380]   You can preserve quantum coherence
[00:47:46.380 --> 00:47:48.260]   much better with symmetrical structures.
[00:47:48.260 --> 00:47:50.420]   And so there's a good reason for that.
[00:47:50.420 --> 00:47:52.620]   And that impressed me a lot.
[00:47:52.620 --> 00:47:54.780]   I didn't know the difference between the A-lattice
[00:47:54.780 --> 00:47:58.020]   and B-lattice at that time, which could be important.
[00:47:58.020 --> 00:48:00.940]   No, that couldn't, which isn't talked about much.
[00:48:00.940 --> 00:48:02.700]   - But that's in some sense details.
[00:48:02.700 --> 00:48:04.420]   We've got to take a step back just to say,
[00:48:04.420 --> 00:48:06.220]   in case people are not familiar.
[00:48:06.220 --> 00:48:11.220]   So this was called the orchestrated objective reduction idea
[00:48:11.220 --> 00:48:18.460]   or ORC-OR, which is a biological philosophy of mind
[00:48:18.460 --> 00:48:20.700]   that postulates that consciousness originates
[00:48:20.700 --> 00:48:22.340]   at the quantum level inside neurons.
[00:48:22.340 --> 00:48:25.300]   So that has to do with your search for where,
[00:48:25.300 --> 00:48:26.660]   where is it coming from?
[00:48:26.660 --> 00:48:29.540]   So that's counter to the notion that consciousness
[00:48:29.540 --> 00:48:33.180]   might arise from the computation performed by the synapses.
[00:48:33.180 --> 00:48:35.540]   - Yes, I think the key point,
[00:48:35.540 --> 00:48:40.540]   sometimes people say it's because it's quantum mechanical.
[00:48:40.540 --> 00:48:42.620]   It's not just that.
[00:48:42.620 --> 00:48:45.040]   See, it's more outrageous than that.
[00:48:45.040 --> 00:48:48.300]   You see, this is one reason I think we're so far off from it
[00:48:48.300 --> 00:48:51.020]   because we don't even know the physics right.
[00:48:51.020 --> 00:48:53.820]   You see, it's not just quantum mechanics.
[00:48:53.820 --> 00:48:54.900]   People say, oh, you know,
[00:48:54.900 --> 00:48:57.300]   quantum systems and biological structures.
[00:48:57.300 --> 00:48:59.100]   No, well, you're starting to see
[00:48:59.100 --> 00:49:04.100]   that some basic biological systems does depend on quantum.
[00:49:04.100 --> 00:49:07.540]   I mean, look, in the first place,
[00:49:07.540 --> 00:49:09.780]   all of chemistry is quantum mechanics.
[00:49:09.780 --> 00:49:13.100]   People got used to that, so they don't count that.
[00:49:13.100 --> 00:49:16.620]   So he said, let's not count quantum chemistry.
[00:49:16.620 --> 00:49:19.100]   We sort of got the hang of that, I think.
[00:49:19.100 --> 00:49:21.340]   But you have quantum effects,
[00:49:21.340 --> 00:49:25.420]   which are not just chemical, in photosynthesis.
[00:49:25.420 --> 00:49:27.220]   And this is one of the striking things
[00:49:27.220 --> 00:49:29.300]   in the last several years,
[00:49:29.300 --> 00:49:34.220]   that photosynthesis seems to be a basically quantum process,
[00:49:34.220 --> 00:49:36.860]   which is not simply chemical.
[00:49:36.860 --> 00:49:41.460]   It's using quantum mechanics in a very basic way.
[00:49:41.460 --> 00:49:43.100]   So you could start saying, oh, well,
[00:49:43.100 --> 00:49:45.580]   with photosynthesis is based on quantum mechanics,
[00:49:45.580 --> 00:49:50.260]   why not behavior of neurons and things like that?
[00:49:50.260 --> 00:49:53.740]   Maybe there's something which is a bit like photosynthesis
[00:49:53.740 --> 00:49:55.060]   in that respect.
[00:49:55.060 --> 00:49:58.140]   But what I'm saying is even more outrageous than that,
[00:49:58.140 --> 00:50:00.780]   because those things are talking
[00:50:00.780 --> 00:50:03.700]   about conventional quantum mechanics.
[00:50:03.700 --> 00:50:07.540]   Now, my argument says that conventional quantum mechanics,
[00:50:07.540 --> 00:50:09.420]   if you're just following the Schrodinger equation,
[00:50:09.420 --> 00:50:11.700]   that's still computable.
[00:50:11.700 --> 00:50:13.900]   So you've got to go beyond that.
[00:50:13.900 --> 00:50:18.900]   So you've got to go to where quantum mechanics goes wrong
[00:50:18.900 --> 00:50:21.060]   in a certain sense.
[00:50:21.060 --> 00:50:23.780]   You have to be a little bit careful about that,
[00:50:23.780 --> 00:50:26.020]   because the way people do quantum mechanics
[00:50:26.020 --> 00:50:31.020]   is a sort of mixture of two different processes.
[00:50:31.020 --> 00:50:35.460]   One of them is the Schrodinger equation,
[00:50:35.460 --> 00:50:38.820]   which is an equation that Schrodinger wrote down,
[00:50:38.820 --> 00:50:42.620]   and it tells you how the state of a system evolves.
[00:50:42.620 --> 00:50:44.780]   And it evolves, according to this equation,
[00:50:44.780 --> 00:50:47.340]   completely deterministic,
[00:50:47.340 --> 00:50:50.340]   but it evolves into ridiculous situations.
[00:50:50.340 --> 00:50:52.700]   And this was what Schrodinger was very much pointing out
[00:50:52.700 --> 00:50:54.260]   with his cat.
[00:50:54.260 --> 00:50:55.860]   He says, you follow my equation,
[00:50:55.860 --> 00:50:57.380]   that's Schrodinger's equation,
[00:50:57.380 --> 00:51:00.220]   and you could say that you have to,
[00:51:00.220 --> 00:51:04.300]   you have a cat which is dead and alive at the same time.
[00:51:04.300 --> 00:51:07.180]   That would be the evolution of the Schrodinger equation
[00:51:07.180 --> 00:51:08.740]   would lead to a state,
[00:51:08.740 --> 00:51:12.740]   which is the cat being dead and alive at the same time.
[00:51:12.740 --> 00:51:15.700]   And he's more or less saying, this is an absurdity.
[00:51:15.700 --> 00:51:18.420]   People nowadays say, oh, well, Schrodinger said
[00:51:18.420 --> 00:51:19.780]   you can have a cat which is dead and alive.
[00:51:19.780 --> 00:51:23.420]   It's not that, you see, he was saying, this is an absurdity.
[00:51:23.420 --> 00:51:24.740]   There's something missing.
[00:51:24.740 --> 00:51:28.660]   And that the reduction of the state
[00:51:28.660 --> 00:51:31.980]   or the collapse of the wave function or whatever it is,
[00:51:31.980 --> 00:51:34.740]   is something which has to be understood.
[00:51:34.740 --> 00:51:37.820]   It's not following the Schrodinger equation.
[00:51:37.820 --> 00:51:41.940]   It's not the way we conventionally do quantum mechanics.
[00:51:41.940 --> 00:51:43.620]   There's something more than that.
[00:51:43.620 --> 00:51:48.220]   And it's easy to quote authority here because Einstein,
[00:51:48.220 --> 00:51:54.740]   at least three of the greatest physicists of 20th century,
[00:51:54.740 --> 00:51:58.780]   who were very fundamental in developing quantum mechanics,
[00:51:58.780 --> 00:52:03.620]   Einstein, one of them, Schrodinger, another, Dirac, another.
[00:52:03.620 --> 00:52:05.500]   You have to look carefully at Dirac's writing
[00:52:05.500 --> 00:52:09.180]   'cause he didn't tend to say this out loud very much
[00:52:09.180 --> 00:52:11.300]   'cause he was very cautious about what he said.
[00:52:11.300 --> 00:52:13.460]   You find the right place and you see,
[00:52:13.460 --> 00:52:16.620]   he says quantum mechanics is a provisional theory.
[00:52:16.620 --> 00:52:21.660]   We need something which explains
[00:52:21.660 --> 00:52:23.500]   the collapse of a wave function.
[00:52:23.500 --> 00:52:26.220]   We need to go beyond the theory we have now.
[00:52:26.220 --> 00:52:29.900]   I happen to be one of the kinds of people,
[00:52:29.900 --> 00:52:31.860]   there are many, there is a whole group of people,
[00:52:31.860 --> 00:52:35.580]   they're all considered to be a bit mavericks,
[00:52:35.580 --> 00:52:38.900]   who believe that quantum mechanics needs to be modified.
[00:52:38.900 --> 00:52:41.180]   There's a small minority of those people,
[00:52:41.180 --> 00:52:42.740]   which are already a minority,
[00:52:42.740 --> 00:52:46.220]   who think that the way in which it's modified
[00:52:46.220 --> 00:52:47.540]   has to be with gravity.
[00:52:47.540 --> 00:52:51.420]   And there is an even smaller minority of those people
[00:52:51.420 --> 00:52:54.540]   who think it's the particular way that I think it is.
[00:52:54.540 --> 00:52:55.620]   So-- - So those are
[00:52:55.620 --> 00:52:57.500]   the quantum gravity folks, but what's--
[00:52:57.500 --> 00:53:00.700]   - You see, quantum gravity is already not this
[00:53:00.700 --> 00:53:02.620]   because when you say quantum gravity,
[00:53:02.620 --> 00:53:05.420]   what you really mean is quantum mechanics
[00:53:05.420 --> 00:53:07.980]   applied to gravitational theory.
[00:53:07.980 --> 00:53:10.620]   So you say, let's take this wonderful formalism
[00:53:10.620 --> 00:53:15.220]   of quantum mechanics and make gravity fit into it.
[00:53:15.220 --> 00:53:18.020]   So that is what quantum gravity is meant to be.
[00:53:18.020 --> 00:53:21.460]   Now I'm saying, you've got to be more even handed
[00:53:21.460 --> 00:53:23.140]   that gravity affects the structure
[00:53:23.140 --> 00:53:24.420]   of quantum mechanics too.
[00:53:24.420 --> 00:53:26.820]   It's not just you quantize gravity,
[00:53:26.820 --> 00:53:29.420]   you've got to gravitize quantum mechanics.
[00:53:29.420 --> 00:53:31.140]   And it's a two-way thing.
[00:53:31.140 --> 00:53:32.980]   - But then when do you even get started?
[00:53:32.980 --> 00:53:35.300]   So that you're saying that we have to figure out
[00:53:35.300 --> 00:53:37.960]   a totally new ideas in that. - Exactly.
[00:53:37.960 --> 00:53:41.260]   No, you're stuck, you don't have a theory.
[00:53:41.260 --> 00:53:42.780]   That's the trouble.
[00:53:42.780 --> 00:53:44.740]   So this is a big problem, actually,
[00:53:44.740 --> 00:53:45.940]   you say, okay, well, what's the theory?
[00:53:45.940 --> 00:53:47.260]   I don't know. (laughs)
[00:53:47.260 --> 00:53:49.420]   - So maybe in the very early days, sort of--
[00:53:49.420 --> 00:53:51.020]   - It is in the very early days,
[00:53:51.020 --> 00:53:53.780]   but just making this point. - Yes.
[00:53:53.780 --> 00:53:55.780]   - You see, Stuart Hameroff tends to be,
[00:53:55.780 --> 00:53:58.140]   oh, Penrose says that it's got to be
[00:53:58.140 --> 00:54:00.580]   a reduction of the state and so on, so let's use it.
[00:54:00.580 --> 00:54:02.100]   The trouble is Penrose doesn't say that.
[00:54:02.100 --> 00:54:03.900]   Penrose says, well, I think that.
[00:54:03.900 --> 00:54:05.460]   - Yeah, right. (laughs)
[00:54:05.460 --> 00:54:10.060]   - We have no experiments as yet, which shows that.
[00:54:10.060 --> 00:54:12.540]   There are experiments which are being thought through
[00:54:12.540 --> 00:54:15.700]   and which I'm hoping will be performed.
[00:54:15.700 --> 00:54:18.300]   There is an experiment which is being developed
[00:54:18.300 --> 00:54:22.020]   by Dirk Baumeister, who I've known for a long time,
[00:54:22.020 --> 00:54:25.300]   who shares his time between Leiden in the Netherlands
[00:54:25.300 --> 00:54:27.860]   and Santa Barbara in the US.
[00:54:27.860 --> 00:54:29.700]   And he's been working on an experiment
[00:54:29.700 --> 00:54:34.700]   which could perhaps demonstrate that quantum mechanics,
[00:54:34.700 --> 00:54:36.620]   as we now understand it,
[00:54:36.620 --> 00:54:39.020]   if you don't bring in the gravitational effects,
[00:54:39.020 --> 00:54:41.720]   has to be modified.
[00:54:41.720 --> 00:54:45.980]   - And then there's also experiments that are underway
[00:54:45.980 --> 00:54:50.620]   that kind of look at the microtubule side of things
[00:54:50.620 --> 00:54:52.580]   to see if there's, in the biology,
[00:54:52.580 --> 00:54:53.820]   you could see something like that.
[00:54:53.820 --> 00:54:55.020]   Could you briefly mention it?
[00:54:55.020 --> 00:54:58.140]   Because that's a really sort of one of the only
[00:54:58.140 --> 00:55:00.860]   experimental attempts in the very early days
[00:55:00.860 --> 00:55:02.740]   of even thinking about consciousness.
[00:55:02.740 --> 00:55:05.420]   - I think there's a very serious area here,
[00:55:05.420 --> 00:55:07.300]   which is what Stuart Hameroff is doing,
[00:55:07.300 --> 00:55:09.020]   and I think it's very important.
[00:55:09.020 --> 00:55:11.740]   One of the few places that you can really get
[00:55:11.740 --> 00:55:14.780]   a bit of a handle on what consciousness is
[00:55:14.780 --> 00:55:17.040]   is what turns it off.
[00:55:17.040 --> 00:55:20.020]   And when you're thinking about general anesthetics,
[00:55:20.020 --> 00:55:21.660]   it's very specific.
[00:55:21.660 --> 00:55:24.220]   These things turn consciousness off.
[00:55:24.220 --> 00:55:26.300]   What the hell do they do?
[00:55:26.300 --> 00:55:29.900]   Well, Stuart and a number of people who work with him
[00:55:29.900 --> 00:55:34.420]   and others happen to believe that the general anesthetics
[00:55:34.420 --> 00:55:36.740]   directly affect microtubules.
[00:55:36.740 --> 00:55:38.660]   And there is some evidence for this.
[00:55:38.660 --> 00:55:40.180]   I don't know how strong it is
[00:55:40.180 --> 00:55:43.780]   and how watertight the case is,
[00:55:43.780 --> 00:55:45.380]   but I think there is some evidence
[00:55:45.380 --> 00:55:49.140]   pointing in that kind of direction.
[00:55:49.140 --> 00:55:51.180]   It's not just an ordinary chemical process.
[00:55:51.180 --> 00:55:53.500]   There's something quite different about it.
[00:55:53.500 --> 00:55:57.420]   And one of the main candidates is that
[00:55:57.420 --> 00:56:01.640]   these anesthetic gases do affect directly microtubules.
[00:56:01.640 --> 00:56:04.460]   And how strong that evidence is,
[00:56:04.460 --> 00:56:07.100]   I wouldn't be in a position to say,
[00:56:07.100 --> 00:56:09.860]   but I think there is fairly impressive evidence.
[00:56:09.860 --> 00:56:12.700]   - And the point is the experiments are being undertaken,
[00:56:12.700 --> 00:56:13.540]   which is-- - Yes.
[00:56:13.540 --> 00:56:14.700]   I mean, that is experimental.
[00:56:14.700 --> 00:56:17.260]   You see, so it's a very clear direction
[00:56:17.260 --> 00:56:20.900]   where you can think of experiments which could indicate
[00:56:20.900 --> 00:56:23.100]   whether or not it's really microtubules,
[00:56:23.100 --> 00:56:26.100]   which the anesthetic gases directly affect.
[00:56:26.100 --> 00:56:27.300]   - That's really exciting.
[00:56:27.300 --> 00:56:30.380]   One of the sad things is, as far as I'm,
[00:56:30.380 --> 00:56:31.780]   from my outside perspective,
[00:56:31.780 --> 00:56:34.420]   is not many people are working on this.
[00:56:34.420 --> 00:56:37.260]   So there's a very, like with Stuart,
[00:56:37.260 --> 00:56:38.940]   it feels like there's very few people
[00:56:38.940 --> 00:56:41.260]   are carrying the flag forward on this.
[00:56:41.260 --> 00:56:44.860]   - I think it's not many in the sense it's a minority,
[00:56:44.860 --> 00:56:46.420]   but it's not zero anymore.
[00:56:46.420 --> 00:56:49.620]   You see, when Stuart and I were originally taught by this,
[00:56:49.620 --> 00:56:52.860]   you know, we were just us and a few of our friends,
[00:56:52.860 --> 00:56:54.220]   there weren't many people taking it,
[00:56:54.220 --> 00:56:59.220]   but it's grown into one of the main viewpoints.
[00:56:59.220 --> 00:57:04.500]   There might be about four or five or six different views
[00:57:04.500 --> 00:57:07.660]   that people hold, and it's one of them.
[00:57:07.660 --> 00:57:11.060]   So it's considered as one of the possible
[00:57:11.060 --> 00:57:13.360]   lines of thinking, yes.
[00:57:13.360 --> 00:57:15.100]   - You describe physics theories
[00:57:15.100 --> 00:57:16.940]   as falling into one of three categories,
[00:57:16.940 --> 00:57:19.860]   the superb, the useful, or the tentative.
[00:57:19.860 --> 00:57:21.700]   I like those words.
[00:57:21.700 --> 00:57:23.580]   It's a beautiful categorization.
[00:57:23.580 --> 00:57:26.980]   Do you think we'll ever have a superb theory
[00:57:26.980 --> 00:57:29.780]   of intelligence and of consciousness?
[00:57:29.780 --> 00:57:30.620]   - We might.
[00:57:30.620 --> 00:57:33.720]   We're a long way from it.
[00:57:33.720 --> 00:57:35.020]   I don't think we're even,
[00:57:35.020 --> 00:57:36.920]   whether we're in the tentative scale.
[00:57:36.920 --> 00:57:37.860]   I mean, it's--
[00:57:37.860 --> 00:57:41.260]   - You don't think we've even entered
[00:57:41.260 --> 00:57:42.460]   the realm of tentative?
[00:57:42.460 --> 00:57:43.300]   - Probably not, I think it's--
[00:57:43.300 --> 00:57:44.540]   - Yeah, that's right.
[00:57:44.540 --> 00:57:47.140]   - No, when you see this, it's so controversial.
[00:57:47.140 --> 00:57:49.180]   We don't have a clear view,
[00:57:49.180 --> 00:57:53.100]   which is accepted by a majority.
[00:57:53.100 --> 00:57:54.340]   I mean, you say, yeah, people,
[00:57:54.340 --> 00:57:57.300]   most views are computational in one form or another.
[00:57:57.300 --> 00:57:59.260]   I think it's some, but it's not very clear,
[00:57:59.260 --> 00:58:04.260]   'cause even the IIT people who think of them
[00:58:04.260 --> 00:58:07.900]   as computational, but I've heard them say,
[00:58:07.900 --> 00:58:09.980]   "No, consciousness is supposed to be not computational."
[00:58:09.980 --> 00:58:10.940]   I say, "Well, if it's not computational,
[00:58:10.940 --> 00:58:12.060]   "what in the hell is it?
[00:58:12.060 --> 00:58:14.060]   "What's going on?
[00:58:14.060 --> 00:58:17.220]   "What physical processes are going on which are that?"
[00:58:18.900 --> 00:58:21.700]   - What does it mean for something to be computational, then?
[00:58:21.700 --> 00:58:23.780]   So, is--
[00:58:23.780 --> 00:58:27.560]   - Well, there has to be a process which is,
[00:58:27.560 --> 00:58:31.820]   you see, it's very curious the way the history
[00:58:31.820 --> 00:58:34.140]   has developed in quantum mechanics,
[00:58:34.140 --> 00:58:36.060]   because very early on, people thought
[00:58:36.060 --> 00:58:37.780]   there was something to do with consciousness,
[00:58:37.780 --> 00:58:39.980]   but it was almost the other way around.
[00:58:39.980 --> 00:58:42.980]   You see, you have to say the Schrodinger equations
[00:58:42.980 --> 00:58:46.020]   says all these different alternatives happen all at once,
[00:58:46.020 --> 00:58:48.540]   and then when is it that only one of them happens?
[00:58:48.540 --> 00:58:50.820]   Well, one of the views, which was quite commonly held
[00:58:50.820 --> 00:58:53.460]   by a few distinguished quantum physicists,
[00:58:53.460 --> 00:58:56.620]   that's when a conscious being looks at the system
[00:58:56.620 --> 00:58:59.300]   or becomes aware of it, and at that point,
[00:58:59.300 --> 00:59:00.700]   it becomes one or the other.
[00:59:00.700 --> 00:59:03.700]   That's a role where consciousness
[00:59:03.700 --> 00:59:07.020]   is somehow actively reducing the state.
[00:59:07.020 --> 00:59:10.100]   My view is almost the exact opposite of that.
[00:59:10.100 --> 00:59:14.140]   It's the state reduces itself in some way which,
[00:59:14.140 --> 00:59:17.100]   some non-computational way which we don't understand,
[00:59:17.100 --> 00:59:19.180]   we don't have a proper theory of,
[00:59:19.180 --> 00:59:24.180]   and that is the building block of what consciousness is.
[00:59:24.180 --> 00:59:26.220]   So consciousness, it's the other way around.
[00:59:26.220 --> 00:59:31.220]   It depends on that choice which nature makes all the time
[00:59:31.220 --> 00:59:33.100]   when the state becomes one or the other,
[00:59:33.100 --> 00:59:36.020]   rather than the superposition of one and the other,
[00:59:36.020 --> 00:59:39.520]   and when that happens, there is what we're saying now,
[00:59:39.520 --> 00:59:43.080]   an element of proto-consciousness takes place.
[00:59:43.080 --> 00:59:45.580]   Proto-consciousness is, roughly speaking,
[00:59:45.580 --> 00:59:47.360]   the building block out of which
[00:59:47.360 --> 00:59:50.020]   actual consciousness is constructed.
[00:59:50.020 --> 00:59:53.140]   So you have these proto-conscious elements
[00:59:53.140 --> 00:59:54.980]   which are when the state decides
[00:59:54.980 --> 00:59:57.500]   to do one thing or the other,
[00:59:57.500 --> 01:00:01.500]   and that's the thing which, when organized together,
[01:00:01.500 --> 01:00:05.380]   that's the OR part in OrcOR, but the Orc part,
[01:00:05.380 --> 01:00:08.540]   that's the, the OR part, at least one can see
[01:00:08.540 --> 01:00:10.220]   where we're driving as a theory.
[01:00:10.220 --> 01:00:13.100]   You can say it's the quantum choice
[01:00:13.100 --> 01:00:14.660]   of going this way or that way,
[01:00:14.660 --> 01:00:17.660]   but the Orc part, which is the orchestration of this,
[01:00:17.660 --> 01:00:19.540]   is much more mysterious,
[01:00:19.540 --> 01:00:23.200]   and how does the brain somehow orchestrate
[01:00:23.200 --> 01:00:26.540]   all these individual OR processes
[01:00:26.540 --> 01:00:31.540]   into a genuine conscious experience?
[01:00:31.540 --> 01:00:35.060]   - And it might be something that's beautifully simple,
[01:00:35.060 --> 01:00:37.740]   but we're completely in the dark about.
[01:00:37.740 --> 01:00:40.180]   - Yeah, I think at the moment, that's the thing.
[01:00:40.180 --> 01:00:42.900]   You know, we happily put the word Orc down there
[01:00:42.900 --> 01:00:47.460]   to say orchestrated, but that's even more unclear
[01:00:47.460 --> 01:00:49.020]   what that really means.
[01:00:49.020 --> 01:00:54.020]   - Just like the word material, orchestrated, who knows?
[01:00:54.020 --> 01:00:56.180]   And we've been dancing a little bit
[01:00:56.180 --> 01:00:58.760]   between the word intelligence
[01:00:58.760 --> 01:01:00.940]   or understanding and consciousness.
[01:01:00.940 --> 01:01:03.020]   Do you kind of see those as sitting
[01:01:03.020 --> 01:01:05.780]   in the same space of mystery as we've been discussing?
[01:01:05.780 --> 01:01:07.780]   - Yes, but you see, I tend to say
[01:01:07.780 --> 01:01:12.780]   you have understanding and intelligence and awareness.
[01:01:13.620 --> 01:01:18.620]   And somehow, understanding is in the middle of it.
[01:01:18.620 --> 01:01:24.140]   You see, I like to say, could you say of an entity
[01:01:24.140 --> 01:01:27.820]   that is actually intelligent
[01:01:27.820 --> 01:01:30.340]   if it doesn't have the quality of understanding?
[01:01:30.340 --> 01:01:33.700]   Maybe I'm using terms I don't even know how to define,
[01:01:33.700 --> 01:01:34.540]   but who cares?
[01:01:34.540 --> 01:01:35.380]   I'm just relating them.
[01:01:35.380 --> 01:01:38.460]   - They're somewhat poetic, so if I somehow understand them.
[01:01:38.460 --> 01:01:40.860]   - Yes, that's right, we don't, exactly.
[01:01:40.860 --> 01:01:42.260]   - But they're not mathematical in nature.
[01:01:42.260 --> 01:01:44.060]   - Yes, you see, as a mathematician,
[01:01:44.060 --> 01:01:45.380]   I don't know how to define any of them,
[01:01:45.380 --> 01:01:47.420]   but at least I can point to the connections.
[01:01:47.420 --> 01:01:50.220]   So the idea is intelligence is something
[01:01:50.220 --> 01:01:53.940]   which I believe needs understanding.
[01:01:53.940 --> 01:01:56.380]   Otherwise, you wouldn't say it's really intelligence.
[01:01:56.380 --> 01:01:59.420]   And understanding needs awareness.
[01:01:59.420 --> 01:02:01.980]   Otherwise, you wouldn't really say it's understanding.
[01:02:01.980 --> 01:02:04.380]   Do you say of an entity that understands something
[01:02:04.380 --> 01:02:08.420]   unless it's really aware of it, in our normal usage.
[01:02:08.420 --> 01:02:11.780]   So there's a three sort of awareness, understanding,
[01:02:11.780 --> 01:02:13.820]   and intelligence.
[01:02:13.820 --> 01:02:17.540]   And I just tend to concentrate on understanding
[01:02:17.540 --> 01:02:19.780]   because that's where I can say something.
[01:02:19.780 --> 01:02:21.980]   And that's the Godel theorem, things like that.
[01:02:21.980 --> 01:02:26.460]   But what does it mean to perceive the color blue
[01:02:26.460 --> 01:02:28.500]   or something, I'm foggiest.
[01:02:28.500 --> 01:02:31.060]   That's a much more difficult question.
[01:02:31.060 --> 01:02:34.060]   I mean, is it the same if I see a color blue and you see it?
[01:02:34.060 --> 01:02:36.580]   If you're something with, what, this condition,
[01:02:36.580 --> 01:02:38.300]   what is it called?
[01:02:38.300 --> 01:02:41.540]   - Oh, where you assign a sound to a color?
[01:02:41.540 --> 01:02:42.380]   - Yeah, that's right.
[01:02:42.380 --> 01:02:44.740]   You get colors and sounds mixed up.
[01:02:44.740 --> 01:02:45.860]   And that sort of thing.
[01:02:45.860 --> 01:02:47.780]   I mean, an interesting subject.
[01:02:47.780 --> 01:02:50.860]   - But from the physics perspective,
[01:02:50.860 --> 01:02:53.220]   from the fundamentals perspective, we don't.
[01:02:53.220 --> 01:02:56.300]   - I think we're way off having much understanding
[01:02:56.300 --> 01:02:57.900]   what's going on there.
[01:02:57.900 --> 01:03:01.340]   - In your 2010 book, "Cycles of Time,"
[01:03:01.340 --> 01:03:03.540]   you suggest that another universe
[01:03:03.540 --> 01:03:06.220]   may have existed before the Big Bang.
[01:03:06.220 --> 01:03:08.780]   Can you describe this idea?
[01:03:08.780 --> 01:03:10.940]   First of all, what is the Big Bang?
[01:03:10.940 --> 01:03:13.020]   Sounds like a funny word.
[01:03:13.020 --> 01:03:17.060]   And what may have been there before it?
[01:03:17.060 --> 01:03:19.300]   - Yes, just as a matter of terminology,
[01:03:19.300 --> 01:03:21.740]   I don't like to call it another universe.
[01:03:21.740 --> 01:03:23.020]   'Cause when you have another universe,
[01:03:23.020 --> 01:03:25.500]   you think of it kind of quite separate from us.
[01:03:25.500 --> 01:03:28.660]   But these things, they're not separate.
[01:03:28.660 --> 01:03:31.820]   Now, the Big Bang, conventional theory.
[01:03:31.820 --> 01:03:34.780]   You see, I was actually brought up in the sense
[01:03:34.780 --> 01:03:36.900]   of when I started getting interested in cosmology,
[01:03:36.900 --> 01:03:39.260]   there was a thing called the steady state model,
[01:03:39.260 --> 01:03:41.380]   which was sort of philosophically very interesting.
[01:03:41.380 --> 01:03:43.020]   And there wasn't a Big Bang in that theory,
[01:03:43.020 --> 01:03:46.980]   that somehow new material was created all the time
[01:03:46.980 --> 01:03:48.100]   in the form of hydrogen,
[01:03:48.100 --> 01:03:50.540]   and the universe kept on expanding, expanding, expanding,
[01:03:50.540 --> 01:03:52.580]   and there was room for more hydrogen.
[01:03:52.580 --> 01:03:54.980]   It was a rather philosophically nice picture.
[01:03:54.980 --> 01:03:59.140]   It was disproved when the Big Bang,
[01:03:59.140 --> 01:04:01.860]   well, when I say the Big Bang,
[01:04:01.860 --> 01:04:04.900]   this was theoretically discovered
[01:04:04.900 --> 01:04:07.900]   by people trying to solve Einstein's equations
[01:04:07.900 --> 01:04:09.340]   and apply it to cosmology.
[01:04:09.340 --> 01:04:10.700]   Einstein didn't like the idea.
[01:04:10.700 --> 01:04:14.340]   He liked a universe which was there all the time.
[01:04:14.340 --> 01:04:16.740]   And he had a model which was there all the time.
[01:04:16.740 --> 01:04:20.740]   But then there was this discovery, accidental discovery,
[01:04:20.740 --> 01:04:25.140]   a very important discovery, of this microwave background.
[01:04:25.140 --> 01:04:28.460]   And if you, there's the crackle on your television screen,
[01:04:28.460 --> 01:04:32.740]   which is already sensing this microwave background,
[01:04:32.740 --> 01:04:35.140]   which is coming at us from all directions.
[01:04:35.140 --> 01:04:37.740]   And you can trace it back and back and back and back,
[01:04:37.740 --> 01:04:40.820]   and it came from a very early stage of the universe.
[01:04:40.820 --> 01:04:43.700]   Well, it's part of the Big Bang theory.
[01:04:43.700 --> 01:04:45.660]   The Big Bang theory was when people tried
[01:04:45.660 --> 01:04:47.660]   to solve Einstein's equations.
[01:04:47.660 --> 01:04:50.780]   They really found you had to have this initial state
[01:04:50.780 --> 01:04:52.420]   where the universe, it used to be called
[01:04:52.420 --> 01:04:55.340]   the primordial atom and things like this.
[01:04:55.340 --> 01:04:57.860]   There's Friedmann and Lemaitre.
[01:04:57.860 --> 01:05:01.420]   Friedmann was a Russian, Lemaitre was a Belgian.
[01:05:01.420 --> 01:05:04.780]   And they independently, well, basically Friedmann first.
[01:05:04.780 --> 01:05:08.860]   And Lemaitre talked about the initial state,
[01:05:08.860 --> 01:05:11.420]   which is a very, very concentrated initial state,
[01:05:11.420 --> 01:05:13.500]   which seemed to be the origin of the universe.
[01:05:13.500 --> 01:05:14.820]   - Primordial atom, that's a nice--
[01:05:14.820 --> 01:05:16.740]   - Primordial atom is what he called it, yes.
[01:05:16.740 --> 01:05:17.620]   - Beautiful term.
[01:05:17.620 --> 01:05:20.220]   - And then it became, well, Fred Hoyle used the term
[01:05:20.220 --> 01:05:22.580]   Big Bang in a kind of derogatory sense.
[01:05:22.580 --> 01:05:25.100]   - Just like with the Schrodinger and the cats, right?
[01:05:25.100 --> 01:05:28.300]   - Yes, it's like sort of, it got picked up on,
[01:05:28.300 --> 01:05:30.780]   whereas it wasn't his intention originally.
[01:05:30.780 --> 01:05:33.620]   But then the evidence piled up and piled up.
[01:05:33.620 --> 01:05:36.380]   And one of my friends that I learned a lot from
[01:05:36.380 --> 01:05:38.060]   and when I was in Cambridge was Dennis Schama.
[01:05:38.060 --> 01:05:40.580]   He was a great proponent of steady state.
[01:05:40.580 --> 01:05:43.340]   And then he got converted, he said, "No, I'm sorry.
[01:05:43.340 --> 01:05:44.460]   "I had a great respect for him."
[01:05:44.460 --> 01:05:46.700]   He went around lecturing, said, "I was wrong.
[01:05:46.700 --> 01:05:48.800]   "The steady state model doesn't work.
[01:05:48.800 --> 01:05:50.820]   "There was this Big Bang.
[01:05:50.820 --> 01:05:53.520]   "And this microwave background that you see,
[01:05:53.520 --> 01:05:55.340]   "okay, it's not actually quite the Big Bang."
[01:05:55.340 --> 01:05:58.620]   When I said not quite, it's about 380,000 years
[01:05:58.620 --> 01:06:01.440]   after the Big Bang, but that's what you see.
[01:06:01.440 --> 01:06:03.200]   But then you have to have had this Big Bang
[01:06:03.200 --> 01:06:05.740]   before it in order to make the equations work.
[01:06:05.740 --> 01:06:09.660]   And it works beautifully, except for one little thing,
[01:06:09.660 --> 01:06:11.060]   which is this thing called inflation,
[01:06:11.060 --> 01:06:14.060]   which people had to put into it to make it work.
[01:06:14.060 --> 01:06:16.860]   When I first heard of it, I didn't like it at all.
[01:06:16.860 --> 01:06:17.940]   - What's inflation?
[01:06:17.940 --> 01:06:20.360]   - Inflation is it in the first,
[01:06:20.360 --> 01:06:22.720]   I'm gonna give you a very tiny number.
[01:06:22.720 --> 01:06:25.180]   Think of a second, that's not very long.
[01:06:25.180 --> 01:06:26.960]   Now I'm gonna give you a fraction of a second,
[01:06:26.960 --> 01:06:29.460]   one over a number.
[01:06:29.460 --> 01:06:32.900]   This number has 32 digits.
[01:06:32.900 --> 01:06:37.720]   Between, well, let's say between 36 and 32 digits.
[01:06:37.720 --> 01:06:42.720]   Tiny, tiny time between those two tiny ridiculous seconds,
[01:06:42.720 --> 01:06:45.600]   fraction of a second, the universe was supposed
[01:06:45.600 --> 01:06:49.000]   to have expanded in this exponential way.
[01:06:49.000 --> 01:06:51.360]   An enormous way, for no apparent reason,
[01:06:51.360 --> 01:06:53.520]   you had to invent a particular thing
[01:06:53.520 --> 01:06:56.040]   called the inflaton field to make it do it.
[01:06:56.040 --> 01:06:58.180]   And I thought this is completely crazy.
[01:06:58.180 --> 01:07:01.980]   There are reasons why people stuck with this idea.
[01:07:01.980 --> 01:07:04.200]   You see, the thing is that I formed my model
[01:07:04.200 --> 01:07:07.680]   for reasons which are very fundamental, if you like.
[01:07:07.680 --> 01:07:10.420]   It has to do this very fundamental principle,
[01:07:10.420 --> 01:07:13.800]   which is known as the second law of thermodynamics.
[01:07:13.800 --> 01:07:16.120]   The second law of thermodynamics says more or less,
[01:07:16.120 --> 01:07:18.700]   things get more and more random as time goes on.
[01:07:18.700 --> 01:07:22.080]   Now, another way of saying exactly the same thing
[01:07:22.080 --> 01:07:25.400]   is things get less and less random as things go back.
[01:07:25.400 --> 01:07:28.040]   As you go back in time, they get less and less random.
[01:07:28.040 --> 01:07:30.100]   So you go back and back and back and back.
[01:07:30.100 --> 01:07:32.040]   And the earliest thing you can directly see
[01:07:32.040 --> 01:07:33.560]   is this microwave background.
[01:07:33.560 --> 01:07:37.560]   What's one of the most striking features of it
[01:07:37.560 --> 01:07:39.240]   is that it's random.
[01:07:39.240 --> 01:07:42.500]   It has this, what you call this spectrum of,
[01:07:42.500 --> 01:07:47.800]   which is what's called the Planck spectrum of frequencies,
[01:07:47.800 --> 01:07:49.640]   different intensities for different frequencies.
[01:07:49.640 --> 01:07:53.300]   And it's this wonderful curve due to Max Planck.
[01:07:53.300 --> 01:07:54.680]   And what's it telling you?
[01:07:54.680 --> 01:07:58.000]   It's telling you that the entropy is at a maximum.
[01:07:58.000 --> 01:08:02.100]   Started off at a maximum and it's going up ever since.
[01:08:02.100 --> 01:08:03.880]   I call that the mammoth in the room.
[01:08:03.880 --> 01:08:05.560]   I mean, it's a paradox.
[01:08:05.560 --> 01:08:07.280]   - A mammoth, yeah, it is.
[01:08:07.280 --> 01:08:10.480]   - And so people, why don't cosmologists worry about this?
[01:08:10.480 --> 01:08:11.920]   So I worried about it.
[01:08:11.920 --> 01:08:14.920]   And then I thought, well, it's not really a paradox
[01:08:14.920 --> 01:08:19.040]   because you're looking at matter and radiation
[01:08:19.040 --> 01:08:20.680]   at a maximum entropy state.
[01:08:20.680 --> 01:08:25.360]   What you're not seeing directly in that is the gravitation.
[01:08:25.360 --> 01:08:28.440]   It's gravitation, which is not thermalized.
[01:08:28.440 --> 01:08:32.000]   The gravitation was very, very low entropy.
[01:08:32.000 --> 01:08:34.440]   And it's low entropy by the uniformity.
[01:08:34.440 --> 01:08:35.920]   And you see that in the microwave too.
[01:08:35.920 --> 01:08:38.240]   It's very uniform over the whole sky.
[01:08:38.240 --> 01:08:40.800]   I'm compressing a long story into a very short few sentences.
[01:08:40.800 --> 01:08:42.000]   - And doing a great job, yeah.
[01:08:42.000 --> 01:08:45.680]   - So what I'm saying is that there's a huge puzzle.
[01:08:45.680 --> 01:08:50.600]   Why was gravity in this very low entropy state,
[01:08:50.600 --> 01:08:55.160]   very highly organized state, everything else was all random?
[01:08:55.160 --> 01:08:58.960]   And that, to me, was the biggest problem in cosmology.
[01:08:58.960 --> 01:09:02.760]   The biggest problem, nobody seems to even worry about it.
[01:09:02.760 --> 01:09:04.440]   People say they solved all the problems
[01:09:04.440 --> 01:09:05.520]   and they don't even worry about it.
[01:09:05.520 --> 01:09:07.320]   They think inflation solves it.
[01:09:07.320 --> 01:09:08.720]   It doesn't, it can't.
[01:09:08.720 --> 01:09:11.240]   Because it's just--
[01:09:11.240 --> 01:09:14.680]   - Just to clarify, that was your problem
[01:09:14.680 --> 01:09:18.160]   with the inflation describing some aspect
[01:09:18.160 --> 01:09:20.520]   of the moments right after the Big Bang?
[01:09:20.520 --> 01:09:22.240]   - Inflation is supposed to stretch it out
[01:09:22.240 --> 01:09:23.960]   and make it all uniform, you see.
[01:09:23.960 --> 01:09:25.440]   It doesn't do it because it can only do it
[01:09:25.440 --> 01:09:27.920]   if it's uniform already at the beginning.
[01:09:27.920 --> 01:09:28.760]   You just have to look at it.
[01:09:28.760 --> 01:09:30.400]   I can't go into the details.
[01:09:30.400 --> 01:09:31.720]   But it doesn't solve it.
[01:09:31.720 --> 01:09:33.880]   And it was completely clear to me it doesn't solve it.
[01:09:33.880 --> 01:09:36.880]   - But where does the conformal cyclic cosmology of--
[01:09:36.880 --> 01:09:37.720]   - Yeah, well--
[01:09:37.720 --> 01:09:39.800]   - Starting to talk about something before--
[01:09:39.800 --> 01:09:40.640]   - Yes.
[01:09:40.640 --> 01:09:41.480]   - That singularity--
[01:09:41.480 --> 01:09:44.240]   - Well, I began, I was just thinking to myself,
[01:09:44.240 --> 01:09:47.680]   how boring this universe is going to be.
[01:09:47.680 --> 01:09:49.520]   You've got this exponential expansion.
[01:09:49.520 --> 01:09:51.520]   This was discovered early in the,
[01:09:51.520 --> 01:09:56.520]   in this century, 21st century.
[01:09:56.520 --> 01:10:01.040]   People discovered that these supernova exploding stars
[01:10:01.040 --> 01:10:04.560]   showed that the universe is actually undergoing
[01:10:04.560 --> 01:10:06.600]   this exponential expansion.
[01:10:06.600 --> 01:10:09.540]   So it's a self-similar expansion.
[01:10:09.540 --> 01:10:14.280]   And it seems to be a feature of this term
[01:10:14.280 --> 01:10:17.120]   that Einstein introduced into his cosmology
[01:10:17.120 --> 01:10:18.520]   for the wrong reason.
[01:10:18.520 --> 01:10:20.600]   He wanted a universe that was static.
[01:10:20.600 --> 01:10:23.480]   He put this new term into his cosmology
[01:10:23.480 --> 01:10:24.440]   to make it make sense.
[01:10:24.440 --> 01:10:26.480]   It's called the cosmological constant.
[01:10:26.480 --> 01:10:28.280]   And then when he got convinced
[01:10:28.280 --> 01:10:29.560]   that the universe had a big bang,
[01:10:29.560 --> 01:10:30.880]   he retracted it,
[01:10:30.880 --> 01:10:33.280]   complaining that this was his greatest blunder.
[01:10:33.280 --> 01:10:34.640]   The trouble is it wasn't a blunder.
[01:10:34.640 --> 01:10:35.880]   It was actually right.
[01:10:35.880 --> 01:10:36.720]   (laughs)
[01:10:36.720 --> 01:10:37.880]   Very ironic.
[01:10:37.880 --> 01:10:40.240]   And so the universe seems to be behaving
[01:10:40.240 --> 01:10:41.960]   with this cosmological constant.
[01:10:41.960 --> 01:10:45.080]   Okay, so this universe is expanding and expanding.
[01:10:45.080 --> 01:10:46.320]   What's going to happen in the future?
[01:10:46.320 --> 01:10:48.840]   Well, it gets more and more boring for a while.
[01:10:48.840 --> 01:10:50.560]   What's the most interesting thing in the universe?
[01:10:50.560 --> 01:10:51.840]   Well, there's black holes.
[01:10:51.840 --> 01:10:53.640]   The black holes more or less gulp down
[01:10:53.640 --> 01:10:56.640]   entire clusters of galaxies.
[01:10:56.640 --> 01:10:59.080]   The cluster, it'll swallow up most of our galaxy.
[01:10:59.080 --> 01:11:01.440]   We will run into our Andromeda galaxy's black hole.
[01:11:01.440 --> 01:11:03.640]   That black hole will swallow our one.
[01:11:03.640 --> 01:11:04.680]   They'll get bigger and bigger,
[01:11:04.680 --> 01:11:07.080]   and they'll basically swallow up
[01:11:07.080 --> 01:11:09.040]   the whole cluster of galaxies,
[01:11:09.040 --> 01:11:11.800]   gulp it all down, pretty well all, most of it,
[01:11:11.800 --> 01:11:13.720]   maybe not all, most of it.
[01:11:13.720 --> 01:11:15.280]   Okay, and then that'll happen to,
[01:11:15.280 --> 01:11:16.760]   there'll be just these black holes around,
[01:11:16.760 --> 01:11:18.360]   pretty boring, but still not as boring
[01:11:18.360 --> 01:11:19.560]   as it's going to get.
[01:11:19.560 --> 01:11:20.600]   It's going to get more boring
[01:11:20.600 --> 01:11:22.120]   because these black holes, you wait,
[01:11:22.120 --> 01:11:23.520]   you wait, and you wait, and you wait,
[01:11:23.520 --> 01:11:26.080]   and you wait, an unbelievable length of time,
[01:11:26.080 --> 01:11:30.240]   and Hawking's black hole evaporation starts to come in.
[01:11:30.240 --> 01:11:34.280]   And the black holes, you just, it's incredibly tedious.
[01:11:34.280 --> 01:11:36.280]   Finally evaporate away.
[01:11:36.280 --> 01:11:39.640]   Each one goes away, disappears with a pop at the end.
[01:11:39.640 --> 01:11:40.920]   What could be more boring?
[01:11:40.920 --> 01:11:41.960]   It was boring then.
[01:11:41.960 --> 01:11:43.800]   Now this is really boring.
[01:11:43.800 --> 01:11:46.560]   There's nothing, not even black holes.
[01:11:46.560 --> 01:11:48.880]   Universe gets colder and colder and colder and colder.
[01:11:48.880 --> 01:11:52.400]   And I thought, this is very, very boring.
[01:11:52.400 --> 01:11:54.480]   Now that's not science, is it?
[01:11:54.480 --> 01:11:56.360]   But it's emotional.
[01:11:56.360 --> 01:11:59.560]   So I thought, who's going to be bored by this universe?
[01:11:59.560 --> 01:12:01.520]   Not us, we won't be around.
[01:12:01.520 --> 01:12:04.080]   It'll be mostly photons running around.
[01:12:04.080 --> 01:12:06.160]   And what the photons do, they don't get bored
[01:12:06.160 --> 01:12:08.760]   because it's part of relativity, you see.
[01:12:08.760 --> 01:12:10.840]   It's not really that they don't experience anything,
[01:12:10.840 --> 01:12:12.360]   that's not the point.
[01:12:12.360 --> 01:12:15.800]   Photons get right out to infinity
[01:12:15.800 --> 01:12:18.560]   without experience any time.
[01:12:18.560 --> 01:12:21.000]   It's the way relativity works.
[01:12:21.000 --> 01:12:23.480]   And this was part of what I used to do in my old days
[01:12:23.480 --> 01:12:25.240]   when I was looking at gravitational radiation
[01:12:25.240 --> 01:12:27.480]   and how things behaved to infinity.
[01:12:27.480 --> 01:12:30.040]   Infinity is just like another place.
[01:12:30.040 --> 01:12:31.880]   You can squash it down,
[01:12:31.880 --> 01:12:34.440]   as long as you don't have any mass in the world,
[01:12:34.440 --> 01:12:36.480]   infinity is just another place.
[01:12:36.480 --> 01:12:39.720]   The photons get there, the gravitons get there.
[01:12:39.720 --> 01:12:40.560]   What do they get?
[01:12:40.560 --> 01:12:42.120]   They run to infinity.
[01:12:42.120 --> 01:12:44.320]   They say, well, now I'm here, what do I?
[01:12:44.320 --> 01:12:46.680]   There's something on the other side, is there?
[01:12:46.680 --> 01:12:48.640]   In the usual view, it's just a mathematical notion.
[01:12:48.640 --> 01:12:49.640]   There's nothing on the other side,
[01:12:49.640 --> 01:12:51.720]   that's just the boundary of it.
[01:12:51.720 --> 01:12:55.000]   A nice example is this beautiful series of pictures
[01:12:55.000 --> 01:12:57.200]   by the Dutch artist, M.C. Escher.
[01:12:57.200 --> 01:12:59.680]   You may know them, the ones called Circle Limits.
[01:12:59.680 --> 01:13:02.480]   They're a very famous one with the angels and the devils.
[01:13:02.480 --> 01:13:04.200]   And you can see them crowding and crowding
[01:13:04.200 --> 01:13:06.000]   and crowding up to the edge.
[01:13:06.000 --> 01:13:07.440]   Now, the kind of geometry
[01:13:07.440 --> 01:13:10.160]   that these angels and devils inhabit,
[01:13:10.160 --> 01:13:11.520]   that's their infinity.
[01:13:11.520 --> 01:13:14.120]   But from our perspective,
[01:13:14.120 --> 01:13:16.840]   infinity is just a place.
[01:13:16.840 --> 01:13:17.680]   Okay, there is--
[01:13:17.680 --> 01:13:20.200]   - I'm sorry, can you just take a brief pause?
[01:13:20.200 --> 01:13:21.040]   - Yes.
[01:13:21.040 --> 01:13:22.840]   - In just the words you're saying,
[01:13:22.840 --> 01:13:24.080]   infinity is just a place.
[01:13:24.080 --> 01:13:26.960]   So, for the most part, infinity,
[01:13:26.960 --> 01:13:28.760]   sort of even just going back,
[01:13:28.760 --> 01:13:31.200]   infinity is a mathematical concept?
[01:13:31.200 --> 01:13:32.040]   - I think this is one of the--
[01:13:32.040 --> 01:13:35.480]   - You think there's an actual physical manifestation?
[01:13:35.480 --> 01:13:38.400]   In which way does infinity ever manifest itself
[01:13:38.400 --> 01:13:40.120]   in our physical universe?
[01:13:40.120 --> 01:13:41.760]   - Well, it does in various places.
[01:13:41.760 --> 01:13:43.400]   You see, it's a thing that,
[01:13:43.400 --> 01:13:44.480]   if you're not a mathematician,
[01:13:44.480 --> 01:13:45.320]   you think, oh, infinity,
[01:13:45.320 --> 01:13:46.480]   I can't think about that.
[01:13:46.480 --> 01:13:48.680]   Mathematicians think about infinity all the time.
[01:13:48.680 --> 01:13:49.880]   They get used to the idea,
[01:13:49.880 --> 01:13:50.880]   and they just play around
[01:13:50.880 --> 01:13:52.280]   with different kinds of infinities,
[01:13:52.280 --> 01:13:54.200]   and it becomes no problem.
[01:13:54.200 --> 01:13:57.240]   But you just have to take my word for it.
[01:13:57.240 --> 01:13:58.440]   Now, one of the things is,
[01:13:58.440 --> 01:14:00.800]   you see, you take a Euclidean geometry.
[01:14:00.800 --> 01:14:02.680]   Well, it just keeps on, keeps on, keeps on going,
[01:14:02.680 --> 01:14:04.640]   and it goes out to infinity.
[01:14:04.640 --> 01:14:06.160]   Now, there's other kinds of geometry,
[01:14:06.160 --> 01:14:09.240]   and this is what's called hyperbolic geometry.
[01:14:09.240 --> 01:14:10.800]   It's a bit like Euclidean geometry,
[01:14:10.800 --> 01:14:12.120]   it's a little bit different.
[01:14:12.120 --> 01:14:14.640]   It's like what Escher was trying to describe
[01:14:14.640 --> 01:14:17.240]   in his "Angels and Devils."
[01:14:17.240 --> 01:14:19.800]   And he learned about this from Coxeter,
[01:14:19.800 --> 01:14:22.720]   and he think that's a very nice thing,
[01:14:22.720 --> 01:14:25.000]   and so I represent this infinity
[01:14:25.000 --> 01:14:26.800]   to this kind of geometry.
[01:14:26.800 --> 01:14:28.160]   So it's not quite Euclidean geometry,
[01:14:28.160 --> 01:14:29.240]   it's a bit like it,
[01:14:29.240 --> 01:14:31.840]   that the angels and the devils inhabit.
[01:14:31.840 --> 01:14:33.400]   And their infinity,
[01:14:33.400 --> 01:14:35.120]   by this nice transformation,
[01:14:35.120 --> 01:14:37.680]   you squash their infinity down,
[01:14:37.680 --> 01:14:40.480]   so you can draw it as this nice circle boundary
[01:14:40.480 --> 01:14:43.200]   to their universe.
[01:14:43.200 --> 01:14:45.200]   Now, from our outside perspective,
[01:14:45.200 --> 01:14:48.280]   we can see their infinity as this boundary.
[01:14:48.280 --> 01:14:53.080]   Now, what I'm saying is that it's very like that.
[01:14:53.080 --> 01:14:56.040]   The infinity that we might experience
[01:14:56.040 --> 01:14:58.200]   like those angels and devils in their world
[01:14:58.200 --> 01:15:01.960]   can be thought of as a boundary.
[01:15:01.960 --> 01:15:04.600]   Now, I found this a very useful way
[01:15:04.600 --> 01:15:07.920]   of talking about radiation, gravitational radiation,
[01:15:07.920 --> 01:15:09.000]   and things like that.
[01:15:09.880 --> 01:15:12.560]   It was a trick, mathematical trick.
[01:15:12.560 --> 01:15:13.840]   So now what I'm saying is that
[01:15:13.840 --> 01:15:17.440]   that mathematical trick becomes real,
[01:15:17.440 --> 01:15:19.600]   that somehow the photons,
[01:15:19.600 --> 01:15:22.280]   they need to go somewhere,
[01:15:22.280 --> 01:15:25.120]   because from their perspective,
[01:15:25.120 --> 01:15:27.160]   infinity is just another place.
[01:15:27.160 --> 01:15:30.640]   Now, this is a difficult idea to get your mind around,
[01:15:30.640 --> 01:15:34.040]   so that's one of the reasons cosmologists
[01:15:34.040 --> 01:15:37.160]   are finding a lot of trouble taking me seriously.
[01:15:37.160 --> 01:15:39.880]   But to me, it's not such a wild idea.
[01:15:39.880 --> 01:15:42.080]   What's on the other side of that infinity?
[01:15:42.080 --> 01:15:45.280]   You have to think, why am I allowed to think of this?
[01:15:45.280 --> 01:15:48.880]   Because photons don't have any mass.
[01:15:48.880 --> 01:15:53.560]   And we in physics have beautiful ways of measuring time.
[01:15:53.560 --> 01:15:55.880]   There are incredibly precise clocks,
[01:15:55.880 --> 01:15:59.560]   atomic and nuclear clocks, unbelievably precise.
[01:15:59.560 --> 01:16:01.600]   Why are they so precise?
[01:16:01.600 --> 01:16:04.600]   Because of the two most famous equations
[01:16:04.600 --> 01:16:06.760]   of 20th century physics.
[01:16:06.760 --> 01:16:09.960]   One of them is Einstein's E equals MC squared.
[01:16:09.960 --> 01:16:11.040]   What's that tell us?
[01:16:11.040 --> 01:16:13.920]   Energy and mass are equivalent.
[01:16:13.920 --> 01:16:16.600]   The other one is even older than that,
[01:16:16.600 --> 01:16:18.480]   still 20th century, only just.
[01:16:18.480 --> 01:16:22.600]   Max Planck, E equals h nu.
[01:16:22.600 --> 01:16:26.400]   Nu is a frequency, h is a constant, again, like C.
[01:16:26.400 --> 01:16:27.960]   E is energy.
[01:16:27.960 --> 01:16:30.640]   Energy and frequency are equivalent.
[01:16:30.640 --> 01:16:33.040]   Put the two together,
[01:16:33.040 --> 01:16:34.920]   energy and mass are equivalent, Einstein,
[01:16:34.920 --> 01:16:37.280]   energy and frequency are equivalent, Max Planck.
[01:16:37.280 --> 01:16:41.400]   Put the two together, mass and frequency are equivalent.
[01:16:41.400 --> 01:16:44.040]   Absolutely basic physical principle.
[01:16:44.040 --> 01:16:47.480]   If you have a massive entity, a massive particle,
[01:16:47.480 --> 01:16:51.960]   it is a clock with a very, very precise frequency.
[01:16:51.960 --> 01:16:54.960]   It's not, you can't directly use it,
[01:16:54.960 --> 01:16:56.080]   you have to scale it down.
[01:16:56.080 --> 01:16:57.600]   So your atomic and nuclear clocks,
[01:16:57.600 --> 01:16:59.120]   but that's the basic principle.
[01:16:59.120 --> 01:17:02.200]   You scale it down to something you can actually perceive.
[01:17:02.200 --> 01:17:03.800]   But it's the same principle.
[01:17:03.800 --> 01:17:06.760]   If you have mass, you have beautiful clocks.
[01:17:06.760 --> 01:17:10.320]   But the other side of that coin is,
[01:17:10.320 --> 01:17:13.920]   if you don't have mass, you don't have clocks.
[01:17:13.920 --> 01:17:18.040]   If you don't have clocks, you don't have rulers.
[01:17:18.040 --> 01:17:20.160]   You don't have scale.
[01:17:20.160 --> 01:17:21.360]   - So you don't have space and time.
[01:17:21.360 --> 01:17:24.360]   - You don't have a measure of the scale of space and time.
[01:17:24.360 --> 01:17:26.480]   - Oh, scale of space and time.
[01:17:26.480 --> 01:17:29.320]   - You do have the structure,
[01:17:29.320 --> 01:17:30.840]   what's called the conformal structure.
[01:17:30.840 --> 01:17:33.080]   You see, it's what the angels and devils have.
[01:17:33.080 --> 01:17:35.040]   If you look at the eye of the devil,
[01:17:35.040 --> 01:17:36.880]   no matter how close to the boundary it is,
[01:17:36.880 --> 01:17:40.800]   it has the same shape, but it has a different size.
[01:17:40.800 --> 01:17:43.360]   So you can scale up and you can scale down,
[01:17:43.360 --> 01:17:45.280]   but you mustn't change the shape.
[01:17:45.280 --> 01:17:48.520]   So it's basically the same idea,
[01:17:48.520 --> 01:17:50.720]   but applied to space-time now.
[01:17:50.720 --> 01:17:52.560]   In the very remote future,
[01:17:52.560 --> 01:17:55.680]   you have things which don't measure the scale,
[01:17:55.680 --> 01:17:58.440]   but the shape, if you like, is still there.
[01:17:58.440 --> 01:17:59.920]   Now that's in the remote future.
[01:17:59.920 --> 01:18:01.960]   Now I'm gonna do the exact opposite.
[01:18:01.960 --> 01:18:04.640]   Now I'm gonna go way back into the Big Bang.
[01:18:04.640 --> 01:18:08.080]   Now as you get there, things get hotter and hotter,
[01:18:08.080 --> 01:18:09.400]   denser and denser.
[01:18:09.400 --> 01:18:13.000]   What's the universe dominated by?
[01:18:13.000 --> 01:18:16.560]   Particles moving around almost with the speed of light.
[01:18:16.560 --> 01:18:19.040]   When they get almost with the speed of light,
[01:18:19.040 --> 01:18:21.800]   okay, they begin to lose the mass too.
[01:18:21.800 --> 01:18:24.240]   So for a completely opposite reason,
[01:18:24.240 --> 01:18:26.840]   they lose the sense of scale as well.
[01:18:26.840 --> 01:18:31.840]   So my crazy idea is the Big Bang and a remote future,
[01:18:32.200 --> 01:18:33.440]   they seem completely different.
[01:18:33.440 --> 01:18:36.080]   One is extremely dense, extremely hot.
[01:18:36.080 --> 01:18:39.720]   The other's very, very rarefied and very, very cold.
[01:18:39.720 --> 01:18:42.760]   But if you squash one down by this conformal scaling,
[01:18:42.760 --> 01:18:44.240]   you get the other.
[01:18:44.240 --> 01:18:47.940]   So although they look and feel very different,
[01:18:47.940 --> 01:18:50.360]   they're really almost the same.
[01:18:50.360 --> 01:18:53.120]   The remote future on the other side,
[01:18:53.120 --> 01:18:55.520]   I'm claiming is that, where do the photons go?
[01:18:55.520 --> 01:18:57.200]   They go into the next Big Bang.
[01:18:57.200 --> 01:19:01.160]   You've got to get your mind around that crazy idea.
[01:19:01.160 --> 01:19:03.120]   - Taking a step on the other side
[01:19:03.120 --> 01:19:05.600]   of the place that is infinity.
[01:19:05.600 --> 01:19:07.200]   Okay, but-- - Yes.
[01:19:07.200 --> 01:19:09.000]   So I'm saying the other side of our Big Bang,
[01:19:09.000 --> 01:19:10.600]   now I'm going back into the Big Bang.
[01:19:10.600 --> 01:19:12.360]   - Back, backwards. - There was the remote future
[01:19:12.360 --> 01:19:13.760]   of a previous eon.
[01:19:13.760 --> 01:19:15.040]   - Previous eon.
[01:19:15.040 --> 01:19:17.560]   - And what I'm saying is that previous eon,
[01:19:17.560 --> 01:19:20.200]   there are signals coming through to us,
[01:19:20.200 --> 01:19:23.760]   which we can see and which we do see.
[01:19:23.760 --> 01:19:25.100]   And these are both signals,
[01:19:25.100 --> 01:19:29.440]   the two main signals are to do with black holes.
[01:19:29.440 --> 01:19:33.040]   One of them is the collisions between black holes,
[01:19:33.040 --> 01:19:35.200]   and as they spiral into each other,
[01:19:35.200 --> 01:19:36.960]   they release a lot of energy
[01:19:36.960 --> 01:19:39.120]   in the form of gravitational waves.
[01:19:39.120 --> 01:19:42.200]   Those gravitational waves get through
[01:19:42.200 --> 01:19:44.160]   in a certain form into the next eon.
[01:19:44.160 --> 01:19:46.240]   - That's fascinating that there's some,
[01:19:46.240 --> 01:19:49.040]   I mean, maybe you can correct me if I'm wrong,
[01:19:49.040 --> 01:19:51.560]   but that means that some information can travel--
[01:19:51.560 --> 01:19:53.320]   - Yes. - From another eon.
[01:19:53.320 --> 01:19:54.240]   - Exactly.
[01:19:54.240 --> 01:19:58.880]   - That is fascinating.
[01:19:58.880 --> 01:20:01.720]   I mean, I've seen somewhere described
[01:20:01.720 --> 01:20:05.840]   sort of the discussion of the Fermi paradox,
[01:20:05.840 --> 01:20:08.280]   that if there's intelligent life--
[01:20:08.280 --> 01:20:09.840]   - Yes.
[01:20:09.840 --> 01:20:13.160]   - Communication immediately takes you there, so--
[01:20:13.160 --> 01:20:17.000]   - We have a paper, my colleague, Vahe Guzajan,
[01:20:17.000 --> 01:20:19.840]   who I worked with on these ideas for a while,
[01:20:19.840 --> 01:20:21.760]   we have a crazy paper on that, yes.
[01:20:21.760 --> 01:20:23.560]   Looking at the Fermi paradox, yes.
[01:20:23.560 --> 01:20:26.000]   - Right, so if the universe is just cycling
[01:20:26.000 --> 01:20:27.280]   over and over and over,
[01:20:27.280 --> 01:20:32.280]   punctuated by the singularity of the Big Bang,
[01:20:32.280 --> 01:20:34.920]   and then intelligent,
[01:20:34.920 --> 01:20:36.840]   or any kind of intelligent systems
[01:20:36.840 --> 01:20:39.640]   can communicate through from eon to eon,
[01:20:39.640 --> 01:20:44.640]   why haven't we heard anything from our alien friends?
[01:20:44.640 --> 01:20:47.000]   - 'Cause we don't know how to look.
[01:20:47.000 --> 01:20:48.920]   - That's fundamentally the reason, is we--
[01:20:48.920 --> 01:20:51.840]   - I don't know, you see, it's speculation.
[01:20:51.840 --> 01:20:55.520]   I mean, the SETI program is a reasonable thing to do,
[01:20:55.520 --> 01:20:57.000]   but still speculation.
[01:20:57.000 --> 01:21:01.880]   It's trying to say, okay, maybe not too far away
[01:21:01.880 --> 01:21:05.640]   was a civilization which got there first, before us,
[01:21:05.640 --> 01:21:08.760]   early enough that they could send us signals,
[01:21:08.760 --> 01:21:11.080]   but how far away would you need to go before,
[01:21:11.080 --> 01:21:14.520]   I mean, I don't know, we have so little knowledge about that
[01:21:14.520 --> 01:21:16.960]   we haven't seen any signals yet, but it's worth looking.
[01:21:16.960 --> 01:21:18.280]   It's worth looking.
[01:21:18.280 --> 01:21:19.440]   What I'm trying to say,
[01:21:19.440 --> 01:21:22.600]   here's another possible place where you might look.
[01:21:22.600 --> 01:21:24.600]   Now you're not looking at civilizations
[01:21:24.600 --> 01:21:26.240]   which got there first.
[01:21:26.240 --> 01:21:27.960]   You're looking at those civilizations
[01:21:27.960 --> 01:21:31.240]   which were so successful, probably a lot more successful
[01:21:31.240 --> 01:21:33.920]   than they're more likely to be by the looks of things,
[01:21:33.920 --> 01:21:38.080]   which knew how to handle their own global warming
[01:21:38.080 --> 01:21:40.480]   or whatever it is and to get through it all
[01:21:40.480 --> 01:21:45.440]   and to live to a ripe old age in the sense of a civilization
[01:21:45.440 --> 01:21:49.160]   to the extent that they could harness signals,
[01:21:49.160 --> 01:21:52.320]   that they could propagate through for some reason
[01:21:52.320 --> 01:21:55.680]   of their own desires, whatever we wouldn't know,
[01:21:55.680 --> 01:21:58.560]   to other civilizations which might be able
[01:21:58.560 --> 01:22:00.200]   to pick up the signals.
[01:22:00.200 --> 01:22:01.960]   But what kind of signals would they be?
[01:22:01.960 --> 01:22:03.240]   I haven't the foggiest.
[01:22:03.240 --> 01:22:06.960]   - Let me ask the question.
[01:22:06.960 --> 01:22:09.920]   What to you is the most beautiful idea in physics
[01:22:09.920 --> 01:22:14.160]   or mathematics or the art at the intersection of the two?
[01:22:14.160 --> 01:22:17.180]   - I'm gonna have to say complex analysis.
[01:22:17.180 --> 01:22:20.680]   I might've said infinities.
[01:22:20.680 --> 01:22:23.440]   One of the most single most beautiful idea, I think,
[01:22:23.440 --> 01:22:25.560]   is the fact that you can have infinities
[01:22:25.560 --> 01:22:27.320]   of different sizes and so on.
[01:22:27.320 --> 01:22:30.800]   But that's in a way, I think, complex analysis.
[01:22:30.800 --> 01:22:33.400]   It's got so much magic in it.
[01:22:33.400 --> 01:22:35.360]   It's a very simple idea.
[01:22:35.360 --> 01:22:41.160]   You take these, you take numbers, you take the integers
[01:22:41.160 --> 01:22:43.120]   and then you fill them up into the fractions
[01:22:43.120 --> 01:22:44.640]   and the real numbers.
[01:22:44.640 --> 01:22:47.520]   You imagine you're trying to measure a continuous line.
[01:22:47.520 --> 01:22:50.400]   And then you think of how you can solve equations.
[01:22:50.400 --> 01:22:53.400]   Then what about X squared equals minus one?
[01:22:53.400 --> 01:22:57.460]   Well, there's no real number which satisfies that.
[01:22:57.460 --> 01:23:00.480]   So you have to think of, well, there's a number called I.
[01:23:00.480 --> 01:23:02.340]   You think you invent it.
[01:23:02.340 --> 01:23:05.160]   Well, in a certain sense, it's there already.
[01:23:05.160 --> 01:23:07.440]   But this number, when you add that square root
[01:23:07.440 --> 01:23:09.260]   of minus one to it, you have what's called
[01:23:09.260 --> 01:23:10.960]   the complex numbers.
[01:23:10.960 --> 01:23:12.740]   And they're an incredible system.
[01:23:12.740 --> 01:23:15.720]   If you like, you put one little thing in,
[01:23:15.720 --> 01:23:17.320]   you put square root of minus one in
[01:23:17.320 --> 01:23:20.640]   and you get how much benefit out of it?
[01:23:20.640 --> 01:23:23.400]   All sorts of things that you'd never imagined before.
[01:23:23.400 --> 01:23:27.760]   And it's that amazing, all hiding there
[01:23:27.760 --> 01:23:30.160]   in putting that square root of minus one in.
[01:23:30.160 --> 01:23:31.200]   - So in a sense-- - I think that's
[01:23:31.200 --> 01:23:34.040]   the most magical thing I've seen in mathematics or physics.
[01:23:34.040 --> 01:23:35.560]   And it's in quantum mechanics.
[01:23:35.560 --> 01:23:36.400]   - In quantum mechanics.
[01:23:36.400 --> 01:23:38.200]   - You see, it's there already.
[01:23:38.200 --> 01:23:39.720]   You might think, what's it doing there?
[01:23:39.720 --> 01:23:41.640]   Okay, just a nice, beautiful piece of mathematics.
[01:23:41.640 --> 01:23:44.160]   And then suddenly we see, nope.
[01:23:44.160 --> 01:23:47.200]   It's the very crucial basis of quantum mechanics.
[01:23:47.200 --> 01:23:49.520]   It's there in the way the world works.
[01:23:49.520 --> 01:23:50.960]   - So on the question of whether math
[01:23:50.960 --> 01:23:53.440]   is discovered or invented, it sounds like
[01:23:53.440 --> 01:23:56.160]   you may be suggesting that partially it's possible
[01:23:56.160 --> 01:23:57.840]   that math is indeed discovered.
[01:23:57.840 --> 01:23:59.660]   - Oh, absolutely, yes.
[01:23:59.660 --> 01:24:02.160]   No, it's more like archeology than you might think.
[01:24:02.160 --> 01:24:03.880]   Yes, yes.
[01:24:03.880 --> 01:24:06.520]   - So let me ask the most ridiculous,
[01:24:06.520 --> 01:24:08.640]   maybe the most important question.
[01:24:08.640 --> 01:24:12.400]   What is the meaning of life?
[01:24:12.400 --> 01:24:15.000]   What gives your life fulfillment, purpose,
[01:24:15.000 --> 01:24:15.960]   happiness, and meaning?
[01:24:15.960 --> 01:24:18.240]   Why do you think we're here on this?
[01:24:18.240 --> 01:24:20.280]   Given all the big bang and the infinities
[01:24:20.280 --> 01:24:21.600]   of photons that we've talked about.
[01:24:21.600 --> 01:24:24.400]   - All I would say, I think it's not a stupid question.
[01:24:24.400 --> 01:24:26.560]   (laughs)
[01:24:26.560 --> 01:24:28.160]   I mean, there are some people, you know,
[01:24:28.160 --> 01:24:29.760]   many of my colleagues who are scientists,
[01:24:29.760 --> 01:24:31.280]   and they say, well, that's a stupid question,
[01:24:31.280 --> 01:24:33.560]   meaning, well, we're just here because
[01:24:33.560 --> 01:24:36.120]   things came together and produced life and so what.
[01:24:36.120 --> 01:24:39.240]   I think there's more to it.
[01:24:39.240 --> 01:24:41.040]   But what there is that's more to it,
[01:24:41.040 --> 01:24:43.080]   I have really much idea.
[01:24:43.080 --> 01:24:45.400]   - And it might be somehow connected to the mechanisms
[01:24:45.400 --> 01:24:47.400]   of consciousness that we've been talking about,
[01:24:47.400 --> 01:24:48.520]   the mystery there.
[01:24:48.520 --> 01:24:49.480]   - Yeah, yeah.
[01:24:49.480 --> 01:24:51.000]   It's connected with all sorts of, yeah,
[01:24:51.000 --> 01:24:53.560]   I think these things are tied up in ways which are,
[01:24:53.560 --> 01:24:56.720]   you see, I tend to think the mystery of consciousness
[01:24:56.720 --> 01:25:00.960]   is tied up with the mystery of quantum mechanics
[01:25:00.960 --> 01:25:04.000]   and how it fits in with the classical world,
[01:25:04.000 --> 01:25:07.440]   and that's all to do with the mystery of complex numbers.
[01:25:07.440 --> 01:25:11.520]   And there are mysteries there which look like
[01:25:11.520 --> 01:25:15.720]   mathematical mysteries, but they seem to have a bearing
[01:25:15.720 --> 01:25:17.680]   on the way the physical world operates.
[01:25:17.680 --> 01:25:20.760]   We're scratching the surface.
[01:25:20.760 --> 01:25:22.960]   We have a long, huge way to go
[01:25:22.960 --> 01:25:24.840]   before we really understand that.
[01:25:24.840 --> 01:25:28.360]   - And it's a beautiful idea that the depth,
[01:25:28.360 --> 01:25:30.680]   the mathematical depth could be discovered,
[01:25:30.680 --> 01:25:33.640]   and then there's tragedies of Gato's incompleteness
[01:25:33.640 --> 01:25:35.360]   along the way that we'll have to somehow
[01:25:35.360 --> 01:25:36.640]   figure our ways around.
[01:25:36.640 --> 01:25:38.920]   - Yeah.
[01:25:38.920 --> 01:25:42.080]   - So, Roger, it was a huge honor to talk to you.
[01:25:42.080 --> 01:25:43.440]   Thank you so much for your time today.
[01:25:43.440 --> 01:25:44.560]   - It's been my pleasure.
[01:25:44.560 --> 01:25:46.080]   Thank you.
[01:25:46.080 --> 01:25:47.600]   - Thanks for listening to this conversation
[01:25:47.600 --> 01:25:49.800]   with Roger Penrose, and thank you
[01:25:49.800 --> 01:25:52.000]   to our presenting sponsor, Cash App.
[01:25:52.000 --> 01:25:53.920]   Please consider supporting this podcast
[01:25:53.920 --> 01:25:58.920]   by getting ExpressVPN at expressvpn.com/lexpod
[01:25:58.920 --> 01:26:03.920]   and downloading Cash App and using code LEXPODCAST.
[01:26:03.920 --> 01:26:06.400]   If you enjoy this podcast, subscribe on YouTube,
[01:26:06.400 --> 01:26:09.000]   review it with Five Stars and Apple Podcasts,
[01:26:09.000 --> 01:26:12.440]   support on Patreon, or simply connect with me on Twitter
[01:26:12.440 --> 01:26:14.000]   at Lex Friedman.
[01:26:14.000 --> 01:26:16.920]   And now, let me leave you with some words of wisdom
[01:26:16.920 --> 01:26:19.200]   that Roger Penrose wrote in his book,
[01:26:19.200 --> 01:26:20.600]   "The Emperor's New Mind."
[01:26:20.600 --> 01:26:24.400]   Beneath all this technicality is the feeling
[01:26:24.400 --> 01:26:28.000]   that it is indeed, quote unquote, obvious
[01:26:28.000 --> 01:26:31.160]   that the conscious mind cannot work like a computer,
[01:26:31.160 --> 01:26:33.000]   even though much of what is involved
[01:26:33.000 --> 01:26:35.400]   in mental activity might do so.
[01:26:35.400 --> 01:26:39.480]   This is the kind of obviousness that a child can see,
[01:26:39.480 --> 01:26:42.680]   though the child may later in life become browbeaten
[01:26:42.680 --> 01:26:44.720]   into believing that the obvious problems
[01:26:44.720 --> 01:26:47.200]   are quote unquote, non-problems,
[01:26:47.200 --> 01:26:51.000]   to be argued into nonexistence by careful reasoning
[01:26:51.000 --> 01:26:52.820]   and clever choices of definition.
[01:26:52.820 --> 01:26:56.440]   Children sometimes see things clearly
[01:26:56.440 --> 01:26:59.040]   that are obscured in later life.
[01:26:59.040 --> 01:27:02.360]   We often forget the wonder that we felt as children
[01:27:02.360 --> 01:27:05.200]   when the cares of the quote unquote, real world
[01:27:05.200 --> 01:27:07.760]   have begun to settle on our shoulders.
[01:27:07.760 --> 01:27:10.440]   Children are not afraid to pose basic questions
[01:27:10.440 --> 01:27:13.560]   that may embarrass us as adults to ask.
[01:27:13.560 --> 01:27:15.680]   What happens to each of our streams of consciousness
[01:27:15.680 --> 01:27:17.160]   after we die?
[01:27:17.160 --> 01:27:19.520]   Where was it before we were born?
[01:27:19.520 --> 01:27:23.160]   Might we become or have been someone else?
[01:27:23.160 --> 01:27:25.120]   Why do we perceive it all?
[01:27:25.120 --> 01:27:26.840]   Why are we here?
[01:27:26.840 --> 01:27:28.560]   Why is there a universe here at all
[01:27:28.560 --> 01:27:30.840]   in which we can actually be?
[01:27:30.840 --> 01:27:32.560]   These are puzzles that tend to come
[01:27:32.560 --> 01:27:35.920]   with the awakenings of awareness in any of us,
[01:27:35.920 --> 01:27:39.920]   and no doubt with the awakening of self-awareness
[01:27:39.920 --> 01:27:43.620]   within whichever creature or other entity it first came.
[01:27:43.620 --> 01:27:48.240]   Thank you for listening and hope to see you next time.
[01:27:48.240 --> 01:27:50.820]   (upbeat music)
[01:27:50.820 --> 01:27:53.400]   (upbeat music)
[01:27:53.400 --> 01:28:03.400]   [BLANK_AUDIO]

