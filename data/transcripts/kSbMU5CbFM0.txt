
[00:00:00.000 --> 00:00:03.300]   The following is a conversation with Alex Gladstein,
[00:00:03.300 --> 00:00:06.240]   Chief Strategy Officer at the Human Rights Foundation
[00:00:06.240 --> 00:00:08.400]   and the Oslo Freedom Forum.
[00:00:08.400 --> 00:00:11.880]   In recent times, Alex has focused on how cryptocurrency
[00:00:11.880 --> 00:00:15.360]   and especially Bitcoin can be a tool for empowering democracy
[00:00:15.360 --> 00:00:17.880]   and civil liberties in the world.
[00:00:17.880 --> 00:00:20.000]   Most crucially, parts of the world
[00:00:20.000 --> 00:00:23.560]   that are living under authoritarian regimes.
[00:00:23.560 --> 00:00:27.000]   As a side note, let me say that I have been learning a lot
[00:00:27.000 --> 00:00:30.480]   about the ways in which money can be used to amass power.
[00:00:30.480 --> 00:00:33.320]   And in the same way, the decentralization of money
[00:00:33.320 --> 00:00:36.920]   can be used to resist the corrupting nature of this power.
[00:00:36.920 --> 00:00:39.880]   Alex and I do not agree on everything,
[00:00:39.880 --> 00:00:42.600]   but we strive for the same betterment of humanity.
[00:00:42.600 --> 00:00:45.200]   He's sensitive to the suffering in the world
[00:00:45.200 --> 00:00:48.120]   and is dedicating his life to finding solutions
[00:00:48.120 --> 00:00:49.880]   that lessen that suffering.
[00:00:49.880 --> 00:00:53.400]   Whether Bitcoin is one such solution, I don't know,
[00:00:53.400 --> 00:00:55.160]   but I think it has a chance.
[00:00:55.160 --> 00:00:58.560]   And that means it is worth exploring deeply.
[00:00:58.560 --> 00:01:01.240]   I'm staying in this path of learning patiently
[00:01:01.240 --> 00:01:03.680]   and with as little ego as possible.
[00:01:03.680 --> 00:01:07.160]   I hope you come along with me on this journey as well.
[00:01:07.160 --> 00:01:09.300]   This is the Alex Friedman Podcast.
[00:01:09.300 --> 00:01:11.400]   To support it, please check out our sponsors
[00:01:11.400 --> 00:01:12.960]   in the description.
[00:01:12.960 --> 00:01:15.720]   We recorded this conversation a while ago
[00:01:15.720 --> 00:01:17.600]   and I thought I lost the audio
[00:01:17.600 --> 00:01:20.560]   and was really disappointed with myself
[00:01:20.560 --> 00:01:22.300]   for messing this thing up.
[00:01:22.300 --> 00:01:25.360]   But luckily last week I found it
[00:01:25.360 --> 00:01:30.360]   and so rescued from out of the abyss of non-existence.
[00:01:30.360 --> 00:01:33.600]   Here's my conversation with Alex Glassstein.
[00:01:33.600 --> 00:01:36.900]   What are some universal human rights
[00:01:36.900 --> 00:01:39.000]   that you believe all people should have?
[00:01:39.000 --> 00:01:43.200]   - So free speech, freedom of assembly,
[00:01:43.200 --> 00:01:44.640]   freedom of belief,
[00:01:44.640 --> 00:01:46.800]   freedom to participate in your government,
[00:01:46.800 --> 00:01:48.400]   the freedom to have privacy,
[00:01:48.400 --> 00:01:51.120]   the freedom to own things, property rights.
[00:01:51.120 --> 00:01:54.520]   These are all basic fundamental negative rights,
[00:01:54.520 --> 00:01:55.760]   what we call them.
[00:01:55.760 --> 00:01:59.040]   These are the basic fundamental human freedoms.
[00:01:59.040 --> 00:02:00.680]   - What does negative rights mean?
[00:02:00.680 --> 00:02:04.880]   - Negative rights are liberties
[00:02:04.880 --> 00:02:07.240]   and positive rights are entitlements.
[00:02:07.240 --> 00:02:10.840]   So after World War II, when the UN came together,
[00:02:10.840 --> 00:02:13.380]   it was largely a compromise between the Communist Soviet Union
[00:02:13.380 --> 00:02:16.040]   and the free United States, right?
[00:02:16.040 --> 00:02:18.880]   So the US had on its side
[00:02:18.880 --> 00:02:21.240]   of the UN Declaration of Human Rights,
[00:02:21.240 --> 00:02:23.480]   a bunch of liberties, essentially,
[00:02:23.480 --> 00:02:26.000]   things like free speech, freedom of association,
[00:02:26.000 --> 00:02:27.280]   freedom of assembly.
[00:02:27.280 --> 00:02:30.720]   The Soviets wanted entitlements like the right to work,
[00:02:30.720 --> 00:02:32.680]   the right to have housing, the right to water,
[00:02:32.680 --> 00:02:34.120]   the right to a vacation.
[00:02:34.120 --> 00:02:36.800]   So you actually read the UN Declaration for Human Rights.
[00:02:36.800 --> 00:02:40.440]   It's a negotiation between the Soviets and the Americans.
[00:02:40.440 --> 00:02:43.040]   Later, there was another document in the '70s
[00:02:43.040 --> 00:02:44.960]   released called the International Covenant
[00:02:44.960 --> 00:02:46.680]   on Civil and Political Rights.
[00:02:46.680 --> 00:02:50.760]   And this is what HRF uses as its sort of like lodestar,
[00:02:50.760 --> 00:02:51.960]   its founding document.
[00:02:51.960 --> 00:02:54.440]   And this is like essentially an international agreement
[00:02:54.440 --> 00:02:56.280]   on the negative rights.
[00:02:56.280 --> 00:02:58.360]   Those are the things we choose to focus on
[00:02:58.360 --> 00:03:02.040]   because essentially, authoritarian regimes can commit fraud
[00:03:02.040 --> 00:03:04.280]   and claim they're giving the positive rights,
[00:03:04.280 --> 00:03:06.600]   the entitlements, without having
[00:03:06.600 --> 00:03:08.120]   any of the negative liberties.
[00:03:08.120 --> 00:03:09.880]   And they can do that because they don't have
[00:03:09.880 --> 00:03:11.920]   any like free speech or press freedom.
[00:03:11.920 --> 00:03:15.560]   When you take people's basic fundamental freedoms away,
[00:03:15.560 --> 00:03:17.880]   it's quite easy to make like a Potemkin village
[00:03:17.880 --> 00:03:20.000]   and pretend that there's the entitlements
[00:03:20.000 --> 00:03:22.360]   and that we have good healthcare.
[00:03:22.360 --> 00:03:24.760]   And it's the same sort of thing
[00:03:24.760 --> 00:03:26.800]   that authoritarians have done for decades,
[00:03:26.800 --> 00:03:29.800]   Cuba and Venezuela and the Soviet Union.
[00:03:29.800 --> 00:03:32.120]   - Do you think it's possible for authoritarian regimes
[00:03:32.120 --> 00:03:35.600]   to manipulate, to kind of lie about the negative rights
[00:03:35.600 --> 00:03:39.360]   as well by saying that the people have free speech,
[00:03:39.360 --> 00:03:41.640]   the people have the freedom for assembly
[00:03:41.640 --> 00:03:42.920]   and all those kinds of things?
[00:03:42.960 --> 00:03:46.160]   Can't you still manipulate the idea
[00:03:46.160 --> 00:03:49.200]   that the citizenry still has those rights?
[00:03:49.200 --> 00:03:52.720]   - The opposition leader of Malaysia, Anwar Ibrahim,
[00:03:52.720 --> 00:03:56.200]   he once told me the funny joke that,
[00:03:56.200 --> 00:03:58.440]   you know, in my country, we have freedom of speech,
[00:03:58.440 --> 00:04:00.520]   we don't have freedom after speech.
[00:04:00.520 --> 00:04:04.240]   So yeah, they can absolutely manipulate whatever they want.
[00:04:04.240 --> 00:04:07.440]   But I've done research into socioeconomic data.
[00:04:07.440 --> 00:04:08.480]   And I guess what I'm telling you
[00:04:08.480 --> 00:04:10.280]   is that authoritarian regimes,
[00:04:10.280 --> 00:04:13.680]   which make up 53% of the world's population
[00:04:13.680 --> 00:04:18.440]   across 95 countries, about 4.3 billion people,
[00:04:18.440 --> 00:04:20.400]   those who live under those regimes
[00:04:20.400 --> 00:04:23.520]   are subject to massive fraud
[00:04:23.520 --> 00:04:26.600]   when it comes to things like literacy rates,
[00:04:26.600 --> 00:04:30.360]   life expectancy, any sort of socioeconomic data,
[00:04:30.360 --> 00:04:32.520]   economic growth, they can do this
[00:04:32.520 --> 00:04:34.720]   because there's no free press.
[00:04:34.720 --> 00:04:36.760]   So for us at the Human Rights Foundation
[00:04:36.760 --> 00:04:38.520]   and for people like me,
[00:04:38.520 --> 00:04:41.360]   we believe that the negative rights, the liberties,
[00:04:41.360 --> 00:04:43.280]   the things that are in, for example,
[00:04:43.280 --> 00:04:45.240]   the Bill of Rights in the US Constitution,
[00:04:45.240 --> 00:04:46.560]   these things are the table.
[00:04:46.560 --> 00:04:48.000]   And then we can build on top of that.
[00:04:48.000 --> 00:04:50.560]   We can build the rest of our societies on top of that.
[00:04:50.560 --> 00:04:51.840]   The freest countries in the world
[00:04:51.840 --> 00:04:55.120]   have both the negative liberties and the entitlements,
[00:04:55.120 --> 00:04:56.640]   like Norway, for example.
[00:04:56.640 --> 00:04:59.720]   But there's a big difference between Norway and North Korea.
[00:04:59.720 --> 00:05:02.480]   In North Korea, they only claim to have the entitlements
[00:05:02.480 --> 00:05:05.000]   and they definitely don't have the liberties.
[00:05:05.000 --> 00:05:06.240]   - Do you think there's one right
[00:05:06.240 --> 00:05:07.560]   that's more important than others?
[00:05:07.560 --> 00:05:09.920]   You kind of suggested the freedom of the press,
[00:05:09.920 --> 00:05:11.880]   maybe freedom of speech,
[00:05:11.880 --> 00:05:13.600]   that if you take that away,
[00:05:13.600 --> 00:05:15.080]   all the other ones kind of collapse
[00:05:15.080 --> 00:05:17.280]   along with like from a ripple effect.
[00:05:17.280 --> 00:05:18.720]   Is there something fundamental
[00:05:18.720 --> 00:05:21.880]   that you like to focus your attention on
[00:05:21.880 --> 00:05:25.160]   to defend, to protect, to make sure it's there?
[00:05:25.160 --> 00:05:27.640]   - Yeah, I think free speech is probably the most fundamental.
[00:05:27.640 --> 00:05:29.800]   It's probably why the founders chose to make it
[00:05:29.800 --> 00:05:31.040]   into the First Amendment.
[00:05:31.040 --> 00:05:34.600]   A lot of things are downstream from there.
[00:05:34.600 --> 00:05:36.880]   Property rights are also very, very important.
[00:05:37.720 --> 00:05:41.960]   Obviously, we've seen the toll of violent redistributionism
[00:05:41.960 --> 00:05:44.160]   in over the last 100 years,
[00:05:44.160 --> 00:05:48.880]   whether it was Lenin or Stalin or Mao or other regimes
[00:05:48.880 --> 00:05:53.400]   and everywhere from Ethiopia to colonialists everywhere
[00:05:53.400 --> 00:05:56.760]   to North Korea, it's not a pretty legacy.
[00:05:56.760 --> 00:06:00.480]   - Is free speech clear to you as a concept?
[00:06:00.480 --> 00:06:02.000]   There's been quite a few debates,
[00:06:02.000 --> 00:06:04.280]   especially in the digital age,
[00:06:04.280 --> 00:06:06.360]   what it means to violate freedom of speech.
[00:06:06.360 --> 00:06:10.200]   There's been a lot of new, like novel mechanisms
[00:06:10.200 --> 00:06:12.280]   for people to communicate with each other,
[00:06:12.280 --> 00:06:14.320]   like especially on social networks.
[00:06:14.320 --> 00:06:17.000]   And it seems that unclear,
[00:06:17.000 --> 00:06:18.920]   because a lot of times those are managed
[00:06:18.920 --> 00:06:23.160]   by private companies, it's unclear how much protection
[00:06:23.160 --> 00:06:26.760]   do the citizens have to have when they're communicating.
[00:06:26.760 --> 00:06:28.440]   A lot of people are being censored
[00:06:28.440 --> 00:06:30.200]   on these social platforms.
[00:06:30.200 --> 00:06:31.840]   Some people, even presidents,
[00:06:31.840 --> 00:06:35.440]   get removed from those social platforms.
[00:06:35.440 --> 00:06:37.880]   Have you thought about the freedom of speech
[00:06:37.880 --> 00:06:40.600]   in the United States, but in the world,
[00:06:40.600 --> 00:06:47.480]   as it's implemented in the 21st century,
[00:06:47.480 --> 00:06:50.420]   given the internet and all those kinds of things?
[00:06:50.420 --> 00:06:54.960]   - There is a Soviet dissident named Natan Sharansky
[00:06:54.960 --> 00:06:59.880]   who survived the regime.
[00:06:59.880 --> 00:07:03.080]   And he wrote a book in which his thesis
[00:07:03.080 --> 00:07:06.160]   was essentially the way that you can define a free society
[00:07:06.160 --> 00:07:08.600]   is through something called the Town Square Test.
[00:07:08.600 --> 00:07:11.200]   Can you go to a public space where you live
[00:07:11.200 --> 00:07:13.840]   and criticize your ruler loudly
[00:07:13.840 --> 00:07:15.960]   without fear of retribution?
[00:07:15.960 --> 00:07:18.320]   If you can do that, you have free speech.
[00:07:18.320 --> 00:07:20.440]   I think that's a pretty good litmus test.
[00:07:20.440 --> 00:07:21.920]   Most people in this world cannot do that.
[00:07:21.920 --> 00:07:24.600]   If you live in Havana, if you live in Moscow,
[00:07:24.600 --> 00:07:27.200]   if you live in Beijing, you cannot do that.
[00:07:27.200 --> 00:07:29.680]   And that's not a free society.
[00:07:29.680 --> 00:07:32.800]   In Austin, Texas, in Boston, Massachusetts,
[00:07:32.800 --> 00:07:36.880]   in London, in Santiago, Chile, in Tokyo, Japan,
[00:07:36.880 --> 00:07:38.880]   in many democracies, you can do that.
[00:07:38.880 --> 00:07:40.340]   And I think that that's a really helpful
[00:07:40.340 --> 00:07:42.600]   basic sort of litmus test.
[00:07:42.600 --> 00:07:45.960]   - Does the content of the criticism matter?
[00:07:45.960 --> 00:07:50.960]   Can it be complete lies, meaning conspiracy theories
[00:07:50.960 --> 00:07:55.000]   that involve claiming that the leader is,
[00:07:55.000 --> 00:08:00.000]   let's say, a lizard/pedophile/you know,
[00:08:00.000 --> 00:08:04.800]   I'm not saying that those are lies, look into it,
[00:08:04.800 --> 00:08:08.680]   but they're very unlikely phenomena.
[00:08:08.680 --> 00:08:10.480]   So like, does that matter?
[00:08:10.480 --> 00:08:13.560]   - I think it ends poorly when the state
[00:08:13.560 --> 00:08:15.080]   tries to restrict speech.
[00:08:15.080 --> 00:08:18.520]   I think that's kind of how I would define censorship.
[00:08:18.520 --> 00:08:22.520]   I think censorship and deplatforming are two different things.
[00:08:22.520 --> 00:08:25.800]   Private companies, you know,
[00:08:25.800 --> 00:08:27.000]   they get to make up their own rules
[00:08:27.000 --> 00:08:29.320]   about what's allowed on their platforms.
[00:08:29.320 --> 00:08:30.940]   And I think that's very different from a government
[00:08:30.940 --> 00:08:34.480]   with guns and an army restricting the speech
[00:08:34.480 --> 00:08:37.040]   of its citizens with threats of violence.
[00:08:37.040 --> 00:08:38.960]   These things are different for me.
[00:08:38.960 --> 00:08:41.380]   - That violence is a fundamental difference.
[00:08:41.380 --> 00:08:45.520]   I don't know, I've gotten the chance to have dinner
[00:08:45.520 --> 00:08:50.520]   with Alex Jones, and I've talked to him a few times offline.
[00:08:51.240 --> 00:08:55.760]   And it does, I understand why people are so off-put by him,
[00:08:55.760 --> 00:08:58.380]   but it does bother me that he's universally removed
[00:08:58.380 --> 00:09:00.160]   from every platform.
[00:09:00.160 --> 00:09:04.680]   It feels like there's many more evil people,
[00:09:04.680 --> 00:09:08.360]   bad people, compared to Alex Jones,
[00:09:08.360 --> 00:09:12.520]   who still are given a voice on these platforms.
[00:09:12.520 --> 00:09:17.040]   And so I'm uncomfortable with the universality
[00:09:17.040 --> 00:09:19.400]   of the application of this censorship
[00:09:19.400 --> 00:09:22.400]   by these platforms.
[00:09:22.400 --> 00:09:23.800]   But on the flip side, you're right,
[00:09:23.800 --> 00:09:27.040]   there's not a violence, there's not tanks,
[00:09:27.040 --> 00:09:29.480]   there's not guns behind that censorship.
[00:09:29.480 --> 00:09:30.980]   - Yeah, it's a bit of a generalization,
[00:09:30.980 --> 00:09:34.360]   but Alex Jones would be in prison, or dead,
[00:09:34.360 --> 00:09:37.160]   if he were in North Korea, or in Cuba,
[00:09:37.160 --> 00:09:38.760]   or in Russia, or in China.
[00:09:38.760 --> 00:09:42.240]   The authorities would not tolerate him to do what he did.
[00:09:42.240 --> 00:09:45.120]   And here, he can kind of do what he wants.
[00:09:45.120 --> 00:09:46.640]   He's encountering some resistance
[00:09:46.640 --> 00:09:49.160]   in the marketplace of ideas.
[00:09:49.160 --> 00:09:51.800]   Large organizations, corporations,
[00:09:51.800 --> 00:09:53.920]   and a lot of public sentiment
[00:09:53.920 --> 00:09:58.640]   in different parts of our country don't like him.
[00:09:58.640 --> 00:10:01.020]   They're doing their best to drown out his voice.
[00:10:01.020 --> 00:10:03.840]   But that's very different from a violent threat
[00:10:03.840 --> 00:10:05.280]   of censorship from the state.
[00:10:05.280 --> 00:10:08.220]   And that's what we study, that's what I study.
[00:10:08.220 --> 00:10:09.560]   What is the state doing?
[00:10:09.560 --> 00:10:11.600]   That's kind of paramount for me.
[00:10:11.600 --> 00:10:12.520]   - Yeah, and that's true.
[00:10:12.520 --> 00:10:14.240]   Because in the marketplace of ideas,
[00:10:14.240 --> 00:10:15.880]   there could be a company that springs up
[00:10:15.880 --> 00:10:17.920]   that gives Alex Jones a platform,
[00:10:17.920 --> 00:10:20.440]   and the United States is not going
[00:10:20.440 --> 00:10:23.400]   to prevent those companies from functioning.
[00:10:23.400 --> 00:10:28.400]   Of course, there's, from a technology perspective,
[00:10:28.400 --> 00:10:32.120]   there is AWS removing Parler from the platform.
[00:10:32.120 --> 00:10:34.480]   It gets a little weird, you know,
[00:10:34.480 --> 00:10:37.200]   as you get closer and closer to the compute infrastructure,
[00:10:37.200 --> 00:10:39.240]   because then you get closer and closer to the state,
[00:10:39.240 --> 00:10:43.420]   actually, the more you get to the infrastructure
[00:10:43.420 --> 00:10:45.320]   that's usually managed by the state,
[00:10:45.320 --> 00:10:48.400]   the closer it gets to then the control of the state.
[00:10:48.400 --> 00:10:50.880]   I would argue AWS is pretty damn close
[00:10:50.880 --> 00:10:53.740]   to infrastructure that's kind of controlled by the state.
[00:10:53.740 --> 00:10:58.740]   If you especially look at other nations, China, Russia,
[00:10:58.740 --> 00:11:02.840]   there's, I don't know who runs the compute infrastructure
[00:11:02.840 --> 00:11:04.600]   for Russia and China, but I bet the state
[00:11:04.600 --> 00:11:07.220]   has complete oversight over that.
[00:11:07.220 --> 00:11:10.600]   And so that level of compute infrastructure,
[00:11:10.600 --> 00:11:14.720]   having control about which social networks can
[00:11:14.720 --> 00:11:17.320]   and cannot operate is very uncomfortable to me.
[00:11:17.320 --> 00:11:20.520]   But you're right, I think it's good to focus
[00:11:20.520 --> 00:11:22.920]   on the obvious violations of these principles
[00:11:22.920 --> 00:11:25.320]   as opposed to the gray areas.
[00:11:25.320 --> 00:11:27.420]   Of course, the gray areas are fascinating.
[00:11:27.420 --> 00:11:31.600]   You mentioned HRF, Human Rights Foundation.
[00:11:31.600 --> 00:11:32.640]   What is it?
[00:11:32.640 --> 00:11:34.400]   What is its mission?
[00:11:34.400 --> 00:11:38.220]   - Yeah, so I've been working for HRF since 2007.
[00:11:38.220 --> 00:11:44.440]   We are a charity, a nonprofit, a 501(c)(3) based in New York
[00:11:44.440 --> 00:11:48.840]   and our mission is to promote and protect individual rights
[00:11:48.840 --> 00:11:52.480]   and freedoms in authoritarian societies around the world.
[00:11:52.480 --> 00:11:55.800]   So again, we define about 95 countries as authoritarian,
[00:11:55.800 --> 00:11:57.920]   meaning it's either a one party state
[00:11:57.920 --> 00:12:01.920]   or opposition politicians are outlawed or persecuted.
[00:12:01.920 --> 00:12:04.080]   There's no real free speech, there's no press freedom,
[00:12:04.080 --> 00:12:05.680]   there's no independent judiciary,
[00:12:05.680 --> 00:12:07.400]   there really aren't checks and balances
[00:12:07.400 --> 00:12:10.240]   and even trying to create like a human rights organization
[00:12:10.240 --> 00:12:13.920]   or like an environmental group would be illegal.
[00:12:13.920 --> 00:12:15.640]   And the majority of the world's population
[00:12:15.640 --> 00:12:17.200]   lives in that environment, that's very important.
[00:12:17.200 --> 00:12:18.720]   - You said 53%.
[00:12:18.720 --> 00:12:20.680]   - 53%, 4.3 billion people.
[00:12:20.680 --> 00:12:25.240]   - And I saw you outlined a lot of different sources
[00:12:25.240 --> 00:12:27.600]   of suffering in the world.
[00:12:27.600 --> 00:12:29.760]   And then you sort of put people living
[00:12:29.760 --> 00:12:32.560]   under authoritarian governments
[00:12:32.560 --> 00:12:34.320]   as like more than all of them.
[00:12:34.320 --> 00:12:38.560]   I forget all the examples you provided, but--
[00:12:38.560 --> 00:12:39.760]   - Sure, I mean--
[00:12:39.760 --> 00:12:41.880]   - Yeah, maybe you can mention if you remember.
[00:12:41.880 --> 00:12:43.280]   - The number of people who are refugees,
[00:12:43.280 --> 00:12:45.520]   the number of people who suffer from natural disasters,
[00:12:45.520 --> 00:12:47.760]   the number of people who live under abject poverty,
[00:12:47.760 --> 00:12:49.640]   the number of people who don't have access
[00:12:49.640 --> 00:12:51.920]   to clean drinking water, all of these are dwarfed
[00:12:51.920 --> 00:12:54.880]   by the number of people who live under authoritarianism.
[00:12:54.880 --> 00:12:57.840]   And yet it's not something that we talk about a lot
[00:12:57.840 --> 00:12:59.600]   because people are mercantilist
[00:12:59.600 --> 00:13:03.000]   and the powers that be are happy to sacrifice freedoms
[00:13:03.000 --> 00:13:04.880]   and privacy for money.
[00:13:04.880 --> 00:13:07.480]   We live in a profit seeking world.
[00:13:07.480 --> 00:13:10.440]   To get evidence of this, take a look at the list of sponsors
[00:13:10.440 --> 00:13:13.520]   of the upcoming Olympics in China,
[00:13:13.520 --> 00:13:15.440]   where the CCP is currently committing genocide
[00:13:15.440 --> 00:13:17.080]   against the weaker population.
[00:13:17.080 --> 00:13:19.960]   Or look at the number of people and the famous investors
[00:13:19.960 --> 00:13:22.080]   who went to Saudi Arabia a couple months ago
[00:13:22.080 --> 00:13:23.920]   for the Davos in the desert.
[00:13:23.920 --> 00:13:27.000]   I mean, Ray Dalio was there, all kinds of people were there.
[00:13:27.000 --> 00:13:28.000]   Or at least they were invited
[00:13:28.000 --> 00:13:29.640]   and they said they were gonna go.
[00:13:29.640 --> 00:13:32.800]   And this is a government that at the time
[00:13:32.800 --> 00:13:35.360]   was torturing a female activist
[00:13:35.360 --> 00:13:37.000]   who just wanted to drive a car.
[00:13:37.000 --> 00:13:40.240]   This is a government that had murdered Jamal Khashoggi
[00:13:40.240 --> 00:13:44.200]   in a brutal fashion just a couple years earlier.
[00:13:44.200 --> 00:13:45.320]   So I mean, at the end of the day,
[00:13:45.320 --> 00:13:47.320]   when it comes down to brass tacks,
[00:13:47.320 --> 00:13:50.280]   I mean, the powers that be,
[00:13:50.280 --> 00:13:53.760]   even the free countries are led by people
[00:13:53.760 --> 00:13:56.960]   who are very, very happy to sacrifice
[00:13:56.960 --> 00:13:58.520]   all these pretty words about human rights
[00:13:58.520 --> 00:14:01.160]   when it comes down to profits, unfortunately.
[00:14:01.160 --> 00:14:02.840]   - So do you think capitalism,
[00:14:02.840 --> 00:14:04.880]   that's maybe one of the flaws of capitalism
[00:14:04.880 --> 00:14:09.520]   is it turns a blind eye to injustices against human nature,
[00:14:09.520 --> 00:14:11.600]   against the human rights?
[00:14:11.600 --> 00:14:15.040]   Like it turns a blind eye to authoritarian governments?
[00:14:15.040 --> 00:14:17.200]   - Look, I think that at the end of the day,
[00:14:17.200 --> 00:14:22.600]   free trade is actually really good.
[00:14:22.600 --> 00:14:25.400]   And you can just look at France and Germany as an example
[00:14:25.400 --> 00:14:28.400]   of how a capitalist structure would develop.
[00:14:28.400 --> 00:14:30.160]   If you have two capitalist actors,
[00:14:30.160 --> 00:14:31.520]   they're very unlikely to fight each other.
[00:14:31.520 --> 00:14:33.400]   There's very unlikely to be violence, right?
[00:14:33.400 --> 00:14:36.800]   These are two countries which basically murdered
[00:14:36.800 --> 00:14:39.360]   some large percentage of each other's male population,
[00:14:39.360 --> 00:14:40.640]   three times in a hundred years
[00:14:40.640 --> 00:14:42.120]   in three different wars, right?
[00:14:42.120 --> 00:14:44.520]   And now today, war is like unthinkable.
[00:14:44.520 --> 00:14:47.480]   And a lot of that is because of increased collaboration,
[00:14:47.480 --> 00:14:48.720]   increased trade.
[00:14:48.720 --> 00:14:51.480]   So when you have two capitalist actors,
[00:14:51.480 --> 00:14:54.600]   they act in a very productive way with each other.
[00:14:54.600 --> 00:14:58.280]   But as soon as you introduce an authoritarian actor,
[00:14:58.280 --> 00:14:59.680]   all bets are off.
[00:14:59.680 --> 00:15:01.800]   So I think what you have is a conflict
[00:15:01.800 --> 00:15:05.520]   between capitalist actors and authoritarian actors.
[00:15:05.520 --> 00:15:08.920]   And at the end of the day, people need to,
[00:15:08.920 --> 00:15:12.240]   yes, have more than just capitalist intentions.
[00:15:12.240 --> 00:15:16.400]   In the geopolitical level I'm talking about,
[00:15:16.400 --> 00:15:19.080]   they need to actually take a stand for principles.
[00:15:19.080 --> 00:15:23.920]   Otherwise you have athletes and businesses and governments
[00:15:23.920 --> 00:15:25.920]   that are all too happy to do business
[00:15:25.920 --> 00:15:28.480]   with the Chinese Communist Party, for example, right now.
[00:15:28.480 --> 00:15:29.720]   I think that there is a little more
[00:15:29.720 --> 00:15:34.120]   than just kind of the pure profit, yes.
[00:15:34.120 --> 00:15:36.200]   - You mentioned what are the signs
[00:15:37.200 --> 00:15:40.600]   that the state is an authoritarian state.
[00:15:40.600 --> 00:15:44.480]   How do you know if you're living in an authoritarian state
[00:15:44.480 --> 00:15:46.120]   or when you study another nation
[00:15:46.120 --> 00:15:48.000]   and analyze the behavior of another nation,
[00:15:48.000 --> 00:15:51.760]   how do you know that's an authoritarian state?
[00:15:51.760 --> 00:15:54.600]   Is it as simple as them having a dictator?
[00:15:54.600 --> 00:15:56.360]   Is it as simple as them as declaring
[00:15:56.360 --> 00:15:57.560]   that they don't have a democracy
[00:15:57.560 --> 00:15:59.200]   or is there something more subtle?
[00:15:59.200 --> 00:16:01.280]   - There's a couple of good litmus tests.
[00:16:01.280 --> 00:16:03.720]   One is actually, can you have a gay pride parade?
[00:16:03.720 --> 00:16:04.840]   (laughing)
[00:16:04.840 --> 00:16:06.000]   - That's a good- - I'm serious.
[00:16:06.000 --> 00:16:07.160]   It actually lines up perfectly.
[00:16:07.160 --> 00:16:10.000]   It doesn't matter what religion the dictatorship is.
[00:16:10.000 --> 00:16:13.160]   They don't like minorities and they love to scapegoat,
[00:16:13.160 --> 00:16:15.960]   whether it's gays or religious minorities, et cetera.
[00:16:15.960 --> 00:16:17.160]   So it lines up pretty well.
[00:16:17.160 --> 00:16:18.000]   - That's really interesting.
[00:16:18.000 --> 00:16:20.460]   - If you cannot have a gay pride parade in your country
[00:16:20.460 --> 00:16:22.520]   because you're fearful that you're gonna get
[00:16:22.520 --> 00:16:24.000]   the crap kicked out of you,
[00:16:24.000 --> 00:16:26.000]   probably live in an authoritarian regime.
[00:16:26.000 --> 00:16:31.480]   - I'm sure that's not just about some kind of homophobia.
[00:16:31.480 --> 00:16:32.320]   Why is that?
[00:16:32.320 --> 00:16:33.160]   That's really interesting.
[00:16:33.160 --> 00:16:34.000]   - It's scapegoating. - 'Cause that's right.
[00:16:34.000 --> 00:16:35.440]   I'm going through, so the-
[00:16:35.440 --> 00:16:37.280]   - Fascism scapegoats minorities.
[00:16:37.280 --> 00:16:38.240]   - There's an other.
[00:16:38.240 --> 00:16:40.960]   You create an other group and then you-
[00:16:40.960 --> 00:16:43.720]   - Yeah, I mean, Uganda is a great example of this,
[00:16:43.720 --> 00:16:46.720]   but so is Saudi Arabia, so is China.
[00:16:46.720 --> 00:16:48.360]   I mean, so is Cuba.
[00:16:48.360 --> 00:16:50.720]   I mean, these are all regimes which demonize
[00:16:50.720 --> 00:16:53.760]   the LGBT communities.
[00:16:53.760 --> 00:16:56.480]   - It's interesting because, maybe you can correct me,
[00:16:56.480 --> 00:16:59.280]   but from my very distant outsider perspective,
[00:17:02.880 --> 00:17:07.080]   sort of the way that certain authoritarian governments
[00:17:07.080 --> 00:17:11.480]   speak about gay people is it's almost like,
[00:17:11.480 --> 00:17:12.360]   what is it?
[00:17:12.360 --> 00:17:16.920]   We don't have gay people in our country kind of idea
[00:17:16.920 --> 00:17:20.100]   as opposed to scapegoating, which is like-
[00:17:20.100 --> 00:17:23.800]   - Well, denial is the most powerful form of demonization.
[00:17:23.800 --> 00:17:27.040]   I mean, this is what the Iranian dictatorship does.
[00:17:27.040 --> 00:17:29.480]   A few years ago when Ahmadinejad,
[00:17:29.480 --> 00:17:31.440]   who was then sort of the de facto leader,
[00:17:31.440 --> 00:17:34.080]   he came to Columbia University and he tried to give a speech
[00:17:34.080 --> 00:17:35.840]   which you can look up and he tried to claim
[00:17:35.840 --> 00:17:37.720]   that there were no gays in Iran.
[00:17:37.720 --> 00:17:39.800]   And that's the most powerful form of demonization
[00:17:39.800 --> 00:17:42.160]   is trying to just wipe out your outer existence.
[00:17:42.160 --> 00:17:43.960]   There's other good litmus tests too.
[00:17:43.960 --> 00:17:49.320]   For example, you can think about comedy.
[00:17:49.320 --> 00:17:51.920]   Can you make money making fun of your government
[00:17:51.920 --> 00:17:53.240]   on television?
[00:17:53.240 --> 00:17:55.880]   If you cannot, you live in a dictatorship most likely.
[00:17:55.880 --> 00:17:58.540]   I mean, it's shocking to people that I work with
[00:17:58.540 --> 00:18:00.800]   who live in dictatorships when I tell them
[00:18:00.800 --> 00:18:04.400]   that not only are comedians able to safely make fun
[00:18:04.400 --> 00:18:07.240]   of our government, but they get paid very well to do so.
[00:18:07.240 --> 00:18:09.160]   That's a hallmark of a free society.
[00:18:09.160 --> 00:18:11.680]   So that's another good litmus test.
[00:18:11.680 --> 00:18:13.920]   - Hear that Tim Dillon, you should go to North Korea.
[00:18:13.920 --> 00:18:14.760]   Check it out.
[00:18:14.760 --> 00:18:17.680]   - Yeah, and look, there are tons of flaws with democracies.
[00:18:17.680 --> 00:18:19.000]   - These are really good tests by the way.
[00:18:19.000 --> 00:18:21.280]   - United States is a deeply flawed country in many ways.
[00:18:21.280 --> 00:18:24.040]   Our prison system is a disaster.
[00:18:24.040 --> 00:18:26.880]   There's a horrible war on drugs.
[00:18:26.880 --> 00:18:30.780]   We committed a grievous crime in my opinion,
[00:18:30.780 --> 00:18:31.700]   by invading Iraq.
[00:18:31.700 --> 00:18:34.860]   Like we did a lot of problematic things,
[00:18:34.860 --> 00:18:38.520]   but our core architecture is still an open society.
[00:18:38.520 --> 00:18:41.560]   The people who criticize the US the most,
[00:18:41.560 --> 00:18:44.000]   usually live within it.
[00:18:44.000 --> 00:18:47.320]   And if they were to move to a different country
[00:18:47.320 --> 00:18:49.800]   and try to use that criticism against their new rulers,
[00:18:49.800 --> 00:18:51.560]   they wouldn't fare so well.
[00:18:51.560 --> 00:18:55.020]   So whether it's Chomsky or whomever,
[00:18:55.020 --> 00:18:56.960]   if they were to go to Cuba and live in Cuba
[00:18:56.960 --> 00:18:59.560]   and try to criticize Cuba like they do America,
[00:18:59.560 --> 00:19:01.140]   it wouldn't last very long.
[00:19:01.140 --> 00:19:03.360]   So I think what's important to distinguish
[00:19:03.360 --> 00:19:06.180]   between open societies and closed ones,
[00:19:06.180 --> 00:19:09.080]   or like free societies and authoritarian regimes,
[00:19:09.080 --> 00:19:10.860]   it doesn't mean that your government's
[00:19:10.860 --> 00:19:13.240]   gonna be good all the time.
[00:19:13.240 --> 00:19:14.760]   What it means is that the citizens
[00:19:14.760 --> 00:19:16.780]   have a way to push for reform,
[00:19:16.780 --> 00:19:18.780]   have a way to hold the rulers accountable.
[00:19:18.780 --> 00:19:21.880]   So even if you don't like what the US government does,
[00:19:21.880 --> 00:19:24.900]   whether it was under Biden or Trump or Obama or Bush,
[00:19:24.900 --> 00:19:26.960]   we can rotate them through voting.
[00:19:26.960 --> 00:19:29.440]   And we have an independent Supreme Court
[00:19:29.440 --> 00:19:30.760]   that rotates over time.
[00:19:30.760 --> 00:19:33.440]   And we have people that we can elect directly
[00:19:33.440 --> 00:19:34.760]   to serve our interests.
[00:19:34.760 --> 00:19:37.880]   And then there's like a free press and there's lobbyists
[00:19:37.880 --> 00:19:40.120]   and all kinds of people that jostle for power.
[00:19:40.120 --> 00:19:42.240]   So there's a separation of powers.
[00:19:42.240 --> 00:19:45.020]   And I like to think about a free society really
[00:19:45.020 --> 00:19:48.720]   as like at the bottom of the foundation of the pyramid
[00:19:48.720 --> 00:19:50.580]   really would be free speech.
[00:19:50.580 --> 00:19:52.360]   And then you would have civil society,
[00:19:52.360 --> 00:19:55.040]   like for example, human rights organizations,
[00:19:55.040 --> 00:19:57.640]   environmental groups, stamp collectors, athletes,
[00:19:57.640 --> 00:19:59.920]   any groups that come together beyond the government's
[00:19:59.920 --> 00:20:01.600]   sort of strict instruction.
[00:20:01.600 --> 00:20:03.240]   And then on top of that, in the third level,
[00:20:03.240 --> 00:20:04.800]   you have separation of powers.
[00:20:04.800 --> 00:20:06.760]   Again, what I'm describing.
[00:20:06.760 --> 00:20:08.180]   So authoritarian regimes don't really have
[00:20:08.180 --> 00:20:10.160]   any of these layers to them, right?
[00:20:10.160 --> 00:20:13.200]   And then at the top, then you put elections,
[00:20:13.200 --> 00:20:14.280]   but the elections are meaningless
[00:20:14.280 --> 00:20:16.000]   if you don't have the foundation below.
[00:20:16.000 --> 00:20:17.540]   Every dictator gets elected.
[00:20:17.540 --> 00:20:19.200]   Kim Jong-un gets elected.
[00:20:19.200 --> 00:20:21.220]   He's the only person on the ballot.
[00:20:21.220 --> 00:20:24.920]   Every dictator from Hitler to Chavez, they all got elected.
[00:20:24.920 --> 00:20:27.560]   Elections on their own mean literally nothing.
[00:20:27.560 --> 00:20:29.660]   You have to have these other layers beneath
[00:20:29.660 --> 00:20:31.760]   to actually be an open and free society.
[00:20:31.760 --> 00:20:34.200]   I think it's very important for people to understand.
[00:20:34.200 --> 00:20:37.760]   - Although Hitler in an interesting way,
[00:20:37.760 --> 00:20:39.160]   at a certain point just said,
[00:20:39.160 --> 00:20:42.160]   "I'm gonna be a ruler forever," which is interesting.
[00:20:42.160 --> 00:20:44.360]   There's an important switch that happens
[00:20:44.360 --> 00:20:46.960]   when you, as opposed to having a facade of elections,
[00:20:46.960 --> 00:20:49.840]   you just put that aside and saying basically like,
[00:20:49.840 --> 00:20:50.920]   "We're not even doing this."
[00:20:50.920 --> 00:20:53.680]   - Yeah, there's like a ladder that you climb, the election,
[00:20:53.680 --> 00:20:54.800]   and you pull the ladder up,
[00:20:54.800 --> 00:20:56.280]   and then no one else can climb up.
[00:20:56.280 --> 00:20:58.080]   This sadly happened in Egypt,
[00:20:58.080 --> 00:20:59.560]   and it was quite predictable
[00:20:59.560 --> 00:21:02.720]   after Mubarak was ousted after the Arab Spring.
[00:21:02.720 --> 00:21:06.680]   Morsi came in, and it looked like the Muslim Brotherhood
[00:21:06.680 --> 00:21:09.640]   was not really gonna be very democratic,
[00:21:09.640 --> 00:21:10.480]   but it didn't really matter
[00:21:10.480 --> 00:21:11.720]   because then the military came back,
[00:21:11.720 --> 00:21:14.160]   and now we have Sisi, who's even worse than Mubarak.
[00:21:14.160 --> 00:21:17.520]   So a lot of times in these regimes, unfortunately,
[00:21:17.520 --> 00:21:18.680]   it's very difficult for people
[00:21:18.680 --> 00:21:20.960]   to build that democratic society afterwards.
[00:21:20.960 --> 00:21:24.020]   Some people have told me that when you live
[00:21:24.020 --> 00:21:25.960]   in a totalitarian or an authoritarian regime,
[00:21:25.960 --> 00:21:27.440]   it's kind of like a political desert.
[00:21:27.440 --> 00:21:28.640]   What grows in the desert?
[00:21:28.640 --> 00:21:30.360]   Scorpions and cacti, right?
[00:21:30.360 --> 00:21:32.960]   So basically people with very extreme views
[00:21:32.960 --> 00:21:35.160]   because you, as an authoritarian ruler,
[00:21:35.160 --> 00:21:38.480]   your best method for control is to get rid of the moderates.
[00:21:38.480 --> 00:21:39.600]   You have to crush the moderates.
[00:21:39.600 --> 00:21:40.600]   That's very important.
[00:21:40.600 --> 00:21:43.800]   You wanna have the only opposition to you be extremists.
[00:21:43.800 --> 00:21:45.440]   That way, when you go and have negotiations
[00:21:45.440 --> 00:21:46.560]   with the United States,
[00:21:46.560 --> 00:21:48.600]   you can kind of hold up the terrorists or whomever,
[00:21:48.600 --> 00:21:51.240]   the extremists, and say, "It's either us or them," right?
[00:21:51.240 --> 00:21:52.960]   And then the realists who run the US government
[00:21:52.960 --> 00:21:53.960]   are gonna choose you,
[00:21:53.960 --> 00:21:56.320]   and that's one of the reasons why the US government
[00:21:56.320 --> 00:21:58.520]   has supported so many dictators around the world
[00:21:58.520 --> 00:22:00.640]   over the last few decades.
[00:22:00.640 --> 00:22:04.640]   - Do you think authoritarian systems emerge naturally,
[00:22:04.640 --> 00:22:06.880]   like that's the natural state of things?
[00:22:06.880 --> 00:22:10.240]   If you incorporate what human nature is,
[00:22:10.240 --> 00:22:13.320]   well, is there always going to be corrupt people
[00:22:13.320 --> 00:22:14.520]   that rise to the top?
[00:22:14.520 --> 00:22:17.840]   And we almost have to construct systems
[00:22:17.840 --> 00:22:21.560]   that protect us against ourselves kind of thing.
[00:22:21.560 --> 00:22:24.800]   Another way to ask that is,
[00:22:24.800 --> 00:22:29.600]   what kind of systems protect us from our own human nature?
[00:22:29.600 --> 00:22:34.400]   - We started with authoritarianism or autocracy, right?
[00:22:34.400 --> 00:22:38.000]   Ruled by one or a small group oligarchy.
[00:22:38.000 --> 00:22:40.680]   And all humans lived under this structure
[00:22:40.680 --> 00:22:44.960]   for the virtual bulk of all human existence,
[00:22:44.960 --> 00:22:46.360]   only until pretty recently
[00:22:46.360 --> 00:22:49.040]   did we start having actual democracy.
[00:22:49.040 --> 00:22:51.400]   The idea that we should be ruled by rules,
[00:22:51.400 --> 00:22:53.240]   not by rulers, very powerful.
[00:22:53.240 --> 00:22:56.920]   Invented in many places across the world.
[00:22:56.920 --> 00:22:58.920]   Western Africa had this idea,
[00:22:58.920 --> 00:23:00.960]   and so did the ancient Greeks.
[00:23:00.960 --> 00:23:02.640]   And they started to implement it.
[00:23:02.640 --> 00:23:03.800]   Although, as most know,
[00:23:03.800 --> 00:23:06.440]   we didn't have full democracy for a long, long time,
[00:23:06.440 --> 00:23:09.040]   'cause it was only property owners, only men,
[00:23:09.040 --> 00:23:11.440]   only people of a certain race.
[00:23:11.440 --> 00:23:15.080]   But this idea that we can rotate our rulers
[00:23:15.080 --> 00:23:18.360]   and that we could be ruled by rules is extremely powerful.
[00:23:18.360 --> 00:23:22.400]   And it really, for me, the ideas behind this,
[00:23:22.400 --> 00:23:25.480]   I think, unlocked a lot of the Industrial Revolution,
[00:23:25.480 --> 00:23:27.160]   these small personal freedoms that were allowed
[00:23:27.160 --> 00:23:28.640]   in some countries but not others.
[00:23:28.640 --> 00:23:30.800]   And they unlocked a lot of the scientific innovation
[00:23:30.800 --> 00:23:33.200]   over the last few hundred years.
[00:23:33.200 --> 00:23:34.960]   And to me, there's a really straight line
[00:23:34.960 --> 00:23:37.960]   between scientific inquiry, free speech, freedoms,
[00:23:37.960 --> 00:23:39.600]   and then more prosperity
[00:23:39.600 --> 00:23:42.800]   and more effectiveness as a civilization.
[00:23:42.800 --> 00:23:47.120]   So I think that democracy, ruled by the people,
[00:23:47.120 --> 00:23:51.400]   is definitely an upgrade from autocracy or oligarchy,
[00:23:51.400 --> 00:23:55.360]   which would be ruled by one or ruled by a small group.
[00:23:55.360 --> 00:23:58.400]   And I think that the Democratic Revolution
[00:23:58.400 --> 00:24:00.640]   has been an incredible thing for our world.
[00:24:00.640 --> 00:24:04.640]   You could do half-class full, half-class empty.
[00:24:04.640 --> 00:24:06.440]   The half-class full is that almost half the world
[00:24:06.440 --> 00:24:07.960]   lives under democracy.
[00:24:07.960 --> 00:24:09.600]   That's an incredible achievement.
[00:24:09.600 --> 00:24:10.800]   (laughing)
[00:24:10.800 --> 00:24:12.720]   - But just under half.
[00:24:12.720 --> 00:24:13.920]   - Yeah, just under half.
[00:24:13.920 --> 00:24:16.480]   But that's billions of people.
[00:24:16.480 --> 00:24:17.840]   It is billions of people.
[00:24:17.840 --> 00:24:20.600]   And if you look at the progress of things,
[00:24:20.600 --> 00:24:22.400]   it's getting better and better and better.
[00:24:22.400 --> 00:24:24.120]   I mean, if you, you know.
[00:24:24.120 --> 00:24:28.080]   - Yeah, we're a little bit of a stalemate here.
[00:24:28.080 --> 00:24:32.560]   Democracy's really blossomed between World War II
[00:24:32.560 --> 00:24:35.800]   and the year 2000, especially in the '80s and '90s.
[00:24:35.800 --> 00:24:39.960]   You had an incredible wave of fall,
[00:24:39.960 --> 00:24:42.120]   where many, many authoritarian regimes fell
[00:24:42.120 --> 00:24:44.040]   and were replaced by democracies.
[00:24:44.040 --> 00:24:49.040]   I think around 2015, the acceleration kind of
[00:24:49.040 --> 00:24:51.240]   came to a standstill a little bit.
[00:24:51.240 --> 00:24:54.440]   There's some good news in some countries
[00:24:54.440 --> 00:24:56.840]   and there's bad news in others.
[00:24:56.840 --> 00:25:00.040]   Like in the last 10 years, you've had, for example,
[00:25:00.040 --> 00:25:02.680]   the Philippines has gone backwards.
[00:25:02.680 --> 00:25:04.520]   Thailand has gone backwards.
[00:25:04.520 --> 00:25:05.880]   Bangladesh has gone backwards.
[00:25:05.880 --> 00:25:07.120]   Turkey has gone backwards.
[00:25:07.120 --> 00:25:09.440]   That's like a half billion people right there.
[00:25:09.440 --> 00:25:11.120]   So you've had some positives.
[00:25:12.480 --> 00:25:15.480]   Like, you know, there was positive movement forward
[00:25:15.480 --> 00:25:18.800]   in Armenia, Malaysia, some other countries.
[00:25:18.800 --> 00:25:21.000]   But we're kind of at a stalemate right now.
[00:25:21.000 --> 00:25:25.880]   And what most people fear about where we are right now,
[00:25:25.880 --> 00:25:29.200]   who I respect, is what is the digital transformation
[00:25:29.200 --> 00:25:32.480]   of the world due to this like progress of democracy
[00:25:32.480 --> 00:25:34.120]   or of open societies?
[00:25:34.120 --> 00:25:36.800]   And that's what concerns me the most.
[00:25:36.800 --> 00:25:37.640]   - Oh, interesting.
[00:25:37.640 --> 00:25:40.600]   So I have, and we'll talk about one of the most
[00:25:40.600 --> 00:25:42.760]   fascinating technologies, which is Bitcoin,
[00:25:42.760 --> 00:25:43.600]   how it can help.
[00:25:43.600 --> 00:25:47.120]   But I have a sense that technology,
[00:25:47.120 --> 00:25:51.400]   like most technological innovations will give power
[00:25:51.400 --> 00:25:56.400]   to the individuals, will fight authoritarian governments
[00:25:56.400 --> 00:26:00.360]   as opposed to give more power to authoritarian governments.
[00:26:00.360 --> 00:26:03.760]   But your sense is there's ways to give,
[00:26:03.760 --> 00:26:06.920]   for technology to be utilized as a tool
[00:26:06.920 --> 00:26:08.920]   for the abuse of the citizenry.
[00:26:08.920 --> 00:26:10.400]   - I've seen both.
[00:26:10.400 --> 00:26:13.120]   In my work at Ahrefs, I started by helping
[00:26:13.120 --> 00:26:15.840]   to put together backpacks with foreign information
[00:26:15.840 --> 00:26:18.520]   that we sent to the Cuban Underground Library Movement.
[00:26:18.520 --> 00:26:20.800]   So in Cuba, you know, to own a book,
[00:26:20.800 --> 00:26:23.440]   at the time you had to have the government's permission.
[00:26:23.440 --> 00:26:25.800]   There was very little internet penetration, okay?
[00:26:25.800 --> 00:26:28.400]   So we would send in movies, you know,
[00:26:28.400 --> 00:26:30.320]   V for Vendetta dubbed into Spanish,
[00:26:30.320 --> 00:26:32.920]   and people would sit inside their homes
[00:26:32.920 --> 00:26:33.960]   and they'd watch it.
[00:26:33.960 --> 00:26:35.760]   And they would answer questions with each other.
[00:26:35.760 --> 00:26:36.800]   And it was very powerful.
[00:26:36.800 --> 00:26:38.480]   And then after that, I worked with people
[00:26:38.480 --> 00:26:39.740]   inside North Korea.
[00:26:39.740 --> 00:26:41.160]   We would send in flash drives.
[00:26:41.160 --> 00:26:42.760]   We have this program called Flash Drives for Freedom.
[00:26:42.760 --> 00:26:45.840]   We've sent over a hundred thousand flash drives
[00:26:45.840 --> 00:26:47.720]   in our work into North Korea,
[00:26:47.720 --> 00:26:49.480]   a country of about 25 million people.
[00:26:49.480 --> 00:26:50.320]   That's a lot.
[00:26:50.320 --> 00:26:51.140]   It's a big, big difference.
[00:26:51.140 --> 00:26:52.960]   That's, you know, many, many millions of hours
[00:26:52.960 --> 00:26:55.160]   of films, books, movies, et cetera.
[00:26:55.160 --> 00:26:57.280]   So I've seen the power that technology can have
[00:26:57.280 --> 00:27:00.320]   where, you know, in the '60s and '70s,
[00:27:00.320 --> 00:27:02.280]   you know, to get, to break an information blockade,
[00:27:02.280 --> 00:27:03.840]   you had to like send in crates of books
[00:27:03.840 --> 00:27:05.320]   into a communist country.
[00:27:05.320 --> 00:27:07.840]   So now all of a sudden you can send the entire contents
[00:27:07.840 --> 00:27:10.260]   of what was once the Library of Alexandria
[00:27:10.260 --> 00:27:11.940]   on something the size of your thumbnail.
[00:27:11.940 --> 00:27:13.100]   Like that's remarkable.
[00:27:13.100 --> 00:27:15.500]   So obviously I've seen the positives of technology.
[00:27:15.500 --> 00:27:17.120]   We'll certainly get into Bitcoin,
[00:27:17.120 --> 00:27:18.740]   but I'm, you know, very concerned
[00:27:18.740 --> 00:27:20.820]   about essentially big data analysis,
[00:27:20.820 --> 00:27:23.460]   like what people call AI or general, you know,
[00:27:23.460 --> 00:27:26.680]   specific kinds of AI, like very concerning.
[00:27:26.680 --> 00:27:28.400]   I think these are very authoritarian.
[00:27:28.400 --> 00:27:30.620]   I mean, it's very hard to make a case
[00:27:30.620 --> 00:27:33.640]   that AI is going to be good for human rights.
[00:27:33.640 --> 00:27:35.720]   Very difficult, in my opinion.
[00:27:35.720 --> 00:27:37.100]   But it may be good for health.
[00:27:37.100 --> 00:27:40.380]   It may be good for our efforts to protect the planet.
[00:27:40.380 --> 00:27:43.060]   It may be good for a lot of scientific things.
[00:27:43.060 --> 00:27:44.180]   I find it very hard to believe
[00:27:44.180 --> 00:27:45.780]   it'll be good for civil liberties.
[00:27:45.780 --> 00:27:46.660]   - Oh, that's fun.
[00:27:46.660 --> 00:27:48.580]   This is fun 'cause I disagree.
[00:27:48.580 --> 00:27:50.700]   - Give me your examples.
[00:27:50.700 --> 00:27:52.420]   I'm serious.
[00:27:52.420 --> 00:27:55.500]   What AI applications will improve civil liberties?
[00:27:55.500 --> 00:27:58.860]   - I thought you meant examples of stuff
[00:27:58.860 --> 00:28:00.220]   that's already out there.
[00:28:00.220 --> 00:28:03.060]   'Cause I can give you examples that, for example,
[00:28:03.060 --> 00:28:04.920]   the kind of things that I would like to work on,
[00:28:04.920 --> 00:28:07.700]   but also the kind of things I'm hoping to see,
[00:28:07.700 --> 00:28:12.700]   which is AI could be used by centralized powers,
[00:28:12.700 --> 00:28:16.300]   by governments, by big organizations
[00:28:16.300 --> 00:28:18.820]   like Facebook and Twitter and so on,
[00:28:18.820 --> 00:28:21.940]   to collect data about people.
[00:28:21.940 --> 00:28:23.540]   - Right. - Right.
[00:28:23.540 --> 00:28:27.820]   But I believe there's a huge hunger among people
[00:28:27.820 --> 00:28:31.400]   to have control over their own data.
[00:28:31.400 --> 00:28:35.420]   So instead, you can have AI that's distributed
[00:28:35.420 --> 00:28:37.020]   where people have complete ownership
[00:28:37.020 --> 00:28:39.220]   of their little AI systems.
[00:28:39.220 --> 00:28:41.940]   So like the kind of stuff that I would like to build
[00:28:41.940 --> 00:28:45.100]   or like to see to be built is,
[00:28:45.100 --> 00:28:47.500]   you could think of it as personal assistance
[00:28:47.500 --> 00:28:51.380]   or AI that's owned by you.
[00:28:51.380 --> 00:28:53.340]   And you get to give it out.
[00:28:53.340 --> 00:28:55.620]   You have complete control over all of your data.
[00:28:55.620 --> 00:28:58.140]   You have complete control over everything
[00:28:58.140 --> 00:29:01.820]   that's learnable about your day-to-day experiences
[00:29:01.820 --> 00:29:06.820]   that could be useful in the market of goods and ideas
[00:29:06.820 --> 00:29:08.220]   and all those kinds of things.
[00:29:08.220 --> 00:29:10.300]   So it has to do with,
[00:29:10.300 --> 00:29:13.100]   so I know you talk about the surveillance,
[00:29:13.100 --> 00:29:14.580]   which is very interesting.
[00:29:14.580 --> 00:29:17.580]   It's who gets to have control of the data.
[00:29:17.580 --> 00:29:21.060]   And I think, I believe there's a lot of hunger
[00:29:21.060 --> 00:29:27.320]   among regular people to have control over their data.
[00:29:28.020 --> 00:29:31.420]   Such that if you want to create a business,
[00:29:31.420 --> 00:29:33.300]   you have a lot of money to be made
[00:29:33.300 --> 00:29:35.100]   from a capitalist perspective
[00:29:35.100 --> 00:29:38.660]   by providing products that let people control their data,
[00:29:38.660 --> 00:29:40.740]   where you have no control.
[00:29:40.740 --> 00:29:43.380]   - Sounds like to me, you're describing encryption
[00:29:43.380 --> 00:29:45.620]   or at least the ability to encrypt,
[00:29:45.620 --> 00:29:49.900]   the ability to use digital keys to secure your property.
[00:29:49.900 --> 00:29:54.220]   And that to me is a very powerful individual right,
[00:29:54.220 --> 00:29:56.500]   force for individual rights, very powerful.
[00:29:56.500 --> 00:29:58.460]   And it's what animates Bitcoin ultimately,
[00:29:58.460 --> 00:30:00.140]   which we'll get into.
[00:30:00.140 --> 00:30:03.940]   But for me, at least the way I look at it today in 2021,
[00:30:03.940 --> 00:30:07.140]   the threat from big data analysis
[00:30:07.140 --> 00:30:10.340]   used by governments and authoritarian regimes is terrifying.
[00:30:10.340 --> 00:30:11.300]   I mean, to actually see
[00:30:11.300 --> 00:30:13.480]   what the Chinese Communist Party is doing,
[00:30:13.480 --> 00:30:15.740]   where they have hundreds of millions of cameras
[00:30:15.740 --> 00:30:17.220]   overseeing society,
[00:30:17.220 --> 00:30:20.560]   cameras that can tell who's a Uyghur and who's a Han,
[00:30:20.560 --> 00:30:22.120]   that to me is terrifying.
[00:30:22.120 --> 00:30:24.340]   And everything is sorted instantly.
[00:30:24.340 --> 00:30:27.740]   There are super computers that are built in Urumqi,
[00:30:27.740 --> 00:30:30.460]   in Xinjiang for this explicit purpose.
[00:30:30.460 --> 00:30:33.700]   And it allows the government to quickly sort
[00:30:33.700 --> 00:30:35.780]   and basically commit genocide a lot faster.
[00:30:35.780 --> 00:30:37.020]   And it's really scary.
[00:30:37.020 --> 00:30:39.660]   So I do agree and I've seen personally
[00:30:39.660 --> 00:30:43.820]   how powerful technology can be as a force for freedom.
[00:30:43.820 --> 00:30:46.980]   But I'm very, very worried about big data analysis
[00:30:46.980 --> 00:30:48.160]   in the hands of governments.
[00:30:48.160 --> 00:30:51.020]   - See, that's funny 'cause I tend to see governments
[00:30:51.020 --> 00:30:53.880]   as ultimately incompetent in the space of technology
[00:30:53.880 --> 00:30:56.420]   to where there will always be lagging behind.
[00:30:56.420 --> 00:30:58.900]   So you look at what the Chinese surveillance systems
[00:30:58.900 --> 00:31:00.140]   are doing.
[00:31:00.140 --> 00:31:03.060]   I believe once it started getting bad enough
[00:31:03.060 --> 00:31:08.980]   that technologies would be created to resist that.
[00:31:08.980 --> 00:31:12.180]   So to mess with it from the hacker community,
[00:31:12.180 --> 00:31:14.800]   but also from the individual community.
[00:31:14.800 --> 00:31:16.540]   So surveillance is actually very difficult
[00:31:16.540 --> 00:31:20.280]   from a centralized perspective to detect,
[00:31:20.280 --> 00:31:22.400]   to collect data about you, to detect everything you are,
[00:31:22.400 --> 00:31:24.800]   because you can spoof a lot of that information.
[00:31:24.800 --> 00:31:27.980]   So I believe you can put power in the hands of the citizens
[00:31:27.980 --> 00:31:31.060]   to sort of feed the government fake data,
[00:31:31.060 --> 00:31:33.260]   to confuse it at a mass scale
[00:31:33.260 --> 00:31:36.740]   to where it'll make their surveillance less effective.
[00:31:36.740 --> 00:31:39.740]   But that, okay, that could be very sort of hopeful.
[00:31:39.740 --> 00:31:42.300]   - Yeah, I mean, the practical application in Xinjiang,
[00:31:42.300 --> 00:31:44.660]   which is a territory the size of Alaska,
[00:31:44.660 --> 00:31:46.620]   where a large percentage of the population
[00:31:46.620 --> 00:31:48.900]   has been put into prison camps.
[00:31:48.900 --> 00:31:50.100]   The current issue of the New Yorker
[00:31:50.100 --> 00:31:52.540]   has an absolutely harrowing essay
[00:31:52.540 --> 00:31:55.220]   that tells the story of one such woman
[00:31:55.220 --> 00:31:59.900]   who in, I believe, 2017 got sucked into one of these camps
[00:31:59.900 --> 00:32:03.240]   and it took her a year or more to get out.
[00:32:03.240 --> 00:32:08.080]   And she's talking about how in each home in Xinjiang,
[00:32:08.080 --> 00:32:10.620]   each home has a QR code on it that the police can scan
[00:32:10.620 --> 00:32:13.360]   and get like a quick instant download of who lives there.
[00:32:13.360 --> 00:32:16.420]   Each car has like a scannable code.
[00:32:17.700 --> 00:32:20.380]   Every single person has their DNA taken
[00:32:20.380 --> 00:32:22.140]   and the DNA is being sifted through
[00:32:22.140 --> 00:32:24.160]   and analyzed by algorithms.
[00:32:24.160 --> 00:32:26.560]   So this is like the Chinese government's laboratory
[00:32:26.560 --> 00:32:29.740]   for how can we use technology to oppress.
[00:32:29.740 --> 00:32:31.300]   It's like sort of like digital Leninism.
[00:32:31.300 --> 00:32:34.940]   And that to me is one of the biggest risks
[00:32:34.940 --> 00:32:37.340]   in our world today and it's not talked about enough.
[00:32:37.340 --> 00:32:38.180]   - That's interesting.
[00:32:38.180 --> 00:32:40.940]   So technology basically enables
[00:32:40.940 --> 00:32:42.460]   the automation of oppression.
[00:32:42.460 --> 00:32:43.300]   - Absolutely.
[00:32:43.300 --> 00:32:44.500]   - So like.
[00:32:44.500 --> 00:32:46.940]   - But define technology.
[00:32:46.940 --> 00:32:51.700]   - Big data analysis and maybe specific AI, et cetera does.
[00:32:51.700 --> 00:32:53.860]   But encryption allows us to fight back.
[00:32:53.860 --> 00:32:55.060]   It's very important people understand
[00:32:55.060 --> 00:32:56.500]   we have tools to fight back.
[00:32:56.500 --> 00:33:02.220]   Big Brother can only grow if it can feed on your data.
[00:33:02.220 --> 00:33:04.580]   If it can't get your data, it can't grow.
[00:33:04.580 --> 00:33:08.780]   So you have to willingly give up stuff to the cloud
[00:33:08.780 --> 00:33:10.220]   for this monster to grow.
[00:33:10.220 --> 00:33:13.820]   We can make the monster hungry and shrink it
[00:33:13.820 --> 00:33:15.100]   if we give it less data.
[00:33:15.100 --> 00:33:16.420]   And I think that's where I would agree with you
[00:33:16.420 --> 00:33:18.340]   in terms of like wanting to empower people
[00:33:18.340 --> 00:33:21.220]   to be able to do stuff on their own terms
[00:33:21.220 --> 00:33:22.580]   in a sovereign way.
[00:33:22.580 --> 00:33:25.140]   And yeah, maybe you're kind of thinking
[00:33:25.140 --> 00:33:27.260]   like the personal assistant who helps out Tony Stark
[00:33:27.260 --> 00:33:28.420]   or something like that.
[00:33:28.420 --> 00:33:30.860]   And that's yeah, as long as there's no back doors
[00:33:30.860 --> 00:33:32.660]   and that's a sovereign thing that you've popped up
[00:33:32.660 --> 00:33:36.000]   and created and you have the keys to, absolutely.
[00:33:36.000 --> 00:33:39.700]   But practically speaking, if we're talking about
[00:33:39.700 --> 00:33:43.140]   the world today as is, we need to be concerned
[00:33:43.140 --> 00:33:44.740]   about the way that authoritarian regimes
[00:33:44.740 --> 00:33:46.460]   are using big data analysis.
[00:33:46.460 --> 00:33:48.780]   And they're gonna buy the software and this equipment
[00:33:48.780 --> 00:33:49.700]   from the Chinese government.
[00:33:49.700 --> 00:33:50.940]   They're already doing it.
[00:33:50.940 --> 00:33:53.420]   Street level surveillance has already been purchased
[00:33:53.420 --> 00:33:55.020]   by governments everywhere from Latin America
[00:33:55.020 --> 00:33:58.100]   to Sub-Saharan Africa to the heart of Europe.
[00:33:58.100 --> 00:33:59.820]   There's been huge scandals in Britain
[00:33:59.820 --> 00:34:02.580]   over their purchase of Chinese surveillance technology.
[00:34:02.580 --> 00:34:06.260]   Part of the Chinese government's Belt and Road campaign,
[00:34:06.260 --> 00:34:09.360]   which is basically to build the infrastructure
[00:34:09.360 --> 00:34:11.580]   of this century and to be in control of it,
[00:34:12.340 --> 00:34:14.900]   part of that idea is to ship out
[00:34:14.900 --> 00:34:17.660]   and install surveillance technology,
[00:34:17.660 --> 00:34:20.380]   both at the telecom level and at the surveillance level
[00:34:20.380 --> 00:34:22.420]   across dozens of countries around the world
[00:34:22.420 --> 00:34:24.020]   and have that back door.
[00:34:24.020 --> 00:34:26.040]   There's this national security law in China,
[00:34:26.040 --> 00:34:28.420]   which states that companies that are Chinese,
[00:34:28.420 --> 00:34:30.660]   which are abroad, are mandated to send data
[00:34:30.660 --> 00:34:32.060]   back to Beijing.
[00:34:32.060 --> 00:34:35.380]   So they are building this huge global surveillance state.
[00:34:35.380 --> 00:34:37.380]   And again, not talked about enough,
[00:34:37.380 --> 00:34:40.060]   you should go Google and research the Belt and Road.
[00:34:40.060 --> 00:34:42.560]   I think it's very important that we confront this.
[00:34:42.560 --> 00:34:45.740]   - Yeah, I'm really glad you're talking about it
[00:34:45.740 --> 00:34:48.300]   because it's probably important to understand.
[00:34:48.300 --> 00:34:52.720]   I'm also hopeful that as people get educated
[00:34:52.720 --> 00:34:57.560]   about how much their data, when collected, unencrypted,
[00:34:57.560 --> 00:35:01.100]   but in general, can be used to harm them.
[00:35:01.100 --> 00:35:02.860]   I mean, it's almost like an education.
[00:35:02.860 --> 00:35:07.620]   I feel like if you know,
[00:35:07.620 --> 00:35:08.700]   it's a double-edged sword
[00:35:08.700 --> 00:35:11.180]   because I feel like people become fearful too easily
[00:35:11.180 --> 00:35:12.940]   and that actually has a very negative effect
[00:35:12.940 --> 00:35:14.620]   on the quality of life.
[00:35:14.620 --> 00:35:16.700]   In some sense, you want to have tools
[00:35:16.700 --> 00:35:19.160]   that allow you to live freely as opposed to live in fear.
[00:35:19.160 --> 00:35:22.540]   If you live in fear, it's not a good way to live.
[00:35:22.540 --> 00:35:24.420]   So it's a balance.
[00:35:24.420 --> 00:35:26.180]   - It's a free society versus a fear society.
[00:35:26.180 --> 00:35:27.020]   - Yeah, fear society.
[00:35:27.020 --> 00:35:28.300]   - And look, people are,
[00:35:28.300 --> 00:35:30.460]   it's all about the trade-offs you make in your daily life.
[00:35:30.460 --> 00:35:33.140]   Like living more privately with more freedom
[00:35:33.140 --> 00:35:35.620]   is less convenient.
[00:35:35.620 --> 00:35:39.460]   You trade freedom and privacy for convenience
[00:35:39.460 --> 00:35:41.180]   and comfort and speed.
[00:35:41.180 --> 00:35:43.020]   Absolutely, it's an engineering decision
[00:35:43.020 --> 00:35:44.320]   in everything that you do.
[00:35:44.320 --> 00:35:49.100]   In the West, in advanced democracies,
[00:35:49.100 --> 00:35:53.460]   we have not necessarily personally seen
[00:35:53.460 --> 00:35:54.500]   the results of that trade-off
[00:35:54.500 --> 00:35:56.940]   because we live in these free societies
[00:35:56.940 --> 00:35:59.180]   that have these checks and balances and freedoms.
[00:35:59.180 --> 00:36:01.260]   But as soon as you step into an authoritarian state
[00:36:01.260 --> 00:36:02.620]   and you make those trade-offs,
[00:36:02.620 --> 00:36:05.860]   your life immediately becomes more restrictive.
[00:36:05.860 --> 00:36:07.960]   And what people are worried about is that
[00:36:07.960 --> 00:36:12.960]   even in advanced economies, market democracies, et cetera,
[00:36:12.960 --> 00:36:16.080]   the people are worried that they might not survive
[00:36:16.080 --> 00:36:19.580]   the great social digital transformation.
[00:36:19.580 --> 00:36:23.020]   Look at what the NSA is capable of doing.
[00:36:23.020 --> 00:36:26.560]   I mean, for now, it's not that big of a problem
[00:36:26.560 --> 00:36:28.980]   because we still have free speech.
[00:36:28.980 --> 00:36:31.720]   But it's deeply concerning what Snowden revealed,
[00:36:31.720 --> 00:36:34.900]   and it's a nice reminder that we need to be focused
[00:36:34.900 --> 00:36:38.020]   on privacy and encryption and on helping users
[00:36:38.020 --> 00:36:41.380]   become more sovereign regardless of where you live.
[00:36:41.380 --> 00:36:43.780]   It's kind of like a crutch to live in a free society.
[00:36:43.780 --> 00:36:47.220]   Like, you know, it's almost like a free lunch in a way.
[00:36:47.220 --> 00:36:49.280]   You're not gonna be sent to a prison camp
[00:36:49.280 --> 00:36:51.940]   because of the color of your skin or your beliefs
[00:36:51.940 --> 00:36:54.060]   or what you say about the government.
[00:36:54.060 --> 00:36:55.420]   And you're very lucky.
[00:36:55.420 --> 00:36:57.500]   Again, most people do live in a society
[00:36:57.500 --> 00:37:00.340]   where you can be persecuted for those things.
[00:37:00.340 --> 00:37:03.580]   And I feel like, especially in America, we forget that.
[00:37:03.580 --> 00:37:07.960]   We're distanced from that really strong reality, you know?
[00:37:07.960 --> 00:37:11.140]   - On the topic of Snowden and the NSA,
[00:37:11.140 --> 00:37:12.980]   what should we be thinking about?
[00:37:12.980 --> 00:37:15.020]   'Cause that feels like already an outdated
[00:37:15.020 --> 00:37:17.540]   set of conversations because of the information
[00:37:17.540 --> 00:37:19.460]   we've gotten from the past.
[00:37:19.460 --> 00:37:21.440]   It feels like everything's gotten quiet now
[00:37:21.440 --> 00:37:23.380]   in terms of how much we actually know about the--
[00:37:23.380 --> 00:37:24.980]   - Hugely important.
[00:37:24.980 --> 00:37:27.080]   I think the two lessons from Snowden are A,
[00:37:28.420 --> 00:37:31.100]   the Patriot Act and the War on Terror and mass surveillance
[00:37:31.100 --> 00:37:34.960]   are not necessary for our democracy and for our freedoms.
[00:37:34.960 --> 00:37:37.220]   This was a false choice.
[00:37:37.220 --> 00:37:39.380]   We never had to sacrifice them to be safer.
[00:37:39.380 --> 00:37:41.660]   And we've seen that.
[00:37:41.660 --> 00:37:43.140]   Government has spent hundreds and hundreds
[00:37:43.140 --> 00:37:45.620]   of millions of dollars on these surveillance programs
[00:37:45.620 --> 00:37:48.700]   that you can read about have amounted to very little,
[00:37:48.700 --> 00:37:50.380]   except for tremendous bureaucratic waste
[00:37:50.380 --> 00:37:54.260]   and the erosion of our freedoms.
[00:37:54.260 --> 00:37:57.260]   But at the same time, we need to practice more privacy.
[00:37:57.260 --> 00:38:00.460]   And the dramatic increase in the usage of Signal,
[00:38:00.460 --> 00:38:03.940]   for example, has been really, really great to see.
[00:38:03.940 --> 00:38:05.980]   It's fantastic that tens of millions of people
[00:38:05.980 --> 00:38:08.380]   are downloading Signal and using it.
[00:38:08.380 --> 00:38:10.900]   You should try to be onboarding more and more
[00:38:10.900 --> 00:38:13.540]   of your conversations onto Signal, for example,
[00:38:13.540 --> 00:38:16.260]   where governments can't see what you're saying.
[00:38:16.260 --> 00:38:17.820]   Maybe they can see the metadata.
[00:38:17.820 --> 00:38:20.240]   Maybe they can see that you sent your phone number,
[00:38:20.240 --> 00:38:23.540]   sent a message to someone else's phone number at this time,
[00:38:23.540 --> 00:38:25.080]   but they can't see what's inside.
[00:38:25.080 --> 00:38:27.620]   So using encryption in your life is very, very important.
[00:38:27.620 --> 00:38:29.100]   That's a good starting point.
[00:38:29.100 --> 00:38:30.800]   I would say that's kind of step A.
[00:38:30.800 --> 00:38:34.380]   - The ideas of democracy,
[00:38:34.380 --> 00:38:36.420]   the ideas of the balance of power,
[00:38:36.420 --> 00:38:40.580]   all the ideas that we were talking about,
[00:38:40.580 --> 00:38:44.260]   the constructs, were inventions.
[00:38:44.260 --> 00:38:46.500]   I wonder if there's other inventions
[00:38:46.500 --> 00:38:50.140]   that will allow us to sort of not engage,
[00:38:50.140 --> 00:38:53.780]   not give governments or any centralized institutions
[00:38:53.780 --> 00:38:55.460]   so much power.
[00:38:55.460 --> 00:38:59.100]   Like why do citizens have to use Signal?
[00:38:59.100 --> 00:38:59.940]   Why?
[00:38:59.940 --> 00:39:00.760]   Because that's an effort.
[00:39:00.760 --> 00:39:01.600]   You have to be,
[00:39:01.600 --> 00:39:03.860]   'cause you have to like understand exactly why.
[00:39:03.860 --> 00:39:05.140]   So that's a nice little solution
[00:39:05.140 --> 00:39:06.460]   for a particular set of problems.
[00:39:06.460 --> 00:39:08.020]   But like there's a million other ways
[00:39:08.020 --> 00:39:11.560]   that data I'm sure is being collected constantly.
[00:39:11.560 --> 00:39:14.340]   If we don't create a system
[00:39:14.340 --> 00:39:18.760]   that prevents the establishments of these centralized powers,
[00:39:18.760 --> 00:39:20.820]   then we'll always have this problem.
[00:39:20.820 --> 00:39:22.020]   - Yeah, I think we can keep it simple
[00:39:22.020 --> 00:39:23.700]   for the purposes of this conversation.
[00:39:23.700 --> 00:39:25.900]   You have politics, information, and money.
[00:39:25.900 --> 00:39:26.740]   Those are the three things
[00:39:26.740 --> 00:39:28.820]   I would encourage us to focus on.
[00:39:28.820 --> 00:39:32.140]   In politics, yes, someone invented democracy.
[00:39:32.140 --> 00:39:34.340]   I mean, whether it was the Greeks,
[00:39:34.340 --> 00:39:36.620]   the West Africans, or many others around the world
[00:39:36.620 --> 00:39:38.380]   around the same time invented this idea
[00:39:38.380 --> 00:39:41.660]   that we should be ruled by rules and not by rulers, right?
[00:39:41.660 --> 00:39:45.380]   And that has evolved dramatically, right?
[00:39:45.380 --> 00:39:46.900]   And then you have information.
[00:39:46.900 --> 00:39:50.060]   Information also used to be highly centralized, right?
[00:39:50.060 --> 00:39:52.220]   Think about how rich you had to be
[00:39:52.220 --> 00:39:54.700]   to gain access to a library before the printing press,
[00:39:54.700 --> 00:39:56.940]   or how much money you had to have,
[00:39:56.940 --> 00:40:00.480]   or how close to the king or the feudal lord you had to be
[00:40:00.480 --> 00:40:02.580]   to be able to have that ability.
[00:40:02.580 --> 00:40:05.900]   But now, the majority of the world,
[00:40:05.900 --> 00:40:07.980]   billions of people have access to all information
[00:40:07.980 --> 00:40:09.580]   in their pocket, and they can set up an account
[00:40:09.580 --> 00:40:11.460]   on social media and get their word out.
[00:40:11.460 --> 00:40:13.360]   So not only politics,
[00:40:13.360 --> 00:40:17.120]   but information has been dramatically decentralized.
[00:40:17.120 --> 00:40:19.820]   And I would say that encrypted messaging
[00:40:19.820 --> 00:40:22.860]   is kind of a corollary to that second innovation.
[00:40:22.860 --> 00:40:26.060]   And as much as now people are more effortlessly,
[00:40:26.060 --> 00:40:29.580]   like signal is a lot easier to use than PGP, for example,
[00:40:29.580 --> 00:40:32.020]   they're more easily able to practice privacy
[00:40:32.020 --> 00:40:35.980]   when it comes to having private messages globally.
[00:40:35.980 --> 00:40:38.280]   These are all good things, and we need to keep pushing.
[00:40:38.280 --> 00:40:40.940]   And I think money is, honestly,
[00:40:40.940 --> 00:40:42.540]   maybe the most important piece.
[00:40:42.540 --> 00:40:45.420]   And that's why I spend so much time thinking about Bitcoin.
[00:40:45.420 --> 00:40:49.620]   - Okay, so politics, information, money.
[00:40:49.620 --> 00:40:50.460]   - Yes.
[00:40:50.460 --> 00:40:52.020]   - Let's talk about money.
[00:40:52.020 --> 00:40:54.180]   What is money and why is it important
[00:40:54.180 --> 00:40:57.480]   to think about in the context of human rights?
[00:40:57.480 --> 00:41:03.540]   - I have witnessed money be peripheralized.
[00:41:03.540 --> 00:41:07.700]   It has taken a back seat in the human rights conversation.
[00:41:07.700 --> 00:41:10.020]   The idea of currency, who makes the money,
[00:41:10.020 --> 00:41:12.040]   who makes the rules, who issues it,
[00:41:12.040 --> 00:41:14.780]   who sets the interest rates, all these things,
[00:41:14.780 --> 00:41:17.180]   it is not on the menu of human rights activists.
[00:41:17.180 --> 00:41:18.760]   If you just do like a systematic study
[00:41:18.760 --> 00:41:20.140]   of like the human rights discourse
[00:41:20.140 --> 00:41:23.540]   over the last several decades, money is not there.
[00:41:23.540 --> 00:41:25.100]   It's also not really taught in schools.
[00:41:25.100 --> 00:41:26.940]   Like children don't really learn about money.
[00:41:26.940 --> 00:41:28.060]   Where does it come from?
[00:41:28.060 --> 00:41:31.960]   It's kind of hidden from a lot of our discourse.
[00:41:31.960 --> 00:41:35.180]   Only really when I got into Bitcoin
[00:41:35.180 --> 00:41:37.940]   did I start learning more about money.
[00:41:37.940 --> 00:41:40.580]   I spent 10 years at the Human Rights Foundation,
[00:41:40.580 --> 00:41:43.140]   and we did all kinds of programs around the world.
[00:41:43.140 --> 00:41:45.660]   We convened Oslo Freedom Forums in different places,
[00:41:45.660 --> 00:41:47.900]   and I got to meet hundreds of dissidents.
[00:41:47.900 --> 00:41:50.160]   And very rarely did they ever speak about currency
[00:41:50.160 --> 00:41:53.740]   or bank accounts or moving money from one place to another.
[00:41:53.740 --> 00:41:55.620]   But when I started asking them,
[00:41:55.620 --> 00:41:58.320]   they always had amazing stories about money, always.
[00:41:58.320 --> 00:41:59.780]   I mean, my friend Ivan Mawire,
[00:41:59.780 --> 00:42:03.140]   who started the Disflag Movement in Zimbabwe,
[00:42:03.140 --> 00:42:05.320]   which ended up toppling Robert Mugabe,
[00:42:05.320 --> 00:42:07.160]   when I asked him to come to San Francisco
[00:42:07.160 --> 00:42:10.340]   to give a talk about hyperinflation, which he lived through,
[00:42:10.340 --> 00:42:12.660]   he said, "No one's ever asked me to do that before,
[00:42:12.660 --> 00:42:13.500]   "but I'll come."
[00:42:13.500 --> 00:42:15.540]   And he came, this was about three years ago.
[00:42:15.540 --> 00:42:17.180]   And the first thing he did when he got on the stage
[00:42:17.180 --> 00:42:19.620]   was he opened up a shirt and he brought out a necklace
[00:42:19.620 --> 00:42:21.940]   that had the 1980 Zimbabwean dollar on it.
[00:42:21.940 --> 00:42:25.180]   And he said, "We in the activist community wear this
[00:42:25.180 --> 00:42:27.040]   "as a symbol of where our country used to be,
[00:42:27.040 --> 00:42:28.300]   "because the Zimbabwean dollar
[00:42:28.300 --> 00:42:30.220]   "used to be worth two British pounds."
[00:42:30.220 --> 00:42:33.660]   And then, of course, over the next two and a half decades
[00:42:33.660 --> 00:42:37.060]   of economic mismanagement and corruption by Mugabe,
[00:42:37.060 --> 00:42:38.580]   it got inflated out of existence, right?
[00:42:38.580 --> 00:42:41.880]   You've seen those like $100 trillion Zimbabwean notes.
[00:42:41.880 --> 00:42:43.020]   So he had to live through that,
[00:42:43.020 --> 00:42:45.420]   which was terrible and crushing.
[00:42:45.420 --> 00:42:47.420]   But he is an expert on money.
[00:42:47.420 --> 00:42:49.920]   If you actually talk to human rights activists about money,
[00:42:49.920 --> 00:42:51.780]   they know a lot about money.
[00:42:51.780 --> 00:42:54.200]   They're just not usually asked to talk about it.
[00:42:54.200 --> 00:42:59.200]   So for me, money, when I study money or look at money,
[00:42:59.200 --> 00:43:01.100]   it's really about control.
[00:43:01.100 --> 00:43:04.260]   Who is creating it and how much does the population know
[00:43:04.260 --> 00:43:06.500]   about the creation of that money?
[00:43:06.500 --> 00:43:09.380]   And when it comes to Bitcoin, it's really the people's money.
[00:43:09.380 --> 00:43:12.500]   Like there is no shadowy force in charge of it.
[00:43:12.500 --> 00:43:13.980]   We all know the rules.
[00:43:13.980 --> 00:43:15.580]   We all know how it's gonna get minted
[00:43:15.580 --> 00:43:17.300]   and how it's gonna get printed.
[00:43:17.300 --> 00:43:20.260]   And that information is out there for everybody to see.
[00:43:20.260 --> 00:43:22.300]   And there's no like special group of rules
[00:43:22.300 --> 00:43:25.500]   for one group of people or another group.
[00:43:25.500 --> 00:43:28.180]   A billionaire and a refugee are the same
[00:43:28.180 --> 00:43:29.980]   in the eyes of the protocol.
[00:43:29.980 --> 00:43:33.140]   This is a rather revolutionary concept.
[00:43:33.140 --> 00:43:35.860]   And in the same way that democracy allowed us
[00:43:35.860 --> 00:43:38.900]   to decentralize politics and have checks and balances,
[00:43:38.900 --> 00:43:40.380]   and in the same way that the internet
[00:43:40.380 --> 00:43:41.920]   is this culmination of technologies
[00:43:41.920 --> 00:43:44.700]   that allowed us to decentralize information,
[00:43:44.700 --> 00:43:47.060]   access to and control over it,
[00:43:47.060 --> 00:43:49.820]   Bitcoin, you know, decentralizes money.
[00:43:49.820 --> 00:43:52.960]   I mean, no longer again, is there one group of people
[00:43:52.960 --> 00:43:54.880]   who can just change it arbitrarily?
[00:43:54.880 --> 00:43:56.920]   We're all in the same playing field.
[00:43:56.920 --> 00:43:59.360]   And I think that that is a tremendous innovation.
[00:43:59.360 --> 00:44:02.360]   - You know, from one perspective,
[00:44:02.360 --> 00:44:05.120]   money and inflation, hyperinflation,
[00:44:05.120 --> 00:44:08.080]   is a kind of symptom of corruption
[00:44:08.080 --> 00:44:10.380]   as opposed to the core of the corruption.
[00:44:11.620 --> 00:44:15.440]   And at the flip side, in terms of resisting the corruption,
[00:44:15.440 --> 00:44:19.300]   resisting the abuse of human rights,
[00:44:19.300 --> 00:44:24.840]   it's interesting to think that fighting inflation
[00:44:24.840 --> 00:44:29.840]   or fighting the mismanagement of the money supply
[00:44:29.840 --> 00:44:35.000]   is a way to fight back authoritarianism
[00:44:35.000 --> 00:44:37.060]   or to fight authoritarianism.
[00:44:37.060 --> 00:44:40.700]   And that's an interesting concept
[00:44:40.700 --> 00:44:42.520]   that I think was introduced to me
[00:44:42.520 --> 00:44:45.000]   by just plugging myself intellectually
[00:44:45.000 --> 00:44:46.160]   into the Bitcoin community,
[00:44:46.160 --> 00:44:48.560]   but also just cryptocurrency in general.
[00:44:48.560 --> 00:44:53.560]   It's to like, it's not that money is a symptom.
[00:44:53.560 --> 00:44:57.920]   You know, money is a tool to fight back too.
[00:44:57.920 --> 00:45:00.180]   - Absolutely.
[00:45:00.180 --> 00:45:03.680]   - So in what way can Bitcoin be used
[00:45:03.680 --> 00:45:07.720]   to fight authoritarianism?
[00:45:07.720 --> 00:45:10.320]   - Yes. - Not just in the United States,
[00:45:10.320 --> 00:45:13.660]   but all of those 53% that you're referring to.
[00:45:13.660 --> 00:45:15.360]   How can Bitcoin help?
[00:45:15.360 --> 00:45:17.520]   - So we talked about authoritarianism
[00:45:17.520 --> 00:45:20.240]   and we talked about the surveillance state.
[00:45:20.240 --> 00:45:23.560]   To me, Bitcoin has two kind of key mechanisms
[00:45:23.560 --> 00:45:25.000]   through which it can help us.
[00:45:25.000 --> 00:45:29.160]   Number one, it's a sovereign savings account.
[00:45:29.160 --> 00:45:30.400]   It's debasement proof,
[00:45:30.400 --> 00:45:32.040]   meaning the government cannot print more
[00:45:32.040 --> 00:45:33.720]   whenever they want.
[00:45:33.720 --> 00:45:35.960]   This is very, very different from fiat currency,
[00:45:35.960 --> 00:45:38.520]   which by its very name, its very nature,
[00:45:38.520 --> 00:45:41.840]   can be issued on sort of demand, right, by the rulers.
[00:45:41.840 --> 00:45:43.920]   And while I live in a country
[00:45:43.920 --> 00:45:46.080]   where the rulers do a reasonable job
[00:45:46.080 --> 00:45:48.800]   of managing the money, most people aren't so lucky.
[00:45:48.800 --> 00:45:51.640]   So only 13% of humans in the world
[00:45:51.640 --> 00:45:53.520]   live in a country that's a liberal democracy
[00:45:53.520 --> 00:45:54.640]   with property rights
[00:45:54.640 --> 00:45:57.080]   and has what we call a reserve currency,
[00:45:57.080 --> 00:45:58.960]   meaning a currency so stable and desirable
[00:45:58.960 --> 00:46:00.400]   that other countries save in it
[00:46:00.400 --> 00:46:02.120]   at the central bank level, right?
[00:46:02.120 --> 00:46:06.080]   You basically have the US, the UK, Australia,
[00:46:06.080 --> 00:46:09.000]   Switzerland, the Euro, and Canada.
[00:46:09.000 --> 00:46:10.640]   I mean, those are like reserve currencies
[00:46:10.640 --> 00:46:11.880]   and these are liberal democracies
[00:46:11.880 --> 00:46:13.160]   where people have reasonable guarantees
[00:46:13.160 --> 00:46:14.280]   over property rights.
[00:46:14.280 --> 00:46:17.800]   Everybody else either lives under like a weaker currency
[00:46:17.800 --> 00:46:19.440]   or an authoritarian regime.
[00:46:19.440 --> 00:46:21.300]   That's 87% of the world's population,
[00:46:21.300 --> 00:46:22.720]   almost 7 billion people.
[00:46:22.720 --> 00:46:26.120]   So for them, a sovereign savings account
[00:46:26.120 --> 00:46:26.960]   that's permissionless,
[00:46:26.960 --> 00:46:28.920]   meaning you don't have to have ID to use it,
[00:46:28.920 --> 00:46:30.160]   is a big, big deal.
[00:46:30.160 --> 00:46:32.600]   And a lot of people talk about Zimbabwe or Venezuela
[00:46:32.600 --> 00:46:34.440]   as some like isolated cases.
[00:46:34.440 --> 00:46:37.420]   Oh, well, you know, hyperinflation only happens
[00:46:37.420 --> 00:46:39.240]   in those two countries.
[00:46:39.240 --> 00:46:40.720]   I actually did some research into this
[00:46:40.720 --> 00:46:42.840]   and there's about one point,
[00:46:42.840 --> 00:46:46.920]   over, you know, close to 1.3 billion people
[00:46:46.920 --> 00:46:49.200]   who live under double or triple digit inflation.
[00:46:49.200 --> 00:46:51.240]   This is not an isolated instance.
[00:46:51.240 --> 00:46:52.800]   We're talking huge countries.
[00:46:52.800 --> 00:46:56.000]   Nigeria, 200 million people, 15% inflation.
[00:46:56.000 --> 00:46:59.440]   Turkey, 15% inflation for 100 million people.
[00:46:59.440 --> 00:47:04.040]   Argentina, 40% inflation for a country of 45 million people.
[00:47:04.040 --> 00:47:04.920]   So you can go down the list.
[00:47:04.920 --> 00:47:08.360]   There's about 35 countries where like people's earnings,
[00:47:08.360 --> 00:47:11.040]   their wages are literally disappearing
[00:47:11.040 --> 00:47:14.080]   in front of their eyes over a matter of weeks or months
[00:47:14.080 --> 00:47:17.280]   against things like the dollar, gold, real estate, right?
[00:47:17.280 --> 00:47:19.480]   So this is a huge issue.
[00:47:19.480 --> 00:47:21.240]   It absolutely is a human rights issue for me.
[00:47:21.240 --> 00:47:23.260]   I mean, when it comes to your time and energy,
[00:47:23.260 --> 00:47:26.320]   having control over that or having it stolen from you,
[00:47:26.320 --> 00:47:27.880]   I think this is pretty clear.
[00:47:27.880 --> 00:47:31.480]   And Bitcoin is like an immediate, low cost,
[00:47:31.480 --> 00:47:34.040]   easily accessible solution for people.
[00:47:34.040 --> 00:47:37.200]   And I've learned this not from my own assumptions,
[00:47:37.200 --> 00:47:40.840]   but by talking to people, by interviewing dozens of people,
[00:47:40.840 --> 00:47:42.680]   whether it's in Sudan,
[00:47:42.680 --> 00:47:45.720]   which currently has triple digit inflation,
[00:47:45.720 --> 00:47:48.840]   or people who've escaped from Syria,
[00:47:48.840 --> 00:47:51.520]   who have used Bitcoin to get their wealth out of the country
[00:47:51.520 --> 00:47:54.600]   and then also to make payments back to people inside,
[00:47:54.600 --> 00:47:56.240]   or Venezuela or elsewhere.
[00:47:56.240 --> 00:47:58.320]   It's very, very powerful.
[00:47:58.320 --> 00:48:00.440]   - I think some very small percentage of people
[00:48:00.440 --> 00:48:02.720]   have used, have owned Bitcoin.
[00:48:02.720 --> 00:48:05.240]   What's it something like 1% of the world?
[00:48:05.240 --> 00:48:07.040]   Whatever the number is, it's small.
[00:48:07.040 --> 00:48:09.360]   - Call it 2% for the purposes of our time.
[00:48:09.360 --> 00:48:12.200]   About a little under 200 million people.
[00:48:12.200 --> 00:48:13.160]   - Wow, yeah.
[00:48:13.160 --> 00:48:15.040]   - At most right now.
[00:48:15.040 --> 00:48:17.920]   - So if we look at Zimbabwe, Sudan, if we look at-
[00:48:17.920 --> 00:48:19.840]   - Small percentages of people.
[00:48:19.840 --> 00:48:22.320]   - Do you think the technology is mature enough?
[00:48:22.320 --> 00:48:23.720]   'Cause it's not just about the idea,
[00:48:23.720 --> 00:48:25.660]   it's also about the implementation of it.
[00:48:25.660 --> 00:48:29.580]   Like, you know, Bitcoin for the most part
[00:48:29.580 --> 00:48:32.840]   requires access to the internet.
[00:48:32.840 --> 00:48:33.680]   - Yeah.
[00:48:33.680 --> 00:48:38.680]   - And what do you think about accessibility
[00:48:38.680 --> 00:48:41.880]   of this technology now as a method of activism
[00:48:41.880 --> 00:48:43.340]   in the worst parts of the world?
[00:48:43.340 --> 00:48:45.420]   We often think, like all the conversations we've had
[00:48:45.420 --> 00:48:48.220]   about Bitcoin is essentially middle-class,
[00:48:48.220 --> 00:48:51.100]   like wealthy people relative to the rest of the world.
[00:48:51.100 --> 00:48:53.400]   They're kind of talking with sort of investment
[00:48:53.400 --> 00:48:55.880]   and high concept ideas.
[00:48:55.880 --> 00:48:58.300]   Then there's also the people in the world who are suffering,
[00:48:58.300 --> 00:49:01.020]   who are living through hyperinflation.
[00:49:01.020 --> 00:49:03.820]   They may not have a computer or access to the internet.
[00:49:03.820 --> 00:49:05.900]   How do you think Bitcoin can help there?
[00:49:05.900 --> 00:49:08.940]   - Yeah, so again, we have one clear use case,
[00:49:08.940 --> 00:49:10.660]   which is a sovereign savings account
[00:49:10.660 --> 00:49:11.980]   that you can control, right?
[00:49:11.980 --> 00:49:15.140]   The other use case is an unstoppable payments network.
[00:49:15.140 --> 00:49:16.980]   This is very important for people who live behind,
[00:49:16.980 --> 00:49:18.540]   for example, sanctions.
[00:49:18.540 --> 00:49:21.740]   Like the US basically weaponizes the dollar
[00:49:21.740 --> 00:49:24.220]   and it like sanctions different countries.
[00:49:24.220 --> 00:49:27.020]   And instead of sanctioning like a handful of rulers,
[00:49:27.020 --> 00:49:28.400]   for example, which I would support,
[00:49:28.400 --> 00:49:30.740]   this is like a Magnitsky or smart sanctions.
[00:49:30.740 --> 00:49:31.740]   Sometimes we'll just say,
[00:49:31.740 --> 00:49:33.100]   we're just gonna shut off this whole country.
[00:49:33.100 --> 00:49:34.160]   - So the people suffer.
[00:49:34.160 --> 00:49:36.000]   - Cuba or Iran are good examples.
[00:49:36.000 --> 00:49:37.600]   Average people suffer, right?
[00:49:37.600 --> 00:49:40.060]   So people in those two countries I just mentioned,
[00:49:40.060 --> 00:49:41.840]   Cuba, Iran, or even Palestine,
[00:49:41.840 --> 00:49:45.500]   which is also sort of like blockaded by the Israelis.
[00:49:45.500 --> 00:49:48.660]   So you have Cuba, Iran, Palestine are three good examples
[00:49:48.660 --> 00:49:50.880]   where people inside all three of those countries now
[00:49:50.880 --> 00:49:53.700]   are using Bitcoin to do commerce, do their business,
[00:49:53.700 --> 00:49:54.860]   send money back and forth.
[00:49:54.860 --> 00:49:56.340]   - So it's sanction resistant.
[00:49:56.340 --> 00:49:57.640]   - Sanctions resistant.
[00:49:57.640 --> 00:49:59.840]   It does not get stopped by sanctions, right?
[00:49:59.840 --> 00:50:03.980]   And also it's again, remittances are extortionate.
[00:50:03.980 --> 00:50:08.420]   I mean, the average remittance costs has a high fee,
[00:50:08.420 --> 00:50:09.540]   takes several days.
[00:50:09.540 --> 00:50:11.880]   If your family is in Ghana or something like that,
[00:50:11.880 --> 00:50:13.620]   or Nigeria, and you live in the United States,
[00:50:13.620 --> 00:50:16.020]   it can take time to use Western Union.
[00:50:16.020 --> 00:50:19.100]   Sometimes, it gets paused, it gets lost, there's issues.
[00:50:19.100 --> 00:50:20.780]   You have to deal with customer service,
[00:50:20.780 --> 00:50:21.620]   screw that.
[00:50:21.620 --> 00:50:24.020]   I mean, the person has a cell phone,
[00:50:24.020 --> 00:50:25.980]   which increasingly is the case.
[00:50:25.980 --> 00:50:27.580]   I mean, by the end of next year,
[00:50:27.580 --> 00:50:30.900]   more than five or six billion people,
[00:50:30.900 --> 00:50:31.860]   depending on different estimates,
[00:50:31.860 --> 00:50:35.700]   will have smartphones basically by the end of 2022.
[00:50:35.700 --> 00:50:38.260]   We're talking like the vast majority of humans
[00:50:38.260 --> 00:50:40.060]   will have access to smartphones.
[00:50:40.060 --> 00:50:42.380]   They can all have sovereign Bitcoin wallets.
[00:50:42.380 --> 00:50:46.220]   And there's even ways to access Bitcoin without the internet.
[00:50:46.220 --> 00:50:48.780]   But I mean, we can get into that.
[00:50:48.780 --> 00:50:50.500]   - There's like hardware wallets and so on.
[00:50:50.500 --> 00:50:54.140]   What do you mean by sovereign Bitcoin wallet?
[00:50:54.140 --> 00:50:58.340]   - You know, most users today are using Bitcoin
[00:50:58.340 --> 00:51:00.300]   in a custodial manner.
[00:51:00.300 --> 00:51:03.340]   So this is kind of like having a bank account,
[00:51:03.340 --> 00:51:07.240]   where you have a deposit account at a bank, right?
[00:51:07.240 --> 00:51:08.660]   So you have a claim, right?
[00:51:08.660 --> 00:51:10.820]   You go to the bank and they have some of your money,
[00:51:10.820 --> 00:51:12.220]   and you take it out, right?
[00:51:12.220 --> 00:51:13.260]   With an ATM.
[00:51:13.260 --> 00:51:17.980]   So what I would call non-custodial Bitcoin use
[00:51:17.980 --> 00:51:20.940]   would be similar to withdrawing cash from an ATM.
[00:51:20.940 --> 00:51:23.060]   You have it, it's a bearer instrument, okay?
[00:51:23.060 --> 00:51:23.900]   So when I-- - Bearer instrument.
[00:51:23.900 --> 00:51:25.380]   - That's what it's called, the bearer instrument.
[00:51:25.380 --> 00:51:26.500]   - I know, I apologize.
[00:51:26.500 --> 00:51:28.060]   I'm outside this community, it just sounds funny.
[00:51:28.060 --> 00:51:29.820]   - No, no, no, yeah, so like a bearer instrument
[00:51:29.820 --> 00:51:33.820]   would be like a bar of gold or a bank note,
[00:51:33.820 --> 00:51:35.180]   or Bitcoin that you control,
[00:51:35.180 --> 00:51:37.260]   meaning you have the seed phrase, right?
[00:51:37.260 --> 00:51:40.980]   Which for the listeners essentially is 12 to 24
[00:51:40.980 --> 00:51:42.740]   English words that you write down on a piece of paper.
[00:51:42.740 --> 00:51:46.180]   That's your password to get into your Bitcoin account.
[00:51:46.180 --> 00:51:49.380]   And that gives you that bearer instrument quality, right?
[00:51:49.380 --> 00:51:53.500]   But unfortunately, most users still use Bitcoin
[00:51:53.500 --> 00:51:56.300]   in a custodial way, meaning they buy it on Coinbase.
[00:51:56.300 --> 00:51:57.700]   - So Coinbase-- - Or Square,
[00:51:57.700 --> 00:51:58.540]   or something like that.
[00:51:58.540 --> 00:52:00.900]   - You would put into the-- - Custodial.
[00:52:00.900 --> 00:52:02.900]   - Into the custodial category-- - It's like a Bitcoin bank.
[00:52:02.900 --> 00:52:03.820]   - Yeah.
[00:52:03.820 --> 00:52:06.260]   - And look, the good news is you can withdraw
[00:52:06.260 --> 00:52:07.460]   to your own control.
[00:52:07.460 --> 00:52:10.100]   And in the Bitcoin community, we try to teach this idea
[00:52:10.100 --> 00:52:12.420]   that it's not your keys, not your coins.
[00:52:12.420 --> 00:52:14.680]   In the same way that if you deposit your money at the bank,
[00:52:14.680 --> 00:52:15.660]   you might not get it back.
[00:52:15.660 --> 00:52:19.620]   I mean, it's low likelihood, but it's very possible.
[00:52:19.620 --> 00:52:20.700]   Same thing in Bitcoin.
[00:52:20.700 --> 00:52:22.060]   If you wanna get the full experience,
[00:52:22.060 --> 00:52:24.340]   you wanna actually custody your own Bitcoin.
[00:52:24.340 --> 00:52:26.900]   You wanna put it, whether it's on an open source
[00:52:26.900 --> 00:52:29.200]   software wallet, like the Blue Wallet is a good one
[00:52:29.200 --> 00:52:31.740]   for people to check out, or a hardware wallet,
[00:52:31.740 --> 00:52:33.580]   like Cold Card, for example.
[00:52:33.580 --> 00:52:35.540]   There's different ways to do this.
[00:52:35.540 --> 00:52:39.660]   But essentially, around the world, people are innovating.
[00:52:39.660 --> 00:52:41.900]   Don't think so low of your fellow man,
[00:52:41.900 --> 00:52:42.720]   you know what I mean?
[00:52:42.720 --> 00:52:44.820]   People are able to figure this out.
[00:52:44.820 --> 00:52:46.300]   I get a lot of flack from people saying,
[00:52:46.300 --> 00:52:47.860]   "Oh, Bitcoin's so hard to use."
[00:52:47.860 --> 00:52:49.260]   I read this article in the New York Times
[00:52:49.260 --> 00:52:51.880]   saying this guy in Silicon Valley lost all of his Bitcoin.
[00:52:51.880 --> 00:52:54.320]   That's 'cause he was a moron and didn't care about it.
[00:52:54.320 --> 00:52:55.700]   This guy lost all this Bitcoin
[00:52:55.700 --> 00:52:57.820]   because it wasn't worth much 10 years ago.
[00:52:57.820 --> 00:52:59.500]   And he forgot the password.
[00:52:59.500 --> 00:53:01.660]   But if you're receiving your remittance
[00:53:01.660 --> 00:53:04.660]   from a family member, you're not gonna lose the password.
[00:53:04.660 --> 00:53:06.740]   - And you trust in the basic intelligence of people
[00:53:06.740 --> 00:53:10.860]   to figure this out and to innovate and so on and figure out.
[00:53:10.860 --> 00:53:12.700]   - We're watching it, man.
[00:53:12.700 --> 00:53:15.820]   - Yeah, you know, it's kind of funny,
[00:53:15.820 --> 00:53:17.700]   but people in the United States
[00:53:17.700 --> 00:53:19.740]   are not very savvy with money.
[00:53:19.740 --> 00:53:21.940]   It's exactly the way you're describing it.
[00:53:21.940 --> 00:53:24.580]   When you have very little money,
[00:53:24.580 --> 00:53:26.900]   you're going to be savvy with money.
[00:53:26.900 --> 00:53:30.460]   You're going to understand exactly the mechanisms that work,
[00:53:30.460 --> 00:53:33.080]   that are resistant to the corruption that's around you.
[00:53:33.080 --> 00:53:36.880]   I mean, I remember sort of growing up in the Soviet Union,
[00:53:36.880 --> 00:53:41.020]   the general bureaucracy and the corruption
[00:53:41.020 --> 00:53:42.100]   of everything around you.
[00:53:42.100 --> 00:53:43.980]   You figure out ways around that.
[00:53:43.980 --> 00:53:45.740]   You figure out ways how to function
[00:53:45.740 --> 00:53:49.180]   within that kind of system to survive under inflation,
[00:53:49.180 --> 00:53:52.460]   under hyperinflation, under all like basically
[00:53:52.460 --> 00:53:54.160]   being unable to trust any kind of,
[00:53:54.160 --> 00:53:56.120]   even the police force and all those kinds of things.
[00:53:56.120 --> 00:53:57.200]   You figure it out.
[00:53:57.200 --> 00:54:00.460]   And that same way, perhaps Bitcoin could be
[00:54:00.460 --> 00:54:05.420]   all the different ways to store and gain Bitcoin.
[00:54:05.420 --> 00:54:08.100]   These mechanisms could be something that's figured out
[00:54:08.100 --> 00:54:09.780]   in the third world as opposed to in the United States.
[00:54:09.780 --> 00:54:11.780]   - Oh, I mean, I would say the capital of Bitcoin
[00:54:11.780 --> 00:54:14.620]   could easily be Lagos and not San Francisco
[00:54:14.620 --> 00:54:16.820]   in terms of users, in terms of people using it.
[00:54:16.820 --> 00:54:20.060]   And again, the two use cases as a savings account
[00:54:20.060 --> 00:54:21.980]   and as an unstoppable payment rail.
[00:54:21.980 --> 00:54:23.860]   These are the two ones that you should really think about.
[00:54:23.860 --> 00:54:25.520]   This is how people are using it today.
[00:54:25.520 --> 00:54:29.620]   Now, when it comes to, could it possibly be adopted
[00:54:29.620 --> 00:54:32.620]   by like a sufficient majority of the population?
[00:54:32.620 --> 00:54:33.460]   I say yes.
[00:54:33.460 --> 00:54:36.260]   And it's very similar to the way the mobile phone spread.
[00:54:36.260 --> 00:54:39.820]   At the beginning, the cell phone was only for rich people.
[00:54:39.820 --> 00:54:40.780]   It was only for the elite.
[00:54:40.780 --> 00:54:41.620]   It was huge.
[00:54:41.620 --> 00:54:42.500]   It didn't work very well.
[00:54:42.500 --> 00:54:43.380]   The interface sucked.
[00:54:43.380 --> 00:54:44.580]   It was clunky.
[00:54:44.580 --> 00:54:47.700]   Over time, it got smaller and smaller and cheaper
[00:54:47.700 --> 00:54:49.780]   and cheaper and easier to use and easier to use.
[00:54:49.780 --> 00:54:51.980]   And today, everyone benefits.
[00:54:51.980 --> 00:54:53.960]   So you're gonna watch a similar technology
[00:54:53.960 --> 00:54:55.620]   upgrade process with Bitcoin.
[00:54:55.620 --> 00:54:57.380]   Already in the last 10 years,
[00:54:57.380 --> 00:54:59.500]   Bitcoin has gotten so much easier to use.
[00:54:59.500 --> 00:55:02.500]   I mean, there are now mobile wallets that are so slick.
[00:55:02.500 --> 00:55:05.180]   There's one called Moon, M-U-U-N wallet
[00:55:05.180 --> 00:55:06.420]   from a team in Argentina.
[00:55:06.420 --> 00:55:09.900]   And these guys created it because they saw their own currency
[00:55:09.900 --> 00:55:12.700]   devalued like three times in the last 20 years.
[00:55:12.700 --> 00:55:14.740]   And they've had a hell of a time trying to get their money
[00:55:14.740 --> 00:55:16.340]   back and forth in different countries.
[00:55:16.340 --> 00:55:19.060]   So they were like, let's make this easy for people.
[00:55:19.060 --> 00:55:21.980]   Again, this is the people's money.
[00:55:21.980 --> 00:55:24.020]   This is something that cannot be controlled
[00:55:24.020 --> 00:55:25.920]   by governments or corporations.
[00:55:25.920 --> 00:55:27.840]   And that makes it very powerful.
[00:55:27.840 --> 00:55:29.900]   And I think it's actually quite exciting
[00:55:29.900 --> 00:55:31.860]   to be here in the adoption phase.
[00:55:31.860 --> 00:55:32.940]   - In the early days.
[00:55:32.940 --> 00:55:34.460]   - Yeah, man, this is the early days.
[00:55:34.460 --> 00:55:36.900]   - And you also mentioned that sort of Bitcoin
[00:55:36.900 --> 00:55:40.060]   is the mechanism of a peaceful revolution.
[00:55:40.060 --> 00:55:45.060]   So it's a way to resist authoritarianism in a peaceful way.
[00:55:45.060 --> 00:55:47.220]   It's ultimately a, you know,
[00:55:47.220 --> 00:55:52.220]   you mentioned sort of politics, information, and money.
[00:55:52.220 --> 00:55:55.660]   It seems like in the space of money,
[00:55:55.660 --> 00:55:57.780]   this is one of the peaceful mechanisms.
[00:55:57.780 --> 00:55:59.780]   - It's a way to opt out.
[00:55:59.780 --> 00:56:02.800]   You can opt out peacefully from the system.
[00:56:02.800 --> 00:56:05.020]   - And yeah, it's beautiful.
[00:56:05.020 --> 00:56:06.380]   It's beautiful.
[00:56:06.380 --> 00:56:10.300]   So Bitcoin is currently by far the most popular
[00:56:10.300 --> 00:56:12.340]   sort of dominant cryptocurrency.
[00:56:12.340 --> 00:56:15.260]   That said, and I look forward to your letters,
[00:56:15.260 --> 00:56:17.540]   Bitcoin maximalists.
[00:56:17.540 --> 00:56:19.860]   That said, you know, Internet Explorer
[00:56:19.860 --> 00:56:23.980]   was the most popular browser for quite a long time.
[00:56:23.980 --> 00:56:27.940]   And then other browsers came along that out-competed it,
[00:56:27.940 --> 00:56:32.380]   like Chrome, Firefox, people should check out Brave.
[00:56:32.380 --> 00:56:34.060]   It's a great browser.
[00:56:34.060 --> 00:56:36.340]   I think it's my favorite browser at this point.
[00:56:36.340 --> 00:56:38.020]   Anyway, so why Bitcoin?
[00:56:38.020 --> 00:56:39.780]   Why not another cryptocurrency?
[00:56:39.780 --> 00:56:43.620]   If you look in the next 10, 20, 50, 100 years,
[00:56:43.620 --> 00:56:46.500]   do you think it's possible for another cryptocurrency
[00:56:46.500 --> 00:56:49.860]   like Ethereum or something that's not even here yet
[00:56:49.860 --> 00:56:52.440]   to overtake Bitcoin as a mechanism?
[00:56:52.440 --> 00:56:57.340]   - When you say overtake, what do you mean?
[00:56:57.340 --> 00:56:58.420]   What do you mean overtake?
[00:56:58.420 --> 00:56:59.300]   You mean number of users?
[00:56:59.300 --> 00:57:02.060]   Do you mean a price per coin?
[00:57:02.060 --> 00:57:03.060]   - Yeah, the number of users,
[00:57:03.060 --> 00:57:05.460]   'cause we're talking about 1%, 2%.
[00:57:05.460 --> 00:57:10.460]   And if we are serious about this being in the space of money
[00:57:10.460 --> 00:57:16.980]   as a way to give individuals power,
[00:57:16.980 --> 00:57:20.500]   fight the centralized powers that abuse the money system
[00:57:20.500 --> 00:57:24.860]   and so on, how do we get from 2% to 50%, right?
[00:57:24.860 --> 00:57:28.500]   To 60%, to 80%.
[00:57:28.500 --> 00:57:31.540]   That jump, is it obvious to you?
[00:57:31.540 --> 00:57:34.900]   Not obvious, but do you think Bitcoin
[00:57:34.900 --> 00:57:38.260]   is the way to get from 2% to 50%
[00:57:38.260 --> 00:57:41.020]   or are there going to be other cryptocurrencies
[00:57:41.020 --> 00:57:43.260]   that may emerge that get us to 50%?
[00:57:43.260 --> 00:57:45.420]   - No, I mean, Bitcoin is the innovation.
[00:57:45.420 --> 00:57:48.540]   The innovation is in having the decentralized mint.
[00:57:48.540 --> 00:57:51.060]   No one can change the monetary policy.
[00:57:51.060 --> 00:57:53.140]   Everything else is downstream from there.
[00:57:53.140 --> 00:57:55.500]   In Bitcoin, the mean would be 21 million.
[00:57:55.500 --> 00:57:57.740]   There's never gonna be any more than 21 million.
[00:57:57.740 --> 00:57:59.220]   Every other cryptocurrency
[00:57:59.220 --> 00:58:01.620]   either has an inflationary policy,
[00:58:01.620 --> 00:58:02.460]   meaning there's gonna continue
[00:58:02.460 --> 00:58:04.420]   to be more and more of it over time,
[00:58:04.420 --> 00:58:06.580]   or its monetary policy can be changed
[00:58:06.580 --> 00:58:08.020]   by a small group of people.
[00:58:08.020 --> 00:58:09.820]   This is vividly on display in Ethereum,
[00:58:09.820 --> 00:58:11.260]   which is like the second largest
[00:58:11.260 --> 00:58:13.980]   and second most robust cryptocurrency, right?
[00:58:13.980 --> 00:58:17.180]   I've talked to senior Ethereum engineers
[00:58:17.180 --> 00:58:18.020]   over the last couple of weeks,
[00:58:18.020 --> 00:58:21.860]   trying to figure out what is the monetary policy of Ethereum?
[00:58:21.860 --> 00:58:23.060]   No one can tell me.
[00:58:23.060 --> 00:58:25.260]   No one knows how much ETH is gonna be minted
[00:58:25.260 --> 00:58:29.020]   in 2022 and 2023 after they shift to proof of stake.
[00:58:29.020 --> 00:58:33.140]   I've seen estimates that range from 100,000 to 2 million.
[00:58:33.140 --> 00:58:33.980]   So at the end of the day,
[00:58:33.980 --> 00:58:35.620]   you're gonna be trusting a small group of people
[00:58:35.620 --> 00:58:36.860]   to make those decisions.
[00:58:36.860 --> 00:58:39.140]   That is what we are escaping with Bitcoin.
[00:58:39.140 --> 00:58:41.300]   So all these other cryptocurrencies,
[00:58:41.300 --> 00:58:42.980]   they might have their use cases.
[00:58:42.980 --> 00:58:44.540]   Virtually all of them are not.
[00:58:44.540 --> 00:58:45.940]   It's very important for people to know
[00:58:45.940 --> 00:58:48.420]   that if you take like the 4,500 cryptocurrencies
[00:58:48.420 --> 00:58:52.660]   on CoinMarketCap, almost all of them are scams, straight up.
[00:58:52.660 --> 00:58:55.700]   Even the ones that have like noble intentions,
[00:58:55.700 --> 00:58:59.460]   I just don't think are gonna add that much value ultimately.
[00:58:59.460 --> 00:59:02.140]   I think Bitcoin to me is the innovation.
[00:59:02.140 --> 00:59:05.220]   And that's because it has a monetary policy
[00:59:05.220 --> 00:59:08.300]   and an issuance schedule that cannot be changed.
[00:59:08.300 --> 00:59:09.580]   And that's what gets me so excited about it.
[00:59:09.580 --> 00:59:11.340]   I mean, that's why it's such an important tool
[00:59:11.340 --> 00:59:12.220]   for human rights.
[00:59:12.220 --> 00:59:15.220]   - Yeah, it's interesting 'cause when you grow from 2%,
[00:59:15.220 --> 00:59:18.380]   when you grow in the number of people using it
[00:59:18.380 --> 00:59:19.940]   at the scale they're using it,
[00:59:19.940 --> 00:59:25.380]   it's going to need to be resistant to governments
[00:59:25.380 --> 00:59:27.500]   and institutions messing with it.
[00:59:27.500 --> 00:59:29.100]   So it's interesting to see
[00:59:29.220 --> 00:59:33.380]   what kind of cryptocurrency would be resistant to that.
[00:59:33.380 --> 00:59:36.580]   Obviously, Dogecoin is gonna win, let's be honest.
[00:59:36.580 --> 00:59:41.380]   - Well, I mean, look, the number two cryptocurrency
[00:59:41.380 --> 00:59:44.500]   in the world probably by like how useful it is to people
[00:59:44.500 --> 00:59:49.020]   is Tether, which is totally centralized, has blacklists.
[00:59:49.020 --> 00:59:52.460]   So I'm not saying there won't be like new digital assets
[00:59:52.460 --> 00:59:55.700]   that are lumped into this category that have usage,
[00:59:55.700 --> 00:59:59.260]   but it's not the same innovation as Bitcoin.
[00:59:59.260 --> 01:00:01.300]   It's just sort of building on this idea
[01:00:01.300 --> 01:00:02.620]   of like a Euro dollar maybe,
[01:00:02.620 --> 01:00:04.660]   like a dollar that is minted outside
[01:00:04.660 --> 01:00:07.260]   of the control of the US Federal Reserve, right?
[01:00:07.260 --> 01:00:08.140]   It would be a Euro dollar.
[01:00:08.140 --> 01:00:09.660]   So stable coins are kind of like Euro dollars
[01:00:09.660 --> 01:00:11.900]   just minted by private actors in a way, right?
[01:00:11.900 --> 01:00:13.260]   But they're still tied to the dollar.
[01:00:13.260 --> 01:00:14.740]   They're pegged to the dollar.
[01:00:14.740 --> 01:00:16.340]   They're not escaping the system.
[01:00:16.340 --> 01:00:18.180]   Escaping the system is Bitcoin.
[01:00:18.180 --> 01:00:20.540]   We aren't reliant on the dollar.
[01:00:20.540 --> 01:00:24.980]   We have our own full store value, medium of exchange,
[01:00:24.980 --> 01:00:26.540]   unit of account eventually.
[01:00:26.540 --> 01:00:29.520]   And the Bitcoin world will be denominated
[01:00:29.520 --> 01:00:30.540]   in different terms.
[01:00:30.540 --> 01:00:32.720]   And I think everyone, everything else will be tied to it.
[01:00:32.720 --> 01:00:33.740]   I really do.
[01:00:33.740 --> 01:00:37.780]   - It does feel currently like Bitcoin is like pirates
[01:00:37.780 --> 01:00:38.700]   or something like that.
[01:00:38.700 --> 01:00:40.500]   And there's still like the central banks
[01:00:40.500 --> 01:00:44.220]   that are like the main navies of the different nations.
[01:00:44.220 --> 01:00:46.420]   It's just like, if you talk about scale,
[01:00:46.420 --> 01:00:48.020]   so there's going to be a moment
[01:00:48.020 --> 01:00:50.980]   if Bitcoin continues to grow in its impact,
[01:00:50.980 --> 01:00:54.380]   when governments are going to seriously contend with,
[01:00:54.380 --> 01:00:55.780]   what do we do with this?
[01:00:55.780 --> 01:00:58.420]   Do you think about those moments?
[01:00:58.420 --> 01:01:02.020]   Is Bitcoin, is the cryptocurrency world in general
[01:01:02.020 --> 01:01:07.020]   going to be able to withstand the serious legal pushback
[01:01:07.020 --> 01:01:09.140]   from countries, from nations,
[01:01:09.140 --> 01:01:11.580]   especially authoritarian nations?
[01:01:11.580 --> 01:01:13.160]   - Yeah, so it's been interesting.
[01:01:13.160 --> 01:01:15.780]   It's been 12 years, okay?
[01:01:15.780 --> 01:01:19.300]   More than 12 years since Satoshi Nakamoto created Bitcoin.
[01:01:19.300 --> 01:01:21.420]   And they haven't been able to stop it.
[01:01:21.420 --> 01:01:22.660]   They have tried.
[01:01:22.660 --> 01:01:23.660]   They have tried a lot.
[01:01:23.660 --> 01:01:25.620]   I wrote a long essay for Quillette on this.
[01:01:25.620 --> 01:01:28.820]   Like, why haven't governments been able to stop Bitcoin?
[01:01:28.820 --> 01:01:31.340]   And my thesis is essentially that there's been like this mix
[01:01:31.340 --> 01:01:34.780]   of different kinds of technical, social,
[01:01:34.780 --> 01:01:37.500]   and economic and political incentives and disincentives
[01:01:37.500 --> 01:01:39.260]   that make it very difficult.
[01:01:39.260 --> 01:01:42.460]   And I think to me, the best way to think about it
[01:01:42.460 --> 01:01:44.300]   is that Bitcoin is like a Trojan horse.
[01:01:44.300 --> 01:01:47.860]   So just to actually tell that story just a little bit,
[01:01:47.860 --> 01:01:49.540]   because I think it's important to understand
[01:01:49.540 --> 01:01:52.540]   the classical mythology tale,
[01:01:52.540 --> 01:01:53.640]   I find this very interesting.
[01:01:53.640 --> 01:01:54.480]   - Of the actual Trojan horse?
[01:01:54.480 --> 01:01:55.660]   - Of the actual Trojan horse, yeah,
[01:01:55.660 --> 01:01:59.140]   which was told in the Aeneid, actually, by Virgil, right?
[01:01:59.140 --> 01:02:00.980]   And the idea was the Greeks had been like
[01:02:00.980 --> 01:02:03.620]   trying to take the city of Troy for like a decade
[01:02:03.620 --> 01:02:06.420]   at these like impregnable walls, and they couldn't do it.
[01:02:06.420 --> 01:02:08.620]   And Ulysses and the rest of the Greek army were like,
[01:02:08.620 --> 01:02:10.060]   we don't know what to do.
[01:02:10.060 --> 01:02:13.980]   So Minerva, the god of strategy and war,
[01:02:13.980 --> 01:02:15.980]   kind of like they get this idea from her, I guess,
[01:02:15.980 --> 01:02:18.540]   to actually try to use subterfuge and trickery
[01:02:18.540 --> 01:02:20.220]   to take over the city.
[01:02:20.220 --> 01:02:23.180]   So the idea is to, and this was sort of hatched by Ulysses,
[01:02:23.180 --> 01:02:25.540]   right, to put this horse together
[01:02:25.540 --> 01:02:27.420]   that would kind of be like a gift.
[01:02:27.420 --> 01:02:30.840]   So the idea was the Greeks just like pretended to leave,
[01:02:30.840 --> 01:02:33.840]   right, they deserted, they left behind one soldier
[01:02:33.840 --> 01:02:35.920]   and this horse, and the Trojans looked at it
[01:02:35.920 --> 01:02:37.540]   and they were like, what's going on here?
[01:02:37.540 --> 01:02:39.080]   And they brought in the soldier,
[01:02:39.080 --> 01:02:40.800]   and the soldier's like, look, they left,
[01:02:40.800 --> 01:02:43.600]   they're so sorry for all of the desecration and blood spill.
[01:02:43.600 --> 01:02:47.080]   This is their gift to you, it's honoring Minerva.
[01:02:47.080 --> 01:02:50.160]   It's like this like, you know, trophy for you guys.
[01:02:50.160 --> 01:02:53.460]   And there were actually people inside Troy,
[01:02:53.460 --> 01:02:55.780]   Cassandra, a prophet, as well as Laocoon,
[01:02:55.780 --> 01:02:57.080]   who was like a priest who said, no, no, no,
[01:02:57.080 --> 01:02:59.940]   this is obviously a trick, this is obviously a trick.
[01:02:59.940 --> 01:03:01.880]   But they were like dispatched and ignored
[01:03:01.880 --> 01:03:04.440]   because the horse was like, it was just like so badass.
[01:03:04.440 --> 01:03:07.480]   So the Trojans were like, bring it into the city.
[01:03:07.480 --> 01:03:08.920]   So they brought it in themselves.
[01:03:08.920 --> 01:03:10.360]   No blood spilled at all, right?
[01:03:10.360 --> 01:03:11.720]   In the middle of the night, of course,
[01:03:11.720 --> 01:03:13.360]   we've, what you realize is the horse was packed
[01:03:13.360 --> 01:03:14.520]   with Greek soldiers and they come out
[01:03:14.520 --> 01:03:15.360]   and they let the army in,
[01:03:15.360 --> 01:03:16.860]   which was like hiding behind an island.
[01:03:16.860 --> 01:03:21.660]   So this idea that like, something could be so attractive
[01:03:21.660 --> 01:03:22.900]   that you really can't say no,
[01:03:22.900 --> 01:03:24.340]   even if you know what's inside of it,
[01:03:24.340 --> 01:03:26.140]   is it played in Bitcoin.
[01:03:26.140 --> 01:03:29.580]   So like, in Bitcoin has this number go up technology, right?
[01:03:29.580 --> 01:03:33.780]   It is what we call it in sort of shorthand, NGO, NGU, right?
[01:03:33.780 --> 01:03:36.220]   But what people don't realize is that NGU
[01:03:36.220 --> 01:03:37.660]   is like the Trojan horse.
[01:03:37.660 --> 01:03:41.140]   Inside the Trojan horse is FGU, freedom go up technology.
[01:03:41.140 --> 01:03:44.740]   So dictators and rogue regimes and corporations
[01:03:44.740 --> 01:03:48.500]   are gonna buy, mine, tax, accumulate this thing
[01:03:48.500 --> 01:03:50.620]   because it's the best performing financial asset
[01:03:50.620 --> 01:03:51.460]   in the world.
[01:03:51.460 --> 01:03:55.060]   What they don't realize or they're gonna have to ignore
[01:03:55.060 --> 01:03:56.740]   is that they're also aiding and abetting
[01:03:56.740 --> 01:03:57.840]   this freedom technology,
[01:03:57.840 --> 01:04:00.060]   which allows individuals to be sovereign
[01:04:00.060 --> 01:04:02.000]   and eventually erodes their power.
[01:04:02.000 --> 01:04:04.460]   There's no question that rogue regimes and bad actors
[01:04:04.460 --> 01:04:06.780]   are already used and will continue to use Bitcoin.
[01:04:06.780 --> 01:04:08.460]   The thing is, when you think about a North Korea
[01:04:08.460 --> 01:04:11.620]   or a Venezuela and that government instructs
[01:04:11.620 --> 01:04:14.300]   some of its bureaucrats and cronies and officials
[01:04:14.300 --> 01:04:18.060]   to start stealing Bitcoin or accumulating it or whatever
[01:04:18.060 --> 01:04:20.300]   for short-term gain to get around sanctions
[01:04:20.300 --> 01:04:22.500]   and use it to buy dollars or something like that, right?
[01:04:22.500 --> 01:04:24.060]   Which they can't get normally.
[01:04:24.060 --> 01:04:24.880]   Well, guess what?
[01:04:24.880 --> 01:04:26.500]   All those people who the regime has instructed
[01:04:26.500 --> 01:04:28.340]   to like figure this thing out and use it,
[01:04:28.340 --> 01:04:30.100]   they're all gonna realize, oh my God, this is money
[01:04:30.100 --> 01:04:31.340]   the government doesn't control.
[01:04:31.340 --> 01:04:33.260]   And it's gonna spread like a virus, okay?
[01:04:33.260 --> 01:04:35.900]   So this is like the idea of the Trojan horse allegory.
[01:04:35.900 --> 01:04:38.340]   Why I think it's so important and powerful with Bitcoin.
[01:04:38.340 --> 01:04:41.460]   All the people talking about Bitcoin today on TV,
[01:04:41.460 --> 01:04:43.380]   they don't care about freedom or privacy.
[01:04:43.380 --> 01:04:45.060]   They just care about number go up.
[01:04:45.060 --> 01:04:47.180]   But what they don't realize is what's concealed within.
[01:04:47.180 --> 01:04:49.220]   And that's very, very powerful to me.
[01:04:49.220 --> 01:04:52.460]   - So the people talking about Bitcoin on TV
[01:04:52.460 --> 01:04:54.540]   are maybe investor types.
[01:04:54.540 --> 01:04:57.200]   - Professional investors, corporations,
[01:04:57.200 --> 01:04:58.280]   and soon governments.
[01:04:58.280 --> 01:05:01.080]   I mean, you just had today, this morning on CNBC,
[01:05:01.080 --> 01:05:04.740]   the leader of the Republican leader
[01:05:04.740 --> 01:05:06.820]   of the House of Representatives, a Congressman,
[01:05:06.820 --> 01:05:09.460]   saying like, we need to be pro-Bitcoin as a country.
[01:05:09.460 --> 01:05:11.700]   And the other day, Peter Thiel had a very interesting
[01:05:11.700 --> 01:05:13.260]   comment where he was basically like,
[01:05:13.260 --> 01:05:15.940]   let's not fall behind China in this race.
[01:05:15.940 --> 01:05:19.940]   So you have influential people in our government,
[01:05:19.940 --> 01:05:22.820]   like sort of posturing for this like, you know,
[01:05:22.820 --> 01:05:25.120]   Bitcoin race that's gonna happen in the next 10 years.
[01:05:25.120 --> 01:05:26.300]   You're gonna see this.
[01:05:26.300 --> 01:05:29.060]   Countries are gonna compete to stack Bitcoin.
[01:05:29.060 --> 01:05:29.900]   Absolutely.
[01:05:29.900 --> 01:05:33.380]   - So you believe the thing that's shiny and sexy
[01:05:33.380 --> 01:05:36.420]   like the Trojan horse is the number go up.
[01:05:36.420 --> 01:05:38.180]   - It's too hard to ignore.
[01:05:38.180 --> 01:05:42.380]   - And to define that a little further,
[01:05:42.380 --> 01:05:45.660]   meaning it does seem like the more people get excited
[01:05:45.660 --> 01:05:48.260]   and start using Bitcoin, the more its value grows.
[01:05:48.260 --> 01:05:49.220]   So it's just a good--
[01:05:49.220 --> 01:05:50.060]   - Feedback loop.
[01:05:50.060 --> 01:05:51.220]   - Yeah, it's a feedback loop.
[01:05:51.220 --> 01:05:53.260]   And then the reason you're excited about it,
[01:05:53.260 --> 01:05:56.300]   especially is that FG.
[01:05:56.300 --> 01:05:57.500]   - Yeah, freedom go up.
[01:05:57.500 --> 01:06:01.220]   - Freedom go up, which is it ultimately gives power
[01:06:01.220 --> 01:06:04.580]   to the individuals to, so decentralize the entire system.
[01:06:04.580 --> 01:06:06.860]   - When Tesla stacks Bitcoin,
[01:06:06.860 --> 01:06:08.540]   they're just doing that as self-interest.
[01:06:08.540 --> 01:06:11.080]   They think it's gonna be a good inflation hedge, fine.
[01:06:11.080 --> 01:06:13.060]   But what they maybe don't care about,
[01:06:13.060 --> 01:06:14.720]   don't realize or they don't need to care.
[01:06:14.720 --> 01:06:17.960]   I mean, Bitcoin's power is it like co-ops people
[01:06:17.960 --> 01:06:19.420]   into promoting a freedom tool,
[01:06:19.420 --> 01:06:20.520]   even if they don't care about,
[01:06:20.520 --> 01:06:22.740]   or even if they hate freedom, it doesn't matter.
[01:06:22.740 --> 01:06:25.580]   So when Tesla stacks Bitcoin and the price goes up
[01:06:25.580 --> 01:06:26.860]   and more interest goes up
[01:06:26.860 --> 01:06:29.460]   and more people around the world are like, wow, Bitcoin,
[01:06:29.460 --> 01:06:31.060]   then more people get involved.
[01:06:31.060 --> 01:06:33.780]   Again, more adoption, more price, more developers,
[01:06:33.780 --> 01:06:36.420]   better user interface, more privacy tools,
[01:06:36.420 --> 01:06:38.060]   more mining, more network security.
[01:06:38.060 --> 01:06:39.780]   It's just this like positive feedback loop
[01:06:39.780 --> 01:06:40.960]   that continues to grow.
[01:06:40.960 --> 01:06:43.580]   And it will grow intensely in the next decade
[01:06:43.580 --> 01:06:45.140]   as we go through the adoption cycle.
[01:06:45.140 --> 01:06:47.140]   And the reason why I'm so excited about this
[01:06:47.140 --> 01:06:48.140]   is the human rights world,
[01:06:48.140 --> 01:06:50.580]   again, to get back to our previous conversation,
[01:06:50.580 --> 01:06:54.540]   is very hard to find people who have the empathy
[01:06:54.540 --> 01:06:57.100]   or the altruism to actually make a difference abroad
[01:06:57.100 --> 01:06:59.940]   in places like China or Saudi Arabia or North Korea.
[01:06:59.940 --> 01:07:01.900]   People are very quick to just like,
[01:07:01.900 --> 01:07:04.620]   they'll just quickly toss off the pretty words
[01:07:04.620 --> 01:07:05.980]   that they care about human rights
[01:07:05.980 --> 01:07:07.700]   as soon as profits come into play.
[01:07:07.700 --> 01:07:09.900]   So there's no alignment of incentives, right?
[01:07:09.900 --> 01:07:11.340]   The reason why Bitcoin is so powerful
[01:07:11.340 --> 01:07:13.060]   is that it aligns the incentives.
[01:07:13.060 --> 01:07:15.900]   All of a sudden, they can be as greedy as they want.
[01:07:15.900 --> 01:07:18.380]   They are being forced to promote a freedom tool.
[01:07:18.380 --> 01:07:19.500]   This I've never seen before.
[01:07:19.500 --> 01:07:21.660]   And it makes me, it gives me a lot of like excitement.
[01:07:21.660 --> 01:07:22.900]   It's very refreshing
[01:07:22.900 --> 01:07:25.420]   because we've been laboring in the human rights space
[01:07:25.420 --> 01:07:26.720]   and you have to like raise money
[01:07:26.720 --> 01:07:28.260]   and it's all like nonprofit work
[01:07:28.260 --> 01:07:29.460]   and you're like begging for people
[01:07:29.460 --> 01:07:30.940]   to make a difference for you.
[01:07:30.940 --> 01:07:33.440]   Here you have this like incredible asset
[01:07:33.440 --> 01:07:35.860]   which people will accumulate out of self-preservation,
[01:07:35.860 --> 01:07:37.180]   self-interest and greed,
[01:07:37.180 --> 01:07:40.380]   and yet it will strengthen the power of the individual.
[01:07:40.380 --> 01:07:42.460]   That is what we need to fight, big brother.
[01:07:42.460 --> 01:07:43.720]   That's what we need to fight,
[01:07:43.720 --> 01:07:45.820]   like what I'm scared is happening in China.
[01:07:45.820 --> 01:07:48.000]   Like this growing authoritarian state,
[01:07:48.000 --> 01:07:50.300]   which is powered by big data analysis.
[01:07:50.300 --> 01:07:52.000]   This is our way to fight back.
[01:07:52.000 --> 01:07:56.100]   And it runs on this like really interesting engine,
[01:07:56.100 --> 01:07:57.620]   again, that like takes advantage
[01:07:57.620 --> 01:07:59.340]   of our base nature as humans.
[01:07:59.340 --> 01:08:01.620]   And I know that it sounds terrible for me to say this,
[01:08:01.620 --> 01:08:05.420]   but I mean, ultimately we are self-interested
[01:08:05.420 --> 01:08:08.380]   and it is hard to get people to care about others
[01:08:08.380 --> 01:08:10.180]   living a thousand miles away.
[01:08:10.180 --> 01:08:14.020]   You know, we are kind of localized in our empathy.
[01:08:14.020 --> 01:08:16.800]   Speaking as someone who works to help people
[01:08:16.800 --> 01:08:19.200]   who live in like a hundred different countries,
[01:08:19.200 --> 01:08:20.980]   it's very difficult to get Americans
[01:08:20.980 --> 01:08:23.260]   to care about what's happening in Belarus or in Kashmir.
[01:08:23.260 --> 01:08:24.320]   It just is.
[01:08:24.320 --> 01:08:25.740]   But guess what?
[01:08:25.740 --> 01:08:27.340]   They're gonna definitely care about Bitcoin
[01:08:27.340 --> 01:08:29.900]   because they wanna see their net worth go up.
[01:08:29.900 --> 01:08:31.940]   They wanna do better for their family, et cetera.
[01:08:31.940 --> 01:08:33.740]   They're gonna get into this thing
[01:08:33.740 --> 01:08:36.200]   and it's really gonna like make that powerful tool
[01:08:36.200 --> 01:08:37.820]   for everyone else who's using it.
[01:08:37.820 --> 01:08:42.260]   So this interplay dynamic is fascinating to me.
[01:08:42.260 --> 01:08:44.060]   - Yeah, I have to,
[01:08:44.060 --> 01:08:47.220]   so I'm somebody who doesn't like
[01:08:47.220 --> 01:08:49.500]   the corrupting effects of greed,
[01:08:49.500 --> 01:08:53.220]   but it is also human nature.
[01:08:53.220 --> 01:08:54.060]   - Yeah, I don't like it either,
[01:08:54.060 --> 01:08:55.900]   but we have to be realists here.
[01:08:55.900 --> 01:08:57.340]   You have to acknowledge it
[01:08:57.340 --> 01:09:00.580]   and then maybe use it for your advantage.
[01:09:00.580 --> 01:09:02.100]   - And it's not just Bitcoin itself.
[01:09:02.100 --> 01:09:04.340]   Like exchanges today are adopting something
[01:09:04.340 --> 01:09:05.540]   called lightning network,
[01:09:05.540 --> 01:09:07.940]   which is a way to scale Bitcoin on a second layer.
[01:09:07.940 --> 01:09:09.140]   Much like we had gold bars,
[01:09:09.140 --> 01:09:10.620]   which we scaled with paper money.
[01:09:10.620 --> 01:09:12.260]   And then we had visa credit cards,
[01:09:12.260 --> 01:09:14.780]   which were a way of scaling the paper notes.
[01:09:14.780 --> 01:09:16.500]   Bitcoin scales through lightning network.
[01:09:16.500 --> 01:09:20.260]   It's a private instant globally final settlement network.
[01:09:20.260 --> 01:09:22.500]   It's something you all should check out.
[01:09:22.500 --> 01:09:24.420]   It's very, very interesting.
[01:09:24.420 --> 01:09:26.020]   The exchanges aren't adopting lightning
[01:09:26.020 --> 01:09:27.820]   for its privacy benefits.
[01:09:27.820 --> 01:09:29.860]   Like lightning operates off the chain,
[01:09:29.860 --> 01:09:31.660]   meaning surveillance companies can't see,
[01:09:31.660 --> 01:09:33.260]   they can't do chain analysis on lightning
[01:09:33.260 --> 01:09:35.220]   'cause it's on an onion routed second layer
[01:09:35.220 --> 01:09:38.660]   kind of that works kind of like the tour project.
[01:09:38.660 --> 01:09:40.980]   The exchanges don't care about privacy.
[01:09:40.980 --> 01:09:43.140]   They're doing it because it reduces fees.
[01:09:43.140 --> 01:09:45.060]   Lightning is cheaper and faster.
[01:09:45.060 --> 01:09:46.660]   So again, we have this really interesting
[01:09:46.660 --> 01:09:48.860]   alignment of incentives where like the freedom tech
[01:09:48.860 --> 01:09:50.740]   is being promoted by people who don't,
[01:09:50.740 --> 01:09:52.900]   I don't, it doesn't matter what their incentives are.
[01:09:52.900 --> 01:09:55.340]   I could care less if they were altruistic or not.
[01:09:55.340 --> 01:09:56.500]   And I think this is,
[01:09:56.500 --> 01:09:58.660]   and you're gonna maybe see this even in the future.
[01:09:58.660 --> 01:10:01.540]   There's more things coming in Bitcoin down the pike.
[01:10:01.540 --> 01:10:04.220]   Lightning was enabled by an upgrade called SegWit, right?
[01:10:04.220 --> 01:10:05.460]   Which took place a few years ago,
[01:10:05.460 --> 01:10:08.220]   which was the culmination of the block size conflict.
[01:10:08.220 --> 01:10:09.380]   There's another thing coming up
[01:10:09.380 --> 01:10:11.260]   called cross input signature aggregation,
[01:10:11.260 --> 01:10:15.420]   which may, if it takes effect in the next few years,
[01:10:15.420 --> 01:10:18.580]   it may compel exchanges to collaboratively spend
[01:10:18.580 --> 01:10:19.940]   all their Bitcoin together in a way
[01:10:19.980 --> 01:10:23.140]   that really protects our privacy and fights surveillance.
[01:10:23.140 --> 01:10:25.140]   But they're not gonna do it for moral reasons.
[01:10:25.140 --> 01:10:26.620]   They're gonna do it 'cause it's gonna save them money
[01:10:26.620 --> 01:10:28.220]   and improve their bottom line.
[01:10:28.220 --> 01:10:29.660]   - Can you speak to that kind of collaborative
[01:10:29.660 --> 01:10:31.780]   so that you can have multiple parties
[01:10:31.780 --> 01:10:33.140]   in a single transaction kind of thing?
[01:10:33.140 --> 01:10:35.740]   - Yeah, like you could do that today.
[01:10:35.740 --> 01:10:36.580]   Absolutely.
[01:10:36.580 --> 01:10:38.140]   It's called the coin join, for example.
[01:10:38.140 --> 01:10:40.260]   But right now it's more expensive to coin join in Bitcoin.
[01:10:40.260 --> 01:10:42.180]   You have to pay a premium for your privacy.
[01:10:42.180 --> 01:10:43.580]   This would flip that on its head
[01:10:43.580 --> 01:10:46.140]   and would basically say, if you have one transaction,
[01:10:46.140 --> 01:10:48.500]   hey, pile them all in, have as many parties as you want.
[01:10:48.500 --> 01:10:50.180]   The more parties you get in, the cheaper it's gonna be
[01:10:50.180 --> 01:10:51.700]   per party, okay?
[01:10:51.700 --> 01:10:53.580]   And that's not possible in Bitcoin today,
[01:10:53.580 --> 01:10:55.020]   but it might be in the future.
[01:10:55.020 --> 01:10:58.980]   But again, the beauty in Bitcoin are these ways
[01:10:58.980 --> 01:11:00.580]   that it just aligns human incentives
[01:11:00.580 --> 01:11:04.180]   and it aligns our most base desires and needs
[01:11:04.180 --> 01:11:07.780]   and realities with freedom and privacy.
[01:11:07.780 --> 01:11:09.500]   And that I've never seen before.
[01:11:09.500 --> 01:11:12.100]   And that's why I think it's so interesting.
[01:11:12.100 --> 01:11:15.340]   - So something that somebody like Eric Weisland
[01:11:15.380 --> 01:11:19.820]   actually spoke to this, the idea of blockchain in general.
[01:11:19.820 --> 01:11:24.780]   From like a 10,000 foot view,
[01:11:24.780 --> 01:11:26.900]   the blockchain is a centralized place
[01:11:26.900 --> 01:11:30.060]   to keep the record of everything that ever happened.
[01:11:30.060 --> 01:11:32.940]   And does that concern you?
[01:11:32.940 --> 01:11:35.540]   From a privacy perspective, from a control perspective,
[01:11:35.540 --> 01:11:38.860]   even though it's managed, especially,
[01:11:38.860 --> 01:11:42.180]   given the low frequency of transactions for Bitcoin,
[01:11:42.180 --> 01:11:47.180]   you can have a lot of small computers across the globe
[01:11:47.180 --> 01:11:50.700]   contain the entirety set of transactions,
[01:11:50.700 --> 01:11:52.260]   all of those kinds of features.
[01:11:52.260 --> 01:11:54.540]   Does that concern you that there's one place
[01:11:54.540 --> 01:11:57.420]   where everything is made public
[01:11:57.420 --> 01:12:00.060]   in terms of everything that ever happened?
[01:12:00.060 --> 01:12:02.180]   - No, and I'll give you two reasons.
[01:12:02.180 --> 01:12:04.940]   Number one, the Bitcoin blockchain
[01:12:04.940 --> 01:12:07.100]   is ultimately a settlement layer.
[01:12:07.100 --> 01:12:10.380]   It's kind of like something like Fedwire in the United States.
[01:12:10.380 --> 01:12:13.780]   It's a way for like institutions to settle with each other.
[01:12:13.780 --> 01:12:15.220]   That's what I think it's gonna be like
[01:12:15.220 --> 01:12:17.140]   in 20, 30 years from now.
[01:12:17.140 --> 01:12:18.820]   The average person's never gonna touch
[01:12:18.820 --> 01:12:20.700]   the Bitcoin blockchain probably.
[01:12:20.700 --> 01:12:22.380]   They're gonna use things like Lightning,
[01:12:22.380 --> 01:12:24.860]   or unfortunately, they may use Bitcoin banks,
[01:12:24.860 --> 01:12:26.260]   but they'll either use custodians
[01:12:26.260 --> 01:12:28.100]   or they'll use second layer,
[01:12:28.100 --> 01:12:30.300]   non-custodial solutions to interact.
[01:12:30.300 --> 01:12:32.140]   The main chain's gonna get very expensive.
[01:12:32.140 --> 01:12:34.860]   It's gonna be hundreds and hundreds and hundreds of dollars
[01:12:34.860 --> 01:12:37.740]   or even more if the dollar starts to weaken
[01:12:37.740 --> 01:12:39.700]   to make a transaction on the main chain.
[01:12:39.700 --> 01:12:43.140]   And that will be reserved for like very large transactions
[01:12:43.140 --> 01:12:45.500]   or transactions that need final, final settlement,
[01:12:45.500 --> 01:12:46.580]   et cetera, et cetera.
[01:12:46.580 --> 01:12:52.980]   And I think that that's fine and that's okay.
[01:12:52.980 --> 01:12:56.460]   And it's very important that that ledger,
[01:12:56.460 --> 01:12:58.300]   that settlement layer,
[01:12:58.300 --> 01:13:01.220]   be kept by thousands of people around the world.
[01:13:01.220 --> 01:13:03.100]   The Bitcoin blockchain is not centralized.
[01:13:03.100 --> 01:13:04.740]   It is decentralized.
[01:13:04.740 --> 01:13:06.820]   It is run by people like me who run a node at home.
[01:13:06.820 --> 01:13:08.140]   I run a personal server.
[01:13:08.140 --> 01:13:10.580]   I run the Bitcoin blockchain, no one else.
[01:13:10.580 --> 01:13:11.460]   You run it.
[01:13:11.460 --> 01:13:12.300]   That person runs it.
[01:13:12.300 --> 01:13:13.420]   There's no one in charge.
[01:13:13.420 --> 01:13:14.660]   - Wait, you have a full node?
[01:13:14.660 --> 01:13:16.340]   - Yeah, I run a full node.
[01:13:16.340 --> 01:13:17.180]   It's great.
[01:13:17.180 --> 01:13:18.020]   I mean, it's pretty easy, man.
[01:13:18.020 --> 01:13:20.140]   You run it and that way you can be sovereign
[01:13:20.140 --> 01:13:21.900]   over all of your usage, right?
[01:13:21.900 --> 01:13:23.700]   And you can run it on a Raspberry Pi
[01:13:23.700 --> 01:13:25.940]   with less than 150 bucks of equipment.
[01:13:25.940 --> 01:13:27.580]   And that's so important because again,
[01:13:27.580 --> 01:13:30.420]   there is no Amazon web service vulnerability here.
[01:13:30.420 --> 01:13:32.020]   That is a problem and I agree with you.
[01:13:32.020 --> 01:13:33.340]   We're trending in a bad direction.
[01:13:33.340 --> 01:13:35.900]   We're like, the government could just turn off
[01:13:35.900 --> 01:13:37.780]   a big important website or a news source.
[01:13:37.780 --> 01:13:38.900]   Well, they can't turn off Bitcoin
[01:13:38.900 --> 01:13:40.260]   because it doesn't live on AWS.
[01:13:40.260 --> 01:13:41.180]   It lives with us.
[01:13:41.180 --> 01:13:42.020]   We are Bitcoin.
[01:13:42.020 --> 01:13:45.180]   And I think that that's very, very powerful.
[01:13:45.180 --> 01:13:48.580]   - And then you can have something like a lightning network
[01:13:48.580 --> 01:13:51.220]   where you can escape some of the constraints
[01:13:51.220 --> 01:13:53.780]   of the blockchain depending on your needs
[01:13:53.780 --> 01:13:56.020]   of the privacy and all those kinds of things.
[01:13:56.020 --> 01:13:57.380]   - Everything's an engineering trade-off,
[01:13:57.380 --> 01:13:59.300]   but yeah, you can trade off some of the assurances
[01:13:59.300 --> 01:14:02.340]   of the base layer to go into lightning, for example.
[01:14:02.340 --> 01:14:04.540]   And there you can get more speed and more privacy.
[01:14:04.540 --> 01:14:06.940]   And the things that Bitcoin lacks,
[01:14:06.940 --> 01:14:09.100]   speed and privacy, for example,
[01:14:09.100 --> 01:14:10.620]   you can get on these second layers.
[01:14:10.620 --> 01:14:12.580]   So there's all kinds of cool engineering things
[01:14:12.580 --> 01:14:14.500]   that people are coming up with.
[01:14:14.500 --> 01:14:16.140]   But I also would just say,
[01:14:16.140 --> 01:14:17.900]   anyone who says the blockchain,
[01:14:17.900 --> 01:14:19.740]   like that's a red flag for that person
[01:14:19.740 --> 01:14:21.180]   doesn't really know what they're talking about.
[01:14:21.180 --> 01:14:25.140]   Like Satoshi didn't use the blockchain in the white paper.
[01:14:25.140 --> 01:14:26.980]   Blockchain was a marketing term
[01:14:26.980 --> 01:14:30.260]   that people came up with later to try and do this thing
[01:14:30.260 --> 01:14:33.020]   that was kind of like, it peaked in 2015
[01:14:33.020 --> 01:14:35.260]   and it continues to be an issue today
[01:14:35.260 --> 01:14:37.620]   of it's blockchain, not Bitcoin.
[01:14:37.620 --> 01:14:40.140]   And that was like a very corporate
[01:14:40.140 --> 01:14:42.300]   kind of social attack on Bitcoin
[01:14:42.300 --> 01:14:44.300]   to say we could take this like ledger part
[01:14:44.300 --> 01:14:46.340]   of this radical thing that's for criminals
[01:14:46.340 --> 01:14:47.420]   and all these bad people,
[01:14:47.420 --> 01:14:49.020]   but we could take one part of it out
[01:14:49.020 --> 01:14:50.300]   and we can bring it over here
[01:14:50.300 --> 01:14:52.940]   and we can make it safe for everybody.
[01:14:52.940 --> 01:14:54.860]   The real McCoy's Bitcoin,
[01:14:54.860 --> 01:14:57.060]   I mean, Satoshi referred to it as the time chain.
[01:14:57.060 --> 01:14:58.460]   I mean, really what they're talking about
[01:14:58.460 --> 01:14:59.460]   is just these like blocks
[01:14:59.460 --> 01:15:02.100]   that are connected chronologically of transactions.
[01:15:02.100 --> 01:15:03.580]   It's really not that exciting.
[01:15:03.580 --> 01:15:06.820]   The exciting part of Bitcoin is the proof of work,
[01:15:06.820 --> 01:15:09.020]   where the transaction processing is done
[01:15:09.020 --> 01:15:11.900]   by mining and by energy and by real world expenditures
[01:15:11.900 --> 01:15:15.500]   instead of like some central ledger.
[01:15:15.500 --> 01:15:18.420]   And when you remove the blockchain from Bitcoin,
[01:15:18.420 --> 01:15:22.660]   it's not very, to me, it's just not that interesting.
[01:15:22.660 --> 01:15:25.500]   - I don't know, to me, blockchain, time chain, whatever,
[01:15:25.500 --> 01:15:28.020]   as it philosophically is a pretty beautiful idea.
[01:15:28.020 --> 01:15:29.660]   I mean, it's pretty simple,
[01:15:29.660 --> 01:15:31.500]   but nevertheless it's beautiful.
[01:15:31.500 --> 01:15:33.780]   I'm a big database person.
[01:15:33.780 --> 01:15:36.100]   It's an interesting way to store information
[01:15:36.100 --> 01:15:39.220]   that especially that's totally publicly accessible.
[01:15:39.220 --> 01:15:43.480]   I know that to Bitcoin, proof of work
[01:15:43.480 --> 01:15:45.460]   is the fundamental idea,
[01:15:45.460 --> 01:15:48.620]   but to cryptocurrency and digital money in general
[01:15:48.620 --> 01:15:49.460]   and to money,
[01:15:49.460 --> 01:15:51.820]   the blockchain is a really interesting idea to me.
[01:15:51.820 --> 01:15:55.260]   The way I think about it is it's kind of physics.
[01:15:55.260 --> 01:15:58.700]   And I like that there's a place that you can rely on
[01:15:58.700 --> 01:16:00.540]   that's very difficult to mess with.
[01:16:00.540 --> 01:16:03.780]   But it's not though, like it's outside of maybe Ethereum.
[01:16:03.780 --> 01:16:06.100]   Every other blockchain is easy to mess with.
[01:16:06.100 --> 01:16:07.900]   - So you're saying that proof of work
[01:16:07.900 --> 01:16:09.660]   is what makes it hard to mess with.
[01:16:09.660 --> 01:16:11.940]   - Absolutely, proof of work is the key.
[01:16:11.940 --> 01:16:14.020]   And Ethereum is about to leave proof of work.
[01:16:14.020 --> 01:16:16.900]   So it's about to go to proof of stake,
[01:16:16.900 --> 01:16:18.740]   which is literally the existing system
[01:16:18.740 --> 01:16:19.620]   where a small group of people
[01:16:19.620 --> 01:16:21.140]   get to decide the monetary policy.
[01:16:21.140 --> 01:16:23.860]   - Yeah, reputation has a lot of value there
[01:16:23.860 --> 01:16:25.860]   and that it could be manipulated.
[01:16:25.860 --> 01:16:26.700]   - I may sound brutal,
[01:16:26.700 --> 01:16:28.940]   but I'm coming at it from a political science perspective.
[01:16:28.940 --> 01:16:31.780]   For me, it's all about freedom versus dictatorship.
[01:16:31.780 --> 01:16:33.820]   And that's why I find it so compelling
[01:16:33.820 --> 01:16:36.940]   that regardless of how much power or might
[01:16:36.940 --> 01:16:38.700]   or how many armies you have,
[01:16:38.700 --> 01:16:40.820]   you can't change the rules of Bitcoin.
[01:16:40.820 --> 01:16:45.420]   - If you're wrong about Bitcoin, what would that look like?
[01:16:45.420 --> 01:16:50.420]   What kind of thing that in 10, 20 years that you're not wrong.
[01:16:50.420 --> 01:16:54.660]   - Right, it doesn't pan out.
[01:16:54.660 --> 01:16:55.940]   - It doesn't pan out,
[01:16:55.940 --> 01:16:58.300]   but other things that actually make you feel good
[01:16:58.300 --> 01:17:01.100]   about all the hard work you've done do pan out.
[01:17:01.100 --> 01:17:02.460]   Something you haven't expected.
[01:17:02.460 --> 01:17:04.380]   What might that be?
[01:17:04.380 --> 01:17:05.860]   - Well, as we've talked about,
[01:17:05.860 --> 01:17:07.660]   my career started in human rights
[01:17:07.660 --> 01:17:09.180]   and in promoting individual freedom
[01:17:09.180 --> 01:17:10.700]   and fighting authoritarianism.
[01:17:10.700 --> 01:17:12.860]   That fight will continue on
[01:17:12.860 --> 01:17:15.140]   no matter what happens with Bitcoin.
[01:17:15.140 --> 01:17:18.340]   I think it would be a massive failure and a tragedy
[01:17:18.340 --> 01:17:20.420]   if this project didn't work.
[01:17:20.420 --> 01:17:21.260]   - The Bitcoin project.
[01:17:21.260 --> 01:17:23.900]   - Yes, if the Bitcoin project didn't work,
[01:17:23.900 --> 01:17:26.860]   honestly, it's one of the only things that gives me hope
[01:17:26.860 --> 01:17:28.620]   because it is an effective way to push back
[01:17:28.620 --> 01:17:30.580]   against creeping centralized control.
[01:17:30.580 --> 01:17:34.020]   If for whatever reason, and I can't really see,
[01:17:34.020 --> 01:17:35.100]   one of the reasons I'm so into it
[01:17:35.100 --> 01:17:37.340]   is I can't really see how it's not gonna work.
[01:17:37.340 --> 01:17:41.220]   Again, I think the Trojan horse allegory is too powerful.
[01:17:41.220 --> 01:17:43.660]   These big centralized actors are gonna be too greedy
[01:17:43.660 --> 01:17:45.940]   and they're gonna want some as opposed to banning it.
[01:17:45.940 --> 01:17:47.820]   It's way easier for them to buy it than to ban it.
[01:17:47.820 --> 01:17:49.260]   I think that's just what's gonna happen.
[01:17:49.260 --> 01:17:51.700]   But if for whatever reason it failed,
[01:17:51.700 --> 01:17:52.940]   I would have very little hope left
[01:17:52.940 --> 01:17:55.180]   because really, I mean, the Chinese model
[01:17:55.300 --> 01:17:58.700]   of centralizing all of your data and controlling it,
[01:17:58.700 --> 01:18:02.500]   I mean, ultimately is a very, very powerful
[01:18:02.500 --> 01:18:03.860]   sort of like arch force.
[01:18:03.860 --> 01:18:06.580]   And I would be concerned that that would be
[01:18:06.580 --> 01:18:09.380]   all of our sort of destiny.
[01:18:09.380 --> 01:18:10.620]   - I do have to sort of push back
[01:18:10.620 --> 01:18:11.980]   at a style of communication.
[01:18:11.980 --> 01:18:13.900]   And you're not doing it today.
[01:18:13.900 --> 01:18:17.340]   You're being exceptionally eloquent in arguing these ideas.
[01:18:17.340 --> 01:18:21.420]   But me, especially just from studying history
[01:18:21.420 --> 01:18:23.980]   and being very skeptical from growing up
[01:18:23.980 --> 01:18:28.980]   in the Soviet Union, I'm very skeptical and cautious
[01:18:28.980 --> 01:18:34.700]   when I see a community of people being very sure of an idea.
[01:18:34.700 --> 01:18:36.420]   Doesn't matter what that idea is.
[01:18:36.420 --> 01:18:40.060]   And there's a huge amount of certainty around Bitcoin.
[01:18:40.060 --> 01:18:41.540]   Part of it is an important feature
[01:18:41.540 --> 01:18:43.500]   because it's number go up.
[01:18:43.500 --> 01:18:46.420]   - So far.
[01:18:46.420 --> 01:18:50.620]   - Number go up is a really important part of the mechanism
[01:18:50.620 --> 01:18:55.620]   to make sure that it grows in impact, network effects,
[01:18:55.620 --> 01:18:57.860]   because I mean, it's really important to get excited
[01:18:57.860 --> 01:18:59.140]   about idea for a take hold.
[01:18:59.140 --> 01:19:01.380]   That's the way human nature works and so on.
[01:19:01.380 --> 01:19:06.380]   But I also get even something that you mentioned
[01:19:06.380 --> 01:19:12.020]   that others may not, if you mentioned blockchain,
[01:19:12.020 --> 01:19:16.900]   you're sensitive to the attacks that have been mounted
[01:19:16.900 --> 01:19:18.460]   where the word blockchain has been used.
[01:19:18.460 --> 01:19:19.420]   - People have been fooled.
[01:19:19.420 --> 01:19:22.180]   I mean, like people in the humanitarian sector
[01:19:22.180 --> 01:19:23.220]   have been fooled into thinking
[01:19:23.220 --> 01:19:24.900]   that some centralized blockchain project
[01:19:24.900 --> 01:19:27.460]   is gonna help some refugee, all collapsed.
[01:19:27.460 --> 01:19:29.260]   - There's a, yeah, there's a huge,
[01:19:29.260 --> 01:19:31.660]   it makes me sad that there's a huge number of scams.
[01:19:31.660 --> 01:19:33.300]   Like, you know what makes me really sad?
[01:19:33.300 --> 01:19:35.540]   And just a tiny little tangent.
[01:19:35.540 --> 01:19:38.300]   There's been recently, I guess with the growing platform
[01:19:38.300 --> 01:19:40.060]   or something, there's been a bunch of fake
[01:19:40.060 --> 01:19:41.980]   Lex Friedman accounts.
[01:19:41.980 --> 01:19:44.220]   - Yeah, must have a million.
[01:19:44.220 --> 01:19:47.380]   - But not only do they do stupid stuff,
[01:19:47.380 --> 01:19:49.460]   but they've been messaging people.
[01:19:49.460 --> 01:19:50.620]   - Oh, to get the Bitcoin and stuff like that.
[01:19:50.620 --> 01:19:51.460]   - On LinkedIn.
[01:19:51.460 --> 01:19:52.280]   - Totally.
[01:19:52.280 --> 01:19:54.980]   - And people write to me and they're saying like--
[01:19:54.980 --> 01:19:56.340]   - Tough man.
[01:19:56.340 --> 01:19:57.880]   - I think it gets people.
[01:19:57.880 --> 01:19:59.260]   I think they click on stuff.
[01:19:59.260 --> 01:20:00.980]   I think they were not sure.
[01:20:00.980 --> 01:20:05.980]   And it makes me think like people are gullible
[01:20:05.980 --> 01:20:11.060]   or not gullible, but like they're just like I am,
[01:20:11.060 --> 01:20:12.820]   which is they're like hopeful about the world.
[01:20:12.820 --> 01:20:14.140]   They're optimistic about the world.
[01:20:14.140 --> 01:20:15.980]   They're almost like naive about the evil that's out there.
[01:20:15.980 --> 01:20:17.700]   - This is what goes wrong with Bitcoin.
[01:20:17.700 --> 01:20:18.540]   And I've seen it.
[01:20:18.540 --> 01:20:21.500]   People fall for these, I mean,
[01:20:21.500 --> 01:20:22.580]   like in these different countries,
[01:20:22.580 --> 01:20:25.020]   I'm trying to like talk to different people about Bitcoin.
[01:20:25.020 --> 01:20:27.340]   And like the amount of like MLM schemes,
[01:20:27.340 --> 01:20:29.940]   pyramid schemes, Ponzi schemes,
[01:20:29.940 --> 01:20:31.220]   there are just so many of them.
[01:20:31.220 --> 01:20:32.340]   And there's plenty here too.
[01:20:32.340 --> 01:20:34.940]   But like in Zimbabwe, I was talking to this guy
[01:20:34.940 --> 01:20:37.340]   who is a reporter who studies the FX,
[01:20:37.340 --> 01:20:39.780]   like the foreign currency exchange markets.
[01:20:39.780 --> 01:20:41.260]   He's just saying one of the main reasons
[01:20:41.260 --> 01:20:42.820]   people don't wanna get into Bitcoin
[01:20:42.820 --> 01:20:44.300]   is because they've been scammed so hard
[01:20:44.300 --> 01:20:45.660]   by all these other things.
[01:20:45.660 --> 01:20:47.860]   So I would say that that's one way it could go wrong
[01:20:47.860 --> 01:20:51.860]   is that like people just continue to be like afraid of it
[01:20:51.860 --> 01:20:54.460]   because of things that are like that in the past.
[01:20:54.460 --> 01:20:56.500]   - Well, it's not just the volatility,
[01:20:56.500 --> 01:20:59.580]   it's just the, you know, yeah, having--
[01:20:59.580 --> 01:21:00.820]   - Yeah, if you think it's a pyramid scheme,
[01:21:00.820 --> 01:21:02.660]   you're not gonna wanna get involved.
[01:21:02.660 --> 01:21:05.460]   - And in some sense, if I were to speak
[01:21:05.460 --> 01:21:08.420]   to the Bitcoin maximalist community
[01:21:08.420 --> 01:21:10.420]   is to maybe ease up on the certainty
[01:21:10.420 --> 01:21:13.100]   because that gives me the signal that it's a scam,
[01:21:13.100 --> 01:21:13.980]   to be honest.
[01:21:13.980 --> 01:21:17.580]   So whenever somebody, whenever there's a lot of people
[01:21:17.580 --> 01:21:22.580]   being cultishly excited about something,
[01:21:22.580 --> 01:21:24.620]   I start being very skeptical.
[01:21:24.620 --> 01:21:26.940]   It's like, you know, I used to like Green Day
[01:21:26.940 --> 01:21:29.140]   before they became really popular.
[01:21:29.140 --> 01:21:31.140]   And then the moment they became really popular,
[01:21:31.140 --> 01:21:33.180]   I'm like, I don't know, he started wearing mascara.
[01:21:33.180 --> 01:21:35.100]   And it's like, I don't know, I don't like him anymore.
[01:21:35.100 --> 01:21:40.100]   So like, I'm very skeptical about evangelists of an idea
[01:21:40.100 --> 01:21:42.020]   because I think Bitcoin on its own
[01:21:42.020 --> 01:21:44.100]   is just a powerful idea that stands.
[01:21:44.100 --> 01:21:46.340]   But I also understand that in a world
[01:21:46.340 --> 01:21:50.580]   of a lot of competing ideas where there's a lot of scams
[01:21:50.580 --> 01:21:53.140]   and a lot of money to be made through those scams,
[01:21:53.140 --> 01:21:56.900]   that you have to be innovative in the kind of mechanisms
[01:21:56.900 --> 01:22:00.500]   you use to break through the scam, the ocean of scams.
[01:22:00.500 --> 01:22:05.260]   - I took this personality test and I'm a 99 skepticism.
[01:22:05.260 --> 01:22:08.100]   So I was first, sadly, 'cause I was first introduced
[01:22:08.100 --> 01:22:10.300]   to Bitcoin in 2013.
[01:22:10.300 --> 01:22:12.060]   And I was like, eh, whatever.
[01:22:12.060 --> 01:22:15.300]   And it took me four years to actually get into it,
[01:22:15.300 --> 01:22:16.280]   to go down the rat pole.
[01:22:16.280 --> 01:22:17.980]   I didn't really start to grasp it
[01:22:17.980 --> 01:22:20.780]   and start getting excited about it until 2017.
[01:22:20.780 --> 01:22:24.940]   So I was regrettably very, very skeptical for a long time.
[01:22:24.940 --> 01:22:26.620]   And I just thought it was like, whatever.
[01:22:26.620 --> 01:22:30.300]   So I appreciate that and you should be skeptical.
[01:22:30.300 --> 01:22:32.980]   But ultimately you gotta believe in things like,
[01:22:32.980 --> 01:22:35.100]   I believe in democracy, I believe it's good for people.
[01:22:35.100 --> 01:22:36.700]   I believe it's better than tyranny.
[01:22:36.700 --> 01:22:37.580]   I believe in the internet.
[01:22:37.580 --> 01:22:39.960]   I know that we've had issues with centralization
[01:22:39.960 --> 01:22:41.820]   of the internet, but I still believe it's better
[01:22:41.820 --> 01:22:44.500]   to be connected than to have bridges between us.
[01:22:44.500 --> 01:22:45.580]   And I believe in Bitcoin.
[01:22:45.580 --> 01:22:49.500]   And to me, it's like a very similar progressive force
[01:22:49.500 --> 01:22:50.740]   that we're encountering.
[01:22:50.740 --> 01:22:54.100]   But yeah, be skeptical.
[01:22:54.100 --> 01:22:57.980]   Nothing will befall you that's bad
[01:22:57.980 --> 01:22:59.740]   if you're cautious and skeptical.
[01:22:59.740 --> 01:23:02.920]   That's a good mentality to have.
[01:23:02.920 --> 01:23:05.340]   - One thing we haven't talked about,
[01:23:05.340 --> 01:23:08.000]   all the violations of the human rights
[01:23:08.000 --> 01:23:11.820]   that authoritarian regimes do,
[01:23:11.820 --> 01:23:16.300]   there's not a positive, but there's,
[01:23:16.300 --> 01:23:18.740]   you mentioned that nationalism is a drug.
[01:23:18.740 --> 01:23:19.700]   - Yeah.
[01:23:19.700 --> 01:23:22.900]   - There's something beautiful about loving your country,
[01:23:22.900 --> 01:23:26.940]   having pride in your country, loving the,
[01:23:26.940 --> 01:23:30.260]   there's a feeling of belonging.
[01:23:30.260 --> 01:23:32.260]   It could be country, it could be tribe,
[01:23:32.260 --> 01:23:35.100]   it could be family, that's really powerful.
[01:23:35.100 --> 01:23:37.500]   And that speaks to human nature as well.
[01:23:37.500 --> 01:23:40.760]   And that can sometimes overpower everything else.
[01:23:40.760 --> 01:23:41.600]   - Patriotism.
[01:23:41.600 --> 01:23:42.440]   - Patriotism.
[01:23:42.440 --> 01:23:43.260]   - Yeah.
[01:23:43.260 --> 01:23:47.080]   - And sometimes it can be seen when you study history,
[01:23:47.080 --> 01:23:51.960]   when you look at Stalinist, the Soviet Union,
[01:23:51.960 --> 01:23:55.020]   or you can even look at Hitler and Nazi Germany,
[01:23:55.020 --> 01:23:58.560]   we tend to paint patriotism in a negative light.
[01:23:58.560 --> 01:24:00.680]   And then maybe when we look at the United States,
[01:24:00.680 --> 01:24:01.840]   but even here in the United States,
[01:24:01.840 --> 01:24:06.400]   people often paint patriotism in a bad light.
[01:24:06.400 --> 01:24:08.300]   - You know, every time I say I love America,
[01:24:08.300 --> 01:24:12.160]   so as an immigrant, I love this country.
[01:24:12.160 --> 01:24:15.080]   It's funny how that's taken as a political statement
[01:24:15.080 --> 01:24:21.440]   that people, I guess, on the right have been more active
[01:24:21.440 --> 01:24:22.820]   in saying that they love the country
[01:24:22.820 --> 01:24:27.020]   and people on the left have not sort of,
[01:24:27.020 --> 01:24:28.700]   it's almost become a weird slogan
[01:24:28.700 --> 01:24:31.860]   as opposed to a statement of just love.
[01:24:31.860 --> 01:24:35.020]   And I understand that patriotism can be a slippery slope
[01:24:35.020 --> 01:24:37.340]   into letting your government,
[01:24:37.340 --> 01:24:38.820]   I mean, it's exactly what you're saying,
[01:24:38.820 --> 01:24:42.340]   the value of freedom of speech is you hold your government
[01:24:42.340 --> 01:24:45.300]   to account for all the ways they mess up.
[01:24:45.300 --> 01:24:46.300]   - I mean, look, you have patriotism
[01:24:46.300 --> 01:24:47.540]   and then you have jingoism, right?
[01:24:47.540 --> 01:24:49.820]   It's very important that we stay on the patriotic side.
[01:24:49.820 --> 01:24:52.500]   Like as an American, I'm very patriotic in terms of,
[01:24:52.500 --> 01:24:55.060]   I love the values that this country was founded on
[01:24:55.060 --> 01:24:56.540]   if you read the Bill of Rights.
[01:24:56.540 --> 01:24:58.380]   And I love the fact that it was just flexible enough
[01:24:58.380 --> 01:25:00.580]   that we were able to change it to grant,
[01:25:00.580 --> 01:25:03.340]   or at least to try to grant all people the same rights.
[01:25:03.340 --> 01:25:05.260]   It was not the original plan of the founders, right?
[01:25:05.260 --> 01:25:06.500]   It had to be changed.
[01:25:06.500 --> 01:25:08.860]   But since then we've remained,
[01:25:08.860 --> 01:25:14.180]   those laws have remained and they're very good.
[01:25:14.180 --> 01:25:16.300]   And I'm very proud of that.
[01:25:16.300 --> 01:25:19.480]   What I'm not proud of is the jingoistic part of our country
[01:25:19.480 --> 01:25:21.660]   where we invade other countries and bomb other countries.
[01:25:21.660 --> 01:25:23.460]   I'm not proud of our prison system.
[01:25:23.460 --> 01:25:25.300]   I think it's a huge stain on our nation.
[01:25:25.300 --> 01:25:26.540]   I'm not proud of a lot of things.
[01:25:26.540 --> 01:25:27.940]   So I think you can be patriotic,
[01:25:27.940 --> 01:25:30.740]   but you can be critical of your country.
[01:25:30.740 --> 01:25:31.940]   And that's important.
[01:25:32.740 --> 01:25:34.300]   I feel like the jingoistic thing
[01:25:34.300 --> 01:25:36.500]   is the thing that we need to watch out for.
[01:25:36.500 --> 01:25:39.340]   That's just my own personal take.
[01:25:39.340 --> 01:25:41.380]   - Out of all the projects
[01:25:41.380 --> 01:25:43.340]   that the Human Rights Foundation works on,
[01:25:43.340 --> 01:25:45.540]   what's the most important one to you right now?
[01:25:45.540 --> 01:25:47.940]   Like what that's been occupying your mind.
[01:25:47.940 --> 01:25:49.220]   - Yeah, I just read again,
[01:25:49.220 --> 01:25:50.940]   this New Yorker piece that just came out
[01:25:50.940 --> 01:25:51.860]   that you should read.
[01:25:51.860 --> 01:25:53.300]   It's called "Ghost Walls."
[01:25:53.300 --> 01:25:57.400]   And it's the story of how the Chinese Communist Party
[01:25:57.400 --> 01:25:58.980]   is committing genocide right now,
[01:25:58.980 --> 01:26:00.540]   just like other regimes did
[01:26:00.540 --> 01:26:02.580]   and the Turks did to the Armenians
[01:26:02.580 --> 01:26:04.420]   and the Nazis did to the Jews.
[01:26:04.420 --> 01:26:06.060]   And it's happening again right now.
[01:26:06.060 --> 01:26:08.900]   We said never again, and that's just not true.
[01:26:08.900 --> 01:26:09.820]   We're letting it happen.
[01:26:09.820 --> 01:26:12.020]   And again, with the business stuff,
[01:26:12.020 --> 01:26:14.500]   like people are, like Airbnb is like a sponsor
[01:26:14.500 --> 01:26:16.060]   of the Olympics, like what?
[01:26:16.060 --> 01:26:18.620]   - At the individual level, at a business level,
[01:26:18.620 --> 01:26:21.900]   how does somebody like me, who's just one little ant,
[01:26:21.900 --> 01:26:24.460]   how does somebody like Elon Musk,
[01:26:24.460 --> 01:26:28.860]   who's in charge of 10,000 ants fight it?
[01:26:28.860 --> 01:26:30.060]   Like how do we--
[01:26:30.060 --> 01:26:30.900]   - Yeah.
[01:26:30.900 --> 01:26:31.940]   - How do we push back?
[01:26:31.940 --> 01:26:34.240]   - A great blueprint is the fight
[01:26:34.240 --> 01:26:36.020]   against the South African apartheid.
[01:26:36.020 --> 01:26:39.180]   So we did a few events down in Johannesburg
[01:26:39.180 --> 01:26:41.540]   and I've had the pleasure of being able
[01:26:41.540 --> 01:26:43.660]   to go to the Apartheid Museum several times.
[01:26:43.660 --> 01:26:45.300]   And it really does a good job of chronicling
[01:26:45.300 --> 01:26:46.140]   how they were able to do it.
[01:26:46.140 --> 01:26:47.940]   It took a while, there's no doubt,
[01:26:47.940 --> 01:26:50.380]   but the way it was done was good.
[01:26:50.380 --> 01:26:54.100]   Peaceful action from abroad was very important.
[01:26:54.100 --> 01:26:55.660]   So there was like the Sullivan Principles.
[01:26:55.660 --> 01:26:59.820]   So like you can peacefully protest as a company
[01:26:59.820 --> 01:27:03.860]   particular regimes and it's very effective.
[01:27:03.860 --> 01:27:05.500]   And not just corporations,
[01:27:05.500 --> 01:27:08.140]   but like the Olympics is a great example.
[01:27:08.140 --> 01:27:09.980]   Like Chinese government should not be able
[01:27:09.980 --> 01:27:10.820]   to host the Olympics.
[01:27:10.820 --> 01:27:13.020]   The IOC should say no, not until you close down
[01:27:13.020 --> 01:27:14.220]   those prison camps.
[01:27:14.220 --> 01:27:16.580]   This is a perfect, peaceful way to push back.
[01:27:16.580 --> 01:27:17.700]   No one gets hurt.
[01:27:17.700 --> 01:27:20.460]   Same thing when we had the Korean Olympics a few years ago.
[01:27:20.460 --> 01:27:21.700]   North Korea should not have been allowed
[01:27:21.700 --> 01:27:24.700]   any sort of symbolistic kind of hosting rights there.
[01:27:24.700 --> 01:27:26.900]   They have prison camps, gulags that we can see
[01:27:26.900 --> 01:27:28.820]   from outer space very clearly.
[01:27:28.820 --> 01:27:32.380]   And their regime is the cruelest one on the planet probably.
[01:27:32.380 --> 01:27:34.100]   Why were they able to sit and cheer
[01:27:34.100 --> 01:27:37.420]   and get to sort of co-host the Olympics?
[01:27:37.420 --> 01:27:38.420]   This is spineless.
[01:27:38.420 --> 01:27:41.780]   Like the IOC, the Olympics and major corporations
[01:27:41.780 --> 01:27:44.780]   should stand up, especially in the cultural sector
[01:27:44.780 --> 01:27:46.180]   where you don't lose anything.
[01:27:46.180 --> 01:27:49.220]   Like, you know, or you shouldn't have to lose anything.
[01:27:49.220 --> 01:27:50.380]   So I think if we look at the way
[01:27:50.380 --> 01:27:54.540]   that we forced the Apartheid regime out,
[01:27:54.540 --> 01:27:56.740]   this international solidarity of musicians,
[01:27:56.740 --> 01:27:59.820]   athletes, performers, celebrities is very, very powerful.
[01:27:59.820 --> 01:28:02.660]   Unfortunately, today's celebrities are doing the opposite.
[01:28:02.660 --> 01:28:04.980]   We just, you know, had this press release go out yesterday
[01:28:04.980 --> 01:28:08.540]   about Akon, and he's off whitewashing the crimes
[01:28:08.540 --> 01:28:10.540]   of the dictator of Uganda
[01:28:10.540 --> 01:28:13.460]   and trying to build a future city there with him.
[01:28:13.460 --> 01:28:15.500]   You know, if this was the 1980s,
[01:28:15.500 --> 01:28:18.020]   Akon would be raising his fist and saying,
[01:28:18.020 --> 01:28:20.180]   "We need to, you know, fight the Apartheid regime."
[01:28:20.180 --> 01:28:21.640]   How do we get back to that?
[01:28:21.640 --> 01:28:22.920]   You know, we need to think about that.
[01:28:22.920 --> 01:28:25.460]   We have to figure out how to harness celebrities,
[01:28:25.460 --> 01:28:27.340]   influencers, and companies,
[01:28:27.340 --> 01:28:30.060]   and get them to actually stand up for something for once.
[01:28:30.060 --> 01:28:31.480]   I mean, that's something we've lost.
[01:28:31.480 --> 01:28:33.860]   We really had a spine against that,
[01:28:33.860 --> 01:28:37.260]   and, you know, we've lost it, you know?
[01:28:37.260 --> 01:28:39.300]   And you lose things, you lose them forever.
[01:28:39.300 --> 01:28:40.340]   Look at Tibet.
[01:28:40.340 --> 01:28:42.580]   Tibet was a big cause for people in the '90s.
[01:28:42.580 --> 01:28:43.660]   Used to go to colleges,
[01:28:43.660 --> 01:28:45.140]   and kids would have the Tibetan flags
[01:28:45.140 --> 01:28:46.060]   all over their dorm rooms.
[01:28:46.060 --> 01:28:49.580]   It was like Radiohead would have Tibet on the stage,
[01:28:49.580 --> 01:28:52.620]   and everybody wanted, you know, free Tibet was a big thing.
[01:28:52.620 --> 01:28:53.460]   Guess what?
[01:28:53.460 --> 01:28:55.240]   Like, we've lost it for some reason.
[01:28:55.240 --> 01:28:56.240]   It's not a thing anymore,
[01:28:56.240 --> 01:28:58.440]   and Tibet has been totally colonized, you know?
[01:28:58.440 --> 01:29:02.120]   So I think it's important that we find a way to unlock
[01:29:02.120 --> 01:29:05.120]   an interest in the celebrity classes
[01:29:05.120 --> 01:29:08.200]   among athletes, singers, presidents.
[01:29:08.200 --> 01:29:11.320]   You know, we need to find a way to punish these people.
[01:29:11.320 --> 01:29:12.160]   - Yeah, it's surprising,
[01:29:12.160 --> 01:29:15.280]   'cause we've become more and more connected,
[01:29:15.280 --> 01:29:17.800]   so we can communicate more effectively at a large scale,
[01:29:17.800 --> 01:29:22.520]   and yet we seem to be worse and worse at real activism.
[01:29:22.520 --> 01:29:25.260]   It seems like the outrage that's overtaken
[01:29:25.260 --> 01:29:27.980]   the communication channels has been very US-focused,
[01:29:27.980 --> 01:29:31.020]   and often more about outrage
[01:29:31.020 --> 01:29:34.260]   and less about productive activism.
[01:29:34.260 --> 01:29:35.100]   - I'm very jaded.
[01:29:35.100 --> 01:29:36.540]   I mean, it's very difficult
[01:29:36.540 --> 01:29:38.980]   to do these things at scale effectively.
[01:29:38.980 --> 01:29:40.860]   I do not believe we will be successful
[01:29:40.860 --> 01:29:43.420]   in boycotting the Chinese Olympics.
[01:29:43.420 --> 01:29:44.700]   We weren't in 2008.
[01:29:44.700 --> 01:29:46.780]   I don't think, and they're much more evil now,
[01:29:46.780 --> 01:29:49.340]   and I don't think we're gonna be able to do it this time.
[01:29:49.340 --> 01:29:51.740]   And again, to go back to the Bitcoin piece,
[01:29:51.740 --> 01:29:54.140]   that's why I'm very interested in this thing,
[01:29:54.140 --> 01:29:55.940]   because it doesn't require my altruism.
[01:29:55.940 --> 01:29:57.340]   It doesn't require some famous singer
[01:29:57.340 --> 01:30:00.460]   or some corporation to sacrifice anything.
[01:30:00.460 --> 01:30:03.420]   They're literally just gonna follow their own profit-seeking
[01:30:03.420 --> 01:30:06.020]   self-interested motives, and they're gonna end up
[01:30:06.020 --> 01:30:08.620]   making a stronger human rights tool for other people.
[01:30:08.620 --> 01:30:09.820]   - Freedom go up.
[01:30:09.820 --> 01:30:10.860]   - FGU, man.
[01:30:10.860 --> 01:30:11.700]   (Lex laughs)
[01:30:11.700 --> 01:30:15.220]   - Do you think we're, it's kind of a dark question,
[01:30:15.220 --> 01:30:17.860]   but you think we're headed towards a war with China,
[01:30:17.860 --> 01:30:19.560]   the United States versus China?
[01:30:20.580 --> 01:30:22.060]   - I hope not.
[01:30:22.060 --> 01:30:22.900]   I hope not.
[01:30:22.900 --> 01:30:25.540]   - In the cyber space and potentially even a hot war?
[01:30:25.540 --> 01:30:27.780]   - I think there's too many people with too much money
[01:30:27.780 --> 01:30:31.300]   to be lost to go to a hot war on both sides.
[01:30:31.300 --> 01:30:32.980]   But eventually, we're just gonna,
[01:30:32.980 --> 01:30:34.100]   someone's gonna have to stand up.
[01:30:34.100 --> 01:30:35.760]   I mean, the subjugation of Hong Kong
[01:30:35.760 --> 01:30:37.340]   and the genocide of the Uyghurs
[01:30:37.340 --> 01:30:39.020]   and the colonization of Tibet.
[01:30:39.020 --> 01:30:40.780]   I mean, Taiwan is the next big thing.
[01:30:40.780 --> 01:30:42.620]   I mean, Xi Jinping has made it very clear.
[01:30:42.620 --> 01:30:46.060]   You know, Xinjiang, Tibet, Hong Kong, Taiwan.
[01:30:46.060 --> 01:30:48.660]   So we're gonna have to stand up for Taiwan
[01:30:48.660 --> 01:30:50.900]   for different reasons, both for moral reasons,
[01:30:50.900 --> 01:30:52.460]   but also for semiconductor reasons.
[01:30:52.460 --> 01:30:54.540]   We need TSMC to be on our side.
[01:30:54.540 --> 01:30:56.900]   We cannot have China take over TSMC.
[01:30:56.900 --> 01:30:59.260]   So there's different reasons why we're gonna have
[01:30:59.260 --> 01:31:01.180]   to protect Taiwan.
[01:31:01.180 --> 01:31:04.780]   And you just hope it's not a hot war, I mean, at this point.
[01:31:04.780 --> 01:31:07.460]   - Well, but also from inside the governments of China
[01:31:07.460 --> 01:31:09.100]   and Russia as well, but China, I guess,
[01:31:09.100 --> 01:31:11.620]   is the powerhouse here.
[01:31:11.620 --> 01:31:13.340]   How do these governments get reformed?
[01:31:13.340 --> 01:31:15.740]   Is there a hope for them to become democracies,
[01:31:15.740 --> 01:31:19.100]   like true democracies, representative democracies,
[01:31:19.100 --> 01:31:24.100]   and sort of reform them to be ethical players
[01:31:24.100 --> 01:31:26.900]   on the world stage?
[01:31:26.900 --> 01:31:28.680]   - No empire lasts forever.
[01:31:28.680 --> 01:31:31.180]   And it's impossible to predict when these regimes fall.
[01:31:31.180 --> 01:31:33.460]   I mean, no one thought the Soviet Union
[01:31:33.460 --> 01:31:34.580]   was gonna fall when it fell.
[01:31:34.580 --> 01:31:39.100]   Like if you studied the news and the scholarship of the era,
[01:31:39.100 --> 01:31:42.140]   no one knew that the Tunisian government was gonna fall
[01:31:42.140 --> 01:31:44.300]   after Mohamed Bouazizi lit himself on fire.
[01:31:44.300 --> 01:31:47.020]   No one predicted that that would become
[01:31:47.020 --> 01:31:49.580]   what we now know as the Arab Spring, right?
[01:31:49.580 --> 01:31:52.020]   These things are impossible to predict.
[01:31:52.020 --> 01:31:54.060]   And one day, the Chinese regime will fall.
[01:31:54.060 --> 01:31:56.740]   I just, we don't know when.
[01:31:56.740 --> 01:31:59.420]   - Yes, you know, and there's quite a few folks
[01:31:59.420 --> 01:32:02.580]   who talk about the fall of the American empire.
[01:32:02.580 --> 01:32:05.420]   And it also concerns me that we don't know
[01:32:05.420 --> 01:32:06.340]   when that might fall.
[01:32:06.340 --> 01:32:10.060]   You assume me as a very excited, naive American,
[01:32:10.060 --> 01:32:12.980]   I'm very excited by this project that I think
[01:32:12.980 --> 01:32:15.660]   is the beacon of hope in the world still.
[01:32:15.660 --> 01:32:20.660]   But that's probably how you feel before it's the end.
[01:32:20.660 --> 01:32:24.700]   It's a--
[01:32:24.700 --> 01:32:25.980]   - Yeah, the party, you wanna leave the party
[01:32:25.980 --> 01:32:28.500]   before it starts to deteriorate.
[01:32:28.500 --> 01:32:31.060]   I think America could continue to have
[01:32:31.060 --> 01:32:34.520]   like a major, major leadership role for a long, long time.
[01:32:34.520 --> 01:32:36.580]   I think certain things we do will become
[01:32:36.580 --> 01:32:38.420]   maybe no longer possible in terms of the way
[01:32:38.420 --> 01:32:40.060]   we intimidate people on the world stage
[01:32:41.060 --> 01:32:43.620]   especially the way we use our currency as a weapon.
[01:32:43.620 --> 01:32:45.800]   I think that that's going to decline over time
[01:32:45.800 --> 01:32:48.660]   as we become more of a multipolar world.
[01:32:48.660 --> 01:32:50.780]   But I do still believe in America
[01:32:50.780 --> 01:32:52.380]   and the values that we're founded on,
[01:32:52.380 --> 01:32:53.500]   despite all the warts.
[01:32:53.500 --> 01:32:56.900]   I do believe in us and I would prefer us absolutely
[01:32:56.900 --> 01:32:59.900]   to be the most prominent of the multipolar world
[01:32:59.900 --> 01:33:02.260]   vis-a-vis a regime like Russia or China.
[01:33:02.260 --> 01:33:03.660]   Absolutely, there's no question.
[01:33:03.660 --> 01:33:05.980]   - So we've been talking about states and nations.
[01:33:05.980 --> 01:33:09.020]   But can we just briefly talk about Facebook and Twitter
[01:33:09.020 --> 01:33:11.700]   and companies that have a huge impact on the world as well.
[01:33:11.700 --> 01:33:13.560]   And actually one of the things that make America
[01:33:13.560 --> 01:33:16.660]   a great nation is it is the place from which
[01:33:16.660 --> 01:33:18.900]   these great companies have sprung up.
[01:33:18.900 --> 01:33:22.580]   Is there, from a human rights perspective,
[01:33:22.580 --> 01:33:24.820]   is there something that bothers you about Facebook,
[01:33:24.820 --> 01:33:26.300]   about these large companies?
[01:33:26.300 --> 01:33:29.020]   Is there something we need to fix?
[01:33:29.020 --> 01:33:33.500]   Something we need to be upset about,
[01:33:33.500 --> 01:33:38.500]   fight back on, reform, do some sort of real activism about?
[01:33:39.460 --> 01:33:42.460]   - I'm very concerned about social media platforms
[01:33:42.460 --> 01:33:43.540]   and companies.
[01:33:43.540 --> 01:33:45.340]   It almost feels like we're losing the golden age
[01:33:45.340 --> 01:33:46.180]   of the internet.
[01:33:46.180 --> 01:33:47.620]   You know, when we could like go online
[01:33:47.620 --> 01:33:50.420]   and interact with each other and share
[01:33:50.420 --> 01:33:52.380]   and not be worried about censorship.
[01:33:52.380 --> 01:33:54.180]   It feels like that was a golden age,
[01:33:54.180 --> 01:33:56.900]   like in the late 90s, 2000s.
[01:33:56.900 --> 01:33:59.760]   And now everything is becoming very politicized.
[01:33:59.760 --> 01:34:02.100]   And I'm not sure that there's a solution.
[01:34:02.100 --> 01:34:05.380]   Like I don't think there's a button we can press to fix it.
[01:34:05.380 --> 01:34:08.100]   I'm kind of afraid that this is sort of
[01:34:08.100 --> 01:34:12.660]   just what happens when society's digitized.
[01:34:12.660 --> 01:34:17.660]   Like I think that certain opinions just become demonized
[01:34:17.660 --> 01:34:23.020]   in the sort of, in the room, in the social room
[01:34:23.020 --> 01:34:25.500]   that we have on the internet.
[01:34:25.500 --> 01:34:28.680]   And I don't know if there's a magical solution there.
[01:34:28.680 --> 01:34:31.620]   I do know that there's technological solutions
[01:34:31.620 --> 01:34:35.060]   that will allow us to continue to communicate
[01:34:35.060 --> 01:34:37.440]   and for creators to reach their audiences
[01:34:37.440 --> 01:34:38.860]   without censorship.
[01:34:38.860 --> 01:34:41.060]   And that's very exciting.
[01:34:41.060 --> 01:34:43.500]   Like right now you could be de-platformed
[01:34:43.500 --> 01:34:48.300]   from your, you know, from like whether it's Patreon
[01:34:48.300 --> 01:34:49.620]   or YouTube or whatever.
[01:34:49.620 --> 01:34:52.140]   And your bank account can be closed down, right?
[01:34:52.140 --> 01:34:55.620]   There are emerging ways that Adam Curry,
[01:34:55.620 --> 01:34:57.300]   like the Podfather and a bunch of other people
[01:34:57.300 --> 01:34:59.540]   are experimenting with, where you can essentially
[01:34:59.540 --> 01:35:02.220]   have your audio podcast across a whole bunch
[01:35:02.220 --> 01:35:04.940]   of different, you know, platforms.
[01:35:04.940 --> 01:35:06.940]   So, you know, it's censorship resistant.
[01:35:06.940 --> 01:35:10.480]   And then your audience can pay you over Lightning
[01:35:10.480 --> 01:35:11.540]   in streaming money.
[01:35:11.540 --> 01:35:13.760]   Like they can stream you money as they listen.
[01:35:13.760 --> 01:35:16.040]   So you're removing the whole advertising piece.
[01:35:16.040 --> 01:35:18.340]   You don't need to do advertising anymore.
[01:35:18.340 --> 01:35:22.600]   You have this direct relationship with your,
[01:35:22.600 --> 01:35:24.800]   you know, your audience.
[01:35:24.800 --> 01:35:27.240]   And this is possible with something like Lightning
[01:35:27.240 --> 01:35:30.360]   where you can do streaming money that's censorship resistant.
[01:35:30.360 --> 01:35:32.040]   And a lot of the people who are building
[01:35:32.040 --> 01:35:35.560]   a Lightning network, for example, Elizabeth Stark,
[01:35:35.560 --> 01:35:37.660]   who, you know, started Lightning Labs
[01:35:37.660 --> 01:35:40.940]   and has done within her company,
[01:35:40.940 --> 01:35:43.760]   the people that work with her have built a huge part
[01:35:43.760 --> 01:35:45.080]   of the Lightning infrastructure.
[01:35:45.080 --> 01:35:48.120]   You know, what animates her is this idea of like,
[01:35:48.120 --> 01:35:50.820]   again, artists and creators being able to have
[01:35:50.820 --> 01:35:54.040]   that direct ability to reach out
[01:35:54.040 --> 01:35:55.800]   and have that peer to peer relationship
[01:35:55.800 --> 01:35:57.200]   with their audience.
[01:35:57.200 --> 01:35:59.000]   And I'm excited for that.
[01:35:59.000 --> 01:36:00.780]   And I do think that's coming,
[01:36:00.780 --> 01:36:04.060]   but I am very worried that the golden age
[01:36:04.060 --> 01:36:07.160]   of like centralized social media platforms
[01:36:07.160 --> 01:36:08.600]   is kind of behind us.
[01:36:08.600 --> 01:36:10.160]   And I'm not sure how to fix that.
[01:36:10.160 --> 01:36:12.040]   I don't know if that's like a fixable problem.
[01:36:12.040 --> 01:36:12.880]   - Interesting.
[01:36:12.880 --> 01:36:15.680]   I have a hope that it's a fixable problem.
[01:36:15.680 --> 01:36:18.720]   I think it's fixable because there's demand
[01:36:18.720 --> 01:36:19.600]   for it to be fixed.
[01:36:19.600 --> 01:36:21.080]   That's the way I think about it.
[01:36:21.080 --> 01:36:22.680]   - Well, is Twitter that bad right now?
[01:36:22.680 --> 01:36:24.040]   Like, I mean, it's fixable in as much
[01:36:24.040 --> 01:36:25.680]   as you can do a verification.
[01:36:25.680 --> 01:36:27.640]   So you can give a blue check to someone
[01:36:27.640 --> 01:36:29.720]   and then that person is like more credible
[01:36:29.720 --> 01:36:31.640]   and they go to the top of the comments
[01:36:31.640 --> 01:36:33.040]   and there's like tweaks you can do.
[01:36:33.040 --> 01:36:34.820]   You can continue to improve it,
[01:36:34.820 --> 01:36:37.100]   but it's not gonna fix the fact that like Twitter
[01:36:37.100 --> 01:36:39.540]   can decide to kick off the president.
[01:36:39.540 --> 01:36:41.300]   And like a lot of people are gonna be upset by that.
[01:36:41.300 --> 01:36:44.080]   You know, like there's ways you can improve the UX
[01:36:44.080 --> 01:36:46.780]   over time and they continue to do so.
[01:36:46.780 --> 01:36:50.540]   Like Clubhouse is a lot of fun, great phenomenon.
[01:36:50.540 --> 01:36:51.940]   So is Twitter Spaces.
[01:36:51.940 --> 01:36:53.580]   So they continue to iterate,
[01:36:53.580 --> 01:36:56.300]   but the censorship, the platforming piece,
[01:36:56.300 --> 01:36:58.540]   I'm not sure is fixable because if you,
[01:36:58.540 --> 01:36:59.740]   I mean, you watch the US government
[01:36:59.740 --> 01:37:03.960]   haul Zuckerberg and Dorsey and whatever
[01:37:03.960 --> 01:37:07.120]   in front of Congress, they want more censorship.
[01:37:07.120 --> 01:37:11.600]   I mean, our elected leaders want more censorship, right?
[01:37:11.600 --> 01:37:16.300]   - See, I just believe censorship is a really harsh word.
[01:37:16.300 --> 01:37:18.160]   I believe it's possible to create technologies
[01:37:18.160 --> 01:37:20.800]   where it's not Twitter doing the censorship,
[01:37:20.800 --> 01:37:24.840]   but it's individuals doing their own selection
[01:37:24.840 --> 01:37:26.840]   of what they want and don't want to see.
[01:37:26.840 --> 01:37:30.200]   So for example, if you get sick and tired of Donald Trump
[01:37:30.200 --> 01:37:33.120]   and whatever he says, or you love Donald Trump,
[01:37:33.120 --> 01:37:35.420]   you get to select yourself.
[01:37:35.420 --> 01:37:39.540]   Like you get to have more control over what you consume.
[01:37:39.540 --> 01:37:41.600]   Twitter tries to do that a little bit,
[01:37:41.600 --> 01:37:43.320]   but they obviously fail.
[01:37:43.320 --> 01:37:48.320]   Where ideas infiltrate our view that we,
[01:37:48.320 --> 01:37:52.680]   that like misinformation spreads really fast
[01:37:52.680 --> 01:37:54.840]   and conspiracy theories spread really fast
[01:37:54.840 --> 01:37:57.760]   to where the immune system that Twitter has created
[01:37:57.760 --> 01:38:02.280]   to try to censor conspiracy theories and misinformation
[01:38:02.280 --> 01:38:07.280]   is over firing and you're now censoring too many people.
[01:38:07.280 --> 01:38:11.880]   So that, it's exactly the same intuition as you said before.
[01:38:11.880 --> 01:38:14.600]   If the state is doing it, in this case,
[01:38:14.600 --> 01:38:16.520]   Twitter's kind of the state,
[01:38:16.520 --> 01:38:18.560]   it's not going to work out well.
[01:38:18.560 --> 01:38:20.920]   But if you give power to the individuals
[01:38:20.920 --> 01:38:24.120]   to do this sort of the, not even censorship,
[01:38:24.120 --> 01:38:28.760]   but incentivization and de-incentivization
[01:38:28.760 --> 01:38:32.040]   of great thoughtful content
[01:38:32.040 --> 01:38:34.720]   and terrible low effort content,
[01:38:34.720 --> 01:38:38.840]   then I feel like that's going to create a system
[01:38:38.840 --> 01:38:41.400]   where there's going to be a much more open discourse
[01:38:41.400 --> 01:38:44.240]   of ideas, dangerous ideas, difficult ideas,
[01:38:44.240 --> 01:38:48.320]   controversial ideas, and people in a decentralized way
[01:38:48.320 --> 01:38:50.440]   will be able to use their own intelligence
[01:38:50.440 --> 01:38:53.440]   to select content, to share content, spread content.
[01:38:53.440 --> 01:38:55.480]   - Let's keep it simple.
[01:38:55.480 --> 01:38:58.600]   Let's look at one example, Twitter and Jack Dorsey.
[01:38:58.600 --> 01:39:00.440]   And I think it's quite clear
[01:39:00.440 --> 01:39:02.840]   that what he believes is the solution
[01:39:02.840 --> 01:39:04.680]   is as you're kind of hinting at,
[01:39:04.680 --> 01:39:09.080]   a more kind of like regionalized system,
[01:39:09.080 --> 01:39:12.480]   which is not have one, we call it federated system, right?
[01:39:12.480 --> 01:39:13.920]   Which does not just have like one company
[01:39:13.920 --> 01:39:16.560]   in charge of everything, but there's an open protocol
[01:39:16.560 --> 01:39:18.760]   and then there's like different instances, right?
[01:39:18.760 --> 01:39:21.880]   So Twitter make, you know, Jack's dream for Twitter
[01:39:21.880 --> 01:39:24.120]   is that Twitter is this open protocol
[01:39:24.120 --> 01:39:25.760]   that the Russian government can use
[01:39:25.760 --> 01:39:26.960]   and the Chinese government can use
[01:39:26.960 --> 01:39:28.080]   and the Iranian government can use
[01:39:28.080 --> 01:39:29.120]   and the American government can use.
[01:39:29.120 --> 01:39:31.520]   And then Twitter as a company is going to use too.
[01:39:31.520 --> 01:39:32.920]   And you as the customer decide
[01:39:32.920 --> 01:39:35.040]   which implementation you want to join.
[01:39:35.040 --> 01:39:36.520]   And there's going to be different censorship
[01:39:36.520 --> 01:39:39.800]   on each instance or each federation,
[01:39:39.800 --> 01:39:43.520]   but the protocol itself would be like untouchable.
[01:39:43.520 --> 01:39:45.960]   This is kind of like the idea behind the internet, right?
[01:39:45.960 --> 01:39:48.120]   There's like different parts of the internet
[01:39:48.120 --> 01:39:51.000]   that are censored, but like at the very bottom
[01:39:51.000 --> 01:39:53.120]   of the very bottom of the backbone of it,
[01:39:53.120 --> 01:39:56.440]   it's like this globally connected,
[01:39:56.440 --> 01:39:58.840]   relatively unstoppable thing, right?
[01:39:58.840 --> 01:40:00.440]   So I think that's a pretty good vision
[01:40:00.440 --> 01:40:01.680]   and Twitter's working towards that
[01:40:01.680 --> 01:40:04.120]   with the Blue Sky Initiative.
[01:40:04.120 --> 01:40:06.520]   We'll see, I'm a little skeptical that it like works out
[01:40:06.520 --> 01:40:08.960]   'cause I've used, I use Mastodon, for example.
[01:40:08.960 --> 01:40:13.200]   Mastodon is an example of a federated social media.
[01:40:13.200 --> 01:40:15.240]   Now it's ruled by a benevolent,
[01:40:15.240 --> 01:40:17.800]   each instance is ruled by a benevolent dictator.
[01:40:17.800 --> 01:40:20.480]   It's just like, I happen to like this one, so I know.
[01:40:20.480 --> 01:40:24.240]   So rather than trust one dictator, Twitter,
[01:40:24.240 --> 01:40:27.080]   you could choose which dictator you wanna trust.
[01:40:27.080 --> 01:40:28.800]   And that's kind of the federated model.
[01:40:28.800 --> 01:40:30.880]   And maybe we head that way, but you lose things.
[01:40:30.880 --> 01:40:33.560]   When it's federated, you lose the UX,
[01:40:33.560 --> 01:40:36.040]   you lose the slickness and the feel
[01:40:36.040 --> 01:40:37.320]   and all the millions of dollars
[01:40:37.320 --> 01:40:38.760]   that they spend on developers.
[01:40:38.760 --> 01:40:41.120]   Like Mastodon is like not anywhere close
[01:40:41.120 --> 01:40:43.280]   to as nice to use as Twitter.
[01:40:43.280 --> 01:40:45.480]   So I feel like it's, again, it's this trade-off
[01:40:45.480 --> 01:40:47.400]   that we make with everything where it's convenience,
[01:40:47.400 --> 01:40:50.080]   comfort, speed versus privacy and freedom, right?
[01:40:50.080 --> 01:40:52.360]   It's very hard to have something that gives you both.
[01:40:52.360 --> 01:40:53.200]   - I don't know.
[01:40:53.200 --> 01:40:55.320]   I think, yeah, it is a trade-off.
[01:40:55.320 --> 01:40:56.320]   - Have you used one of these things
[01:40:56.320 --> 01:40:57.440]   that you feel like is good? - I have not.
[01:40:57.440 --> 01:40:59.080]   The federated-- - Dude, they're not.
[01:40:59.080 --> 01:40:59.920]   - They're not, they're not. - Not as good.
[01:40:59.920 --> 01:41:03.120]   - But the federated, I don't think it's a good,
[01:41:03.120 --> 01:41:05.800]   I think it requires genius, it requires skill,
[01:41:05.800 --> 01:41:08.680]   it requires great design to come up with a way to,
[01:41:08.680 --> 01:41:12.640]   there's a Pareto front here.
[01:41:12.640 --> 01:41:15.880]   There's a right way to hit that trade-off.
[01:41:15.880 --> 01:41:19.000]   And I honestly think there's the UX,
[01:41:19.720 --> 01:41:23.640]   the experience should be centralized,
[01:41:23.640 --> 01:41:26.200]   should be designed by the company,
[01:41:26.200 --> 01:41:31.200]   but the data and a lot of stuff that could be used
[01:41:31.200 --> 01:41:33.120]   to violate your basic rights
[01:41:33.120 --> 01:41:34.520]   should be owned by the individual.
[01:41:34.520 --> 01:41:36.800]   And I think there's a way to decouple those,
[01:41:36.800 --> 01:41:38.960]   like create an incredible experience
[01:41:38.960 --> 01:41:43.480]   to where you go there and you enjoy the market
[01:41:43.480 --> 01:41:46.160]   where you can share your data
[01:41:46.160 --> 01:41:48.000]   and have complete control over it
[01:41:48.000 --> 01:41:51.760]   and always have, I mean, there's a lot of basic UX ideas.
[01:41:51.760 --> 01:41:53.840]   Like just as an example,
[01:41:53.840 --> 01:41:58.640]   I think there should always be in everything you design
[01:41:58.640 --> 01:42:00.880]   a one button that's always there that says,
[01:42:00.880 --> 01:42:05.880]   forget I ever existed, delete everything you know about me.
[01:42:05.880 --> 01:42:09.760]   And maybe it's one button that you click
[01:42:09.760 --> 01:42:11.560]   and it asks, are you sure?
[01:42:11.560 --> 01:42:13.360]   And you have to be able to say yes.
[01:42:13.360 --> 01:42:15.520]   Like that's a feature that's fundamental
[01:42:15.520 --> 01:42:17.800]   to a good social network, I believe.
[01:42:17.800 --> 01:42:20.680]   Like currently social networks,
[01:42:20.680 --> 01:42:23.400]   first of all, most of them don't allow you to do that.
[01:42:23.400 --> 01:42:25.840]   They don't make it transparent how much data they had,
[01:42:25.840 --> 01:42:27.040]   who they shared it with,
[01:42:27.040 --> 01:42:29.160]   and they also make it exceptionally difficult
[01:42:29.160 --> 01:42:30.280]   to delete accounts.
[01:42:30.280 --> 01:42:33.280]   So like that's a very basic starting point,
[01:42:33.280 --> 01:42:38.120]   but having that button means that you have control,
[01:42:38.120 --> 01:42:39.880]   but that's step one of the control.
[01:42:39.880 --> 01:42:42.640]   There's a transparency of knowing exactly
[01:42:42.640 --> 01:42:45.760]   when what data is being shared about you,
[01:42:45.760 --> 01:42:48.440]   how much data is already being recorded about you.
[01:42:48.440 --> 01:42:50.040]   All that is transparency.
[01:42:50.040 --> 01:42:53.800]   And I believe that's a really good business model
[01:42:53.800 --> 01:42:56.040]   because when there's transparency and control,
[01:42:56.040 --> 01:42:59.040]   people would be willing to give over a lot more data
[01:42:59.040 --> 01:43:01.600]   as long as they know what they're giving over,
[01:43:01.600 --> 01:43:03.800]   as long as they know what they can delete.
[01:43:03.800 --> 01:43:06.320]   - Yeah, I guess maybe you're more optimistic
[01:43:06.320 --> 01:43:07.640]   about people caring.
[01:43:07.640 --> 01:43:10.960]   I feel like so few people actually care
[01:43:10.960 --> 01:43:12.400]   about their privacy and freedom.
[01:43:12.400 --> 01:43:15.280]   I've just watched everybody give it up, you know.
[01:43:15.280 --> 01:43:16.560]   But we'll see.
[01:43:16.560 --> 01:43:18.800]   I guess just to bookend that,
[01:43:18.800 --> 01:43:19.720]   I think we're at this moment
[01:43:19.720 --> 01:43:21.440]   where obviously the centralized platforms
[01:43:21.440 --> 01:43:23.360]   are just so much easier and better to use,
[01:43:23.360 --> 01:43:27.000]   and to strike it out and venture out
[01:43:27.000 --> 01:43:30.720]   and use a federated instance or something,
[01:43:30.720 --> 01:43:31.560]   even like Keybase,
[01:43:31.560 --> 01:43:33.040]   which is kind of like a cool encrypted way
[01:43:33.040 --> 01:43:35.280]   to have group chats.
[01:43:35.280 --> 01:43:37.760]   It just requires a lot of your time,
[01:43:37.760 --> 01:43:39.520]   and a lot of people don't have that time.
[01:43:39.520 --> 01:43:40.680]   But I will say one thing.
[01:43:40.680 --> 01:43:42.000]   I do think there is this future
[01:43:42.000 --> 01:43:44.840]   where we do go into more of this,
[01:43:44.840 --> 01:43:49.720]   it's called a tribal model, or tribes,
[01:43:49.720 --> 01:43:52.000]   which is this social environment
[01:43:52.000 --> 01:43:53.440]   being built on top of Lightning
[01:43:53.440 --> 01:43:57.320]   by an app called Sphinx.
[01:43:57.320 --> 01:44:00.280]   And the idea is kind of like it's a decentralized Slack.
[01:44:00.280 --> 01:44:02.080]   You have your Slack instance,
[01:44:02.080 --> 01:44:04.000]   which has a bunch of people in the community,
[01:44:04.000 --> 01:44:06.400]   and you have different ways to message each other,
[01:44:06.400 --> 01:44:07.400]   and it's all encrypted.
[01:44:07.400 --> 01:44:10.240]   And then it has plugins for things like Jitsi
[01:44:10.240 --> 01:44:11.120]   instead of Zoom.
[01:44:11.120 --> 01:44:14.600]   So like an open source encrypted video messenger.
[01:44:14.600 --> 01:44:17.320]   It has ways to plug in the content you wanna get
[01:44:17.320 --> 01:44:21.520]   from different platforms that you follow,
[01:44:21.520 --> 01:44:23.120]   like podcasts, things like that.
[01:44:23.120 --> 01:44:25.400]   And again, it allows you to pay those people directly
[01:44:25.400 --> 01:44:27.520]   in a censorship-resistant private way.
[01:44:27.520 --> 01:44:28.560]   - So it's really nice to connect
[01:44:28.560 --> 01:44:29.640]   to the Lightning network.
[01:44:29.640 --> 01:44:31.320]   - Yeah, so it's all sort of built on Lightning,
[01:44:31.320 --> 01:44:33.640]   but the idea you can think about it is like
[01:44:33.640 --> 01:44:36.840]   you're slowly starting to build up the idea of a WeChat,
[01:44:36.840 --> 01:44:38.520]   but with freedom principles.
[01:44:38.520 --> 01:44:40.120]   'Cause right now WeChat's the king
[01:44:40.120 --> 01:44:41.160]   of convenience and comfort,
[01:44:41.160 --> 01:44:42.600]   but of course it's feeding all that data
[01:44:42.600 --> 01:44:44.720]   to the big brother in the surveillance state.
[01:44:44.720 --> 01:44:47.520]   And then we have like our own versions over here in America
[01:44:47.520 --> 01:44:50.120]   that are not quite as convenient or amazing,
[01:44:50.120 --> 01:44:53.360]   but like we give up slightly less privacy and freedom.
[01:44:53.360 --> 01:44:55.880]   But this thing has a lot of promising features to it.
[01:44:55.880 --> 01:44:56.800]   It's worth checking out.
[01:44:56.800 --> 01:44:58.080]   It's very like early days.
[01:44:58.080 --> 01:45:00.360]   Like it feels like, I mean, I was pretty young,
[01:45:00.360 --> 01:45:03.320]   but it feels like the '90s in the internet.
[01:45:03.320 --> 01:45:04.520]   Like it has that feeling.
[01:45:04.520 --> 01:45:05.360]   - The Sphinx does.
[01:45:05.360 --> 01:45:07.640]   - Yeah, you know it's rough around the edges,
[01:45:07.640 --> 01:45:08.920]   but you can feel the magic.
[01:45:08.920 --> 01:45:09.920]   It's pretty cool.
[01:45:09.920 --> 01:45:12.960]   - I'm very much like with Steve Jobs on this.
[01:45:12.960 --> 01:45:16.120]   I think the founding principles are exceptionally important,
[01:45:16.120 --> 01:45:17.280]   but at the end of the day,
[01:45:17.280 --> 01:45:22.280]   the design of how sleek it is, how easy it is to use.
[01:45:22.280 --> 01:45:26.740]   And that's not just like pretty icing on the cake.
[01:45:26.740 --> 01:45:29.840]   That is, the icing is the cake.
[01:45:29.840 --> 01:45:30.680]   - Yeah. - Because like,
[01:45:30.680 --> 01:45:33.000]   how easy it is to use, how natural it is.
[01:45:33.000 --> 01:45:34.240]   It's the Trojan horse thing.
[01:45:34.240 --> 01:45:37.880]   Like you don't get, it has to be pretty and shiny.
[01:45:37.880 --> 01:45:40.400]   It has to fundamentally connect
[01:45:40.400 --> 01:45:41.720]   to the basics of human nature,
[01:45:41.720 --> 01:45:45.540]   which is what is pleasant to use, what feels good to use.
[01:45:45.540 --> 01:45:47.840]   You have to, you know, to trick people
[01:45:47.840 --> 01:45:51.040]   into eating a broccoli, you have to put like a delicious,
[01:45:51.040 --> 01:45:51.880]   whatever on it. - Well, again,
[01:45:51.880 --> 01:45:53.760]   PGP is a kind of a pain to use, right?
[01:45:53.760 --> 01:45:55.000]   For, if you want privacy.
[01:45:55.000 --> 01:45:55.840]   - Yeah, so signals don't upgrade.
[01:45:55.840 --> 01:45:57.280]   - Signal is way better.
[01:45:57.280 --> 01:45:59.740]   I mean, and it's way better than it was five years ago.
[01:45:59.740 --> 01:46:02.700]   And it's not quite as good as like,
[01:46:02.700 --> 01:46:05.780]   not quite as seamless, right, as like a WhatsApp yet,
[01:46:05.780 --> 01:46:07.480]   but it's almost there.
[01:46:07.480 --> 01:46:08.840]   And they were able to do it.
[01:46:08.840 --> 01:46:12.800]   And you're gonna see that with Bitcoin wallets as well.
[01:46:12.800 --> 01:46:14.180]   I mean, they're almost there.
[01:46:14.180 --> 01:46:17.520]   They're like, if you use like a moon wallet is like,
[01:46:17.520 --> 01:46:19.520]   I mean, it's so cool looking and it's so seamless.
[01:46:19.520 --> 01:46:20.880]   And they've spent so many hours
[01:46:20.880 --> 01:46:22.760]   thinking about your experience.
[01:46:22.760 --> 01:46:23.820]   We are getting there.
[01:46:23.820 --> 01:46:25.880]   Whereas 10 years ago, it was like impossible to use.
[01:46:25.880 --> 01:46:27.640]   - One of the things that signal doesn't have,
[01:46:27.640 --> 01:46:32.640]   and I believe these kinds of applications need to have,
[01:46:32.640 --> 01:46:35.520]   is like a, I hate the term, but killer app,
[01:46:35.520 --> 01:46:38.800]   which is like a dumb,
[01:46:38.800 --> 01:46:42.720]   but very viral and popular reason to switch.
[01:46:42.720 --> 01:46:45.800]   I didn't see exactly, I mean, I've been using signal,
[01:46:45.800 --> 01:46:50.800]   but I haven't seen a big reason to switch.
[01:46:50.800 --> 01:46:54.040]   I mean, the reason--
[01:46:54.040 --> 01:46:55.840]   - No, but I haven't switched everything to it.
[01:46:55.840 --> 01:46:57.080]   You know what I mean?
[01:46:57.080 --> 01:47:00.280]   - Yeah, the exodus to signal was in January.
[01:47:00.280 --> 01:47:04.360]   They had a huge user surge for two main reasons.
[01:47:04.360 --> 01:47:05.880]   One, hilariously enough, of course,
[01:47:05.880 --> 01:47:09.320]   was Elon tweeted like, you should use signal, right?
[01:47:09.320 --> 01:47:10.700]   Which is not insignificant.
[01:47:10.700 --> 01:47:13.160]   And then the other one was that like WhatsApp
[01:47:13.160 --> 01:47:14.960]   changed kind of some of its terms of service
[01:47:14.960 --> 01:47:17.260]   and like announced to all of its users
[01:47:17.260 --> 01:47:19.840]   in this little pop-up that it was gonna be
[01:47:19.840 --> 01:47:21.720]   sort of like changing the way it handled your data.
[01:47:21.720 --> 01:47:23.120]   That spooked a lot of people.
[01:47:23.120 --> 01:47:25.520]   So these two things really combined
[01:47:25.520 --> 01:47:28.720]   and tens of millions of people in the following weeks
[01:47:28.720 --> 01:47:30.680]   between January and February joined signal.
[01:47:30.680 --> 01:47:33.080]   It's like, it really has had its day in the sun.
[01:47:33.960 --> 01:47:36.760]   And they are like frantically trying to keep up with it.
[01:47:36.760 --> 01:47:38.760]   Like, and it's really nice to see
[01:47:38.760 --> 01:47:42.160]   that this encrypted messaging service,
[01:47:42.160 --> 01:47:46.520]   which prioritizes your privacy in a way that,
[01:47:46.520 --> 01:47:48.480]   you know, the government, again,
[01:47:48.480 --> 01:47:49.760]   may know like the metadata,
[01:47:49.760 --> 01:47:51.180]   but doesn't know exactly what you're saying
[01:47:51.180 --> 01:47:53.080]   unless they can get your hands on your phone.
[01:47:53.080 --> 01:47:54.220]   I think that's very, very powerful.
[01:47:54.220 --> 01:47:55.620]   So it can be done.
[01:47:55.620 --> 01:47:57.540]   I don't wanna be too jaded here.
[01:47:57.540 --> 01:47:59.520]   I think it can be done.
[01:47:59.520 --> 01:48:01.120]   I think we can fight back.
[01:48:01.120 --> 01:48:02.480]   And I think we can make,
[01:48:02.480 --> 01:48:04.560]   continue to make these digital communications tools
[01:48:04.560 --> 01:48:09.120]   and platforms in a way that really benefits us.
[01:48:09.120 --> 01:48:12.600]   - Yeah, I'm not sure, but I'm hopeful as well.
[01:48:12.600 --> 01:48:16.840]   I'm hopeful that if you look at the trend of technologies,
[01:48:16.840 --> 01:48:19.560]   they ultimately are ones that respect privacy,
[01:48:19.560 --> 01:48:23.640]   respect security and basic human rights.
[01:48:23.640 --> 01:48:25.840]   I mean, that's at least the hope.
[01:48:25.840 --> 01:48:28.480]   So Garry Kasparov, I'm Russian.
[01:48:28.480 --> 01:48:30.860]   He means a lot to me on a personal level.
[01:48:30.860 --> 01:48:34.320]   He is the chairman of Human Rights Foundation.
[01:48:34.320 --> 01:48:37.000]   What does Garry have to do with anything?
[01:48:37.000 --> 01:48:39.200]   What's your relationship like with him?
[01:48:39.200 --> 01:48:40.800]   Do you like chess?
[01:48:40.800 --> 01:48:45.040]   What are his specific focuses and ideas around the HRF?
[01:48:45.040 --> 01:48:47.400]   Can you just speak to it in general?
[01:48:47.400 --> 01:48:50.040]   - Yeah, so our chairman at the Human Rights Foundation
[01:48:50.040 --> 01:48:53.960]   was Václav Havel, who of course was like
[01:48:53.960 --> 01:48:56.200]   the famous Czech democracy activist
[01:48:56.200 --> 01:48:59.760]   who helped lead the Velvet Revolution
[01:48:59.760 --> 01:49:01.360]   and then ended up becoming
[01:49:01.360 --> 01:49:04.280]   the first democratically elected leader
[01:49:04.280 --> 01:49:07.920]   of the Czech Republic after the Soviet Union fell.
[01:49:07.920 --> 01:49:10.420]   He passed away in 2011.
[01:49:10.420 --> 01:49:13.280]   And it was very difficult to find a replacement
[01:49:13.280 --> 01:49:16.380]   'cause who can fill Havel's shoes?
[01:49:16.380 --> 01:49:19.120]   But if one could, it would be Garry, right?
[01:49:19.120 --> 01:49:21.440]   So we like really tried to get Garry to join
[01:49:21.440 --> 01:49:22.580]   and thankfully he agreed.
[01:49:22.580 --> 01:49:24.860]   And we've had an amazing relationship
[01:49:24.860 --> 01:49:26.180]   with Garry over the years.
[01:49:26.180 --> 01:49:29.080]   I mean, he's been relentless in his pursuit of freedom.
[01:49:29.080 --> 01:49:30.520]   I mean, he could have retired
[01:49:30.520 --> 01:49:32.560]   and taken his career in a different direction
[01:49:32.560 --> 01:49:34.040]   and he could be hanging out with Putin
[01:49:34.040 --> 01:49:36.440]   and have a pleasure yacht and all kinds of stuff.
[01:49:36.440 --> 01:49:38.720]   But he decided to risk it.
[01:49:38.720 --> 01:49:41.320]   And if you actually study like the times
[01:49:41.320 --> 01:49:43.720]   when he was running for president in Russia,
[01:49:43.720 --> 01:49:46.160]   Masha Gessen followed him around in "The Man Without a Face."
[01:49:46.160 --> 01:49:48.320]   It's a great, great book about Putin.
[01:49:48.320 --> 01:49:51.640]   There's a fabulous chapter where she's following around Garry
[01:49:51.640 --> 01:49:52.520]   when he's campaigning.
[01:49:52.520 --> 01:49:54.700]   And I mean, he risked a lot.
[01:49:54.700 --> 01:49:56.260]   I mean, he can't go back to Russia anymore.
[01:49:56.260 --> 01:49:58.060]   He gave up his country.
[01:49:58.060 --> 01:50:01.140]   He's given up a huge amount to be able to speak his mind
[01:50:01.140 --> 01:50:03.880]   and to have this dream, this beautiful vision
[01:50:03.880 --> 01:50:05.240]   of a free and democratic Russia.
[01:50:05.240 --> 01:50:06.600]   He really believes in it.
[01:50:06.600 --> 01:50:07.640]   It's been a great experience.
[01:50:07.640 --> 01:50:09.520]   I work very closely with Garry.
[01:50:09.520 --> 01:50:11.080]   We talk a lot.
[01:50:11.080 --> 01:50:13.280]   We do different things around the world together.
[01:50:13.280 --> 01:50:15.480]   He's come out to a lot of events
[01:50:15.480 --> 01:50:18.040]   in different cities around the world.
[01:50:18.040 --> 01:50:19.560]   And he's been a very active chairman.
[01:50:19.560 --> 01:50:20.880]   This isn't some figurehead.
[01:50:20.880 --> 01:50:23.480]   He's very involved and it's really, really great.
[01:50:23.480 --> 01:50:26.440]   I mean, everything he's involved with is,
[01:50:26.440 --> 01:50:28.940]   as one journalist who attends our events says,
[01:50:28.940 --> 01:50:30.320]   when he walks in the room,
[01:50:30.320 --> 01:50:33.620]   the average IQ of the room goes up pretty significantly.
[01:50:33.620 --> 01:50:36.540]   I'm not a big chess person, unfortunately,
[01:50:36.540 --> 01:50:38.300]   so I have not been able to connect with him on that.
[01:50:38.300 --> 01:50:40.500]   But I think he probably would prefer it that way.
[01:50:40.500 --> 01:50:43.420]   All he gets is people who wanna talk to him about chess.
[01:50:43.420 --> 01:50:46.060]   So here we can talk about kind of human rights strategy
[01:50:46.060 --> 01:50:50.900]   and how to improve our fight against dictators.
[01:50:50.900 --> 01:50:53.860]   But he really has that moral clarity
[01:50:53.860 --> 01:50:57.460]   that I really appreciate.
[01:50:57.460 --> 01:51:00.240]   - Yeah, so he has a lot of fascinating ideas
[01:51:00.240 --> 01:51:02.540]   about artificial intelligence as well.
[01:51:02.540 --> 01:51:05.020]   He's opened my eyes a little bit
[01:51:05.020 --> 01:51:09.300]   to the state of Russia today
[01:51:09.300 --> 01:51:13.140]   because I've read most books on Putin
[01:51:13.140 --> 01:51:14.620]   in the English language
[01:51:14.620 --> 01:51:16.820]   in sort of trying to understand things.
[01:51:16.820 --> 01:51:21.460]   And I try to look at it from a historical perspective,
[01:51:21.460 --> 01:51:24.700]   like almost like we're living 100 years from now.
[01:51:24.700 --> 01:51:28.220]   And I look at Putin as a important figure
[01:51:28.220 --> 01:51:30.180]   in the history of human civilization
[01:51:30.180 --> 01:51:31.740]   and study it in that way.
[01:51:31.740 --> 01:51:34.620]   I think the way Gary looks at it,
[01:51:34.620 --> 01:51:37.460]   he probably doesn't appreciate me looking at the way I do.
[01:51:37.460 --> 01:51:40.260]   But the way he looks at it is
[01:51:40.260 --> 01:51:46.460]   we can still change the direction of Russia.
[01:51:46.460 --> 01:51:48.180]   And we individual human beings,
[01:51:48.180 --> 01:51:52.020]   and we communities, and we nations can take actions,
[01:51:52.020 --> 01:51:55.220]   have policies that can change the direction of Russia.
[01:51:55.220 --> 01:51:58.660]   To me, I take a sort of going to the library,
[01:51:58.660 --> 01:52:01.940]   passive view of studying fascinating aspects of Russia.
[01:52:01.940 --> 01:52:03.900]   To me, Russia means,
[01:52:03.900 --> 01:52:06.900]   like most of my family suffered through the Soviet Union
[01:52:06.900 --> 01:52:09.660]   and I see beauty in suffering,
[01:52:09.660 --> 01:52:12.660]   the poetry, the music, the stories.
[01:52:12.660 --> 01:52:16.140]   And just there's so much love that emerged from the pain
[01:52:16.140 --> 01:52:18.700]   that I just enjoy the music of that.
[01:52:18.700 --> 01:52:23.700]   But to Gary and to many activists that I speak to,
[01:52:23.700 --> 01:52:28.940]   they love not just the Russia of the past.
[01:52:28.940 --> 01:52:32.380]   They have a vision and a hope for Russia of the future.
[01:52:32.380 --> 01:52:35.100]   And they criticize me a little bit
[01:52:35.100 --> 01:52:38.100]   for being a little bit too scholarly about the past
[01:52:38.100 --> 01:52:39.140]   and ignoring the future.
[01:52:39.140 --> 01:52:40.900]   And there's something to that.
[01:52:40.900 --> 01:52:45.660]   So he opens my eyes to look to the future of Russia.
[01:52:45.660 --> 01:52:48.980]   Gary and a handful of other Russian activists
[01:52:48.980 --> 01:52:50.380]   that we work closely with,
[01:52:50.380 --> 01:52:51.860]   including Vladimir Kara-Murza,
[01:52:51.860 --> 01:52:54.140]   who again, I mean, it's just incredibly heroic.
[01:52:54.140 --> 01:52:56.580]   The man has survived two poisonings by Putin.
[01:52:56.580 --> 01:52:59.100]   They like to say that,
[01:52:59.100 --> 01:53:02.940]   Russians will bring democracy to Russia on their own terms.
[01:53:02.940 --> 01:53:04.140]   They don't need our help.
[01:53:04.140 --> 01:53:07.020]   This is what Vladimir especially says.
[01:53:07.020 --> 01:53:07.860]   But what he does say
[01:53:07.860 --> 01:53:09.980]   is that we should stop propping up Putin.
[01:53:09.980 --> 01:53:11.540]   Like that's kind of his,
[01:53:11.540 --> 01:53:13.460]   stop kind of legitimizing him.
[01:53:13.460 --> 01:53:15.140]   That's kind of his argument.
[01:53:15.140 --> 01:53:17.460]   He's like, we don't need your foreign interference.
[01:53:17.460 --> 01:53:18.420]   We don't need your ideas.
[01:53:18.420 --> 01:53:19.780]   We don't need your help.
[01:53:19.780 --> 01:53:20.900]   We can do it on our own,
[01:53:20.900 --> 01:53:24.380]   but please stop like propping up our illegitimate ruler.
[01:53:24.380 --> 01:53:26.260]   That's kind of like his point of view,
[01:53:26.260 --> 01:53:30.380]   which I think is interesting and fair.
[01:53:30.380 --> 01:53:35.100]   - Yeah, let me just say on one unrelated comment,
[01:53:35.100 --> 01:53:37.980]   some people criticize me and others,
[01:53:37.980 --> 01:53:40.700]   like Joe Rogan for giving people a platform.
[01:53:44.020 --> 01:53:46.100]   I think in some cases that's applicable,
[01:53:46.100 --> 01:53:51.020]   but I think in most cases, knowledge is power.
[01:53:51.020 --> 01:53:54.020]   And there's no such thing as giving a platform.
[01:53:54.020 --> 01:53:56.700]   The conversation just shines a light,
[01:53:56.700 --> 01:53:58.660]   as long as you shine the light well.
[01:53:58.660 --> 01:54:02.060]   And as long as in shining the light
[01:54:02.060 --> 01:54:03.380]   and having the conversation,
[01:54:03.380 --> 01:54:07.140]   you reveal something fundamental about the state of things,
[01:54:07.140 --> 01:54:09.820]   about the people, whether that's Putin
[01:54:09.820 --> 01:54:11.940]   or some of the other controversial figures
[01:54:11.940 --> 01:54:12.860]   that have come up.
[01:54:13.700 --> 01:54:16.020]   In a possible future conversation.
[01:54:16.020 --> 01:54:20.060]   So I don't like this kind of platforming idea.
[01:54:20.060 --> 01:54:22.220]   I think conversations save us.
[01:54:22.220 --> 01:54:24.220]   They don't destroy us.
[01:54:24.220 --> 01:54:26.540]   - Yeah, I mean, that's journalism though.
[01:54:26.540 --> 01:54:29.380]   I mean, that's very different from advocacy
[01:54:29.380 --> 01:54:32.980]   or strategic thinking about what to do with Russia.
[01:54:32.980 --> 01:54:33.940]   Absolutely, yeah.
[01:54:33.940 --> 01:54:35.220]   We should interview everybody
[01:54:35.220 --> 01:54:38.140]   and everybody should know exactly what they're thinking.
[01:54:38.140 --> 01:54:41.060]   - But journalism to me has become a dirty word
[01:54:41.060 --> 01:54:45.780]   because it's done so poorly by so many people that...
[01:54:45.780 --> 01:54:51.260]   I listen to sometimes certain programs,
[01:54:51.260 --> 01:54:53.060]   like, I don't know,
[01:54:53.060 --> 01:54:56.900]   like Meet the Press and the Fox Sunday program,
[01:54:56.900 --> 01:54:59.020]   just certain things just to tune in
[01:54:59.020 --> 01:55:02.860]   and see what different news medias are paying attention to.
[01:55:02.860 --> 01:55:05.380]   And the kind of interviews they do
[01:55:05.380 --> 01:55:07.540]   is like five minutes at most,
[01:55:07.540 --> 01:55:08.860]   but usually it's like one minute.
[01:55:08.860 --> 01:55:13.300]   It's these quick clip things and it's very gotcha.
[01:55:13.300 --> 01:55:14.620]   And they're looking for ways
[01:55:14.620 --> 01:55:17.620]   to sort of grab almost a misstatement.
[01:55:17.620 --> 01:55:19.900]   They wanna catch you off guard.
[01:55:19.900 --> 01:55:23.860]   They wanna ask the quote, like the harsh question,
[01:55:23.860 --> 01:55:27.420]   but without any of the dance of conversation
[01:55:27.420 --> 01:55:29.100]   that reveals the truth.
[01:55:29.100 --> 01:55:33.660]   You can't just get to the truth by asking it.
[01:55:33.660 --> 01:55:36.420]   You have to sneak up on it.
[01:55:36.420 --> 01:55:38.820]   And I think that's an art form.
[01:55:38.820 --> 01:55:42.460]   And I think that art form involves long form conversation.
[01:55:42.460 --> 01:55:44.820]   Like I'm a huge believer in just,
[01:55:44.820 --> 01:55:46.380]   I guess that's what's called, I don't know,
[01:55:46.380 --> 01:55:48.020]   in-depth journalism or whatever,
[01:55:48.020 --> 01:55:51.140]   like where you spend months or years on a story.
[01:55:51.140 --> 01:55:51.980]   - Yeah, beautiful.
[01:55:51.980 --> 01:55:54.380]   - In that same way, I think of long form conversation
[01:55:54.380 --> 01:55:56.820]   is like you spend many hours
[01:55:56.820 --> 01:55:58.460]   and you spend months and years preparing
[01:55:58.460 --> 01:55:59.540]   for those many hours,
[01:55:59.540 --> 01:56:02.620]   but like it's not this like short form
[01:56:02.620 --> 01:56:05.420]   trying to get the most controversial
[01:56:05.420 --> 01:56:07.260]   little tidbit of a story out.
[01:56:07.260 --> 01:56:09.660]   And unfortunately, the funding mechanisms
[01:56:09.660 --> 01:56:13.020]   behind journalism are such that they are incentivized,
[01:56:13.020 --> 01:56:16.340]   clickbait journalism versus like in-depth,
[01:56:16.340 --> 01:56:18.660]   long form digging for the truth.
[01:56:18.660 --> 01:56:20.340]   - I have a conflicted relationship with journalism
[01:56:20.340 --> 01:56:22.940]   because to me, press freedom is so core.
[01:56:22.940 --> 01:56:23.780]   - Right.
[01:56:23.780 --> 01:56:24.620]   - And independent journalists around the world
[01:56:24.620 --> 01:56:25.460]   are so brave.
[01:56:25.460 --> 01:56:26.420]   - Yes.
[01:56:26.420 --> 01:56:28.820]   - Especially in countries like Russia or China, et cetera.
[01:56:28.820 --> 01:56:32.500]   And really good journalism is still something
[01:56:32.500 --> 01:56:34.780]   I absolutely, I love and I enjoy.
[01:56:34.780 --> 01:56:37.020]   Like this, especially like to say again,
[01:56:37.020 --> 01:56:38.900]   this New Yorker piece on what's happening to the Uyghurs
[01:56:38.900 --> 01:56:40.700]   is incredibly well reported.
[01:56:40.700 --> 01:56:43.020]   However, on the other hand,
[01:56:43.020 --> 01:56:46.780]   you have this sort of clickbaity journalism
[01:56:46.780 --> 01:56:48.300]   that's all about sensationalism
[01:56:48.300 --> 01:56:49.860]   and that gets used as a tool.
[01:56:49.860 --> 01:56:53.980]   I mean, whether it be against things like privacy
[01:56:53.980 --> 01:56:54.980]   or Bitcoin or whatever,
[01:56:54.980 --> 01:56:57.500]   you have like people who sensationalize
[01:56:57.500 --> 01:57:00.700]   and it gets used in the service of the surveillance state,
[01:57:00.700 --> 01:57:02.260]   the war on terror, whatever.
[01:57:02.580 --> 01:57:06.020]   It's difficult, but I think journalism is essential
[01:57:06.020 --> 01:57:11.020]   to a free society, but it can sometimes be,
[01:57:11.020 --> 01:57:13.300]   it can wear my patience thin sometimes.
[01:57:13.300 --> 01:57:14.940]   - Like it's been, to be honest,
[01:57:14.940 --> 01:57:16.780]   it's been a huge burden on me personally,
[01:57:16.780 --> 01:57:18.980]   if I were to just turn this into a therapy session
[01:57:18.980 --> 01:57:20.220]   for a brief moment.
[01:57:20.220 --> 01:57:22.460]   When I look at people, when I interact with people,
[01:57:22.460 --> 01:57:24.980]   I'd like to see the best in them.
[01:57:24.980 --> 01:57:28.940]   And the burden that weighs heavy on me
[01:57:28.940 --> 01:57:31.660]   is sometimes people I talk to may not be
[01:57:32.380 --> 01:57:33.980]   good people.
[01:57:33.980 --> 01:57:36.620]   And I don't, I'd love to say,
[01:57:36.620 --> 01:57:39.020]   I believe everybody has good in them.
[01:57:39.020 --> 01:57:41.260]   And I try to focus on that.
[01:57:41.260 --> 01:57:45.420]   The burden that weighs on me is sometimes that
[01:57:45.420 --> 01:57:48.660]   there may be conversations where that's irresponsible,
[01:57:48.660 --> 01:57:53.660]   where I have to also call people out.
[01:57:53.660 --> 01:57:55.500]   I have to do enough of the hard lifting
[01:57:55.500 --> 01:57:57.980]   and the hard work of knowing exactly
[01:57:57.980 --> 01:58:01.540]   what are the bad things that that person has done.
[01:58:01.540 --> 01:58:05.300]   And I also have the responsibility to call them out on it.
[01:58:05.300 --> 01:58:07.940]   And that's for me personally, just an unpleasant feeling.
[01:58:07.940 --> 01:58:10.100]   That's where speaking to journalism,
[01:58:10.100 --> 01:58:12.900]   like I think journalists are too much focused
[01:58:12.900 --> 01:58:16.900]   on the bad things a person has done
[01:58:16.900 --> 01:58:21.700]   and not enough on the digging into the full complexity
[01:58:21.700 --> 01:58:25.260]   of the human being behind all the things that have been done.
[01:58:25.260 --> 01:58:28.060]   But at the same time, you know,
[01:58:28.060 --> 01:58:30.980]   I can't have a conversation with Hitler
[01:58:30.980 --> 01:58:33.700]   and not ask about the prison camps.
[01:58:33.700 --> 01:58:34.620]   - Yeah. - Yeah.
[01:58:34.620 --> 01:58:36.220]   Yeah, no, so from the human rights perspective,
[01:58:36.220 --> 01:58:40.340]   one of our programs is we try to go after people
[01:58:40.340 --> 01:58:41.940]   who do PR for dictators.
[01:58:41.940 --> 01:58:45.300]   So like, and a lot of people do.
[01:58:45.300 --> 01:58:48.300]   Like PR firms in Washington get hired by all these dictators
[01:58:48.300 --> 01:58:51.740]   and they make a lot of money to make them look good.
[01:58:51.740 --> 01:58:53.820]   It's called whitewashing or putting lipstick on a pig
[01:58:53.820 --> 01:58:54.660]   or whatever you wanna do.
[01:58:54.660 --> 01:58:56.140]   Astro-turfing is like the fake,
[01:58:56.140 --> 01:58:57.580]   you make fake social media accounts
[01:58:57.580 --> 01:58:59.900]   to make it seem like you're popular.
[01:58:59.900 --> 01:59:01.340]   But whitewashing is a huge issue.
[01:59:01.340 --> 01:59:06.340]   So I think it's completely fair to interview like dictators
[01:59:06.340 --> 01:59:07.580]   and stuff like that.
[01:59:07.580 --> 01:59:09.300]   Amanpour does a pretty good job.
[01:59:09.300 --> 01:59:10.700]   She's really good.
[01:59:10.700 --> 01:59:13.980]   She makes sure that there's no messing around.
[01:59:13.980 --> 01:59:16.580]   I mean, her interviews of Museveni recently,
[01:59:16.580 --> 01:59:18.500]   the Ugandan dictator was very good.
[01:59:18.500 --> 01:59:19.340]   I mean, she's basically like,
[01:59:19.340 --> 01:59:22.620]   "Well, like, why are you rigging another election?
[01:59:22.620 --> 01:59:24.020]   "Please tell us," you know?
[01:59:24.020 --> 01:59:26.020]   And she's fearless and she's good.
[01:59:26.020 --> 01:59:27.860]   And that can be a helpful thing to have
[01:59:27.860 --> 01:59:30.020]   on YouTube as a resource.
[01:59:30.020 --> 01:59:35.020]   But it's quite clear when it descends into a PR session
[01:59:35.020 --> 01:59:37.460]   and you just have to be like very careful about it.
[01:59:37.460 --> 01:59:41.540]   Like Asma al-Assad, the wife of the butcher in Syria,
[01:59:41.540 --> 01:59:43.540]   you know, was like profiled by Vogue
[01:59:43.540 --> 01:59:45.500]   and it was this whole rose in the desert thing.
[01:59:45.500 --> 01:59:46.700]   It's a bunch of nonsense.
[01:59:46.700 --> 01:59:50.340]   Terrible, terrible, terrible, total propaganda.
[01:59:50.340 --> 01:59:54.980]   But a like honest interview where you're asking
[01:59:54.980 --> 01:59:58.700]   about all the tough questions, very important.
[01:59:58.700 --> 02:00:01.060]   So I think it's just a matter of like content, right?
[02:00:01.060 --> 02:00:03.860]   - Is there a good resource to study whitewashing?
[02:00:03.860 --> 02:00:07.380]   Like to know what manipulative PR looks like?
[02:00:07.380 --> 02:00:09.060]   - I think you just, you should know,
[02:00:09.060 --> 02:00:10.920]   if you've researched the topic,
[02:00:10.920 --> 02:00:13.580]   you should know it inside you because it would be,
[02:00:13.580 --> 02:00:15.580]   is there anything you're afraid to ask?
[02:00:15.580 --> 02:00:16.420]   That would be it.
[02:00:16.420 --> 02:00:18.020]   Make sure you're asking all the questions.
[02:00:18.020 --> 02:00:20.020]   As long as you're asking all the questions that you have,
[02:00:20.020 --> 02:00:20.980]   you're good.
[02:00:20.980 --> 02:00:23.260]   But if there's something you're afraid to ask,
[02:00:23.260 --> 02:00:25.900]   then maybe you're self-censoring, right?
[02:00:25.900 --> 02:00:26.740]   - That's a good way.
[02:00:26.740 --> 02:00:29.420]   It takes us back to that, like, what is it?
[02:00:29.420 --> 02:00:31.780]   That litmus test about,
[02:00:31.780 --> 02:00:33.780]   is your country allowed to have a gay pride parade?
[02:00:33.780 --> 02:00:34.620]   - Yeah.
[02:00:34.620 --> 02:00:35.940]   (laughing)
[02:00:35.940 --> 02:00:38.780]   - So there's like obvious things that might be on your mind
[02:00:38.780 --> 02:00:41.980]   that you just want to ask and you shouldn't run from them.
[02:00:41.980 --> 02:00:43.540]   - As long as you feel like you're a free person
[02:00:43.540 --> 02:00:46.100]   when you're interviewing, I think you're good.
[02:00:46.100 --> 02:00:47.880]   - That's beautifully put.
[02:00:47.880 --> 02:00:52.460]   Are there books, technical fiction, philosophical,
[02:00:52.460 --> 02:00:56.420]   that had an impact on your life that you would recommend?
[02:00:56.420 --> 02:00:59.980]   Or even resources like blogs, films?
[02:00:59.980 --> 02:01:03.180]   - I have four books I'll briefly mention.
[02:01:03.180 --> 02:01:05.660]   Number one is "The Fear."
[02:01:05.660 --> 02:01:07.700]   "The Fear" had a deep impact on me.
[02:01:07.700 --> 02:01:09.540]   "The Fear" was written by Peter Godwin.
[02:01:09.540 --> 02:01:12.580]   It's about the systematic dismantling of Zimbabwe
[02:01:12.580 --> 02:01:14.100]   under Robert Mugabe.
[02:01:14.100 --> 02:01:17.500]   Peter is Zimbabwean and it is a riveting book.
[02:01:17.500 --> 02:01:18.680]   I think everyone should read it
[02:01:18.680 --> 02:01:20.860]   because it helps you understand what it's like
[02:01:20.860 --> 02:01:22.700]   to go through not just authoritarianism
[02:01:22.700 --> 02:01:24.480]   but also hyperinflation.
[02:01:24.480 --> 02:01:26.940]   And I mean really, at the end of the day,
[02:01:26.940 --> 02:01:30.340]   what "The Fear" describes is how Mugabe took this country
[02:01:30.340 --> 02:01:33.740]   in the 1980s and he actually brought it back in time
[02:01:33.740 --> 02:01:36.460]   to the 1920s in terms of infrastructure,
[02:01:36.460 --> 02:01:38.540]   literacy rates, health rates, all these things.
[02:01:38.540 --> 02:01:40.520]   He stole so much from the people.
[02:01:40.520 --> 02:01:41.820]   And it's a heartbreaking book
[02:01:41.820 --> 02:01:43.320]   but it's a very important book.
[02:01:43.320 --> 02:01:49.260]   And it's a way to do excellent, excellent journalism.
[02:01:49.260 --> 02:01:51.060]   So "The Fear" is a good one.
[02:01:51.060 --> 02:01:52.660]   - And it's a personal story?
[02:01:52.660 --> 02:01:53.860]   - Absolutely, yeah.
[02:01:53.860 --> 02:01:57.020]   Because he was, it's part of his whole family story
[02:01:57.020 --> 02:02:00.380]   and he's in there, he's interviewing people personally.
[02:02:00.380 --> 02:02:02.300]   So I would say that one.
[02:02:02.300 --> 02:02:03.940]   - Is it also connected, sorry to interrupt.
[02:02:03.940 --> 02:02:06.420]   Is it, from the inflation perspective,
[02:02:06.420 --> 02:02:09.920]   is it a good study of hyperinflation and the effects?
[02:02:09.920 --> 02:02:12.220]   Does Bitcoin at all come as a,
[02:02:12.220 --> 02:02:15.660]   - No. - You know,
[02:02:15.660 --> 02:02:16.820]   a discussion of money?
[02:02:16.820 --> 02:02:18.340]   Does that come into the,
[02:02:18.340 --> 02:02:20.620]   or is it purely the experience of inflation
[02:02:20.620 --> 02:02:22.420]   as almost a symptom of an authoritarian government?
[02:02:22.420 --> 02:02:23.460]   - A little bit, a little bit.
[02:02:23.460 --> 02:02:24.460]   I would say it's not deep.
[02:02:24.460 --> 02:02:26.300]   I have another book on that which I'll recommend
[02:02:26.300 --> 02:02:28.540]   in a second but I would just say
[02:02:28.540 --> 02:02:32.080]   that it's a very powerfully written book
[02:02:32.080 --> 02:02:36.940]   about how society can basically deteriorate
[02:02:36.940 --> 02:02:38.540]   and how you can lose everything.
[02:02:38.540 --> 02:02:41.340]   The second book is, I just mentioned it,
[02:02:41.340 --> 02:02:43.660]   but "The Man Without a Face" by Masha Gessen.
[02:02:43.660 --> 02:02:46.100]   Incredible book about modern Russia and Putin.
[02:02:46.100 --> 02:02:47.660]   Just a masterpiece.
[02:02:47.660 --> 02:02:48.500]   So that one is--
[02:02:48.500 --> 02:02:49.820]   - Could be one of your favorite books
[02:02:49.820 --> 02:02:50.820]   about Putin and Russia?
[02:02:50.820 --> 02:02:51.780]   - That one's the best.
[02:02:51.780 --> 02:02:54.020]   I mean, she's just so fearless, incredible.
[02:02:54.020 --> 02:02:56.740]   She interviews Putin in the book at the end.
[02:02:56.740 --> 02:02:57.580]   It's really good.
[02:02:57.580 --> 02:03:02.940]   Third one is a fiction book called "The Mandibles"
[02:03:02.940 --> 02:03:04.820]   written by Lionel Shriver.
[02:03:04.820 --> 02:03:05.660]   This one's good.
[02:03:05.660 --> 02:03:06.480]   It's a good gift book.
[02:03:06.480 --> 02:03:08.020]   It's funny, it's dark, it's witty.
[02:03:08.020 --> 02:03:12.060]   But it's about the United States losing its status
[02:03:12.060 --> 02:03:14.940]   as the reserve currency and going into hyperinflation.
[02:03:14.940 --> 02:03:16.540]   And what's interesting is that the characters
[02:03:16.540 --> 02:03:19.240]   in the book map where we are today.
[02:03:19.240 --> 02:03:20.620]   The book itself is about the late,
[02:03:20.620 --> 02:03:22.520]   I think it's the late 2020s,
[02:03:22.520 --> 02:03:25.080]   and we have a populist president who decides
[02:03:25.080 --> 02:03:26.840]   to announce that the United States
[02:03:26.840 --> 02:03:28.960]   is basically gonna default on its debts,
[02:03:28.960 --> 02:03:31.980]   and the rest of the world comes up with a new currency,
[02:03:31.980 --> 02:03:33.500]   and everybody switches to that one,
[02:03:33.500 --> 02:03:36.040]   and the dollar overnight becomes worthless.
[02:03:36.040 --> 02:03:38.180]   And all these economists are saying,
[02:03:38.180 --> 02:03:41.640]   "No, it's fine, inflation won't be a problem."
[02:03:41.640 --> 02:03:44.780]   And there's this one character who's an economist,
[02:03:44.780 --> 02:03:47.220]   and he's basically, he gets to the point
[02:03:47.220 --> 02:03:48.620]   where he's living as a refugee
[02:03:48.620 --> 02:03:50.220]   in Prospect Park in Brooklyn,
[02:03:50.220 --> 02:03:52.360]   and he's still saying everything's fine.
[02:03:52.360 --> 02:03:54.140]   So it's dry, it's witty,
[02:03:54.140 --> 02:03:57.040]   but it's also about the surveillance state,
[02:03:57.040 --> 02:03:59.340]   it's about centralization of power.
[02:03:59.340 --> 02:04:00.300]   It's really good.
[02:04:00.300 --> 02:04:03.740]   So "The Mandibles" I would highly recommend.
[02:04:03.740 --> 02:04:06.660]   So those three books, and then on the topic of Bitcoin,
[02:04:06.660 --> 02:04:07.860]   because we talked about it a lot,
[02:04:07.860 --> 02:04:10.020]   I would just say that my portal into Bitcoin
[02:04:10.020 --> 02:04:13.140]   was "The Internet of Money" by Andreas Antonopoulos.
[02:04:13.140 --> 02:04:13.980]   - Oh, wow.
[02:04:13.980 --> 02:04:16.380]   - And I did it by audio book.
[02:04:16.380 --> 02:04:18.860]   And I just think this is an important one
[02:04:18.860 --> 02:04:20.340]   for people to start with,
[02:04:20.340 --> 02:04:23.300]   because he goes through all the main concepts,
[02:04:23.300 --> 02:04:24.820]   whether it be proof of work,
[02:04:24.820 --> 02:04:27.240]   or how the network functions.
[02:04:27.240 --> 02:04:30.060]   But he does it in a way that's extremely engaging,
[02:04:30.060 --> 02:04:31.580]   and really fascinating,
[02:04:31.580 --> 02:04:34.500]   and it really just sparked my curiosity.
[02:04:34.500 --> 02:04:37.180]   - Is it discussing the technical sides,
[02:04:37.180 --> 02:04:38.220]   or also the philosophical?
[02:04:38.220 --> 02:04:39.540]   Because a lot of people mentioned
[02:04:39.540 --> 02:04:41.780]   the Bitcoin standard as a philosophical entry
[02:04:41.780 --> 02:04:43.540]   into the whole Bitcoin world.
[02:04:43.540 --> 02:04:44.940]   - It's very different from the Bitcoin standard.
[02:04:44.940 --> 02:04:47.740]   It's more for the average person.
[02:04:47.740 --> 02:04:49.220]   It's not a history book.
[02:04:49.220 --> 02:04:50.420]   It's a collection of his talks
[02:04:50.420 --> 02:04:52.540]   that he gave over two or three years.
[02:04:52.540 --> 02:04:54.180]   It's not very technical.
[02:04:54.180 --> 02:04:55.700]   It's very approachable.
[02:04:55.700 --> 02:04:57.940]   And some of it might be dated now,
[02:04:57.940 --> 02:05:00.380]   'cause it's 2015, 2016.
[02:05:00.380 --> 02:05:01.220]   But I mean--
[02:05:01.220 --> 02:05:03.460]   - It's great to hear a shout out for Andreas,
[02:05:03.460 --> 02:05:06.540]   because he seems to be one of the seminal figures
[02:05:06.540 --> 02:05:10.380]   to make Bitcoin ideas accessible.
[02:05:10.380 --> 02:05:11.540]   - Andreas is the GOAT.
[02:05:11.540 --> 02:05:12.380]   - He's the GOAT.
[02:05:12.380 --> 02:05:13.500]   - Andreas is the GOAT.
[02:05:13.500 --> 02:05:14.340]   - Andreas is the GOAT.
[02:05:14.340 --> 02:05:15.540]   - I know a lot of people have issues
[02:05:15.540 --> 02:05:16.980]   with some of his more recent work,
[02:05:16.980 --> 02:05:18.460]   but Andreas is the GOAT.
[02:05:18.460 --> 02:05:21.100]   I mean, he's the reason I'm in Bitcoin.
[02:05:21.100 --> 02:05:23.020]   - Yeah, that's fascinating.
[02:05:23.020 --> 02:05:26.500]   And it's funny to watch the Bitcoin maximalist
[02:05:26.500 --> 02:05:30.300]   immune system also attacking him,
[02:05:30.300 --> 02:05:33.580]   and this whole feedback mechanism is working together.
[02:05:33.580 --> 02:05:34.420]   It's fascinating.
[02:05:34.420 --> 02:05:36.460]   - Well, I probably consider myself a maximalist,
[02:05:36.460 --> 02:05:38.540]   but I really like Andreas.
[02:05:38.540 --> 02:05:40.220]   So I think there's room for nuance.
[02:05:40.220 --> 02:05:42.100]   - There's room for nuance in this world.
[02:05:42.100 --> 02:05:43.820]   I'm glad to hear that.
[02:05:43.820 --> 02:05:46.580]   If people are fascinated by your work,
[02:05:46.580 --> 02:05:51.060]   what is the way to get more of Alex?
[02:05:51.060 --> 02:05:53.900]   - So two years ago, I came together
[02:05:53.900 --> 02:05:55.420]   with seven other people from around the world,
[02:05:55.420 --> 02:05:57.460]   and we wrote a book in a book sprint.
[02:05:57.460 --> 02:05:58.500]   We lived in a house for four days.
[02:05:58.500 --> 02:05:59.820]   We wrote a book together.
[02:05:59.820 --> 02:06:00.660]   It was really cool.
[02:06:00.660 --> 02:06:02.780]   It was like a design sprint, but we did it in book format.
[02:06:02.780 --> 02:06:07.540]   And my co-authors are from Nigeria, Venezuela,
[02:06:07.540 --> 02:06:10.780]   the Philippines, from former Soviet Union, from all over.
[02:06:10.780 --> 02:06:12.300]   And it's called "The Little Bitcoin Book,"
[02:06:12.300 --> 02:06:14.540]   and I'm still proud of it.
[02:06:14.540 --> 02:06:15.460]   It's 100 pages.
[02:06:15.460 --> 02:06:16.580]   It's something you give to somebody
[02:06:16.580 --> 02:06:18.460]   who knows nothing about the topic,
[02:06:18.460 --> 02:06:19.900]   and it's not a technical book.
[02:06:19.900 --> 02:06:23.940]   It's about the sort of social, political aspect of it,
[02:06:23.940 --> 02:06:26.220]   like why is it important for you, for your finances,
[02:06:26.220 --> 02:06:28.900]   for your freedom, for your future.
[02:06:28.900 --> 02:06:32.460]   And we've translated it into a lot of languages by now.
[02:06:32.460 --> 02:06:35.460]   I think English, Spanish, and Portuguese are for sale,
[02:06:35.460 --> 02:06:38.340]   and at littlebitcoinbook.com, you go buy it.
[02:06:38.340 --> 02:06:43.340]   But we've made it as a free PDF in Mandarin, Hindi, Punjab,
[02:06:43.340 --> 02:06:47.780]   Korean, Uyghur, which I was really excited about,
[02:06:47.780 --> 02:06:50.860]   Arabic, Farsi, and I mean, it spreads, man.
[02:06:50.860 --> 02:06:52.020]   It's been really, really cool.
[02:06:52.020 --> 02:06:53.220]   So I'm proud of that.
[02:06:53.220 --> 02:06:57.420]   I also made a video that did very well
[02:06:57.420 --> 02:06:58.900]   for Reason Magazine called
[02:06:58.900 --> 02:07:01.580]   "Why is Bitcoin Protecting Human Rights Around the World?"
[02:07:01.580 --> 02:07:04.300]   It's five minutes, and I feel like I tried to boil
[02:07:04.300 --> 02:07:07.060]   everything that I wanna tell you
[02:07:07.060 --> 02:07:08.840]   into this five-minute video.
[02:07:08.840 --> 02:07:11.420]   So there's that, would recommend that.
[02:07:11.420 --> 02:07:14.140]   And then if you're interested in the
[02:07:14.140 --> 02:07:17.420]   why have governments not stopped it,
[02:07:17.420 --> 02:07:18.900]   which I think is really intriguing,
[02:07:18.900 --> 02:07:21.860]   I wrote this long essay in Quillette in February called
[02:07:21.860 --> 02:07:26.020]   why haven't governments banned Bitcoin?
[02:07:26.020 --> 02:07:28.660]   And maybe that'll be a helpful guide to some folks.
[02:07:28.660 --> 02:07:30.420]   - Is it speaking to the Trojan horse idea
[02:07:30.420 --> 02:07:32.860]   that there's something enticing about it?
[02:07:32.860 --> 02:07:34.740]   - Yeah, at the end, it does get into that,
[02:07:34.740 --> 02:07:36.880]   but it really also just kinda goes through technically
[02:07:36.880 --> 02:07:39.020]   why is it hard to do a 51% attack?
[02:07:39.020 --> 02:07:41.580]   Like, if a government wanted to,
[02:07:41.580 --> 02:07:43.540]   could it really get all that equipment?
[02:07:43.540 --> 02:07:45.820]   There's a semiconductor shortage, like it can't.
[02:07:45.820 --> 02:07:47.020]   There's like certain things
[02:07:47.020 --> 02:07:49.140]   that stop governments from doing it, right?
[02:07:49.140 --> 02:07:51.780]   And same thing with like this idea of a 6102,
[02:07:51.780 --> 02:07:56.780]   which would be based on the idea of the executive order 6102,
[02:07:56.780 --> 02:07:59.100]   which is from 1933 when FDR
[02:07:59.100 --> 02:08:01.100]   made holding gold illegal in the United States.
[02:08:01.100 --> 02:08:03.300]   The idea is that like banks would go around now
[02:08:03.300 --> 02:08:05.580]   with governments and try to like steal everybody's Bitcoin.
[02:08:05.580 --> 02:08:08.420]   Well, in Bitcoin, we have like a practice
[02:08:08.420 --> 02:08:10.620]   called Proof of Keys Day every January 3rd,
[02:08:10.620 --> 02:08:14.140]   which is coinciding with the launch of the Bitcoin blockchain
[02:08:14.140 --> 02:08:16.300]   where we all like withdraw our keys from exchanges
[02:08:16.300 --> 02:08:17.720]   and we'd be sovereign users.
[02:08:17.720 --> 02:08:20.260]   What we are doing is we are preparing for a 6102 attack,
[02:08:20.260 --> 02:08:22.220]   which will one day probably come, right?
[02:08:22.220 --> 02:08:25.220]   So the essay just goes through all of the like
[02:08:25.220 --> 02:08:27.500]   possible attacks and it runs through like
[02:08:27.500 --> 02:08:28.500]   the ones that happened,
[02:08:28.500 --> 02:08:29.780]   like the Chinese and Indian governments,
[02:08:29.780 --> 02:08:31.380]   the two largest governments in the world,
[02:08:31.380 --> 02:08:34.540]   both tried to attack Bitcoin by banning their citizens
[02:08:34.540 --> 02:08:36.340]   from exchanging fiat for Bitcoin.
[02:08:36.340 --> 02:08:37.180]   It didn't work.
[02:08:37.180 --> 02:08:38.420]   Interest instead exploded.
[02:08:38.420 --> 02:08:40.380]   It's like the Barbra Streisand effect
[02:08:40.380 --> 02:08:44.820]   where by making something public
[02:08:44.820 --> 02:08:46.300]   and saying you shouldn't do X,
[02:08:46.300 --> 02:08:49.580]   it actually increases attention about X a lot more, right?
[02:08:49.580 --> 02:08:53.780]   So I think there's a lot of interesting game theory there
[02:08:53.780 --> 02:08:54.620]   that people would enjoy.
[02:08:54.620 --> 02:08:58.140]   - Do you think, are you seriously concerned
[02:08:58.140 --> 02:09:01.940]   about this kind of thing where the ideas of sovereignty
[02:09:01.940 --> 02:09:05.980]   that Bitcoin espouses would actually one day be tested?
[02:09:05.980 --> 02:09:09.060]   Do you have like a legitimate concern?
[02:09:09.060 --> 02:09:12.220]   'Cause you said like one day very well might.
[02:09:12.220 --> 02:09:14.500]   Do you think it might go down?
[02:09:14.500 --> 02:09:15.580]   - Yeah, well, first of all,
[02:09:15.580 --> 02:09:18.380]   Bitcoin has been attacked again many times.
[02:09:18.380 --> 02:09:20.500]   And we talk about the,
[02:09:20.500 --> 02:09:23.100]   you spoke about this with Nick Carter on your show,
[02:09:23.100 --> 02:09:26.780]   the sort of protocol wars or conflict or whatever, right?
[02:09:26.780 --> 02:09:29.620]   And Bitcoin almost died a whole bunch of times during that
[02:09:29.620 --> 02:09:30.780]   and ended up surviving.
[02:09:30.780 --> 02:09:33.620]   - Oh, wow, I didn't know how bad the block side war was.
[02:09:33.620 --> 02:09:35.460]   - Oh, it got really bad.
[02:09:35.460 --> 02:09:38.060]   It was sort of a very existential threat
[02:09:38.060 --> 02:09:39.660]   and Bitcoin survived.
[02:09:39.660 --> 02:09:42.500]   And that's why I'm so intrigued by it
[02:09:42.500 --> 02:09:46.420]   is that it basically survived an attack
[02:09:46.420 --> 02:09:48.180]   in an environment several years ago
[02:09:48.180 --> 02:09:50.900]   when Bitcoin was much more vulnerable than it is today.
[02:09:50.900 --> 02:09:53.020]   It survived an attack by a conglomeration
[02:09:53.020 --> 02:09:55.940]   of Chinese billionaires, Silicon Valley corporations,
[02:09:55.940 --> 02:09:59.300]   and a ton of people who owned the majority of the hash rate
[02:09:59.300 --> 02:10:00.860]   and all of this infrastructure.
[02:10:00.860 --> 02:10:02.900]   They had 83% of all the hash rate
[02:10:02.900 --> 02:10:04.700]   and they couldn't get what they wanted.
[02:10:04.700 --> 02:10:06.020]   And that was so intriguing to me.
[02:10:06.020 --> 02:10:08.260]   Like, why didn't it get killed?
[02:10:08.260 --> 02:10:10.580]   So as Nick said, I think you should read
[02:10:10.580 --> 02:10:12.900]   "The Block Size War," which is a book
[02:10:12.900 --> 02:10:14.940]   that you can get on Amazon by Jonathan Beer.
[02:10:14.940 --> 02:10:16.620]   Really good, kind of like,
[02:10:16.620 --> 02:10:20.660]   really important to understand the scaling conflict
[02:10:20.660 --> 02:10:22.060]   and the visions over,
[02:10:22.060 --> 02:10:24.300]   the different visions of what Bitcoin should be.
[02:10:24.300 --> 02:10:25.860]   And again, people like me believe
[02:10:25.860 --> 02:10:26.860]   it should be a freedom tool,
[02:10:26.860 --> 02:10:29.740]   not like a payments technology for retail.
[02:10:29.740 --> 02:10:32.260]   And I'm just, I'm glad it worked out the way it did
[02:10:32.260 --> 02:10:34.060]   'cause it almost didn't.
[02:10:34.060 --> 02:10:38.260]   - Do you think a human's civilization will destroy itself?
[02:10:38.260 --> 02:10:41.460]   So if we think about all the threats
[02:10:41.460 --> 02:10:45.900]   facing human civilization, nuclear war,
[02:10:45.900 --> 02:10:48.780]   natural or engineered pandemics,
[02:10:48.780 --> 02:10:51.900]   you know, we talk about human rights violations.
[02:10:51.900 --> 02:10:55.180]   We talk about authoritarian governments
[02:10:55.180 --> 02:10:58.540]   taking control of the money supply.
[02:10:58.540 --> 02:11:01.100]   But do you have grander concerns
[02:11:01.100 --> 02:11:02.980]   for the future of human civilization?
[02:11:02.980 --> 02:11:07.820]   Do you have hope for us becoming multi-planetary species?
[02:11:07.820 --> 02:11:09.780]   - Yeah, I mean, I guess long-term
[02:11:09.780 --> 02:11:11.540]   we'd wanna decentralize, right?
[02:11:11.540 --> 02:11:12.860]   We don't want a single point of failure.
[02:11:12.860 --> 02:11:14.100]   - In the physical space too.
[02:11:14.100 --> 02:11:16.540]   - The Earth is a single point of failure.
[02:11:16.540 --> 02:11:17.820]   But no, I mean, you look at all this
[02:11:17.820 --> 02:11:20.660]   kind of like space fiction and,
[02:11:20.660 --> 02:11:22.420]   I mean, who would wanna live on Mars, man?
[02:11:22.420 --> 02:11:23.700]   It's like a fricking desert.
[02:11:23.700 --> 02:11:24.900]   I mean, the Earth is so beautiful.
[02:11:24.900 --> 02:11:27.020]   I hope we can save it, you know?
[02:11:27.020 --> 02:11:28.460]   It's just so gorgeous.
[02:11:28.460 --> 02:11:30.140]   When you look at the Earth compared to any other
[02:11:30.140 --> 02:11:32.540]   like exoplanet or whatever, you look at it.
[02:11:32.540 --> 02:11:34.380]   I mean, the Earth is so spectacular
[02:11:34.380 --> 02:11:36.200]   and wondrous and singular.
[02:11:36.200 --> 02:11:39.540]   I think we've gotta do everything we can to save it here.
[02:11:39.540 --> 02:11:40.380]   - That's funny.
[02:11:40.380 --> 02:11:42.780]   I mean, I'm sure a lot of people
[02:11:42.780 --> 02:11:45.100]   would have said that about Europe
[02:11:45.100 --> 02:11:48.420]   before the explorers ventured out,
[02:11:48.420 --> 02:11:51.460]   Columbus and the rest out into the unknown.
[02:11:51.460 --> 02:11:54.580]   The thing about human nature is that we are explorers too.
[02:11:54.580 --> 02:11:55.420]   - We are, I agree.
[02:11:55.420 --> 02:11:58.420]   - Some small fraction of us are insane enough
[02:11:58.420 --> 02:12:01.820]   to explore in the most dangerous grounds.
[02:12:01.820 --> 02:12:03.780]   And I'm pretty sure there's quite a few people
[02:12:03.780 --> 02:12:06.780]   that would love to take the first step on Mars,
[02:12:06.780 --> 02:12:08.620]   the first few steps on Mars,
[02:12:08.620 --> 02:12:10.420]   in the harshest of environments,
[02:12:10.420 --> 02:12:13.980]   even when the odds of survival are extremely low.
[02:12:13.980 --> 02:12:16.780]   And I'm thankful for those people.
[02:12:16.780 --> 02:12:19.780]   As I sit back and drink my vodka back here on Earth
[02:12:19.780 --> 02:12:21.580]   and enjoy good friendships,
[02:12:21.580 --> 02:12:25.620]   because I think ultimately that step to Mars
[02:12:25.620 --> 02:12:29.940]   is going to be a first step into a multi,
[02:12:29.940 --> 02:12:33.980]   into exploring and colonizing the rest of the galaxy.
[02:12:33.980 --> 02:12:36.000]   Mars might be a harsh environment,
[02:12:36.000 --> 02:12:37.940]   but maybe space is not.
[02:12:37.940 --> 02:12:42.660]   Like other planets, other exoplanets,
[02:12:42.660 --> 02:12:44.420]   but also forget planets,
[02:12:44.420 --> 02:12:48.260]   just creating colonies that float about in space.
[02:12:48.260 --> 02:12:50.740]   There's exciting technologies that are yet to be discovered,
[02:12:50.740 --> 02:12:52.740]   yet to be engineered and built,
[02:12:52.740 --> 02:12:55.500]   that I think require that first painful step.
[02:12:55.500 --> 02:12:58.060]   Like, yeah, the journey of a thousand miles
[02:12:58.060 --> 02:12:58.900]   starts with one step.
[02:12:58.900 --> 02:13:00.700]   And I think Mars is that first step.
[02:13:00.700 --> 02:13:04.340]   - Yeah, no, I was born the day before the Challenger blew up
[02:13:04.340 --> 02:13:07.580]   and it was always so tragic for me to look back on that.
[02:13:07.580 --> 02:13:10.100]   'Cause that really like altered our arc
[02:13:10.100 --> 02:13:11.380]   in terms of space exploration.
[02:13:11.380 --> 02:13:13.020]   Like if that had not happened,
[02:13:13.020 --> 02:13:14.020]   we'd be in a very different arc.
[02:13:14.020 --> 02:13:17.500]   And I do respect and admire people pushing for exploration,
[02:13:17.500 --> 02:13:20.300]   but at the same time, I just, I want to recognize,
[02:13:20.300 --> 02:13:23.100]   like we just, you know, we know how unique Earth is.
[02:13:23.100 --> 02:13:27.660]   And I do think we got to do everything we can to protect.
[02:13:27.660 --> 02:13:31.620]   - But I think you avoid answering the question
[02:13:31.620 --> 02:13:33.900]   if we're going to destroy ourselves.
[02:13:33.900 --> 02:13:35.860]   - Oh, yeah, yeah, I guess.
[02:13:35.860 --> 02:13:36.700]   - Are you hopeful?
[02:13:36.700 --> 02:13:38.060]   - If we do not, okay, fine.
[02:13:38.060 --> 02:13:40.460]   If we do not decentralize properly
[02:13:40.460 --> 02:13:45.460]   out into different physical spaces, probably, I guess, yeah.
[02:13:45.460 --> 02:13:47.860]   - And then, I mean, do you have concerns
[02:13:47.860 --> 02:13:49.180]   that are immediately facing you?
[02:13:49.180 --> 02:13:53.860]   So not in terms of the injustices on the world,
[02:13:53.860 --> 02:13:55.180]   but nuclear war?
[02:13:55.180 --> 02:13:57.180]   - Yeah, look, I'm a lot more concerned
[02:13:57.180 --> 02:13:58.820]   about what's happening right now.
[02:13:58.820 --> 02:14:01.740]   Like what is destroying ourselves?
[02:14:01.740 --> 02:14:03.940]   If you were to go and see what's happening
[02:14:03.940 --> 02:14:07.460]   in Xinjiang or North Korea right now, or Eritrea,
[02:14:07.460 --> 02:14:10.340]   that is destroying ourselves and it's already happened.
[02:14:10.340 --> 02:14:13.140]   So I guess that's why I said, yes.
[02:14:13.140 --> 02:14:14.780]   I mean, if you don't decentralize
[02:14:14.780 --> 02:14:18.380]   and power is completely under one person,
[02:14:18.380 --> 02:14:20.700]   life is destroyed as we know it.
[02:14:20.700 --> 02:14:23.980]   And you don't have to go into science fiction
[02:14:23.980 --> 02:14:28.180]   to know what a totalitarian hellscape dystopia is.
[02:14:28.180 --> 02:14:29.740]   There's several that exist already.
[02:14:29.740 --> 02:14:33.060]   And let's try to help those people
[02:14:33.060 --> 02:14:36.180]   at the same time as we're trying to push out into space
[02:14:36.180 --> 02:14:38.060]   would be my counter, I guess.
[02:14:38.060 --> 02:14:39.180]   - Yeah, I agree with you.
[02:14:39.180 --> 02:14:41.900]   In my mind, destruction and suffering
[02:14:41.900 --> 02:14:43.180]   are next door neighbors.
[02:14:43.180 --> 02:14:46.220]   So we don't need to destroy all of human civilization
[02:14:46.220 --> 02:14:50.340]   if a large fraction of it lives in conditions
[02:14:50.340 --> 02:14:51.760]   that we would equate to suffering.
[02:14:51.760 --> 02:14:54.140]   That's not a good world.
[02:14:54.140 --> 02:14:59.980]   Is there advice that you would give to young people today
[02:14:59.980 --> 02:15:03.300]   about life, about career, about how they can help a world
[02:15:03.300 --> 02:15:08.300]   where 53% are living under authoritarian governments?
[02:15:09.300 --> 02:15:12.300]   But in general, a world that's full of injustice,
[02:15:12.300 --> 02:15:13.920]   but also full of opportunity.
[02:15:13.920 --> 02:15:16.980]   - Just thinking about my own upbringing,
[02:15:16.980 --> 02:15:18.500]   I went to a public school here
[02:15:18.500 --> 02:15:21.420]   and we never learned about money.
[02:15:21.420 --> 02:15:23.220]   It was never part of our curriculum.
[02:15:23.220 --> 02:15:27.700]   Even personal finances was not part of our curriculum.
[02:15:27.700 --> 02:15:28.980]   You could take like an optional course
[02:15:28.980 --> 02:15:31.820]   to learn about like business or something.
[02:15:31.820 --> 02:15:33.940]   And I think that that would be really valuable
[02:15:33.940 --> 02:15:37.060]   as a young person or as a teenager
[02:15:37.060 --> 02:15:40.660]   to start incorporating into your children's lives
[02:15:40.660 --> 02:15:43.100]   is like a curiosity about what is money.
[02:15:43.100 --> 02:15:44.460]   I think it'd be very healthy,
[02:15:44.460 --> 02:15:47.300]   regardless of what path that takes them down.
[02:15:47.300 --> 02:15:48.940]   Because we don't think about it enough,
[02:15:48.940 --> 02:15:51.340]   either from an administrative sort of personal finance thing
[02:15:51.340 --> 02:15:52.940]   about like responsibility,
[02:15:52.940 --> 02:15:57.420]   or more fundamentally, like what is it and who creates it?
[02:15:57.420 --> 02:15:58.780]   Where did it come from?
[02:15:58.780 --> 02:16:00.180]   Both of those things are very important.
[02:16:00.180 --> 02:16:01.780]   So my advice to a young person would be
[02:16:01.780 --> 02:16:03.540]   to get to the point where you feel like
[02:16:03.540 --> 02:16:06.120]   you can answer the question, what is money?
[02:16:06.120 --> 02:16:07.520]   (laughing)
[02:16:07.520 --> 02:16:10.000]   - So you ultimately see money as a kind of power
[02:16:10.000 --> 02:16:13.520]   and freedom and a mechanism of self-reliance.
[02:16:13.520 --> 02:16:15.400]   - It is so core to everything.
[02:16:15.400 --> 02:16:17.800]   The United States, whether you wanna call it
[02:16:17.800 --> 02:16:20.880]   the Pax Americana, the empire, the hyper power,
[02:16:20.880 --> 02:16:22.840]   whatever you wanna call this moment in time
[02:16:22.840 --> 02:16:24.280]   where the US is dominant around the world,
[02:16:24.280 --> 02:16:26.680]   it is because of the fact that we have
[02:16:26.680 --> 02:16:30.640]   this petrodollar system where we are able to force
[02:16:30.640 --> 02:16:33.200]   the Saudis and other oil producing nations
[02:16:33.200 --> 02:16:36.120]   to sell their oil in dollars.
[02:16:36.120 --> 02:16:39.920]   That is really inescapable, inseparable from our power.
[02:16:39.920 --> 02:16:42.260]   And that's very rarely talked about.
[02:16:42.260 --> 02:16:44.060]   And it's very important to understand.
[02:16:44.060 --> 02:16:46.200]   So yeah, if young people could start thinking
[02:16:46.200 --> 02:16:48.040]   about that stuff, it'd be good.
[02:16:48.040 --> 02:16:50.320]   - I remember being, it sounds silly to say,
[02:16:50.320 --> 02:16:52.780]   but I remember being really uncomfortable
[02:16:52.780 --> 02:16:56.560]   that I was dependent on my parents at a young age
[02:16:56.560 --> 02:16:58.800]   for like financial--
[02:16:58.800 --> 02:17:00.640]   - Oh, you need to be 18 to have a bank account or whatever.
[02:17:00.640 --> 02:17:01.480]   - Right.
[02:17:01.480 --> 02:17:03.440]   - And one of the people that we supported at Ahrefs
[02:17:03.440 --> 02:17:05.600]   through our, we do software development funding
[02:17:05.600 --> 02:17:07.800]   for people in Bitcoin, open source projects.
[02:17:07.800 --> 02:17:09.360]   And he's one of the guys we funded
[02:17:09.360 --> 02:17:11.880]   is this very young, smart sort of prodigy.
[02:17:11.880 --> 02:17:13.320]   He's like 17.
[02:17:13.320 --> 02:17:14.640]   But one of the reasons he got into Bitcoin
[02:17:14.640 --> 02:17:16.640]   was 'cause he wanted to have control of his money
[02:17:16.640 --> 02:17:18.120]   when he was like 14.
[02:17:18.120 --> 02:17:19.080]   I mean, if you think in history,
[02:17:19.080 --> 02:17:23.080]   people who invented all kinds of incredible contributions
[02:17:23.080 --> 02:17:25.600]   to science or math, I mean, a lot of them did it
[02:17:25.600 --> 02:17:27.500]   before they were 15.
[02:17:27.500 --> 02:17:30.520]   So think about that maturity that is capable
[02:17:30.520 --> 02:17:31.600]   and possible in many people.
[02:17:31.600 --> 02:17:34.360]   Like I've participated in some of the, years ago,
[02:17:34.360 --> 02:17:36.880]   some of the sort of selection processes
[02:17:36.880 --> 02:17:39.000]   for like the Thiel Fellowship, which is like really amazing.
[02:17:39.000 --> 02:17:41.320]   Like these people who are 14, 15, 16,
[02:17:41.320 --> 02:17:42.280]   who don't need to go to college.
[02:17:42.280 --> 02:17:44.400]   They're already like so smart, they can figure it out.
[02:17:44.400 --> 02:17:46.360]   But they wouldn't be allowed to have a bank account, right?
[02:17:46.360 --> 02:17:48.480]   So, hey, that's kind of cool.
[02:17:48.480 --> 02:17:50.040]   Like now you have a permissionless money.
[02:17:50.040 --> 02:17:51.440]   You can open up yourself
[02:17:51.440 --> 02:17:53.280]   without permission from your parents.
[02:17:53.280 --> 02:17:54.100]   That's kind of cool.
[02:17:54.100 --> 02:17:55.240]   - Yeah, that's fascinating to me.
[02:17:55.240 --> 02:18:00.240]   I feel like I would have loved my parents more
[02:18:01.240 --> 02:18:03.040]   - If you had a little more separation.
[02:18:03.040 --> 02:18:06.200]   - If I had freedom to fully realize myself,
[02:18:06.200 --> 02:18:08.840]   because I felt like I was a little bit trapped by,
[02:18:08.840 --> 02:18:11.560]   I don't know, it's not explicit, right?
[02:18:11.560 --> 02:18:15.480]   It's a little bit, it's like a subtle push
[02:18:15.480 --> 02:18:17.480]   that you're somehow dependent on them.
[02:18:17.480 --> 02:18:19.060]   I mean, part of that is like,
[02:18:19.060 --> 02:18:22.160]   I think it actually very much has to do
[02:18:22.160 --> 02:18:23.220]   not talking about money.
[02:18:23.220 --> 02:18:24.880]   Like what does it take to operate
[02:18:24.880 --> 02:18:26.600]   as an individual entity in this world?
[02:18:26.600 --> 02:18:28.880]   Like knowing that when you're 10 years old,
[02:18:28.880 --> 02:18:31.040]   knowing that when you're very young,
[02:18:31.040 --> 02:18:36.040]   so that you've, then you see how amazing it is
[02:18:36.040 --> 02:18:40.120]   to have the support of your parents until you're 18.
[02:18:40.120 --> 02:18:41.560]   Like have that freedom.
[02:18:41.560 --> 02:18:47.340]   Have the freedom to appreciate the value your parents bring,
[02:18:47.340 --> 02:18:51.600]   and at the same time, the freedom to leave
[02:18:51.600 --> 02:18:56.080]   in some capacity to carve your own path.
[02:18:56.080 --> 02:18:58.040]   I mean, just all of that, I think,
[02:18:58.040 --> 02:19:00.120]   for weirdos like me, especially,
[02:19:00.120 --> 02:19:02.960]   'cause that was a very non-traditional path
[02:19:02.960 --> 02:19:06.120]   that I think it would be very empowering,
[02:19:06.120 --> 02:19:07.960]   and certainly would be empowering in the third world.
[02:19:07.960 --> 02:19:10.200]   - Not just weirdos like you, I was gonna mention.
[02:19:10.200 --> 02:19:13.440]   One of the people I got who taught me about Bitcoin,
[02:19:13.440 --> 02:19:14.600]   her name is Roya Mahboob.
[02:19:14.600 --> 02:19:17.200]   She's an Afghan technology CEO.
[02:19:17.200 --> 02:19:20.720]   And in 2013, she started paying her employees in Bitcoin
[02:19:20.720 --> 02:19:23.760]   because they were not allowed to open bank accounts,
[02:19:23.760 --> 02:19:24.740]   the women that worked for her.
[02:19:24.740 --> 02:19:27.280]   She started the country's first female,
[02:19:27.280 --> 02:19:29.200]   all-female software company.
[02:19:29.200 --> 02:19:31.400]   And if they brought cash home,
[02:19:31.400 --> 02:19:32.960]   their husbands or uncles or brothers
[02:19:32.960 --> 02:19:33.800]   would steal it from them.
[02:19:33.800 --> 02:19:36.840]   There's a power, patriarchal dominance thing going on.
[02:19:36.840 --> 02:19:40.200]   But they had phones, and she was able to pay them in Bitcoin
[02:19:40.200 --> 02:19:42.640]   and no one knew, and it gave them that power.
[02:19:42.640 --> 02:19:44.280]   And that's always stuck in my mind
[02:19:44.280 --> 02:19:47.280]   as a very interesting effect of this kind of thing,
[02:19:47.280 --> 02:19:49.000]   of permissionless money,
[02:19:49.000 --> 02:19:52.040]   that it can be an empowerment tool, so absolutely.
[02:19:52.040 --> 02:19:53.800]   - So in your own personal life,
[02:19:53.800 --> 02:19:58.520]   where did the deep concern
[02:19:58.520 --> 02:20:01.400]   for the suffering in the world come from?
[02:20:01.400 --> 02:20:03.720]   Where was that born?
[02:20:03.720 --> 02:20:07.040]   - I was gonna be an engineer actually,
[02:20:07.040 --> 02:20:09.440]   and then in 2003, we invaded Iraq,
[02:20:09.440 --> 02:20:12.640]   and I got very interested in why we did that as a nation.
[02:20:12.640 --> 02:20:15.240]   And I switched my focus of study
[02:20:15.240 --> 02:20:17.000]   to like international relations,
[02:20:17.000 --> 02:20:19.120]   and that's how I kind of went down
[02:20:19.120 --> 02:20:22.120]   the kind of political science, democracy rabbit hole,
[02:20:22.120 --> 02:20:24.880]   and ended up getting a job at the Human Rights Foundation.
[02:20:24.880 --> 02:20:28.560]   So I'm very much a child of like 9/11 and the Iraq War.
[02:20:28.560 --> 02:20:32.480]   Those are the two really formative events for me personally.
[02:20:32.480 --> 02:20:33.760]   - Can you break that apart a little bit?
[02:20:33.760 --> 02:20:36.520]   Like what illusion about this world
[02:20:36.520 --> 02:20:41.520]   was broken apart by the invasion of Iraq?
[02:20:41.520 --> 02:20:45.720]   - Well, I think first of all, 9/11
[02:20:45.720 --> 02:20:48.160]   just shifted the world dynamics completely
[02:20:48.160 --> 02:20:50.840]   from a focus on big power politics
[02:20:50.840 --> 02:20:52.240]   between the US, Russia, and China
[02:20:52.240 --> 02:20:55.000]   to this new threat of Islamic terror.
[02:20:55.000 --> 02:20:58.300]   And a lot of it, we learned later,
[02:20:58.300 --> 02:21:00.920]   a lot of the things we did were manufactured, choreographed.
[02:21:00.920 --> 02:21:03.320]   Like there were no WMDs in Iraq.
[02:21:03.320 --> 02:21:05.640]   Like the reason our rulers said we needed to invade
[02:21:05.640 --> 02:21:07.400]   and destroy this country was a lie.
[02:21:07.400 --> 02:21:10.760]   And that I think has really been forgotten.
[02:21:10.760 --> 02:21:13.400]   Like I think a lot of like the Zoomers like today
[02:21:13.400 --> 02:21:15.640]   don't really know a lot about that time period.
[02:21:15.640 --> 02:21:16.880]   I mean, it was pretty crazy.
[02:21:16.880 --> 02:21:20.160]   Unanimously, I mean, Democrat, Republican,
[02:21:20.160 --> 02:21:23.040]   like Joe Biden, Hillary Clinton, like,
[02:21:23.040 --> 02:21:25.640]   and the Republicans, everybody wanted to invade this country
[02:21:25.640 --> 02:21:30.020]   and it was very, it's very, it's a confusing time.
[02:21:30.020 --> 02:21:32.600]   There's a really good book by Ian McEwen called "Saturday,"
[02:21:32.600 --> 02:21:35.760]   a fiction book that takes place during, I think, 2003.
[02:21:35.760 --> 02:21:39.120]   And it's one day in the life of the doctor in London.
[02:21:39.120 --> 02:21:41.200]   It's really good though to revisit this time
[02:21:41.200 --> 02:21:43.560]   because he has two characters,
[02:21:43.560 --> 02:21:44.760]   he has characters in the book,
[02:21:44.760 --> 02:21:46.040]   one of whom is very pro-war
[02:21:46.040 --> 02:21:47.640]   and one of them is very against war.
[02:21:47.640 --> 02:21:49.920]   Basically, he, the father himself is pro-war
[02:21:49.920 --> 02:21:52.040]   and his son is against it and they have all these debates.
[02:21:52.040 --> 02:21:53.560]   And it's nice to go back to revisit,
[02:21:53.560 --> 02:21:55.880]   but that time was, it's really crazy.
[02:21:55.880 --> 02:21:58.480]   And it really showed you that like the media
[02:21:58.480 --> 02:22:01.720]   could be captured into like helping promote this idea
[02:22:01.720 --> 02:22:03.720]   of like invading another country.
[02:22:03.720 --> 02:22:05.920]   So I was very curious about why we did it
[02:22:05.920 --> 02:22:07.720]   and like who was pulling the strings
[02:22:07.720 --> 02:22:09.960]   and what are the reasons that we went?
[02:22:09.960 --> 02:22:12.200]   And what's really interesting is that like
[02:22:12.200 --> 02:22:13.400]   I took all these courses on it,
[02:22:13.400 --> 02:22:15.760]   interviewed all these decision makers,
[02:22:15.760 --> 02:22:17.600]   whether they were like neocons or whatever,
[02:22:17.600 --> 02:22:19.320]   different people who were involved.
[02:22:19.320 --> 02:22:22.520]   And the whole like dollar reserve currency thing
[02:22:22.520 --> 02:22:24.400]   like really never came up until like,
[02:22:24.400 --> 02:22:27.200]   I learned about it more recently because of Bitcoin.
[02:22:27.200 --> 02:22:29.520]   And today, when I look back, it seems kind of obvious
[02:22:29.520 --> 02:22:31.040]   that the reason we invaded Iraq
[02:22:31.040 --> 02:22:35.080]   was because Saddam Hussein wanted to sell oil in euros.
[02:22:35.080 --> 02:22:36.640]   It seems really obvious when you go back
[02:22:36.640 --> 02:22:38.480]   and look at the chronology of it.
[02:22:38.480 --> 02:22:40.320]   And we were like, no, we actually don't want you
[02:22:40.320 --> 02:22:41.800]   to sell dollars in euros
[02:22:41.800 --> 02:22:43.480]   because that would threaten the dollar.
[02:22:43.480 --> 02:22:45.360]   So we're gonna invade you and then you're not gonna do it
[02:22:45.360 --> 02:22:47.800]   and no one else is gonna like sell dollars in euro,
[02:22:47.800 --> 02:22:49.000]   oil in euros, right?
[02:22:49.000 --> 02:22:51.720]   I guess you could say the same thing about Gaddafi,
[02:22:51.720 --> 02:22:55.680]   but we as a nation have very much protected
[02:22:55.680 --> 02:22:57.720]   our reserve currency, let's put it that way.
[02:22:57.720 --> 02:22:59.800]   - Yeah, actually one of the things that Bitcoin community
[02:22:59.800 --> 02:23:03.320]   has motivated me to do is to look back to the histories
[02:23:03.320 --> 02:23:07.240]   that I have studied myself from just even the two world wars,
[02:23:07.240 --> 02:23:09.960]   the history of the 20th century from a perspective
[02:23:09.960 --> 02:23:13.120]   of the monetary system of money.
[02:23:13.120 --> 02:23:14.600]   And it's interesting.
[02:23:14.600 --> 02:23:16.320]   It's interesting to look at human history
[02:23:16.320 --> 02:23:17.480]   in the context of money.
[02:23:17.480 --> 02:23:19.920]   - Can't we be patriotic and be pro-America,
[02:23:19.920 --> 02:23:21.840]   but like not want the petrodollar?
[02:23:21.840 --> 02:23:24.000]   Like I should be proud of my country.
[02:23:24.000 --> 02:23:26.080]   Why do we need to be propping up the Saudis?
[02:23:26.080 --> 02:23:29.560]   Why do we need to be threatening to invade other countries
[02:23:29.560 --> 02:23:31.600]   if they sell their oil for a different currency?
[02:23:31.600 --> 02:23:33.800]   I think we can be just as powerful as we are today,
[02:23:33.800 --> 02:23:36.040]   if not more powerful in a Bitcoin world.
[02:23:36.040 --> 02:23:37.880]   If you think about the infrastructure Americans
[02:23:37.880 --> 02:23:39.320]   are building, all the innovations we're building,
[02:23:39.320 --> 02:23:41.920]   all the wealth we have, I think we'll be fine,
[02:23:41.920 --> 02:23:42.840]   better than fine.
[02:23:42.840 --> 02:23:45.720]   And we won't have these horrible negative externalities.
[02:23:45.720 --> 02:23:49.760]   It's really an optimistic vision for the future.
[02:23:49.760 --> 02:23:51.840]   - I thought we learned the lesson of 9/11
[02:23:51.840 --> 02:23:54.420]   and the invasion of Iraq and Afghanistan.
[02:23:54.420 --> 02:23:57.280]   But maybe-- - We're leaving,
[02:23:57.280 --> 02:24:00.160]   and Biden announced we're leaving Afghanistan this year.
[02:24:00.160 --> 02:24:02.400]   20 years, for what?
[02:24:02.400 --> 02:24:03.720]   Taliban are gonna take over again.
[02:24:03.720 --> 02:24:05.680]   - I mean, that's like at least a good,
[02:24:05.680 --> 02:24:08.320]   this is the longest war, right?
[02:24:08.320 --> 02:24:09.680]   - The forever wars.
[02:24:09.680 --> 02:24:12.000]   - I feel like the past 20 years or whatever,
[02:24:12.000 --> 02:24:15.560]   it is 18 years, 19 years,
[02:24:15.560 --> 02:24:19.840]   we've been very skeptical about invading other countries.
[02:24:19.840 --> 02:24:25.600]   We've been skeptical about military intervention
[02:24:25.600 --> 02:24:26.760]   in other nations.
[02:24:26.760 --> 02:24:30.320]   - Well, our leaders certainly haven't.
[02:24:30.320 --> 02:24:32.760]   We're at, what do we have, like seven active wars right now?
[02:24:32.760 --> 02:24:34.960]   And neither the Russians and the Chinese,
[02:24:34.960 --> 02:24:37.920]   everybody's starting to invade everybody else.
[02:24:37.920 --> 02:24:40.080]   - I mean, so yes, but I meant to a degree
[02:24:40.080 --> 02:24:42.160]   that I was worried about like conflicts
[02:24:42.160 --> 02:24:46.400]   with hot conflicts with Iran, with North Korea,
[02:24:46.400 --> 02:24:47.720]   those kinds of things.
[02:24:47.720 --> 02:24:52.240]   That there was not as much warmongering
[02:24:52.240 --> 02:24:54.520]   as I was afraid about.
[02:24:54.520 --> 02:24:55.880]   But yes, you're absolutely right.
[02:24:55.880 --> 02:24:59.440]   We're still, there's a big presence by the United States
[02:24:59.440 --> 02:25:03.080]   and other nations and across the world, that's military.
[02:25:03.080 --> 02:25:06.000]   The military-industrial complex is a thing
[02:25:06.880 --> 02:25:11.120]   that has huge detrimental ripple effects
[02:25:11.120 --> 02:25:14.160]   throughout the entirety of our governments.
[02:25:14.160 --> 02:25:17.000]   - Yeah, so the big question is how do we prevent the rise
[02:25:17.000 --> 02:25:22.000]   of this like authoritarian surveillance state in China
[02:25:22.000 --> 02:25:24.800]   while at the same time kind of diffusing
[02:25:24.800 --> 02:25:27.000]   the military-industrial complex on our side?
[02:25:27.000 --> 02:25:29.800]   That to me is like the biggest challenge of our time.
[02:25:29.800 --> 02:25:32.440]   I don't have the answer, but we should keep digging.
[02:25:32.440 --> 02:25:36.640]   - Yeah, I believe there's technological innovations.
[02:25:36.640 --> 02:25:38.080]   You're suggesting that perhaps
[02:25:38.080 --> 02:25:41.120]   one of the technological innovations like is Bitcoin.
[02:25:41.120 --> 02:25:42.240]   - Bitcoin's a big part of it, yeah.
[02:25:42.240 --> 02:25:44.600]   - On the money side, I think the information side,
[02:25:44.600 --> 02:25:48.320]   there's innovations that are open, that's possible.
[02:25:48.320 --> 02:25:51.560]   And the political side, I'm the most skeptical about.
[02:25:51.560 --> 02:25:54.440]   I just feel like there's without hot wars
[02:25:54.440 --> 02:25:57.360]   that we don't seem to make any kind of progress.
[02:25:57.360 --> 02:26:01.200]   Bureaucracies just grow, corruption and greed grow,
[02:26:01.200 --> 02:26:05.760]   and human nature does not do well in the political arena.
[02:26:05.760 --> 02:26:09.520]   So I hope technology can outpace
[02:26:09.520 --> 02:26:11.200]   the darker sides of human nature.
[02:26:11.200 --> 02:26:14.840]   So you're busy fighting the demons,
[02:26:14.840 --> 02:26:16.200]   the darkness that's out there,
[02:26:16.200 --> 02:26:19.040]   but looking in the mirror, you're a finite being.
[02:26:19.040 --> 02:26:22.140]   Unfortunately, this ride ends for you pretty soon.
[02:26:22.140 --> 02:26:28.440]   Do you ever ask yourself about the meaning of it all,
[02:26:28.440 --> 02:26:32.480]   of why the hell us descendants of apes
[02:26:32.480 --> 02:26:34.120]   are even on this thing,
[02:26:34.120 --> 02:26:36.840]   striving so hard to make a better world for ourselves?
[02:26:36.840 --> 02:26:41.720]   - I don't often Zoom out that much.
[02:26:41.720 --> 02:26:44.640]   I feel like my day job is pretty interesting.
[02:26:44.640 --> 02:26:46.000]   It keeps me very engaged
[02:26:46.000 --> 02:26:49.600]   with all the stuff we've been talking about.
[02:26:49.600 --> 02:26:53.840]   As far as the meaning of life though,
[02:26:53.840 --> 02:26:58.840]   it seems quite clear that we do have the possibility
[02:26:58.840 --> 02:27:03.320]   as a species to create these beautiful communities
[02:27:03.320 --> 02:27:06.440]   and constructs and to share an exploration
[02:27:06.440 --> 02:27:07.720]   of the world together
[02:27:07.720 --> 02:27:13.760]   that is often marred by cold realities that we've discussed.
[02:27:13.760 --> 02:27:17.780]   But I do feel like in a way
[02:27:17.780 --> 02:27:20.580]   that the meaning of life is that pursuit.
[02:27:20.580 --> 02:27:25.280]   Of course, biologically is the spread, our species, right?
[02:27:25.280 --> 02:27:30.280]   But also to pursue knowledge and science and innovation
[02:27:30.280 --> 02:27:32.960]   and freedom, most importantly.
[02:27:32.960 --> 02:27:35.280]   I mean, I think it freedom has to guide us
[02:27:35.280 --> 02:27:37.800]   or else we end up with prison camps.
[02:27:37.800 --> 02:27:39.360]   If we don't let freedom guide us,
[02:27:39.360 --> 02:27:40.840]   we end up with the prison camps.
[02:27:40.840 --> 02:27:43.560]   So we need to have scientific innovation and adventurism
[02:27:43.560 --> 02:27:45.920]   and colonization of the stars,
[02:27:45.920 --> 02:27:48.520]   but without the slavery and without the prison camps.
[02:27:48.520 --> 02:27:50.080]   I think that's so key.
[02:27:50.080 --> 02:27:53.320]   - There's something about the creation of beauty
[02:27:53.320 --> 02:27:55.120]   that seems fundamental to human nature.
[02:27:55.120 --> 02:28:00.120]   And what seems beautiful is these communities
[02:28:00.160 --> 02:28:05.160]   that don't have suffering, they don't have injustice.
[02:28:05.160 --> 02:28:09.560]   And we have some kind of inner sense of what is injustice.
[02:28:09.560 --> 02:28:11.080]   I don't know, like some of the human rights
[02:28:11.080 --> 02:28:12.640]   that you've mentioned earlier,
[02:28:12.640 --> 02:28:16.720]   they're just philosophical constructs,
[02:28:16.720 --> 02:28:19.880]   but there also seem to be somehow deeply in us too.
[02:28:19.880 --> 02:28:24.240]   We have a sense of what is right and what is wrong.
[02:28:24.240 --> 02:28:28.000]   It's not just a kind of illusion we've all agreed on.
[02:28:28.000 --> 02:28:31.600]   - Arbitrary power, torture, executions.
[02:28:31.600 --> 02:28:32.800]   We know these things are wrong.
[02:28:32.800 --> 02:28:34.440]   I mean, we know they're wrong.
[02:28:34.440 --> 02:28:36.540]   We don't have to read a book to know that.
[02:28:36.540 --> 02:28:41.860]   But you do need to, people can get brainwashed.
[02:28:41.860 --> 02:28:43.840]   I mean, you talk to people who've grown up in North Korea,
[02:28:43.840 --> 02:28:45.840]   they don't know any better.
[02:28:45.840 --> 02:28:48.600]   Like they don't know what's going on in the outside world.
[02:28:48.600 --> 02:28:51.120]   So they've never experienced anything differently.
[02:28:51.120 --> 02:28:54.960]   So that's why, look, technology can play a big role here
[02:28:54.960 --> 02:28:56.400]   in terms of like the meaning of it all.
[02:28:56.400 --> 02:28:59.200]   Like it can really help emancipate, liberate people,
[02:28:59.200 --> 02:29:01.340]   at least so that they can make their own choices
[02:29:01.340 --> 02:29:02.480]   about what to do,
[02:29:02.480 --> 02:29:04.280]   at least so that we're on a level playing field.
[02:29:04.280 --> 02:29:07.200]   So technologies like the internet and Bitcoin,
[02:29:07.200 --> 02:29:09.840]   they can at least like give you the option
[02:29:09.840 --> 02:29:12.560]   to do things your own way on your own terms.
[02:29:12.560 --> 02:29:15.640]   And then from there we'll see.
[02:29:15.640 --> 02:29:19.160]   I think it's important that we have design choices
[02:29:19.160 --> 02:29:22.960]   where we can like have a little more say
[02:29:22.960 --> 02:29:26.080]   and not everything be pre-programmed for us.
[02:29:26.080 --> 02:29:28.400]   That would be very disappointing.
[02:29:28.400 --> 02:29:32.240]   So I mean, the open web and encryption and Bitcoin,
[02:29:32.240 --> 02:29:35.720]   these are things that help prevent social engineering
[02:29:35.720 --> 02:29:39.520]   and that promote more freedom and more possibilities,
[02:29:39.520 --> 02:29:42.440]   honestly, and more entrepreneurship and more creativity
[02:29:42.440 --> 02:29:44.040]   and more scientific inquiry.
[02:29:44.040 --> 02:29:45.800]   I mean, think about the people who tried to shut down
[02:29:45.800 --> 02:29:49.200]   scientific inquiry 500, 600 years ago or whatever,
[02:29:49.200 --> 02:29:50.440]   that were trying to say,
[02:29:50.440 --> 02:29:55.400]   the earth was the center of everything and they were wrong.
[02:29:55.400 --> 02:29:58.320]   And then all these conservative religious types
[02:29:58.320 --> 02:30:00.320]   throughout history have always said that
[02:30:00.320 --> 02:30:02.960]   there's no value in science
[02:30:02.960 --> 02:30:04.480]   and there's no value in technology
[02:30:04.480 --> 02:30:05.840]   and they've been wrong the whole time.
[02:30:05.840 --> 02:30:07.840]   So let's continue pushing here.
[02:30:07.840 --> 02:30:09.800]   Let's continue pushing.
[02:30:09.800 --> 02:30:11.760]   - It's kind of scary to me sometimes,
[02:30:11.760 --> 02:30:15.240]   humbling, beautiful, but also scary to think of.
[02:30:15.240 --> 02:30:17.440]   You mentioned North Korea,
[02:30:17.440 --> 02:30:19.480]   people are kind of living in ignorance.
[02:30:19.480 --> 02:30:22.880]   It's scary to me to think about how much ignorance
[02:30:22.880 --> 02:30:23.920]   there is in the world today.
[02:30:23.920 --> 02:30:26.120]   Like how little I know personally,
[02:30:26.120 --> 02:30:28.760]   or us as a human civilization knows
[02:30:28.760 --> 02:30:29.960]   there is yet to be discovered.
[02:30:29.960 --> 02:30:31.280]   - Well, there's a difference between laziness
[02:30:31.280 --> 02:30:32.720]   and ignorance, right?
[02:30:32.720 --> 02:30:34.760]   So I would be lazy if I didn't
[02:30:34.760 --> 02:30:37.920]   take advantage of the internet, right?
[02:30:37.920 --> 02:30:40.680]   Someone in North Korea doesn't have the option.
[02:30:40.680 --> 02:30:42.960]   There's literally no way for them to access the internet.
[02:30:42.960 --> 02:30:47.360]   So there's kind of like social laziness
[02:30:47.360 --> 02:30:49.200]   that philosophers have warned about forever,
[02:30:49.200 --> 02:30:51.720]   that we basically become sheep, okay?
[02:30:51.720 --> 02:30:55.560]   And then there's actual brainwashing and censorship
[02:30:55.560 --> 02:30:58.640]   that's possible by closing off your population
[02:30:58.640 --> 02:31:01.640]   and keeping them off the internet, right?
[02:31:01.640 --> 02:31:03.440]   So I think these are two very different concepts.
[02:31:03.440 --> 02:31:04.280]   - Absolutely.
[02:31:04.280 --> 02:31:07.320]   But I also mean just like, not even laziness,
[02:31:07.320 --> 02:31:09.240]   but cognitive limitations
[02:31:09.240 --> 02:31:11.920]   and just historical scientific limitations.
[02:31:11.920 --> 02:31:17.080]   We're a very young species.
[02:31:17.080 --> 02:31:18.880]   All of the exciting stuff we've been talking about
[02:31:18.880 --> 02:31:21.640]   have happened on the scale of decades, maybe centuries.
[02:31:21.640 --> 02:31:25.240]   We're very young in all the cool stuff we've come up with.
[02:31:25.240 --> 02:31:28.480]   And it's just humbling to think about how little we know.
[02:31:28.480 --> 02:31:32.200]   But you're right that ultimately having the freedom
[02:31:32.200 --> 02:31:35.640]   to keep exploring, keep venturing out.
[02:31:35.640 --> 02:31:38.320]   Even if we later discover that a lot of the stuff
[02:31:38.320 --> 02:31:43.320]   we've been doing now is ethically horrible.
[02:31:43.320 --> 02:31:47.480]   If you think about animals, or I think about robots a lot,
[02:31:47.480 --> 02:31:49.280]   the kind of things we might be doing
[02:31:50.760 --> 02:31:53.760]   to other consciousnesses that are here on earth,
[02:31:53.760 --> 02:31:56.960]   might be, we might see as atrocities later on.
[02:31:56.960 --> 02:31:58.480]   But ultimately you have to have the freedom
[02:31:58.480 --> 02:32:00.360]   to explore those kinds of ideas.
[02:32:00.360 --> 02:32:01.700]   And without that freedom,
[02:32:01.700 --> 02:32:05.440]   you don't even get the chance to be lazy.
[02:32:05.440 --> 02:32:07.400]   - Yeah, I mean, look, don't be a sheep.
[02:32:07.400 --> 02:32:09.520]   It's easy to be a sheep.
[02:32:09.520 --> 02:32:10.360]   - No offense to sheep.
[02:32:10.360 --> 02:32:11.960]   - And there's some practical things, man.
[02:32:11.960 --> 02:32:14.440]   Get on Signal, start encrypting your messages.
[02:32:14.440 --> 02:32:16.940]   Take control over your privacy.
[02:32:16.940 --> 02:32:20.680]   The media doesn't want you to, but check out Bitcoin.
[02:32:20.680 --> 02:32:22.080]   You can be your own bank.
[02:32:22.080 --> 02:32:23.720]   You can transact with people around the world
[02:32:23.720 --> 02:32:25.140]   and no one can stop you.
[02:32:25.140 --> 02:32:28.760]   This can put a stop to a lot of arbitrary power
[02:32:28.760 --> 02:32:30.660]   and a lot of human rights violations.
[02:32:30.660 --> 02:32:34.760]   Don't use WeChat, question more.
[02:32:34.760 --> 02:32:38.080]   Research what's happening in Xinjiang.
[02:32:38.080 --> 02:32:40.520]   I mean, learn about what's happening
[02:32:40.520 --> 02:32:42.080]   in the genocide in that country.
[02:32:42.080 --> 02:32:44.600]   And let's think about how we can build our societies
[02:32:44.600 --> 02:32:46.820]   so that we never have that kind of power concentration
[02:32:46.820 --> 02:32:48.280]   ever again.
[02:32:48.280 --> 02:32:50.000]   - Each of us can make a difference.
[02:32:50.000 --> 02:32:51.880]   Alex, it's a huge honor to talk to you.
[02:32:51.880 --> 02:32:53.160]   I've been a fan of your work.
[02:32:53.160 --> 02:32:55.560]   A lot of people spoke really highly of you
[02:32:55.560 --> 02:32:58.560]   as one of the beacons of hope for human civilization.
[02:32:58.560 --> 02:33:01.320]   So I'm really glad we got a chance to talk.
[02:33:01.320 --> 02:33:03.000]   Thank you for wasting all this time with me today.
[02:33:03.000 --> 02:33:03.840]   - It's been an honor.
[02:33:03.840 --> 02:33:04.680]   Thanks, man.
[02:33:04.680 --> 02:33:06.040]   A lot of fun.
[02:33:06.040 --> 02:33:07.680]   - Thanks for listening to this conversation
[02:33:07.680 --> 02:33:09.200]   with Alex Glastine.
[02:33:09.200 --> 02:33:10.560]   To support this podcast,
[02:33:10.560 --> 02:33:13.160]   please check out our sponsors in the description.
[02:33:13.160 --> 02:33:17.220]   And now let me leave you with some words from Alice Walker.
[02:33:18.320 --> 02:33:21.360]   The most common way people give up their power
[02:33:21.360 --> 02:33:23.700]   is by thinking they don't have any.
[02:33:23.700 --> 02:33:25.880]   Thank you for listening.
[02:33:25.880 --> 02:33:27.840]   I hope to see you next time.
[02:33:27.840 --> 02:33:30.420]   (upbeat music)
[02:33:30.420 --> 02:33:33.000]   (upbeat music)
[02:33:33.000 --> 02:33:43.000]   [BLANK_AUDIO]

