
[00:00:00.000 --> 00:00:15.000]   .
[00:00:15.000 --> 00:00:16.500]   Nice meeting you guys.
[00:00:16.500 --> 00:00:17.840]   Great to be here.
[00:00:17.840 --> 00:00:20.320]   And I'm here to present Hyperbolic, which
[00:00:20.320 --> 00:00:22.400]   is an AI cloud for developers.
[00:00:22.400 --> 00:00:28.320]   And so my topic is why we don't need more data centers.
[00:00:28.320 --> 00:00:31.320]   It's like a very eye-catching title.
[00:00:31.320 --> 00:00:33.820]   But what I want to clarify is I still
[00:00:33.820 --> 00:00:36.420]   think building data centers is important.
[00:00:36.420 --> 00:00:41.640]   But just building data centers alone can solve the problem.
[00:00:41.640 --> 00:00:47.320]   So wait, before we get started, let me introduce myself.
[00:00:47.320 --> 00:00:47.820]   I'm Jasper.
[00:00:47.820 --> 00:00:50.440]   I'm the CEO and co-founder of Hyperbolic.
[00:00:50.440 --> 00:00:54.200]   I did my math PhD at UC Berkeley, finished my PhD in two years,
[00:00:54.200 --> 00:00:57.480]   which made me the fastest person in the history of Berkeley.
[00:00:57.480 --> 00:00:59.460]   And then I also won a few gold medals.
[00:00:59.460 --> 00:01:02.260]   So after that, I worked at State of Securities,
[00:01:02.260 --> 00:01:04.780]   trying to use AI and machine learning to predict the market
[00:01:04.780 --> 00:01:05.940]   as a key strategy.
[00:01:05.940 --> 00:01:08.300]   So I always have a passion about how
[00:01:08.300 --> 00:01:10.860]   to make things very efficient and how
[00:01:10.860 --> 00:01:12.240]   to help you to save money.
[00:01:12.240 --> 00:01:15.020]   Because everyone knows that compute is actually
[00:01:15.020 --> 00:01:17.140]   one of the biggest costs for your companies
[00:01:17.140 --> 00:01:18.960]   or for your startups.
[00:01:18.960 --> 00:01:21.580]   Usually, if you want to rent 1,000 GPU,
[00:01:21.580 --> 00:01:24.480]   we'll spend you millions of dollars per year.
[00:01:24.480 --> 00:01:26.760]   And we think that these problems should
[00:01:26.760 --> 00:01:30.240]   be solved by not just building more data centers,
[00:01:30.240 --> 00:01:33.120]   but actually building a GPU marketplace.
[00:01:33.120 --> 00:01:36.880]   So let's get started with the problem that we're facing.
[00:01:36.880 --> 00:01:39.460]   First, I think--
[00:01:39.460 --> 00:01:41.700]   so everyone knows that AI is going to integrate
[00:01:41.700 --> 00:01:43.720]   with everything in the future.
[00:01:43.720 --> 00:01:46.540]   And every company will be AI companies.
[00:01:46.540 --> 00:01:51.380]   So the demand for GPUs as well as data centers is exploding.
[00:01:51.380 --> 00:01:58.780]   So by McKinsey, by 2030, we'll need 4x more data centers built
[00:01:58.780 --> 00:02:04.060]   in one quarter of the time that we built in this bit.
[00:02:04.060 --> 00:02:07.140]   But what if I tell you that you actually don't need
[00:02:07.140 --> 00:02:09.240]   that many data centers?
[00:02:09.240 --> 00:02:11.820]   You actually need another solution.
[00:02:11.820 --> 00:02:15.200]   So we can break down the demand first.
[00:02:15.200 --> 00:02:22.220]   Right now, the current capacity for data center is 55 gigawatts.
[00:02:22.220 --> 00:02:28.220]   By the median scenario, we're going to see 22% annual growth
[00:02:28.220 --> 00:02:29.640]   rate for the demand.
[00:02:29.640 --> 00:02:34.920]   So in 2030, we're going to need 219 gigawatts.
[00:02:38.300 --> 00:02:43.280]   And however, there are a lot of challenges building data centers.
[00:02:43.280 --> 00:02:46.440]   So first, everyone knows StartGate.
[00:02:46.440 --> 00:02:49.780]   So it takes-- for the first StartGate data center,
[00:02:49.780 --> 00:02:52.860]   it takes more than a billion dollars to build.
[00:02:52.860 --> 00:02:56.000]   And then also, it's very slow to connect data center
[00:02:56.000 --> 00:02:58.160]   to the electrical grid.
[00:02:58.160 --> 00:03:02.280]   For example, right now, the wait list is like seven years.
[00:03:02.280 --> 00:03:05.420]   So you need to wait seven years to connect 100 megawatts
[00:03:05.420 --> 00:03:11.720]   facility to the electrical grid in Northern Virginia.
[00:03:11.720 --> 00:03:17.360]   And then, it's also very consuming a lot of energy.
[00:03:17.360 --> 00:03:21.320]   So currently, we're spending 4% of the total electricity
[00:03:21.320 --> 00:03:24.700]   consumption in the US for just GPUs and data centers.
[00:03:24.700 --> 00:03:28.500]   And also, it's not very environmentally sustainable.
[00:03:28.500 --> 00:03:32.640]   If you can look at the number, that's crazy CO2 emissions
[00:03:32.640 --> 00:03:34.520]   annually.
[00:03:34.520 --> 00:03:39.380]   And even say, if we're going to deliver all the data centers
[00:03:39.380 --> 00:03:43.540]   on time, there is still a data center supply deficit
[00:03:43.540 --> 00:03:48.720]   of more than 15 gigawatts in the US along by 2030.
[00:03:48.720 --> 00:03:52.660]   And so it means that just building data center
[00:03:52.660 --> 00:03:54.740]   can solve the problem.
[00:03:54.740 --> 00:04:00.500]   On the other hand, we think the GPU utilization
[00:04:00.500 --> 00:04:01.980]   is actually pretty low.
[00:04:01.980 --> 00:04:08.380]   So according to Deloitte, GPUs sit idle 80% of the time
[00:04:08.380 --> 00:04:11.920]   for enterprises and companies.
[00:04:11.920 --> 00:04:17.240]   According to semi-analysis, there exists 100-plus GPU clouds.
[00:04:17.240 --> 00:04:20.740]   So we can see how fragmented this space is.
[00:04:20.740 --> 00:04:25.000]   A lot of you guys need GPUs, but you can't find them.
[00:04:25.000 --> 00:04:28.420]   Or you are going to pay extremely high price.
[00:04:28.420 --> 00:04:32.500]   On the other hand, there are a lot of GPUs sit idle in data centers
[00:04:32.500 --> 00:04:34.240]   or in different clouds.
[00:04:34.240 --> 00:04:39.880]   And so naturally, a solution that we think we should build is actually
[00:04:39.880 --> 00:04:43.160]   build a GPU marketplace or aggregation layer that
[00:04:43.160 --> 00:04:48.100]   aggregate different data centers and GPU providers to solve the problem
[00:04:48.100 --> 00:04:50.280]   for GPU users.
[00:04:50.280 --> 00:04:52.480]   So it doesn't necessarily need to be hyperbolic,
[00:04:52.480 --> 00:04:57.760]   but I just use hyperbolic as an example to show you.
[00:04:57.760 --> 00:05:03.040]   So I can just share what we're trying to solve.
[00:05:03.040 --> 00:05:06.100]   So we're building this global orchestration layer.
[00:05:06.100 --> 00:05:10.420]   We invented a software called HyperDOS, which is short for Hyperbolic
[00:05:10.420 --> 00:05:13.520]   Distributed Operating System.
[00:05:13.520 --> 00:05:17.280]   So basically, it's like Kubernetes software.
[00:05:17.280 --> 00:05:22.460]   So any cluster, as long as it installed our software within five
[00:05:22.460 --> 00:05:27.280]   minutes, suddenly the data center become a cluster in our network.
[00:05:27.280 --> 00:05:32.300]   And on the other side, users can rent GPUs in different ways
[00:05:32.300 --> 00:05:32.960]   that they want.
[00:05:32.960 --> 00:05:36.540]   They can just do the spot instance.
[00:05:36.540 --> 00:05:37.720]   They can on-demand.
[00:05:37.720 --> 00:05:39.180]   They can long-term reserve.
[00:05:39.180 --> 00:05:41.680]   Or they can also host models on top.
[00:05:41.680 --> 00:05:49.080]   And so we see that there are several benefits.
[00:05:49.080 --> 00:05:56.340]   One, we kind of solve the matching problem of compute.
[00:05:56.340 --> 00:05:59.560]   And then second, GPU become commodities.
[00:05:59.560 --> 00:06:02.860]   So you don't need to spend too much time to wait for data center.
[00:06:02.860 --> 00:06:04.780]   You just buy them on the marketplace.
[00:06:04.780 --> 00:06:09.160]   And then third, you can have different options.
[00:06:09.160 --> 00:06:13.640]   And so we do some math modeling.
[00:06:13.640 --> 00:06:16.180]   I mean, I don't have time to kind of put down the math
[00:06:16.180 --> 00:06:16.900]   in the slides.
[00:06:16.900 --> 00:06:19.120]   But this is our conclusion, right?
[00:06:19.120 --> 00:06:25.080]   Basically, we can save the cost by 50% to 75%.
[00:06:25.080 --> 00:06:27.340]   Even if you look at the current--
[00:06:27.340 --> 00:06:30.940]   we're running some beta version of our marketplace right now.
[00:06:30.940 --> 00:06:36.480]   And our GPU cost for H100 is $0.99 per hour.
[00:06:36.480 --> 00:06:39.160]   But if you look at Google, for example,
[00:06:39.160 --> 00:06:40.600]   they have on-demand GPU.
[00:06:40.600 --> 00:06:42.080]   It's like $11.
[00:06:42.080 --> 00:06:42.980]   They're like a lambda.
[00:06:42.980 --> 00:06:44.380]   They have like $2 or $3.
[00:06:44.380 --> 00:06:48.900]   But on average, by aggregating more supply
[00:06:48.900 --> 00:06:53.180]   and then have a uniform distribution channel,
[00:06:53.180 --> 00:06:57.020]   you can drastically reduce the price.
[00:06:57.020 --> 00:07:00.800]   It's the theory behind that is like the queuing theory.
[00:07:00.800 --> 00:07:04.180]   Basically, it's MMC theory.
[00:07:04.180 --> 00:07:06.580]   Probably next time, if we're going to watch my talk,
[00:07:06.580 --> 00:07:09.440]   I will share more math behind it.
[00:07:09.440 --> 00:07:11.240]   But yeah, and then you can just save time
[00:07:11.240 --> 00:07:12.380]   to vetting your suppliers.
[00:07:12.380 --> 00:07:15.400]   Because if you think about--
[00:07:15.400 --> 00:07:17.820]   I mean, how many people here are funders
[00:07:17.820 --> 00:07:21.840]   or need to acquire GPUs?
[00:07:21.840 --> 00:07:26.120]   So are you frustrated when you are trying to talk to--
[00:07:26.120 --> 00:07:28.140]   how many suppliers are you talking to?
[00:07:28.140 --> 00:07:32.500]   If you have talked to more than five, raise your hands.
[00:07:32.500 --> 00:07:34.140]   Are you frustrated when you're trying
[00:07:34.140 --> 00:07:40.760]   to have five sales calls and try to know which GPUs are
[00:07:40.760 --> 00:07:42.720]   frustrated, yeah, are good, yeah.
[00:07:42.720 --> 00:07:43.360]   That's good, yeah.
[00:07:43.360 --> 00:07:47.580]   So basically, by having this uniform platform,
[00:07:47.580 --> 00:07:50.260]   like funders or startups or companies
[00:07:50.260 --> 00:07:53.140]   no longer need to vet different data centers.
[00:07:53.140 --> 00:07:57.820]   They just pick the one that they have high rating
[00:07:57.820 --> 00:07:59.440]   or have the best price.
[00:07:59.440 --> 00:08:01.840]   We're also going to do benchmarking
[00:08:01.840 --> 00:08:03.120]   on the performance of the GPUs.
[00:08:10.160 --> 00:08:10.700]   Sorry.
[00:08:10.700 --> 00:08:13.980]   All right.
[00:08:13.980 --> 00:08:14.820]   So sorry.
[00:08:14.820 --> 00:08:17.520]   Somehow the graph didn't show.
[00:08:17.520 --> 00:08:22.860]   Give me one sec.
[00:08:22.860 --> 00:08:34.200]   So basically, we can think about a use case example.
[00:08:34.200 --> 00:08:39.120]   So let's say if you are a startup and you want 1,000 GPUs
[00:08:39.120 --> 00:08:39.960]   at the beginning.
[00:08:39.960 --> 00:08:43.820]   So usually, you will just reserve these 1,000 GPUs for a year.
[00:08:43.820 --> 00:08:48.060]   You think, I might need to use these GPUs for training.
[00:08:48.060 --> 00:08:49.840]   And later on, I want to do inference.
[00:08:49.840 --> 00:08:52.340]   And so you run some training jobs.
[00:08:52.340 --> 00:08:56.180]   And then after three months, then you realize that, OK, now,
[00:08:56.180 --> 00:09:00.940]   I have a bad idea by running those experiments.
[00:09:00.940 --> 00:09:05.040]   And now I need 1,000 more GPUs just for a month, right?
[00:09:05.040 --> 00:09:10.920]   And then after six months, then you finish your training job.
[00:09:10.920 --> 00:09:12.700]   And then you realize that now I only
[00:09:12.700 --> 00:09:16.280]   need 500 GPUs for hosting my model.
[00:09:16.280 --> 00:09:19.460]   But I still have 500 GPUs left.
[00:09:19.460 --> 00:09:23.900]   So on the traditional unhyperbolic case,
[00:09:23.900 --> 00:09:27.380]   you basically can say, OK, I will rent 1,000 GPUs
[00:09:27.380 --> 00:09:29.140]   for a year at the beginning.
[00:09:29.140 --> 00:09:34.280]   But then in month three, I can say,
[00:09:34.280 --> 00:09:40.920]   I just rent an extra 1,000 GPUs for just a month.
[00:09:40.920 --> 00:09:44.720]   And then in month six, then I can say, OK,
[00:09:44.720 --> 00:09:49.380]   I can release my idle GPUs on hyperbolic and try to sell them
[00:09:49.380 --> 00:09:52.580]   to other people that need them.
[00:09:52.580 --> 00:09:55.320]   But if you just use some traditional cloud,
[00:09:55.320 --> 00:09:57.920]   then you need to rent 1,000 GPUs at the beginning.
[00:09:57.920 --> 00:10:02.240]   And then in month three, you need to rent actually 1,000 GPUs
[00:10:02.240 --> 00:10:03.720]   for a year, usually.
[00:10:03.720 --> 00:10:06.660]   And if you calculate the cost, compare that,
[00:10:06.660 --> 00:10:12.340]   and then also think about the price difference you will have,
[00:10:12.340 --> 00:10:19.000]   you can reduce the cost from $43.8 million to $6.9 million.
[00:10:19.000 --> 00:10:21.360]   So it's like 6x saving.
[00:10:21.360 --> 00:10:24.520]   And you also help other people to get cheaper GPUs too,
[00:10:24.520 --> 00:10:27.900]   because you can release those idle GPUs to other people.
[00:10:27.900 --> 00:10:34.660]   And so this is how we think that we're going to increase
[00:10:34.660 --> 00:10:36.340]   the productivity.
[00:10:36.340 --> 00:10:39.760]   People only think about saving, but actually,
[00:10:39.760 --> 00:10:42.580]   this is not true for GPU, right?
[00:10:42.580 --> 00:10:46.620]   By scaling law, we know that the more compute you spend,
[00:10:46.620 --> 00:10:49.700]   the better quality your model will be.
[00:10:49.700 --> 00:10:53.980]   So it's not just about saving your cost by 6x.
[00:10:53.980 --> 00:10:56.720]   It's more about with the same budget,
[00:10:56.720 --> 00:11:00.260]   you will increase your productivity by 6x.
[00:11:00.260 --> 00:11:05.300]   And imagine how many startups that they use
[00:11:05.300 --> 00:11:08.800]   only need to rely on open AI and anthropic those closed AI
[00:11:08.800 --> 00:11:09.540]   models.
[00:11:09.540 --> 00:11:13.680]   But now suddenly, their money become more valuable,
[00:11:13.680 --> 00:11:19.080]   and they can rent as many GPUs as they want for their training.
[00:11:19.080 --> 00:11:23.040]   And so the next step that we think usually the GPU marketplace will
[00:11:23.040 --> 00:11:29.140]   evolve into is that it will be an all-in-one platform for a different AI
[00:11:29.140 --> 00:11:30.020]   workload.
[00:11:30.020 --> 00:11:33.940]   Because what people really want is not just GPUs.
[00:11:33.940 --> 00:11:37.060]   They want to run their different AI jobs, right?
[00:11:37.060 --> 00:11:42.040]   So you will have AI inference, online inference, offline inference,
[00:11:42.040 --> 00:11:44.000]   and then you will also have a training job.
[00:11:47.080 --> 00:11:52.840]   And so, yeah, so this is, like, to, like, some takeaway.
[00:11:52.840 --> 00:11:58.320]   Like, basically, we don't think we need, like, just focus on building
[00:11:58.320 --> 00:11:58.980]   data centers.
[00:11:58.980 --> 00:12:03.200]   We also need to do, like, smart allocation for the resources.
[00:12:03.200 --> 00:12:09.220]   And then second, we can reduce your costs by building GPUs
[00:12:09.220 --> 00:12:10.260]   marketplace.
[00:12:10.260 --> 00:12:14.520]   And lastly, I think just focusing on building data centers
[00:12:14.520 --> 00:12:15.920]   is not very sustainable.
[00:12:15.920 --> 00:12:20.420]   We're costing a lot of energy, taking a lot of land.
[00:12:20.420 --> 00:12:24.620]   We should better reuse, recycle those idle compute
[00:12:24.620 --> 00:12:27.860]   by sending it to others.
[00:12:27.860 --> 00:12:31.520]   So if you're interested in trying out,
[00:12:31.520 --> 00:12:34.520]   you can come to our website.
[00:12:34.520 --> 00:12:37.580]   The left QR code is the current product
[00:12:37.580 --> 00:12:39.280]   that we have, which is a marketplace.
[00:12:39.280 --> 00:12:41.100]   But then we're also launching our business card
[00:12:41.100 --> 00:12:44.760]   and enterprise card that give you, like, production-ready GPUs
[00:12:44.760 --> 00:12:47.400]   with 99.5% reliability.
[00:12:47.400 --> 00:12:47.820]   All right.
[00:12:47.820 --> 00:12:48.200]   Thanks.
[00:12:48.200 --> 00:12:53.460]   Awesome.
[00:12:53.460 --> 00:12:55.260]   So I actually got--
[00:12:55.260 --> 00:12:56.040]   I'm curious.
[00:12:56.040 --> 00:12:59.520]   Can you tell us more about the kind of hyperbolic OS?
[00:12:59.520 --> 00:13:01.260]   How exactly does that turn?
[00:13:01.260 --> 00:13:03.760]   Because I know a lot of times you have a data center,
[00:13:03.760 --> 00:13:05.260]   you have a cluster set of GPUs.
[00:13:05.260 --> 00:13:09.760]   How does it actually work to connect it to hyperbolic itself?
[00:13:09.760 --> 00:13:10.260]   Yeah.
[00:13:10.260 --> 00:13:10.260]   Yeah.
[00:13:10.260 --> 00:13:10.260]   Yeah.
[00:13:10.260 --> 00:13:13.260]   So basically, this is a hybrid--
[00:13:13.260 --> 00:13:15.820]   HyperDOS is like a Kubernetes agent.
[00:13:15.820 --> 00:13:19.360]   So you just install that in your cluster,
[00:13:19.360 --> 00:13:21.540]   as long as you have Kubernetes.
[00:13:21.540 --> 00:13:24.520]   I mean, most data centers have Kubernetes.
[00:13:24.520 --> 00:13:27.940]   But then even for your MacBook or for your other PC,
[00:13:27.940 --> 00:13:30.700]   you can just install, like, to kind
[00:13:30.700 --> 00:13:34.120]   of become a Kubernetes-ready machine.
[00:13:34.120 --> 00:13:38.060]   And so basically, now you kind of have--
[00:13:38.060 --> 00:13:40.340]   we have terminology in-house.
[00:13:40.340 --> 00:13:45.580]   We call, like, our hyperbolic server Monarch.
[00:13:45.580 --> 00:13:48.840]   And then we have different Barons.
[00:13:48.840 --> 00:13:50.740]   So it's like a model.
[00:13:50.740 --> 00:13:54.160]   So different Barons, they own different compute.
[00:13:54.160 --> 00:13:58.120]   And then every time when a user wants to rent GPU,
[00:13:58.120 --> 00:14:00.160]   they will talk to our Monarch server.
[00:14:00.160 --> 00:14:04.140]   And the Monarch server will send a request to the Barron.
[00:14:04.140 --> 00:14:07.540]   And then Barron will basically provision the machines
[00:14:07.540 --> 00:14:11.380]   and set up the SSH instance for customers to access.
[00:14:11.380 --> 00:14:11.880]   Yeah.
[00:14:11.880 --> 00:14:16.880]   And then we'll see you next time.

