
[00:00:00.000 --> 00:00:08.120]   I play tennis a lot, and a ball hits the net court a lot.
[00:00:08.120 --> 00:00:12.480]   Sometimes it plops over to the other side of the court, and sometimes it plops over
[00:00:12.480 --> 00:00:14.400]   to your side of the court.
[00:00:14.400 --> 00:00:17.920]   This can be on very big points that this happens.
[00:00:17.920 --> 00:00:22.160]   When it plops back over to your side of the court, you're super sad, and you feel like
[00:00:22.160 --> 00:00:24.040]   you're really unlucky.
[00:00:24.040 --> 00:00:28.400]   But then what I say to myself is, "But it's gone the other way for me at really important
[00:00:28.400 --> 00:00:30.560]   times as well."
[00:00:30.560 --> 00:00:32.520]   So I try to always remember that.
[00:00:32.520 --> 00:00:38.680]   And the question then I try to focus on is, "Did I pick the right shot?
[00:00:38.680 --> 00:00:43.440]   Should I have done something which was going to have more clearance over the net?"
[00:00:43.440 --> 00:00:47.240]   So then I start to think about, "Was it the right choice?"
[00:00:47.240 --> 00:00:51.040]   I try to get back to the decision itself, as opposed to just the outcome.
[00:00:51.040 --> 00:00:54.840]   Hello, and welcome to another episode of All The Hacks, a show about upgrading your life,
[00:00:54.840 --> 00:00:58.000]   money, and travel, all while spending less and saving more.
[00:00:58.000 --> 00:01:01.320]   I'm Chris Hutchins, and I'm excited to have you on my journey to optimize my own life
[00:01:01.320 --> 00:01:05.760]   by sitting down each week with the world's best experts to learn the strategies, tactics,
[00:01:05.760 --> 00:01:08.040]   and frameworks that shape their success.
[00:01:08.040 --> 00:01:11.960]   Today I'm talking with Annie Duke, a former professional poker player turned bestselling
[00:01:11.960 --> 00:01:15.600]   author and what I'll call a professional decision maker.
[00:01:15.600 --> 00:01:20.000]   Her 2018 bestseller, Thinking in Bets, Making Smarter Decisions When You Don't Have All
[00:01:20.000 --> 00:01:24.260]   the Facts, explored how life is more like poker than chess, and has helped countless
[00:01:24.260 --> 00:01:26.140]   people make better decisions.
[00:01:26.140 --> 00:01:30.080]   And her latest book, Quit, The Power of Knowing When to Walk Away, is all about learning to
[00:01:30.080 --> 00:01:34.360]   quit well, which is a skill that can not only be learned, but that should be learned and
[00:01:34.360 --> 00:01:36.060]   practiced by just about everyone.
[00:01:36.060 --> 00:01:41.440]   We're going to talk about making good decisions, getting better at quitting, but more specifically,
[00:01:41.440 --> 00:01:45.480]   why learning the difference between luck and the quality of your decisions is so important,
[00:01:45.480 --> 00:01:49.460]   and how that can improve your life and your career, why just looking at the outcome of
[00:01:49.460 --> 00:01:54.480]   decisions isn't enough, what forces work against good quitting behavior, and why so many people
[00:01:54.480 --> 00:01:58.560]   struggle with the decision to walk away, how to use kill criteria to determine when to
[00:01:58.560 --> 00:02:02.040]   quit a project, a job, or some other endeavor, and a lot more.
[00:02:02.040 --> 00:02:09.840]   Annie, welcome to the show, thanks for being here.
[00:02:09.840 --> 00:02:11.460]   Thanks for having me.
[00:02:11.460 --> 00:02:15.480]   You say there are only two factors in how life turns out, luck and the quality of your
[00:02:15.480 --> 00:02:16.480]   decisions.
[00:02:16.480 --> 00:02:19.280]   You don't have control over luck, but you do have control over the quality of the decisions
[00:02:19.280 --> 00:02:20.360]   you make.
[00:02:20.360 --> 00:02:23.560]   How can people tell the difference between the two, and more importantly, improve the
[00:02:23.560 --> 00:02:25.240]   quality of the decisions they make?
[00:02:25.240 --> 00:02:29.960]   Yeah, so that's like the $64,000 question.
[00:02:29.960 --> 00:02:34.480]   So let's just first of all say, when you make a decision, there's two forces that are going
[00:02:34.480 --> 00:02:38.480]   to influence that outcome of the decision, right?
[00:02:38.480 --> 00:02:42.400]   One is luck, and one is the quality of the decision itself.
[00:02:42.400 --> 00:02:47.440]   Now luck is a form of uncertainty that exerts itself on the outcome, right?
[00:02:47.440 --> 00:02:53.140]   So I could make a choice that's going to work out 95% of the time.
[00:02:53.140 --> 00:02:58.280]   That means by definition, 5% of the time, I'm going to observe a bad outcome, and I
[00:02:58.280 --> 00:03:02.160]   have no control over when I'm going to observe that 5%, right?
[00:03:02.160 --> 00:03:05.280]   So that's just kind of how it is.
[00:03:05.280 --> 00:03:10.720]   What's important to good decision-making is to accept that luck exists and try to see
[00:03:10.720 --> 00:03:12.680]   it clearly, right?
[00:03:12.680 --> 00:03:20.240]   So what we want to do is know that this is a 95% to 5% good to bad ratio on the outcomes
[00:03:20.240 --> 00:03:23.760]   that I could see and not believe something else.
[00:03:23.760 --> 00:03:28.800]   So if we forecast that it will work out 95% of the time, but it's actually only going
[00:03:28.800 --> 00:03:32.440]   to work out 65% of the time, that would be a problem.
[00:03:32.440 --> 00:03:37.440]   So it's not about controlling luck because you can't definitionally, it's about being
[00:03:37.440 --> 00:03:42.920]   able to forecast appropriately how luck might exert its influence, what the influence of
[00:03:42.920 --> 00:03:45.240]   luck on the outcome might be.
[00:03:45.240 --> 00:03:50.000]   And we know from a lot of work in cognitive bias, for example, that there's all sorts
[00:03:50.000 --> 00:03:53.800]   of different ways in which we don't see luck very well.
[00:03:53.800 --> 00:03:56.600]   The illusion of control, we think we have more control over the way that things are
[00:03:56.600 --> 00:04:02.720]   going to turn out than we do actually, or overoptimism and overconfidence, for example,
[00:04:02.720 --> 00:04:06.960]   are ways in which we will just sort of misassign the probabilities of different outcomes that
[00:04:06.960 --> 00:04:08.420]   might occur in the future.
[00:04:08.420 --> 00:04:10.500]   So that's the luck side, right?
[00:04:10.500 --> 00:04:15.700]   So part of a good quality decision is to be a good forecaster of these things, to start
[00:04:15.700 --> 00:04:23.200]   to see the outcomes in the way that they actually are true to reality, what ground truth actually
[00:04:23.200 --> 00:04:27.240]   is, as opposed to what our brains sort of think they are, right?
[00:04:27.240 --> 00:04:29.680]   So that's piece number one.
[00:04:29.680 --> 00:04:35.600]   Piece number two, the other form of uncertainty that is going to exert itself on the quality
[00:04:35.600 --> 00:04:39.800]   of the outcome that we might observe, and in fact, the quality of the decision that
[00:04:39.800 --> 00:04:42.720]   we're making is just hidden information.
[00:04:42.720 --> 00:04:47.780]   So for most things that we're deciding about, we know very little in comparison to all there
[00:04:47.780 --> 00:04:48.780]   is to be known.
[00:04:48.780 --> 00:04:53.260]   You know, like I said, the stuff we know fits on like the head of a pin, the stuff we don't
[00:04:53.260 --> 00:04:55.700]   know is like the size of the whole universe, right?
[00:04:55.700 --> 00:05:00.420]   So obviously, I'm sure you've had the feeling, Chris, of saying, "I wish I knew then what
[00:05:00.420 --> 00:05:01.420]   I know now."
[00:05:01.420 --> 00:05:02.420]   All the time.
[00:05:02.420 --> 00:05:03.420]   Right?
[00:05:03.420 --> 00:05:06.340]   So that's just hidden information.
[00:05:06.340 --> 00:05:10.740]   You're just sort of seeing the influence of hidden information that you sort of realize,
[00:05:10.740 --> 00:05:14.820]   if I knew then what I know now, I may have made a different choice.
[00:05:14.820 --> 00:05:15.820]   Why?
[00:05:15.820 --> 00:05:20.420]   Because when we're thinking about those forecasts that we make, right, I'm considering a decision
[00:05:20.420 --> 00:05:26.460]   and I'm thinking about what the possible outcomes are, each of those outcomes has a payoff associated
[00:05:26.460 --> 00:05:27.460]   with it.
[00:05:27.460 --> 00:05:31.060]   Each of those outcomes has a probability associated with it.
[00:05:31.060 --> 00:05:38.300]   So when we think about our beliefs, the things that we believe to be true, they're determining
[00:05:38.300 --> 00:05:42.660]   for us how we think any option that we're considering might turn out, right?
[00:05:42.660 --> 00:05:46.720]   What we believe to be true of the world is going to influence what we think the possible
[00:05:46.720 --> 00:05:51.820]   outcomes are of any decision that we might be considering, what the payoffs are associated
[00:05:51.820 --> 00:05:54.620]   with those and what the probability of those are.
[00:05:54.620 --> 00:06:00.140]   And in fact, our beliefs are going to inform other things as well, like what options we
[00:06:00.140 --> 00:06:02.900]   might actually consider, right?
[00:06:02.900 --> 00:06:05.640]   So we're usually considering more than one option.
[00:06:05.640 --> 00:06:08.000]   They're going to inform what we think our goals are.
[00:06:08.000 --> 00:06:13.420]   What is the point that we want to be heading toward, right?
[00:06:13.420 --> 00:06:19.900]   So beliefs change over time, not as much as they should, but they do change over time.
[00:06:19.900 --> 00:06:22.100]   And those beliefs are always going to be imperfect.
[00:06:22.100 --> 00:06:27.340]   There's always going to be inaccuracies in the things that we believe because we're partially
[00:06:27.340 --> 00:06:29.460]   behind the veil of ignorance, right?
[00:06:29.460 --> 00:06:31.820]   We just don't, we don't know a whole lot.
[00:06:31.820 --> 00:06:36.460]   So that's the second way in which we can think about how do we actually improve the forecast?
[00:06:36.460 --> 00:06:42.480]   So we can consider from the option that we're making a decision about going forward, seeing
[00:06:42.480 --> 00:06:47.000]   the luck very clearly, but then we can take a step back and say, well, if beliefs are
[00:06:47.000 --> 00:06:51.880]   at the center of that, if they're the foundation really of every decision we make, that's a
[00:06:51.880 --> 00:06:56.980]   place that we can really start to focus our energy on improving the quality of the beliefs
[00:06:56.980 --> 00:06:58.400]   that we have.
[00:06:58.400 --> 00:07:02.160]   - Is there a common decision you think people make where this kind of really comes to life?
[00:07:02.800 --> 00:07:07.340]   - Well, it's like every decision, but one of the ones that I love to think about is
[00:07:07.340 --> 00:07:09.720]   hiring, right?
[00:07:09.720 --> 00:07:19.020]   So in hiring, we can see all sorts of different things at play, but we can see a basic decision,
[00:07:19.020 --> 00:07:20.020]   right?
[00:07:20.020 --> 00:07:24.500]   You have some idea of what your goal is, what you want to hire for, what your values are,
[00:07:24.500 --> 00:07:25.500]   right?
[00:07:25.500 --> 00:07:32.140]   So that's going to be the rack, the job description, but that's going to have to do with things
[00:07:32.140 --> 00:07:35.900]   like who's the person that you think is going to be right for the role, right?
[00:07:35.900 --> 00:07:41.580]   What's the role that you think you need to be hiring for, which is sometimes not explored
[00:07:41.580 --> 00:07:42.700]   enough.
[00:07:42.700 --> 00:07:45.020]   Then you get lots of resumes in, right?
[00:07:45.020 --> 00:07:49.480]   And you start to try to fit the resumes to what you think that you want.
[00:07:49.480 --> 00:07:53.260]   And those are different options that you're considering, different people that you're
[00:07:53.260 --> 00:07:55.380]   thinking about hiring.
[00:07:55.380 --> 00:07:59.860]   There's other options you're considering, like what is the, what's the comp going to
[00:07:59.860 --> 00:08:02.100]   be?
[00:08:02.100 --> 00:08:11.420]   What's going to be the balance of say equity to cash, the balance of guaranteed comp versus
[00:08:11.420 --> 00:08:12.420]   bonus, things like that.
[00:08:12.420 --> 00:08:16.340]   But we'll put those aside and just think about the options, which are the people that you're
[00:08:16.340 --> 00:08:19.260]   considering hiring into the role.
[00:08:19.260 --> 00:08:24.700]   And then for any of those people that you're considering, whether you know it or not, you're
[00:08:24.700 --> 00:08:28.060]   thinking about what are the chances this person is going to work out?
[00:08:28.060 --> 00:08:29.980]   What's the chances they're not?
[00:08:29.980 --> 00:08:35.660]   Now we don't, we don't often do that, do that explicitly, but it's an implicit in any decision
[00:08:35.660 --> 00:08:36.660]   that we make.
[00:08:36.660 --> 00:08:39.020]   And there's a lot of luck that influences the outcome.
[00:08:39.020 --> 00:08:42.620]   So let's think about that and the hidden information.
[00:08:42.620 --> 00:08:47.580]   In terms of the hidden information, as you're considering each of those, those people to
[00:08:47.580 --> 00:08:57.800]   fill the open rack, well, okay, you have a CV, you have a few references and a couple
[00:08:57.800 --> 00:08:58.800]   of interviews.
[00:08:58.800 --> 00:08:59.800]   Right?
[00:08:59.800 --> 00:09:03.460]   Like they haven't worked at your company for a long time.
[00:09:03.460 --> 00:09:07.420]   You don't really know if they're going to be a good fit.
[00:09:07.420 --> 00:09:10.260]   You don't know really what their work ethic is.
[00:09:10.260 --> 00:09:14.740]   You have a little bit of idea, but you don't really find out most of the things that you
[00:09:14.740 --> 00:09:19.300]   would want to know until after you've decided whether to hire them or not.
[00:09:19.300 --> 00:09:23.940]   And separate from that, all the people that you say no to, you have no idea how they would
[00:09:23.940 --> 00:09:25.140]   have turned out.
[00:09:25.140 --> 00:09:26.140]   Right?
[00:09:26.140 --> 00:09:29.020]   So, so we can see this hidden information problem.
[00:09:29.020 --> 00:09:32.800]   Like I sort of say like with hiring, it's kind of like marrying someone after like a
[00:09:32.800 --> 00:09:37.180]   couple of dates and two friends telling you they're cool.
[00:09:37.180 --> 00:09:38.900]   People do that by the way.
[00:09:38.900 --> 00:09:40.660]   And what do we all think when they do that?
[00:09:40.660 --> 00:09:41.660]   Wow.
[00:09:41.660 --> 00:09:42.660]   You're kind of nuts.
[00:09:42.660 --> 00:09:46.780]   You know, when they're like, oh, I'm in love and it's, you, your first date was a week
[00:09:46.780 --> 00:09:47.780]   ago.
[00:09:47.780 --> 00:09:48.780]   You're heading to Vegas.
[00:09:48.780 --> 00:09:49.780]   Really?
[00:09:49.780 --> 00:09:52.100]   But that's kind of what hiring is.
[00:09:52.100 --> 00:09:55.060]   It's like heading a loping to Vegas after a week.
[00:09:55.060 --> 00:09:56.060]   Right?
[00:09:56.060 --> 00:09:57.060]   It's all part of the hidden information.
[00:09:57.060 --> 00:10:00.420]   And then what happens is that you find things out after the fact and you say, I wish I had
[00:10:00.420 --> 00:10:03.900]   known that before I hired them.
[00:10:03.900 --> 00:10:10.880]   And then in terms of luck, you know, when you hire, when you hire anybody most the,
[00:10:10.880 --> 00:10:15.000]   the probability of the person working out, it depends on sort of how you cut the data
[00:10:15.000 --> 00:10:18.460]   is around 50, 50.
[00:10:18.460 --> 00:10:20.860]   And you know, that's just a lot of luck, right?
[00:10:20.860 --> 00:10:22.660]   Like you sort of think they're going to be a fit.
[00:10:22.660 --> 00:10:24.300]   Did they turn out to be a fit?
[00:10:24.300 --> 00:10:26.040]   Did something happen in their personal life?
[00:10:26.040 --> 00:10:30.140]   Like after you hire them that you couldn't have known about beforehand.
[00:10:30.140 --> 00:10:31.140]   So on and so forth.
[00:10:31.140 --> 00:10:36.600]   So it's just a very kind of noisy, uh, it's a noisy decision.
[00:10:36.600 --> 00:10:40.740]   Now you can do things to improve the quality of the decision to increase the probability
[00:10:40.740 --> 00:10:45.140]   of getting a good outcome to somewhere between 60 and 65%, but that's about as far as you
[00:10:45.140 --> 00:10:48.380]   can push it because it's just too uncertain.
[00:10:48.380 --> 00:10:51.960]   So hiring is one of those places where it's like super clear that you can see the problems
[00:10:51.960 --> 00:10:54.860]   with this kind of decision making investments.
[00:10:54.860 --> 00:10:59.100]   Investing is another, but there's all obviously a huge influence of luck on the way that your
[00:10:59.100 --> 00:11:00.220]   investments turn out.
[00:11:00.220 --> 00:11:01.220]   Just look at the pandemic.
[00:11:01.220 --> 00:11:02.780]   Nobody had control over that.
[00:11:02.780 --> 00:11:03.780]   Right.
[00:11:03.780 --> 00:11:08.340]   And it had all sorts of effects on the stock market supply chain issues, which I don't
[00:11:08.340 --> 00:11:09.340]   control.
[00:11:09.340 --> 00:11:10.340]   You said there are a few things you can do.
[00:11:10.340 --> 00:11:15.820]   It's like, I now feel like I totally get why the decision just might not, I might be outside
[00:11:15.820 --> 00:11:19.060]   of my control, but it seems like there's a part of it that is in your control.
[00:11:19.060 --> 00:11:20.060]   Oh, there is.
[00:11:20.060 --> 00:11:21.060]   Yeah.
[00:11:21.060 --> 00:11:24.180]   And so what's, that's the piece that I, let's dive into.
[00:11:24.180 --> 00:11:27.080]   So let's talk about what are the things that you can do.
[00:11:27.080 --> 00:11:30.900]   So the first thing you can do is make yourself familiar with a concept called base rates.
[00:11:30.900 --> 00:11:32.840]   This is really, really important.
[00:11:32.840 --> 00:11:36.600]   So if we go to that first thing that I said, that we're not very good at understanding
[00:11:36.600 --> 00:11:41.400]   what the probability of any event occurring is, know your base rates.
[00:11:41.400 --> 00:11:42.480]   What's a base rate?
[00:11:42.480 --> 00:11:46.520]   A base rate is how often something occurs in a situation similar to the one that you're
[00:11:46.520 --> 00:11:47.520]   considering.
[00:11:47.520 --> 00:11:48.520]   Simple.
[00:11:48.520 --> 00:11:49.520]   All right.
[00:11:49.520 --> 00:11:54.680]   So I'll give you a really simple example of a base rate.
[00:11:54.680 --> 00:11:57.040]   So let's just take your morning routine, right?
[00:11:57.040 --> 00:12:01.760]   You're trying to decide when to wake up because you need to decide how long does it take me
[00:12:01.760 --> 00:12:06.120]   to get ready in the morning so that I know when I need to get into my car in order to
[00:12:06.120 --> 00:12:07.120]   get to work on time.
[00:12:07.120 --> 00:12:11.600]   So this is something that people do, you know, every morning, at least before the pandemic,
[00:12:11.600 --> 00:12:15.680]   before we're all online, there's a whole bunch of base rates involved in there, right?
[00:12:15.680 --> 00:12:19.840]   So one is how long does it, on average, take me to get ready?
[00:12:19.840 --> 00:12:20.840]   Okay.
[00:12:20.840 --> 00:12:23.280]   So I could figure that out.
[00:12:23.280 --> 00:12:28.200]   I could track that for you over a certain period of time and figure out on average how
[00:12:28.200 --> 00:12:29.360]   long it takes you to get ready.
[00:12:29.360 --> 00:12:32.280]   I could even figure out a lower bound and an upper bound.
[00:12:32.280 --> 00:12:37.440]   That's going to tell you sort of like something about risk, what's the volatility.
[00:12:37.440 --> 00:12:41.120]   And then you can sort of figure out for yourself how much risk you want to take on, like how
[00:12:41.120 --> 00:12:45.340]   important is it for you to get to where you're going exactly on time?
[00:12:45.340 --> 00:12:49.520]   You would want to be at a sort of account for the upper bound of how long it takes you
[00:12:49.520 --> 00:12:50.520]   to get ready.
[00:12:50.520 --> 00:12:55.140]   Um, if you have some slack in there, you could account for the lower bound of how long it
[00:12:55.140 --> 00:12:58.120]   takes you to get ready, but we can figure out on average, how long does it take you
[00:12:58.120 --> 00:12:59.120]   to get ready?
[00:12:59.120 --> 00:13:04.280]   And in fact, when you're deciding when to set your alarm, that's included in your decision,
[00:13:04.280 --> 00:13:05.280]   just not explicitly.
[00:13:05.280 --> 00:13:06.280]   Right.
[00:13:06.280 --> 00:13:12.080]   Then when we think about, okay, I got to get in my car and figure out, you know, when do
[00:13:12.080 --> 00:13:14.200]   I need to be in my car in order to go to work?
[00:13:14.200 --> 00:13:17.820]   That's another base rate that we're considering, which is on average, how long does it take
[00:13:17.820 --> 00:13:21.060]   me to get to work on the route that I'm considering taking?
[00:13:21.060 --> 00:13:22.060]   Right.
[00:13:22.060 --> 00:13:23.060]   Okay.
[00:13:23.060 --> 00:13:24.060]   So that's for you personally.
[00:13:24.060 --> 00:13:26.780]   We could figure out those base rates, but there's all sorts of base rates in the world
[00:13:26.780 --> 00:13:27.780]   as well.
[00:13:27.780 --> 00:13:28.780]   Right.
[00:13:28.780 --> 00:13:29.780]   What?
[00:13:29.780 --> 00:13:33.740]   Like I gave you one just a second ago, depending on how you cut the data, uh, your chances
[00:13:33.740 --> 00:13:38.860]   of success, a successful hire about 50, 50, that's a base rate.
[00:13:38.860 --> 00:13:44.400]   So when I'm sitting here thinking, um, you know, in that, what we talked about, like
[00:13:44.400 --> 00:13:49.360]   being overoptimistic, illusion of control, overconfidence, those kinds of things.
[00:13:49.360 --> 00:13:54.280]   When I'm saying I'm a great person at hiring, when I talk to someone, I can look into their
[00:13:54.280 --> 00:13:58.960]   eyes and I can figure out whether they're going to be a good fit or not.
[00:13:58.960 --> 00:14:00.920]   And I'm great at this.
[00:14:00.920 --> 00:14:04.520]   So you say to me, well, what do you think the probability is when you hire for this
[00:14:04.520 --> 00:14:08.920]   role that it's going to work out and I say, oh, I think it's going to work out 90% of
[00:14:08.920 --> 00:14:10.280]   the time.
[00:14:10.280 --> 00:14:15.040]   Well, that's too far away from the base rate to be sane.
[00:14:15.040 --> 00:14:18.640]   So what base rates do is they give us a starting point for the forecast that we're going to
[00:14:18.640 --> 00:14:19.640]   make, right?
[00:14:19.640 --> 00:14:23.720]   That forecast of what's the probability that things will work out one way or another.
[00:14:23.720 --> 00:14:29.640]   Um, and if I know that the base rate is about 50, 50, and I'm estimating that I'm going
[00:14:29.640 --> 00:14:36.600]   to successfully hire 90% of the time, I need to discipline myself to that base rate.
[00:14:36.600 --> 00:14:42.560]   Now maybe I am better than the average bear, but I can't be that much better than the average
[00:14:42.560 --> 00:14:43.560]   bear.
[00:14:43.560 --> 00:14:44.560]   Right?
[00:14:44.560 --> 00:14:45.560]   That's the thing.
[00:14:45.560 --> 00:14:47.160]   So, so maybe I can say like, Ooh, I'm great.
[00:14:47.160 --> 00:14:51.040]   I'll be 60%, but notice how far that is away from 90%.
[00:14:51.040 --> 00:14:53.400]   So it's just disciplining you to the base right now.
[00:14:53.400 --> 00:14:57.480]   I actually do research on this with Phil Tetlock who wrote super forecasting along with his
[00:14:57.480 --> 00:15:00.000]   collaborator and wife, Barb Mellors.
[00:15:00.000 --> 00:15:04.120]   And this is the single most important thing we found in getting people to be better estimators
[00:15:04.120 --> 00:15:08.520]   of sort of probabilities and outcomes in the future is to teach them about race rates and
[00:15:08.520 --> 00:15:12.520]   start to discipline their guests, give them that starting point of a base rate.
[00:15:12.520 --> 00:15:15.600]   So that's the first thing that you can do for anything you're considering, try to figure
[00:15:15.600 --> 00:15:19.840]   out what's the base rate, uh, what's the appropriate reference class, right?
[00:15:19.840 --> 00:15:24.160]   So if I want to figure out how long it's going to take me to get to work and I live in Philadelphia,
[00:15:24.160 --> 00:15:27.240]   I shouldn't ask how long it takes people to get to work in Cincinnati.
[00:15:27.240 --> 00:15:28.520]   It doesn't have anything to do with me.
[00:15:28.520 --> 00:15:29.520]   Right.
[00:15:29.520 --> 00:15:31.760]   So you want to get the right group that you're comparing to.
[00:15:31.760 --> 00:15:38.080]   Um, so like if I'm thinking about hiring, I could look at, uh, averages for all hires,
[00:15:38.080 --> 00:15:44.960]   but if say, um, uh, a SAS startup, I can look at average turnover at SAS startups, right?
[00:15:44.960 --> 00:15:47.500]   And that gives me a really good base rate to start from.
[00:15:47.500 --> 00:15:49.840]   So that's piece number one is know your base rate.
[00:15:49.840 --> 00:15:53.200]   So that has to do with seeing that look really clearly.
[00:15:53.200 --> 00:15:57.400]   Piece number two is improve the quality of the information that you're getting.
[00:15:57.400 --> 00:16:02.880]   And the way to do that, honestly, the best way that you can do that is to start gathering
[00:16:02.880 --> 00:16:06.120]   independent viewpoints on the problem that you're considering.
[00:16:06.120 --> 00:16:07.120]   Okay.
[00:16:07.120 --> 00:16:10.120]   So we can go back to the hiring example.
[00:16:10.120 --> 00:16:17.200]   When you're thinking about creating the job description, um, gather, figure out a group
[00:16:17.200 --> 00:16:22.280]   of people that are going to be on the hiring committee and are appropriate to be giving
[00:16:22.280 --> 00:16:25.160]   input into what you think that role requires.
[00:16:25.160 --> 00:16:31.120]   So let's say we're talking about like a C-level executive, let's say it's like a CRO, right?
[00:16:31.120 --> 00:16:35.360]   We would, you know, want maybe the CMO to be involved.
[00:16:35.360 --> 00:16:40.960]   Certainly the CEO, um, you may want the chief product officer involved, you want customer
[00:16:40.960 --> 00:16:45.480]   success involved, uh, you want people who are doing enablement, so on and so forth.
[00:16:45.480 --> 00:16:48.520]   So you want to get the people who are sort of like in that function.
[00:16:48.520 --> 00:16:52.060]   And then the leaders that that person, the other leaders, that person is going to be
[00:16:52.060 --> 00:16:53.060]   interacting with.
[00:16:53.060 --> 00:16:57.320]   So you figure out who the people are that you think should give input on this.
[00:16:57.320 --> 00:17:00.320]   And when it's a personal decision, because I, you know, like, let's say I'm trying to
[00:17:00.320 --> 00:17:02.160]   decide if I should buy a house.
[00:17:02.160 --> 00:17:05.560]   Do I build a group of people that I get feedback from?
[00:17:05.560 --> 00:17:09.680]   Or how do you apply that to a normal kind of non-professional decision where there's
[00:17:09.680 --> 00:17:10.680]   teams involved?
[00:17:10.680 --> 00:17:16.840]   Yes, a hundred percent, you should find people that you get opinions from, but here's the
[00:17:16.840 --> 00:17:17.840]   really important thing.
[00:17:17.840 --> 00:17:23.920]   So what I was about to say is you need to ask them independently and asynchronously.
[00:17:23.920 --> 00:17:28.120]   So you just send out to them, write a job description for C level.
[00:17:28.120 --> 00:17:29.120]   You would have them write a job.
[00:17:29.120 --> 00:17:33.480]   You know, you would do a little more work, write a job description, what, uh, describe
[00:17:33.480 --> 00:17:37.620]   this person to a recruiter, and you're asking them to do this all independently.
[00:17:37.620 --> 00:17:42.240]   What are the near term challenges, near term opportunities, far term challenges, far, you
[00:17:42.240 --> 00:17:43.240]   know, things like that.
[00:17:43.240 --> 00:17:47.960]   So you're just asking for, tell me independently what you think this role should be.
[00:17:47.960 --> 00:17:49.960]   Now, why are you asking them independently?
[00:17:49.960 --> 00:17:51.920]   Because otherwise they're going to influence each other.
[00:17:51.920 --> 00:17:52.920]   Okay.
[00:17:52.920 --> 00:17:58.080]   So when you're asking for yourself, your own self, you want to use that same principle
[00:17:58.080 --> 00:18:01.320]   of how do I get independent information?
[00:18:01.320 --> 00:18:06.200]   And that's to say, um, um, you give them a bunch of facts.
[00:18:06.200 --> 00:18:08.840]   I'm thinking about buying a house.
[00:18:08.840 --> 00:18:12.580]   I assume you're currently renting in that case, maybe I'm currently renting.
[00:18:12.580 --> 00:18:14.480]   This is the location I rent in.
[00:18:14.480 --> 00:18:19.640]   This is, uh, how much money I pay in rent and utilities.
[00:18:19.640 --> 00:18:22.280]   Uh, this is how much I'm making.
[00:18:22.280 --> 00:18:25.080]   This is the estimate that I have of my job stability.
[00:18:25.080 --> 00:18:32.040]   Uh, here's the area that I'm thinking about, um, buying in, um, whatever you give them
[00:18:32.040 --> 00:18:33.040]   the facts.
[00:18:33.040 --> 00:18:38.360]   Now notice nowhere have I said, but here's my concern, right?
[00:18:38.360 --> 00:18:41.000]   Like renting gives me all sorts of flexibility.
[00:18:41.000 --> 00:18:46.180]   If I get a house and I'm kind of tied down to that house and what if I don't like it?
[00:18:46.180 --> 00:18:52.580]   And uh, I'm thinking that maybe, um, given the percentage of my total net worth that
[00:18:52.580 --> 00:18:55.700]   I would have to put into the house, it's too much, which is the way that I would normally
[00:18:55.700 --> 00:18:56.700]   ask.
[00:18:56.700 --> 00:19:00.260]   You know, like if you're sort of left to your own devices, that's the way you ask things
[00:19:00.260 --> 00:19:04.140]   in the simplest sense of, if I say to you, like, I thought Queens gambit was like such
[00:19:04.140 --> 00:19:05.140]   a great show.
[00:19:05.140 --> 00:19:06.140]   What did you think?
[00:19:06.140 --> 00:19:07.140]   Right?
[00:19:07.140 --> 00:19:08.140]   Like you've done that before.
[00:19:08.140 --> 00:19:09.140]   Yeah.
[00:19:09.140 --> 00:19:10.140]   We all do that.
[00:19:10.140 --> 00:19:11.140]   We all are very confident.
[00:19:11.140 --> 00:19:15.460]   But what instead of what you want to say is, did you watch Queens gambit?
[00:19:15.460 --> 00:19:17.460]   And you say, yes, I assume.
[00:19:17.460 --> 00:19:18.460]   Yes.
[00:19:18.460 --> 00:19:20.500]   And then I say, what did you think of it?
[00:19:20.500 --> 00:19:23.940]   And I completely withhold my opinion from you.
[00:19:23.940 --> 00:19:25.660]   Now this is really hard to do.
[00:19:25.660 --> 00:19:27.340]   It's incredibly unnatural.
[00:19:27.340 --> 00:19:32.500]   We think about our opinion as being important data for the other person to have.
[00:19:32.500 --> 00:19:37.300]   But the issue is that the opinion that I'm about to offer you is actually the information
[00:19:37.300 --> 00:19:40.060]   that I'm trying to get from you.
[00:19:40.060 --> 00:19:45.100]   So if I give you my opinion first, I'm not going to get your opinion in a way that's
[00:19:45.100 --> 00:19:47.220]   actually going to be helpful for me.
[00:19:47.220 --> 00:19:51.500]   So instead, what I want to do is just offer you up the facts that you need in order to
[00:19:51.500 --> 00:19:58.700]   give me a good opinion and then just get your opinion back in it in a uncontaminated way.
[00:19:58.700 --> 00:20:02.380]   So when I say I'm currently renting and this is how much my rent is, and this is my family
[00:20:02.380 --> 00:20:09.620]   situation, and this is how much money I have saved, and this is how much I make, and I'm
[00:20:09.620 --> 00:20:14.620]   thinking about buying a house, I would just love your opinion on that.
[00:20:14.620 --> 00:20:15.620]   Tell me what you know.
[00:20:15.620 --> 00:20:16.620]   Tell me what you think.
[00:20:16.620 --> 00:20:21.140]   So I've given you the facts that you need, and now you can tell me all sorts of things
[00:20:21.140 --> 00:20:22.940]   about what you think.
[00:20:22.940 --> 00:20:27.580]   And what you want to do is get a good range of people who have kind of differing schools
[00:20:27.580 --> 00:20:33.980]   of thought, if possible, and find out what they think.
[00:20:33.980 --> 00:20:36.260]   And then explore that.
[00:20:36.260 --> 00:20:37.900]   And then you'll have collected all the data.
[00:20:37.900 --> 00:20:43.380]   You can go back to them and say, well, I had another opinion that was kind of saying this.
[00:20:43.380 --> 00:20:46.100]   I'd love to hear what you think about that.
[00:20:46.100 --> 00:20:49.740]   But you've allowed them to express themselves in a way where they don't have to disagree
[00:20:49.740 --> 00:20:50.740]   with you.
[00:20:50.740 --> 00:20:54.100]   They don't know what you already think, because mostly when we're having conversations, we're
[00:20:54.100 --> 00:20:57.340]   just trying to affirm the other person.
[00:20:57.340 --> 00:21:01.620]   So even if I did disagree with you, or you disagreed with me and you thought The Queen's
[00:21:01.620 --> 00:21:07.300]   Gambit was a terrible show, you would say it in a super nice way.
[00:21:07.300 --> 00:21:09.020]   Instead of me just saying, what did you think of The Queen's Gambit?
[00:21:09.020 --> 00:21:10.860]   And you're like, oh, that's horrible.
[00:21:10.860 --> 00:21:13.080]   Yeah, it's much more stressful on the other side.
[00:21:13.080 --> 00:21:15.900]   Someone asks you a question with no opinion, you're like, oh, I don't know what to say.
[00:21:15.900 --> 00:21:16.900]   Do I want to?
[00:21:16.900 --> 00:21:17.900]   I don't want to offend them.
[00:21:17.900 --> 00:21:18.900]   Right.
[00:21:18.900 --> 00:21:19.900]   You have to give people permission to do that.
[00:21:19.900 --> 00:21:22.500]   Say, look, I'm really trying to just get your opinion here, so I'm not going to tell you
[00:21:22.500 --> 00:21:23.500]   what I think.
[00:21:23.500 --> 00:21:27.500]   Because this is a really tough decision for me, and I need your help.
[00:21:27.500 --> 00:21:30.580]   Understanding the base rate so you kind of have a sense of what you're expecting, which
[00:21:30.580 --> 00:21:36.020]   I guess we can get into how that might affect resulting in the future, knowing that you
[00:21:36.020 --> 00:21:41.220]   had an opinion and you weren't as far off and you don't judge your decision incorrectly.
[00:21:41.220 --> 00:21:46.420]   And then asking people with kind of a more objective manner to get their feedback.
[00:21:46.420 --> 00:21:50.180]   Any other big things to make a better decision?
[00:21:50.180 --> 00:21:51.180]   Yeah.
[00:21:51.180 --> 00:21:53.860]   So, well, do you want personal or business?
[00:21:53.860 --> 00:21:57.100]   I think personal is probably going to be much more relevant.
[00:21:57.100 --> 00:21:58.100]   Right.
[00:21:58.100 --> 00:22:02.700]   So improve the quality of your decisions as much as possible.
[00:22:02.700 --> 00:22:07.260]   Try to write things down that you're deciding about.
[00:22:07.260 --> 00:22:12.340]   Get other people, trusted advisors, particularly people who have different points of view with
[00:22:12.340 --> 00:22:14.980]   you are really important.
[00:22:14.980 --> 00:22:16.020]   Here's a really important one.
[00:22:16.020 --> 00:22:19.020]   You have to give permission.
[00:22:19.020 --> 00:22:25.300]   So when we're trying to seek information from other people, we think that permission is
[00:22:25.300 --> 00:22:30.980]   implied for them to say whatever to us, but we have to actually offer that permission
[00:22:30.980 --> 00:22:33.420]   and they have to be willing to give it to us.
[00:22:33.420 --> 00:22:37.860]   So I'm sure this has happened to you.
[00:22:37.860 --> 00:22:42.780]   You like fire someone or you break up with somebody or whatever.
[00:22:42.780 --> 00:22:47.100]   And as soon as you do that, you have a whole bunch of friends who say, "Oh, I'm so glad
[00:22:47.100 --> 00:22:48.100]   you did that.
[00:22:48.100 --> 00:22:50.540]   I thought you should have done that like six months ago."
[00:22:50.540 --> 00:22:52.980]   Has that one happened to you?
[00:22:52.980 --> 00:22:56.900]   That one hasn't because my wife and I started dating, oh gosh, 2004.
[00:22:56.900 --> 00:23:00.420]   So it's been a long time since I've had that conversation.
[00:23:00.420 --> 00:23:02.540]   I'm sure it has, but boy, has it been a while.
[00:23:02.540 --> 00:23:07.940]   But like, or you fire someone or you quit your job or whatever.
[00:23:07.940 --> 00:23:12.140]   And people say, I bet you might've said it to somebody when they break up, like, "Oh,
[00:23:12.140 --> 00:23:15.500]   I'm so happy because really wish you would've done that sooner."
[00:23:15.500 --> 00:23:22.800]   So this is like a really common thing that happens, you know, "Oh, I'm so happy you quit
[00:23:22.800 --> 00:23:23.800]   your job.
[00:23:23.800 --> 00:23:25.020]   Like you were so miserable every single day.
[00:23:25.020 --> 00:23:28.020]   I knew you should have done that like a long time ago."
[00:23:28.020 --> 00:23:33.420]   And your thought when people say that to you is, "Okay, but like, why didn't you tell me?"
[00:23:33.420 --> 00:23:38.360]   And the answer is because there wasn't any explicit permission given.
[00:23:38.360 --> 00:23:42.780]   So in order to really find out what somebody thinks, you have to give them permission to
[00:23:42.780 --> 00:23:43.780]   say what they think.
[00:23:43.780 --> 00:23:44.780]   Yeah.
[00:23:44.780 --> 00:23:49.060]   I saw this so much in venture capital that I would be in meetings with other venture
[00:23:49.060 --> 00:23:54.220]   investors and they'd give feedback to founders saying, "Oh, I think it's like pretty good,
[00:23:54.220 --> 00:23:55.220]   but it's not a good fit."
[00:23:55.220 --> 00:23:57.620]   And then after they'd turn to me and be like, "God, that company's horrible.
[00:23:57.620 --> 00:23:58.620]   It's terrible."
[00:23:58.620 --> 00:24:02.180]   I was like, "We should have just told him that."
[00:24:02.180 --> 00:24:05.660]   And I think everyone feels bad telling them that.
[00:24:05.660 --> 00:24:09.140]   And now every time someone asks me for feedback on their startup, I'm like, "How honest do
[00:24:09.140 --> 00:24:10.140]   you want me to be?"
[00:24:10.140 --> 00:24:12.900]   Like, "Do you want me to tell you to quit?"
[00:24:12.900 --> 00:24:18.980]   So I guess if you're on the other side, you can also invite someone to invite you to be
[00:24:18.980 --> 00:24:20.540]   more honest and give critical feedback.
[00:24:20.540 --> 00:24:21.540]   Yeah.
[00:24:21.540 --> 00:24:23.060]   So I actually do that with my friends.
[00:24:23.060 --> 00:24:30.020]   I'm like, "Are we having a conversation where you want advice or where you're just offloading
[00:24:30.020 --> 00:24:31.020]   your emotions?"
[00:24:31.020 --> 00:24:33.220]   Because I want to know, right?
[00:24:33.220 --> 00:24:36.580]   Because sometimes they don't really want your advice.
[00:24:36.580 --> 00:24:37.860]   So I think that's really important.
[00:24:37.860 --> 00:24:39.620]   I mean, I think that's just really important.
[00:24:39.620 --> 00:24:47.620]   I think Ron Conway, who founded SV Angel, is such a good example of doing this really
[00:24:47.620 --> 00:24:50.860]   well, being a very good decision coach to somebody.
[00:24:50.860 --> 00:24:55.500]   So he would actually tell the companies what he thought of them.
[00:24:55.500 --> 00:25:00.100]   But he would sit down and he'd basically say like, "I think we can admit this isn't working."
[00:25:00.100 --> 00:25:03.820]   As opposed to, "It seems pretty good.
[00:25:03.820 --> 00:25:04.820]   Just keep going."
[00:25:04.820 --> 00:25:08.060]   He'd be like, "Look, it's not working."
[00:25:08.060 --> 00:25:13.100]   And invariably the founders would push back on him and say, "No, but I know we can turn
[00:25:13.100 --> 00:25:14.100]   it around."
[00:25:14.100 --> 00:25:16.300]   So it wasn't so much disagreement that it wasn't working, because I think everybody
[00:25:16.300 --> 00:25:19.780]   knows when things aren't working very well, but it was always, "No, but we can turn it
[00:25:19.780 --> 00:25:20.780]   around."
[00:25:20.780 --> 00:25:26.100]   So he was trying to coach them into letting go.
[00:25:26.100 --> 00:25:28.720]   And founders are gritty by nature.
[00:25:28.720 --> 00:25:30.540]   Of course they don't want to let go.
[00:25:30.540 --> 00:25:36.240]   So when they said, "No, but I think I can turn it around," his tactic was not to disagree
[00:25:36.240 --> 00:25:43.620]   with them, which I think would have just caused a rift, but to say, "Okay, tell me exactly
[00:25:43.620 --> 00:25:47.020]   what turning it around looks like."
[00:25:47.020 --> 00:25:50.540]   So let's think about the next two months.
[00:25:50.540 --> 00:25:53.060]   So you're saying you're going to turn this around.
[00:25:53.060 --> 00:25:54.340]   What exactly does that look like?
[00:25:54.340 --> 00:25:57.300]   And try to figure out what those benchmarks are.
[00:25:57.300 --> 00:26:01.740]   Now he would sit down and do that with the founder so that the founder now owned that
[00:26:01.740 --> 00:26:03.780]   along with Ron Conway.
[00:26:03.780 --> 00:26:08.020]   And this is a really good trick for decision-making is that often your decision-making is at its
[00:26:08.020 --> 00:26:11.980]   worst when you're trying to make the decision right then, like when you're actually facing
[00:26:11.980 --> 00:26:13.340]   the decision down.
[00:26:13.340 --> 00:26:17.220]   And this is something that really improves decision quality is to think in advance.
[00:26:17.220 --> 00:26:19.860]   As much as possible, do advanced planning on your decisions.
[00:26:19.860 --> 00:26:21.140]   It's much more efficient.
[00:26:21.140 --> 00:26:22.340]   It creates much better decisions.
[00:26:22.340 --> 00:26:24.260]   So that's essentially what he's doing in this moment.
[00:26:24.260 --> 00:26:28.140]   He's saying, "Let's think about two months ago, two months from now, rather.
[00:26:28.140 --> 00:26:31.900]   So we're going to think about two months from now or three months from now, the end of the
[00:26:31.900 --> 00:26:33.660]   next quarter.
[00:26:33.660 --> 00:26:36.620]   Let's think about what this is going to look like when you've turned it around."
[00:26:36.620 --> 00:26:40.220]   And then basically just set a set of benchmarks.
[00:26:40.220 --> 00:26:44.980]   And then in three months, you can sit down with them and say, "But you haven't hit them."
[00:26:44.980 --> 00:26:46.580]   And we agreed that that's what it looked like.
[00:26:46.580 --> 00:26:49.780]   And that actually makes those decisions a lot cleaner.
[00:26:49.780 --> 00:26:52.860]   And you can do that with your personal decisions as well, right?
[00:26:52.860 --> 00:26:53.860]   Like if you ever...
[00:26:53.860 --> 00:26:58.980]   We're all in these situations, like you have a relationship where it's just not going well,
[00:26:58.980 --> 00:27:00.820]   but you feel like you can turn it around.
[00:27:00.820 --> 00:27:04.500]   You feel like you have so much time invested and you do love the person, but you're like
[00:27:04.500 --> 00:27:08.340]   unhappy, but you know you can make it change.
[00:27:08.340 --> 00:27:11.020]   There's kind of two things to do.
[00:27:11.020 --> 00:27:13.520]   Don't face the decision down right then.
[00:27:13.520 --> 00:27:17.260]   Figure out, "But what does change look like?"
[00:27:17.260 --> 00:27:22.980]   So at that moment, say, "How long am I willing to tolerate the status quo, the way that the
[00:27:22.980 --> 00:27:26.820]   relationship is right now or worse?
[00:27:26.820 --> 00:27:30.260]   What do I need to do, do I think, in order to turn this around?"
[00:27:30.260 --> 00:27:34.620]   And then however long that is that you're willing to tolerate the status quo, figure
[00:27:34.620 --> 00:27:40.780]   out at the end of that time period, say it's six months, what does change look like?
[00:27:40.780 --> 00:27:44.340]   What will it look like when things have actually turned around here?
[00:27:44.340 --> 00:27:46.020]   You can do this for a job, right?
[00:27:46.020 --> 00:27:48.740]   A job that you're miserable in, what do I need to do?
[00:27:48.740 --> 00:27:50.740]   What will it look like that it's actually turned around?
[00:27:50.740 --> 00:27:52.260]   What will have changed?
[00:27:52.260 --> 00:27:56.740]   And the reason that you need to do that is because when you're actually facing down the
[00:27:56.740 --> 00:28:00.300]   decision, that's when you're most likely to be rationalizing things away.
[00:28:00.300 --> 00:28:03.540]   That's when your forecasts are going to be really inaccurate.
[00:28:03.540 --> 00:28:08.500]   That's when the things that you want to be true of the world are going to influence your
[00:28:08.500 --> 00:28:10.540]   actions the most.
[00:28:10.540 --> 00:28:13.980]   It's when everything kind of goes to crap.
[00:28:13.980 --> 00:28:18.180]   And the way that I try to sort of put it to people to get them to understand this is that
[00:28:18.180 --> 00:28:21.500]   you can say all you want that you don't want to eat sugar, but when there's a cupcake right
[00:28:21.500 --> 00:28:24.260]   in front of you, it's really hard to say no.
[00:28:24.260 --> 00:28:29.060]   And that's true, not just of like cupcakes or pizza or whatever that are, you know, it's
[00:28:29.060 --> 00:28:30.060]   sitting right in front of you.
[00:28:30.060 --> 00:28:37.180]   It's also true like when you're facing a breakup or you're facing having to fire an employee,
[00:28:37.180 --> 00:28:43.720]   which isn't fun, or you're facing wanting to quit your job, right?
[00:28:43.720 --> 00:28:47.060]   Or breakup with a friend or whatever.
[00:28:47.060 --> 00:28:51.060]   These things are very hard to do because it's that moment where we're worried about all
[00:28:51.060 --> 00:28:56.780]   the time we've put into something, whether it's that moment where you go from in a state
[00:28:56.780 --> 00:29:02.540]   of failing to having failed, because as long as you keep going, you might turn it around
[00:29:02.540 --> 00:29:08.580]   and not have to actually sort of put that failure on the books.
[00:29:08.580 --> 00:29:12.100]   You know, like if you buy a stock and you bought it at 50 and it goes to 30, as long
[00:29:12.100 --> 00:29:14.060]   as you hold, you could get back to 50.
[00:29:14.060 --> 00:29:15.060]   Yeah.
[00:29:15.060 --> 00:29:17.460]   But selling now is kind of accepting that.
[00:29:17.460 --> 00:29:18.860]   It's accepting that.
[00:29:18.860 --> 00:29:20.180]   And that's really hard for us.
[00:29:20.180 --> 00:29:23.940]   So that's why we want to think about both.
[00:29:23.940 --> 00:29:30.020]   How do we ask for permission for people to tell us the truth?
[00:29:30.020 --> 00:29:34.300]   How do we explicitly ask people if they want the truth, right?
[00:29:34.300 --> 00:29:37.620]   So we need to have both of those things going on.
[00:29:37.620 --> 00:29:42.660]   And then how do we also figure out how the person can receive the truth?
[00:29:42.660 --> 00:29:46.860]   And that's true whether we're coaching somebody else or we're thinking about how we can do
[00:29:46.860 --> 00:29:47.860]   this for ourselves.
[00:29:48.180 --> 00:29:52.580]   And one of the best ways for us to receive the truth is for us to think about the truth
[00:29:52.580 --> 00:29:54.780]   as something in the future.
[00:29:54.780 --> 00:29:59.700]   So in the investment example, you know, this is a very common thing.
[00:29:59.700 --> 00:30:04.580]   I have some stock and I know I should probably sell it, but now that I want to make sure
[00:30:04.580 --> 00:30:08.700]   it goes up, in advance, obviously it would have been great if I had said, "You know what?
[00:30:08.700 --> 00:30:10.980]   If this gets to this point, I'm going to sell it."
[00:30:10.980 --> 00:30:14.420]   And you could even go as far as to set up the order so that you force yourself to do
[00:30:14.420 --> 00:30:15.420]   it.
[00:30:15.420 --> 00:30:16.420]   Yes, you can put in a stop loss order.
[00:30:16.420 --> 00:30:17.420]   Yes.
[00:30:17.420 --> 00:30:21.740]   If you didn't do that, how do we get past that point?
[00:30:21.740 --> 00:30:24.500]   What can you tell someone or coach someone through it?
[00:30:24.500 --> 00:30:25.500]   Just do it now.
[00:30:25.500 --> 00:30:26.500]   Just do it.
[00:30:26.500 --> 00:30:27.740]   But sometimes that's hard to just do it.
[00:30:27.740 --> 00:30:28.740]   No, no.
[00:30:28.740 --> 00:30:29.740]   I don't mean sell it now.
[00:30:29.740 --> 00:30:31.260]   I mean, put in the order now.
[00:30:31.260 --> 00:30:32.260]   Yeah.
[00:30:32.260 --> 00:30:33.260]   But let's say I'm in the moment.
[00:30:33.260 --> 00:30:35.460]   What does it mean to be trading at it in a week?
[00:30:35.460 --> 00:30:36.460]   Okay.
[00:30:36.460 --> 00:30:39.940]   So you're saying if you're worried now, then set it for a week from now.
[00:30:39.940 --> 00:30:42.220]   Don't try to make the decision today.
[00:30:42.220 --> 00:30:46.700]   Try to make a smaller future decision, even though you're dealing with it in the present.
[00:30:46.700 --> 00:30:49.380]   So look, in an ideal world, you would do it right now.
[00:30:49.380 --> 00:30:50.380]   Yeah.
[00:30:50.380 --> 00:30:51.380]   Right?
[00:30:51.380 --> 00:30:57.220]   And one of the ways that you can do it, one of the ways that you can get to doing it right
[00:30:57.220 --> 00:31:03.620]   now is to ask yourself what you could do with that $30.
[00:31:03.620 --> 00:31:05.740]   So this is a helpful tool.
[00:31:05.740 --> 00:31:08.500]   So you bought it at 50, it's now at 30.
[00:31:08.500 --> 00:31:15.260]   You don't want to sell it because you're worried about losing the $20.
[00:31:15.260 --> 00:31:16.780]   But that $20 is already lost.
[00:31:16.780 --> 00:31:19.980]   So this is something called the sunk cost fallacy.
[00:31:19.980 --> 00:31:21.440]   It's not just about stocks.
[00:31:21.440 --> 00:31:25.700]   It's about like, I'm in a job and I want to quit, but what about all the time and effort
[00:31:25.700 --> 00:31:30.780]   I've put into the job and the onboarding and the training, and then I'll have just wasted
[00:31:30.780 --> 00:31:33.740]   all of that.
[00:31:33.740 --> 00:31:34.740]   It's true of relationships.
[00:31:34.740 --> 00:31:37.140]   It's true of employees that we've hired.
[00:31:37.140 --> 00:31:39.860]   So it's basically true of everything.
[00:31:39.860 --> 00:31:45.500]   It's true, like if you buy a concert ticket, you've now paid for the concert ticket.
[00:31:45.500 --> 00:31:53.660]   There's planning that's gone involved when it's freezing cold and the driving conditions
[00:31:53.660 --> 00:31:55.620]   aren't even safe for you to go to the concert.
[00:31:55.620 --> 00:31:59.100]   You still go because you don't want to have wasted the ticket, even though it's a ridiculous
[00:31:59.100 --> 00:32:00.820]   decision to go.
[00:32:00.820 --> 00:32:01.820]   Okay.
[00:32:01.820 --> 00:32:02.940]   So we know that this is a problem.
[00:32:02.940 --> 00:32:08.020]   So one of the things to do is to shift the frame and say, instead of saying, but I don't
[00:32:08.020 --> 00:32:11.860]   want to lose my $20, say, what could I do with that $30?
[00:32:11.860 --> 00:32:16.540]   So that can be helpful in the moment because what that does is it focuses you on the opportunity
[00:32:16.540 --> 00:32:21.780]   cost of the capital or the opportunity cost of your time, so on and so forth.
[00:32:21.780 --> 00:32:24.580]   What could I use that $30 for?
[00:32:24.580 --> 00:32:27.260]   What could I use this time for?
[00:32:27.260 --> 00:32:30.620]   That kind of assumes that you've made the decision that you know you need to sell it,
[00:32:30.620 --> 00:32:32.340]   you're just struggling with it.
[00:32:32.340 --> 00:32:38.140]   But you highlighted in quit that, let's say sometimes I used to tell people, "Oh, if you're
[00:32:38.140 --> 00:32:39.140]   trying to...
[00:32:39.140 --> 00:32:42.180]   " Let's say you work at Google and you have a ton of Google stock, and I would often tell
[00:32:42.180 --> 00:32:45.580]   people as a financial advisor, I'd say, "You probably don't want all of your money tied
[00:32:45.580 --> 00:32:47.300]   in the same company."
[00:32:47.300 --> 00:32:49.780]   And people would say, "Okay, well, I'm trying to figure out if I should sell it."
[00:32:49.780 --> 00:32:53.900]   And I would ask them, "Well, let's pretend there was a mistake and it all got sold.
[00:32:53.900 --> 00:32:55.520]   Would you want to buy it all?"
[00:32:55.520 --> 00:32:59.340]   And you said in the book that that kind of like Jedi mind trick doesn't really work.
[00:32:59.340 --> 00:33:02.740]   So I'm very curious what we should do instead or maybe why it doesn't work.
[00:33:02.740 --> 00:33:06.820]   - There's two things that you can do instead.
[00:33:06.820 --> 00:33:10.700]   One is advanced planning, which we've just talked about.
[00:33:10.700 --> 00:33:14.260]   So advanced planning combined with a pre-commitment contract.
[00:33:14.260 --> 00:33:17.020]   So essentially you want to set up kill criteria.
[00:33:17.020 --> 00:33:22.220]   What could I observe in the future that would make me want to sell this?
[00:33:22.220 --> 00:33:27.220]   So sometimes you'll discover, "Oh, that's the state of the world today."
[00:33:27.220 --> 00:33:34.340]   And you may sell, but just saying like, "If I were fresh to this decision, what would
[00:33:34.340 --> 00:33:35.340]   I do?"
[00:33:35.340 --> 00:33:38.060]   Doesn't really help you.
[00:33:38.060 --> 00:33:41.100]   So the first thing is that you can think about it.
[00:33:41.100 --> 00:33:43.860]   You can do this advanced planning, you can sell kill criteria.
[00:33:43.860 --> 00:33:47.900]   Kill criteria are just what we've been talking about.
[00:33:47.900 --> 00:33:50.660]   What are the signals that I'm going to see in the future that would tell me that I should
[00:33:50.660 --> 00:33:53.100]   walk away?
[00:33:53.100 --> 00:33:56.340]   This is actually going to get you to walk away sooner.
[00:33:56.340 --> 00:33:59.380]   You won't be perfect, but it will help you do it.
[00:33:59.380 --> 00:34:03.500]   So if you talk about like a stop loss order, for example, people cancel them all the time.
[00:34:03.500 --> 00:34:06.220]   But the thing is not everybody does.
[00:34:06.220 --> 00:34:08.700]   And I might cancel some stop loss orders, but not others.
[00:34:08.700 --> 00:34:13.580]   And that means at least I'm selling some things sooner than I otherwise would have.
[00:34:13.580 --> 00:34:14.900]   So that's good.
[00:34:14.900 --> 00:34:19.260]   So a little bit of progress goes a long way, but we want to always be thinking about kill
[00:34:19.260 --> 00:34:20.660]   criteria.
[00:34:20.660 --> 00:34:26.260]   So that's like I'm so miserable in my job, but I don't want to quit because maybe I have
[00:34:26.260 --> 00:34:30.580]   equity in it or whatever, but it's like the cost benefit doesn't look good to me right
[00:34:30.580 --> 00:34:31.860]   now.
[00:34:31.860 --> 00:34:36.340]   What would have to happen over the next three months in my work that would tell me that
[00:34:36.340 --> 00:34:37.900]   things I've turned things around?
[00:34:37.900 --> 00:34:41.380]   What would I see that would tell me things are still bad?
[00:34:41.380 --> 00:34:46.420]   Write that list of things down and commit to an action associated with any of those
[00:34:46.420 --> 00:34:48.020]   things.
[00:34:48.020 --> 00:34:52.980]   So I think one of the simplest examples of a kill criteria is when people mountain climb
[00:34:52.980 --> 00:34:56.700]   there, something called the turnaround time.
[00:34:56.700 --> 00:35:00.660]   So when you're climbing Everest, they have turnaround times for each day's climb.
[00:35:00.660 --> 00:35:07.300]   So there's base camp, you know, camp one, two, three, and four, four is when you would
[00:35:07.300 --> 00:35:10.940]   actually head towards the summit, but you have to sort of go up and down in between
[00:35:10.940 --> 00:35:15.260]   those camps in order to get acclimated to the altitude.
[00:35:15.260 --> 00:35:18.820]   And for any climb that you do on the day, including summit day, they have a turnaround
[00:35:18.820 --> 00:35:23.520]   time, which is sad because they don't want you to descend in darkness.
[00:35:23.520 --> 00:35:28.840]   So for example, on summit day, when you leave camp four, the turnaround time is 1 PM.
[00:35:28.840 --> 00:35:34.580]   And what that means is that if I'm not at a certain point at 1 PM, then I must turn
[00:35:34.580 --> 00:35:35.580]   around.
[00:35:35.580 --> 00:35:37.820]   Now, why do you set that those times?
[00:35:37.820 --> 00:35:41.100]   Well, because of like summit fever, right?
[00:35:41.100 --> 00:35:46.740]   Because we know that people will continue in very bad circumstances up to the summit,
[00:35:46.740 --> 00:35:50.460]   you know, even when visibility is bad or the climbing conditions aren't good, or there's
[00:35:50.460 --> 00:35:53.500]   a snow storm, there's famous books written about it.
[00:35:53.500 --> 00:35:59.320]   John Krakauer, Into Thin Air, talking about a year when a whole bunch of people got injured
[00:35:59.320 --> 00:36:03.300]   and like four people died, because they just continued up to the summit.
[00:36:03.300 --> 00:36:06.700]   So those turnaround times are meant to make it much more likely that you're actually going
[00:36:06.700 --> 00:36:11.060]   to turn around when it's no longer safe to be climbing.
[00:36:11.060 --> 00:36:14.640]   Knowing that when you're facing that decision down, you're not going to be particularly
[00:36:14.640 --> 00:36:15.640]   good at it.
[00:36:15.640 --> 00:36:21.800]   So that's piece number one is think in advance and set turnaround times for yourself basically.
[00:36:21.800 --> 00:36:24.680]   Thing number two is get a good coach.
[00:36:24.680 --> 00:36:30.560]   So when you're coaching people about Google and their stock, you're giving them an outside
[00:36:30.560 --> 00:36:34.580]   perspective that's more likely to get them to do it today.
[00:36:34.580 --> 00:36:38.880]   So notice they're not saying for themselves, what would I do in this situation?
[00:36:38.880 --> 00:36:42.560]   That's not really the important thing that's going on there.
[00:36:42.560 --> 00:36:46.440]   The important thing is they're getting somebody's perspective, who's been there, done that,
[00:36:46.440 --> 00:36:51.480]   who kind of thinks about equity, who's offering them a perspective that's really important
[00:36:51.480 --> 00:36:57.460]   where they're getting advice that would be similar to the advice they would give somebody
[00:36:57.460 --> 00:37:00.760]   if they could get out of their own head.
[00:37:00.760 --> 00:37:05.360]   So that is really helpful is to get yourself a quitting coach, which is what you're saying
[00:37:05.360 --> 00:37:07.400]   to them there, right?
[00:37:07.400 --> 00:37:11.480]   So that's offering them that perspective that allows them also to sort of get out of the
[00:37:11.480 --> 00:37:12.520]   moment.
[00:37:12.520 --> 00:37:17.600]   What Daniel Kahneman says, the Nobel Laureate is, don't make a decision when you're in it.
[00:37:17.600 --> 00:37:18.600]   Okay?
[00:37:18.600 --> 00:37:22.620]   So notice both of these things are trying to get you to not be in it.
[00:37:22.620 --> 00:37:24.200]   One is to get you to think about the future.
[00:37:24.200 --> 00:37:28.800]   The other is to have somebody looking in from the outside who can allow you, because they're
[00:37:28.800 --> 00:37:34.200]   not in it, to see the way it looks to somebody else.
[00:37:34.200 --> 00:37:37.140]   Or we could think about it a different way, the way it would look if you were standing
[00:37:37.140 --> 00:37:38.480]   in their shoes.
[00:37:38.480 --> 00:37:44.860]   Now, the best thing to do is to combine the two, which is what Ron Conway does.
[00:37:44.860 --> 00:37:46.540]   So he acts as a quitting coach.
[00:37:46.540 --> 00:37:51.520]   He tells them things aren't really working out here, or I think this would be a good
[00:37:51.520 --> 00:37:52.520]   decision.
[00:37:52.520 --> 00:37:56.520]   But when they disagree, he then turns to kill criteria and coaches them through that.
[00:37:56.520 --> 00:38:01.800]   - And is there something to look for in a good quitting coach, like a particular profile
[00:38:01.800 --> 00:38:03.640]   of a friend or a colleague?
[00:38:03.640 --> 00:38:04.640]   - Yeah.
[00:38:04.640 --> 00:38:06.960]   I love the way that Kahneman put it to me.
[00:38:06.960 --> 00:38:12.480]   Find somebody who loves you, but doesn't care much about hurt feelings in the moment.
[00:38:12.480 --> 00:38:15.080]   So his quitting coach is Richard Thaler.
[00:38:15.080 --> 00:38:16.920]   He has a Nobel Laureate for his quitting coach.
[00:38:16.920 --> 00:38:20.320]   - Yeah, I assume most people listening don't have that luxury.
[00:38:20.320 --> 00:38:22.800]   - No, I don't.
[00:38:22.800 --> 00:38:23.800]   But what's he saying there?
[00:38:23.800 --> 00:38:26.600]   Find someone who loves you, but doesn't care much about hurt feelings in the moment.
[00:38:26.600 --> 00:38:29.720]   You need someone who cares about, like who really has your best interest at heart.
[00:38:29.720 --> 00:38:30.720]   Really important.
[00:38:30.720 --> 00:38:33.340]   - But this is not, to be clear, it's not your hype person.
[00:38:33.340 --> 00:38:37.440]   It's not the person you call who's always like pumping you up and giving you compliments.
[00:38:37.440 --> 00:38:40.000]   It's almost like the exact opposite of that.
[00:38:40.000 --> 00:38:45.600]   - Someone who really cares about how you do in life.
[00:38:45.600 --> 00:38:52.920]   Who really is rooting for you, but isn't concerned about hurt feelings in the moment.
[00:38:52.920 --> 00:38:56.180]   Because why don't we tell somebody the things that we see?
[00:38:56.180 --> 00:38:58.800]   Because we're afraid they'll be sad, right?
[00:38:58.800 --> 00:39:01.260]   Who wants to deliver the news to somebody?
[00:39:01.260 --> 00:39:05.100]   When you're talking about the VCs who are like, "Yeah, it's pretty good.
[00:39:05.100 --> 00:39:07.500]   I think you're getting there with the product market fit."
[00:39:07.500 --> 00:39:12.040]   And then the person walks out of the room and they're like, "That's just a dead company
[00:39:12.040 --> 00:39:13.040]   walking."
[00:39:13.040 --> 00:39:14.040]   Right?
[00:39:14.040 --> 00:39:15.040]   And it's like, "Oh, hold on.
[00:39:15.040 --> 00:39:16.040]   Why didn't you tell them?
[00:39:16.040 --> 00:39:17.040]   Why?"
[00:39:17.040 --> 00:39:18.460]   Because they don't want to hurt their feelings.
[00:39:18.460 --> 00:39:24.160]   They don't want to be like the Debbie Downer character from SNL.
[00:39:24.160 --> 00:39:28.500]   But the problem is they're doing a tremendous amount of harm to those founders.
[00:39:28.500 --> 00:39:32.780]   That's the problem is we think that we're sparing them harm.
[00:39:32.780 --> 00:39:36.860]   We think that we're being kind by not telling them the truth right now.
[00:39:36.860 --> 00:39:39.540]   But what we're actually doing is harming them.
[00:39:39.540 --> 00:39:43.340]   Because the founders aren't getting feedback that they need to get, right?
[00:39:43.340 --> 00:39:46.760]   So there's all sorts of things that could come from that feedback.
[00:39:46.760 --> 00:39:49.340]   One is they could stop.
[00:39:49.340 --> 00:39:51.660]   They could return the capital to the investors.
[00:39:51.660 --> 00:39:52.660]   That's a good thing.
[00:39:52.660 --> 00:39:57.660]   That's capital that can be used for other opportunities that might be better, right?
[00:39:57.660 --> 00:39:59.940]   They can free up their time.
[00:39:59.940 --> 00:40:07.740]   Anybody who's a founder is, for the most part, super smart, super driven, really gritty,
[00:40:07.740 --> 00:40:08.740]   right?
[00:40:08.740 --> 00:40:11.460]   And their time is incredibly valuable.
[00:40:11.460 --> 00:40:17.200]   And if they're spending time on something that isn't worth that time, then you are doing
[00:40:17.200 --> 00:40:19.380]   them harm by not letting them know that.
[00:40:19.380 --> 00:40:24.580]   So they could switch and turn their attention to something better, something more worth
[00:40:24.580 --> 00:40:27.620]   their time and their brainpower.
[00:40:27.620 --> 00:40:31.500]   And then the other thing is that it's a real disservice to their employees.
[00:40:31.500 --> 00:40:36.480]   Because the people who are working at a startup, as you know, Chris, are generally working
[00:40:36.480 --> 00:40:39.700]   for very low cash comp, but lots of equity.
[00:40:39.700 --> 00:40:45.260]   So once you determine that the equity isn't worth their time, you ought to free them up.
[00:40:45.260 --> 00:40:50.860]   And what's interesting is that founders will often say, "I owe it to my employees to keep
[00:40:50.860 --> 00:40:51.860]   going."
[00:40:51.860 --> 00:40:56.040]   And it's like, no, but once you've decided that the equity isn't worth their time, you
[00:40:56.040 --> 00:40:59.940]   owe it to them to let them go so that they can go spend their time on something that
[00:40:59.940 --> 00:41:04.180]   might actually be world-changing, where the equity might really matter, right?
[00:41:04.180 --> 00:41:07.620]   Because there's only two reasons that people are willing to do this, because they want
[00:41:07.620 --> 00:41:12.140]   to change the world or they think the equity is going to be worth a lot, or both.
[00:41:12.140 --> 00:41:15.220]   So once you've figured out that none of those things are true, let them go.
[00:41:15.220 --> 00:41:21.380]   So when the VC is trying to spare their feelings, look at all the harm that's coming from that,
[00:41:21.380 --> 00:41:22.620]   right?
[00:41:22.620 --> 00:41:28.140]   You're allowing someone to be a dead company walking for however long until, you know,
[00:41:28.140 --> 00:41:31.500]   I guess they can't raise another round.
[00:41:31.500 --> 00:41:36.340]   That's months and months and months and months, sometimes years, that you're trapping people
[00:41:36.340 --> 00:41:39.260]   in a losing endeavor when you see something else.
[00:41:39.260 --> 00:41:42.860]   And so when you're looking for a quitting coach, this has to do with like that, first
[00:41:42.860 --> 00:41:44.180]   of all, that permission giving.
[00:41:44.180 --> 00:41:47.540]   You have to be clear with the person that you want to hear the truth.
[00:41:47.540 --> 00:41:52.340]   And then you need to go find someone who really has your long-term best interest at heart,
[00:41:52.340 --> 00:41:55.820]   is willing to say the hard things to you because they love you.
[00:41:55.820 --> 00:41:58.220]   - Yeah, I have a few people like that.
[00:41:58.220 --> 00:42:02.780]   For some decisions and then for others, it's a little tough.
[00:42:02.780 --> 00:42:08.740]   I briefly want to go back in time to talk about base rates for a second, 'cause I just
[00:42:08.740 --> 00:42:09.740]   thought as I was-
[00:42:09.740 --> 00:42:10.740]   - Okay, 'cause I love base rates.
[00:42:10.740 --> 00:42:12.220]   It's like my favorite topic, for real.
[00:42:12.220 --> 00:42:16.020]   - Yeah, so when I think about base rates, it reminds me of kind of the whole premise
[00:42:16.020 --> 00:42:21.860]   of thinking in bets, which is that, and really brought to life, the idea of asking someone
[00:42:21.860 --> 00:42:22.860]   to want to bet, right?
[00:42:22.860 --> 00:42:27.580]   Like the fact that we think of these beliefs, we have these ideas that we think are so certain
[00:42:27.580 --> 00:42:32.020]   and we're so confident, I'm gonna hire someone, they're gonna be the best, is really just
[00:42:32.020 --> 00:42:36.660]   thinking about everything in life as a bet and challenging yourself to put certainties
[00:42:36.660 --> 00:42:42.260]   around things, even mundane, silly decisions, kind of the best way to rewire how this all
[00:42:42.260 --> 00:42:43.260]   works in your head?
[00:42:43.260 --> 00:42:45.340]   - Oh, I think so, absolutely.
[00:42:45.340 --> 00:42:46.340]   So here's the thing.
[00:42:46.340 --> 00:42:48.260]   When I say, "Do you want to bet?"
[00:42:48.260 --> 00:42:53.340]   All I'm doing is making you examine the assumptions that are going into your statement.
[00:42:53.340 --> 00:42:56.380]   - Yeah, one for my wife and I is always just like remembering something.
[00:42:56.380 --> 00:43:03.140]   I'm like, "Oh, I'm totally sure that our daughter's preschool is starting next week."
[00:43:03.140 --> 00:43:04.140]   And like-
[00:43:04.140 --> 00:43:05.140]   - Right, do you want to bet?
[00:43:05.140 --> 00:43:07.380]   - My wife didn't ask that, but if she had, I would've been like, "Oh, I don't know if
[00:43:07.380 --> 00:43:10.020]   I want to put all my money on the line."
[00:43:10.020 --> 00:43:13.620]   - Right, because what it makes you think about is like, there's a couple things.
[00:43:13.620 --> 00:43:16.900]   Well, what is the person who's betting me know that I don't know?
[00:43:16.900 --> 00:43:18.460]   So in some sense, when I say, "Want to bet?"
[00:43:18.460 --> 00:43:22.900]   I'm acting a little bit as a coach to you, because I'm telling you that I have a perspective
[00:43:22.900 --> 00:43:24.100]   that is different from yours.
[00:43:24.100 --> 00:43:27.900]   If I'm willing to bet, that means that I'm saying that I believe something different
[00:43:27.900 --> 00:43:28.900]   than you.
[00:43:28.900 --> 00:43:33.260]   Okay, so it's automatically making you start to think like, "Well, what's a different way
[00:43:33.260 --> 00:43:36.320]   to look at this?"
[00:43:36.320 --> 00:43:42.220]   And then you have to start examining like, "Well, exactly how sure am I of this?"
[00:43:42.220 --> 00:43:50.020]   So this is, my husband and I talk like this all the time, where generally where it is,
[00:43:50.020 --> 00:43:52.060]   it's like, "Well, what's the price?"
[00:43:52.060 --> 00:43:54.980]   That's what we end up doing, which is just a way to say, "What's the probability?"
[00:43:54.980 --> 00:44:01.620]   So we don't think about bets as just like dollar for dollar.
[00:44:01.620 --> 00:44:11.460]   He might say that, let's say that it's an election, and you say, "I live in Pennsylvania."
[00:44:11.460 --> 00:44:15.260]   So let's say you say like, "I'm sure John Fetterman's going to win the election."
[00:44:15.260 --> 00:44:18.740]   And someone says, "Want to bet?"
[00:44:18.740 --> 00:44:22.940]   You could immediately say, "Yes," but then the response would be, "Well, what's the price?
[00:44:22.940 --> 00:44:25.460]   What are you willing to, are you willing to lay me a price?
[00:44:25.460 --> 00:44:26.880]   Are you giving me a price?"
[00:44:26.880 --> 00:44:32.460]   So in other words, as an example, if I say to you, "I'll bet $10 for every dollar that
[00:44:32.460 --> 00:44:36.860]   you bet," I'm telling you that I'm very certain that I'm right, because I'm risking a lot
[00:44:36.860 --> 00:44:38.740]   compared to what I can win.
[00:44:38.740 --> 00:44:41.440]   But if I say, "No, no, no, no, no."
[00:44:41.440 --> 00:44:47.040]   So the implied thing, it's like if I say I'm 90% sure of something, I should be willing
[00:44:47.040 --> 00:44:51.020]   to lay you nine to one, $9 for every one, right?
[00:44:51.020 --> 00:44:53.580]   But as soon as I'm like, "What?"
[00:44:53.580 --> 00:44:59.500]   When you say, "Okay, I'll take the nine to one," and I go, "Wait, no, no, no, no, no,"
[00:44:59.500 --> 00:45:05.260]   like even money, then what I'm saying actually is actually I think it's 50/50, and I wasn't
[00:45:05.260 --> 00:45:06.660]   really thinking about it.
[00:45:06.660 --> 00:45:12.060]   So it's like a good way to kind of be like interacting.
[00:45:12.060 --> 00:45:16.100]   And I can tell you that I do this with little things and big things and whatever.
[00:45:16.100 --> 00:45:20.460]   It's actually kind of fun once you start like, "Well, what price do you want to lay?"
[00:45:20.460 --> 00:45:21.460]   And we always bet $1.
[00:45:21.460 --> 00:45:22.460]   It's really fun.
[00:45:22.460 --> 00:45:32.360]   But I think that the thing that's really important about the betting, this is so crucial to good
[00:45:32.360 --> 00:45:39.260]   decision-making, is that it forces you to make the things that are implicit in the decision
[00:45:39.260 --> 00:45:42.920]   you're making explicit, okay?
[00:45:42.920 --> 00:45:49.840]   So as an example, the simplest example is one of the things that is always implicit
[00:45:49.840 --> 00:45:56.840]   in the decision you're making is your forecast of the probability of different things occurring.
[00:45:56.840 --> 00:46:04.400]   In other words, whether you know it or not, base rates are part of the decision-making.
[00:46:04.400 --> 00:46:12.680]   So when I say to you, "I'm going to meet you for dinner at seven o'clock, and I promise
[00:46:12.680 --> 00:46:19.620]   I'll be on time," and you say, "Want a bet," implied in that is that I must have a tendency
[00:46:19.620 --> 00:46:21.520]   to be late.
[00:46:21.520 --> 00:46:25.000]   And the question is, how much of a tendency do I have to be late, and how willing am I
[00:46:25.000 --> 00:46:30.120]   to say to you, "Yes, I'll bet you that I'm going to be on time," right?
[00:46:30.120 --> 00:46:34.680]   So when I say things like that, and then you bet back, those are all things that have to
[00:46:34.680 --> 00:46:38.200]   do with base rates, right?
[00:46:38.200 --> 00:46:42.200]   You could say something like, "I know the stock market is going to go up this year."
[00:46:42.200 --> 00:46:44.400]   Well, that's a prediction of the future.
[00:46:44.400 --> 00:46:48.280]   And if I know the base rates, I may bet you on that, depending on what you're willing
[00:46:48.280 --> 00:46:49.600]   to lay me, right?
[00:46:49.600 --> 00:46:52.800]   Because the stock market goes up actually somewhere between, like, it depends on how
[00:46:52.800 --> 00:46:57.400]   you measure it, 65% and 75% of the years, it will go up.
[00:46:57.400 --> 00:47:01.160]   So if you say, "I'm 100% sure it's going to go up this year," I might bet you.
[00:47:01.160 --> 00:47:02.160]   Because now what I'm doing-
[00:47:02.160 --> 00:47:07.640]   I would take that bet, because there are actually options out there I could use to arbitrage
[00:47:07.640 --> 00:47:09.520]   your confidence.
[00:47:09.520 --> 00:47:10.960]   That is true.
[00:47:10.960 --> 00:47:13.400]   That is very true.
[00:47:13.400 --> 00:47:16.680]   But I'm not involved in the arbitrage, so you could hedge away.
[00:47:16.680 --> 00:47:21.760]   I'm just going to take my bet, and then maybe I'll hedge it as well.
[00:47:21.760 --> 00:47:27.360]   But the point being that when somebody says, "I want to bet," it's like when you say, "I
[00:47:27.360 --> 00:47:31.640]   think this person I'm going to hire is going to work out 90% of the time," and I bet you,
[00:47:31.640 --> 00:47:34.080]   it makes you actually go through and start thinking, "Well, wait a minute.
[00:47:34.080 --> 00:47:36.960]   Why do I believe that?"
[00:47:36.960 --> 00:47:40.880]   Remember one of the things that we want to do in order to improve decision-making is
[00:47:40.880 --> 00:47:44.560]   to start thinking about what's the quality of the beliefs that we have that go into any
[00:47:44.560 --> 00:47:46.840]   decision that we're making.
[00:47:46.840 --> 00:47:50.680]   And part of that is making the implicit explicit.
[00:47:50.680 --> 00:47:54.760]   And this is one of the things that's so incredibly important.
[00:47:54.760 --> 00:47:58.880]   Even talking about a hiring example, where you send out to a bunch of people, "What do
[00:47:58.880 --> 00:48:00.960]   you think the job description should be?
[00:48:00.960 --> 00:48:05.680]   What do you think the person," if you were describing them to a recruiter, and you're
[00:48:05.680 --> 00:48:13.400]   getting that all independently, what you're finding out is, in an explicit way, when they
[00:48:13.400 --> 00:48:17.880]   would otherwise just go and interview somebody, what are the things that they think are important
[00:48:17.880 --> 00:48:20.800]   for filling this role?
[00:48:20.800 --> 00:48:24.360]   And now you've made that explicit in a way that you can, first of all, examine it, which
[00:48:24.360 --> 00:48:26.680]   is incredibly important.
[00:48:26.680 --> 00:48:30.480]   We have to be able to examine our decisions.
[00:48:30.480 --> 00:48:36.160]   And that means that we have to actually make all this stuff that's in our gut explicit
[00:48:36.160 --> 00:48:39.220]   in a way where you can examine it like an object.
[00:48:39.220 --> 00:48:40.400]   You can walk around it.
[00:48:40.400 --> 00:48:43.320]   You can have discussions about it.
[00:48:43.320 --> 00:48:47.560]   I can see that you have a different perspective, and when we see that we have a dispersion
[00:48:47.560 --> 00:48:53.200]   of opinion, we can dive into that dispersion to see where the gaps are, to see why you
[00:48:53.200 --> 00:48:56.200]   believe something different about the world than I do.
[00:48:56.200 --> 00:48:59.760]   And this is the way that we start to learn really fast.
[00:48:59.760 --> 00:49:03.640]   It's the way that we start to get our decisions to be much more accurate.
[00:49:03.640 --> 00:49:09.600]   But there's a side effect of this, of this making things explicit, which is that it allows
[00:49:09.600 --> 00:49:12.560]   us to close feedback loops a lot better.
[00:49:12.560 --> 00:49:17.280]   So now, when we do actually start to get some sort of set of outcomes, when we see an outcome,
[00:49:17.280 --> 00:49:22.800]   we can actually now go back and say, what did I believe at the time when I made this
[00:49:22.800 --> 00:49:24.280]   decision?
[00:49:24.280 --> 00:49:28.040]   And we can understand, here were my beliefs at the time.
[00:49:28.040 --> 00:49:32.160]   Here's what I found out after the fact, right?
[00:49:32.160 --> 00:49:39.960]   Let me go back and figure out, did I already have these outcomes in my set of possibilities?
[00:49:39.960 --> 00:49:44.240]   Do I feel like I had the probabilities right that those were going to occur?
[00:49:44.240 --> 00:49:47.960]   Was there stuff that I learned after the fact that I didn't know beforehand?
[00:49:47.960 --> 00:49:50.160]   Could I have known it beforehand?
[00:49:50.160 --> 00:49:52.520]   Could I know it going forward?
[00:49:52.520 --> 00:50:01.520]   So as an example, if I'm just thinking about when should I leave for work, right?
[00:50:01.520 --> 00:50:07.880]   And I wouldn't write this down because it's a more mundane decision, but I'm actually
[00:50:07.880 --> 00:50:10.320]   explicitly thinking about when should I leave for work?
[00:50:10.320 --> 00:50:12.600]   How long do I think it's going to take for me to be here?
[00:50:12.600 --> 00:50:15.800]   How bad is it if I'm late, right?
[00:50:15.800 --> 00:50:20.600]   And I decide in an explicit way, it's not very bad if I'm late today.
[00:50:20.600 --> 00:50:25.460]   I don't really have any important meetings for the first hour and a half of the morning.
[00:50:25.460 --> 00:50:27.440]   So I've got a little bit of leeway.
[00:50:27.440 --> 00:50:32.120]   So I'm really going to leave according to what the average time it is for me to get
[00:50:32.120 --> 00:50:33.480]   to work.
[00:50:33.480 --> 00:50:40.400]   So now I go and there's some huge accident on the highway and I ended up being 45 minutes
[00:50:40.400 --> 00:50:42.560]   late to work, okay?
[00:50:42.560 --> 00:50:48.000]   So do we look back on that and say that that was a mistake, which is what we have a tendency
[00:50:48.000 --> 00:50:49.000]   to do, right?
[00:50:49.000 --> 00:50:52.320]   Do we look back and say that was so stupid, why did I leave so late?
[00:50:52.320 --> 00:50:55.400]   Well, in this particular case, it wouldn't make sense to do that because you took it
[00:50:55.400 --> 00:50:57.920]   into account, right?
[00:50:57.920 --> 00:51:01.560]   You sort of knew there's some possibility of bad things happening on the road.
[00:51:01.560 --> 00:51:05.880]   You don't really have control over whether there's an accident on the road or not, and
[00:51:05.880 --> 00:51:10.200]   that you had a lot of leeway because it wasn't a big deal if you were late that morning.
[00:51:10.200 --> 00:51:13.700]   So you took all of that into account and then a bad thing happened, but that doesn't mean
[00:51:13.700 --> 00:51:18.120]   that the decision was bad to take that risk on, right?
[00:51:18.120 --> 00:51:24.220]   Whereas if I'm deciding to leave for the airport, I may say, well, I can't miss my flight.
[00:51:24.220 --> 00:51:27.920]   This is the only flight that they have today to the location I'm going.
[00:51:27.920 --> 00:51:33.440]   So now you may leave a lot of time for just that type of thing, like bad traffic or an
[00:51:33.440 --> 00:51:35.520]   accident.
[00:51:35.520 --> 00:51:37.520]   So what are you sacrificing for that?
[00:51:37.520 --> 00:51:41.360]   Well, you may end up spending an extra hour hanging out in the airport, but you make sure
[00:51:41.360 --> 00:51:43.880]   that you get to your plane on time.
[00:51:43.880 --> 00:51:50.160]   Now just as in the reverse case, when there is no traffic and the roads are totally clear
[00:51:50.160 --> 00:51:55.560]   and you get to the airport an hour early and you find yourself sitting around bored in
[00:51:55.560 --> 00:52:01.240]   an airport lounge, you also shouldn't think it was a mistake because in an explicit way,
[00:52:01.240 --> 00:52:03.360]   you thought about what your risk tolerance was.
[00:52:03.360 --> 00:52:08.640]   You thought about the base rates, how long it could take you to get to work, and you
[00:52:08.640 --> 00:52:11.960]   took that all into account when you made the decision.
[00:52:11.960 --> 00:52:15.760]   And this is what we need ultimately in order to be good decision makers.
[00:52:15.760 --> 00:52:20.200]   If you think about in advance the likelihood of the outcome happening, that makes it much
[00:52:20.200 --> 00:52:22.360]   easier to reflect on it.
[00:52:22.360 --> 00:52:27.680]   This happened to me in a situation where we were trying to, I won't go into the details
[00:52:27.680 --> 00:52:32.360]   of it because I could go down a rabbit hole, but we were trying to do something tax efficiently
[00:52:32.360 --> 00:52:35.280]   when we were buying a home and it involved taking some money out of the market.
[00:52:35.280 --> 00:52:38.840]   And I was like, "Okay, we're going to have to take a good chunk of our investments out
[00:52:38.840 --> 00:52:42.860]   of the market for about 60 days."
[00:52:42.860 --> 00:52:47.220]   And data showed about what the return on average is for 60 days.
[00:52:47.220 --> 00:52:53.840]   And so we knew about what we thought we would lose out in those 60 days, and we knew the
[00:52:53.840 --> 00:52:58.800]   upside of going through this entire process to buy the house in this specific way.
[00:52:58.800 --> 00:53:03.960]   And the only X factor was that in those 60 days was our last presidential election.
[00:53:03.960 --> 00:53:07.320]   So we were like, "Oh, we're a little anxious about this because there's this thing that
[00:53:07.320 --> 00:53:10.000]   could really move the markets."
[00:53:10.000 --> 00:53:14.880]   And so at the end of the day, I think time will tell if we stay in this house for more
[00:53:14.880 --> 00:53:17.720]   than seven years, it was a good decision.
[00:53:17.720 --> 00:53:20.920]   But if we don't, I still think it was a good decision.
[00:53:20.920 --> 00:53:23.440]   And even the wording I just used is probably wrong.
[00:53:23.440 --> 00:53:28.000]   If we stay in this house for seven years, it will have been the optimal outcome.
[00:53:28.000 --> 00:53:30.600]   But no matter what, it was the right decision.
[00:53:30.600 --> 00:53:34.200]   And I just have to keep harping on myself when people say, "Oh, is that a bummer?
[00:53:34.200 --> 00:53:35.200]   You might have lost out."
[00:53:35.200 --> 00:53:39.360]   It's like, "Well, I made the best decision with the information I had at the time, and
[00:53:39.360 --> 00:53:41.720]   I can feel good about that as hard as it is."
[00:53:41.720 --> 00:53:42.720]   That's still...
[00:53:42.720 --> 00:53:46.640]   I don't know if you have any tips for getting over that emotional angst of like, it's really
[00:53:46.640 --> 00:53:48.320]   easy to know you made the right decision.
[00:53:48.320 --> 00:53:52.480]   But if the right decision made you lose money, it's still hard to deal with that.
[00:53:52.480 --> 00:53:53.480]   Yeah.
[00:53:53.480 --> 00:53:56.400]   And I mean, the other thing is I assume that you took that into account, right?
[00:53:56.400 --> 00:53:59.980]   There are base rates for how long people stay in their homes as well, right?
[00:53:59.980 --> 00:54:04.680]   So you can say like, "In the worst case scenario, this is how long we would have to be in the
[00:54:04.680 --> 00:54:05.680]   house.
[00:54:05.680 --> 00:54:07.880]   What do we think the probability is that we'd be in the house this long?
[00:54:07.880 --> 00:54:09.880]   In the best case scenario, this is how long we..."
[00:54:09.880 --> 00:54:13.560]   So you take all of that into account, right?
[00:54:13.560 --> 00:54:16.560]   One of the things that I do, again, is to always change the frame.
[00:54:16.560 --> 00:54:18.680]   Well, how would I feel if it had worked out?
[00:54:18.680 --> 00:54:19.680]   Yeah.
[00:54:19.680 --> 00:54:23.880]   I guess in the last presidential election, there's other factors, but just from a financial
[00:54:23.880 --> 00:54:28.600]   standpoint, how would I feel if it worked out?
[00:54:28.600 --> 00:54:34.320]   So one of the things that I always try to think about is, "Oh, but those things go my
[00:54:34.320 --> 00:54:35.320]   way a lot too."
[00:54:35.320 --> 00:54:36.320]   Right?
[00:54:36.320 --> 00:54:46.040]   So I think I'll take a really simple example where I play tennis a lot, and a ball hits
[00:54:46.040 --> 00:54:48.480]   the net court a lot.
[00:54:48.480 --> 00:54:53.640]   And sometimes it plops over to the other side of the court, and sometimes it plops over
[00:54:53.640 --> 00:54:55.440]   to your side of the court.
[00:54:55.440 --> 00:54:58.960]   And this can be on very big points that this happens.
[00:54:58.960 --> 00:55:03.160]   And when it plops back over to your side of the court, you're super sad, and you feel
[00:55:03.160 --> 00:55:05.200]   like you're really unlucky.
[00:55:05.200 --> 00:55:09.560]   But then what I say to myself is, "But it's gone the other way for me at really important
[00:55:09.560 --> 00:55:10.560]   times as well."
[00:55:10.560 --> 00:55:13.680]   So I try to always remember that.
[00:55:13.680 --> 00:55:19.840]   And the question then I try to focus on is, "Did I pick the right shot?
[00:55:19.840 --> 00:55:24.580]   Should I have done something which was going to have more clearance over the net?"
[00:55:24.580 --> 00:55:28.400]   So then I start to think about, "Was it the right choice?"
[00:55:28.400 --> 00:55:32.920]   I try to get back to the decision itself as opposed to just the outcome.
[00:55:32.920 --> 00:55:34.980]   And we do this all the time.
[00:55:34.980 --> 00:55:38.800]   You're talking about a pretty high stakes decision that has to do with financial planning
[00:55:38.800 --> 00:55:43.880]   in-house, but you're taking equal risk by taking it out of the market.
[00:55:43.880 --> 00:55:48.480]   And the thing is that you weren't taking it out of the market because you were guessing
[00:55:48.480 --> 00:55:50.720]   out the outcome of the presidential election.
[00:55:50.720 --> 00:55:54.160]   Now, that I would say that's not so smart, right?
[00:55:54.160 --> 00:55:58.040]   We just know that from the base rates, that that's not trying to time the market doesn't
[00:55:58.040 --> 00:56:00.180]   really work out for people very much.
[00:56:00.180 --> 00:56:04.120]   But you're taking it out for a different reason where you understand what the risks are, that
[00:56:04.120 --> 00:56:07.400]   sometimes it's going to go up, sometimes it's going to go down.
[00:56:07.400 --> 00:56:12.480]   You understand how long you would have to stay in your house in order for it to be a
[00:56:12.480 --> 00:56:16.680]   reasonable decision, so on and so forth.
[00:56:16.680 --> 00:56:20.920]   And you decided that you were willing to take on that risk, I don't have any issues with
[00:56:20.920 --> 00:56:21.920]   that.
[00:56:21.920 --> 00:56:25.320]   Now, that's not to say that you wouldn't close the feedback loop and go back and say, "Would
[00:56:25.320 --> 00:56:34.640]   it have made more sense for us to wait until the presidential election had played out?"
[00:56:34.640 --> 00:56:38.400]   And the answer to that might've been, "But this is the house that we really want.
[00:56:38.400 --> 00:56:42.480]   We've been looking for a long time, and it's kind of go time.
[00:56:42.480 --> 00:56:43.480]   We can't wait."
[00:56:43.480 --> 00:56:48.760]   Okay, right, none of that sounds bad.
[00:56:48.760 --> 00:56:53.920]   The only thing that would be bad is that I had lots and lots and lots of time to wait,
[00:56:53.920 --> 00:56:57.680]   and I didn't need to do this at a moment of high uncertainty.
[00:56:57.680 --> 00:57:01.080]   Then I would say, "Well, maybe we should talk about that issue."
[00:57:01.080 --> 00:57:04.360]   But outside of that, you've thought it through.
[00:57:04.360 --> 00:57:10.640]   But this tendency, when you said, "Then it will have been a mistake, been a bad decision,"
[00:57:10.640 --> 00:57:12.040]   it's so strong with us.
[00:57:12.040 --> 00:57:13.480]   Let me ask you this.
[00:57:13.480 --> 00:57:20.960]   You've gone to a restaurant, and you're looking at the menu, and you're trying to figure out
[00:57:20.960 --> 00:57:21.960]   what to order.
[00:57:21.960 --> 00:57:24.960]   Let's say it's a restaurant you've never been to.
[00:57:24.960 --> 00:57:26.520]   You're trying to figure out what to order.
[00:57:26.520 --> 00:57:30.080]   This is really high uncertainty, like you've never been to this restaurant.
[00:57:30.080 --> 00:57:32.880]   It's got good Yelp reviews.
[00:57:32.880 --> 00:57:37.540]   You're trying to figure out what to order, and you narrow it down to a couple of dishes.
[00:57:37.540 --> 00:57:42.440]   Then at some point, you've just got to order.
[00:57:42.440 --> 00:57:46.760]   You do, and you get the food, and it's disgusting.
[00:57:46.760 --> 00:57:47.760]   It's yucky.
[00:57:47.760 --> 00:57:52.000]   What do you immediately say to yourself, "Oh, I made such a big mistake, I should have ordered
[00:57:52.000 --> 00:57:53.000]   something else"?
[00:57:53.000 --> 00:57:56.560]   What do you mean, you should have ordered something else?
[00:57:56.560 --> 00:58:00.680]   You know what your preferences are, you know what you like.
[00:58:00.680 --> 00:58:07.260]   What I try to tell people is, "Look, you know what you know, and then there's a lot of luck.
[00:58:07.260 --> 00:58:09.560]   You know what you know, there's a whole bunch of stuff you don't know, and then there's
[00:58:09.560 --> 00:58:10.560]   a lot of luck."
[00:58:10.560 --> 00:58:16.340]   Even with something like ordering off a menu, I say, "Just look, here's the deal.
[00:58:16.340 --> 00:58:21.760]   You should just divide the menu up into stuff you like and stuff you don't like."
[00:58:21.760 --> 00:58:22.760]   It's easy for me.
[00:58:22.760 --> 00:58:23.760]   I'm a vegan.
[00:58:23.760 --> 00:58:24.760]   It's like, "What's vegan?
[00:58:24.760 --> 00:58:25.760]   What's not vegan?"
[00:58:25.760 --> 00:58:29.840]   I can divide it up that way, and then I could do further things, like, "What has eggplant
[00:58:29.840 --> 00:58:30.840]   in it?"
[00:58:30.840 --> 00:58:36.720]   Then I get it narrowed down to whatever is available for me to eat off the menu, and
[00:58:36.720 --> 00:58:43.220]   then honestly, you should flip a coin, like literally, just, "Okay, here's the things
[00:58:43.220 --> 00:58:46.000]   that are in my choice set.
[00:58:46.000 --> 00:58:48.680]   I'm just going to flip a coin to try to figure it out."
[00:58:48.680 --> 00:58:51.720]   Now, if you're not comfortable doing that, I'll do this sometimes.
[00:58:51.720 --> 00:58:54.600]   I'll just say to the waiter, "You decide."
[00:58:54.600 --> 00:59:00.200]   It's the same thing as flipping a coin, like, "Oh, here are these two things.
[00:59:00.200 --> 00:59:01.200]   Surprise me."
[00:59:01.200 --> 00:59:02.200]   Yeah.
[00:59:02.200 --> 00:59:06.120]   I did an episode with Patrick McGinnis, who's kind of notable for coining the term FOMO,
[00:59:06.120 --> 00:59:07.440]   and he just looks at his watch.
[00:59:07.440 --> 00:59:08.440]   He comes up with two things.
[00:59:08.440 --> 00:59:10.720]   He says, "If the second hand's on the left, it's this.
[00:59:10.720 --> 00:59:11.880]   If it's on the right, it's this."
[00:59:11.880 --> 00:59:13.600]   It's his version of flipping a coin.
[00:59:13.600 --> 00:59:20.440]   Or you can just tell, like I say, you can tell the wait person to just decide for you,
[00:59:20.440 --> 00:59:22.640]   and then you get what you get, and it's fine.
[00:59:22.640 --> 00:59:27.880]   But that strategy, so I call it the menu strategy, is actually a way to make your whole life
[00:59:27.880 --> 00:59:28.880]   much more efficient.
[00:59:28.880 --> 00:59:32.960]   It's like you're trying to decide what to watch on TV, like figure out what your choice
[00:59:32.960 --> 00:59:35.680]   set is and flip a coin.
[00:59:35.680 --> 00:59:43.720]   The key to doing that is that when you don't like the thing you're watching, quit it.
[00:59:43.720 --> 00:59:45.640]   This is the thing about this type of strategy.
[00:59:45.640 --> 00:59:49.280]   It's like you have to be willing to abandon it.
[00:59:49.280 --> 00:59:55.580]   The problem is that when we're approaching a decision like, "Should we start this series?"
[00:59:55.580 --> 00:59:58.480]   We think we have to finish the series.
[00:59:58.480 --> 01:00:01.520]   We think we have to finish an episode.
[01:00:01.520 --> 01:00:05.400]   We think all of these weird things about it, and so then we get really caught up in trying
[01:00:05.400 --> 01:00:07.920]   to do research, and we're like, "Whatever."
[01:00:07.920 --> 01:00:12.240]   I just look at Rotten Tomatoes and look at the things that are high rated, or things
[01:00:12.240 --> 01:00:18.080]   that my friends have recommended, and then I just do it, and if I don't like it, I stop.
[01:00:18.080 --> 01:00:21.120]   But you have to be able to do the thing on the back end in order to do it, but you can
[01:00:21.120 --> 01:00:23.280]   do this with everything.
[01:00:23.280 --> 01:00:26.480]   There's two houses that you love, and you can't decide between them.
[01:00:26.480 --> 01:00:30.520]   Okay, if you can't decide between them, by definition, that means that your forecast
[01:00:30.520 --> 01:00:35.000]   of the probability of you loving either one and being happy in them is equal.
[01:00:35.000 --> 01:00:37.360]   So flip a coin.
[01:00:37.360 --> 01:00:39.520]   You can really do it with big decisions.
[01:00:39.520 --> 01:00:47.080]   The difference between a big decision and a small decision is that the bar for sorting
[01:00:47.080 --> 01:00:52.920]   out options you would consider versus options you wouldn't is higher.
[01:00:52.920 --> 01:00:55.440]   For what you'd order off a menu, it's not that big a deal.
[01:00:55.440 --> 01:01:00.820]   You eat three meals a day, I assume, whatever.
[01:01:00.820 --> 01:01:03.720]   It's a very low bar for getting to a coin flip.
[01:01:03.720 --> 01:01:07.840]   For buying a house, it's a pretty high bar for getting to a coin flip.
[01:01:07.840 --> 01:01:11.680]   That's all that you need to think about is what's the threshold.
[01:01:11.680 --> 01:01:15.140]   I love this idea, because I have an example I've mentioned in the past of we were going
[01:01:15.140 --> 01:01:19.560]   to Greece, and we found three hotels, and they were all pretty similar, and we were
[01:01:19.560 --> 01:01:20.560]   struggling.
[01:01:20.560 --> 01:01:23.360]   We were like, "Well, does this room look nice in this room?"
[01:01:23.360 --> 01:01:25.760]   Yeah, and it turns into months.
[01:01:25.760 --> 01:01:29.680]   The easy answer was once you've gotten to a point that you're pretty sure all of them
[01:01:29.680 --> 01:01:32.680]   would be fine, just pick one and move on.
[01:01:32.680 --> 01:01:35.760]   But it brings up the bigger question, which is you've written a couple books on decision
[01:01:35.760 --> 01:01:41.120]   making, and then you decided that this one decision of quitting and walking away was
[01:01:41.120 --> 01:01:45.040]   different enough, I assume, that you wrote an entire another book on it that just came
[01:01:45.040 --> 01:01:46.040]   out.
[01:01:46.040 --> 01:01:49.640]   I'm curious what made quitting such a hard decision.
[01:01:49.640 --> 01:01:55.040]   What characterized it so differently that it was worth the follow-up to dig into?
[01:01:55.040 --> 01:01:59.480]   Basically, here's the deal.
[01:01:59.480 --> 01:02:04.720]   What allows us to make decisions under uncertainty is that we have the option to quit.
[01:02:04.720 --> 01:02:07.280]   Just basic.
[01:02:07.280 --> 01:02:12.560]   Imagine if when you hired someone, you could never fire them.
[01:02:12.560 --> 01:02:15.480]   How hard of a decision that would be.
[01:02:15.480 --> 01:02:21.740]   Imagine if as soon as you went on a date with somebody, you had to marry them.
[01:02:21.740 --> 01:02:26.320]   How hard would it be to choose somebody to go on a date with?
[01:02:26.320 --> 01:02:31.940]   Imagine if you rented an apartment, you couldn't get out of the lease, like ever.
[01:02:31.940 --> 01:02:35.520]   These things would become very difficult.
[01:02:35.520 --> 01:02:39.680]   Decision making under uncertainty is really hard, but what allows us to be able to do
[01:02:39.680 --> 01:02:45.960]   it, to be able to choose things when we know so little, is that when we find out new stuff,
[01:02:45.960 --> 01:02:50.480]   whether it's about the world or it's about our own preferences, "Oh, it turns out I don't
[01:02:50.480 --> 01:02:54.720]   like this neighborhood," whatever, that we can quit.
[01:02:54.720 --> 01:02:58.260]   It's a really, really, really important decision.
[01:02:58.260 --> 01:03:03.600]   Having this option to quit is incredibly valuable, but what's interesting is that what the science
[01:03:03.600 --> 01:03:08.480]   tells us is that we're really bad at it.
[01:03:08.480 --> 01:03:09.480]   There's a lot.
[01:03:09.480 --> 01:03:12.720]   Obviously, grit is a really, really popular concept.
[01:03:12.720 --> 01:03:20.560]   People think about grit as character building, in fact, as almost synonymous with character.
[01:03:20.560 --> 01:03:24.360]   It's true that grit's really important for getting you to stick to hard things that are
[01:03:24.360 --> 01:03:25.360]   worthwhile.
[01:03:25.360 --> 01:03:27.000]   That's incredibly important.
[01:03:27.000 --> 01:03:31.400]   We have to not quit things just because they're hard, otherwise we won't ever be successful
[01:03:31.400 --> 01:03:36.440]   at anything because anything worth doing is going to be hard at some point.
[01:03:36.440 --> 01:03:38.120]   That's for sure true.
[01:03:38.120 --> 01:03:43.160]   I think everybody should read Grit, and it's a great book, and Angela Duckworth is brilliant,
[01:03:43.160 --> 01:03:48.640]   but I was missing the other side of the conversation, which is that grit also gets you to stick
[01:03:48.640 --> 01:03:52.160]   to hard things that are not worthwhile.
[01:03:52.160 --> 01:03:54.760]   That's a really huge problem.
[01:03:54.760 --> 01:03:59.920]   We can't think about grit as a virtue and quitting as a vice or a character flaw, because
[01:03:59.920 --> 01:04:05.460]   I can show you lots of circumstances where grit is a character flaw, where sticking to
[01:04:05.460 --> 01:04:12.200]   something too long is bad, like Muhammad Ali boxing for years after he already had symptoms
[01:04:12.200 --> 01:04:15.200]   of Parkinson.
[01:04:15.200 --> 01:04:22.400]   When he was really suffering physically, he should have walked away from the game.
[01:04:22.400 --> 01:04:26.360]   We know that it's very context dependent.
[01:04:26.360 --> 01:04:29.160]   Sometimes quitting is the best thing that you can ever do.
[01:04:29.160 --> 01:04:34.360]   If you're in a job with a toxic boss, or you're in a toxic relationship, or you're at the
[01:04:34.360 --> 01:04:39.560]   top of Everest, and it's past the turnaround time, and there's a snowstorm coming in, clearly
[01:04:39.560 --> 01:04:42.800]   sticking to it is dumb in that situation.
[01:04:42.800 --> 01:04:46.600]   You need to realize that they're the same decision.
[01:04:46.600 --> 01:04:48.480]   One is not good, and one is not bad.
[01:04:48.480 --> 01:04:50.120]   It's very dependent on context.
[01:04:50.120 --> 01:04:55.920]   Then, when you start to look and dive into the scientific literature, it turns out that
[01:04:55.920 --> 01:05:03.740]   there's just a tremendous cognitive forces that make it very hard for us to walk away
[01:05:03.740 --> 01:05:08.920]   from things, not at the right time anyway, all the way from sunk costs, which we've talked
[01:05:08.920 --> 01:05:12.560]   about a little, which is this tendency to stick to things because you're worried you'll
[01:05:12.560 --> 01:05:16.820]   have wasted the time, or the money, or whatever that you put into it, because you want to
[01:05:16.820 --> 01:05:23.360]   get that back somehow, like when you hold on to a stock, or you stay in a job, or whatever.
[01:05:23.360 --> 01:05:26.480]   There's issues that have to do with endowment ownership over things.
[01:05:26.480 --> 01:05:32.160]   We value the things that we own more than the things that we don't, including our beliefs,
[01:05:32.160 --> 01:05:33.600]   by the way.
[01:05:33.600 --> 01:05:38.520]   We don't like to let go of those things that have to do with something called sure loss
[01:05:38.520 --> 01:05:44.000]   aversion, which Daniel Kahneman talks about, which is, as we just said, you have a loss
[01:05:44.000 --> 01:05:45.120]   on the books.
[01:05:45.120 --> 01:05:49.000]   If you quit, it turns it ... I'm sorry, you have a loss on paper rather.
[01:05:49.000 --> 01:05:53.160]   If you quit, it turns into a realized loss.
[01:05:53.160 --> 01:05:54.680]   We don't like that.
[01:05:54.680 --> 01:05:58.320]   That doesn't feel good to us.
[01:05:58.320 --> 01:06:03.800]   As Richard Thaler says, we don't like to close mental accounts in the losses.
[01:06:03.800 --> 01:06:11.960]   We don't like to close those accounts and eat that loss, even though, obviously, just
[01:06:11.960 --> 01:06:18.120]   like a stock portfolio, our decisions are a portfolio, our opportunities are a portfolio.
[01:06:18.120 --> 01:06:21.680]   We ought to be trying to spend our time on the ones that are going to move us toward
[01:06:21.680 --> 01:06:26.000]   our goals the most, that are going to cause us to gain the most ground.
[01:06:26.000 --> 01:06:31.320]   We open an account for a particular thing we're doing, whether it's a marathon, or climbing
[01:06:31.320 --> 01:06:34.920]   Everest, or a job, or a relationship, or whatever.
[01:06:34.920 --> 01:06:39.880]   We don't think about that time, that effort, that all of that is fungible across all the
[01:06:39.880 --> 01:06:41.840]   possible opportunities we have.
[01:06:41.840 --> 01:06:45.580]   Instead, we just think, "If I quit now, I won't have hit my goal, and then I'm going
[01:06:45.580 --> 01:06:50.200]   to be a failure, and I'm going to have lost, and so we won't quit."
[01:06:50.200 --> 01:06:54.320]   There's identity, cognitive dissonance, status quo bias.
[01:06:54.320 --> 01:06:57.560]   These are all in the book, omission/commission bias.
[01:06:57.560 --> 01:07:03.080]   It's like there's so much stuff that we just carry around with us, this cognitive debris
[01:07:03.080 --> 01:07:06.560]   that makes it really hard for us to walk away.
[01:07:06.560 --> 01:07:12.440]   Here's the thing, why I'm so passionate about this topic, is that we think that quitting
[01:07:12.440 --> 01:07:15.680]   will slow our progress down.
[01:07:15.680 --> 01:07:22.880]   We think it may actually cause us to lose ground, but that's not true.
[01:07:22.880 --> 01:07:28.640]   When you quit at the right time, it actually gets you to where you want to go faster, because
[01:07:28.640 --> 01:07:33.880]   it stops you from sticking to something that isn't actually causing you to get there, to
[01:07:33.880 --> 01:07:39.480]   gain ground toward your goal, and allows you to switch to something that will allow you
[01:07:39.480 --> 01:07:42.440]   to gain ground toward your goal.
[01:07:42.440 --> 01:07:46.320]   That's the thing that we miss, because we don't see the other opportunities that the
[01:07:46.320 --> 01:07:53.320]   thing we're doing is stopping us from engaging in, because there's a cost to that time.
[01:07:53.320 --> 01:07:58.320]   There's a cost to that money that we're spending on whatever it is that we're into, or that
[01:07:58.320 --> 01:08:03.760]   we're pursuing, the path that we're on, and we won't let go of it, because if we haven't
[01:08:03.760 --> 01:08:07.440]   reached our goal, we think we're a failure.
[01:08:07.440 --> 01:08:12.560]   Just like if you sell that stock at 30 and you take the $20, whatever, you lost the $20,
[01:08:12.560 --> 01:08:13.560]   so what?
[01:08:13.800 --> 01:08:17.640]   You can put that $30 into other investments that are actually going to get you to financial
[01:08:17.640 --> 01:08:20.680]   well-being more quickly.
[01:08:20.680 --> 01:08:26.360]   Holding on to a stock that isn't worthwhile, because you already lost $20 in it, is actually
[01:08:26.360 --> 01:08:30.400]   slowing your progress down, because you can't go put those resources into something that
[01:08:30.400 --> 01:08:33.160]   will get you to financial well-being more quickly.
[01:08:33.160 --> 01:08:37.040]   That's true whether it's a stock, or a job, or a relationship, or a race you're running.
[01:08:37.040 --> 01:08:39.120]   I don't really care.
[01:08:39.120 --> 01:08:43.600]   If the world tells you you should quit, you ought to do that, because that's the thing
[01:08:43.600 --> 01:08:46.680]   that allows us to decide under uncertainty in the first place.
[01:08:46.680 --> 01:08:51.440]   Let's start exercising that option, so that we can more efficiently and more quickly get
[01:08:51.440 --> 01:08:52.600]   to where we want to go.
[01:08:52.600 --> 01:08:53.600]   I love it.
[01:08:53.600 --> 01:08:55.440]   There's so much more about quitting the book.
[01:08:55.440 --> 01:08:59.760]   I'm going to rapid-fire ask you a few things to see if you could just overview quick one
[01:08:59.760 --> 01:09:00.760]   or two minutes.
[01:09:00.760 --> 01:09:01.760]   Okay.
[01:09:01.760 --> 01:09:08.380]   I love the Astro Teller example of the monkey and the pedestal, and can you just walk people
[01:09:08.380 --> 01:09:09.500]   through that?
[01:09:09.500 --> 01:09:13.160]   We want to be efficient in the things that we're pursuing.
[01:09:13.160 --> 01:09:18.360]   We want to get to understand, should we continue, or should we quit as quickly as possible?
[01:09:18.360 --> 01:09:20.440]   Here's a mental model that will help people do that.
[01:09:20.440 --> 01:09:25.840]   It's called Monkeys and Pedestals, from Astro Teller, as you said, over at X at Google.
[01:09:25.840 --> 01:09:29.160]   Imagine you're trying to train a monkey to juggle flaming torches while standing on a
[01:09:29.160 --> 01:09:31.160]   pedestal in a town square.
[01:09:31.160 --> 01:09:35.160]   This will be a money-making opportunity.
[01:09:35.160 --> 01:09:36.680]   What's the thing that you should do first?
[01:09:36.680 --> 01:09:39.820]   Should you build the pedestal first, or should you try to train the monkey to juggle the
[01:09:39.820 --> 01:09:40.820]   flaming torches?
[01:09:40.820 --> 01:09:45.340]   Well, the thing about the pedestal building is that you already know you can do it.
[01:09:45.340 --> 01:09:47.920]   We've been building pedestals forever.
[01:09:47.920 --> 01:09:49.780]   It doesn't really help you.
[01:09:49.780 --> 01:09:55.860]   It's low-hanging fruit, but it's not something that's actually going to help you to accomplish
[01:09:55.860 --> 01:09:59.700]   your goal, because you could just turn a milk crate upside down even.
[01:09:59.700 --> 01:10:04.100]   If you spend time building the pedestal, it's really kind of wasted time, because it's not
[01:10:04.100 --> 01:10:08.040]   unlocking the bottleneck in the system, which is, "Can I actually train this monkey to juggle
[01:10:08.040 --> 01:10:10.180]   the flaming torches?"
[01:10:10.180 --> 01:10:14.980]   His point is that when you approach this project, you should say, "What are the monkeys?"
[01:10:14.980 --> 01:10:15.980]   Ask yourself this.
[01:10:15.980 --> 01:10:16.980]   What are the monkeys?
[01:10:16.980 --> 01:10:17.980]   What are the pedestals?
[01:10:17.980 --> 01:10:18.980]   What are the things I know I can accomplish?
[01:10:18.980 --> 01:10:22.500]   What are the things that are going to unlock the whole system, but are really hard, and
[01:10:22.500 --> 01:10:24.820]   I don't know if we can do it?
[01:10:24.820 --> 01:10:28.820]   Attack those things you don't know first, and that's going to do two really important
[01:10:28.820 --> 01:10:29.820]   things for you.
[01:10:29.820 --> 01:10:34.340]   One, it's going to get you to understand whether you can actually do this thing or not really
[01:10:34.340 --> 01:10:35.340]   quickly.
[01:10:35.340 --> 01:10:42.060]   Two, and this is really important, is it's going to reduce those sunk costs, because
[01:10:42.060 --> 01:10:47.700]   all that time you spend building pedestals is time and effort and money that you're putting
[01:10:47.700 --> 01:10:52.460]   into something that's then going to cause friction when you butt up against the monkey
[01:10:52.460 --> 01:10:54.760]   that's hard to train.
[01:10:54.760 --> 01:10:56.760]   Train the monkey first.
[01:10:56.760 --> 01:10:59.420]   This is the opposite of the way that most people do things.
[01:10:59.420 --> 01:11:03.900]   How many times have people approached a project and said, "Well, what's the low-hanging fruit?
[01:11:03.900 --> 01:11:05.740]   Let's try to solve for that."
[01:11:05.740 --> 01:11:08.980]   The problem with the low-hanging fruit is that those are all pedestals.
[01:11:08.980 --> 01:11:12.340]   Don't do the low-hanging fruit until you know whether you can actually grow the whole tree.
[01:11:12.340 --> 01:11:14.780]   Can you get to the fruit at the top of the tree?
[01:11:14.780 --> 01:11:17.260]   That's what you really care about, so I love that mental model.
[01:11:17.260 --> 01:11:18.260]   Yeah.
[01:11:18.260 --> 01:11:19.260]   I'm going to link in the show notes.
[01:11:19.260 --> 01:11:23.860]   A friend of mine, Aaron Battalion, wrote this post about knowns and unknowns.
[01:11:23.860 --> 01:11:25.580]   He pushed me so hard in my last startup.
[01:11:25.580 --> 01:11:28.300]   He was like, "Figure out what that known unknown is.
[01:11:28.300 --> 01:11:32.860]   What's the thing that you don't know how to do that you know you don't know how to do?"
[01:11:32.860 --> 01:11:37.700]   In his case, ultimately, the thing that he pushed me to focus on that, sorry, Aaron,
[01:11:37.700 --> 01:11:41.400]   I didn't follow at the beginning, was the thing that we realized halfway through running
[01:11:41.400 --> 01:11:43.260]   the company was the problem.
[01:11:43.260 --> 01:11:49.860]   We ended up shutting the company down with $4 million in the bank because we realized
[01:11:49.860 --> 01:11:52.900]   the thing wasn't going to work and we didn't want to keep going.
[01:11:52.900 --> 01:11:57.340]   You probably could have done that with $5 million in the bank.
[01:11:57.340 --> 01:12:01.700]   This is what AstroTeller is trying to say is like, "Look, you're going to spend some
[01:12:01.700 --> 01:12:07.100]   time trying to solve for the monkey or figure out if you can solve the monkey or monkeys."
[01:12:07.100 --> 01:12:12.420]   You might spend $2 million doing that, but if you can get to that answer in $2 million
[01:12:12.420 --> 01:12:18.560]   instead of $9 million, again, that's a savings of $7 million, not a waste of $2 million.
[01:12:18.560 --> 01:12:21.700]   That's why this is such an important mental model for people to use.
[01:12:21.700 --> 01:12:26.820]   There were a bunch of other great mental models on all kinds of different aspects of quitting.
[01:12:26.820 --> 01:12:30.220]   Where can people find out more about the book and everything else you're working on?
[01:12:30.220 --> 01:12:33.060]   People can always go to annieduke.com.
[01:12:33.060 --> 01:12:34.060]   I have a newsletter.
[01:12:34.060 --> 01:12:38.220]   Lately, it's been a lot about quitting, not surprisingly.
[01:12:38.220 --> 01:12:43.460]   I'm super into the topic, as you can imagine, or you can tell.
[01:12:43.460 --> 01:12:46.020]   And then Twitter @annieduke.
[01:12:46.020 --> 01:12:52.140]   And then you can obviously buy the book at any online or physical retailer near you.
[01:12:52.140 --> 01:12:53.380]   I got an advanced copy.
[01:12:53.380 --> 01:12:54.380]   I appreciate that.
[01:12:54.380 --> 01:12:56.040]   I really enjoyed it.
[01:12:56.040 --> 01:12:58.220]   Sometimes I don't get through the whole book before I talk to someone.
[01:12:58.220 --> 01:13:00.180]   This time, I was staying up late.
[01:13:00.180 --> 01:13:02.140]   My wife's like, "We got to wake up our kids in the morning."
[01:13:02.140 --> 01:13:03.840]   So I really enjoyed it.
[01:13:03.840 --> 01:13:05.100]   Thank you so much for writing it.
[01:13:05.100 --> 01:13:07.060]   And thanks so much for being here.
[01:13:07.060 --> 01:13:08.460]   Thank you so much for having me.

