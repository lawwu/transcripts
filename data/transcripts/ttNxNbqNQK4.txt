
[00:00:00.000 --> 00:00:02.240]   - Welcome to the Huberman Lab Podcast,
[00:00:02.240 --> 00:00:03.720]   where we discuss science
[00:00:03.720 --> 00:00:05.920]   and science-based tools for everyday life.
[00:00:05.920 --> 00:00:10.120]   I'm Andrew Huberman,
[00:00:10.120 --> 00:00:13.160]   and I'm a professor of neurobiology and ophthalmology
[00:00:13.160 --> 00:00:15.280]   at Stanford School of Medicine.
[00:00:15.280 --> 00:00:18.060]   Recently, the Huberman Lab Podcast hosted a live event
[00:00:18.060 --> 00:00:20.720]   at the Plenary Theater in Melbourne, Australia.
[00:00:20.720 --> 00:00:22.880]   The event was called the Brain-Body Contract
[00:00:22.880 --> 00:00:24.080]   and featured a lecture,
[00:00:24.080 --> 00:00:25.840]   followed by a question and answer session
[00:00:25.840 --> 00:00:26.880]   with the audience.
[00:00:26.880 --> 00:00:28.760]   We wanted to make the question and answer session
[00:00:28.760 --> 00:00:31.840]   available to everyone, regardless if you could attend.
[00:00:31.840 --> 00:00:34.300]   So what follows is the question and answer session
[00:00:34.300 --> 00:00:37.120]   from the Plenary Theater in Melbourne, Australia.
[00:00:37.120 --> 00:00:39.540]   I also would like to thank the sponsors for the event.
[00:00:39.540 --> 00:00:41.760]   They are 8Sleep and AG1.
[00:00:41.760 --> 00:00:43.520]   8Sleep makes smart mattress covers
[00:00:43.520 --> 00:00:45.960]   with cooling, heating, and sleep tracking capacity.
[00:00:45.960 --> 00:00:48.160]   And one of the key aspects to getting a great night's sleep
[00:00:48.160 --> 00:00:50.840]   is to control the temperature of your sleeping environment.
[00:00:50.840 --> 00:00:53.720]   And that's because in order to fall and stay deeply asleep,
[00:00:53.720 --> 00:00:55.480]   your body temperature actually has to drop
[00:00:55.480 --> 00:00:57.100]   by about one to three degrees.
[00:00:57.100 --> 00:00:59.080]   And in order to wake up in the morning feeling refreshed,
[00:00:59.080 --> 00:01:01.240]   your body temperature actually has to increase
[00:01:01.240 --> 00:01:02.840]   by about one to three degrees.
[00:01:02.840 --> 00:01:05.200]   8Sleep makes it extremely easy to control the temperature
[00:01:05.200 --> 00:01:07.760]   of your sleeping environment at the beginning, middle,
[00:01:07.760 --> 00:01:08.600]   and throughout the night,
[00:01:08.600 --> 00:01:10.140]   and when you wake up in the morning.
[00:01:10.140 --> 00:01:11.980]   I've been sleeping on an 8Sleep mattress cover
[00:01:11.980 --> 00:01:13.480]   for nearly three years now,
[00:01:13.480 --> 00:01:15.860]   and it has dramatically improved my sleep.
[00:01:15.860 --> 00:01:17.120]   If you'd like to try 8Sleep,
[00:01:17.120 --> 00:01:20.240]   you can go to 8sleep.com/huberman
[00:01:20.240 --> 00:01:23.320]   to save $150 off their Pod 3 cover.
[00:01:23.320 --> 00:01:26.220]   8Sleep currently ships to the USA, Canada, UK,
[00:01:26.220 --> 00:01:28.560]   select countries in the EU, and Australia.
[00:01:28.560 --> 00:01:31.600]   Again, that's 8sleep.com/huberman.
[00:01:31.600 --> 00:01:34.080]   The other live event sponsor, AG1,
[00:01:34.080 --> 00:01:36.120]   is a vitamin mineral probiotic drink
[00:01:36.120 --> 00:01:37.760]   that also contains adaptogens
[00:01:37.760 --> 00:01:39.740]   and other critical micronutrients.
[00:01:39.740 --> 00:01:42.600]   I've been taking AG1 daily since 2012,
[00:01:42.600 --> 00:01:44.040]   so I'm delighted that they decided
[00:01:44.040 --> 00:01:45.520]   to sponsor the live event.
[00:01:45.520 --> 00:01:46.800]   The reason I started taking it,
[00:01:46.800 --> 00:01:48.560]   and the reason I still take it every day,
[00:01:48.560 --> 00:01:49.560]   once or twice a day,
[00:01:49.560 --> 00:01:51.920]   is that it ensures that I meet all of my quotas
[00:01:51.920 --> 00:01:53.680]   for vitamins and minerals.
[00:01:53.680 --> 00:01:56.540]   And it ensures that I get enough prebiotic and probiotic
[00:01:56.540 --> 00:01:57.660]   to support gut health.
[00:01:57.660 --> 00:02:00.320]   Now, of course, I strive to consume healthy whole foods
[00:02:00.320 --> 00:02:03.740]   for the majority of my nutritional intake every single day,
[00:02:03.740 --> 00:02:05.700]   but there are a number of things in AG1,
[00:02:05.700 --> 00:02:07.380]   including specific micronutrients
[00:02:07.380 --> 00:02:08.960]   that are hard to get from whole foods,
[00:02:08.960 --> 00:02:10.820]   or at least in sufficient quantities.
[00:02:10.820 --> 00:02:13.260]   So AG1 allows me to get the vitamins and minerals
[00:02:13.260 --> 00:02:15.140]   that I need, probiotics, prebiotics,
[00:02:15.140 --> 00:02:18.060]   the adaptogens, and critical micronutrients.
[00:02:18.060 --> 00:02:21.940]   To try AG1, go to drinkag1.com/huberman,
[00:02:21.940 --> 00:02:25.080]   and you'll get a year supply of vitamin D3K2,
[00:02:25.080 --> 00:02:27.200]   and five free travel packs of AG1.
[00:02:27.200 --> 00:02:31.000]   Again, that's drinkag1.com/huberman.
[00:02:31.000 --> 00:02:32.960]   And now for the question and answer session
[00:02:32.960 --> 00:02:34.660]   from Melbourne, Australia.
[00:02:34.660 --> 00:02:37.240]   [upbeat music]
[00:02:50.480 --> 00:02:53.440]   - Hey, Dr. Huberman, some of your listeners
[00:02:53.440 --> 00:02:55.480]   are in or approaching our 50s.
[00:02:55.480 --> 00:02:56.780]   Okay, same.
[00:02:56.780 --> 00:03:01.560]   And are thinking of doing all we can to prevent dementia.
[00:03:01.560 --> 00:03:02.840]   Same.
[00:03:02.840 --> 00:03:04.720]   Do you have any additional thoughts or protocols
[00:03:04.720 --> 00:03:06.560]   or research we could focus on?
[00:03:06.560 --> 00:03:10.880]   Yes, so, for the next two and a half hours,
[00:03:10.880 --> 00:03:14.560]   no, I'm kidding, I'm not known for being succinct.
[00:03:14.560 --> 00:03:16.960]   I didn't go over too much earlier.
[00:03:16.960 --> 00:03:19.920]   So, okay, so, ground truths.
[00:03:19.920 --> 00:03:21.240]   So, let's start with ground truths,
[00:03:21.240 --> 00:03:25.040]   and then let's move to emerging.
[00:03:25.040 --> 00:03:27.640]   Let's maybe get to a little bit of speculation.
[00:03:27.640 --> 00:03:29.000]   Let's avoid conjecture.
[00:03:29.000 --> 00:03:30.860]   Ground truths.
[00:03:30.860 --> 00:03:35.720]   Blood circulation is good for the brain,
[00:03:35.720 --> 00:03:37.880]   perhaps most important for the brain.
[00:03:37.880 --> 00:03:41.400]   So, anything that is good for cardiovascular health
[00:03:41.400 --> 00:03:44.200]   is going to be good for brain health.
[00:03:44.200 --> 00:03:46.120]   It's not the only thing, but that's true.
[00:03:46.120 --> 00:03:47.200]   We know this.
[00:03:47.200 --> 00:03:50.680]   So, you hear these days a lot about zone two cardio.
[00:03:50.680 --> 00:03:51.880]   I don't know who gets credit for that.
[00:03:51.880 --> 00:03:53.200]   Peter Ortea talks a lot about it.
[00:03:53.200 --> 00:03:54.240]   I talk a lot about it.
[00:03:54.240 --> 00:03:55.840]   None of us invented the notion.
[00:03:55.840 --> 00:03:59.580]   But 150, probably more like 180 to 200 minutes
[00:03:59.580 --> 00:04:02.480]   of so-called zone two cardio per week
[00:04:02.480 --> 00:04:06.000]   is good numbers to shoot for.
[00:04:06.000 --> 00:04:07.880]   Some of us get more, some of us less.
[00:04:07.880 --> 00:04:09.080]   What is zone two cardio?
[00:04:09.080 --> 00:04:12.460]   Zone two cardio is cardiovascular exercise.
[00:04:12.460 --> 00:04:15.080]   Could be running, could be swimming, could be walking,
[00:04:15.080 --> 00:04:16.800]   depending on your level of fitness,
[00:04:16.800 --> 00:04:21.080]   which you can just barely maintain a conversation.
[00:04:21.080 --> 00:04:24.000]   Were you to push any harder or faster,
[00:04:24.000 --> 00:04:25.920]   you wouldn't be able to complete your sentences
[00:04:25.920 --> 00:04:28.640]   with much ease, okay?
[00:04:28.640 --> 00:04:30.280]   So, is this zone two cardio for me?
[00:04:30.280 --> 00:04:33.160]   No, but if I were to jog and try and have a conversation,
[00:04:33.160 --> 00:04:35.620]   at some point I would have a little bit of a hard time.
[00:04:35.620 --> 00:04:37.140]   That's zone two cardio.
[00:04:37.140 --> 00:04:40.560]   So, we know that's true.
[00:04:40.560 --> 00:04:41.740]   Why?
[00:04:41.740 --> 00:04:44.040]   Well, it seems to do a number of things
[00:04:44.040 --> 00:04:47.800]   at the level of release of growth factors,
[00:04:47.800 --> 00:04:49.780]   brain-derived nootrophic factor,
[00:04:49.780 --> 00:04:54.480]   at the level of different, let's call them,
[00:04:54.480 --> 00:04:56.820]   I realize the immunologists are gonna roll their eyes,
[00:04:56.820 --> 00:05:01.700]   but anti-inflammatory cytokines and things of that sort.
[00:05:01.700 --> 00:05:03.560]   You also have inflammatory cytokines
[00:05:03.560 --> 00:05:06.640]   and things of that sort.
[00:05:06.640 --> 00:05:09.360]   It does seem that increasing blood flow
[00:05:09.360 --> 00:05:12.780]   in and through the brain is important for brain health,
[00:05:12.780 --> 00:05:14.520]   which is not all that surprising.
[00:05:14.520 --> 00:05:15.800]   There are species of animals
[00:05:15.800 --> 00:05:18.400]   that spend part of their life swimming about,
[00:05:18.400 --> 00:05:23.320]   and then when they stop and stick to a rock or something,
[00:05:23.320 --> 00:05:25.820]   a good portion of the nervous system actually degenerates.
[00:05:25.820 --> 00:05:28.720]   But neurodegeneration and dementia
[00:05:28.720 --> 00:05:31.080]   are not necessarily the same thing,
[00:05:31.080 --> 00:05:33.720]   and this is something that we don't often hear about.
[00:05:33.720 --> 00:05:37.440]   The age-related decline in memory capacity,
[00:05:37.440 --> 00:05:38.880]   in particular working memory,
[00:05:38.940 --> 00:05:41.580]   can be related to reductions
[00:05:41.580 --> 00:05:43.500]   in dopamine transmission in the brain,
[00:05:43.500 --> 00:05:45.620]   so things that increase the catecholamines
[00:05:45.620 --> 00:05:47.680]   that we talked about earlier.
[00:05:47.680 --> 00:05:49.340]   This could be pharmacology, of course,
[00:05:49.340 --> 00:05:50.980]   but it doesn't have to be pharmacology.
[00:05:50.980 --> 00:05:54.940]   It could be anything that increases the catecholamines,
[00:05:54.940 --> 00:05:57.140]   and we talk about this on the podcast.
[00:05:57.140 --> 00:05:59.260]   We have zero-cost protocols
[00:05:59.260 --> 00:06:00.380]   that you don't have to sign up for.
[00:06:00.380 --> 00:06:01.580]   You can just go to our website
[00:06:01.580 --> 00:06:03.540]   and go to dopamine regulation,
[00:06:03.540 --> 00:06:06.100]   and it will list out ways to increase the catecholamines
[00:06:06.100 --> 00:06:09.320]   through zero-cost and very low-cost ways.
[00:06:09.320 --> 00:06:10.960]   They are known to improve working memory.
[00:06:10.960 --> 00:06:12.200]   Working memory, of course,
[00:06:12.200 --> 00:06:14.880]   the capacity to maintain a string of numbers
[00:06:14.880 --> 00:06:17.580]   or information for sake of kind of immediate goals,
[00:06:17.580 --> 00:06:21.180]   but not information that's passed to the longer-term memory.
[00:06:21.180 --> 00:06:23.520]   So that's different than neurodegeneration.
[00:06:23.520 --> 00:06:26.080]   That's simply reductions
[00:06:26.080 --> 00:06:27.640]   in the amount of neuromodulators,
[00:06:27.640 --> 00:06:29.940]   like dopamine, being deployed as we get older.
[00:06:29.940 --> 00:06:35.880]   So modulating dopamine through healthy, ideally, means.
[00:06:36.720 --> 00:06:40.600]   But I do think we are going to see an increase
[00:06:40.600 --> 00:06:43.360]   in the use of selective pharmacology for this purpose,
[00:06:43.360 --> 00:06:45.480]   and here I'm not recommending anyone do drugs
[00:06:45.480 --> 00:06:48.480]   or take drugs, prescription or otherwise,
[00:06:48.480 --> 00:06:52.800]   but it does seem that certain compounds,
[00:06:52.800 --> 00:06:55.640]   like nicotine, believe it or not,
[00:06:55.640 --> 00:06:58.920]   even though it increases vasoconstriction and blood pressure,
[00:06:58.920 --> 00:07:01.700]   can offset some of the age-related reductions
[00:07:01.700 --> 00:07:05.740]   in dopaminergic and cholinergic acetylcholine,
[00:07:05.740 --> 00:07:07.140]   cholinergic transmission.
[00:07:07.140 --> 00:07:12.380]   And you don't wanna smoke, vape, dip, or snuff.
[00:07:12.380 --> 00:07:14.340]   I'm not even recommending people take Zin patches,
[00:07:14.340 --> 00:07:17.380]   but I think there is some use cases
[00:07:17.380 --> 00:07:20.420]   for nicotine-provided you're doing it
[00:07:20.420 --> 00:07:23.640]   with your physician knows
[00:07:23.640 --> 00:07:25.140]   and you're not getting into blood pressure,
[00:07:25.140 --> 00:07:27.220]   dangerous blood pressure range,
[00:07:27.220 --> 00:07:29.260]   or supplementation with choline donors
[00:07:29.260 --> 00:07:30.700]   and things of that sort
[00:07:30.700 --> 00:07:33.420]   to increase acetylcholine and dopamine.
[00:07:33.420 --> 00:07:34.860]   Some people are starting to take things
[00:07:34.860 --> 00:07:38.260]   like modafinil and Adderall in older age.
[00:07:38.260 --> 00:07:40.480]   But keep in mind, these are not modafinil,
[00:07:40.480 --> 00:07:42.200]   but Adderall, Vyvanse, et cetera.
[00:07:42.200 --> 00:07:43.540]   These are amphetamines.
[00:07:43.540 --> 00:07:44.380]   They're amphetamines.
[00:07:44.380 --> 00:07:45.380]   I'm not recommending this,
[00:07:45.380 --> 00:07:47.140]   but I think that's where we're headed.
[00:07:47.140 --> 00:07:48.260]   I think you're gonna see a number
[00:07:48.260 --> 00:07:51.140]   of different cognitive enhancers
[00:07:51.140 --> 00:07:55.620]   that are used to offset some age-related cognitive decline,
[00:07:55.620 --> 00:07:56.460]   aka dementia.
[00:07:56.460 --> 00:07:59.540]   Now, in terms of, so we're going zone two cardio
[00:07:59.540 --> 00:08:00.740]   to prescription drugs.
[00:08:00.740 --> 00:08:02.180]   We're kind of bracketing here.
[00:08:02.180 --> 00:08:04.180]   And then behavioral protocols
[00:08:04.180 --> 00:08:05.700]   that can increase neuromodulators,
[00:08:05.700 --> 00:08:07.220]   such as the catecholamines.
[00:08:07.220 --> 00:08:11.220]   Now, in terms of other things
[00:08:11.220 --> 00:08:14.260]   that can perhaps decrease the likelihood
[00:08:14.260 --> 00:08:17.880]   of Alzheimer's and other forms of dementia
[00:08:17.880 --> 00:08:20.300]   as it relates to neurodegeneration,
[00:08:20.300 --> 00:08:23.540]   currently there are a lot of do nots.
[00:08:23.540 --> 00:08:24.660]   Don't hit your head too hard.
[00:08:24.660 --> 00:08:26.380]   If you hit it really hard, don't hit it again.
[00:08:26.380 --> 00:08:27.200]   Hit it hard.
[00:08:27.200 --> 00:08:30.180]   The so-called two-hit model, literally.
[00:08:30.180 --> 00:08:34.500]   You know, and we think of football or, I guess, rugby.
[00:08:34.500 --> 00:08:35.820]   That's a sport you guys play down here
[00:08:35.820 --> 00:08:37.960]   where they use the head as a battering ram.
[00:08:37.960 --> 00:08:40.380]   I've seen this, right?
[00:08:40.380 --> 00:08:41.740]   Big necks on those kids.
[00:08:41.740 --> 00:08:42.820]   And then there's boom.
[00:08:42.820 --> 00:08:43.940]   And they, yeah.
[00:08:43.940 --> 00:08:48.380]   But the problem is not necessarily just rugby
[00:08:48.380 --> 00:08:51.100]   or American football or,
[00:08:51.100 --> 00:08:53.140]   I was told that, someone told me I had to shout out
[00:08:53.140 --> 00:08:55.980]   an Australian football team, and I know it's a setup.
[00:08:55.980 --> 00:08:57.340]   So I'm not gonna do it.
[00:08:57.340 --> 00:08:59.060]   They're like, "When you're in Melbourne tomorrow,
[00:08:59.060 --> 00:09:01.500]   "you gotta say that your favorite team is blank."
[00:09:01.500 --> 00:09:04.620]   And I'm like, "This feels really dangerous."
[00:09:04.620 --> 00:09:05.920]   So I'm not gonna do it.
[00:09:05.920 --> 00:09:08.380]   I'm not gonna do it.
[00:09:08.380 --> 00:09:09.940]   But, what's that?
[00:09:09.940 --> 00:09:12.540]   Do it.
[00:09:12.540 --> 00:09:14.740]   I can't remember the name of the team, so.
[00:09:14.740 --> 00:09:18.620]   But I watched the document.
[00:09:18.620 --> 00:09:19.460]   What's that?
[00:09:19.460 --> 00:09:24.020]   But I still don't understand the rugby thing.
[00:09:24.020 --> 00:09:25.980]   Do they use the guy's head, or gal's head,
[00:09:25.980 --> 00:09:27.180]   as a battering ram?
[00:09:27.180 --> 00:09:31.180]   'Cause they used to play at UCSD outside my lab.
[00:09:31.180 --> 00:09:33.380]   We had this big field, and my bulldog loved watching.
[00:09:33.380 --> 00:09:36.140]   He was like, "This sport makes sense."
[00:09:36.140 --> 00:09:38.060]   But they were just like, "Run."
[00:09:38.060 --> 00:09:40.220]   And then the, I never understood it.
[00:09:40.220 --> 00:09:42.900]   But, anyway.
[00:09:42.900 --> 00:09:43.740]   What's that?
[00:09:43.740 --> 00:09:48.160]   Got it.
[00:09:48.160 --> 00:09:50.060]   I need a translator.
[00:09:50.060 --> 00:09:50.900]   Sorry.
[00:09:50.900 --> 00:09:53.140]   (laughing)
[00:09:53.140 --> 00:09:55.040]   So, I need a translator.
[00:09:55.040 --> 00:09:58.300]   But I love the enthusiasm.
[00:09:58.300 --> 00:10:04.540]   So we think about head injuries and brain injuries
[00:10:04.540 --> 00:10:05.820]   mostly in the context of sport,
[00:10:05.820 --> 00:10:07.400]   but that's not where most of the head injuries occur.
[00:10:07.400 --> 00:10:09.460]   Most of them occur, construction workers,
[00:10:09.460 --> 00:10:12.740]   car accidents, TBI, things of that sort.
[00:10:12.740 --> 00:10:15.620]   There's some interesting data on hyperbaric chambers.
[00:10:15.620 --> 00:10:18.620]   This is getting really into the high-level stuff here,
[00:10:18.620 --> 00:10:20.540]   meaning most people don't have access to them.
[00:10:20.540 --> 00:10:22.020]   I look forward to learning more.
[00:10:22.020 --> 00:10:24.540]   These are playing with different concentrations of oxygen
[00:10:24.540 --> 00:10:26.100]   and in a little microenvironment
[00:10:26.100 --> 00:10:29.860]   for traumatic brain injury and neurodegeneration.
[00:10:29.860 --> 00:10:31.820]   I mean, do I think in five years
[00:10:31.820 --> 00:10:34.300]   that everyone's gonna be sitting in hyperbaric chambers
[00:10:34.300 --> 00:10:36.420]   in order to offset neuron loss?
[00:10:36.420 --> 00:10:37.320]   Probably not.
[00:10:37.320 --> 00:10:39.300]   I think it's not cost-effective.
[00:10:39.300 --> 00:10:42.380]   But I will say that most of the things
[00:10:42.380 --> 00:10:44.860]   that are good for the body are good for the brain,
[00:10:44.860 --> 00:10:49.220]   keeping kind of anything that plaques the arteries,
[00:10:49.220 --> 00:10:50.620]   capillaries, and veins of the brain,
[00:10:50.620 --> 00:10:54.140]   'cause it's so heavily vascularized, minimal,
[00:10:54.140 --> 00:10:57.180]   and minding those neuromodulators.
[00:10:57.180 --> 00:11:00.740]   Obviously, drugs of abuse like methamphetamine
[00:11:00.740 --> 00:11:02.740]   can deplete dopamine neurons.
[00:11:02.740 --> 00:11:05.380]   The data on MDMA, by the way, I don't know.
[00:11:05.380 --> 00:11:07.580]   There's drug enforcement in the room.
[00:11:07.580 --> 00:11:10.560]   The data, you know where they have most of the safety data
[00:11:10.560 --> 00:11:13.300]   or lack of safety data in some cases on MDMA?
[00:11:13.300 --> 00:11:17.620]   Keep in mind, MDMA ecstasy is methylene deoxymethamphetamine.
[00:11:17.620 --> 00:11:21.300]   Methamphetamine, we know, causes neurodegeneration.
[00:11:21.300 --> 00:11:22.580]   No question.
[00:11:22.580 --> 00:11:23.980]   It also causes bad teeth.
[00:11:23.980 --> 00:11:25.100]   Do you know how?
[00:11:25.100 --> 00:11:25.960]   Do you know how?
[00:11:25.960 --> 00:11:27.620]   Turns people into mouth breathers.
[00:11:27.620 --> 00:11:30.720]   Dry mouth and the teeth degenerate.
[00:11:30.720 --> 00:11:32.580]   Yeah, we have an episode on oral health coming up.
[00:11:32.580 --> 00:11:33.660]   This is real.
[00:11:33.660 --> 00:11:35.180]   That's actually why the teeth degenerate
[00:11:35.180 --> 00:11:38.700]   is from excessive dry, and it limits saliva production.
[00:11:38.700 --> 00:11:41.700]   Saliva's very important for remineralization of the teeth.
[00:11:41.700 --> 00:11:43.660]   Shout out to the dentists in the house.
[00:11:43.660 --> 00:11:48.660]   So the thing about MDMA is interesting
[00:11:48.660 --> 00:11:51.180]   because it turns out that MDMA,
[00:11:51.180 --> 00:11:53.740]   because it also, it increases dopamine
[00:11:53.740 --> 00:11:56.100]   just as methamphetamine does.
[00:11:56.100 --> 00:11:58.340]   Remember, MDMA, methylene deoxymethamphetamine,
[00:11:58.340 --> 00:12:00.820]   but also huge increases in serotonin
[00:12:00.820 --> 00:12:04.720]   seem to be most of the effect of MDMA,
[00:12:04.720 --> 00:12:06.500]   the kind of empathogenic effect.
[00:12:06.500 --> 00:12:12.480]   There was a study done of people from the LDS,
[00:12:12.500 --> 00:12:15.740]   Latter-day Saints, sometimes referred to as Mormons.
[00:12:15.740 --> 00:12:18.180]   Why was a study on MDMA done
[00:12:18.180 --> 00:12:20.540]   with people from the LDS community?
[00:12:20.540 --> 00:12:21.780]   And I don't want to imply that everyone
[00:12:21.780 --> 00:12:24.080]   from the LDS community does MDMA, but why?
[00:12:24.080 --> 00:12:26.200]   They're a very interesting test population
[00:12:26.200 --> 00:12:28.240]   because they don't do other drugs.
[00:12:28.240 --> 00:12:32.380]   But for some reason, MDMA is not on the no-fly list.
[00:12:32.380 --> 00:12:37.380]   So it's a beautiful paper in which they took people
[00:12:37.380 --> 00:12:40.100]   who had only done as any drug,
[00:12:40.100 --> 00:12:42.540]   not even taking caffeine, right,
[00:12:42.540 --> 00:12:47.060]   either once or semi-frequent or very frequent use of MDMA,
[00:12:47.060 --> 00:12:48.480]   and they did a bunch of cognitive testing.
[00:12:48.480 --> 00:12:50.140]   And there were some attention issues
[00:12:50.140 --> 00:12:53.140]   when people had taken over what was a couple hundred doses
[00:12:53.140 --> 00:12:55.480]   of MDMA at the 80 milligram dose or more,
[00:12:55.480 --> 00:12:57.700]   but doesn't seem to be much neurodegeneration,
[00:12:57.700 --> 00:12:59.300]   which is not to say that it's all safe.
[00:12:59.300 --> 00:13:01.500]   There is an abuse and addictive potential there.
[00:13:01.500 --> 00:13:05.260]   The biggest issue seems to be contamination of batches.
[00:13:05.260 --> 00:13:06.860]   We have a fentanyl issue in the US.
[00:13:06.860 --> 00:13:08.980]   I don't know if it's happening down here as well.
[00:13:08.980 --> 00:13:10.180]   Very concerning.
[00:13:10.180 --> 00:13:14.580]   Okay, so the point here is that I think very soon
[00:13:14.580 --> 00:13:18.560]   you're going to hear about drugs,
[00:13:18.560 --> 00:13:19.980]   prescription drugs and supplements
[00:13:19.980 --> 00:13:22.160]   to augment the release of neuromodulators,
[00:13:22.160 --> 00:13:24.920]   not for sake of empathogenic states or psychedelic states,
[00:13:24.920 --> 00:13:28.200]   but to try and keep those dopaminergic neurons online
[00:13:28.200 --> 00:13:30.260]   to offset dementia, 'cause that's what the question's about.
[00:13:30.260 --> 00:13:32.420]   In fact, there's a Nobel Prize-winning neuroscientist
[00:13:32.420 --> 00:13:35.140]   at Columbia University, whose name I won't tell you,
[00:13:35.140 --> 00:13:38.300]   or maybe I will, who, when I went to visit his office,
[00:13:38.300 --> 00:13:40.540]   chewed no fewer than five pieces of Nicorette
[00:13:40.540 --> 00:13:42.020]   in the course of a half an hour.
[00:13:42.020 --> 00:13:43.420]   And I'm like, what's going on?
[00:13:43.420 --> 00:13:45.780]   He's got a Nobel Prize, but this looks kind of pathologic.
[00:13:45.780 --> 00:13:46.620]   And I said, why?
[00:13:46.620 --> 00:13:49.260]   And he said, well, the nicotine is to offset
[00:13:49.260 --> 00:13:53.500]   age-related loss of dopaminergic and cholinergic neurons.
[00:13:53.500 --> 00:13:54.540]   I thought, really?
[00:13:54.540 --> 00:13:56.100]   He's like, yeah, when I quit smoking,
[00:13:56.100 --> 00:13:57.900]   'cause I didn't want lung cancer, but this is him.
[00:13:57.900 --> 00:13:58.740]   This is an anecdote.
[00:13:58.740 --> 00:14:00.360]   I'm not suggesting you do this.
[00:14:00.360 --> 00:14:02.100]   I think there are a number of things that we can do,
[00:14:02.100 --> 00:14:03.580]   but protect those neuromodulators,
[00:14:03.580 --> 00:14:06.420]   keep perfusion, that is blood flow to the brain, strong.
[00:14:06.420 --> 00:14:09.300]   There's a case for cardiovascular exercise.
[00:14:09.300 --> 00:14:13.620]   And it does seem, it really does seem that exercise
[00:14:13.620 --> 00:14:15.740]   that engages the neuromuscular connections
[00:14:15.740 --> 00:14:17.260]   more than cardiovascular exercise,
[00:14:17.260 --> 00:14:18.660]   so not just resistance training,
[00:14:18.660 --> 00:14:21.620]   but anything that involves coordinated bodily training,
[00:14:21.620 --> 00:14:24.500]   learning new physical skills, dance, et cetera,
[00:14:24.500 --> 00:14:27.740]   really does seem to offset some of the loss
[00:14:27.740 --> 00:14:30.640]   of cognitive functioning in adults.
[00:14:30.640 --> 00:14:32.700]   So it's kind of interesting that physical exercise
[00:14:32.700 --> 00:14:37.380]   is great for cognition, and probably cognition
[00:14:37.380 --> 00:14:39.660]   may or may not help physical ability,
[00:14:39.660 --> 00:14:42.260]   but one probably can imagine
[00:14:42.260 --> 00:14:44.140]   why there's a bidirectional relationship there.
[00:14:44.140 --> 00:14:46.440]   Your nervous system doesn't really distinguish
[00:14:46.440 --> 00:14:48.860]   between physical and cognitive.
[00:14:48.860 --> 00:14:51.300]   It's all working as a bunch of functional units.
[00:14:51.300 --> 00:14:52.600]   I could go on and on about this,
[00:14:52.600 --> 00:14:55.300]   but hopefully that at least gets your,
[00:14:55.300 --> 00:14:57.640]   the gears turning around some things
[00:14:57.640 --> 00:14:58.700]   that perhaps you've heard about
[00:14:58.700 --> 00:15:00.260]   and some things that you haven't.
[00:15:00.260 --> 00:15:01.820]   And we'll do an episode on dementia
[00:15:01.820 --> 00:15:03.580]   and offsetting dementia in order to get into
[00:15:03.580 --> 00:15:05.020]   some of the fine details.
[00:15:05.020 --> 00:15:05.860]   Okay.
[00:15:05.860 --> 00:15:08.300]   Can we increase our willpower,
[00:15:08.300 --> 00:15:09.420]   just like training a muscle group,
[00:15:09.420 --> 00:15:11.380]   with your research into the AMCC?
[00:15:11.380 --> 00:15:13.420]   Ooh, I'm so glad that you mentioned the AMCC.
[00:15:13.420 --> 00:15:18.060]   I think of all the new areas of neuroscience research
[00:15:18.060 --> 00:15:20.980]   that are out there, I think the anterior mid-cingulate cortex
[00:15:20.980 --> 00:15:24.220]   is one of the most interesting structures
[00:15:24.220 --> 00:15:27.520]   and areas of research nowadays.
[00:15:27.520 --> 00:15:29.900]   You know, I think, if I have my way,
[00:15:29.900 --> 00:15:33.060]   then not only will most people have heard of dopamine
[00:15:33.060 --> 00:15:36.140]   and the amygdala, I guess you need a Star Wars character
[00:15:36.140 --> 00:15:38.460]   named after your brain part.
[00:15:38.460 --> 00:15:39.380]   Isn't there one?
[00:15:39.380 --> 00:15:40.620]   I only saw the first three.
[00:15:40.620 --> 00:15:41.740]   I'm of that generation.
[00:15:41.740 --> 00:15:43.940]   But isn't there an Amy Dalla or something?
[00:15:43.940 --> 00:15:45.380]   Yeah, right?
[00:15:45.380 --> 00:15:46.260]   Don't leave me hanging here.
[00:15:46.260 --> 00:15:47.100]   Is there or not?
[00:15:47.100 --> 00:15:48.860]   If I'm wrong, just say no.
[00:15:48.860 --> 00:15:49.700]   Okay.
[00:15:49.700 --> 00:15:52.660]   Anyway, the amygdala, thanks.
[00:15:52.660 --> 00:15:55.900]   The amygdala is a brain structure
[00:15:55.900 --> 00:15:59.500]   that is involved in threat detection
[00:15:59.500 --> 00:16:01.940]   and novelty detection, not just threats.
[00:16:01.940 --> 00:16:04.620]   The anterior mid-cingulate cortex
[00:16:04.620 --> 00:16:07.840]   is an area of the brain that we know is activated.
[00:16:07.840 --> 00:16:10.220]   Well, let me tell you the best experiment.
[00:16:10.220 --> 00:16:12.500]   The best experiment was done, in my opinion,
[00:16:12.500 --> 00:16:16.420]   by a neurosurgeon at Stanford, Joe Parvizzi.
[00:16:16.420 --> 00:16:18.420]   He's probing around in people's brains.
[00:16:18.420 --> 00:16:19.780]   They got a little piece of skull missing.
[00:16:19.780 --> 00:16:22.220]   He's stimulating in the brain.
[00:16:22.220 --> 00:16:23.260]   He's asking them questions.
[00:16:23.260 --> 00:16:24.080]   How do you feel?
[00:16:24.080 --> 00:16:24.920]   What's going on?
[00:16:24.920 --> 00:16:25.900]   What's going on?
[00:16:25.900 --> 00:16:26.980]   And he's got this electrode
[00:16:26.980 --> 00:16:29.180]   in the anterior mid-cingulate cortex.
[00:16:29.180 --> 00:16:33.140]   And the patient says,
[00:16:33.140 --> 00:16:37.020]   "I feel like something really bad's gonna happen,
[00:16:37.020 --> 00:16:38.740]   "like a storm's coming."
[00:16:38.740 --> 00:16:40.340]   He's like, "Okay, well, we can stop stimulating."
[00:16:40.340 --> 00:16:43.260]   He's like, "No, I'm going into the storm."
[00:16:43.260 --> 00:16:44.660]   He's like, "Oh, that's interesting."
[00:16:44.660 --> 00:16:46.500]   Stimulate a little bit further back,
[00:16:46.500 --> 00:16:48.220]   just by a millimeter or so,
[00:16:48.220 --> 00:16:51.720]   completely different subjective experience for the patient.
[00:16:51.720 --> 00:16:52.820]   That's interesting.
[00:16:52.820 --> 00:16:53.980]   Get a different patient in there,
[00:16:53.980 --> 00:16:57.260]   map to the anterior mid-cingulate cortex, stimulate.
[00:16:57.260 --> 00:16:58.660]   And the person says,
[00:16:58.660 --> 00:17:00.220]   "I feel like I'm gonna get out of my chair,
[00:17:00.220 --> 00:17:02.580]   "and I'm gonna do something hard."
[00:17:02.580 --> 00:17:03.660]   Wild, right?
[00:17:03.660 --> 00:17:05.460]   This is prior to any knowledge
[00:17:05.460 --> 00:17:08.140]   of what the anterior mid-cingulate cortex is doing.
[00:17:08.140 --> 00:17:10.100]   Make a long story short,
[00:17:10.100 --> 00:17:14.500]   people who successfully overcome a physical challenge,
[00:17:14.500 --> 00:17:16.940]   a cognitive challenge, that learn a new skill,
[00:17:16.940 --> 00:17:21.700]   that successful dieters, I don't really like that term,
[00:17:22.660 --> 00:17:25.940]   their anterior mid-cingulate cortex grows,
[00:17:25.940 --> 00:17:28.340]   or becomes more active under conditions
[00:17:28.340 --> 00:17:30.220]   that challenge the anterior mid-cingulate cortex.
[00:17:30.220 --> 00:17:33.260]   So this brain region seems to be the brain region
[00:17:33.260 --> 00:17:35.820]   that puts us in a forward center of mass,
[00:17:35.820 --> 00:17:38.780]   physically and sort of cognitively and emotionally.
[00:17:38.780 --> 00:17:40.860]   I often like to think that the nervous system,
[00:17:40.860 --> 00:17:42.540]   as sophisticated as it is,
[00:17:42.540 --> 00:17:45.220]   and psychology as sophisticated as it is,
[00:17:45.220 --> 00:17:47.460]   as it is, excuse me,
[00:17:47.460 --> 00:17:49.300]   can be binned into kind of three categories.
[00:17:49.300 --> 00:17:51.940]   Things that we like to eat or don't like to eat,
[00:17:51.940 --> 00:17:56.940]   or can kind of be binned into yum, yuck, or meh.
[00:17:56.940 --> 00:17:59.780]   That's kind of what the nervous system has to do,
[00:17:59.780 --> 00:18:01.060]   because ultimately you have to decide,
[00:18:01.060 --> 00:18:03.700]   do I wanna go toward it, so-called repetitive behavior,
[00:18:03.700 --> 00:18:05.180]   do I wanna get away from it?
[00:18:05.180 --> 00:18:06.940]   Well, I can do nothing.
[00:18:06.940 --> 00:18:10.700]   People, we're either like yum,
[00:18:10.700 --> 00:18:14.860]   or in some cases, yum, yuck,
[00:18:14.860 --> 00:18:17.220]   or in some cases, like, ugh,
[00:18:17.220 --> 00:18:19.420]   or like, meh, right?
[00:18:19.420 --> 00:18:21.180]   Yum, yuck, meh, yum, yum, meh.
[00:18:21.180 --> 00:18:24.780]   This is the sort of three tributaries
[00:18:24.780 --> 00:18:26.500]   that we have the option of moving down,
[00:18:26.500 --> 00:18:29.180]   not moving down, or moving away from.
[00:18:29.180 --> 00:18:31.580]   So the anterior mid-cingulate cortex,
[00:18:31.580 --> 00:18:34.420]   because it has inputs from so many different areas
[00:18:34.420 --> 00:18:35.980]   and outputs to so many different areas,
[00:18:35.980 --> 00:18:39.460]   it can access circuits related to dopamine, norepinephrine,
[00:18:39.460 --> 00:18:42.740]   it can access circuits related to memory and context.
[00:18:42.740 --> 00:18:44.020]   It's a hub.
[00:18:44.020 --> 00:18:47.780]   It's a hub that, by all views,
[00:18:47.780 --> 00:18:50.900]   through all lenses of the existing research,
[00:18:50.900 --> 00:18:55.140]   suggests that any time we do something truly challenging,
[00:18:55.140 --> 00:18:57.620]   in particular things that we do not enjoy,
[00:18:57.620 --> 00:19:01.300]   this is key, the anterior mid-cingulate cortex
[00:19:01.300 --> 00:19:03.940]   undergoes some sort of plasticity.
[00:19:03.940 --> 00:19:07.620]   Everything in the research data now points to the idea
[00:19:07.620 --> 00:19:09.140]   that the anterior mid-cingulate cortex
[00:19:09.140 --> 00:19:11.480]   is the seat of so-called willpower,
[00:19:11.480 --> 00:19:13.940]   which is linked to concepts like tenacity,
[00:19:13.940 --> 00:19:15.580]   or grit, and et cetera.
[00:19:15.580 --> 00:19:17.580]   And what I love about this research
[00:19:17.580 --> 00:19:19.340]   is that it comes from a bunch of different areas,
[00:19:19.340 --> 00:19:23.460]   human brain imaging, brain stimulation, et cetera.
[00:19:23.460 --> 00:19:26.660]   Here's what I don't like about the reality,
[00:19:26.660 --> 00:19:27.860]   but that we all need to accept,
[00:19:27.860 --> 00:19:30.300]   which is that the anterior mid-cingulate cortex
[00:19:30.300 --> 00:19:34.120]   is modifiable by experience, by leaning into challenges
[00:19:34.120 --> 00:19:36.040]   at any stage of life.
[00:19:36.040 --> 00:19:39.460]   That's great, we talked about that earlier, plasticity.
[00:19:39.460 --> 00:19:42.020]   But, lest we forget,
[00:19:42.020 --> 00:19:46.220]   plasticity goes in the other direction, too.
[00:19:46.220 --> 00:19:49.400]   It seems that when we don't engage in challenges,
[00:19:49.400 --> 00:19:52.980]   that the anterior mid-cingulate cortex,
[00:19:52.980 --> 00:19:55.780]   it doesn't atrophy, but it undergoes
[00:19:55.780 --> 00:19:59.140]   sort of a downshift in activation.
[00:19:59.140 --> 00:20:01.860]   Now, here's what's really, really interesting,
[00:20:01.860 --> 00:20:03.700]   and relates to the previous question.
[00:20:03.700 --> 00:20:07.100]   The anterior mid-cingulate cortex
[00:20:07.100 --> 00:20:12.040]   seems to be especially active at baseline,
[00:20:12.040 --> 00:20:15.940]   and available for plasticity in what are called super-agers.
[00:20:15.940 --> 00:20:18.440]   Super-agers, you know, we've all heard of blue zones.
[00:20:18.440 --> 00:20:20.180]   The super-agers are these people who are,
[00:20:20.180 --> 00:20:22.460]   they don't just exist in blue zones,
[00:20:22.460 --> 00:20:23.540]   they're spread around the world.
[00:20:23.540 --> 00:20:26.960]   These are people that seem, at least by cognitive measures,
[00:20:26.960 --> 00:20:30.000]   and other physiological measures of the body,
[00:20:30.000 --> 00:20:33.620]   seem to age extremely slowly.
[00:20:33.620 --> 00:20:36.380]   So they shouldn't really be called super-agers, right?
[00:20:36.380 --> 00:20:39.820]   They should be called super-non-agers, anyway.
[00:20:39.820 --> 00:20:41.620]   The anterior mid-cingulate cortex
[00:20:41.620 --> 00:20:45.500]   seems to be hyperactive in these super-agers,
[00:20:45.500 --> 00:20:49.420]   as they're called, and so it seems that
[00:20:49.420 --> 00:20:52.540]   not only do they maintain cognitive function later in life,
[00:20:52.540 --> 00:20:54.780]   but that seems to be related to
[00:20:54.780 --> 00:20:57.480]   their regular engagement in challenging things.
[00:20:57.480 --> 00:20:59.100]   So, remember for so many years, we heard,
[00:20:59.100 --> 00:21:00.940]   okay, like, nuns don't get dementia,
[00:21:00.940 --> 00:21:02.540]   and then there's all sorts of things you can imagine
[00:21:02.540 --> 00:21:03.580]   could be related to that.
[00:21:03.580 --> 00:21:08.180]   And then we're thinking, oh, maybe it's crossword puzzles.
[00:21:08.180 --> 00:21:09.860]   Maybe it's crossword puzzles.
[00:21:09.860 --> 00:21:11.660]   Maybe it's hanging out with other people.
[00:21:11.660 --> 00:21:14.100]   And then you know that person down the street,
[00:21:14.100 --> 00:21:16.100]   and she's cycling on the weekends like crazy,
[00:21:16.100 --> 00:21:18.380]   and she's 90, and she looks like she's 50,
[00:21:18.380 --> 00:21:19.860]   and she's sharp as a tack.
[00:21:19.860 --> 00:21:23.780]   It's probably leaning into challenge on a regular basis.
[00:21:23.780 --> 00:21:25.460]   Leaning into challenge on a regular basis,
[00:21:25.460 --> 00:21:28.540]   as opposed to one specific cognitive or physical thing,
[00:21:28.540 --> 00:21:30.780]   which means that if you love cycling,
[00:21:30.780 --> 00:21:32.120]   or you love the cold plunge,
[00:21:32.120 --> 00:21:34.160]   or you love a certain form of exercise,
[00:21:34.160 --> 00:21:36.100]   it's probably not doing that much
[00:21:36.100 --> 00:21:38.000]   for your anterior mid-cingulate cortex.
[00:21:38.000 --> 00:21:41.060]   But these superagers also live longer.
[00:21:41.060 --> 00:21:42.540]   And so there is this notion that
[00:21:42.540 --> 00:21:44.800]   because the anterior mid-cingulate cortex
[00:21:44.800 --> 00:21:48.780]   has connectivity to a lot of areas of the brain and body,
[00:21:48.780 --> 00:21:52.340]   that it is somehow linked to the will to live.
[00:21:52.340 --> 00:21:53.820]   And this is being examined now
[00:21:53.820 --> 00:21:56.700]   in so-called terminal cancer patients.
[00:21:56.700 --> 00:21:59.840]   So-called, you know, terminal cases.
[00:21:59.840 --> 00:22:01.020]   I don't like the language.
[00:22:01.020 --> 00:22:03.000]   Because there are these amazing instances,
[00:22:03.000 --> 00:22:04.860]   and physicians and oncologists
[00:22:04.860 --> 00:22:06.020]   have known this for a long time,
[00:22:06.020 --> 00:22:09.320]   that when people decide they're gonna fight cancer,
[00:22:09.320 --> 00:22:12.780]   they don't always win that fight, unfortunately.
[00:22:12.780 --> 00:22:15.020]   But oftentimes, it's the people
[00:22:15.020 --> 00:22:19.880]   who insist on fighting it psychologically,
[00:22:19.880 --> 00:22:20.900]   that they won't give in,
[00:22:20.900 --> 00:22:25.300]   that end up still living more months, more years,
[00:22:25.300 --> 00:22:28.420]   and in some cases, putting the cancer into remission.
[00:22:28.420 --> 00:22:30.500]   With, of course, other tools, right?
[00:22:30.500 --> 00:22:31.620]   I'm not saying you shouldn't use
[00:22:31.620 --> 00:22:33.140]   other tools to combat cancer.
[00:22:33.140 --> 00:22:34.640]   It's a very interesting structure,
[00:22:34.640 --> 00:22:36.420]   relates to the question on dementia.
[00:22:36.420 --> 00:22:38.780]   Hopefully that was informative.
[00:22:38.780 --> 00:22:40.220]   Julian, thank you.
[00:22:40.220 --> 00:22:41.540]   How would you recommend shift workers
[00:22:41.540 --> 00:22:42.900]   minimize the effects of disruption
[00:22:42.900 --> 00:22:43.880]   to their circadian rhythm?
[00:22:43.880 --> 00:22:44.980]   Oh, this is so important.
[00:22:44.980 --> 00:22:45.820]   You know why?
[00:22:45.820 --> 00:22:50.100]   Because like right now, 9.20, ah, 9.40 p.m.,
[00:22:50.100 --> 00:22:51.880]   we're kind of doing shift work right now.
[00:22:51.880 --> 00:22:55.060]   Most people are on a shift work schedule now in the world.
[00:22:55.060 --> 00:22:56.140]   This is true.
[00:22:56.140 --> 00:22:57.700]   We think of shift workers as only the people
[00:22:57.700 --> 00:22:58.540]   who are up in the middle of the night
[00:22:58.540 --> 00:22:59.540]   and sleeping during the day,
[00:22:59.540 --> 00:23:01.680]   but most people are doing shift work.
[00:23:01.680 --> 00:23:06.060]   The criteria for shift work is at least a two-hour,
[00:23:06.060 --> 00:23:08.160]   at least in the U.S., a two-hour variance
[00:23:08.160 --> 00:23:11.300]   in the sleep-wake cycle, more than three nights a week.
[00:23:11.300 --> 00:23:13.900]   Anyone here go to sleep every night, same time,
[00:23:13.900 --> 00:23:15.880]   wake up every morning, same time,
[00:23:15.880 --> 00:23:18.880]   never stay up later than that, more than two nights a week?
[00:23:18.880 --> 00:23:21.480]   Okay, most people are doing shift work nowadays.
[00:23:21.480 --> 00:23:24.140]   They're just on their phone or they're on their computer.
[00:23:24.140 --> 00:23:27.340]   And I'm not going to argue that's, you know,
[00:23:27.340 --> 00:23:30.940]   you shouldn't, many times that's me as well.
[00:23:30.940 --> 00:23:33.420]   So here's what we do know, and I could,
[00:23:33.420 --> 00:23:34.760]   we did a whole episode on shift work,
[00:23:34.760 --> 00:23:37.220]   but I'll try and summarize some of the key points.
[00:23:37.220 --> 00:23:42.700]   You want to have your cortisol elevated early in the day
[00:23:42.700 --> 00:23:44.340]   and then subside across the day.
[00:23:44.340 --> 00:23:46.460]   That's the ideal pattern of cortisol release.
[00:23:46.460 --> 00:23:48.180]   Cortisol is a great thing when it's high
[00:23:48.180 --> 00:23:51.940]   and then tapers off from early day into the later day.
[00:23:51.940 --> 00:23:54.760]   It's a bad thing if that cortisol peak is shifted late.
[00:23:54.760 --> 00:23:57.260]   That cortisol peak is coming every 24 hours.
[00:23:57.260 --> 00:23:59.020]   You don't have a choice.
[00:23:59.020 --> 00:24:00.380]   Question is, is it going to be early day
[00:24:00.380 --> 00:24:01.740]   or is it going to be late day?
[00:24:01.740 --> 00:24:04.560]   Late day cortisol peaks are associated
[00:24:04.560 --> 00:24:05.820]   with depression, anxiety.
[00:24:05.820 --> 00:24:08.060]   This was done by my colleague, David Spiegel
[00:24:08.060 --> 00:24:10.740]   and the great Robert Sapolsky at Stanford.
[00:24:10.740 --> 00:24:11.840]   I study about that.
[00:24:11.840 --> 00:24:16.240]   Robert, another great beard.
[00:24:16.240 --> 00:24:19.640]   Amazing.
[00:24:19.640 --> 00:24:22.400]   And I always thought it was to blend in
[00:24:22.400 --> 00:24:24.500]   with the species that he studies,
[00:24:24.500 --> 00:24:27.220]   'cause he was like the baboon guy, you know.
[00:24:27.220 --> 00:24:29.020]   I haven't quite figured out how to master that one,
[00:24:29.020 --> 00:24:30.560]   you know, like the cuttlefish look,
[00:24:30.560 --> 00:24:33.720]   but I'm working on it, working on it.
[00:24:33.720 --> 00:24:35.180]   Maybe I just have to, no, never mind.
[00:24:35.180 --> 00:24:38.740]   There's a story about, you remember the earlier story?
[00:24:38.740 --> 00:24:41.200]   The cuttlefish, anyway, never mind.
[00:24:41.200 --> 00:24:45.280]   Again, this is why I don't like to speak
[00:24:45.280 --> 00:24:46.600]   too late in the day.
[00:24:46.600 --> 00:24:48.020]   I can get myself into trouble.
[00:24:48.020 --> 00:24:53.020]   But the point here is that having that cortisol peak
[00:24:54.020 --> 00:24:56.640]   early in the day sets you up for mood focus
[00:24:56.640 --> 00:24:58.220]   and alertness, immune system function
[00:24:58.220 --> 00:25:02.060]   in a really great way.
[00:25:02.060 --> 00:25:04.380]   Shift workers have a serious problem,
[00:25:04.380 --> 00:25:07.020]   which is that late peaks in cortisol
[00:25:07.020 --> 00:25:10.020]   are kind of paramount in all forms of shift work.
[00:25:10.020 --> 00:25:12.420]   And so what you need to do is to put yourself,
[00:25:12.420 --> 00:25:14.620]   ideally, in lighting conditions that limit
[00:25:14.620 --> 00:25:17.740]   the amount of blue light coming in at night,
[00:25:17.740 --> 00:25:19.220]   or when you're doing that shift work.
[00:25:19.220 --> 00:25:21.180]   Now, you have to do your work.
[00:25:21.180 --> 00:25:23.620]   And I think in the next two years,
[00:25:23.620 --> 00:25:26.980]   if I have my way, one idea that I'd like to
[00:25:26.980 --> 00:25:29.340]   embed in people's minds is we hear a lot now
[00:25:29.340 --> 00:25:30.900]   about how hyper-processed foods
[00:25:30.900 --> 00:25:32.900]   and highly-processed foods are bad for us,
[00:25:32.900 --> 00:25:34.020]   sort of empty calories.
[00:25:34.020 --> 00:25:34.980]   What are empty calories?
[00:25:34.980 --> 00:25:36.920]   It's foods that are very calorie-dense,
[00:25:36.920 --> 00:25:38.820]   but micronutrient-poor, right?
[00:25:38.820 --> 00:25:40.340]   That's what it really is.
[00:25:40.340 --> 00:25:42.100]   It's also the quality of food issues,
[00:25:42.100 --> 00:25:44.020]   and people get, like, let's please not have
[00:25:44.020 --> 00:25:45.060]   the seed oil debate.
[00:25:45.060 --> 00:25:47.220]   It's like, people get really into this,
[00:25:47.220 --> 00:25:50.040]   and it's unclear to me still, and okay.
[00:25:50.040 --> 00:25:53.080]   But we sort of think of empty calories
[00:25:53.080 --> 00:25:55.520]   like alcohol, sugar, et cetera.
[00:25:55.520 --> 00:25:58.560]   Calorie-dense, micronutrient-poor.
[00:25:58.560 --> 00:26:01.360]   Light can be viewed in much the same way.
[00:26:01.360 --> 00:26:05.080]   These days, we live in a very blue-light-rich world.
[00:26:05.080 --> 00:26:07.480]   Lot of blue light, so short-wavelength light,
[00:26:07.480 --> 00:26:08.920]   blue light, UV light.
[00:26:08.920 --> 00:26:11.560]   And by the way, in sunlight, especially down here,
[00:26:11.560 --> 00:26:14.940]   it's very UV-rich blue, which is great during the day,
[00:26:14.940 --> 00:26:17.480]   especially when it's offset, or sorry,
[00:26:17.480 --> 00:26:21.000]   when it includes long-wavelength light, full-spectrum light.
[00:26:21.000 --> 00:26:23.400]   By the way, for everyone that's obsessed with red light,
[00:26:23.400 --> 00:26:25.200]   and I love red light and red light therapies,
[00:26:25.200 --> 00:26:29.220]   remember, the best source of red light is the sun.
[00:26:29.220 --> 00:26:31.760]   It's full-spectrum light.
[00:26:31.760 --> 00:26:33.080]   It includes red.
[00:26:33.080 --> 00:26:34.680]   It's just there's a bunch of other stuff in there, too,
[00:26:34.680 --> 00:26:37.520]   so it doesn't look like a red light panel.
[00:26:37.520 --> 00:26:39.880]   That said, if you are going to do shift work,
[00:26:39.880 --> 00:26:40.960]   one of the best things you can do,
[00:26:40.960 --> 00:26:44.400]   and it's been shown to reduce cortisol levels at night
[00:26:44.400 --> 00:26:46.760]   while you're doing that shift work,
[00:26:46.760 --> 00:26:48.640]   is to filter out some of the blue.
[00:26:48.640 --> 00:26:51.420]   So that is a use case for blue blockers,
[00:26:51.420 --> 00:26:55.440]   or even for glasses that put you
[00:26:55.440 --> 00:26:57.240]   into more reddish conditions,
[00:26:57.240 --> 00:26:59.800]   provided you can still do the work you need to do safely.
[00:26:59.800 --> 00:27:02.960]   You will see a dramatic reduction in cortisol
[00:27:02.960 --> 00:27:04.620]   under those conditions.
[00:27:04.620 --> 00:27:07.320]   This blue and UV pathway,
[00:27:07.320 --> 00:27:10.200]   picked up by a certain set of neurons in the eye,
[00:27:10.200 --> 00:27:12.600]   the intrinsically photosensitive melanopsin cells, et cetera,
[00:27:12.600 --> 00:27:15.840]   is a real thing, and it's designed to activate you.
[00:27:15.840 --> 00:27:18.080]   This is why so-called seasonal affective disorder lamps,
[00:27:18.080 --> 00:27:23.080]   sad lamps, are basically bright blue-white-ish light.
[00:27:23.080 --> 00:27:26.120]   So when you're doing that shift work,
[00:27:26.120 --> 00:27:27.960]   if you can get into red or orange
[00:27:27.960 --> 00:27:30.320]   or amber light conditions, that's great.
[00:27:30.320 --> 00:27:32.700]   You can do this very inexpensively, by the way,
[00:27:32.700 --> 00:27:34.080]   by just getting some party lights.
[00:27:34.080 --> 00:27:36.020]   It doesn't have to be any fancy red light.
[00:27:36.020 --> 00:27:38.760]   This is not talking about red light panels.
[00:27:38.760 --> 00:27:40.640]   The other thing, of course,
[00:27:40.640 --> 00:27:45.640]   is when you get back to your non-work environment,
[00:27:45.920 --> 00:27:47.600]   you need to do some work to think about
[00:27:47.600 --> 00:27:49.840]   when is best to sleep, when is not best to sleep.
[00:27:49.840 --> 00:27:52.220]   You know, is it best to sleep all day and be up all night,
[00:27:52.220 --> 00:27:53.560]   or get that sunlight in the morning?
[00:27:53.560 --> 00:27:56.160]   And I talk about that in the shift work episode,
[00:27:56.160 --> 00:27:58.440]   and I'm tempted to go down that rabbit hole now,
[00:27:58.440 --> 00:27:59.400]   but I would just encourage you
[00:27:59.400 --> 00:28:01.480]   to take a look at that episode.
[00:28:01.480 --> 00:28:03.840]   And I'll just cue you all to a resource.
[00:28:03.840 --> 00:28:06.720]   The hubermanlab.com website allows you,
[00:28:06.720 --> 00:28:09.160]   thanks to our wonderful engineers,
[00:28:09.160 --> 00:28:10.880]   to put in multiple topics.
[00:28:10.880 --> 00:28:14.520]   So you could say shift work red light,
[00:28:14.520 --> 00:28:18.440]   or shift work dopamine, or shift work sunlight,
[00:28:18.440 --> 00:28:20.240]   and it will take you to the exact timestamps
[00:28:20.240 --> 00:28:23.920]   across all the episodes where those specific topics occur.
[00:28:23.920 --> 00:28:25.240]   It's all at zero cost,
[00:28:25.240 --> 00:28:26.920]   as opposed to having to go and peruse
[00:28:26.920 --> 00:28:28.600]   all these different episodes.
[00:28:28.600 --> 00:28:31.960]   A lot of people have said, "Why not shorter episodes?"
[00:28:31.960 --> 00:28:33.200]   It's like, well, the idea was to create
[00:28:33.200 --> 00:28:38.120]   a library of information that now AI is,
[00:28:38.120 --> 00:28:40.280]   and better engineering of websites,
[00:28:40.280 --> 00:28:42.360]   can allow you to just pull the relevant information
[00:28:42.360 --> 00:28:43.840]   just like you would a book.
[00:28:43.840 --> 00:28:44.960]   Well, I used to go to the library,
[00:28:44.960 --> 00:28:46.480]   for those of you like me old enough to remember,
[00:28:46.480 --> 00:28:48.640]   you actually took this thing called a book off a shelf,
[00:28:48.640 --> 00:28:50.240]   you Xerox copied it.
[00:28:50.240 --> 00:28:53.760]   In any event, it was very archaic and very expensive,
[00:28:53.760 --> 00:28:55.680]   and you'd always get the margin of the book in the middle,
[00:28:55.680 --> 00:28:57.520]   like the spine, it sucked.
[00:28:57.520 --> 00:28:59.920]   Now you can go to the website and just get that information,
[00:28:59.920 --> 00:29:01.320]   and then we also just launched
[00:29:01.320 --> 00:29:04.000]   an ai.hubermanlab.com website.
[00:29:04.000 --> 00:29:04.920]   Again, it's all zero cost.
[00:29:04.920 --> 00:29:07.360]   You can just say, "Hey, what should I do for shift work?"
[00:29:07.360 --> 00:29:09.360]   But I wanted to hear, to come here tonight,
[00:29:09.360 --> 00:29:10.960]   so I didn't tell you that until you got here.
[00:29:10.960 --> 00:29:12.800]   No, I'm just kidding, I'm just kidding.
[00:29:12.800 --> 00:29:15.560]   Okay, and there are a few other tools
[00:29:15.560 --> 00:29:18.800]   about adjusting eating schedules and whatnot for shift work,
[00:29:18.800 --> 00:29:23.120]   but hopefully that gets you going, Julia.
[00:29:23.120 --> 00:29:24.480]   Thank you.
[00:29:24.480 --> 00:29:27.840]   What's the difference between NSDR and meditation?
[00:29:27.840 --> 00:29:29.480]   Thank you for this question.
[00:29:29.480 --> 00:29:34.400]   I am a huge, huge, huge believer and proponent
[00:29:34.400 --> 00:29:37.040]   and practitioner of NSDR, non-sleep deep rest.
[00:29:37.040 --> 00:29:38.640]   What is non-sleep deep rest?
[00:29:38.640 --> 00:29:40.480]   Well, to be fair, yoga nidra,
[00:29:40.480 --> 00:29:42.000]   which translates to yoga sleep,
[00:29:42.000 --> 00:29:45.040]   is a thousand-year-old practice,
[00:29:45.040 --> 00:29:46.800]   thousands of year old practice
[00:29:46.800 --> 00:29:51.800]   in which you lie completely still, keep the mind awake.
[00:29:51.800 --> 00:29:53.400]   You're not thinking in a structured way.
[00:29:53.400 --> 00:29:56.040]   It's more of a body scan, directed relaxation, et cetera.
[00:29:56.040 --> 00:29:58.160]   I discovered this in 2015
[00:29:58.160 --> 00:29:59.600]   when I was doing some research for a book
[00:29:59.600 --> 00:30:02.760]   that I still can't manage to seem to finish
[00:30:02.760 --> 00:30:05.320]   on trauma and addiction.
[00:30:05.320 --> 00:30:08.840]   And I have a friend, very talented trauma therapist,
[00:30:08.840 --> 00:30:12.520]   who's managed to help people with all sorts of addictions.
[00:30:12.520 --> 00:30:15.280]   He'll be on the podcast in the not too distant future.
[00:30:15.280 --> 00:30:18.200]   And I went down to this clinic in Florida
[00:30:18.200 --> 00:30:20.880]   and everyone there spent the first hour of the day
[00:30:20.880 --> 00:30:22.800]   doing yoga nidra.
[00:30:22.800 --> 00:30:24.520]   This is pretty wacky.
[00:30:24.520 --> 00:30:26.160]   I was still in my pure scientist,
[00:30:26.160 --> 00:30:29.600]   quote unquote pure scientist, naive scientist lens.
[00:30:29.600 --> 00:30:30.800]   And I thought, what is this about?
[00:30:30.800 --> 00:30:31.640]   And he said, well, you know,
[00:30:31.640 --> 00:30:33.640]   so much of addiction is about an inability
[00:30:33.640 --> 00:30:37.080]   to regulate impulses, to deal with agitation,
[00:30:37.080 --> 00:30:39.240]   especially in the early days of trying to get sober
[00:30:39.240 --> 00:30:40.600]   or being sober.
[00:30:40.600 --> 00:30:42.760]   And it just helps people learn
[00:30:42.760 --> 00:30:45.120]   to self-direct their nervous system
[00:30:45.120 --> 00:30:47.080]   in terms of self-directed relaxation.
[00:30:47.080 --> 00:30:48.840]   It also seems to help with their sleep.
[00:30:48.840 --> 00:30:53.160]   It also has these components about time and sort of,
[00:30:53.160 --> 00:30:54.600]   'cause he said, you know, it's kind of interesting.
[00:30:54.600 --> 00:30:55.960]   If you take a step back,
[00:30:55.960 --> 00:30:59.840]   you know, if you can tolerate craving for a second,
[00:30:59.840 --> 00:31:02.000]   you just did it, so why couldn't you do it
[00:31:02.000 --> 00:31:02.840]   for another second?
[00:31:02.840 --> 00:31:05.760]   If I can do it for another second, another second.
[00:31:05.760 --> 00:31:08.320]   It's not as if it necessarily increases linearly
[00:31:08.320 --> 00:31:10.680]   or over time.
[00:31:10.680 --> 00:31:12.080]   So, you know, what's going on?
[00:31:12.080 --> 00:31:15.160]   And so again, sort of our ability to realize
[00:31:15.160 --> 00:31:16.880]   and regulate our states across time
[00:31:16.880 --> 00:31:18.960]   and to realize there's this funny thing
[00:31:18.960 --> 00:31:20.240]   where when we feel terrible,
[00:31:20.240 --> 00:31:21.640]   we think it's gonna go on forever.
[00:31:21.640 --> 00:31:23.120]   And when we're happy,
[00:31:23.120 --> 00:31:25.560]   we're like certain it's gonna stop.
[00:31:25.560 --> 00:31:27.280]   There's like kind of asymmetry in our nervous system
[00:31:27.280 --> 00:31:28.360]   that we don't understand.
[00:31:28.360 --> 00:31:30.240]   We showed, he started talking about yoga nidra
[00:31:30.240 --> 00:31:33.160]   really seems to help addicts recover and stay sober.
[00:31:33.160 --> 00:31:34.000]   They do it regularly.
[00:31:34.000 --> 00:31:35.000]   I thought, well, this is cool.
[00:31:35.000 --> 00:31:35.840]   What is it?
[00:31:35.840 --> 00:31:36.680]   I'm a neuroscientist.
[00:31:36.680 --> 00:31:39.440]   We started studying it in my laboratory.
[00:31:39.440 --> 00:31:42.600]   We discovered that the brain goes into these states
[00:31:42.600 --> 00:31:46.720]   during yoga nidra that are similar to sleep,
[00:31:46.720 --> 00:31:49.320]   body still, mind alert.
[00:31:49.320 --> 00:31:52.080]   And that seems to be very beneficial,
[00:31:52.080 --> 00:31:54.280]   maybe even accelerates neuroplasticity and learning.
[00:31:54.280 --> 00:31:55.800]   And indeed there's evidence for that.
[00:31:55.800 --> 00:31:57.080]   And there's evidence that yoga nidra
[00:31:57.080 --> 00:31:59.760]   out from a laboratory out of Scandinavia,
[00:31:59.760 --> 00:32:03.440]   not my laboratory showing that it can increase dopamine
[00:32:03.440 --> 00:32:07.800]   levels in the striatum, basal ganglia by up to 60%
[00:32:07.800 --> 00:32:10.720]   using human positron emission tomography imaging.
[00:32:10.720 --> 00:32:12.360]   So we're talking about how to increase dopamine
[00:32:12.360 --> 00:32:14.920]   through non pharmacologic means.
[00:32:14.920 --> 00:32:17.440]   This is something about body still brain active,
[00:32:17.440 --> 00:32:20.080]   very, very powerful way to do that.
[00:32:20.080 --> 00:32:23.360]   I made up this term, this acronym non-sleep deep rest
[00:32:23.360 --> 00:32:26.600]   because I have tremendous respect for yoga nidra
[00:32:26.600 --> 00:32:28.920]   and the yoga traditions,
[00:32:28.920 --> 00:32:32.880]   but I was concerned for a lot of people, unfortunately,
[00:32:32.880 --> 00:32:36.280]   when they hear yoga nidra, it sounds esoteric
[00:32:36.280 --> 00:32:37.840]   and they're not gonna approach that practice.
[00:32:37.840 --> 00:32:40.000]   Also yoga nidra includes intentions
[00:32:40.000 --> 00:32:42.600]   and some things that are a little bit on the mystical side.
[00:32:42.600 --> 00:32:45.400]   And I knew I was gonna take some heat for it
[00:32:45.400 --> 00:32:46.720]   and I feel badly about it.
[00:32:46.720 --> 00:32:49.960]   But that bad feeling is offset by,
[00:32:49.960 --> 00:32:51.800]   I think when you call something non-sleep deep rest,
[00:32:51.800 --> 00:32:53.520]   it tells you what it is.
[00:32:53.520 --> 00:32:55.520]   And then more people are likely to come to the practice.
[00:32:55.520 --> 00:32:59.760]   And I felt like it was worth kind of putting myself,
[00:32:59.760 --> 00:33:01.800]   jumping on the grenade for that one.
[00:33:01.800 --> 00:33:05.520]   So non-sleep deep rest is very effective
[00:33:05.520 --> 00:33:09.080]   at restoring cognitive and physical vigor
[00:33:09.080 --> 00:33:14.080]   and can indeed offset some degree of sleep loss.
[00:33:14.080 --> 00:33:16.640]   It also gets you better at falling and staying asleep.
[00:33:16.640 --> 00:33:18.440]   And it's very simple and very easy to do
[00:33:18.440 --> 00:33:19.360]   and it's zero cost.
[00:33:19.360 --> 00:33:20.800]   And if you wanna try it,
[00:33:20.800 --> 00:33:23.680]   you can go onto YouTube and put NSDR in my last name.
[00:33:23.680 --> 00:33:26.080]   There's a woman named Kelly Boyes, B-O-Y-S,
[00:33:26.080 --> 00:33:28.880]   who has a much more pleasant voice than mine,
[00:33:28.880 --> 00:33:29.800]   who does them as well.
[00:33:29.800 --> 00:33:31.080]   These are all zero cost protocol.
[00:33:31.080 --> 00:33:32.760]   She's also in the waking up app.
[00:33:32.760 --> 00:33:35.240]   And there are many of them.
[00:33:35.240 --> 00:33:37.000]   Kamini Desai is another person
[00:33:37.000 --> 00:33:40.480]   who has wonderful yoga nidra scripts.
[00:33:40.480 --> 00:33:41.680]   So you can find these things
[00:33:41.680 --> 00:33:44.080]   and they're really about 10 minutes to 20 minutes,
[00:33:44.080 --> 00:33:45.480]   sometimes 30 minutes long.
[00:33:45.480 --> 00:33:46.760]   You can do it for an hour,
[00:33:46.760 --> 00:33:48.200]   but most people won't do that consistently.
[00:33:48.200 --> 00:33:49.280]   You don't have to do them every day.
[00:33:49.280 --> 00:33:51.440]   And they're very, very effective
[00:33:51.440 --> 00:33:54.000]   at restoring mental and physical vigor
[00:33:54.000 --> 00:33:55.280]   when you're feeling depleted
[00:33:55.280 --> 00:33:58.080]   and getting you to be a better sleeper.
[00:33:59.240 --> 00:34:01.720]   So I figure that's a zero cost tool
[00:34:01.720 --> 00:34:04.360]   that is grounded in good mechanistic science
[00:34:04.360 --> 00:34:07.400]   and makes sense logically, so why not?
[00:34:07.400 --> 00:34:09.560]   Meditation, typically,
[00:34:09.560 --> 00:34:11.560]   and there are many different forms of meditation,
[00:34:11.560 --> 00:34:15.920]   but if you're, let's just say kind of standard,
[00:34:15.920 --> 00:34:17.640]   if there were such a thing.
[00:34:17.640 --> 00:34:19.200]   Third eye meditation, closing your eyes,
[00:34:19.200 --> 00:34:21.360]   focusing your concentration on a point
[00:34:21.360 --> 00:34:22.520]   just sort of at your forehead,
[00:34:22.520 --> 00:34:23.560]   concentrating on your breathing,
[00:34:23.560 --> 00:34:25.320]   redirecting your attention to your breathing
[00:34:25.320 --> 00:34:27.280]   if your attention drifts.
[00:34:27.280 --> 00:34:30.680]   We know based on work from Wendy Suzuki's laboratory
[00:34:30.680 --> 00:34:32.040]   at New York University
[00:34:32.040 --> 00:34:34.800]   and some work out of the University of Wisconsin,
[00:34:34.800 --> 00:34:37.360]   can improve memory,
[00:34:37.360 --> 00:34:40.920]   can improve focus,
[00:34:40.920 --> 00:34:44.760]   and does seem to have some stress offsetting effects,
[00:34:44.760 --> 00:34:48.240]   but it's more of a focus exercise
[00:34:48.240 --> 00:34:51.120]   as opposed to an energy replenishing exercise.
[00:34:51.120 --> 00:34:53.040]   Now, some people meditate and feel better afterwards,
[00:34:53.040 --> 00:34:53.880]   they have more energy,
[00:34:53.880 --> 00:34:56.880]   but then it's sort of like, well, compared to what?
[00:34:56.880 --> 00:34:59.160]   I don't think that's the major effect of meditation.
[00:34:59.160 --> 00:35:00.680]   And while we're on these topics,
[00:35:00.680 --> 00:35:02.920]   I should just say that self-directed hypnosis
[00:35:02.920 --> 00:35:05.360]   of the sort that my colleague David Spiegel studies
[00:35:05.360 --> 00:35:08.440]   is more about solving a particular problem.
[00:35:08.440 --> 00:35:11.040]   So hypnosis is more about engaging neuroplasticity.
[00:35:11.040 --> 00:35:13.920]   Remember earlier we said that neuroplasticity in adulthood
[00:35:13.920 --> 00:35:17.080]   can be activated by focus followed by rest.
[00:35:17.080 --> 00:35:20.680]   It seems that in the self-directed hypnotic states,
[00:35:20.680 --> 00:35:23.720]   the brain enters kind of pattern of activity
[00:35:23.720 --> 00:35:27.960]   in which neuroplasticity can be accessed more quickly,
[00:35:27.960 --> 00:35:31.400]   we think, because the brain is both focused and relaxed
[00:35:31.400 --> 00:35:34.920]   in a particular way, merging that focus and rest state.
[00:35:34.920 --> 00:35:37.000]   And of course, the hypnotic script
[00:35:37.000 --> 00:35:39.360]   is not about getting you to do crazy things on stage,
[00:35:39.360 --> 00:35:40.480]   that's stage hypnosis,
[00:35:40.480 --> 00:35:42.800]   but self-directed hypnosis is, for instance,
[00:35:42.800 --> 00:35:44.240]   smoking cessation.
[00:35:44.240 --> 00:35:47.320]   By the way, the success with smoking cessation from hypnosis
[00:35:47.320 --> 00:35:49.800]   is far greater than the cessation with smoking
[00:35:49.800 --> 00:35:52.200]   from pretty much any other protocol.
[00:35:52.200 --> 00:35:54.760]   But unfortunately, it has the name hypnosis,
[00:35:54.760 --> 00:35:56.200]   which makes people think about stuff
[00:35:56.200 --> 00:35:59.240]   that people do on stage that's kind of wacky.
[00:35:59.240 --> 00:36:01.600]   So we need a new name for it,
[00:36:01.600 --> 00:36:03.960]   because unfortunately, names are a problem.
[00:36:03.960 --> 00:36:06.240]   Their names can be differentiators
[00:36:06.240 --> 00:36:07.320]   as opposed to integrators.
[00:36:07.320 --> 00:36:08.200]   They don't bring people...
[00:36:08.200 --> 00:36:09.800]   When people say, "I'm gonna hypnotize you,"
[00:36:09.800 --> 00:36:11.160]   or, "You should try hypnosis,"
[00:36:11.160 --> 00:36:12.320]   people are like, "Eh."
[00:36:12.320 --> 00:36:13.800]   Like, "Yum, yuck, meh?"
[00:36:13.800 --> 00:36:15.480]   They're like, "Yuck."
[00:36:15.480 --> 00:36:18.280]   So by the way, does everyone here remember
[00:36:18.280 --> 00:36:20.720]   how you know if you're highly hypnotizable?
[00:36:20.720 --> 00:36:23.360]   You know that the Spiegel eye roll test?
[00:36:23.360 --> 00:36:24.640]   It's not what teenagers do.
[00:36:24.640 --> 00:36:28.640]   David Spiegel and his father, psychiatrists,
[00:36:28.640 --> 00:36:31.080]   discovered the clinical application of hypnosis.
[00:36:31.080 --> 00:36:33.240]   It's a clinically-approved tool.
[00:36:33.240 --> 00:36:37.800]   There's brainstem neurons that cause elevations
[00:36:37.800 --> 00:36:39.600]   and alertness and focus,
[00:36:39.600 --> 00:36:41.640]   and they're associated with moving the eyes up.
[00:36:41.640 --> 00:36:43.760]   They're brainstem neurons that close the eyelids
[00:36:43.760 --> 00:36:46.840]   and essentially drive the eyes down
[00:36:46.840 --> 00:36:48.680]   that are associated with parasympathetic states,
[00:36:48.680 --> 00:36:50.400]   which is why you go like this when you're tired.
[00:36:50.400 --> 00:36:51.760]   You're out there, I'm sure.
[00:36:51.760 --> 00:36:56.080]   If you are capable of keeping your gaze upward
[00:36:56.080 --> 00:36:57.840]   and closing your eyelids,
[00:36:57.840 --> 00:37:00.640]   you score on a particular end
[00:37:00.640 --> 00:37:02.120]   of the so-called Spiegel eye roll test,
[00:37:02.120 --> 00:37:04.920]   which makes you highly hypnotizable
[00:37:04.920 --> 00:37:07.280]   because that state of hypnosis
[00:37:07.280 --> 00:37:08.360]   is one in which you're what?
[00:37:08.360 --> 00:37:10.480]   Alert, but very, very relaxed.
[00:37:10.480 --> 00:37:13.080]   So if you go to Spiegel's laboratory,
[00:37:13.080 --> 00:37:13.920]   they're gonna look at you,
[00:37:13.920 --> 00:37:15.560]   and they say, "Look up at the ceiling,"
[00:37:15.560 --> 00:37:16.520]   and then close your eyelids,
[00:37:16.520 --> 00:37:19.200]   and if you can still see the whites of,
[00:37:19.200 --> 00:37:20.600]   if they still see the whites of your eyes
[00:37:20.600 --> 00:37:22.360]   as your eyelids close,
[00:37:22.360 --> 00:37:25.360]   well, then you're in the highly hypnotizable realm.
[00:37:25.360 --> 00:37:26.320]   Kind of interesting, right?
[00:37:26.320 --> 00:37:27.960]   There's all nervous system-related,
[00:37:27.960 --> 00:37:29.400]   and you can see this stuff is,
[00:37:29.400 --> 00:37:32.000]   this is like real clinical tools.
[00:37:32.000 --> 00:37:33.280]   Okay, how do we stop ourselves
[00:37:33.280 --> 00:37:36.240]   from mindlessly scrolling on our phones?
[00:37:36.240 --> 00:37:38.160]   Hard questions.
[00:37:38.160 --> 00:37:39.560]   I didn't look at my watch 'cause I'm bored.
[00:37:39.560 --> 00:37:41.760]   I'm just thinking, how much time do you have?
[00:37:44.380 --> 00:37:47.100]   Well, on the way here to Australia,
[00:37:47.100 --> 00:37:48.860]   my, Rob, who you met earlier,
[00:37:48.860 --> 00:37:51.820]   my friend and podcast producer,
[00:37:51.820 --> 00:37:53.100]   he said, "Okay, you guys,
[00:37:53.100 --> 00:37:56.800]   "everyone's deleting social media from your phones
[00:37:56.800 --> 00:38:00.660]   "for the whole trip, the whole trip."
[00:38:00.660 --> 00:38:02.700]   And I'm like, "Mm, I don't know if I can go on this trip,
[00:38:02.700 --> 00:38:03.860]   "Rob, no, I'm kidding."
[00:38:03.860 --> 00:38:07.900]   We have one guy who's kept it on his phone
[00:38:07.900 --> 00:38:11.300]   so that we can post things, and we continue to.
[00:38:12.520 --> 00:38:14.480]   Honestly, I think that's what it takes.
[00:38:14.480 --> 00:38:17.320]   If it's social media that you're scrolling,
[00:38:17.320 --> 00:38:21.280]   I think you should do a delete and reinstall.
[00:38:21.280 --> 00:38:23.960]   If I'm honest, a delete and reinstall every day.
[00:38:23.960 --> 00:38:27.360]   Because I think,
[00:38:27.360 --> 00:38:29.280]   and then you have to limit the amount of time.
[00:38:29.280 --> 00:38:32.280]   And one of the members of my podcast team experienced this.
[00:38:32.280 --> 00:38:33.940]   He said, "I just picked up my phone a minute ago,
[00:38:33.940 --> 00:38:36.520]   "and I went to hit the Instagram tab,
[00:38:36.520 --> 00:38:38.640]   "and it wasn't there, and I know it's not there."
[00:38:38.640 --> 00:38:40.760]   And that's where I say, yeah, at some point,
[00:38:40.760 --> 00:38:43.160]   it becomes more compulsive than addiction.
[00:38:43.160 --> 00:38:44.920]   These are just reflexive behaviors.
[00:38:44.920 --> 00:38:46.640]   It's like walking in the refrigerator.
[00:38:46.640 --> 00:38:49.200]   I did it every day of my life, all day.
[00:38:49.200 --> 00:38:50.120]   I walk into people's homes
[00:38:50.120 --> 00:38:52.080]   and just look in the refrigerator.
[00:38:52.080 --> 00:38:52.920]   I don't even know.
[00:38:52.920 --> 00:38:55.520]   I get into people's cars, I look in the glove box.
[00:38:55.520 --> 00:38:56.360]   I just do this.
[00:38:56.360 --> 00:38:57.440]   I'm kinda like looking around.
[00:38:57.440 --> 00:38:59.020]   I'm not gonna steal anything.
[00:38:59.020 --> 00:39:02.120]   But it's like the teenage boy in me.
[00:39:02.120 --> 00:39:03.320]   You know, I just kinda like walk in,
[00:39:03.320 --> 00:39:04.960]   I'm gonna open your refrigerator.
[00:39:04.960 --> 00:39:09.600]   So I think it gets to the point of reflexive,
[00:39:09.600 --> 00:39:13.600]   and it's compulsive, and it might be addictive,
[00:39:13.600 --> 00:39:17.960]   but it can't be good when it's like that.
[00:39:17.960 --> 00:39:20.200]   But I think social media can be really useful.
[00:39:20.200 --> 00:39:24.720]   So I think if you're, you can set timers.
[00:39:24.720 --> 00:39:26.040]   You can try graying out the screen,
[00:39:26.040 --> 00:39:27.720]   getting rid of the color thing.
[00:39:27.720 --> 00:39:28.580]   There's all this stuff,
[00:39:28.580 --> 00:39:30.560]   but I think if there are particular apps
[00:39:30.560 --> 00:39:31.400]   that you're struggling with,
[00:39:31.400 --> 00:39:33.860]   I would just delete them from your phone and do a reinstall,
[00:39:33.860 --> 00:39:37.680]   because that's enough of a behavioral barrier.
[00:39:37.680 --> 00:39:39.680]   There are enough steps involved, enough sequencing
[00:39:39.680 --> 00:39:42.800]   to put the thing back on there each day and each time,
[00:39:42.800 --> 00:39:44.640]   maybe twice a day, that you're going
[00:39:44.640 --> 00:39:46.720]   to vastly reduce your use.
[00:39:46.720 --> 00:39:48.960]   To be honest, I think that's probably the best way to do it.
[00:39:48.960 --> 00:39:50.680]   And there are probably people in this audience
[00:39:50.680 --> 00:39:52.360]   that are thinking this seems crazy.
[00:39:52.360 --> 00:39:53.480]   Like just don't turn it on.
[00:39:53.480 --> 00:39:55.560]   Just don't open it.
[00:39:55.560 --> 00:39:59.640]   And look, if I was 65 years old, I'd say that too.
[00:39:59.640 --> 00:40:03.640]   But it doesn't work that way
[00:40:03.640 --> 00:40:06.420]   for certainly the younger generation.
[00:40:06.420 --> 00:40:07.260]   It doesn't.
[00:40:07.260 --> 00:40:08.280]   I know this 'cause I gave a talk
[00:40:08.280 --> 00:40:10.120]   at Santa Clara University a few years ago,
[00:40:10.120 --> 00:40:15.120]   and I was talking about limiting social media use and phones.
[00:40:15.120 --> 00:40:16.720]   And this kid came up to me afterwards.
[00:40:16.720 --> 00:40:18.360]   He said, "You don't get it."
[00:40:18.360 --> 00:40:20.600]   It's like you're like, back then I was like 43.
[00:40:20.600 --> 00:40:22.120]   He said, "You don't get it."
[00:40:22.120 --> 00:40:24.200]   He said, "For you, the phone was a thing
[00:40:24.200 --> 00:40:25.360]   "that you like integrated
[00:40:25.360 --> 00:40:27.800]   "into your like post '90s high school life.
[00:40:27.800 --> 00:40:29.880]   "Like you watched 'The Breakfast Club'."
[00:40:29.880 --> 00:40:31.680]   Or something, I don't know how he knew that movie.
[00:40:31.680 --> 00:40:32.500]   I was like, "You're right.
[00:40:32.500 --> 00:40:35.000]   "I did watch 'The Breakfast Club' a bunch of times."
[00:40:36.200 --> 00:40:41.040]   And he said, "But for us, it's like life."
[00:40:41.040 --> 00:40:42.080]   I was like.
[00:40:42.080 --> 00:40:43.700]   I rolled my eyes and I thought, wait, no, listen.
[00:40:43.700 --> 00:40:45.840]   I'm gonna listen 'cause no one knows what it's like
[00:40:45.840 --> 00:40:49.340]   to be 16 years old or 24 years old in 2024,
[00:40:49.340 --> 00:40:51.100]   unless you're 16 or 24.
[00:40:51.100 --> 00:40:53.180]   I'm like, okay, here we go.
[00:40:53.180 --> 00:40:54.700]   Listen, he said, "When my phone,"
[00:40:54.700 --> 00:40:57.300]   he said, "When my phone powers down,
[00:40:57.300 --> 00:41:01.280]   "I feel the energy drain out of me.
[00:41:01.280 --> 00:41:02.700]   "And when it comes back up,
[00:41:02.700 --> 00:41:06.120]   "I feel life energy come back into my body."
[00:41:06.120 --> 00:41:09.200]   And I thought, oh my goodness, like we are hosed.
[00:41:09.200 --> 00:41:12.300]   But that's the reality.
[00:41:12.300 --> 00:41:15.520]   And I'm of the mind, you know, I was a camp counselor.
[00:41:15.520 --> 00:41:16.720]   I worked with at-risk kids.
[00:41:16.720 --> 00:41:17.720]   I was a wild kid.
[00:41:17.720 --> 00:41:18.880]   And you learn something,
[00:41:18.880 --> 00:41:21.280]   especially when you work with kids like me.
[00:41:21.280 --> 00:41:23.360]   When I was a teenager, I was a hellion,
[00:41:23.360 --> 00:41:26.380]   is be a channel, not a dam.
[00:41:26.380 --> 00:41:30.200]   You cannot block this system that's emerged.
[00:41:30.200 --> 00:41:31.940]   This is here and it's here to stay.
[00:41:31.940 --> 00:41:34.040]   So I think things like deleting the app
[00:41:34.040 --> 00:41:36.520]   is putting it back on there is the only way to go.
[00:41:36.520 --> 00:41:37.400]   And we have to listen.
[00:41:37.400 --> 00:41:39.440]   I think we have to listen to understand that,
[00:41:39.440 --> 00:41:42.760]   you know, we, after all, adults created these technologies
[00:41:42.760 --> 00:41:44.280]   and these kids are using them.
[00:41:44.280 --> 00:41:46.760]   And I don't think we're gonna see a reversal.
[00:41:46.760 --> 00:41:47.800]   I don't.
[00:41:47.800 --> 00:41:51.040]   So we have to really, I think that what he said to me,
[00:41:51.040 --> 00:41:53.740]   as scary as it was to me, I think reflects the reality.
[00:41:53.740 --> 00:41:55.440]   It's part of their life energy.
[00:41:55.440 --> 00:41:57.440]   It's part of their connectivity.
[00:41:57.440 --> 00:41:59.720]   And we're gonna have to come up with better tools.
[00:41:59.720 --> 00:42:02.500]   And I doubt those tools are going to be
[00:42:02.500 --> 00:42:04.860]   to the effect of eliminating it.
[00:42:04.860 --> 00:42:07.780]   You could say, unfortunately, you know, all the adult,
[00:42:07.780 --> 00:42:09.220]   last I checked, I'm an adult
[00:42:09.220 --> 00:42:11.380]   and people in my life have argued differently.
[00:42:11.380 --> 00:42:14.520]   But I think we're gonna have to learn to be a channel,
[00:42:14.520 --> 00:42:16.140]   not a dam with this.
[00:42:16.140 --> 00:42:16.960]   I do.
[00:42:16.960 --> 00:42:19.660]   If resources and ethics were not an issue,
[00:42:19.660 --> 00:42:22.900]   what would your dream clinical trial to run?
[00:42:22.900 --> 00:42:26.880]   Oh my goodness, this is a hard question.
[00:42:26.880 --> 00:42:29.880]   (audience laughing)
[00:42:29.880 --> 00:42:32.760]   Okay.
[00:42:32.760 --> 00:42:34.560]   Dream clinical trial.
[00:42:34.560 --> 00:42:36.980]   What's that?
[00:42:36.980 --> 00:42:41.060]   Oh gosh, the accent is killing me.
[00:42:41.060 --> 00:42:44.560]   More cuttlefish, yeah, more cuttlefish.
[00:42:44.560 --> 00:42:47.400]   Like cuttlefish, I like the idea of more cuddling.
[00:42:47.400 --> 00:42:52.140]   Physical contact, so key.
[00:42:52.140 --> 00:42:56.420]   I think we're all still recovering from the years,
[00:42:56.420 --> 00:42:58.660]   we had a few years of just like no physical,
[00:42:58.660 --> 00:43:00.940]   like physical contact, so minimal.
[00:43:00.940 --> 00:43:04.060]   I mean, there's the classic Harlow experiments, right?
[00:43:04.060 --> 00:43:06.540]   The wire monkey versus the cloth monkey.
[00:43:06.540 --> 00:43:09.620]   I mean, primates go to the cloth monkey
[00:43:09.620 --> 00:43:10.900]   even if they don't get food there.
[00:43:10.900 --> 00:43:13.060]   I mean, it's such a critical component
[00:43:13.060 --> 00:43:15.660]   of, you know, how our nervous system forms.
[00:43:15.660 --> 00:43:20.340]   I think this is a, you know what?
[00:43:20.340 --> 00:43:21.500]   I'm gonna do something I've never done before.
[00:43:21.500 --> 00:43:23.400]   I'm gonna turn the question around.
[00:43:23.400 --> 00:43:25.140]   I actually would, seriously,
[00:43:25.140 --> 00:43:26.500]   I'm not trying to avoid answering this,
[00:43:26.500 --> 00:43:28.420]   but, you know, we've worked on all sorts,
[00:43:28.420 --> 00:43:29.260]   I've worked on cuttlefish,
[00:43:29.260 --> 00:43:30.960]   we've worked on respiration practices,
[00:43:30.960 --> 00:43:32.860]   we've worked on vision,
[00:43:32.860 --> 00:43:34.540]   we've worked on neural regeneration.
[00:43:34.540 --> 00:43:38.420]   You know, I've enjoyed working on a great number
[00:43:38.420 --> 00:43:39.260]   of different things.
[00:43:39.260 --> 00:43:41.940]   I'm sort of curious what people,
[00:43:41.940 --> 00:43:43.940]   like what do you think we need more of?
[00:43:43.940 --> 00:43:46.220]   I've never done this, but I really wanna know.
[00:43:46.220 --> 00:43:47.180]   I don't know how we're gonna do this
[00:43:47.180 --> 00:43:49.840]   in any kind of non-chaotic format, but what the hell.
[00:43:49.840 --> 00:43:51.020]   (audience laughing)
[00:43:51.020 --> 00:43:54.160]   It's late enough in the evening, we'll just do it.
[00:43:54.160 --> 00:43:56.980]   Like really, I mean, so now there's trials on psychedelics.
[00:43:56.980 --> 00:43:58.500]   Maybe we do this by kind of like,
[00:43:58.500 --> 00:44:00.380]   I'll throw out some options and then we'll do it.
[00:44:00.380 --> 00:44:03.440]   So right now it seems that psychedelics are a big thing.
[00:44:03.440 --> 00:44:06.740]   Do they increase plasticity?
[00:44:06.740 --> 00:44:07.980]   Yeah, I'm excited about it.
[00:44:07.980 --> 00:44:10.820]   I'm a convert, but I do think that one has to be careful
[00:44:10.820 --> 00:44:13.100]   and there are certain people in populations,
[00:44:13.100 --> 00:44:17.620]   like people who suffer from certain types of manic bipolar
[00:44:17.620 --> 00:44:19.720]   or schizophrenia that really need to avoid these things.
[00:44:19.720 --> 00:44:22.100]   Kids, I mean, being a kid is basically
[00:44:22.100 --> 00:44:23.580]   being in a psychedelic state.
[00:44:24.240 --> 00:44:27.680]   The lateral connectivity of the brain is extensive
[00:44:27.680 --> 00:44:30.560]   and I don't encourage it.
[00:44:30.560 --> 00:44:33.760]   I mean, the trials with MDMA and PTSD are incredible.
[00:44:33.760 --> 00:44:35.720]   What's happening with MAPS is incredible.
[00:44:35.720 --> 00:44:38.120]   60 plus percent remission rates,
[00:44:38.120 --> 00:44:40.080]   done with licensed physicians, of course.
[00:44:40.080 --> 00:44:41.800]   I don't get cavalier with this.
[00:44:41.800 --> 00:44:43.200]   So, okay, so I'll just ask.
[00:44:43.200 --> 00:44:47.820]   So, I mean, it's gonna be hard to draw out the dissenters,
[00:44:47.820 --> 00:44:51.280]   but more work on psychedelics, psilocybin, et cetera,
[00:44:51.280 --> 00:44:53.120]   as ways to ameliorate depression.
[00:44:53.120 --> 00:44:56.680]   Are people like more like yum, yuck, or meh?
[00:44:56.680 --> 00:44:59.720]   Is it like yum, okay, or like yuck?
[00:44:59.720 --> 00:45:01.000]   Don't be afraid to say yuck.
[00:45:01.000 --> 00:45:02.240]   I like a good argument.
[00:45:02.240 --> 00:45:04.520]   Is anyone like yuck on psychedelics?
[00:45:04.520 --> 00:45:06.360]   Sorcery, it's sorcery.
[00:45:06.360 --> 00:45:07.200]   I heard that.
[00:45:07.200 --> 00:45:09.480]   Meh, okay.
[00:45:09.480 --> 00:45:10.440]   All right, interesting.
[00:45:10.440 --> 00:45:12.360]   Okay, so psychedelics get a strong push.
[00:45:12.360 --> 00:45:14.240]   I think we have enough evidence
[00:45:14.240 --> 00:45:18.000]   that changing patterns of respiration changes brain states,
[00:45:18.000 --> 00:45:20.260]   but I think that that's an interesting area.
[00:45:21.880 --> 00:45:22.720]   I don't know.
[00:45:22.720 --> 00:45:23.880]   Can you just shout it out?
[00:45:23.880 --> 00:45:24.960]   Just shout it out.
[00:45:24.960 --> 00:45:27.640]   All right, first over here, yes?
[00:45:27.640 --> 00:45:29.840]   Oh, God, the accent.
[00:45:29.840 --> 00:45:31.000]   You guys are so good.
[00:45:31.000 --> 00:45:32.920]   I love the accent.
[00:45:32.920 --> 00:45:35.600]   Listen, I don't drink anymore,
[00:45:35.600 --> 00:45:37.640]   but when I used to go to bars,
[00:45:37.640 --> 00:45:40.960]   I'll just say the Australian accent never fails.
[00:45:40.960 --> 00:45:42.160]   In the US, yeah?
[00:45:42.160 --> 00:45:46.480]   Time chambers.
[00:45:46.480 --> 00:45:47.600]   Time chambers.
[00:45:47.600 --> 00:45:51.180]   (audience member mumbling)
[00:45:51.180 --> 00:45:55.640]   Oh, hyperbaric chambers.
[00:45:55.640 --> 00:45:57.240]   Yeah, hyperbaric, that's an interesting one.
[00:45:57.240 --> 00:46:00.240]   Yeah, I mean, when I think of ways to modify physiology,
[00:46:00.240 --> 00:46:04.760]   you think temperature, light, neuromodulators, right?
[00:46:04.760 --> 00:46:06.280]   You think, by the way,
[00:46:06.280 --> 00:46:08.080]   anytime you wanna think about changing something
[00:46:08.080 --> 00:46:09.040]   in the body or brain,
[00:46:09.040 --> 00:46:11.160]   you think mechanical and chemical.
[00:46:11.160 --> 00:46:12.640]   So this is kind of,
[00:46:12.640 --> 00:46:15.280]   this is changing the chemistry of the brain and body
[00:46:15.280 --> 00:46:16.300]   through hyperbaric chambers.
[00:46:16.300 --> 00:46:17.140]   Thank you.
[00:46:17.140 --> 00:46:17.980]   I appreciate it.
[00:46:17.980 --> 00:46:18.800]   I think I,
[00:46:18.800 --> 00:46:20.640]   did we run into each other at the gym the other day?
[00:46:20.640 --> 00:46:24.360]   No, anyway, I think I recognize you.
[00:46:24.360 --> 00:46:30.480]   Okay, I'll get to you in one second, yeah?
[00:46:30.480 --> 00:46:33.160]   Yeah, love that.
[00:46:33.160 --> 00:46:36.000]   Okay, so protocols for childhood trauma, yeah.
[00:46:36.000 --> 00:46:37.840]   So, I mean, I think we're finally at the place
[00:46:37.840 --> 00:46:40.240]   where we, as a world,
[00:46:40.240 --> 00:46:43.440]   where this word trauma actually is meaningful,
[00:46:43.440 --> 00:46:44.920]   because we knew it before,
[00:46:44.920 --> 00:46:47.040]   but I think before, people thought if you hadn't,
[00:46:47.040 --> 00:46:49.840]   lived in a war zone, which obviously is trauma,
[00:46:49.840 --> 00:46:53.200]   now I think people appreciate that trauma
[00:46:53.200 --> 00:46:55.660]   is inherent to a lot of life.
[00:46:55.660 --> 00:46:56.700]   By the way, I love your shirt.
[00:46:56.700 --> 00:46:57.540]   I own that shirt.
[00:46:57.540 --> 00:46:59.560]   It's like, yeah, it's a Lonsdale shirt.
[00:46:59.560 --> 00:47:00.560]   It's against racism.
[00:47:00.560 --> 00:47:02.760]   Hey, I love that shirt.
[00:47:02.760 --> 00:47:04.400]   You know the history of that shirt, right?
[00:47:04.400 --> 00:47:08.040]   It's like Lonsdale was co-opted by some neo-Nazi groups
[00:47:08.040 --> 00:47:08.880]   as a brand.
[00:47:08.880 --> 00:47:11.640]   So Lonsdale came out with an against racism and hate shirt,
[00:47:11.640 --> 00:47:14.520]   which is like the best, like, to that, which is, yeah.
[00:47:14.520 --> 00:47:16.600]   So anyway, a little side note there.
[00:47:16.600 --> 00:47:18.100]   Not sponsored by Lonsdale,
[00:47:18.100 --> 00:47:20.920]   but rad shirt.
[00:47:20.920 --> 00:47:22.360]   Yeah, I think childhood trauma,
[00:47:22.360 --> 00:47:25.980]   you know, trauma can be best defined as an adverse event
[00:47:25.980 --> 00:47:28.480]   that changes the nervous system in a way
[00:47:28.480 --> 00:47:30.920]   that causes maladaptive functioning going forward.
[00:47:30.920 --> 00:47:33.000]   It's not every bad thing, right?
[00:47:33.000 --> 00:47:34.040]   But it certainly happens.
[00:47:34.040 --> 00:47:38.320]   And I think we need to learn to rewire the nervous system.
[00:47:38.320 --> 00:47:40.000]   Let's face it, whether or not psychedelics
[00:47:40.000 --> 00:47:42.720]   or it's talk therapy or it's hyperbaric chambers
[00:47:42.720 --> 00:47:43.600]   or it's cold plunges,
[00:47:43.600 --> 00:47:45.380]   what we're talking about is neuroplasticity.
[00:47:45.380 --> 00:47:47.200]   We're trying to rewire the nervous system.
[00:47:47.200 --> 00:47:49.100]   So I love that one.
[00:47:49.100 --> 00:47:52.120]   We need some very structured tools.
[00:47:52.120 --> 00:47:54.200]   And there's all sorts of stuff about SOAS release
[00:47:54.200 --> 00:47:55.040]   for trauma.
[00:47:55.040 --> 00:47:56.100]   And, you know, there's little bits,
[00:47:56.100 --> 00:47:58.800]   like little silos of things that are all very interesting,
[00:47:58.800 --> 00:48:00.580]   breath work, you know, release work.
[00:48:00.580 --> 00:48:03.760]   But so far there isn't like a structured framework
[00:48:03.760 --> 00:48:05.000]   for treating trauma.
[00:48:05.000 --> 00:48:07.440]   Different groups doing different things, EMDR, et cetera.
[00:48:07.440 --> 00:48:09.200]   I think they all have merit.
[00:48:09.200 --> 00:48:11.100]   Okay, there was the shouting out.
[00:48:12.520 --> 00:48:16.760]   Consciousness, the big C, yeah.
[00:48:16.760 --> 00:48:18.620]   In my house, Costello was the big C.
[00:48:18.620 --> 00:48:19.700]   He would always remind me of that.
[00:48:19.700 --> 00:48:24.060]   But consciousness, I think that now with AI,
[00:48:24.060 --> 00:48:27.460]   we have to ask ourselves like, what is consciousness?
[00:48:27.460 --> 00:48:30.260]   And I think we need a clear definition of what that is.
[00:48:30.260 --> 00:48:31.860]   Do you guys know this story of like,
[00:48:31.860 --> 00:48:33.980]   they were gonna solve consciousness a few years ago
[00:48:33.980 --> 00:48:35.580]   and they didn't do it.
[00:48:35.580 --> 00:48:37.780]   There was this bet in neuroscience
[00:48:37.780 --> 00:48:42.680]   that it was gonna be solved by 2015 or something like that.
[00:48:42.680 --> 00:48:44.360]   So I think we need, and it's not obviously,
[00:48:44.360 --> 00:48:46.320]   so we need better definition of what that means.
[00:48:46.320 --> 00:48:49.880]   But I think it's a very important problem indeed.
[00:48:49.880 --> 00:48:50.860]   So thank you.
[00:48:50.860 --> 00:48:51.700]   Maybe a--
[00:48:51.700 --> 00:48:55.700]   Free will, yeah, that's a tough one.
[00:48:55.700 --> 00:48:57.080]   That's one I usually avoid.
[00:48:57.080 --> 00:49:01.680]   Robert slammed me on that one on the podcast.
[00:49:01.680 --> 00:49:02.880]   What was it in the back?
[00:49:02.880 --> 00:49:07.720]   I heard it as an adaptive technique,
[00:49:07.720 --> 00:49:11.000]   but, oh, yeah.
[00:49:11.000 --> 00:49:15.000]   You know, we hear so much, I'm agreeing with you.
[00:49:15.000 --> 00:49:17.200]   We hear so much about ADHD these days
[00:49:17.200 --> 00:49:20.120]   without an understanding of what it really reflects,
[00:49:20.120 --> 00:49:22.560]   except in the extreme clinical cases.
[00:49:22.560 --> 00:49:24.520]   So I think a better understanding.
[00:49:24.520 --> 00:49:26.440]   I did two episodes of the podcast, by the way,
[00:49:26.440 --> 00:49:27.680]   on attention and ADHD.
[00:49:27.680 --> 00:49:31.880]   One focused mainly on behavioral and nutritional tools.
[00:49:31.880 --> 00:49:34.280]   It was positively received by about half of people.
[00:49:34.280 --> 00:49:37.320]   And then the other half were like, this is garbage.
[00:49:37.320 --> 00:49:38.960]   What about all the drugs that are useful?
[00:49:38.960 --> 00:49:41.800]   Then I did one about all the drugs that can be useful.
[00:49:41.800 --> 00:49:43.560]   People said, this is garbage.
[00:49:43.560 --> 00:49:44.880]   You're putting kids on meth.
[00:49:44.880 --> 00:49:46.600]   And I'm like, wait a second, hold on.
[00:49:46.600 --> 00:49:48.360]   We try and cover it all.
[00:49:48.360 --> 00:49:52.540]   So, because I favor balance.
[00:49:52.540 --> 00:49:54.880]   I heard excellent things.
[00:49:54.880 --> 00:49:56.280]   They were all male voices.
[00:49:56.280 --> 00:49:58.120]   We kind of got a sampling bias here,
[00:49:58.120 --> 00:50:00.660]   unless I've got a high frequency cutoff.
[00:50:00.660 --> 00:50:01.500]   Thank you.
[00:50:01.500 --> 00:50:05.340]   Something negotiation, sorry.
[00:50:05.980 --> 00:50:08.180]   (audience member speaking faintly)
[00:50:08.180 --> 00:50:12.100]   Science of negotiation.
[00:50:12.100 --> 00:50:17.100]   Yeah, so people being able to resolve differences better.
[00:50:17.100 --> 00:50:19.940]   Lord, please, yes.
[00:50:19.940 --> 00:50:21.620]   (audience laughing)
[00:50:21.620 --> 00:50:22.620]   Oh my goodness.
[00:50:22.620 --> 00:50:25.620]   I mean, this is, yes, thank you.
[00:50:25.620 --> 00:50:29.160]   If ever there was a call to action, it's like,
[00:50:29.160 --> 00:50:31.980]   you know, this is a big question, right?
[00:50:31.980 --> 00:50:34.060]   I'm a neuroscientist, not a historian,
[00:50:34.060 --> 00:50:38.300]   not a futurist or a politician, but thank goodness.
[00:50:38.300 --> 00:50:39.940]   Imagine what a terrible job I would do.
[00:50:39.940 --> 00:50:40.820]   I like being outdoors.
[00:50:40.820 --> 00:50:42.300]   I hate meetings.
[00:50:42.300 --> 00:50:43.980]   I like dressing like this.
[00:50:43.980 --> 00:50:46.940]   And I don't like the news.
[00:50:46.940 --> 00:50:48.740]   It'd be the worst.
[00:50:48.740 --> 00:50:53.580]   But yeah, if ever there was a need and a question,
[00:50:53.580 --> 00:50:56.060]   it's, you know, are we just gonna continue
[00:50:56.060 --> 00:50:58.380]   in these like iterative cycles of like,
[00:50:58.380 --> 00:51:00.380]   when the economy is good, things seem mostly good.
[00:51:00.380 --> 00:51:01.900]   And then a lot of people are still suffering.
[00:51:01.900 --> 00:51:03.700]   And then it's like these cycles of,
[00:51:03.700 --> 00:51:08.540]   or are we going to finally just sit back and go,
[00:51:08.540 --> 00:51:11.060]   okay, what are we good at as a species?
[00:51:11.060 --> 00:51:13.060]   What are we really bad at?
[00:51:13.060 --> 00:51:14.580]   What are we like kind of good at?
[00:51:14.580 --> 00:51:16.020]   And start coming up with some tools
[00:51:16.020 --> 00:51:17.840]   to try and function better on the whole,
[00:51:17.840 --> 00:51:20.960]   with the understanding that there are bad actors out there
[00:51:20.960 --> 00:51:23.380]   that are constantly trying to, you know,
[00:51:23.380 --> 00:51:24.480]   exploit and manipulate.
[00:51:24.480 --> 00:51:26.380]   But there are also a lot of good actors too.
[00:51:26.380 --> 00:51:28.300]   And by good actors, I don't mean actors
[00:51:28.300 --> 00:51:29.900]   in the stage acting sense.
[00:51:29.900 --> 00:51:34.900]   I mean, I think that, look, we're a smart species.
[00:51:34.900 --> 00:51:38.140]   We can think in past, present, and future terms.
[00:51:38.140 --> 00:51:39.740]   We can look at mechanism.
[00:51:39.740 --> 00:51:41.820]   We can communicate better with each other,
[00:51:41.820 --> 00:51:44.500]   better than any species, except maybe the cuttlefish.
[00:51:44.500 --> 00:51:48.060]   And so I think the question is, are we, you know,
[00:51:48.060 --> 00:51:50.500]   is there gonna be some sort of sitting back
[00:51:50.500 --> 00:51:53.380]   and finally just saying like enough?
[00:51:53.380 --> 00:51:56.300]   Like, let's just figure out a way to dialogue.
[00:51:56.300 --> 00:51:57.900]   And I love that.
[00:51:59.460 --> 00:52:03.900]   You know, it's a science way that there are problems
[00:52:03.900 --> 00:52:05.300]   and there are hard problems.
[00:52:05.300 --> 00:52:09.620]   And honestly, I think it's gonna come about,
[00:52:09.620 --> 00:52:12.420]   if it comes about, it's gonna come about through groups,
[00:52:12.420 --> 00:52:13.580]   not through individuals.
[00:52:13.580 --> 00:52:15.820]   I don't think we're gonna get like the world leader
[00:52:15.820 --> 00:52:19.300]   or world leaders of 12 people like, let's get it done.
[00:52:19.300 --> 00:52:21.400]   Let's get it done right this time.
[00:52:21.400 --> 00:52:25.380]   I think it's gonna be a more collective consciousness.
[00:52:25.380 --> 00:52:28.100]   You know, I'd like to see fewer individual leaders
[00:52:28.100 --> 00:52:30.340]   and more groups and panels leading things.
[00:52:30.340 --> 00:52:33.340]   But anyway, that's my bias in that, you know.
[00:52:33.340 --> 00:52:37.220]   Genetics?
[00:52:37.220 --> 00:52:44.140]   Genetics?
[00:52:44.140 --> 00:52:46.700]   Genetics.
[00:52:46.700 --> 00:52:48.620]   Love it.
[00:52:48.620 --> 00:52:50.980]   Yeah.
[00:52:50.980 --> 00:52:54.020]   Okay, well there's, okay, I'll say two things
[00:52:54.020 --> 00:52:57.220]   and then I think my team's gonna make me close out.
[00:52:57.220 --> 00:52:58.060]   Wait.
[00:52:58.060 --> 00:53:07.940]   Rad, okay, awesome.
[00:53:07.940 --> 00:53:10.340]   Now it's turning into like a science punk rock show.
[00:53:10.340 --> 00:53:15.340]   So the genetics, well I think the big things in genetics
[00:53:15.340 --> 00:53:17.580]   are we're soon gonna be in the place
[00:53:17.580 --> 00:53:21.460]   where we can do genetic, right now you can take human embryos
[00:53:21.460 --> 00:53:24.820]   and screen them for mutations by whole genome sequencing.
[00:53:24.820 --> 00:53:27.260]   It's very inexpensive compared to a few years ago.
[00:53:27.260 --> 00:53:29.780]   It's still expensive and you can do selection.
[00:53:29.780 --> 00:53:32.860]   You can select out based on lack of mutations.
[00:53:32.860 --> 00:53:36.260]   Maybe even based on over representation of certain genes.
[00:53:36.260 --> 00:53:41.220]   That's interesting, has some ethical considerations.
[00:53:41.220 --> 00:53:43.980]   But soon we'll be, you can do CRISPR.
[00:53:43.980 --> 00:53:48.580]   You could, in theory, you could modify the genome
[00:53:48.580 --> 00:53:52.140]   of adults and certainly babies.
[00:53:52.140 --> 00:53:53.540]   And so that's where we're headed.
[00:53:53.540 --> 00:53:55.100]   It's already being done in certain countries.
[00:53:55.100 --> 00:53:57.060]   It was done in China.
[00:53:57.060 --> 00:53:59.340]   It was not looked upon kindly
[00:53:59.340 --> 00:54:01.300]   by the international ethics committees.
[00:54:01.300 --> 00:54:06.340]   But it was done, a mutation in the HIV receptor.
[00:54:06.340 --> 00:54:10.300]   So those babies exist.
[00:54:10.300 --> 00:54:11.820]   So it's happening.
[00:54:11.820 --> 00:54:13.860]   It's gonna be interesting times.
[00:54:13.860 --> 00:54:15.940]   The microbiome, I think, is really exciting.
[00:54:15.940 --> 00:54:18.360]   Here's my big call to action is that
[00:54:18.360 --> 00:54:19.620]   there's a microbiome in the gut
[00:54:19.620 --> 00:54:21.300]   but there's also a microbiome on the skin
[00:54:21.300 --> 00:54:23.940]   and the nose and the mouth and the genitals.
[00:54:23.940 --> 00:54:26.140]   Like these, all these little niches.
[00:54:26.140 --> 00:54:27.460]   And well, I guess it depends.
[00:54:27.460 --> 00:54:29.620]   The little or not so little niches.
[00:54:29.620 --> 00:54:30.460]   Depends.
[00:54:30.460 --> 00:54:34.060]   I was thinking about the nostrils.
[00:54:34.060 --> 00:54:37.020]   The night's getting long.
[00:54:37.020 --> 00:54:37.940]   There I go again.
[00:54:37.940 --> 00:54:43.820]   They are all important and there's a lot more to understand.
[00:54:43.820 --> 00:54:47.340]   I think the gut microbiome is just one of the microbiomes.
[00:54:47.340 --> 00:54:50.480]   So, and female hormones, certainly important topic.
[00:54:50.480 --> 00:54:53.900]   It's received far less, sadly, far less attention
[00:54:53.900 --> 00:54:57.220]   than male hormone therapy or understanding.
[00:54:57.220 --> 00:55:00.540]   And things are starting to change there.
[00:55:00.540 --> 00:55:01.880]   It's been slow.
[00:55:01.880 --> 00:55:04.780]   Yeah, yeah, it's been, can you believe it?
[00:55:04.780 --> 00:55:07.540]   It was like, only like eight years ago
[00:55:07.540 --> 00:55:09.780]   that the National Institutes of Health in the United States
[00:55:09.780 --> 00:55:11.180]   was like, hey, maybe you should start
[00:55:11.180 --> 00:55:12.780]   studying female mice too.
[00:55:12.780 --> 00:55:17.780]   It's like, I mean, modern science is very far behind.
[00:55:17.780 --> 00:55:19.980]   We're very far behind.
[00:55:19.980 --> 00:55:21.780]   And I think it's a resource issue.
[00:55:21.780 --> 00:55:26.780]   It's also, there's a bunch of sociological considerations
[00:55:26.780 --> 00:55:27.660]   in science.
[00:55:27.660 --> 00:55:31.220]   Anyway, I'm trying to change the story there,
[00:55:31.220 --> 00:55:33.260]   but I'm but one person.
[00:55:33.260 --> 00:55:35.260]   And I hope to live a very long time.
[00:55:35.260 --> 00:55:40.040]   But should I get hit by a bullet, a bus, or cancer tomorrow,
[00:55:40.040 --> 00:55:41.980]   I want you to know that it's gonna be,
[00:55:41.980 --> 00:55:44.980]   or long time from now, to have natural causes.
[00:55:44.980 --> 00:55:47.500]   Sorry, I have a morbid sense of humor.
[00:55:47.500 --> 00:55:48.820]   I worked with the physicians.
[00:55:48.820 --> 00:55:50.060]   They all talk like that.
[00:55:50.060 --> 00:55:52.460]   I hope to live a very long time.
[00:55:52.460 --> 00:55:53.820]   But it's a collective effort.
[00:55:53.820 --> 00:55:56.260]   So I just want to, before we wrap,
[00:55:56.260 --> 00:55:58.020]   I want to say a couple of things.
[00:55:58.020 --> 00:56:00.880]   And we can get on with the rest of the night.
[00:56:00.880 --> 00:56:04.660]   First of all, it is a collective effort.
[00:56:04.660 --> 00:56:07.020]   You know, as I've mentioned several times this evening,
[00:56:07.020 --> 00:56:11.940]   I look no differently on the massage therapy
[00:56:11.940 --> 00:56:15.820]   versus chiropractic versus whole genome sequencing.
[00:56:15.820 --> 00:56:18.580]   It's just all different lenses to look at
[00:56:18.580 --> 00:56:21.620]   the same sort of set of goals through.
[00:56:21.620 --> 00:56:24.060]   And yes, there's a range of quality and rigor
[00:56:24.060 --> 00:56:26.420]   and communication styles and personalities.
[00:56:26.420 --> 00:56:29.220]   But if you can maintain some level of curiosity
[00:56:29.220 --> 00:56:31.220]   and discernment about what works for you
[00:56:31.220 --> 00:56:32.100]   or doesn't work for you,
[00:56:32.100 --> 00:56:34.620]   or where you think there's merit, that's great.
[00:56:34.620 --> 00:56:37.300]   But it's gonna be a wonderful thing
[00:56:37.300 --> 00:56:38.740]   when we can all start to dialogue
[00:56:38.740 --> 00:56:40.500]   and see where the points of convergence are,
[00:56:40.500 --> 00:56:43.000]   where you're basically talking about two different groups
[00:56:43.000 --> 00:56:44.300]   talking about the exact same thing
[00:56:44.300 --> 00:56:45.140]   through a different language.
[00:56:45.140 --> 00:56:48.380]   I think that's where things really can move forward.
[00:56:48.380 --> 00:56:51.520]   The discourse of public science and health communication
[00:56:51.520 --> 00:56:54.140]   obviously is something I'm very passionate about.
[00:56:54.140 --> 00:56:56.740]   I would love to see more podcasts, believe it or not,
[00:56:56.740 --> 00:56:59.820]   not just my podcast, but there are more podcasts.
[00:56:59.820 --> 00:57:02.280]   If you have something to say to the world, please say it.
[00:57:02.280 --> 00:57:03.900]   Please put it out there on social media.
[00:57:03.900 --> 00:57:05.580]   I do think that there's value there.
[00:57:05.580 --> 00:57:07.780]   So I'm encouraging every person,
[00:57:07.780 --> 00:57:09.840]   not just usually they go the young people,
[00:57:09.840 --> 00:57:13.580]   but like the every people to, you know,
[00:57:13.580 --> 00:57:16.860]   get information out there and to support the efforts.
[00:57:16.860 --> 00:57:19.580]   And I also wanna say thank you so much for coming out
[00:57:19.580 --> 00:57:21.720]   on a Saturday night here in Melbourne,
[00:57:21.720 --> 00:57:27.220]   and for listening to the podcast, and for, yeah,
[00:57:27.220 --> 00:57:28.220]   it really means a lot to me.
[00:57:28.220 --> 00:57:30.460]   Thank you, thank you. (audience applauding)
[00:57:30.460 --> 00:57:34.160]   Thank you, thank you, thank you so much.
[00:57:34.160 --> 00:57:35.000]   Thank you.
[00:57:35.000 --> 00:57:38.580]   Thank you.
[00:57:38.580 --> 00:57:41.420]   Thank you.
[00:57:42.740 --> 00:57:45.380]   I really appreciate it that the podcast
[00:57:45.380 --> 00:57:47.340]   is indeed a labor of love.
[00:57:47.340 --> 00:57:48.980]   I feel oh so blessed to do it.
[00:57:48.980 --> 00:57:53.020]   And my hope is that the tools, protocols, and information
[00:57:53.020 --> 00:57:56.020]   will radiate out as far and wide as possible.
[00:57:56.020 --> 00:57:57.460]   I don't need or want credit.
[00:57:57.460 --> 00:57:59.500]   I just want people to have the information.
[00:57:59.500 --> 00:58:01.920]   I really mean that, and to share it
[00:58:01.920 --> 00:58:04.060]   where you think it can be useful to people.
[00:58:04.060 --> 00:58:07.580]   And last, but certainly not least,
[00:58:07.580 --> 00:58:09.580]   thank you for your interest in science.
[00:58:09.580 --> 00:58:11.660]   (audience applauding and cheering)
[00:58:11.660 --> 00:58:13.080]   Thank you so much, thank you so much.
[00:58:13.080 --> 00:58:13.920]   Thank you.
[00:58:13.920 --> 00:58:21.500]   (upbeat music)
[00:58:21.500 --> 00:58:24.080]   (upbeat music)
[00:58:24.080 --> 00:58:26.140]   you

