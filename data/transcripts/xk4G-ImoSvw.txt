
[00:00:00.000 --> 00:00:03.480]   [MUSIC PLAYING]
[00:00:03.480 --> 00:00:06.960]   [MUSIC PLAYING]
[00:00:06.960 --> 00:00:10.440]   [MUSIC PLAYING]
[00:00:10.440 --> 00:00:13.920]   [MUSIC PLAYING]
[00:00:13.920 --> 00:00:17.400]   [MUSIC PLAYING]
[00:00:17.400 --> 00:00:20.880]   [MUSIC PLAYING]
[00:00:45.840 --> 00:00:48.600]   Everybody give it up for the dictator himself,
[00:00:48.600 --> 00:00:50.640]   Chamal Palihapitiya.
[00:00:50.640 --> 00:00:53.360]   The rain man, yeah, definitely David Sachs.
[00:00:53.360 --> 00:00:57.640]   And your sultan of science, David Friedberg.
[00:00:57.640 --> 00:01:00.440]   I love how it's freezing and there's one heat lamp.
[00:01:00.440 --> 00:01:01.040]   One heat lamp.
[00:01:01.040 --> 00:01:03.160]   We're all just going to chat.
[00:01:03.160 --> 00:01:04.600]   Save $6.
[00:01:04.600 --> 00:01:07.240]   I mean, these are literally like $80 for the night.
[00:01:07.240 --> 00:01:09.560]   Yeah, they cost about $50 a night to rent,
[00:01:09.560 --> 00:01:11.680]   so I just thought $250 was enough.
[00:01:11.680 --> 00:01:13.080]   Yeah, it'd be fun.
[00:01:13.080 --> 00:01:16.800]   No, no, I mean, this is a super expensive place,
[00:01:16.800 --> 00:01:18.560]   especially since this is what happens.
[00:01:18.560 --> 00:01:19.240]   This is my life.
[00:01:19.240 --> 00:01:19.740]   Oh, my god.
[00:01:19.740 --> 00:01:23.520]   I come in and they're like, Jacob.
[00:01:23.520 --> 00:01:24.240]   I'm like, yeah.
[00:01:24.240 --> 00:01:25.680]   It's like, Chamal's been here since 430.
[00:01:25.680 --> 00:01:26.400]   I'm like, yeah, that's fine.
[00:01:26.400 --> 00:01:26.960]   That's great.
[00:01:26.960 --> 00:01:28.200]   You know, he got here early.
[00:01:28.200 --> 00:01:30.840]   And they're like, he's been ordering wine on your tab.
[00:01:30.840 --> 00:01:32.920]   I'm like, oh, no.
[00:01:32.920 --> 00:01:34.720]   So the event just flipped from being in the black
[00:01:34.720 --> 00:01:36.080]   to being in the red.
[00:01:36.080 --> 00:01:37.640]   A lot of people had questions for us,
[00:01:37.640 --> 00:01:39.720]   so we thought we would do like a little Q&A.
[00:01:39.720 --> 00:01:44.920]   But I thought I would start with maybe asking the besties,
[00:01:44.920 --> 00:01:48.280]   what has it been like, I think, having this podcast get
[00:01:48.280 --> 00:01:52.400]   so big, and the scrutiny it's under, but the excitement,
[00:01:52.400 --> 00:01:54.520]   and just how it's affected your life,
[00:01:54.520 --> 00:01:57.540]   and maybe how you operate in the world?
[00:01:57.540 --> 00:01:59.320]   I think I may have told the story on the pod,
[00:01:59.320 --> 00:02:02.800]   but I'll tell it again because I do like the story.
[00:02:02.800 --> 00:02:08.200]   So I think I was visiting Chamath in Milan.
[00:02:08.200 --> 00:02:12.160]   I think it was either last summer or two years ago.
[00:02:12.160 --> 00:02:15.680]   And we were literally just walking down the street
[00:02:15.680 --> 00:02:21.040]   in Milan, and somebody comes up to Chamath and stops him.
[00:02:21.040 --> 00:02:23.520]   And it's like it's a tourist from Australia
[00:02:23.520 --> 00:02:25.600]   who's a fan of the pod.
[00:02:25.600 --> 00:02:27.560]   And he wants to take selfies.
[00:02:27.560 --> 00:02:28.880]   I mean, he definitely--
[00:02:28.880 --> 00:02:31.040]   Chamath was definitely his favorite bestie.
[00:02:31.040 --> 00:02:33.480]   And it was like this excited conversation.
[00:02:33.480 --> 00:02:36.920]   And then that all happened, and then he moved on.
[00:02:36.920 --> 00:02:38.960]   And Chamath turned to me and said--
[00:02:38.960 --> 00:02:40.720]   oh, by the way, just some context here--
[00:02:40.720 --> 00:02:44.480]   is that these two were in like a big fight.
[00:02:44.480 --> 00:02:47.000]   And there was some question about whether the pod would--
[00:02:47.000 --> 00:02:49.320]   whether the pod would survive.
[00:02:49.320 --> 00:02:51.360]   And I think we were just talking about that
[00:02:51.360 --> 00:02:53.320]   as this guy came up to us.
[00:02:53.320 --> 00:02:56.840]   In any event, so he comes up, takes a selfie, and then
[00:02:56.840 --> 00:02:57.680]   leaves.
[00:02:57.680 --> 00:02:59.200]   And Chamath turns to me and said,
[00:02:59.200 --> 00:03:01.000]   these two idiots better figure things out
[00:03:01.000 --> 00:03:02.280]   because I like being famous.
[00:03:02.280 --> 00:03:05.280]   [LAUGHTER]
[00:03:05.280 --> 00:03:08.040]   I'd love to hear you guys talk more
[00:03:08.040 --> 00:03:12.100]   about the current state of Gen AI and particular software
[00:03:12.100 --> 00:03:12.600]   companies.
[00:03:12.600 --> 00:03:14.440]   I know, Chamath, you got 80/90 going.
[00:03:14.440 --> 00:03:19.680]   I'd love to hear about the lower cost of actually engineering
[00:03:19.680 --> 00:03:24.280]   software and building companies versus actually Gen AI doing--
[00:03:24.280 --> 00:03:26.160]   replacing human judgment, replacing judgment,
[00:03:26.160 --> 00:03:28.400]   self-driving the software itself.
[00:03:28.400 --> 00:03:31.120]   And those two dimensions feel like they're not
[00:03:31.120 --> 00:03:34.200]   exclusive to each other, but they are two different axes.
[00:03:34.200 --> 00:03:37.240]   I'd love to hear current thoughts on the return
[00:03:37.240 --> 00:03:39.000]   potential from an investment standpoint.
[00:03:39.000 --> 00:03:44.680]   I think that the entire software stack is going to get rebuilt.
[00:03:44.680 --> 00:03:47.120]   And I think it's going to be a bunch of 10- and 20-
[00:03:47.120 --> 00:03:50.040]   and 30-person companies that do it.
[00:03:50.040 --> 00:03:55.080]   And I think the core artifact of a new company today
[00:03:55.080 --> 00:03:56.680]   are two decisions.
[00:03:56.680 --> 00:03:59.200]   The first decision is that you must
[00:03:59.200 --> 00:04:02.280]   demand that the people that join you
[00:04:02.280 --> 00:04:05.120]   use every available tool at their disposal.
[00:04:05.120 --> 00:04:07.880]   And you measure them against the counterfactual,
[00:04:07.880 --> 00:04:10.840]   where that counterfactual is what your productivity was
[00:04:10.840 --> 00:04:12.560]   at a traditional company.
[00:04:12.560 --> 00:04:16.720]   And you need to be 100% to 200% more productive.
[00:04:16.720 --> 00:04:20.320]   So if an engineer is writing x amount of features
[00:04:20.320 --> 00:04:23.440]   or x amount of code, they need to be at a 2x or 3x.
[00:04:23.440 --> 00:04:26.020]   And if you do that in an existing company,
[00:04:26.020 --> 00:04:28.640]   all I've seen is organ rejection.
[00:04:28.640 --> 00:04:30.040]   So that's the first decision.
[00:04:30.040 --> 00:04:33.040]   So the people that join you, you must
[00:04:33.040 --> 00:04:35.600]   expect that they do that, which means that you also
[00:04:35.600 --> 00:04:39.600]   have to deprive them of any help along the way--
[00:04:39.600 --> 00:04:43.400]   no administrative help, no HR help, no finance help.
[00:04:43.400 --> 00:04:47.800]   All of that stuff needs to be a workflow or a bot
[00:04:47.800 --> 00:04:49.160]   or some form of AI logic.
[00:04:49.160 --> 00:04:53.080]   So that's one critical decision.
[00:04:53.080 --> 00:04:57.040]   And I think the second is that the document that
[00:04:57.040 --> 00:05:00.960]   matters more than ever is that PRD that defines
[00:05:00.960 --> 00:05:03.280]   the v0 MVP of the product.
[00:05:03.280 --> 00:05:06.460]   Because I don't think you should be writing much code.
[00:05:06.460 --> 00:05:08.120]   I think what you really need to be doing
[00:05:08.120 --> 00:05:11.720]   is defining in excruciating detail what the feature
[00:05:11.720 --> 00:05:13.320]   set is, what the parameters are, what
[00:05:13.320 --> 00:05:16.680]   the guardrails of how features should behave in certain
[00:05:16.680 --> 00:05:19.680]   boundary conditions, fed into an LLM that then spits out
[00:05:19.680 --> 00:05:21.600]   the code that then compiles, and then you
[00:05:21.600 --> 00:05:23.560]   have a working product.
[00:05:23.560 --> 00:05:26.520]   And that is a 10%, 20%, 30% effort
[00:05:26.520 --> 00:05:28.720]   that can probably topple giants.
[00:05:28.720 --> 00:05:31.720]   It'll take a couple of years for us to get to that place.
[00:05:31.720 --> 00:05:35.240]   But in that world, there is no room for $500 million
[00:05:35.240 --> 00:05:36.520]   into a SaaS company.
[00:05:36.520 --> 00:05:38.320]   It doesn't make any sense.
[00:05:38.320 --> 00:05:40.260]   And the reason is the 10- and 20-person company
[00:05:40.260 --> 00:05:43.400]   can price that thing at just a fraction of what
[00:05:43.400 --> 00:05:44.640]   the incumbent charges.
[00:05:44.640 --> 00:05:47.280]   Because the incumbent has an OPEX load that's
[00:05:47.280 --> 00:05:49.780]   not correlated to features.
[00:05:49.780 --> 00:05:53.000]   It's correlated to the fact that you have 50,000 people
[00:05:53.000 --> 00:05:56.000]   across 50 offices all over the world
[00:05:56.000 --> 00:05:59.680]   with all this ridiculous infrastructure that all
[00:05:59.680 --> 00:06:01.480]   of a sudden becomes obsolete.
[00:06:01.480 --> 00:06:03.200]   So I think there's two models.
[00:06:03.200 --> 00:06:05.160]   One is more of the lightweight approach.
[00:06:05.160 --> 00:06:08.460]   So like, Sachs and JCal both seed a lot of stuff,
[00:06:08.460 --> 00:06:11.040]   get it off the ground, spin it up, and then raise money.
[00:06:11.040 --> 00:06:12.580]   He just did with Glue, which is like,
[00:06:12.580 --> 00:06:14.600]   I'm going to build something, get it to a place
[00:06:14.600 --> 00:06:17.040]   where the rest of us can kind of pile on.
[00:06:17.040 --> 00:06:19.480]   But the other version is much more distributed.
[00:06:19.480 --> 00:06:22.360]   And I'll say a dirty word here, but I
[00:06:22.360 --> 00:06:25.560]   think it matters, it's like this web 3 model does actually
[00:06:25.560 --> 00:06:30.040]   apply here, where there are some really interesting early
[00:06:30.040 --> 00:06:34.140]   adventures in crowdsourcing technical completion.
[00:06:34.140 --> 00:06:35.880]   I would encourage you to look at a project
[00:06:35.880 --> 00:06:39.960]   that I'm starting to focus a little bit on called BitTensor.
[00:06:39.960 --> 00:06:41.560]   And I was like, what is this thing?
[00:06:41.560 --> 00:06:44.960]   And it's basically a thing where you go and solve
[00:06:44.960 --> 00:06:48.040]   technical problems and produce features that people require--
[00:06:48.040 --> 00:06:51.780]   that need, and you get paid in this underlying currency.
[00:06:51.780 --> 00:06:54.040]   That is actually a distributed form of venture
[00:06:54.040 --> 00:06:55.720]   that actually makes sense in a world--
[00:06:55.720 --> 00:06:56.600]   Like a bounty?
[00:06:56.600 --> 00:06:58.680]   Essentially, where like, you know,
[00:06:58.680 --> 00:07:01.360]   15 companies that need a replacement to Salesforce just
[00:07:01.360 --> 00:07:04.480]   say, here's the bounty, and here's the feature set,
[00:07:04.480 --> 00:07:09.120]   and it's a crowdsourced or a community-sourced PRD,
[00:07:09.120 --> 00:07:10.640]   and then some LLM spits out the code.
[00:07:10.640 --> 00:07:13.800]   Like, that is this crazy new world that we're going through.
[00:07:13.800 --> 00:07:15.960]   So it's all about speed of execution, I think.
[00:07:15.960 --> 00:07:17.580]   Sachs, do you have any thoughts on it
[00:07:17.580 --> 00:07:20.120]   and what you're seeing in the field right now?
[00:07:20.120 --> 00:07:23.280]   Yeah, I mean, I think in having conversations
[00:07:23.280 --> 00:07:27.840]   with enterprises and businesses, what they basically want
[00:07:27.840 --> 00:07:29.480]   is to be able to throw all of their data
[00:07:29.480 --> 00:07:33.800]   somehow into a LLM and be able to ask it questions.
[00:07:33.800 --> 00:07:36.680]   So they've seen ChatGPT, and they basically
[00:07:36.680 --> 00:07:40.040]   want to be able to do that, but with their own enterprise data.
[00:07:40.040 --> 00:07:41.960]   And it sounds easy, but it's actually
[00:07:41.960 --> 00:07:43.520]   like pretty hard to make that happen.
[00:07:43.520 --> 00:07:47.200]   One problem is that the LLMs don't
[00:07:47.200 --> 00:07:49.480]   have that big what's called a context window, which
[00:07:49.480 --> 00:07:52.200]   is kind of like, it's almost like active memory
[00:07:52.200 --> 00:07:53.640]   or something like that.
[00:07:53.640 --> 00:07:55.960]   And we're in the early days of-- it's
[00:07:55.960 --> 00:07:58.760]   like in the early days of computers where you had
[00:07:58.760 --> 00:08:00.440]   to worry about your RAM.
[00:08:00.440 --> 00:08:04.080]   It was like 8 megabytes, 16, then 32, then 64.
[00:08:04.080 --> 00:08:05.200]   Remember that?
[00:08:05.200 --> 00:08:08.480]   We had floppies and the 3 and 1/2 inch disks or whatever.
[00:08:08.480 --> 00:08:10.680]   And eventually, just people stopped talking about RAM
[00:08:10.680 --> 00:08:12.640]   because it went away as a constraint.
[00:08:12.640 --> 00:08:14.320]   But we're still in the days of, you
[00:08:14.320 --> 00:08:17.520]   have to be selective about what you feed into the model
[00:08:17.520 --> 00:08:21.120]   because it just can only absorb so much information.
[00:08:21.120 --> 00:08:23.040]   So if you give it all of your enterprise data,
[00:08:23.040 --> 00:08:24.520]   how does it even know where to look?
[00:08:24.520 --> 00:08:26.680]   And so you've got to figure out how to optimize it so
[00:08:26.680 --> 00:08:31.880]   that you can give the AI model the right chunks of data
[00:08:31.880 --> 00:08:33.600]   to give you the right answers.
[00:08:33.600 --> 00:08:38.120]   And that's actually-- it's a complicated problem right now.
[00:08:38.120 --> 00:08:40.640]   And we're dealing with it at Glue.
[00:08:40.640 --> 00:08:42.600]   We just invested in a company, a startup
[00:08:42.600 --> 00:08:45.240]   called Raggy, which is basically RAG as a service.
[00:08:45.240 --> 00:08:48.120]   It does retrieval augmented generation as a service.
[00:08:48.120 --> 00:08:49.880]   It basically helps solve this problem.
[00:08:49.880 --> 00:08:51.920]   So I think that's the stage that we're at,
[00:08:51.920 --> 00:08:54.720]   is everyone knows where they want to get to.
[00:08:54.720 --> 00:08:58.920]   And we're just dealing with some of the limitations
[00:08:58.920 --> 00:09:01.680]   so that the model can work effectively.
[00:09:01.680 --> 00:09:04.440]   And what you see right now are glimpses
[00:09:04.440 --> 00:09:07.240]   of genius or greatness.
[00:09:07.240 --> 00:09:10.320]   If you feed the exact right chunks into the model,
[00:09:10.320 --> 00:09:13.120]   you'll get answers that can blow you away.
[00:09:13.120 --> 00:09:14.560]   But then sometimes you'll just get
[00:09:14.560 --> 00:09:17.160]   an answer that just kind of isn't that good.
[00:09:17.160 --> 00:09:19.600]   And again, the reason is because the model didn't really
[00:09:19.600 --> 00:09:21.000]   know where to look for the answer.
[00:09:21.000 --> 00:09:24.920]   So right now, it's like, again, glimpses of something amazing.
[00:09:24.920 --> 00:09:27.680]   And we just have to kind of get to more predictability
[00:09:27.680 --> 00:09:28.360]   around that.
[00:09:28.360 --> 00:09:30.120]   And there's a lot of effort that's
[00:09:30.120 --> 00:09:32.960]   going into solving some of these sorts of issues.
[00:09:32.960 --> 00:09:34.120]   It's not just LLMs.
[00:09:34.120 --> 00:09:36.680]   It's also-- although it is at the LLM level,
[00:09:36.680 --> 00:09:41.040]   it's also the infrastructure around it.
[00:09:41.040 --> 00:09:42.840]   And to put the two thoughts together,
[00:09:42.840 --> 00:09:45.240]   I think the people who embrace this
[00:09:45.240 --> 00:09:46.920]   are becoming bionic at work.
[00:09:46.920 --> 00:09:50.560]   I mean, we had many challenges in podcast production
[00:09:50.560 --> 00:09:53.720]   around things like transcripts or doing show notes
[00:09:53.720 --> 00:09:58.160]   and learning, hey, about this person who's a guest.
[00:09:58.160 --> 00:09:59.520]   They were on these three podcasts.
[00:09:59.520 --> 00:10:02.000]   Now, we have producers at our company
[00:10:02.000 --> 00:10:05.280]   who will take those three podcast interviews,
[00:10:05.280 --> 00:10:09.640]   download the MP3, put them into a chat GPT,
[00:10:09.640 --> 00:10:11.440]   and say, what are the key points in here?
[00:10:11.440 --> 00:10:12.560]   What are the key timestamps?
[00:10:12.560 --> 00:10:14.240]   And even, what questions would you ask?
[00:10:14.240 --> 00:10:16.640]   Or what are relevant topics this person is talking about?
[00:10:16.640 --> 00:10:18.160]   And these data sets are disparate,
[00:10:18.160 --> 00:10:19.240]   and they're not connected.
[00:10:19.240 --> 00:10:21.840]   So you can't say, well, what's David Sacks talking about,
[00:10:21.840 --> 00:10:24.160]   if you're going to have him on your podcast, on Twitter?
[00:10:24.160 --> 00:10:26.860]   Because there's no way to get that information.
[00:10:26.860 --> 00:10:28.400]   I could tell you what the topics are.
[00:10:28.400 --> 00:10:29.760]   It's pretty-- anyway.
[00:10:29.760 --> 00:10:32.080]   And those individuals are becoming
[00:10:32.080 --> 00:10:34.320]   so valuable in organizations.
[00:10:34.320 --> 00:10:37.000]   And it's allowing people to do so much work so fast
[00:10:37.000 --> 00:10:39.840]   and then unlocking things that were just not possible.
[00:10:39.840 --> 00:10:45.660]   And that, to me, is very obvious inside the startups
[00:10:45.660 --> 00:10:48.240]   we invest in, because when they're resource constrained,
[00:10:48.240 --> 00:10:50.960]   they look for the fastest, cheapest way to do things.
[00:10:50.960 --> 00:10:52.640]   And if you watch those startups, they're
[00:10:52.640 --> 00:10:55.800]   the same ones who, when other people were racking servers,
[00:10:55.800 --> 00:10:57.240]   they were using AWS.
[00:10:57.240 --> 00:10:59.080]   They were using cloud computing.
[00:10:59.080 --> 00:11:00.540]   And they figured it out first.
[00:11:00.540 --> 00:11:03.100]   And then they built businesses that you may have heard of,
[00:11:03.100 --> 00:11:05.080]   like Dropbox, YouTube.
[00:11:05.080 --> 00:11:07.200]   That whole wave was a group of people
[00:11:07.200 --> 00:11:10.700]   who just fundamentally said, the paradigm of cloud computing
[00:11:10.700 --> 00:11:13.040]   is going to work, even though it's not perfect right now,
[00:11:13.040 --> 00:11:15.200]   even though it's slow, or expensive, or it breaks,
[00:11:15.200 --> 00:11:15.760]   whatever.
[00:11:15.760 --> 00:11:17.220]   I'm just going to go all in on that.
[00:11:17.220 --> 00:11:18.760]   And Dropbox made this critical error.
[00:11:18.760 --> 00:11:20.460]   I don't know if you remember that, Sacks,
[00:11:20.460 --> 00:11:23.260]   where they stood up their own data centers instead of--
[00:11:23.260 --> 00:11:25.920]   they were just scared to have their data at, I guess,
[00:11:25.920 --> 00:11:27.160]   AWS or whatever it was.
[00:11:27.160 --> 00:11:29.880]   And so it's going to be unbelievable
[00:11:29.880 --> 00:11:32.480]   how many businesses become viable with just three, four,
[00:11:32.480 --> 00:11:33.360]   or five employees.
[00:11:33.360 --> 00:11:35.800]   And that's what I'm seeing on the field.
[00:11:35.800 --> 00:11:39.760]   Freeberg, you have any thoughts on AI right now?
[00:11:39.760 --> 00:11:42.840]   I think that there's a chance that SaaS
[00:11:42.840 --> 00:11:46.240]   gets kind of obviated.
[00:11:46.240 --> 00:11:47.560]   I've shared this in the past.
[00:11:47.560 --> 00:11:49.400]   I think that there's a chance that SaaS looks
[00:11:49.400 --> 00:11:52.400]   like this kind of temporary phenomenon that
[00:11:52.400 --> 00:11:54.320]   occurred between the ubiquity of the internet
[00:11:54.320 --> 00:11:58.760]   and the prevalence of AI for writing software.
[00:11:58.760 --> 00:12:02.600]   If you've worked with any enterprise,
[00:12:02.600 --> 00:12:04.320]   from a traditional industry, meaning
[00:12:04.320 --> 00:12:05.940]   they didn't grow up in software, and they're not software
[00:12:05.940 --> 00:12:07.680]   native, they have IT departments.
[00:12:07.680 --> 00:12:09.140]   And those IT departments are really
[00:12:09.140 --> 00:12:10.640]   good at procurement of software.
[00:12:10.640 --> 00:12:12.560]   And that's really been their primary function.
[00:12:12.560 --> 00:12:14.400]   But they all try to hire software engineers,
[00:12:14.400 --> 00:12:16.320]   and they generally suck.
[00:12:16.320 --> 00:12:18.520]   But they understand the needs of the business.
[00:12:18.520 --> 00:12:22.720]   And I think that if they can have software written for them
[00:12:22.720 --> 00:12:26.200]   at basically a cost of zero to improve their workplace
[00:12:26.200 --> 00:12:28.200]   productivity, which was the original thing that
[00:12:28.200 --> 00:12:31.680]   was enabled by software in the first place,
[00:12:31.680 --> 00:12:36.040]   it starts to really change how folks are sourcing and using
[00:12:36.040 --> 00:12:38.760]   software, that it can actually be written for them
[00:12:38.760 --> 00:12:41.600]   in real time by software.
[00:12:41.600 --> 00:12:44.400]   And so I think that the tooling and the capabilities
[00:12:44.400 --> 00:12:46.560]   to enable the enterprise to write their own custom
[00:12:46.560 --> 00:12:49.020]   workplace productivity tools and their own custom workplace
[00:12:49.020 --> 00:12:50.840]   software, whether that's customer-facing
[00:12:50.840 --> 00:12:55.040]   or internal-facing, really becomes kind of the standard
[00:12:55.040 --> 00:12:56.040]   maybe going forward.
[00:12:56.040 --> 00:12:59.240]   And you see this, what I think Doug Leone called
[00:12:59.240 --> 00:13:01.760]   the greatest business model in human history,
[00:13:01.760 --> 00:13:05.440]   which is SaaS, getting kind of blown up in that new landscape.
[00:13:05.440 --> 00:13:08.560]   So I think there's a chance that that happens, non-zero chance.
[00:13:08.560 --> 00:13:12.240]   And I've just seen this in a bunch of settings
[00:13:12.240 --> 00:13:14.720]   where folks are having software written for them
[00:13:14.720 --> 00:13:15.760]   by the software.
[00:13:15.760 --> 00:13:18.200]   And they kind of just really state clearly,
[00:13:18.200 --> 00:13:20.320]   here's the layout, here's what I want it to do.
[00:13:20.320 --> 00:13:23.300]   And with a couple of rounds of iteration,
[00:13:23.300 --> 00:13:24.880]   they can get it working pretty well.
[00:13:24.880 --> 00:13:26.920]   And they don't need to go pay some third-party per-seat
[00:13:26.920 --> 00:13:28.440]   license fee per year to use it.
[00:13:28.440 --> 00:13:32.480]   I have heard about your poker love through the podcast.
[00:13:32.480 --> 00:13:33.940]   I've been listening for a few years.
[00:13:33.940 --> 00:13:35.520]   And it was really fun to experience it
[00:13:35.520 --> 00:13:36.880]   with you last night.
[00:13:36.880 --> 00:13:38.680]   Could you comment a little bit on how
[00:13:38.680 --> 00:13:40.960]   you think about your utility function personally?
[00:13:40.960 --> 00:13:44.000]   Is it networking, strategy training?
[00:13:44.000 --> 00:13:44.940]   Is it fun?
[00:13:44.940 --> 00:13:46.640]   Could you comment a little bit on how you all think about it?
[00:13:46.640 --> 00:13:47.720]   Why we play poker.
[00:13:47.720 --> 00:13:49.560]   There is networking that has occurred at it.
[00:13:49.560 --> 00:13:53.360]   But I think-- also, you made a good comment about it.
[00:13:53.360 --> 00:13:55.840]   Or maybe Bobby Baldwin said it.
[00:13:55.840 --> 00:13:58.760]   He never saw-- or it was--
[00:13:58.760 --> 00:14:02.520]   a poker player get old and lose their mental facilities,
[00:14:02.520 --> 00:14:03.020]   right?
[00:14:03.020 --> 00:14:03.600]   Like, they--
[00:14:03.600 --> 00:14:07.800]   No, Bobby Baldwin ran the city center in Aria for a long time.
[00:14:07.800 --> 00:14:09.240]   He plays in our game.
[00:14:09.240 --> 00:14:10.280]   And he made this comment.
[00:14:10.280 --> 00:14:12.680]   He's like, have you ever seen a poker player
[00:14:12.680 --> 00:14:14.480]   get Alzheimer's or dementia?
[00:14:14.480 --> 00:14:15.280]   Right, that was it.
[00:14:15.280 --> 00:14:17.080]   And he was saying that about Doyle Brunson,
[00:14:17.080 --> 00:14:19.800]   because Doyle, when he died, was super sharp, sharp as a tack.
[00:14:19.800 --> 00:14:21.940]   His body failed before his mind failed.
[00:14:21.940 --> 00:14:22.560]   And it's true.
[00:14:22.560 --> 00:14:24.720]   It's one of these unique games where you can really
[00:14:24.720 --> 00:14:26.320]   stay mentally sharp as you get old.
[00:14:26.320 --> 00:14:28.000]   Yeah, absolutely.
[00:14:28.000 --> 00:14:29.880]   Sax, you still love it?
[00:14:29.880 --> 00:14:31.760]   Yeah?
[00:14:31.760 --> 00:14:32.880]   Definitely?
[00:14:32.880 --> 00:14:33.360]   Yeah.
[00:14:33.360 --> 00:14:35.920]   Look, I like it for the same reason that you guys like it.
[00:14:35.920 --> 00:14:39.160]   There was a phase early on where I would play in the World
[00:14:39.160 --> 00:14:40.080]   Series of Poker.
[00:14:40.080 --> 00:14:40.980]   I would go to that.
[00:14:40.980 --> 00:14:43.040]   And then I was just like, you know,
[00:14:43.040 --> 00:14:45.560]   I actually don't like sitting there for three days
[00:14:45.560 --> 00:14:47.120]   playing with strangers.
[00:14:47.120 --> 00:14:50.000]   It's actually not that fun to do that.
[00:14:50.000 --> 00:14:53.440]   And the thing that's fun is just playing with your friends.
[00:14:53.440 --> 00:14:55.640]   So now I just play in friend games.
[00:14:55.640 --> 00:14:58.000]   I first started playing poker when I-- did I ever tell you
[00:14:58.000 --> 00:14:58.480]   this?
[00:14:58.480 --> 00:15:00.560]   I worked at a pool hall in upstate New York.
[00:15:00.560 --> 00:15:02.520]   I was 16 years old.
[00:15:02.520 --> 00:15:05.240]   I got paid $4.25 an hour to work at this pool hall.
[00:15:05.240 --> 00:15:08.320]   I cleaned toilets and scrubbed down the tables.
[00:15:08.320 --> 00:15:10.240]   And the guy sat at the payphone all day
[00:15:10.240 --> 00:15:12.280]   was the bookie for upstate New York.
[00:15:12.280 --> 00:15:14.640]   And he would take all of the bets on the payphone
[00:15:14.640 --> 00:15:15.640]   and write them down.
[00:15:15.640 --> 00:15:17.880]   And one day, after he got to know me for a couple of months,
[00:15:17.880 --> 00:15:19.720]   he's like, come and play poker with us at our home game.
[00:15:19.720 --> 00:15:21.040]   And they played Limit Hold 'Em.
[00:15:21.040 --> 00:15:24.480]   $1.00, $1.00, $1.00, $1.00, $1.00, $1.00, $1.00, $1.00, $1.00.
[00:15:24.480 --> 00:15:26.880]   And these fuckers took all my money.
[00:15:26.880 --> 00:15:29.800]   And I was 16, going to college, like fucking cold.
[00:15:29.800 --> 00:15:31.080]   I had to walk through the snow.
[00:15:31.080 --> 00:15:32.600]   I couldn't afford boots or a jacket.
[00:15:32.600 --> 00:15:35.160]   It was like really shitty.
[00:15:35.160 --> 00:15:36.640]   And they took all my money.
[00:15:36.640 --> 00:15:37.560]   And I had to call my mom.
[00:15:37.560 --> 00:15:38.240]   And I lied to her.
[00:15:38.240 --> 00:15:39.780]   And I'm like, mom, I lost my jacket.
[00:15:39.780 --> 00:15:42.480]   Can you like loan me $150 Western Union
[00:15:42.480 --> 00:15:43.840]   so I can buy a fucking jacket?
[00:15:43.840 --> 00:15:46.480]   So that summer, I bought all the books
[00:15:46.480 --> 00:15:48.040]   from the back of the poker magazines
[00:15:48.040 --> 00:15:49.600]   to learn how to play poker strategy.
[00:15:49.600 --> 00:15:51.960]   And it was all Limit Hold 'Em at that time.
[00:15:51.960 --> 00:15:55.520]   And then my freshman year of college at Cal,
[00:15:55.520 --> 00:15:58.160]   I made $10,000 that summer playing Limit Hold 'Em
[00:15:58.160 --> 00:16:01.680]   at the Oaks Card Club, playing tournaments in 6-12.
[00:16:01.680 --> 00:16:03.600]   And after that, I was-- and I learned so much
[00:16:03.600 --> 00:16:06.480]   about investing and life and like perseverance
[00:16:06.480 --> 00:16:07.480]   through ups and downs.
[00:16:07.480 --> 00:16:09.200]   Because you sit there, you grind it out.
[00:16:09.200 --> 00:16:11.840]   As long as you have a positive EV decision,
[00:16:11.840 --> 00:16:14.040]   you know you made the right decision over time,
[00:16:14.040 --> 00:16:15.320]   the money will come to you.
[00:16:15.320 --> 00:16:18.040]   You don't need to like win every fucking hand.
[00:16:18.040 --> 00:16:19.880]   And to learn that at that age, I think,
[00:16:19.880 --> 00:16:22.440]   was really influential to me in entrepreneurship
[00:16:22.440 --> 00:16:25.480]   and investing and in decision making later on in life.
[00:16:25.480 --> 00:16:27.120]   It was very important to me.
[00:16:27.120 --> 00:16:29.200]   And so when I sold my company in 2013,
[00:16:29.200 --> 00:16:31.160]   I was introduced to Chamath and invited
[00:16:31.160 --> 00:16:32.840]   to come and play in the home game.
[00:16:32.840 --> 00:16:34.920]   And for me, it was like a very kind of nostalgia.
[00:16:34.920 --> 00:16:38.660]   Because I hadn't played really much since 2001, 2002.
[00:16:38.660 --> 00:16:41.880]   What's the most impactful advice you've been given?
[00:16:41.880 --> 00:16:43.480]   And how has it shaped your careers?
[00:16:43.480 --> 00:16:47.800]   Early on, I got two good pieces of advice.
[00:16:47.800 --> 00:16:50.200]   One was from Mike Savino, who's here somewhere,
[00:16:50.200 --> 00:16:50.880]   speaking tomorrow.
[00:16:50.880 --> 00:16:51.920]   There it is.
[00:16:51.920 --> 00:16:54.520]   And he said, the piece of advice his dad gave him
[00:16:54.520 --> 00:16:57.080]   was look to the left and come in an hour before that guy.
[00:16:57.080 --> 00:17:00.800]   And then look to the right and come in and stay an hour later
[00:17:00.800 --> 00:17:02.840]   than that guy, just basically the hard work stuff.
[00:17:02.840 --> 00:17:04.400]   And I had gotten that from my mom, as well,
[00:17:04.400 --> 00:17:06.640]   who worked three or four jobs to put us through school.
[00:17:06.640 --> 00:17:08.760]   And my dad, who worked really hard.
[00:17:08.760 --> 00:17:11.320]   And so the hard work ethic, I think,
[00:17:11.320 --> 00:17:13.600]   was the key to a lot of my success.
[00:17:13.600 --> 00:17:16.760]   Because I just decided, I'm just going to outwork everybody.
[00:17:16.760 --> 00:17:19.360]   Because I was coming not from Harvard or Stanford,
[00:17:19.360 --> 00:17:22.720]   but from Bayridge, Brooklyn, and going to night school
[00:17:22.720 --> 00:17:23.200]   at Fordham.
[00:17:23.200 --> 00:17:24.640]   So I had to use hustle.
[00:17:24.640 --> 00:17:25.720]   There was no connections.
[00:17:25.720 --> 00:17:26.600]   There was no network.
[00:17:26.600 --> 00:17:29.480]   I just had to literally kill what I ate.
[00:17:29.480 --> 00:17:31.120]   And then after I sold my first company,
[00:17:31.120 --> 00:17:34.160]   I was at TED at the Billionaire's Dinner
[00:17:34.160 --> 00:17:36.600]   with my book agent, John Brockman.
[00:17:36.600 --> 00:17:38.760]   And I still had a chip on my shoulder,
[00:17:38.760 --> 00:17:40.560]   but I had sold my company.
[00:17:40.560 --> 00:17:45.400]   And he said, hey, Schmuck, you made it.
[00:17:45.400 --> 00:17:47.920]   You stopped fighting with everybody.
[00:17:47.920 --> 00:17:52.320]   And I was like, OK, I'll stop fighting with everybody.
[00:17:52.320 --> 00:17:53.600]   So you took that advice?
[00:17:53.600 --> 00:17:54.520]   I took it sometimes.
[00:17:54.520 --> 00:17:55.680]   I flip a coin.
[00:17:55.680 --> 00:17:57.640]   When did you do that?
[00:17:57.640 --> 00:17:58.880]   You need to look at that memo.
[00:17:58.880 --> 00:17:59.720]   When did you get that advice?
[00:17:59.720 --> 00:18:00.720]   Last night, or--
[00:18:00.720 --> 00:18:01.600]   Yeah, I just got it.
[00:18:01.600 --> 00:18:03.560]   You're just texting me right now.
[00:18:03.560 --> 00:18:07.000]   But it was actually because I had to fight for everything,
[00:18:07.000 --> 00:18:12.240]   I think I just kept fighting to try to get the next level.
[00:18:12.240 --> 00:18:14.240]   And at a certain point, I decided
[00:18:14.240 --> 00:18:16.000]   I would be like super magnanimous
[00:18:16.000 --> 00:18:19.440]   and just be helpful and elder statesman-like.
[00:18:19.440 --> 00:18:21.440]   And I'm not perfect, but--
[00:18:21.440 --> 00:18:22.680]   What?
[00:18:22.680 --> 00:18:24.280]   Well, I mean, when you don't see me working,
[00:18:24.280 --> 00:18:26.520]   you don't see me working with startups.
[00:18:26.520 --> 00:18:30.080]   I am tireless in my ability with patience for them.
[00:18:30.080 --> 00:18:30.680]   And supportive.
[00:18:30.680 --> 00:18:31.240]   And supportive.
[00:18:31.240 --> 00:18:33.320]   And I just-- and I try to do that with my friends as well.
[00:18:33.320 --> 00:18:34.920]   It's just, what's the point of being successful
[00:18:34.920 --> 00:18:37.320]   if you can't support the people around you who you love
[00:18:37.320 --> 00:18:38.400]   and try to pay it forward?
[00:18:38.400 --> 00:18:39.240]   So those are just--
[00:18:39.240 --> 00:18:42.760]   You are like the most reliable wingman of all of us.
[00:18:42.760 --> 00:18:43.760]   Oh, thank you.
[00:18:43.760 --> 00:18:46.640]   You know, value your friends and your family
[00:18:46.640 --> 00:18:49.160]   is just such critically important advice.
[00:18:49.160 --> 00:18:52.600]   Because at the end of the day, all you have is your memories.
[00:18:52.600 --> 00:18:54.720]   And you make them with your friends and your family.
[00:18:54.720 --> 00:18:57.720]   And so I am on a mission to make great memories
[00:18:57.720 --> 00:19:01.040]   with my friends and family, as many as possible.
[00:19:01.040 --> 00:19:03.560]   And actually, this is part of it, you all being here.
[00:19:03.560 --> 00:19:06.240]   And that's why I always tell you, make a couple of friends.
[00:19:06.240 --> 00:19:08.560]   It's hard to make friends, especially as you get older.
[00:19:08.560 --> 00:19:10.400]   And people kind of tighten up their circles.
[00:19:10.400 --> 00:19:15.320]   Make a couple of new friends and go do things together.
[00:19:15.320 --> 00:19:17.360]   Anyway, some philosophy, I don't know.
[00:19:17.360 --> 00:19:20.120]   Advice that you got?
[00:19:20.120 --> 00:19:23.360]   The best career advice I got was from Peter Thiel,
[00:19:23.360 --> 00:19:26.200]   who advised me not to go to law school.
[00:19:26.200 --> 00:19:27.920]   And unfortunately, I didn't listen to him.
[00:19:27.920 --> 00:19:29.600]   I went anyway.
[00:19:29.600 --> 00:19:31.920]   But it ended up not mattering, because I ended up joining
[00:19:31.920 --> 00:19:34.520]   PayPal after I graduated from law school.
[00:19:34.520 --> 00:19:36.040]   So I wish I had a better story.
[00:19:36.040 --> 00:19:38.760]   The best career advice I've actually heard for Silicon
[00:19:38.760 --> 00:19:42.960]   Valley was the advice that Eric Schmidt gave Sheryl Sandberg
[00:19:42.960 --> 00:19:45.200]   when she joined Google, which is,
[00:19:45.200 --> 00:19:49.360]   when you get invited to take a seat on a rocket ship,
[00:19:49.360 --> 00:19:50.360]   don't ask which seat.
[00:19:50.360 --> 00:19:52.240]   Yeah, just get on board.
[00:19:52.240 --> 00:19:55.760]   I actually think that is perennially great advice
[00:19:55.760 --> 00:19:57.320]   for anyone in Silicon Valley.
[00:19:57.320 --> 00:19:59.200]   There aren't that many of these rocket ships.
[00:19:59.200 --> 00:20:00.960]   So when you get a chance to be on one,
[00:20:00.960 --> 00:20:03.480]   you should just take it and worry about the titles
[00:20:03.480 --> 00:20:05.200]   and all that kind of stuff later.
[00:20:05.200 --> 00:20:06.240]   Yeah, the details later.
[00:20:07.200 --> 00:20:08.840]   The biggest piece of advice that I still
[00:20:08.840 --> 00:20:12.600]   struggle to take every day--
[00:20:12.600 --> 00:20:15.520]   every time I have, though, it's had profound impact on my life--
[00:20:15.520 --> 00:20:16.120]   is to focus.
[00:20:16.120 --> 00:20:21.760]   I think the bigger a portfolio you develop,
[00:20:21.760 --> 00:20:22.880]   the less alpha there is.
[00:20:22.880 --> 00:20:25.280]   You try and minimize beta, but you take all the alpha away
[00:20:25.280 --> 00:20:26.080]   if you do that.
[00:20:26.080 --> 00:20:29.080]   In 2009, I focused my company on the agriculture market,
[00:20:29.080 --> 00:20:29.800]   which was crazy.
[00:20:29.800 --> 00:20:32.680]   We were in seven verticals and doing all sorts of stuff.
[00:20:32.680 --> 00:20:34.440]   When I focused on it, again, I went deep.
[00:20:34.440 --> 00:20:37.600]   I went on a long hike in Iceland and I came up
[00:20:37.600 --> 00:20:39.840]   with this crazy idea for the product for the app market
[00:20:39.840 --> 00:20:41.720]   and came back.
[00:20:41.720 --> 00:20:44.480]   We launched it and we did like $30 million in sales that year.
[00:20:44.480 --> 00:20:46.240]   And that made a huge impact in my life
[00:20:46.240 --> 00:20:48.040]   and the trajectory of the business changed.
[00:20:48.040 --> 00:20:51.200]   And every time I focused and avoided distractions,
[00:20:51.200 --> 00:20:52.240]   it's made a huge impact.
[00:20:52.240 --> 00:20:54.960]   I think my decision to become a CEO again back in November
[00:20:54.960 --> 00:20:56.600]   was a really important one for me.
[00:20:56.600 --> 00:20:58.600]   And I realized I was on lots of boards and doing
[00:20:58.600 --> 00:21:00.760]   lots of investing and thinking about lots of things,
[00:21:00.760 --> 00:21:02.280]   but now I can really dig deep.
[00:21:02.280 --> 00:21:04.000]   And I think that everyone assumes
[00:21:04.000 --> 00:21:06.600]   that there's this power law in the world
[00:21:06.600 --> 00:21:10.360]   that you are a passive participant in.
[00:21:10.360 --> 00:21:12.760]   You're either going to catch one of the power law winners
[00:21:12.760 --> 00:21:14.040]   or you're going to lose it.
[00:21:14.040 --> 00:21:16.720]   Therefore, you've got to portfolio your way to a power
[00:21:16.720 --> 00:21:18.400]   law to catch a power law.
[00:21:18.400 --> 00:21:21.280]   I don't give a shit about that because I think my job in life
[00:21:21.280 --> 00:21:24.280]   is to make the power law and to make that outcome.
[00:21:24.280 --> 00:21:26.400]   And I feel like that has made a huge impact
[00:21:26.400 --> 00:21:27.520]   on how I think about life.
[00:21:27.520 --> 00:21:30.560]   And it's really-- every time I've tried to act on it,
[00:21:30.560 --> 00:21:33.000]   it's actually paid back significantly.
[00:21:33.000 --> 00:21:34.960]   So focus is the biggest piece of advice
[00:21:34.960 --> 00:21:36.440]   I've gotten that I think matters.
[00:21:36.440 --> 00:21:39.400]   So the version of that that I tell founders all the time
[00:21:39.400 --> 00:21:42.440]   is always be all in on your best idea.
[00:21:42.440 --> 00:21:44.520]   Because founders, sometimes they have a whole bunch
[00:21:44.520 --> 00:21:45.200]   of different ideas.
[00:21:45.200 --> 00:21:46.600]   Sometimes they're doing multiple startups.
[00:21:46.600 --> 00:21:48.360]   Sometimes they're thinking about pivoting,
[00:21:48.360 --> 00:21:51.120]   but they're still hanging on to the old idea.
[00:21:51.120 --> 00:21:53.800]   And I always give them permission to pivot.
[00:21:53.800 --> 00:21:55.600]   I'm like, don't worry about what you
[00:21:55.600 --> 00:21:58.280]   said you're going to do whatever two quarters ago
[00:21:58.280 --> 00:21:59.800]   when you raised this money.
[00:22:00.200 --> 00:22:03.360]   Whatever you think the best idea is right now,
[00:22:03.360 --> 00:22:04.600]   let's go all in on that.
[00:22:04.600 --> 00:22:06.440]   Do not hedge your bets.
[00:22:06.440 --> 00:22:08.800]   I think that's just really important for founders.
[00:22:08.800 --> 00:22:10.440]   And it goes back to what you're saying.
[00:22:10.440 --> 00:22:14.400]   It's just so hard to execute any idea that you
[00:22:14.400 --> 00:22:16.560]   can't be hedged as a founder.
[00:22:16.560 --> 00:22:18.440]   Seven samurai.
[00:22:18.440 --> 00:22:21.880]   Akira Kurosawa did such an amazing job
[00:22:21.880 --> 00:22:24.680]   representing this ethos, I think.
[00:22:24.680 --> 00:22:26.440]   You strike, and you strike perfectly,
[00:22:26.440 --> 00:22:28.720]   and you strike with full force and with all your energy
[00:22:28.720 --> 00:22:31.320]   and everything you have, your whole character, everything.
[00:22:31.320 --> 00:22:33.120]   And you can accomplish incredible things.
[00:22:33.120 --> 00:22:37.440]   You have to put one foot in front of the other every day.
[00:22:37.440 --> 00:22:42.480]   And you have to focus on tangible progress.
[00:22:42.480 --> 00:22:46.040]   And where that fails is when most people--
[00:22:46.040 --> 00:22:47.680]   and I do it a lot, and I've tried
[00:22:47.680 --> 00:22:49.680]   to get better as I've gotten older-- is when I get
[00:22:49.680 --> 00:22:53.280]   comparative and I compare myself to the other person,
[00:22:53.280 --> 00:22:56.600]   the other company, the other funding round.
[00:22:56.600 --> 00:22:58.160]   There are so many reasons for you
[00:22:58.160 --> 00:23:01.560]   to feel like you're less than something else.
[00:23:01.560 --> 00:23:03.960]   And the reality is that has nothing to do with you.
[00:23:03.960 --> 00:23:06.240]   You're not in control of that.
[00:23:06.240 --> 00:23:07.760]   But it's so hard.
[00:23:07.760 --> 00:23:12.560]   And then if I don't take that medicine, I become insecure,
[00:23:12.560 --> 00:23:16.160]   and then I make mistakes that are entirely avoidable.
[00:23:16.160 --> 00:23:20.160]   So it's just tangible progress, the things that I can control.
[00:23:20.160 --> 00:23:22.960]   That's probably the most useful piece of advice
[00:23:22.960 --> 00:23:26.080]   that I try to remind myself of every day.
[00:23:26.080 --> 00:23:29.200]   And then I kind of have these two jobs.
[00:23:29.200 --> 00:23:31.360]   One is I'll incubate companies from time to time
[00:23:31.360 --> 00:23:33.840]   if I get intellectually curious enough.
[00:23:33.840 --> 00:23:36.280]   But the other part is just as an investor.
[00:23:36.280 --> 00:23:38.480]   And the best piece of advice I got as an investor
[00:23:38.480 --> 00:23:44.200]   is you are a big wave rider.
[00:23:44.200 --> 00:23:48.600]   And the swells that become ginormous
[00:23:48.600 --> 00:23:51.280]   are not visible when you paddle into them.
[00:23:51.280 --> 00:23:55.160]   And so you've got to commit, and you've got to go,
[00:23:55.160 --> 00:23:58.880]   and you are going to have less than 100% hit rate,
[00:23:58.880 --> 00:24:02.000]   and you will get massively washed out.
[00:24:02.000 --> 00:24:04.480]   And you just got to get to the surface and swim back out.
[00:24:04.480 --> 00:24:06.140]   And as an investor, that's been helpful
[00:24:06.140 --> 00:24:08.480]   because I've had some huge wins, but I've also
[00:24:08.480 --> 00:24:11.480]   had some huge losses and some total embarrassments
[00:24:11.480 --> 00:24:12.080]   and flame outs.
[00:24:12.080 --> 00:24:14.520]   And it's the totality of that that
[00:24:14.520 --> 00:24:15.880]   allows me to swim back out.
[00:24:15.880 --> 00:24:17.840]   So those are two different things.
[00:24:17.840 --> 00:24:19.840]   But the entrepreneurial one and the life one
[00:24:19.840 --> 00:24:24.960]   is more valuable because it's so easy to get distracted
[00:24:24.960 --> 00:24:27.840]   and feel insecure because of what somebody else is doing.
[00:24:27.840 --> 00:24:29.560]   And it always ends up screwing me up.
[00:24:29.560 --> 00:24:31.240]   I think that's a good note to end on.
[00:24:31.240 --> 00:24:33.800]   Give it up for my besties.
[00:24:33.800 --> 00:24:37.440]   And we're going to take a little walk over here
[00:24:37.440 --> 00:24:38.440]   for a little surprise.
[00:24:38.440 --> 00:24:40.800]   If I could have my four besties follow me over here.
[00:24:40.800 --> 00:24:44.160]   [MUSIC PLAYING]
[00:24:44.160 --> 00:24:46.800]   I'm going to walk over here because it's
[00:24:46.800 --> 00:24:51.160]   a very special day or a special time of the year.
[00:24:51.160 --> 00:24:54.040]   It's the Sultan of Science's birthday again.
[00:24:54.040 --> 00:24:55.760]   So come on around.
[00:24:55.760 --> 00:24:57.880]   And we got him a beautiful cake and then
[00:24:57.880 --> 00:25:00.080]   a tiny little vegan cake.
[00:25:00.080 --> 00:25:05.040]   And we're all going to sing the Sultan happy birthday.
[00:25:05.040 --> 00:25:07.520]   3, 2, 1.
[00:25:07.520 --> 00:25:11.740]   Happy birthday to you.
[00:25:11.740 --> 00:25:15.040]   Happy birthday to you.
[00:25:15.040 --> 00:25:19.760]   Happy birthday, dear Caleb.
[00:25:19.760 --> 00:25:23.400]   Happy birthday to you.
[00:25:23.400 --> 00:25:24.560]   We love you, pretty bird.
[00:25:24.560 --> 00:25:27.920]   [MUSIC PLAYING]
[00:25:27.920 --> 00:25:55.280]  ,

