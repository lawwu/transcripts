
[00:00:00.000 --> 00:00:05.000]   All right, so let's do a Cal Reacts to the News segment.
[00:00:05.000 --> 00:00:10.200]   As promised, I want to talk about this article
[00:00:10.200 --> 00:00:11.980]   from The Atlantic online.
[00:00:11.980 --> 00:00:14.040]   It's titled, "Why the Past 10 Years of American Life
[00:00:14.040 --> 00:00:15.240]   Has Been Uniquely Stupid."
[00:00:15.240 --> 00:00:19.360]   In the magazine, it was called "After Babel,"
[00:00:19.360 --> 00:00:21.800]   and is an epic article by,
[00:00:21.800 --> 00:00:24.200]   I'm gonna say friend of the show.
[00:00:24.200 --> 00:00:26.160]   What I mean is someone that people who've listened
[00:00:26.160 --> 00:00:28.800]   to this show enjoy, John Haidt.
[00:00:29.720 --> 00:00:32.120]   So I've talked to John Haidt once or twice.
[00:00:32.120 --> 00:00:35.360]   I don't know him well, but I really respect his work.
[00:00:35.360 --> 00:00:36.800]   Because he has psychology training,
[00:00:36.800 --> 00:00:39.120]   he can work with literatures in an academic way,
[00:00:39.120 --> 00:00:43.180]   but also has a real mind towards cultural criticism
[00:00:43.180 --> 00:00:44.880]   and public facing work, which I think is great.
[00:00:44.880 --> 00:00:45.920]   So I'm a big John Haidt fan.
[00:00:45.920 --> 00:00:47.440]   So I was excited to see this article.
[00:00:47.440 --> 00:00:49.280]   I'm gonna read just a few highlights.
[00:00:49.280 --> 00:00:52.040]   Some highlighted sentences from this article,
[00:00:52.040 --> 00:00:53.880]   then I'm gonna give you some thoughts on it.
[00:00:53.880 --> 00:00:55.880]   All right, so one thing he says here is,
[00:00:57.280 --> 00:01:01.640]   "Something went terribly wrong very suddenly
[00:01:01.640 --> 00:01:05.200]   with America in the 2010s."
[00:01:05.200 --> 00:01:10.200]   As he clarifies, "In the first decade of the new century,"
[00:01:10.200 --> 00:01:13.960]   so the 2000 to the late 2000, like 2009, 2010,
[00:01:13.960 --> 00:01:16.760]   "Social media was widely believed
[00:01:16.760 --> 00:01:19.080]   to be a boon to democracy."
[00:01:19.080 --> 00:01:23.160]   Haidt argues, "The high point of techno-democratic optimism
[00:01:23.160 --> 00:01:26.960]   was arguably 2011, a year that began
[00:01:26.960 --> 00:01:27.920]   with the Arab Spring
[00:01:27.920 --> 00:01:30.800]   and ended with the global Occupy movement."
[00:01:30.800 --> 00:01:37.440]   He goes on, however, to say, okay, and he clarifies also,
[00:01:37.440 --> 00:01:38.920]   "In their early incarnations,
[00:01:38.920 --> 00:01:40.640]   platforms such as MySpace and Facebook
[00:01:40.640 --> 00:01:42.400]   were relatively harmless.
[00:01:42.400 --> 00:01:43.960]   They allowed users to create pages
[00:01:43.960 --> 00:01:45.760]   on which to post photos, family updates,
[00:01:45.760 --> 00:01:48.200]   and link to mostly static pages
[00:01:48.200 --> 00:01:51.040]   of their friends and favorite bands.
[00:01:51.040 --> 00:01:52.860]   In this way, early social media can be seen
[00:01:52.860 --> 00:01:54.600]   as just another step in the long progression
[00:01:54.600 --> 00:01:56.600]   of technological improvements from the postal service
[00:01:56.600 --> 00:01:59.200]   through the telephone to email and texting,
[00:01:59.200 --> 00:02:01.440]   all of which helped people achieve the eternal goal
[00:02:01.440 --> 00:02:03.880]   of maintaining their social ties."
[00:02:03.880 --> 00:02:04.880]   All right?
[00:02:04.880 --> 00:02:06.720]   So John Haidt is setting things up
[00:02:06.720 --> 00:02:10.080]   where there's gonna be this fall, the 2010s.
[00:02:10.080 --> 00:02:11.600]   And in the first decade of the 2000s,
[00:02:11.600 --> 00:02:16.600]   basically we are in a more eidonic, eidetic time
[00:02:16.600 --> 00:02:20.280]   where social media was great.
[00:02:20.280 --> 00:02:22.960]   It was helping people connect to their friends and bands
[00:02:22.960 --> 00:02:25.200]   and get new information.
[00:02:25.200 --> 00:02:26.960]   And it was helping to overthrow dictators
[00:02:26.960 --> 00:02:28.360]   and everyone's really happy.
[00:02:28.360 --> 00:02:33.600]   And what he argues is there was a major change.
[00:02:33.600 --> 00:02:36.540]   So what was this major change that happened to social media
[00:02:36.540 --> 00:02:40.720]   that set up the fall that he talks about in this piece?
[00:02:40.720 --> 00:02:43.640]   Well, he goes on to give his theory.
[00:02:43.640 --> 00:02:47.520]   He says, okay, look, in 2009 and before,
[00:02:47.520 --> 00:02:50.920]   if you're on Facebook, you had a simple timeline,
[00:02:50.920 --> 00:02:52.240]   a never-ending stream of content
[00:02:52.240 --> 00:02:53.480]   generated by friends and connections
[00:02:53.480 --> 00:02:54.720]   with the newest post at the top
[00:02:54.720 --> 00:02:56.280]   and the oldest at the bottom.
[00:02:56.280 --> 00:02:58.240]   That began to change in 2009
[00:02:58.240 --> 00:03:02.000]   when Facebook offered users a way to publicly like posts
[00:03:02.000 --> 00:03:03.640]   with the click of a button.
[00:03:03.640 --> 00:03:04.880]   That same year, Twitter introduced
[00:03:04.880 --> 00:03:07.640]   something even more powerful, the retweet button,
[00:03:07.640 --> 00:03:10.160]   which allowed users to publicly endorse a post
[00:03:10.160 --> 00:03:12.360]   while also sharing it with all their followers.
[00:03:12.360 --> 00:03:13.900]   Facebook soon copied that innovation
[00:03:13.900 --> 00:03:14.840]   with its own share button,
[00:03:14.840 --> 00:03:17.960]   which became available to smartphone users in 2012.
[00:03:17.960 --> 00:03:20.480]   Like and share buttons quickly became standard
[00:03:20.480 --> 00:03:24.460]   on most social media platforms.
[00:03:24.460 --> 00:03:29.320]   Shortly after its like button began to produce data
[00:03:29.320 --> 00:03:30.920]   about what best engaged its users,
[00:03:30.920 --> 00:03:33.200]   Facebook developed algorithms to bring each user
[00:03:33.200 --> 00:03:35.340]   the content most likely to generate a like
[00:03:35.340 --> 00:03:36.920]   or some other interaction,
[00:03:36.920 --> 00:03:39.240]   eventually including the share as well.
[00:03:39.240 --> 00:03:42.280]   By 2013, social media had become a new game
[00:03:42.280 --> 00:03:44.760]   with dynamics unlike those in 2008.
[00:03:44.760 --> 00:03:45.960]   If you were skillful or lucky,
[00:03:45.960 --> 00:03:47.480]   you might create a post that would go viral
[00:03:47.480 --> 00:03:49.160]   and make you internet famous for a few days.
[00:03:49.160 --> 00:03:50.840]   If you blundered, you could find yourself buried
[00:03:50.840 --> 00:03:52.760]   in hateful comments.
[00:03:52.760 --> 00:03:55.560]   This new game encouraged dishonesty and mob dynamics.
[00:03:55.560 --> 00:03:57.740]   Users were guided not just by their true preferences,
[00:03:57.740 --> 00:04:01.040]   but by their past experiences of reward and punishment
[00:04:01.040 --> 00:04:02.920]   and the prediction of how others would react
[00:04:02.920 --> 00:04:05.300]   to each new action.
[00:04:05.300 --> 00:04:11.080]   So that is the story that Hyte tells
[00:04:11.080 --> 00:04:16.080]   for what is essentially the fall of social media,
[00:04:16.080 --> 00:04:18.280]   the fall from grace of social media.
[00:04:18.280 --> 00:04:22.080]   So this is a story, it's a tale of techno determinism.
[00:04:22.080 --> 00:04:23.960]   I talk about this in digital minimalism.
[00:04:23.960 --> 00:04:26.800]   I've talked about this in an article I wrote
[00:04:26.800 --> 00:04:28.600]   for the communications of the ACM.
[00:04:28.600 --> 00:04:31.640]   It's a point I've been making a lot recently,
[00:04:31.640 --> 00:04:33.760]   which is we have to be incredibly aware
[00:04:33.760 --> 00:04:35.760]   of unintentional techno social dynamics
[00:04:35.760 --> 00:04:38.200]   where a technology introduced for one period
[00:04:38.200 --> 00:04:41.360]   can have massive influences that we weren't expecting.
[00:04:41.360 --> 00:04:43.920]   And we should be monitoring those and aware of those
[00:04:43.920 --> 00:04:45.000]   and reacting to those.
[00:04:45.000 --> 00:04:46.360]   And we often don't.
[00:04:46.360 --> 00:04:47.200]   And as Hyte says,
[00:04:47.200 --> 00:04:49.480]   this is what happened with the like and retweet button.
[00:04:49.480 --> 00:04:53.040]   It completely changed the character of social media.
[00:04:53.040 --> 00:04:55.800]   Where social media used to be about connecting to people,
[00:04:55.800 --> 00:04:57.040]   posting information, connecting,
[00:04:57.040 --> 00:05:00.360]   it became instead about viral dynamics.
[00:05:00.360 --> 00:05:02.400]   What's gonna be a hit?
[00:05:02.400 --> 00:05:05.160]   What is going to avoid me being attacked?
[00:05:05.160 --> 00:05:06.680]   You don't have that without retweet.
[00:05:06.680 --> 00:05:07.960]   You don't have that without likes.
[00:05:07.960 --> 00:05:10.200]   But once it became this algorithmic stream
[00:05:10.200 --> 00:05:13.660]   with viral dynamics, it completely changed the character.
[00:05:13.660 --> 00:05:15.580]   It wasn't the intention.
[00:05:15.580 --> 00:05:18.220]   As I talk about in my book, "Digital Minimalism",
[00:05:18.220 --> 00:05:20.220]   the intention of the like button originally
[00:05:20.220 --> 00:05:23.120]   was that engineers thought it was not elegant.
[00:05:23.120 --> 00:05:27.280]   That someone would post a photo on Facebook
[00:05:27.280 --> 00:05:30.320]   and so many comments would say more or less the same thing.
[00:05:30.320 --> 00:05:33.120]   Awesome, cool, great, good.
[00:05:33.120 --> 00:05:34.360]   Like, well, let's just put a like button in
[00:05:34.360 --> 00:05:37.140]   so that if all you're gonna say is like, that's great,
[00:05:37.140 --> 00:05:39.000]   just click that button and we'll count up
[00:05:39.000 --> 00:05:39.960]   how many people said that
[00:05:39.960 --> 00:05:41.000]   so that you don't have to waste time
[00:05:41.000 --> 00:05:41.840]   scrolling through comments
[00:05:41.840 --> 00:05:44.340]   that are all just simple positive affirmations.
[00:05:44.340 --> 00:05:45.600]   That was the point of the like button.
[00:05:45.600 --> 00:05:46.440]   But almost immediately,
[00:05:46.440 --> 00:05:48.480]   it completely changed the dynamics of Facebook
[00:05:48.480 --> 00:05:50.600]   because A, it made it more addictive
[00:05:50.600 --> 00:05:51.780]   because you began to care about
[00:05:51.780 --> 00:05:53.480]   how many likes your things got.
[00:05:53.480 --> 00:05:56.120]   And B, it gave them data that they could use
[00:05:56.120 --> 00:05:57.920]   to create algorithmically generated streams,
[00:05:57.920 --> 00:06:00.860]   which broke the whole model of I know you.
[00:06:00.860 --> 00:06:04.080]   And Facebook is great because I can see what you're up to.
[00:06:04.080 --> 00:06:06.400]   And made into this model of, oh my God,
[00:06:06.400 --> 00:06:07.760]   what am I seeing in my newsfeed?
[00:06:07.760 --> 00:06:09.640]   This is interesting, this is outrageous,
[00:06:09.640 --> 00:06:10.840]   this is emotionally engaged,
[00:06:10.840 --> 00:06:13.240]   and it completely changed the dynamic.
[00:06:13.240 --> 00:06:14.080]   So is that a bad thing?
[00:06:14.080 --> 00:06:16.640]   Well, Haidt says it's undermining democracy.
[00:06:16.640 --> 00:06:18.440]   It is like one of the worst things to happen
[00:06:18.440 --> 00:06:21.320]   is the social media platforms going towards
[00:06:21.320 --> 00:06:23.800]   this optimized streams that create,
[00:06:23.800 --> 00:06:26.520]   equipped with or augmented with viral dynamics.
[00:06:26.520 --> 00:06:28.180]   He gives three things he said went wrong
[00:06:28.180 --> 00:06:29.440]   once we switched to this.
[00:06:29.440 --> 00:06:35.760]   Number one, it gave more power to tools and provocateurs
[00:06:35.760 --> 00:06:39.240]   while silencing good citizens.
[00:06:39.240 --> 00:06:42.760]   Number two, this approach gave more power
[00:06:42.760 --> 00:06:45.400]   and voice to the political extremes
[00:06:45.400 --> 00:06:49.720]   while reducing the power and voice of the moderate majority.
[00:06:49.720 --> 00:06:51.880]   Because again, when you have viral dynamics
[00:06:51.880 --> 00:06:53.880]   in terms of both praise and attack,
[00:06:53.880 --> 00:06:57.280]   you migrate to the extremes.
[00:06:57.280 --> 00:06:59.320]   A, you're not gonna get shared for saying things moderate,
[00:06:59.320 --> 00:07:03.600]   and two, the extremes are gonna be motivated to pile on
[00:07:03.600 --> 00:07:05.240]   or try to attack people that seem like
[00:07:05.240 --> 00:07:06.320]   they're drifting from it.
[00:07:06.320 --> 00:07:10.280]   He cites the pro-democracy group More in Common,
[00:07:10.280 --> 00:07:11.660]   a very important survey.
[00:07:12.600 --> 00:07:16.040]   Back in 2017, they surveyed 8,000 Americans
[00:07:16.040 --> 00:07:18.840]   and they split the Americans up into seven groups
[00:07:18.840 --> 00:07:21.280]   that shared beliefs and behaviors.
[00:07:21.280 --> 00:07:24.480]   And they found that devoted conservatives
[00:07:24.480 --> 00:07:27.480]   comprised 6% of the US population,
[00:07:27.480 --> 00:07:29.600]   and the group furthest to the left,
[00:07:29.600 --> 00:07:31.080]   what they called progressive activists,
[00:07:31.080 --> 00:07:33.380]   comprised just 8% of the population.
[00:07:33.380 --> 00:07:37.000]   And the progressive activists in particular
[00:07:37.000 --> 00:07:40.200]   were the most prolific group on social media.
[00:07:40.200 --> 00:07:43.000]   70% had shared political content over the previous years,
[00:07:43.000 --> 00:07:45.160]   and the devoted conservatives were also very active
[00:07:45.160 --> 00:07:46.240]   on social media.
[00:07:46.240 --> 00:07:51.240]   At least 56% had shared political content.
[00:07:51.240 --> 00:07:54.500]   And the irony, he points out, is that those two groups
[00:07:54.500 --> 00:07:56.800]   tend to be both richer than the average American
[00:07:56.800 --> 00:07:58.400]   and wider than the average American.
[00:07:58.400 --> 00:08:01.320]   So that we have, quote, two subsets of the elite
[00:08:01.320 --> 00:08:02.960]   who are not representative of the broader society
[00:08:02.960 --> 00:08:04.840]   that are completely driving
[00:08:04.840 --> 00:08:08.840]   sort of extreme conversation on social media.
[00:08:09.680 --> 00:08:13.320]   Finally, he says, "Social media in this new form
[00:08:13.320 --> 00:08:15.680]   deputize everyone to administer justice
[00:08:15.680 --> 00:08:17.480]   with no due process.
[00:08:17.480 --> 00:08:19.860]   Platforms like Twitter devolve into the Wild West
[00:08:19.860 --> 00:08:22.720]   with no accountability for vigilantes.
[00:08:22.720 --> 00:08:25.000]   A successful attack attracts a barrage of likes
[00:08:25.000 --> 00:08:25.880]   and follow-on strikes.
[00:08:25.880 --> 00:08:27.320]   Enhanced virality platforms
[00:08:27.320 --> 00:08:29.520]   thereby facilitate massive collective punishment
[00:08:29.520 --> 00:08:31.520]   for small or imagined offenses
[00:08:31.520 --> 00:08:32.820]   with real-world consequences,
[00:08:32.820 --> 00:08:34.800]   including innocent people losing their jobs
[00:08:34.800 --> 00:08:36.320]   and being shamed into suicide.
[00:08:36.320 --> 00:08:38.520]   When our public square is governed by mob dynamics,
[00:08:38.520 --> 00:08:39.840]   unrestrained by due process,
[00:08:39.840 --> 00:08:42.200]   we don't get justice and inclusion.
[00:08:42.200 --> 00:08:44.040]   We get a society that ignores context,
[00:08:44.040 --> 00:08:47.480]   proportionality, mercy, and truth."
[00:08:47.480 --> 00:08:50.160]   So we get that happening as well.
[00:08:50.160 --> 00:08:53.120]   That is, again, another point I will just say,
[00:08:53.120 --> 00:08:58.120]   I hear this a lot in conversations about social media,
[00:08:58.120 --> 00:08:59.760]   content, content moderations.
[00:08:59.760 --> 00:09:01.320]   This came up, I think, in the context
[00:09:01.320 --> 00:09:04.160]   of last week's discussion of Elon Musk and Twitter,
[00:09:04.160 --> 00:09:07.920]   where people say, "No, I think it's good.
[00:09:07.920 --> 00:09:10.020]   Look, it's good that there's blowback.
[00:09:10.020 --> 00:09:13.260]   If you're worried about saying something,
[00:09:13.260 --> 00:09:15.960]   that means you should be worried about saying it."
[00:09:15.960 --> 00:09:17.540]   And you often hear the phrase,
[00:09:17.540 --> 00:09:20.100]   "Free speech doesn't mean freedom from consequences.
[00:09:20.100 --> 00:09:21.520]   You can say what you want,
[00:09:21.520 --> 00:09:23.040]   but you have to be ready for the consequences."
[00:09:23.040 --> 00:09:25.880]   And I think what Haidt is pointing out here is
[00:09:25.880 --> 00:09:28.320]   that on its own is a vacuous statement.
[00:09:28.320 --> 00:09:31.860]   You look at any example in history
[00:09:31.860 --> 00:09:33.860]   where there is a clearly, let's say,
[00:09:33.900 --> 00:09:38.900]   authoritarian regime dispensing arbitrary dictatorial justice.
[00:09:38.900 --> 00:09:43.180]   So let's look at Stalin throwing people into the Gulag.
[00:09:43.180 --> 00:09:46.480]   If you were to go there and see what was going on,
[00:09:46.480 --> 00:09:50.500]   he was not just saying, "I have arbitrary power,
[00:09:50.500 --> 00:09:53.140]   and I'm putting you in the Gulag because I don't like you,
[00:09:53.140 --> 00:09:54.540]   and what are you going to do about it?"
[00:09:54.540 --> 00:09:56.260]   No, there'd be a trial.
[00:09:56.260 --> 00:09:57.540]   And he would say, look,
[00:09:57.540 --> 00:09:59.340]   he would say the similar sort of thing.
[00:09:59.340 --> 00:10:01.060]   What you say, "Things have consequences.
[00:10:01.060 --> 00:10:02.980]   You were treasonous to the country.
[00:10:02.980 --> 00:10:07.220]   This treason's going to unsettle the communist utopia.
[00:10:07.220 --> 00:10:10.100]   Like, you know, your actions have consequences,
[00:10:10.100 --> 00:10:11.660]   and you're doing something dangerous.
[00:10:11.660 --> 00:10:12.500]   You need to go to the Gulag."
[00:10:12.500 --> 00:10:15.660]   I mean, that's true of any time, anywhere.
[00:10:15.660 --> 00:10:16.960]   So what you have to do, of course,
[00:10:16.960 --> 00:10:19.620]   is with some humanity and common sense,
[00:10:19.620 --> 00:10:22.420]   just look at the particular context and say,
[00:10:22.420 --> 00:10:25.420]   is this largely actually just, or is it disproportionate?
[00:10:25.420 --> 00:10:26.540]   So if you're in Stalin's Russia,
[00:10:26.540 --> 00:10:28.100]   you would say this is very disproportionate.
[00:10:28.100 --> 00:10:29.660]   He's sending people to the Gulag
[00:10:29.660 --> 00:10:31.460]   clearly because he just doesn't like them,
[00:10:31.460 --> 00:10:32.460]   or they're not on his team,
[00:10:32.460 --> 00:10:35.020]   or he's trying to make sure that he can preserve power.
[00:10:35.020 --> 00:10:37.140]   And obviously things aren't that bad now,
[00:10:37.140 --> 00:10:38.940]   but I think a lot of neutral observers
[00:10:38.940 --> 00:10:41.780]   looking at the swiftness and virality of pylons,
[00:10:41.780 --> 00:10:42.900]   both on the left and right,
[00:10:42.900 --> 00:10:46.940]   would say this can't possibly be proportional and just.
[00:10:46.940 --> 00:10:48.420]   It just doesn't seem that way.
[00:10:48.420 --> 00:10:50.220]   Our common sense is saying that's not true.
[00:10:50.220 --> 00:10:52.580]   So I don't buy the argument of,
[00:10:52.580 --> 00:10:56.700]   hey, you can say what you want, consequences,
[00:10:56.700 --> 00:10:58.660]   but you can't be free from consequences.
[00:10:58.660 --> 00:11:00.140]   That applies in every context.
[00:11:00.180 --> 00:11:03.340]   What matters is, are the consequences we've seen,
[00:11:03.340 --> 00:11:06.740]   as Haidt would say, proportional, merciful, and truthful?
[00:11:06.740 --> 00:11:10.180]   And often they're not, and it's because, as Haidt points out,
[00:11:10.180 --> 00:11:13.500]   the viral dynamics of these platforms
[00:11:13.500 --> 00:11:16.060]   have pushed out most of the middle,
[00:11:16.060 --> 00:11:18.060]   pushed out most normal people.
[00:11:18.060 --> 00:11:20.740]   We have these two extremes on either side,
[00:11:20.740 --> 00:11:24.100]   completely disproportionate of the population
[00:11:24.100 --> 00:11:25.980]   that not only control the conversation,
[00:11:25.980 --> 00:11:27.860]   but are doing so in an incredibly aggressive way
[00:11:27.860 --> 00:11:29.740]   because they're trying to play the dynamics
[00:11:29.740 --> 00:11:32.660]   of great viral reward while avoiding
[00:11:32.660 --> 00:11:34.540]   or participating in great viral punishment.
[00:11:34.540 --> 00:11:36.340]   And so it really is a wild west
[00:11:36.340 --> 00:11:39.060]   of a small number of disproportionate vigilantes
[00:11:39.060 --> 00:11:40.260]   running around.
[00:11:40.260 --> 00:11:42.660]   And he thinks that's very destabilizing,
[00:11:42.660 --> 00:11:44.220]   and I think he's probably true.
[00:11:44.220 --> 00:11:48.380]   All right, so what do we do about it?
[00:11:48.380 --> 00:11:51.100]   Well, I don't have a definitive answer,
[00:11:51.100 --> 00:11:53.900]   but there's a couple points I wanna make.
[00:11:53.900 --> 00:11:56.540]   First of all, I think I am somewhat alone
[00:11:57.740 --> 00:12:00.780]   in my argument that I do not think Twitter
[00:12:00.780 --> 00:12:02.700]   is as fundamental as everyone else does.
[00:12:02.700 --> 00:12:04.700]   Haidt makes this point,
[00:12:04.700 --> 00:12:06.460]   Elon Musk has recently made this point.
[00:12:06.460 --> 00:12:08.100]   They're all saying this is the town square,
[00:12:08.100 --> 00:12:09.300]   it's critical to democracy,
[00:12:09.300 --> 00:12:11.460]   that's why we really have to care about it.
[00:12:11.460 --> 00:12:13.020]   I don't think it's critical to democracy,
[00:12:13.020 --> 00:12:15.460]   I don't think it's the town square.
[00:12:15.460 --> 00:12:17.580]   I think if Haidt is right, that what Twitter is
[00:12:17.580 --> 00:12:22.340]   is 11% of the population segregated at the extremes
[00:12:22.340 --> 00:12:25.500]   playing this weird viral vigilante game
[00:12:25.500 --> 00:12:28.540]   of viral reward and viral punishment,
[00:12:28.540 --> 00:12:31.460]   maybe being observed by a larger group of people
[00:12:31.460 --> 00:12:33.980]   who find the emotions of this kind of entertaining.
[00:12:33.980 --> 00:12:37.340]   This is not the public town square.
[00:12:37.340 --> 00:12:39.780]   This is the Colosseum.
[00:12:39.780 --> 00:12:44.340]   This is the gladiator to the fights to the death
[00:12:44.340 --> 00:12:46.380]   that people in Rome will wander over to watch
[00:12:46.380 --> 00:12:48.340]   'cause it's bloody and interesting
[00:12:48.340 --> 00:12:50.580]   and is better than doing something else,
[00:12:50.580 --> 00:12:52.020]   it's kind of exciting,
[00:12:52.020 --> 00:12:53.340]   but it's not at the core of democracy,
[00:12:53.340 --> 00:12:54.540]   and how do we know that?
[00:12:54.540 --> 00:12:57.580]   'Cause what would happen if, for whatever reason,
[00:12:57.580 --> 00:13:00.140]   let's say Elon succeeds and his latest thing
[00:13:00.140 --> 00:13:01.740]   is he wants to buy Twitter, he made an offer,
[00:13:01.740 --> 00:13:03.700]   let's say he just shuts it down.
[00:13:03.700 --> 00:13:05.860]   Nothing bad would happen.
[00:13:05.860 --> 00:13:09.380]   85% of the country or 90% of the country
[00:13:09.380 --> 00:13:12.300]   wouldn't even notice 'cause most people don't use Twitter.
[00:13:12.300 --> 00:13:14.980]   You don't need Twitter to report the news,
[00:13:14.980 --> 00:13:16.580]   you don't need Twitter to be a politician,
[00:13:16.580 --> 00:13:18.940]   you don't need Twitter to be entertaining,
[00:13:18.940 --> 00:13:20.740]   nothing bad would happen.
[00:13:20.740 --> 00:13:22.020]   People would barely notice.
[00:13:22.020 --> 00:13:24.820]   It would have less of an impact
[00:13:24.820 --> 00:13:29.620]   than supply chain disruption for toilet paper.
[00:13:29.620 --> 00:13:33.300]   So how could that be critical to the town square?
[00:13:33.300 --> 00:13:37.860]   It's a Colosseum, it's not the Roman Senate.
[00:13:37.860 --> 00:13:39.020]   That is my argument.
[00:13:39.020 --> 00:13:42.860]   So once we recognize that, then I would argue
[00:13:42.860 --> 00:13:44.660]   we need to downgrade the importance of Twitter.
[00:13:44.660 --> 00:13:48.220]   It's weird, it's this weird 240 characters
[00:13:48.220 --> 00:13:50.620]   or whatever it is now with these weird viral dynamics
[00:13:50.620 --> 00:13:52.140]   and these little boxes with these threads
[00:13:52.140 --> 00:13:53.940]   and it's this weird bloody gladiator game
[00:13:53.940 --> 00:13:55.780]   and we say I'm leaving the Colosseum.
[00:13:55.780 --> 00:13:57.780]   And here's what I think we need instead.
[00:13:57.780 --> 00:14:01.660]   A, we replace the distraction that Twitter gives,
[00:14:01.660 --> 00:14:03.940]   whoever it gives distraction to with better distraction.
[00:14:03.940 --> 00:14:06.140]   There's better things to do if you're bored.
[00:14:06.140 --> 00:14:08.980]   Yeah, it's exciting, but listen to a podcast,
[00:14:08.980 --> 00:14:10.380]   read a book, have a better hobby.
[00:14:10.380 --> 00:14:11.860]   There's all sorts of things you can do
[00:14:11.860 --> 00:14:13.620]   that are interesting and entertaining,
[00:14:13.620 --> 00:14:17.460]   more so than these weird short character threads
[00:14:17.460 --> 00:14:19.700]   of extreme people fighting each other.
[00:14:20.660 --> 00:14:24.260]   Two, I think social media itself needs to fragment much more
[00:14:24.260 --> 00:14:28.300]   and get back more towards that 2000 to 2009 period
[00:14:28.300 --> 00:14:30.860]   where it is about connecting to people
[00:14:30.860 --> 00:14:34.620]   that you find interesting and know, expressing yourself.
[00:14:34.620 --> 00:14:36.780]   Social media should be more niche.
[00:14:36.780 --> 00:14:39.420]   It should be more about like people felt MySpace
[00:14:39.420 --> 00:14:41.900]   was in the early days or Facebook was in the early days.
[00:14:41.900 --> 00:14:45.940]   Here is a group of amateur bicyclists
[00:14:45.940 --> 00:14:47.860]   and we connect with each other
[00:14:47.860 --> 00:14:49.500]   and we share photos of our rides
[00:14:49.500 --> 00:14:50.460]   and encourage each other.
[00:14:50.460 --> 00:14:54.180]   And we have our own norms and our own way of talking.
[00:14:54.180 --> 00:14:55.020]   And it's great.
[00:14:55.020 --> 00:14:56.020]   And I'm glad it exists
[00:14:56.020 --> 00:14:57.780]   because there's not enough amateur cyclists
[00:14:57.780 --> 00:15:00.100]   who live near me to actually like meet that many people.
[00:15:00.100 --> 00:15:02.140]   And that's what social media should be.
[00:15:02.140 --> 00:15:04.740]   It should not try to be a virtual town square.
[00:15:04.740 --> 00:15:05.860]   There should not be a service
[00:15:05.860 --> 00:15:08.020]   that everyone feels like they have to use.
[00:15:08.020 --> 00:15:10.460]   That doesn't work.
[00:15:10.460 --> 00:15:14.460]   Finally, C, we need better ways
[00:15:14.460 --> 00:15:18.340]   for those who actually do have important, useful
[00:15:18.340 --> 00:15:19.980]   or thought provoking information to share
[00:15:19.980 --> 00:15:21.580]   to use the internet to share that.
[00:15:21.580 --> 00:15:24.060]   There is no reason why the best and brightest,
[00:15:24.060 --> 00:15:27.380]   the most interesting, the smartest,
[00:15:27.380 --> 00:15:30.300]   the most engaging thinkers and writers out there
[00:15:30.300 --> 00:15:34.140]   should be constrained to a small number of characters,
[00:15:34.140 --> 00:15:36.660]   retweets and linking and adding
[00:15:36.660 --> 00:15:38.380]   and all of these weird arbitrary rules
[00:15:38.380 --> 00:15:40.580]   that serve to do nothing but virality.
[00:15:40.580 --> 00:15:43.020]   And virality is not useful
[00:15:43.020 --> 00:15:47.540]   for giving you the ability to share and express yourself
[00:15:47.540 --> 00:15:48.580]   and to hear what other people are saying.
[00:15:48.580 --> 00:15:49.940]   It's really not that useful for it.
[00:15:49.940 --> 00:15:52.060]   The internet existed before the retweet.
[00:15:52.060 --> 00:15:53.980]   Social media and internet existed before the like button.
[00:15:53.980 --> 00:15:58.980]   So I think we need perhaps an earlier web 2.0 type approach,
[00:15:58.980 --> 00:16:01.980]   podcasts, blogs, individual websites
[00:16:01.980 --> 00:16:04.500]   where you can express yourself at length and in detail.
[00:16:04.500 --> 00:16:08.700]   And yes, it's harder to find attention
[00:16:08.700 --> 00:16:10.060]   when you're kind of on your own,
[00:16:10.060 --> 00:16:12.020]   but that I think is a feature.
[00:16:12.020 --> 00:16:16.100]   That means you're gonna gather a more focused crowd.
[00:16:16.100 --> 00:16:17.780]   The best will rise to the top.
[00:16:17.780 --> 00:16:20.740]   You know, yeah, most podcasts don't get listened to,
[00:16:20.740 --> 00:16:22.700]   but ones that are interesting get big audiences.
[00:16:22.700 --> 00:16:25.420]   It's harder, but it's longer form, it's more nuanced,
[00:16:25.420 --> 00:16:27.420]   and it doesn't have viral dynamics.
[00:16:27.420 --> 00:16:30.060]   It doesn't create these weird pushes to the extremes.
[00:16:30.060 --> 00:16:32.500]   I wrote an article about this for Wired Magazine
[00:16:32.500 --> 00:16:34.780]   early in the pandemic, where I said,
[00:16:34.780 --> 00:16:36.260]   the best thing we could do
[00:16:36.260 --> 00:16:37.940]   from a public health perspective
[00:16:37.940 --> 00:16:41.700]   for during the pandemic would probably shut down Twitter.
[00:16:41.700 --> 00:16:43.060]   It's just gonna make people crazy.
[00:16:43.060 --> 00:16:44.580]   It's gonna push people in weird directions.
[00:16:44.580 --> 00:16:48.420]   It's not gonna help our psychological
[00:16:48.420 --> 00:16:49.740]   or physical health during a pandemic.
[00:16:49.740 --> 00:16:52.100]   And my argument in that Wired piece was
[00:16:52.100 --> 00:16:54.260]   we should go back to blogs for medical experts,
[00:16:54.260 --> 00:16:56.980]   and they should be hosted on institutional websites
[00:16:56.980 --> 00:16:58.220]   so we trust it.
[00:16:58.220 --> 00:17:03.220]   Oh, this doctor works for this medical network.
[00:17:03.220 --> 00:17:06.100]   The blog is posted on that network.
[00:17:06.100 --> 00:17:07.580]   Like we're already validating,
[00:17:07.580 --> 00:17:09.100]   like this is where this person comes from.
[00:17:09.100 --> 00:17:10.060]   Here's why I should trust them.
[00:17:10.060 --> 00:17:13.300]   And he's not doing tweet threads of screenshotted charts.
[00:17:13.300 --> 00:17:15.140]   He can write a real article.
[00:17:15.140 --> 00:17:16.940]   And yeah, if you wanted to use social media to say,
[00:17:16.940 --> 00:17:20.620]   I published a new article, you can find it here, fine.
[00:17:20.620 --> 00:17:22.620]   But that was the appropriate form
[00:17:22.620 --> 00:17:24.260]   'cause it allows us to do curation
[00:17:24.260 --> 00:17:26.180]   of who we should be listening to, to get more information,
[00:17:26.180 --> 00:17:27.900]   to have context, to have nuance.
[00:17:27.900 --> 00:17:31.140]   Twitter was a terrible medium for that type of discussion.
[00:17:31.140 --> 00:17:32.980]   So I think we need to go back or forward,
[00:17:32.980 --> 00:17:35.860]   we could even say, to a way of communicating,
[00:17:35.860 --> 00:17:37.620]   expressing ourself that doesn't constrain us
[00:17:37.620 --> 00:17:39.300]   to these weird, narrow platforms
[00:17:39.300 --> 00:17:42.700]   that are built around virality and active user minutes,
[00:17:42.700 --> 00:17:46.700]   not around the most effective ways to convey information.
[00:17:46.700 --> 00:17:50.900]   All right, so that's my thoughts on this general point.
[00:17:50.900 --> 00:17:54.460]   I think John Haidt is right and perceptive.
[00:17:54.460 --> 00:17:55.620]   I think he clarified better.
[00:17:55.620 --> 00:17:58.900]   I've made this argument, he clarifies it a little bit better
[00:17:58.900 --> 00:18:02.220]   that as you shifted from, the way I usually put it
[00:18:02.220 --> 00:18:05.300]   is as you shifted from the wall to the newsfeed,
[00:18:05.300 --> 00:18:08.700]   as you shifted from looking at friends' posts
[00:18:08.700 --> 00:18:10.340]   to liking and retweeting,
[00:18:10.340 --> 00:18:12.020]   you got these weird viral dynamics
[00:18:12.020 --> 00:18:15.140]   that transformed the social media landscape
[00:18:15.140 --> 00:18:19.940]   into this weird group of extremes and vigilantes
[00:18:19.940 --> 00:18:21.380]   that's had a huge negative effect.
[00:18:21.380 --> 00:18:23.180]   And again, most people don't use Twitter,
[00:18:23.180 --> 00:18:26.100]   but reporters use it, politicians use it,
[00:18:26.100 --> 00:18:27.980]   corporate executives look at it,
[00:18:27.980 --> 00:18:30.300]   and it has, so therefore, a huge outsized effect.
[00:18:30.300 --> 00:18:33.780]   And to me, again, it's not the town square,
[00:18:33.780 --> 00:18:36.100]   it's not the Roman Senate, it's the Colosseum.
[00:18:36.100 --> 00:18:39.100]   And we're letting the bloody combat in the Colosseum,
[00:18:39.100 --> 00:18:41.100]   as entertaining as it is to look at in the moment,
[00:18:41.100 --> 00:18:42.380]   we're letting that actually dictate
[00:18:42.380 --> 00:18:44.740]   the way the rest of us live their lives,
[00:18:44.740 --> 00:18:49.740]   how news is covered, how politicians act as legislatures,
[00:18:49.740 --> 00:18:55.300]   how companies set policy or change their directives
[00:18:55.300 --> 00:18:57.620]   or initiatives, or even decide who to hire or fire.
[00:18:57.620 --> 00:18:59.420]   And this is crazy, the Colosseum
[00:18:59.420 --> 00:19:00.980]   should not have a major role.
[00:19:00.980 --> 00:19:02.700]   There is nothing fundamental about this technology.
[00:19:02.700 --> 00:19:04.740]   We can do better with the internet,
[00:19:04.740 --> 00:19:06.980]   and I hope we actually do.
[00:19:07.860 --> 00:19:10.100]   So that's my thought on John Haidt's article on Twitter.
[00:19:10.100 --> 00:19:11.820]   So good job, John Haidt.
[00:19:11.820 --> 00:19:15.140]   And that would be what I add to it.
[00:19:15.140 --> 00:19:18.540]   I mean, the one exception where we do need Twitter,
[00:19:18.540 --> 00:19:20.580]   I think is Baseball Trade Rumors,
[00:19:20.580 --> 00:19:22.220]   'cause I need that information fast.
[00:19:22.220 --> 00:19:24.620]   But hey, look, that's an example though.
[00:19:24.620 --> 00:19:26.340]   Yeah, Twitter is good for getting
[00:19:26.340 --> 00:19:29.100]   Baseball Trade Rumor information fast,
[00:19:29.100 --> 00:19:31.820]   but there's a website, mlbtraderumors.com,
[00:19:31.820 --> 00:19:34.940]   that works just as well, and it's focused on just that.
[00:19:34.940 --> 00:19:37.740]   And I'll tell you something, and then I'll let this go,
[00:19:37.740 --> 00:19:39.140]   but I'll tell you something.
[00:19:39.140 --> 00:19:42.620]   That is where I went to see what was going on
[00:19:42.620 --> 00:19:45.060]   in the highly compressed free agency that happened in March
[00:19:45.060 --> 00:19:46.980]   after the collective bargaining agreement
[00:19:46.980 --> 00:19:49.700]   was made, finalized for MLB,
[00:19:49.700 --> 00:19:51.860]   because specifically I did not wanna go to Twitter
[00:19:51.860 --> 00:19:53.340]   to see what the baseball reporters were saying,
[00:19:53.340 --> 00:19:55.660]   because Twitter was gonna push in my face
[00:19:55.660 --> 00:19:57.700]   terrible, terrifying news about Ukraine
[00:19:57.700 --> 00:19:59.900]   and nuclear war and about COVID.
[00:19:59.900 --> 00:20:02.500]   And I was like, I don't wanna go to the Colosseum
[00:20:02.500 --> 00:20:04.740]   to find out about my team.
[00:20:04.740 --> 00:20:06.780]   And so I went to a special purpose website,
[00:20:06.780 --> 00:20:09.340]   got the news I wanted without the stress.
[00:20:09.340 --> 00:20:12.340]   So case in point, that's the future we need.
[00:20:12.340 --> 00:20:14.940]   (upbeat music)
[00:20:14.940 --> 00:20:18.280]   [MUSIC PLAYING]
[00:20:18.280 --> 00:20:19.380]   (upbeat music)

