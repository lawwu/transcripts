
[00:00:00.000 --> 00:00:05.520]   Whenever we start a new project, it has to have these ingredients of simultaneous
[00:00:05.520 --> 00:00:06.200]   complexity.
[00:00:06.200 --> 00:00:10.020]   It has to be novel in terms of the synthetic biology, material science,
[00:00:10.020 --> 00:00:14.760]   robotics, engineering, all of these elements that are discipline based or
[00:00:14.760 --> 00:00:16.640]   rooted must be novel.
[00:00:16.640 --> 00:00:22.220]   If you can combine novelty in synthetic biology with a novelty in robotics, with
[00:00:22.220 --> 00:00:26.100]   a novelty in material science, with a novelty in computational design, you are
[00:00:26.100 --> 00:00:28.120]   bound to create something novel.
[00:00:28.120 --> 00:00:35.360]   The following is a conversation with Neri Oxman, an engineer, scientist,
[00:00:35.360 --> 00:00:39.680]   designer, architect, artist, and one of the kindest, most thoughtful, and
[00:00:39.680 --> 00:00:41.880]   brilliant human beings I've ever gotten to know.
[00:00:41.880 --> 00:00:47.640]   For a long time, she led the mediated matter group at MIT that did research and
[00:00:47.640 --> 00:00:51.720]   built incredible stuff at the intersection of computational design, digital
[00:00:51.720 --> 00:00:57.480]   fabrication, material science, and synthetic biology, doing so at all scales,
[00:00:57.560 --> 00:00:59.760]   from the micro scale to the building scale.
[00:00:59.760 --> 00:01:05.180]   Now she's continuing this work at a very new company for now called Oxman,
[00:01:05.180 --> 00:01:10.160]   looking to revolutionize how humans design and build products, working
[00:01:10.160 --> 00:01:12.200]   with nature, not against it.
[00:01:12.200 --> 00:01:17.360]   On a personal note, let me say that Neri has for a long time been a friend and
[00:01:17.360 --> 00:01:21.320]   someone who in my darker moments has always been there with a note of
[00:01:21.320 --> 00:01:22.600]   kindness and support.
[00:01:22.600 --> 00:01:25.000]   I am forever grateful to her.
[00:01:25.600 --> 00:01:28.160]   She's a brilliant and a beautiful human being.
[00:01:28.160 --> 00:01:35.120]   Oh, and she also brought me a present, War and Peace by Tolstoy and
[00:01:35.120 --> 00:01:37.240]   Meditations by Marcus Aurelius.
[00:01:37.240 --> 00:01:39.120]   It doesn't get better than that.
[00:01:39.120 --> 00:01:41.680]   This is the Lex Friedman Podcast.
[00:01:41.680 --> 00:01:44.840]   To support it, please check out our sponsors in the description.
[00:01:44.840 --> 00:01:48.520]   And now, dear friends, here's Neri Oxman.
[00:01:48.520 --> 00:01:50.920]   Let's start with the universe.
[00:01:50.920 --> 00:01:54.640]   You ever think of the universe as a kind of machine that designs beautiful
[00:01:54.640 --> 00:01:56.280]   things at multiple scales?
[00:01:56.280 --> 00:01:57.440]   I do.
[00:01:57.440 --> 00:02:05.120]   And I think of nature in that way, in general, in the context of design
[00:02:05.120 --> 00:02:12.040]   specifically, I think of nature as everything that isn't anthropomass,
[00:02:12.040 --> 00:02:16.200]   everything that is not produced by humankind, the birds and the rocks and
[00:02:16.200 --> 00:02:19.480]   everything in between, fungi, elephants, whales.
[00:02:19.480 --> 00:02:22.520]   Do you think there's an intricate ways in which there's a connection
[00:02:22.520 --> 00:02:23.800]   between humans and nature?
[00:02:23.800 --> 00:02:24.560]   Yes.
[00:02:24.720 --> 00:02:26.280]   And we're looking for it.
[00:02:26.280 --> 00:02:33.280]   I think that from, let's say, from the beginning of mankind, going back 200,000
[00:02:33.280 --> 00:02:39.160]   years, the products that we have designed have separated us from nature.
[00:02:39.160 --> 00:02:44.200]   And it's ironic that the things that we designed and produced as humankind,
[00:02:44.200 --> 00:02:46.800]   those are exactly the things that separated us.
[00:02:46.800 --> 00:02:50.880]   Before that, we were totally and completely connected.
[00:02:50.880 --> 00:02:53.800]   And I want to return to that world.
[00:02:54.360 --> 00:02:57.040]   But bring the tools of engineering and computation to it.
[00:02:57.040 --> 00:02:57.600]   Yes.
[00:02:57.600 --> 00:02:58.160]   Yes.
[00:02:58.160 --> 00:03:04.680]   I absolutely believe that there is so much to nature that we still have not
[00:03:04.680 --> 00:03:07.400]   leveraged and we still have not understood.
[00:03:07.400 --> 00:03:13.800]   And so much of our work is design, but a lot of it is science, is unveiling and
[00:03:13.800 --> 00:03:21.440]   finding new truths about the natural world that we were not aware of before.
[00:03:22.120 --> 00:03:26.680]   Everybody talks about intelligence these days, but I like to think that nature
[00:03:26.680 --> 00:03:32.640]   has a kind of wisdom that exists beyond intelligence or above intelligence.
[00:03:32.640 --> 00:03:37.680]   And it's that wisdom that we're trying to tap into through technology.
[00:03:37.680 --> 00:03:42.800]   If you think about humans versus nature, at least in the realm, at least in the
[00:03:42.800 --> 00:03:49.720]   context of definition of nature is everything but anthropomass, and I'm
[00:03:49.720 --> 00:03:54.200]   using Ron Milo, who is an incredible professor from the Weizmann Institute
[00:03:54.200 --> 00:04:00.240]   who came up with this definition of anthropomass in 2020, when he identified
[00:04:00.240 --> 00:04:07.000]   that 2020 was the crossover year when anthropomass exceeded biomass on the planet.
[00:04:07.000 --> 00:04:12.800]   So all of the design goods that we have created and brought into the world now
[00:04:12.800 --> 00:04:18.400]   outweigh all of the biomass, including of course, all plastics and wearables,
[00:04:18.400 --> 00:04:24.920]   building cities, but also asphalt and concrete, all outweigh the scale of the
[00:04:24.920 --> 00:04:26.680]   biomass, and actually that was a moment.
[00:04:26.680 --> 00:04:31.520]   You know how in life there are moments that, maybe a handful of moments that
[00:04:31.520 --> 00:04:38.440]   get you to course correct, and it was a Zoom conversation with Ron, and that
[00:04:38.440 --> 00:04:46.120]   was a moment for me when I realized that that imbalance, now we've superseded
[00:04:46.640 --> 00:04:49.560]   the biomass on the planet, where do we go from here?
[00:04:49.560 --> 00:04:54.200]   And you've heard the expression more phones than bones and the anthropomass
[00:04:54.200 --> 00:05:00.240]   and the anthropocene and the technosphere sort of outweighing the biosphere.
[00:05:00.240 --> 00:05:08.560]   But now we are really trying to look at is there a way in which all things
[00:05:08.560 --> 00:05:14.520]   technosphere are designed as if they are part of the biosphere, meaning if you
[00:05:14.520 --> 00:05:19.560]   could today grow instead of build everything and anything, if you could
[00:05:19.560 --> 00:05:24.640]   grow an iPhone, if you could grow a car, what would that world look like?
[00:05:24.640 --> 00:05:29.920]   Where the Turing test for sort of this, this kind of, I call this material
[00:05:29.920 --> 00:05:34.000]   ecology approach, but this notion that everything material, everything that
[00:05:34.000 --> 00:05:43.720]   you design in the physical universe can be read and written to as, or thought
[00:05:43.720 --> 00:05:45.680]   of, or perceived of as nature grown.
[00:05:45.680 --> 00:05:50.080]   That's sort of the Turing test for the company, or at least that's how I started.
[00:05:50.080 --> 00:05:51.880]   I thought, well, grow everything.
[00:05:51.880 --> 00:05:52.840]   That's sort of the slogan.
[00:05:52.840 --> 00:05:54.320]   Let's grow everything.
[00:05:54.320 --> 00:06:00.880]   And if we grow everything, is there a world in which driving a car is better
[00:06:00.880 --> 00:06:04.720]   for nature than a world in which there are no cars?
[00:06:04.720 --> 00:06:11.320]   Is there, is it possible that a world in which you build buildings and cities,
[00:06:12.240 --> 00:06:15.880]   that those buildings and cities actually augment and heal nature
[00:06:15.880 --> 00:06:17.360]   as opposed to their absence?
[00:06:17.360 --> 00:06:23.640]   Is there a world in which we now go back to that kind of synergy between nature
[00:06:23.640 --> 00:06:29.560]   and humans, where you cannot separate between grown and made and it doesn't even matter?
[00:06:29.560 --> 00:06:34.080]   Is there a good term for the intersection between biomass and
[00:06:34.080 --> 00:06:36.040]   entropomass, like things that are grown?
[00:06:36.040 --> 00:06:36.760]   Yes.
[00:06:36.760 --> 00:06:40.000]   So in 2005, I called this material ecology.
[00:06:40.000 --> 00:06:45.320]   I thought, well, what if all things materials would be considered part of the
[00:06:45.320 --> 00:06:50.480]   ecology and would have an impact, a positive impact on the ecology, where we
[00:06:50.480 --> 00:06:54.000]   work together to help each other, all things nature, all things human.
[00:06:54.000 --> 00:06:58.000]   And again, you can say that that wisdom in nature exists in fungi.
[00:06:58.000 --> 00:07:03.880]   Many mushroom lovers always contest my thesis here saying, well, we have the
[00:07:03.880 --> 00:07:08.480]   mushroom network and we have the mother trees and they're all connected.
[00:07:08.560 --> 00:07:11.920]   And why don't we just simply hack into mushrooms?
[00:07:11.920 --> 00:07:16.640]   Well, first of all, yes, they're connected, but that network stops
[00:07:16.640 --> 00:07:18.080]   when there is a physical gap.
[00:07:18.080 --> 00:07:25.280]   That network does not necessarily enable the whales in the Dominican to connect
[00:07:25.280 --> 00:07:28.200]   with an olive tree in Israel, to connect with a weeping willow in Montana.
[00:07:28.200 --> 00:07:31.040]   And that's sort of a world that I'm dreaming about.
[00:07:31.040 --> 00:07:36.120]   What does it mean for nature to have access to the cloud?
[00:07:36.640 --> 00:07:40.040]   The kind of bandwidth that we're talking about, sort of think Neuralink for
[00:07:40.040 --> 00:07:48.240]   nature, you know, since the first computer, and you know this by heart
[00:07:48.240 --> 00:07:54.440]   probably better than I do, but we're both MIT lifers, we today have computational
[00:07:54.440 --> 00:07:59.720]   power that is 1 trillion times the power that we had in those times.
[00:07:59.720 --> 00:08:11.080]   We have 26.5 trillion times the bandwidth and 11.5 quintillion times
[00:08:11.080 --> 00:08:13.480]   the memory, which is incredible.
[00:08:13.480 --> 00:08:19.680]   So humankind, since the first computer has approached and accessed
[00:08:19.680 --> 00:08:21.280]   such incredible bandwidth.
[00:08:21.280 --> 00:08:24.680]   And we're asking, well, what if nature had that bandwidth?
[00:08:24.760 --> 00:08:31.240]   So beyond genes and evolution, if there was a way to augment nature and allow
[00:08:31.240 --> 00:08:35.320]   it access to the world of bits, what does nature look like now?
[00:08:35.320 --> 00:08:41.480]   And can nature make decisions for herself as opposed to being guided
[00:08:41.480 --> 00:08:45.120]   and guarded and abused by humankind?
[00:08:45.120 --> 00:08:50.200]   So nature has this inherent wisdom that you spoke to, but you're also
[00:08:50.200 --> 00:08:54.480]   referring to augmenting that inherent wisdom with something
[00:08:54.480 --> 00:08:55.800]   like a large language model.
[00:08:55.800 --> 00:08:56.800]   Exactly.
[00:08:56.800 --> 00:09:02.040]   So compress human knowledge, but also maintain whatever is that intricate
[00:09:02.040 --> 00:09:07.840]   wisdom that allows plants, bacteria, fungi to grow incredible things at
[00:09:07.840 --> 00:09:12.280]   arbitrary scales, adapting to whatever environment and just surviving and
[00:09:12.280 --> 00:09:14.360]   thriving no matter where, no matter how.
[00:09:14.360 --> 00:09:15.000]   Exactly.
[00:09:15.000 --> 00:09:19.440]   So I think of it as large molecule models and those large molecule models,
[00:09:19.960 --> 00:09:25.080]   of course, large language models are based on Google and search
[00:09:25.080 --> 00:09:26.680]   engines and so on and so forth.
[00:09:26.680 --> 00:09:30.120]   And we don't have this data currently.
[00:09:30.120 --> 00:09:32.960]   And part of our mission is to do just that.
[00:09:32.960 --> 00:09:41.480]   Trying to quantify and understand the language that exists across all
[00:09:41.480 --> 00:09:43.840]   kingdoms of life, across all five kingdoms of life.
[00:09:43.840 --> 00:09:49.640]   And if we can understand that language, is there a way for us to first make
[00:09:49.640 --> 00:09:54.440]   sense of it, find logic in it, and then generate certain computational tools
[00:09:54.440 --> 00:10:01.720]   that empower nature to build better crops, to increase the level of biodiversity.
[00:10:01.720 --> 00:10:05.680]   In the company, we're constantly asking, what does nature want?
[00:10:05.680 --> 00:10:11.720]   Like, what does nature want from a compute view?
[00:10:11.720 --> 00:10:15.520]   If it knew it, what could aid it in whatever the heck it's wanting to do?
[00:10:15.520 --> 00:10:16.040]   Yeah.
[00:10:16.080 --> 00:10:22.200]   So we keep coming back to this answer of nature wants to increase
[00:10:22.200 --> 00:10:26.600]   information, but decrease entropy, right?
[00:10:26.600 --> 00:10:30.520]   So find order, but constantly increase the information scale.
[00:10:30.520 --> 00:10:35.640]   And this is true for what our work also tries to do, because we're constantly
[00:10:35.640 --> 00:10:40.560]   trying to fight against the dimensional mismatch between things made and things
[00:10:40.560 --> 00:10:41.520]   grown, right?
[00:10:41.600 --> 00:10:45.680]   And as designers, we are educated to think in X, Y, and Z, and that's pretty
[00:10:45.680 --> 00:10:50.560]   much where architectural education ends and biological education begins.
[00:10:50.560 --> 00:10:54.600]   So in reducing that dimensional mismatch, we're missing out on opportunities
[00:10:54.600 --> 00:10:56.120]   to create things made as if grown.
[00:10:56.120 --> 00:11:01.120]   But in the natural environment, we're asking, can we provide nature
[00:11:01.120 --> 00:11:02.960]   with these extra dimensions?
[00:11:02.960 --> 00:11:10.120]   And again, I'm not sure what nature wants, but I'm curious as to what happens
[00:11:10.120 --> 00:11:13.520]   when you provide these tools to the natural environments, obviously with
[00:11:13.520 --> 00:11:18.560]   responsibility, obviously with control, obviously with ethics and moral code.
[00:11:18.560 --> 00:11:25.840]   But is there a world in which nature can help fix itself using those tools?
[00:11:25.840 --> 00:11:29.960]   And by the way, we're talking about a company called Oxman.
[00:11:29.960 --> 00:11:30.480]   Yeah.
[00:11:30.480 --> 00:11:32.720]   I'll just, just a few words about the team.
[00:11:32.720 --> 00:11:33.080]   Yeah.
[00:11:33.080 --> 00:11:36.200]   What kind of humans work at a place like this that are trying to
[00:11:36.200 --> 00:11:37.160]   figure out what nature wants?
[00:11:37.160 --> 00:11:38.960]   You know, I think they're first like you.
[00:11:38.960 --> 00:11:40.640]   They're, they're humanists first.
[00:11:40.640 --> 00:11:45.920]   They come from different disciplines and different disciplinary backgrounds.
[00:11:45.920 --> 00:11:50.800]   And just as an example, we have a brilliant designer who is just a
[00:11:50.800 --> 00:11:55.000]   mathematical genius and a computer scientist and a mechanical engineer
[00:11:55.000 --> 00:11:59.120]   who is trained as a synthetic biologist.
[00:11:59.120 --> 00:12:06.320]   And, and now we're hiring a microbiologist and a chemist, architects, of course,
[00:12:06.320 --> 00:12:08.840]   and designers, a roboticist.
[00:12:08.840 --> 00:12:12.280]   So it's really, it's Noah's Ark, right?
[00:12:12.280 --> 00:12:12.920]   Two of each.
[00:12:12.920 --> 00:12:16.760]   And always dancing between this line of the artificial, the
[00:12:16.760 --> 00:12:18.520]   synthetic and the, and the real.
[00:12:18.520 --> 00:12:20.720]   What's the term for, and the natural.
[00:12:20.720 --> 00:12:21.120]   Yeah.
[00:12:21.120 --> 00:12:25.000]   The built and the grown, nature and culture, technology and biology.
[00:12:25.000 --> 00:12:30.120]   But we're, we're, we're constantly seeking to, to ask how can we build,
[00:12:30.120 --> 00:12:36.080]   design and deploy products in three scales, the molecular scale, which
[00:12:36.080 --> 00:12:41.640]   I briefly hinted to, and there, and the molecular scale, we're really
[00:12:41.640 --> 00:12:46.480]   looking to understand whether there is a universal language to nature
[00:12:46.480 --> 00:12:52.760]   and what that language is, and then build, build a tool that I think and
[00:12:52.760 --> 00:12:54.480]   dream of it as the iPhone for nature.
[00:12:54.480 --> 00:12:59.440]   If nature had an iPhone, what would that iPhone look like?
[00:12:59.440 --> 00:13:02.760]   Does that mean creating an interface?
[00:13:02.760 --> 00:13:04.000]   Yeah.
[00:13:04.000 --> 00:13:06.920]   Between nature and the computational tools we have.
[00:13:06.920 --> 00:13:07.520]   Exactly.
[00:13:07.520 --> 00:13:12.200]   It goes back to that 11.5 quintillion times the bandwidth that, that humans
[00:13:12.200 --> 00:13:16.880]   have, have, have now arrived at and, and giving that to nature and seeing
[00:13:16.880 --> 00:13:18.600]   what, you know, what, what happens there.
[00:13:18.600 --> 00:13:25.160]   Can animals actually use this interface to know that they need to run away from fire?
[00:13:25.160 --> 00:13:29.040]   Can plants use this interface to increase the rate of photosynthesis
[00:13:29.040 --> 00:13:31.120]   in the presence of a smoke cloud?
[00:13:31.600 --> 00:13:35.240]   Can they do this quote unquote automatically without a kind of a top
[00:13:35.240 --> 00:13:42.040]   down brute force policy based method that's authored and deployed by humans?
[00:13:42.040 --> 00:13:45.440]   And so this work really relates to that interface with the natural world.
[00:13:45.440 --> 00:13:50.760]   And then there's a second area in the company, which focuses on growing products.
[00:13:50.760 --> 00:13:56.880]   And here we're focusing on a single product that starts from CO2.
[00:13:56.880 --> 00:14:01.480]   It becomes a product it's consumed, it's used, it's worn.
[00:14:01.800 --> 00:14:02.920]   By a human.
[00:14:02.920 --> 00:14:09.920]   And then it, goes back to the soil and it grows an edible fruit plant.
[00:14:09.920 --> 00:14:12.480]   So we're talking about from CO2 to fruit.
[00:14:12.480 --> 00:14:13.160]   Yeah.
[00:14:13.160 --> 00:14:16.960]   It starts from CO2 and it ends with something that you can like literally eat.
[00:14:16.960 --> 00:14:23.920]   So, so the world's first, entirely biodegradable, biocompatible, biorenewable product.
[00:14:23.920 --> 00:14:24.960]   That's grown.
[00:14:24.960 --> 00:14:25.960]   Yes.
[00:14:25.960 --> 00:14:28.880]   Either using plant matter or using bacteria.
[00:14:29.240 --> 00:14:34.320]   But we are really looking at carbon recycling technologies that start with methane or
[00:14:34.320 --> 00:14:35.240]   wastewater.
[00:14:35.240 --> 00:14:43.600]   And end with this wonderful reincarnation of a, a thing that doesn't need to end up in a
[00:14:43.600 --> 00:14:49.040]   composting site, but can just be thrown into the ground and grow olive and find peace.
[00:14:49.040 --> 00:14:54.560]   And there's a lot of textile based work out there that is focused on one single element in
[00:14:54.560 --> 00:15:00.920]   this long chain, like, oh, let's create, you know, leather out of mycelium or, or let's
[00:15:00.920 --> 00:15:03.200]   create textile out of cellulose.
[00:15:03.200 --> 00:15:08.000]   But then it stops there and you get to assembling the shoe or the wearable and you,
[00:15:08.000 --> 00:15:11.760]   and you, you need a little bit of glue and you need a little bit of this material and a
[00:15:11.760 --> 00:15:14.960]   little bit of that material to, to make it water resistant.
[00:15:14.960 --> 00:15:15.800]   And then it's over.
[00:15:15.800 --> 00:15:21.520]   So that's one thing that we're trying to solve for is how to create a product that is
[00:15:21.520 --> 00:15:27.920]   materially, computationally, robotically novel and goes through all of these phases from
[00:15:27.920 --> 00:15:34.640]   the creation, from this carbon recycling technology to, to the product to literally
[00:15:34.640 --> 00:15:40.920]   how do you think about, you know, reinventing an industry that is focused on assembly and
[00:15:40.920 --> 00:15:44.160]   putting things together and using humans to do that.
[00:15:44.160 --> 00:15:48.760]   Can that, you know, can that happen just using robots and microbes and that's it.
[00:15:48.760 --> 00:15:49.920]   And doing it end to end.
[00:15:50.040 --> 00:15:53.160]   I would love to see what this factory looks like.
[00:15:53.160 --> 00:15:55.560]   And the factory is great too.
[00:15:55.560 --> 00:15:57.000]   I'm, I'm very, very excited.
[00:15:57.000 --> 00:16:02.840]   In October, we'll, we'll share first, first renditions of, of, of some of this work.
[00:16:02.840 --> 00:16:05.240]   And in February, we'll, we'll invite you to the lab.
[00:16:05.240 --> 00:16:06.120]   I'm there.
[00:16:06.120 --> 00:16:08.440]   I've already applied.
[00:16:08.440 --> 00:16:09.440]   I can't, I haven't heard back.
[00:16:09.440 --> 00:16:10.160]   I don't understand.
[00:16:10.160 --> 00:16:11.160]   Okay.
[00:16:11.160 --> 00:16:16.160]   I mean, it's just before we get to number three, it'd be amazing to just talk about
[00:16:16.160 --> 00:16:21.920]   what it takes with robotic arms or in general, the whole process of how to build the life
[00:16:21.920 --> 00:16:25.800]   form, stuff you've done in the past, maybe stuff you're doing now, how to use bacteria,
[00:16:25.800 --> 00:16:30.440]   it's kind of synthetic biology, how to grow stuff by leveraging bacteria.
[00:16:30.440 --> 00:16:31.720]   Is there examples from the past?
[00:16:31.720 --> 00:16:32.520]   Yes.
[00:16:32.520 --> 00:16:37.000]   And just take a step back over the 10 years, the Mediated Matter Group, which was my
[00:16:37.000 --> 00:16:44.800]   group at MIT, has sort of dedicated itself to, bio-based design would be a suitcase
[00:16:44.800 --> 00:16:49.600]   word, but sort of thinking about that synergy between nature and culture, biology
[00:16:49.600 --> 00:16:55.200]   and technology, and we attempted to build a suite of embodiments, let's say, that
[00:16:55.200 --> 00:17:00.400]   they ended up in amazing museums and amazing shows and, and we wrote patents
[00:17:00.400 --> 00:17:03.840]   and papers on them, but they were still N of ones.
[00:17:03.840 --> 00:17:09.000]   Again, the challenge, as you say, was to grow them and we classified them into
[00:17:09.000 --> 00:17:12.880]   fibers, cellular solids, biopolymers, pigments.
[00:17:13.280 --> 00:17:16.760]   And in each of the examples, although the material was different, sometimes we used
[00:17:16.760 --> 00:17:21.120]   fibers, sometimes we used silk with silkworms and honey with bees and, or comb
[00:17:21.120 --> 00:17:26.320]   as the structural material, with vespers we used synthetically engineered bacteria
[00:17:26.320 --> 00:17:30.720]   to produce pigments, although the materials were different and the hero organisms
[00:17:30.720 --> 00:17:32.640]   were different, the philosophy was always the same.
[00:17:32.640 --> 00:17:36.520]   The approach was really an approach of computational templating.
[00:17:36.520 --> 00:17:41.720]   That templating allowed us to create templates for the natural environment
[00:17:41.720 --> 00:17:48.320]   where nature and technology could duet, could dance together to create these
[00:17:48.320 --> 00:17:48.680]   products.
[00:17:48.680 --> 00:17:54.080]   So just as a few examples with a silk pavilion, we've had a couple of pavilions
[00:17:54.080 --> 00:17:59.000]   made of silk and the second one, which was the bigger one, which ended up at the
[00:17:59.000 --> 00:18:04.320]   Museum of Modern Art with my friend and incredible mentor, Paolo Antonelli, that
[00:18:04.320 --> 00:18:08.920]   pavilion was six meter tall and it was produced by silkworms.
[00:18:08.960 --> 00:18:12.600]   And there we had different types of templates.
[00:18:12.600 --> 00:18:16.720]   There were physical templates that were basically just these water soluble meshes
[00:18:16.720 --> 00:18:19.080]   upon which the silkworms were spinning.
[00:18:19.080 --> 00:18:22.920]   And then there were environmental templates, which was a robot basically
[00:18:22.920 --> 00:18:27.880]   applying a variation of environmental conditions, such as heat and light to
[00:18:27.880 --> 00:18:29.240]   guide the movement of the silkworm.
[00:18:29.240 --> 00:18:32.360]   - You're saying so many amazing things and I'm trying not to interrupt you, but
[00:18:32.360 --> 00:18:37.480]   like one of the things you've learned by observing, by doing science on these is
[00:18:37.800 --> 00:18:43.240]   that the environment defines the shape that they create or contributes or
[00:18:43.240 --> 00:18:44.960]   intricately plays with the shape they create.
[00:18:44.960 --> 00:18:48.800]   And so like, and you get to, that's one of the ways you can get to guide their
[00:18:48.800 --> 00:18:51.680]   work is by defining that environment.
[00:18:51.680 --> 00:18:54.800]   By the way, you said hero organism, which is an epic term.
[00:18:54.800 --> 00:19:00.160]   That means like, is whatever is the biological living system that's doing the
[00:19:00.160 --> 00:19:00.760]   creation.
[00:19:00.760 --> 00:19:03.760]   - And that's what's happening in pharma and biomaterials.
[00:19:03.760 --> 00:19:08.760]   And by the way, precision ag and food, new food design technologies as people are
[00:19:08.760 --> 00:19:12.680]   betting on a hero organism is the sort of how I think of it.
[00:19:12.680 --> 00:19:19.920]   And the hero organism is sometimes it's the palm oil or it's the mycelium.
[00:19:19.920 --> 00:19:26.160]   There's a lot of mushrooms around for good and bad and it's cellulose or it's,
[00:19:26.160 --> 00:19:29.640]   you know, fake bananas or the workhorse E.coli.
[00:19:29.840 --> 00:19:36.480]   But these hero organisms are being betted on as like the, what's the one answer
[00:19:36.480 --> 00:19:37.440]   that solves everything?
[00:19:37.440 --> 00:19:38.600]   Hitchhiker's Guide?
[00:19:38.600 --> 00:19:39.200]   - 42.
[00:19:39.200 --> 00:19:39.720]   - 42.
[00:19:39.720 --> 00:19:40.040]   - Yeah.
[00:19:40.040 --> 00:19:44.440]   - These are sort of the 42s of, you know, of the enchanted new universe.
[00:19:44.440 --> 00:19:51.640]   And back at MIT, we said, instead of betting on all of these organisms, let's
[00:19:51.640 --> 00:19:54.280]   approach them as almost like movement in a symphony.
[00:19:54.280 --> 00:19:59.400]   And let's kind of lean into what we can learn from each of these organisms in the
[00:19:59.400 --> 00:20:03.280]   context of building a project in an architectural scale.
[00:20:03.280 --> 00:20:04.960]   And those usually were pavilions.
[00:20:04.960 --> 00:20:10.880]   - And then the computational templating is the way you guide the work of this.
[00:20:10.880 --> 00:20:11.880]   How many did you say?
[00:20:11.880 --> 00:20:12.720]   17,000?
[00:20:12.720 --> 00:20:15.040]   - 17,532.
[00:20:15.040 --> 00:20:20.880]   So each of these silkworms threads are about, you know, one mile in distance.
[00:20:20.880 --> 00:20:22.680]   And they're beautiful.
[00:20:22.680 --> 00:20:28.080]   And just thinking about the amount of material, you know, it's a bit like
[00:20:28.080 --> 00:20:34.400]   thinking about the, you know, the length of capillary vessels that grow in your
[00:20:34.400 --> 00:20:38.160]   belly when you're pregnant to feed that incredible new life form.
[00:20:38.160 --> 00:20:40.720]   It's just, nature is amazing.
[00:20:40.720 --> 00:20:46.080]   But back to the silkworms, I think I had three months to build this incredible
[00:20:46.080 --> 00:20:52.200]   pavilion, but we couldn't figure out how, we were thinking of emulating the process
[00:20:52.200 --> 00:20:56.400]   of how a silkworm goes about building its incredible architecture, this cocoon over
[00:20:56.400 --> 00:20:58.840]   the period of 24 to 72 hours.
[00:20:58.840 --> 00:21:03.000]   And it builds a cocoon basically to protect itself.
[00:21:03.000 --> 00:21:08.920]   It's a beautiful form of architecture and it uses pretty much just two materials, two
[00:21:08.920 --> 00:21:11.760]   chemical compounds, sericin and fibrin.
[00:21:11.760 --> 00:21:14.760]   The sericin is sort of the glue of the cocoon.
[00:21:14.760 --> 00:21:19.040]   The fibrin is the fiber-based material of the cocoon and through fibers and glue,
[00:21:19.040 --> 00:21:22.560]   and that's true for so many systems in nature, lots of fiber and glue.
[00:21:23.080 --> 00:21:26.840]   And that architecture allows them to metamorphosize.
[00:21:26.840 --> 00:21:31.320]   And in the process, they vary the properties of that silk thread.
[00:21:31.320 --> 00:21:36.480]   So it's stiffer or softer depending on where it is in the section of the cocoon.
[00:21:36.480 --> 00:21:42.560]   And so we were trying to emulate this robotically with a 3D printer that was a
[00:21:42.560 --> 00:21:45.800]   six-axis kooka arm, one of these baby kookas.
[00:21:45.800 --> 00:21:49.000]   And we're trying to emulate that process computationally and build something very
[00:21:49.000 --> 00:21:53.840]   large when one of my students now, a brilliant industrial engineer, a
[00:21:53.840 --> 00:21:58.800]   roboticist on my team, Marcus, said, "Well, you know, we were just playing with
[00:21:58.800 --> 00:22:04.040]   those silkworms and enjoying their presence when we realized that if they're
[00:22:04.040 --> 00:22:11.600]   placed on a desk or a horizontal surface, they will go about creating their cocoon.
[00:22:11.600 --> 00:22:13.960]   Only the cocoon would be flat."
[00:22:15.560 --> 00:22:20.280]   Because they're constantly looking for a vertical post in order to use that
[00:22:20.280 --> 00:22:23.160]   post as an anchor to spin the cocoon.
[00:22:23.160 --> 00:22:29.200]   But in the absence of that post, on surfaces that are less than 21
[00:22:29.200 --> 00:22:33.240]   millimeters and flat, they will spin flat patches.
[00:22:33.240 --> 00:22:41.480]   And we say, "Aha, let's work with them to produce this dome as a set of flat
[00:22:41.480 --> 00:22:47.000]   patches." And a silkworm, mind you, is quite an egocentric creature.
[00:22:47.000 --> 00:22:52.240]   And actually, the furthest you go, you move forward in evolution by natural
[00:22:52.240 --> 00:22:57.720]   selection, the more egoism you find in creatures.
[00:22:57.720 --> 00:23:04.400]   So when you think about termites, right, their material sophistication is
[00:23:04.400 --> 00:23:08.960]   actually very primitive, but they have incredible ability to communicate and
[00:23:08.960 --> 00:23:09.720]   connect with each other.
[00:23:09.720 --> 00:23:14.000]   So if you think about the entire, all of nature, let's say all of living
[00:23:14.000 --> 00:23:19.240]   systems as like a matrix that runs across two axes, one is material
[00:23:19.240 --> 00:23:22.960]   sophistication, which is terribly irrelevant for designers, and the other
[00:23:22.960 --> 00:23:23.920]   is communication.
[00:23:23.920 --> 00:23:30.840]   The termites ace on communication, but their material sophistication is crap,
[00:23:30.840 --> 00:23:31.120]   right?
[00:23:31.120 --> 00:23:36.040]   It's just saliva and feces and some soil particles that are built to create
[00:23:36.040 --> 00:23:40.200]   these incredible termite mounds at the scale that, when compared to human
[00:23:40.200 --> 00:23:46.280]   skyscrapers, transcend all of buildable scales, at least in terms of what we
[00:23:46.280 --> 00:23:49.440]   have today in architectural practice, just relative to the size of the
[00:23:49.440 --> 00:23:49.880]   termite.
[00:23:49.880 --> 00:23:54.520]   But when you look at the silkworm, the silkworm has zero connection and
[00:23:54.520 --> 00:23:56.400]   communication across silkworms.
[00:23:56.400 --> 00:23:59.040]   They were not designed to connect and communicate with each other.
[00:23:59.040 --> 00:24:05.560]   They're sort of a human-designed species because the domesticated silk
[00:24:05.560 --> 00:24:07.680]   moth creates the cocoon.
[00:24:07.680 --> 00:24:11.400]   We then produce the silk of it and then it dies.
[00:24:11.400 --> 00:24:14.320]   So it has dysfunctional wings.
[00:24:14.320 --> 00:24:15.160]   It cannot fly.
[00:24:15.160 --> 00:24:22.600]   It's not, so, and that's another problem that the sericulture industry has is
[00:24:22.600 --> 00:24:27.720]   why did we in the first place author this organism 4,000 years ago that is
[00:24:27.720 --> 00:24:35.520]   unable to fly and is just there to basically live as, to serve a human
[00:24:35.520 --> 00:24:36.760]   need, which is textiles.
[00:24:36.760 --> 00:24:41.680]   And so here we were fascinated by the computational kind of biology
[00:24:41.680 --> 00:24:45.880]   dimension of silkworms, but along the way, by the way, this is great.
[00:24:45.880 --> 00:24:47.360]   I never get to tell the full story.
[00:24:47.360 --> 00:24:48.000]   I'm so great.
[00:24:48.000 --> 00:24:49.360]   I'm enjoying this so much.
[00:24:49.360 --> 00:24:53.440]   I always, I'm always, like people say, I always speak in Nietzschean
[00:24:53.440 --> 00:24:56.000]   paragraphs, they're way too long and this is wonderful.
[00:24:56.000 --> 00:24:56.760]   This is like heaven.
[00:24:56.760 --> 00:24:57.760]   Nietzschean paragraphs.
[00:24:57.760 --> 00:25:00.480]   You drop me so many good lines.
[00:25:00.480 --> 00:25:00.840]   I love it.
[00:25:00.840 --> 00:25:01.280]   Okay.
[00:25:01.280 --> 00:25:05.480]   But, but, but really those, those silkworms are not, yes, they're not
[00:25:05.480 --> 00:25:07.680]   designed to be like humans, right?
[00:25:07.680 --> 00:25:10.360]   They're not designed to connect, communicate and build things that are
[00:25:10.360 --> 00:25:13.320]   bigger than themselves through connection and communication.
[00:25:13.320 --> 00:25:16.640]   So what happens when you had 17,000 of them communicating effectively?
[00:25:16.640 --> 00:25:18.320]   That's a really great question.
[00:25:18.320 --> 00:25:25.080]   What happens is that at some point the templating strategies, and as you said
[00:25:25.080 --> 00:25:28.840]   correctly, there were geometrical templating, material templating,
[00:25:28.840 --> 00:25:32.160]   environmental templating, chemical templating, if you're using pheromones
[00:25:32.160 --> 00:25:36.520]   to guide the movement of bees in the absence of a queen, where you have a
[00:25:36.520 --> 00:25:42.680]   robotic queen, but whenever you have these templating strategies, you have
[00:25:42.680 --> 00:25:44.960]   sort of control over nature, right?
[00:25:44.960 --> 00:25:48.680]   But the question is, is there a world in which we can move from templating,
[00:25:48.680 --> 00:25:54.080]   from providing these computational material and immaterial, physical and
[00:25:54.080 --> 00:25:59.200]   molecular platforms that guide nature, almost guiding a product, almost like a
[00:25:59.200 --> 00:26:04.800]   gardener, to a problem or an opportunity of emergence where that biological
[00:26:04.800 --> 00:26:11.440]   organism assumes agency by virtue of accessing the robotic code and saying,
[00:26:11.440 --> 00:26:14.880]   now I own the code, I get to do what I want with this code.
[00:26:14.880 --> 00:26:18.280]   Let me show you what this pavilion may look like, or this product may look like.
[00:26:18.280 --> 00:26:23.040]   And I think one of the exciting moments for us is when we realized that these
[00:26:23.040 --> 00:26:28.960]   robotic platforms that were designed initially as templates actually inspired,
[00:26:28.960 --> 00:26:35.720]   if I may, a kind of a collaboration and cooperation between silkworms that
[00:26:35.720 --> 00:26:38.760]   are not a swarm-based organism.
[00:26:38.760 --> 00:26:40.480]   They're not like the bees and the termites.
[00:26:40.480 --> 00:26:45.320]   They don't work together and they don't have, you know, social orders amongst
[00:26:45.320 --> 00:26:47.240]   them, the queen and the drones, et cetera.
[00:26:47.240 --> 00:26:51.120]   They're all the same in a way, right?
[00:26:51.160 --> 00:26:56.000]   And here, what was so exciting for us is that these computational and
[00:26:56.000 --> 00:27:03.600]   fabrication technologies enable the silkworm to sort of, to kind of hop from
[00:27:03.600 --> 00:27:09.440]   the branch in ecology of worms to the branch in ecology of maybe human-like
[00:27:09.440 --> 00:27:14.600]   intelligence, where they could connect and communicate by virtue of, you know,
[00:27:14.600 --> 00:27:19.040]   feeling or rubbing against each other in an area that was hotter or colder.
[00:27:19.320 --> 00:27:23.560]   And they were, so the product that we got at the end, the variation of density of
[00:27:23.560 --> 00:27:29.120]   fiber and the distribution of the fiber and the transparency, the product at the
[00:27:29.120 --> 00:27:35.280]   end seems like it was produced by a swarm silk community, but of course it wasn't.
[00:27:35.280 --> 00:27:38.960]   It's a bunch of biological agents working together to assemble this thing.
[00:27:38.960 --> 00:27:40.960]   That's really, really fascinating to us.
[00:27:40.960 --> 00:27:50.120]   How can technology augment or enable a swarm-like behavior in creatures that
[00:27:50.120 --> 00:27:53.600]   have not been designed to work as swarms?
[00:27:53.600 --> 00:28:00.960]   So how do you construct a computational template from which a certain kind of
[00:28:00.960 --> 00:28:01.760]   thing emerges?
[00:28:01.760 --> 00:28:04.840]   So how can you predict what emerges, I suppose?
[00:28:04.840 --> 00:28:09.320]   So if you can predict it, it doesn't count as emergence.
[00:28:09.360 --> 00:28:11.000]   Actually, I think...
[00:28:11.000 --> 00:28:13.480]   That's a deeply poetic line.
[00:28:13.480 --> 00:28:14.720]   We can talk about it.
[00:28:14.720 --> 00:28:15.480]   I mean...
[00:28:15.480 --> 00:28:17.800]   It's a bit like if you measure it, it doesn't count.
[00:28:17.800 --> 00:28:19.080]   Right, right.
[00:28:19.080 --> 00:28:26.880]   Speaking of emergence and empowerment, because we're constantly moving between
[00:28:26.880 --> 00:28:29.640]   those as if they're equals on the team.
[00:28:29.640 --> 00:28:35.200]   And one of them, Christoph, shared with me a mathematical equation for what does it
[00:28:35.200 --> 00:28:39.440]   mean to empower nature and what does empowerment in nature look like?
[00:28:39.440 --> 00:28:44.920]   And that relates to emergence and we can go back to emergence in a few moments,
[00:28:44.920 --> 00:28:48.800]   but I want to say it so that I know that I've learned it.
[00:28:48.800 --> 00:28:53.400]   And if I've learned it, I can use it later.
[00:28:53.400 --> 00:28:53.720]   Yeah.
[00:28:53.720 --> 00:28:56.760]   And maybe you'll figure something out as you say it also.
[00:28:56.760 --> 00:29:03.080]   Of course Christoph is the master here, but really we were thinking, again,
[00:29:03.080 --> 00:29:04.000]   what does nature want?
[00:29:04.000 --> 00:29:10.480]   Nature wants to increase the information dimension and reduce entropy.
[00:29:10.480 --> 00:29:12.480]   What do we want?
[00:29:12.480 --> 00:29:14.400]   We kind of want the same thing.
[00:29:14.400 --> 00:29:18.560]   We want more, but we want order, right?
[00:29:18.560 --> 00:29:23.720]   And this goes back to your conversation with Yosha about stochastic versus
[00:29:23.720 --> 00:29:25.760]   deterministic languages or processes.
[00:29:26.400 --> 00:29:36.520]   His definition or the definition he found was that an agent is empowered if the
[00:29:36.520 --> 00:29:43.560]   entropy of the distribution of all of its states is high, while the entropy of the
[00:29:43.560 --> 00:29:49.360]   distribution of a single state given a choice, given an action is low.
[00:29:49.920 --> 00:29:57.800]   Meaning it's that kind of duality between opportunity, like starting like this and
[00:29:57.800 --> 00:29:59.840]   going like this, opening and closing.
[00:29:59.840 --> 00:30:04.080]   And this really, I think, is analogous to human empowerment.
[00:30:04.080 --> 00:30:14.200]   Given an infinite, wide array of choices, what is the choice that you make to enable,
[00:30:14.200 --> 00:30:18.640]   to empower, to provide you with the agency that you need?
[00:30:18.960 --> 00:30:23.120]   - And how much does that, making that choice actually control the trajectory
[00:30:23.120 --> 00:30:23.720]   of the system?
[00:30:23.720 --> 00:30:24.480]   That's really nice.
[00:30:24.480 --> 00:30:27.840]   So this applies to all the kinds of systems you're talking about.
[00:30:27.840 --> 00:30:28.400]   - Yeah.
[00:30:28.400 --> 00:30:34.240]   And the cool thing is it can apply to a human on an individual basis, but, or a
[00:30:34.240 --> 00:30:41.880]   silkworm or a bee or a microbe, a microbe that has agency or by virtue of a template.
[00:30:41.880 --> 00:30:46.000]   But it also applies to a community of organisms like the bees.
[00:30:46.520 --> 00:30:50.520]   And so we've done a lot of work sort of moving from, you've asked how to grow
[00:30:50.520 --> 00:30:57.880]   things, so we've grown things using co-fabrication where we're digitally
[00:30:57.880 --> 00:31:03.360]   fabricating with other organisms that live across the various kingdoms of life.
[00:31:03.360 --> 00:31:06.480]   And those were silkworms and bees.
[00:31:06.480 --> 00:31:12.800]   And with bees, which we've sent to outer space and returned healthily
[00:31:12.800 --> 00:31:14.640]   and they were reproductive.
[00:31:14.640 --> 00:31:15.960]   - Okay, you're going to have to tell that story.
[00:31:16.040 --> 00:31:18.640]   You're going to have to talk about the robotic queen and the pheromones.
[00:31:18.640 --> 00:31:19.040]   Come on.
[00:31:19.040 --> 00:31:24.880]   - So we've built what we call a synthetic apiary and the synthetic apiary was
[00:31:24.880 --> 00:31:31.440]   designed as an environment that was a perpetual spring environment for the bees
[00:31:31.440 --> 00:31:32.400]   of Massachusetts.
[00:31:32.400 --> 00:31:35.640]   They go in hibernation, of course, during the winter season.
[00:31:35.640 --> 00:31:39.560]   And then we lose 80% of them or more during that period.
[00:31:39.560 --> 00:31:45.120]   We're thinking, okay, what if we created this environment where before you
[00:31:45.120 --> 00:31:49.680]   template, right, before you can design with, you have to design for, right?
[00:31:49.680 --> 00:31:55.080]   You have to create this space of mutualism, space of sort of shared
[00:31:55.080 --> 00:31:57.840]   connection between you and the organism.
[00:31:57.840 --> 00:32:00.200]   And with bees, it started as the synthetic apiary.
[00:32:00.200 --> 00:32:06.520]   And we have proven that that curated environment where we designed the space
[00:32:06.520 --> 00:32:11.920]   with high levels of control of temperature, humidity, and light, and we've
[00:32:11.920 --> 00:32:16.280]   proven that they were reproductive and alive and we realized, wow, this
[00:32:16.280 --> 00:32:22.960]   environment that we created can help augment bees in the winter season in any
[00:32:22.960 --> 00:32:28.560]   city around the world where bees survive and thrive in the summer and spring
[00:32:28.560 --> 00:32:32.840]   seasons, and could this be a kind of a new urban typology, an architectural
[00:32:32.840 --> 00:32:37.440]   typology of symbiosis, of mutualism between organisms and humans where these
[00:32:37.640 --> 00:32:42.200]   By the way, the synthetic apiary was in a co-op in, you know, nearby Somerville.
[00:32:42.200 --> 00:32:47.400]   We had, you know, we had robots, our team, you know, schlepped there every day
[00:32:47.400 --> 00:32:51.320]   with our, with our tools and machines and we made it happen and the neighbors
[00:32:51.320 --> 00:32:54.880]   were very happy and they got to get a ton of honey at the end of the winter.
[00:32:54.880 --> 00:32:59.160]   And those bees, of course, were released into the wild at the end
[00:32:59.160 --> 00:33:00.600]   of the winter, alive and kicking.
[00:33:00.920 --> 00:33:08.160]   So then in order to actually experiment with the robotic queen idea or concept,
[00:33:08.160 --> 00:33:13.640]   we had to prove obviously that we can create this space for bees.
[00:33:13.640 --> 00:33:18.320]   And then after that, we had this amazing opportunity to send the bees to space
[00:33:18.320 --> 00:33:23.120]   on Blue Shepard mission that is part of Blue Origin and we of course said,
[00:33:23.120 --> 00:33:24.320]   yes, we'll take a slot.
[00:33:24.320 --> 00:33:26.440]   We said, okay, can we outdo NASA?
[00:33:26.440 --> 00:33:32.040]   So NASA in 1982 had an experiment where they sent bees to outer space.
[00:33:32.040 --> 00:33:38.720]   The bees returned, they were not reproductive and some of them died.
[00:33:38.720 --> 00:33:43.600]   And we thought, well, is there a way in which we can create a life support
[00:33:43.600 --> 00:33:49.880]   system, almost like a small mini biolab of a queen and her retinue that would be
[00:33:49.880 --> 00:33:55.960]   sent in this Blue Origin New Shepard mission in this one cell and so that's,
[00:33:56.000 --> 00:33:59.440]   if the synthetic apiary was an architectural project, in this case,
[00:33:59.440 --> 00:34:02.120]   this second synthetic apiary was a product.
[00:34:02.120 --> 00:34:03.000]   It was right.
[00:34:03.000 --> 00:34:07.840]   So from an architectural controlled environment to a product scale
[00:34:07.840 --> 00:34:08.560]   controlled environment.
[00:34:08.560 --> 00:34:15.160]   And this biolab, this life support system for bees was designed to provide the bees
[00:34:15.160 --> 00:34:17.760]   with all the conditions that they needed.
[00:34:17.760 --> 00:34:23.760]   And we looked at that time at the Nassanove pheromone that the queen uses
[00:34:24.280 --> 00:34:29.000]   to guide the other bees and we looked at pheromones that are associated with a bee
[00:34:29.000 --> 00:34:33.320]   and thinking of those pheromones being released inside the capsules that go,
[00:34:33.320 --> 00:34:35.000]   the capsule that goes to outer space.
[00:34:35.000 --> 00:34:42.240]   They returned back to our, the Media Lab roof and those bees were alive and
[00:34:42.240 --> 00:34:48.760]   kicking and reproductive and, you know, and they continued to create comb and it
[00:34:48.760 --> 00:34:53.800]   ended with a beautiful nature paper that the team and I published together.
[00:34:54.360 --> 00:34:58.640]   We gave them gold nanoparticles and silver nanoparticles because we were
[00:34:58.640 --> 00:35:01.240]   interested if bees recycle wax.
[00:35:01.240 --> 00:35:07.680]   It was known forever that bees do not recycle the wax and by feeding them these
[00:35:07.680 --> 00:35:14.400]   gold nanoparticles, we were able to prove that the bees actually do recycle the wax.
[00:35:14.400 --> 00:35:20.280]   The reason I'm bringing this forward is because we don't view ourselves as
[00:35:20.640 --> 00:35:26.360]   designers of consumable products and architectural environments only, but we
[00:35:26.360 --> 00:35:30.480]   love that moment where these technologies and by the way, every one of these
[00:35:30.480 --> 00:35:35.640]   projects that we created involved the creation of a new technology, whether it
[00:35:35.640 --> 00:35:43.040]   be a glass printer or the spinning robot or the life support system for the bee
[00:35:43.040 --> 00:35:47.720]   colony, they all involved a technology that was associated with the project.
[00:35:47.720 --> 00:35:51.600]   And I never, ever, ever, ever want to let that part go because I love, love
[00:35:51.600 --> 00:35:52.680]   technology so much.
[00:35:52.680 --> 00:35:59.480]   But also another element of this is it always, these projects, if they're great,
[00:35:59.480 --> 00:36:05.960]   they reveal new knowledge about, or new science about the topic that you're
[00:36:05.960 --> 00:36:11.400]   investigating, be it, you know, silkworms or bees or glass.
[00:36:11.400 --> 00:36:15.360]   That's why I say, I always tell my team, it should be at MoMA and the cover of
[00:36:15.360 --> 00:36:16.920]   Nature or Science at the same time.
[00:36:16.920 --> 00:36:19.040]   We don't separate between the art and the science.
[00:36:19.040 --> 00:36:20.760]   It's, it's, it's, it's one of the same.
[00:36:20.760 --> 00:36:24.600]   So as you're creating the art, you're going to learn something about these
[00:36:24.600 --> 00:36:26.600]   organisms or something about these materials.
[00:36:26.600 --> 00:36:30.040]   I mean, is there something that stands out to you about these hero organisms
[00:36:30.040 --> 00:36:32.440]   like bees, silkworms, you mentioned E.
[00:36:32.440 --> 00:36:35.480]   coli has its pros and cons, this bacteria.
[00:36:35.480 --> 00:36:41.040]   What have you learned that small or big that's interesting about these organisms?
[00:36:41.040 --> 00:36:43.680]   Yeah, that's a beautiful question.
[00:36:43.680 --> 00:36:45.160]   What have I learned?
[00:36:45.200 --> 00:36:51.320]   I've learned that, you know, we did, we also worked with shrimp shells with
[00:36:51.320 --> 00:36:56.680]   Agroxa, we built this tower on the roof of SF MoMA, which by a couple of months
[00:36:56.680 --> 00:37:01.240]   ago, and until it was on the roof, we we've shown the structure completely
[00:37:01.240 --> 00:37:04.560]   biodegrade into then, well, not completely, but almost completely
[00:37:04.560 --> 00:37:06.680]   biodegrade to the soil.
[00:37:06.680 --> 00:37:14.320]   And, and this notion that a product or part, an organism or part of that
[00:37:14.320 --> 00:37:21.400]   organism can reincarnate is very, very moving thought to me, because I want
[00:37:21.400 --> 00:37:23.400]   to believe that I believe in reincarnation.
[00:37:23.400 --> 00:37:25.720]   I want to believe that I believe.
[00:37:25.720 --> 00:37:28.120]   Yeah, that's my relationship with God.
[00:37:28.120 --> 00:37:30.880]   I want to, I want, I like to believe in believing.
[00:37:30.880 --> 00:37:37.080]   Most great things in life are second derivatives of things, but that's
[00:37:37.080 --> 00:37:38.720]   part of another conversation.
[00:37:38.720 --> 00:37:42.840]   I feel like that's a quote that's going to take weeks to really internalize.
[00:37:43.080 --> 00:37:50.120]   That notion of, "I want you to want," or "I need you to need," or that there's
[00:37:50.120 --> 00:37:53.960]   always something, a deeper truth behind what is on the surface.
[00:37:53.960 --> 00:37:59.880]   And so I like to go to the second and tertiary derivative of things and
[00:37:59.880 --> 00:38:02.040]   discover new truths about them through that.
[00:38:02.040 --> 00:38:04.720]   But what have I learned about organisms?
[00:38:04.720 --> 00:38:06.760]   And why don't you like E. coli?
[00:38:07.080 --> 00:38:13.520]   I like E. coli, and a lot of the work that we've done was not possible without
[00:38:13.520 --> 00:38:19.200]   our working on E. coli or other workhorse organisms like cyanobacteria.
[00:38:19.200 --> 00:38:20.440]   How are bacteria used?
[00:38:20.440 --> 00:38:22.920]   Death masks, the death masks.
[00:38:22.920 --> 00:38:24.200]   So what are death masks?
[00:38:24.200 --> 00:38:29.560]   So we did this project called Vespers, and those were basically death masks
[00:38:29.560 --> 00:38:34.480]   that was set as a process for designing a living product.
[00:38:34.720 --> 00:38:39.400]   What happens, and we looked at, I looked at, I remember looking at Beethoven's
[00:38:39.400 --> 00:38:44.240]   death mask and Agamemnon's death mask and just studying how they were created.
[00:38:44.240 --> 00:38:49.160]   And really they were sort of geometrically attuned to the face of the dead.
[00:38:49.160 --> 00:38:55.600]   And what we wanted to do is create a death mask that was not based on the
[00:38:55.600 --> 00:39:02.600]   shape of the wearer, but rather was based on their legacy and their biology.
[00:39:02.600 --> 00:39:08.360]   And maybe we could harness a few stem cells there for future generations
[00:39:08.360 --> 00:39:10.640]   or contain the last breath.
[00:39:10.640 --> 00:39:15.440]   Lazarus, which preceded Vespers, was a project where we designed a mask to
[00:39:15.440 --> 00:39:18.840]   contain a single breath, the last breath of the wearer.
[00:39:18.840 --> 00:39:23.760]   And again, if I had access to these technologies today, I would totally
[00:39:23.760 --> 00:39:29.600]   reincorporate my grandmother's last breath in a product.
[00:39:29.600 --> 00:39:31.040]   So it was like an air memento.
[00:39:31.400 --> 00:39:41.280]   So with Vespers, we actually used E. coli to create pigmented masks, masks
[00:39:41.280 --> 00:39:45.960]   whose pigments would be recreated at the surface of the mask.
[00:39:45.960 --> 00:39:53.080]   And I'm skipping over a lot of content, but basically there were 15 masks and
[00:39:53.080 --> 00:39:57.160]   they were created as three sets, the masks of the past, the mask of the
[00:39:57.160 --> 00:39:58.800]   present and the mask of the future.
[00:40:00.120 --> 00:40:04.120]   The masks, there were five, five and five and the masks of the past were based on
[00:40:04.120 --> 00:40:12.280]   ornaments and they were embedded with natural minerals like gold.
[00:40:12.280 --> 00:40:13.560]   Yes, yes, yes.
[00:40:13.560 --> 00:40:15.720]   And we're looking at pictures of these and they're gorgeous.
[00:40:15.720 --> 00:40:16.440]   Yes.
[00:40:16.440 --> 00:40:23.440]   Extremely delicate and interesting fractal patterns that are symmetrical.
[00:40:23.440 --> 00:40:25.560]   They look symmetrical, but they're not.
[00:40:26.000 --> 00:40:31.800]   This is, we intended for you to be tricked and think that they're all symmetrical.
[00:40:31.800 --> 00:40:32.960]   But there's imperfections.
[00:40:32.960 --> 00:40:35.040]   There are imperfections by design.
[00:40:35.040 --> 00:40:43.200]   All of these forms and shapes and distribution of matter that you're
[00:40:43.200 --> 00:40:47.960]   looking at was entirely designed using a computational program.
[00:40:47.960 --> 00:40:49.520]   So none of it is manual.
[00:40:49.520 --> 00:40:55.880]   But long story short, the first collection is about the surface of
[00:40:55.880 --> 00:40:58.960]   the mask and the second collection, which you're looking at, is about
[00:40:58.960 --> 00:41:03.760]   the volume of the mask and what happens to the mask when all the colors from
[00:41:03.760 --> 00:41:09.080]   the surface, yes, enter the volume of the mask inside, create pockets and
[00:41:09.080 --> 00:41:11.320]   channels to guide life through them.
[00:41:11.320 --> 00:41:15.760]   They were incorporated with pigment producing living organisms.
[00:41:15.760 --> 00:41:20.840]   And then those organisms were templated to recreate the patterns
[00:41:20.840 --> 00:41:22.520]   of the original death masks.
[00:41:22.800 --> 00:41:26.760]   And so life recycles and rebegins and so on and so forth.
[00:41:26.760 --> 00:41:29.240]   The past meets the future, the future meets the past.
[00:41:29.240 --> 00:41:34.080]   From the surface to the volume, from death to life, to death, to life, to
[00:41:34.080 --> 00:41:38.880]   death, to life, and that again is a recurring theme in the projects that we
[00:41:38.880 --> 00:41:44.040]   take on, but there, from a technological perspective, what was interesting is
[00:41:44.040 --> 00:41:49.120]   that we embedded chemical signals in the jet, in the printer, and those chemical
[00:41:49.120 --> 00:41:58.160]   signals basically interacted with the pigment producing bacteria, in this
[00:41:58.160 --> 00:42:02.680]   case E. coli, that were introduced on the surface of the mask and those
[00:42:02.680 --> 00:42:08.200]   interactions between the chemical signals inside the resins and the
[00:42:08.200 --> 00:42:12.800]   bacteria at the surface of the mask at the resolution that is native to the
[00:42:12.800 --> 00:42:19.320]   printer, in this case 20 microns per voxel, allowed us to compute the exact
[00:42:19.320 --> 00:42:21.040]   patterns that we wanted to achieve.
[00:42:21.040 --> 00:42:24.760]   And we thought, well, if we can do this with pigments, can we do this with
[00:42:24.760 --> 00:42:25.520]   antibiotics?
[00:42:25.520 --> 00:42:28.240]   If we can do this with antibiotics, could we do it with melanin?
[00:42:28.240 --> 00:42:29.880]   And what are the implications?
[00:42:29.880 --> 00:42:31.840]   Again, this is a platform technology.
[00:42:31.840 --> 00:42:37.600]   Now that we have it, what are the actual real world implications and potential
[00:42:37.600 --> 00:42:40.400]   applications for this technology?
[00:42:41.280 --> 00:42:43.400]   And we started a new area.
[00:42:43.400 --> 00:42:51.760]   One of my students, Rachel, her PhD thesis was titled after this new class of
[00:42:51.760 --> 00:42:56.000]   materials that we created through this project Vespers, hybrid living materials,
[00:42:56.000 --> 00:43:03.640]   HLMs, and these hybrid living materials really paved the way towards a whole
[00:43:03.640 --> 00:43:09.000]   other set of products that we've designed, like the work that we did with
[00:43:09.000 --> 00:43:14.360]   melanin for the Mandela pavilion that we presented at SFMOMA, where again, we're
[00:43:14.360 --> 00:43:19.120]   using the same principles of templating, in this case, not silkworms and not bees,
[00:43:19.120 --> 00:43:26.920]   but we're templating bacteria at a much, much, much more finer resolution.
[00:43:26.920 --> 00:43:32.240]   And now instead of templating using a robot, we're templating using a printer.
[00:43:32.240 --> 00:43:34.960]   But compute is very, very much part of it.
[00:43:35.000 --> 00:43:40.760]   And what's nice about bacteria, of course, is that from an ethical
[00:43:40.760 --> 00:43:43.440]   perspective, I think there's a range, right?
[00:43:43.440 --> 00:43:48.000]   So at the end of the silk pavilion, I got an email from a professor in Japan who
[00:43:48.000 --> 00:43:52.400]   has been working on transgenic silk and said, well, if you did this, this
[00:43:52.400 --> 00:43:59.400]   create amazing silk pavilion, why don't we create glow in the light silk dresses?
[00:43:59.440 --> 00:44:09.200]   And in order to create this glow in the light silk, we need to apply genes that
[00:44:09.200 --> 00:44:11.480]   are taken from a spider to a silkworm.
[00:44:11.480 --> 00:44:15.040]   And this is what is known as a transgenic operation.
[00:44:15.040 --> 00:44:16.240]   And we said, no.
[00:44:16.240 --> 00:44:22.960]   And that was for us a clear decision that no, we will work with these organisms
[00:44:22.960 --> 00:44:28.640]   as long as we know that what we are doing with them is not only better for
[00:44:28.640 --> 00:44:31.040]   humans, but it's also better for them.
[00:44:31.040 --> 00:44:37.480]   And again, just to remind you where, I forget the exact number, but it's around
[00:44:37.480 --> 00:44:43.600]   a thousand cocoons per single shirt that are exterminated in India and China and
[00:44:43.600 --> 00:44:48.720]   we're in those sericulture industries that are being abused.
[00:44:48.720 --> 00:44:58.360]   Now, yes, this organism was designed to serve the human species and maybe we
[00:44:58.360 --> 00:45:07.720]   should, maybe it's time to retire that conception of organisms that are designed
[00:45:07.720 --> 00:45:11.240]   for a human centric world or human centric set of applications.
[00:45:11.240 --> 00:45:13.520]   I don't feel the same way about E.
[00:45:13.520 --> 00:45:14.040]   coli.
[00:45:14.040 --> 00:45:21.800]   Not that I'm agnostic, organism agnostic, but still I believe there's so much for
[00:45:21.800 --> 00:45:25.400]   us to do on this planet with bacteria.
[00:45:26.080 --> 00:45:32.600]   And so in general, your design principle is to grow cool stuff as a byproduct of
[00:45:32.600 --> 00:45:34.080]   the organism flourishing.
[00:45:34.080 --> 00:45:36.480]   So not using the organism.
[00:45:36.480 --> 00:45:37.880]   The win-win, the synergy.
[00:45:37.880 --> 00:45:39.760]   A whole that's bigger than the sum of its parts.
[00:45:39.760 --> 00:45:40.720]   It's interesting.
[00:45:40.720 --> 00:45:46.960]   I mean, it just feels like a gray area where genetic modification of an organism.
[00:45:46.960 --> 00:45:55.360]   It just feels like, I don't know, if you genetically modified me to make me glow
[00:45:55.880 --> 00:45:59.240]   in the light, I kind of like it.
[00:45:59.240 --> 00:46:00.640]   I think you have enough of an aura.
[00:46:00.640 --> 00:46:01.600]   Aura, thank you.
[00:46:01.600 --> 00:46:03.680]   That was, I was just fishing for compliments.
[00:46:03.680 --> 00:46:04.160]   Thank you.
[00:46:04.160 --> 00:46:05.000]   I appreciate it so much.
[00:46:05.000 --> 00:46:05.760]   But you're absolutely right.
[00:46:05.760 --> 00:46:11.480]   And by the way, the gray area is where some of us like to live and like to thrive.
[00:46:11.480 --> 00:46:12.640]   And that's okay.
[00:46:12.640 --> 00:46:17.280]   And thank goodness that there's so many of us that like the black and white
[00:46:17.280 --> 00:46:19.120]   and that thrive in the black and white.
[00:46:19.120 --> 00:46:21.400]   My husband is a good example for that.
[00:46:21.400 --> 00:46:25.480]   Well, but just to clarify, in this case, you're also trying to thrive in the
[00:46:25.480 --> 00:46:30.680]   black and white in that you're saying like the silkworm is a beautiful,
[00:46:30.680 --> 00:46:33.440]   wonderful creature, let us not modify it.
[00:46:33.440 --> 00:46:38.440]   Is that the idea or is it okay to modify a little bit as long as we can see that
[00:46:38.440 --> 00:46:41.400]   it benefits the organism as well as the final creation?
[00:46:41.400 --> 00:46:45.440]   So with silkworms, absolutely, let's not modify it genetically.
[00:46:45.440 --> 00:46:47.680]   Let's not modify it genetically.
[00:46:47.680 --> 00:46:54.760]   And then some, because why did we get there to begin with 4,000 years ago in
[00:46:54.760 --> 00:47:00.640]   the Silk Road and we should never get to a point where we evolve life for the
[00:47:00.640 --> 00:47:08.360]   service of mankind at the risk of these wonderful creatures across the kingdom
[00:47:08.360 --> 00:47:15.040]   of life, I don't think about the same kind of ethical range when I think about
[00:47:15.040 --> 00:47:15.640]   bacteria.
[00:47:15.640 --> 00:47:18.560]   Nevertheless, bacteria are pretty wonderful organisms.
[00:47:18.560 --> 00:47:20.040]   I'm moving to my second cup here.
[00:47:20.040 --> 00:47:21.560]   Take two.
[00:47:21.560 --> 00:47:23.480]   Things are getting serious now.
[00:47:23.560 --> 00:47:25.560]   Bacteria are, yeah, for sure.
[00:47:25.560 --> 00:47:27.600]   Let's give bacteria all the love they deserve.
[00:47:27.600 --> 00:47:28.760]   We wouldn't be here without them.
[00:47:28.760 --> 00:47:32.200]   They were here for, I don't know what it is, like a billion years before anything
[00:47:32.200 --> 00:47:32.600]   else showed up?
[00:47:32.600 --> 00:47:37.120]   But in a way, if you think about it, they create the matter that we consume and
[00:47:37.120 --> 00:47:45.280]   then reincarnates or dissolves into the soil and then creates a tree and then
[00:47:45.280 --> 00:47:46.760]   that tree creates more bacteria.
[00:47:46.760 --> 00:47:52.000]   And then that bacteria, I mean, again, that's why I like to think about not
[00:47:52.000 --> 00:47:58.360]   recycling, but reincarnating because that assumes a kind of imparting upon nature
[00:47:58.360 --> 00:48:03.200]   that dimension of agency and maybe awareness.
[00:48:03.200 --> 00:48:07.000]   But yeah, lots of really interesting work happening with bacteria.
[00:48:07.000 --> 00:48:10.560]   Directed evolution is one of them.
[00:48:10.560 --> 00:48:16.880]   We're looking at directed evolution, so high throughput directed evolution of
[00:48:16.880 --> 00:48:19.560]   bacteria for the production of products.
[00:48:19.600 --> 00:48:25.120]   And again, those products can be a shoe, wearables, biomaterials, therapeutics.
[00:48:25.120 --> 00:48:27.360]   And doing that direction computationally.
[00:48:27.360 --> 00:48:32.960]   Totally computationally, obviously in the lab with the hero organism, the hero
[00:48:32.960 --> 00:48:33.400]   bacteria.
[00:48:33.400 --> 00:48:41.120]   And what's happening today in ecromicrobial synthetic biology, synthetic
[00:48:41.120 --> 00:48:43.120]   biology that lends itself to ecology.
[00:48:43.120 --> 00:48:45.320]   And again, all of these fields are coming together.
[00:48:45.320 --> 00:48:48.040]   It's such a wonderful time to be a designer.
[00:48:48.160 --> 00:48:50.960]   I can't think of a better time to be a designer in this world.
[00:48:50.960 --> 00:48:58.040]   But with high throughput directed evolution, and I should say that the
[00:48:58.040 --> 00:49:05.400]   physical space in our new lab will have these capsules, which we have designed,
[00:49:05.400 --> 00:49:11.600]   that are designed like growth chambers or grow rooms.
[00:49:12.360 --> 00:49:19.680]   And in those grow rooms, we can basically program top down environmental
[00:49:19.680 --> 00:49:23.640]   templating, top down environmental control of lights, humidity, light, etc.
[00:49:23.640 --> 00:49:28.680]   So light, humidity, and temperature while doing a bottom up genetic regulation.
[00:49:28.680 --> 00:49:34.480]   So it is a wet lab, but in that wet lab, you could do at the same time, genetic
[00:49:34.480 --> 00:49:38.280]   modulation, regulation, and environmental templating.
[00:49:39.160 --> 00:49:43.000]   And then again, the idea is that in one of those capsules, maybe we grow transparent
[00:49:43.000 --> 00:49:46.720]   wood, and in another capsule, we, you know, we, transparent wood for architectural
[00:49:46.720 --> 00:49:49.360]   application, another capsule, we grow a shoe.
[00:49:49.360 --> 00:49:54.080]   And in another capsule, we look at that language, you know, large language model
[00:49:54.080 --> 00:49:55.360]   that we talked about.
[00:49:55.360 --> 00:49:58.960]   And there is a particular technology associated with that, which we're hoping
[00:49:58.960 --> 00:50:00.840]   to reveal to the world in February.
[00:50:00.840 --> 00:50:07.240]   And in each of those capsules is basically a high throughput computational
[00:50:07.240 --> 00:50:12.360]   environment, like a breadboard that has, think of sort of physical breadboard
[00:50:12.360 --> 00:50:18.240]   environment that has access to oxygen and nitrogen and CO2 and nutritional
[00:50:18.240 --> 00:50:19.080]   dispensing.
[00:50:19.080 --> 00:50:23.360]   And these little capsules could be stressed.
[00:50:23.360 --> 00:50:25.960]   They're sort of an ecology in a box.
[00:50:25.960 --> 00:50:30.760]   And they could be stressed to produce the food of the future or the products of the
[00:50:30.760 --> 00:50:33.320]   future or the construction materials of the future.
[00:50:34.680 --> 00:50:39.520]   Food is a very interesting one, obviously because of food insecurity and the issues
[00:50:39.520 --> 00:50:44.960]   that we have around both in terms of food insecurity, but also in terms of the future
[00:50:44.960 --> 00:50:49.640]   of food and what will remain after we can't eat plants and animals anymore and all we
[00:50:49.640 --> 00:50:56.240]   can eat is these false bananas and, you know, and insects as our protein source.
[00:50:56.240 --> 00:51:00.680]   So there we're thinking, you know, can we design these capsules to stress an
[00:51:00.680 --> 00:51:03.960]   environment and see how that environment behaves?
[00:51:03.960 --> 00:51:10.000]   Think about a kind of a, an ecological, a biodiversity chamber, right?
[00:51:10.000 --> 00:51:15.800]   A kind of a time capsule that is designed as a biodiversity chamber where you can
[00:51:15.800 --> 00:51:23.080]   program the exact temperature, humidity, and light combination to emulate the
[00:51:23.080 --> 00:51:24.280]   environment from the past.
[00:51:24.280 --> 00:51:30.600]   So Ohio, 1981, December 31st at 5am in the morning, what did tomatoes taste like?
[00:51:31.400 --> 00:51:36.840]   To all the way in the future, 200 years ago, these are the environmental inputs.
[00:51:36.840 --> 00:51:41.800]   These are some genetic regulations that I'm testing and what might the food of the
[00:51:41.800 --> 00:51:47.160]   future or the products of the future or the construction materials of the future feel
[00:51:47.160 --> 00:51:48.840]   like, test like, behave like, et cetera.
[00:51:48.840 --> 00:51:50.880]   And so these capsules are designed as part of a lab.
[00:51:50.880 --> 00:51:55.680]   That's why it's been taking us such a long time to get to this point because we
[00:51:55.680 --> 00:52:00.800]   started designing them in 2019 and they're currently, literally as I speak to you,
[00:52:00.800 --> 00:52:01.760]   under construction.
[00:52:01.760 --> 00:52:06.400]   - How well is it understood how to do this dance of controlling these different
[00:52:06.400 --> 00:52:09.760]   variables in order for various kinds of growth to happen?
[00:52:09.760 --> 00:52:10.560]   - It's not.
[00:52:10.560 --> 00:52:14.080]   It's never been done before and these capsules have never been designed before.
[00:52:14.080 --> 00:52:17.360]   So I, you know, when, when, when we first decided these are going to be
[00:52:17.360 --> 00:52:19.200]   environmental capsules, people thought we're crazy.
[00:52:19.200 --> 00:52:19.920]   What are you building?
[00:52:19.920 --> 00:52:20.560]   What are you making?
[00:52:20.560 --> 00:52:25.280]   So the answer is that we don't know, but we know that there has never been a space
[00:52:25.280 --> 00:52:31.360]   like this where you have basically a wet lab and a grow room at that resolution,
[00:52:31.360 --> 00:52:38.400]   at that granularity of, of, of, of, of control over organisms.
[00:52:38.400 --> 00:52:45.520]   There was a reason why there is this incredible evolution of products in the
[00:52:45.520 --> 00:52:46.480]   software space.
[00:52:46.480 --> 00:52:52.800]   The hardware space, that's a more limiting space that because of the physical
[00:52:52.800 --> 00:52:55.920]   infrastructure that we have to test and experiment with things.
[00:52:55.920 --> 00:53:02.560]   So we really wanted to push on creating a wet lab that is novel in every possible way.
[00:53:02.560 --> 00:53:04.000]   What could you create in it?
[00:53:04.000 --> 00:53:05.200]   You could create the future.
[00:53:05.200 --> 00:53:12.160]   You could create a, you could create an environment of plants talking to each
[00:53:12.160 --> 00:53:17.040]   other with a robotic referee and the robotic referee, we, you know, and you
[00:53:18.000 --> 00:53:26.960]   could set an objective function and let's say for, for, for, for the transaction
[00:53:26.960 --> 00:53:31.680]   driven individuals in the world, let's say the objective function is carbon
[00:53:31.680 --> 00:53:40.560]   sequestration and, and all of those plants are, are implemented with a gaming
[00:53:40.560 --> 00:53:43.040]   engine and they have these reward system, right?
[00:53:43.120 --> 00:53:48.080]   And they're constantly needing to optimize the way in which they carbon
[00:53:48.080 --> 00:53:48.720]   sequest.
[00:53:48.720 --> 00:53:53.680]   We weed out the bad guys, we leave the good guys and we end up with this like
[00:53:53.680 --> 00:53:58.480]   ideal ecology of carbon sequestering heroes that connect and communicate with
[00:53:58.480 --> 00:53:59.120]   each other.
[00:53:59.120 --> 00:54:03.200]   And once we have that model, this biodiversity chamber, we send it out into
[00:54:03.200 --> 00:54:06.240]   the field and we see what happens in nature.
[00:54:06.240 --> 00:54:08.080]   And that, that's sort of what I'm talking about.
[00:54:09.120 --> 00:54:16.880]   Augmenting plants with that extra dimension of, of bandwidth that they do
[00:54:16.880 --> 00:54:17.440]   not have.
[00:54:17.440 --> 00:54:26.800]   There, there just, just last week I came across a paper that discusses the
[00:54:26.800 --> 00:54:33.680]   in vivo neurons that are, that are augmented with a pong game and, and in a
[00:54:33.680 --> 00:54:38.480]   dish, they basically present sentience and the beginning of awareness, which is,
[00:54:38.480 --> 00:54:39.920]   which is wonderful.
[00:54:39.920 --> 00:54:44.320]   Like that, that you could actually take these neurons from a mouse brain and,
[00:54:44.320 --> 00:54:49.040]   and you have the electrical circuits and the physiological circuits that enable
[00:54:49.040 --> 00:54:55.040]   these cells to connect and communicate and together arrive at sort of swarm
[00:54:55.040 --> 00:55:00.880]   situation that allows them to act as a system that is not only perceived to be
[00:55:00.880 --> 00:55:02.960]   sentient, but is actually sentient.
[00:55:02.960 --> 00:55:08.080]   Michael Levine calls this agential material, material that has agency, right?
[00:55:08.080 --> 00:55:13.920]   So, so, so this, this, this is of interest to us because this is sort of, again,
[00:55:13.920 --> 00:55:15.680]   this is emergence post-templating.
[00:55:15.680 --> 00:55:19.840]   You template until you don't need to template anymore because, because the
[00:55:19.840 --> 00:55:21.520]   system has its own rules, right?
[00:55:21.520 --> 00:55:25.680]   What we don't want to happen with AGI, we want to happen with synthetic biology.
[00:55:25.680 --> 00:55:30.240]   What we don't want to happen online and software with language, we want for it to
[00:55:30.240 --> 00:55:34.720]   happen with, with bio-based materials, because that will get us closer to growing
[00:55:34.720 --> 00:55:39.840]   things as opposed to assembly and, and mechanically, yeah, putting them together
[00:55:39.840 --> 00:55:42.320]   with toxic materials and compounds.
[00:55:42.320 --> 00:55:44.960]   If I can ask a pothead question for a second.
[00:55:44.960 --> 00:55:51.360]   So you mentioned just like the silkworms, the individualist silkworms got to
[00:55:51.360 --> 00:55:55.360]   actually learn how to collaborate or actually to collaborate in a swarm like way.
[00:55:55.360 --> 00:55:59.840]   You're talking about getting plants to communicate in some interesting way based
[00:55:59.840 --> 00:56:01.520]   on an objective function.
[00:56:01.520 --> 00:56:06.880]   Is it possible to have some kind of interface between another kind of
[00:56:06.880 --> 00:56:10.960]   organisms, humans and nature?
[00:56:10.960 --> 00:56:14.080]   So like a human to have a conversation with, with a plant.
[00:56:14.080 --> 00:56:15.680]   There already is.
[00:56:15.680 --> 00:56:22.080]   You know that when we cut freshly cut grass, I love the smell, but it's a smell
[00:56:22.080 --> 00:56:26.560]   of, actually it's a smell of distress that the leaves of grass are communicating to
[00:56:26.560 --> 00:56:26.960]   each other.
[00:56:26.960 --> 00:56:34.160]   So the grass when it's cut emits green leaf volatiles, GLVs, and those GLVs are
[00:56:34.160 --> 00:56:37.600]   basically one leaf of grass communicating to another leaf of grass.
[00:56:37.600 --> 00:56:40.400]   Be careful, mind you, you're about to be cut.
[00:56:40.400 --> 00:56:44.800]   These incredible life forms are communicating using a different language than
[00:56:44.800 --> 00:56:45.040]   ours.
[00:56:45.040 --> 00:56:48.080]   We use language models, they use molecular models.
[00:56:48.080 --> 00:56:54.960]   At the moment where we can parse, we can, we can decode these molecular moments is
[00:56:54.960 --> 00:56:57.520]   when we can start having a conversation with plants.
[00:56:57.520 --> 00:57:01.040]   Now, of course, there is a lot of work around plant neurobiology.
[00:57:01.040 --> 00:57:02.400]   It's a real thing.
[00:57:02.400 --> 00:57:08.720]   Plants do not have a nervous system, but they have something akin to a nervous
[00:57:08.720 --> 00:57:09.600]   system.
[00:57:09.600 --> 00:57:14.720]   It has a kind of a ecological intelligence that is focused on a particular time
[00:57:14.720 --> 00:57:19.120]   scale, and the time scale is very, very slow, slow, slow, slow time scale.
[00:57:19.120 --> 00:57:26.640]   So it is when we can melt these time scales and, and, and, and connect with these
[00:57:26.640 --> 00:57:31.200]   plants in terms of the content of the language, in this case, molecules, the
[00:57:31.200 --> 00:57:35.840]   duration of the language, and we can start having a conversation, if not simply to
[00:57:35.840 --> 00:57:37.840]   understand what is happening in the plant kingdom.
[00:57:37.840 --> 00:57:42.560]   Precision agriculture, I promise to you, will look very, very different, right?
[00:57:42.560 --> 00:57:48.000]   Because right now we're using drones to take photos of crops of corn that look bad.
[00:57:48.000 --> 00:57:51.040]   And when we take that photo, it's already too late.
[00:57:51.040 --> 00:57:55.200]   But if we understand these molecular footprints and things that they are trying
[00:57:55.200 --> 00:57:59.040]   to say, the stress that they are trying to communicate, then we could, of course,
[00:57:59.040 --> 00:58:05.440]   predict the physiological, biological behavior of these crops, both for their own
[00:58:05.440 --> 00:58:11.920]   self-perpetuation, but also for the foods and the pharma and the type of molecules
[00:58:11.920 --> 00:58:14.800]   that we're seeking to grow for the benefit of humanity.
[00:58:14.800 --> 00:58:20.800]   And so these languages that we are attempting now to quantify and qualify will
[00:58:20.800 --> 00:58:27.520]   really help us not only better nature and help nature in its striving to surviving,
[00:58:27.520 --> 00:58:34.160]   but also help us, you know, design better wines and, you know, and, and better
[00:58:34.160 --> 00:58:38.640]   foods and, and, and better medicine and better products, again, across all
[00:58:38.640 --> 00:58:41.200]   scales, across all application domains.
[00:58:41.440 --> 00:58:45.920]   Is there intricacies to understanding the time scales, like you mentioned, at which
[00:58:45.920 --> 00:58:49.920]   these communications, these languages, like operate?
[00:58:49.920 --> 00:58:54.320]   Is there something different between the way humans communicate and the way plants
[00:58:54.320 --> 00:58:55.600]   communicate in terms of time?
[00:58:55.600 --> 00:59:01.200]   Remember when we started the conversation talking about sort of definitions in the
[00:59:01.200 --> 00:59:03.760]   context of design and then in the context of being?
[00:59:03.760 --> 00:59:11.040]   That question requires, I think, a kind of a shift, a humility.
[00:59:11.040 --> 00:59:15.600]   That requires a kind of a humility towards nature, understanding that it
[00:59:15.600 --> 00:59:17.360]   operates on different scales.
[00:59:17.360 --> 00:59:24.000]   We recently discovered that, you know, that the molecular footprint of a rose or of a
[00:59:24.000 --> 00:59:28.160]   plant in general during nighttime is different than its molecular footprint during
[00:59:28.160 --> 00:59:28.720]   daytime.
[00:59:28.720 --> 00:59:34.240]   So these are circadian rhythms that are associated with what kind of molecules these
[00:59:34.240 --> 00:59:43.840]   plants emit, given stress, stresses and given, you know, there's a reason why, why
[00:59:43.840 --> 00:59:48.880]   the jasmine, a jasmine field smells so, so delicious at 4 a.m.
[00:59:48.880 --> 00:59:49.600]   in the morning.
[00:59:49.600 --> 00:59:54.160]   And there's like, there's, there's peace and rest amongst, you know, amongst the
[00:59:54.160 --> 00:59:54.960]   plants.
[00:59:54.960 --> 01:00:01.120]   And you have to sort of tune into that time dimension of, of the plant kingdom.
[01:00:01.120 --> 01:00:06.160]   And that, of course, requires all this humility where in a single capsule to design a
[01:00:06.160 --> 01:00:12.320]   biodiversity chamber, it will take years, not months and definitely not days, and to
[01:00:12.320 --> 01:00:13.520]   see these products.
[01:00:13.520 --> 01:00:20.720]   And also that humility in design comes from simply, you know, looking at how we are
[01:00:20.720 --> 01:00:24.240]   today as a civilization, how we use and abuse nature.
[01:00:24.240 --> 01:00:26.720]   Like, just think of all these Christmas trees, right?
[01:00:26.720 --> 01:00:29.600]   These Christmas trees, they take years to grow.
[01:00:29.600 --> 01:00:32.240]   We use them for one night, the holiest night of the year.
[01:00:32.240 --> 01:00:34.320]   And then we let them go.
[01:00:34.320 --> 01:00:41.600]   And think about in nature to design a quote unquote product, an organism spends energy
[01:00:41.600 --> 01:00:45.440]   and time and thoughtfulness and many, many, many years.
[01:00:45.440 --> 01:00:46.880]   And I'm thinking about the redwoods.
[01:00:46.880 --> 01:00:54.880]   To grow these channels, these, you know, the cellulose layers and channels and reach
[01:00:54.880 --> 01:01:00.080]   these incredible heights takes sometimes hundreds of years, sometimes thousands of years.
[01:01:00.080 --> 01:01:06.400]   Am I afraid of building a company that designs products in the scale of thousands of years?
[01:01:06.400 --> 01:01:07.520]   No, I'm not.
[01:01:07.520 --> 01:01:16.480]   And the way of being in the physical world today is really not in tune with the time
[01:01:16.480 --> 01:01:18.800]   dimension of the natural world at all.
[01:01:18.800 --> 01:01:22.800]   And, and that needs to change.
[01:01:22.800 --> 01:01:31.360]   And that's obviously very, very hard to do in a community of human beings that is, at
[01:01:31.360 --> 01:01:34.320]   least in the Western world, that is based on capitalism.
[01:01:34.320 --> 01:01:40.720]   And so here, the wonderful challenge that we have ahead of us is how do we impart upon
[01:01:40.720 --> 01:01:42.160]   the capitalist movement?
[01:01:42.160 --> 01:01:46.720]   We know that we need to produce now products that will enter the real world and be, you
[01:01:46.720 --> 01:01:53.520]   know, shared and used by others and still benefit the natural world while benefiting
[01:01:53.520 --> 01:01:53.920]   humans.
[01:01:53.920 --> 01:01:55.680]   And that's a wonderful challenge to have.
[01:01:55.680 --> 01:02:00.400]   - So integrate technology with nature, and that's a really difficult problem.
[01:02:00.400 --> 01:02:06.240]   I see parallels here with another company of Neuralink, which is, is basically like
[01:02:06.240 --> 01:02:13.040]   you, I think you mentioned Neuralink for nature, that there are short-term products you can
[01:02:13.040 --> 01:02:19.120]   come up with, but it's ultimately a long-term challenge of how do you integrate the machine
[01:02:19.120 --> 01:02:25.600]   with this creation of nature, this intricate, complex creation of nature, which is the human
[01:02:25.600 --> 01:02:28.960]   brain, and then you're speaking more generally, nature.
[01:02:28.960 --> 01:02:37.920]   - You know how every company has an image, like this one single image that embodies the
[01:02:37.920 --> 01:02:38.960]   spirit of the company.
[01:02:40.000 --> 01:02:46.320]   And I think for Neuralink, it was to me that chimpanzee playing a video game.
[01:02:46.320 --> 01:02:49.040]   It was just unbelievable.
[01:02:49.040 --> 01:02:56.480]   But with plants, there potentially is a set of molecules that impacts or inspires, I like
[01:02:56.480 --> 01:03:03.920]   that word, the plant to behave or act in a certain way and allows still the plant the
[01:03:03.920 --> 01:03:07.920]   possibility of deciding where it or she or he wants to go.
[01:03:09.840 --> 01:03:15.120]   Which is why our first product for this molecular space is going to be a functionalized fragrance.
[01:03:15.120 --> 01:03:20.480]   So here, we're thinking about the future of fragrances and the future of fragrances and
[01:03:20.480 --> 01:03:21.040]   flavors.
[01:03:21.040 --> 01:03:30.080]   You know, these products are in the industry as we know it today, are designed for totally
[01:03:30.080 --> 01:03:36.800]   for a human-centric use and enjoyment and indulgence and luxury.
[01:03:38.240 --> 01:03:44.800]   They're used on the body for the sake of, I don't know, attraction and feeling good
[01:03:44.800 --> 01:03:46.160]   and smelling good.
[01:03:46.160 --> 01:03:53.760]   And we were asking ourselves, is there a world in which a fragrance can be not a functional
[01:03:53.760 --> 01:03:57.280]   fragrance, because you could claim that all fragrances are functional, but is there a
[01:03:57.280 --> 01:04:04.240]   world in which the fragrance becomes functionalized, is again, imparted upon or given agency to
[01:04:04.240 --> 01:04:06.400]   connect with another organism?
[01:04:06.400 --> 01:04:12.160]   Is there a world in which you and I can go down to your garden and use a perfume that
[01:04:12.160 --> 01:04:15.040]   will interact with the rose garden downstairs?
[01:04:15.040 --> 01:04:23.120]   I've just been enamored with the statements that are being made in the media around, "Oh,
[01:04:23.120 --> 01:04:27.840]   this is completely biologically derived fragrance and it's bio-based."
[01:04:27.840 --> 01:04:31.440]   And, but when you look into the fragrance and you understand that in order to get to
[01:04:31.440 --> 01:04:39.360]   this bio-derived fragrance, you went through, you blew through, you know, 10,000 bushes
[01:04:39.360 --> 01:04:43.280]   of rose to create five milliliters of a rose fragrance.
[01:04:43.280 --> 01:04:48.480]   And all these 10,000 bushes of rose, they take space, they take, you know, water management
[01:04:48.480 --> 01:04:50.400]   and so much waste.
[01:04:50.400 --> 01:04:56.800]   Is this really what we want the future of our agriculture and molecular goods to look
[01:04:56.800 --> 01:04:57.120]   like?
[01:04:57.120 --> 01:05:03.440]   And so, when we did the Aguajo pavilion on the roof of SF MoMA, we calculated that for
[01:05:03.440 --> 01:05:07.760]   that pavilion, we had 40,000 calories embedded into this pavilion that was made of shrimp
[01:05:07.760 --> 01:05:13.840]   shells and chitosan and apple skins and cellulose from tree pulp.
[01:05:13.840 --> 01:05:18.800]   And we calculated that overall, the structure had 40,000 calories.
[01:05:18.800 --> 01:05:20.800]   Interesting way to think about a structure, right?
[01:05:21.360 --> 01:05:23.760]   From the point of view of calories.
[01:05:23.760 --> 01:05:28.880]   But as you left the gallery, you saw these three clocks that were so beautifully designed
[01:05:28.880 --> 01:05:33.760]   by Felix on our team, and these clocks measured temperature and humidity and we connected
[01:05:33.760 --> 01:05:39.600]   them to a weather channel so that we could directly look at how the pavilion was biodegrading
[01:05:39.600 --> 01:05:40.400]   in real time.
[01:05:40.400 --> 01:05:48.240]   And in our calculations, I say this long-winded description of the pavilion to say that in
[01:05:48.240 --> 01:05:55.360]   the calculation, we incorporated how much electricity we used for our computers, for
[01:05:55.360 --> 01:05:57.520]   the 3D printers that printed the pavilion.
[01:05:57.520 --> 01:06:00.960]   And these were called energy calculations, right?
[01:06:00.960 --> 01:06:02.480]   Energy and materials.
[01:06:02.480 --> 01:06:08.720]   And when you think about a product, and you think about a shoe or a chair or a perfume
[01:06:08.720 --> 01:06:12.240]   or a building, you don't stop at the object.
[01:06:12.240 --> 01:06:14.880]   You want to go all the way to the system.
[01:06:14.880 --> 01:06:22.240]   Again, instead of designing objects or singular embodiments of the will of the designer, you're
[01:06:22.240 --> 01:06:26.720]   really tabbing into an entire system that is interconnected.
[01:06:26.720 --> 01:06:32.240]   And if you look at the energy budget that characterized the Project Agroha, it traverses
[01:06:32.240 --> 01:06:33.520]   the entire planet, right?
[01:06:33.520 --> 01:06:38.640]   Some of these shrimp shells were brought from places in the world we haven't thought of
[01:06:38.640 --> 01:06:42.080]   in terms of the apples and the shrimp shells and the tree pop.
[01:06:42.080 --> 01:06:51.760]   And so going back to fragrances, it's really, really important to understand the product
[01:06:51.760 --> 01:06:56.400]   in the context of the ecological system from which it's sourced and how it's designed.
[01:06:56.400 --> 01:07:03.760]   And that is the kind of thinking that is not only desired, but is required if we are to
[01:07:03.760 --> 01:07:06.240]   achieve synergy between humanity and nature.
[01:07:06.240 --> 01:07:09.360]   - And it's interesting 'cause the system level thinking is almost always gonna take
[01:07:09.360 --> 01:07:12.800]   you to the entire Earth, to considering the entire Earth ecosystem.
[01:07:12.800 --> 01:07:16.400]   - Which is why it's important to have a left brain and a right brain competing for attention.
[01:07:16.400 --> 01:07:18.000]   (laughing)
[01:07:18.000 --> 01:07:18.560]   - Sometimes you're the same.
[01:07:18.560 --> 01:07:19.680]   - And intimacy, I mean, yes.
[01:07:19.680 --> 01:07:27.520]   - You mentioned a fragrance that kind of sends out a message to the environment, essentially.
[01:07:27.520 --> 01:07:28.960]   - A message in a bottle, yeah.
[01:07:28.960 --> 01:07:30.160]   - A message in a bottle.
[01:07:30.160 --> 01:07:34.640]   So like, so you can go to a rose garden and trick the rose garden to think it's 4 a.m.,
[01:07:34.640 --> 01:07:35.760]   essentially.
[01:07:35.760 --> 01:07:38.000]   - You could if you wanted to, but maybe that is--
[01:07:38.400 --> 01:07:40.320]   - Not trick, trick is such a bad word.
[01:07:40.320 --> 01:07:40.800]   - Right, right.
[01:07:40.800 --> 01:07:41.680]   - Inspire.
[01:07:41.680 --> 01:07:44.240]   - But inspire I like.
[01:07:44.240 --> 01:07:49.920]   I like the idea of providing nature with a choice, which is why I love that elegant mathematical
[01:07:49.920 --> 01:07:52.880]   equation of empowerment and agency.
[01:07:52.880 --> 01:08:00.000]   - Empower the rose garden to create a romantic moment for the wearer of the fragrance.
[01:08:00.000 --> 01:08:07.600]   - But now again, you're, again, all of this to go back to that human-centric notion of
[01:08:07.600 --> 01:08:15.520]   romance, but maybe there's another way to do romance, right, that we haven't yet explored.
[01:08:15.520 --> 01:08:22.240]   And maybe there is a way to tap into what happens to the rose when it's dreaming.
[01:08:22.240 --> 01:08:28.160]   Assuming that plants are sentient and assuming that we can tap into that sentience, what
[01:08:28.160 --> 01:08:31.600]   can we discover about what does the rose want?
[01:08:31.600 --> 01:08:41.440]   Like what does it actually want and what does it need and what are the rose's dreams?
[01:08:41.440 --> 01:08:45.520]   - But do you think there's some correlation in terms of romance, in terms of the word
[01:08:45.520 --> 01:08:46.800]   you sometimes use, magic?
[01:08:46.800 --> 01:08:53.440]   Is there some similarities in what humans want and what roses want and what nature wants?
[01:08:53.440 --> 01:08:54.640]   - I think so.
[01:08:54.640 --> 01:08:59.360]   I think there is, and if I did not think so, oh my goodness, this would not be a nice world
[01:08:59.360 --> 01:08:59.920]   to live in.
[01:08:59.920 --> 01:09:03.440]   I think we all want love.
[01:09:03.440 --> 01:09:12.800]   I recently read this beautiful letter that was written by Einstein to his daughter and
[01:09:12.800 --> 01:09:18.080]   was discovered, Einstein asked his daughter to wait 20 years until she reveals these letters,
[01:09:18.080 --> 01:09:18.880]   and so she did.
[01:09:18.880 --> 01:09:23.920]   It's just one of the most beautiful letters I've ever read from a father to his daughter.
[01:09:24.480 --> 01:09:34.960]   And the letter overall is imbued with a kind of a sense of remorse or maybe even feelings
[01:09:34.960 --> 01:09:36.240]   of sadness.
[01:09:36.240 --> 01:09:42.480]   And there is some kind of melancholy note in the letter where Einstein regrets not having
[01:09:42.480 --> 01:09:47.680]   spent enough time with his daughter, having focused on the theory of general relativity
[01:09:47.680 --> 01:09:48.560]   and changing the world.
[01:09:49.120 --> 01:09:55.520]   And then he goes on to talk about this beautiful and elegant equation of E equals mc2, and
[01:09:55.520 --> 01:10:02.160]   he tells his daughter that he believes that love is actually the force that shapes the
[01:10:02.160 --> 01:10:04.400]   universe because it is like gravity, right?
[01:10:04.400 --> 01:10:05.440]   It attracts people.
[01:10:05.440 --> 01:10:06.880]   It is like light.
[01:10:06.880 --> 01:10:12.080]   It brings people together and connects between people, and it's all empowering.
[01:10:12.080 --> 01:10:18.720]   And so if you multiply it by the speed of light, you could really change the world for
[01:10:18.720 --> 01:10:19.280]   the better.
[01:10:19.280 --> 01:10:21.760]   And call me a romanticist.
[01:10:21.760 --> 01:10:26.640]   I know you are too, which is why I so love being here.
[01:10:26.640 --> 01:10:28.560]   I believe in this.
[01:10:28.560 --> 01:10:34.400]   I totally and utterly believe in this.
[01:10:34.400 --> 01:10:35.200]   - In love.
[01:10:35.200 --> 01:10:38.720]   By the way, let me just excerpt from Einstein's letter.
[01:10:38.720 --> 01:10:44.080]   "There's an extremely powerful force that so far science has not found a formal explanation
[01:10:44.080 --> 01:10:44.320]   to.
[01:10:44.880 --> 01:10:49.920]   It is a force that includes and governs all others and is even behind any phenomena operating
[01:10:49.920 --> 01:10:53.120]   in the universe and has not yet been identified by us.
[01:10:53.120 --> 01:10:56.000]   This universal force is love."
[01:10:56.000 --> 01:11:01.520]   He also, the last paragraph in the letter, as you've mentioned, "I deeply regret not
[01:11:01.520 --> 01:11:07.600]   having been able to express what is in my heart, which has quietly beaten for you all
[01:11:07.600 --> 01:11:08.320]   my life.
[01:11:08.320 --> 01:11:12.320]   Maybe it's too late to apologize, but as time is relative."
[01:11:13.200 --> 01:11:14.960]   That joke's to Einstein.
[01:11:14.960 --> 01:11:20.720]   "I need to tell you that I love you and thanks to you, I have reached the ultimate
[01:11:20.720 --> 01:11:21.280]   answer.
[01:11:21.280 --> 01:11:22.960]   Your father, Albert Einstein."
[01:11:22.960 --> 01:11:29.040]   "But that regret, I deeply regret not having been able to express what is in my heart."
[01:11:29.040 --> 01:11:33.440]   Maybe that's a universal regret.
[01:11:33.440 --> 01:11:42.720]   Filling your days with busyness and silly pursuits and not sitting down and expressing
[01:11:42.720 --> 01:11:42.960]   that.
[01:11:43.440 --> 01:11:46.320]   But it is everything.
[01:11:46.320 --> 01:11:47.280]   It is everything.
[01:11:47.280 --> 01:11:49.680]   It is why I love that expression.
[01:11:49.680 --> 01:11:59.760]   And I forget who said this, but I love my daughter more than evolution required, right?
[01:11:59.760 --> 01:12:05.600]   And I feel the same way towards my other half.
[01:12:05.600 --> 01:12:12.160]   And I feel that when you find that connection, everything and anything is possible.
[01:12:12.720 --> 01:12:19.760]   And it's a very, very, very magical moment.
[01:12:19.760 --> 01:12:24.720]   So I believe in love and I believe in the one.
[01:12:24.720 --> 01:12:28.720]   It might be the same thing.
[01:12:28.720 --> 01:12:29.760]   It might be a different thing.
[01:12:29.760 --> 01:12:34.640]   But let me ask you a ridiculously big philosophical question about beauty.
[01:12:34.640 --> 01:12:39.440]   Dostoevsky said, "Beauty will save the world" in "The Idiot," one of my favorite books
[01:12:39.440 --> 01:12:39.760]   of his.
[01:12:40.800 --> 01:12:42.320]   What is beauty to you?
[01:12:42.320 --> 01:12:49.360]   You've created through this intersection of engineering and nature, you've created
[01:12:49.360 --> 01:12:50.880]   some incredibly beautiful things.
[01:12:50.880 --> 01:12:52.800]   What do you think is beauty?
[01:12:52.800 --> 01:12:56.240]   That's a beautiful question.
[01:12:56.240 --> 01:12:59.440]   Maybe it is connected to the love question.
[01:12:59.440 --> 01:13:01.040]   It is connected to the love question.
[01:13:01.040 --> 01:13:03.200]   Of course, everything is connected to the love question.
[01:13:03.200 --> 01:13:03.520]   Okay.
[01:13:03.520 --> 01:13:08.960]   To me, beauty is agency.
[01:13:10.000 --> 01:13:14.560]   To me, something that has agency, it is beautiful.
[01:13:14.560 --> 01:13:20.480]   There is this special quote from Buckminster Fuller, which I cannot remember word for word,
[01:13:20.480 --> 01:13:24.320]   but I remember the concept, which goes something like this.
[01:13:24.320 --> 01:13:28.640]   "When I work on a problem, I never think about beauty.
[01:13:28.640 --> 01:13:33.920]   But when I'm done solving the problem and I look at what I've created and it's not
[01:13:33.920 --> 01:13:35.600]   beautiful, I know that I was wrong."
[01:13:35.600 --> 01:13:38.080]   Okay.
[01:13:38.080 --> 01:13:38.400]   Yeah.
[01:13:38.400 --> 01:13:45.040]   It's kind of an agency that speaks to, quote unquote, "the objective function of the
[01:13:45.040 --> 01:13:46.160]   creation," right?
[01:13:46.160 --> 01:13:48.880]   Whether for Bucky, it's useless or useful.
[01:13:48.880 --> 01:13:52.320]   So this idea of empowerment that you talked about is fundamentally connected to it.
[01:13:52.320 --> 01:13:53.920]   Yes, comes back to that, yeah.
[01:13:53.920 --> 01:13:59.520]   What's the difference that you hinted at between empowerment and emergence?
[01:13:59.520 --> 01:14:03.680]   Is emergence completely lacks control?
[01:14:05.200 --> 01:14:10.400]   And empowerment is more controlled?
[01:14:10.400 --> 01:14:14.720]   There's an agent making decisions?
[01:14:14.720 --> 01:14:16.720]   Is there an interesting distinction there?
[01:14:16.720 --> 01:14:17.280]   Yes.
[01:14:17.280 --> 01:14:20.400]   I think empowerment is a force with direction.
[01:14:20.400 --> 01:14:22.960]   It has directionality to it.
[01:14:22.960 --> 01:14:28.560]   Emergence is, I believe, multidirectional.
[01:14:28.560 --> 01:14:30.320]   Again, that depends on the application.
[01:14:31.040 --> 01:14:37.120]   Emergence is perhaps, in terms of a material definition, is the isotropic spirit.
[01:14:37.120 --> 01:14:48.560]   When empowerment is the anisotropic counterpart, I think they overlap because I think that
[01:14:48.560 --> 01:14:58.160]   empowerment is a way of inspiring emergence.
[01:14:58.160 --> 01:15:04.240]   I think emergence does not happen without empowerment, but empowerment can happen without
[01:15:04.240 --> 01:15:04.800]   emergence.
[01:15:04.800 --> 01:15:07.680]   Do you think of emergence as the loss of control?
[01:15:07.680 --> 01:15:12.720]   Like when you're thinking about these capsules and then the things they create, is emergence
[01:15:12.720 --> 01:15:18.960]   a thing that is not a desirable conclusion?
[01:15:18.960 --> 01:15:25.280]   I love that question because to some of us, the loss of control is control.
[01:15:26.400 --> 01:15:32.400]   In design, we're used to extreme levels of control over form and the shape of a thing
[01:15:32.400 --> 01:15:34.320]   and how it behaves and how it functions.
[01:15:34.320 --> 01:15:38.480]   That's something we've inherited from the Industrial Revolution.
[01:15:38.480 --> 01:15:48.400]   But with nature, there is this diversity that happens without necessarily having a
[01:15:48.400 --> 01:15:49.680]   reward function, right?
[01:15:49.680 --> 01:15:51.120]   This is good or bad.
[01:15:51.120 --> 01:15:55.280]   Things just happen, and some of them happen to have wings and some of them happen to have
[01:15:55.280 --> 01:16:02.720]   scales, and you end up with this incredible potential for diversity.
[01:16:02.720 --> 01:16:08.960]   So I think the future of design is in that soft control, is in the ability to design
[01:16:08.960 --> 01:16:14.720]   highly controlled systems that enable the loss of control.
[01:16:14.720 --> 01:16:24.000]   And creativity is very much part of this because creativity is all about letting go and beginning
[01:16:24.000 --> 01:16:25.920]   again and beginning again, beginning again.
[01:16:25.920 --> 01:16:33.200]   And when you cannot let go, you cannot be creative and you can't find novelty.
[01:16:33.200 --> 01:16:41.280]   But I think that letting go is a moment that enables empowerment, agency, creativity, emergence.
[01:16:41.280 --> 01:16:43.360]   And they're all connected.
[01:16:43.360 --> 01:16:48.240]   They sort of associate themselves with the definition of destiny or the inevitable.
[01:16:49.440 --> 01:16:57.840]   A good friend of mine shared with me elegant definition of fate, which is the ratio of
[01:16:57.840 --> 01:16:59.920]   who you are and who you want to be.
[01:16:59.920 --> 01:17:03.200]   Ratio of who you are, who you want to be.
[01:17:03.200 --> 01:17:04.720]   Exactly.
[01:17:04.720 --> 01:17:07.600]   And that sort of ends up defining you.
[01:17:07.600 --> 01:17:08.160]   Yeah.
[01:17:08.160 --> 01:17:15.360]   And those tools, I think, when you let go, you sort of find, you give peace to your will,
[01:17:15.360 --> 01:17:16.640]   right, to a sense of will.
[01:17:18.480 --> 01:17:22.720]   And so I think that's very, very important in design, but also in life.
[01:17:22.720 --> 01:17:30.000]   She said this fate is the ratio of who you are and who you want to be.
[01:17:30.000 --> 01:17:34.640]   Do you think there's something to this whole manifestation thing, like focusing on a vision
[01:17:34.640 --> 01:17:41.120]   of what you want the world to become and in that focusing, you manifest it?
[01:17:41.120 --> 01:17:44.800]   Like Paulo Coelho said in "The Alchemist," when you want something, all the universe
[01:17:44.800 --> 01:17:46.640]   conspires in helping you to achieve it.
[01:17:46.640 --> 01:17:48.240]   Is there something to that?
[01:17:48.560 --> 01:17:50.080]   I think so, yes.
[01:17:50.080 --> 01:17:58.320]   And I always think of what I do as the culmination of energy, information, and matter, and how
[01:17:58.320 --> 01:18:03.680]   to direct energy, information, and matter in the design of a thing or in the design
[01:18:03.680 --> 01:18:04.240]   of a life.
[01:18:04.240 --> 01:18:12.560]   I think living is very much a process of channeling these energies to where they need to go.
[01:18:13.280 --> 01:18:19.520]   I think that the manifestation or part of that manifestation is the pointing to the
[01:18:19.520 --> 01:18:21.600]   moon in order to get to the moon.
[01:18:21.600 --> 01:18:25.040]   And that's why manifestation is also directional.
[01:18:25.040 --> 01:18:30.080]   It has that vector quality to it that I think of agency as.
[01:18:30.080 --> 01:18:36.240]   Have you, in your own life, has there been things you've done where you kind of direct
[01:18:36.240 --> 01:18:40.560]   that energy, information, and matter in a way that opens up?
[01:18:40.560 --> 01:18:42.000]   New possibilities.
[01:18:42.000 --> 01:18:50.320]   Yeah. I mean, you've also said somewhere, I'm probably misquoting, that you're many
[01:18:50.320 --> 01:18:55.760]   things, you, Neri, are many things, and you become new things every 10 years or so.
[01:18:55.760 --> 01:18:57.440]   Oh, I did say that somewhere.
[01:18:57.440 --> 01:18:58.160]   Somewhere.
[01:18:58.160 --> 01:18:59.920]   That every decade you've sort of switched.
[01:18:59.920 --> 01:19:02.960]   That was an old, that was a previous Neri that said that.
[01:19:02.960 --> 01:19:10.080]   Yeah, I did say some time ago that you have to sort of reboot every 10 years to keep creative
[01:19:10.080 --> 01:19:12.720]   and keep inventive and keep fresh.
[01:19:12.720 --> 01:19:16.960]   Is there things you've done in your life where just kind of doors opened?
[01:19:16.960 --> 01:19:22.800]   I think everything, everything.
[01:19:22.800 --> 01:19:29.840]   Everything good I've found in my life has been found in that way of
[01:19:29.840 --> 01:19:37.200]   letting go and suspending my sense of disbelief.
[01:19:37.200 --> 01:19:41.200]   And often you will find me say to the team, "Suspend your disbelief.
[01:19:41.200 --> 01:19:44.160]   I don't care that this is impossible.
[01:19:44.160 --> 01:19:45.440]   Let's assume it is.
[01:19:45.440 --> 01:19:46.880]   Where does it take us?"
[01:19:46.880 --> 01:19:51.200]   And that suspension of disbelief is absolutely part and parcel of the creative act.
[01:19:51.200 --> 01:20:01.440]   You know, I did so when I was in medical school.
[01:20:01.440 --> 01:20:04.480]   I was in Hadassah and in the Hebrew University.
[01:20:05.280 --> 01:20:13.200]   And I remember I left medical school for architecture the day my grandmother passed away.
[01:20:13.200 --> 01:20:15.760]   And that was a moment of relief.
[01:20:15.760 --> 01:20:19.840]   And that was a moment, a door that was closing that opened other opportunities.
[01:20:19.840 --> 01:20:26.400]   But that, of course, required letting go of the great vision of becoming a doctor and
[01:20:26.400 --> 01:20:34.320]   letting go of the dream of being surrounded by wonderful patients and the science of medicine
[01:20:34.320 --> 01:20:40.560]   and the research associated with that science and letting go of that dream to accomplish another.
[01:20:40.560 --> 01:20:46.960]   And it has happened throughout my life in different ways.
[01:20:46.960 --> 01:20:54.480]   MIT was another experience like that where people pointed at me as, you know, the designer
[01:20:54.480 --> 01:21:00.320]   for whom the academic currency is not necessarily the citation index.
[01:21:01.040 --> 01:21:06.160]   And of course, in order to get tenure at MIT, you have to look at the citation index.
[01:21:06.160 --> 01:21:09.360]   But for me, it was not that.
[01:21:09.360 --> 01:21:16.480]   It was manifesting our work in shows and writing papers and writing patents and creating a
[01:21:16.480 --> 01:21:17.920]   celebration around the work.
[01:21:17.920 --> 01:21:24.480]   And I never saw a distinction between those ways of being.
[01:21:25.040 --> 01:21:32.640]   I also think that another kind of way of being or a modality of being that I found helpful
[01:21:32.640 --> 01:21:38.880]   is, Victor Frankl wrote this incredible book, "Man's Search for Meaning After the Holocaust."
[01:21:38.880 --> 01:21:45.760]   And he writes different people pursue life for different reasons.
[01:21:45.760 --> 01:21:50.080]   According to Freud, the goal of life is to find pleasure.
[01:21:50.080 --> 01:21:52.960]   And according to Adler, it's to find power.
[01:21:53.920 --> 01:21:58.400]   And for Victor Frankl, it was about finding meaning.
[01:21:58.400 --> 01:22:06.000]   And when you let go of the titles and the disciplines and the boundaries and the expectations
[01:22:06.000 --> 01:22:15.360]   and the perception, you are elevated to this really special, yes, spiritual, but definitely
[01:22:15.360 --> 01:22:23.520]   very, very creative plane where you can sort of start anew and look at the world through
[01:22:23.520 --> 01:22:30.800]   the lens of a bacterium or a robot or look at ecology through the lens of chemistry and
[01:22:30.800 --> 01:22:34.000]   look at chemistry through the lens of robotics and look at robotics through the lens of
[01:22:34.000 --> 01:22:38.720]   microbial ecologies and so on and so forth.
[01:22:38.720 --> 01:22:44.320]   And I feel that kind of rebooting, not every 10 years, but every minute, every breath,
[01:22:44.320 --> 01:22:52.640]   is very, very important for a creative life and for just maintaining this fresh mind.
[01:22:52.640 --> 01:22:56.880]   To reboot, to begin again with every breath, begin again.
[01:22:56.880 --> 01:22:59.680]   And that can be confusing for some, right?
[01:22:59.680 --> 01:23:04.160]   For my team members, I like to change my mind.
[01:23:04.160 --> 01:23:04.960]   It's who I am.
[01:23:04.960 --> 01:23:05.760]   It's how I think.
[01:23:05.760 --> 01:23:06.720]   It's how I operate.
[01:23:06.720 --> 01:23:08.000]   You don't know.
[01:23:08.000 --> 01:23:15.600]   And they'll come and we found another technique or another technology that's interesting.
[01:23:15.600 --> 01:23:19.760]   And we thought that we were working on dysfunctionalized fragrance, but now there's
[01:23:19.760 --> 01:23:21.440]   another opportunity and let's go there.
[01:23:21.440 --> 01:23:30.320]   And to me, I would much rather live life, like if I had to pick sort of my favorite
[01:23:30.320 --> 01:23:36.640]   Broadway show to enter and live through, it would be "Into the Woods."
[01:23:36.640 --> 01:23:39.040]   It's not a specific fairy tale.
[01:23:39.040 --> 01:23:46.400]   It's not "The Sleeping Beauty" or "Little Red Riding Hood" or "Rapunzel."
[01:23:46.400 --> 01:23:47.280]   It's all of them.
[01:23:47.280 --> 01:23:52.400]   It's sort of moving into the forest and seeing this wonder and getting close and learning
[01:23:52.400 --> 01:23:54.400]   about that and then moving to another wonder.
[01:23:54.400 --> 01:24:03.280]   And life is really about tying all of these little fairy tales together in work and also
[01:24:03.280 --> 01:24:04.000]   in life.
[01:24:04.000 --> 01:24:06.160]   Unafraid to leap into the unknown.
[01:24:06.160 --> 01:24:08.640]   Unafraid to leap into the unknown.
[01:24:08.640 --> 01:24:15.200]   Speaking of MIT, you got a tenure at MIT and then you leaped to New York and started a
[01:24:15.200 --> 01:24:20.000]   new company with a vision that doesn't span a couple of years, but centuries.
[01:24:20.000 --> 01:24:22.240]   I did.
[01:24:22.240 --> 01:24:24.800]   It was my destiny to start a company.
[01:24:24.800 --> 01:24:29.120]   And do I have mornings when I wake up and I ask myself, "What the hell am I doing?"
[01:24:29.120 --> 01:24:31.200]   Yes, I have those mornings.
[01:24:31.200 --> 01:24:32.640]   What do you do with those mornings, by the way?
[01:24:32.640 --> 01:24:38.800]   I embrace them and I find gratitude and I say to myself, "Thank goodness.
[01:24:40.240 --> 01:24:46.560]   I'm so lucky to have the ability to be frustrated in this way."
[01:24:46.560 --> 01:24:52.640]   So I really, really embrace these frustrations.
[01:24:52.640 --> 01:25:05.120]   And I take them, I wrap them in a bubble and I look at it on the outside of my aware mind
[01:25:05.120 --> 01:25:07.840]   and I laugh at them.
[01:25:07.840 --> 01:25:08.720]   I smile at them.
[01:25:08.960 --> 01:25:11.040]   (laughing)
[01:25:11.040 --> 01:25:15.440]   If I could return actually to the question of beauty for a second, I forgot to ask you
[01:25:15.440 --> 01:25:15.840]   something.
[01:25:15.840 --> 01:25:19.280]   You mentioned imperfection in the death masks.
[01:25:19.280 --> 01:25:20.240]   Mm-hmm.
[01:25:20.240 --> 01:25:26.640]   What role does imperfection play in our conception of beauty?
[01:25:26.640 --> 01:25:30.640]   What role does imperfection play in nature?
[01:25:31.280 --> 01:25:40.560]   There's this Japanese aesthetics concept of wabi-sabi, which basically embraces imperfection.
[01:25:40.560 --> 01:25:43.200]   Nothing lasts, nothing is finished, and nothing is perfect.
[01:25:43.200 --> 01:25:44.720]   What do you think of that?
[01:25:44.720 --> 01:25:54.880]   I totally agree that change is the only permanence, that imperfection is there if only to signal
[01:25:54.880 --> 01:26:00.720]   that we are part of a bigger thing than ourselves, that we are on a journey.
[01:26:00.720 --> 01:26:01.220]   Mm-hmm.
[01:26:01.220 --> 01:26:06.400]   That things are in movement.
[01:26:06.400 --> 01:26:13.920]   And if they were perfect, of course when things are perfect it is just so boring, we end up
[01:26:13.920 --> 01:26:14.880]   with stereotypes.
[01:26:14.880 --> 01:26:21.280]   And as humans, but I think just in general as living beings, we're here to find meaning.
[01:26:21.280 --> 01:26:27.200]   And that meaning cannot be found without struggle and without seeking to, not to perfect, but
[01:26:27.200 --> 01:26:29.680]   to build towards something better.
[01:26:30.400 --> 01:26:39.120]   And when I was a child, my mother, who I love so much, always explained to me how important
[01:26:39.120 --> 01:26:47.040]   it is to fall and to fail and to fight and to argue, and that there is a way, that there
[01:26:47.040 --> 01:26:52.800]   is a culture to failing and to imperfection.
[01:26:53.920 --> 01:27:06.400]   So I think it is necessary for something beautiful to be imperfect, and it is a sign of nature,
[01:27:06.400 --> 01:27:08.320]   because nothing in nature is perfect.
[01:27:08.320 --> 01:27:10.640]   What about human relations?
[01:27:10.640 --> 01:27:12.080]   You mentioned finding love.
[01:27:12.080 --> 01:27:17.360]   Are the flaws in humans, the imperfection in humans a component of love?
[01:27:17.360 --> 01:27:20.800]   What role do you think the flaws play?
[01:27:23.040 --> 01:27:25.920]   That's a really profound question.
[01:27:25.920 --> 01:27:42.720]   I think the flaws are there to present a vulnerability.
[01:27:42.720 --> 01:27:51.120]   And those flaws are a sign of those vulnerabilities.
[01:27:52.480 --> 01:27:56.960]   And I think love is very, very gentle.
[01:27:56.960 --> 01:28:05.040]   Love ... With Bill we often talk about, between the two of us, about what drives all human
[01:28:05.040 --> 01:28:08.880]   behavior, and for him it's incentive, as you might expect.
[01:28:08.880 --> 01:28:13.840]   And he will repeat this sentence to me, "Incentive drives all human behavior."
[01:28:13.840 --> 01:28:18.320]   But I would say to me it's love, very much so.
[01:28:20.080 --> 01:28:28.160]   And I think flaws are part of that, because flaws are a sign of that vulnerability, whether
[01:28:28.160 --> 01:28:29.920]   physical, whether emotional vulnerability.
[01:28:29.920 --> 01:28:35.120]   And these vulnerabilities, they either tear us apart or they bring us together.
[01:28:35.120 --> 01:28:40.800]   The vulnerability is what is the glue, I think.
[01:28:40.800 --> 01:28:45.520]   I think that the vulnerability enables connection.
[01:28:45.520 --> 01:28:47.200]   The connection is the glue.
[01:28:47.200 --> 01:28:53.040]   And that connection enables accessing a higher ground as a community as opposed to as an
[01:28:53.040 --> 01:28:53.680]   individual.
[01:28:53.680 --> 01:28:58.960]   So if there is a society of the mind, or if there are higher levels of awareness that
[01:28:58.960 --> 01:29:06.160]   can be accessed in community as opposed to, again, going to the silkworm, as opposed to
[01:29:06.160 --> 01:29:11.760]   on the individual level, I think that those occur through the flaws and the vulnerabilities.
[01:29:11.760 --> 01:29:17.200]   And without them, we cannot find connection, community.
[01:29:17.200 --> 01:29:22.640]   And without community, we can't build what we have built as a civilization, you know,
[01:29:22.640 --> 01:29:24.960]   for the past hundreds of thousands of years.
[01:29:24.960 --> 01:29:31.760]   So I think not only are they beautiful, but they have a functional role in building civilizations.
[01:29:31.760 --> 01:29:38.320]   Yeah, there's a sense in which love requires vulnerability, and maybe love is the leap
[01:29:38.320 --> 01:29:40.000]   into that vulnerability.
[01:29:40.000 --> 01:29:49.440]   And I think, yes, I think a flaw, think about it, like physically, I'm thinking about a
[01:29:49.440 --> 01:29:56.080]   brick that's flawed, but in a way, I think of a flaw as an increased surface area.
[01:29:56.080 --> 01:30:01.200]   God, that's a good line.
[01:30:01.200 --> 01:30:02.720]   That's a good line.
[01:30:02.720 --> 01:30:02.960]   Right?
[01:30:02.960 --> 01:30:06.560]   A surface area that physically or emotionally, right?
[01:30:06.880 --> 01:30:11.600]   It sort of introduces this whole new dimension to a human or a brick.
[01:30:11.600 --> 01:30:17.120]   And because you have more surface area, you can, you know, use mortar and build a home.
[01:30:17.120 --> 01:30:23.440]   And yeah, I think of it as accessing this additional dimension of surface area that
[01:30:23.440 --> 01:30:25.840]   could be used for good or bad, right?
[01:30:25.840 --> 01:30:30.560]   To connect, to communicate, to collaborate.
[01:30:31.440 --> 01:30:37.120]   It makes me think of that quote from this incredible movie I've watched years ago,
[01:30:37.120 --> 01:30:43.440]   "Particle Fever," I think it was called, a documentary about the Large Hadron Collider,
[01:30:43.440 --> 01:30:49.360]   an incredible film, where they talk about the things that are least important for our survival
[01:30:49.360 --> 01:30:50.880]   are the things that make us human.
[01:30:50.880 --> 01:31:00.480]   Like the pure romantic act or, you know, the notion of, and Viktor Frankl talks about that
[01:31:00.480 --> 01:31:13.840]   too, he talks about feeling the sun on his arms as he is working the soil in two degrees
[01:31:13.840 --> 01:31:15.680]   Fahrenheit without clothes.
[01:31:15.680 --> 01:31:22.960]   And the officer berates him and says, "What have you done?
[01:31:22.960 --> 01:31:26.720]   Have you been a businessman before you came here to the camp?"
[01:31:27.600 --> 01:31:28.960]   And he says, "I was a doctor."
[01:31:28.960 --> 01:31:31.600]   And he said, "You must have made a lot of money as a doctor."
[01:31:31.600 --> 01:31:35.920]   And he said, "All my work I've done for free, I've been helping the poor."
[01:31:35.920 --> 01:31:53.200]   But he keeps his humility and he keeps his modesty and he keeps his preservation of the
[01:31:53.200 --> 01:32:05.840]   spirit, and he says the things that actually made him able to outlive the terrible experience
[01:32:05.840 --> 01:32:12.160]   in the Holocaust was really cherishing this moment when the sun hits his skin or when
[01:32:12.160 --> 01:32:17.920]   he can eat a grain of rice, a single grain of rice.
[01:32:17.920 --> 01:32:27.440]   So I think cherishing is a very important part of living a meaningful life, being able
[01:32:27.440 --> 01:32:29.280]   to cherish those simple things.
[01:32:29.280 --> 01:32:31.840]   Like to notice them and to--
[01:32:31.840 --> 01:32:35.600]   To notice them, to pay attention to them in the moment.
[01:32:35.600 --> 01:32:39.920]   And I do this now more than ever.
[01:32:39.920 --> 01:32:47.200]   I mean, there is some, Bukowski has this poem I like called "Nirvana," where it tells
[01:32:47.200 --> 01:32:51.840]   the story of a young man on a bus going through like North Carolina or something like this,
[01:32:51.840 --> 01:32:58.800]   and they stop off in a cafe and he has this, there's a waitress, and just, he talks about
[01:32:58.800 --> 01:33:04.560]   that he notices the magic, something indescribable, he just notices the magic of it.
[01:33:04.560 --> 01:33:08.320]   And he gets back on the bus with the rest of the passengers and none of them seem to
[01:33:08.320 --> 01:33:09.360]   have noticed the magic.
[01:33:10.800 --> 01:33:18.960]   And I think if you just allow yourself to pause and just to feel whatever that is, maybe
[01:33:18.960 --> 01:33:24.880]   ultimately it's a kind of gratitude for, I don't know what it is.
[01:33:24.880 --> 01:33:31.840]   It's just, I'm sure it's just chemicals in the brain, but it's just so incredible to
[01:33:31.840 --> 01:33:38.160]   be alive and noticing that and appreciating that and being one in that with others.
[01:33:38.160 --> 01:33:39.600]   Yes, yes.
[01:33:39.600 --> 01:33:46.160]   And that goes back to, you know, to the fireplace, right?
[01:33:46.160 --> 01:33:47.680]   To the first technology.
[01:33:47.680 --> 01:33:49.040]   What was the first technology?
[01:33:49.040 --> 01:33:50.080]   It was fire.
[01:33:50.080 --> 01:33:57.200]   First technology to have built community, and it emerged out of a vulnerability of wanting
[01:33:57.200 --> 01:34:00.080]   to stay away from the cold and be warm together.
[01:34:02.080 --> 01:34:09.040]   And of course that fire is associated with not only with comfort and the ability to form
[01:34:09.040 --> 01:34:24.080]   bio-relevant nutrients in our food and provide heat and comfort, but also spirits and a kind
[01:34:24.080 --> 01:34:35.280]   of a way to enter a spiritual moment, to enter a moment that can only be experienced in a
[01:34:35.280 --> 01:34:38.400]   community as a form of a meditative moment.
[01:34:38.400 --> 01:34:41.200]   There is a lot to be said about light.
[01:34:41.200 --> 01:34:52.880]   Light is, I think, an important part of these moments of, I think it's a real thing.
[01:34:52.880 --> 01:35:00.800]   I really truly believe that we're born with an aura, surface area that is measurable.
[01:35:00.800 --> 01:35:09.680]   I think we're born into the world with an aura.
[01:35:09.680 --> 01:35:18.000]   And how do we channel that is really sort of ends, I mean, ends up sort of defining
[01:35:18.000 --> 01:35:21.280]   the light in our lives.
[01:35:21.840 --> 01:35:24.560]   Do you think we're all lonely?
[01:35:24.560 --> 01:35:26.720]   Do you think there's loneliness in us humans?
[01:35:26.720 --> 01:35:27.360]   Oh, yes.
[01:35:27.360 --> 01:35:33.200]   Yes, loneliness is part, yes, I think we all have that loneliness, whether we're willing
[01:35:33.200 --> 01:35:44.080]   to access that loneliness and look at it in the eye or completely avoid it or deny it.
[01:35:44.080 --> 01:35:50.640]   It's like, it feels like it's some kind of foundation for longing, and longing leads to
[01:35:51.280 --> 01:35:54.960]   this combination of vulnerability and connection with others.
[01:35:54.960 --> 01:35:55.920]   Yes.
[01:35:55.920 --> 01:35:59.440]   And it feels like that's a really important part of being human, is being lonely.
[01:35:59.440 --> 01:36:02.880]   Very, it's very ... we are born into this world alone.
[01:36:02.880 --> 01:36:09.120]   Again, being alone and being lonely are two different things, right?
[01:36:09.120 --> 01:36:13.760]   You can be together but be lonely, and you can be alone but not be lonely at all.
[01:36:13.760 --> 01:36:18.800]   We often joke, Bill and I, that he cannot be lonely.
[01:36:18.800 --> 01:36:21.440]   He cannot deal with being by himself.
[01:36:21.440 --> 01:36:22.800]   He always needs people around him.
[01:36:22.800 --> 01:36:32.400]   And I strive long, must have creative solitude, must find pockets of solitude and loneliness
[01:36:32.400 --> 01:36:36.400]   in order to find creativity and reconnect with myself.
[01:36:36.400 --> 01:36:45.200]   So, loneliness is a recipe for community, in my opinion, and I think those things complement
[01:36:45.200 --> 01:36:48.640]   each other, and they're synergetic, absolutely.
[01:36:48.640 --> 01:36:58.880]   The yin and yang of togetherness, and they allow you, I think, to reset and to tune in
[01:36:58.880 --> 01:37:05.680]   to that ratio we talked about of who you are and who you want to be.
[01:37:05.680 --> 01:37:11.680]   If you go to this place of creative solitude, what's your creative process?
[01:37:11.680 --> 01:37:17.760]   Is there something you've noticed about what you do that leads to good work?
[01:37:18.720 --> 01:37:25.920]   I love to be able, not only to lose focus, but kind of to focus on the peripheral view.
[01:37:25.920 --> 01:37:30.880]   And to allow different things to occur at once.
[01:37:30.880 --> 01:37:37.680]   So, I will often, in my loneliness journeys, I will often listen to, like, Leonard Bernstein,
[01:37:37.680 --> 01:37:41.040]   anything I can find online by Lenny Bernstein.
[01:37:41.040 --> 01:37:43.600]   It's reading a nature paper.
[01:37:43.600 --> 01:37:44.880]   It's war and peace.
[01:37:44.880 --> 01:37:50.480]   It's really revisiting all the texts that are so timeless for me with opportunities
[01:37:50.480 --> 01:37:52.000]   that are very, very timely.
[01:37:52.000 --> 01:37:59.840]   And I think for me, the creative process is really about bringing timeless problems or
[01:37:59.840 --> 01:38:05.760]   concepts together with timely technologies to observe them.
[01:38:05.760 --> 01:38:11.280]   I remember when we did the Mandela Pavilion, we read Moby Dick, The Whiteness of the Whale,
[01:38:11.280 --> 01:38:13.280]   The Albino, The Different, The Other.
[01:38:14.240 --> 01:38:17.360]   And that got us to work on Melanin.
[01:38:17.360 --> 01:38:20.160]   And Melanin also is sort of an output from the Death Mass.
[01:38:20.160 --> 01:38:26.720]   So, it's lots of things happening at the same time and really allowing them to come
[01:38:26.720 --> 01:38:35.520]   together to form this view about the world through the lens of a spirit being or a living
[01:38:35.520 --> 01:38:41.200]   being or a material, and then focus on the world through the lens of that material.
[01:38:41.200 --> 01:38:46.640]   The glass work was another project like that, where we were fascinated by glass because
[01:38:46.640 --> 01:38:49.760]   obviously it's superb material for architecture.
[01:38:49.760 --> 01:38:55.680]   But we created this new glass printing technology for the first time that was shedding light
[01:38:55.680 --> 01:39:01.200]   on the biomechanics of fluid glass, the math and the physics of which was never done before,
[01:39:01.200 --> 01:39:02.640]   which was so exciting to us.
[01:39:02.640 --> 01:39:07.920]   But revealing new knowledge about the world through technology, that's one theme.
[01:39:09.360 --> 01:39:14.240]   The reincarnation between things, material and immaterial, that's another theme.
[01:39:14.240 --> 01:39:17.840]   Lenny Bernstein, War and Peace, Tolstoy.
[01:39:17.840 --> 01:39:24.240]   You've tweeted a Tolstoy quote from War and Peace, as of course you would.
[01:39:24.240 --> 01:39:26.800]   "Everything I know, I know because of love."
[01:39:26.800 --> 01:39:28.560]   Love, yeah, I love this quote.
[01:39:28.560 --> 01:39:37.840]   So, you use these kind of inspirations to focus you and then find the actual idea in
[01:39:37.840 --> 01:39:38.560]   the periphery.
[01:39:39.360 --> 01:39:44.880]   Yes, and then connect them with whatever it is that we're working on, whether it's
[01:39:44.880 --> 01:39:52.720]   high throughput, directed evolution of bacteria, whether it's recreating that Garden of Eden
[01:39:52.720 --> 01:39:55.360]   in the capsule and what it looks like, the food of the future.
[01:39:55.360 --> 01:39:58.240]   It is a little bit like directing a film.
[01:39:58.240 --> 01:40:03.680]   Creating a new project is a bit like creating a film.
[01:40:04.240 --> 01:40:10.080]   And you have these heroes, you have these characters, and you put them together, and
[01:40:10.080 --> 01:40:13.040]   there is a narrative, and there is a story.
[01:40:13.040 --> 01:40:19.760]   Whenever we start a new project, it has to have these ingredients of simultaneous
[01:40:19.760 --> 01:40:20.480]   complexity.
[01:40:20.480 --> 01:40:24.960]   It has to be novel in terms of the synthetic biology, material science, robotics,
[01:40:24.960 --> 01:40:25.680]   engineering.
[01:40:25.680 --> 01:40:30.800]   All of these elements that are discipline-based or rooted must be novel.
[01:40:31.440 --> 01:40:37.360]   If you can combine novelty in synthetic biology with a novelty in robotics, with a novelty
[01:40:37.360 --> 01:40:42.400]   in material science, with a novelty in computational design, you are bound to create
[01:40:42.400 --> 01:40:44.320]   something novel, period.
[01:40:44.320 --> 01:40:47.920]   And that's how I run the company, and that's how I pick the people.
[01:40:47.920 --> 01:40:54.160]   And so that's another very, very important ingredient of the cutting edge across multiple
[01:40:54.160 --> 01:40:56.160]   disciplines that come together.
[01:40:56.160 --> 01:41:00.560]   And then in the background, in the periphery, there's all these messages, the whispers of
[01:41:00.560 --> 01:41:02.800]   the ancient oldies, right?
[01:41:02.800 --> 01:41:05.520]   The Beethovens and the Picassos.
[01:41:05.520 --> 01:41:07.200]   So Beethoven's always whispering to you?
[01:41:07.200 --> 01:41:08.160]   Yeah.
[01:41:08.160 --> 01:41:11.280]   How could one not include Beethoven in the whispers?
[01:41:11.280 --> 01:41:15.360]   I'm going to ask you about Beethoven and the Evgeny Kislyny you've mentioned, because
[01:41:15.360 --> 01:41:16.720]   I've played piano my whole life.
[01:41:16.720 --> 01:41:18.560]   I obviously know a lot of Beethoven.
[01:41:18.560 --> 01:41:23.760]   And it's one of the private things for me, I suppose, because I don't think I've ever
[01:41:23.760 --> 01:41:24.880]   publicly played piano.
[01:41:24.880 --> 01:41:26.080]   By the way, me too.
[01:41:26.080 --> 01:41:29.200]   I mean, not everything.
[01:41:29.200 --> 01:41:30.880]   I play in private only.
[01:41:30.880 --> 01:41:36.000]   Yeah, people sometimes, even with guitar, people ask me, "Can you play something?"
[01:41:36.000 --> 01:41:37.920]   And it just feels like certain things are...
[01:41:37.920 --> 01:41:39.280]   Are meant to be done...
[01:41:39.280 --> 01:41:39.760]   Privately.
[01:41:39.760 --> 01:41:40.400]   Yeah.
[01:41:40.400 --> 01:41:41.040]   It's weird.
[01:41:41.040 --> 01:41:42.320]   I mean, it's a difficult...
[01:41:42.320 --> 01:41:49.760]   And some of the times I have performed publicly, it is an ultimate leap in vulnerability.
[01:41:49.760 --> 01:41:51.760]   It's very, very, very difficult for me.
[01:41:51.760 --> 01:41:52.640]   And I'm sure it's...
[01:41:52.640 --> 01:41:55.120]   I know it's not for a lot of people, but it is for me.
[01:41:55.120 --> 01:41:56.240]   Anyway, we'll return to that.
[01:41:56.240 --> 01:42:01.680]   But since you've mentioned combination of knowledge across multiple disciplines, that's
[01:42:01.680 --> 01:42:08.080]   what you seek when you build teams or pick people you work with.
[01:42:08.080 --> 01:42:16.560]   I just wanted to kind of linger on this idea of what kind of humans are you looking for
[01:42:16.560 --> 01:42:20.800]   in this endeavor that you're taking on, this fascinating thing that you've been talking
[01:42:20.800 --> 01:42:21.360]   about?
[01:42:21.360 --> 01:42:28.320]   I want to think somewhere else, a previous version, version 5.7 of Neri said somewhere
[01:42:28.320 --> 01:42:33.600]   that there's four fields that are combined to create this intersection of biology and
[01:42:33.600 --> 01:42:34.800]   engineering work in.
[01:42:34.800 --> 01:42:39.600]   It's computational design, additive manufacturing, material engineering, synthetic biology.
[01:42:39.600 --> 01:42:40.720]   I'm sure there's others.
[01:42:40.720 --> 01:42:42.800]   But how do you find these humans?
[01:42:42.800 --> 01:42:44.000]   Machine learning is in the mix.
[01:42:44.000 --> 01:42:47.120]   I manifest and they come.
[01:42:47.120 --> 01:42:48.260]   Yeah.
[01:42:48.260 --> 01:42:49.520]   There are a few approaches.
[01:42:49.520 --> 01:42:50.820]   Manifest.
[01:42:50.980 --> 01:42:53.540]   They show up.
[01:42:53.540 --> 01:42:59.700]   You know, "send your message upon the water," those job descriptions that you saw, the first
[01:42:59.700 --> 01:43:01.300]   ones I wrote by myself.
[01:43:01.300 --> 01:43:08.260]   And you find interesting people and brilliant people when you look—we talked about second
[01:43:08.260 --> 01:43:10.580]   derivative—when you look under and under and under.
[01:43:10.580 --> 01:43:17.140]   And if you look deep enough and specialized enough, and if you allow yourself to look
[01:43:17.140 --> 01:43:23.860]   at the cracks, at the flaws, at the cracks between disciplines and between skills, you
[01:43:23.860 --> 01:43:27.380]   find really, really interesting diamonds in the rough.
[01:43:27.380 --> 01:43:36.740]   And so I like for those job descriptions to be those messages in a bottle that bring those
[01:43:36.740 --> 01:43:38.340]   really interesting people our way.
[01:43:38.340 --> 01:43:42.100]   I mean, they have to have humility.
[01:43:42.100 --> 01:43:44.820]   They have to have a shine in their eye.
[01:43:44.820 --> 01:43:46.420]   They have to be hungry and foolish.
[01:43:46.420 --> 01:43:53.780]   As Job so famously said, a friend of mine who's a dean of a well-known architectural
[01:43:53.780 --> 01:43:57.380]   school said, "Today, architects don't want to be architects.
[01:43:57.380 --> 01:44:02.020]   Architects don't look up to the star architects as role models.
[01:44:02.020 --> 01:44:04.020]   Star architects are no longer role models.
[01:44:04.020 --> 01:44:07.620]   Architects want to build by virtue of not building."
[01:44:07.620 --> 01:44:13.060]   She said, "We're back in the '60s when we think about architecture, back in the
[01:44:13.060 --> 01:44:13.700]   hippie movement."
[01:44:15.140 --> 01:44:23.860]   I think that in a way, they have to be somewhat of a hippie, somewhat of a kind of a jack
[01:44:23.860 --> 01:44:25.220]   of all trades, master of all.
[01:44:25.220 --> 01:44:27.540]   And yet with humility.
[01:44:27.540 --> 01:44:29.940]   And yet with humility.
[01:44:29.940 --> 01:44:31.620]   Now, that is hard to find.
[01:44:31.620 --> 01:44:36.900]   And that is why, you know, when I start an interview, I talk about childhood memories,
[01:44:36.900 --> 01:44:41.380]   and I asked about music, and I ask about connection.
[01:44:41.380 --> 01:44:48.900]   And through these interviews, you can learn a lot about a person's future by spending
[01:44:48.900 --> 01:44:51.940]   time hearing them talk about their past.
[01:44:51.940 --> 01:44:57.860]   Do you find that educational, like PhDs versus, like, what's the life trajectory?
[01:44:57.860 --> 01:44:59.540]   Yours is an interesting life trajectory, too.
[01:44:59.540 --> 01:45:04.900]   Like, what's the life trajectory that leads to the kind of person that would work with
[01:45:04.900 --> 01:45:05.400]   you?
[01:45:06.020 --> 01:45:13.140]   It's, you know, people who have ideally had industry experience and know what it's
[01:45:13.140 --> 01:45:15.300]   like to be in the quote-unquote "real world."
[01:45:15.300 --> 01:45:20.020]   They're dreamers that are addicted to reality, as opposed to realists that are addicted to
[01:45:20.020 --> 01:45:20.520]   dreams.
[01:45:20.520 --> 01:45:23.380]   Meaning they have that innocence in them.
[01:45:23.380 --> 01:45:24.500]   They have the hunger.
[01:45:24.500 --> 01:45:34.660]   They have the idealism without being entitled and with understanding the systems that govern
[01:45:34.660 --> 01:45:35.700]   our world.
[01:45:35.700 --> 01:45:41.460]   And understanding how to utilize these systems as Torjan horses to bring those values into
[01:45:41.460 --> 01:45:41.960]   the world.
[01:45:41.960 --> 01:45:51.780]   There are individuals who feel comfortable in this friction between, you know, highly
[01:45:51.780 --> 01:45:58.980]   wondrous and dreamy and incredible fantasy renditions of what the world could be with
[01:46:01.940 --> 01:46:05.540]   an extremely brilliant skills in terms of their disciplinary background.
[01:46:05.540 --> 01:46:13.460]   So PhD with industrial experience in a certain field or a double major in two fields that
[01:46:13.460 --> 01:46:19.300]   make no sense whatsoever in their combination are things that really, really attract me.
[01:46:19.300 --> 01:46:24.180]   And especially that span the technology-biology gap.
[01:46:24.180 --> 01:46:24.680]   Yes.
[01:46:24.680 --> 01:46:26.900]   Technology, biology, nature, culture.
[01:46:26.900 --> 01:46:29.700]   I mean, the secret to one thing is through the lens of another.
[01:46:29.700 --> 01:46:34.500]   And I always believe in that kind of translational design ability to be able to see something
[01:46:34.500 --> 01:46:35.620]   through the lens of another.
[01:46:35.620 --> 01:46:41.140]   And always allows you to think again, begin again, reestablish, redefine, suspend your
[01:46:41.140 --> 01:46:42.980]   disbelief, revisit.
[01:46:42.980 --> 01:46:49.700]   And when you revisit enough times, like a hundred times or like 200 times, and you revisit
[01:46:49.700 --> 01:46:55.700]   the same question through the lens of any possible discipline and any possible scenario,
[01:46:55.700 --> 01:46:58.900]   eventually you get to the truth.
[01:46:58.900 --> 01:47:08.020]   I have to ask you, because you work at the interplay of the machine and the natural world,
[01:47:08.020 --> 01:47:11.380]   is there a good definition for you of what is life?
[01:47:11.380 --> 01:47:14.100]   What is a living organism?
[01:47:14.100 --> 01:47:24.500]   I think like 440 million years ago, there were all these plants that the cyanobacteria,
[01:47:24.500 --> 01:47:29.620]   I believe actually that was like the first extinction, right?
[01:47:29.620 --> 01:47:31.380]   There were five extinctions.
[01:47:31.380 --> 01:47:34.100]   We are apparently the sixth.
[01:47:34.100 --> 01:47:35.460]   We are in the eye of the storm.
[01:47:35.460 --> 01:47:36.740]   We are in the sixth extinction.
[01:47:36.740 --> 01:47:39.060]   We are going to be extinct as we speak.
[01:47:39.060 --> 01:47:42.260]   I mean, death is upon us, whether we want to admit it or not.
[01:47:42.260 --> 01:47:50.820]   And actually, they found in Argentina and in various places around the world, they found
[01:47:50.820 --> 01:47:58.660]   these spores of the first plants that existed on the planet, and they emerged out of these
[01:47:58.660 --> 01:48:03.300]   cyanobacteria were the first, of course, and then they found these spore-based plants.
[01:48:03.300 --> 01:48:08.980]   And because they didn't have seeds, they're only spores, the spores became sort of the
[01:48:08.980 --> 01:48:12.340]   fossils by which we've come to know of their existence.
[01:48:12.340 --> 01:48:17.140]   And because of these spores, we know that this first extinction existed.
[01:48:18.020 --> 01:48:23.940]   But this extinction is actually what enabled plants to resurrect, right?
[01:48:23.940 --> 01:48:32.020]   So the death of these first plants, because they clinked to the rocks and they generated
[01:48:32.020 --> 01:48:40.020]   a ton of phosphorus that went into the ocean by clinking to the rocks, like 60 times more
[01:48:40.020 --> 01:48:41.460]   phosphorus than without them.
[01:48:41.460 --> 01:48:46.580]   And then all this phosphorus basically choked the oceans and made them super cold.
[01:48:46.580 --> 01:48:49.860]   And without oxygen, aoxic.
[01:48:49.860 --> 01:48:53.700]   And then we lost the plant kingdom.
[01:48:53.700 --> 01:49:00.100]   And then because of the death of these first plants, they actually enriched the soil and
[01:49:00.100 --> 01:49:04.500]   created nutrients for these new plants to come to the planet.
[01:49:04.500 --> 01:49:12.340]   And those planets had like more sophisticated vein systems, and they were moving beyond
[01:49:12.340 --> 01:49:16.100]   spores to seeded plants, et cetera, and flowering plants.
[01:49:16.580 --> 01:49:25.540]   And so in a way, one mass extinction sort of led in the Ordovician period, sort of led
[01:49:25.540 --> 01:49:27.620]   to life as we know it.
[01:49:27.620 --> 01:49:30.900]   And where would we be without plants in a way?
[01:49:30.900 --> 01:49:34.820]   So I think that death is very much part of life.
[01:49:34.820 --> 01:49:42.180]   And through that definition, that kind of planetary wide definition in the context of
[01:49:42.180 --> 01:49:48.740]   hundreds of millions of years, life gains a completely new, sort of a new light.
[01:49:48.740 --> 01:49:52.980]   And that's when the particles become a wave, right?
[01:49:52.980 --> 01:49:55.220]   Where humans are, we are not alone.
[01:49:55.220 --> 01:49:57.780]   And we are here because of those plants, right?
[01:49:57.780 --> 01:50:00.740]   So I think death is very much part of life.
[01:50:00.740 --> 01:50:10.500]   So in the context of the redwood tree, perhaps life is defined as 10 generations.
[01:50:10.500 --> 01:50:15.460]   And through the lens of a bacteria, perhaps life is defined as a millisecond.
[01:50:15.460 --> 01:50:22.180]   And perhaps through the lens of an AGI, life is defined as all of human civilization.
[01:50:22.180 --> 01:50:31.460]   So I think it really is a question of this time scale again, the time scale and the organism,
[01:50:31.460 --> 01:50:35.620]   the life form that's asking the question, through which we can answer what is life?
[01:50:35.620 --> 01:50:40.900]   - What do you think about this since you're, if we think of ourselves as in the eye of
[01:50:40.900 --> 01:50:48.500]   the storm of another extinction, the natural question to ask here is you have all of nature,
[01:50:48.500 --> 01:50:55.860]   and then you have this new human creation that is currently being termed artificial intelligence.
[01:50:55.860 --> 01:51:05.140]   How does your work play with the possibility of a future superintelligent ecosystem
[01:51:05.620 --> 01:51:09.780]   and AGI that either joins or supersedes humans?
[01:51:09.780 --> 01:51:10.660]   - Yeah.
[01:51:10.660 --> 01:51:14.820]   So I'm glad you asked this question.
[01:51:14.820 --> 01:51:17.140]   - And are you hopeful or terrified?
[01:51:17.140 --> 01:51:18.100]   - Both.
[01:51:18.100 --> 01:51:19.860]   I'm hopeful and terrified.
[01:51:19.860 --> 01:51:25.060]   I did watch your interview with Eliezer Yudkowsky, and I loved it.
[01:51:25.060 --> 01:51:28.340]   - Because you were scared or because you were excited or because there was a profound fear?
[01:51:28.340 --> 01:51:30.020]   - First of all, I was both.
[01:51:30.020 --> 01:51:40.500]   I was, I totally scared, shamed, excited, and totally also inspired because he's just
[01:51:40.500 --> 01:51:42.100]   such an incredible thinker.
[01:51:42.100 --> 01:51:48.980]   And I can agree or disagree with what he says, but I just found his way of thinking about AGI
[01:51:48.980 --> 01:51:52.900]   and the perils of humanity as a result.
[01:51:52.900 --> 01:51:56.020]   - There's an inevitability to what he's saying.
[01:51:56.020 --> 01:51:59.780]   His advice to young people is that prepare for a short life.
[01:51:59.780 --> 01:52:00.660]   - Yeah.
[01:52:00.660 --> 01:52:06.340]   - He thinks it's very almost simple.
[01:52:06.340 --> 01:52:15.060]   It's almost common sense that AGI would get rid of humans, that he can't imagine a trajectory
[01:52:15.060 --> 01:52:21.460]   eventually that leads to a place that doesn't have AGI kill all humans.
[01:52:21.460 --> 01:52:26.980]   There's just too many trajectories where a superintelligent systems gets rid of humans
[01:52:26.980 --> 01:52:30.100]   and in the near term.
[01:52:30.100 --> 01:52:35.140]   And so that clarity of thinking is very sobering to me.
[01:52:35.140 --> 01:52:38.500]   It's, maybe it is to you as well.
[01:52:38.500 --> 01:52:44.020]   It's super inspiring because I think he's wrong, but it's like, you almost want to prove him wrong.
[01:52:44.020 --> 01:52:46.900]   It's like, no, we humans are clever bunch.
[01:52:46.900 --> 01:52:48.020]   We're going to find a way.
[01:52:48.180 --> 01:52:50.820]   - It is a bit like jumping into super cold water.
[01:52:50.820 --> 01:52:53.700]   It's sort of a kind of a fist in your face.
[01:52:53.700 --> 01:52:54.660]   It wakes you up.
[01:52:54.660 --> 01:52:56.420]   And I like these moments so much.
[01:52:56.420 --> 01:53:06.260]   And he was able to bring that moment to life, even though I think a mother can never think that way
[01:53:06.260 --> 01:53:06.760]   ever.
[01:53:06.760 --> 01:53:13.940]   And it's a little bit like that notion of, I love her more than evolution requires.
[01:53:14.660 --> 01:53:20.900]   On your question about AGI and nature, look, I think we've been through a lot in terms of,
[01:53:20.900 --> 01:53:25.060]   to get here, we sort of moved from data, right?
[01:53:25.060 --> 01:53:29.620]   The ability to collect information, to knowledge, the ability to use this information for utility,
[01:53:29.620 --> 01:53:31.620]   from knowledge to intelligence.
[01:53:31.620 --> 01:53:32.660]   And what is intelligence?
[01:53:32.660 --> 01:53:35.940]   It's the ability to problem solve and adapt and translate.
[01:53:35.940 --> 01:53:41.060]   So that sort of from data to information, to knowledge, I think the next frontier is wisdom.
[01:53:41.060 --> 01:53:43.060]   And what is wisdom?
[01:53:43.060 --> 01:53:51.460]   Wisdom is the ability to have or find insight about the world and from wisdom to spiritual
[01:53:51.460 --> 01:53:58.500]   awareness, which is sort of transcends wisdom and is able to chart the world into new territory.
[01:53:58.500 --> 01:54:04.340]   But I think what is interesting about AGI is that it is sort of almost like a self-recursive
[01:54:04.340 --> 01:54:04.900]   thing, right?
[01:54:04.900 --> 01:54:09.220]   Because it's like a washing machine of like a third derivative Wikipedia.
[01:54:09.220 --> 01:54:14.980]   It uses kind of like language to create language, to create language, to create language.
[01:54:14.980 --> 01:54:17.060]   It feels like novelty is being constantly created.
[01:54:17.060 --> 01:54:20.180]   I don't, it doesn't feel like it's regurgitating.
[01:54:20.180 --> 01:54:24.020]   And that's so fascinating because, you know, these are not the stochastic parrots.
[01:54:24.020 --> 01:54:32.340]   This is sort of a new form of emergence, perhaps of novelty, as you say, that exists by virtue of
[01:54:32.340 --> 01:54:36.180]   using old things to create new things.
[01:54:38.500 --> 01:54:42.580]   But it's not as if the AGI has self-awareness, right?
[01:54:42.580 --> 01:54:50.020]   It's not as if it has, maybe, maybe, maybe, maybe it has, but as far as I can tell, it's
[01:54:50.020 --> 01:54:55.220]   not as if AGI has approached consciousness or sentience just yet.
[01:54:55.220 --> 01:55:03.780]   It's probably getting there, but the language appears to present itself as if there is sentience
[01:55:03.780 --> 01:55:04.900]   there, but it doesn't.
[01:55:04.900 --> 01:55:10.180]   But I think that's the problem at the point where this AGI sounds like me and speaks like
[01:55:10.180 --> 01:55:14.420]   me and behaves like me and feels like me and breathes like me.
[01:55:14.420 --> 01:55:20.900]   And my daughter knows the AGI to be me as sort of the end of everything, right?
[01:55:20.900 --> 01:55:22.660]   As the end of human agency.
[01:55:22.660 --> 01:55:30.420]   But what is the end of human agency to humans, I think is the beginning of agency to nature.
[01:55:30.420 --> 01:55:34.980]   Because if you take all of this agency, if you take all of these language models that
[01:55:34.980 --> 01:55:42.020]   can summarize all of human civilization and consciousness and then upload that to nature
[01:55:42.020 --> 01:55:48.180]   and have nature now deal with that world of consciousness that it never had access to.
[01:55:48.180 --> 01:55:54.660]   So maybe through Eliezer's lens, the sort of short-lived human becomes sort of a very
[01:55:54.660 --> 01:56:00.340]   long-lived human-like sentient weeping willow, maybe?
[01:56:00.340 --> 01:56:02.260]   Maybe that's the end and the beginning.
[01:56:02.260 --> 01:56:13.060]   And maybe on the more optimistic side for us humans, it's a different form of existence
[01:56:13.060 --> 01:56:20.580]   where everything we create and everything we consume and everything we process is all
[01:56:20.580 --> 01:56:26.900]   made up of six elements and that's it.
[01:56:26.900 --> 01:56:31.300]   And there's only those six elements and not 118 elements.
[01:56:31.300 --> 01:56:41.540]   And it's all the stuff of biology plus some fair amount of bits, genes and atoms.
[01:56:41.540 --> 01:56:42.740]   Well, I think the idea--
[01:56:42.740 --> 01:56:43.860]   A lot of Beethoven.
[01:56:43.860 --> 01:56:45.060]   A lot of Beethoven.
[01:56:45.060 --> 01:56:50.740]   I think the idea of connecting AGI to nature through your work is really fascinating.
[01:56:51.540 --> 01:57:02.420]   Sort of unlocking this incredible machinery of intelligence that is AGI and connecting
[01:57:02.420 --> 01:57:09.380]   it to the incredible machinery of wisdom that is nature as evolved through billions of years.
[01:57:09.380 --> 01:57:10.180]   Yeah.
[01:57:10.180 --> 01:57:14.660]   A pretty crazy, intense evolution.
[01:57:15.380 --> 01:57:15.940]   Exactly.
[01:57:15.940 --> 01:57:26.420]   And unlike--again, I'm going back to directed evolution--unlike this sort of high-throughput,
[01:57:26.420 --> 01:57:34.980]   brute-force approach, if there is a way to utilize this synergy for diversity and diversification,
[01:57:39.620 --> 01:57:47.220]   what happens if you ask a ChatGPT question, but it takes 10,000 years to answer that question?
[01:57:47.220 --> 01:57:52.980]   What does that look like when you completely switch the time scale
[01:57:52.980 --> 01:57:58.420]   and you can afford the time to answer the question?
[01:57:58.420 --> 01:58:05.300]   And again, I don't know, but that world to me is possibly amazing.
[01:58:06.340 --> 01:58:12.340]   Do you think there's--because when we start to think about time scales like this,
[01:58:12.340 --> 01:58:17.460]   just looking at Earth, all the possible trajectories it might take of this living
[01:58:17.460 --> 01:58:21.140]   organism that is Earth, do you think there's others like it?
[01:58:21.140 --> 01:58:24.580]   Do you think there's other planets with life forms on them that are just
[01:58:24.580 --> 01:58:27.220]   doing their thing in this kind of way?
[01:58:27.220 --> 01:58:35.380]   Because in what you're doing, you're directly playing with what's possible with life.
[01:58:36.340 --> 01:58:37.780]   Life-like things.
[01:58:37.780 --> 01:58:42.420]   That kind of maps the question of, well, what kind of other things are possible elsewhere?
[01:58:42.420 --> 01:58:49.540]   Do you think there's other worlds full of life, full of alien life out there?
[01:58:49.540 --> 01:58:59.460]   I've studied the calculations that point towards the verdict that the possibility of life in
[01:59:01.300 --> 01:59:03.780]   and around us is very, very low.
[01:59:03.780 --> 01:59:06.820]   We are a chosen planet in a way, right?
[01:59:06.820 --> 01:59:08.260]   There's water and there's love.
[01:59:08.260 --> 01:59:09.060]   What else do you need?
[01:59:09.060 --> 01:59:20.580]   And that sort of very peculiar juxtaposition of conditions, the oxygen, the water, the carbon,
[01:59:20.580 --> 01:59:30.340]   again, is in a way a miracle given the massive extinctions that we've been through.
[01:59:31.140 --> 01:59:38.420]   As life forms, and that said, I cannot believe that there is no other life form.
[01:59:38.420 --> 01:59:50.740]   I want to believe more than I know that yes, that there are life forms in the white fountain
[01:59:50.740 --> 01:59:53.220]   that is the black hole, right?
[01:59:53.220 --> 02:00:02.500]   That there are these life forms that are light years away from us that are forming other
[02:00:02.500 --> 02:00:03.940]   forms of life forces.
[02:00:03.940 --> 02:00:10.420]   - Yeah, I'm much more worried about probably the thing that you're working on, which is
[02:00:10.420 --> 02:00:17.220]   that there's all kinds of life out around us that we're not communicating with.
[02:00:17.220 --> 02:00:17.700]   - Yes.
[02:00:17.860 --> 02:00:23.860]   - There's aliens in a sense all around us that we're not seeing, that we're not talking
[02:00:23.860 --> 02:00:25.300]   to, that we're not communicating.
[02:00:25.300 --> 02:00:26.020]   - Yeah.
[02:00:26.020 --> 02:00:30.100]   - Because that to me just seems the more likely situation.
[02:00:30.100 --> 02:00:31.220]   - That they're here.
[02:00:31.220 --> 02:00:36.500]   - That they're here, they're all around us in different forms, that there is a connection.
[02:00:36.500 --> 02:00:43.140]   There's a thing that connects all of us, all of living beings across the universe.
[02:00:43.140 --> 02:00:47.060]   And we're just beginning to understand any of it.
[02:00:47.060 --> 02:00:51.620]   And I feel like that's the important problem is I feel like you can get there with the
[02:00:51.620 --> 02:00:54.740]   tools of science today by just studying life on earth.
[02:00:54.740 --> 02:01:00.020]   Unlock some really fundamental things that maybe you can start to answer questions about
[02:01:00.020 --> 02:01:01.060]   what is consciousness?
[02:01:01.060 --> 02:01:08.820]   Maybe this thing that we've been saying about love, but honestly in a serious way.
[02:01:08.820 --> 02:01:13.860]   And then you'll start to understand that there is alien life all out there.
[02:01:13.860 --> 02:01:21.540]   And it's much more complicated and interesting that we kind of realize as opposed to looking
[02:01:21.540 --> 02:01:24.500]   to human-like, exactly human-like things.
[02:01:24.500 --> 02:01:27.780]   It's the variety of life that's possible is just almost endless.
[02:01:27.780 --> 02:01:29.620]   - I totally agree with you.
[02:01:29.620 --> 02:01:35.060]   I think again define alien, right?
[02:01:35.060 --> 02:01:38.420]   - Yeah, define intelligence, define life.
[02:01:38.420 --> 02:01:39.780]   - Right, right.
[02:01:39.780 --> 02:01:43.220]   And Marvin Minsky used to say intelligence is a suitcase word.
[02:01:43.780 --> 02:01:45.300]   Right, it's a word so big.
[02:01:45.300 --> 02:01:49.860]   It's a word like sustainability and it's a word like rock and roll.
[02:01:49.860 --> 02:01:54.660]   And suitcase words are always very, very dangerous.
[02:01:54.660 --> 02:01:58.420]   - Speaking of rock and roll, you've mentioned music and you mentioned Beethoven a bunch
[02:01:58.420 --> 02:01:58.900]   of times.
[02:01:58.900 --> 02:02:04.980]   You've also tweeted about Evgeny Kisin performance and so on.
[02:02:04.980 --> 02:02:08.900]   What can you say about the role of music in your life?
[02:02:08.900 --> 02:02:11.060]   - I love music.
[02:02:12.340 --> 02:02:16.900]   I always wondered why is it that plastic arts, meaning architecture and sculpture and painting
[02:02:16.900 --> 02:02:23.060]   can't get us to cry and music gets us to cry so quickly and connect so quickly.
[02:02:23.060 --> 02:02:28.260]   There is something about music that it is, and no wonder that plants also respond to
[02:02:28.260 --> 02:02:28.900]   music.
[02:02:28.900 --> 02:02:33.380]   But that is the top of the creative pyramid in my opinion.
[02:02:33.380 --> 02:02:36.340]   - It's a weird mystery that we're so connected to music.
[02:02:36.340 --> 02:02:39.620]   Well, by the way, to push back, a good bridge will make me cry.
[02:02:39.620 --> 02:02:41.380]   - A good arch, it's true.
[02:02:41.380 --> 02:02:49.300]   And I will say when I visited the Sagrada Familia, I had that kind of spiritual reverence
[02:02:49.300 --> 02:02:55.300]   towards that spatial experience and being in that space and feeling the intention in
[02:02:55.300 --> 02:02:58.580]   the space and appreciating every little gesture.
[02:02:58.580 --> 02:02:59.620]   So it's true.
[02:02:59.620 --> 02:03:02.100]   It is the universal language.
[02:03:02.100 --> 02:03:05.700]   It's the language of waves, right?
[02:03:05.700 --> 02:03:09.300]   It's the language of the waves, not the language of the particles.
[02:03:09.300 --> 02:03:11.220]   It is the universal language, I believe.
[02:03:11.220 --> 02:03:16.020]   And that is definitely one of my loves.
[02:03:16.020 --> 02:03:22.180]   - And you said that if you weren't doing what you were doing now, perhaps you would be a
[02:03:22.180 --> 02:03:22.900]   film director.
[02:03:22.900 --> 02:03:26.900]   So I have to ask, what do you think is the best film of all time?
[02:03:26.900 --> 02:03:28.980]   Maybe top three.
[02:03:28.980 --> 02:03:32.260]   - Yeah, maybe "The Godfather."
[02:03:32.260 --> 02:03:33.780]   - "Godfather," okay.
[02:03:33.780 --> 02:03:36.580]   - "The Godfather" is definitely up there.
[02:03:36.580 --> 02:03:38.420]   Francis Coppola is one of my heroes.
[02:03:38.420 --> 02:03:39.780]   - Have you met him?
[02:03:39.780 --> 02:03:41.140]   - I have met him.
[02:03:41.140 --> 02:03:42.580]   Yes, yes, yes.
[02:03:42.580 --> 02:03:44.340]   I was very, very lucky.
[02:03:44.340 --> 02:03:49.300]   We were very lucky to work with him on his new film, "Ogallapolis," which is coming out,
[02:03:49.300 --> 02:03:50.660]   I hope, in 2024.
[02:03:50.660 --> 02:03:56.980]   And think about the cities of the future in the context of new materials and the unity
[02:03:56.980 --> 02:03:58.340]   between nature and culture.
[02:03:58.340 --> 02:04:00.660]   "Godfather" is definitely up there.
[02:04:00.660 --> 02:04:03.780]   "2001" is up there.
[02:04:03.780 --> 02:04:07.300]   I would watch that film again and again and again.
[02:04:08.260 --> 02:04:09.140]   It's incredible.
[02:04:09.140 --> 02:04:14.500]   The last scene in "Odyssey 2001," that's...
[02:04:14.500 --> 02:04:23.620]   Just watch the last scene of "2001," then listen to Yudkowsky, and then go to the garden,
[02:04:23.620 --> 02:04:27.860]   and that's pretty much the end and the beginning.
[02:04:27.860 --> 02:04:31.700]   But that scene, that last scene from "2001" is everything.
[02:04:31.700 --> 02:04:34.180]   It says so much with so little.
[02:04:34.820 --> 02:04:35.620]   And it leaves...
[02:04:35.620 --> 02:04:42.180]   It's sort of the embodiment, I believe, of ambivalence.
[02:04:42.180 --> 02:04:48.820]   And there's opportunity to believe in the beginning of humankind, the end of humankind,
[02:04:48.820 --> 02:04:53.860]   the planet, child, star, or star child of the future.
[02:04:53.860 --> 02:04:56.180]   Was there a death?
[02:04:56.180 --> 02:04:57.860]   Was there a reincarnation?
[02:05:00.180 --> 02:05:06.820]   That final scene, to me, is something that I go back to and study.
[02:05:06.820 --> 02:05:10.980]   And every time there is a different reading of that scene that inspires me.
[02:05:10.980 --> 02:05:13.380]   So that scene, it's just...
[02:05:13.380 --> 02:05:17.140]   And then the first scene in "The Godfather," still one of the best scenes of all times.
[02:05:17.140 --> 02:05:22.580]   Sort of a portrait of America, the ideals and values that are brought from Italy.
[02:05:22.580 --> 02:05:29.700]   A family of loyalty, of values, of how different values are constructed.
[02:05:29.700 --> 02:05:36.260]   Yes, loyalty and the human spirit and how Coppola celebrates the human spirit through
[02:05:36.260 --> 02:05:40.580]   the most simple gestures in language and acting.
[02:05:40.580 --> 02:05:49.460]   And I think in Kubrick, you see this highly curated and controlled and manicured vision
[02:05:49.460 --> 02:05:50.660]   of creating a film.
[02:05:50.660 --> 02:05:54.820]   And with Francis, it's like an Italian feast.
[02:05:54.820 --> 02:05:58.340]   It's like anything can happen at any moment in time.
[02:05:59.060 --> 02:06:06.980]   And just being on the set with him is an experience I'll take with me to my grave.
[02:06:06.980 --> 02:06:09.140]   It's very, very, very special.
[02:06:09.140 --> 02:06:12.980]   And you said music is also part of that, of creating a feeling in the movies.
[02:06:12.980 --> 02:06:13.780]   Yeah.
[02:06:13.780 --> 02:06:20.820]   Actually, the "Godfather," that tune...
[02:06:20.820 --> 02:06:24.900]   That makes me emotional every time on some weird level.
[02:06:24.900 --> 02:06:29.140]   Yeah, it's one of these tunes I'm sure that has...
[02:06:29.140 --> 02:06:37.940]   If you play it to a jazzman, you'll get the best scent of all time.
[02:06:37.940 --> 02:06:43.940]   But I think with that particular tune, I learned staccato.
[02:06:43.940 --> 02:06:47.380]   As something very, very happy and joyous.
[02:06:49.460 --> 02:06:56.260]   And then made into this stretched in time and became kind of the refrain of
[02:06:56.260 --> 02:07:04.100]   nostalgia and melancholy and loyalty and all of these values that ride on top of this one
[02:07:04.100 --> 02:07:04.820]   single tune.
[02:07:04.820 --> 02:07:07.300]   You can play it in all kinds of different ways.
[02:07:07.300 --> 02:07:09.620]   I've played on guitar in all kinds of different ways.
[02:07:09.620 --> 02:07:14.340]   And I think in "Godfather III," the son plays it on guitar to the father.
[02:07:14.340 --> 02:07:16.820]   I think this happens in movies.
[02:07:17.700 --> 02:07:21.700]   But sometimes a melody, and that's a simple melody, can just like...
[02:07:21.700 --> 02:07:24.980]   And the Strauss melody in 2001.
[02:07:24.980 --> 02:07:25.540]   Yeah.
[02:07:25.540 --> 02:07:34.740]   And when you juxtapose these melodies with the scene, you get this, again,
[02:07:34.740 --> 02:07:40.260]   whole that's bigger than some of its parts where you get this moment that is, I think...
[02:07:40.260 --> 02:07:46.260]   Like these are the moments I would send with the next Voyager to outer space.
[02:07:46.260 --> 02:07:54.180]   I definitely sent "The Godfather" in 2001 would definitely be on that golden record.
[02:07:54.180 --> 02:08:00.340]   You are an incredibly successful scientist, engineer, architect, artist, designer.
[02:08:00.340 --> 02:08:03.220]   You've mentored a lot of successful people.
[02:08:03.220 --> 02:08:09.780]   Can you give advice to young people listening to this, how to have a successful career
[02:08:09.780 --> 02:08:14.340]   and how to have a successful life?
[02:08:14.340 --> 02:08:19.300]   Look, I think there's this beautiful line in "Sheltering Sky."
[02:08:19.300 --> 02:08:25.940]   How many times have you seen a full moon in your life and actually took the time to
[02:08:25.940 --> 02:08:30.580]   ingest and explore and reflect upon the full moon?
[02:08:30.580 --> 02:08:32.420]   Probably 20, I believe he says.
[02:08:32.420 --> 02:08:36.340]   I spend time with a full moon.
[02:08:36.340 --> 02:08:40.180]   I take my time with a full moon.
[02:08:40.180 --> 02:08:43.460]   And I pay attention to a full moon.
[02:08:44.420 --> 02:08:53.460]   And I think paying attention to the seasons and taking time to appreciate
[02:08:53.460 --> 02:09:00.740]   the little things, the simple things is what makes a meaningful life.
[02:09:00.740 --> 02:09:08.340]   I was very lucky to have had, you know, to have grown up in a home that
[02:09:11.780 --> 02:09:13.060]   taught me this way of being.
[02:09:13.060 --> 02:09:19.700]   My parents, my grandmother, who played a very important role in my growing up.
[02:09:19.700 --> 02:09:32.820]   And that ability to pay attention and to be present is so, so, so, so.
[02:09:32.820 --> 02:09:35.860]   I could not emphasize it enough.
[02:09:35.860 --> 02:09:36.980]   It's so crucial.
[02:09:36.980 --> 02:09:40.020]   And be grateful.
[02:09:40.020 --> 02:09:41.380]   And be grateful.
[02:09:42.180 --> 02:09:53.060]   I think gratitude and presence, appreciation are really the most important things in life.
[02:09:53.060 --> 02:09:56.580]   If you could take a short tangent about your grandmother,
[02:09:56.580 --> 02:10:01.700]   who's played a big role in your life, what do you remember?
[02:10:01.700 --> 02:10:04.020]   What lessons have you learned from her?
[02:10:04.020 --> 02:10:09.140]   She had this blanket that she would give me every time I came back from school and say,
[02:10:09.140 --> 02:10:12.660]   you know, "Do your homework here and meet with your friends here."
[02:10:12.660 --> 02:10:14.020]   And it was always in her garden.
[02:10:14.020 --> 02:10:16.740]   And her garden, in my mind, was ginormous.
[02:10:16.740 --> 02:10:23.380]   But when I, you know, last I went there and saw the site, which has now become the site for another
[02:10:23.380 --> 02:10:32.420]   tall building, it was a tiny, tiny little garden that to me seemed so large when I was
[02:10:32.420 --> 02:10:35.540]   growing up, because it had everything.
[02:10:35.540 --> 02:10:42.980]   It had fig trees, it had olive trees, it had mushrooms, it had the blanket.
[02:10:42.980 --> 02:10:44.420]   I would do my homework there.
[02:10:44.420 --> 02:10:45.460]   It was everything.
[02:10:45.460 --> 02:10:47.620]   And I needed nothing, nothing else.
[02:10:47.620 --> 02:10:51.860]   And that was my Garden of Eden.
[02:10:51.860 --> 02:10:53.860]   That was my childhood.
[02:10:53.860 --> 02:11:00.100]   And she taught me, you know, we would lie on the blanket and look at the clouds and
[02:11:00.100 --> 02:11:03.460]   reflect upon the shapes of the clouds and study the shapes of the plants.
[02:11:03.460 --> 02:11:08.580]   And there was a lot of wonder in that childhood with her.
[02:11:08.580 --> 02:11:19.380]   And she taught me the importance of wonder in sort of, in an eternal childhood and living
[02:11:19.380 --> 02:11:22.340]   adulthood as a child.
[02:11:22.340 --> 02:11:25.220]   And so I'm very, very grateful for that.
[02:11:25.220 --> 02:11:27.060]   I think it is the sense of wonder.
[02:11:31.780 --> 02:11:38.100]   Speaking up was always something that she adhered to, to speak up your truth, to be
[02:11:38.100 --> 02:11:42.100]   straightforward, to be positive.
[02:11:42.100 --> 02:11:44.100]   These are things that I also got from my mom.
[02:11:44.100 --> 02:11:47.940]   And from my mom, the sense of humor.
[02:11:47.940 --> 02:11:56.740]   She had the best sense of humor that I could think of and was just a joy to be around.
[02:11:56.740 --> 02:12:00.180]   And my father taught me everything.
[02:12:00.180 --> 02:12:01.620]   My father taught me everything I know.
[02:12:01.620 --> 02:12:03.300]   My mom taught me everything I feel.
[02:12:03.300 --> 02:12:05.060]   - That's a good way to put it.
[02:12:05.060 --> 02:12:07.540]   - My grandma taught me everything I incite.
[02:12:07.540 --> 02:12:11.780]   - Well, I see the sense of wonder that just carries through everything you do.
[02:12:11.780 --> 02:12:15.700]   So I think you would, you make your grandmother proud.
[02:12:15.700 --> 02:12:20.500]   Well, what about advice for how to have a career?
[02:12:20.500 --> 02:12:27.700]   So you've had a very interesting career and a successful career, but not an easy one.
[02:12:27.700 --> 02:12:29.220]   You took a few leaps.
[02:12:29.380 --> 02:12:32.020]   I did take a few leaps and they were uncomfortable.
[02:12:32.020 --> 02:12:42.020]   My father, and I'll never forget, I think we were like listening to a Rolling Stones song
[02:12:42.020 --> 02:12:49.620]   in the kitchen and my dad, who was actually born in Boston, he's American, he said,
[02:12:49.620 --> 02:12:58.180]   I started to have sort of these second thoughts about continuing my education in Israel.
[02:12:58.180 --> 02:13:04.260]   And I wanted to go, I was on my way to London to the architectural association to do my diploma
[02:13:04.260 --> 02:13:04.900]   studies there.
[02:13:04.900 --> 02:13:09.380]   And he looked at me and he said, get out of here, kiddo.
[02:13:09.380 --> 02:13:10.740]   You got to get out of here.
[02:13:10.740 --> 02:13:14.340]   And you've outgrown where you're at.
[02:13:14.340 --> 02:13:16.580]   You need to move forward.
[02:13:16.580 --> 02:13:22.420]   Another thing he had taught me, the feeling of discomfort, as you say, the feeling of
[02:13:22.420 --> 02:13:28.660]   loneliness and discomfort is imperative to growth.
[02:13:28.660 --> 02:13:31.300]   Growth is painful, period.
[02:13:31.300 --> 02:13:35.140]   Any form of growth is difficult and painful.
[02:13:35.140 --> 02:13:37.300]   Birth is difficult and painful.
[02:13:37.300 --> 02:13:43.380]   And it is really, really important to place yourself in situations of discomfort.
[02:13:43.380 --> 02:13:47.060]   I like to be in a room where everyone in the room is more intelligent than me.
[02:13:47.060 --> 02:13:55.540]   I like to be in that kind of state where the people that I surround myself with are orders
[02:13:55.540 --> 02:13:58.580]   of magnitude more intelligent than I am.
[02:13:58.580 --> 02:14:01.780]   And I can say that that is true of all of my team members.
[02:14:01.780 --> 02:14:05.540]   And that's the intellectual discomfort that I feed off of.
[02:14:05.540 --> 02:14:08.980]   The same is true for physical exertion.
[02:14:10.340 --> 02:14:17.540]   You got to put yourself in these uncomfortable situations in order to grow, in order to find
[02:14:17.540 --> 02:14:18.040]   comfort.
[02:14:18.040 --> 02:14:33.300]   And then, on the other hand, is love, is finding love and finding that human, this other human
[02:14:33.300 --> 02:14:41.140]   that complements you and that makes you a better version of the one you are and even
[02:14:41.140 --> 02:14:43.060]   of the one you want to be.
[02:14:43.060 --> 02:14:50.580]   But with gratitude and attention and love, you can go so, so far.
[02:14:50.580 --> 02:14:55.220]   To the younger generation, I don't speak of a career.
[02:14:55.220 --> 02:15:01.220]   I never thought of my work as my career ever.
[02:15:01.220 --> 02:15:09.140]   And there was this constant entanglement between life and work and love and longing and being
[02:15:09.140 --> 02:15:09.860]   and mothering.
[02:15:09.860 --> 02:15:10.660]   It's all the same.
[02:15:10.660 --> 02:15:21.780]   And I appreciate that to some people that doesn't work in their arrangement of will
[02:15:21.780 --> 02:15:26.580]   versus comfort versus the reality.
[02:15:26.580 --> 02:15:28.580]   But for me, it has always worked.
[02:15:28.580 --> 02:15:35.140]   So I think to the younger generation, I say, don't think of your career.
[02:15:35.140 --> 02:15:37.380]   A career is something that is imposed upon you.
[02:15:37.380 --> 02:15:38.340]   Think of your calling.
[02:15:38.340 --> 02:15:44.660]   That's something that's innately and directionally moves you.
[02:15:44.660 --> 02:15:46.660]   And it's something that transcends a career.
[02:15:46.660 --> 02:15:52.900]   Similarly, you can think about the difference between, you know, learning versus being
[02:15:52.900 --> 02:15:53.380]   educated.
[02:15:53.380 --> 02:15:55.300]   Being educated is something that's given to you.
[02:15:55.300 --> 02:15:56.180]   That's external.
[02:15:56.180 --> 02:15:56.980]   That's being imposed.
[02:15:56.980 --> 02:15:58.100]   That's top-down imposed.
[02:15:58.500 --> 02:16:00.340]   This learning is something that comes from within.
[02:16:00.340 --> 02:16:03.380]   It's also the difference between joy and happiness.
[02:16:03.380 --> 02:16:06.340]   Many times I'm sad and I'm still joyous.
[02:16:06.340 --> 02:16:13.940]   And it's very, very important to understand the difference between these externally perceived
[02:16:13.940 --> 02:16:22.340]   success paths and internally driven, value-based, you know, ways of being in the world.
[02:16:22.340 --> 02:16:30.740]   And we, together, when we combine all of these, you know, all of these, the broken puzzle,
[02:16:30.740 --> 02:16:40.820]   let's say, of substance and vulnerability, we get this bigger gestalt, this wondrous
[02:16:40.820 --> 02:16:52.340]   world of a future that is peaceful, that is, you know, that is wholesome, and that, you
[02:16:52.340 --> 02:16:57.140]   know, that proposes or, you know, advocates for that kind of synergy that we've been talking
[02:16:57.140 --> 02:16:57.940]   about throughout.
[02:16:57.940 --> 02:16:59.700]   But it's all fun.
[02:16:59.700 --> 02:17:03.940]   >> AJ: Well, thank you for this incredible conversation.
[02:17:03.940 --> 02:17:05.780]   Thank you for all the work you're doing.
[02:17:05.780 --> 02:17:11.380]   And I just have to say that thank you for noticing me and listening to me.
[02:17:11.380 --> 02:17:17.780]   You're somebody from just today and from our exchanges before this, like there's a
[02:17:17.780 --> 02:17:23.380]   sense where you care about me as a human being, which I could tell you care about other humans.
[02:17:23.380 --> 02:17:24.980]   Thank you for doing that.
[02:17:24.980 --> 02:17:31.460]   Thank you for having empathy and just like, yeah, really listening and noticing me, that
[02:17:31.460 --> 02:17:32.180]   I exist.
[02:17:32.180 --> 02:17:33.620]   So thank you for that.
[02:17:33.620 --> 02:17:38.260]   I've been a huge fan of your work, been a huge fan of who you are as a human being.
[02:17:38.260 --> 02:17:40.260]   It's just an honor that you would sit with me.
[02:17:40.260 --> 02:17:40.740]   Thank you.
[02:17:40.740 --> 02:17:42.660]   >> NERI: Thank you so much, Lex.
[02:17:42.660 --> 02:17:43.700]   I feel the same way.
[02:17:43.700 --> 02:17:45.700]   I'll just say the same.
[02:17:45.700 --> 02:17:49.380]   >> LEX: And I look forward to hearing the response to my job application that I've
[02:17:49.380 --> 02:17:49.700]   submitted.
[02:17:49.700 --> 02:17:51.220]   >> NERI: Oh, you're accepted.
[02:17:51.220 --> 02:17:52.180]   >> LEX: Oh, damn.
[02:17:52.180 --> 02:17:52.580]   All right.
[02:17:52.580 --> 02:17:52.820]   Excellent.
[02:17:52.820 --> 02:17:54.340]   >> NERI: We all speak of you all the time.
[02:17:54.340 --> 02:17:55.540]   >> LEX: Thank you so much.
[02:17:55.540 --> 02:17:56.180]   Thank you, Neri.
[02:17:56.180 --> 02:17:56.500]   >> NERI: Thank you, Lex.
[02:17:56.500 --> 02:17:56.980]   Thank you.
[02:17:56.980 --> 02:18:00.660]   >> AJ: Thanks for listening to this conversation with Neri Aksman.
[02:18:00.660 --> 02:18:04.020]   To support this podcast, please check out our sponsors in the description.
[02:18:04.020 --> 02:18:07.860]   And now let me leave you with some words from Leo Tolstoy.
[02:18:07.860 --> 02:18:12.180]   "Everything I know, I know because of love."
[02:18:12.180 --> 02:18:14.500]   Thank you for listening.
[02:18:14.500 --> 02:18:16.340]   I hope to see you next time.
[02:18:16.500 --> 02:18:16.580]   [END]
[02:18:17.540 --> 02:18:18.580]   Leo Tolstoy - www.leo.com/podcast
[02:18:19.140 --> 02:18:19.220]   [END]
[02:18:20.180 --> 02:18:22.180]   Leo Tolstoy - www.leo.com/podcast
[02:18:22.180 --> 02:18:32.180]   [BLANK_AUDIO]

