
[00:00:00.000 --> 00:00:16.240]   Thank you for sticking around in here, I suppose.
[00:00:16.240 --> 00:00:18.220]   It'd probably be the most apropos thing to say.
[00:00:18.220 --> 00:00:20.540]   Thank you for joining me today.
[00:00:20.540 --> 00:00:23.760]   I wanted to talk a little bit about how all of this technology
[00:00:23.760 --> 00:00:25.980]   actually gets into the path of value
[00:00:25.980 --> 00:00:29.640]   inside large organizations and large businesses.
[00:00:29.640 --> 00:00:34.420]   As it would turn out, the ability for us to go prototype cool stuff
[00:00:34.420 --> 00:00:37.800]   versus us go and deliver these things into the critical path
[00:00:37.800 --> 00:00:39.120]   can vary widely.
[00:00:39.120 --> 00:00:39.760]   I'm Craig.
[00:00:39.760 --> 00:00:42.280]   I lead product management for Databricks,
[00:00:42.280 --> 00:00:44.040]   in case you hadn't figured that yet.
[00:00:44.040 --> 00:00:46.600]   Been with Databricks for about three years.
[00:00:46.600 --> 00:00:49.660]   Before that was at Google, where I was the leader of product
[00:00:49.660 --> 00:00:51.840]   for the founding of Vertex AI,
[00:00:51.840 --> 00:00:55.800]   and before that I was the founding general manager of AWS SageMaker.
[00:00:55.800 --> 00:00:59.920]   So I've been, as my wife says, continuing to strike out
[00:00:59.920 --> 00:01:04.160]   as I try and get better and better at helping enterprises build AI.
[00:01:04.160 --> 00:01:07.000]   But as we dive into this,
[00:01:07.000 --> 00:01:11.140]   I wanted to quickly just set a little bit of context on who Databricks,
[00:01:11.140 --> 00:01:14.360]   why Databricks, and why is Databricks here talking to you,
[00:01:14.360 --> 00:01:14.940]   and what have you.
[00:01:15.340 --> 00:01:21.020]   We are a leading data platform, cross-cloud data platform,
[00:01:21.020 --> 00:01:26.240]   tens of thousands of customers, billions of dollars in revenue,
[00:01:26.240 --> 00:01:29.280]   and moreover, the creator of a number of open source,
[00:01:29.280 --> 00:01:31.340]   very popular open source capabilities,
[00:01:31.340 --> 00:01:34.720]   Spark, MLflow, Delta, et cetera.
[00:01:36.120 --> 00:01:39.560]   You know, we live in a world, Brad just a minute ago,
[00:01:39.560 --> 00:01:41.880]   he talked about the importance of the model
[00:01:41.880 --> 00:01:44.420]   and then the data you bring to the model.
[00:01:44.420 --> 00:01:49.540]   And the enterprises we work with have a kind of nightmarish data scenario
[00:01:49.540 --> 00:01:53.940]   because, you know, you talk to these large multinational banks
[00:01:53.940 --> 00:01:54.980]   or something like that,
[00:01:54.980 --> 00:02:00.940]   and they've done dozens, if not scores of acquisitions over the years,
[00:02:00.940 --> 00:02:05.260]   and they have data on every cloud, in every possible vendor,
[00:02:05.260 --> 00:02:06.820]   in every possible service,
[00:02:06.820 --> 00:02:09.000]   and they're trying at this moment
[00:02:09.000 --> 00:02:12.140]   to figure out how to take advantage
[00:02:12.140 --> 00:02:16.980]   of this kind of transformational technological moment,
[00:02:16.980 --> 00:02:21.140]   but they're doing it with kind of a mess in the back end, if you will, right?
[00:02:21.140 --> 00:02:23.860]   And it turns out the problem is actually much worse than this
[00:02:23.860 --> 00:02:26.540]   because it's not like they just have one data warehouse
[00:02:26.540 --> 00:02:27.500]   or something like that.
[00:02:27.500 --> 00:02:29.540]   They often have many of them, right?
[00:02:29.540 --> 00:02:33.620]   And often the experts in one or two of these systems
[00:02:33.620 --> 00:02:36.360]   are only experts in one or two of these systems,
[00:02:36.360 --> 00:02:38.240]   and they don't know the other systems.
[00:02:38.240 --> 00:02:40.740]   So if you're stuck in your data warehouse
[00:02:40.740 --> 00:02:43.800]   or your streaming person isn't a Gen AI person,
[00:02:43.800 --> 00:02:46.180]   you may find yourself kind of locked out
[00:02:46.180 --> 00:02:50.720]   of being able to bring your data into these systems
[00:02:50.720 --> 00:02:51.840]   as easily as you want to.
[00:02:51.840 --> 00:02:53.980]   Now, I'm not going to go head on into Databricks.
[00:02:53.980 --> 00:02:56.900]   Databricks, ultimately, we help you manage your data,
[00:02:56.900 --> 00:02:59.520]   and then on top of that management of your data,
[00:02:59.520 --> 00:03:01.360]   we have a whole series of capabilities.
[00:03:01.360 --> 00:03:05.980]   I'm going to really focus on our AI capabilities with Mosaic AI today.
[00:03:06.480 --> 00:03:12.700]   Now, we think of this as a difference between what we call general intelligence
[00:03:12.700 --> 00:03:13.940]   and data intelligence.
[00:03:13.940 --> 00:03:20.000]   Both of these things are extraordinarily useful and extraordinarily important.
[00:03:20.000 --> 00:03:27.000]   But as Brad talked about, particularly for businesses or large enterprises,
[00:03:27.000 --> 00:03:32.560]   as they want to move into using this technology to automate more of their systems
[00:03:32.560 --> 00:03:35.780]   or drive greater insights within their organization,
[00:03:35.780 --> 00:03:39.780]   almost always it comes back to connecting it.
[00:03:39.780 --> 00:03:44.480]   We saw here Brad connecting it to the web or connecting it to MCP servers,
[00:03:44.480 --> 00:03:49.560]   but inevitably it comes back to trying to connect it to their data estate, right?
[00:03:49.720 --> 00:03:52.820]   So for a really good example of this, FactSet.
[00:03:52.820 --> 00:03:54.300]   I don't know if you guys have heard of FactSet.
[00:03:54.300 --> 00:03:59.420]   FactSet is a financial services company that sells data about other companies.
[00:03:59.420 --> 00:04:04.080]   They sell financial data about companies to banks and hedge funds and what have you.
[00:04:04.080 --> 00:04:07.560]   FactSet has their own query language,
[00:04:07.560 --> 00:04:12.900]   which is now a yellow flag to me when considering employers.
[00:04:12.900 --> 00:04:15.460]   If your employer has their own query language,
[00:04:15.460 --> 00:04:19.540]   you've got to think about whether or not this is the right place to be.
[00:04:19.540 --> 00:04:21.160]   Having said that, I did work at Google,
[00:04:21.160 --> 00:04:23.600]   who I think probably has a dozen of their own query languages.
[00:04:23.600 --> 00:04:28.060]   So FactSet had this problem and opportunity,
[00:04:28.060 --> 00:04:32.380]   which is that any customer they had who wanted to access their data,
[00:04:32.380 --> 00:04:37.740]   they had to learn FQL, FactSet Query Language, creative name in there.
[00:04:37.740 --> 00:04:41.360]   And so when this whole Gen.AI craze started,
[00:04:41.460 --> 00:04:43.160]   these guys lost their minds with excitement
[00:04:43.160 --> 00:04:43.860]   because they thought,
[00:04:43.860 --> 00:04:48.660]   what if we could translate English into FactSet query language?
[00:04:48.660 --> 00:04:51.580]   And so they went to their favorite cloud of choice.
[00:04:51.580 --> 00:04:54.600]   They hit the one-click rag button.
[00:04:54.600 --> 00:04:57.160]   I think they did a little more than the one-click rag button,
[00:04:57.160 --> 00:05:00.900]   but they basically showed up with this massive prompt
[00:05:00.900 --> 00:05:03.900]   of a bunch of examples and a bunch of documentation
[00:05:03.900 --> 00:05:07.660]   and then a massive VectorDB of a bunch of prompts
[00:05:07.660 --> 00:05:10.680]   and a bunch of documentation or a bunch of examples
[00:05:10.680 --> 00:05:11.780]   and a bunch of documentation.
[00:05:11.780 --> 00:05:14.560]   And this is what they ended up with, right?
[00:05:14.560 --> 00:05:20.340]   They ended up with 59% accuracy in about 15 seconds of latency.
[00:05:20.340 --> 00:05:22.540]   And I share with you that latency metric,
[00:05:22.540 --> 00:05:27.340]   not just because it's an important customer experience metric
[00:05:27.340 --> 00:05:28.480]   and all of these kinds of things,
[00:05:28.480 --> 00:05:30.040]   but in this world of Gen.AI,
[00:05:30.040 --> 00:05:33.920]   it's probably the closest thing we have to a cost metric, right?
[00:05:33.920 --> 00:05:35.700]   You're more or less paying for compute time.
[00:05:35.700 --> 00:05:39.560]   And so that 15 seconds is basically 15 seconds of cost, right?
[00:05:39.560 --> 00:05:41.340]   And 59% accuracy.
[00:05:41.340 --> 00:05:43.200]   With this, they showed up,
[00:05:43.200 --> 00:05:44.560]   they contacted us and said,
[00:05:44.560 --> 00:05:45.940]   hey, good news.
[00:05:45.940 --> 00:05:48.160]   We've got a Gen.AI solution.
[00:05:48.160 --> 00:05:49.500]   Bad news.
[00:05:49.500 --> 00:05:53.180]   It's just slightly better than a coin flip kind of thing, right?
[00:05:53.440 --> 00:05:56.580]   And so we worked with them on this problem
[00:05:56.580 --> 00:06:00.600]   and tried to understand what the opportunity was,
[00:06:00.600 --> 00:06:01.440]   what the challenge was.
[00:06:01.440 --> 00:06:05.780]   And really what we did was we just decomposed the prompt
[00:06:05.780 --> 00:06:09.740]   into each of the individual tasks
[00:06:09.740 --> 00:06:12.380]   that that prompt was being asked to use, right?
[00:06:12.380 --> 00:06:15.340]   So effectively what we did was we took that prompt
[00:06:15.340 --> 00:06:18.100]   and created kind of something of an agent,
[00:06:18.100 --> 00:06:22.300]   a multi-node, a multi-step chain or process
[00:06:22.300 --> 00:06:25.120]   to be able to solve this problem more wholly.
[00:06:25.120 --> 00:06:28.520]   And really the reason we did that was
[00:06:28.520 --> 00:06:30.780]   because it allowed us the opportunity
[00:06:30.780 --> 00:06:32.420]   to start tuning performance
[00:06:32.420 --> 00:06:35.820]   at each step of this problem, right?
[00:06:35.820 --> 00:06:38.760]   And you can see we got them to 85% accuracy
[00:06:38.760 --> 00:06:40.320]   in six seconds of latency.
[00:06:40.320 --> 00:06:43.940]   At 85% accuracy, they did two things.
[00:06:43.940 --> 00:06:45.440]   They turned to us and they said,
[00:06:45.440 --> 00:06:47.540]   cool, we're comfortable showing this
[00:06:47.540 --> 00:06:48.820]   to our existing customers.
[00:06:48.820 --> 00:06:52.320]   And they said, we get how you're helping us.
[00:06:52.320 --> 00:06:54.320]   We don't want to pay you to help us anymore.
[00:06:54.320 --> 00:06:55.640]   We'll take it from here.
[00:06:55.640 --> 00:06:58.820]   Last I talked to them, they had it into the 90s.
[00:06:58.820 --> 00:07:00.200]   And last I talked to them,
[00:07:00.200 --> 00:07:04.980]   transitioning to Claude was one of their next roadmap items.
[00:07:04.980 --> 00:07:07.620]   The reason I say all of this
[00:07:07.620 --> 00:07:09.440]   is because there's a paper out there
[00:07:09.440 --> 00:07:13.240]   from the Berkeley Artificial Intelligence Research Lab,
[00:07:13.240 --> 00:07:15.520]   which if you look into it,
[00:07:15.520 --> 00:07:17.460]   yes, there's a little bit of cross-pollination
[00:07:17.460 --> 00:07:19.280]   between us and Berkeley.
[00:07:19.280 --> 00:07:23.100]   But basically the folks at Berkeley did a,
[00:07:23.100 --> 00:07:26.420]   right after Gen.ai kind of really hit its stride,
[00:07:26.420 --> 00:07:29.840]   they went out and they looked at all the popular AI systems
[00:07:29.840 --> 00:07:31.920]   that are out in production today.
[00:07:32.620 --> 00:07:36.800]   And what they found was that none of these systems
[00:07:36.800 --> 00:07:42.580]   were as easy as kind of a single input
[00:07:42.580 --> 00:07:45.880]   and a single output kind of basic system.
[00:07:45.880 --> 00:07:50.140]   These systems were all kind of very complex,
[00:07:50.140 --> 00:07:53.600]   multi-node, kind of multi-part systems
[00:07:53.600 --> 00:07:54.860]   that were being chained together
[00:07:54.860 --> 00:07:56.700]   to create really fantastic outcomes.
[00:07:57.200 --> 00:07:59.360]   So our goal at Databricks
[00:07:59.360 --> 00:08:01.780]   is really to simplify the creation
[00:08:01.780 --> 00:08:03.780]   of these kinds of capabilities
[00:08:03.780 --> 00:08:05.440]   for our customers.
[00:08:05.440 --> 00:08:07.680]   But very specifically,
[00:08:07.680 --> 00:08:10.300]   we want to do it on the areas
[00:08:10.300 --> 00:08:12.740]   where there is financial and reputational risk.
[00:08:12.740 --> 00:08:14.020]   If what you're wanting to do
[00:08:14.020 --> 00:08:16.340]   is build a chatbot for you and your buddies
[00:08:16.340 --> 00:08:20.200]   to kind of search over your documents
[00:08:20.200 --> 00:08:23.160]   or your emails or what have you,
[00:08:23.160 --> 00:08:25.140]   your recent PRDs in my case,
[00:08:25.140 --> 00:08:27.000]   great, go for it.
[00:08:27.000 --> 00:08:30.260]   One click rag away at that thing,
[00:08:30.260 --> 00:08:32.320]   kind of, or prompt away at that thing.
[00:08:32.320 --> 00:08:34.440]   But if what you want to do is build something
[00:08:34.440 --> 00:08:37.280]   that you trust putting into a situation
[00:08:37.280 --> 00:08:38.880]   of financial or reputational risk,
[00:08:38.880 --> 00:08:40.720]   then it takes some additional capabilities.
[00:08:40.720 --> 00:08:41.880]   And not only that,
[00:08:41.880 --> 00:08:43.700]   but one of the things we see,
[00:08:43.700 --> 00:08:45.020]   and I'm sure you've seen this as well,
[00:08:45.020 --> 00:08:47.200]   is that many of the folks out there
[00:08:47.200 --> 00:08:48.880]   who are developing these systems,
[00:08:48.880 --> 00:08:52.140]   they're trying to develop
[00:08:52.140 --> 00:08:53.540]   deterministic systems
[00:08:53.540 --> 00:08:56.380]   using the most probabilistic portion
[00:08:56.380 --> 00:08:59.080]   of their entire software stack, right?
[00:08:59.080 --> 00:09:01.740]   And so one of the pieces of this
[00:09:01.740 --> 00:09:04.740]   is how do we help them drive those levels of,
[00:09:04.740 --> 00:09:06.880]   consistently drive those levels
[00:09:06.880 --> 00:09:08.520]   of repeatable determinism?
[00:09:08.520 --> 00:09:10.620]   And we think it comes down to two things.
[00:09:10.620 --> 00:09:12.700]   All else being equal,
[00:09:12.700 --> 00:09:14.240]   we think it comes down to governance,
[00:09:14.240 --> 00:09:16.140]   making sure you can control
[00:09:16.140 --> 00:09:17.520]   at the tightest levels,
[00:09:17.520 --> 00:09:18.640]   at the lowest grain,
[00:09:18.640 --> 00:09:21.160]   what this thing has access to and can do.
[00:09:21.160 --> 00:09:23.300]   And then evaluation.
[00:09:23.300 --> 00:09:25.460]   I was super excited.
[00:09:25.460 --> 00:09:27.280]   I met with a company this morning,
[00:09:27.280 --> 00:09:29.120]   a global logistics provider this morning,
[00:09:29.120 --> 00:09:30.940]   and it was one of the first times
[00:09:30.940 --> 00:09:32.780]   I had met with a customer who said,
[00:09:32.780 --> 00:09:34.120]   hey, we built this system,
[00:09:34.120 --> 00:09:36.320]   and it's like 85% accurate.
[00:09:36.320 --> 00:09:38.400]   And it was such a joy,
[00:09:38.400 --> 00:09:39.680]   because usually people say,
[00:09:39.680 --> 00:09:40.620]   hey, we built this system,
[00:09:40.620 --> 00:09:41.400]   we have it in production,
[00:09:41.400 --> 00:09:42.420]   we're super proud of it.
[00:09:42.420 --> 00:09:43.980]   And I say, how accurate is it?
[00:09:43.980 --> 00:09:45.040]   And they go, oh, it's pretty good.
[00:09:45.080 --> 00:09:49.100]   And so being able to really start to quantify
[00:09:49.100 --> 00:09:50.160]   and hill climb that,
[00:09:50.160 --> 00:09:51.140]   we believe is critical.
[00:09:51.140 --> 00:09:52.740]   So governance, what are we talking about?
[00:09:52.740 --> 00:09:55.740]   We're talking about really governing the access,
[00:09:55.740 --> 00:09:57.640]   treating these agents,
[00:09:57.640 --> 00:10:00.480]   or these prototype agents we're building,
[00:10:00.480 --> 00:10:03.780]   as principles within our data stack,
[00:10:03.780 --> 00:10:07.200]   and governing every single aspect of that.
[00:10:07.300 --> 00:10:08.180]   Now, on Databricks,
[00:10:08.180 --> 00:10:10.860]   we don't just govern your data.
[00:10:10.860 --> 00:10:14.780]   We also govern access to the models, right?
[00:10:14.780 --> 00:10:17.660]   And we govern tools, right?
[00:10:17.660 --> 00:10:19.140]   And we govern queries.
[00:10:19.140 --> 00:10:20.740]   So we govern access to the data,
[00:10:20.740 --> 00:10:22.220]   we govern access to the models,
[00:10:22.220 --> 00:10:23.080]   we govern access,
[00:10:23.080 --> 00:10:24.160]   all of the pieces.
[00:10:24.160 --> 00:10:27.840]   There is one piece we don't yet govern,
[00:10:27.840 --> 00:10:28.820]   yet,
[00:10:28.820 --> 00:10:30.760]   is MCP servers.
[00:10:31.300 --> 00:10:32.340]   But stick with us.
[00:10:32.340 --> 00:10:33.620]   We have a conference in a few weeks.
[00:10:33.620 --> 00:10:34.940]   You might come check it out.
[00:10:34.940 --> 00:10:37.320]   And hopefully, we'll have news for you there.
[00:10:37.320 --> 00:10:41.040]   So how do we get all of this to reason over your data?
[00:10:41.040 --> 00:10:42.460]   And, you know,
[00:10:42.460 --> 00:10:45.220]   we do that by injecting it with either the vector store
[00:10:45.220 --> 00:10:46.860]   or the feature store.
[00:10:46.860 --> 00:10:49.140]   And then we, as I said,
[00:10:49.140 --> 00:10:50.540]   we govern all of the aspects,
[00:10:50.540 --> 00:10:51.580]   whether it's the data,
[00:10:51.580 --> 00:10:52.220]   the models,
[00:10:52.220 --> 00:10:52.880]   the tools.
[00:10:52.880 --> 00:10:54.420]   And I want to stop for a second
[00:10:54.420 --> 00:10:56.320]   and talk about tools and tool calling.
[00:10:56.320 --> 00:10:59.000]   Because we saw some of it just a second ago
[00:10:59.000 --> 00:10:59.880]   in Brad's demos.
[00:10:59.880 --> 00:11:01.520]   And tool calling,
[00:11:01.520 --> 00:11:03.460]   when it comes to trying to build
[00:11:03.460 --> 00:11:05.720]   a deterministic system,
[00:11:05.720 --> 00:11:08.940]   usually what we actually see
[00:11:08.940 --> 00:11:11.440]   is we see someone building,
[00:11:12.820 --> 00:11:15.600]   using an LLM as a classifier
[00:11:15.600 --> 00:11:19.080]   to choose one of six or eight paths,
[00:11:19.080 --> 00:11:19.920]   right?
[00:11:19.920 --> 00:11:21.140]   One of six or eight tools.
[00:11:21.140 --> 00:11:23.080]   And those tools may be agents.
[00:11:23.080 --> 00:11:24.760]   Those tools may be SQL queries.
[00:11:24.760 --> 00:11:26.320]   Those tools are any sort of
[00:11:26.320 --> 00:11:28.420]   parameterizable function kind of thing, right?
[00:11:28.420 --> 00:11:31.240]   So we see them creating access to these tools.
[00:11:31.240 --> 00:11:33.460]   And then what do we see?
[00:11:33.460 --> 00:11:34.820]   We often see the next layer,
[00:11:34.820 --> 00:11:38.260]   another set of agents
[00:11:38.260 --> 00:11:41.240]   choosing between a set of tools.
[00:11:41.240 --> 00:11:42.340]   And so they end up
[00:11:42.340 --> 00:11:44.020]   with this massive decision tree,
[00:11:44.020 --> 00:11:45.000]   which is great
[00:11:45.000 --> 00:11:46.880]   from a kind of deterministic perspective
[00:11:46.880 --> 00:11:49.320]   on really reducing the entropy
[00:11:49.320 --> 00:11:50.180]   in these systems.
[00:11:50.180 --> 00:11:52.040]   The challenge for us
[00:11:52.040 --> 00:11:54.340]   was that before we had
[00:11:54.340 --> 00:11:55.960]   this relationship with Anthropic,
[00:11:55.960 --> 00:11:57.880]   we were talking to people
[00:11:57.880 --> 00:11:58.840]   about this stuff.
[00:11:58.840 --> 00:12:00.540]   But the tool calling
[00:12:00.540 --> 00:12:02.860]   just wasn't where it was needed to be.
[00:12:02.860 --> 00:12:04.260]   You would have these moments
[00:12:04.260 --> 00:12:06.260]   where it would be unbelievably obvious
[00:12:06.260 --> 00:12:07.640]   what tools should be called.
[00:12:07.640 --> 00:12:09.500]   and the models would consistently
[00:12:09.500 --> 00:12:10.420]   not necessarily,
[00:12:10.420 --> 00:12:11.700]   well, would consistently
[00:12:11.700 --> 00:12:13.020]   not get it right.
[00:12:13.020 --> 00:12:15.280]   With Claude,
[00:12:15.280 --> 00:12:18.440]   that has changed completely, right?
[00:12:18.440 --> 00:12:19.700]   We now see
[00:12:19.700 --> 00:12:21.880]   the ability for these systems
[00:12:21.880 --> 00:12:23.200]   to do tool calling
[00:12:23.200 --> 00:12:25.220]   really becomes
[00:12:25.220 --> 00:12:26.980]   the way in which
[00:12:26.980 --> 00:12:29.160]   software development engineers
[00:12:29.160 --> 00:12:31.280]   and app engineers
[00:12:31.280 --> 00:12:33.400]   can start building
[00:12:33.400 --> 00:12:35.960]   these quasi-deterministic systems
[00:12:35.960 --> 00:12:38.780]   using a highly probabilistic backend.
[00:12:38.780 --> 00:12:40.540]   Claude really in many ways
[00:12:40.540 --> 00:12:42.580]   completes this puzzle for us
[00:12:42.580 --> 00:12:43.540]   by giving us
[00:12:43.540 --> 00:12:45.000]   that frontier LLM
[00:12:45.000 --> 00:12:46.280]   available directly
[00:12:46.280 --> 00:12:47.500]   inside Databricks
[00:12:47.500 --> 00:12:49.920]   that has all
[00:12:49.920 --> 00:12:51.360]   of the capabilities needed
[00:12:51.360 --> 00:12:52.780]   to really superpower
[00:12:52.780 --> 00:12:54.200]   the use cases
[00:12:54.200 --> 00:12:54.900]   that our customers
[00:12:54.900 --> 00:12:55.740]   are putting together.
[00:12:55.740 --> 00:12:57.140]   So why Claude
[00:12:57.140 --> 00:12:58.220]   and Databricks together?
[00:12:58.220 --> 00:12:58.880]   First of all,
[00:12:58.880 --> 00:13:00.260]   Claude is natively available
[00:13:00.260 --> 00:13:01.040]   on Databricks
[00:13:01.040 --> 00:13:03.140]   on any cloud, right?
[00:13:03.140 --> 00:13:03.800]   So on Azure,
[00:13:03.800 --> 00:13:04.460]   on AWS,
[00:13:04.460 --> 00:13:05.140]   on GCP,
[00:13:05.140 --> 00:13:06.660]   you can call Claude
[00:13:06.660 --> 00:13:08.080]   within your Databricks instance.
[00:13:08.080 --> 00:13:09.220]   You can build
[00:13:09.220 --> 00:13:10.940]   state-of-the-art agents
[00:13:10.940 --> 00:13:11.740]   on Databricks
[00:13:11.740 --> 00:13:12.520]   powered by Claude,
[00:13:12.520 --> 00:13:13.540]   and then fundamentally
[00:13:13.540 --> 00:13:15.140]   you can connect Claude.
[00:13:15.140 --> 00:13:15.580]   You know,
[00:13:15.580 --> 00:13:16.420]   the vast majority
[00:13:16.420 --> 00:13:17.860]   of folks who are using Databricks
[00:13:17.860 --> 00:13:19.420]   are much lower-level
[00:13:19.420 --> 00:13:20.260]   data engineers
[00:13:20.260 --> 00:13:20.960]   and what have you,
[00:13:20.960 --> 00:13:21.660]   building out
[00:13:21.660 --> 00:13:23.260]   kind of massive schemas
[00:13:23.260 --> 00:13:23.840]   and building out
[00:13:23.840 --> 00:13:25.200]   massive governance policies,
[00:13:25.200 --> 00:13:26.160]   systems,
[00:13:26.160 --> 00:13:26.940]   and what have you.
[00:13:27.120 --> 00:13:28.640]   and you can use Claude
[00:13:28.640 --> 00:13:30.620]   as a principle
[00:13:30.620 --> 00:13:32.760]   within that system,
[00:13:32.760 --> 00:13:33.380]   right?
[00:13:33.380 --> 00:13:34.480]   And as you can see,
[00:13:34.480 --> 00:13:36.620]   including MCP servers
[00:13:36.620 --> 00:13:37.820]   coming soon.
[00:13:37.820 --> 00:13:40.840]   So why use it with us,
[00:13:40.840 --> 00:13:41.080]   right?
[00:13:41.080 --> 00:13:41.560]   Well,
[00:13:41.560 --> 00:13:42.440]   it really comes down
[00:13:42.440 --> 00:13:43.720]   to really pairing
[00:13:43.720 --> 00:13:45.080]   the strongest model
[00:13:45.080 --> 00:13:46.640]   with the strongest platform,
[00:13:46.640 --> 00:13:47.640]   using it
[00:13:47.640 --> 00:13:48.800]   in a fully controlled,
[00:13:48.800 --> 00:13:49.040]   right?
[00:13:49.040 --> 00:13:49.480]   You know,
[00:13:49.480 --> 00:13:50.040]   when you talk
[00:13:50.040 --> 00:13:50.780]   to these companies,
[00:13:50.780 --> 00:13:51.720]   I was sitting
[00:13:51.720 --> 00:13:53.020]   at a collection
[00:13:53.020 --> 00:13:54.660]   of banks recently.
[00:13:54.660 --> 00:13:56.720]   There were 10 or 12 banks
[00:13:56.720 --> 00:13:57.340]   at the table.
[00:13:57.340 --> 00:13:58.440]   We were all talking
[00:13:58.440 --> 00:13:59.660]   about what they were working on.
[00:13:59.660 --> 00:14:01.280]   I think more than half
[00:14:01.280 --> 00:14:02.560]   the banks in the room
[00:14:02.560 --> 00:14:04.220]   were prototyping
[00:14:04.220 --> 00:14:04.860]   on Claude
[00:14:04.860 --> 00:14:05.640]   as we spoke.
[00:14:05.640 --> 00:14:06.980]   One of the banks
[00:14:06.980 --> 00:14:07.720]   did raise their hand
[00:14:07.720 --> 00:14:08.040]   and said,
[00:14:08.040 --> 00:14:08.760]   we're not allowed
[00:14:08.760 --> 00:14:09.600]   to use any of this
[00:14:09.600 --> 00:14:10.380]   generative stuff
[00:14:10.380 --> 00:14:11.180]   in this industry,
[00:14:11.180 --> 00:14:13.260]   of which he was laughed at
[00:14:13.260 --> 00:14:14.400]   by the others in the room
[00:14:14.400 --> 00:14:15.020]   who were working
[00:14:15.020 --> 00:14:15.940]   on these things.
[00:14:15.940 --> 00:14:18.400]   And the real difference
[00:14:18.400 --> 00:14:19.380]   was what that guy
[00:14:19.380 --> 00:14:20.180]   was saying was,
[00:14:20.180 --> 00:14:20.580]   hey,
[00:14:20.580 --> 00:14:21.080]   we don't have
[00:14:21.080 --> 00:14:22.920]   the controls in place
[00:14:22.920 --> 00:14:23.940]   to use this
[00:14:23.940 --> 00:14:25.240]   within our own organization,
[00:14:25.240 --> 00:14:26.560]   whereas the banks,
[00:14:26.560 --> 00:14:27.200]   the hospitals,
[00:14:27.200 --> 00:14:28.660]   the other highly governed,
[00:14:28.660 --> 00:14:29.900]   highly regulated areas
[00:14:29.900 --> 00:14:31.280]   that have gone through this
[00:14:31.280 --> 00:14:32.680]   now have full access
[00:14:32.680 --> 00:14:33.720]   to this technology
[00:14:33.720 --> 00:14:34.660]   and no longer need
[00:14:34.660 --> 00:14:36.060]   to wait for the technology
[00:14:36.060 --> 00:14:37.720]   to kind of come to them,
[00:14:37.720 --> 00:14:38.240]   right?
[00:14:38.240 --> 00:14:39.040]   You can,
[00:14:39.040 --> 00:14:39.860]   commercially,
[00:14:39.860 --> 00:14:40.940]   there are some advantages.
[00:14:40.940 --> 00:14:41.880]   Scale
[00:14:41.880 --> 00:14:43.920]   and operational capabilities
[00:14:43.920 --> 00:14:45.340]   really add to the reasons
[00:14:45.340 --> 00:14:47.760]   for why to use it all together.
[00:14:47.760 --> 00:14:48.400]   Now,
[00:14:48.400 --> 00:14:49.800]   together,
[00:14:49.980 --> 00:14:51.160]   we enable these
[00:14:51.160 --> 00:14:53.840]   really high-value use cases.
[00:14:53.840 --> 00:14:55.940]   And one of the great things
[00:14:55.940 --> 00:14:58.080]   about sitting at the intersection
[00:14:58.080 --> 00:14:58.960]   of Gen AI
[00:14:58.960 --> 00:14:59.880]   and enterprise
[00:14:59.880 --> 00:15:01.140]   is getting to see
[00:15:01.140 --> 00:15:02.620]   these high-value use cases
[00:15:02.620 --> 00:15:04.240]   that kind of come through
[00:15:04.240 --> 00:15:05.160]   and really,
[00:15:05.160 --> 00:15:05.820]   you know,
[00:15:05.820 --> 00:15:08.180]   give us the confidence
[00:15:08.180 --> 00:15:10.180]   to see that this technology
[00:15:10.180 --> 00:15:11.460]   is not going to be
[00:15:11.460 --> 00:15:14.580]   another kind of three-year
[00:15:14.580 --> 00:15:15.600]   flash in the pan,
[00:15:15.600 --> 00:15:17.660]   but is really going to end up
[00:15:17.660 --> 00:15:19.240]   changing the way we all work.
[00:15:19.240 --> 00:15:20.520]   and we can now see
[00:15:20.520 --> 00:15:21.760]   that coming to fruition
[00:15:21.760 --> 00:15:23.600]   in some of these organizations
[00:15:23.600 --> 00:15:25.120]   we're working with.
[00:15:25.120 --> 00:15:25.620]   Now,
[00:15:25.620 --> 00:15:26.920]   I had said at the beginning
[00:15:26.920 --> 00:15:28.560]   that this comes down
[00:15:28.560 --> 00:15:29.080]   to governance
[00:15:29.080 --> 00:15:29.980]   and evaluation,
[00:15:29.980 --> 00:15:31.280]   right?
[00:15:31.400 --> 00:15:32.560]   and for us,
[00:15:32.560 --> 00:15:34.340]   one is not complete
[00:15:34.340 --> 00:15:35.360]   without the other.
[00:15:35.360 --> 00:15:37.200]   You can lock these things down.
[00:15:37.200 --> 00:15:37.840]   You can control
[00:15:37.840 --> 00:15:38.820]   what they have access to.
[00:15:38.820 --> 00:15:39.560]   You can control
[00:15:39.560 --> 00:15:41.060]   how they're going to operate
[00:15:41.060 --> 00:15:42.480]   within your data state.
[00:15:42.480 --> 00:15:44.380]   But if you're not measuring
[00:15:44.380 --> 00:15:47.160]   the quality of the system,
[00:15:47.160 --> 00:15:49.620]   then you're really not going to know
[00:15:49.620 --> 00:15:50.480]   whether or not
[00:15:50.480 --> 00:15:52.320]   this system you've built
[00:15:52.320 --> 00:15:53.620]   is high enough quality
[00:15:53.620 --> 00:15:55.200]   to be able to start putting in
[00:15:55.200 --> 00:15:56.660]   to those higher risk
[00:15:56.660 --> 00:15:57.460]   use cases
[00:15:57.460 --> 00:15:58.860]   without necessarily
[00:15:58.860 --> 00:15:59.780]   a human approval
[00:15:59.780 --> 00:16:00.380]   in the loop
[00:16:00.380 --> 00:16:01.300]   at every step,
[00:16:01.300 --> 00:16:01.860]   right?
[00:16:01.860 --> 00:16:02.920]   And so that's where
[00:16:02.920 --> 00:16:03.900]   eval comes in.
[00:16:03.900 --> 00:16:05.280]   This is our eval platform,
[00:16:05.280 --> 00:16:05.800]   by the way.
[00:16:05.800 --> 00:16:07.340]   You bring in a golden data set.
[00:16:07.340 --> 00:16:08.280]   We have a series
[00:16:08.280 --> 00:16:09.420]   of LLM judges
[00:16:09.420 --> 00:16:10.860]   that help determine
[00:16:10.860 --> 00:16:11.720]   whether or not
[00:16:11.720 --> 00:16:12.460]   your performance
[00:16:12.460 --> 00:16:13.900]   is what it needs to be.
[00:16:13.900 --> 00:16:15.800]   And you can use this.
[00:16:15.800 --> 00:16:16.280]   By the way,
[00:16:16.280 --> 00:16:17.120]   this whole system
[00:16:17.120 --> 00:16:18.520]   has a secondary UI
[00:16:18.520 --> 00:16:20.080]   for your subject matter expert.
[00:16:20.480 --> 00:16:21.240]   Time and again,
[00:16:21.240 --> 00:16:22.560]   we see the app developers
[00:16:22.560 --> 00:16:23.740]   building these systems
[00:16:23.740 --> 00:16:25.180]   are not necessarily
[00:16:25.180 --> 00:16:26.540]   the subject matter experts
[00:16:26.540 --> 00:16:27.460]   on these topics.
[00:16:27.460 --> 00:16:29.560]   And so having a simplified UI
[00:16:29.560 --> 00:16:31.200]   for that subject matter expert
[00:16:31.200 --> 00:16:32.680]   to be able to kind of quickly
[00:16:32.680 --> 00:16:35.280]   and easily give context
[00:16:35.280 --> 00:16:37.720]   or correct a prompt
[00:16:37.720 --> 00:16:39.320]   or create a better answer
[00:16:39.320 --> 00:16:40.260]   is critical.
[00:16:40.260 --> 00:16:42.180]   But this is how we start
[00:16:42.180 --> 00:16:44.060]   down this path
[00:16:44.060 --> 00:16:45.180]   of gaining confidence
[00:16:45.180 --> 00:16:46.640]   that these systems
[00:16:46.640 --> 00:16:48.120]   can perform in robust,
[00:16:48.120 --> 00:16:50.260]   higher risk situations.
[00:16:50.260 --> 00:16:52.180]   is by really kind of,
[00:16:52.180 --> 00:16:52.440]   you know,
[00:16:52.440 --> 00:16:54.080]   I had a guy
[00:16:54.080 --> 00:16:55.300]   the other day
[00:16:55.300 --> 00:16:56.080]   who said,
[00:16:56.080 --> 00:16:57.360]   you know,
[00:16:57.360 --> 00:16:58.160]   oh, you're just unit
[00:16:58.160 --> 00:16:59.040]   testing the agent.
[00:16:59.040 --> 00:17:01.060]   And I kind of said,
[00:17:01.060 --> 00:17:01.880]   well, I'd like to think
[00:17:01.880 --> 00:17:03.080]   it's more clever than that,
[00:17:03.080 --> 00:17:03.860]   but yeah,
[00:17:03.860 --> 00:17:04.640]   you know,
[00:17:04.640 --> 00:17:05.680]   more or less, right?
[00:17:05.680 --> 00:17:06.220]   You know,
[00:17:06.220 --> 00:17:07.680]   really kind of searching
[00:17:07.680 --> 00:17:09.760]   across the question space
[00:17:09.760 --> 00:17:11.100]   or that is expected
[00:17:11.100 --> 00:17:14.240]   to be kind of gone after
[00:17:14.240 --> 00:17:15.060]   with this system
[00:17:15.060 --> 00:17:16.580]   and then diving in
[00:17:16.580 --> 00:17:18.140]   at the most granular levels
[00:17:18.140 --> 00:17:19.460]   to ensure that this system
[00:17:19.460 --> 00:17:20.040]   is performing.
[00:17:20.040 --> 00:17:21.620]   now this eval system,
[00:17:21.620 --> 00:17:22.320]   I should say,
[00:17:22.320 --> 00:17:24.420]   a lot of it is open source
[00:17:24.420 --> 00:17:25.520]   in MLflow.
[00:17:25.520 --> 00:17:27.520]   The LLM judges are not,
[00:17:27.520 --> 00:17:28.960]   but a lot of the capabilities
[00:17:28.960 --> 00:17:30.100]   here can be run.
[00:17:30.100 --> 00:17:30.980]   Whether or not
[00:17:30.980 --> 00:17:31.860]   you're using Databricks
[00:17:31.860 --> 00:17:32.240]   or not,
[00:17:32.240 --> 00:17:34.220]   you can use open source MLflow
[00:17:34.220 --> 00:17:35.300]   to do these evals
[00:17:35.300 --> 00:17:36.100]   or you can,
[00:17:36.100 --> 00:17:37.640]   if you're using Databricks,
[00:17:37.640 --> 00:17:38.320]   you can hook it up
[00:17:38.320 --> 00:17:39.220]   and gain all the value
[00:17:39.220 --> 00:17:40.540]   of some of our custom judges
[00:17:40.540 --> 00:17:41.760]   and what have you,
[00:17:41.760 --> 00:17:42.280]   right?
[00:17:43.820 --> 00:17:46.440]   So that is kind of the stack
[00:17:46.440 --> 00:17:48.100]   and that's how we're helping
[00:17:48.100 --> 00:17:50.640]   organizations bring Gen AI
[00:17:50.640 --> 00:17:52.300]   and particularly bringing
[00:17:52.300 --> 00:17:54.440]   Claude into this space.
[00:17:54.440 --> 00:17:55.100]   Now,
[00:17:55.100 --> 00:17:56.480]   before we wrap up though,
[00:17:56.480 --> 00:17:57.460]   I wanted to share,
[00:17:57.460 --> 00:17:58.680]   you know,
[00:17:58.680 --> 00:18:01.520]   there are these analysts out there,
[00:18:01.520 --> 00:18:03.020]   Gartner and Forrester
[00:18:03.020 --> 00:18:03.680]   and all these,
[00:18:03.680 --> 00:18:04.600]   they go around
[00:18:04.600 --> 00:18:07.020]   and they write report cards
[00:18:07.020 --> 00:18:08.520]   on how good is every,
[00:18:08.520 --> 00:18:10.560]   how good are all the vendors,
[00:18:10.560 --> 00:18:10.960]   right?
[00:18:10.960 --> 00:18:12.600]   which vendors are the leaders
[00:18:12.600 --> 00:18:13.340]   and what have you.
[00:18:13.340 --> 00:18:15.060]   We do pretty well in these,
[00:18:15.060 --> 00:18:18.880]   but I'm really excited to say
[00:18:18.880 --> 00:18:20.980]   that we're now using ARIA
[00:18:20.980 --> 00:18:21.820]   to do these.
[00:18:21.820 --> 00:18:22.960]   So to give you a sense,
[00:18:22.960 --> 00:18:24.660]   the last time we filled out
[00:18:24.660 --> 00:18:26.060]   the Gartner one of these things,
[00:18:26.060 --> 00:18:27.140]   we ended up writing
[00:18:27.140 --> 00:18:29.220]   a 450 page document,
[00:18:29.220 --> 00:18:29.980]   right?
[00:18:29.980 --> 00:18:31.740]   They had 180 questions for us
[00:18:31.740 --> 00:18:33.040]   and we ended up passing back
[00:18:33.040 --> 00:18:34.940]   to them a 450 page document.
[00:18:34.940 --> 00:18:38.500]   So using Claude,
[00:18:39.340 --> 00:18:41.420]   we actually have taken
[00:18:41.420 --> 00:18:41.880]   a whole,
[00:18:41.880 --> 00:18:43.400]   our doc,
[00:18:43.400 --> 00:18:44.160]   our blogs,
[00:18:44.160 --> 00:18:45.080]   our docs,
[00:18:45.080 --> 00:18:48.060]   a whole bunch of the information
[00:18:48.060 --> 00:18:49.380]   about our system,
[00:18:49.380 --> 00:18:51.480]   as well as past answers
[00:18:51.480 --> 00:18:52.020]   we've written
[00:18:52.020 --> 00:18:53.360]   for these types of things
[00:18:53.360 --> 00:18:55.080]   and we've actually gotten it
[00:18:55.080 --> 00:18:56.940]   so that when Gartner
[00:18:56.940 --> 00:18:57.800]   or Forrester
[00:18:57.800 --> 00:18:58.500]   or what have you
[00:18:58.500 --> 00:19:01.040]   send us these questionnaires,
[00:19:01.040 --> 00:19:01.900]   we just run them
[00:19:01.900 --> 00:19:02.540]   through the bot.
[00:19:03.620 --> 00:19:04.420]   and, you know,
[00:19:04.420 --> 00:19:05.760]   I'll say the answers,
[00:19:05.760 --> 00:19:07.580]   we still read the answers over
[00:19:07.580 --> 00:19:10.660]   and we correct some of them
[00:19:10.660 --> 00:19:12.360]   some of the time,
[00:19:12.360 --> 00:19:14.480]   but the ability for us
[00:19:14.480 --> 00:19:15.080]   to do this
[00:19:15.080 --> 00:19:15.680]   has made it
[00:19:15.680 --> 00:19:16.480]   so that now
[00:19:16.480 --> 00:19:17.800]   instead of it being
[00:19:17.800 --> 00:19:20.000]   kind of hundreds of hours
[00:19:20.000 --> 00:19:21.140]   of product managers
[00:19:21.140 --> 00:19:21.920]   and engineers
[00:19:21.920 --> 00:19:22.920]   and marketing folks
[00:19:22.920 --> 00:19:23.760]   all kind of pounding
[00:19:23.760 --> 00:19:24.480]   on the keyboard
[00:19:24.480 --> 00:19:26.240]   to try and put something together,
[00:19:26.240 --> 00:19:27.840]   now we're just editing
[00:19:27.840 --> 00:19:29.540]   what I wouldn't even call
[00:19:29.540 --> 00:19:30.180]   a rough draft.
[00:19:30.300 --> 00:19:30.840]   we're editing
[00:19:30.840 --> 00:19:31.920]   what's pretty darn close
[00:19:31.920 --> 00:19:33.080]   to a final draft
[00:19:33.080 --> 00:19:34.480]   coming out of Claude
[00:19:34.480 --> 00:19:35.900]   and the reason why
[00:19:35.900 --> 00:19:36.960]   I have this up here
[00:19:36.960 --> 00:19:39.920]   is because we built this,
[00:19:39.920 --> 00:19:42.640]   this went through
[00:19:42.640 --> 00:19:43.500]   many iterations.
[00:19:43.500 --> 00:19:44.500]   We started with
[00:19:44.500 --> 00:19:45.340]   open source models,
[00:19:45.340 --> 00:19:47.480]   then we went to
[00:19:47.480 --> 00:19:49.620]   non-anthropic models
[00:19:49.620 --> 00:19:51.480]   of a different vendor
[00:19:51.480 --> 00:19:53.460]   and then we started
[00:19:53.460 --> 00:19:54.440]   using Claude
[00:19:54.440 --> 00:19:55.780]   and it wasn't until
[00:19:55.780 --> 00:19:57.160]   we started using Claude
[00:19:57.160 --> 00:19:58.440]   that the results
[00:19:58.440 --> 00:19:59.180]   were good enough
[00:19:59.180 --> 00:19:59.540]   that we,
[00:19:59.760 --> 00:20:00.740]   it was when
[00:20:00.740 --> 00:20:01.980]   we started using Claude
[00:20:01.980 --> 00:20:02.280]   that we,
[00:20:02.280 --> 00:20:03.540]   for the first time,
[00:20:03.540 --> 00:20:04.500]   had results
[00:20:04.500 --> 00:20:05.420]   that we could ship
[00:20:05.420 --> 00:20:07.100]   without touching them
[00:20:07.100 --> 00:20:08.960]   and that was a huge win
[00:20:08.960 --> 00:20:09.520]   for us
[00:20:09.520 --> 00:20:11.860]   and so it's a really exciting,
[00:20:11.860 --> 00:20:12.720]   this is one of these
[00:20:12.720 --> 00:20:14.200]   that I'm super excited about
[00:20:14.200 --> 00:20:14.700]   because it makes
[00:20:14.700 --> 00:20:15.880]   my life way better.
[00:20:15.880 --> 00:20:18.080]   We just published
[00:20:18.080 --> 00:20:19.180]   a blog on this,
[00:20:19.180 --> 00:20:21.420]   really exciting stuff
[00:20:21.420 --> 00:20:23.120]   if you have to spend
[00:20:23.120 --> 00:20:24.180]   your days filling out
[00:20:24.180 --> 00:20:25.480]   these darn questionnaires.
[00:20:25.480 --> 00:20:27.160]   Block is also
[00:20:27.160 --> 00:20:28.440]   a customer of ours
[00:20:28.440 --> 00:20:29.840]   and Block has built
[00:20:29.840 --> 00:20:30.960]   this open source system
[00:20:30.960 --> 00:20:31.680]   called Goose
[00:20:31.680 --> 00:20:32.300]   and if you haven't
[00:20:32.300 --> 00:20:33.240]   given Goose a try,
[00:20:33.240 --> 00:20:34.100]   you should take a look.
[00:20:34.100 --> 00:20:35.080]   As I said,
[00:20:35.080 --> 00:20:35.680]   it's open source.
[00:20:35.680 --> 00:20:38.540]   It's really a dev environment,
[00:20:38.540 --> 00:20:40.600]   an agentic dev environment
[00:20:40.600 --> 00:20:43.200]   to accelerate their developers
[00:20:43.200 --> 00:20:45.600]   to be able to build,
[00:20:45.600 --> 00:20:45.940]   you know,
[00:20:45.940 --> 00:20:46.940]   it has basically
[00:20:46.940 --> 00:20:48.220]   Claude built into it
[00:20:48.220 --> 00:20:49.100]   and it has connections
[00:20:49.100 --> 00:20:50.560]   to all of their systems
[00:20:50.560 --> 00:20:51.660]   and all of their data
[00:20:51.660 --> 00:20:52.760]   so that they can
[00:20:52.760 --> 00:20:53.360]   much,
[00:20:53.360 --> 00:20:54.240]   much more quickly
[00:20:54.240 --> 00:20:54.900]   and easily
[00:20:54.900 --> 00:20:55.980]   build,
[00:20:55.980 --> 00:20:57.360]   you know,
[00:20:57.360 --> 00:20:58.240]   kind of within
[00:20:58.240 --> 00:20:59.460]   and really accelerate
[00:20:59.460 --> 00:21:00.780]   the developer experience
[00:21:00.780 --> 00:21:01.540]   far,
[00:21:01.540 --> 00:21:02.360]   far beyond
[00:21:02.360 --> 00:21:03.720]   kind of what we're all used to
[00:21:03.720 --> 00:21:04.640]   with Code Complete
[00:21:04.640 --> 00:21:05.860]   or something like that
[00:21:05.860 --> 00:21:07.180]   into a much more
[00:21:07.180 --> 00:21:08.480]   purpose-built system
[00:21:08.480 --> 00:21:10.040]   to be able to go attack
[00:21:10.040 --> 00:21:11.740]   improvement of their workflows
[00:21:11.740 --> 00:21:12.640]   and things like this.
[00:21:12.780 --> 00:21:15.040]   You can see 40 to 50%
[00:21:15.040 --> 00:21:16.700]   weekly user adoption increase,
[00:21:16.700 --> 00:21:19.100]   8 to 10 hours saved per week
[00:21:19.100 --> 00:21:20.360]   by using this
[00:21:20.360 --> 00:21:22.480]   and it's been really exciting
[00:21:22.480 --> 00:21:24.560]   to see Block be this successful
[00:21:24.560 --> 00:21:26.400]   with Databricks on,
[00:21:26.400 --> 00:21:28.160]   or with Claude on Databricks
[00:21:28.160 --> 00:21:30.640]   as well as to see Goose
[00:21:30.640 --> 00:21:32.500]   start to pick up in the market
[00:21:32.500 --> 00:21:33.600]   and more and more people
[00:21:33.600 --> 00:21:34.580]   playing around
[00:21:34.580 --> 00:21:36.160]   and starting to try out Goose.
[00:21:36.160 --> 00:21:37.560]   So those are just a couple
[00:21:37.560 --> 00:21:38.160]   of the areas
[00:21:38.160 --> 00:21:39.200]   where we've had success
[00:21:39.200 --> 00:21:41.700]   getting these models
[00:21:41.700 --> 00:21:42.500]   and these systems
[00:21:42.500 --> 00:21:43.060]   in production
[00:21:43.060 --> 00:21:43.980]   and creating value
[00:21:43.980 --> 00:21:44.660]   for customers.
[00:21:44.660 --> 00:21:47.080]   So I'll just end it with,
[00:21:47.080 --> 00:21:47.580]   you know,
[00:21:47.580 --> 00:21:49.460]   I'm sure everyone here
[00:21:49.460 --> 00:21:50.740]   is deep enough in this
[00:21:50.740 --> 00:21:51.840]   that I don't need to tell you
[00:21:51.840 --> 00:21:52.760]   to start identifying
[00:21:52.760 --> 00:21:54.020]   your AI use cases,
[00:21:54.020 --> 00:21:55.720]   but once you've identified
[00:21:55.720 --> 00:21:56.880]   those AI use cases
[00:21:56.880 --> 00:21:57.580]   and you've started
[00:21:57.580 --> 00:21:58.320]   to understand
[00:21:58.320 --> 00:21:59.880]   what success may look like,
[00:21:59.880 --> 00:22:01.200]   you know,
[00:22:01.200 --> 00:22:01.960]   contact us,
[00:22:01.960 --> 00:22:03.060]   reach out to Databricks,
[00:22:03.060 --> 00:22:04.640]   reach out to Anthropic,
[00:22:04.640 --> 00:22:06.560]   happy to work with you,
[00:22:06.560 --> 00:22:07.240]   either,
[00:22:07.240 --> 00:22:08.000]   you know,
[00:22:08.000 --> 00:22:08.740]   kind of in your
[00:22:08.740 --> 00:22:09.660]   professional capacity
[00:22:09.660 --> 00:22:10.580]   with the organizations
[00:22:10.580 --> 00:22:11.440]   you work for
[00:22:11.440 --> 00:22:13.240]   and really help them
[00:22:13.240 --> 00:22:14.740]   gain the confidence.
[00:22:14.740 --> 00:22:16.200]   The meeting I was in
[00:22:16.200 --> 00:22:17.000]   earlier today,
[00:22:17.000 --> 00:22:19.540]   as I was walking
[00:22:19.540 --> 00:22:20.120]   out of the meeting,
[00:22:20.120 --> 00:22:20.820]   the head of AI
[00:22:20.820 --> 00:22:22.080]   came running over to me
[00:22:22.080 --> 00:22:22.560]   and he said,
[00:22:22.560 --> 00:22:22.720]   hey,
[00:22:22.720 --> 00:22:23.500]   I really appreciate
[00:22:23.500 --> 00:22:24.300]   the session today.
[00:22:24.300 --> 00:22:25.040]   And I said,
[00:22:25.040 --> 00:22:25.240]   no,
[00:22:25.240 --> 00:22:25.760]   no worries,
[00:22:25.760 --> 00:22:27.080]   like happy to present,
[00:22:27.080 --> 00:22:28.040]   happy to chat with you
[00:22:28.040 --> 00:22:28.740]   about what we're doing.
[00:22:28.740 --> 00:22:29.140]   He goes,
[00:22:29.140 --> 00:22:29.320]   no,
[00:22:29.320 --> 00:22:29.460]   no,
[00:22:29.460 --> 00:22:29.580]   no,
[00:22:29.580 --> 00:22:29.780]   no,
[00:22:29.780 --> 00:22:30.460]   it wasn't learning
[00:22:30.460 --> 00:22:31.180]   about your stuff
[00:22:31.180 --> 00:22:32.000]   that I appreciated.
[00:22:32.000 --> 00:22:33.160]   It was you telling
[00:22:33.160 --> 00:22:34.600]   our chief data officer
[00:22:34.600 --> 00:22:35.820]   how hard my job is
[00:22:35.820 --> 00:22:37.060]   that I really appreciated,
[00:22:37.060 --> 00:22:37.380]   right?
[00:22:37.380 --> 00:22:38.900]   And so let us know
[00:22:38.900 --> 00:22:39.900]   how we can help you
[00:22:39.900 --> 00:22:41.540]   in this journey.
[00:22:41.540 --> 00:22:42.320]   With that,
[00:22:42.320 --> 00:22:43.500]   I wanted to open it up
[00:22:43.500 --> 00:22:44.440]   to any questions.
[00:22:44.440 --> 00:22:46.260]   So your safe score
[00:22:46.260 --> 00:22:47.220]   in the evaluation,
[00:22:47.220 --> 00:22:48.020]   is that
[00:22:48.020 --> 00:22:50.640]   leveraging adversarial
[00:22:50.640 --> 00:22:52.900]   testing problems
[00:22:52.900 --> 00:22:53.200]   or
[00:22:53.200 --> 00:22:54.700]   no,
[00:22:54.700 --> 00:22:56.940]   no,
[00:22:56.940 --> 00:22:57.400]   no.
[00:22:57.400 --> 00:22:58.300]   So the question was,
[00:22:58.300 --> 00:22:59.700]   is the safe score
[00:22:59.700 --> 00:23:01.100]   among our LLM judges
[00:23:01.100 --> 00:23:02.820]   kind of using a red teaming
[00:23:02.820 --> 00:23:04.580]   or a kind of adversarial
[00:23:04.580 --> 00:23:05.080]   technique
[00:23:05.080 --> 00:23:05.900]   or something like that?
[00:23:05.900 --> 00:23:06.300]   No,
[00:23:06.300 --> 00:23:07.040]   it's much more
[00:23:07.040 --> 00:23:07.780]   of a kind of,
[00:23:07.780 --> 00:23:08.600]   think of it more
[00:23:08.600 --> 00:23:09.540]   as like a guardrail
[00:23:09.540 --> 00:23:10.200]   type measure
[00:23:10.200 --> 00:23:10.760]   around,
[00:23:10.760 --> 00:23:11.240]   you know,
[00:23:11.240 --> 00:23:13.160]   was this response
[00:23:13.160 --> 00:23:14.500]   a green response
[00:23:14.500 --> 00:23:16.720]   or a comfortable response
[00:23:16.720 --> 00:23:17.340]   kind of thing?
[00:23:17.340 --> 00:23:19.040]   Any other questions?
[00:23:19.040 --> 00:23:20.840]   Yeah.
[00:23:20.840 --> 00:23:22.780]   Would you think
[00:23:22.780 --> 00:23:23.740]   like Minecraft Cloud
[00:23:23.740 --> 00:23:24.340]   is a compender?
[00:23:24.340 --> 00:23:24.920]   Like,
[00:23:24.920 --> 00:23:25.500]   do you feel some good
[00:23:25.500 --> 00:23:25.760]   of that?
[00:23:25.760 --> 00:23:26.260]   Yeah,
[00:23:26.260 --> 00:23:26.740]   I mean,
[00:23:26.740 --> 00:23:27.900]   you know,
[00:23:27.900 --> 00:23:28.620]   some of the folks
[00:23:28.620 --> 00:23:28.960]   over,
[00:23:28.960 --> 00:23:29.800]   you know,
[00:23:29.800 --> 00:23:30.480]   it's tough.
[00:23:30.600 --> 00:23:33.660]   we have a bunch
[00:23:33.660 --> 00:23:34.220]   of competitors
[00:23:34.220 --> 00:23:35.980]   for point solutions
[00:23:35.980 --> 00:23:37.540]   within the Gen AI space,
[00:23:37.540 --> 00:23:37.720]   right?
[00:23:37.720 --> 00:23:37.940]   You know,
[00:23:37.940 --> 00:23:38.380]   eval,
[00:23:38.380 --> 00:23:39.100]   you could say,
[00:23:39.100 --> 00:23:39.760]   you know,
[00:23:39.760 --> 00:23:41.000]   it might be Galileo,
[00:23:41.000 --> 00:23:42.020]   it might be,
[00:23:42.020 --> 00:23:42.520]   you know,
[00:23:42.520 --> 00:23:43.740]   Patronus,
[00:23:43.740 --> 00:23:44.540]   it might be others
[00:23:44.540 --> 00:23:45.220]   kind of thing,
[00:23:45.220 --> 00:23:45.500]   right?
[00:23:45.500 --> 00:23:46.800]   You know,
[00:23:46.800 --> 00:23:47.260]   and so there's
[00:23:47.260 --> 00:23:48.700]   some point-specific folks.
[00:23:48.700 --> 00:23:49.820]   I think
[00:23:49.820 --> 00:23:50.840]   the way we think
[00:23:50.840 --> 00:23:51.380]   about this
[00:23:51.380 --> 00:23:52.260]   is much more
[00:23:52.260 --> 00:23:53.480]   that the value
[00:23:53.480 --> 00:23:54.640]   comes in the connection
[00:23:54.640 --> 00:23:55.860]   between the AI system
[00:23:55.860 --> 00:23:56.740]   and the data system.
[00:23:56.740 --> 00:23:57.360]   Like,
[00:23:57.360 --> 00:23:58.220]   having worked
[00:23:58.220 --> 00:23:59.080]   at both AWS
[00:23:59.080 --> 00:24:00.060]   and GCP,
[00:24:00.260 --> 00:24:00.800]   I can say,
[00:24:00.800 --> 00:24:01.160]   like,
[00:24:01.160 --> 00:24:03.320]   the reason I'm at Databricks
[00:24:03.320 --> 00:24:04.080]   is because
[00:24:04.080 --> 00:24:05.740]   there was a conversation
[00:24:05.740 --> 00:24:06.280]   I had
[00:24:06.280 --> 00:24:07.980]   while at Vertex
[00:24:07.980 --> 00:24:08.780]   where we were
[00:24:08.780 --> 00:24:09.960]   sitting there saying,
[00:24:09.960 --> 00:24:10.220]   hey,
[00:24:10.220 --> 00:24:11.020]   with MLOps,
[00:24:11.020 --> 00:24:11.660]   we had taken
[00:24:11.660 --> 00:24:12.680]   an order of magnitude
[00:24:12.680 --> 00:24:14.020]   off the development time.
[00:24:14.020 --> 00:24:15.340]   Where does the next
[00:24:15.340 --> 00:24:16.380]   order of magnitude
[00:24:16.380 --> 00:24:17.640]   off development time
[00:24:17.640 --> 00:24:18.160]   came from?
[00:24:18.160 --> 00:24:18.620]   And it really,
[00:24:18.620 --> 00:24:19.880]   I believe,
[00:24:19.880 --> 00:24:21.000]   comes from being able
[00:24:21.000 --> 00:24:22.780]   to really integrate
[00:24:22.780 --> 00:24:23.360]   the AI
[00:24:23.360 --> 00:24:24.620]   and the data layers
[00:24:24.620 --> 00:24:25.520]   together much,
[00:24:25.520 --> 00:24:26.840]   much more intimately
[00:24:26.840 --> 00:24:27.420]   and deeply
[00:24:27.420 --> 00:24:28.180]   than we've seen
[00:24:28.180 --> 00:24:28.800]   from most of the
[00:24:28.800 --> 00:24:29.440]   hyperscalers.
[00:24:29.920 --> 00:24:31.180]   any other
[00:24:31.180 --> 00:24:31.880]   last questions?
[00:24:31.880 --> 00:24:32.160]   Yeah.
[00:24:32.160 --> 00:24:34.720]   In one of your earlier slides,
[00:24:34.720 --> 00:24:35.860]   the customer investment
[00:24:35.860 --> 00:24:37.140]   is not on Claude yet.
[00:24:37.140 --> 00:24:37.960]   Yeah.
[00:24:37.960 --> 00:24:38.980]   It looks like
[00:24:38.980 --> 00:24:40.180]   they have many agents
[00:24:40.180 --> 00:24:41.420]   going together.
[00:24:41.420 --> 00:24:43.680]   Have you found
[00:24:43.680 --> 00:24:44.540]   that with Claude
[00:24:44.540 --> 00:24:45.940]   or in the three points
[00:24:45.940 --> 00:24:46.380]   that it's like
[00:24:46.380 --> 00:24:47.120]   you don't need
[00:24:47.120 --> 00:24:47.840]   many agents,
[00:24:47.840 --> 00:24:49.100]   it can kind of
[00:24:49.100 --> 00:24:49.560]   what you see
[00:24:49.560 --> 00:24:50.660]   if they manage that?
[00:24:50.660 --> 00:24:51.200]   Yeah.
[00:24:51.200 --> 00:24:51.960]   I mean,
[00:24:51.960 --> 00:24:52.780]   that's certainly,
[00:24:52.780 --> 00:24:53.220]   you know,
[00:24:53.220 --> 00:24:56.420]   we often encourage
[00:24:56.420 --> 00:24:56.880]   companies
[00:24:56.880 --> 00:24:58.840]   to take a more
[00:24:58.840 --> 00:24:59.680]   kind of
[00:24:59.680 --> 00:25:00.880]   composable agentic
[00:25:00.880 --> 00:25:01.420]   approach
[00:25:01.420 --> 00:25:02.200]   and we often
[00:25:02.200 --> 00:25:02.900]   encourage them
[00:25:02.900 --> 00:25:03.420]   to do that
[00:25:03.420 --> 00:25:04.320]   simply because
[00:25:04.320 --> 00:25:05.400]   when you're trying
[00:25:05.400 --> 00:25:06.440]   to build these systems
[00:25:06.440 --> 00:25:07.440]   to behave
[00:25:07.440 --> 00:25:08.280]   deterministically
[00:25:08.280 --> 00:25:11.240]   in a higher risk
[00:25:11.240 --> 00:25:12.120]   environment,
[00:25:12.120 --> 00:25:14.820]   then you need
[00:25:14.820 --> 00:25:15.580]   to be able
[00:25:15.580 --> 00:25:16.560]   to tune them
[00:25:16.560 --> 00:25:17.560]   at a much
[00:25:17.560 --> 00:25:18.680]   more granular level
[00:25:18.680 --> 00:25:19.620]   and so,
[00:25:19.620 --> 00:25:20.080]   you know,
[00:25:20.080 --> 00:25:20.920]   our goal
[00:25:20.920 --> 00:25:21.360]   is really
[00:25:21.360 --> 00:25:21.820]   to drive
[00:25:21.820 --> 00:25:22.600]   as much entropy
[00:25:22.600 --> 00:25:23.660]   out of these systems
[00:25:23.660 --> 00:25:24.380]   as possible
[00:25:24.380 --> 00:25:25.580]   in trying to
[00:25:25.580 --> 00:25:26.980]   get this determinism
[00:25:26.980 --> 00:25:27.440]   and so,
[00:25:27.440 --> 00:25:28.080]   you know,
[00:25:28.080 --> 00:25:29.220]   yes,
[00:25:29.220 --> 00:25:31.880]   I think 3.7,
[00:25:31.880 --> 00:25:32.860]   I haven't gotten
[00:25:32.860 --> 00:25:33.780]   to play with 4
[00:25:33.780 --> 00:25:34.760]   nearly enough yet
[00:25:34.760 --> 00:25:35.760]   but I think 3.7
[00:25:35.760 --> 00:25:37.980]   probably could do
[00:25:37.980 --> 00:25:38.700]   a lot of that
[00:25:38.700 --> 00:25:39.740]   but I guess
[00:25:39.740 --> 00:25:40.620]   my only concern
[00:25:40.620 --> 00:25:41.200]   would be
[00:25:41.200 --> 00:25:43.180]   if we did find errors,
[00:25:43.280 --> 00:25:43.740]   would we have
[00:25:43.740 --> 00:25:44.180]   the knobs
[00:25:44.180 --> 00:25:44.580]   to be able
[00:25:44.580 --> 00:25:44.840]   to go
[00:25:44.840 --> 00:25:45.440]   and get them
[00:25:45.440 --> 00:25:46.280]   beyond just
[00:25:46.280 --> 00:25:47.800]   swapping up
[00:25:47.800 --> 00:25:48.420]   the prompts,
[00:25:48.420 --> 00:25:48.860]   right?
[00:25:48.860 --> 00:25:49.680]   And that's,
[00:25:49.680 --> 00:25:49.980]   I think,
[00:25:49.980 --> 00:25:50.280]   where,
[00:25:50.280 --> 00:25:50.940]   you know,
[00:25:50.940 --> 00:25:52.240]   even as these models
[00:25:52.240 --> 00:25:53.260]   have gotten much larger,
[00:25:53.260 --> 00:25:54.280]   I'll tell you,
[00:25:54.280 --> 00:25:55.380]   one of the things 3.7
[00:25:55.380 --> 00:25:56.340]   that I've really
[00:25:56.340 --> 00:25:57.580]   appreciated about 3.7
[00:25:57.580 --> 00:25:58.140]   is that
[00:25:58.140 --> 00:26:00.200]   it does a great job
[00:26:00.200 --> 00:26:01.300]   of taking prompts
[00:26:01.300 --> 00:26:02.280]   to other models
[00:26:02.280 --> 00:26:03.600]   and decomposing them
[00:26:03.600 --> 00:26:04.860]   into each of the steps.
[00:26:04.860 --> 00:26:05.360]   Like,
[00:26:05.360 --> 00:26:06.000]   I can take it
[00:26:06.000 --> 00:26:06.340]   and say,
[00:26:06.340 --> 00:26:06.640]   hey,
[00:26:06.640 --> 00:26:07.560]   if I needed
[00:26:07.560 --> 00:26:08.580]   to rewrite this
[00:26:08.580 --> 00:26:10.320]   where it was
[00:26:10.320 --> 00:26:11.620]   as many small
[00:26:11.620 --> 00:26:12.620]   granular steps
[00:26:12.620 --> 00:26:13.360]   as possible,
[00:26:13.360 --> 00:26:15.380]   then 3.7
[00:26:15.380 --> 00:26:16.420]   has done
[00:26:16.420 --> 00:26:17.000]   a great job
[00:26:17.000 --> 00:26:17.340]   of that.
[00:26:17.340 --> 00:26:18.000]   So listen,
[00:26:18.000 --> 00:26:18.680]   I appreciate
[00:26:18.680 --> 00:26:19.880]   all the time
[00:26:19.880 --> 00:26:20.660]   and attention today.
[00:26:20.660 --> 00:26:21.520]   I'll be back
[00:26:21.520 --> 00:26:21.920]   if you have
[00:26:21.920 --> 00:26:22.660]   other questions
[00:26:22.660 --> 00:26:23.540]   back by the door
[00:26:23.540 --> 00:26:24.180]   or back outside
[00:26:24.180 --> 00:26:25.240]   and thanks again
[00:26:25.240 --> 00:26:25.880]   for coming today.
[00:26:25.880 --> 00:26:26.600]   Thank you.
[00:26:26.600 --> 00:26:27.600]   Thank you.
[00:26:27.600 --> 00:26:28.600]   Thank you.
[00:26:28.600 --> 00:26:29.600]   Thank you.
[00:26:29.600 --> 00:26:30.600]   Thank you.
[00:26:30.600 --> 00:26:31.600]   Thank you.
[00:26:31.600 --> 00:26:32.600]   Thank you.
[00:26:32.600 --> 00:26:33.100]   you
[00:26:33.100 --> 00:26:36.820]   I'll see you next time.

