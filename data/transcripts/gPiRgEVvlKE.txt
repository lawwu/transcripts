
[00:00:00.000 --> 00:00:01.900]   something of science. What's what's going on? Are you still
[00:00:01.900 --> 00:00:05.240]   riding high after your big NASA zoom interview? Your space
[00:00:05.240 --> 00:00:06.300]   station zoom interview?
[00:00:06.300 --> 00:00:09.560]   That was really fun. Shout out to Woody Hoberg from the
[00:00:09.560 --> 00:00:13.880]   International Space Station astronaut Cal alumni. Woody
[00:00:13.880 --> 00:00:18.200]   listens to the pod on the ISS while he works out the
[00:00:18.200 --> 00:00:21.880]   astronauts workout. He said two hours and 15 minutes every day
[00:00:21.880 --> 00:00:24.240]   to you know, obviously your body can atrophy got to work out a
[00:00:24.240 --> 00:00:26.280]   lot. He's like when he's working out he listens to old episodes
[00:00:26.280 --> 00:00:29.120]   of the all in pod. A buddy of his put him onto it. He's become
[00:00:29.120 --> 00:00:32.840]   a big fan. Right on. Shout out to Woody. Yeah, I got a DM from
[00:00:32.840 --> 00:00:35.280]   NASA astronauts. I thought it was like some sort of scam or
[00:00:35.280 --> 00:00:38.640]   something. I clicked on it because I follow NASA astronauts
[00:00:38.640 --> 00:00:41.360]   they DM me and I'm like obviously this astronaut wants
[00:00:41.360 --> 00:00:45.000]   to chat. That's so crazy. I looked the guy up seems legit.
[00:00:45.000 --> 00:00:49.680]   He's following me on Twitter. So we did a zoom call yesterday and
[00:00:49.680 --> 00:00:52.720]   I put it on Twitter. The call I did with him is really fun.
[00:00:52.720 --> 00:00:57.560]   Honestly, like a thrill for me. An amazing individual. This guy
[00:00:57.680 --> 00:01:03.240]   got his PhD at Cal in computer science, did a thesis on convex
[00:01:03.240 --> 00:01:05.600]   optimization applied to aerospace engineering became a
[00:01:05.600 --> 00:01:08.560]   professor at MIT for three years, and applied to the
[00:01:08.560 --> 00:01:14.400]   astronaut program and got in. Fast forward. 2023. In March, he
[00:01:14.400 --> 00:01:17.080]   is the pilot of the crew six mission, the SpaceX crew six
[00:01:17.080 --> 00:01:21.240]   mission to the ISS. And he's been on the ISS since March. And
[00:01:21.240 --> 00:01:23.760]   he's coming back in a couple of days, an incredible individual
[00:01:23.760 --> 00:01:26.800]   amazing story. It was super fun to chat with them.
[00:01:26.840 --> 00:01:30.680]   I don't think I've ever seen you smile or be more excited about
[00:01:30.680 --> 00:01:35.440]   anything. You look absolutely ecstatic. Oh, it was amazing. Did
[00:01:35.440 --> 00:01:39.760]   he have any comments on Uranus? Any thoughts on Uranus?
[00:01:39.760 --> 00:01:41.800]   We didn't get there.
[00:01:41.800 --> 00:01:42.760]   You didn't get to your age.
[00:01:42.760 --> 00:01:46.800]   How you blew that? Let's try that again. Let me take a shot
[00:01:46.800 --> 00:01:49.680]   this freeberg. So did he talk about going to the moon?
[00:01:49.680 --> 00:01:51.360]   Yeah, he's actually on the Artemis mission.
[00:01:51.360 --> 00:01:52.480]   And what about Uranus?
[00:01:55.600 --> 00:01:58.840]   We didn't get that far. We didn't get that far. It was the
[00:01:58.840 --> 00:02:00.120]   first day. It was only 20 minutes.
[00:02:00.120 --> 00:02:03.160]   It was the first day in 20 minutes. Did he go for Uranus?
[00:02:03.160 --> 00:02:04.400]   Hey, hey.
[00:02:04.400 --> 00:02:10.000]   I hear that we're trying to actually land on the south side
[00:02:10.000 --> 00:02:10.440]   of the moon.
[00:02:10.440 --> 00:02:13.080]   Yeah, so he's actually on that.
[00:02:13.080 --> 00:02:16.480]   Would he have an opinion on the dark side of the moon? Or I
[00:02:16.480 --> 00:02:17.880]   don't know the dark side of Uranus.
[00:02:23.360 --> 00:02:25.840]   Three for three. Three for three.
[00:02:25.840 --> 00:02:47.800]   I just want to explain somebody was like, why are you bullying
[00:02:47.800 --> 00:02:50.120]   Jake out? Why are you bullying freeberg? Chamath's bullying
[00:02:50.120 --> 00:02:50.560]   this person.
[00:02:50.720 --> 00:02:54.000]   He loves the attention. Our love language is breaking chops.
[00:02:54.000 --> 00:02:57.320]   That's it. We like to laugh and take the piss out because
[00:02:57.320 --> 00:02:59.680]   everybody takes themselves too seriously. And then what's going
[00:02:59.680 --> 00:03:02.080]   on with the tequila? Are you guys serious about this? Because
[00:03:02.080 --> 00:03:02.480]   now I'm getting
[00:03:02.480 --> 00:03:05.240]   don't talk about that right now. I'm getting 50 emails a day with
[00:03:05.240 --> 00:03:08.680]   people. Yeah, we'll talk about it. All right. We'll talk about
[00:03:08.680 --> 00:03:11.600]   it. I did run a poll asking people if they're trying all in
[00:03:11.600 --> 00:03:13.840]   tequila and the poll had narrowly won.
[00:03:13.840 --> 00:03:17.240]   Okay. And then I ran a poll asking what the most they'd ever
[00:03:17.240 --> 00:03:20.960]   spent on a bottle was. If you price it around to 200 bucks,
[00:03:20.960 --> 00:03:23.880]   you can, you can really maximize the man I think the demand
[00:03:23.880 --> 00:03:28.600]   maximizing function is probably around 180 $190. Right? You do
[00:03:28.600 --> 00:03:31.520]   not need a majority of people to want to buy your tequila, you
[00:03:31.520 --> 00:03:33.480]   just need enough that are willing to pay the right price.
[00:03:33.480 --> 00:03:36.760]   For Oh, I agree. I was just trying to see how much interest
[00:03:36.760 --> 00:03:41.480]   there'd be out there. And in this poll, I think it was 41%
[00:03:41.480 --> 00:03:44.600]   said they would try it 40% said they wouldn't. And then the
[00:03:44.600 --> 00:03:46.800]   remainder was just kind of, you know, show me the answer.
[00:03:46.840 --> 00:03:50.480]   I think if we don't have advertising ever, but we have a
[00:03:50.480 --> 00:03:53.040]   nice sipping tequila, because you know, I don't drink a lot.
[00:03:53.040 --> 00:03:54.800]   But I do like when sacks.
[00:03:54.800 --> 00:04:02.920]   Guys, 32,000 votes. So if you look at 18.8%, so it's 79% is
[00:04:02.920 --> 00:04:06.320]   200 or less. That's the sum of both of those two cohorts. So
[00:04:06.320 --> 00:04:13.120]   like if you price today, call it 189, you probably can get 15%.
[00:04:13.840 --> 00:04:16.800]   And so you know, you could probably sell several 100,000
[00:04:16.800 --> 00:04:19.360]   bottles a year. I mean, that's like a pretty real business.
[00:04:19.360 --> 00:04:22.800]   Okay, but I need something smooth. And I like it a little
[00:04:22.800 --> 00:04:26.400]   sweet. Is that a problem? Can I just give you my opinion? I
[00:04:26.400 --> 00:04:31.720]   think that the thing that people get wrong, just as a consumer,
[00:04:31.720 --> 00:04:35.800]   and I think like I'm a pretty discerning consumer. The thing
[00:04:35.800 --> 00:04:38.720]   that I don't like is that people focus on all of this window
[00:04:38.720 --> 00:04:43.840]   dressing. And they don't focus on the core. And the core is
[00:04:43.840 --> 00:04:50.120]   that, for example, in wine, there's seven or eight rating
[00:04:50.120 --> 00:04:54.320]   systems. And over time, if you buy enough wine and taste
[00:04:54.320 --> 00:04:56.760]   enough wine, you can really figure out who's good at what.
[00:04:56.760 --> 00:05:00.440]   And there's just nothing that replaces a highly rated wine,
[00:05:00.440 --> 00:05:05.120]   it's exceptional. And that kind of discernment is now moving
[00:05:05.120 --> 00:05:08.400]   itself into tequila. And so I would just encourage us if
[00:05:08.400 --> 00:05:11.760]   we're going to make a bottle, just make it an exceptionally
[00:05:11.760 --> 00:05:14.640]   good tasting bottle. And one of the things that I saw in the
[00:05:14.640 --> 00:05:17.880]   comments was that people said, Oh, you can't differentiate. But
[00:05:17.880 --> 00:05:21.160]   then I see some other articles like combos, which is the one
[00:05:21.160 --> 00:05:24.640]   that I tasted at the one and only mandarina. That was the
[00:05:24.640 --> 00:05:28.480]   first 100 point tequila that had ever been given out. And so
[00:05:28.480 --> 00:05:31.360]   there are people that are starting to rate it and create
[00:05:31.360 --> 00:05:33.800]   these rankings. And if we were going to put out a product, I
[00:05:33.800 --> 00:05:38.120]   would err on extreme product quality, versus price point.
[00:05:38.200 --> 00:05:40.640]   I invested in a tequila company, I showed this to you guys
[00:05:40.640 --> 00:05:45.920]   called 21 seeds. And it started by my friends, Nicole, cat and
[00:05:45.920 --> 00:05:51.600]   sarica. And they spent a lot of time in Mexico, finding the
[00:05:51.600 --> 00:05:54.280]   right producer and they put fresh fruit, it's a it's a
[00:05:54.280 --> 00:05:57.640]   female niche tequila. So the goal is to create a tequila
[00:05:57.640 --> 00:06:00.840]   that will appeal to the female demographic. And they spent
[00:06:00.840 --> 00:06:03.720]   quite a lot of time trying to figure out how to actually get
[00:06:03.720 --> 00:06:05.800]   the flavor of fresh fruit without using artificial
[00:06:05.800 --> 00:06:08.400]   flavoring into the tequila. And so there was this big
[00:06:08.400 --> 00:06:10.560]   investment in trying to get this thing to work. This thing
[00:06:10.560 --> 00:06:13.960]   worked, it took off and Diageo bought the company, but it was
[00:06:13.960 --> 00:06:16.520]   because they spent so much time on the quality of the product
[00:06:16.520 --> 00:06:18.560]   that I think they were successful. And that's everyone
[00:06:18.560 --> 00:06:21.920]   else puts their name and label on a on a bottle of tequila and
[00:06:21.920 --> 00:06:24.640]   says, Hey, this is my tequila. But if you don't get the quality
[00:06:24.640 --> 00:06:26.880]   right, Chamath is totally right. People don't buy a second time,
[00:06:26.880 --> 00:06:27.520]   you got to get it right.
[00:06:27.520 --> 00:06:30.200]   If you look at what the rock did, the rock went in a
[00:06:30.200 --> 00:06:32.800]   different direction, which is I think he has a very accessible
[00:06:32.840 --> 00:06:36.440]   and affordable tequila, which I think makes sense, as well.
[00:06:36.440 --> 00:06:38.920]   It's just a different strategy. And that also works for the
[00:06:38.920 --> 00:06:43.080]   rock, because he has almost 400 million followers. And so he can
[00:06:43.080 --> 00:06:46.240]   really play a volume game. But I don't think that that's what we
[00:06:46.240 --> 00:06:47.040]   should ever do.
[00:06:47.040 --> 00:06:48.800]   No, we should stand for exceptional quality,
[00:06:48.800 --> 00:06:51.200]   exceptional quality. And this speaks to something else, which
[00:06:51.200 --> 00:06:53.760]   is one of the biggest points of feedback that I get. So for
[00:06:53.760 --> 00:06:56.640]   example, I took three days, not an item, three days, we took a
[00:06:56.640 --> 00:06:59.640]   little bit of a, our own little honeymoon away from all the kids
[00:06:59.640 --> 00:07:02.080]   and we went to Villa d'Este, just to kind of hang out in Lake
[00:07:02.080 --> 00:07:06.880]   Como, because I was flying out of Milan, and ran into a few
[00:07:06.880 --> 00:07:11.120]   people there. And the consistent feedback that I get from those
[00:07:11.120 --> 00:07:15.240]   folks is like, they love hearing about these different places,
[00:07:15.240 --> 00:07:20.480]   whether it's different brands, different kinds of wine, all of
[00:07:20.480 --> 00:07:24.120]   these things, because all these folks are a little bit left out
[00:07:24.120 --> 00:07:27.520]   in the cold. Now, they don't have like, how to live life
[00:07:27.520 --> 00:07:31.320]   well. And if you work really hard, and you're lucky enough to
[00:07:31.320 --> 00:07:34.440]   then also have some amount of success, why should you feel
[00:07:34.440 --> 00:07:37.280]   ashamed about it? Why shouldn't you be allowed to enjoy that and
[00:07:37.280 --> 00:07:41.280]   actually like, pamper yourself and celebrate yourself and I say
[00:07:41.280 --> 00:07:45.520]   go for it. So if we can find high quality products, like this
[00:07:45.520 --> 00:07:48.280]   is the thing, for example, like I think there's different ways
[00:07:48.280 --> 00:07:53.840]   of expressing success. When I was poor, I was poor in wallet.
[00:07:53.840 --> 00:07:59.280]   And I was also poor in mind. And then somewhere along the way, I
[00:07:59.280 --> 00:08:02.560]   actually became rich in wallet, but I was still poor in mind.
[00:08:02.560 --> 00:08:05.080]   And so I would wear these clothes that were gaudy and had
[00:08:05.080 --> 00:08:09.920]   Oh, God, huge labels are not meables. Dior and Balenciaga.
[00:08:09.920 --> 00:08:13.120]   All those crowds don't pull it up, man. The haircut looked like
[00:08:13.120 --> 00:08:15.800]   Friedberg's. It was disgusting. It was gross. And then I learned
[00:08:15.800 --> 00:08:19.000]   how to be rich in wallet and rich in mind, which is then you
[00:08:19.000 --> 00:08:22.200]   go totally brand off and you can actually find things that are
[00:08:22.200 --> 00:08:25.720]   just like, really well tailored, well made, they can be almost
[00:08:25.720 --> 00:08:29.960]   generational pieces of clothing or whatever. And I think that
[00:08:29.960 --> 00:08:32.640]   it's great that you can find these things and tell other
[00:08:32.640 --> 00:08:35.720]   people because you find that there's a latent so many number
[00:08:35.720 --> 00:08:38.800]   of people that want that. So at Villa d'Este as an example, that
[00:08:38.800 --> 00:08:41.520]   is probably the Harvard of hospitality. I've never been to
[00:08:41.520 --> 00:08:45.920]   a hotel that is more on point anywhere in the world than that
[00:08:45.920 --> 00:08:49.440]   one place. Incredible, incredible ways in which the
[00:08:49.440 --> 00:08:52.960]   name of the winners one more time, Villa d'Este Villa d
[00:08:52.960 --> 00:08:56.320]   apostrophe, e s t e on Lake Cole. I'll give you one simple
[00:08:56.320 --> 00:09:00.120]   example. Matt and I were like, talking about this one kind of
[00:09:00.120 --> 00:09:04.720]   olive oil, and the waiter at the other table heard, he went to
[00:09:04.720 --> 00:09:07.480]   the kitchen brought back and he said here, I heard I just
[00:09:07.480 --> 00:09:10.400]   overheard I apologize, but and I thought this is incredible. You
[00:09:10.400 --> 00:09:14.080]   feel so pampered and loved and taken care of the level of
[00:09:14.080 --> 00:09:17.280]   service and quality there was incredible. And I think that
[00:09:17.280 --> 00:09:20.960]   there's so many examples of this, where if you can have
[00:09:20.960 --> 00:09:24.160]   elements of that in your life, you should do it. By the way,
[00:09:24.160 --> 00:09:26.880]   there's a very high chance that this is where I use all of you
[00:09:26.880 --> 00:09:31.040]   guys for the all in summit 2025. Okay, I'm still figuring out all
[00:09:31.040 --> 00:09:34.320]   the details. I'm picking 2024. My point is whether it's Laura
[00:09:34.320 --> 00:09:37.920]   Piana, which is, in my opinion, the top of the top in terms of
[00:09:37.920 --> 00:09:42.360]   brand off really high quality clothes. Look at that place. The
[00:09:42.360 --> 00:09:45.280]   point is like there's all these brands that exist that take
[00:09:45.280 --> 00:09:49.600]   enormous amounts of time to exemplify craftsmanship and care.
[00:09:50.080 --> 00:09:53.000]   And I think that it's appropriate for people who can
[00:09:53.000 --> 00:09:56.000]   participate in those experiences to be able to have them and not
[00:09:56.000 --> 00:09:58.520]   feel ashamed and actually like enjoy it and celebrate
[00:09:58.520 --> 00:10:02.240]   themselves and do it. So let's go high quality stuff. Not
[00:10:02.240 --> 00:10:05.480]   shitty, big label tacky crap. Okay, Nvidia has smashed their
[00:10:05.480 --> 00:10:08.280]   earnings massive interest coming into this earnings report,
[00:10:08.280 --> 00:10:10.440]   obviously, because we've been talking about Nvidia, they've
[00:10:10.440 --> 00:10:15.160]   had a massive run up. Everybody is trying to buy capacity to run
[00:10:15.160 --> 00:10:18.880]   language models, etc. self driving, yada, yada. And it's
[00:10:18.880 --> 00:10:23.120]   not just the Googles and Amazons of the world, you have startups
[00:10:23.120 --> 00:10:26.920]   trying to buy h 100s a 100s and buy this infrastructure, you
[00:10:26.920 --> 00:10:30.520]   also have sovereign wealth funds and countries buying these in
[00:10:30.520 --> 00:10:33.040]   the Middle East and Europe, and you have traditional corporations
[00:10:33.040 --> 00:10:36.680]   buying them. This is the blowout of world blowouts. In terms of
[00:10:36.680 --> 00:10:41.600]   performance q2 revenue 13.5 billion, 101% year over year,
[00:10:41.600 --> 00:10:45.240]   that's extraordinary on that large of a number, but up 88%
[00:10:45.240 --> 00:10:48.960]   quarter over quarter high growth in stocks is 2030% year over
[00:10:48.960 --> 00:10:52.720]   year. So this is just very uncommon, obviously, q2 net
[00:10:52.720 --> 00:10:58.480]   income $6 billion up 843% year over year, Nvidia is now with
[00:10:58.480 --> 00:11:02.560]   1.2 trillion, it's closing in on Amazon 1.4 trillion, and Google
[00:11:02.560 --> 00:11:05.840]   at $1.7 trillion in terms of market cap. And here's the
[00:11:05.840 --> 00:11:09.360]   kicker, they're printing up so much money, and so much profits
[00:11:09.360 --> 00:11:14.320]   rather that the Nvidia board is approving a $25 billion share
[00:11:14.320 --> 00:11:17.720]   buyback. That's a very large number. In terms of share
[00:11:17.720 --> 00:11:19.360]   buybacks, that's six times higher than what they were
[00:11:19.360 --> 00:11:24.000]   currently allotted. Yeah, I guess Chamath a when you see
[00:11:24.000 --> 00:11:27.840]   this kind of extraordinary run up, what is the ramification
[00:11:27.840 --> 00:11:32.600]   going to be in terms of for the industry competition, and then
[00:11:32.600 --> 00:11:37.120]   just trading this name? Is this peak Nvidia? Or is the peak yet
[00:11:37.120 --> 00:11:37.440]   to come?
[00:11:37.440 --> 00:11:39.920]   Well, I think it's peak in one way, but this is less about a
[00:11:39.920 --> 00:11:42.960]   commentary on Nvidia because they're clearly firing on all
[00:11:42.960 --> 00:11:46.160]   cylinders. But, you know, it's a pretty well established rule in
[00:11:46.160 --> 00:11:49.520]   capitalism, which is when the market observes that there's a
[00:11:49.520 --> 00:11:53.680]   company just printing enormous revenues and profits, they want
[00:11:53.680 --> 00:11:56.080]   to compete with them naturally to get their share of those
[00:11:56.080 --> 00:11:58.960]   revenues and profits. And that typically happens in all
[00:11:58.960 --> 00:12:02.360]   markets. And the result of that are just decaying margins in the
[00:12:02.360 --> 00:12:05.120]   in the absence of a monopoly, this is what you should expect.
[00:12:05.120 --> 00:12:07.520]   And so, because in this market, there's nothing really
[00:12:07.520 --> 00:12:10.240]   monopolistic about what they do, what they do is exceptional and
[00:12:10.240 --> 00:12:14.240]   good. But there are other ways and other systems and other
[00:12:14.240 --> 00:12:17.000]   companies that are developing chipsets and capabilities here
[00:12:17.000 --> 00:12:21.160]   to compete with Nvidia. So it probably just motivates them
[00:12:21.160 --> 00:12:24.440]   even more and accelerates the path where you see competition.
[00:12:24.440 --> 00:12:27.280]   I tweeted this out yesterday. But one of the most interesting
[00:12:27.280 --> 00:12:29.680]   things that could happen is somebody like Tesla decides to
[00:12:29.680 --> 00:12:32.000]   either open source their chip or actually starts to sell their
[00:12:32.000 --> 00:12:35.560]   platform because if FSD gets to a reasonable level of scale, that
[00:12:35.560 --> 00:12:38.760]   entire platform system is a learning and inference system
[00:12:39.080 --> 00:12:41.840]   for the physical world. And I think that has tremendous
[00:12:41.840 --> 00:12:44.760]   applications, you have something called risky, which is an open
[00:12:44.760 --> 00:12:48.600]   architecture spec to essentially compete and create different
[00:12:48.600 --> 00:12:51.360]   versions of different chips that has implications more I think to
[00:12:51.360 --> 00:12:53.920]   arm you have companies like Google that you know, frankly,
[00:12:53.920 --> 00:12:57.360]   spun their own silicon a long time ago, TPU, you have Amazon
[00:12:57.360 --> 00:13:00.280]   now talking about doing the same thing. Microsoft has invested a
[00:13:00.280 --> 00:13:05.000]   lot of money in FPGA technology. So it's just yet another
[00:13:05.000 --> 00:13:11.040]   accelerant in this trend to create many forms of AI enabled
[00:13:11.040 --> 00:13:15.120]   silicon. And so I think that that sort of it, it pulls that
[00:13:15.120 --> 00:13:17.520]   reality forward. And I think we're gonna have to figure out
[00:13:17.520 --> 00:13:21.160]   when the market prices that in, because I think that that
[00:13:21.160 --> 00:13:25.320]   probably decays the Nvidia margin and upside over time.
[00:13:25.320 --> 00:13:27.800]   Again, that is not a commentary on them. That's just a market
[00:13:27.800 --> 00:13:28.440]   reality.
[00:13:28.440 --> 00:13:32.000]   Yeah, margins get competed away. For folks who don't know, Tesla
[00:13:32.000 --> 00:13:34.840]   is making something called dojo. It's their own supercomputer.
[00:13:34.840 --> 00:13:37.840]   Here's a picture of it. They showed that at Tesla AI day last
[00:13:37.840 --> 00:13:42.800]   year. And you have arms, open source competitor is the risk
[00:13:42.800 --> 00:13:45.880]   five chip you're talking about. It's an open source architecture
[00:13:45.880 --> 00:13:49.480]   for doing large jobs. And so I guess my question to you,
[00:13:49.480 --> 00:13:53.320]   Friedberg is, if you look at all this capacity coming online, do
[00:13:53.320 --> 00:13:56.480]   you think we're going to be in a situation where the amount of
[00:13:56.480 --> 00:14:00.480]   capacity compute being put online is going to outstrip the
[00:14:00.480 --> 00:14:03.360]   need for that compute, because software is getting so much
[00:14:03.360 --> 00:14:06.920]   better. And then maybe, you know, people are running hugging
[00:14:06.920 --> 00:14:11.520]   face jobs and various LM's on the new silicon from Apple, and
[00:14:11.520 --> 00:14:14.640]   they're running it on their M two's. And so do we need this
[00:14:14.640 --> 00:14:17.560]   much capacity? Are there enough interesting jobs in the world
[00:14:17.560 --> 00:14:20.400]   to for all this capacity? And then might that also be a
[00:14:20.400 --> 00:14:23.680]   headwind against Nvidia when people say, you know what, I got
[00:14:23.680 --> 00:14:25.200]   enough, I got enough capacity here.
[00:14:25.200 --> 00:14:29.600]   I think the rational way to think about this is to try and
[00:14:29.600 --> 00:14:35.320]   calculate the efficient frontier on compute use. So the more
[00:14:35.320 --> 00:14:41.040]   compute you use, the more it costs you. The question then is,
[00:14:41.040 --> 00:14:43.400]   if you double the amount of compute you're using for a
[00:14:43.400 --> 00:14:47.360]   particular application, do you get twice the return on the
[00:14:47.360 --> 00:14:52.360]   investment? If you triple it, does your ROI on a percentage
[00:14:52.360 --> 00:14:56.320]   basis, you know, go up or go down. So at some point, you
[00:14:56.320 --> 00:14:59.400]   reach an efficient frontier, which is you start to see a
[00:14:59.400 --> 00:15:02.960]   declining or negative rate of return on the investment in the
[00:15:02.960 --> 00:15:06.040]   compute that you're using for a particular application. And this
[00:15:06.040 --> 00:15:08.360]   is certainly going to be application and market specific,
[00:15:08.360 --> 00:15:11.280]   it's going to be largely driven by the data that is available in
[00:15:11.280 --> 00:15:15.160]   that market to do training to do tuning the market's appetite to
[00:15:15.160 --> 00:15:18.840]   spend money for that particular set of applications that emerges
[00:15:18.840 --> 00:15:23.760]   from that compute that's being used. And so we don't know today
[00:15:23.760 --> 00:15:27.640]   where the efficient frontier is across each of these different
[00:15:27.640 --> 00:15:30.360]   markets and sets of applications. And the market is
[00:15:30.360 --> 00:15:34.160]   finding that out. In the process of finding that out, everyone is
[00:15:34.160 --> 00:15:37.520]   spending a shit ton of money on compute. And they are trying to
[00:15:37.520 --> 00:15:40.800]   get as many server racks as they can. They're trying to get as
[00:15:40.800 --> 00:15:44.200]   many chipsets as they can, they're trying to get as much
[00:15:44.200 --> 00:15:47.200]   server time as they can. And everyone's got this idea that
[00:15:47.200 --> 00:15:51.760]   the more compute I can throw at a problem, the return is going
[00:15:51.760 --> 00:15:54.200]   to scale linearly. And it turns out that like with most most
[00:15:54.200 --> 00:15:58.400]   things, the answer is likely not. So we're at this point
[00:15:58.400 --> 00:16:03.680]   right now. And I would argue a bit of a cycle, that the there
[00:16:03.680 --> 00:16:06.640]   looks to be a bubble. And what I mean by that is that there's a
[00:16:06.640 --> 00:16:10.000]   lot of inefficient spending going on, as the efficient
[00:16:10.000 --> 00:16:12.800]   frontiers are discovered across all these different application
[00:16:12.800 --> 00:16:17.440]   sets. And so my intuition without a lot of actual data to
[00:16:17.440 --> 00:16:20.840]   back this up, is that based just anecdotally on what I'm hearing
[00:16:20.840 --> 00:16:23.240]   people doing in the market, what companies are doing, what
[00:16:23.240 --> 00:16:26.320]   startups are doing, etc. Everyone is throwing everything
[00:16:26.320 --> 00:16:28.680]   they can compute. And they're going to realize that they're
[00:16:28.680 --> 00:16:31.000]   going to need to rationalize those expenses at some time at
[00:16:31.000 --> 00:16:34.280]   some point. So I would, I would envision Nvidia is probably
[00:16:34.280 --> 00:16:37.360]   writing, writing a little bit of a discovery of the efficient
[00:16:37.360 --> 00:16:40.480]   frontier wave right now. And that this probably is not
[00:16:40.480 --> 00:16:41.800]   necessarily steady state.
[00:16:41.800 --> 00:16:46.080]   Saks, we experienced this before. As you remember, from
[00:16:46.080 --> 00:16:49.800]   the dotcom era, there was a massive investment very similar
[00:16:49.800 --> 00:16:53.240]   to this in fiber, and the overspending of building the
[00:16:53.240 --> 00:16:56.040]   fiber infrastructure, so everybody could get broadband,
[00:16:56.040 --> 00:17:01.560]   and they could stream movies, etc. happened in that 97 to 2002
[00:17:01.560 --> 00:17:04.120]   time period. A lot of those companies went out of business,
[00:17:04.120 --> 00:17:06.960]   a lot of that fiber never got used. People were working on
[00:17:06.960 --> 00:17:09.280]   compression algorithms while they were building a massive
[00:17:09.280 --> 00:17:11.720]   fiber, and a lot of that fiber got sold. I think Google bought
[00:17:11.720 --> 00:17:14.640]   up a lot of it, other people bought it up. And it was just a
[00:17:14.640 --> 00:17:18.960]   massive overspend. So is this like the dark fiber of this era
[00:17:18.960 --> 00:17:22.360]   where we're just going to build so much capacity, that there's
[00:17:22.360 --> 00:17:25.320]   just going to be not enough jobs to run on it in your mind?
[00:17:25.320 --> 00:17:27.120]   Well, I think it's a little different than fiber in the
[00:17:27.120 --> 00:17:29.480]   sense that every year, there's gonna be a new generation of
[00:17:29.480 --> 00:17:35.920]   chips. And so these cloud providers who are providing GPU
[00:17:35.920 --> 00:17:38.760]   compute, they're going to want to keep upgrading the chips to
[00:17:38.760 --> 00:17:41.760]   be able to address the next generation of applications. So I
[00:17:41.760 --> 00:17:44.600]   don't think it's quite as static as fiber where you kind of build
[00:17:44.600 --> 00:17:47.720]   it once. And you're right that there was kind of a glut of
[00:17:47.720 --> 00:17:50.560]   capacity was created. Eventually, though, the internet
[00:17:50.560 --> 00:17:53.640]   usage grew into that capacity. But I think this is a little
[00:17:53.640 --> 00:17:55.600]   different, because again, you're going to need to upgrade the
[00:17:55.600 --> 00:17:58.840]   chips every year or two. I think Freeberg is right that this is
[00:17:58.840 --> 00:18:03.520]   clearly a spike in demand that may not be sustainable. I mean,
[00:18:03.520 --> 00:18:06.880]   recall what happened here is that chat GPT launched on
[00:18:06.880 --> 00:18:10.280]   November 30, last year, and really caught everyone by
[00:18:10.280 --> 00:18:13.120]   surprise, it kind of took the world by storm. And over the
[00:18:13.120 --> 00:18:15.440]   next few months, you had hundreds of millions of users
[00:18:15.440 --> 00:18:19.120]   discover AI, I think it's surprised even the open AI team,
[00:18:19.120 --> 00:18:21.840]   I think when they launched chat GPT, they thought it'd be more
[00:18:21.840 --> 00:18:25.480]   of a proof of concept. But it ended up being a lot more than
[00:18:25.480 --> 00:18:28.920]   that. And so everyone has scrambled all of a sudden, in
[00:18:28.920 --> 00:18:32.840]   the last nine months or so, to develop their own AI strategy.
[00:18:32.840 --> 00:18:36.840]   And so, again, it was this giant platform shift that happened
[00:18:36.840 --> 00:18:41.080]   overnight. So there is a tremendous GPU shortage right
[00:18:41.080 --> 00:18:46.000]   now. And that's also what's leading to these almost software
[00:18:46.000 --> 00:18:49.360]   like profit margins by Nvidia. Because when everyone's
[00:18:49.360 --> 00:18:53.080]   clamoring to get a limited supply of these chips, and
[00:18:53.080 --> 00:18:55.760]   there just aren't enough Nvidia can almost charge whatever they
[00:18:55.760 --> 00:18:59.280]   want. And so I think even more than the demand, the profit
[00:18:59.280 --> 00:19:02.960]   margins might not be sustainable. But I think the
[00:19:02.960 --> 00:19:06.120]   reality is we just don't know what the steady state of demand
[00:19:06.120 --> 00:19:10.560]   in this market is going to be. I think we can say that it can't
[00:19:10.560 --> 00:19:14.440]   continue at these growth rates. But probably there will be some
[00:19:14.440 --> 00:19:17.520]   steady state of demand. That's, you know, it probably is at
[00:19:17.520 --> 00:19:18.560]   least where we are today.
[00:19:18.560 --> 00:19:21.680]   Yeah, I don't think it's perfectly analogous Chamath. But
[00:19:21.680 --> 00:19:25.760]   just to bring up some historical context, check out this article
[00:19:25.760 --> 00:19:28.080]   I was reading the other day, the dimensions of the collapse of
[00:19:28.080 --> 00:19:32.000]   the telecommunications industry. This is August 20 2002. And it
[00:19:32.000 --> 00:19:35.320]   says, the dimension of the collapse in the telecommunications
[00:19:35.320 --> 00:19:37.840]   industry during the past two years has been staggering half a
[00:19:37.840 --> 00:19:40.120]   million people have lost their jobs in that time, the Dow Jones
[00:19:40.120 --> 00:19:42.920]   communication technology index has dropped 86% the wireless
[00:19:42.920 --> 00:19:46.920]   communication index 89%. These are declines in value worthy of
[00:19:46.920 --> 00:19:49.960]   comparison to the Great Crash of 1929. Out of the 7 trillion
[00:19:49.960 --> 00:19:53.160]   decline in the stock market since its peak about 2 trillion
[00:19:53.160 --> 00:19:55.680]   have disappeared in the capitalization of telecom
[00:19:55.680 --> 00:19:58.440]   companies. 23 telecom companies have gone bankrupt in a wave
[00:19:58.440 --> 00:20:01.880]   capped off by the July 21 collapse of worldcom the single
[00:20:01.880 --> 00:20:04.480]   largest bankruptcy in American history. So just a little
[00:20:04.480 --> 00:20:08.560]   history there of this, it's not perfectly analogous. Obviously,
[00:20:08.560 --> 00:20:10.480]   we don't have Nvidia is not going bankrupt or anything like
[00:20:10.480 --> 00:20:13.040]   that. But this overcapacity issue is definitely going to be
[00:20:13.040 --> 00:20:17.040]   something but you had mentioned that in one of your tweet storms
[00:20:17.040 --> 00:20:19.040]   in the past couple of weeks, or these long form that you're
[00:20:19.040 --> 00:20:23.480]   doing on x, previously known as Twitter. You mentioned that what
[00:20:23.480 --> 00:20:27.880]   are the jobs that could be pushed to this compute? And what
[00:20:27.880 --> 00:20:29.880]   if one of the works, I think you were doing a speaking gig that
[00:20:29.880 --> 00:20:33.840]   somebody tweeted out a little clip of. So let's unpack that.
[00:20:33.840 --> 00:20:36.320]   What do you think are some jobs that people might push here that
[00:20:36.320 --> 00:20:39.360]   we don't anticipate that could solve something miraculous in
[00:20:39.360 --> 00:20:39.760]   the world?
[00:20:39.760 --> 00:20:43.800]   Well, the the framing is really like if you if you go back to
[00:20:43.800 --> 00:20:47.680]   like the the gold rush of the 1800s in San Francisco, the
[00:20:47.680 --> 00:20:50.160]   people that made the money were the platform enablers, right?
[00:20:50.160 --> 00:20:52.720]   They were the ones that sold the picks the shovels, the pans and
[00:20:52.720 --> 00:20:55.820]   the jeans. Right. And that's where that's where Levi Strauss
[00:20:55.820 --> 00:20:59.480]   was born. The the equivalent analogy, the equivalence in that
[00:20:59.480 --> 00:21:04.720]   analogy today is Nvidia, because they are the dominant pick and
[00:21:04.720 --> 00:21:08.520]   shovel provider. So the question is, well, what are we going to
[00:21:08.520 --> 00:21:10.920]   use these picks and shovels to create? Are we going to find
[00:21:10.920 --> 00:21:14.200]   gold? And I think the question is unclear. And where will that
[00:21:14.200 --> 00:21:17.200]   gold be found? Will it be found inside of a big tech company? Or
[00:21:17.200 --> 00:21:20.200]   will it be found inside of a startup? If you look inside of
[00:21:20.200 --> 00:21:23.880]   where these resources are being used inside of big tech, it is
[00:21:23.880 --> 00:21:28.840]   to completely scorch the earth on the economic value of large
[00:21:28.840 --> 00:21:32.960]   models. And I think that that's very, very good for all of the
[00:21:32.960 --> 00:21:35.920]   startups that come after it. So what do I mean by this? You
[00:21:35.920 --> 00:21:40.800]   know, we were also wrapped around the axle around chat GPT
[00:21:40.800 --> 00:21:44.720]   and then GPT in general. And now, you know, if you look at
[00:21:44.720 --> 00:21:49.160]   the quality of llama, llama to basically these big companies
[00:21:49.160 --> 00:21:52.520]   have decided, no, we're just going to make all these models
[00:21:52.520 --> 00:21:57.520]   extremely good, extremely useful and very, very free. And so a
[00:21:57.520 --> 00:22:00.960]   lot of the resources are going there to subsidize economically
[00:22:00.960 --> 00:22:05.120]   subsidize and by implication, economically destroy the value
[00:22:05.120 --> 00:22:09.960]   of that category, that's going to be good for startups. And so
[00:22:09.960 --> 00:22:14.120]   the question is, what will you then build on top of these
[00:22:14.120 --> 00:22:19.080]   quasi free, almost free tools. And so one area that I have been
[00:22:19.080 --> 00:22:21.520]   looking at for a while is in computational biology, I think
[00:22:21.520 --> 00:22:23.360]   that that clip that you're talking about was just me
[00:22:23.360 --> 00:22:29.360]   talking with Orin Z. Just around the ability to compute large
[00:22:29.360 --> 00:22:33.960]   complex spaces with very sparse information. It's not it's a
[00:22:33.960 --> 00:22:36.920]   very difficult task today. But tomorrow in an AI model that you
[00:22:36.920 --> 00:22:39.880]   can train, you can literally characterize every single
[00:22:39.880 --> 00:22:43.280]   molecular permutation you could imagine. You combine it with
[00:22:43.280 --> 00:22:45.280]   something like alpha fold, and you can understand protein
[00:22:45.280 --> 00:22:47.440]   folding. And all of a sudden, you can sequentially start to
[00:22:47.440 --> 00:22:50.760]   put tools together that could theoretically give you much
[00:22:50.760 --> 00:22:56.760]   higher probability, guessing for specific compounds that could
[00:22:56.760 --> 00:22:59.320]   actually cure disease. A different version of that as a
[00:22:59.320 --> 00:23:02.840]   company that myself and a few other people started, I tweeted
[00:23:02.840 --> 00:23:05.440]   that out, which is more in the material science space. And
[00:23:05.440 --> 00:23:08.120]   we've had some pretty important breakthroughs there, which is
[00:23:08.120 --> 00:23:10.800]   really about trying to invent next generation battery
[00:23:10.800 --> 00:23:16.040]   materials. And we have one candidate that could be pretty
[00:23:16.040 --> 00:23:19.320]   revolutionary, if it turns out to work, we don't know yet some
[00:23:19.320 --> 00:23:22.440]   positive science. So there are there are some of these green
[00:23:22.440 --> 00:23:25.160]   shoots. So my perspective is that a lot of the money that
[00:23:25.160 --> 00:23:28.440]   NVIDIA makes today is going to be money well spent, because it
[00:23:28.440 --> 00:23:33.360]   will be going to the big guys, big tech plus Tesla, they are
[00:23:33.360 --> 00:23:37.640]   then going to create some really foundational platform
[00:23:37.640 --> 00:23:42.000]   technologies with it, whether it's dojo, whether it's FSD,
[00:23:42.000 --> 00:23:44.680]   whether it's the full platform inside of Tesla, that is the
[00:23:44.680 --> 00:23:48.080]   cameras plus the inference plus the training for all forms of
[00:23:48.080 --> 00:23:51.640]   physical world interaction, whether it's llama to, and all
[00:23:51.640 --> 00:23:54.640]   of that stuff will be given away, essentially, I think, open
[00:23:54.640 --> 00:23:58.760]   source quasi free to the ecosystem over the next few
[00:23:58.760 --> 00:24:02.480]   years. And I think that will be a really important moment, which
[00:24:02.480 --> 00:24:06.520]   will create hundreds of new companies doing really clever,
[00:24:06.520 --> 00:24:10.480]   cool things. So we haven't yet seen the big breakout company
[00:24:10.480 --> 00:24:13.680]   yet. And so I think that right now, most of this capex is going
[00:24:13.680 --> 00:24:18.600]   to the big guys. But the dividends of all the work that
[00:24:18.600 --> 00:24:22.720]   these big guys are doing will be seen over the next few years in
[00:24:22.720 --> 00:24:25.480]   the startups that get started in the next four or five years.
[00:24:25.480 --> 00:24:28.160]   I love the California analogy. Ultimately, what all that
[00:24:28.160 --> 00:24:31.640]   prospecting for gold did was create the state of California,
[00:24:31.640 --> 00:24:35.320]   putting aside the Levi's and the jeans. And if you know anything
[00:24:35.320 --> 00:24:40.840]   about California's GDP, it would be Yeah, I think these
[00:24:40.840 --> 00:24:43.400]   statistics are always talked about fifth, 10th, eighth
[00:24:43.400 --> 00:24:46.960]   largest, has a bigger GDP, California than some of the
[00:24:46.960 --> 00:24:51.200]   largest countries in the world. So this is a 2015 chart, it's
[00:24:51.200 --> 00:24:53.400]   hard to find the updated information on this. But
[00:24:53.400 --> 00:24:55.560]   ultimately, that was the product of the gold rush is this
[00:24:55.560 --> 00:24:57.920]   incredible state. Any other thoughts on Nvidia before we
[00:24:57.920 --> 00:24:59.440]   move on to arm,
[00:24:59.440 --> 00:25:02.880]   I think OpenAI had a potentially significant product
[00:25:02.880 --> 00:25:07.080]   announcement that's related to this. So they just launched
[00:25:07.080 --> 00:25:13.000]   fine tuning for chat dbt, actually version 3.5. Turbo says
[00:25:13.000 --> 00:25:15.160]   here fine tuning lets you train the model and your company's
[00:25:15.160 --> 00:25:19.240]   data run at scale early tests have shown that fine tune dbt
[00:25:19.360 --> 00:25:24.120]   3.5 can metric CGT for on narrow tasks. So you can do things
[00:25:24.120 --> 00:25:30.200]   like fine tune the formatting of the output, you can fine tune
[00:25:30.200 --> 00:25:33.360]   the tone fine tuning also allows businesses to make the model
[00:25:33.360 --> 00:25:38.200]   follow instructions better. So I think the point of this is that
[00:25:38.200 --> 00:25:41.800]   we're still at such an early stage of this. And there are so
[00:25:41.800 --> 00:25:44.360]   many applications that are going to be developed, and they're
[00:25:44.360 --> 00:25:48.120]   making the models more and more useful. So Jason, to your
[00:25:48.120 --> 00:25:51.400]   analogy about fiber, what happened with fiber is there was
[00:25:51.400 --> 00:25:55.200]   a big build out of overcapacity, but then the number of
[00:25:55.200 --> 00:25:58.840]   applications kept growing until that capacity got used. And I
[00:25:58.840 --> 00:26:01.040]   think we're probably going to see something like that here
[00:26:01.040 --> 00:26:04.600]   where there is a big build out going on of capacity, but and
[00:26:04.600 --> 00:26:07.040]   capabilities, and that's going to lead to the next generation
[00:26:07.040 --> 00:26:11.120]   of applications. And I just think we don't know yet what the
[00:26:11.120 --> 00:26:14.480]   steady state of either demand or supply for these chips is going
[00:26:14.480 --> 00:26:18.600]   to be. Obviously, the market got taken by surprise over the last
[00:26:18.600 --> 00:26:22.280]   year. So you've seen, again, this huge spike in demand, the
[00:26:22.280 --> 00:26:25.560]   supply cannot react fast enough. That's led to gigantic profits
[00:26:25.560 --> 00:26:29.120]   for Nvidia. But it's hard to know exactly again, what is the
[00:26:29.120 --> 00:26:31.000]   steady state going to be? Is it going to be like this? Or is
[00:26:31.000 --> 00:26:34.560]   this a one time spike? And we also don't know what the supply
[00:26:34.560 --> 00:26:37.720]   will be once the manufacturers all adjust, because now they
[00:26:37.720 --> 00:26:38.840]   know that the demand is there.
[00:26:38.840 --> 00:26:43.280]   And to your point, like the the big use cases are pushing us
[00:26:43.280 --> 00:26:48.040]   well past chips to really be more like entire systems, and
[00:26:48.040 --> 00:26:50.640]   these racks. And so if you look like at grace opera, which is
[00:26:50.640 --> 00:26:54.800]   their next gen design, it's like a bunch of chiplets plus memory
[00:26:54.800 --> 00:26:58.560]   on a huge board. It's not a chip, you're talking about
[00:26:58.560 --> 00:27:01.880]   system level manufacturing at this point. And that will also
[00:27:01.880 --> 00:27:05.000]   create different kinds of use cases. Because for example,
[00:27:05.000 --> 00:27:06.960]   today, right now, when you look at simple things like
[00:27:06.960 --> 00:27:10.040]   probabilistic tasks, I think chat GPT, and all these GPTs
[00:27:10.040 --> 00:27:13.680]   are, are pretty marvelous and pretty inspirational. But
[00:27:13.680 --> 00:27:16.280]   deterministic tasks, they're shit, like, you know, they
[00:27:16.280 --> 00:27:18.880]   hallucinate on simple things like multiplication, why,
[00:27:18.880 --> 00:27:20.840]   because you infer multiplication, and you try to
[00:27:20.840 --> 00:27:23.760]   calculate it probabilistically, and you get these simple math
[00:27:23.760 --> 00:27:27.360]   functions wrong. And so these are all these things where the
[00:27:27.360 --> 00:27:30.280]   software has to become more and more sophisticated, and actually
[00:27:30.280 --> 00:27:33.560]   be able to path and tunnel code into different ways of getting
[00:27:33.560 --> 00:27:35.880]   an executed and then bringing it back and stitching it together.
[00:27:35.880 --> 00:27:39.440]   All of these things don't exist. Those are very rudimentary
[00:27:39.440 --> 00:27:43.400]   things that were solved in v1 of compute. So I think that to
[00:27:43.400 --> 00:27:47.080]   your point, David, like we don't know where this goes, we're
[00:27:47.080 --> 00:27:49.800]   probably going to go to a place that it's not just about chips,
[00:27:49.800 --> 00:27:53.160]   but it's about systems. But that's going to create this
[00:27:53.160 --> 00:27:58.440]   weird balkanization almost. And I think that's where a lot of
[00:27:58.440 --> 00:28:01.200]   the profit margins will get eroded away, because that will
[00:28:01.200 --> 00:28:06.560]   make it a much more competitive industry. And there just isn't
[00:28:06.560 --> 00:28:08.840]   a lot of margin to capture when you actually stitch all these
[00:28:08.840 --> 00:28:09.480]   things together.
[00:28:09.480 --> 00:28:14.160]   Yeah. And if you think about what were the massive wins for
[00:28:14.160 --> 00:28:17.600]   all that extra fiber, it was really two companies. The first
[00:28:17.600 --> 00:28:20.880]   was YouTube, which stopped charging people for transport on
[00:28:20.880 --> 00:28:24.040]   their videos before that, if you had a video go viral, your your
[00:28:24.040 --> 00:28:28.080]   server got shut down, because you hit your $5,000 a month
[00:28:28.080 --> 00:28:31.120]   limit, or whatever you had set with your ISP. And then Netflix,
[00:28:31.120 --> 00:28:33.200]   of course, right, Netflix couldn't exist, and all that
[00:28:33.200 --> 00:28:35.760]   dark fiber built that. So we'll see with all this extra GPU,
[00:28:35.760 --> 00:28:39.160]   what could happen. And to your point about the the breakthrough
[00:28:39.160 --> 00:28:45.000]   is there, you can now go into your chat GPT, and you can put
[00:28:45.000 --> 00:28:47.680]   in custom instructions. And so it asks you, what would you like
[00:28:47.680 --> 00:28:52.360]   chat GPT to know about you and provide better responses. And
[00:28:52.360 --> 00:28:54.720]   you know, for example, I told it, I'm a venture capitalist, I
[00:28:54.720 --> 00:28:57.880]   live in the Bay Area, I'm looking for concise business
[00:28:57.880 --> 00:29:01.760]   information. And then it says, Well, how do you like, how would
[00:29:01.760 --> 00:29:04.360]   you like chat GPT to respond? And I said, I like to see data
[00:29:04.360 --> 00:29:07.880]   in a table. I like to see data in those tables with hyperlinks.
[00:29:07.880 --> 00:29:10.480]   I like citations when possible. Yeah, just to be clear what
[00:29:10.480 --> 00:29:12.720]   you're describing with custom instructions. That was a feature
[00:29:12.720 --> 00:29:15.480]   I think they launched like a month or two ago. And what that
[00:29:15.480 --> 00:29:20.000]   is doing is prompt engineering, basically, it's pre saving, like
[00:29:20.000 --> 00:29:22.840]   all that preamble that you would have to put in every single one
[00:29:22.840 --> 00:29:25.880]   of your prompts. Yeah. Whereas this fine tuning, as I
[00:29:25.880 --> 00:29:29.320]   understand it is more about fine tuning the model to your to
[00:29:29.320 --> 00:29:31.640]   improve the model for a certain kind of data or certain kind of
[00:29:31.640 --> 00:29:34.880]   output. Right. So the example there would be if you had your
[00:29:34.880 --> 00:29:37.400]   email box, or you had your Google Docs, or you had a
[00:29:37.400 --> 00:29:40.120]   repository of all your slack messages or something in your
[00:29:40.120 --> 00:29:43.120]   company, you had your company handbooks, or, you know, all of
[00:29:43.120 --> 00:29:45.640]   Chamath's letters he writes every year, you could have that
[00:29:45.640 --> 00:29:48.480]   uploaded to chat GPT is potentially very powerful, I
[00:29:48.480 --> 00:29:52.720]   think for enterprises. I think the big enterprise use case, the
[00:29:52.720 --> 00:29:56.040]   most obvious one is that every enterprise wants its own
[00:29:56.040 --> 00:30:00.280]   internal chatbot, it wants its own internal chat GPT, where the
[00:30:00.280 --> 00:30:04.920]   employees can ask questions, and the AI has access to all the
[00:30:04.920 --> 00:30:07.400]   company's information, and it understands permissions and
[00:30:07.400 --> 00:30:10.240]   privacy. So it only reveals information to people who have
[00:30:10.240 --> 00:30:13.000]   the right to see it. That's kind of a tall order. But I think
[00:30:13.000 --> 00:30:16.320]   that's what the market wants. Yeah, they want the chat GPT for
[00:30:16.320 --> 00:30:19.360]   the company intranet. Yes. And so there's a lot of people
[00:30:19.360 --> 00:30:23.080]   racing to provide that. And there was a interesting tweet by
[00:30:23.080 --> 00:30:25.800]   Nathan, the nature anyway, he just said, bye bye a bunch of
[00:30:25.800 --> 00:30:28.240]   startups. So I guess a lot of stars were working on this fine
[00:30:28.240 --> 00:30:32.160]   tuning problem that may be to glib. Because I think there's
[00:30:32.160 --> 00:30:35.000]   just a lot of enterprises who do not want to share all their
[00:30:35.000 --> 00:30:36.640]   corporate information with open AI.
[00:30:36.640 --> 00:30:38.960]   Of course, what if it's HR information, then you have
[00:30:38.960 --> 00:30:41.200]   people asking, like, Who are the most overpaid people in this
[00:30:41.200 --> 00:30:43.760]   company? You know, what if it's like the badge information and
[00:30:43.760 --> 00:30:45.200]   how many hours people are working? Or
[00:30:45.200 --> 00:30:47.960]   that's more about permissions, Jason. But even if open AI can
[00:30:47.960 --> 00:30:50.120]   nail the permissions problem, I think there's a lot of
[00:30:50.120 --> 00:30:53.800]   enterprises who will not want to trust their data to AI. Yeah,
[00:30:53.800 --> 00:30:55.800]   they're gonna be afraid about where it goes. This is why I
[00:30:55.800 --> 00:30:59.560]   think open source is taking off in a big way is that I think big
[00:30:59.560 --> 00:31:02.400]   enterprises would much rather roll their own models, and
[00:31:02.400 --> 00:31:04.360]   control it and do the fine tuning. And that's why they're
[00:31:04.360 --> 00:31:07.760]   using tools like mosaic and hugging faces, they want to have
[00:31:07.760 --> 00:31:08.920]   control over it themselves.
[00:31:08.920 --> 00:31:11.800]   That's an excellent point. And that has implications as well
[00:31:11.800 --> 00:31:14.320]   into the hardware, which is also probably a good jumping off
[00:31:14.320 --> 00:31:17.600]   point for arm because this that what you said is exactly must
[00:31:17.600 --> 00:31:21.280]   happen for the integrity of an organization to want to use
[00:31:21.280 --> 00:31:25.120]   these things. And if that happens, then it just further
[00:31:25.120 --> 00:31:28.000]   further accelerates, I think, how the hardware will get
[00:31:28.000 --> 00:31:31.640]   abstracted, and frankly, quasi open sourced as well. All right,
[00:31:31.640 --> 00:31:34.120]   let's talk Facebook did a great job of this, because like, when
[00:31:34.120 --> 00:31:37.960]   Facebook was building data centers, they had to invent
[00:31:37.960 --> 00:31:41.640]   tremendous capabilities that didn't exist before. And the
[00:31:41.640 --> 00:31:44.120]   market was really fragmented, it was very expensive. And what
[00:31:44.120 --> 00:31:47.000]   they did was they basically created these reference designs
[00:31:47.000 --> 00:31:49.640]   for servers and blades and the whole nine yards and open
[00:31:49.640 --> 00:31:53.280]   source the whole thing. And it just, you know, in essence,
[00:31:53.520 --> 00:31:56.920]   destroyed a market, but it created a hyper efficient market
[00:31:56.920 --> 00:32:00.240]   that then everybody could use. And I think the question is that
[00:32:00.240 --> 00:32:03.880]   if it's happening at the software layer already now, just
[00:32:03.880 --> 00:32:08.800]   like it did in web to software, and then we see certain elements
[00:32:08.800 --> 00:32:12.720]   of web to hardware been open sourced, I think it makes pretty
[00:32:12.720 --> 00:32:14.840]   logical sense that you can expect the same things to
[00:32:14.840 --> 00:32:18.880]   happen in the AI world. The AI models and the AI platforms and
[00:32:18.880 --> 00:32:21.440]   they all of that stuff will first get open source because
[00:32:21.440 --> 00:32:25.280]   it's a data integrity, security issue. And then the hardware
[00:32:25.280 --> 00:32:27.800]   will get open source as well, because you just want simple
[00:32:27.800 --> 00:32:30.000]   reference designs you can use and plug and play.
[00:32:30.000 --> 00:32:33.120]   Yeah, if you want to look at that, it's called the open
[00:32:33.120 --> 00:32:37.280]   compute project, open compute.org. Just a way to use
[00:32:37.280 --> 00:32:39.960]   open source to grind down the prices take out the margin, I
[00:32:39.960 --> 00:32:43.640]   guess is what you're saying, Chama to make all these data
[00:32:43.640 --> 00:32:46.520]   centers scale, right? Well, so
[00:32:46.520 --> 00:32:50.120]   you know, so one related story here is this just happened in
[00:32:50.120 --> 00:32:54.040]   the last few weeks, there's a company called core weave, which
[00:32:54.040 --> 00:32:56.960]   provides cloud infrastructure for AI training, it secured a
[00:32:56.960 --> 00:33:01.000]   $2.3 billion investment in the form of a loan, what core weave
[00:33:01.000 --> 00:33:06.200]   is trying to do, it's kind of like AWS, but for GPUs. So
[00:33:06.200 --> 00:33:10.400]   essentially, instead of having to buy your own GPUs, in order
[00:33:10.400 --> 00:33:13.040]   to, you know, set up your own infrastructure, you just
[00:33:13.040 --> 00:33:16.480]   basically rent compute from these guys.
[00:33:16.480 --> 00:33:18.960]   But this is this is exactly why like none of these, none of
[00:33:18.960 --> 00:33:21.600]   these companies will really be allowed to exist in this exact
[00:33:21.600 --> 00:33:24.400]   way four or five years from now, because ultimately, what people
[00:33:24.400 --> 00:33:27.080]   want is massive throughput, right tokens per second, give me
[00:33:27.080 --> 00:33:30.520]   as many tokens per second as possible. And they don't
[00:33:30.520 --> 00:33:34.080]   particularly care. Again, if you understand the model, do they
[00:33:34.080 --> 00:33:37.000]   really care what the underlying substrate hardware should be? It
[00:33:37.000 --> 00:33:39.680]   doesn't seem like they should, they should care what is the
[00:33:39.680 --> 00:33:42.640]   throughput? What do I pay for it? And by the way, that is
[00:33:42.640 --> 00:33:45.520]   exactly what happened when AWS really start to scale. Because
[00:33:45.520 --> 00:33:48.040]   if you guys remember, when we started to first extract code
[00:33:48.160 --> 00:33:51.200]   into AWS, what do we care about? How much did an EC two instance
[00:33:51.200 --> 00:33:53.920]   cost? How much did an s3 bucket cost? And that's all we cared
[00:33:53.920 --> 00:33:57.800]   about. Because that abstraction allowed us to not care about the
[00:33:57.800 --> 00:34:01.000]   underlying hardware, who was the vendor? What was the con
[00:34:01.000 --> 00:34:04.520]   configuration, it didn't matter. And so in an interesting way,
[00:34:04.520 --> 00:34:06.640]   we're going to go through that same evolution here, because
[00:34:06.640 --> 00:34:10.400]   it's just economically rational that that kind of market exists,
[00:34:10.400 --> 00:34:13.520]   you should only care tokens per second, I think.
[00:34:13.520 --> 00:34:16.320]   All right, in other news, oh, by the way, there's something
[00:34:16.320 --> 00:34:19.280]   called common crawl, which is another interesting open source
[00:34:19.280 --> 00:34:22.800]   project that is getting a lot more attention today. Because
[00:34:22.800 --> 00:34:25.160]   they have crawled the web, and you can use this common crawl,
[00:34:25.160 --> 00:34:28.120]   they release it monthly. And that's what a lot of people are
[00:34:28.120 --> 00:34:31.440]   training their data on. Now, they don't have permission from
[00:34:31.440 --> 00:34:35.040]   all those people to do training data. But they do have the
[00:34:35.040 --> 00:34:37.680]   ability for you to download an open crawl, essentially what
[00:34:37.680 --> 00:34:41.680]   Google has, and you have a an open source version of it. So
[00:34:42.000 --> 00:34:46.560]   common crawl was started and funded by Gil Alba's. Yeah, he's
[00:34:46.560 --> 00:34:50.520]   a he's a friend. Gil sold his company applied semantics to
[00:34:50.520 --> 00:34:56.120]   Google back in Oh, two or three. And a big part of his effort
[00:34:56.120 --> 00:35:01.600]   with common crawl is to that's not effectively is it AdSense
[00:35:01.600 --> 00:35:06.480]   for words in AdSense. So basically, applied semantics
[00:35:06.480 --> 00:35:10.960]   could read a web page, and then create the keywords associated
[00:35:10.960 --> 00:35:13.160]   with the content on that web page. And then those keywords
[00:35:13.160 --> 00:35:15.520]   would trigger AdWords ads on the on the web page. So he called it
[00:35:15.520 --> 00:35:18.400]   AdSense. So AdSense started, and the whole publisher network at
[00:35:18.400 --> 00:35:22.880]   Google was born from the applied semantics acquisition. And Gil
[00:35:22.880 --> 00:35:25.240]   was obviously a pretty significant shareholder of
[00:35:25.240 --> 00:35:29.000]   Google. He's even in the s1 as one of the major shareholders,
[00:35:29.000 --> 00:35:32.600]   he's a really great human being. And his intention with this
[00:35:32.600 --> 00:35:35.840]   common crawl project was, you know, to make the crawling of
[00:35:35.840 --> 00:35:39.920]   the web, the index, and the caching available for all these
[00:35:39.920 --> 00:35:42.560]   different projects that might exist. And he didn't at the time
[00:35:42.560 --> 00:35:47.920]   anticipate the, the open AI application becoming, you know,
[00:35:47.920 --> 00:35:51.200]   the big breakthrough. But when GPT three was published, I think
[00:35:51.200 --> 00:35:56.120]   they said that 80 plus percent of the waiting came from the
[00:35:56.120 --> 00:35:59.240]   content out of common crawl. And so it's really been this a this
[00:35:59.240 --> 00:36:03.160]   amazing project, completely nonprofit, all funded, mostly
[00:36:03.160 --> 00:36:07.320]   funded by Gil, and has really unlocked this opportunity for a
[00:36:07.320 --> 00:36:10.240]   lot of the open source alternatives to now try and
[00:36:10.240 --> 00:36:14.360]   provide solutions that can exist and coexist with open AI and
[00:36:14.360 --> 00:36:16.680]   others in the commercial options in the world.
[00:36:16.680 --> 00:36:20.360]   A small piece of trivia. We were one of the first AdSense
[00:36:20.360 --> 00:36:24.840]   publishers. And so here's a story from October of 2005.
[00:36:24.840 --> 00:36:27.280]   Weblogs, Inc, which didn't gadget, the blogging company I
[00:36:27.280 --> 00:36:30.920]   started hit $3,000 a day in AdSense, thanks to Gil and the
[00:36:30.920 --> 00:36:34.480]   team over there. And we wound up selling it to awesome. And this
[00:36:34.480 --> 00:36:38.720]   is the story about it. And we were in the s one, they had two
[00:36:38.720 --> 00:36:42.480]   examples of publishers, one was New York Times. And then one was
[00:36:42.480 --> 00:36:45.520]   weblogs, Inc, they want to show like an upstart and this one is
[00:36:45.520 --> 00:36:49.080]   a lot of history here. And it's fun to go back down to and we
[00:36:49.080 --> 00:36:50.840]   were we were in the s one for by the way, Google,
[00:36:50.840 --> 00:36:52.480]   Gil was gonna be at the summit. So
[00:36:52.480 --> 00:36:55.160]   I'm gonna give him a hug and take a picture.
[00:36:55.160 --> 00:37:00.320]   Charles Barkley had this great story, which is like he is like
[00:37:00.320 --> 00:37:03.000]   over the moon about being a grandfather. I saw this on 60
[00:37:03.000 --> 00:37:06.920]   minutes. And he said, it's because I want my grandchild
[00:37:06.920 --> 00:37:10.720]   grandson to Google me and notice that I did some things. And then
[00:37:10.720 --> 00:37:15.160]   we can talk about it. Yeah. And Jay, Jay, I had this thought for
[00:37:15.160 --> 00:37:18.320]   you. Like that's like, that's a cool piece of internet history
[00:37:18.320 --> 00:37:21.040]   that you're a part of. Yeah, hopefully your your, your
[00:37:21.040 --> 00:37:23.040]   grandkids will Google that. And you can tell us where it's
[00:37:23.040 --> 00:37:23.560]   pretty cool.
[00:37:23.560 --> 00:37:27.840]   Or, you know, 1800 episodes of this week in startups. I just
[00:37:27.840 --> 00:37:32.680]   tweeted a, an episode with Gary tan from 2009 that I recorded
[00:37:32.680 --> 00:37:35.720]   at Sequoia his office. And I just put it on the this week in
[00:37:35.720 --> 00:37:38.080]   startups Twitter account. It's pretty funny to have babyface
[00:37:38.080 --> 00:37:40.600]   Gary tan from posterous on there. Alright, arm officially
[00:37:40.600 --> 00:37:44.160]   filed its f1. It's kind of like an s1 for a foreign company. And
[00:37:44.160 --> 00:37:47.520]   they plan to go public next month arms revenue last quarter
[00:37:47.520 --> 00:37:52.440]   675 million down 2% year over year up 7% quarter of a quarter
[00:37:52.440 --> 00:37:57.640]   fiscal full year 2023 2.7 billion ish down 1% year over
[00:37:57.640 --> 00:38:01.960]   year. Arms major business just so you know, is smartphones
[00:38:01.960 --> 00:38:06.000]   99% of smartphones are built with arms chip architecture
[00:38:06.000 --> 00:38:09.360]   embedded systems, they have a system systems, we'll get into
[00:38:09.360 --> 00:38:11.760]   it. The problem is the market is totally moved when when SoftBank
[00:38:11.760 --> 00:38:15.680]   bought arm, it was probably like the last year where, you know,
[00:38:15.680 --> 00:38:19.440]   there was so much focus on the hardware and platform
[00:38:19.440 --> 00:38:22.400]   technologies inside of mobile and tablets and all that stuff.
[00:38:22.400 --> 00:38:25.640]   But in these last few years, think of what's happened. We've
[00:38:25.640 --> 00:38:29.440]   had a massive shift to AI. Right. And so that's pushing a
[00:38:29.440 --> 00:38:33.360]   lot more pressure on GPUs and whatever comes after that. We
[00:38:33.360 --> 00:38:37.120]   have had a reemergence of the popularity of risk fee, which is
[00:38:37.120 --> 00:38:41.840]   an open source competitor to arm. We have had Apple in source a
[00:38:41.840 --> 00:38:43.800]   whole bunch of their own architectural decisions in
[00:38:43.800 --> 00:38:46.320]   silicon design because they don't want the dependency
[00:38:46.320 --> 00:38:49.360]   they have a type of philosophy. Yeah, well, also, they also care
[00:38:49.360 --> 00:38:51.600]   about different things like they care about battery life. So
[00:38:51.600 --> 00:38:54.040]   that's why that's the focus of their chip architecture.
[00:38:54.040 --> 00:38:57.760]   And so all of this just means that that market embedded
[00:38:57.760 --> 00:39:02.560]   systems becomes more and more constrained and commoditized
[00:39:02.560 --> 00:39:06.360]   over time, which again, as we said, in capitalism means that
[00:39:06.360 --> 00:39:10.160]   future profits will be less than historical profits. And so I
[00:39:10.160 --> 00:39:15.280]   think this is a very tough valuation to get right. And
[00:39:15.280 --> 00:39:19.080]   trying to stretch to a 60 or $70 billion print, I think is
[00:39:19.080 --> 00:39:24.120]   really tough. This is a honestly a 15 to $20 billion company.
[00:39:24.120 --> 00:39:27.400]   Ouch. So question for you, I come off and I'll open it up to
[00:39:27.440 --> 00:39:32.000]   to the Davids. Why would SoftBank? I know the answer, but
[00:39:32.000 --> 00:39:35.600]   I'm asking you so you can explain to the audience. Why
[00:39:35.600 --> 00:39:39.240]   would SoftBank take a company public with these headwinds with
[00:39:39.240 --> 00:39:43.120]   no growth being flat? Why are they taking the public now?
[00:39:43.120 --> 00:39:46.400]   Well, soft softbank has the D lever, right? They have a they
[00:39:46.400 --> 00:39:50.360]   have a very big problem, which is that they have this forget
[00:39:50.360 --> 00:39:53.640]   SoftBank Vision Fund for a second, but SoftBank itself is a
[00:39:54.200 --> 00:39:58.120]   telco operator that has ginormous piles of debt that
[00:39:58.120 --> 00:40:01.040]   they've used to finance the building of their business. And
[00:40:01.040 --> 00:40:06.080]   so when you have contraction, your core business, you become
[00:40:06.080 --> 00:40:08.480]   more and more at risk of breaching the covenants of all
[00:40:08.480 --> 00:40:11.720]   that debt and or you just like run out of free cash flow, like
[00:40:11.720 --> 00:40:15.200]   all of these things really hurt your future ability to invest.
[00:40:15.200 --> 00:40:18.400]   And so SoftBank is under a lot of pressure to just clean up the
[00:40:18.400 --> 00:40:22.160]   balance sheet and D lever. And so when you have an asset like
[00:40:22.160 --> 00:40:26.240]   this sitting there, if you can sell, you know, 20 or $30
[00:40:26.240 --> 00:40:31.680]   billion of that, call it to somebody, and then replenish
[00:40:31.680 --> 00:40:35.280]   your balance sheet, that provides tremendous liquidity
[00:40:35.280 --> 00:40:38.880]   and relief. And they did that as well. A few months ago with
[00:40:38.880 --> 00:40:42.280]   Alibaba, they've started to, I think now they may have sold out
[00:40:42.280 --> 00:40:45.360]   of the overwhelming majority of the position in Alibaba again,
[00:40:45.360 --> 00:40:48.360]   because they have massive liquidity needs because they
[00:40:48.640 --> 00:40:52.840]   have so much debt. So this is just part and parcel of them D
[00:40:52.840 --> 00:40:53.800]   levering the balance sheet.
[00:40:53.800 --> 00:40:56.080]   So they're forced to get it out is I guess what you're saying.
[00:40:56.080 --> 00:41:00.320]   And then we've talked sacks a little bit about other companies
[00:41:00.320 --> 00:41:03.440]   that are going to be forced. They're on the what do they call
[00:41:03.440 --> 00:41:05.560]   it when you're on a pirate ship, they make you walk the plank.
[00:41:05.560 --> 00:41:09.080]   I'd say this is like the walking of the plank to an IPO, you got
[00:41:09.080 --> 00:41:12.280]   other companies that have issues where they just have to get
[00:41:12.280 --> 00:41:15.880]   public at some point. So maybe the public markets are going to
[00:41:15.880 --> 00:41:20.040]   open up. And in some cases, it's going to be because people are
[00:41:20.040 --> 00:41:22.120]   walking the plank, other cases, it's going to be opportunistic.
[00:41:22.120 --> 00:41:23.880]   So maybe you could talk a little bit about your thoughts on that.
[00:41:23.880 --> 00:41:26.160]   I think it's hard to walk the plank into the public markets.
[00:41:26.160 --> 00:41:28.160]   I'm not sure exactly what you mean by that, because the public
[00:41:28.160 --> 00:41:31.880]   markets have to want to buy your issuance. So if it's not a good
[00:41:31.880 --> 00:41:34.400]   company, then you know, in this environment, they're not gonna
[00:41:34.400 --> 00:41:35.160]   be able to IPO.
[00:41:35.160 --> 00:41:37.800]   Well, they're gonna be able to I think the question is the price.
[00:41:37.800 --> 00:41:40.680]   They have no choice but to get so yeah, there may be a lot of
[00:41:40.680 --> 00:41:44.520]   down rounds into an IPO from the last private round, which was
[00:41:44.560 --> 00:41:47.400]   two or three times what the IPO price is going to be. Maybe what
[00:41:47.400 --> 00:41:51.600]   you mean by walk the plank is that, well, you tell me, but
[00:41:51.600 --> 00:41:54.640]   there are a lot of companies which have built up huge prep
[00:41:54.640 --> 00:41:58.080]   stacks, because they raise too much money at the peak at
[00:41:58.080 --> 00:42:01.680]   valuations are too high. And going public does allow you to
[00:42:01.680 --> 00:42:04.920]   reset your whole prep stack, because all the preferred with
[00:42:04.920 --> 00:42:08.520]   all the rights and preferences converts to common. So post IPO,
[00:42:08.520 --> 00:42:13.720]   you just have common. And so it is a way to like clear out all
[00:42:13.720 --> 00:42:16.560]   the structure and all the mess that has built up in a company
[00:42:16.560 --> 00:42:21.000]   and you can get to a real valuation that reflects basically
[00:42:21.000 --> 00:42:22.440]   the truth of what the company is worth.
[00:42:22.440 --> 00:42:24.720]   Another analogy might be the house is on fire, you got it,
[00:42:24.720 --> 00:42:27.000]   you're on the balcony, you got to jump, or you got to stay in
[00:42:27.000 --> 00:42:27.640]   the burning building.
[00:42:27.640 --> 00:42:29.840]   Yeah, but you know, listen, if your company's on fire, I don't
[00:42:29.840 --> 00:42:32.080]   think you're gonna be able to IPO. I mean, it's, it's going to
[00:42:32.080 --> 00:42:37.160]   be a tough scrutinizing public market for new offerings. I
[00:42:37.160 --> 00:42:41.760]   think that the scenario in which you can IPO is if the company
[00:42:41.760 --> 00:42:45.880]   is fundamentally good, it will be able to IPO at some valuation
[00:42:45.880 --> 00:42:48.280]   and that valuation may be a significant down round from
[00:42:48.280 --> 00:42:51.440]   their last private round, those will be able to get out.
[00:42:51.440 --> 00:42:54.480]   Yeah, and that's right, I guess. Now, are you saying
[00:42:54.480 --> 00:42:59.200]   stripe? Yeah. Are you seeing David, the M&A activity starting
[00:42:59.200 --> 00:43:01.920]   to bubble up in your portfolio or in you know, the back
[00:43:01.920 --> 00:43:04.960]   channels, because I'm starting to see that a bit. founders are
[00:43:04.960 --> 00:43:07.520]   packing it in, in some instances and saying, you know what, we
[00:43:07.520 --> 00:43:11.760]   want to try for M&A. Or, you know, some companies are getting
[00:43:11.760 --> 00:43:13.920]   a little bit frisky and saying, Hey, what what's available in
[00:43:13.920 --> 00:43:16.600]   the market on the small side? So you're seeing an Emmy, any M&A
[00:43:16.600 --> 00:43:16.960]   action,
[00:43:16.960 --> 00:43:20.680]   not a ton yet. But there's definitely a growing number of
[00:43:20.680 --> 00:43:22.920]   startups who are realizing that what they're doing is not
[00:43:22.920 --> 00:43:25.480]   working, and they're not gonna be able to raise another round.
[00:43:25.480 --> 00:43:29.080]   And so therefore figuring out a graceful exit, whether it's an
[00:43:29.080 --> 00:43:32.000]   aqua hire or some other type of landing.
[00:43:32.000 --> 00:43:34.760]   Got it. Those are those might be the accurate walking the
[00:43:34.760 --> 00:43:35.200]   planks.
[00:43:35.760 --> 00:43:37.640]   Yes, those are the walking the planks, you're gonna start
[00:43:37.640 --> 00:43:38.960]   seeing a lot more of that for sure.
[00:43:38.960 --> 00:43:42.200]   Freeberg, your thoughts on the on the public markets here in
[00:43:42.200 --> 00:43:45.520]   relation to privates, and people walk in the plank.
[00:43:45.520 --> 00:43:49.240]   I don't think there is a public market right now. There's no IPO
[00:43:49.240 --> 00:43:55.240]   window. This arm thing is, you know, pretty forced. It seems
[00:43:55.240 --> 00:43:58.600]   it's not like there's a ton of pent up public demand to buy
[00:43:58.600 --> 00:44:01.760]   these arm shares. At least that's what it seems. So you
[00:44:01.760 --> 00:44:03.840]   know, they're gonna go shop it, they're gonna find out what the
[00:44:03.840 --> 00:44:07.360]   market tells them it's worth. And, and then we'll see in
[00:44:07.360 --> 00:44:09.920]   video, it's gonna help buoy it, I'm sure. There'll be an
[00:44:09.920 --> 00:44:14.360]   argument that, you know, all boats will rise, and arm will be
[00:44:14.360 --> 00:44:17.480]   a beneficiary. But I don't know if that necessarily leads into
[00:44:17.480 --> 00:44:20.400]   the IPO window being open again. I think we've all heard the
[00:44:20.400 --> 00:44:22.680]   commentary from Morgan Stanley that they don't think the
[00:44:22.680 --> 00:44:27.360]   windows opening until q2 q3 of next year, maybe I can't
[00:44:27.360 --> 00:44:33.080]   remember the exact commentary. But as we all know, a lot of
[00:44:33.080 --> 00:44:37.920]   LPS in venture funds and private equity funds are waiting for
[00:44:37.920 --> 00:44:40.680]   the IPO window to reopen before they're going to start
[00:44:40.680 --> 00:44:44.240]   reallocating capital back into the private venture funds.
[00:44:44.240 --> 00:44:47.640]   Because they need to get liquid in order to be able to recycle
[00:44:47.640 --> 00:44:52.080]   capital back into the next class of funds. So this glut right
[00:44:52.080 --> 00:44:55.000]   now, this inability to kind of get companies public is
[00:44:55.000 --> 00:44:59.000]   certainly weighing on folks, you know, you effectively have three
[00:44:59.000 --> 00:45:03.400]   options when you're running a private company. You got to keep
[00:45:03.400 --> 00:45:07.400]   raising money, which means either raise private capital or
[00:45:07.400 --> 00:45:09.680]   go public. And we've talked about the challenges of late
[00:45:09.680 --> 00:45:11.800]   raising late stage private capital, if you've had a high
[00:45:11.800 --> 00:45:15.760]   private valuation in your prior round, going public is very
[00:45:15.760 --> 00:45:18.400]   difficult right now, because a lot of folks are still
[00:45:18.400 --> 00:45:21.520]   digesting and having indigestion from the last couple of years,
[00:45:21.520 --> 00:45:23.720]   or you got to sell the company or you got to get profitable.
[00:45:23.720 --> 00:45:26.720]   Now on the sell the company side, many of the acquisitions
[00:45:26.720 --> 00:45:29.240]   that we're seeing with a few exceptions are generally more
[00:45:29.240 --> 00:45:31.760]   bolt on and less like, hey, I'm going to pay some big strategic
[00:45:31.760 --> 00:45:35.080]   premium for some big strategic game changing company right now
[00:45:35.080 --> 00:45:37.880]   because all the buyers are dealing with their own
[00:45:37.880 --> 00:45:40.440]   shareholder issues and their own public stock issues right now,
[00:45:40.440 --> 00:45:42.960]   then the you know, can you get profitable? It's really as you
[00:45:42.960 --> 00:45:45.600]   guys know, where a lot of folks are going, which is totally
[00:45:45.600 --> 00:45:49.520]   restructure your ambition, restructure your plans and build
[00:45:49.520 --> 00:45:53.040]   a business where customers are willing to pay you money. And
[00:45:53.040 --> 00:45:56.200]   where you can then take that profit and only reinvest that
[00:45:56.200 --> 00:45:59.120]   profit and not invest more than that profit. And if you can get
[00:45:59.120 --> 00:46:02.960]   to that steady state, you know, you can live to see another
[00:46:02.960 --> 00:46:06.240]   another day, another year, another decade. And those
[00:46:06.240 --> 00:46:09.520]   businesses, by the way, that we saw in the.com boom in the
[00:46:09.520 --> 00:46:12.240]   global financial crisis that that we're able to do that
[00:46:12.240 --> 00:46:15.920]   during the doldrum Death Valley march that everyone's going
[00:46:15.920 --> 00:46:19.120]   through right now, they emerged victorious, they learned how to
[00:46:19.120 --> 00:46:22.280]   be frugal, they learned how to be nimble, they learned how to
[00:46:22.280 --> 00:46:24.800]   really focus on customer experience, because they had to
[00:46:24.800 --> 00:46:27.240]   increase retention, and they had to increase the prices they were
[00:46:27.240 --> 00:46:29.840]   charging, they learned how to be efficient with allocating
[00:46:29.840 --> 00:46:35.040]   resources. And so profitability became a core part of their DNA
[00:46:35.040 --> 00:46:40.160]   and their ability to succeed. So I think this is really a trial
[00:46:40.160 --> 00:46:44.040]   era. And you know, on the other side of this trial era, a number
[00:46:44.040 --> 00:46:46.440]   of very high quality companies will emerge. But in the interim,
[00:46:46.440 --> 00:46:49.520]   I don't think that there's a an IPO path that a lot of folks can
[00:46:49.520 --> 00:46:51.760]   just check the box and say, let's go ahead and go public,
[00:46:51.760 --> 00:46:54.880]   even if the valuation is not great. Remember, an IPO process,
[00:46:54.880 --> 00:46:57.440]   you got to over sell your book, or the bankers won't underwrite
[00:46:57.440 --> 00:47:00.320]   it. So if they're, you know, you can't just say, hey, the price
[00:47:00.320 --> 00:47:03.240]   is now five bucks and expect bankers are there. If a company
[00:47:03.240 --> 00:47:06.200]   is burning money, the big concern with going public right
[00:47:06.200 --> 00:47:09.320]   now is that there is no pipe market, there is no ability to
[00:47:09.320 --> 00:47:12.600]   do secondary to do follow on offerings. So the company can't
[00:47:12.600 --> 00:47:15.880]   raise capital after it's public. So unless you're actually
[00:47:15.880 --> 00:47:19.880]   profitable, your option of going public right now really isn't
[00:47:19.880 --> 00:47:21.720]   there because shareholders don't want to buy shares in a
[00:47:21.720 --> 00:47:24.800]   company that may run out of money. Yeah. And that's what it
[00:47:24.800 --> 00:47:25.480]   is. Yeah.
[00:47:25.480 --> 00:47:28.840]   And to your point, if you take this third option, and you you
[00:47:28.840 --> 00:47:32.400]   become really resilient, and you have profits, Jamal, that seems
[00:47:32.400 --> 00:47:36.080]   to me to be the setup for the next boom, that we could
[00:47:36.080 --> 00:47:39.160]   experience in the coming years, hopefully, which is, we don't
[00:47:39.160 --> 00:47:42.240]   have companies that are burning, you know, mountains of cash,
[00:47:42.240 --> 00:47:44.280]   people are getting to profitable, these businesses
[00:47:44.280 --> 00:47:48.280]   look great. And then if the big companies are now, you know,
[00:47:48.280 --> 00:47:50.360]   having their stock prices recover, and they've laid off
[00:47:50.360 --> 00:47:53.040]   20,000 employees, and they got people returning to the office,
[00:47:53.040 --> 00:47:56.520]   and they're fit, and they're strong. Hey, that's a setup for
[00:47:56.520 --> 00:47:58.840]   strong companies buying strong companies or those strong
[00:47:58.840 --> 00:48:00.440]   companies that are private.
[00:48:00.440 --> 00:48:03.280]   The M&A market is dead as a doornail. It's more dead than
[00:48:03.280 --> 00:48:07.440]   the IPO market. So two days ago, the European Commission and the
[00:48:07.440 --> 00:48:11.720]   CMA in the UK said that they're probing Adobe Figma, because
[00:48:11.720 --> 00:48:14.720]   they have some concerns that it's going to limit competition
[00:48:14.720 --> 00:48:19.280]   in the market, it looks like Microsoft will have to give a
[00:48:19.280 --> 00:48:23.560]   15 year license to video game streaming to Ubisoft in order to
[00:48:23.560 --> 00:48:27.120]   get the UK folks to agree to Activision to their Activision
[00:48:27.120 --> 00:48:30.120]   acquisition. So you're talking about the first case of $20
[00:48:30.120 --> 00:48:35.000]   billion merger that may not happen. Because the CMA, they
[00:48:35.000 --> 00:48:40.960]   found their footing. They clearly had a win in the
[00:48:40.960 --> 00:48:44.840]   Microsoft Activision thing. And now they're probably going to
[00:48:44.840 --> 00:48:48.120]   find issue with the Adobe Figma thing. And the Europeans don't
[00:48:48.120 --> 00:48:50.160]   want to be left out in the action. So they're jumping in.
[00:48:50.160 --> 00:48:54.720]   So I think the M&A market is effectively dead. What it leaves
[00:48:54.720 --> 00:48:59.080]   is an IPO market. But that is very tenuous, because you don't
[00:48:59.080 --> 00:49:01.640]   have a leading candidate that can really catalyze something.
[00:49:01.640 --> 00:49:03.960]   And I made this prediction earlier. But I think the only
[00:49:03.960 --> 00:49:06.560]   company that can really catalyze things would be if people were
[00:49:06.560 --> 00:49:09.920]   ready to do Starlink. I mean, it's the most obvious natural
[00:49:09.920 --> 00:49:13.720]   logical thing that would just get everybody excited and off
[00:49:13.720 --> 00:49:18.160]   the sidelines and into the arena. But that may take
[00:49:18.160 --> 00:49:22.280]   another year may not, but it may. In the meantime, I don't
[00:49:22.280 --> 00:49:24.600]   think there's any company like Instacart, I don't think people
[00:49:24.600 --> 00:49:28.160]   are going to be jumping off the sidelines, arm, it'll be tough.
[00:49:28.160 --> 00:49:33.440]   Even stripe now is like a very complicated valuation trade. And
[00:49:33.440 --> 00:49:37.000]   I think that that's a really technical thing to be involved
[00:49:37.000 --> 00:49:41.800]   in an IPO like that, a technical valuation. And so companies have
[00:49:41.800 --> 00:49:45.400]   no choice, except to get profitable and get to default
[00:49:45.400 --> 00:49:48.600]   alive to use the famous Paul Graham quote, that's the only
[00:49:48.600 --> 00:49:51.840]   path. That's it. Yeah, I mean, so it's the only path,
[00:49:51.840 --> 00:49:54.960]   you either have to be default alive, which means profitable or
[00:49:54.960 --> 00:49:58.920]   default investable, which means that you're capable of producing
[00:49:58.920 --> 00:50:02.960]   metrics that a VC will fund. But really, that starts with 100%
[00:50:02.960 --> 00:50:05.480]   year over year growth. There's a lot of companies that aren't
[00:50:05.480 --> 00:50:09.720]   growing very fast or growing 2030 4050 60% growth, that's not
[00:50:09.720 --> 00:50:12.720]   for their final. Yeah, or they're flat, even worse. Some
[00:50:12.720 --> 00:50:17.080]   are shrinking. So those cases, they got to think more like a PE
[00:50:17.080 --> 00:50:21.400]   model than a venture model. Yeah. And PE companies are cash
[00:50:21.400 --> 00:50:26.280]   deposit if they don't burn cash. I put out this video a few
[00:50:26.280 --> 00:50:29.680]   months ago, called VC or P what's the right framework for
[00:50:29.680 --> 00:50:31.600]   thinking about your startup. This was a
[00:50:31.600 --> 00:50:34.200]   craft ventures YouTube.
[00:50:34.200 --> 00:50:37.640]   This was a talk that I gave to our portfolio companies, we
[00:50:37.640 --> 00:50:40.480]   recorded it and then published it. Really, it should have gotten
[00:50:40.480 --> 00:50:44.680]   more attention. But this was basically recommending to all
[00:50:44.680 --> 00:50:49.040]   those slower growing companies, our portfolio, stop thinking
[00:50:49.040 --> 00:50:52.680]   that VC funding is always gonna be available and start thinking
[00:50:52.680 --> 00:50:56.680]   more like a PE funded private equity company, which is to say
[00:50:56.680 --> 00:51:00.120]   you need to cut your burn to get cash for positive, you will then
[00:51:00.120 --> 00:51:03.720]   be able to control your own destiny. So yeah, this slide
[00:51:03.720 --> 00:51:06.680]   here, if you're not VC eligible, act realistically. So we
[00:51:06.680 --> 00:51:11.600]   provided some guidance on what makes a company eligible for VC
[00:51:11.600 --> 00:51:14.040]   funding. And you can see there's a good column is a great column.
[00:51:14.040 --> 00:51:17.560]   Good starts at 2x growth greatest three x gross margins.
[00:51:17.560 --> 00:51:22.120]   Good starts at 50%. Great is 80% net dollar retention. Good
[00:51:22.120 --> 00:51:27.600]   starts 100%. Great 120% CAC payback. Good is 12 to 18 months
[00:51:27.600 --> 00:51:32.120]   great is six to 12 months burn multiple good is one and a half
[00:51:32.120 --> 00:51:35.360]   great is one or less. And then there's some danger zones as
[00:51:35.360 --> 00:51:38.880]   well. This was to provide them with some realistic guidance in
[00:51:38.880 --> 00:51:41.480]   terms of whether they'll be able to raise another VC round or
[00:51:41.480 --> 00:51:45.760]   not. And I can tell you like most startups in startup world
[00:51:45.760 --> 00:51:49.080]   right now are in the danger zone. It's a really tough
[00:51:49.080 --> 00:51:53.360]   environment. And so, you know, listen, if you're a startup with
[00:51:53.360 --> 00:51:55.760]   sub 1 million of ARR, and you're in the danger zone, you're
[00:51:55.760 --> 00:51:57.560]   probably going to have to pack it in or maybe you package
[00:51:57.560 --> 00:52:02.000]   yourself up for an aqua hire. But if you're a startup that has
[00:52:02.120 --> 00:52:06.120]   50 million of ARR, but you're in the danger zone, just cut your
[00:52:06.120 --> 00:52:09.000]   burn, you could basically make ourselves cash flow positive.
[00:52:09.000 --> 00:52:11.640]   And you could engineer an outcome for yourself a pretty
[00:52:11.640 --> 00:52:12.280]   good outcome.
[00:52:12.280 --> 00:52:18.400]   My anecdotal experience is one of our larger investments. We
[00:52:18.400 --> 00:52:22.760]   brought in a private equity firm where they came in. And my god,
[00:52:22.760 --> 00:52:26.960]   it's been an incredible experience. Because the
[00:52:26.960 --> 00:52:30.520]   combination of how like a VC looks at a business and how a PE
[00:52:30.520 --> 00:52:33.640]   firm looks at the business in a moment like this is hyper
[00:52:33.640 --> 00:52:36.320]   additive, because it's super clarifying. It's very
[00:52:36.320 --> 00:52:39.960]   straightforward. And it gives a CEO an extremely clear mandate
[00:52:39.960 --> 00:52:43.840]   from which to operate and then they become very measurable. And
[00:52:43.840 --> 00:52:48.000]   I found it to be a really, really healthy thing. Now, PE
[00:52:48.000 --> 00:52:51.240]   guys can only get involved in companies of a certain size. So
[00:52:51.240 --> 00:52:52.040]   it limits
[00:52:52.040 --> 00:52:54.440]   50 million and above in revenue 100 million.
[00:52:54.440 --> 00:52:58.960]   Yeah, in our case, it was a 400 million 380 300 more than 300
[00:52:58.960 --> 00:53:02.000]   million revenue. So it's a big it's a big company. But my point
[00:53:02.000 --> 00:53:05.480]   is just just more that we were moving along a trajectory to
[00:53:05.480 --> 00:53:08.440]   getting to default alive. But by adding that PE
[00:53:08.440 --> 00:53:14.960]   person to our board, boom, I think we were able to focus on
[00:53:14.960 --> 00:53:19.600]   it probably a year to 18 months faster and with specific
[00:53:19.600 --> 00:53:22.160]   precision, because they have a very different toolkit and a
[00:53:22.160 --> 00:53:25.880]   reaction to miss execution. And that's extremely healthy.
[00:53:26.680 --> 00:53:29.960]   Yeah, we had this happen, you know, meeting with just from the
[00:53:29.960 --> 00:53:35.040]   front lines, we, we meet with, we have 20,000 people apply for
[00:53:35.040 --> 00:53:37.960]   funding from our firm, in large part, I would say we doubled the
[00:53:37.960 --> 00:53:40.680]   number of applications after all in started. So shout out to my
[00:53:40.680 --> 00:53:43.840]   besties here, really helped our deal flow. And we find
[00:53:43.840 --> 00:53:46.840]   companies and we found a company that was obsessed with all in.
[00:53:46.840 --> 00:53:49.160]   And the two founders were quants and they made this company
[00:53:49.160 --> 00:53:52.640]   called stone algo. We meet this company, they've got very little
[00:53:52.640 --> 00:53:56.280]   money. It's a bootstrap company, and they got to a half million
[00:53:56.280 --> 00:54:00.560]   dollars in revenue. You know, just on sweat equity. And we
[00:54:00.560 --> 00:54:03.920]   find this company, it's not part of the Silicon Valley, you know,
[00:54:03.920 --> 00:54:07.000]   accelerator system. It's basically kayak for diamonds,
[00:54:07.000 --> 00:54:09.320]   shout out to the team over there. And we were able to place
[00:54:09.320 --> 00:54:13.160]   a nice bet on this company that was break even. And, you know,
[00:54:13.160 --> 00:54:16.520]   put in, you know, a couple of $100,000 to start start them
[00:54:16.520 --> 00:54:20.360]   down this road to growing faster, but what a delightful
[00:54:20.360 --> 00:54:25.040]   thing to find a profitable company in the world. And so if
[00:54:25.040 --> 00:54:28.520]   you have a profitable company, like and it's just 50,000 a
[00:54:28.520 --> 00:54:30.720]   month or 25,000 a month, please email me Jason at
[00:54:30.720 --> 00:54:33.680]   callaghanis.com. I want to invest in your company. When you
[00:54:33.680 --> 00:54:37.120]   have that company, small amount of revenue profitable, you're
[00:54:37.120 --> 00:54:39.840]   not burning a ton, you are so attractive to investors right
[00:54:39.840 --> 00:54:44.400]   now. It's the highest attractiveness in the world. And
[00:54:44.400 --> 00:54:47.760]   I just want to point out David, as this market has, you know,
[00:54:47.760 --> 00:54:51.880]   completely gone from absolute chaos, the hair has gotten
[00:54:51.880 --> 00:54:56.640]   tighter and tighter. You were in crazy banning. And now you are
[00:54:56.640 --> 00:55:00.920]   tight tight is right. sax is focused. He's deploying that LP
[00:55:00.920 --> 00:55:04.120]   capital. He's deploying that advice to SAS companies. And
[00:55:04.120 --> 00:55:09.360]   it's no joke now, folks. General sacks is here. He is not crazy.
[00:55:09.360 --> 00:55:14.280]   History Uncle is SAS sacks. He's SAS sacks is back.
[00:55:14.280 --> 00:55:18.440]   This is like when Mark Zuckerberg started wearing a tie
[00:55:18.440 --> 00:55:20.800]   to work to start showing that it was serious.
[00:55:21.000 --> 00:55:25.880]   Yes, yes. SAS is SAS sacks and serious sacks is back with that
[00:55:25.880 --> 00:55:28.680]   slick back hair. All right, listen, we got to get going
[00:55:28.680 --> 00:55:33.560]   here. We got a lot more on the docket. I think we just maybe
[00:55:33.560 --> 00:55:36.600]   I'm going to jump the fence here. And we just go right to
[00:55:36.600 --> 00:55:37.640]   the Republican primary.
[00:55:37.640 --> 00:55:41.200]   The funniest thing last night was that poker. We watched it.
[00:55:41.200 --> 00:55:44.240]   You watched it during poker. Were you able to focus?
[00:55:44.240 --> 00:55:48.320]   You have to hear Kevin Hart react. When all these guys are
[00:55:48.320 --> 00:55:51.080]   doing it's one of the funniest things I've ever heard. And the
[00:55:51.080 --> 00:55:53.760]   worst part of the poker was
[00:55:53.760 --> 00:55:59.000]   the magician. Here we go.
[00:55:59.000 --> 00:56:03.920]   That's just how can you both be playing poker here but also the
[00:56:03.920 --> 00:56:04.720]   debate stage.
[00:56:04.720 --> 00:56:10.880]   Which I thought was a really funny joke.
[00:56:15.920 --> 00:56:18.760]   It was very funny. All right, listen, I know everybody's I
[00:56:18.760 --> 00:56:22.040]   just want to go around the horn here. Friedberg. Did you watch
[00:56:22.040 --> 00:56:28.560]   the debate? Who won the debate who had the largest gain? net
[00:56:28.560 --> 00:56:33.160]   gain in terms of their profile in your mind after watching
[00:56:33.160 --> 00:56:37.600]   debate number one of the GOP. David Friedberg biggest gain I
[00:56:37.600 --> 00:56:41.160]   watched the debate. I kind of think about these guys on three
[00:56:41.160 --> 00:56:44.960]   dimensions, which is the content, how dynamic they are and
[00:56:44.960 --> 00:56:47.680]   their personality. I think those are the three dimensions that
[00:56:47.680 --> 00:56:51.640]   people are going to be kind of assessing them on. I think Nikki
[00:56:51.640 --> 00:56:56.960]   Haley did a tremendous job gaining interest with respect to
[00:56:56.960 --> 00:57:00.360]   her personality and her content.
[00:57:00.360 --> 00:57:07.040]   Bergam Hutchinson, I don't think had a chance to move the needle
[00:57:07.040 --> 00:57:12.360]   on any of them. I think Vivek was by far the winner on dynamic.
[00:57:12.840 --> 00:57:16.480]   He had the hardest hitting biggest comeback with a very
[00:57:16.480 --> 00:57:19.600]   close second being Chris Christie. But I do think that
[00:57:19.600 --> 00:57:23.800]   Vivek got taken apart when it comes to content and I have real
[00:57:23.800 --> 00:57:26.280]   concerns about his personality. There's a lot of people that are
[00:57:26.280 --> 00:57:29.920]   just turned off by him, that he seems a little too eager that he
[00:57:29.920 --> 00:57:35.320]   seems a little too smart for his own good. The commentary about
[00:57:35.320 --> 00:57:38.440]   him being so junior and doesn't have experience I think standing
[00:57:38.440 --> 00:57:42.440]   next to those guys on stage really showed to be honest,
[00:57:42.440 --> 00:57:48.280]   Nikki Haley tearing him apart on his point of view on Russia. And
[00:57:48.280 --> 00:57:51.640]   sex, you know, we can debate the point or not. But I think she did
[00:57:51.640 --> 00:57:54.160]   a masterful I don't think she tore him apart. I think the
[00:57:54.160 --> 00:57:58.840]   biggest dunk line of the evening was when he congratulated her on
[00:57:58.840 --> 00:58:02.360]   her future appointments to the boards of Raytheon and Lockheed.
[00:58:02.360 --> 00:58:04.840]   Yeah, that was that was brilliant. I just think he's the
[00:58:04.840 --> 00:58:07.720]   most dynamic character. And I think people people do in a
[00:58:07.720 --> 00:58:10.800]   democracy vote on that they vote on how dynamic someone is. They
[00:58:10.800 --> 00:58:13.720]   vote on their personality and whether they can trust the
[00:58:13.720 --> 00:58:16.720]   person that Nikki Haley shines there. She seems extremely
[00:58:16.720 --> 00:58:19.480]   trustworthy and personable. Chris Christie came across as
[00:58:19.480 --> 00:58:22.920]   very personable. So your big winners? Yeah, Mike Pence, I
[00:58:22.920 --> 00:58:27.080]   would say, under underwhelmed and Rhonda Santas, man, it's
[00:58:27.080 --> 00:58:33.320]   like he didn't show up. So I would say Haley, Chris Christie,
[00:58:33.320 --> 00:58:37.400]   Vivek and Scott are probably like, you know, across those
[00:58:37.400 --> 00:58:41.320]   dimensions, like, you know, the four runners and everyone else
[00:58:41.320 --> 00:58:42.240]   is probably off.
[00:58:42.240 --> 00:58:45.120]   Now, let me get your mouth and then sack you get to comment on
[00:58:45.120 --> 00:58:47.480]   both of their so I want to go to you last because you have the
[00:58:47.480 --> 00:58:51.840]   most passion here. Chamath, who are your big winners coming out
[00:58:51.840 --> 00:58:54.400]   of it? In other words, who gained the most last night?
[00:58:54.400 --> 00:58:57.480]   What can Brown do for you? What can Brown do for you? I think
[00:58:57.480 --> 00:59:00.960]   that okay, ups settlement. Great. I thought that I thought
[00:59:00.960 --> 00:59:04.920]   that Nikki Haley did an incredible job. And I do think
[00:59:04.920 --> 00:59:08.840]   that Vivek did a very good job. And I think what's interesting
[00:59:08.840 --> 00:59:12.400]   is that I'm fascinated to see what the Republican reaction
[00:59:12.400 --> 00:59:17.920]   over the next few weeks will be to Vivek. And specifically, what
[00:59:17.920 --> 00:59:23.720]   I'm interested in seeing is, do the Trump loyalists start to
[00:59:23.720 --> 00:59:28.520]   where they incepted with an idea yesterday, which is that this
[00:59:28.520 --> 00:59:33.120]   guy can give us a lot of the talking points we want without
[00:59:33.120 --> 00:59:38.840]   some of the heartburn and agita that we don't want. And if he is
[00:59:38.840 --> 00:59:42.040]   able to thread that needle, which is what I think his
[00:59:42.040 --> 00:59:48.920]   effective strategy has been, he could really build momentum
[00:59:48.920 --> 00:59:53.840]   going into the fall. So that was my that was my real takeaway is
[00:59:53.840 --> 00:59:57.600]   that he is refining a playbook. Look, the guy is a clearly a
[00:59:57.600 --> 01:00:04.000]   really brilliant person. Well studied, well prepared, and
[01:00:04.000 --> 01:00:07.960]   dynamic, as David said, so he can, you know, clap back at
[01:00:07.960 --> 01:00:10.720]   people, which I think is important. But the most
[01:00:10.720 --> 01:00:16.360]   important thing that he's done is he has defined a very precise
[01:00:16.360 --> 01:00:21.360]   strategy to thread this needle of being close enough to Trump
[01:00:22.400 --> 01:00:28.640]   to, frankly, eventually go after him. But do it in a way where
[01:00:28.640 --> 01:00:32.280]   he's slowly building credibility among Trump loyalists. And I
[01:00:32.280 --> 01:00:36.440]   think if you look at where other people made huge gaffes,
[01:00:36.440 --> 01:00:42.440]   unnecessary gaffes, was they took their beliefs, and they
[01:00:42.440 --> 01:00:46.040]   confuse them with the strategy of winning. And that doesn't
[01:00:46.040 --> 01:00:49.560]   work in the Republican Party. So when the candidates were asked
[01:00:49.560 --> 01:00:51.720]   about Trump and the ones that drew a hard line and said that
[01:00:51.720 --> 01:00:54.160]   this guy's going to go to jail, what happened, they got booed.
[01:00:54.160 --> 01:01:00.040]   And it just ended their ability to be credible. For what they
[01:01:00.040 --> 01:01:02.120]   said afterwards. I'm not saying that that's right or wrong. It's
[01:01:02.120 --> 01:01:05.640]   just an observation. So I think Vivek is doing the smartest job
[01:01:05.640 --> 01:01:10.920]   of understanding the rules on the field. And he's in the arena
[01:01:10.920 --> 01:01:14.640]   to okay, so that gives them a lot that can now we go to sack
[01:01:14.640 --> 01:01:18.960]   sacks. You heard Nikki Vivek, Christie from freeberg. And
[01:01:18.960 --> 01:01:23.920]   then Nikki, yeah. And Tim Scott. So Vivek, clearly, the buzz and
[01:01:23.920 --> 01:01:26.840]   the search terms and everything, it seems to be favoring Vivek as
[01:01:26.840 --> 01:01:31.720]   the big lift here. Do you think Vivek is the Trump change agent
[01:01:31.720 --> 01:01:36.400]   without the indictments without the baggage without the Trump
[01:01:36.400 --> 01:01:40.280]   derangement syndrome insanity is Chamath correct here that he's
[01:01:40.280 --> 01:01:43.000]   a more palatable version of the change agent that is Trump.
[01:01:43.000 --> 01:01:47.640]   I think he's positioning himself as the backup plan to Trump. So
[01:01:47.640 --> 01:01:51.560]   he's not criticizing Trump, he is cultivating support within
[01:01:51.560 --> 01:01:55.320]   Trump space. Again, not to supersede him, but I think to
[01:01:55.320 --> 01:01:57.880]   perhaps be a backup plan. I think it is a smart strategy.
[01:01:57.880 --> 01:02:00.120]   But let me back up a little bit here.
[01:02:00.120 --> 01:02:02.360]   Who won for you? Well,
[01:02:02.360 --> 01:02:06.320]   before you make your points, well, everybody else played the
[01:02:06.320 --> 01:02:07.840]   game. biggest game.
[01:02:07.840 --> 01:02:11.960]   The biggest game was a fact that's reflected in the polling.
[01:02:11.960 --> 01:02:15.760]   There's a poll on Drudge Report in which 33%, which was the
[01:02:15.760 --> 01:02:19.760]   highest number said that he won the debate. 22% for Haley 18%
[01:02:19.760 --> 01:02:23.440]   for DeSantis, Christie got 16%. The rest were just non factors.
[01:02:23.440 --> 01:02:27.200]   So Nate scientific, but pretty scientific, but this is
[01:02:27.200 --> 01:02:30.280]   corroborated by Nate silver. Yes, some stuck this morning,
[01:02:30.280 --> 01:02:34.080]   Chris Lee saying that based on the buzz on social media and the
[01:02:34.080 --> 01:02:38.320]   sentiment and Google Trends, Google Trends, he predicted that
[01:02:39.760 --> 01:02:47.040]   Vivek would, we keep saying Vivek Vivek, it's it is he's
[01:02:47.040 --> 01:02:49.640]   gonna have the biggest bounce out of the debate. Partly,
[01:02:49.640 --> 01:02:52.360]   that's a function of the fact that he was the least well known
[01:02:52.360 --> 01:02:55.920]   candidate. Okay, so this gave him a lot of exposure. And he
[01:02:55.920 --> 01:03:00.240]   has a good orator. I mean, just the way he talks the energy, the
[01:03:00.240 --> 01:03:04.680]   timber of his voice, he projects well. And he had a clear point
[01:03:04.680 --> 01:03:07.560]   of view in this debate. You may not agree with everything he
[01:03:07.560 --> 01:03:10.200]   said, but he had a very clear point of view. And I expect that
[01:03:10.200 --> 01:03:12.840]   both the number of people who like him and the number of
[01:03:12.840 --> 01:03:16.080]   people who dislike him will go up as a result of this, but I
[01:03:16.080 --> 01:03:19.080]   think the net effect of that will be positive. Now, let me
[01:03:19.080 --> 01:03:21.120]   back up just give you a couple more thoughts on the debate.
[01:03:21.120 --> 01:03:24.000]   First of all, in terms of winners, I think the Republican
[01:03:24.000 --> 01:03:28.960]   Party in a way, demonstrated that it is the party of ideas
[01:03:28.960 --> 01:03:32.240]   where there actually are debates happening. Because you saw here,
[01:03:32.240 --> 01:03:35.800]   I think, real differences between the candidates, and I
[01:03:35.800 --> 01:03:38.760]   could break them up into really three categories, if you like,
[01:03:38.760 --> 01:03:44.200]   there's this neocon wing of sort of hardline foreign policy
[01:03:44.200 --> 01:03:47.360]   hawks. And you saw Nikki Haley's part of that and Chris Christie
[01:03:47.360 --> 01:03:51.640]   and Pence, and Tim Scott, then you had this religious right
[01:03:51.640 --> 01:03:55.440]   faction where you've got Pence and Scott, and then you've kind
[01:03:55.440 --> 01:03:58.840]   of got the MAGA wing, which Vivek really took up the mantle
[01:03:58.840 --> 01:04:02.880]   of opposing Ukraine and defending Trump. So you have
[01:04:02.880 --> 01:04:05.360]   three very different groups within the party who are
[01:04:05.360 --> 01:04:09.120]   battling, I think, for mindshare within the party and to be the
[01:04:09.120 --> 01:04:12.600]   future of the party. So it's not just about candidates and
[01:04:12.600 --> 01:04:15.760]   personal style, but it really is about ideas. You compare that to
[01:04:15.760 --> 01:04:17.840]   the Democratic Party, they're not even having a debate,
[01:04:17.840 --> 01:04:20.920]   they're protecting Biden from a debate, there could be a real
[01:04:20.920 --> 01:04:25.520]   debate because RFK Jr. has really different ideas. And he
[01:04:25.520 --> 01:04:28.080]   would like to take the party in a very different direction, the
[01:04:28.080 --> 01:04:33.120]   direction of his father and uncle, Bobby Kennedy and John F.
[01:04:33.120 --> 01:04:36.360]   Kennedy, he's saying that we have moved away from where we
[01:04:36.360 --> 01:04:39.920]   should be as a party, but the people who control the Democratic
[01:04:39.920 --> 01:04:42.280]   Party do not want to have that debate, they have shut it down.
[01:04:42.280 --> 01:04:45.440]   Completely. There is no debate, they're just protecting Biden.
[01:04:45.440 --> 01:04:48.840]   So that's number one is I think we should give the Republican
[01:04:48.840 --> 01:04:51.880]   Party some credit for being willing to discuss and debate.
[01:04:51.880 --> 01:04:55.840]   I agree with you on that. I love the fact that you had a vibrant
[01:04:55.840 --> 01:04:58.560]   debate, you had differences of opinions. Now it was a little
[01:04:58.560 --> 01:05:03.120]   like a UFC fight and you know, zingers and back and forth. But
[01:05:03.120 --> 01:05:08.000]   I did like the fact that you had people who in moderation was
[01:05:08.000 --> 01:05:10.320]   actually surprisingly good when they forced them to say like,
[01:05:10.320 --> 01:05:13.680]   would you give Trump a pardon? Or, you know, what would you do
[01:05:13.680 --> 01:05:17.440]   in terms of support for Ukraine? This was like really well done.
[01:05:17.440 --> 01:05:19.640]   And they had that 32nd thing where they stopped people, they
[01:05:19.640 --> 01:05:22.160]   say, this is a 32nd one, and they had to rein in Pence
[01:05:22.160 --> 01:05:26.320]   because he kept, you know, interrupting, and they were kind
[01:05:26.320 --> 01:05:29.000]   of respectful. So I just want to shout out to Fox for good
[01:05:29.000 --> 01:05:32.960]   moderation. There were some crazy zingers in there as well.
[01:05:32.960 --> 01:05:36.520]   And it seems like we live in zinger culture. I think the the
[01:05:36.520 --> 01:05:38.920]   best zinger goes to the moderator who said, let's talk
[01:05:38.920 --> 01:05:41.960]   about the elephant that's not in the room. And then they brought
[01:05:41.960 --> 01:05:44.440]   up Trump. Well, frankly, you caught that one. But that was
[01:05:44.440 --> 01:05:45.360]   pretty hardcore.
[01:05:45.360 --> 01:05:48.720]   Well, so let's talk about winner number two, which was Trump,
[01:05:48.720 --> 01:05:50.960]   because Trump did not participate. And he didn't pay
[01:05:50.960 --> 01:05:54.440]   any price whatsoever for that. He barely got mentioned or
[01:05:54.440 --> 01:05:57.600]   attacked on that stage. And then he did this interview with
[01:05:57.600 --> 01:06:00.840]   Tucker, which started five minutes before the debate, which
[01:06:00.840 --> 01:06:03.320]   was kind of brilliant, because once again, Trump was able to
[01:06:03.320 --> 01:06:06.160]   suck up a lot of the oxygen, maybe not all of it, but a lot
[01:06:06.160 --> 01:06:08.200]   of oxygen without even participating in the debate.
[01:06:08.200 --> 01:06:11.160]   It was a perfect bookend. I watched both. It was a perfect
[01:06:11.160 --> 01:06:14.200]   bookend. You got Trump over here saying, Chamath, I'm interested
[01:06:14.200 --> 01:06:16.240]   in your position. But he said, Listen, I don't need to be in
[01:06:16.240 --> 01:06:17.920]   there with these guys mudslinging and they have zero
[01:06:17.920 --> 01:06:21.920]   1%. And I think he got the sense that he's excited to debate them
[01:06:21.920 --> 01:06:24.480]   when there's two people left or something like that. What did
[01:06:24.480 --> 01:06:26.760]   you think of? Did you watch Trump's thing? freeberg or
[01:06:26.760 --> 01:06:28.880]   Chamath? No, watch it.
[01:06:28.880 --> 01:06:32.840]   I watched the debate. I watched both the debate and then I
[01:06:32.840 --> 01:06:36.080]   watched I do think Trump effectively won the debate
[01:06:36.080 --> 01:06:40.200]   night. Because you had all these guys going at each other. And
[01:06:40.200 --> 01:06:44.280]   then you had Trump playing the Trump card. I'm not even going
[01:06:44.280 --> 01:06:47.800]   to show up. Because I don't have to. He literally made himself
[01:06:47.800 --> 01:06:51.200]   better than everyone else in the room by saying I'm not even it's
[01:06:51.200 --> 01:06:54.160]   not even worth my time to show up to talk to you guys go ahead
[01:06:54.160 --> 01:06:57.120]   and fight with each other. I'll also just restate this, this
[01:06:57.120 --> 01:07:00.440]   point about Vivek. I think it became abundantly clear that his
[01:07:00.440 --> 01:07:04.600]   strategy Vivek his his strategy is to pander to the Trump
[01:07:04.600 --> 01:07:09.240]   audience, that his commentary about you know, God is real.
[01:07:09.240 --> 01:07:15.520]   Climate change is two genders. He knows through polling, through
[01:07:15.520 --> 01:07:19.640]   his understanding, and his intelligence, that this is what
[01:07:19.640 --> 01:07:23.680]   this audience that is the bulk of the voting members of the
[01:07:23.680 --> 01:07:27.400]   Republican Party want to hear, and he is telling them what they
[01:07:27.400 --> 01:07:29.120]   want to hear. And then
[01:07:29.120 --> 01:07:32.000]   isn't that the job of a politician? Yeah, I mean, isn't
[01:07:32.000 --> 01:07:34.560]   that better than pandering to the military industrial complex
[01:07:34.560 --> 01:07:35.480]   like Nikki Haley did,
[01:07:35.480 --> 01:07:37.480]   there was a comment last night that I thought was really
[01:07:37.480 --> 01:07:40.120]   important, which is that leadership is not about
[01:07:40.120 --> 01:07:43.440]   consensus. And what he is doing is he is reflecting back the
[01:07:43.440 --> 01:07:45.960]   consensus view of the majority of people in that party in order
[01:07:45.960 --> 01:07:48.680]   to get himself elected, rather than leading with a different
[01:07:48.680 --> 01:07:51.360]   message that casts a different opportunity, the different light
[01:07:51.360 --> 01:07:54.160]   on the opportunity for this nation. And I think that's
[01:07:54.160 --> 01:07:57.200]   really where he and others on that stage, or he particularly
[01:07:57.200 --> 01:08:00.880]   fall short, is that he speaks too much to what people already
[01:08:00.880 --> 01:08:03.440]   believe and say, because he knows that that's what they're
[01:08:03.440 --> 01:08:06.840]   voting for Trump about. And then the bet is that there's some
[01:08:06.840 --> 01:08:10.600]   chance, not 100%, but some chance that Trump doesn't make
[01:08:10.600 --> 01:08:13.320]   it all the way he ends up in jail or people start to turn
[01:08:13.320 --> 01:08:16.720]   on him. And then he's the front runner. Because he's basically
[01:08:16.720 --> 01:08:17.840]   captivated that audience.
[01:08:17.840 --> 01:08:21.240]   Hold on, but but freeberg, and I will let you address it here.
[01:08:21.240 --> 01:08:24.480]   Chamath just said, the brilliance of the vacant his
[01:08:24.480 --> 01:08:28.200]   positioning here is that he understands how to win. And he
[01:08:28.200 --> 01:08:32.320]   is playing this game. And you call it pandering. saxes, I
[01:08:32.320 --> 01:08:35.600]   think saying it's understanding the needs of that audience. The
[01:08:35.600 --> 01:08:39.960]   job of a politician sacks is to win and to stay in office. So I
[01:08:39.960 --> 01:08:42.000]   don't believe the vakes positions on a lot of the stuff.
[01:08:42.080 --> 01:08:45.800]   I think he is pandering. I think he wouldn't do what Trump did. I
[01:08:45.800 --> 01:08:49.200]   think, you know, he's doing the part in promise, because he
[01:08:49.200 --> 01:08:53.000]   knows he gets some votes. So how do you reconcile this? Your job
[01:08:53.000 --> 01:08:55.600]   is to win, right? And you would rather see DeSantis maybe pick
[01:08:55.600 --> 01:09:00.120]   up on some of this action? No. As your preferred candidate,
[01:09:00.120 --> 01:09:00.760]   that's the same.
[01:09:00.760 --> 01:09:03.360]   Actually, that's a good that's a good question. freeberg. Do you
[01:09:03.360 --> 01:09:07.400]   think that a politician's job when you're running for
[01:09:07.400 --> 01:09:10.080]   President of the United States? Is it to understand the
[01:09:10.080 --> 01:09:12.400]   conditions on the field and win or not?
[01:09:12.400 --> 01:09:17.720]   I think the politicians job or I don't want to say the job. I
[01:09:17.720 --> 01:09:21.240]   think the opportunity to get elected in a democracy is to
[01:09:21.240 --> 01:09:25.040]   provide leadership, to cast a light on where you think the
[01:09:25.040 --> 01:09:29.360]   country or whatever constituency you're supposed to lead can go
[01:09:29.360 --> 01:09:32.720]   to provide a sense of opportunity to provide a sense
[01:09:32.720 --> 01:09:36.120]   of optimism, to provide a sense of what's not happening today
[01:09:36.120 --> 01:09:39.520]   that should be different, rather than reflecting back to those
[01:09:39.520 --> 01:09:41.800]   people exactly what they want. Now, the flip side of that is
[01:09:41.800 --> 01:09:44.040]   exactly what you're saying to math, which is that I think what
[01:09:44.040 --> 01:09:46.200]   happens in a democracy is that people elect people that
[01:09:46.200 --> 01:09:48.480]   represent what they believe. And I think that's what's gonna
[01:09:48.480 --> 01:09:51.960]   happen. And he's raising his hand and he's saying, I believe
[01:09:51.960 --> 01:09:54.360]   these things, and he's going to get elected, or he's going to
[01:09:54.360 --> 01:09:57.120]   put himself in a position to get elected if Trump drops out.
[01:09:57.120 --> 01:10:01.600]   I just think there's a lot of people who are very smart, who
[01:10:01.600 --> 01:10:04.640]   if they are too idealistic will achieve nothing in their lives.
[01:10:04.640 --> 01:10:07.600]   And I don't think Vivek is one of those people. idealism has a
[01:10:07.600 --> 01:10:10.000]   place in the world. It's not on the debate stage when you're
[01:10:10.000 --> 01:10:12.200]   running for president. Okay, sacks, you wanted to get in
[01:10:12.200 --> 01:10:15.360]   here. Okay, let's take the issue of Ukraine, because that was one
[01:10:15.360 --> 01:10:19.360]   of the main issues that Vivek differed from the rest of the
[01:10:19.360 --> 01:10:23.320]   people on that stage. There is polling by CNN that a majority
[01:10:23.320 --> 01:10:26.280]   of Americans have now turned against the idea of giving more
[01:10:26.280 --> 01:10:29.000]   aid to Ukraine. I'm sure that number is much higher in the
[01:10:29.000 --> 01:10:32.920]   Republican Party. If you remember, there was an event,
[01:10:32.920 --> 01:10:37.160]   Charlie Kirk, who is a conservative influencer, has an
[01:10:37.160 --> 01:10:40.480]   event called turning point USA. And they did polling of their
[01:10:40.480 --> 01:10:44.160]   conference attendees. The number one issue that everyone agreed
[01:10:44.160 --> 01:10:49.520]   on was Ukraine 95% of the attendees opposed giving more
[01:10:49.520 --> 01:10:54.360]   aid to Ukraine. Donald Trump only got 85% popularity. So the
[01:10:54.360 --> 01:10:58.880]   base of the party is even more united against Joe Biden's
[01:10:58.880 --> 01:11:02.080]   policy in Ukraine than they are on loving Trump. Okay, that
[01:11:02.080 --> 01:11:05.660]   tells you something and yet, Vivek is the only kid on that
[01:11:05.660 --> 01:11:09.640]   stage that was willing to raise his hand, like aggressively like
[01:11:09.640 --> 01:11:12.800]   full throatedly, not kind of a half hearted to saying that he
[01:11:12.800 --> 01:11:16.000]   did not agree with Biden's policy on Ukraine. What is wrong
[01:11:16.000 --> 01:11:18.200]   with all these other people on the stage that they cannot
[01:11:18.200 --> 01:11:22.480]   understand what is wrong with Biden's Ukraine policy, which by
[01:11:22.480 --> 01:11:27.400]   the way, is the signature policy of his presidency? What is the
[01:11:27.400 --> 01:11:30.520]   point of Republicans nominating a candidate who's just going to
[01:11:30.520 --> 01:11:35.080]   agree with Joe Biden on providing aid to Ukraine as much
[01:11:35.080 --> 01:11:37.760]   as it takes for as long as it takes? Is this your position
[01:11:37.760 --> 01:11:40.840]   here? freeberg? Is that, you know, when at all costs, let's
[01:11:40.840 --> 01:11:43.160]   call it the vague when at all costs, play the game on the
[01:11:43.160 --> 01:11:47.780]   field as Chamath is saying, and just win the game. Versus being
[01:11:47.780 --> 01:11:49.440]   principled, because you did have a
[01:11:49.440 --> 01:11:52.160]   no, no, I think that that framing is such a setup. Can I
[01:11:52.160 --> 01:11:52.920]   can I just say something
[01:11:52.920 --> 01:11:55.240]   frame it how you want you said playing the game on the field.
[01:11:55.240 --> 01:11:59.240]   And freeberg said, having a principle here and having like
[01:11:59.240 --> 01:12:01.640]   an actual vision for the country. So I'm taking both of
[01:12:01.640 --> 01:12:02.120]   yours.
[01:12:02.120 --> 01:12:04.680]   Look, I think the framing is not as not what is wrong with
[01:12:04.680 --> 01:12:09.120]   the vague, but what is wrong with candidates like Christie
[01:12:09.120 --> 01:12:14.800]   and Pence, and Haley and Scott, where even though 95% of their
[01:12:14.800 --> 01:12:18.680]   party is opposed to Ukraine, they are adopting Joe Biden's
[01:12:18.680 --> 01:12:22.280]   policy. And their only criticism of Joe Biden is that he's not
[01:12:22.280 --> 01:12:24.680]   doing enough fast enough for that. Okay, let's let freeberg
[01:12:24.680 --> 01:12:27.360]   get in here. They're completely out of point with the Republican
[01:12:27.360 --> 01:12:30.120]   Party as it stands today. We got your point. But is it not
[01:12:30.120 --> 01:12:32.880]   freeberg? What you're saying is that there is this profile and
[01:12:32.880 --> 01:12:36.420]   courage to invoke that book, where you there's something
[01:12:36.420 --> 01:12:39.880]   that's unpopular that you have to do. And I think Nikki Haley,
[01:12:39.880 --> 01:12:43.760]   Pence, Christie, and the other ones who are pro defending
[01:12:43.760 --> 01:12:48.520]   Ukraine from Russia. Their profile and courage freeberg is
[01:12:48.520 --> 01:12:51.760]   that they will go against that 95% polling and say it's the
[01:12:51.760 --> 01:12:54.480]   right thing to do. We should defend Taiwan, we should defend
[01:12:54.480 --> 01:12:57.720]   Israel, we should defend Ukraine against those are three
[01:12:57.720 --> 01:12:59.720]   different issues. I know it's three different issues, but they
[01:12:59.720 --> 01:13:03.000]   were all evoked by Vivek Vivek himself. So freeberg your
[01:13:03.000 --> 01:13:06.900]   chance, I think the West Wing does a great job of exploring
[01:13:06.900 --> 01:13:10.280]   both sides of this, which is, when do you have to break the
[01:13:10.280 --> 01:13:13.460]   mold and break the expectation of the people to do the right
[01:13:13.460 --> 01:13:16.800]   principle thing? And when do you have to do the thing that you
[01:13:16.800 --> 01:13:19.640]   don't think is right, but it's what the people want to have
[01:13:19.640 --> 01:13:23.800]   happened. And I think that that's a, obviously a balance
[01:13:23.800 --> 01:13:26.400]   that needs to be struck when you're in this position of being
[01:13:26.400 --> 01:13:29.160]   an elected leader in a democracy. And so there's no,
[01:13:29.240 --> 01:13:32.960]   there's no real answer. I wish that there was, like, I wish Mr.
[01:13:32.960 --> 01:13:37.760]   beast had like a presidential process like he you guys saw his
[01:13:37.760 --> 01:13:40.520]   Olympics video that he did last week, where he brought people
[01:13:40.520 --> 01:13:43.840]   and he created this like, these like five things. I wish that we
[01:13:43.840 --> 01:13:46.760]   had something like that to elect president, that it was more
[01:13:46.760 --> 01:13:50.840]   than just oration, because we elect the president today, based
[01:13:50.840 --> 01:13:53.680]   on their oratory skills, they go on stage and who has the best
[01:13:53.680 --> 01:13:56.680]   quippy comment, the person who would be the most decisive under
[01:13:56.680 --> 01:14:00.640]   pressure doesn't necessarily win the person who can inspire and
[01:14:00.640 --> 01:14:03.560]   attract and retain the best leadership, the person who can
[01:14:03.560 --> 01:14:06.240]   have the best foreign policy interactions with other leaders
[01:14:06.240 --> 01:14:10.000]   doesn't necessarily win. Those are skills that show up in other
[01:14:10.000 --> 01:14:14.920]   contexts. And when we put people on a stage, and we say, okay,
[01:14:14.920 --> 01:14:18.000]   speak to the audience, the guy who speaks the best looks the
[01:14:18.000 --> 01:14:21.640]   best. It's not necessarily the guy who is best equipped to
[01:14:21.640 --> 01:14:25.400]   handle the challenge of the Bay of Pigs, or, you know, the
[01:14:25.400 --> 01:14:27.800]   decision on whether or not I think you're very, very
[01:14:27.800 --> 01:14:30.480]   distress. I think you're being very dismissive. You have the
[01:14:30.480 --> 01:14:34.280]   floor. Go. Go. This is like, that's kind of like saying, why
[01:14:34.280 --> 01:14:37.360]   isn't it that it's the quarterback with the strongest
[01:14:37.360 --> 01:14:40.480]   arm that isn't the most successful? Why? Because that
[01:14:40.480 --> 01:14:44.080]   person is a fucking loser. And the person that's the winner is
[01:14:44.080 --> 01:14:47.840]   the one that can thread together a multifaceted set of skills to
[01:14:47.840 --> 01:14:51.400]   win the game. Tom Brady was drafted in the seventh round,
[01:14:51.400 --> 01:14:55.280]   not the first round, he wins the game, because he has the
[01:14:55.280 --> 01:14:58.880]   requisite skills, which is a basket of things, and a nuance
[01:14:58.880 --> 01:15:02.000]   of skills in different moments at different times. And so I
[01:15:02.000 --> 01:15:04.960]   think that you're being a little glib by saying the person isn't
[01:15:04.960 --> 01:15:09.760]   cool under pressure or this or that. It's not true. The people
[01:15:09.760 --> 01:15:15.960]   that win these races have a preternatural ability to be a
[01:15:15.960 --> 01:15:19.280]   complete egoist, but not a narcissist. That is an
[01:15:19.280 --> 01:15:23.440]   incredibly deft set of skills that a fair rare people have it
[01:15:23.440 --> 01:15:28.160]   gives them this energy to be out there talking to 1000s and
[01:15:28.160 --> 01:15:31.720]   1000s and 1000s and 1000s of people may be saying the same
[01:15:31.720 --> 01:15:35.760]   thing 1000s of times. But being able to stay focused being able
[01:15:35.760 --> 01:15:39.000]   to be on point having a sense of what they need to believe. Know
[01:15:39.000 --> 01:15:41.480]   the details in a certain part know the high level in another
[01:15:41.480 --> 01:15:45.200]   part stay punchy but stay affable stay. That's the game.
[01:15:45.200 --> 01:15:47.560]   There are a set of skills that it takes to become president.
[01:15:47.920 --> 01:15:51.000]   You test the oration skills of a person when you put them on a
[01:15:51.000 --> 01:15:54.520]   debate stage. You don't test the other complex skills that it
[01:15:54.520 --> 01:15:57.360]   takes to be president. And getting people to understand the
[01:15:57.360 --> 01:16:00.760]   complexity of the role and all the other aspects of someone's
[01:16:00.760 --> 01:16:04.120]   personality are lacking in these fucking debates. But there are
[01:16:04.120 --> 01:16:07.040]   other these other skills are in play and many things other than
[01:16:07.040 --> 01:16:10.200]   just the debate. Like the campaign is a highly sophisticated
[01:16:10.200 --> 01:16:14.520]   orchestration of running a small little government. Mario Cuomo
[01:16:14.520 --> 01:16:19.320]   famously said that you campaign in poetry and and govern in
[01:16:19.320 --> 01:16:22.760]   prose. And there is a difference between campaigning skills and
[01:16:22.760 --> 01:16:26.280]   governing skills. There is a gap there, I would update it to say
[01:16:26.280 --> 01:16:30.560]   that you govern in prose and campaign and tweets, you know,
[01:16:30.560 --> 01:16:34.160]   so the campaign definitely puts a huge emphasis on a candidate's
[01:16:34.160 --> 01:16:40.000]   communication skills. But that is not all just gloss or style.
[01:16:40.260 --> 01:16:44.860]   It also has to do with their policies and the nuances of
[01:16:44.860 --> 01:16:48.980]   their policies, and how they handle pressure, how good they
[01:16:48.980 --> 01:16:51.900]   are under pressure and how good they are when they're attacked.
[01:16:51.900 --> 01:16:54.180]   So you know, we put these candidates through a pressure
[01:16:54.180 --> 01:16:56.300]   cooker and kind of learn who they really are. I'm not sure
[01:16:56.300 --> 01:16:57.420]   it's a horrible process.
[01:16:57.420 --> 01:17:00.220]   So sex, let me ask you a question. Yeah. Pence has been
[01:17:00.220 --> 01:17:04.740]   in the situation room dealing with a foreign adversary. Vivek
[01:17:04.740 --> 01:17:07.100]   has no military or defense experience. He has no foreign
[01:17:07.100 --> 01:17:11.420]   state experience. How do you assess Vivek in his ability to
[01:17:11.420 --> 01:17:13.860]   address those critical issues that he's going to have to lead
[01:17:13.860 --> 01:17:16.980]   us through versus someone who's been there and done that? And
[01:17:16.980 --> 01:17:19.300]   how do you know, give a great question? Great question. Okay,
[01:17:19.300 --> 01:17:20.380]   trust him. We trust the
[01:17:20.380 --> 01:17:24.260]   vision. Pence made that argument against a vague, apparently not
[01:17:24.260 --> 01:17:27.060]   realizing that the guy he was vice president for was in that
[01:17:27.060 --> 01:17:31.020]   exact same position in 2016. No previous political experience,
[01:17:31.020 --> 01:17:34.140]   right? No experience being in the situation room. The only
[01:17:34.140 --> 01:17:38.180]   reason why Pence got to warm his ass on a chair in the situation
[01:17:38.180 --> 01:17:41.540]   room is because Donald Trump picked him to be his VP. Oh, but
[01:17:41.540 --> 01:17:44.620]   he wasn't responsible for making any important decisions. He was
[01:17:44.620 --> 01:17:47.940]   basically clocking time as vice president, give me a break. And
[01:17:47.940 --> 01:17:52.060]   that's why he's at what is it one or 1%? No one gives a shit
[01:17:52.060 --> 01:17:52.660]   about Pence.
[01:17:52.660 --> 01:17:55.740]   That's what they said about Obama as well. Obama had zero
[01:17:55.740 --> 01:17:58.780]   experience. Obama barely could get elected before he became
[01:17:58.780 --> 01:18:02.020]   senator and then president in a matter of four years. And for
[01:18:02.020 --> 01:18:04.860]   Bush, what happened to Bush? They said that exact argument as
[01:18:04.860 --> 01:18:06.980]   well. And what do they do? They packed them with Rumsfeld and
[01:18:06.980 --> 01:18:08.380]   Cheney. How did that end?
[01:18:08.380 --> 01:18:11.820]   Yeah, I just want to also point out here that sometimes things
[01:18:11.820 --> 01:18:13.820]   get a little bit heated. And when we get heated, it's
[01:18:13.820 --> 01:18:16.300]   typically because we're we're triangulating around something
[01:18:16.300 --> 01:18:18.420]   very important. I think what we're trying triangulating
[01:18:18.420 --> 01:18:22.260]   around here is that we are moving from an era of
[01:18:22.260 --> 01:18:26.580]   incumbents, and insiders to an era of outsiders. If you're your
[01:18:26.580 --> 01:18:33.220]   point, sacks, post Trump, we now have the two or three most
[01:18:33.220 --> 01:18:37.820]   fascinating candidates are people who do social media who
[01:18:37.820 --> 01:18:40.460]   do podcasts who do earned media like we talked about, I think
[01:18:40.460 --> 01:18:43.220]   two or three weeks ago is really good insight. And the vague is
[01:18:43.220 --> 01:18:46.200]   him has mastered it. And he is exactly like Trump. And he's
[01:18:46.200 --> 01:18:48.700]   exactly like Obama to a certain extent in that those people were
[01:18:48.700 --> 01:18:51.300]   incredibly personable. They knew how to talk on podcasts, they
[01:18:51.300 --> 01:18:55.580]   knew how to engage people. And I think that, you know, this
[01:18:55.600 --> 01:18:58.140]   spiciness that we're having here on the pod and the spiciness that
[01:18:58.140 --> 01:19:01.860]   you're seeing with some of those candidates, is that we're moving
[01:19:01.860 --> 01:19:07.480]   from traditional media defining these candidates to direct to
[01:19:07.480 --> 01:19:11.440]   consumer direct through Twitter slash x direct through podcasts,
[01:19:11.440 --> 01:19:15.460]   this podcast included, making people like RFK and Vivek, you
[01:19:15.460 --> 01:19:18.780]   know, very palatable people and Ross Perot, I know I'm gonna get
[01:19:18.780 --> 01:19:22.860]   laughed up for bringing this up who got 19% of the vote, which
[01:19:22.860 --> 01:19:27.220]   is a serious number. He went direct as well. But at that
[01:19:27.220 --> 01:19:32.580]   time, after he dropped out, no, he got 90% pro because he
[01:19:32.580 --> 01:19:35.520]   actually went as an independent all the way. And what Ross Perot
[01:19:35.520 --> 01:19:38.500]   did was the equivalent of what Vivek and RFK are doing on
[01:19:38.500 --> 01:19:41.460]   podcast, he bought television time, you don't know that, or
[01:19:41.460 --> 01:19:44.900]   some people who understand who Ross Perot even is, but look it
[01:19:44.900 --> 01:19:48.060]   up. He bought television time, and he went direct to the
[01:19:48.060 --> 01:19:52.620]   country with our budget. I thought this is going to be the
[01:19:52.620 --> 01:19:55.620]   future of politics. What we're witnessing right now is the
[01:19:55.620 --> 01:19:58.700]   transition from traditional media and the establishment,
[01:19:58.700 --> 01:20:02.180]   defining who the great candidates are to the public.
[01:20:02.180 --> 01:20:05.500]   And the people on podcasts and social media who are the tip of
[01:20:05.500 --> 01:20:08.060]   the spear on the vanguard, they're going to pick the
[01:20:08.060 --> 01:20:10.380]   winners. And I think this could be the tipping point election
[01:20:10.380 --> 01:20:15.020]   Trump was the first Obama than Trump and now the vague and RFK.
[01:20:15.020 --> 01:20:18.380]   So I just like you all to maybe respond to that, especially you
[01:20:18.380 --> 01:20:21.140]   sex and she brought this media issue up two weeks ago,
[01:20:21.140 --> 01:20:24.540]   let me partially agree with freeberg. In this sense, look,
[01:20:24.540 --> 01:20:27.680]   obviously, track record is important. Obviously, the
[01:20:27.680 --> 01:20:31.580]   ability to be an executive executive functioning is
[01:20:31.580 --> 01:20:34.780]   important for the chief executive of our country. So I'm
[01:20:34.780 --> 01:20:39.980]   not saying that we shouldn't look at that kind of record. And
[01:20:39.980 --> 01:20:41.940]   this is why was one of the reasons why I support to
[01:20:41.940 --> 01:20:44.100]   Sanchez. I think he's been a brilliant governor, he's done a
[01:20:44.100 --> 01:20:47.820]   superb job in the state of Florida. He did the best job of
[01:20:47.820 --> 01:20:50.820]   all the governors during COVID. I think he did a better job than
[01:20:50.820 --> 01:20:53.140]   Trump did during COVID. So listen, I think those things are
[01:20:53.140 --> 01:20:56.500]   important, where I disagree is, just because Mike Pence has,
[01:20:56.500 --> 01:21:00.140]   again, warmed a chair in the situation room, as vice
[01:21:00.140 --> 01:21:03.740]   president, to me, that's just not that relevant experience. I
[01:21:03.740 --> 01:21:08.420]   mean, the VP is kind of a nothing job unless something
[01:21:08.420 --> 01:21:10.460]   terrible happens to the president, they get tapped on
[01:21:10.460 --> 01:21:14.220]   the shoulder. So I just disagree with what is relevant
[01:21:14.220 --> 01:21:18.260]   experience. Second, I think it's important to recognize that the
[01:21:18.260 --> 01:21:22.820]   reason why the vague has a lane here. And the reason why Trump
[01:21:22.820 --> 01:21:27.180]   had a lane in 2016 is that the establishment wing of the party
[01:21:27.180 --> 01:21:31.780]   is so completely out of touch with what the base wants. Look,
[01:21:31.780 --> 01:21:35.740]   the reason why Trump came out of nowhere in 2016 is he basically
[01:21:35.740 --> 01:21:38.380]   turned everything on his head. He said no more bushes, no more
[01:21:38.380 --> 01:21:40.780]   of these stupid forever wars in the Middle East, we need to
[01:21:40.780 --> 01:21:44.780]   build a wall, no more of this open border policy. And we need
[01:21:44.780 --> 01:21:48.180]   to reset our trade relation with with China's. Those are three
[01:21:48.180 --> 01:21:51.740]   mega issues that no one else in the party was talking about. And
[01:21:51.740 --> 01:21:56.660]   the the mega issue today is Ukraine 95% of the bases against
[01:21:56.660 --> 01:22:00.340]   it. And they have left the vape this gigantic lane to exploit.
[01:22:00.340 --> 01:22:04.940]   Why? I don't know. I mean, they're trapped in legacy neocon
[01:22:04.940 --> 01:22:06.380]   thinking that the US is
[01:22:06.380 --> 01:22:11.580]   sacks are he kept saying, I think that was a great moment.
[01:22:11.580 --> 01:22:14.780]   It's a combination of being trapped in legacy thinking where
[01:22:14.780 --> 01:22:17.180]   we have to be the policeman of the world, combined with all the
[01:22:17.180 --> 01:22:19.700]   big donors in the party, many of whom are wrapped up with the
[01:22:19.700 --> 01:22:22.140]   military industrial complex want to contribute to that.
[01:22:22.140 --> 01:22:25.060]   People can you just say it again? What you feel like I'm
[01:22:25.060 --> 01:22:28.100]   not hearing? No, I think that being president requires being
[01:22:28.100 --> 01:22:31.500]   better more than just an orator. And I think that the debates
[01:22:31.500 --> 01:22:33.980]   allow the best orator to show off their skills and
[01:22:33.980 --> 01:22:37.100]   capabilities on the debate stage. I was saying I wish that
[01:22:37.100 --> 01:22:41.380]   there were other events, I would love to see some set of systems
[01:22:41.380 --> 01:22:46.300]   to expose the candidates success or failings and how well equipped
[01:22:46.300 --> 01:22:48.980]   they are, rather than the person who can just give the best
[01:22:48.980 --> 01:22:51.820]   interview. We all know this when you interview a candidate, an
[01:22:51.820 --> 01:22:54.780]   engineer, the engineer that gives the best interview is not
[01:22:54.780 --> 01:22:57.620]   necessarily going to become the best engineer, you can look at
[01:22:57.620 --> 01:23:00.780]   their code to see if they're a great, great engineer, you can
[01:23:00.780 --> 01:23:02.980]   talk to people that reported to them to see if they're a great
[01:23:02.980 --> 01:23:06.660]   manager, you can learn more about their success and skills
[01:23:06.660 --> 01:23:09.060]   through more than just their oration on the stage. And yes,
[01:23:09.060 --> 01:23:12.220]   there's data in fact, that we can pull from these people. I
[01:23:12.220 --> 01:23:16.140]   was just speculating in kind of a pseudo silly way about the
[01:23:16.140 --> 01:23:18.980]   concept of can we do more than just put people on a debate
[01:23:18.980 --> 01:23:22.900]   how to hire a CEO for your companies. So the board, what do
[01:23:22.900 --> 01:23:25.740]   you judge? Well, yeah, what I'll tell you we don't do is we don't
[01:23:25.740 --> 01:23:28.620]   have the employees elect the CEO through a vote by having that
[01:23:28.620 --> 01:23:32.700]   CEO going from the best guy for the job. I hear you but you're
[01:23:32.700 --> 01:23:35.940]   doing part of it, but you can interview we do reference calls,
[01:23:35.940 --> 01:23:39.780]   right? We we talked to them about their strategy. And you
[01:23:39.780 --> 01:23:41.980]   know, through the interview through the reference calls,
[01:23:41.980 --> 01:23:44.260]   through looking at the performance of other businesses
[01:23:44.260 --> 01:23:48.340]   that they've built and run and, you know, and that can have a
[01:23:48.340 --> 01:23:50.940]   fulsome understanding of his candidacy and his ability to be
[01:23:50.940 --> 01:23:53.540]   president. My point is, I think that there are certain things
[01:23:53.540 --> 01:23:56.780]   like with Trump, that had not been tested or tried that are
[01:23:56.780 --> 01:23:59.300]   going to come up in this role that they'd never done before in
[01:23:59.300 --> 01:24:02.420]   the past. And I'm not saying look, by the way, I'm certainly
[01:24:02.420 --> 01:24:05.180]   not a big, you know, political career guys, you guys know, I
[01:24:05.180 --> 01:24:08.300]   think, you know, I hate that people build a career out of
[01:24:08.300 --> 01:24:10.700]   politics. I think it's the most inane, ridiculous thing. And if
[01:24:10.700 --> 01:24:13.300]   we could go back and rewrite the Constitution, that's probably
[01:24:13.300 --> 01:24:16.420]   the first thing I put in there. The thing with that this line of
[01:24:16.420 --> 01:24:19.020]   thinking, and maybe this is where I reacted, so I apologize
[01:24:19.020 --> 01:24:23.740]   if I personalize it, is that it creates the risk of exactly what
[01:24:23.740 --> 01:24:26.660]   you just said in this, what you just said right now, which is
[01:24:26.660 --> 01:24:31.820]   this blob class of people that use those arguments as the
[01:24:31.820 --> 01:24:35.700]   reason why change can't happen. Yeah, why it must be disagree
[01:24:35.700 --> 01:24:37.700]   with that. I don't disagree with that. And I think that is the
[01:24:37.700 --> 01:24:41.740]   huge red flag about this line of argumentation around why out of
[01:24:41.740 --> 01:24:46.100]   the box candidates can't be evaluated by reasonably smart
[01:24:46.100 --> 01:24:49.380]   people of which there are 300 million of us in America that
[01:24:49.380 --> 01:24:53.340]   have the ability to see it. And so I actually don't think it's
[01:24:53.340 --> 01:24:56.780]   as hard of a job as we make it out to be and that when you get
[01:24:56.780 --> 01:25:01.940]   180 190 million different people voting, I do think you actually
[01:25:01.940 --> 01:25:07.820]   get a pretty good wisdom of the crowds and take away Trump's UI
[01:25:07.820 --> 01:25:11.180]   for a second. What Saks just said is so profound, because
[01:25:11.180 --> 01:25:15.260]   what Trump nailed was three ginormous lanes that turned out
[01:25:15.260 --> 01:25:18.620]   now we can all agree with. None of us wanted these wars.
[01:25:18.620 --> 01:25:22.340]   Everybody basically believes that the border needed to be
[01:25:22.340 --> 01:25:26.780]   closed. And everybody believes that China has taken advantage
[01:25:26.780 --> 01:25:30.100]   in a way that is really hollowed out the middle class in America.
[01:25:30.100 --> 01:25:34.420]   Those were three totems that nobody would have touched. And
[01:25:34.420 --> 01:25:37.380]   if we had allowed this whole thing of like, oh, Trump
[01:25:37.380 --> 01:25:39.660]   doesn't have this Trump doesn't have that he just gives cute
[01:25:39.660 --> 01:25:43.300]   nicknames to his advert series, we would have missed that he
[01:25:43.300 --> 01:25:46.940]   actually had enough executive function to nail the three
[01:25:46.940 --> 01:25:49.660]   biggest themes of our current lifetime.
[01:25:49.660 --> 01:25:52.820]   Okay, I think that's fair. I guess my commentary can just be
[01:25:52.820 --> 01:25:56.060]   reduced down to the debate stage and saying who won and who
[01:25:56.060 --> 01:25:58.220]   should be is different than who should be president. Okay,
[01:25:58.220 --> 01:26:00.900]   necessarily. I think looking at the broader context, good job.
[01:26:00.900 --> 01:26:04.740]   Folks have done a good job. But the presidential candidacy is
[01:26:04.740 --> 01:26:08.660]   much more than just debates. Okay. Yes. There's a lot of
[01:26:08.660 --> 01:26:09.660]   other things going on.
[01:26:09.660 --> 01:26:12.900]   If we're judging people just based on how well they talk and
[01:26:12.900 --> 01:26:15.300]   how quick on their feet they are. Chris Christie is a great
[01:26:15.300 --> 01:26:18.540]   talker. Okay, he's a media trained talker. But guess what?
[01:26:18.540 --> 01:26:19.380]   He got booed.
[01:26:19.380 --> 01:26:22.380]   That was the low point of the debate. The dope point of the
[01:26:22.380 --> 01:26:26.300]   debate for me was that he I thought took a kind of like a
[01:26:26.300 --> 01:26:31.060]   low key racist jab at Vivek when he read it. He referred to
[01:26:31.060 --> 01:26:33.660]   person. Yeah, the last person in one of these debates who stood
[01:26:33.660 --> 01:26:35.980]   in the middle of the stage and said, What's a skinny guy with
[01:26:35.980 --> 01:26:39.500]   an odd last name doing up here was Barack Obama. I'm afraid
[01:26:39.500 --> 01:26:41.980]   we're dealing with the same type of amateur standing on the
[01:26:41.980 --> 01:26:43.580]   stage tonight. You felt was a little
[01:26:43.580 --> 01:26:46.620]   no, not that it's when you got out of the back like chat GPT.
[01:26:46.620 --> 01:26:50.220]   Already have a guy who sounds like chat GPT standing here's
[01:26:50.220 --> 01:26:53.020]   like this Indian tech worker. And I thought, Hey, man, that's
[01:26:53.020 --> 01:26:55.020]   like you read into it. That's interesting. I thought he was
[01:26:55.020 --> 01:26:57.300]   just saying he sounded as a South Asian.
[01:27:01.980 --> 01:27:06.420]   That he was very like, robotic and formulaic or something. But
[01:27:06.420 --> 01:27:09.780]   what did you how did you read it as a as the palace white guy on
[01:27:09.780 --> 01:27:10.180]   the panel,
[01:27:10.180 --> 01:27:13.540]   there was something almost personal about the way that both
[01:27:13.540 --> 01:27:17.060]   Christie and Pence seem to react to a vague it was almost like,
[01:27:17.060 --> 01:27:20.220]   Who are you you young whippersnapper to be on the stage
[01:27:20.220 --> 01:27:23.940]   with me, especially Pence. I've been the vice president. Who are
[01:27:23.940 --> 01:27:26.060]   you? You know, and all this was
[01:27:26.060 --> 01:27:27.420]   here's what his quotes were
[01:27:27.420 --> 01:27:30.020]   dismissive. And I think there was a resentment that even
[01:27:30.020 --> 01:27:33.260]   before this debate, Vivek was rising in the polls, and those
[01:27:33.260 --> 01:27:36.540]   guys were going nowhere. Let me explain it. And again, it's not
[01:27:36.540 --> 01:27:40.420]   just oratorical skill. It's the substance. Yes, of the issues,
[01:27:40.420 --> 01:27:43.620]   and where he's willing to go that these other candidates are
[01:27:43.620 --> 01:27:43.900]   not
[01:27:43.900 --> 01:27:46.340]   here are the quotes to respond to let me explain it to you.
[01:27:46.340 --> 01:27:51.100]   Vivek. I'll go slower this time. Now is not the time for on the
[01:27:51.100 --> 01:27:54.620]   job training. And we don't need to bring in a rookie all this
[01:27:54.620 --> 01:27:58.500]   dismissive stuff from Pence to Vivek got some applause because
[01:27:58.500 --> 01:28:01.220]   you know, conflict, conflict and confrontation gets applaused by
[01:28:01.220 --> 01:28:04.100]   these lunatics in the audience who were like it was like a
[01:28:04.100 --> 01:28:07.220]   while you also get an allocation of seats for your own team. So
[01:28:07.220 --> 01:28:12.540]   yeah, it was the only reason why Pence was VP is because a rookie
[01:28:12.540 --> 01:28:14.620]   got elected president. Yeah, that's a very good. It's a good
[01:28:14.620 --> 01:28:17.460]   insight. Yeah, that was very weird. I thought the thing that
[01:28:17.460 --> 01:28:19.940]   was very interesting was not to make it all about Trump, but he
[01:28:19.940 --> 01:28:24.100]   was the quote unquote elephant that was not in the room was the
[01:28:24.100 --> 01:28:28.140]   undying support for Pence you had everybody say Pence did the
[01:28:28.140 --> 01:28:31.180]   right thing on January 6. What was your takeaway from that
[01:28:31.180 --> 01:28:35.100]   sacks? Because there was some there was a mix of booze and
[01:28:35.100 --> 01:28:38.020]   cheers for Christie when he kind of said like we need somebody
[01:28:38.020 --> 01:28:40.260]   who doesn't behave this way. It's unbecoming of the
[01:28:40.260 --> 01:28:44.300]   presidency referring to Trump. So what was your take on is the
[01:28:44.300 --> 01:28:48.900]   Republican Party in this audience trying to move past
[01:28:48.900 --> 01:28:50.980]   Trump given all these indictments? I'm going to leave
[01:28:50.980 --> 01:28:54.060]   the Trump Stockholm syndrome and Trump derangement syndrome out
[01:28:54.060 --> 01:28:56.180]   of this just objectively. Yeah.
[01:28:56.420 --> 01:29:00.700]   Well, I thought I thought DeSantis had the best response,
[01:29:00.700 --> 01:29:03.900]   which is listen, if we spend our time relitigating January 6,
[01:29:03.900 --> 01:29:06.220]   and looking in the rearview mirror, we're gonna lose to Joe
[01:29:06.220 --> 01:29:10.060]   Biden. This is exactly the conversation and the debate that
[01:29:10.060 --> 01:29:12.700]   Democrats want us to be having. I think that's just factually
[01:29:12.700 --> 01:29:16.100]   true. That if the Republican Party spends its time debating
[01:29:16.100 --> 01:29:18.820]   January 6, that's playing into Biden's hands.
[01:29:18.820 --> 01:29:22.820]   So you don't think Trump can necessarily be Biden that these
[01:29:22.820 --> 01:29:25.220]   other candidates have a better chance of beating Biden? Is that
[01:29:25.220 --> 01:29:25.420]   what you
[01:29:25.420 --> 01:29:27.820]   know, I didn't say that. I'm asking a question saying,
[01:29:27.820 --> 01:29:32.500]   focusing on relitigating, okay, January six is not only is it a
[01:29:32.500 --> 01:29:35.420]   waste of time, it's just a loser for Republicans. And by the way,
[01:29:35.420 --> 01:29:38.940]   it's Trump's worst quality to keep harkening back to the last
[01:29:38.940 --> 01:29:41.980]   election. Even I think his fans and supporters don't want to
[01:29:41.980 --> 01:29:42.500]   hear that.
[01:29:42.500 --> 01:29:45.900]   Who has a better chance of winning some pairing of these
[01:29:45.900 --> 01:29:50.140]   candidates, axe, or Trump and one of these candidates versus
[01:29:50.140 --> 01:29:55.140]   Biden heads up, you know, does something like DeSantis, Vivek
[01:29:55.180 --> 01:29:58.140]   or Haley and Vivek, you know, pick pick your combination here,
[01:29:58.140 --> 01:30:01.660]   have a better chance versus Biden, then Trump plus one of
[01:30:01.660 --> 01:30:01.980]   these.
[01:30:01.980 --> 01:30:08.860]   I think it's tough to say, but I do think that Trump has really
[01:30:08.860 --> 01:30:12.540]   high negatives. And in order for him to win the presidency, he's
[01:30:12.540 --> 01:30:16.700]   got to flip something like two or three out of five states,
[01:30:16.700 --> 01:30:20.980]   like swing states that voted against him last time. And I do
[01:30:20.980 --> 01:30:23.700]   think that this is one of the stronger arguments that DeSantis
[01:30:23.700 --> 01:30:27.140]   makes is that, you know, I could deliver those states, whereas
[01:30:27.140 --> 01:30:32.660]   Trump may not. So I think there is an electability argument for
[01:30:32.660 --> 01:30:33.580]   DeSantis.
[01:30:33.580 --> 01:30:37.460]   Okay. And so Friedberg, hearing all this,
[01:30:37.460 --> 01:30:39.420]   by the way, I'm not saying that that's what's gonna happen. But
[01:30:39.420 --> 01:30:43.140]   I do think we know that Trump does have very high negatives.
[01:30:43.140 --> 01:30:45.220]   And yeah, he's gonna flip some states.
[01:30:45.220 --> 01:30:49.820]   He's gonna have a lot of Democrats and women come out to
[01:30:49.820 --> 01:30:52.220]   vote against him. He supercharges the base in the way
[01:30:52.220 --> 01:30:53.460]   Hillary charged the other way.
[01:30:53.460 --> 01:30:56.100]   Can I say one other thing about DeSantis' performance in that
[01:30:56.100 --> 01:31:00.700]   debate? So I know that he doesn't stand out in the way
[01:31:00.700 --> 01:31:03.500]   that, you know, Vivek or some of these other candidates do,
[01:31:03.500 --> 01:31:06.940]   because he didn't deliver any zingers. And also, he wasn't the
[01:31:06.940 --> 01:31:09.540]   brunt of attack. I think we all thought that maybe there'd be a
[01:31:09.540 --> 01:31:12.060]   lot more incoming for him and the incoming really went for
[01:31:12.060 --> 01:31:16.540]   Vivek. But I think that he had a strategy in that debate. This is
[01:31:16.540 --> 01:31:19.340]   my interpretation. It's not based on any insider knowledge
[01:31:19.340 --> 01:31:23.580]   or anything like that. Which was the way he answered questions
[01:31:23.580 --> 01:31:26.900]   was, I think, to be broadly acceptable to all the different
[01:31:26.900 --> 01:31:30.020]   factions in the GOP. So like I mentioned, there's kind of the
[01:31:30.020 --> 01:31:33.380]   MAGA faction, there's the neocon faction, and there's the
[01:31:33.380 --> 01:31:39.020]   religious right faction. And his answers may not have been the
[01:31:39.020 --> 01:31:42.820]   ones that were most loved by any of those factions. But I also
[01:31:42.820 --> 01:31:46.460]   think that none of his answers disqualified himself with any of
[01:31:46.460 --> 01:31:49.060]   those factions, which is kind of hard to do given how much
[01:31:49.060 --> 01:31:50.180]   they're at each other's throats.
[01:31:50.180 --> 01:31:52.900]   So sacks, if this was a poker tournament, and this was the
[01:31:52.900 --> 01:31:57.620]   final table, would you say the strategy for the Santas was,
[01:31:57.620 --> 01:32:00.020]   Hey, listen, I'm gonna let these other guys shoot it out. I'm
[01:32:00.020 --> 01:32:02.620]   just gonna sit on my big chip stack here. I'm in second place.
[01:32:02.620 --> 01:32:06.220]   You got let me let let's let the field eliminate themselves. I'm
[01:32:06.220 --> 01:32:08.340]   going to just protect my stack. I'm not going to play a lot of
[01:32:08.340 --> 01:32:12.020]   hands here. He's just sort of sitting and waiting for it to
[01:32:12.020 --> 01:32:13.540]   get down to three or four people. And then I'll mix it up
[01:32:13.540 --> 01:32:14.860]   some more. Is that the strategy?
[01:32:14.860 --> 01:32:17.260]   I think he came across as the grown up.
[01:32:18.300 --> 01:32:21.100]   Nobody really took swipes at him or shots at him. And he didn't
[01:32:21.100 --> 01:32:24.220]   really take shots anybody else. He did, again, try to focus the
[01:32:24.220 --> 01:32:27.180]   Republican Party on what it's going to take to win. He was one
[01:32:27.180 --> 01:32:30.780]   of the only people on that stage who had criticism of Biden. I
[01:32:30.780 --> 01:32:32.820]   think it was a mistake not to criticize Biden's record.
[01:32:32.820 --> 01:32:35.980]   Yeah, they shocked at that. That was such a weird thing that
[01:32:35.980 --> 01:32:38.740]   they were all going after Trump. And the only attacks on nothing
[01:32:38.740 --> 01:32:39.300]   about Biden.
[01:32:39.300 --> 01:32:42.540]   The only attacks on Biden that I even remember from that night
[01:32:42.540 --> 01:32:46.620]   were from Trump's interview with Tucker where he criticized God,
[01:32:46.620 --> 01:32:49.780]   he destroyed, criticized Biden's lack of physical and mental
[01:32:49.780 --> 01:32:52.740]   acuity. But look, I think that if if the convention were
[01:32:52.740 --> 01:32:55.420]   ultimately to be a broker convention, which all the
[01:32:55.420 --> 01:32:58.740]   different factions of the GOP had to agree on a candidate,
[01:32:58.740 --> 01:33:02.020]   then I think this answers to be that candidate because he may
[01:33:02.020 --> 01:33:05.260]   not be the candidate who is most loved by any of those factions.
[01:33:05.260 --> 01:33:07.780]   But I think he's made himself the most broadly acceptable to
[01:33:07.780 --> 01:33:10.460]   all of them. The problem is, I don't think that's the way that
[01:33:10.460 --> 01:33:13.380]   candidates are chosen. You know, I think that what happens in
[01:33:13.380 --> 01:33:16.460]   practice is that the factions are trying to feed each other.
[01:33:17.300 --> 01:33:20.860]   And that one faction is going to win. And I think it's probably
[01:33:20.860 --> 01:33:23.660]   give me the MAGA faction. So that's the problem, I think,
[01:33:23.660 --> 01:33:27.140]   with this strategy. But look, he came across the grown up and he
[01:33:27.140 --> 01:33:28.980]   came across as the most broadly acceptable.
[01:33:28.980 --> 01:33:35.700]   Okay, so if this is a final table of a poker tournament, and
[01:33:35.700 --> 01:33:38.300]   Trump is going to sit down and debate three of these people
[01:33:38.300 --> 01:33:43.500]   come off, who's going to be left to debate Trump and be the final
[01:33:43.500 --> 01:33:45.380]   three or four seats here? Which three?
[01:33:45.380 --> 01:33:53.420]   I think it'll be the Santas, Vivek, and it'll be either Tim
[01:33:53.420 --> 01:33:54.220]   Scott or Nikki Haley.
[01:33:54.220 --> 01:33:57.180]   Interesting, Freeberg, who are the final three who are going to
[01:33:57.180 --> 01:33:59.700]   debate Trump, you know, in debate number four or five?
[01:33:59.700 --> 01:34:03.180]   I don't know if he's gonna show up. I don't know why he would if
[01:34:03.180 --> 01:34:07.900]   he's up 50 60 70% of the polls. I mean, it would be it would just
[01:34:07.900 --> 01:34:11.620]   be such a Trump move to do not show up to any of these debates
[01:34:11.620 --> 01:34:12.900]   and just like get elected.
[01:34:12.900 --> 01:34:13.460]   Play the game.
[01:34:13.460 --> 01:34:16.860]   How incredible debate would that be if it was from the Santos and
[01:34:16.860 --> 01:34:17.460]   Vivek?
[01:34:17.460 --> 01:34:18.940]   Fire.
[01:34:18.940 --> 01:34:21.940]   My fourth would be Nikki Haley. I think she had a good she had
[01:34:21.940 --> 01:34:24.420]   her moments in that debate. I think she had good advice for
[01:34:24.420 --> 01:34:26.180]   the Republican Party on the abortion issue.
[01:34:26.180 --> 01:34:27.940]   Yeah, she did a great job.
[01:34:27.940 --> 01:34:32.220]   And she pointed out how, you know, much money. I thought that
[01:34:32.220 --> 01:34:34.660]   was a tea party moment for her. That's when I warmed up to Nikki
[01:34:34.660 --> 01:34:38.340]   Halley a bunch. She's like, Listen, we also approved, you
[01:34:38.340 --> 01:34:41.100]   know, six, $8 trillion, we got to look at ourselves. And it was
[01:34:41.100 --> 01:34:43.940]   like, Okay, is it the tea party 2010? Here? I thought that was a
[01:34:43.940 --> 01:34:46.220]   great moment. Who do you who do you have left freeberg? Everybody
[01:34:46.220 --> 01:34:48.980]   else played the game play along, who will be the final three here
[01:34:48.980 --> 01:34:51.860]   to debate Trump if Trump shows up? play along for the game.
[01:34:51.860 --> 01:34:55.380]   I mean, I'll get mine. Vivek seems to be in a good place.
[01:34:55.380 --> 01:34:55.940]   Okay.
[01:34:55.940 --> 01:35:00.180]   I don't know. The Santa says a lot of money. Yeah, he's
[01:35:00.180 --> 01:35:01.460]   probably gonna stick around.
[01:35:01.460 --> 01:35:05.260]   Yeah. So the vacant Santa's are we all have consensus. Nikki
[01:35:05.260 --> 01:35:05.740]   Halley.
[01:35:05.740 --> 01:35:08.820]   I don't think he's gonna show up.
[01:35:08.820 --> 01:35:11.020]   We got your we got your point. Yeah.
[01:35:11.140 --> 01:35:15.940]   You're critical of the fact that the vague is having a boom or
[01:35:15.940 --> 01:35:19.060]   surge based on his oratorical skills, which I think you regard
[01:35:19.060 --> 01:35:20.500]   as being a shot away.
[01:35:20.500 --> 01:35:22.780]   Question.
[01:35:22.780 --> 01:35:26.340]   You're showing no enthusiasm for de Santos, who actually has a
[01:35:26.340 --> 01:35:28.060]   track record of being the most capable exec.
[01:35:28.060 --> 01:35:30.540]   Oh, no, no, I'm not. By the way, I didn't. I'm not we're not
[01:35:30.540 --> 01:35:32.380]   talking about who I would vote for president. We haven't even
[01:35:32.380 --> 01:35:34.420]   had that comment. Like we didn't even ask that question once.
[01:35:34.420 --> 01:35:38.700]   Okay, so we're asking now. Putting aside Trump, who do you
[01:35:38.700 --> 01:35:39.060]   pick?
[01:35:39.140 --> 01:35:41.740]   What was really interesting is hearing the governors speak
[01:35:41.740 --> 01:35:44.860]   about their skills. I think Nikki Haley, Chris Christie,
[01:35:44.860 --> 01:35:49.460]   Bergam, the Santa's all had moments where they shine from
[01:35:49.460 --> 01:35:52.420]   from from Hutchinson, from my perspective, from a content
[01:35:52.420 --> 01:35:54.420]   perspective, which is what I was talking about at the beginning,
[01:35:54.420 --> 01:35:57.740]   which people largely ignore, which is that they actually had
[01:35:57.740 --> 01:36:00.740]   quite a lot to draw from and, you know, some policy that seemed
[01:36:00.740 --> 01:36:01.380]   pretty strong.
[01:36:01.380 --> 01:36:04.140]   Here we go. Final question. Final question. I want you to
[01:36:04.140 --> 01:36:08.380]   give me your one and two not Trump. Saks, we know de Santos
[01:36:08.380 --> 01:36:10.580]   is number one for you. So then who's who's your number two to
[01:36:10.580 --> 01:36:11.940]   pair with him? Who would you pair with?
[01:36:11.940 --> 01:36:15.180]   We're saying be what to be the candidate to be that the ticket,
[01:36:15.180 --> 01:36:18.060]   Republican ticket, you're going to go to Santa's one. And then
[01:36:18.060 --> 01:36:19.700]   who do you put with a measure as a number two?
[01:36:19.700 --> 01:36:26.860]   Well, for me, to Santa's end, I think that the only candidates
[01:36:26.860 --> 01:36:30.820]   who have acceptable answers on what I regard as the number one
[01:36:30.820 --> 01:36:33.420]   issue of our time, which is Ukraine, because that could lead
[01:36:33.420 --> 01:36:35.620]   to war three, the only candidates have acceptable
[01:36:35.620 --> 01:36:38.980]   answers are Trump, the vacant Santa's, meaning they've all
[01:36:38.980 --> 01:36:41.780]   been pretty clear, they would de escalate. I think all the other
[01:36:41.780 --> 01:36:44.340]   candidates have basically indicated in one way or another,
[01:36:44.340 --> 01:36:44.820]   they would ask,
[01:36:44.820 --> 01:36:48.300]   Vivek is those three candidates are the only ones that are
[01:36:48.300 --> 01:36:50.740]   acceptable to me. Okay, so we take Trump off if Trump doesn't
[01:36:50.740 --> 01:36:52.940]   run, which that's my personal belief. But just of the people
[01:36:52.940 --> 01:36:55.700]   who are on stage last night, you're going to Santa's Vivek is
[01:36:55.700 --> 01:37:00.140]   your ticket to math, who's your ticket? After one debate, not
[01:37:00.140 --> 01:37:02.820]   counting Trump? If the Republican ticket, who do you
[01:37:02.820 --> 01:37:03.420]   think is a Republican?
[01:37:03.420 --> 01:37:05.580]   Look, I like to buy these deep out of the money options. I
[01:37:05.580 --> 01:37:08.220]   think we'll go out on a limb. I think that Vivek has a really
[01:37:08.220 --> 01:37:10.300]   good chance of winning this Republican nomination. That's
[01:37:10.300 --> 01:37:14.220]   what I saw. I saw like outright against Trump. Yeah, I
[01:37:14.220 --> 01:37:16.580]   were taking Trump off the table. So just pick, you know, for
[01:37:16.580 --> 01:37:20.420]   example, for example, no, no, no, no, I really do think he's
[01:37:20.420 --> 01:37:23.740]   he can win this thing. And, for example, I thought it was very
[01:37:23.740 --> 01:37:28.420]   clever when he said that he had a line, he said, Donald Trump
[01:37:28.420 --> 01:37:33.100]   was the best. Let me be categorically clear. Donald
[01:37:33.100 --> 01:37:36.420]   Trump was the best president of the 21st century. And I was
[01:37:36.420 --> 01:37:40.140]   like, what? And then I thought about it is and I thought, why
[01:37:40.140 --> 01:37:42.620]   is he saying it? Does he say it because he believes it? Or does
[01:37:42.620 --> 01:37:47.740]   he saying because it's like a tactic? And there's probably
[01:37:47.740 --> 01:37:51.220]   bits of both. Yep. Because I do think that there are elements
[01:37:51.220 --> 01:37:55.460]   where he fundamentally does believe that Trump has at least
[01:37:55.460 --> 01:37:58.980]   shine the path forward. And so I think he does believe it to
[01:37:58.980 --> 01:38:02.540]   some degree. But then I thought it's even smarter to have said
[01:38:02.540 --> 01:38:06.500]   it. And again, this is where I go back to, I'm not sure that
[01:38:06.500 --> 01:38:10.420]   that's oratory skills versus like, understanding, you know,
[01:38:10.420 --> 01:38:14.260]   game theory, strategy, and and strategy and being a strategic
[01:38:14.260 --> 01:38:16.860]   thinker and trying to win. I thought that that was a very
[01:38:16.860 --> 01:38:20.500]   smart thing to have said. And all along that evening, I
[01:38:20.500 --> 01:38:25.500]   thought that he did the best job of preserving optionality for
[01:38:25.500 --> 01:38:30.540]   the Trump base to say, you know what, Vivek is all of the
[01:38:30.540 --> 01:38:33.820]   positive features of Trump without some of the negatives.
[01:38:33.820 --> 01:38:36.620]   So let's just clean up the ticket and let's go and I think
[01:38:36.620 --> 01:38:40.060]   that there's still again, there's a long way. Yeah, I
[01:38:40.060 --> 01:38:43.020]   like the call. I like the call. But I would buy that deep out of
[01:38:43.020 --> 01:38:45.420]   the money option. And who's your number two, then? We're going
[01:38:45.420 --> 01:38:48.020]   one, two here, one, two, either as to pair with Vivek or your
[01:38:48.020 --> 01:38:51.900]   number two choice in terms of know that I if the deck doesn't
[01:38:51.900 --> 01:38:55.220]   figure out a way to slipstream past Trump, the Trump will win
[01:38:55.220 --> 01:38:58.060]   the nomination. Okay, taking Trump out of the rest. Who's
[01:38:58.060 --> 01:39:01.420]   your number two? Okay, great. Fascinating to see this
[01:39:01.420 --> 01:39:04.860]   happening. I agree with what a lot of what Jamal said. I think
[01:39:04.860 --> 01:39:10.980]   Vivek is positioning himself to be the backup candidate for the
[01:39:10.980 --> 01:39:15.140]   MAGA wing. Yeah. And he's doing it by never attacking Trump and
[01:39:15.140 --> 01:39:18.140]   by complimenting him. By the way, saying that Trump was the
[01:39:18.140 --> 01:39:20.060]   best president of the 21st century. There's only been
[01:39:20.060 --> 01:39:25.100]   three. It was George W. Bush, Obama, and then Trump. Sorry,
[01:39:25.100 --> 01:39:28.860]   Biden. Sorry, Biden's has been for George W. Bush was one of
[01:39:28.860 --> 01:39:31.580]   the worst presidents in American history. Yeah, so it's a
[01:39:31.580 --> 01:39:34.900]   forever wars. Obama, obviously, a Republican candidate is not
[01:39:34.900 --> 01:39:38.940]   going to think highly of Obama or Biden. So it kind of narrows
[01:39:38.940 --> 01:39:39.740]   it down, doesn't it?
[01:39:39.740 --> 01:39:44.100]   Yeah, what was the intelligence of actually saying the words?
[01:39:44.100 --> 01:39:46.740]   Yeah, strategically brilliant. I know, I agree.
[01:39:46.740 --> 01:39:50.380]   facts. What do you think about the VIX unpopular statement? And
[01:39:50.380 --> 01:39:52.900]   it may I'd like to hear whether it's unpopular with the base,
[01:39:52.980 --> 01:39:55.420]   but it was certainly unpopular in the room last night, that the
[01:39:55.420 --> 01:39:59.460]   climate change agenda is a hoax, which drew a lot of booze. That
[01:39:59.460 --> 01:40:04.340]   was is that like, is that a lightning bolt kind of thing to
[01:40:04.340 --> 01:40:08.700]   say? Why would he say that? And what's the strategy?
[01:40:08.700 --> 01:40:12.940]   Like Trump saying he loves coal? He loves coal miners. It's just
[01:40:12.940 --> 01:40:15.980]   it felt to me a little bit like he was trying to say agenda is a
[01:40:15.980 --> 01:40:19.300]   hoax, meaning like all the ESG stuff is nonsense. But it comes
[01:40:19.300 --> 01:40:22.140]   across as him saying climate change isn't real. And he's got
[01:40:22.140 --> 01:40:24.300]   to now deal with the repercussions. And climate change
[01:40:24.300 --> 01:40:25.060]   is strategic.
[01:40:25.060 --> 01:40:30.180]   I think it's I don't I don't think you know what he believes
[01:40:30.180 --> 01:40:30.860]   J. Cal, but
[01:40:30.860 --> 01:40:33.700]   yeah, his follow up comment around that was he said that it
[01:40:33.700 --> 01:40:38.420]   is an economic yoke on our country. Because the combination
[01:40:38.420 --> 01:40:42.660]   of subsidies and the lack of expansion of carbon is what's
[01:40:42.660 --> 01:40:45.580]   holding back the country economically. So that's I think
[01:40:45.580 --> 01:40:48.500]   I remember him tying these two things together. So that's
[01:40:48.500 --> 01:40:50.700]   probably where the state no intelligent person doesn't
[01:40:50.700 --> 01:40:53.860]   believe that the planet's not heating up. Come on. And that
[01:40:53.860 --> 01:40:55.580]   it's not better to go to renewables. That's just
[01:40:55.580 --> 01:40:57.460]   how do you know if you looked at the science, J. Cal?
[01:40:57.460 --> 01:40:59.460]   Of course I have. Yes, it's massive.
[01:40:59.460 --> 01:41:00.700]   You've gone deep on the science.
[01:41:00.700 --> 01:41:03.420]   You know, as deep as a person needs to go free bird.
[01:41:03.420 --> 01:41:06.900]   You just treat it. Look, it's just something you're supposed
[01:41:06.900 --> 01:41:09.420]   to believe in. No, I'm not saying that.
[01:41:09.420 --> 01:41:12.940]   How the planet has gotten warmer. That's it.
[01:41:12.940 --> 01:41:17.380]   I will say sacks is right. That it has become a thing that it's
[01:41:17.380 --> 01:41:20.900]   like we're all supposed to take as given. No one is going to go
[01:41:20.900 --> 01:41:24.140]   up and say, here's the science that validates here's the data
[01:41:24.140 --> 01:41:26.420]   that validates here's there's some empirical evidence and
[01:41:26.420 --> 01:41:28.660]   then people use counter empirical evidence to try and
[01:41:28.660 --> 01:41:30.940]   counter it. And that's what makes it a little bit of a
[01:41:30.940 --> 01:41:36.460]   movement now, which is the institutions, the elites,
[01:41:36.460 --> 01:41:39.300]   however, they're framed have been wrong so many times on the
[01:41:39.300 --> 01:41:41.740]   things that they told us were given, that we're supposed to
[01:41:41.740 --> 01:41:45.420]   assume that this is a given to F that I'm not going to decide
[01:41:45.420 --> 01:41:48.020]   what to believe anymore. And I don't want to be told what to
[01:41:48.020 --> 01:41:50.780]   believe anymore is exactly what people let me let me state my
[01:41:50.780 --> 01:41:54.300]   what they heard from that song last week. And that's what they
[01:41:54.300 --> 01:41:56.660]   heard. You know, and let me state my position. I totally
[01:41:56.660 --> 01:42:00.460]   agree. Yeah, here's the thing. After COVID without me even
[01:42:00.460 --> 01:42:03.340]   making a comment on climate change 100% we were told so
[01:42:03.340 --> 01:42:07.580]   much bullshit in the name of science during COVID. They told
[01:42:07.580 --> 01:42:10.020]   us that vaccines are safe and effective. I just want to
[01:42:10.020 --> 01:42:11.460]   clarify my position before you respond to it.
[01:42:12.540 --> 01:42:15.420]   It's undeniable that temperatures have risen. I
[01:42:15.420 --> 01:42:19.580]   think it's a crazy experiment to run to not try to lower it.
[01:42:19.580 --> 01:42:23.020]   It's just a crazy experiment. The planet is precious. I don't
[01:42:23.020 --> 01:42:25.940]   think we should run it. I am not dogmatic about it. It's not a
[01:42:25.940 --> 01:42:27.420]   religious thing. I'm not genuinely
[01:42:27.420 --> 01:42:30.060]   experiment we're running Jake. It's called human development
[01:42:30.060 --> 01:42:30.860]   and growth. Yes.
[01:42:30.860 --> 01:42:35.820]   And the temperature goes up. So why wouldn't we use renewable
[01:42:35.820 --> 01:42:40.140]   energy nuclear when not pollute because not polluting is is good
[01:42:40.140 --> 01:42:41.420]   to when you have
[01:42:41.420 --> 01:42:48.380]   self proclaimed scientific experts and or 16 year old
[01:42:48.380 --> 01:42:56.580]   girls shaming everybody with pretty flimsy data. There was a
[01:42:56.580 --> 01:42:59.060]   while where we were everybody just said, Ma, they must be
[01:42:59.060 --> 01:43:03.620]   right. And COVID exposed the hoax. And so now we're a lot
[01:43:03.620 --> 01:43:08.060]   less prone to believe these self proclaimed intellectuals and
[01:43:08.060 --> 01:43:14.020]   their jargon and their nonsense. So ask me how much money have I
[01:43:14.020 --> 01:43:18.580]   invested in climate change with all that data? Zero. Ask me how
[01:43:18.580 --> 01:43:21.700]   much money I've invested in technologies that will benefit
[01:43:21.700 --> 01:43:24.620]   climate change as a byproduct of national security. hundreds of
[01:43:24.620 --> 01:43:27.260]   millions of dollars. Yes. And the reason I give you that
[01:43:27.260 --> 01:43:31.940]   example is that, for me, that framing was just such a turnoff
[01:43:31.940 --> 01:43:35.500]   because I couldn't buy into it. Yeah, there are multiple reasons
[01:43:35.500 --> 01:43:39.540]   the more pragmatic, realistic framing, which allowed us to
[01:43:39.540 --> 01:43:42.420]   actually say maybe you're right, but maybe you're wrong. But
[01:43:42.420 --> 01:43:44.660]   let's not even debate the issue. Let's just go and make sure
[01:43:44.660 --> 01:43:46.620]   we're not dependent on another country and fighting endless
[01:43:46.620 --> 01:43:49.660]   wars. That got me off my ass to do stuff. And I think there's a
[01:43:49.660 --> 01:43:52.660]   lot of people in America that are in that second category.
[01:43:52.660 --> 01:43:56.220]   They don't want absolutely emotionally riddled dogma to
[01:43:56.220 --> 01:43:58.820]   drive their life and how they're forced to make decisions. You
[01:43:58.820 --> 01:44:03.260]   can come up with three or four really good reasons to not keep
[01:44:03.260 --> 01:44:07.260]   burning fossil fuels. They're dirty. They're pollutants. There
[01:44:07.260 --> 01:44:10.380]   are better options that are more sustainable that are more cost
[01:44:10.380 --> 01:44:13.140]   effective, it's more cost effective to put solar in than
[01:44:13.140 --> 01:44:16.300]   to burn coal or build a new coal plant. So there's economic
[01:44:16.300 --> 01:44:19.820]   reasons. And then of course, those points, you know, we're
[01:44:19.820 --> 01:44:22.620]   saying is we're not automatically going to trust. I
[01:44:22.620 --> 01:44:25.340]   am not automatically trusting I'm taking the body of evidence
[01:44:25.340 --> 01:44:28.100]   search. I'm not blindly trusting anybody. I'm taking the body of
[01:44:28.100 --> 01:44:30.700]   evidence and saying that entire body of evidence.
[01:44:30.700 --> 01:44:32.900]   Geopolitical really looked at the evidence. I don't believe
[01:44:32.900 --> 01:44:36.420]   I know on this issue. Okay, anyway, I haven't gone deep on
[01:44:36.420 --> 01:44:38.060]   this issue. That's all I'm saying.
[01:44:38.060 --> 01:44:43.220]   To what I'm saying, if you listen, as opposed to telling me
[01:44:43.220 --> 01:44:46.420]   what I think, and listen to what I'm telling you, there are many
[01:44:46.420 --> 01:44:51.380]   reasons to pursue sustainable energy, clean energy, and
[01:44:51.380 --> 01:44:55.220]   geopolitics is one of them. And, you know, polluting the
[01:44:55.220 --> 01:44:57.700]   environment is one of them and temperatures rising if that
[01:44:57.700 --> 01:45:03.180]   indeed results in damages to the oceans and you know, weather
[01:45:03.180 --> 01:45:07.580]   patterns, there are five or six great reasons to stop burning
[01:45:07.580 --> 01:45:09.260]   coal and stop burning oil.
[01:45:09.260 --> 01:45:12.580]   Look at these two climate whitewashers were living in in
[01:45:12.580 --> 01:45:16.620]   this moment. People were so convinced they just needed to
[01:45:16.620 --> 01:45:20.180]   roil the country around the hurricane hitting California.
[01:45:20.180 --> 01:45:24.340]   Then by the time it landed, it was a storm. There was rain in
[01:45:24.340 --> 01:45:27.180]   Los Angeles. I asked people here when I got here, I said, How is
[01:45:27.180 --> 01:45:30.140]   hurricane? They're like, it wasn't a hurricane. And in fact,
[01:45:30.140 --> 01:45:33.740]   the news were so tilted about it, they had to call it it could
[01:45:33.740 --> 01:45:36.660]   have been a hurricane. Yeah, there was a storm ratings.
[01:45:36.660 --> 01:45:40.900]   Second is this thing in Maui, it turns out Michael Schellenberger
[01:45:40.900 --> 01:45:44.420]   has done some pretty good work on this is exposing that a lot
[01:45:44.420 --> 01:45:48.260]   of the reason these fires may have started was because of this
[01:45:48.260 --> 01:45:53.020]   radical climate agenda that caused the utility to not invest
[01:45:53.020 --> 01:45:55.900]   in the protective measures they should have around power lines.
[01:45:56.100 --> 01:45:57.820]   That is crazy, Jason.
[01:45:57.820 --> 01:46:01.380]   Oh, yeah, I'm not defending what happened in Maui. It's obviously
[01:46:01.380 --> 01:46:03.940]   incompetence. We should be bearing we have the same issue
[01:46:03.940 --> 01:46:07.660]   in California, which is dogmatic belief. There's a consequence.
[01:46:07.660 --> 01:46:10.460]   It's not a dogmatic believer. No, I'm not saying you are. I'm
[01:46:10.460 --> 01:46:12.740]   just trying to make I'm not saying you are. I'm trying to
[01:46:12.740 --> 01:46:16.060]   make this point. When people dogmatically believe bodies of
[01:46:16.060 --> 01:46:19.020]   evidence that they themselves don't interrogate fully, they
[01:46:19.020 --> 01:46:22.020]   may, it may lead them to conclusions and then actions
[01:46:22.020 --> 01:46:24.900]   that you are now seeing have measurable human consequences.
[01:46:24.900 --> 01:46:27.700]   If you look at PG&E in California, it's riddled with
[01:46:27.700 --> 01:46:28.340]   these issues.
[01:46:28.340 --> 01:46:31.140]   Yeah, they shut our power off because they're afraid that wind
[01:46:31.140 --> 01:46:33.340]   is going to blow down power lines and start fires. Yeah, I
[01:46:33.340 --> 01:46:35.100]   mean, and we just need to bury them. So.
[01:46:35.100 --> 01:46:37.860]   So I think that it would be great to like not debate the
[01:46:37.860 --> 01:46:41.340]   climate issue, put a pin in it. And instead, just say, we all
[01:46:41.340 --> 01:46:44.980]   want our kids to be able to have clean air around us. Yes, clean
[01:46:44.980 --> 01:46:47.860]   water to drink. And we want to make sure that we have the
[01:46:47.860 --> 01:46:50.900]   resources to be productive as human beings without having to
[01:46:50.900 --> 01:46:53.860]   send our kids to war, or without putting the country in danger.
[01:46:53.980 --> 01:46:57.900]   100% which is exactly my point. There's so many reasons to take
[01:46:57.900 --> 01:47:00.300]   this seriously and move to renewables and nuclear. All
[01:47:00.300 --> 01:47:03.300]   right, listen, this has been an insanely great episode. Hey,
[01:47:03.300 --> 01:47:07.940]   let me just get one person's comments. So here's your here's
[01:47:07.940 --> 01:47:13.500]   your red meat for sacks here. It sounds like there was the the
[01:47:13.500 --> 01:47:17.300]   coup. 60 days later, the guy who was running the coup in Russia
[01:47:17.300 --> 01:47:22.780]   had a little accident so random. Maybe your thoughts. Sacks.
[01:47:23.460 --> 01:47:26.580]   You're talking about for Goshen? Yeah, I mean, he had some
[01:47:26.580 --> 01:47:29.300]   mechanical difficulties on his PJ. I don't know what happened.
[01:47:29.300 --> 01:47:31.820]   Is he sending that citation in for maintenance? What happened?
[01:47:31.820 --> 01:47:34.340]   They had a bad engine or something. It's so random. Poor
[01:47:34.340 --> 01:47:36.460]   guy. The latest reporting from the New York Times this morning
[01:47:36.460 --> 01:47:39.660]   is that for Goshen's plane was not shot shot down, but rather
[01:47:39.660 --> 01:47:42.860]   they believe there was an explosive device on it. Oh, so
[01:47:42.860 --> 01:47:46.580]   we don't know. You know, we don't we don't know exactly. It
[01:47:46.580 --> 01:47:48.980]   was a bird strike something random like a bird strike. No,
[01:47:48.980 --> 01:47:51.700]   not somebody took him out. Somebody took him off the board.
[01:47:51.700 --> 01:47:54.500]   Really? Oh, must have been. It must have been Ukraine, right?
[01:47:54.500 --> 01:47:57.540]   That's who you're putting it on. It's Ukraine. No, I mean, I
[01:47:57.540 --> 01:48:00.740]   think it's probably pretty obvious who did it. Although we
[01:48:00.740 --> 01:48:06.700]   won't know for sure. So I think, listen, I think that
[01:48:06.700 --> 01:48:12.660]   allegedly, allegedly, that's what you always say whenever 100
[01:48:12.660 --> 01:48:14.700]   binds accused of doing something you always have to insert
[01:48:14.700 --> 01:48:18.700]   allegedly, there was a little cocaine and maybe some bribes. I
[01:48:18.700 --> 01:48:21.940]   think this resolves the question of who came out on top during
[01:48:21.940 --> 01:48:25.980]   that mutiny. There were a lot of people speculating that somehow
[01:48:25.980 --> 01:48:28.780]   pergoes and had the upper hand or he was paid off or that
[01:48:28.780 --> 01:48:30.700]   happened. Right? Remember, there was a line of thinking, Oh,
[01:48:30.700 --> 01:48:34.620]   this wasn't a coup. If it wasn't a coup, then why did Putin whack
[01:48:34.620 --> 01:48:34.820]   him?
[01:48:34.820 --> 01:48:36.780]   Back, back.
[01:48:36.780 --> 01:48:40.260]   And it was exactly 60 days later. Is that correct? That was
[01:48:40.260 --> 01:48:42.700]   the other thing is that can ask a question. How funny is it
[01:48:42.700 --> 01:48:45.380]   that it's like, Putin's like, hey, pergoes and come, come and
[01:48:45.380 --> 01:48:48.340]   see me. We're good. Nothing to worry about. I'll send a
[01:48:48.340 --> 01:48:52.780]   private jet. And then it's like, Listen, where are you going to
[01:48:52.780 --> 01:48:55.660]   the black? So you can take my PJ and he's like, I can't see
[01:48:55.660 --> 01:48:59.620]   later. How does this happen? Like, you can't even write this
[01:48:59.620 --> 01:49:00.180]   stuff related.
[01:49:00.180 --> 01:49:02.820]   freeberg is sending his PJ to take me down to the
[01:49:02.820 --> 01:49:06.100]   thanks for the ride freeberg. I told you it's like Michael
[01:49:06.100 --> 01:49:09.780]   Corleone. Apparently, there's a meeting about a month ago. I
[01:49:09.780 --> 01:49:12.380]   remember it being reported where progression and the other heads
[01:49:12.380 --> 01:49:16.220]   of Wagner came to meet with Putin. And the deal that Putin
[01:49:16.220 --> 01:49:20.140]   supposedly offered was that Wagner could stay together, but
[01:49:20.140 --> 01:49:23.140]   they had to report to the Russian military. And the Wagner
[01:49:23.140 --> 01:49:26.460]   commanders were on board with it. But one person objected and
[01:49:26.460 --> 01:49:29.140]   that was progression. Oh, so it's a little bit like remember
[01:49:29.140 --> 01:49:32.220]   that the meeting between Michael Corleone and Mo green and
[01:49:32.220 --> 01:49:35.860]   Vegas? Yeah, yeah, yeah. You know, Michael's like, think of a
[01:49:35.860 --> 01:49:39.500]   price and Mo greens like, you don't buy me out. I buy you
[01:49:39.500 --> 01:49:44.100]   out. That kind of reaction. Yeah. And the guy had some sort
[01:49:44.100 --> 01:49:45.100]   of death wish, I guess.
[01:49:45.380 --> 01:49:48.980]   You know what they say, beware the dog that doesn't bark. Putin
[01:49:48.980 --> 01:49:51.220]   said nothing for the last two months. He was like, Yeah, it's
[01:49:51.220 --> 01:49:55.860]   all good. Nothing out of the Putin camp. And then boom. Putin
[01:49:55.860 --> 01:49:59.420]   is a murderous lunatic, who must be stopped and contained.
[01:49:59.420 --> 01:50:02.140]   I think the opposite of being a lunatic. I think this is
[01:50:02.140 --> 01:50:04.740]   somebody who is very cold and calculating. Okay, yeah,
[01:50:04.740 --> 01:50:06.580]   murderous, calculated sociopath.
[01:50:06.580 --> 01:50:10.180]   He figured out how to diffuse a mutiny. I don't think it was a
[01:50:10.180 --> 01:50:13.820]   full on coup, but a mutiny that would have been very disruptive
[01:50:13.820 --> 01:50:15.900]   to his front line if he had basically tried to violently
[01:50:15.900 --> 01:50:20.980]   suppress it. So he cuts a deal where basically he offers
[01:50:20.980 --> 01:50:24.220]   banishment to Belarus. progression was supposed to go
[01:50:24.220 --> 01:50:28.260]   to Belarus. By the way, we don't know exactly why progression
[01:50:28.260 --> 01:50:31.300]   returned to Moscow or St. Petersburg. He was supposed to
[01:50:31.300 --> 01:50:34.820]   be staying in Belarus or Africa. So maybe he violated the terms
[01:50:34.820 --> 01:50:37.300]   of his probation. We don't know. There are all these people on
[01:50:37.300 --> 01:50:40.300]   social media who are pinning their hopes for regime change
[01:50:40.300 --> 01:50:44.900]   and liberal reform within Russia on progression, which was always
[01:50:44.900 --> 01:50:48.340]   absurd, because he was this warlord, whose behavior and
[01:50:48.340 --> 01:50:53.140]   conduct was even more erratic and violent than Putin. So he
[01:50:53.140 --> 01:50:56.340]   was never going to be a great vessel for liberal reform in
[01:50:56.340 --> 01:50:59.940]   Russia. Nonetheless, there are all these people who pin their
[01:50:59.940 --> 01:51:02.460]   hopes for regime change in Russia on progression. We can
[01:51:02.460 --> 01:51:07.140]   see now what a stupid idea that was. The Russian regime, whether
[01:51:07.140 --> 01:51:10.820]   you like it or not, is stable is not unstable. Russia is winning
[01:51:10.820 --> 01:51:14.860]   the war. And you may hate Putin, but he is still master of
[01:51:14.860 --> 01:51:17.260]   Russia. And eventually, we're gonna have to deal with him.
[01:51:17.260 --> 01:51:22.220]   These fantasies that we're gonna be able to regime change him, I
[01:51:22.220 --> 01:51:24.740]   think are absurd. And they've led us to this horrible point.
[01:51:24.740 --> 01:51:29.900]   Okay, for the dictator for the Sultan of science and focused
[01:51:29.900 --> 01:51:34.540]   SAS sacks with a slick back hair. I am the most great
[01:51:34.540 --> 01:51:35.740]   moderator. See you next time. Bye bye.
[01:51:35.740 --> 01:51:38.540]   Oh, let your winners ride.
[01:51:38.540 --> 01:51:41.060]   Rain Man David
[01:51:41.060 --> 01:51:48.140]   We open sources to the fans and they've just gone crazy with it.
[01:51:48.140 --> 01:51:48.820]   Love you.
[01:51:48.820 --> 01:51:50.620]   West Coast Queen of Kinhwa
[01:51:50.620 --> 01:51:58.060]   besties are
[01:51:58.060 --> 01:52:02.060]   dog taking a notice in your driveway.
[01:52:03.020 --> 01:52:05.820]   Oh, man.
[01:52:05.820 --> 01:52:10.460]   We should all just get a room and just have one big huge orgy
[01:52:10.460 --> 01:52:12.300]   because they're all just useless. It's like this like
[01:52:12.300 --> 01:52:14.540]   sexual tension that they just need to release somehow.
[01:52:14.540 --> 01:52:17.020]   What? You're a B.
[01:52:17.020 --> 01:52:17.380]   B.
[01:52:17.380 --> 01:52:18.540]   What? You're a B.
[01:52:18.540 --> 01:52:19.340]   You're a B.
[01:52:19.340 --> 01:52:19.780]   B.
[01:52:19.780 --> 01:52:20.260]   What?
[01:52:20.260 --> 01:52:22.100]   We need to get merch.
[01:52:22.100 --> 01:52:22.940]   Besties are back.
[01:52:22.940 --> 01:52:24.220]   I'm going all in.
[01:52:30.460 --> 01:52:32.460]   I'm going all in
[01:52:32.460 --> 01:52:34.460]   You

