
[00:00:00.000 --> 00:00:04.800]   After a 10 month wait, OpenAI have released Sora to paying users.
[00:00:04.800 --> 00:00:10.300]   With just a prompt, it can generate videos of up to 20 seconds in lower resolutions and
[00:00:10.300 --> 00:00:15.800]   10 seconds at 1080p if you can fork out $200 a month.
[00:00:15.800 --> 00:00:18.220]   I've tested it and read the system card.
[00:00:18.220 --> 00:00:23.640]   The user interface is really quite beautiful, even if the videos themselves operate under
[00:00:23.640 --> 00:00:25.640]   entirely new rules of physics.
[00:00:25.640 --> 00:00:33.740]   But I just can't help wondering if OpenAI want us to focus on releases like Sora rather
[00:00:33.740 --> 00:00:36.400]   than some quietly broken promises.
[00:00:36.400 --> 00:00:42.200]   First things first, Sora is available in almost every country aside from those of the EU and
[00:00:42.200 --> 00:00:43.200]   the UK.
[00:00:43.200 --> 00:00:46.960]   And for those of you who've noticed my accent, you might be wondering how am I using it and
[00:00:46.960 --> 00:00:47.960]   I'm using a VPN.
[00:00:47.960 --> 00:00:52.240]   No, don't worry, I'm not going to do an awkward segue to a VPN sponsorship.
[00:00:52.240 --> 00:00:57.120]   As mentioned at the start, you do need to be a paying user of ChachiBT to get Sora and
[00:00:57.120 --> 00:01:02.280]   the standard $20 tier only gets 1000 credits and the meaning of that we'll see in just
[00:01:02.280 --> 00:01:03.280]   a second.
[00:01:03.280 --> 00:01:09.760]   ChachiBT+ is also capped at 720p resolution, not 1080 and just 5 seconds of duration.
[00:01:09.760 --> 00:01:16.240]   Pro at $200 a month gets you 10,000 credits, but you also get to download without the watermark.
[00:01:16.240 --> 00:01:21.960]   Now you can see how quickly you would use up those 1000 credits from the $20 tier.
[00:01:21.960 --> 00:01:25.560]   Look, 720p, 5 seconds, that's 60 credits.
[00:01:25.560 --> 00:01:30.600]   Dare I say it, even on the $200 tier, you can eat through your credits quite quickly.
[00:01:30.600 --> 00:01:34.840]   In fact, just prepping for this video, I've probably used up like 80% of my allowance.
[00:01:34.840 --> 00:01:37.480]   The allowances, by the way, don't roll over to the next month.
[00:01:37.480 --> 00:01:42.260]   By now, I'm sure that almost everyone watching this video has seen at least a dozen other
[00:01:42.260 --> 00:01:45.200]   videos from other creators, so I'm going to keep this one short.
[00:01:45.200 --> 00:01:51.160]   The first is just a standard generation and it has remembered to pick out the shard, but
[00:01:51.160 --> 00:01:54.600]   I wouldn't say this shadow is being cast over the shard.
[00:01:54.600 --> 00:01:59.440]   Next for the budding content creators out there, how about a futuristic YouTube intro?
[00:01:59.440 --> 00:02:02.640]   I'm not going to use it for the channel, but I think that's pretty cool.
[00:02:02.640 --> 00:02:04.720]   How about the storyboard feature?
[00:02:04.720 --> 00:02:07.720]   And honestly, I think the user interface is pretty amazing.
[00:02:07.720 --> 00:02:10.440]   It's very Apple-like, very sleek and clean.
[00:02:10.440 --> 00:02:15.080]   But of course, the central problem with all Sora generations, indeed, all of generative
[00:02:15.080 --> 00:02:19.440]   AI, including ChachiBT, is that it doesn't really follow physics.
[00:02:19.440 --> 00:02:20.520]   It hallucinates.
[00:02:20.520 --> 00:02:25.360]   So I prompted Sora with an image I featured in a previous video and then had the ending
[00:02:25.360 --> 00:02:28.280]   be that the sign falls off the turtle.
[00:02:28.280 --> 00:02:30.600]   The turtle doesn't notice and walks off screen.
[00:02:30.600 --> 00:02:33.800]   The sign, by the way, is supposed to stay on the ground.
[00:02:33.800 --> 00:02:35.480]   Here was the resulting video.
[00:02:35.480 --> 00:02:41.400]   Now when you're watching this video, remember that if you buy the $200 tier just for Sora,
[00:02:41.400 --> 00:02:45.480]   this video alone used up more than 5% of your allowance.
[00:02:45.480 --> 00:02:49.040]   Translated, it costs you, or in this case me, $10.
[00:02:49.040 --> 00:02:53.480]   For those listening to the podcast version of this video, the sign definitively does
[00:02:53.480 --> 00:02:55.360]   not fall off the turtle.
[00:02:55.360 --> 00:03:00.120]   The next topic that I just have to get to if any of you are considering getting Sora
[00:03:00.120 --> 00:03:01.880]   is the refusals.
[00:03:01.880 --> 00:03:07.280]   Any prompt mentioning something proprietary, in this case an Arsenal shirt, just gets blocked.
[00:03:07.280 --> 00:03:11.880]   In this case, as with the VPN, there is one way of slightly getting around that.
[00:03:11.880 --> 00:03:16.640]   What you can do is generate the relevant image in a different image generator, something
[00:03:16.640 --> 00:03:18.760]   like Ideagram or Midjourney.
[00:03:18.760 --> 00:03:24.600]   Then you feed it in as an image prompt and, lo and behold, Sora will generate the video
[00:03:24.600 --> 00:03:26.200]   based on that image.
[00:03:26.200 --> 00:03:30.800]   Notice again, though, that this hedgehog is supposed to be scoring a goal rather than
[00:03:30.800 --> 00:03:32.480]   just staring at the potato.
[00:03:32.480 --> 00:03:35.560]   Also, did you notice that massive mangling at the beginning?
[00:03:35.560 --> 00:03:36.560]   God knows what that is.
[00:03:36.560 --> 00:03:38.920]   Oh yeah, and the potato levitates.
[00:03:38.920 --> 00:03:43.240]   So far in my use of image prompts, it has been pretty hit or miss.
[00:03:43.240 --> 00:03:48.640]   I tried to make the image logo for my AI Insiders on Patreon pop out.
[00:03:48.640 --> 00:03:53.680]   So I fed in the image and the prompt as part of a storyboard.
[00:03:53.680 --> 00:03:58.080]   And the prompt was the robot, and this is around four seconds in, it should kick in.
[00:03:58.080 --> 00:04:02.640]   The robot holding the AI Insiders book, looks at the book, then brings it closer to the
[00:04:02.640 --> 00:04:03.640]   screen.
[00:04:03.640 --> 00:04:07.560]   You can move those prompts earlier or later in the timeline to adjust when they kick in.
[00:04:07.560 --> 00:04:12.480]   The only problem is, as you can see, the robot instantly transforms into a different robot,
[00:04:12.480 --> 00:04:14.280]   albeit holding the right book.
[00:04:14.280 --> 00:04:18.420]   So that's really cool, but not quite what I was intending.
[00:04:18.420 --> 00:04:23.720]   Big plug for my $9 a month Patreon, where I release videos like this one on the media's
[00:04:23.720 --> 00:04:26.360]   misreporting over O1's quote escape.
[00:04:26.360 --> 00:04:31.360]   My favorite creation had to be this one, a hedgehog showing off its vegetables.
[00:04:31.360 --> 00:04:37.480]   I did prompt it with an image, but I think the resulting 1080p video is crisp and clear.
[00:04:37.480 --> 00:04:42.680]   You might know that your prompt can be a video, not just an image or some text.
[00:04:42.680 --> 00:04:47.920]   And so I got Sora to extend this scene both backwards in time and forwards in time.
[00:04:47.920 --> 00:04:52.580]   For Kling AI, I used the motion brush tool to get the turtle to move, but Sora quite
[00:04:52.580 --> 00:04:54.920]   literally took the turtle in a different direction.
[00:04:54.920 --> 00:04:59.440]   Obviously, I'm not the best text-to-video prompter, but you can see some hand-selected
[00:04:59.440 --> 00:05:03.320]   videos in the featured section on the product page.
[00:05:03.320 --> 00:05:05.060]   Some of these are pretty incredible.
[00:05:05.060 --> 00:05:11.480]   This is 1950's Suburban Bliss, generated just 40 minutes ago, 1080p of course.
[00:05:11.480 --> 00:05:16.880]   This is a drone shot of a container ship on docks, loading containers.
[00:05:16.880 --> 00:05:17.880]   Not bad at all.
[00:05:17.880 --> 00:05:22.800]   If you were just looking for a bit of cuteness in a quick short video at say 720p, there
[00:05:22.800 --> 00:05:26.200]   are competitors though, like Runway and Pika.
[00:05:26.200 --> 00:05:31.880]   But yes, overall, Sora is the best and especially at higher resolutions, I wouldn't say it's
[00:05:31.880 --> 00:05:32.880]   that close.
[00:05:32.880 --> 00:05:36.960]   Just don't bank on it being reliable as Sam Altman found out tonight when they were
[00:05:36.960 --> 00:05:38.400]   doing the live demo.
[00:05:38.400 --> 00:05:41.800]   In neither of the videos did the crane catch a fish.
[00:05:41.800 --> 00:05:46.340]   Then there are rivals like Google DeepMind who've produced Veo, their most capable
[00:05:46.340 --> 00:05:47.800]   generative video model.
[00:05:47.800 --> 00:05:53.320]   The only problem is, it's not accessible to anyone hardly, and definitely not me.
[00:05:53.320 --> 00:05:57.020]   So that, if you will, is my initial review of Sora.
[00:05:57.020 --> 00:06:02.720]   The best currently available, although very pricey with a limited amount of generations
[00:06:02.720 --> 00:06:05.520]   and hardly any adherence to physics.
[00:06:05.520 --> 00:06:09.760]   The system card, by the way, even though I read it in full, doesn't tell us that much,
[00:06:09.760 --> 00:06:11.920]   so I've just picked out five highlights.
[00:06:11.920 --> 00:06:16.140]   After covering these highlights, I'll touch on why I think there is an element of distraction
[00:06:16.140 --> 00:06:17.140]   in play.
[00:06:17.140 --> 00:06:22.160]   First is the team keeps repeating "we made Sora to understand and simulate the real world",
[00:06:22.160 --> 00:06:26.240]   a capability we believe will be an important milestone for achieving AGI.
[00:06:26.240 --> 00:06:28.480]   Here's my cynical theory on that.
[00:06:28.480 --> 00:06:34.720]   OpenAI was funded by people like Elon Musk as a non-profit to create AGI that benefits
[00:06:34.720 --> 00:06:35.720]   humanity.
[00:06:35.720 --> 00:06:41.920]   It is really quite hard to link the creation of an entertaining video generator to creating
[00:06:41.920 --> 00:06:42.920]   AGI.
[00:06:42.920 --> 00:06:47.580]   It's great for signing up new subscriptions, and indeed new signups are currently blocked
[00:06:47.580 --> 00:06:49.000]   because it's so popular.
[00:06:49.000 --> 00:06:53.520]   And great, of course, for building a ton of revenue, but really quite hard to link to
[00:06:53.520 --> 00:06:54.520]   the creation of AGI.
[00:06:54.520 --> 00:07:00.280]   Call me cynical, but Sora is miles away from understanding the real world, if it ever could,
[00:07:00.280 --> 00:07:03.880]   and certainly further than a model like O1 in ChatGPT.
[00:07:03.880 --> 00:07:06.640]   Just seems like a justification for why they're doing Sora.
[00:07:06.640 --> 00:07:11.400]   For all the lawyers watching, they again don't go into where they get the data from, I covered
[00:07:11.400 --> 00:07:13.120]   this back in February of this year.
[00:07:13.120 --> 00:07:18.320]   They just say "mostly collected from industry standard machine learning datasets".
[00:07:18.320 --> 00:07:23.400]   They are very well aware that they are a big target for lawsuits, which is why they're
[00:07:23.400 --> 00:07:25.300]   not going to be any more specific.
[00:07:25.300 --> 00:07:30.260]   One interesting bit of technical detail is that they customise their own GPT to achieve
[00:07:30.260 --> 00:07:33.520]   high precision on the moderation for certain topics.
[00:07:33.520 --> 00:07:37.880]   And the reason that they could afford that latency is because we're all waiting anyway
[00:07:37.880 --> 00:07:43.400]   for the video generation, so they use that window of time to run this precision targeted
[00:07:43.400 --> 00:07:44.400]   GPT.
[00:07:44.400 --> 00:07:49.720]   What that model can do, by the way, is identify third party content as well as deceptive content.
[00:07:49.720 --> 00:07:54.600]   I tried clipping out a section of Lord of the Rings and feeding it in as a video prompt
[00:07:54.600 --> 00:07:56.000]   and it was flagged immediately.
[00:07:56.000 --> 00:08:01.880]   Next, in case you were wondering or intending to do this, you can't actually ask for a video
[00:08:01.880 --> 00:08:04.720]   generation in the style of a living artist.
[00:08:04.720 --> 00:08:09.080]   They thought about allowing this, but then opted for the conservative approach.
[00:08:09.080 --> 00:08:14.500]   Also, you can't use as an image prompt, a photo or video of a real person.
[00:08:14.500 --> 00:08:19.040]   They say given the potential for abuse, we are not initially making that capability available
[00:08:19.040 --> 00:08:20.040]   to all users.
[00:08:20.040 --> 00:08:25.080]   I know that's not many highlights from a long report, but that is as much as I got.
[00:08:25.080 --> 00:08:29.040]   And I think you've got to admit that that was at least a fairly decent segue to this
[00:08:29.040 --> 00:08:31.500]   video sponsors 80,000 hours.
[00:08:31.500 --> 00:08:36.260]   One of their recent podcasts from the 27th of November was covering what one critic calls
[00:08:36.260 --> 00:08:38.540]   OpenAI's theft of the millennium.
[00:08:38.540 --> 00:08:43.020]   As you can see, they are super highly rated, but they also cover other topics too.
[00:08:43.020 --> 00:08:47.800]   I'm also subscribed to their YouTube channel and tend to listen when I'm doing long drives
[00:08:47.800 --> 00:08:48.980]   or long walks.
[00:08:48.980 --> 00:08:53.340]   They also produce a career guide, so do check them out with the links in the description.
[00:08:53.340 --> 00:08:57.140]   Just as I end though, what's that distraction element that I mentioned at the beginning?
[00:08:57.140 --> 00:09:00.140]   For some of you, this will be the most important part of the video.
[00:09:00.140 --> 00:09:05.940]   Well, we have all of these so-called 12 days of shipmas, OpenAI releasing product after
[00:09:05.940 --> 00:09:07.940]   product, one after another.
[00:09:07.940 --> 00:09:12.660]   And all of us are starting to think about Christmas and breaks to come, so that would
[00:09:12.660 --> 00:09:14.860]   be a good time to bury bad news.
[00:09:14.860 --> 00:09:18.940]   Just one example would be a coincidence, but three, let me know what you think.
[00:09:18.940 --> 00:09:23.300]   First, on December 2nd, OpenAI opened the door to doing ads.
[00:09:23.300 --> 00:09:25.820]   That doesn't sound like too big of a deal though, right?
[00:09:25.820 --> 00:09:28.220]   Their CFO just said that they're looking into ads.
[00:09:28.220 --> 00:09:33.540]   But remember, Sam Altman has said in the past, "I think that ads plus AI is sort of uniquely
[00:09:33.540 --> 00:09:34.980]   unsettling to me."
[00:09:34.980 --> 00:09:37.820]   On Lex Friedman, he also called them a last resort.
[00:09:37.820 --> 00:09:42.180]   That's just the warm-up though, because on December 6th, in the Financial Times, we
[00:09:42.180 --> 00:09:43.180]   got this.
[00:09:43.180 --> 00:09:47.500]   This story for me, if it turns out to be true, is far more, quote, "unsettling".
[00:09:47.500 --> 00:09:52.420]   OpenAI have promised that when they reach AGI, their commercial contract with Microsoft
[00:09:52.420 --> 00:09:53.500]   would be void.
[00:09:53.500 --> 00:09:57.780]   All the profits thereafter would go to their non-profit to distribute to everyone.
[00:09:57.780 --> 00:10:02.780]   That was key because as Sam Altman himself has said, AGI would break capitalism.
[00:10:02.780 --> 00:10:07.380]   It's even in their very definition of AGI that it can do half of the world's jobs.
[00:10:07.380 --> 00:10:11.460]   They made this commitment repeatedly, I've covered it many times before on the channel
[00:10:11.460 --> 00:10:13.340]   and it's in their bloody charter.
[00:10:13.340 --> 00:10:17.740]   Well apparently, they are now discussing removing that provision.
[00:10:17.740 --> 00:10:23.540]   AGI, according to this article, might well be misused then for commercial purposes.
[00:10:23.540 --> 00:10:28.740]   Just for a moment, I want you to picture Microsoft having a monopoly over AGI.
[00:10:28.740 --> 00:10:33.180]   You might not believe they would do so, and you might not even believe AGI is coming,
[00:10:33.180 --> 00:10:36.300]   but just imagine if those two things happen.
[00:10:36.300 --> 00:10:40.700]   Why are they trying to ditch this provision that shuts Microsoft out of its most advanced
[00:10:40.700 --> 00:10:41.700]   models?
[00:10:41.700 --> 00:10:44.020]   A provision they've promised repeatedly to uphold?
[00:10:44.020 --> 00:10:48.140]   Well, they are seeking to unlock billions of dollars of future investment.
[00:10:48.140 --> 00:10:52.700]   Just in case you think it's me making up all of these clauses, the FT directly quotes
[00:10:52.700 --> 00:10:54.220]   them many times.
[00:10:54.220 --> 00:10:58.980]   According to OpenAI's own website, AGI is explicitly carved out of all commercial and
[00:10:58.980 --> 00:11:01.100]   IP licensing agreements.
[00:11:01.100 --> 00:11:03.020]   But there's a problem with that, dear viewer.
[00:11:03.020 --> 00:11:07.240]   That would limit the potential profit and value for Microsoft.
[00:11:07.240 --> 00:11:11.120]   After all, they've pumped in $13 billion into OpenAI.
[00:11:11.120 --> 00:11:15.420]   This would disincentivise the big tech group from further investment.
[00:11:15.420 --> 00:11:16.420]   Oh no.
[00:11:16.420 --> 00:11:20.420]   By the way, this isn't just rumour, this is according to multiple people familiar with
[00:11:20.420 --> 00:11:21.420]   the conversations.
[00:11:21.420 --> 00:11:25.960]   Altman said, apparently, "We've left ourselves some flexibility because we don't know what
[00:11:25.960 --> 00:11:26.960]   will happen."
[00:11:26.960 --> 00:11:30.280]   Again though, the FT quotes from OpenAI's own history.
[00:11:30.280 --> 00:11:35.220]   They told anyone investing in them to consider their investments in the spirit of a donation,
[00:11:35.220 --> 00:11:38.720]   with the understanding, as I've quoted before on this channel, that it may be difficult
[00:11:38.720 --> 00:11:42.180]   to know what role money will play in a post-AGI world.
[00:11:42.180 --> 00:11:46.340]   All that seems out of the window though, and there's only one thing they're promising.
[00:11:46.340 --> 00:11:51.780]   OpenAI's non-profit, which does still exist, they say, will continue to exist and thrive
[00:11:51.780 --> 00:11:54.720]   and receive full value for its current stake.
[00:11:54.720 --> 00:11:58.820]   We don't know the exact figure, but I think their current stake is in the region of 30%
[00:11:58.820 --> 00:12:00.740]   of the current value of OpenAI.
[00:12:00.740 --> 00:12:06.140]   In other words, that non-profit will be bunged $50, maybe $80 billion, and receive quote
[00:12:06.140 --> 00:12:07.140]   full value.
[00:12:07.140 --> 00:12:11.780]   Yes, that will surely give it an enhanced ability to pursue its mission, but that's
[00:12:11.780 --> 00:12:15.300]   not the same as Microsoft not owning AGI.
[00:12:15.300 --> 00:12:19.440]   That's the same Microsoft, by the way, that was reported just today in the information
[00:12:19.440 --> 00:12:23.620]   was boasting about how much labor costs you could save if you adopt AI.
[00:12:23.620 --> 00:12:28.740]   They're being explicit about making sales for their co-pilot service based on showing
[00:12:28.740 --> 00:12:33.540]   the example to their customers of how they laid off 10,000 people last year.
[00:12:33.540 --> 00:12:36.180]   That's according to three current sales employees.
[00:12:36.180 --> 00:12:41.560]   We've been able to improve our throughput per customer service agent by 12% using co-pilot.
[00:12:41.560 --> 00:12:42.560]   That's real money.
[00:12:42.560 --> 00:12:47.400]   That means we don't have to hire as many people, Microsoft's Spatero said.
[00:12:47.400 --> 00:12:50.440]   Is that the kind of company that you want controlling AGI?
[00:12:50.440 --> 00:12:55.200]   Oh, and by the way, I haven't even got to the third thing that OpenAI are potentially
[00:12:55.200 --> 00:12:56.820]   trying to distract us from.
[00:12:56.820 --> 00:13:03.360]   They have pivoted to work inside the military-industrial complex, albeit with some small caveats.
[00:13:03.360 --> 00:13:08.720]   As MIT reports at the start of this year, OpenAI's rules for how armed forces might
[00:13:08.720 --> 00:13:11.520]   use its technology were unambiguous.
[00:13:11.520 --> 00:13:16.360]   No one could use their models for weapons development or military or warfare.
[00:13:16.360 --> 00:13:21.960]   Then that changed in January to "don't use our technology to harm yourself or others"
[00:13:21.960 --> 00:13:25.520]   by "developing or using weapons" or "destroying property".
[00:13:25.520 --> 00:13:28.400]   That "destroying property" went out of the window quite quickly.
[00:13:28.400 --> 00:13:32.960]   In October, they changed the terms to "you can only use it to protect people and deter
[00:13:32.960 --> 00:13:33.960]   adversaries".
[00:13:33.960 --> 00:13:38.640]   Now, though, their technology will be deployed directly on the battlefield.
[00:13:38.640 --> 00:13:42.560]   To help, apparently, the US and allied forces defend against drone attacks.
[00:13:42.560 --> 00:13:46.500]   Now, you can argue the rights and wrongs of this, but you've got to admit it's a shift
[00:13:46.500 --> 00:13:47.500]   in policy.
[00:13:47.500 --> 00:13:51.400]   As one analyst said, "Defensive weapons are indeed still weapons.
[00:13:51.400 --> 00:13:56.680]   They can often be positioned offensively, subject to the locale and aim of a mission."
[00:13:56.680 --> 00:14:02.080]   OpenAI, MIT says, has long pontificated about how to steward AI responsibly, and they will
[00:14:02.080 --> 00:14:07.200]   now work in a defence tech industry that plays by an entirely different set of rules.
[00:14:07.200 --> 00:14:11.160]   In that system, when your customer is the US military, tech companies do not get to
[00:14:11.160 --> 00:14:13.000]   decide how their products are used.
[00:14:13.000 --> 00:14:17.200]   And according to the Washington Post, even their own employees are pushing back on the
[00:14:17.200 --> 00:14:21.880]   deal and asking for more transparency from leaders, wherever we heard that before.
[00:14:21.880 --> 00:14:28.160]   Those OpenAI employees apparently want assurances that their technology won't be directed against
[00:14:28.160 --> 00:14:30.080]   human piloted aircraft.
[00:14:30.080 --> 00:14:31.320]   It's a great point, right?
[00:14:31.320 --> 00:14:36.020]   Because a defensive weapon could still be used against humans if those humans are piloting
[00:14:36.020 --> 00:14:37.440]   offensive aircraft.
[00:14:37.440 --> 00:14:42.520]   One other OpenAI employee said that "Defensive use cases still represented militarization
[00:14:42.520 --> 00:14:48.200]   of AI" and noted that the fictional AI system Skynet, which turns on humanity in the Terminator
[00:14:48.200 --> 00:14:53.080]   movies, was also originally designed to defend against aerial attacks on North America.
[00:14:53.080 --> 00:14:55.840]   OpenAI executives quickly acknowledged the concerns.
[00:14:55.840 --> 00:14:59.960]   It should immediately be pointed out that they are not the only ones with people like
[00:14:59.960 --> 00:15:04.440]   Anthropic and Meta changing their policies to allow military use of their technology.
[00:15:04.440 --> 00:15:09.460]   If you were looking for a purely positive review of Sora, I'm sorry to have disappointed
[00:15:09.460 --> 00:15:10.460]   you.
[00:15:10.460 --> 00:15:16.100]   The videos can be amazing if you ignore the physics and the user interface is exemplary.
[00:15:16.100 --> 00:15:19.580]   But it's quite pricey for the number of credits you get.
[00:15:19.580 --> 00:15:26.140]   And I just wonder if these 12 days of releases might be distracting us a little bit from
[00:15:26.140 --> 00:15:28.100]   other news about OpenAI.
[00:15:28.100 --> 00:15:30.340]   As always though, let me know what you think.
[00:15:30.340 --> 00:15:34.380]   Thank you so much for watching to the end, and have a wonderful day.

