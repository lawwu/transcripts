
[00:00:00.000 --> 00:00:03.240]   The following is a conversation with Yaron Brook,
[00:00:03.240 --> 00:00:05.640]   one of the best known objectivist philosophers
[00:00:05.640 --> 00:00:07.200]   and thinkers in the world.
[00:00:07.200 --> 00:00:09.520]   Objectivism is the philosophical system
[00:00:09.520 --> 00:00:12.920]   developed by Ayn Rand that she first expressed
[00:00:12.920 --> 00:00:16.720]   in her fiction books, "The Fountainhead" and "Atlas Shrugged"
[00:00:16.720 --> 00:00:19.840]   and later in nonfiction essays and books.
[00:00:19.840 --> 00:00:22.880]   Yaron is the current chairman of the board
[00:00:22.880 --> 00:00:24.560]   at the Ayn Rand Institute,
[00:00:24.560 --> 00:00:26.800]   host of the "Yaron Brook Show"
[00:00:26.800 --> 00:00:30.000]   and the co-author of "Free Market Revolution",
[00:00:30.000 --> 00:00:33.360]   "Equal is Unfair" and several other books
[00:00:33.360 --> 00:00:36.080]   where he analyzes systems of government,
[00:00:36.080 --> 00:00:38.960]   human behavior and the human condition
[00:00:38.960 --> 00:00:41.800]   from the perspective of objectivism.
[00:00:41.800 --> 00:00:43.360]   Quick mention of each sponsor,
[00:00:43.360 --> 00:00:46.280]   followed by some thoughts related to the episode.
[00:00:46.280 --> 00:00:49.120]   Blinkist, an app I use for reading
[00:00:49.120 --> 00:00:51.080]   through summaries of books.
[00:00:51.080 --> 00:00:54.640]   ExpressVPN, the VPN I've used for many years
[00:00:54.640 --> 00:00:57.240]   to protect my privacy on the internet
[00:00:57.240 --> 00:01:01.440]   and Cash App, the app I use to send money to friends.
[00:01:01.440 --> 00:01:03.640]   Please check out these sponsors in the description
[00:01:03.640 --> 00:01:07.320]   to get a discount and to support this podcast.
[00:01:07.320 --> 00:01:09.760]   As a side note, let me say that I first read
[00:01:09.760 --> 00:01:13.480]   "Atlas Shrugged" and "The Fountainhead" early in college,
[00:01:13.480 --> 00:01:16.960]   along with many other literary and philosophical works
[00:01:16.960 --> 00:01:21.320]   from Nietzsche, Heidegger, Kant, Locke, Foucault,
[00:01:21.320 --> 00:01:25.160]   Wittgenstein and of course, all the great existentialists
[00:01:25.160 --> 00:01:27.680]   from Kierkegaard to Camus.
[00:01:27.680 --> 00:01:30.200]   I always had an open mind, curious to learn
[00:01:30.200 --> 00:01:33.120]   and explore the ideas of thinkers throughout history,
[00:01:33.120 --> 00:01:36.760]   no matter how mundane or radical
[00:01:36.760 --> 00:01:39.560]   or even dangerous they were considered to be.
[00:01:39.560 --> 00:01:44.520]   Ayn Rand was, and I think still is a divisive figure.
[00:01:44.520 --> 00:01:46.960]   Some people love her, some people dislike
[00:01:46.960 --> 00:01:49.240]   or even dismiss her.
[00:01:49.240 --> 00:01:51.480]   I prefer to look past what some may consider
[00:01:51.480 --> 00:01:53.800]   to be the flaws of the person
[00:01:53.800 --> 00:01:57.920]   and consider with an open mind, the ideas she presents
[00:01:57.920 --> 00:02:00.800]   and Yaron now describes and applies
[00:02:00.800 --> 00:02:03.000]   in his philosophical discussions.
[00:02:03.000 --> 00:02:05.440]   In general, I hope that you will be patient
[00:02:05.440 --> 00:02:08.840]   and understanding as I venture out across the space
[00:02:08.840 --> 00:02:12.800]   of ideas and the ever widening Overton window,
[00:02:12.800 --> 00:02:15.120]   pulling at the thread of curiosity,
[00:02:15.120 --> 00:02:17.160]   sometimes saying stupid things,
[00:02:17.160 --> 00:02:19.280]   but always striving to understand
[00:02:19.280 --> 00:02:23.340]   how we can better build a better world together.
[00:02:23.340 --> 00:02:25.760]   If you enjoy this thing, subscribe on YouTube,
[00:02:25.760 --> 00:02:28.000]   review it with Five Stars on Apple Podcast,
[00:02:28.000 --> 00:02:30.680]   follow on Spotify, support on Patreon
[00:02:30.680 --> 00:02:34.440]   or connect with me on Twitter @LexFriedman.
[00:02:34.440 --> 00:02:38.320]   And now here's my conversation with Yaron Rook.
[00:02:38.320 --> 00:02:42.640]   Let me ask the biggest possible question first.
[00:02:42.640 --> 00:02:43.480]   - Sure.
[00:02:43.480 --> 00:02:46.320]   - What are the principles of a life well lived?
[00:02:47.320 --> 00:02:51.960]   - I think it's to live with thought,
[00:02:51.960 --> 00:02:55.960]   that is to live a rational life, to think it through.
[00:02:55.960 --> 00:02:59.600]   I think so many people are in a sense zombies out there.
[00:02:59.600 --> 00:03:01.920]   They're alive, but they're not really alive
[00:03:01.920 --> 00:03:03.960]   'cause their mind is not focused.
[00:03:03.960 --> 00:03:07.960]   Their mind is not focused on what do I need to do
[00:03:07.960 --> 00:03:10.040]   in order to live a great life?
[00:03:10.040 --> 00:03:13.400]   So too many people just go through the motions of living
[00:03:13.400 --> 00:03:16.760]   rather than really embrace life.
[00:03:16.760 --> 00:03:19.760]   So I think the secret to living a great life
[00:03:19.760 --> 00:03:22.720]   is to take it seriously.
[00:03:22.720 --> 00:03:24.460]   And what it means to take it seriously
[00:03:24.460 --> 00:03:27.000]   is to use the one tool that makes us human,
[00:03:27.000 --> 00:03:29.080]   the one tool that provides us with all the values
[00:03:29.080 --> 00:03:31.680]   that we have, our mind, our reason,
[00:03:31.680 --> 00:03:34.880]   and to use it, apply it to living.
[00:03:34.880 --> 00:03:36.780]   People apply it to their work,
[00:03:36.780 --> 00:03:38.880]   they apply it to their math problems,
[00:03:38.880 --> 00:03:41.920]   to science, to programming.
[00:03:41.920 --> 00:03:43.660]   But imagine if they used that same energy,
[00:03:43.660 --> 00:03:45.640]   that same focus, that same concentration
[00:03:45.640 --> 00:03:48.720]   to actually living life and choosing values
[00:03:48.720 --> 00:03:51.080]   that they should pursue.
[00:03:51.080 --> 00:03:54.280]   That would change the world
[00:03:54.280 --> 00:03:56.200]   and it would change their lives.
[00:03:56.200 --> 00:04:00.320]   - Yeah, actually, I wear this silly suit and tie.
[00:04:00.320 --> 00:04:03.120]   It symbolizes to me always, it makes me feel
[00:04:03.120 --> 00:04:06.440]   like I'm taking the moment really seriously.
[00:04:06.440 --> 00:04:08.480]   - I think that's really, that's right.
[00:04:08.480 --> 00:04:10.940]   And each one of us has different ways
[00:04:10.940 --> 00:04:14.440]   to kind of condition our consciousness.
[00:04:14.440 --> 00:04:17.780]   I'm serious now, and for you, it's a suit and tie.
[00:04:17.780 --> 00:04:19.600]   It's a conditioning of your consciousness
[00:04:19.600 --> 00:04:21.560]   to now I'm focused, now I'm at work,
[00:04:21.560 --> 00:04:22.920]   now I'm doing my thing.
[00:04:22.920 --> 00:04:26.040]   And I think that's terrific
[00:04:26.040 --> 00:04:28.020]   and I wish everybody took that.
[00:04:28.020 --> 00:04:32.080]   Look, I mean, it's a cliche, but we only live once.
[00:04:32.080 --> 00:04:34.840]   Every minute of your life, you're never gonna live again.
[00:04:34.840 --> 00:04:36.520]   This is really valuable.
[00:04:36.580 --> 00:04:41.020]   And when people don't have that deep respect
[00:04:41.020 --> 00:04:44.860]   for their own life, for their own time, for their own mind,
[00:04:44.860 --> 00:04:49.140]   and if they did, again, one could only imagine,
[00:04:49.140 --> 00:04:50.900]   look at how productive people are.
[00:04:50.900 --> 00:04:52.620]   Look at the amazing things they produce
[00:04:52.620 --> 00:04:54.540]   and they do in their work.
[00:04:54.540 --> 00:04:58.540]   And if they apply that to everything, wow.
[00:04:58.540 --> 00:05:00.260]   - So you kind of talk about reason.
[00:05:00.260 --> 00:05:05.140]   Where does the kind of existentialist idea
[00:05:05.140 --> 00:05:10.140]   of experience maybe, fully experiencing all the moments
[00:05:10.140 --> 00:05:13.740]   versus fully thinking through?
[00:05:13.740 --> 00:05:17.260]   Is there an interesting line to separate the two?
[00:05:17.260 --> 00:05:21.820]   Like why such an emphasis on reason for a life well-lived
[00:05:21.820 --> 00:05:26.480]   versus just enjoy, like experience?
[00:05:26.480 --> 00:05:28.360]   - Well, because I think experience in a sense
[00:05:28.360 --> 00:05:31.220]   is the easy part.
[00:05:31.460 --> 00:05:36.460]   I'm not saying it's how we experience the life that we live.
[00:05:36.460 --> 00:05:41.980]   And yes, I'm all with the take time to value what you value,
[00:05:41.980 --> 00:05:46.700]   but I don't think that's the problem of people out there.
[00:05:46.700 --> 00:05:48.660]   I don't think the problem is they're not taking time
[00:05:48.660 --> 00:05:51.060]   to appreciate where they are and what they do.
[00:05:51.060 --> 00:05:53.360]   I think it's that they don't use their mind
[00:05:53.360 --> 00:05:57.780]   in this one respect in planning their life,
[00:05:57.780 --> 00:06:00.100]   in thinking about how to live.
[00:06:00.100 --> 00:06:02.380]   So the focus is on reason is because
[00:06:02.380 --> 00:06:03.900]   it's our only source of knowledge.
[00:06:03.900 --> 00:06:05.260]   There's no other source of knowledge.
[00:06:05.260 --> 00:06:10.100]   We don't know anything that does not come
[00:06:10.100 --> 00:06:12.500]   from our senses and our mind,
[00:06:12.500 --> 00:06:15.220]   the integration of the evidence of our senses.
[00:06:15.220 --> 00:06:16.700]   Now we know stuff about ourselves,
[00:06:16.700 --> 00:06:18.300]   and I think it's important to know oneself
[00:06:18.300 --> 00:06:19.740]   through introspection.
[00:06:19.740 --> 00:06:24.740]   And I consider that part of reasoning is to introspect.
[00:06:24.740 --> 00:06:28.380]   But I think reason is undervalued,
[00:06:28.380 --> 00:06:31.340]   which is funny to say because it's our means of survival.
[00:06:31.340 --> 00:06:33.000]   It's how human beings survive.
[00:06:33.000 --> 00:06:35.740]   We cannot, see, this is why I disagree
[00:06:35.740 --> 00:06:38.620]   with so many scientists and people like Sam Harris.
[00:06:38.620 --> 00:06:40.620]   You mentioned Sam Harris before the show.
[00:06:40.620 --> 00:06:46.140]   We're not programmed to know how to hunt.
[00:06:46.140 --> 00:06:49.020]   We're not programmed to do agriculture.
[00:06:49.020 --> 00:06:51.660]   We're not programmed to build computers
[00:06:51.660 --> 00:06:53.860]   and build networks on which we can podcast
[00:06:53.860 --> 00:06:55.320]   and do our shows.
[00:06:55.320 --> 00:06:58.100]   All of that requires effort.
[00:06:58.100 --> 00:06:59.740]   It requires focus.
[00:06:59.740 --> 00:07:03.360]   It requires energy, and it requires will.
[00:07:03.360 --> 00:07:05.940]   It requires somebody to will it.
[00:07:05.940 --> 00:07:08.540]   It requires somebody to choose it.
[00:07:08.540 --> 00:07:11.200]   And once you make that choice,
[00:07:11.200 --> 00:07:13.580]   you have to engage that choice means
[00:07:13.580 --> 00:07:15.940]   that you're choosing to engage your reason
[00:07:15.940 --> 00:07:19.240]   in discovery, in integration,
[00:07:19.240 --> 00:07:23.140]   and then in work to change the world in which we live.
[00:07:23.140 --> 00:07:27.500]   And human beings have to discover, figure out,
[00:07:27.500 --> 00:07:29.140]   solve the problem of hunting.
[00:07:29.140 --> 00:07:31.620]   Hunting, everybody thinks, oh, that's easy.
[00:07:31.620 --> 00:07:32.660]   I've seen the movie.
[00:07:32.660 --> 00:07:36.220]   But human beings had to figure out how to do it.
[00:07:36.220 --> 00:07:40.740]   You can't run down a bison and bite into it.
[00:07:40.740 --> 00:07:41.580]   You're not gonna catch it.
[00:07:41.580 --> 00:07:44.100]   You have no fangs to bite into it.
[00:07:44.100 --> 00:07:45.560]   You have to build weapons.
[00:07:45.560 --> 00:07:46.460]   You have to build tools.
[00:07:46.460 --> 00:07:47.700]   You have to create traps.
[00:07:47.700 --> 00:07:49.520]   You have to have a strategy.
[00:07:49.520 --> 00:07:50.940]   All of that requires reason.
[00:07:50.940 --> 00:07:56.540]   So the most important thing that allows human beings
[00:07:56.540 --> 00:07:58.780]   to survive and to thrive in every value,
[00:07:58.780 --> 00:08:01.420]   from the most simple to the most sophisticated,
[00:08:01.420 --> 00:08:03.140]   from the most material to, I believe,
[00:08:03.140 --> 00:08:06.340]   the most spiritual, requires thinking.
[00:08:06.340 --> 00:08:10.260]   So stopping and appreciating the moment
[00:08:10.260 --> 00:08:14.500]   is something that I think is relatively easy
[00:08:14.500 --> 00:08:17.620]   once you have a plan, once you've thought it through,
[00:08:17.620 --> 00:08:19.660]   once you know what your values are.
[00:08:19.660 --> 00:08:21.940]   There is a mistake people make.
[00:08:21.940 --> 00:08:22.900]   They attain their values,
[00:08:23.620 --> 00:08:26.660]   and they don't take a moment to savor that
[00:08:26.660 --> 00:08:29.060]   and to appreciate that and to even pat themselves
[00:08:29.060 --> 00:08:31.380]   on the back that they did it.
[00:08:31.380 --> 00:08:33.220]   But that's not what's screwing up the world.
[00:08:33.220 --> 00:08:34.340]   What's screwing up the world
[00:08:34.340 --> 00:08:35.780]   is that people have the wrong values,
[00:08:35.780 --> 00:08:37.340]   and they don't think about them,
[00:08:37.340 --> 00:08:39.020]   and they don't really focus on them,
[00:08:39.020 --> 00:08:41.500]   and they don't have a plan for their own life
[00:08:41.500 --> 00:08:42.600]   and how to live it.
[00:08:42.600 --> 00:08:44.300]   - If we look at human nature,
[00:08:44.300 --> 00:08:46.780]   you're saying the fundamental big thing
[00:08:46.780 --> 00:08:49.100]   that we need to consider is our capacity,
[00:08:49.100 --> 00:08:51.620]   like a capability to reason.
[00:08:51.620 --> 00:08:55.220]   - I said to me, reason is this massive
[00:08:55.220 --> 00:08:58.700]   evolutionary achievement, right, in quotes, right?
[00:08:58.700 --> 00:09:03.340]   If you think about any other sophisticated animal,
[00:09:03.340 --> 00:09:04.840]   everything has to be coded.
[00:09:04.840 --> 00:09:08.300]   Everything has to be written in the hard way.
[00:09:08.300 --> 00:09:09.980]   It has to be there.
[00:09:09.980 --> 00:09:12.180]   And they have to have a solution for every outcome,
[00:09:12.180 --> 00:09:14.380]   and if there's no solution, the animal dies, typically,
[00:09:14.380 --> 00:09:16.740]   or the animal suffers in some way.
[00:09:16.740 --> 00:09:19.660]   Human beings have this capacity to self-program.
[00:09:19.660 --> 00:09:21.460]   They have this capacity.
[00:09:21.460 --> 00:09:25.020]   There's not, it's not a tabula rasa
[00:09:25.020 --> 00:09:26.380]   in the sense that there's nothing there.
[00:09:26.380 --> 00:09:27.900]   Obviously, we have a nature.
[00:09:27.900 --> 00:09:30.300]   Obviously, our minds, our brains
[00:09:30.300 --> 00:09:32.300]   are structured in a particular way.
[00:09:32.300 --> 00:09:36.180]   But given that, we have the ability
[00:09:36.180 --> 00:09:38.420]   to turn it on or turn it off.
[00:09:38.420 --> 00:09:40.460]   We have the ability to commit suicide,
[00:09:40.460 --> 00:09:44.740]   to reject our nature, to work against our interests,
[00:09:44.740 --> 00:09:49.500]   not to use the tool that evolution has provided us,
[00:09:49.500 --> 00:09:51.900]   which is this mind, which is reason.
[00:09:51.900 --> 00:09:54.780]   So that choice, that fundamental choice,
[00:09:54.780 --> 00:09:58.460]   Hamlet says it, right, to be or not to be.
[00:09:58.460 --> 00:10:01.900]   But to be or not to be is to think or not to think,
[00:10:01.900 --> 00:10:05.540]   to engage or not to engage, to focus or not to focus.
[00:10:05.540 --> 00:10:09.940]   In the morning when you get up, you're not really
[00:10:09.940 --> 00:10:12.740]   completely there, you're kind of out of focus and stuff.
[00:10:12.740 --> 00:10:14.940]   It requires an act of will to say,
[00:10:14.940 --> 00:10:17.540]   okay, I'm awake, I've got stuff to do.
[00:10:17.540 --> 00:10:19.340]   Some people never do that.
[00:10:19.340 --> 00:10:21.620]   Some people live in that haze.
[00:10:21.620 --> 00:10:23.460]   And they never engage that mind.
[00:10:23.460 --> 00:10:25.860]   And when you're sitting and trying to solve
[00:10:25.860 --> 00:10:29.460]   a complex computer problem or a math problem,
[00:10:29.460 --> 00:10:31.940]   you have to turn something on.
[00:10:31.940 --> 00:10:36.220]   You have to, in a sense, exert certain energy
[00:10:36.220 --> 00:10:38.100]   to focus on the problem, to do it.
[00:10:38.100 --> 00:10:41.180]   And that is not determined in a sense
[00:10:41.180 --> 00:10:43.180]   that you have to focus.
[00:10:43.180 --> 00:10:44.500]   You choose to focus.
[00:10:44.500 --> 00:10:46.260]   And you could choose not to focus.
[00:10:46.260 --> 00:10:47.700]   - And that choice is more powerful
[00:10:47.700 --> 00:10:50.700]   than any other parts of our brain
[00:10:50.700 --> 00:10:52.180]   that we've borrowed from fish
[00:10:52.180 --> 00:10:54.660]   and from our evolutionary origins.
[00:10:54.660 --> 00:10:58.080]   Like this, whatever this crazy little leap in evolution is
[00:10:58.080 --> 00:11:00.700]   that allowed us to think is more powerful than anything else.
[00:11:00.700 --> 00:11:05.180]   - So I think neuroscientists pretend they know
[00:11:05.180 --> 00:11:07.500]   a lot more about the brain than they really do.
[00:11:07.500 --> 00:11:08.340]   - Yeah.
[00:11:08.340 --> 00:11:10.620]   Shots fired.
[00:11:10.620 --> 00:11:12.620]   I agree with you.
[00:11:12.620 --> 00:11:14.820]   - And we don't know that much yet
[00:11:14.820 --> 00:11:16.980]   about how the brain functions and what's a fish
[00:11:16.980 --> 00:11:18.820]   and all this stuff.
[00:11:18.820 --> 00:11:23.240]   So I think what exists there is a lot of potentialities.
[00:11:23.240 --> 00:11:28.780]   But the beauty of the human brain is it's potentialities
[00:11:28.780 --> 00:11:31.880]   that we have to manifest through our choices.
[00:11:31.880 --> 00:11:34.540]   It's there, it's sitting there.
[00:11:34.540 --> 00:11:37.900]   And yes, there's certain things that are gonna evoke
[00:11:37.900 --> 00:11:42.700]   certain senses, certain feelings.
[00:11:42.700 --> 00:11:43.860]   I'm not even saying emotions
[00:11:43.860 --> 00:11:45.400]   'cause I think emotions are too complex
[00:11:45.400 --> 00:11:48.100]   to have been programmed into our mind.
[00:11:48.100 --> 00:11:49.980]   But I don't think so.
[00:11:49.980 --> 00:11:52.100]   There's this big issue of evolutionary psychology
[00:11:52.100 --> 00:11:54.620]   is huge right now and it's a big issue.
[00:11:54.620 --> 00:12:01.100]   I find it to a large extent as way too early
[00:12:01.100 --> 00:12:07.820]   and storytelling about ex-post storytelling about stuff.
[00:12:07.820 --> 00:12:10.460]   We still don't, so for example,
[00:12:10.460 --> 00:12:12.340]   I would like to see evolutionary psychology
[00:12:12.340 --> 00:12:17.080]   differentiate between things like inclinations,
[00:12:17.080 --> 00:12:22.080]   feelings, emotions, sensations, thoughts, concepts, ideas.
[00:12:22.080 --> 00:12:26.340]   What of those, the programmed and what of those
[00:12:26.340 --> 00:12:29.560]   are developed and chosen and a product of reason?
[00:12:29.560 --> 00:12:32.920]   I think anything from emotion to abstract ideas
[00:12:32.920 --> 00:12:36.800]   is all chosen, is all a product of reason.
[00:12:36.800 --> 00:12:41.800]   And everything before that, we might've been programmed for.
[00:12:42.460 --> 00:12:45.060]   But the fact is, so clearly a sensation
[00:12:45.060 --> 00:12:48.740]   is not a product of, is something that we feel
[00:12:48.740 --> 00:12:50.740]   because that's how our biology works.
[00:12:50.740 --> 00:12:54.260]   So until we have these categories
[00:12:54.260 --> 00:12:58.740]   and until we can clearly specify what is what
[00:12:58.740 --> 00:13:01.340]   and where did they come from,
[00:13:01.340 --> 00:13:03.260]   the whole discussion in evolutionary psychology
[00:13:03.260 --> 00:13:04.340]   seems to be rambling.
[00:13:04.340 --> 00:13:06.420]   It doesn't seem to be scientific.
[00:13:06.420 --> 00:13:08.900]   So we have to define our terms,
[00:13:08.900 --> 00:13:10.020]   which is the basis of science.
[00:13:10.020 --> 00:13:12.140]   You have to have some clear definitions
[00:13:12.140 --> 00:13:13.740]   about what we're talking about.
[00:13:13.740 --> 00:13:16.380]   When you ask them these questions,
[00:13:16.380 --> 00:13:18.540]   there's never really a coherent answer
[00:13:18.540 --> 00:13:20.460]   about what is it exactly.
[00:13:20.460 --> 00:13:22.800]   And everybody is afraid of the issue of free will.
[00:13:22.800 --> 00:13:25.000]   And I think to some extent, I mean,
[00:13:25.000 --> 00:13:28.300]   Harris has this, and I don't wanna misrepresent anything
[00:13:28.300 --> 00:13:32.000]   Harris has 'cause I'm a fan and I like a lot of his stuff.
[00:13:32.000 --> 00:13:37.180]   But on the one hand, he is obviously intellectually active
[00:13:37.180 --> 00:13:38.740]   and wants to change our minds.
[00:13:38.740 --> 00:13:41.900]   So he believes that we have some capacity to choose.
[00:13:41.900 --> 00:13:44.780]   On the other hand, he's undermining that capacity to choose
[00:13:44.780 --> 00:13:45.820]   by saying it's just determinants.
[00:13:45.820 --> 00:13:47.380]   You're gonna choose what you choose.
[00:13:47.380 --> 00:13:48.740]   You have no say in it.
[00:13:48.740 --> 00:13:50.260]   There's actually no you.
[00:13:50.260 --> 00:13:55.900]   So it's, and that's to me completely unscientific.
[00:13:55.900 --> 00:14:00.460]   That's completely him pulling it out of nowhere.
[00:14:00.460 --> 00:14:03.660]   We all experience the fact that we have an eye.
[00:14:03.660 --> 00:14:05.340]   - That kind of certainty saying
[00:14:05.340 --> 00:14:07.820]   that we do not have that fundamental choice
[00:14:07.820 --> 00:14:12.020]   that reason provides is unfounded currently.
[00:14:12.020 --> 00:14:13.260]   - Look, there's a sense in which
[00:14:13.260 --> 00:14:15.860]   it can never be contradicted
[00:14:15.860 --> 00:14:20.860]   because it's a product of your experience.
[00:14:20.860 --> 00:14:21.940]   It's not a product of your experience.
[00:14:21.940 --> 00:14:24.140]   You can experience it directly.
[00:14:24.140 --> 00:14:28.260]   So no science will ever prove that this table isn't here.
[00:14:28.260 --> 00:14:31.140]   I can see it, it's here, right?
[00:14:31.140 --> 00:14:32.220]   I can feel it.
[00:14:32.220 --> 00:14:36.400]   I know I have free will 'cause I can introspect it.
[00:14:36.400 --> 00:14:37.980]   In a sense, I can see it.
[00:14:37.980 --> 00:14:41.120]   I can see myself engaging it.
[00:14:41.120 --> 00:14:47.400]   And that is as valid as the evidence of my senses.
[00:14:47.400 --> 00:14:49.020]   Now I can't point at it
[00:14:49.020 --> 00:14:51.420]   so that you can see the same thing I'm seeing,
[00:14:51.420 --> 00:14:53.580]   but you can do the same thing in your own consciousness
[00:14:53.580 --> 00:14:55.220]   and you can identify the same thing.
[00:14:55.220 --> 00:14:59.220]   And to deny that in the name of science
[00:14:59.220 --> 00:15:00.620]   is to get things upside down.
[00:15:00.620 --> 00:15:04.780]   You start with that and that's the beginning of science.
[00:15:04.780 --> 00:15:07.320]   And the beginning of science is the identification
[00:15:07.320 --> 00:15:10.720]   that I choose and that I can reason.
[00:15:10.720 --> 00:15:13.320]   And now I need to figure out the mechanism,
[00:15:13.320 --> 00:15:16.720]   the rules of reasoning, the rules of logic.
[00:15:16.720 --> 00:15:17.680]   How does this work?
[00:15:17.680 --> 00:15:19.560]   And that's where science comes from.
[00:15:19.560 --> 00:15:21.240]   - Of course, it's possible that science,
[00:15:21.240 --> 00:15:24.620]   like from my place of AI, would be able to,
[00:15:24.620 --> 00:15:30.720]   if we were able to engineer consciousness or understand,
[00:15:30.720 --> 00:15:32.120]   I mean, it's very difficult
[00:15:32.120 --> 00:15:33.440]   'cause we're so far away from it now,
[00:15:33.440 --> 00:15:36.500]   but understand how the actual mechanism
[00:15:36.500 --> 00:15:38.580]   of that consciousness emerges,
[00:15:38.580 --> 00:15:40.580]   that in fact this table is not real,
[00:15:40.580 --> 00:15:43.520]   that we can determine that it,
[00:15:43.520 --> 00:15:47.460]   exactly how our mind constructs the reality
[00:15:47.460 --> 00:15:51.620]   that we perceive, then you can start to make interesting.
[00:15:51.620 --> 00:15:54.460]   - But our mind doesn't construct the reality that we perceive.
[00:15:54.460 --> 00:15:56.300]   The reality we perceive is there.
[00:15:56.300 --> 00:15:59.780]   We perceive a reality that exists.
[00:15:59.780 --> 00:16:02.140]   Now, and we perceive it in particular ways
[00:16:02.140 --> 00:16:05.020]   given the nature of our senses, right?
[00:16:05.020 --> 00:16:07.180]   A bat perceives this table differently,
[00:16:07.180 --> 00:16:08.500]   but it's still the same table
[00:16:08.500 --> 00:16:12.860]   with the same characteristics and the same identity.
[00:16:12.860 --> 00:16:16.100]   It's just a matter of, we use eyes,
[00:16:16.100 --> 00:16:17.980]   they use a radar system to,
[00:16:17.980 --> 00:16:19.840]   they use sound waves to perceive it,
[00:16:19.840 --> 00:16:20.780]   but it's still there.
[00:16:20.780 --> 00:16:22.940]   Existence exists whether we exist or not.
[00:16:22.940 --> 00:16:27.020]   And so you could create, I mean, I don't know how,
[00:16:27.020 --> 00:16:28.460]   and I don't know if it's possible,
[00:16:28.460 --> 00:16:30.940]   but let's say you could create a consciousness, right?
[00:16:30.940 --> 00:16:33.620]   And I suspect that to do that,
[00:16:33.620 --> 00:16:37.140]   you would have to use biology, not just electronics,
[00:16:37.140 --> 00:16:39.380]   but way outside my expertise.
[00:16:39.380 --> 00:16:42.700]   Because consciousness, as far as we know,
[00:16:42.700 --> 00:16:43.700]   is a phenomenon of life,
[00:16:43.700 --> 00:16:45.420]   and you would have to figure out how to create life
[00:16:45.420 --> 00:16:48.420]   before you created consciousness, I think.
[00:16:48.420 --> 00:16:51.900]   But if you did that, then that wouldn't change anything.
[00:16:51.900 --> 00:16:54.300]   All it would say is we have another conscious being, cool.
[00:16:54.300 --> 00:16:55.120]   That's great.
[00:16:55.120 --> 00:16:58.140]   But it wouldn't change the nature of our consciousness.
[00:16:58.140 --> 00:17:00.500]   Our consciousness is what it is.
[00:17:00.500 --> 00:17:02.340]   - But, so that's very interesting.
[00:17:02.340 --> 00:17:05.660]   I think this is a good way to set the table
[00:17:05.660 --> 00:17:08.260]   for discussion of objectivism is,
[00:17:08.260 --> 00:17:12.340]   let me at least challenge a thought experiment,
[00:17:12.340 --> 00:17:14.220]   which is, I don't know if you're familiar
[00:17:14.220 --> 00:17:17.260]   with Donald Hoffman's work about reality.
[00:17:17.260 --> 00:17:20.460]   So his idea is that we're just,
[00:17:20.460 --> 00:17:23.460]   our perception is just an interface to reality.
[00:17:23.460 --> 00:17:26.580]   - So Donald Hoffman is the guy, you see Owein?
[00:17:26.580 --> 00:17:27.420]   - Yeah.
[00:17:27.420 --> 00:17:28.860]   - Yes, I've met Donald, and I've seen his video.
[00:17:28.860 --> 00:17:31.860]   And look, Donald has not invented anything new.
[00:17:31.860 --> 00:17:34.060]   This goes back to ancient philosophy.
[00:17:34.060 --> 00:17:38.180]   - Let me just state in case people aren't familiar.
[00:17:38.180 --> 00:17:41.500]   I mean, it's a fascinating thought experiment to me,
[00:17:41.500 --> 00:17:44.140]   like of out-of-the-box thinking, perhaps literally,
[00:17:44.140 --> 00:17:49.140]   is that there's a gap between the world as we perceive it
[00:17:49.140 --> 00:17:52.800]   and the world as it actually exists.
[00:17:52.800 --> 00:17:55.700]   And I think that's, for the philosophy of objectivism,
[00:17:55.700 --> 00:17:59.780]   there's a really important gap to close.
[00:17:59.780 --> 00:18:03.660]   So can you maybe at least try to entertain the idea
[00:18:03.660 --> 00:18:08.660]   that there is more to reality than our minds can perceive?
[00:18:08.660 --> 00:18:13.420]   - Well, I don't understand what more means, right?
[00:18:13.420 --> 00:18:14.820]   Of course there's more to reality
[00:18:14.820 --> 00:18:16.460]   than what our senses perceive.
[00:18:16.460 --> 00:18:19.380]   That is, for example, I don't know,
[00:18:19.380 --> 00:18:24.220]   certain elements have radiation, right?
[00:18:24.220 --> 00:18:25.180]   Uranium has radiation.
[00:18:25.180 --> 00:18:27.140]   I can't perceive radiation.
[00:18:27.140 --> 00:18:32.140]   The beauty of human reason is I can, through experimentation,
[00:18:32.140 --> 00:18:34.340]   discover the phenomena of radiation,
[00:18:34.340 --> 00:18:36.780]   then actually measure radiation,
[00:18:36.780 --> 00:18:37.660]   and I don't worry about it.
[00:18:37.660 --> 00:18:39.060]   I can't perceive the world
[00:18:39.060 --> 00:18:40.420]   the way a bat perceives the world,
[00:18:40.420 --> 00:18:43.180]   and I might not be able to see certain things.
[00:18:43.180 --> 00:18:44.980]   But I can, we've created radar,
[00:18:44.980 --> 00:18:47.860]   so A, we understand how a bat perceives the world,
[00:18:47.860 --> 00:18:50.340]   and I can mimic it through a radar screen
[00:18:50.340 --> 00:18:53.320]   and create images like the bat,
[00:18:53.320 --> 00:18:55.780]   its consciousness somehow perceives it, right?
[00:18:55.780 --> 00:19:00.280]   So the beauty of human reason is our capacity
[00:19:00.280 --> 00:19:02.860]   to understand the world beyond
[00:19:02.860 --> 00:19:05.220]   what our senses give us directly.
[00:19:05.220 --> 00:19:07.860]   At the end, everything comes in through our senses,
[00:19:07.860 --> 00:19:10.380]   but we can understand things
[00:19:10.380 --> 00:19:11.540]   that our senses don't provide us.
[00:19:11.540 --> 00:19:14.940]   But what he's doing is he's doing something very different.
[00:19:14.940 --> 00:19:17.420]   He is saying what our senses provides us
[00:19:17.420 --> 00:19:20.700]   might have nothing to do with the reality out there.
[00:19:20.700 --> 00:19:25.700]   That is just a random, arbitrary, nonsensical statement.
[00:19:25.700 --> 00:19:28.880]   And he actually has a whole evolutionary explanation for it.
[00:19:28.880 --> 00:19:30.720]   He runs some simulations.
[00:19:30.720 --> 00:19:32.440]   The simulations seem, I mean,
[00:19:32.440 --> 00:19:33.760]   I'm not an expert in this field,
[00:19:33.760 --> 00:19:35.360]   but they seem silly to me.
[00:19:35.360 --> 00:19:36.760]   They don't seem to reflect.
[00:19:36.760 --> 00:19:41.080]   And look, all he's doing is taking Immanuel Kant's philosophy
[00:19:41.080 --> 00:19:43.240]   which articulate exactly the same cause,
[00:19:43.240 --> 00:19:48.240]   and he's giving it a veneer of evolutionary ideas.
[00:19:48.240 --> 00:19:50.400]   I'm not an expert on evolution,
[00:19:50.400 --> 00:19:52.300]   and I'm not an expert on epistemology,
[00:19:52.300 --> 00:19:53.620]   which is what this is.
[00:19:53.620 --> 00:19:58.620]   So to me, as a semi-layman, it doesn't make any sense.
[00:19:58.620 --> 00:20:03.820]   And I'm actually, I have this Yaron Burk show.
[00:20:03.820 --> 00:20:05.540]   I don't know if I'm allowed to pitch it,
[00:20:05.540 --> 00:20:06.380]   but I've got this Yaron Burk show on.
[00:20:06.380 --> 00:20:08.020]   - Oh, please, first of all, let me pause.
[00:20:08.020 --> 00:20:09.340]   - On YouTube. - I'm a huge fan
[00:20:09.340 --> 00:20:11.140]   of the Yaron Burk show. - Thank you.
[00:20:11.140 --> 00:20:12.820]   - I listen to it very often.
[00:20:12.820 --> 00:20:17.820]   As a small aside, the cool thing about reason,
[00:20:18.020 --> 00:20:21.460]   which you practice, is you have a systematic way
[00:20:21.460 --> 00:20:24.400]   of thinking through basically anything.
[00:20:24.400 --> 00:20:25.480]   - Yes.
[00:20:25.480 --> 00:20:27.600]   - And that's so fun to listen to.
[00:20:27.600 --> 00:20:32.600]   I mean, it's rare that I think there's flaws in your logic,
[00:20:32.600 --> 00:20:34.560]   but even then, it's fun,
[00:20:34.560 --> 00:20:37.320]   'cause I'm like disagreeing with the screen.
[00:20:37.320 --> 00:20:39.120]   - And it's great when somebody disagrees with me,
[00:20:39.120 --> 00:20:40.560]   and they give good arguments,
[00:20:40.560 --> 00:20:42.280]   because that makes it challenging.
[00:20:42.280 --> 00:20:43.120]   - Anyway, sorry.
[00:20:43.120 --> 00:20:46.120]   - So one of the shows I wanna do in the next few weeks
[00:20:46.340 --> 00:20:49.140]   is bring one of my philosopher friends
[00:20:49.140 --> 00:20:51.820]   to discuss the video that Hoffman,
[00:20:51.820 --> 00:20:52.820]   where he presents his theory,
[00:20:52.820 --> 00:20:57.820]   because it surprises me how seductive it is.
[00:20:57.820 --> 00:21:00.780]   And it seems to be so, first of all,
[00:21:00.780 --> 00:21:02.820]   completely counterintuitive,
[00:21:02.820 --> 00:21:05.860]   because somehow we managed to cross the road
[00:21:05.860 --> 00:21:07.020]   and not get hit by the car,
[00:21:07.020 --> 00:21:10.080]   and if our senses did not provide us any information
[00:21:10.080 --> 00:21:12.180]   about what's actually going on in reality,
[00:21:12.180 --> 00:21:13.660]   how do we do that?
[00:21:13.660 --> 00:21:16.060]   And not to mention build computers.
[00:21:16.060 --> 00:21:17.600]   Not to mention fly to the moon
[00:21:17.600 --> 00:21:18.640]   and actually land on the moon.
[00:21:18.640 --> 00:21:21.800]   And if reality's not giving us information about the moon,
[00:21:21.800 --> 00:21:24.620]   if our senses are not giving us information about the moon,
[00:21:24.620 --> 00:21:25.820]   how did we get there?
[00:21:25.820 --> 00:21:27.120]   And where did we go?
[00:21:27.120 --> 00:21:28.860]   Maybe we didn't go anywhere.
[00:21:28.860 --> 00:21:30.920]   It's just, it's nonsensical to me,
[00:21:30.920 --> 00:21:35.920]   and it's a very bad place philosophically,
[00:21:35.920 --> 00:21:38.680]   because it basically says
[00:21:38.680 --> 00:21:40.840]   there is no objective standard for anything.
[00:21:40.840 --> 00:21:42.480]   There is no objective reality.
[00:21:42.480 --> 00:21:43.600]   You can come up with anything.
[00:21:43.600 --> 00:21:44.680]   You could argue anything,
[00:21:44.680 --> 00:21:46.400]   and there's no methodology, right?
[00:21:46.400 --> 00:21:48.160]   I believe that at the end of the day,
[00:21:48.160 --> 00:21:50.040]   what reason allows us to do
[00:21:50.040 --> 00:21:52.240]   is provides us with a methodology for truth.
[00:21:52.240 --> 00:21:54.760]   And at the end of the day, for every claim that I make,
[00:21:54.760 --> 00:21:57.880]   I should be able to boil it down to,
[00:21:57.880 --> 00:22:02.520]   see, look, the evidence of the senses is right there.
[00:22:02.520 --> 00:22:03.840]   And once you take that away,
[00:22:03.840 --> 00:22:06.240]   knowledge is gone, and truth is gone,
[00:22:06.240 --> 00:22:09.680]   and that opens it up to complete disaster.
[00:22:09.680 --> 00:22:12.740]   - So to me, why it's compelling
[00:22:12.740 --> 00:22:16.220]   to at least entertain this idea,
[00:22:16.220 --> 00:22:18.960]   first of all, it shakes up the mind a little bit
[00:22:18.960 --> 00:22:23.960]   to force you to go back to first principles
[00:22:23.960 --> 00:22:27.420]   and ask the question, what do I really know?
[00:22:27.420 --> 00:22:31.500]   And the second part of that that I really enjoy
[00:22:31.500 --> 00:22:35.420]   is it's a reminder that we know very little,
[00:22:35.420 --> 00:22:37.380]   to be a little bit more humble.
[00:22:37.380 --> 00:22:40.580]   So if reality doesn't exist at all,
[00:22:40.580 --> 00:22:43.060]   before you start thinking about it,
[00:22:43.060 --> 00:22:46.660]   I think it's a really nice wake-up call to think,
[00:22:46.660 --> 00:22:51.180]   wait a minute, I don't really know much about this universe,
[00:22:51.180 --> 00:22:52.680]   that humbleness.
[00:22:52.680 --> 00:22:54.980]   I think something I'd like to ask you about
[00:22:54.980 --> 00:22:56.500]   in terms of reason,
[00:22:56.500 --> 00:22:59.940]   when you, you can become very confident
[00:22:59.940 --> 00:23:03.060]   in your ability to understand the world
[00:23:03.060 --> 00:23:04.900]   if you practice reason often.
[00:23:04.900 --> 00:23:07.940]   And I feel like it can lead you astray
[00:23:07.940 --> 00:23:11.020]   because you can start to think,
[00:23:11.020 --> 00:23:12.940]   so I love psychology,
[00:23:12.940 --> 00:23:15.380]   and psychologists have this certainty
[00:23:15.380 --> 00:23:17.860]   about understanding the human condition,
[00:23:17.860 --> 00:23:19.540]   which is undeserved.
[00:23:19.540 --> 00:23:21.580]   You run a study with 50 people
[00:23:21.580 --> 00:23:23.700]   and you think you can understand
[00:23:23.700 --> 00:23:25.620]   the source of all these psychiatric disorders,
[00:23:25.620 --> 00:23:27.100]   all these kinds of things.
[00:23:27.100 --> 00:23:31.820]   That's similar kind of trouble I feel like you can get into
[00:23:31.820 --> 00:23:35.300]   when you overreach with reason.
[00:23:35.300 --> 00:23:36.540]   - So I don't think there is such a thing
[00:23:36.540 --> 00:23:38.260]   as overreaching with reason,
[00:23:38.260 --> 00:23:40.540]   but there are bad applications of reason.
[00:23:40.540 --> 00:23:42.140]   There are bad uses of reason,
[00:23:42.140 --> 00:23:44.420]   or the pretense of using reason.
[00:23:44.420 --> 00:23:46.820]   I think a lot of these psychological studies
[00:23:46.820 --> 00:23:48.220]   are pretense of using reason,
[00:23:48.220 --> 00:23:51.120]   and these psychologists have never really taken
[00:23:51.120 --> 00:23:53.660]   a serious stat class or a serious econometrics class,
[00:23:53.660 --> 00:23:55.780]   so they use statistics in weird ways
[00:23:55.780 --> 00:23:57.360]   that just don't make any sense.
[00:23:57.360 --> 00:23:59.500]   And that's a mis, that's not reason, right?
[00:23:59.500 --> 00:24:01.140]   That's just bad thinking, right?
[00:24:01.140 --> 00:24:05.040]   So I don't think you can do too much good thinking,
[00:24:05.940 --> 00:24:08.620]   and that's what reason is, it's good thinking.
[00:24:08.620 --> 00:24:13.620]   Now, the fact that you try to use reason
[00:24:13.620 --> 00:24:17.060]   does not guarantee you won't make mistakes.
[00:24:17.060 --> 00:24:18.880]   It doesn't guarantee you won't be wrong.
[00:24:18.880 --> 00:24:21.820]   It doesn't guarantee you won't go down a rabbit hole
[00:24:21.820 --> 00:24:24.360]   and completely get it wrong,
[00:24:24.360 --> 00:24:29.220]   but it does give you the only existing mechanism to fix it,
[00:24:29.220 --> 00:24:30.380]   which is going back to reality,
[00:24:30.380 --> 00:24:32.640]   going back to facts, going back to reason,
[00:24:32.640 --> 00:24:34.780]   and getting out of the rabbit hole
[00:24:34.780 --> 00:24:37.380]   and getting back to reality.
[00:24:37.380 --> 00:24:40.220]   So I agree with you that it's interesting
[00:24:40.220 --> 00:24:44.700]   to think about these, what I consider crazy ideas,
[00:24:44.700 --> 00:24:47.840]   because it, oh wait, what is my argument about them?
[00:24:47.840 --> 00:24:49.900]   If I don't really have a good argument about them,
[00:24:49.900 --> 00:24:51.120]   then do I know what I know?
[00:24:51.120 --> 00:24:53.940]   So in that sense, it's always nice to be challenged
[00:24:53.940 --> 00:24:56.020]   and pushed and oriented.
[00:24:56.020 --> 00:24:57.620]   You know, the nice thing about objectivism
[00:24:57.620 --> 00:25:00.320]   is everybody's doing that to me all the time, right?
[00:25:00.320 --> 00:25:01.820]   Because nobody agrees with me on anything,
[00:25:01.820 --> 00:25:04.180]   so I'm constantly being challenged,
[00:25:04.180 --> 00:25:08.260]   whether it's by Hoffman on metaphysics and epistemology,
[00:25:08.260 --> 00:25:10.020]   right, on the very foundations of my knowledge,
[00:25:10.020 --> 00:25:12.260]   in ethics, everybody constantly,
[00:25:12.260 --> 00:25:14.060]   and in politics all the time.
[00:25:14.060 --> 00:25:18.540]   So I find that it's part of, you know,
[00:25:18.540 --> 00:25:19.580]   I prefer that everybody,
[00:25:19.580 --> 00:25:20.900]   there's a sense in which I prefer
[00:25:20.900 --> 00:25:22.580]   that everybody agreed with me, right?
[00:25:22.580 --> 00:25:24.460]   Because I think we'd live in a better world,
[00:25:24.460 --> 00:25:27.680]   but there's a sense in which that disagreement makes it,
[00:25:27.680 --> 00:25:31.300]   at least up to a point, makes it interesting and challenging
[00:25:31.300 --> 00:25:35.620]   and forces you to be able to rethink
[00:25:35.620 --> 00:25:37.300]   or to confirm your own thinking
[00:25:37.300 --> 00:25:39.540]   and to challenge that thinking.
[00:25:39.540 --> 00:25:42.220]   - Can you try to do the impossible task
[00:25:42.220 --> 00:25:45.760]   and give a whirlwind introduction to Ayn Rand,
[00:25:45.760 --> 00:25:49.260]   the many sides of Ayn Rand?
[00:25:49.260 --> 00:25:53.820]   So Ayn Rand, the human being, Ayn Rand, the novelist,
[00:25:53.820 --> 00:25:56.040]   and Ayn Rand, the philosopher.
[00:25:56.040 --> 00:25:57.780]   So who was Ayn Rand?
[00:25:57.780 --> 00:26:02.780]   - Sure, so her life story is one that I think is fascinating
[00:26:02.780 --> 00:26:07.420]   but it also lends itself to this integration
[00:26:07.420 --> 00:26:08.860]   of all of these things.
[00:26:08.860 --> 00:26:12.620]   She was born in St. Petersburg, Russia in 1905
[00:26:12.620 --> 00:26:16.460]   to kind of a middle-class family, Jewish family.
[00:26:16.460 --> 00:26:19.740]   They owned a pharmacy, her father owned a pharmacy.
[00:26:19.740 --> 00:26:25.580]   And, you know, she grew up, she was a very,
[00:26:27.420 --> 00:26:29.020]   she knew what she wanted to do
[00:26:29.020 --> 00:26:31.220]   and what she wanted to be from a very young age.
[00:26:31.220 --> 00:26:32.380]   I think from the age of nine,
[00:26:32.380 --> 00:26:33.620]   she knew she wanted to be a writer.
[00:26:33.620 --> 00:26:35.020]   She wanted to write stories.
[00:26:35.020 --> 00:26:37.380]   That was the thing she wanted to do.
[00:26:37.380 --> 00:26:41.520]   And, you know, she focused her life after that
[00:26:41.520 --> 00:26:44.800]   on this goal of, I want to be a novelist, I want to write.
[00:26:44.800 --> 00:26:50.020]   And the philosophy was incidental to that, in a sense,
[00:26:50.020 --> 00:26:52.700]   at least until some point in her life.
[00:26:52.700 --> 00:26:55.700]   She witnessed the Russian Revolution,
[00:26:55.700 --> 00:26:57.020]   literally it happened outside.
[00:26:57.020 --> 00:26:59.340]   They lived in St. Petersburg
[00:26:59.340 --> 00:27:01.380]   where the first kind of demonstrations
[00:27:01.380 --> 00:27:03.460]   and of the revolution happened.
[00:27:03.460 --> 00:27:04.540]   So she witnessed it.
[00:27:04.540 --> 00:27:06.740]   She lived through it as a teenager,
[00:27:06.740 --> 00:27:10.900]   went to school under the Soviets.
[00:27:10.900 --> 00:27:14.260]   For a while, they were under kind of the,
[00:27:14.260 --> 00:27:18.100]   on the Black Sea where the opposition government was ruling
[00:27:18.100 --> 00:27:19.780]   and then they would go back and forth
[00:27:19.780 --> 00:27:21.500]   between the communists and the whites.
[00:27:21.500 --> 00:27:23.820]   But she experienced what communism was like.
[00:27:23.820 --> 00:27:26.700]   She saw the pharmacy being taken away from her family.
[00:27:26.700 --> 00:27:28.900]   She saw their apartment being taken away
[00:27:28.900 --> 00:27:31.700]   or other families being brought into the apartment
[00:27:31.700 --> 00:27:32.800]   they already lived in.
[00:27:32.800 --> 00:27:38.620]   And it was very clear, given her nature,
[00:27:38.620 --> 00:27:42.080]   given her views, even at a very young age,
[00:27:42.080 --> 00:27:44.660]   that she would not survive this system.
[00:27:44.660 --> 00:27:47.260]   So a lot of effort was put into how do we get,
[00:27:47.260 --> 00:27:48.380]   how does she get out?
[00:27:48.380 --> 00:27:51.260]   And her family was really helpful in this.
[00:27:51.260 --> 00:27:54.100]   And she had a cousin in Chicago
[00:27:54.100 --> 00:27:58.420]   and she had been studying kind of film at the university.
[00:27:58.420 --> 00:28:00.460]   - This is in her 20s?
[00:28:00.460 --> 00:28:03.220]   - This is in her 20s, early 20s.
[00:28:03.220 --> 00:28:06.820]   And Lenin, there was a small window
[00:28:06.820 --> 00:28:09.260]   where Lenin was allowing some people
[00:28:09.260 --> 00:28:12.460]   to leave under certain circumstances.
[00:28:12.460 --> 00:28:15.820]   And she managed to get out to go do research on film
[00:28:15.820 --> 00:28:17.140]   in the United States.
[00:28:17.140 --> 00:28:19.180]   Everybody knew, everybody who knew her
[00:28:19.180 --> 00:28:21.120]   knew she would never come back,
[00:28:21.120 --> 00:28:22.500]   that this was a one-way ticket.
[00:28:22.500 --> 00:28:24.500]   And she got out, she made it to Chicago,
[00:28:24.500 --> 00:28:28.820]   spent a few weeks in Chicago, and then headed to Hollywood.
[00:28:28.820 --> 00:28:30.180]   She wanted to write scripts.
[00:28:30.180 --> 00:28:32.440]   That was the goal.
[00:28:32.440 --> 00:28:36.380]   Here's this short woman from Russia
[00:28:36.380 --> 00:28:39.740]   with a strong accent, learning English,
[00:28:39.740 --> 00:28:43.540]   showing up in Hollywood, and I wanna be a script writer.
[00:28:43.540 --> 00:28:44.460]   - In English?
[00:28:44.460 --> 00:28:46.540]   - In English, writing in English.
[00:28:46.540 --> 00:28:51.160]   And this is kind of one of these fairy tale stories,
[00:28:51.160 --> 00:28:55.460]   but it's true, she shows up at the Cecil B. DeMille Studios.
[00:28:55.460 --> 00:28:58.380]   And she has a letter of introduction
[00:28:58.380 --> 00:29:02.060]   from her cousin in Chicago who owns a movie theater.
[00:29:02.060 --> 00:29:05.940]   And this is in the late 1920s.
[00:29:05.940 --> 00:29:07.660]   And she shows up there with this letter,
[00:29:07.660 --> 00:29:10.420]   and they say, "Don't call us, we'll call you," kind of thing.
[00:29:10.420 --> 00:29:15.420]   And she steps out, and there's this massive convertible.
[00:29:15.420 --> 00:29:18.060]   And in the convertible is Cecil B. DeMille.
[00:29:18.060 --> 00:29:20.140]   And he's driving slowly past her
[00:29:20.140 --> 00:29:21.540]   right at the entrance of the studio,
[00:29:21.540 --> 00:29:23.260]   and she stares at him, and he stops the car,
[00:29:23.260 --> 00:29:25.760]   and he says, "Why are you staring at me?"
[00:29:25.760 --> 00:29:28.220]   And she says, she tells him a story for Russia,
[00:29:28.220 --> 00:29:30.100]   and I wanna make it in the movies,
[00:29:30.100 --> 00:29:31.580]   I wanna be a script writer one day.
[00:29:31.580 --> 00:29:35.060]   And he says, "Well, if you want that, get in the car."
[00:29:35.060 --> 00:29:37.060]   She gets in the car, and he takes her
[00:29:37.060 --> 00:29:38.940]   to the back lot of his studio
[00:29:38.940 --> 00:29:40.380]   where they're filming "The King of Kings,"
[00:29:40.380 --> 00:29:41.980]   the story of Jesus.
[00:29:41.980 --> 00:29:45.180]   And he says, "Here's a pass for a week.
[00:29:45.180 --> 00:29:47.300]   If you wanna write for the movies,
[00:29:47.300 --> 00:29:49.700]   you better know how movies are made."
[00:29:49.700 --> 00:29:51.540]   And she basically spends a week,
[00:29:51.540 --> 00:29:53.140]   and then she spends more time there.
[00:29:53.140 --> 00:29:54.500]   She managed to get an extension.
[00:29:54.500 --> 00:29:56.100]   She lands up being an extra in the movie,
[00:29:56.100 --> 00:29:58.260]   so you can see Iron Man there,
[00:29:58.260 --> 00:30:03.020]   and it's one of the masses when Jesus is walking by.
[00:30:03.020 --> 00:30:05.580]   She meets her future husband on the sets
[00:30:05.580 --> 00:30:07.340]   of "The King of Kings."
[00:30:07.340 --> 00:30:09.180]   She lands up getting married,
[00:30:09.180 --> 00:30:12.140]   getting her American citizenship that way.
[00:30:12.140 --> 00:30:15.860]   And she lands up doing odds and ends jobs in Hollywood,
[00:30:15.860 --> 00:30:17.660]   living in a tiny little apartment.
[00:30:19.380 --> 00:30:20.700]   Somehow making a living.
[00:30:20.700 --> 00:30:22.020]   Her husband was an actor.
[00:30:22.020 --> 00:30:26.620]   He was struggling actors, difficult times.
[00:30:26.620 --> 00:30:28.780]   And in the evenings, studying English,
[00:30:28.780 --> 00:30:30.460]   writing, writing, writing, writing,
[00:30:30.460 --> 00:30:31.900]   and studying, and studying, and studying.
[00:30:31.900 --> 00:30:34.700]   She finally makes it by writing a play
[00:30:34.700 --> 00:30:39.420]   that is successful in LA,
[00:30:39.420 --> 00:30:41.240]   and ultimately goes to Broadway.
[00:30:41.240 --> 00:30:45.420]   And she writes her first novel,
[00:30:45.420 --> 00:30:47.720]   is a novel called "We the Living,"
[00:30:47.720 --> 00:30:50.820]   which is the most autobiographical of all her novels.
[00:30:50.820 --> 00:30:54.380]   It's about a young woman in the Soviet Union.
[00:30:54.380 --> 00:30:58.140]   It's a powerful story, a very moving story,
[00:30:58.140 --> 00:31:01.300]   and probably, if not the best,
[00:31:01.300 --> 00:31:05.020]   one of the best portrayals of life under communism.
[00:31:05.020 --> 00:31:06.500]   - So you would recommend the book?
[00:31:06.500 --> 00:31:08.020]   - Definitely recommend "We the Living."
[00:31:08.020 --> 00:31:09.460]   It's her first novel.
[00:31:09.460 --> 00:31:13.260]   She wrote in the '30s, and it didn't go anywhere,
[00:31:13.260 --> 00:31:16.060]   because if you think about the intelligentsia,
[00:31:16.060 --> 00:31:20.320]   the people who mattered, the people who wrote book reviews,
[00:31:20.320 --> 00:31:23.400]   this is a time of Durante,
[00:31:23.400 --> 00:31:25.940]   who's the "New York Times" guy in Moscow,
[00:31:25.940 --> 00:31:29.760]   who's praising Stalin to the hills, and the success.
[00:31:29.760 --> 00:31:34.280]   So the novel fails, but she's got a novel out.
[00:31:34.280 --> 00:31:36.840]   She writes a small novelette called "Anthem."
[00:31:36.840 --> 00:31:38.200]   A lot of people have read that,
[00:31:38.200 --> 00:31:39.840]   and it's read in high schools.
[00:31:39.840 --> 00:31:42.200]   It's kind of a dystopian novel,
[00:31:42.200 --> 00:31:45.840]   and it doesn't get published in the US.
[00:31:45.840 --> 00:31:47.120]   It gets published in the UK.
[00:31:47.120 --> 00:31:50.200]   UK is very interested in dystopian novels.
[00:31:50.200 --> 00:31:54.680]   "Animal Farm" in 1984, '84,
[00:31:54.680 --> 00:31:58.920]   is published a couple of years after, I think, after "Anthem."
[00:31:58.920 --> 00:32:01.700]   There's reason to believe he read "Anthem."
[00:32:01.700 --> 00:32:06.560]   - And George Orwell read that for "Animal Farm."
[00:32:06.560 --> 00:32:07.680]   - Yeah.
[00:32:07.680 --> 00:32:11.140]   - Just the small side, "Animal Farm" is probably top.
[00:32:11.140 --> 00:32:13.000]   I mean, it's weird to say,
[00:32:13.000 --> 00:32:14.920]   but I would say it's my favorite book, which is--
[00:32:14.920 --> 00:32:17.600]   - Have you seen this movie out now called "Mr. Jones?"
[00:32:17.600 --> 00:32:18.440]   - No.
[00:32:18.440 --> 00:32:19.600]   - Oh, you've got to see "Mr. Jones."
[00:32:19.600 --> 00:32:21.080]   - What's "Mr. Jones?"
[00:32:21.080 --> 00:32:22.960]   - It's a-- - Sorry for my ignorance.
[00:32:22.960 --> 00:32:25.640]   - No, no, it's a movie, and it hasn't got any publicity,
[00:32:25.640 --> 00:32:28.200]   which is tragic, 'cause it's a really good movie.
[00:32:28.200 --> 00:32:29.660]   It's both brilliantly made.
[00:32:29.660 --> 00:32:32.960]   It's made by a Polish director, but it's in English.
[00:32:32.960 --> 00:32:36.440]   It's a true story, and George Orwell's "Animal Farm"
[00:32:36.440 --> 00:32:40.240]   is featured in it, in the sense that during the story,
[00:32:40.240 --> 00:32:42.560]   George Orwell was writing "Animal Farm,"
[00:32:42.560 --> 00:32:47.360]   and the narrator is reading off sections of "Animal Farm"
[00:32:47.360 --> 00:32:49.360]   as the movie is progressing.
[00:32:49.360 --> 00:32:50.960]   And the movie is a true story
[00:32:50.960 --> 00:32:55.720]   about the first Western journalist to discover
[00:32:55.720 --> 00:32:57.760]   and to write about the famine in Ukraine.
[00:32:57.760 --> 00:33:01.040]   And so he goes to Moscow, and then he gets on a train,
[00:33:01.040 --> 00:33:02.240]   and he finds himself in Ukraine,
[00:33:02.240 --> 00:33:05.760]   and it's beautifully and horrifically made.
[00:33:05.760 --> 00:33:10.480]   So the horror of the famine is brilliantly conveyed,
[00:33:10.480 --> 00:33:13.000]   and it's a true story, so it's a very moving story,
[00:33:13.000 --> 00:33:16.560]   very powerful story, and just very well-made movie.
[00:33:16.560 --> 00:33:19.880]   So it's tragic, in my view, that not more people are seeing.
[00:33:19.880 --> 00:33:20.720]   - That's interesting.
[00:33:20.720 --> 00:33:23.240]   I was actually recently just complaining
[00:33:23.240 --> 00:33:26.920]   that there's not enough content on the famine,
[00:33:26.920 --> 00:33:29.440]   the '30s of stuff.
[00:33:29.440 --> 00:33:30.440]   There's so much on Hitler.
[00:33:30.440 --> 00:33:32.520]   Like, I love the reading.
[00:33:32.520 --> 00:33:34.640]   I'm reading, it's so long.
[00:33:34.640 --> 00:33:35.880]   It's been taking me forever.
[00:33:35.880 --> 00:33:39.440]   The rise and fall of the Third Reich, yeah, I love it.
[00:33:39.440 --> 00:33:42.160]   I've got the book to complement that that you have to read.
[00:33:42.160 --> 00:33:44.160]   It's called "The Ominous Parallels."
[00:33:44.160 --> 00:33:47.080]   It's Leonard Picoff, and it's "The Ominous Parallels,"
[00:33:47.080 --> 00:33:52.080]   and it's about the causes of the rise of Hitler,
[00:33:52.080 --> 00:33:54.240]   but a philosophical causes.
[00:33:54.240 --> 00:33:58.480]   So whereas the rise and fall is more of a kind of,
[00:33:58.480 --> 00:34:00.880]   the existential kind of what happened,
[00:34:00.880 --> 00:34:07.720]   but really delving into the intellectual currents
[00:34:07.720 --> 00:34:09.240]   that led to the rise of Hitler.
[00:34:09.240 --> 00:34:11.280]   - And maybe-- - Highly recommend that.
[00:34:11.280 --> 00:34:15.800]   - And basically suggesting how it might rise another--
[00:34:15.800 --> 00:34:17.200]   - That's "The Ominous Parallels."
[00:34:17.200 --> 00:34:20.480]   So the parallel he draws is to the United States,
[00:34:20.480 --> 00:34:22.640]   and he says those same intellectual forces
[00:34:22.640 --> 00:34:23.840]   are rising in the United States,
[00:34:23.840 --> 00:34:28.840]   and this was published, I think, in '82.
[00:34:28.840 --> 00:34:30.260]   It was published in '82.
[00:34:30.260 --> 00:34:31.760]   So it was published a long time ago,
[00:34:31.760 --> 00:34:34.600]   and yet you look around us,
[00:34:34.600 --> 00:34:37.220]   and it's unbelievably predictive, sadly,
[00:34:37.220 --> 00:34:38.740]   about the state of the world.
[00:34:38.740 --> 00:34:40.120]   - So I haven't finished Dianne Rant's story.
[00:34:40.120 --> 00:34:41.360]   I don't know if you want me to--
[00:34:41.360 --> 00:34:44.360]   - No, no, but on that point, I'll have to,
[00:34:44.360 --> 00:34:46.800]   let's please return to it, but let's now,
[00:34:46.800 --> 00:34:47.640]   for now, let's talk--
[00:34:47.640 --> 00:34:50.160]   - But let me also say, just because I don't want
[00:34:50.160 --> 00:34:54.440]   to forget about Mr. Jones, it is true, the point you made,
[00:34:54.440 --> 00:34:58.520]   that tons of movies that are anti-fascist, anti-Nazi,
[00:34:58.520 --> 00:35:02.640]   and that's good, but there are way too few movies
[00:35:02.640 --> 00:35:05.520]   that are anti-communist, just almost not.
[00:35:05.520 --> 00:35:08.000]   And it's very interesting, and if you remind me later,
[00:35:08.000 --> 00:35:09.300]   I'll tell you a story about that.
[00:35:09.300 --> 00:35:13.920]   But so she publishes "Anthem," and then she starts,
[00:35:13.920 --> 00:35:15.720]   and she's doing okay in Hollywood,
[00:35:15.720 --> 00:35:18.060]   and she's doing okay with the play,
[00:35:18.060 --> 00:35:21.620]   and then she starts on the book "The Fountainhead,"
[00:35:21.620 --> 00:35:25.260]   and she writes "The Fountainhead," and it comes out,
[00:35:25.260 --> 00:35:30.260]   she finishes it in 1945, and she sends it to publishers,
[00:35:30.260 --> 00:35:37.100]   and publisher after publisher after publisher turn it down.
[00:35:37.100 --> 00:35:41.860]   And it takes 12 publishers before this editor reads it
[00:35:41.860 --> 00:35:44.800]   and says, "I want to publish this book."
[00:35:44.800 --> 00:35:47.040]   And he basically tells his bosses,
[00:35:47.040 --> 00:35:49.820]   "If you don't publish this book, I'm leaving."
[00:35:49.820 --> 00:35:54.740]   And they don't really believe in the book,
[00:35:54.740 --> 00:35:58.640]   so they publish just a few copies, they don't do a mat,
[00:35:58.640 --> 00:36:00.860]   and the book becomes a bestseller from word of mouth,
[00:36:00.860 --> 00:36:03.620]   and they land up having to publish more and more and more.
[00:36:03.620 --> 00:36:07.540]   And she's basically gone from this immigrant
[00:36:07.540 --> 00:36:10.060]   who comes here with very little command of English,
[00:36:10.060 --> 00:36:14.860]   and to all kinds of odds and ends jobs in Hollywood,
[00:36:14.860 --> 00:36:19.860]   to writing one of the seminal, I think, American books.
[00:36:19.860 --> 00:36:24.060]   She is an American author.
[00:36:24.060 --> 00:36:27.540]   I mean, if you read "The Fountainhead," it's not Russian.
[00:36:27.540 --> 00:36:29.220]   This is not Dostoyevsky.
[00:36:29.220 --> 00:36:32.780]   - It feels like a symbol of what America is
[00:36:32.780 --> 00:36:34.380]   in the 20th century.
[00:36:34.380 --> 00:36:38.260]   And I mean, probably, maybe you can...
[00:36:38.260 --> 00:36:42.500]   So there's a famous kind of sexual rape scene in there.
[00:36:42.500 --> 00:36:44.780]   Is that like a lesson you want to throw in
[00:36:44.780 --> 00:36:47.060]   some controversial stuff to make
[00:36:47.060 --> 00:36:49.340]   your philosophical books work out?
[00:36:49.340 --> 00:36:51.980]   I mean, why was it so popular?
[00:36:51.980 --> 00:36:53.580]   Do you have a sense?
[00:36:53.580 --> 00:36:55.780]   - Well, because I think it illustrated...
[00:36:55.780 --> 00:36:58.940]   First of all, 'cause I think the character's fantastic.
[00:36:58.940 --> 00:37:01.340]   It's got a real hero.
[00:37:01.340 --> 00:37:03.820]   And I think the whole book is basically
[00:37:03.820 --> 00:37:05.860]   illustrating this massive conflict
[00:37:05.860 --> 00:37:09.300]   that I think went on in America then, is going on today,
[00:37:09.300 --> 00:37:12.460]   and it goes on in a big scale politics,
[00:37:12.460 --> 00:37:14.720]   all the way down to the scale of the choices
[00:37:14.720 --> 00:37:16.160]   you make in your life.
[00:37:16.160 --> 00:37:20.160]   And the issue is individualism versus collectivism.
[00:37:20.160 --> 00:37:22.380]   Should you live for yourself?
[00:37:22.380 --> 00:37:23.580]   Should you live for your values?
[00:37:23.580 --> 00:37:25.460]   Should you pursue your passions?
[00:37:25.460 --> 00:37:29.020]   Or should you do what your mother tells you?
[00:37:29.020 --> 00:37:31.580]   Should you follow your mother's passions?
[00:37:31.580 --> 00:37:33.700]   And that's...
[00:37:33.700 --> 00:37:38.700]   And it's very, very much a book about individuals,
[00:37:38.700 --> 00:37:42.600]   and people relate to that.
[00:37:42.600 --> 00:37:45.660]   But it obviously has this massive implications
[00:37:45.660 --> 00:37:47.060]   to the world outside.
[00:37:47.060 --> 00:37:50.980]   And at the time of collectivism just having been defeated,
[00:37:50.980 --> 00:37:53.580]   communism, well, fascism,
[00:37:53.580 --> 00:37:58.580]   and the United States representing individualism
[00:37:58.620 --> 00:38:01.420]   has defeated collectivism.
[00:38:01.420 --> 00:38:03.820]   But where collectivist ideas are still popular
[00:38:03.820 --> 00:38:06.260]   in the form of socialism and communism,
[00:38:06.260 --> 00:38:08.100]   and for the individual,
[00:38:08.100 --> 00:38:10.940]   this constant struggle between what people tell me to do,
[00:38:10.940 --> 00:38:12.100]   what society tells me to do,
[00:38:12.100 --> 00:38:13.260]   what my mother tells me to do,
[00:38:13.260 --> 00:38:15.260]   and what I think I should do,
[00:38:15.260 --> 00:38:17.580]   I think it's unbelievably appealing,
[00:38:17.580 --> 00:38:18.860]   particularly to young people
[00:38:18.860 --> 00:38:21.500]   who are trying to figure out what they wanna do in life,
[00:38:21.500 --> 00:38:23.740]   trying to figure out what's important in life.
[00:38:23.740 --> 00:38:26.420]   It had this enormous appeal.
[00:38:26.420 --> 00:38:28.300]   It's romantic, it's bigger than life.
[00:38:28.300 --> 00:38:29.940]   The characters are big heroes.
[00:38:29.940 --> 00:38:31.660]   It's very American in that sense.
[00:38:31.660 --> 00:38:32.940]   It's about individualism.
[00:38:32.940 --> 00:38:35.500]   It's about the triumph of individualism.
[00:38:35.500 --> 00:38:38.900]   And so I think that's what related.
[00:38:38.900 --> 00:38:42.980]   And it had this big romantic element from the...
[00:38:42.980 --> 00:38:44.260]   I mean, when I use romantic,
[00:38:44.260 --> 00:38:49.260]   I use it kind of in the sense of a movement in art.
[00:38:49.260 --> 00:38:51.620]   But it also has this romantic element
[00:38:51.620 --> 00:38:54.180]   in the sense of a relationship between a man and a woman
[00:38:54.180 --> 00:38:55.640]   who's, that's very intriguing.
[00:38:55.640 --> 00:38:58.140]   It's not only that there's a,
[00:38:58.140 --> 00:39:00.420]   I would say, almost rape scene, right?
[00:39:00.420 --> 00:39:03.620]   I would say, but it's also that this woman
[00:39:03.620 --> 00:39:04.940]   is hard to understand.
[00:39:04.940 --> 00:39:06.860]   I mean, I've read it more than once,
[00:39:06.860 --> 00:39:09.460]   and I still can't quite figure out Dominique, right?
[00:39:09.460 --> 00:39:11.620]   Because she loves him and she wants to destroy him,
[00:39:11.620 --> 00:39:12.980]   and she marries other people.
[00:39:12.980 --> 00:39:14.220]   I mean, think about that too.
[00:39:14.220 --> 00:39:16.220]   Here, she's writing a book in the 1940s.
[00:39:16.220 --> 00:39:19.820]   There's lots of sex.
[00:39:19.820 --> 00:39:23.660]   There's a woman who marries more than one person,
[00:39:23.660 --> 00:39:25.840]   has having sex with more than one person.
[00:39:25.840 --> 00:39:27.320]   Very unconventional.
[00:39:27.320 --> 00:39:29.860]   She's having sex with Rourke,
[00:39:29.860 --> 00:39:31.080]   even though she's not married to Rourke.
[00:39:31.080 --> 00:39:33.100]   This is 1945.
[00:39:33.100 --> 00:39:36.920]   And it's very jarring to people.
[00:39:36.920 --> 00:39:39.840]   It's very unexpected, but it's also a book of its time.
[00:39:39.840 --> 00:39:42.400]   It's about individuals pursuing their passion,
[00:39:42.400 --> 00:39:45.560]   pursuing their life, and not caring about convention
[00:39:45.560 --> 00:39:49.560]   and what people think, but doing what they think is right.
[00:39:52.780 --> 00:39:55.500]   So I think it's, I encourage everybody to read it,
[00:39:55.500 --> 00:39:56.340]   obviously.
[00:39:56.340 --> 00:39:59.380]   - So was that the first time she articulated
[00:39:59.380 --> 00:40:04.940]   something that sounded like a philosophy of individualism?
[00:40:04.940 --> 00:40:08.680]   - I mean, the philosophy's there in "We the Living," right?
[00:40:08.680 --> 00:40:12.660]   Because at the end of the day, the woman is,
[00:40:12.660 --> 00:40:16.100]   the hero of "We the Living" is this individualist
[00:40:16.100 --> 00:40:18.340]   stuck in Soviet Union, so she's struggling
[00:40:18.340 --> 00:40:19.280]   with these things.
[00:40:20.300 --> 00:40:22.440]   So the theme is there already.
[00:40:22.440 --> 00:40:23.960]   It's not as fleshed out.
[00:40:23.960 --> 00:40:26.400]   It's not as articulated philosophically.
[00:40:26.400 --> 00:40:27.720]   And it's certainly there in "Anthem,"
[00:40:27.720 --> 00:40:31.400]   which is a dystopian novel, where this dystopia
[00:40:31.400 --> 00:40:35.720]   in the future has, there's no I.
[00:40:35.720 --> 00:40:36.720]   Everything is we.
[00:40:36.720 --> 00:40:40.960]   And it's about one guy who breaks out of that.
[00:40:40.960 --> 00:40:43.500]   I don't wanna give it away, but breaks out of that.
[00:40:43.500 --> 00:40:48.080]   So these themes are running, and then we have,
[00:40:48.080 --> 00:40:50.800]   and they've been published, some of the early Ayn Rand
[00:40:50.800 --> 00:40:53.960]   stories that she was writing in preparation
[00:40:53.960 --> 00:40:56.000]   for writing her novel, stories she was writing
[00:40:56.000 --> 00:40:57.320]   when she first came to America.
[00:40:57.320 --> 00:41:01.160]   And you can see these same philosophical elements,
[00:41:01.160 --> 00:41:03.840]   even in the male-female relationships,
[00:41:03.840 --> 00:41:07.160]   and the compassion, and the, you know,
[00:41:07.160 --> 00:41:10.880]   in the conflict, you see them even in those early pieces.
[00:41:10.880 --> 00:41:12.360]   And she's just developing them.
[00:41:12.360 --> 00:41:13.920]   It's the same philosophically.
[00:41:13.920 --> 00:41:17.800]   She's developing her philosophy with her literature.
[00:41:17.800 --> 00:41:20.040]   And of course, after "The Fountainhead,"
[00:41:20.040 --> 00:41:22.520]   she starts on what turns out to be her magnus opus,
[00:41:22.520 --> 00:41:25.500]   which is "Atlas Shrugged," which takes her 12 years
[00:41:25.500 --> 00:41:26.340]   to publish.
[00:41:26.340 --> 00:41:28.680]   By the time, of course, she brings that out,
[00:41:28.680 --> 00:41:31.040]   every publisher in New York wants to publish it,
[00:41:31.040 --> 00:41:34.240]   because "The Fountainhead" has been such a huge success.
[00:41:34.240 --> 00:41:35.360]   They don't quite understand it.
[00:41:35.360 --> 00:41:37.120]   They don't know what to do with "Atlas Shrugged,"
[00:41:37.120 --> 00:41:39.760]   but they're eager to get it out there.
[00:41:39.760 --> 00:41:41.320]   And indeed, when it's published,
[00:41:41.320 --> 00:41:43.560]   it becomes an instant bestseller.
[00:41:43.560 --> 00:41:45.600]   And the thing about the, particularly "The Fountainhead"
[00:41:45.600 --> 00:41:47.920]   and "Atlas Shrugged," but true of even "Anthem"
[00:41:47.920 --> 00:41:52.920]   and "We the Living," she is one of the only dead authors
[00:41:52.920 --> 00:41:55.400]   that sell more after they've died
[00:41:55.400 --> 00:41:56.320]   than when they was alive.
[00:41:56.320 --> 00:41:58.520]   Now, you know, that's true maybe in music.
[00:41:58.520 --> 00:42:00.440]   We listen to more Beethoven than when he was alive,
[00:42:00.440 --> 00:42:03.000]   but it's not true typically of novelists.
[00:42:03.000 --> 00:42:08.000]   And yet here we are, you know, what is it, 50,
[00:42:08.000 --> 00:42:11.520]   you know, 60 years after, 63 years after the publication
[00:42:11.520 --> 00:42:15.200]   of "Atlas Shrugged," and it sells probably more today
[00:42:15.200 --> 00:42:16.520]   than it sold when it was a bestseller
[00:42:16.520 --> 00:42:17.600]   when it first came out.
[00:42:17.600 --> 00:42:21.600]   - Is it true that it's like one of the most sold books
[00:42:21.600 --> 00:42:22.440]   in history?
[00:42:22.440 --> 00:42:23.840]   - No. - Okay.
[00:42:23.840 --> 00:42:25.200]   I've heard this kind of statement.
[00:42:25.200 --> 00:42:27.200]   - Any Tom Clancy book comes out,
[00:42:27.200 --> 00:42:28.600]   sells more than "Atlas Shrugged."
[00:42:28.600 --> 00:42:31.680]   - But I've never read, I've heard statements like this.
[00:42:31.680 --> 00:42:33.880]   - So there was a very, and I shouldn't say this,
[00:42:33.880 --> 00:42:35.320]   but it's the truth, so I'll say it,
[00:42:35.320 --> 00:42:40.320]   a very unscientific study done by the Smithsonian Institute,
[00:42:40.320 --> 00:42:42.760]   probably in the early '90s,
[00:42:42.760 --> 00:42:47.280]   that basically surveyed CEOs and asked them,
[00:42:47.280 --> 00:42:49.340]   what was the most influential book on you?
[00:42:49.340 --> 00:42:53.520]   And "Atlas Shrugged" came out as number two,
[00:42:53.520 --> 00:42:57.080]   the second most influential book on CEOs in the country.
[00:42:57.080 --> 00:42:58.720]   But there's so many flaws in the study.
[00:42:58.720 --> 00:43:01.480]   One was, you want to guess what the number one book?
[00:43:01.480 --> 00:43:03.200]   - Bible? - The Bible.
[00:43:03.200 --> 00:43:05.760]   But the Bible was like, you know,
[00:43:05.760 --> 00:43:07.080]   so maybe they surveyed 100 people.
[00:43:07.080 --> 00:43:07.920]   I don't know what the exact numbers were,
[00:43:07.920 --> 00:43:09.880]   but let's say it's 100 people,
[00:43:09.880 --> 00:43:12.960]   and 60 said the Bible, and 10 said "Atlas Shrugged,"
[00:43:12.960 --> 00:43:15.040]   and there were a bunch of books over here.
[00:43:15.040 --> 00:43:16.280]   So, you know, I don't--
[00:43:16.280 --> 00:43:18.080]   - That's, again, the psychology discussion
[00:43:18.080 --> 00:43:18.920]   we're having right now.
[00:43:18.920 --> 00:43:21.600]   - Exactly, well, and it's, one thing I've learned,
[00:43:21.600 --> 00:43:23.200]   and maybe COVID has taught me,
[00:43:23.200 --> 00:43:27.040]   and nobody, you know, there are very few people
[00:43:27.040 --> 00:43:29.560]   who know how to do statistics,
[00:43:29.560 --> 00:43:33.360]   and almost nobody knows how to think probabilistically.
[00:43:33.360 --> 00:43:35.560]   That is, think in terms of probabilities,
[00:43:35.560 --> 00:43:38.220]   that it is a skill, it's a hard skill.
[00:43:38.220 --> 00:43:39.600]   And everybody thinks they know it,
[00:43:39.600 --> 00:43:42.320]   but I see doctors thinking they're statisticians,
[00:43:42.320 --> 00:43:45.400]   and giving whole analyses of the data on COVID,
[00:43:45.400 --> 00:43:46.960]   and they don't have a clue what they're talking about.
[00:43:46.960 --> 00:43:48.520]   Not because they're not good doctors,
[00:43:48.520 --> 00:43:49.960]   but because they're not good statisticians.
[00:43:49.960 --> 00:43:53.680]   It's not, you know, people think that they have one skill,
[00:43:53.680 --> 00:43:55.960]   and therefore it translates immediately into another skill,
[00:43:55.960 --> 00:43:57.280]   and it's just not true.
[00:43:57.280 --> 00:44:01.840]   So I've been astounded at how bad people are at that.
[00:44:01.840 --> 00:44:05.800]   - For people who haven't read any of the books
[00:44:05.800 --> 00:44:07.240]   that we were just discussing,
[00:44:09.240 --> 00:44:11.480]   what would you recommend,
[00:44:11.480 --> 00:44:14.120]   what book would you recommend they read?
[00:44:14.120 --> 00:44:17.160]   And maybe also just elaborate,
[00:44:17.160 --> 00:44:20.640]   what mindset should they enter
[00:44:20.640 --> 00:44:22.820]   the reading of that book with?
[00:44:22.820 --> 00:44:25.240]   - So I would recommend everybody read
[00:44:25.240 --> 00:44:26.920]   "Fountainhead" and "Atlas Shrugged."
[00:44:26.920 --> 00:44:29.000]   And in one-- - In that order?
[00:44:29.000 --> 00:44:31.640]   - So it would depend on where you are in life, right?
[00:44:31.640 --> 00:44:35.280]   So it depends on who you are and what you are.
[00:44:35.280 --> 00:44:38.200]   So "Fountainhead" is a more personal story.
[00:44:38.200 --> 00:44:39.680]   For many people, it's their favorite,
[00:44:39.680 --> 00:44:41.440]   and for many people, it was their first book,
[00:44:41.440 --> 00:44:44.000]   and they wouldn't replace that, right?
[00:44:44.000 --> 00:44:50.840]   If "Atlas Shrugged" is a, it's about the world.
[00:44:50.840 --> 00:44:54.040]   It's about what impacts the world,
[00:44:54.040 --> 00:44:57.760]   how the world functions, how it's a bigger book
[00:44:57.760 --> 00:44:59.200]   in the sense of the scope.
[00:44:59.200 --> 00:45:01.600]   If you're interested in politics,
[00:45:01.600 --> 00:45:03.640]   and you're interested in the world,
[00:45:03.640 --> 00:45:05.480]   read "Atlas Shrugged" first.
[00:45:05.480 --> 00:45:08.120]   If you're mainly focused on your life, your career,
[00:45:08.120 --> 00:45:10.400]   what you wanna do with yourself, start with "Fountainhead."
[00:45:10.400 --> 00:45:12.040]   I still think you should read both,
[00:45:12.040 --> 00:45:14.520]   because I think they are, I mean, to me,
[00:45:14.520 --> 00:45:17.880]   they were life-altering, and to many, many people,
[00:45:17.880 --> 00:45:20.760]   they're life-altering, and you should go into reading them
[00:45:20.760 --> 00:45:24.520]   with an open mind, I'd say, and with a,
[00:45:24.520 --> 00:45:27.040]   put aside everything you've heard about Ayn Rand.
[00:45:27.040 --> 00:45:30.560]   Put aside any, even if it's true, just put it aside.
[00:45:30.560 --> 00:45:33.280]   Even what I just said about Ayn Rand, put it aside.
[00:45:33.280 --> 00:45:36.920]   Just read the book as a book, and let it move you,
[00:45:36.920 --> 00:45:41.720]   and let your thoughts, let it shape how you think,
[00:45:41.720 --> 00:45:46.440]   and it'll have, it either have,
[00:45:46.440 --> 00:45:49.000]   you'll either have a response to it, or you won't.
[00:45:49.000 --> 00:45:52.160]   But I think most people have a very strong response to it.
[00:45:52.160 --> 00:45:55.560]   And then the question is, do they,
[00:45:55.560 --> 00:45:57.320]   are they willing to respond to the philosophy?
[00:45:57.320 --> 00:45:58.720]   Are they willing to integrate the philosophy?
[00:45:58.720 --> 00:46:01.720]   Are they willing to think through the philosophy, or not?
[00:46:01.720 --> 00:46:03.960]   Because I know a lot of people who completely disagree
[00:46:03.960 --> 00:46:06.360]   with the philosophy, right?
[00:46:06.360 --> 00:46:07.640]   Here in Hollywood, right?
[00:46:07.640 --> 00:46:11.400]   Lots of people here in Hollywood love "The Fountainhead."
[00:46:11.400 --> 00:46:12.240]   - Interesting.
[00:46:12.240 --> 00:46:16.760]   - Oliver Stone, who is, I think, a avowed Marxist, right?
[00:46:16.760 --> 00:46:19.440]   I think he's admitted to being a Marxist.
[00:46:19.440 --> 00:46:23.240]   He is, his movies certainly reflect the Marxist theme,
[00:46:23.240 --> 00:46:27.320]   is a huge fan of "The Fountainhead,"
[00:46:27.320 --> 00:46:30.400]   and is actually, his dream project, he has said in public,
[00:46:30.400 --> 00:46:33.080]   his dream project is to make "The Fountainhead."
[00:46:33.080 --> 00:46:37.560]   Now, he would completely change it, as movie directors do,
[00:46:37.560 --> 00:46:40.080]   and he's actually outlined what his script would look like,
[00:46:40.080 --> 00:46:43.520]   and it would be a disaster for the ideas of the,
[00:46:43.520 --> 00:46:45.280]   but he loves the story, because to him,
[00:46:45.280 --> 00:46:47.520]   the story is about artistic integrity.
[00:46:47.520 --> 00:46:49.320]   - Yeah.
[00:46:49.320 --> 00:46:50.240]   - And that's what he catches on.
[00:46:50.240 --> 00:46:53.120]   And what he hates about the story is the individualism.
[00:46:53.120 --> 00:46:56.920]   And I think that his movie ends with Howard Rourke
[00:46:56.920 --> 00:46:59.520]   joining some kind of commune of architects
[00:46:59.520 --> 00:47:02.120]   that do it for the love and don't do it for the money.
[00:47:02.120 --> 00:47:03.080]   - Interesting.
[00:47:03.080 --> 00:47:05.160]   So yeah, so he can connect with you without the philosophy.
[00:47:05.160 --> 00:47:07.800]   And before we get into the philosophy,
[00:47:07.800 --> 00:47:09.160]   staying on Ayn Rand,
[00:47:09.160 --> 00:47:12.760]   I'll tell you sort of my own personal experience,
[00:47:12.760 --> 00:47:15.120]   and I think it's one that people share.
[00:47:15.120 --> 00:47:18.120]   I've experienced this with two people, Ayn Rand and Nietzsche.
[00:47:18.120 --> 00:47:24.000]   When I brought up Ayn Rand when I was in my early 20s,
[00:47:24.000 --> 00:47:29.000]   the number of eye rolls I got from advisors and so on,
[00:47:30.800 --> 00:47:34.280]   that of dismissal.
[00:47:34.280 --> 00:47:38.200]   I've seen that later in life about more specific concepts
[00:47:38.200 --> 00:47:39.920]   in artificial intelligence and technical,
[00:47:39.920 --> 00:47:43.400]   where people decide that this is a set of ideas
[00:47:43.400 --> 00:47:46.320]   that are acceptable, and these sets of ideas are not.
[00:47:46.320 --> 00:47:48.880]   And they dismissed Ayn Rand
[00:47:48.880 --> 00:47:52.960]   without giving me any justification
[00:47:52.960 --> 00:47:55.680]   of why they dismissed her,
[00:47:55.680 --> 00:47:58.800]   except, oh, that's something you're into
[00:47:58.800 --> 00:48:01.800]   when you're 19 or 20.
[00:48:01.800 --> 00:48:03.480]   Same thing people say about Nietzsche.
[00:48:03.480 --> 00:48:06.520]   Well, that's just something you do when you're in college
[00:48:06.520 --> 00:48:09.600]   and you take an intro to philosophy course.
[00:48:09.600 --> 00:48:14.600]   So I've never really heard anybody cleanly articulate
[00:48:14.600 --> 00:48:18.400]   their opposition to Ayn Rand
[00:48:18.400 --> 00:48:21.240]   in my own private little circles and so on.
[00:48:21.240 --> 00:48:23.840]   Maybe one question I just want to ask is,
[00:48:23.840 --> 00:48:28.600]   why is there such a opposition to Ayn Rand?
[00:48:28.600 --> 00:48:31.560]   And maybe another way to ask the same thing is,
[00:48:31.560 --> 00:48:35.120]   what's misunderstood about Ayn Rand?
[00:48:35.120 --> 00:48:37.400]   - So we haven't talked about the philosophy,
[00:48:37.400 --> 00:48:39.000]   so it's harder to answer right now.
[00:48:39.000 --> 00:48:40.160]   - We can return to it if you think
[00:48:40.160 --> 00:48:41.400]   that's the right way to go.
[00:48:41.400 --> 00:48:43.320]   - Well, let me give a broad answer,
[00:48:43.320 --> 00:48:45.120]   and then we'll do the philosophy,
[00:48:45.120 --> 00:48:45.960]   and then we'll return to it,
[00:48:45.960 --> 00:48:47.440]   'cause I think it's important to know
[00:48:47.440 --> 00:48:49.400]   something about her ideas.
[00:48:49.400 --> 00:48:54.400]   She, I think her philosophy challenges everything.
[00:48:54.400 --> 00:48:56.840]   It really does.
[00:48:56.840 --> 00:48:58.200]   It shakes up the world.
[00:48:58.200 --> 00:49:01.520]   It challenges so many of our preconceptions.
[00:49:01.520 --> 00:49:03.520]   It challenges so many of the things
[00:49:03.520 --> 00:49:06.440]   that people take for granted as truth.
[00:49:06.440 --> 00:49:11.640]   From religion to morality to politics to almost everything,
[00:49:11.640 --> 00:49:13.760]   there's never quite been a thinker like her
[00:49:13.760 --> 00:49:17.240]   in the sense of really challenging everything
[00:49:17.240 --> 00:49:18.520]   and doing it systematically,
[00:49:18.520 --> 00:49:21.400]   and having a complete philosophy
[00:49:21.400 --> 00:49:23.960]   that is a challenge to everything that has come before her.
[00:49:23.960 --> 00:49:27.680]   Now, I'm not saying they're on threads that connect.
[00:49:27.680 --> 00:49:28.520]   They are, right?
[00:49:28.520 --> 00:49:30.120]   In politics, there might be a thread,
[00:49:30.120 --> 00:49:31.760]   and in morality, there might be a thread,
[00:49:31.760 --> 00:49:34.800]   but on everything, there's just never been like it,
[00:49:34.800 --> 00:49:37.960]   and people are afraid of that
[00:49:37.960 --> 00:49:39.800]   because it challenges them to the core.
[00:49:39.800 --> 00:49:42.640]   She's basically telling you to rethink almost everything,
[00:49:42.640 --> 00:49:47.800]   and that is, that people reject.
[00:49:47.800 --> 00:49:49.560]   The other thing that it does,
[00:49:49.560 --> 00:49:51.560]   and this goes to this point about,
[00:49:51.560 --> 00:49:54.280]   oh yeah, that's what you do when you're 14, 15, right?
[00:49:55.600 --> 00:49:59.540]   She points out to them that they've lost something.
[00:49:59.540 --> 00:50:02.040]   They've lost their idealism.
[00:50:02.040 --> 00:50:05.960]   They've lost their youthful idealism.
[00:50:05.960 --> 00:50:10.000]   What makes youthfulness meaningful,
[00:50:10.000 --> 00:50:13.320]   other than we're in better physical shape,
[00:50:13.320 --> 00:50:15.440]   starting to feel, 'cause I'm getting older?
[00:50:15.440 --> 00:50:21.400]   When we're young, sometime in the teen years,
[00:50:21.400 --> 00:50:24.560]   there's something that happens to human consciousness.
[00:50:24.560 --> 00:50:27.240]   We almost awaken anew, right?
[00:50:27.240 --> 00:50:30.800]   We suddenly discover that we can think for ourselves.
[00:50:30.800 --> 00:50:33.400]   We suddenly discover that not everything
[00:50:33.400 --> 00:50:36.160]   our parents and our teachers tell us is true.
[00:50:36.160 --> 00:50:39.440]   We suddenly discover that this tool, our minds,
[00:50:39.440 --> 00:50:42.680]   is suddenly available to us to discover the world
[00:50:42.680 --> 00:50:46.640]   and to discover truth, and it is a time of idealism.
[00:50:46.640 --> 00:50:49.760]   It's a time of, whoa, I wanna, you know,
[00:50:49.760 --> 00:50:52.240]   the better teenagers, I wanna know about the world.
[00:50:52.240 --> 00:50:53.200]   I wanna go out there.
[00:50:53.200 --> 00:50:54.320]   I don't believe my parents.
[00:50:54.320 --> 00:50:56.360]   I don't believe my teachers, and this is healthy.
[00:50:56.360 --> 00:50:59.800]   This is fantastic, and I wanna go out there and experiment,
[00:50:59.800 --> 00:51:01.440]   and that gets us into trouble, right?
[00:51:01.440 --> 00:51:03.400]   We do stupid things when we're teenagers.
[00:51:03.400 --> 00:51:05.080]   Why? 'Cause we're experimenting.
[00:51:05.080 --> 00:51:06.740]   It's the experiential part of it, right?
[00:51:06.740 --> 00:51:10.000]   We wanna go and experience life, but we're learning.
[00:51:10.000 --> 00:51:11.400]   It's part of the learning process,
[00:51:11.400 --> 00:51:15.400]   and we become risk-takers because we wanna experience,
[00:51:15.400 --> 00:51:16.960]   but the risk is something we need to learn,
[00:51:16.960 --> 00:51:19.360]   'cause we need to learn where the boundaries are,
[00:51:19.360 --> 00:51:21.780]   and one of the damages that helicopter parents do
[00:51:21.780 --> 00:51:23.200]   is they prevent us from taking those risks
[00:51:23.200 --> 00:51:24.400]   so we don't learn about the world
[00:51:24.400 --> 00:51:26.560]   and we don't learn about where the boundaries are,
[00:51:26.560 --> 00:51:30.400]   so the teenage years are these years of wonder.
[00:51:30.400 --> 00:51:32.720]   They're depressing when you're in them
[00:51:32.720 --> 00:51:33.720]   for a variety of reasons,
[00:51:33.720 --> 00:51:35.440]   which I think primarily have to do with the culture,
[00:51:35.440 --> 00:51:39.640]   but also with oneself, but they are exciting,
[00:51:39.640 --> 00:51:42.000]   the periods of discovery,
[00:51:42.000 --> 00:51:45.440]   and people get excited about ideas,
[00:51:45.440 --> 00:51:48.640]   and good ideas, bad ideas, all kinds of ideas,
[00:51:48.640 --> 00:51:50.280]   and then what happens?
[00:51:50.280 --> 00:51:53.760]   We settle, we compromise.
[00:51:53.760 --> 00:51:55.800]   Whether that happens in college,
[00:51:55.800 --> 00:51:58.160]   where we're taught that nothing exists and nothing matters,
[00:51:58.160 --> 00:52:01.900]   and start being, be a nihilist, be a cynic, be whatever,
[00:52:01.900 --> 00:52:04.400]   or whether it happens when we get married and get a job
[00:52:04.400 --> 00:52:05.680]   and have kids and are too busy
[00:52:05.680 --> 00:52:07.480]   and can't think about our ideals and forget
[00:52:07.480 --> 00:52:10.460]   and just get into the norm of conventional life,
[00:52:10.460 --> 00:52:14.000]   or whether it's because a mother pesters us
[00:52:14.000 --> 00:52:15.060]   to get married and have kids
[00:52:15.060 --> 00:52:17.920]   and do all the things that she wanted us to do,
[00:52:17.920 --> 00:52:20.360]   we give up on those ideals,
[00:52:20.360 --> 00:52:24.880]   and there's a sense in which Ayn Rand reminds them
[00:52:24.880 --> 00:52:25.920]   that they gave up.
[00:52:25.920 --> 00:52:27.840]   - That's beautifully, that's so beautifully put,
[00:52:27.840 --> 00:52:28.920]   and so true.
[00:52:28.920 --> 00:52:34.320]   It's worth pausing on,
[00:52:34.320 --> 00:52:38.520]   that this dismissal,
[00:52:38.520 --> 00:52:41.640]   people forget the beauty of that curiosity.
[00:52:41.640 --> 00:52:43.640]   That's true in the scientific field too,
[00:52:47.440 --> 00:52:51.880]   that youthful joy of everything is possible
[00:52:51.880 --> 00:52:56.200]   and we can understand it with the tools of our mind.
[00:52:56.200 --> 00:52:57.880]   - Yes, and that's what it's all about.
[00:52:57.880 --> 00:52:59.580]   That's what Ayn Rand's ideas at the end of the day
[00:52:59.580 --> 00:53:02.560]   all boil down to, is that confidence and that passion
[00:53:02.560 --> 00:53:05.320]   and that curiosity and that interest.
[00:53:05.320 --> 00:53:08.840]   And if you, think about what academia does
[00:53:08.840 --> 00:53:10.320]   to so many of us.
[00:53:10.320 --> 00:53:12.760]   We go into academia and we're excited about it.
[00:53:12.760 --> 00:53:16.200]   We're gonna learn stuff, we're gonna discover things.
[00:53:16.200 --> 00:53:18.400]   And then they stick you into sub-sub field
[00:53:18.400 --> 00:53:21.520]   and examining some minutiae that's insignificant
[00:53:21.520 --> 00:53:22.840]   and unimportant.
[00:53:22.840 --> 00:53:25.560]   And to get published, you have to be conventional,
[00:53:25.560 --> 00:53:27.080]   you have to do what everybody else does.
[00:53:27.080 --> 00:53:29.640]   And then there's the tenure process of seven years
[00:53:29.640 --> 00:53:32.200]   where they put you through this torture to write papers
[00:53:32.200 --> 00:53:34.160]   that fit into a certain mold.
[00:53:34.160 --> 00:53:38.080]   And by the time you're done, you're in your mid-30s
[00:53:38.080 --> 00:53:39.900]   and you've done nothing, you discovered nothing.
[00:53:39.900 --> 00:53:43.040]   You're all in this minutiae in this stuff
[00:53:43.040 --> 00:53:44.320]   and it's destructive.
[00:53:44.320 --> 00:53:48.080]   And with holding onto that passion,
[00:53:48.080 --> 00:53:52.200]   holding onto that knowledge and that confidence is hard.
[00:53:52.200 --> 00:53:55.480]   And when people do away with it, they become cynical.
[00:53:55.480 --> 00:53:57.320]   And they become part of the system
[00:53:57.320 --> 00:54:00.320]   and they inflict the same pain on the next guy
[00:54:00.320 --> 00:54:03.440]   that they suffered because that's part of how it works.
[00:54:03.440 --> 00:54:06.020]   - Yeah, this happens in artificial intelligence.
[00:54:06.020 --> 00:54:08.920]   This happens when a young person shows up
[00:54:08.920 --> 00:54:11.600]   and with fire in their eyes and they say,
[00:54:11.600 --> 00:54:14.600]   I wanna understand the nature of intelligence.
[00:54:14.600 --> 00:54:17.120]   And everybody rolls their eyes.
[00:54:17.120 --> 00:54:20.320]   Well, for these same reasons,
[00:54:20.320 --> 00:54:21.880]   because they've spent so many years
[00:54:21.880 --> 00:54:25.120]   on the very specific set of questions
[00:54:25.120 --> 00:54:30.120]   that they compete over and they write papers over
[00:54:30.120 --> 00:54:31.720]   and they have conferences about.
[00:54:31.720 --> 00:54:34.100]   And it's true, that incremental research
[00:54:34.100 --> 00:54:35.280]   is the way you make progress,
[00:54:35.280 --> 00:54:37.200]   answering the question of what is intelligence
[00:54:37.200 --> 00:54:38.880]   is exceptionally difficult.
[00:54:38.880 --> 00:54:43.880]   But when you mock it, you actually destroy the realities.
[00:54:43.880 --> 00:54:47.920]   When we look centuries from now,
[00:54:47.920 --> 00:54:49.360]   we'll look back at this time
[00:54:49.360 --> 00:54:52.680]   for this particular field of artificial intelligence,
[00:54:52.680 --> 00:54:55.560]   it will be the people who will be remembered
[00:54:55.560 --> 00:54:58.080]   will be the people who've asked the question
[00:54:58.080 --> 00:55:01.560]   and made it their life journey of what is intelligence
[00:55:01.560 --> 00:55:04.800]   and actually had the chance to succeed.
[00:55:04.800 --> 00:55:06.720]   Most will fail asking that question,
[00:55:06.880 --> 00:55:09.520]   but the ones that had a chance of succeeding
[00:55:09.520 --> 00:55:11.840]   and had that throughout their whole life.
[00:55:11.840 --> 00:55:15.120]   And I suppose the same is true for philosophy.
[00:55:15.120 --> 00:55:16.080]   - It's in every field.
[00:55:16.080 --> 00:55:20.200]   It's asking the big questions and staying curious
[00:55:20.200 --> 00:55:22.880]   and staying passionate and staying excited
[00:55:22.880 --> 00:55:26.120]   and accepting failure, right?
[00:55:26.120 --> 00:55:27.920]   Accepting that you're not gonna get it first time,
[00:55:27.920 --> 00:55:29.640]   you're not gonna get the whole thing.
[00:55:29.640 --> 00:55:31.880]   But and sometimes you have to do the minutiae work
[00:55:31.880 --> 00:55:34.320]   and I'm not here to say nobody should specialize
[00:55:34.320 --> 00:55:36.680]   and you shouldn't do the minutiae, you have to do that.
[00:55:36.680 --> 00:55:38.800]   But there has to be a way to do that work
[00:55:38.800 --> 00:55:41.920]   and keep the passion and keep it all integrated.
[00:55:41.920 --> 00:55:42.760]   That's another thing.
[00:55:42.760 --> 00:55:46.440]   I mean, we don't live in a culture that integrates, right?
[00:55:46.440 --> 00:55:51.040]   We live in a culture that is all about this minutiae
[00:55:51.040 --> 00:55:53.560]   and medicine is another field
[00:55:53.560 --> 00:55:55.360]   where you specialize in the kidney.
[00:55:55.360 --> 00:55:57.000]   I mean, the kidney is connected to other things.
[00:55:57.000 --> 00:55:59.880]   You've gotta, and we don't have a holistic view
[00:55:59.880 --> 00:56:02.240]   of these things and I'm sure in artificial intelligence,
[00:56:02.240 --> 00:56:05.000]   you're not gonna make the big leaps forward
[00:56:05.000 --> 00:56:08.000]   without a holistic view of what it is
[00:56:08.000 --> 00:56:08.880]   you're trying to achieve.
[00:56:08.880 --> 00:56:10.720]   And maybe that's the question, what is intelligence?
[00:56:10.720 --> 00:56:14.320]   But that's the kind of questions you have to ask
[00:56:14.320 --> 00:56:17.400]   to make big leaps forward, to really move the field
[00:56:17.400 --> 00:56:19.160]   in a positive direction.
[00:56:19.160 --> 00:56:21.960]   And it's the people who can think that way,
[00:56:21.960 --> 00:56:25.640]   who move fields and move technology, move anything.
[00:56:25.640 --> 00:56:27.360]   Anything is, everything is like--
[00:56:27.360 --> 00:56:28.840]   - Which is just like you said, it's painful
[00:56:28.840 --> 00:56:32.660]   because underlying that kind of questioning is,
[00:56:32.660 --> 00:56:35.360]   well, maybe the work I've done for the past 20 years
[00:56:35.360 --> 00:56:40.100]   was a dead end and you have to kind of face that.
[00:56:40.100 --> 00:56:42.080]   Even just, it might not be true,
[00:56:42.080 --> 00:56:44.220]   but even just facing that reality,
[00:56:44.220 --> 00:56:47.760]   it's just, it's a painful feeling.
[00:56:47.760 --> 00:56:50.600]   - Absolutely, but that's part of the reason
[00:56:50.600 --> 00:56:52.880]   why it's important to enjoy the work that you do.
[00:56:52.880 --> 00:56:54.800]   So that even if it doesn't completely work out,
[00:56:54.800 --> 00:56:55.640]   at least you enjoyed the process.
[00:56:55.640 --> 00:56:56.480]   - It was never a waste.
[00:56:56.480 --> 00:56:59.320]   - It was not a waste because you enjoyed the process.
[00:56:59.320 --> 00:57:02.780]   And if you learn, as any entrepreneur knows this,
[00:57:02.780 --> 00:57:05.540]   and if you learn from the waste of time,
[00:57:05.540 --> 00:57:07.580]   from the errors, from the mistakes,
[00:57:07.580 --> 00:57:10.620]   then you can build on them and make things even better.
[00:57:10.620 --> 00:57:15.620]   And so the next 20 years, I'm a massive success.
[00:57:15.620 --> 00:57:18.860]   - Can we, another impossible task.
[00:57:18.860 --> 00:57:22.660]   So you did wonderfully on talking about Ayn Rand.
[00:57:22.660 --> 00:57:25.980]   The other impossible task of giving a whirlwind overview
[00:57:25.980 --> 00:57:30.640]   of the philosophy of objectivism, the philosophy of Ayn Rand.
[00:57:30.640 --> 00:57:33.640]   - Yeah, so luckily she did it in an essay.
[00:57:33.640 --> 00:57:36.080]   She talks about doing her philosophy on one foot.
[00:57:36.080 --> 00:57:39.560]   But let me integrate it with the literature
[00:57:39.560 --> 00:57:41.820]   and with her life a little bit.
[00:57:41.820 --> 00:57:44.660]   She wanted to be a writer,
[00:57:44.660 --> 00:57:47.420]   but her goal, she had a particular goal in her writing.
[00:57:47.420 --> 00:57:50.200]   She was an idealist, right?
[00:57:50.200 --> 00:57:52.680]   She wanted to portray the ideal man.
[00:57:55.160 --> 00:57:57.900]   So one of the things you do when you wanna do something
[00:57:57.900 --> 00:57:58.960]   is what is an ideal man?
[00:57:58.960 --> 00:58:00.240]   You have to ask that question.
[00:58:00.240 --> 00:58:01.200]   What does that mean?
[00:58:01.200 --> 00:58:03.140]   You might have a sense of it.
[00:58:03.140 --> 00:58:06.520]   You might have certain glimpses of it
[00:58:06.520 --> 00:58:08.780]   in other people's literature, but what is it?
[00:58:08.780 --> 00:58:12.100]   So she starts reading philosophy to try to figure out
[00:58:12.100 --> 00:58:15.100]   what do philosophers say about the ideal man.
[00:58:15.100 --> 00:58:16.940]   And what she finds horrifies her
[00:58:16.940 --> 00:58:19.040]   in terms of the view of most philosophers of man.
[00:58:19.040 --> 00:58:23.500]   And she's attracted, certainly when she's young, to Nietzsche
[00:58:23.500 --> 00:58:26.700]   because Nietzsche at least has a vision
[00:58:26.700 --> 00:58:30.380]   of grandeur for man, even though his philosophy
[00:58:30.380 --> 00:58:31.980]   is very flawed and has other problems
[00:58:31.980 --> 00:58:34.020]   and contradicts iron man in many ways.
[00:58:34.020 --> 00:58:38.020]   But at least he has that vision of what is possible to man.
[00:58:38.020 --> 00:58:40.100]   And she's attracted to that romantic vision,
[00:58:40.100 --> 00:58:42.100]   that idealistic vision.
[00:58:42.100 --> 00:58:43.620]   So she discovers in writing,
[00:58:43.620 --> 00:58:45.020]   and particularly in writing "Atlas Shrugged,"
[00:58:45.020 --> 00:58:46.660]   but even in "The Fountainhead,"
[00:58:46.660 --> 00:58:49.300]   that she's gonna have to develop her own philosophy.
[00:58:49.300 --> 00:58:52.780]   She's gonna have to discover these ideas for herself
[00:58:52.780 --> 00:58:55.860]   because they're not fully articulated anywhere else.
[00:58:55.860 --> 00:59:00.340]   The glimpses again of it in Aristotle, in Nietzsche,
[00:59:00.340 --> 00:59:02.060]   but they're not fully fleshed out.
[00:59:02.060 --> 00:59:05.820]   So to a large extent, she develops a philosophy
[00:59:05.820 --> 00:59:08.900]   for a very practical purpose, to write,
[00:59:08.900 --> 00:59:11.300]   to write a novel about the ideal man.
[00:59:11.300 --> 00:59:14.580]   And "Atlas Shrugged" is the manifestation of that.
[00:59:14.580 --> 00:59:16.540]   - By the way, sorry to interrupt.
[00:59:16.540 --> 00:59:21.000]   As a little aside, she does, when you say man,
[00:59:21.000 --> 00:59:22.460]   you mean human.
[00:59:22.460 --> 00:59:26.340]   And because we'll bring this up often,
[00:59:26.340 --> 00:59:28.860]   she does, I mean, maybe you can elaborate
[00:59:28.860 --> 00:59:33.380]   of how she specifically uses man and he in the work.
[00:59:33.380 --> 00:59:36.260]   We live in a time now of gender.
[00:59:36.260 --> 00:59:40.340]   - Well, she did that in the sense that everybody did it
[00:59:40.340 --> 00:59:41.520]   during her period of time, right?
[00:59:41.520 --> 00:59:45.380]   It's only in modern times where we do he/she, right?
[00:59:45.380 --> 00:59:48.620]   Historically, when you said he, you meant a human being,
[00:59:48.620 --> 00:59:51.600]   unless the particular context implied that it was a...
[00:59:51.600 --> 00:59:55.720]   But in Einran's case, in this case, in this one sentence,
[00:59:55.720 --> 00:59:57.360]   she probably meant man.
[00:59:57.360 --> 01:00:02.040]   Not that because she viewed that there are differences
[01:00:02.040 --> 01:00:03.840]   between men and women, were not the same,
[01:00:03.840 --> 01:00:06.080]   which I know comes as a shock to many people,
[01:00:06.080 --> 01:00:11.080]   but she--
[01:00:11.080 --> 01:00:12.400]   - She's working on a character.
[01:00:12.400 --> 01:00:15.480]   - She was working on a particular vision, right?
[01:00:15.480 --> 01:00:18.900]   She considered herself a man worshiper,
[01:00:18.900 --> 01:00:23.060]   and a man, not human being, a male.
[01:00:23.060 --> 01:00:28.060]   She worshipped manhood, if you will, the hero in man.
[01:00:28.060 --> 01:00:32.020]   And she wanted to fully understand what that was.
[01:00:32.020 --> 01:00:35.300]   Now, it has massive implications for ideal woman,
[01:00:35.300 --> 01:00:36.940]   and I think she does portray the ideal woman
[01:00:36.940 --> 01:00:40.860]   in Atlas Shrugged and the character of Dagny.
[01:00:40.860 --> 01:00:45.860]   But her goal is, I think her selfish goal
[01:00:45.860 --> 01:00:49.200]   for what she wanted to get out of the novel
[01:00:49.200 --> 01:00:52.620]   is that excitement, partially sexual,
[01:00:52.620 --> 01:00:56.240]   about seeing your ideal manifest in reality
[01:00:56.240 --> 01:01:00.960]   of what you perceive as that which you would be
[01:01:00.960 --> 01:01:04.720]   attracted to, fully, intellectually, physically,
[01:01:04.720 --> 01:01:06.640]   sexually, in every aspect of your life.
[01:01:06.640 --> 01:01:08.160]   That's what she's trying to bring into the novel.
[01:01:08.160 --> 01:01:09.840]   - So there was no ambiguity of gender,
[01:01:09.840 --> 01:01:12.840]   so there was a masculinity and a femininity in her work.
[01:01:12.840 --> 01:01:14.360]   - Very much so.
[01:01:14.360 --> 01:01:17.080]   And if you read the novels, you see that.
[01:01:17.080 --> 01:01:19.960]   Now, remember, this is in the context of,
[01:01:19.960 --> 01:01:22.840]   in Atlas Shrugged, she is portraying a woman
[01:01:22.840 --> 01:01:26.520]   who runs a railroad, the most masculine
[01:01:26.520 --> 01:01:28.480]   of all jobs you could imagine, right?
[01:01:28.480 --> 01:01:31.760]   Running a railroad, better than any man could run it.
[01:01:31.760 --> 01:01:33.440]   And achieving huge success,
[01:01:33.440 --> 01:01:35.840]   better than any other man out there.
[01:01:35.840 --> 01:01:40.840]   But, but for her, even Dagny needs somebody to,
[01:01:40.840 --> 01:01:47.360]   needs a man, in some sense, to look up to.
[01:01:47.360 --> 01:01:48.280]   - Yeah.
[01:01:48.280 --> 01:01:51.360]   - And that's the character whose name I will mention,
[01:01:51.360 --> 01:01:53.200]   because it gives away too much of the plot.
[01:01:53.200 --> 01:01:54.800]   But there has to be--
[01:01:54.800 --> 01:01:57.120]   - I like how you do that, you're good.
[01:01:57.120 --> 01:01:59.680]   You're not, a lot of practice, a lot of practice.
[01:01:59.680 --> 01:02:01.720]   - Nothing, brilliant, 'cause you convey
[01:02:01.720 --> 01:02:04.560]   all the important things without giving away plot lines.
[01:02:04.560 --> 01:02:05.880]   - That's beautiful, you're a master.
[01:02:05.880 --> 01:02:09.360]   - So she's, so she's very much,
[01:02:09.360 --> 01:02:14.360]   she, she described herself once as a male chauvinist.
[01:02:14.360 --> 01:02:16.240]   - Okay.
[01:02:16.240 --> 01:02:19.600]   - She very, she likes the idea of a man opening a door for her.
[01:02:19.600 --> 01:02:25.960]   But more metaphysically, she identifies something
[01:02:25.960 --> 01:02:29.040]   in the difference between a way a man relates to a woman
[01:02:29.040 --> 01:02:30.200]   and a woman relates to a man.
[01:02:30.200 --> 01:02:32.160]   It's not the same.
[01:02:32.160 --> 01:02:35.360]   - And let's not take too far of a tangent,
[01:02:35.360 --> 01:02:37.480]   but I just, as a side comment,
[01:02:37.480 --> 01:02:43.200]   to me, she represented, she was a feminist to me.
[01:02:43.200 --> 01:02:45.800]   Perhaps there's a, perhaps technically,
[01:02:45.800 --> 01:02:47.600]   Filosofsky, you disagree with that, whatever.
[01:02:47.600 --> 01:02:52.600]   But the, you know, that to me represented strong,
[01:02:52.600 --> 01:02:55.400]   like she had some of the strongest female characters
[01:02:55.400 --> 01:02:56.800]   in the history of literature.
[01:02:56.800 --> 01:03:00.200]   - Again, this is a woman running a railroad in 1957.
[01:03:00.200 --> 01:03:01.080]   - Yeah.
[01:03:01.080 --> 01:03:02.680]   - And not just a woman running a railroad,
[01:03:02.680 --> 01:03:05.080]   and this is true of the Fountainhead as well.
[01:03:05.080 --> 01:03:09.800]   A woman who is sexually, in a sense, assertive,
[01:03:09.800 --> 01:03:11.280]   sexually open.
[01:03:11.280 --> 01:03:15.760]   This is, this is not a woman who, you know,
[01:03:15.760 --> 01:03:20.480]   this is a woman who embraces her sexuality.
[01:03:20.480 --> 01:03:22.800]   And, you know, sex is important in life.
[01:03:22.800 --> 01:03:24.600]   This is why it keeps coming up, right?
[01:03:24.600 --> 01:03:25.960]   It was important to Ayn Rand.
[01:03:25.960 --> 01:03:27.440]   It was, it's important in the novels.
[01:03:27.440 --> 01:03:29.000]   It's important in life.
[01:03:29.000 --> 01:03:32.360]   And for her, one's attitude towards sex
[01:03:32.360 --> 01:03:34.520]   is a reflection of one's attitude towards life.
[01:03:34.520 --> 01:03:36.720]   And, you know, and what attitude towards pleasure,
[01:03:36.720 --> 01:03:38.400]   which is an important part of life.
[01:03:38.400 --> 01:03:41.920]   And she thought that was an incredibly important thing.
[01:03:41.920 --> 01:03:46.920]   And so she has these assertive, powerful, sexual women
[01:03:46.920 --> 01:03:53.920]   who live their lives on their terms 100%,
[01:03:53.920 --> 01:03:56.960]   who seek a man to look up to.
[01:03:56.960 --> 01:03:57.800]   - Yeah.
[01:03:57.800 --> 01:04:00.760]   - And now, this is psychologically complex.
[01:04:00.760 --> 01:04:02.320]   It's more psychology than philosophy, right?
[01:04:02.320 --> 01:04:03.680]   It's psychologically complex.
[01:04:03.680 --> 01:04:06.480]   And, you know, not my area of expertise,
[01:04:06.480 --> 01:04:08.640]   but this is, there's something,
[01:04:08.640 --> 01:04:11.640]   and she would argue there's something
[01:04:11.640 --> 01:04:14.400]   fundamentally different about a male and a woman,
[01:04:14.400 --> 01:04:16.160]   about a male and female,
[01:04:16.160 --> 01:04:18.880]   psychologically in their attitude towards one another.
[01:04:18.880 --> 01:04:22.000]   - Yeah, but as a side note, I say that,
[01:04:22.000 --> 01:04:25.520]   I would say that, I don't know, philosophically,
[01:04:25.520 --> 01:04:28.960]   if her ideas about gender are interesting,
[01:04:28.960 --> 01:04:30.760]   I think her other philosophical ideas
[01:04:30.760 --> 01:04:32.360]   are much more interesting.
[01:04:32.360 --> 01:04:36.240]   But reading-wise, like the stories it created,
[01:04:36.240 --> 01:04:39.520]   the tension it created, that was pretty powerful.
[01:04:39.520 --> 01:04:43.360]   I mean, that was, that's pretty powerful stuff.
[01:04:43.360 --> 01:04:45.680]   - I'll speculate that the reason it's so powerful
[01:04:45.680 --> 01:04:47.400]   is because it reflects something in reality.
[01:04:47.400 --> 01:04:48.680]   - Yeah, that's true.
[01:04:48.680 --> 01:04:50.160]   There's a thread that at least it pulls.
[01:04:50.160 --> 01:04:53.400]   - And look, it's really important to say,
[01:04:53.400 --> 01:04:56.120]   I think she was the first feminist in a sense.
[01:04:56.120 --> 01:04:59.360]   I think in a sense, the feminist that provoked feminism
[01:04:59.360 --> 01:05:00.800]   into something that it shouldn't be.
[01:05:00.800 --> 01:05:04.220]   But in the sense of men and women are capable,
[01:05:04.220 --> 01:05:08.600]   she was the first one who really put that
[01:05:08.600 --> 01:05:10.680]   into a novel and showed it.
[01:05:10.680 --> 01:05:15.560]   - To me, as a boy, when I was reading "Atlas Shrugged,"
[01:05:15.560 --> 01:05:18.200]   I think I read that before "Fountainhead,"
[01:05:18.200 --> 01:05:20.520]   that was one of the early introductions,
[01:05:20.520 --> 01:05:21.840]   at least if an American woman,
[01:05:21.840 --> 01:05:24.240]   I had examples in my own life for Russian women,
[01:05:24.240 --> 01:05:26.960]   but of like a badass lady.
[01:05:26.960 --> 01:05:30.240]   Like I admire, like I love engineering.
[01:05:30.240 --> 01:05:32.440]   I had loved it that she could,
[01:05:32.440 --> 01:05:34.400]   here's a lady that's running the show.
[01:05:34.400 --> 01:05:36.720]   So that at least to me was an example
[01:05:36.720 --> 01:05:37.960]   of a really strong woman.
[01:05:37.960 --> 01:05:39.040]   But objectivism.
[01:05:39.040 --> 01:05:39.880]   - Objectivism.
[01:05:39.880 --> 01:05:42.080]   So, and so she developed it for a novel.
[01:05:42.080 --> 01:05:44.040]   She spent the latter part of her life
[01:05:44.040 --> 01:05:45.440]   after the publication of "Atlas Shrugged"
[01:05:45.440 --> 01:05:46.880]   really articulating her philosophy.
[01:05:46.880 --> 01:05:47.800]   So that's what she did.
[01:05:47.800 --> 01:05:50.800]   She applied it to politics, to life, to gender,
[01:05:50.800 --> 01:05:54.280]   to all these issues from 1957 until she died in 1982.
[01:05:54.280 --> 01:05:56.120]   - So the objectivism was born
[01:05:56.120 --> 01:05:57.920]   out of the later parts of "Atlas Shrugged."
[01:05:57.920 --> 01:05:59.320]   - Yes, definitely.
[01:05:59.320 --> 01:06:00.480]   It was there all the time,
[01:06:00.480 --> 01:06:03.000]   but it was fleshed out during the latter parts
[01:06:03.000 --> 01:06:04.360]   of "Atlas Shrugged" and then articulated
[01:06:04.360 --> 01:06:05.200]   for the next 20 years.
[01:06:05.200 --> 01:06:06.680]   - So what is objectivism?
[01:06:06.680 --> 01:06:09.920]   - So objectivism, so there are five branches in philosophy.
[01:06:09.920 --> 01:06:13.200]   And so I'm gonna just go through the branches.
[01:06:13.200 --> 01:06:15.080]   She starts with, you start with metaphysics,
[01:06:15.080 --> 01:06:16.800]   the nature of reality.
[01:06:16.800 --> 01:06:20.240]   And objectivism argues that reality is what it is.
[01:06:20.240 --> 01:06:22.800]   It's kind of, it goes, harkens back to Aristotle,
[01:06:22.800 --> 01:06:23.800]   law of identity.
[01:06:23.800 --> 01:06:24.880]   A is A.
[01:06:24.880 --> 01:06:27.000]   You can wish it to be B,
[01:06:27.000 --> 01:06:29.440]   but wishes do not make something real.
[01:06:29.440 --> 01:06:32.640]   Reality is what it is and it is the primary.
[01:06:32.640 --> 01:06:37.400]   And it's not manipulated, directed by consciousness.
[01:06:37.400 --> 01:06:40.400]   Consciousness is there to observe,
[01:06:40.400 --> 01:06:45.880]   to give us information about reality.
[01:06:45.880 --> 01:06:48.200]   That is the purpose of consciousness.
[01:06:48.200 --> 01:06:50.360]   That is the nature of it.
[01:06:50.360 --> 01:06:54.600]   So in metaphysics, existence exists.
[01:06:54.600 --> 01:06:57.080]   The law of identity, the law of causality,
[01:06:57.080 --> 01:07:01.120]   the things act based on their nature,
[01:07:01.120 --> 01:07:04.640]   not randomly, not arbitrarily, but based on their nature.
[01:07:04.640 --> 01:07:08.480]   And then we have the tool to know reality.
[01:07:08.480 --> 01:07:11.480]   This is epistemology, the theory of knowledge.
[01:07:11.480 --> 01:07:14.400]   A tool to know reality is reason.
[01:07:14.400 --> 01:07:16.640]   It's our senses and our capacity
[01:07:16.640 --> 01:07:19.160]   to integrate the information we get from our senses
[01:07:19.160 --> 01:07:20.720]   and to integrate it into new knowledge
[01:07:20.720 --> 01:07:22.560]   and to conceptualize it.
[01:07:22.560 --> 01:07:25.240]   And that is uniquely human.
[01:07:25.240 --> 01:07:31.240]   We don't know the truth from revelation.
[01:07:31.240 --> 01:07:35.240]   We don't know truth from our emotions.
[01:07:35.240 --> 01:07:36.880]   Our emotions are interesting.
[01:07:36.880 --> 01:07:39.560]   Our emotions tell us something about ourselves.
[01:07:39.560 --> 01:07:42.360]   But our emotions are not tools of cognition.
[01:07:42.360 --> 01:07:45.200]   They don't tell us the truth about what's out there,
[01:07:45.200 --> 01:07:47.680]   about what's in reality.
[01:07:47.680 --> 01:07:50.880]   So reason is a means of knowledge,
[01:07:50.880 --> 01:07:53.360]   and therefore reason is a means of survival.
[01:07:53.360 --> 01:07:56.160]   Only individuals reason,
[01:07:56.160 --> 01:07:59.160]   just in the same way that only individuals can eat.
[01:07:59.160 --> 01:08:00.920]   We don't have a collective stomach.
[01:08:00.920 --> 01:08:03.440]   Nobody can eat for me,
[01:08:03.440 --> 01:08:05.720]   and therefore nobody can think for me.
[01:08:05.720 --> 01:08:07.280]   We don't have a collective mind.
[01:08:07.280 --> 01:08:09.400]   There's no collective consciousness.
[01:08:09.400 --> 01:08:11.800]   It's bizarre that people talk about
[01:08:11.800 --> 01:08:14.960]   these collectivized aspects of the mind.
[01:08:14.960 --> 01:08:16.680]   They don't talk about collective feet
[01:08:16.680 --> 01:08:18.800]   and collective stomachs and collective things.
[01:08:18.800 --> 01:08:21.800]   But so we all think for ourselves,
[01:08:21.800 --> 01:08:25.320]   and it is our fundamental basic responsibility
[01:08:25.320 --> 01:08:29.880]   to live our lives, to live, to choose.
[01:08:29.880 --> 01:08:31.040]   Once we choose to live,
[01:08:31.040 --> 01:08:34.160]   to live our lives to the best of our ability.
[01:08:34.160 --> 01:08:38.080]   So in morality, she is an egoist.
[01:08:38.080 --> 01:08:40.440]   She believes that the purpose of morality
[01:08:40.440 --> 01:08:43.560]   is to provide you with a code of values and virtues,
[01:08:43.560 --> 01:08:47.800]   to guide your life for the purpose of your own success,
[01:08:47.800 --> 01:08:51.120]   your own survival, your own thriving, your own happiness.
[01:08:51.120 --> 01:08:54.360]   Happiness is the moral purpose of your life.
[01:08:54.360 --> 01:08:55.960]   The purpose of morality is to guide you
[01:08:55.960 --> 01:08:57.760]   towards a happy life.
[01:08:57.760 --> 01:08:58.800]   - Your own happiness.
[01:08:58.800 --> 01:09:01.880]   - Your own happiness, absolutely, your own happiness.
[01:09:01.880 --> 01:09:04.880]   So she rejects the idea that she should live for other people,
[01:09:04.880 --> 01:09:06.240]   that you should live for the purpose
[01:09:06.240 --> 01:09:07.760]   of other people's happiness.
[01:09:07.760 --> 01:09:09.360]   Your purpose is not to make them happy
[01:09:09.360 --> 01:09:10.240]   or to make them anything.
[01:09:10.240 --> 01:09:12.040]   Your purpose is your own happiness.
[01:09:12.040 --> 01:09:14.560]   But she also rejects the idea
[01:09:14.560 --> 01:09:18.080]   that you could argue maybe the Nietzschean idea
[01:09:18.080 --> 01:09:20.960]   of you should use other people for your own purposes.
[01:09:20.960 --> 01:09:24.480]   So every person is an end in himself.
[01:09:24.480 --> 01:09:28.200]   Every person's moral responsibility is their own happiness.
[01:09:28.200 --> 01:09:30.160]   And you shouldn't use other people for your own,
[01:09:30.160 --> 01:09:32.080]   shouldn't exploit other people for your own happiness,
[01:09:32.080 --> 01:09:33.320]   and you shouldn't allow yourself
[01:09:33.320 --> 01:09:34.960]   to be exploited for other people.
[01:09:34.960 --> 01:09:37.320]   Every individual is responsible for themselves.
[01:09:37.320 --> 01:09:40.840]   And what is it that allows us to be happy?
[01:09:40.840 --> 01:09:44.720]   What is it that facilitates human flourishing,
[01:09:44.720 --> 01:09:47.000]   human success, human survival?
[01:09:47.000 --> 01:09:49.080]   Well, it's the use of our minds, right?
[01:09:49.080 --> 01:09:50.380]   Goes back to reason.
[01:09:50.380 --> 01:09:56.160]   And what does reason require in order to be successful,
[01:09:56.160 --> 01:09:58.620]   in order to work effectively?
[01:09:58.620 --> 01:10:02.240]   It requires freedom.
[01:10:02.240 --> 01:10:07.040]   So the enemy of reason, the enemy of reason is force.
[01:10:07.040 --> 01:10:09.160]   The enemy of reason is coercion.
[01:10:09.160 --> 01:10:12.880]   The enemy of reason is authority, right?
[01:10:12.880 --> 01:10:16.840]   The Catholic Church doing what they did to Galileo, right?
[01:10:16.840 --> 01:10:19.200]   That restricts Galileo's thinking, right?
[01:10:19.200 --> 01:10:20.440]   When he's in house arrest,
[01:10:20.440 --> 01:10:21.680]   is he gonna come up with a new theory?
[01:10:21.680 --> 01:10:23.760]   Is he gonna discover new truths?
[01:10:23.760 --> 01:10:28.760]   No, the punishment is too, it's too dangerous.
[01:10:28.760 --> 01:10:34.160]   So force, coercion are enemies of reason.
[01:10:34.160 --> 01:10:39.080]   And what reason needs is to be free,
[01:10:39.080 --> 01:10:42.720]   to think, to discover, to innovate,
[01:10:42.720 --> 01:10:44.700]   to break out of convention.
[01:10:44.700 --> 01:10:48.680]   So we need to create an environment
[01:10:48.680 --> 01:10:52.400]   in which individuals are free to reason, free to think.
[01:10:52.400 --> 01:10:55.640]   And to do that, we come up with a concept,
[01:10:55.640 --> 01:10:57.200]   historically we've come up with a concept
[01:10:57.200 --> 01:10:58.760]   of individual rights.
[01:10:58.760 --> 01:11:01.240]   Individual rights define the scope of,
[01:11:01.240 --> 01:11:05.560]   define the fact that we should be left alone,
[01:11:05.560 --> 01:11:09.400]   free to pursue our values, using our reason,
[01:11:09.400 --> 01:11:10.240]   free of what?
[01:11:10.240 --> 01:11:12.400]   Free of coercion, force, authority.
[01:11:12.400 --> 01:11:14.840]   And that the job of government
[01:11:14.840 --> 01:11:17.160]   is to make sure that we are free.
[01:11:17.160 --> 01:11:18.400]   The whole point of government,
[01:11:18.400 --> 01:11:21.660]   the whole point of when we come in a social context,
[01:11:21.660 --> 01:11:24.600]   the whole point of establishing a government
[01:11:24.600 --> 01:11:29.600]   in that context is to secure that freedom.
[01:11:29.600 --> 01:11:34.640]   It's to make sure that I don't use coercion on you.
[01:11:34.640 --> 01:11:36.040]   The government is supposed to stop me,
[01:11:36.040 --> 01:11:38.040]   supposed to intervene before I can do that,
[01:11:38.040 --> 01:11:40.440]   or if I've already done it,
[01:11:40.440 --> 01:11:42.680]   to prevent me from doing it again.
[01:11:42.680 --> 01:11:47.020]   So the purpose of government is to protect our freedom
[01:11:47.020 --> 01:11:49.940]   to think and to act based on our thoughts.
[01:11:49.940 --> 01:11:53.360]   It's to leave individuals free to pursue their values,
[01:11:53.360 --> 01:11:58.240]   to pursue their happiness, to pursue their rational thought,
[01:11:58.240 --> 01:12:01.540]   and to be left alone to do it.
[01:12:01.540 --> 01:12:04.160]   And so she rejects socialism,
[01:12:04.160 --> 01:12:07.800]   which basically assumes some kind of collective goal,
[01:12:07.800 --> 01:12:11.000]   assumes the sacrifice of the individual to the group,
[01:12:11.000 --> 01:12:13.080]   assumes that your moral purpose in life
[01:12:13.080 --> 01:12:15.840]   is the well-being of other people rather than your own.
[01:12:15.840 --> 01:12:20.560]   And she rejects all form of statism,
[01:12:20.560 --> 01:12:24.560]   all form of government that is overly,
[01:12:24.560 --> 01:12:28.680]   that is involved in any aspect
[01:12:28.680 --> 01:12:32.580]   other than to protect us from forced coercion and authority.
[01:12:33.600 --> 01:12:36.600]   And she rejects anarchy, and we can talk about that.
[01:12:36.600 --> 01:12:39.480]   I think you had a question in the list of questions
[01:12:39.480 --> 01:12:41.560]   you sent me about anarchy, so I'm happy to discuss that.
[01:12:41.560 --> 01:12:43.520]   - I just talked to Michael Malice about anarchy,
[01:12:43.520 --> 01:12:45.720]   so I don't know if you're familiar with him.
[01:12:45.720 --> 01:12:46.760]   - Yes, I'm familiar with him.
[01:12:46.760 --> 01:12:49.840]   So yeah, so she would completely reject anarchy.
[01:12:49.840 --> 01:12:52.440]   Anarchy is completely inconsistent with her point of view,
[01:12:52.440 --> 01:12:54.120]   and we can talk about why if you want.
[01:12:54.120 --> 01:12:55.680]   - So there is some perfect place
[01:12:55.680 --> 01:12:57.200]   where freedom is maximized,
[01:12:57.200 --> 01:12:58.920]   so systems of government that--
[01:12:58.920 --> 01:13:00.400]   - Absolutely, and she thought
[01:13:00.400 --> 01:13:01.580]   that the American system of government
[01:13:01.580 --> 01:13:04.080]   came close in its idea,
[01:13:04.080 --> 01:13:06.240]   obviously founded with original sin,
[01:13:06.240 --> 01:13:10.040]   with the sin of slavery, but in its conception,
[01:13:10.040 --> 01:13:11.320]   the Declaration of Independence
[01:13:11.320 --> 01:13:14.620]   is about as perfect a political document as one could write,
[01:13:14.620 --> 01:13:17.100]   I think the greatest political document in human history,
[01:13:17.100 --> 01:13:21.920]   but really articulated almost perfectly and beautifully.
[01:13:21.920 --> 01:13:23.160]   And that the American system of government
[01:13:23.160 --> 01:13:25.120]   with the checks and balances,
[01:13:25.120 --> 01:13:27.560]   which is with its emphasis on individual rights,
[01:13:27.560 --> 01:13:29.480]   with its emphasis on freedom,
[01:13:29.480 --> 01:13:32.120]   with its emphasis on leaving individual free
[01:13:32.120 --> 01:13:33.360]   to pursue their happiness,
[01:13:33.360 --> 01:13:36.640]   an explicit recognition of happiness as a goal,
[01:13:36.640 --> 01:13:39.240]   individual happiness, was the model.
[01:13:39.240 --> 01:13:41.640]   It wasn't perfect, there were a lot of problems,
[01:13:41.640 --> 01:13:43.080]   to a large extent because the founders
[01:13:43.080 --> 01:13:45.440]   had mixed philosophical premises,
[01:13:45.440 --> 01:13:50.440]   so there were alien premises introduced
[01:13:50.440 --> 01:13:52.260]   into the founding of the country,
[01:13:52.260 --> 01:13:55.120]   slavery obviously being the biggest problem,
[01:13:55.120 --> 01:13:59.040]   but it was close, and we need to build on that
[01:13:59.040 --> 01:14:01.280]   to create an ideal political system
[01:14:01.280 --> 01:14:06.240]   that will, yes, maximize the freedom of individuals
[01:14:06.240 --> 01:14:07.380]   to do exactly this.
[01:14:07.380 --> 01:14:10.680]   And then of course she had,
[01:14:10.680 --> 01:14:15.440]   so that's the manifestation of this individualism
[01:14:15.440 --> 01:14:18.040]   in a political realm, and she had a theory of art,
[01:14:18.040 --> 01:14:19.560]   she had a theory of aesthetics,
[01:14:19.560 --> 01:14:21.620]   which is the fifth branch of,
[01:14:21.620 --> 01:14:25.080]   she had metaphysics, epistemology, ethics, and politics,
[01:14:25.080 --> 01:14:26.880]   and the fifth branch is aesthetics,
[01:14:26.880 --> 01:14:31.720]   and she viewed art as an essential human need,
[01:14:31.720 --> 01:14:34.160]   a fuel for the human spirit,
[01:14:34.160 --> 01:14:36.240]   and that just like any human need,
[01:14:36.240 --> 01:14:40.220]   it had certain principles that it had to abide by,
[01:14:40.220 --> 01:14:42.760]   that is just like there's nutrition, right,
[01:14:42.760 --> 01:14:45.180]   so some food is good for you and some food is bad for you,
[01:14:45.180 --> 01:14:47.760]   some food, some stuff is poison.
[01:14:47.760 --> 01:14:49.640]   She believed the same is true of art,
[01:14:49.640 --> 01:14:51.640]   that art had an identity,
[01:14:51.640 --> 01:14:53.840]   which is very controversial today, right,
[01:14:54.560 --> 01:14:57.280]   today if you put a frame around it, it is art, right,
[01:14:57.280 --> 01:15:01.080]   if you put a urinal in a museum, it becomes art,
[01:15:01.080 --> 01:15:05.080]   which she thought was evil and ludicrous,
[01:15:05.080 --> 01:15:07.160]   and she rejected completely,
[01:15:07.160 --> 01:15:09.120]   that art had an identity,
[01:15:09.120 --> 01:15:11.440]   and that it served a certain function
[01:15:11.440 --> 01:15:13.600]   that human beings needed it,
[01:15:13.600 --> 01:15:17.180]   and if it didn't have, not only did it have the identity,
[01:15:17.180 --> 01:15:20.080]   but that function was served well by some art
[01:15:20.080 --> 01:15:21.440]   and poorly by other art.
[01:15:22.640 --> 01:15:24.840]   And then there's a whole realm of stuff that's not art,
[01:15:24.840 --> 01:15:28.720]   basically, all of what today is considered modern art,
[01:15:28.720 --> 01:15:31.360]   she would consider as not being art,
[01:15:31.360 --> 01:15:34.080]   splashing paint on a canvas, not art.
[01:15:34.080 --> 01:15:40.120]   So she had very clear ideas,
[01:15:40.120 --> 01:15:42.520]   she articulated them not,
[01:15:42.520 --> 01:15:47.540]   so I would say not in conventional philosophical form,
[01:15:47.540 --> 01:15:50.300]   so she didn't write philosophical essays
[01:15:50.300 --> 01:15:52.840]   using the philosopher's language,
[01:15:52.840 --> 01:15:55.360]   it's why, partially why I think philosophers
[01:15:55.360 --> 01:15:57.160]   have never taken it seriously,
[01:15:57.160 --> 01:15:59.240]   they're actually accessible to us,
[01:15:59.240 --> 01:16:01.480]   we can actually read them,
[01:16:01.480 --> 01:16:04.000]   and she integrates the philosophy
[01:16:04.000 --> 01:16:07.020]   in what I think are amazing ways with psychology,
[01:16:07.020 --> 01:16:10.440]   with history, with economics, with politics,
[01:16:10.440 --> 01:16:12.520]   with what's going on in the world,
[01:16:12.520 --> 01:16:15.640]   and she has dozens and dozens and dozens of essays
[01:16:15.640 --> 01:16:20.280]   that she wrote, many of them were aggregated into books,
[01:16:20.280 --> 01:16:22.420]   I particularly recommend books like
[01:16:22.420 --> 01:16:25.960]   The Virtue of Selfishness,
[01:16:25.960 --> 01:16:28.280]   Capitalism, The Unknown Ideal,
[01:16:28.280 --> 01:16:32.920]   and Philosophy, Who Needs It?
[01:16:32.920 --> 01:16:37.920]   And I think it's a beautiful philosophy,
[01:16:37.920 --> 01:16:39.760]   I know you're big on love,
[01:16:39.760 --> 01:16:41.660]   I think it's a philosophy of love,
[01:16:41.660 --> 01:16:42.640]   we can talk about that,
[01:16:42.640 --> 01:16:44.140]   essentially it's about love,
[01:16:44.140 --> 01:16:45.700]   that's what the philosophy is all about,
[01:16:45.700 --> 01:16:48.180]   and when it apply in terms of it applying to self,
[01:16:49.140 --> 01:16:54.140]   and I think it's sad that so few people read it,
[01:16:54.140 --> 01:16:57.420]   and so few intellectuals take it seriously
[01:16:57.420 --> 01:16:58.740]   and are willing to engage with it.
[01:16:58.740 --> 01:17:01.980]   - Let me ask, that was incredible,
[01:17:01.980 --> 01:17:04.300]   but after that beautiful whirlwind overview,
[01:17:04.300 --> 01:17:06.260]   let me ask the most shallow of questions,
[01:17:06.260 --> 01:17:09.440]   which is the name objectivism.
[01:17:09.440 --> 01:17:16.640]   How should people think about the name being rooted,
[01:17:16.640 --> 01:17:19.340]   why not individualism, what are the options,
[01:17:19.340 --> 01:17:21.260]   if we're like had a branding meeting right now?
[01:17:21.260 --> 01:17:23.900]   - Sure, so she actually had a branding meeting,
[01:17:23.900 --> 01:17:26.020]   so she did this, she went through the exercise,
[01:17:26.020 --> 01:17:27.660]   objectivism, I do not think,
[01:17:27.660 --> 01:17:28.940]   I don't know all the details,
[01:17:28.940 --> 01:17:31.660]   but I don't think objectivism was the first
[01:17:31.660 --> 01:17:32.640]   name she came with,
[01:17:32.640 --> 01:17:35.300]   the problem was that the other names were taken,
[01:17:35.300 --> 01:17:38.280]   and they were not positive implications.
[01:17:38.280 --> 01:17:41.260]   So for example, rationalism could have been a good word,
[01:17:41.260 --> 01:17:44.060]   because she's an advocate of rational thought,
[01:17:44.060 --> 01:17:47.060]   or reasonism, but reasonism sounds weird,
[01:17:47.060 --> 01:17:50.100]   right, the ism, because of too many S's I guess.
[01:17:50.100 --> 01:17:52.960]   Rationalism, but it was already a philosophy,
[01:17:52.960 --> 01:17:55.480]   and it was a philosophy inconsistent with hers,
[01:17:55.480 --> 01:17:59.080]   because it was what she considered a false view
[01:17:59.080 --> 01:18:01.120]   of reason, of rationality.
[01:18:01.120 --> 01:18:05.640]   Realityism, you know, just doesn't work.
[01:18:05.640 --> 01:18:08.680]   So she came on objectivism, and I think actually,
[01:18:08.680 --> 01:18:12.520]   it's a great word, it's a great name,
[01:18:12.520 --> 01:18:16.660]   because it has two aspects to it,
[01:18:16.660 --> 01:18:18.640]   and this is a unique view of what objectivity
[01:18:18.640 --> 01:18:19.480]   actually means.
[01:18:19.480 --> 01:18:23.680]   In objectivism, in objectivity is the idea
[01:18:23.680 --> 01:18:26.020]   of an independent reality.
[01:18:26.020 --> 01:18:29.840]   There is truth, there's actually something out there,
[01:18:29.840 --> 01:18:33.520]   and then there's the role of consciousness, right,
[01:18:33.520 --> 01:18:37.240]   there is the role of figuring out the truth.
[01:18:37.240 --> 01:18:39.940]   The truth doesn't just hit you.
[01:18:41.000 --> 01:18:43.840]   The truth is not in the thing.
[01:18:43.840 --> 01:18:45.400]   You have to discover it.
[01:18:45.400 --> 01:18:49.280]   It's that a consciousness applied to,
[01:18:49.280 --> 01:18:52.900]   that's what objectivity is, right?
[01:18:52.900 --> 01:18:56.880]   It's you discovering the truth in reality.
[01:18:56.880 --> 01:19:00.160]   It's your consciousness interacting.
[01:19:00.160 --> 01:19:02.640]   - And thereby opposing the individual in that sense.
[01:19:02.640 --> 01:19:03.840]   - And only the individual could do it.
[01:19:03.840 --> 01:19:06.200]   Now the problem with individualism
[01:19:06.200 --> 01:19:09.980]   is it would have made the philosophy too political.
[01:19:09.980 --> 01:19:10.920]   - Right.
[01:19:10.920 --> 01:19:13.840]   - And she always said, so she said,
[01:19:13.840 --> 01:19:15.840]   she said, "I'm an advocate for capitalism
[01:19:15.840 --> 01:19:19.460]   "because I'm really an advocate for rational egoism,
[01:19:19.460 --> 01:19:23.680]   "but I'm an advocate for rational egoism
[01:19:23.680 --> 01:19:26.120]   "really because I'm an advocate for reason."
[01:19:26.120 --> 01:19:29.040]   So she viewed the essential of her philosophy
[01:19:29.040 --> 01:19:34.040]   as being this reason and her particular view of reason,
[01:19:34.040 --> 01:19:36.720]   and she has a whole book, she has a book called
[01:19:36.720 --> 01:19:39.480]   Introduction to Objectivist Epistemology,
[01:19:39.480 --> 01:19:42.160]   which I encourage any scientist, mathematician,
[01:19:42.160 --> 01:19:43.760]   anybody interested in science to read
[01:19:43.760 --> 01:19:47.440]   because it is a total force on,
[01:19:47.440 --> 01:19:53.000]   in a sense, what it means to hold concepts
[01:19:53.000 --> 01:19:56.920]   and what it means to discover new discoveries
[01:19:56.920 --> 01:20:01.920]   and to use concepts and how we use concepts.
[01:20:01.920 --> 01:20:08.200]   And she has a theory of concepts that is completely new,
[01:20:09.200 --> 01:20:11.240]   that is completely revolutionary,
[01:20:11.240 --> 01:20:14.360]   and I think is essential for the philosophy of science,
[01:20:14.360 --> 01:20:16.040]   and therefore ultimately,
[01:20:16.040 --> 01:20:18.840]   the more abstract we get with scientific discoveries,
[01:20:18.840 --> 01:20:23.240]   the easier it is to detach them from reality
[01:20:23.240 --> 01:20:25.400]   and to detach them from truth,
[01:20:25.400 --> 01:20:27.900]   the easier it is to be inside our heads
[01:20:27.900 --> 01:20:30.560]   instead of about what's real,
[01:20:30.560 --> 01:20:32.520]   and there are probably examples
[01:20:32.520 --> 01:20:34.960]   from modern physics that fit that.
[01:20:34.960 --> 01:20:37.900]   And I think what she teaches in the book
[01:20:37.900 --> 01:20:39.800]   is how to ground your concepts
[01:20:39.800 --> 01:20:42.640]   and how to bring them into grounding in reality.
[01:20:42.640 --> 01:20:44.600]   So Introduction to Objectivist Epistemology,
[01:20:44.600 --> 01:20:46.520]   and note that it's only an introduction
[01:20:46.520 --> 01:20:48.040]   'cause one of the things she realized,
[01:20:48.040 --> 01:20:50.400]   one of the things that I think a lot of her critics
[01:20:50.400 --> 01:20:52.080]   don't give enough credit for,
[01:20:52.080 --> 01:20:56.080]   is that philosophy is, there's no end, right?
[01:20:56.080 --> 01:20:58.280]   It's always growing, there are always new discoveries,
[01:20:58.280 --> 01:21:00.360]   there's always, it's like science,
[01:21:00.360 --> 01:21:01.360]   there's always new things,
[01:21:01.360 --> 01:21:06.280]   and there's a ton of work to do in philosophy,
[01:21:07.400 --> 01:21:09.520]   and particularly in epistemology, in the theory of knowledge
[01:21:09.520 --> 01:21:10.960]   that she was actually,
[01:21:10.960 --> 01:21:12.720]   given your interest in mathematics,
[01:21:12.720 --> 01:21:15.560]   she actually saw a lot of parallels
[01:21:15.560 --> 01:21:18.340]   between math and concept formation,
[01:21:18.340 --> 01:21:23.600]   and she was actually, in the years before she died,
[01:21:23.600 --> 01:21:26.000]   she was taking private lessons in mathematics,
[01:21:26.000 --> 01:21:28.920]   in algebra and calculus,
[01:21:28.920 --> 01:21:31.300]   because she believed that there was real insight
[01:21:31.300 --> 01:21:33.640]   in understanding algebra and calculus
[01:21:33.640 --> 01:21:38.640]   to philosophy, into epistemology,
[01:21:38.640 --> 01:21:42.800]   and she also was very interested in neuroscience,
[01:21:42.800 --> 01:21:45.540]   'cause she believed that that had a lot to tell us
[01:21:45.540 --> 01:21:48.840]   about epistemology, but also about music,
[01:21:48.840 --> 01:21:50.760]   therefore about aesthetics.
[01:21:50.760 --> 01:21:55.520]   So, I mean, she recognized the importance
[01:21:55.520 --> 01:21:56.960]   of all these different fields,
[01:21:56.960 --> 01:21:58.720]   and the beauty of philosophy
[01:21:58.720 --> 01:22:00.600]   is it should be integrating all of them,
[01:22:00.600 --> 01:22:03.140]   and one of the sad things about the world in which we live
[01:22:03.140 --> 01:22:05.460]   is, again, we view these things as silos.
[01:22:05.460 --> 01:22:06.940]   We don't view them as integrating.
[01:22:06.940 --> 01:22:10.840]   We don't have teams of people from different arenas,
[01:22:10.840 --> 01:22:13.680]   different fields, discovering things.
[01:22:13.680 --> 01:22:17.280]   We become like ants, specialized.
[01:22:17.280 --> 01:22:19.920]   So, she was definitely like that,
[01:22:19.920 --> 01:22:22.240]   and she was constantly curious,
[01:22:22.240 --> 01:22:25.280]   constantly interested in new discoveries,
[01:22:25.280 --> 01:22:29.040]   and new ideas, and how this could expand
[01:22:29.040 --> 01:22:30.620]   the scope of her philosophy
[01:22:30.620 --> 01:22:32.080]   and the application of her philosophy.
[01:22:32.080 --> 01:22:33.920]   - There's like a million topics I could talk to you,
[01:22:33.920 --> 01:22:35.640]   but since you mentioned math, I'm almost curious.
[01:22:35.640 --> 01:22:36.880]   - We've only got three hours.
[01:22:36.880 --> 01:22:40.720]   - You know, I'm almost curious.
[01:22:40.720 --> 01:22:41.600]   I don't know if you're familiar
[01:22:41.600 --> 01:22:44.160]   with Gayle's incompleteness theorem.
[01:22:44.160 --> 01:22:45.080]   - I'm not, unfortunately.
[01:22:45.080 --> 01:22:49.240]   - Okay, it was a powerful proof
[01:22:49.240 --> 01:22:51.100]   that any axiomatic systems,
[01:22:51.100 --> 01:22:53.840]   when you start from a bunch of axioms,
[01:22:53.840 --> 01:22:57.880]   that there will, in that system,
[01:22:57.880 --> 01:23:00.920]   provably must be an inconsistency.
[01:23:00.920 --> 01:23:04.520]   So, that was this painful stab
[01:23:04.520 --> 01:23:07.440]   in the idea of mathematics that,
[01:23:07.440 --> 01:23:09.940]   if we start with a set of assumptions,
[01:23:09.940 --> 01:23:12.960]   kind of like Adrian started with objectivism,
[01:23:12.960 --> 01:23:16.520]   there will have to be at least one contradiction.
[01:23:16.520 --> 01:23:20.960]   - See, I intuitively am gonna say that's false.
[01:23:20.960 --> 01:23:25.920]   - Philosophically, but in math, it's just true.
[01:23:25.920 --> 01:23:28.200]   - It's a question about how you define,
[01:23:28.200 --> 01:23:30.200]   again, definitions matter,
[01:23:30.200 --> 01:23:32.920]   and you have to be careful on how you define axioms,
[01:23:32.920 --> 01:23:34.320]   and you have to be careful about
[01:23:34.320 --> 01:23:35.880]   what you define as an inconsistency,
[01:23:35.880 --> 01:23:38.640]   and what that means to say there's an inconsistency.
[01:23:38.640 --> 01:23:40.280]   And I don't know, I'm not gonna say more than that,
[01:23:40.280 --> 01:23:42.640]   'cause I don't know, but I'm suspicious
[01:23:42.640 --> 01:23:47.640]   that there is some, and this is the power of philosophy,
[01:23:47.640 --> 01:23:49.040]   and this is why I said before,
[01:23:49.040 --> 01:23:50.640]   concept formation is so important,
[01:23:50.640 --> 01:23:53.040]   and understanding concept formation is so important,
[01:23:53.040 --> 01:23:54.240]   for particularly, again, mathematics,
[01:23:54.240 --> 01:23:55.880]   because it's such an abstract field,
[01:23:55.880 --> 01:24:00.360]   and it's so easy to lose grounding in reality,
[01:24:00.360 --> 01:24:03.720]   that if you properly define axioms,
[01:24:03.720 --> 01:24:05.640]   and you properly define what you're doing in math,
[01:24:05.640 --> 01:24:08.280]   whether that is true, and I don't think it is.
[01:24:08.280 --> 01:24:11.200]   - This is, yeah, we'll leave it as an open mystery,
[01:24:11.200 --> 01:24:13.480]   'cause actually, this audience,
[01:24:13.480 --> 01:24:17.680]   you know, there's literally over 100,000 people
[01:24:17.680 --> 01:24:20.040]   that have PhDs, and so they know
[01:24:20.040 --> 01:24:21.400]   Gato's incomplete theorem.
[01:24:21.400 --> 01:24:25.080]   I have this intuition that there is something different
[01:24:25.080 --> 01:24:27.280]   between mathematics and philosophy,
[01:24:27.280 --> 01:24:28.880]   that I'd love to hear from people.
[01:24:28.880 --> 01:24:31.480]   Like, what exactly is that difference?
[01:24:31.480 --> 01:24:36.000]   Because there's a precision to mathematics
[01:24:36.000 --> 01:24:39.120]   that philosophy doesn't have,
[01:24:39.120 --> 01:24:42.680]   but that precision gets you in trouble.
[01:24:42.680 --> 01:24:46.320]   It somehow, it actually takes you away from truth.
[01:24:46.320 --> 01:24:49.840]   Like, the very constraints of the language used
[01:24:49.840 --> 01:24:53.400]   in mathematics actually puts a constraint
[01:24:53.400 --> 01:24:56.200]   on the capture of truth that it's able to do.
[01:24:56.200 --> 01:25:00.560]   - I'm gonna argue that that is a total product
[01:25:00.560 --> 01:25:02.840]   of the way you're conceptualizing
[01:25:02.840 --> 01:25:05.760]   the terms within mathematics.
[01:25:05.760 --> 01:25:07.660]   It's not in reality.
[01:25:07.660 --> 01:25:10.480]   - Yeah, so you would argue it's in the fact
[01:25:10.480 --> 01:25:13.800]   that mathematics, in as much as it's detached from reality,
[01:25:13.800 --> 01:25:15.240]   that you can do these kinds of things.
[01:25:15.240 --> 01:25:20.240]   - Yes, and that mathematicians have come up with concepts
[01:25:21.240 --> 01:25:26.240]   that they haven't grounded in reality properly
[01:25:26.240 --> 01:25:32.120]   that allows them to go off in places
[01:25:32.120 --> 01:25:34.200]   that don't lead to truth, that's right,
[01:25:34.200 --> 01:25:35.360]   that don't lead to truth.
[01:25:35.360 --> 01:25:38.040]   But I encourage you then, I encourage you
[01:25:38.040 --> 01:25:42.720]   to do one of these podcasts with one of our philosophers
[01:25:42.720 --> 01:25:46.160]   who know more about this stuff.
[01:25:46.160 --> 01:25:48.080]   And if you move to Austin, I've got somebody
[01:25:48.080 --> 01:25:49.600]   I'd recommend to you.
[01:25:49.600 --> 01:25:51.440]   - Can you throw a name out, or no?
[01:25:51.440 --> 01:25:54.120]   - Yeah, I mean, I would talk to Greg Sommieri.
[01:25:54.120 --> 01:25:57.640]   - When you say our, can you say what you mean by our?
[01:25:57.640 --> 01:26:00.100]   - I'd say people who are affiliated
[01:26:00.100 --> 01:26:02.220]   with the Ironman Institute are philosophers
[01:26:02.220 --> 01:26:04.960]   who are affiliated with objectivism, right?
[01:26:04.960 --> 01:26:08.240]   And Greg is one of our brightest, and he's in Austin.
[01:26:08.240 --> 01:26:10.400]   He's just got a position at UT,
[01:26:10.400 --> 01:26:13.240]   so at the University of Texas.
[01:26:13.240 --> 01:26:15.720]   And he would want, Encargate would be another one
[01:26:15.720 --> 01:26:17.520]   who actually works at the Institute
[01:26:17.520 --> 01:26:20.440]   and a chief philosophy officer at the Institute.
[01:26:20.440 --> 01:26:21.280]   - That's awesome.
[01:26:21.280 --> 01:26:23.640]   - And there are others who specialize
[01:26:23.640 --> 01:26:26.760]   in philosophy of science who I think Greg
[01:26:26.760 --> 01:26:28.720]   could probably give you a lead.
[01:26:28.720 --> 01:26:31.340]   But these are unbelievably smart people
[01:26:31.340 --> 01:26:34.920]   who know this part of the philosophy much better than I do.
[01:26:34.920 --> 01:26:36.620]   - Can you just briefly perhaps say
[01:26:36.620 --> 01:26:38.560]   what is the Ironman Institute?
[01:26:38.560 --> 01:26:40.600]   - Yeah, so the Ironman Institute was an organization
[01:26:40.600 --> 01:26:44.760]   founded three years after Ironman died.
[01:26:44.760 --> 01:26:49.760]   She died in 1982, and it was founded in 1985
[01:26:49.760 --> 01:26:53.080]   to promote her ideas, to make sure that her ideas
[01:26:53.080 --> 01:26:58.080]   and her novels continued in the culture and were relevant.
[01:26:58.080 --> 01:27:01.880]   Well, they're relevant, but the people saw the relevance.
[01:27:01.880 --> 01:27:04.360]   So our mission is to get people to read her books,
[01:27:04.360 --> 01:27:06.320]   to engage in the ideas.
[01:27:06.320 --> 01:27:10.080]   We teach, we have the Objectivist Academic Center
[01:27:10.080 --> 01:27:12.720]   where we teach the philosophy,
[01:27:12.720 --> 01:27:14.800]   primarily to graduate students and others
[01:27:14.800 --> 01:27:16.840]   who take the idea seriously and who really want
[01:27:16.840 --> 01:27:20.840]   a deep understanding of the philosophy.
[01:27:20.840 --> 01:27:22.640]   And we apply the ideas.
[01:27:22.640 --> 01:27:25.000]   So we take the ideas and apply them to ethics,
[01:27:25.000 --> 01:27:28.160]   to philosophy, to issues of the day,
[01:27:28.160 --> 01:27:31.120]   which is more my strength and more what I tend to do.
[01:27:31.120 --> 01:27:34.720]   I've never formally studied philosophy.
[01:27:34.720 --> 01:27:39.600]   So all my education philosophy is informal.
[01:27:39.600 --> 01:27:42.360]   And I'm an engineer.
[01:27:42.360 --> 01:27:44.560]   And a finance guy, that's my background.
[01:27:44.560 --> 01:27:45.760]   So I'm a no-biz guy.
[01:27:45.760 --> 01:27:49.760]   - Well, let me, I feel pretty under-educated.
[01:27:49.760 --> 01:27:54.800]   I have a pretty open mind,
[01:27:54.800 --> 01:27:57.080]   which sometimes can be painful on the internet
[01:27:57.080 --> 01:28:02.080]   because people mock me or, you know,
[01:28:02.080 --> 01:28:05.480]   if I say something nuanced about communism,
[01:28:05.480 --> 01:28:09.080]   people immediately kind of put you in a bin
[01:28:09.080 --> 01:28:10.760]   or something like that.
[01:28:10.760 --> 01:28:13.920]   It hurts to be open-minded, to say, I don't know,
[01:28:13.920 --> 01:28:18.400]   to ask the question, why is communism or Marxism
[01:28:18.400 --> 01:28:21.920]   so problematic, why is capitalism problematic and so on?
[01:28:21.920 --> 01:28:25.180]   But let me nevertheless go into that direction with you.
[01:28:25.180 --> 01:28:29.840]   Maybe let's talk about capitalism a little bit.
[01:28:29.840 --> 01:28:33.720]   How does objectivism compare, relate
[01:28:33.720 --> 01:28:36.080]   to the idea of capitalism?
[01:28:36.080 --> 01:28:37.880]   - Well, first we have to define what capitalism is
[01:28:37.920 --> 01:28:40.960]   'cause again, people use capitalism in all kinds of ways.
[01:28:40.960 --> 01:28:43.600]   And I know you had Ray Dalio on your show once.
[01:28:43.600 --> 01:28:46.360]   I need to listen to that episode.
[01:28:46.360 --> 01:28:48.720]   But Ray has no clue what capitalism is.
[01:28:48.720 --> 01:28:51.680]   And that's his big problem.
[01:28:51.680 --> 01:28:56.880]   So when he says there are real problems today in capitalism,
[01:28:56.880 --> 01:28:58.240]   he's not talking about capitalism.
[01:28:58.240 --> 01:28:59.880]   He's talking about problems in the world today.
[01:28:59.880 --> 01:29:01.480]   And I agree with many of the problems,
[01:29:01.480 --> 01:29:03.440]   but they have nothing to do with capitalism.
[01:29:04.920 --> 01:29:08.680]   Capitalism is a social, political, economic system
[01:29:08.680 --> 01:29:13.360]   in which all property is privately owned
[01:29:13.360 --> 01:29:15.280]   and in which the only role of government
[01:29:15.280 --> 01:29:18.040]   is the protection of individual rights.
[01:29:18.040 --> 01:29:19.920]   I think it's the ideal system.
[01:29:19.920 --> 01:29:21.040]   I think it's the right system
[01:29:21.040 --> 01:29:22.320]   for the reasons we talked about earlier.
[01:29:22.320 --> 01:29:24.440]   It's a system that leaves you as an individual
[01:29:24.440 --> 01:29:27.400]   to pursue your values, your life, your happiness,
[01:29:27.400 --> 01:29:28.920]   free of coercion or force.
[01:29:28.920 --> 01:29:32.120]   And you get to decide what happens to you.
[01:29:32.120 --> 01:29:34.440]   And I get to decide if to help you or not.
[01:29:34.440 --> 01:29:35.600]   Let's say you fall flat on your face.
[01:29:35.600 --> 01:29:37.280]   People always say, "Well, what about the poor?"
[01:29:37.280 --> 01:29:39.480]   Well, if you care about the poor, help them.
[01:29:39.480 --> 01:29:43.760]   Just don't, you know, what do you need a government for?
[01:29:43.760 --> 01:29:45.440]   You know, I always ask audiences,
[01:29:45.440 --> 01:29:49.760]   okay, if there's a poor kid who can't afford to go to school
[01:29:49.760 --> 01:29:50.800]   and all the schools are private
[01:29:50.800 --> 01:29:53.480]   because capitalism is being instituted,
[01:29:53.480 --> 01:29:55.200]   and he can't go to school,
[01:29:55.200 --> 01:29:56.920]   would you be willing to participate in a fund
[01:29:56.920 --> 01:29:58.920]   that pays for his education?
[01:29:58.920 --> 01:30:00.440]   Every hand in the room goes up.
[01:30:00.440 --> 01:30:02.480]   So what do you need government for?
[01:30:02.480 --> 01:30:04.880]   Just let's get all the money together
[01:30:04.880 --> 01:30:05.960]   and pay for his schooling.
[01:30:05.960 --> 01:30:08.360]   So the point is that what capitalism does
[01:30:08.360 --> 01:30:11.200]   is leave individuals free to make their own decisions.
[01:30:11.200 --> 01:30:14.160]   And as long as they're not violating other people's rights,
[01:30:14.160 --> 01:30:17.360]   in other words, as long as they're not using coercion force
[01:30:17.360 --> 01:30:20.280]   on other people, then leave them alone.
[01:30:20.280 --> 01:30:21.920]   And people are going to make mistakes
[01:30:21.920 --> 01:30:23.120]   and people are gonna screw up their lives
[01:30:23.120 --> 01:30:24.480]   and people are gonna commit suicide.
[01:30:24.480 --> 01:30:27.360]   People are gonna do terrible things to themselves.
[01:30:27.360 --> 01:30:29.120]   That is fundamentally their problem.
[01:30:29.120 --> 01:30:30.920]   And if you want to help,
[01:30:30.920 --> 01:30:33.840]   you under capitalism are free to help.
[01:30:33.840 --> 01:30:37.000]   It's just the only thing that doesn't happen under capitalism
[01:30:37.000 --> 01:30:40.560]   is you don't get to impose your will on other people.
[01:30:40.560 --> 01:30:41.800]   How's that a bad thing?
[01:30:41.800 --> 01:30:46.800]   - So the question then is how does the implementation
[01:30:46.800 --> 01:30:52.360]   of capitalism deviate from its ideal in practice?
[01:30:52.360 --> 01:30:57.480]   I mean, this is what is the question with a lot of systems
[01:30:57.480 --> 01:31:00.880]   is how does it start to then fail?
[01:31:00.880 --> 01:31:05.000]   So one thing maybe you can correct me or inform me,
[01:31:05.000 --> 01:31:10.560]   it seems like information is very important.
[01:31:10.560 --> 01:31:15.560]   Like being able to make decisions, to be free,
[01:31:15.560 --> 01:31:18.360]   you have to have access,
[01:31:18.360 --> 01:31:21.200]   full access of all the information you need
[01:31:21.200 --> 01:31:23.680]   to make rational decisions.
[01:31:23.680 --> 01:31:25.800]   - No, that can't be.
[01:31:25.800 --> 01:31:26.880]   Because it can't be right.
[01:31:26.880 --> 01:31:28.800]   'Cause none of us has full access
[01:31:28.800 --> 01:31:31.240]   to all the information we need.
[01:31:31.240 --> 01:31:32.360]   I mean, what does that even mean?
[01:31:32.360 --> 01:31:35.680]   And how much of the scope do you want to do?
[01:31:35.680 --> 01:31:36.520]   - Let's just start there.
[01:31:36.520 --> 01:31:37.360]   Yeah, we don't.
[01:31:37.360 --> 01:31:39.840]   - So you need to have access to information.
[01:31:39.840 --> 01:31:41.920]   So one of the big criticisms of capitalism
[01:31:41.920 --> 01:31:44.280]   is this asymmetrical information.
[01:31:44.280 --> 01:31:46.800]   The drug maker has more information about the drug
[01:31:46.800 --> 01:31:48.440]   than the drug buyer, right?
[01:31:48.440 --> 01:31:49.680]   Pharmaceutical drugs.
[01:31:49.680 --> 01:31:53.800]   True, it's a problem.
[01:31:53.800 --> 01:31:55.800]   Well, I wonder if one can think about,
[01:31:55.800 --> 01:31:58.080]   an entrepreneur can think about how to solve that problem.
[01:31:58.080 --> 01:32:01.200]   See, I view any one of these challenges to capitalism
[01:32:01.200 --> 01:32:03.320]   as an opportunity for entrepreneur to make money.
[01:32:03.320 --> 01:32:04.880]   - And they have the freedom to do it.
[01:32:04.880 --> 01:32:07.360]   - Yeah, so imagine an entrepreneur steps in and says,
[01:32:07.360 --> 01:32:11.400]   "I will test all the drugs that drug companies make.
[01:32:11.400 --> 01:32:15.820]   "And I will provide you for a fee with the answer.
[01:32:15.820 --> 01:32:18.400]   "And how do I know he's not gonna be corrupted?
[01:32:18.400 --> 01:32:21.620]   "Well, there'll be other ones and they'll compete.
[01:32:21.620 --> 01:32:25.080]   "And who am I to tell which one of these is the right one?"
[01:32:25.080 --> 01:32:26.760]   Well, it won't be you really getting
[01:32:26.760 --> 01:32:28.840]   the information from them.
[01:32:28.840 --> 01:32:30.560]   It'll be your doctor.
[01:32:30.560 --> 01:32:32.260]   The doctors need that information.
[01:32:32.260 --> 01:32:36.000]   So the doctor who has some expertise in medicine
[01:32:36.000 --> 01:32:39.280]   will be evaluating which rating agency to use
[01:32:39.280 --> 01:32:41.480]   to evaluate the drugs and which ones then
[01:32:41.480 --> 01:32:43.080]   to recommend to you.
[01:32:43.080 --> 01:32:45.480]   So do we need an FDA?
[01:32:45.480 --> 01:32:48.360]   Do we need a government that siphons all the information
[01:32:48.360 --> 01:32:51.080]   to one source that does all the research, all the thing,
[01:32:51.080 --> 01:32:53.000]   and has a clear incentive, by the way,
[01:32:53.000 --> 01:32:54.520]   not to approve drugs.
[01:32:55.080 --> 01:32:57.520]   Because they don't make any money from it.
[01:32:57.520 --> 01:32:59.240]   Nobody pays them for the information.
[01:32:59.240 --> 01:33:00.720]   Nobody pays them to be accurate.
[01:33:00.720 --> 01:33:02.440]   They're bureaucrats at the end of the day.
[01:33:02.440 --> 01:33:04.120]   And what is a bureaucrat?
[01:33:04.120 --> 01:33:06.680]   What's the main focus of a bureaucrat?
[01:33:06.680 --> 01:33:09.000]   Even if they go in with the best of intentions,
[01:33:09.000 --> 01:33:10.840]   which I'm sure all the scientists at the FDA
[01:33:10.840 --> 01:33:13.360]   have the best of intentions, what's their incentive?
[01:33:13.360 --> 01:33:17.040]   The system builds in this incentive not to screw up.
[01:33:17.040 --> 01:33:22.000]   Because one drug gets value and does damage,
[01:33:22.000 --> 01:33:23.800]   you lose your job.
[01:33:23.800 --> 01:33:27.040]   But if 100 drugs that could kill cancer tomorrow
[01:33:27.040 --> 01:33:29.120]   don't ever get to market,
[01:33:29.120 --> 01:33:31.560]   nobody's gonna come after you.
[01:33:31.560 --> 01:33:35.840]   - Yeah, and you're saying that's not a mechanism
[01:33:35.840 --> 01:33:37.960]   that's conducive to--
[01:33:37.960 --> 01:33:39.440]   - You see, the marketplace is competition.
[01:33:39.440 --> 01:33:41.200]   So if you won't approve the drug,
[01:33:41.200 --> 01:33:43.760]   if I still think it's possible, I will,
[01:33:43.760 --> 01:33:45.240]   and it's not zero-one.
[01:33:45.240 --> 01:33:47.200]   You see, the other thing that happens with the FDA
[01:33:47.200 --> 01:33:48.040]   is it's zero-one.
[01:33:48.040 --> 01:33:50.360]   It's either approved or it's not approved.
[01:33:50.360 --> 01:33:52.600]   Oh, it's approved for this, but it's not approved for that.
[01:33:52.600 --> 01:33:57.000]   But what if a drug came out and you said,
[01:33:57.000 --> 01:33:58.120]   you told the doctors,
[01:33:58.120 --> 01:34:03.360]   this drug in 10% of the cases
[01:34:03.360 --> 01:34:07.520]   can cause patients an increased risk of heart disease?
[01:34:07.520 --> 01:34:09.720]   You and your patients should,
[01:34:09.720 --> 01:34:12.640]   we're not forcing you, but you should, right?
[01:34:12.640 --> 01:34:15.520]   It's your medical responsibility to evaluate that
[01:34:15.520 --> 01:34:17.480]   and decide if the drug is appropriate or not.
[01:34:17.480 --> 01:34:19.080]   Why don't I get to make that choice
[01:34:19.080 --> 01:34:21.760]   if I wanna take on the 10% risk of heart disease?
[01:34:21.760 --> 01:34:24.520]   So there was a drug, and right now I forget the name,
[01:34:24.520 --> 01:34:26.360]   but it was a drug against pain,
[01:34:26.360 --> 01:34:29.320]   particularly for arthritic pain, and it worked.
[01:34:29.320 --> 01:34:31.600]   It reduced pain dramatically, right?
[01:34:31.600 --> 01:34:33.240]   And some people tried everything,
[01:34:33.240 --> 01:34:35.800]   and this was the only drug that reduced their pain.
[01:34:35.800 --> 01:34:39.340]   And it turned out that in 10% of the cases,
[01:34:39.340 --> 01:34:42.320]   it caused the elevated risk.
[01:34:42.320 --> 01:34:43.900]   Didn't kill people necessarily,
[01:34:43.900 --> 01:34:46.160]   but it caused elevated risk of heart disease.
[01:34:46.160 --> 01:34:49.080]   Okay, what did the FDA do?
[01:34:49.080 --> 01:34:50.040]   It banned the drug.
[01:34:50.920 --> 01:34:53.600]   Some people, I know a lot of people who said,
[01:34:53.600 --> 01:34:58.440]   living with pain is much worse than taking on a 10% risk.
[01:34:58.440 --> 01:34:59.560]   Again, probabilities, right?
[01:34:59.560 --> 01:35:01.360]   People don't think in those numbers.
[01:35:01.360 --> 01:35:03.200]   10% risk of maybe getting heart disease.
[01:35:03.200 --> 01:35:04.660]   Why don't I get to make that choice?
[01:35:04.660 --> 01:35:07.520]   Why does some bureaucrat make that choice for me?
[01:35:07.520 --> 01:35:08.900]   That's capitalism.
[01:35:08.900 --> 01:35:11.140]   Capitalism gives you the choice,
[01:35:11.140 --> 01:35:13.080]   not you as an ignorant person,
[01:35:13.080 --> 01:35:17.040]   you with your doctor and a whole marketplace,
[01:35:17.040 --> 01:35:20.120]   which is now created to provide you with information.
[01:35:20.120 --> 01:35:23.680]   And think about a world where we didn't have
[01:35:23.680 --> 01:35:25.800]   all these regulations and controls.
[01:35:25.800 --> 01:35:31.960]   The amount of opportunities that would exist
[01:35:31.960 --> 01:35:35.000]   to create, to provide information,
[01:35:35.000 --> 01:35:36.920]   to educate you about that information
[01:35:36.920 --> 01:35:39.480]   would mushroom dramatically.
[01:35:39.480 --> 01:35:41.720]   Bloomberg, the billionaire Bloomberg,
[01:35:41.720 --> 01:35:42.960]   how did he make his money?
[01:35:42.960 --> 01:35:45.560]   He made his money by providing financial information,
[01:35:45.560 --> 01:35:47.480]   by creating this service called Bloomberg
[01:35:47.480 --> 01:35:49.080]   that you buy a terminal
[01:35:49.080 --> 01:35:50.840]   and you get all this amazing information.
[01:35:50.840 --> 01:35:53.720]   And he was before computers, desktop computers.
[01:35:53.720 --> 01:35:55.240]   I mean, he was very early on
[01:35:55.240 --> 01:35:57.360]   in that whole computing revolution.
[01:35:57.360 --> 01:35:59.800]   But his focus was providing financial information
[01:35:59.800 --> 01:36:00.740]   to professionals.
[01:36:00.740 --> 01:36:04.380]   And you hire a professional to manage your money.
[01:36:04.380 --> 01:36:06.080]   That's the way it's supposed to be.
[01:36:06.080 --> 01:36:11.880]   So you as an individual cannot have all the knowledge
[01:36:11.880 --> 01:36:12.840]   you need in medicine,
[01:36:12.840 --> 01:36:14.120]   all the knowledge you need in finance,
[01:36:14.120 --> 01:36:16.280]   all the knowledge you need in every aspect of your life.
[01:36:16.280 --> 01:36:17.280]   You can't do that.
[01:36:17.280 --> 01:36:19.560]   You have to delegate.
[01:36:19.560 --> 01:36:21.160]   And you hire a doctor.
[01:36:21.160 --> 01:36:23.080]   Now you should be able to figure out
[01:36:23.080 --> 01:36:24.240]   if the doctor's good or not.
[01:36:24.240 --> 01:36:26.840]   You should be able to ask doctors for reasons
[01:36:26.840 --> 01:36:28.960]   for why you have to make the decision at the end.
[01:36:28.960 --> 01:36:29.800]   But that's why you have a doctor.
[01:36:29.800 --> 01:36:31.080]   That's why you have a financial advisor.
[01:36:31.080 --> 01:36:32.840]   That's why you have different people
[01:36:32.840 --> 01:36:36.440]   who you're delegating certain aspects of your life to.
[01:36:36.440 --> 01:36:38.440]   But you want choices.
[01:36:38.440 --> 01:36:41.560]   And what the marketplace provides is those choices.
[01:36:41.560 --> 01:36:45.560]   - So let's, let me then, this is what I do.
[01:36:45.560 --> 01:36:47.680]   I'll make a dumb case for things,
[01:36:47.680 --> 01:36:48.960]   and then you shut me down,
[01:36:48.960 --> 01:36:51.160]   and then the internet says how dumb Lex is.
[01:36:51.160 --> 01:36:52.000]   This is good.
[01:36:52.000 --> 01:36:52.840]   This is how it works.
[01:36:52.840 --> 01:36:54.160]   - I'm good at shutting down.
[01:36:54.160 --> 01:36:55.000]   (laughing)
[01:36:55.000 --> 01:36:59.840]   And they're foolish in blaming you for the question
[01:36:59.840 --> 01:37:02.840]   because you're here to ask me questions.
[01:37:02.840 --> 01:37:06.460]   - Let's make the, let me make a case for socialism.
[01:37:06.460 --> 01:37:08.240]   (laughing)
[01:37:08.240 --> 01:37:09.680]   So.
[01:37:09.680 --> 01:37:11.680]   - It's gonna be bad because that's the only case
[01:37:11.680 --> 01:37:12.520]   there is for socialism.
[01:37:12.520 --> 01:37:13.640]   - All right. - That's reality.
[01:37:13.640 --> 01:37:16.920]   - So, and then perhaps it's not a case for socialism,
[01:37:16.920 --> 01:37:21.860]   but just a certain notion that inequality,
[01:37:21.860 --> 01:37:26.840]   the wealth inequality, that the bigger the gap
[01:37:26.840 --> 01:37:30.440]   between the poorest or the average and the richest,
[01:37:30.440 --> 01:37:35.000]   the more painful it is to be average.
[01:37:35.000 --> 01:37:38.480]   Psychologically speaking, if you know that there is,
[01:37:38.480 --> 01:37:43.480]   the CEOs of companies make 300, 1,000,
[01:37:43.720 --> 01:37:46.000]   1 million times more than you do,
[01:37:46.000 --> 01:37:50.520]   that makes life for a large part of the population
[01:37:50.520 --> 01:37:53.120]   less fulfilling, that there's a relative notion
[01:37:53.120 --> 01:37:55.240]   to the experience of our life,
[01:37:55.240 --> 01:37:58.240]   that even though everybody's life has gotten better
[01:37:58.240 --> 01:38:02.080]   over the past decades and centuries,
[01:38:02.080 --> 01:38:06.600]   it may feel actually worse because you know
[01:38:06.600 --> 01:38:10.320]   that life could be so, so much better
[01:38:10.320 --> 01:38:13.720]   in the life of these CEOs that, yeah,
[01:38:13.720 --> 01:38:17.240]   that gap is fundamentally a thing
[01:38:17.240 --> 01:38:19.740]   that is undesirable in a society.
[01:38:19.740 --> 01:38:23.040]   - Everything about that is wrong.
[01:38:23.040 --> 01:38:25.080]   (laughing)
[01:38:25.080 --> 01:38:27.040]   I like to start off like that, yeah.
[01:38:27.040 --> 01:38:32.040]   Which, so, I mean, so my wife likes to remind me
[01:38:32.040 --> 01:38:36.140]   that as well as we've done in life,
[01:38:36.140 --> 01:38:38.240]   we are actually from a wealth perspective
[01:38:38.240 --> 01:38:41.120]   closer to a homeless person than we are to Bill Gates.
[01:38:41.120 --> 01:38:43.120]   Just a math, right, just a math, right?
[01:38:43.120 --> 01:38:44.880]   (laughing)
[01:38:44.880 --> 01:38:46.160]   - It's a good ego check.
[01:38:46.160 --> 01:38:49.280]   - When I look at Bill Gates, I get a smile on my face.
[01:38:49.280 --> 01:38:51.400]   I love Bill Gates, I've never met Bill Gates.
[01:38:51.400 --> 01:38:52.440]   I love Bill Gates.
[01:38:52.440 --> 01:38:54.800]   I love what he stands for.
[01:38:54.800 --> 01:38:56.720]   I love that he has $100 billion.
[01:38:56.720 --> 01:39:01.160]   I love that he has built a trampoline room in his house
[01:39:01.160 --> 01:39:03.560]   where his kids can jump up and down in a trampoline
[01:39:03.560 --> 01:39:04.920]   in a safe environment.
[01:39:04.920 --> 01:39:06.640]   - Can we take another billionaire?
[01:39:06.640 --> 01:39:09.400]   Because I'm not sure if you're paying attention,
[01:39:09.400 --> 01:39:12.360]   but there's all kinds of conspiracy theories
[01:39:12.360 --> 01:39:13.800]   about Bill Gates.
[01:39:13.800 --> 01:39:15.560]   - Well, but that's part of the story, right?
[01:39:15.560 --> 01:39:17.920]   They have to pull him down because people resent him.
[01:39:17.920 --> 01:39:19.120]   - And that's strange.
[01:39:19.120 --> 01:39:21.520]   - That's strange, but yes, we can take Jeff Bezos.
[01:39:21.520 --> 01:39:24.880]   We can take my favorite, historically,
[01:39:24.880 --> 01:39:28.740]   just 'cause I like a lot about him, was Steve Jobs.
[01:39:28.740 --> 01:39:32.720]   I mean, I love these people.
[01:39:32.720 --> 01:39:36.360]   And I can't, there are very few billionaires I don't love.
[01:39:36.360 --> 01:39:41.240]   In a sense that I appreciate everything they've done for me,
[01:39:41.240 --> 01:39:46.020]   for people I cherish and love,
[01:39:46.020 --> 01:39:48.360]   they've made the world a better place.
[01:39:48.360 --> 01:39:51.800]   Why would it ever cross my mind
[01:39:51.800 --> 01:39:55.920]   that they make me look bad because they're richer than me
[01:39:55.920 --> 01:39:58.360]   or that I don't have what they have?
[01:39:58.360 --> 01:40:02.520]   They've made me so much richer
[01:40:02.520 --> 01:40:07.400]   that they've made inventions that used to cost
[01:40:07.400 --> 01:40:10.280]   millions and millions and millions of dollars
[01:40:10.280 --> 01:40:12.120]   accessible to me.
[01:40:12.120 --> 01:40:15.980]   I mean, this is a super computer in my pocket.
[01:40:15.980 --> 01:40:18.520]   Now, but think about it, right?
[01:40:18.520 --> 01:40:21.040]   What is the difference between,
[01:40:21.040 --> 01:40:23.560]   and I'll get to the essence of your point in a minute,
[01:40:23.560 --> 01:40:25.660]   but think about what the difference is
[01:40:25.660 --> 01:40:28.600]   between me and Bill Gates in terms of,
[01:40:28.600 --> 01:40:30.320]   because it's true that in terms of wealth,
[01:40:30.320 --> 01:40:31.820]   I'm closer to the homeless person.
[01:40:31.820 --> 01:40:34.980]   But in terms of my day-to-day life, I'm closer to Bill Gates.
[01:40:34.980 --> 01:40:37.840]   We both live in a nice house.
[01:40:37.840 --> 01:40:40.160]   His is nicer, but we live in a nice house.
[01:40:40.160 --> 01:40:43.100]   His is bigger, but mine is plenty big.
[01:40:43.100 --> 01:40:44.560]   We both drive cars.
[01:40:44.560 --> 01:40:46.700]   His is nicer, but we both drive cars.
[01:40:46.700 --> 01:40:50.160]   Cars, 100 years ago, what cars?
[01:40:50.160 --> 01:40:54.280]   We both can fly, get on a plane in Los Angeles
[01:40:54.280 --> 01:40:57.100]   and fly to New York and get there in about the same time.
[01:40:57.100 --> 01:40:58.540]   We're both flying private.
[01:40:58.540 --> 01:41:01.280]   The only difference is my private plane,
[01:41:01.280 --> 01:41:03.320]   I share with 300 other people.
[01:41:03.320 --> 01:41:07.160]   And his, but it's accessible.
[01:41:07.160 --> 01:41:08.700]   It's relatively comfortable.
[01:41:08.700 --> 01:41:11.400]   Again, in the perspective of 50 years ago, 100 years ago,
[01:41:11.400 --> 01:41:13.800]   it's unimaginable that I could fly like that
[01:41:13.800 --> 01:41:15.480]   for such a low fee.
[01:41:15.480 --> 01:41:18.840]   We live very similar lives in that sense.
[01:41:18.840 --> 01:41:20.160]   So I don't resent him.
[01:41:20.160 --> 01:41:23.800]   So first of all, I'm an exception to the supposed rule
[01:41:23.800 --> 01:41:24.840]   that people resent.
[01:41:24.840 --> 01:41:26.840]   I don't think anybody, I don't think people do resent
[01:41:26.840 --> 01:41:28.320]   unless they're taught to resent.
[01:41:28.320 --> 01:41:29.680]   And this is the key.
[01:41:29.680 --> 01:41:33.120]   People are taught, and I've seen this in America.
[01:41:33.120 --> 01:41:37.520]   And this is, to me, the most horrible, shocking thing
[01:41:37.520 --> 01:41:40.400]   that has happened in America over the last 40 years.
[01:41:40.400 --> 01:41:42.320]   I came to America, so I'm an immigrant.
[01:41:42.320 --> 01:41:45.760]   I came to America from Israel in 1987.
[01:41:45.760 --> 01:41:48.440]   And I came here because I thought this was the place
[01:41:48.440 --> 01:41:50.880]   where I could, where I'd had the most opportunities.
[01:41:50.880 --> 01:41:52.920]   And it is, most opportunities.
[01:41:52.920 --> 01:41:54.280]   And I came here 'cause I believed
[01:41:54.280 --> 01:41:58.840]   there was a certain American spirit of individualism,
[01:41:58.840 --> 01:42:01.160]   and exactly the opposite of what you just described,
[01:42:01.160 --> 01:42:06.160]   a sense of, I live my life, it's my happiness.
[01:42:06.160 --> 01:42:07.680]   I'm not looking at my neighbor.
[01:42:07.680 --> 01:42:09.600]   I'm not competing with the Joneses.
[01:42:09.600 --> 01:42:12.860]   The American dream is my dream, my two kids,
[01:42:12.860 --> 01:42:16.440]   my dog, my station wagon, not because other people have it,
[01:42:16.440 --> 01:42:18.360]   it's because I want it, in that sense.
[01:42:18.360 --> 01:42:22.840]   And when I came here in the '80s, you had that.
[01:42:22.840 --> 01:42:25.280]   You had, you still had it.
[01:42:25.280 --> 01:42:28.120]   It was less than I think it had been in the past.
[01:42:28.120 --> 01:42:29.480]   But you had that spirit.
[01:42:29.480 --> 01:42:31.280]   There was no envy, there was no resentment.
[01:42:31.280 --> 01:42:34.180]   There were rich people, and they were celebrated.
[01:42:34.180 --> 01:42:37.560]   There was still this admiration for entrepreneurs
[01:42:37.560 --> 01:42:39.720]   and admiration for success.
[01:42:39.720 --> 01:42:42.680]   Not by everybody, certainly not by the intellectuals,
[01:42:42.680 --> 01:42:45.120]   but by the average person.
[01:42:45.120 --> 01:42:47.960]   I have witnessed, particularly over the last 10 years,
[01:42:47.960 --> 01:42:50.140]   a complete transformation,
[01:42:50.140 --> 01:42:52.500]   and America's become like Europe.
[01:42:52.500 --> 01:42:54.280]   I know, are you Russian?
[01:42:54.280 --> 01:42:55.120]   - Yeah. - Yeah.
[01:42:55.120 --> 01:42:59.480]   It's become Russian, in a sense where,
[01:42:59.480 --> 01:43:01.680]   you know, they've always done these studies.
[01:43:01.680 --> 01:43:06.840]   I'll give you $100 and your neighbor $100,
[01:43:06.840 --> 01:43:09.400]   or I'll give you, what is it?
[01:43:09.400 --> 01:43:14.040]   Or I'll give you $1,000, but your neighbor gets $10,000.
[01:43:14.040 --> 01:43:16.560]   And a Russian will always choose the $100, right?
[01:43:16.560 --> 01:43:20.720]   He wants equality above being better himself.
[01:43:20.720 --> 01:43:24.540]   Americans would always choose that gap.
[01:43:24.540 --> 01:43:26.780]   - And that's changing. - My sense is not anymore.
[01:43:26.780 --> 01:43:31.780]   And it's changing because we've been told it should change.
[01:43:31.780 --> 01:43:35.020]   - And morally, you're saying that doesn't make any sense.
[01:43:35.020 --> 01:43:38.900]   So there's no sense in which, let me put another spin,
[01:43:38.900 --> 01:43:41.780]   I forget the book, but the sense of,
[01:43:41.780 --> 01:43:45.500]   if you're working for Steve Jobs, and your hands,
[01:43:45.500 --> 01:43:48.260]   you're the engineer behind the iPhone,
[01:43:48.260 --> 01:43:51.340]   and there's a sense in which his salary
[01:43:51.340 --> 01:43:53.960]   is stealing from your efforts.
[01:43:53.960 --> 01:43:57.340]   Because, I forget the book, right?
[01:43:57.340 --> 01:43:59.940]   That's literally the terminology is used, right?
[01:43:59.940 --> 01:44:02.420]   - This is straight out of Karl Marx.
[01:44:02.420 --> 01:44:05.260]   - Sure, it's also straight, but out of Karl Marx.
[01:44:05.260 --> 01:44:08.180]   But there's no sense, morally speaking,
[01:44:08.180 --> 01:44:09.700]   that you see that as the best--
[01:44:09.700 --> 01:44:11.060]   - The other way around.
[01:44:11.060 --> 01:44:12.660]   That engineer's stealing off of,
[01:44:12.660 --> 01:44:14.260]   and it's not stealing, right?
[01:44:14.260 --> 01:44:15.740]   It's not.
[01:44:15.740 --> 01:44:18.420]   But the engineer's getting more from Steve Jobs,
[01:44:18.420 --> 01:44:20.420]   by a lot, not by a little bit,
[01:44:20.420 --> 01:44:23.340]   than Steve Jobs is getting from the engineer.
[01:44:23.340 --> 01:44:26.140]   The engineer, even if they're a great engineer,
[01:44:26.140 --> 01:44:27.380]   there are probably other great engineers
[01:44:27.380 --> 01:44:28.540]   that could replace him.
[01:44:28.540 --> 01:44:32.140]   Would he even have a job without Steve Jobs?
[01:44:32.140 --> 01:44:34.980]   Would the industry exist without Steve Jobs?
[01:44:34.980 --> 01:44:38.500]   Without the giants that carry these things forward?
[01:44:38.500 --> 01:44:39.340]   Let me ask you this.
[01:44:39.340 --> 01:44:41.140]   I mean, you're a scientist.
[01:44:41.140 --> 01:44:43.640]   Do you resent Einstein for being smarter than you?
[01:44:44.640 --> 01:44:45.920]   (laughing)
[01:44:45.920 --> 01:44:47.360]   I mean, do you envy him?
[01:44:47.360 --> 01:44:48.360]   Are you angry with him?
[01:44:48.360 --> 01:44:51.520]   Would you feel negative towards him
[01:44:51.520 --> 01:44:52.720]   if he was in the room right now?
[01:44:52.720 --> 01:44:54.040]   Or would you, if you came into the room,
[01:44:54.040 --> 01:44:55.400]   you'd say, "Oh my God."
[01:44:55.400 --> 01:44:58.320]   I mean, you interview people who I think some of them
[01:44:58.320 --> 01:45:00.040]   are probably smarter than you and me.
[01:45:00.040 --> 01:45:00.880]   - For sure.
[01:45:00.880 --> 01:45:03.280]   - And your attitude towards them is one of reverence.
[01:45:03.280 --> 01:45:07.080]   - Well, one interesting little side question there
[01:45:07.080 --> 01:45:10.920]   is what is the natural state of being for us humans?
[01:45:10.920 --> 01:45:15.680]   You kind of implied education has polluted our minds,
[01:45:15.680 --> 01:45:19.640]   but like if I, 'cause you're referring to jealousy,
[01:45:19.640 --> 01:45:22.640]   the Einstein question, the Steve Jobs question,
[01:45:22.640 --> 01:45:26.000]   I wonder which way, if we're left without education,
[01:45:26.000 --> 01:45:27.480]   would we naturally go?
[01:45:27.480 --> 01:45:30.100]   - So there is no such thing as the natural state
[01:45:30.100 --> 01:45:31.940]   in that sense, right?
[01:45:31.940 --> 01:45:36.940]   This is the myth of Rousseau's "Nobel Savage"
[01:45:37.920 --> 01:45:42.520]   and of John Walls' "Behind the Veil of Ignorance."
[01:45:42.520 --> 01:45:44.720]   Well, if you're ignorant, you're ignorant.
[01:45:44.720 --> 01:45:48.120]   You can't make any decisions, you're just ignorant.
[01:45:48.120 --> 01:45:54.520]   There is no human nature that determines
[01:45:54.520 --> 01:45:56.540]   how you will relate to other people.
[01:45:56.540 --> 01:45:58.960]   You will relate to other people based on the conclusions
[01:45:58.960 --> 01:46:01.920]   you come to about how to relate to other people.
[01:46:01.920 --> 01:46:05.700]   You can relate to other people as values,
[01:46:06.920 --> 01:46:10.320]   to use your terminology, from the perspective of love.
[01:46:10.320 --> 01:46:13.600]   This other human being is a value to me
[01:46:13.600 --> 01:46:15.760]   and I want to trade with them
[01:46:15.760 --> 01:46:19.060]   and trade the beauty of trade is it's win-win.
[01:46:19.060 --> 01:46:21.440]   I wanna benefit and they are going to benefit.
[01:46:21.440 --> 01:46:24.080]   I don't wanna screw them, I don't want them to screw me,
[01:46:24.080 --> 01:46:25.560]   I want this to be win-win.
[01:46:25.560 --> 01:46:31.400]   Or you can deal with other people as threats, as enemies.
[01:46:31.400 --> 01:46:33.440]   Much of human history we have done that
[01:46:34.560 --> 01:46:37.320]   and therefore is a zero-sum world.
[01:46:37.320 --> 01:46:41.880]   What they have, I want, I will take it.
[01:46:41.880 --> 01:46:43.080]   I will use force to take it,
[01:46:43.080 --> 01:46:44.600]   I will use political force to take it,
[01:46:44.600 --> 01:46:46.200]   I will use the force of my arm to take it,
[01:46:46.200 --> 01:46:47.640]   I will just take it.
[01:46:47.640 --> 01:46:51.080]   So those are two options, right?
[01:46:51.080 --> 01:46:52.680]   And they will determine whether we live
[01:46:52.680 --> 01:46:54.640]   in civilization or not.
[01:46:54.640 --> 01:46:57.480]   And they aren't determined by conclusions people come to
[01:46:57.480 --> 01:46:59.360]   about the world and the nature of reality
[01:46:59.360 --> 01:47:01.480]   and the nature of morality and the nature of politics
[01:47:01.480 --> 01:47:02.880]   and all these things.
[01:47:02.880 --> 01:47:05.320]   They're determined by philosophy.
[01:47:05.320 --> 01:47:07.680]   And this is why philosophy is so important
[01:47:07.680 --> 01:47:12.400]   because philosophy shapes, evolution doesn't do this.
[01:47:12.400 --> 01:47:14.520]   It doesn't just happen.
[01:47:14.520 --> 01:47:17.200]   Ideas shape how we relate to other people.
[01:47:17.200 --> 01:47:19.960]   And you say, "Well, little children do it."
[01:47:19.960 --> 01:47:22.600]   Well, little children don't have a frontal cortex.
[01:47:22.600 --> 01:47:24.440]   It's not relevant, right?
[01:47:24.440 --> 01:47:27.020]   What happens as you develop a frontal cortex,
[01:47:27.020 --> 01:47:32.020]   as you develop the brain, you learn ideas.
[01:47:32.160 --> 01:47:35.240]   And those ideas will shape how you relate to other people.
[01:47:35.240 --> 01:47:37.000]   And if you learn good ideas,
[01:47:37.000 --> 01:47:40.440]   you relate to other people in a healthy, productive win-win.
[01:47:40.440 --> 01:47:43.840]   And if you develop bad ideas,
[01:47:43.840 --> 01:47:47.800]   you will resent other people and you will want their stuff.
[01:47:47.800 --> 01:47:50.240]   And the thing is that human progress depends
[01:47:50.240 --> 01:47:52.480]   on the win-win relationship.
[01:47:52.480 --> 01:47:55.480]   It depends on civilization, depends on peace.
[01:47:55.480 --> 01:47:57.820]   It depends on allowing people,
[01:47:57.820 --> 01:47:59.240]   going back to what we talked about earlier,
[01:47:59.240 --> 01:48:01.800]   allowing people the freedom to think for themselves.
[01:48:02.640 --> 01:48:05.040]   And anytime you try to interrupt that,
[01:48:05.040 --> 01:48:06.160]   you're causing damage.
[01:48:06.160 --> 01:48:09.480]   So this change in America is not some reversion
[01:48:09.480 --> 01:48:11.400]   to a natural state.
[01:48:11.400 --> 01:48:12.800]   It's a shift in ideas.
[01:48:12.800 --> 01:48:19.520]   We still live, the better part of American society
[01:48:19.520 --> 01:48:24.360]   and the world still lives on the remnants of the Enlightenment.
[01:48:24.360 --> 01:48:26.840]   The Enlightenment ideas,
[01:48:26.840 --> 01:48:30.760]   the ideas that brought about the scientific revolution,
[01:48:30.760 --> 01:48:33.120]   the ideas that brought about the creation of this country.
[01:48:33.120 --> 01:48:36.480]   And it's the same basic ideas that led to both of those.
[01:48:36.480 --> 01:48:41.120]   And as those ideas get more distant,
[01:48:41.120 --> 01:48:43.480]   as those ideas are not defended,
[01:48:43.480 --> 01:48:47.360]   as those ideas disappear, as Enlightenment goes away,
[01:48:47.360 --> 01:48:53.000]   we will become more violent, more resentful, more tribal,
[01:48:53.000 --> 01:48:58.000]   more obnoxious, more unpleasant, more primitive.
[01:48:58.200 --> 01:49:02.680]   - A very specific example of this that bothers me,
[01:49:02.680 --> 01:49:04.960]   I'd be curious to get your comment on.
[01:49:04.960 --> 01:49:08.760]   So Elon Musk is a billionaire.
[01:49:08.760 --> 01:49:14.760]   And one of the things that really,
[01:49:14.760 --> 01:49:16.240]   maybe it's almost a pet peeve,
[01:49:16.240 --> 01:49:18.520]   it really bothers me when the press
[01:49:18.520 --> 01:49:21.320]   and the general public will say,
[01:49:21.320 --> 01:49:24.880]   "Well, all those rockets they're sending up there,
[01:49:24.880 --> 01:49:26.460]   "those are just like the toys,
[01:49:26.460 --> 01:49:28.600]   "the games that billionaires play."
[01:49:28.600 --> 01:49:34.960]   That to me, billionaire has become a dirty word to use,
[01:49:34.960 --> 01:49:41.520]   like as if money can buy or has anything to do with genius.
[01:49:41.520 --> 01:49:47.640]   Like, I'm trying to articulate a specific
[01:49:47.640 --> 01:49:53.960]   line of question here, because it just bothers me.
[01:49:53.960 --> 01:49:55.960]   I guess the question is like,
[01:49:55.960 --> 01:49:58.480]   why, how do we get here and how do we get out of that?
[01:49:58.480 --> 01:50:02.240]   Because Elon Musk is doing some of the most incredible things
[01:50:02.240 --> 01:50:05.120]   that a human being has ever participated in,
[01:50:05.120 --> 01:50:07.480]   in mostly, he doesn't build the rockets himself,
[01:50:07.480 --> 01:50:10.560]   he's getting a bunch of other geniuses together that have--
[01:50:10.560 --> 01:50:11.400]   - That takes genius.
[01:50:11.400 --> 01:50:14.840]   - That takes genius, but why, where do we go
[01:50:14.840 --> 01:50:17.640]   and how do we get back to where Elon Musk
[01:50:17.640 --> 01:50:20.160]   is an inspiring figure as opposed to
[01:50:20.160 --> 01:50:23.160]   a billionaire playing with some toys?
[01:50:23.160 --> 01:50:25.080]   - So this is the role of philosophy.
[01:50:25.080 --> 01:50:26.520]   It goes back to the same place.
[01:50:26.520 --> 01:50:28.520]   It goes back to our understanding of the world
[01:50:28.520 --> 01:50:30.280]   and our role in it.
[01:50:30.280 --> 01:50:32.640]   And if you understand that the only way
[01:50:32.640 --> 01:50:34.800]   to become a billionaire, for example,
[01:50:34.800 --> 01:50:37.560]   is to create value, value for whom?
[01:50:37.560 --> 01:50:39.760]   Value for people who are gonna consume it.
[01:50:39.760 --> 01:50:41.240]   The only way to become a billionaire,
[01:50:41.240 --> 01:50:45.600]   the only way Elon Musk became a billionaire is through PayPal.
[01:50:45.600 --> 01:50:47.560]   Now, PayPal is something we all use.
[01:50:47.560 --> 01:50:50.040]   PayPal is an enormous value to all of us.
[01:50:50.040 --> 01:50:52.680]   It's why it's worth several billions of dollars,
[01:50:52.680 --> 01:50:57.680]   which Elon Musk could then earn.
[01:50:57.680 --> 01:51:01.640]   But you cannot become a billionaire in a free society
[01:51:01.640 --> 01:51:02.920]   by exploiting people.
[01:51:02.920 --> 01:51:05.840]   You cannot because you'll be laughed,
[01:51:05.840 --> 01:51:06.880]   nobody will deal with you.
[01:51:06.880 --> 01:51:09.160]   Nobody will have any interactions with you.
[01:51:09.160 --> 01:51:10.640]   The only way to become a billionaire
[01:51:10.640 --> 01:51:14.200]   is to do billions of win-win transactions.
[01:51:14.200 --> 01:51:18.440]   So the only way to become a billionaire in a free society
[01:51:18.440 --> 01:51:21.720]   is to change the world to make it a better place.
[01:51:21.720 --> 01:51:24.640]   Billionaires are the great humanitarians of our time,
[01:51:24.640 --> 01:51:26.360]   not because they give charity,
[01:51:26.360 --> 01:51:29.200]   but because they make them billions.
[01:51:29.200 --> 01:51:32.760]   And it's true that money and genius
[01:51:32.760 --> 01:51:35.440]   are not necessarily correlated,
[01:51:35.440 --> 01:51:37.360]   but you cannot become a billionaire
[01:51:37.360 --> 01:51:38.960]   without being super smart.
[01:51:38.960 --> 01:51:42.400]   You cannot become a billionaire by figuring something out
[01:51:42.400 --> 01:51:44.560]   that nobody else has figured out
[01:51:44.560 --> 01:51:46.160]   in whatever realm it happens to be.
[01:51:46.160 --> 01:51:48.400]   And that thing that you figure out
[01:51:48.400 --> 01:51:50.680]   has to be something that provides immense value
[01:51:50.680 --> 01:51:51.560]   to other people.
[01:51:51.560 --> 01:51:54.400]   Where do we go wrong?
[01:51:54.400 --> 01:51:56.760]   We go wrong, our culture goes wrong,
[01:51:56.760 --> 01:52:01.760]   because it views billionaires as self-interested, as selfish.
[01:52:01.760 --> 01:52:04.800]   And there's a sense in which, and not a sense,
[01:52:04.800 --> 01:52:06.400]   it's absolutely true.
[01:52:06.400 --> 01:52:08.680]   The billionaire doesn't ask for my opinion
[01:52:08.680 --> 01:52:11.520]   on what product to launch.
[01:52:11.520 --> 01:52:13.840]   Elon Musk doesn't ask others
[01:52:13.840 --> 01:52:15.960]   what they think you should spend his money on,
[01:52:15.960 --> 01:52:18.520]   what the greatest social well-being will be.
[01:52:18.520 --> 01:52:19.960]   Elon, I mean, there's a sense
[01:52:19.960 --> 01:52:21.880]   in which the rockets are his toys.
[01:52:21.880 --> 01:52:24.480]   There's a sense in which he chose
[01:52:24.480 --> 01:52:28.240]   that he would be inspired the most.
[01:52:28.240 --> 01:52:30.160]   He would have the most fun
[01:52:30.160 --> 01:52:32.680]   by going to Mars and building rockets.
[01:52:32.680 --> 01:52:35.400]   And he's probably dreamt of rockets from when he was a kid
[01:52:35.400 --> 01:52:37.360]   and probably always played with rockets.
[01:52:37.360 --> 01:52:39.040]   And now he has the funds, the capital,
[01:52:39.040 --> 01:52:40.760]   to be able to deploy it.
[01:52:40.760 --> 01:52:43.840]   So he's being selfish.
[01:52:43.840 --> 01:52:45.600]   Obviously, he's being self-interested.
[01:52:45.600 --> 01:52:47.280]   This is what Elon Musk is about.
[01:52:47.280 --> 01:52:50.440]   I mean, the same with Jeff Bezos.
[01:52:50.440 --> 01:52:52.320]   There's no committee to decide
[01:52:52.320 --> 01:52:57.000]   whether to invest in cloud computing or not.
[01:52:57.000 --> 01:52:58.960]   Bezos decided that.
[01:52:58.960 --> 01:53:01.840]   And at the end of the day, they are the bosses.
[01:53:01.840 --> 01:53:03.720]   They pursue the values they believe are good.
[01:53:03.720 --> 01:53:06.080]   They create the wealth.
[01:53:06.080 --> 01:53:07.240]   It's their decisions.
[01:53:07.240 --> 01:53:08.960]   It's their mind.
[01:53:08.960 --> 01:53:10.960]   And the fact is we live in a world
[01:53:10.960 --> 01:53:15.960]   where for 2,000-plus years, self-interest,
[01:53:15.960 --> 01:53:20.600]   even though we all do it, to a small extent or less,
[01:53:20.600 --> 01:53:24.000]   we deem it as morally abhorrent.
[01:53:24.000 --> 01:53:26.160]   It's bad. It's wrong.
[01:53:26.160 --> 01:53:27.720]   I mean, your mother probably taught you
[01:53:27.720 --> 01:53:29.240]   the same thing my mother taught me.
[01:53:29.240 --> 01:53:31.000]   Think of others first.
[01:53:31.000 --> 01:53:32.760]   Think of yourself last.
[01:53:32.760 --> 01:53:35.680]   The good stuff is kept for the guests.
[01:53:35.680 --> 01:53:38.040]   You never get to use the good stuff.
[01:53:38.040 --> 01:53:39.720]   You know, it's others.
[01:53:39.720 --> 01:53:41.600]   That's what the focus of morality is.
[01:53:41.600 --> 01:53:44.960]   Now, no mother, even no Jewish mother,
[01:53:44.960 --> 01:53:47.040]   actually believes that, right?
[01:53:47.040 --> 01:53:50.640]   Because they don't really want you to be last.
[01:53:50.640 --> 01:53:53.480]   They want you to be first, and they push you to be first.
[01:53:53.480 --> 01:53:56.400]   But morally, they've been taught their entire lives,
[01:53:56.400 --> 01:53:59.800]   and they believe that the right thing to say
[01:53:59.800 --> 01:54:02.600]   and to some extent do
[01:54:02.600 --> 01:54:06.840]   is to argue for sacrifice for other people, right?
[01:54:06.840 --> 01:54:12.480]   So most people, 99% of people, are torn.
[01:54:12.480 --> 01:54:17.920]   They know they should be selfless,
[01:54:17.920 --> 01:54:20.000]   sacrifice, live for other people.
[01:54:20.000 --> 01:54:21.920]   They don't really want to,
[01:54:21.920 --> 01:54:25.040]   so they act selfishly in their day-to-day life,
[01:54:25.040 --> 01:54:28.480]   and they feel guilty, and they can't be happy.
[01:54:28.480 --> 01:54:30.000]   They can't be happy, and Jewish mothers
[01:54:30.000 --> 01:54:31.440]   and Catholic mothers are excellent
[01:54:31.440 --> 01:54:33.920]   at using that guilt to manipulate you.
[01:54:33.920 --> 01:54:35.120]   But the guilt is inevitable
[01:54:35.120 --> 01:54:38.360]   because you've got these two conflicting things,
[01:54:38.360 --> 01:54:39.360]   the way you want to live
[01:54:39.360 --> 01:54:42.040]   and the way you've been taught to live.
[01:54:42.040 --> 01:54:45.480]   And what objectivism does is it, at the end of the day,
[01:54:45.480 --> 01:54:49.160]   provides you with a way to unite morality,
[01:54:49.160 --> 01:54:52.720]   a proper morality, with what you want
[01:54:52.720 --> 01:54:55.080]   and to think about what you really want,
[01:54:55.080 --> 01:54:58.120]   to conceptualize what you really want properly.
[01:54:58.120 --> 01:55:00.080]   So what you want is really good for you,
[01:55:00.080 --> 01:55:03.360]   and what you want will really lead to your happiness.
[01:55:03.360 --> 01:55:06.760]   So, you know, we reject the idea of sacrifice.
[01:55:06.760 --> 01:55:08.480]   We reject the idea of living for other people.
[01:55:09.400 --> 01:55:14.160]   But you see, if you believe that the purpose of morality
[01:55:14.160 --> 01:55:16.200]   is to sacrifice for other people,
[01:55:16.200 --> 01:55:18.920]   and you look at Jeff Bezos,
[01:55:18.920 --> 01:55:22.160]   when was the last time he sacrificed anything, right?
[01:55:22.160 --> 01:55:23.560]   He's living pretty well.
[01:55:23.560 --> 01:55:26.240]   He's got billions that he could give it all away,
[01:55:26.240 --> 01:55:27.720]   and yet he doesn't.
[01:55:27.720 --> 01:55:28.840]   How dare he?
[01:55:28.840 --> 01:55:33.000]   You know, in my talks, I often position,
[01:55:33.000 --> 01:55:36.760]   and I'm gonna use vocate, sorry, guys.
[01:55:36.760 --> 01:55:38.000]   Drop the conspiracy theory.
[01:55:38.000 --> 01:55:41.360]   They're all BS, complete and utter nonsense.
[01:55:41.360 --> 01:55:42.920]   There's not a shred of truth.
[01:55:42.920 --> 01:55:47.440]   You know, I disagree with Bill Gates on everything political.
[01:55:47.440 --> 01:55:51.000]   I think he politically is a complete ignoramus,
[01:55:51.000 --> 01:55:54.200]   but the guy's a genius when it comes to technology.
[01:55:54.200 --> 01:55:58.000]   And he's just thoughtful, even in his philanthropy.
[01:55:58.000 --> 01:56:00.360]   He just uses his mind, and I respect that,
[01:56:00.360 --> 01:56:01.720]   even though politically he's terrible.
[01:56:01.720 --> 01:56:04.040]   Anyway, think about this.
[01:56:04.040 --> 01:56:06.920]   Who had a bigger impact on the lives
[01:56:06.920 --> 01:56:10.400]   of poor people in the world, Bill Gates or Mother Teresa?
[01:56:10.400 --> 01:56:13.640]   - Bill Gates. - It's not even close.
[01:56:13.640 --> 01:56:17.440]   And Mother Teresa lived this altruistic life to the core.
[01:56:17.440 --> 01:56:19.240]   She lived it consistently,
[01:56:19.240 --> 01:56:21.720]   and yet she was miserable, pathetic, horrible.
[01:56:21.720 --> 01:56:23.000]   She hated her life.
[01:56:23.000 --> 01:56:26.600]   She was miserable, and most of the people she helped
[01:56:26.600 --> 01:56:30.040]   didn't do very well, because she just helped them not die.
[01:56:30.040 --> 01:56:30.880]   Right? - Yeah.
[01:56:30.880 --> 01:56:32.840]   - And then Bill Gates changed the world,
[01:56:32.840 --> 01:56:35.120]   and he helped a lot by providing technology.
[01:56:35.120 --> 01:56:37.240]   We even, philanthropy gets to them.
[01:56:37.240 --> 01:56:39.600]   The food gets to them much faster, more efficient.
[01:56:39.600 --> 01:56:41.000]   Yet, who is the moral saint?
[01:56:41.000 --> 01:56:44.680]   Sainthood is not determined based on
[01:56:44.680 --> 01:56:46.160]   what you do for other people.
[01:56:46.160 --> 01:56:49.140]   Sainthood is based on how much pain you suffer.
[01:56:49.140 --> 01:56:52.120]   I like to ask people to go to a museum
[01:56:52.120 --> 01:56:54.680]   and look at all the paintings of saints,
[01:56:54.680 --> 01:56:57.440]   how many of them are smiling and are happy?
[01:56:57.440 --> 01:56:59.320]   They've usually got arrows through them
[01:56:59.320 --> 01:57:00.800]   and holes in their body,
[01:57:00.800 --> 01:57:02.740]   and they're just suffering a horrible death.
[01:57:02.740 --> 01:57:05.200]   The whole point of the morality we are taught
[01:57:05.200 --> 01:57:10.160]   is that happiness is immorality,
[01:57:10.160 --> 01:57:15.240]   that happy people cannot be good people,
[01:57:15.240 --> 01:57:17.320]   and that good people suffer,
[01:57:17.320 --> 01:57:20.800]   and that suffering is necessary for morality.
[01:57:20.800 --> 01:57:25.100]   Morality is about sacrifice, self-sacrifice and suffering.
[01:57:25.100 --> 01:57:28.420]   And at the end of the day,
[01:57:28.420 --> 01:57:30.040]   almost all the problems in the world
[01:57:30.040 --> 01:57:34.220]   boil down to that false view.
[01:57:34.220 --> 01:57:37.620]   - So, can we try to talk about,
[01:57:37.620 --> 01:57:39.860]   part of it is the problem of the word selfishness,
[01:57:39.860 --> 01:57:42.980]   but let's talk about the virtue of selfishness.
[01:57:42.980 --> 01:57:45.220]   So, let's start at the fact that, for me,
[01:57:45.220 --> 01:57:48.180]   I really enjoy doing stuff for other people.
[01:57:48.180 --> 01:57:53.180]   I enjoy being, cheering on the success of others.
[01:57:53.180 --> 01:57:55.420]   - Why?
[01:57:55.420 --> 01:57:56.500]   - I don't know.
[01:57:56.500 --> 01:57:57.500]   It's deep in the-- - Well, think about it.
[01:57:57.500 --> 01:57:58.340]   Why?
[01:57:59.300 --> 01:58:01.460]   'Cause I think you do know.
[01:58:01.460 --> 01:58:03.660]   - If I were to really think,
[01:58:03.660 --> 01:58:08.700]   I don't wanna resort to evolutionary arguments,
[01:58:08.700 --> 01:58:10.460]   or this is some how-- - No, some of it's evolutionary.
[01:58:10.460 --> 01:58:13.140]   - So, I think--
[01:58:13.140 --> 01:58:17.020]   - So, I can tell you why I enjoy helping others.
[01:58:17.020 --> 01:58:18.500]   - Maybe you can go there.
[01:58:18.500 --> 01:58:21.140]   One thing, 'cause we should talk about love a little bit.
[01:58:21.140 --> 01:58:23.020]   I'll tell you, there's a part of me
[01:58:23.020 --> 01:58:26.980]   that's a little bit not rational.
[01:58:26.980 --> 01:58:29.660]   There's a gut that I follow
[01:58:29.660 --> 01:58:32.420]   that not everything I do is perfectly rational.
[01:58:32.420 --> 01:58:36.700]   Like, for example, my dad criticizes me.
[01:58:36.700 --> 01:58:39.020]   He says, "You should always have a plan.
[01:58:39.020 --> 01:58:40.000]   "It should make sense.
[01:58:40.000 --> 01:58:41.540]   "You have to have a strategy."
[01:58:41.540 --> 01:58:45.420]   And I say that I stepped down
[01:58:45.420 --> 01:58:47.980]   from my full-salary position at MIT.
[01:58:47.980 --> 01:58:50.320]   There's so many things I did without a plan.
[01:58:50.320 --> 01:58:51.160]   It's the gut.
[01:58:51.160 --> 01:58:53.780]   It's like, I wanna start a company.
[01:58:53.780 --> 01:58:55.460]   Well, you know how many companies fail?
[01:58:55.460 --> 01:58:56.300]   I don't know.
[01:58:56.300 --> 01:58:57.140]   - 90%.
[01:58:57.140 --> 01:58:58.900]   - It's the gut.
[01:58:58.900 --> 01:59:02.900]   And the same thing with being kind to others is a gut.
[01:59:02.900 --> 01:59:06.540]   I watch the way that karma works in this world,
[01:59:06.540 --> 01:59:07.940]   that the people like us,
[01:59:07.940 --> 01:59:09.980]   one guy I look up to is Joe Rogan,
[01:59:09.980 --> 01:59:12.300]   that he does stuff for others,
[01:59:12.300 --> 01:59:15.460]   and that the joy he experiences,
[01:59:15.460 --> 01:59:16.940]   the way he sees the world,
[01:59:16.940 --> 01:59:20.860]   like just the glimmer in his eyes
[01:59:20.860 --> 01:59:22.740]   because he does stuff for others
[01:59:22.740 --> 01:59:24.300]   that creates a joyful experience.
[01:59:24.300 --> 01:59:27.940]   And that somehow seems to be an instructive way to,
[01:59:27.940 --> 01:59:31.660]   that to me is inspiring of a life well-lived.
[01:59:31.660 --> 01:59:33.100]   - But you probably know a lot of people
[01:59:33.100 --> 01:59:35.600]   who have done stuff for others who are not happy.
[01:59:35.600 --> 01:59:38.100]   - True.
[01:59:38.100 --> 01:59:40.060]   - So I don't think it's the doing stuff for others
[01:59:40.060 --> 01:59:41.220]   that brings the happiness.
[01:59:41.220 --> 01:59:42.640]   It's why you do stuff for others
[01:59:42.640 --> 01:59:44.260]   and what else you're doing in your life
[01:59:44.260 --> 01:59:48.540]   and what is the proportion.
[01:59:48.540 --> 01:59:50.260]   But it's why at the end of the day,
[01:59:50.260 --> 01:59:52.500]   which is, and it's the same.
[01:59:52.500 --> 01:59:55.180]   Look, you can maybe through a gut feeling,
[01:59:55.180 --> 01:59:56.780]   say I want to start a company,
[01:59:56.780 --> 01:59:59.700]   but you better start doing thinking about how and what
[01:59:59.700 --> 02:00:00.540]   and all of that.
[02:00:00.540 --> 02:00:01.900]   And to some extent the why,
[02:00:01.900 --> 02:00:03.840]   because if you really want to be happy doing this,
[02:00:03.840 --> 02:00:05.360]   you may better make sure you're doing it
[02:00:05.360 --> 02:00:06.860]   for the right reason.
[02:00:06.860 --> 02:00:10.340]   So I'm not, there's something called fast thinking,
[02:00:10.340 --> 02:00:11.180]   Coleman, the-
[02:00:11.180 --> 02:00:13.780]   - Daniel Kahneman?
[02:00:13.780 --> 02:00:14.620]   - Yes.
[02:00:14.620 --> 02:00:15.700]   Daniel Kahneman talks about,
[02:00:15.700 --> 02:00:18.420]   and there is, it's,
[02:00:18.420 --> 02:00:22.060]   all the integrations you've made so far in your life
[02:00:22.060 --> 02:00:25.180]   cause you to have specialized knowledge in certain things
[02:00:25.180 --> 02:00:27.160]   and you can think very fast.
[02:00:27.160 --> 02:00:31.500]   And your gut tells you what the right answer is.
[02:00:31.500 --> 02:00:32.820]   But it's not.
[02:00:32.820 --> 02:00:35.900]   Your mind is constantly evaluating and constantly working.
[02:00:35.900 --> 02:00:39.340]   You want to make it as rational as you can,
[02:00:39.340 --> 02:00:41.020]   not in the sense that I have to think through
[02:00:41.020 --> 02:00:42.520]   every time I make a decision,
[02:00:42.520 --> 02:00:45.900]   but that they've so programmed my mind in a sense
[02:00:45.900 --> 02:00:48.600]   that the answers are the right answers,
[02:00:48.600 --> 02:00:51.480]   when I get them.
[02:00:51.720 --> 02:00:56.720]   So, you know, I like,
[02:00:56.720 --> 02:00:59.220]   I view other people as a value.
[02:00:59.220 --> 02:01:02.980]   Other people contribute enormously to my life.
[02:01:02.980 --> 02:01:07.360]   Whether it's a romantic love relationship
[02:01:07.360 --> 02:01:09.440]   or whether it's a friendship relationship
[02:01:09.440 --> 02:01:12.560]   or whether it's just, you know,
[02:01:12.560 --> 02:01:15.000]   Jeff Bezos creating Amazon
[02:01:15.000 --> 02:01:18.520]   and delivering goodies to my home when I get them.
[02:01:18.520 --> 02:01:20.640]   And people do all that, right?
[02:01:20.640 --> 02:01:22.160]   It's not just Jeff Bezos.
[02:01:22.160 --> 02:01:23.080]   He gets the most credit,
[02:01:23.080 --> 02:01:24.760]   but everybody in that chain of command,
[02:01:24.760 --> 02:01:27.360]   everybody at Amazon is working for me.
[02:01:27.360 --> 02:01:28.560]   I love that.
[02:01:28.560 --> 02:01:31.560]   I love the idea of a human being.
[02:01:31.560 --> 02:01:34.520]   I love the idea that there are people capable
[02:01:34.520 --> 02:01:37.600]   of being an Einstein, of being, you know,
[02:01:37.600 --> 02:01:40.400]   and creating and building and making stuff
[02:01:40.400 --> 02:01:42.400]   that makes my life so good.
[02:01:42.400 --> 02:01:45.480]   You know, most of us like,
[02:01:45.480 --> 02:01:47.440]   this is not a good room for an example.
[02:01:47.440 --> 02:01:50.020]   Most of us like plants, right?
[02:01:50.020 --> 02:01:51.400]   We like pets.
[02:01:51.400 --> 02:01:53.240]   I don't particularly, but people like pets.
[02:01:53.240 --> 02:01:54.080]   Why?
[02:01:54.080 --> 02:01:55.760]   We like to see life.
[02:01:55.760 --> 02:01:59.800]   Human beings are life on steroids, right?
[02:01:59.800 --> 02:02:01.040]   They're life with a brain.
[02:02:01.040 --> 02:02:03.560]   It's amazing, right, what they can do.
[02:02:03.560 --> 02:02:05.260]   I love people.
[02:02:05.260 --> 02:02:07.160]   Now, that doesn't mean I love everybody
[02:02:07.160 --> 02:02:08.040]   'cause there's some,
[02:02:08.040 --> 02:02:10.680]   there are really bad people out there who I hate, right?
[02:02:10.680 --> 02:02:11.960]   And I do hate.
[02:02:11.960 --> 02:02:14.120]   And there are people out there that are just,
[02:02:14.120 --> 02:02:15.520]   I have no opinion about.
[02:02:15.520 --> 02:02:18.680]   But generally, the idea of a human being
[02:02:18.680 --> 02:02:20.000]   to me is a phenomenal idea.
[02:02:20.000 --> 02:02:22.600]   When I see a baby, I light up
[02:02:22.600 --> 02:02:26.060]   because to me, there's a potential, you know,
[02:02:26.060 --> 02:02:31.100]   there's this magnificent potential that is embodied in that.
[02:02:31.100 --> 02:02:34.120]   And when I see people struggling and need help,
[02:02:34.120 --> 02:02:36.640]   I think they're human beings.
[02:02:36.640 --> 02:02:38.640]   They embody that potential.
[02:02:38.640 --> 02:02:40.820]   They embody that goodness.
[02:02:40.820 --> 02:02:43.240]   They might turn out to be bad,
[02:02:43.240 --> 02:02:45.360]   but why would I ever give the presumption of that?
[02:02:45.360 --> 02:02:46.980]   I give them the presumption of the positive
[02:02:46.980 --> 02:02:48.880]   and I cheer them on.
[02:02:48.880 --> 02:02:52.200]   And I enjoy watching people succeed.
[02:02:52.200 --> 02:02:54.760]   I enjoy watching people get to the top of the mountain
[02:02:54.760 --> 02:02:56.160]   and produce something.
[02:02:56.160 --> 02:02:59.080]   Even if I don't get anything directly from it,
[02:02:59.080 --> 02:03:03.360]   I enjoy that because it's part of my enjoyment of life.
[02:03:03.360 --> 02:03:08.280]   - So the word, to you, the morality of selfishness,
[02:03:08.280 --> 02:03:10.360]   this kind of love of other human beings,
[02:03:10.360 --> 02:03:13.920]   the love of life fits into a morality of selfishness.
[02:03:13.920 --> 02:03:14.880]   - Can't not.
[02:03:15.860 --> 02:03:20.060]   Because there's no context in which you can truly
[02:03:20.060 --> 02:03:23.300]   love yourself without loving life
[02:03:23.300 --> 02:03:25.140]   and loving what it means to be human.
[02:03:25.140 --> 02:03:30.180]   So, you know, the love of yourself is gonna manifest itself
[02:03:30.180 --> 02:03:32.900]   differently in different people, but it's core.
[02:03:32.900 --> 02:03:34.940]   What do you love about yourself?
[02:03:34.940 --> 02:03:35.920]   First of all, I love.
[02:03:35.920 --> 02:03:37.020]   I love that I'm alive.
[02:03:37.020 --> 02:03:39.380]   I love that, you know, I love this world
[02:03:39.380 --> 02:03:40.980]   and the opportunities it provides me
[02:03:40.980 --> 02:03:45.020]   and the fun and the excitement of discovering something new
[02:03:45.020 --> 02:03:48.200]   and meeting a new person and having a conversation.
[02:03:48.200 --> 02:03:52.580]   You know, all of this is immensely enjoyable,
[02:03:52.580 --> 02:03:55.540]   but behind all of that is a particular human capability
[02:03:55.540 --> 02:03:57.700]   that not only I have, other people have.
[02:03:57.700 --> 02:03:59.940]   And the fact that they have it makes my life
[02:03:59.940 --> 02:04:02.900]   so much more fun because, so it's,
[02:04:02.900 --> 02:04:07.380]   you cannot view, you know, it's all integrated
[02:04:07.380 --> 02:04:09.340]   and you cannot view yourself in isolation.
[02:04:09.340 --> 02:04:13.240]   Now that doesn't place a moral commandment on me.
[02:04:14.660 --> 02:04:17.020]   Help everybody who's poor that you happen
[02:04:17.020 --> 02:04:18.580]   to meet in the street.
[02:04:18.580 --> 02:04:21.540]   It doesn't place a burden on me in a sense
[02:04:21.540 --> 02:04:25.660]   that now I have this moral duty to help everybody.
[02:04:25.660 --> 02:04:27.820]   It leaves me free to make decisions
[02:04:27.820 --> 02:04:28.940]   about who I help and who I don't.
[02:04:28.940 --> 02:04:31.580]   There's some people who I will not help.
[02:04:31.580 --> 02:04:35.520]   There's some people who I do not wish positive things upon.
[02:04:35.520 --> 02:04:39.500]   Bad people should have bad outcomes.
[02:04:39.500 --> 02:04:41.800]   Bad people should suffer.
[02:04:41.800 --> 02:04:42.640]   So--
[02:04:42.640 --> 02:04:44.140]   - And then you have the freedom to choose
[02:04:44.140 --> 02:04:45.620]   who's good, who's bad within your home.
[02:04:45.620 --> 02:04:47.740]   - It's your decision based on your values.
[02:04:47.740 --> 02:04:49.780]   Now, I think there's an objectivity to it.
[02:04:49.780 --> 02:04:52.100]   There's a standard by which you should evaluate
[02:04:52.100 --> 02:04:54.420]   good versus bad, and that standard should be
[02:04:54.420 --> 02:04:57.580]   to what extent do they contribute or hurt human life?
[02:04:57.580 --> 02:04:59.640]   The standard is human life.
[02:04:59.640 --> 02:05:01.620]   And so when I say, look at Jeff Bezos,
[02:05:01.620 --> 02:05:04.220]   I say he's contributed to human life, good guy.
[02:05:04.220 --> 02:05:05.860]   I might disagree with him on stuff.
[02:05:05.860 --> 02:05:07.300]   We might disagree about politics.
[02:05:07.300 --> 02:05:08.940]   We might disagree about women.
[02:05:08.940 --> 02:05:12.980]   I don't know what we agree, but overall, big picture,
[02:05:12.980 --> 02:05:15.340]   he is pro-life, right?
[02:05:15.340 --> 02:05:16.900]   I look at somebody like, you know,
[02:05:16.900 --> 02:05:20.620]   to take like 99.9% of our politicians,
[02:05:20.620 --> 02:05:22.900]   and they are pro-death.
[02:05:22.900 --> 02:05:25.580]   They are pro-destruction.
[02:05:25.580 --> 02:05:28.060]   They are pro-cutting corners in ways
[02:05:28.060 --> 02:05:30.220]   that destroy human life and human potential
[02:05:30.220 --> 02:05:31.240]   and human ability.
[02:05:31.240 --> 02:05:34.340]   So I literally hate almost every politician out there.
[02:05:34.340 --> 02:05:38.100]   And I wish ill on them, right?
[02:05:38.100 --> 02:05:40.180]   I don't want them to be successful or happy.
[02:05:40.180 --> 02:05:42.260]   I want them all to go away, right?
[02:05:42.260 --> 02:05:43.100]   Don't leave me alone.
[02:05:43.100 --> 02:05:45.260]   So I believe in justice.
[02:05:45.260 --> 02:05:46.860]   I believe good things should happen to good people
[02:05:46.860 --> 02:05:48.020]   and bad things should happen to bad people.
[02:05:48.020 --> 02:05:52.660]   So I make those generalizations based on this one,
[02:05:52.660 --> 02:05:54.180]   you know, on the other hand,
[02:05:54.180 --> 02:05:55.780]   I shouldn't say all politicians, right?
[02:05:55.780 --> 02:05:57.580]   So if I, you know, I love Thomas Jefferson
[02:05:57.580 --> 02:05:59.460]   and George Washington, right?
[02:05:59.460 --> 02:06:00.580]   I love Abraham Lincoln.
[02:06:00.580 --> 02:06:02.740]   I love people who fought for freedom
[02:06:02.740 --> 02:06:04.800]   and who believed in freedom, who had these ideas
[02:06:04.800 --> 02:06:07.600]   and lived up to, at least in parts of their lives,
[02:06:07.600 --> 02:06:08.440]   to those principles.
[02:06:08.440 --> 02:06:10.420]   Now, do I think Thomas Jefferson was flawed
[02:06:10.420 --> 02:06:11.420]   because he helped slaves?
[02:06:11.420 --> 02:06:12.980]   Absolutely.
[02:06:12.980 --> 02:06:15.620]   But the virtues way outweigh that in my view.
[02:06:15.620 --> 02:06:17.660]   And I understand people who don't accept that.
[02:06:17.660 --> 02:06:20.580]   - You don't have to also love and hate the entirety
[02:06:20.580 --> 02:06:21.400]   of the person.
[02:06:21.400 --> 02:06:23.500]   There's parts of that person that you're attracted to.
[02:06:23.500 --> 02:06:25.020]   - The major part is pro-life
[02:06:25.020 --> 02:06:26.620]   and therefore I'm pro that person.
[02:06:26.620 --> 02:06:28.620]   And I think, and I said earlier
[02:06:28.620 --> 02:06:30.140]   that objectivism is philosophy of love.
[02:06:30.140 --> 02:06:35.140]   And I believe that because objectivism is about your life,
[02:06:35.140 --> 02:06:38.300]   about loving your life, about embracing your life,
[02:06:38.300 --> 02:06:40.020]   about engaging with the world,
[02:06:40.020 --> 02:06:42.660]   about loving the world in which you live,
[02:06:42.660 --> 02:06:44.860]   about win-win relationships with other people,
[02:06:44.860 --> 02:06:48.340]   which means to a large extent loving the good
[02:06:48.340 --> 02:06:50.780]   in other people and the best in other people
[02:06:50.780 --> 02:06:53.520]   and encouraging that and supporting that and promoting that.
[02:06:53.520 --> 02:06:56.500]   So I know selfishness is a harsh word
[02:06:56.500 --> 02:06:59.060]   because the culture has given it that harshness.
[02:06:59.060 --> 02:07:00.380]   Selfishness is a harsh word
[02:07:00.380 --> 02:07:02.020]   because the people who don't like selfishness
[02:07:02.020 --> 02:07:04.300]   want you to believe it's a harsh word.
[02:07:04.300 --> 02:07:05.700]   But it's not.
[02:07:05.700 --> 02:07:06.620]   What does it mean?
[02:07:06.620 --> 02:07:09.060]   It means focus on self.
[02:07:09.060 --> 02:07:10.900]   It means take care of self.
[02:07:10.900 --> 02:07:13.440]   It means make yourself your highest priority,
[02:07:13.440 --> 02:07:16.820]   not your only priority, because in taking care of self,
[02:07:16.820 --> 02:07:20.420]   what would I be without my wife?
[02:07:20.420 --> 02:07:24.540]   What would I be without the people who support me,
[02:07:24.540 --> 02:07:28.620]   who help me, who I have these love relationships with?
[02:07:28.620 --> 02:07:31.980]   So other people are crucial.
[02:07:31.980 --> 02:07:35.940]   What would my life be without Steve Jobs?
[02:07:36.100 --> 02:07:37.020]   Right?
[02:07:37.020 --> 02:07:41.420]   - A lot of things you mentioned here are just beautiful.
[02:07:41.420 --> 02:07:42.940]   So one is win-win.
[02:07:42.940 --> 02:07:45.900]   So one key thing about this selfishness
[02:07:45.900 --> 02:07:48.820]   and the idea of objectivism as a philosophy of love
[02:07:48.820 --> 02:07:52.340]   is that you don't want parasitism.
[02:07:52.340 --> 02:07:54.500]   So that is unethical.
[02:07:54.500 --> 02:07:58.380]   So you actually, first of all, you say win-win a lot,
[02:07:58.380 --> 02:08:00.320]   and I just like that terminology
[02:08:00.320 --> 02:08:02.340]   because it's a good way to see life.
[02:08:02.340 --> 02:08:06.620]   It's trying to maximize the number of win-win interactions.
[02:08:06.620 --> 02:08:08.420]   That's a good way to see business, actually.
[02:08:08.420 --> 02:08:09.580]   - Well, life generally.
[02:08:09.580 --> 02:08:11.020]   I think every aspect of life,
[02:08:11.020 --> 02:08:13.880]   you want to have a win-win relationship with your wife.
[02:08:13.880 --> 02:08:16.100]   Imagine if it was win-lose.
[02:08:16.100 --> 02:08:18.300]   Either way, if you win and she loses,
[02:08:18.300 --> 02:08:20.500]   how long is that going to sustain?
[02:08:20.500 --> 02:08:25.300]   So win-lose relationships are not in equilibrium.
[02:08:25.300 --> 02:08:27.180]   What they turn into is lose-lose.
[02:08:27.180 --> 02:08:29.880]   Like win-lose turns into lose-lose.
[02:08:29.880 --> 02:08:34.360]   And so the only alternative to lose-lose is win-win.
[02:08:34.360 --> 02:08:36.960]   And you win and the person you love wins.
[02:08:36.960 --> 02:08:38.480]   What's better than that, right?
[02:08:38.480 --> 02:08:39.980]   - That's the way to maximize.
[02:08:39.980 --> 02:08:43.360]   So like the selfishness is you're trying
[02:08:43.360 --> 02:08:46.060]   to maximize the win, but the way to maximize the win
[02:08:46.060 --> 02:08:48.220]   is to maximize the win-win.
[02:08:48.220 --> 02:08:49.640]   - Yes, and it turns out,
[02:08:49.640 --> 02:08:51.840]   and Adam Smith understood this a long time ago,
[02:08:51.840 --> 02:08:54.120]   that if you focus on your own winning
[02:08:54.120 --> 02:08:58.000]   while respecting other people as human beings,
[02:08:58.000 --> 02:08:59.160]   then everybody wins.
[02:08:59.160 --> 02:09:00.280]   And the beauty of capitalism,
[02:09:00.280 --> 02:09:02.240]   if we go back to capitalism for a second,
[02:09:02.240 --> 02:09:05.120]   the beauty of capitalism is you cannot be successful
[02:09:05.120 --> 02:09:08.800]   in capitalism without producing values
[02:09:08.800 --> 02:09:10.240]   that other people appreciate
[02:09:10.240 --> 02:09:12.120]   and therefore willing to buy from you.
[02:09:12.120 --> 02:09:14.960]   And they buy them, and this goes back to that question
[02:09:14.960 --> 02:09:16.520]   about the engineer and Steve Jobs.
[02:09:16.520 --> 02:09:18.960]   Why is the engineer working there?
[02:09:18.960 --> 02:09:22.560]   Because he's getting paid more than his time is worth to him.
[02:09:22.560 --> 02:09:24.280]   I know people don't like to think in those terms,
[02:09:24.280 --> 02:09:25.720]   but that's the reality.
[02:09:25.720 --> 02:09:27.160]   If his time is worth more to him
[02:09:27.160 --> 02:09:29.880]   than what he's getting paid, he would leave.
[02:09:29.880 --> 02:09:30.840]   So he's winning.
[02:09:30.840 --> 02:09:33.120]   And is Apple winning?
[02:09:33.120 --> 02:09:35.280]   Yes, because they're getting more productivity from him,
[02:09:35.280 --> 02:09:36.600]   they're getting more from him
[02:09:36.600 --> 02:09:40.240]   than what he's actually producing.
[02:09:40.240 --> 02:09:44.120]   - It's tough because there's human psychology
[02:09:44.120 --> 02:09:45.720]   and imperfect information.
[02:09:45.720 --> 02:09:47.820]   It just makes it a little messier
[02:09:47.820 --> 02:09:50.360]   than the clarity of thinking you have about this.
[02:09:50.360 --> 02:09:54.240]   It's just, you know, because for sure,
[02:09:54.240 --> 02:09:56.920]   but not everything in life is an economic transaction.
[02:09:56.920 --> 02:10:00.480]   It ultimately is close.
[02:10:00.480 --> 02:10:02.240]   - Even if it's not an economic transaction,
[02:10:02.240 --> 02:10:05.560]   even if it's a relationship transaction,
[02:10:05.560 --> 02:10:08.640]   when you get to a point with a friend
[02:10:08.640 --> 02:10:11.400]   where you're not gaining from the relationship,
[02:10:11.400 --> 02:10:12.560]   friendship's gonna be over.
[02:10:12.560 --> 02:10:14.720]   Not immediately, because it takes time for these things
[02:10:14.720 --> 02:10:17.200]   to manifest itself and to really absorb into,
[02:10:17.200 --> 02:10:20.200]   but we change friendships, we change our loves, right?
[02:10:20.200 --> 02:10:22.000]   We fall in and out of love.
[02:10:22.000 --> 02:10:23.880]   We fall out of love because we're not,
[02:10:23.880 --> 02:10:27.000]   love, so let's go back to love, right?
[02:10:27.000 --> 02:10:29.160]   Love is the most selfish of all emotions.
[02:10:29.160 --> 02:10:33.000]   Love is about what you do to me, right?
[02:10:33.000 --> 02:10:34.760]   So I love my wife 'cause she makes me
[02:10:34.760 --> 02:10:36.240]   feel better about myself.
[02:10:36.240 --> 02:10:41.440]   So, you know, the idea of selfless love is bizarre.
[02:10:41.440 --> 02:10:45.840]   So Ayn Rand used to say, before you say, "I love you,"
[02:10:45.840 --> 02:10:47.240]   you have to say the "I."
[02:10:47.240 --> 02:10:51.400]   And you have to know who you are
[02:10:51.400 --> 02:10:52.960]   and you have to appreciate yourself.
[02:10:52.960 --> 02:10:54.440]   If you hate yourself,
[02:10:54.440 --> 02:10:56.400]   what does it mean to love somebody else?
[02:10:56.400 --> 02:10:59.960]   So I love my wife 'cause she makes me
[02:10:59.960 --> 02:11:01.440]   feel great about the world.
[02:11:01.440 --> 02:11:04.800]   And she loves me for the same reason.
[02:11:04.800 --> 02:11:07.800]   And so Ayn Rand used to use this example.
[02:11:07.800 --> 02:11:11.080]   Imagine you go up to your, to be spoused
[02:11:11.080 --> 02:11:13.480]   the night before the wedding, and you say,
[02:11:13.480 --> 02:11:16.720]   "I get nothing out of this relationship.
[02:11:16.720 --> 02:11:21.040]   "I'm doing this purely as an act of noble self-sacrifice."
[02:11:21.040 --> 02:11:22.240]   (laughing)
[02:11:22.240 --> 02:11:23.720]   She would slap you.
[02:11:23.720 --> 02:11:25.520]   And she should, right?
[02:11:25.520 --> 02:11:30.120]   So, no, we know this intuitively that love is selfish,
[02:11:30.120 --> 02:11:32.080]   but we are afraid to admit it to ourselves.
[02:11:32.080 --> 02:11:32.960]   And why?
[02:11:32.960 --> 02:11:35.240]   Because the other side has convinced us
[02:11:35.240 --> 02:11:38.760]   that selfishness is associated with exploiting other people.
[02:11:38.760 --> 02:11:41.400]   Selfishness means lying, cheating, stealing,
[02:11:41.400 --> 02:11:44.440]   walking on corpses, backstabbing people.
[02:11:44.440 --> 02:11:48.240]   But is that ever in your self-interest?
[02:11:48.240 --> 02:11:49.800]   Truly, right?
[02:11:50.760 --> 02:11:52.320]   I'll often be in front of an audience and say,
[02:11:52.320 --> 02:11:54.600]   "Okay, how many people here have lied?"
[02:11:54.600 --> 02:11:57.080]   I'm kidding, right?
[02:11:57.080 --> 02:12:00.880]   How many of you think that if you did that consistently,
[02:12:00.880 --> 02:12:02.520]   that would make your life better?
[02:12:02.520 --> 02:12:05.000]   Nobody thinks that, right?
[02:12:05.000 --> 02:12:09.840]   Because everybody's experienced how shitty lying,
[02:12:09.840 --> 02:12:11.400]   not because of how it makes you feel
[02:12:11.400 --> 02:12:12.480]   out of a sense of guilt.
[02:12:12.480 --> 02:12:15.360]   Existentially, it's just a bad strategy, right?
[02:12:15.360 --> 02:12:18.240]   You get caught, you have to create other lies
[02:12:18.240 --> 02:12:19.960]   to cover up the previous lie.
[02:12:19.960 --> 02:12:21.720]   It screws up with your own psychology
[02:12:21.720 --> 02:12:23.560]   and your own cognition.
[02:12:23.560 --> 02:12:27.920]   The mind, to some extent like a computer, right,
[02:12:27.920 --> 02:12:29.720]   is an integrating machine.
[02:12:29.720 --> 02:12:31.160]   And in computer science, I understand
[02:12:31.160 --> 02:12:33.800]   there's a term called garbage in, garbage out.
[02:12:33.800 --> 02:12:35.080]   Lying is garbage in.
[02:12:35.080 --> 02:12:36.040]   - Yeah.
[02:12:36.040 --> 02:12:40.600]   - So it's not good strategy, cheating,
[02:12:40.600 --> 02:12:42.800]   screwing your customers in a business,
[02:12:42.800 --> 02:12:45.160]   not paying your suppliers as a businessman,
[02:12:45.160 --> 02:12:47.080]   not good business practices,
[02:12:47.080 --> 02:12:49.360]   not good practices for being alive.
[02:12:49.360 --> 02:12:53.000]   So win-win is both moral and practical.
[02:12:53.000 --> 02:12:55.080]   And the beauty of Ayn Rand's philosophy,
[02:12:55.080 --> 02:12:57.280]   and I think this is really important,
[02:12:57.280 --> 02:12:58.800]   is that the moral is the practical
[02:12:58.800 --> 02:13:00.360]   and the practical is the moral.
[02:13:00.360 --> 02:13:03.320]   And therefore, if you are moral, you will be happy.
[02:13:03.320 --> 02:13:08.080]   - Yeah, that's why the application
[02:13:08.080 --> 02:13:11.880]   of the philosophy of objectivism is so easy to practice,
[02:13:11.880 --> 02:13:15.240]   so like, or to discuss, or possible to discuss.
[02:13:15.240 --> 02:13:16.600]   That's why you talk about all--
[02:13:16.600 --> 02:13:17.640]   - So clear cut.
[02:13:17.640 --> 02:13:18.480]   - Yeah.
[02:13:18.480 --> 02:13:19.400]   - I'm not ambiguous about my view.
[02:13:19.400 --> 02:13:20.960]   - And it's fundamentally practical.
[02:13:20.960 --> 02:13:24.480]   I mean, that's the best of philosophies is practical.
[02:13:24.480 --> 02:13:27.760]   - It's in a sense teaching you how to live a good life.
[02:13:27.760 --> 02:13:30.200]   And it's teaching you how to live a good life,
[02:13:30.200 --> 02:13:33.320]   not just as you, but as a human being.
[02:13:33.320 --> 02:13:35.480]   And therefore, the principles that apply to you
[02:13:35.480 --> 02:13:37.280]   probably apply to me as well.
[02:13:37.280 --> 02:13:40.080]   And if we both share the same principles
[02:13:40.080 --> 02:13:41.320]   of how to live a good life,
[02:13:41.320 --> 02:13:42.680]   we're not gonna be enemies.
[02:13:42.680 --> 02:13:46.880]   - You brought up anarchy earlier.
[02:13:46.880 --> 02:13:49.600]   It's an interesting question
[02:13:49.600 --> 02:13:52.060]   because you've kind of said politicians,
[02:13:52.060 --> 02:13:54.040]   I mean, part of it is a little bit joking,
[02:13:54.040 --> 02:13:57.440]   but politicians are not good people.
[02:13:57.440 --> 02:13:58.280]   - Yeah.
[02:13:58.280 --> 02:14:02.120]   - But we should have some?
[02:14:02.120 --> 02:14:05.880]   So you have an opposition to anarchism.
[02:14:05.880 --> 02:14:08.400]   - So first of all, they weren't always not bad people.
[02:14:08.400 --> 02:14:10.880]   That is, I gave examples of people
[02:14:10.880 --> 02:14:11.920]   who engage in political life
[02:14:11.920 --> 02:14:13.880]   who I think were good people basically.
[02:14:13.880 --> 02:14:17.160]   But they think they get worse over time
[02:14:17.160 --> 02:14:20.000]   if the system is corrupt.
[02:14:20.000 --> 02:14:21.960]   And I think the system, unfortunately,
[02:14:21.960 --> 02:14:24.600]   even the American system, as good as it was,
[02:14:24.600 --> 02:14:27.400]   was founded on quicksand and have corruption built in.
[02:14:27.400 --> 02:14:30.400]   They didn't quite get it.
[02:14:30.400 --> 02:14:31.960]   And they needed Ayn Rand to get it.
[02:14:31.960 --> 02:14:32.960]   So I'm not blaming them.
[02:14:32.960 --> 02:14:34.480]   I don't think they share any blame.
[02:14:34.480 --> 02:14:39.280]   You needed a philosophy in order to completely fulfill
[02:14:39.280 --> 02:14:40.840]   the promise that is America,
[02:14:40.840 --> 02:14:42.280]   or the promise that is the founding of America.
[02:14:42.280 --> 02:14:45.360]   - So the place where the corruption sneaked in
[02:14:45.360 --> 02:14:48.440]   is the lack in some way of the philosophy
[02:14:48.440 --> 02:14:49.640]   underlying the nation?
[02:14:49.640 --> 02:14:50.480]   - Absolutely.
[02:14:50.480 --> 02:14:53.120]   So it's Christianity.
[02:14:53.120 --> 02:14:57.160]   It's, you know, not to hit on another controversial topic.
[02:14:57.160 --> 02:15:01.840]   It's religion, which undercut their morality.
[02:15:01.840 --> 02:15:05.920]   So the founders were explicitly Christian
[02:15:05.920 --> 02:15:08.260]   and altruistic in their morality.
[02:15:09.100 --> 02:15:11.820]   Implicitly, in terms of their actions,
[02:15:11.820 --> 02:15:12.900]   they were completely secular,
[02:15:12.900 --> 02:15:15.260]   and they were very secular anyway.
[02:15:15.260 --> 02:15:17.740]   But in their morality, even, they were secular.
[02:15:17.740 --> 02:15:20.060]   So there's nothing in Christianity that says
[02:15:20.060 --> 02:15:23.240]   that you have an inalienable right to pursue happiness.
[02:15:23.240 --> 02:15:25.180]   That's unbelievably self-interested
[02:15:25.180 --> 02:15:27.980]   and based on kind of a moral philosophy,
[02:15:27.980 --> 02:15:30.100]   of egoistic moral philosophy.
[02:15:30.100 --> 02:15:31.180]   But they didn't know that.
[02:15:31.180 --> 02:15:33.100]   And they didn't know how to ground it.
[02:15:33.100 --> 02:15:36.100]   They implicitly, they had that fast thinking, that gut,
[02:15:36.100 --> 02:15:37.580]   that told them that this was right.
[02:15:37.580 --> 02:15:39.020]   And the whole enlightenment,
[02:15:39.020 --> 02:15:43.460]   that period from John Locke on to really to Hume,
[02:15:43.460 --> 02:15:47.300]   that period is about pursuit of happiness
[02:15:47.300 --> 02:15:50.300]   using reason in pursuit of the good life, right?
[02:15:50.300 --> 02:15:51.540]   But they can't ground it.
[02:15:51.540 --> 02:15:53.300]   They don't really understand what reason is,
[02:15:53.300 --> 02:15:56.860]   and they don't really understand what happiness requires,
[02:15:56.860 --> 02:16:00.080]   and they can't detach themselves from Christianity.
[02:16:00.080 --> 02:16:01.420]   They're not allowed to politically,
[02:16:01.420 --> 02:16:02.740]   and I think conceptually,
[02:16:02.740 --> 02:16:05.140]   you just can't make that big break.
[02:16:05.140 --> 02:16:07.180]   Rand is an enlightenment thinker in that sense.
[02:16:07.180 --> 02:16:10.980]   She is what should have followed right after, right?
[02:16:10.980 --> 02:16:15.860]   She should have come in, grounded them in the secular
[02:16:15.860 --> 02:16:19.940]   and in the egoistic and Aristotelian view of morality
[02:16:19.940 --> 02:16:24.940]   as a code of values to basically to guide your life,
[02:16:24.940 --> 02:16:27.260]   to guide your life towards happiness.
[02:16:27.260 --> 02:16:28.820]   That's Aristotle's view, right?
[02:16:28.820 --> 02:16:34.020]   So they didn't have that.
[02:16:34.020 --> 02:16:38.420]   So I think that government is necessary.
[02:16:38.420 --> 02:16:40.860]   It's not a necessary evil, it's a necessary good
[02:16:40.860 --> 02:16:42.940]   'cause it does something good.
[02:16:42.940 --> 02:16:45.860]   And the good that it does
[02:16:45.860 --> 02:16:48.060]   is it eliminates coercion from society.
[02:16:48.060 --> 02:16:50.020]   It eliminates violence from society.
[02:16:50.020 --> 02:16:52.700]   It eliminates the use of force
[02:16:52.700 --> 02:16:55.380]   between individuals from society.
[02:16:55.380 --> 02:16:56.940]   And that--
[02:16:56.940 --> 02:16:59.380]   - But see, the argument that Michael Malice would make.
[02:16:59.380 --> 02:17:00.740]   (laughing)
[02:17:00.740 --> 02:17:02.500]   Give me a chance here.
[02:17:03.340 --> 02:17:05.940]   Why can't you apply the same kind of reasoning
[02:17:05.940 --> 02:17:08.740]   that you've effectively used for the rest
[02:17:08.740 --> 02:17:12.140]   of mutually agreed upon institutions
[02:17:12.140 --> 02:17:14.020]   that are driven by capitalism,
[02:17:14.020 --> 02:17:18.020]   that we can't also hire forces to protect us
[02:17:18.020 --> 02:17:21.520]   from the violence to ensure the stability of society
[02:17:21.520 --> 02:17:23.260]   that protects us from the violence?
[02:17:23.260 --> 02:17:28.420]   Why draw the line at this particular place, right?
[02:17:28.420 --> 02:17:30.780]   - Well, because there is no other place to draw a line
[02:17:30.780 --> 02:17:32.460]   and there is a line.
[02:17:32.460 --> 02:17:34.960]   And by the way, we draw lines other places, right?
[02:17:34.960 --> 02:17:40.340]   We don't vote.
[02:17:40.340 --> 02:17:43.180]   We don't have...
[02:17:43.180 --> 02:17:48.000]   We don't determine truth in science based on competition.
[02:17:48.000 --> 02:17:51.380]   - Right, so that's a line.
[02:17:51.380 --> 02:17:52.220]   - That's a line.
[02:17:52.220 --> 02:17:53.540]   - But first of all, some people might say--
[02:17:53.540 --> 02:17:55.220]   - I mean, there's competition in a sense
[02:17:55.220 --> 02:17:57.220]   that you have alternate theories,
[02:17:57.220 --> 02:17:58.940]   but at the end of the day,
[02:17:58.940 --> 02:18:01.700]   whether you decide that he's right or he's right
[02:18:01.700 --> 02:18:04.660]   is not based on the market,
[02:18:04.660 --> 02:18:09.180]   it's based on facts, on reality, on objective reality.
[02:18:09.180 --> 02:18:14.300]   And some people will never accept that this person is right
[02:18:14.300 --> 02:18:16.980]   because they don't see the strength.
[02:18:16.980 --> 02:18:19.140]   So first of all, what they reject,
[02:18:19.140 --> 02:18:20.480]   what most anarchists reject,
[02:18:20.480 --> 02:18:23.620]   even if they don't admit it or recognize it,
[02:18:23.620 --> 02:18:26.660]   is they object, they reject objective reality.
[02:18:26.660 --> 02:18:29.860]   - In which sense?
[02:18:29.860 --> 02:18:31.340]   So like, okay. - I'll get to it, right?
[02:18:31.340 --> 02:18:32.940]   So there's a whole...
[02:18:32.940 --> 02:18:36.300]   So the whole realm of law
[02:18:36.300 --> 02:18:40.700]   is a scientific realm
[02:18:40.700 --> 02:18:44.380]   to define, for example,
[02:18:44.380 --> 02:18:46.140]   the boundaries of private property.
[02:18:46.140 --> 02:18:49.560]   It's not an issue of competition.
[02:18:49.560 --> 02:18:54.020]   It's not an issue of I have one system
[02:18:54.020 --> 02:18:55.900]   and you have another system.
[02:18:55.900 --> 02:18:57.980]   It's an issue of objective reality.
[02:18:57.980 --> 02:19:00.900]   And now it's more difficult than science in a sense
[02:19:00.900 --> 02:19:03.660]   because it's more difficult to prove
[02:19:03.660 --> 02:19:05.580]   that my conception of property is correct
[02:19:05.580 --> 02:19:07.740]   and you're correct.
[02:19:07.740 --> 02:19:10.260]   But there is a correct one.
[02:19:10.260 --> 02:19:12.340]   In reality, there's a correct vision.
[02:19:12.340 --> 02:19:13.340]   It's more abstract.
[02:19:13.340 --> 02:19:19.580]   But look, somebody has to decide what property is.
[02:19:19.580 --> 02:19:22.700]   So I have defined, my property is defined
[02:19:22.700 --> 02:19:25.540]   by certain boundaries.
[02:19:25.540 --> 02:19:27.700]   And I have a police force
[02:19:27.700 --> 02:19:30.580]   and I have a judiciary system that backs my vision.
[02:19:30.580 --> 02:19:34.500]   And you have a claim against my property.
[02:19:34.500 --> 02:19:35.660]   You have a claim against my property.
[02:19:35.660 --> 02:19:38.780]   And you have a police force and a judicial system
[02:19:38.780 --> 02:19:39.900]   that backs your claim.
[02:19:39.900 --> 02:19:42.300]   Who's right?
[02:19:42.300 --> 02:19:45.740]   - So our definitions of property are different.
[02:19:45.740 --> 02:19:46.940]   - Yes, our definitions of property
[02:19:46.940 --> 02:19:49.540]   or our claim on the property is different.
[02:19:49.540 --> 02:19:52.020]   - So why can't we just agree
[02:19:52.020 --> 02:19:54.740]   on the definition of property and--
[02:19:54.740 --> 02:19:55.940]   - But why should we agree, right?
[02:19:55.940 --> 02:19:58.940]   Your judicial system is one definition of property.
[02:19:58.940 --> 02:20:00.540]   My judicial system is not.
[02:20:00.540 --> 02:20:03.140]   You think that there's no such thing
[02:20:03.140 --> 02:20:05.420]   as intellectual property rights.
[02:20:05.420 --> 02:20:07.580]   And your whole system believes that.
[02:20:07.580 --> 02:20:09.780]   And my whole system believes there is such thing.
[02:20:09.780 --> 02:20:12.380]   So you are duplicating my books
[02:20:12.380 --> 02:20:14.460]   and handing them out to all your friends
[02:20:14.460 --> 02:20:16.140]   and not paying me a royalty.
[02:20:16.140 --> 02:20:19.820]   And I think that's wrong.
[02:20:19.820 --> 02:20:21.900]   And my judicial system and my police force
[02:20:21.900 --> 02:20:24.180]   think that's wrong.
[02:20:24.180 --> 02:20:28.100]   And we're both living in the same geographic area, right?
[02:20:28.100 --> 02:20:31.780]   So we have overlapping jurisdictions.
[02:20:31.780 --> 02:20:34.820]   Now, the anarchists would say, well, we'll negotiate.
[02:20:34.820 --> 02:20:35.980]   Why should we negotiate?
[02:20:35.980 --> 02:20:37.660]   My system is actually right.
[02:20:37.660 --> 02:20:39.500]   There is such a thing as intellectual property rights.
[02:20:39.500 --> 02:20:40.780]   There's no negotiation here.
[02:20:40.780 --> 02:20:41.780]   You're wrong.
[02:20:41.780 --> 02:20:44.500]   And you should either pay a fine or go to jail.
[02:20:44.500 --> 02:20:46.540]   - Yeah, but why can't, 'cause it's a community,
[02:20:46.540 --> 02:20:48.700]   it's multiple, there's multiple parties
[02:20:48.700 --> 02:20:50.620]   and it's like a majority vote.
[02:20:50.620 --> 02:20:52.820]   They'll hire different forces that says,
[02:20:52.820 --> 02:20:54.900]   yeah, your honor is onto something here
[02:20:54.900 --> 02:20:57.260]   with the definition of property and we'll go with that.
[02:20:57.260 --> 02:21:01.460]   - So anarchist pro-democracy in the majority rule sense?
[02:21:01.460 --> 02:21:02.300]   - Well, I think so.
[02:21:02.300 --> 02:21:07.300]   I think anarchy promotes like emergent democracy, right?
[02:21:07.300 --> 02:21:09.140]   - No, it doesn't.
[02:21:09.140 --> 02:21:11.380]   I'll tell you what it promotes.
[02:21:11.380 --> 02:21:16.140]   It promotes emergent strife and civil war and violence,
[02:21:16.140 --> 02:21:18.420]   constant uninterrupted violence.
[02:21:18.420 --> 02:21:21.060]   'Cause the only way to settle the dispute between us,
[02:21:21.060 --> 02:21:23.460]   since we both think that we are right
[02:21:23.460 --> 02:21:27.100]   and we have guns behind us to protect that.
[02:21:27.100 --> 02:21:30.340]   And we have a legal system, we have a whole theory of ideas
[02:21:30.340 --> 02:21:33.900]   is you're stealing my stuff.
[02:21:33.900 --> 02:21:35.740]   How do I get it back?
[02:21:35.740 --> 02:21:37.620]   I invade you, right?
[02:21:37.620 --> 02:21:42.060]   I take over, you know, and who's gonna win that battle?
[02:21:42.060 --> 02:21:43.220]   The smartest guy?
[02:21:43.220 --> 02:21:44.580]   No, the guy with the biggest guns.
[02:21:44.580 --> 02:21:46.540]   - See, but the anarchists would say
[02:21:46.540 --> 02:21:48.460]   that they're using implied,
[02:21:48.460 --> 02:21:51.860]   like the state uses implied force.
[02:21:51.860 --> 02:21:53.180]   They're already doing violence.
[02:21:53.180 --> 02:21:56.220]   - Because they take the state as it is today
[02:21:56.220 --> 02:21:58.940]   and they refuse to engage in the conversation
[02:21:58.940 --> 02:22:01.380]   about what a state should and could look like
[02:22:01.380 --> 02:22:04.260]   and how we can create mechanisms
[02:22:04.260 --> 02:22:07.220]   to protect us from the state using those.
[02:22:07.220 --> 02:22:10.540]   But look, my view of anarchy is very simple.
[02:22:10.540 --> 02:22:12.620]   It's a ridiculous position.
[02:22:12.620 --> 02:22:13.740]   It's infantile.
[02:22:13.740 --> 02:22:15.140]   I mean, I really mean this, right?
[02:22:15.140 --> 02:22:16.420]   And I'm sorry to Michael,
[02:22:16.660 --> 02:22:19.300]   and all the other very, very smart,
[02:22:19.300 --> 02:22:20.700]   very, very smart anarchists,
[02:22:20.700 --> 02:22:22.260]   'cause anarchists is never,
[02:22:22.260 --> 02:22:25.620]   you won't find a dumb anarchist.
[02:22:25.620 --> 02:22:26.460]   - Right.
[02:22:26.460 --> 02:22:28.740]   - Because dumb people know it wouldn't work.
[02:22:28.740 --> 02:22:31.620]   You have to have, it's absolutely true.
[02:22:31.620 --> 02:22:35.740]   You have to have a certain IQ to be an anarchist.
[02:22:35.740 --> 02:22:37.340]   - That's true, they're all really intelligent.
[02:22:37.340 --> 02:22:39.660]   - All intelligent, and the reason is
[02:22:39.660 --> 02:22:44.660]   that you have to create such a mythology in your head.
[02:22:45.780 --> 02:22:49.420]   You have to create so many rationalizations.
[02:22:49.420 --> 02:22:52.620]   Any Joe in the street knows it doesn't work
[02:22:52.620 --> 02:22:55.540]   because they can understand what happens
[02:22:55.540 --> 02:22:59.220]   when two people who are armed are in the street
[02:22:59.220 --> 02:23:00.220]   and have a dispute,
[02:23:00.220 --> 02:23:03.700]   and there's no mechanism to resolve that dispute.
[02:23:03.700 --> 02:23:04.620]   - Yeah.
[02:23:04.620 --> 02:23:07.860]   - That's objective, and this is where it gets subjective.
[02:23:07.860 --> 02:23:09.420]   That's objective.
[02:23:09.420 --> 02:23:11.300]   The whole point of government is
[02:23:11.300 --> 02:23:14.820]   that it is the objective authority
[02:23:14.820 --> 02:23:18.860]   for determining the truth in one regard,
[02:23:18.860 --> 02:23:20.340]   in regard to force,
[02:23:20.340 --> 02:23:25.620]   because the only alternative to determining it
[02:23:25.620 --> 02:23:27.940]   when it comes to force is through force.
[02:23:27.940 --> 02:23:31.140]   The only way to resolve disputes is through force,
[02:23:31.140 --> 02:23:33.180]   or through this negotiation, which is unjust,
[02:23:33.180 --> 02:23:34.780]   because if one party's right and one party's wrong,
[02:23:34.780 --> 02:23:35.620]   why negotiate?
[02:23:35.620 --> 02:23:38.620]   And this is the point.
[02:23:38.620 --> 02:23:41.780]   I'm not against competition of governance.
[02:23:41.780 --> 02:23:43.740]   I'm all for competition of governance.
[02:23:43.740 --> 02:23:44.660]   We do that all the time.
[02:23:44.660 --> 02:23:46.260]   It's called countries.
[02:23:46.260 --> 02:23:49.140]   The United States has a certain governance structure.
[02:23:49.140 --> 02:23:50.820]   The Soviet Union had a governance structure.
[02:23:50.820 --> 02:23:52.820]   Mexico has a governance structure,
[02:23:52.820 --> 02:23:54.180]   and they're competing.
[02:23:54.180 --> 02:23:56.580]   And we can observe the competition.
[02:23:56.580 --> 02:23:58.660]   In my world, you could move freely
[02:23:58.660 --> 02:24:00.300]   from one governance to another.
[02:24:00.300 --> 02:24:01.580]   If you didn't like your governance,
[02:24:01.580 --> 02:24:03.860]   you would move to a better governance system,
[02:24:03.860 --> 02:24:07.300]   but they have to have autonomy within a geographic area.
[02:24:07.300 --> 02:24:10.780]   Otherwise, what you get is complete and utter civil war.
[02:24:10.780 --> 02:24:13.140]   The law needs to be objective,
[02:24:13.140 --> 02:24:15.380]   and there needs to be one law over a piece of ground.
[02:24:15.380 --> 02:24:16.860]   And if you disagree with that law,
[02:24:16.860 --> 02:24:18.580]   you can move somewhere else where they may.
[02:24:18.580 --> 02:24:21.540]   This is why federalism is such a beautiful system.
[02:24:21.540 --> 02:24:23.980]   Even within the United States, we have states.
[02:24:23.980 --> 02:24:25.300]   And on certain issues,
[02:24:25.300 --> 02:24:27.100]   we're allowed to disagree between states,
[02:24:27.100 --> 02:24:27.980]   like the death penalty.
[02:24:27.980 --> 02:24:30.020]   Some states do, some states don't.
[02:24:30.020 --> 02:24:30.940]   Fine.
[02:24:30.940 --> 02:24:33.780]   And now I can move from one state if I don't like it.
[02:24:33.780 --> 02:24:36.100]   But there's certain issues you cannot have disagreement.
[02:24:36.100 --> 02:24:37.140]   Slavery, for example.
[02:24:37.140 --> 02:24:39.100]   This is why we had a civil war.
[02:24:39.100 --> 02:24:42.660]   But let me, one other argument against anarchy.
[02:24:43.620 --> 02:24:47.980]   Markets exist where force has been eliminated.
[02:24:47.980 --> 02:24:50.020]   - Sorry, can you say that again?
[02:24:50.020 --> 02:24:54.380]   Markets exist where the rule of force has been eliminated.
[02:24:54.380 --> 02:24:57.060]   - The rule of force?
[02:24:57.060 --> 02:24:57.900]   - Yes.
[02:24:57.900 --> 02:24:58.740]   - Can you elaborate that?
[02:24:58.740 --> 02:25:02.700]   - So a market will exist if we know
[02:25:02.700 --> 02:25:05.700]   that you can't pull a gun on me and just take my stuff.
[02:25:05.700 --> 02:25:08.140]   I am willing to engage in transaction with you
[02:25:08.140 --> 02:25:10.900]   if we have an implicit understanding
[02:25:10.900 --> 02:25:13.220]   we're not gonna use force against each other.
[02:25:13.220 --> 02:25:15.620]   - So force has something special to it.
[02:25:15.620 --> 02:25:16.460]   - Yes.
[02:25:16.460 --> 02:25:18.820]   - It's a special, it overrides,
[02:25:18.820 --> 02:25:21.820]   'cause we're still agreeing we can manipulate each other.
[02:25:21.820 --> 02:25:22.860]   - Yes.
[02:25:22.860 --> 02:25:23.700]   But force we can't.
[02:25:23.700 --> 02:25:27.140]   - Force kinda, so there's something fundamental
[02:25:27.140 --> 02:25:28.340]   about violence.
[02:25:28.340 --> 02:25:30.660]   - Force is a fundamental force.
[02:25:30.660 --> 02:25:32.500]   It's the anti-reason.
[02:25:32.500 --> 02:25:34.460]   It's the anti-life.
[02:25:34.460 --> 02:25:37.660]   It's the anti-force against another person.
[02:25:38.660 --> 02:25:41.620]   And what it does is shuts down the mind.
[02:25:41.620 --> 02:25:43.020]   - Right.
[02:25:43.020 --> 02:25:48.020]   - So in order to have a market, you have to extract force.
[02:25:48.020 --> 02:25:50.100]   - That's fascinating.
[02:25:50.100 --> 02:25:51.500]   - How can you have a market in force?
[02:25:51.500 --> 02:25:56.500]   - There's an Instagram channel called Nature's Metal
[02:25:56.500 --> 02:26:00.940]   where it has all these videos of animals
[02:26:00.940 --> 02:26:03.180]   basically having a market of force.
[02:26:03.180 --> 02:26:04.020]   - Yes.
[02:26:04.020 --> 02:26:06.060]   - But that shuts down the ability to reason.
[02:26:06.060 --> 02:26:08.020]   And animals don't need to because they can't.
[02:26:08.020 --> 02:26:11.020]   - Exactly, so the innovation that is human beings
[02:26:11.020 --> 02:26:12.500]   is our capacity to reason.
[02:26:12.500 --> 02:26:16.060]   And therefore, the relegation of force to the animals.
[02:26:16.060 --> 02:26:17.500]   We don't do force.
[02:26:17.500 --> 02:26:20.260]   Civilization is where we don't have force.
[02:26:20.260 --> 02:26:25.260]   And so what you have is you cannot have a market in that,
[02:26:25.260 --> 02:26:29.020]   which a market requires the elimination of it.
[02:26:29.020 --> 02:26:32.300]   And I don't debate formally these guys,
[02:26:32.300 --> 02:26:34.300]   but I interact with them all the time, right?
[02:26:34.300 --> 02:26:37.180]   And you get these absurd arguments where,
[02:26:37.180 --> 02:26:40.060]   David Friedman will say, that's Milton Friedman's son,
[02:26:40.060 --> 02:26:42.860]   he will say something like, well, in Somalia,
[02:26:42.860 --> 02:26:44.060]   in the Northern part of Somalia,
[02:26:44.060 --> 02:26:45.460]   where they have no government,
[02:26:45.460 --> 02:26:46.660]   you have all these wonderful,
[02:26:46.660 --> 02:26:51.300]   you have these tribunals of these tribes
[02:26:51.300 --> 02:26:52.980]   and they resolve disputes.
[02:26:52.980 --> 02:26:57.180]   Yeah, barbarically, they use Sharia law.
[02:26:57.180 --> 02:26:58.820]   They have no respect for individual rights,
[02:26:58.820 --> 02:27:00.380]   no respect for property.
[02:27:00.380 --> 02:27:02.580]   And the only reason they have any authority
[02:27:02.580 --> 02:27:04.980]   is because they have guns and they have power
[02:27:04.980 --> 02:27:08.660]   and they have force and they do it barbarically.
[02:27:08.660 --> 02:27:13.660]   There's nothing civilizing about the courts of Somalian
[02:27:13.660 --> 02:27:18.220]   and they write about pirates and because they view force,
[02:27:18.220 --> 02:27:20.420]   they don't view force as something unique
[02:27:20.420 --> 02:27:23.260]   that must be extracted from human life.
[02:27:23.260 --> 02:27:26.220]   And that's why anarchy has to devolve into violence
[02:27:26.220 --> 02:27:29.220]   because it treats force as just, what's the big deal?
[02:27:29.220 --> 02:27:32.460]   We're negotiating over guns.
[02:27:32.460 --> 02:27:34.660]   So we covered a lot of high level philosophy,
[02:27:34.660 --> 02:27:39.660]   but I'd like to touch on the troubles,
[02:27:39.660 --> 02:27:41.500]   the chaos of the day.
[02:27:41.500 --> 02:27:43.860]   A couple of things,
[02:27:43.860 --> 02:27:48.860]   and I really would trying to find a hopeful path way out.
[02:27:48.860 --> 02:27:55.100]   So one is the current coronavirus pandemic,
[02:27:55.100 --> 02:28:00.100]   or in particular, not the virus, but our handling of it.
[02:28:00.540 --> 02:28:04.860]   Is there something philosophically, politically
[02:28:04.860 --> 02:28:08.180]   that you would like to see, that you would like to recommend,
[02:28:08.180 --> 02:28:11.100]   that you would like to maybe give a hopeful message
[02:28:11.100 --> 02:28:12.820]   if we take that kind of trajectory
[02:28:12.820 --> 02:28:14.300]   we might be able to get out?
[02:28:14.300 --> 02:28:18.260]   Because I'm kind of worried about the economic pain
[02:28:18.260 --> 02:28:22.100]   that people are feeling, that there's this quiet suffering.
[02:28:22.100 --> 02:28:23.620]   - I mean, I agree with you completely.
[02:28:23.620 --> 02:28:26.140]   There is a quiet suffering, it's horrible.
[02:28:26.140 --> 02:28:29.460]   I mean, I know people, I go to a lot of restaurants.
[02:28:29.460 --> 02:28:31.740]   One of the things we love to do is eat out.
[02:28:31.740 --> 02:28:33.860]   My wife doesn't like cooking anymore.
[02:28:33.860 --> 02:28:35.980]   We don't have kids in the house anymore,
[02:28:35.980 --> 02:28:36.820]   so she doesn't have to.
[02:28:36.820 --> 02:28:38.140]   So we go out a lot, we go to restaurants.
[02:28:38.140 --> 02:28:39.740]   And because we have our favorites,
[02:28:39.740 --> 02:28:40.580]   so we go to them a lot,
[02:28:40.580 --> 02:28:43.820]   we get to know the owners of the restaurant, the chef.
[02:28:43.820 --> 02:28:46.940]   And it's just heartbreaking.
[02:28:46.940 --> 02:28:51.100]   These people put their life, their blood, sweat, and tears,
[02:28:51.100 --> 02:28:54.020]   I mean, real blood, sweat, and tears into these projects.
[02:28:54.020 --> 02:28:56.980]   Restaurants are super difficult to manage.
[02:28:56.980 --> 02:28:58.580]   Most of them go bankrupt anyway.
[02:28:59.580 --> 02:29:01.780]   And the restaurants, we go to a good restaurant,
[02:29:01.780 --> 02:29:03.100]   so they've done a good job,
[02:29:03.100 --> 02:29:06.580]   and they offer unique value.
[02:29:06.580 --> 02:29:09.460]   And they shut them down.
[02:29:09.460 --> 02:29:12.940]   And many of them will never open.
[02:29:12.940 --> 02:29:16.180]   Something like, they estimate 50, 60% of restaurants
[02:29:16.180 --> 02:29:17.660]   in some places won't open.
[02:29:17.660 --> 02:29:19.580]   These are people's lives, these are people's capital,
[02:29:19.580 --> 02:29:22.060]   these are people's effort, these are people's love.
[02:29:22.060 --> 02:29:24.300]   Talk about love, they love what they do,
[02:29:24.300 --> 02:29:26.500]   particularly if they're the chef as well.
[02:29:26.500 --> 02:29:28.340]   And it's gone, and it's disappeared.
[02:29:28.340 --> 02:29:29.540]   What are they gonna do with their lives now?
[02:29:29.540 --> 02:29:30.620]   They're gonna live off the government
[02:29:30.620 --> 02:29:32.540]   the way our politicians would like them?
[02:29:32.540 --> 02:29:34.180]   Bigger and bigger stimulus plans,
[02:29:34.180 --> 02:29:35.740]   so we can hand checks to people
[02:29:35.740 --> 02:29:37.340]   to get them used to living off of us,
[02:29:37.340 --> 02:29:40.500]   rather than, it's disgusting, and it's offensive,
[02:29:40.500 --> 02:29:42.780]   and it's unbelievably sad.
[02:29:42.780 --> 02:29:44.460]   And this is where it comes to this,
[02:29:44.460 --> 02:29:45.420]   I care about other people.
[02:29:45.420 --> 02:29:46.940]   I mean, this idea that objectivists don't care.
[02:29:46.940 --> 02:29:50.700]   I mean, I love these people who provide me with pleasure
[02:29:50.700 --> 02:29:54.780]   of eating wonderful food in a great environment.
[02:29:54.780 --> 02:29:56.700]   - And there's something inspiring about them too.
[02:29:56.700 --> 02:29:58.500]   Like when I see a great restaurant,
[02:29:58.500 --> 02:30:00.460]   I wanna do better with my own stuff.
[02:30:00.460 --> 02:30:02.980]   - Yeah, exactly, they're inspiring.
[02:30:02.980 --> 02:30:04.740]   Anybody who does it is excellent.
[02:30:04.740 --> 02:30:07.020]   I love sports, because it's the one realm
[02:30:07.020 --> 02:30:10.820]   in which you'd still value and celebrate excellence.
[02:30:10.820 --> 02:30:13.300]   But I try to celebrate excellence everything in my life.
[02:30:13.300 --> 02:30:16.660]   So I try to be nice to these people,
[02:30:16.660 --> 02:30:20.260]   and with COVID, we went more to restaurants,
[02:30:20.260 --> 02:30:21.100]   if you believe it or not.
[02:30:21.100 --> 02:30:23.220]   And we did more takeout stuff.
[02:30:23.220 --> 02:30:25.420]   We made an effort, particularly at the restaurants,
[02:30:25.420 --> 02:30:27.380]   we really loved to keep them going,
[02:30:27.380 --> 02:30:29.140]   to encourage them, to support them.
[02:30:29.140 --> 02:30:34.180]   The problem is, the problem is philosophy drives the world.
[02:30:34.180 --> 02:30:38.620]   The response to COVID has been worse than pathetic.
[02:30:38.620 --> 02:30:42.140]   And it's driven by philosophy.
[02:30:42.140 --> 02:30:46.260]   It's driven by disrespect to science,
[02:30:46.260 --> 02:30:48.980]   ignorance and disrespect of statistics,
[02:30:48.980 --> 02:30:53.060]   a disrespect of individual human decision-making.
[02:30:53.060 --> 02:30:55.220]   Government has to decide everything for us.
[02:30:55.220 --> 02:30:58.620]   And just throughout the process,
[02:30:58.620 --> 02:30:59.940]   and a disrespect of markets,
[02:30:59.940 --> 02:31:01.380]   because we didn't let markets work
[02:31:01.380 --> 02:31:03.820]   to facilitate what we needed
[02:31:03.820 --> 02:31:05.900]   in order to deal with this virus.
[02:31:05.900 --> 02:31:08.100]   If you look at the, it's interesting
[02:31:08.100 --> 02:31:09.420]   that the only place on the planet
[02:31:09.420 --> 02:31:12.660]   that's done well with this are parts of Asia, right?
[02:31:12.660 --> 02:31:15.180]   Taiwan did phenomenally with this.
[02:31:15.180 --> 02:31:18.900]   And the vice president of Taiwan is a epidemiologist.
[02:31:18.900 --> 02:31:20.820]   So he knew what he was doing.
[02:31:20.820 --> 02:31:22.860]   And they got it right from the beginning.
[02:31:22.860 --> 02:31:25.140]   South Korea did amazing.
[02:31:25.140 --> 02:31:26.780]   Even Hong Kong and Singapore.
[02:31:26.780 --> 02:31:30.420]   Hong Kong is just very few deaths.
[02:31:30.420 --> 02:31:35.140]   And the economy wasn't shut down in any of those places.
[02:31:35.140 --> 02:31:37.580]   There were no lockdowns in any of those places.
[02:31:37.580 --> 02:31:43.860]   The CDC had plans before this happened
[02:31:43.860 --> 02:31:45.780]   on how to deal with good plans.
[02:31:45.780 --> 02:31:48.260]   Indeed, if you ask people around the world
[02:31:48.260 --> 02:31:49.140]   before the pandemic,
[02:31:49.140 --> 02:31:52.100]   which country is best prepared for a pandemic,
[02:31:52.100 --> 02:31:53.740]   they would have said the United States.
[02:31:53.740 --> 02:31:55.420]   Because of the CDC's plans
[02:31:55.420 --> 02:31:57.540]   and all of our emergency reserves and all that,
[02:31:57.540 --> 02:31:58.380]   and the wealth.
[02:31:58.380 --> 02:32:02.700]   And yet all of that went out the window
[02:32:02.700 --> 02:32:05.260]   because people panicked.
[02:32:05.260 --> 02:32:08.660]   People didn't think, go back to reason.
[02:32:08.660 --> 02:32:10.220]   People were arrogant,
[02:32:10.220 --> 02:32:14.340]   refused to use the tools that they had
[02:32:14.340 --> 02:32:16.260]   at their disposal to deal with this.
[02:32:16.260 --> 02:32:17.460]   So you deal with pandemics.
[02:32:17.460 --> 02:32:19.060]   It's very simple how you deal with pandemics.
[02:32:19.060 --> 02:32:21.260]   And this is how South Korea and Taiwan,
[02:32:21.260 --> 02:32:24.380]   you deal with them by testing,
[02:32:24.380 --> 02:32:27.380]   tracing, and isolating.
[02:32:27.380 --> 02:32:28.580]   That's it.
[02:32:28.580 --> 02:32:29.940]   And you do it well.
[02:32:29.940 --> 02:32:30.980]   And you do it vigorously.
[02:32:30.980 --> 02:32:32.940]   And you do it on scale if you have to.
[02:32:32.940 --> 02:32:34.140]   And you scale up to do it.
[02:32:34.140 --> 02:32:35.780]   And we have the wealth to do that.
[02:32:35.780 --> 02:32:39.060]   - So one question I have,
[02:32:39.060 --> 02:32:41.220]   it's a difficult one.
[02:32:41.220 --> 02:32:43.860]   So I talk about love a lot.
[02:32:43.860 --> 02:32:45.620]   And you've just talked about Donald Trump.
[02:32:45.620 --> 02:32:47.900]   I guarantee you this particular segment
[02:32:47.900 --> 02:32:50.260]   will be full of division from the internet.
[02:32:51.260 --> 02:32:56.260]   But I believe that should be and can be fixed.
[02:32:56.260 --> 02:33:00.460]   What I'm referring to in particular is the division
[02:33:00.460 --> 02:33:03.340]   because we've talked about the value of reason.
[02:33:03.340 --> 02:33:06.100]   And what I've noticed on the internet
[02:33:06.100 --> 02:33:10.220]   is the division shuts down reason.
[02:33:10.220 --> 02:33:12.500]   So when people hear you say Trump,
[02:33:12.500 --> 02:33:14.620]   actually the first sentence you said about Trump,
[02:33:14.620 --> 02:33:17.260]   they'll hear Trump and their ears will perk up.
[02:33:17.260 --> 02:33:19.700]   And they'll immediately start in that first sentence,
[02:33:19.700 --> 02:33:22.740]   they'll say, is he a Trump supporter or a Trump--
[02:33:22.740 --> 02:33:24.540]   - They're not interested in anything else after that.
[02:33:24.540 --> 02:33:26.460]   - And then after that, that's it.
[02:33:26.460 --> 02:33:29.380]   And what, how do, so my question is,
[02:33:29.380 --> 02:33:34.340]   you as one of the beacons of intellectualism,
[02:33:34.340 --> 02:33:37.540]   maybe quite honest, I mean, it sounds silly to say,
[02:33:37.540 --> 02:33:40.660]   but you are a beacon of reason.
[02:33:40.660 --> 02:33:43.580]   How do we bring people together
[02:33:43.580 --> 02:33:46.060]   long enough to where we can reason?
[02:33:48.340 --> 02:33:51.020]   - I mean, there's no easy way out of this
[02:33:51.020 --> 02:33:54.540]   because the fact that people have become tribal
[02:33:54.540 --> 02:33:56.380]   and they have, very tribal.
[02:33:56.380 --> 02:34:02.580]   And the tribe, in the tribe reason doesn't matter.
[02:34:02.580 --> 02:34:04.620]   It's all about emotion.
[02:34:04.620 --> 02:34:06.380]   It's all about belonging or not belonging.
[02:34:06.380 --> 02:34:07.980]   And you don't wanna stand out.
[02:34:07.980 --> 02:34:10.140]   You don't wanna have a different opinion.
[02:34:10.140 --> 02:34:11.220]   You wanna belong.
[02:34:11.220 --> 02:34:13.420]   And it's all about belonging.
[02:34:13.420 --> 02:34:18.340]   It took us decades to get back to tribalism
[02:34:18.340 --> 02:34:20.580]   where we were hundreds of years ago.
[02:34:20.580 --> 02:34:23.140]   It took millennium to get out of tribalism.
[02:34:23.140 --> 02:34:24.740]   It took the enlightenment to get us
[02:34:24.740 --> 02:34:26.780]   to the point of individualism where we think for,
[02:34:26.780 --> 02:34:28.380]   and reason, respect for reason.
[02:34:28.380 --> 02:34:30.180]   Before that, we were all tribal.
[02:34:30.180 --> 02:34:31.980]   So it took the enlightenment to get us out of it.
[02:34:31.980 --> 02:34:34.460]   We've been in the enlightenment for about 250 years
[02:34:34.460 --> 02:34:38.060]   influenced by the enlightenment and it's fading.
[02:34:38.060 --> 02:34:39.900]   The impact is fading.
[02:34:39.900 --> 02:34:42.260]   So what would we need to get out of it?
[02:34:42.260 --> 02:34:43.380]   We need self-esteem.
[02:34:43.380 --> 02:34:48.980]   People join a tribe because they don't trust their own mind.
[02:34:48.980 --> 02:34:52.780]   People join a tribe because they're afraid
[02:34:52.780 --> 02:34:54.140]   to stand on their own two feet.
[02:34:54.140 --> 02:34:55.900]   They're afraid to think for themselves.
[02:34:55.900 --> 02:34:57.140]   They're afraid to be different.
[02:34:57.140 --> 02:34:58.340]   They're afraid to be unique.
[02:34:58.340 --> 02:35:00.820]   They're afraid to be an individual.
[02:35:00.820 --> 02:35:02.420]   People need self-esteem.
[02:35:02.420 --> 02:35:07.420]   To gain self-esteem, they have to have respect
[02:35:07.420 --> 02:35:08.780]   for rationality.
[02:35:08.780 --> 02:35:10.780]   They have to think and they have to achieve
[02:35:10.780 --> 02:35:12.980]   and they have to recognize that achievement.
[02:35:12.980 --> 02:35:19.740]   To do that, they have to have respect for thinking.
[02:35:19.740 --> 02:35:22.140]   They have to have respect for reason.
[02:35:22.140 --> 02:35:24.820]   And we have to, and think about the schools.
[02:35:24.820 --> 02:35:27.620]   We have to have schools that teach people to think,
[02:35:27.620 --> 02:35:29.900]   teach people to value their mind.
[02:35:29.900 --> 02:35:32.700]   We have schools that teach people to feel
[02:35:32.700 --> 02:35:33.820]   and value their feelings.
[02:35:33.820 --> 02:35:36.260]   We have groups of six-year-olds sitting around a circle
[02:35:36.260 --> 02:35:37.620]   discussing politics.
[02:35:37.620 --> 02:35:38.460]   What?
[02:35:38.460 --> 02:35:39.660]   They don't know anything.
[02:35:39.660 --> 02:35:40.980]   They're ignorant.
[02:35:40.980 --> 02:35:43.260]   See, you don't know anything when you're ignorant.
[02:35:43.260 --> 02:35:46.420]   Yes, you can feel, but your feelings are useless
[02:35:46.420 --> 02:35:49.140]   as decision-making tools.
[02:35:49.140 --> 02:35:51.340]   But we emphasize emotion.
[02:35:51.340 --> 02:35:53.700]   It's all about socialization and emotion.
[02:35:53.700 --> 02:35:57.500]   This is why they talk about this generation of snowflakes.
[02:35:57.500 --> 02:36:00.500]   They can't hear anything that they're opposed to
[02:36:00.500 --> 02:36:03.420]   because they've not learned how to use their mind,
[02:36:03.420 --> 02:36:04.300]   how to think.
[02:36:04.300 --> 02:36:09.020]   So it boils down to teaching people how to think,
[02:36:09.020 --> 02:36:13.100]   two things, how to think and how to care about themselves.
[02:36:13.100 --> 02:36:16.260]   So it's thinking of self-esteem and the connected,
[02:36:16.260 --> 02:36:18.620]   because when you think, you achieve,
[02:36:18.620 --> 02:36:20.860]   which gains you self-esteem.
[02:36:20.860 --> 02:36:23.860]   When you have self-esteem, it's easier to think for yourself.
[02:36:23.860 --> 02:36:28.060]   And I don't know how you do that quickly.
[02:36:28.060 --> 02:36:31.380]   I mean, I think leadership matters.
[02:36:31.380 --> 02:36:33.860]   So, you know, part of what I try to do
[02:36:33.860 --> 02:36:36.940]   is try to encourage people to do those things,
[02:36:36.940 --> 02:36:38.980]   but I am a small voice.
[02:36:38.980 --> 02:36:40.420]   You asked me when early on,
[02:36:40.420 --> 02:36:42.820]   you said we should talk about why I'm not more famous.
[02:36:42.820 --> 02:36:43.980]   I'm not famous.
[02:36:43.980 --> 02:36:45.140]   My following is not big.
[02:36:45.140 --> 02:36:48.660]   It's very small in the scope of things.
[02:36:48.660 --> 02:36:51.500]   - Well, yours and objectivism, and that question,
[02:36:51.500 --> 02:36:53.580]   could you linger on it for a moment?
[02:36:53.580 --> 02:36:57.980]   Why isn't objectivism more famous?
[02:36:57.980 --> 02:37:00.380]   - I think because it's so challenging.
[02:37:00.380 --> 02:37:03.100]   It's not challenging to me, right?
[02:37:03.100 --> 02:37:05.140]   When I first encountered objectivism,
[02:37:05.140 --> 02:37:07.900]   it's like after the first shock
[02:37:07.900 --> 02:37:10.100]   and after the first kind of,
[02:37:10.100 --> 02:37:12.820]   none of this can be true, this is all BS,
[02:37:12.820 --> 02:37:17.740]   and fighting it, once I got it, it was easy.
[02:37:17.740 --> 02:37:19.140]   It required years of studying,
[02:37:19.140 --> 02:37:22.700]   but it was easy in the sense of, yes, this makes sense.
[02:37:22.700 --> 02:37:25.860]   But it's challenging because it upends everything.
[02:37:25.860 --> 02:37:28.820]   It really says what my mother taught me is wrong.
[02:37:28.820 --> 02:37:32.700]   And what my politicians say, left and right, is wrong.
[02:37:32.700 --> 02:37:33.540]   All of them.
[02:37:33.540 --> 02:37:35.420]   There's not a single politician
[02:37:35.420 --> 02:37:39.220]   on which I agree with on almost anything, right?
[02:37:39.220 --> 02:37:42.140]   Because on the fundamentals, we disagree.
[02:37:42.140 --> 02:37:45.300]   And what my teachers are telling me is wrong,
[02:37:45.300 --> 02:37:50.300]   and what Jesus said is wrong, and it's hard.
[02:37:50.300 --> 02:37:53.580]   - But the thing is, so you talk about politics
[02:37:53.580 --> 02:37:56.260]   and all that kind of stuff, but most people don't care.
[02:37:56.260 --> 02:37:58.740]   The more powerful thing about objectivism
[02:37:58.740 --> 02:38:02.180]   is the practical of my life,
[02:38:02.180 --> 02:38:04.860]   of how I revolutionized my life.
[02:38:04.860 --> 02:38:09.860]   And that feels to be like a very important and appealing,
[02:38:09.860 --> 02:38:12.180]   you know, get your shit together.
[02:38:12.180 --> 02:38:14.580]   - Yeah, but this is why Jordan Peterson
[02:38:14.580 --> 02:38:16.300]   is so much more successful than we are, right?
[02:38:16.300 --> 02:38:17.380]   - Why is that?
[02:38:17.380 --> 02:38:19.100]   Make your bed, or whatever.
[02:38:19.100 --> 02:38:19.940]   - What's that?
[02:38:19.940 --> 02:38:20.780]   - Make your bed, or whatever he says.
[02:38:20.780 --> 02:38:23.380]   - Yeah, because his personal responsibility is shallow.
[02:38:23.380 --> 02:38:25.700]   It's make your bed, stand up straight.
[02:38:25.700 --> 02:38:27.340]   It's what my mother told me when I was growing up.
[02:38:27.340 --> 02:38:29.660]   There's nothing new about Jordan Peterson.
[02:38:29.660 --> 02:38:33.940]   He says, embrace Christianity, Christianity's fine, right?
[02:38:33.940 --> 02:38:36.020]   Religion is okay.
[02:38:36.020 --> 02:38:38.060]   Just do these few things and you'll be fine.
[02:38:38.060 --> 02:38:42.380]   And by the way, he says, happiness, you know,
[02:38:42.380 --> 02:38:43.660]   you either have it or you don't.
[02:38:43.660 --> 02:38:44.700]   You know, it's random.
[02:38:44.700 --> 02:38:47.180]   You don't actually, you can't bring about your own happiness.
[02:38:47.180 --> 02:38:49.140]   So he's giving people an easy out.
[02:38:49.140 --> 02:38:50.220]   People want easy outs.
[02:38:50.220 --> 02:38:53.900]   People buy self-help books that give them five principles
[02:38:53.900 --> 02:38:57.460]   for living a, you know, shallow, I'm telling them,
[02:38:57.460 --> 02:39:02.460]   think, stand on your own two feet, be independent.
[02:39:02.640 --> 02:39:04.980]   Don't listen to your mother.
[02:39:04.980 --> 02:39:09.480]   Do your own thing, but thoughtfully, not based on emotions.
[02:39:09.480 --> 02:39:12.420]   - So you're responsible not just for a set
[02:39:12.420 --> 02:39:14.900]   of particular habits and so on.
[02:39:14.900 --> 02:39:17.260]   You're responsible for everything.
[02:39:17.260 --> 02:39:20.140]   - Yes, and you're responsible, here's the big one, right?
[02:39:20.140 --> 02:39:25.580]   You're responsible for shaping your own soul.
[02:39:25.580 --> 02:39:30.300]   Your consciousness, you get to decide
[02:39:30.300 --> 02:39:32.060]   what it's gonna be like.
[02:39:32.060 --> 02:39:34.460]   - And the only tool you have is your mind.
[02:39:34.460 --> 02:39:36.580]   - Your only tool is your mind.
[02:39:36.580 --> 02:39:38.220]   Well, your emotions play a tool
[02:39:38.220 --> 02:39:39.580]   when they're properly cultivated.
[02:39:39.580 --> 02:39:41.420]   They play a role in that.
[02:39:41.420 --> 02:39:45.340]   And the tools you have is thinking, experiencing, living,
[02:39:45.340 --> 02:39:47.580]   coming to the right conclusions, you know,
[02:39:47.580 --> 02:39:50.540]   listening to great music and watching good movies.
[02:39:50.540 --> 02:39:54.260]   And art is very important in shaping your own soul
[02:39:54.260 --> 02:39:56.220]   and helping you do this.
[02:39:56.220 --> 02:40:01.220]   It's got a crucial role in that, but it's work.
[02:40:01.720 --> 02:40:04.580]   And it's lonely work,
[02:40:04.580 --> 02:40:05.980]   because it's work you do with yourself.
[02:40:05.980 --> 02:40:08.060]   Now, if you find somebody who you love,
[02:40:08.060 --> 02:40:10.220]   who shares these values and you can do with them,
[02:40:10.220 --> 02:40:12.980]   that's great, but it's mostly lonely work.
[02:40:12.980 --> 02:40:16.660]   It's hard, it's challenging, it ends your world.
[02:40:16.660 --> 02:40:18.700]   The reward is unbelievable.
[02:40:18.700 --> 02:40:23.700]   But even at the, think about the enlightenment, right?
[02:40:23.700 --> 02:40:26.820]   So up until the enlightenment, where was truth?
[02:40:26.820 --> 02:40:27.980]   Truth came from a book.
[02:40:27.980 --> 02:40:30.740]   And there were a few people who understood the book.
[02:40:30.740 --> 02:40:33.460]   Most of us couldn't read and they conveyed it to us.
[02:40:33.460 --> 02:40:34.700]   And they just told us what to do.
[02:40:34.700 --> 02:40:36.140]   And in that sense, life's easy.
[02:40:36.140 --> 02:40:37.300]   It sucks.
[02:40:37.300 --> 02:40:41.020]   And we die young and we have nothing and we don't enjoy it,
[02:40:41.020 --> 02:40:42.540]   but it's easy.
[02:40:42.540 --> 02:40:45.260]   And the enlightenment comes around and says,
[02:40:45.260 --> 02:40:49.100]   "We've got this tool, it's called reason.
[02:40:49.100 --> 02:40:51.500]   "And it allows us to discover truth about the world.
[02:40:51.500 --> 02:40:52.860]   "It's not in a book.
[02:40:52.860 --> 02:40:54.780]   "It's actually your reason allows you
[02:40:54.780 --> 02:40:56.500]   "to discover stuff about the world."
[02:40:56.500 --> 02:41:00.140]   And I consider the first, really the first figure
[02:41:00.140 --> 02:41:02.460]   of the enlightenment is Newton, not Locke, right?
[02:41:02.460 --> 02:41:03.500]   It's a scientist.
[02:41:03.500 --> 02:41:07.940]   Because he teaches us the laws of mechanics,
[02:41:07.940 --> 02:41:10.060]   like how does stuff work?
[02:41:10.060 --> 02:41:13.160]   And people go, "Oh, wow, this is cool.
[02:41:13.160 --> 02:41:14.540]   "I can use my mind.
[02:41:14.540 --> 02:41:16.120]   "I can discover truth.
[02:41:16.120 --> 02:41:18.100]   "Isn't that amazing?"
[02:41:18.100 --> 02:41:19.900]   And everything opens up once you do that.
[02:41:19.900 --> 02:41:23.940]   Hey, if I can discover, if I understand the laws of motion,
[02:41:23.940 --> 02:41:25.620]   if I can understand truth in the world,
[02:41:25.620 --> 02:41:27.620]   how come I can't decide who I marry?
[02:41:27.620 --> 02:41:29.940]   I mean, everything was fixed in those days.
[02:41:29.940 --> 02:41:33.100]   How come I can't decide what profession I should be in?
[02:41:33.100 --> 02:41:35.180]   Right, everybody belonged to a guild.
[02:41:35.180 --> 02:41:38.500]   How come I can't decide who my political leader should be?
[02:41:38.500 --> 02:41:40.580]   That's, so it's all reason.
[02:41:40.580 --> 02:41:43.260]   It's all, once you understand the efficacy of your own mind
[02:41:43.260 --> 02:41:45.220]   to understand truth, to understand reality,
[02:41:45.220 --> 02:41:48.220]   discover truth, not understand truth, discover it,
[02:41:48.220 --> 02:41:49.300]   everything opens up.
[02:41:49.300 --> 02:41:51.300]   Now you can take responsibility for your own life
[02:41:51.300 --> 02:41:53.980]   'cause now you have the tool to do it.
[02:41:53.980 --> 02:41:57.240]   But we are living in an era where postmodernism tells us
[02:41:57.240 --> 02:41:59.140]   there is no truth, there is no reality,
[02:41:59.140 --> 02:42:00.860]   and our mind is useless anyway.
[02:42:00.860 --> 02:42:04.420]   Critical race theory tells us that you're determined
[02:42:04.420 --> 02:42:06.980]   by your race and your race shapes everything
[02:42:06.980 --> 02:42:08.620]   and your free will is meaningless
[02:42:08.620 --> 02:42:10.260]   and your reason doesn't matter
[02:42:10.260 --> 02:42:12.780]   'cause reason is just shaped by your genes
[02:42:12.780 --> 02:42:15.040]   and shaped by your color of your skin.
[02:42:15.040 --> 02:42:17.140]   It's the most racist theory of all.
[02:42:17.140 --> 02:42:21.140]   And you've got our friend at UC Irvine telling them,
[02:42:21.140 --> 02:42:24.260]   "Oh, your senses don't tell you anything about reality.
[02:42:24.260 --> 02:42:25.400]   "Anyway, reality is what it is.
[02:42:25.400 --> 02:42:28.160]   "So, you know, what's the purpose of reason?
[02:42:28.160 --> 02:42:29.980]   "It's to invent stuff, it's to make stuff up.
[02:42:29.980 --> 02:42:30.960]   "Then what use is that?
[02:42:30.960 --> 02:42:32.840]   "It's complete fantasy."
[02:42:32.840 --> 02:42:35.780]   You've basically got every philosophical,
[02:42:35.780 --> 02:42:37.620]   intellectual voice in the culture
[02:42:37.620 --> 02:42:42.020]   telling them their reason is impotent.
[02:42:42.020 --> 02:42:44.740]   There's like a Steven Pinker who tries,
[02:42:44.740 --> 02:42:47.140]   and I love Pinker and he's really good
[02:42:47.140 --> 02:42:48.180]   and I love his books,
[02:42:48.180 --> 02:42:53.420]   but he needs to be stronger about this.
[02:42:53.420 --> 02:42:55.180]   And there's a few people on kind of,
[02:42:55.180 --> 02:42:57.620]   there's a few people partially in the intellectual dark web
[02:42:57.620 --> 02:42:59.560]   in other ways who are big on reason,
[02:42:59.560 --> 02:43:02.600]   but not consistent enough and not full understanding
[02:43:02.600 --> 02:43:05.160]   of what it means or what it implies.
[02:43:05.160 --> 02:43:06.720]   And then there's little old me.
[02:43:06.720 --> 02:43:08.780]   (laughing)
[02:43:08.780 --> 02:43:10.680]   And it's me against the world in a sense
[02:43:10.680 --> 02:43:13.040]   because I'm not only willing to accept,
[02:43:13.040 --> 02:43:16.600]   to articulate the case for reason,
[02:43:16.600 --> 02:43:18.560]   but then what that implies.
[02:43:18.560 --> 02:43:20.600]   It implies freedom, it implies capitalism,
[02:43:20.600 --> 02:43:22.240]   it implies taking personal responsibility
[02:43:22.240 --> 02:43:23.240]   over your own life.
[02:43:23.240 --> 02:43:25.160]   And there are other intellectual dark web people
[02:43:25.160 --> 02:43:28.860]   get to reason and then, "Oh, politics, you can be whatever."
[02:43:28.860 --> 02:43:32.340]   No, you can't, you can't be a socialist and for reason.
[02:43:32.340 --> 02:43:35.080]   It doesn't actually, those are incompatible.
[02:43:35.080 --> 02:43:38.260]   And you can't be a determinist and for reason.
[02:43:38.260 --> 02:43:40.700]   Reason and determinism don't go together.
[02:43:40.700 --> 02:43:43.620]   The whole point of reason is that it's an achievement
[02:43:43.620 --> 02:43:45.620]   and it requires effort and it requires engagement
[02:43:45.620 --> 02:43:47.340]   and it requires choice.
[02:43:47.340 --> 02:43:49.700]   So it is, it does feel like a little old me
[02:43:49.700 --> 02:43:51.540]   because that's it.
[02:43:51.540 --> 02:43:53.520]   The allies I have are allies,
[02:43:53.520 --> 02:43:56.760]   I have allies among some libertarians over economics.
[02:43:56.760 --> 02:43:58.680]   I have some allies in the intellectual dark web
[02:43:58.680 --> 02:44:00.000]   maybe over reason,
[02:44:00.000 --> 02:44:02.800]   but none of them are allies in the full sense.
[02:44:02.800 --> 02:44:04.540]   My allies are the other objectivists,
[02:44:04.540 --> 02:44:06.400]   but we just, they're not a lot of us.
[02:44:06.400 --> 02:44:10.280]   - For people listening to this,
[02:44:10.280 --> 02:44:12.360]   for the few folks kind of listening to this
[02:44:12.360 --> 02:44:16.420]   and thinking about the trajectory of their own life,
[02:44:17.760 --> 02:44:22.760]   I guess the takeaway is reason is a difficult project,
[02:44:22.760 --> 02:44:27.300]   but a project that's worthy of taking on.
[02:44:27.300 --> 02:44:29.620]   - Yeah, and difficult is,
[02:44:29.620 --> 02:44:31.140]   I don't know if difficult is the right word
[02:44:31.140 --> 02:44:33.020]   'cause difficult sounds like it's,
[02:44:33.020 --> 02:44:35.220]   I have to push this boulder up a hill.
[02:44:35.220 --> 02:44:37.020]   It's not difficult in that sense.
[02:44:37.020 --> 02:44:39.020]   It's difficult in the sense that it requires energy
[02:44:39.020 --> 02:44:41.720]   and focus, it requires effort,
[02:44:41.720 --> 02:44:43.980]   but it's immediately rewarding.
[02:44:43.980 --> 02:44:48.980]   It's fun to do and it's rewards immediate, pretty quick.
[02:44:48.980 --> 02:44:53.960]   It takes a while to undo all the garbage that you have,
[02:44:53.960 --> 02:44:56.640]   but we all have that I had that took me years
[02:44:56.640 --> 02:44:58.600]   and years and years to get rid of certain concepts
[02:44:58.600 --> 02:45:01.960]   and certain emotions that I had that didn't make any sense,
[02:45:01.960 --> 02:45:04.960]   but it takes a long time to fully integrate that.
[02:45:04.960 --> 02:45:09.240]   So I don't want it to sound like it's a burden,
[02:45:09.240 --> 02:45:11.520]   like it's hard in that sense.
[02:45:11.520 --> 02:45:13.760]   It does require focus and energy.
[02:45:13.760 --> 02:45:16.760]   And I don't want to sound like a Dr. Spock.
[02:45:16.760 --> 02:45:18.640]   I don't want to say, and I don't think I do
[02:45:18.640 --> 02:45:20.360]   because I'm a pretty passionate guy,
[02:45:20.360 --> 02:45:22.060]   but I don't want it to appeal like,
[02:45:22.060 --> 02:45:24.400]   oh, just forget about emotions.
[02:45:24.400 --> 02:45:26.900]   Emotions are how you experience the world.
[02:45:26.900 --> 02:45:29.700]   You want to have strong emotions.
[02:45:29.700 --> 02:45:33.760]   You wanna live, you wanna experience life strongly
[02:45:33.760 --> 02:45:35.760]   and passionately.
[02:45:35.760 --> 02:45:39.580]   You just need to know that emotions are not cognition.
[02:45:39.580 --> 02:45:40.700]   It's another realm.
[02:45:40.700 --> 02:45:42.460]   It's like, don't mix the realms.
[02:45:42.460 --> 02:45:45.360]   Think about outcomes and then experience them.
[02:45:45.360 --> 02:45:47.320]   And sometimes your emotions won't coincide
[02:45:47.320 --> 02:45:49.920]   with what you think should be.
[02:45:49.920 --> 02:45:52.680]   And that means there's still more integration to be done.
[02:45:52.680 --> 02:45:55.960]   - Jan, as I told you offline,
[02:45:55.960 --> 02:45:58.200]   I've been a fan of yours for a long time.
[02:45:58.200 --> 02:46:01.720]   It's been, I was a little starstruck early on,
[02:46:01.720 --> 02:46:02.920]   getting a little more comfortable now.
[02:46:02.920 --> 02:46:04.120]   - I believe that's gone.
[02:46:04.120 --> 02:46:08.480]   - I highly recommend that people
[02:46:08.480 --> 02:46:12.320]   that haven't heard your work, listen to it.
[02:46:13.180 --> 02:46:14.180]   The Yaron Brook show.
[02:46:14.180 --> 02:46:18.820]   The times I've disagreed with something I've hear you say
[02:46:18.820 --> 02:46:21.980]   is usually a first step on a journey
[02:46:21.980 --> 02:46:24.420]   of learning a lot more about that thing,
[02:46:24.420 --> 02:46:25.780]   about that viewpoint.
[02:46:25.780 --> 02:46:27.300]   And that's been so fulfilling.
[02:46:27.300 --> 02:46:28.140]   It's been a gift.
[02:46:28.140 --> 02:46:32.140]   The passion, you talk about reason a lot,
[02:46:32.140 --> 02:46:35.420]   but the passion radiates in a way
[02:46:35.420 --> 02:46:38.180]   that's just contagious and awe-inspiring.
[02:46:38.180 --> 02:46:41.020]   So thank you for everything you've done for this world.
[02:46:41.020 --> 02:46:43.560]   It's truly an honor and a pleasure to talk to you.
[02:46:43.560 --> 02:46:44.400]   - Well, thank you.
[02:46:44.400 --> 02:46:48.560]   And it's, my award is that if I've had an impact on you
[02:46:48.560 --> 02:46:51.440]   and people like you, wow, I mean, that's amazing.
[02:46:51.440 --> 02:46:54.200]   When you wrote to me an email saying you being a fan,
[02:46:54.200 --> 02:46:56.840]   I was blown away 'cause I had no idea
[02:46:56.840 --> 02:46:58.440]   and completely unexpected.
[02:46:58.440 --> 02:47:02.360]   And I, every few months I discover,
[02:47:02.360 --> 02:47:03.920]   hey, I had an impact on this world
[02:47:03.920 --> 02:47:05.720]   and people that I would have never thought.
[02:47:05.720 --> 02:47:09.640]   And they, so the only way to change the world
[02:47:10.800 --> 02:47:12.700]   is to change your one mind at a time.
[02:47:12.700 --> 02:47:18.140]   And when you have an impact on a good mind
[02:47:18.140 --> 02:47:20.200]   and a mind that cares about the world
[02:47:20.200 --> 02:47:22.600]   and a mind that goes out and does something about it,
[02:47:22.600 --> 02:47:24.840]   then you get the exponential growth.
[02:47:24.840 --> 02:47:27.840]   So through you, I've impacted other people
[02:47:27.840 --> 02:47:29.140]   and that's how you get,
[02:47:29.140 --> 02:47:31.840]   that's how you ultimately change everything.
[02:47:31.840 --> 02:47:34.280]   And so I'm, in spite of everything,
[02:47:34.280 --> 02:47:37.080]   I'm optimistic in a sense that I think
[02:47:37.080 --> 02:47:39.800]   that the progress we've made today
[02:47:39.800 --> 02:47:41.880]   is so universally accepted,
[02:47:41.880 --> 02:47:44.360]   that scientific progress, the technological progress,
[02:47:44.360 --> 02:47:48.800]   it can't just vanish like it did under when Rome collapsed.
[02:47:48.800 --> 02:47:51.200]   And whether it's in the United States or somewhere,
[02:47:51.200 --> 02:47:52.720]   progress will continue.
[02:47:52.720 --> 02:47:57.800]   The human project for human progress will continue.
[02:47:57.800 --> 02:47:58.960]   And I think these ideas,
[02:47:58.960 --> 02:48:00.800]   the ideas of reason and individualism
[02:48:00.800 --> 02:48:02.520]   will always be at the heart of it.
[02:48:02.520 --> 02:48:05.040]   And what we are doing
[02:48:05.040 --> 02:48:07.040]   is continuing the project of the enlightenment.
[02:48:07.040 --> 02:48:12.040]   And it's the project that will save the human race
[02:48:12.040 --> 02:48:14.880]   and allow it to, for Elon Musk
[02:48:14.880 --> 02:48:19.040]   and for Jeff Bezos to reach the stars.
[02:48:19.040 --> 02:48:22.560]   - Thank you for masterfully ending on a hopeful note.
[02:48:22.560 --> 02:48:24.320]   Yaron, a pleasure and an honor.
[02:48:24.320 --> 02:48:25.700]   Thanks.
[02:48:25.700 --> 02:48:27.240]   Thanks for listening to this conversation
[02:48:27.240 --> 02:48:28.400]   with Yaron Brook.
[02:48:28.400 --> 02:48:30.480]   And thank you to our sponsors,
[02:48:30.480 --> 02:48:32.520]   Blinkist, an app I use for reading
[02:48:32.520 --> 02:48:34.080]   through summaries of books,
[02:48:34.080 --> 02:48:37.400]   ExpressVPN, the VPN I've used for many years
[02:48:37.400 --> 02:48:39.960]   to protect my privacy on the internet,
[02:48:39.960 --> 02:48:43.440]   and Cash App, the app I use to send money to friends.
[02:48:43.440 --> 02:48:45.900]   Please check out these sponsors in the description
[02:48:45.900 --> 02:48:49.400]   to get a discount and to support this podcast.
[02:48:49.400 --> 02:48:51.800]   If you enjoy this thing, subscribe on YouTube,
[02:48:51.800 --> 02:48:54.040]   review it with 5,000 Apple Podcasts,
[02:48:54.040 --> 02:48:56.760]   follow on Spotify, support on Patreon,
[02:48:56.760 --> 02:49:00.040]   or connect with me on Twitter @LexFriedman.
[02:49:00.040 --> 02:49:03.120]   And now let me leave you with some words from Ayn Rand.
[02:49:04.000 --> 02:49:06.480]   Do not let your fire go out,
[02:49:06.480 --> 02:49:11.160]   spark by irreplaceable spark in the hopeless swamps
[02:49:11.160 --> 02:49:15.960]   of the not quite, the not yet, and the not at all.
[02:49:15.960 --> 02:49:19.040]   Do not let the hero in your soul perish
[02:49:19.040 --> 02:49:22.280]   in lonely frustration for the life you deserved
[02:49:22.280 --> 02:49:24.860]   and have never been able to reach.
[02:49:24.860 --> 02:49:27.400]   The world you desire can be one.
[02:49:27.400 --> 02:49:28.720]   It exists.
[02:49:28.720 --> 02:49:30.040]   It is real.
[02:49:30.040 --> 02:49:31.640]   It is possible.
[02:49:31.640 --> 02:49:32.780]   It is yours.
[02:49:33.980 --> 02:49:37.560]   Thank you for listening and hope to see you next time.
[02:49:37.560 --> 02:49:40.140]   (upbeat music)
[02:49:40.140 --> 02:49:42.720]   (upbeat music)
[02:49:42.720 --> 02:49:52.720]   [BLANK_AUDIO]

