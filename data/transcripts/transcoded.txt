
[00:00:00.000 --> 00:00:02.580]   (upbeat music)
[00:00:02.580 --> 00:00:07.080]   - Ladies and gentlemen,
[00:00:07.080 --> 00:00:09.240]   it's the Latent Space Weekend edition.
[00:00:09.240 --> 00:00:10.400]   Woo-hoo!
[00:00:10.400 --> 00:00:12.020]   This weekend is a special one,
[00:00:12.020 --> 00:00:14.280]   as we are gathering many of our former guests
[00:00:14.280 --> 00:00:15.920]   and over 10,000 of you
[00:00:15.920 --> 00:00:18.440]   for our very first AI Engineer Summit,
[00:00:18.440 --> 00:00:21.400]   both in San Francisco and on YouTube.
[00:00:21.400 --> 00:00:23.120]   We're all very excited about the summit,
[00:00:23.120 --> 00:00:24.320]   and we were even interviewed
[00:00:24.320 --> 00:00:27.400]   on a few of our fellow AI podcasts about it.
[00:00:27.400 --> 00:00:29.560]   We figured we would cross-post those episodes
[00:00:29.560 --> 00:00:31.520]   over the weekend to help you prepare
[00:00:31.520 --> 00:00:33.840]   for the exciting lineup of speakers,
[00:00:33.840 --> 00:00:36.040]   even if you can't join us in person.
[00:00:36.040 --> 00:00:37.880]   First, we'll have an introductory episode
[00:00:37.880 --> 00:00:40.720]   recorded with Tejas Kumar of PodRocket,
[00:00:40.720 --> 00:00:43.240]   where we introduce the concept of an AI engineer
[00:00:43.240 --> 00:00:45.520]   to a generalist engineer audience,
[00:00:45.520 --> 00:00:47.920]   and go over SWIX's recent conference keynote
[00:00:47.920 --> 00:00:49.500]   on software 3.0.
[00:00:49.500 --> 00:00:51.680]   While you are listening,
[00:00:51.680 --> 00:00:52.840]   there are two things you can do
[00:00:52.840 --> 00:00:55.960]   to be part of the AI Engineer experience.
[00:00:55.960 --> 00:00:59.120]   One, join the AI Engineer Summit Slack.
[00:00:59.120 --> 00:01:01.720]   Two, take the State of AI Engineering Survey
[00:01:01.720 --> 00:01:04.080]   and help us get to 1,000 respondents.
[00:01:04.080 --> 00:01:05.440]   Both are linked in the show notes,
[00:01:05.440 --> 00:01:07.480]   and we would really love to have you.
[00:01:07.480 --> 00:01:10.200]   Now here's SWIX's conversation about software,
[00:01:10.200 --> 00:01:12.720]   3.0 and the AI Engineer Summit.
[00:01:12.720 --> 00:01:16.900]   - I'm really excited to get into your talk,
[00:01:16.900 --> 00:01:18.520]   especially 'cause we've already talked a little bit
[00:01:18.520 --> 00:01:20.660]   about AI and adjacent things.
[00:01:20.660 --> 00:01:21.520]   But before we get into it,
[00:01:21.520 --> 00:01:23.000]   let's zero in on scope a little bit,
[00:01:23.000 --> 00:01:24.040]   talk about your talk,
[00:01:24.040 --> 00:01:27.240]   Software 3.0 and the Emerging AI Developer Landscape.
[00:01:27.240 --> 00:01:31.240]   I've seen the term web 1.0, web 2.0, web 3.0,
[00:01:31.240 --> 00:01:32.840]   also like in outside of web dev,
[00:01:32.840 --> 00:01:36.500]   there's the industry 3.0 is a trending term.
[00:01:36.500 --> 00:01:39.020]   I'm curious, software 3.0, where does that come from?
[00:01:39.020 --> 00:01:42.000]   - It doesn't have any lineage whatsoever with web 3.0.
[00:01:42.000 --> 00:01:46.680]   So that's a very unfortunate comparison there, I think.
[00:01:46.680 --> 00:01:48.560]   But the origin actually comes from
[00:01:48.560 --> 00:01:52.740]   a very influential article created by Andrej Karpathy
[00:01:52.740 --> 00:01:55.380]   about six years ago called Software 2.0.
[00:01:55.380 --> 00:01:57.820]   And he was basically trying to articulate the difference
[00:01:57.820 --> 00:02:00.020]   between hand-coded software,
[00:02:00.020 --> 00:02:02.380]   where we write every single line of code ourselves
[00:02:02.380 --> 00:02:04.240]   with like if statements, loops,
[00:02:04.240 --> 00:02:07.580]   and whatever traditional coding paradigms,
[00:02:07.580 --> 00:02:09.300]   and then machine-learned code,
[00:02:09.300 --> 00:02:11.860]   where you write the layers
[00:02:11.860 --> 00:02:15.180]   of what the machine learning model should do,
[00:02:15.180 --> 00:02:16.580]   like the architecture of the model.
[00:02:16.580 --> 00:02:18.620]   And then you just run it through a lot of data
[00:02:18.620 --> 00:02:20.460]   in order to achieve weights.
[00:02:20.460 --> 00:02:21.460]   And the weights themselves
[00:02:21.460 --> 00:02:23.260]   are the encoding of the knowledge.
[00:02:23.260 --> 00:02:25.580]   So he was trying to articulate that difference
[00:02:25.580 --> 00:02:27.940]   that the possible space of problems
[00:02:27.940 --> 00:02:29.580]   you can tackle with Software 1.0
[00:02:29.580 --> 00:02:31.740]   is the problems that you can kind of code for
[00:02:31.740 --> 00:02:34.420]   deterministically, and the possible space of problems
[00:02:34.420 --> 00:02:36.420]   that you can address with Software 2.0
[00:02:36.420 --> 00:02:39.700]   is the stuff that you can address it by machine learning.
[00:02:39.700 --> 00:02:41.780]   For example, computer vision and voice recognition.
[00:02:41.780 --> 00:02:43.060]   It's that stuff that you'll never be able
[00:02:43.060 --> 00:02:44.700]   to hand-code by yourself.
[00:02:44.700 --> 00:02:47.100]   And I think there's the fundamental realization
[00:02:47.100 --> 00:02:48.380]   that a lot of people should have
[00:02:48.380 --> 00:02:51.860]   with regards to how they write Software 1.0 code,
[00:02:51.860 --> 00:02:52.980]   which is a lot of the times,
[00:02:52.980 --> 00:02:54.380]   what do you do as a programmer,
[00:02:54.380 --> 00:02:55.900]   as a software engineer, right?
[00:02:55.900 --> 00:02:57.020]   You write some functioning app,
[00:02:57.020 --> 00:02:59.140]   and then you send it out there.
[00:02:59.140 --> 00:03:01.500]   You look at your analytics and your metrics and all that,
[00:03:01.500 --> 00:03:04.100]   and then you adjust by adding in some features
[00:03:04.100 --> 00:03:06.660]   and adding in some if statements and all that from learning.
[00:03:06.660 --> 00:03:08.380]   And essentially what Software 2.0
[00:03:08.380 --> 00:03:10.660]   is accelerated learning from data,
[00:03:10.660 --> 00:03:11.820]   whereas in Software 1.0,
[00:03:11.820 --> 00:03:13.980]   we learn from data through humans in the loop
[00:03:13.980 --> 00:03:15.300]   and designers in the loop.
[00:03:15.300 --> 00:03:17.740]   So I think that's a really fundamental realization there
[00:03:17.740 --> 00:03:19.940]   that once you realize that
[00:03:19.940 --> 00:03:22.860]   sometimes you are just a very slow machine learning model
[00:03:22.860 --> 00:03:24.620]   and you're writing all these algorithms,
[00:03:24.620 --> 00:03:26.340]   but yourself, sometimes you can just kind of
[00:03:26.340 --> 00:03:27.300]   machine learn the algorithms
[00:03:27.300 --> 00:03:28.860]   rather than writing them yourselves.
[00:03:28.860 --> 00:03:32.020]   So how do you proceed from Software 2.0 to 3.0?
[00:03:32.020 --> 00:03:33.660]   It's the arrival of foundation models,
[00:03:33.660 --> 00:03:36.500]   and that's the change that has happened
[00:03:36.500 --> 00:03:38.580]   more or less in the last three years,
[00:03:38.580 --> 00:03:42.060]   enabled by the transformer architecture becoming a thing,
[00:03:42.060 --> 00:03:43.940]   which enables deep learning
[00:03:43.940 --> 00:03:46.020]   that's parallelizable at massive scale,
[00:03:46.020 --> 00:03:48.380]   and obviously a lot more money and GPUs
[00:03:48.380 --> 00:03:50.260]   and data thrown at this problem.
[00:03:50.260 --> 00:03:52.220]   So now foundation models mean
[00:03:52.220 --> 00:03:54.540]   that you do not have to collect a whole bunch of data
[00:03:54.540 --> 00:03:56.940]   to create models before you start
[00:03:56.940 --> 00:03:59.020]   delivering ML products into production.
[00:03:59.020 --> 00:04:00.460]   You can just grab one off the shelf,
[00:04:00.460 --> 00:04:01.980]   whether it's open source or closed source,
[00:04:01.980 --> 00:04:03.020]   it doesn't really matter.
[00:04:03.020 --> 00:04:04.180]   You take a foundation model
[00:04:04.180 --> 00:04:05.900]   and then you put that into production,
[00:04:05.900 --> 00:04:07.260]   and then you can start collecting data
[00:04:07.260 --> 00:04:08.420]   to fine tune them if you want to,
[00:04:08.420 --> 00:04:12.300]   but otherwise the time to MVP of an AI product
[00:04:12.300 --> 00:04:16.380]   has significantly reduced by orders of magnitude
[00:04:16.380 --> 00:04:18.060]   in the Software 3.0 paradigm.
[00:04:18.060 --> 00:04:19.580]   So hopefully that transition is clear.
[00:04:19.580 --> 00:04:21.420]   Software 1.0 is hand-coded code,
[00:04:21.420 --> 00:04:23.180]   Software 2.0 is machine-learned code
[00:04:23.180 --> 00:04:24.980]   on your data that you collect,
[00:04:24.980 --> 00:04:27.380]   and Software 3.0 is just off-the-shelf models
[00:04:27.380 --> 00:04:29.140]   where you don't even have to collect the data.
[00:04:29.140 --> 00:04:31.380]   - Wow, that was an amazing answer.
[00:04:31.380 --> 00:04:34.300]   You alluded quite a few times to model architecture,
[00:04:34.300 --> 00:04:35.980]   the architecture of a model, et cetera.
[00:04:35.980 --> 00:04:36.820]   Maybe for our listeners,
[00:04:36.820 --> 00:04:38.620]   you could have maybe a sentence or two
[00:04:38.620 --> 00:04:40.780]   about what model architecture even is
[00:04:40.780 --> 00:04:42.780]   and why grabbing one off the shelf
[00:04:42.780 --> 00:04:46.100]   is beneficial to this Software 3.0 paradigm.
[00:04:46.100 --> 00:04:47.180]   - There's a lot of ways
[00:04:47.180 --> 00:04:48.980]   in which we can take that question.
[00:04:48.980 --> 00:04:52.740]   I would say that a very typical model
[00:04:52.740 --> 00:04:55.660]   would be these days, transformers-based models,
[00:04:55.660 --> 00:04:58.220]   a decoder-only generative P-train model.
[00:04:58.220 --> 00:05:01.620]   A GPT itself is actually a type of architecture
[00:05:01.620 --> 00:05:04.820]   that you can reference the GPT-1 and 2 papers from OpenAI,
[00:05:04.820 --> 00:05:06.620]   and they actually publish open-source code.
[00:05:06.620 --> 00:05:08.980]   To do that, I would say the most definitive
[00:05:08.980 --> 00:05:11.220]   open-source reference implementation
[00:05:11.220 --> 00:05:14.620]   of that kind of architecture is currently from Meta,
[00:05:14.620 --> 00:05:17.020]   where they released the Lama 2 code,
[00:05:17.020 --> 00:05:18.500]   which is only a few hundred lines of code.
[00:05:18.500 --> 00:05:19.780]   It's actually very little code.
[00:05:19.780 --> 00:05:22.420]   And all the value of the code has now shifted
[00:05:22.420 --> 00:05:24.700]   from the code base to the data weights.
[00:05:24.700 --> 00:05:26.380]   And that's a very common paradigm
[00:05:26.380 --> 00:05:28.500]   coming from Software 1.0 to 3.0, right?
[00:05:28.500 --> 00:05:31.500]   Like, Meta can open-source the code base.
[00:05:31.500 --> 00:05:32.340]   It doesn't matter.
[00:05:32.340 --> 00:05:33.860]   It's 'cause there's only a few hundred lines of code,
[00:05:33.860 --> 00:05:36.980]   but they are not open-sourcing their dataset, right?
[00:05:36.980 --> 00:05:39.060]   Because that's actually now the much more valuable thing
[00:05:39.060 --> 00:05:40.540]   that they're not giving you.
[00:05:40.540 --> 00:05:42.460]   They do somewhat open-source the weights.
[00:05:42.460 --> 00:05:44.420]   It's not fully, properly open-source,
[00:05:44.420 --> 00:05:45.700]   but for most people,
[00:05:45.700 --> 00:05:47.740]   they can actually use it in their commercial pursuits.
[00:05:47.740 --> 00:05:49.380]   And that's what most people care about.
[00:05:49.380 --> 00:05:51.580]   So this contrasts, by the way,
[00:05:51.580 --> 00:05:53.260]   with some of the other architectures
[00:05:53.260 --> 00:05:54.740]   that we might have pursued in the past.
[00:05:54.740 --> 00:05:56.820]   So for example, LSTM networks,
[00:05:56.820 --> 00:05:59.100]   if you're in traditional NLP,
[00:05:59.100 --> 00:06:01.420]   or convolutional neural networks,
[00:06:01.420 --> 00:06:03.460]   if you're in image recognition.
[00:06:03.460 --> 00:06:06.220]   And there's a bunch of other architectures as well.
[00:06:06.220 --> 00:06:08.380]   The RNN is one of the oldest ones,
[00:06:08.380 --> 00:06:10.100]   and is actually making a little bit of a comeback
[00:06:10.100 --> 00:06:12.180]   as a potential challenger to the transformer.
[00:06:12.180 --> 00:06:14.860]   But all these are possible architectures
[00:06:14.860 --> 00:06:17.620]   where you spec out the model in something like PyTorch,
[00:06:17.620 --> 00:06:19.700]   you define the number of layers that you're doing,
[00:06:19.700 --> 00:06:20.540]   that you need,
[00:06:20.540 --> 00:06:22.460]   and then you run it through a training process,
[00:06:22.460 --> 00:06:23.900]   and then you start deploying it.
[00:06:23.900 --> 00:06:25.860]   And I'm cutting out a lot,
[00:06:25.860 --> 00:06:28.420]   but I do think that AI engineers don't really need
[00:06:28.420 --> 00:06:29.860]   to know the internals of these things.
[00:06:29.860 --> 00:06:32.020]   They need to know how that impacts the products
[00:06:32.020 --> 00:06:33.660]   that they can make, and that's about it.
[00:06:33.660 --> 00:06:35.620]   And so I think this is classic engineering,
[00:06:35.620 --> 00:06:37.380]   where you're not quite a researcher,
[00:06:37.380 --> 00:06:38.900]   you're not quite a scientist.
[00:06:38.900 --> 00:06:41.260]   AI and ML is at a point where it's crossing over
[00:06:41.260 --> 00:06:42.540]   into the engineering sphere,
[00:06:42.540 --> 00:06:44.460]   where a lot of the rest of us,
[00:06:44.460 --> 00:06:46.500]   without that training backgrounds,
[00:06:46.500 --> 00:06:48.340]   can actually get pretty far
[00:06:48.340 --> 00:06:50.220]   just by knowing how to use the end products,
[00:06:50.220 --> 00:06:52.780]   rather than to make the products ourselves.
[00:06:52.780 --> 00:06:55.420]   - Yeah, that's a conversation I'm really excited to have.
[00:06:55.420 --> 00:06:56.260]   Before we do,
[00:06:56.260 --> 00:06:58.060]   I have just a couple more questions based on what you said.
[00:06:58.060 --> 00:06:59.300]   And the questions come from
[00:06:59.300 --> 00:07:00.580]   wanting to really answer the questions
[00:07:00.580 --> 00:07:02.540]   that I know we're gonna get from the listeners.
[00:07:02.540 --> 00:07:04.220]   You mentioned foundational models.
[00:07:04.220 --> 00:07:06.180]   I've heard similar terminology
[00:07:06.180 --> 00:07:07.900]   in the space pre-trained models.
[00:07:07.900 --> 00:07:10.100]   Is that somewhere close to the same thing?
[00:07:10.100 --> 00:07:11.060]   Are they similar somehow?
[00:07:11.060 --> 00:07:13.620]   - Yeah, I would say they mostly have 100% overlap.
[00:07:13.620 --> 00:07:15.940]   So some pedantic people might want me to point out
[00:07:15.940 --> 00:07:18.940]   that the term is foundation models, not foundational.
[00:07:18.940 --> 00:07:20.700]   And then there's also another term that's emerging
[00:07:20.700 --> 00:07:22.060]   called the frontier models.
[00:07:22.060 --> 00:07:24.140]   And so the frontier models would be foundation models
[00:07:24.140 --> 00:07:25.180]   that are extremely cutting edge
[00:07:25.180 --> 00:07:26.580]   and the largest of them
[00:07:26.580 --> 00:07:28.620]   that most probably come under
[00:07:28.620 --> 00:07:31.580]   some kind of regulational scrutiny from Congress
[00:07:31.580 --> 00:07:32.900]   or some other government bodies,
[00:07:32.900 --> 00:07:33.740]   because they are so big
[00:07:33.740 --> 00:07:36.540]   that they are potentially civilization threatening.
[00:07:36.540 --> 00:07:39.060]   So example foundation models would be GPT-3 and 4,
[00:07:39.060 --> 00:07:42.620]   CLOD, but also Whisper, also Segment Anything.
[00:07:42.620 --> 00:07:44.060]   All these are foundation models
[00:07:44.060 --> 00:07:45.740]   where you can get them off the shelf
[00:07:45.740 --> 00:07:46.900]   without actually training anything
[00:07:46.900 --> 00:07:48.420]   and they zero-shot transfer
[00:07:48.420 --> 00:07:50.740]   to tasks that you actually want to put them
[00:07:50.740 --> 00:07:52.940]   into use on your apps.
[00:07:52.940 --> 00:07:54.540]   And that's what a foundation model is.
[00:07:54.540 --> 00:07:55.660]   Stable Diffusion, for example,
[00:07:55.660 --> 00:07:56.940]   is also another foundation model.
[00:07:56.940 --> 00:07:59.860]   Basically, they are big binary blobs of data,
[00:07:59.860 --> 00:08:02.980]   sometimes four gigabytes, sometimes 180 gigabytes,
[00:08:02.980 --> 00:08:05.260]   depending on how you quantize the models.
[00:08:05.260 --> 00:08:07.500]   But these models are just a result
[00:08:07.500 --> 00:08:09.220]   of millions and millions of dollars
[00:08:09.220 --> 00:08:10.980]   of training these models through GPUs,
[00:08:10.980 --> 00:08:13.100]   running data through them
[00:08:13.100 --> 00:08:15.140]   based on some predefined recipes,
[00:08:15.140 --> 00:08:16.660]   such that you get the end result
[00:08:16.660 --> 00:08:18.460]   of these blobs of binary data
[00:08:18.460 --> 00:08:21.020]   that you can actually run in inference mode
[00:08:21.020 --> 00:08:21.860]   through these models
[00:08:21.860 --> 00:08:24.020]   in order to make inferences and predictions.
[00:08:24.020 --> 00:08:25.500]   And when we say inferences and predictions,
[00:08:25.500 --> 00:08:27.020]   that's a very machine learning term.
[00:08:27.020 --> 00:08:29.340]   In terms of products, when we make AI products,
[00:08:29.340 --> 00:08:31.300]   it's really much more like generating texts
[00:08:31.300 --> 00:08:33.220]   or generating images, anything like that.
[00:08:33.220 --> 00:08:35.580]   And that's the fun linguistic challenge
[00:08:35.580 --> 00:08:38.860]   when you cross fields from the research field
[00:08:38.860 --> 00:08:39.740]   into the products field.
[00:08:39.740 --> 00:08:41.780]   Because at the end of the day, in the product domain,
[00:08:41.780 --> 00:08:43.300]   in the AI engineering domain,
[00:08:43.300 --> 00:08:45.460]   we just care about what we can do for our users, right?
[00:08:45.460 --> 00:08:48.420]   And once we can produce interesting things for our users
[00:08:48.420 --> 00:08:49.460]   that people want to pay for,
[00:08:49.460 --> 00:08:50.860]   then we get a lot interested,
[00:08:50.860 --> 00:08:52.500]   but we have to respect that
[00:08:52.500 --> 00:08:54.620]   there's a lot of prehistory of research terminology
[00:08:54.620 --> 00:08:55.660]   that is completely different
[00:08:55.660 --> 00:08:57.780]   because they think about things in a different way.
[00:08:57.780 --> 00:08:59.780]   - Yeah, I once heard, I think it's Ashi Krishnan,
[00:08:59.780 --> 00:09:02.060]   say this term stochastic gradient descent
[00:09:02.060 --> 00:09:04.940]   in the ML academic world just means try stuff randomly
[00:09:04.940 --> 00:09:06.980]   and have less errors over time.
[00:09:06.980 --> 00:09:08.460]   So. (laughs)
[00:09:08.460 --> 00:09:11.420]   - I would say my favorite spin on stochastic gradient descent
[00:09:11.420 --> 00:09:13.580]   is the graduate student descent,
[00:09:13.580 --> 00:09:15.380]   which is instead of trying stuff by machines,
[00:09:15.380 --> 00:09:16.460]   you just throw graduate students
[00:09:16.460 --> 00:09:17.780]   until you find something that works.
[00:09:17.780 --> 00:09:19.060]   (laughs)
[00:09:19.060 --> 00:09:21.580]   - Yeah, final question about what you just said.
[00:09:21.580 --> 00:09:23.860]   You mentioned nowadays with software 3.0,
[00:09:23.860 --> 00:09:27.180]   it's very easy to grab these foundation models
[00:09:27.180 --> 00:09:28.620]   and put them into production.
[00:09:28.620 --> 00:09:30.820]   What does putting a foundation model of production mean?
[00:09:30.820 --> 00:09:32.740]   How do you practically do that?
[00:09:32.740 --> 00:09:36.300]   - That's a whole topic of a conference.
[00:09:36.300 --> 00:09:40.700]   So I think there's a bit of a U-curve in the difficulty.
[00:09:40.700 --> 00:09:43.500]   If you're just wrapping the OpenAI API,
[00:09:43.500 --> 00:09:44.820]   then you just call it an API,
[00:09:44.820 --> 00:09:47.300]   just like you would call any other API in an app.
[00:09:47.300 --> 00:09:48.620]   There's not that much difference there,
[00:09:48.620 --> 00:09:50.340]   apart from maybe you have to be mindful
[00:09:50.340 --> 00:09:52.540]   of things like your context limits,
[00:09:52.540 --> 00:09:54.660]   your privacy considerations,
[00:09:54.660 --> 00:09:57.380]   especially when people are putting in sensitive information
[00:09:57.380 --> 00:09:58.300]   into your stuff.
[00:09:58.300 --> 00:09:59.980]   And then maybe like your rate limits.
[00:09:59.980 --> 00:10:02.460]   So if someone, there are a lot of bots out there
[00:10:02.460 --> 00:10:04.780]   that will scrape any exposed OpenAI endpoints
[00:10:04.780 --> 00:10:07.700]   because these are valuable things and expensive token calls.
[00:10:07.700 --> 00:10:10.020]   So if you leave your API endpoints guarded,
[00:10:10.020 --> 00:10:12.540]   or if you, God forbid, leave your tokens out there,
[00:10:12.540 --> 00:10:14.740]   they will be scraped and used and they'll run up your bill.
[00:10:14.740 --> 00:10:17.420]   And then there's the path towards the local llamas,
[00:10:17.420 --> 00:10:19.700]   or where you run your models locally.
[00:10:19.700 --> 00:10:22.420]   And that is "production" just for yourself, right?
[00:10:22.420 --> 00:10:24.620]   You're not serving an outside audience.
[00:10:24.620 --> 00:10:26.340]   So you're just serving for personal use
[00:10:26.340 --> 00:10:29.100]   and you probably want to run it on your local machine.
[00:10:29.100 --> 00:10:31.060]   And so that's a one level of difficulty up
[00:10:31.060 --> 00:10:32.740]   from just calling an API,
[00:10:32.740 --> 00:10:34.620]   because typically you would want to run things
[00:10:34.620 --> 00:10:37.860]   like llama.cpp or whisper.cpp locally.
[00:10:37.860 --> 00:10:40.660]   And there's a whole stack that needs to be done there.
[00:10:40.660 --> 00:10:41.780]   And then the hardest of all
[00:10:41.780 --> 00:10:44.740]   is actually serving your own custom models
[00:10:44.740 --> 00:10:47.420]   to a lot of users externally,
[00:10:47.420 --> 00:10:50.020]   as though you were a model infrastructure platform.
[00:10:50.020 --> 00:10:51.300]   And there are many of these out there.
[00:10:51.300 --> 00:10:53.340]   You can actually buy them off the shelf
[00:10:53.340 --> 00:10:54.500]   or you can set them up yourself.
[00:10:54.500 --> 00:10:57.580]   I would say you probably have to be infrastructure expert
[00:10:57.580 --> 00:11:00.340]   to be able to be running these by yourself.
[00:11:00.340 --> 00:11:03.020]   From what I can tell, it's not that hard.
[00:11:03.020 --> 00:11:04.420]   The mechanics in these things,
[00:11:04.420 --> 00:11:06.460]   you just have to understand basic principles
[00:11:06.460 --> 00:11:08.460]   like saturation, basic principles,
[00:11:08.460 --> 00:11:11.060]   like what the bandwidth is of individual parts
[00:11:11.060 --> 00:11:12.980]   of the model architecture that you've chosen
[00:11:12.980 --> 00:11:15.500]   to be able to serve things well.
[00:11:15.500 --> 00:11:17.780]   But I think ultimately,
[00:11:17.780 --> 00:11:20.780]   the secrets of high model flop utilization,
[00:11:20.780 --> 00:11:22.380]   basically when you buy a GPU,
[00:11:22.380 --> 00:11:24.300]   you have a certain amount of theoretical flops.
[00:11:24.300 --> 00:11:27.500]   Most people only operate at like 40 to 50%
[00:11:27.500 --> 00:11:28.500]   model flop utilization.
[00:11:28.500 --> 00:11:30.220]   So if you want to go down that path,
[00:11:30.220 --> 00:11:31.820]   you are basically going to have to become
[00:11:31.820 --> 00:11:34.180]   a GPU infrastructure expert,
[00:11:34.180 --> 00:11:35.820]   which I am not.
[00:11:35.820 --> 00:11:38.620]   In my mind, that is how the landscape flows, right?
[00:11:38.620 --> 00:11:40.380]   Like either you use something off the shelf
[00:11:40.380 --> 00:11:41.420]   or you build your own.
[00:11:41.420 --> 00:11:44.540]   - Can you quickly just define flop for our listeners?
[00:11:44.540 --> 00:11:45.780]   - Floating point operations.
[00:11:45.780 --> 00:11:48.580]   And a lot of this math really
[00:11:48.580 --> 00:11:51.540]   is just multiplying matrices again and again.
[00:11:51.540 --> 00:11:54.580]   And that's how we do everything from embedding tokens
[00:11:54.580 --> 00:11:56.860]   to predicting the next token
[00:11:56.860 --> 00:11:58.660]   that eventually ends up towards
[00:11:58.660 --> 00:12:00.300]   either building a diffusion model
[00:12:00.300 --> 00:12:02.860]   or predicting the next token in a language model.
[00:12:02.860 --> 00:12:03.980]   It's all math at the end of the day,
[00:12:03.980 --> 00:12:05.980]   which is actually pretty interesting and fun,
[00:12:05.980 --> 00:12:07.820]   but very intimidating.
[00:12:07.820 --> 00:12:10.060]   So ultimately, like every operation reduces
[00:12:10.060 --> 00:12:11.540]   to a certain amount of flops, right?
[00:12:11.540 --> 00:12:13.780]   Larger models require more flops to operate.
[00:12:13.780 --> 00:12:15.700]   So how many flops can you generate
[00:12:15.700 --> 00:12:17.980]   in order to serve those models quickly?
[00:12:17.980 --> 00:12:21.180]   That is the fundamental problem of infrastructure serving.
[00:12:21.180 --> 00:12:22.020]   But there's one concern,
[00:12:22.020 --> 00:12:23.220]   which I will point out for people,
[00:12:23.220 --> 00:12:24.740]   which is the ability to batch.
[00:12:24.740 --> 00:12:26.580]   And that is primarily the key trick
[00:12:26.580 --> 00:12:28.140]   to reducing costs per tenants,
[00:12:28.140 --> 00:12:29.740]   if you're having a multi-tenant situation.
[00:12:29.740 --> 00:12:31.980]   - So far, we've talked about like half your talk title.
[00:12:31.980 --> 00:12:33.700]   We've talked about software 3.0.
[00:12:33.700 --> 00:12:35.740]   I wanna spend the rest of our time talking about a topic
[00:12:35.740 --> 00:12:37.340]   that I personally am really interested in.
[00:12:37.340 --> 00:12:39.020]   We started this discussion earlier
[00:12:39.020 --> 00:12:41.060]   and I'm really excited to continue it.
[00:12:41.060 --> 00:12:43.540]   The emerging AI developer landscape.
[00:12:43.540 --> 00:12:45.340]   This is a topic that I absolutely love.
[00:12:45.340 --> 00:12:47.140]   And Swix, you'll be proud to know
[00:12:47.140 --> 00:12:49.900]   I've been officially wearing the badge of AI engineer
[00:12:49.900 --> 00:12:51.580]   since our discussion.
[00:12:51.580 --> 00:12:53.420]   But I wanna clarify this for everyone.
[00:12:53.420 --> 00:12:56.860]   So in your talk, you mentioned AI is shifting right.
[00:12:56.860 --> 00:12:58.620]   And you mentioned a new role.
[00:12:58.620 --> 00:13:01.140]   I'm curious if you could expand on that just a little bit.
[00:13:01.140 --> 00:13:02.260]   - Yeah.
[00:13:02.260 --> 00:13:06.620]   Basically, I think that the arrival of foundation models
[00:13:06.620 --> 00:13:09.540]   make it such that you actually don't need an ML team
[00:13:09.540 --> 00:13:12.340]   in-house to ship an AI product.
[00:13:12.340 --> 00:13:15.100]   And that is a very different situation than 10 years ago
[00:13:15.100 --> 00:13:17.300]   when you would very much need to do that in-house.
[00:13:17.300 --> 00:13:18.700]   So what does that mean?
[00:13:18.700 --> 00:13:21.220]   It means that there's a few orders of magnitude
[00:13:21.220 --> 00:13:23.500]   more people that will be trying to ship AI products
[00:13:23.500 --> 00:13:26.860]   that don't have the traditional ML and research backgrounds
[00:13:26.860 --> 00:13:29.500]   to fully understand all of it or to make all of it themselves.
[00:13:29.500 --> 00:13:31.420]   But when you give them a shapeable tool
[00:13:31.420 --> 00:13:32.620]   like a foundation model,
[00:13:32.620 --> 00:13:34.580]   they can actually go make lots of money
[00:13:34.580 --> 00:13:37.180]   and make a lot of people happy by building AI products.
[00:13:37.180 --> 00:13:39.420]   And which is exactly what we're seeing happen
[00:13:39.420 --> 00:13:41.220]   in the sort of indie hackersphere
[00:13:41.220 --> 00:13:43.500]   and increasingly in the B2B sphere.
[00:13:43.500 --> 00:13:46.060]   So I basically would call this
[00:13:46.060 --> 00:13:47.660]   self-socialization of software engineering.
[00:13:47.660 --> 00:13:49.820]   If you imagine a spectrum from left to right,
[00:13:49.820 --> 00:13:51.660]   the left would be the research scientists,
[00:13:51.660 --> 00:13:53.300]   the people who are innovating on the algorithms
[00:13:53.300 --> 00:13:56.380]   and the architectures like the ones that we talked about.
[00:13:56.380 --> 00:13:58.540]   And then on the further right of those
[00:13:58.540 --> 00:14:00.180]   are the machine learning engineers.
[00:14:00.180 --> 00:14:03.180]   Those people that are not research scientists
[00:14:03.180 --> 00:14:05.980]   aren't as good at calculus as the other folks,
[00:14:05.980 --> 00:14:08.140]   but they are good at model infrastructure
[00:14:08.140 --> 00:14:09.420]   and serving and data pipelines
[00:14:09.420 --> 00:14:11.740]   and all that fun data science ML stuff.
[00:14:11.740 --> 00:14:13.980]   At that point, there's like a permeable boundary,
[00:14:13.980 --> 00:14:15.740]   which I like draw a line between.
[00:14:15.740 --> 00:14:17.860]   And basically I draw a line at the API layer.
[00:14:17.860 --> 00:14:20.500]   Like when stuff gets thrown over the API,
[00:14:20.500 --> 00:14:22.860]   whether internally within a company or between companies
[00:14:22.860 --> 00:14:24.860]   as an API foundation model lab,
[00:14:24.860 --> 00:14:27.700]   then you can consume it on the software engineer side
[00:14:27.700 --> 00:14:30.100]   as an API and put that into products.
[00:14:30.100 --> 00:14:31.740]   And so on the right of the spectrum
[00:14:31.740 --> 00:14:32.620]   is the software engineers.
[00:14:32.620 --> 00:14:35.700]   I do think like the traditional full stack software engineer,
[00:14:35.700 --> 00:14:39.820]   the one that is typically front-end only or serverless
[00:14:39.820 --> 00:14:40.780]   or front-end and serverless,
[00:14:40.780 --> 00:14:42.460]   or whatever you call it, or full stack web dev,
[00:14:42.460 --> 00:14:43.300]   it doesn't really matter
[00:14:43.300 --> 00:14:45.780]   because there's millions of those out there
[00:14:45.780 --> 00:14:47.540]   and don't have any experience with AI.
[00:14:47.540 --> 00:14:51.060]   And the real argument is that this sort of skills gap
[00:14:51.060 --> 00:14:54.220]   between the ML engineer and the research scientist
[00:14:54.220 --> 00:14:56.820]   is crossing over into the software fields
[00:14:56.820 --> 00:14:58.980]   and there'll be a new class of software engineer
[00:14:58.980 --> 00:15:01.660]   called the AI engineer that will specialize in this stack
[00:15:01.660 --> 00:15:03.140]   because keeping up to date,
[00:15:03.140 --> 00:15:05.020]   knowing all the latest techniques,
[00:15:05.020 --> 00:15:06.980]   knowing how to put stuff into production
[00:15:06.980 --> 00:15:08.300]   and knowing how to advise companies
[00:15:08.300 --> 00:15:09.460]   on what is a bad idea to do
[00:15:09.460 --> 00:15:11.220]   because it's not ready yet or whatever,
[00:15:11.220 --> 00:15:13.340]   all of these are the domain of something
[00:15:13.340 --> 00:15:15.580]   that will probably be a specialist field,
[00:15:15.580 --> 00:15:17.780]   calling it the AI engineer.
[00:15:17.780 --> 00:15:19.580]   - Just so I understand, in the past,
[00:15:19.580 --> 00:15:20.780]   I think even today, frankly,
[00:15:20.780 --> 00:15:23.300]   there would be people who hear the term AI engineer
[00:15:23.300 --> 00:15:24.980]   and without further clarification,
[00:15:25.020 --> 00:15:27.140]   would maybe consider it something interchangeable
[00:15:27.140 --> 00:15:28.900]   with a machine learning ML engineer.
[00:15:28.900 --> 00:15:30.140]   But what I'm hearing is a distinction
[00:15:30.140 --> 00:15:34.500]   where the AI engineer is one who consumes foundation models
[00:15:34.500 --> 00:15:37.540]   that expose APIs and use those foundation models
[00:15:37.540 --> 00:15:40.260]   as primitives for building apps that encompass them
[00:15:40.260 --> 00:15:42.340]   and more logic to serve users.
[00:15:42.340 --> 00:15:44.140]   So it's different from the ML engineer
[00:15:44.140 --> 00:15:45.540]   in that it is not academic.
[00:15:45.540 --> 00:15:47.140]   You don't need a calculus background,
[00:15:47.140 --> 00:15:48.260]   but all you need to be able to do
[00:15:48.260 --> 00:15:51.780]   is actually be a software engineer as the crude version.
[00:15:51.780 --> 00:15:54.420]   And then the specialization is a software engineer
[00:15:54.420 --> 00:15:56.900]   who knows how to work with these foundation models
[00:15:56.900 --> 00:15:58.380]   exposed over APIs.
[00:15:58.380 --> 00:15:59.220]   Is that accurate?
[00:15:59.220 --> 00:16:00.060]   - Yeah, I think so.
[00:16:00.060 --> 00:16:01.820]   And what's fun about this is that
[00:16:01.820 --> 00:16:04.420]   I think that AI engineers will be low status for a while
[00:16:04.420 --> 00:16:05.900]   because a machine learning engineer
[00:16:05.900 --> 00:16:08.220]   is a well-established role with a lot of hierarchy
[00:16:08.220 --> 00:16:10.380]   and a lot of syllabus and curriculum,
[00:16:10.380 --> 00:16:12.300]   most of which is completely unnecessary
[00:16:12.300 --> 00:16:14.260]   when it comes to foundation models.
[00:16:14.260 --> 00:16:15.740]   (laughs)
[00:16:15.740 --> 00:16:18.940]   So it'll be a very fun, disruptive few years
[00:16:18.940 --> 00:16:22.780]   when we figure out what's the right pay
[00:16:22.780 --> 00:16:25.300]   or a career path of an AI engineer is
[00:16:25.300 --> 00:16:27.220]   as it starts to separate from ML engineer
[00:16:27.220 --> 00:16:29.580]   because they're enabled by foundation models.
[00:16:29.580 --> 00:16:31.780]   I'm pretty strongly convicted that this will happen
[00:16:31.780 --> 00:16:35.700]   just because this is not a prediction based on tech.
[00:16:35.700 --> 00:16:37.580]   This is a prediction based on economics,
[00:16:37.580 --> 00:16:40.380]   on pure demand and supply of relative numbers of people
[00:16:40.380 --> 00:16:41.780]   and skill sets available.
[00:16:41.780 --> 00:16:45.340]   - Wow, that's really an interesting perspective.
[00:16:45.340 --> 00:16:46.220]   I'm curious if you could speak more
[00:16:46.220 --> 00:16:47.500]   to the economics of this.
[00:16:47.500 --> 00:16:49.340]   I'm an engineer and the fact that you tell me
[00:16:49.340 --> 00:16:51.980]   I can query things over the network
[00:16:51.980 --> 00:16:53.780]   or query things in general and build apps
[00:16:53.780 --> 00:16:55.940]   and call myself an AI engineer, I'm really happy with.
[00:16:55.940 --> 00:16:57.140]   But could you speak a little bit more
[00:16:57.140 --> 00:16:58.180]   about the economics of it?
[00:16:58.180 --> 00:17:00.420]   Is it just that there's a ton of demand and-
[00:17:00.420 --> 00:17:02.420]   - Yeah, it's purely demand and supply, right?
[00:17:02.420 --> 00:17:03.980]   Like there's a ton of demands,
[00:17:03.980 --> 00:17:05.700]   not enough machine learning engineers
[00:17:05.700 --> 00:17:08.060]   and machine learning research scientists around
[00:17:08.060 --> 00:17:09.420]   to supply that demand.
[00:17:09.420 --> 00:17:12.540]   So an intermediate class will be created
[00:17:12.540 --> 00:17:14.700]   and it will probably come from the software engineer side
[00:17:14.700 --> 00:17:15.780]   going down the stack
[00:17:15.780 --> 00:17:18.900]   rather than the ML engineer side going up the stack
[00:17:18.900 --> 00:17:21.100]   just because there's a lot more of the software engineers.
[00:17:21.100 --> 00:17:24.380]   So that is guaranteed as one thing.
[00:17:24.380 --> 00:17:25.860]   I think socioeconomically,
[00:17:25.860 --> 00:17:29.380]   software engineers also wants a way to jump in on the hype,
[00:17:29.380 --> 00:17:31.940]   which is why a lot of people have issues
[00:17:31.940 --> 00:17:34.100]   with my usage of the term AI engineer.
[00:17:34.100 --> 00:17:35.780]   A lot of people propose alternatives
[00:17:35.780 --> 00:17:38.260]   like LLM engineer or cognitive engineer.
[00:17:38.260 --> 00:17:40.620]   The thing is that these things don't roll off the tongue
[00:17:40.620 --> 00:17:42.260]   as easily as AI engineer.
[00:17:42.260 --> 00:17:44.300]   People want to associate themselves with AI.
[00:17:44.300 --> 00:17:46.900]   And so I think the people who do a good job of it
[00:17:46.900 --> 00:17:49.020]   will be able to put AI into practice
[00:17:49.020 --> 00:17:51.020]   for any company that approaches them
[00:17:51.020 --> 00:17:52.740]   and there'll be very high demands.
[00:17:52.740 --> 00:17:54.540]   You know, I think that was a very core inspiration
[00:17:54.540 --> 00:17:55.580]   for why I did this,
[00:17:55.580 --> 00:17:57.700]   which is that I noticed that a lot of companies
[00:17:57.700 --> 00:18:00.620]   were trying to hire this profile software engineer
[00:18:00.620 --> 00:18:02.340]   and a lot of software engineers
[00:18:02.340 --> 00:18:04.260]   wanted to pick up more skills,
[00:18:04.260 --> 00:18:07.540]   but they didn't have any other ways to find each other.
[00:18:07.540 --> 00:18:09.980]   And so I think once you have the industry collect
[00:18:09.980 --> 00:18:11.860]   and coalesce around a single term
[00:18:11.860 --> 00:18:15.420]   that identifies a skillset and interest
[00:18:15.420 --> 00:18:18.220]   and maybe a career path eventually
[00:18:18.460 --> 00:18:21.340]   according to the kind of tools they're confident with,
[00:18:21.340 --> 00:18:23.900]   the papers that they might be familiar with,
[00:18:23.900 --> 00:18:25.460]   that becomes its own community
[00:18:25.460 --> 00:18:27.100]   and its own career and sub-industry.
[00:18:27.100 --> 00:18:29.220]   So I'm pretty interested in growing that.
[00:18:29.220 --> 00:18:30.900]   Obviously, I've already made my bets.
[00:18:30.900 --> 00:18:33.660]   I definitely will be honest and admit
[00:18:33.660 --> 00:18:35.300]   that this is super early, right?
[00:18:35.300 --> 00:18:36.940]   Like there are people walking around
[00:18:36.940 --> 00:18:38.180]   with the title of AI engineer,
[00:18:38.180 --> 00:18:41.180]   but it's definitely still in a smaller minority.
[00:18:41.180 --> 00:18:42.580]   But I do think that it will grow over time
[00:18:42.580 --> 00:18:45.260]   and it will probably exceed ML engineer by a lot.
[00:18:45.260 --> 00:18:47.220]   So this was backed up by Andrej Karpathy,
[00:18:47.220 --> 00:18:48.980]   who is one of the figureheads of AI.
[00:18:48.980 --> 00:18:50.980]   I think he was a co-founder of OpenAI actually,
[00:18:50.980 --> 00:18:53.660]   when he read my piece on the advice of the AI engineer.
[00:18:53.660 --> 00:18:54.780]   And he said, yeah, it's probably true
[00:18:54.780 --> 00:18:56.900]   that there'll be more AI engineers than ML engineers.
[00:18:56.900 --> 00:18:59.500]   And I think this is emerging as a category
[00:18:59.500 --> 00:19:02.020]   and we'll have to basically fill out the tech tree.
[00:19:02.020 --> 00:19:03.220]   Right now it's very undefined.
[00:19:03.220 --> 00:19:04.660]   It's just a bunch of people hacking on Twitter
[00:19:04.660 --> 00:19:06.500]   and Reddit and Hacker News.
[00:19:06.500 --> 00:19:09.020]   But over time, the courses will come in,
[00:19:09.020 --> 00:19:12.100]   the degrees will come in, the bootcamps will come in.
[00:19:12.100 --> 00:19:15.940]   And I'm very excited to see how that develops.
[00:19:15.940 --> 00:19:17.660]   - Just to be clear, since it's so young,
[00:19:17.660 --> 00:19:22.020]   there isn't currently a senior AI engineer title.
[00:19:22.020 --> 00:19:24.460]   - People can call themselves senior, whatever they want.
[00:19:24.460 --> 00:19:26.860]   Yeah, ultimately your definition of senior
[00:19:26.860 --> 00:19:28.220]   has been around for five years.
[00:19:28.220 --> 00:19:29.860]   The Transformers architecture
[00:19:29.860 --> 00:19:31.060]   has only been around for six years,
[00:19:31.060 --> 00:19:34.820]   so you'd be that senior on that front.
[00:19:34.820 --> 00:19:37.620]   But I will say it's still a lot of software engineering.
[00:19:37.620 --> 00:19:39.740]   Maybe 90% of it is still software engineering.
[00:19:39.740 --> 00:19:41.660]   And if you qualify for senior software engineer
[00:19:41.660 --> 00:19:43.900]   on that side, then you just need a bit more training
[00:19:43.900 --> 00:19:46.020]   on the AI side to match up.
[00:19:46.020 --> 00:19:47.340]   - Yeah, no, the reason I ask this
[00:19:47.340 --> 00:19:49.060]   is because I'm pretty sure someone's receiving
[00:19:49.060 --> 00:19:51.780]   a recruiter email asking for a senior AI engineer
[00:19:51.780 --> 00:19:54.220]   with 20 years of experience or something.
[00:19:54.220 --> 00:19:57.620]   Your diagram of this on the left-hand side
[00:19:57.620 --> 00:19:59.780]   is the academics, the machine learning engineers,
[00:19:59.780 --> 00:20:00.780]   and on the right-hand side
[00:20:00.780 --> 00:20:03.180]   is the front-end serverless type of people,
[00:20:03.180 --> 00:20:04.300]   I think is so awesome.
[00:20:04.300 --> 00:20:06.780]   And I think it can be generalized enough
[00:20:06.780 --> 00:20:10.020]   to where really you can use it to reason about
[00:20:10.020 --> 00:20:12.860]   a lot of the way the tech industry at large has developed.
[00:20:12.860 --> 00:20:13.700]   - What do I mean by that?
[00:20:13.700 --> 00:20:16.900]   For example, if we think about personal computing even,
[00:20:16.900 --> 00:20:18.940]   on the left-hand side, you had these mainframe folks
[00:20:18.940 --> 00:20:21.100]   that was super inaccessible to everyone else.
[00:20:21.100 --> 00:20:23.820]   And then on the far right, you have us today
[00:20:23.820 --> 00:20:25.900]   who use personal computers.
[00:20:25.900 --> 00:20:28.340]   But at one point in time, computers weren't personal,
[00:20:28.340 --> 00:20:30.260]   and they were largely in labs.
[00:20:30.260 --> 00:20:32.060]   And over time, that line has expanded.
[00:20:32.060 --> 00:20:34.300]   And today we see it commoditized for everybody,
[00:20:34.300 --> 00:20:36.180]   mass market commoditization.
[00:20:36.180 --> 00:20:38.780]   AI is experiencing something similar,
[00:20:38.780 --> 00:20:40.500]   where AI to this point is personal.
[00:20:40.500 --> 00:20:42.500]   I literally use chat GPT every day.
[00:20:42.500 --> 00:20:43.780]   And it wasn't before.
[00:20:43.780 --> 00:20:45.620]   I could never run that type of model locally,
[00:20:45.620 --> 00:20:47.180]   or maybe I could, and I just didn't know how.
[00:20:47.180 --> 00:20:49.420]   Is that a fair way of reasoning about things?
[00:20:49.420 --> 00:20:52.020]   And if so, would it be appropriate
[00:20:52.020 --> 00:20:53.340]   to consider other things today?
[00:20:53.340 --> 00:20:56.620]   For maybe people wanting to come up with startup ideas
[00:20:56.620 --> 00:20:58.820]   of things that are currently gatekept behind,
[00:20:58.820 --> 00:21:00.860]   I don't know, academia, or money,
[00:21:00.860 --> 00:21:02.500]   or access to certain machinery,
[00:21:02.500 --> 00:21:05.780]   that over time might make it into the mass market,
[00:21:05.780 --> 00:21:09.020]   ergo broader consumer style people.
[00:21:09.020 --> 00:21:11.580]   - I think that's never really been a hurdle.
[00:21:11.580 --> 00:21:14.580]   If you were smart and motivated enough,
[00:21:14.580 --> 00:21:16.900]   you would have figured it out at some point,
[00:21:16.900 --> 00:21:18.100]   but now it's just getting,
[00:21:18.100 --> 00:21:20.540]   the bar is just constantly getting easier and easier.
[00:21:20.540 --> 00:21:21.660]   At the end of the day,
[00:21:21.660 --> 00:21:24.660]   I would hesitate to offer startup advice
[00:21:24.660 --> 00:21:27.300]   just 'cause I'm not a VC or anything like that.
[00:21:27.300 --> 00:21:29.980]   I would say like probably what is still successful,
[00:21:29.980 --> 00:21:31.860]   important for startups is to build things
[00:21:31.860 --> 00:21:33.660]   that people want, (laughs)
[00:21:33.660 --> 00:21:36.180]   that, and to know your customer better than anyone else,
[00:21:36.180 --> 00:21:37.580]   and serve them and make them happier,
[00:21:37.580 --> 00:21:38.780]   better than anyone else,
[00:21:38.780 --> 00:21:40.060]   and hopefully pick a growing market
[00:21:40.060 --> 00:21:41.500]   that is in demand for that.
[00:21:41.500 --> 00:21:44.820]   I do think that there are very good opportunities
[00:21:44.820 --> 00:21:48.500]   in effectively creating a poorer version
[00:21:48.500 --> 00:21:50.580]   of what a professional would do.
[00:21:50.580 --> 00:21:53.540]   And that's effectively what some of these things offer.
[00:21:53.540 --> 00:21:54.380]   Right?
[00:21:54.380 --> 00:21:58.140]   Like, hey, you can hire an SEO copywriting experts
[00:21:58.140 --> 00:22:03.060]   to work on your website copy for like $3,000 an hour,
[00:22:03.060 --> 00:22:07.420]   or you can pay ChatGPT $20 a month and do an 80% good job.
[00:22:07.420 --> 00:22:09.020]   And that's what automation is gonna do.
[00:22:09.020 --> 00:22:11.860]   You're really going to take away like the lower tier
[00:22:11.860 --> 00:22:14.140]   of all of these specialist roles
[00:22:14.140 --> 00:22:16.860]   because now we have a generative AI to do it.
[00:22:16.860 --> 00:22:18.980]   And I think, and this is gonna make sense
[00:22:18.980 --> 00:22:21.780]   'cause obviously that's gonna take away some people's jobs,
[00:22:21.780 --> 00:22:24.220]   but it's gonna free them up towards doing higher value
[00:22:24.220 --> 00:22:26.380]   at jobs that machines cannot do yet.
[00:22:26.380 --> 00:22:28.340]   - Yeah, if I was in such a situation,
[00:22:28.340 --> 00:22:31.540]   I'd probably try to use that time to learn AI engineering
[00:22:31.540 --> 00:22:32.460]   and get ahead of it.
[00:22:32.460 --> 00:22:34.620]   And that may be a prompt for some people listening.
[00:22:34.620 --> 00:22:37.620]   Okay, so the AI engineer is a new position
[00:22:37.620 --> 00:22:39.620]   that is effectively encompassed
[00:22:39.620 --> 00:22:42.420]   by folks consuming foundation models
[00:22:42.420 --> 00:22:44.140]   and using them to solve problems.
[00:22:44.140 --> 00:22:45.380]   You mentioned the stack,
[00:22:45.380 --> 00:22:47.740]   the modern data stack of the AI engineer.
[00:22:47.740 --> 00:22:48.940]   What is the stack?
[00:22:48.940 --> 00:22:49.980]   Is it outdated yet?
[00:22:49.980 --> 00:22:51.860]   Does it change as fast as JavaScript?
[00:22:51.860 --> 00:22:53.300]   Is Tailwind good?
[00:22:53.300 --> 00:22:55.260]   - It's actually changing slower than JavaScript.
[00:22:55.260 --> 00:22:58.020]   So for a while I was saying that JavaScript framework
[00:22:58.020 --> 00:23:01.020]   was over and then now we have like Svelte and Solid
[00:23:01.020 --> 00:23:04.060]   and Inferno, I don't know what the new thing is.
[00:23:04.060 --> 00:23:06.100]   HTMX is the new thing.
[00:23:06.100 --> 00:23:08.660]   Anyway, so I would say it hasn't been that churny.
[00:23:08.660 --> 00:23:09.580]   I can go through the stack.
[00:23:09.580 --> 00:23:11.780]   So the thing that I announced at the talk
[00:23:11.780 --> 00:23:13.780]   and we're doing a survey on actually
[00:23:13.780 --> 00:23:15.900]   is the software 3.0 stack,
[00:23:15.900 --> 00:23:17.460]   which I obviously it's an idea I brought over
[00:23:17.460 --> 00:23:19.180]   from the modern data stack, which you referenced.
[00:23:19.180 --> 00:23:21.860]   Modern data stack is this sort of nice composition
[00:23:21.860 --> 00:23:26.260]   of how a data engineer should view their tools of the trade.
[00:23:26.260 --> 00:23:28.700]   And I think it's a nice map of like what you should learn
[00:23:28.700 --> 00:23:31.260]   and be familiar with, or at least consider if you need it
[00:23:31.260 --> 00:23:33.180]   within your company for your own needs.
[00:23:33.180 --> 00:23:35.700]   So the software 3.0 stack, instead of data warehouse,
[00:23:35.700 --> 00:23:38.420]   I basically have the system of reasoning is what I call it,
[00:23:38.420 --> 00:23:41.900]   instead of like a system of knowledge or system of record.
[00:23:41.900 --> 00:23:43.500]   The system of reasoning is like the source
[00:23:43.500 --> 00:23:45.420]   of your foundation model, right?
[00:23:45.420 --> 00:23:46.780]   Whether it's a foundation model lab,
[00:23:46.780 --> 00:23:49.060]   like OpenAI or Anthropic, where it's closed source,
[00:23:49.060 --> 00:23:50.380]   but it's the best in class
[00:23:50.380 --> 00:23:52.660]   and they provide it to you through an API,
[00:23:52.660 --> 00:23:54.860]   or it's open source and you have to take care
[00:23:54.860 --> 00:23:57.420]   of a lot of the model hosting issues yourself.
[00:23:57.420 --> 00:23:59.660]   And that's typically provided through HuggingFace,
[00:23:59.660 --> 00:24:03.020]   Replicate, Base10, Modal.com and Lambda Labs.
[00:24:03.020 --> 00:24:05.540]   And so that would be like the most valuable ones now, right?
[00:24:05.540 --> 00:24:07.900]   OpenAI has a valuation of $40 billion.
[00:24:07.900 --> 00:24:11.860]   Anthropic now probably has a valuation of $10 to $15 billion.
[00:24:11.860 --> 00:24:13.860]   HuggingFace has a valuation of $4 billion
[00:24:13.860 --> 00:24:15.260]   and all the others are much smaller.
[00:24:15.260 --> 00:24:17.140]   Those are by far the biggest chunk
[00:24:17.140 --> 00:24:18.980]   of the value captured so far.
[00:24:18.980 --> 00:24:21.300]   And then we can go on to the RAG stack,
[00:24:21.300 --> 00:24:23.420]   the Retrieval Augmented Generation stack,
[00:24:23.420 --> 00:24:27.220]   because that is the stack that basically personalizes
[00:24:27.220 --> 00:24:30.620]   and orchestrates the AI models.
[00:24:30.620 --> 00:24:31.940]   So what does that really mean?
[00:24:31.940 --> 00:24:33.820]   Retrieval Augmented Generation really means
[00:24:33.820 --> 00:24:36.540]   that in every natural language model,
[00:24:36.540 --> 00:24:38.140]   let's just say like a GPT-4,
[00:24:38.140 --> 00:24:39.420]   there's a certain amount of context
[00:24:39.420 --> 00:24:43.540]   that lets you put in some extra information or examples
[00:24:43.540 --> 00:24:45.940]   such that you can actually personalize your answer
[00:24:45.940 --> 00:24:48.860]   towards something that you specifically want.
[00:24:48.860 --> 00:24:51.620]   So GPT-4 is trained on a lot
[00:24:51.620 --> 00:24:54.300]   of web general knowledge facts out there,
[00:24:54.300 --> 00:24:56.380]   but it's not going to know specific things
[00:24:56.380 --> 00:24:58.180]   about your company, it's not gonna know specific things
[00:24:58.180 --> 00:24:59.700]   about your products or person.
[00:24:59.700 --> 00:25:02.380]   So how are you going to pull in information
[00:25:02.380 --> 00:25:05.100]   and paste it in there and generate all that stuff?
[00:25:05.100 --> 00:25:07.340]   That is the subject of the Retrieval Augmented Generation
[00:25:07.340 --> 00:25:09.460]   stack or the RAG stack, as I call it.
[00:25:09.460 --> 00:25:12.780]   So in that bucket are the VectorDB companies.
[00:25:12.780 --> 00:25:17.020]   So most notably Pinecone, which is valued at $750 million.
[00:25:17.020 --> 00:25:18.700]   And then there's a long tail of others,
[00:25:18.700 --> 00:25:20.260]   Milvus, Weaviate, Chroma.
[00:25:20.260 --> 00:25:21.940]   All in all, people really like to invest
[00:25:21.940 --> 00:25:22.780]   in database companies.
[00:25:22.780 --> 00:25:25.780]   These companies have raised $235 million this year,
[00:25:25.780 --> 00:25:26.700]   which is a lot of money.
[00:25:26.700 --> 00:25:28.500]   That's more money than MongoDB ever raised
[00:25:28.500 --> 00:25:30.940]   its entire lifetime leading up to IPO.
[00:25:30.940 --> 00:25:32.940]   So people are just investing very far ahead
[00:25:32.940 --> 00:25:34.780]   on the database side of things.
[00:25:34.780 --> 00:25:36.860]   And then the piping, the orchestration
[00:25:36.860 --> 00:25:38.820]   and application frameworks, the two leaders here
[00:25:38.820 --> 00:25:40.340]   are Lanchain and Lamaindex.
[00:25:40.340 --> 00:25:41.620]   Lanchain has raised $35 million
[00:25:41.620 --> 00:25:43.620]   and Lamaindex has raised $9 million.
[00:25:43.620 --> 00:25:45.980]   And both of them are effectively,
[00:25:45.980 --> 00:25:50.100]   will connect your LLM adapter, whatever LLM you have,
[00:25:50.100 --> 00:25:52.380]   whether it's the closed-source ones or the open-source ones,
[00:25:52.380 --> 00:25:54.460]   will connect it to your data source,
[00:25:54.460 --> 00:25:56.500]   whether it's your Notion, your Slack, your Gmail,
[00:25:56.500 --> 00:25:58.540]   your Google Drive, doesn't matter,
[00:25:58.540 --> 00:26:00.740]   and embed it inside of a vector database
[00:26:00.740 --> 00:26:03.300]   like a Pineco, Chroma, VVM, or VS.
[00:26:03.300 --> 00:26:05.260]   And then we'll insert them into your context
[00:26:05.260 --> 00:26:06.460]   whenever you need to generate them,
[00:26:06.460 --> 00:26:08.980]   and that will serve as your personalization stack,
[00:26:08.980 --> 00:26:10.140]   and that's your RAG stack.
[00:26:10.140 --> 00:26:11.340]   There are other companies
[00:26:11.340 --> 00:26:13.620]   that are focused on eliminating that process
[00:26:13.620 --> 00:26:16.740]   because it's a janky process that nobody really loves,
[00:26:16.740 --> 00:26:19.020]   but it is by far the best in class right now.
[00:26:19.020 --> 00:26:21.220]   So people RAG right into the model itself
[00:26:21.220 --> 00:26:23.700]   instead of stitching together all these tools.
[00:26:23.700 --> 00:26:26.540]   There's a company called Contextual AI that pursues that.
[00:26:26.540 --> 00:26:28.340]   The founder is the author of the RAG paper
[00:26:28.340 --> 00:26:29.740]   that founded this whole field.
[00:26:29.740 --> 00:26:32.300]   And then there's other open questions as to,
[00:26:32.300 --> 00:26:35.260]   can you fine-tune new knowledge into existing models?
[00:26:35.260 --> 00:26:37.740]   And that is currently completely unknown.
[00:26:37.740 --> 00:26:40.420]   So finally, those are the two most established parts
[00:26:40.420 --> 00:26:42.020]   of the stack, the system of reasoning,
[00:26:42.020 --> 00:26:43.940]   and then the RAG stack.
[00:26:43.940 --> 00:26:46.780]   The part that is completely open water right now
[00:26:46.780 --> 00:26:48.460]   is how people interact with the models,
[00:26:48.460 --> 00:26:50.660]   and what I've been calling AI/UX.
[00:26:50.660 --> 00:26:53.780]   I held the very first AI/UX meetup in San Francisco,
[00:26:53.780 --> 00:26:56.620]   and AI/UX is a big portion of the conference
[00:26:56.620 --> 00:26:58.420]   that I'm holding in October.
[00:26:58.420 --> 00:26:59.860]   And I think this is where front-end engineers
[00:26:59.860 --> 00:27:01.780]   should really get excited, right?
[00:27:01.780 --> 00:27:05.340]   Basically, when Chat2BT was announced in November last year,
[00:27:05.340 --> 00:27:07.340]   it was mostly an UX innovation, right?
[00:27:07.340 --> 00:27:09.700]   Instead of the sort of open AI playground
[00:27:09.700 --> 00:27:11.780]   that was not very inspiring,
[00:27:11.780 --> 00:27:14.700]   just being able to thread together a chat
[00:27:14.700 --> 00:27:15.900]   and going back and forth
[00:27:15.900 --> 00:27:17.660]   seems to unlock a lot of value for a lot of people,
[00:27:17.660 --> 00:27:19.260]   and that caught open AI by surprise.
[00:27:19.260 --> 00:27:21.900]   Like, the reason that they actually dropped it quietly
[00:27:21.900 --> 00:27:22.980]   with a very small blog post
[00:27:22.980 --> 00:27:24.580]   is 'cause they didn't think it was gonna be a big deal,
[00:27:24.580 --> 00:27:25.460]   but it was.
[00:27:25.460 --> 00:27:28.300]   So how do we break beyond the chat box?
[00:27:28.300 --> 00:27:31.340]   How do we unlock the capabilities of this reasoning
[00:27:31.340 --> 00:27:32.740]   and large-damage models
[00:27:32.740 --> 00:27:37.100]   towards more intuitive interfaces apart from just the UX?
[00:27:37.100 --> 00:27:39.860]   So one form of that is, for example, GitHub Copilot,
[00:27:39.860 --> 00:27:42.100]   where instead of a separate chat box,
[00:27:42.100 --> 00:27:44.100]   GitHub Copilot watches as you type
[00:27:44.100 --> 00:27:46.220]   and then tries to auto-complete as you type.
[00:27:46.220 --> 00:27:47.660]   That's something that they consciously engineered
[00:27:47.660 --> 00:27:50.220]   for over six months to get that experience,
[00:27:50.220 --> 00:27:51.980]   because people find that
[00:27:51.980 --> 00:27:54.260]   if you have to context switch back and forth
[00:27:54.260 --> 00:27:55.980]   between your code and your chat box,
[00:27:55.980 --> 00:27:57.740]   they're not really going to use it as much.
