
[00:00:00.000 --> 00:00:03.000]   (keyboard clicking)
[00:00:03.000 --> 00:00:05.000]   Okay, it says, "Win live."
[00:00:05.000 --> 00:00:06.340]   Take 30 seconds.
[00:00:06.340 --> 00:00:10.480]   It says, "Win live."
[00:00:10.480 --> 00:00:14.040]   Hey everybody, thank you for joining us.
[00:00:14.040 --> 00:00:15.960]   I'm super excited to be having time
[00:00:15.960 --> 00:00:17.600]   at the Watson Sciences Club.
[00:00:17.600 --> 00:00:21.420]   I had the opportunity to interview Sebastian Rashka a few,
[00:00:21.420 --> 00:00:23.040]   I think it was quite a few months ago
[00:00:23.040 --> 00:00:25.560]   and it's always an honor to learn from him.
[00:00:25.560 --> 00:00:27.440]   Sebastian, thanks again for your time
[00:00:27.440 --> 00:00:30.080]   and thanks for joining us today.
[00:00:30.080 --> 00:00:31.680]   - Yeah, thanks for organizing that.
[00:00:31.680 --> 00:00:33.200]   And yeah, I'm excited to talk to you
[00:00:33.200 --> 00:00:35.240]   about exciting things again.
[00:00:35.240 --> 00:00:37.320]   So last time I remember it was a lot of fun
[00:00:37.320 --> 00:00:40.060]   and I hope we are going to have fun again here.
[00:00:40.060 --> 00:00:42.480]   - I'm sure you won't be surprised,
[00:00:42.480 --> 00:00:46.000]   but for me it was one of the best received episodes
[00:00:46.000 --> 00:00:48.920]   on the podcast, so thanks for making that happen.
[00:00:48.920 --> 00:00:51.200]   I'll share my screen to give the audience
[00:00:51.200 --> 00:00:52.520]   an introduction about you,
[00:00:52.520 --> 00:00:54.240]   although I'm sure most of them don't know this,
[00:00:54.240 --> 00:00:55.940]   but I would still like to do that.
[00:00:55.940 --> 00:00:58.700]   (mouse clicking)
[00:00:58.700 --> 00:01:04.340]   So you can find Sebastian on Twitter.
[00:01:04.340 --> 00:01:06.980]   His handle is @raspt.
[00:01:06.980 --> 00:01:10.220]   He's the incoming Lead AI Educator at GreatAI
[00:01:10.220 --> 00:01:12.700]   and we'll be talking a lot about this.
[00:01:12.700 --> 00:01:16.400]   And he's been the Associate Professor of Statistics
[00:01:16.400 --> 00:01:18.320]   at the University of Madison.
[00:01:18.320 --> 00:01:20.740]   You can also check out his website,
[00:01:20.740 --> 00:01:23.180]   which is there on his Twitter profile.
[00:01:23.180 --> 00:01:27.300]   I have the second and the third edition of my book
[00:01:27.300 --> 00:01:30.180]   near my desk, which also we'll be talking about.
[00:01:30.180 --> 00:01:32.340]   And I would also highly encourage all of you
[00:01:32.340 --> 00:01:34.460]   to check out Sebastian's YouTube channel.
[00:01:34.460 --> 00:01:38.960]   It has a lot of very high content educational videos,
[00:01:38.960 --> 00:01:40.740]   things that I always try to watch
[00:01:40.740 --> 00:01:42.940]   and always end up learning a lot from them.
[00:01:42.940 --> 00:01:47.460]   Did I miss anything from the-
[00:01:47.460 --> 00:01:49.820]   - Actually, yeah, you covered so many things.
[00:01:49.820 --> 00:01:51.260]   I'm really flattered, actually.
[00:01:51.260 --> 00:01:54.300]   Thank you so much for the kind introduction.
[00:01:54.300 --> 00:01:58.580]   Yeah, I think, yeah, that's about it in a nutshell, I guess.
[00:01:58.580 --> 00:01:59.680]   Yeah, thank you.
[00:01:59.680 --> 00:02:03.420]   - So I'd love to start by talking about the book.
[00:02:03.420 --> 00:02:06.300]   Like I said, I've owned all three editions
[00:02:06.300 --> 00:02:07.780]   and you've been teasing out the,
[00:02:07.780 --> 00:02:09.940]   I think it's the fourth edition of the book.
[00:02:09.940 --> 00:02:12.260]   So if you could tell us more about what's coming up
[00:02:12.260 --> 00:02:14.180]   and another question,
[00:02:14.180 --> 00:02:16.780]   since you've been focusing on lectures on PyTorch,
[00:02:16.780 --> 00:02:20.380]   will the book be now in PyTorch?
[00:02:20.380 --> 00:02:22.420]   - Yeah, so that's a good point.
[00:02:22.420 --> 00:02:26.300]   So usually we say all good things come in threes, right?
[00:02:26.300 --> 00:02:29.180]   So three editions, but there will be a new edition.
[00:02:29.180 --> 00:02:31.740]   Actually, we have been working on that since summer.
[00:02:31.740 --> 00:02:35.300]   So mostly the summer I was working on this a lot
[00:02:35.300 --> 00:02:37.580]   and there's been a lot of changes,
[00:02:37.580 --> 00:02:38.540]   really a lot of changes,
[00:02:38.540 --> 00:02:41.660]   which is why it will not be called the fourth edition.
[00:02:41.660 --> 00:02:44.700]   It will be actually an entirely new title.
[00:02:44.700 --> 00:02:47.400]   So we haven't, I think, 100% decided yet,
[00:02:47.400 --> 00:02:49.040]   but it will be something along the lines
[00:02:49.040 --> 00:02:52.340]   of machine learning with PyTorch and Scikit-learn.
[00:02:52.340 --> 00:02:54.260]   So like you said,
[00:02:54.260 --> 00:02:56.540]   kind of like related to the PyTorch lectures
[00:02:56.540 --> 00:02:59.780]   I was teaching, there will be a focus on PyTorch.
[00:02:59.780 --> 00:03:02.300]   So switching from TensorFlow to PyTorch.
[00:03:02.300 --> 00:03:04.620]   But maybe just top of my head,
[00:03:04.620 --> 00:03:07.660]   like just stepping through all the things
[00:03:07.660 --> 00:03:08.780]   that we worked on this summer
[00:03:08.780 --> 00:03:11.760]   or also in the upcoming last couple of months.
[00:03:11.760 --> 00:03:14.080]   So I've been like mostly tweaking
[00:03:14.080 --> 00:03:17.260]   the first couple of chapters in terms of refining them
[00:03:17.260 --> 00:03:20.040]   and coming up with sometimes better visuals
[00:03:20.040 --> 00:03:22.280]   because yeah, over the course of the years,
[00:03:22.280 --> 00:03:24.080]   there have been so many questions by people
[00:03:24.080 --> 00:03:25.720]   about certain things that I felt like,
[00:03:25.720 --> 00:03:27.480]   okay, if I have a better figure here,
[00:03:27.480 --> 00:03:30.480]   that could probably address a lot of these questions
[00:03:30.480 --> 00:03:31.600]   that some people have.
[00:03:31.600 --> 00:03:36.000]   So then I remember a lot of time was spent
[00:03:36.000 --> 00:03:38.160]   like on new sections, actually.
[00:03:38.160 --> 00:03:41.500]   Like I was writing a new section on gradient boosting
[00:03:41.500 --> 00:03:42.580]   for classification.
[00:03:42.580 --> 00:03:45.680]   I felt like it was a really important thing to have
[00:03:45.680 --> 00:03:47.740]   because yeah, gradient boosting, I would say,
[00:03:47.740 --> 00:03:49.840]   is among the most,
[00:03:49.840 --> 00:03:53.660]   I wouldn't say most widely used machine learning algorithm.
[00:03:53.660 --> 00:03:55.000]   Although it might be actually,
[00:03:55.000 --> 00:03:57.520]   if I think back of the Kaggle survey that came out,
[00:03:57.520 --> 00:04:00.580]   it's one of the most widely used ones.
[00:04:00.580 --> 00:04:01.420]   And I didn't have--
[00:04:01.420 --> 00:04:05.200]   - Is it because Kaggle is a really used boosting reason?
[00:04:05.200 --> 00:04:07.020]   So I'm sorry to interrupt you.
[00:04:07.020 --> 00:04:07.920]   - No, it's a good point.
[00:04:07.920 --> 00:04:09.540]   It's like a chicken egg problem, right?
[00:04:09.540 --> 00:04:12.380]   Because this algorithm is successful in Kaggle.
[00:04:12.380 --> 00:04:14.780]   And I think the Kaggle survey is more general
[00:04:14.780 --> 00:04:17.540]   in terms of asking people, but you're right.
[00:04:17.540 --> 00:04:20.680]   It's mostly people who probably are familiar with Kaggle.
[00:04:20.680 --> 00:04:22.700]   And if you see that it wins competitions,
[00:04:22.700 --> 00:04:23.900]   you probably start using it.
[00:04:23.900 --> 00:04:26.080]   And then it's kind of like this,
[00:04:26.080 --> 00:04:29.060]   almost like a self-fulfilling prophecy here.
[00:04:29.060 --> 00:04:32.320]   But no, I think it's actually a very powerful method
[00:04:32.320 --> 00:04:34.540]   for tabular data sets.
[00:04:34.540 --> 00:04:37.420]   So I added a section on that.
[00:04:37.420 --> 00:04:39.140]   One thing that took me quite some time
[00:04:39.140 --> 00:04:40.980]   as going back to the original paper,
[00:04:40.980 --> 00:04:43.180]   because there is no good resource
[00:04:43.180 --> 00:04:46.860]   on gradient boosting for classification, like explaining it.
[00:04:46.860 --> 00:04:49.460]   It's usually only about regression examples.
[00:04:49.460 --> 00:04:51.420]   In my lectures themselves,
[00:04:51.420 --> 00:04:54.180]   I only always had regression examples
[00:04:54.180 --> 00:04:56.200]   because it's simpler to explain.
[00:04:56.200 --> 00:04:58.180]   So I went back and rewrote this
[00:04:58.180 --> 00:05:01.500]   for losing the logistic loss for classification.
[00:05:01.500 --> 00:05:03.540]   That was one big thing.
[00:05:03.540 --> 00:05:07.180]   I was also completely rewriting the back propagation section
[00:05:07.180 --> 00:05:11.340]   because I felt like it was something I've wrote like 2014, 15.
[00:05:11.340 --> 00:05:14.420]   And due to the way I was teaching it
[00:05:14.420 --> 00:05:16.340]   in the context of the class,
[00:05:16.340 --> 00:05:19.740]   I felt like I could have explained that way better or cleaner.
[00:05:19.740 --> 00:05:22.820]   And so in that way, yeah, like making these little changes.
[00:05:22.820 --> 00:05:24.060]   But like you said,
[00:05:24.060 --> 00:05:27.340]   one big change will be that it is based on PyTorch.
[00:05:27.340 --> 00:05:30.540]   So I got a co-author who helped me a lot with this
[00:05:30.540 --> 00:05:32.060]   because it's like 19 chapters,
[00:05:32.060 --> 00:05:33.420]   now it's such a long book.
[00:05:33.420 --> 00:05:36.580]   And so Hayden Liu helped me a lot
[00:05:36.580 --> 00:05:37.860]   or was basically in charge
[00:05:37.860 --> 00:05:41.140]   of converting the TensorFlow chapters to PyTorch.
[00:05:41.140 --> 00:05:44.020]   And then I also recently added a section,
[00:05:44.020 --> 00:05:45.540]   let's say on PyTorch Lightning.
[00:05:45.540 --> 00:05:47.980]   And the summer with Ben Kaufman,
[00:05:47.980 --> 00:05:50.580]   I brought a graph neural network chapter,
[00:05:50.580 --> 00:05:52.340]   which is a brand new chapter.
[00:05:52.340 --> 00:05:53.620]   'Cause yeah, we have been working a lot
[00:05:53.620 --> 00:05:56.960]   on graph neural networks for molecular data.
[00:05:56.960 --> 00:06:00.860]   So like in a context of generating molecules,
[00:06:00.860 --> 00:06:04.100]   but then also classifying bioactivity of molecules.
[00:06:04.100 --> 00:06:06.980]   So that will be a new chapter.
[00:06:06.980 --> 00:06:10.680]   And with Jitin Jao, I worked on a transformer chapter.
[00:06:10.680 --> 00:06:13.500]   So language transformers, it was also a huge chapter.
[00:06:13.500 --> 00:06:16.020]   I just got it back a few weeks ago for like
[00:06:16.020 --> 00:06:18.020]   from the review us to do some final editing.
[00:06:18.020 --> 00:06:20.500]   So it's currently the last chapter I'm editing
[00:06:20.500 --> 00:06:23.900]   and I'm hoping then the book will be finalized
[00:06:23.900 --> 00:06:27.100]   maybe hopefully end of the month
[00:06:27.100 --> 00:06:30.220]   or maybe early January, we'll see.
[00:06:30.220 --> 00:06:31.580]   I mean, we don't have an official time.
[00:06:31.580 --> 00:06:33.300]   I don't want to make any promises,
[00:06:33.300 --> 00:06:34.520]   but it's not too far away.
[00:06:34.520 --> 00:06:35.700]   It's like the final stages.
[00:06:35.700 --> 00:06:38.340]   So every evening I'm spending a couple of hours
[00:06:38.340 --> 00:06:40.980]   and making the final tweaks, but it's getting there.
[00:06:40.980 --> 00:06:44.400]   Long story short, I'm really excited about this
[00:06:44.400 --> 00:06:45.920]   because it's like a big overhaul.
[00:06:45.920 --> 00:06:48.720]   I mean, the previous editions have also been big overhauls,
[00:06:48.720 --> 00:06:52.040]   always something new, but this time I feel like really,
[00:06:52.040 --> 00:06:54.240]   it's really exciting because I also teach in PyTorch
[00:06:54.240 --> 00:06:57.840]   and then having everything neatly in PyTorch
[00:06:57.840 --> 00:06:59.680]   and everything a little bit refined,
[00:06:59.680 --> 00:07:01.720]   I think it will be really nice.
[00:07:01.720 --> 00:07:05.000]   - As a reminder to the people watching live,
[00:07:05.000 --> 00:07:07.080]   I know I'm greedy about this opportunity
[00:07:07.080 --> 00:07:08.960]   so I'm asking the question, but this is for you.
[00:07:08.960 --> 00:07:11.760]   So please keep the questions coming in and ask them.
[00:07:11.760 --> 00:07:14.040]   Since I don't see any, I'll ask this.
[00:07:14.040 --> 00:07:17.760]   Have you personally seen any changes in maybe your students
[00:07:17.760 --> 00:07:21.680]   as you've made these changes to different frameworks?
[00:07:21.680 --> 00:07:23.480]   I know you keep tweeting about this,
[00:07:23.480 --> 00:07:25.320]   how you're experimenting with new ideas.
[00:07:25.320 --> 00:07:28.600]   You're also super active about being on top
[00:07:28.600 --> 00:07:32.440]   of research papers, also constantly reading through Reddit.
[00:07:32.440 --> 00:07:35.280]   So as you've shifted to TensorFlow 2,
[00:07:35.280 --> 00:07:37.080]   from TensorFlow 1 then to PyTorch,
[00:07:37.080 --> 00:07:40.920]   have you seen any changes in the students as well?
[00:07:40.920 --> 00:07:42.120]   - That's a very good question.
[00:07:42.120 --> 00:07:45.040]   Actually, I haven't taught a class in TensorFlow.
[00:07:45.040 --> 00:07:46.760]   I used TensorFlow back then myself,
[00:07:46.760 --> 00:07:49.500]   but that was before I was joining
[00:07:49.500 --> 00:07:50.940]   the university for teaching.
[00:07:50.940 --> 00:07:53.640]   So actually while the third edition was in TensorFlow,
[00:07:53.640 --> 00:07:57.120]   that was in 2019, I was actually teaching in PyTorch.
[00:07:57.120 --> 00:08:00.840]   So we tweaked the second edition to the third edition
[00:08:00.840 --> 00:08:04.640]   by using the Eager API.
[00:08:04.640 --> 00:08:06.400]   So the Eager mode in TensorFlow,
[00:08:06.400 --> 00:08:10.500]   like using the tf.keras and so forth.
[00:08:10.500 --> 00:08:13.000]   But at this time I was already mainly using PyTorch
[00:08:13.000 --> 00:08:13.820]   and also in teaching.
[00:08:13.820 --> 00:08:16.720]   So I honestly don't have experience
[00:08:16.720 --> 00:08:18.000]   with teaching in TensorFlow.
[00:08:18.000 --> 00:08:20.400]   I only used it back then, a long time ago.
[00:08:20.400 --> 00:08:23.000]   I still sometimes look at examples in TensorFlow.
[00:08:23.000 --> 00:08:24.240]   I think it has evolved a lot.
[00:08:24.240 --> 00:08:26.200]   It's a really nice tool.
[00:08:26.200 --> 00:08:29.300]   I must say though, it's just when PyTorch came out,
[00:08:29.300 --> 00:08:31.080]   it kind of clicked a little bit with me
[00:08:31.080 --> 00:08:33.280]   in terms of how Autograd works
[00:08:33.280 --> 00:08:35.120]   and the computation graphs work.
[00:08:35.120 --> 00:08:36.720]   And I kind of really like it.
[00:08:36.720 --> 00:08:39.100]   So it's why I use it for teaching
[00:08:39.100 --> 00:08:42.280]   and can't really say how, let's say,
[00:08:42.280 --> 00:08:44.760]   how students appreciate the difference
[00:08:44.760 --> 00:08:46.360]   between TensorFlow and PyTorch.
[00:08:46.360 --> 00:08:50.000]   Yeah, but I must say in general teaching,
[00:08:50.000 --> 00:08:51.900]   I teach both the deep learning class
[00:08:51.900 --> 00:08:53.280]   and the machine learning class.
[00:08:53.280 --> 00:08:57.760]   And PyTorch, even though let's say it's kind of intuitive
[00:08:57.760 --> 00:08:59.360]   for a deep learning framework,
[00:08:59.360 --> 00:09:01.360]   it's still a steep learning curve.
[00:09:01.360 --> 00:09:04.440]   So teaching something in PyTorch,
[00:09:04.440 --> 00:09:06.360]   it's kind of still very difficult
[00:09:06.360 --> 00:09:09.080]   if you have not had any experience
[00:09:09.080 --> 00:09:10.680]   with machine learning and deep learning,
[00:09:10.680 --> 00:09:11.840]   like learning this from scratch,
[00:09:11.840 --> 00:09:13.040]   because it's a lot of overhead
[00:09:13.040 --> 00:09:16.080]   if you compare that, for example, to Scikit-Learn.
[00:09:16.080 --> 00:09:17.680]   Scikit-Learn, it's, I mean,
[00:09:17.680 --> 00:09:19.760]   even Scikit-Learn could be a lot.
[00:09:19.760 --> 00:09:21.640]   I remember when I learned Scikit-Learn,
[00:09:21.640 --> 00:09:23.400]   it was like, whoa, there's so much stuff.
[00:09:23.400 --> 00:09:25.260]   How does it all work and everything?
[00:09:25.260 --> 00:09:27.480]   And it took like maybe a year or something
[00:09:27.480 --> 00:09:30.080]   to really get comfortable with everything
[00:09:30.080 --> 00:09:31.600]   'cause you can do very powerful things
[00:09:31.600 --> 00:09:33.500]   like with the pipelines, chaining things together,
[00:09:33.500 --> 00:09:35.920]   the column transformer, heterogeneous data sets,
[00:09:35.920 --> 00:09:37.120]   like figuring all that out,
[00:09:37.120 --> 00:09:39.520]   it takes a lot of practice, I would say.
[00:09:39.520 --> 00:09:42.960]   And then PyTorch is even more complicated on top of that
[00:09:42.960 --> 00:09:45.440]   because it's more, I would say lower level
[00:09:45.440 --> 00:09:47.560]   because in Scikit-Learn, you have a fit function
[00:09:47.560 --> 00:09:50.660]   and then it just fits the model it's ready to use.
[00:09:50.660 --> 00:09:52.240]   Whereas in PyTorch, you really have to,
[00:09:52.240 --> 00:09:53.160]   or in general in deep learning,
[00:09:53.160 --> 00:09:57.000]   you have to really look at the loss over the training time,
[00:09:57.000 --> 00:09:59.120]   like to tweak hyperparameters in the way
[00:09:59.120 --> 00:10:01.120]   that you want to see if it converges.
[00:10:01.120 --> 00:10:03.160]   You have to write your training loop yourself.
[00:10:03.160 --> 00:10:07.320]   So it's more like way more nitty gritty, hands-on.
[00:10:07.320 --> 00:10:11.240]   So in that way, yeah, it is still a steep learning curve
[00:10:11.240 --> 00:10:12.560]   but it's also a lot of fun.
[00:10:12.560 --> 00:10:13.400]   I really like that.
[00:10:13.400 --> 00:10:15.240]   It's like, I like tinkering with things.
[00:10:15.240 --> 00:10:17.560]   So I kind of appreciate to be more hands-on
[00:10:17.560 --> 00:10:20.360]   and trying things out and toying around with things.
[00:10:20.360 --> 00:10:23.280]   - For the audience, I just wanted to remind them
[00:10:23.280 --> 00:10:27.360]   that you put up 170 lectures, a lot of which are in PyTorch
[00:10:27.360 --> 00:10:29.680]   and this is one of the best resources
[00:10:29.680 --> 00:10:31.480]   in my biased opinion on PyTorch
[00:10:31.480 --> 00:10:33.480]   as if they want to start up.
[00:10:33.480 --> 00:10:34.380]   - Well, thank you.
[00:10:34.380 --> 00:10:38.400]   - Have you played around with charts?
[00:10:38.400 --> 00:10:41.000]   I thought you have any thoughts on that.
[00:10:41.000 --> 00:10:43.160]   - Very good question.
[00:10:43.160 --> 00:10:44.760]   It's something on my to-do list.
[00:10:44.760 --> 00:10:47.160]   It's like, I'm kind of familiar with it.
[00:10:47.160 --> 00:10:48.080]   I looked at it.
[00:10:48.080 --> 00:10:50.120]   I know approximately how it's, let's say,
[00:10:50.120 --> 00:10:51.800]   different from PyTorch.
[00:10:51.800 --> 00:10:53.720]   Where in PyTorch, you are more like
[00:10:53.720 --> 00:10:55.400]   have the computation graph with,
[00:10:55.400 --> 00:10:57.760]   you differentiate with respect to the output.
[00:10:57.760 --> 00:11:02.520]   In Jacks, what's nice is you create derivatives
[00:11:02.520 --> 00:11:03.560]   of functions directly.
[00:11:03.560 --> 00:11:06.040]   So you have like a derivative function and things like that.
[00:11:06.040 --> 00:11:09.080]   I think it can be very useful in certain contexts,
[00:11:09.080 --> 00:11:12.960]   but in my applied work, there was no,
[00:11:12.960 --> 00:11:17.400]   I would say there was no reason to really dive into it
[00:11:17.400 --> 00:11:20.800]   to in way more detail and experiment with it.
[00:11:20.800 --> 00:11:24.260]   And then I saw there are also many libraries on top of it.
[00:11:24.260 --> 00:11:26.840]   I think Haiku, Flax, and I was like,
[00:11:26.840 --> 00:11:29.640]   ah, maybe I will save that for another day.
[00:11:29.640 --> 00:11:31.200]   Yeah, no, it looks nice.
[00:11:31.200 --> 00:11:33.000]   I think it's good to always have these options
[00:11:33.000 --> 00:11:36.160]   and different things for slightly different niche,
[00:11:36.160 --> 00:11:39.480]   not niche, but like slightly different research focus areas
[00:11:39.480 --> 00:11:44.480]   where the Flax or Jacks Flax frameworks might be more,
[00:11:44.480 --> 00:11:46.760]   better for certain types of theoretical work.
[00:11:46.760 --> 00:11:50.280]   Whereas for other things, PyTorch might be a better choice.
[00:11:50.280 --> 00:11:51.920]   So it's good to have these options.
[00:11:51.920 --> 00:11:55.100]   For my purposes, I haven't had the need to use Jacks yet,
[00:11:55.100 --> 00:11:57.060]   which is why I was putting it off a little bit.
[00:11:57.060 --> 00:11:58.380]   Same thing with Julia.
[00:11:58.380 --> 00:11:59.920]   I think Julia is a very nice language,
[00:11:59.920 --> 00:12:02.780]   but it's always like, okay, the day has 24 hours.
[00:12:02.780 --> 00:12:04.580]   There are so many cool things.
[00:12:04.580 --> 00:12:05.420]   Which one?
[00:12:05.420 --> 00:12:08.380]   - I think the audience has like at least 50 hours.
[00:12:08.380 --> 00:12:09.700]   - Yeah, yeah.
[00:12:09.700 --> 00:12:14.540]   It's like always, yeah, you have to make trade-offs.
[00:12:14.540 --> 00:12:15.380]   Yeah.
[00:12:15.380 --> 00:12:18.620]   - This is a question from the audience.
[00:12:18.620 --> 00:12:21.420]   What are you learning currently yourself?
[00:12:21.420 --> 00:12:25.680]   What's your learning (indistinct)
[00:12:25.680 --> 00:12:29.160]   - Yeah, so for me, it's usually I pick a topic
[00:12:29.160 --> 00:12:31.480]   and I learn by topic usually.
[00:12:31.480 --> 00:12:33.840]   If there's something I find interesting,
[00:12:33.840 --> 00:12:36.520]   then I dive into these individual topics.
[00:12:36.520 --> 00:12:39.120]   For example, recently, because I was also teaching
[00:12:39.120 --> 00:12:44.120]   in a lecture on that, I was looking into performance metrics
[00:12:44.120 --> 00:12:46.080]   like Matthew's correlation coefficient.
[00:12:46.080 --> 00:12:47.860]   I was going down a rabbit hole
[00:12:47.860 --> 00:12:49.680]   and these types of comparisons.
[00:12:49.680 --> 00:12:52.160]   But in more general terms,
[00:12:52.160 --> 00:12:54.240]   what I was actually just learning yesterday
[00:12:54.240 --> 00:12:56.320]   is unrelated to machine learning,
[00:12:56.320 --> 00:12:59.720]   but it is Adobe Premiere because yeah,
[00:12:59.720 --> 00:13:01.280]   I wanted to kind of also,
[00:13:01.280 --> 00:13:03.880]   what I did is when we were switching to online teaching,
[00:13:03.880 --> 00:13:07.080]   I was just really just figuring out things on the fly
[00:13:07.080 --> 00:13:10.320]   and I was working, I just used iMovie on the Mac
[00:13:10.320 --> 00:13:12.280]   and doing these types of things.
[00:13:12.280 --> 00:13:14.600]   And then I moved to a different apartment
[00:13:14.600 --> 00:13:17.000]   where I have right now a lot of background noise.
[00:13:17.000 --> 00:13:20.160]   I got like this a Yeti microphone
[00:13:20.160 --> 00:13:22.360]   and there's some automatic software.
[00:13:22.360 --> 00:13:25.580]   And I was just last week trying to get this to work
[00:13:25.580 --> 00:13:27.520]   because I don't want to have all the background noise,
[00:13:27.520 --> 00:13:29.700]   but then they have like this nice software that removes it.
[00:13:29.700 --> 00:13:32.040]   I did a few recordings and it was just dropping out
[00:13:32.040 --> 00:13:34.480]   totally my voice at the end of each sentence
[00:13:34.480 --> 00:13:36.480]   because it was too aggressive
[00:13:36.480 --> 00:13:38.060]   in terms of removing background noise.
[00:13:38.060 --> 00:13:41.000]   And then I went down that rabbit hole of figuring out,
[00:13:41.000 --> 00:13:43.800]   okay, what software can I use to kind of fix that?
[00:13:43.800 --> 00:13:48.240]   And I mean, there are these different paradigms,
[00:13:48.240 --> 00:13:49.480]   people like, what is it called?
[00:13:49.480 --> 00:13:51.520]   Final Cut and Logic.
[00:13:51.520 --> 00:13:53.200]   And then there is the Adobe Suite
[00:13:53.200 --> 00:13:54.880]   with Audition and Premiere.
[00:13:54.880 --> 00:13:57.600]   And since I have Adobe subscription already,
[00:13:57.600 --> 00:14:00.320]   I thought, okay, let me try this out.
[00:14:00.320 --> 00:14:03.440]   And then I was just yesterday in that rabbit hole
[00:14:03.440 --> 00:14:06.300]   of watching videos, how to edit your video in Premiere
[00:14:06.300 --> 00:14:07.560]   and also doing the audio editing.
[00:14:07.560 --> 00:14:11.340]   So which I hope will help me making better lecture videos
[00:14:11.340 --> 00:14:13.760]   now in the future, now that I have figured things out.
[00:14:13.760 --> 00:14:15.640]   'Cause yeah, I can't really use the software,
[00:14:15.640 --> 00:14:18.040]   the Yeti software because it's too aggressive.
[00:14:18.040 --> 00:14:22.000]   And I will just use the raw voice and then do some editing.
[00:14:22.000 --> 00:14:25.000]   But this is really, I found it really fascinating.
[00:14:25.000 --> 00:14:27.880]   I thought always I was watching YouTube videos myself
[00:14:27.880 --> 00:14:30.520]   and I'm always like, I took it for granted
[00:14:30.520 --> 00:14:33.360]   that the quality is as good as it is.
[00:14:33.360 --> 00:14:36.080]   So I was always like, well, that is just something
[00:14:36.080 --> 00:14:38.600]   that happens to be good quality,
[00:14:38.600 --> 00:14:42.560]   but then I never really appreciated how much work it takes
[00:14:42.560 --> 00:14:44.740]   to set everything up and do the editing
[00:14:44.740 --> 00:14:47.200]   and edit out all the Ms and Ms,
[00:14:47.200 --> 00:14:50.160]   and then also removing the echo and the background noise.
[00:14:50.160 --> 00:14:52.960]   And yeah, so it's actually a lot of work.
[00:14:52.960 --> 00:14:56.480]   It's like, I can see that it's a full-time job,
[00:14:56.480 --> 00:14:57.720]   maybe even doing that.
[00:14:57.720 --> 00:15:01.320]   So yeah, but I don't want to get into this nitty gritty
[00:15:01.320 --> 00:15:03.800]   detail where I spent like hours and hours on it,
[00:15:03.800 --> 00:15:06.840]   but I wanted to do at least have a little understanding
[00:15:06.840 --> 00:15:10.220]   to make some tweaks and improve things here and there.
[00:15:10.220 --> 00:15:12.740]   So I found that kind of like a fascinating, actually.
[00:15:12.740 --> 00:15:15.060]   Nothing to do, actually can have something to do
[00:15:15.060 --> 00:15:17.160]   with machine learning because I'm pretty sure
[00:15:17.160 --> 00:15:18.600]   they use some machine learning algorithms
[00:15:18.600 --> 00:15:19.440]   under the hood now.
[00:15:19.440 --> 00:15:22.940]   So that's actually also last thing about this.
[00:15:22.940 --> 00:15:23.980]   There's like the service.
[00:15:23.980 --> 00:15:28.740]   I saw one other issue is subtitles or closed captioning,
[00:15:28.740 --> 00:15:31.620]   'cause I have this very strong German accent.
[00:15:31.620 --> 00:15:35.460]   When I was doing the subtitles for my online lectures,
[00:15:35.460 --> 00:15:37.540]   I just uploaded them to YouTube.
[00:15:37.540 --> 00:15:39.640]   And for some reason, YouTube was always,
[00:15:39.640 --> 00:15:41.160]   even though I was speaking in English,
[00:15:41.160 --> 00:15:43.300]   it was thinking I was speaking German
[00:15:43.300 --> 00:15:45.560]   and then it was doing these closed captions
[00:15:45.560 --> 00:15:46.980]   that didn't make sense at all.
[00:15:46.980 --> 00:15:49.500]   And yeah, what I ended up using was,
[00:15:49.500 --> 00:15:51.340]   I think it was called otter.ai
[00:15:51.340 --> 00:15:53.940]   and they can actually do really good on closed captioning.
[00:15:53.940 --> 00:15:54.780]   - I used the same tool.
[00:15:54.780 --> 00:15:57.260]   - Oh yeah, and I think it's based on deep learning, right?
[00:15:57.260 --> 00:15:59.540]   So in that way, so that's like full circle.
[00:15:59.540 --> 00:16:01.620]   We are back at deep learning here.
[00:16:01.620 --> 00:16:03.100]   So yeah.
[00:16:03.100 --> 00:16:05.460]   - That's also a very interesting bias
[00:16:05.460 --> 00:16:08.020]   in the YouTube captioning system, right?
[00:16:08.020 --> 00:16:09.340]   If it's defaulting to zero.
[00:16:09.340 --> 00:16:10.180]   - Yeah, there was like,
[00:16:10.180 --> 00:16:11.960]   and there was no setting to change it.
[00:16:11.960 --> 00:16:14.780]   I mean, sometimes I think deep learning
[00:16:14.780 --> 00:16:15.980]   and machine learning is very powerful.
[00:16:15.980 --> 00:16:18.660]   It's very cool if it can do things automatically,
[00:16:18.660 --> 00:16:20.960]   but sometimes forcing it to always
[00:16:20.960 --> 00:16:23.180]   automatically do something,
[00:16:23.180 --> 00:16:24.240]   I'm not sure if that's necessary.
[00:16:24.240 --> 00:16:26.300]   There could be an option, like I want this,
[00:16:26.300 --> 00:16:27.180]   or I don't want this.
[00:16:27.180 --> 00:16:29.460]   So, and I think maybe they changed it now,
[00:16:29.460 --> 00:16:30.780]   but back then there was no option
[00:16:30.780 --> 00:16:32.380]   to turn off this auto guessing.
[00:16:32.380 --> 00:16:34.380]   So that was kind of like annoying, yeah.
[00:16:35.740 --> 00:16:40.100]   - And on this topic, as you're now optimizing
[00:16:40.100 --> 00:16:42.940]   to make sure your video quality is high,
[00:16:42.940 --> 00:16:45.740]   which is presumably being broadcasted compared to,
[00:16:45.740 --> 00:16:49.300]   I assume inside of a lecture hall,
[00:16:49.300 --> 00:16:51.500]   it would be a completely different scenario.
[00:16:51.500 --> 00:16:53.940]   Did you miss the person to person interaction
[00:16:53.940 --> 00:16:57.180]   and what are your thoughts on the comparisons?
[00:16:57.180 --> 00:16:58.180]   - Yeah, that's a very good point.
[00:16:58.180 --> 00:17:02.300]   I actually, I really liked the in-person interaction,
[00:17:02.300 --> 00:17:04.820]   especially when you explain something
[00:17:04.820 --> 00:17:09.820]   and of course you want everyone to understand everything,
[00:17:09.820 --> 00:17:12.660]   but it's very satisfying if,
[00:17:12.660 --> 00:17:14.460]   let's say someone has a question
[00:17:14.460 --> 00:17:17.820]   and the person, let's say they didn't understand something
[00:17:17.820 --> 00:17:20.540]   because you went over it too quickly
[00:17:20.540 --> 00:17:22.480]   or it was just too complicated.
[00:17:22.480 --> 00:17:24.380]   And then you explain it again
[00:17:24.380 --> 00:17:26.540]   and you see the person light up in the way like,
[00:17:26.540 --> 00:17:28.500]   well, that makes so much more sense now.
[00:17:28.500 --> 00:17:31.620]   I really like this type of like where you feel like
[00:17:31.620 --> 00:17:33.720]   you're helping someone really to understand something
[00:17:33.720 --> 00:17:34.940]   and they really appreciate it.
[00:17:34.940 --> 00:17:37.060]   I really missed that one.
[00:17:37.060 --> 00:17:39.840]   So, I mean, we have in-person lectures right now,
[00:17:39.840 --> 00:17:41.620]   but it's something that you don't have,
[00:17:41.620 --> 00:17:44.220]   let's say when you make a video and upload the video.
[00:17:44.220 --> 00:17:45.820]   So that is something I really like,
[00:17:45.820 --> 00:17:48.080]   like this type of where you really get this feedback.
[00:17:48.080 --> 00:17:51.060]   Okay, this person really, it makes,
[00:17:51.060 --> 00:17:52.660]   so you put some work into it
[00:17:52.660 --> 00:17:54.060]   and the person really appreciates it
[00:17:54.060 --> 00:17:55.980]   and you feel like you're helping someone there.
[00:17:55.980 --> 00:17:58.420]   Like you see that life basically,
[00:17:58.420 --> 00:17:59.920]   which is really cool, I think.
[00:18:02.020 --> 00:18:05.000]   - For the online version, do you have any pros and cons
[00:18:05.000 --> 00:18:06.680]   if I may, that you really enjoy?
[00:18:06.680 --> 00:18:09.360]   Because you also put up lectures on,
[00:18:09.360 --> 00:18:10.680]   the same lectures on YouTube,
[00:18:10.680 --> 00:18:12.680]   but many people like me get to learn them
[00:18:12.680 --> 00:18:14.920]   from different countries.
[00:18:14.920 --> 00:18:19.920]   - Yeah, so an advantage of online is that,
[00:18:19.920 --> 00:18:23.240]   yeah, it's something you produce and then you have it.
[00:18:23.240 --> 00:18:24.560]   If you're happy with it,
[00:18:24.560 --> 00:18:27.040]   you can focus on other things then.
[00:18:27.040 --> 00:18:30.840]   I like in-person teaching, but I feel like also,
[00:18:30.840 --> 00:18:34.220]   let's say if you would do that for 10 years or 20 years,
[00:18:34.220 --> 00:18:36.020]   every year I update my lectures.
[00:18:36.020 --> 00:18:38.900]   So I make some changes, but there's also the danger
[00:18:38.900 --> 00:18:41.800]   that you learn yourself more things
[00:18:41.800 --> 00:18:44.060]   and you add and add and add more things to the lecture.
[00:18:44.060 --> 00:18:46.260]   So the lectures become longer and longer and longer
[00:18:46.260 --> 00:18:47.660]   because there are so many more things
[00:18:47.660 --> 00:18:48.500]   you want to talk about
[00:18:48.500 --> 00:18:51.620]   that you just recently got excited about.
[00:18:51.620 --> 00:18:53.580]   And if you make an online lecture, it's like,
[00:18:53.580 --> 00:18:56.340]   okay, you make this online lecture at this point in time.
[00:18:56.340 --> 00:19:00.260]   And yeah, you are, I would say you can then move on
[00:19:00.260 --> 00:19:03.160]   and work on other things in terms of new topics
[00:19:03.160 --> 00:19:05.760]   rather than doing the same topic again and again,
[00:19:05.760 --> 00:19:10.200]   you feel like, okay, I can now do new things, right?
[00:19:10.200 --> 00:19:12.840]   So I think it's in that way, maybe a better,
[00:19:12.840 --> 00:19:15.400]   better time efficiency wise,
[00:19:15.400 --> 00:19:18.020]   where you do something like you do a course,
[00:19:18.020 --> 00:19:19.680]   and then you can have in the end,
[00:19:19.680 --> 00:19:22.400]   instead of doing the course again next year or something,
[00:19:22.400 --> 00:19:24.200]   you can have additional topics.
[00:19:24.200 --> 00:19:27.600]   So, or maybe every so and so many years,
[00:19:27.600 --> 00:19:29.240]   you want to also change the course
[00:19:29.240 --> 00:19:31.080]   or these types of things.
[00:19:31.080 --> 00:19:34.120]   But in general, I think it's a time efficiency thing.
[00:19:34.120 --> 00:19:35.520]   You can also reach more people with that.
[00:19:35.520 --> 00:19:38.860]   I mean, it's like you have like a bigger audience
[00:19:38.860 --> 00:19:41.520]   in that way where you don't require people
[00:19:41.520 --> 00:19:42.600]   to come in person.
[00:19:42.600 --> 00:19:44.720]   And it's also more, that was one important point.
[00:19:44.720 --> 00:19:48.040]   It's also way more flexible in terms of people can learn
[00:19:48.040 --> 00:19:49.180]   whenever they want to learn.
[00:19:49.180 --> 00:19:51.180]   So they don't have to be at a certain place
[00:19:51.180 --> 00:19:52.400]   at a certain time.
[00:19:52.400 --> 00:19:55.200]   One disadvantage I heard from students is
[00:19:55.200 --> 00:19:56.500]   it can be harder to focus.
[00:19:56.500 --> 00:19:57.520]   And I have that problem too.
[00:19:57.520 --> 00:20:00.260]   When I watch videos, there's my email,
[00:20:00.260 --> 00:20:01.500]   there's something else.
[00:20:01.500 --> 00:20:03.340]   And it's like, I watch a video for 10 minutes,
[00:20:03.340 --> 00:20:05.780]   and then I catch myself thinking about something
[00:20:05.780 --> 00:20:06.900]   and checking my email or something.
[00:20:06.900 --> 00:20:08.340]   And then, oh, I should,
[00:20:08.340 --> 00:20:11.840]   I really have to be more disciplined to,
[00:20:11.840 --> 00:20:14.140]   like to focus really.
[00:20:14.140 --> 00:20:15.980]   And that is easier in person, I think.
[00:20:15.980 --> 00:20:19.280]   But I have also a tool kind of like that
[00:20:19.280 --> 00:20:22.100]   automatically quits programs that I'm opening
[00:20:22.100 --> 00:20:23.980]   when I'm in like this focus mode.
[00:20:23.980 --> 00:20:26.520]   So yeah, you have to be a little bit more disciplined
[00:20:26.520 --> 00:20:28.380]   about that, but yeah.
[00:20:28.380 --> 00:20:30.700]   Another advantage, by the way, is a video
[00:20:30.700 --> 00:20:31.820]   is that you can go back.
[00:20:31.820 --> 00:20:34.660]   So you can pause and go back
[00:20:34.660 --> 00:20:37.100]   and you can watch it multiple times,
[00:20:37.100 --> 00:20:40.900]   which I noticed is eliminating a lot of questions.
[00:20:40.900 --> 00:20:45.620]   In previous years, where we only had in-person lectures,
[00:20:45.620 --> 00:20:49.400]   students came to me often with questions and it's just fine.
[00:20:49.400 --> 00:20:53.600]   But when we had the recordings of people,
[00:20:53.600 --> 00:20:55.180]   it's because sometimes people miss something
[00:20:55.180 --> 00:20:56.100]   because it was too fast.
[00:20:56.100 --> 00:20:58.420]   They can just go back and watch it again.
[00:20:58.420 --> 00:21:00.200]   Of course, there are also a lot of questions,
[00:21:00.200 --> 00:21:01.700]   but there are different types of questions.
[00:21:01.700 --> 00:21:04.700]   I noticed they are more about additional topics
[00:21:04.700 --> 00:21:06.740]   rather than topics we covered already,
[00:21:06.740 --> 00:21:08.300]   which I find also interesting.
[00:21:08.300 --> 00:21:12.900]   Yeah, so related to also going back
[00:21:12.900 --> 00:21:13.880]   and these types of things.
[00:21:13.880 --> 00:21:16.740]   So this semester we have an in-person lecture.
[00:21:16.740 --> 00:21:19.220]   So I go there in person and give the lecture,
[00:21:19.220 --> 00:21:22.500]   but I also record the lecture because you never know.
[00:21:22.500 --> 00:21:25.160]   I mean, based on also we have the COVID situation
[00:21:25.160 --> 00:21:27.040]   and I don't want to force students, let's say,
[00:21:27.040 --> 00:21:29.240]   to come to the classroom if they don't feel well.
[00:21:29.240 --> 00:21:31.760]   So they have the option also to watch it online
[00:21:31.760 --> 00:21:33.760]   and students really appreciated that.
[00:21:33.760 --> 00:21:36.200]   I mean, they watch it as they attend the lecture,
[00:21:36.200 --> 00:21:38.200]   but then they can also go back and watch it again
[00:21:38.200 --> 00:21:40.000]   if things were unclear and these types of things.
[00:21:40.000 --> 00:21:42.740]   So I think both have advantages.
[00:21:42.740 --> 00:21:44.560]   I find it also interesting to think about
[00:21:44.560 --> 00:21:46.080]   what's the future of education.
[00:21:46.080 --> 00:21:49.160]   Is it like, are we going back to in-person
[00:21:49.160 --> 00:21:51.240]   or will it be entirely online?
[00:21:51.240 --> 00:21:54.140]   And I don't know how it will be,
[00:21:54.140 --> 00:21:59.140]   but I can see, yeah, the education more shifting to online
[00:21:59.140 --> 00:22:01.900]   because it's just more efficient in that way.
[00:22:01.900 --> 00:22:06.900]   It's almost like if you think about a movie and a theater,
[00:22:06.900 --> 00:22:11.780]   like movies are really the high quality polished things.
[00:22:11.780 --> 00:22:15.060]   You can have it in multiple theaters, movie theaters,
[00:22:15.060 --> 00:22:18.060]   and people all over the world can watch it.
[00:22:18.060 --> 00:22:20.460]   It costs more money to make, it's more polished.
[00:22:21.280 --> 00:22:23.720]   But it's something, yeah, everyone can watch.
[00:22:23.720 --> 00:22:25.740]   And then you have in-person theaters,
[00:22:25.740 --> 00:22:28.900]   which is where you have people playing live or acting live,
[00:22:28.900 --> 00:22:30.900]   which is also super cool.
[00:22:30.900 --> 00:22:32.340]   But I would say most of the time
[00:22:32.340 --> 00:22:34.040]   we would go to movie theaters
[00:22:34.040 --> 00:22:35.980]   because also let's say tickets are cheaper
[00:22:35.980 --> 00:22:39.640]   and it's easier to have that everywhere
[00:22:39.640 --> 00:22:42.880]   or even watching movies at home nowadays, basically.
[00:22:42.880 --> 00:22:46.360]   But theaters in person are this very special experience.
[00:22:46.360 --> 00:22:51.080]   You do it maybe once in a year or even less than that.
[00:22:51.080 --> 00:22:52.920]   I think it's something very special
[00:22:52.920 --> 00:22:55.300]   and it is very well appreciated
[00:22:55.300 --> 00:22:57.240]   because it's so much work to do this live.
[00:22:57.240 --> 00:22:59.880]   It's just a very different type of skill almost.
[00:22:59.880 --> 00:23:03.000]   And I feel like it could be also similar to that
[00:23:03.000 --> 00:23:06.600]   with online education where you have the videos
[00:23:06.600 --> 00:23:09.480]   and everything, but then you can have live sessions
[00:23:09.480 --> 00:23:12.080]   that say occasionally like workshops that are live
[00:23:12.080 --> 00:23:14.920]   where you can really provide more feedback in person
[00:23:14.920 --> 00:23:17.200]   where you have some more hands-on parts
[00:23:17.200 --> 00:23:18.040]   or something like that.
[00:23:18.040 --> 00:23:20.440]   So I think there's a place for both things.
[00:23:20.440 --> 00:23:22.120]   Both have different trade-offs,
[00:23:22.120 --> 00:23:23.960]   but it will be interesting to see
[00:23:23.960 --> 00:23:28.800]   how we make best use of our, let's say, time,
[00:23:28.800 --> 00:23:31.600]   but also it goes for both.
[00:23:31.600 --> 00:23:33.760]   I mean, time is both for the instructors,
[00:23:33.760 --> 00:23:35.380]   but also for the students, right?
[00:23:35.380 --> 00:23:37.600]   What is like, how do we optimize that?
[00:23:37.600 --> 00:23:41.360]   I mean, always comes back to also having a good time
[00:23:41.360 --> 00:23:42.220]   and experience, right?
[00:23:42.220 --> 00:23:44.440]   So yeah, it'll be interesting to see.
[00:23:44.440 --> 00:23:47.400]   Yeah, so how that develops.
[00:23:47.400 --> 00:23:49.200]   - That was such an amazing analogy
[00:23:49.200 --> 00:23:52.960]   between live theaters and movies at the cinemas.
[00:23:52.960 --> 00:23:55.280]   I feel like with creating content,
[00:23:55.280 --> 00:23:57.160]   it's always like filling this gap.
[00:23:57.160 --> 00:23:58.960]   And sorry to use my example,
[00:23:58.960 --> 00:24:01.880]   but it's like whenever you feel maybe,
[00:24:01.880 --> 00:24:04.120]   I'm assuming for you that there's a certain topic
[00:24:04.120 --> 00:24:05.160]   you'd like to cover,
[00:24:05.160 --> 00:24:07.840]   you might be able to create a lecture around it.
[00:24:07.840 --> 00:24:12.440]   So teasing out, what are your plans for teaching at Great AI?
[00:24:12.440 --> 00:24:14.680]   You'll be the AI lead educator there.
[00:24:14.680 --> 00:24:17.840]   What will you be creating or what can we expect you?
[00:24:17.840 --> 00:24:19.840]   - That's a very good question.
[00:24:19.840 --> 00:24:22.120]   Yeah, so what will I be doing at Great AI?
[00:24:22.120 --> 00:24:25.640]   So I don't want to, let's say, honestly,
[00:24:25.640 --> 00:24:28.520]   this will be, the details are not ironed out yet.
[00:24:28.520 --> 00:24:30.640]   So I can't say too much yet.
[00:24:30.640 --> 00:24:32.840]   So I will be officially starting next month
[00:24:32.840 --> 00:24:34.840]   and there will be more like the time
[00:24:34.840 --> 00:24:38.520]   to also really think and plan the next things.
[00:24:38.520 --> 00:24:39.360]   But I can already tell you,
[00:24:39.360 --> 00:24:42.840]   it will probably somewhere around education
[00:24:42.840 --> 00:24:44.320]   and creating online content
[00:24:44.320 --> 00:24:46.720]   and probably more like on the video side
[00:24:46.720 --> 00:24:49.880]   or course, online course side, rather than writing.
[00:24:49.880 --> 00:24:52.000]   Although I really like writing too.
[00:24:52.000 --> 00:24:55.920]   So we will see how to balance this.
[00:24:55.920 --> 00:24:58.000]   'Cause I think also both have advantages
[00:24:58.000 --> 00:25:00.280]   like written content and video content.
[00:25:00.280 --> 00:25:01.880]   I noticed that myself, for example,
[00:25:01.880 --> 00:25:05.680]   when I was just yesterday learning about Adobe Premiere,
[00:25:05.680 --> 00:25:08.560]   that you can write about these things,
[00:25:08.560 --> 00:25:10.400]   but I really needed to see the settings
[00:25:10.400 --> 00:25:12.480]   because this interface is so complicated.
[00:25:12.480 --> 00:25:14.840]   And when someone told me, okay,
[00:25:14.840 --> 00:25:16.960]   set the noise reduction to so-and-so,
[00:25:16.960 --> 00:25:19.040]   I wanted, I mean, it was so much easier
[00:25:19.040 --> 00:25:20.920]   when someone had a video tutorial on there
[00:25:20.920 --> 00:25:23.560]   and I could see where to click and where to go.
[00:25:23.560 --> 00:25:26.560]   So in that way, also when you show certain concepts
[00:25:26.560 --> 00:25:29.240]   and even math, it's sometimes easier to annotate
[00:25:29.240 --> 00:25:32.000]   and show things than having written content.
[00:25:32.000 --> 00:25:34.560]   But then the advantage of written content is also
[00:25:34.560 --> 00:25:36.840]   that you sometimes can look up things very quickly
[00:25:36.840 --> 00:25:38.920]   and efficiently, like the documentation.
[00:25:38.920 --> 00:25:41.280]   I mean, if you use, for example, Scikit-Learn
[00:25:41.280 --> 00:25:43.520]   and you want to know what a default parameter is,
[00:25:43.520 --> 00:25:44.760]   you wouldn't look for a video
[00:25:44.760 --> 00:25:47.000]   and then scroll to the video
[00:25:47.000 --> 00:25:49.040]   and see where you can find an explanation.
[00:25:49.040 --> 00:25:51.800]   You would just search online, go to the documentation,
[00:25:51.800 --> 00:25:54.480]   Command + F, type in something and find it.
[00:25:54.480 --> 00:25:56.840]   And I feel like the same thing is also
[00:25:56.840 --> 00:25:59.520]   when we develop educational content,
[00:25:59.520 --> 00:26:01.880]   they're both use cases where someone,
[00:26:01.880 --> 00:26:03.640]   if you search, text is more efficient.
[00:26:03.640 --> 00:26:05.960]   If you want to really learn about something,
[00:26:05.960 --> 00:26:08.440]   then video content might be more efficient.
[00:26:08.440 --> 00:26:11.560]   And it might be also interesting to see maybe in the future
[00:26:11.560 --> 00:26:13.880]   how we can use machine learning or deep learning
[00:26:13.880 --> 00:26:15.400]   to better search in videos,
[00:26:15.400 --> 00:26:17.680]   because I think this is not really there yet.
[00:26:17.680 --> 00:26:19.560]   We don't, I mean, there could be an option
[00:26:19.560 --> 00:26:22.400]   where you have the closed captioning of the video,
[00:26:22.400 --> 00:26:25.680]   you search those and find a place
[00:26:25.680 --> 00:26:27.980]   and then you just jump to the video in that section.
[00:26:27.980 --> 00:26:30.200]   But it's, I think it's just something
[00:26:30.200 --> 00:26:33.080]   that is not very widely used yet.
[00:26:33.080 --> 00:26:35.120]   So you can't just search for some text
[00:26:35.120 --> 00:26:36.840]   and then it brings you to the YouTube video
[00:26:36.840 --> 00:26:38.200]   at the timestamp.
[00:26:38.200 --> 00:26:41.920]   So I think in that case, both are still useful.
[00:26:41.920 --> 00:26:43.720]   My focus at GrittyEye will probably be more
[00:26:43.720 --> 00:26:44.920]   on the video content,
[00:26:44.920 --> 00:26:48.640]   but I still think written content
[00:26:48.640 --> 00:26:50.720]   is very useful and important.
[00:26:50.720 --> 00:26:54.560]   Also for me personally, when I do my lectures,
[00:26:54.560 --> 00:26:57.040]   well, in general, I start with writing things
[00:26:57.040 --> 00:27:00.800]   because it's somehow the more,
[00:27:00.800 --> 00:27:03.000]   I would say more complete medium.
[00:27:03.000 --> 00:27:04.560]   So when you make a video,
[00:27:04.560 --> 00:27:06.800]   you don't want to have text everywhere, right?
[00:27:06.800 --> 00:27:10.480]   And personally, when I make lectures or something,
[00:27:10.480 --> 00:27:12.560]   I don't have any lecture,
[00:27:12.560 --> 00:27:14.360]   like subtitles or notes that I read off.
[00:27:14.360 --> 00:27:17.000]   It's just really, I look at the slide,
[00:27:17.000 --> 00:27:20.360]   I have the figure and then I kind of almost spontaneously
[00:27:20.360 --> 00:27:21.400]   talk about it.
[00:27:21.400 --> 00:27:25.720]   But it's not that like I see the slide for the first time.
[00:27:25.720 --> 00:27:28.880]   There was a time where I had some text written for myself
[00:27:28.880 --> 00:27:31.440]   and then based on a text, I was creating these slides.
[00:27:31.440 --> 00:27:34.800]   So the written context for me always comes first.
[00:27:34.800 --> 00:27:37.680]   So I'd create something like very detailed notes
[00:27:37.680 --> 00:27:39.040]   and then I create the slides.
[00:27:39.040 --> 00:27:41.080]   And I think it might be even worthwhile
[00:27:41.080 --> 00:27:43.760]   to also share these written notes in some form,
[00:27:43.760 --> 00:27:45.320]   like a little bit maybe more polished.
[00:27:45.320 --> 00:27:48.000]   So I think the same thing goes for people
[00:27:48.000 --> 00:27:50.360]   when they watch something sometimes like this,
[00:27:50.360 --> 00:27:54.240]   yeah, supporting material might be very useful.
[00:27:54.240 --> 00:27:57.000]   So it will be interesting to think about how to plan this,
[00:27:57.000 --> 00:28:01.920]   how to create value that is also for different running styles
[00:28:01.920 --> 00:28:05.880]   because not everyone likes, let's say, video content.
[00:28:05.880 --> 00:28:08.360]   Some people also prefer the written text
[00:28:08.360 --> 00:28:11.040]   because it can be more efficient sometimes even also.
[00:28:11.040 --> 00:28:16.520]   - I'm honestly looking forward to,
[00:28:16.520 --> 00:28:18.880]   maybe it'll be a course or short videos
[00:28:18.880 --> 00:28:19.720]   or whatever it turns out to be.
[00:28:19.720 --> 00:28:22.120]   I'm looking forward to learning from that.
[00:28:22.120 --> 00:28:23.960]   - Yeah, it will be exciting for sure.
[00:28:24.920 --> 00:28:29.920]   - So will you be missing anything from the academia life
[00:28:29.920 --> 00:28:33.800]   or things that you really enjoy that you-
[00:28:33.800 --> 00:28:35.120]   - Oh, big question.
[00:28:35.120 --> 00:28:39.440]   Yeah, so what I like, I mean, I like academia.
[00:28:39.440 --> 00:28:42.680]   It's like this place where there's like the certain type
[00:28:42.680 --> 00:28:44.000]   of where you can structure your day.
[00:28:44.000 --> 00:28:45.880]   You can come up with your own projects.
[00:28:45.880 --> 00:28:48.040]   You are like very independent in that way.
[00:28:48.040 --> 00:28:51.720]   So what I will miss is, yeah, like we talked about
[00:28:51.720 --> 00:28:53.000]   the interaction with the students
[00:28:53.000 --> 00:28:54.640]   when you explain something
[00:28:54.640 --> 00:28:56.400]   and the students really light up.
[00:28:56.400 --> 00:28:57.960]   They appreciate the explanation.
[00:28:57.960 --> 00:29:00.160]   You feel like you changed someone's, I mean,
[00:29:00.160 --> 00:29:01.600]   not in the lecture itself,
[00:29:01.600 --> 00:29:02.640]   but in the grand scheme of things,
[00:29:02.640 --> 00:29:06.220]   you positively influenced someone's life potentially,
[00:29:06.220 --> 00:29:08.800]   like career and I think I really like that.
[00:29:08.800 --> 00:29:11.680]   It's like you feel like you're helping people out there.
[00:29:11.680 --> 00:29:15.240]   You're helping people on the path
[00:29:15.240 --> 00:29:20.240]   of becoming a successful researcher, scientist or engineer.
[00:29:22.080 --> 00:29:25.240]   And I think I really like that aspect of it.
[00:29:25.240 --> 00:29:27.120]   What I also like, it's a weird thing,
[00:29:27.120 --> 00:29:30.160]   but when I write papers and you have an idea
[00:29:30.160 --> 00:29:33.160]   and you feel like things work and you keep working on it
[00:29:33.160 --> 00:29:36.160]   and you get really into the zone, I kind of like that too.
[00:29:36.160 --> 00:29:38.640]   And especially it's kind of maybe almost
[00:29:38.640 --> 00:29:42.160]   like a little endorphin or something
[00:29:42.160 --> 00:29:44.320]   like where you, when you submit a paper
[00:29:44.320 --> 00:29:46.400]   and let's say it gets accepted,
[00:29:46.400 --> 00:29:47.760]   it's like the best feeling in the world,
[00:29:47.760 --> 00:29:49.560]   basically where you have your paper accepted,
[00:29:49.560 --> 00:29:50.600]   you are super proud.
[00:29:50.600 --> 00:29:52.480]   I kind of really like that too.
[00:29:52.480 --> 00:29:54.720]   The downside of course is also,
[00:29:54.720 --> 00:29:56.040]   sometimes it doesn't get accepted.
[00:29:56.040 --> 00:30:01.000]   And that is, it's like both sides of the coin basically.
[00:30:01.000 --> 00:30:04.800]   There's also that thing, maybe one thing I will not miss
[00:30:04.800 --> 00:30:07.000]   is reviewing papers.
[00:30:07.000 --> 00:30:08.120]   So that is something.
[00:30:08.120 --> 00:30:12.920]   So, I mean, that's maybe the only part I would say
[00:30:12.920 --> 00:30:15.520]   also about teaching that I don't like is grading.
[00:30:15.520 --> 00:30:18.760]   So I like teaching people useful things,
[00:30:18.760 --> 00:30:21.520]   but I don't like necessarily the part
[00:30:21.520 --> 00:30:24.760]   where you have to make a judgment call.
[00:30:24.760 --> 00:30:26.920]   What, I mean, it's not, it's based on scores
[00:30:26.920 --> 00:30:29.480]   and everything, but it's sometimes feels,
[00:30:29.480 --> 00:30:32.800]   it's not fun to give people bad grades
[00:30:32.800 --> 00:30:34.040]   if they don't perform well.
[00:30:34.040 --> 00:30:36.680]   Even if let's say they didn't perform well,
[00:30:36.680 --> 00:30:39.240]   it doesn't, I don't really like that part.
[00:30:39.240 --> 00:30:41.880]   I kind of try to be very generous with grading,
[00:30:41.880 --> 00:30:44.960]   but this part I won't miss, I hope.
[00:30:44.960 --> 00:30:46.760]   So I like teaching.
[00:30:46.880 --> 00:30:50.600]   I like helping people understanding something,
[00:30:50.600 --> 00:30:53.960]   but the evaluation part, it's like one little thing
[00:30:53.960 --> 00:30:58.640]   I would say, I wouldn't miss that part.
[00:30:58.640 --> 00:31:00.600]   Let's say it like that.
[00:31:00.600 --> 00:31:03.800]   - I had the chance to interview Sendex,
[00:31:03.800 --> 00:31:06.600]   someone who I really look up to as much as I look up to you.
[00:31:06.600 --> 00:31:08.520]   And he was mentioning this that,
[00:31:08.520 --> 00:31:11.680]   even though like he has impacted so many lives,
[00:31:11.680 --> 00:31:13.560]   he doesn't get to witness the same
[00:31:13.560 --> 00:31:14.920]   person to person interaction.
[00:31:14.920 --> 00:31:18.960]   And he always underestimates how many people he's affected.
[00:31:18.960 --> 00:31:21.280]   Although like it's, I would assume it's similar,
[00:31:21.280 --> 00:31:23.880]   if not more as in-person lectures,
[00:31:23.880 --> 00:31:26.080]   if you're broadcasting to a large audience.
[00:31:26.080 --> 00:31:31.040]   - Yeah, so it depends on how big the classes are,
[00:31:31.040 --> 00:31:35.280]   but I feel like, yeah, so either way,
[00:31:35.280 --> 00:31:36.400]   you have a positive impact,
[00:31:36.400 --> 00:31:38.200]   whether it's online or in person, right?
[00:31:38.200 --> 00:31:39.400]   So, yeah.
[00:31:39.400 --> 00:31:44.400]   - So, and this question is from the audience as well.
[00:31:44.400 --> 00:31:47.360]   I'll try to loop it into this.
[00:31:47.360 --> 00:31:50.160]   This is by Nikan and they're trying to ask,
[00:31:50.160 --> 00:31:52.520]   what is the best way to communicate
[00:31:52.520 --> 00:31:53.520]   the story of their life?
[00:31:53.520 --> 00:31:56.400]   You mentioned grades aren't the most optimal way.
[00:31:56.400 --> 00:31:58.720]   As someone who's like trying to get into the field
[00:31:58.720 --> 00:32:02.160]   or maybe in academia or maybe in an industry,
[00:32:02.160 --> 00:32:05.800]   what's the best way to communicate your skillsets?
[00:32:05.800 --> 00:32:07.520]   - Oh, that's a good question.
[00:32:07.520 --> 00:32:12.000]   Personally, I honestly don't care so much
[00:32:12.000 --> 00:32:13.480]   about grades really.
[00:32:14.440 --> 00:32:17.920]   I, so when I get emails from students
[00:32:17.920 --> 00:32:19.560]   who would want to work with me,
[00:32:19.560 --> 00:32:23.400]   I honestly don't really look at GPA or grades or something,
[00:32:23.400 --> 00:32:25.280]   'cause I think that is just,
[00:32:25.280 --> 00:32:28.560]   I don't think it's super important.
[00:32:28.560 --> 00:32:32.520]   I do think though, for getting admitted to a program,
[00:32:32.520 --> 00:32:33.680]   it might be important.
[00:32:33.680 --> 00:32:36.400]   It depends on how the program does the admissions.
[00:32:36.400 --> 00:32:40.400]   So I wouldn't tell anyone not to focus on grades
[00:32:40.400 --> 00:32:42.800]   because it might be super important to get admitted
[00:32:42.800 --> 00:32:45.280]   to a, depending on how that system works.
[00:32:45.280 --> 00:32:48.800]   But for me personally, when I, let's say,
[00:32:48.800 --> 00:32:52.320]   if someone sends me their CV or their resume,
[00:32:52.320 --> 00:32:53.440]   I wouldn't look for the GPA.
[00:32:53.440 --> 00:32:56.680]   I would more look for what the person is like,
[00:32:56.680 --> 00:32:58.400]   basically in the email saying about
[00:32:58.400 --> 00:33:00.240]   why they would want to work with me,
[00:33:00.240 --> 00:33:02.440]   like what makes them interested in that?
[00:33:02.440 --> 00:33:05.120]   Is it like just getting papers
[00:33:05.120 --> 00:33:07.640]   or is it really they care about a certain problem?
[00:33:07.640 --> 00:33:09.280]   It's basically, is it a good fit basically?
[00:33:09.280 --> 00:33:11.720]   Is it like, do we have a mutual interest?
[00:33:11.720 --> 00:33:13.320]   Like this type of thing.
[00:33:13.320 --> 00:33:17.920]   And I also value skills, like applied skills,
[00:33:17.920 --> 00:33:19.840]   because my work is very applied.
[00:33:19.840 --> 00:33:23.640]   So I think if someone has worked on some project,
[00:33:23.640 --> 00:33:25.560]   doesn't have to be academic,
[00:33:25.560 --> 00:33:27.640]   just in general, like having some experience,
[00:33:27.640 --> 00:33:29.720]   like where someone worked independently,
[00:33:29.720 --> 00:33:31.120]   I think that's also very important,
[00:33:31.120 --> 00:33:36.120]   because, yeah, so you don't want to have always,
[00:33:36.120 --> 00:33:40.720]   as a student, maybe you want to also be independent.
[00:33:40.720 --> 00:33:43.960]   Because if you think about how life works later,
[00:33:43.960 --> 00:33:46.680]   you don't maybe want to have always someone
[00:33:46.680 --> 00:33:47.520]   telling you what to do.
[00:33:47.520 --> 00:33:50.160]   You want to maybe design your own experiments
[00:33:50.160 --> 00:33:51.560]   and these types of things.
[00:33:51.560 --> 00:33:54.800]   And I think it is important to also have some skills
[00:33:54.800 --> 00:33:56.600]   in that area that you,
[00:33:56.600 --> 00:33:57.960]   I mean, it doesn't have to be successful,
[00:33:57.960 --> 00:34:00.680]   just trying these out, that you have some,
[00:34:00.680 --> 00:34:02.520]   I would say, some independence,
[00:34:02.520 --> 00:34:04.160]   some autonomy or something like that,
[00:34:04.160 --> 00:34:06.480]   where you demonstrate skills.
[00:34:06.480 --> 00:34:09.320]   How to communicate that, that is a good question.
[00:34:09.320 --> 00:34:13.200]   So, yeah, in the email itself,
[00:34:13.200 --> 00:34:14.320]   I would say highlighting that,
[00:34:14.320 --> 00:34:18.200]   because if you send someone like an application
[00:34:18.200 --> 00:34:21.760]   or something, I think before someone opens the attachments,
[00:34:21.760 --> 00:34:23.160]   the CV and the resume,
[00:34:23.160 --> 00:34:24.680]   they wouldn't read the body of the email.
[00:34:24.680 --> 00:34:27.560]   So just highlighting maybe what your interests are
[00:34:27.560 --> 00:34:30.480]   and why you are interested in, let's say,
[00:34:30.480 --> 00:34:33.280]   working with someone might be very important
[00:34:33.280 --> 00:34:35.360]   to, let's say, get your foot into the door
[00:34:35.360 --> 00:34:38.440]   that someone spends, let's say,
[00:34:38.440 --> 00:34:41.080]   the time then to think about whether
[00:34:41.080 --> 00:34:44.800]   they could make it happen to work with someone, essentially.
[00:34:44.800 --> 00:34:46.040]   Yes, also for my classes,
[00:34:46.040 --> 00:34:48.920]   one big focus is to have these class projects.
[00:34:48.920 --> 00:34:50.120]   So we are currently in this phase
[00:34:50.120 --> 00:34:51.120]   at the end of the semester
[00:34:51.120 --> 00:34:53.960]   where the students get to present their class projects.
[00:34:53.960 --> 00:34:57.200]   And so usually it takes a lot of time and work,
[00:34:57.200 --> 00:34:59.320]   but this is what students also really like.
[00:34:59.320 --> 00:35:03.720]   It's like they have a proposal in the mid of the semester
[00:35:03.720 --> 00:35:06.120]   where they tell me what they want to work on.
[00:35:06.120 --> 00:35:07.720]   And then the rest of the semester,
[00:35:07.720 --> 00:35:09.200]   it's almost like two or three months,
[00:35:09.200 --> 00:35:10.320]   they work on their class project.
[00:35:10.320 --> 00:35:12.000]   I give feedback along the way.
[00:35:12.000 --> 00:35:13.640]   So mostly when they have questions,
[00:35:13.640 --> 00:35:14.680]   they come to office hours
[00:35:14.680 --> 00:35:17.720]   and then we come up with some solutions.
[00:35:17.720 --> 00:35:19.560]   And this is also really fun.
[00:35:19.560 --> 00:35:20.400]   But then in the end,
[00:35:20.400 --> 00:35:22.120]   the coolest thing is when they give a presentation
[00:35:22.120 --> 00:35:23.120]   on what they worked on.
[00:35:23.120 --> 00:35:25.800]   It's like a 10 minute approximately presentation.
[00:35:25.800 --> 00:35:26.720]   And they write a report
[00:35:26.720 --> 00:35:29.080]   that is kind of like a conference style paper.
[00:35:29.080 --> 00:35:31.600]   I mean, the reason why it's a conference style paper
[00:35:31.600 --> 00:35:33.480]   is because you have to have a rubric
[00:35:33.480 --> 00:35:35.320]   or like a same, let's say,
[00:35:35.320 --> 00:35:37.200]   restriction for everyone, like an eight page paper,
[00:35:37.200 --> 00:35:41.680]   because otherwise it would be hard to compare projects.
[00:35:41.680 --> 00:35:45.240]   So in that way, I think this is also very valuable.
[00:35:45.240 --> 00:35:47.520]   People said that there were students emailing me
[00:35:47.520 --> 00:35:48.560]   that I got an internship
[00:35:48.560 --> 00:35:51.480]   and they think it was probably because of the class,
[00:35:51.480 --> 00:35:53.500]   they had like a project in that area
[00:35:53.500 --> 00:35:55.360]   that the company was focusing on.
[00:35:55.360 --> 00:35:59.600]   So I think it is kind of like this applied project.
[00:35:59.600 --> 00:36:01.080]   Classwork is super important
[00:36:01.080 --> 00:36:03.120]   because that's where you get your knowledge.
[00:36:03.120 --> 00:36:06.640]   But in that sense, everyone can take classes in that way.
[00:36:06.640 --> 00:36:11.400]   So, and classes is also, it's very important,
[00:36:11.400 --> 00:36:13.400]   it's essential, but it's also very generic.
[00:36:13.400 --> 00:36:16.000]   It's like you learn a general concept.
[00:36:16.000 --> 00:36:18.240]   And usually when you work on something,
[00:36:18.240 --> 00:36:20.160]   you have to be more specialized usually.
[00:36:20.160 --> 00:36:23.120]   So a project is also like a demonstration
[00:36:23.120 --> 00:36:24.520]   like that you are flexible,
[00:36:24.520 --> 00:36:26.660]   you can take knowledge and convert that
[00:36:26.660 --> 00:36:31.000]   into something tangible, some real project basically.
[00:36:31.000 --> 00:36:34.560]   So I think, yeah, having something
[00:36:34.560 --> 00:36:37.240]   that shows your motivation or passion
[00:36:37.240 --> 00:36:38.440]   is very important, I think.
[00:36:38.440 --> 00:36:39.280]   So, yeah.
[00:36:39.280 --> 00:36:42.600]   - I know you've been having the Kaggle community
[00:36:42.600 --> 00:36:45.800]   as well you've shared top Kaggle solutions
[00:36:45.800 --> 00:36:46.680]   with the community.
[00:36:46.680 --> 00:36:49.320]   How much weight is you put on Kaggle experience
[00:36:49.320 --> 00:36:53.960]   if that's in fact in the resume or in the email?
[00:36:53.960 --> 00:36:56.720]   - Yeah, honestly, I personally haven't really
[00:36:56.720 --> 00:36:58.160]   done much Kaggle work.
[00:36:58.160 --> 00:37:01.280]   So what I did is recently though,
[00:37:01.280 --> 00:37:03.820]   so it's maybe a little bit of tangent,
[00:37:03.820 --> 00:37:07.080]   but for my class, I try always to come up
[00:37:07.080 --> 00:37:08.880]   with interesting homework.
[00:37:08.880 --> 00:37:10.480]   And since so much weight, like you said,
[00:37:10.480 --> 00:37:14.160]   is sometimes, so with Kaggle, it's also that thing.
[00:37:14.160 --> 00:37:17.240]   It's really about winning it.
[00:37:17.240 --> 00:37:20.500]   So you try very hard to get the optimal performance,
[00:37:20.500 --> 00:37:23.520]   but it's something, so there's no,
[00:37:23.520 --> 00:37:25.480]   I would say there is no restriction
[00:37:25.480 --> 00:37:27.800]   on how long it takes you to come to the solution.
[00:37:27.800 --> 00:37:29.600]   It's like, time is unlimited.
[00:37:29.600 --> 00:37:31.920]   Okay, the competition runs for so and so many months,
[00:37:31.920 --> 00:37:34.680]   but there's no comparison in terms of
[00:37:34.680 --> 00:37:39.500]   whether someone spends 10 hours or 100 or 1,000 hours.
[00:37:39.500 --> 00:37:41.340]   So it's only the performance, right?
[00:37:41.340 --> 00:37:44.380]   And I think in the real world, this is not feasible.
[00:37:44.380 --> 00:37:46.420]   It's like when you work at a company or something,
[00:37:46.420 --> 00:37:50.640]   or in general, you can't sometimes like spend that much time
[00:37:50.640 --> 00:37:53.140]   it's like to get only 1% more.
[00:37:53.140 --> 00:37:54.420]   I mean, there are some implications
[00:37:54.420 --> 00:37:55.580]   that say you have Google search,
[00:37:55.580 --> 00:37:58.780]   which is a search engine that is used by billions of people,
[00:37:58.780 --> 00:38:01.060]   a percent more accuracy.
[00:38:01.060 --> 00:38:02.680]   And the results makes a huge difference.
[00:38:02.680 --> 00:38:06.520]   So it's maybe time well spent optimizing that.
[00:38:06.520 --> 00:38:08.360]   But in many real world applications
[00:38:08.360 --> 00:38:10.600]   where you have a limited data set,
[00:38:10.600 --> 00:38:12.880]   I'm not sure if that's the best bang for the buck
[00:38:12.880 --> 00:38:16.220]   to just spend exponentially more hours
[00:38:16.220 --> 00:38:17.600]   to get a better result.
[00:38:17.600 --> 00:38:19.840]   So I think what is interesting is also
[00:38:19.840 --> 00:38:21.980]   to not look at the best solution,
[00:38:21.980 --> 00:38:25.480]   but to come up with something that is,
[00:38:25.480 --> 00:38:28.040]   let's say within, I don't know,
[00:38:28.040 --> 00:38:30.440]   5% of the best solution or something like that.
[00:38:31.120 --> 00:38:32.320]   Where I wanted to go with this,
[00:38:32.320 --> 00:38:33.960]   so I was just coming up,
[00:38:33.960 --> 00:38:36.720]   so it was not a Kaggle competition, but for homework,
[00:38:36.720 --> 00:38:40.700]   just wanted to have students also have this experience
[00:38:40.700 --> 00:38:44.240]   of working on an applied problem
[00:38:44.240 --> 00:38:46.480]   and trying to optimize accuracy.
[00:38:46.480 --> 00:38:48.840]   So I think it was the dry bean data set.
[00:38:48.840 --> 00:38:51.600]   It was like a data set that was not too old.
[00:38:51.600 --> 00:38:54.280]   It was on the UCI data set repository.
[00:38:54.280 --> 00:38:56.020]   I wanted to have something where there's no,
[00:38:56.020 --> 00:38:58.320]   let's say not too many solutions on the internet,
[00:38:58.320 --> 00:39:00.760]   something maybe more recent than let's say
[00:39:00.760 --> 00:39:03.160]   the Titanic or the Iris data set.
[00:39:03.160 --> 00:39:06.960]   And then I let, so I showed them different techniques.
[00:39:06.960 --> 00:39:09.160]   First of all, all the gradient boosting algorithms.
[00:39:09.160 --> 00:39:12.640]   So we have covered in class random forests,
[00:39:12.640 --> 00:39:17.160]   decision trees, k-nearest neighbors, gradient boosting.
[00:39:17.160 --> 00:39:21.160]   I went over like XGBoost, CatBoost, LightGBM,
[00:39:21.160 --> 00:39:22.720]   His gradient boosting classifier.
[00:39:22.720 --> 00:39:25.160]   So all the fancy gradient boosting classifiers.
[00:39:25.160 --> 00:39:28.040]   And then also different tuning strategies
[00:39:28.040 --> 00:39:31.320]   like a grid search, randomized search,
[00:39:31.320 --> 00:39:32.400]   the exhaust, what is it?
[00:39:32.400 --> 00:39:36.320]   The having, so successive having and so forth,
[00:39:36.320 --> 00:39:39.160]   Hyperopt and Optuna.
[00:39:39.160 --> 00:39:40.520]   So with Bayesian optimization.
[00:39:40.520 --> 00:39:41.920]   So all these different techniques,
[00:39:41.920 --> 00:39:43.360]   they're all very fancy techniques.
[00:39:43.360 --> 00:39:46.560]   And, but the bottom line,
[00:39:46.560 --> 00:39:48.920]   the lesson I wanted them to teach with this homework
[00:39:48.920 --> 00:39:52.760]   is that simple approaches can also be sufficient
[00:39:52.760 --> 00:39:54.040]   for solving a problem.
[00:39:54.040 --> 00:39:56.760]   Actually, what I did is I tried to get good results myself
[00:39:56.760 --> 00:39:59.960]   and I actually got really good results with random forests.
[00:39:59.960 --> 00:40:02.640]   So I looked, okay, what is the performance
[00:40:02.640 --> 00:40:04.520]   I can get with a random forest?
[00:40:04.520 --> 00:40:08.560]   And I think it was like 92%, 92.5 or something.
[00:40:08.560 --> 00:40:12.240]   So I said, okay, if you get 92% accuracy for the homework,
[00:40:12.240 --> 00:40:13.800]   you get a full points.
[00:40:13.800 --> 00:40:17.440]   You can get better at that, but 92% is the cutoff.
[00:40:17.440 --> 00:40:20.680]   And a lot of students tried really hard
[00:40:20.680 --> 00:40:25.240]   and spent, let's say a lot of time using gradient boosting
[00:40:25.240 --> 00:40:28.880]   and like Optuna and these types of things.
[00:40:28.880 --> 00:40:32.800]   And they got sometimes 92%, sometimes 91%
[00:40:32.800 --> 00:40:36.080]   because using these methods that are really fancy,
[00:40:36.080 --> 00:40:38.360]   very advanced, takes much more work.
[00:40:38.360 --> 00:40:40.240]   It's like, and sometimes they don't always
[00:40:40.240 --> 00:40:41.080]   give you better results.
[00:40:41.080 --> 00:40:44.840]   So you spend a lot of work, let's say getting this 1%,
[00:40:44.840 --> 00:40:46.800]   while sometimes using a simple method,
[00:40:46.800 --> 00:40:48.840]   like a random forest can get you
[00:40:48.840 --> 00:40:50.320]   almost all the way there already.
[00:40:50.320 --> 00:40:53.680]   So the question then is it worthwhile spending my time,
[00:40:53.680 --> 00:40:55.560]   like using all these fancy methods,
[00:40:55.560 --> 00:40:59.040]   whether, or I should just use like something
[00:40:59.040 --> 00:41:02.320]   that is off the shelf, good.
[00:41:02.320 --> 00:41:05.080]   And yeah, also the lesson here was basically
[00:41:05.080 --> 00:41:06.680]   that it's good to have a baseline.
[00:41:06.680 --> 00:41:09.880]   So if you start with a simple method, like a random forest,
[00:41:09.880 --> 00:41:11.160]   you are basically done.
[00:41:11.160 --> 00:41:14.000]   You can solve the homework in five minutes, maybe.
[00:41:14.000 --> 00:41:16.160]   So it's good to always have like a simple baseline
[00:41:16.160 --> 00:41:20.360]   before you start, yeah, trying more complicated things.
[00:41:20.360 --> 00:41:22.200]   And when I remember correctly,
[00:41:22.200 --> 00:41:24.320]   the outcome of the homework was random forest
[00:41:24.320 --> 00:41:26.200]   was definitely not the best method,
[00:41:26.200 --> 00:41:27.640]   but it was also interesting.
[00:41:27.640 --> 00:41:29.000]   I think bagging was the best method,
[00:41:29.000 --> 00:41:31.560]   bagging with a logistic regression classifier.
[00:41:31.560 --> 00:41:35.360]   And I think cat boost, which was also interesting
[00:41:35.360 --> 00:41:37.480]   because it was not a categorical data set.
[00:41:37.480 --> 00:41:41.280]   So sometimes it's hard to know what is really working well.
[00:41:41.280 --> 00:41:43.640]   And it also depends on how much time
[00:41:43.640 --> 00:41:45.760]   you spend on tuning something.
[00:41:45.760 --> 00:41:47.520]   If you want to really get good results,
[00:41:47.520 --> 00:41:51.000]   you also have to expect, like if you want to use
[00:41:51.000 --> 00:41:55.160]   a fancy method to exponentially spend more time on it,
[00:41:55.160 --> 00:41:57.680]   which is sometimes depending on the context,
[00:41:57.680 --> 00:41:58.680]   what you want and not want.
[00:41:58.680 --> 00:42:00.760]   And Kaggle, it gets rewarded in real life.
[00:42:00.760 --> 00:42:01.880]   I'm not so sure.
[00:42:01.880 --> 00:42:02.720]   So, yeah.
[00:42:02.720 --> 00:42:07.000]   - Do you, this is again a question from the email
[00:42:07.000 --> 00:42:08.160]   that I'm pressing a bit,
[00:42:08.160 --> 00:42:12.360]   but what's your own framework like as you,
[00:42:12.360 --> 00:42:15.600]   you obviously experiment a lot with these things.
[00:42:15.600 --> 00:42:17.840]   Last week you had shared what's the best approach
[00:42:17.840 --> 00:42:19.000]   to skimming different papers
[00:42:19.000 --> 00:42:21.960]   and you were also having a discussion on Twitter around it.
[00:42:21.960 --> 00:42:24.240]   How do you optimize your own learning approach
[00:42:24.240 --> 00:42:27.200]   and do you follow certain framework
[00:42:27.200 --> 00:42:29.360]   of learning new things or techniques?
[00:42:29.360 --> 00:42:30.560]   - Yeah, how do I learn?
[00:42:30.560 --> 00:42:31.440]   That's a good question.
[00:42:31.440 --> 00:42:36.440]   So usually what I do is I learn like my topic
[00:42:36.440 --> 00:42:39.360]   where I, there's something I'm really interested in.
[00:42:39.360 --> 00:42:41.360]   And then I really just go on the internet
[00:42:41.360 --> 00:42:42.800]   and search for that topic.
[00:42:42.800 --> 00:42:45.440]   And I bookmark all the different resources I can find
[00:42:45.440 --> 00:42:47.440]   and just keep a list of that.
[00:42:47.440 --> 00:42:48.560]   And then I go through them.
[00:42:48.560 --> 00:42:49.960]   I actually take notes.
[00:42:49.960 --> 00:42:53.160]   So I used to type notes.
[00:42:53.160 --> 00:42:55.920]   Now I'm back to writing them on paper
[00:42:55.920 --> 00:42:58.760]   because that gets me less distracted.
[00:42:58.760 --> 00:43:01.400]   But it was also funny because I was typing so much
[00:43:01.400 --> 00:43:03.520]   that I almost forgot how to write on paper.
[00:43:03.520 --> 00:43:05.520]   It took me like a while to get used to it.
[00:43:05.520 --> 00:43:07.240]   My handwriting was so bad.
[00:43:07.240 --> 00:43:09.320]   But yeah, I write these down.
[00:43:09.320 --> 00:43:11.680]   And then after I've done that,
[00:43:11.680 --> 00:43:15.080]   I just take my notes and then I type them up,
[00:43:15.080 --> 00:43:16.000]   but more structured.
[00:43:16.000 --> 00:43:18.120]   It's like, so people think,
[00:43:18.120 --> 00:43:20.520]   I mean, I'm not sure if that's the best approach,
[00:43:20.520 --> 00:43:21.480]   but people think, okay,
[00:43:21.480 --> 00:43:24.040]   if I start with taking good notes, then I'm done.
[00:43:24.040 --> 00:43:25.880]   I don't have to worry about them.
[00:43:25.880 --> 00:43:28.400]   If I just, let's say, type them up, they are neat.
[00:43:28.400 --> 00:43:29.800]   I don't have to go back to them.
[00:43:29.800 --> 00:43:31.160]   Might be true for meeting notes.
[00:43:31.160 --> 00:43:32.660]   That's maybe more efficient.
[00:43:32.660 --> 00:43:34.400]   But if you want to learn something,
[00:43:34.400 --> 00:43:37.720]   the way you learn is by going over it multiple times,
[00:43:37.720 --> 00:43:40.600]   usually, because usually if you go over it one time,
[00:43:40.600 --> 00:43:42.840]   it's not so much anchored in your memory yet.
[00:43:42.840 --> 00:43:45.600]   So there's actually an advantage in like revisiting
[00:43:45.600 --> 00:43:47.620]   your notes and then organizing them.
[00:43:47.620 --> 00:43:51.480]   And what I also do then is I write them up neatly.
[00:43:51.480 --> 00:43:55.200]   And I have a tool, I mean, I right now use Typeora.
[00:43:55.200 --> 00:43:56.440]   It's like a markdown editor,
[00:43:56.440 --> 00:44:00.700]   but I try to use an editor where I have a table of contents
[00:44:00.700 --> 00:44:02.440]   on the left side, because that helps me,
[00:44:02.440 --> 00:44:03.680]   like coming up with the headlines,
[00:44:03.680 --> 00:44:06.480]   with the theme of what I'm trying to learn there,
[00:44:06.480 --> 00:44:08.480]   like having a big picture view.
[00:44:08.480 --> 00:44:11.320]   And what I'm also doing is I'm creating a mind map,
[00:44:11.320 --> 00:44:15.360]   usually, like, so where I have like the branches
[00:44:15.360 --> 00:44:17.520]   and connections between topics,
[00:44:17.520 --> 00:44:20.100]   I don't do that if it's a very simple topic,
[00:44:20.100 --> 00:44:21.060]   if it's a very short topic,
[00:44:21.060 --> 00:44:23.380]   but if I'm diving more into detail
[00:44:23.380 --> 00:44:24.900]   and I have a lot of material,
[00:44:24.900 --> 00:44:27.460]   I do this approach where I map everything out.
[00:44:27.460 --> 00:44:29.100]   And I actually also do that for my blocks.
[00:44:29.100 --> 00:44:31.060]   When I was writing these,
[00:44:31.060 --> 00:44:33.640]   let's say model evaluation articles,
[00:44:33.640 --> 00:44:34.960]   I was also doing like the mind map
[00:44:34.960 --> 00:44:37.580]   to see how these concepts fit together.
[00:44:37.580 --> 00:44:39.440]   So that helps me a lot.
[00:44:39.440 --> 00:44:40.500]   And while you're doing this,
[00:44:40.500 --> 00:44:44.580]   I think there's no explicit learning where you,
[00:44:44.580 --> 00:44:46.580]   let's say, it's not like an exam or test
[00:44:46.580 --> 00:44:49.460]   that you post yourself or something,
[00:44:49.460 --> 00:44:53.420]   but it's more like the way you structure things,
[00:44:53.420 --> 00:44:56.220]   you kind of get a better understanding, I think,
[00:44:56.220 --> 00:44:58.540]   because that's the thing,
[00:44:58.540 --> 00:45:01.740]   when you think about how do I organize these headlines?
[00:45:01.740 --> 00:45:02.860]   Should it be a subheading
[00:45:02.860 --> 00:45:04.140]   or should it be a separate headline?
[00:45:04.140 --> 00:45:06.340]   That's the part where you really try
[00:45:06.340 --> 00:45:08.260]   to understand things more deeply,
[00:45:08.260 --> 00:45:10.460]   the different aspects of something.
[00:45:10.460 --> 00:45:13.780]   What I do sometimes also is once that's done,
[00:45:13.780 --> 00:45:16.320]   when I have my notes finished taking,
[00:45:16.320 --> 00:45:19.420]   then I usually pick out some particular things
[00:45:19.420 --> 00:45:21.540]   I really want to remember for the future.
[00:45:21.540 --> 00:45:23.500]   So, and then I put into Anki,
[00:45:23.500 --> 00:45:25.900]   which is like a spaced repetition software.
[00:45:25.900 --> 00:45:28.660]   It's like flashcards.
[00:45:28.660 --> 00:45:31.580]   Actually, I have done that for a while.
[00:45:31.580 --> 00:45:33.500]   I remember when I was studying biology
[00:45:33.500 --> 00:45:35.580]   and biology is a lot of memorization.
[00:45:35.580 --> 00:45:38.140]   And that was before I had a smartphone.
[00:45:38.140 --> 00:45:41.620]   It was like 2008 or nine.
[00:45:41.620 --> 00:45:43.180]   I didn't have like a cell phone or smartphone,
[00:45:43.180 --> 00:45:46.160]   but I think I had a cell phone, but a very simple one.
[00:45:46.160 --> 00:45:48.860]   So I was still doing flashcards on pen and paper.
[00:45:48.860 --> 00:45:50.980]   And I usually, I went on walks.
[00:45:50.980 --> 00:45:52.620]   So, 'cause I couldn't,
[00:45:52.620 --> 00:45:54.380]   I found it boring just to sit somewhere.
[00:45:54.380 --> 00:45:56.160]   Like I would get distracted by my computer.
[00:45:56.160 --> 00:45:58.540]   I actually went to the park or in nature
[00:45:58.540 --> 00:45:59.500]   and I had my flashcards.
[00:45:59.500 --> 00:46:01.260]   And people probably thought I was like a crazy person
[00:46:01.260 --> 00:46:03.420]   always going to the flashcards there.
[00:46:03.420 --> 00:46:04.720]   That really helped me learning,
[00:46:04.720 --> 00:46:05.980]   like doing these flashcards.
[00:46:05.980 --> 00:46:08.540]   And it's maybe not necessarily just doing
[00:46:08.540 --> 00:46:09.500]   like the memorization.
[00:46:09.500 --> 00:46:11.740]   It's about creating these flashcards
[00:46:11.740 --> 00:46:14.000]   because you have to come up with a question really.
[00:46:14.000 --> 00:46:17.540]   And thinking about what the question should be,
[00:46:17.540 --> 00:46:20.140]   that is something I think where you also learn.
[00:46:20.140 --> 00:46:21.660]   And yeah, I do that with Anki.
[00:46:21.660 --> 00:46:23.620]   I'm not so good anymore at,
[00:46:23.620 --> 00:46:25.820]   I do it like 10 minutes a day where I review my cards,
[00:46:25.820 --> 00:46:27.540]   but I have more cards right now
[00:46:27.540 --> 00:46:30.380]   than I have time reviewing them.
[00:46:30.380 --> 00:46:31.940]   So I sometimes get a little bit behind.
[00:46:31.940 --> 00:46:35.100]   I have like this counter of like 200 unreviewed cards
[00:46:35.100 --> 00:46:35.940]   or something.
[00:46:35.940 --> 00:46:38.500]   So I have to think about how to maybe
[00:46:38.500 --> 00:46:39.460]   do this more efficiently,
[00:46:39.460 --> 00:46:41.500]   but that's also a good way to learn.
[00:46:41.500 --> 00:46:42.900]   I mean, I'm not running for an exam,
[00:46:42.900 --> 00:46:45.720]   but sometimes I feel like when I learn something
[00:46:45.720 --> 00:46:47.720]   just for myself, I don't want to lose it
[00:46:47.720 --> 00:46:48.640]   because it's so cool.
[00:46:48.640 --> 00:46:49.840]   I want to remember this.
[00:46:49.840 --> 00:46:51.440]   And then I put it in there basically.
[00:46:51.440 --> 00:46:52.280]   So yeah.
[00:46:52.280 --> 00:46:55.560]   Actually, oh, sorry.
[00:46:55.560 --> 00:46:56.600]   - Please go ahead.
[00:46:56.600 --> 00:46:58.680]   - Yeah, so also sometimes I use my,
[00:46:58.680 --> 00:47:00.820]   so I have some, I have different categories.
[00:47:00.820 --> 00:47:03.720]   I have like math, machine learning,
[00:47:03.720 --> 00:47:06.920]   statistics, biology, also computing.
[00:47:06.920 --> 00:47:08.720]   And I have things, weird things like this.
[00:47:08.720 --> 00:47:11.440]   One thing I, for some reason I can't remember this,
[00:47:12.440 --> 00:47:16.980]   how to rename multiple files in the command line in Bash.
[00:47:16.980 --> 00:47:19.700]   And I, once in a while I remember that,
[00:47:19.700 --> 00:47:22.460]   but it's also for myself, it's like a good,
[00:47:22.460 --> 00:47:24.900]   like a lookup resource.
[00:47:24.900 --> 00:47:26.000]   Sometimes I need to do that.
[00:47:26.000 --> 00:47:27.960]   And then I just go to my Anki and search for this,
[00:47:27.960 --> 00:47:30.640]   Bash rename, and then I use that, copy paste it.
[00:47:30.640 --> 00:47:32.860]   And so it's kind of like also a knowledge base
[00:47:32.860 --> 00:47:33.700]   in a way for me.
[00:47:33.700 --> 00:47:37.560]   - I was just going to say to me, it's very inspiring.
[00:47:37.560 --> 00:47:41.320]   I think of myself as a early bit of a (indistinct)
[00:47:41.320 --> 00:47:43.120]   machine learning engineer student.
[00:47:43.120 --> 00:47:45.960]   And even someone at your level is constantly
[00:47:45.960 --> 00:47:48.960]   re-evaluating how to approach materials.
[00:47:48.960 --> 00:47:51.200]   And it's such a nice reminder that,
[00:47:51.200 --> 00:47:53.360]   I would always assume that this is how you learn things.
[00:47:53.360 --> 00:47:55.560]   It's just weird stuff, I'm supposed to remember it.
[00:47:55.560 --> 00:47:59.360]   But now I'm learning, you should be spaced,
[00:47:59.360 --> 00:48:01.240]   repeating things that you should be creating,
[00:48:01.240 --> 00:48:02.200]   flashcards you should be--
[00:48:02.200 --> 00:48:04.160]   - I'm not sure if that's the best approach though,
[00:48:04.160 --> 00:48:06.680]   but yeah, it's what I like doing, yeah.
[00:48:06.680 --> 00:48:10.120]   - I follow the same one, that's why I'm teaching that.
[00:48:10.120 --> 00:48:11.200]   - That's cool, yeah.
[00:48:11.200 --> 00:48:13.840]   - There's a question by Alejandro,
[00:48:13.840 --> 00:48:17.120]   do you have any resources that you prefer
[00:48:17.120 --> 00:48:19.600]   for learning theory, just using audio,
[00:48:19.600 --> 00:48:22.320]   so any podcasts that you listen to and such?
[00:48:22.320 --> 00:48:26.080]   - Any, okay, that's a good point.
[00:48:26.080 --> 00:48:30.960]   So yeah, I honestly don't know any good theory podcast
[00:48:30.960 --> 00:48:33.840]   or audio, it's mostly always like with,
[00:48:33.840 --> 00:48:35.540]   I think it's because it's very hard.
[00:48:35.540 --> 00:48:37.620]   I remember there's this book,
[00:48:38.180 --> 00:48:43.180]   it's on causal inference or causality,
[00:48:43.180 --> 00:48:47.460]   and that's an audio book version of this,
[00:48:47.460 --> 00:48:49.340]   the book of why, I think.
[00:48:49.340 --> 00:48:52.340]   I tried this as an audio book and I had to stop it
[00:48:52.340 --> 00:48:55.460]   because I need this like visualized almost,
[00:48:55.460 --> 00:48:58.220]   at least I have to sit down and write it down
[00:48:58.220 --> 00:49:00.700]   or certain things, because sometimes it's hard
[00:49:00.700 --> 00:49:03.180]   to just do certain things in audio.
[00:49:03.180 --> 00:49:05.500]   And honestly, what I did is I liked
[00:49:05.500 --> 00:49:08.780]   like educational podcasts a lot,
[00:49:08.780 --> 00:49:10.820]   but I don't do this so much anymore
[00:49:10.820 --> 00:49:15.140]   because yeah, it's also important to take breaks
[00:49:15.140 --> 00:49:19.260]   in my opinion, like, because when you work the whole day,
[00:49:19.260 --> 00:49:20.660]   right now, when I listen to podcasts,
[00:49:20.660 --> 00:49:22.180]   it's more like for entertainment,
[00:49:22.180 --> 00:49:24.380]   when I'm, let's say if there's some really long,
[00:49:24.380 --> 00:49:27.240]   boring drive that I do like a podcast for entertainment,
[00:49:27.240 --> 00:49:30.580]   but then also I feel like it helps me being more refreshed
[00:49:30.580 --> 00:49:31.820]   when I'm back at my desk.
[00:49:31.820 --> 00:49:35.780]   So because yeah, doing a podcast,
[00:49:35.780 --> 00:49:37.980]   listening to a more like complicated podcast
[00:49:37.980 --> 00:49:39.100]   while doing something else,
[00:49:39.100 --> 00:49:40.940]   it's really, you have to focus a lot
[00:49:40.940 --> 00:49:44.380]   and then it's so much more effort in that way,
[00:49:44.380 --> 00:49:46.860]   I feel like it's maybe not the best bang for the buck
[00:49:46.860 --> 00:49:47.700]   in that way.
[00:49:47.700 --> 00:49:50.660]   So I try right now, if I have free time,
[00:49:50.660 --> 00:49:53.020]   I try to spend that free time on let's say entertainment
[00:49:53.020 --> 00:49:54.640]   or like relaxing.
[00:49:54.640 --> 00:49:55.980]   And then when I'm back at my desk,
[00:49:55.980 --> 00:49:59.740]   I use the resources that give me the most bang for the buck
[00:49:59.740 --> 00:50:00.700]   in terms of learning.
[00:50:00.700 --> 00:50:02.420]   And that is like usually video and text.
[00:50:02.420 --> 00:50:04.660]   So yeah, I don't have any recommendations
[00:50:04.660 --> 00:50:07.340]   for audio podcasts that are very educational,
[00:50:07.340 --> 00:50:09.620]   but I like interview podcasts actually.
[00:50:09.620 --> 00:50:11.720]   So I usually, because it's something
[00:50:11.720 --> 00:50:14.280]   where you can always learn something new,
[00:50:14.280 --> 00:50:16.340]   but it's not where you have to focus
[00:50:16.340 --> 00:50:20.540]   on like having some visual symbols in your mind
[00:50:20.540 --> 00:50:22.540]   when you think about math or something like that.
[00:50:22.540 --> 00:50:24.820]   So yeah.
[00:50:24.820 --> 00:50:28.100]   - That's a nice reminder that you're trying to optimize
[00:50:28.100 --> 00:50:30.660]   for a lot of learning for your time,
[00:50:30.660 --> 00:50:31.500]   something like that.
[00:50:31.500 --> 00:50:34.580]   And you should always be focusing in that direction.
[00:50:34.580 --> 00:50:35.780]   - Yeah, yeah.
[00:50:35.780 --> 00:50:37.860]   Yeah, I think it's also important to keep in mind
[00:50:37.860 --> 00:50:40.940]   that the brain is like a muscle in that way.
[00:50:40.940 --> 00:50:44.140]   You have to also have some breaks in that way.
[00:50:44.140 --> 00:50:47.780]   So it's like the more, sometimes it feels okay,
[00:50:47.780 --> 00:50:52.220]   maybe I could use my time better by learning all the time,
[00:50:52.220 --> 00:50:54.480]   but I feel like over time you get tired
[00:50:54.480 --> 00:50:56.840]   and then when you learn, you don't learn as efficiently,
[00:50:56.840 --> 00:50:57.760]   I feel like, I don't know.
[00:50:57.760 --> 00:51:01.220]   But it's just like, yeah, my opinion.
[00:51:01.220 --> 00:51:02.620]   Maybe I'm just getting old.
[00:51:02.620 --> 00:51:03.460]   (laughs)
[00:51:03.460 --> 00:51:04.300]   Yeah.
[00:51:04.300 --> 00:51:07.300]   - I'm in the same boat as it.
[00:51:07.300 --> 00:51:09.420]   Okay, so the next question will be in random order
[00:51:09.420 --> 00:51:11.820]   since these are from Yim and I want to mix them.
[00:51:11.820 --> 00:51:16.420]   If you were a biologist who self-learned machine learning,
[00:51:16.420 --> 00:51:19.340]   which direction and topics would you focus on today
[00:51:19.340 --> 00:51:21.940]   for the best opportunity career-wise?
[00:51:21.940 --> 00:51:25.620]   Any data sets you'd work on to build a good profile?
[00:51:25.840 --> 00:51:28.520]   (indistinct)
[00:51:28.520 --> 00:51:31.960]   - Okay, so that's a good question for, I think,
[00:51:31.960 --> 00:51:35.140]   yeah, so I feel like in biology,
[00:51:35.140 --> 00:51:38.440]   I don't know any general data sets in that way.
[00:51:38.440 --> 00:51:41.360]   Biology is also a very big field.
[00:51:41.360 --> 00:51:45.540]   So there are, for example, there's the CASP competition
[00:51:45.540 --> 00:51:49.880]   where people get, let's say a protein structure
[00:51:49.880 --> 00:51:52.760]   that they have to refine or they predict a structure
[00:51:52.760 --> 00:51:53.960]   from a sequence, for example,
[00:51:53.960 --> 00:51:56.860]   that is where Alpha Fold was also participating.
[00:51:56.860 --> 00:51:58.420]   That would be like something like Kaggle,
[00:51:58.420 --> 00:52:01.300]   but for biologists, but again, this is very specialized.
[00:52:01.300 --> 00:52:03.860]   So this would be for structural biology.
[00:52:03.860 --> 00:52:06.980]   So, and biology, I mean, there are so many different fields
[00:52:06.980 --> 00:52:10.300]   from neurobiology, structural biology,
[00:52:10.300 --> 00:52:13.620]   genomics, drug discovery.
[00:52:13.620 --> 00:52:15.180]   There are so many subfields.
[00:52:15.180 --> 00:52:17.080]   Every subfield has its own data set.
[00:52:17.080 --> 00:52:19.620]   So right now we are working on, let's say,
[00:52:19.620 --> 00:52:21.300]   the more like not drug discovery,
[00:52:21.300 --> 00:52:23.580]   but more like molecular screening.
[00:52:23.580 --> 00:52:25.480]   So drug discovery is very specific,
[00:52:25.480 --> 00:52:28.680]   but sometimes you just want to find a bioactive ligand.
[00:52:28.680 --> 00:52:31.120]   And there are also benchmark data sets.
[00:52:31.120 --> 00:52:34.920]   So you can usually find benchmark data sets in all areas.
[00:52:34.920 --> 00:52:37.520]   I don't know that much about genomics, I must say.
[00:52:37.520 --> 00:52:40.600]   I'm more like familiar with structural biology
[00:52:40.600 --> 00:52:44.980]   and small molecules, but then neurobiology,
[00:52:44.980 --> 00:52:47.880]   they have a lot of data too, like the whole MRI scan.
[00:52:47.880 --> 00:52:52.240]   So I would say if you are a biologist,
[00:52:52.240 --> 00:52:53.560]   or if you're interested in biology,
[00:52:53.560 --> 00:52:56.920]   there's also the thing that you really have to focus
[00:52:56.920 --> 00:52:59.480]   on a sub area because you can't do all of these things.
[00:52:59.480 --> 00:53:01.760]   Really, it's like the same with machine learning.
[00:53:01.760 --> 00:53:05.600]   I try to keep up with natural language processing,
[00:53:05.600 --> 00:53:08.840]   but I would say more like a computer vision person.
[00:53:08.840 --> 00:53:11.200]   Although I'm also, again, more general,
[00:53:11.200 --> 00:53:14.600]   I learn a little bit here and there, things like that.
[00:53:14.600 --> 00:53:17.960]   So it's kind of important to have a broad perspective
[00:53:17.960 --> 00:53:21.340]   on different fields, but then if you really want
[00:53:21.340 --> 00:53:23.840]   to do research, you have to hone in onto one of them
[00:53:23.840 --> 00:53:26.240]   because otherwise, yeah, you only scratch
[00:53:26.240 --> 00:53:27.400]   the surface essentially.
[00:53:27.400 --> 00:53:32.400]   So I can't make a general recommendation for biology,
[00:53:32.400 --> 00:53:35.280]   but for structural biology, there is, for example,
[00:53:35.280 --> 00:53:38.940]   the CASP data competitions to look at.
[00:53:38.940 --> 00:53:40.840]   And for small molecule discovery,
[00:53:40.840 --> 00:53:44.160]   there are also lots of small, not small,
[00:53:44.160 --> 00:53:46.440]   they are actually very big data sets to work on.
[00:53:46.440 --> 00:53:49.280]   Currently, most of my projects are very specific
[00:53:49.280 --> 00:53:52.220]   where I have collaborators that have a certain data set
[00:53:52.220 --> 00:53:53.120]   that I work with.
[00:53:53.120 --> 00:53:56.180]   - Thank you for that.
[00:53:56.180 --> 00:53:58.220]   Adi Andro is asking this,
[00:53:58.220 --> 00:54:00.740]   since you mentioned this, I'll loop it in.
[00:54:00.740 --> 00:54:03.380]   There's so many topics to learn at a personal level.
[00:54:03.380 --> 00:54:05.980]   Also, do you ever get formal fear of missing out?
[00:54:05.980 --> 00:54:09.420]   How do you deal with that?
[00:54:09.420 --> 00:54:10.940]   - Oh, that's a very tough one.
[00:54:10.940 --> 00:54:14.180]   I have a fear of missing out a lot, actually.
[00:54:14.180 --> 00:54:16.700]   I don't have like a cure for that,
[00:54:16.700 --> 00:54:19.260]   but what helps me is just to write these at least down.
[00:54:19.260 --> 00:54:22.640]   So it's always like I read also, yeah,
[00:54:22.640 --> 00:54:24.260]   news and newsletters around machine learning
[00:54:24.260 --> 00:54:27.300]   and deep learning, and there's always so much more stuff
[00:54:27.300 --> 00:54:29.580]   out there than I could possibly read.
[00:54:29.580 --> 00:54:30.940]   I just take notes.
[00:54:30.940 --> 00:54:35.460]   So I have files where I have topics, different topics.
[00:54:35.460 --> 00:54:38.500]   For example, topic is transformer,
[00:54:38.500 --> 00:54:40.860]   and then I have subcategories of visual transformers
[00:54:40.860 --> 00:54:44.020]   and language transformers and transformers
[00:54:44.020 --> 00:54:45.340]   for tabular data sets.
[00:54:45.340 --> 00:54:49.020]   And then if I find a paper or something new or news
[00:54:49.020 --> 00:54:51.780]   that falls into that category, I put that there.
[00:54:51.780 --> 00:54:55.820]   And I have a checkbox, and I'm hoping to read that one day.
[00:54:55.820 --> 00:54:59.340]   But what I do is I also have a weekly to-do list.
[00:54:59.340 --> 00:55:02.140]   So every Sunday, so it will be later today,
[00:55:02.140 --> 00:55:04.900]   I sit down and plan what I have to do for the week.
[00:55:04.900 --> 00:55:09.620]   And in there are two research papers and one video.
[00:55:09.620 --> 00:55:13.220]   It's mostly a conference video or conference talk.
[00:55:13.220 --> 00:55:15.420]   Sometimes I don't get to even read the two papers
[00:55:15.420 --> 00:55:16.580]   because there are too many other things,
[00:55:16.580 --> 00:55:18.460]   but I aim for reading two papers.
[00:55:18.460 --> 00:55:23.460]   So I'm trying to aim for having at least some consistency
[00:55:23.460 --> 00:55:29.740]   and not always, if you find something interesting,
[00:55:29.740 --> 00:55:31.780]   not getting distracted from your current task
[00:55:31.780 --> 00:55:32.620]   and jump to that one.
[00:55:32.620 --> 00:55:35.500]   Because yeah, that is, so I try to be disciplined.
[00:55:35.500 --> 00:55:39.080]   Okay, this is what I planned to read this week.
[00:55:39.080 --> 00:55:41.700]   And I have a list of things I want to read in the future.
[00:55:41.700 --> 00:55:43.620]   And if I see something interesting on the internet,
[00:55:43.620 --> 00:55:44.700]   I put that in there.
[00:55:44.700 --> 00:55:46.420]   And then each Sunday I would write,
[00:55:46.420 --> 00:55:48.700]   okay, should I read this new one I read
[00:55:48.700 --> 00:55:50.900]   or something I had bookmarked before?
[00:55:50.900 --> 00:55:52.420]   And then you have to make a decision
[00:55:52.420 --> 00:55:54.900]   which one is currently the most important one.
[00:55:54.900 --> 00:55:56.740]   And sometimes you will find,
[00:55:56.740 --> 00:55:59.100]   you have all these cool things that you see on the internet
[00:55:59.100 --> 00:56:00.060]   and you keep a list of them,
[00:56:00.060 --> 00:56:01.620]   but then like one or two weeks later,
[00:56:01.620 --> 00:56:03.180]   hmm, okay, that was actually cool,
[00:56:03.180 --> 00:56:04.220]   but it was not that cool.
[00:56:04.220 --> 00:56:05.900]   So actually, yeah.
[00:56:05.900 --> 00:56:07.700]   So just putting that down
[00:56:07.700 --> 00:56:10.140]   and then not immediately jumping to it,
[00:56:10.140 --> 00:56:13.220]   but just maybe thinking about revisiting it later
[00:56:13.220 --> 00:56:15.780]   might be something to kind of like at least curb
[00:56:15.780 --> 00:56:17.080]   the fear of missing out a little bit.
[00:56:17.080 --> 00:56:20.220]   But it is tricky because there are so many things out there
[00:56:20.220 --> 00:56:23.060]   that are exciting and you can't do everything really.
[00:56:23.060 --> 00:56:23.900]   Yeah.
[00:56:23.900 --> 00:56:24.900]   - That's fascinating to know.
[00:56:24.900 --> 00:56:26.780]   Sebastian, I love your opinion on this.
[00:56:26.780 --> 00:56:29.340]   I know you mentioned you shouldn't try to read all papers.
[00:56:29.340 --> 00:56:32.380]   As someone like me who's early in their career,
[00:56:32.380 --> 00:56:35.780]   I feel like for me, I try to read the impactful papers.
[00:56:35.780 --> 00:56:39.220]   So I'm reading sometimes more than one paper a day
[00:56:39.220 --> 00:56:42.220]   just because these are these classic papers.
[00:56:42.220 --> 00:56:45.300]   Moscow CNN was on my desk today.
[00:56:45.300 --> 00:56:47.460]   FCN was there on my desk.
[00:56:47.460 --> 00:56:48.860]   Do you think this is the right approach
[00:56:48.860 --> 00:56:51.020]   for at least the classical papers
[00:56:51.020 --> 00:56:52.260]   if you're trying to read more of them
[00:56:52.260 --> 00:56:55.140]   just to establish your understanding?
[00:56:55.140 --> 00:56:55.980]   - Yeah, that's a good point.
[00:56:55.980 --> 00:56:58.140]   And I also wanted to say,
[00:56:58.140 --> 00:57:01.200]   I read, let's say more than two papers a week,
[00:57:01.200 --> 00:57:04.260]   but with reading, I meant really like reading them in detail.
[00:57:04.260 --> 00:57:07.460]   So like most papers, I just skim to be honest.
[00:57:07.460 --> 00:57:10.740]   I have maybe like five papers a week that I skim.
[00:57:10.740 --> 00:57:12.340]   I think it's a good point.
[00:57:12.340 --> 00:57:13.180]   There are-
[00:57:13.180 --> 00:57:15.820]   - Sorry, I meant it in the same sense
[00:57:15.820 --> 00:57:17.380]   as someone who's just starting out,
[00:57:17.380 --> 00:57:19.780]   I feel they should be reading more just to capture.
[00:57:19.780 --> 00:57:21.220]   And once they have the understanding,
[00:57:21.220 --> 00:57:24.620]   then they can really understand one or two papers a week
[00:57:24.620 --> 00:57:26.500]   once they have a good understanding.
[00:57:26.500 --> 00:57:27.980]   Do you agree with that?
[00:57:27.980 --> 00:57:30.860]   - Yeah, no, I totally agree with that because papers,
[00:57:30.860 --> 00:57:35.420]   yeah, this goes back to the question
[00:57:35.420 --> 00:57:36.900]   why you read the paper, right?
[00:57:36.900 --> 00:57:40.940]   So, and this is also why I don't have
[00:57:40.940 --> 00:57:43.200]   like a reference manager for papers
[00:57:43.200 --> 00:57:46.460]   where I take notes about that paper.
[00:57:46.460 --> 00:57:49.580]   I have more like something where I have projects
[00:57:49.580 --> 00:57:52.600]   and then for each project, I take notes about that paper.
[00:57:52.600 --> 00:57:55.560]   'Cause sometimes I read the same paper multiple times
[00:57:55.560 --> 00:57:56.780]   for different purposes.
[00:57:56.780 --> 00:58:00.780]   And I think that goes kind of what you said is
[00:58:00.780 --> 00:58:01.780]   when you read the paper,
[00:58:01.780 --> 00:58:03.880]   so depends on what you're interested in.
[00:58:03.880 --> 00:58:05.580]   Are you interested in the hyperparameters?
[00:58:05.580 --> 00:58:07.380]   Maybe then you read the section differently
[00:58:07.380 --> 00:58:10.380]   compared to a math part or something like that,
[00:58:10.380 --> 00:58:11.960]   or the related work part.
[00:58:11.960 --> 00:58:13.780]   Sometimes I honestly just read a paper
[00:58:13.780 --> 00:58:15.500]   because I want to know the related work.
[00:58:15.500 --> 00:58:17.180]   And then I follow up with the related work.
[00:58:17.180 --> 00:58:19.260]   I don't so much care about the method itself.
[00:58:19.260 --> 00:58:20.940]   So sometimes you just have a good introduction
[00:58:20.940 --> 00:58:22.220]   or related work section.
[00:58:22.220 --> 00:58:25.340]   And yeah, here it really depends.
[00:58:25.340 --> 00:58:29.340]   I think it makes sense to read a lot of papers,
[00:58:29.340 --> 00:58:32.260]   but I think it doesn't make so much sense
[00:58:32.260 --> 00:58:34.820]   to read a lot of papers in detail.
[00:58:34.820 --> 00:58:37.580]   So skimming a lot of papers makes a lot of sense
[00:58:37.580 --> 00:58:39.300]   and focusing on certain sections.
[00:58:39.300 --> 00:58:42.980]   But also if you think about a topic
[00:58:42.980 --> 00:58:44.460]   you are already familiar with,
[00:58:44.460 --> 00:58:46.680]   it doesn't make so much sense
[00:58:46.680 --> 00:58:49.180]   to read the complete papers in detail
[00:58:49.180 --> 00:58:51.740]   because the introduction is kind of like similar
[00:58:51.740 --> 00:58:52.880]   every time, every paper.
[00:58:52.880 --> 00:58:54.500]   It's just something necessary
[00:58:54.500 --> 00:58:56.060]   that the authors have to provide,
[00:58:56.060 --> 00:58:58.340]   but then it would be kind of not very efficient
[00:58:58.340 --> 00:59:00.500]   to read every introduction in detail.
[00:59:00.500 --> 00:59:02.820]   So you can jump to the most interesting parts.
[00:59:02.820 --> 00:59:05.620]   So in that way, yeah, being a little bit,
[00:59:05.620 --> 00:59:07.260]   I would say time efficient with papers
[00:59:07.260 --> 00:59:09.460]   is also I think important.
[00:59:09.460 --> 00:59:11.580]   But yeah, sometimes also there's no,
[00:59:11.580 --> 00:59:12.940]   I would say a rule of thumb,
[00:59:12.940 --> 00:59:13.900]   how long it should take,
[00:59:13.900 --> 00:59:16.220]   because it really depends on why you read the paper.
[00:59:16.220 --> 00:59:17.980]   If you do a review, you have to spend
[00:59:17.980 --> 00:59:19.220]   maybe three or four hours.
[00:59:19.220 --> 00:59:21.140]   If you only care about, okay,
[00:59:21.140 --> 00:59:22.420]   how did they tune the hyperparameters?
[00:59:22.420 --> 00:59:25.680]   Is there like a learning rate schedule I find useful?
[00:59:25.680 --> 00:59:28.600]   You read that, it can be five minutes, right?
[00:59:28.600 --> 00:59:31.420]   Yeah, so it doesn't make sense
[00:59:31.420 --> 00:59:34.220]   if you only want to know about the learning rate schedule
[00:59:34.220 --> 00:59:36.620]   in the paper they use to read all about
[00:59:36.620 --> 00:59:39.580]   the related work or something like that.
[00:59:39.580 --> 00:59:43.340]   So yeah, there's I think a trade-off
[00:59:43.340 --> 00:59:45.260]   between what you want to get out of this paper,
[00:59:45.260 --> 00:59:46.660]   but also learning something useful.
[00:59:46.660 --> 00:59:49.140]   I think that's a tricky, tricky question.
[00:59:49.140 --> 00:59:50.740]   I wish I could read more papers,
[00:59:50.740 --> 00:59:52.700]   but then you also have to always think about,
[00:59:52.700 --> 00:59:54.420]   okay, instead of reading the paper,
[00:59:54.420 --> 00:59:55.820]   you could also read a textbook,
[00:59:55.820 --> 00:59:57.380]   which has more information,
[00:59:57.380 --> 00:59:59.740]   which is more dense about certain things.
[00:59:59.740 --> 01:00:03.100]   So of course, in an ideal world, I would do everything,
[01:00:03.100 --> 01:00:05.820]   but it's always like trading off things also.
[01:00:05.820 --> 01:00:08.860]   - That's great advice.
[01:00:08.860 --> 01:00:11.060]   Sebastian, is it okay to squeeze in another question?
[01:00:11.060 --> 01:00:11.900]   I know we're out of time.
[01:00:11.900 --> 01:00:13.260]   - Sure, we can do one more.
[01:00:13.260 --> 01:00:17.420]   - So this is by Brian Bishop, who's from Bates & Bises.
[01:00:17.420 --> 01:00:21.580]   What machine learning topic doesn't get enough attention
[01:00:21.580 --> 01:00:24.020]   that students should absolutely know?
[01:00:24.020 --> 01:00:27.020]   So any underrated topic, students?
[01:00:27.020 --> 01:00:30.340]   - I would say nowadays there's a lot of hype
[01:00:30.340 --> 01:00:34.660]   around deep learning, which is reasonable,
[01:00:34.660 --> 01:00:36.420]   which is totally justified.
[01:00:36.420 --> 01:00:38.940]   But then at the expense of deep learning,
[01:00:38.940 --> 01:00:42.820]   we sometimes forget the traditional methods.
[01:00:42.820 --> 01:00:45.300]   So maybe not necessarily something like,
[01:00:45.300 --> 01:00:47.020]   I mean, Naive Bayes and SVMs
[01:00:47.020 --> 01:00:49.700]   are also very important fundamentals,
[01:00:49.700 --> 01:00:51.940]   but I think gradient boosting.
[01:00:51.940 --> 01:00:55.740]   Honestly, I have even colleagues,
[01:00:55.740 --> 01:00:58.500]   let's say who are not super familiar with gradient boosting
[01:00:58.500 --> 01:01:01.900]   because it's somewhere in between like traditional methods
[01:01:01.900 --> 01:01:04.220]   and deep learning, not in terms of how they work,
[01:01:04.220 --> 01:01:05.420]   but the timeline.
[01:01:05.420 --> 01:01:08.260]   So SVMs were like super popular in the '90s.
[01:01:08.260 --> 01:01:10.140]   Everyone knows about them in some way.
[01:01:10.140 --> 01:01:12.900]   And a lot of classes teach you these types of things.
[01:01:12.900 --> 01:01:14.260]   And then there are classes that teach you
[01:01:14.260 --> 01:01:15.580]   about neural networks and deep learning.
[01:01:15.580 --> 01:01:19.180]   But I think when I looked at syllabi,
[01:01:19.180 --> 01:01:21.220]   a lot of people don't talk about gradient boosting.
[01:01:21.220 --> 01:01:25.100]   And I think this is something important to teach,
[01:01:25.100 --> 01:01:26.260]   I feel like.
[01:01:26.260 --> 01:01:29.620]   So I feel like this is an underappreciated technique
[01:01:29.620 --> 01:01:30.580]   in a sense.
[01:01:30.580 --> 01:01:31.860]   Might not be true everywhere.
[01:01:31.860 --> 01:01:35.460]   I think, I mean, your mileage may vary,
[01:01:35.460 --> 01:01:38.260]   but I feel like this is like a thing
[01:01:38.260 --> 01:01:41.540]   in your tool bag to know about, if that makes sense.
[01:01:41.540 --> 01:01:43.620]   - Awesome.
[01:01:43.620 --> 01:01:45.060]   On that note, I'll try to wrap up
[01:01:45.060 --> 01:01:47.500]   and I'll remind the audience that Sebastian,
[01:01:47.500 --> 01:01:49.180]   as you mentioned, in the fourth,
[01:01:49.180 --> 01:01:51.100]   not the fourth edition of,
[01:01:51.100 --> 01:01:53.300]   in the newer edition of this book,
[01:01:53.300 --> 01:01:54.620]   he'll be covering these topics.
[01:01:54.620 --> 01:01:56.300]   So keep an eye out for that.
[01:01:56.300 --> 01:01:59.660]   I'm guessing in the first part of next year,
[01:01:59.660 --> 01:02:01.660]   we should be able to do it with that.
[01:02:01.660 --> 01:02:03.860]   And let me quickly share my screen
[01:02:03.860 --> 01:02:06.340]   and remind the audience to follow Sebastian on Twitter.
[01:02:06.340 --> 01:02:08.900]   He is @RASBT.
[01:02:08.900 --> 01:02:11.100]   That is again @RASBT.
[01:02:11.100 --> 01:02:12.860]   That's his handle on Twitter.
[01:02:12.860 --> 01:02:15.100]   I always learn a lot just based on the resources
[01:02:15.100 --> 01:02:16.540]   he shares there.
[01:02:16.540 --> 01:02:18.820]   You can also hop over to his website from there
[01:02:18.820 --> 01:02:22.740]   and find his courses on YouTube.
[01:02:22.740 --> 01:02:25.980]   They're incredibly education-packed
[01:02:25.980 --> 01:02:27.820]   and really high quality.
[01:02:27.820 --> 01:02:30.260]   Any other platform you want to mention?
[01:02:30.260 --> 01:02:33.580]   - I don't have anything else in mind,
[01:02:33.580 --> 01:02:34.420]   but thank you so much.
[01:02:34.420 --> 01:02:35.460]   I wanted to just say something
[01:02:35.460 --> 01:02:36.580]   about my Twitter handle actually,
[01:02:36.580 --> 01:02:38.260]   because there wasn't a question,
[01:02:38.260 --> 01:02:40.860]   but I think just want to talk about it.
[01:02:40.860 --> 01:02:44.220]   So it's short for RASCHKA Sebastian.
[01:02:44.220 --> 01:02:46.020]   And I spent a lot of time back then
[01:02:46.020 --> 01:02:47.380]   coming up with a handle.
[01:02:47.380 --> 01:02:51.140]   So R-A for RASCHKA and S-B-T for Sebastian,
[01:02:51.140 --> 01:02:53.020]   because that was like long time ago
[01:02:53.020 --> 01:02:56.900]   when Twitter had a 140 character limit
[01:02:56.900 --> 01:02:59.540]   and a short handle was very precious.
[01:02:59.540 --> 01:03:02.060]   So I really tried very hard to come up
[01:03:02.060 --> 01:03:03.900]   with something as short as possible.
[01:03:03.900 --> 01:03:06.820]   Now it's a little bit awkward maybe to remember R-A-S-B-T,
[01:03:06.820 --> 01:03:08.140]   but yeah, that's where it's coming from
[01:03:08.140 --> 01:03:11.940]   because back then characters were very precious on Twitter.
[01:03:11.940 --> 01:03:15.380]   So nowadays I wish I had maybe a more longer Twitter handle
[01:03:15.380 --> 01:03:18.780]   that is let's say more like easy to remember or something,
[01:03:18.780 --> 01:03:20.260]   but yeah.
[01:03:20.260 --> 01:03:22.500]   So thanks so much for the invitation.
[01:03:22.500 --> 01:03:25.300]   Yeah, thanks so much for also talking about my book
[01:03:25.300 --> 01:03:29.980]   and yeah, that was like a fun hour to spend here.
[01:03:29.980 --> 01:03:30.820]   I really enjoyed it.
[01:03:30.820 --> 01:03:32.020]   - Thanks for your time.
[01:03:32.020 --> 01:03:34.220]   It was an honor to have you on the podcast earlier
[01:03:34.220 --> 01:03:37.020]   and again an honor to learn from you live this time
[01:03:37.020 --> 01:03:38.380]   and also have the audience with it.
[01:03:38.380 --> 01:03:40.700]   So thanks so much to you for your time.
[01:03:40.700 --> 01:03:43.340]   - Yeah, thank you and have a good rest of the day then.
[01:03:43.340 --> 01:03:46.300]   - And so I will end the live stream here.
[01:03:46.300 --> 01:03:48.380]   Thanks everybody for joining.
[01:03:48.380 --> 01:03:50.420]   - Yeah, thanks everyone for the questions.

