
[00:00:00.000 --> 00:00:07.300]   OK, hi everybody, thanks for joining.
[00:00:07.300 --> 00:00:14.820]   This is an entirely optional presentation, which I'll call a Lesson 0, which is all about
[00:00:14.820 --> 00:00:18.220]   how to fast AI.
[00:00:18.220 --> 00:00:24.640]   It's all about how to get the most out of this course, how to make sure you finish it,
[00:00:24.640 --> 00:00:31.800]   and how to make sure you feel like it's been a productive time.
[00:00:31.800 --> 00:00:38.780]   And the reason I'm doing this is because a lot of people who take the course, when they
[00:00:38.780 --> 00:00:42.600]   get to the end of it, they say to me, "Oh, it wasn't until I got to the end of the course
[00:00:42.600 --> 00:00:45.240]   that I realized how I should have done the whole course, and now I'm going to go back
[00:00:45.240 --> 00:00:48.080]   and redo the whole thing over again."
[00:00:48.080 --> 00:00:54.040]   And so I'm going to tell you about what the messages I've heard are about what people
[00:00:54.040 --> 00:00:59.160]   have found the best approaches to making the course work.
[00:00:59.160 --> 00:01:07.200]   I'm also going to go through the actual mechanics of how to get set up with two systems, Google
[00:01:07.200 --> 00:01:14.880]   Colab and AWS EC2, and I'll talk about why you might use one versus the other.
[00:01:14.880 --> 00:01:20.600]   So a lot of people now, as in many hundreds of thousands, have gone through the fast AI
[00:01:20.600 --> 00:01:26.680]   practical deep learning for coders course, and many, many, many of them have gone on
[00:01:26.680 --> 00:01:35.400]   to create successful startups, to write research papers with high impact factors, to create
[00:01:35.400 --> 00:01:38.080]   new products at their companies.
[00:01:38.080 --> 00:01:44.240]   It's a pretty well proven course at this time, but there's also a lot of people that never
[00:01:44.240 --> 00:01:46.680]   finish the course.
[00:01:46.680 --> 00:01:53.440]   And so if you're watching this, it's because you've decided you do want to learn deep learning,
[00:01:53.440 --> 00:01:57.120]   so I'm going to talk a bit about like what's it going to take for you to be one of the
[00:01:57.120 --> 00:01:59.960]   people that makes this into a great experience.
[00:01:59.960 --> 00:02:05.360]   When I talk about the course, I'm also talking about the book.
[00:02:05.360 --> 00:02:11.920]   So just to be clear, there's a book that Sylvain Goudre and I wrote, which you can either
[00:02:11.920 --> 00:02:19.120]   buy from Amazon, and people like it happily, or believe it or not, you can read the whole
[00:02:19.120 --> 00:02:21.420]   thing for free.
[00:02:21.420 --> 00:02:25.000]   So it's called Fastbook, it's a fastbook repo.
[00:02:25.000 --> 00:02:30.320]   Honestly, I make basically nothing from the book, so I don't feel like you need to buy
[00:02:30.320 --> 00:02:33.800]   it to say thank you or something, buy it if you want the book.
[00:02:33.800 --> 00:02:39.800]   If you're happy using notebooks, use the free one, it's all good.
[00:02:39.800 --> 00:02:44.360]   So the book was actually written as Jupyter notebooks, and we wrote something to turn
[00:02:44.360 --> 00:02:46.000]   it into a book book.
[00:02:46.000 --> 00:02:50.280]   Now the book will also, by the way, actually looks great on Kindle, online, as well as
[00:02:50.280 --> 00:02:51.280]   paper.
[00:02:51.280 --> 00:02:57.400]   I know often technical books don't, this one actually does.
[00:02:57.400 --> 00:03:02.440]   And then the course goes through half of the book.
[00:03:02.440 --> 00:03:06.840]   And so quite soon we'll do a part two, which will go through the other half of the book
[00:03:06.840 --> 00:03:09.640]   plus some other new stuff.
[00:03:09.640 --> 00:03:14.980]   But basically each lesson covers a chapter or so of the book.
[00:03:14.980 --> 00:03:19.100]   So if you're doing this course, you'll be going through the book, at least in the notebooks
[00:03:19.100 --> 00:03:22.480]   and you might want the paper one as well.
[00:03:22.480 --> 00:03:30.240]   So here is the main thing that you should commit to right now, which is to finish the
[00:03:30.240 --> 00:03:37.160]   damn course, right, and or finish at least half of the book.
[00:03:37.160 --> 00:03:41.080]   Because everybody I think who joins comes in thinking, okay, I'm going to do this, I'm
[00:03:41.080 --> 00:03:45.880]   going to do deep learning, but if you, when I look at our YouTube analytics, a lot of
[00:03:45.880 --> 00:03:48.420]   people don't finish, okay?
[00:03:48.420 --> 00:03:54.160]   So you just need to decide what day are you going to watch the course each week?
[00:03:54.160 --> 00:03:55.840]   What day are you going to do the assignment?
[00:03:55.840 --> 00:03:58.920]   What day, like how are you going to stretch your time to finish the course?
[00:03:58.920 --> 00:04:04.880]   And maybe you're coming in deciding, I don't want to finish it, which is fine, right?
[00:04:04.880 --> 00:04:07.400]   If that's your intention up front, no problem.
[00:04:07.400 --> 00:04:15.800]   But if your intention is to be a really effective deep learning practitioner, you need to finish
[00:04:15.800 --> 00:04:17.600]   the damn course, okay?
[00:04:17.600 --> 00:04:20.520]   So put it in your head that that's your goal.
[00:04:20.520 --> 00:04:23.600]   Talk to your friends or your spouse and tell them that's my goal.
[00:04:23.600 --> 00:04:27.440]   Get that social pressure that you're going to finish it.
[00:04:27.440 --> 00:04:33.760]   You're not just going to finish the course, but try to finish a project, right?
[00:04:33.760 --> 00:04:37.740]   So Christine McClavy is one of our fantastic alumni.
[00:04:37.740 --> 00:04:43.120]   She's now at OpenAI, one of the world's top research organizations.
[00:04:43.120 --> 00:04:48.800]   She built a fantastic system for creating new music with deep learning.
[00:04:48.800 --> 00:04:52.200]   She used to be a pianist herself.
[00:04:52.200 --> 00:05:01.680]   And I remember this discussion, I told her, focus on making one project great and polishing
[00:05:01.680 --> 00:05:05.440]   it off and finishing it.
[00:05:05.440 --> 00:05:07.200]   And she did.
[00:05:07.200 --> 00:05:14.440]   And that project has ended up creating music which the BBC Orchestra played, right?
[00:05:14.440 --> 00:05:22.660]   And amongst other things helped her get this extremely exclusive job at OpenAI.
[00:05:22.660 --> 00:05:29.600]   So this is a clip from a podcast with one of our students, Sanyam and Christine, in which
[00:05:29.600 --> 00:05:33.400]   Christine is saying this is one of her key insights.
[00:05:33.400 --> 00:05:37.560]   And so I've got to be giving you a few key insights, some of which are from me or some
[00:05:37.560 --> 00:05:43.080]   of them are from me via students, but they're all like things I've heard a bunch of times.
[00:05:43.080 --> 00:05:44.860]   So this is one example.
[00:05:44.860 --> 00:05:49.160]   So finish the course and finish a project.
[00:05:49.160 --> 00:05:52.820]   The project doesn't have to be something no one's ever built before.
[00:05:52.820 --> 00:05:56.360]   Maybe it's just like, oh, I really love that thing that person built.
[00:05:56.360 --> 00:06:00.840]   Gosh, it would be a real stretch if I could build it too.
[00:06:00.840 --> 00:06:02.940]   You know, great.
[00:06:02.940 --> 00:06:05.620]   Or it doesn't have to be world changing, you know.
[00:06:05.620 --> 00:06:13.080]   So one of our students built something for his fiancé, which was a cousin recognizer.
[00:06:13.080 --> 00:06:15.520]   He had, I think, 14 cousins.
[00:06:15.520 --> 00:06:20.500]   And so his fiancé could take a picture of one of the cousins and it would tell them
[00:06:20.500 --> 00:06:24.080]   which cousin it was, right?
[00:06:24.080 --> 00:06:31.740]   In our first course, one of our students built the app for the Silicon Valley TV show which
[00:06:31.740 --> 00:06:38.320]   did Hot Dog or Not Hot Dog, which was actually a huge smash hit, like millions of downloads
[00:06:38.320 --> 00:06:40.080]   that it was written about in the media.
[00:06:40.080 --> 00:06:45.000]   And it did exactly one thing just to tell you whether or not something was a hot dog.
[00:06:45.000 --> 00:06:50.160]   Anyway, or it could, you know, solve medicine.
[00:06:50.160 --> 00:06:51.160]   That would be fine too.
[00:06:51.160 --> 00:06:55.560]   I mean, whatever.
[00:06:55.560 --> 00:07:00.280]   So finishing the course means being tenacious.
[00:07:00.280 --> 00:07:07.440]   And one of the things I hear a lot is a lot of the approaches people learn as they do
[00:07:07.440 --> 00:07:12.480]   fast AI around how to learn and how to study are useful more generally.
[00:07:12.480 --> 00:07:18.440]   And in fact, this is a quote from our book, the number one thing I see the difference
[00:07:18.440 --> 00:07:24.300]   between successful deep learning practitioners and not is tenacity, okay?
[00:07:24.300 --> 00:07:27.860]   And tenacity is on the whole something you can choose.
[00:07:27.860 --> 00:07:33.000]   Now something you can't choose is whether you find yourself in the middle of a global
[00:07:33.000 --> 00:07:39.720]   pandemic or, you know, somebody in your family dies or you come down with a terrible cold
[00:07:39.720 --> 00:07:42.840]   or whatever, like obstacles happen, right?
[00:07:42.840 --> 00:07:48.280]   And so part of being tenacious is being understanding with yourself, right?
[00:07:48.280 --> 00:07:50.400]   And saying, okay, something's happened.
[00:07:50.400 --> 00:07:54.680]   I can't do what I hope to do right now, but then getting back to it, right?
[00:07:54.680 --> 00:08:01.600]   So part of tenacity is not about ignoring the bumps, but keeping going after the bumps.
[00:08:01.600 --> 00:08:06.880]   And maybe that's, you know, quite often I'll have a bump that's like a year long, right?
[00:08:06.880 --> 00:08:11.240]   But if I've decided to finish something, you know, at the end of that year, I'll go back
[00:08:11.240 --> 00:08:13.120]   and finish it.
[00:08:13.120 --> 00:08:19.200]   So sometimes that involves me emailing somebody more than a year after they've sent me something
[00:08:19.200 --> 00:08:25.880]   and saying, okay, I'm ready to reply now, and they forgot that they even sent me an email.
[00:08:25.880 --> 00:08:32.520]   Okay, so what I'm going to do now is I'm going to share with you a bunch of insights from
[00:08:32.520 --> 00:08:35.120]   this book called Meta-Learning.
[00:08:35.120 --> 00:08:39.840]   If you haven't seen it before, that's okay, it came out yesterday.
[00:08:39.840 --> 00:08:48.320]   And it was written by a guy called Redek, who is one of the top alumni of this course.
[00:08:48.320 --> 00:08:55.280]   And it's a book well worth reading because his journey is extraordinary.
[00:08:55.280 --> 00:09:03.440]   You know, this is a guy without a degree who couldn't code just a few years ago with a
[00:09:03.440 --> 00:09:13.000]   job that he found boring, and he set out to learn deep learning and repeatedly failed
[00:09:13.000 --> 00:09:15.560]   to do so.
[00:09:15.560 --> 00:09:22.640]   But Redek is extremely tenacious, and each time he failed to do so, he tried again.
[00:09:22.640 --> 00:09:25.080]   And eventually he figured out a way to do it.
[00:09:25.080 --> 00:09:32.800]   And the way he did it was very intensely based on fast AI, both the course and the philosophy
[00:09:32.800 --> 00:09:34.160]   of learning.
[00:09:34.160 --> 00:09:39.400]   And he is now a Kaggle competition winner.
[00:09:39.400 --> 00:09:47.280]   He was the only non-San Francisco person at QAI, which is one of the world's top medical
[00:09:47.280 --> 00:09:48.480]   AI startups.
[00:09:48.480 --> 00:09:57.560]   And now he works at a new nonprofit that is literally trying to translate animal language.
[00:09:57.560 --> 00:10:02.080]   And so he's kind of a good example, like I always think it's a good idea to have a role
[00:10:02.080 --> 00:10:03.080]   model.
[00:10:03.080 --> 00:10:05.760]   And in the fast AI community, there's a lot of role models.
[00:10:05.760 --> 00:10:11.200]   And so here's somebody who's like both a role model for like trying, failing, trying, failing,
[00:10:11.200 --> 00:10:15.600]   trying, failing, and then, you know, finding some success.
[00:10:15.600 --> 00:10:21.080]   And so I'm going to show you some things from his book.
[00:10:21.080 --> 00:10:28.640]   And a lot of his book is him taking stuff I say and kind of casting it into what he took
[00:10:28.640 --> 00:10:29.640]   away from it.
[00:10:29.640 --> 00:10:32.660]   That's his ideas.
[00:10:32.660 --> 00:10:41.440]   So one of the things we hear again and again from unsuccessful deep learning students is
[00:10:41.440 --> 00:10:44.880]   they keep preparing to do deep learning.
[00:10:44.880 --> 00:10:47.120]   And they keep preparing to do projects.
[00:10:47.120 --> 00:10:49.560]   So they study linear algebra.
[00:10:49.560 --> 00:10:51.180]   They study calculus.
[00:10:51.180 --> 00:10:53.440]   They study C++.
[00:10:53.440 --> 00:10:56.180]   They study all these different things.
[00:10:56.180 --> 00:11:01.280]   They do a MOOC and then another MOOC and then they read a book and then another book.
[00:11:01.280 --> 00:11:05.400]   You know, and at what point are they actually going to start doing something?
[00:11:05.400 --> 00:11:10.940]   So the fast AI philosophy is you start doing something week one, OK?
[00:11:10.940 --> 00:11:17.400]   So week one, you need to actually train a model, OK?
[00:11:17.400 --> 00:11:23.320]   Which is not to say that you're not going to learn theory.
[00:11:23.320 --> 00:11:25.320]   You will, right?
[00:11:25.320 --> 00:11:29.080]   As needed in the context of getting stuff done, OK?
[00:11:29.080 --> 00:11:37.000]   And so if you do finish it, right, particularly if you finish the full two parts of the course,
[00:11:37.000 --> 00:11:42.840]   right, you'll have implemented basically all of fast AI's library just about from scratch.
[00:11:42.840 --> 00:11:45.160]   You'll know all about batch normalization.
[00:11:45.160 --> 00:11:49.320]   You'll have benchmarked various matrix multiplication approaches.
[00:11:49.320 --> 00:11:53.200]   You'll know how to write bare metal GPU optimized code.
[00:11:53.200 --> 00:11:59.240]   You'll understand how to do back propagation and the calculus of that from scratch.
[00:11:59.240 --> 00:12:01.240]   You'll do all of that, OK?
[00:12:01.240 --> 00:12:06.000]   But it will all be as you go along in the context of like solving a particular problem
[00:12:06.000 --> 00:12:10.120]   or understanding the next piece of the puzzle.
[00:12:10.120 --> 00:12:18.560]   So yeah, really just reading books and watching videos is not going to get you there.
[00:12:18.560 --> 00:12:24.040]   The thing which is going to get you there is writing code, doing experiments and training
[00:12:24.040 --> 00:12:25.800]   models.
[00:12:25.800 --> 00:12:29.360]   Some of you might not be that great at coding.
[00:12:29.360 --> 00:12:30.360]   Fine.
[00:12:30.360 --> 00:12:31.360]   OK.
[00:12:31.360 --> 00:12:34.400]   That's a perfectly OK place to be.
[00:12:34.400 --> 00:12:40.920]   And but you guys are going to find it the most challenging because being good at coding
[00:12:40.920 --> 00:12:43.160]   is the thing that lets you zip through quickly.
[00:12:43.160 --> 00:12:45.840]   So rather than think, oh, that's a shame.
[00:12:45.840 --> 00:12:47.200]   I'm not that good at coding yet.
[00:12:47.200 --> 00:12:53.160]   This is actually an opportunity because now you have a really fun project to learn to
[00:12:53.160 --> 00:12:54.160]   code in.
[00:12:54.160 --> 00:13:00.240]   So a lot of people have become good coders by doing the course.
[00:13:00.240 --> 00:13:04.840]   Because as you do the course, you'll learn about a lot of computer science concepts like
[00:13:04.840 --> 00:13:09.520]   object-oriented programming and functional programming and mapping over a list and list
[00:13:09.520 --> 00:13:15.160]   comprehensions and GPU acceleration and so on and so forth, right?
[00:13:15.160 --> 00:13:21.560]   So the thing is, though, if you come across a computer science concept or a programming
[00:13:21.560 --> 00:13:26.800]   idea or a piece of syntax that you're not that familiar with, that's a place it's worth
[00:13:26.800 --> 00:13:33.560]   pausing for a moment and making sure that you do understand how that code works.
[00:13:33.560 --> 00:13:38.880]   Because the coding is the kind of critical foundational skill.
[00:13:38.880 --> 00:13:43.240]   This is a pretty good course for getting started with basic computer science.
[00:13:43.240 --> 00:13:50.600]   Harvard CS50 course, which everybody at Harvard does for computer science to get started.
[00:13:50.600 --> 00:13:52.840]   And that's all available for free online.
[00:13:52.840 --> 00:13:58.160]   So I would recommend, well, and so would Radek start there.
[00:13:58.160 --> 00:14:02.840]   And so these quotes are all from Radek's book, by the way.
[00:14:02.840 --> 00:14:08.240]   And then the other piece, so Radek talks about this four-legged table of the things that
[00:14:08.240 --> 00:14:16.200]   are going to help you do your deep learning experiments more effectively and efficiently.
[00:14:16.200 --> 00:14:17.600]   And these are the ideas.
[00:14:17.600 --> 00:14:26.760]   Knowing the basic ideas around code, knowing your tools, so an editor, do you put a notebook,
[00:14:26.760 --> 00:14:32.840]   knowing stuff like Git, like how to save your work and pull in other people's work and so
[00:14:32.840 --> 00:14:40.240]   forth, and understanding kind of SSH and Linux, like how to access a server and manipulate
[00:14:40.240 --> 00:14:43.520]   it and do stuff with it.
[00:14:43.520 --> 00:14:49.400]   So there's this great course called the missing semester of your CS education, which was actually
[00:14:49.400 --> 00:14:57.720]   created, I believe, by students at MIT who said, oh, everybody at MIT is assuming we
[00:14:57.720 --> 00:15:02.080]   already know this stuff, but a lot of us don't.
[00:15:02.080 --> 00:15:08.920]   So there's nothing to be ashamed of if you've never used Git or you've never used SSH or
[00:15:08.920 --> 00:15:09.920]   whatever.
[00:15:09.920 --> 00:15:16.360]   They're just tools which, at some point in the journey, most people just kind of have
[00:15:16.360 --> 00:15:17.360]   to figure out.
[00:15:17.360 --> 00:15:23.720]   So this is actually a great time to do it, and this is a great course to use to help
[00:15:23.720 --> 00:15:24.720]   you get there.
[00:15:24.720 --> 00:15:30.300]   And of course, again, the main thing is to practice these tools.
[00:15:30.300 --> 00:15:39.640]   So that's the kind of foundation around coding and your kind of development environment.
[00:15:39.640 --> 00:15:44.200]   The next big piece of advice, which we talk about a lot in the course and that Radek talks
[00:15:44.200 --> 00:15:54.780]   about in his book, is sharing your work, communicating your work, and writing about your work.
[00:15:54.780 --> 00:16:00.920]   This is something that a lot of people feel very uncomfortable, like tweeting or blogging
[00:16:00.920 --> 00:16:01.920]   or whatever.
[00:16:01.920 --> 00:16:08.080]   It's like, who the hell am I to start writing about deep learning?
[00:16:08.080 --> 00:16:09.880]   I've just started.
[00:16:09.880 --> 00:16:13.400]   Well, here's the thing.
[00:16:13.400 --> 00:16:20.280]   No one is better placed than you to write for, like, what would you have wanted to know
[00:16:20.280 --> 00:16:22.200]   six months ago?
[00:16:22.200 --> 00:16:27.000]   So you now know more than you did six months ago, and you'll know more in a week and more
[00:16:27.000 --> 00:16:28.320]   in a week, more in a week.
[00:16:28.320 --> 00:16:33.700]   And so if you've got a background in, say, the hospitality industry, you know, you could
[00:16:33.700 --> 00:16:38.440]   probably write something very interesting for your colleagues in the hospitality industry
[00:16:38.440 --> 00:16:43.800]   about ideas around deep learning, for example.
[00:16:43.800 --> 00:16:48.040]   Or if you teach at high school, you know, you might have ideas that you could write
[00:16:48.040 --> 00:16:52.460]   down about what high school students might find interesting or teachers might find interesting.
[00:16:52.460 --> 00:16:55.240]   So you know, everybody's got something to say.
[00:16:55.240 --> 00:17:01.200]   And the key thing is just to write it down because that is going to help embed your understanding
[00:17:01.200 --> 00:17:09.000]   a lot better, and it's going to start to build up your portfolio.
[00:17:09.000 --> 00:17:11.080]   And so we'll talk more about that in a moment.
[00:17:11.080 --> 00:17:17.360]   But a lot of people have found that this message of sharing their work has been a critical
[00:17:17.360 --> 00:17:22.800]   part of their journey of learning, and of also building up their personal brand that
[00:17:22.800 --> 00:17:26.160]   has ended up getting them a job.
[00:17:26.160 --> 00:17:27.320]   OK.
[00:17:27.320 --> 00:17:33.680]   So what does it mean to do a fast AI lesson?
[00:17:33.680 --> 00:17:45.080]   So a fast AI lesson is basically a chapter of the book or one video from the course.
[00:17:45.080 --> 00:17:46.080]   Or both.
[00:17:46.080 --> 00:17:50.400]   So what does it mean to do one of these lessons?
[00:17:50.400 --> 00:17:55.900]   Assuming you're doing the video, then it means, OK, obviously watching the video.
[00:17:55.900 --> 00:17:58.800]   So there's a couple of hours, right?
[00:17:58.800 --> 00:18:06.120]   And then it means running the notebook, which we'll look at in a moment.
[00:18:06.120 --> 00:18:11.720]   When you run the notebook, you have the whole book with all of its code and all of its outputs
[00:18:11.720 --> 00:18:16.640]   there, you're playing with it.
[00:18:16.640 --> 00:18:19.240]   You should experiment, right?
[00:18:19.240 --> 00:18:21.140]   You should try things out.
[00:18:21.140 --> 00:18:25.680]   So if you wonder, oh, why is this done before that?
[00:18:25.680 --> 00:18:27.640]   Well, try removing it.
[00:18:27.640 --> 00:18:29.280]   Try doing it in a different order.
[00:18:29.280 --> 00:18:34.120]   If you're wondering, you know, what would happen if I did that, but to this other image,
[00:18:34.120 --> 00:18:35.120]   try it, right?
[00:18:35.120 --> 00:18:39.680]   The more you can start to experiment, the more you're feeding your brain with these
[00:18:39.680 --> 00:18:43.200]   kind of like your own deep learning happening in your brain.
[00:18:43.200 --> 00:18:44.200]   Input output patterns.
[00:18:44.200 --> 00:18:45.440]   You try something, what happens?
[00:18:45.440 --> 00:18:49.680]   You try something, what happens?
[00:18:49.680 --> 00:19:02.140]   So after that, the next step is to try to reproduce the notebook from scratch, OK?
[00:19:02.140 --> 00:19:05.720]   Now you're going to have to look things up, obviously.
[00:19:05.720 --> 00:19:18.680]   But the idea is, can you, with a fresh new notebook, can you go back and recreate some
[00:19:18.680 --> 00:19:23.080]   of those models, retrain them, or redo some of that data processing pipeline?
[00:19:23.080 --> 00:19:28.600]   So try to like type it in yourself, you know, you can switch back to the answer as much
[00:19:28.600 --> 00:19:34.800]   as you like, but you're really trying to start to actually, you know, fill in your own, write
[00:19:34.800 --> 00:19:38.000]   your own code.
[00:19:38.000 --> 00:19:43.000]   And then what you really, the point you really want to get to is repeating some parts of
[00:19:43.000 --> 00:19:49.640]   the lesson with a different data set, which you collect or download.
[00:19:49.640 --> 00:19:58.320]   Now this whole process often takes people a number of times through the course, right?
[00:19:58.320 --> 00:20:03.080]   So often the first time through, people might just watch each lecture and try to kind of
[00:20:03.080 --> 00:20:07.620]   run it and, you know, just get to the end to get a kind of a general sense of what's
[00:20:07.620 --> 00:20:08.620]   going on.
[00:20:08.620 --> 00:20:12.280]   So people will often kind of go through the whole thing like three times and then come
[00:20:12.280 --> 00:20:15.360]   back and try to go further and further, right?
[00:20:15.360 --> 00:20:20.840]   So don't worry if you can't do all this right away.
[00:20:20.840 --> 00:20:23.200]   Certainly in lesson one, that's going to be challenging.
[00:20:23.200 --> 00:20:24.680]   Just take it as far as you can, right?
[00:20:24.680 --> 00:20:29.240]   And as you go along, try to push yourself to do more and more, and you could even go
[00:20:29.240 --> 00:20:33.760]   back to an earlier notebook and see if you can understand more and more of it.
[00:20:33.760 --> 00:20:38.280]   So let's take a look at what that looks like.
[00:20:38.280 --> 00:20:42.120]   So here's the course, okay?
[00:20:42.120 --> 00:20:49.000]   And here's the lessons, which you can watch.
[00:20:49.000 --> 00:20:54.560]   And then here are the places you can run the notebooks.
[00:20:54.560 --> 00:21:01.840]   So there's two types of platform for running the notebooks.
[00:21:01.840 --> 00:21:03.080]   There are notebook servers.
[00:21:03.080 --> 00:21:09.440]   These are things that as soon as you click into it, the actual environment we use, Jupyter
[00:21:09.440 --> 00:21:15.460]   notebook, will pop up and you can just start running it pretty much straight away.
[00:21:15.460 --> 00:21:20.300]   So that is obviously the easiest.
[00:21:20.300 --> 00:21:22.920]   Colab is free.
[00:21:22.920 --> 00:21:25.840]   Colab has a free tier.
[00:21:25.840 --> 00:21:31.320]   And SageMaker is not free.
[00:21:31.320 --> 00:21:35.720]   So we're going to look at Colab today.
[00:21:35.720 --> 00:21:40.160]   The other option is to use a full Linux server, and this is something where you're going to
[00:21:40.160 --> 00:21:46.560]   have to basically set up Linux and install the Python system and install notebooks and
[00:21:46.560 --> 00:21:52.040]   get the code from GitHub and run the server and log into SSH and do all that.
[00:21:52.040 --> 00:21:54.360]   That's obviously a lot more work.
[00:21:54.360 --> 00:22:01.180]   You might want to skip it for now in like lesson one.
[00:22:01.180 --> 00:22:07.480]   But I would recommend at some point you go through this path.
[00:22:07.480 --> 00:22:13.280]   And the reason why is that in real life at your workplace or if you do your own startup
[00:22:13.280 --> 00:22:16.720]   or whatever, this is what you'll be doing.
[00:22:16.720 --> 00:22:22.720]   You will be interacting with a Linux server using SSH that's running a GPU.
[00:22:22.720 --> 00:22:25.400]   And you'll want to understand how it all works.
[00:22:25.400 --> 00:22:31.440]   And once you're using your own Linux server, you'll suddenly learn about all these productivity-enhancing
[00:22:31.440 --> 00:22:36.200]   tips and tools that make your life easier.
[00:22:36.200 --> 00:22:46.880]   So I'll be showing how to set up AWS EC2, that's the Amazon platform today.
[00:22:46.880 --> 00:22:54.320]   You'll find Google Cloud looks very, very similar indeed.
[00:22:54.320 --> 00:22:58.800]   Jarvis Labs was created by a Fast AI alum, and this is probably at this stage the best
[00:22:58.800 --> 00:23:02.060]   value of the full Linux servers.
[00:23:02.060 --> 00:23:06.920]   So that would certainly be also very much worth checking out.
[00:23:06.920 --> 00:23:13.600]   One good thing about AWS, so a couple of things, AWS is currently the most popular platform
[00:23:13.600 --> 00:23:14.960]   for cloud computing.
[00:23:14.960 --> 00:23:22.120]   So it's very likely that whatever company you're at or end up at is already using it.
[00:23:22.120 --> 00:23:26.680]   They're also pretty generous with credits for startups and students.
[00:23:26.680 --> 00:23:33.440]   So even though it can set you back 60 or 70 cents an hour, you might well find you can
[00:23:33.440 --> 00:23:39.680]   get a few hundred dollars worth of credits through your school or even a few thousand
[00:23:39.680 --> 00:23:45.440]   dollars worth of credits through their startup programs and so forth.
[00:23:45.440 --> 00:23:51.920]   So let's have a look at what Colab looks like.
[00:23:51.920 --> 00:23:57.960]   So Colab is, it's wonderful how easy it is to get started.
[00:23:57.960 --> 00:24:10.240]   You literally just click on the chapter, so let's do chapter one, and it pops up Colab.
[00:24:10.240 --> 00:24:17.280]   You can pay, I think it's $10 a month for Colab Pro to get like longer sessions and
[00:24:17.280 --> 00:24:21.960]   more likely that you'll get a better GPU, but for most people you'll find the free version
[00:24:21.960 --> 00:24:23.320]   is totally fine.
[00:24:23.320 --> 00:24:30.400]   One of the biggest problems with Colab is that it's not persistent, which is to say
[00:24:30.400 --> 00:24:35.200]   when I go to this notebook, it thinks it's never seen me before.
[00:24:35.200 --> 00:24:39.720]   Nothing's set up for me the way I want it, but we've set up the notebook so that the
[00:24:39.720 --> 00:24:44.020]   very first cell actually installs everything you need.
[00:24:44.020 --> 00:24:51.680]   So if I click this little run cell button here, it will run the cell.
[00:24:51.680 --> 00:25:04.360]   Although what I will do is I'm going to pop over to Colab here, and let's also read the
[00:25:04.360 --> 00:25:05.360]   steps here.
[00:25:05.360 --> 00:25:09.600]   And actually it says here before running anything, you should tell Colab you're interested in
[00:25:09.600 --> 00:25:11.140]   using a GPU.
[00:25:11.140 --> 00:25:20.760]   So if you find that when you run a cell from the course, and it's going to take like half
[00:25:20.760 --> 00:25:25.920]   an hour or an hour or more, it's very likely you forgot to use GPU.
[00:25:25.920 --> 00:25:29.540]   The GPU runs things many hundreds of times faster.
[00:25:29.540 --> 00:25:39.960]   So all you do as it says here is go runtime, change runtime type, and say GPU, okay?
[00:25:39.960 --> 00:25:50.000]   So now I can run this cell.
[00:25:50.000 --> 00:25:56.920]   And this is all Python code except lines that start with an explanation mark actually sent
[00:25:56.920 --> 00:25:58.560]   to a terminal.
[00:25:58.560 --> 00:26:05.320]   So PIP is something that installs Python software, and Fastbook contains all of the Python software
[00:26:05.320 --> 00:26:11.800]   necessary for the course, and so it's going to go away and set it all up.
[00:26:11.800 --> 00:26:18.000]   And so this is this like mildly annoying bit.
[00:26:18.000 --> 00:26:26.200]   You can then connect Colab to Google Drive, and that's going to be how you can save your
[00:26:26.200 --> 00:26:28.840]   notebooks and save your work as you go, okay?
[00:26:28.840 --> 00:26:33.440]   I'm not going to do that right now, but if you go to this link that it says and it'll
[00:26:33.440 --> 00:26:39.240]   give you a code and then that'll connect it up to your Google Drive.
[00:26:39.240 --> 00:26:47.400]   And so at this point now everything from the for the course is now available, and you can
[00:26:47.400 --> 00:26:53.200]   see the whole book is here, okay?
[00:26:53.200 --> 00:27:03.960]   So here's the book, and you can open up sections to read them, okay?
[00:27:03.960 --> 00:27:15.940]   You can go to the table of contents, okay?
[00:27:15.940 --> 00:27:25.880]   And so eventually we'll get to this cell here which contains all the code needed to run
[00:27:25.880 --> 00:27:27.440]   a model.
[00:27:27.440 --> 00:27:34.080]   So if I click run, here is where it goes.
[00:27:34.080 --> 00:27:40.320]   Now this is going to it's amazing how much this little bit of code is going to do.
[00:27:40.320 --> 00:27:46.400]   It's going to download tens of thousands of pictures of dogs and cats.
[00:27:46.400 --> 00:27:52.480]   It's going to use a simple rule to recognize the dogs from the cats based on their file
[00:27:52.480 --> 00:27:53.480]   names.
[00:27:53.480 --> 00:27:57.240]   Basically the way that this has been set up is that you can tell from the file name whether
[00:27:57.240 --> 00:28:00.240]   it's a dog or a cat.
[00:28:00.240 --> 00:28:04.000]   It's then going to download something called a pre-trained model, which is something that
[00:28:04.000 --> 00:28:09.000]   already knows how to recognize various types of images.
[00:28:09.000 --> 00:28:14.520]   It's then going to construct, it's then going to train that model to make it particularly
[00:28:14.520 --> 00:28:19.480]   good at recognizing dogs from cats, and then it's going to validate that model to see how
[00:28:19.480 --> 00:28:25.040]   good it is at recognizing dogs from cats using a set of pictures that it hasn't seen before.
[00:28:25.040 --> 00:28:26.880]   And that's all happening.
[00:28:26.880 --> 00:28:33.320]   So so far it's already downloaded the dataset, it's already downloaded the pre-trained model,
[00:28:33.320 --> 00:28:38.880]   and it's now busily going through the first epoch, which is to look at every picture once
[00:28:38.880 --> 00:28:44.120]   to try to learn how to recognize dogs from cats.
[00:28:44.120 --> 00:28:45.120]   And that's it.
[00:28:45.120 --> 00:28:47.840]   The lines starting with a hash are just comments.
[00:28:47.840 --> 00:28:53.360]   Because this is also the source of an actual book, there's a few like slightly weird comments
[00:28:53.360 --> 00:28:54.360]   that you can ignore.
[00:28:54.360 --> 00:28:58.480]   They're just things that are used for setting up references in the book.
[00:28:58.480 --> 00:29:00.080]   There's the caption, so forth.
[00:29:00.080 --> 00:29:05.480]   Okay, so it's now testing out, I think that first epoch.
[00:29:05.480 --> 00:29:11.000]   Okay, so it's finished in epoch, and so far it's got a 1% error rate.
[00:29:11.000 --> 00:29:19.880]   So after 54 seconds, it has learned to recognize dogs from cats with 99% accuracy.
[00:29:19.880 --> 00:29:25.560]   And so yeah, we're going to let that finish off.
[00:29:25.560 --> 00:29:27.920]   So that's how we get started with Colab.
[00:29:27.920 --> 00:29:34.440]   And there's nothing else to set up.
[00:29:34.440 --> 00:29:57.560]   Now what you can do is you can open Notebook, and you can open a notebook from GitHub.
[00:29:57.560 --> 00:30:04.600]   And here is the Fastbook repository.
[00:30:04.600 --> 00:30:08.240]   And you'll see in the Fastbook repository, for every notebook, there's a second copy
[00:30:08.240 --> 00:30:11.320]   inside the clean folder with the same name.
[00:30:11.320 --> 00:30:13.680]   So I was just looking at 01Intro.
[00:30:13.680 --> 00:30:15.640]   There's also a clean 01Intro.
[00:30:15.640 --> 00:30:26.440]   If I open that up, you'll see that it's got exactly the same thing as the last one I was
[00:30:26.440 --> 00:30:30.560]   just looking at, but all the pros is now missing.
[00:30:30.560 --> 00:30:34.480]   It's just got headings and code.
[00:30:34.480 --> 00:30:37.800]   Also all the outputs are missing.
[00:30:37.800 --> 00:30:45.520]   So the reason that we have this clean version is to help you with these stages here, is
[00:30:45.520 --> 00:30:52.120]   our suggestion is once you've gone through the lesson, and you've run the notebook, and
[00:30:52.120 --> 00:30:57.960]   you feel like, okay, I think I get it, is you open up this clean version.
[00:30:57.960 --> 00:31:04.800]   And before you run each cell, try to think, okay, why is this cell here?
[00:31:04.800 --> 00:31:06.040]   What's it for?
[00:31:06.040 --> 00:31:07.320]   What's it going to do?
[00:31:07.320 --> 00:31:09.640]   What's the output going to look like, right?
[00:31:09.640 --> 00:31:15.120]   So once you remove all that context, this is a good test for you to kind of get your
[00:31:15.120 --> 00:31:18.480]   brain going to think what was actually going on.
[00:31:18.480 --> 00:31:23.880]   So this is a kind of much more active approach to reading and recall.
[00:31:23.880 --> 00:31:32.000]   And so then once you've done that, and you've finished going through this, at the bottom,
[00:31:32.000 --> 00:31:35.760]   one thing that is kept is the questionnaire.
[00:31:35.760 --> 00:31:38.260]   So at the end of every chapter is a questionnaire.
[00:31:38.260 --> 00:31:44.880]   And so then at this point, you should now, as much as you can without looking, go through
[00:31:44.880 --> 00:31:48.480]   and try to answer each of those questions.
[00:31:48.480 --> 00:31:52.520]   They all have answers in the notebook, in the book.
[00:31:52.520 --> 00:31:56.280]   So if you can't remember, you can always look it up.
[00:31:56.280 --> 00:32:01.920]   But if you can't remember, that's a sign to you that like, oh, did I skip over that bit
[00:32:01.920 --> 00:32:02.920]   too quickly?
[00:32:02.920 --> 00:32:06.080]   Like what's happened that I've not remembered?
[00:32:06.080 --> 00:32:12.180]   And then try to remind yourself, and then go back and finish the questionnaire.
[00:32:12.180 --> 00:32:19.900]   So there's a lot of pieces to help take this from a passive, I'm just watching a video,
[00:32:19.900 --> 00:32:33.680]   I'm just reading a book, into a participatory exercise that you're a part of.
[00:32:33.680 --> 00:32:41.640]   So as soon as you can, we want you to create something that's yours.
[00:32:41.640 --> 00:32:46.880]   And so this is the easiest way to do that, is basically at the end of lesson one, once
[00:32:46.880 --> 00:32:51.800]   you're kind of up and running, try to do it with your own data set.
[00:32:51.800 --> 00:32:58.040]   And if you go to forums.fast.ai, which is something that you're going to want to be
[00:32:58.040 --> 00:33:02.760]   deeply familiar with, because this is going to be full of people just like you, other
[00:33:02.760 --> 00:33:05.720]   people who want to learn deep learning.
[00:33:05.720 --> 00:33:11.760]   And these people are all asking questions, and making comments, and you can see there's
[00:33:11.760 --> 00:33:14.600]   like a lot going on all the time.
[00:33:14.600 --> 00:33:22.380]   And so you can see here's the part one course topic.
[00:33:22.380 --> 00:33:26.300]   And you can see there's 1.4 thousand topics there, and each one is going to have lots
[00:33:26.300 --> 00:33:29.600]   and lots of replies.
[00:33:29.600 --> 00:33:35.600]   So this is where, amongst other things, you'll find, if you search for it, something called
[00:33:35.600 --> 00:33:41.360]   Share Your Work Here, which has 2,000 replies, and you can see links to and pictures of lots
[00:33:41.360 --> 00:33:47.120]   of examples of things that other people have done after the first week or two of the course.
[00:33:47.120 --> 00:33:52.800]   And so hopefully that might help give you some inspiration.
[00:33:52.800 --> 00:34:00.720]   And it would be great if you could reply and add a picture or a link to what you build.
[00:34:00.720 --> 00:34:08.040]   And you'll see, you know, everybody is very positive to each other on the forums in general
[00:34:08.040 --> 00:34:09.800]   and in this topic in particular.
[00:34:09.800 --> 00:34:15.320]   Nobody's going to go, "Oh my god, I could have done that years ago," right?
[00:34:15.320 --> 00:34:20.260]   People are going to be excited for you, that you have now joined the ranks of people that
[00:34:20.260 --> 00:34:23.320]   have built their first deep learning model.
[00:34:23.320 --> 00:34:30.120]   And I will be excited for you.
[00:34:30.120 --> 00:34:39.600]   So as I said, Radik, this is again from his book, expresses in his book a way of not doing
[00:34:39.600 --> 00:34:43.960]   fast AI, which I have heard now probably hundreds of times.
[00:34:43.960 --> 00:34:50.080]   I don't know why this is so common, but many, many people do what Radik did, which was basically
[00:34:50.080 --> 00:34:54.720]   to learn all these math things, right?
[00:34:54.720 --> 00:35:01.080]   So he started with calculus, and then once he got to a certain point in calculus, he
[00:35:01.080 --> 00:35:05.080]   found that he had to start understanding real analysis.
[00:35:05.080 --> 00:35:11.120]   And then as he started understanding real analysis, he had found he had to learn set
[00:35:11.120 --> 00:35:13.740]   theory, you know, and you get the idea, right?
[00:35:13.740 --> 00:35:20.640]   If you want to learn all of math, that's going to take a while.
[00:35:20.640 --> 00:35:25.440]   There's a lot of gatekeeping out there that says like, "Oh, if you're going to be a real
[00:35:25.440 --> 00:35:30.560]   deep learning practitioner, you have to finish, you know, a graduate level course in linear
[00:35:30.560 --> 00:35:31.560]   algebra."
[00:35:31.560 --> 00:35:39.880]   Here's the truth, the actual linear algebra you do in basically all deep learning is matrix
[00:35:39.880 --> 00:35:41.600]   multiplication.
[00:35:41.600 --> 00:35:46.400]   And if you've forgotten what that is, that is multiplying things together and then adding
[00:35:46.400 --> 00:35:48.200]   them up, okay?
[00:35:48.200 --> 00:35:53.160]   So what you need to be able to do is multiply things together and add them up, right?
[00:35:53.160 --> 00:35:57.460]   So if you can do that, you're good to go.
[00:35:57.460 --> 00:36:04.960]   So yeah, don't get, you know, you're not going to finish it if A, you never start it because
[00:36:04.960 --> 00:36:10.280]   you keep preparing, or B, you keep thinking, "Oh, I wonder exactly what's happening here,"
[00:36:10.280 --> 00:36:13.560]   and you go all the way down to the bottom until you found yourself in the midst of set
[00:36:13.560 --> 00:36:14.560]   theory, right?
[00:36:14.560 --> 00:36:22.240]   Don't worry, you'll get deeper and deeper over time, but if you're learning mathematical
[00:36:22.240 --> 00:36:27.160]   theory, you're not coding, you're not experimenting, you're not practicing, you're not actually
[00:36:27.160 --> 00:36:31.680]   building deep learning models, and if you're watching this course and your goal is not
[00:36:31.680 --> 00:36:35.560]   to build deep learning models, you're in the wrong course, okay?
[00:36:35.560 --> 00:36:46.360]   But if your goal is to build deep learning models, then don't do this.
[00:36:46.360 --> 00:36:54.840]   So as Rennick says here, it's as you train actual models that you're going to get feedback,
[00:36:54.840 --> 00:36:55.840]   right?
[00:36:55.840 --> 00:37:01.360]   And the feedback that a lot of people get is, "Oh my God, I can already train useful
[00:37:01.360 --> 00:37:09.600]   models," like a lot of people are surprised at how early on they can actually get astonishingly
[00:37:09.600 --> 00:37:10.600]   good results.
[00:37:10.600 --> 00:37:16.360]   Okay, so, you know, jump in and be open to surprising yourself that you can do a bit
[00:37:16.360 --> 00:37:17.360]   more than you thought.
[00:37:17.360 --> 00:37:22.080]   You can't do everything right away, okay, but start that feedback loop of figuring out
[00:37:22.080 --> 00:37:30.240]   what do you know, what can you do, what can you get working, what can't you get working?
[00:37:30.240 --> 00:37:34.240]   So one of the key things that you're going to need to do if you're going to finish all
[00:37:34.240 --> 00:37:40.240]   of the course is become an even better developer than you are now, even better coder than you
[00:37:40.240 --> 00:37:48.720]   are now, wherever you're up to, and so to do this, you need to read code and write code.
[00:37:48.720 --> 00:37:53.300]   The fast.ai source code is designed to be extremely readable, so you can read that code.
[00:37:53.300 --> 00:37:59.120]   You can obviously read the code in the notebooks, but yeah, you want to be spending as much
[00:37:59.120 --> 00:38:05.240]   time as possible reading and writing code, and particularly reading and writing deep learning
[00:38:05.240 --> 00:38:08.080]   code.
[00:38:08.080 --> 00:38:17.400]   All right, how do you find out what's going on in the world of deep learning, and how do
[00:38:17.400 --> 00:38:22.560]   you get yourself on the map of people doing deep learning?
[00:38:22.560 --> 00:38:24.600]   Probably the best answer is Twitter.
[00:38:24.600 --> 00:38:31.720]   For those of you whose only knowledge of Twitter is the Kardashians and Donald Trump, this might
[00:38:31.720 --> 00:38:39.600]   come as a surprise, but actually to create this slide, I opened Twitter and I copied
[00:38:39.600 --> 00:38:43.360]   and pasted the first three tweets that appeared on my screen.
[00:38:43.360 --> 00:38:50.600]   So one of them is somebody has a discussion about costs and impacts of different approaches
[00:38:50.600 --> 00:38:58.680]   to labeling. This is a fast.ai alum who's a 17 year old PhD graduate who's doing well,
[00:38:58.680 --> 00:39:04.840]   who shows how to mix PyTorch and fast.ai, and then Hilary Mason, who's a professor,
[00:39:04.840 --> 00:39:11.240]   and I guess not a professor anymore, but now in industry, talking about organizational
[00:39:11.240 --> 00:39:13.600]   issues in data science.
[00:39:13.600 --> 00:39:23.480]   So there's a whole world out there of machine learning on Twitter, and if you want to get
[00:39:23.480 --> 00:39:29.840]   your work noticed, that's a great place to do it because really everybody's there.
[00:39:29.840 --> 00:39:35.680]   And if you want me to highlight your work, that's where I can see it and I can retweet
[00:39:35.680 --> 00:39:44.880]   it. So yeah, Twitter is a really good place to be. If you're just starting with Twitter
[00:39:44.880 --> 00:39:51.800]   and you don't know who to follow, go to my Twitter, go to my likes, and go through my
[00:39:51.800 --> 00:39:57.320]   likes and find tweets that you think you actually like that tweet to, and then follow the person
[00:39:57.320 --> 00:40:03.520]   who did that tweet. Okay, and pretty quickly you'll have 100 people you're following, okay,
[00:40:03.520 --> 00:40:07.800]   and then they'll retweet things and you'll find other people you like, and before you
[00:40:07.800 --> 00:40:12.620]   know it, hopefully you've got a nice big lot of interesting, deep learning stuff to read
[00:40:12.620 --> 00:40:19.080]   every day. At first you'll understand like 1% of it, which is fine, but you know, you're
[00:40:19.080 --> 00:40:24.320]   there, you're in it, and it'll be all washing over you, and you'll start to find the people
[00:40:24.320 --> 00:40:29.720]   who write stuff you find engaging and interesting, and you'll also find the people that actually
[00:40:29.720 --> 00:40:34.720]   you don't, and make sure you unfollow them so that you don't have your feed, have stuff
[00:40:34.720 --> 00:40:44.720]   you don't care about. So then beyond Twitter, you want to start blogging. Okay, and again,
[00:40:44.720 --> 00:40:51.920]   blogging is not about writing what you had for dinner, okay, it's about writing something
[00:40:51.920 --> 00:40:56.960]   that you of six months ago would have found interesting. Okay, so you know more than you
[00:40:56.960 --> 00:41:04.000]   did six months ago, so write that down. We have something called Fast Pages that makes
[00:41:04.000 --> 00:41:13.440]   it ridiculously easy to start a blog, and so there's no reason for you not to, you know,
[00:41:13.440 --> 00:41:20.800]   at least create a blog. There we go. And one of the nice things about Fast Pages is you
[00:41:20.800 --> 00:41:24.880]   can even turn Jupyter Notebooks into blog posts, so it's great for kind of technical
[00:41:24.880 --> 00:41:29.400]   reasons. So this is what a Fast Pages blog looks like. This is a Fast Pages blog about
[00:41:29.400 --> 00:41:36.240]   Fast Pages. I had to write Fast Pages in order to write the Fast Pages blog about Fast Pages.
[00:41:36.240 --> 00:41:41.920]   But basically, and one of the other nice things, it's all in GitHub, right? So as you're blogging,
[00:41:41.920 --> 00:41:46.240]   you're learning more about Git. It's all written with Markdown, which is something that you're
[00:41:46.240 --> 00:41:50.800]   definitely going to need to know anyway. So as you're blogging, you'll be learning about
[00:41:50.800 --> 00:42:04.560]   a lot of the tools you need to learn about anyway.
[00:42:04.560 --> 00:42:11.160]   So one interesting idea for things to blog about is this example from Aman Arora, who
[00:42:11.160 --> 00:42:16.920]   is an Aussie Fast AI alum who is now working at Weights and Biases, which is one of the
[00:42:16.920 --> 00:42:25.240]   top AI startups in the world. This is a really interesting kind of blog post. What Aman did
[00:42:25.240 --> 00:42:32.360]   was he took a video that I did at the launch here of the Queensland AI Hub, and he wrote
[00:42:32.360 --> 00:42:40.720]   down what I said. And that's an example of something that you could do. If there are
[00:42:40.720 --> 00:42:47.520]   videos out there that you liked and nobody's turned it into a post, be the first to do
[00:42:47.520 --> 00:42:55.080]   so because there's all these benefits. When somebody sends me something saying, "I've
[00:42:55.080 --> 00:43:00.480]   written up this talk you gave," I'm very grateful to that person because now my talk
[00:43:00.480 --> 00:43:04.280]   is now available in a second medium. A lot of people prefer to read rather than listen
[00:43:04.280 --> 00:43:10.280]   to a talk. You know, that person's taken the time to do this. They've taken the time to
[00:43:10.280 --> 00:43:17.360]   have me check their work. And kind of everybody ends up winning from this. So I've seen with
[00:43:17.360 --> 00:43:26.240]   Aman's post about my talk, it's got attention from people that my talk didn't. So for example,
[00:43:26.240 --> 00:43:34.440]   I noticed on my LinkedIn feed, the CEO of Data61, which is the CSIRO, so the top data
[00:43:34.440 --> 00:43:41.680]   science body in Australia, highlighted it and said, "Check out this post from Anamurara."
[00:43:41.680 --> 00:43:48.920]   So this is like an example of the kind of stuff you can do. It's like try to be helpful,
[00:43:48.920 --> 00:43:54.400]   and at the same time you're also learning. So there's an example of an interesting kind
[00:43:54.400 --> 00:43:59.760]   of blog post which very few people are writing, and so there's a huge amount of opportunity
[00:43:59.760 --> 00:44:12.320]   here for you to practice your writing. Okay, now, what is the difference between machine
[00:44:12.320 --> 00:44:20.920]   learning and other kinds of coding? Ezra Dex says in this chapter of his book, "The key
[00:44:20.920 --> 00:44:29.280]   about machine learning is that we can generalize. We can train a model with one set of data
[00:44:29.280 --> 00:44:36.640]   and apply it to a different set of data and still get good results." And everything just
[00:44:36.640 --> 00:44:43.320]   about that we're doing in this course is all about creating models that are going to generalize
[00:44:43.320 --> 00:44:53.120]   well. And we're going to be learning about how you can measure how well your model generalizes.
[00:44:53.120 --> 00:45:00.240]   So answering these questions about can we trust our model to be correct on new data
[00:45:00.240 --> 00:45:07.600]   that we feed it is absolutely critical to every model that you build, whether it be
[00:45:07.600 --> 00:45:18.260]   in a Kaggle competition or a little prototype or a production model you're creating at work.
[00:45:18.260 --> 00:45:22.360]   One of the most important things here is creating a good validation set, and this is something
[00:45:22.360 --> 00:45:28.040]   that you'll hear about in lesson one of the course. But I really wanted to highlight it
[00:45:28.040 --> 00:45:36.320]   here, as did Radek in his book. It's a really important idea is you need a good way to measure
[00:45:36.320 --> 00:45:42.080]   whether your model is any good. So you need a data set that really represents what kind
[00:45:42.080 --> 00:45:51.120]   of data is your model likely to have to deal with in real life. And my partner Rachel wrote
[00:45:51.120 --> 00:45:56.760]   this really great blog post on the Fast.ai blog about this. Actually interestingly, this
[00:45:56.760 --> 00:46:03.760]   was kind of came out of a lesson that I did at the University of San Francisco and then
[00:46:03.760 --> 00:46:08.880]   Rachel turned it into a blog post and Rachel's blog post has ended up much more influential
[00:46:08.880 --> 00:46:13.600]   than my video ever was. So this is actually a good example of what I was talking about.
[00:46:13.600 --> 00:46:25.720]   And she took it a lot further. Okay. The next key thing that Radek mentions and I totally
[00:46:25.720 --> 00:46:35.360]   agree with is it's hard to write correct machine learning code. I always assume that every
[00:46:35.360 --> 00:46:40.720]   line of machine learning code I write is wrong. And I'm normally correct about that. It normally
[00:46:40.720 --> 00:46:50.720]   is wrong because there's lots of ways to be wrong. And unlike creating a you know, a context
[00:46:50.720 --> 00:46:55.160]   management app on the web or whatever, it's much harder to see that you're wrong. You
[00:46:55.160 --> 00:46:59.600]   know, you can't see that the name didn't get stored in the database or you can't see that
[00:46:59.600 --> 00:47:05.120]   the title isn't centered. Right. Often it's wrong that it's going to be like half a percent
[00:47:05.120 --> 00:47:09.440]   less accurate, you know, or your image is upside down, but it's kind of maybe you didn't
[00:47:09.440 --> 00:47:13.520]   even look at it. I got straight into the system and you end up with something that can only
[00:47:13.520 --> 00:47:22.640]   recognize upside down images or whatever. So whenever you're doing, you know, whenever
[00:47:22.640 --> 00:47:28.240]   you're building a project, make sure you start with a simple baseline, right? Like create
[00:47:28.240 --> 00:47:34.600]   the simplest possible model you can that's that, you know, solves the problem so simply
[00:47:34.600 --> 00:47:40.760]   that you can't have made a mistake. So often that'll be like just taking the average of
[00:47:40.760 --> 00:47:46.320]   the data or if there's two groups, take the average of each of the two groups or you know,
[00:47:46.320 --> 00:47:52.080]   something that something really, really simple and then you can gradually build up from there.
[00:47:52.080 --> 00:47:57.800]   So another very common beginner mistake with projects, remember we want you all doing projects
[00:47:57.800 --> 00:48:05.040]   is somebody in a project group will say, Oh, I read about this new Bayesian learning thing
[00:48:05.040 --> 00:48:10.840]   with these clusters and this, you know, advanced transformers pipeline, and we could put all
[00:48:10.840 --> 00:48:16.800]   that together. It's going to be better than anything before. And they then spend months
[00:48:16.800 --> 00:48:23.720]   creating this complex thing. And at the end, it doesn't work. Now, why doesn't it work?
[00:48:23.720 --> 00:48:28.720]   Well, I don't know. It's so big and so complicated. Maybe it's a stupid idea. Maybe there's a
[00:48:28.720 --> 00:48:32.400]   bug in one piece of it. Maybe that one piece there shouldn't be there, but it should be
[00:48:32.400 --> 00:48:38.600]   somewhere else. I don't know, right? That's not how anybody creates successful machine
[00:48:38.600 --> 00:48:45.280]   learning projects. Machine successful machine learning projects are always built, in my
[00:48:45.280 --> 00:48:51.760]   experience, by creating a simplest possible solution that gets something all the way from
[00:48:51.760 --> 00:48:59.680]   end to end first, and then very gradually it makes it incrementally slightly better. Okay,
[00:48:59.680 --> 00:49:05.520]   so keep that in mind, right? You might feel a bit silly when you build that first model
[00:49:05.520 --> 00:49:11.600]   that just takes the average of the data, right? But that's how, that's how the pros do it.
[00:49:11.600 --> 00:49:18.640]   That's how everybody that actually gets it to work does it. So often I've had, you know,
[00:49:18.640 --> 00:49:23.000]   Silicon Valley startup hotshots come to me and ask me to like, check out their amazing
[00:49:23.000 --> 00:49:30.560]   new startup, and I'll ask them, you know, oh, you reckon this can separate, you know,
[00:49:30.560 --> 00:49:35.100]   sick people from well people or whatever. Have you taken the average of each of these
[00:49:35.100 --> 00:49:40.640]   two groups and compared that to your model, for example? And they'll say, oh, no. And
[00:49:40.640 --> 00:49:46.080]   then they try it and they find out their model's worse, right? So you need to know whether
[00:49:46.080 --> 00:49:57.160]   your model's actually doing something useful. For projects, one of the things you might
[00:49:57.160 --> 00:50:05.680]   want to do is join a Kaggle competition. That might be the last thing you see yourself as
[00:50:05.680 --> 00:50:12.000]   doing is being a Kaggle competitor, but actually this is one of the best possible projects you
[00:50:12.000 --> 00:50:17.560]   can do because to enter a Kaggle competition, even to come last, you have to go through
[00:50:17.560 --> 00:50:23.680]   the entire process of downloading a dataset, formatting it into the right method, ready
[00:50:23.680 --> 00:50:28.360]   for a model, getting it through the model, saving the output, getting it into the correct
[00:50:28.360 --> 00:50:37.400]   submission format and submitting it back to Kaggle, right? So getting a model actually
[00:50:37.400 --> 00:50:43.040]   up onto the Kaggle leaderboard is really going to test out your end-to-end understanding,
[00:50:43.040 --> 00:50:47.120]   right? And once you've done that, you can start to iterate. You can start to make it
[00:50:47.120 --> 00:50:54.760]   slightly better, slightly better, slightly better. So although in a lot of ways, Kaggle
[00:50:54.760 --> 00:50:58.800]   is not representative of the real world, you know, you don't have to worry about deployment.
[00:50:58.800 --> 00:51:03.400]   You don't particularly have to worry about kind of inference speed, stuff like that.
[00:51:03.400 --> 00:51:08.880]   In a lot of ways, it is closer to the real world than you might expect and that it really
[00:51:08.880 --> 00:51:16.560]   does force you to go through the whole process and also to think about kind of planning your
[00:51:16.560 --> 00:51:25.640]   project carefully. So enter a competition with your kind of goal that I want to win.
[00:51:25.640 --> 00:51:29.800]   Now obviously on your first one, you're not going to win, but the whole point is it's
[00:51:29.800 --> 00:51:35.960]   a competition. So you've got to try to do your best, right? And so to do your best,
[00:51:35.960 --> 00:51:44.360]   join a competition that's early, right? Give yourself plenty of time. And every single
[00:51:44.360 --> 00:51:52.680]   day try to make a small improvement. And then you'll find that, you know, if you keep reading
[00:51:52.680 --> 00:51:57.640]   the forums on Kaggle and keep trying a bit more every day, you'd be amazed at the end
[00:51:57.640 --> 00:52:01.820]   of the three months how much you've learned, how much of the stuff that at the start you
[00:52:01.820 --> 00:52:08.640]   thought this is, I have no idea what's going on. And then you'll realize, oh, suddenly I
[00:52:08.640 --> 00:52:15.920]   do know what's going on. And you might find you get in the top 50% which might be better
[00:52:15.920 --> 00:52:23.960]   than you expected. So that this is, you know, highly recommended at some point during this
[00:52:23.960 --> 00:52:36.920]   course is have a real go at a Kaggle competition. So at the end of all of this, you might be
[00:52:36.920 --> 00:52:44.240]   looking for a job. Now this could mean a number of things. A lot of people just want to bring
[00:52:44.240 --> 00:52:51.160]   some deep learning into their current job. And so, you know, that's, if your organization's
[00:52:51.160 --> 00:52:55.000]   already doing some deep learning, that might be easier than if it's not. If it's not, you
[00:52:55.000 --> 00:52:59.640]   might just have to start prototyping some things and try to build up some kind of, you
[00:52:59.640 --> 00:53:07.120]   know, proof of concepts internally. Or maybe you're going to try and go out and get a new
[00:53:07.120 --> 00:53:17.520]   role as a researcher or a data scientist or whatever. Most people are not going to be
[00:53:17.520 --> 00:53:28.040]   able to rely on their, you know, Stanford PhD to get them there, right? Most people are
[00:53:28.040 --> 00:53:34.920]   going to rely, have to rely on their portfolio. So your portfolio is going to be all the stuff
[00:53:34.920 --> 00:53:43.400]   you build along the way. It's your footprint on the deep learning community. And that footprint
[00:53:43.400 --> 00:53:49.440]   is going to include, you know, think things like your contributions to the Fast AI forums
[00:53:49.440 --> 00:53:58.760]   and your tweets and your stuff on Discord. I would say pretty much every one of the Fast
[00:53:58.760 --> 00:54:07.560]   AI alumni that have come to my attention as being thoughtful and effective community members
[00:54:07.560 --> 00:54:14.720]   all have very, very, very good jobs now. And so like people really, really notice this
[00:54:14.720 --> 00:54:22.800]   footprint, right? So your blog posts, your GitHub projects, these are the things that
[00:54:22.800 --> 00:54:34.200]   are going to get you a job. They probably won't get you a job at a big company, a big
[00:54:34.200 --> 00:54:42.920]   old company in a, you know, kind of standard established IT job, right? That's going to
[00:54:42.920 --> 00:54:47.680]   go through HR and HR, like they're not going to understand any of your GitHub code or know
[00:54:47.680 --> 00:54:52.960]   any about your community impact. They're just going to know about credentials, right? And
[00:54:52.960 --> 00:54:59.720]   you'll come up against somebody with a Stanford PhD and they'll get the job, right? But startups,
[00:54:59.720 --> 00:55:04.600]   really startups from other people who've got similar backgrounds of which there are many
[00:55:04.600 --> 00:55:10.280]   are going to appreciate you or companies that don't really have an established AI group
[00:55:10.280 --> 00:55:22.320]   yet, or the startup you built yourself will certainly appreciate you, right? So it's the
[00:55:22.320 --> 00:55:27.240]   more you've got a portfolio and that you can show that you've really built stuff, the better.
[00:55:27.240 --> 00:55:45.920]   And so start early. Another reason to finish this first course is that it's going to allow
[00:55:45.920 --> 00:55:52.040]   you to do the second course. And if you're doing this live, part two, we're going to
[00:55:52.040 --> 00:55:59.360]   be doing actually a whole new part two towards, you know, basically shortly after this is finished,
[00:55:59.360 --> 00:56:04.920]   right? So if you finish this and do a good job of it, then you could actually be one
[00:56:04.920 --> 00:56:19.500]   of the first to do part two. Now, we've seen how easy Colab is to get started. We've also
[00:56:19.500 --> 00:56:24.080]   talked about some of the downsides of it, right? It's kind of ephemeral. You start from scratch
[00:56:24.080 --> 00:56:28.720]   every time. You've got this kind of hacky stuff of saving notebooks into your Google
[00:56:28.720 --> 00:56:35.960]   Drive, blah, blah, blah. AWS, on the other hand, is going to give you and Google Cloud
[00:56:35.960 --> 00:56:42.400]   and Java Slabs and so forth are going to give you a real Linux server. Okay. And it's going
[00:56:42.400 --> 00:56:50.960]   to cost you, Java Slabs is the cheapest, about 40 cents, AWS, I think about 60 cents US per
[00:56:50.960 --> 00:56:58.160]   hour. It's not going to send you broke, but it's, you know, it's not nothing. But it's
[00:56:58.160 --> 00:57:05.280]   a good idea to try it if you can. And I'm going to show you how to get started there.
[00:57:05.280 --> 00:57:16.060]   And what we might do, Michael, is I'll do some Q&A while things are running. So I'm going
[00:57:16.060 --> 00:57:25.200]   to head over to AWS EC2. Okay. So one of the tricky things about AWS is they've got hundreds
[00:57:25.200 --> 00:57:29.960]   of products. This is Amazon Web Services, and they all have names that are totally meaningless.
[00:57:29.960 --> 00:57:35.000]   Okay. So you just have to know, EC2 is the name of the thing that you go to, to rent
[00:57:35.000 --> 00:57:45.640]   a computer. Okay. So they don't call it Amazon Computer Rental, they call it EC2. So the first
[00:57:45.640 --> 00:57:54.440]   thing you need to do is you need to sign up to AWS. And one of the things that they get
[00:57:54.440 --> 00:57:59.720]   is a lot of fraud. So a lot of people try to use their GPUs to mine Bitcoin. So you have
[00:57:59.720 --> 00:58:05.120]   to ask them to give you permission to use their GPUs. Now that's called requesting a
[00:58:05.120 --> 00:58:11.640]   service limit increase. So you'll need to follow the steps here to ask them for a limit
[00:58:11.640 --> 00:58:17.760]   increase. If you write these exact words with this exact formatting, it might come through
[00:58:17.760 --> 00:58:27.560]   a little bit quicker. If you're from a country where there's a lot of fraud, you might not
[00:58:27.560 --> 00:58:34.840]   even get this permission. Maybe Java Slabs is going to be easier. I'm not sure Java Slabs
[00:58:34.840 --> 00:58:41.620]   even has the fraud check. So anyway, there's quite a few places you can try to get an instance.
[00:58:41.620 --> 00:58:46.520]   So if AWS has a problem with your quota, try somewhere else. But generally speaking, most
[00:58:46.520 --> 00:58:50.660]   people should get a response pretty quickly saying you've now got approved. So for you
[00:58:50.660 --> 00:58:57.160]   doing this course, if you're going to try out AWS EC2, I suggest you log in and request
[00:58:57.160 --> 00:59:02.400]   this service limit increase right away. So that, you know, by the time you come back
[00:59:02.400 --> 00:59:05.840]   tomorrow or the next day, it'll be done. And so what I'm currently doing is I'm on course
[00:59:05.840 --> 00:59:11.200]   fast.ai and I've gone Linux servers, AWS EC2, and we're following through that project
[00:59:11.200 --> 00:59:18.680]   process. Okay. Now to log in to your server, you're going to need to use something called
[00:59:18.680 --> 00:59:26.560]   SSH, Secure Shell. So this is something where on your computer screen, that server's computer
[00:59:26.560 --> 00:59:31.880]   screen effectively is going to appear and the stuff you type is actually running on that
[00:59:31.880 --> 00:59:39.120]   remote server, not on your computer. Nowadays, pretty much nobody uses usernames and passwords
[00:59:39.120 --> 00:59:46.520]   for SSH. Instead, we use something called public key cryptography, which is where you basically
[00:59:46.520 --> 00:59:54.480]   have a secret number, which only you know. And then there's another public number that
[00:59:54.480 --> 01:00:01.520]   you tell other people. And basically there's a really cool math trick, which allows people
[01:00:01.520 --> 01:00:05.780]   to check whether you have the secret number without actually anybody, without actually
[01:00:05.780 --> 01:00:11.320]   telling them the secret number. And the process, so that's called, so that's what an SSH key
[01:00:11.320 --> 01:00:17.280]   is. So there's this thing called a public key, and that's the number that you're, the
[01:00:17.280 --> 01:00:20.680]   code that you're going to give to anybody you want to be able to log into. And then
[01:00:20.680 --> 01:00:27.360]   there's your private key, which you're going to keep for yourself. So you're going to need
[01:00:27.360 --> 01:00:35.640]   a terminal. So on Windows, in the store, there's something called the Windows Terminal, which
[01:00:35.640 --> 01:00:41.520]   Microsoft provides for free, which is pretty good. Mac has a terminal that comes with it.
[01:00:41.520 --> 01:00:48.760]   Linux has a terminal that comes with it. So I'm using Windows, but it'll basically look
[01:00:48.760 --> 01:00:59.960]   the same for everybody. Now on Windows, you need a Ubuntu Linux shell, not a normal Windows
[01:00:59.960 --> 01:01:06.280]   shell. So to do that, you need something called WSL, Windows Subsystem for Linux. And that
[01:01:06.280 --> 01:01:11.600]   will give you a full Ubuntu system on your Windows computer. Again, it's free. It only
[01:01:11.600 --> 01:01:15.520]   takes a couple of minutes to set up. So there's a link to how to do it here. So once you've
[01:01:15.520 --> 01:01:22.320]   done it, whatever, whether you're on Mac or Linux or Windows, it's going to look basically
[01:01:22.320 --> 01:01:30.120]   the same, right? And so you'll create your SSH key by following the instructions in the
[01:01:30.120 --> 01:01:35.880]   documentation, which is basically you run SSH keygen, and it's just going to go through
[01:01:35.880 --> 01:01:45.240]   and create these two files. So you just run it, it creates these two files. And so this
[01:01:45.240 --> 01:01:50.680]   is the one that we have to give Amazon. This is the one that we're going to keep for ourselves.
[01:01:50.680 --> 01:02:05.720]   So following along in the documentation here, it says to click on services, EC2, find key
[01:02:05.720 --> 01:02:23.760]   pairs. Okay, and then we'll go here, import key pair, and whatever, AWS. And this is where
[01:02:23.760 --> 01:02:37.960]   we're going to find the ID RSA pub that we just created. And you can see this, here it
[01:02:37.960 --> 01:02:42.280]   is, right? It's just a big long code. And it's fine, you can all look at this. This is public,
[01:02:42.280 --> 01:02:47.600]   not secret. This is the call thing, right? There's no passwords. And I say import. And
[01:02:47.600 --> 01:02:56.120]   so now we have an SSH key, and we can use that to log in. Okay, so this is just all this
[01:02:56.120 --> 01:03:07.720]   is. Here's all those steps. So renting a server in AWS speak is called launching an instance.
[01:03:07.720 --> 01:03:14.560]   So to launch an instance, we'll scroll back up to the top to instances, and we will say
[01:03:14.560 --> 01:03:22.560]   launch instance. Okay. And it'll say, okay, what kind of thing do you want to run Amazon
[01:03:22.560 --> 01:03:27.520]   Linux or Windows or Red Hat or whatever? I strongly, strongly suggest you use Ubuntu
[01:03:27.520 --> 01:03:33.960]   and the latest version, which is currently 20. So I'm just going to say select. Okay.
[01:03:33.960 --> 01:03:39.520]   And then it'll say, okay, what kind of server do you want? For playing around, there's actually
[01:03:39.520 --> 01:03:44.240]   one that you can get for free. Now it doesn't do, it's pretty, it's kind of slow, right?
[01:03:44.240 --> 01:03:50.080]   But for learning about SSH and Linux and stuff, this is actually a great one to use. It's
[01:03:50.080 --> 01:03:57.360]   no good for deep learning. It doesn't have a GPU. So if I go to G4DN, that's the cheapest
[01:03:57.360 --> 01:04:05.880]   kind of good GPUs we can get. And I'll get the smallest one there. G4DN xlarge. And then
[01:04:05.880 --> 01:04:18.840]   I'll say next. Next. So how big a hard drive do I want? I normally say about 100 gig. Launch.
[01:04:18.840 --> 01:04:25.040]   And launch. And so now it's going to say, okay, when you log into this, which key pair
[01:04:25.040 --> 01:04:31.240]   are you going to use? Okay. So you just select the one that you just imported and say, yep,
[01:04:31.240 --> 01:04:42.040]   I know that I have that. And then launch. And you'll see, Dell says, this has now been initiated.
[01:04:42.040 --> 01:04:47.160]   It's got a code. So this is the thing that I've just launched. So if I click on it, here
[01:04:47.160 --> 01:05:01.640]   it shows me, here's my instance. Okay. So as you, if you haven't done much with servers
[01:05:01.640 --> 01:05:06.400]   and Linux and SSH and stuff, there's going to be this whole world of new stuff for you
[01:05:06.400 --> 01:05:10.560]   to learn about. But this is an opportunity. It's not a problem. So if you're not familiar
[01:05:10.560 --> 01:05:14.760]   with things like IP addresses, that's cool. There's lots of tutorials around at the moment.
[01:05:14.760 --> 01:05:20.840]   But for now, just know this is the unique address, like a street address that your new
[01:05:20.840 --> 01:05:25.080]   computer has. And so we're going to connect to it. So this button here will click, will
[01:05:25.080 --> 01:05:33.960]   copy that address. Okay. So we can then go to our terminal and we can type SSH and paste
[01:05:33.960 --> 01:05:39.360]   in the address. And then the only other thing I do need to do is I need to say, provide
[01:05:39.360 --> 01:05:50.440]   a username and AWS always uses the username Ubuntu for all of its Ubuntu images. So you
[01:05:50.440 --> 01:05:59.120]   say Ubuntu at, and then the IP. And so if I'm now press enter, we're in. Okay. So now
[01:05:59.120 --> 01:06:05.800]   everything I type here is actually being typed on that remote computer. So for example, to
[01:06:05.800 --> 01:06:11.040]   list the contents of a directory, I type LS. Okay. So the thing I'm actually typing into
[01:06:11.040 --> 01:06:15.320]   here is bash, a bash shell. So bash is something, another of these things need to be familiar
[01:06:15.320 --> 01:06:21.320]   with and you can learn about it in that missing semester MIT course I mentioned. You know,
[01:06:21.320 --> 01:06:29.120]   it takes a few weeks to get somewhat comfortable with bash. It's a very different feel to using
[01:06:29.120 --> 01:06:33.920]   a GUI if you're more familiar with explorer or finder or whatever, but you'll find it's,
[01:06:33.920 --> 01:06:38.280]   will be much more productive soon enough because you can replicate things quickly. You can
[01:06:38.280 --> 01:06:43.920]   script things, you can copy and paste things and so forth. Anyway, so here's my, here's
[01:06:43.920 --> 01:06:54.800]   my computer. It's going to sit here running until you tell it not to. Even if you turn
[01:06:54.800 --> 01:06:58.960]   your computer off, your server is still running and that means you're still paying for it.
[01:06:58.960 --> 01:07:04.440]   Okay. So one of the things I guarantee you're going to learn the hard way by wasting money
[01:07:04.440 --> 01:07:10.400]   is that you're going to forget to turn it off. Okay. So to turn it off, you're just going
[01:07:10.400 --> 01:07:20.480]   to go stop instance. Okay. So you make sure you do that. All right. Let's see how we're
[01:07:20.480 --> 01:07:38.840]   going here. So we've launched our instance and we SSH into it. Okay. So keeping a Linux
[01:07:38.840 --> 01:07:48.960]   server up to date and running used to be kind of annoying, but luckily I've created something
[01:07:48.960 --> 01:07:55.280]   called fast set up for you, which makes it easy. And all you need to do is copy this
[01:07:55.280 --> 01:07:59.260]   and paste it into your terminal. And this is one of the really cool things about Linux
[01:07:59.260 --> 01:08:05.400]   and using bash is like in windows or with Mac finder, you'd have pages and pages of
[01:08:05.400 --> 01:08:09.960]   click this and drag that and scroll here. But I've just scripted the whole thing. So
[01:08:09.960 --> 01:08:16.520]   I'm just going to go ahead and paste it over here and it's off. Okay. Now what this is
[01:08:16.520 --> 01:08:22.720]   going to do is it's going to fully set up this Linux server. It's going to make it automatically
[01:08:22.720 --> 01:08:31.760]   update with the latest software. It's going to configure it all correctly. And so forth.
[01:08:31.760 --> 01:08:34.960]   And it's going to ask a minimum number of questions. So I'm just going to show you the
[01:08:34.960 --> 01:08:39.480]   questions it's going to ask you. It's going to ask for a host name. So a host name is just
[01:08:39.480 --> 01:08:44.000]   a more convenient way to access a server. And so you can basically write anything you
[01:08:44.000 --> 01:08:50.580]   like as long as it's got at least two dots in it. So I'm going to call this course test
[01:08:50.580 --> 01:08:59.280]   dot fast dot AI, for example. Okay. And then after an email address. Now the email address
[01:08:59.280 --> 01:09:04.480]   is basically just goes where it's going to send kind of error locks and stuff too. So
[01:09:04.480 --> 01:09:12.000]   maybe we'll say info at fast dot AI. Okay. Do you want to set a password? Probably do.
[01:09:12.000 --> 01:09:23.720]   So hit enter for yes. So I'm going to put in a password. Ask you to type it again. Okay.
[01:09:23.720 --> 01:09:29.120]   Reboot automatically when required. I'll say yes. And that's it. Okay. So that's all the
[01:09:29.120 --> 01:09:41.280]   information that it needed. So behind the scenes. What's actually happening here. Is
[01:09:41.280 --> 01:09:48.800]   it's grabbed the latest get repo from fast set up. And it's running this thing called
[01:09:48.800 --> 01:09:53.600]   Ubuntu initial. And you know this is something you can check out if you're interested. It's
[01:09:53.600 --> 01:10:02.480]   basically 125 lines of bash script, which is going to set up your firewall for you, set
[01:10:02.480 --> 01:10:08.440]   up SSH security for you, set up your swap file for you, set up your SSH configuration
[01:10:08.440 --> 01:10:13.960]   for you, install all the software you need for you, set up your logging and upgrades
[01:10:13.960 --> 01:10:23.200]   for you, set up your password and host name for you. Okay. So it's going to do all that.
[01:10:23.200 --> 01:10:25.880]   And you know this is the kind of thing that if you, you know from time to time you can
[01:10:25.880 --> 01:10:31.720]   just might think oh I'm interested in how X works. And since everything is open source
[01:10:31.720 --> 01:10:37.040]   you can just go in and see how X works. And at first none of this might make any sense.
[01:10:37.040 --> 01:10:42.320]   And so you go oh all right let's pick something and learn about it. Enable firewall. UFW. No
[01:10:42.320 --> 01:10:51.720]   what's UFW? Copy, paste. UFW. Probably not United Farm Workers. Uncomplicated firewall.
[01:10:51.720 --> 01:10:55.960]   Did Jeremy mention firewall? Okay. What the hell's a firewall? And you know you can start
[01:10:55.960 --> 01:11:03.560]   reading right. And then you could be like oh maybe firewall tutorial. Often adding tutorial
[01:11:03.560 --> 01:11:10.240]   can be helpful. Okay. So you know you can start to just jump in here and there. Okay. Don't
[01:11:10.240 --> 01:11:14.800]   get too distracted. We want to spend as much time as possible training models. But this
[01:11:14.800 --> 01:11:24.640]   is how we learn about our tools. Okay. So this is now going and downloading the latest version
[01:11:24.640 --> 01:11:28.600]   of all the software that it's going to need from Linux. So it may be a good time for questions
[01:11:28.600 --> 01:11:34.480]   if we have any Michael. What's your current opinion regarding Swift and Julia as replacements
[01:11:34.480 --> 01:11:43.440]   of Python? So Swift is basically out now. So Google has basically archived the Swift for
[01:11:43.440 --> 01:11:52.600]   TensorFlow project. So you can safely ignore that. Yeah. Julia is interesting. You know
[01:11:52.600 --> 01:12:04.280]   I think it's a lovely language. Nothing has the ecosystem that Python does. So you know
[01:12:04.280 --> 01:12:08.440]   if you use Julia you're going to have to figure out a lot more stuff on your own and you'll
[01:12:08.440 --> 01:12:13.640]   find a lot more hard edges. But I do think at some point Python is going to have to be
[01:12:13.640 --> 01:12:20.680]   replaced and Julia seems like one of if not the most likely thing to replace it. Or maybe
[01:12:20.680 --> 01:12:25.320]   it won't be replaced by Julia. Maybe there will be replaced by something else that's
[01:12:25.320 --> 01:12:31.840]   kind of Python like Jax which actually takes Python and compiles it using something called
[01:12:31.840 --> 01:12:48.980]   XLA into a much faster thing than Python otherwise would be. Okay. Do you think that deep learning
[01:12:48.980 --> 01:12:55.400]   or more traditional ML or stats approaches are more useful for traditional industry applications
[01:12:55.400 --> 01:13:01.240]   right now? So before I answer that question I'm going to press Y which is going to reboot
[01:13:01.240 --> 01:13:08.200]   our computer now that it's all updated. And obviously when we reboot that computer running
[01:13:08.200 --> 01:13:15.000]   at the AWS data center it closes the connection because it's busy rebooting. Okay so we'll
[01:13:15.000 --> 01:13:24.360]   give it a couple of minutes. There's not a single good answer to that question and you
[01:13:24.360 --> 01:13:31.880]   don't really need to answer that question because basically any time you want to try
[01:13:31.880 --> 01:13:38.920]   any kind of machine learning model on a problem you should try a few different algorithms.
[01:13:38.920 --> 01:13:43.120]   And switching from a random forest to a gradient boosting machine to logistic regression to
[01:13:43.120 --> 01:13:53.160]   deep learning is you know an extra half hour. So you should just try a few different approaches.
[01:13:53.160 --> 01:14:00.920]   I find personally for me deep learning is increasingly turning out to be the easiest
[01:14:00.920 --> 01:14:07.680]   thing to get started with and gives me the best results for most projects I seem to do
[01:14:07.680 --> 01:14:12.280]   nowadays. But you know have a look at like Kaggle competitions from time to time there
[01:14:12.280 --> 01:14:18.640]   are still things where gradient boosting machines work better or very often people use both
[01:14:18.640 --> 01:14:25.000]   and ensemble them. But yeah it's not a question that you actually need to answer because it's
[01:14:25.000 --> 01:14:30.480]   you want to get to a point where it just takes you a few minutes to try another algorithm
[01:14:30.480 --> 01:14:36.040]   out and so you don't need to be wedded to one or the other. So I'm just going to see
[01:14:36.040 --> 01:14:39.040]   if I could I don't know how long it's going to take to reboot so I'm just going to I just
[01:14:39.040 --> 01:14:42.840]   pressed up arrow to get back my last SSH command and I'll press enter and we'll see if we're
[01:14:42.840 --> 01:14:56.080]   back we're back. OK so this is finished rebooting. Oh actually this time it says to do something
[01:14:56.080 --> 01:15:00.440]   slightly different which is to add this minus L here. This is the thing that's going to
[01:15:00.440 --> 01:15:07.400]   let us connect to Jupyter Notebook. So I'm going to type excerpt to excerpt from the server
[01:15:07.400 --> 01:15:17.040]   and this time I'm going to add the extra bit of the command. There we go. OK and all right
[01:15:17.040 --> 01:15:20.520]   so the next thing is we're going to install something called MIDI Conda. MIDI Conda is
[01:15:20.520 --> 01:15:30.480]   a very nice distribution of Python the programming language. A lot of people have bad experiences
[01:15:30.480 --> 01:15:37.600]   of their computers getting really confused with Python packages and things conflicting
[01:15:37.600 --> 01:15:43.280]   and all kinds of stuff like that. That's because pretty much all the major operating systems
[01:15:43.280 --> 01:15:49.680]   now come with a version of Python that is used by your computer for you know important
[01:15:49.680 --> 01:15:54.680]   operating system tasks. You should not be using that Python to train your machine learning
[01:15:54.680 --> 01:16:02.280]   models. Leave that Python alone. Right. You should always install many Conda which is
[01:16:02.280 --> 01:16:05.980]   going to give you your own version of Python which is nothing to do with your operating
[01:16:05.980 --> 01:16:12.720]   system as you can play around with as you like. It's really easy just you can delete
[01:16:12.720 --> 01:16:17.600]   the whole folder and create it again in like three minutes. You can create new environments
[01:16:17.600 --> 01:16:22.160]   which is like little testing grounds. You can try different things. This is a very strong
[01:16:22.160 --> 01:16:27.960]   recommendation is to make sure that you install even if you're just playing around on Windows
[01:16:27.960 --> 01:16:33.880]   or a Mac not on a server install many Conda. It's cross platform. You can use it everywhere
[01:16:33.880 --> 01:16:43.440]   and use that Python. OK. So many Conda is now installed. So we now have our own Python
[01:16:43.440 --> 01:16:54.080]   setup. So the last setup step is we have to install drivers for the GPU and Ubuntu actually
[01:16:54.080 --> 01:16:59.680]   comes with something that figures out for you what the best drivers are for your device.
[01:16:59.680 --> 01:17:04.280]   So this is just what this step here is. And so I'm going to look down. Look here it says
[01:17:04.280 --> 01:17:10.960]   recommended. OK. So here's the driver I want. OK. But what I actually recommend is you use
[01:17:10.960 --> 01:17:15.760]   that but also the one at the dash server to the end. That's going to make like not install
[01:17:15.760 --> 01:17:23.240]   the stuff for playing computer games or whatever. OK. So let's go ahead and run these lines
[01:17:23.240 --> 01:17:28.360]   of code. This is a bit here. See this is 460 depending on your graphics card. When you
[01:17:28.360 --> 01:17:33.200]   run this you might have some different number. OK. But since I wrote this today it's still
[01:17:33.200 --> 01:17:43.680]   460. So we'll go ahead and do that. And this is going to go ahead and install this. Oh
[01:17:43.680 --> 01:17:51.040]   pseudo pseudo is a special thing you can add to the front of a command that runs it as
[01:17:51.040 --> 01:17:59.720]   an administrator. OK. So some things you know by default commands you run basically can't
[01:17:59.720 --> 01:18:05.000]   break your system. Right. Where else things like installing new software you have to tell
[01:18:05.000 --> 01:18:09.480]   it to run it as an administrator. So when you do that it'll ask you for your password.
[01:18:09.480 --> 01:18:16.020]   This is the password that you put in just just a moment ago with the setup. There we
[01:18:16.020 --> 01:18:38.080]   go. OK. Is there a section of the course that people skip over too quickly. Yes. Part two.
[01:18:38.080 --> 01:18:46.680]   But not enough people do part two. And the difference between part one and part two is
[01:18:46.680 --> 01:18:55.600]   the difference between being a pretty handy practitioner you know who can who can do some
[01:18:55.600 --> 01:19:03.120]   pretty good work as long as it's in reasonably well established kinds of areas and versus
[01:19:03.120 --> 01:19:07.800]   being somebody who understands how everything's put together you could you know if you're
[01:19:07.800 --> 01:19:12.240]   told to create a deep learning model on in a domain that's like there are no published
[01:19:12.240 --> 01:19:17.560]   models you'll be able to create one. If you'll you'll understand how to create models which
[01:19:17.560 --> 01:19:29.800]   combine multiple different data types you know you'll it's it's yeah it's it's a really
[01:19:29.800 --> 01:19:38.480]   big thing to to finish and not enough people realize how much is is there. And just the
[01:19:38.480 --> 01:19:47.000]   later lessons in in general you know it can like after you've done three lessons you you
[01:19:47.000 --> 01:19:52.720]   are pretty handy and you'll feel pretty handy right. But it's pretty easy to stop there
[01:19:52.720 --> 01:20:00.720]   because it feels like OK I get it you know I can train a model I get what's going on
[01:20:00.720 --> 01:20:07.440]   and to be fair it does very dramatically kind of scale up in terms of intensity after that
[01:20:07.440 --> 01:20:12.560]   because in lesson 4 you'll have to write your own optimizer from scratch and you'll be getting
[01:20:12.560 --> 01:20:20.120]   into the calculus and stuff. But you know it it it is a big difference in terms of what
[01:20:20.120 --> 01:20:25.340]   what you can do and what you understand. So I think in general you know not enough people
[01:20:25.340 --> 01:20:34.680]   are getting deeper into the lessons. OK. So this is now finished installing the Nvidia
[01:20:34.680 --> 01:20:41.640]   drivers. Normally at this point people say to reboot but there's actually a magic thing
[01:20:41.640 --> 01:20:49.920]   you can do which means you don't have to reboot. And the Nvidia provides something called Nvidia
[01:20:49.920 --> 01:20:56.680]   SMI which will tell you about your installed GPUs. And so if you run it and it pops up
[01:20:56.680 --> 01:21:01.800]   anything at all other than an error it means that you are successfully have your GPUs installed.
[01:21:01.800 --> 01:21:11.720]   So in this case we have a Tesla T4. It's currently 36 centigrade in there and the most important
[01:21:11.720 --> 01:21:17.200]   thing to know about is that it has 15 gigabytes of memory of which we're using nothing at
[01:21:17.200 --> 01:21:25.040]   all. And there are no processors currently running on the GPU. So if you're finding something's
[01:21:25.040 --> 01:21:30.120]   going very slowly and you're wondering maybe it's not using the GPU you can always run
[01:21:30.120 --> 01:21:39.680]   Nvidia SMI and if it says no running process is found you're not using the GPU. OK. OK.
[01:21:39.680 --> 01:21:47.040]   So one more setup step which is we have to install all of the software all of the Python
[01:21:47.040 --> 01:21:53.840]   libraries needed. So PyTorch, FastAI, Jupyter Notebook and so forth. And so I've created
[01:21:53.840 --> 01:22:00.320]   a package which has that whole lot. It's called Fastbook. If you're if you've used had a condor
[01:22:00.320 --> 01:22:05.660]   or mini condor before you might be surprised who says Mamba rather than condor. You should
[01:22:05.660 --> 01:22:11.160]   definitely use Mamba and not condor. It's way way way faster. So anytime you see something
[01:22:11.160 --> 01:22:20.760]   saying condor install you should instead type Mamba install. It's way faster. OK. So off
[01:22:20.760 --> 01:22:26.440]   it goes. Members now going to install all of the all this Python software getting installed
[01:22:26.440 --> 01:22:35.880]   for us. PyTorch is well over a gigabyte. So this is going to take a few minutes just because
[01:22:35.880 --> 01:22:41.600]   it has to download that that whole thing. And yeah that can take a while. So while this
[01:22:41.600 --> 01:22:50.640]   is going do we got any more questions Michael. Do you recommend any software for experiment
[01:22:50.640 --> 01:23:00.480]   tracking. So the most popular experiment tracking software would be TensorBoard and Weights
[01:23:00.480 --> 01:23:08.080]   and Biases. Experiment tracking software is stuff which will basically you can use a faster
[01:23:08.080 --> 01:23:14.720]   call back and you basically will say train whilst tracking with TensorBoard or train
[01:23:14.720 --> 01:23:20.920]   whilst tracking with Weights and Biases. And what it will do is it will kind of create
[01:23:20.920 --> 01:23:26.160]   a little database showing you all the training results from all the different experiments
[01:23:26.160 --> 01:23:35.920]   you've run and create some little graphs of them and so forth. Personally I don't use any
[01:23:35.920 --> 01:23:43.480]   experiment tracking software. And the reason I don't is I found that many many many people
[01:23:43.480 --> 01:23:49.000]   just about everybody I know who uses them finds it incredibly distracting. So the trick
[01:23:49.000 --> 01:23:54.560]   to training models is don't watch them train. So if you've done any C programming it's like
[01:23:54.560 --> 01:24:03.400]   don't watch it compile right. Go and do something else preferably set up your next experiment.
[01:24:03.400 --> 01:24:08.240]   Experiment tracking software just makes it so tempting to look at all the pretty graphs
[01:24:08.240 --> 01:24:18.160]   in my opinion. So I would suggest get it running leave come back when it's done and there should
[01:24:18.160 --> 01:24:26.880]   be a bit of reason you were running that experiment. So check whatever that reason was right. Having
[01:24:26.880 --> 01:24:33.680]   said that if you're really sure you need the services of experiment tracking software
[01:24:33.680 --> 01:24:39.120]   for what you're doing and there are some things that genuinely need it then I think Weights
[01:24:39.120 --> 01:24:46.360]   and Biases is the best at the moment. I think it's really great. And furthermore they've
[01:24:46.360 --> 01:24:59.880]   hired lots of fast AI alumni and they're super nice people. So definitely recommend that.
[01:24:59.880 --> 01:25:06.760]   So that's all the installation. So the last step is just to grab the book the notebooks.
[01:25:06.760 --> 01:25:11.640]   And so you use something called get clone to grab a repository of code and this is going
[01:25:11.640 --> 01:25:25.680]   to grab the fast book repository. Paste. So you can see it's saying cloning this repository.
[01:25:25.680 --> 01:25:34.000]   And so you'll now find that there is a fast book directory so you can CD into it. And
[01:25:34.000 --> 01:25:43.280]   there is our book. OK. So I think something on Anaconda is going slowly so we're not going
[01:25:43.280 --> 01:25:48.480]   to wait for it to download. But so I want to show the very last step. But the very last
[01:25:48.480 --> 01:25:54.000]   step is to run Jupyter Notebook and then you'll be able to click on the URL that pops up and
[01:25:54.000 --> 01:25:59.640]   it'll bring up something that basically looks just like we saw in Colab. But the nice thing
[01:25:59.640 --> 01:26:07.800]   is everything you save like everything you do will be remembered. So all of your experiments
[01:26:07.800 --> 01:26:17.400]   are going to be there. The data sets you download is still there. So on and so forth. So that's
[01:26:17.400 --> 01:26:26.840]   that. So when you're done it will remind you here to as I mentioned before stop your instance.
[01:26:26.840 --> 01:26:35.600]   So you can either choose stop in this menu or you can choose stop here. Or personally
[01:26:35.600 --> 01:26:41.800]   what I quite like to do is to run pseudo. Remember pseudo is this thing that runs as
[01:26:41.800 --> 01:26:49.760]   an administrator shut down halt now. And so that shuts it down from here without having
[01:26:49.760 --> 01:27:08.120]   to go into the AWS GUI. And there we go. OK. So if we look back at the EC2 here in a moment
[01:27:08.120 --> 01:27:17.680]   this will switch from running state to stop state. OK. So I think that's everything Michael
[01:27:17.680 --> 01:27:25.120]   is there anything else to cover. OK. Great. All right. Well thank you everybody for listening
[01:27:25.120 --> 01:27:38.120]   into Lesson 0. And I look forward to hearing how you go with Lesson 1 and seeing your projects
[01:27:38.120 --> 01:27:45.160]   that you create. And don't forget to get involved in the forums. If you do get stuck with something
[01:27:45.160 --> 01:27:50.080]   the first thing to do is to search the forums because out of the hundreds of thousands of
[01:27:50.080 --> 01:27:54.320]   people that have done this before somebody's probably got stuck in the same way before.
[01:27:54.320 --> 01:27:58.440]   So hopefully they can answer your question. Otherwise feel free to ask your own questions
[01:27:58.440 --> 01:28:03.160]   and hopefully somebody will answer for you. Thanks everybody. Bye.
[01:28:03.160 --> 01:28:06.160]   (audience applauds)

