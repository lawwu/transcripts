
[00:00:00.000 --> 00:00:01.440]   Hi, guys.
[00:00:01.440 --> 00:00:07.100]   So I'm Adrian, and you already gave my first couple of slides.
[00:00:07.100 --> 00:00:09.360]   I was a professor at Carnegie Mellon
[00:00:09.360 --> 00:00:11.440]   working on big data and machine learning
[00:00:11.440 --> 00:00:15.240]   way before it was cool, and then worked at Google X
[00:00:15.240 --> 00:00:18.720]   on some top secret projects and on self-driving cars at Zoox,
[00:00:18.720 --> 00:00:21.800]   and then about five years ago started
[00:00:21.800 --> 00:00:24.520]   a company called Streamlet.
[00:00:24.520 --> 00:00:27.620]   And Streamlet was based on the idea
[00:00:27.620 --> 00:00:31.160]   that for machine learning engineers like us,
[00:00:31.160 --> 00:00:36.840]   it was really easy to build Python scripts, little bits
[00:00:36.840 --> 00:00:40.560]   of Python that would read some data and transform that data,
[00:00:40.560 --> 00:00:44.160]   and then write the results to a file.
[00:00:44.160 --> 00:00:46.120]   But the kind of coding that was required
[00:00:46.120 --> 00:00:49.120]   to create complex apps involving a stack
[00:00:49.120 --> 00:00:52.160]   with many different languages and callbacks
[00:00:52.160 --> 00:00:54.920]   was a much harder thing to do.
[00:00:54.920 --> 00:00:58.920]   And so we had this idea that really the machine learning
[00:00:58.920 --> 00:01:04.720]   community needed a way to build apps using their own language.
[00:01:04.720 --> 00:01:06.720]   And so we came up with this thought
[00:01:06.720 --> 00:01:10.000]   that there was a new way of writing apps in which
[00:01:10.000 --> 00:01:12.640]   your so-called machine learning app just
[00:01:12.640 --> 00:01:16.440]   felt like a little Python script that you loaded some data,
[00:01:16.440 --> 00:01:19.100]   transformed it, and saved it.
[00:01:19.100 --> 00:01:21.440]   And of course, it's not just about
[00:01:21.440 --> 00:01:25.560]   the technical theoretical underpinnings
[00:01:25.560 --> 00:01:26.800]   of this kind of thing.
[00:01:26.800 --> 00:01:31.080]   We also wanted to make it just super, super easy and fun
[00:01:31.080 --> 00:01:34.840]   and just feel really good in the hand to use.
[00:01:34.840 --> 00:01:40.560]   In fact, there is this amazing idea from the game design
[00:01:40.560 --> 00:01:44.040]   community, which is that when a game is toy-like--
[00:01:44.040 --> 00:01:47.260]   do you know what toy-like means?
[00:01:47.260 --> 00:01:48.920]   It means that you can play with it
[00:01:48.920 --> 00:01:52.320]   without even knowing the rules.
[00:01:52.320 --> 00:01:55.000]   It's something that you want to play with and hold,
[00:01:55.000 --> 00:01:59.420]   even like a GI Joe, even if you don't have any specific rules.
[00:01:59.420 --> 00:02:02.080]   And we wanted to give Streamlet that sensibility.
[00:02:02.080 --> 00:02:10.780]   So five years ago, we wrote a little post in Medium,
[00:02:10.780 --> 00:02:15.440]   and we explained what this thing was and what we were building.
[00:02:15.440 --> 00:02:20.000]   And how many of you are startup founders?
[00:02:20.000 --> 00:02:20.680]   Raise your hand.
[00:02:20.680 --> 00:02:22.280]   OK.
[00:02:22.280 --> 00:02:26.840]   All right, so we're like 10% startup founders, maybe 5%.
[00:02:26.840 --> 00:02:29.360]   Well, you'll all recall what it felt
[00:02:29.360 --> 00:02:33.260]   like when you launched your product for the first time.
[00:02:33.260 --> 00:02:36.160]   We launched it, and we held our breath,
[00:02:36.160 --> 00:02:39.400]   and it felt like nothing was happening.
[00:02:39.400 --> 00:02:43.520]   And then all of a sudden, it just worked.
[00:02:43.520 --> 00:02:48.520]   And Streamlet turned into one of the fastest-growing machine
[00:02:48.520 --> 00:02:52.120]   learning and data science open-source projects
[00:02:52.120 --> 00:02:54.080]   of all time.
[00:02:54.080 --> 00:02:57.560]   And so last year, we were lucky enough
[00:02:57.560 --> 00:03:01.200]   to be acquired by Snowflake.
[00:03:01.200 --> 00:03:03.800]   And this had allowed us to do a number
[00:03:03.800 --> 00:03:06.960]   of extremely interesting things and really give us
[00:03:06.960 --> 00:03:09.940]   a different purchase on the world.
[00:03:09.940 --> 00:03:12.820]   Not only can we continue to develop Streamlet,
[00:03:12.820 --> 00:03:15.800]   which is super fun, and grow the community, which
[00:03:15.800 --> 00:03:18.240]   is still growing very quickly, but we also
[00:03:18.240 --> 00:03:24.000]   get access to Snowflake's unbelievable set of customers.
[00:03:24.000 --> 00:03:29.320]   And we've been developing a first-class implementation
[00:03:29.320 --> 00:03:32.120]   of Streamlet in Snowflake that lets
[00:03:32.120 --> 00:03:35.920]   you take all the fun and ease and quickness of building
[00:03:35.920 --> 00:03:40.000]   Streamlet apps and use the integrated IDE in Snowflake
[00:03:40.000 --> 00:03:42.440]   and share it with other people in your company.
[00:03:42.440 --> 00:03:45.100]   So this is not released quite yet,
[00:03:45.100 --> 00:03:48.980]   but it's in private preview with a couple hundred Snowflake
[00:03:48.980 --> 00:03:52.380]   customers, and we're really excited about it.
[00:03:52.380 --> 00:04:00.800]   But this isn't just a talk about Streamlet and Snowflake.
[00:04:00.800 --> 00:04:06.060]   This is also a talk about Streamlet and LLMs.
[00:04:06.060 --> 00:04:10.820]   Because remember when I said that Streamlet was
[00:04:10.820 --> 00:04:16.020]   one of the fastest growing open source machine learning and data
[00:04:16.020 --> 00:04:20.980]   science libraries of all time, whatever that means?
[00:04:20.980 --> 00:04:22.220]   Right?
[00:04:22.220 --> 00:04:28.420]   Well, six months ago, this crap happened.
[00:04:28.420 --> 00:04:30.860]   Yeah.
[00:04:30.860 --> 00:04:36.060]   I mean, it's just super embarrassing, you know?
[00:04:36.060 --> 00:04:40.180]   And we've been working on this for a long time,
[00:04:40.180 --> 00:04:44.380]   and I think if you look at a graph like this,
[00:04:44.380 --> 00:04:47.180]   there's really only one conclusion that you can
[00:04:47.180 --> 00:04:51.220]   possibly come to, which is that we spent way too
[00:04:51.220 --> 00:04:52.300]   much money on our website.
[00:04:52.300 --> 00:05:06.700]   But actually, as we all know, this isn't a passing fad.
[00:05:06.700 --> 00:05:14.500]   We are actually living truly in one of the most amazing years
[00:05:14.500 --> 00:05:18.700]   in human history right now.
[00:05:18.700 --> 00:05:21.940]   It's just amazing to be alive.
[00:05:21.940 --> 00:05:27.900]   2023 was really the year where LLMs, generative AI,
[00:05:27.900 --> 00:05:32.100]   exploded into our consciousness.
[00:05:32.100 --> 00:05:36.300]   And it's had an extremely profound effect on Streamlet
[00:05:36.300 --> 00:05:37.900]   as well.
[00:05:37.900 --> 00:05:41.900]   It turns out that Streamlet is an amazing way
[00:05:41.900 --> 00:05:44.860]   to write LLM apps.
[00:05:44.860 --> 00:05:48.300]   And so we've actually seen GPT-0.
[00:05:48.300 --> 00:05:50.620]   Do you guys remember GPT-0?
[00:05:50.620 --> 00:05:53.420]   So this was an app created by a Princeton student which
[00:05:53.420 --> 00:05:57.780]   allows you to determine whether or not text was generated
[00:05:57.780 --> 00:06:00.100]   by GPT, or at least estimate whether or not
[00:06:00.100 --> 00:06:01.300]   that's the case.
[00:06:01.300 --> 00:06:03.100]   It was released on Streamlet.
[00:06:03.100 --> 00:06:06.660]   And that led to this explosion of Streamlet apps,
[00:06:06.660 --> 00:06:12.820]   which all use GPT on the back end in order to-- or GPT
[00:06:12.820 --> 00:06:15.340]   or other LLMs, I should say, on the back end--
[00:06:15.340 --> 00:06:20.860]   in order to provide these really amazing generative experiences.
[00:06:20.860 --> 00:06:26.300]   And so the sort of explosion in generative AI
[00:06:26.300 --> 00:06:28.900]   over the past couple of months has really
[00:06:28.900 --> 00:06:32.260]   started to change what Streamlet is.
[00:06:32.260 --> 00:06:35.300]   And we're seeing it just amazingly
[00:06:35.300 --> 00:06:38.860]   change our own statistics.
[00:06:38.860 --> 00:06:45.720]   So we now have 150,000 unique monthly active developers
[00:06:45.720 --> 00:06:48.000]   that we know of.
[00:06:48.000 --> 00:06:50.180]   And they are generating apps which
[00:06:50.180 --> 00:06:56.460]   are being viewed 3.6 million unique times every month.
[00:06:56.460 --> 00:06:59.300]   So it's pretty remarkable.
[00:06:59.300 --> 00:07:03.380]   Now, it's very interesting to watch
[00:07:03.380 --> 00:07:08.420]   this observe happen from inside a company like Snowflake.
[00:07:08.420 --> 00:07:12.340]   Because from the perspective of a Snowflake customer,
[00:07:12.340 --> 00:07:15.260]   really for the past 10 years, the world
[00:07:15.260 --> 00:07:16.820]   has kind of looked like this.
[00:07:16.820 --> 00:07:22.220]   You will have a stakeholder, which
[00:07:22.220 --> 00:07:24.300]   will come to you in the data science group
[00:07:24.300 --> 00:07:27.900]   and ask you to, let's say, write a query
[00:07:27.900 --> 00:07:30.540]   or perhaps create a visualization.
[00:07:30.540 --> 00:07:35.380]   And of course, inevitably, it's not the right query,
[00:07:35.380 --> 00:07:37.220]   and it's not the right visualization.
[00:07:37.220 --> 00:07:40.300]   And so these things happen over and over and over
[00:07:40.300 --> 00:07:42.860]   again in this iterative loop.
[00:07:42.860 --> 00:07:46.840]   And this is really the world of a data scientist or a data
[00:07:46.840 --> 00:07:48.900]   engineer today.
[00:07:48.900 --> 00:07:52.060]   And with the advent of generative AI,
[00:07:52.060 --> 00:07:55.900]   we now have the ability to do something really profound,
[00:07:55.900 --> 00:07:59.660]   which is give the stakeholder the ability
[00:07:59.660 --> 00:08:03.180]   to iterate directly on the results that they're getting.
[00:08:03.180 --> 00:08:09.700]   And of course, what this looks like is we generate a chatbot.
[00:08:09.700 --> 00:08:12.360]   And with this chatbot, we basically
[00:08:12.360 --> 00:08:17.260]   give the stakeholder the ability not just to say, I want this,
[00:08:17.260 --> 00:08:20.740]   but no, not quite that.
[00:08:20.740 --> 00:08:24.560]   And it was realizing this for me that
[00:08:24.560 --> 00:08:30.260]   made me realize that this chat interface thing is really--
[00:08:30.260 --> 00:08:33.940]   it's not just an artifact of a particular way
[00:08:33.940 --> 00:08:39.580]   that OpenAI released their product for now.
[00:08:39.580 --> 00:08:42.620]   It's actually a fundamental paradigm
[00:08:42.620 --> 00:08:47.060]   of the generative AI LLM world, that you'd
[00:08:47.060 --> 00:08:51.220]   want the ability to tell the app not quite this,
[00:08:51.220 --> 00:08:55.840]   a little bit more of that over and over and over again,
[00:08:55.840 --> 00:09:00.080]   and sort of co-interact with it to generate the result
[00:09:00.080 --> 00:09:02.520]   that you want.
[00:09:02.520 --> 00:09:10.640]   Now, I was going to live code a Streamlit chatbot, which
[00:09:10.640 --> 00:09:13.280]   was going to be super awesome.
[00:09:13.280 --> 00:09:20.160]   But I didn't have time to get the template working.
[00:09:20.160 --> 00:09:24.980]   So I'm going to instead show you what this looks like.
[00:09:24.980 --> 00:09:27.300]   And we're going to do some live coding.
[00:09:27.300 --> 00:09:29.820]   Don't worry, just that template.
[00:09:29.820 --> 00:09:30.460]   Where are you?
[00:09:30.460 --> 00:09:46.740]   And so this allows us to quickly build a chatbot in Streamlit.
[00:09:46.740 --> 00:09:50.640]   In this case, just doing nothing interesting,
[00:09:50.640 --> 00:09:53.980]   but interact with an LLM under the hood.
[00:09:53.980 --> 00:09:55.860]   In this case, it's Anthropx LLM.
[00:09:55.860 --> 00:10:02.500]   And this is about 15 lines of Streamlit.
[00:10:02.500 --> 00:10:05.420]   And notably, not just 15 lines where we hermetically
[00:10:05.420 --> 00:10:06.660]   sealed it all.
[00:10:06.660 --> 00:10:08.900]   Of course, you could do this in one line of Streamlit
[00:10:08.900 --> 00:10:10.800]   if you wanted to have an API like that.
[00:10:10.800 --> 00:10:15.780]   This is 15 lines of Streamlit in which
[00:10:15.780 --> 00:10:19.340]   every part of it can be understood, pulled apart,
[00:10:19.340 --> 00:10:20.900]   and customized.
[00:10:20.900 --> 00:10:25.140]   And of course, that lets you do really interesting things
[00:10:25.140 --> 00:10:33.020]   like basically intercept the input from the user,
[00:10:33.020 --> 00:10:36.540]   alter it on its way to the LLM.
[00:10:36.540 --> 00:10:39.460]   We haven't gotten into chain of thought yet.
[00:10:39.460 --> 00:10:42.660]   Alter it however you want on its way to the LLM,
[00:10:42.660 --> 00:10:46.180]   and then interpret the results on the way back,
[00:10:46.180 --> 00:10:48.860]   which essentially gives you the ability
[00:10:48.860 --> 00:10:52.420]   to create an arbitrarily programmable chatbot.
[00:10:52.420 --> 00:10:56.100]   So this is a very, very simple chatbot, which again,
[00:10:56.100 --> 00:11:00.180]   is only a few lines more of code than the most basic one,
[00:11:00.180 --> 00:11:06.020]   which actually asks the LLM to generate SQL queries.
[00:11:06.020 --> 00:11:08.000]   And then based on those SQL queries,
[00:11:08.000 --> 00:11:12.260]   execute them on behalf of your private data.
[00:11:12.260 --> 00:11:21.340]   So the point here is that we've created a way on behalf
[00:11:21.340 --> 00:11:25.620]   of Snowflake's customers to very rapidly access
[00:11:25.620 --> 00:11:29.020]   the power of LLMs and their private data
[00:11:29.020 --> 00:11:33.260]   and create bespoke chat apps with the same speed
[00:11:33.260 --> 00:11:36.260]   that they can generate Streamlit apps in general
[00:11:36.260 --> 00:11:40.980]   to do arbitrary data analyses.
[00:11:40.980 --> 00:11:42.900]   OK.
[00:11:42.900 --> 00:11:47.260]   So we talked about the fact that Streamlit--
[00:11:47.260 --> 00:11:52.020]   there's been an explosion of LLM apps generated using Streamlit,
[00:11:52.020 --> 00:11:52.660]   a.k.a.
[00:11:52.660 --> 00:11:56.540]   the Streamlit app, which then calls the API of an LLM, which
[00:11:56.540 --> 00:11:58.660]   then does interesting things.
[00:11:58.660 --> 00:12:00.940]   And there are thousands of these,
[00:12:00.940 --> 00:12:03.420]   and we have a web page about it now.
[00:12:03.420 --> 00:12:08.820]   But there's a sort of flip side to this, which is interesting,
[00:12:08.820 --> 00:12:17.140]   which is that not only is Streamlit an amazing way
[00:12:17.140 --> 00:12:25.580]   to write LLM apps, LLMs are an amazing way
[00:12:25.580 --> 00:12:28.340]   to write Streamlit apps.
[00:12:28.340 --> 00:12:29.620]   OK.
[00:12:29.620 --> 00:12:34.060]   So for this next demonstration, I'm
[00:12:34.060 --> 00:12:38.700]   going to need a volunteer from the audience.
[00:12:38.700 --> 00:12:40.780]   Who would like to be a volunteer from the audience?
[00:12:40.780 --> 00:12:43.060]   OK, I see a hand raised right there.
[00:12:43.060 --> 00:12:44.820]   Can you stand up?
[00:12:44.820 --> 00:12:45.940]   OK.
[00:12:45.940 --> 00:12:47.820]   Are you guys ready?
[00:12:47.820 --> 00:12:48.320]   Here we go.
[00:12:48.320 --> 00:12:52.860]   All righty.
[00:12:52.860 --> 00:12:56.220]   What is your name, volunteer?
[00:12:56.220 --> 00:12:57.220]   Mario.
[00:12:57.220 --> 00:12:58.860]   OK.
[00:12:58.860 --> 00:13:02.620]   What company do you work at?
[00:13:02.620 --> 00:13:04.540]   Say that again.
[00:13:04.540 --> 00:13:06.860]   VIO?
[00:13:06.860 --> 00:13:09.060]   Wind IO.
[00:13:09.060 --> 00:13:10.380]   We're just going to say Wind IO.
[00:13:10.380 --> 00:13:15.220]   I know that that's not actually true, but that's OK.
[00:13:15.220 --> 00:13:17.460]   You know what, we're just going to hallucinate this.
[00:13:17.460 --> 00:13:18.780]   All right.
[00:13:18.780 --> 00:13:22.220]   Tell me, Mario, not to embarrass you in front of the audience,
[00:13:22.220 --> 00:13:25.500]   but what is your dream?
[00:13:25.500 --> 00:13:27.060]   Your dream is to become a rock star.
[00:13:27.060 --> 00:13:27.940]   OK.
[00:13:27.940 --> 00:13:32.540]   Let's go into to become a rock star.
[00:13:32.540 --> 00:13:35.100]   Now obviously, this is a data analytics problem,
[00:13:35.100 --> 00:13:37.300]   so we're going to want at least one numerical input
[00:13:37.300 --> 00:13:41.500]   slider and an Altair bar chart and an Altair line chart.
[00:13:41.500 --> 00:13:43.540]   And we don't need any biographical information
[00:13:43.540 --> 00:13:44.060]   about Mike.
[00:13:44.060 --> 00:13:44.460]   I don't know.
[00:13:44.460 --> 00:13:45.500]   That's from an old slide.
[00:13:45.500 --> 00:13:46.060]   OK.
[00:13:46.060 --> 00:13:50.460]   And what is your goal in terms of becoming a rock star?
[00:13:50.460 --> 00:13:50.960]   Help us.
[00:13:50.960 --> 00:13:53.540]   What's the first step?
[00:13:53.540 --> 00:13:54.620]   Writing a hit song.
[00:13:54.620 --> 00:13:55.660]   Writing a hit song.
[00:13:55.660 --> 00:13:56.260]   OK.
[00:13:56.260 --> 00:14:00.540]   So we want Mario to be able to write a hit song.
[00:14:00.540 --> 00:14:02.620]   OK.
[00:14:02.620 --> 00:14:09.020]   So what we have created here is a little prompt.
[00:14:09.020 --> 00:14:17.060]   So let's have fun and ask chat GPT using GPT-4--
[00:14:17.060 --> 00:14:18.700]   can't mess around here on stage--
[00:14:18.700 --> 00:14:22.100]   [LAUGHTER]
[00:14:22.100 --> 00:14:24.820]   --to generate a little app for us.
[00:14:27.420 --> 00:14:33.540]   Now this does take a little bit of time,
[00:14:33.540 --> 00:14:39.020]   and it brings to mind a sort of interesting aspect
[00:14:39.020 --> 00:14:44.740]   of living amidst these incredible superhuman
[00:14:44.740 --> 00:14:49.100]   intelligences, which is, why do they take so long to run?
[00:14:55.860 --> 00:14:59.700]   I mean, obviously, it would be ideal
[00:14:59.700 --> 00:15:02.660]   if these hyper-intelligent machines also
[00:15:02.660 --> 00:15:03.900]   were instantaneous.
[00:15:03.900 --> 00:15:04.940]   But here we go.
[00:15:04.940 --> 00:15:09.640]   So part of the point here is that this is a non-trivial app.
[00:15:09.640 --> 00:15:13.860]   And also, this is a non-canned demo.
[00:15:13.860 --> 00:15:17.540]   So this is really GPT-4 running right now.
[00:15:17.540 --> 00:15:19.100]   How many of you think this is going--
[00:15:19.100 --> 00:15:21.580]   this is probably, I don't know, 50 lines of code,
[00:15:21.580 --> 00:15:22.780]   75 lines of code.
[00:15:22.780 --> 00:15:27.580]   How many of you think this is going to run on the first go?
[00:15:27.580 --> 00:15:28.580]   All right.
[00:15:28.580 --> 00:15:30.660]   How many of you think I should run it right now?
[00:15:30.660 --> 00:15:32.300]   [APPLAUSE]
[00:15:32.300 --> 00:15:33.540]   All right.
[00:15:33.540 --> 00:15:37.860]   Mario, let's see what we have.
[00:15:37.860 --> 00:15:39.300]   All right.
[00:15:39.300 --> 00:15:41.900]   We're going to go over here, and we're going to test this.
[00:15:41.900 --> 00:15:43.300]   Hello, Weights and Biases.
[00:15:43.300 --> 00:15:46.500]   Oh, by the way, shout out to Weights and Biases.
[00:15:46.500 --> 00:15:50.420]   When I said, hello, Weights, GitHub autocomplete
[00:15:50.420 --> 00:15:51.940]   and biases.
[00:15:51.940 --> 00:15:52.780]   All right.
[00:15:52.780 --> 00:15:54.540]   So let's delete this.
[00:15:54.540 --> 00:15:56.220]   You can delete this, too.
[00:15:56.220 --> 00:15:57.460]   And let's write our app.
[00:15:57.460 --> 00:15:59.660]   Now, recall, this app was literally
[00:15:59.660 --> 00:16:05.340]   generated seconds ago live on stage by GPT.
[00:16:05.340 --> 00:16:06.380]   Let's see what happens.
[00:16:06.380 --> 00:16:09.540]   Here we go.
[00:16:09.540 --> 00:16:11.420]   Mario's Rockstar Dream.
[00:16:11.420 --> 00:16:12.060]   Hello there.
[00:16:12.060 --> 00:16:15.380]   I'm Mario from Window IO.
[00:16:15.380 --> 00:16:16.540]   I'm sorry, Mario.
[00:16:16.540 --> 00:16:18.700]   I'm sorry, Window IO.
[00:16:18.700 --> 00:16:20.940]   I dream of being a rock star.
[00:16:20.940 --> 00:16:23.380]   Select the number of verses from your hit song.
[00:16:23.380 --> 00:16:24.180]   OK.
[00:16:24.180 --> 00:16:28.020]   So this is obviously a humorous app.
[00:16:28.020 --> 00:16:30.060]   It doesn't have real data in it.
[00:16:30.060 --> 00:16:33.700]   But on the other hand, it is a true, non-trivial Streamlit
[00:16:33.700 --> 00:16:41.660]   app, which actually has a bunch of pieces coming together
[00:16:41.660 --> 00:16:45.340]   and interacting with one another.
[00:16:45.340 --> 00:16:48.540]   And the fact that I have run this demo many times,
[00:16:48.540 --> 00:16:52.860]   and it has never not succeeded, that I feel comfortable doing
[00:16:52.860 --> 00:16:58.900]   it on stage in front of 200 ML engineers with GPT-4
[00:16:58.900 --> 00:17:02.020]   is really a remarkable thing about this age.
[00:17:02.020 --> 00:17:06.300]   And so when we come back and think about this,
[00:17:06.300 --> 00:17:09.060]   we see that there are actually two sides to this coin.
[00:17:09.060 --> 00:17:14.740]   Not only is Streamlit an amazing--
[00:17:14.740 --> 00:17:17.540]   in a world in which Streamlit is an amazing way
[00:17:17.540 --> 00:17:22.940]   to write LLM apps, and LLMs are an amazing way
[00:17:22.940 --> 00:17:28.060]   to write Streamlit apps, a sort of interesting thing
[00:17:28.060 --> 00:17:29.620]   happens here.
[00:17:29.620 --> 00:17:32.280]   And this is something that we've been thinking a great deal
[00:17:32.280 --> 00:17:36.540]   about at Snowflake with our customers.
[00:17:36.540 --> 00:17:40.900]   I can't give you a full preview of what we're going to show,
[00:17:40.900 --> 00:17:44.100]   because we're going to demonstrate a lot at Snowflake
[00:17:44.100 --> 00:17:46.900]   Summit, which is our big user conference,
[00:17:46.900 --> 00:17:48.180]   in about--
[00:17:48.180 --> 00:17:50.780]   well, in exactly 19 days.
[00:17:50.780 --> 00:17:56.020]   And I had to swear up and down to Snowflake Marketing
[00:17:56.020 --> 00:17:57.820]   and whoever else that I was not going
[00:17:57.820 --> 00:17:59.620]   to reveal all of our secrets.
[00:17:59.620 --> 00:18:02.540]   But can you guys keep a little secret here?
[00:18:02.540 --> 00:18:03.500]   OK, good.
[00:18:03.500 --> 00:18:10.340]   With some chain of thought magic,
[00:18:10.340 --> 00:18:16.580]   and with Streamlit's new chatbot API to be released,
[00:18:16.580 --> 00:18:20.500]   you can start to enter a world in which the chatbot can not
[00:18:20.500 --> 00:18:24.180]   only interpret natural language--
[00:18:24.180 --> 00:18:29.540]   so not only a world in which Streamlit can--
[00:18:29.540 --> 00:18:33.420]   or rather, Streamlit can be used to harness the power of LLMs
[00:18:33.420 --> 00:18:35.780]   on behalf of your enterprise partners,
[00:18:35.780 --> 00:18:39.740]   but also in which the LLM itself can generate fragments
[00:18:39.740 --> 00:18:43.220]   of Streamlit apps as part of the interaction.
[00:18:43.220 --> 00:18:46.220]   And the remarkable thing is not only
[00:18:46.220 --> 00:18:49.580]   that this is possible, which six months ago or a year ago,
[00:18:49.580 --> 00:18:55.500]   I would have not believed, but also how remarkably few lines
[00:18:55.500 --> 00:18:56.860]   of code this is.
[00:18:56.860 --> 00:18:58.820]   We don't have to tell the chatbot really
[00:18:58.820 --> 00:19:01.180]   anything about the world.
[00:19:01.180 --> 00:19:02.700]   It knows about Streamlit.
[00:19:02.700 --> 00:19:04.020]   It knows about data.
[00:19:04.020 --> 00:19:05.580]   It knows about SQL.
[00:19:05.580 --> 00:19:10.180]   And so in 19 days in Las Vegas, we're
[00:19:10.180 --> 00:19:13.380]   going to make a series of really interesting and exciting
[00:19:13.380 --> 00:19:14.660]   announcements.
[00:19:14.660 --> 00:19:18.620]   And you'll also get to see exactly how we built
[00:19:18.620 --> 00:19:20.860]   this chatbot from top to bottom.
[00:19:20.860 --> 00:19:24.660]   So really excited to share this with you.
[00:19:24.660 --> 00:19:27.340]   Please, if you haven't downloaded Streamlit yet,
[00:19:27.340 --> 00:19:30.980]   go ahead and download Streamlit and play with it
[00:19:30.980 --> 00:19:33.060]   and connect it to your LLMs.
[00:19:33.060 --> 00:19:38.100]   And if you are interested, come to Las Vegas in 19 days.
[00:19:38.100 --> 00:19:42.180]   Join 10,000 other developers and hear a lot more
[00:19:42.180 --> 00:19:44.940]   about Snowflake, Streamlit, LLMs,
[00:19:44.940 --> 00:19:47.220]   and other exciting things.
[00:19:47.220 --> 00:19:50.580]   [MUSIC PLAYING]
[00:19:50.580 --> 00:19:53.160]   (upbeat music)
[00:19:53.160 --> 00:20:03.160]   [BLANK_AUDIO]

