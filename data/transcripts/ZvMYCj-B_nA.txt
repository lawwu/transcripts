
[00:00:00.000 --> 00:00:02.240]   (upbeat music)
[00:00:02.240 --> 00:00:03.760]   - We have to be faced with this concept
[00:00:03.760 --> 00:00:05.840]   that technology is not value neutral.
[00:00:05.840 --> 00:00:08.080]   And if you think about what machine learning really is,
[00:00:08.080 --> 00:00:10.560]   it is the application of massive amounts of compute,
[00:00:10.560 --> 00:00:12.280]   you know, rent a supercomputer in the cloud,
[00:00:12.280 --> 00:00:13.860]   kind of massive amounts of compute,
[00:00:13.860 --> 00:00:15.280]   to massive amounts of data,
[00:00:15.280 --> 00:00:17.680]   that's even deeper and creepier than ever before,
[00:00:17.680 --> 00:00:19.120]   'cause they have sensors everywhere,
[00:00:19.120 --> 00:00:22.240]   to achieve business ends and to optimize business outcomes.
[00:00:22.240 --> 00:00:25.200]   And we know just how good businesses are at capturing
[00:00:25.200 --> 00:00:27.360]   and self-regulating about externalities, right,
[00:00:27.360 --> 00:00:28.560]   to their business outcomes.
[00:00:28.560 --> 00:00:30.800]   So just as a human looking at this,
[00:00:30.800 --> 00:00:32.720]   I would say, wow, I've got a chance to actually speak
[00:00:32.720 --> 00:00:34.760]   to this practitioner crowd about,
[00:00:34.760 --> 00:00:36.000]   if you're doing your job well,
[00:00:36.000 --> 00:00:38.720]   you'll be forced to drive a lot of conversations
[00:00:38.720 --> 00:00:41.800]   about ethics and the practice of your thing,
[00:00:41.800 --> 00:00:44.440]   about what you're doing within your business,
[00:00:44.440 --> 00:00:47.400]   as it goes through this data transformation.
[00:00:47.400 --> 00:00:50.160]   And you should be ready for that, steal yourself for that.
[00:00:50.160 --> 00:00:52.480]   Don't punt, don't punt on it.
[00:00:52.480 --> 00:00:54.040]   We can't afford to punt.
[00:00:54.040 --> 00:00:56.000]   - You're listening to Gradient Dissent,
[00:00:56.000 --> 00:00:58.400]   a show where we learn about making machine learning models
[00:00:58.400 --> 00:00:59.680]   work in the real world.
[00:00:59.680 --> 00:01:01.520]   I'm your host, Lucas Biewald.
[00:01:01.520 --> 00:01:04.080]   Peter Wang is the co-founder, CEO,
[00:01:04.080 --> 00:01:06.000]   and creator of Anaconda.
[00:01:06.000 --> 00:01:08.920]   He's been developing commercial scientific computing
[00:01:08.920 --> 00:01:12.480]   and visualization software for over 15 years.
[00:01:12.480 --> 00:01:14.680]   He created the PyData community and conferences
[00:01:14.680 --> 00:01:15.960]   and devotes his time and energy
[00:01:15.960 --> 00:01:18.600]   to growing the Python data science community
[00:01:18.600 --> 00:01:21.400]   and teaching Python at conferences around the world.
[00:01:21.400 --> 00:01:23.880]   Couldn't be more excited to talk to him.
[00:01:23.880 --> 00:01:27.320]   So, maybe for starters, I guess I know of you
[00:01:27.320 --> 00:01:28.560]   because of your product, Conda,
[00:01:28.560 --> 00:01:30.240]   which I've used for many years.
[00:01:30.240 --> 00:01:32.000]   I have a feeling most of the people listening to this
[00:01:32.000 --> 00:01:33.120]   will know what Conda is,
[00:01:33.120 --> 00:01:35.560]   but maybe could you describe it in your words,
[00:01:35.560 --> 00:01:37.920]   just to make sure we're all on the same page here?
[00:01:37.920 --> 00:01:41.960]   - Yeah, so Conda is a package manager
[00:01:41.960 --> 00:01:44.440]   that we built as part of the overall
[00:01:44.440 --> 00:01:46.760]   Anaconda Python distribution.
[00:01:46.760 --> 00:01:51.480]   And it started as a way just to get people package updates
[00:01:51.480 --> 00:01:53.720]   of the binary builds that we do.
[00:01:53.720 --> 00:01:57.600]   And it's expanded to then manage virtual environments.
[00:01:57.600 --> 00:02:00.320]   So we could have different versions of libraries
[00:02:00.320 --> 00:02:04.400]   and different, in fact, versions of Python in user land,
[00:02:04.400 --> 00:02:07.000]   on any of the platforms we support.
[00:02:07.000 --> 00:02:09.520]   And then we also created a space
[00:02:09.520 --> 00:02:11.200]   for people to upload their own packages.
[00:02:11.200 --> 00:02:15.560]   And so that's the anaconda.org service.
[00:02:15.560 --> 00:02:18.040]   Around that, a community has grown up called CondaForge,
[00:02:18.040 --> 00:02:22.280]   where they make recipes, maintain recipes, upload packages.
[00:02:22.280 --> 00:02:26.480]   But lots of other people like NVIDIA folks or like PyTorch,
[00:02:26.480 --> 00:02:29.280]   they will upload their own official builds
[00:02:29.280 --> 00:02:31.160]   into the anaconda.org system.
[00:02:31.160 --> 00:02:33.680]   So we run all of that infrastructure.
[00:02:33.680 --> 00:02:36.000]   We pay the bills for the CDN
[00:02:36.000 --> 00:02:37.480]   and for all the storage and everything.
[00:02:37.480 --> 00:02:41.720]   And then we do have a community
[00:02:41.720 --> 00:02:44.040]   around the Conda package manager itself.
[00:02:44.040 --> 00:02:46.160]   So people making tools and extensions for it.
[00:02:46.160 --> 00:02:48.640]   So that's in a nutshell what Conda is.
[00:02:48.640 --> 00:02:49.960]   So you can think of it as like an RPM
[00:02:49.960 --> 00:02:51.000]   or something like that.
[00:02:51.000 --> 00:02:53.880]   But primarily for data science
[00:02:53.880 --> 00:02:56.640]   and numerical-oriented computing.
[00:02:56.640 --> 00:02:57.800]   - And what's your original background?
[00:02:57.800 --> 00:03:00.520]   Like, were you always making software,
[00:03:00.520 --> 00:03:02.360]   running a successful software company?
[00:03:02.360 --> 00:03:03.280]   (laughing)
[00:03:03.280 --> 00:03:07.280]   - No, so I've always been programming pretty much
[00:03:07.280 --> 00:03:09.160]   since I was like, I think eight years old.
[00:03:09.160 --> 00:03:11.240]   I've been programming in something.
[00:03:11.240 --> 00:03:13.920]   But I ended up going to college for physics.
[00:03:13.920 --> 00:03:16.040]   And so I graduated with a degree of physics
[00:03:16.040 --> 00:03:20.360]   and I decided to join kind of the dot-com kind of boom
[00:03:20.360 --> 00:03:21.640]   by going and joining a startup.
[00:03:21.640 --> 00:03:24.600]   And I've been in software ever since then.
[00:03:24.600 --> 00:03:28.000]   But I spent a number of years working in consulting,
[00:03:28.000 --> 00:03:31.320]   using the scientific Python and the Python stack
[00:03:31.320 --> 00:03:32.240]   in the 2000s.
[00:03:32.240 --> 00:03:34.800]   And that's really where I started seeing the possibilities
[00:03:34.800 --> 00:03:37.880]   for using Python for a broader set of data analysis
[00:03:37.880 --> 00:03:41.760]   use cases than just kind of sort of niche scientific
[00:03:41.760 --> 00:03:44.680]   and engineering computing kinds of use cases.
[00:03:44.680 --> 00:03:47.560]   - Cool, and can you explain to me kind of what was going on
[00:03:47.560 --> 00:03:49.240]   that you started this project
[00:03:49.240 --> 00:03:52.960]   and like what the original conception was when it began?
[00:03:52.960 --> 00:03:53.800]   - Yeah, sure.
[00:03:53.800 --> 00:03:55.040]   Well, the original conception,
[00:03:55.040 --> 00:03:56.760]   so the company was called Continuum Analytics.
[00:03:56.760 --> 00:03:59.560]   I started that with my co-founder, Travis Oliphant,
[00:03:59.560 --> 00:04:01.040]   who is the creator of NumPy
[00:04:01.040 --> 00:04:03.000]   and one of the co-founders of SciPy.
[00:04:03.000 --> 00:04:08.000]   And we put the company together to promote the use of Python
[00:04:08.000 --> 00:04:10.760]   and to advance the state of the art for Python
[00:04:10.760 --> 00:04:14.440]   for a broader set of data analysis needs.
[00:04:14.440 --> 00:04:17.080]   So that was the original vision.
[00:04:17.080 --> 00:04:18.920]   And at that time, this was 2012,
[00:04:18.920 --> 00:04:20.680]   we formed the company.
[00:04:20.680 --> 00:04:25.680]   Wes McKinney had just really started pushing pandas
[00:04:25.680 --> 00:04:29.080]   as a data frame library.
[00:04:29.080 --> 00:04:30.920]   The Jupyter notebook was relatively new at the time.
[00:04:30.920 --> 00:04:33.000]   It was still called the IPython notebook.
[00:04:33.000 --> 00:04:38.640]   And the world was sort of awash in Hadoop big data craze.
[00:04:38.640 --> 00:04:42.120]   And what we could see was that once people
[00:04:42.120 --> 00:04:43.600]   threw all their data Hadoop,
[00:04:43.600 --> 00:04:46.520]   they wanted to do bigger analyses.
[00:04:46.520 --> 00:04:49.600]   They wanted to do broader, more cross kind of cross data set,
[00:04:49.600 --> 00:04:52.160]   cross schema sort of analyses.
[00:04:52.160 --> 00:04:53.480]   And they would need tools like Python.
[00:04:53.480 --> 00:04:55.120]   SQL wasn't gonna do it for them.
[00:04:55.120 --> 00:04:58.320]   And so we were putting this stuff together.
[00:04:58.320 --> 00:05:01.720]   We were trying to find alternative MapReduce frameworks
[00:05:01.720 --> 00:05:05.120]   that were nicer to Python than Hadoop.
[00:05:05.120 --> 00:05:06.560]   And the rest of kind of the Java,
[00:05:06.560 --> 00:05:09.440]   the Apache Java JVM big data stack, if you will,
[00:05:09.440 --> 00:05:13.400]   the JVM world does not play with the Python C++
[00:05:13.400 --> 00:05:14.560]   native world very well.
[00:05:14.560 --> 00:05:17.480]   So any case, as we're looking at doing all this stuff,
[00:05:17.480 --> 00:05:22.160]   it became clear to me that if people couldn't install SciPy
[00:05:22.160 --> 00:05:24.480]   and Matplotlib and IPython,
[00:05:24.480 --> 00:05:26.000]   they were not gonna be able to install
[00:05:26.000 --> 00:05:28.920]   any new fangled compiler tools we built
[00:05:28.920 --> 00:05:30.520]   or any new fangled MapReduce framework.
[00:05:30.520 --> 00:05:32.160]   It was just gonna be completely off the table.
[00:05:32.160 --> 00:05:34.000]   So we started by saying, well, you know what?
[00:05:34.000 --> 00:05:37.240]   We should probably produce a special collection of packages,
[00:05:37.240 --> 00:05:39.880]   a distribution of Python that helps people get started,
[00:05:39.880 --> 00:05:41.800]   that includes all of the basic things they need,
[00:05:41.800 --> 00:05:43.480]   that works on Mac, Windows, Linux.
[00:05:44.400 --> 00:05:45.840]   And so that was the basic idea.
[00:05:45.840 --> 00:05:47.120]   So we built Anaconda.
[00:05:47.120 --> 00:05:49.080]   I came up with the name 'cause it's Python for big data.
[00:05:49.080 --> 00:05:50.960]   So it's a big snake kind of.
[00:05:50.960 --> 00:05:52.600]   Although of course I don't like snakes that much.
[00:05:52.600 --> 00:05:55.040]   And Python is of course named after Monty Python,
[00:05:55.040 --> 00:05:56.640]   but whatever, we'll ignore that.
[00:05:56.640 --> 00:05:58.280]   So that's where the name Anaconda came from
[00:05:58.280 --> 00:05:59.560]   for that product.
[00:05:59.560 --> 00:06:04.080]   And then that just took off like quite well.
[00:06:04.080 --> 00:06:06.160]   And so we eventually renamed the company Continuum
[00:06:06.160 --> 00:06:08.360]   to Anaconda because we'd be at conferences
[00:06:08.360 --> 00:06:10.080]   and they'd say, where are you from?
[00:06:10.080 --> 00:06:11.320]   Or like, what company are you with?
[00:06:11.320 --> 00:06:12.840]   And we say, we're with Continuum.
[00:06:12.840 --> 00:06:13.960]   And say, okay, yeah, that's nice.
[00:06:13.960 --> 00:06:16.560]   And we say, well, we make this thing called Anaconda.
[00:06:16.560 --> 00:06:18.640]   And they say, oh, we use Anaconda, we love Anaconda.
[00:06:18.640 --> 00:06:20.320]   And so we're like, after that happens,
[00:06:20.320 --> 00:06:21.520]   like the thousands of time,
[00:06:21.520 --> 00:06:23.200]   you sort of figure out you should,
[00:06:23.200 --> 00:06:24.400]   the world's telling you something.
[00:06:24.400 --> 00:06:28.080]   So anyway, but anyway, that's the journey.
[00:06:28.080 --> 00:06:29.480]   And since then we've continued to push
[00:06:29.480 --> 00:06:32.280]   like new open source tools and things like that
[00:06:32.280 --> 00:06:34.840]   in the Python kind of data stack.
[00:06:34.840 --> 00:06:38.040]   - It's incredible the impact that I think you've had
[00:06:38.040 --> 00:06:40.920]   and certainly NumPy and SciPy
[00:06:40.920 --> 00:06:44.160]   in terms of just making Python a popular product.
[00:06:44.160 --> 00:06:47.040]   Do you ever regret choosing Python for this?
[00:06:47.040 --> 00:06:48.480]   Has that been a good choice for you?
[00:06:48.480 --> 00:06:50.920]   - Oh, no, no, that was completely intentional.
[00:06:50.920 --> 00:06:54.000]   I mean, a thing that people should understand, I think,
[00:06:54.000 --> 00:06:57.120]   especially as more software engineers move into ML,
[00:06:57.120 --> 00:06:58.720]   become ML engineers, right?
[00:06:58.720 --> 00:07:00.720]   For them, language is just a choice.
[00:07:00.720 --> 00:07:03.200]   It's like, well, I'm a C++ coder now
[00:07:03.200 --> 00:07:05.680]   and I learned some Go and now I'm doing Python.
[00:07:05.680 --> 00:07:06.520]   It's like, whatever, right?
[00:07:06.520 --> 00:07:08.640]   And Python's got some warts and it's got some good things.
[00:07:08.640 --> 00:07:12.440]   But the thing to recognize is that Travis and I,
[00:07:12.440 --> 00:07:13.560]   when we started this,
[00:07:13.560 --> 00:07:15.760]   the reason why we wanted to push Python
[00:07:15.760 --> 00:07:19.000]   was because of the democratization and the access,
[00:07:19.000 --> 00:07:20.520]   the accessibility of it.
[00:07:20.520 --> 00:07:21.520]   When you're a software developer,
[00:07:21.520 --> 00:07:22.920]   you learn new languages all the time
[00:07:22.920 --> 00:07:24.240]   'cause that's part of your gig.
[00:07:24.240 --> 00:07:25.480]   If you're not a software developer,
[00:07:25.480 --> 00:07:26.680]   if you're a subject matter expert
[00:07:26.680 --> 00:07:28.280]   or a domain expert in some other field,
[00:07:28.280 --> 00:07:29.560]   let's say you're a geneticist
[00:07:29.560 --> 00:07:32.080]   or let's say you're a policymaker or whoever, right?
[00:07:32.080 --> 00:07:33.800]   You're an astrophysicist.
[00:07:33.800 --> 00:07:36.200]   Learning a new software programming language is hard.
[00:07:36.200 --> 00:07:38.000]   You're not really a coder anyway.
[00:07:38.000 --> 00:07:41.920]   You had to learn some Fortran or C++ or MATLAB in grad school
[00:07:41.920 --> 00:07:45.000]   but otherwise, you're not doing this on a weekend
[00:07:45.000 --> 00:07:46.360]   just because you love it, right?
[00:07:46.360 --> 00:07:48.280]   So if you learn a language,
[00:07:48.280 --> 00:07:50.120]   this is gonna stick with you for a while
[00:07:50.120 --> 00:07:52.760]   and if we, as people who make languages
[00:07:52.760 --> 00:07:53.680]   or who make software tools,
[00:07:53.680 --> 00:07:56.400]   if we can find a language that people like to use
[00:07:56.400 --> 00:07:57.760]   and is powerful for them
[00:07:57.760 --> 00:08:00.000]   and that multiple different kinds of people can use,
[00:08:00.000 --> 00:08:01.600]   that's incredibly powerful.
[00:08:01.600 --> 00:08:02.960]   So one of the things about Python
[00:08:02.960 --> 00:08:04.840]   is that the creator of Python, Guido,
[00:08:06.600 --> 00:08:09.080]   before Python, he was working on a project
[00:08:09.080 --> 00:08:11.040]   called Computer Programming for Everyone
[00:08:11.040 --> 00:08:12.960]   and so some of the ideas that went to Python
[00:08:12.960 --> 00:08:15.680]   came from that precursor language called ABC
[00:08:15.680 --> 00:08:18.400]   and that readability counts
[00:08:18.400 --> 00:08:21.120]   and that kind of executable pseudocode thing,
[00:08:21.120 --> 00:08:23.080]   the same things that make Python hard to optimize, right?
[00:08:23.080 --> 00:08:24.520]   They make it cost a nation
[00:08:24.520 --> 00:08:27.280]   for statically typed language aficionados.
[00:08:27.280 --> 00:08:29.280]   Those things also make it incredibly accessible
[00:08:29.280 --> 00:08:30.440]   to lots of people
[00:08:30.440 --> 00:08:32.840]   and when we make these kinds of advanced tools
[00:08:32.840 --> 00:08:34.880]   available and accessible to lots of people,
[00:08:34.880 --> 00:08:38.480]   what we do is we grow the universe of possible innovations.
[00:08:38.480 --> 00:08:41.280]   So for me, it's very intentional that we chose Python.
[00:08:41.280 --> 00:08:44.720]   There's a thousand new languages you could create
[00:08:44.720 --> 00:08:45.680]   that are better than Python
[00:08:45.680 --> 00:08:47.000]   in all these different dimensions
[00:08:47.000 --> 00:08:47.840]   but at the end of the day,
[00:08:47.840 --> 00:08:50.040]   Python is kind of the language everyone uses, right?
[00:08:50.040 --> 00:08:53.000]   It is valuable that everyone uses that same language
[00:08:53.000 --> 00:08:56.000]   so I have a very, very strong opinion
[00:08:56.000 --> 00:08:59.080]   about the fact that we should continue promoting its use
[00:08:59.080 --> 00:09:00.000]   and growing its use
[00:09:00.000 --> 00:09:01.480]   even as I fundamentally believe
[00:09:01.480 --> 00:09:03.680]   there must be a better language out there, right?
[00:09:03.680 --> 00:09:05.160]   I think that's the successor to it.
[00:09:05.160 --> 00:09:07.600]   I have some ideas about that as well.
[00:09:07.600 --> 00:09:08.440]   - Oh, interesting.
[00:09:08.440 --> 00:09:09.280]   I'd love to hear about that
[00:09:09.280 --> 00:09:12.440]   because we were talking with one of the Fast.ai founders,
[00:09:12.440 --> 00:09:16.240]   Jeremy Howard, and he's written so much Python code
[00:09:16.240 --> 00:09:18.480]   and he was really emphatic
[00:09:18.480 --> 00:09:21.320]   when I was talking to him on this same podcast
[00:09:21.320 --> 00:09:24.400]   about Python can't possibly be the future
[00:09:24.400 --> 00:09:26.640]   of scientific computing and I was kind of surprised.
[00:09:26.640 --> 00:09:29.600]   I would say my perspective is definitely a non-expert
[00:09:29.600 --> 00:09:31.960]   but I really enjoy programming in Python
[00:09:31.960 --> 00:09:33.400]   and maybe it's hard for me to really see
[00:09:33.400 --> 00:09:34.280]   how things could be better
[00:09:34.280 --> 00:09:37.440]   or maybe I don't have to kind of worry about performance
[00:09:37.440 --> 00:09:41.080]   as much as other people but what would your take be?
[00:09:41.080 --> 00:09:43.560]   Is there any kind of language with less adoption
[00:09:43.560 --> 00:09:45.160]   that you think is really intriguing
[00:09:45.160 --> 00:09:47.320]   and could kind of replace Python
[00:09:47.320 --> 00:09:49.080]   or are there tweaks to Python that you'd like to see?
[00:09:49.080 --> 00:09:50.520]   How do you think about that?
[00:09:50.520 --> 00:09:55.560]   - So yes and no.
[00:09:55.560 --> 00:09:58.640]   So there are languages out there that do interesting things
[00:10:00.000 --> 00:10:03.320]   that are things that Python can't quite do
[00:10:03.320 --> 00:10:05.320]   or that Python may never be able to do.
[00:10:05.320 --> 00:10:08.520]   So one of the fastest database systems out there
[00:10:08.520 --> 00:10:11.440]   is a thing called KDB and the language in it, K,
[00:10:11.440 --> 00:10:14.240]   you're not gonna find any,
[00:10:14.240 --> 00:10:17.840]   I mean, it comes from like the APL roots
[00:10:17.840 --> 00:10:20.000]   which are the precursors to like the Fortran stuff
[00:10:20.000 --> 00:10:22.760]   and then MATLAB and NumPy and all these things.
[00:10:22.760 --> 00:10:27.120]   So in any kind of ALGOL and modular derived
[00:10:27.120 --> 00:10:29.160]   kind of imperative programming language,
[00:10:29.160 --> 00:10:30.320]   you're not gonna meet the kinds
[00:10:30.320 --> 00:10:35.040]   of raw numerical performance that like K and KDB can achieve
[00:10:35.040 --> 00:10:38.640]   and the creator of K and KDB has a new thing
[00:10:38.640 --> 00:10:39.920]   that he's building called Shakti
[00:10:39.920 --> 00:10:43.400]   which is even more interesting.
[00:10:43.400 --> 00:10:45.440]   So there's that kind of lineage of things, right?
[00:10:45.440 --> 00:10:48.680]   There's sort of like the most out there amazing bits
[00:10:48.680 --> 00:10:52.080]   of Lisp plus like Fortran and you get something like that
[00:10:52.080 --> 00:10:54.600]   and Python is not there but Python has a lot
[00:10:54.600 --> 00:10:56.160]   of the good parts of the ideas there
[00:10:56.160 --> 00:11:00.840]   and expresses them in a infix imperative language.
[00:11:00.840 --> 00:11:01.800]   Then there's things like Julia
[00:11:01.800 --> 00:11:02.640]   that do whole program optimization.
[00:11:02.640 --> 00:11:03.480]   - Wait, sorry, sorry.
[00:11:03.480 --> 00:11:04.640]   Let me make sure I understood what you said
[00:11:04.640 --> 00:11:06.720]   about K and other ones like it.
[00:11:06.720 --> 00:11:08.040]   What's the advantage of that?
[00:11:08.040 --> 00:11:09.880]   They have the potential to be faster?
[00:11:09.880 --> 00:11:12.680]   - It's more than just faster.
[00:11:12.680 --> 00:11:17.680]   It's a fast and correct and performant representation
[00:11:17.680 --> 00:11:21.400]   of your idea but you have to sort of warp your brain
[00:11:21.400 --> 00:11:23.880]   a little bit to thinking in that way.
[00:11:23.880 --> 00:11:26.600]   So Ken Iverson, the creator of APL
[00:11:26.600 --> 00:11:29.400]   which is kind of the root of all of this stuff,
[00:11:29.400 --> 00:11:34.200]   he had this idea that notation is a tool of thought.
[00:11:34.200 --> 00:11:35.880]   So if you really want to help people think better
[00:11:35.880 --> 00:11:38.360]   and faster and more correct all at the same time,
[00:11:38.360 --> 00:11:39.760]   you need better notations.
[00:11:39.760 --> 00:11:42.600]   And so if you ever go and look at a bit of K,
[00:11:42.600 --> 00:11:45.960]   it looks different, let's just put it that way,
[00:11:45.960 --> 00:11:49.400]   than what you are mostly used to in like a Python
[00:11:49.400 --> 00:11:52.160]   or even a C++ or C or Java world.
[00:11:52.160 --> 00:11:55.360]   It's completely different, comes from a different brain space.
[00:11:55.360 --> 00:11:58.800]   And so yeah.
[00:11:58.800 --> 00:11:59.640]   - Interesting.
[00:11:59.640 --> 00:12:00.480]   - But there's something like that.
[00:12:00.480 --> 00:12:01.320]   - Can you say a little more, like is that just because
[00:12:01.320 --> 00:12:03.640]   it's sort of following different conventions
[00:12:03.640 --> 00:12:06.400]   or is there something to this perspective?
[00:12:06.400 --> 00:12:08.840]   'Cause I feel like every so often, not in many years,
[00:12:08.840 --> 00:12:11.760]   but in grad school I used to occasionally run across Fortran
[00:12:11.760 --> 00:12:13.880]   and it would just be like, okay, I'm stopping here.
[00:12:13.880 --> 00:12:15.560]   Like I'm not gonna go any deeper.
[00:12:15.560 --> 00:12:17.320]   This just feels impenetrable to me.
[00:12:17.320 --> 00:12:20.520]   But is that my fault or is that like,
[00:12:21.640 --> 00:12:23.200]   - Yeah, is there something there that's like better
[00:12:23.200 --> 00:12:25.960]   about it, I guess, in the notation?
[00:12:25.960 --> 00:12:29.120]   - Well, better is a big word.
[00:12:29.120 --> 00:12:32.200]   So I'll back up and say like,
[00:12:32.200 --> 00:12:36.040]   the difference between something like K or fourth
[00:12:36.040 --> 00:12:41.040]   or J, kind of like J, K, fourth, APL versus ALGOL
[00:12:41.040 --> 00:12:46.200]   or like Pascal C, kind of this lineage
[00:12:46.200 --> 00:12:50.160]   of fairly imperative procedural languages.
[00:12:50.160 --> 00:12:52.080]   At the end of the day, we are programming.
[00:12:52.080 --> 00:12:56.160]   When we write a program, we're sort of meeting,
[00:12:56.160 --> 00:12:59.560]   we're making a balance of three things, right?
[00:12:59.560 --> 00:13:01.200]   There's the expression itself,
[00:13:01.200 --> 00:13:02.760]   like what it is we're trying to express.
[00:13:02.760 --> 00:13:06.520]   Like, there's the data, the representation of the data
[00:13:06.520 --> 00:13:08.280]   and then there's like some compute system
[00:13:08.280 --> 00:13:10.240]   that's able to compute on that data.
[00:13:10.240 --> 00:13:13.760]   And so I call this kind of the iron triangle of programming
[00:13:13.760 --> 00:13:15.680]   is that you've got expressions and expressivity
[00:13:15.680 --> 00:13:17.920]   or expressiveness, you have data schemas,
[00:13:17.920 --> 00:13:19.960]   data correctness, things like that.
[00:13:19.960 --> 00:13:22.400]   And then you've got the compute, which is runtime,
[00:13:22.400 --> 00:13:24.800]   again, correctness, runtime characteristics.
[00:13:24.800 --> 00:13:28.040]   And every programming system sits somewhere
[00:13:28.040 --> 00:13:30.800]   in the middle of this like ternary chart, right?
[00:13:30.800 --> 00:13:32.720]   And usually you trade off.
[00:13:32.720 --> 00:13:35.760]   What happens is usually collapse one axis onto the other
[00:13:35.760 --> 00:13:37.480]   and you have a linear trade off.
[00:13:37.480 --> 00:13:40.920]   And most of the post-Nicholas Wirth kind of era
[00:13:40.920 --> 00:13:44.080]   of like looking at, okay, you've got data,
[00:13:44.080 --> 00:13:45.760]   you've got a virtual machine
[00:13:45.760 --> 00:13:47.400]   and you're gonna basically load data in
[00:13:47.400 --> 00:13:49.360]   and do things to it with functions
[00:13:49.360 --> 00:13:51.080]   that proceed like this.
[00:13:51.080 --> 00:13:53.280]   That's a very, that model is sort of
[00:13:53.280 --> 00:13:56.320]   everyone has in their heads as a programming system, right?
[00:13:56.320 --> 00:13:59.160]   When you look at something like Forth or like K,
[00:13:59.160 --> 00:14:00.520]   you actually come from a different perspective.
[00:14:00.520 --> 00:14:02.080]   So Forth, I'll throw that in there
[00:14:02.080 --> 00:14:03.080]   because even when you do have
[00:14:03.080 --> 00:14:05.040]   an explicit data representation in mind,
[00:14:05.040 --> 00:14:06.480]   when you write programs in Forth
[00:14:06.480 --> 00:14:08.160]   or if you ever had an HP calculator,
[00:14:08.160 --> 00:14:09.480]   reverse Polish notation,
[00:14:09.480 --> 00:14:11.080]   it's probably the closest that most people
[00:14:11.080 --> 00:14:12.240]   will ever get to Forth.
[00:14:12.240 --> 00:14:15.520]   You're explicitly manipulating stacks,
[00:14:15.520 --> 00:14:17.120]   you're explicitly manipulating these things
[00:14:17.120 --> 00:14:20.240]   and you're writing tiny programs that can do a lot.
[00:14:20.240 --> 00:14:21.360]   It's amazing, right?
[00:14:21.360 --> 00:14:22.600]   And that's what an explicit stack
[00:14:22.600 --> 00:14:24.480]   and explicit these kinds of things.
[00:14:24.480 --> 00:14:27.640]   When you go to something like Lisp or like K,
[00:14:27.640 --> 00:14:30.040]   you're writing these conceptual things,
[00:14:30.040 --> 00:14:31.720]   these expressions.
[00:14:31.720 --> 00:14:33.960]   Well, in the case of Lisp, it's a conceptual algorithm.
[00:14:33.960 --> 00:14:36.640]   In the case of K, it's also an algorithm,
[00:14:36.640 --> 00:14:38.600]   but it's an algorithm on parallel data,
[00:14:38.600 --> 00:14:41.480]   parallelizable data structures on arrays and on vectors.
[00:14:41.480 --> 00:14:43.200]   And then you can,
[00:14:43.200 --> 00:14:46.440]   a part of your first class thing that you can do
[00:14:46.440 --> 00:14:49.280]   is you can change the structure of those data structures.
[00:14:49.280 --> 00:14:50.680]   You can do fold operators,
[00:14:50.680 --> 00:14:51.840]   you can apply in these ways,
[00:14:51.840 --> 00:14:54.320]   you can broadcast and collapse and project.
[00:14:54.320 --> 00:14:56.520]   And all of those are first class little things
[00:14:56.520 --> 00:14:58.320]   you can do in line as you're trying
[00:14:58.320 --> 00:14:59.480]   to express something else.
[00:14:59.480 --> 00:15:02.000]   So you end up with a line of K that's this long
[00:15:02.000 --> 00:15:05.640]   that would take you this, a page of Java to do.
[00:15:05.640 --> 00:15:08.720]   And by the way, the genius of the K system
[00:15:08.720 --> 00:15:11.400]   is that the underlying machine that interprets that,
[00:15:11.400 --> 00:15:13.920]   the compiler and then the interpreter system
[00:15:13.920 --> 00:15:16.840]   is incredibly mathematically elegant
[00:15:16.840 --> 00:15:18.600]   because there's actually fundamental algebra
[00:15:18.600 --> 00:15:20.440]   that you can sit in the heart of this stuff
[00:15:20.440 --> 00:15:23.280]   that you can then, basically K will load into,
[00:15:23.280 --> 00:15:26.840]   I think the claim is that it loads into L1, Icache.
[00:15:26.840 --> 00:15:31.560]   And so your program just streams to the CPU like a mofo,
[00:15:31.560 --> 00:15:34.240]   like you're never even hitting L2, right?
[00:15:34.240 --> 00:15:36.160]   So that's kind of an amazing thing.
[00:15:36.160 --> 00:15:37.720]   And so I think when you turn around
[00:15:37.720 --> 00:15:39.080]   and you look at something like Python,
[00:15:39.080 --> 00:15:41.800]   which is like not that optimized at all,
[00:15:41.800 --> 00:15:44.080]   it's like the C-based virtual machine.
[00:15:44.080 --> 00:15:45.920]   But when we do NumPy things,
[00:15:45.920 --> 00:15:48.360]   you're expressing some of those same ideas, right?
[00:15:48.360 --> 00:15:49.200]   So, yeah.
[00:15:49.200 --> 00:15:50.640]   - Yeah, I was gonna say this reminds me
[00:15:50.640 --> 00:15:52.880]   of my experience with NumPy where,
[00:15:52.880 --> 00:15:55.360]   I keep kind of making it tighter and tighter
[00:15:55.360 --> 00:15:57.920]   and shorter and shorter and more and more elegant,
[00:15:57.920 --> 00:15:59.160]   but then when I need to debug it,
[00:15:59.160 --> 00:16:00.880]   I feel like I often end up just unpacking
[00:16:00.880 --> 00:16:01.720]   the whole thing again.
[00:16:01.720 --> 00:16:03.640]   And I don't know if that's like me being stupid,
[00:16:03.640 --> 00:16:04.640]   but that's definitely my process.
[00:16:04.640 --> 00:16:06.440]   - Well, it depends on what you're debugging though, right?
[00:16:06.440 --> 00:16:07.960]   'Cause you can make it compact.
[00:16:07.960 --> 00:16:09.840]   And then when you debug it, it's like,
[00:16:09.840 --> 00:16:13.000]   are you debugging an actual bug
[00:16:13.000 --> 00:16:15.700]   in the runtime of NumPy itself?
[00:16:15.700 --> 00:16:17.560]   Are you debugging a performance mismatch
[00:16:17.560 --> 00:16:18.520]   with your expectation relative
[00:16:18.520 --> 00:16:20.520]   to how the data structure is laid out in memory?
[00:16:20.520 --> 00:16:22.720]   Are you debugging a impedance mismatch
[00:16:22.720 --> 00:16:25.320]   between your understanding of what NumPy is gonna do
[00:16:25.320 --> 00:16:27.880]   in each of these steps versus what it's,
[00:16:27.880 --> 00:16:30.200]   there's a lot of things to debug, so to speak,
[00:16:30.200 --> 00:16:31.360]   but that's one of the downsides
[00:16:31.360 --> 00:16:33.000]   of making really tight NumPy snippets.
[00:16:33.000 --> 00:16:34.600]   'Cause I did some of that back in the day
[00:16:34.600 --> 00:16:36.080]   and I was like, oh, this is so great.
[00:16:36.080 --> 00:16:38.680]   And then something blows up and it's like, oh crap.
[00:16:38.680 --> 00:16:40.000]   (laughing)
[00:16:40.000 --> 00:16:41.760]   - But wait, I'm like taking off on all these tangents
[00:16:41.760 --> 00:16:43.160]   and I'm actually really fascinated by it.
[00:16:43.160 --> 00:16:45.560]   - Oh, this is a conversation.
[00:16:45.560 --> 00:16:46.400]   - Totally.
[00:16:46.400 --> 00:16:48.120]   But like, so you were saying, so you're comparing to K,
[00:16:48.120 --> 00:16:50.080]   which actually Jeremy Howard did talk about
[00:16:50.080 --> 00:16:51.840]   and really, really praised.
[00:16:51.840 --> 00:16:52.840]   - Ah, great, yeah.
[00:16:52.840 --> 00:16:55.180]   - But then what are the other kind of languages
[00:16:55.180 --> 00:16:57.120]   that have like interesting pieces
[00:16:57.120 --> 00:16:59.520]   that could be useful for scientific computing?
[00:16:59.520 --> 00:17:02.480]   - Yes, well, I think we,
[00:17:02.480 --> 00:17:06.400]   so Jim Gray, the late great Jim Gray,
[00:17:06.400 --> 00:17:10.040]   wrote an amazing paper back in 2005
[00:17:10.040 --> 00:17:12.440]   called "Scientific Computing in the Coming Decade."
[00:17:12.440 --> 00:17:14.680]   It was prescient, it was ahead of its time, I think.
[00:17:14.680 --> 00:17:17.880]   I mean, it was, well, it was at Jim's time, so he knew it,
[00:17:17.880 --> 00:17:19.000]   but he was writing this great paper
[00:17:19.000 --> 00:17:20.680]   and it talked about how,
[00:17:20.680 --> 00:17:23.480]   so many different things he talked about in this paper,
[00:17:23.480 --> 00:17:25.280]   it's just, it's worth everyone to read it.
[00:17:25.280 --> 00:17:27.080]   But he talked about how we would need
[00:17:27.080 --> 00:17:29.480]   to have computational sort of notebooks,
[00:17:29.480 --> 00:17:32.440]   how we need to have metadata indices over large data
[00:17:32.440 --> 00:17:34.160]   that would have to live in data centers
[00:17:34.160 --> 00:17:35.720]   that we couldn't move anymore.
[00:17:35.720 --> 00:17:38.760]   We'd have to do computing, we'd have to move ideas to code.
[00:17:38.760 --> 00:17:41.840]   I'm sorry, move code to data, move ideas to data.
[00:17:41.840 --> 00:17:42.680]   All these different things.
[00:17:42.680 --> 00:17:44.120]   But one of the things he explores is
[00:17:44.120 --> 00:17:47.400]   why don't scientists use databases, right?
[00:17:47.400 --> 00:17:50.120]   Databases is the realm of like business apps
[00:17:50.120 --> 00:17:51.280]   and like Oracle nerds.
[00:17:51.280 --> 00:17:54.560]   Why don't geneticists and astrophysicists use databases?
[00:17:54.560 --> 00:17:57.520]   The closest they get is using HDF5, right?
[00:17:57.520 --> 00:17:59.000]   Which is really just like, it's a,
[00:17:59.000 --> 00:18:02.080]   okay, it's a file system, great, it's a tarball, right?
[00:18:02.080 --> 00:18:03.280]   It's a tarball that lays out a memory
[00:18:03.280 --> 00:18:04.560]   so you can compute on it, so that's great.
[00:18:04.560 --> 00:18:05.800]   You can do out-of-core execution on it.
[00:18:05.800 --> 00:18:08.680]   But why don't scientists use databases more?
[00:18:08.680 --> 00:18:10.880]   And so he kind of looked at this a little bit more.
[00:18:10.880 --> 00:18:12.800]   But one of the things I think
[00:18:12.800 --> 00:18:14.840]   that would really move scientific computing forward
[00:18:14.840 --> 00:18:16.600]   is to treat the data side of the problem
[00:18:16.600 --> 00:18:19.880]   as being more than just fast arrays.
[00:18:19.880 --> 00:18:22.920]   And actually, as we have more and more sensor systems
[00:18:22.920 --> 00:18:26.160]   that have more and more computational machinery
[00:18:26.160 --> 00:18:28.120]   to get to additional data sets,
[00:18:28.120 --> 00:18:31.080]   which then become transformed to additional data sets,
[00:18:31.080 --> 00:18:33.320]   that entire data provenance pipeline,
[00:18:33.320 --> 00:18:35.040]   even as businesses have to reinvent
[00:18:35.040 --> 00:18:36.320]   the enterprise data warehouse
[00:18:36.320 --> 00:18:38.240]   to do machine learning on all their business data,
[00:18:38.240 --> 00:18:41.320]   I think scientific computing has to honestly sit down
[00:18:41.320 --> 00:18:43.280]   and face this giant problem
[00:18:43.280 --> 00:18:45.600]   it's tried to ignore for a very long time,
[00:18:45.600 --> 00:18:48.480]   which is, how do we actually make sense of our data,
[00:18:48.480 --> 00:18:51.960]   not just some, like, slash home slash,
[00:18:51.960 --> 00:18:55.080]   some grad student's name slash temp slash project five
[00:18:55.080 --> 00:18:57.240]   slash whatever, like, we've got to actually do this
[00:18:57.240 --> 00:18:58.480]   for reals, right?
[00:18:58.480 --> 00:19:00.040]   So I think one of the ways
[00:19:00.040 --> 00:19:01.880]   to move scientific computing forward,
[00:19:02.800 --> 00:19:04.240]   that is on the completely opposite side
[00:19:04.240 --> 00:19:07.720]   of, like, going to the K land and fast APL land,
[00:19:07.720 --> 00:19:11.680]   is treating data, the metadata problem,
[00:19:11.680 --> 00:19:13.240]   and the data catalog problem,
[00:19:13.240 --> 00:19:15.920]   and in fact, the schema semantics problem
[00:19:15.920 --> 00:19:18.720]   as a first class problem for scientific computing.
[00:19:18.720 --> 00:19:20.960]   So if you look at what F# did with type providers
[00:19:20.960 --> 00:19:25.960]   and building a nice extensible catalog of schema
[00:19:25.960 --> 00:19:27.800]   that was actually part of your coding
[00:19:27.800 --> 00:19:29.600]   as you were using data sets,
[00:19:29.600 --> 00:19:32.040]   that, and they did that in, like, 10 years ago,
[00:19:32.040 --> 00:19:33.960]   that stuff is amazing, right?
[00:19:33.960 --> 00:19:36.120]   And that is something that we should make available.
[00:19:36.120 --> 00:19:39.520]   That's something that would be a game changer.
[00:19:39.520 --> 00:19:40.440]   I don't know if you saw this thing
[00:19:40.440 --> 00:19:44.520]   where some, like, council of, like, geneticists,
[00:19:44.520 --> 00:19:48.240]   they declared they would change, actually, gene names.
[00:19:48.240 --> 00:19:49.360]   Did you hear about this?
[00:19:49.360 --> 00:19:50.680]   - No, no. - They changed,
[00:19:50.680 --> 00:19:52.760]   there were gene names they changed
[00:19:52.760 --> 00:19:55.120]   from March 1, Sept 1, things like that,
[00:19:55.120 --> 00:19:59.440]   because power-informaticians use Excel so much,
[00:19:59.440 --> 00:20:00.880]   and when those show up in Excel data,
[00:20:00.880 --> 00:20:03.000]   Excel translates them into dates,
[00:20:03.000 --> 00:20:04.840]   and it screws them up. (laughing)
[00:20:04.840 --> 00:20:08.360]   So because of Excel's auto-formatting of their things,
[00:20:08.360 --> 00:20:10.960]   they're literally changing the names of these genes.
[00:20:10.960 --> 00:20:13.760]   This is how depraved science has gotten, right?
[00:20:13.760 --> 00:20:16.520]   Is that we will, not that those are necessarily
[00:20:16.520 --> 00:20:17.360]   great names to start with,
[00:20:17.360 --> 00:20:19.840]   but the fact that we will wrap ourselves around
[00:20:19.840 --> 00:20:21.960]   a fairly broken tool for this purpose.
[00:20:21.960 --> 00:20:25.360]   I don't know, that's, so for me,
[00:20:25.360 --> 00:20:28.360]   handling the data and schema problem for science,
[00:20:28.360 --> 00:20:31.040]   like, full stop, that's a huge part of the problem
[00:20:31.040 --> 00:20:32.240]   that needs to be done.
[00:20:32.240 --> 00:20:33.240]   Yeah. - That's so interesting.
[00:20:33.240 --> 00:20:35.360]   Is that something you're working on?
[00:20:35.360 --> 00:20:36.720]   - No, no, no, I have a company to run.
[00:20:36.720 --> 00:20:38.960]   Like, we're gonna make money, we're gonna make money,
[00:20:38.960 --> 00:20:40.320]   and yeah, no, no, no.
[00:20:40.320 --> 00:20:43.080]   But if I, when we get to a certain point
[00:20:43.080 --> 00:20:47.720]   where we have the resources to invest in additional projects,
[00:20:47.720 --> 00:20:48.920]   then this is one of the ones
[00:20:48.920 --> 00:20:50.280]   that I would absolutely try to tackle.
[00:20:50.280 --> 00:20:52.040]   We do have a project that's kind of in this vein,
[00:20:52.040 --> 00:20:53.120]   it's called Intake.
[00:20:53.120 --> 00:20:56.320]   It's not the sexiest sounding thing in the world,
[00:20:56.320 --> 00:20:58.720]   but Intake is a virtual data catalog
[00:20:58.720 --> 00:21:00.080]   that lets you set up a data server.
[00:21:00.080 --> 00:21:02.120]   So if you set up an Intake server over here,
[00:21:02.120 --> 00:21:04.440]   near your data, and you fire up the client,
[00:21:04.440 --> 00:21:07.400]   just in your terminal or in your notebook or whatever,
[00:21:07.400 --> 00:21:09.120]   you can connect to it, and you can basically do,
[00:21:09.120 --> 00:21:11.560]   you hit it with remote pandas and DAS calls
[00:21:11.560 --> 00:21:12.440]   and things like that.
[00:21:12.440 --> 00:21:13.960]   And you can also create transformed,
[00:21:13.960 --> 00:21:17.840]   almost like materialized views of those things
[00:21:17.840 --> 00:21:18.920]   on the server.
[00:21:18.920 --> 00:21:20.720]   So it's been used in a few projects,
[00:21:20.720 --> 00:21:21.600]   some people are starting to pick it up,
[00:21:21.600 --> 00:21:23.480]   but it's something I would recommend people check out,
[00:21:23.480 --> 00:21:24.520]   it's called Intake.
[00:21:24.520 --> 00:21:26.160]   - Cool, all right, we'll put a link to it.
[00:21:26.160 --> 00:21:27.000]   - Yeah.
[00:21:27.000 --> 00:21:29.560]   - Do you, so can you give me some examples
[00:21:29.560 --> 00:21:33.680]   of who your customers are and what's the value,
[00:21:33.680 --> 00:21:34.680]   this is like such business speak,
[00:21:34.680 --> 00:21:37.760]   what's the value that they get out of your company?
[00:21:37.760 --> 00:21:39.880]   - Yeah, so we have a couple of different things
[00:21:39.880 --> 00:21:41.080]   that we sell.
[00:21:41.080 --> 00:21:42.440]   For a while now, we've been selling
[00:21:42.440 --> 00:21:44.280]   a enterprise machine learning platform
[00:21:44.280 --> 00:21:46.320]   called Anaconda Enterprise, and that has,
[00:21:46.320 --> 00:21:51.720]   it's based on Kubernetes and data scientists can,
[00:21:51.720 --> 00:21:53.560]   IT can stand it up, data scientists log into it,
[00:21:53.560 --> 00:21:56.720]   and they have a managed, governed notebook environment,
[00:21:56.720 --> 00:21:58.040]   well, any number of different UIs,
[00:21:58.040 --> 00:22:00.360]   but generally people prefer notebook environments.
[00:22:00.360 --> 00:22:03.760]   And then they have one-click deploy for dashboards,
[00:22:03.760 --> 00:22:06.120]   for like notebooks and things like that.
[00:22:06.120 --> 00:22:07.560]   They can run machine learning models,
[00:22:07.560 --> 00:22:10.080]   you know, have rest endpoints they deploy.
[00:22:10.080 --> 00:22:13.160]   It's sort of like, it's a, yeah,
[00:22:13.160 --> 00:22:15.160]   a big data science platform thing.
[00:22:15.160 --> 00:22:16.680]   There's another thing we sell
[00:22:16.680 --> 00:22:19.000]   that is just the package server.
[00:22:19.000 --> 00:22:21.080]   So a lot of the value that businesses get from us
[00:22:21.080 --> 00:22:23.600]   is that they have a actual vendor-backed
[00:22:23.600 --> 00:22:26.920]   place to get binaries to run,
[00:22:26.920 --> 00:22:28.160]   like in their governed environments,
[00:22:28.160 --> 00:22:30.640]   which actually doesn't matter to them, right?
[00:22:30.640 --> 00:22:32.800]   And so in that situation,
[00:22:32.800 --> 00:22:35.320]   what they wanna do is they have like a server,
[00:22:35.320 --> 00:22:37.360]   they buy a server from us that has the packages,
[00:22:37.360 --> 00:22:39.640]   and then it's proxied locally for them.
[00:22:39.640 --> 00:22:42.040]   We don't get to see all the packages they're downloading,
[00:22:42.040 --> 00:22:44.000]   what they're doing with their data analysis,
[00:22:44.000 --> 00:22:45.760]   and they also have faster access
[00:22:45.760 --> 00:22:47.280]   to all of these different packages.
[00:22:47.280 --> 00:22:48.920]   They also, they're IT people,
[00:22:48.920 --> 00:22:50.160]   this is a really important thing.
[00:22:50.160 --> 00:22:53.080]   IT has a chance then to also govern which clusters,
[00:22:53.080 --> 00:22:54.800]   which machines, and which environments
[00:22:54.800 --> 00:22:57.720]   can use which versions of which libraries, right?
[00:22:57.720 --> 00:22:58.760]   Which is a really important thing
[00:22:58.760 --> 00:23:00.320]   because in an enterprise environment,
[00:23:00.320 --> 00:23:01.880]   you have data scientists who want the latest,
[00:23:01.880 --> 00:23:03.480]   the greatest, and bleeding edge everything,
[00:23:03.480 --> 00:23:05.000]   and then you've got production machines,
[00:23:05.000 --> 00:23:06.760]   which you do not want getting
[00:23:06.760 --> 00:23:07.840]   the latest and greatest everything.
[00:23:07.840 --> 00:23:09.200]   You want to know exactly which version,
[00:23:09.200 --> 00:23:11.600]   how many CVEs, which ones are patched,
[00:23:11.600 --> 00:23:13.320]   and that's all that runs on production, right?
[00:23:13.320 --> 00:23:14.920]   So this is a package server
[00:23:14.920 --> 00:23:18.440]   that gives businesses the ability to do that.
[00:23:18.440 --> 00:23:21.680]   So those are primarily our two commercial products,
[00:23:21.680 --> 00:23:23.040]   and we'll be coming up with some more things
[00:23:23.040 --> 00:23:24.560]   later in the year.
[00:23:24.560 --> 00:23:26.120]   It's an individual commercial edition
[00:23:26.120 --> 00:23:28.920]   that individual practitioners can buy, things like that.
[00:23:28.920 --> 00:23:31.400]   - And you've been doing this a while, right?
[00:23:31.400 --> 00:23:33.360]   Like at least a decade?
[00:23:33.360 --> 00:23:35.280]   - Not, no, not a decade.
[00:23:35.280 --> 00:23:38.560]   An octal decade, I mean we started in 2012, so.
[00:23:38.560 --> 00:23:39.680]   - Nice, I guess like,
[00:23:39.680 --> 00:23:44.280]   even that is quite a long time, I think, for this space.
[00:23:44.280 --> 00:23:47.080]   I'm curious, like when you started,
[00:23:47.080 --> 00:23:48.320]   what kinds of customers,
[00:23:48.320 --> 00:23:50.760]   or like what industries were using you the most,
[00:23:50.760 --> 00:23:54.240]   and how has that changed over the last eight years?
[00:23:54.240 --> 00:23:55.640]   - Yeah, when we started,
[00:23:55.640 --> 00:23:58.720]   it was very heavily in the finance.
[00:23:58.720 --> 00:24:01.600]   So hedge funds, investment banks, things like that.
[00:24:01.600 --> 00:24:04.320]   There was a heavy use of Python there at the time.
[00:24:04.320 --> 00:24:10.320]   And we were doing a lot of consulting and training,
[00:24:10.320 --> 00:24:14.160]   open source consulting, standard sort of things like that.
[00:24:14.160 --> 00:24:16.760]   Unlike a lot of, nowadays,
[00:24:16.760 --> 00:24:18.640]   you see a lot of these open source,
[00:24:18.640 --> 00:24:19.960]   venture-backed open source companies
[00:24:19.960 --> 00:24:22.240]   that have like a product,
[00:24:22.240 --> 00:24:24.600]   and it's like, here's our open source Fubar,
[00:24:24.600 --> 00:24:26.880]   and here's the enterprise Fubar++, right?
[00:24:26.880 --> 00:24:28.560]   And then they like,
[00:24:28.560 --> 00:24:32.440]   and then Amazon builds a clone of it off their open source,
[00:24:32.440 --> 00:24:34.400]   and they go public anyway, make tons of money.
[00:24:34.400 --> 00:24:36.840]   This is a play that many companies have done,
[00:24:36.840 --> 00:24:38.080]   especially around some of the big data
[00:24:38.080 --> 00:24:39.200]   infrastructure projects, right?
[00:24:39.200 --> 00:24:40.800]   It's a pretty popular move.
[00:24:40.800 --> 00:24:43.040]   We are an open source company
[00:24:43.040 --> 00:24:45.320]   that supports an ecosystem of innovation.
[00:24:45.320 --> 00:24:46.960]   So there's a lot of things that are out there
[00:24:46.960 --> 00:24:49.120]   that we deliver and ship via Anaconda
[00:24:49.120 --> 00:24:50.680]   that we ourselves don't write.
[00:24:50.680 --> 00:24:54.360]   And so that innovation space has changed,
[00:24:54.360 --> 00:24:56.480]   and it's gotten sucked into so many different things.
[00:24:56.480 --> 00:24:58.920]   So now we've seen everybody,
[00:24:58.920 --> 00:25:02.840]   I mean, insurance, oil and gas, logistics,
[00:25:02.840 --> 00:25:04.480]   DOD, and three-letter agencies,
[00:25:04.480 --> 00:25:06.480]   and just like everybody is using Python
[00:25:06.480 --> 00:25:08.520]   to do data analysis and machine learning.
[00:25:08.520 --> 00:25:10.080]   So it's just literally everywhere,
[00:25:10.080 --> 00:25:11.760]   like sports betting sites,
[00:25:11.760 --> 00:25:13.360]   Netflix and the Ubers of the world,
[00:25:13.360 --> 00:25:15.880]   like everybody is doing this stuff.
[00:25:15.880 --> 00:25:19.240]   Now, not all of them are paying us yet,
[00:25:19.240 --> 00:25:23.120]   paying customers, but that diversification of,
[00:25:23.120 --> 00:25:24.800]   well, I wouldn't say diversification,
[00:25:24.800 --> 00:25:28.200]   but that growth and adoption was what we were hoping
[00:25:28.200 --> 00:25:30.160]   to unleash, right, when we started the company.
[00:25:30.160 --> 00:25:32.960]   And so it's been really great to see all that happening.
[00:25:32.960 --> 00:25:34.200]   We couldn't have predicted deep learning.
[00:25:34.200 --> 00:25:35.800]   We couldn't have predicted that machine learning
[00:25:35.800 --> 00:25:37.480]   would have been the thing to take off.
[00:25:37.480 --> 00:25:39.920]   We were really thinking that it would be more
[00:25:39.920 --> 00:25:42.800]   rapid dashboards around notebooks, around building,
[00:25:42.800 --> 00:25:45.520]   here's a data analysis, I'm a subject matter expert,
[00:25:45.520 --> 00:25:47.240]   'cause I can write a little bit of Python code,
[00:25:47.240 --> 00:25:51.400]   I've now can produce a much more meaningful,
[00:25:51.400 --> 00:25:53.480]   rich, interactive dashboard and control pane
[00:25:53.480 --> 00:25:55.640]   for my business processes or for my whatever,
[00:25:55.640 --> 00:25:57.920]   like heavy industrial machinery.
[00:25:57.920 --> 00:26:00.280]   We saw that happening pretty well in the 2000s
[00:26:00.280 --> 00:26:01.680]   around a rich client tool set
[00:26:01.680 --> 00:26:04.520]   as sort of a MATLAB displacer.
[00:26:04.520 --> 00:26:06.560]   But now with machine learning on the rise,
[00:26:06.560 --> 00:26:09.280]   it's completely flipped Python usage into a different mode.
[00:26:09.280 --> 00:26:11.440]   That's the, as you would know at Ways and Biases,
[00:26:11.440 --> 00:26:13.680]   that's the dominant conversation on Python.
[00:26:13.680 --> 00:26:15.160]   But these other use cases are still there.
[00:26:15.160 --> 00:26:16.680]   There's still a lot of people using Python
[00:26:16.680 --> 00:26:19.200]   for all these engineering simulation things.
[00:26:19.200 --> 00:26:21.960]   And so anyway, it's just been great to see all this growth
[00:26:21.960 --> 00:26:23.920]   and diversification of use cases.
[00:26:23.920 --> 00:26:28.120]   - Is machine learning even the top use case that you see?
[00:26:28.120 --> 00:26:29.600]   I feel like it's certainly the,
[00:26:29.600 --> 00:26:31.120]   it feels like the buzziest right now,
[00:26:31.120 --> 00:26:33.440]   but I always wonder what's the reality
[00:26:33.440 --> 00:26:35.280]   of the usage volumes versus what you see on the ground.
[00:26:35.280 --> 00:26:39.840]   - It's the aspiration that people get paid for,
[00:26:39.840 --> 00:26:40.680]   (laughing)
[00:26:40.680 --> 00:26:41.600]   I'll put it that way.
[00:26:41.600 --> 00:26:47.680]   I think there's a strong disconnect between older businesses.
[00:26:47.680 --> 00:26:49.800]   I would say Python has crossed the chasm, right?
[00:26:49.800 --> 00:26:52.560]   So you talk about the chasm of technology
[00:26:52.560 --> 00:26:53.680]   and crossing the chasm.
[00:26:53.680 --> 00:26:55.080]   Python has crossed the chasm.
[00:26:55.080 --> 00:26:56.160]   On the other side of the chasm,
[00:26:56.160 --> 00:26:58.720]   the way that this kind of innovative technology has landed
[00:26:58.720 --> 00:26:59.920]   is that you have a lot of buyers
[00:26:59.920 --> 00:27:01.000]   who are not as sophisticated
[00:27:01.000 --> 00:27:02.760]   about what it is they really wanna buy
[00:27:02.760 --> 00:27:04.160]   or what it is they're buying
[00:27:04.160 --> 00:27:06.560]   or how ready they are as a business
[00:27:06.560 --> 00:27:08.880]   to adopt what they've bought, okay?
[00:27:08.880 --> 00:27:11.040]   So you can buy the fanciest Ferrari,
[00:27:11.040 --> 00:27:12.720]   but if you have a dirt track road,
[00:27:12.720 --> 00:27:14.120]   it's not gonna go as fast
[00:27:14.120 --> 00:27:16.640]   as if you have an actual smooth paved road.
[00:27:16.640 --> 00:27:18.080]   So a lot of businesses have this problem
[00:27:18.080 --> 00:27:21.640]   where they can buy the hottest, sweetest ML gear,
[00:27:21.640 --> 00:27:24.200]   team tooling, blah, blah, blah,
[00:27:24.200 --> 00:27:28.200]   but then their internal data is just a mishmash.
[00:27:28.200 --> 00:27:30.280]   And so you spend 80% of your time
[00:27:30.280 --> 00:27:33.560]   digging that ML team out of the data swamp, right?
[00:27:33.560 --> 00:27:37.000]   So that message, I think people are starting to get it now
[00:27:37.000 --> 00:27:40.360]   as they come over into the chasm of mist,
[00:27:40.360 --> 00:27:46.360]   the trough of what, not despair, something, yeah.
[00:27:46.360 --> 00:27:48.280]   - Disillusionment. - Disillusionment.
[00:27:48.280 --> 00:27:50.680]   Disillusionment, that's what it is, that one.
[00:27:50.680 --> 00:27:53.480]   Right, and so, but the truth is this.
[00:27:53.480 --> 00:27:55.760]   It's like there's an ML hierarchy of needs
[00:27:55.760 --> 00:27:57.080]   just like Maslow's, right?
[00:27:57.080 --> 00:27:58.760]   And if you don't have your data stuff together,
[00:27:58.760 --> 00:28:00.480]   if you don't understand the domain problem
[00:28:00.480 --> 00:28:01.520]   you're trying to solve,
[00:28:01.520 --> 00:28:03.480]   you have no business even doing data science on it.
[00:28:03.480 --> 00:28:04.480]   If you haven't done data science,
[00:28:04.480 --> 00:28:06.400]   there's no models to go and optimize
[00:28:06.400 --> 00:28:07.800]   with machine learning, right?
[00:28:07.800 --> 00:28:10.480]   But if you get all that in place,
[00:28:10.480 --> 00:28:12.640]   then machine learning can absolutely deliver on the promise.
[00:28:12.640 --> 00:28:14.080]   So I think people try to buy the promise,
[00:28:14.080 --> 00:28:15.960]   but most of the people they pay are out there
[00:28:15.960 --> 00:28:17.160]   slugging a bunch of like,
[00:28:17.160 --> 00:28:19.680]   trying to basically denormalize data, dedupe data,
[00:28:19.680 --> 00:28:21.840]   and just do a lot of that kind of stuff.
[00:28:21.840 --> 00:28:23.680]   - But you actually see, I mean,
[00:28:23.680 --> 00:28:26.520]   most of the verticals that you mentioned, I think,
[00:28:26.520 --> 00:28:29.080]   are not the first things that come to mind here
[00:28:29.080 --> 00:28:31.760]   in Silicon Valley for ML applications.
[00:28:31.760 --> 00:28:34.520]   But you actually see like insurance doing ML
[00:28:34.520 --> 00:28:37.720]   and thinking of it as ML, just as a specific example?
[00:28:37.720 --> 00:28:38.720]   - Oh, absolutely.
[00:28:38.720 --> 00:28:40.360]   So the hardcore finance folks
[00:28:40.360 --> 00:28:42.440]   are probably the only people I would say
[00:28:42.440 --> 00:28:45.280]   that lead Silicon Valley in terms of ML.
[00:28:45.280 --> 00:28:47.560]   I mean, the hedge funds were there first
[00:28:47.560 --> 00:28:50.080]   because they operate in a pure data environment.
[00:28:50.080 --> 00:28:51.760]   And the thing about that data environment
[00:28:51.760 --> 00:28:53.240]   is everyone else is operating
[00:28:53.240 --> 00:28:54.920]   in the same pure data environment.
[00:28:54.920 --> 00:28:57.360]   And by the way, it's all zero sum.
[00:28:57.360 --> 00:29:01.080]   So you, like, and if you screw up by a millisecond,
[00:29:01.080 --> 00:29:03.000]   you lose millions of dollars.
[00:29:03.000 --> 00:29:05.240]   So it's incredibly hard odds,
[00:29:05.240 --> 00:29:09.440]   or hard boundary conditions to be optimizing in, right?
[00:29:09.440 --> 00:29:11.160]   And I think Silicon Valley,
[00:29:11.160 --> 00:29:13.520]   there's a lot of, it's a lot of consumer behavior.
[00:29:13.520 --> 00:29:15.680]   It's a lot of like this kind of thing.
[00:29:15.680 --> 00:29:17.200]   Certainly anything in ad tech
[00:29:17.200 --> 00:29:19.000]   and kind of the attention economy,
[00:29:19.000 --> 00:29:23.000]   the ML there is fairly low stakes, right?
[00:29:23.000 --> 00:29:25.360]   I would say that, I mean, of course,
[00:29:25.360 --> 00:29:28.120]   hundreds of billions of dollars of corporate valuation
[00:29:28.120 --> 00:29:28.960]   hang in the balance.
[00:29:28.960 --> 00:29:31.040]   But like, if you screw a little bit of something up,
[00:29:31.040 --> 00:29:32.880]   it's like, well, they'll be back tomorrow, doom scrolling.
[00:29:32.880 --> 00:29:35.200]   So we'll give them some better content tomorrow.
[00:29:35.200 --> 00:29:37.680]   But when you're in insurance and these other things,
[00:29:37.680 --> 00:29:40.200]   the ML, those models, you know,
[00:29:40.200 --> 00:29:41.960]   the kinds of diligence that a credit card company
[00:29:41.960 --> 00:29:43.960]   has around its models and model integrity,
[00:29:43.960 --> 00:29:45.520]   the kinds of actuarial work
[00:29:45.520 --> 00:29:49.520]   that goes into building models at an insurance company,
[00:29:49.520 --> 00:29:50.440]   that's real.
[00:29:50.440 --> 00:29:51.880]   That's like, there's real hard uncertainty.
[00:29:51.880 --> 00:29:54.640]   If you screw up, that's $100 million screw up, right?
[00:29:54.640 --> 00:29:57.760]   So there's real stuff happening there.
[00:29:57.760 --> 00:29:59.760]   And there are no lightweights on this stuff.
[00:29:59.760 --> 00:30:01.840]   They're doing real things, yeah.
[00:30:01.840 --> 00:30:02.680]   - Cool.
[00:30:02.680 --> 00:30:04.520]   I guess when I've talked to insurance companies,
[00:30:04.520 --> 00:30:07.000]   it's felt like there's almost these sort of
[00:30:07.000 --> 00:30:09.480]   two separate teams that feel a little bit at odds
[00:30:09.480 --> 00:30:10.320]   with each other.
[00:30:10.320 --> 00:30:12.760]   Like, there's sort of like the old school math guys,
[00:30:12.760 --> 00:30:14.760]   like the actuaries who are like,
[00:30:14.760 --> 00:30:16.200]   what is this, we've been doing ML forever.
[00:30:16.200 --> 00:30:17.760]   Like, this is just a rebranding
[00:30:17.760 --> 00:30:19.560]   of the stuff we've always been doing.
[00:30:19.560 --> 00:30:20.960]   And then a couple of guys off to the side,
[00:30:20.960 --> 00:30:22.840]   maybe doing some crazy deep learning projects
[00:30:22.840 --> 00:30:25.520]   that you wonder how connected they are to the business.
[00:30:25.520 --> 00:30:27.440]   Like, do you feel that same dynamic?
[00:30:27.440 --> 00:30:28.320]   - Oh yeah, absolutely.
[00:30:28.320 --> 00:30:31.480]   I mean, you know, any organization over like 50 people
[00:30:31.480 --> 00:30:32.680]   is a complex beast, right?
[00:30:32.680 --> 00:30:34.880]   So even 50 people can be pretty complex.
[00:30:34.880 --> 00:30:38.240]   So these larger firms,
[00:30:38.240 --> 00:30:40.720]   there is definitely a struggle internally
[00:30:40.720 --> 00:30:43.120]   as they do this data transformation
[00:30:43.120 --> 00:30:44.360]   into the cybernetic era,
[00:30:44.360 --> 00:30:46.320]   is what I've been calling it, the cybernetic era.
[00:30:46.320 --> 00:30:50.600]   And many of them, the theory of action is still open, right?
[00:30:50.600 --> 00:30:53.400]   It's like, oh, we sell this particular insurance policy
[00:30:53.400 --> 00:30:56.480]   and we'll see what comes back five years from now, right?
[00:30:56.480 --> 00:30:57.720]   And when we get screwed,
[00:30:57.720 --> 00:30:59.840]   like we'll look at our five year retroactive performance
[00:30:59.840 --> 00:31:02.360]   and then we'll know if the model is correct.
[00:31:02.360 --> 00:31:05.040]   And those kind of old guard folks who are, you know, yeah,
[00:31:05.040 --> 00:31:07.240]   a bunch of actuaries writing a bunch of SaaS code,
[00:31:07.240 --> 00:31:08.640]   that's some old school stuff.
[00:31:08.640 --> 00:31:10.800]   And then there are new people in that space
[00:31:10.800 --> 00:31:12.120]   who have access to the data,
[00:31:12.120 --> 00:31:13.600]   who have the statistical background
[00:31:13.600 --> 00:31:15.760]   and who know they can do way better.
[00:31:15.760 --> 00:31:17.200]   And so there is this kind of,
[00:31:17.200 --> 00:31:18.440]   there is a conversation happening.
[00:31:18.440 --> 00:31:20.200]   I mean, within credit card companies, you'll have,
[00:31:20.200 --> 00:31:21.800]   like, they're a great example, right?
[00:31:21.800 --> 00:31:23.280]   'Cause there's like regulatory pressure,
[00:31:23.280 --> 00:31:25.000]   there's like old school models in SaaS,
[00:31:25.000 --> 00:31:27.960]   there's newer people trying to do some better credit models,
[00:31:27.960 --> 00:31:29.840]   and there's really cutting edge people
[00:31:29.840 --> 00:31:32.640]   doing real time risk, real time fraud,
[00:31:32.640 --> 00:31:34.800]   like all these kinds of things,
[00:31:34.800 --> 00:31:35.920]   using deep learning sometimes,
[00:31:35.920 --> 00:31:38.480]   using all sorts of GPU based clusters.
[00:31:38.480 --> 00:31:40.880]   So you just see a whole pile of different things
[00:31:40.880 --> 00:31:43.240]   within like a credit card company.
[00:31:43.240 --> 00:31:45.320]   That you might not see it in Silicon Valley,
[00:31:45.320 --> 00:31:46.160]   it's gonna be more monoculture
[00:31:46.160 --> 00:31:48.240]   'cause there's less tech overburden
[00:31:48.240 --> 00:31:50.200]   that they had to like dig out from, right?
[00:31:50.200 --> 00:31:52.080]   There's like, well, we need a bunch of machines in the cloud,
[00:31:52.080 --> 00:31:53.360]   you got it, 'cause there's no regulators
[00:31:53.360 --> 00:31:54.560]   checking any of this stuff.
[00:31:54.560 --> 00:31:56.280]   So, yeah.
[00:31:56.280 --> 00:31:57.920]   - What do you make of like, I guess like
[00:31:57.920 --> 00:32:00.240]   the MATLABs and the SaaSs of the world?
[00:32:00.240 --> 00:32:03.120]   Like, is that ever like a sensible choice for someone
[00:32:03.120 --> 00:32:04.920]   for their tech stack?
[00:32:04.920 --> 00:32:09.920]   Or is that just a completely legacy software choice?
[00:32:09.920 --> 00:32:11.000]   - For DeNovo?
[00:32:11.000 --> 00:32:15.600]   Well, let me see here.
[00:32:15.600 --> 00:32:16.760]   I think the best way to answer that
[00:32:16.760 --> 00:32:19.960]   is that anytime we make a technology choice,
[00:32:19.960 --> 00:32:22.840]   we should be very respectful of Conway's Law,
[00:32:22.840 --> 00:32:25.280]   which is that the technology systems that we build,
[00:32:25.280 --> 00:32:26.640]   the software systems we build,
[00:32:26.640 --> 00:32:28.240]   are a reflection of the communication patterns
[00:32:28.240 --> 00:32:32.000]   within the teams that built it, right?
[00:32:32.000 --> 00:32:34.000]   - Third time that's come up this week in interviews,
[00:32:34.000 --> 00:32:34.920]   by the way. - Really?
[00:32:34.920 --> 00:32:35.760]   Yeah.
[00:32:35.760 --> 00:32:39.720]   But it hits the ML stuff in a different way,
[00:32:39.720 --> 00:32:41.520]   which is that if those different teams
[00:32:41.520 --> 00:32:43.360]   speak different languages, then you have two teams.
[00:32:43.360 --> 00:32:44.760]   If the same team speaks two different languages,
[00:32:44.760 --> 00:32:46.920]   you have two teams, right?
[00:32:46.920 --> 00:32:48.840]   And we see this actually with people
[00:32:48.840 --> 00:32:51.040]   trying to get Python into ML production,
[00:32:51.040 --> 00:32:52.600]   where sometimes those production processes
[00:32:52.600 --> 00:32:54.360]   are optimized for managing a pile of Java
[00:32:54.360 --> 00:32:55.320]   with a bunch of Maven, right?
[00:32:55.320 --> 00:32:58.480]   Or it's like you had to recode all this in C++
[00:32:58.480 --> 00:33:00.560]   'cause we only deploy TensorFlow C++.
[00:33:00.560 --> 00:33:02.360]   So there's this kind of thing.
[00:33:02.360 --> 00:33:03.840]   When you have a language barrier,
[00:33:03.840 --> 00:33:07.120]   you create two technology fiefdoms,
[00:33:07.120 --> 00:33:10.240]   which then lead to a bimodal or trimodal
[00:33:10.240 --> 00:33:12.480]   or whatever kind of software product.
[00:33:12.480 --> 00:33:14.640]   And an ML system is a software product,
[00:33:14.640 --> 00:33:15.640]   you know, however you wanna look at it.
[00:33:15.640 --> 00:33:17.720]   It fundamentally has a pile of software in it.
[00:33:17.720 --> 00:33:20.120]   So when we talk about this question of like,
[00:33:20.120 --> 00:33:21.920]   is MATLAB or SAS ever an appropriate choice?
[00:33:21.920 --> 00:33:23.200]   The answer is, well, obviously, yes,
[00:33:23.200 --> 00:33:25.160]   'cause the whole team knows MATLAB or SAS,
[00:33:25.160 --> 00:33:26.440]   and they're building this,
[00:33:26.440 --> 00:33:28.720]   then you should probably use MATLAB or SAS,
[00:33:28.720 --> 00:33:31.640]   like even for brand new projects starting tomorrow.
[00:33:31.640 --> 00:33:34.160]   However, the question then is taking a step back.
[00:33:34.160 --> 00:33:36.040]   If I'm the manager of this team,
[00:33:36.040 --> 00:33:39.560]   how much longer do I want to have a team
[00:33:39.560 --> 00:33:42.560]   that only knows how to use MATLAB or SAS,
[00:33:42.560 --> 00:33:45.360]   when clearly all the papers at ICML, whatever,
[00:33:45.360 --> 00:33:48.080]   are being published in Python, right?
[00:33:48.080 --> 00:33:50.640]   So like, you gotta sort of make that call
[00:33:50.640 --> 00:33:51.680]   if you're the manager.
[00:33:51.680 --> 00:33:54.240]   So I would say that the answer is yes,
[00:33:54.240 --> 00:33:55.960]   but if you're doing that,
[00:33:55.960 --> 00:33:58.280]   you should be aware that there's all this innovation
[00:33:58.280 --> 00:34:00.120]   happening in different languages.
[00:34:00.120 --> 00:34:01.360]   And even if we're bringing those languages
[00:34:01.360 --> 00:34:02.400]   into a hybrid environment,
[00:34:02.400 --> 00:34:03.920]   if you say, fine, I'll hybridize,
[00:34:03.920 --> 00:34:06.480]   I got my legacy MATLAB that's never going away
[00:34:06.480 --> 00:34:08.640]   because that's how we modeled like airflow
[00:34:08.640 --> 00:34:09.880]   through this turbine system.
[00:34:09.880 --> 00:34:12.000]   I'm not gonna redo all that work.
[00:34:12.000 --> 00:34:14.880]   But then I have to build discipline about how to hybridize,
[00:34:14.880 --> 00:34:16.480]   how to bring these people forward
[00:34:16.480 --> 00:34:17.600]   so they know some Python,
[00:34:17.600 --> 00:34:19.160]   bring the Python technology back
[00:34:19.160 --> 00:34:20.720]   to be able to couple with the MATLAB
[00:34:20.720 --> 00:34:24.000]   and see yourself as having to become an expert
[00:34:24.000 --> 00:34:25.560]   in doing that, right?
[00:34:25.560 --> 00:34:28.800]   So I think that's the answer is yes.
[00:34:28.800 --> 00:34:29.640]   That would be my answer.
[00:34:29.640 --> 00:34:31.280]   Yes, you could absolutely make a justification
[00:34:31.280 --> 00:34:33.200]   for starting new projects and those things.
[00:34:33.200 --> 00:34:36.920]   But generally, if you're doing it in teams
[00:34:36.920 --> 00:34:38.120]   that already know those languages,
[00:34:38.120 --> 00:34:40.720]   I probably wouldn't recommend it for a Python team.
[00:34:40.720 --> 00:34:42.040]   - What about, okay, what about R?
[00:34:42.040 --> 00:34:43.000]   Like, where does that sit?
[00:34:43.000 --> 00:34:46.720]   Is that ever like a reasonable choice for a team
[00:34:46.720 --> 00:34:50.160]   where you have Greenfield or not?
[00:34:50.160 --> 00:34:51.000]   - No, of course.
[00:34:51.000 --> 00:34:52.520]   I mean, there's lots of people who do that.
[00:34:52.520 --> 00:34:53.440]   - And what would be going on
[00:34:53.440 --> 00:34:57.280]   that you would choose to use R versus Python?
[00:34:57.280 --> 00:34:59.360]   - Well, for me, 'cause I'm a Python expert,
[00:34:59.360 --> 00:35:00.480]   I would choose Python.
[00:35:00.480 --> 00:35:03.240]   So the only reason I would have my team use R
[00:35:03.240 --> 00:35:06.640]   is if there's a lot of existing stuff that's in R
[00:35:06.640 --> 00:35:08.520]   or they're all R experts,
[00:35:08.520 --> 00:35:10.360]   in which case I'm not gonna try to convert them to Python.
[00:35:10.360 --> 00:35:13.200]   I'm gonna try to make the best go of R with them, right?
[00:35:13.200 --> 00:35:16.160]   But if there are really new capabilities
[00:35:16.160 --> 00:35:17.280]   and things that are only available
[00:35:17.280 --> 00:35:20.400]   in like a Python bridge to some CPU or some GPU stuff,
[00:35:20.400 --> 00:35:22.000]   then I would encourage,
[00:35:22.000 --> 00:35:24.680]   I would have to hire some people who are polyglot
[00:35:24.680 --> 00:35:26.520]   that can build that bridge.
[00:35:26.520 --> 00:35:28.720]   So again, it comes down to the teams.
[00:35:28.720 --> 00:35:30.360]   - Although I feel like you do,
[00:35:30.360 --> 00:35:31.800]   I don't think you really have the perspective
[00:35:31.800 --> 00:35:34.000]   that like kind of all languages are created equal, right?
[00:35:34.000 --> 00:35:36.440]   I mean, of course, you know, we hit like the real world
[00:35:36.440 --> 00:35:38.400]   and you know, we have to choose our language
[00:35:38.400 --> 00:35:39.840]   maybe around what library is available
[00:35:39.840 --> 00:35:41.600]   or like what's gonna be maintainable.
[00:35:41.600 --> 00:35:44.280]   But I'm curious what you kind of make of R.
[00:35:44.280 --> 00:35:46.560]   I mean, when I was in grad school, I used all R
[00:35:46.560 --> 00:35:47.960]   and I absolutely loved it.
[00:35:47.960 --> 00:35:49.880]   And then I had this experience of like,
[00:35:49.880 --> 00:35:52.080]   you know, kind of seeing pandas and NumPy
[00:35:52.080 --> 00:35:53.560]   and just be like, well, this is way better.
[00:35:53.560 --> 00:35:55.960]   Like, I just want to switch to this and use this.
[00:35:55.960 --> 00:35:57.840]   - Well, some people take the opposite position
[00:35:57.840 --> 00:35:58.680]   from you on that.
[00:35:58.680 --> 00:35:59.520]   They would say, I went to R
[00:35:59.520 --> 00:36:01.880]   and now I can think like a statistician again
[00:36:01.880 --> 00:36:04.600]   and actually do my, you know, express what I'm trying.
[00:36:04.600 --> 00:36:06.800]   'Cause like the tidyverse and dplyr
[00:36:06.800 --> 00:36:08.200]   and these things are so nice
[00:36:08.200 --> 00:36:09.960]   and ggplot's gorgeous and all these things.
[00:36:09.960 --> 00:36:10.960]   - Yeah, that's true.
[00:36:10.960 --> 00:36:14.840]   - A lot of the R advocates, they have good points.
[00:36:14.840 --> 00:36:18.280]   Like there is, I would say a more,
[00:36:18.280 --> 00:36:20.000]   monoculture is the wrong term.
[00:36:20.000 --> 00:36:22.720]   There's a smaller set of obvious choices in R.
[00:36:22.720 --> 00:36:25.520]   And if you've used those and the team around you uses those,
[00:36:25.520 --> 00:36:27.480]   you can get to very nice results
[00:36:27.480 --> 00:36:29.520]   without a whole lot of like people tearing their hair out
[00:36:29.520 --> 00:36:30.720]   because they have conflicting versions
[00:36:30.720 --> 00:36:32.320]   of like 15 different plotting libraries
[00:36:32.320 --> 00:36:34.320]   like we have in the Python land, right?
[00:36:34.320 --> 00:36:38.560]   So anyway, that's, so yeah, I don't know.
[00:36:38.560 --> 00:36:40.280]   Of course, I don't think all languages are created equal,
[00:36:40.280 --> 00:36:41.680]   but you did ask me a question,
[00:36:41.680 --> 00:36:43.040]   which is, is there ever reason
[00:36:43.040 --> 00:36:44.160]   to do these different languages?
[00:36:44.160 --> 00:36:45.560]   And I said, yes, there's always a reason
[00:36:45.560 --> 00:36:46.640]   to use these other languages.
[00:36:46.640 --> 00:36:48.400]   - That was probably a poorly formed question.
[00:36:48.400 --> 00:36:50.000]   I was giving you too many outs.
[00:36:50.000 --> 00:36:51.120]   - You're giving me an out for sure.
[00:36:51.120 --> 00:36:53.320]   - A CEO of a company that wants to sell software,
[00:36:53.320 --> 00:36:55.640]   I know you don't want to take too hard of a position.
[00:36:55.640 --> 00:36:57.040]   - Well, Anaconda does support R.
[00:36:57.040 --> 00:37:00.680]   I will point out, Anaconda does support R and R packages
[00:37:00.680 --> 00:37:02.480]   managed within the Conda environment.
[00:37:02.480 --> 00:37:04.120]   So you can actually manage,
[00:37:04.120 --> 00:37:05.680]   and one of the things that we're doing
[00:37:05.680 --> 00:37:07.600]   is actually looking at the precise versions
[00:37:07.600 --> 00:37:09.000]   and building the dependency graph.
[00:37:09.000 --> 00:37:09.840]   So if you want to go in
[00:37:09.840 --> 00:37:11.920]   and you don't want to just take a whole snapshot,
[00:37:11.920 --> 00:37:13.480]   like a whole cramped snapshot,
[00:37:13.480 --> 00:37:14.520]   and you want to say, well,
[00:37:14.520 --> 00:37:16.920]   what if I want to use this version of this thing,
[00:37:16.920 --> 00:37:18.200]   but that version of that thing,
[00:37:18.200 --> 00:37:20.040]   I just want to upgrade that, can I do it?
[00:37:20.040 --> 00:37:22.480]   So we're using a Conda approach to package management
[00:37:22.480 --> 00:37:24.200]   for the R ecosystem as well.
[00:37:24.200 --> 00:37:25.920]   And that's what's happening in conjunction
[00:37:25.920 --> 00:37:27.060]   with the Conda Forge folks.
[00:37:27.060 --> 00:37:27.900]   That's what I'm building out.
[00:37:27.900 --> 00:37:30.320]   Now we have coverage of several thousand libraries
[00:37:30.320 --> 00:37:31.680]   in the R universe too.
[00:37:31.680 --> 00:37:32.520]   - Wow, awesome.
[00:37:32.520 --> 00:37:36.800]   Interesting.
[00:37:36.800 --> 00:37:38.720]   Okay, here's the question I really want to ask you.
[00:37:38.720 --> 00:37:40.920]   I'm just going to ask you this question.
[00:37:40.920 --> 00:37:41.760]   This might be dumb,
[00:37:41.880 --> 00:37:44.400]   I guess the one thing that I really felt
[00:37:44.400 --> 00:37:46.440]   when I switched from R to Python
[00:37:46.440 --> 00:37:48.440]   is like, man, the graphing libraries are worse.
[00:37:48.440 --> 00:37:50.800]   And I hope I don't offend anyone with that comment.
[00:37:50.800 --> 00:37:52.400]   And I feel like I've never,
[00:37:52.400 --> 00:37:55.480]   I feel like NumPy has improved so much
[00:37:55.480 --> 00:37:58.600]   and SciPy seems to have so many libraries
[00:37:58.600 --> 00:38:00.080]   that anything that I would want
[00:38:00.080 --> 00:38:03.120]   is not a super deep scientist.
[00:38:03.120 --> 00:38:06.720]   I feel like it used to feel like R
[00:38:06.720 --> 00:38:08.720]   had way more packages to cover my needs.
[00:38:08.720 --> 00:38:10.220]   And it feels like Python's kind of catching up there.
[00:38:10.220 --> 00:38:14.200]   But it sort of feels to me like the graphing libraries
[00:38:14.200 --> 00:38:15.440]   are still kind of frustrating.
[00:38:15.440 --> 00:38:17.280]   Is that because I'm misusing them?
[00:38:17.280 --> 00:38:20.200]   Or is there a library out there that I should know about?
[00:38:20.200 --> 00:38:23.560]   - No, yeah, no, the graphing libraries in Python are awesome
[00:38:23.560 --> 00:38:24.960]   and it's clearly the user's fault.
[00:38:24.960 --> 00:38:26.800]   So I don't know what you're talking about.
[00:38:26.800 --> 00:38:29.200]   - This is one user that I'm using.
[00:38:29.200 --> 00:38:30.400]   - No, no, no.
[00:38:30.400 --> 00:38:31.400]   It's a common complaint.
[00:38:31.400 --> 00:38:34.160]   I think what happens in Python there
[00:38:34.160 --> 00:38:37.720]   is that if one were to take a sort of
[00:38:37.720 --> 00:38:39.160]   a more objective look at all these,
[00:38:39.160 --> 00:38:42.140]   there's the author of like two or three different,
[00:38:42.140 --> 00:38:43.980]   not the only author, but the originator, let's say,
[00:38:43.980 --> 00:38:47.540]   of two or three of the graphing libraries in Python.
[00:38:47.540 --> 00:38:49.980]   And now there's like, there's several dozen, right?
[00:38:49.980 --> 00:38:51.520]   There have been.
[00:38:51.520 --> 00:38:55.940]   What we have here is a couple of different things going on.
[00:38:55.940 --> 00:38:59.440]   So R does what R does very well,
[00:38:59.440 --> 00:39:01.900]   precisely because it was designed by a user community
[00:39:01.900 --> 00:39:03.340]   for that community.
[00:39:03.340 --> 00:39:07.560]   So, and also because of its sort of Lispy heritage,
[00:39:07.560 --> 00:39:09.540]   it is able to do some really neat tricks
[00:39:09.540 --> 00:39:11.740]   by preserving kind of the transformation pipeline
[00:39:11.740 --> 00:39:13.580]   and kind of quoting the expressions and things like that,
[00:39:13.580 --> 00:39:15.380]   that give you some really awesome superpowers
[00:39:15.380 --> 00:39:16.300]   when you're building,
[00:39:16.300 --> 00:39:18.780]   like just give me a facet of like these things.
[00:39:18.780 --> 00:39:20.580]   And it's like, it just does the right thing, right?
[00:39:20.580 --> 00:39:21.420]   Obviously.
[00:39:21.420 --> 00:39:23.700]   I mean, also Hadley did great work with ggplot2.
[00:39:23.700 --> 00:39:24.740]   Like there's nothing,
[00:39:24.740 --> 00:39:26.440]   not to say there wasn't hard work involved there,
[00:39:26.440 --> 00:39:30.520]   but then if you want to go and do some additional,
[00:39:30.520 --> 00:39:32.740]   if you want to do plots outside of some of the things
[00:39:32.740 --> 00:39:35.460]   that ggplot is great for,
[00:39:35.460 --> 00:39:39.040]   then it's a more impoverished landscape, let's say, right?
[00:39:39.040 --> 00:39:42.440]   If you want to do real-time spectrograms there in R,
[00:39:42.440 --> 00:39:43.280]   I don't know, man.
[00:39:43.280 --> 00:39:44.400]   Like that's, you know,
[00:39:44.400 --> 00:39:46.080]   or if you want to do like really large scale
[00:39:46.080 --> 00:39:47.800]   and active web graphics with like all this,
[00:39:47.800 --> 00:39:50.280]   like crazy map data, I don't know.
[00:39:50.280 --> 00:39:54.280]   Let's like, so the Python world has always been more multi,
[00:39:54.280 --> 00:39:55.920]   it's just been,
[00:39:55.920 --> 00:39:58.240]   there's a lot more Mongols across a bigger plane.
[00:39:58.240 --> 00:39:59.640]   And so there's just many different flavors,
[00:39:59.640 --> 00:40:00.540]   different things all over the place.
[00:40:00.540 --> 00:40:03.520]   And that plot lib was written by a guy in grad school
[00:40:03.520 --> 00:40:05.340]   trying to plot EEG plots, right?
[00:40:05.340 --> 00:40:07.860]   And then he moved on to Hedge Fund,
[00:40:07.860 --> 00:40:09.540]   but then he was trying to copy what he knew,
[00:40:09.540 --> 00:40:10.740]   which was MATLAB.
[00:40:10.740 --> 00:40:12.860]   And it does great for that, actually,
[00:40:12.860 --> 00:40:14.880]   if you're an engineering MATLAB user,
[00:40:14.880 --> 00:40:16.220]   that plot lib works great.
[00:40:16.220 --> 00:40:18.220]   Like you just fit your brain, right?
[00:40:18.220 --> 00:40:20.900]   But most, most like, you know,
[00:40:20.900 --> 00:40:23.460]   ML people were not MATLAB people, right?
[00:40:23.460 --> 00:40:27.940]   And then likewise, if you use tools like Seaborn,
[00:40:27.940 --> 00:40:29.620]   you know, they get you kind of some of the way there,
[00:40:29.620 --> 00:40:32.700]   but then they don't have the support from the language level
[00:40:32.700 --> 00:40:35.160]   to encapsulate some of the statistical transformations
[00:40:35.160 --> 00:40:37.060]   that would help inform something even better.
[00:40:37.060 --> 00:40:38.400]   So it has to sort of include
[00:40:38.400 --> 00:40:41.000]   some of those transformations within it, right?
[00:40:41.000 --> 00:40:42.600]   Facets, names, things like that.
[00:40:42.600 --> 00:40:43.600]   So then you go around
[00:40:43.600 --> 00:40:45.600]   and you look at some of the interactive plotting systems,
[00:40:45.600 --> 00:40:47.440]   whether it's Altair, whether it's like Bokeh
[00:40:47.440 --> 00:40:49.380]   or any of these other things, plotly,
[00:40:49.380 --> 00:40:51.820]   then they all are solving
[00:40:51.820 --> 00:40:53.980]   for kinds of different parts of the problem.
[00:40:53.980 --> 00:40:57.980]   And to do as much of a cover of the Python use cases
[00:41:00.160 --> 00:41:05.160]   is just bigger than any kind of project was able to do.
[00:41:05.160 --> 00:41:08.920]   I think there's more compact set of use cases in R.
[00:41:08.920 --> 00:41:11.520]   And so therefore it was possible to do a more,
[00:41:11.520 --> 00:41:14.240]   a higher level of cover in a single project.
[00:41:14.240 --> 00:41:15.240]   Does that make sense?
[00:41:15.240 --> 00:41:16.080]   - Totally, yeah.
[00:41:16.080 --> 00:41:17.080]   That's really well said.
[00:41:17.080 --> 00:41:21.120]   - And very, not judgmental, I love your...
[00:41:21.120 --> 00:41:23.160]   (laughing)
[00:41:23.160 --> 00:41:24.480]   - We're all about Big Ten, Anaconda,
[00:41:24.480 --> 00:41:25.680]   it's all about the Big Ten, right?
[00:41:25.680 --> 00:41:27.480]   - Big Ten, yeah, totally.
[00:41:27.480 --> 00:41:28.440]   You do packages.
[00:41:28.760 --> 00:41:30.520]   - No, not played favorites.
[00:41:30.520 --> 00:41:31.520]   - Not played favorites.
[00:41:31.520 --> 00:41:33.040]   (laughing)
[00:41:33.040 --> 00:41:35.760]   - So okay, we always end with two questions
[00:41:35.760 --> 00:41:36.760]   that I want to make sure I get them in
[00:41:36.760 --> 00:41:38.320]   'cause I'm curious to hear your thoughts.
[00:41:38.320 --> 00:41:42.560]   So one question that we always ask people,
[00:41:42.560 --> 00:41:44.360]   and maybe I should ask this in a more expansive way,
[00:41:44.360 --> 00:41:45.320]   but we always ask people is,
[00:41:45.320 --> 00:41:49.240]   is there a topic in ML that doesn't get as much attention
[00:41:49.240 --> 00:41:50.480]   as you think it should,
[00:41:50.480 --> 00:41:53.280]   that people should focus on more than they do?
[00:41:53.280 --> 00:41:54.480]   And I might expand that for you
[00:41:54.480 --> 00:41:56.520]   into like all of scientific computing.
[00:41:56.520 --> 00:41:58.240]   Like what's the things that people aren't,
[00:41:58.240 --> 00:42:00.440]   or what's one thing that you think people don't pay
[00:42:00.440 --> 00:42:04.960]   as much attention to as this usefulness would suggest?
[00:42:04.960 --> 00:42:09.760]   - I think the top, well, a topic, there's lots of topics.
[00:42:09.760 --> 00:42:12.800]   My general thing stems in,
[00:42:12.800 --> 00:42:20.160]   it comes from this place where I feel very strongly
[00:42:20.160 --> 00:42:23.640]   that ML practitioners,
[00:42:23.640 --> 00:42:26.560]   more so than just software like coder nerds,
[00:42:26.560 --> 00:42:31.560]   are going to run into the ethical implications of their work
[00:42:31.560 --> 00:42:35.920]   and even more uncomfortably,
[00:42:35.920 --> 00:42:39.560]   they're going to be the ones forcing that conversation
[00:42:39.560 --> 00:42:41.120]   in businesses that for a long time
[00:42:41.120 --> 00:42:43.640]   maybe have not had to think about that
[00:42:43.640 --> 00:42:46.200]   because ML is about engineering the crown jewels
[00:42:46.200 --> 00:42:47.800]   of the business models.
[00:42:47.800 --> 00:42:50.360]   So you're like, hey, we just figured out this way.
[00:42:50.360 --> 00:42:52.600]   If we buy these two datasets and do this kind of model
[00:42:52.600 --> 00:42:55.320]   and reject these kinds of people from our user base,
[00:42:55.320 --> 00:42:56.640]   we get this kind of lift.
[00:42:56.640 --> 00:42:58.280]   Should we do it?
[00:42:58.280 --> 00:43:01.040]   Well, it's like, heck, I mean, I never,
[00:43:01.040 --> 00:43:02.520]   I'm just a VP of God knows what.
[00:43:02.520 --> 00:43:03.520]   I didn't ask to be presented
[00:43:03.520 --> 00:43:05.360]   this incredibly difficult trolley problem.
[00:43:05.360 --> 00:43:06.760]   Like, don't look at me, right?
[00:43:06.760 --> 00:43:09.280]   I slept through that crap in college.
[00:43:09.280 --> 00:43:13.680]   So I think that ML, more than any other thing right now,
[00:43:13.680 --> 00:43:16.960]   we have to be faced with this concept
[00:43:16.960 --> 00:43:19.040]   that technology is not value neutral.
[00:43:19.040 --> 00:43:21.320]   And if you think about what machine learning really is,
[00:43:21.320 --> 00:43:24.000]   it is the application of massive amounts of compute,
[00:43:24.000 --> 00:43:25.520]   rent a supercomputer in the cloud,
[00:43:25.520 --> 00:43:27.080]   kind of massive amounts of compute
[00:43:27.080 --> 00:43:28.520]   to massive amounts of data
[00:43:28.520 --> 00:43:30.920]   that's even deeper and creepier than ever before
[00:43:30.920 --> 00:43:32.360]   'cause they have sensors everywhere,
[00:43:32.360 --> 00:43:35.440]   to achieve business ends and to optimize business outcomes.
[00:43:35.440 --> 00:43:38.440]   And we know just how good businesses are at capturing
[00:43:38.440 --> 00:43:40.600]   and self-regulating about externalities
[00:43:40.600 --> 00:43:41.800]   to their business outcomes.
[00:43:41.800 --> 00:43:44.440]   So just as a human looking at this, I would say,
[00:43:44.440 --> 00:43:45.960]   wow, I've got a chance to actually speak
[00:43:45.960 --> 00:43:47.960]   to this practitioner crowd about,
[00:43:47.960 --> 00:43:49.240]   if you're doing your job well,
[00:43:49.240 --> 00:43:51.960]   you'll be forced to drive a lot of conversations
[00:43:51.960 --> 00:43:55.040]   about ethics and the practice of your thing,
[00:43:55.040 --> 00:43:57.680]   about what you're doing within your business
[00:43:57.680 --> 00:44:00.320]   as it goes through this data transformation.
[00:44:00.320 --> 00:44:01.960]   And you should be ready for that.
[00:44:01.960 --> 00:44:03.360]   Steal yourself for that.
[00:44:03.360 --> 00:44:04.520]   Don't punt.
[00:44:04.520 --> 00:44:06.400]   Don't punt on it.
[00:44:06.400 --> 00:44:07.920]   We can't afford to punt.
[00:44:07.920 --> 00:44:10.320]   - Besides stealing yourself for that,
[00:44:10.320 --> 00:44:13.640]   which is probably a good verb for that,
[00:44:13.640 --> 00:44:14.920]   (both laughing)
[00:44:14.920 --> 00:44:16.440]   do you have any suggestions
[00:44:16.440 --> 00:44:18.720]   on how someone might educate themselves on that?
[00:44:18.720 --> 00:44:20.920]   'Cause I think we have a lot of people listening to this
[00:44:20.920 --> 00:44:23.440]   that's in that situation that might be wondering,
[00:44:23.440 --> 00:44:25.640]   where could I find more resources?
[00:44:25.640 --> 00:44:26.880]   Do you have any suggestions?
[00:44:26.880 --> 00:44:30.800]   - Yes, so I think there's books that have been written now,
[00:44:30.800 --> 00:44:34.120]   especially in the era of the Facebook
[00:44:34.120 --> 00:44:37.480]   and information attention economy sort of dystopia stuff.
[00:44:37.480 --> 00:44:41.120]   There's books by Shoshana Zuboff,
[00:44:41.120 --> 00:44:43.960]   Cathy O'Neill, "Weapons of Mass Destruction."
[00:44:43.960 --> 00:44:45.760]   There are books, even like, I think,
[00:44:45.760 --> 00:44:47.160]   Christian Rutter, "Dataclism," right?
[00:44:47.160 --> 00:44:48.360]   And some of these other things.
[00:44:48.360 --> 00:44:52.680]   You can look at, arm yourself with knowledge
[00:44:52.680 --> 00:44:54.320]   about the anti-patterns of what happens
[00:44:54.320 --> 00:44:56.600]   when ML, blindly applied, goes wrong.
[00:44:56.600 --> 00:44:58.720]   And that at least gives you a bit of a war chest
[00:44:58.720 --> 00:45:01.000]   of like, or a quiver of things you can reach for
[00:45:01.000 --> 00:45:03.120]   to say, what we're doing here is exactly like what happened
[00:45:03.120 --> 00:45:04.960]   when, I just pull one out of the hat,
[00:45:04.960 --> 00:45:08.200]   like when AOL anonymized their user data,
[00:45:08.200 --> 00:45:10.320]   or it was AOL or AT&T, anonymized their user data
[00:45:10.320 --> 00:45:11.520]   back in the early 2000s.
[00:45:11.520 --> 00:45:13.120]   And they did this anonymous data release
[00:45:13.120 --> 00:45:14.960]   and this thing happened and somebody got outed.
[00:45:14.960 --> 00:45:17.240]   Like, there's all sorts of wonderful examples
[00:45:17.240 --> 00:45:19.160]   you can pull from 'cause we've actually been making
[00:45:19.160 --> 00:45:20.600]   a lot of mistakes.
[00:45:20.600 --> 00:45:22.480]   So one thing is take your time,
[00:45:22.480 --> 00:45:23.520]   take the time to read about that stuff.
[00:45:23.520 --> 00:45:27.400]   Number two is go to and attend talks
[00:45:27.400 --> 00:45:29.080]   about sort of this, quote unquote,
[00:45:29.080 --> 00:45:33.600]   this soft topic about ethics in ML and fairness
[00:45:33.600 --> 00:45:35.120]   and whatnot.
[00:45:35.120 --> 00:45:37.200]   I know some of it may seem a bit sermon-y and preach-y.
[00:45:37.200 --> 00:45:40.120]   It's like, hey, I came here for like the hardcore CovNets.
[00:45:40.120 --> 00:45:41.800]   I didn't come here to go listen to somebody
[00:45:41.800 --> 00:45:43.520]   drone on about ethics.
[00:45:43.520 --> 00:45:46.000]   But in every conference you go to
[00:45:46.000 --> 00:45:47.520]   and everything you go and do,
[00:45:47.520 --> 00:45:49.480]   spend some time getting educated
[00:45:49.480 --> 00:45:50.440]   about the state-of-the-art thinking.
[00:45:50.440 --> 00:45:51.920]   'Cause right now, we are, you know,
[00:45:51.920 --> 00:45:53.640]   people are trying to think about preserving privacy,
[00:45:53.640 --> 00:45:55.480]   privacy, preserving encryption,
[00:45:55.480 --> 00:45:58.920]   and some of these things, differential privacy.
[00:45:58.920 --> 00:45:59.960]   Those things are coming.
[00:45:59.960 --> 00:46:00.880]   Those are gonna be part of like
[00:46:00.880 --> 00:46:02.720]   the state-of-the-art best practice soon.
[00:46:02.720 --> 00:46:03.960]   You should be educated about those things.
[00:46:03.960 --> 00:46:05.800]   And not only just do it 'cause you have to,
[00:46:05.800 --> 00:46:07.720]   but know why, because I guarantee you,
[00:46:07.720 --> 00:46:09.520]   when you go and scope those into your project,
[00:46:09.520 --> 00:46:10.720]   some VP is gonna come and say,
[00:46:10.720 --> 00:46:12.720]   well, can't you just get rid of that and do it faster?
[00:46:12.720 --> 00:46:14.240]   And you have to be able to argue the principles
[00:46:14.240 --> 00:46:16.280]   of why you need to do it this way, right?
[00:46:16.280 --> 00:46:18.840]   So that would be the one thing I would say is,
[00:46:18.840 --> 00:46:20.640]   I don't know if it gets maybe already too much press,
[00:46:20.640 --> 00:46:22.480]   but it probably doesn't get enough press,
[00:46:22.480 --> 00:46:24.320]   is that the ML practitioners,
[00:46:24.320 --> 00:46:27.760]   if they're not going to be just serfs in this,
[00:46:27.760 --> 00:46:30.040]   if they actually want to have agency in that conversation
[00:46:30.040 --> 00:46:32.640]   to hold their own ground in what we should do
[00:46:32.640 --> 00:46:35.240]   and not have a pile of regret down the road,
[00:46:35.240 --> 00:46:37.600]   then now is the time to start getting educated
[00:46:37.600 --> 00:46:39.160]   and start asserting yourselves more
[00:46:39.160 --> 00:46:41.640]   in those internal corporate political discussions.
[00:46:43.320 --> 00:46:44.360]   - Awesome, well said.
[00:46:44.360 --> 00:46:47.640]   Ooh, I was taking a deep breath.
[00:46:47.640 --> 00:46:49.440]   Final question.
[00:46:49.440 --> 00:46:50.640]   - All right, final question.
[00:46:50.640 --> 00:46:52.280]   - When you look at companies trying
[00:46:52.280 --> 00:46:54.920]   to get stuff into production,
[00:46:54.920 --> 00:46:58.480]   what are the surprising bottlenecks that they run into?
[00:46:58.480 --> 00:47:00.960]   Like when somebody's trying to take an ML project
[00:47:00.960 --> 00:47:03.760]   from kind of an idea to deploy it
[00:47:03.760 --> 00:47:06.520]   and it's working and doing something useful,
[00:47:06.520 --> 00:47:08.920]   where do you see people get stuck?
[00:47:10.080 --> 00:47:14.040]   - Oh, well, every part of the process can be troublesome.
[00:47:14.040 --> 00:47:16.080]   I don't know if there's a surprise there at all.
[00:47:16.080 --> 00:47:18.320]   I guess one, yeah, one thing that's surprising to me
[00:47:18.320 --> 00:47:22.160]   is how many corporate IT places
[00:47:22.160 --> 00:47:27.160]   are still pretty backwards relative to open source.
[00:47:27.160 --> 00:47:29.840]   This was surprising to me in 2014,
[00:47:29.840 --> 00:47:31.320]   it's still surprising now,
[00:47:31.320 --> 00:47:32.400]   how many places will say,
[00:47:32.400 --> 00:47:35.720]   well, we don't really do open source
[00:47:35.720 --> 00:47:37.240]   or here's the open source that we do,
[00:47:37.240 --> 00:47:38.680]   it's just these few things.
[00:47:38.680 --> 00:47:40.240]   And then when they say that, they trot out
[00:47:40.240 --> 00:47:42.480]   all the tired FUD arguments about
[00:47:42.480 --> 00:47:44.560]   how can we trust this thing, how can we trust that?
[00:47:44.560 --> 00:47:46.720]   The other thing is that there is still
[00:47:46.720 --> 00:47:48.200]   a very strong Python allergy
[00:47:48.200 --> 00:47:50.520]   and a lot of lack of awareness
[00:47:50.520 --> 00:47:52.720]   of what Python actually is and can do.
[00:47:52.720 --> 00:47:54.280]   And so there are some companies that are like,
[00:47:54.280 --> 00:47:56.120]   well, this is a Java shop or this is .NET shop,
[00:47:56.120 --> 00:47:59.000]   we really only know how to deploy these ways.
[00:47:59.000 --> 00:48:00.360]   You know, we don't deploy Python,
[00:48:00.360 --> 00:48:02.160]   you have to recode that 'cause it's just a language,
[00:48:02.160 --> 00:48:03.360]   you can recode in this other thing, right?
[00:48:03.360 --> 00:48:05.400]   Why wouldn't you be able to?
[00:48:05.400 --> 00:48:07.480]   And these IT shops, they don't understand
[00:48:07.480 --> 00:48:10.040]   that when you use Python, you're harnessing,
[00:48:10.040 --> 00:48:11.640]   like you're linking into like
[00:48:11.640 --> 00:48:13.920]   seriously optimized low-level code
[00:48:13.920 --> 00:48:16.200]   that a lot of seriously smart people have been doing
[00:48:16.200 --> 00:48:18.360]   and there's not the equivalent over in the Java space.
[00:48:18.360 --> 00:48:19.880]   And all the data marshaling back and forth
[00:48:19.880 --> 00:48:21.640]   is gonna cost you a tremendous amount of performance
[00:48:21.640 --> 00:48:22.840]   in the Java space, right?
[00:48:22.840 --> 00:48:25.680]   And these IT shops have not yet understood that.
[00:48:25.680 --> 00:48:27.720]   And sadly, a lot of the ML engineers,
[00:48:27.720 --> 00:48:29.400]   they are relatively new and they don't know
[00:48:29.400 --> 00:48:30.520]   how to articulate that argument.
[00:48:30.520 --> 00:48:32.000]   They don't know how to sit there and talk about
[00:48:32.000 --> 00:48:33.960]   JVM internals and all these other bits
[00:48:33.960 --> 00:48:35.960]   'cause that's not their gig, right?
[00:48:35.960 --> 00:48:38.600]   So I think that's been sort of the depressing,
[00:48:38.600 --> 00:48:40.440]   it's surprising that it's still this issue
[00:48:40.440 --> 00:48:43.520]   because we do have companies that deploy Python
[00:48:43.520 --> 00:48:45.160]   in frontline production stuff
[00:48:45.160 --> 00:48:47.760]   to do some of these ML things and they're fine.
[00:48:47.760 --> 00:48:49.400]   And even with that as proof points,
[00:48:49.400 --> 00:48:53.720]   there's still kind of these industry inertia, yeah.
[00:48:53.720 --> 00:48:55.160]   - I mean, what would you even use for it?
[00:48:55.160 --> 00:48:58.200]   Like a non-open source machine learning framework?
[00:48:58.200 --> 00:49:01.320]   This shows you how sort of maybe Silicon Valley Kool-Aid
[00:49:01.320 --> 00:49:02.880]   I would pick on, but.
[00:49:02.880 --> 00:49:05.440]   - No, I think what ends up happening,
[00:49:05.440 --> 00:49:08.160]   to be honest, they'll buy some vendor thing
[00:49:08.160 --> 00:49:09.880]   which still just embeds the machine learning,
[00:49:09.880 --> 00:49:11.360]   the same open source machine learning thing.
[00:49:11.360 --> 00:49:14.120]   No, I kid you not, like that's literally
[00:49:14.120 --> 00:49:15.840]   what they will do sometimes.
[00:49:15.840 --> 00:49:18.080]   It is, if you get into corporate IT enough,
[00:49:18.080 --> 00:49:20.200]   like it gets pretty depressing about the kinds of like,
[00:49:20.200 --> 00:49:22.640]   the incentives are all messed up there, unfortunately.
[00:49:22.640 --> 00:49:24.000]   Which is one of the reasons why Silicon Valley
[00:49:24.000 --> 00:49:26.600]   does run circles around some of these other companies.
[00:49:26.600 --> 00:49:28.440]   Yeah.
[00:49:28.440 --> 00:49:29.840]   - Man, we should have ended on your ethics answer.
[00:49:29.840 --> 00:49:31.160]   This is just depressing.
[00:49:31.160 --> 00:49:32.160]   (laughing)
[00:49:32.160 --> 00:49:35.400]   I guess both are kind of worrying in different ways.
[00:49:35.400 --> 00:49:36.800]   - We have our work cut out for us.
[00:49:36.800 --> 00:49:39.240]   We have our work cut out for us, that's for sure.
[00:49:39.240 --> 00:49:41.360]   - Nice, that's a good way of putting it.
[00:49:41.360 --> 00:49:43.360]   Thanks so much, that was really fun.
[00:49:43.360 --> 00:49:44.520]   - Yeah, no, thank you.
[00:49:44.520 --> 00:49:47.240]   - When we first started making these videos,
[00:49:47.240 --> 00:49:49.240]   we didn't know if anyone would be interested
[00:49:49.240 --> 00:49:51.960]   or wanna see them, but we made them for fun.
[00:49:51.960 --> 00:49:55.080]   And we started off by making videos that would teach people.
[00:49:55.080 --> 00:49:56.760]   And now we get these great interviews
[00:49:56.760 --> 00:49:58.840]   with real industry practitioners.
[00:49:58.840 --> 00:50:01.680]   And I love making this available to the whole world,
[00:50:01.680 --> 00:50:03.760]   so everyone can watch these things for free.
[00:50:03.760 --> 00:50:04.920]   The more feedback you give us,
[00:50:04.920 --> 00:50:06.160]   the better stuff we can produce.
[00:50:06.160 --> 00:50:09.080]   So please subscribe, leave a comment, engage with us.
[00:50:09.080 --> 00:50:10.280]   We really appreciate it.

