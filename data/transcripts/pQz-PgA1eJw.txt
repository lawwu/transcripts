
[00:00:00.000 --> 00:00:19.040]   I'm Sid, I'm one of the co-founders of Aleve, and this is The New Lean Startup.
[00:00:19.040 --> 00:00:25.760]   We've been seeing a fundamental shift in how successful companies are being built. More and
[00:00:25.760 --> 00:00:29.760]   more companies are getting smaller, rounds are getting delayed, and profitability is being
[00:00:29.760 --> 00:00:34.260]   attained earlier than ever in their lifetime. A lot of this is being driven mainly by the
[00:00:34.260 --> 00:00:40.440]   advent of AI tooling. These companies are generating millions of ARR with teams smaller than most
[00:00:40.440 --> 00:00:45.500]   startups engineering departments. The age of bloated teams and endless hiring rounds is
[00:00:45.500 --> 00:00:53.040]   over. Welcome to the era of tiny teams. First, a bit of background on Aleve. We're
[00:00:53.040 --> 00:00:58.080]   building a family of iconic consumer software products that we hope will enable people to
[00:00:58.080 --> 00:01:03.580]   live better, more fulfilling, and productive lives. We are a tiny team that scaled a portfolio
[00:01:03.580 --> 00:01:07.960]   of virally successful products to $6 million in ARR profitably, and have generated over half
[00:01:07.960 --> 00:01:12.320]   a billion views across social media, achieving this with a tiny team of just four. We're based
[00:01:12.320 --> 00:01:16.580]   out of New York City, and here's a brief history on us.
[00:01:16.580 --> 00:01:22.080]   On the 26th of January in 2023, we launched the Quizzert AI mobile app. We launched it with a TikTok video that went viral overnight and generated a million views that turned into 10,000 users in less than 30 hours. We actually started scaling with no LLM costs. This is because back then we had the initial Codex model launch, which was in beta preview. Funny enough, we were cycling between 10 different accounts from our friends just so that we could prompt engineer or generate these AI outputs. Interestingly enough, Codex
[00:01:22.080 --> 00:01:27.580]   Codex, even though it was meant for as a coding model, could be prompt engineered for any open domain conversation.
[00:01:27.580 --> 00:01:57.560]   Codex. As you all may know, it ended up being sunset for abuse. We ended up getting a lot. We ended up getting a lot of users in less than 30 hours. We actually started scaling with no LLM costs. This is because back then we had the initial Codex model launch, which was in beta preview. Funny enough, we were cycling between 10 different accounts from our friends, just so that we could prompt engineer or generate these AI outputs. Interestingly enough, Codex, even though it was meant for as a coding model, could be prompt engineered for any open domain conversation. As you all may know, it ended up being sunset for abuse. We ended up getting a lot. We ended up getting a lot of users.
[00:01:57.560 --> 00:02:27.540]   getting reached out directly by open AI on a few of our different accounts that we were cycling through as being one of the top model users for the Codex model at the time. My co-founders and I then graduated. And then we moved to New York City, the fall of 2023, where we started our back to school campaign, which was a series of man on the street videos across different prestigious colleges in the US. This is when we fit our first million dollars in ARR and also achieve profitability within the first nine months of operating.
[00:02:27.540 --> 00:02:39.540]   We then even had another successful campaign in the spring of 2024 that got us all the way to number six in the charts of education alongside giants like Duolingo, Photomath, and Goth.
[00:02:39.540 --> 00:02:57.520]   We then took all our learnings in the spring of 2024 and doubled down on a new product on Stuck AI, a study companion tool for students. We were able to get to a million users in under nine weeks and generate over a quarter billion views across socials in a month. A few weeks ago, we were able to get to a million users in under nine weeks and generate over a quarter billion views across socials in a month. A few weeks ago, we were able to get to a million users in under nine weeks and generate over a quarter billion views across socials in a month. A few weeks ago, we were able to get to a million users in under nine weeks and generate over a quarter billion views across socials in a month.
[00:02:57.520 --> 00:03:04.520]   We were able to get both products in the top 10 in the education charts. Unstuck went all the way up to number three in the education charts right under Goth and Duolingo.
[00:03:04.520 --> 00:03:21.520]   We've now also launched in stealth our third product, which is our first product outside the education domain. It took three weeks to build thanks to all the blueprints that we've built in advance. We'll speak more on this later. And have already reached 1000 plus users. By the way, it's already profitable.
[00:03:21.520 --> 00:03:30.520]   Our lean playbook boils down to three key pillars, operating principles that lay the foundation of leanness,
[00:03:30.520 --> 00:03:37.520]   organizational structure that set up the systems for this leanness, and AI tooling augmentation which optimizes scaling.
[00:03:37.520 --> 00:03:42.520]   Let me start with operating principles, which I believe is the main bedrock for why we're so lean.
[00:03:42.520 --> 00:03:53.520]   It starts with hiring. We either hire right or not at all. We only hire 10Xer generalists that have multiple complementary spikes in similar fields.
[00:03:53.520 --> 00:04:00.520]   So for example, our product engineers are full stack developers, great product thinkers, and really good at fundamentals of computer network, for example.
[00:04:00.520 --> 00:04:11.520]   We also have marketers who can code, we have designers who can build, and the likes. We try to aim for people whose complementary spikes can shape and drive 10X outputs within the team.
[00:04:11.520 --> 00:04:19.520]   The second key principle is profit first mentality. We are relentless about prioritizing profits, because profit is power and profit is focus.
[00:04:19.520 --> 00:04:29.520]   Profit gives us a clear mechanism to make all our decisions and guide a north star for the company. This leads to our third principle. Does this move your KPI?
[00:04:29.520 --> 00:04:39.520]   Everyone in the company owns a KPI. KPI alignment removes micromanagement bullshit, because everyone is focused on moving their metric week over week.
[00:04:39.520 --> 00:04:44.520]   This also means decisions must be validated against this KPI.
[00:04:44.520 --> 00:04:57.520]   Our fourth principle is continuous process refinement. For any repeating process, we always ask, "How would we do this better? Is there any way we can improve? What was wrong about this previous run?"
[00:04:57.520 --> 00:05:10.520]   We view failures in the company and issues in the company as systems failures, which lets us set up a feedback loop for improving ourselves, improving the process that we use, both on an operational standpoint, but also a technical standpoint.
[00:05:10.520 --> 00:05:25.520]   The fifth pillar is super tools. We're pretty lazy. So we like to consolidate a lot of our workflows onto one platform if we can. And that ends up meaning that we have to reinvent the ways we use old tools. More on this in a bit.
[00:05:25.520 --> 00:05:40.520]   The last principle I'd emphasize is don't learn it twice. We believe in building compounding benefits by investing in technical playbooks and operational blueprints. This allows us to compound our learnings so that the benefits can be used across new products.
[00:05:40.520 --> 00:05:47.520]   This is exactly how we were able to hit a million users within nine weeks, taking everything we learned over a year and a half on Quizzard.
[00:05:47.520 --> 00:05:59.520]   More on the super tools concept. For example, one of our super tools is LaunchDarkly. The intended use case of LaunchDarkly is a feature management platform that helps software teams control and release features safely and quickly.
[00:05:59.520 --> 00:06:14.520]   Here are some of our extended use cases. We use LaunchDarkly as a manual traffic load balancer. Specifically, we put LaunchDarkly in between all our LLM calls so that we can reroute traffic to different LLM providers based on hitting rate limits, different strategic initiatives, or whatever.
[00:06:14.520 --> 00:06:33.520]   It just gives us an on-the-fly mechanism for choosing where our traffic goes, and allows us to split things within rate limits. This was especially important in the early days when rate limits were really tight, and also it was hard to get quotas increased on individual endpoints. Specifically, I'm talking about Azure OpenAI.
[00:06:33.520 --> 00:06:49.520]   I'm talking about Azure OpenAI. The second extended use case is on-the-fly infrastructure changes. For us, this looks like how on Unstuck, which takes in a lot of files to ingest, for specific file formats, we have a lot of waterfall ingestion processes.
[00:06:49.520 --> 00:07:02.520]   What I mean by that is, we depend on a lot of third-party services that can be reliable. By using LaunchDarkly, we're able to change the prioritization of these processes on the fly, so that if one of these third-party services goes down, we're able to reorganize the service on the fly.
[00:07:02.520 --> 00:07:07.520]   to make sure it's up and running and available to our users worldwide.
[00:07:07.520 --> 00:07:23.520]   The third extended use case is UI modifications and paywall experiments without having code pushes. We have built an experimentation layer around LaunchDarkly, which allows us to run and spin up experiments without needing to make a code push.
[00:07:23.520 --> 00:07:34.520]   The second pillar that guides our leanness is our organizational structure, especially in our engineering org, in the way we hire and that we organize our engineers.
[00:07:34.520 --> 00:07:44.520]   For this, we look to Palantir, who has successfully scaled across multiple market segments. We believe that we're building the consumer version of Palantir with our harvester and cultivator model. Let me explain this.
[00:07:44.520 --> 00:08:02.520]   For harvesters, these are product engineers similar to the Palantir deltas of the four deployed software engineers that own and live and die by their products. They're living in the metrics, working on A/B experiments, building features end-to-end, working with the marketing team, and effectively owning the entire product's existence.
[00:08:02.520 --> 00:08:08.520]   Harvesters are people who build products that people actually want and pay for.
[00:08:08.520 --> 00:08:25.520]   Then we have the cultivators. Cultivators are AI software engineers whose main goal is building the company's agentic operating system. They're pioneering automation across different business units, including marketing, design, product, with the idea of expanding infrastructure that affects all the users everywhere and helps us win in every market.
[00:08:25.520 --> 00:08:54.520]   And finally, the last pillar is AI-driven and AI and tool augmentation. One important note in thinking about this is, when we think about hiring, we like to think of tool use as being something that will allow a 10Xer become a 100Xer, as opposed to the contrast, which is using tools to fill gaps and augment the shortcomings of someone who's not at the standpoint.
[00:08:54.520 --> 00:09:15.520]   With that being said, we use a slew of products for our day-to-day task automation, for things like script writing, campaign analysis, operations, code generation, and communications. Effectively, by paying for a bunch of services, we have augmented and enabled everyone to have their own chief of staff within the company.
[00:09:15.520 --> 00:09:43.520]   Now, back to the blueprints. Now, back to the blueprints. One more thing is, we believe heavily in compounding benefits and reinvesting in blueprints. This includes things like code complete templates, which build in all the learnings that we've learned over two and a half years of scaling products with virality in mind, reusable internal libraries and modules that govern our core services that we use, like our LLM providers, and shared infrastructure that we reuse across applications, such as our notification system or the experimentation layer that I talked about earlier.
[00:09:43.520 --> 00:09:50.520]   Being in consumer, experimentation is kind of the backbone of everything we do, and that's why it is always built out as a first layer to every new product that we launch.
[00:09:50.520 --> 00:10:04.520]   But while blueprints give us a deterministic leverage and compounding effects, what happens when these blueprints can be executed on demand by systems that can learn and adapt and coordinate faster than real teams?
[00:10:04.520 --> 00:10:12.520]   At Olive, we're thinking about taking this further and how AI can augment the future of our work. And this is devised into three specific stages.
[00:10:12.520 --> 00:10:21.520]   The first stage is human-led tooling. We build specialized tooling that sits and is embedded into the workflows of our different teams across marketing, product, and design.
[00:10:21.520 --> 00:10:29.520]   This includes things like internal dashboards, scraping tools, and prompt-chain agents. The whole idea is we are trying to augment the day-to-day tasks of anyone on our team.
[00:10:29.520 --> 00:10:43.520]   Stage two of this automation includes workflow automation, where we actually take off entire processes from people on the team, i.e., we have now consolidated on the individual tools that we built them to augment their workflows to now take over the entire workflows.
[00:10:43.520 --> 00:10:52.520]   This field frees a bandwidth on their end to take on more interesting tasks or take on more high leverage opportunities within the company.
[00:10:52.520 --> 00:11:05.520]   The third stage of all this is consolidating all the workflows that we've built under one autonomous decision-making system, i.e., an orchestration of multiple agents working together to serve the role of one new employee.
[00:11:05.520 --> 00:11:16.520]   Part of the goal with Olive is to build a company where we hire people for their strategic insight, their talent, and their taste, but run the entire company on a bunch of agents.
[00:11:16.520 --> 00:11:29.520]   We've already started this. For example, we've started building platforms that drive our market research so that we can find out lucrative markets to launch a new product into, as well as our acquisition process as we start to acquire new apps and scale a company.
[00:11:29.520 --> 00:11:42.520]   This includes things like agents that are scanning the markets consistently and daily for lucrative opportunities, categories that are doing super well, and trends in the market, as well as scoring acquisition targets for strategic fit.
[00:11:42.520 --> 00:11:51.520]   We've also started scaling and augmenting our growth systems. The same principles apply in terms of leveraging tools and AI. We are trying to automate our virality engine.
[00:11:51.520 --> 00:12:03.520]   This includes monitoring content, having on-the-fly feedback loops be kicked off when we have certain events being triggered, and also dealing with relationships as we work with creators and influencers and such.
[00:12:03.520 --> 00:12:16.520]   But we think we can take this further. We imagine a world where we can have one strategic person sit on top of an army of specialized agents. Instead of managing people, it becomes a game of commanding capability.
[00:12:16.520 --> 00:12:29.520]   They set the objective, the agents execute, and the system improves over time. But what we really want to build is a larger future, where we can have not just one person running a team, but one person running an entire product org,
[00:12:29.520 --> 00:12:41.520]   commanding multiple clusters of agents that serve different business units. We see a world where we can have people run entire portfolios of apps themselves just by leveraging the systems that we build and automate over time.
[00:12:41.520 --> 00:12:57.520]   This is effectively our vision. We're building a portfolio of one person billion dollar companies. As a quick aside, before I wrap up here, I will be talking tomorrow about Trellis, which stands for Targeted Refinement of Emergent LM Intelligence through Structured Segmentation.
[00:12:57.520 --> 00:13:10.520]   It is a framework that I came up with for scaling reliable AI user experiences to 5 million users designed specifically around a virality engine, i.e., it is built for systems where you intend to go viral as your main go-to-market.
[00:13:10.520 --> 00:13:14.520]   This will be part of the Testing the Untestable talk tomorrow at 2:20 p.m. in the SOMA room.
[00:13:14.520 --> 00:13:17.520]   Thank you for listening.
[00:13:17.520 --> 00:13:18.520]   Thank you for listening.
[00:13:18.520 --> 00:13:18.520]   Thank you.
[00:13:18.520 --> 00:13:19.520]   Thank you.
[00:13:19.520 --> 00:13:19.520]   Thank you.
[00:13:19.520 --> 00:13:19.520]   Thank you.
[00:13:19.520 --> 00:13:20.520]   Thank you.
[00:13:20.520 --> 00:13:20.520]   Thank you.
[00:13:20.520 --> 00:13:21.520]   Thank you.
[00:13:21.520 --> 00:13:25.620]   We'll see you next time.

