
[00:00:00.000 --> 00:00:05.320]   Just the other day, Australia passed a law, the first in the world of its kind, to ban
[00:00:05.320 --> 00:00:09.360]   social media for children under 16 and to offer stiff fines to social media companies
[00:00:09.360 --> 00:00:13.280]   if they don't put in the right safeguards to make this ban possible.
[00:00:13.280 --> 00:00:15.480]   I'm going to get into this law today.
[00:00:15.480 --> 00:00:17.680]   I'm going to go through the main arguments from both sides.
[00:00:17.680 --> 00:00:22.440]   So I will quote a key player both for and against this law, and we will go through these
[00:00:22.440 --> 00:00:26.880]   arguments together piece by piece, and then we will conclude where I stand on this or
[00:00:26.880 --> 00:00:29.840]   similar types of legislative action.
[00:00:29.840 --> 00:00:35.080]   The final part of this deep dive, I will then connect what's going on in Australia with
[00:00:35.080 --> 00:00:39.880]   all of our general struggles to control the role of technology for better or for worse
[00:00:39.880 --> 00:00:40.880]   in our lives.
[00:00:40.880 --> 00:00:42.920]   All right, let's start with some details.
[00:00:42.920 --> 00:00:46.780]   I'm going to read a couple of quotes from a recent CNN article about the law, just so
[00:00:46.780 --> 00:00:50.760]   that we are all starting from the same page with information about what's going on.
[00:00:50.760 --> 00:00:52.960]   So let me read here.
[00:00:52.960 --> 00:00:57.240]   Australia's parliament has passed a world first law banning social media for children
[00:00:57.240 --> 00:01:02.080]   under 16, putting tech companies on notice to tighten security before a cutoff date that's
[00:01:02.080 --> 00:01:04.000]   yet to be set.
[00:01:04.000 --> 00:01:09.280]   Under the new law, tech companies must take reasonable steps to prevent underage users
[00:01:09.280 --> 00:01:14.040]   from accessing social media services or face fines of nearly 50 million Australian dollars,
[00:01:14.040 --> 00:01:17.700]   which is about 32 million US.
[00:01:17.700 --> 00:01:21.400]   It's the world's toughest response yet to a problem that has seen other countries impose
[00:01:21.400 --> 00:01:25.640]   restrictions but not hold companies accountable for breaches of a nationwide ban.
[00:01:25.640 --> 00:01:31.640]   The ban is expected to apply to Snapchat, TikTok, Facebook, Instagram, Reddit and X,
[00:01:31.640 --> 00:01:33.040]   but that list could expand.
[00:01:33.040 --> 00:01:35.440]   All right, so that's just a quick summary.
[00:01:35.440 --> 00:01:37.400]   A couple other points.
[00:01:37.400 --> 00:01:42.000]   The bill was backed by most members of Australia's main opposition party, which is the Liberal
[00:01:42.000 --> 00:01:43.000]   Party.
[00:01:43.000 --> 00:01:47.680]   It does have some opposition, including some fierce opposition from independents and some
[00:01:47.680 --> 00:01:50.440]   of the smaller parties, including the Greens.
[00:01:50.440 --> 00:01:55.520]   And in terms of the Australian public, it has pretty large majority support.
[00:01:55.520 --> 00:02:01.880]   All right, so a strong social media ban for users under 16.
[00:02:01.880 --> 00:02:04.600]   Let's start for the arguments in favor.
[00:02:04.600 --> 00:02:10.440]   So the best summary I could find about the arguments in favor of this bill came from
[00:02:10.440 --> 00:02:15.400]   a quote from the prime minister of Australia, Anthony Albanese, who in that same CNN article
[00:02:15.400 --> 00:02:20.080]   I mentioned before said the following, "We know that social media can be a weapon for
[00:02:20.080 --> 00:02:26.440]   bullies, a platform for peer pressure, a driver of anxiety, a vehicle for scammers, and worst
[00:02:26.440 --> 00:02:31.300]   of all, a tool for online predators."
[00:02:31.300 --> 00:02:36.400]   This sentence packs in a lot of different arguments, so it's worth briefly unpacking
[00:02:36.400 --> 00:02:39.480]   into its constituent parts.
[00:02:39.480 --> 00:02:43.720]   So first of all, he's talking about social media being a weapon for bullies.
[00:02:43.720 --> 00:02:50.720]   So what's being captured here is that there is something about the pseudonymous communication
[00:02:50.720 --> 00:02:55.520]   that happens through these platforms, where you're talking to sort of visual, digital
[00:02:55.520 --> 00:03:00.320]   abstractions of individuals, typically just through text, not actually interacting with
[00:03:00.320 --> 00:03:03.220]   real flesh and blood individuals who are in front of you, who you can see and read their
[00:03:03.220 --> 00:03:08.560]   body language, feel the full force of social capital cost of what you're saying.
[00:03:08.560 --> 00:03:09.560]   It's pseudonymous.
[00:03:09.560 --> 00:03:10.560]   It's abstracted.
[00:03:10.560 --> 00:03:11.560]   It's digital.
[00:03:11.560 --> 00:03:15.620]   And as anyone who has spent any time looking at, say, political discussion online knows,
[00:03:15.620 --> 00:03:21.880]   this leads to a lack of the standard interpersonal inhibitions that typically structure our interactions
[00:03:21.880 --> 00:03:23.520]   with other humans.
[00:03:23.520 --> 00:03:25.240]   And it can really lead to extreme behaviors.
[00:03:25.240 --> 00:03:28.320]   It can lead to behaviors that in person be considered really antisocial.
[00:03:28.320 --> 00:03:33.800]   And among adolescents, the young adolescents and pre-adolescents who are very sensitive
[00:03:33.800 --> 00:03:39.080]   to social interactions, social media-based platforms, online interactions can really
[00:03:39.080 --> 00:03:47.320]   lead to bullying or all sorts of, think of it as verbal, I don't want to say violence,
[00:03:47.320 --> 00:03:49.320]   but negative outcomes.
[00:03:49.320 --> 00:03:52.400]   It's a platform for peer pressure, he says.
[00:03:52.400 --> 00:03:57.200]   I believe what he's alluding here is the fact that pre-adolescents and adolescents are very
[00:03:57.200 --> 00:04:01.280]   vulnerable to groups and peer pressures, and there is a lot of niche online communities
[00:04:01.280 --> 00:04:02.620]   that can be very persuasive.
[00:04:02.620 --> 00:04:06.520]   Their brains aren't used to the persuasiveness of these online communities, and it can push
[00:04:06.520 --> 00:04:10.400]   them into weird or destructive behaviors.
[00:04:10.400 --> 00:04:14.680]   What we have to think about about these online communities is that you have this sort of
[00:04:14.680 --> 00:04:20.880]   digital competition that is being mediated by curation algorithms and engagement-driven
[00:04:20.880 --> 00:04:27.440]   metrics, which it's as if you have hundreds of thousands of small, weird, cultish niche
[00:04:27.440 --> 00:04:31.740]   groups all competing in some giant American Idol-style competition.
[00:04:31.740 --> 00:04:34.320]   And those are the most compelling win.
[00:04:34.320 --> 00:04:39.600]   So now, when you're the 13-year-old and you're on TikTok and kind of browsing things, you're
[00:04:39.600 --> 00:04:43.600]   on Instagram sort of browsing things, it's not just that you're going to find yourself
[00:04:43.600 --> 00:04:46.660]   in the niche communities that are going to sort of suck you in and maybe change your
[00:04:46.660 --> 00:04:52.280]   behavior in drastic ways, but you're being subjected to the A-team, the all-star team
[00:04:52.280 --> 00:04:56.000]   of niche cultish communities, because just the fact that you are being shown them in
[00:04:56.000 --> 00:05:00.960]   your feed means that they have survived these algorithmically-mediated tournaments.
[00:05:00.960 --> 00:05:06.280]   So it used to be, hey, maybe you ran into a weird crowd or a cult at the airport when
[00:05:06.280 --> 00:05:07.280]   you were growing up.
[00:05:07.280 --> 00:05:11.440]   Now it's like, no, we've scoured the country to find niche communities that are most effective
[00:05:11.440 --> 00:05:15.800]   at grabbing people's attention, and this can cause lots of problems.
[00:05:15.800 --> 00:05:20.440]   One of the issues that these niche communities have exacerbated in pre-adolescence and adolescence
[00:05:20.440 --> 00:05:22.920]   we know is eating disorders.
[00:05:22.920 --> 00:05:29.280]   You can fall into these communities that are very compelling and very much glamorize very
[00:05:29.280 --> 00:05:32.120]   dangerous disordered eating behavior.
[00:05:32.120 --> 00:05:35.880]   Some of the small number of very powerful lawsuits right now that have been waged against
[00:05:35.880 --> 00:05:41.800]   META are specifically aimed at the damage caused by eating disorder communities online
[00:05:41.800 --> 00:05:43.360]   and what it did to kids.
[00:05:43.360 --> 00:05:45.520]   There's a lot of other things as well.
[00:05:45.520 --> 00:05:49.160]   All right, a driver of anxiety.
[00:05:49.160 --> 00:05:51.000]   The evidence here is clear.
[00:05:51.000 --> 00:05:52.000]   I've read the evidence.
[00:05:52.000 --> 00:05:53.000]   I've read the counter evidence.
[00:05:53.000 --> 00:05:54.000]   I've read the counter to the counter evidence.
[00:05:54.000 --> 00:05:56.400]   I've read the counter to the counter to the counter evidence.
[00:05:56.400 --> 00:06:01.640]   We have multiple independent streams of data that exactly matches self-reports.
[00:06:01.640 --> 00:06:03.280]   You cannot ignore self-reports.
[00:06:03.280 --> 00:06:05.880]   That's probably the strongest signal of all.
[00:06:05.880 --> 00:06:08.760]   That heavy social media use among young people makes them more anxious, and there's a lot
[00:06:08.760 --> 00:06:13.600]   of drivers for that, including these other issues that we're mentioning here.
[00:06:13.600 --> 00:06:15.380]   The scammers and online predators.
[00:06:15.380 --> 00:06:19.620]   This seems to be a real focus if you read the press coverage in Australia around the
[00:06:19.620 --> 00:06:22.560]   bill because it's the most concrete.
[00:06:22.560 --> 00:06:28.880]   When you put people on a pseudo-anonymous, open-access, global conversation platform,
[00:06:28.880 --> 00:06:31.900]   bad people are going to find the kids on there.
[00:06:31.900 --> 00:06:38.400]   It's like letting your kids free at 2 a.m. at the port authority.
[00:06:38.400 --> 00:06:41.120]   Most people there are probably pretty normal, but there's the weirdos, and they're probably
[00:06:41.120 --> 00:06:46.380]   going to find you, especially if you're walking around looking a little bit clueless.
[00:06:46.380 --> 00:06:50.080]   Because of this, online predators is kind of obvious.
[00:06:50.080 --> 00:06:53.520]   The scamming thing is becoming a real issue.
[00:06:53.520 --> 00:06:59.320]   There's been a slate of suicides, for example, recently that comes from these sexploitation
[00:06:59.320 --> 00:07:09.580]   scams where the scammer will meet you online and get you through various platforms to send
[00:07:09.580 --> 00:07:13.120]   them compromising or embarrassing video or photos, and then they say, "Yeah, we're going
[00:07:13.120 --> 00:07:16.480]   to send this to your parents unless you give us like $60,000."
[00:07:16.480 --> 00:07:19.520]   Kids can't handle that, and they feel trapped, and terrible things happen.
[00:07:19.520 --> 00:07:27.420]   It's very dangerous to put people who are young into, again, an open-access, global,
[00:07:27.420 --> 00:07:31.880]   pseudo-anonymous conversation platform.
[00:07:31.880 --> 00:07:37.160]   Everything that the prime minister is arguing here, I think every one of these is actually
[00:07:37.160 --> 00:07:40.200]   a real valid point and a real valid concern.
[00:07:40.200 --> 00:07:43.320]   There's some histrionics sometimes when we're talking about technology and kids.
[00:07:43.320 --> 00:07:45.960]   This seems not that.
[00:07:45.960 --> 00:07:49.300]   This list of issues, I'm like, "Yeah, this is a solid list of real issues that have real
[00:07:49.300 --> 00:07:54.440]   harms that come from kids or young adolescents using social media."
[00:07:54.440 --> 00:07:59.440]   All right, so what is the opposition saying?
[00:07:59.440 --> 00:08:00.960]   So we have some quotes here.
[00:08:00.960 --> 00:08:06.700]   I'm going to pull from, I found the best summary of the opposition came from an AP article
[00:08:06.700 --> 00:08:09.680]   I found that's sort of summarizing what the various opposition said.
[00:08:09.680 --> 00:08:15.520]   All right, so let me quote this, "Critics of the legislation fear that banning young
[00:08:15.520 --> 00:08:19.280]   children from social media will impact the privacy of all users who must establish their
[00:08:19.280 --> 00:08:21.660]   older than 16.
[00:08:21.660 --> 00:08:25.160]   Opponents also argue the ban would isolate children, deprive them of the positive aspects
[00:08:25.160 --> 00:08:30.200]   of social media, drive them to the dark web, discourage children too young for social media
[00:08:30.200 --> 00:08:35.480]   to report harm, and reduce incentives for platforms to improve online safety."
[00:08:35.480 --> 00:08:38.600]   All right, there's some legitimate arguments here.
[00:08:38.600 --> 00:08:42.680]   I'm going to take these one by one, not necessarily in that order, but let's take these one by
[00:08:42.680 --> 00:08:45.560]   one.
[00:08:45.560 --> 00:08:49.440]   So the first issue here is with the age-gating mechanism.
[00:08:49.440 --> 00:08:51.040]   How do we know who kids are?
[00:08:51.040 --> 00:08:54.440]   All right, there's a couple arguments surrounding this.
[00:08:54.440 --> 00:08:56.560]   One is this a technical argument.
[00:08:56.560 --> 00:08:58.520]   This is really what the social media companies are pushing.
[00:08:58.520 --> 00:09:00.480]   They're saying this is too hard.
[00:09:00.480 --> 00:09:02.920]   It's not really our responsibility.
[00:09:02.920 --> 00:09:04.320]   We don't know how to do this.
[00:09:04.320 --> 00:09:05.320]   You're not being clear enough.
[00:09:05.320 --> 00:09:10.680]   I would say this is the main lobbying pressure point they applied in Australia, which was
[00:09:10.680 --> 00:09:15.500]   the companies, "We don't want to argue about the harms or lack of harms, but we need more
[00:09:15.500 --> 00:09:19.080]   time and more studies," basically trying to slow walk the bill, because we don't know
[00:09:19.080 --> 00:09:21.480]   technically how to do this.
[00:09:21.480 --> 00:09:25.200]   And so don't give us these technical demands and just say, "Do it or we're going to fine
[00:09:25.200 --> 00:09:26.520]   you $50 million Australian dollars."
[00:09:26.520 --> 00:09:28.960]   So they're trying to slow walk it.
[00:09:28.960 --> 00:09:33.120]   I think this is a general response that the social media companies are having right now
[00:09:33.120 --> 00:09:39.800]   to this style of legislation, including COSA in the US, which is slow walk bills that have
[00:09:39.800 --> 00:09:46.440]   regulatory teeth, until you can do enough type of controls or options on your own that
[00:09:46.440 --> 00:09:49.560]   people will feel like, "I think they have enough stuff in place now.
[00:09:49.560 --> 00:09:50.560]   We don't need laws."
[00:09:50.560 --> 00:09:51.640]   Hey, it's Cal.
[00:09:51.640 --> 00:09:56.160]   I wanted to interrupt briefly to say that if you're enjoying this video, then you need
[00:09:56.160 --> 00:10:03.620]   to check out my new book, Slow Productivity, The Lost Art of Accomplishment Without Burnout.
[00:10:03.620 --> 00:10:09.040]   This is like the Bible for most of the ideas we talk about here in these videos.
[00:10:09.040 --> 00:10:14.440]   You can get a free excerpt at calnewport.com/slow.
[00:10:14.440 --> 00:10:16.240]   I know you're going to like it.
[00:10:16.240 --> 00:10:17.240]   Check it out.
[00:10:17.240 --> 00:10:19.280]   Now let's get back to the video.
[00:10:19.280 --> 00:10:21.920]   The other concern about this is the privacy concerns.
[00:10:21.920 --> 00:10:22.920]   It's a little confusing.
[00:10:22.920 --> 00:10:28.620]   In the US, some of the advocacy groups that are pushing these concerns are also heavily
[00:10:28.620 --> 00:10:30.880]   connected to the social media companies themselves.
[00:10:30.880 --> 00:10:37.000]   There's a lot of complicated backstory when it comes to who's arguing what, but let's
[00:10:37.000 --> 00:10:41.800]   just take the concerns in abstract and separate them from who's pushing them.
[00:10:41.800 --> 00:10:44.240]   There's a privacy concern.
[00:10:44.240 --> 00:10:45.240]   Forget the kids.
[00:10:45.240 --> 00:10:50.000]   I now, as an adult, have to prove that I'm 16 or older, and that's a privacy concern.
[00:10:50.000 --> 00:10:54.520]   Do I have to upload my license and show a social media company?
[00:10:54.520 --> 00:11:01.560]   Now a social media company knows who I am, and now I guess they can track what I'm saying
[00:11:01.560 --> 00:11:05.360]   or they can punish me in the real world for things I'm saying online, so there's privacy
[00:11:05.360 --> 00:11:07.280]   concerns around it.
[00:11:07.280 --> 00:11:11.760]   Ultimately, I think these are solvable issues.
[00:11:11.760 --> 00:11:14.240]   There's a couple of different ways to think about it.
[00:11:14.240 --> 00:11:17.560]   One is, and this is what the Australian legislatures are doing, it's a rip-the-band-it, like, look,
[00:11:17.560 --> 00:11:20.280]   you got a year, figure something out good enough.
[00:11:20.280 --> 00:11:22.360]   That often tends to work.
[00:11:22.360 --> 00:11:28.840]   I think there's many examples of regulation of this general flavor that have some sort
[00:11:28.840 --> 00:11:32.000]   of technical complexity that is eventually solved, where you say, look, you have to do
[00:11:32.000 --> 00:11:33.720]   it, and something is solved.
[00:11:33.720 --> 00:11:35.880]   It's imperfect, but something is solved.
[00:11:35.880 --> 00:11:41.440]   It should be said, there are, in the American context, there are other web-based services
[00:11:41.440 --> 00:11:46.640]   that have to do things like this, so notably in multiple U.S. states, pornographic websites
[00:11:46.640 --> 00:11:49.560]   have to do various types of age verification.
[00:11:49.560 --> 00:11:56.080]   It has not led to as big of privacy arguments because I think there's not as big of a lobbying
[00:11:56.080 --> 00:11:58.240]   effort to protect those sites.
[00:11:58.240 --> 00:12:01.040]   Let me tell you my preferred solution here.
[00:12:01.040 --> 00:12:08.120]   I do think, from a technologist's standpoint, the approach of saying the sites and apps
[00:12:08.120 --> 00:12:11.200]   need to age-gate, I actually don't think that's right.
[00:12:11.200 --> 00:12:14.320]   I don't think that's the right way to do this.
[00:12:14.320 --> 00:12:16.400]   There is privacy and technical concerns.
[00:12:16.400 --> 00:12:17.400]   Those are fair points.
[00:12:17.400 --> 00:12:22.000]   I actually think the right way to do this is at the operating system level.
[00:12:22.000 --> 00:12:27.380]   Here's my proposal, and I've talked about this before in various forums.
[00:12:27.380 --> 00:12:33.520]   My proposal is, what is something we know someone under 16 can't do?
[00:12:33.520 --> 00:12:40.960]   They can't go and buy an iPhone and set up cellular service for that iPhone, right?
[00:12:40.960 --> 00:12:42.880]   That we know an adult does.
[00:12:42.880 --> 00:12:47.120]   These 13-year-olds who have phones and they're using the phones to go on Instagram or to
[00:12:47.120 --> 00:12:51.360]   go on TikTok, the one thing we know is their parents set up that phone for them.
[00:12:51.360 --> 00:12:52.680]   You can't sign contracts.
[00:12:52.680 --> 00:12:54.200]   You don't have the money for it.
[00:12:54.200 --> 00:12:56.760]   You can't have a cellular contract.
[00:12:56.760 --> 00:13:02.200]   So I think that is actually the choke point for age verification, and I think it is as
[00:13:02.200 --> 00:13:05.200]   simple as this.
[00:13:05.200 --> 00:13:09.520]   When you buy a phone and set up a plan or add a phone to your plan, as the owner of
[00:13:09.520 --> 00:13:16.000]   this plan, the person who the plan's name is in, you just specify this is an under-16
[00:13:16.000 --> 00:13:20.680]   or above-16 phone, a single bit.
[00:13:20.680 --> 00:13:21.680]   We trust you.
[00:13:21.680 --> 00:13:24.240]   Yeah, you can lie, fine.
[00:13:24.240 --> 00:13:26.080]   We're not doing any more verification.
[00:13:26.080 --> 00:13:27.120]   There's no government.
[00:13:27.120 --> 00:13:29.640]   There's no government documents.
[00:13:29.640 --> 00:13:30.640]   There's no photos.
[00:13:30.640 --> 00:13:32.660]   There's no looking at your behavior.
[00:13:32.660 --> 00:13:36.640]   Just parents say this phone is for a kid, this phone is for an adult, and then if that
[00:13:36.640 --> 00:13:38.360]   kid gets older, they can change that.
[00:13:38.360 --> 00:13:43.240]   The same place they change the credit card you use for your billing.
[00:13:43.240 --> 00:13:46.480]   Now the operating system just has a single bit.
[00:13:46.480 --> 00:13:51.800]   Any service who wants can query the phone and say, is this someone who is 16 and older
[00:13:51.800 --> 00:13:55.160]   or not, and they get one bit yes or no.
[00:13:55.160 --> 00:13:56.600]   I think that's going to solve.
[00:13:56.600 --> 00:13:58.560]   That gives you like 90% there.
[00:13:58.560 --> 00:14:00.360]   There's no privacy concerns here.
[00:14:00.360 --> 00:14:02.680]   Technically it's pretty straightforward.
[00:14:02.680 --> 00:14:04.960]   From an effectiveness standpoint, it largely works.
[00:14:04.960 --> 00:14:10.840]   Yes, like adults can lie, but so they can do that with any of these bans, just set up
[00:14:10.840 --> 00:14:13.880]   an account and give it to their kid, give them their password to use.
[00:14:13.880 --> 00:14:15.600]   But this is simple.
[00:14:15.600 --> 00:14:17.120]   It gets rid of privacy issues.
[00:14:17.120 --> 00:14:19.040]   It gets rid of technical concerns, right?
[00:14:19.040 --> 00:14:25.000]   Now all these websites have to do is just access, make an OS call, is this an adult
[00:14:25.000 --> 00:14:26.000]   or not.
[00:14:26.000 --> 00:14:27.960]   And it simplifies a lot of things.
[00:14:27.960 --> 00:14:30.040]   So I do think it's a solvable problem.
[00:14:30.040 --> 00:14:32.440]   I don't want to dismiss it, but it's not a showstopper.
[00:14:32.440 --> 00:14:34.200]   And I am very suspicious of slow walking.
[00:14:34.200 --> 00:14:38.480]   Like eventually with these things, you have to just push something through.
[00:14:38.480 --> 00:14:43.960]   This has been, I think, more or less the approach with some of the US state laws that have age-related
[00:14:43.960 --> 00:14:45.720]   restrictions for various technologies.
[00:14:45.720 --> 00:14:46.720]   They're kind of saying, just figure it out.
[00:14:46.720 --> 00:14:50.360]   Ultimately, you do have to do something like that, but I like my OS solution.
[00:14:50.360 --> 00:14:51.440]   All right.
[00:14:51.440 --> 00:14:56.840]   Another argument, social media will become worse without the excuse of protecting kids.
[00:14:56.840 --> 00:15:00.120]   And kids will sneak in and not tell anyone because they're not supposed to be there.
[00:15:00.120 --> 00:15:02.320]   I don't buy this at all.
[00:15:02.320 --> 00:15:11.320]   This idea that the only thing keeping TikTok, Instagram, X, whatever, these are whatever
[00:15:11.320 --> 00:15:12.760]   services are being targeted here.
[00:15:12.760 --> 00:15:20.280]   The only thing keeping them from 8chan, just like straight up chaos, is the fact that we
[00:15:20.280 --> 00:15:21.600]   worry about kids being on there.
[00:15:21.600 --> 00:15:22.960]   That's nonsense.
[00:15:22.960 --> 00:15:24.160]   These companies don't care about kids.
[00:15:24.160 --> 00:15:27.760]   They haven't been doing almost anything for kids other than adding some privacy controls
[00:15:27.760 --> 00:15:30.760]   that parents can control.
[00:15:30.760 --> 00:15:35.480]   We are not, I do not buy this concept that our current social media experience is mediated
[00:15:35.480 --> 00:15:37.960]   by these companies being worried about kids.
[00:15:37.960 --> 00:15:40.360]   They're mediated by trying to keep their customers.
[00:15:40.360 --> 00:15:42.600]   What will our customers bear?
[00:15:42.600 --> 00:15:49.640]   If Instagram turns themselves into 8chan, most adults won't want to use Instagram.
[00:15:49.640 --> 00:15:54.960]   We see X decided we are going to get less content moderatedly, and then Blue Sky came
[00:15:54.960 --> 00:15:58.960]   along and said we'll get more content moderation.
[00:15:58.960 --> 00:16:01.200]   These found different audiences.
[00:16:01.200 --> 00:16:07.080]   People are carefully trying to titrate what their content's like.
[00:16:07.080 --> 00:16:10.460]   Threads are saying they're going to turn down political content, and we're going to turn
[00:16:10.460 --> 00:16:11.460]   up this type of content.
[00:16:11.460 --> 00:16:16.760]   Anyway, so I don't buy this idea that, oh, we know the kids aren't here.
[00:16:16.760 --> 00:16:21.860]   Let's bring out the Klu Klux Klan memes or whatever, because you're going to lose all
[00:16:21.860 --> 00:16:23.400]   your customers.
[00:16:23.400 --> 00:16:27.600]   I'm also not that convinced by the argument that, well, now kids will sneak in and not
[00:16:27.600 --> 00:16:31.000]   report what's going on because they're not supposed to be there.
[00:16:31.000 --> 00:16:35.080]   They're not reporting what's going on now that they're seeing that's bad.
[00:16:35.080 --> 00:16:37.160]   That's not compelling to me.
[00:16:37.160 --> 00:16:43.640]   I think the craziest argument against is this idea of, well, if kids can't use social media,
[00:16:43.640 --> 00:16:45.480]   they'll turn to the dark web.
[00:16:45.480 --> 00:16:53.000]   This is a canard, not just a canard, it's like a complete factual inaccuracy that I
[00:16:53.000 --> 00:16:57.240]   have been railing against for a long time.
[00:16:57.240 --> 00:16:59.640]   Social media is not the internet.
[00:16:59.640 --> 00:17:03.460]   Social media is a small number of services that essentially run their own private version
[00:17:03.460 --> 00:17:07.720]   of the internet that are accessed through internet protocols.
[00:17:07.720 --> 00:17:11.360]   But a lot of commentators, especially people who grew up on this or the companies themselves,
[00:17:11.360 --> 00:17:13.840]   like to equate social media with internet themselves.
[00:17:13.840 --> 00:17:17.720]   So they say if you're not on a social media platform, what's left?
[00:17:17.720 --> 00:17:19.840]   The dark web.
[00:17:19.840 --> 00:17:20.840]   That's crazy.
[00:17:20.840 --> 00:17:23.360]   The dark web is a very specific thing.
[00:17:23.360 --> 00:17:29.720]   It's sites and services that don't publicly have domain names that are accessible through
[00:17:29.720 --> 00:17:35.520]   standard DNS services or so that you only can get to them if someone has told you specifically
[00:17:35.520 --> 00:17:39.480]   how to log into them so that they can have less scrutiny from law enforcement.
[00:17:39.480 --> 00:17:44.280]   It's like this very small corner of the internet that's used for hiring hit men and drug trafficking
[00:17:44.280 --> 00:17:45.560]   and child pornography.
[00:17:45.560 --> 00:17:49.720]   You have all of the internet outside of social media that's not the dark web.
[00:17:49.720 --> 00:17:52.040]   I've never had a social media account.
[00:17:52.040 --> 00:17:53.840]   I use the internet a lot.
[00:17:53.840 --> 00:17:56.120]   I'm not on the dark web.
[00:17:56.120 --> 00:18:01.360]   So I do not like this idea that the internet is social media, and if you're not on social
[00:18:01.360 --> 00:18:05.040]   media, you're on some dark website ordering hit men.
[00:18:05.040 --> 00:18:08.920]   All right, the final argument is kids will isolate and lose the positive benefits of
[00:18:08.920 --> 00:18:09.920]   social media.
[00:18:09.920 --> 00:18:12.280]   I think this is the point that's most worth arguing.
[00:18:12.280 --> 00:18:19.060]   It's the point that's most relevant when it comes to concerns about social media bans.
[00:18:19.060 --> 00:18:22.200]   It's not one that should be dismissed.
[00:18:22.200 --> 00:18:27.080]   Now the key to this, let's get fine tuned.
[00:18:27.080 --> 00:18:32.280]   The key to this argument is discerning between two different subgroups of kids.
[00:18:32.280 --> 00:18:36.240]   And this is why I think it's confusing for people when they hear this argument on either
[00:18:36.240 --> 00:18:40.840]   side of it is because they're mixing together two different groups of kids.
[00:18:40.840 --> 00:18:49.440]   For most kids, losing access to internet-based community is not a problem.
[00:18:49.440 --> 00:18:54.740]   For most kids, actually, the moving more sociality to digital communication itself is causing
[00:18:54.740 --> 00:18:55.880]   more harms.
[00:18:55.880 --> 00:19:01.560]   For most kids, if you move them back to a more localized in-person sociality, that's
[00:19:01.560 --> 00:19:05.720]   actually really healthy for kids, because it's very complicated to build up your social
[00:19:05.720 --> 00:19:08.360]   skills to mature as a social being.
[00:19:08.360 --> 00:19:12.880]   It takes lots of practice, and you need all of the sources of information we're evolved
[00:19:12.880 --> 00:19:13.880]   to take in.
[00:19:13.880 --> 00:19:14.880]   We need to see people in front of us.
[00:19:14.880 --> 00:19:15.880]   We need to see their body language.
[00:19:15.880 --> 00:19:17.220]   We need to struggle.
[00:19:17.220 --> 00:19:20.800]   We need the friction of trying to navigate complicated in-person social interactions
[00:19:20.800 --> 00:19:23.160]   to get that practice that's going to make us better at it.
[00:19:23.160 --> 00:19:28.360]   So for most kids, it's kind of what you need, actually, is like what I had in the 1990s
[00:19:28.360 --> 00:19:30.640]   as a junior, as a high school student.
[00:19:30.640 --> 00:19:31.640]   It's actually fine.
[00:19:31.640 --> 00:19:34.040]   Most kids are going to be fine.
[00:19:34.040 --> 00:19:42.080]   There is, however, certain kids who perhaps are in a marginalized group living in an area
[00:19:42.080 --> 00:19:43.440]   where there really is very little support.
[00:19:43.440 --> 00:19:45.520]   Maybe there's just not very many other people like them.
[00:19:45.520 --> 00:19:48.180]   They really do feel isolated.
[00:19:48.180 --> 00:19:50.880]   In-person sociality is not going well.
[00:19:50.880 --> 00:19:54.540]   Traditionally, they would have had a very hard childhood.
[00:19:54.540 --> 00:19:59.960]   They would have felt very isolated, and maybe on social media they can find other people
[00:19:59.960 --> 00:20:04.880]   to support them, find other people who are of a similar community that shows that they're
[00:20:04.880 --> 00:20:07.320]   not alone.
[00:20:07.320 --> 00:20:10.160]   All of this could be really useful for that group.
[00:20:10.160 --> 00:20:13.480]   So that's the group, I think, for which that's true.
[00:20:13.480 --> 00:20:21.560]   That's where you need to be worried about when it comes to this particular type of argument.
[00:20:21.560 --> 00:20:28.320]   One thing I'll say here, and one way we can think about this, is asking the question of
[00:20:28.320 --> 00:20:37.600]   whether social media platforms are inherent in Internet-based support communities.
[00:20:37.600 --> 00:20:40.480]   There are Internet-based support communities that come through social media.
[00:20:40.480 --> 00:20:43.840]   Social media kind of makes them easier to find, and typically it's a good interface.
[00:20:43.840 --> 00:20:44.840]   It's easy to use.
[00:20:44.840 --> 00:20:50.240]   You can find your particular—maybe you're on TikTok pretty quickly, for example.
[00:20:50.240 --> 00:20:53.960]   Just automatically find you want to see videos from these type of people, and you'll see
[00:20:53.960 --> 00:20:54.960]   them a lot.
[00:20:54.960 --> 00:20:55.960]   You don't have to do much.
[00:20:55.960 --> 00:21:01.840]   Or you can find a Facebook group or a Reddit thread that's of a particular community, and
[00:21:01.840 --> 00:21:06.480]   the interface is there, and you have a nice app, and so it could be really useful.
[00:21:06.480 --> 00:21:10.240]   But there is a lot of Internet, like we just argued, that's not through these global conversation
[00:21:10.240 --> 00:21:11.240]   platforms.
[00:21:11.240 --> 00:21:16.040]   There's a lot of Internet that can be leveraged successfully to help young people find support
[00:21:16.040 --> 00:21:17.040]   communities.
[00:21:17.040 --> 00:21:20.440]   You have, for example, the whole world of things like newsletters and podcasts, which
[00:21:20.440 --> 00:21:22.440]   often spawn their own communities.
[00:21:22.440 --> 00:21:27.480]   If you belong to a sub-stack newsletter about something you really care about, you're probably
[00:21:27.480 --> 00:21:32.120]   familiar with the fact that there's a comment section on the newsletter post, there's chats
[00:21:32.120 --> 00:21:37.400]   that happen back and forth with the author of it, and they're niche communities.
[00:21:37.400 --> 00:21:38.800]   It's people who are interested in this very thing.
[00:21:38.800 --> 00:21:40.760]   It's a small group of people.
[00:21:40.760 --> 00:21:42.440]   It's much more cohesive.
[00:21:42.440 --> 00:21:43.940]   There's no algorithmic curation.
[00:21:43.940 --> 00:21:45.800]   There's no engagement.
[00:21:45.800 --> 00:21:49.520]   It's not 100,000 people talking about this and the most outrageous stuff being curated
[00:21:49.520 --> 00:21:50.520]   for what you see.
[00:21:50.520 --> 00:21:52.880]   It's there's 600 people here.
[00:21:52.880 --> 00:21:53.880]   We're kind of on the same page.
[00:21:53.880 --> 00:21:56.840]   We set up our own community norms, right?
[00:21:56.840 --> 00:21:58.840]   You can have a very strong community.
[00:21:58.840 --> 00:22:01.800]   There's communities run by teens themselves.
[00:22:01.800 --> 00:22:04.680]   These are based around discussion boards or chat channels, et cetera, that just don't
[00:22:04.680 --> 00:22:07.720]   happen to live in a social media ecosystem.
[00:22:07.720 --> 00:22:11.200]   Community groups themselves could run their own online services, be it web or app-based,
[00:22:11.200 --> 00:22:15.160]   where people could come together and chat and share resources and have appropriate moderation
[00:22:15.160 --> 00:22:19.880]   for exactly what this community is.
[00:22:19.880 --> 00:22:21.560]   Moderation is not a bad thing.
[00:22:21.560 --> 00:22:27.460]   Moderation is hard when you're trying to apply rules to 600 million Twitter users.
[00:22:27.460 --> 00:22:28.460]   Moderation is much easier.
[00:22:28.460 --> 00:22:35.240]   This is a group for teens from this background, and there's a few hundred of us on here.
[00:22:35.240 --> 00:22:39.680]   That's a very easy community to moderate compared to we need rules for 600 million people.
[00:22:39.680 --> 00:22:43.560]   So my argument there is that is a fair point.
[00:22:43.560 --> 00:22:46.440]   We need to think about groups that are finding support in the internet and make sure that
[00:22:46.440 --> 00:22:49.920]   we don't wrench them away from that, but we should start thinking about finding that support
[00:22:49.920 --> 00:22:54.560]   in ways that does not necessarily involve global conversation platforms, these social
[00:22:54.560 --> 00:22:55.560]   platforms.
[00:22:55.560 --> 00:22:56.560]   All right.
[00:22:56.560 --> 00:22:59.140]   So there's the arguments for and the arguments against.
[00:22:59.140 --> 00:23:00.280]   I've gone through each of those.
[00:23:00.280 --> 00:23:01.280]   What's my take?
[00:23:02.160 --> 00:23:05.960]   I would say I'm generally in favor of legislation like this at this moment.
[00:23:05.960 --> 00:23:09.720]   Not because I think it solves all the problems, like put a law like this in place and then
[00:23:09.720 --> 00:23:11.400]   we can all go home.
[00:23:11.400 --> 00:23:14.320]   Our kids will be safe and we don't have to think about it.
[00:23:14.320 --> 00:23:19.520]   What's good about this type of legislation is the signal it sends, and it is a signal
[00:23:19.520 --> 00:23:23.280]   that is fundamentally techno-selectionist, to use a piece of terminology that I like
[00:23:23.280 --> 00:23:25.560]   and that I introduced.
[00:23:25.560 --> 00:23:31.360]   It shows that we can notice that something that we embraced and had many good attributes
[00:23:31.360 --> 00:23:36.320]   is having unexpected negative side effects in certain instances or certain groups, and
[00:23:36.320 --> 00:23:38.640]   it's perfectly appropriate to say, "Well, great.
[00:23:38.640 --> 00:23:46.120]   Maybe we should pull it back there," that the arrow of the future with technology is
[00:23:46.120 --> 00:23:48.320]   not unvaryingly straight.
[00:23:48.320 --> 00:23:50.260]   It's like a meandering river.
[00:23:50.260 --> 00:23:54.160]   It's generally heading towards some sort of proverbial future sea, but it takes turns
[00:23:54.160 --> 00:23:57.120]   and has oxbows, and we can say, "This technology is great.
[00:23:57.120 --> 00:23:59.000]   Let's try it out.
[00:23:59.000 --> 00:24:00.080]   That service didn't work.
[00:24:00.080 --> 00:24:01.080]   Kids shouldn't use this.
[00:24:01.080 --> 00:24:03.040]   Actually, if we change it to this, this works better."
[00:24:03.040 --> 00:24:08.200]   We can edit and reflect and curate and change our relationship to technologies that already
[00:24:08.200 --> 00:24:11.360]   exist, even technologies that are already widely used.
[00:24:11.360 --> 00:24:16.820]   I also like that legislation like this sends a message to parents, right?
[00:24:16.820 --> 00:24:18.480]   It's okay to say, "I worry about this.
[00:24:18.480 --> 00:24:20.400]   I don't like my kids using this."
[00:24:20.400 --> 00:24:25.460]   When you have a law that's like, "Kids shouldn't use this," it makes it so much easier to
[00:24:25.460 --> 00:24:27.160]   actually tell your kids, "I don't want to use it."
[00:24:27.160 --> 00:24:31.000]   It makes it so much easier for your kids not to feel alone when they don't use it.
[00:24:31.000 --> 00:24:34.400]   This is something that opponents often don't understand about these type of laws, is they
[00:24:34.400 --> 00:24:35.880]   say, "Well, wait a second.
[00:24:35.880 --> 00:24:38.680]   So many kids will get around this.
[00:24:38.680 --> 00:24:42.040]   It's not that hard to get around if they really want to."
[00:24:42.040 --> 00:24:43.040]   That's not the point.
[00:24:43.040 --> 00:24:45.920]   I think the point is not trying to get 100% compliance.
[00:24:45.920 --> 00:24:49.960]   It's trying to make the lives of families and parents who are really worried about this
[00:24:49.960 --> 00:24:53.400]   100% easier.
[00:24:53.400 --> 00:24:58.200]   Because now it's not, "I will be the only one in my class who's not on Snapchat and
[00:24:58.200 --> 00:25:01.880]   my life's going to be terrible," to now the kid has to argue to a parent, "Will you break
[00:25:01.880 --> 00:25:03.520]   the law for me?"
[00:25:03.520 --> 00:25:05.440]   That's a much easier place for parents to be.
[00:25:05.440 --> 00:25:07.560]   So I think that's fine.
[00:25:07.560 --> 00:25:12.260]   I'm also generally not in favor of the approach of, "Why don't we just instead make social
[00:25:12.260 --> 00:25:13.440]   media safer for everyone?"
[00:25:13.440 --> 00:25:17.920]   I just think that's an impossible thing to do.
[00:25:17.920 --> 00:25:19.760]   It's somewhat techno-utopian.
[00:25:19.760 --> 00:25:22.060]   It gets very vague.
[00:25:22.060 --> 00:25:25.340]   It runs into all sorts of issues.
[00:25:25.340 --> 00:25:31.400]   I just have not, I don't have a lot of confidence that there's a way legislatively to make social
[00:25:31.400 --> 00:25:32.920]   media good for everyone.
[00:25:32.920 --> 00:25:38.640]   It ends up being like having extra long filters on the cigarettes you sell the kids.
[00:25:38.640 --> 00:25:42.120]   Sometimes something is just not appropriate for one group that's better for another.
[00:25:42.120 --> 00:25:44.240]   Yeah, we do our best.
[00:25:44.240 --> 00:25:45.760]   This social media is an interesting thing.
[00:25:45.760 --> 00:25:46.760]   It's entertaining.
[00:25:46.760 --> 00:25:47.760]   It's also kind of dangerous.
[00:25:47.760 --> 00:25:48.840]   So maybe just kids shouldn't be there.
[00:25:48.840 --> 00:25:52.040]   That's often easier than somehow trying to go through.
[00:25:52.040 --> 00:25:55.640]   We tried this with movies and then we figured out it's better just to have ratings and say,
[00:25:55.640 --> 00:25:58.940]   you have to be older than 16 to go to the R-rated movies.
[00:25:58.940 --> 00:26:02.680]   It was easier than trying to have the Hays Codes or whatever that was trying to make
[00:26:02.680 --> 00:26:04.940]   all movies appropriate for all people.
[00:26:04.940 --> 00:26:08.520]   We didn't get as good of movies with those in place and it was just easier to say, "Well,
[00:26:08.520 --> 00:26:11.760]   if we want to be really violent or whatever, maybe just young people shouldn't go there
[00:26:11.760 --> 00:26:15.320]   unless a parent really wants them to see it and the parent can make that choice and that's
[00:26:15.320 --> 00:26:16.320]   the R-rated movie system."
[00:26:16.320 --> 00:26:17.320]   All right.
[00:26:17.320 --> 00:26:20.160]   But I want to emphasize two things here.
[00:26:20.160 --> 00:26:25.240]   What's talked about in these type of bills does not capture all the harm of the internet
[00:26:25.240 --> 00:26:27.280]   facing kids.
[00:26:27.280 --> 00:26:30.160]   Much of the digital bullying that's happening right now with kids is happening on group
[00:26:30.160 --> 00:26:33.800]   text messaging apps, not in social media platforms.
[00:26:33.800 --> 00:26:36.920]   Snapchat is where this used to happen, but that's really just a glorified text messaging
[00:26:36.920 --> 00:26:39.580]   service that kids like to use.
[00:26:39.580 --> 00:26:44.600]   So if you really want to help the bullying issue, this is where having a culture of kids
[00:26:44.600 --> 00:26:47.880]   aren't just on their own phones all the time makes more of a difference.
[00:26:47.880 --> 00:26:51.160]   This also ignores online games.
[00:26:51.160 --> 00:26:54.800]   Online games are a huge source of the sort of predation, online exploitation, predation
[00:26:54.800 --> 00:26:55.800]   issues.
[00:26:55.800 --> 00:27:01.160]   You know, a lot of parents who maybe would not give their kid a phone thinks it's fine
[00:27:01.160 --> 00:27:06.800]   that their kid is playing Minecraft on a server on their iPad, not realize they're playing
[00:27:06.800 --> 00:27:10.120]   that with unknown adults who are able to interact with them.
[00:27:10.120 --> 00:27:13.860]   So it's sort of missing out other sources of predation.
[00:27:13.860 --> 00:27:17.560]   But mainly this is missing out on this type of bill, this type of discussion is missing
[00:27:17.560 --> 00:27:22.200]   out on the fact that these types of devices and the content accessible to these devices
[00:27:22.200 --> 00:27:25.720]   is hugely distracting and addicting for young people.
[00:27:25.720 --> 00:27:27.620]   It's digital fentanyl for a young person.
[00:27:27.620 --> 00:27:32.600]   Think about any 14-year-old you've ever known or have ever seen who's been given a smartphone.
[00:27:32.600 --> 00:27:35.500]   It is glued to their eyeball.
[00:27:35.500 --> 00:27:38.820]   The ultra processed content, be it coming through a social media platform or through
[00:27:38.820 --> 00:27:43.860]   online games or through like hyper addictive web content or video, you know, hyper addictive
[00:27:43.860 --> 00:27:50.200]   video content, whatever it is, the growing kid brain can't handle this.
[00:27:50.200 --> 00:27:54.860]   Like we thought this was bad enough in the 70s when latchkey kids like got glued to TV.
[00:27:54.860 --> 00:27:57.780]   This is like a hundred times worse.
[00:27:57.780 --> 00:28:01.260]   Now this is not something that these type of bills are trying to handle, but it is one
[00:28:01.260 --> 00:28:02.260]   of the largest issues.
[00:28:02.260 --> 00:28:04.900]   We're going to see it in the questions that we're about to answer here.
[00:28:04.900 --> 00:28:07.760]   This causes real issues for people.
[00:28:07.760 --> 00:28:12.560]   It causes real issues to sort of all out distraction and addiction of these devices.
[00:28:12.560 --> 00:28:17.000]   So honestly, if you want to know what I think is most appropriate, it comes back to my main
[00:28:17.000 --> 00:28:21.880]   suggestion, which is it's not just social media, it's unrestricted internet access.
[00:28:21.880 --> 00:28:24.600]   That is a problem when you're younger than 16.
[00:28:24.600 --> 00:28:29.520]   So no, you shouldn't have a smartphone or a tablet with unrestricted internet access.
[00:28:29.520 --> 00:28:34.280]   I mean, you can just do what you want on this without supervision until you're 16.
[00:28:34.280 --> 00:28:37.860]   That's really the move here that if I'm a parent or I'm a community group, that's really
[00:28:37.860 --> 00:28:40.020]   the move here that probably matters.
[00:28:40.020 --> 00:28:42.820]   That's not something that I think could be easily legislated and I don't think it necessarily
[00:28:42.820 --> 00:28:43.820]   needs to.
[00:28:43.820 --> 00:28:45.440]   This could be a cultural shift.
[00:28:45.440 --> 00:28:48.880]   So again, laws like Australia is fine for signaling that it's fine to make different
[00:28:48.880 --> 00:28:53.960]   choices in your family, but the lack of unrestricted internet access for kids before 16 is probably
[00:28:53.960 --> 00:28:56.840]   like the bigger choice that's going to make a bigger difference.
[00:28:56.840 --> 00:28:57.840]   All right.
[00:28:57.840 --> 00:29:00.240]   So how do we connect this to all of us?
[00:29:00.240 --> 00:29:05.980]   Well, what we are seeing here is techno-selectionism in play.
[00:29:05.980 --> 00:29:10.400]   This idea that it's okay to try, watch, and change.
[00:29:10.400 --> 00:29:12.120]   Try, watch, and change.
[00:29:12.120 --> 00:29:15.640]   The introduction of a technology doesn't mean it always has to be used.
[00:29:15.640 --> 00:29:20.040]   Your prior use of a technology doesn't dictate your future use of a technology.
[00:29:20.040 --> 00:29:21.700]   Be aware of the impact of technologies.
[00:29:21.700 --> 00:29:26.340]   Make assessments of this impact of technology and make changes accordingly.
[00:29:26.340 --> 00:29:28.800]   That's what all of us should be thinking about.
[00:29:28.800 --> 00:29:32.540]   There's probably a technology in all of our lives that needs the equivalent of the Australian
[00:29:32.540 --> 00:29:33.540]   ban.
[00:29:33.540 --> 00:29:36.400]   Someone to come along and say, "Hey, just stop using this.
[00:29:36.400 --> 00:29:39.200]   Maybe it was good before, but it's causing more trouble than it's worth."
[00:29:39.200 --> 00:29:44.200]   We should be comfortable with moving backwards in this sense without thinking it's progress
[00:29:44.200 --> 00:29:45.200]   turning backwards.
[00:29:45.200 --> 00:29:47.240]   So I think there's a general message here of techno-selectionism.
[00:29:47.240 --> 00:29:49.540]   All right.
[00:29:49.540 --> 00:29:51.440]   That's enough on what's going on in Australia.
[00:29:51.440 --> 00:29:53.560]   Let's get to some questions about these general topics.
[00:29:53.560 --> 00:29:57.040]   But first, let's hear a word from a sponsor.
[00:29:57.040 --> 00:30:03.280]   I want to start by talking about a new sponsor of the podcast that I'm excited about, and
[00:30:03.280 --> 00:30:07.880]   that is our friends at Lofty, makers of the Lofty Clock.
[00:30:07.880 --> 00:30:12.280]   One of the big points I talk about a lot on this show is that your smartphone should not
[00:30:12.280 --> 00:30:15.640]   be a constant companion.
[00:30:15.640 --> 00:30:19.820]   Nowhere is this advice more true than when it comes to your bedroom.
[00:30:19.820 --> 00:30:23.400]   If you have your phone next to your bed, that means it's going to be the last thing you
[00:30:23.400 --> 00:30:26.440]   look at before you go to sleep, the first thing you look at when you wake up, and whatever
[00:30:26.440 --> 00:30:30.080]   you whenever you wake up in the middle of the night, what's going to keep you up a little
[00:30:30.080 --> 00:30:31.400]   bit longer.
[00:30:31.400 --> 00:30:35.920]   This not only is going to eat into your sleep time, it really feeds the addictive relationship
[00:30:35.920 --> 00:30:36.920]   with your phone.
[00:30:36.920 --> 00:30:40.160]   So you've got to get those phones out of your bedroom.
[00:30:40.160 --> 00:30:42.520]   The problem is, how do you wake up?
[00:30:42.520 --> 00:30:45.960]   We have become used to using our smartphones as our alarm clocks.
[00:30:45.960 --> 00:30:50.000]   This is where the Lofty Clock enters the scene.
[00:30:50.000 --> 00:30:57.960]   It is a beautifully designed piece of machinery technology that has one purpose, to be a clock
[00:30:57.960 --> 00:30:59.920]   that wakes you up.
[00:30:59.920 --> 00:31:00.920]   It does this really well.
[00:31:00.920 --> 00:31:06.260]   We're well past the old-school bells ringing on an old-fashioned alarm clock.
[00:31:06.260 --> 00:31:08.160]   You can choose how you want to do it.
[00:31:08.160 --> 00:31:12.800]   There's soothing sounds like birds chirping or waves crashing.
[00:31:12.800 --> 00:31:16.320]   For my wife and I, I don't know what you would call the sound that we use.
[00:31:16.320 --> 00:31:19.640]   It's like nice flutes, like pan flutes.
[00:31:19.640 --> 00:31:22.440]   I don't know, but it's a very nice way to wake up because we do not have our phones
[00:31:22.440 --> 00:31:23.440]   in our room.
[00:31:23.440 --> 00:31:25.520]   I keep mine plugged in at night downstairs.
[00:31:25.520 --> 00:31:30.040]   My wife literally plugs it in outside of our bedroom, just so it's technically not in there.
[00:31:30.040 --> 00:31:35.300]   So having one of these modern, sleek alarm clocks allows us to wake up nicely without
[00:31:35.300 --> 00:31:38.640]   having to have our phones right there.
[00:31:38.640 --> 00:31:40.440]   We can think about Lofty as more than just a clock.
[00:31:40.440 --> 00:31:44.080]   Think of it as a sleep companion because it also has guided meditations, breathwork, even
[00:31:44.080 --> 00:31:47.240]   white noise to help you drift off peacefully at night.
[00:31:47.240 --> 00:31:48.320]   I'm a huge white noise guy.
[00:31:48.320 --> 00:31:49.800]   I cannot sleep in silence.
[00:31:49.800 --> 00:31:52.440]   I travel to hotels with a white noise machine.
[00:31:52.440 --> 00:31:53.440]   That's a true story.
[00:31:53.440 --> 00:31:57.680]   The two-phase alarm, that's a two-phase alarm that will give you a gentle nudge at first,
[00:31:57.680 --> 00:32:01.200]   which often is enough to wake you up, and then a final wake up to help ease you into
[00:32:01.200 --> 00:32:03.560]   your day instead of just jolting you awake.
[00:32:03.560 --> 00:32:07.720]   The library of daily meditations, breathwork, exercises, sound baths, sleep stories, and
[00:32:07.720 --> 00:32:12.240]   more will help you relax and unwind without having to use your phone.
[00:32:12.240 --> 00:32:18.080]   I think it's kind of cool to have a meditation if you're a little stressed before bed, coming
[00:32:18.080 --> 00:32:20.640]   right from your clock without having to bring your phone into the room.
[00:32:20.640 --> 00:32:26.000]   It has an entire rainbow of white and color noises, as well as nature sounds to help you
[00:32:26.000 --> 00:32:28.600]   drift into a slumber without having to look at a screen.
[00:32:28.600 --> 00:32:33.880]   Again, its design is beautiful, sleek, minimalist, modern aesthetics, clutter-free vibe.
[00:32:33.880 --> 00:32:36.400]   It's going to fit in well in any bedroom.
[00:32:36.400 --> 00:32:41.600]   The Lofty clock will help you, like it has helped me, get your phone out of your bedroom
[00:32:41.600 --> 00:32:42.880]   and make your sleep better.
[00:32:42.880 --> 00:32:46.880]   If you're ready to ditch your phone and reclaim your rest, or you want to give the gift of
[00:32:46.880 --> 00:32:50.680]   better sleep to someone you love, you've got to check out Lofty.
[00:32:50.680 --> 00:32:57.760]   Go to buylofty.com, that's b-y-lofty.com, and grab yours today.
[00:32:57.760 --> 00:33:02.680]   If you use the code DEEP20, the word DEEP, the number 20, you will get 20% off orders
[00:33:02.680 --> 00:33:04.140]   over $125.
[00:33:04.140 --> 00:33:07.520]   That's buylofty.com, use the code DEEP20.
[00:33:07.520 --> 00:33:11.320]   Trust me, this little clock is a game changer and the perfect gift.
[00:33:11.320 --> 00:33:15.400]   I also want to talk about our longtime friends at Element who have a new thing going on that's
[00:33:15.400 --> 00:33:16.400]   pretty cool.
[00:33:16.400 --> 00:33:21.320]   For those who don't know, Element is a zero sugar electrolyte drink mix and sparkling
[00:33:21.320 --> 00:33:25.120]   electrolyte water born from the growing body of research revealing that optimal health
[00:33:25.120 --> 00:33:30.040]   outcomes occur at sodium levels two to three times government recommendations.
[00:33:30.040 --> 00:33:32.780]   What I like about Element is that not only does it give you the sodium you need when
[00:33:32.780 --> 00:33:38.240]   you're dehydrated, but it doesn't have junk in it, no sugar, no weird artificial ingredients.
[00:33:38.240 --> 00:33:43.480]   You can feel good about adding that mix to your water or pulling a premix can of their
[00:33:43.480 --> 00:33:46.580]   sparkling water with the electrolytes already in it.
[00:33:46.580 --> 00:33:50.140]   We have a large box of Element at our house.
[00:33:50.140 --> 00:33:51.300]   After workouts, I drink it.
[00:33:51.300 --> 00:33:56.600]   After long days of podcasting or lecturing, which is very dehydrating, I drink it.
[00:33:56.600 --> 00:34:00.060]   Or if I spend a lot of time outside, or if I had a hard night, I'm feeling sluggish in
[00:34:00.060 --> 00:34:03.840]   the morning, it helps get me hydrated and I know I'm not drinking junk.
[00:34:03.840 --> 00:34:08.920]   The new thing I want to tell you about is now that we're in winter, consider the limited
[00:34:08.920 --> 00:34:13.700]   time availability of Element chocolate medley, which includes chocolate mint, chocolate chai,
[00:34:13.700 --> 00:34:15.200]   and chocolate raspberry flavors.
[00:34:15.200 --> 00:34:16.560]   Here's the thing.
[00:34:16.560 --> 00:34:21.860]   You can mix the chocolate medley flavors with hot water and you can enjoy it on your own
[00:34:21.860 --> 00:34:25.760]   or add it to an existing hot drink recipe that you like.
[00:34:25.760 --> 00:34:29.020]   You can put, and here's something I've been messing around with, put a half stick of chocolate
[00:34:29.020 --> 00:34:36.520]   mint in your coffee and now you have like a hydrating mint mocha coffee in the morning.
[00:34:36.520 --> 00:34:37.520]   It's a great ritual.
[00:34:37.520 --> 00:34:42.640]   You get in from shoveling that snow, you're dehydrated, you don't want to just grab a
[00:34:42.640 --> 00:34:48.720]   cold water bottle, heat up some of this Element chocolate medley flavors, it will be a ritual
[00:34:48.720 --> 00:34:53.280]   that you will come to enjoy in the cold months we're in right now.
[00:34:53.280 --> 00:34:54.640]   Here's a good news.
[00:34:54.640 --> 00:35:00.280]   You will receive a free Element sample pack with any order if you go to www.drinkelement.com/deep
[00:35:00.280 --> 00:35:01.280]   to order.
[00:35:01.280 --> 00:35:07.400]   That's www.drinkelement.com/deep to make your order and you will get a free Element sample
[00:35:07.400 --> 00:35:08.400]   pack.
[00:35:08.400 --> 00:35:10.020]   Remember, you can try Element totally risk-free.
[00:35:10.020 --> 00:35:12.680]   If you don't like it, give it away to a salty friend and we'll give you your money back.
[00:35:12.680 --> 00:35:13.680]   No questions asked.
[00:35:13.680 --> 00:35:14.680]   But don't worry.
[00:35:14.680 --> 00:35:18.780]   They have a very low return rate and high reorder rate because people like me love us
[00:35:18.780 --> 00:35:19.780]   some Element.
[00:35:19.780 --> 00:35:20.780]   All right.
[00:35:20.780 --> 00:35:21.780]   Let's get back to the show.
[00:35:21.780 --> 00:35:22.780]   All right.
[00:35:22.780 --> 00:35:23.780]   We're back.
[00:35:23.780 --> 00:35:24.780]   Let's do some questions.
[00:35:24.780 --> 00:35:27.840]   Without Jesse here, I'm going to have to read these questions myself.
[00:35:27.840 --> 00:35:28.840]   This is no fun.
[00:35:28.840 --> 00:35:29.840]   All right.
[00:35:29.840 --> 00:35:30.840]   Our first question comes from EM.
[00:35:30.840 --> 00:35:36.520]   EM says, "I recently lost my iPhone and my life has gotten exponentially better as a
[00:35:36.520 --> 00:35:37.520]   result.
[00:35:37.520 --> 00:35:40.560]   I easily keep up with my graduate school work and research goals.
[00:35:40.560 --> 00:35:44.160]   I'm spending more time reading and immersed in my hobbies and am taking better care of
[00:35:44.160 --> 00:35:47.040]   myself by sleeping enough and eating well.
[00:35:47.040 --> 00:35:52.040]   I spend maybe an hour a week on social media on my laptop, but here's the problem.
[00:35:52.040 --> 00:35:54.560]   I've realized that I am profoundly lonely.
[00:35:54.560 --> 00:35:59.640]   I moved across the country away from all my friends from graduate school and now that
[00:35:59.640 --> 00:36:04.160]   I'm not spending hours every day fake socializing on Instagram, I'm actually noticing that loneliness.
[00:36:04.160 --> 00:36:05.160]   Any advice?"
[00:36:05.160 --> 00:36:10.540]   Well, I like this because there's also a little case study hidden in here.
[00:36:10.540 --> 00:36:16.200]   Notice all the fantastic stuff that happened to EM when he lost his iPhone and then later
[00:36:16.200 --> 00:36:21.920]   just changed his social media to something he just does on his laptop one hour a week,
[00:36:21.920 --> 00:36:24.080]   which by the way, you're allowed to do.
[00:36:24.080 --> 00:36:28.240]   And by the way, I make this argument in digital minimalism, but when I talk to adults who
[00:36:28.240 --> 00:36:35.320]   give me a case that they need to be using social media, 95% of the time the things they
[00:36:35.320 --> 00:36:40.440]   say they need to use social media for could be handled in one hour a week on their laptop.
[00:36:40.440 --> 00:36:42.800]   So they use that small number of things.
[00:36:42.800 --> 00:36:48.200]   I need to be on the Facebook group for my running club to justify five hours a day of
[00:36:48.200 --> 00:36:49.200]   scrolling on their phone.
[00:36:49.200 --> 00:36:50.920]   So I really love seeing that.
[00:36:50.920 --> 00:36:57.480]   I love, and I'm going to emphasize what EM got out of this, he easily keeps up with his
[00:36:57.480 --> 00:37:00.240]   work now, makes progress on his research goals.
[00:37:00.240 --> 00:37:03.640]   He reads, he's in hobbies, he sleeps.
[00:37:03.640 --> 00:37:07.320]   All this good stuff happened when he got rid of the phone addiction.
[00:37:07.320 --> 00:37:08.320]   Okay, the loneliness.
[00:37:08.320 --> 00:37:16.000]   Well, this is important because it underscores one of the more insidious side effects or
[00:37:16.000 --> 00:37:21.000]   attractions maybe I should say of our current digital world.
[00:37:21.000 --> 00:37:29.040]   It simulates, these services and apps and devices simulate deep human needs.
[00:37:29.040 --> 00:37:34.640]   Now not in a sort of deep way where it's actually going to satisfy those needs, but just enough
[00:37:34.640 --> 00:37:36.560]   to be alluring, right?
[00:37:36.560 --> 00:37:42.180]   It's like they have evolved to say if we can offer a satisfaction of deep human needs,
[00:37:42.180 --> 00:37:47.420]   that will make us particularly alluring to people and we can become a real part of their
[00:37:47.420 --> 00:37:51.600]   life and therefore harvest their date and eyeballs.
[00:37:51.600 --> 00:37:55.120]   So fake socializing as he talks about it, so being on social media and talking with
[00:37:55.120 --> 00:37:58.640]   people with digital typing back and forth on these various sort of global conversation
[00:37:58.640 --> 00:38:05.180]   platforms, draws on our deep human need for sociality and sort of makes us feel vaguely
[00:38:05.180 --> 00:38:07.720]   speaking like, okay, I guess we're social.
[00:38:07.720 --> 00:38:11.840]   Like in a rational way, we're social, we're talking to people all the time.
[00:38:11.840 --> 00:38:16.380]   But the problem is, and I argue this in detail in Digital Minimalism, it's not actually fulfilling
[00:38:16.380 --> 00:38:21.800]   our need for sociality because the deep parts of our brain isn't seeing another person.
[00:38:21.800 --> 00:38:22.800]   Where is this person?
[00:38:22.800 --> 00:38:23.800]   What do they look like?
[00:38:23.800 --> 00:38:27.520]   When are we sacrificing non-trivial time and attention on their behalf?
[00:38:27.520 --> 00:38:30.200]   So the deep part of our brain is not seeing real human relations.
[00:38:30.200 --> 00:38:33.440]   It's just the rational part of our brain saying, "I'm very social, I'm very social."
[00:38:33.440 --> 00:38:38.220]   And so we're actually very lonely but don't realize it.
[00:38:38.220 --> 00:38:42.720]   And so what we see here is once EM actually took away the fake socialization, he realized,
[00:38:42.720 --> 00:38:44.400]   "Oh, I have been really lonely.
[00:38:44.400 --> 00:38:45.880]   There's not real people in my lives.
[00:38:45.880 --> 00:38:48.960]   I was papering it over.
[00:38:48.960 --> 00:38:50.720]   I was papering it over with this."
[00:38:50.720 --> 00:38:53.600]   There's other needs these fulfill where they do similar things.
[00:38:53.600 --> 00:38:58.620]   For example, we have this drive for competency, to be good at things, because it increases
[00:38:58.620 --> 00:39:02.760]   our status in the community tribe as someone who's useful and valuable, and we build a
[00:39:02.760 --> 00:39:04.280]   lot of meaning on it.
[00:39:04.280 --> 00:39:06.000]   Video games can get in there and toy with that.
[00:39:06.000 --> 00:39:08.240]   "Oh, you're leveling up.
[00:39:08.240 --> 00:39:11.420]   You just killed all the Nazis in this base in Call of Duty.
[00:39:11.420 --> 00:39:12.600]   It plays with that."
[00:39:12.600 --> 00:39:14.080]   So you're like, "Yeah, that's fine.
[00:39:14.080 --> 00:39:15.080]   I'm okay.
[00:39:15.080 --> 00:39:17.200]   I feel like I'm doing enough to feel competent."
[00:39:17.200 --> 00:39:21.320]   But you're not actually doing anything that's building real competence.
[00:39:21.320 --> 00:39:22.320]   There's no real friction.
[00:39:22.320 --> 00:39:26.320]   You're not building up real hard skills in a way that our body recognizes, our communities
[00:39:26.320 --> 00:39:27.320]   recognize.
[00:39:27.320 --> 00:39:28.320]   That comes to haunt you.
[00:39:28.320 --> 00:39:33.320]   And at some point you're like, "Why do I feel so hollow and angry or adrift or isolated?"
[00:39:33.320 --> 00:39:37.120]   It's because I wasn't actually building up a tangible skill that's valuable to the community.
[00:39:37.120 --> 00:39:39.360]   I was pretending to build up a skill.
[00:39:39.360 --> 00:39:41.360]   It simulates that.
[00:39:41.360 --> 00:39:42.360]   It gives you numbers.
[00:39:42.360 --> 00:39:45.440]   You're level six, and you do some button pressing, and now you're level seven.
[00:39:45.440 --> 00:39:48.640]   It sort of simulates it, but it's not really giving you what you need.
[00:39:48.640 --> 00:39:49.740]   So Ian, what should you do?
[00:39:49.740 --> 00:39:55.840]   You have to do old-fashioned, the old-fashioned work of actually building connections.
[00:39:55.840 --> 00:39:59.600]   So join communities and be useful in those communities.
[00:39:59.600 --> 00:40:03.880]   Over time, try to get a leadership position in those communities.
[00:40:03.880 --> 00:40:06.920]   That's a great way to be around people, to feel useful, to feel less lonely, and to feel
[00:40:06.920 --> 00:40:07.920]   connected.
[00:40:07.920 --> 00:40:09.720]   You'll meet people that way as well.
[00:40:09.720 --> 00:40:14.280]   You also have to think about taking regular doses of what I call "vitamin people."
[00:40:14.280 --> 00:40:19.620]   Being around real people in person is necessary for your health.
[00:40:19.620 --> 00:40:25.120]   So it's not about, "Am I in the mood to be social this week?"
[00:40:25.120 --> 00:40:27.440]   Especially if you've been fake socializing, you might have lost that muscle and might
[00:40:27.440 --> 00:40:28.440]   feel very uncomfortable.
[00:40:28.440 --> 00:40:32.680]   It's, "Have I gotten a sufficiently large dose of vitamin people this week?"
[00:40:32.680 --> 00:40:37.160]   You go and you do things, or you invite someone you know or go to something you know to get
[00:40:37.160 --> 00:40:41.760]   that dose of vitamin people, and then over time, as the rewards come from forming these
[00:40:41.760 --> 00:40:45.480]   connections, it's less something you have to sort of force yourself to do, and it's
[00:40:45.480 --> 00:40:47.040]   something that you're really going to want to do.
[00:40:47.040 --> 00:40:51.720]   So yeah, it can be hard work to rebuild your social connection, but it's important, and
[00:40:51.720 --> 00:40:57.320]   I appreciate you highlighting the degree to which social media in particular can obfuscate
[00:40:57.320 --> 00:40:59.020]   the idea that you actually are very lonely.
[00:40:59.020 --> 00:41:00.720]   You just don't realize it.
[00:41:00.720 --> 00:41:04.520]   Let's move on with Fahad.
[00:41:04.520 --> 00:41:10.800]   Fahad says, "You mentioned the following Arnold Bennett quote in some of your books.
[00:41:10.800 --> 00:41:15.880]   One of the chief things which my typical man has to learn is that the mental faculties
[00:41:15.880 --> 00:41:17.840]   are capable of a continuous hard activity.
[00:41:17.840 --> 00:41:19.540]   They do not tire like an arm or a leg.
[00:41:19.540 --> 00:41:21.680]   All they want is change, not rest except in sleep."
[00:41:21.680 --> 00:41:27.640]   Fahad continues his question, "Do you still agree with what it says?
[00:41:27.640 --> 00:41:30.040]   Do we really not need a rest?
[00:41:30.040 --> 00:41:32.280]   Can we work all the time like robots?"
[00:41:32.280 --> 00:41:38.380]   Well, no, we can't work all the time like robots.
[00:41:38.380 --> 00:41:39.380]   That is exhausting.
[00:41:39.380 --> 00:41:41.720]   I talk about this in my book, Slow Productivity.
[00:41:41.720 --> 00:41:43.280]   Particular principle two, work at a natural pace.
[00:41:43.280 --> 00:41:48.120]   We need great variations in effort over different timescales.
[00:41:48.120 --> 00:41:51.340]   But Bennett isn't talking about professional work here.
[00:41:51.340 --> 00:41:56.480]   The argument he's making, and this comes from his book, How to Live on 24 Hours a Day, the
[00:41:56.480 --> 00:42:06.120]   argument he's basically making is you don't need as much like veg-out resting as you think.
[00:42:06.120 --> 00:42:07.920]   That's what sleep is for.
[00:42:07.920 --> 00:42:14.640]   Sleep is for the restorative, "I'm doing nothing and my body is like recharging for the next
[00:42:14.640 --> 00:42:15.640]   day."
[00:42:15.640 --> 00:42:20.920]   He's saying, "With your other time, do stuff that matters, like do interesting high-quality
[00:42:20.920 --> 00:42:21.920]   stuff."
[00:42:21.920 --> 00:42:25.360]   Now, Bennett is actually pretty dismissive of work itself because he was addressing the
[00:42:25.360 --> 00:42:29.920]   sort of newly enlarged London middle class.
[00:42:29.920 --> 00:42:32.840]   They worked downtown and they would take the trains back to their suburbs.
[00:42:32.840 --> 00:42:35.080]   He was like, "Yeah, you got your job, do your job.
[00:42:35.080 --> 00:42:38.960]   All right, when you get home, you have eight hours until you go to bed."
[00:42:38.960 --> 00:42:41.220]   And what he's saying is like, "Don't veg-out.
[00:42:41.220 --> 00:42:44.680]   Do good stuff, like intentional, meaningful stuff at that time.
[00:42:44.680 --> 00:42:47.760]   It's going to energize you instead of exhausting you."
[00:42:47.760 --> 00:42:51.520]   Now his version of vegging out, if you read the book, because this is the early 20th century,
[00:42:51.520 --> 00:42:52.520]   is like drinking.
[00:42:52.520 --> 00:42:54.160]   Like, "Ah, I'm going to drink."
[00:42:54.160 --> 00:42:56.360]   I think he had like playing cards and drinking.
[00:42:56.360 --> 00:42:59.880]   I guess that's their equivalent of like vaping and scrolling social media.
[00:42:59.880 --> 00:43:03.200]   He's like, "No, do meaningful stuff.
[00:43:03.200 --> 00:43:08.320]   Read poetry and think big thoughts and have grand conversations or whatever."
[00:43:08.320 --> 00:43:10.400]   And I think there's truth to that.
[00:43:10.400 --> 00:43:14.520]   I think intentional activity is something that we crave.
[00:43:14.520 --> 00:43:17.660]   It doesn't have to be hard activity.
[00:43:17.660 --> 00:43:21.600]   It doesn't have to be like a real strain.
[00:43:21.600 --> 00:43:28.240]   But being intentional versus, "I'm now going to spend two hours on my phone while Netflix
[00:43:28.240 --> 00:43:31.880]   is playing," he's saying being intentional is going to be better.
[00:43:31.880 --> 00:43:32.880]   It's not going to exhaust you.
[00:43:32.880 --> 00:43:33.880]   It's going to give you energy.
[00:43:33.880 --> 00:43:35.320]   I think that's true.
[00:43:35.320 --> 00:43:40.080]   I think a softer way of thinking about this is in your time outside of work to embrace
[00:43:40.080 --> 00:43:47.320]   what I call the PIG, P-I-G, which is an acronym that stands for being present, being intentional,
[00:43:47.320 --> 00:43:49.940]   and seeking gratitude.
[00:43:49.940 --> 00:43:58.680]   So moment by moment in your after-work time, when you're deciding what to do next, be intentional
[00:43:58.680 --> 00:44:00.440]   about what you choose.
[00:44:00.440 --> 00:44:02.360]   Don't just stumble into something.
[00:44:02.360 --> 00:44:05.080]   Be present while you're doing it.
[00:44:05.080 --> 00:44:08.160]   Don't also be on your phone or only half pay attention.
[00:44:08.160 --> 00:44:09.160]   And seek gratitude.
[00:44:09.160 --> 00:44:10.160]   "Isn't this great?
[00:44:10.160 --> 00:44:11.160]   I really enjoy this.
[00:44:11.160 --> 00:44:12.160]   This is really good."
[00:44:12.160 --> 00:44:16.940]   PIG activities do not have to be mentally trying.
[00:44:16.940 --> 00:44:20.800]   It could be, for example, like watching a dumb movie with your kids.
[00:44:20.800 --> 00:44:24.360]   But if you chose to watch this movie, like we're all going to get together to watch it,
[00:44:24.360 --> 00:44:26.560]   you're present with them and the movie and what's going on.
[00:44:26.560 --> 00:44:30.640]   You find gratitude in being able to watch this movie that you remember from your childhood
[00:44:30.640 --> 00:44:35.080]   and your kids are there and it's like a nice night or whatever.
[00:44:35.080 --> 00:44:36.840]   That is a meaningful activity.
[00:44:36.840 --> 00:44:38.400]   It's not draining.
[00:44:38.400 --> 00:44:39.400]   It's not hard.
[00:44:39.400 --> 00:44:41.860]   You're not getting after it or crushing it.
[00:44:41.860 --> 00:44:44.280]   But it's different than, "I'm just kind of vegging with my phone."
[00:44:44.280 --> 00:44:50.580]   So maybe that's a softer way to think about Bennett is presence, intentionality, and gratitude.
[00:44:50.580 --> 00:44:54.040]   Live on purpose at most times.
[00:44:54.040 --> 00:44:57.140]   Even if what you're doing on purpose is something that's not particularly mentally trying or
[00:44:57.140 --> 00:44:58.140]   difficult.
[00:44:58.140 --> 00:44:59.640]   So anyways, thanks for bringing that up.
[00:44:59.640 --> 00:45:00.640]   And I like that book, actually.
[00:45:00.640 --> 00:45:04.880]   It's one of the first self-help books, "How to Live on 24 Hours a Day."
[00:45:04.880 --> 00:45:07.280]   And we've got a question here from Heather.
[00:45:07.280 --> 00:45:09.880]   "How do you do your research for books and articles?
[00:45:09.880 --> 00:45:13.880]   I find it challenging to sort through all of the information online.
[00:45:13.880 --> 00:45:16.600]   How do you write your books in terms of tools and organizing your thoughts?"
[00:45:16.600 --> 00:45:21.980]   I thought this was an interesting question.
[00:45:21.980 --> 00:45:27.240]   The main point I wanted to respond to here is the reality that the world of available
[00:45:27.240 --> 00:45:29.880]   information is vast.
[00:45:29.880 --> 00:45:33.120]   So like you want to write an article, you want to write a book.
[00:45:33.120 --> 00:45:39.160]   Between other books and other articles and the world of online information, it's endless.
[00:45:39.160 --> 00:45:45.740]   The idea that I'm going to master everything relevant to this topic and somehow organize
[00:45:45.740 --> 00:45:50.160]   it and present it back in my books or my articles is hopeless.
[00:45:50.160 --> 00:45:51.560]   It's quixotic.
[00:45:51.560 --> 00:45:55.840]   So the way a lot of idea writers like myself or critical commentators like myself—so
[00:45:55.840 --> 00:46:01.160]   I write critical commentary and I write idea books—the way we often operate is trying
[00:46:01.160 --> 00:46:06.720]   to create a coherent path through this world.
[00:46:06.720 --> 00:46:09.120]   It's like pattern matching.
[00:46:09.120 --> 00:46:14.440]   These four or five things I've encountered seem to connect together, and if we connect
[00:46:14.440 --> 00:46:19.020]   together right, it makes a coherent path here, or a coherent structure, if you want to use
[00:46:19.020 --> 00:46:23.600]   that metaphor, for one way of seeing some part of our life that allows us to take useful
[00:46:23.600 --> 00:46:26.560]   action or make useful critique.
[00:46:26.560 --> 00:46:30.800]   And the landscape in which this path or structure is built is massive.
[00:46:30.800 --> 00:46:33.960]   The landscape of all relevant ideas and information is massive, and we don't have to get our
[00:46:33.960 --> 00:46:35.480]   arms around all that.
[00:46:35.480 --> 00:46:40.960]   Just here is a coherent path that'll take you from one place to somewhere else useful.
[00:46:40.960 --> 00:46:43.040]   So we often think about that.
[00:46:43.040 --> 00:46:50.160]   You're building a coherent path instead of trying to be comprehensive—coherency over
[00:46:50.160 --> 00:46:53.680]   being comprehensive.
[00:46:53.680 --> 00:46:57.640]   One of the ways we see this violated is you get people that become encyclopedic when they
[00:46:57.640 --> 00:46:59.440]   tackle issues.
[00:46:59.440 --> 00:47:04.360]   Well, there's 15 relevant main issues to this issue that we're trying to face here, and
[00:47:04.360 --> 00:47:10.280]   if we go into sub-issue number three, sub-point four, sub-sub-point A, we see this particular
[00:47:10.280 --> 00:47:14.160]   argument, and then we can contrast that with point seven, sub-point six.
[00:47:14.160 --> 00:47:19.080]   You can get this complicated hierarchy of information that in most instances is just
[00:47:19.080 --> 00:47:22.340]   overwhelming and doesn't help.
[00:47:22.340 --> 00:47:27.920]   The other issue we see when we ignore the reality of coherence versus comprehensiveness
[00:47:27.920 --> 00:47:29.320]   is that people get petrified.
[00:47:29.320 --> 00:47:34.600]   If I build a path over here, what about the landscape over here and over here and over
[00:47:34.600 --> 00:47:38.120]   here and over here, and what if someone is over in that landscape and they will be upset
[00:47:38.120 --> 00:47:41.560]   that my path over here doesn't speak to their particular landscape?
[00:47:41.560 --> 00:47:47.840]   The problem is that's also a quixotic approach as well, because the landscape is vast.
[00:47:47.840 --> 00:47:50.980]   The number of ways to think about it is vast.
[00:47:50.980 --> 00:47:55.000]   The number of different things that people care about most when it comes to a particular
[00:47:55.000 --> 00:48:02.400]   issue is vast, and to try to address or handle everyone, to build a map that covers the entire
[00:48:02.400 --> 00:48:07.400]   space, you're probably not equipped to build that map because most of these other spaces
[00:48:07.400 --> 00:48:11.120]   you've never been to before, so it's not a useful map, and it's much more boring.
[00:48:11.120 --> 00:48:15.520]   I want to go—I'm stretching this metaphor—but I want to go on a nice nature walk now.
[00:48:15.520 --> 00:48:17.920]   I don't need a topographic map of the whole state, right?
[00:48:17.920 --> 00:48:21.160]   So that's the other thing that happens.
[00:48:21.160 --> 00:48:26.200]   This can lead to a sort of incomprehensibility because it's just you're trying to do too
[00:48:26.200 --> 00:48:27.200]   much.
[00:48:27.200 --> 00:48:30.640]   So it's my approach, and a lot of commentators are doing the same.
[00:48:30.640 --> 00:48:35.200]   In this vast space of issues and information and ideas, here is a coherent path that for
[00:48:35.200 --> 00:48:37.640]   a lot of people hopefully is useful.
[00:48:37.640 --> 00:48:42.840]   Add it to your list of particular outings, and that's a huge elaboration of a metaphor
[00:48:42.840 --> 00:48:48.320]   beyond its actual usefulness, but I just want to make that point, Heather, that sometimes
[00:48:48.320 --> 00:48:54.620]   it's okay to just find something useful to say, and then let people integrate that into
[00:48:54.620 --> 00:48:57.840]   the much broader maps they're creating.
[00:48:57.840 --> 00:49:00.480]   All right.
[00:49:00.480 --> 00:49:04.160]   We got a case study here, but I'm going to put an asterisk in front of this.
[00:49:04.160 --> 00:49:07.480]   It's a case study, but it's also a plea for advice.
[00:49:07.480 --> 00:49:10.080]   So it's a useful case study.
[00:49:10.080 --> 00:49:16.440]   It's kind of at first a sad case study, but we're going to at the end give some advice
[00:49:16.440 --> 00:49:18.200]   to help this person.
[00:49:18.200 --> 00:49:22.880]   So we're going to both see an issue be illuminated in detail, and then we can talk about some
[00:49:22.880 --> 00:49:23.880]   advice.
[00:49:23.880 --> 00:49:24.880]   All right.
[00:49:24.880 --> 00:49:29.960]   Our modified case study today comes from Shane.
[00:49:29.960 --> 00:49:34.160]   Shane says, "I'm turning 25 soon, and the reality is starting to hit me.
[00:49:34.160 --> 00:49:38.880]   I have wasted the past eight years of my life scrolling through TikTok and Instagram and
[00:49:38.880 --> 00:49:41.000]   binge-watching Netflix.
[00:49:41.000 --> 00:49:46.880]   My daily social media usage is 15 plus hours, and I'm sleep-deprived due to this.
[00:49:46.880 --> 00:49:50.560]   The longest I can go without scrolling through social media is two days.
[00:49:50.560 --> 00:49:52.440]   I had no goals when I was young.
[00:49:52.440 --> 00:49:56.300]   I just went along with what my friends at the time chose to study in university.
[00:49:56.300 --> 00:49:58.000]   Now they all have successful careers and are getting married.
[00:49:58.000 --> 00:49:59.840]   I fell behind in life.
[00:49:59.840 --> 00:50:03.240]   I dropped out of university two times, but due to my parents forcing me to study, I somehow
[00:50:03.240 --> 00:50:04.680]   managed to complete my degree.
[00:50:04.680 --> 00:50:08.440]   But even when I was in university, I barely attended classes, and teachers called me a
[00:50:08.440 --> 00:50:12.120]   daydreamer because I never focused in class, and I always zoned out.
[00:50:12.120 --> 00:50:17.440]   As for getting a job, I prefer roles that don't necessitate daily attendance in an office
[00:50:17.440 --> 00:50:20.960]   or any consistent regular work schedule.
[00:50:20.960 --> 00:50:25.600]   My introverted personality has led me to isolation as I do not like talking to people, and I'm
[00:50:25.600 --> 00:50:30.160]   also ashamed to meet anyone as I haven't achieved anything.
[00:50:30.160 --> 00:50:33.680]   So I've tried learning various skills in the past three years, such as coding, copywriting,
[00:50:33.680 --> 00:50:37.520]   graphic design, web design, and animation, so I can do freelancing but never succeed
[00:50:37.520 --> 00:50:39.200]   at anything.
[00:50:39.200 --> 00:50:43.440]   When something gets difficult, I just drop it and continue scrolling through social media.
[00:50:43.440 --> 00:50:48.240]   The most I can focus is 10 minutes, or sometimes I go into a flow state for hours, but most
[00:50:48.240 --> 00:50:51.240]   of the time, my mind just goes blank when I try to learn something.
[00:50:51.240 --> 00:50:56.600]   I've watched over hundreds of self-help videos and tried everything I saw on the videos.
[00:50:56.600 --> 00:51:01.480]   From daily planning and specific goals to every piece of advice out there, nothing works.
[00:51:01.480 --> 00:51:04.560]   I know what to learn and the exact steps I need to learn these skills and how I will
[00:51:04.560 --> 00:51:09.320]   use them, but after creating a schedule, I barely follow through, and as I said, my mind
[00:51:09.320 --> 00:51:11.760]   just goes blank when I try to study.
[00:51:11.760 --> 00:51:15.520]   Now I have no idea how to get myself to do something and achieve something.
[00:51:15.520 --> 00:51:20.920]   All right, well, let's start here with a little bit of empathy.
[00:51:20.920 --> 00:51:27.380]   This is sort of the worst-case scenario or a crystallization of people's fears when it
[00:51:27.380 --> 00:51:31.760]   comes to smartphones and social media and young people.
[00:51:31.760 --> 00:51:34.080]   It is not for some people benign.
[00:51:34.080 --> 00:51:40.640]   It is not for some people a way to check on sports rumors and a community that's really
[00:51:40.640 --> 00:51:44.440]   supportive to them as part of an otherwise rich lives.
[00:51:44.440 --> 00:51:51.320]   These devices with these types of services can be incredibly addicting and have damage
[00:51:51.320 --> 00:51:58.240]   to people's lives that counters or is comparable to the damage of any of the more sort of well-known
[00:51:58.240 --> 00:52:02.520]   addictions, and we see that here in this case study.
[00:52:02.520 --> 00:52:04.440]   Now why do they do this?
[00:52:04.440 --> 00:52:08.720]   Well, we have the distraction component, right?
[00:52:08.720 --> 00:52:10.040]   So, like, how does this damage happen?
[00:52:10.040 --> 00:52:11.720]   There's the distraction component.
[00:52:11.720 --> 00:52:14.080]   You're using your phone instead of doing other things that are more valuable, but there's
[00:52:14.080 --> 00:52:17.840]   a deeper issue going on, and I alluded to this earlier in the show, but I'm going to
[00:52:17.840 --> 00:52:20.600]   detail it here more.
[00:52:20.600 --> 00:52:28.260]   These phones simulate deep human needs that were designed to actually drive humans to
[00:52:28.260 --> 00:52:33.720]   do the hard work of becoming a successful, sustainable, proud human being.
[00:52:33.720 --> 00:52:40.120]   It is hard work to become a respectable adult who feels satisfied in life and has a sustainable,
[00:52:40.120 --> 00:52:41.640]   meaningful life.
[00:52:41.640 --> 00:52:43.960]   That is hard work.
[00:52:43.960 --> 00:52:48.840]   Evolution set us up to help us do that hard work by giving us a collection of fundamental
[00:52:48.840 --> 00:52:56.200]   human needs, and they're so compelling that in the pursuit of satisfying these needs,
[00:52:56.200 --> 00:53:00.160]   we will do the hard stuff necessary to become a successful adult.
[00:53:00.160 --> 00:53:08.680]   So these needs include connection, a sense of competency, community standing, and curiosity
[00:53:08.680 --> 00:53:15.560]   slash fear of boredom, among others.
[00:53:15.560 --> 00:53:16.560]   Those needs are very strong.
[00:53:16.560 --> 00:53:21.680]   Trying to satisfy those needs, we end up learning how to socialize, doing the hard work of getting
[00:53:21.680 --> 00:53:26.640]   good at things, trying to become a leader in our community, seeking out interesting
[00:53:26.640 --> 00:53:33.080]   information or productive activity because we really hate being bored, etc.
[00:53:33.080 --> 00:53:39.120]   Modern phones and the apps and services that are on them can simulate fulfilling these
[00:53:39.120 --> 00:53:44.080]   human needs just enough to short-circuit us from actually going after them.
[00:53:44.080 --> 00:53:49.360]   They make us feel just enough connected, just enough competent, just enough part of a community,
[00:53:49.360 --> 00:53:54.280]   and just enough not bored that we don't actually get up off of the couch and do the stuff needed
[00:53:54.280 --> 00:53:57.380]   to become a successful adult.
[00:53:57.380 --> 00:54:07.360]   So by short-circuiting those fundamental human drives, we lose the carrot and the stick that
[00:54:07.360 --> 00:54:16.040]   evolution granted us to prevent what is happening here with Shane from happening in our lives.
[00:54:16.040 --> 00:54:21.880]   That really is the fundamental danger of just unrestricted phone access to a kid, that if
[00:54:21.880 --> 00:54:26.820]   it's satisfying these drives as they gain autonomy as they go through their young adulthood,
[00:54:26.820 --> 00:54:29.920]   they never do the work necessary.
[00:54:29.920 --> 00:54:33.680]   That's really the insidious part, more so than the distraction or the addictiveness.
[00:54:33.680 --> 00:54:38.000]   Because part of the reason why they're so addicting is it becomes our only outlet.
[00:54:38.000 --> 00:54:41.680]   This is Shane's only outlet for satisfying these drives.
[00:54:41.680 --> 00:54:44.960]   We're miserable if our human drives aren't satisfied.
[00:54:44.960 --> 00:54:49.120]   This is his only outlet now because he never developed the hard adult skills necessary
[00:54:49.120 --> 00:54:51.360]   to do this in the way that we're really meant to do it.
[00:54:51.360 --> 00:54:55.280]   So now all he's left with is the devices.
[00:54:55.280 --> 00:54:58.280]   The good news is, Shane, it's recoverable.
[00:54:58.280 --> 00:55:00.040]   Those drives are there.
[00:55:00.040 --> 00:55:05.960]   You just have to learn how to satisfy them in the real-world way that evolution intended.
[00:55:05.960 --> 00:55:10.880]   Your phone will then become less compelling because it's not necessary anymore.
[00:55:10.880 --> 00:55:13.640]   So this is very recoverable.
[00:55:13.640 --> 00:55:16.280]   Now how do we actually do this?
[00:55:16.280 --> 00:55:20.000]   The big argument in part one of the book I'm writing now on the deep life, part one is
[00:55:20.000 --> 00:55:21.000]   called "Prepare."
[00:55:21.000 --> 00:55:26.980]   The big argument is, we jump too quickly into making the big changes in our life.
[00:55:26.980 --> 00:55:29.700]   I want to be like, "Let's get out there, I'm going to be super social and get really good
[00:55:29.700 --> 00:55:31.320]   at things."
[00:55:31.320 --> 00:55:34.960]   But we skip the first part, which is just preparing ourselves to be an eminently qualified
[00:55:34.960 --> 00:55:35.960]   human being.
[00:55:35.960 --> 00:55:38.960]   Just the hard work of learning how to be someone who can do hard things.
[00:55:38.960 --> 00:55:43.600]   Until you've practiced and created yourself into someone who can tackle hard things in
[00:55:43.600 --> 00:55:49.000]   a consistent way, any attempt to just go do something hard is going to fail.
[00:55:49.000 --> 00:55:53.960]   So I'm going to recommend a three-part solution here.
[00:55:53.960 --> 00:55:56.560]   Let's start with discipline.
[00:55:56.560 --> 00:56:00.740]   The ability to do hard things that are valuable that you don't want to in the moment is the
[00:56:00.740 --> 00:56:02.960]   fundamental ability if you're going to transform your life.
[00:56:02.960 --> 00:56:06.440]   You were very bad at this now, that's fine, because it's practiced.
[00:56:06.440 --> 00:56:10.560]   To say you were bad at discipline now is like saying also you're bad at the banjo.
[00:56:10.560 --> 00:56:12.640]   The latter thing wouldn't upset you, because you're like, "Yeah, I've never played the
[00:56:12.640 --> 00:56:15.680]   banjo, but I'm sure I could get better if I practiced."
[00:56:15.680 --> 00:56:17.560]   Well, the same is for discipline.
[00:56:17.560 --> 00:56:20.640]   I would use the discipline ladder technique I talked about in a recent episode where you
[00:56:20.640 --> 00:56:26.920]   start with a really small thing that you do daily, but it's easy, and then you ladder
[00:56:26.920 --> 00:56:29.680]   up to something slightly harder, and then once you get used to that, you ladder up to
[00:56:29.680 --> 00:56:30.680]   something harder.
[00:56:30.680 --> 00:56:36.680]   So you work your way up to increasingly demanding versions of whatever you're working on.
[00:56:36.680 --> 00:56:43.840]   I would run two discipline ladders, one involving health and physical fitness, and one involving
[00:56:43.840 --> 00:56:44.840]   the intellect.
[00:56:44.840 --> 00:56:50.720]   This is probably around working your way up to being able to read interesting, hard books.
[00:56:50.720 --> 00:56:55.120]   So have a ladder you build up towards, which will lead to you getting in good shape, and
[00:56:55.120 --> 00:57:00.720]   a ladder that will lead up to you being able to use your mind and apply it in a consistent,
[00:57:00.720 --> 00:57:06.480]   sustained way, and be exposed to interesting ideas.
[00:57:06.480 --> 00:57:08.200]   Run those ladders concurrently.
[00:57:08.200 --> 00:57:12.960]   This could take three to six months, but it's going to give you a base of discipline we
[00:57:12.960 --> 00:57:13.960]   can now use going forward.
[00:57:13.960 --> 00:57:17.280]   All right, next you've got to organize your life.
[00:57:17.280 --> 00:57:18.280]   Start with capture systems.
[00:57:18.280 --> 00:57:21.760]   Just have a place where you write down all the different stuff you have to do, broken
[00:57:21.760 --> 00:57:24.440]   up by role and status.
[00:57:24.440 --> 00:57:27.820]   Then put away to lightweight morning shutdown routines, so just every morning, a very lightweight
[00:57:27.820 --> 00:57:28.820]   thing you do.
[00:57:28.820 --> 00:57:34.520]   I'm going to glance at these lists and sketch out a plan, put a couple notes down, and a
[00:57:34.520 --> 00:57:38.020]   shutdown routine you do, this should be really centered on, I just want to make sure anything
[00:57:38.020 --> 00:57:43.400]   that came up gets put in those lists, so I'm not remembering anything in my head.
[00:57:43.400 --> 00:57:46.440]   Once you get used to that, ladder that up to something like multi-scale planning.
[00:57:46.440 --> 00:57:49.760]   Then you'll be ready at this point to do something like multi-scale planning.
[00:57:49.760 --> 00:57:52.080]   All right, step three.
[00:57:52.080 --> 00:57:57.240]   Now we're pretty far into 2025 right now, and now we're going to reclaim your brain
[00:57:57.240 --> 00:57:58.240]   from the phone.
[00:57:58.240 --> 00:57:59.840]   I don't want you doing this yet.
[00:57:59.840 --> 00:58:04.760]   Before you have discipline, before you have some organization over your time and obligations,
[00:58:04.760 --> 00:58:08.080]   I don't want you going cold turkey on your phone yet, because it's going to be like going
[00:58:08.080 --> 00:58:10.120]   cold turkey on an alcohol dependency.
[00:58:10.120 --> 00:58:13.760]   You're going to get the DTs, it's going to be dangerous.
[00:58:13.760 --> 00:58:17.920]   But as a third step, you're ready to reclaim your brain, and this is where you're going
[00:58:17.920 --> 00:58:20.720]   to take a 30-day break from optional digital technologies.
[00:58:20.720 --> 00:58:23.840]   I kind of walked through this in my book, Digital Minimalism.
[00:58:23.840 --> 00:58:27.500]   You're going to aggressively explore in-person community opportunities, you're going to aggressively
[00:58:27.500 --> 00:58:32.580]   explore a hobby or skill that teaches you the joys of real competency, you're going
[00:58:32.580 --> 00:58:37.360]   to aggressively look into the world of ideas outside of your phone, it's going to be like
[00:58:37.360 --> 00:58:42.640]   reading or documentaries, and in whatever work you're doing, you're going to aggressively
[00:58:42.640 --> 00:58:47.080]   look at how do I get better at this job, not what do I want this job to offer me, what
[00:58:47.080 --> 00:58:52.000]   can I offer this job, I want to become indispensable so that later I can take control of my career.
[00:58:52.000 --> 00:58:56.320]   You have to get good first before your job gets good.
[00:58:56.320 --> 00:59:01.240]   Journal throughout this whole thing, reflect what's working, what's not.
[00:59:01.240 --> 00:59:06.240]   You'll be ready then to sort of get used to going after these fundamental human needs
[00:59:06.240 --> 00:59:08.360]   without your device.
[00:59:08.360 --> 00:59:12.680]   After 30 days, make very specific rules about what comes back into your digital world and
[00:59:12.680 --> 00:59:14.640]   why and what rules you have for using it.
[00:59:14.640 --> 00:59:19.640]   You'll probably have to repeat this a couple times a year for a while.
[00:59:19.640 --> 00:59:22.720]   So you can come back from all this.
[00:59:22.720 --> 00:59:28.220]   This is not destiny, but it's going to take hard work.
[00:59:28.220 --> 00:59:29.220]   Work your way up slowly.
[00:59:29.220 --> 00:59:32.840]   You're going to have some setbacks, but I absolutely believe in you, Shane, and that's
[00:59:32.840 --> 00:59:33.840]   the advice I would give.
[00:59:33.840 --> 00:59:36.080]   I just pointed to multiple books and multiple past episodes.
[00:59:36.080 --> 00:59:40.120]   You're going to have to dive into all of those as well to really understand what I'm saying.
[00:59:40.120 --> 00:59:43.020]   But I will say clearly, this is recoverable.
[00:59:43.020 --> 00:59:45.640]   You can figure out how to actually be an eminently qualified human being.
[00:59:45.640 --> 00:59:47.800]   This is going to take some work.
[00:59:47.800 --> 00:59:50.520]   Now is a good time to do it.
[00:59:50.520 --> 00:59:53.360]   All right.
[00:59:53.360 --> 01:00:07.200]   And now we're at the Slow Productivity Corner question.
[01:00:07.200 --> 01:00:08.520]   The Slow Productivity Corner question.
[01:00:08.520 --> 01:00:12.520]   We do one question a week that relates to my new book, "Slow Productivity, the Lost
[01:00:12.520 --> 01:00:14.400]   Art of Accomplishment Without Burnout."
[01:00:14.400 --> 01:00:15.400]   All right.
[01:00:15.400 --> 01:00:19.920]   Today's Slow Productivity Corner question of the week comes from...
[01:00:19.920 --> 01:00:20.920]   Oh, I don't have a name.
[01:00:20.920 --> 01:00:21.920]   That's a cool question.
[01:00:21.920 --> 01:00:22.920]   All right.
[01:00:22.920 --> 01:00:30.560]   It says, "How does Faustina Lente compare to the Tanias Longer Shorter Way?
[01:00:30.560 --> 01:00:35.080]   Sounds quite similar, and I like finding a source for the essence of this wisdom in Torah."
[01:00:35.080 --> 01:00:36.980]   All right.
[01:00:36.980 --> 01:00:41.520]   So we got to do a little bit of scholarship here.
[01:00:41.520 --> 01:00:48.880]   Faustina Lente is this Roman phrase, "Make haste slowly," which I talk about in my book,
[01:00:48.880 --> 01:00:54.080]   "Slow Productivity," because it ties to the second principle of slow productivity, which
[01:00:54.080 --> 01:00:57.120]   is to work at a natural pace.
[01:00:57.120 --> 01:01:00.000]   So make haste slowly.
[01:01:00.000 --> 01:01:05.320]   What it's capturing is you're sort of relentlessly and systematically moving towards a goal,
[01:01:05.320 --> 01:01:07.560]   but doing it carefully and slowly.
[01:01:07.560 --> 01:01:09.240]   All right.
[01:01:09.240 --> 01:01:15.040]   The Longer Short Way, which is a Jewish concept, I didn't know about until this question, so
[01:01:15.040 --> 01:01:20.560]   I did a little bit of research, and as anyone who knows anything about serious Talmudic
[01:01:20.560 --> 01:01:25.080]   study knows, 20 minutes of Internet research is all it takes to master these concepts.
[01:01:25.080 --> 01:01:26.600]   I'm being sarcastic.
[01:01:26.600 --> 01:01:31.600]   I'm apologizing in advance to all of the rabbis who are about to say, "Oh, you're getting
[01:01:31.600 --> 01:01:32.600]   this completely wrong."
[01:01:32.600 --> 01:01:39.140]   But let me give you my understanding of the Longer Short Way concept.
[01:01:39.140 --> 01:01:45.040]   It comes from a story from Talmud.
[01:01:45.040 --> 01:01:48.760]   For those who don't know, Talmud is the combination of the Mishnah, the oral law of Judaism, combined
[01:01:48.760 --> 01:01:53.540]   with commentary known as the Gemara in just sort of one book, etc., etc.
[01:01:53.540 --> 01:01:57.760]   It's old, and it's something that is studied in Judaism.
[01:01:57.760 --> 01:02:02.960]   So I found, using Internet searches, the story from Talmud from which this concept comes
[01:02:02.960 --> 01:02:09.400]   from, and then we're going to say, "Does this give us more insight on slow productivity?"
[01:02:09.400 --> 01:02:10.920]   Here's the story.
[01:02:10.920 --> 01:02:17.720]   Said Rabbi Yeshua ben Shania, "Once a child got the better of me.
[01:02:17.720 --> 01:02:21.040]   I was traveling, and I met with a child at a crossroads.
[01:02:21.040 --> 01:02:23.160]   I asked him, 'Which way to the city?'
[01:02:23.160 --> 01:02:28.280]   And he answered, 'This way is short and long, and this way is long and short.'
[01:02:28.280 --> 01:02:29.920]   I took the short and long way.
[01:02:29.920 --> 01:02:34.720]   I soon reached the city, but found my approach obstructed by gardens and orchards.
[01:02:34.720 --> 01:02:38.480]   So I retraced my steps and said to the child, 'My son, did you not tell me that this is
[01:02:38.480 --> 01:02:39.480]   the short way?'
[01:02:39.480 --> 01:02:43.040]   Answered the child, 'Did I not tell you that it is also long?'"
[01:02:43.040 --> 01:02:53.680]   All right, so this story has a lot of interpretations, in particular, I believe, maybe in Hasidic
[01:02:53.680 --> 01:02:54.680]   tradition.
[01:02:54.680 --> 01:02:55.680]   There's a book about it.
[01:02:55.680 --> 01:02:57.960]   There's a rabbi that's done a lot of glosses on it.
[01:02:57.960 --> 01:03:02.960]   But the simple version, as best as I could tell from my 20 minutes of internet searching,
[01:03:02.960 --> 01:03:07.520]   what's being said here is the long-short way, so the path pointed out by the child that
[01:03:07.520 --> 01:03:13.680]   is long but short, is sometimes the most direct way to get to an important goal.
[01:03:13.680 --> 01:03:21.280]   It is a long path of intentional steady effort is sometimes the shortest way, the best way
[01:03:21.280 --> 01:03:23.720]   overall to get to a goal.
[01:03:23.720 --> 01:03:26.960]   By contrast, a short-long way where you think you're taking a shortcut, but it ends up being
[01:03:26.960 --> 01:03:29.260]   very long.
[01:03:29.260 --> 01:03:35.200]   So in Jewish tradition, as far as I understand, this is often applied to Torah study, to get
[01:03:35.200 --> 01:03:38.760]   to the goal of connection to God.
[01:03:38.760 --> 01:03:45.400]   Actually the shortest path there is a long commitment to studying Torah.
[01:03:45.400 --> 01:03:49.360]   Long path of steady intentional effort is sometimes the shortest way to a goal.
[01:03:49.360 --> 01:03:51.880]   That's a cool concept.
[01:03:51.880 --> 01:03:58.280]   I think that is very similar to Festina Lente, and I think it's a nice way of capturing some
[01:03:58.280 --> 01:04:02.200]   of the core ideas of working at a natural pace.
[01:04:02.200 --> 01:04:05.400]   The shortest path somewhere is sometimes long.
[01:04:05.400 --> 01:04:10.720]   That's okay because once you recognize that, you can chill out and start doing the daily
[01:04:10.720 --> 01:04:13.760]   or weekly or whatever pace you're working at.
[01:04:13.760 --> 01:04:17.720]   Do the stuff that matters and let it pile up.
[01:04:17.720 --> 01:04:18.720]   The path is long.
[01:04:18.720 --> 01:04:25.000]   So to make it sustainable, do the right stuff at a reasonable pace, so the long, the longer
[01:04:25.000 --> 01:04:26.080]   short way.
[01:04:26.080 --> 01:04:27.120]   I like that phrase.
[01:04:27.120 --> 01:04:31.920]   I'm going to add that to my lexicon of slow productivity related ancient wisdom.
[01:04:31.920 --> 01:04:32.920]   So thank you for sending that in.
[01:04:32.920 --> 01:04:39.080]   All right, speaking of wisdom, I want to go over the books I read in November.
[01:04:39.080 --> 01:04:41.560]   But first, let's hear from some of our sponsors.
[01:04:41.560 --> 01:04:45.760]   So I want to talk in particular about our friends at Cozy Earth.
[01:04:45.760 --> 01:04:48.100]   Oh, I am a huge Cozy Earth fan.
[01:04:48.100 --> 01:04:49.880]   You know this.
[01:04:49.880 --> 01:04:53.160]   You know my wife and I love the Cozy Earth sheets.
[01:04:53.160 --> 01:04:58.840]   Their bamboo sheet set is the ultimate gift this holiday season, elevating everyday luxury
[01:04:58.840 --> 01:05:00.860]   into something everyone will use and absolutely adore.
[01:05:00.860 --> 01:05:01.860]   We adore it.
[01:05:01.860 --> 01:05:03.960]   They are incredibly soft.
[01:05:03.960 --> 01:05:04.960]   They're cool.
[01:05:04.960 --> 01:05:05.960]   They're temperature regulating.
[01:05:05.960 --> 01:05:09.400]   We own multiple pairs of these so that when we're washing one pair of these sheets, we
[01:05:09.400 --> 01:05:10.800]   have another pair to put on.
[01:05:10.800 --> 01:05:12.840]   We travel with them.
[01:05:12.840 --> 01:05:13.840]   We go away for the summer.
[01:05:13.840 --> 01:05:16.280]   We bring our Cozy Earth sheets with them.
[01:05:16.280 --> 01:05:17.520]   They are just incredibly comfortable.
[01:05:17.520 --> 01:05:19.280]   I love them.
[01:05:19.280 --> 01:05:21.160]   Cozy Earth is not just about sheets as well.
[01:05:21.160 --> 01:05:24.080]   They have other things such as pajamas.
[01:05:24.080 --> 01:05:25.840]   My wife has the Cozy Earth pajamas.
[01:05:25.840 --> 01:05:27.760]   I have the Cozy Earth sweatshirt.
[01:05:27.760 --> 01:05:29.480]   We have the Cozy Earth towels.
[01:05:29.480 --> 01:05:33.320]   They just make really comfortable stuff.
[01:05:33.320 --> 01:05:38.760]   And once we became addicts for the sheets, we began, "Oh, we have the duvet cover."
[01:05:38.760 --> 01:05:41.000]   It's comfortable stuff.
[01:05:41.000 --> 01:05:44.560]   I really do love the Cozy Earth stuff, especially the bamboo sheet set.
[01:05:44.560 --> 01:05:47.600]   Their goal is to help you create a sanctuary within your home, a refuge from the demand
[01:05:47.600 --> 01:05:49.580]   of the outside world.
[01:05:49.580 --> 01:05:52.560]   They understand the significance of finding comfort and tranquility in the midst of our
[01:05:52.560 --> 01:05:53.920]   hectic lives.
[01:05:53.920 --> 01:05:58.280]   Your five to nine should consist of relaxation, rejuvenation, unwinding, and embracing a sense
[01:05:58.280 --> 01:05:59.280]   of calm.
[01:05:59.280 --> 01:06:02.400]   With Cozy Earth, you can transform your space into an elevated haven when serenity and renewal
[01:06:02.400 --> 01:06:04.400]   intertwine effortlessly.
[01:06:04.400 --> 01:06:07.560]   I think this is a great gift, idea.
[01:06:07.560 --> 01:06:11.000]   If not for someone else, make this your gift for yourself this season.
[01:06:11.000 --> 01:06:15.080]   I want to go into the new year with sheets or pajamas or whatever that are super comfortable.
[01:06:15.080 --> 01:06:17.600]   They all come with a 10-year warranty.
[01:06:17.600 --> 01:06:20.800]   That's how much they believe in them, and they have a lot of responsible production
[01:06:20.800 --> 01:06:21.800]   practices, etc.
[01:06:21.800 --> 01:06:27.200]   All right, so if you want your Cozy Earth pajamas by Christmas, you need to order by
[01:06:27.200 --> 01:06:31.080]   December 13th to get free shipping.
[01:06:31.080 --> 01:06:32.080]   Missed it?
[01:06:32.080 --> 01:06:35.640]   You can still get expedited shipping until December 20th to ensure it arrives in time.
[01:06:35.640 --> 01:06:37.520]   You can get your Cozy Earth sheets for someone else.
[01:06:37.520 --> 01:06:38.520]   You've got time.
[01:06:38.520 --> 01:06:42.300]   If you're doing them for yourself, well, do that soon as well.
[01:06:42.300 --> 01:06:43.300]   So don't wait.
[01:06:43.300 --> 01:06:49.280]   Head to CozyEarth.com/Deep now and use my exclusive code "Deep" for up to 40% off.
[01:06:49.280 --> 01:06:50.360]   You want that discount.
[01:06:50.360 --> 01:06:54.880]   So remember, CozyEarth.com/Deep and use the code "Deep."
[01:06:54.880 --> 01:06:56.480]   Give the gift a luxury this holiday season.
[01:06:56.480 --> 01:06:58.640]   That's CozyEarth.com/Deep.
[01:06:58.640 --> 01:07:03.260]   If you get a post-purchase survey, this is like a request from me, say you heard about
[01:07:03.260 --> 01:07:05.360]   Cozy Earth from Deep Questions podcast.
[01:07:05.360 --> 01:07:08.380]   If you select it from the list in that survey, if one comes up, it really helps me.
[01:07:08.380 --> 01:07:12.600]   I also want to talk about our friends at My Body Tutor.
[01:07:12.600 --> 01:07:13.600]   We come out of the holidays.
[01:07:13.600 --> 01:07:14.600]   We have Thanksgiving.
[01:07:14.600 --> 01:07:20.320]   We got like Christmas or all the other holidays in December, and you sometimes feel as if
[01:07:20.320 --> 01:07:21.320]   you've been eating a lot.
[01:07:21.320 --> 01:07:22.720]   You've been sitting around on the couch a lot.
[01:07:22.720 --> 01:07:23.720]   It's dark.
[01:07:23.720 --> 01:07:24.720]   You're not outside enough.
[01:07:24.720 --> 01:07:26.860]   You're not feeling healthy.
[01:07:26.860 --> 01:07:28.320]   You have your New Year's resolutions pending.
[01:07:28.320 --> 01:07:29.320]   I want to get in better shape.
[01:07:29.320 --> 01:07:31.000]   Well, let me tell you how to do it.
[01:07:31.000 --> 01:07:33.100]   My Body Tutor.
[01:07:33.100 --> 01:07:38.520]   My Body Tutor, which is founded by Adam Gilbert, who I've known forever, is a 100% online
[01:07:38.520 --> 01:07:43.540]   coaching problem that solves the biggest problem in health and fitness, which is lack of consistency.
[01:07:43.540 --> 01:07:47.320]   They do this by simplifying the process of getting healthier in the practical sustainable
[01:07:47.320 --> 01:07:53.000]   behaviors and then letting you check in and work with your coach online every day to actually
[01:07:53.000 --> 01:07:58.200]   be accountable and to make the sort of flexible changes you need as life comes at you.
[01:07:58.200 --> 01:08:01.880]   That's why My Body Tutor works, because you're working with someone else.
[01:08:01.880 --> 01:08:05.480]   They help you come up with your diet plan, help you come up with your exercise plan,
[01:08:05.480 --> 01:08:07.200]   and then you check in with them about how it's going.
[01:08:07.200 --> 01:08:08.200]   They hold you accountable.
[01:08:08.200 --> 01:08:12.240]   When you travel for Christmas, they say, "What changes are we going to make, for example,
[01:08:12.240 --> 01:08:14.760]   so that you don't fall too much off your plan?
[01:08:14.760 --> 01:08:15.760]   You don't have a gym.
[01:08:15.760 --> 01:08:16.760]   What exercises should you do?"
[01:08:16.760 --> 01:08:22.140]   So they help you adapt as well, and because it's 100% online, it is much cheaper than
[01:08:22.140 --> 01:08:27.080]   having to work with a nutritionist or a trainer in your gym in person.
[01:08:27.080 --> 01:08:32.240]   So now is the time to finally fulfill your wish of getting healthier, and I recommend
[01:08:32.240 --> 01:08:34.560]   My Body Tutor as a great way to do that.
[01:08:34.560 --> 01:08:38.100]   Just go to MyBodyTutor.com, T-U-T-O-R.
[01:08:38.100 --> 01:08:42.720]   Mention deep questions when you sign up, and Adam will give you $50 off your first month.
[01:08:42.720 --> 01:08:45.300]   MyBodyTutor.com and mention deep questions.
[01:08:45.300 --> 01:08:48.760]   All right, let's move on now to books.
[01:08:48.760 --> 01:08:57.060]   All right, I try to read five books a month and then report back at the first or second
[01:08:57.060 --> 01:08:59.040]   podcast of each month what I read the month before.
[01:08:59.040 --> 01:09:01.260]   So we're in December now.
[01:09:01.260 --> 01:09:05.960]   What books did I read in November 2024?
[01:09:05.960 --> 01:09:08.200]   First I read Gaining Ground by Forrest Pritchard.
[01:09:08.200 --> 01:09:10.000]   It's a cool memoir.
[01:09:10.000 --> 01:09:14.680]   It's a memoir of Forrest, went back to his family farm and took it over.
[01:09:14.680 --> 01:09:16.560]   He's over in Shenandoah, not far from here.
[01:09:16.560 --> 01:09:20.520]   He sells at the Tacoma Park Farmer's Market, so I love crossing paths with him.
[01:09:20.520 --> 01:09:21.520]   And I enjoyed it.
[01:09:21.520 --> 01:09:26.320]   It's like a good memoir of someone learning and embracing the farming life.
[01:09:26.320 --> 01:09:30.200]   Another memoir I read—I guess I was in a memoir mood this month, I'm realizing this—I
[01:09:30.200 --> 01:09:32.840]   read Little Chapel on the River by Gwendolyn Bounds.
[01:09:32.840 --> 01:09:35.560]   I like Gwendolyn Bounds' writing.
[01:09:35.560 --> 01:09:39.360]   Earlier this year I read that great book she wrote about not too late, about people in
[01:09:39.360 --> 01:09:43.280]   middle age taking on difficult physical goals.
[01:09:43.280 --> 01:09:47.800]   Little Chapel on the River is about her moving from New York in the wake of 9/11 to a small
[01:09:47.800 --> 01:09:53.360]   town on the Hudson River Valley and how she got really involved in this old, small pub
[01:09:53.360 --> 01:09:57.480]   on the river in this town and getting involved in the life of the people at the pub.
[01:09:57.480 --> 01:10:00.940]   And she's a great writer and it's a great book.
[01:10:00.940 --> 01:10:02.400]   It wasn't what I thought it was.
[01:10:02.400 --> 01:10:04.900]   This is my fault, not Gwendolyn's.
[01:10:04.900 --> 01:10:08.960]   I came into this thinking, "I really want to hear about what it's like moving upstate
[01:10:08.960 --> 01:10:16.080]   from a city, the life in the countryside and the slowness," because that's very aspirational.
[01:10:16.080 --> 01:10:21.520]   It really was about this bar and the people in the bar, and it's very touching, the relationships
[01:10:21.520 --> 01:10:25.180]   she made with these people, but it was like the vignettes of this.
[01:10:25.180 --> 01:10:26.560]   It ended up being a very affecting book.
[01:10:26.560 --> 01:10:29.160]   It wasn't what I thought, but I ended up enjoying it.
[01:10:29.160 --> 01:10:33.560]   I also read Lost in Thought by Zena Hitz.
[01:10:33.560 --> 01:10:37.320]   This I thought was going to be a memoir.
[01:10:37.320 --> 01:10:42.880]   She studied at St. John's in Annapolis, the great books program there, and was a successful
[01:10:42.880 --> 01:10:46.520]   academic but left the track and went to what was essentially a monastery.
[01:10:46.520 --> 01:10:50.600]   I thought this book was going to be about her recommitting to a life of the mind.
[01:10:50.600 --> 01:10:53.280]   It's not really about her, though, after the beginning.
[01:10:53.280 --> 01:10:59.280]   It's just more of a polemic about the value of the life of the mind, the sort of standalone
[01:10:59.280 --> 01:11:03.880]   value of a life that's dedicated to embracing and engaging thoughts.
[01:11:03.880 --> 01:11:06.900]   So once I adjusted that that's what this was really about, there are some really good arguments
[01:11:06.900 --> 01:11:09.280]   in there.
[01:11:09.280 --> 01:11:12.280]   I read it because I'm thinking about one day writing this book in defense of thinking,
[01:11:12.280 --> 01:11:14.160]   and she's kind of doing something like that.
[01:11:14.160 --> 01:11:20.560]   So if you want a sort of muscular argument in favor of hard books and ideas as having
[01:11:20.560 --> 01:11:25.240]   intrinsic value, Lost in Thought will give that to you.
[01:11:25.240 --> 01:11:30.240]   I then was, I guess, the last person left to read Outlived by Peter Atiyah.
[01:11:30.240 --> 01:11:33.760]   I had done an event with Peter and he had given me a copy of his book, and I read it
[01:11:33.760 --> 01:11:36.340]   on the way home.
[01:11:36.340 --> 01:11:38.200]   It was much better than I thought.
[01:11:38.200 --> 01:11:42.640]   It's interesting because there's a lot of Peter in this book, and basically his trajectory
[01:11:42.640 --> 01:11:49.600]   was "I used to be super fiddly optimized, like exactly this diet and exactly this supplement,"
[01:11:49.600 --> 01:11:53.480]   and he sort of matured and was like, "No, no, no.
[01:11:53.480 --> 01:11:54.840]   Different people respond to things differently.
[01:11:54.840 --> 01:11:57.040]   Let's get to the big ideas that really matter."
[01:11:57.040 --> 01:12:04.960]   I mean, it was a more medically rigorous and less bro-science-y than you're going to expect.
[01:12:04.960 --> 01:12:10.800]   It's a really good argument for what matters for longevity and what it looks like to actually
[01:12:10.800 --> 01:12:12.240]   prioritize in your life.
[01:12:12.240 --> 01:12:13.920]   It's affected me in various ways.
[01:12:13.920 --> 01:12:14.920]   It's well written.
[01:12:14.920 --> 01:12:21.560]   No wonder it sold, and I'm checking the official list here, all the copies because it's a very
[01:12:21.560 --> 01:12:22.560]   good book.
[01:12:22.560 --> 01:12:26.240]   And again, it's more general and less in the weeds than you might imagine.
[01:12:26.240 --> 01:12:28.240]   So I'm glad I read that.
[01:12:28.240 --> 01:12:34.260]   Finally I read We Have Never Been Woke by Musa al-Gharbi, who's an assistant professor
[01:12:34.260 --> 01:12:36.280]   sociologist at Stony Brook.
[01:12:36.280 --> 01:12:38.960]   That's probably my favorite book of the month.
[01:12:38.960 --> 01:12:43.560]   I love books like this where you have a young academic throwing bombs.
[01:12:43.560 --> 01:12:45.340]   He just comes into the building.
[01:12:45.340 --> 01:12:49.380]   He looks at the people around him and is like, "I've got something to say," and he's making
[01:12:49.380 --> 01:12:55.240]   a big argument, and it's a bold argument, and he does it confidently, and it is very
[01:12:55.240 --> 01:12:58.360]   timely and very convincing.
[01:12:58.360 --> 01:13:00.400]   It's not saying something like, "Oh, we all are thinking this."
[01:13:00.400 --> 01:13:02.200]   He's just taking his term saying it.
[01:13:02.200 --> 01:13:04.420]   It's surprising.
[01:13:04.420 --> 01:13:05.980]   It's the type of intellectual books I love.
[01:13:05.980 --> 01:13:11.480]   It's an intellectual experience, and I thought it was an exciting, fun book to read.
[01:13:11.480 --> 01:13:14.040]   Man, he's got some courage, too.
[01:13:14.040 --> 01:13:17.840]   He's basically looking around at all of his fellow academics and other what he calls the
[01:13:17.840 --> 01:13:23.260]   symbolic capitalists, but sort of the technocratic elite of U.S. culture, and just saying, "Hey,
[01:13:23.260 --> 01:13:28.300]   all this woke stuff, this is like you guys playing internal status games.
[01:13:28.300 --> 01:13:32.160]   It's about you trying to justify yourselves and your position, and it allows you to ignore
[01:13:32.160 --> 01:13:36.000]   or put down people who have it worse off than you and still feel good about it."
[01:13:36.000 --> 01:13:40.160]   He's pretty compelling about it, and it's a fantastic, exciting intellectual journey.
[01:13:40.160 --> 01:13:44.640]   You might not agree with all of it, but you'll learn a lot, and there's an energy to it which
[01:13:44.640 --> 01:13:45.760]   you don't always see in these books.
[01:13:45.760 --> 01:13:47.680]   All right, so that's all I've got for today.
[01:13:47.680 --> 01:13:53.160]   We'll be back next week, hopefully, if everything goes well with what I'm up to, with Jesse.
[01:13:53.160 --> 01:13:54.160]   I promise.
[01:13:54.160 --> 01:13:55.160]   Jesse's coming back.
[01:13:55.160 --> 01:13:56.160]   I can't wait for that.
[01:13:56.160 --> 01:14:02.760]   Until then, as always, stay deep.

