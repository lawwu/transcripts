
[00:00:00.280 --> 00:00:02.280]   - Welcome to the Huberman Lab Podcast,
[00:00:02.280 --> 00:00:04.880]   where we discuss science and science-based tools
[00:00:04.880 --> 00:00:05.900]   for everyday life.
[00:00:05.900 --> 00:00:10.240]   I'm Andrew Huberman,
[00:00:10.240 --> 00:00:13.020]   and I'm a professor of neurobiology and ophthalmology
[00:00:13.020 --> 00:00:14.920]   at Stanford School of Medicine.
[00:00:14.920 --> 00:00:17.160]   Today, my guest is Dr. David Berson,
[00:00:17.160 --> 00:00:19.480]   professor of medical science, neurobiology,
[00:00:19.480 --> 00:00:22.240]   and ophthalmology at Brown University.
[00:00:22.240 --> 00:00:24.020]   Dr. Berson's laboratory is credited
[00:00:24.020 --> 00:00:25.960]   with discovering the cells in the eye
[00:00:25.960 --> 00:00:28.180]   that set your circadian rhythms.
[00:00:28.180 --> 00:00:30.080]   These are the so-called intrinsically
[00:00:30.080 --> 00:00:32.020]   photosensitive melanopsin cells,
[00:00:32.020 --> 00:00:33.720]   and while that's a mouthful,
[00:00:33.720 --> 00:00:36.140]   all you need to know for sake of this introduction
[00:00:36.140 --> 00:00:38.760]   is that those are the cells that inform your brain and body
[00:00:38.760 --> 00:00:40.560]   about the time of day.
[00:00:40.560 --> 00:00:42.480]   Dr. Berson's laboratory has also made
[00:00:42.480 --> 00:00:44.240]   a number of other important discoveries
[00:00:44.240 --> 00:00:47.880]   about how we convert our perceptions of the outside world
[00:00:47.880 --> 00:00:50.080]   into motor action.
[00:00:50.080 --> 00:00:53.240]   More personally, Dr. Berson has been my go-to resource
[00:00:53.240 --> 00:00:57.160]   for all things neuroscience for nearly two decades.
[00:00:57.160 --> 00:01:00.180]   I knew of his reputation as a spectacular researcher
[00:01:00.180 --> 00:01:01.500]   for a long period of time,
[00:01:01.500 --> 00:01:05.080]   and then many years ago, I cold called him out of the blue.
[00:01:05.080 --> 00:01:08.220]   I basically corralled him into a long conversation
[00:01:08.220 --> 00:01:10.920]   over the phone after which he invited me out to Brown,
[00:01:10.920 --> 00:01:13.020]   and we've been discussing neuroscience
[00:01:13.020 --> 00:01:16.700]   and how the brain works and the emerging new technologies
[00:01:16.700 --> 00:01:19.440]   and the emerging new concepts in neuroscience
[00:01:19.440 --> 00:01:22.020]   for a very long time now.
[00:01:22.020 --> 00:01:23.100]   You're going to realize today
[00:01:23.100 --> 00:01:25.600]   why Dr. Berson is my go-to source.
[00:01:25.600 --> 00:01:29.260]   He has an exceptionally clear and organized view
[00:01:29.260 --> 00:01:31.360]   of how the nervous system works.
[00:01:31.360 --> 00:01:33.520]   Now, there are many, many parts of the nervous system,
[00:01:33.520 --> 00:01:36.420]   different nuclei and connections and circuits and chemicals
[00:01:36.420 --> 00:01:39.180]   and so forth, but it takes a special kind of person
[00:01:39.180 --> 00:01:41.240]   to be able to organize that information
[00:01:41.240 --> 00:01:43.860]   into a structured and logical framework
[00:01:43.860 --> 00:01:46.980]   that can allow us to make sense of how we function
[00:01:46.980 --> 00:01:49.140]   in terms of what we feel, what we experience,
[00:01:49.140 --> 00:01:51.020]   how we move through the world.
[00:01:51.020 --> 00:01:54.040]   Dr. Berson is truly one of a kind in his ability
[00:01:54.040 --> 00:01:57.380]   to synthesize and organize and communicate that information,
[00:01:57.380 --> 00:02:00.100]   and I give him credit as one of my mentors
[00:02:00.100 --> 00:02:02.260]   and one of the people that I respect most
[00:02:02.260 --> 00:02:05.220]   in the field of science and medical science generally.
[00:02:05.220 --> 00:02:07.580]   Today, Dr. Berson takes us on a journey
[00:02:07.580 --> 00:02:09.340]   from the periphery of the nervous system,
[00:02:09.340 --> 00:02:12.720]   meaning from the outside, deep into the nervous system,
[00:02:12.720 --> 00:02:16.660]   layer by layer, structure by structure, circuit by circuit,
[00:02:16.660 --> 00:02:19.540]   making clear to us how each of these individual circuits
[00:02:19.540 --> 00:02:22.420]   work and how they work together as a whole.
[00:02:22.420 --> 00:02:24.480]   It's a really magnificent description
[00:02:24.480 --> 00:02:27.420]   that you simply cannot get from any textbook,
[00:02:27.420 --> 00:02:30.280]   from any popular book, and frankly, as far as I know,
[00:02:30.280 --> 00:02:33.120]   from any podcast that currently exists out there.
[00:02:33.120 --> 00:02:34.880]   So it's a real gift to have this opportunity
[00:02:34.880 --> 00:02:36.540]   to learn from Dr. Berson.
[00:02:36.540 --> 00:02:39.340]   Again, I consider him my mentor in the field
[00:02:39.340 --> 00:02:41.420]   of learning and teaching neuroscience,
[00:02:41.420 --> 00:02:43.780]   and I'm excited for you to learn from him.
[00:02:43.780 --> 00:02:46.680]   One thing is for certain, by the end of this podcast,
[00:02:46.680 --> 00:02:49.560]   you will know far more about how your nervous system works
[00:02:49.560 --> 00:02:51.620]   than the vast majority of people out there,
[00:02:51.620 --> 00:02:55.320]   including many expert biologists and neuroscientists.
[00:02:55.320 --> 00:02:58.020]   Before we begin, I'd like to emphasize that this podcast
[00:02:58.020 --> 00:03:00.940]   is separate from my teaching and research roles at Stanford.
[00:03:00.940 --> 00:03:02.880]   It is, however, part of my desire and effort
[00:03:02.880 --> 00:03:05.460]   to bring zero cost to consumer information about science
[00:03:05.460 --> 00:03:08.220]   and science-related tools to the general public.
[00:03:08.220 --> 00:03:09.220]   In keeping with that theme,
[00:03:09.220 --> 00:03:12.000]   I'd like to thank the sponsors of today's podcast.
[00:03:12.000 --> 00:03:14.260]   Our first sponsor is Athletic Greens.
[00:03:14.260 --> 00:03:15.860]   Athletic Greens is an all-in-one
[00:03:15.860 --> 00:03:18.300]   vitamin mineral probiotic drink.
[00:03:18.300 --> 00:03:21.500]   I've been taking Athletic Greens every day since 2012,
[00:03:21.500 --> 00:03:23.900]   so I'm delighted that they're sponsoring the podcast.
[00:03:23.900 --> 00:03:25.700]   The reason I started taking Athletic Greens
[00:03:25.700 --> 00:03:27.660]   and the reason I still take Athletic Greens
[00:03:27.660 --> 00:03:29.740]   is that it covers all of my vitamin mineral
[00:03:29.740 --> 00:03:31.480]   and probiotic needs.
[00:03:31.480 --> 00:03:33.560]   Nowadays, there's a lot of data out there
[00:03:33.560 --> 00:03:36.240]   pointing to the fact that a healthy gut microbiome,
[00:03:36.240 --> 00:03:38.280]   literally little microbes that live in our gut
[00:03:38.280 --> 00:03:40.700]   that are good for us, is important to support
[00:03:40.700 --> 00:03:43.620]   our immune system, our nervous system, our endocrine system,
[00:03:43.620 --> 00:03:46.940]   and various aspects of our immediate and long-term health.
[00:03:46.940 --> 00:03:47.780]   With Athletic Greens,
[00:03:47.780 --> 00:03:49.820]   I get all the vitamins and minerals that I need,
[00:03:49.820 --> 00:03:53.540]   plus the probiotics ensure a healthy gut microbiome.
[00:03:53.540 --> 00:03:54.620]   It also tastes really good.
[00:03:54.620 --> 00:03:56.900]   I mix mine up with some water, a little bit of lemon juice.
[00:03:56.900 --> 00:03:58.240]   I'll have that early in the day
[00:03:58.240 --> 00:04:00.740]   and sometimes a second time later in the day as well.
[00:04:00.740 --> 00:04:02.580]   It's compatible with intermittent fasting.
[00:04:02.580 --> 00:04:05.960]   It's compatible with vegan diets, with keto diets,
[00:04:05.960 --> 00:04:07.140]   and essentially every diet
[00:04:07.140 --> 00:04:09.860]   that you could possibly imagine out there.
[00:04:09.860 --> 00:04:12.180]   It's also filled with adaptogens for recovery.
[00:04:12.180 --> 00:04:14.040]   It has digestive enzymes for gut health
[00:04:14.040 --> 00:04:15.100]   and has a number of other things
[00:04:15.100 --> 00:04:16.660]   that support the immune system.
[00:04:16.660 --> 00:04:18.900]   If you'd like to try Athletic Greens,
[00:04:18.900 --> 00:04:21.460]   you can go to athleticgreens.com/huberman
[00:04:21.460 --> 00:04:22.940]   to claim their special offer.
[00:04:22.940 --> 00:04:24.460]   They'll give you five free travel packs
[00:04:24.460 --> 00:04:26.340]   that make it really easy to mix up Athletic Greens
[00:04:26.340 --> 00:04:27.460]   while you're on the road,
[00:04:27.460 --> 00:04:30.940]   and they'll give you a year's supply of vitamin D3 K2.
[00:04:30.940 --> 00:04:33.780]   There's now a lot of evidence that vitamin D3
[00:04:33.780 --> 00:04:37.520]   supports a huge number of metabolic factors,
[00:04:37.520 --> 00:04:39.640]   immune system factors, endocrine factors.
[00:04:39.640 --> 00:04:41.380]   Basically, we need vitamin D3.
[00:04:41.380 --> 00:04:42.700]   We can get it from the sun,
[00:04:42.700 --> 00:04:45.180]   but many people are deficient in vitamin D3
[00:04:45.180 --> 00:04:46.380]   even if they are getting
[00:04:46.380 --> 00:04:48.300]   what they think is sufficient sunlight.
[00:04:48.300 --> 00:04:50.720]   And K2 is important for cardiovascular health.
[00:04:50.720 --> 00:04:53.620]   So again, if you go to athleticgreens.com/huberman,
[00:04:53.620 --> 00:04:55.140]   you can claim their special offer,
[00:04:55.140 --> 00:04:56.300]   the five free travel packs,
[00:04:56.300 --> 00:04:59.180]   plus the year supply of vitamin D3 K2.
[00:04:59.180 --> 00:05:02.380]   Today's podcast is also brought to us by InsideTracker.
[00:05:02.380 --> 00:05:04.860]   InsideTracker is a personalized nutrition platform
[00:05:04.860 --> 00:05:07.300]   that analyzes data from your blood and DNA
[00:05:07.300 --> 00:05:08.820]   to help you better understand your body
[00:05:08.820 --> 00:05:10.740]   and help you reach your health goals.
[00:05:10.740 --> 00:05:13.660]   I've long been a believer in getting regular blood work done
[00:05:13.660 --> 00:05:16.220]   for the simple reason that many of the factors
[00:05:16.220 --> 00:05:18.540]   that impact your immediate and long-term health
[00:05:18.540 --> 00:05:21.100]   can only be analyzed from a quality blood test.
[00:05:21.100 --> 00:05:23.580]   And now with the advent of modern DNA tests,
[00:05:23.580 --> 00:05:26.180]   you can also get information about how your specific genes
[00:05:26.180 --> 00:05:28.740]   are impacting your immediate and long-term health.
[00:05:28.740 --> 00:05:30.220]   Now, a problem with a lot of blood tests
[00:05:30.220 --> 00:05:32.700]   and DNA tests out there is you get the numbers back,
[00:05:32.700 --> 00:05:34.700]   but you don't know what to do with those numbers.
[00:05:34.700 --> 00:05:37.380]   With InsideTracker, they make it very simple
[00:05:37.380 --> 00:05:39.620]   to figure out what to do to bring those numbers
[00:05:39.620 --> 00:05:41.580]   into the ranges that are right for you.
[00:05:41.580 --> 00:05:44.300]   They have a dashboard that's very easy to use.
[00:05:44.300 --> 00:05:47.780]   You can see the numbers from your blood and or DNA tests,
[00:05:47.780 --> 00:05:50.420]   and it will point to specific lifestyle factors,
[00:05:50.420 --> 00:05:53.260]   nutritional factors, as well as supplementation,
[00:05:53.260 --> 00:05:55.920]   maybe even prescription factors that would be right for you
[00:05:55.920 --> 00:05:57.940]   to bring the numbers into range that are ideal
[00:05:57.940 --> 00:06:00.360]   for your immediate and long-term health goals.
[00:06:00.360 --> 00:06:02.040]   Another feature that InsideTracker has
[00:06:02.040 --> 00:06:03.920]   is their inner age test.
[00:06:03.920 --> 00:06:06.180]   This test shows you what your biological age is
[00:06:06.180 --> 00:06:08.500]   and compares that to your chronological age
[00:06:08.500 --> 00:06:11.220]   and what you can do to improve your biological age,
[00:06:11.220 --> 00:06:13.100]   which of course is the important number.
[00:06:13.100 --> 00:06:14.460]   If you'd like to try InsideTracker,
[00:06:14.460 --> 00:06:17.100]   you can visit insidetracker.com/huberman
[00:06:17.100 --> 00:06:20.060]   to get 25% off any of InsideTracker's plans.
[00:06:20.060 --> 00:06:23.380]   Also, an interview I did with longevity research doctor
[00:06:23.380 --> 00:06:25.860]   and InsideTracker's founder, Dr. Gil Blander,
[00:06:25.860 --> 00:06:27.540]   is out now on their podcast,
[00:06:27.540 --> 00:06:29.580]   the Longevity by Design podcast,
[00:06:29.580 --> 00:06:31.360]   and a link to that interview can be found
[00:06:31.360 --> 00:06:32.820]   in today's show notes.
[00:06:32.820 --> 00:06:35.940]   Today's episode is also brought to us by Magic Spoon.
[00:06:35.940 --> 00:06:37.700]   Magic Spoon is a zero-sugar,
[00:06:37.700 --> 00:06:40.140]   grain-free, keto-friendly cereal.
[00:06:40.140 --> 00:06:41.880]   I don't follow a ketogenic diet.
[00:06:41.880 --> 00:06:44.120]   The way that I eat is basically geared toward
[00:06:44.120 --> 00:06:46.100]   feeling alert when I want to be alert
[00:06:46.100 --> 00:06:48.000]   and feeling sleepy when I want to go to sleep,
[00:06:48.000 --> 00:06:50.620]   which for me means fasting until about 11 a.m. or noon,
[00:06:50.620 --> 00:06:51.700]   most days.
[00:06:51.700 --> 00:06:53.940]   Then I eat low carb during the day.
[00:06:53.940 --> 00:06:56.580]   So I'll have some meat or fish or chicken and some salad.
[00:06:56.580 --> 00:06:57.460]   That's what works for me.
[00:06:57.460 --> 00:06:58.300]   And in the afternoon,
[00:06:58.300 --> 00:07:00.940]   I remain on a more or less low carb-ish diet.
[00:07:00.940 --> 00:07:03.960]   And then in the evening, I eat pastas and things primarily,
[00:07:03.960 --> 00:07:05.380]   and I throttle back on the protein,
[00:07:05.380 --> 00:07:07.140]   and that's what allows me to fall asleep at night.
[00:07:07.140 --> 00:07:08.700]   That's just what works for me.
[00:07:08.700 --> 00:07:10.740]   So if I want a snack in the afternoon,
[00:07:10.740 --> 00:07:14.080]   I want that to be a ketogenic or low carb snack.
[00:07:14.080 --> 00:07:16.820]   And that snack these days is Magic Spoon.
[00:07:16.820 --> 00:07:18.140]   Magic Spoon is really terrific.
[00:07:18.140 --> 00:07:21.120]   It has zero grams of sugar, 13 to 14 grams of protein,
[00:07:21.120 --> 00:07:24.200]   and only four net grams of carbohydrates in each serving.
[00:07:24.200 --> 00:07:25.120]   It's really delicious.
[00:07:25.120 --> 00:07:27.200]   They have a number of different flavors like cocoa,
[00:07:27.200 --> 00:07:29.300]   fruity, peanut butter, and frosted.
[00:07:29.300 --> 00:07:32.140]   I particularly like frosted, tastes like donuts,
[00:07:32.140 --> 00:07:33.240]   and I really like donuts,
[00:07:33.240 --> 00:07:36.540]   although I try not to eat donuts too often, if ever.
[00:07:36.540 --> 00:07:38.580]   What I do lately is I take Magic Spoon,
[00:07:38.580 --> 00:07:40.960]   I put it in some Bulgarian yogurt, which is really good,
[00:07:40.960 --> 00:07:42.660]   and I mix that up, I put those in there,
[00:07:42.660 --> 00:07:43.980]   and sometimes I put some cinnamon on them,
[00:07:43.980 --> 00:07:44.860]   and as I'm describing this,
[00:07:44.860 --> 00:07:46.160]   I'm getting hungry for Magic Spoon.
[00:07:46.160 --> 00:07:47.960]   So if you want to try Magic Spoon,
[00:07:47.960 --> 00:07:50.920]   you can go to magicspoon.com/huberman
[00:07:50.920 --> 00:07:52.140]   to get their variety pack.
[00:07:52.140 --> 00:07:54.020]   Just use the promo code Huberman
[00:07:54.020 --> 00:07:56.300]   at checkout to get $5 off your order.
[00:07:56.300 --> 00:07:58.940]   Again, that's magicspoon.com/huberman,
[00:07:58.940 --> 00:08:01.740]   and use the code Huberman to get $5 off.
[00:08:01.740 --> 00:08:05.140]   And now for my discussion with Dr. David Berson.
[00:08:05.140 --> 00:08:06.020]   Welcome.
[00:08:06.020 --> 00:08:06.940]   - Thank you. - Yeah.
[00:08:06.940 --> 00:08:08.120]   - So nice to be here.
[00:08:08.120 --> 00:08:09.200]   - Great to have you.
[00:08:09.200 --> 00:08:11.900]   For more than 20 years,
[00:08:11.900 --> 00:08:14.260]   you've been my go-to source for all things,
[00:08:14.260 --> 00:08:17.120]   nervous system, how it works, how it's structured.
[00:08:17.120 --> 00:08:20.120]   So today I want to ask you some questions about that.
[00:08:20.120 --> 00:08:22.900]   I think people would gain a lot of insight
[00:08:22.900 --> 00:08:24.940]   into this machine that makes them think,
[00:08:24.940 --> 00:08:27.180]   and feel, and see, et cetera.
[00:08:27.180 --> 00:08:31.760]   If you would, could you tell us how we see?
[00:08:31.760 --> 00:08:36.300]   You know, a photon of light enters the eye.
[00:08:36.300 --> 00:08:37.480]   What happens?
[00:08:37.480 --> 00:08:38.320]   - Right.
[00:08:38.320 --> 00:08:40.020]   - I mean, how is it that I look outside,
[00:08:40.020 --> 00:08:42.200]   I see a truck drive by, or I look on the wall,
[00:08:42.200 --> 00:08:44.400]   I see a photo of my dog.
[00:08:44.400 --> 00:08:46.320]   How does that work?
[00:08:46.320 --> 00:08:49.100]   - Right, so this is an old question, obviously.
[00:08:49.100 --> 00:08:50.900]   And clearly in the end,
[00:08:50.900 --> 00:08:52.780]   the reason you have a visual experience
[00:08:52.780 --> 00:08:56.120]   is that your brain has got some pattern of activity
[00:08:56.120 --> 00:08:59.100]   that it associates with the input from the periphery.
[00:08:59.100 --> 00:09:00.760]   But you can have a visual experience
[00:09:00.760 --> 00:09:02.560]   with no input from the periphery as well.
[00:09:02.560 --> 00:09:06.000]   When you're dreaming, you're seeing things
[00:09:06.000 --> 00:09:07.480]   that aren't coming through your eyes.
[00:09:07.480 --> 00:09:08.520]   - Are those memories?
[00:09:08.520 --> 00:09:10.700]   - I would say in a sense,
[00:09:10.700 --> 00:09:13.140]   they may reflect your visual experience.
[00:09:13.140 --> 00:09:15.120]   They're not necessarily specific visual memories,
[00:09:15.120 --> 00:09:16.720]   but of course they can be.
[00:09:16.720 --> 00:09:18.880]   But the point is that the experience of seeing
[00:09:18.880 --> 00:09:21.400]   is actually a brain phenomenon.
[00:09:21.400 --> 00:09:24.520]   But of course, under normal circumstances,
[00:09:24.520 --> 00:09:26.480]   we see the world because we're looking at it,
[00:09:26.480 --> 00:09:28.500]   and we're using our eyes to look at it.
[00:09:28.500 --> 00:09:32.240]   And fundamentally, when we're looking at the exterior world,
[00:09:32.240 --> 00:09:35.020]   it's what the retina is telling the brain that matters.
[00:09:35.020 --> 00:09:37.860]   So there are cells called ganglion cells.
[00:09:37.860 --> 00:09:40.480]   These are neurons that are the key cells
[00:09:40.480 --> 00:09:43.100]   for communicating between eye and brain.
[00:09:43.100 --> 00:09:44.420]   The eye is like the camera.
[00:09:44.420 --> 00:09:46.420]   It's detecting the initial image,
[00:09:46.420 --> 00:09:47.660]   doing some initial processing,
[00:09:47.660 --> 00:09:51.480]   and then that signal gets sent back to the brain proper.
[00:09:51.480 --> 00:09:54.320]   And of course, it's there at the level of the cortex
[00:09:54.320 --> 00:09:56.200]   that we have this conscious visual experience.
[00:09:56.200 --> 00:09:57.720]   There are many other places in the brain
[00:09:57.720 --> 00:09:59.740]   that get visual input as well,
[00:09:59.740 --> 00:10:02.740]   doing other things with that kind of information.
[00:10:02.740 --> 00:10:05.980]   - So I get a lot of questions about color vision.
[00:10:05.980 --> 00:10:09.060]   If you would, could you explain how is it
[00:10:09.060 --> 00:10:12.320]   that we can perceive reds and greens and blues
[00:10:12.320 --> 00:10:13.460]   and things of that sort?
[00:10:13.460 --> 00:10:14.300]   - Right.
[00:10:14.300 --> 00:10:16.380]   So the first thing to understand about light
[00:10:16.380 --> 00:10:19.900]   is that it's just a form of electromagnetic radiation.
[00:10:19.900 --> 00:10:23.400]   It's vibrating, it's oscillating.
[00:10:23.400 --> 00:10:24.240]   But-
[00:10:24.240 --> 00:10:25.520]   - When you say it's vibrating, it's oscillating,
[00:10:25.520 --> 00:10:28.480]   you mean that photons are actually moving?
[00:10:28.480 --> 00:10:29.800]   - Well, in a sense, photons are,
[00:10:29.800 --> 00:10:31.840]   they're certainly moving through space.
[00:10:31.840 --> 00:10:34.440]   We think about photons as particles,
[00:10:34.440 --> 00:10:36.020]   and that's one way of thinking about light,
[00:10:36.020 --> 00:10:39.200]   but we can also think of it as a wave, like a radio wave.
[00:10:39.200 --> 00:10:40.860]   Either way is acceptable.
[00:10:40.860 --> 00:10:42.540]   And the radio waves have frequencies,
[00:10:42.540 --> 00:10:45.260]   like the frequencies on your radio dial.
[00:10:45.260 --> 00:10:48.380]   And certain frequencies in the electromagnetic spectrum
[00:10:48.380 --> 00:10:50.960]   can be detected by neurons in the retina.
[00:10:50.960 --> 00:10:52.940]   Those are the things we see.
[00:10:52.940 --> 00:10:54.620]   But there are still different wavelengths
[00:10:54.620 --> 00:10:57.780]   within the light that can be seen by the eye.
[00:10:57.780 --> 00:11:00.500]   And those different wavelengths are unpacked in a sense,
[00:11:00.500 --> 00:11:03.540]   or decoded by the nervous system
[00:11:03.540 --> 00:11:06.400]   to lead to our experience of color.
[00:11:06.400 --> 00:11:10.480]   Essentially, different wavelengths give us the sensation
[00:11:10.480 --> 00:11:13.660]   of different colors through the auspices
[00:11:13.660 --> 00:11:15.880]   of different neurons that are tuned
[00:11:15.880 --> 00:11:17.660]   to different wavelengths of light.
[00:11:17.660 --> 00:11:20.060]   - So when a photon,
[00:11:20.060 --> 00:11:23.760]   so when a little bit of light hits my eye, goes in,
[00:11:23.760 --> 00:11:26.440]   the photoreceptors convert that into electrical signal.
[00:11:26.440 --> 00:11:27.280]   - Right.
[00:11:27.280 --> 00:11:30.700]   - How is it that a given photon of light
[00:11:30.700 --> 00:11:31.920]   gives me the perception,
[00:11:31.920 --> 00:11:33.160]   eventually leads to the perception
[00:11:33.160 --> 00:11:35.200]   of red versus green versus blue?
[00:11:35.200 --> 00:11:36.040]   - Right.
[00:11:36.040 --> 00:11:40.640]   So if you imagine that in the first layer of the retina
[00:11:40.640 --> 00:11:42.320]   where this transformation occurs
[00:11:42.320 --> 00:11:45.200]   from electromagnetic radiation into neural signals,
[00:11:45.200 --> 00:11:49.740]   that you have different kinds of sensitive cells
[00:11:49.740 --> 00:11:51.120]   that are expressing,
[00:11:51.120 --> 00:11:54.920]   they're making different molecules within themselves
[00:11:54.920 --> 00:11:58.320]   for this express purpose of absorbing photons,
[00:11:58.320 --> 00:12:01.320]   which is the first step in the process of seeing.
[00:12:01.320 --> 00:12:03.880]   Now, it turns out that altogether
[00:12:03.880 --> 00:12:06.660]   there are about five proteins like this
[00:12:06.660 --> 00:12:09.660]   that we need to think about in the typical retina.
[00:12:09.660 --> 00:12:11.840]   But for seeing color, really it's three of them.
[00:12:11.840 --> 00:12:13.300]   So there are three different proteins.
[00:12:13.300 --> 00:12:17.540]   Each absorbs light with a different preferred frequency.
[00:12:17.540 --> 00:12:20.600]   And then the nervous system keeps track of those signals,
[00:12:20.600 --> 00:12:23.980]   compares and contrasts them
[00:12:23.980 --> 00:12:25.680]   to extract some understanding
[00:12:25.680 --> 00:12:28.080]   of the wavelength composition of light.
[00:12:28.080 --> 00:12:30.600]   So you can see just by looking at a landscape,
[00:12:30.600 --> 00:12:33.360]   oh, it must be late in the day
[00:12:33.360 --> 00:12:34.920]   because things are looking golden.
[00:12:34.920 --> 00:12:38.080]   That's all a function of our absorbing
[00:12:38.080 --> 00:12:39.920]   the light that's coming from the world
[00:12:39.920 --> 00:12:41.680]   and interpreting that with our brain
[00:12:41.680 --> 00:12:43.040]   because of the different composition
[00:12:43.040 --> 00:12:45.980]   of the light that's reaching our eyes.
[00:12:45.980 --> 00:12:48.160]   - Is it fair to assume that my perception of red
[00:12:48.160 --> 00:12:50.200]   is the same as your perception of red?
[00:12:50.200 --> 00:12:51.360]   - Well, that's a great question.
[00:12:51.360 --> 00:12:52.560]   - And that mine is better.
[00:12:52.560 --> 00:12:54.220]   - No, I'm just kidding.
[00:12:54.220 --> 00:12:56.100]   It's a great question.
[00:12:56.100 --> 00:12:57.460]   It's a deep philosophical question.
[00:12:57.460 --> 00:12:59.000]   It's a question that really probably
[00:12:59.000 --> 00:13:01.140]   can't even ultimately be answered
[00:13:01.140 --> 00:13:05.180]   by the usual empirical scientific processes
[00:13:05.180 --> 00:13:08.420]   'cause it's really about an individual's experience.
[00:13:08.420 --> 00:13:14.340]   What we can say is that the biological mechanisms
[00:13:14.340 --> 00:13:17.440]   that we think are important for seeing color, for example,
[00:13:17.440 --> 00:13:19.520]   seem to be very highly similar
[00:13:19.520 --> 00:13:20.980]   from one individual to the next,
[00:13:20.980 --> 00:13:23.180]   whether it be human beings or other animals.
[00:13:23.180 --> 00:13:27.500]   And so we think that the physiological process
[00:13:27.500 --> 00:13:29.780]   looks very similar on the front end,
[00:13:29.780 --> 00:13:32.220]   but once you're at the level of perception
[00:13:32.220 --> 00:13:34.920]   or understanding or experience,
[00:13:34.920 --> 00:13:38.480]   that's something that's a little bit tougher to nail down
[00:13:38.480 --> 00:13:42.560]   with the sorts of scientific approaches
[00:13:42.560 --> 00:13:46.100]   that we approach biological vision with, let's say.
[00:13:46.100 --> 00:13:47.880]   - You mentioned that there are five
[00:13:47.880 --> 00:13:49.940]   different cone types, essentially,
[00:13:49.940 --> 00:13:51.620]   cones being the cells that absorb light
[00:13:51.620 --> 00:13:52.820]   of different wavelengths.
[00:13:52.820 --> 00:13:58.820]   I often wondered when I had my dog what he saw
[00:13:58.820 --> 00:14:01.940]   and how his vision differs from our vision.
[00:14:01.940 --> 00:14:04.220]   And certainly there are animals that can see things
[00:14:04.220 --> 00:14:05.620]   that we can't see.
[00:14:05.620 --> 00:14:09.140]   What are some of the more outrageous examples of that?
[00:14:09.140 --> 00:14:10.940]   - Of seeing things that we can't.
[00:14:10.940 --> 00:14:12.260]   - And in the extreme.
[00:14:12.260 --> 00:14:16.620]   Dogs, I'm guessing, see reds more as oranges.
[00:14:16.620 --> 00:14:17.580]   Is that right?
[00:14:17.580 --> 00:14:21.340]   'Cause they don't have the same array of neurons
[00:14:21.340 --> 00:14:22.900]   that we have for seeing color.
[00:14:22.900 --> 00:14:25.160]   - Right, so the first thing is it's not really
[00:14:25.160 --> 00:14:26.980]   five types of cones.
[00:14:26.980 --> 00:14:29.020]   There are really three types of cones.
[00:14:29.020 --> 00:14:31.140]   And if you look at the way that color vision
[00:14:31.140 --> 00:14:32.720]   is thought to work, you can sort of see
[00:14:32.720 --> 00:14:35.120]   that it has to be three different signals.
[00:14:35.120 --> 00:14:37.300]   There are a couple of other types of pigments.
[00:14:37.300 --> 00:14:40.660]   One is really mostly for dim light vision.
[00:14:40.660 --> 00:14:42.780]   When you're walking around in a moonless night
[00:14:42.780 --> 00:14:45.720]   and you're seeing things with very low light,
[00:14:45.720 --> 00:14:49.220]   that's the rod cell that uses its own pigment.
[00:14:49.220 --> 00:14:51.380]   And then there's another class of pigments
[00:14:51.380 --> 00:14:52.960]   we'll probably talk about a little bit later,
[00:14:52.960 --> 00:14:54.380]   this melanopsin pigment.
[00:14:54.380 --> 00:14:56.240]   - I thought you were referring to like ultraviolet
[00:14:56.240 --> 00:14:58.500]   and infrared and things of that sort.
[00:14:58.500 --> 00:15:01.660]   - Right, so in the case of a typical,
[00:15:01.660 --> 00:15:04.300]   well, let's put it this way, in human beings,
[00:15:04.300 --> 00:15:06.540]   most of us have three cone types
[00:15:06.540 --> 00:15:10.860]   and we can see colors that stem from that.
[00:15:10.860 --> 00:15:15.860]   In most mammals, including your dog or your cat,
[00:15:15.860 --> 00:15:18.540]   there really are only two cone types.
[00:15:18.540 --> 00:15:21.860]   And that limits the kind of vision that they can have
[00:15:21.860 --> 00:15:25.080]   in the domain of wavelength or color, as you would say.
[00:15:25.080 --> 00:15:27.960]   So really a dog sees the world kind of like
[00:15:27.960 --> 00:15:31.720]   a particular kind of colorblind human might see the world
[00:15:31.720 --> 00:15:33.300]   because instead of having three channels
[00:15:33.300 --> 00:15:35.760]   to compare and contrast, they only have two channels.
[00:15:35.760 --> 00:15:37.480]   And that makes it much more difficult to figure out
[00:15:37.480 --> 00:15:40.140]   exactly which wavelength you're looking at.
[00:15:40.140 --> 00:15:42.320]   - Do colorblind people suffer much
[00:15:42.320 --> 00:15:44.460]   as a consequence of being colorblind?
[00:15:44.460 --> 00:15:47.420]   - Well, it's like so many other disabilities.
[00:15:47.420 --> 00:15:52.420]   We are, the world is built for people
[00:15:52.420 --> 00:15:54.860]   of the most common type.
[00:15:54.860 --> 00:15:59.660]   So in some cases, the expectation can be there
[00:15:59.660 --> 00:16:01.980]   that somebody can see something that they won't be able to
[00:16:01.980 --> 00:16:04.460]   if they're missing one of their cone types, let's say.
[00:16:04.460 --> 00:16:07.680]   So in those moments, that can be a real problem.
[00:16:08.740 --> 00:16:12.500]   If there's a lack of contrast to their visual system,
[00:16:12.500 --> 00:16:14.020]   they will be blind to that.
[00:16:14.020 --> 00:16:19.020]   In general, it's a fairly modest visual limitation
[00:16:19.020 --> 00:16:20.640]   as things go.
[00:16:20.640 --> 00:16:23.020]   For example, if not being able to see acutely
[00:16:23.020 --> 00:16:24.180]   can be much more damaging,
[00:16:24.180 --> 00:16:26.900]   not being able to read fine print, for example.
[00:16:26.900 --> 00:16:28.700]   - Yeah, I suppose if I had to give up
[00:16:28.700 --> 00:16:31.660]   the ability to see certain colors
[00:16:31.660 --> 00:16:33.380]   or give up the ability to see clearly,
[00:16:33.380 --> 00:16:37.500]   I'd certainly trade out color for clarity.
[00:16:37.500 --> 00:16:40.020]   - Right, of course, color is very meaningful to us
[00:16:40.020 --> 00:16:43.920]   as human beings, so we would hate to give it up.
[00:16:43.920 --> 00:16:46.580]   But obviously dogs and cats and all kinds of other mammals
[00:16:46.580 --> 00:16:48.100]   do perfectly well in the world.
[00:16:48.100 --> 00:16:49.260]   - Yeah, because we take care of them.
[00:16:49.260 --> 00:16:51.660]   I spent most of my time taking care of that dog.
[00:16:51.660 --> 00:16:54.260]   He took care of me too.
[00:16:54.260 --> 00:16:59.920]   Let's talk about that odd photopigment.
[00:16:59.920 --> 00:17:03.540]   Photopigment, of course, being the thing that absorbs light
[00:17:03.540 --> 00:17:05.100]   of a particular wavelength.
[00:17:05.100 --> 00:17:09.060]   And let's talk about these specialized ganglion cells
[00:17:09.060 --> 00:17:12.380]   that communicate certain types of information
[00:17:12.380 --> 00:17:15.580]   from eye to the brain that are so important
[00:17:15.580 --> 00:17:16.660]   for so many things.
[00:17:16.660 --> 00:17:17.960]   What I'm referring to here, of course,
[00:17:17.960 --> 00:17:20.120]   is your co-discovery of the so-called
[00:17:20.120 --> 00:17:22.260]   intrinsically photosensitive cells,
[00:17:22.260 --> 00:17:25.020]   the neurons in the eye that do so many of the things
[00:17:25.020 --> 00:17:27.540]   that don't actually have to do with perception,
[00:17:27.540 --> 00:17:30.260]   but have to do with important biological functions.
[00:17:30.260 --> 00:17:33.220]   What I would love for you to do is explain to me
[00:17:33.220 --> 00:17:35.100]   why once I heard you say,
[00:17:35.100 --> 00:17:38.880]   we have a bit of fly eye in our eye.
[00:17:38.880 --> 00:17:42.220]   And you showed this slide of like a giant fly
[00:17:42.220 --> 00:17:46.260]   from a horror movie trying to attack this woman.
[00:17:46.260 --> 00:17:48.600]   And maybe it was an eye also.
[00:17:48.600 --> 00:17:52.080]   So what does it mean that we have a bit of a fly eye
[00:17:52.080 --> 00:17:53.140]   in our eye?
[00:17:53.140 --> 00:17:58.520]   - Yeah, so this last pigment is a really peculiar one.
[00:18:01.540 --> 00:18:04.460]   One can think about it as really the initial
[00:18:04.460 --> 00:18:07.120]   sensitive element in a system that's designed
[00:18:07.120 --> 00:18:09.640]   to tell your brain about how bright things are
[00:18:09.640 --> 00:18:10.560]   in your world.
[00:18:10.560 --> 00:18:15.260]   And the thing that's really peculiar about this pigment
[00:18:15.260 --> 00:18:18.460]   is that it's in the wrong place, in a sense.
[00:18:18.460 --> 00:18:20.620]   When you think about the structure of the retina,
[00:18:20.620 --> 00:18:22.560]   you think about a layer cake, essentially.
[00:18:22.560 --> 00:18:25.340]   You've got this thin membrane at the back of your eye,
[00:18:25.340 --> 00:18:27.820]   but it's actually a stack of thin layers.
[00:18:27.820 --> 00:18:29.460]   And the outermost of those layers
[00:18:29.460 --> 00:18:31.940]   is where these photoreceptors you were talking about earlier
[00:18:31.940 --> 00:18:32.780]   are sitting.
[00:18:32.780 --> 00:18:35.420]   That's where the film of your camera is, essentially.
[00:18:35.420 --> 00:18:37.020]   That's where the photons do their magic
[00:18:37.020 --> 00:18:39.140]   with the photopigments and turn it into a neural signal.
[00:18:39.140 --> 00:18:39.980]   - I like that.
[00:18:39.980 --> 00:18:41.020]   I've never really thought of the photoreceptors
[00:18:41.020 --> 00:18:42.780]   as the film of the camera, but that makes sense.
[00:18:42.780 --> 00:18:44.820]   - Yeah, or like the sensitive chip,
[00:18:44.820 --> 00:18:47.220]   CCD chip in your cell phone.
[00:18:47.220 --> 00:18:49.420]   It's the surface on which the light pattern
[00:18:49.420 --> 00:18:52.240]   is imaged by the optics of the eye.
[00:18:52.240 --> 00:18:54.180]   And now you've got an array of sensors
[00:18:54.180 --> 00:18:56.260]   that's capturing that information
[00:18:56.260 --> 00:18:59.100]   and creating a bitmap, essentially.
[00:18:59.100 --> 00:19:01.060]   But now it's in neural signals distributed
[00:19:01.060 --> 00:19:03.260]   across the surface of the retina.
[00:19:03.260 --> 00:19:07.040]   So all of that was known to be going on 150 years ago.
[00:19:07.040 --> 00:19:10.740]   A couple of types of photoreceptors, cones and rods.
[00:19:10.740 --> 00:19:13.820]   If you look a little bit more closely, three types of cones.
[00:19:13.820 --> 00:19:15.580]   That's where the transformation
[00:19:15.580 --> 00:19:20.480]   from electromagnetic radiation to neural signals
[00:19:20.480 --> 00:19:22.520]   was thought to take place.
[00:19:22.520 --> 00:19:24.680]   But it turns out that this last photopigment
[00:19:24.680 --> 00:19:27.060]   is in the other end of the retina,
[00:19:27.060 --> 00:19:28.500]   the innermost part of the retina.
[00:19:28.500 --> 00:19:30.540]   That's where the so-called ganglion cells are.
[00:19:30.540 --> 00:19:32.140]   Those are the cells that talk to the brain,
[00:19:32.140 --> 00:19:34.860]   the ones that actually can communicate directly
[00:19:34.860 --> 00:19:38.220]   what information comes to them from the photoreceptors.
[00:19:38.220 --> 00:19:39.900]   And here you've got a case
[00:19:39.900 --> 00:19:43.100]   where actually some of the output neurons
[00:19:43.100 --> 00:19:44.780]   that we didn't think had any business
[00:19:44.780 --> 00:19:46.980]   being directly sensitive to light
[00:19:46.980 --> 00:19:50.060]   were actually making this photopigment,
[00:19:50.060 --> 00:19:53.420]   absorbing light and converting that to neural signals
[00:19:53.420 --> 00:19:54.900]   and sending it to the brain.
[00:19:54.900 --> 00:19:58.640]   So that made it pretty surprising and unexpected,
[00:19:58.640 --> 00:20:01.800]   but there are many surprising things about these cells.
[00:20:01.800 --> 00:20:05.140]   So, and what is the relationship to the fly eye?
[00:20:05.140 --> 00:20:08.180]   Right, so the link there is that if you ask
[00:20:08.180 --> 00:20:13.180]   how the photopigment now communicates downstream
[00:20:13.180 --> 00:20:15.960]   from the initial absorption event
[00:20:15.960 --> 00:20:17.560]   to get to the electrical signal,
[00:20:17.560 --> 00:20:19.500]   that's a complex cellular process,
[00:20:19.500 --> 00:20:22.260]   involves many chemical steps.
[00:20:22.260 --> 00:20:26.640]   And if you look at how photoreceptors in our eyes work,
[00:20:26.640 --> 00:20:30.340]   you can see what that cascade is, how that chain works.
[00:20:30.340 --> 00:20:33.400]   If you look in the eyes of flies
[00:20:33.400 --> 00:20:36.660]   or other insects or other invertebrates,
[00:20:36.660 --> 00:20:38.740]   there's a very similar kind of chain,
[00:20:38.740 --> 00:20:41.460]   but the specifics of how the signals get
[00:20:41.460 --> 00:20:43.600]   from the absorption event by the pigment
[00:20:43.600 --> 00:20:44.860]   to the electrical response
[00:20:44.860 --> 00:20:47.040]   that the nervous system can understand
[00:20:47.040 --> 00:20:48.900]   are characteristically different
[00:20:48.900 --> 00:20:53.740]   between fuzzy furry creatures like us
[00:20:53.740 --> 00:20:56.500]   and insects, for example, like the fly.
[00:20:56.500 --> 00:20:57.340]   I see.
[00:20:57.340 --> 00:21:00.640]   So these funny extra photoreceptors
[00:21:00.640 --> 00:21:01.740]   that are in the wrong layer
[00:21:01.740 --> 00:21:03.060]   doing something completely different
[00:21:03.060 --> 00:21:06.740]   are actually using a chemical cascade
[00:21:06.740 --> 00:21:08.300]   that looks much more like what you would see
[00:21:08.300 --> 00:21:10.100]   in a fly photoreceptor
[00:21:10.100 --> 00:21:12.900]   than what you would see in a human photoreceptor,
[00:21:12.900 --> 00:21:14.580]   a rod or a cone, for example.
[00:21:14.580 --> 00:21:18.700]   So it sounds like it's a very primitive aspect
[00:21:18.700 --> 00:21:20.380]   of biology that we maintain.
[00:21:20.380 --> 00:21:22.100]   - Exactly right.
[00:21:22.100 --> 00:21:22.940]   - And despite the fact
[00:21:22.940 --> 00:21:25.060]   that dogs can't see as many colors as we can
[00:21:25.060 --> 00:21:26.860]   and cats can't see as many colors as we can,
[00:21:26.860 --> 00:21:29.760]   we have all this extravagant stuff for seeing color.
[00:21:29.760 --> 00:21:31.560]   And then you've got this other pigment
[00:21:31.560 --> 00:21:33.700]   sitting in the wrong, not wrong,
[00:21:33.700 --> 00:21:36.980]   but in a different part of the eye,
[00:21:36.980 --> 00:21:40.300]   sending, processing light very differently
[00:21:40.300 --> 00:21:42.460]   and sending that information into the brain.
[00:21:42.460 --> 00:21:45.580]   So what do these cells do?
[00:21:45.580 --> 00:21:47.820]   I mean, presumably they're there for a reason.
[00:21:47.820 --> 00:21:48.740]   - They are.
[00:21:48.740 --> 00:21:53.740]   And the interesting thing is that one cell type like this,
[00:21:53.740 --> 00:21:56.300]   carrying one kind of signal,
[00:21:56.300 --> 00:22:00.220]   which I would call a brightness signal, essentially,
[00:22:00.220 --> 00:22:02.120]   can do many things in the brain.
[00:22:02.120 --> 00:22:03.180]   - When you say brightness signal,
[00:22:03.180 --> 00:22:05.940]   you mean that it, like right now, I have these cells.
[00:22:05.940 --> 00:22:06.780]   Do I have these cells?
[00:22:06.780 --> 00:22:07.620]   Of course not. - You do.
[00:22:07.620 --> 00:22:09.760]   - I'm joking, I hope I have these cells in my eye.
[00:22:09.760 --> 00:22:12.760]   And they're paying attention to how bright it is overall,
[00:22:12.760 --> 00:22:14.060]   but they're not paying attention, for instance,
[00:22:14.060 --> 00:22:15.140]   to the edge of your ear
[00:22:15.140 --> 00:22:16.740]   or what else is going on in the room.
[00:22:16.740 --> 00:22:19.140]   - Right, so it's the difference between
[00:22:19.140 --> 00:22:21.740]   knowing what the objects are on the table
[00:22:21.740 --> 00:22:23.180]   and knowing whether it's bright enough
[00:22:23.180 --> 00:22:25.820]   to be daylight right now.
[00:22:25.820 --> 00:22:28.960]   So why does your nervous system need to know
[00:22:28.960 --> 00:22:30.700]   whether it's daylight right now?
[00:22:30.700 --> 00:22:31.980]   Well, one thing that needs to know,
[00:22:31.980 --> 00:22:33.980]   that is your circadian clock.
[00:22:33.980 --> 00:22:37.420]   You know, if you travel across time zones to Europe,
[00:22:37.420 --> 00:22:41.940]   now your internal clock thinks it's California time,
[00:22:41.940 --> 00:22:44.880]   but the rotation of the earth is, you know,
[00:22:44.880 --> 00:22:46.420]   for a different part of the planet.
[00:22:46.420 --> 00:22:47.860]   You know, the rising and setting of the sun
[00:22:47.860 --> 00:22:50.280]   is not at all what your body is anticipating.
[00:22:50.280 --> 00:22:52.100]   So you've got an internal representation
[00:22:52.100 --> 00:22:54.640]   of the rotation of the earth in your own brain.
[00:22:54.640 --> 00:22:56.180]   That's your circadian system.
[00:22:56.180 --> 00:22:58.660]   It's keeping time.
[00:22:58.660 --> 00:23:00.900]   But now you've played a trick on your nervous system.
[00:23:00.900 --> 00:23:02.360]   You put yourself in a different place
[00:23:02.360 --> 00:23:05.660]   where the sun is rising at the, quote, wrong time.
[00:23:05.660 --> 00:23:07.620]   Well, that's not good for you, right?
[00:23:07.620 --> 00:23:08.980]   So you gotta get back on track.
[00:23:08.980 --> 00:23:12.020]   One of the things this system does is sends a,
[00:23:12.020 --> 00:23:14.980]   oh, it's daylight now signal to the brain,
[00:23:14.980 --> 00:23:16.860]   which compares with its internal clock.
[00:23:16.860 --> 00:23:18.420]   And if that's not right,
[00:23:18.420 --> 00:23:20.460]   it tweaks the clock gradually
[00:23:20.460 --> 00:23:21.840]   until you get over your jet lag
[00:23:21.840 --> 00:23:24.100]   and you feel back on track again.
[00:23:24.100 --> 00:23:26.980]   So the jet lag case makes a lot of sense to me,
[00:23:26.980 --> 00:23:31.380]   but presumably these elements didn't evolve for jet lag.
[00:23:31.380 --> 00:23:32.220]   Right.
[00:23:32.220 --> 00:23:35.900]   So what are they doing on a day-to-day basis?
[00:23:35.900 --> 00:23:37.460]   Right, well, one way to think about this
[00:23:37.460 --> 00:23:42.460]   is that the clock that you have in not just your brain,
[00:23:42.980 --> 00:23:45.660]   in all the cells, or almost all of the cells of your body,
[00:23:45.660 --> 00:23:49.020]   they're all oscillating, they're all, you know.
[00:23:49.020 --> 00:23:49.860]   They got little clocks in them.
[00:23:49.860 --> 00:23:51.660]   They got little clocks in them themselves.
[00:23:51.660 --> 00:23:52.780]   They're all clocks.
[00:23:52.780 --> 00:23:58.820]   You know, they need to be synchronized appropriately.
[00:23:58.820 --> 00:24:04.620]   And the whole thing has to be built in biological machinery.
[00:24:04.620 --> 00:24:07.380]   This is actually a beautiful story
[00:24:07.380 --> 00:24:10.940]   about how gene expression can control gene expression.
[00:24:10.940 --> 00:24:12.060]   And if you set it up right,
[00:24:12.060 --> 00:24:13.420]   you can set up a little thing
[00:24:13.420 --> 00:24:16.940]   that just sort of hums along at a particular frequency.
[00:24:16.940 --> 00:24:19.340]   In our case, it's humming along at 24 hours,
[00:24:19.340 --> 00:24:21.060]   'cause that's how our earth rotates,
[00:24:21.060 --> 00:24:23.460]   and it's all built into our biology.
[00:24:23.460 --> 00:24:24.840]   So this is great,
[00:24:24.840 --> 00:24:28.060]   but the reality is that the clock can only be so good.
[00:24:28.060 --> 00:24:29.620]   I mean, we're talking about biology here.
[00:24:29.620 --> 00:24:32.380]   It's not precision engineering,
[00:24:32.380 --> 00:24:34.140]   and so it can be a little bit off.
[00:24:34.140 --> 00:24:35.900]   Well, also it doesn't, it's in our brain,
[00:24:35.900 --> 00:24:39.620]   so it doesn't have access to any regular unerring signal.
[00:24:39.620 --> 00:24:42.460]   Well, if in the absence of the rising and setting
[00:24:42.460 --> 00:24:43.460]   of the sun, it doesn't.
[00:24:43.460 --> 00:24:45.560]   If you put someone in a cave,
[00:24:45.560 --> 00:24:47.820]   their biological clock will keep time
[00:24:47.820 --> 00:24:51.860]   to within a handful of minutes of 24 hours.
[00:24:51.860 --> 00:24:55.020]   That's no problem for one day.
[00:24:55.020 --> 00:24:57.280]   But if this went on without any correction,
[00:24:57.280 --> 00:24:59.220]   eventually you'd be out of phase.
[00:24:59.220 --> 00:25:00.500]   And this is actually one of the things
[00:25:00.500 --> 00:25:03.540]   that blind patients often complain about.
[00:25:03.540 --> 00:25:06.980]   If they've got retinal blindness, is insomnia.
[00:25:08.540 --> 00:25:10.140]   Or sleep and history in the middle of the night.
[00:25:10.140 --> 00:25:11.740]   Exactly, they're not synchronized.
[00:25:11.740 --> 00:25:14.740]   Their clock is there, but they're drifting out of phase
[00:25:14.740 --> 00:25:19.700]   because their clock's only good to 24.2 hours
[00:25:19.700 --> 00:25:21.900]   or 23.8 hours.
[00:25:21.900 --> 00:25:24.140]   Little by little, they're drifting.
[00:25:24.140 --> 00:25:26.020]   So you need a synchronization signal.
[00:25:26.020 --> 00:25:27.580]   So even if you never across time,
[00:25:27.580 --> 00:25:29.680]   as I was saying, of course, we didn't back on the savanna.
[00:25:29.680 --> 00:25:32.620]   We stayed within walking distance of where we were.
[00:25:32.620 --> 00:25:35.620]   You still need a synchronizer
[00:25:35.620 --> 00:25:39.140]   'cause otherwise you have nothing to actually confirm
[00:25:39.140 --> 00:25:41.580]   when the rising and the setting of the sun is.
[00:25:41.580 --> 00:25:44.340]   That's what you're trying to synchronize yourself to.
[00:25:44.340 --> 00:25:47.100]   I'm fascinated by the circadian clock
[00:25:47.100 --> 00:25:50.100]   and the fact that all the cells of our body
[00:25:50.100 --> 00:25:53.340]   have essentially a 24 hour-ish clock in them.
[00:25:53.340 --> 00:25:54.460]   Right.
[00:25:54.460 --> 00:25:56.180]   We hear a lot about these circadian rhythms
[00:25:56.180 --> 00:25:59.180]   and circadian clocks, the fact that we need light input
[00:25:59.180 --> 00:26:02.300]   from these special neurons in order to set the clock.
[00:26:02.300 --> 00:26:04.300]   But I've never really heard it describe
[00:26:04.300 --> 00:26:06.460]   how the clock itself works
[00:26:06.460 --> 00:26:10.180]   and how the clock signals to all the rest of the body
[00:26:10.180 --> 00:26:12.860]   when the liver should be doing one thing
[00:26:12.860 --> 00:26:15.580]   and when the stomach should be doing another.
[00:26:15.580 --> 00:26:18.180]   I know you've done some work on the clock.
[00:26:18.180 --> 00:26:21.580]   So if you would just maybe briefly describe
[00:26:21.580 --> 00:26:24.500]   where the clock is, what it does,
[00:26:24.500 --> 00:26:26.860]   and some of the top contour
[00:26:26.860 --> 00:26:29.780]   of how it tells the cells of the body what to do.
[00:26:29.780 --> 00:26:30.600]   Right.
[00:26:30.600 --> 00:26:32.860]   So the first thing to say is that, as you said,
[00:26:32.860 --> 00:26:34.660]   the clock is all over the place.
[00:26:34.660 --> 00:26:37.980]   Most of the tissues in your body have clocks.
[00:26:37.980 --> 00:26:40.260]   We probably have, what, millions of clocks in our body.
[00:26:40.260 --> 00:26:42.020]   I would say that's probably fair.
[00:26:42.020 --> 00:26:43.340]   If you have millions of cell types,
[00:26:43.340 --> 00:26:46.100]   you probably may have millions of clocks.
[00:26:46.100 --> 00:26:50.260]   The role of the central pacemaker for the circadian system
[00:26:50.260 --> 00:26:52.760]   is to coordinate all of these.
[00:26:52.760 --> 00:26:55.900]   And there's a little nucleus,
[00:26:55.900 --> 00:26:59.540]   a little collection of nerve cells in your brain.
[00:26:59.540 --> 00:27:03.620]   It's called the suprachiasmatic nucleus, the SCN.
[00:27:03.620 --> 00:27:05.760]   And it is sitting in a funny place
[00:27:05.760 --> 00:27:07.660]   for the rest of the structures in the nervous system
[00:27:07.660 --> 00:27:09.600]   that get direct retinal input.
[00:27:09.600 --> 00:27:11.980]   It's sitting in the hypothalamus,
[00:27:11.980 --> 00:27:15.500]   which you can think about as sort of the great coordinator
[00:27:15.500 --> 00:27:18.460]   of drives and-
[00:27:18.460 --> 00:27:20.740]   The source of all our pleasures and all our problems.
[00:27:20.740 --> 00:27:22.100]   Right. Or most our problems.
[00:27:22.100 --> 00:27:23.980]   Yes, it really is.
[00:27:23.980 --> 00:27:26.220]   But it's sort of deep in your brain,
[00:27:26.220 --> 00:27:28.020]   things that drive you to do things.
[00:27:28.020 --> 00:27:31.460]   If you're freezing cold, you put on a coat, you shivery.
[00:27:31.460 --> 00:27:34.140]   All these things are coordinated by the hypothalamus.
[00:27:34.140 --> 00:27:37.580]   So this pathway that we're talking about from the retina
[00:27:37.580 --> 00:27:39.660]   and from these peculiar cells
[00:27:39.660 --> 00:27:41.820]   that are encoding light intensity
[00:27:41.820 --> 00:27:45.420]   are sending signals directly into a center
[00:27:45.420 --> 00:27:47.940]   that's surrounded by all of these centers
[00:27:47.940 --> 00:27:51.060]   that control autonomic nervous system
[00:27:51.060 --> 00:27:54.160]   and your hormonal systems.
[00:27:54.160 --> 00:27:57.220]   So this is a part of your visual system
[00:27:57.220 --> 00:27:59.500]   that doesn't really reach the level of consciousness.
[00:27:59.500 --> 00:28:01.900]   It's not something you think about.
[00:28:01.900 --> 00:28:05.900]   It's happening under the radar kind of all the time.
[00:28:05.900 --> 00:28:07.540]   And the signal is working its way
[00:28:07.540 --> 00:28:12.380]   into this central clock coordinating center.
[00:28:12.380 --> 00:28:17.400]   Now, what happens then is not that well understood,
[00:28:17.400 --> 00:28:20.020]   but it's clear that this is a neural center
[00:28:20.020 --> 00:28:21.740]   that has the same ability to communicate
[00:28:21.740 --> 00:28:25.580]   with other parts of your brain as any other neural center.
[00:28:25.580 --> 00:28:28.780]   And clearly there are circuits
[00:28:28.780 --> 00:28:31.220]   that involve connections between neurons
[00:28:31.220 --> 00:28:34.060]   that are conventional.
[00:28:34.060 --> 00:28:35.340]   But in addition, it's quite clear
[00:28:35.340 --> 00:28:37.480]   that there are also sort of humoral effects
[00:28:37.480 --> 00:28:42.020]   that things are oozing out of the cells in the center
[00:28:42.020 --> 00:28:43.580]   and maybe into the circulation
[00:28:43.580 --> 00:28:47.620]   or just diffusing through the brain to some extent
[00:28:47.620 --> 00:28:50.660]   that can also affect neurons all swear.
[00:28:50.660 --> 00:28:52.760]   But the hypothalamus uses everything
[00:28:52.760 --> 00:28:54.240]   to control the rest of the bodies.
[00:28:54.240 --> 00:28:56.640]   And that's true of the suprachiasmatic nucleus,
[00:28:56.640 --> 00:28:59.020]   this circadian center as well.
[00:28:59.020 --> 00:29:03.400]   It can get its fingers into the autonomic nervous system,
[00:29:03.400 --> 00:29:04.740]   the humoral system,
[00:29:04.740 --> 00:29:07.160]   and of course up to the centers of the brain
[00:29:07.160 --> 00:29:12.160]   that organize coordinated rational behavior.
[00:29:12.160 --> 00:29:14.300]   So if I understand correctly,
[00:29:14.300 --> 00:29:16.620]   we have this group of cells, the suprachiasmatic nucleus,
[00:29:16.620 --> 00:29:18.520]   it's got a 24 hour rhythm.
[00:29:18.520 --> 00:29:21.620]   That rhythm is more or less matched
[00:29:21.620 --> 00:29:23.840]   to what's going on in our external world
[00:29:23.840 --> 00:29:26.420]   by the specialized set of neurons in our eye.
[00:29:26.420 --> 00:29:30.460]   But then the master clock itself, the SCN,
[00:29:30.460 --> 00:29:33.020]   releases things in the blood, humoral signals
[00:29:33.020 --> 00:29:37.820]   that go out various places in the body.
[00:29:37.820 --> 00:29:39.360]   And then you said to the autonomic system,
[00:29:39.360 --> 00:29:42.100]   which is regulating more or less how alert or calm we are,
[00:29:42.100 --> 00:29:44.240]   as well as our thinking and our cognition.
[00:29:44.240 --> 00:29:48.380]   So I'd love to talk to you about the autonomic part.
[00:29:48.380 --> 00:29:52.220]   Presumably that's through melatonin,
[00:29:52.220 --> 00:29:55.660]   it's through adrenaline.
[00:29:55.660 --> 00:29:58.380]   How is it that this clock is impacting
[00:29:58.380 --> 00:30:02.060]   how the autonomic system, how alert or calm we feel?
[00:30:02.060 --> 00:30:05.140]   - Right, so there are pathways
[00:30:05.140 --> 00:30:09.300]   by which the suprachiasmatic nucleus can access
[00:30:09.300 --> 00:30:12.260]   both the parasympathetic and sympathetic nervous system.
[00:30:12.260 --> 00:30:14.400]   - Just so people know, the sympathetic nervous system
[00:30:14.400 --> 00:30:16.180]   is the one that tends to make us more alert,
[00:30:16.180 --> 00:30:18.100]   and the parasympathetic nervous system
[00:30:18.100 --> 00:30:20.880]   is the portion of the autonomic nervous system
[00:30:20.880 --> 00:30:24.120]   makes us feel more calm, in broad context.
[00:30:24.120 --> 00:30:25.780]   - To first approximation, right.
[00:30:25.780 --> 00:30:30.780]   So this is, both of these systems are within the grasp
[00:30:30.780 --> 00:30:35.020]   of the circadian system through hypothalamic circuits.
[00:30:35.020 --> 00:30:37.700]   One of the circuits that will be, I think,
[00:30:37.700 --> 00:30:40.040]   of particular interest to some of your listeners
[00:30:40.040 --> 00:30:44.100]   is a pathway that involves this sympathetic branch
[00:30:44.100 --> 00:30:47.740]   of the autonomic nervous system, the fight or flight system,
[00:30:47.740 --> 00:30:50.900]   that is actually, through a very circuitous route,
[00:30:50.900 --> 00:30:52.780]   innervating the pineal gland,
[00:30:52.780 --> 00:30:55.380]   which is sitting in the middle of your brain.
[00:30:55.380 --> 00:30:56.980]   - The so-called third eye.
[00:30:56.980 --> 00:30:58.380]   - Right, so this is the-
[00:30:58.380 --> 00:31:00.600]   - We'll have to get back to why it's called the third eye,
[00:31:00.600 --> 00:31:02.260]   because, yeah. - That's an interesting history.
[00:31:02.260 --> 00:31:04.060]   - You can't call something the third eye and not,
[00:31:04.060 --> 00:31:05.240]   and just, you know.
[00:31:05.240 --> 00:31:06.780]   - Just leave it there. - Just leave it there.
[00:31:06.780 --> 00:31:08.440]   - Right. - Right.
[00:31:08.440 --> 00:31:11.500]   - Anyway, this is the major source of melatonin in your body.
[00:31:11.500 --> 00:31:15.200]   - So light comes into my eye. - Yes.
[00:31:15.200 --> 00:31:18.020]   - Passed off to the suprachiasmatic nucleus, essentially,
[00:31:18.020 --> 00:31:18.880]   not the light itself,
[00:31:18.880 --> 00:31:21.220]   but the signal representing the light.
[00:31:21.220 --> 00:31:22.060]   - Sure.
[00:31:22.060 --> 00:31:24.300]   - Then the SCN, the suprachiasmatic nucleus,
[00:31:24.300 --> 00:31:28.880]   can impact the melatonin system via the pineal.
[00:31:28.880 --> 00:31:30.600]   - Right, the way this is seen is that
[00:31:30.600 --> 00:31:33.880]   if you were to measure your melatonin level
[00:31:33.880 --> 00:31:35.600]   over the course of the day,
[00:31:35.600 --> 00:31:38.160]   if you could do this, you know, hour by hour,
[00:31:38.160 --> 00:31:40.480]   you'd see that it's really low during the day,
[00:31:40.480 --> 00:31:42.160]   very high at night.
[00:31:42.160 --> 00:31:44.100]   But if you get up in the middle of the night
[00:31:44.100 --> 00:31:45.300]   and go to the bathroom and turn on
[00:31:45.300 --> 00:31:47.120]   the bright fluorescent light,
[00:31:47.120 --> 00:31:49.480]   your melatonin level is slammed to the floor.
[00:31:49.480 --> 00:31:53.360]   Light is directly impacting your hormonal levels
[00:31:53.360 --> 00:31:57.180]   through this mechanism that we just described.
[00:31:57.180 --> 00:32:00.560]   So this is one of the routes by which light can act
[00:32:00.560 --> 00:32:04.440]   on your hormonal status through pathways
[00:32:04.440 --> 00:32:06.440]   that are completely beyond
[00:32:06.440 --> 00:32:08.440]   what you normally would think about, right?
[00:32:08.440 --> 00:32:10.540]   You're thinking about the things in the bathroom.
[00:32:10.540 --> 00:32:12.080]   Oh, there's the toothbrush.
[00:32:12.080 --> 00:32:13.820]   You know, there's the tube of toothpaste.
[00:32:13.820 --> 00:32:17.680]   But meanwhile, this other system is just counting photons
[00:32:17.680 --> 00:32:20.120]   and saying, oh, wow, there's a lot of photons right now.
[00:32:20.120 --> 00:32:22.640]   Let's shut down the melatonin release.
[00:32:22.640 --> 00:32:24.400]   - This is one of the main reasons why
[00:32:24.400 --> 00:32:27.280]   I've encouraged people to avoid bright light exposure
[00:32:27.280 --> 00:32:28.320]   in the middle of the night.
[00:32:28.320 --> 00:32:32.120]   Not just blue light, but bright light of any wavelength.
[00:32:32.120 --> 00:32:34.800]   Because there's this myth out there that blue light,
[00:32:34.800 --> 00:32:37.720]   because it's the optimal signal for activating this pathway
[00:32:37.720 --> 00:32:39.520]   and shutting down melatonin,
[00:32:39.520 --> 00:32:43.420]   is the only wavelength of light that can shut it down.
[00:32:43.420 --> 00:32:45.360]   But am I correct in thinking that
[00:32:45.360 --> 00:32:47.200]   if a light is bright enough,
[00:32:47.200 --> 00:32:49.320]   it doesn't matter if it's blue light, green light,
[00:32:49.320 --> 00:32:51.720]   purple light, even red light,
[00:32:51.720 --> 00:32:54.720]   you're going to slam melatonin down to the ground,
[00:32:54.720 --> 00:32:57.000]   which is not a good thing to happen
[00:32:57.000 --> 00:32:58.400]   in the middle of the night, correct?
[00:32:58.400 --> 00:32:59.320]   - Right, yeah.
[00:32:59.320 --> 00:33:03.480]   I mean, any light will affect the system to some extent.
[00:33:03.480 --> 00:33:06.440]   The blue light is somewhat more effective,
[00:33:06.440 --> 00:33:09.000]   but don't fool yourself into thinking
[00:33:09.000 --> 00:33:09.920]   that if you use red light,
[00:33:09.920 --> 00:33:12.640]   that means you're avoiding the effect.
[00:33:12.640 --> 00:33:14.460]   It's certainly still there.
[00:33:14.460 --> 00:33:15.660]   And certainly if it's very bright,
[00:33:15.660 --> 00:33:18.440]   it'll be more effective in driving the system
[00:33:18.440 --> 00:33:20.060]   than dim blue light would be.
[00:33:20.060 --> 00:33:20.900]   - Interesting.
[00:33:20.900 --> 00:33:22.520]   A lot of people wear blue blockers.
[00:33:22.520 --> 00:33:28.480]   And in a kind of odd twist of misinformation out there,
[00:33:28.480 --> 00:33:29.720]   a lot of people wear blue blockers
[00:33:29.720 --> 00:33:31.200]   during the middle of the day,
[00:33:31.200 --> 00:33:32.920]   which basically makes no sense
[00:33:32.920 --> 00:33:34.060]   because during the middle of the day
[00:33:34.060 --> 00:33:36.880]   is when you want to get a lot of bright light
[00:33:36.880 --> 00:33:39.420]   and including blue light into your eyes, correct?
[00:33:39.420 --> 00:33:40.260]   - Absolutely.
[00:33:40.260 --> 00:33:42.700]   Not just for the reasons we've been talking about
[00:33:42.700 --> 00:33:44.540]   in terms of circadian effects.
[00:33:44.540 --> 00:33:47.060]   There are major effects of light on mood
[00:33:47.060 --> 00:33:51.060]   and seasonal affective disorder
[00:33:51.060 --> 00:33:53.660]   apparently is essentially a reflection
[00:33:53.660 --> 00:33:55.820]   of this same system in reverse.
[00:33:55.820 --> 00:33:58.700]   If you're living in the Northern climes
[00:33:58.700 --> 00:34:00.620]   and you're not getting that much light
[00:34:00.620 --> 00:34:03.600]   during the middle of the winter in Stockholm,
[00:34:03.600 --> 00:34:06.580]   you might be prone to depression
[00:34:06.580 --> 00:34:09.420]   and phototherapy might be just the ticket for you.
[00:34:09.420 --> 00:34:13.620]   And that's because there's a direct effect of light on mood.
[00:34:13.620 --> 00:34:16.460]   There's an example where if you don't have enough light,
[00:34:16.460 --> 00:34:17.660]   it's a problem.
[00:34:17.660 --> 00:34:18.700]   So I think you're exactly right.
[00:34:18.700 --> 00:34:20.380]   It's not about is light good or bad for you?
[00:34:20.380 --> 00:34:22.780]   It's about what kind of light and when
[00:34:22.780 --> 00:34:25.440]   that makes the difference.
[00:34:25.440 --> 00:34:27.260]   - Yeah, the general rule of thumb that I've been living by
[00:34:27.260 --> 00:34:29.100]   is to get as much bright light in my eyes,
[00:34:29.100 --> 00:34:31.220]   ideally from sunlight,
[00:34:31.220 --> 00:34:32.900]   anytime I want to be alert
[00:34:32.900 --> 00:34:36.260]   and doing exactly the opposite when I want to be asleep
[00:34:36.260 --> 00:34:37.100]   or getting drowsy.
[00:34:37.100 --> 00:34:40.820]   - And there are aspects of this that spin out
[00:34:40.820 --> 00:34:42.620]   way beyond the conversation we're having now
[00:34:42.620 --> 00:34:44.320]   to things like this.
[00:34:44.320 --> 00:34:47.540]   It turns out that the incidence of myopia-
[00:34:47.540 --> 00:34:48.640]   - Nearsightedness.
[00:34:48.640 --> 00:34:50.780]   - Nearsightedness, right,
[00:34:50.780 --> 00:34:53.560]   is strongly related to the amount of time
[00:34:53.560 --> 00:34:56.140]   that kids spend outdoors.
[00:34:56.140 --> 00:34:57.740]   - In what direction of effect?
[00:34:57.740 --> 00:34:59.800]   - The more they spend time outdoors,
[00:34:59.800 --> 00:35:02.120]   the less nearsightedness they have.
[00:35:02.120 --> 00:35:02.960]   So this is all about-
[00:35:02.960 --> 00:35:04.460]   - And is that because they're viewing things at a distance
[00:35:04.460 --> 00:35:06.540]   or because they're getting a lot of blue light,
[00:35:06.540 --> 00:35:07.360]   less sunlight?
[00:35:07.360 --> 00:35:08.300]   - It's a great question.
[00:35:08.300 --> 00:35:11.620]   It is not fully resolved what the epidemiological,
[00:35:11.620 --> 00:35:14.380]   what the basis of that epidemiological finding is.
[00:35:14.380 --> 00:35:16.180]   One possibility is the amount of light,
[00:35:16.180 --> 00:35:17.660]   which would make me think about this
[00:35:17.660 --> 00:35:19.960]   melanopsin system again,
[00:35:19.960 --> 00:35:22.700]   but it might very well be a question of accommodation
[00:35:22.700 --> 00:35:24.380]   that is the process by which you focus on
[00:35:24.380 --> 00:35:25.960]   near or far things.
[00:35:25.960 --> 00:35:28.360]   If you're never outdoors, everything is nearby.
[00:35:28.360 --> 00:35:30.340]   If you're outdoors, you're focusing far.
[00:35:30.340 --> 00:35:31.580]   - Unless you're on your phone.
[00:35:31.580 --> 00:35:32.900]   - Right, exactly.
[00:35:32.900 --> 00:35:36.060]   - There's a tremendous amount of interest these days
[00:35:36.060 --> 00:35:39.580]   in watches and things that count steps.
[00:35:39.580 --> 00:35:41.740]   I'm beginning to realize that we should probably
[00:35:41.740 --> 00:35:45.920]   have a device that can count photons during the day
[00:35:45.920 --> 00:35:47.620]   and can also count photons at night
[00:35:47.620 --> 00:35:49.420]   and tell us, hey, you're getting too many photons.
[00:35:49.420 --> 00:35:51.040]   You're going to shut down your melatonin at night,
[00:35:51.040 --> 00:35:52.360]   or you're not getting enough photons.
[00:35:52.360 --> 00:35:53.900]   Today, you didn't get enough bright light,
[00:35:53.900 --> 00:35:56.740]   whether or not it's from artificial light or from sunlight.
[00:35:56.740 --> 00:35:58.020]   I guess the, where would you put it?
[00:35:58.020 --> 00:35:59.180]   I guess you put it on the top of your head,
[00:35:59.180 --> 00:36:02.620]   or you'd probably want it someplace outward facing.
[00:36:02.620 --> 00:36:05.580]   - Right, probably what you need is as many photons
[00:36:05.580 --> 00:36:07.260]   over as much of the retina as possible
[00:36:07.260 --> 00:36:11.380]   to recruit as much of this system as possible.
[00:36:11.380 --> 00:36:12.620]   - In thinking about other effects
[00:36:12.620 --> 00:36:15.180]   of this non-image forming pathway
[00:36:15.180 --> 00:36:19.800]   that involves these special cells in the eye and the SCN,
[00:36:19.800 --> 00:36:21.580]   you had a paper a few years ago
[00:36:21.580 --> 00:36:26.580]   looking at retinal input to an area of the brain,
[00:36:26.580 --> 00:36:30.780]   which has a fancy name, the perihabenula,
[00:36:30.780 --> 00:36:33.020]   but names don't necessarily matter,
[00:36:33.020 --> 00:36:36.380]   that had some important effects on mood
[00:36:36.380 --> 00:36:39.440]   and other aspects of light.
[00:36:39.440 --> 00:36:40.740]   Maybe you could tell us a little bit about
[00:36:40.740 --> 00:36:42.780]   what is the perihabenula?
[00:36:42.780 --> 00:36:45.100]   - Oh, wow, so that's a fancy term,
[00:36:45.100 --> 00:36:47.040]   but I think the way to think about this
[00:36:47.040 --> 00:36:51.260]   is as a chunk of the brain that is sitting
[00:36:51.260 --> 00:36:55.420]   as part of a bigger chunk that's really the linker
[00:36:55.420 --> 00:36:58.220]   between peripheral sensory input of all kinds,
[00:36:58.220 --> 00:37:02.780]   virtually all kinds, whether it's auditory input
[00:37:02.780 --> 00:37:07.060]   or tactile input or visual input
[00:37:07.060 --> 00:37:09.220]   to the region of your brain, the cortex,
[00:37:09.220 --> 00:37:11.080]   that allows you to think about these things
[00:37:11.080 --> 00:37:13.740]   and make plans around them and to integrate them
[00:37:13.740 --> 00:37:15.000]   and that kind of thing.
[00:37:15.000 --> 00:37:21.900]   So we've known about a pathway that gets from the retina
[00:37:21.900 --> 00:37:27.900]   through this sort of linker center,
[00:37:27.900 --> 00:37:31.460]   it's called the thalamus, and then on up to the cortex.
[00:37:31.460 --> 00:37:34.460]   - Exactly, but you want to arrive at the destination, right?
[00:37:34.460 --> 00:37:36.740]   Now you're at grand central and now you can do your thing
[00:37:36.740 --> 00:37:38.340]   'cause you're up at the cortex.
[00:37:38.340 --> 00:37:40.100]   So this is the standard pattern.
[00:37:40.100 --> 00:37:41.860]   You have the sensory input coming from the periphery,
[00:37:41.860 --> 00:37:43.380]   you've got these peripheral elements
[00:37:43.380 --> 00:37:45.980]   that are doing the initial stages of-
[00:37:45.980 --> 00:37:47.520]   - The eye, the ear, the nose.
[00:37:47.520 --> 00:37:49.820]   - The eye, the skin of your fingertips, right?
[00:37:49.820 --> 00:37:51.520]   No, the taste buds on your tongue,
[00:37:51.520 --> 00:37:53.480]   they're taking this raw information in
[00:37:53.480 --> 00:37:56.860]   and they're doing some pre-processing maybe
[00:37:56.860 --> 00:37:58.900]   or the early circuits are,
[00:37:58.900 --> 00:38:00.420]   but eventually most of these signals
[00:38:00.420 --> 00:38:02.660]   have to pass through the gateway to the cortex,
[00:38:02.660 --> 00:38:04.660]   which is the thalamus.
[00:38:04.660 --> 00:38:09.160]   And we've known for years, for decades, many decades,
[00:38:09.160 --> 00:38:11.100]   what the major throughput pathway
[00:38:11.100 --> 00:38:14.500]   from the retina to the cortex is and where it ends up.
[00:38:14.500 --> 00:38:15.820]   It ends up in the visual cortex.
[00:38:15.820 --> 00:38:17.300]   You pat the back of your head,
[00:38:17.300 --> 00:38:20.820]   that's where the receiving center is
[00:38:20.820 --> 00:38:23.840]   for the main pathway from retina to cortex.
[00:38:23.840 --> 00:38:25.700]   But wait a minute, there's more.
[00:38:25.700 --> 00:38:27.540]   There's this little side pathway
[00:38:27.540 --> 00:38:30.340]   that goes through a different part of that linking
[00:38:30.340 --> 00:38:32.660]   thalamus center, the gateway to the cortex.
[00:38:32.660 --> 00:38:34.900]   - It's like a local train from Grand Central to-
[00:38:34.900 --> 00:38:37.580]   - It's in a weird part of the neighborhood, right?
[00:38:37.580 --> 00:38:38.700]   It's a completely different,
[00:38:38.700 --> 00:38:41.580]   it's like a little trunk line that branches off
[00:38:41.580 --> 00:38:43.620]   and goes out into the hinterlands
[00:38:43.620 --> 00:38:46.460]   and it's going to the part of this linker center
[00:38:46.460 --> 00:38:48.820]   that's talking to a completely different part of cortex,
[00:38:48.820 --> 00:38:51.300]   way up front, frontal lobe,
[00:38:51.300 --> 00:38:54.140]   which is much more involved in things like planning
[00:38:54.140 --> 00:38:57.660]   or self-image or-
[00:38:57.660 --> 00:39:01.020]   - Self-image, literally how one thinks about oneself.
[00:39:01.020 --> 00:39:02.920]   - Do you feel good about yourself?
[00:39:02.920 --> 00:39:06.480]   Or what's your plan for next Thursday?
[00:39:06.480 --> 00:39:11.020]   It's a very high level center
[00:39:11.020 --> 00:39:13.580]   in the highest level of your nervous system.
[00:39:13.580 --> 00:39:16.060]   And this is the region that is getting input
[00:39:16.060 --> 00:39:18.980]   from this pathway, which is mostly worked out
[00:39:18.980 --> 00:39:21.340]   in this function by Samer Hatara's lab.
[00:39:21.340 --> 00:39:23.220]   I know you had him on the podcast.
[00:39:23.220 --> 00:39:24.220]   - We didn't talk about this pathway.
[00:39:24.220 --> 00:39:25.660]   - This pathway at all, right.
[00:39:25.660 --> 00:39:30.660]   So, Diego Fernandez and Samer and the folks
[00:39:30.660 --> 00:39:33.100]   that work with them were able to show
[00:39:33.100 --> 00:39:35.020]   that this pathway doesn't just exist
[00:39:35.020 --> 00:39:37.140]   and get you to a weird place.
[00:39:37.140 --> 00:39:41.940]   But if you activate it at kind of the wrong time of day,
[00:39:41.940 --> 00:39:45.360]   animals can become depressed.
[00:39:45.360 --> 00:39:48.740]   And if you silence it under the right circumstances,
[00:39:48.740 --> 00:39:52.000]   then weird lighting cycles that would normally
[00:39:52.000 --> 00:39:55.560]   make them act sort of depressed,
[00:39:55.560 --> 00:39:57.520]   no longer have that effect.
[00:39:57.520 --> 00:39:59.240]   - So, it sounds to me like there's this pathway
[00:39:59.240 --> 00:40:03.740]   from I to this unusual train route
[00:40:03.740 --> 00:40:06.740]   through the structure we call the thalamus,
[00:40:06.740 --> 00:40:08.780]   then up to the front of the brain that relates
[00:40:08.780 --> 00:40:13.360]   to things of self-perception, kind of higher level functions.
[00:40:13.360 --> 00:40:14.980]   I find that really interesting because most
[00:40:14.980 --> 00:40:17.740]   of what I think about when I think about these fancy,
[00:40:17.740 --> 00:40:20.860]   well, or these primitive, rather, neurons
[00:40:20.860 --> 00:40:22.840]   that don't pay attention to the shapes of things,
[00:40:22.840 --> 00:40:24.800]   but instead to brightness, I think of,
[00:40:24.800 --> 00:40:28.780]   well, it regulates melatonin, circadian clock, mood, hunger,
[00:40:28.780 --> 00:40:32.540]   the really kind of vegetative stuff, if you will.
[00:40:32.540 --> 00:40:35.480]   And this is interesting because I think a lot
[00:40:35.480 --> 00:40:38.480]   of people experience depression, not just people
[00:40:38.480 --> 00:40:42.120]   that live in Scandinavia in the middle of winter.
[00:40:42.120 --> 00:40:45.080]   And we are very much divorced
[00:40:45.080 --> 00:40:47.800]   from our normal interactions with light.
[00:40:47.800 --> 00:40:49.780]   It also makes me realize
[00:40:49.780 --> 00:40:52.220]   that these intrinsically photosensitive cells
[00:40:52.220 --> 00:40:55.400]   that set the clock, et cetera, are involved
[00:40:55.400 --> 00:40:56.620]   in a lot of things.
[00:40:56.620 --> 00:40:59.760]   I mean, they seem to regulate a dozen
[00:40:59.760 --> 00:41:01.500]   or more different basic functions.
[00:41:01.500 --> 00:41:05.200]   I want to ask you about a different aspect
[00:41:05.200 --> 00:41:08.300]   of the visual system now, which is the one
[00:41:08.300 --> 00:41:10.880]   that relates to our sense of balance.
[00:41:10.880 --> 00:41:13.700]   So, I love boats, but I hate being on them.
[00:41:13.700 --> 00:41:18.280]   I love the ocean from shore because I get incredibly seasick.
[00:41:18.280 --> 00:41:19.540]   I'll just, it's awful.
[00:41:19.540 --> 00:41:22.060]   I think I'm gonna get seasick if I think about it too much.
[00:41:22.060 --> 00:41:23.920]   And once I went on a boat trip, I came back
[00:41:23.920 --> 00:41:27.380]   and I actually got, I got motion sick
[00:41:27.380 --> 00:41:30.260]   or wasn't seasick 'cause I went rafting.
[00:41:30.260 --> 00:41:33.520]   So, there's a system that somehow gets messed up.
[00:41:33.520 --> 00:41:34.720]   They always tell us if you're feeling sick
[00:41:34.720 --> 00:41:37.320]   to look at the horizon, et cetera, et cetera.
[00:41:37.320 --> 00:41:39.480]   So, what is the link between our visual system
[00:41:39.480 --> 00:41:40.700]   and our balance system?
[00:41:40.700 --> 00:41:43.320]   And why does it make us nauseous sometimes
[00:41:43.320 --> 00:41:45.640]   when the world is moving in a way
[00:41:45.640 --> 00:41:47.360]   that we're not accustomed to?
[00:41:47.360 --> 00:41:48.880]   I realize this is a big question
[00:41:48.880 --> 00:41:51.600]   because it involves eye movement, et cetera.
[00:41:51.600 --> 00:41:56.320]   But let's maybe just walk in at the simplest layers
[00:41:56.320 --> 00:42:01.320]   of vision, vestibular, so-called balance system,
[00:42:01.320 --> 00:42:04.320]   and then maybe we can piece the system together for people
[00:42:04.320 --> 00:42:05.160]   so that they can understand.
[00:42:05.160 --> 00:42:06.880]   And then also we should give them some tools
[00:42:06.880 --> 00:42:08.640]   for adjusting their nausea
[00:42:08.640 --> 00:42:12.000]   when their vestibular system is out of whack.
[00:42:12.000 --> 00:42:14.460]   - Cool, so, I mean, the first thing to think about
[00:42:14.460 --> 00:42:19.460]   is that the vestibular system is designed to allow you
[00:42:20.460 --> 00:42:25.460]   to see how your, or detect, sense how you're moving
[00:42:25.460 --> 00:42:29.020]   in the world, through the world.
[00:42:29.020 --> 00:42:34.360]   It's a funny one because it's about your movement
[00:42:34.360 --> 00:42:36.300]   in relationship to the world in a sense,
[00:42:36.300 --> 00:42:39.460]   and yet it's sort of interoceptive in the sense
[00:42:39.460 --> 00:42:44.460]   that it is really in the end sensing the movement
[00:42:44.460 --> 00:42:46.180]   of your own body.
[00:42:46.180 --> 00:42:48.120]   - Okay, so, interoception we should probably delineate
[00:42:48.120 --> 00:42:50.660]   for people is when you're focusing on your internal state
[00:42:50.660 --> 00:42:52.140]   as opposed to something outside you.
[00:42:52.140 --> 00:42:52.980]   - Right.
[00:42:52.980 --> 00:42:55.280]   - But it's a gravity sensing system.
[00:42:55.280 --> 00:42:57.540]   - Well, it's partly a gravity sensing system
[00:42:57.540 --> 00:43:02.540]   in the sense that gravity is a force that's acting on you
[00:43:02.540 --> 00:43:05.380]   as if you were moving through the world
[00:43:05.380 --> 00:43:06.860]   in the opposite direction.
[00:43:06.860 --> 00:43:10.440]   - All right, now you gotta explain that one to me.
[00:43:10.440 --> 00:43:12.920]   - Okay, so basically the idea is that
[00:43:12.920 --> 00:43:16.840]   if we leave gravity aside,
[00:43:16.840 --> 00:43:21.820]   we're just sitting in a car in the passenger seat
[00:43:21.820 --> 00:43:24.500]   and the driver hits the accelerator
[00:43:24.500 --> 00:43:26.740]   and you start moving forward, you sense that.
[00:43:26.740 --> 00:43:28.420]   If your eyes were closed, you'd sense it.
[00:43:28.420 --> 00:43:30.580]   If your ears were plugged and your eyes were closed,
[00:43:30.580 --> 00:43:31.740]   you'd still know it.
[00:43:31.740 --> 00:43:33.900]   - Yeah, many people take off on the plane like this,
[00:43:33.900 --> 00:43:35.100]   they're dreading the flight
[00:43:35.100 --> 00:43:36.900]   and they know when the plane is taking off.
[00:43:36.900 --> 00:43:38.920]   - Sure, that's your vestibular system talking
[00:43:38.920 --> 00:43:40.900]   because anything that jostles you
[00:43:40.900 --> 00:43:43.100]   out of the current position you're in right now
[00:43:43.100 --> 00:43:46.640]   will be detected by the vestibular system, pretty much.
[00:43:46.640 --> 00:43:49.600]   So this is a complicated system,
[00:43:49.600 --> 00:43:52.840]   but it's basically in your inner ear,
[00:43:52.840 --> 00:43:54.240]   very close to where you're hearing.
[00:43:54.240 --> 00:43:55.580]   - Right, they put it there.
[00:43:55.580 --> 00:43:57.880]   And I don't know who they is.
[00:43:57.880 --> 00:44:00.280]   - I don't really know, they're starting to ride.
[00:44:00.280 --> 00:44:01.400]   - I'm just kidding.
[00:44:01.400 --> 00:44:03.960]   To steal our friend Russ Van Gelder's explanation,
[00:44:03.960 --> 00:44:06.560]   we weren't consulted the design phase and no one-
[00:44:06.560 --> 00:44:08.760]   - That's a great line, that's a great line.
[00:44:08.760 --> 00:44:11.880]   - But it's interesting, it's in the ear.
[00:44:11.880 --> 00:44:14.660]   - Yeah, yeah, it's deep in there
[00:44:14.660 --> 00:44:18.520]   and it's served by the same nerve actually
[00:44:18.520 --> 00:44:20.620]   that serves the hearing system.
[00:44:20.620 --> 00:44:23.420]   One way to think about it is both the hearing system
[00:44:23.420 --> 00:44:26.880]   and the vestibular self-motion sensing system
[00:44:26.880 --> 00:44:29.320]   are really detecting the signal in the same way.
[00:44:29.320 --> 00:44:32.400]   They're hairy cells and they're excited.
[00:44:32.400 --> 00:44:33.240]   - Really hairy?
[00:44:33.240 --> 00:44:35.320]   - Yeah, sort of, they got little cilia sticking up
[00:44:35.320 --> 00:44:36.820]   off the surfaces.
[00:44:36.820 --> 00:44:38.720]   And depending on which way you bend those,
[00:44:38.720 --> 00:44:41.100]   the cells will either be inhibited or excited.
[00:44:41.100 --> 00:44:44.080]   They're not even neurons, but then they talk to neurons
[00:44:44.080 --> 00:44:46.140]   with a neuron-like process and off you go.
[00:44:46.140 --> 00:44:47.560]   Now you've got an auditory signal
[00:44:47.560 --> 00:44:51.480]   if you're sensing things bouncing around in your cochlea,
[00:44:51.480 --> 00:44:52.320]   which is-
[00:44:52.320 --> 00:44:53.160]   - Sound waves.
[00:44:53.160 --> 00:44:55.760]   - Sympathetically the bouncing of your eardrum,
[00:44:55.760 --> 00:44:58.800]   which is sympathetically the sound waves in the world.
[00:44:58.800 --> 00:45:01.280]   But in the case of the vestibular apparatus,
[00:45:01.280 --> 00:45:04.500]   evolution has built a system that detects the motion
[00:45:04.500 --> 00:45:07.880]   of say fluid going by those hairs.
[00:45:07.880 --> 00:45:11.300]   And if you put a sensor like that in a tube
[00:45:11.300 --> 00:45:14.040]   that's fluid-filled, now you've got a sensor
[00:45:14.040 --> 00:45:17.940]   that will be activated when you rotate that tube
[00:45:17.940 --> 00:45:20.020]   around the axis that passes through the middle of it.
[00:45:20.020 --> 00:45:22.420]   Those who were just listening won't be able to visualize.
[00:45:22.420 --> 00:45:23.380]   - No, I think that makes sense.
[00:45:23.380 --> 00:45:25.420]   I was thinking of it as three hula hoops.
[00:45:25.420 --> 00:45:26.260]   - Right, three hula hoops.
[00:45:26.260 --> 00:45:28.300]   - One standing up, one lying down on the ground.
[00:45:28.300 --> 00:45:31.680]   - Right, one in the other direction, three directions.
[00:45:31.680 --> 00:45:35.080]   The people who fly will talk about roll, pitch, and yaw,
[00:45:35.080 --> 00:45:35.920]   that kind of thing.
[00:45:35.920 --> 00:45:39.260]   So the three axes of encoding,
[00:45:39.260 --> 00:45:40.080]   just like in the cones of the retina.
[00:45:40.080 --> 00:45:43.220]   - Sort of the yes, the no, and then I always say it's,
[00:45:43.220 --> 00:45:44.380]   and then the puppy head tilt.
[00:45:44.380 --> 00:45:46.700]   - Yeah, the puppy head tilt, that's the other one.
[00:45:46.700 --> 00:45:50.320]   So the point is that your brain is eventually going to be
[00:45:50.320 --> 00:45:54.620]   able to unpack what these sensors are telling you
[00:45:54.620 --> 00:45:57.100]   about how you just rotated your head
[00:45:57.100 --> 00:45:59.460]   in very much the way that the three types of cones
[00:45:59.460 --> 00:46:04.460]   we were talking about before are reading the incoming photons
[00:46:04.860 --> 00:46:06.840]   in the wavelength domain differently.
[00:46:06.840 --> 00:46:09.940]   And if you can compare and trust, you get red, green, blue.
[00:46:09.940 --> 00:46:11.680]   So it's the same basic idea.
[00:46:11.680 --> 00:46:14.600]   If you have three sensors and you array them properly,
[00:46:14.600 --> 00:46:16.680]   now you can tell if you're rotating your head
[00:46:16.680 --> 00:46:18.460]   left or right, up or down.
[00:46:18.460 --> 00:46:22.440]   That's the sensory signal coming back into your brain,
[00:46:22.440 --> 00:46:26.560]   confirming that you've just made a movement that you will.
[00:46:26.560 --> 00:46:27.700]   - But what about on the plane?
[00:46:27.700 --> 00:46:29.720]   Because when I'm on the plane, I'm completely stationary.
[00:46:29.720 --> 00:46:32.440]   The plane's moving, but my head hasn't moved.
[00:46:32.440 --> 00:46:35.420]   So I'm just moving forward, gravity is constant.
[00:46:35.420 --> 00:46:36.260]   - Exactly.
[00:46:36.260 --> 00:46:37.880]   - How do I know I'm accelerating?
[00:46:37.880 --> 00:46:39.640]   - So what's happening now is your brain
[00:46:39.640 --> 00:46:44.640]   is sensing the motion and the brain is smart enough also
[00:46:44.640 --> 00:46:48.580]   to ask itself, did I will that movement
[00:46:48.580 --> 00:46:50.560]   or did that come from the outside?
[00:46:50.560 --> 00:46:52.520]   So now in terms of sort of understanding
[00:46:52.520 --> 00:46:54.680]   what the distributor signal means,
[00:46:54.680 --> 00:46:56.300]   it's gotta be embedded in the context
[00:46:56.300 --> 00:47:01.160]   of what you tried to do or what your other sensory systems
[00:47:01.160 --> 00:47:02.680]   are telling you about what's happening right now.
[00:47:02.680 --> 00:47:06.600]   - I see, so it's very interesting, but it's not conscious.
[00:47:06.600 --> 00:47:09.400]   Or at least if it's conscious, it's not conscious,
[00:47:09.400 --> 00:47:11.520]   it's definitely very fast, right?
[00:47:11.520 --> 00:47:12.840]   The moment that plane starts moving,
[00:47:12.840 --> 00:47:14.480]   I know that I didn't get up out of my chair
[00:47:14.480 --> 00:47:15.320]   and run forward.
[00:47:15.320 --> 00:47:16.160]   - Right.
[00:47:16.160 --> 00:47:17.280]   - But I'm not really thinking about
[00:47:17.280 --> 00:47:18.580]   getting up out of my chair.
[00:47:18.580 --> 00:47:19.420]   I just know.
[00:47:19.420 --> 00:47:20.440]   - I guess the way I think about it
[00:47:20.440 --> 00:47:25.440]   is that the nervous system is "aware" at many levels.
[00:47:25.440 --> 00:47:29.000]   When it gets all the way up to the cortex
[00:47:29.000 --> 00:47:30.420]   and we're thinking about it,
[00:47:30.420 --> 00:47:34.140]   you're talking about it, that's cortical.
[00:47:34.140 --> 00:47:37.380]   But the lower levels of the brain
[00:47:37.380 --> 00:47:40.400]   that don't require you to actually actively think about it,
[00:47:40.400 --> 00:47:42.320]   they're just doing their thing,
[00:47:42.320 --> 00:47:44.040]   are also made aware, right?
[00:47:44.040 --> 00:47:45.880]   A lot of this is happening under the surface
[00:47:45.880 --> 00:47:47.080]   of what you're thinking.
[00:47:47.080 --> 00:47:48.760]   These are reflexes.
[00:47:48.760 --> 00:47:52.440]   - Okay, so we've got this gravity sensing system.
[00:47:52.440 --> 00:47:53.280]   - Right.
[00:47:53.280 --> 00:47:57.100]   - I'm nodding for those that are listening
[00:47:57.100 --> 00:47:59.180]   for a yes movement of the head,
[00:47:59.180 --> 00:48:00.360]   a no movement of the head
[00:48:00.360 --> 00:48:02.720]   or the tilting of the head from side to side.
[00:48:02.720 --> 00:48:03.560]   - Right.
[00:48:03.560 --> 00:48:04.840]   - And then you said that knowledge about
[00:48:04.840 --> 00:48:07.400]   whether or not activation of that system
[00:48:07.400 --> 00:48:08.960]   comes from my own movements
[00:48:08.960 --> 00:48:12.520]   or something acting upon me, like the plane moving,
[00:48:12.520 --> 00:48:15.640]   has to be combined with other signals.
[00:48:15.640 --> 00:48:19.600]   And so how is the visual information
[00:48:19.600 --> 00:48:21.040]   or information about the visual world
[00:48:21.040 --> 00:48:22.880]   combined with balance information?
[00:48:22.880 --> 00:48:23.720]   - Right.
[00:48:23.720 --> 00:48:26.560]   So, yeah, I mean, I guess maybe the best way
[00:48:26.560 --> 00:48:29.940]   to think about how these two systems work together
[00:48:29.940 --> 00:48:31.060]   is to think about what happens
[00:48:31.060 --> 00:48:34.020]   when you suddenly rotate your head to the left.
[00:48:34.020 --> 00:48:36.620]   When you suddenly rotate your head to the left,
[00:48:36.620 --> 00:48:40.820]   your eyes are actually rotating to the right automatically.
[00:48:40.820 --> 00:48:43.260]   You do this in complete darkness.
[00:48:43.260 --> 00:48:48.100]   If you had an infrared camera and watched yourself
[00:48:48.100 --> 00:48:49.780]   in complete darkness, you can't see anything.
[00:48:49.780 --> 00:48:50.780]   Rotating your head to the left,
[00:48:50.780 --> 00:48:52.460]   your eyes would rotate to the right.
[00:48:52.460 --> 00:48:54.420]   That's your vestibular system saying,
[00:48:56.340 --> 00:49:00.960]   I'm gonna try to compensate for the head rotation
[00:49:00.960 --> 00:49:04.160]   so my eyes are still looking in the same place.
[00:49:04.160 --> 00:49:05.240]   Why is that useful?
[00:49:05.240 --> 00:49:08.400]   Well, if it's always doing that,
[00:49:08.400 --> 00:49:10.240]   then the image of the world on your retina
[00:49:10.240 --> 00:49:12.800]   will be pretty stable most of the time.
[00:49:12.800 --> 00:49:14.800]   And that actually helps vision.
[00:49:14.800 --> 00:49:18.280]   - Have they built this into cameras for image stabilization?
[00:49:18.280 --> 00:49:20.400]   'Cause when I move, when I take a picture with my phone,
[00:49:20.400 --> 00:49:22.460]   it's blurry, it's not clear.
[00:49:22.460 --> 00:49:25.600]   - Well, actually, you might wanna get a better phone
[00:49:25.600 --> 00:49:29.680]   because now what they have is software in the better apps
[00:49:29.680 --> 00:49:32.640]   that will do a kind of image stabilization post hoc
[00:49:32.640 --> 00:49:34.480]   by doing a registration of the images
[00:49:34.480 --> 00:49:35.760]   that are bouncing around.
[00:49:35.760 --> 00:49:38.240]   They say the edge of the house was here,
[00:49:38.240 --> 00:49:40.580]   so let's get that aligned at each of your images.
[00:49:40.580 --> 00:49:44.760]   So you may not be aware if you're using a good new phone
[00:49:44.760 --> 00:49:49.760]   that if you walk around a landscape and hold your phone,
[00:49:49.760 --> 00:49:52.980]   that there's all this image stabilization going on.
[00:49:52.980 --> 00:49:57.980]   But it's built into standard cinematic technology now
[00:49:57.980 --> 00:50:00.200]   because if you tried to do a handheld camera,
[00:50:00.200 --> 00:50:02.800]   things would be bouncing around, things would be unwatchable.
[00:50:02.800 --> 00:50:04.160]   You wouldn't be able to really understand
[00:50:04.160 --> 00:50:05.560]   what's going on in the scene.
[00:50:05.560 --> 00:50:08.720]   So the brain works really hard
[00:50:08.720 --> 00:50:12.200]   to mostly stabilize the image of the world on your retina.
[00:50:12.200 --> 00:50:13.500]   Of course, you're moving through the world,
[00:50:13.500 --> 00:50:14.880]   so you can't stabilize everything.
[00:50:14.880 --> 00:50:17.740]   But the more you can stabilize most of the time,
[00:50:17.740 --> 00:50:19.060]   the better you can see.
[00:50:19.060 --> 00:50:22.000]   And that's why when we're scanning a scene,
[00:50:22.840 --> 00:50:24.600]   looking around at things,
[00:50:24.600 --> 00:50:26.840]   we're making very rapid eye movements
[00:50:26.840 --> 00:50:30.440]   for very short periods of time, and then we just rest.
[00:50:30.440 --> 00:50:31.940]   But we're not the only ones that do that.
[00:50:31.940 --> 00:50:33.120]   If you ever watch a hummingbird,
[00:50:33.120 --> 00:50:35.540]   it does exactly the same thing at a feeder, right?
[00:50:35.540 --> 00:50:37.040]   But it's with its body.
[00:50:37.040 --> 00:50:38.680]   It's gonna make a quick movement,
[00:50:38.680 --> 00:50:41.460]   and then it's gonna be stable.
[00:50:41.460 --> 00:50:44.520]   And when you watch a pigeon walking on the sidewalk,
[00:50:44.520 --> 00:50:46.160]   it does this funny head bobbing thing.
[00:50:46.160 --> 00:50:48.820]   But what it's really doing is racking its head back
[00:50:48.820 --> 00:50:51.260]   on its neck while its body goes forward
[00:50:51.260 --> 00:50:54.380]   so that the image of the visual world stays static.
[00:50:54.380 --> 00:50:55.860]   Is that why they're doing it?
[00:50:55.860 --> 00:50:56.820]   Yes.
[00:50:56.820 --> 00:50:59.540]   And you've seen the funny chicken videos on YouTube, right?
[00:50:59.540 --> 00:51:01.060]   You take a chicken, move it up and down,
[00:51:01.060 --> 00:51:02.140]   the head stays in one place.
[00:51:02.140 --> 00:51:03.700]   It's all the same thing.
[00:51:03.700 --> 00:51:06.200]   All of these animals are trying hard
[00:51:06.200 --> 00:51:08.820]   to keep the image of the world stable on their retina
[00:51:08.820 --> 00:51:10.880]   as much of the time as they possibly can.
[00:51:10.880 --> 00:51:13.340]   And then when they've got to move, make it fast,
[00:51:13.340 --> 00:51:15.460]   make it quick, and then stabilize again.
[00:51:15.460 --> 00:51:16.900]   That's why the pigeons have their head back?
[00:51:16.900 --> 00:51:18.060]   It is, yeah.
[00:51:18.060 --> 00:51:19.340]   Wow.
[00:51:19.340 --> 00:51:20.180]   Yeah.
[00:51:20.180 --> 00:51:23.200]   I just need to pause there for a second and digest that.
[00:51:23.200 --> 00:51:24.040]   Amazing.
[00:51:24.040 --> 00:51:28.440]   In case people aren't, well,
[00:51:28.440 --> 00:51:30.060]   there's no reason why people would know
[00:51:30.060 --> 00:51:30.900]   what we're doing here,
[00:51:30.900 --> 00:51:32.740]   but essentially what we're doing is we're building up
[00:51:32.740 --> 00:51:36.780]   from sensory, you know, light onto the eye, color,
[00:51:36.780 --> 00:51:39.060]   to what the brain does with that,
[00:51:39.060 --> 00:51:40.520]   the integration of that, you know,
[00:51:40.520 --> 00:51:42.100]   circadian clock, melatonin, et cetera.
[00:51:42.100 --> 00:51:43.460]   And now what we're doing is we're talking about
[00:51:43.460 --> 00:51:45.800]   multi-sensory or multimodal,
[00:51:45.800 --> 00:51:50.560]   combining one sense vision with another sense balance.
[00:51:50.560 --> 00:51:53.600]   And it turns out that pigeons know more about this
[00:51:53.600 --> 00:51:56.240]   than I do because pigeons know to keep their head back
[00:51:56.240 --> 00:51:57.960]   as they walk forward.
[00:51:57.960 --> 00:52:02.520]   All right, so that gets us to this issue of motion sickness.
[00:52:02.520 --> 00:52:05.680]   And you don't have to go out on a boat.
[00:52:05.680 --> 00:52:06.900]   Anytime I go to New York,
[00:52:06.900 --> 00:52:09.440]   I sit in an Uber or in a cab in the back.
[00:52:09.440 --> 00:52:13.220]   And if I'm looking at my phone while the car is driving,
[00:52:13.220 --> 00:52:17.020]   I feel nauseous by time I arrive at my destination.
[00:52:17.020 --> 00:52:19.380]   I always try and look out the front of the windshield
[00:52:19.380 --> 00:52:20.620]   because I'm told that helps,
[00:52:20.620 --> 00:52:22.800]   but it's a little tiny window.
[00:52:22.800 --> 00:52:26.960]   And I end up feeling slightly less sick if I do that.
[00:52:26.960 --> 00:52:31.960]   So what's going on with the vision and the balance system
[00:52:31.960 --> 00:52:34.300]   that causes a kind of a nausea?
[00:52:34.300 --> 00:52:35.820]   And actually, if I keep talking about this,
[00:52:35.820 --> 00:52:37.220]   I probably will get sick.
[00:52:37.220 --> 00:52:38.300]   I don't throw up easily,
[00:52:38.300 --> 00:52:42.620]   but for some reason, motion sickness is a real thing for me.
[00:52:42.620 --> 00:52:44.340]   It's a problem for a lot of people.
[00:52:44.340 --> 00:52:47.120]   I mean, I think the fundamental problem typically
[00:52:47.120 --> 00:52:48.240]   when you get motion sick
[00:52:48.240 --> 00:52:52.760]   is what they call visual vestibular conflict.
[00:52:52.760 --> 00:52:55.360]   That is, you have two sensory systems
[00:52:55.360 --> 00:52:56.480]   that are talking to your brain
[00:52:56.480 --> 00:52:58.520]   about how you're moving through the world.
[00:52:58.520 --> 00:53:02.440]   And as long as they agree, you're fine.
[00:53:02.440 --> 00:53:04.320]   So if you're driving,
[00:53:04.320 --> 00:53:07.160]   your body senses that you're moving forward.
[00:53:07.160 --> 00:53:08.800]   Your vestibular systems
[00:53:08.800 --> 00:53:11.480]   is picking up this acceleration of the car.
[00:53:12.480 --> 00:53:14.900]   And your visual system is seeing the consequences
[00:53:14.900 --> 00:53:19.360]   of forward motion in the sweeping of the scene past you.
[00:53:19.360 --> 00:53:20.860]   Everything is honky-dory, right?
[00:53:20.860 --> 00:53:22.140]   No problem.
[00:53:22.140 --> 00:53:25.580]   But when you are headed forward,
[00:53:25.580 --> 00:53:26.880]   but you're looking at your cell phone,
[00:53:26.880 --> 00:53:28.000]   what is your retina seeing?
[00:53:28.000 --> 00:53:30.280]   Your retina is seeing the stable image of the screen.
[00:53:30.280 --> 00:53:33.560]   There's absolutely no motion in that screen.
[00:53:33.560 --> 00:53:35.740]   Or the motion is, or some other motion,
[00:53:35.740 --> 00:53:36.580]   like a movie or, yeah. Or it's a motion
[00:53:36.580 --> 00:53:37.940]   you're watching if you're playing a game,
[00:53:37.940 --> 00:53:40.400]   or you're watching a video, a football game.
[00:53:40.400 --> 00:53:43.360]   The motion is uncoupled with what's actually happening
[00:53:43.360 --> 00:53:44.300]   to your body.
[00:53:44.300 --> 00:53:45.560]   Your brain doesn't like that.
[00:53:45.560 --> 00:53:48.280]   Your brain likes everything to be aligned.
[00:53:48.280 --> 00:53:50.580]   And if it's not, it's going to complain to you.
[00:53:50.580 --> 00:53:51.420]   By making me feel nauseous.
[00:53:51.420 --> 00:53:52.420]   By making you feel nauseous,
[00:53:52.420 --> 00:53:53.880]   and maybe you'll change your behavior.
[00:53:53.880 --> 00:53:54.760]   So you're getting-
[00:53:54.760 --> 00:53:55.840]   I'm getting punished.
[00:53:55.840 --> 00:53:57.980]   Yeah, for setting it up
[00:53:57.980 --> 00:53:59.740]   so your signal's not going to flick, right.
[00:53:59.740 --> 00:54:01.120]   By the vestibular-
[00:54:01.120 --> 00:54:01.940]   You'll learn.
[00:54:01.940 --> 00:54:02.780]   Visuals.
[00:54:02.780 --> 00:54:06.400]   In time. I love it.
[00:54:06.400 --> 00:54:08.560]   I love the idea of reward signals.
[00:54:08.560 --> 00:54:10.280]   And we've done a lot of discussion
[00:54:10.280 --> 00:54:12.840]   about this on this podcast of things like dopamine reward
[00:54:12.840 --> 00:54:14.560]   and things, but also punishment signals.
[00:54:14.560 --> 00:54:17.120]   And I love this example.
[00:54:17.120 --> 00:54:20.440]   Well, maybe marching a little bit further
[00:54:20.440 --> 00:54:24.240]   along this pathway, visual input is combined
[00:54:24.240 --> 00:54:25.900]   with balance input.
[00:54:25.900 --> 00:54:28.320]   Where does that occur?
[00:54:28.320 --> 00:54:32.160]   And maybe, 'cause I have some hint of where it occurs,
[00:54:32.160 --> 00:54:34.200]   you could tell us a little bit about this
[00:54:34.200 --> 00:54:37.560]   kind of mysterious little mini brain
[00:54:37.560 --> 00:54:38.600]   that they call the cerebellum.
[00:54:38.600 --> 00:54:40.100]   Cerebellum, yeah.
[00:54:40.100 --> 00:54:43.760]   So, you know, the way I tried to describe the cerebellum
[00:54:43.760 --> 00:54:48.760]   to my students is that it serves sort of like
[00:54:48.760 --> 00:54:53.320]   the air traffic control system functions in air travel.
[00:54:53.320 --> 00:54:57.560]   So that it's a system that's very complicated
[00:54:57.560 --> 00:55:01.060]   and it's really dependent on great information.
[00:55:01.060 --> 00:55:02.620]   So it's taking in the information
[00:55:02.620 --> 00:55:04.620]   about everything that's happening everywhere,
[00:55:04.620 --> 00:55:07.640]   not only through your sensory systems,
[00:55:07.640 --> 00:55:10.520]   but it's listening in to all the little centers elsewhere
[00:55:10.520 --> 00:55:11.680]   in your brain that are computing
[00:55:11.680 --> 00:55:13.580]   what you're gonna be doing next and so forth.
[00:55:13.580 --> 00:55:15.780]   So it's just ravenous for that kind of information.
[00:55:15.780 --> 00:55:17.700]   So it really is like a little mini brain.
[00:55:17.700 --> 00:55:21.820]   It is, it's got access to all those signals.
[00:55:21.820 --> 00:55:25.460]   And it really has an important role
[00:55:25.460 --> 00:55:29.880]   in coordinating and shaping movements.
[00:55:29.880 --> 00:55:33.680]   But, you know, if you suddenly eliminated
[00:55:33.680 --> 00:55:36.460]   the air traffic control system,
[00:55:36.460 --> 00:55:38.940]   planes could still take off and land,
[00:55:38.940 --> 00:55:43.940]   but you might have some unhappy accidents in the process.
[00:55:43.940 --> 00:55:45.860]   So the cerebellum is kind of like that.
[00:55:45.860 --> 00:55:48.160]   It's not that you would be paralyzed
[00:55:48.160 --> 00:55:49.900]   if your cerebellum was gone
[00:55:49.900 --> 00:55:51.360]   because you still have motor neurons.
[00:55:51.360 --> 00:55:54.100]   You still have ways to talk to your muscles.
[00:55:54.100 --> 00:55:56.420]   You still have reflex centers.
[00:55:56.420 --> 00:55:59.800]   And it's not like you would have any sensory loss
[00:55:59.800 --> 00:56:01.480]   because you still have your cortex
[00:56:01.480 --> 00:56:03.020]   getting all of those beautiful signals
[00:56:03.020 --> 00:56:04.980]   that you can think about.
[00:56:04.980 --> 00:56:09.380]   But you wouldn't be coordinating things so well anymore.
[00:56:09.380 --> 00:56:12.860]   The timing between input and output might be off.
[00:56:12.860 --> 00:56:16.660]   Or if you were trying to practice a new athletic move,
[00:56:16.660 --> 00:56:19.260]   like an overhead serve in tennis,
[00:56:19.260 --> 00:56:21.380]   you'd be just terrible at learning.
[00:56:21.380 --> 00:56:25.220]   But all of the sequences of muscle movements
[00:56:25.220 --> 00:56:27.320]   and the feedback from your sensory apparatus
[00:56:27.320 --> 00:56:29.360]   that would let you really hit that ball
[00:56:29.360 --> 00:56:32.700]   exactly where you wanted to after the nth rep, right?
[00:56:32.700 --> 00:56:34.940]   You know, the thousandth rep or something,
[00:56:34.940 --> 00:56:36.100]   you get much better at it.
[00:56:36.100 --> 00:56:38.500]   So the cerebellum's all involved in things like
[00:56:38.500 --> 00:56:44.380]   motor learning and refining the precisions of movement
[00:56:44.380 --> 00:56:47.220]   so that they get you where you want to go.
[00:56:47.220 --> 00:56:49.940]   If you reach for a glass of champagne
[00:56:49.940 --> 00:56:52.200]   that you don't knock it over or stop short.
[00:56:52.200 --> 00:56:54.580]   You know, that's what it's good at.
[00:56:54.580 --> 00:56:57.320]   People who have selective damage to the cerebellum.
[00:56:57.320 --> 00:56:58.160]   Absolutely.
[00:56:58.160 --> 00:57:03.160]   And what I come familiar with, well, Korsakoff's
[00:57:03.160 --> 00:57:04.440]   is different, right?
[00:57:04.440 --> 00:57:07.560]   Isn't that a B vitamin deficiency in chronic alcoholics?
[00:57:07.560 --> 00:57:08.400]   Right.
[00:57:08.400 --> 00:57:10.120]   And they have a, they tend to walk kind of bow-legged
[00:57:10.120 --> 00:57:11.860]   and they can't coordinate their movements.
[00:57:11.860 --> 00:57:13.480]   Is that, that has some, that-
[00:57:13.480 --> 00:57:15.300]   Not sure about the cerebellar-
[00:57:15.300 --> 00:57:16.440]   But also cerebellum.
[00:57:16.440 --> 00:57:19.060]   I'm not sure about the cerebellar involvement there,
[00:57:19.060 --> 00:57:22.000]   but you know, the typical thing would be
[00:57:22.000 --> 00:57:26.680]   a patient who has a cerebellar stroke or a tumor,
[00:57:26.680 --> 00:57:31.680]   for example, might be not that steady on their feet.
[00:57:31.680 --> 00:57:37.340]   You know, if the, you know, dynamics of the situation
[00:57:37.340 --> 00:57:40.840]   is standing on a street car with no pole to hold onto,
[00:57:40.840 --> 00:57:43.000]   they might not be as good at adjusting
[00:57:43.000 --> 00:57:45.360]   all of the little movements of the car.
[00:57:45.360 --> 00:57:49.340]   You know, there's a kind of tremor that can occur
[00:57:49.340 --> 00:57:50.940]   as they're reaching for things
[00:57:50.940 --> 00:57:53.560]   because they reach a little too far
[00:57:53.560 --> 00:57:55.700]   and then they over-correct and come back.
[00:57:56.260 --> 00:57:57.500]   Things like that.
[00:57:57.500 --> 00:58:02.500]   So it's very common neurological phenomenon, actually.
[00:58:02.500 --> 00:58:07.260]   Cerebellar ataxia is what the neurologists call it.
[00:58:07.260 --> 00:58:09.140]   And it can happen not just with cerebellar damage,
[00:58:09.140 --> 00:58:11.420]   but damage to the tracts that feed the information
[00:58:11.420 --> 00:58:12.260]   into the cerebellum.
[00:58:12.260 --> 00:58:13.340]   Right, just deprive the structure.
[00:58:13.340 --> 00:58:15.500]   Exactly, or output from the cerebellum.
[00:58:15.500 --> 00:58:17.860]   And so the cerebellum is where a lot of visual
[00:58:17.860 --> 00:58:19.900]   and balance information is combined.
[00:58:19.900 --> 00:58:21.960]   In a very key place in the cerebellum,
[00:58:21.960 --> 00:58:26.320]   which is, it's really one of the oldest parts
[00:58:26.320 --> 00:58:27.160]   in terms of evolution.
[00:58:27.160 --> 00:58:27.980]   Talking about the flocculus.
[00:58:27.980 --> 00:58:28.820]   The flocculus, right.
[00:58:28.820 --> 00:58:32.200]   This is a, it's a critical place in the cerebellum
[00:58:32.200 --> 00:58:35.160]   where visual and vestibular information comes together
[00:58:35.160 --> 00:58:37.300]   for according just the kinds of movements
[00:58:37.300 --> 00:58:38.320]   we were talking about.
[00:58:38.320 --> 00:58:41.920]   This image stabilizing network, it's all happening there.
[00:58:41.920 --> 00:58:43.660]   And there's learning happening there as well.
[00:58:43.660 --> 00:58:45.960]   So that if your vestibular apparatus
[00:58:45.960 --> 00:58:48.880]   is a little bit damaged somehow,
[00:58:48.880 --> 00:58:52.820]   your visual system is actually talking to your cerebellum
[00:58:52.820 --> 00:58:55.860]   saying there's a problem here, there's an error.
[00:58:55.860 --> 00:58:58.840]   And your cerebellum is learning to do better
[00:58:58.840 --> 00:59:01.260]   by increasing the output of the vestibular system
[00:59:01.260 --> 00:59:03.680]   to compensate for whatever that loss was.
[00:59:03.680 --> 00:59:05.340]   So it's a little error correction system.
[00:59:05.340 --> 00:59:08.400]   That's sort of typical of a cerebellar function.
[00:59:08.400 --> 00:59:10.180]   And it can happen in many, many different domains.
[00:59:10.180 --> 00:59:11.900]   This is just one of the domains
[00:59:11.900 --> 00:59:15.300]   of sensory motor integration that takes place there.
[00:59:15.300 --> 00:59:18.700]   So I should stay off my phone in the Ubers.
[00:59:18.700 --> 00:59:22.300]   If I'm on a boat, I should essentially look
[00:59:22.300 --> 00:59:25.760]   and as much as possible act as if I'm driving the machine.
[00:59:25.760 --> 00:59:26.600]   - Right.
[00:59:26.600 --> 00:59:28.180]   - That'd be weird if I was in the passenger seat
[00:59:28.180 --> 00:59:29.480]   pretending I was driving the machine,
[00:59:29.480 --> 00:59:30.660]   but I do always feel better
[00:59:30.660 --> 00:59:32.700]   if I'm sitting in the front seat passenger.
[00:59:32.700 --> 00:59:35.780]   - Right, the more of the visual world that you can see
[00:59:35.780 --> 00:59:38.380]   as if you were actually the one doing the motion,
[00:59:38.380 --> 00:59:39.420]   I would think.
[00:59:39.420 --> 00:59:41.020]   - Let's stay in the inner ear for a minute
[00:59:41.020 --> 00:59:44.400]   as we continue to march around the nervous system.
[00:59:44.400 --> 00:59:48.500]   When you take off in the plane or when you land
[00:59:48.500 --> 00:59:50.060]   or sometimes in the middle of the air,
[00:59:50.060 --> 00:59:53.260]   your ears get clogged, or at least my ears get clogged.
[00:59:53.260 --> 00:59:56.300]   That's because of pressure buildup
[00:59:56.300 --> 00:59:59.340]   in the various tubes of the inner ear, et cetera.
[00:59:59.340 --> 01:00:00.220]   We'll get into this.
[01:00:00.220 --> 01:00:05.100]   But years ago, our good friend, Harvey Carton,
[01:00:05.100 --> 01:00:08.220]   who's another world-class neuroanatomist,
[01:00:08.220 --> 01:00:12.140]   gave a lecture and it talked about
[01:00:12.140 --> 01:00:14.420]   how plugging your nose and blowing out
[01:00:14.420 --> 01:00:17.420]   versus plugging your nose and sucking in
[01:00:17.420 --> 01:00:20.100]   can, should be done at different times
[01:00:20.100 --> 01:00:23.600]   depending on whether or not you're taking off or landing.
[01:00:23.600 --> 01:00:26.920]   And I always see people try to un-pop their ears.
[01:00:26.920 --> 01:00:28.340]   And when you do scuba diving,
[01:00:28.340 --> 01:00:30.300]   you learn how to do this without necessarily,
[01:00:30.300 --> 01:00:32.860]   I can do it by just kind of moving my jaw now
[01:00:32.860 --> 01:00:35.480]   'cause I've done a little bit of diving.
[01:00:35.480 --> 01:00:37.700]   But what's the story there?
[01:00:37.700 --> 01:00:39.740]   We don't have to get into all the differences
[01:00:39.740 --> 01:00:41.140]   in atmospheric pressure, et cetera.
[01:00:41.140 --> 01:00:44.260]   But if I'm taking off and my ears are plugged,
[01:00:44.260 --> 01:00:46.460]   or I've recently ascended, plane took off,
[01:00:46.460 --> 01:00:48.540]   my ears are plugged, do I plug my nose and blow out
[01:00:48.540 --> 01:00:49.940]   or do I plug my nose and suck in?
[01:00:49.940 --> 01:00:54.940]   - Right, so the basic idea is that if your ears feel bad
[01:00:54.940 --> 01:00:58.620]   because you're going into an area of higher pressure,
[01:00:58.620 --> 01:01:01.960]   so if they pressurize the cabin more than the pressure
[01:01:01.960 --> 01:01:03.760]   that you have on the surface of the planet,
[01:01:03.760 --> 01:01:07.020]   your eardrums will be bending in and they don't like that.
[01:01:07.020 --> 01:01:08.640]   If you push them more, they'll hurt even more.
[01:01:08.640 --> 01:01:11.620]   - That's a good description that the pressure goes up,
[01:01:11.620 --> 01:01:12.580]   then they're gonna bend in.
[01:01:12.580 --> 01:01:14.660]   - Bend in, and then the reverse would be true
[01:01:14.660 --> 01:01:16.620]   if you go into an area of low pressure.
[01:01:16.620 --> 01:01:20.140]   So if you started to drive up the mountainside,
[01:01:20.140 --> 01:01:22.140]   the pressure is getting lower and lower outside.
[01:01:22.140 --> 01:01:26.860]   Now the air behind your eardrum is blooming out, right?
[01:01:26.860 --> 01:01:28.680]   So it's just a question of are you trying to get
[01:01:28.680 --> 01:01:31.460]   more pressure or less pressure behind the eardrum?
[01:01:31.460 --> 01:01:32.780]   And there's a little tube that does that
[01:01:32.780 --> 01:01:35.540]   and comes down into the back of your throat there.
[01:01:35.540 --> 01:01:37.580]   And if you force pressure up that tube,
[01:01:37.580 --> 01:01:39.500]   you're gonna be putting more air pressure
[01:01:39.500 --> 01:01:41.100]   into the compartment.
[01:01:41.100 --> 01:01:42.260]   - To counter it.
[01:01:42.260 --> 01:01:45.500]   - If it's not enough, and if you're sucking,
[01:01:45.500 --> 01:01:46.460]   you're going the other way.
[01:01:46.460 --> 01:01:49.080]   In reality, I think as long as you open the passageway,
[01:01:49.080 --> 01:01:50.780]   I think the pressure differential
[01:01:50.780 --> 01:01:52.220]   is gonna solve your problem.
[01:01:52.220 --> 01:01:54.220]   So I think you could actually blow in
[01:01:54.220 --> 01:01:55.960]   when you're not, quote, supposed to.
[01:01:55.960 --> 01:02:00.180]   - Okay, so you could just hold your nose and blow air out
[01:02:00.180 --> 01:02:04.100]   or hold your nose and suck in the effect.
[01:02:04.100 --> 01:02:05.020]   Either way is fine.
[01:02:05.020 --> 01:02:05.860]   - I think so.
[01:02:05.860 --> 01:02:09.100]   - Excellent, I just won $100 from Harvey Carton.
[01:02:09.100 --> 01:02:10.500]   Thank you very much.
[01:02:10.500 --> 01:02:12.820]   Harvey and I used to teach in our anatomy together,
[01:02:12.820 --> 01:02:14.180]   and I'll say, I don't think it matters,
[01:02:14.180 --> 01:02:16.820]   but thank you, I'll split that with you.
[01:02:16.820 --> 01:02:21.940]   This is important stuff, but it's true.
[01:02:21.940 --> 01:02:25.420]   You hear this, so it doesn't matter either way.
[01:02:25.420 --> 01:02:27.300]   - I'm no expert in this area.
[01:02:27.300 --> 01:02:28.140]   Don't quote me.
[01:02:28.140 --> 01:02:30.260]   - He's not gonna, well, I'm going to quote you.
[01:02:30.260 --> 01:02:32.140]   Okay, so we've talked about the inner ear
[01:02:32.140 --> 01:02:33.960]   and we've talked about the cerebellum.
[01:02:33.960 --> 01:02:35.740]   I want to talk about an area of the brain
[01:02:35.740 --> 01:02:40.160]   that is rarely discussed, which is the midbrain.
[01:02:40.160 --> 01:02:42.820]   And for those that don't know,
[01:02:42.820 --> 01:02:45.640]   the midbrain is an area beneath the cortex.
[01:02:45.640 --> 01:02:47.180]   I guess we never really defined cortex.
[01:02:47.180 --> 01:02:48.500]   It was just kind of the outer layers
[01:02:48.500 --> 01:02:51.800]   or are the outer layers of the,
[01:02:51.800 --> 01:02:54.500]   at least mammalian brain or human brain.
[01:02:54.500 --> 01:02:57.140]   But the midbrain is super interesting
[01:02:57.140 --> 01:03:02.140]   because it controls a lot of unconscious stuff,
[01:03:02.140 --> 01:03:03.860]   reflexes, et cetera.
[01:03:03.860 --> 01:03:07.900]   And then there's this phenomenon even called blindsight.
[01:03:07.900 --> 01:03:11.320]   So could you please tell us about the midbrain,
[01:03:11.320 --> 01:03:15.660]   about what it does and what in the world is blindsight?
[01:03:15.660 --> 01:03:19.520]   - Yeah, so this is a, there's a lot of pieces there.
[01:03:19.520 --> 01:03:20.920]   I think the first thing to say is
[01:03:20.920 --> 01:03:25.280]   if you imagine the nervous system in your mind's eye,
[01:03:25.280 --> 01:03:27.080]   you see this big honking brain
[01:03:27.080 --> 01:03:32.080]   and then there's this little wand that dangles down
[01:03:32.080 --> 01:03:34.540]   into your vertebral column, the spinal cord,
[01:03:34.540 --> 01:03:36.600]   and that's kind of your visual impression.
[01:03:37.760 --> 01:03:40.080]   What you have to imagine is starting in the spinal cord
[01:03:40.080 --> 01:03:42.700]   and working your way up into this big, magnificent brain.
[01:03:42.700 --> 01:03:46.400]   And what you would do as you enter the skull
[01:03:46.400 --> 01:03:47.920]   is get into a little place
[01:03:47.920 --> 01:03:50.160]   where the spinal cord kind of thickens out.
[01:03:50.160 --> 01:03:54.800]   It still has that sort of long, skinny, trunk-like feeling.
[01:03:54.800 --> 01:03:56.660]   - Sort of like a paddle or a spoon shape.
[01:03:56.660 --> 01:03:58.520]   - Right, it starts to spread out a little bit,
[01:03:58.520 --> 01:04:00.480]   and that's 'cause your evolution has packed
[01:04:00.480 --> 01:04:02.040]   more interesting goodies in there
[01:04:02.040 --> 01:04:05.300]   for processing information and generating movement.
[01:04:05.300 --> 01:04:09.740]   So beyond that is this tween brain
[01:04:09.740 --> 01:04:12.180]   we were talking about, this linker brain.
[01:04:12.180 --> 01:04:14.820]   Diencephalon really means the between brain.
[01:04:14.820 --> 01:04:16.020]   - Oh, I thought you said tween.
[01:04:16.020 --> 01:04:16.860]   - Well, it is, yes.
[01:04:16.860 --> 01:04:19.740]   - No, no, between, between, I'm sorry, I thought you said tween.
[01:04:19.740 --> 01:04:20.820]   - Yeah, it's the between,
[01:04:20.820 --> 01:04:24.280]   it's the between brain is what the name means.
[01:04:24.280 --> 01:04:27.740]   It's the linker from the spinal cord in the periphery
[01:04:27.740 --> 01:04:30.380]   up to these grand centers of the cortex.
[01:04:30.380 --> 01:04:33.300]   But this midbrain you're talking about
[01:04:33.300 --> 01:04:37.240]   is the last bit of this enlarged sort of spinal cordy thing
[01:04:37.240 --> 01:04:39.500]   in your skull, which is really the brainstem
[01:04:39.500 --> 01:04:40.940]   is what we call it.
[01:04:40.940 --> 01:04:43.860]   The last bit of that before you get to this relay
[01:04:43.860 --> 01:04:46.940]   up to the cortex is the midbrain.
[01:04:46.940 --> 01:04:49.560]   And there's a really important visual center there.
[01:04:49.560 --> 01:04:51.480]   It's called the superior colliculus.
[01:04:51.480 --> 01:04:54.540]   There's a similar center in the brains
[01:04:54.540 --> 01:04:57.440]   of other vertebrate animals, a frog, for example,
[01:04:57.440 --> 01:04:59.020]   or a lizard would have this.
[01:04:59.020 --> 01:05:01.380]   It's called the optic tectum there.
[01:05:01.380 --> 01:05:06.380]   But it's a center that in these non-mammalian vertebrates
[01:05:06.380 --> 01:05:10.420]   is really the main visual center.
[01:05:10.420 --> 01:05:13.900]   They don't really have what we would call a visual cortex,
[01:05:13.900 --> 01:05:16.040]   although there's something sort of like that.
[01:05:16.040 --> 01:05:17.540]   But this is where most of the action is
[01:05:17.540 --> 01:05:19.560]   in terms of interpreting visual input
[01:05:19.560 --> 01:05:22.480]   and organizing behavior around that.
[01:05:22.480 --> 01:05:27.420]   You can sort of think about this region of the brainstem
[01:05:27.420 --> 01:05:32.420]   as a reflex center that can reorient the animal's gaze
[01:05:32.420 --> 01:05:37.740]   or body, or maybe even attention to particular regions
[01:05:37.740 --> 01:05:41.580]   of space out there around the animal.
[01:05:41.580 --> 01:05:43.540]   And that could be for all kinds of reasons.
[01:05:43.540 --> 01:05:45.780]   I mean, it might be a predator just showed up
[01:05:45.780 --> 01:05:48.520]   in one corner of the forest and you pick that up
[01:05:48.520 --> 01:05:50.000]   and you're trying to avoid it.
[01:05:50.000 --> 01:05:51.020]   Or just any movement.
[01:05:51.020 --> 01:05:52.420]   Many movement, right?
[01:05:52.420 --> 01:05:57.300]   It might be that suddenly something splats on the page
[01:05:57.300 --> 01:05:58.540]   when you're reading a novel
[01:05:58.540 --> 01:06:02.020]   and your eye reflexly looks at it.
[01:06:02.020 --> 01:06:03.180]   You don't have to think about that.
[01:06:03.180 --> 01:06:04.140]   That's a reflex.
[01:06:04.140 --> 01:06:07.260]   - What if you throw me a ball, but I'm not expecting it,
[01:06:07.260 --> 01:06:10.700]   and I just reach up and try and grab it, catch it or not?
[01:06:10.700 --> 01:06:12.260]   Is that handled by the midbrain?
[01:06:12.260 --> 01:06:14.920]   - Well, that's probably not the midbrain,
[01:06:14.920 --> 01:06:17.080]   although, I mean, by itself,
[01:06:17.080 --> 01:06:19.660]   because it's going to involve all these limb movements,
[01:06:19.660 --> 01:06:21.480]   this movement of your arm and body.
[01:06:21.480 --> 01:06:24.780]   - What about ducking if something's suddenly
[01:06:24.780 --> 01:06:25.620]   thrown at my head?
[01:06:25.620 --> 01:06:26.460]   - Yeah, sure, right.
[01:06:26.460 --> 01:06:29.020]   Brains like that will certainly have a brainstem component,
[01:06:29.020 --> 01:06:30.460]   a midbrain component.
[01:06:30.460 --> 01:06:32.420]   You know, something looms and you duck.
[01:06:32.420 --> 01:06:36.840]   It may not be the superior colliculus we're talking about.
[01:06:36.840 --> 01:06:39.140]   Now, it might be another part of the visual midbrain,
[01:06:39.140 --> 01:06:41.700]   but these are centers that emerged early
[01:06:41.700 --> 01:06:43.900]   in the evolution of brains like ours
[01:06:43.900 --> 01:06:46.740]   to handle complicated visual events
[01:06:46.740 --> 01:06:48.900]   that have significance for the animal.
[01:06:48.900 --> 01:06:51.620]   In terms of space, where is it in space?
[01:06:51.620 --> 01:06:54.340]   And in fact, this same center actually gets input
[01:06:54.340 --> 01:06:56.200]   from all kinds of other sensory systems
[01:06:56.200 --> 01:06:58.900]   that take information from the external world,
[01:06:58.900 --> 01:07:00.580]   from particular locations,
[01:07:00.580 --> 01:07:03.540]   and where you might want to either avoid or approach things
[01:07:03.540 --> 01:07:05.660]   according to their significance to you.
[01:07:05.660 --> 01:07:08.700]   So you get input from the touch system.
[01:07:08.700 --> 01:07:11.540]   You get input from the auditory system.
[01:07:11.540 --> 01:07:13.500]   I worked for a while in rattlesnakes.
[01:07:13.500 --> 01:07:17.740]   They get input from a part of their warm sensors
[01:07:17.740 --> 01:07:18.580]   on their face.
[01:07:18.580 --> 01:07:20.580]   They're in these little pits on the face.
[01:07:20.580 --> 01:07:22.220]   - They used to work on baby rattlesnakes, right?
[01:07:22.220 --> 01:07:23.980]   - Well, they were adults, actually.
[01:07:23.980 --> 01:07:25.660]   - Oh, I wasn't trying to diminish the danger.
[01:07:25.660 --> 01:07:27.660]   I thought for some reason they were little ones.
[01:07:27.660 --> 01:07:30.280]   Why in the world would you work on rattlesnakes?
[01:07:30.280 --> 01:07:33.780]   - Well, because they have a version
[01:07:33.780 --> 01:07:35.940]   of an extra receptive sensory system.
[01:07:35.940 --> 01:07:39.020]   That is, they're looking out into the world
[01:07:39.020 --> 01:07:41.100]   using a completely different set of sensors.
[01:07:41.100 --> 01:07:42.300]   They're using the same sensors
[01:07:42.300 --> 01:07:44.000]   that would feel the warmth on your face
[01:07:44.000 --> 01:07:45.880]   if you stood in front of a bonfire,
[01:07:45.880 --> 01:07:48.420]   except evolution has given them
[01:07:48.420 --> 01:07:49.960]   this very nice specialized system
[01:07:49.960 --> 01:07:52.220]   that lets them image where the heat's coming from.
[01:07:52.220 --> 01:07:53.900]   You can sort of do that anyway, right?
[01:07:53.900 --> 01:07:56.220]   If you walk around the fire,
[01:07:56.220 --> 01:07:57.900]   you can feel where the fire is
[01:07:57.900 --> 01:08:00.460]   from the heat hitting your face.
[01:08:00.460 --> 01:08:04.300]   - Is that the primary way in which they detect prey?
[01:08:04.300 --> 01:08:06.660]   - It's one of the major ways.
[01:08:06.660 --> 01:08:09.100]   And in fact, they use vision as well.
[01:08:09.100 --> 01:08:11.100]   And they bring these two systems together
[01:08:11.100 --> 01:08:13.620]   in the same place, in this tectum region,
[01:08:13.620 --> 01:08:15.460]   this brain stem, midbrain region.
[01:08:15.460 --> 01:08:17.580]   - What's all the tongue jutting about when the snakes?
[01:08:17.580 --> 01:08:19.080]   - That I don't know.
[01:08:19.080 --> 01:08:20.380]   That may be olfactory.
[01:08:20.380 --> 01:08:21.220]   There may be-
[01:08:21.220 --> 01:08:22.220]   - They're sniffing the air with their tongue.
[01:08:22.220 --> 01:08:23.900]   - Yeah, there may be a-
[01:08:23.900 --> 01:08:24.780]   - Earlier in our drive,
[01:08:24.780 --> 01:08:26.300]   you told me that flies actually
[01:08:26.300 --> 01:08:27.700]   taste things with their feet.
[01:08:27.700 --> 01:08:28.540]   - They do, yeah.
[01:08:28.540 --> 01:08:29.380]   - That's so weird.
[01:08:29.380 --> 01:08:31.060]   - Yeah, they have taste receptors
[01:08:31.060 --> 01:08:32.540]   in lots of funny places.
[01:08:32.540 --> 01:08:34.920]   - I want to pause here just for one second
[01:08:34.920 --> 01:08:36.500]   before we get back into the midbrain.
[01:08:36.500 --> 01:08:40.120]   I think what's so interesting in all seriousness
[01:08:40.120 --> 01:08:45.040]   about taste receptors on feet, heat sensors,
[01:08:45.040 --> 01:08:47.660]   tongues jutting out of snakes,
[01:08:47.660 --> 01:08:49.360]   and vision and all this integration
[01:08:49.360 --> 01:08:51.980]   is that it really speaks to the fact
[01:08:51.980 --> 01:08:55.020]   that all these sensory neurons
[01:08:55.020 --> 01:08:57.820]   are trying to gather information
[01:08:57.820 --> 01:08:59.720]   and stuff it into a system
[01:08:59.720 --> 01:09:03.260]   that can make meaningful decisions and actions.
[01:09:03.260 --> 01:09:04.620]   And that it really doesn't matter
[01:09:04.620 --> 01:09:06.680]   whether or not it's coming from eyes or ears or nose
[01:09:06.680 --> 01:09:08.520]   or bottoms of feet,
[01:09:08.520 --> 01:09:11.460]   because in the end, it's just electricity flowing in.
[01:09:11.460 --> 01:09:14.860]   And so it sounds like it's placed on each animal.
[01:09:14.860 --> 01:09:17.300]   It always feels weird to call fly an animal,
[01:09:17.300 --> 01:09:20.400]   but they are creatures, they are animals.
[01:09:21.380 --> 01:09:23.740]   It's placed in different locations on different animals,
[01:09:23.740 --> 01:09:26.620]   depending on the particular needs of that animal.
[01:09:26.620 --> 01:09:29.140]   - Right, but how much more powerful
[01:09:29.140 --> 01:09:32.820]   if the nervous systems can also cross-correlate
[01:09:32.820 --> 01:09:34.920]   across sensory systems?
[01:09:34.920 --> 01:09:38.100]   So if you've got a weak signal from one sensory system,
[01:09:38.100 --> 01:09:40.320]   you're not quite sure there's something there,
[01:09:40.320 --> 01:09:42.980]   and a weak signal from another sensory system
[01:09:42.980 --> 01:09:44.780]   that's telling you the same locations
[01:09:44.780 --> 01:09:46.320]   is a little bit interesting.
[01:09:46.320 --> 01:09:47.740]   There might be something there.
[01:09:47.740 --> 01:09:50.500]   If you've got those two together, you've got corroboration.
[01:09:50.500 --> 01:09:53.100]   Your brain now says it's much more likely
[01:09:53.100 --> 01:09:56.860]   that that's gonna be something worth paying attention to.
[01:09:56.860 --> 01:09:59.540]   - Right, so maybe I'm feeling some heat
[01:09:59.540 --> 01:10:01.200]   on one side of my face,
[01:10:01.200 --> 01:10:05.820]   and I also smell something baking in the oven.
[01:10:05.820 --> 01:10:08.180]   So now neither is particularly strong,
[01:10:08.180 --> 01:10:10.380]   but as you said, there's some corroboration,
[01:10:10.380 --> 01:10:12.460]   and that corroboration is occurring in the midbrain.
[01:10:12.460 --> 01:10:15.960]   - Right, and then if you throw things into conflict,
[01:10:15.960 --> 01:10:17.300]   now the brain is confused,
[01:10:17.300 --> 01:10:20.000]   and that may be where your emotion sickness comes from.
[01:10:20.000 --> 01:10:22.980]   So it's great to have, as a brain,
[01:10:22.980 --> 01:10:24.740]   it's great to have as many sources of information
[01:10:24.740 --> 01:10:29.400]   as you can have, just like if you're a spy or a journalist.
[01:10:29.400 --> 01:10:30.580]   You don't want as much information
[01:10:30.580 --> 01:10:33.040]   as you can get about what's out there,
[01:10:33.040 --> 01:10:35.640]   but if things conflict, that's problematic, right?
[01:10:35.640 --> 01:10:37.300]   Your sources are giving you different information
[01:10:37.300 --> 01:10:38.480]   about what's going on.
[01:10:38.480 --> 01:10:39.820]   Now you've got a problem on your hands.
[01:10:39.820 --> 01:10:40.820]   What do you publish?
[01:10:40.820 --> 01:10:43.520]   - The midbrain is so fascinating.
[01:10:43.520 --> 01:10:46.300]   I don't wanna eject us from the midbrain
[01:10:46.300 --> 01:10:47.820]   and go back to the vestibular system,
[01:10:47.820 --> 01:10:49.640]   but I do have a question that I forgot to ask
[01:10:49.640 --> 01:10:50.740]   about the vestibular system,
[01:10:50.740 --> 01:10:53.780]   which is why is it that for many people, including me,
[01:10:53.780 --> 01:10:56.420]   there's, despite my motion sickness in cabs,
[01:10:56.420 --> 01:11:00.820]   that there's a sense of pleasure in moving through space
[01:11:00.820 --> 01:11:03.380]   and getting tilted relative to the gravitational pull
[01:11:03.380 --> 01:11:04.220]   of the earth?
[01:11:04.220 --> 01:11:05.680]   For me growing up, it was skateboarding,
[01:11:05.680 --> 01:11:08.800]   but people like to corner in cars, corner on bikes.
[01:11:08.800 --> 01:11:13.340]   It may be, for some people, it's done running or dance,
[01:11:13.340 --> 01:11:16.300]   but what is it about moving through space
[01:11:16.300 --> 01:11:19.680]   and getting tilted, a lot of surfers around here,
[01:11:19.680 --> 01:11:23.220]   getting tilted that can tap
[01:11:23.220 --> 01:11:25.320]   into some of the pleasure centers?
[01:11:25.320 --> 01:11:26.940]   Do we have any idea why that would feel good?
[01:11:26.940 --> 01:11:28.620]   - I have no clue.
[01:11:28.620 --> 01:11:31.460]   - Is there dopaminergic input to this system?
[01:11:31.460 --> 01:11:36.220]   - Well, the dopaminergic system gets a lot of places.
[01:11:36.220 --> 01:11:40.300]   It's pretty much, to some extent,
[01:11:40.300 --> 01:11:41.340]   everywhere in the cortex,
[01:11:41.340 --> 01:11:43.500]   a lot more in the frontal lobe, of course,
[01:11:43.500 --> 01:11:45.880]   but that's just for starters.
[01:11:45.880 --> 01:11:47.880]   I mean, there's basically dopaminergic innervation
[01:11:47.880 --> 01:11:50.280]   most places in the central nervous system,
[01:11:50.280 --> 01:11:52.700]   so there's the potential for dopaminergic involvement,
[01:11:52.700 --> 01:11:55.200]   but I really have no clue about the tilting phenomenon.
[01:11:55.200 --> 01:11:56.040]   I mean-
[01:11:56.040 --> 01:11:58.000]   - People pay money to go on roller coasters.
[01:11:58.000 --> 01:11:58.840]   - Right.
[01:11:58.840 --> 01:12:00.640]   Well, I think that may be as much about the thrill
[01:12:00.640 --> 01:12:01.480]   as anything else. - Sure.
[01:12:01.480 --> 01:12:04.360]   And falling is, the falling reflex is very robust
[01:12:04.360 --> 01:12:05.200]   in all of us.
[01:12:05.200 --> 01:12:07.160]   When the visual world's going up very fast,
[01:12:07.160 --> 01:12:08.420]   it usually means that we're falling.
[01:12:08.420 --> 01:12:09.260]   - Right, right.
[01:12:09.260 --> 01:12:10.740]   - But in some people like that, some people don't.
[01:12:10.740 --> 01:12:14.640]   - Right, and kids tolerate a lot more
[01:12:14.640 --> 01:12:16.720]   sort of vestibular craziness spinning around
[01:12:16.720 --> 01:12:18.460]   until they've dropped.
[01:12:18.460 --> 01:12:21.420]   - Well, I've friends, it always, you know,
[01:12:21.420 --> 01:12:23.600]   worries me a little bit that they throw their kids.
[01:12:23.600 --> 01:12:25.000]   I'm not recommending anyone do this.
[01:12:25.000 --> 01:12:25.860]   When they're little kids, you know,
[01:12:25.860 --> 01:12:29.000]   like throwing the kids really far back and forth.
[01:12:29.000 --> 01:12:30.420]   Some kids seem to love it.
[01:12:30.420 --> 01:12:31.260]   - Yeah.
[01:12:31.260 --> 01:12:33.920]   Yeah, our son loved being shaken up and down
[01:12:33.920 --> 01:12:37.200]   very, very vigorously.
[01:12:37.200 --> 01:12:39.280]   That's the only thing that would calm him down sometimes.
[01:12:39.280 --> 01:12:40.280]   - Interesting.
[01:12:40.280 --> 01:12:41.360]   Yeah, so I'm guessing.
[01:12:41.360 --> 01:12:46.360]   We can guess that maybe there's some activation
[01:12:46.360 --> 01:12:50.200]   of the reward systems from moving through space.
[01:12:50.200 --> 01:12:51.860]   - Well, I mean, if you think about, you know,
[01:12:51.860 --> 01:12:54.820]   how rewarding it is to be able to move through space
[01:12:54.820 --> 01:12:57.920]   and how unhappy people are who are used to that,
[01:12:57.920 --> 01:12:59.680]   who suddenly aren't able to do that,
[01:12:59.680 --> 01:13:01.740]   there is a sense of agency, right?
[01:13:01.740 --> 01:13:05.240]   If you can choose to move through the world and to tilt,
[01:13:05.240 --> 01:13:06.800]   that's not only you're moving through the world,
[01:13:06.800 --> 01:13:08.440]   but you're doing it with a certain amount of finesse.
[01:13:08.440 --> 01:13:09.360]   Maybe that's what it is.
[01:13:09.360 --> 01:13:13.240]   You can feel like you're the master of your own movement
[01:13:13.240 --> 01:13:15.120]   in a way that you wouldn't if you were going straight.
[01:13:15.120 --> 01:13:17.160]   I'm just blowing smoke here, right?
[01:13:17.160 --> 01:13:18.420]   - Yeah, well, we can speculate.
[01:13:18.420 --> 01:13:19.260]   That's fine.
[01:13:19.260 --> 01:13:21.400]   I couldn't help but ask the question.
[01:13:21.400 --> 01:13:25.000]   Okay, so if we move ourselves, pun intended,
[01:13:25.000 --> 01:13:27.220]   back into the midbrain.
[01:13:27.220 --> 01:13:29.080]   The midbrain's combining all these different signals
[01:13:29.080 --> 01:13:31.120]   for reflexive action.
[01:13:31.120 --> 01:13:34.880]   At what point does this become deliberate action?
[01:13:34.880 --> 01:13:36.740]   Because if I look at something I want
[01:13:36.740 --> 01:13:37.580]   and I want to pursue it,
[01:13:37.580 --> 01:13:41.060]   I'm going to go toward it, and many times,
[01:13:41.060 --> 01:13:42.320]   that's a deliberate decision.
[01:13:42.320 --> 01:13:46.660]   - Right, so this gets very slippery, I think,
[01:13:46.660 --> 01:13:49.260]   because what you have to try to imagine
[01:13:49.260 --> 01:13:51.000]   is all these different parts of the brain
[01:13:51.000 --> 01:13:53.940]   working on the problem of staying alive
[01:13:53.940 --> 01:13:58.980]   and surviving in the world.
[01:13:58.980 --> 01:14:01.080]   They're working on the problem simultaneously,
[01:14:01.080 --> 01:14:04.920]   and there's not one right answer to how to do that.
[01:14:06.260 --> 01:14:09.880]   But one way to think about it is that
[01:14:09.880 --> 01:14:11.760]   you have high levels of your nervous system
[01:14:11.760 --> 01:14:16.100]   that are very well designed to override
[01:14:16.100 --> 01:14:19.580]   an otherwise automatic movement if it's inappropriate.
[01:14:19.580 --> 01:14:22.320]   So if you've imagined you've been invited to tea
[01:14:22.320 --> 01:14:25.120]   with the queen, and she hands you
[01:14:25.120 --> 01:14:29.760]   a very fancy wedge wood tea cup, very thin.
[01:14:29.760 --> 01:14:30.840]   - Wedge wood tea cup?
[01:14:30.840 --> 01:14:33.040]   - Yes, with very hot tea in it,
[01:14:33.040 --> 01:14:34.100]   and you're burning your hand,
[01:14:34.100 --> 01:14:36.960]   you probably will try to find a way to put that back down
[01:14:36.960 --> 01:14:40.140]   on the saucer rather than just dropping it on the floor
[01:14:40.140 --> 01:14:42.380]   because you're with the queen.
[01:14:42.380 --> 01:14:45.520]   You're trying to be appropriate to that.
[01:14:45.520 --> 01:14:49.380]   So you have ways of reining in automatic behaviors
[01:14:49.380 --> 01:14:51.160]   if they're going to be maladaptive,
[01:14:51.160 --> 01:14:54.580]   but you also want the reflex to work quickly
[01:14:54.580 --> 01:14:56.060]   if it's the only thing that's going to save you,
[01:14:56.060 --> 01:14:58.340]   the looming object coming at your head.
[01:14:58.340 --> 01:15:00.300]   You don't have time to think about that.
[01:15:00.300 --> 01:15:04.300]   So this is the interplay in these hierarchically
[01:15:04.300 --> 01:15:06.100]   organized centers of the nervous system.
[01:15:06.100 --> 01:15:09.500]   At the lowest level, you've got the automatic sensors
[01:15:09.500 --> 01:15:14.500]   and centers and reflex arcs that will keep you safe
[01:15:14.500 --> 01:15:16.740]   even if you don't have time to think about it.
[01:15:16.740 --> 01:15:18.740]   And then you've got the higher center saying,
[01:15:18.740 --> 01:15:20.640]   well, maybe we could do this as well,
[01:15:20.640 --> 01:15:23.500]   or maybe we shouldn't do that at all, right?
[01:15:23.500 --> 01:15:25.700]   So you have all of these different levels
[01:15:25.700 --> 01:15:27.540]   operating simultaneously,
[01:15:27.540 --> 01:15:30.620]   and you need bi-directional communication
[01:15:30.620 --> 01:15:34.620]   between high level cognitive centers,
[01:15:34.620 --> 01:15:37.740]   decision-making on the one hand,
[01:15:37.740 --> 01:15:40.300]   and these low level, very helpful reflexive centers,
[01:15:40.300 --> 01:15:43.460]   but they're a little bit rigid, a little hardwired,
[01:15:43.460 --> 01:15:44.540]   so they need some nuance.
[01:15:44.540 --> 01:15:47.380]   So both of these things are operating in tandem
[01:15:47.380 --> 01:15:49.860]   in real time, all the time in our brains.
[01:15:49.860 --> 01:15:51.780]   And sometimes we listen more to one than the other.
[01:15:51.780 --> 01:15:53.980]   You've heard people in sports talking about
[01:15:55.060 --> 01:15:57.540]   messing up at the plate 'cause they overthought it,
[01:15:57.540 --> 01:15:59.020]   thinking too hard about it.
[01:15:59.020 --> 01:16:01.900]   That's partly, you've already trained your cerebellum
[01:16:01.900 --> 01:16:04.980]   how to hit a fastball right down the middle.
[01:16:04.980 --> 01:16:08.100]   Right, and if you start looking for something new
[01:16:08.100 --> 01:16:11.140]   or different, you're gonna mess up your reflexive swing.
[01:16:11.140 --> 01:16:12.960]   Right, if you're trying to think about the physics
[01:16:12.960 --> 01:16:15.020]   of the ball as it's coming at you,
[01:16:15.020 --> 01:16:16.380]   you've already missed, right?
[01:16:16.380 --> 01:16:18.780]   'Cause you're not using your,
[01:16:18.780 --> 01:16:22.260]   all those reps have built a kind of knowledge
[01:16:22.260 --> 01:16:25.380]   is what you wanna rely on when you don't have enough time
[01:16:25.380 --> 01:16:27.100]   to contemplate.
[01:16:27.100 --> 01:16:30.300]   - This is important and a great segue
[01:16:30.300 --> 01:16:32.960]   for what I'd like to discuss next,
[01:16:32.960 --> 01:16:35.900]   which is the basal ganglia,
[01:16:35.900 --> 01:16:38.220]   this really interesting area of the brain
[01:16:38.220 --> 01:16:43.220]   that's involved in GO-type commands and behaviors,
[01:16:43.220 --> 01:16:46.460]   instructing us to do things, and NO-GO,
[01:16:46.460 --> 01:16:47.760]   preventing us from doing things.
[01:16:47.760 --> 01:16:50.720]   Because so much of motor learning and skill execution
[01:16:50.720 --> 01:16:53.520]   and not saying the wrong thing,
[01:16:53.520 --> 01:16:55.640]   or sitting still in class when,
[01:16:55.640 --> 01:16:59.480]   or as you used with the "Tea with the Queen" example,
[01:16:59.480 --> 01:17:03.900]   feeling discomfort involves suppressing behavior,
[01:17:03.900 --> 01:17:05.820]   and sometimes it's activating behavior.
[01:17:05.820 --> 01:17:07.880]   A tremendous amount of online attention is devoted
[01:17:07.880 --> 01:17:11.360]   to trying to get people motivated.
[01:17:11.360 --> 01:17:13.320]   This isn't the main focus of our podcast.
[01:17:13.320 --> 01:17:15.080]   We touch on some of the underlying neural circuits
[01:17:15.080 --> 01:17:17.400]   of motivation, dopamine, and so forth.
[01:17:17.400 --> 01:17:20.840]   But so much of what people struggle with out there
[01:17:20.840 --> 01:17:25.840]   are elements around failure to pay attention,
[01:17:25.840 --> 01:17:28.300]   or challenges in paying attention,
[01:17:28.300 --> 01:17:30.660]   which is essentially like putting the blinders on,
[01:17:30.660 --> 01:17:32.660]   getting a soda straw view of the world
[01:17:32.660 --> 01:17:34.700]   and maintaining that for a bout of work
[01:17:34.700 --> 01:17:35.940]   or something of that sort,
[01:17:35.940 --> 01:17:38.900]   and trying to get into action.
[01:17:38.900 --> 01:17:42.420]   So of course, this is carried out by many neural circuits,
[01:17:42.420 --> 01:17:43.580]   not just the basal ganglia,
[01:17:43.580 --> 01:17:45.840]   but what are the basal ganglia
[01:17:45.840 --> 01:17:47.900]   and what are their primary roles
[01:17:47.900 --> 01:17:51.920]   in controlling go-type behavior and no-go-type behavior?
[01:17:51.920 --> 01:17:55.440]   - Yeah, so I mean, the basal ganglia are sitting deep
[01:17:55.440 --> 01:17:57.920]   in what you would call the forebrain,
[01:17:57.920 --> 01:18:00.520]   so the highest levels of the brain.
[01:18:00.520 --> 01:18:05.480]   They are sort of cousins to the cerebral cortex,
[01:18:05.480 --> 01:18:07.440]   which we talked about as sort of the highest level
[01:18:07.440 --> 01:18:09.920]   of your brain, the thing you're thinking with.
[01:18:09.920 --> 01:18:11.880]   - Cerebral cortex being the refined cousins,
[01:18:11.880 --> 01:18:13.480]   and then you've got the- - Right.
[01:18:13.480 --> 01:18:15.320]   - The brutes. - Yeah.
[01:18:15.320 --> 01:18:18.600]   - I mean, that's probably totally unfair, but the point-
[01:18:18.600 --> 01:18:19.560]   - I like the basal ganglia.
[01:18:19.560 --> 01:18:22.700]   I can relate to the brutish parts of the brain.
[01:18:22.700 --> 01:18:25.600]   Little bit of hypothalamus, little bit of basal ganglia, sure.
[01:18:25.600 --> 01:18:27.820]   - We need it all, we need it all.
[01:18:27.820 --> 01:18:32.820]   And this area of the brain has gotten a lot bigger
[01:18:32.820 --> 01:18:35.280]   as the cortex has gotten bigger,
[01:18:35.280 --> 01:18:39.320]   and it's deeply intertwined with cortical function.
[01:18:39.320 --> 01:18:41.520]   The cortex can't really do what it needs to do
[01:18:41.520 --> 01:18:43.680]   without the help of the basal ganglia and vice versa,
[01:18:43.680 --> 01:18:46.560]   so they're really intertwined.
[01:18:46.560 --> 01:18:51.600]   And in a way, you can think about this logically
[01:18:51.600 --> 01:18:55.440]   as saying if you have the ability to withhold behavior
[01:18:55.440 --> 01:18:58.880]   or to execute it, how do you decide which to do?
[01:18:58.880 --> 01:19:01.720]   Well, the cortex is gonna have to do that thinking for you.
[01:19:01.720 --> 01:19:04.340]   You have to be looking at all the contingencies
[01:19:04.340 --> 01:19:07.680]   of your situation to decide, is this a crazy move
[01:19:07.680 --> 01:19:11.480]   or is this a really smart investment right now or what?
[01:19:11.480 --> 01:19:13.120]   - I don't wanna go out for a run in the morning,
[01:19:13.120 --> 01:19:15.280]   I'm gonna make myself go out for a run,
[01:19:15.280 --> 01:19:17.840]   or I'm having a great time out on a run
[01:19:17.840 --> 01:19:19.040]   and I know I need to get back,
[01:19:19.040 --> 01:19:20.720]   but I kind of wanna go another mile.
[01:19:20.720 --> 01:19:23.640]   - I mean, another great example is that the marshmallow test
[01:19:23.640 --> 01:19:25.860]   for the little kids, they can get two marshmallows
[01:19:25.860 --> 01:19:30.860]   if they hold off just 30 seconds initially.
[01:19:30.860 --> 01:19:32.560]   They can have one right away,
[01:19:32.560 --> 01:19:34.280]   but if they can wait 30 seconds, they got two.
[01:19:34.280 --> 01:19:37.400]   So that's the no-go because their cortex is saying,
[01:19:37.400 --> 01:19:40.020]   I really like to have two more than having one,
[01:19:41.000 --> 01:19:43.920]   but they're not gonna get the two unless they can
[01:19:43.920 --> 01:19:45.680]   not reach for the one.
[01:19:45.680 --> 01:19:48.780]   So they've got to hold off the action
[01:19:48.780 --> 01:19:53.360]   and that has to result from a cognitive process.
[01:19:53.360 --> 01:19:56.660]   So the cortex is involved in this in a major way.
[01:19:56.660 --> 01:19:59.000]   - Yeah, as I recall in that experiment,
[01:19:59.000 --> 01:20:01.000]   the kids used a variety of tools to,
[01:20:01.000 --> 01:20:03.000]   some would distract themselves.
[01:20:03.000 --> 01:20:04.880]   I particularly related to the kid that would just
[01:20:04.880 --> 01:20:07.320]   put himself right next to the marshmallows
[01:20:07.320 --> 01:20:09.960]   and then some of the kids covered their eyes,
[01:20:09.960 --> 01:20:11.840]   some of them would count or sing.
[01:20:11.840 --> 01:20:13.280]   Yeah, so that's all very cortical, right?
[01:20:13.280 --> 01:20:15.080]   Coming up with a novel strategy,
[01:20:15.080 --> 01:20:16.560]   simple example that we're using here.
[01:20:16.560 --> 01:20:19.520]   But of course, this is at play anytime someone decides
[01:20:19.520 --> 01:20:21.880]   they wanna go watch a motivational speech or something,
[01:20:21.880 --> 01:20:24.260]   just, you know, a Steve Jobs commencement speech
[01:20:24.260 --> 01:20:26.560]   just to get motivated to engage in their day.
[01:20:26.560 --> 01:20:28.360]   - Should I take this new job?
[01:20:28.360 --> 01:20:30.000]   You know, it's got great benefits,
[01:20:30.000 --> 01:20:32.080]   but it's in a lousy part of the country.
[01:20:32.080 --> 01:20:36.080]   - Why do you think that some people have a harder time
[01:20:36.080 --> 01:20:38.120]   running these go no-go circuits
[01:20:38.120 --> 01:20:42.180]   and other people seem to have very low activation energy,
[01:20:42.180 --> 01:20:43.020]   we would say.
[01:20:43.020 --> 01:20:44.720]   They can just, you know, they have a task,
[01:20:44.720 --> 01:20:46.040]   they just lean into the task.
[01:20:46.040 --> 01:20:49.040]   Whereas some people getting into task completion
[01:20:49.040 --> 01:20:52.440]   or things of that sort is very challenging for them.
[01:20:52.440 --> 01:20:54.920]   - Yeah, I mean, I think it's really just another,
[01:20:54.920 --> 01:20:57.280]   it's a special case of a very general phenomenon,
[01:20:57.280 --> 01:21:00.280]   which is brains are complicated
[01:21:00.280 --> 01:21:05.280]   and brains we have are the result of genetics and experience
[01:21:07.000 --> 01:21:08.820]   and my genes are different from your genes
[01:21:08.820 --> 01:21:11.000]   and my experiences are different from your experiences.
[01:21:11.000 --> 01:21:13.600]   So the things that will be easy or hard for us
[01:21:13.600 --> 01:21:15.040]   won't necessarily be aligned.
[01:21:15.040 --> 01:21:18.640]   They might just happen to be just because they are.
[01:21:18.640 --> 01:21:20.560]   But the point is that, you know,
[01:21:20.560 --> 01:21:23.940]   you're dealt a certain set of cards,
[01:21:23.940 --> 01:21:27.640]   you have a certain set of genes, you are handed a brain.
[01:21:27.640 --> 01:21:30.280]   You don't choose your brain, it's handed to you.
[01:21:30.280 --> 01:21:32.300]   But then there's all this stuff you can do with it.
[01:21:32.300 --> 01:21:34.100]   You know, you can learn.
[01:21:36.320 --> 01:21:39.880]   You know, to have new skills or to act differently
[01:21:39.880 --> 01:21:41.240]   or to show more restraint,
[01:21:41.240 --> 01:21:43.820]   which is kind of relevant to what we're talking about here,
[01:21:43.820 --> 01:21:47.200]   or maybe show less restraint if your problem is
[01:21:47.200 --> 01:21:49.200]   you're so buttoned down, you never have any fun in life
[01:21:49.200 --> 01:21:50.840]   and you should loosen up a little bit.
[01:21:50.840 --> 01:21:52.680]   - Thank you, I appreciate the insult.
[01:21:52.680 --> 01:21:53.520]   Yeah.
[01:21:53.520 --> 01:21:58.120]   David's always encouraged me to have a little more fun.
[01:21:58.120 --> 01:22:04.080]   So basal ganglia are, they're kind of the disciplinarian
[01:22:04.080 --> 01:22:07.960]   or they're sort of the instructor conductor of sorts, right?
[01:22:07.960 --> 01:22:11.440]   Go, no go, you know, you be quiet, you start now.
[01:22:11.440 --> 01:22:14.920]   - I wish I knew more about the basal ganglia than I do.
[01:22:14.920 --> 01:22:19.320]   My sense is that it, you know, this system is key
[01:22:19.320 --> 01:22:23.500]   for implementing the plans that get cooked up in the cortex,
[01:22:23.500 --> 01:22:27.640]   but they also influence the plans
[01:22:27.640 --> 01:22:30.540]   that the cortex is dishing out
[01:22:30.540 --> 01:22:33.700]   because this is a major source of information
[01:22:33.700 --> 01:22:34.540]   to the cortex.
[01:22:34.540 --> 01:22:36.900]   So it becomes almost impossible to figure out
[01:22:36.900 --> 01:22:40.640]   where the computation begins and where it ends
[01:22:40.640 --> 01:22:41.780]   and who's doing what,
[01:22:41.780 --> 01:22:44.200]   because these things are all interacting
[01:22:44.200 --> 01:22:45.780]   in a complex network.
[01:22:45.780 --> 01:22:47.600]   And it's all of it, it's the whole network.
[01:22:47.600 --> 01:22:49.380]   It's not, you know, one is the leader
[01:22:49.380 --> 01:22:50.500]   and the other is the follower.
[01:22:50.500 --> 01:22:51.340]   - Right, of course.
[01:22:51.340 --> 01:22:53.320]   Yeah, these are, all the structures that we're discussing
[01:22:53.320 --> 01:22:55.400]   are working in parallel.
[01:22:55.400 --> 01:22:56.240]   - Right.
[01:22:56.240 --> 01:22:59.140]   - And there's a lot of changing crosstalk.
[01:22:59.140 --> 01:23:03.260]   I have this somewhat sick habit, David,
[01:23:03.260 --> 01:23:06.200]   every day I try and do 21 no-goes.
[01:23:06.200 --> 01:23:08.160]   So if I want to reach for my phone,
[01:23:08.160 --> 01:23:12.080]   I try and not do it just to see if I can prevent myself
[01:23:12.080 --> 01:23:15.520]   from engaging in that behavior, if it was reflexive.
[01:23:15.520 --> 01:23:18.520]   If it's something I want to do, deliberate choice,
[01:23:18.520 --> 01:23:20.560]   then I certainly allow myself to do it.
[01:23:20.560 --> 01:23:22.880]   I don't tend to have too much trouble with motivation,
[01:23:22.880 --> 01:23:25.880]   with go type functions, mostly because I'm so busy
[01:23:25.880 --> 01:23:29.160]   that I wish I had more time for more goes,
[01:23:29.160 --> 01:23:31.100]   but so to speak.
[01:23:31.100 --> 01:23:34.880]   But do you think these circuits have genuine plasticity
[01:23:34.880 --> 01:23:35.720]   in them?
[01:23:35.720 --> 01:23:36.540]   - Absolutely.
[01:23:36.540 --> 01:23:39.580]   I mean, everybody knows how they've learned over time
[01:23:39.580 --> 01:23:41.600]   to wait for the two marshmallows, right?
[01:23:41.600 --> 01:23:44.000]   You know, you don't have to have instant gratification
[01:23:44.000 --> 01:23:44.840]   all the time.
[01:23:44.840 --> 01:23:48.380]   You know, you're willing to do a job sometimes
[01:23:48.380 --> 01:23:49.480]   that isn't your favorite job
[01:23:49.480 --> 01:23:50.840]   because it comes with the territory
[01:23:50.840 --> 01:23:52.800]   and you want the salary that comes at the end of the week
[01:23:52.800 --> 01:23:54.200]   or the end of the month, right?
[01:23:54.200 --> 01:23:57.240]   So we can defer gratification.
[01:23:57.240 --> 01:23:59.900]   You know, we can choose not to say the thing
[01:23:59.900 --> 01:24:01.880]   that we know is going to inflame our partner
[01:24:01.880 --> 01:24:04.960]   and create a meltdown for the next week.
[01:24:04.960 --> 01:24:07.920]   You know, we learn this control,
[01:24:07.920 --> 01:24:10.120]   but I think these are skills like any other.
[01:24:10.120 --> 01:24:13.080]   You can get better at them if you practice them.
[01:24:13.080 --> 01:24:15.720]   So I think you're choosing to do that spontaneously
[01:24:15.720 --> 01:24:18.020]   as kind of a, you know, it's a mental practice.
[01:24:18.020 --> 01:24:18.860]   It's a discipline.
[01:24:18.860 --> 01:24:21.760]   It's a way of building a skill that you want to have.
[01:24:21.760 --> 01:24:25.360]   - Yeah, I find it to be something that when I engage
[01:24:25.360 --> 01:24:28.260]   in a no-go type situation,
[01:24:29.860 --> 01:24:32.040]   then the next time and the next time
[01:24:32.040 --> 01:24:34.640]   that I find myself about to move reflexively,
[01:24:34.640 --> 01:24:36.320]   there's a little gap in consciousness
[01:24:36.320 --> 01:24:38.240]   that I can make a decision
[01:24:38.240 --> 01:24:40.820]   whether or not this is really the best use of my time.
[01:24:40.820 --> 01:24:42.760]   Because I sometimes wonder
[01:24:42.760 --> 01:24:45.440]   whether or not all this business around attention,
[01:24:45.440 --> 01:24:46.960]   certainly there's the case of ADHD
[01:24:46.960 --> 01:24:48.680]   and clinical diagnosed ADHD,
[01:24:48.680 --> 01:24:51.200]   but all these, the issue around focus and attention
[01:24:51.200 --> 01:24:53.440]   is really that people just have not really learned
[01:24:53.440 --> 01:24:56.260]   how to short circuit a reflex.
[01:24:56.260 --> 01:24:59.140]   And so much of what makes us different than rattlesnakes
[01:24:59.140 --> 01:25:01.120]   or, well, actually they could be deliberate,
[01:25:01.120 --> 01:25:03.240]   but from the other animals
[01:25:03.240 --> 01:25:06.400]   and is our ability to suppress reflex.
[01:25:06.400 --> 01:25:08.280]   - Yeah, well, that's the cortex.
[01:25:08.280 --> 01:25:10.040]   I mean, or let's say the forebrain.
[01:25:10.040 --> 01:25:12.580]   Cortex and basal ganglia working together,
[01:25:12.580 --> 01:25:15.600]   sitting on top of this lizard brain
[01:25:15.600 --> 01:25:17.920]   that's giving you all these great adaptive reflexes
[01:25:17.920 --> 01:25:19.440]   that help you survive.
[01:25:19.440 --> 01:25:22.400]   You just hope you don't get the surprising case
[01:25:22.400 --> 01:25:24.640]   where the thing that your reflex is telling you
[01:25:24.640 --> 01:25:26.160]   is actually exactly the wrong thing
[01:25:26.160 --> 01:25:28.280]   and you make a mistake, right?
[01:25:28.280 --> 01:25:29.900]   - Right, so that's what the cortex is for.
[01:25:29.900 --> 01:25:33.780]   It's adding nuance and context and experience,
[01:25:33.780 --> 01:25:36.740]   past association, and in human beings,
[01:25:36.740 --> 01:25:41.360]   obviously learning from others through communication.
[01:25:41.360 --> 01:25:43.660]   - Well, I was, you went right to it
[01:25:43.660 --> 01:25:45.700]   and it was where I was gonna go.
[01:25:45.700 --> 01:25:47.100]   So let's talk about the cortex.
[01:25:47.100 --> 01:25:49.420]   We've worked our way up the so-called neuroaxis
[01:25:49.420 --> 01:25:52.640]   as the aficionados will know.
[01:25:52.640 --> 01:25:54.120]   So we're in the cortex.
[01:25:54.120 --> 01:25:55.860]   This is the seat of our higher consciousness,
[01:25:55.860 --> 01:25:58.220]   self-image, planning and action.
[01:25:58.220 --> 01:26:00.500]   But as you mentioned, the cortex isn't just about that.
[01:26:00.500 --> 01:26:02.960]   It's got other regions that are involved in other things.
[01:26:02.960 --> 01:26:05.620]   So maybe we should, staying with vision,
[01:26:05.620 --> 01:26:07.880]   let's talk a little bit about visual cortex.
[01:26:07.880 --> 01:26:11.800]   You told me a story, an amazing story about visual cortex.
[01:26:11.800 --> 01:26:13.840]   And it was a somewhat of a sad story, unfortunately,
[01:26:13.840 --> 01:26:17.020]   about someone who had a stroke to visual cortex.
[01:26:17.020 --> 01:26:20.280]   Maybe if you would share that story,
[01:26:20.280 --> 01:26:23.240]   because I think it illustrates many important principles
[01:26:23.240 --> 01:26:25.080]   about what the cortex does.
[01:26:25.080 --> 01:26:29.680]   - Right, so the visual cortex is,
[01:26:29.680 --> 01:26:31.600]   you could say the projection screen,
[01:26:31.600 --> 01:26:35.720]   the first place where this information streaming
[01:26:35.720 --> 01:26:40.720]   from the retina through this thalamus connecting linker
[01:26:40.720 --> 01:26:46.780]   gets played out for the highest level of your brain to see.
[01:26:46.780 --> 01:26:48.800]   I mean, it's a representation.
[01:26:48.800 --> 01:26:52.560]   It's a map of things going on in the visual world
[01:26:52.560 --> 01:26:57.560]   that's in your brain, and when we describe a scene
[01:26:57.560 --> 01:27:03.320]   to a friend, we're using this chunk of our brain
[01:27:03.320 --> 01:27:04.960]   to be able to put words, which are coming
[01:27:04.960 --> 01:27:07.260]   from a different part of our cortex,
[01:27:07.260 --> 01:27:10.220]   to the objects and movements and colors
[01:27:10.220 --> 01:27:11.620]   that we see in the world.
[01:27:11.620 --> 01:27:17.740]   So that's a key part of your visual experience.
[01:27:17.740 --> 01:27:20.280]   When you can describe the things you're seeing,
[01:27:20.280 --> 01:27:23.560]   you're looking at your visual cortex, and this is-
[01:27:23.560 --> 01:27:24.640]   - Could I just ask a quick question?
[01:27:24.640 --> 01:27:27.780]   So right now, because I'm looking at your face,
[01:27:27.780 --> 01:27:31.060]   as we're talking, there are neurons in my brain,
[01:27:31.060 --> 01:27:34.720]   more or less in the configuration of your face
[01:27:34.720 --> 01:27:37.840]   that are active as you move about.
[01:27:37.840 --> 01:27:42.840]   And what if I were to close my eyes and just imagine,
[01:27:42.840 --> 01:27:44.960]   I do this all the time, by the way, David,
[01:27:44.960 --> 01:27:48.920]   I close my eyes and I imagine David Berson's face.
[01:27:48.920 --> 01:27:51.080]   I don't tend to do that as often, maybe I should,
[01:27:51.080 --> 01:27:52.360]   but you get the point.
[01:27:52.360 --> 01:27:55.760]   I'm now using visualization of what you look like
[01:27:55.760 --> 01:27:57.200]   by way of memory.
[01:27:57.200 --> 01:27:59.960]   If we were to image the neurons in my brain,
[01:27:59.960 --> 01:28:04.440]   would the activity of neurons resemble the activity
[01:28:04.440 --> 01:28:08.600]   of neurons that's present when I open my eyes
[01:28:08.600 --> 01:28:09.640]   and look at your actual face?
[01:28:09.640 --> 01:28:11.040]   - This is a deep question.
[01:28:11.040 --> 01:28:14.960]   We don't really have a full accounting yet.
[01:28:14.960 --> 01:28:18.760]   Yes, except you're talking about looking in detail
[01:28:18.760 --> 01:28:22.600]   at the activity of neurons in a human brain
[01:28:22.600 --> 01:28:25.120]   and that's not as easy to do as it would be
[01:28:25.120 --> 01:28:27.420]   in some kind of animal model.
[01:28:27.420 --> 01:28:32.420]   But the bottom line is that you have a spatial representation
[01:28:32.420 --> 01:28:36.740]   of the visual world, laid as a map of the visual world,
[01:28:36.740 --> 01:28:38.880]   laid out on the surface of your cortex.
[01:28:38.880 --> 01:28:42.560]   The thing that's surprising is that it's not one map.
[01:28:42.560 --> 01:28:44.840]   It's actually dozens of maps.
[01:28:44.840 --> 01:28:46.360]   - What do each of those maps do?
[01:28:46.360 --> 01:28:48.720]   - Well, we don't really have a full accounting there either,
[01:28:48.720 --> 01:28:52.200]   but it looks a little bit like the diversification
[01:28:52.200 --> 01:28:54.960]   of the output neurons of the retina,
[01:28:54.960 --> 01:28:56.920]   the ganglion cells we were talking about before.
[01:28:56.920 --> 01:28:58.760]   There are different types of ganglion cells
[01:28:58.760 --> 01:29:00.920]   that are encoding different kinds of information
[01:29:00.920 --> 01:29:01.920]   about the visual world.
[01:29:01.920 --> 01:29:05.020]   We talk about the ones that were encoding the brightness,
[01:29:05.020 --> 01:29:07.720]   but other ones are encoding motion or color,
[01:29:07.720 --> 01:29:08.800]   these kinds of things.
[01:29:08.800 --> 01:29:10.560]   The same kinds of specializations
[01:29:10.560 --> 01:29:12.960]   in different representations of the visual world
[01:29:12.960 --> 01:29:15.980]   in the cortex seem to be true.
[01:29:15.980 --> 01:29:17.200]   It's a complex story.
[01:29:17.200 --> 01:29:19.900]   We don't have the whole picture yet,
[01:29:19.900 --> 01:29:21.760]   but it does look as if some parts of the brain
[01:29:21.760 --> 01:29:26.160]   are much more important for things like reaching for things
[01:29:26.160 --> 01:29:28.160]   in the space around you.
[01:29:28.160 --> 01:29:30.040]   And other parts of the cortex are really important
[01:29:30.040 --> 01:29:32.800]   for making associations between particular visual things
[01:29:32.800 --> 01:29:35.840]   you're looking at now and their significance.
[01:29:35.840 --> 01:29:37.600]   What is that object?
[01:29:37.600 --> 01:29:38.440]   What can it do for me?
[01:29:38.440 --> 01:29:39.640]   How can I use it?
[01:29:39.640 --> 01:29:42.360]   - What about the really specialized areas of cortex,
[01:29:42.360 --> 01:29:46.460]   like neurons that respond to particular faces,
[01:29:46.460 --> 01:29:49.600]   or neurons that, I don't know,
[01:29:49.600 --> 01:29:52.320]   can help me understand where I am
[01:29:52.320 --> 01:29:54.680]   relative to some other specific object?
[01:29:54.680 --> 01:29:58.960]   - Right, so these are properties of neurons
[01:29:58.960 --> 01:30:03.960]   that are extracted from, detected by,
[01:30:03.960 --> 01:30:07.500]   recording the activity of single neurons
[01:30:07.500 --> 01:30:09.500]   in some experimental system.
[01:30:09.500 --> 01:30:11.880]   What's going on when you actually perceive
[01:30:11.880 --> 01:30:15.440]   your grandmother's face is a much more complicated question.
[01:30:15.440 --> 01:30:17.560]   It clearly involves hundreds and thousands
[01:30:17.560 --> 01:30:19.680]   and probably millions of neurons
[01:30:19.680 --> 01:30:21.480]   acting in a cooperative way.
[01:30:21.480 --> 01:30:23.900]   So you can pick out any one little element
[01:30:23.900 --> 01:30:26.060]   in this very complicated system
[01:30:26.060 --> 01:30:28.160]   and see that it's responding differentially
[01:30:28.160 --> 01:30:29.940]   to certain kinds of visual patterns.
[01:30:29.940 --> 01:30:31.620]   And you think you're seeing a glimpse
[01:30:31.620 --> 01:30:33.040]   of some part of the process
[01:30:33.040 --> 01:30:36.140]   by which you recognize your grandmother's face.
[01:30:36.140 --> 01:30:38.940]   But that's a long way from a complete description.
[01:30:38.940 --> 01:30:40.940]   And it certainly isn't gonna be at the level
[01:30:40.940 --> 01:30:44.160]   of a magic single neuron that has the special stuff
[01:30:44.160 --> 01:30:45.320]   to recognize your grandmother.
[01:30:45.320 --> 01:30:47.640]   It's gonna be in some pattern of activity
[01:30:47.640 --> 01:30:50.980]   across many, many cells resonating
[01:30:50.980 --> 01:30:52.900]   in some kind of special way
[01:30:52.900 --> 01:30:57.580]   that will represent the internal memory of your mother.
[01:30:57.580 --> 01:30:59.120]   - Which is really incredible.
[01:30:59.120 --> 01:30:59.960]   - Yeah.
[01:30:59.960 --> 01:31:01.620]   - I mean, every time we do this deep dive,
[01:31:01.620 --> 01:31:02.840]   which we do from time to time,
[01:31:02.840 --> 01:31:05.240]   you and I, we kind of like march into the nervous system
[01:31:05.240 --> 01:31:08.640]   and explore how different aspects
[01:31:08.640 --> 01:31:12.520]   of our life experiences is handled there
[01:31:12.520 --> 01:31:14.000]   and how it's organized.
[01:31:15.040 --> 01:31:17.620]   It, after so many decades of doing this,
[01:31:17.620 --> 01:31:22.620]   it still boggles my mind that the collection of neurons,
[01:31:22.620 --> 01:31:26.400]   one through seven, active in a particular sequence
[01:31:26.400 --> 01:31:28.940]   gives the memory of a particular face
[01:31:28.940 --> 01:31:32.600]   and run backwards seven through to one.
[01:31:32.600 --> 01:31:33.640]   It gives you a complete, you know,
[01:31:33.640 --> 01:31:37.260]   could be, you know, rattlesnake, pit viper,
[01:31:37.260 --> 01:31:39.920]   heat sensing organs, as we were talking about earlier.
[01:31:39.920 --> 01:31:43.240]   So it sounds, is it true that there's a lot
[01:31:43.240 --> 01:31:45.520]   of multi-purposing of the circuitry?
[01:31:45.520 --> 01:31:49.280]   Like we can't say one area of the brain does A
[01:31:49.280 --> 01:31:50.960]   and another area of the brain does B.
[01:31:50.960 --> 01:31:54.120]   So, you know, areas can multitask
[01:31:54.120 --> 01:31:56.440]   or have multiple jobs, they can moonlight.
[01:31:56.440 --> 01:32:01.120]   - Right, but I think in my career,
[01:32:01.120 --> 01:32:05.160]   the hard problem has been to square that
[01:32:05.160 --> 01:32:10.880]   with the fact that, you know, things are specialized,
[01:32:10.880 --> 01:32:14.840]   that there are specific genes expressed in specific neurons
[01:32:14.840 --> 01:32:17.160]   that make them make synaptic connections
[01:32:17.160 --> 01:32:19.240]   with only certain other neurons.
[01:32:19.240 --> 01:32:22.880]   And that particular synaptic arrangement actually results
[01:32:22.880 --> 01:32:26.180]   in the processing of information that's useful
[01:32:26.180 --> 01:32:28.400]   to the animal to survive, right?
[01:32:28.400 --> 01:32:33.400]   So it's not as if it's either a big undifferentiated network
[01:32:33.400 --> 01:32:35.840]   of cells and looking at any one
[01:32:35.840 --> 01:32:37.060]   is never gonna tell you anything,
[01:32:37.060 --> 01:32:39.280]   that's too extreme on the one hand,
[01:32:39.280 --> 01:32:41.040]   nor is it the case that everything is hardwired
[01:32:41.040 --> 01:32:42.600]   and every neuron has one function
[01:32:42.600 --> 01:32:45.760]   and this all happens in one place in the brain.
[01:32:45.760 --> 01:32:47.960]   It's way more complicated and interactive
[01:32:47.960 --> 01:32:49.560]   and interconnected than that.
[01:32:49.560 --> 01:32:52.160]   - So we're not hardwired or softwired.
[01:32:52.160 --> 01:32:54.920]   We're sort of, I don't know what the analogy should be.
[01:32:54.920 --> 01:32:57.120]   What substance would work best, David?
[01:32:57.120 --> 01:32:58.920]   - No idea there, but you know,
[01:32:58.920 --> 01:33:03.420]   the idea is that it's always network activity.
[01:33:03.420 --> 01:33:06.040]   There's always many, many neurons involved
[01:33:06.040 --> 01:33:08.680]   and yet there's tremendous specificity
[01:33:08.680 --> 01:33:10.940]   in the neurons that might or might not be participating
[01:33:10.940 --> 01:33:13.860]   in any distributed function like that, right?
[01:33:13.860 --> 01:33:15.400]   So you have to get your mind around the fact
[01:33:15.400 --> 01:33:17.300]   that it's both very specific
[01:33:17.300 --> 01:33:19.360]   and very nonspecific at the same time.
[01:33:19.360 --> 01:33:20.600]   It's a little tricky to do,
[01:33:20.600 --> 01:33:23.080]   but I think that's kind of where the truth lies.
[01:33:23.080 --> 01:33:27.180]   - Yeah, and so this example that you mentioned
[01:33:27.180 --> 01:33:29.760]   to me once before about a woman who had a stroke
[01:33:29.760 --> 01:33:32.120]   in visual cortex, I think it speaks to some of this.
[01:33:32.120 --> 01:33:33.340]   - Right.
[01:33:33.340 --> 01:33:34.760]   - Could you share with us that story?
[01:33:34.760 --> 01:33:38.480]   - Sure, so the point is that you all,
[01:33:38.480 --> 01:33:42.280]   those of us who see, have representations
[01:33:42.280 --> 01:33:44.680]   of the visual world and our visual cortex.
[01:33:44.680 --> 01:33:49.680]   What happens to somebody when they become blind
[01:33:49.680 --> 01:33:53.460]   because of problems in the eye, the retina, perhaps?
[01:33:53.460 --> 01:33:56.440]   You have a big chunk of the cortex,
[01:33:56.440 --> 01:33:59.520]   this really valuable real estate for neural processing
[01:33:59.520 --> 01:34:05.040]   that has come to expect input from the visual system
[01:34:05.040 --> 01:34:06.480]   and there isn't any anymore.
[01:34:06.480 --> 01:34:08.960]   So you might think about that as fallow land, right?
[01:34:08.960 --> 01:34:13.080]   It's unused by the nervous system.
[01:34:13.080 --> 01:34:13.920]   And that would be a pity,
[01:34:13.920 --> 01:34:16.640]   but it turns out that it is in fact used.
[01:34:16.640 --> 01:34:20.840]   And the case that you're talking about
[01:34:20.840 --> 01:34:25.840]   is of a woman who was blind from very early in her life
[01:34:25.840 --> 01:34:30.400]   and who had risen through the ranks
[01:34:30.400 --> 01:34:33.720]   to a very high level executive secretarial position
[01:34:33.720 --> 01:34:35.340]   in a major corporation.
[01:34:36.200 --> 01:34:38.640]   And she was extremely good at braille reading
[01:34:38.640 --> 01:34:39.760]   and she had a braille typewriter
[01:34:39.760 --> 01:34:41.960]   and that's how everything was done.
[01:34:41.960 --> 01:34:44.980]   And apparently she had a stroke
[01:34:44.980 --> 01:34:46.600]   and was discovered at work, collapsed,
[01:34:46.600 --> 01:34:48.460]   and they brought her to the hospital.
[01:34:48.460 --> 01:34:51.980]   And apparently the neurologist who saw her
[01:34:51.980 --> 01:34:54.500]   when she finally came to said,
[01:34:54.500 --> 01:34:56.200]   I've got good news and bad news.
[01:34:56.200 --> 01:34:57.960]   Bad news is you've had a stroke.
[01:34:57.960 --> 01:35:00.260]   The good news is that it was in an area of your brain
[01:35:00.260 --> 01:35:03.040]   you're not even using, it's your visual cortex.
[01:35:03.040 --> 01:35:04.580]   And I know you're blind from birth,
[01:35:04.580 --> 01:35:06.560]   so there shouldn't be any issue here.
[01:35:06.560 --> 01:35:10.000]   The problem was she lost her ability to read braille.
[01:35:10.000 --> 01:35:13.500]   So what appears to have been the case,
[01:35:13.500 --> 01:35:16.380]   and this has been confirmed in other ways
[01:35:16.380 --> 01:35:18.700]   by imaging experiments in humans,
[01:35:18.700 --> 01:35:22.020]   is that in people who are blind from very early in birth,
[01:35:22.020 --> 01:35:25.260]   the visual cortex gets repurposed
[01:35:25.260 --> 01:35:28.780]   as a center for processing tactile information.
[01:35:28.780 --> 01:35:31.560]   And especially if you drain to be a good braille reader,
[01:35:31.560 --> 01:35:34.320]   you're actually reallocating somehow
[01:35:34.320 --> 01:35:37.300]   that real estate to your fingertips,
[01:35:37.300 --> 01:35:38.380]   you know, a part of the cortex
[01:35:38.380 --> 01:35:40.260]   that should be listening to the eyes.
[01:35:40.260 --> 01:35:42.440]   So that's an extreme level of plasticity,
[01:35:42.440 --> 01:35:45.740]   but what it shows is the visual cortex
[01:35:45.740 --> 01:35:48.760]   is kind of a general purpose processing machine.
[01:35:48.760 --> 01:35:51.620]   It's good at spatial information
[01:35:51.620 --> 01:35:55.060]   and the skin of your fingers is just another spatial sense
[01:35:55.060 --> 01:35:57.360]   and deprived of any other input.
[01:35:57.360 --> 01:35:59.620]   The brain seems smart enough,
[01:35:59.620 --> 01:36:01.100]   if you want to put it that way,
[01:36:01.100 --> 01:36:05.160]   to rewire itself, to use that real estate for something
[01:36:05.160 --> 01:36:07.120]   useful, in this case, reading braille.
[01:36:07.120 --> 01:36:08.840]   - Incredible.
[01:36:08.840 --> 01:36:10.340]   Somewhat tragic, but incredible.
[01:36:10.340 --> 01:36:12.280]   At least in that case, tragic.
[01:36:12.280 --> 01:36:13.120]   - Very informative.
[01:36:13.120 --> 01:36:14.080]   - Very informative.
[01:36:14.080 --> 01:36:16.080]   And of course it can go the other way too,
[01:36:16.080 --> 01:36:20.160]   where people can gain function in particular modalities
[01:36:20.160 --> 01:36:22.640]   like improved hearing or tactile function
[01:36:22.640 --> 01:36:23.960]   in the absence of vision.
[01:36:23.960 --> 01:36:24.800]   - Right.
[01:36:24.800 --> 01:36:29.360]   - Tell us about connectomes.
[01:36:29.360 --> 01:36:33.040]   We hear about genomes, proteomes, microbiomes,
[01:36:33.040 --> 01:36:35.580]   ohms, ohms, ohms these days.
[01:36:35.580 --> 01:36:39.360]   What's a connectome and why is it valuable?
[01:36:39.360 --> 01:36:42.720]   - Yeah, so connectome actually now has two meanings.
[01:36:42.720 --> 01:36:47.680]   So I only refer to the one that is my passion right now,
[01:36:47.680 --> 01:36:50.100]   and that is really trying to understand the structure
[01:36:50.100 --> 01:36:55.100]   of nervous tissue at a scale that's very, very fine.
[01:36:55.100 --> 01:36:59.160]   - Smaller than a millimeter.
[01:36:59.160 --> 01:37:02.680]   - Way smaller than a millimeter, a nanometer or less.
[01:37:02.680 --> 01:37:04.580]   As that's a thousand times smaller,
[01:37:04.580 --> 01:37:11.080]   or it's actually a million times smaller.
[01:37:11.080 --> 01:37:16.080]   So really, really tiny on the scale of individual synapses
[01:37:16.080 --> 01:37:18.140]   between individual neurons or even smaller,
[01:37:18.140 --> 01:37:20.440]   like the individual synaptic vesicles
[01:37:20.440 --> 01:37:22.240]   containing little packets of neurotransmitter
[01:37:22.240 --> 01:37:23.800]   that are gonna get released
[01:37:23.800 --> 01:37:26.360]   to allow one neuron to communicate to the next.
[01:37:26.360 --> 01:37:27.820]   So very, very fine.
[01:37:28.300 --> 01:37:33.300]   But the notion here is that you're doing this
[01:37:33.300 --> 01:37:39.300]   section after section at very fine scale.
[01:37:39.300 --> 01:37:41.900]   So in theory, what you have is a complete description
[01:37:41.900 --> 01:37:46.300]   of a chunk of nervous tissue that is so complete
[01:37:46.300 --> 01:37:48.080]   that if you took enough time to identify
[01:37:48.080 --> 01:37:49.860]   where the boundaries of all the cells are,
[01:37:49.860 --> 01:37:52.380]   you could come up with a complete description
[01:37:52.380 --> 01:37:55.780]   of the synaptic wiring of that chunk of nervous tissue
[01:37:55.780 --> 01:37:56.860]   because you have a complete description
[01:37:56.860 --> 01:37:58.980]   where all the cells are and where all the synapses
[01:37:58.980 --> 01:38:00.380]   between where all the cells are.
[01:38:00.380 --> 01:38:02.700]   So now you essentially have a wiring diagram
[01:38:02.700 --> 01:38:04.660]   of this complicated piece of tissue.
[01:38:04.660 --> 01:38:08.540]   So the omics part is the exhaustiveness of it.
[01:38:08.540 --> 01:38:10.620]   Rather than looking at a couple of synapses
[01:38:10.620 --> 01:38:13.860]   that are interesting to you from two different cell types,
[01:38:13.860 --> 01:38:17.980]   you're looking at all the synapses of all of the cell types,
[01:38:17.980 --> 01:38:22.680]   which of course is this massive avalanche of data, right?
[01:38:22.680 --> 01:38:25.340]   - So in genetics, you have genetics and then you have genomics
[01:38:25.340 --> 01:38:27.060]   which is the idea of getting the whole genome.
[01:38:27.060 --> 01:38:27.900]   - All of it.
[01:38:27.900 --> 01:38:30.900]   - And we don't really have an analogous word for genetics,
[01:38:30.900 --> 01:38:33.180]   but it would be connectivity and canomics.
[01:38:33.180 --> 01:38:35.540]   - Right, connectivity. - Excuse me, connectomics.
[01:38:35.540 --> 01:38:36.980]   - Connectomics, sure, sure.
[01:38:36.980 --> 01:38:38.020]   - Connectivity and connectomics.
[01:38:38.020 --> 01:38:40.340]   - Right, so it's wanting it all.
[01:38:40.340 --> 01:38:42.700]   And of course it's crazy ambitious,
[01:38:42.700 --> 01:38:45.240]   but that's where it gets fun.
[01:38:45.240 --> 01:38:48.540]   Really it's a use of electron microscopy,
[01:38:48.540 --> 01:38:53.480]   a very high resolution microscopic imaging system
[01:38:53.480 --> 01:38:56.900]   on a new scale with way more payoff
[01:38:56.900 --> 01:38:58.700]   in terms of understanding the connectivity
[01:38:58.700 --> 01:38:59.540]   of the nervous system.
[01:38:59.540 --> 01:39:01.520]   And it's just emerging,
[01:39:01.520 --> 01:39:04.300]   but I really think it's gonna revolutionize the field
[01:39:04.300 --> 01:39:07.240]   because we're gonna be able to query these circuits.
[01:39:07.240 --> 01:39:08.540]   How did they actually do it?
[01:39:08.540 --> 01:39:09.900]   Look at the hardware
[01:39:09.900 --> 01:39:12.420]   in a way that's never been possible before.
[01:39:12.420 --> 01:39:15.100]   - The way that I describe this to people is
[01:39:15.100 --> 01:39:18.300]   if you were to take a chunk of kind of cooked
[01:39:18.300 --> 01:39:21.760]   but cold spaghetti and slice it up very thin,
[01:39:21.760 --> 01:39:25.940]   and you're trying to connect up each image of each slice
[01:39:25.940 --> 01:39:28.100]   of the edge of the spaghetti
[01:39:28.100 --> 01:39:30.820]   as figure out which ropes of spaghetti belong to which.
[01:39:30.820 --> 01:39:32.220]   - And have a complete description
[01:39:32.220 --> 01:39:33.820]   of where this piece of spaghetti touches
[01:39:33.820 --> 01:39:34.660]   that piece of spaghetti,
[01:39:34.660 --> 01:39:36.340]   and is there something special there?
[01:39:36.340 --> 01:39:38.680]   - Where the meat sauce is and all the other cell types
[01:39:38.680 --> 01:39:43.680]   and the pesto, where it all is around the spaghetti,
[01:39:43.680 --> 01:39:44.740]   because those are the other cells,
[01:39:44.740 --> 01:39:47.520]   the blood vessels and the glial cells.
[01:39:47.520 --> 01:39:49.820]   So what's it good for?
[01:39:49.820 --> 01:39:51.780]   I mean, maps are great.
[01:39:51.780 --> 01:39:57.440]   I always think of connectomics and genomics and proteomics,
[01:39:57.440 --> 01:40:00.080]   et cetera, as necessary but not sufficient.
[01:40:00.080 --> 01:40:01.360]   - Right, right.
[01:40:01.360 --> 01:40:02.520]   So I mean, in many cases,
[01:40:02.520 --> 01:40:05.860]   what you do is you go out and probe the function,
[01:40:05.860 --> 01:40:08.000]   and you understand how the brain does the function
[01:40:08.000 --> 01:40:10.920]   by finding neurons that seem to be firing
[01:40:10.920 --> 01:40:14.100]   in association with this function that you're observing.
[01:40:14.100 --> 01:40:15.700]   And little by little, you work your way in,
[01:40:15.700 --> 01:40:17.300]   and now you wanna know what the connectivity is.
[01:40:17.300 --> 01:40:19.720]   Maybe the anatomy could help you.
[01:40:19.720 --> 01:40:21.540]   But this connectomics approach,
[01:40:21.540 --> 01:40:23.660]   or at least the serial electron microscopy
[01:40:23.660 --> 01:40:27.220]   reconstruction of neurons approach,
[01:40:27.220 --> 01:40:29.960]   really is allowing us to frame questions
[01:40:29.960 --> 01:40:33.460]   starting from the anatomy and saying,
[01:40:33.460 --> 01:40:35.120]   I see a synaptic circuit here.
[01:40:35.120 --> 01:40:37.200]   My prediction would be that these cell types
[01:40:37.200 --> 01:40:38.860]   would interact in a particular way.
[01:40:38.860 --> 01:40:40.160]   Is that right?
[01:40:40.160 --> 01:40:42.180]   And then you can go and probe the physiology,
[01:40:42.180 --> 01:40:43.760]   and you might be right or you might be wrong.
[01:40:43.760 --> 01:40:45.380]   But more often than not,
[01:40:45.380 --> 01:40:47.460]   it looks like the structure is pointing us
[01:40:47.460 --> 01:40:48.780]   in the right direction.
[01:40:48.780 --> 01:40:53.500]   So in my case, I'm using this to try to understand a circuit
[01:40:53.500 --> 01:40:56.160]   that is involved in this image stabilization network
[01:40:56.160 --> 01:41:00.260]   we're talking about, keeping things stable on the retina.
[01:41:00.260 --> 01:41:02.540]   And this thing will only respond
[01:41:02.540 --> 01:41:04.740]   at certain speeds of motion.
[01:41:04.740 --> 01:41:07.300]   These cells in the circuit, like slow motion,
[01:41:07.300 --> 01:41:09.180]   they won't respond to fast motion.
[01:41:09.180 --> 01:41:10.340]   How does that come about?
[01:41:10.340 --> 01:41:14.060]   Well, I was able to probe the circuitry.
[01:41:14.060 --> 01:41:15.500]   I knew what my cells looked like.
[01:41:15.500 --> 01:41:17.460]   I could see which other cells were talking to it.
[01:41:17.460 --> 01:41:19.060]   I could categorize all the cells
[01:41:19.060 --> 01:41:20.580]   that might be the players here
[01:41:20.580 --> 01:41:22.240]   that are involved in this mechanism
[01:41:22.240 --> 01:41:25.520]   of tuning the thing for slow speeds.
[01:41:25.520 --> 01:41:27.860]   And then we said, it looks like it's that cell type.
[01:41:27.860 --> 01:41:31.120]   And we went and looked and the data bore that up.
[01:41:31.120 --> 01:41:34.500]   But the anatomy drove the search for the particular cell type
[01:41:34.500 --> 01:41:36.880]   because we could see it connected in the right place
[01:41:36.880 --> 01:41:38.020]   to the right cells.
[01:41:38.020 --> 01:41:40.100]   So that creates the hypothesis
[01:41:40.100 --> 01:41:42.620]   that lets you go query the physiology,
[01:41:42.620 --> 01:41:44.020]   but it can go the other way as well.
[01:41:44.020 --> 01:41:46.100]   So it's always the synergy between these functional
[01:41:46.100 --> 01:41:51.100]   and structural approaches that gives you the most lift.
[01:41:51.100 --> 01:41:53.660]   But in many cases,
[01:41:53.660 --> 01:41:56.660]   the anatomy has been a little bit the weak sister in this,
[01:41:56.660 --> 01:41:59.120]   the structure, trying to work out the diagram
[01:41:59.120 --> 01:42:00.900]   because we haven't had the methods.
[01:42:00.900 --> 01:42:02.660]   Now the methods exist.
[01:42:02.660 --> 01:42:05.740]   And this whole field is expanding very quickly
[01:42:05.740 --> 01:42:08.240]   because people want these circuit diagrams
[01:42:08.240 --> 01:42:10.900]   for the particular part of the nervous system
[01:42:10.900 --> 01:42:12.400]   that they're working on.
[01:42:12.400 --> 01:42:14.300]   If you don't know the cell types and the connections,
[01:42:14.300 --> 01:42:17.380]   how do you really understand how the machine works?
[01:42:17.380 --> 01:42:18.820]   - Yeah, what I love about is
[01:42:18.820 --> 01:42:20.580]   we don't know what we don't know.
[01:42:20.580 --> 01:42:22.700]   And as scientists, we don't ask questions.
[01:42:22.700 --> 01:42:23.860]   We pose hypotheses.
[01:42:23.860 --> 01:42:25.460]   Hypotheses being, of course,
[01:42:25.460 --> 01:42:29.260]   some prediction that you wager your time on, basically.
[01:42:29.260 --> 01:42:32.300]   And it either turns out to be true or not true.
[01:42:32.300 --> 01:42:37.580]   But if you don't know that a particular cell type is there,
[01:42:37.580 --> 01:42:42.540]   you could never in any configuration of life
[01:42:42.540 --> 01:42:46.540]   or a career or exploration of a nervous system
[01:42:46.540 --> 01:42:49.300]   wager a hypothesis because you didn't know it was there.
[01:42:49.300 --> 01:42:50.140]   So this allows you to say,
[01:42:50.140 --> 01:42:52.900]   "Ah, there's this little interesting little connection
[01:42:52.900 --> 01:42:54.980]   between this cell that I know is interesting
[01:42:54.980 --> 01:42:56.660]   and another cell that's a little mysterious,
[01:42:56.660 --> 01:42:57.600]   but interesting.
[01:42:57.600 --> 01:43:00.020]   I'm going to hypothesize that it's doing blank,
[01:43:00.020 --> 01:43:01.280]   blank, and blank and go test that."
[01:43:01.280 --> 01:43:03.400]   And in the absence of these connectomes,
[01:43:03.400 --> 01:43:04.540]   you would never know that that cell
[01:43:04.540 --> 01:43:06.540]   was lurking there in the shadows.
[01:43:06.540 --> 01:43:07.980]   - Right, right.
[01:43:07.980 --> 01:43:09.500]   Yeah, and if you're just trying to understand
[01:43:09.500 --> 01:43:14.240]   how information flows through this biological machine,
[01:43:14.240 --> 01:43:16.380]   you want to know where things are.
[01:43:16.380 --> 01:43:18.640]   Neuro-transmitters are dumped out of the terminals
[01:43:18.640 --> 01:43:21.880]   of one cell and they diffuse across the space
[01:43:21.880 --> 01:43:24.600]   between the two cells, which is kind of a liquidy space,
[01:43:24.600 --> 01:43:26.700]   and they hit some receptors on the postsynaptic cell
[01:43:26.700 --> 01:43:28.920]   and they have some impact.
[01:43:28.920 --> 01:43:31.400]   Sometimes that's not through a regular synapse.
[01:43:31.400 --> 01:43:33.080]   Sometimes it's through a neuromodulator,
[01:43:33.080 --> 01:43:35.840]   like you often talk about on your podcast,
[01:43:35.840 --> 01:43:36.680]   that are sort of oozing-
[01:43:36.680 --> 01:43:38.220]   - Dopamine or something. - Dopamine, exactly.
[01:43:38.220 --> 01:43:40.540]   Oozing into the space between the cells,
[01:43:40.540 --> 01:43:42.700]   and it may be acting at some distance
[01:43:42.700 --> 01:43:45.020]   far from where it was released, right?
[01:43:45.020 --> 01:43:47.200]   But if you don't know where the release is happening
[01:43:47.200 --> 01:43:49.200]   and where other things are that might respond
[01:43:49.200 --> 01:43:52.500]   to that release, you're groping around in the dark.
[01:43:52.500 --> 01:43:54.100]   - Well, I love that you are doing this,
[01:43:54.100 --> 01:43:57.800]   and I have to share with the listeners
[01:43:57.800 --> 01:44:00.460]   that the first time I ever met David,
[01:44:00.460 --> 01:44:03.220]   and every time I've ever met with him in person,
[01:44:03.220 --> 01:44:06.220]   at least at his laboratory at Brown,
[01:44:06.220 --> 01:44:08.740]   he was in his office, door closed,
[01:44:08.740 --> 01:44:11.740]   drawing neurons and their connections.
[01:44:11.740 --> 01:44:13.700]   And this is somewhat unusual for somebody
[01:44:13.700 --> 01:44:16.500]   who's a, you know, endowed full professor,
[01:44:16.500 --> 01:44:19.240]   chairman of the department, et cetera, for many years,
[01:44:19.240 --> 01:44:20.900]   to be doing the hands-on work.
[01:44:20.900 --> 01:44:22.780]   Typically that's the stuff that's done by technicians
[01:44:22.780 --> 01:44:24.180]   or graduate students or postdocs.
[01:44:24.180 --> 01:44:28.080]   But I think it's fair to say that you really love
[01:44:28.080 --> 01:44:31.460]   looking at nervous systems and drawing
[01:44:31.460 --> 01:44:34.940]   the accurate renditions of how those nervous systems
[01:44:34.940 --> 01:44:37.340]   are organized and thinking about how they work.
[01:44:37.340 --> 01:44:38.820]   - Yeah, it's pure joy for me.
[01:44:38.820 --> 01:44:40.440]   I mean, I'm a very visual person.
[01:44:40.440 --> 01:44:41.560]   My wife is an artist.
[01:44:41.560 --> 01:44:43.540]   We look at a lot of art together.
[01:44:43.540 --> 01:44:47.580]   Just the forms of things are gorgeous in their own right.
[01:44:47.580 --> 01:44:51.280]   But to know that the form is, in a sense, the function,
[01:44:51.280 --> 01:44:55.560]   that the architecture of the connectivity
[01:44:55.560 --> 01:44:59.460]   is how the computation happens in the brain at some level,
[01:44:59.460 --> 01:45:02.840]   even though we don't fully understand that in most contexts,
[01:45:02.840 --> 01:45:05.400]   gives me great joy, 'cause I'm working on something
[01:45:05.400 --> 01:45:09.880]   that's both visually beautiful, but also deeply beautiful
[01:45:09.880 --> 01:45:14.880]   and sort of a higher sort of knowledge context.
[01:45:14.880 --> 01:45:17.600]   You know, what is it all about?
[01:45:17.600 --> 01:45:18.440]   - Love it.
[01:45:18.440 --> 01:45:21.560]   Well, as a final question, I get asked very often
[01:45:21.560 --> 01:45:24.080]   about how people should learn about neuroscience
[01:45:24.080 --> 01:45:28.160]   or how they should go about pursuing maybe an education
[01:45:28.160 --> 01:45:30.320]   in neuroscience if they're at that stage of their life
[01:45:30.320 --> 01:45:34.040]   or that's appropriate for their current trajectory.
[01:45:34.040 --> 01:45:37.080]   Do you have any advice to young people, old people,
[01:45:37.080 --> 01:45:39.720]   and anything in between about how to learn
[01:45:39.720 --> 01:45:42.480]   about the nervous system, maybe in a more formal way?
[01:45:42.480 --> 01:45:43.880]   I mean, obviously we have our podcast.
[01:45:43.880 --> 01:45:46.800]   There are other sources of neuroscience information
[01:45:46.800 --> 01:45:49.340]   out there, but for the young person who thinks
[01:45:49.340 --> 01:45:51.600]   they want to understand the brain,
[01:45:51.600 --> 01:45:53.800]   they want to learn about the brain,
[01:45:53.800 --> 01:45:55.080]   what should we tell them?
[01:45:55.080 --> 01:45:56.360]   - Well, that's a great question.
[01:45:56.360 --> 01:45:57.840]   And there's so many sources out there.
[01:45:57.840 --> 01:46:01.080]   It's almost a question of how do you deal with this avalanche
[01:46:01.080 --> 01:46:02.840]   of information out there?
[01:46:02.840 --> 01:46:05.320]   I mean, I think our podcast is a great way for people
[01:46:05.320 --> 01:46:08.240]   to learn more about the nervous system in an accessible way,
[01:46:08.240 --> 01:46:09.760]   but there's so much stuff out there.
[01:46:09.760 --> 01:46:10.960]   And it's not just that.
[01:46:10.960 --> 01:46:13.920]   I mean, the resources are becoming more and more available
[01:46:13.920 --> 01:46:18.580]   for average folks to participate in neuroscience research
[01:46:18.580 --> 01:46:19.420]   on some level.
[01:46:19.420 --> 01:46:21.360]   There's this famous eye wire project of Sebastian Sommer.
[01:46:21.360 --> 01:46:23.240]   - Oh yeah, maybe tell us about eye wire.
[01:46:23.240 --> 01:46:24.560]   - Yeah, so that's connectomics.
[01:46:24.560 --> 01:46:28.200]   And that's a situation where a very clever scientist
[01:46:28.200 --> 01:46:31.600]   realized that the physical work
[01:46:31.600 --> 01:46:34.720]   of doing all this reconstruction of neurons
[01:46:34.720 --> 01:46:37.240]   from these electron micrographs,
[01:46:37.240 --> 01:46:39.920]   there's a lot of time involved.
[01:46:39.920 --> 01:46:42.400]   Many, many person hours have to go into that
[01:46:42.400 --> 01:46:44.760]   to come up with the map that you want
[01:46:44.760 --> 01:46:46.340]   of where the cells are.
[01:46:46.340 --> 01:46:49.240]   And he was very clever about setting up a context
[01:46:49.240 --> 01:46:51.360]   in which he could crowdsource this.
[01:46:51.360 --> 01:46:52.200]   And people who were interested
[01:46:52.200 --> 01:46:54.760]   in getting a little experience, looking at nervous tissue
[01:46:54.760 --> 01:46:57.440]   and participating in a research project
[01:46:57.440 --> 01:46:59.600]   could learn how to do this and do a little bit.
[01:46:59.600 --> 01:47:00.440]   - From their living room.
[01:47:00.440 --> 01:47:01.800]   - From their living room, their laptop.
[01:47:01.800 --> 01:47:03.040]   - We'll put a link to eye wire.
[01:47:03.040 --> 01:47:04.600]   That's a, it also is a great bridge
[01:47:04.600 --> 01:47:06.480]   between what we were just talking about connectomics
[01:47:06.480 --> 01:47:08.520]   and actually participating in research.
[01:47:08.520 --> 01:47:09.360]   - Right.
[01:47:09.360 --> 01:47:10.680]   - And you don't need a graduate mentor
[01:47:10.680 --> 01:47:12.120]   or anything like that.
[01:47:12.120 --> 01:47:14.640]   - Right, so more of this is coming
[01:47:14.640 --> 01:47:17.360]   and I'm actually interested in building more of this
[01:47:17.360 --> 01:47:20.160]   so that people who are interested,
[01:47:20.160 --> 01:47:21.560]   want to participate at some level,
[01:47:21.560 --> 01:47:24.520]   don't necessarily have the time or resources
[01:47:24.520 --> 01:47:27.160]   to get involved in laboratory research
[01:47:27.160 --> 01:47:29.920]   can get exposed to it and participate
[01:47:29.920 --> 01:47:31.120]   and actually contribute.
[01:47:31.120 --> 01:47:34.640]   So I think that's one thing.
[01:47:34.640 --> 01:47:38.240]   I mean, just asking questions of the people around you
[01:47:38.240 --> 01:47:39.400]   who know a little bit more
[01:47:39.400 --> 01:47:41.200]   and have them point you in the right direction.
[01:47:41.200 --> 01:47:42.600]   Here's a book you might like to read.
[01:47:42.600 --> 01:47:45.840]   There's lots of great popular books out there
[01:47:45.840 --> 01:47:48.760]   that are accessible that will give you some more sense
[01:47:48.760 --> 01:47:51.720]   of the full range of what's out there in the neurosciences
[01:47:51.720 --> 01:47:52.560]   and how-
[01:47:52.560 --> 01:47:53.640]   - We can put some links to a few of those
[01:47:53.640 --> 01:47:56.280]   that we like on basic neuroscience.
[01:47:56.280 --> 01:47:59.560]   Our good friend, Dick Maslin, the late Richard,
[01:47:59.560 --> 01:48:02.360]   people will call him Dick, Dick Maslin had a good book.
[01:48:02.360 --> 01:48:05.360]   I forget the title at the moment.
[01:48:05.360 --> 01:48:07.320]   It's sitting behind me somewhere over there on the shelf,
[01:48:07.320 --> 01:48:10.440]   but about vision and how nervous systems work.
[01:48:10.440 --> 01:48:12.600]   A pretty accessible book for the general public.
[01:48:12.600 --> 01:48:13.480]   - Right, right.
[01:48:13.480 --> 01:48:16.580]   So that, and there's so many sources out there.
[01:48:16.580 --> 01:48:18.120]   I mean, Wikipedia is a great way.
[01:48:18.120 --> 01:48:20.160]   If you had a particular question about visual function,
[01:48:20.160 --> 01:48:23.040]   I would say by all means head to Wikipedia
[01:48:23.040 --> 01:48:27.560]   and get the first look and follow the references from there
[01:48:27.560 --> 01:48:30.320]   or go to your library or, you know,
[01:48:30.320 --> 01:48:32.000]   there's so many ways to get into it.
[01:48:32.000 --> 01:48:33.960]   It's such an exciting field now.
[01:48:33.960 --> 01:48:35.080]   There's so many, I mean,
[01:48:35.080 --> 01:48:37.520]   any particular realm that's special to you,
[01:48:37.520 --> 01:48:40.000]   your experience, your, you know, your strengths,
[01:48:40.000 --> 01:48:44.000]   your passions, there's a field of neuroscience
[01:48:44.000 --> 01:48:44.840]   devoted to that.
[01:48:44.840 --> 01:48:45.680]   You know, if you've got,
[01:48:45.680 --> 01:48:47.920]   if you know somebody who's got a neurological problem
[01:48:47.920 --> 01:48:50.480]   or a psychiatric problem,
[01:48:50.480 --> 01:48:51.880]   there's a branch of neuroscience
[01:48:51.880 --> 01:48:54.640]   that is devoted to trying to understand that
[01:48:54.640 --> 01:48:57.480]   and to solve these kinds of problems down the line.
[01:48:57.480 --> 01:49:00.960]   So feel the, feel the buzz.
[01:49:00.960 --> 01:49:03.380]   It's an exciting time to get involved.
[01:49:03.380 --> 01:49:04.720]   - Great, those are great resources
[01:49:04.720 --> 01:49:06.520]   that people can access from anywhere,
[01:49:06.520 --> 01:49:08.780]   zero cost as you need an internet connection.
[01:49:08.780 --> 01:49:11.320]   But aside from that, we'll put the links to some,
[01:49:11.320 --> 01:49:13.820]   and I'm remembering Dick's book is called
[01:49:13.820 --> 01:49:15.960]   "We Know It When We See It."
[01:49:15.960 --> 01:49:16.960]   - One of my heroes.
[01:49:16.960 --> 01:49:18.480]   - Yeah, a wonderful colleague,
[01:49:18.480 --> 01:49:20.080]   who unfortunately we lost a few years ago,
[01:49:20.080 --> 01:49:24.120]   but listen, David, this has been wonderful.
[01:49:24.120 --> 01:49:24.960]   - It's been a blast.
[01:49:24.960 --> 01:49:26.820]   - We really appreciate you taking the time to do this.
[01:49:26.820 --> 01:49:29.320]   As people probably realize by now,
[01:49:29.320 --> 01:49:31.040]   you're an incredible wealth of knowledge
[01:49:31.040 --> 01:49:32.960]   about the entire nervous system.
[01:49:32.960 --> 01:49:35.240]   Today, we just hit this top contour
[01:49:35.240 --> 01:49:36.360]   of a number of different areas
[01:49:36.360 --> 01:49:38.340]   to give a flavor of the different ways
[01:49:38.340 --> 01:49:41.020]   that the nervous system works and is organized
[01:49:41.020 --> 01:49:43.360]   and how that's put together,
[01:49:43.360 --> 01:49:45.220]   how these areas are talking to one another.
[01:49:45.220 --> 01:49:46.060]   What I love about you
[01:49:46.060 --> 01:49:48.320]   is that you're such an incredible educator
[01:49:48.320 --> 01:49:50.460]   and I've taught so many students over the years,
[01:49:50.460 --> 01:49:54.200]   but also for me personally as friends,
[01:49:54.200 --> 01:49:57.840]   but also anytime that I want to touch into the beauty
[01:49:57.840 --> 01:50:00.740]   of the nervous system, I rarely lose touch with it,
[01:50:00.740 --> 01:50:02.160]   but anytime I want to touch into it
[01:50:02.160 --> 01:50:03.920]   and start thinking about new problems
[01:50:03.920 --> 01:50:06.480]   and ways that the nervous system is doing things
[01:50:06.480 --> 01:50:08.360]   that I hadn't thought about, I call you.
[01:50:08.360 --> 01:50:12.040]   So please forgive me for the calls past, present,
[01:50:12.040 --> 01:50:13.880]   and future, unless you change your number.
[01:50:13.880 --> 01:50:15.960]   And even if you do, I'll be calling.
[01:50:15.960 --> 01:50:18.540]   It's been such a blast, Andy.
[01:50:18.540 --> 01:50:20.980]   This has been a great session
[01:50:20.980 --> 01:50:22.700]   and it's always fun talking to you.
[01:50:22.700 --> 01:50:24.960]   It always gets my brain racing.
[01:50:24.960 --> 01:50:27.860]   So thank you.
[01:50:27.860 --> 01:50:28.780]   - Thank you.
[01:50:28.780 --> 01:50:29.880]   Thank you for joining me today
[01:50:29.880 --> 01:50:32.280]   for my discussion with Dr. David Berson.
[01:50:32.280 --> 01:50:35.180]   By now, you should have a much clearer understanding
[01:50:35.180 --> 01:50:37.100]   of how the brain is organized
[01:50:37.100 --> 01:50:39.580]   and how it works to do all the incredible things
[01:50:39.580 --> 01:50:40.780]   that it does.
[01:50:40.780 --> 01:50:43.200]   If you're enjoying and/or learning from this podcast,
[01:50:43.200 --> 01:50:45.020]   please subscribe to our YouTube channel.
[01:50:45.020 --> 01:50:47.820]   That's a terrific zero cost way to support us.
[01:50:47.820 --> 01:50:50.300]   In addition, please subscribe to our podcast
[01:50:50.300 --> 01:50:52.020]   on Apple and Spotify.
[01:50:52.020 --> 01:50:53.640]   And on Apple, you have the opportunity
[01:50:53.640 --> 01:50:56.140]   to leave us up to a five-star review.
[01:50:56.140 --> 01:50:58.040]   As well, if you'd like to make suggestions
[01:50:58.040 --> 01:51:00.440]   for future podcast episode topics
[01:51:00.440 --> 01:51:02.900]   or future podcast episode guests,
[01:51:02.900 --> 01:51:04.960]   please put those in the comment section
[01:51:04.960 --> 01:51:06.660]   on our YouTube channel.
[01:51:06.660 --> 01:51:08.380]   Please also check out our sponsors mentioned
[01:51:08.380 --> 01:51:09.900]   at the beginning of each podcast.
[01:51:09.900 --> 01:51:11.780]   That's the best way to support us.
[01:51:11.780 --> 01:51:13.020]   And we have a Patreon.
[01:51:13.020 --> 01:51:15.880]   It's patreon.com/andrewhuberman.
[01:51:15.880 --> 01:51:18.560]   There, you can support us at any level that you like.
[01:51:18.560 --> 01:51:21.580]   While today's discussion did not focus on supplements,
[01:51:21.580 --> 01:51:24.220]   many previous podcast episodes include discussions
[01:51:24.220 --> 01:51:25.220]   about supplements.
[01:51:25.220 --> 01:51:28.220]   And while supplements aren't necessary for everybody,
[01:51:28.220 --> 01:51:30.100]   many people derive benefit from them
[01:51:30.100 --> 01:51:33.940]   for things like sleep or focus or anxiety relief and so on.
[01:51:33.940 --> 01:51:36.140]   One issue with the supplement industry, however,
[01:51:36.140 --> 01:51:38.060]   is that oftentimes the quality
[01:51:38.060 --> 01:51:40.580]   will really vary across brands.
[01:51:40.580 --> 01:51:43.060]   That's why we partnered with Thorne, T-H-O-R-I-N-E,
[01:51:43.060 --> 01:51:44.540]   because Thorne supplements
[01:51:44.540 --> 01:51:46.260]   are of the absolute highest standards
[01:51:46.260 --> 01:51:48.520]   in terms of the quality of the ingredients they include
[01:51:48.520 --> 01:51:50.020]   and the precision of the amounts
[01:51:50.020 --> 01:51:51.420]   of the ingredients they include.
[01:51:51.420 --> 01:51:53.140]   In other words, what's listed on the bottle
[01:51:53.140 --> 01:51:54.900]   is what's actually found in the bottle,
[01:51:54.900 --> 01:51:57.080]   which is not true of many supplements out there
[01:51:57.080 --> 01:51:58.280]   that have been tested.
[01:51:58.280 --> 01:52:00.120]   If you'd like to see the supplements that I take,
[01:52:00.120 --> 01:52:04.980]   you can go to thorne.com/u/huberman.
[01:52:04.980 --> 01:52:06.980]   And there, you can see the supplements that I take
[01:52:06.980 --> 01:52:09.600]   and you can get 20% off any of those supplements.
[01:52:09.600 --> 01:52:11.660]   And if you navigate deeper into the Thorne site
[01:52:11.660 --> 01:52:15.640]   through that portal, thorne.com/u/huberman,
[01:52:15.640 --> 01:52:18.560]   you can also get 20% off any of the other supplements
[01:52:18.560 --> 01:52:20.040]   that Thorne happens to make.
[01:52:20.040 --> 01:52:21.780]   If you're not already following Huberman Lab
[01:52:21.780 --> 01:52:24.720]   on Instagram and Twitter, feel free to do so.
[01:52:24.720 --> 01:52:27.860]   Both places I regularly post short video posts
[01:52:27.860 --> 01:52:31.200]   or text posts that give tools related to health
[01:52:31.200 --> 01:52:32.780]   and neuroscience and so forth.
[01:52:32.780 --> 01:52:35.740]   And most of the time, that information is non-overlapping
[01:52:35.740 --> 01:52:37.140]   with the information on the podcast.
[01:52:37.140 --> 01:52:39.680]   Again, it's just Huberman Lab on Instagram and Twitter.
[01:52:39.680 --> 01:52:41.240]   And last but not least,
[01:52:41.240 --> 01:52:43.120]   thank you for your interest in science.
[01:52:43.120 --> 01:52:45.700]   [upbeat music]
[01:52:45.700 --> 01:52:47.760]   you

