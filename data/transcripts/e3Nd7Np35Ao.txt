
[00:00:00.000 --> 00:00:05.760]   When you are advising big enterprises, you know, the type of companies that have traditionally
[00:00:05.760 --> 00:00:10.320]   moved slow and I think that I'll pick a bank, you know, or something, something big with
[00:00:10.320 --> 00:00:12.360]   all kinds of compliance issues.
[00:00:12.360 --> 00:00:13.960]   How would you advise they start?
[00:00:13.960 --> 00:00:15.600]   Uh, yeah, baby steps.
[00:00:15.600 --> 00:00:20.960]   Like first thing, just like get a way for your developers to actually try stuff on the
[00:00:20.960 --> 00:00:23.000]   data that you're, you're concerned about.
[00:00:23.000 --> 00:00:24.000]   Right.
[00:00:24.000 --> 00:00:28.920]   So that means either they can only run inference in the infrastructure where the sensitive
[00:00:28.920 --> 00:00:34.920]   data is using, you know, things like Lama or other open source models, or you just get
[00:00:34.920 --> 00:00:41.200]   that enterprise contract with, with Microsoft to have like a private instance of, of GPT.
[00:00:41.200 --> 00:00:46.360]   What you need is like strong cases for, for how you could actually deploy these things
[00:00:46.360 --> 00:00:47.760]   within your organization.
[00:00:47.760 --> 00:00:51.200]   And, uh, any blocker to the developer is just, you know, it's deflating.
[00:00:51.200 --> 00:00:52.640]   We just want to make stuff.
[00:00:52.640 --> 00:00:57.960]   Let your developer free, let them at least prototype you, you said like let your developer
[00:00:57.960 --> 00:00:59.840]   Remember, try.

