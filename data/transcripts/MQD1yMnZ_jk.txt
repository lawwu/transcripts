
[00:00:00.000 --> 00:00:04.800]   Hi, welcome to this introduction to the sequential model in TensorFlow.
[00:00:04.800 --> 00:00:09.300]   So we're just going to go ahead and start a new notebook here.
[00:00:09.300 --> 00:00:12.800]   Now what I want to do is import TensorFlow.
[00:00:12.800 --> 00:00:21.600]   Now, the sequential model is one of two different approaches
[00:00:21.600 --> 00:00:24.400]   that we can use for building our models in TensorFlow.
[00:00:24.400 --> 00:00:27.000]   Those are the functional API
[00:00:27.400 --> 00:00:30.600]   and then the sequential model that we're going to go through here.
[00:00:30.600 --> 00:00:35.600]   So the sequential model is better for simple sequential stacks of layers
[00:00:35.600 --> 00:00:38.800]   where each layer has just one input and just one output.
[00:00:38.800 --> 00:00:43.400]   So if our model looks something like this,
[00:00:43.400 --> 00:00:49.500]   then the sequential approach is probably better.
[00:00:49.500 --> 00:00:57.100]   So we access the sequential model using tf.keras.sequential
[00:00:57.500 --> 00:00:58.600]   so it looks like this.
[00:00:58.600 --> 00:01:07.700]   And then that initializes the sequential model.
[00:01:07.700 --> 00:01:12.000]   And now there are two methods for adding layers with this model.
[00:01:12.000 --> 00:01:16.800]   The first of those which I'm going to show you is using the add method.
[00:01:16.800 --> 00:01:23.600]   So all we do is take model, add, and then we add our layer here.
[00:01:24.100 --> 00:01:28.100]   So one of the layers that we'll be using quite a lot
[00:01:28.100 --> 00:01:31.100]   is a densely connected neural network layer.
[00:01:31.100 --> 00:01:37.000]   So we just write tf.keras.layers.dense.
[00:01:37.000 --> 00:01:42.200]   And then we're going to add in 32 units here.
[00:01:42.200 --> 00:01:47.200]   And our input shape will be 10 units.
[00:01:47.200 --> 00:01:50.000]   So here we have 10 inputs
[00:01:50.300 --> 00:01:56.700]   and they are each connected to 32 units within our dense layer here.
[00:01:56.700 --> 00:02:01.400]   And they will use a ReLU activation function
[00:02:01.400 --> 00:02:04.200]   which is a rectified linear unit.
[00:02:04.200 --> 00:02:08.100]   Now you don't need to know all of this right now
[00:02:08.100 --> 00:02:13.000]   but what I do want you to focus on is the shape that we are producing.
[00:02:13.000 --> 00:02:15.600]   So if we go over to here,
[00:02:16.700 --> 00:02:20.800]   this is the shape of the network that we're building.
[00:02:20.800 --> 00:02:23.400]   So we have 10 inputs.
[00:02:23.400 --> 00:02:27.000]   So that was represented by the input shape.
[00:02:27.000 --> 00:02:31.900]   And then we have 32 neurons in the middle, so 32 units.
[00:02:31.900 --> 00:02:35.100]   If you look, because it's a densely connected neural network,
[00:02:35.100 --> 00:02:38.500]   every single one of these is connected to every single one.
[00:02:38.500 --> 00:02:42.200]   So all of our 10 inputs are connected to this unit here,
[00:02:42.200 --> 00:02:44.700]   this one, this one, this one, and so on.
[00:02:46.300 --> 00:02:49.500]   And then in our output, I want to put 2 units.
[00:02:49.500 --> 00:02:52.500]   So we'll go ahead and do that now.
[00:02:52.500 --> 00:02:58.200]   So if we want to add another layer, we just call add again.
[00:02:58.200 --> 00:02:59.900]   So we can run that.
[00:02:59.900 --> 00:03:02.800]   Okay, sorry, this is input shape.
[00:03:02.800 --> 00:03:11.000]   And if we want to add another layer, all we do is model add again.
[00:03:12.000 --> 00:03:14.800]   Now, we only need to define the input shape
[00:03:14.800 --> 00:03:17.800]   in our first layer with the sequential model.
[00:03:17.800 --> 00:03:21.300]   Otherwise, we don't need to define it because it will assume
[00:03:21.300 --> 00:03:24.800]   that our input shape matches the shape of the previous layer,
[00:03:24.800 --> 00:03:26.300]   which in this case is 32.
[00:03:26.300 --> 00:03:28.200]   So we don't need to do anything there.
[00:03:28.200 --> 00:03:32.400]   So we just put 2, and then we add in our activation.
[00:03:32.400 --> 00:03:35.900]   Now, because this is a sequential model,
[00:03:35.900 --> 00:03:37.800]   we don't need to define the input shape.
[00:03:37.900 --> 00:03:39.700]   We just use our activation.
[00:03:39.700 --> 00:03:43.100]   Now, because this is the output layer,
[00:03:43.100 --> 00:03:45.800]   and we have more than one output,
[00:03:45.800 --> 00:03:48.700]   we will be using the softmax activation.
[00:03:48.700 --> 00:03:55.600]   So in the output layer, you will usually have either sigmoid or softmax.
[00:03:55.600 --> 00:03:58.100]   If you just have one output,
[00:03:58.100 --> 00:04:03.000]   so if your output is just one value between 0 and 1,
[00:04:03.000 --> 00:04:05.600]   you use sigmoid.
[00:04:06.700 --> 00:04:10.000]   If you have multiple outputs, so we have two units here,
[00:04:10.000 --> 00:04:12.900]   that means our output can look something like this.
[00:04:12.900 --> 00:04:20.000]   And what we will want to do is take the maximum value
[00:04:20.000 --> 00:04:21.600]   as the answer.
[00:04:21.600 --> 00:04:23.800]   So in this case, it would be index 0.
[00:04:23.800 --> 00:04:26.600]   So the output label would be 0.
[00:04:26.600 --> 00:04:28.500]   And when we're doing that,
[00:04:28.500 --> 00:04:31.600]   we want to use the softmax activation function.
[00:04:31.600 --> 00:04:36.000]   So we can execute that.
[00:04:36.600 --> 00:04:38.400]   And then we can print out our model
[00:04:38.400 --> 00:04:40.300]   with the model summary.
[00:04:40.300 --> 00:04:42.000]   And here we can see,
[00:04:42.000 --> 00:04:44.700]   okay, we have a sequential model,
[00:04:44.700 --> 00:04:47.000]   and it has two layers.
[00:04:47.000 --> 00:04:50.400]   So this doesn't include the input layer.
[00:04:50.400 --> 00:04:53.800]   So our input layer is actually 10 units.
[00:04:53.800 --> 00:04:58.900]   And then it goes into the actual model, which is 32 units.
[00:04:58.900 --> 00:05:01.300]   This is our hidden layer.
[00:05:01.300 --> 00:05:04.500]   And then our output layer is two units at the end there.
[00:05:05.600 --> 00:05:08.400]   And we see that there are a total of 418 parameters
[00:05:08.400 --> 00:05:09.500]   and all those trainable.
[00:05:09.500 --> 00:05:11.900]   So those are the number of numbers
[00:05:11.900 --> 00:05:15.700]   that the model will adjust
[00:05:15.700 --> 00:05:19.300]   in order to learn patterns within the training data.
[00:05:19.300 --> 00:05:23.200]   Okay, so that is our first option
[00:05:23.200 --> 00:05:25.100]   for building a sequential model.
[00:05:25.100 --> 00:05:28.300]   But we also have another way of building it.
[00:05:28.300 --> 00:05:31.800]   So rather than using the add method,
[00:05:31.800 --> 00:05:33.600]   we can actually define our model
[00:05:34.600 --> 00:05:38.200]   all within the single initialization function
[00:05:38.200 --> 00:05:40.100]   like this.
[00:05:40.100 --> 00:05:44.600]   We just add a list.
[00:05:44.600 --> 00:05:47.600]   And then we take what we had here,
[00:05:47.600 --> 00:05:52.800]   just the layer,
[00:05:52.800 --> 00:05:56.800]   and add it in.
[00:05:56.800 --> 00:06:00.000]   And you just add each layer
[00:06:00.000 --> 00:06:02.700]   as a item within the list.
[00:06:03.700 --> 00:06:05.300]   And then we just execute that.
[00:06:05.300 --> 00:06:09.000]   Print the model summary.
[00:06:09.000 --> 00:06:14.900]   And we have the exact same model.
[00:06:14.900 --> 00:06:22.000]   So that is everything on the sequential model.
[00:06:22.000 --> 00:06:24.900]   I hope you've enjoyed and I hope it's been useful.
[00:06:24.900 --> 00:06:27.900]   So thank you for watching and I will see you again soon.
[00:06:27.900 --> 00:06:28.500]   Bye.
[00:06:28.500 --> 00:06:31.180]   and I will see you again soon. Bye!

