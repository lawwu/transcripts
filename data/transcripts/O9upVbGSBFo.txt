
[00:00:00.000 --> 00:00:03.340]   The following is a conversation with Brian Kernighan,
[00:00:03.340 --> 00:00:07.560]   a professor of computer science at Princeton University.
[00:00:07.560 --> 00:00:10.140]   He was a key figure in the computer science community
[00:00:10.140 --> 00:00:13.760]   in the early Unix days, alongside Unix creators,
[00:00:13.760 --> 00:00:16.240]   Ken Thompson and Dennis Ritchie.
[00:00:16.240 --> 00:00:18.540]   He co-authored the C programming language
[00:00:18.540 --> 00:00:21.440]   with Dennis Ritchie, the creator of C,
[00:00:21.440 --> 00:00:24.340]   and has written a lot of books on programming,
[00:00:24.340 --> 00:00:28.460]   computers and life, including "The Practice of Programming,"
[00:00:28.460 --> 00:00:30.160]   "The Go Programming Language,"
[00:00:30.160 --> 00:00:34.100]   and his latest, "Unix, a History and a Memoir."
[00:00:34.100 --> 00:00:36.940]   He co-created AWK, the text processing language
[00:00:36.940 --> 00:00:39.500]   used by Linux folks like myself.
[00:00:39.500 --> 00:00:43.800]   He co-designed Ample, an algebraic modeling language
[00:00:43.800 --> 00:00:47.580]   that I personally love and have used a lot in my life
[00:00:47.580 --> 00:00:49.580]   for large-scale optimization.
[00:00:49.580 --> 00:00:51.700]   I think I can keep going for a long time
[00:00:51.700 --> 00:00:54.260]   with his creations and accomplishments,
[00:00:54.260 --> 00:00:56.620]   which is funny because given all that,
[00:00:56.620 --> 00:00:59.180]   he's one of the most humble and kind people
[00:00:59.180 --> 00:01:01.780]   I've spoken to on this podcast.
[00:01:01.780 --> 00:01:04.880]   Quick summary of the ads, two new sponsors,
[00:01:04.880 --> 00:01:09.880]   the amazing self-cooling 8Sleep mattress
[00:01:09.880 --> 00:01:13.260]   and Raycon earbuds.
[00:01:13.260 --> 00:01:15.420]   Please consider supporting the podcast
[00:01:15.420 --> 00:01:19.060]   by going to 8sleep.com/lex
[00:01:19.060 --> 00:01:23.020]   and going to buyraycon.com/lex.
[00:01:23.020 --> 00:01:25.200]   Click the links, buy the stuff.
[00:01:25.200 --> 00:01:27.700]   It really is the best way to support this podcast
[00:01:27.700 --> 00:01:29.660]   and the journey I'm on.
[00:01:29.660 --> 00:01:32.020]   If you enjoy this thing, subscribe on YouTube,
[00:01:32.020 --> 00:01:34.200]   review it with Firestarz and Apple Podcasts,
[00:01:34.200 --> 00:01:35.540]   support it on Patreon,
[00:01:35.540 --> 00:01:38.720]   or connect with me on Twitter @LexFriedman.
[00:01:38.720 --> 00:01:41.980]   As usual, I'll do a few minutes of ads now
[00:01:41.980 --> 00:01:43.300]   and never any ads in the middle
[00:01:43.300 --> 00:01:45.900]   that can break the flow of the conversation.
[00:01:45.900 --> 00:01:49.260]   This show is sponsored by 8Sleep
[00:01:49.260 --> 00:01:51.860]   and its incredible Pod Pro mattress
[00:01:51.860 --> 00:01:54.700]   that you can check out at 8sleep.com/lex
[00:01:54.700 --> 00:01:57.340]   to get $200 off.
[00:01:57.340 --> 00:02:00.700]   The mattress controls temperature with an app
[00:02:00.700 --> 00:02:03.820]   and can cool down to as low as 55 degrees.
[00:02:03.820 --> 00:02:06.960]   Research shows the temperature has a big impact
[00:02:06.960 --> 00:02:09.020]   on the quality of our sleep.
[00:02:09.020 --> 00:02:11.260]   Anecdotally, it's been a game changer for me.
[00:02:11.260 --> 00:02:12.260]   I love it.
[00:02:12.260 --> 00:02:14.300]   The Pod Pro is packed with sensors
[00:02:14.300 --> 00:02:17.100]   that track heart rate, heart rate variability
[00:02:17.100 --> 00:02:18.620]   and respiratory rate,
[00:02:18.620 --> 00:02:21.400]   showing it all on their app once you wake up.
[00:02:21.400 --> 00:02:23.500]   Plus, if you have a partner,
[00:02:23.500 --> 00:02:26.560]   you can control the temperature of each side of the bed.
[00:02:26.560 --> 00:02:28.220]   I don't happen to have one,
[00:02:28.220 --> 00:02:30.020]   but the 8Sleep app reminds me
[00:02:30.020 --> 00:02:32.000]   that I should probably get on that.
[00:02:32.000 --> 00:02:34.820]   So ladies, if a temperature controlled mattress
[00:02:34.820 --> 00:02:36.740]   isn't a good reason to apply,
[00:02:36.740 --> 00:02:38.880]   I don't know what is.
[00:02:38.880 --> 00:02:41.120]   The app's health metrics are amazing,
[00:02:41.120 --> 00:02:44.420]   but the cooling alone is honestly worth the money.
[00:02:44.420 --> 00:02:47.260]   As some of you know, I don't always sleep,
[00:02:47.260 --> 00:02:51.660]   but when I do, I choose the 8Sleep Pod Pro mattress.
[00:02:51.660 --> 00:02:56.660]   Check it out at 8sleep.com/lex to get $200 off.
[00:02:56.660 --> 00:03:01.580]   This show is also sponsored by Raycon earbuds.
[00:03:01.580 --> 00:03:06.020]   Get them at buyraycon.com/lex.
[00:03:06.020 --> 00:03:07.700]   They've quickly become my main method
[00:03:07.700 --> 00:03:10.440]   of listening to podcasts, audio books, and music.
[00:03:10.440 --> 00:03:13.900]   When I run, do the pushups and pull-ups
[00:03:13.900 --> 00:03:15.900]   that I've begun to hate at this point,
[00:03:15.900 --> 00:03:17.500]   or just living life.
[00:03:17.500 --> 00:03:20.260]   In fact, I often listen to brown noise with these
[00:03:20.260 --> 00:03:22.300]   when I'm thinking deeply about something.
[00:03:22.300 --> 00:03:24.300]   It helps me focus the mind.
[00:03:24.300 --> 00:03:26.460]   They're super comfortable, pair easily,
[00:03:26.460 --> 00:03:30.180]   great sound, great bass, six hours of playtime.
[00:03:30.180 --> 00:03:33.500]   In fact, for fun, I have one of the earbuds in now,
[00:03:33.500 --> 00:03:36.340]   and I'm listening to Europa by Santana,
[00:03:36.340 --> 00:03:39.120]   probably one of my favorite guitar songs.
[00:03:39.120 --> 00:03:41.540]   It kind of makes me feel like I'm in a music video.
[00:03:41.540 --> 00:03:44.820]   So they told me to say that a bunch of celebrities
[00:03:44.820 --> 00:03:49.720]   use these, like Snoop Dogg, Melissa Etheridge, and Cardi B.
[00:03:50.480 --> 00:03:52.720]   I don't even know who Cardi B is,
[00:03:52.720 --> 00:03:55.600]   but her earbud game is on point.
[00:03:55.600 --> 00:03:58.320]   To mention celebrities I actually care about,
[00:03:58.320 --> 00:04:01.180]   I'm sure if Richard Feynman was still with us,
[00:04:01.180 --> 00:04:03.840]   he'd be listening to the Joe Rogan experience
[00:04:03.840 --> 00:04:06.020]   with Raycon earbuds.
[00:04:06.020 --> 00:04:09.360]   Get them at buyraycon.com/lex.
[00:04:09.360 --> 00:04:11.040]   It's how they know I sent you,
[00:04:11.040 --> 00:04:13.600]   and increases the chance that he'll support this podcast
[00:04:13.600 --> 00:04:14.640]   in the future.
[00:04:14.640 --> 00:04:17.640]   So for all of the sponsors, click all of the links.
[00:04:17.640 --> 00:04:20.000]   It really helps this podcast.
[00:04:20.000 --> 00:04:24.040]   And now, here's my conversation with Brian Kernighan.
[00:04:24.040 --> 00:04:28.600]   Unix started being developed 50 years ago,
[00:04:28.600 --> 00:04:30.600]   maybe more than 50 years ago.
[00:04:30.600 --> 00:04:33.600]   Can you tell the story, like you describe in your new book,
[00:04:33.600 --> 00:04:35.760]   of how Unix was created?
[00:04:35.760 --> 00:04:38.360]   - Ha, if I can remember that far back,
[00:04:38.360 --> 00:04:39.580]   it was some while ago.
[00:04:39.580 --> 00:04:45.480]   So I think the gist of it is that at Bell Labs in 1969,
[00:04:45.800 --> 00:04:48.280]   there were a group of people who had just finished
[00:04:48.280 --> 00:04:49.920]   working on the Multics project,
[00:04:49.920 --> 00:04:54.300]   which was itself a follow-on to CTSS.
[00:04:54.300 --> 00:04:57.040]   So we can go back sort of an infinite regress in time,
[00:04:57.040 --> 00:05:01.000]   but the CTSS was a very, very, very nice time-sharing system.
[00:05:01.000 --> 00:05:02.080]   It was very nice to use.
[00:05:02.080 --> 00:05:04.560]   I actually used it as that summer I spent
[00:05:04.560 --> 00:05:06.920]   in Cambridge in 1966.
[00:05:06.920 --> 00:05:08.520]   - What was the hardware there?
[00:05:08.520 --> 00:05:09.560]   So what's the operating system?
[00:05:09.560 --> 00:05:10.400]   What's the hardware there?
[00:05:10.400 --> 00:05:12.160]   What's the CTSS look like?
[00:05:12.160 --> 00:05:14.240]   - So CTSS looked like,
[00:05:14.240 --> 00:05:17.040]   kind of like a standard time-sharing system.
[00:05:17.040 --> 00:05:18.920]   Certainly at the time, it was the only time-sharing,
[00:05:18.920 --> 00:05:19.760]   if no-
[00:05:19.760 --> 00:05:20.760]   - Let's go back to the basic.
[00:05:20.760 --> 00:05:22.360]   What's a time-sharing system?
[00:05:22.360 --> 00:05:23.760]   - Okay, in the beginning was the word,
[00:05:23.760 --> 00:05:24.600]   and the word was itself.
[00:05:24.600 --> 00:05:27.040]   - And then there was time-sharing systems.
[00:05:27.040 --> 00:05:29.920]   - Yeah, if we go back into, let's call it the 1950s
[00:05:29.920 --> 00:05:33.280]   and early 1960s, most computing was done
[00:05:33.280 --> 00:05:35.600]   on very big computers, physically big,
[00:05:35.600 --> 00:05:38.800]   although not terribly powerful by today's standards,
[00:05:38.800 --> 00:05:42.120]   that were maintained in very large rooms,
[00:05:42.120 --> 00:05:45.760]   and you used things like punch cards
[00:05:45.760 --> 00:05:47.400]   to write your programs on and talk to them.
[00:05:47.400 --> 00:05:49.280]   So you would take a deck of cards,
[00:05:49.280 --> 00:05:51.880]   write your program on it, send it over a counter,
[00:05:51.880 --> 00:05:54.480]   hand it to an operator, and some while later,
[00:05:54.480 --> 00:05:55.720]   back would come something that said,
[00:05:55.720 --> 00:05:58.000]   oh, you made a mistake, and then you'd recycle.
[00:05:58.000 --> 00:05:59.440]   And so it was very, very slow.
[00:05:59.440 --> 00:06:02.240]   So the idea of time-sharing was that you take
[00:06:02.240 --> 00:06:06.240]   basically that same computer, but connect to it
[00:06:06.240 --> 00:06:09.400]   with something that looked like an electric typewriter.
[00:06:09.400 --> 00:06:11.920]   That could be a long distance away, it could be close,
[00:06:11.920 --> 00:06:14.920]   but fundamentally what the operating system did
[00:06:14.920 --> 00:06:18.080]   was to give each person who was connected to it
[00:06:18.080 --> 00:06:21.640]   and wanting to do something a small slice of time
[00:06:21.640 --> 00:06:24.840]   to do a particular job.
[00:06:24.840 --> 00:06:28.160]   So I might be editing a file, so I would be typing,
[00:06:28.160 --> 00:06:29.480]   and every time I hit a keystroke,
[00:06:29.480 --> 00:06:30.960]   the operating system would wake up and said,
[00:06:30.960 --> 00:06:33.400]   oh, he typed character, let me remember that,
[00:06:33.400 --> 00:06:34.960]   and then it'd go back to doing something else.
[00:06:34.960 --> 00:06:38.000]   So it'd be going around and around a group of people
[00:06:38.000 --> 00:06:39.240]   who were trying to get something done,
[00:06:39.240 --> 00:06:43.120]   giving each a small slice of time,
[00:06:43.120 --> 00:06:45.120]   and giving them each the illusion
[00:06:45.120 --> 00:06:47.560]   that they pretty much had the whole machine to themselves,
[00:06:47.560 --> 00:06:49.800]   and hence time-sharing, that is sharing
[00:06:49.800 --> 00:06:52.480]   the computing time resource of the computer
[00:06:52.480 --> 00:06:54.920]   among a number of people who were doing it.
[00:06:54.920 --> 00:06:56.840]   - Without the individual people being aware
[00:06:56.840 --> 00:06:59.240]   that there's others, in a sense, the illusion,
[00:06:59.240 --> 00:07:02.520]   the feelings that the machine is your own.
[00:07:02.520 --> 00:07:04.240]   - Pretty much that was the idea, yes.
[00:07:04.240 --> 00:07:08.040]   You had, if it were well done, and if it were fast enough,
[00:07:08.040 --> 00:07:09.800]   and other people weren't doing too much,
[00:07:09.800 --> 00:07:11.000]   you did have the illusion
[00:07:11.000 --> 00:07:13.000]   that you had the whole machine to yourself,
[00:07:13.000 --> 00:07:16.520]   and it was very much better than the punch card model.
[00:07:16.520 --> 00:07:19.800]   And so CTSS, the compatible time-sharing system,
[00:07:19.800 --> 00:07:22.440]   was, I think, arguably the first of these.
[00:07:22.440 --> 00:07:25.320]   It was done, I guess, technically in '64,
[00:07:25.320 --> 00:07:26.400]   or something like that.
[00:07:26.400 --> 00:07:30.040]   It ran on an IBM 7094, slightly modified
[00:07:30.040 --> 00:07:32.800]   to have twice as much memory as the norm.
[00:07:32.800 --> 00:07:37.480]   It had two banks of 32K words instead of one.
[00:07:37.480 --> 00:07:38.840]   So, (laughs)
[00:07:38.840 --> 00:07:40.760]   - 32K words, yeah.
[00:07:40.760 --> 00:07:42.880]   - Each word was 36 bits, so call it,
[00:07:42.880 --> 00:07:46.400]   about 150 kilobytes times two.
[00:07:46.400 --> 00:07:49.600]   So, by today's standards, that's down in the noise.
[00:07:49.600 --> 00:07:51.480]   But at the time, that was a lot of memory,
[00:07:51.480 --> 00:07:53.240]   and memory was expensive.
[00:07:53.240 --> 00:07:56.880]   So, CTSS was just a wonderful environment to work on.
[00:07:56.880 --> 00:07:58.680]   It was done by people at MIT,
[00:07:58.680 --> 00:08:02.200]   led by Fernando Corbato, Corby,
[00:08:02.200 --> 00:08:04.280]   who died just earlier this year,
[00:08:04.280 --> 00:08:06.800]   and a bunch of other folks.
[00:08:06.800 --> 00:08:09.520]   And so I spent the summer of '66 working on that.
[00:08:09.520 --> 00:08:12.640]   Had a great time, met a lot of really nice people,
[00:08:12.640 --> 00:08:17.640]   and indirectly knew of people at Bell Labs
[00:08:17.640 --> 00:08:22.520]   who were also working on a follow-on to CTSS
[00:08:22.520 --> 00:08:24.080]   that was called Multics.
[00:08:24.080 --> 00:08:26.000]   So, Multics was meant to be the system
[00:08:26.000 --> 00:08:27.720]   that would do everything that CTSS did,
[00:08:27.720 --> 00:08:30.760]   but do it better for a larger population.
[00:08:30.760 --> 00:08:31.720]   All the usual stuff.
[00:08:31.720 --> 00:08:34.120]   - Now, the actual time-sharing, the scheduling,
[00:08:35.160 --> 00:08:37.720]   how much, what's the algorithm
[00:08:37.720 --> 00:08:39.040]   that performs the scheduling?
[00:08:39.040 --> 00:08:39.880]   What's that look like?
[00:08:39.880 --> 00:08:40.980]   How much magic is there?
[00:08:40.980 --> 00:08:42.720]   What are the metrics?
[00:08:42.720 --> 00:08:44.840]   How does it all work in the beginning?
[00:08:44.840 --> 00:08:46.200]   - So, the answer is I don't have a clue.
[00:08:46.200 --> 00:08:48.280]   I think the basic idea was nothing more
[00:08:48.280 --> 00:08:50.600]   than who all wants to get something done.
[00:08:50.600 --> 00:08:52.040]   Suppose that things are very quiet
[00:08:52.040 --> 00:08:53.660]   in the middle of the night,
[00:08:53.660 --> 00:08:55.760]   then I get all the time that I want.
[00:08:55.760 --> 00:08:58.080]   Suppose that you and I are contending at high noon
[00:08:58.080 --> 00:08:59.880]   for something like that,
[00:08:59.880 --> 00:09:02.420]   then probably the simplest algorithm is a round-robin,
[00:09:02.420 --> 00:09:05.120]   one that gives you a bit of time, gives me a bit of time.
[00:09:05.120 --> 00:09:07.080]   And then we could adapt to that.
[00:09:07.080 --> 00:09:08.680]   Like, what are you trying to do?
[00:09:08.680 --> 00:09:12.000]   Are you text editing or are you compiling or something?
[00:09:12.000 --> 00:09:13.600]   And then we might adjust the scheduler
[00:09:13.600 --> 00:09:15.040]   according to things like that.
[00:09:15.040 --> 00:09:18.960]   - So, okay, so Multics was trying to just do some of the,
[00:09:18.960 --> 00:09:20.280]   clean it up a little bit.
[00:09:20.280 --> 00:09:22.280]   - Well, it was meant to be much more than that.
[00:09:22.280 --> 00:09:24.320]   So, Multics was the multiplexed information
[00:09:24.320 --> 00:09:25.460]   and computing service,
[00:09:25.460 --> 00:09:27.840]   and it was meant to be a very large thing
[00:09:27.840 --> 00:09:29.980]   that would provide computing utility,
[00:09:29.980 --> 00:09:32.940]   something that where you could actually think of it
[00:09:32.940 --> 00:09:35.080]   as just a plug-in-the-wall service.
[00:09:35.080 --> 00:09:38.360]   Sort of like cloud computing today, same idea,
[00:09:38.360 --> 00:09:40.680]   but 50 odd years earlier.
[00:09:40.680 --> 00:09:43.800]   And so what Multics offered
[00:09:43.800 --> 00:09:46.560]   was a richer operating system environment,
[00:09:46.560 --> 00:09:48.880]   a piece of hardware that was better designed
[00:09:48.880 --> 00:09:53.160]   for doing the kind of sharing of resources,
[00:09:53.160 --> 00:09:55.960]   and presumably lots of other things.
[00:09:55.960 --> 00:09:58.560]   - Do you think people at that time had the dream
[00:09:58.560 --> 00:10:01.120]   of what cloud computing is starting to become now,
[00:10:01.120 --> 00:10:03.160]   which is computing is everywhere,
[00:10:03.160 --> 00:10:05.760]   that you can just plug in almost,
[00:10:05.760 --> 00:10:09.080]   and you never know how the magic works.
[00:10:09.080 --> 00:10:11.760]   You just kind of plug in, add your little computation
[00:10:11.760 --> 00:10:13.720]   that you need to perform, and it does it.
[00:10:13.720 --> 00:10:14.920]   Was that the dream?
[00:10:14.920 --> 00:10:16.040]   - I don't know where that was the dream.
[00:10:16.040 --> 00:10:17.440]   I wasn't part of it at that point.
[00:10:17.440 --> 00:10:19.280]   Remember, I was an intern for a summer.
[00:10:19.280 --> 00:10:23.280]   But my sense is, given that it was over 50 years ago,
[00:10:23.280 --> 00:10:24.400]   yeah, they had that idea
[00:10:24.400 --> 00:10:26.280]   that it was an information utility,
[00:10:26.280 --> 00:10:27.680]   that it was something where
[00:10:27.680 --> 00:10:29.840]   if you had a computing task to do,
[00:10:29.840 --> 00:10:31.680]   you could just go and do it.
[00:10:31.680 --> 00:10:35.880]   Now, I'm betting that they didn't have the same view
[00:10:35.880 --> 00:10:38.840]   of computing for the masses, let's call it,
[00:10:38.840 --> 00:10:43.240]   the idea that your grandmother would be shopping on Amazon.
[00:10:43.240 --> 00:10:45.000]   I don't think that was part of it.
[00:10:45.000 --> 00:10:47.160]   But if your grandmother were a programmer,
[00:10:47.160 --> 00:10:49.080]   it might be very easy for her to go
[00:10:49.080 --> 00:10:51.500]   and use this kind of utility.
[00:10:51.500 --> 00:10:53.680]   - What was your dream of computers at that time?
[00:10:53.680 --> 00:10:55.680]   What did you see as the future of computers?
[00:10:55.680 --> 00:10:59.600]   'Cause you have predicted what computers are today.
[00:10:59.600 --> 00:11:01.760]   - Oh, short answer, absolutely not.
[00:11:01.760 --> 00:11:02.600]   I have no clue.
[00:11:02.600 --> 00:11:03.880]   I'm not sure I had a dream.
[00:11:03.880 --> 00:11:05.920]   It was a dream job in the sense that
[00:11:05.920 --> 00:11:07.480]   I really enjoyed what I was doing.
[00:11:07.480 --> 00:11:10.040]   I was surrounded by really, really nice people.
[00:11:10.040 --> 00:11:12.880]   Cambridge is a very fine city to live in in the summer,
[00:11:12.880 --> 00:11:14.300]   less so in the winter when it snows,
[00:11:14.300 --> 00:11:16.880]   but in the summer, it was a delightful time.
[00:11:16.880 --> 00:11:19.200]   And so I really enjoyed all of that stuff
[00:11:19.200 --> 00:11:20.360]   and I learned things.
[00:11:20.360 --> 00:11:25.000]   And I think the good fortune of being there for summer
[00:11:25.000 --> 00:11:27.200]   led me then to get a summer job at Bell Labs
[00:11:27.200 --> 00:11:28.480]   the following summer.
[00:11:28.480 --> 00:11:31.760]   And that was quite useful for the future.
[00:11:31.760 --> 00:11:35.960]   - So Bell Labs is this magical, legendary place.
[00:11:35.960 --> 00:11:39.040]   So first of all, where is Bell Labs?
[00:11:39.040 --> 00:11:44.040]   And can you start talking about that journey
[00:11:44.040 --> 00:11:46.600]   towards Unix at Bell Labs?
[00:11:46.600 --> 00:11:50.160]   - Yeah, so Bell Labs is physically scattered around,
[00:11:50.160 --> 00:11:52.320]   at the time, scattered around New Jersey.
[00:11:52.320 --> 00:11:54.920]   The primary location was in a town called Murray Hill,
[00:11:54.920 --> 00:11:56.320]   or a location called Murray Hill.
[00:11:56.320 --> 00:11:58.680]   It was actually across the boundary
[00:11:58.680 --> 00:12:00.840]   between two small towns in New Jersey
[00:12:00.840 --> 00:12:03.400]   called New Providence and Berkeley Heights.
[00:12:03.400 --> 00:12:05.400]   Think of it as about 15, 20 miles straight west
[00:12:05.400 --> 00:12:08.880]   of New York City, and therefore about an hour north
[00:12:08.880 --> 00:12:10.000]   of here in Princeton.
[00:12:10.000 --> 00:12:15.040]   And at that time, it had, make up a number,
[00:12:15.040 --> 00:12:17.960]   three or 4,000 people there, many of whom had PhDs
[00:12:17.960 --> 00:12:20.760]   and mostly doing physical sciences,
[00:12:20.760 --> 00:12:24.400]   chemistry, physics, materials kinds of things,
[00:12:24.400 --> 00:12:29.040]   but very strong math and rapidly growing interest
[00:12:29.040 --> 00:12:31.160]   in computing as people realized you could do things
[00:12:31.160 --> 00:12:33.920]   with computers that you might not have been able
[00:12:33.920 --> 00:12:35.240]   to do before.
[00:12:35.240 --> 00:12:37.440]   You could replace labs with computers
[00:12:37.440 --> 00:12:40.360]   that had worked on models of what was going on.
[00:12:40.360 --> 00:12:44.080]   So that was the essence of Bell Labs.
[00:12:44.080 --> 00:12:46.520]   And again, I wasn't a permanent employee there.
[00:12:46.520 --> 00:12:47.880]   That was another internship.
[00:12:47.880 --> 00:12:49.520]   I got lucky in internships.
[00:12:49.520 --> 00:12:52.480]   - I mean, if you could just linger on it a little bit,
[00:12:52.480 --> 00:12:55.440]   what was in the air there?
[00:12:55.440 --> 00:12:57.720]   'Cause some of the, the number of Nobel Prizes,
[00:12:57.720 --> 00:12:58.920]   the number of Turing Awards,
[00:12:58.920 --> 00:13:00.960]   and just legendary computer scientists
[00:13:00.960 --> 00:13:04.040]   that come from there, inventions including,
[00:13:04.040 --> 00:13:07.840]   developments including Unix, it's just, it's unbelievable.
[00:13:07.840 --> 00:13:11.560]   So was there something special about that place?
[00:13:11.560 --> 00:13:14.560]   - Oh, I think there was very definitely something special.
[00:13:14.560 --> 00:13:15.760]   I mentioned the number of people.
[00:13:15.760 --> 00:13:19.040]   It's a very large number of people, very highly skilled,
[00:13:19.040 --> 00:13:21.280]   and working in an environment where there was always
[00:13:21.280 --> 00:13:23.080]   something interesting to work on,
[00:13:23.080 --> 00:13:25.080]   because the goal of Bell Labs,
[00:13:25.080 --> 00:13:27.240]   which was a small part of AT&T,
[00:13:27.240 --> 00:13:30.120]   which provided basically the country's phone service.
[00:13:30.120 --> 00:13:33.400]   The goal of AT&T was to provide service for everybody.
[00:13:33.400 --> 00:13:36.920]   And the goal of Bell Labs was to try and make that service
[00:13:36.920 --> 00:13:39.160]   keep getting better, so improving service.
[00:13:39.160 --> 00:13:43.880]   And that meant doing research on a lot of different things,
[00:13:43.880 --> 00:13:46.400]   physical devices like the transistor,
[00:13:46.400 --> 00:13:50.840]   or fiber optical cables, or microwave systems,
[00:13:50.840 --> 00:13:53.200]   all of these things the labs worked on.
[00:13:53.200 --> 00:13:56.560]   And it was kind of just the beginning of real boom times
[00:13:56.560 --> 00:13:59.080]   in computing as well, 'cause when I was there,
[00:13:59.080 --> 00:14:01.120]   I went there first in '66.
[00:14:01.120 --> 00:14:04.520]   So computing was at that point fairly young,
[00:14:04.520 --> 00:14:06.480]   and so people were discovering that you could do
[00:14:06.480 --> 00:14:08.720]   lots of things with computers.
[00:14:08.720 --> 00:14:10.800]   - So how was Unix born?
[00:14:10.800 --> 00:14:14.560]   - So Multics, in spite of having an enormous number
[00:14:14.560 --> 00:14:16.840]   of really good ideas, lots of good people working on it,
[00:14:16.840 --> 00:14:20.040]   fundamentally didn't live up, at least in the short run,
[00:14:20.040 --> 00:14:22.160]   and I think ultimately really ever,
[00:14:22.160 --> 00:14:25.560]   to its goal of being this information utility.
[00:14:25.560 --> 00:14:29.200]   It was too expensive, and certainly what was promised
[00:14:29.200 --> 00:14:31.280]   was delivered much too late.
[00:14:31.280 --> 00:14:34.600]   And so in roughly the beginning of 1969,
[00:14:34.600 --> 00:14:37.200]   Bell Labs pulled out of the project.
[00:14:37.200 --> 00:14:41.640]   The project at that point had included MIT,
[00:14:41.640 --> 00:14:44.040]   Bell Labs, and General Electric.
[00:14:44.040 --> 00:14:45.480]   General Electric made computers,
[00:14:45.480 --> 00:14:48.320]   so General Electric was the hardware operation.
[00:14:48.320 --> 00:14:50.880]   So Bell Labs, realizing this wasn't going anywhere
[00:14:50.880 --> 00:14:54.160]   on a timescale they cared about, pulled out of the project.
[00:14:54.160 --> 00:14:59.160]   And this left several people with an acquired taste
[00:14:59.160 --> 00:15:01.640]   for really, really nice computing environments,
[00:15:01.640 --> 00:15:03.520]   but no computing environment.
[00:15:03.520 --> 00:15:06.800]   And so they started thinking about what could you do
[00:15:06.800 --> 00:15:09.480]   if you were gonna design a new operating system
[00:15:09.480 --> 00:15:12.920]   that would provide the same kind of comfortable computing
[00:15:12.920 --> 00:15:16.040]   as CTSS had, but also the facilities of something
[00:15:16.040 --> 00:15:17.960]   like Multics sort of brought forward.
[00:15:17.960 --> 00:15:21.720]   And so they did a lot of paper design stuff,
[00:15:21.720 --> 00:15:23.920]   and at the same time, Ken Thompson found
[00:15:23.920 --> 00:15:27.280]   what is characterized as a little-used PDP-7,
[00:15:27.280 --> 00:15:31.080]   where he started to do experiments with file systems,
[00:15:31.080 --> 00:15:33.640]   just how do you store information on a computer
[00:15:33.640 --> 00:15:36.360]   in an efficient way, and then this famous story
[00:15:36.360 --> 00:15:39.160]   that his wife went away to California for three weeks
[00:15:39.160 --> 00:15:43.280]   taking their one-year-old son, and three weeks,
[00:15:43.280 --> 00:15:45.640]   and he sat down and wrote an operating system,
[00:15:45.640 --> 00:15:47.440]   which ultimately became Unix.
[00:15:47.440 --> 00:15:50.280]   So software productivity was good in those days.
[00:15:50.280 --> 00:15:52.000]   - So PDP, what's a PDP-7?
[00:15:52.000 --> 00:15:53.360]   So it's a piece of hardware?
[00:15:53.360 --> 00:15:54.520]   - Yeah, it's a piece of hardware.
[00:15:54.520 --> 00:15:56.720]   It was one of early machines made
[00:15:56.720 --> 00:15:59.840]   by Digital Equipment Corporation, DEC,
[00:15:59.840 --> 00:16:03.440]   and it was a mini-computer, so-called.
[00:16:03.440 --> 00:16:07.440]   It had, I would have to look up the numbers exactly,
[00:16:07.440 --> 00:16:09.320]   but it had a very small amount of memory,
[00:16:09.320 --> 00:16:13.280]   maybe 16K, 16-bit words or something like that,
[00:16:13.280 --> 00:16:17.120]   relatively slow, probably not super expensive,
[00:16:17.120 --> 00:16:19.760]   maybe, again, making this up, I'd have to look it up,
[00:16:19.760 --> 00:16:21.840]   $100,000 or something like that.
[00:16:21.840 --> 00:16:24.360]   - Which is not super expensive in those days, right?
[00:16:24.360 --> 00:16:25.400]   - It was expensive.
[00:16:25.400 --> 00:16:26.840]   It was enough that you and I probably
[00:16:26.840 --> 00:16:27.680]   wouldn't be able to buy one,
[00:16:27.680 --> 00:16:30.880]   but a modest group of people could get together.
[00:16:30.880 --> 00:16:34.880]   But in any case, it came out, if I recall, in 1964,
[00:16:34.880 --> 00:16:38.640]   so by 1969, it was getting a little obsolete,
[00:16:38.640 --> 00:16:40.500]   and that's why it was little-used.
[00:16:41.520 --> 00:16:43.400]   - If you can sort of comment, what do you think
[00:16:43.400 --> 00:16:45.680]   it's like to write an operating system like that?
[00:16:45.680 --> 00:16:48.680]   So that process that Ken went through in three weeks,
[00:16:48.680 --> 00:16:52.800]   because you were, I mean, you're a part of that process.
[00:16:52.800 --> 00:16:57.600]   You contributed a lot to Enix's early development.
[00:16:57.600 --> 00:17:01.360]   So what do you think it takes to do that first step,
[00:17:01.360 --> 00:17:05.460]   that first kind of, from design to reality on the PDP?
[00:17:05.460 --> 00:17:07.160]   - Well, let me correct one thing.
[00:17:07.160 --> 00:17:10.440]   I had nothing to do with it, so I did not write it.
[00:17:10.440 --> 00:17:12.560]   I have never written operating system code.
[00:17:12.560 --> 00:17:16.400]   And so I don't know.
[00:17:16.400 --> 00:17:18.960]   Now, an operating system is simply code,
[00:17:18.960 --> 00:17:21.400]   and this first one wasn't very big,
[00:17:21.400 --> 00:17:24.600]   but it's something that lets you run processes of some,
[00:17:24.600 --> 00:17:27.320]   lets you execute some kind of code that has been written.
[00:17:27.320 --> 00:17:30.820]   It lets you store information for periods of time
[00:17:30.820 --> 00:17:33.160]   so that it doesn't go away when you turn the power off
[00:17:33.160 --> 00:17:35.220]   or reboot or something like that.
[00:17:35.220 --> 00:17:38.560]   And there's kind of a core set of tools
[00:17:38.560 --> 00:17:40.960]   that are technically not part of an operating system,
[00:17:40.960 --> 00:17:42.400]   but you probably need them.
[00:17:42.400 --> 00:17:46.080]   In this case, Ken wrote an assembler for the PDP-7
[00:17:46.080 --> 00:17:46.900]   that worked.
[00:17:46.900 --> 00:17:49.880]   He did a text editor so that he could actually create text.
[00:17:49.880 --> 00:17:52.160]   He had the file system stuff that he had been working on,
[00:17:52.160 --> 00:17:55.760]   and then the rest of it was just a way to load things,
[00:17:55.760 --> 00:17:58.840]   executable code from the file system into the memory,
[00:17:58.840 --> 00:18:01.880]   give it control, and then recover control
[00:18:01.880 --> 00:18:04.840]   when it was finished or in some other way quit.
[00:18:04.840 --> 00:18:06.640]   - What was the code written in,
[00:18:06.640 --> 00:18:08.200]   primarily the programming language?
[00:18:08.200 --> 00:18:09.200]   Was it in assembly?
[00:18:09.200 --> 00:18:12.320]   - Yeah, PDP-7 assembler that Ken created.
[00:18:12.320 --> 00:18:17.440]   These things were assembly language until probably the,
[00:18:17.440 --> 00:18:20.180]   call it 1973 or '74, something like that.
[00:18:20.180 --> 00:18:23.000]   - Forgive me if it's a dumb question,
[00:18:23.000 --> 00:18:25.200]   but it feels like a daunting task
[00:18:25.200 --> 00:18:28.760]   to write any kind of complex system in assembly.
[00:18:28.760 --> 00:18:29.600]   - Absolutely.
[00:18:29.600 --> 00:18:32.940]   - It feels like impossible to do any kind of
[00:18:32.940 --> 00:18:36.160]   what we think of as software engineering with assembly
[00:18:36.160 --> 00:18:40.080]   'cause to work on a big picture sort of.
[00:18:40.080 --> 00:18:41.480]   - I think it's hard.
[00:18:41.480 --> 00:18:43.760]   It's been a long time since I wrote assembly language.
[00:18:43.760 --> 00:18:45.600]   It is absolutely true that in assembly language,
[00:18:45.600 --> 00:18:47.140]   if you make a mistake, nobody tells you.
[00:18:47.140 --> 00:18:49.320]   There are no training wheels whatsoever.
[00:18:49.320 --> 00:18:51.120]   And so stuff doesn't work.
[00:18:51.120 --> 00:18:51.960]   Now what?
[00:18:51.960 --> 00:18:53.400]   - There's no debuggers.
[00:18:53.400 --> 00:18:54.440]   - Well, there could be debuggers,
[00:18:54.440 --> 00:18:56.780]   but that's the same problem, right?
[00:18:56.780 --> 00:18:58.920]   How do you actually get something
[00:18:58.920 --> 00:19:00.400]   that will help you debug it?
[00:19:00.400 --> 00:19:05.400]   So part of it is an ability to see the big picture.
[00:19:05.640 --> 00:19:07.240]   Now these systems were not big
[00:19:07.240 --> 00:19:08.680]   in the sense that today's pictures are.
[00:19:08.680 --> 00:19:11.840]   So the big picture was in some sense more manageable.
[00:19:11.840 --> 00:19:15.240]   I mean, then realistically, there's an enormous variation
[00:19:15.240 --> 00:19:17.520]   in the capabilities of programmers.
[00:19:17.520 --> 00:19:20.200]   And Ken Thompson, who did that first one,
[00:19:20.200 --> 00:19:24.520]   is kind of the singularity in my experience of programmers
[00:19:24.520 --> 00:19:27.760]   with no disrespect to you or even to me.
[00:19:27.760 --> 00:19:31.000]   He's in several leagues removed.
[00:19:31.000 --> 00:19:32.460]   - I know there's levels.
[00:19:33.760 --> 00:19:37.160]   It's a fascinating thing that there are unique stars
[00:19:37.160 --> 00:19:39.800]   in particular in the programming space
[00:19:39.800 --> 00:19:41.160]   and at a particular time.
[00:19:41.160 --> 00:19:42.720]   The time matters too, the timing
[00:19:42.720 --> 00:19:44.440]   of when that person comes along.
[00:19:44.440 --> 00:19:47.800]   And a wife does have to leave.
[00:19:47.800 --> 00:19:49.760]   There's this weird timing that happens
[00:19:49.760 --> 00:19:50.760]   that and then all of a sudden
[00:19:50.760 --> 00:19:52.280]   something beautiful is created.
[00:19:52.280 --> 00:19:53.440]   I mean, how does it make you feel
[00:19:53.440 --> 00:19:58.320]   that there's a system that was created in three weeks
[00:19:58.320 --> 00:20:01.200]   or maybe you can even say on a whim,
[00:20:01.200 --> 00:20:03.660]   but not really, but of course quickly,
[00:20:03.660 --> 00:20:07.140]   that is now, you could think of most of the computers
[00:20:07.140 --> 00:20:10.640]   in the world run on a Unix-like system.
[00:20:10.640 --> 00:20:11.480]   - Right.
[00:20:11.480 --> 00:20:12.880]   (laughs)
[00:20:12.880 --> 00:20:15.280]   - How do you, if you kind of zoom
[00:20:15.280 --> 00:20:16.560]   from the alien perspective,
[00:20:16.560 --> 00:20:18.420]   if you're just observing Earth,
[00:20:18.420 --> 00:20:21.000]   that all of a sudden these computers took over the world
[00:20:21.000 --> 00:20:24.840]   and they started from this little initial seed of Unix,
[00:20:24.840 --> 00:20:26.640]   how does that make you feel?
[00:20:26.640 --> 00:20:27.680]   - It's quite surprising.
[00:20:27.680 --> 00:20:30.280]   And you asked earlier about prediction.
[00:20:30.280 --> 00:20:31.120]   The answer is no.
[00:20:31.120 --> 00:20:33.980]   There's no way you could predict that kind of evolution.
[00:20:33.980 --> 00:20:37.140]   And I don't know whether it was inevitable
[00:20:37.140 --> 00:20:39.120]   or just a whole sequence of blind luck.
[00:20:39.120 --> 00:20:40.960]   I suspect more of the latter.
[00:20:40.960 --> 00:20:45.360]   And so I look at it and think, gee, that's kind of neat.
[00:20:45.360 --> 00:20:47.760]   (laughs)
[00:20:47.760 --> 00:20:51.020]   I think the real question is what does Ken think about that?
[00:20:51.020 --> 00:20:55.180]   'Cause he's the guy arguably from whom it really came.
[00:20:55.180 --> 00:20:57.220]   Tremendous contributions from Dennis Ritchie
[00:20:57.220 --> 00:21:00.220]   and then others around in that Bell Labs environment.
[00:21:00.220 --> 00:21:04.540]   But if you had to pick a single person, that would be Ken.
[00:21:04.540 --> 00:21:06.260]   - So you've written a new book,
[00:21:06.260 --> 00:21:08.340]   Unix, a history and a memoir.
[00:21:08.340 --> 00:21:10.940]   Are there some memorable human stories,
[00:21:10.940 --> 00:21:14.180]   funny or profound from that time that just kind of stand out?
[00:21:14.180 --> 00:21:15.740]   - Oh, there's a lot of them in a sense.
[00:21:15.740 --> 00:21:18.220]   And again, it's a question of can you resurrect them
[00:21:18.220 --> 00:21:19.060]   in real time? - Memory?
[00:21:19.060 --> 00:21:20.420]   (laughs)
[00:21:20.420 --> 00:21:21.780]   - Memory fails.
[00:21:21.780 --> 00:21:25.100]   But I think part of it was that Bell Labs at the time
[00:21:25.100 --> 00:21:27.100]   was a very special kind of place to work
[00:21:27.100 --> 00:21:29.020]   because there were a lot of interesting people
[00:21:29.020 --> 00:21:31.740]   and the environment was very, very open and free.
[00:21:31.740 --> 00:21:33.340]   It was a very cooperative environment,
[00:21:33.340 --> 00:21:34.420]   very friendly environment.
[00:21:34.420 --> 00:21:36.000]   And so if you had an interesting problem,
[00:21:36.000 --> 00:21:37.220]   you go and talk to somebody
[00:21:37.220 --> 00:21:39.320]   and they might help you with the solution.
[00:21:39.320 --> 00:21:43.660]   And it was a kind of a fun environment too
[00:21:43.660 --> 00:21:46.660]   in which people did strange things
[00:21:46.660 --> 00:21:51.660]   and often tweaking the bureaucracy in one way or another.
[00:21:51.660 --> 00:21:54.940]   - So rebellious in certain kinds of ways.
[00:21:54.940 --> 00:21:56.700]   - In some ways, yeah, absolutely.
[00:21:56.700 --> 00:21:58.860]   I think most people didn't take too kindly
[00:21:58.860 --> 00:22:01.540]   to the bureaucracy and I'm sure the bureaucracy
[00:22:01.540 --> 00:22:03.820]   put up with an enormous amount
[00:22:03.820 --> 00:22:05.980]   that they didn't really want to.
[00:22:05.980 --> 00:22:09.500]   - So maybe to linger on it a little bit,
[00:22:09.500 --> 00:22:11.820]   do you have a sense of what the philosophy
[00:22:11.820 --> 00:22:15.300]   that characterizes Unix is, the design?
[00:22:15.300 --> 00:22:18.860]   Not just the initial, but just carry through the years,
[00:22:18.860 --> 00:22:20.640]   just being there, being around it.
[00:22:20.640 --> 00:22:23.340]   What's the fundamental philosophy behind the system?
[00:22:23.340 --> 00:22:25.620]   - I think one aspect of the fundamental philosophy
[00:22:25.620 --> 00:22:29.100]   was to provide an environment that made it easy to write
[00:22:29.100 --> 00:22:31.940]   or easier, productive to write programs.
[00:22:31.940 --> 00:22:33.700]   So it was meant as a programmer environment.
[00:22:33.700 --> 00:22:36.060]   It wasn't meant specifically as something
[00:22:36.060 --> 00:22:38.380]   to do some other kind of job.
[00:22:38.380 --> 00:22:41.380]   For example, it was used extensively for word processing,
[00:22:41.380 --> 00:22:43.700]   but it wasn't designed as a word processing system.
[00:22:43.700 --> 00:22:45.800]   It was used extensively for lab control,
[00:22:45.800 --> 00:22:47.340]   but it wasn't designed for that.
[00:22:47.340 --> 00:22:49.460]   It was used extensively as a front end
[00:22:49.460 --> 00:22:52.460]   for big other systems, big dumb systems,
[00:22:52.460 --> 00:22:53.780]   but it wasn't designed for that.
[00:22:53.780 --> 00:22:55.620]   It was meant to be an environment
[00:22:55.620 --> 00:22:57.980]   where it was really easy to write programs.
[00:22:57.980 --> 00:23:00.260]   So the programmers could be highly productive.
[00:23:00.260 --> 00:23:03.100]   And part of that was to be a community.
[00:23:03.100 --> 00:23:05.780]   And there's some observation from Dennis Ritchie,
[00:23:05.780 --> 00:23:06.940]   I think at the end of the book,
[00:23:06.940 --> 00:23:09.700]   it says that from his standpoint,
[00:23:09.700 --> 00:23:11.900]   the real goal was to create a community
[00:23:11.900 --> 00:23:16.900]   where people could work as programmers on a system.
[00:23:16.900 --> 00:23:19.580]   I think in that sense, certainly for many, many years,
[00:23:19.580 --> 00:23:22.660]   it succeeded quite well at that.
[00:23:22.660 --> 00:23:25.020]   And part of that is the technical aspects
[00:23:25.020 --> 00:23:27.580]   of because it made it really easy to write programs,
[00:23:27.580 --> 00:23:29.500]   people did write interesting programs.
[00:23:29.500 --> 00:23:31.980]   Those programs tended to be used by other programmers.
[00:23:31.980 --> 00:23:34.020]   And so it was kind of a virtuous circle
[00:23:34.020 --> 00:23:36.540]   of more and more stuff coming out
[00:23:36.540 --> 00:23:39.340]   that was really good for programmers.
[00:23:39.340 --> 00:23:41.780]   - And you were part of that community of programmers.
[00:23:41.780 --> 00:23:45.780]   So what was it like writing programs on that early Unix?
[00:23:45.780 --> 00:23:47.380]   - It was a blast, it really was.
[00:23:47.380 --> 00:23:51.100]   You know, I liked to program.
[00:23:51.100 --> 00:23:52.820]   I'm not a terribly good programmer,
[00:23:52.820 --> 00:23:55.260]   but it was a lot of fun to write code.
[00:23:55.260 --> 00:23:56.620]   And in the early days,
[00:23:56.620 --> 00:23:58.220]   there was an enormous amount of what you would,
[00:23:58.220 --> 00:24:00.100]   today I suppose, call low-hanging fruit.
[00:24:00.100 --> 00:24:02.500]   People hadn't done things before,
[00:24:02.500 --> 00:24:04.300]   and this was this new environment,
[00:24:04.300 --> 00:24:07.620]   and the whole combination of nice tools
[00:24:07.620 --> 00:24:11.580]   and very responsive system and tremendous colleagues
[00:24:11.580 --> 00:24:13.660]   made it possible to write code.
[00:24:13.660 --> 00:24:16.420]   You could have an idea in the morning,
[00:24:16.420 --> 00:24:19.060]   you could do an experiment with it,
[00:24:19.060 --> 00:24:21.300]   you could have something limping along that night
[00:24:21.300 --> 00:24:23.580]   or the next day, and people would react to it,
[00:24:23.580 --> 00:24:25.860]   and they would say, "Oh, that's wonderful,
[00:24:25.860 --> 00:24:27.780]   "but you're really screwed up here."
[00:24:27.780 --> 00:24:31.660]   And the feedback loop was then very, very short and tight.
[00:24:31.660 --> 00:24:34.940]   And so a lot of things got developed fairly quickly
[00:24:34.940 --> 00:24:39.860]   that in many cases still exist today.
[00:24:39.860 --> 00:24:43.220]   And I think that was part of what made it fun,
[00:24:43.220 --> 00:24:44.660]   because programming itself is fun.
[00:24:44.660 --> 00:24:46.860]   It's puzzle solving in a variety of ways,
[00:24:46.860 --> 00:24:49.940]   but I think it's even more fun when you do something
[00:24:49.940 --> 00:24:52.260]   that somebody else then uses.
[00:24:52.260 --> 00:24:54.540]   Even if they whine about it not working,
[00:24:54.540 --> 00:24:58.500]   the fact that they used it is part of the reward mechanism.
[00:24:58.500 --> 00:25:00.420]   - And what was the method of interaction,
[00:25:00.420 --> 00:25:03.580]   the communication, that feedback loop?
[00:25:03.580 --> 00:25:05.380]   I mean, this is before the internet.
[00:25:05.380 --> 00:25:07.460]   - Certainly before the internet.
[00:25:07.460 --> 00:25:11.580]   It was mostly physical right there,
[00:25:11.580 --> 00:25:13.620]   somebody would come into your office and say something.
[00:25:13.620 --> 00:25:15.220]   - So these places are all close by,
[00:25:15.220 --> 00:25:16.700]   like offices are nearby,
[00:25:16.700 --> 00:25:18.940]   so you're really lively in interaction.
[00:25:18.940 --> 00:25:20.940]   - Yeah, yeah, no, Bell Labs was fundamentally
[00:25:20.940 --> 00:25:23.020]   one giant building, and most of the people
[00:25:23.020 --> 00:25:24.380]   who were involved in this Unix stuff
[00:25:24.380 --> 00:25:27.620]   were in two or three quarters, and there was a room,
[00:25:27.620 --> 00:25:29.380]   oh, how big was it?
[00:25:29.380 --> 00:25:33.460]   Probably, call it 50 feet by 50 feet,
[00:25:33.460 --> 00:25:37.300]   make up a number of that, which had some access
[00:25:37.300 --> 00:25:39.940]   to computers there as well as in offices,
[00:25:39.940 --> 00:25:42.900]   and people hung out there, and it had a coffee machine.
[00:25:42.900 --> 00:25:46.300]   And so it was mostly very physical.
[00:25:46.300 --> 00:25:48.020]   We did use email, of course,
[00:25:48.020 --> 00:25:52.700]   but it was fundamentally, for a long time,
[00:25:52.700 --> 00:25:56.500]   all on one machine, so there was no need for internet.
[00:25:56.500 --> 00:25:58.660]   - It's fascinating to think about what computing
[00:25:58.660 --> 00:26:00.900]   would be today without Bell Labs.
[00:26:00.900 --> 00:26:02.420]   'Cause it seems so many,
[00:26:02.420 --> 00:26:06.380]   people being in the vicinity of each other,
[00:26:06.380 --> 00:26:08.460]   that sort of getting that quick feedback,
[00:26:08.460 --> 00:26:11.460]   working together, so many brilliant people.
[00:26:11.460 --> 00:26:13.180]   I don't know where else that could have existed
[00:26:13.180 --> 00:26:16.140]   in the world, I mean, given how that came together.
[00:26:16.140 --> 00:26:17.980]   (laughs)
[00:26:17.980 --> 00:26:19.700]   Yeah, how does that make you feel,
[00:26:19.700 --> 00:26:23.180]   that little element of history?
[00:26:23.180 --> 00:26:24.580]   - Well, I think that's very nice,
[00:26:24.580 --> 00:26:26.700]   but in a sense, it's survivor bias,
[00:26:26.700 --> 00:26:29.220]   and if it hadn't happened at Bell Labs,
[00:26:29.220 --> 00:26:30.980]   there were other places that were doing
[00:26:30.980 --> 00:26:32.860]   really interesting work as well.
[00:26:32.860 --> 00:26:34.980]   Xerox PARC is perhaps the most obvious one.
[00:26:34.980 --> 00:26:38.140]   Xerox PARC contributed an enormous amount of good material,
[00:26:38.140 --> 00:26:40.540]   and many of the things we take for granted today
[00:26:40.540 --> 00:26:43.300]   in the same way came from Xerox PARC experience.
[00:26:43.300 --> 00:26:46.420]   I don't think they capitalized in the long run as much.
[00:26:46.420 --> 00:26:49.740]   Their parent company was perhaps not as lucky
[00:26:49.740 --> 00:26:52.780]   in capitalizing on this, who knows?
[00:26:52.780 --> 00:26:54.940]   But that's certainly another place
[00:26:54.940 --> 00:26:58.020]   where there was a tremendous amount of influence.
[00:26:58.020 --> 00:27:00.180]   There were a lot of good university activities.
[00:27:00.180 --> 00:27:03.660]   MIT was obviously no slouch in this kind of thing,
[00:27:03.660 --> 00:27:07.100]   and others as well.
[00:27:07.100 --> 00:27:10.620]   - So Unix turned out to be open source
[00:27:10.620 --> 00:27:13.540]   because of the various ways that AT&T operated,
[00:27:13.540 --> 00:27:17.660]   and sort of it had to, the focus was on telephones.
[00:27:17.660 --> 00:27:21.540]   - I think that's a mischaracterization in a sense.
[00:27:21.540 --> 00:27:23.820]   It absolutely was not open source.
[00:27:23.820 --> 00:27:27.820]   It was very definitely proprietary, licensed,
[00:27:27.820 --> 00:27:30.820]   but it was licensed freely to universities
[00:27:30.820 --> 00:27:33.500]   in source code form for many years,
[00:27:33.500 --> 00:27:37.660]   and because of that, generations of university students
[00:27:37.660 --> 00:27:41.740]   and their faculty people grew up knowing about Unix,
[00:27:41.740 --> 00:27:44.740]   and there was enough expertise in the community
[00:27:44.740 --> 00:27:46.660]   that it then became possible for people
[00:27:46.660 --> 00:27:48.100]   to kind of go off in their own direction
[00:27:48.100 --> 00:27:50.540]   and build something that looked Unix-like.
[00:27:50.540 --> 00:27:54.780]   The Berkeley version of Unix started
[00:27:54.780 --> 00:27:58.220]   with that licensed code and gradually picked up
[00:27:58.220 --> 00:28:01.720]   enough of its own code contributions,
[00:28:01.720 --> 00:28:04.060]   notably from people like Bill Joy,
[00:28:04.060 --> 00:28:07.740]   that eventually it was able to become
[00:28:07.740 --> 00:28:10.500]   completely free of any AT&T code.
[00:28:10.500 --> 00:28:13.140]   Now, there was an enormous amount of legal jockeying
[00:28:13.140 --> 00:28:17.460]   around this in the late, early to late '80s, early '90s,
[00:28:17.460 --> 00:28:22.460]   something like that, and then not,
[00:28:22.460 --> 00:28:26.020]   I guess the open source movement might have started
[00:28:26.020 --> 00:28:28.300]   when Richard Stallman started to think about this
[00:28:28.300 --> 00:28:32.660]   in the late '80s, and by 1991, when Torvalds decided
[00:28:32.660 --> 00:28:37.060]   he was going to do a Unix-like operating system,
[00:28:37.060 --> 00:28:40.460]   there was enough expertise in the community
[00:28:40.460 --> 00:28:44.300]   that first he had a target, he could see what to do,
[00:28:44.300 --> 00:28:47.500]   because the kind of the Unix system call interface
[00:28:47.500 --> 00:28:49.380]   and the tools and so on were there,
[00:28:49.380 --> 00:28:53.440]   and so he was able to build an operating system
[00:28:53.440 --> 00:28:56.140]   that at this point, when you say Unix,
[00:28:56.140 --> 00:28:58.380]   in many cases what you're really thinking is Linux.
[00:28:58.380 --> 00:28:59.860]   - Linux, yeah.
[00:28:59.860 --> 00:29:02.900]   - It's funny that from my distant perception,
[00:29:02.900 --> 00:29:04.740]   I felt that Unix was open source
[00:29:04.740 --> 00:29:08.940]   without actually knowing it, but what you're really saying,
[00:29:08.940 --> 00:29:11.540]   it was just freely licensed.
[00:29:11.540 --> 00:29:12.940]   - It was freely licensed.
[00:29:12.940 --> 00:29:15.860]   - So it felt open source, because universities
[00:29:15.860 --> 00:29:18.540]   are not trying to make money, so it felt open source
[00:29:18.540 --> 00:29:20.540]   in the sense that you can get access if you wanted.
[00:29:20.540 --> 00:29:23.020]   - Right, and a very, very, very large number
[00:29:23.020 --> 00:29:24.900]   of universities had the license, and they were able
[00:29:24.900 --> 00:29:27.380]   to talk to all the other universities who had the license,
[00:29:27.380 --> 00:29:32.220]   and so technically not open, technically belonging to AT&T,
[00:29:32.220 --> 00:29:34.860]   pragmatically pretty open.
[00:29:34.860 --> 00:29:37.340]   - And so there's a ripple effect that all the faculty
[00:29:37.340 --> 00:29:38.980]   and the students, then they all grew up,
[00:29:38.980 --> 00:29:41.860]   and then they went throughout the world
[00:29:41.860 --> 00:29:45.420]   and permeated in that kind of way.
[00:29:45.420 --> 00:29:49.820]   So what kind of features do you think make
[00:29:49.820 --> 00:29:51.280]   for a good operating system?
[00:29:51.280 --> 00:29:55.500]   If you take the lessons of Unix, you said,
[00:29:57.240 --> 00:30:00.980]   make it easy for programmers, that seems to be
[00:30:00.980 --> 00:30:05.340]   an important one, but also Unix turned out
[00:30:05.340 --> 00:30:08.180]   to be exceptionally robust and efficient.
[00:30:08.180 --> 00:30:09.020]   - Right.
[00:30:09.020 --> 00:30:12.100]   - So is that an accident when you focus on the programmer,
[00:30:12.100 --> 00:30:14.740]   or is that a natural outcome?
[00:30:14.740 --> 00:30:17.540]   - I think part of the reason for efficiency
[00:30:17.540 --> 00:30:21.180]   was that it began on extremely modest hardware,
[00:30:21.180 --> 00:30:23.980]   very, very, very tiny, and so you couldn't get carried away,
[00:30:23.980 --> 00:30:26.680]   you couldn't do a lot of complicated things
[00:30:26.680 --> 00:30:30.000]   because you just didn't have the resources,
[00:30:30.000 --> 00:30:32.360]   either processor speed or memory,
[00:30:32.360 --> 00:30:37.360]   and so that enforced a certain minimality of mechanisms,
[00:30:37.360 --> 00:30:40.040]   and maybe a search for generalizations
[00:30:40.040 --> 00:30:41.800]   so that you would find one mechanism
[00:30:41.800 --> 00:30:43.480]   that served for a lot of different things
[00:30:43.480 --> 00:30:45.880]   rather than having lots of different special cases.
[00:30:45.880 --> 00:30:48.760]   I think the file system in Unix is a good example
[00:30:48.760 --> 00:30:51.440]   of that file system interface in its fundamental form
[00:30:51.440 --> 00:30:53.560]   is extremely straightforward,
[00:30:53.560 --> 00:30:55.580]   and that means that you can write code
[00:30:55.580 --> 00:30:58.880]   very, very effectively for the file system,
[00:30:58.880 --> 00:31:02.680]   and then one of those generalizations
[00:31:02.680 --> 00:31:04.560]   is that, gee, that file system interface
[00:31:04.560 --> 00:31:06.740]   works for all kinds of other things as well,
[00:31:06.740 --> 00:31:09.560]   and so in particular, the idea of reading and writing
[00:31:09.560 --> 00:31:11.960]   to devices is the same as reading and writing
[00:31:11.960 --> 00:31:14.600]   to a disk that has a file system,
[00:31:14.600 --> 00:31:17.820]   and then that gets carried further in other parts.
[00:31:17.820 --> 00:31:21.800]   The world processes become, in effect,
[00:31:21.800 --> 00:31:23.360]   files in a file system,
[00:31:23.360 --> 00:31:25.800]   and the Plan 9 operating system,
[00:31:25.800 --> 00:31:27.420]   which came along, I guess, in the late '80s
[00:31:27.420 --> 00:31:30.520]   or something like that, took a lot of those ideas
[00:31:30.520 --> 00:31:32.980]   from the original Unix and tried to push
[00:31:32.980 --> 00:31:34.720]   the generalization even further
[00:31:34.720 --> 00:31:37.160]   so that in Plan 9, a lot of different resources
[00:31:37.160 --> 00:31:38.160]   are file systems.
[00:31:38.160 --> 00:31:40.040]   They all share that interface,
[00:31:40.040 --> 00:31:42.200]   so that would be one example
[00:31:42.200 --> 00:31:45.480]   where finding the right model of how to do something
[00:31:45.480 --> 00:31:48.040]   means that an awful lot of things become simpler,
[00:31:48.040 --> 00:31:50.360]   and it means, therefore, that more people can do useful,
[00:31:50.360 --> 00:31:51.720]   interesting things with them
[00:31:51.720 --> 00:31:54.440]   without having to think as hard about it.
[00:31:54.440 --> 00:31:56.960]   - So you said you're not a very good programmer.
[00:31:56.960 --> 00:31:58.480]   - True.
[00:31:58.480 --> 00:32:01.400]   - You're the world's most modest human being, okay,
[00:32:01.400 --> 00:32:03.280]   but you'll continue saying that.
[00:32:03.280 --> 00:32:04.440]   I understand how this works,
[00:32:04.440 --> 00:32:07.760]   but you do radiate a sort of love for programming,
[00:32:07.760 --> 00:32:10.840]   so let me ask, do you think programming
[00:32:10.840 --> 00:32:13.240]   is more an art or a science?
[00:32:13.240 --> 00:32:16.640]   Is it creativity or kind of rigor?
[00:32:16.640 --> 00:32:18.040]   - I think it's some of each.
[00:32:18.040 --> 00:32:20.760]   It's some combination.
[00:32:20.760 --> 00:32:22.640]   Some of the art is figuring out what it is
[00:32:22.640 --> 00:32:25.480]   that you really wanna do, what should that program be,
[00:32:25.480 --> 00:32:27.520]   what would make a good program,
[00:32:27.520 --> 00:32:30.600]   and that's some understanding of what the task is,
[00:32:30.600 --> 00:32:33.560]   what the people who might use this program want,
[00:32:33.560 --> 00:32:37.720]   and I think that's art in many respects.
[00:32:37.720 --> 00:32:40.440]   The science part is trying to figure out how to do it well,
[00:32:40.440 --> 00:32:45.200]   and some of that is real computer science-y stuff,
[00:32:45.200 --> 00:32:48.040]   like what algorithm should we use at some point,
[00:32:48.040 --> 00:32:52.280]   mostly in the sense of being careful to use algorithms
[00:32:52.280 --> 00:32:56.200]   that will actually work properly, scale properly,
[00:32:56.200 --> 00:32:57.960]   avoiding quadratic algorithms
[00:32:57.960 --> 00:33:01.240]   when a linear algorithm should be the right thing,
[00:33:01.240 --> 00:33:04.040]   that kind of more formal view of it.
[00:33:04.040 --> 00:33:06.360]   Same thing for data structures,
[00:33:06.360 --> 00:33:10.280]   but also it's, I think, an engineering field as well,
[00:33:10.280 --> 00:33:12.440]   and engineering's not quite the same as science
[00:33:12.440 --> 00:33:15.240]   because in engineering you're working with constraints.
[00:33:15.240 --> 00:33:18.520]   You have to figure out not only,
[00:33:18.520 --> 00:33:20.920]   so what is a good algorithm for this kind of thing,
[00:33:20.920 --> 00:33:22.800]   but what's the most appropriate algorithm
[00:33:22.800 --> 00:33:26.200]   given the amount of time we have to compute,
[00:33:26.200 --> 00:33:27.920]   the amount of time we have to program,
[00:33:27.920 --> 00:33:30.720]   what's likely to happen in the future with maintenance,
[00:33:30.720 --> 00:33:33.040]   who's gonna pick this up in the future,
[00:33:33.040 --> 00:33:35.800]   all of those kind of things that if you're an engineer,
[00:33:35.800 --> 00:33:37.160]   you get to worry about,
[00:33:37.160 --> 00:33:39.120]   whereas if you think of yourself as a scientist,
[00:33:39.120 --> 00:33:42.040]   well, you can maybe push them over the horizon in a way,
[00:33:42.040 --> 00:33:44.080]   and if you're an artist, what's that?
[00:33:44.080 --> 00:33:45.320]   (laughing)
[00:33:45.320 --> 00:33:48.560]   - So just on your own personal level,
[00:33:48.560 --> 00:33:50.640]   what's your process like of writing a program,
[00:33:50.640 --> 00:33:55.640]   say a small and large sort of tinkering with stuff?
[00:33:55.640 --> 00:33:57.960]   Do you just start coding right away
[00:33:57.960 --> 00:34:02.960]   and just kind of evolve iteratively with a loose notion,
[00:34:02.960 --> 00:34:05.760]   or do you plan on a sheet of paper first
[00:34:05.760 --> 00:34:09.280]   and then kind of design what they teach you
[00:34:09.280 --> 00:34:12.640]   in the kind of software engineering courses in undergrad
[00:34:12.640 --> 00:34:13.640]   or something like that?
[00:34:13.640 --> 00:34:14.880]   What's your process like?
[00:34:14.880 --> 00:34:17.440]   - It's certainly much more the informal incremental.
[00:34:17.440 --> 00:34:20.160]   First, I don't write big programs at this point.
[00:34:20.160 --> 00:34:21.720]   It's been a long time since I wrote a program
[00:34:21.720 --> 00:34:25.560]   that was more than, I call it a few hundred or more lines,
[00:34:25.560 --> 00:34:27.000]   something like that.
[00:34:27.000 --> 00:34:29.040]   Many of the programs I write are experiments
[00:34:29.040 --> 00:34:31.640]   for either something I'm curious about
[00:34:31.640 --> 00:34:34.560]   or often for something that I wanna talk about in a class,
[00:34:34.560 --> 00:34:37.560]   and so those necessarily tend to be relatively small.
[00:34:38.960 --> 00:34:41.400]   A lot of the kind of code I write these days
[00:34:41.400 --> 00:34:44.280]   tends to be for sort of exploratory data analysis
[00:34:44.280 --> 00:34:46.240]   where I've got some collection of data
[00:34:46.240 --> 00:34:47.080]   and I wanna try and figure out
[00:34:47.080 --> 00:34:49.200]   what on earth is going on in it,
[00:34:49.200 --> 00:34:52.280]   and for that, those programs tend to be very small.
[00:34:52.280 --> 00:34:53.920]   Sometimes you're not even programming,
[00:34:53.920 --> 00:34:57.800]   you're just using existing tools like counting things,
[00:34:57.800 --> 00:35:00.200]   or sometimes you're writing ox scripts
[00:35:00.200 --> 00:35:02.800]   because two or three lines will tell you something
[00:35:02.800 --> 00:35:05.160]   about a piece of data, and then when it gets bigger,
[00:35:05.160 --> 00:35:07.720]   well, then I will probably write something in Python
[00:35:08.760 --> 00:35:10.720]   because that scales better,
[00:35:10.720 --> 00:35:14.560]   up to, call it a few hundred lines or something like that,
[00:35:14.560 --> 00:35:16.280]   and it's been a long time since I wrote programs
[00:35:16.280 --> 00:35:18.560]   that were much more than that.
[00:35:18.560 --> 00:35:21.000]   - Speaking of data exploration and awk,
[00:35:21.000 --> 00:35:23.600]   first, what is awk?
[00:35:23.600 --> 00:35:25.400]   - So awk is a scripting language
[00:35:25.400 --> 00:35:30.240]   that was done by myself, Al Aho, and Peter Weinberger.
[00:35:30.240 --> 00:35:32.680]   We did that originally in the late '70s.
[00:35:32.680 --> 00:35:34.800]   It was a language that was meant to make it really easy
[00:35:34.800 --> 00:35:39.360]   to do quick and dirty tasks like counting things
[00:35:39.360 --> 00:35:42.800]   or selecting interesting information
[00:35:42.800 --> 00:35:45.040]   from basically all text files,
[00:35:45.040 --> 00:35:48.120]   rearranging it in some way or summarizing it.
[00:35:48.120 --> 00:35:51.520]   - It runs a command on each line of a file.
[00:35:51.520 --> 00:35:55.560]   I mean, it's still exceptionally widely used today.
[00:35:55.560 --> 00:35:56.880]   - Oh, absolutely, yeah.
[00:35:56.880 --> 00:35:58.520]   - It's so simple and elegant,
[00:35:58.520 --> 00:36:01.520]   sort of the way to explore data.
[00:36:01.520 --> 00:36:03.160]   Turns out you can just write a script
[00:36:03.160 --> 00:36:07.160]   that does something seemingly trivial on a single line,
[00:36:07.160 --> 00:36:09.880]   and that giving you that slice of the data
[00:36:09.880 --> 00:36:13.160]   somehow reveals something fundamental about the data,
[00:36:13.160 --> 00:36:17.120]   and that keeps, that seems to work still.
[00:36:17.120 --> 00:36:19.120]   - Yeah, it's very good for that kind of thing,
[00:36:19.120 --> 00:36:21.200]   and that's sort of what it was meant for.
[00:36:21.200 --> 00:36:22.560]   I think what we didn't appreciate
[00:36:22.560 --> 00:36:24.800]   was that the model was actually quite good
[00:36:24.800 --> 00:36:27.640]   for a lot of data processing kinds of tasks,
[00:36:27.640 --> 00:36:30.760]   and that it's kept going as long as it has,
[00:36:30.760 --> 00:36:32.840]   'cause at this point it's over 40 years old,
[00:36:32.840 --> 00:36:35.960]   and it's still, I think, a useful tool.
[00:36:35.960 --> 00:36:38.440]   And well, this is paternal interest, I guess,
[00:36:38.440 --> 00:36:41.000]   but I think in terms of programming languages,
[00:36:41.000 --> 00:36:44.240]   you get the most bang for the buck by learning AWK,
[00:36:44.240 --> 00:36:46.600]   and it doesn't scale to big programs,
[00:36:46.600 --> 00:36:49.960]   but it does pretty darn well on these little things
[00:36:49.960 --> 00:36:52.920]   where you just wanna see all the somethings in something.
[00:36:52.920 --> 00:36:56.000]   So yeah, I find, I probably write more AWK
[00:36:56.000 --> 00:36:58.680]   than anything else at this point.
[00:36:58.680 --> 00:37:01.040]   - So what kind of stuff do you love about AWK?
[00:37:01.040 --> 00:37:05.160]   Like, is there, if you can comment on sort of things
[00:37:05.160 --> 00:37:10.240]   that give you joy when you can, in a simple program,
[00:37:10.240 --> 00:37:11.600]   reveal something about the data,
[00:37:11.600 --> 00:37:14.600]   is there something that stands out from particular features?
[00:37:14.600 --> 00:37:19.200]   - I think it's mostly the selection of default behaviors,
[00:37:19.200 --> 00:37:21.080]   that you sort of hinted at it a moment ago.
[00:37:21.080 --> 00:37:24.800]   What AWK does is to read through a set of files,
[00:37:24.800 --> 00:37:26.240]   and then within each file,
[00:37:26.240 --> 00:37:28.440]   it reads through each of the lines,
[00:37:28.440 --> 00:37:29.960]   and then on each of the lines,
[00:37:29.960 --> 00:37:33.080]   it has a set of patterns that it looks for,
[00:37:33.080 --> 00:37:34.720]   that's your AWK program,
[00:37:34.720 --> 00:37:36.880]   and if one of the patterns matches,
[00:37:36.880 --> 00:37:39.880]   there is a corresponding action that you might perform,
[00:37:39.880 --> 00:37:43.440]   and so it's kind of a quadruply nested loop
[00:37:43.440 --> 00:37:45.040]   or something like that,
[00:37:45.040 --> 00:37:46.600]   and that's all completely automatic.
[00:37:46.600 --> 00:37:48.120]   You don't have to say anything about it,
[00:37:48.120 --> 00:37:49.920]   you just write the pattern and the action,
[00:37:49.920 --> 00:37:52.000]   and then run the data by it,
[00:37:52.000 --> 00:37:54.160]   and so that paradigm for programming
[00:37:54.160 --> 00:37:56.880]   is a very natural and effective one,
[00:37:56.880 --> 00:38:00.160]   and I think we captured that reasonably well in AWK,
[00:38:00.160 --> 00:38:01.920]   and it does other things for free as well.
[00:38:01.920 --> 00:38:04.240]   It splits the data into fields,
[00:38:04.240 --> 00:38:05.240]   so that on each line,
[00:38:05.240 --> 00:38:07.560]   there's fields separated by white space or something,
[00:38:07.560 --> 00:38:08.800]   and so it does that for free,
[00:38:08.800 --> 00:38:11.200]   you don't have to say anything about it,
[00:38:11.200 --> 00:38:13.760]   and it collects information as it goes along,
[00:38:13.760 --> 00:38:15.280]   like what line are we on,
[00:38:15.280 --> 00:38:18.000]   how many fields are there on this line?
[00:38:18.000 --> 00:38:20.800]   So lots of things that just make it so that a program
[00:38:20.800 --> 00:38:24.040]   which in another language, let's say Python,
[00:38:24.040 --> 00:38:26.240]   would be five, 10, 20 lines,
[00:38:26.240 --> 00:38:28.040]   in AWK it's one or two lines.
[00:38:28.040 --> 00:38:29.600]   - And so because it's one or two lines,
[00:38:29.600 --> 00:38:31.840]   you can do it on the shell,
[00:38:31.840 --> 00:38:33.720]   you don't have to open up another whole thing,
[00:38:33.720 --> 00:38:35.200]   you can just do it right there
[00:38:35.200 --> 00:38:37.960]   in the interaction with the operator directly.
[00:38:37.960 --> 00:38:43.920]   Is there other shell commands that you love over the years,
[00:38:43.920 --> 00:38:46.320]   like you really enjoy using?
[00:38:46.320 --> 00:38:47.960]   - Oh, grep. - Grep?
[00:38:47.960 --> 00:38:49.760]   - Grep's the only one.
[00:38:49.760 --> 00:38:51.440]   Yeah, grep does everything.
[00:38:51.440 --> 00:38:53.240]   - So grep is a kind of a, what is it,
[00:38:53.240 --> 00:38:55.320]   a simpler version of AWK, I would say?
[00:38:55.320 --> 00:38:58.000]   - In some sense, yeah, right, because--
[00:38:58.000 --> 00:38:58.880]   - What is grep?
[00:38:58.880 --> 00:39:01.800]   - So grep is, it basically searches the input
[00:39:01.800 --> 00:39:03.960]   for particular patterns, regular expressions,
[00:39:03.960 --> 00:39:05.880]   technically, of a certain class,
[00:39:05.880 --> 00:39:08.600]   and it has that same paradigm that AWK does,
[00:39:08.600 --> 00:39:10.040]   it's a pattern action thing,
[00:39:10.040 --> 00:39:11.280]   it reads through all the files
[00:39:11.280 --> 00:39:13.440]   and then all the lines in each file,
[00:39:13.440 --> 00:39:15.200]   but it has a single pattern,
[00:39:15.200 --> 00:39:17.000]   which is the regular expression you're looking for,
[00:39:17.000 --> 00:39:20.240]   and a single action printed, if it matches.
[00:39:20.240 --> 00:39:22.560]   So in that sense, it's a much simpler version
[00:39:22.560 --> 00:39:25.560]   and you could write grep and AWK as a one-liner,
[00:39:25.560 --> 00:39:30.440]   and I use grep probably more than anything else
[00:39:30.440 --> 00:39:35.040]   at this point, just because it's so convenient and natural.
[00:39:35.040 --> 00:39:38.640]   - Why do you think, it's such a powerful tool, grep and AWK,
[00:39:38.640 --> 00:39:41.280]   why do you think operating systems like Windows,
[00:39:41.280 --> 00:39:44.800]   for example, don't have it?
[00:39:44.800 --> 00:39:48.240]   Sort of, you can, of course, I use, which is amazing now,
[00:39:48.240 --> 00:39:49.920]   there's Windows for Linux,
[00:39:51.560 --> 00:39:54.880]   which you could basically use all the fun stuff
[00:39:54.880 --> 00:39:57.360]   like AWK and grep inside of Windows,
[00:39:57.360 --> 00:39:58.640]   but Windows naturally,
[00:39:58.640 --> 00:40:00.800]   sort of as part of the graphical interface,
[00:40:00.800 --> 00:40:02.400]   the simplicity of grep,
[00:40:02.400 --> 00:40:04.760]   sort of searching through a bunch of files
[00:40:04.760 --> 00:40:06.600]   and just popping up naturally.
[00:40:06.600 --> 00:40:08.120]   Why don't you think that,
[00:40:08.120 --> 00:40:09.040]   why do you think that's unique
[00:40:09.040 --> 00:40:11.600]   to the Unix and Linux environment?
[00:40:11.600 --> 00:40:14.000]   - I don't know, it's not strictly unique,
[00:40:14.000 --> 00:40:16.400]   but it's certainly focused there,
[00:40:16.400 --> 00:40:19.040]   and I think some of it's the weight of history
[00:40:19.040 --> 00:40:22.000]   that Windows came from MS-DOS,
[00:40:22.000 --> 00:40:24.480]   MS-DOS was a pretty pathetic operating system,
[00:40:24.480 --> 00:40:29.000]   although common on an unboundedly large number of machines,
[00:40:29.000 --> 00:40:32.840]   but somewhere in roughly the '90s,
[00:40:32.840 --> 00:40:34.640]   Windows became a graphical system,
[00:40:34.640 --> 00:40:37.920]   and I think Microsoft spent a lot of their energy
[00:40:37.920 --> 00:40:41.240]   on making that graphical interface what it is,
[00:40:41.240 --> 00:40:44.000]   and that's a different model of computing.
[00:40:44.000 --> 00:40:45.560]   It's a model of computing that,
[00:40:45.560 --> 00:40:47.080]   where you point and click
[00:40:47.080 --> 00:40:49.520]   and sort of experiment with menus,
[00:40:49.520 --> 00:40:52.680]   it's a model of computing works rather well
[00:40:52.680 --> 00:40:54.480]   for people who are not programmers,
[00:40:54.480 --> 00:40:56.080]   who just wanna get something done,
[00:40:56.080 --> 00:40:59.120]   whereas teaching something like the command line
[00:40:59.120 --> 00:41:00.960]   to non-programmers turns out
[00:41:00.960 --> 00:41:02.800]   to sometimes be an uphill struggle,
[00:41:02.800 --> 00:41:04.840]   and so I think Microsoft probably was right
[00:41:04.840 --> 00:41:06.280]   in what they did.
[00:41:06.280 --> 00:41:08.440]   Now you mentioned Whistle or whatever it's called,
[00:41:08.440 --> 00:41:09.280]   the Linux.
[00:41:09.280 --> 00:41:11.040]   - Whistle, I wonder what it's pronounced,
[00:41:11.040 --> 00:41:12.240]   W-S-L is what,
[00:41:12.240 --> 00:41:13.920]   I've never actually pronounced the Whistle, I like it.
[00:41:13.920 --> 00:41:14.760]   - I have no idea.
[00:41:14.760 --> 00:41:15.600]   (laughing)
[00:41:15.600 --> 00:41:16.440]   - Whistle.
[00:41:16.440 --> 00:41:17.560]   - And things like that for a long,
[00:41:17.560 --> 00:41:18.760]   a Cygwin, for example,
[00:41:18.760 --> 00:41:20.600]   which is a wonderful collection
[00:41:20.600 --> 00:41:23.280]   of take all your favorite tools from Unix and Linux
[00:41:23.280 --> 00:41:25.400]   and just make them work perfectly on Windows,
[00:41:25.400 --> 00:41:27.280]   and so that's something that's been going on
[00:41:27.280 --> 00:41:29.880]   for at least 20 years, if not longer,
[00:41:29.880 --> 00:41:33.000]   and I use that on my one remaining Windows machine
[00:41:33.000 --> 00:41:37.760]   routinely because if you're doing something
[00:41:37.760 --> 00:41:39.200]   that is batch computing,
[00:41:39.200 --> 00:41:41.720]   suitable for command line,
[00:41:41.720 --> 00:41:42.680]   that's the right way to do it
[00:41:42.680 --> 00:41:44.480]   because the Windows equivalents are,
[00:41:44.480 --> 00:41:46.320]   if nothing else, not familiar to me.
[00:41:46.320 --> 00:41:49.880]   - But I would definitely recommend to people
[00:41:49.880 --> 00:41:52.480]   to if they don't use Cygwin to try Whistle.
[00:41:52.480 --> 00:41:53.320]   - Yes.
[00:41:53.320 --> 00:41:57.080]   - I've been so excited that I could use BASH,
[00:41:57.080 --> 00:42:00.560]   that you bash, write scripts quickly in Windows,
[00:42:00.560 --> 00:42:03.240]   it's changed my life.
[00:42:03.240 --> 00:42:06.480]   Okay, what's your perfect programming setup?
[00:42:06.480 --> 00:42:08.320]   What computer, what operating system,
[00:42:08.320 --> 00:42:10.520]   what keyboard, what editor?
[00:42:10.520 --> 00:42:13.360]   - Yeah, perfect is too strong a word.
[00:42:13.360 --> 00:42:15.320]   It's way too strong a word.
[00:42:15.320 --> 00:42:18.320]   What I use by default, I have a,
[00:42:18.320 --> 00:42:20.920]   at this point, a 13-inch MacBook Air,
[00:42:20.920 --> 00:42:24.240]   which I use because it's kind of a reasonable balance
[00:42:24.240 --> 00:42:25.280]   of the various things I need.
[00:42:25.280 --> 00:42:26.600]   I can carry it around.
[00:42:26.600 --> 00:42:28.040]   It's got enough computing horsepower,
[00:42:28.040 --> 00:42:30.200]   screen's big enough, keyboard's okay,
[00:42:30.200 --> 00:42:34.640]   and so I basically do most of my computing on that.
[00:42:34.640 --> 00:42:37.040]   I have a big iMac in my office
[00:42:37.040 --> 00:42:39.480]   that I use from time to time as well,
[00:42:39.480 --> 00:42:41.040]   especially when I need a big screen,
[00:42:41.040 --> 00:42:44.840]   but otherwise, it tends not to be used that much.
[00:42:44.840 --> 00:42:48.400]   - Editor.
[00:42:48.400 --> 00:42:51.200]   - I use mostly SAM, which is an editor
[00:42:51.200 --> 00:42:55.600]   that Rob Pike wrote long ago at Bell Labs.
[00:42:55.600 --> 00:42:58.680]   - Did that, sorry to interrupt, does that precede VI?
[00:42:58.680 --> 00:43:00.040]   Does that precede Emacs?
[00:43:00.040 --> 00:43:03.160]   - It post-dates both VI and Emacs.
[00:43:03.160 --> 00:43:09.040]   It is derived from Rob's experience with ED and VI.
[00:43:10.040 --> 00:43:10.880]   - ED.
[00:43:10.880 --> 00:43:14.640]   - That's the original Unix editor.
[00:43:14.640 --> 00:43:15.480]   - Oh, wow.
[00:43:15.480 --> 00:43:18.320]   - Dated probably before you were born.
[00:43:18.320 --> 00:43:23.440]   - So what's, actually, what's the history of editors?
[00:43:23.440 --> 00:43:26.680]   Can you briefly, 'cause it's such a,
[00:43:26.680 --> 00:43:28.520]   I use Emacs, I'm sorry to say.
[00:43:28.520 --> 00:43:30.280]   So sorry to come out with that,
[00:43:30.280 --> 00:43:33.640]   but what's the kind of interplay there?
[00:43:33.640 --> 00:43:35.160]   So SAM, yeah, 'cause VI.
[00:43:35.160 --> 00:43:37.400]   - So in ancient times, like,
[00:43:37.400 --> 00:43:39.280]   call it the first time-sharing systems,
[00:43:39.280 --> 00:43:40.840]   going back to what we were talking about,
[00:43:40.840 --> 00:43:43.880]   there were editors, there was an editor on CTSS
[00:43:43.880 --> 00:43:46.120]   that I don't even remember what it was called.
[00:43:46.120 --> 00:43:49.880]   It might've been edit, where you could type text,
[00:43:49.880 --> 00:43:52.000]   program text, and it would do something,
[00:43:52.000 --> 00:43:53.760]   or document text.
[00:43:53.760 --> 00:43:54.600]   - You could save the text.
[00:43:54.600 --> 00:43:57.240]   - And save it, you could edit it,
[00:43:57.240 --> 00:44:00.240]   usual thing that you would get in an editor.
[00:44:00.240 --> 00:44:03.060]   And Ken Thompson wrote an editor called QED,
[00:44:03.060 --> 00:44:06.040]   which was very, very powerful,
[00:44:06.040 --> 00:44:08.680]   but these were all totally a command-based,
[00:44:08.680 --> 00:44:10.760]   they were not mouse or cursor-based,
[00:44:10.760 --> 00:44:13.800]   because it was before mice, and even before cursors,
[00:44:13.800 --> 00:44:15.040]   'cause they were running on terminals
[00:44:15.040 --> 00:44:17.040]   that printed on paper, okay?
[00:44:17.040 --> 00:44:20.500]   No CRT-type displays, let alone LEDs.
[00:44:20.500 --> 00:44:24.240]   And so then when Unix came along,
[00:44:24.240 --> 00:44:28.760]   Ken took QED and stripped it way, way, way, way down,
[00:44:28.760 --> 00:44:31.160]   and that became an editor that he called ED.
[00:44:31.160 --> 00:44:33.880]   And it was very simple, but it was a line-oriented editor.
[00:44:33.880 --> 00:44:36.160]   And so you could load a file,
[00:44:36.160 --> 00:44:37.840]   and then you could talk about the lines,
[00:44:37.840 --> 00:44:39.240]   one through the last line,
[00:44:39.240 --> 00:44:41.600]   and you could print ranges of lines,
[00:44:41.600 --> 00:44:44.000]   you could add text, you could delete text,
[00:44:44.000 --> 00:44:44.880]   you could change text,
[00:44:44.880 --> 00:44:46.480]   or you could do a substitute command
[00:44:46.480 --> 00:44:47.980]   that would change things within a line,
[00:44:47.980 --> 00:44:49.280]   or within groups of lines.
[00:44:49.280 --> 00:44:51.320]   - So you could work on parts of a file, essentially.
[00:44:51.320 --> 00:44:53.000]   - Yeah, you could work on any part of it,
[00:44:53.000 --> 00:44:53.920]   the whole thing, or whatever,
[00:44:53.920 --> 00:44:57.340]   but it was entirely command-line-based,
[00:44:57.340 --> 00:45:00.840]   and it was entirely on paper, okay?
[00:45:00.840 --> 00:45:02.280]   Paper, and that meant that you changed--
[00:45:02.280 --> 00:45:03.120]   - Actual paper.
[00:45:03.120 --> 00:45:04.080]   - Yeah, right, real paper.
[00:45:04.080 --> 00:45:06.120]   And so if you changed a line,
[00:45:06.120 --> 00:45:07.820]   you had to print that line,
[00:45:07.820 --> 00:45:09.140]   using up another line of paper
[00:45:09.140 --> 00:45:11.760]   to see what the change caused, okay?
[00:45:11.760 --> 00:45:12.920]   - Yeah, it's amazing.
[00:45:12.920 --> 00:45:17.080]   - So when CRT displays came along,
[00:45:17.080 --> 00:45:19.800]   then you could start to use cursor control,
[00:45:19.800 --> 00:45:23.280]   and you could sort of move where you were on the screen in--
[00:45:23.280 --> 00:45:26.160]   - Without reprinting every time.
[00:45:26.160 --> 00:45:29.840]   - Printing, and there were a number of editors there.
[00:45:29.840 --> 00:45:31.680]   The one that I was most familiar with,
[00:45:31.680 --> 00:45:35.200]   and still use, is VI, which was done by Bill Choi.
[00:45:35.200 --> 00:45:40.200]   And so that dates from probably the late '70s, as a guess,
[00:45:40.200 --> 00:45:45.240]   and it took full advantage of the cursor controls.
[00:45:45.240 --> 00:45:48.340]   I suspected Emacs was roughly at the same time,
[00:45:48.340 --> 00:45:51.040]   but I don't know, I've never internalized Emacs.
[00:45:51.040 --> 00:45:54.720]   So I use, at this point, I stopped using ED,
[00:45:54.720 --> 00:45:56.360]   although I still can.
[00:45:56.360 --> 00:46:00.160]   I use VI sometimes, and I use SAM when I can.
[00:46:00.160 --> 00:46:02.480]   - And SAM is available on most systems?
[00:46:02.480 --> 00:46:04.520]   - It is available.
[00:46:04.520 --> 00:46:05.640]   You have to download it yourself
[00:46:05.640 --> 00:46:08.560]   from typically the plan line operating system distribution.
[00:46:08.560 --> 00:46:10.960]   It's been maintained by people there.
[00:46:10.960 --> 00:46:12.640]   And so--
[00:46:12.640 --> 00:46:14.360]   - I'll get home tonight, I'll try it.
[00:46:14.360 --> 00:46:15.200]   It's cool.
[00:46:15.200 --> 00:46:17.840]   It sounds fascinating.
[00:46:17.840 --> 00:46:20.640]   Although my love is with Lisp and Emacs,
[00:46:20.640 --> 00:46:23.080]   I've went into that hippie world of--
[00:46:23.080 --> 00:46:25.120]   (both laughing)
[00:46:25.120 --> 00:46:26.040]   - I think it's a lot of things.
[00:46:26.040 --> 00:46:27.600]   What religion were you brought up with?
[00:46:27.600 --> 00:46:28.720]   - Yeah, that's true.
[00:46:28.720 --> 00:46:29.560]   That's true.
[00:46:29.560 --> 00:46:31.920]   Most of the actual programming I do
[00:46:31.920 --> 00:46:34.080]   is C, C++, and Python,
[00:46:34.080 --> 00:46:36.240]   but my weird sort of, yeah,
[00:46:36.240 --> 00:46:38.080]   my religious upbringing is in Lisp.
[00:46:38.080 --> 00:46:41.760]   So can you take on the impossible task
[00:46:41.760 --> 00:46:44.760]   and give a brief history of programming languages
[00:46:44.760 --> 00:46:46.400]   from your perspective?
[00:46:46.400 --> 00:46:48.360]   - So I guess you could say programming languages
[00:46:48.360 --> 00:46:51.080]   started probably in what, the late '40s
[00:46:51.080 --> 00:46:51.960]   or something like that.
[00:46:51.960 --> 00:46:53.760]   People used to program computers
[00:46:53.760 --> 00:46:56.200]   by basically putting in zeros and ones
[00:46:56.200 --> 00:46:58.800]   using something like switches on a console.
[00:46:59.800 --> 00:47:03.560]   And then, or maybe holes in paper tapes,
[00:47:03.560 --> 00:47:04.920]   something like that.
[00:47:04.920 --> 00:47:07.960]   So extremely tedious, awful, whatever.
[00:47:07.960 --> 00:47:10.240]   And so I think the first programming languages
[00:47:10.240 --> 00:47:14.560]   were relatively crude assembly languages
[00:47:14.560 --> 00:47:18.360]   where people would basically write a program
[00:47:18.360 --> 00:47:22.360]   that would convert mnemonics like add, A-D-D,
[00:47:22.360 --> 00:47:24.880]   into whatever the bit pattern was
[00:47:24.880 --> 00:47:26.720]   that corresponded to an add instruction.
[00:47:26.720 --> 00:47:28.200]   And they would do the clerical work
[00:47:28.200 --> 00:47:30.040]   of figuring out where things were.
[00:47:30.040 --> 00:47:32.760]   So you could put a name on a location in a program
[00:47:32.760 --> 00:47:34.920]   and the assembler would figure out
[00:47:34.920 --> 00:47:36.320]   where that corresponded to
[00:47:36.320 --> 00:47:37.880]   when the thing was all put together
[00:47:37.880 --> 00:47:39.920]   and dropped into memory.
[00:47:39.920 --> 00:47:45.560]   And early on, and this would be the late '40s
[00:47:45.560 --> 00:47:46.680]   and very early '50s,
[00:47:46.680 --> 00:47:50.000]   there were assemblers written for the various machines
[00:47:50.000 --> 00:47:51.000]   that people used.
[00:47:51.000 --> 00:47:52.920]   You may have seen in the paper just a couple of days ago,
[00:47:52.920 --> 00:47:54.160]   Tony Berker died.
[00:47:54.160 --> 00:47:55.880]   He did this thing in Manchester
[00:47:55.880 --> 00:48:00.880]   called AutoCode, a language which I knew only by name.
[00:48:00.880 --> 00:48:04.400]   But it sounds like it was a flavor of assembly language,
[00:48:04.400 --> 00:48:06.720]   sort of a little higher in some ways.
[00:48:06.720 --> 00:48:09.080]   And it replaced a language that Alan Turing wrote,
[00:48:09.080 --> 00:48:11.120]   which you put in zeros and ones,
[00:48:11.120 --> 00:48:12.440]   but you put it in backwards order
[00:48:12.440 --> 00:48:14.400]   because that was a hardware work.
[00:48:14.400 --> 00:48:15.480]   Very strange. - That's right.
[00:48:15.480 --> 00:48:17.880]   Yeah, yeah, that's right, backwards.
[00:48:17.880 --> 00:48:19.400]   - So assembly languages,
[00:48:19.400 --> 00:48:22.280]   and let's call that the early 1950s.
[00:48:22.280 --> 00:48:24.280]   And so every different flavor of computer
[00:48:24.280 --> 00:48:25.800]   has its own assembly language.
[00:48:25.800 --> 00:48:28.880]   So the EdSac had its, and the Manchester had its,
[00:48:28.880 --> 00:48:33.880]   and the IBM, whatever, 7090 or 704 or whatever had its,
[00:48:33.880 --> 00:48:34.720]   and so on.
[00:48:34.720 --> 00:48:35.840]   So everybody had their own assembly language.
[00:48:35.840 --> 00:48:38.920]   - And assembly languages have a few commands, additions,
[00:48:38.920 --> 00:48:41.160]   subtraction, then branching of some kind,
[00:48:41.160 --> 00:48:42.920]   if then type of situation.
[00:48:42.920 --> 00:48:46.720]   - Right, they have exactly, in their simplest form at least,
[00:48:46.720 --> 00:48:50.040]   one assembly language instruction
[00:48:50.040 --> 00:48:52.840]   per instruction in the machine's repertoire.
[00:48:52.840 --> 00:48:54.960]   And so you have to know the machine intimately
[00:48:54.960 --> 00:48:56.720]   to be able to write programs in it.
[00:48:56.720 --> 00:48:58.680]   And if you write an assembly language program
[00:48:58.680 --> 00:49:00.360]   for one kind of machine, and then you say,
[00:49:00.360 --> 00:49:02.880]   "Gee, it's nice, I'd like it in a different machine,"
[00:49:02.880 --> 00:49:04.760]   start over, okay.
[00:49:04.760 --> 00:49:05.960]   So, very bad.
[00:49:05.960 --> 00:49:08.720]   And so what happened in the late '50s
[00:49:08.720 --> 00:49:11.000]   was people realized you could play this game again,
[00:49:11.000 --> 00:49:14.400]   and you could move up a level in writing
[00:49:14.400 --> 00:49:16.320]   or creating languages that were closer
[00:49:16.320 --> 00:49:18.400]   to the way that real people might think about
[00:49:18.400 --> 00:49:19.680]   how to write code.
[00:49:20.760 --> 00:49:24.080]   And there were, I guess, arguably three or four
[00:49:24.080 --> 00:49:25.560]   at that time period.
[00:49:25.560 --> 00:49:28.040]   There was Fortran, which came from IBM,
[00:49:28.040 --> 00:49:29.720]   which was formula translation,
[00:49:29.720 --> 00:49:31.640]   meant to make it easy to do scientific
[00:49:31.640 --> 00:49:32.840]   and engineering computations.
[00:49:32.840 --> 00:49:34.600]   - I didn't know that, formula translation, wow.
[00:49:34.600 --> 00:49:35.440]   - That's what it stood for.
[00:49:35.440 --> 00:49:37.840]   There was COBOL, which is the Common Business Oriented
[00:49:37.840 --> 00:49:40.680]   Language that Grace Hopper and others worked on,
[00:49:40.680 --> 00:49:44.240]   which was aimed at business kinds of tasks.
[00:49:44.240 --> 00:49:45.920]   There was ALGOL, which was mostly meant
[00:49:45.920 --> 00:49:49.360]   to describe algorithmic computations.
[00:49:49.360 --> 00:49:51.320]   I guess you could argue BASIC was in there somewhere.
[00:49:51.320 --> 00:49:52.960]   I think it's just a little later.
[00:49:52.960 --> 00:49:56.360]   And so all of those moved the level up.
[00:49:56.360 --> 00:49:59.880]   And so they were closer to what you and I might think of
[00:49:59.880 --> 00:50:02.560]   as we were trying to write a program.
[00:50:02.560 --> 00:50:05.880]   And they were focused on different domains,
[00:50:05.880 --> 00:50:09.120]   Fortran for formula translation, engineering computations,
[00:50:09.120 --> 00:50:11.720]   let's say COBOL for business, that kind of thing.
[00:50:11.720 --> 00:50:14.480]   - And still used today, at least Fortran probably.
[00:50:14.480 --> 00:50:16.760]   - Oh yeah, COBOL too.
[00:50:16.760 --> 00:50:19.440]   But the deal was that once you moved up that level,
[00:50:19.440 --> 00:50:21.960]   then you, let's call it Fortran, you had a language
[00:50:21.960 --> 00:50:25.280]   that was not tied to a particular kind of hardware
[00:50:25.280 --> 00:50:26.840]   because a different compiler would compile
[00:50:26.840 --> 00:50:27.920]   for a different kind of hardware.
[00:50:27.920 --> 00:50:30.000]   And that meant two things.
[00:50:30.000 --> 00:50:32.200]   It meant you only had to write the program once,
[00:50:32.200 --> 00:50:33.640]   which was very important.
[00:50:33.640 --> 00:50:35.920]   And it meant that you could, in fact,
[00:50:35.920 --> 00:50:38.440]   if you were a random engineer, physicist, whatever,
[00:50:38.440 --> 00:50:39.760]   you could write that program yourself.
[00:50:39.760 --> 00:50:42.680]   You didn't have to hire a programmer to do it for you.
[00:50:42.680 --> 00:50:44.520]   It might not be as good as you'd get with a real programmer,
[00:50:44.520 --> 00:50:45.840]   but it was pretty good.
[00:50:45.840 --> 00:50:49.720]   And so it democratized and made much more broadly available
[00:50:49.720 --> 00:50:51.520]   the ability to write code.
[00:50:51.520 --> 00:50:53.120]   - So it puts the power of programming
[00:50:53.120 --> 00:50:54.680]   into the hands of people like you.
[00:50:54.680 --> 00:50:57.720]   - Yeah, anybody who wants, who is willing to invest
[00:50:57.720 --> 00:50:59.440]   some time in learning a programming language
[00:50:59.440 --> 00:51:03.560]   and is not then tied to a particular kind of computer.
[00:51:03.560 --> 00:51:06.320]   And then in the '70s, you get system programming languages,
[00:51:06.320 --> 00:51:07.880]   of which C is the survivor.
[00:51:07.880 --> 00:51:11.840]   - What does system programming languages mean?
[00:51:11.840 --> 00:51:14.920]   - Programs that, programming languages
[00:51:14.920 --> 00:51:16.560]   that would take on the kinds of things
[00:51:16.560 --> 00:51:19.360]   that would necessary to write so-called system programs,
[00:51:19.360 --> 00:51:22.720]   things like text editors or assemblers or compilers
[00:51:22.720 --> 00:51:26.640]   or operating systems themselves, those kinds of things.
[00:51:26.640 --> 00:51:28.360]   And Fortran-
[00:51:28.360 --> 00:51:30.760]   - Feature rich, they have to be able to do a lot of stuff,
[00:51:30.760 --> 00:51:33.680]   a lot of memory management, access processes,
[00:51:33.680 --> 00:51:34.680]   all that kind of stuff.
[00:51:34.680 --> 00:51:35.640]   - They have to- - Level of processing.
[00:51:35.640 --> 00:51:37.200]   - It's a different flavor of what they're doing.
[00:51:37.200 --> 00:51:41.240]   They're much more in touch with the actual machine
[00:51:41.240 --> 00:51:42.360]   but in a positive way.
[00:51:42.360 --> 00:51:45.920]   That is, you can talk about memory in a more controlled way.
[00:51:45.920 --> 00:51:47.840]   You can talk about the different data types
[00:51:47.840 --> 00:51:50.720]   that the machine supports and the way they're,
[00:51:50.720 --> 00:51:54.840]   and more ways to structure and organize data.
[00:51:54.840 --> 00:51:57.360]   And so the system programming languages,
[00:51:57.360 --> 00:51:59.760]   there was a lot of effort in that in the,
[00:51:59.760 --> 00:52:02.160]   call it the late '60s, early '70s.
[00:52:02.160 --> 00:52:05.120]   C is, I think, the only real survivor of that.
[00:52:05.120 --> 00:52:08.080]   And then what happens after that,
[00:52:08.080 --> 00:52:12.120]   you get things like object-oriented programming languages
[00:52:12.120 --> 00:52:14.920]   because as you write programs in a language like C,
[00:52:14.920 --> 00:52:16.560]   at some point, scale gets to you
[00:52:16.560 --> 00:52:18.480]   and it's too hard to keep track of the pieces
[00:52:18.480 --> 00:52:21.080]   and there's no guardrails or training wheels
[00:52:21.080 --> 00:52:24.400]   or something like that to prevent you from doing bad things.
[00:52:24.400 --> 00:52:28.040]   So C++ comes out of that tradition.
[00:52:28.040 --> 00:52:29.600]   - And then it took off from there.
[00:52:29.600 --> 00:52:32.200]   I mean, there's also a parallel, slightly parallel track
[00:52:32.200 --> 00:52:33.760]   with a little bit of the functional stuff
[00:52:33.760 --> 00:52:35.160]   with Lisp and so on.
[00:52:35.160 --> 00:52:37.000]   But I guess from that point,
[00:52:37.000 --> 00:52:38.680]   it's just an explosion of languages.
[00:52:38.680 --> 00:52:41.880]   There's the Java story, there's the JavaScript,
[00:52:41.880 --> 00:52:44.960]   there's all the stuff that the cool kids these days
[00:52:44.960 --> 00:52:46.640]   are doing with Rust and all that.
[00:52:46.640 --> 00:52:51.040]   So what's to you, so you wrote a book,
[00:52:51.040 --> 00:52:53.120]   C programming language,
[00:52:53.120 --> 00:52:56.920]   and C is probably one of the most important languages
[00:52:56.920 --> 00:52:58.840]   in the history of programming languages
[00:52:58.840 --> 00:53:01.080]   if you kind of look at impact.
[00:53:01.080 --> 00:53:02.960]   What do you think is the most elegant
[00:53:02.960 --> 00:53:06.240]   or powerful part of C?
[00:53:06.240 --> 00:53:07.560]   Why did it survive?
[00:53:07.560 --> 00:53:10.340]   Why did it have such a long-lasting impact?
[00:53:11.320 --> 00:53:16.320]   - I think it found a sweet spot of expressiveness,
[00:53:16.320 --> 00:53:17.680]   that you could really write things
[00:53:17.680 --> 00:53:20.360]   in a pretty natural way, and efficiency,
[00:53:20.360 --> 00:53:22.200]   which was particularly important
[00:53:22.200 --> 00:53:24.360]   when computers were not nearly as powerful
[00:53:24.360 --> 00:53:25.200]   as they are today.
[00:53:25.200 --> 00:53:28.000]   You're gonna put yourself back 50 years,
[00:53:28.000 --> 00:53:31.240]   almost in terms of what computers could do,
[00:53:31.240 --> 00:53:35.040]   and that's roughly four or five generations,
[00:53:35.040 --> 00:53:36.640]   decades of Moore's law, right?
[00:53:37.520 --> 00:53:40.840]   So expressiveness and efficiency,
[00:53:40.840 --> 00:53:43.840]   and I don't know, perhaps the environment
[00:53:43.840 --> 00:53:46.360]   that it came with as well, which was Unix.
[00:53:46.360 --> 00:53:47.880]   So it meant if you wrote a program,
[00:53:47.880 --> 00:53:50.520]   it could be used on all those computers that ran Unix,
[00:53:50.520 --> 00:53:51.960]   and that was all of those computers
[00:53:51.960 --> 00:53:53.400]   because they were all written in C,
[00:53:53.400 --> 00:53:56.520]   and that way Unix, the operating system itself,
[00:53:56.520 --> 00:53:58.640]   was portable, as were all the tools.
[00:53:58.640 --> 00:54:00.680]   So it all worked together, again,
[00:54:00.680 --> 00:54:03.640]   in one of these things where things fed on each other
[00:54:03.640 --> 00:54:05.960]   in a positive cycle.
[00:54:05.960 --> 00:54:10.000]   - What did it take to write sort of a definitive book,
[00:54:10.000 --> 00:54:11.960]   probably definitive book on all of program,
[00:54:11.960 --> 00:54:14.480]   like it's more definitive to a particular language
[00:54:14.480 --> 00:54:16.640]   than any other book on any other language,
[00:54:16.640 --> 00:54:19.000]   and did two really powerful things,
[00:54:19.000 --> 00:54:22.720]   which is popularized the language,
[00:54:22.720 --> 00:54:24.880]   at least from my perspective, maybe you can correct me,
[00:54:24.880 --> 00:54:27.400]   and second is created a standard
[00:54:27.400 --> 00:54:33.280]   of how this language is supposed to be used and applied.
[00:54:33.640 --> 00:54:34.960]   So what did it take?
[00:54:34.960 --> 00:54:37.400]   Did you have those kinds of ambitions in mind
[00:54:37.400 --> 00:54:38.240]   when working on that?
[00:54:38.240 --> 00:54:39.600]   - Is this some kind of joke?
[00:54:39.600 --> 00:54:41.400]   (laughing)
[00:54:41.400 --> 00:54:42.840]   No, of course not.
[00:54:42.840 --> 00:54:47.840]   - So it's an accident of timing, skill, and just luck.
[00:54:47.840 --> 00:54:51.520]   - A lot of it is, clearly, timing was good.
[00:54:51.520 --> 00:54:54.000]   Now, Dennis and I wrote the book in 1977.
[00:54:54.000 --> 00:54:56.440]   - Dennis Ritchie. - Yeah, right.
[00:54:56.440 --> 00:54:58.920]   And at that point, Unix was starting to spread.
[00:54:58.920 --> 00:55:00.040]   I don't know how many there were,
[00:55:00.040 --> 00:55:03.320]   but it would be dozens to hundreds of Unix systems,
[00:55:03.320 --> 00:55:06.680]   and C was also available on other kinds of computers
[00:55:06.680 --> 00:55:08.320]   that had nothing to do with Unix,
[00:55:08.320 --> 00:55:11.440]   and so the language had some potential.
[00:55:11.440 --> 00:55:17.720]   And there were no other books on C,
[00:55:17.720 --> 00:55:20.360]   and Bell Labs was really the only source for it,
[00:55:20.360 --> 00:55:22.560]   and Dennis, of course, was authoritative
[00:55:22.560 --> 00:55:23.920]   because it was his language,
[00:55:23.920 --> 00:55:26.800]   and he had written the reference manual,
[00:55:26.800 --> 00:55:28.040]   which is a marvelous example
[00:55:28.040 --> 00:55:29.480]   of how to write a reference manual.
[00:55:29.480 --> 00:55:31.480]   Really, really very, very well done.
[00:55:31.480 --> 00:55:34.240]   So I twisted his arm until he agreed to write a book,
[00:55:34.240 --> 00:55:35.440]   and then we wrote a book.
[00:55:35.440 --> 00:55:38.560]   And the virtue, or advantage, at least,
[00:55:38.560 --> 00:55:40.840]   I guess, of going first is that then other people
[00:55:40.840 --> 00:55:43.280]   have to follow you if they're gonna do anything.
[00:55:43.280 --> 00:55:46.800]   And I think it worked well
[00:55:46.800 --> 00:55:50.400]   because Dennis was a superb writer.
[00:55:50.400 --> 00:55:51.600]   I mean, he really, really did,
[00:55:51.600 --> 00:55:55.080]   and the reference manual in that book is his, period.
[00:55:55.080 --> 00:55:57.280]   I had nothing to do with that at all.
[00:55:58.760 --> 00:56:02.720]   So just crystal clear prose, very, very well expressed.
[00:56:02.720 --> 00:56:03.880]   And then he and I,
[00:56:03.880 --> 00:56:07.720]   I wrote most of the expository material,
[00:56:07.720 --> 00:56:09.760]   and then he and I sort of did the usual
[00:56:09.760 --> 00:56:13.400]   ping-ponging back and forth, refining it.
[00:56:13.400 --> 00:56:15.600]   But I spent a lot of time trying to find examples
[00:56:15.600 --> 00:56:16.840]   that would sort of hang together
[00:56:16.840 --> 00:56:18.960]   and that would tell people what they might need to know
[00:56:18.960 --> 00:56:20.160]   at about the right time,
[00:56:20.160 --> 00:56:22.460]   that they should be thinking about needing it.
[00:56:22.460 --> 00:56:25.560]   And I'm not sure it completely succeeded,
[00:56:25.560 --> 00:56:28.520]   but it mostly worked out fairly well.
[00:56:28.520 --> 00:56:30.160]   - What do you think is the power of example?
[00:56:30.160 --> 00:56:34.280]   I mean, you're the creator,
[00:56:34.280 --> 00:56:36.000]   at least one of the first people
[00:56:36.000 --> 00:56:38.360]   to do the Hello World program,
[00:56:38.360 --> 00:56:40.440]   which is like the example.
[00:56:40.440 --> 00:56:43.080]   If aliens discover our civilization
[00:56:43.080 --> 00:56:44.200]   hundreds of years from now,
[00:56:44.200 --> 00:56:46.840]   it'll probably be Hello World programs,
[00:56:46.840 --> 00:56:48.600]   just like a half-broken robot
[00:56:48.600 --> 00:56:50.800]   communicating with them with a Hello World.
[00:56:50.800 --> 00:56:53.440]   So what, and that's a representative example,
[00:56:53.440 --> 00:56:57.080]   so what do you find powerful about examples?
[00:56:57.080 --> 00:57:01.560]   - I think a good example will tell you how to do something
[00:57:01.560 --> 00:57:03.880]   and it will be representative of,
[00:57:03.880 --> 00:57:05.720]   you might not wanna do exactly that,
[00:57:05.720 --> 00:57:06.960]   but you will wanna do something
[00:57:06.960 --> 00:57:09.740]   that's at least in that same general vein.
[00:57:09.740 --> 00:57:13.400]   And so a lot of the examples in the C book
[00:57:13.400 --> 00:57:15.720]   were picked for these very, very simple,
[00:57:15.720 --> 00:57:17.700]   straightforward text processing problems
[00:57:17.700 --> 00:57:19.760]   that were typical of Unix.
[00:57:19.760 --> 00:57:23.600]   I want to read input and write it out again.
[00:57:23.600 --> 00:57:24.600]   There's a copy command.
[00:57:24.600 --> 00:57:27.080]   I wanna read input and do something to it
[00:57:27.080 --> 00:57:28.000]   and write it out again.
[00:57:28.000 --> 00:57:28.840]   There's a grab.
[00:57:28.840 --> 00:57:31.360]   And so that kind of find things
[00:57:31.360 --> 00:57:35.000]   that are representative of what people want to do
[00:57:35.000 --> 00:57:39.400]   and spell those out so that they can then take those
[00:57:39.400 --> 00:57:44.400]   and see the core parts and modify them to their taste.
[00:57:44.400 --> 00:57:48.800]   And I think that a lot of programming books that,
[00:57:48.800 --> 00:57:51.160]   I don't look at programming books
[00:57:51.160 --> 00:57:52.320]   a tremendous amount these days,
[00:57:52.320 --> 00:57:54.480]   but when I do, a lot of them don't do that.
[00:57:54.480 --> 00:57:59.040]   They don't give you examples that are both realistic
[00:57:59.040 --> 00:58:01.880]   and something you might want to do.
[00:58:01.880 --> 00:58:03.800]   Some of them are pure syntax.
[00:58:03.800 --> 00:58:05.320]   Here's how you add three numbers.
[00:58:05.320 --> 00:58:07.300]   Well, come on, I could figure that out.
[00:58:07.300 --> 00:58:09.200]   Tell me how I would get those three numbers
[00:58:09.200 --> 00:58:11.920]   into the computer and how we would do something useful
[00:58:11.920 --> 00:58:14.320]   with them and then how I put them back out again,
[00:58:14.320 --> 00:58:15.560]   neatly formatted.
[00:58:15.560 --> 00:58:17.180]   - And especially if you follow that example,
[00:58:17.180 --> 00:58:19.440]   there is something magical of doing something
[00:58:19.440 --> 00:58:21.020]   that feels useful.
[00:58:21.020 --> 00:58:21.860]   - Yeah, right.
[00:58:21.860 --> 00:58:23.560]   And I think it's the attempt,
[00:58:23.560 --> 00:58:25.560]   and it's absolutely not perfect,
[00:58:25.560 --> 00:58:28.800]   but the attempt in all cases was to get something
[00:58:28.800 --> 00:58:31.560]   that was going to be either directly useful
[00:58:31.560 --> 00:58:35.600]   or would be very representative of useful things
[00:58:35.600 --> 00:58:37.960]   that a programmer might want to do.
[00:58:37.960 --> 00:58:41.120]   But within that vein of fundamentally text processing,
[00:58:41.120 --> 00:58:43.680]   reading text, doing something, writing text.
[00:58:43.680 --> 00:58:47.420]   - So you've also written a book on Go language.
[00:58:47.420 --> 00:58:50.960]   I have to admit, so I worked at Google for a while
[00:58:50.960 --> 00:58:53.000]   and I've never used Go.
[00:58:53.640 --> 00:58:54.680]   - Well, you missed something.
[00:58:54.680 --> 00:58:56.760]   - Well, I know I missed something for sure.
[00:58:56.760 --> 00:59:01.660]   So Go and Rust are two languages that I hear very,
[00:59:01.660 --> 00:59:05.840]   spoken very highly of and I wish I would like to,
[00:59:05.840 --> 00:59:06.840]   well, there's a lot of them.
[00:59:06.840 --> 00:59:10.760]   There's Julia, there's all these incredible modern languages
[00:59:10.760 --> 00:59:12.680]   but if you can comment before,
[00:59:12.680 --> 00:59:16.280]   or maybe comment on what do you find,
[00:59:16.280 --> 00:59:19.640]   where does Go sit in this broad spectrum of languages?
[00:59:19.640 --> 00:59:23.960]   And also how do you yourself feel about this wide range
[00:59:23.960 --> 00:59:26.480]   of powerful, interesting languages
[00:59:26.480 --> 00:59:30.480]   that you may never even get to try to explore
[00:59:30.480 --> 00:59:31.520]   because of time?
[00:59:31.520 --> 00:59:36.520]   - So I think, so Go first comes from that same
[00:59:36.520 --> 00:59:39.240]   Bell Labs tradition in part, not exclusively,
[00:59:39.240 --> 00:59:42.480]   but two of the three creators, Ken Thompson and Rob Pike.
[00:59:42.480 --> 00:59:44.000]   - So literally the people.
[00:59:44.000 --> 00:59:45.560]   - Yeah, the people.
[00:59:45.560 --> 00:59:49.040]   And then with this very, very useful influence
[00:59:49.040 --> 00:59:51.840]   from the European school in particular,
[00:59:51.840 --> 00:59:55.560]   the Klaus Spirth influence through Robert Griesemer
[00:59:55.560 --> 01:00:00.560]   who was, I guess, a second generation down student at ETH.
[01:00:00.560 --> 01:00:03.200]   And so that's an interesting combination of things.
[01:00:03.200 --> 01:00:08.200]   And so some ways Go captures the good parts of C,
[01:00:08.200 --> 01:00:11.040]   it looks sort of like C, it's sometimes characterized
[01:00:11.040 --> 01:00:12.940]   as C for the 21st century.
[01:00:12.940 --> 01:00:17.540]   On the surface, it looks very, very much like C.
[01:00:17.540 --> 01:00:20.000]   But at the same time, it has some interesting
[01:00:20.000 --> 01:00:21.840]   data structuring capabilities.
[01:00:21.840 --> 01:00:25.200]   And then I think the part that I would say
[01:00:25.200 --> 01:00:29.640]   is particularly useful, and again, I'm not a Go expert.
[01:00:29.640 --> 01:00:31.800]   In spite of co-authoring the book,
[01:00:31.800 --> 01:00:34.840]   about 90% of the work was done by Alan Donovan,
[01:00:34.840 --> 01:00:36.860]   my co-author who is a Go expert.
[01:00:36.860 --> 01:00:42.440]   But Go provides a very nice model of concurrency.
[01:00:42.440 --> 01:00:44.780]   It's basically the cooperating,
[01:00:44.780 --> 01:00:47.400]   communicating sequential processes that Tony Hoare
[01:00:47.400 --> 01:00:51.340]   set forth, geez, I don't know, 40 plus years ago.
[01:00:51.340 --> 01:00:56.000]   And Go routines are, to my mind, a very natural way
[01:00:56.000 --> 01:00:59.400]   to talk about parallel computation.
[01:00:59.400 --> 01:01:01.800]   And in the few experiments I've done with them,
[01:01:01.800 --> 01:01:04.800]   they're easy to write and typically it's gonna work
[01:01:04.800 --> 01:01:07.240]   and very efficient as well.
[01:01:07.240 --> 01:01:09.960]   So I think that's one place where Go stands out,
[01:01:09.960 --> 01:01:13.080]   that that model of parallel computation
[01:01:13.080 --> 01:01:16.140]   is very, very easy and nice to work with.
[01:01:16.140 --> 01:01:19.500]   - Just to comment on that, do you think C foresaw,
[01:01:19.500 --> 01:01:22.740]   or the early Unix days foresaw threads
[01:01:22.740 --> 01:01:26.060]   and massively parallel computation?
[01:01:26.060 --> 01:01:27.700]   - I would guess not really.
[01:01:27.700 --> 01:01:30.440]   I mean, maybe it was seen, but not at the level
[01:01:30.440 --> 01:01:33.380]   where it was something you had to do anything about.
[01:01:33.380 --> 01:01:38.180]   For a long time, processors got faster.
[01:01:38.180 --> 01:01:41.340]   And then processors stopped getting faster
[01:01:41.340 --> 01:01:43.880]   because of things like power consumption
[01:01:43.880 --> 01:01:46.200]   and heat generation.
[01:01:46.200 --> 01:01:49.160]   And so what happened instead was that instead
[01:01:49.160 --> 01:01:50.520]   of processors getting faster,
[01:01:50.520 --> 01:01:52.600]   there started to be more of them.
[01:01:52.600 --> 01:01:55.680]   And that's where that parallel thread stuff comes in.
[01:01:55.680 --> 01:02:01.040]   - So if you can comment on all the other languages,
[01:02:01.040 --> 01:02:03.040]   does it break your heart that you'll never get
[01:02:03.040 --> 01:02:04.480]   to explore them?
[01:02:04.480 --> 01:02:07.200]   How do you feel about the full variety?
[01:02:07.200 --> 01:02:10.080]   - It's not break my heart, but I would love
[01:02:10.080 --> 01:02:12.980]   to be able to try more of these languages.
[01:02:12.980 --> 01:02:14.880]   The closest I've come is in a class
[01:02:14.880 --> 01:02:17.020]   that I often teach in the spring here.
[01:02:17.020 --> 01:02:18.580]   It's a programming class.
[01:02:18.580 --> 01:02:23.580]   And I often give, I have one sort of small example
[01:02:23.580 --> 01:02:27.320]   that I will write in as many languages as I possibly can.
[01:02:27.320 --> 01:02:30.220]   I've got it in 20 odd languages at this point.
[01:02:30.220 --> 01:02:35.220]   And that's so I do a minimal experiment with a language,
[01:02:35.220 --> 01:02:37.340]   just to say, okay, I have this trivial task,
[01:02:37.340 --> 01:02:39.340]   which I understand the task, and it should,
[01:02:39.340 --> 01:02:42.800]   it takes 15 lines in awk and not much more
[01:02:42.800 --> 01:02:44.400]   in a variety of other languages.
[01:02:44.400 --> 01:02:45.360]   So how big is it?
[01:02:45.360 --> 01:02:46.420]   How fast does it run?
[01:02:46.420 --> 01:02:49.880]   And what pain did I go through to learn how to do it?
[01:02:49.880 --> 01:02:55.440]   And that's like anic data, right?
[01:02:55.440 --> 01:02:58.180]   It's very, very, very narrowly focused.
[01:02:58.180 --> 01:02:59.420]   - Anic data, I like that term.
[01:02:59.420 --> 01:03:01.920]   So yeah, but still, it's a little sample
[01:03:01.920 --> 01:03:04.000]   'cause you get the, I think the hardest step
[01:03:04.000 --> 01:03:06.340]   of the programming language is probably the first step.
[01:03:06.340 --> 01:03:08.760]   Right, so there you're taking the first step.
[01:03:08.760 --> 01:03:13.400]   - Yeah, and so my experience with some languages
[01:03:13.400 --> 01:03:14.880]   is very positive, like Lua,
[01:03:14.880 --> 01:03:17.540]   a scripting language I had never used.
[01:03:17.540 --> 01:03:19.740]   And I took my little program.
[01:03:19.740 --> 01:03:21.660]   The program is a trivial formatter.
[01:03:21.660 --> 01:03:24.620]   It just takes in lines of text of varying lengths,
[01:03:24.620 --> 01:03:26.460]   and it puts them out in lines
[01:03:26.460 --> 01:03:28.900]   that have no more than 60 characters on each line.
[01:03:28.900 --> 01:03:31.900]   So think of it as just kind of the flow of process
[01:03:31.900 --> 01:03:34.460]   in a browser or something.
[01:03:34.460 --> 01:03:36.240]   So it's a very short program.
[01:03:36.240 --> 01:03:39.300]   And in Lua, I downloaded Lua,
[01:03:39.300 --> 01:03:41.020]   and in an hour I had it working,
[01:03:41.020 --> 01:03:43.140]   never having written Lua in my life,
[01:03:43.140 --> 01:03:44.900]   just going with online documentation.
[01:03:44.900 --> 01:03:46.140]   I did the same thing in Scala,
[01:03:46.140 --> 01:03:48.900]   which you can think of as a flavor of Java,
[01:03:48.900 --> 01:03:50.060]   equally trivial.
[01:03:50.060 --> 01:03:52.100]   I did it in Haskell.
[01:03:52.100 --> 01:03:53.560]   It took me several weeks.
[01:03:53.560 --> 01:03:57.820]   But it did run like a turtle.
[01:03:57.820 --> 01:04:03.900]   And I did it in Fortran 90,
[01:04:03.900 --> 01:04:06.100]   and it was painful, but it worked.
[01:04:06.100 --> 01:04:07.980]   And I tried it in Rust,
[01:04:07.980 --> 01:04:10.200]   and it took me several days to get it working
[01:04:10.200 --> 01:04:12.140]   because the model of memory management
[01:04:12.140 --> 01:04:13.820]   was just a little unfamiliar to me.
[01:04:13.820 --> 01:04:15.940]   And the problem I had with Rust,
[01:04:15.940 --> 01:04:18.280]   and it's back to what we were just talking about,
[01:04:18.280 --> 01:04:21.520]   I couldn't find good, consistent documentation on Rust.
[01:04:21.520 --> 01:04:22.740]   Now, this was several years ago,
[01:04:22.740 --> 01:04:24.180]   and I'm sure things have stabilized,
[01:04:24.180 --> 01:04:26.500]   but at the time, everything in the Rust world
[01:04:26.500 --> 01:04:27.900]   seemed to be changing rapidly.
[01:04:27.900 --> 01:04:30.500]   And so you would find what looked like a working example,
[01:04:30.500 --> 01:04:32.220]   and it wouldn't work with the version
[01:04:32.220 --> 01:04:33.720]   of the language that I had.
[01:04:34.820 --> 01:04:37.540]   So it took longer than it should have.
[01:04:37.540 --> 01:04:39.620]   Rust is a language I would like to get back to,
[01:04:39.620 --> 01:04:41.180]   but probably won't.
[01:04:41.180 --> 01:04:42.060]   I think one of the issues,
[01:04:42.060 --> 01:04:44.060]   you have to have something you want to do.
[01:04:44.060 --> 01:04:47.620]   If you don't have something that is the right combination,
[01:04:47.620 --> 01:04:48.700]   if I want to do it,
[01:04:48.700 --> 01:04:53.520]   and yet I have enough disposable time, whatever,
[01:04:53.520 --> 01:04:56.460]   to make it worth learning a new language at the same time,
[01:04:56.460 --> 01:04:58.140]   it's never gonna happen.
[01:04:58.140 --> 01:05:02.100]   - So what do you think about another language of JavaScript
[01:05:02.100 --> 01:05:06.860]   that's this, well, let me just sort of comment on this.
[01:05:06.860 --> 01:05:08.140]   When I was brought up,
[01:05:08.140 --> 01:05:09.780]   sort of JavaScript was seen as
[01:05:09.780 --> 01:05:15.580]   the probably like the ugliest language possible,
[01:05:15.580 --> 01:05:18.240]   and yet it's quite arguably, quite possibly,
[01:05:18.240 --> 01:05:20.020]   taking over not just the front end
[01:05:20.020 --> 01:05:21.620]   and the back end of the internet,
[01:05:21.620 --> 01:05:24.000]   but possibly in the future taking over everything,
[01:05:24.000 --> 01:05:27.100]   because they've now learned to make it very efficient.
[01:05:27.100 --> 01:05:27.940]   - Yeah.
[01:05:27.940 --> 01:05:29.700]   - And so what do you think about this?
[01:05:29.780 --> 01:05:32.180]   - Yeah, well, I think you've captured it in a lot of ways.
[01:05:32.180 --> 01:05:33.020]   When it first came out,
[01:05:33.020 --> 01:05:35.500]   JavaScript was deemed to be fairly irregular
[01:05:35.500 --> 01:05:36.540]   and an ugly language,
[01:05:36.540 --> 01:05:37.820]   and certainly in the academy,
[01:05:37.820 --> 01:05:39.300]   if you said you were working on JavaScript,
[01:05:39.300 --> 01:05:40.500]   people would ridicule you.
[01:05:40.500 --> 01:05:43.820]   It was just not fit for academics to work on.
[01:05:43.820 --> 01:05:45.500]   I think a lot of that has evolved.
[01:05:45.500 --> 01:05:47.580]   The language itself has evolved,
[01:05:47.580 --> 01:05:50.700]   and certainly the technology of compiling it
[01:05:50.700 --> 01:05:53.700]   is fantastically better than it was.
[01:05:53.700 --> 01:05:54.820]   And so in that sense,
[01:05:54.820 --> 01:05:58.860]   it's absolutely a viable solution on back ends,
[01:05:58.860 --> 01:06:00.260]   as well as the front ends.
[01:06:00.260 --> 01:06:03.480]   Used well, I think it's a pretty good language.
[01:06:03.480 --> 01:06:06.340]   I've written a modest amount of it,
[01:06:06.340 --> 01:06:09.140]   and I've played with JavaScript translators
[01:06:09.140 --> 01:06:10.300]   and things like that.
[01:06:10.300 --> 01:06:12.000]   I'm not a real expert,
[01:06:12.000 --> 01:06:13.660]   and it's hard to keep up even there
[01:06:13.660 --> 01:06:15.860]   with the new things that come along with it.
[01:06:15.860 --> 01:06:21.160]   So I don't know whether it will ever take over the world.
[01:06:21.160 --> 01:06:22.580]   I think not,
[01:06:22.580 --> 01:06:26.620]   but it's certainly an important language
[01:06:26.620 --> 01:06:29.060]   and worth knowing more about.
[01:06:29.060 --> 01:06:32.420]   - Maybe to get your comment on something,
[01:06:32.420 --> 01:06:35.340]   which JavaScript, and actually most languages,
[01:06:35.340 --> 01:06:36.780]   sort of Python,
[01:06:36.780 --> 01:06:40.140]   such a big part of the experience of programming
[01:06:40.140 --> 01:06:42.700]   with those languages includes libraries.
[01:06:42.700 --> 01:06:44.540]   So using, building on top of the code
[01:06:44.540 --> 01:06:46.060]   that other people have built.
[01:06:46.060 --> 01:06:48.060]   I think that's probably different from the experience
[01:06:48.060 --> 01:06:51.900]   that we just talked about from Unix and C days
[01:06:51.900 --> 01:06:53.260]   when you're building stuff from scratch.
[01:06:53.260 --> 01:06:55.220]   What do you think about this world
[01:06:55.220 --> 01:06:56.660]   of essentially leveraging,
[01:06:56.660 --> 01:06:58.460]   building up libraries on top of each other
[01:06:58.460 --> 01:06:59.460]   and leveraging them?
[01:06:59.460 --> 01:07:02.860]   - Yeah, that's a very perceptive kind of question.
[01:07:02.860 --> 01:07:06.260]   One of the reasons programming was fun in the old days
[01:07:06.260 --> 01:07:09.020]   was that you were really building it all yourself.
[01:07:09.020 --> 01:07:10.980]   The number of libraries you had to deal with
[01:07:10.980 --> 01:07:11.820]   was quite small.
[01:07:11.820 --> 01:07:14.060]   Maybe it was printf or the standard library
[01:07:14.060 --> 01:07:16.020]   or something like that.
[01:07:16.020 --> 01:07:17.900]   And that is not the case today.
[01:07:17.900 --> 01:07:20.220]   And if you want to do something in,
[01:07:20.220 --> 01:07:22.660]   you mentioned Python and JavaScript,
[01:07:22.660 --> 01:07:24.440]   and those are the two fine examples
[01:07:24.440 --> 01:07:27.980]   you have to typically download a boatload of other stuff
[01:07:27.980 --> 01:07:29.820]   and you have no idea what you're getting.
[01:07:29.820 --> 01:07:31.380]   Absolutely nothing.
[01:07:31.380 --> 01:07:33.660]   I've been doing some playing with machine learning
[01:07:33.660 --> 01:07:37.700]   over the last couple of days and gee,
[01:07:37.700 --> 01:07:38.620]   something doesn't work.
[01:07:38.620 --> 01:07:40.940]   Well, you pip install this, okay?
[01:07:40.940 --> 01:07:44.460]   And down comes another gazillion megabytes of something
[01:07:44.460 --> 01:07:46.420]   and you have no idea what it was.
[01:07:46.420 --> 01:07:48.060]   And if you're lucky it works.
[01:07:48.060 --> 01:07:51.300]   And if it doesn't work, you have no recourse.
[01:07:51.300 --> 01:07:52.880]   There's absolutely no way you could figure out
[01:07:52.880 --> 01:07:55.220]   which in these thousand different packages.
[01:07:55.220 --> 01:07:59.660]   And I think it's worse in the NPM environment
[01:07:59.660 --> 01:08:00.500]   for JavaScript.
[01:08:00.500 --> 01:08:03.100]   I think there's less discipline, less control there.
[01:08:03.100 --> 01:08:06.220]   - And there's aspects of not just not understanding
[01:08:06.220 --> 01:08:08.020]   how it works, but there's security issues,
[01:08:08.020 --> 01:08:09.140]   there's robustness issues.
[01:08:09.140 --> 01:08:11.780]   So you don't want to run a nuclear power plant
[01:08:11.780 --> 01:08:14.100]   using JavaScript essentially.
[01:08:14.100 --> 01:08:14.940]   - Probably not.
[01:08:14.940 --> 01:08:18.860]   - So speaking to the variety of languages,
[01:08:18.860 --> 01:08:20.460]   do you think that variety is good?
[01:08:20.460 --> 01:08:23.580]   Or do you hope, think that over time
[01:08:23.580 --> 01:08:25.760]   we should converge towards one, two, three
[01:08:25.760 --> 01:08:27.440]   programming languages?
[01:08:27.440 --> 01:08:29.720]   That you mentioned to the Bell a lot of days
[01:08:29.720 --> 01:08:32.920]   when people could sort of, the community of it.
[01:08:32.920 --> 01:08:34.520]   And the more languages you have,
[01:08:34.520 --> 01:08:36.800]   the more you separate the communities.
[01:08:36.800 --> 01:08:40.300]   There's the Ruby community, there's the Python community,
[01:08:40.300 --> 01:08:42.700]   there's C++ community.
[01:08:42.700 --> 01:08:45.460]   Do you hope that they'll unite one day
[01:08:45.460 --> 01:08:47.720]   to just one or two languages?
[01:08:47.720 --> 01:08:48.840]   - I certainly don't hope it.
[01:08:48.840 --> 01:08:50.000]   I'm not sure that that's right
[01:08:50.000 --> 01:08:51.960]   'cause I honestly don't think there is one language
[01:08:51.960 --> 01:08:54.240]   that will suffice for all the programming needs
[01:08:54.240 --> 01:08:55.360]   of the world.
[01:08:55.360 --> 01:08:56.880]   Are there too many at this point?
[01:08:56.880 --> 01:09:00.000]   Well, arguably, but I think if you look at the,
[01:09:00.000 --> 01:09:03.160]   that sort of the distribution of how they are used,
[01:09:03.160 --> 01:09:06.780]   there's something called a dozen languages
[01:09:06.780 --> 01:09:10.520]   that probably account for 95% of all programming
[01:09:10.520 --> 01:09:11.360]   at this point.
[01:09:11.360 --> 01:09:13.600]   And that doesn't seem unreasonable.
[01:09:13.600 --> 01:09:17.240]   And then there's another, well, 2000 languages
[01:09:17.240 --> 01:09:19.960]   that are still in use that nobody uses.
[01:09:19.960 --> 01:09:23.320]   And, or at least don't use in any quantity.
[01:09:23.320 --> 01:09:25.920]   But I think new languages are a good idea in many respects
[01:09:25.920 --> 01:09:30.240]   'cause they're often a chance to explore an idea
[01:09:30.240 --> 01:09:32.920]   of how a language might help.
[01:09:32.920 --> 01:09:35.240]   I think that's one of the positive things
[01:09:35.240 --> 01:09:36.480]   about functional languages.
[01:09:36.480 --> 01:09:38.660]   For example, they're a particularly good place
[01:09:38.660 --> 01:09:42.480]   where people have explored ideas
[01:09:42.480 --> 01:09:45.720]   that at the time didn't seem feasible,
[01:09:45.720 --> 01:09:47.480]   but ultimately have wound up
[01:09:47.480 --> 01:09:50.160]   as part of mainstream languages as well.
[01:09:50.160 --> 01:09:52.720]   I mean, you just go back as early as recursion Lisp
[01:09:52.720 --> 01:09:54.960]   and then follow forward.
[01:09:54.960 --> 01:09:57.120]   Functions as first-class citizens
[01:09:57.120 --> 01:10:01.480]   and pattern-based languages, and gee, I don't know,
[01:10:01.480 --> 01:10:04.200]   closures and just on and on and on.
[01:10:04.200 --> 01:10:07.000]   Lambda's interesting ideas that showed up first
[01:10:07.000 --> 01:10:08.840]   in let's call it broadly
[01:10:08.840 --> 01:10:10.680]   the functional programming community
[01:10:10.680 --> 01:10:13.320]   and then find their way into mainstream languages.
[01:10:13.320 --> 01:10:15.600]   - Yeah, it's a playground for rebels.
[01:10:15.600 --> 01:10:16.440]   - Yeah, exactly.
[01:10:16.440 --> 01:10:18.000]   (Lex laughing)
[01:10:18.000 --> 01:10:21.240]   And so I think the languages in the playground themselves
[01:10:21.240 --> 01:10:24.840]   are probably not going to be the mainstream,
[01:10:24.840 --> 01:10:25.880]   at least for some while,
[01:10:25.880 --> 01:10:28.540]   but the ideas that come from there are invaluable.
[01:10:28.540 --> 01:10:33.880]   - So let's go to something that when I found out recently,
[01:10:33.880 --> 01:10:36.240]   so I've known that you've done a million things,
[01:10:36.240 --> 01:10:37.720]   but one of the things I wasn't aware of
[01:10:37.720 --> 01:10:39.680]   that you had a role in AMPL,
[01:10:39.680 --> 01:10:43.640]   and before you interrupt me by minimizing your role in it.
[01:10:44.880 --> 01:10:46.520]   - AMPL is for minimizing functions.
[01:10:46.520 --> 01:10:48.720]   - Yeah, minimizing functions, right, exactly.
[01:10:48.720 --> 01:10:52.360]   Can I just say that the elegance
[01:10:52.360 --> 01:10:57.360]   and abstraction power of AMPL is incredible?
[01:10:57.360 --> 01:11:01.360]   When I first came to it about 10 years ago or so,
[01:11:01.360 --> 01:11:04.280]   can you describe what is the AMPL language?
[01:11:04.280 --> 01:11:08.200]   - Sure, so AMPL is a language for mathematical programming,
[01:11:08.200 --> 01:11:10.760]   technical term, think of it as linear programming,
[01:11:10.760 --> 01:11:14.720]   that is setting up systems of linear equations
[01:11:14.720 --> 01:11:18.800]   that are of some sort of system of constraints,
[01:11:18.800 --> 01:11:20.600]   so that you have a bunch of things
[01:11:20.600 --> 01:11:22.600]   that have to be less than this, greater than that,
[01:11:22.600 --> 01:11:25.640]   or whatever, and you're trying to find a set of values
[01:11:25.640 --> 01:11:29.600]   for some decision variables that will maximize
[01:11:29.600 --> 01:11:32.200]   or minimize some objective function.
[01:11:32.200 --> 01:11:35.880]   So it's a way of solving a particular kind
[01:11:35.880 --> 01:11:38.000]   of optimization problem,
[01:11:38.000 --> 01:11:40.040]   a very formal sort of optimization problem,
[01:11:40.040 --> 01:11:42.560]   but one that's exceptionally useful.
[01:11:42.560 --> 01:11:45.240]   - And it specifies, so there's objective function
[01:11:45.240 --> 01:11:48.160]   constraints and variables that become separate
[01:11:48.160 --> 01:11:50.080]   from the data it operates on.
[01:11:50.080 --> 01:11:50.920]   - Right.
[01:11:50.920 --> 01:11:54.040]   - So that kind of separation allows you
[01:11:54.040 --> 01:11:58.000]   to put on different hats.
[01:11:58.000 --> 01:12:00.360]   One put the hat of an optimization person
[01:12:00.360 --> 01:12:03.280]   and then put another hat of a data person
[01:12:03.280 --> 01:12:04.360]   and dance back and forth,
[01:12:04.360 --> 01:12:08.800]   and also separate the actual solvers,
[01:12:08.800 --> 01:12:12.000]   the optimization systems that do the solving.
[01:12:12.000 --> 01:12:14.240]   Then you can have other people come to the table
[01:12:14.240 --> 01:12:15.480]   and then build their solvers,
[01:12:15.480 --> 01:12:17.400]   whether it's linear or non-linear,
[01:12:17.400 --> 01:12:21.800]   convex, non-convex, that kind of stuff.
[01:12:21.800 --> 01:12:26.800]   So what is the, to you as,
[01:12:26.800 --> 01:12:30.160]   maybe you can comment how you got into that world
[01:12:30.160 --> 01:12:33.480]   and what is the beautiful or interesting idea
[01:12:33.480 --> 01:12:35.400]   to you from the world of optimization?
[01:12:35.400 --> 01:12:36.240]   - Sure.
[01:12:36.240 --> 01:12:39.800]   So I preface it by saying I'm absolutely not an expert
[01:12:39.800 --> 01:12:42.960]   on this and most of the important work in AMPL
[01:12:42.960 --> 01:12:45.360]   comes from my two partners in crime on that,
[01:12:45.360 --> 01:12:48.440]   Bob Forer, who was a professor of,
[01:12:48.440 --> 01:12:50.560]   and in the industrial engineering and management
[01:12:50.560 --> 01:12:52.480]   science department at Northwestern,
[01:12:52.480 --> 01:12:54.800]   and my colleague at Bell Labs, Dave Gay,
[01:12:54.800 --> 01:12:59.000]   who was a numerical analyst and optimization person.
[01:12:59.000 --> 01:13:01.040]   So the deal is linear programming,
[01:13:01.040 --> 01:13:03.800]   preface this by saying.
[01:13:03.800 --> 01:13:05.120]   - Let's stay with linear programming.
[01:13:05.120 --> 01:13:07.600]   - Yeah, linear programming is the simplest example of this.
[01:13:07.600 --> 01:13:09.700]   So linear programming as it's taught in school
[01:13:09.700 --> 01:13:12.240]   is that you have a big matrix, which is always called A,
[01:13:12.240 --> 01:13:14.880]   and you say AX is less than or equal to B.
[01:13:14.880 --> 01:13:18.560]   So B is a set of constraints, X is the decision variables,
[01:13:18.560 --> 01:13:22.960]   and A is how the decision variables are combined
[01:13:22.960 --> 01:13:24.480]   to set up the various constraints.
[01:13:24.480 --> 01:13:28.160]   So A is a matrix and X and B are vectors.
[01:13:28.160 --> 01:13:30.000]   And then there's an objective function,
[01:13:30.000 --> 01:13:31.960]   which is just a sum of a bunch of Xs
[01:13:31.960 --> 01:13:33.560]   and some coefficients on them.
[01:13:33.560 --> 01:13:35.760]   And yet that's the thing you wanna optimize.
[01:13:37.140 --> 01:13:39.980]   The problem is that in the real world,
[01:13:39.980 --> 01:13:43.420]   that matrix A is a very, very, very intricate,
[01:13:43.420 --> 01:13:45.520]   very large and very sparse matrix
[01:13:45.520 --> 01:13:47.820]   where the various components of the model
[01:13:47.820 --> 01:13:50.540]   are distributed among the coefficients
[01:13:50.540 --> 01:13:53.820]   in a way that is totally unobvious to anybody.
[01:13:53.820 --> 01:13:58.860]   And so what you need is some way to express
[01:13:58.860 --> 01:14:01.060]   the original model, which you and I would write,
[01:14:01.060 --> 01:14:03.420]   you know, we'd write mathematics on the board,
[01:14:03.420 --> 01:14:04.980]   the sum of this is greater than the sum
[01:14:04.980 --> 01:14:06.420]   of that kind of thing.
[01:14:06.420 --> 01:14:10.260]   So you need a language to write those kinds of constraints.
[01:14:10.260 --> 01:14:13.160]   And Bob Forer for a long time had been interested
[01:14:13.160 --> 01:14:14.380]   in modeling languages,
[01:14:14.380 --> 01:14:16.500]   languages that made it possible to do this.
[01:14:16.500 --> 01:14:19.020]   There was a modeling language around called GAMS,
[01:14:19.020 --> 01:14:21.260]   the General Algebraic Modeling System,
[01:14:21.260 --> 01:14:24.660]   but it looked very much like Fortran, it was kind of clunky.
[01:14:24.660 --> 01:14:29.180]   And so Bob spent a sabbatical year at Bell Labs in 1984,
[01:14:29.180 --> 01:14:32.780]   and he and, he was in the office across from me,
[01:14:32.780 --> 01:14:35.380]   and it's always geography.
[01:14:35.380 --> 01:14:38.020]   And he and Dave Gay and I started talking
[01:14:38.020 --> 01:14:39.660]   about this kind of thing.
[01:14:39.660 --> 01:14:43.760]   And he wanted to design a language that would make it
[01:14:43.760 --> 01:14:46.480]   so that you could take these algebraic specifications,
[01:14:46.480 --> 01:14:48.780]   you know, summation, sines, oversets,
[01:14:48.780 --> 01:14:51.060]   and that you would write on the board
[01:14:51.060 --> 01:14:55.820]   and convert them into basically this A matrix,
[01:14:55.820 --> 01:14:58.880]   and then pass that off to a solver,
[01:14:58.880 --> 01:15:00.740]   which is an entirely separate thing.
[01:15:00.740 --> 01:15:05.140]   And so we talked about the design of the language.
[01:15:05.140 --> 01:15:07.180]   I don't remember any of the details of this now,
[01:15:07.180 --> 01:15:08.940]   but it's kind of an obvious thing.
[01:15:08.940 --> 01:15:11.220]   You're just writing mathematical expressions
[01:15:11.220 --> 01:15:13.140]   in a Fortran-like, or sorry,
[01:15:13.140 --> 01:15:15.820]   an algebraic but textual-like language.
[01:15:15.820 --> 01:15:21.860]   And I wrote the first version of this AMPL program,
[01:15:21.860 --> 01:15:24.260]   my first C++ program.
[01:15:24.260 --> 01:15:25.100]   (Lex laughs)
[01:15:25.100 --> 01:15:26.180]   And-
[01:15:26.180 --> 01:15:27.420]   - That's written in C++?
[01:15:27.420 --> 01:15:28.620]   - Yeah. - Oh, wow.
[01:15:28.620 --> 01:15:30.980]   - And so I did that fairly quickly.
[01:15:30.980 --> 01:15:33.460]   We wrote, it was, you know, 3,000 lines or something,
[01:15:33.460 --> 01:15:34.340]   so it wasn't very big,
[01:15:34.340 --> 01:15:36.520]   but it sort of showed the feasibility of it,
[01:15:36.520 --> 01:15:37.760]   that you could actually do something
[01:15:37.760 --> 01:15:41.740]   that was easy for people to specify models
[01:15:41.740 --> 01:15:44.700]   and convert it into something that a solver could work with.
[01:15:44.700 --> 01:15:45.860]   At the same time, as you say,
[01:15:45.860 --> 01:15:47.860]   the model and the data are separate things.
[01:15:47.860 --> 01:15:50.060]   So one model would then work
[01:15:50.060 --> 01:15:51.260]   with all kinds of different data
[01:15:51.260 --> 01:15:53.500]   in the same way that lots of programs do the same thing,
[01:15:53.500 --> 01:15:54.420]   but with different data.
[01:15:54.420 --> 01:15:55.660]   - So one of the really nice things
[01:15:55.660 --> 01:15:58.460]   is the specification of the models,
[01:15:58.460 --> 01:16:00.700]   human, just kind of like, as you say,
[01:16:00.700 --> 01:16:01.980]   it's human-readable.
[01:16:01.980 --> 01:16:04.900]   Like I literally, I remember on stuff I worked,
[01:16:04.900 --> 01:16:07.620]   I would send it to colleagues
[01:16:07.620 --> 01:16:10.780]   that I'm pretty sure never programmed in their life,
[01:16:10.780 --> 01:16:15.780]   just to understand what the optimization problem is.
[01:16:15.780 --> 01:16:18.060]   I think, how hard is it to convert that?
[01:16:18.060 --> 01:16:20.300]   You said there's a first prototype in C++,
[01:16:20.300 --> 01:16:22.060]   to convert that into something
[01:16:22.060 --> 01:16:24.300]   that could actually be used by the solver.
[01:16:24.300 --> 01:16:26.300]   - It's not too bad, because most of the solvers
[01:16:26.300 --> 01:16:30.460]   have some mechanism that lets them import a model in a form.
[01:16:30.460 --> 01:16:32.980]   It might be as simple as the matrix itself
[01:16:32.980 --> 01:16:35.020]   in just some representation,
[01:16:35.020 --> 01:16:38.420]   or if you're doing things that are not linear programming,
[01:16:38.420 --> 01:16:39.820]   then there may be some mechanism
[01:16:39.820 --> 01:16:43.420]   that lets you provide things like functions to be called,
[01:16:43.420 --> 01:16:47.140]   or other constraints on the model.
[01:16:47.140 --> 01:16:51.500]   So all Ample does is to generate that kind of thing,
[01:16:51.500 --> 01:16:54.220]   and then solver deals with all the hard work.
[01:16:54.220 --> 01:16:57.380]   And then when the solver comes back with numbers,
[01:16:57.380 --> 01:17:00.220]   Ample converts those back into your original form.
[01:17:00.220 --> 01:17:03.180]   So you know how much of each thing you should be buying,
[01:17:03.180 --> 01:17:05.160]   or making, or shipping, or whatever.
[01:17:05.160 --> 01:17:08.620]   So we did that in '84,
[01:17:08.620 --> 01:17:11.900]   and I haven't had a lot to do with it since,
[01:17:11.900 --> 01:17:14.300]   except that we wrote a couple of versions of a book on it.
[01:17:14.300 --> 01:17:16.560]   - Which is one of the greatest books ever written.
[01:17:16.560 --> 01:17:17.720]   I love that book.
[01:17:17.720 --> 01:17:20.020]   I don't know why.
[01:17:20.020 --> 01:17:21.020]   - It's an excellent book.
[01:17:21.020 --> 01:17:22.540]   Bob Forer wrote most of it.
[01:17:22.540 --> 01:17:24.020]   And so it's really, really well done.
[01:17:24.020 --> 01:17:25.700]   He must have been a dynamite teacher.
[01:17:25.700 --> 01:17:27.560]   - And typeset in LaTeX.
[01:17:27.560 --> 01:17:29.100]   - No, no, no, are you kidding?
[01:17:29.220 --> 01:17:30.340]   (laughing)
[01:17:30.340 --> 01:17:32.940]   I remember liking the typography, so I don't know.
[01:17:32.940 --> 01:17:34.500]   - We did it with T-Rof.
[01:17:34.500 --> 01:17:35.460]   - I don't even know what that is.
[01:17:35.460 --> 01:17:37.180]   - Yeah, exactly, you're too young.
[01:17:37.180 --> 01:17:38.380]   - Oh boy.
[01:17:38.380 --> 01:17:42.180]   - I think of T-Rof as a predecessor
[01:17:42.180 --> 01:17:44.260]   to the tech family of things.
[01:17:44.260 --> 01:17:46.180]   It's a formatter that was done at Bell Labs
[01:17:46.180 --> 01:17:48.860]   in this same period of the very early '70s
[01:17:48.860 --> 01:17:52.460]   that predates tech and things like that
[01:17:52.460 --> 01:17:54.940]   by five to 10 years.
[01:17:54.940 --> 01:17:58.220]   - But it was nevertheless, I'm going by memories.
[01:17:58.220 --> 01:18:00.060]   I remember it being beautiful.
[01:18:00.060 --> 01:18:01.780]   - Yeah, it was nicely done.
[01:18:01.780 --> 01:18:03.820]   - Outside of Unix, C, Ogg, Golang,
[01:18:03.820 --> 01:18:05.780]   all the things we talked about,
[01:18:05.780 --> 01:18:07.940]   all the amazing work you've done,
[01:18:07.940 --> 01:18:09.880]   you've also done work in graph theory.
[01:18:09.880 --> 01:18:16.480]   Let me ask this crazy out there question.
[01:18:16.480 --> 01:18:17.660]   If you had to make a bet,
[01:18:17.660 --> 01:18:19.180]   and I had to force you to make a bet,
[01:18:19.180 --> 01:18:20.900]   do you think P equals NP?
[01:18:20.900 --> 01:18:23.500]   (laughing)
[01:18:23.500 --> 01:18:26.300]   - The answer is no, although I'm told that somebody asked
[01:18:26.300 --> 01:18:28.980]   Jeff Dean if that was, under what conditions
[01:18:28.980 --> 01:18:32.300]   P would equal NP, and he said either P is zero or N is one.
[01:18:32.300 --> 01:18:35.660]   Or vice versa, I've forgotten.
[01:18:35.660 --> 01:18:38.060]   This is why Jeff Dean is a lot smarter than I am.
[01:18:38.060 --> 01:18:38.900]   - Yeah.
[01:18:38.900 --> 01:18:41.660]   So, but your intuition is--
[01:18:41.660 --> 01:18:45.940]   - I have no intuition, but I've got a lot of colleagues
[01:18:45.940 --> 01:18:48.140]   who've got intuition, and their betting is no.
[01:18:48.140 --> 01:18:51.180]   - That's the popular bet.
[01:18:51.180 --> 01:18:55.620]   Okay, so what is computational complexity theory,
[01:18:55.620 --> 01:18:58.260]   and do you think these kinds of complexity classes,
[01:18:58.260 --> 01:19:01.540]   especially as you've taught in this modern world,
[01:19:01.540 --> 01:19:04.260]   are still a useful way to understand
[01:19:04.260 --> 01:19:06.060]   the hardness of problems?
[01:19:06.060 --> 01:19:07.420]   - I don't do that stuff.
[01:19:07.420 --> 01:19:09.420]   The last time I touched anything to do with that--
[01:19:09.420 --> 01:19:10.300]   - Many, many years ago.
[01:19:10.300 --> 01:19:12.420]   - Was before it was invented.
[01:19:12.420 --> 01:19:14.660]   'Cause I, it's literally true.
[01:19:14.660 --> 01:19:17.700]   I did my PhD thesis on graph--
[01:19:17.700 --> 01:19:18.900]   - Before big O notation.
[01:19:18.900 --> 01:19:23.900]   - Oh, absolutely, before, I did this in 1968,
[01:19:24.060 --> 01:19:25.980]   and I worked on graph partitioning,
[01:19:25.980 --> 01:19:27.820]   which is this question, you've got a graph
[01:19:27.820 --> 01:19:30.300]   that is a nodes and edges kind of graph,
[01:19:30.300 --> 01:19:31.660]   and the edges have weights,
[01:19:31.660 --> 01:19:34.460]   and you just wanna divide the nodes into two piles
[01:19:34.460 --> 01:19:36.820]   of equal size, so that the number of edges
[01:19:36.820 --> 01:19:38.060]   that goes from one side to the other
[01:19:38.060 --> 01:19:39.420]   is as small as possible.
[01:19:39.420 --> 01:19:41.580]   And we--
[01:19:41.580 --> 01:19:45.940]   - You developed, so that problem is hard?
[01:19:45.940 --> 01:19:48.420]   - Well, as it turns out, I worked with Shen Lin
[01:19:48.420 --> 01:19:52.140]   at Bell Labs on this, and we were never able to come up
[01:19:52.140 --> 01:19:54.220]   with anything that was guaranteed to give the right answer.
[01:19:54.220 --> 01:19:57.940]   We came up with heuristics that worked pretty darn well,
[01:19:57.940 --> 01:20:01.060]   and I peeled off some special cases for my thesis,
[01:20:01.060 --> 01:20:02.260]   but it was just hard.
[01:20:02.260 --> 01:20:04.700]   And that was just about the time that Steve Cook
[01:20:04.700 --> 01:20:06.500]   was showing that there were classes of problems
[01:20:06.500 --> 01:20:08.140]   that appeared to be really hard,
[01:20:08.140 --> 01:20:10.720]   of which graph partitioning was one.
[01:20:10.720 --> 01:20:13.780]   But this, my expertise, such as it was,
[01:20:13.780 --> 01:20:16.500]   totally predates that development.
[01:20:16.500 --> 01:20:18.100]   - Oh, interesting, so the heuristic,
[01:20:18.100 --> 01:20:21.980]   which now, it carries the two of yours names
[01:20:21.980 --> 01:20:23.740]   for the traveling salesman problem,
[01:20:23.740 --> 01:20:26.380]   and for the graph partitioning, that was,
[01:20:26.380 --> 01:20:28.300]   like, how did you, you weren't even thinking
[01:20:28.300 --> 01:20:29.980]   in terms of classes, you were just trying to find--
[01:20:29.980 --> 01:20:31.140]   - There was no such idea.
[01:20:31.140 --> 01:20:34.460]   - A heuristic that kinda does the job pretty well.
[01:20:34.460 --> 01:20:36.820]   - You were trying to find something that did the job,
[01:20:36.820 --> 01:20:38.700]   and there was nothing that you would call,
[01:20:38.700 --> 01:20:41.740]   let's say, a closed form or algorithmic thing
[01:20:41.740 --> 01:20:44.340]   that would give you a guaranteed right answer.
[01:20:44.340 --> 01:20:48.300]   I mean, compare graph partitioning to max flow min cut,
[01:20:48.300 --> 01:20:50.180]   or something like that.
[01:20:50.180 --> 01:20:52.860]   That's the same problem, except there's no constraint
[01:20:52.860 --> 01:20:56.260]   on the number of nodes on one side or the other of the cut.
[01:20:56.260 --> 01:20:58.700]   And that means it's an easy problem,
[01:20:58.700 --> 01:20:59.980]   at least as I understand it.
[01:20:59.980 --> 01:21:01.500]   Whereas the constraint that says
[01:21:01.500 --> 01:21:03.500]   the two have to be constrained in size
[01:21:03.500 --> 01:21:05.500]   makes it a hard problem.
[01:21:05.500 --> 01:21:07.580]   - Yeah, so Robert Frost has that poem
[01:21:07.580 --> 01:21:09.260]   where you have to choose two paths.
[01:21:09.260 --> 01:21:13.620]   So why did you, is there another alternate universe
[01:21:13.620 --> 01:21:16.600]   in which you pursued the Don Knuth path
[01:21:16.600 --> 01:21:19.860]   of algorithm design, sort of--
[01:21:19.860 --> 01:21:21.380]   - Not smart enough.
[01:21:21.380 --> 01:21:22.380]   - Not smart enough.
[01:21:22.380 --> 01:21:27.300]   You're infinitely modest,
[01:21:27.300 --> 01:21:30.280]   but so you pursued your kind of love of programming.
[01:21:30.280 --> 01:21:33.620]   I mean, when you look back to those,
[01:21:33.620 --> 01:21:35.300]   I mean, just looking into that world,
[01:21:35.300 --> 01:21:37.820]   does that just seem like a distant world
[01:21:37.820 --> 01:21:40.340]   of theoretical computer science?
[01:21:40.340 --> 01:21:42.060]   Then is it fundamentally different
[01:21:42.060 --> 01:21:44.580]   from the world of programming?
[01:21:44.580 --> 01:21:45.460]   - I don't know.
[01:21:45.460 --> 01:21:47.660]   I mean, certainly, in all seriousness,
[01:21:47.660 --> 01:21:49.460]   I just didn't have the talent for it.
[01:21:49.460 --> 01:21:51.860]   When I got here as a grad student at Princeton
[01:21:51.860 --> 01:21:53.540]   and I started to think about research
[01:21:53.540 --> 01:21:55.620]   at the end of my, I don't know, first year
[01:21:55.620 --> 01:21:56.480]   or something like that,
[01:21:56.480 --> 01:21:59.060]   I worked briefly with John Hopcroft,
[01:21:59.060 --> 01:22:00.940]   who is absolutely, you know,
[01:22:00.940 --> 01:22:02.620]   you mentioned during award winner, et cetera,
[01:22:02.620 --> 01:22:04.060]   a great guy.
[01:22:04.060 --> 01:22:05.460]   And it became crystal clear
[01:22:05.460 --> 01:22:08.260]   I was not cut out for this stuff, period.
[01:22:08.260 --> 01:22:09.260]   Okay.
[01:22:09.260 --> 01:22:11.540]   And so I moved into things
[01:22:11.540 --> 01:22:13.620]   where I was more cut out for it.
[01:22:13.620 --> 01:22:16.820]   And that tended to be things like writing programs
[01:22:16.820 --> 01:22:18.500]   and then ultimately writing books.
[01:22:19.500 --> 01:22:22.140]   - You've said that in Toronto,
[01:22:22.140 --> 01:22:24.260]   as an undergrad, you did a senior thesis
[01:22:24.260 --> 01:22:28.740]   or a literature survey on artificial intelligence.
[01:22:28.740 --> 01:22:30.540]   This was 1964.
[01:22:30.540 --> 01:22:32.220]   - Correct.
[01:22:32.220 --> 01:22:37.140]   - What was the AI landscape, ideas, dreams at that time?
[01:22:37.140 --> 01:22:39.100]   - I think that was one of the,
[01:22:39.100 --> 01:22:40.420]   well, you've heard of AI winters.
[01:22:40.420 --> 01:22:41.820]   This is whatever the opposite was,
[01:22:41.820 --> 01:22:43.700]   AI summer or something.
[01:22:43.700 --> 01:22:44.540]   It was one of these things
[01:22:44.540 --> 01:22:46.820]   where people thought that,
[01:22:46.820 --> 01:22:49.300]   boy, we could do anything with computers,
[01:22:49.300 --> 01:22:51.500]   that all these hard problems,
[01:22:51.500 --> 01:22:52.700]   computers will solve them.
[01:22:52.700 --> 01:22:54.420]   They will do machine translation.
[01:22:54.420 --> 01:22:57.860]   They will play games like chess.
[01:22:57.860 --> 01:23:00.780]   They will do, you know,
[01:23:00.780 --> 01:23:02.140]   prove theorems in geometry.
[01:23:02.140 --> 01:23:04.180]   There are all kinds of examples like that
[01:23:04.180 --> 01:23:05.700]   where people thought,
[01:23:05.700 --> 01:23:08.880]   boy, we could really do those sorts of things.
[01:23:08.880 --> 01:23:14.900]   And, you know, I read the Kool-Aid in some sense.
[01:23:14.900 --> 01:23:16.900]   There's a wonderful collection of papers
[01:23:16.900 --> 01:23:18.020]   called "Computers and Thought"
[01:23:18.020 --> 01:23:20.260]   that was published in about that era.
[01:23:20.260 --> 01:23:22.500]   And people were very optimistic.
[01:23:22.500 --> 01:23:24.220]   And then of course it turned out that
[01:23:24.220 --> 01:23:27.340]   what people had thought was just a few years down the pike
[01:23:27.340 --> 01:23:31.300]   was more than a few years down the pike.
[01:23:31.300 --> 01:23:34.580]   And some parts of that are more or less now
[01:23:34.580 --> 01:23:36.380]   sort of under control.
[01:23:36.380 --> 01:23:39.300]   We finally do play games like go and chess and so on
[01:23:39.300 --> 01:23:41.140]   better than people do,
[01:23:41.140 --> 01:23:42.500]   but there are others,
[01:23:42.500 --> 01:23:45.100]   and machine translation is a lot better than it used to be,
[01:23:45.100 --> 01:23:49.700]   but that's, you know, 50, close to 60 years of progress
[01:23:49.700 --> 01:23:51.340]   and a lot of evolution in hardware
[01:23:51.340 --> 01:23:52.820]   and a tremendous amount more data
[01:23:52.820 --> 01:23:56.580]   upon which you can build systems
[01:23:56.580 --> 01:23:58.940]   that actually can learn from some of that data.
[01:23:58.940 --> 01:24:02.600]   - And the infrastructure to support developers
[01:24:02.600 --> 01:24:05.660]   working together like an open source movement,
[01:24:05.660 --> 01:24:08.780]   the internet period is also an empowering.
[01:24:08.780 --> 01:24:11.740]   But what lessons do you draw from that,
[01:24:11.740 --> 01:24:13.780]   the opposite of winter, that optimism?
[01:24:13.780 --> 01:24:19.700]   - Well, I guess the lesson is that in the short run,
[01:24:19.700 --> 01:24:23.540]   it's pretty easy to be too pessimistic
[01:24:23.540 --> 01:24:24.700]   or maybe too optimistic,
[01:24:24.700 --> 01:24:27.180]   and in the long run, you probably shouldn't be too pessimistic.
[01:24:27.180 --> 01:24:28.620]   I'm not saying that very well.
[01:24:28.620 --> 01:24:32.740]   It reminds me of this remark from Arthur Clarke,
[01:24:32.740 --> 01:24:34.620]   a science fiction author, who says,
[01:24:34.620 --> 01:24:36.500]   "When some distinguished but elderly person
[01:24:36.500 --> 01:24:41.160]   "says that something is possible, he's probably right.
[01:24:41.160 --> 01:24:44.340]   "And if he says it's impossible, he's almost surely wrong."
[01:24:44.340 --> 01:24:45.780]   But you don't know what the timescale is.
[01:24:45.780 --> 01:24:48.380]   - The timescale is critical, right.
[01:24:48.380 --> 01:24:52.580]   So what are your thoughts on this new summer of AI
[01:24:52.580 --> 01:24:55.420]   now in the work with machine learning and neural networks?
[01:24:55.420 --> 01:24:57.900]   You've kind of mentioned that you started to try to explore
[01:24:57.900 --> 01:25:01.420]   and look into this world that seems fundamentally different
[01:25:01.420 --> 01:25:06.220]   from the world of heuristics and algorithms like search,
[01:25:06.220 --> 01:25:08.980]   that it's now purely sort of trying to take
[01:25:08.980 --> 01:25:12.480]   huge amounts of data and learn from that data, right?
[01:25:12.480 --> 01:25:14.040]   Programs from the data.
[01:25:14.040 --> 01:25:14.940]   - Yeah.
[01:25:14.940 --> 01:25:17.000]   Look, I think it's very interesting.
[01:25:17.000 --> 01:25:19.800]   I am incredibly far from an expert.
[01:25:19.800 --> 01:25:21.540]   Most of what I know I've learned from my students,
[01:25:21.540 --> 01:25:24.520]   and they're probably disappointed
[01:25:24.520 --> 01:25:26.360]   in how little I've learned from them.
[01:25:26.360 --> 01:25:29.200]   But I think it has tremendous potential
[01:25:29.200 --> 01:25:30.560]   for certain kinds of things.
[01:25:30.560 --> 01:25:34.640]   I mean, games is one where it obviously has had an effect
[01:25:34.640 --> 01:25:36.000]   on some of the others as well.
[01:25:36.000 --> 01:25:39.520]   I think there's, and this is speaking from
[01:25:39.520 --> 01:25:40.700]   definitely not expertise,
[01:25:40.700 --> 01:25:43.640]   I think there are serious problems in certain kinds
[01:25:43.640 --> 01:25:45.480]   of machine learning, at least,
[01:25:45.480 --> 01:25:47.500]   because what they're learning from
[01:25:47.500 --> 01:25:49.180]   is the data that we give them.
[01:25:49.180 --> 01:25:52.060]   And if the data we give them has something wrong with it,
[01:25:52.060 --> 01:25:54.900]   then what they learn from it is probably wrong too.
[01:25:54.900 --> 01:25:59.140]   And the obvious thing is some kind of bias in the data.
[01:25:59.140 --> 01:26:02.340]   That the data has stuff in it like, I don't know,
[01:26:02.340 --> 01:26:05.440]   women aren't as good as men at something, okay?
[01:26:05.440 --> 01:26:07.380]   That's just flat wrong.
[01:26:07.380 --> 01:26:11.480]   But if it's in the data because of historical treatment,
[01:26:11.480 --> 01:26:15.020]   then that machine learning stuff will propagate that.
[01:26:15.020 --> 01:26:17.740]   And that is a serious worry.
[01:26:17.740 --> 01:26:22.700]   - The positive part of that is what machine learning does
[01:26:22.700 --> 01:26:24.680]   is reveal the bias in the data
[01:26:24.680 --> 01:26:27.020]   and puts a mirror to our own society.
[01:26:27.020 --> 01:26:30.940]   And in so doing, helps us remove the bias,
[01:26:30.940 --> 01:26:33.860]   you know, helps us work on ourselves.
[01:26:33.860 --> 01:26:35.720]   - Puts a mirror to ourselves.
[01:26:35.720 --> 01:26:37.440]   - Yeah, that's an optimistic point of view.
[01:26:37.440 --> 01:26:40.000]   And if it works that way, that would be absolutely great.
[01:26:40.000 --> 01:26:42.560]   And what I don't know is whether it does work that way
[01:26:42.560 --> 01:26:46.440]   or whether the AI mechanisms
[01:26:46.440 --> 01:26:48.520]   or machine learning mechanisms reinforce
[01:26:48.520 --> 01:26:52.640]   and amplify things that have been wrong in the past.
[01:26:52.640 --> 01:26:56.000]   And I don't know, but I think that's a serious thing
[01:26:56.000 --> 01:26:58.740]   that we have to be concerned about.
[01:26:58.740 --> 01:27:01.200]   - Let me ask you an out there question, okay?
[01:27:01.200 --> 01:27:03.920]   I know nobody knows, but what do you think it takes
[01:27:03.920 --> 01:27:07.400]   to build a system of human level intelligence?
[01:27:07.400 --> 01:27:09.860]   That's been the dream from the '60s.
[01:27:09.860 --> 01:27:12.120]   We talk about games, about language,
[01:27:12.120 --> 01:27:15.140]   about image recognition,
[01:27:15.140 --> 01:27:18.220]   but really the dream is to create human level
[01:27:18.220 --> 01:27:19.600]   or superhuman level intelligence.
[01:27:19.600 --> 01:27:21.220]   What do you think it takes to do that?
[01:27:21.220 --> 01:27:23.060]   And are we close?
[01:27:23.060 --> 01:27:26.200]   - I haven't a clue and I don't know, roughly speaking.
[01:27:26.200 --> 01:27:27.040]   I mean, this was Turing--
[01:27:27.040 --> 01:27:30.020]   - I was trying to trick you into a hypothesis.
[01:27:30.020 --> 01:27:31.500]   - Yeah, I mean, Turing talked about this
[01:27:31.500 --> 01:27:34.660]   in his paper on machine intelligence back in,
[01:27:34.660 --> 01:27:36.780]   geez, I don't know, early '50s or something like that.
[01:27:36.780 --> 01:27:38.300]   And he had the idea of the Turing test.
[01:27:38.300 --> 01:27:40.940]   And I don't know whether the Turing test is--
[01:27:40.940 --> 01:27:41.780]   - Is a good test of intelligence.
[01:27:41.780 --> 01:27:43.500]   - I don't know, it's an interesting test.
[01:27:43.500 --> 01:27:45.780]   At least it's in some vague sense objective,
[01:27:45.780 --> 01:27:48.460]   whether you can read anything into the conclusions
[01:27:48.460 --> 01:27:50.420]   is a different story.
[01:27:50.420 --> 01:27:55.140]   - Do you have worries, concerns, excitement
[01:27:55.140 --> 01:27:56.960]   about the future of artificial intelligence?
[01:27:56.960 --> 01:27:58.900]   So there's a lot of people who are worried.
[01:27:58.900 --> 01:28:01.740]   And you can speak broadly than just artificial intelligence.
[01:28:01.740 --> 01:28:05.340]   It's basically computing taking over the world
[01:28:05.340 --> 01:28:06.740]   in various forms.
[01:28:06.740 --> 01:28:09.220]   Are you excited by this future,
[01:28:09.220 --> 01:28:12.320]   this possibility of computing being everywhere?
[01:28:12.320 --> 01:28:13.820]   Or are you worried?
[01:28:13.820 --> 01:28:16.420]   - It's some combination of those.
[01:28:16.420 --> 01:28:21.200]   I think almost all technologies over the long run
[01:28:21.200 --> 01:28:24.600]   are for good, but there's plenty of examples
[01:28:24.600 --> 01:28:26.260]   where they haven't been good,
[01:28:26.260 --> 01:28:28.660]   either over a long run for some people
[01:28:28.660 --> 01:28:30.540]   or over a short run.
[01:28:30.540 --> 01:28:33.220]   And computing is one of those.
[01:28:33.220 --> 01:28:36.820]   And AI within it is gonna be one of those as well.
[01:28:36.820 --> 01:28:38.180]   But computing broadly, I mean,
[01:28:38.180 --> 01:28:41.620]   for just a today example is privacy.
[01:28:41.620 --> 01:28:46.620]   That the use of things like social media and so on means that
[01:28:46.620 --> 01:28:49.820]   and the commercial surveillance means that
[01:28:49.820 --> 01:28:54.340]   there's an enormous amount more known about us by people,
[01:28:54.340 --> 01:28:56.940]   other businesses, government, whatever,
[01:28:56.940 --> 01:28:59.540]   than perhaps one ought to feel comfortable with.
[01:28:59.540 --> 01:29:01.080]   So that's an example.
[01:29:01.080 --> 01:29:07.620]   - So that's an example of a possible negative effect
[01:29:07.620 --> 01:29:09.700]   of computing being everywhere.
[01:29:09.700 --> 01:29:14.060]   It's an interesting one 'cause it could also be a positive
[01:29:14.060 --> 01:29:16.140]   if leveraged correctly.
[01:29:16.140 --> 01:29:18.140]   - There's a big if there.
[01:29:18.140 --> 01:29:22.980]   - So I have a deep interest in human psychology
[01:29:22.980 --> 01:29:26.460]   and humans seem to be very paranoid about this data thing.
[01:29:27.460 --> 01:29:31.380]   But that varies depending on age group.
[01:29:31.380 --> 01:29:32.900]   It seems like the younger folks,
[01:29:32.900 --> 01:29:35.940]   so it's exciting to me to see what society looks like
[01:29:35.940 --> 01:29:37.460]   50 years from now,
[01:29:37.460 --> 01:29:39.940]   that the concerns about privacy might be flipped
[01:29:39.940 --> 01:29:42.700]   on their head based purely on human psychology
[01:29:42.700 --> 01:29:45.620]   versus actual concerns or not.
[01:29:45.620 --> 01:29:49.580]   What do you think about Moore's law?
[01:29:49.580 --> 01:29:52.020]   Well, you said a lot of stuff we've talked,
[01:29:52.020 --> 01:29:55.780]   you talked about programming languages in their design,
[01:29:55.780 --> 01:29:58.780]   in their ideas come from the constraints
[01:29:58.780 --> 01:30:00.460]   in the systems they operate in.
[01:30:00.460 --> 01:30:01.820]   Do you think Moore's law,
[01:30:01.820 --> 01:30:07.180]   the exponential improvement of systems
[01:30:07.180 --> 01:30:08.820]   will continue indefinitely?
[01:30:08.820 --> 01:30:12.420]   There's a mix of opinions on that currently.
[01:30:12.420 --> 01:30:17.420]   Or do you think there'll be a plateau?
[01:30:17.420 --> 01:30:21.620]   - Well, the frivolous answer is no exponential
[01:30:21.620 --> 01:30:22.660]   can go on forever.
[01:30:22.660 --> 01:30:25.300]   You run out of something.
[01:30:26.100 --> 01:30:27.740]   Just as we said, timescale matters.
[01:30:27.740 --> 01:30:30.860]   So if it goes on long enough, that might be all we need.
[01:30:30.860 --> 01:30:33.300]   - Yeah, right, won't matter to us.
[01:30:33.300 --> 01:30:34.140]   So I don't know,
[01:30:34.140 --> 01:30:35.940]   we've seen places where Moore's law has changed.
[01:30:35.940 --> 01:30:37.420]   For example, mentioned earlier,
[01:30:37.420 --> 01:30:41.300]   processors don't get faster anymore,
[01:30:41.300 --> 01:30:45.700]   but you use that same growth of,
[01:30:45.700 --> 01:30:48.060]   the ability to put more things in a given area
[01:30:48.060 --> 01:30:51.100]   to go horizontally instead of vertically as it were.
[01:30:51.100 --> 01:30:52.940]   So you can get more and more processors
[01:30:52.940 --> 01:30:55.580]   or memory or whatever on the same chip.
[01:30:55.580 --> 01:30:57.380]   Is that gonna run into a limitation?
[01:30:57.380 --> 01:31:00.660]   Presumably, because at some point
[01:31:00.660 --> 01:31:03.100]   you get down to the individual atoms.
[01:31:03.100 --> 01:31:05.540]   And so you gotta find some way around that.
[01:31:05.540 --> 01:31:07.780]   Will we find some way around that?
[01:31:07.780 --> 01:31:10.020]   I don't know, I just said that if I say it won't,
[01:31:10.020 --> 01:31:10.860]   I'll be wrong.
[01:31:10.860 --> 01:31:12.540]   So perhaps we will.
[01:31:12.540 --> 01:31:15.020]   - So I just talked to Jim Keller and he says,
[01:31:15.020 --> 01:31:16.380]   so he actually describes,
[01:31:16.380 --> 01:31:18.500]   he argues that the Moore's law will continue
[01:31:18.500 --> 01:31:21.780]   for a long, long time because you mentioned the atom.
[01:31:21.780 --> 01:31:25.260]   We actually have, I think a thousand fold increase,
[01:31:25.260 --> 01:31:29.940]   decreased in transistor size still possible
[01:31:29.940 --> 01:31:32.060]   before we get to the quantum level.
[01:31:32.060 --> 01:31:34.700]   So there's still a lot of possibilities.
[01:31:34.700 --> 01:31:36.420]   He thinks it'll continue indefinitely,
[01:31:36.420 --> 01:31:40.660]   which is an interesting, optimistic viewpoint.
[01:31:40.660 --> 01:31:43.420]   But how do you think the programming languages
[01:31:43.420 --> 01:31:45.420]   will change with this increase?
[01:31:45.420 --> 01:31:47.660]   Whether we hit a wall or not,
[01:31:47.660 --> 01:31:49.420]   what do you think?
[01:31:49.420 --> 01:31:51.420]   Do you think there'll be a fundamental change
[01:31:51.420 --> 01:31:54.500]   in the way programming languages are designed?
[01:31:54.500 --> 01:31:55.380]   - I don't know about that.
[01:31:55.380 --> 01:31:58.620]   I think what will happen is continuation
[01:31:58.620 --> 01:32:02.020]   of what we see in some areas at least,
[01:32:02.020 --> 01:32:05.500]   which is that more programming will be done
[01:32:05.500 --> 01:32:08.220]   by programs than by people.
[01:32:08.220 --> 01:32:12.700]   And that more will be done by sort of declarative
[01:32:12.700 --> 01:32:15.740]   rather than procedural mechanisms where I say,
[01:32:15.740 --> 01:32:18.700]   I want this to happen, you figure out how.
[01:32:19.820 --> 01:32:24.260]   And that is in many cases at this point,
[01:32:24.260 --> 01:32:28.700]   domain of specialized languages for narrow domains,
[01:32:28.700 --> 01:32:31.860]   but you can imagine that broadening out.
[01:32:31.860 --> 01:32:35.660]   And so I don't have to say so much in so much detail,
[01:32:35.660 --> 01:32:39.340]   some collection of software, let's call it languages
[01:32:39.340 --> 01:32:41.340]   or programs or something,
[01:32:41.340 --> 01:32:44.820]   we'll figure out how to do what I want to do.
[01:32:44.820 --> 01:32:47.220]   - Interesting, so increased levels of abstraction.
[01:32:47.220 --> 01:32:48.060]   - Yeah.
[01:32:48.900 --> 01:32:50.980]   - And one day getting to the human level
[01:32:50.980 --> 01:32:52.780]   where we can just use natural language.
[01:32:52.780 --> 01:32:54.580]   - Could be possible.
[01:32:54.580 --> 01:32:56.780]   - So you taught, still teach a course,
[01:32:56.780 --> 01:32:59.740]   Computers in Our World here at Princeton
[01:32:59.740 --> 01:33:03.280]   that introduces computing and programming to non-majors.
[01:33:03.280 --> 01:33:07.740]   Just from that experience, what advice do you have
[01:33:07.740 --> 01:33:10.580]   for people who don't know anything about programming
[01:33:10.580 --> 01:33:12.940]   but are kind of curious about this world
[01:33:12.940 --> 01:33:14.780]   where programming seems to become more and more
[01:33:14.780 --> 01:33:17.060]   of a fundamental skill that people need
[01:33:17.060 --> 01:33:18.740]   to be at least aware of?
[01:33:18.740 --> 01:33:20.380]   - Well, I can recommend a good book.
[01:33:20.380 --> 01:33:21.220]   - What's that?
[01:33:21.220 --> 01:33:22.060]   (laughing)
[01:33:22.060 --> 01:33:24.340]   - The book I wrote for the course.
[01:33:24.340 --> 01:33:26.660]   I think this is one of these questions
[01:33:26.660 --> 01:33:28.500]   of should everybody know how to program?
[01:33:28.500 --> 01:33:31.260]   And I think the answer is probably not,
[01:33:31.260 --> 01:33:32.980]   but I think everybody should at least understand
[01:33:32.980 --> 01:33:35.660]   sort of what it is so that if you say to somebody,
[01:33:35.660 --> 01:33:38.100]   I'm a programmer, they have a notion of what that might be,
[01:33:38.100 --> 01:33:40.140]   or if you say this is a program,
[01:33:40.140 --> 01:33:43.560]   or this was decided by a computer running a program,
[01:33:43.560 --> 01:33:47.580]   that they have some vague intuitive understanding
[01:33:47.580 --> 01:33:51.400]   and accurate understanding of what that might imply.
[01:33:51.400 --> 01:33:55.180]   So part of what I'm doing in this course,
[01:33:55.180 --> 01:33:57.460]   which is very definitely for non-technical people,
[01:33:57.460 --> 01:33:59.340]   I mean, a typical person in it is a history
[01:33:59.340 --> 01:34:03.700]   or English major, try and explain how computers work,
[01:34:03.700 --> 01:34:06.300]   how they do their thing, what programming is,
[01:34:06.300 --> 01:34:07.620]   how you write a program,
[01:34:07.620 --> 01:34:11.400]   and how computers talk to each other,
[01:34:11.400 --> 01:34:14.300]   and what do they do when they're talking to each other.
[01:34:14.300 --> 01:34:19.300]   And then I would say nobody, very rarely,
[01:34:19.300 --> 01:34:21.900]   and does anybody in that course go on
[01:34:21.900 --> 01:34:24.180]   to become a real serious programmer,
[01:34:24.180 --> 01:34:27.140]   but at least they've got a somewhat better idea
[01:34:27.140 --> 01:34:29.580]   of what all this stuff is about, not just the programming,
[01:34:29.580 --> 01:34:32.620]   but the technology behind computers and communications.
[01:34:32.620 --> 01:34:35.700]   - Do they try and write a program themselves?
[01:34:35.700 --> 01:34:38.340]   - Oh yeah, yeah, a very small amount.
[01:34:38.340 --> 01:34:40.620]   I introduced them to how machines work
[01:34:40.620 --> 01:34:43.020]   at a level below high-level languages,
[01:34:43.020 --> 01:34:45.220]   so we have a kind of a toy machine
[01:34:45.220 --> 01:34:47.800]   that has a very small repertoire, a dozen instructions,
[01:34:47.800 --> 01:34:51.060]   and they write trivial assembly language programs for that.
[01:34:51.060 --> 01:34:51.900]   - Really? - Yeah.
[01:34:51.900 --> 01:34:55.060]   - Wow, so can you, just, if you were to give a flavor
[01:34:55.060 --> 01:34:59.500]   to people of the programming world, of the computing world,
[01:34:59.500 --> 01:35:01.940]   what are the examples they should go with?
[01:35:01.940 --> 01:35:04.300]   So a little bit of assembly to get a sense
[01:35:04.300 --> 01:35:08.820]   at the lowest level of what the program is really doing?
[01:35:08.820 --> 01:35:10.740]   - Yeah, I mean, in some sense,
[01:35:10.740 --> 01:35:12.500]   there's no such thing as the lowest level,
[01:35:12.500 --> 01:35:13.620]   because you can keep going down,
[01:35:13.620 --> 01:35:15.580]   but that's the place where I drew the line.
[01:35:15.580 --> 01:35:19.380]   So the idea that computers have a fairly small repertoire
[01:35:19.380 --> 01:35:21.740]   of very simple instructions that they can do,
[01:35:21.740 --> 01:35:25.020]   like add and subtract and branch and so on,
[01:35:25.020 --> 01:35:26.220]   as you mentioned earlier,
[01:35:26.220 --> 01:35:31.540]   and that you can write code at that level,
[01:35:31.540 --> 01:35:33.220]   and it will get things done,
[01:35:33.220 --> 01:35:35.540]   and then you have the levels of abstraction
[01:35:35.540 --> 01:35:37.820]   that we get with higher-level languages,
[01:35:37.820 --> 01:35:39.860]   like Fortran or C or whatever,
[01:35:39.860 --> 01:35:42.340]   and that makes it easier to write the code
[01:35:42.340 --> 01:35:44.940]   and less dependent on particular architectures.
[01:35:44.940 --> 01:35:48.020]   And then we talk about a lot of the different kinds
[01:35:48.020 --> 01:35:50.620]   of programs that they use all the time
[01:35:50.620 --> 01:35:52.740]   that they don't probably realize are programs,
[01:35:52.740 --> 01:35:57.620]   like they're running Mac OS on their computers
[01:35:57.620 --> 01:36:00.220]   or maybe Windows, and they're downloading apps
[01:36:00.220 --> 01:36:03.000]   on their phones, and all of those things are programs
[01:36:03.000 --> 01:36:05.940]   that are just what we just talked about,
[01:36:05.940 --> 01:36:08.140]   except at a grand scale.
[01:36:08.140 --> 01:36:10.500]   - Yeah, it's easy to forget that they're actual programs
[01:36:10.500 --> 01:36:11.820]   that people program.
[01:36:11.820 --> 01:36:14.060]   There's engineers that wrote those things.
[01:36:14.060 --> 01:36:17.660]   - Yeah, right, and so in a way,
[01:36:17.660 --> 01:36:20.580]   I'm expecting them to make an enormous conceptual leap
[01:36:20.580 --> 01:36:24.540]   from their five or 10-line toy assembly language thing
[01:36:24.540 --> 01:36:28.260]   that adds two or three numbers to something
[01:36:28.260 --> 01:36:31.020]   that is a browser on their phone or whatever,
[01:36:31.020 --> 01:36:33.460]   but it's really the same thing.
[01:36:33.460 --> 01:36:37.160]   - So if you look in broad strokes at history,
[01:36:37.160 --> 01:36:39.740]   what do you think the world,
[01:36:39.740 --> 01:36:42.860]   how do you think the world changed because of computers?
[01:36:42.860 --> 01:36:45.220]   It's hard to sometimes see the big picture
[01:36:45.220 --> 01:36:48.020]   when you're in it, but I guess I'm asking
[01:36:48.020 --> 01:36:51.540]   if there's something you've noticed over the years
[01:36:51.540 --> 01:36:54.540]   that, like you were mentioning,
[01:36:54.540 --> 01:36:56.820]   the students are more distracted looking at their,
[01:36:56.820 --> 01:36:58.500]   now there's a device to look at.
[01:36:58.500 --> 01:37:00.580]   - Right, well, I think computing has changed
[01:37:00.580 --> 01:37:02.180]   a tremendous amount, obviously,
[01:37:02.180 --> 01:37:04.320]   but I think one aspect of that is the way
[01:37:04.320 --> 01:37:06.460]   that people interact with each other,
[01:37:06.460 --> 01:37:11.300]   both locally and far away, and when I was the age
[01:37:11.300 --> 01:37:14.160]   of those kids, making a phone call to somewhere
[01:37:14.160 --> 01:37:17.220]   was a big deal because it cost serious money,
[01:37:17.220 --> 01:37:19.280]   and this was in the '60s, right?
[01:37:19.280 --> 01:37:22.900]   And today, people don't make phone calls,
[01:37:22.900 --> 01:37:25.660]   they send texts or something like that,
[01:37:25.660 --> 01:37:29.500]   so there's an up and down in what people do.
[01:37:29.500 --> 01:37:34.100]   People think nothing of having correspondence,
[01:37:34.100 --> 01:37:37.460]   regular meetings, video, whatever, with friends
[01:37:37.460 --> 01:37:40.380]   or family or whatever in any other part of the world,
[01:37:40.380 --> 01:37:43.060]   and they don't think about that at all.
[01:37:43.060 --> 01:37:47.100]   And so that's just the communication aspect of it.
[01:37:47.100 --> 01:37:50.940]   - Do you think that brings us closer together,
[01:37:50.940 --> 01:37:55.940]   or does it make us, does it take us away
[01:37:55.940 --> 01:37:59.140]   from the closeness of human-to-human contact?
[01:37:59.140 --> 01:38:02.820]   - I think it depends a lot on all kinds of things.
[01:38:02.820 --> 01:38:05.860]   So I trade mail with my brother and sister in Canada
[01:38:05.860 --> 01:38:08.860]   much more often than I used to talk to them on the phone.
[01:38:08.860 --> 01:38:10.740]   So probably every two or three days,
[01:38:10.740 --> 01:38:14.420]   I get something or send something to them,
[01:38:14.420 --> 01:38:18.860]   whereas 20 years ago, I probably wouldn't have talked
[01:38:18.860 --> 01:38:20.620]   to them on the phone nearly as much.
[01:38:20.620 --> 01:38:22.660]   So in that sense, that's brought my brother
[01:38:22.660 --> 01:38:24.020]   and sister and I closer together.
[01:38:24.020 --> 01:38:25.020]   That's a good thing.
[01:38:25.020 --> 01:38:29.820]   I watch the kids on campus, and they're mostly walking
[01:38:29.820 --> 01:38:32.260]   around with their heads down, fooling with their phones
[01:38:32.260 --> 01:38:34.900]   to the point where I have to duck them.
[01:38:34.900 --> 01:38:39.420]   I don't know that that has brought them closer together
[01:38:39.420 --> 01:38:40.500]   in some ways.
[01:38:40.500 --> 01:38:43.740]   There's sociological research that says people are,
[01:38:43.740 --> 01:38:46.220]   in fact, not as close together as they used to be.
[01:38:46.220 --> 01:38:47.580]   I don't know whether that's really true,
[01:38:47.580 --> 01:38:52.540]   but I can see potential downsides in kids
[01:38:52.540 --> 01:38:54.340]   where you think, "Come on, wake up
[01:38:54.340 --> 01:38:56.780]   "and smell the coffee," or whatever.
[01:38:56.780 --> 01:38:59.140]   - That's right, but if you look at, again,
[01:38:59.140 --> 01:39:02.100]   nobody can predict the future, but are you excited
[01:39:02.100 --> 01:39:04.820]   and I kind of touched this a little bit with AI,
[01:39:04.820 --> 01:39:08.780]   but are you excited by the future in the next 10, 20 years
[01:39:08.780 --> 01:39:11.580]   that computing will bring?
[01:39:11.580 --> 01:39:15.900]   You were there when there was no computers, really,
[01:39:15.900 --> 01:39:19.460]   and now computers are everywhere, all over the world,
[01:39:19.460 --> 01:39:23.100]   in Africa and Asia, and just every person,
[01:39:23.100 --> 01:39:25.580]   almost every person in the world has a device.
[01:39:25.580 --> 01:39:29.320]   So are you hopeful, optimistic about that future?
[01:39:30.740 --> 01:39:32.420]   - It's mixed, if the truth be told.
[01:39:32.420 --> 01:39:34.140]   I mean, I think there are some things about that
[01:39:34.140 --> 01:39:34.980]   that are good.
[01:39:34.980 --> 01:39:36.740]   I think there's the potential for people
[01:39:36.740 --> 01:39:39.100]   to improve their lives all over the place,
[01:39:39.100 --> 01:39:40.940]   and that's obviously good.
[01:39:40.940 --> 01:39:44.260]   And at the same time, at least in the short run,
[01:39:44.260 --> 01:39:45.900]   you can see lots and lots of bad
[01:39:45.900 --> 01:39:48.340]   as people become more tribalistic
[01:39:48.340 --> 01:39:50.360]   or parochial in their interests,
[01:39:50.360 --> 01:39:53.180]   and it's an enormous amount more us and them,
[01:39:53.180 --> 01:39:55.700]   and people are using computers in all kinds of ways
[01:39:55.700 --> 01:39:58.820]   to mislead or misrepresent or flat out lie
[01:39:58.820 --> 01:40:01.860]   about what's going on, and that is affecting politics
[01:40:01.860 --> 01:40:04.220]   locally and, I think, everywhere in the world.
[01:40:04.220 --> 01:40:08.900]   - Yeah, the long-term effect on political systems
[01:40:08.900 --> 01:40:10.900]   and so on, it's who knows.
[01:40:10.900 --> 01:40:11.860]   - Who knows, indeed.
[01:40:11.860 --> 01:40:14.440]   (Lex laughing)
[01:40:14.440 --> 01:40:18.620]   - People now have a voice, which is a powerful thing.
[01:40:18.620 --> 01:40:21.020]   People who are oppressed have a voice,
[01:40:21.020 --> 01:40:24.100]   but also everybody has a voice,
[01:40:24.100 --> 01:40:26.820]   and the chaos that emerges from that is fascinating to watch.
[01:40:26.820 --> 01:40:29.180]   - Yeah, yeah, it's kind of scary.
[01:40:29.180 --> 01:40:33.700]   - If you can go back and relive a moment in your life,
[01:40:33.700 --> 01:40:37.520]   one that made you truly happy outside of family,
[01:40:37.520 --> 01:40:40.060]   or was profoundly transformative,
[01:40:40.060 --> 01:40:44.340]   is there a moment or moments that jump out at you
[01:40:44.340 --> 01:40:45.180]   from memory?
[01:40:45.180 --> 01:40:48.040]   - I don't think specific moments.
[01:40:48.040 --> 01:40:50.340]   I think there were lots and lots and lots of good times
[01:40:50.340 --> 01:40:52.500]   at Bell Labs where you would build something,
[01:40:52.500 --> 01:40:55.380]   and it worked.
[01:40:55.380 --> 01:40:56.740]   Huh, Jason, it worked.
[01:40:56.740 --> 01:40:57.940]   - So the moment it worked.
[01:40:57.940 --> 01:41:00.220]   - Yeah, and somebody used it, and they said,
[01:41:00.220 --> 01:41:01.260]   "Gee, that's neat."
[01:41:01.260 --> 01:41:04.620]   Those kinds of things happened quite often
[01:41:04.620 --> 01:41:07.820]   in that sort of golden era in the '70s
[01:41:07.820 --> 01:41:10.460]   when Unix was young, and there was all this
[01:41:10.460 --> 01:41:13.420]   low-hanging fruit and interesting things to work on,
[01:41:13.420 --> 01:41:16.140]   and a group of people who kind of,
[01:41:16.140 --> 01:41:18.900]   we were all together in this, and if you did something,
[01:41:18.900 --> 01:41:20.540]   they would try it out for you.
[01:41:20.540 --> 01:41:22.780]   And I think that was, in some sense,
[01:41:22.780 --> 01:41:24.500]   a really, really good time.
[01:41:24.500 --> 01:41:27.460]   - And awk was awk an example of that,
[01:41:27.460 --> 01:41:29.420]   that when you built it, then people used it?
[01:41:29.420 --> 01:41:30.420]   - Yeah, absolutely.
[01:41:30.420 --> 01:41:32.700]   - And now millions of people use.
[01:41:32.700 --> 01:41:34.540]   - And all your stupid mistakes are right there
[01:41:34.540 --> 01:41:36.500]   for them to look at, right?
[01:41:36.500 --> 01:41:37.460]   So it's mixed.
[01:41:37.460 --> 01:41:39.140]   - Yeah, it's terrifying and vulnerable,
[01:41:39.140 --> 01:41:42.020]   but it's beautiful 'cause it does have a positive impact
[01:41:42.020 --> 01:41:43.820]   on so, so many people.
[01:41:43.820 --> 01:41:47.220]   So I think there's no better way to end it.
[01:41:47.220 --> 01:41:48.660]   Brian, thank you so much for talking to me.
[01:41:48.660 --> 01:41:49.500]   It was an honor.
[01:41:49.500 --> 01:41:51.260]   - Okay, my pleasure.
[01:41:51.260 --> 01:41:52.100]   Good fun.
[01:41:53.780 --> 01:41:55.380]   - Thank you for listening to this conversation
[01:41:55.380 --> 01:41:58.540]   with Brian Kernighan, and thank you to our sponsors,
[01:41:58.540 --> 01:42:02.380]   8sleep Mattress and Raycon Earbuds.
[01:42:02.380 --> 01:42:05.140]   Please consider supporting this podcast
[01:42:05.140 --> 01:42:08.340]   by going to 8sleep.com/lex
[01:42:08.340 --> 01:42:12.140]   and to buy raycon.com/lex.
[01:42:12.140 --> 01:42:14.540]   Click the links, buy the stuff.
[01:42:14.540 --> 01:42:16.800]   These both are amazing products.
[01:42:16.800 --> 01:42:19.340]   It really is the best way to support this podcast
[01:42:19.340 --> 01:42:21.180]   and the journey I'm on.
[01:42:21.180 --> 01:42:24.740]   It's how they know I sent you and increases the chance
[01:42:24.740 --> 01:42:27.700]   that they'll actually support this podcast in the future.
[01:42:27.700 --> 01:42:30.300]   If you enjoy this thing, subscribe on YouTube,
[01:42:30.300 --> 01:42:32.660]   review it with Firestarz and Apple Podcast,
[01:42:32.660 --> 01:42:35.980]   support it on Patreon, or connect with me on Twitter
[01:42:35.980 --> 01:42:40.100]   at Lex Friedman, spelled somehow, miraculously,
[01:42:40.100 --> 01:42:44.100]   without the letter E, just F-R-I-D-M-A-N,
[01:42:44.100 --> 01:42:46.640]   because when we immigrated to this country,
[01:42:46.640 --> 01:42:49.060]   we were not so good at spelling.
[01:42:49.060 --> 01:42:51.380]   And now let me leave you with some words
[01:42:51.380 --> 01:42:53.340]   from Brian Kernighan.
[01:42:53.340 --> 01:42:56.200]   Don't comment bad code, rewrite it.
[01:42:56.200 --> 01:43:00.600]   Thank you for listening and hope to see you next time.
[01:43:00.600 --> 01:43:03.180]   (upbeat music)
[01:43:03.180 --> 01:43:05.760]   (upbeat music)
[01:43:05.760 --> 01:43:15.760]   [BLANK_AUDIO]

