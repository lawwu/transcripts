
[00:00:00.000 --> 00:00:03.600]   Yesterday, the game went off the chain. It was it's we started
[00:00:03.600 --> 00:00:07.600]   off at 500 1000. And then we were like, wow, these $500 chips
[00:00:07.600 --> 00:00:10.200]   are so annoying. Then we started to play 1000 1000. Then it was
[00:00:10.200 --> 00:00:16.920]   1000 2000. That's 1000 2000 4000. Then 1248 then 1248 1612
[00:00:16.920 --> 00:00:20.160]   4816 32,000 coming around.
[00:00:20.160 --> 00:00:22.860]   Oh my god, how much?
[00:00:22.860 --> 00:00:25.480]   What was the big winner and big loser?
[00:00:26.040 --> 00:00:31.780]   I'm not gonna say how much out 800. I put minus 800.
[00:00:31.780 --> 00:00:35.740]   Minus seven. Don't say these fucking names.
[00:00:35.740 --> 00:00:39.120]   How'd you do tomorrow? Okay.
[00:00:39.120 --> 00:00:39.960]   Yo.
[00:00:39.960 --> 00:00:45.600]   You can tell that your mouth loss because when you ask him
[00:00:45.600 --> 00:00:49.260]   how'd you do and it's like just he goes from the super effusive
[00:00:49.260 --> 00:00:52.860]   talking about the game to just like one word fine. Okay, fine.
[00:00:52.860 --> 00:00:53.940]   Okay, how was your night?
[00:00:53.940 --> 00:00:55.680]   He's like,
[00:00:55.680 --> 00:00:58.500]   look, I should $42 million for breakfast. It was fine.
[00:00:58.500 --> 00:01:00.820]   Here we go. 32
[00:01:00.820 --> 00:01:06.400]   brain man David.
[00:01:06.400 --> 00:01:21.280]   Hey, everybody, welcome to another episode of the all in
[00:01:21.280 --> 00:01:25.260]   podcast 50 episodes down. And yeah, we'll definitely get three
[00:01:25.260 --> 00:01:25.660]   or four more.
[00:01:25.700 --> 00:01:30.280]   In before the band breaks up with us today again, from an
[00:01:30.280 --> 00:01:34.280]   undisclosed location. David Sachs, the Rain Man himself,
[00:01:34.280 --> 00:01:38.460]   Chamath Palihapitiya, the dictator and the Queen of
[00:01:38.460 --> 00:01:42.320]   quinoa. David Friedberg. How's everybody doing? How's everybody
[00:01:42.320 --> 00:01:45.040]   feeling? How's everybody's week going?
[00:01:45.040 --> 00:01:48.220]   Really great. Yours?
[00:01:48.220 --> 00:01:55.120]   Just just great. Awesome. I, I feel really good. I feel super
[00:01:55.120 --> 00:01:55.620]   grateful.
[00:01:55.620 --> 00:01:57.840]   Really?
[00:01:57.840 --> 00:02:05.700]   Stock markets up today. It's been a good week. It's been a good
[00:02:05.700 --> 00:02:12.780]   week. I feel so much equanimity. Mark is up 4%. Freeberg, how are
[00:02:12.780 --> 00:02:13.200]   you doing?
[00:02:13.200 --> 00:02:17.340]   My wife went to the hospital three times this week, all three
[00:02:17.340 --> 00:02:21.780]   times thinking she was in labor. Hey, are you how? I mean, we're
[00:02:21.780 --> 00:02:24.660]   two centimeters dilated. We're still waiting here. I mean, we
[00:02:24.660 --> 00:02:25.460]   are there too.
[00:02:25.460 --> 00:02:30.080]   And we're just waiting any day, like literally any hour. So we
[00:02:30.080 --> 00:02:30.560]   were
[00:02:30.560 --> 00:02:33.440]   get action on this. Can we can we bet who's gonna come first? Or
[00:02:33.440 --> 00:02:35.940]   I think I think free birds and comforts because it's his third.
[00:02:35.940 --> 00:02:38.420]   It's the only that it's Allison's third. It's not second.
[00:02:38.420 --> 00:02:41.960]   Yeah, so we can lay odds two to one. What do we get?
[00:02:41.960 --> 00:02:46.160]   I'll take the over under on what days of thing is the 15th.
[00:02:46.160 --> 00:02:49.520]   We're getting induced on the 26th. It's 11 days or no, I'll
[00:02:49.520 --> 00:02:51.500]   take the over under on the
[00:02:51.500 --> 00:02:54.260]   video render on
[00:02:54.260 --> 00:02:57.200]   the 21st.
[00:02:57.200 --> 00:02:59.360]   That you're setting the line.
[00:02:59.360 --> 00:03:01.160]   I'll set the line at the 21st of October.
[00:03:01.160 --> 00:03:04.820]   I'm going over. I'll go over for that. This is for that. Okay.
[00:03:04.820 --> 00:03:09.140]   Okay. Yeah. For now. Yeah. Under what do you got sacks over on
[00:03:09.140 --> 00:03:13.760]   on the 21st 26 is the expected date where we're betting on
[00:03:13.760 --> 00:03:18.920]   analysis. When their children are born.
[00:03:18.920 --> 00:03:23.900]   You guys a little too old be having kids.
[00:03:23.900 --> 00:03:24.400]   Yeah.
[00:03:24.400 --> 00:03:26.880]   I mean, are you even gonna see them graduate?
[00:03:26.880 --> 00:03:28.220]   So you have a sac to me.
[00:03:28.220 --> 00:03:30.660]   I mean, sack some of us are a whole bar mitzvah younger than you.
[00:03:30.660 --> 00:03:35.480]   So you snipped. I would if anybody was snipped, I would guess it would be sacks.
[00:03:35.480 --> 00:03:36.920]   Are you? Are you snippy snippy?
[00:03:36.920 --> 00:03:40.300]   Is this the type of vital information you think the audience wants to know?
[00:03:40.300 --> 00:03:42.460]   Yeah, I think they do. Actually.
[00:03:42.460 --> 00:03:46.160]   I think that's a yes. I think he's been snipped.
[00:03:46.160 --> 00:03:53.700]   Chamath is definitely not stamped. Nope. You can. You can. You want to come over here and inspect?
[00:03:53.700 --> 00:03:54.540]   Do the procedure.
[00:03:54.540 --> 00:03:55.680]   It's conducted inspection.
[00:03:55.680 --> 00:03:58.200]   I don't think I don't think you can visually understand that.
[00:03:58.200 --> 00:04:01.620]   Let's let's look. We're gonna we're gonna buzzers out. Let's keep going.
[00:04:01.620 --> 00:04:03.720]   It's not visually understandable.
[00:04:03.720 --> 00:04:09.000]   Yeah. Freeburg's definitely not snipped as proven by his wife being pregnant.
[00:04:09.000 --> 00:04:11.400]   I don't think you say snip bro. I think you just say vasectomy.
[00:04:11.400 --> 00:04:14.940]   No, I'm just, you know, I think you say snip snip.
[00:04:14.940 --> 00:04:19.620]   I think sacks has been snipped. That's actually a good bet. We could book it on sacks being snipped.
[00:04:19.620 --> 00:04:21.660]   Okay, listen, a lot of topics to get to.
[00:04:21.660 --> 00:04:23.500]   I think we were trying to get to this topic last week.
[00:04:23.500 --> 00:04:27.320]   There's been a supply chain interruption right now.
[00:04:27.320 --> 00:04:32.360]   There's some shortages obviously of key components like microchips.
[00:04:32.360 --> 00:04:34.300]   We all know this according to car and driver.
[00:04:34.300 --> 00:04:38.440]   The top three models impacted by the chip shortage where the Ford F series pickup trucks,
[00:04:38.440 --> 00:04:41.900]   Jeep Cherokee SUVs and the Chevy Equinox SUVs.
[00:04:41.900 --> 00:04:48.440]   Basically, a lot of the cars that have advanced driving systems are now removing them.
[00:04:48.440 --> 00:04:53.300]   I was looking at getting an SUV for the winter and I was looking at the Cadillac Escalade.
[00:04:53.300 --> 00:05:00.260]   And they took self driving out of the 2022 model or the autopilot basically because they can't get the chips.
[00:05:00.260 --> 00:05:03.420]   And we all know why this is happening.
[00:05:03.420 --> 00:05:04.500]   Obviously, covid.
[00:05:04.500 --> 00:05:07.860]   And then also on top of it demand.
[00:05:07.860 --> 00:05:15.060]   So people are buying second computers, third computers, places like Dell or having an apple are selling a lot of desktops, a lot of laptops.
[00:05:15.060 --> 00:05:19.820]   And there's also a labor shortage.
[00:05:19.820 --> 00:05:23.100]   So the labor force obviously here in the United States is a lot of work.
[00:05:23.100 --> 00:05:25.100]   And the number of people that are working in the United States is much smaller than it was.
[00:05:25.100 --> 00:05:29.640]   We all know that people are raising salaries to try to get people to come back to work.
[00:05:29.640 --> 00:05:33.920]   They're turning off the bonus unemployment early in some states.
[00:05:33.920 --> 00:05:34.680]   We're here in October.
[00:05:34.680 --> 00:05:36.680]   This is all supposed to be turned off by now.
[00:05:36.680 --> 00:05:40.680]   So I guess I'll start with you, Chamath, in terms of the markets here.
[00:05:40.680 --> 00:05:43.580]   What do you think is happening?
[00:05:43.580 --> 00:05:47.260]   And is this an acute risk or just something that will pass?
[00:05:47.260 --> 00:05:52.900]   I think the well, this is where I think I kind of generally disagree with the market.
[00:05:52.900 --> 00:05:57.660]   I think that most people are under the impression that these are short term.
[00:05:57.660 --> 00:06:08.820]   Kind of contractions and expansions and that this is just the thing that needs to get work through the system as we readjust to a post-COVID world, blah, blah, blah.
[00:06:08.820 --> 00:06:10.220]   I think it's different.
[00:06:10.220 --> 00:06:22.700]   And the reason I think it's different is if you just look at one thing and one thing only, which is that we have a massive labor shortage in America and there is an incredible
[00:06:22.700 --> 00:06:31.880]   stat that I saw, which was the average hourly earnings of non-manager people in hospitality and travel.
[00:06:31.880 --> 00:06:38.540]   And the average salary, the mean salary was around 20 some odd dollars an hour, and it's now 33 bucks an hour.
[00:06:38.540 --> 00:06:50.200]   And so what that to me says is that we are going through a really sustained period where you cannot get people to do the work that needs to get done.
[00:06:50.200 --> 00:06:52.500]   Biden had to call the Port of L.A.
[00:06:52.500 --> 00:06:56.100]   and try to get these guys to be open 24 hours a day.
[00:06:56.100 --> 00:07:00.800]   The president of the United States is calling a local port trying to get it to stay open.
[00:07:00.800 --> 00:07:02.800]   But why can't they stay open?
[00:07:02.800 --> 00:07:10.620]   Because you have long Sherman, you have all these unionized folks who will expect to get certain levels of compensation, which they deserve in order to do that work 24/7.
[00:07:10.620 --> 00:07:13.420]   But then all of that is going to get put through the system.
[00:07:13.420 --> 00:07:22.200]   And if you still have millions of jobs that needs to get done in order for the economy to function, the only efficient way that that's going to get resolved is by
[00:07:22.200 --> 00:07:22.300]   raising the minimum wage.
[00:07:22.300 --> 00:07:27.220]   raising salaries. And those are consistent and persistent. Those
[00:07:27.220 --> 00:07:29.540]   things are not just like, oh, you know what I gave a yes, I
[00:07:29.540 --> 00:07:32.020]   did say 50 bucks an hour, but now I'm taking you back to take
[00:07:32.020 --> 00:07:35.560]   that back. That's gonna be that's so on. So I tend to so
[00:07:35.560 --> 00:07:38.780]   that's one thing. And then second, so there's people,
[00:07:38.780 --> 00:07:41.440]   right. So labor capital, I just think it's getting more and more
[00:07:41.440 --> 00:07:44.740]   expensive to get folks to do work. And then there's the raw
[00:07:44.740 --> 00:07:47.980]   materials that you use to make anything. And everything that I
[00:07:47.980 --> 00:07:52.060]   see is that stuff is going bananas. And so I put these two
[00:07:52.060 --> 00:07:54.400]   things together. And I'm like, I think this stuff is here to
[00:07:54.400 --> 00:07:58.120]   stay. I'm really kind of a little bit of a, you know, I
[00:07:58.120 --> 00:08:00.640]   know, and I had not worried. And you can see in every episode
[00:08:00.640 --> 00:08:03.560]   before this, I was always consistently like, there is no
[00:08:03.560 --> 00:08:07.740]   inflation, you can fade the inflation trade. Now I'm kind of
[00:08:07.740 --> 00:08:11.680]   positioning myself to hedge myself in this situation.
[00:08:11.680 --> 00:08:16.840]   All right, freeberg. We've seen the pictures of the Long Beach
[00:08:16.840 --> 00:08:21.220]   and the Los Angeles ports, there's just ships out there,
[00:08:21.220 --> 00:08:21.640]   like,
[00:08:21.820 --> 00:08:25.600]   I think 70 or 80 is where it peaked at in July, I don't know
[00:08:25.600 --> 00:08:29.940]   have the latest data here when it updated. But is there not a
[00:08:29.940 --> 00:08:32.780]   silver lining here that if people are making more money,
[00:08:32.780 --> 00:08:35.700]   then we're going to increase the size of the middle class, and
[00:08:35.700 --> 00:08:39.060]   we're going to, you know, increase upward mobility. And
[00:08:39.060 --> 00:08:41.860]   that is a double edged sword. It's great that we increase the
[00:08:41.860 --> 00:08:44.620]   middle class, but then they're going to want to buy stuff. So
[00:08:44.620 --> 00:08:47.380]   people are now making 35 bucks an hour, and they were making
[00:08:47.380 --> 00:08:49.620]   20. Now they got more disposable, now they're gonna go
[00:08:49.620 --> 00:08:51.580]   on Amazon and buy more stuff. And it's going to accelerate,
[00:08:51.580 --> 00:08:52.080]   right?
[00:08:52.080 --> 00:08:53.080]   Yeah, it's going to accelerate this problem, is it not?
[00:08:53.080 --> 00:08:56.200]   The challenge is the rate of change. This is what the Fed
[00:08:56.200 --> 00:08:59.380]   tries to manage. And you know, there's a White House Economic
[00:08:59.380 --> 00:09:01.400]   Advisory Committee that's involved in trying to figure out
[00:09:01.400 --> 00:09:04.000]   what's going to happen here. Because the current estimate is
[00:09:04.000 --> 00:09:07.240]   it's going to take at least a year or probably a year to work
[00:09:07.240 --> 00:09:10.840]   through the current logjam and the global supply chains. And
[00:09:10.840 --> 00:09:13.300]   during that period of time, as Shamak points out, what's
[00:09:13.300 --> 00:09:19.620]   happening is the cost for goods is climbing, because people have
[00:09:19.620 --> 00:09:21.340]   to charge higher prices.
[00:09:21.340 --> 00:09:24.580]   Yeah, so the cost of goods is going to be higher, and the cost
[00:09:24.580 --> 00:09:27.040]   of goods is going to be higher. And so the cost of goods is going
[00:09:27.040 --> 00:09:29.080]   to be higher. And so the cost of goods is going to be higher.
[00:09:29.080 --> 00:09:31.000]   And so the cost of goods is going to be higher. And so the cost of
[00:09:31.000 --> 00:09:32.200]   goods is going to be higher. And so the cost of goods is going to
[00:09:32.200 --> 00:09:33.580]   be higher. And so the cost of goods is going to be higher. And
[00:09:33.580 --> 00:09:34.480]   so the cost of goods is going to be higher. And so the cost of
[00:09:34.480 --> 00:09:35.200]   goods is going to be higher. And so the cost of goods is going to
[00:09:35.200 --> 00:09:35.920]   be higher. And so the cost of goods is going to be higher. And
[00:09:35.920 --> 00:09:36.460]   so the cost of goods is going to be higher. And so the cost of goods
[00:09:36.460 --> 00:09:36.880]   is going to be higher. And so the cost of goods is going to be higher.
[00:09:36.880 --> 00:09:41.860]   And the cycle can actually go the wrong direction where you have an inflationary spike that persists.
[00:09:41.860 --> 00:09:45.800]   How do you taper that inflation? It's not necessarily great for economic growth if you
[00:09:45.800 --> 00:09:49.900]   can't produce the stuff. And it can actually cause these runaway kind of effects in the dynamic
[00:09:49.900 --> 00:09:55.980]   system of supply and demand when you have these things clogging up the system for supply.
[00:09:55.980 --> 00:10:03.820]   So it is a real risk. And it is the biggest thing that the White House, this economic task force is
[00:10:03.820 --> 00:10:09.520]   kind of trying to figure out right now is where's the balance lie, where you can, you know, basically
[00:10:09.520 --> 00:10:13.960]   try and taper this inflationary effect that's being caused by this logjam in the supply chain
[00:10:13.960 --> 00:10:21.080]   without causing economic disruption by raising interest rates. And so it's a really kind of
[00:10:21.080 --> 00:10:25.200]   complicated, you know, second and third derivative formula that needs to kind of be resolved. And
[00:10:25.200 --> 00:10:28.420]   that's why so many of these little elements are so important to get right. By the way, rates,
[00:10:28.420 --> 00:10:31.880]   by the way, central bankers around the world have raised rates. The only place that hasn't gone up
[00:10:31.880 --> 00:10:33.800]   is Europe, ECB, and the United States.
[00:10:33.800 --> 00:10:38.760]   The Federal Reserve. So and let's be honest, you know, Europe and the United States,
[00:10:38.760 --> 00:10:44.360]   we absorb labor and materials from all around the world, right? We are the net importers,
[00:10:44.360 --> 00:10:48.360]   we are the net ultimate buyers of last resort of all of these things. And so if you're seeing
[00:10:48.360 --> 00:10:52.840]   inflation in those other, you know, supply driven economies, they are going to come on shore,
[00:10:52.840 --> 00:10:56.040]   they're going to hit us in the face. I think prices are going up.
[00:10:56.040 --> 00:11:03.480]   The other the other free market argument that could be made is that these, these current trends,
[00:11:03.480 --> 00:11:10.920]   will accelerate a trend towards more automation of low cost labor. Because it now will make sense
[00:11:10.920 --> 00:11:16.680]   for businesses to invest in the capital in the capex in the infrastructure and ultimately for
[00:11:16.680 --> 00:11:22.680]   technology companies to build that that tooling to support that infrastructure that will automate
[00:11:22.680 --> 00:11:29.960]   jobs like working in fast food, like doing local delivery, like doing factory assembly, like moving
[00:11:29.960 --> 00:11:33.000]   things across the country and trucks. So self driving trucks,
[00:11:33.000 --> 00:11:38.360]   you know, factory automation, biomanufacturing, additive and 3d manufacturing and 3d printing,
[00:11:38.360 --> 00:11:43.720]   these are all industries that could benefit from the fact that labor now for kind of, you know,
[00:11:43.720 --> 00:11:48.680]   traditionally low income work has gotten so expensive that it starts to make sense to switch
[00:11:48.680 --> 00:11:52.520]   to the technology alternative, which historically may have been too expensive, but now starts to
[00:11:52.520 --> 00:11:56.520]   make economic sense to businesses. This is so there's a number of these automation industries
[00:11:56.520 --> 00:12:01.160]   that may significantly benefit and that ends up ultimately being deflationary and the market comes
[00:12:01.160 --> 00:12:02.520]   into balance. So I think that's a good point.
[00:12:02.520 --> 00:12:05.800]   The balance. So that's another way to kind of think about the macro on what may play out.
[00:12:05.800 --> 00:12:11.080]   There's a bigger risk here than just inflation. I mean, there's also a risk of stagnation or
[00:12:11.080 --> 00:12:15.720]   stagflation because it's not just that prices are going up and workers wages are going up,
[00:12:15.720 --> 00:12:20.280]   which could be a good thing. But goods and services aren't being produced. So I mean,
[00:12:20.280 --> 00:12:27.160]   I know like my own experience, I recently ordered a Tesla when I got a Tesla a couple years ago.
[00:12:27.160 --> 00:12:32.040]   I got in two weeks, it was like almost instant. This time, they wanted me to wait two months has
[00:12:32.040 --> 00:12:36.840]   gotten alert that's going to take two more months beyond that. So we have no idea. And if it if,
[00:12:36.840 --> 00:12:41.640]   you know, Tesla doesn't get most of the money, I don't think until I actually take delivery of the
[00:12:41.640 --> 00:12:45.960]   car, right? That's when you make final payment. So now they can't book that revenue and those
[00:12:45.960 --> 00:12:49.880]   earnings. And Tesla isn't even the car company that's most affected by this, you know, the big,
[00:12:49.880 --> 00:12:54.440]   you know, traditional American auto companies like Ford are even more affected. So
[00:12:54.440 --> 00:13:01.560]   if companies cannot deliver their products, you that can cause an economic recession. And I think
[00:13:01.560 --> 00:13:06.040]   like these are major storm clouds looming on the horizon. Now, what is the cause of this? I mean,
[00:13:06.040 --> 00:13:10.840]   I think it's, it's, it's multifactorial. A lot of things that Jamal said, I just want to
[00:13:10.840 --> 00:13:16.760]   really highlight this port issue. There was a great tweet storm by Zach Cantor earlier in the
[00:13:16.760 --> 00:13:20.680]   week where he said, the supply chain crisis is a clever rebrand that makes it seem like there
[00:13:20.680 --> 00:13:25.880]   are grand exogenous forces at work rather than the unions holding ports for ransom,
[00:13:25.880 --> 00:13:31.080]   while dozens of ships pile up, working just two shifts with a two hour break in between
[00:13:31.080 --> 00:13:34.920]   and a half hour break in between. And so, you know, I think that's a really good point.
[00:13:34.920 --> 00:13:35.800]   And I think that's a really good point. And I think that's a really good point. And I think
[00:13:35.800 --> 00:13:36.760]   that's a really good point. And I think that's a really good point. And I think that's a really
[00:13:36.760 --> 00:13:37.320]   good point. And I think that's a really good point. And I think that's a really good point.
[00:13:37.320 --> 00:13:38.360]   They're allowed to do that.
[00:13:38.360 --> 00:13:43.720]   But, but to my point, this is why Biden felt the need to get involved. So
[00:13:43.720 --> 00:13:51.160]   the problem is, if you read the fine print on this story of Biden announcing that the ports of
[00:13:51.160 --> 00:13:55.320]   LA and Long Beach will open 24 hours, which they clearly need to get the goods to market.
[00:13:55.320 --> 00:14:00.600]   If you read the like the bottom part of the story, everyone's announcing their intention to
[00:14:00.600 --> 00:14:06.600]   go 24/7. But there is no date certain for when that's going to be. It's a negotiation with the
[00:14:06.600 --> 00:14:10.200]   unions. So Chamath, to your point, they are going to have to negotiate with the unions.
[00:14:10.200 --> 00:14:14.840]   You know, initially, it looked like the story was that Biden was going to use his sway,
[00:14:14.840 --> 00:14:18.920]   his clout with the unions to basically push them to take a deal. But I don't think
[00:14:18.920 --> 00:14:23.160]   he's really done that. Everyone's just announcing their intentions to negotiate. Well,
[00:14:23.160 --> 00:14:26.520]   you know, if the ports are holding the whole country hostage like this,
[00:14:26.520 --> 00:14:30.120]   that could cause a recession. I think that's going to rebound very badly on Biden.
[00:14:30.120 --> 00:14:36.200]   I think they're running 24/7 now, aren't they, Sax? Long Beach and LA are both running 24/7.
[00:14:36.200 --> 00:14:42.680]   Well, I just posted this article that came out, I mean, like yesterday, and it says it was published
[00:14:42.680 --> 00:14:47.000]   two days ago, and it said there was not a date certain for when this... Oh, it's updated October
[00:14:47.000 --> 00:14:52.040]   14th, which is yesterday. And if you read the bottom of the article, it says they have not
[00:14:52.040 --> 00:14:56.520]   determined a date for when 24/7 operations will start. They've just merely announced their
[00:14:56.520 --> 00:15:00.040]   intention to go 24/7. Oh, yeah, I'm just saying this. The Biden administration said,
[00:15:00.040 --> 00:15:03.800]   it's not really... They announced it as if it was a done-done, but it's not done.
[00:15:03.800 --> 00:15:07.720]   Look, unless Biden is willing to... Listen, I mean, Chamath, you're right that they're entitled
[00:15:07.720 --> 00:15:11.240]   to negotiate. But here's the thing. I mean, they're holding the whole country hostage now.
[00:15:11.240 --> 00:15:15.960]   They're holding the economy hostage. So at a certain point, if their demands are unreasonable,
[00:15:15.960 --> 00:15:20.280]   it's, I think, proper for the President of the United States to step in and say, "Guys,
[00:15:20.280 --> 00:15:25.480]   this is ridiculous. You have to go back to work. We're going to help negotiate a deal here."
[00:15:25.480 --> 00:15:29.160]   That's what Reagan did with the air traffic controllers. The air traffic controllers union
[00:15:29.160 --> 00:15:29.960]   shut down the whole... Yeah.
[00:15:29.960 --> 00:15:34.600]   ...commercial aviation system. Reagan got involved, said, "You cannot shut down
[00:15:34.600 --> 00:15:37.640]   the economy this way. You must go back to work." You can't strike.
[00:15:37.640 --> 00:15:40.200]   Yes, exactly. So I think Biden is probably going to have to get up for a year.
[00:15:40.200 --> 00:15:44.840]   Not that these longshoremen are... Or the ports. I guess they're not striking. They're just not
[00:15:44.840 --> 00:15:47.320]   doing an extra shift. But he could do an executive order.
[00:15:47.320 --> 00:15:51.480]   Look, if they're doing two shifts two hours a day, that's like withholding...
[00:15:51.480 --> 00:15:55.080]   That's like a partial strike. Wait, wait. They're doing two two-hour
[00:15:55.080 --> 00:15:56.920]   shifts or two eight-hour shifts? That's what Zach Hader was saying.
[00:15:56.920 --> 00:15:59.880]   Eight-hour shifts. They can't be doing two-hour shifts. Does that make sense?
[00:15:59.880 --> 00:16:01.160]   Would anybody go to work for two hours?
[00:16:01.160 --> 00:16:04.680]   Read what Zach Hader posted. He said that they're working just two shifts
[00:16:04.680 --> 00:16:06.200]   with a two-hour break in between.
[00:16:06.200 --> 00:16:09.400]   Okay. But those might be two eight-hour shifts with a two-hour break in between. That's how I
[00:16:09.400 --> 00:16:09.800]   read that.
[00:16:09.800 --> 00:16:15.800]   No, no, no. Read the tweet here. He says, "Before any changes this coming week,
[00:16:15.800 --> 00:16:20.920]   the longshore routine at the ports involved two shifts, 8:00 AM to 4:00 PM and 6:00 PM to 3:00 AM.
[00:16:20.920 --> 00:16:27.080]   An overnight shift of five hours is available, but is up to 50% more expensive and rarely used."
[00:16:27.080 --> 00:16:29.800]   So basically, you're talking about, yeah, it's an eight-to-five-hour shift. It's an eight-to-five-hour
[00:16:29.800 --> 00:16:34.200]   shift. It's a week-to-four-PM shift with a two-hour break or 6:00 PM to 3:00 AM. So basically, yes,
[00:16:34.200 --> 00:16:38.280]   so it is for that six-hour. That's two six-hour shifts.
[00:16:38.280 --> 00:16:41.560]   They should be running it like Elon runs the Tesla
[00:16:41.560 --> 00:16:45.240]   factors when they're building, which is 24 hours a day, overlapping shifts. Just get it done.
[00:16:45.240 --> 00:16:45.640]   Yeah, they're going to have to pay them overtime.
[00:16:45.640 --> 00:16:47.000]   There has to be a sense of urgency here.
[00:16:47.000 --> 00:16:49.960]   They're going to have to pay them some reasonable overtime, but they can't.
[00:16:49.960 --> 00:16:54.360]   The unions can't hold the whole country hostage. And look, if Biden, unless Biden steps in to solve
[00:16:54.360 --> 00:16:56.760]   this, we will have a recession. So it will rebound very bad.
[00:16:56.760 --> 00:16:58.520]   Oh, so we do think that this could be a recession?
[00:16:59.720 --> 00:17:03.720]   Bigger than just the ports. I don't think reopening the ports is the entirety of it.
[00:17:03.720 --> 00:17:07.160]   I think there's a lot of other things going on. I mean, Jake, out to a point, you've made,
[00:17:07.160 --> 00:17:12.040]   we had 4 million people drop out of the labor force last month. I mean, that was unbelievable.
[00:17:12.040 --> 00:17:16.920]   So yeah, the unemployment rate looks great, but the number of people actually going to work is
[00:17:16.920 --> 00:17:20.440]   significantly lower. I mean, that was a huge shock to all the economists seeing that many
[00:17:20.440 --> 00:17:25.560]   people drop out. There's still too many people who essentially are being paid not to work in
[00:17:25.560 --> 00:17:29.640]   one form or another, and that is hurting the economy. You also have this issue
[00:17:29.640 --> 00:17:35.560]   in China, which is very interesting. This was, I think, covered in the New York Times about how
[00:17:35.560 --> 00:17:42.600]   dependent Chinese factories are on coal, which is a bad thing. Obviously, that's not a clean energy
[00:17:42.600 --> 00:17:48.280]   source. But because of restrictions on coal, it's actually started to impact manufacturing over
[00:17:48.280 --> 00:17:52.200]   there. We can debate whether that's a good thing or bad thing, but it's contributing to the effect.
[00:17:52.200 --> 00:17:58.600]   I suspect that China has woken up to this and they're not going to shut down their economy
[00:17:58.600 --> 00:17:59.560]   because of concerns about clean energy. I think that's a good thing.
[00:17:59.560 --> 00:18:04.280]   So I assume this is a very temporary decision. And then, of course, you have the whole
[00:18:04.280 --> 00:18:09.400]   issue of COVID restrictions. I mean, there were a lot of international COVID restrictions. It wasn't
[00:18:09.400 --> 00:18:14.360]   just in the US where they were shutting down factories or creating a lot of rules that got
[00:18:14.360 --> 00:18:18.040]   in the way of keeping factories open. They were doing this internationally,
[00:18:18.040 --> 00:18:22.360]   and there was a lot of regulations around seafaring as well because of COVID restrictions.
[00:18:22.360 --> 00:18:29.480]   So you have this pileup, I would say, of regulations. Ultimately, I'd say with COVID
[00:18:29.480 --> 00:18:35.320]   as the origin that have now caused this supply chain crisis. And unless it gets fixed,
[00:18:35.320 --> 00:18:40.200]   it could absolutely cause a 1970s style stagflation type recession next year.
[00:18:40.200 --> 00:18:43.640]   Chamath, do you buy that? Do you think we could have this combination of
[00:18:43.640 --> 00:18:47.720]   people refusing to go to work or just opting out and saying like, "Yeah,
[00:18:47.720 --> 00:18:52.360]   even if you pay me 35 or 40, I'm just not interested. I have enough NFTs and I don't
[00:18:52.360 --> 00:18:53.400]   want to go back to work."
[00:18:53.400 --> 00:18:59.400]   I actually think that's exactly what it is. There was this really interesting tweet that I saw on Twitter. Hopefully, Nick, you can
[00:18:59.400 --> 00:19:05.560]   find it. But it was some kid that basically said, "I'm growing up in Atlanta, and there's a bunch of
[00:19:05.560 --> 00:19:12.360]   kids that I used to run with who would otherwise be in the streets causing all kinds of trouble.
[00:19:12.360 --> 00:19:19.240]   And these kids are now at home specking NFTs and posting on TikTok or whatever." It's just a
[00:19:19.240 --> 00:19:26.920]   completely different reimagination of labor and time spent. And that's just a very small example.
[00:19:26.920 --> 00:19:29.320]   And so that maybe touches retail or maybe touches
[00:19:29.320 --> 00:19:30.040]   the
[00:19:30.040 --> 00:19:34.440]   quick service restaurants. But there's all these different things where now that at the end of this
[00:19:34.440 --> 00:19:38.840]   pandemic, people are making very different decisions about their time and how to spend
[00:19:38.840 --> 00:19:42.600]   their money. And again, I'll tell you again, there's a lot of people. You got to remember,
[00:19:42.600 --> 00:19:48.440]   how many people in the United States have died or are dealing now with some reasonably
[00:19:48.440 --> 00:19:53.240]   important health issues at the back end of coronavirus? Half a million people? A million
[00:19:53.240 --> 00:19:59.240]   people? I want you to keep in mind what I told you guys before. There is 70 trillion dollars
[00:19:59.240 --> 00:20:03.960]   that has to get transferred down from all these baby boomers down to these people in their 20s,
[00:20:03.960 --> 00:20:09.160]   30s, and 40s. And don't think for a second that they're not making different optimization decisions
[00:20:09.160 --> 00:20:17.240]   around perceived wealth. So I just think inflation is here. I think the labor shortage is going to
[00:20:17.240 --> 00:20:21.880]   get worse, not better. I think we're going to have to pay people more to get out of it.
[00:20:21.880 --> 00:20:29.160]   I think prices are going up. Input costs are going up. Energy costs are going up. So
[00:20:29.160 --> 00:20:36.920]   this is it. And I think that probably the Fed and the ECB are really raising. This time next year,
[00:20:36.920 --> 00:20:41.320]   they're probably in a really, really tighter posture. What do you think, Freeberg?
[00:20:41.320 --> 00:20:46.760]   We should also remember that there are going to be some responses from-
[00:20:46.760 --> 00:20:49.560]   Sorry, Freeberg, last thing. Tech stocks in the fucking toilet.
[00:20:49.560 --> 00:20:51.880]   Why? Because of the multiples?
[00:20:51.880 --> 00:20:56.680]   Because of the multiples? No bueno for no cash flow growth stocks.
[00:20:56.680 --> 00:20:59.080]   Yeah. In rising rates.
[00:20:59.080 --> 00:21:02.360]   Everyone's going to start buying yield when- Yucky poops. Nobody wants it. Yucky poops.
[00:21:02.360 --> 00:21:06.280]   Well, wait. Let's explain this to the audience. Why, Freeberg? Why are you agreeing with
[00:21:06.280 --> 00:21:08.120]   your mouth? I mean, once interest rates go up,
[00:21:08.120 --> 00:21:12.440]   you'll see that dividend yields will go up, which means stock prices go down because people will
[00:21:12.440 --> 00:21:15.960]   expect a higher return. Because if I can buy treasury bonds and make a few points of return
[00:21:15.960 --> 00:21:20.920]   on my money, and I'm going to have to buy a stock, I'm going to demand a few more points
[00:21:20.920 --> 00:21:28.280]   of dividend yield on that stock. So the price for stocks will typically go down
[00:21:29.000 --> 00:21:32.200]   to match the yield that you're going to get from these more growth-free investments.
[00:21:32.200 --> 00:21:40.280]   No, no, no. To be more precise, a stock is either a promissory note about cash today
[00:21:40.280 --> 00:21:45.400]   or effectively a promissory note about cash in the future. The thing with tech stocks is we tell
[00:21:45.400 --> 00:21:49.000]   everybody the same thing. Your money is going to come 30 years from now because we're going
[00:21:49.000 --> 00:21:54.040]   to be a monopoly by then. And every dollar that I have today, I'm going to reinvest into R&D and
[00:21:54.040 --> 00:21:58.920]   engineering. And in an environment where interest rates are zero, you're happy to do it.
[00:21:58.920 --> 00:22:02.760]   Because you're like, "Well, great. These guys are investing at way better rates than zero,
[00:22:02.760 --> 00:22:08.440]   which is what I get from my bank. And so I want Facebook and Google and Amazon and all these
[00:22:08.440 --> 00:22:12.680]   startups to be putting all this money in the ground on my behalf." But when interest rates
[00:22:12.680 --> 00:22:17.640]   start going up, they say, "No, hold on a second. I need more money upfront, less money in the
[00:22:17.640 --> 00:22:22.120]   future because the future becomes more uncertain." And that's the big trade-off for tech companies,
[00:22:22.120 --> 00:22:24.040]   where they get really pummeled when rates go up.
[00:22:24.040 --> 00:22:26.920]   Okay. Well, is there a number in terms of the interest rate-
[00:22:26.920 --> 00:22:28.840]   There's a class of tech companies, right?
[00:22:28.840 --> 00:22:35.800]   Like Microsoft, Oracle, Google, where you are actually seeing an Apple, you're getting
[00:22:35.800 --> 00:22:39.640]   dividends and you're getting share buybacks, where the cash is coming out of the business.
[00:22:39.640 --> 00:22:43.800]   And those are the mature businesses that also still happen to have growth attached to them.
[00:22:43.800 --> 00:22:48.760]   And I don't see how portfolios are going to shed those assets. You're going to shed the
[00:22:48.760 --> 00:22:54.040]   more speculative, "Hey, we're not yet at a point of maturity. We're still 20, 30 years out."
[00:22:54.040 --> 00:22:54.520]   Peloton. Whatever.
[00:22:54.520 --> 00:22:58.440]   Whatever. Yeah. The guys that are investing and there's no line of sight to true cash flow coming
[00:22:58.440 --> 00:22:58.760]   back to the share.
[00:22:58.760 --> 00:22:59.800]   Yeah.
[00:22:59.800 --> 00:23:03.000]   But look, at the end of the day, the point I was trying to make earlier was that
[00:23:03.000 --> 00:23:08.920]   there is going to be a response, right? So we've seen, remember when the pandemic kind of set in
[00:23:08.920 --> 00:23:13.240]   and everyone started ordering from home, Amazon rushed out and hired 100,000 local delivery
[00:23:13.240 --> 00:23:17.560]   drivers. They bought all these trucks and they built their own supply chain infrastructure for
[00:23:17.560 --> 00:23:22.920]   last mile delivery to get products to people's homes. And we're now seeing on the other side,
[00:23:22.920 --> 00:23:28.680]   Walmart, Home Depot, Target, and other big retailers integrating their supply chain to get product that
[00:23:28.680 --> 00:23:33.160]   they can sell to people. And so they're starting to buy trucks, hire people, pay them significant
[00:23:33.160 --> 00:23:38.040]   wages to be drivers on staff for them, rather than contracting to these third parties that are saying,
[00:23:38.040 --> 00:23:41.160]   "Oh, we don't have any inventory. We don't have any trucks. We don't have any drivers. We can't
[00:23:41.160 --> 00:23:44.680]   do anything for you now." And so the response is, think about it. You're a product company.
[00:23:44.680 --> 00:23:50.920]   You're Tesla. Tesla just went out and did this massive deal in Caledonia to source some mineral
[00:23:50.920 --> 00:23:54.920]   that they need to make batteries or to make their cars. I can't remember exactly what it was.
[00:23:54.920 --> 00:23:55.480]   Nickel.
[00:23:55.480 --> 00:23:58.600]   But you're increasingly going to see the businesses that have a balance.
[00:23:58.600 --> 00:23:59.000]   Yeah.
[00:23:59.000 --> 00:24:02.680]   Step up and actually start to integrate their supply chains rather than have this...
[00:24:02.680 --> 00:24:03.320]   Be full stack.
[00:24:03.320 --> 00:24:04.200]   Yeah, rather than have this...
[00:24:04.200 --> 00:24:05.320]   More resilient.
[00:24:05.320 --> 00:24:05.880]   Yeah.
[00:24:05.880 --> 00:24:11.480]   This disparate set of service providers, each of which is all typically operating at max capacity,
[00:24:11.480 --> 00:24:15.480]   and then they can't respond to these sorts of jolts to the system. And so we're going to see
[00:24:15.480 --> 00:24:19.880]   a lot of investment, I think, by businesses that make product or deliver product to the consumer
[00:24:19.880 --> 00:24:23.320]   as they try and integrate the supply chain problem themselves. And that may take some
[00:24:23.320 --> 00:24:26.520]   of the strain off the system and some of this inflationary risk out of the equation.
[00:24:26.520 --> 00:24:28.520]   We'll see over the next couple of quarters. But certainly,
[00:24:28.520 --> 00:24:33.560]   in this last earnings report, I saw some statistic, a very large percentage of earnings reports
[00:24:33.560 --> 00:24:37.800]   spoke directly about supply chain disruption affecting the forecast for the business and
[00:24:37.800 --> 00:24:41.880]   the ability for the business to meet their forecast goals. And that's just hurting everyone.
[00:24:41.880 --> 00:24:43.240]   Okay. So throwing to Sachs...
[00:24:43.240 --> 00:24:45.800]   So they're going to have to do something about it if they're resourced to do it, right?
[00:24:45.800 --> 00:24:48.840]   All right. So Sachs, though, there are some silver linings here.
[00:24:48.840 --> 00:24:52.360]   Companies become more resilient. They become more automated.
[00:24:52.360 --> 00:24:58.440]   They build full stack. They build their own factories. We're seeing the Taiwanese
[00:24:58.440 --> 00:25:03.640]   semiconductor company is doing a $7 billion project to build a new factory in Japan,
[00:25:03.640 --> 00:25:07.000]   funded by the Japanese government. So we're seeing a lot of redundancy.
[00:25:07.000 --> 00:25:14.120]   And we're also seeing the middle class grow. If people are making $35 an hour, $40 an hour,
[00:25:14.120 --> 00:25:19.320]   and they're getting healthcare and they're starting to have overtime and other concessions
[00:25:19.320 --> 00:25:23.000]   being made, that builds the middle class. It sounds like we're solving some problems,
[00:25:23.000 --> 00:25:28.360]   as well as dealing with this, I guess what you call indigestion.
[00:25:28.360 --> 00:25:33.880]   Inflation is a good thing. I know people think it's a really bad, terrible thing.
[00:25:33.880 --> 00:25:40.200]   There are certain kinds of inflation that are really productive. We have had to find a way to
[00:25:40.200 --> 00:25:46.360]   fight the bad parts of technology. Technology is great. Nine out of 10 things, it's amazing.
[00:25:46.360 --> 00:25:52.200]   Efficiency, all these great characteristics that it gives you. But one crappy externality
[00:25:52.200 --> 00:25:58.280]   of technology is that it's deflationary. You can do more with less. And that's fundamentally not
[00:25:58.280 --> 00:26:01.720]   great for earnings. It's not great for labor participation. It's not great for all these
[00:26:01.720 --> 00:26:06.760]   things that people are really upset about today. It's great for the individual company getting
[00:26:06.760 --> 00:26:10.920]   those gains. I actually think it's kind of like it actually balances out the natural pace of
[00:26:10.920 --> 00:26:16.200]   technology, which is like you have the natural ability to just actually have cheaper,
[00:26:16.200 --> 00:26:20.040]   faster, better, this inherent efficiency that's building up on one side of the ledger.
[00:26:20.040 --> 00:26:23.720]   But then what's great is on the other side of the ledger, you actually have
[00:26:23.720 --> 00:26:27.720]   labor being able to balance it out. And I think that that's a really good thing because they can
[00:26:28.200 --> 00:26:30.760]   do more to do the rest of the work that's not covered by tech.
[00:26:30.760 --> 00:26:36.040]   So, Sax, what are your thoughts about this expanding middle class? Isn't it a great thing
[00:26:36.040 --> 00:26:40.760]   that people are saying, "I'll stay home instead of making 12 bucks an hour. It's an unfair wage.
[00:26:40.760 --> 00:26:44.760]   It's not a livable wage." And then all of these companies are saying, "You know what? Okay."
[00:26:44.760 --> 00:26:51.400]   They folded so quick, the big companies. They went to $18 to $35 an hour instantly. They always had
[00:26:51.400 --> 00:26:57.320]   the money to pay more. They just didn't need to. Increasing wages in real terms is a good thing.
[00:26:57.320 --> 00:26:58.120]   Increasing wages in real terms is a good thing. I think you have to ask
[00:26:58.120 --> 00:27:02.200]   why the wages are going up. Is it going up because of increased productivity,
[00:27:02.200 --> 00:27:05.560]   which is a good thing, or is it going up because of inflation? If it's going up
[00:27:05.560 --> 00:27:11.480]   because of inflation, then the wage gains are somewhat illusory because all the products
[00:27:11.480 --> 00:27:17.080]   that consumers want to buy are also going up in price. All we've done is devalue the dollar.
[00:27:17.080 --> 00:27:22.040]   So, we don't know yet whether these – Well, we do know that inflation is actually very high.
[00:27:22.040 --> 00:27:28.040]   We don't know exactly if these wage gains are permanent or just a function of that. But we
[00:27:28.040 --> 00:27:28.120]   don't know exactly if these wage gains are permanent or just a function of that. But we don't know exactly if these
[00:27:28.120 --> 00:27:31.160]   Let's go back to this inflation point for a second. I think this is actually
[00:27:31.160 --> 00:27:35.640]   really important. We're at something like a 5.1% inflation rate. It's just about the highest
[00:27:35.640 --> 00:27:42.040]   since the late '70s, early '80s. Now we have this threat of a supply chain crisis. This is
[00:27:42.040 --> 00:27:47.400]   potentially – No, we have a supply chain crisis. It's not a threat. I mean, if people can't sell
[00:27:47.400 --> 00:27:50.440]   cars, who thinks it's a crisis? Right. This is the recipe for stagflation 2.0. Now,
[00:27:50.440 --> 00:27:57.880]   I think there's an assumption that if inflation persists, the Fed will simply just fight it. The
[00:27:57.880 --> 00:28:00.600]   Fed will just fight it. They'll increase interest rates somewhat and they'll control it. But I
[00:28:00.600 --> 00:28:06.680]   actually think that the degrees of action that the Fed can take here might be more constrained
[00:28:06.680 --> 00:28:11.480]   than people think. I just want to flag – So, one of the primary sources I use for the national debt
[00:28:11.480 --> 00:28:18.680]   is this website, fred.stlouisfed.org. It's a good website that has a lot of charts by a branch of
[00:28:18.680 --> 00:28:26.840]   the Fed. So, they have this chart. We've seen that federal debt as a percentage of GDP is at all-time,
[00:28:26.840 --> 00:28:27.720]   peace-time, or whatever. So, they have this chart. We've seen that federal debt as a percentage of GDP is at sort of all-time, peace-time, or whatever.
[00:28:27.720 --> 00:28:28.200]   So, they have this chart. We've seen that federal debt as a percentage of GDP is at sort of all-time, peace-time, or whatever.
[00:28:28.200 --> 00:28:29.560]   So, they have this chart. We've seen that federal debt as a percentage of GDP is at sort of all-time, peace-time, or whatever.
[00:28:29.560 --> 00:28:34.360]   We were at 100% for a few years, and now, because of COVID, we just rocketed up over 120%.
[00:28:34.360 --> 00:28:41.240]   We're close to 140%. Now, the argument by mostly liberal economists that the debt didn't matter
[00:28:41.240 --> 00:28:45.880]   was because the debt service remained very low on this debt. So, we had a huge increase in debt,
[00:28:45.880 --> 00:28:52.040]   but because interest rates were so low, the debt service was still very, very small.
[00:28:52.040 --> 00:28:57.560]   They have a good piece on this website about this as well that I'll just post here in the
[00:28:57.560 --> 00:29:04.120]   notes. But I don't know if you guys remember back to a pod we did in May where we talked about
[00:29:04.120 --> 00:29:10.280]   Stanley Druckenmiller came out swinging against the Fed, and he warned about this very situation.
[00:29:10.280 --> 00:29:16.360]   I just want to just read this article that we covered back, I think, in May. It feels like an
[00:29:16.360 --> 00:29:21.240]   eternity ago. But do you remember when we just talked about this? What Druckenmiller warned is
[00:29:21.240 --> 00:29:26.200]   that if yields on the 10-year Treasury rise to the projected level of 4.9%, which is simply the
[00:29:26.200 --> 00:29:27.400]   historical average, it's going to be a 4.9% increase in the projected level of the 10-year Treasury.
[00:29:27.400 --> 00:29:31.800]   So, the government spending would be close to 30% of GDP each year, simply paying back
[00:29:31.800 --> 00:29:37.720]   interest expense compared to 2% last year, unless it monetizes the debt, which experts think is
[00:29:37.720 --> 00:29:40.680]   unlikely and Druckenmiller believes would have horrible implications for the US dollar.
[00:29:40.680 --> 00:29:45.800]   So, in other words, we now have this enormous debt. The only reason why debt service payments
[00:29:45.800 --> 00:29:50.840]   aren't crowding out the entire federal budget is because we've had interest rates at historically
[00:29:50.840 --> 00:29:57.240]   abnormal lows, zeros basically. So, how exactly is the Fed going to fight inflation? If they jack up interest
[00:29:57.240 --> 00:30:02.600]   rates to where they should be, say 4.9%, then the entire federal budget will be going to debt service.
[00:30:02.600 --> 00:30:06.280]   They're actually working against themselves, right? It's like you're the bank and taking
[00:30:06.280 --> 00:30:09.320]   the loan at the same time. This is like somebody who gets a variable interest
[00:30:09.320 --> 00:30:14.200]   mortgage and they get five, 10 years into their mortgage and then all of a sudden they go from
[00:30:14.200 --> 00:30:18.840]   interest only and some low interest rate and then they have to pay market rate and they realize they
[00:30:18.840 --> 00:30:22.200]   can't afford the home. We might not be able to afford the budget we're putting out there is what
[00:30:22.200 --> 00:30:22.840]   you're saying, Sax.
[00:30:22.840 --> 00:30:27.080]   Well, I'm saying the Fed may not have the tools, all the tools they want to fight inflation if it
[00:30:27.080 --> 00:30:31.160]   comes back. I mean, it's going to be politically very unpopular. I mean, can you imagine the
[00:30:31.160 --> 00:30:35.640]   pressure the Fed will be under not to raise rates if it means that all of these discretionary
[00:30:35.640 --> 00:30:39.720]   programs basically have to be cut, that we have an austerity mode in the federal budget? How are
[00:30:39.720 --> 00:30:43.560]   we going to pay for all this debt service? Yeah. And then the first thing they're going
[00:30:43.560 --> 00:30:48.280]   to think about is, hey, maybe we should cut military spending since it's the largest at the
[00:30:48.280 --> 00:30:56.200]   time when China is doing sorties in and around Taiwan and the South China Sea and we've got
[00:30:56.920 --> 00:31:03.560]   six navies doing coordinated sailing there, which I think is an adjacent issue here.
[00:31:03.560 --> 00:31:09.320]   Historically, great powers that want to remain great don't owe over 100% of their economy,
[00:31:09.320 --> 00:31:15.480]   especially when a lot of it's held by foreign powers. I mean, that is a situation that makes
[00:31:15.480 --> 00:31:22.120]   us fragile, not anti-fragile, right? Because if we hit a crisis, if there is some unforeseen
[00:31:22.120 --> 00:31:26.760]   military conflict, what glass do we break now in case of emergency? We've already
[00:31:26.760 --> 00:31:32.920]   spent, we're in peacetime and we have wartime levels of debt. And now inflation is making a
[00:31:32.920 --> 00:31:36.760]   return and the Fed is going to have to make some really tough choices about whether to control
[00:31:36.760 --> 00:31:43.560]   inflation and essentially impose austerity on government spending or whether they monetize the
[00:31:43.560 --> 00:31:48.120]   debt, which will lead to a runaway depreciation of the dollar. Neither one of those things is a
[00:31:48.120 --> 00:31:51.480]   good situation. How would the Fed impose austerity?
[00:31:51.480 --> 00:31:56.600]   Well, they can't. But again, if debt service rises to 30% of the federal budget, where's I
[00:31:56.600 --> 00:31:57.400]   going to come from?
[00:31:57.400 --> 00:32:01.000]   You have to raise taxes and cut spending. You have to do both.
[00:32:01.000 --> 00:32:04.440]   Which is why, and I think this is Joe Manchin's point. If you've been listening to Joe Manchin
[00:32:04.440 --> 00:32:09.320]   talk about the current reconciliation bill and he says, "Look, 3.5 trillion doesn't make sense.
[00:32:09.320 --> 00:32:14.440]   We don't know what situation we're going to confront in the future. We don't know what
[00:32:14.440 --> 00:32:18.440]   crises are coming. We're going to reduce our ability to tackle all those future problems
[00:32:18.440 --> 00:32:21.400]   by overspending right now." That's been Joe Manchin's argument.
[00:32:21.400 --> 00:32:26.440]   And looking at this risk of stagflation in the forms of the supply chain shortage,
[00:32:26.440 --> 00:32:31.960]   and this 5.1% interest rate number, you'd have to say that if we want to preserve any flexibility
[00:32:31.960 --> 00:32:36.840]   next year to raise interest rates, you better be really careful about how much debt you incur now.
[00:32:36.840 --> 00:32:39.400]   Jamal, agree?
[00:32:39.400 --> 00:32:47.160]   Yeah. Look, when Druck said that the 10-year break even was at a five-year high
[00:32:47.160 --> 00:32:56.280]   at the time, we're back there now. Look, I said this on CNBC. I'll just say it again.
[00:32:57.240 --> 00:33:04.680]   I think it's coming. I don't think it's a short-term blip. And I think that we are
[00:33:04.680 --> 00:33:13.640]   in a period that will resemble the late '70s. And I think that you want to be risk-off and not own
[00:33:13.640 --> 00:33:22.680]   risk assets. And by the way, it is hard because we are all, all of us, all four of us, we're both
[00:33:22.680 --> 00:33:26.120]   risk-on and all we own are risk assets that are going to be in the long run. And we're going to
[00:33:26.120 --> 00:33:27.400]   be in the long run. And we're going to be in the long run. And we're going to be in the long run.
[00:33:27.400 --> 00:33:31.160]   It's one thing to say, let's take risk, but you could take risk in lower of all things.
[00:33:31.160 --> 00:33:36.440]   This is like taking risk in the most risky thing. That's what we all do.
[00:33:36.440 --> 00:33:41.480]   Yes. And at a time when people have run up the valuations of private market companies to a level
[00:33:41.480 --> 00:33:46.760]   that just nobody can understand. I mean, look, I think you got a year to 18 months to clean this
[00:33:46.760 --> 00:33:52.520]   stuff up, meaning as market participants, we can shuck and jive and get everything into a decent
[00:33:52.520 --> 00:33:55.960]   place, but it's coming. And I hope I'm wrong. But...
[00:33:55.960 --> 00:33:59.960]   I think we'll look back on this and we'll say we set it probably
[00:33:59.960 --> 00:34:03.720]   eight to 12 months before it really reared its ugly head, but it's coming.
[00:34:03.720 --> 00:34:08.200]   Freeberg, any thoughts on what's happening in Taiwan and what,
[00:34:08.200 --> 00:34:15.720]   you know, even a modest conflict there would do to markets, given how to Sax's point, this is the
[00:34:15.720 --> 00:34:20.680]   opposite of anti-fragile. We are in like full fragility here. I mean, this is like, you know,
[00:34:20.680 --> 00:34:25.800]   a tray full of champagne glasses on a boat in rough seas. At any point we could trip and everything
[00:34:25.800 --> 00:34:30.280]   comes crashing down. Does it feel like that to you, Freeberg? Or do you feel like we're going to
[00:34:30.280 --> 00:34:36.200]   be able to navigate this? I mean, I don't know about Taiwan, but I think we're just going to
[00:34:36.200 --> 00:34:43.800]   keep inflating our way out of this mess. Remember, like that's what we did last year. And it's what
[00:34:43.800 --> 00:34:54.200]   we'll do again this year. The biggest losers in that equation are the middle class. Because the
[00:34:54.200 --> 00:34:55.640]   middle class actually owns assets. And they're going to be able to get the money back. And so,
[00:34:55.640 --> 00:34:56.360]   you know, we're going to have to keep the money back. And so, you know, we're going to have to
[00:34:56.360 --> 00:34:57.560]   keep the money back. And so, you know, we're going to have to keep the money back. And so,
[00:34:57.560 --> 00:34:58.360]   you know, we're going to have to keep the money back. And so, you know, we're going to have to
[00:34:58.360 --> 00:34:59.080]   keep the money back. And so, you know, we're going to have to keep the money back. And so,
[00:34:59.080 --> 00:35:02.440]   folks who are not in the middle class that are below the middle class don't own assets. So it
[00:35:02.440 --> 00:35:07.320]   doesn't really affect them. They just make higher wages, but stuff costs more, so they'll be fine.
[00:35:07.320 --> 00:35:12.040]   And then, you know, wealthy individuals will end up getting taxed away
[00:35:12.040 --> 00:35:17.160]   to fund some of this. And I think that's the inevitable kind of way that the equation balances.
[00:35:17.160 --> 00:35:21.080]   Right. I mean, think about how much tax rates are about to go up right now in
[00:35:21.080 --> 00:35:25.800]   this reconciliation bill. We haven't even gotten to like any of these crises. By the way, we don't
[00:35:25.800 --> 00:35:29.080]   know for sure if they're going to happen. I think we could describe these things as storm clouds
[00:35:29.080 --> 00:35:33.160]   right now that are very much on the horizon. Multiple storm clouds, right?
[00:35:33.160 --> 00:35:35.080]   Multiple storm clouds. It's sort of like they're converging.
[00:35:35.080 --> 00:35:39.640]   Right. And if they do materialize in the way that we're talking about, what weapons do we have left
[00:35:39.640 --> 00:35:43.640]   in order to fight them? What weapons of fiscal policy? What weapons of monetary policy? We're
[00:35:43.640 --> 00:35:45.960]   already going to have taxes at an all-time high. Yeah.
[00:35:45.960 --> 00:35:48.440]   Yeah. Well, we're going to have taxes. We're going to print money. No, we're going to print
[00:35:48.440 --> 00:35:50.920]   money and we're going to pay ourselves. We're going to go to the central bank,
[00:35:50.920 --> 00:35:56.360]   and it's what you said, we're going to monetize our debt. And that is a disaster.
[00:35:56.360 --> 00:36:03.320]   Remember, the top marginal tax rate was what? 70, 80% in the 60s and 70s. I mean,
[00:36:03.320 --> 00:36:05.800]   that's likely where we're going to go back to.
[00:36:05.800 --> 00:36:09.320]   Well, I think we're already going to be back there as a result of the reconciliation.
[00:36:09.320 --> 00:36:10.920]   The spending we've already done. Yeah.
[00:36:10.920 --> 00:36:14.440]   Right. So we've already broken the glass in case of emergency. We've already done-
[00:36:14.440 --> 00:36:18.840]   You're going to see some of these wealth taxes get chased down. You're going to see the top
[00:36:18.840 --> 00:36:20.760]   marginal tax rate go up 70, 80%.
[00:36:20.760 --> 00:36:24.200]   Yeah. I mean, I think that's the way the equation balances. It's not like the world's going to end.
[00:36:24.200 --> 00:36:28.600]   We're going to solve it by taking assets away from some, and we're going to inflate all assets.
[00:36:28.600 --> 00:36:29.560]   That sounds pretty bad.
[00:36:29.560 --> 00:36:33.480]   Yeah. Yeah. I mean, 78, if you-
[00:36:33.480 --> 00:36:34.440]   By the way, it's not going to affect-
[00:36:34.440 --> 00:36:37.000]   It's not going to affect who's going to work and taking the risk.
[00:36:37.000 --> 00:36:40.920]   That's not a solution, Freeberg. It will affect most people. It will affect most people,
[00:36:40.920 --> 00:36:44.200]   even though they don't think it will, because it's going to affect the quality of our economy.
[00:36:44.200 --> 00:36:46.840]   I'm just trying to predict what's going to happen, Sax. I'm not saying this is the
[00:36:46.840 --> 00:36:50.600]   solution to our problem. I mean, I think the solution to our problem is technology, but
[00:36:50.600 --> 00:36:52.680]   you know, the question is, does that come to market fast enough?
[00:36:52.680 --> 00:36:54.440]   Say more about that.
[00:36:54.440 --> 00:36:57.640]   I feel like we need a deflationary set of technologies that can
[00:36:57.640 --> 00:37:04.040]   mitigate all of these effects, right? So software, automation, self-driving trucks,
[00:37:04.040 --> 00:37:08.840]   things that take the labor force, because people don't want to work low-income jobs, factually.
[00:37:08.840 --> 00:37:11.080]   Full stop. In America.
[00:37:11.080 --> 00:37:16.280]   In America, now that there's a world where people have other options because other jobs have been
[00:37:16.280 --> 00:37:20.440]   created because we've pumped so much money into these other industries, we're seeing people,
[00:37:20.440 --> 00:37:25.880]   people migrate away from low-income jobs, like driving a truck for $10 an hour or working at
[00:37:25.880 --> 00:37:30.840]   McDonald's for $8 an hour. And so to fill that gap and avoid the economic collapse that will occur in
[00:37:30.840 --> 00:37:35.720]   those sectors of the economy, you need to automate and you need to find solutions that can replace
[00:37:35.720 --> 00:37:40.440]   the labor with some alternative technology solution that actually allows the product to
[00:37:40.440 --> 00:37:44.600]   be fulfilled to the consumers that demand it. Or you're going to see rates go up, like you're going
[00:37:44.600 --> 00:37:48.120]   to be paying $12 for a hamburger because you're going to have to pay everyone $25 for working
[00:37:48.120 --> 00:37:48.520]   McDonald's.
[00:37:48.520 --> 00:37:50.280]   Would an easy or Chamath or Sax,
[00:37:50.280 --> 00:37:52.920]   either you can take it. I'm sure you're both going to have opinions here. But
[00:37:52.920 --> 00:37:58.280]   we've been battling over immigration and nobody even seems to understand how many people are
[00:37:58.280 --> 00:38:03.720]   coming into the country or under what system. Should we not tie the number of jobs available
[00:38:03.720 --> 00:38:08.520]   over the trailing X number of months, years, quarters, to how many people we're bringing
[00:38:08.520 --> 00:38:12.040]   to the country? And couldn't we solve this by allowing 5 million people, a million people,
[00:38:12.040 --> 00:38:16.760]   whatever it is per year, a half million people in to take those low-income jobs and utilize that
[00:38:16.760 --> 00:38:20.120]   group of people to get businesses-
[00:38:20.120 --> 00:38:21.080]   Businesses back on track?
[00:38:21.080 --> 00:38:25.080]   I think it's too convenient to say that these are all low-income jobs. I don't think
[00:38:25.080 --> 00:38:30.360]   that's necessarily true. And I think that it then starts to introduce a whole bunch of other
[00:38:30.360 --> 00:38:34.600]   constraints to the system. These are folks that then need healthcare. These are folks that need
[00:38:34.600 --> 00:38:40.600]   childcare. These are folks that need, you know, that they are also a tax on resources as well,
[00:38:40.600 --> 00:38:44.760]   right? We are all taxed on the natural resources and the infrastructure of our country.
[00:38:44.760 --> 00:38:49.960]   And so, you know, I don't think that that's the solution necessarily to that specific
[00:38:49.960 --> 00:38:50.280]   problem.
[00:38:50.280 --> 00:38:53.880]   But what if the jobs that were, the people who are coming in-
[00:38:53.880 --> 00:38:55.960]   We have enough people here to do the work.
[00:38:55.960 --> 00:38:57.000]   But they won't do it.
[00:38:57.000 --> 00:39:00.040]   What we don't have is a market clearing price for that work to get done.
[00:39:00.040 --> 00:39:05.160]   And so, what I'm just trying to say is I think that the simpler and more obvious solution
[00:39:05.160 --> 00:39:11.320]   is to raise salaries until you get people to fill these jobs. And I think that it's happening. And so,
[00:39:11.320 --> 00:39:14.840]   I do think that over the next year or two or three, you're going to see,
[00:39:14.840 --> 00:39:19.800]   you know, labor rates basically go back up and employment rates go back down and salaries,
[00:39:19.800 --> 00:39:24.520]   salaries go back up and inflation go back up. All of these things are going to happen together.
[00:39:24.520 --> 00:39:29.640]   That's the solution. I think immigration is a solution to a completely different problem.
[00:39:29.640 --> 00:39:30.760]   Which is?
[00:39:30.760 --> 00:39:34.120]   Which is that we're not competitive. Like, I've-
[00:39:34.120 --> 00:39:38.280]   Oh, so you're talking about bringing in elite, highly educated technical people.
[00:39:38.280 --> 00:39:42.920]   Look, I really think that running a country should really be like running a sports team,
[00:39:42.920 --> 00:39:44.680]   you know, and-
[00:39:44.680 --> 00:39:46.040]   Recruit the best talent, period.
[00:39:46.040 --> 00:39:49.640]   And you should really be recruiting the best talent. You should be looking at game film.
[00:39:49.640 --> 00:39:53.400]   You should be coming up with plays. You should be running and testing those plays.
[00:39:53.400 --> 00:39:57.320]   You know, you should have different plays that you run in the first quarter versus the fourth quarter,
[00:39:57.320 --> 00:39:58.840]   different plays when you're on the goal line.
[00:39:58.840 --> 00:39:59.320]   Sure.
[00:39:59.320 --> 00:40:03.080]   You know, and I think that like when you look at professional sports,
[00:40:03.080 --> 00:40:08.440]   one thing is that they don't see color, gender, sexual orientation. They see ability to be
[00:40:08.440 --> 00:40:09.000]   performant.
[00:40:09.000 --> 00:40:09.640]   Statistics.
[00:40:09.640 --> 00:40:10.360]   At a task.
[00:40:10.360 --> 00:40:10.760]   Performance.
[00:40:10.760 --> 00:40:12.200]   And statistical excellence.
[00:40:12.200 --> 00:40:12.680]   Yeah.
[00:40:12.680 --> 00:40:16.920]   And then they go seek statistical excellence. And if you translate that to a country,
[00:40:16.920 --> 00:40:19.480]   my simple rubric on immigration is,
[00:40:19.480 --> 00:40:27.080]   every year there's a draft and America is the free place every free agent wants to go.
[00:40:27.080 --> 00:40:28.520]   We're the Yankees. Yeah, we're the Warriors.
[00:40:28.520 --> 00:40:28.840]   Yeah.
[00:40:28.840 --> 00:40:30.280]   All right, fuck the Yankees.
[00:40:30.280 --> 00:40:31.880]   We're like the Warriors.
[00:40:31.880 --> 00:40:34.680]   Yankees are trash. Jesus Christ.
[00:40:34.680 --> 00:40:35.160]   I'm just going with the-
[00:40:35.160 --> 00:40:35.560]   A horrible fucking example.
[00:40:35.560 --> 00:40:37.080]   Who historically has won the most-
[00:40:37.080 --> 00:40:38.360]   We're the New England Patriots.
[00:40:38.360 --> 00:40:38.920]   Okay.
[00:40:38.920 --> 00:40:39.320]   Cheaters.
[00:40:39.320 --> 00:40:44.280]   We're the Chicago Bulls. We're the, you know, we are the team that everybody would want to play for.
[00:40:44.280 --> 00:40:49.320]   It's up to us to have a good GM and a good president of the team and a good front office.
[00:40:49.320 --> 00:40:51.720]   That just picks off all these smart geniuses.
[00:40:51.720 --> 00:40:54.520]   Take the- this should be- I think your great point here, Chamath, is you're saying,
[00:40:54.520 --> 00:40:58.360]   let's take the emotion out of this immigration and let's make it a point-based system.
[00:40:58.360 --> 00:40:58.680]   It's so stupid.
[00:40:58.680 --> 00:41:02.760]   Which by the way, the point-based system is what Australia, New Zealand, the UK,
[00:41:02.760 --> 00:41:06.280]   Canada all do. And Americans don't even know what the point-based system is.
[00:41:06.280 --> 00:41:13.560]   Sax, what are your views as somebody who I've heard leans a little bit to the right
[00:41:13.560 --> 00:41:19.160]   on opening up immigration or maybe sweeping all this amazing talent globally who have the highest
[00:41:19.160 --> 00:41:20.280]   statistics? Go.
[00:41:20.280 --> 00:41:26.360]   I like Chamath's sports team analogy. We want to get the biggest stars from all over the
[00:41:26.360 --> 00:41:30.840]   world to come to the US. I mean, I think that makes sense. I think, you know, this so-called
[00:41:30.840 --> 00:41:34.120]   immigration issue gets so confused with so many different things. I mean, first of all,
[00:41:34.120 --> 00:41:38.360]   there's immigration and then there's border security, right? And immigration or just having
[00:41:38.360 --> 00:41:44.200]   a border period. And so many people think that if you're pro-immigration, you basically can't
[00:41:44.200 --> 00:41:49.000]   have a border. I mean, that makes no sense. You know, we need to have a border and
[00:41:49.000 --> 00:41:53.960]   we need to have actual, like have an actual immigration policy. Shouldn't just get be like,
[00:41:53.960 --> 00:41:56.920]   okay, you make it across. I like what you're saying.
[00:41:56.920 --> 00:42:00.200]   If you were president or if you're a guy, Ron DeSantis becomes president,
[00:42:00.200 --> 00:42:03.720]   what will you tell Ron since you're hosting the fundraiser?
[00:42:03.720 --> 00:42:06.600]   I like what you're saying with the point system, having it be skills-based. I mean,
[00:42:06.600 --> 00:42:07.560]   that makes sense, right? I mean-
[00:42:07.560 --> 00:42:12.680]   Would the Republicans do that? They've been so emotionally tied to this issue because of Trump.
[00:42:12.680 --> 00:42:18.840]   Can they actually, you know, tie themselves to something performance-based and be not-
[00:42:18.840 --> 00:42:20.680]   Super emotional about it? Can they change their position?
[00:42:20.680 --> 00:42:26.680]   I think Trump actually did endorse like a more skills-based immigration system. I think
[00:42:26.680 --> 00:42:29.320]   that, and I don't know that the Republicans are the ones being emotional about it. I mean,
[00:42:29.320 --> 00:42:30.600]   the people who are here- Well, no, both sides are
[00:42:30.600 --> 00:42:33.160]   clearly super emotional about it. Yeah. I mean, the side that I think
[00:42:33.160 --> 00:42:37.240]   is like insane are the people who don't think we need a border. I mean, you clearly have to have a
[00:42:37.240 --> 00:42:37.720]   border. That's insane? Yes.
[00:42:37.720 --> 00:42:41.720]   Yes. And even Obama came out recently and made a statement that you have to have a border
[00:42:41.720 --> 00:42:48.680]   because the progressive left had gone so far. It's almost like they want it to be, whatever
[00:42:48.680 --> 00:42:53.320]   Trump was doing, they want to do the opposite of. You know, it's like pull the 180. And so it's
[00:42:53.320 --> 00:42:58.760]   almost like the Biden administration policy became to stop doing whatever it was that Trump was doing,
[00:42:58.760 --> 00:43:03.480]   including finishing the wall. I don't really understand why that was like such a problem.
[00:43:03.480 --> 00:43:06.920]   Or even, yeah, building a wall also seemed like ridiculous. We could just put up sensors-
[00:43:06.920 --> 00:43:10.840]   It's just one piece. It's just one piece of the solution, but to stop it in mid-construction-
[00:43:10.840 --> 00:43:14.520]   Let me ask you a question. It broke this week that you're hosting
[00:43:14.520 --> 00:43:18.520]   a fundraiser for Ron DeSantis. You got a little bit of blowback from that.
[00:43:18.520 --> 00:43:21.640]   Yeah. From the woke, you know, in the San
[00:43:21.640 --> 00:43:25.880]   Francisco crowd. But in terms of your influence with somebody like that, do you think you can
[00:43:25.880 --> 00:43:30.280]   actually influence them to get Ron DeSantis to listen to this episode and maybe talk about the
[00:43:30.280 --> 00:43:34.120]   point-based system and change the framing of that? Do you think you have enough influence to do that?
[00:43:34.120 --> 00:43:37.640]   I don't know. I mean, I don't know exactly what his position on immigration is.
[00:43:37.640 --> 00:43:42.280]   That's not, that's not like the set of issues that's, that I respect him for. I mean,
[00:43:42.280 --> 00:43:48.360]   the reason why I wanted to support DeSantis is that he was the first governor to end these
[00:43:48.360 --> 00:43:53.640]   insane lockdowns. And I mean, this was back in, it should have been obvious to everybody by May of
[00:43:53.640 --> 00:44:01.000]   2020 that the lockdowns didn't work. And he was the first one to roll them back. And Florida did
[00:44:01.000 --> 00:44:05.480]   very well, especially considering that they have so many old people in Florida. So, you know, on
[00:44:05.480 --> 00:44:09.000]   the whole, not what I have done everything exactly the way he did it. No, you know, but-
[00:44:09.000 --> 00:44:14.200]   Nobody did it perfect. But is he a Trump supporter and a Trump acolyte,
[00:44:14.200 --> 00:44:16.040]   or is he distancing himself from Trump?
[00:44:16.040 --> 00:44:17.400]   I think,
[00:44:18.200 --> 00:44:22.600]   honestly, I think that like point of view is coming from the point of view of somebody who's
[00:44:22.600 --> 00:44:26.760]   not in the Republican party. It doesn't have to deal with the dynamics of winning support in the
[00:44:26.760 --> 00:44:30.120]   Republican party. No, no, no. That's what I'm saying. Yeah. So you, you have to basically toe
[00:44:30.120 --> 00:44:33.640]   the line with Trump to get the nomination. I don't, I don't see it as towing the
[00:44:33.640 --> 00:44:37.320]   line. I just think, look, I think he's his own person. He's the governor of Florida.
[00:44:37.320 --> 00:44:42.440]   He's setting policy over there. He can be supported or not based on what he's doing in
[00:44:42.440 --> 00:44:48.040]   Florida. I think like Trump is the issue that everybody on the other side will want to talk
[00:44:48.040 --> 00:44:52.920]   about, but I don't think it's relevant to what he's doing. I don't think it's relevant to what
[00:44:52.920 --> 00:44:56.040]   he's doing. Isn't there a civil war inside of the Republican party over this? And should we support
[00:44:56.040 --> 00:45:03.240]   Trump? I wouldn't say it's a civil war, but there definitely is some, some conflict and yeah.
[00:45:03.240 --> 00:45:05.640]   How does it resolve?
[00:45:05.640 --> 00:45:10.520]   I hope it resolves in, oh, look, I think elections are always about the future. I don't think people
[00:45:10.520 --> 00:45:16.440]   want to relitigate the past. And I think that, and I think that the Republican party be wise,
[00:45:16.440 --> 00:45:17.880]   I think, to find a,
[00:45:17.880 --> 00:45:22.760]   a candidate of the future and not try to rehash or relitigate the past. Another good reason for
[00:45:22.760 --> 00:45:29.800]   me to support DeSantis. I think he is a future looking future oriented candidate. I do think
[00:45:29.800 --> 00:45:35.240]   that, look, I'll say it, the stuff I hear Trump doing now in these speeches where he's relitigating
[00:45:35.240 --> 00:45:41.720]   what happened last year and, and, and attacking other Republicans like McConnell, because he
[00:45:41.720 --> 00:45:47.240]   doesn't, because they failed his personal loyalty test. It's a little bit like what he did, frankly,
[00:45:47.240 --> 00:45:47.720]   in Georgia.
[00:45:47.720 --> 00:45:48.040]   Yeah.
[00:45:48.040 --> 00:45:54.360]   With the runoffs where he sowed so much chaos that the Republicans lost a seat,
[00:45:54.360 --> 00:45:59.400]   the produce seat that they had won on election night. And then they had that runoff. And you
[00:45:59.400 --> 00:46:04.600]   have to say that a huge part of the reason for that was the, was Trump attacking Raffles burger
[00:46:04.600 --> 00:46:08.920]   and, and all the, the Georgia GOP, because he thought they were insufficiently loyal to him.
[00:46:08.920 --> 00:46:12.280]   And then, you know, you had the whole, the tape come out of, can you just find
[00:46:12.280 --> 00:46:17.560]   11,000 votes? I mean, I think voters in Georgia punished the Republican
[00:46:17.560 --> 00:46:23.640]   party for that by, by giving that seat to the Democrats. That is the, that, that margin created
[00:46:23.640 --> 00:46:28.440]   the Democratic majority, which will now give us probably an incremental four to 6 trillion of
[00:46:28.440 --> 00:46:32.680]   spending and tax increases that we wouldn't otherwise have had. So I, I do think these
[00:46:32.680 --> 00:46:37.320]   elections are very important and it would behoove the Republicans. Look, I'm not, I'm not like one
[00:46:37.320 --> 00:46:41.400]   of these never Trumper people who I'm just not obsessed with Trump period. I just think the
[00:46:41.400 --> 00:46:47.400]   Republicans need to run a future looking candidate, not a backwards looking candidate in 2024. And,
[00:46:47.400 --> 00:46:51.240]   and I think DeSantis could be that guy. It's very, very early to say, I mean, the first thing he has
[00:46:51.240 --> 00:46:57.560]   to do is run for governor, uh, for reelection in, uh, which I think is next year is 2022.
[00:46:57.560 --> 00:46:59.480]   So I will support him for that. All right.
[00:46:59.480 --> 00:47:03.000]   Did you guys, anybody read the Ted Sarandos memo?
[00:47:03.000 --> 00:47:07.080]   Yeah, this is great. They should definitely jump into this. We talked about, uh, the Chappelle
[00:47:07.080 --> 00:47:09.240]   performance, uh, Sacks and, uh, Freebird. You guys watch it?
[00:47:09.240 --> 00:47:10.280]   You guys watch it? You hadn't seen it. Did you watch it?
[00:47:10.280 --> 00:47:13.240]   Yeah, did you watch it? Oh God. What nerd?
[00:47:13.240 --> 00:47:15.240]   You haven't watched it yet? Oh my God.
[00:47:15.240 --> 00:47:19.880]   You guys are culturally bankrupt. What were you guys doing this week? Like fucking beakers and
[00:47:19.880 --> 00:47:24.920]   like, you know, Sacks, you were just like, were you like in like some laboratory doing like sass
[00:47:24.920 --> 00:47:29.000]   testing? I haven't watched it yet, but I don't need to watch it to know I support it.
[00:47:29.000 --> 00:47:34.760]   He's just, yeah. He doesn't have to click on the link. All right.
[00:47:34.760 --> 00:47:40.200]   There's almost nothing Chappelle could say to make me want to cancel him. I mean,
[00:47:40.200 --> 00:47:45.080]   and by the way, I've seen a lot of Chappelle and I love Chappelle. So I think I understand that just
[00:47:45.080 --> 00:47:49.640]   what he was doing, but I do need to see it still. But look, he should not be canceled. It's
[00:47:49.640 --> 00:47:53.960]   ridiculous. I don't think he is. He's going to survive.
[00:47:53.960 --> 00:47:58.520]   Of course. Well, this goes beyond this. Um, let me, uh, read you from it. So
[00:47:58.520 --> 00:48:03.080]   everybody knows that the name of the, uh, special he did was the closer. It was released on October
[00:48:03.080 --> 00:48:10.920]   5th. A lot of outcry from GLAAD and, uh, advocacy groups and actually people inside of, uh, Netflix.
[00:48:10.920 --> 00:48:14.920]   There's been some resignations. There have been some people who contribute content.
[00:48:14.920 --> 00:48:19.000]   To Netflix who are now saying they'll not work with the company. And, um,
[00:48:19.000 --> 00:48:24.360]   really interesting. Ted Saranto sent a memo to the entire company on Monday and he's,
[00:48:24.360 --> 00:48:29.400]   this is the second one he sent. And he says, we know that a number of you have been left angry,
[00:48:29.400 --> 00:48:33.960]   disappointed, and hurt by our decision to put Dave Chappelle's latest special on Netflix.
[00:48:33.960 --> 00:48:38.120]   Very interesting opening. Uh, he's, he's addressing their feelings. Just this is a
[00:48:38.120 --> 00:48:42.600]   masterclass in a memo. Cause in that first part, he just addresses, I understand you feel that way
[00:48:42.600 --> 00:48:44.760]   with the closer. We understand.
[00:48:44.760 --> 00:48:50.360]   That the concern is not about offensive to some content, but titles, which could increase
[00:48:50.360 --> 00:48:55.160]   real world harm. So now he's framing their argument as it's not cause it's offensive.
[00:48:55.160 --> 00:48:59.800]   It's cause of real world harm. You brought this up before SACS, the real world harm concept with,
[00:48:59.800 --> 00:49:05.800]   um, Apple and, uh, Antonio, while some employees disagree, we have a strong belief that content on
[00:49:05.800 --> 00:49:10.200]   screen does not directly translate into real world harm. It's not exactly true. Uh, we'll get into
[00:49:10.200 --> 00:49:14.600]   that. The strongest evidence to support this is that violence on screens has grown hugely over
[00:49:14.600 --> 00:49:19.320]   the last 30 years, especially with first party shooter games. And yet violent crime has fallen
[00:49:19.320 --> 00:49:25.080]   significantly in many countries. Uh, and so he goes above and beyond just talking about offensive
[00:49:25.080 --> 00:49:32.120]   material. Uh, adults can watch violence, assault and abuse, or enjoy shocking standup comedy
[00:49:32.120 --> 00:49:37.720]   without it causing them to harm other standup comedians often expose issues that are
[00:49:37.720 --> 00:49:42.440]   uncomfortable because the art by nature is highly provocative. As a leadership team,
[00:49:42.440 --> 00:49:44.440]   we do not believe that the closer is intended to
[00:49:44.440 --> 00:49:50.200]   incite hatred or violence against anyone, poor sensitive content guidelines. So basically he says,
[00:49:50.200 --> 00:49:54.600]   you know, if you don't like it, change the channel. If you're a customer, you can cancel
[00:49:54.600 --> 00:49:57.960]   your subscription or if you work here and you don't like it, you don't need to work here.
[00:49:57.960 --> 00:50:02.520]   But is this the end of cancel culture? This combined with Brian Armstrong's positioning
[00:50:02.520 --> 00:50:04.840]   SACS. This is your, I don't, I don't think it's the end of it.
[00:50:04.840 --> 00:50:08.760]   Uh, for the simple reason, um, let's assume that this comic
[00:50:08.760 --> 00:50:14.280]   had not signed a $60 million deal with, with Netflix. Let's say he had signed a $60,000 deal.
[00:50:14.280 --> 00:50:19.560]   Okay. Or 6 million or whatever. And, uh, and, and he didn't have the legions of fans
[00:50:19.560 --> 00:50:24.360]   that, that Dave Chappelle had. Do you think that Sarandos would make making the same decision?
[00:50:24.360 --> 00:50:30.920]   I mean, I think that's special by, you know, uh, by, uh, a, a, a Netflix comedy by Dave Smith
[00:50:30.920 --> 00:50:34.200]   would be swept under the rug right now. We, that would never see the light of day.
[00:50:34.200 --> 00:50:37.320]   Uh, I think the same thing was true with Joe Rogan and Spotify, right? I mean,
[00:50:37.320 --> 00:50:44.120]   uh, Spotify made a $60 million deal with Rogan, uh, the employee, oh, a hundred million. The employees all
[00:50:44.120 --> 00:50:50.200]   protested and Spotify stood tall for Rogan, but they had every economic incentive to do so.
[00:50:50.200 --> 00:50:55.320]   I don't completely trust these companies that if it wasn't massively in their bottom line interest,
[00:50:55.320 --> 00:50:59.160]   that they would have stood up for free speech. I suspect that if it was, you know,
[00:50:59.160 --> 00:51:02.120]   they would not have, they would not have, I think we all kind of know that.
[00:51:02.120 --> 00:51:06.600]   He said in the email sticks and stones is one of the most watched, you know, piece of content we
[00:51:06.600 --> 00:51:12.520]   have. And this, the closer was like top four or five in America, uh, over like the last few weeks.
[00:51:12.520 --> 00:51:13.960]   Right. So there's a huge,
[00:51:13.960 --> 00:51:18.520]   huge economic incentive and, and, and Reed Hastings said the same thing when he posted
[00:51:18.520 --> 00:51:24.920]   the other co-CEO into a group forum, which said, listen, our job is to please our customers.
[00:51:24.920 --> 00:51:28.600]   And all this data says is that we've pleased our customer.
[00:51:28.600 --> 00:51:35.240]   Right. And I think in the case of, right. And I think to me, that's him putting his foot down
[00:51:35.240 --> 00:51:39.160]   and saying, we're going to make the content we want to make. I don't think it's a principle.
[00:51:39.160 --> 00:51:42.840]   I don't think it's a super look. I don't want to, I don't want to look past it because I think that
[00:51:42.840 --> 00:51:43.800]   it's so rare.
[00:51:43.800 --> 00:51:50.760]   To get a memo like, uh, Sarandos wrote, uh, where he's defending artistic freedom or
[00:51:50.760 --> 00:51:54.040]   freedom of speech or what have you. I mean, it's so rare to ever see that,
[00:51:54.040 --> 00:51:57.800]   that I don't want to, um, gain, say it too much, but I also do believe
[00:51:57.800 --> 00:52:04.040]   that this sort of special treatment is really reserved for the, for the artists,
[00:52:04.040 --> 00:52:08.520]   the creators like a Chappelle, like a Rogan. They're basically too big to cancel. I mean,
[00:52:08.520 --> 00:52:13.640]   these companies have spent too much money on their programs to just summarily cancel them.
[00:52:13.640 --> 00:52:17.320]   Uh, they also, again, like I said, have legions of fans who would rise up and protest
[00:52:17.320 --> 00:52:20.920]   if they were canceled. But I don't think, but I don't think these companies would make the same
[00:52:20.920 --> 00:52:26.520]   decision for the, the, the middle, the mid-level creator. And in a sense, Rogan and Chappelle,
[00:52:26.520 --> 00:52:31.000]   they're post-economic, right? I mean, they've made so much money that they're free to do what
[00:52:31.000 --> 00:52:34.760]   they want and they've got a big enough audience to protect themselves from these companies.
[00:52:34.760 --> 00:52:39.160]   But it's the little creator who's still on their way up, who could never take the kinds of creative
[00:52:39.160 --> 00:52:41.560]   risks that Chappelle is taking or that Rogan is taking.
[00:52:41.560 --> 00:52:43.480]   Well, they can take it. They just can't do it on Netflix.
[00:52:43.480 --> 00:52:49.640]   But I, I, I, the, the tone of this to me sound sounded like a manifesto and, uh, uh, the end of
[00:52:49.640 --> 00:52:54.520]   the discussion from dad, like we're doing this. If you don't like it, get off the ship, but this
[00:52:54.520 --> 00:52:58.520]   is the way the ship is going. That's the way I read it. And I think Spotify did a similar thing
[00:52:58.520 --> 00:53:03.720]   with, um, Joe Rogan to your point, which was, Hey, listen, there was some content out there
[00:53:03.720 --> 00:53:08.200]   from like Alex Jones or some people who are just conspiracy theorists. They took down those
[00:53:08.200 --> 00:53:13.320]   episodes and Joe Rogan was like, I don't care. I got paid. Um, but yeah, it does feel to me like
[00:53:13.320 --> 00:53:16.920]   this is a tipping point when you put Brian Armstrong, Joe Rogan and Chappelle together
[00:53:16.920 --> 00:53:21.800]   that corporations are going to say, you know what the mob is fine. You can have your opinion,
[00:53:21.800 --> 00:53:25.160]   but your opinion stops where we have to run a business. Freebird. What are your thoughts?
[00:53:25.160 --> 00:53:30.920]   I, I think, I think Netflix has a appreciation for
[00:53:30.920 --> 00:53:36.280]   artistry, certainly evident by the money they've spent and the product they've put
[00:53:36.280 --> 00:53:43.160]   out. And I think good artists and good artistry is, um, uh, you know, can be per,
[00:53:43.160 --> 00:53:47.480]   provocative. It's designed to make you change your opinion, look at things differently,
[00:53:47.480 --> 00:53:53.000]   think about things differently and be challenged in the norms of, you know, your everyday life.
[00:53:53.000 --> 00:53:59.400]   And I think that's, um, that's important in art in all forms. Um, and that means seeing and being
[00:53:59.400 --> 00:54:04.440]   exposed to and, um, being engaged by things that you don't normally get exposed to and engaged by.
[00:54:04.440 --> 00:54:08.360]   And I think that's what Chappelle's is fantastic at. And I think that's what other great
[00:54:08.360 --> 00:54:13.000]   art is great at. And, um, and I think that as long as Netflix maintains that ethos,
[00:54:13.000 --> 00:54:17.560]   that artistry does that. And the good thing is people appreciate it and they, uh, they appreciate
[00:54:17.560 --> 00:54:21.400]   that, that form and they appreciate being challenged in that way. And I think that as
[00:54:21.400 --> 00:54:27.480]   a result, the market will, as Reed Hastings identified, continue to demand it. And as much
[00:54:27.480 --> 00:54:32.200]   as some people might be offended, it's the fact that it is offensive that I think makes it good.
[00:54:32.200 --> 00:54:34.280]   Um, so let me ask you, and I think that they appreciate it.
[00:54:34.280 --> 00:54:39.080]   Hold on. Let me, let me, let me, let me be really clear. I mean,
[00:54:39.080 --> 00:54:42.840]   I hope it goes down exactly the way that you're saying, because that, that is
[00:54:42.840 --> 00:54:47.960]   what I want to believe is happening. I'm a little bit skeptical that this is a little bit more of a
[00:54:47.960 --> 00:54:52.200]   bottom line motive because they got so much money at stake that they can't afford to cancel Chappelle.
[00:54:52.200 --> 00:54:52.440]   I don't think that's true.
[00:54:52.440 --> 00:54:56.040]   But I hope you're right that I hope you're right. That it's a statement of principle
[00:54:56.040 --> 00:55:01.400]   and they will apply that principle to lesser known artists who can't protect themselves as much. Um,
[00:55:01.400 --> 00:55:06.280]   and you know, hopefully this is kind of like, you know, what it reminds me of is the Jon Stewart,
[00:55:06.280 --> 00:55:12.680]   uh, lab, the, the, the, the Wuhan lab leak moment where you had Jon Stewart go on
[00:55:12.680 --> 00:55:19.400]   a Colbert show and he, all of a sudden he made it okay to talk about the lab leak theory. It was like
[00:55:19.400 --> 00:55:20.520]   you couldn't talk about it before.
[00:55:20.520 --> 00:55:21.720]   He cracked the Overton window open.
[00:55:21.720 --> 00:55:27.560]   Yes, exactly. And so hopefully Chappelle will do that for this like woke cancellation mob is to
[00:55:27.560 --> 00:55:31.400]   finally get everybody to realize, oh, like we can stand up to this.
[00:55:31.400 --> 00:55:37.320]   Chamath is the Overton window, uh, on a go forward basis. Do you see it closing more
[00:55:37.320 --> 00:55:40.440]   staying where it is or perhaps even opening?
[00:55:40.440 --> 00:55:42.520]   There's um, there's a really
[00:55:42.520 --> 00:55:46.680]   really great philosopher. This is, uh, this is my, maybe my one and only
[00:55:46.680 --> 00:55:55.400]   grand tribute to Peter Thiel, but he, he is, um, he's a huge supporter of a philosopher
[00:55:55.400 --> 00:56:03.400]   named Rene Girard. And, uh, uh, I agree with a lot of, uh, a lot of that, uh, a lot of Rene
[00:56:03.400 --> 00:56:08.040]   Girard's philosophies. And basically it's called mimetic theory. And the idea is you're born
[00:56:08.040 --> 00:56:12.360]   without preferences and then you kind of just copy what's around you.
[00:56:12.360 --> 00:56:16.280]   And so what the other person wants is what you want. And that's what ultimately leads to a lot
[00:56:16.280 --> 00:56:22.520]   of conflict. And the only way to resolve conflict is, is with a huge grand sacrifice of some kind.
[00:56:22.520 --> 00:56:28.680]   Okay. Um, and if you think about it here, if you're going to really put, you know,
[00:56:28.680 --> 00:56:35.720]   cancel culture, if you're gonna kill it, there needs to be some just massive escalation and
[00:56:35.720 --> 00:56:42.200]   conflict around this idea that allows us to resolve it in one way or the other in one direction,
[00:56:42.200 --> 00:56:47.000]   or the other. And I don't think this is it. I think it's not big enough, quite honestly. I think
[00:56:47.000 --> 00:56:51.560]   it's a little bit sort of like, you know, there's folks like us that love comedy, um, and we're
[00:56:51.560 --> 00:56:56.520]   willing to keep it in a very strict box, which is let people say what they're going to say, be
[00:56:56.520 --> 00:57:01.080]   shocked with it and don't take it onto yourself and don't, you know, and go and reflect it into
[00:57:01.080 --> 00:57:06.920]   the world. It's entertainment and you can, you know, it's like, I choose not to watch, um,
[00:57:06.920 --> 00:57:11.320]   violent stuff. Cause I don't like it. I find it, I find it very offensive or, um, you know,
[00:57:11.320 --> 00:57:12.040]   I don't play first person.
[00:57:12.040 --> 00:57:17.480]   Shooters. I find it really unsettling, you know, grand theft auto. I found it really outrageous.
[00:57:17.480 --> 00:57:23.800]   Uh, and other people will feel like that about Chappelle. My whole thing is we should all be
[00:57:23.800 --> 00:57:27.160]   allowed to make those judgments because I think we're all still pretty rational people at the
[00:57:27.160 --> 00:57:31.080]   end of the day and do the right thing in the normal world. But this isn't the thing that's
[00:57:31.080 --> 00:57:35.480]   going to get this, uh, issue to be resolved. So I don't know how it comes. There needs to
[00:57:35.480 --> 00:57:41.880]   be some huge escalation around this thing. I suspect what happens is it actually just
[00:57:41.880 --> 00:57:47.880]   dissipates and goes away. And the reason is because everybody who's much younger than us
[00:57:47.880 --> 00:57:52.200]   has such a huge digital footprint that they've created through their whole lives.
[00:57:52.200 --> 00:57:52.600]   They're at risk.
[00:57:52.600 --> 00:57:55.160]   There is so much shit that's out there.
[00:57:55.160 --> 00:57:55.960]   Oh God. Yes.
[00:57:55.960 --> 00:57:59.400]   That they just have no choice, but to let everybody else off the hook.
[00:57:59.400 --> 00:58:06.120]   We, we are in a very different situation because we were doing some shady stuff,
[00:58:06.120 --> 00:58:09.000]   always on the down low, always hidden.
[00:58:09.000 --> 00:58:10.360]   Whoa, easy there.
[00:58:10.360 --> 00:58:11.720]   But that, that's how it was.
[00:58:11.720 --> 00:58:16.200]   If you were in your, if you were in your 40s, you would, you would roll deep and you would just,
[00:58:16.200 --> 00:58:20.520]   you would pretend you would not, you know, and now the culture is very different. And I think
[00:58:20.520 --> 00:58:26.680]   with that comes a lot of acceptance. Every, you know, every kid at some point may or may not be on
[00:58:26.680 --> 00:58:32.360]   Tinder, Bumble, Ria, you know, Grindr, whatever. So there's going to be a body of that content.
[00:58:32.360 --> 00:58:38.200]   That's up. Every kid will have said something crazy, you know, on TikTok and all of this stuff
[00:58:38.200 --> 00:58:41.240]   will be there. And so you'll have a choice, which is if you're going to hold me accountable, I'm
[00:58:41.240 --> 00:58:41.560]   going to hold you accountable.
[00:58:41.560 --> 00:58:46.440]   And so it's mutually assured destruction. And I think that's what causes cancel culture to go
[00:58:46.440 --> 00:58:51.960]   away in time. It's the last vestige of very guilty people of our generation.
[00:58:51.960 --> 00:58:56.840]   Fascinating. What do you think, Freeberg? Is the Overton window opening, closing or about the same
[00:58:56.840 --> 00:58:58.040]   over the next year?
[00:58:58.040 --> 00:59:02.440]   What Timoth is saying is right. I, um, I think I've referred to this book called
[00:59:02.440 --> 00:59:05.400]   The Light of Other Days before when we talked. I think so, right?
[00:59:05.400 --> 00:59:05.960]   Yeah.
[00:59:05.960 --> 00:59:11.400]   Um, the book is like all about this notion of all information is available to everyone everywhere.
[00:59:11.400 --> 00:59:16.280]   And societal norms completely change. People no longer find things offensive and they no longer,
[00:59:16.280 --> 00:59:20.920]   and everyone basically shifts to a mode of much more kind of open dialogue because,
[00:59:20.920 --> 00:59:25.240]   you know, keeping things behind closed doors and then positioning one person against the other
[00:59:25.240 --> 00:59:28.120]   completely changes when you can see everyone's cards all the time.
[00:59:28.120 --> 00:59:32.040]   Um, and so I think, yeah, generally we're headed that way. I don't think we're going to,
[00:59:32.040 --> 00:59:37.080]   information wants to be free. More information is being generated about each of us all the time.
[00:59:37.080 --> 00:59:40.600]   I don't think that we're headed in the opposite direction, kind of back to a Victorian era. I
[00:59:40.600 --> 00:59:41.240]   think we're, we're going in the opposite direction. I think we're going in the opposite direction.
[00:59:41.240 --> 00:59:45.480]   I think we're going in the other way. So there's going to be blips and starts, um, uh, that that'll
[00:59:45.480 --> 00:59:51.640]   kind of, you know, be setbacks on that general trajectory. Um, so yeah, I do think it's, it's,
[00:59:51.640 --> 00:59:55.960]   it's a moment, you know, it's a moment in time right now, um, where this is happening.
[00:59:55.960 --> 00:59:58.920]   I mean, Saxon, if you look at the two examples we've discussed,
[00:59:58.920 --> 01:00:05.560]   Brian Armstrong and, uh, Coinbase, that was about essentially Black Lives Matters
[01:00:05.560 --> 01:00:11.080]   and talking about social justice at work. And this one is about trans, uh, and trans rights.
[01:00:11.080 --> 01:00:17.720]   And, and essentially, I don't want to say poking fun at, or, you know, uh, discussing,
[01:00:17.720 --> 01:00:23.320]   uh, I mean, he basically says in it that he's team turf. If you were to take two organizations
[01:00:23.320 --> 01:00:26.920]   that standing up against would be the most challenging and difficult. I think those are
[01:00:26.920 --> 01:00:32.680]   the top two. No, I guess so. I mean, that's why I think this is the mo this is the most telling
[01:00:32.680 --> 01:00:35.480]   is that you have two different organizations saying, Hey, we're going to put our foot down
[01:00:35.480 --> 01:00:40.520]   just for background. Netflix had a very strange, um, I didn't see the actual film, so I won't make
[01:00:40.520 --> 01:00:47.080]   judgment on it. Uh, but it was a very strange, uh, trailer for a film called cuties, which was
[01:00:47.080 --> 01:00:51.080]   really over-sexualizing young girls, like eight, nine, 10 year old girls. And they didn't take it
[01:00:51.080 --> 01:00:58.200]   down, um, in the United States, uh, Netflix, but, uh, they did it. It was in France. It was a French
[01:00:58.200 --> 01:01:05.240]   movie and they have a different view of kids and sexuality. And yeah, uh, I think people found it a
[01:01:05.240 --> 01:01:09.960]   little dark, uh, here in the United States, but they survived that one as well. Uh, or they weathered
[01:01:09.960 --> 01:01:13.640]   that one as well. So I think what people are finding is if you put your foot down at a certain
[01:01:13.640 --> 01:01:17.480]   point, I think what's access says is right then they've, these guys have realized that
[01:01:17.480 --> 01:01:24.440]   if we have this very specific message around artistic freedom and we never violate it,
[01:01:24.440 --> 01:01:28.520]   because that's one of those things where if you take that hill, you have to be there forever,
[01:01:28.520 --> 01:01:34.200]   right? You can't have asterisks around that idea, but by doing that, they basically dominate the
[01:01:34.200 --> 01:01:38.360]   content production game in Hollywood, which then allows them to feel the most content at the
[01:01:38.360 --> 01:01:39.400]   cheapest average price. Uh, and then they're like, Oh, I'm going to do this. I'm going to do this. I'm
[01:01:39.400 --> 01:01:40.120]   going to do this. I'm going to do this. I'm going to do this. I'm going to do this. I'm going to do this.
[01:01:40.120 --> 01:01:45.480]   Which then makes churn less and customer acquisition higher. And they're already the
[01:01:45.480 --> 01:01:49.000]   largest media company in the world. And they're only going to get bigger, you know, they're,
[01:01:49.000 --> 01:01:53.160]   and Netflix says what, 200 million subscribers, they're going to get to a billion subscribers.
[01:01:53.160 --> 01:01:58.440]   It's just inevitable. And so for them, I do think it's a very rational business position to take,
[01:01:58.440 --> 01:02:03.240]   which is that I have to appeal to a billion people over the next, you know, seven or eight years.
[01:02:03.240 --> 01:02:07.400]   You don't have to watch everything on Netflix. You do not have to listen to every album.
[01:02:07.400 --> 01:02:12.120]   And Netflix is a fucking mess. I mean, they should spend 10 minutes and improve the UI.
[01:02:12.120 --> 01:02:15.400]   So you can actually find something. My God, it's so bad.
[01:02:15.400 --> 01:02:21.320]   And you know, he, he basically, Sarandos made the point that, you know, along with Chappelle's show,
[01:02:21.320 --> 01:02:25.720]   they're funding a ton of content by people of color, probably more than anybody and trans people.
[01:02:25.720 --> 01:02:30.520]   It's a big focus of what they're doing at Netflix. And it's, you know, it's essentially to Sax's
[01:02:30.520 --> 01:02:36.520]   point, more speech is better than less. All right. Do we want to go tether? FDA chaos questions.
[01:02:36.520 --> 01:02:40.920]   Why don't you take a, why don't you do your reverse victory lap? Because after all,
[01:02:40.920 --> 01:02:42.840]   you're not a victory lap for me, but.
[01:02:42.840 --> 01:02:48.040]   No, bro. It was the exact opposite. It is not a fraud. It's a fucking fraud. Come on.
[01:02:48.040 --> 01:02:54.200]   Can you please stop saying that? Apparently the CFTC went in, did the work and is actually now
[01:02:54.200 --> 01:02:57.480]   refuting what you thought was the case, Jason. So why don't you just,
[01:02:57.480 --> 01:03:01.240]   how about I read you the quote from at least June 1st, 2016 to February 25th, 2019.
[01:03:01.240 --> 01:03:06.360]   Tether misrepresented to customers and the market that tether maintains sufficient,
[01:03:06.360 --> 01:03:11.320]   US dollar reserves to back every USDT in circulation with the equivalent equivalent
[01:03:11.320 --> 01:03:16.200]   amount of corresponding fiat currency held by tether and safely deposit in tether bank accounts.
[01:03:16.200 --> 01:03:21.560]   In other words, they told everybody they were one for one. They were not, they lied to the public.
[01:03:21.560 --> 01:03:24.120]   What were they Jason? And that's why they're getting a $41 million.
[01:03:24.120 --> 01:03:28.840]   That's why they're banned from New York. And that's why they're banned from trading in Canada.
[01:03:28.840 --> 01:03:35.480]   I think, and they're supposedly a department of justice. Um, these guys are shady as, as, as, as,
[01:03:35.480 --> 01:03:40.040]   as F AF shady AF. Do you have a, do you have an economic interest in tether?
[01:03:40.040 --> 01:03:42.920]   No. In crypto he does. No, no, no. I, I, I.
[01:03:42.920 --> 01:03:46.920]   How can anyone have an economic interest in tether? All it is is a one for one tokenized dollar.
[01:03:46.920 --> 01:03:49.320]   Well, no, it's not. That's what they claim it is.
[01:03:49.320 --> 01:03:54.360]   No, I know you're, you're right that it should be, and we need an audit to establish that it is.
[01:03:54.360 --> 01:03:57.240]   And they won't audit. They'll do an attestation. And when they did their attestation,
[01:03:57.240 --> 01:04:00.200]   all they have to do is show a document that says there's money in an account.
[01:04:00.200 --> 01:04:02.840]   They don't have to show how long that's been in the account.
[01:04:02.840 --> 01:04:05.320]   This certainly, this certainly feels like a security to me.
[01:04:05.320 --> 01:04:08.600]   And I would think the sec should get involved in regulating this.
[01:04:08.600 --> 01:04:13.880]   You, uh, stable coins are the number one thing on Gensler and the sec's mind right now.
[01:04:13.880 --> 01:04:16.920]   I mean, they, they, they make a claim of a secured interest in something, unlike a lot of other crypto.
[01:04:16.920 --> 01:04:21.160]   This is like the easiest part of crypto. This is the easiest part of crypto to regulate.
[01:04:21.160 --> 01:04:21.640]   Why is it easy?
[01:04:21.640 --> 01:04:22.760]   Why? Because, because.
[01:04:22.760 --> 01:04:24.920]   Just look at a bank account. You audit it, you're done.
[01:04:24.920 --> 01:04:28.680]   It's, it's a tokenized dollar. That's it. It is not, it actually, I'm not even sure it's
[01:04:28.680 --> 01:04:32.440]   security. It basically is a digital representation of a dollar that should be sitting in a bank account
[01:04:32.440 --> 01:04:33.560]   somewhere. It's a money market fund.
[01:04:33.560 --> 01:04:35.160]   Yeah. It's a money market fund. So all my
[01:04:35.160 --> 01:04:36.920]   other securities and they're regulated as security.
[01:04:36.920 --> 01:04:40.120]   Okay, fine. But my point is, you know, there are complicated securities and then there's
[01:04:40.120 --> 01:04:43.960]   securities that aren't complicated. This is definitely the least complicated.
[01:04:43.960 --> 01:04:44.440]   The least complicated.
[01:04:44.440 --> 01:04:44.920]   Complicated.
[01:04:44.920 --> 01:04:51.640]   That this company only has to their own attestations, like 6%, 3 to 6% in cash in
[01:04:51.640 --> 01:04:57.080]   a bank account and the rest is in highly volatile corporate, uh, paper.
[01:04:57.080 --> 01:04:59.480]   Here's the point that I was trying to make to you in the group chat.
[01:04:59.480 --> 01:04:59.720]   Oh.
[01:04:59.720 --> 01:05:04.600]   When a company who's got billions and billions and billions of dollars of some stable coin
[01:05:04.600 --> 01:05:09.240]   or something that you think is zero. Okay. It's a multi multi-billion dollar market.
[01:05:09.240 --> 01:05:11.000]   Um, tens of billions.
[01:05:11.000 --> 01:05:12.360]   Oh, sorry. Tens of billions.
[01:05:12.360 --> 01:05:14.600]   They have 70 billion in tether out there.
[01:05:14.600 --> 01:05:18.440]   And, and, and could you imagine if they like, let's just say there were 70 billion
[01:05:18.440 --> 01:05:22.840]   of tether and like, you know, 1 billion of securities. That would be a fraud of
[01:05:22.840 --> 01:05:25.960]   gargantuan proportions, right? We would be beyond talking.
[01:05:25.960 --> 01:05:28.600]   If they, if they siphoned the money out for their own use, that would be a fraud.
[01:05:28.600 --> 01:05:33.560]   Yeah, we'd be beyond talking about fines. What I found comical, Jason is your claims make it seem
[01:05:33.560 --> 01:05:39.480]   like Bernie made off Enron level corruption craziness. Hold on. Okay. And the fine was
[01:05:39.480 --> 01:05:45.080]   42 million, which is like who cares 42 million. And it was between them and another firm.
[01:05:45.080 --> 01:05:49.320]   So either the CFTC completely got the fine wrong and they missed a zero
[01:05:49.320 --> 01:05:53.320]   or two zeros, or this was not nearly as big as you thought it was.
[01:05:53.320 --> 01:05:58.760]   I'm shocked that Jaycott got overly excited about some perceived hopes.
[01:05:58.760 --> 01:06:02.520]   You are a conspiracy theorist.
[01:06:02.520 --> 01:06:09.320]   Jason didn't fully understand something and got very emotional about it.
[01:06:09.320 --> 01:06:16.520]   All right. That's it. I'm off. Here's the best case scenario for making sense of J Cal's points,
[01:06:16.520 --> 01:06:21.320]   which is it's possible that tether, the company behind tether has all the money.
[01:06:21.320 --> 01:06:27.240]   They've just not chosen to keep it in dollar reserves. And so they put it in corporate bonds
[01:06:27.240 --> 01:06:32.040]   and a whole mishmash of different things to get the float, to get the float, to make more money. So,
[01:06:32.040 --> 01:06:32.760]   they're solving.
[01:06:32.760 --> 01:06:39.880]   I don't, my guess is that tether is solvent. I don't think it's, it lacks solvency, but,
[01:06:39.880 --> 01:06:44.760]   but I personally would feel better about any stable coin if it was a hundred percent dollar backed.
[01:06:44.760 --> 01:06:45.480]   I think it should be.
[01:06:45.480 --> 01:06:50.840]   Which is what Jeremy is doing at, um, they see in circle, I had him on the pod this week.
[01:06:50.840 --> 01:06:53.160]   I hope they bought the GitLab, uh, IPO.
[01:06:53.160 --> 01:07:00.680]   Uh, well, I mean, the, the, the issue here is they also co-mingled funds, which is what got Fultzhold in
[01:07:00.680 --> 01:07:06.440]   trouble. The user's accounts with their money in it was mixed with the operating capital. So they
[01:07:06.440 --> 01:07:11.320]   were using the deposits to operate the business, which is the biggest no-no.
[01:07:11.320 --> 01:07:18.200]   Um, they were co-mingling the funds that people thought were backed, uh, and, uh, Bitfinex and
[01:07:18.200 --> 01:07:21.960]   tether were the same company. That's why they both got the fines at the same time.
[01:07:21.960 --> 01:07:25.960]   They've also been banned from doing any, having any customers in New York and they've been banned
[01:07:25.960 --> 01:07:30.440]   in Canada. And there's apparently a DOJ wire for it. So I think this is the beginning,
[01:07:30.440 --> 01:07:33.400]   of the end, not the end of the beginning.
[01:07:33.400 --> 01:07:33.960]   Okay.
[01:07:33.960 --> 01:07:35.080]   That's my personal belief.
[01:07:35.080 --> 01:07:39.160]   I, I was just wanting to get your reaction to what seemed like a really pathetic
[01:07:39.160 --> 01:07:42.920]   fine for what could be a $70 billion fraud. That's all.
[01:07:42.920 --> 01:07:46.440]   I mean, Facebook got a series of speeding tickets too. I mean, I think that that's,
[01:07:46.440 --> 01:07:50.200]   I mean, that's a big issue for our government is that the scale of these companies.
[01:07:50.200 --> 01:07:51.640]   Bro, they paid, they paid $5 billion.
[01:07:51.640 --> 01:07:52.040]   What's that?
[01:07:52.040 --> 01:07:54.280]   They paid like $5 billion or something, right?
[01:07:54.280 --> 01:07:57.240]   Oh yeah. And they're a trillion dollar company. I mean, it's nothing.
[01:07:57.240 --> 01:08:00.200]   I understand, but five, five billion's a big number. That's a big number.
[01:08:00.200 --> 01:08:03.560]   Not in relation to their market cap and how much cash they throw off every year.
[01:08:03.560 --> 01:08:06.280]   42 million. I mean, that's a tax payment. It's a quarterly tax.
[01:08:06.280 --> 01:08:08.920]   For, for you, Tremont, not for us.
[01:08:08.920 --> 01:08:14.680]   Uh, or, or maybe for Sax, he's doing pretty well too. Yum. Yum. All right. Uh, do we want,
[01:08:14.680 --> 01:08:16.920]   we promised we'd do some questions. Should we do a couple of questions?
[01:08:16.920 --> 01:08:18.220]   Sure.
[01:08:18.220 --> 01:08:21.640]   I mean, we could also talk about the FDA.
[01:08:21.640 --> 01:08:25.240]   Oh my God. The FDA, my gosh. Freebird, you want to leave this?
[01:08:25.240 --> 01:08:27.080]   Freebird, you want to tell us about the chaos at the FDA?
[01:08:27.080 --> 01:08:29.960]   Well, I don't think it's chaotic. Like you guys think it is.
[01:08:29.960 --> 01:08:33.640]   Um, I'll make that counter. Why don't you, why don't you make your chaos point first? And then
[01:08:33.640 --> 01:08:34.280]   I'll make that.
[01:08:34.280 --> 01:08:37.160]   That's not my point. It's just kind of the, uh, what people, yeah.
[01:08:37.160 --> 01:08:39.880]   People are perceiving this. So like, you know, there've been a couple of these,
[01:08:39.880 --> 01:08:45.720]   um, changes in recommendations now, all of these recommendations that, um, and you know, the,
[01:08:45.720 --> 01:08:50.840]   these statements and approvals that have come out of the FDA are predicated on these independent
[01:08:50.840 --> 01:08:56.200]   advisory panels that are put together to look at, um, research data, um, assess the research data
[01:08:56.200 --> 01:08:59.720]   and make a recommendation on what they think is appropriate. So we saw this happen with the Pfizer,
[01:08:59.720 --> 01:09:05.000]   um, booster shot a few weeks ago, where initially the, uh, the advisory panel, which again is made
[01:09:05.000 --> 01:09:08.600]   up of independent doctors and scientists who generally don't have any sort of economic
[01:09:08.600 --> 01:09:12.840]   interest in the outcome here. They voted 16 to two against everyone getting a booster shot.
[01:09:12.840 --> 01:09:17.240]   And then they voted 18 to zero in favor of everyone 65 and over. And those at risk of
[01:09:17.240 --> 01:09:21.800]   getting a booster shot. And then recently there was, you know, similar sort of consternation
[01:09:21.800 --> 01:09:25.560]   around the Moderna. And they ended up looking at data that indicated that maybe a half dose,
[01:09:25.560 --> 01:09:29.480]   which is 50 micrograms instead of a hundred micrograms would have a reasonable
[01:09:29.480 --> 01:09:34.680]   amount of efficacy relative to the side effect risk for people over 65. And therefore they
[01:09:34.680 --> 01:09:38.760]   made a recommendation to approve that as a booster, which the FDA is now approving.
[01:09:38.760 --> 01:09:43.800]   And so again, the way this process is run, and I think it's a good process is independent advisors
[01:09:43.800 --> 01:09:48.360]   of doctors and scientists come together. And the one that recently, um, came together was
[01:09:48.360 --> 01:09:54.600]   around this generalized use of, um, aspirin as a heart attack deterrent, um, because it thins the
[01:09:54.600 --> 01:09:58.280]   blood and, and limits the risk of, of people getting heart attacks. But it turns out that such
[01:09:59.240 --> 01:10:02.600]   large percentage of the population or large enough percentage of the population were having
[01:10:02.600 --> 01:10:05.560]   bleeding issues where your stomach bleeds. I don't know if you guys have this, but you know,
[01:10:05.560 --> 01:10:10.920]   you take ibuprofen or NSAIDs, your stomach can bleed. That that was causing more of a problem
[01:10:10.920 --> 01:10:15.880]   for people than they were seeing in the data in terms of a reduction in heart attack effects
[01:10:15.880 --> 01:10:20.040]   for people that were not highly at risk. And so they revised the recommendation and said,
[01:10:20.040 --> 01:10:23.560]   Hey, let's give people that are only at risk and over a certain age, aspirin,
[01:10:23.560 --> 01:10:29.000]   not just like it, give it to everyone over 40 or 50. And so it took in account new data. And I think
[01:10:29.000 --> 01:10:34.040]   this is an important point. Science is messy, right? By definition, science is about gathering
[01:10:34.040 --> 01:10:38.680]   data, forming a hypothesis, testing again, iterating, restating your hypothesis. And it's,
[01:10:38.680 --> 01:10:42.200]   it's a, it's designed to be circular. It's designed to be a learning system,
[01:10:42.200 --> 01:10:46.840]   not designed to be a system that defines absolute truth and absolute fact. And it's good to see the
[01:10:46.840 --> 01:10:50.600]   FDA doing this work. And it's good to see scientists reviewing new data and changing
[01:10:50.600 --> 01:10:55.720]   their recommendations. And we've seen this in, in health. We've seen this in, in the food system
[01:10:55.720 --> 01:10:58.760]   and the USDA changing their diet guidelines. And people used to be told, don't eat the
[01:10:58.760 --> 01:11:02.840]   dietary cholesterol. It turns out saturated fat is what causes cholesterol in your blood. So
[01:11:02.840 --> 01:11:06.360]   there were a lot of changes that, that kind of emerged as new data was gathered. And
[01:11:06.360 --> 01:11:09.880]   Remember when they told us to eat a lot of carbs? Remember the all carb diets?
[01:11:09.880 --> 01:11:13.160]   Yeah. And then they learned and they made a change in their days.
[01:11:13.160 --> 01:11:16.360]   Wait, wait, can we bring that back? I'm starving.
[01:11:16.360 --> 01:11:20.680]   I used to eat pasta every day. First it was rice in my tens and twenties.
[01:11:20.680 --> 01:11:22.520]   Oh, I've seen you eat rice. It is.
[01:11:22.520 --> 01:11:23.080]   Oh my God.
[01:11:23.080 --> 01:11:25.560]   Oh, the shoveling of rice. My Lord.
[01:11:25.560 --> 01:11:28.520]   So, so Freeburg, I mean, if we're going to be just intellectually young.
[01:11:28.520 --> 01:11:28.840]   Pizza.
[01:11:28.840 --> 01:11:32.760]   If we're gonna be intellectually honest about this, the fact that, you know, official health
[01:11:32.760 --> 01:11:39.560]   officials can be wrong about positions they've maintained with, I guess, seemingly total
[01:11:39.560 --> 01:11:44.200]   certainty for decades, and now they can revise those positions. I mean, doesn't that lend some
[01:11:44.200 --> 01:11:49.480]   credence to some of these like anti-vax arguments when they say, well, gee, I'm, I'm skeptical
[01:11:49.480 --> 01:11:52.600]   about injecting our mRNA into myself.
[01:11:52.600 --> 01:11:55.560]   I think it's a totally, you just got the episode banned on YouTube.
[01:11:55.560 --> 01:11:56.040]   No, no, no, no, listen, listen.
[01:11:56.040 --> 01:11:56.920]   We just got a warning.
[01:11:56.920 --> 01:11:58.280]   I'm glad. I'm glad I got this.
[01:11:58.280 --> 01:11:58.840]   I got the vaccine.
[01:11:58.840 --> 01:12:00.200]   I got the Pfizer vaccine.
[01:12:00.200 --> 01:12:02.600]   Um, and I think, look, it could have saved my life.
[01:12:02.600 --> 01:12:05.720]   I mean, I had a very mild case of Delta.
[01:12:05.720 --> 01:12:05.960]   Yeah.
[01:12:05.960 --> 01:12:09.080]   I had one of the first breakthroughs because it's so, but, but it was very mild.
[01:12:09.080 --> 01:12:11.480]   And I think that was because I got Pfizer.
[01:12:11.480 --> 01:12:13.800]   I think the risk return was completely worth it.
[01:12:13.800 --> 01:12:20.600]   And, but, but I can also see why people with like five-year-old like kindergarten age,
[01:12:20.600 --> 01:12:26.280]   you know, might not want to get it for their kids when the upside is absolutely, you know,
[01:12:26.280 --> 01:12:28.040]   tiny given that it doesn't really.
[01:12:28.040 --> 01:12:28.280]   Yeah.
[01:12:28.280 --> 01:12:30.040]   Affect five-year-olds very much.
[01:12:30.040 --> 01:12:34.760]   And the downside is not, there's no proven downside, but how is it any different than
[01:12:34.760 --> 01:12:35.560]   the aspirin thing?
[01:12:35.560 --> 01:12:36.280]   Wait, it might be.
[01:12:36.280 --> 01:12:36.760]   No, I don't know.
[01:12:36.760 --> 01:12:39.000]   I don't wish you had gotten really sick with Delta.
[01:12:39.000 --> 01:12:40.120]   Yes, you are.
[01:12:40.120 --> 01:12:42.520]   No, but it's not, there's a bunch of people on the left.
[01:12:42.520 --> 01:12:47.640]   I don't, I don't, um, I don't disagree with the framing that, that, um, here's what typically
[01:12:47.640 --> 01:12:48.520]   happens.
[01:12:48.520 --> 01:12:52.120]   The scientists or the FDA panel will say, based on the data that we have, this is our
[01:12:52.120 --> 01:12:53.800]   recommendation on what should happen.
[01:12:53.800 --> 01:12:57.800]   And then the framing that, that people then assume is, oh, this is what they believe to
[01:12:57.800 --> 01:12:58.600]   be absolute truth.
[01:12:58.600 --> 01:13:01.000]   And with absolute certainty, this is what we have to do.
[01:13:01.000 --> 01:13:05.880]   And I think the translation layer to the general population is such that this is the 10 commandments
[01:13:05.880 --> 01:13:07.080]   I came down from on Sinai.
[01:13:07.080 --> 01:13:08.680]   And this is what I'm saying has to happen.
[01:13:08.680 --> 01:13:13.000]   When the reality is it is based on data and that data changes over time.
[01:13:13.000 --> 01:13:14.520]   And I think that your point is right.
[01:13:14.520 --> 01:13:18.920]   There is no absolute certainty that the Pfizer vaccine is going to be absolutely perfect
[01:13:18.920 --> 01:13:19.480]   for everyone.
[01:13:19.480 --> 01:13:24.600]   And it's going to absolutely reduce the risk more than it, um, increases the risk for people
[01:13:24.600 --> 01:13:26.440]   five years old and younger.
[01:13:26.440 --> 01:13:27.560]   Um, and it's a, it's a very,
[01:13:27.560 --> 01:13:33.000]   very fair point that like, but the problem as we've seen on all sides is that the framing
[01:13:33.000 --> 01:13:35.480]   is that these things are binary and they're not right.
[01:13:35.480 --> 01:13:40.520]   There is a probability distribution of, of which is defined as the risk and the things
[01:13:40.520 --> 01:13:43.240]   that might go wrong and the probability distribution of the benefits.
[01:13:43.240 --> 01:13:45.160]   And then people assume that it's just binary.
[01:13:45.160 --> 01:13:46.360]   I think you're making it.
[01:13:46.360 --> 01:13:47.480]   I think you're making an excellent point there.
[01:13:47.480 --> 01:13:50.920]   I just want to underscore, let me kind of translate what you're saying is that the,
[01:13:50.920 --> 01:13:55.240]   the people at the FDA are in these positions who actually understand the science make a
[01:13:55.240 --> 01:13:56.680]   cost benefit analysis.
[01:13:56.680 --> 01:13:57.320]   And what they're saying,
[01:13:57.320 --> 01:14:01.720]   what they're saying and approving it is that the costs outweigh the risks, sorry, the benefits
[01:14:01.720 --> 01:14:04.360]   outweigh the risk to the broad population, the broad population.
[01:14:04.360 --> 01:14:04.920]   Okay.
[01:14:04.920 --> 01:14:06.680]   By the way, that's why I got the vaccine.
[01:14:06.680 --> 01:14:10.680]   I don't know for sure that there's no downsides in 10 years.
[01:14:10.680 --> 01:14:13.720]   All I know is there's an upside immediately and I benefited from that.
[01:14:13.720 --> 01:14:15.960]   So I was very happy to take it.
[01:14:15.960 --> 01:14:20.600]   But in any event, instead of this complicated cost benefit analysis, the media translates
[01:14:20.600 --> 01:14:24.680]   that into good, bad, it's almost like a moral case.
[01:14:24.680 --> 01:14:27.080]   And then the politicians translate that into laws.
[01:14:27.080 --> 01:14:32.920]   And if you question the rules, you're now a bad person because you've, you've opposed the quote,
[01:14:32.920 --> 01:14:34.440]   unquote, good side of the argument.
[01:14:34.440 --> 01:14:41.160]   I mean, for example, Gavin Newsom just signed a bill in California saying that if you are a public
[01:14:41.160 --> 01:14:47.800]   school child, elementary school, kindergarten, you have to get vaccinated in order to go to a public
[01:14:47.800 --> 01:14:50.120]   school, even though the vaccine doesn't even exist for them yet.
[01:14:50.120 --> 01:14:55.160]   I mean, you could be pro-vax, which I guess I would consider myself to be clearly pro-vax.
[01:14:55.160 --> 01:14:56.840]   I mean, I got the vaccine.
[01:14:56.840 --> 01:14:57.400]   I got it.
[01:14:57.400 --> 01:14:58.600]   My 13 year old got it.
[01:14:58.600 --> 01:14:59.240]   I support it.
[01:14:59.240 --> 01:15:04.200]   I think it's a smart decision to make, but to require a five year old to get it in order to go
[01:15:04.200 --> 01:15:05.160]   to public schools in California.
[01:15:05.160 --> 01:15:07.080]   You can also wait until we get the FDA data.
[01:15:07.080 --> 01:15:08.840]   Here's a question for you, Friedberg.
[01:15:08.840 --> 01:15:15.480]   You know, having this, one of the complaints has been the FDA restricts progress.
[01:15:15.480 --> 01:15:19.320]   I mean, I think actually Peter Thiel had this position for a while that we should, you know,
[01:15:19.320 --> 01:15:21.320]   just get rid of it and disband it.
[01:15:21.320 --> 01:15:26.600]   What do we think about having the FDA being framed as these are recommendations and then
[01:15:26.600 --> 01:15:30.680]   each state gets to make a decision with their local FDA.
[01:15:30.680 --> 01:15:36.120]   So then if Colorado or Texas or Florida had a difference of opinion about psychedelics,
[01:15:36.120 --> 01:15:40.120]   about vaccines, they could run their own studies.
[01:15:40.120 --> 01:15:42.520]   It's a really important matter of ethics.
[01:15:42.520 --> 01:15:49.800]   What are your ethics that you believe, you know, should be the guiding principles for how the
[01:15:49.800 --> 01:15:53.960]   government plays a role in individuals making choice about their health and their body.
[01:15:53.960 --> 01:15:56.360]   And so if you believe that the
[01:15:56.360 --> 01:15:58.840]   government and this is there's no right or wrong here.
[01:15:58.840 --> 01:16:00.840]   It's simply a framing of what you believe.
[01:16:00.840 --> 01:16:05.320]   If you believe that it's appropriate for the government to make the decision about what's
[01:16:05.320 --> 01:16:10.360]   safe and not safe for you as an individual to do, then the FDA should stay in place and they
[01:16:10.360 --> 01:16:13.640]   should have their criteria of when they're ready to make a recommendation.
[01:16:13.640 --> 01:16:18.840]   There's enough data to define the benefit and the cost of a particular thing that you
[01:16:18.840 --> 01:16:21.880]   might put in your body and then telling you, yes, you should or shouldn't do this.
[01:16:21.880 --> 01:16:25.400]   If you and if not, they're going to take their time and figure that out.
[01:16:25.400 --> 01:16:26.120]   Now, if you don't believe that,
[01:16:26.120 --> 01:16:31.160]   then yes, the FDA should be disbanded and drug companies will go around and they will tell people,
[01:16:31.160 --> 01:16:35.080]   take this drug, it will save your life and people will take it and there will be there will be
[01:16:35.080 --> 01:16:38.280]   people that will suffer from that. There will be people that will have or maybe something in
[01:16:38.280 --> 01:16:39.960]   between. There will be people that will die from that.
[01:16:39.960 --> 01:16:41.080]   Federal.
[01:16:41.080 --> 01:16:45.960]   And remember, like the criteria for the FDA is do no harm. So, you know, that is the criteria
[01:16:45.960 --> 01:16:51.160]   for a doctor in general. It is a very difficult criteria to meet when there are costs to a drug
[01:16:51.160 --> 01:16:55.880]   or costs to a therapy or treatment. When people get chemotherapy for cancer, there are awful,
[01:16:55.880 --> 01:16:59.800]   deleterious side effects to their body. But the benefit of saving their life and getting rid of
[01:16:59.800 --> 01:17:04.040]   the cancer, having at least a shot at doing that is great enough. And the FDA has made a judgment
[01:17:04.040 --> 01:17:08.440]   call that that cost and that benefit kind of create an equation that says this is an approved
[01:17:08.440 --> 01:17:12.040]   drug now. And that's really their goal. And if they don't have enough data and they haven't taken
[01:17:12.040 --> 01:17:15.320]   enough time to figure that out, they don't feel comfortable approving a drug and making that
[01:17:15.320 --> 01:17:19.880]   recommendation. But then if you let them get out of the way and you let individuals make choice,
[01:17:19.880 --> 01:17:24.440]   you could see this being a disgusting free for all where drug companies will hawk snake oil on people
[01:17:24.440 --> 01:17:25.640]   and a lot of harm will be caused.
[01:17:25.640 --> 01:17:28.680]   And that's that's the counter argument. And I'm not saying one is right or one is wrong.
[01:17:28.680 --> 01:17:31.800]   I was thinking there might be something that really comes down to what is the role that you
[01:17:31.800 --> 01:17:34.600]   want? I mean, it's really that what is the role that you want any government, whether it's states
[01:17:34.600 --> 01:17:38.680]   or the federal government to play in deciding what you can and can't do with your body and what you
[01:17:38.680 --> 01:17:42.760]   can and can't put in your body, and ultimately what companies that are making products for you
[01:17:42.760 --> 01:17:48.360]   can and can't say to you about the benefit and the cost of that product. And there's no simple
[01:17:48.360 --> 01:17:52.280]   solution, right? I mean, like, I mean, look at Kyrie Irving. I mean, he's basically he's
[01:17:52.280 --> 01:17:55.400]   not everyone's $200 million. And by the way,
[01:17:55.400 --> 01:18:00.600]   not every individual is equipped to look at the data and make a judgment call on their own. And so
[01:18:00.600 --> 01:18:05.080]   the question then is what authority will they look to? And if the alternative authority that they will
[01:18:05.080 --> 01:18:10.440]   look to is not as good as a research team of 18 scientists, then they're probably going to end up
[01:18:10.440 --> 01:18:17.160]   getting bad advice. You think what do you think the ultra Kyrie retires? I think it's 60% right
[01:18:17.160 --> 01:18:25.160]   now. I think $200 million. He gets paid like 30 or $40 million a year. He refuses to get the
[01:18:25.160 --> 01:18:30.120]   vaccine. He said the reason he's not getting the vaccine is because of all the people who don't
[01:18:30.120 --> 01:18:35.480]   have a choice the pilots who are being forced to get it or not go to work. So he is a privilege,
[01:18:35.480 --> 01:18:40.440]   he says and he wants to make this decision for everybody else. He also believes that the earth
[01:18:40.440 --> 01:18:46.440]   is flat. Stop. That was a joke. He said I don't think it was a joke. Where are you getting that
[01:18:46.440 --> 01:18:51.640]   from J.K. typing Kyrie Irving flat earth he talked about how do we know the earth is actually around
[01:18:51.640 --> 01:18:54.920]   and he basically was holding a position. That sounds like a media distortion to me. Yeah, two
[01:18:54.920 --> 01:18:58.440]   days later, he came out and he was like you guys misinterpret anyways, that's that's that's not the
[01:18:58.440 --> 01:19:04.840]   here or there. He's he's what he's unique and wacky. So I would I wouldn't make that decision.
[01:19:04.840 --> 01:19:09.800]   Why are you so pejorative? Like I know, I know, because it's infuriating that someone disagrees
[01:19:09.800 --> 01:19:15.000]   with you. You say no, because he wanted to come to the next. These are Taylor wanted to come to
[01:19:15.000 --> 01:19:19.320]   the next and Kyrie convinced him to go to Brooklyn. That's the reason take out you're still a member
[01:19:19.320 --> 01:19:24.680]   of the media. You have like a vestigial tale here is that you just bought in to the framework that
[01:19:24.680 --> 01:19:29.320]   Reberg laid out, which is the media takes complicated issues, cost benefit analyses,
[01:19:29.320 --> 01:19:33.560]   and turns them into right or wrong. He didn't come to the next. He didn't come to the next.
[01:19:33.560 --> 01:19:40.120]   He's bad. He now he's bad. Not coming to the next. He says to me, like, a man of conscience,
[01:19:40.120 --> 01:19:44.680]   no man of conscience who's willing to stand up on principle turned down $200 million. I got the
[01:19:44.680 --> 01:19:50.040]   vaccine for free. I sure as hell wouldn't turn away $200 million not to get it. So I mean,
[01:19:50.040 --> 01:19:53.560]   it's not a decision I would make. 200 million to not take it. Would you have taken? Would you have
[01:19:54.440 --> 01:20:00.440]   taken it? I think I'm not taking it for 200 million. There. There was a I heard a great
[01:20:00.440 --> 01:20:06.360]   story yesterday at the poker table. One of the guys was telling me it's his backgammon teacher,
[01:20:06.360 --> 01:20:11.560]   and he says his backgammon teacher or is it in good backgammon teacher and a magician blah, blah,
[01:20:11.560 --> 01:20:23.560]   blah. 20 years ago, he was asked to get female breast implants for a year for $100,000. He did it
[01:20:23.560 --> 01:20:24.200]   and he kept them for $100,000. He did it and he kept them for $100,000. He did it and he kept them
[01:20:24.200 --> 01:20:32.120]   for 20 years. That's quite a free roll. So you know, the bar for people to do the bar for people
[01:20:32.120 --> 01:20:37.080]   to do things is really not that high, is really what I took away from that story. And what I
[01:20:37.080 --> 01:20:41.480]   think from this story is so let's go around the world. No, but Kyrie is willing to draw the line
[01:20:41.480 --> 01:20:45.720]   on something that he believes in. And it's going to cost him $200 million. There's a lot of things
[01:20:45.720 --> 01:20:51.320]   that come with all of that noise. He should be allowed to make that decision in my opinion.
[01:20:53.960 --> 01:20:57.080]   I don't like the way that he's characterized because I think this is a good human being.
[01:20:57.080 --> 01:21:03.000]   He's a phenomenal basketball player. Could you imagine how strongly he feels about this if he's
[01:21:03.000 --> 01:21:07.320]   willing to walk away from the game that he loves and that's, you know, been an enormous part of his
[01:21:07.320 --> 01:21:13.400]   life? Why is it so important to foist on Kyrie Irving the need to get vaccinated? I mean, it's
[01:21:13.400 --> 01:21:18.600]   because in New York City indoors, you have to there's a vaccine requirement and he can't play at
[01:21:18.600 --> 01:21:23.080]   home games he could play in Texas or Houston. So they've talked about trading him to Houston. But
[01:21:23.080 --> 01:21:23.720]   then when he went to New York City, he was forced to go to Houston. So he's forced to go to Houston.
[01:21:23.720 --> 01:21:27.640]   New York, and you also can't practice with the team in New York, New Jersey,
[01:21:27.640 --> 01:21:31.960]   I guess Massachusetts is a bunch of states where you can't go indoors without a vaccine.
[01:21:31.960 --> 01:21:33.880]   They're in close proximity to each other. You get the idea.
[01:21:33.880 --> 01:21:39.240]   I just think we're turning a good thing into which is the vaccine. I genuinely think it's a
[01:21:39.240 --> 01:21:43.720]   it's a great thing that I got done so quickly. It's a miracle science. And I think it's helped
[01:21:43.720 --> 01:21:48.760]   a lot of people. I mean, all of us. I mean, it's the thing that's going to end the pandemic,
[01:21:48.760 --> 01:21:53.480]   largely already has, but we're turning into a bad thing. But why were we demanding that these hold
[01:21:53.480 --> 01:21:59.160]   outs like every last person must get vaccinated? What about what about a flight attendant? Should
[01:21:59.160 --> 01:22:04.360]   a flight attendant before us if they're on a tiny? Here's the thing. They be work.
[01:22:04.360 --> 01:22:10.520]   You get so much protection by being vaccinated yourself. That I don't think so. You don't believe
[01:22:10.520 --> 01:22:18.200]   in mandates now. Well, I think private companies have the right to. I know I get it. So but I'm
[01:22:18.200 --> 01:22:22.920]   just I'm just starting to really question here whether it's truly necessary to get every single
[01:22:22.920 --> 01:22:23.240]   one of these.
[01:22:23.240 --> 01:22:27.560]   These last holdouts. I just there's something un-American about imposing
[01:22:27.560 --> 01:22:31.800]   on free people this decision. They can't just make up their own mind.
[01:22:31.800 --> 01:22:36.280]   You in a previous episode said you were in favor of it if people were dying at a higher rate.
[01:22:36.280 --> 01:22:40.120]   If it was more acute. No, no, no, no. Well, hold on. You did say that you said if it was killing
[01:22:40.120 --> 01:22:45.000]   kids and a lot of people were dying. If it was if it was some sort of like Ebola, like, yeah,
[01:22:45.000 --> 01:22:47.560]   of course, it'd be a whole different cost benefit analysis. Exactly.
[01:22:47.560 --> 01:22:53.000]   But look what I said, and I think this is still my position is that government shouldn't
[01:22:53.000 --> 01:22:56.680]   require shouldn't stick a needle in your arm. I think private businesses can do it
[01:22:56.680 --> 01:23:02.360]   or you don't use that service. So how much would it take for you to get B cups
[01:23:02.360 --> 01:23:05.560]   implanted for one billion dollars? Would you do it?
[01:23:05.560 --> 01:23:11.080]   Only B's. I'm not saying like a strong D or something, just like a modest B cup.
[01:23:11.080 --> 01:23:14.520]   No, I mean, is that a real story, Chamath? Yeah. Send you the link. It's a there's a
[01:23:14.520 --> 01:23:18.760]   huge article about it. It's in Wikipedia. That's an old story. Jason, you've already got B cups.
[01:23:18.760 --> 01:23:22.760]   I hope someone's paying you for that. I've lost 16 pounds. I'm good. I'm good. I'm I'm
[01:23:22.760 --> 01:23:29.080]   just like a perky A right now. B cups be gone. This show has gone off the rails.
[01:23:29.080 --> 01:23:34.520]   We promised the audience would take two questions. The first one is for Friedberg. And the first
[01:23:34.520 --> 01:23:40.600]   question comes from Daniel Nielis. He says AlphaFoam made great progress in predictive protein
[01:23:40.600 --> 01:23:45.240]   folding. Is there anything similar for chemical synthesis? Could a similar system finally predict
[01:23:45.240 --> 01:23:52.520]   a less energy intensive pathway to ammonia than the Haber Bosch process, for example? I,
[01:23:52.520 --> 01:23:58.840]   I don't see this is this is a great question. When molecules interact, a molecule is a bunch
[01:23:58.840 --> 01:24:04.360]   of atoms stuck together and there are electrons and protons that make up that molecule. And
[01:24:04.360 --> 01:24:09.960]   therefore there's this kind of variable electric potential energy potential that surrounds that
[01:24:09.960 --> 01:24:16.200]   molecule. And it's very difficult today to deterministically model how two molecules might
[01:24:16.200 --> 01:24:21.960]   interact with one another in physics. And it turns out that that resolves using quantum physics.
[01:24:21.960 --> 01:24:25.880]   And so today, we can't really kind of put two molecules together and say, here's what happens
[01:24:25.880 --> 01:24:29.960]   when you put these together and have a computer program very quickly and easily solve that.
[01:24:29.960 --> 01:24:33.480]   Quantum physics is involved and we don't have a good way to simulate quantum physics in binary
[01:24:33.480 --> 01:24:39.800]   computers. So one of the theories and there's been some work on this in on the research basis,
[01:24:39.800 --> 01:24:45.320]   creating the framework for it is that we can use quantum computers to simulate the quantum states
[01:24:45.320 --> 01:24:45.960]   of molecules. And so we can use quantum computers to simulate the quantum states of molecules.
[01:24:45.960 --> 01:24:46.520]   Wow.
[01:24:46.520 --> 01:24:50.840]   And use that to figure out how molecules might interact with one another. And as a result,
[01:24:50.840 --> 01:24:55.640]   you could kind of see us creating simulations that resolve certain enzymes or proteins that
[01:24:55.640 --> 01:25:01.160]   might break apart molecules or stick molecules together, or other molecule combinations that
[01:25:01.160 --> 01:25:05.160]   might cause something to happen. The Haber-Bosch process, which is being referred to,
[01:25:05.160 --> 01:25:10.120]   was discovered through trial and error in the early 20th century by a German physicist,
[01:25:10.120 --> 01:25:15.720]   an engineer. And they realized that if they compressed atmospheric air,
[01:25:15.720 --> 01:25:16.280]   they could create a very complex, very complex, very complex, very complex, very complex, very
[01:25:16.280 --> 01:25:16.760]   complex, very complex, very complex, very complex, very complex, very complex, very complex,
[01:25:16.760 --> 01:25:21.320]   200 times atmospheric pressure and ran it over an iron catalyst with electricity. It zapped.
[01:25:21.320 --> 01:25:26.600]   It broke apart the nitrogen bonds in the in the atmosphere and in the air that was compressed
[01:25:26.600 --> 01:25:31.560]   and trickled out ammonia, which is nitrogen and hydrogen. And so this was like this amazing
[01:25:31.560 --> 01:25:34.680]   invention and it saved the world and fed the world. There's a great book called The Alchemy
[01:25:34.680 --> 01:25:38.600]   of Air if anyone's interested in hearing about this. But it was through trial and error and we
[01:25:38.600 --> 01:25:43.560]   got so friggin lucky as a species that we figured this out. Using quantum computing in the next 30
[01:25:43.560 --> 01:25:45.480]   years, hopefully we'll be able to deterministically, we'll be able to determine the energy of the air
[01:25:45.480 --> 01:25:47.560]   that's going to be in the atmosphere. And we'll be able to do this. And we'll be able to
[01:25:47.560 --> 01:25:52.840]   model these these behaviors on a molecular and atomic level, and as a result, kind of build new
[01:25:52.840 --> 01:25:58.440]   systems to make things. And that'll be an incredible kind of toolkit for humans that'll
[01:25:58.440 --> 01:26:03.400]   advance a lot of science and a lot of engineering forward. I'm still really strongly of the belief
[01:26:03.400 --> 01:26:05.560]   and this goes back to your point earlier. I'm sorry, I'm going on a bit of a ramp.
[01:26:05.560 --> 01:26:06.600]   No, it's great.
[01:26:06.600 --> 01:26:11.000]   In 100 to 120 years from now, I do think we'll all have a
[01:26:11.000 --> 01:26:15.240]   replicator in our room. And that replicator will make all the things we want to make nearly
[01:26:15.240 --> 01:26:17.960]   instantaneously with very low energy and very low cost.
[01:26:17.960 --> 01:26:21.000]   Including an organ, a new brain, a new heart.
[01:26:21.000 --> 01:26:25.240]   Some food, the next car you want to make. I mean, we could see and by the way,
[01:26:25.240 --> 01:26:29.240]   this is a crazy concept. It's not just about oh, you know, quantum stuff or whatever was described
[01:26:29.240 --> 01:26:35.000]   in Star Trek. But the general principle that you can locally make things and locally make things
[01:26:35.000 --> 01:26:39.960]   cheaply with very little energy and very little input changes the whole supply chain model. We're
[01:26:39.960 --> 01:26:45.000]   seeing this increasingly with new technologies with 3D printing and biomanufacturing. You start
[01:26:45.000 --> 01:26:49.640]   to put these all together and you take a nonlinear track out in the next couple decades. And you get
[01:26:49.640 --> 01:26:53.560]   to a point that all this nonsense we're talking about where we're mining stuff in one place and
[01:26:53.560 --> 01:26:55.720]   making it another and shipping it and combining it all in another.
[01:26:55.720 --> 01:26:56.520]   I think that solves the Long Beach port.
[01:26:56.520 --> 01:26:58.760]   Sax, you're going to be able to print a conscience.
[01:26:58.760 --> 01:26:59.240]   Wow.
[01:26:59.240 --> 01:27:01.800]   I'm so glad.
[01:27:01.800 --> 01:27:03.000]   You're going to be able to print an emotion.
[01:27:03.000 --> 01:27:05.080]   I'm so glad we took this audience question. So glad.
[01:27:05.080 --> 01:27:09.960]   Yeah. All right, here's a question for Sax. Maddy, or I guess me and also Chamath,
[01:27:09.960 --> 01:27:14.760]   and I guess all four of us. Maddy Chavez asks, between being a VC
[01:27:14.760 --> 01:27:19.720]   founder, angel, corporate employee, which has been the most fun, rewarding, and why, what advice
[01:27:19.720 --> 01:27:26.120]   would you give someone early in their career hoping to be like you, multi-channel investor,
[01:27:26.120 --> 01:27:28.760]   thought leader when they grow up? Sax?
[01:27:28.760 --> 01:27:35.240]   Well, I didn't become a VC until after I had already done a few tours of duty as a founder
[01:27:35.240 --> 01:27:40.040]   and operator. So I mean, my recommendation would be to get involved in startups first,
[01:27:40.040 --> 01:27:44.520]   generally get some operating experience and that would serve you well.
[01:27:44.520 --> 01:27:48.920]   Startups or even bigger companies. I just think getting some reps
[01:27:48.920 --> 01:27:51.560]   inside of an organization is critical.
[01:27:51.560 --> 01:27:55.800]   I tell everyone that's coming out of college or early in their careers,
[01:27:55.800 --> 01:27:58.760]   it's important you go get that perspective and work at a bigger business. I mean,
[01:27:58.760 --> 01:28:02.200]   I spent a few years at Google and it was 1000 people when I joined,
[01:28:02.200 --> 01:28:08.120]   grew to 10,000 by the time I left. But I learned so much just in that role and seeing successful
[01:28:08.120 --> 01:28:13.640]   products, successful models for operating a business. It was really impactful for me long term.
[01:28:13.640 --> 01:28:17.480]   And then you go and make all the mistakes as a founder building a startup.
[01:28:17.480 --> 01:28:21.320]   And a lot of people end up with bad confirmation bias if they work at a startup that didn't work
[01:28:21.320 --> 01:28:26.760]   out and they think and all they can draw from is a failed model for operating if things didn't work.
[01:28:26.760 --> 01:28:30.280]   Which was your favorite? Which role has been your favorite to date, Freeburg?
[01:28:30.280 --> 01:28:36.360]   When I was an executive at Monsanto, it was really nice to have that private jet that would come out
[01:28:36.360 --> 01:28:39.400]   and take me places. They had a whole security requirement.
[01:28:39.400 --> 01:28:40.440]   I already have that anyway.
[01:28:40.440 --> 01:28:41.320]   Yeah.
[01:28:41.320 --> 01:28:43.400]   Oh, wow. The one thing.
[01:28:43.400 --> 01:28:43.960]   1%.
[01:28:43.960 --> 01:28:47.240]   I have this impression of 0.1%.
[01:28:47.240 --> 01:28:48.040]   Edit that out.
[01:28:48.040 --> 01:28:49.640]   We're not editing it out.
[01:28:49.640 --> 01:28:50.600]   We're not editing it out.
[01:28:50.600 --> 01:28:51.880]   No, do not edit that out.
[01:28:51.880 --> 01:28:54.120]   And Henry Belkaster's making a video.
[01:28:54.120 --> 01:28:55.160]   I'm setting the tape.
[01:28:55.160 --> 01:28:55.560]   Do not edit that out.
[01:28:55.560 --> 01:28:56.680]   Do not edit it out.
[01:28:56.680 --> 01:28:58.280]   That's a you said it and it's in your heart.
[01:28:58.280 --> 01:29:01.800]   You own your words, David Sachs. What was your favorite, Sachs?
[01:29:01.800 --> 01:29:03.720]   My favorite stint?
[01:29:03.720 --> 01:29:04.520]   Yeah.
[01:29:04.520 --> 01:29:13.160]   Well, I mean, obviously what we did at PayPal has gone on to become a legend and then PayPal,
[01:29:13.160 --> 01:29:14.200]   I was the founder CEO.
[01:29:14.200 --> 01:29:15.560]   He led that to a unicorn exit.
[01:29:15.560 --> 01:29:18.840]   So you got to say those would be the two best professional experiences.
[01:29:18.840 --> 01:29:19.800]   By the way, I was being a fan.
[01:29:19.800 --> 01:29:21.880]   I was joking about the private jet thing.
[01:29:21.880 --> 01:29:27.240]   Honestly, to me and Sachs, I'm sure, and the rest of you guys can feel the same, but making
[01:29:27.240 --> 01:29:31.640]   a great product and selling that product and working with a customer with that product is
[01:29:31.640 --> 01:29:33.320]   honestly the most rewarding thing you can do.
[01:29:33.320 --> 01:29:37.480]   It's like getting your hands dirty and actually delivering something of value in the world.
[01:29:37.480 --> 01:29:38.840]   There's nothing more rewarding than that.
[01:29:38.840 --> 01:29:42.920]   I mean, all the financial engineering and making money and all the nonsense that goes on is
[01:29:42.920 --> 01:29:46.280]   really kind of a zoom out of that, but that's really where reward comes in.
[01:29:46.280 --> 01:29:49.560]   Yeah. I feel that way too. I was joking about the private jet too.
[01:29:49.560 --> 01:29:51.080]   Dang.
[01:29:51.080 --> 01:29:51.560]   Which one?
[01:29:51.560 --> 01:29:53.160]   Which jet?
[01:29:53.160 --> 01:29:53.720]   Which jet?
[01:29:53.720 --> 01:29:58.600]   Actually, I think Nick caught me misspeaking. So yeah, it was the first experience with PayPal.
[01:29:58.600 --> 01:30:01.240]   The second experience was Yammer. You may have to do some audio work there.
[01:30:01.240 --> 01:30:03.320]   Which is your favorite private jet that you have?
[01:30:03.320 --> 01:30:03.480]   Yeah.
[01:30:03.480 --> 01:30:11.080]   By the way, I just want to defend myself on stealing toiletries on Chamath's plane.
[01:30:11.080 --> 01:30:12.680]   Don't defend yourself.
[01:30:12.680 --> 01:30:13.400]   Don't do it.
[01:30:13.400 --> 01:30:16.760]   It was a mini bottle of Scope. I drank half of it. What are you supposed to do?
[01:30:16.760 --> 01:30:17.560]   How many did you take?
[01:30:17.560 --> 01:30:18.520]   Put it back in the drawer.
[01:30:18.520 --> 01:30:19.640]   How many did you take?
[01:30:19.640 --> 01:30:23.320]   On your plane or on Chamath's? On your plane, I took a...
[01:30:23.320 --> 01:30:27.400]   True story. I did take the half bottle of Pappy Van Winkle.
[01:30:27.400 --> 01:30:28.760]   You took my Pappy Van Winkle?
[01:30:28.760 --> 01:30:32.360]   It was like a half left. That's a $5,000 bottle. It's $2,500.
[01:30:32.360 --> 01:30:33.640]   Actually, I'll tell you a funny story about Pappy.
[01:30:33.640 --> 01:30:36.280]   I boosted a half bottle of Pappy. Can you blame me?
[01:30:36.280 --> 01:30:38.200]   Yeah. Okay. So here, I got to tell you this funny story.
[01:30:38.200 --> 01:30:38.840]   It's not true.
[01:30:38.840 --> 01:30:40.040]   I was going on... You didn't take it.
[01:30:40.040 --> 01:30:42.440]   I didn't take it. I drank it.
[01:30:42.440 --> 01:30:49.080]   I was going on a business trip with a couple of friends, co-workers who... They're actually
[01:30:49.080 --> 01:30:55.480]   founders now of a company I backed. Anyway, we were going to an event in... I think it was in
[01:30:55.480 --> 01:31:01.800]   Atlanta. So it was a four-hour flight. So they opened the liquor drawer or whatever and saw the
[01:31:01.800 --> 01:31:06.600]   Pappy Van Winkle. And they asked if they could have... I was like, "Sure, take whatever you want."
[01:31:06.600 --> 01:31:12.200]   And then I went in the back and went to sleep. So by the time we land, four hours later, the entire...
[01:31:12.200 --> 01:31:12.760]   Oh, no.
[01:31:12.760 --> 01:31:16.440]   Pappy Van Winkle stash has been... They've gone through it. And it's like,
[01:31:16.440 --> 01:31:20.280]   it has all these different types of Pappy. You've got the Pappy 23. You've got some of these...
[01:31:20.280 --> 01:31:20.760]   The Reserve.
[01:31:20.760 --> 01:31:25.960]   You've got some of these antique ones. So they asked me... They've never flown on a private
[01:31:25.960 --> 01:31:31.080]   plane before. They asked me, "Hey, Sax, how much did this flight cost?" And I said,
[01:31:31.080 --> 01:31:34.760]   "It costs about $6,000 in jet fuel and about $8,000 in Pappy Van Winkle."
[01:31:34.760 --> 01:31:38.840]   Pour the Pappy into the jet. Oh, my God.
[01:31:38.840 --> 01:31:40.680]   It costs more in Pappy than in jet fuel.
[01:31:40.680 --> 01:31:41.960]   Listen, I'm from around the way. I'm looking for a Pappy. I'm looking for a Pappy.
[01:31:41.960 --> 01:31:46.200]   I'm leaving with something. I'm leaving with something. If I'm going to be on a PJ,
[01:31:46.200 --> 01:31:47.160]   I'm going to leave with something.
[01:31:47.160 --> 01:31:51.720]   I think we found a way to end this podcast in the most insufferable way possible.
[01:31:51.720 --> 01:31:52.600]   Finally, the saddest comes with crashing.
[01:31:52.600 --> 01:31:54.040]   Insufferable way possible.
[01:31:54.040 --> 01:31:55.640]   Delete all the private jet thoughts.
[01:31:55.640 --> 01:31:56.520]   All right, love you, besties.
[01:31:56.520 --> 01:31:58.200]   All right, Nick, edit it all out.
[01:31:58.200 --> 01:32:02.760]   Edit? No. Edit nothing. Highlight it. Make it the opening. All right. Four,
[01:32:02.760 --> 01:32:07.720]   the Queen of Quinoa, David Freedberg. Four, Rain Man, David Sax. And the dictator himself,
[01:32:07.720 --> 01:32:08.200]   Shema Palahapati.
[01:32:08.200 --> 01:32:11.160]   Saxxy Poo. We're playing next week at Saxxy Poo's place.
[01:32:11.160 --> 01:32:11.720]   Saxxy Poo.
[01:32:11.720 --> 01:32:13.400]   Ah, we're playing at beep.
[01:32:13.400 --> 01:32:14.360]   At the mausoleum.
[01:32:14.360 --> 01:32:16.840]   No, we're playing at the mausoleum. Nobody knows where the mausoleum is.
[01:32:16.840 --> 01:32:18.600]   Nobody knows where the mausoleum is, but it was where Saxx-
[01:32:18.600 --> 01:32:21.160]   I've been docked so many times. We better get security.
[01:32:21.160 --> 01:32:24.040]   Shema Palahapati is coming. He'll bring his.
[01:32:24.040 --> 01:32:24.680]   I'll bring mine.
[01:32:24.680 --> 01:32:26.360]   All right, we'll see you all next time. Bye-bye.
[01:32:26.360 --> 01:32:28.360]   Later.
[01:32:28.360 --> 01:32:29.640]   We'll let your winners ride.
[01:32:29.640 --> 01:32:32.520]   Rain Man, David Sax.
[01:32:32.520 --> 01:32:39.640]   And instead, we open sourced it to the fans and they've just gone crazy with it.
[01:32:39.640 --> 01:32:41.480]   Love you, besties.
[01:32:41.480 --> 01:32:43.480]   I'm going all in.
[01:32:43.480 --> 01:32:44.600]   I'm going all in.
[01:32:44.600 --> 01:32:45.240]   I'm going all in.
[01:32:45.240 --> 01:32:45.880]   I'm going all in.
[01:32:45.880 --> 01:32:46.600]   I'm going all in.
[01:32:46.600 --> 01:32:47.240]   I'm going all in.
[01:32:47.240 --> 01:32:47.800]   I'm going all in.
[01:32:47.800 --> 01:32:48.360]   I'm going all in.
[01:32:48.360 --> 01:32:48.920]   I'm going all in.
[01:32:48.920 --> 01:32:49.960]   Besties are gone.
[01:32:49.960 --> 01:32:50.440]   Besties are gone.
[01:32:50.440 --> 01:32:51.080]   Besties are gone.
[01:32:51.080 --> 01:32:57.480]   That's my dog taking a
[01:32:57.480 --> 01:33:02.280]   We should all just get a room and just have one big huge orgy because they're all just
[01:33:02.280 --> 01:33:02.920]   useless.
[01:33:02.920 --> 01:33:05.720]   It's like this like sexual tension that they just need to release somehow.
[01:33:05.720 --> 01:33:08.120]   Wet your feet.
[01:33:08.120 --> 01:33:08.840]   Beep.
[01:33:08.840 --> 01:33:10.040]   Wet your feet.
[01:33:10.040 --> 01:33:10.600]   Your feet.
[01:33:10.600 --> 01:33:11.240]   Beep.
[01:33:11.240 --> 01:33:12.200]   Wet your feet.
[01:33:12.200 --> 01:33:13.240]   We need to get merch.
[01:33:13.240 --> 01:33:13.800]   Besties are back.
[01:33:13.800 --> 01:33:15.000]   I'm going all in.
[01:33:15.000 --> 01:33:25.000]   I'm going all in.

