
[00:00:00.000 --> 00:00:03.000]   [MUSIC]
[00:00:03.000 --> 00:00:07.000]   So how do we make it so that more people can engage with self-driving cars without
[00:00:07.000 --> 00:00:09.800]   working for Google or Waymo or whatever?
[00:00:09.800 --> 00:00:12.200]   And the answer is you sort of, you take the essence and
[00:00:12.200 --> 00:00:14.960]   you reduce it to a unit that anybody can have access to,
[00:00:14.960 --> 00:00:16.680]   exactly as we did with drones.
[00:00:16.680 --> 00:00:20.120]   I didn't have a Predator, so I made one out of Lego and foam.
[00:00:20.120 --> 00:00:21.480]   And I didn't have a self-driving car, so
[00:00:21.480 --> 00:00:25.040]   I made one out of toy parts and a Raspberry Pi.
[00:00:25.040 --> 00:00:28.000]   And so what you're seeing is this incredible diversity of people who
[00:00:28.000 --> 00:00:28.760]   are engaged.
[00:00:28.760 --> 00:00:30.640]   >> You're listening to Gradient Descent,
[00:00:30.640 --> 00:00:33.160]   a show about machine learning in the real world.
[00:00:33.160 --> 00:00:35.600]   And I'm your host, Lucas Biewald.
[00:00:35.600 --> 00:00:40.120]   I knew Chris originally, or knew of Chris as the chief editor of Wired and
[00:00:40.120 --> 00:00:42.640]   the author of The Long Tail.
[00:00:42.640 --> 00:00:46.960]   But it turns out that in the last decade, he's gotten super into drones and
[00:00:46.960 --> 00:00:49.600]   started a company around DIY drones.
[00:00:49.600 --> 00:00:54.480]   And now works on 3D robotics and DIY robot racing.
[00:00:54.480 --> 00:00:58.040]   So it's a super interesting conversation and I think you'll enjoy it.
[00:00:58.040 --> 00:01:00.000]   Chris, it's such an honor to meet you and
[00:01:00.000 --> 00:01:03.520]   you have such an interesting kind of arc to your career.
[00:01:03.520 --> 00:01:07.240]   Before we get into the stuff you're doing now, could you kind of tell us about
[00:01:07.240 --> 00:01:11.160]   the highlights of what you've done before the robot stuff?
[00:01:11.160 --> 00:01:16.000]   >> Sure, it looks really chaotic and random, but every step made sense at
[00:01:16.000 --> 00:01:20.360]   the time and possibly if I do my job here, I can make it make sense in retrospect.
[00:01:20.360 --> 00:01:24.880]   So I was a terrible student, essentially failed out of high school,
[00:01:24.880 --> 00:01:28.120]   then failed out of college, then played in punk rock bands for
[00:01:28.120 --> 00:01:31.280]   most of my 20s working as a bicycle messenger.
[00:01:31.280 --> 00:01:32.280]   >> Wait, is that right?
[00:01:32.280 --> 00:01:33.360]   >> Yeah. >> Wait, really?
[00:01:33.360 --> 00:01:38.000]   >> Yeah, yeah, I mean, the best story is that I was in REM.
[00:01:38.000 --> 00:01:38.960]   >> No, wait, really?
[00:01:38.960 --> 00:01:42.120]   >> Well, there's a little bit of a footnote to that.
[00:01:42.120 --> 00:01:42.840]   >> Okay.
[00:01:42.840 --> 00:01:44.760]   >> Which is not the REM.
[00:01:44.760 --> 00:01:48.520]   [LAUGH] >> No, I was in a band called REM in
[00:01:48.520 --> 00:01:49.120]   Washington, DC.
[00:01:49.120 --> 00:01:50.720]   We were really good.
[00:01:50.720 --> 00:01:53.520]   We were about to release our first album and
[00:01:53.520 --> 00:01:56.400]   our manager said, that's the weirdest damn thing.
[00:01:56.400 --> 00:02:00.400]   There's this other band called REM, but they're releasing their album on the same
[00:02:00.400 --> 00:02:05.560]   day, but don't worry, they're from Athens, Georgia, how good could they be?
[00:02:05.560 --> 00:02:10.640]   And so we thought it would be really funny that we, the sort of the famous
[00:02:10.640 --> 00:02:15.320]   big city REM would invite the little country REM up to Washington,
[00:02:15.320 --> 00:02:17.480]   DC for a battle of the REMs.
[00:02:17.480 --> 00:02:20.320]   And the winner would get to rename the loser.
[00:02:22.440 --> 00:02:25.840]   Which they agreed to, and they came up and
[00:02:25.840 --> 00:02:30.560]   we played a joint record launch party.
[00:02:30.560 --> 00:02:32.520]   >> Wait, so this is like early 80s, right?
[00:02:32.520 --> 00:02:35.960]   >> Yeah, I guess it was about, I guess it was about 83-ish.
[00:02:35.960 --> 00:02:36.520]   >> 83?
[00:02:36.520 --> 00:02:39.360]   >> Maybe 85-ish, something like that.
[00:02:39.360 --> 00:02:42.080]   And so we have the famous 930 Club in Washington, DC.
[00:02:42.080 --> 00:02:44.400]   So we played and we flipped a coin to see who goes first.
[00:02:44.400 --> 00:02:48.720]   We went first and we played a good set, we got decent applause.
[00:02:48.720 --> 00:02:51.560]   We went to the bar to celebrate our inevitable victory.
[00:02:51.560 --> 00:02:55.440]   Then they came on second and their first song was Radio Free Europe,
[00:02:55.440 --> 00:02:56.920]   which was their first single.
[00:02:56.920 --> 00:02:57.560]   >> Yeah.
[00:02:57.560 --> 00:03:03.040]   >> And our jaws were on the floor and we're like, our beer's unfinished and
[00:03:03.040 --> 00:03:05.520]   we realized we were completely sunk.
[00:03:05.520 --> 00:03:09.040]   And they were great, as you might imagine.
[00:03:09.040 --> 00:03:12.160]   One, as you might imagine, and Mike Mills, the bass player,
[00:03:12.160 --> 00:03:16.320]   stayed around just long enough to rename us Egoslavia.
[00:03:16.320 --> 00:03:18.640]   >> [LAUGH] >> Because we were so
[00:03:18.640 --> 00:03:21.080]   arrogant to think that we would win.
[00:03:21.080 --> 00:03:25.080]   And we released our album under that name, and the rest is history.
[00:03:25.080 --> 00:03:27.200]   >> Wow, that's amazing.
[00:03:27.200 --> 00:03:30.400]   >> Yeah, so that was my little sort of brush of fame.
[00:03:30.400 --> 00:03:35.040]   But yeah, so complete fuck up, student, sorry, we may have to beat that.
[00:03:35.040 --> 00:03:37.200]   But eventually in my late 20s, I was like,
[00:03:37.200 --> 00:03:41.680]   I don't think this punk rock thing is really working out for me.
[00:03:41.680 --> 00:03:43.880]   I should probably use my brain again.
[00:03:43.880 --> 00:03:48.920]   And as a teenager, I'd been sort of thrilled by physics and
[00:03:48.920 --> 00:03:51.800]   I got the Feynman lectures on my 16th birthday,
[00:03:51.800 --> 00:03:54.280]   which was like I read those instead of going to school.
[00:03:54.280 --> 00:03:57.040]   And so I went back to college and I decided at this point I had so
[00:03:57.040 --> 00:04:01.120]   much to prove that I was gonna do the hardest thing possible, which was physics.
[00:04:01.120 --> 00:04:03.840]   And so I got a degree in computational physics,
[00:04:03.840 --> 00:04:06.120]   which was a new thing at the time.
[00:04:06.120 --> 00:04:10.520]   And the job of all of us physicists in those days was basically to understand
[00:04:10.520 --> 00:04:13.680]   the nature of matter as we go closer and closer to the Big Bang, so
[00:04:13.680 --> 00:04:15.560]   higher and higher energies.
[00:04:15.560 --> 00:04:19.120]   And that means bigger and bigger and more expensive particle accelerators.
[00:04:19.120 --> 00:04:21.120]   And we were all sort of queued up to work on something called
[00:04:21.120 --> 00:04:24.600]   the Superconducting Super Collider, which was in Texas.
[00:04:24.600 --> 00:04:28.760]   And the problem is the cost of the collider kind of scales with the energy
[00:04:28.760 --> 00:04:33.080]   it produces and went from 8 billion to 16 billion to 19 billion and
[00:04:33.080 --> 00:04:34.640]   then Congress canceled it.
[00:04:34.640 --> 00:04:35.400]   And that was it.
[00:04:35.400 --> 00:04:40.040]   There were no more interesting experimental facilities in the United States and
[00:04:40.040 --> 00:04:44.920]   it was all gonna be kind of queuing up for CERN, the LHC in CERN, Switzerland.
[00:04:44.920 --> 00:04:48.360]   And I realized I could see my career.
[00:04:48.360 --> 00:04:51.760]   I was gonna be like an assistant professor at Iowa State,
[00:04:51.760 --> 00:04:55.400]   waiting for my experiments to run at CERN.
[00:04:55.400 --> 00:04:58.880]   And 20 years later it would run and it would probably fail and
[00:04:58.880 --> 00:05:02.760]   I would be author 300 on a paper about a experimental failure and
[00:05:02.760 --> 00:05:04.760]   I was like, that sucks.
[00:05:04.760 --> 00:05:06.320]   And I wasn't even very good at it.
[00:05:06.320 --> 00:05:11.000]   So it was time to move on and so I went to the adjacent space,
[00:05:11.000 --> 00:05:13.640]   which was the science journals, Nature and Science,
[00:05:13.640 --> 00:05:15.840]   to write about science rather than be a scientist.
[00:05:15.840 --> 00:05:19.440]   And then went from there to the Economist to lead their tech coverage.
[00:05:19.440 --> 00:05:24.080]   One of the things that we learned from that generation of physicists who just
[00:05:24.080 --> 00:05:28.280]   basically their careers vaporized with the SSC,
[00:05:28.280 --> 00:05:31.760]   was that although physics was not gonna be our future,
[00:05:31.760 --> 00:05:36.640]   we had accidentally created the Internet as physicists.
[00:05:36.640 --> 00:05:40.680]   So the Internet, as you know, was created largely to link research facilities.
[00:05:40.680 --> 00:05:44.360]   The web was created at CERN, a physics lab.
[00:05:44.360 --> 00:05:48.000]   And we as physicists had the only big data out there.
[00:05:48.000 --> 00:05:50.840]   We were the only people doing big data because we had all this data coming from
[00:05:50.840 --> 00:05:51.720]   the particle accelerator.
[00:05:51.720 --> 00:05:54.440]   So we had these skills, big data and Internet.
[00:05:54.440 --> 00:05:59.800]   And so when this generation vaporized to the winds,
[00:05:59.800 --> 00:06:02.000]   most of them went to Wall Street to become quants,
[00:06:02.000 --> 00:06:04.720]   which was the next source of big data.
[00:06:04.720 --> 00:06:08.360]   And then some of the ones who didn't do that went to sort of create
[00:06:08.360 --> 00:06:13.000]   the emerging Internet industry, which is kind of what I did as a writer and
[00:06:13.000 --> 00:06:15.080]   sort of kind of move media onto the Internet.
[00:06:15.080 --> 00:06:20.160]   >> Before you go further, getting a PhD in quantum physics is no joke.
[00:06:20.160 --> 00:06:25.880]   I have a lot of friends who feel kind of stuck in academia and
[00:06:25.880 --> 00:06:29.240]   have trouble getting out even though the careers available to physicists, for
[00:06:29.240 --> 00:06:30.480]   example, are quite good.
[00:06:30.480 --> 00:06:34.880]   I think most people feel a little bit like failures because inside of it,
[00:06:34.880 --> 00:06:38.160]   you're so funneled through this escalator to success.
[00:06:38.160 --> 00:06:41.320]   I mean, you speak so rationally about it, but
[00:06:41.320 --> 00:06:45.160]   actually I feel like most people aren't able to make that leap.
[00:06:45.160 --> 00:06:49.720]   Do you think it was like your perspective of having not jumped from undergrad
[00:06:49.720 --> 00:06:51.680]   to grad school or something else?
[00:06:51.680 --> 00:06:53.960]   >> Yeah, I mean, to be clear, I don't have a PhD.
[00:06:53.960 --> 00:06:58.160]   I dropped out of the PhD program, not even an ABD, I didn't get that far.
[00:06:58.160 --> 00:07:04.640]   But if you love physics, it's kind of heartbreaking to see what's happening now.
[00:07:04.640 --> 00:07:06.920]   So you're inspired by the greats.
[00:07:06.920 --> 00:07:11.240]   But like all scientific disciplines, you need theory and
[00:07:11.240 --> 00:07:16.320]   experiments to be matched by a sort of a limited amount of time.
[00:07:16.320 --> 00:07:19.840]   So a theory comes out and you want the experiment to be able to kind of falsify
[00:07:19.840 --> 00:07:21.560]   or not within, say, five years.
[00:07:21.560 --> 00:07:28.720]   If that gap grows, then theory becomes unmoored in reality and
[00:07:28.720 --> 00:07:30.720]   it becomes almost like poetry.
[00:07:30.720 --> 00:07:35.760]   And now it's like the coolest theories and the ones that sort of are best told are
[00:07:35.760 --> 00:07:38.000]   the ones that spark the imagination.
[00:07:38.000 --> 00:07:39.960]   And it's almost like metaphysics.
[00:07:39.960 --> 00:07:41.360]   No, it's no longer physics.
[00:07:41.360 --> 00:07:43.120]   It's almost philosophy.
[00:07:43.120 --> 00:07:47.640]   And that's a really weird place for a scientific discipline to be.
[00:07:47.640 --> 00:07:53.440]   And I think that the people who stick with it, and all they can really do,
[00:07:53.440 --> 00:07:58.000]   they can either line up for an experimental facility and see you in
[00:07:58.000 --> 00:08:02.080]   a generation, or they can go into theory.
[00:08:02.080 --> 00:08:06.280]   And it's seductive in that it's math, but it's not real.
[00:08:06.280 --> 00:08:08.040]   And I think you can really get lost there.
[00:08:08.040 --> 00:08:09.640]   It's almost religious.
[00:08:09.640 --> 00:08:14.200]   There is a slight ray of hope, though, in cosmology.
[00:08:14.200 --> 00:08:16.960]   And that rather than having physics facilities,
[00:08:16.960 --> 00:08:22.160]   on a terrestrial physics facilities, that we use the stars to create energies and
[00:08:22.160 --> 00:08:22.840]   to observe them.
[00:08:22.840 --> 00:08:27.240]   So we're getting much, much better at using astrophysics as an experiment, but
[00:08:27.240 --> 00:08:28.160]   it can't do everything.
[00:08:28.160 --> 00:08:29.720]   So I mean, I'm not sure I answered your question.
[00:08:29.720 --> 00:08:32.240]   But basically, if you fall in love with physics,
[00:08:32.240 --> 00:08:37.120]   what you get is a really good grounding in statistics and math.
[00:08:37.120 --> 00:08:39.400]   But it's not a great career.
[00:08:39.400 --> 00:08:42.200]   And it's probably best to use that grounding.
[00:08:42.200 --> 00:08:45.520]   And then there's plenty of physicists out there doing good work in machine
[00:08:45.520 --> 00:08:46.360]   learning elsewhere.
[00:08:46.360 --> 00:08:49.440]   And so that's why my degree was actually computational physics,
[00:08:49.440 --> 00:08:54.080]   which in retrospect was more about compute than it was physics.
[00:08:54.080 --> 00:08:55.480]   >> I see, interesting.
[00:08:55.480 --> 00:08:59.240]   And so then, but then you sort of left that whole thing to be a journalist.
[00:08:59.240 --> 00:09:01.800]   >> Well, yeah, I mean, again, it was sort of stepwise.
[00:09:01.800 --> 00:09:02.720]   My parents were journalists.
[00:09:02.720 --> 00:09:05.640]   So it was kind of like the one thing I was sure I was not going to do was
[00:09:05.640 --> 00:09:06.720]   journalism.
[00:09:06.720 --> 00:09:09.880]   But I went writing about it.
[00:09:09.880 --> 00:09:13.560]   But again, science and nature are scientific journals.
[00:09:13.560 --> 00:09:16.960]   So it felt, it wasn't like grubby newspapers.
[00:09:16.960 --> 00:09:20.800]   And then The Economist, again, everybody was a PhD of one sort or
[00:09:20.800 --> 00:09:22.080]   another, most people were.
[00:09:22.080 --> 00:09:24.880]   So it really felt like you were part of extended academia.
[00:09:25.960 --> 00:09:32.480]   And then moving to Wired, and to take over Wired in 90, sorry, 2001.
[00:09:32.480 --> 00:09:35.800]   That was the first leap into traditional media owned by CondÃ© Nast,
[00:09:35.800 --> 00:09:38.480]   which owns like Vanity Fair and New Yorker and things like that.
[00:09:38.480 --> 00:09:41.960]   So traditional media, but they bought Wired, they hadn't created it.
[00:09:41.960 --> 00:09:47.200]   And Wired was created largely as a evangelical
[00:09:47.200 --> 00:09:50.960]   Bible of the emerging Internet.
[00:09:50.960 --> 00:09:56.200]   And one of the reasons I left science was because in 93,
[00:09:56.200 --> 00:10:00.480]   when Wired was launched and the Internet was just forming, I wasn't sure what it was.
[00:10:00.480 --> 00:10:03.280]   I mean, again, we thought it was just like a way to telnet into the cray at
[00:10:03.280 --> 00:10:04.000]   Los Alamos.
[00:10:04.000 --> 00:10:08.240]   And then this magazine comes out with these day glow colors saying,
[00:10:08.240 --> 00:10:09.600]   no, this is a cultural revolution.
[00:10:09.600 --> 00:10:10.560]   This is going to change the world.
[00:10:10.560 --> 00:10:12.120]   This is going to change everything.
[00:10:12.120 --> 00:10:13.240]   And it just blew my mind.
[00:10:13.240 --> 00:10:15.920]   I suddenly realized that this thing I was kind of good at actually had these big
[00:10:15.920 --> 00:10:19.600]   implications and that dictated the direction of my career.
[00:10:19.600 --> 00:10:23.960]   And so when the opportunity came to lead it, I was like, yeah,
[00:10:23.960 --> 00:10:25.640]   this is the religion I believe in.
[00:10:25.640 --> 00:10:29.080]   And it's funny because 2001 is a really interesting year, right?
[00:10:29.080 --> 00:10:32.680]   Was this pre kind of bubble collapse or post?
[00:10:32.680 --> 00:10:33.840]   No, post.
[00:10:33.840 --> 00:10:35.840]   It was like the best and the worst time.
[00:10:35.840 --> 00:10:38.400]   So the bubble collapsed in March of 2000.
[00:10:38.400 --> 00:10:39.200]   2000.
[00:10:39.200 --> 00:10:39.840]   Yeah.
[00:10:39.840 --> 00:10:47.160]   And so at that point, most of the world was saying, this is a subprime mortgage.
[00:10:47.160 --> 00:10:52.120]   This is a hoax, perhaps even worse.
[00:10:52.120 --> 00:10:56.120]   But you had to believe that the internet was not the stock market.
[00:10:56.120 --> 00:10:58.560]   That there was something real at the core of the stock market and
[00:10:58.560 --> 00:11:02.320]   that the bubble was a finance artifact.
[00:11:02.320 --> 00:11:04.240]   But the underlying trends were real.
[00:11:04.240 --> 00:11:07.880]   And it was very unpopular and somewhat minority view at the time
[00:11:07.880 --> 00:11:08.960]   that the internet was real.
[00:11:08.960 --> 00:11:13.280]   But if you were to bet at that time as I did, that the internet was real and
[00:11:13.280 --> 00:11:15.800]   the stock market thing was a stock market thing.
[00:11:15.800 --> 00:11:18.680]   Then you're buying at the bottom, essentially.
[00:11:18.680 --> 00:11:22.160]   So I don't think I would have been offered the opportunity to take over Wired
[00:11:22.160 --> 00:11:25.840]   if everybody knew it was the hot place to be.
[00:11:25.840 --> 00:11:28.680]   And I wouldn't have been able to hire the people I did.
[00:11:28.680 --> 00:11:33.200]   And as I say, the best time to take over when you're not particularly
[00:11:33.200 --> 00:11:37.160]   experienced with this kind of stuff is at the bottom because you can hire people.
[00:11:37.160 --> 00:11:40.880]   Your lack of success is cloaked by the market's lack of success.
[00:11:40.880 --> 00:11:42.480]   It's impossible to succeed in that environment.
[00:11:42.480 --> 00:11:46.480]   So no one can tell whether your failures are yours or exogenous ones.
[00:11:46.480 --> 00:11:48.600]   And then thirdly, once things start to pick up again,
[00:11:48.600 --> 00:11:51.440]   your year on year growth looks amazing.
[00:11:51.440 --> 00:11:54.160]   >> [LAUGH] >> So it worked out really well, but
[00:11:54.160 --> 00:11:57.280]   it was a very counter cyclical bet at the time.
[00:11:57.280 --> 00:12:01.280]   And if you look back at underlying internet adoption trends,
[00:12:01.280 --> 00:12:03.480]   you almost can't see the bubble bursting.
[00:12:03.480 --> 00:12:05.920]   It was really isolated to the stock market.
[00:12:05.920 --> 00:12:08.880]   And all that capital created a huge amount of infrastructure,
[00:12:08.880 --> 00:12:10.120]   which we still enjoy today.
[00:12:11.680 --> 00:12:15.120]   >> Interesting, so what about the long tail?
[00:12:15.120 --> 00:12:17.320]   How did that kind of come about?
[00:12:17.320 --> 00:12:18.240]   >> Yeah, so thank you.
[00:12:18.240 --> 00:12:23.120]   So when you take a physicist basically by heart and you stick them in media.
[00:12:23.120 --> 00:12:27.480]   I'm not trained as a writer or as an editor,
[00:12:27.480 --> 00:12:29.520]   didn't have any particular interest in media.
[00:12:29.520 --> 00:12:32.040]   I was really interested in the story, but I'm a nerd.
[00:12:32.040 --> 00:12:37.720]   So what am I going to do is I'm going to try to do research about this story.
[00:12:37.720 --> 00:12:42.640]   And so not trained as a journalist, I was trained as a data analyst.
[00:12:42.640 --> 00:12:48.560]   And so I was like, well, something important is going on in the server farms
[00:12:48.560 --> 00:12:50.200]   of Amazon and Netflix.
[00:12:50.200 --> 00:12:54.600]   We can probably see it as a lens on human behavior in a way that we never had before.
[00:12:54.600 --> 00:13:00.280]   We're basically instrumenting society in a way we never had before.
[00:13:00.280 --> 00:13:03.200]   And this is obvious today, but it wasn't at the time.
[00:13:03.200 --> 00:13:07.440]   And I said, I bet if I could get that data to see how consumer preference
[00:13:07.440 --> 00:13:10.440]   actually looked at scale, I bet it would be interesting.
[00:13:10.440 --> 00:13:14.240]   I bet we'd learn things that we weren't seeing with the, I don't know,
[00:13:14.240 --> 00:13:19.320]   Department of Commerce reports or the Walmart quarterly earnings.
[00:13:19.320 --> 00:13:20.480]   And so I asked.
[00:13:20.480 --> 00:13:24.200]   And so I just started, I asked the Yahoo's and the Netflix's and
[00:13:24.200 --> 00:13:25.840]   the Amazon's for their data.
[00:13:25.840 --> 00:13:30.320]   And weirdly, they had assigned a couple NDAs and
[00:13:30.320 --> 00:13:32.400]   anonymized some stuff, but they gave it to me.
[00:13:32.400 --> 00:13:35.680]   And I just got these massive data sets.
[00:13:35.680 --> 00:13:37.080]   And I did really dumb stuff.
[00:13:37.080 --> 00:13:38.960]   I just stuck it into a spreadsheet.
[00:13:38.960 --> 00:13:44.040]   And you have basically sales of the set of products, take music for example.
[00:13:44.040 --> 00:13:48.160]   You get like a million tracks, and then you rank them in terms of popularity.
[00:13:48.160 --> 00:13:51.640]   And I just stuck them in a spreadsheet and nothing showed up.
[00:13:51.640 --> 00:13:54.160]   It's like the graph was empty.
[00:13:54.160 --> 00:13:56.040]   And I was like, wait, what happened here?
[00:13:56.040 --> 00:14:00.760]   And I said, well, let me just cut off the first 100 and
[00:14:00.760 --> 00:14:03.880]   just graph from 101 down to a million.
[00:14:03.880 --> 00:14:08.600]   And then I could see the line and I realized what happened is that the
[00:14:08.600 --> 00:14:12.400]   inequity of the marketplace, the incredible scale differences between
[00:14:12.400 --> 00:14:15.120]   the number one track and the number one million track, it basically compressed
[00:14:15.120 --> 00:14:18.160]   my scales, so the scales are set by the number one.
[00:14:18.160 --> 00:14:22.440]   The Y is set by the number one, and the X is set by the number million.
[00:14:22.440 --> 00:14:25.640]   And so the line was basically just right along the axes.
[00:14:25.640 --> 00:14:29.320]   And until you cut off the head, you couldn't see the tail.
[00:14:29.320 --> 00:14:34.320]   And it was simply that dumb thing that I did one night with a spreadsheet that
[00:14:34.320 --> 00:14:38.160]   kind of created this that just shifted my gaze to the right.
[00:14:38.160 --> 00:14:42.320]   And I realized there was a lot there that we weren't paying attention to
[00:14:42.320 --> 00:14:45.920]   because it was high number but low magnitude.
[00:14:45.920 --> 00:14:48.320]   And that created the notion of the long tail.
[00:14:48.320 --> 00:14:52.440]   And then it got to other data sets and they all confirmed that if you have
[00:14:52.440 --> 00:14:57.000]   basically infinite inventory and mechanisms for
[00:14:57.000 --> 00:15:01.920]   people to explore that inventory, that consumer preference shifts down the tail.
[00:15:01.920 --> 00:15:05.600]   Now, not entirely, we still have network effects and hits and things like that.
[00:15:05.600 --> 00:15:07.920]   But basically, there was a lot of suppressed preference for
[00:15:07.920 --> 00:15:13.480]   niche stuff that was suppressed by the scarcity function of shelf space
[00:15:13.480 --> 00:15:15.680]   that was opened up by the non-scarcity,
[00:15:15.680 --> 00:15:20.680]   by the abundance of online databases and e-commerce, etc.
[00:15:20.680 --> 00:15:24.160]   What's interesting is the caveat to that story is that I got a bunch of data sets
[00:15:24.160 --> 00:15:28.320]   and then about a year later, AOL was also sharing some data and
[00:15:28.320 --> 00:15:33.480]   shared with some academics and somebody figured out that you could de-anonymize.
[00:15:33.480 --> 00:15:34.520]   The search data.
[00:15:34.520 --> 00:15:35.240]   The search data.
[00:15:35.240 --> 00:15:36.760]   They could de-anonymize the search data.
[00:15:36.760 --> 00:15:39.360]   Yeah, and it was a shit show.
[00:15:39.360 --> 00:15:43.040]   And as a result of that, all the companies stopped sharing data.
[00:15:43.040 --> 00:15:46.280]   So, it's basically a 12-month period where you could do the work I did.
[00:15:46.280 --> 00:15:48.680]   And internally, companies do it all the time, but
[00:15:48.680 --> 00:15:50.800]   externally, you can't get the data anymore.
[00:15:50.800 --> 00:15:58.040]   But you also kind of, I feel like you named this really important phenomenon.
[00:15:58.040 --> 00:16:01.280]   I think it's still called this today.
[00:16:01.280 --> 00:16:06.560]   It seems like there's a real skill and you just nailed something that's so important.
[00:16:06.560 --> 00:16:13.040]   So, I have to confess that yes, I did kind of come up with that name.
[00:16:13.040 --> 00:16:14.880]   It turns out that actually that phrase has been used before.
[00:16:14.880 --> 00:16:16.160]   People talk about fat tails, etc.
[00:16:16.160 --> 00:16:17.440]   Fat tails, I heard it, yeah.
[00:16:17.440 --> 00:16:20.120]   Yeah, it probably has been used, but I think I called it.
[00:16:20.120 --> 00:16:22.280]   I think I was at least a little inventive in my own head, but
[00:16:22.280 --> 00:16:24.560]   I didn't think it was a big deal.
[00:16:24.560 --> 00:16:28.440]   And then I, it was like slide seven in my presentation.
[00:16:28.440 --> 00:16:31.560]   And then I went to see Reed Hastings, the CEO of Netflix, and
[00:16:31.560 --> 00:16:34.840]   kind of walked through my presentation, walked through my analysis with him,
[00:16:34.840 --> 00:16:36.040]   because they'd helped.
[00:16:36.040 --> 00:16:39.160]   And he got to slide six and he says, there's your headline right there.
[00:16:39.160 --> 00:16:42.280]   And so Reed Hastings was the one who actually identified the long tails being
[00:16:42.280 --> 00:16:44.960]   the sort of, the Moe's juice, if you will.
[00:16:44.960 --> 00:16:45.520]   Wow, I knew it.
[00:16:45.520 --> 00:16:46.880]   They captured it.
[00:16:46.880 --> 00:16:48.040]   Wow.
[00:16:48.040 --> 00:16:51.960]   And I guess it's funny, I feel like that's maybe the thing you're best known for.
[00:16:51.960 --> 00:16:53.960]   Are you kind of sick of talking about it?
[00:16:53.960 --> 00:16:56.200]   No, no, you know what?
[00:16:56.200 --> 00:17:00.280]   I'm not doing any active research in it, but no, I mean,
[00:17:00.280 --> 00:17:05.600]   what's interesting is that any sufficiently novel idea will separate
[00:17:05.600 --> 00:17:06.800]   the audience into two halves.
[00:17:06.800 --> 00:17:10.560]   There's those who say no way, and those who say duh.
[00:17:10.560 --> 00:17:12.880]   And it almost goes generationally.
[00:17:12.880 --> 00:17:16.840]   So anybody who grew up on the internet was like, duh, of course.
[00:17:16.840 --> 00:17:20.360]   Lots of products, lots of choice, lots of niches are a thing.
[00:17:20.360 --> 00:17:23.520]   And anybody who kind of grew up before that, and I don't mean to be ageist, but
[00:17:23.520 --> 00:17:27.480]   it's kind of cultural age, if not chronological.
[00:17:27.480 --> 00:17:31.120]   There's a lot of people who grew up culturally in the era of blockbusters and
[00:17:31.120 --> 00:17:36.000]   top 40 radio and three TV channels, etc.
[00:17:36.000 --> 00:17:39.240]   Who basically argued that the blockbuster was forever and
[00:17:39.240 --> 00:17:45.960]   that the long tail was a mirage that probably wrongly gave hope
[00:17:45.960 --> 00:17:49.000]   to niche artists that they could somehow work.
[00:17:49.000 --> 00:17:51.320]   And of course, they're right.
[00:17:51.320 --> 00:17:53.880]   And it was clear, I never said it was the end of the blockbuster.
[00:17:53.880 --> 00:17:56.480]   I said it was the end of the monopoly of the blockbuster.
[00:17:56.480 --> 00:18:01.680]   And I also, it was clear that the economic rewards would be felt
[00:18:01.680 --> 00:18:05.280]   largely by the aggregators rather than the creators.
[00:18:05.280 --> 00:18:08.600]   And the cultural rewards are felt by all of us, of course.
[00:18:08.600 --> 00:18:12.200]   And the creators obviously take music or writing or whatever.
[00:18:12.200 --> 00:18:15.960]   There's certainly some psychic rewards of being listened to or read.
[00:18:15.960 --> 00:18:20.400]   But the fact that the Internet exists doesn't mean that a struggling
[00:18:20.400 --> 00:18:23.320]   musician is gonna be any less struggling.
[00:18:23.320 --> 00:18:27.120]   So I think there's a lot of people who just kind of read it as only
[00:18:27.120 --> 00:18:30.440]   kind of blockbusters are dead, therefore the long tail is wrong.
[00:18:30.440 --> 00:18:32.120]   And they still say that.
[00:18:32.120 --> 00:18:34.880]   And there's a lot of other people who feel that it's completely self evident.
[00:18:34.880 --> 00:18:40.000]   One of the kind of tragedies is that I wrote the book before YouTube existed.
[00:18:40.000 --> 00:18:44.720]   And YouTube, of course, is the canonical long tail marketplace of all kind of
[00:18:44.720 --> 00:18:46.240]   cultures and niches, etc.
[00:18:46.240 --> 00:18:48.480]   And so on one hand, it's kind of weird.
[00:18:48.480 --> 00:18:52.440]   I mean, I still have academics who like sort of show me people really don't
[00:18:52.440 --> 00:18:56.360]   understand the math, the long tail, and they keep saying percentages.
[00:18:56.360 --> 00:19:01.680]   It's like, well, 1%, the top 1% of X still has 90% of the,
[00:19:01.680 --> 00:19:05.960]   they don't realize that it's 1% of like 100 million.
[00:19:05.960 --> 00:19:08.880]   And so it's from an absolute numbers is a lot, but still.
[00:19:08.880 --> 00:19:12.720]   And I still get this all the time from academics who like in long tails of
[00:19:12.720 --> 00:19:14.920]   hoax because top 1%, etc.
[00:19:14.920 --> 00:19:21.400]   Meanwhile, anybody who like, I should be able to say, YouTube, discuss.
[00:19:21.400 --> 00:19:26.360]   But for some reason, some people just don't want to see it that way.
[00:19:26.360 --> 00:19:30.800]   So I do end up still trying to kind of find evidence of it.
[00:19:30.800 --> 00:19:34.800]   I mean, actually, it was a lot less controversial than my next book, Free,
[00:19:34.800 --> 00:19:37.280]   which was the economics of free stuff.
[00:19:37.280 --> 00:19:40.640]   And obviously, economics is largely focused on monetary economics.
[00:19:40.640 --> 00:19:43.880]   And yet there's obviously a non-monetary marketplace out there as well.
[00:19:43.880 --> 00:19:45.440]   I mean, we're doing it right now.
[00:19:45.440 --> 00:19:48.080]   You don't charge your listeners for this and I don't charge you for this.
[00:19:48.080 --> 00:19:52.800]   And we're doing some exchange, some non-monetary exchange that has value, but
[00:19:52.800 --> 00:19:54.680]   economists don't know how to measure it.
[00:19:54.680 --> 00:19:56.840]   So that one was actually much more controversial.
[00:19:56.840 --> 00:19:58.200]   >> Interesting, what was the controversy?
[00:19:58.200 --> 00:20:01.720]   Or did you feel like you got a lot of negative feedback?
[00:20:01.720 --> 00:20:04.400]   >> Yeah, I mean, especially from media.
[00:20:04.400 --> 00:20:06.800]   I have a kind of a love-hate relationship with the media,
[00:20:06.800 --> 00:20:10.600]   which is increasingly becoming a hate-hate relationship.
[00:20:10.600 --> 00:20:15.280]   But the newspaper business was imploding, and they largely believed that
[00:20:15.280 --> 00:20:19.360]   the canonical error that the newspaper business made was putting their content
[00:20:19.360 --> 00:20:20.440]   free on the Internet.
[00:20:20.440 --> 00:20:23.880]   And had they only set up paywalls at the beginning,
[00:20:23.880 --> 00:20:26.000]   that somehow media would be preserved.
[00:20:26.000 --> 00:20:28.600]   And people in media take themselves pretty seriously.
[00:20:28.600 --> 00:20:31.520]   They feel like they're the fourth estate and protectors of democracy, and
[00:20:31.520 --> 00:20:34.360]   the only people who can keep us from the mob, etc.
[00:20:34.360 --> 00:20:38.600]   And so they believed that free content on the Internet was destroying
[00:20:38.600 --> 00:20:43.680]   this foundation of democracy, and that I was not helping, if you will.
[00:20:43.680 --> 00:20:47.840]   >> [LAUGH] Okay, so what happened next?
[00:20:47.840 --> 00:20:49.880]   So then you got into drone?
[00:20:49.880 --> 00:20:53.680]   >> Yeah, so running a magazine by day, but I still nerd by night.
[00:20:53.680 --> 00:20:58.320]   And so my first nerd thing was the long tail and the statistical analysis.
[00:20:58.320 --> 00:21:00.320]   And writing books, they were largely economic books,
[00:21:00.320 --> 00:21:01.760]   because I'm not trained in economics.
[00:21:01.760 --> 00:21:06.040]   My time at The Economist sort of osmotically gave me some exposure.
[00:21:06.040 --> 00:21:10.280]   But still, basically, I'm a programmer by heart.
[00:21:10.280 --> 00:21:14.360]   And as my kids got older, I've got five kids, and they were,
[00:21:14.360 --> 00:21:16.720]   my wife's a scientist as well.
[00:21:16.720 --> 00:21:19.000]   And we try to get them interested in science and technology.
[00:21:19.000 --> 00:21:22.040]   And so as they got older, I was thinking of cool things to do with them.
[00:21:22.040 --> 00:21:24.680]   I actually started a site called Geek Dad.
[00:21:24.680 --> 00:21:26.320]   >> Are you starting Geek Dad?
[00:21:26.320 --> 00:21:27.880]   Wait, I know Geek Dad, that's awesome.
[00:21:27.880 --> 00:21:32.000]   >> Yeah, although I think Geek Mom is actually doing even better right now.
[00:21:32.000 --> 00:21:32.960]   >> Nice.
[00:21:32.960 --> 00:21:33.960]   >> Also a spin off of this.
[00:21:33.960 --> 00:21:37.680]   But so I started Geek Dad, and it was largely the notion was,
[00:21:37.680 --> 00:21:43.760]   STEM projects that were sort of fun for the kid and fun for the adult.
[00:21:43.760 --> 00:21:45.320]   Because there was a lot of things that were fun for the adult and
[00:21:45.320 --> 00:21:47.600]   not fun for the kid, or fun for the kid and not fun for the adult.
[00:21:47.600 --> 00:21:50.120]   But the ones that kind of got it exactly right.
[00:21:50.120 --> 00:21:53.560]   And so in the course of doing that, I was like, robots.
[00:21:53.560 --> 00:21:55.360]   We should probably do something with robots.
[00:21:55.360 --> 00:22:00.040]   And the kids are like, so we got a Lego, I was on their advisory board.
[00:22:00.040 --> 00:22:03.240]   And Lego sent me the first Lego Mindstorms.
[00:22:03.240 --> 00:22:04.920]   >> Whoa, man, wow.
[00:22:04.920 --> 00:22:07.080]   [LAUGH] >> That's pretty cool.
[00:22:07.080 --> 00:22:09.720]   So they sent me the first Lego Mindstorms beta testing.
[00:22:09.720 --> 00:22:13.760]   And so I showed it to the kids, and the kids are like, yeah, we'll do it.
[00:22:13.760 --> 00:22:16.920]   And so you follow the instruction you put together, and it takes all morning.
[00:22:16.920 --> 00:22:19.920]   And then you have a little sort of wheeled robot that'll kind of move towards
[00:22:19.920 --> 00:22:20.920]   a wall and then back away.
[00:22:20.920 --> 00:22:24.120]   And the kids are like, you're kidding me.
[00:22:24.120 --> 00:22:25.680]   >> [LAUGH] >> No, sorry,
[00:22:25.680 --> 00:22:27.920]   definitely believe that.
[00:22:27.920 --> 00:22:30.120]   They do not use that kind of language.
[00:22:30.120 --> 00:22:35.040]   But internally, whatever the sort of nine-year-old equivalent of that is.
[00:22:35.040 --> 00:22:38.440]   And I realized that Hollywood has ruined robotics for
[00:22:38.440 --> 00:22:42.240]   kids because you've got transformers and this incredible stuff.
[00:22:42.240 --> 00:22:46.760]   And meanwhile, real robots, at least most of them, don't really do anything.
[00:22:46.760 --> 00:22:48.680]   We're talking about Roomba, etc.
[00:22:48.680 --> 00:22:53.200]   So the sort of the gap between the sort of Hollywood version of robots and
[00:22:53.200 --> 00:22:57.360]   the prosaic reality was such that it was really hard to get them excited.
[00:22:57.360 --> 00:23:00.040]   So I thought, well, what would be cooler than a rolling robot?
[00:23:00.040 --> 00:23:02.240]   I thought a flying robot.
[00:23:02.240 --> 00:23:04.240]   And so I'm like, well, I don't actually know what a flying robot is.
[00:23:04.240 --> 00:23:07.600]   >> [LAUGH] >> I just, Astro Boy or something,
[00:23:07.600 --> 00:23:08.320]   I'm not sure.
[00:23:08.320 --> 00:23:12.280]   So I literally Googled flying robot, and the first result was drone.
[00:23:12.280 --> 00:23:16.120]   I was like, huh, I had thought, I guess a drone is a flying robot.
[00:23:16.120 --> 00:23:17.240]   Wait, what's a drone?
[00:23:17.240 --> 00:23:19.160]   So I Googled drone, and a drone is like a-
[00:23:19.160 --> 00:23:20.200]   >> Wait, what year is this?
[00:23:20.200 --> 00:23:23.160]   This is like a- >> This is 96, 97.
[00:23:23.160 --> 00:23:23.680]   >> Got it.
[00:23:23.680 --> 00:23:26.320]   >> Sorry, 2006, 2007.
[00:23:26.320 --> 00:23:30.080]   >> Okay, wow, so drones are not in the Zeitgeist yet.
[00:23:30.080 --> 00:23:33.000]   >> No, well, drones were in the Zeitgeist as a military thing.
[00:23:33.000 --> 00:23:34.120]   >> I see, right, right, right.
[00:23:34.120 --> 00:23:37.600]   >> But there were no consumer drones, you couldn't buy one.
[00:23:37.600 --> 00:23:39.200]   I know, I know, it seems so crazy now.
[00:23:39.200 --> 00:23:43.280]   But at the time, it was like drones were like a predator that shot hellfire
[00:23:43.280 --> 00:23:44.120]   missiles, etc.
[00:23:44.120 --> 00:23:46.080]   It was really a purely military thing.
[00:23:46.080 --> 00:23:46.920]   >> Right. >> And so I Googled,
[00:23:46.920 --> 00:23:48.000]   it sounded like, what's a drone?
[00:23:48.000 --> 00:23:50.600]   And drone's like basically a plane with a brain.
[00:23:50.600 --> 00:23:51.480]   It had an autopilot.
[00:23:51.480 --> 00:23:54.360]   And I'm like, okay, what's an autopilot?
[00:23:54.360 --> 00:23:58.960]   And you Google the autopilot, and it's like basically sensors and compute.
[00:23:58.960 --> 00:24:03.600]   And it's kind of figures out which way is down, which way is up, GPS, etc.
[00:24:03.600 --> 00:24:06.160]   And I was like, those sensors and that compute,
[00:24:06.160 --> 00:24:08.920]   that's kind of what we have here in the Lego Mindstorms box.
[00:24:08.920 --> 00:24:12.960]   Which came with accelerometer and magnetometer and gyro, etc.
[00:24:12.960 --> 00:24:14.800]   And I was like, let's just do it.
[00:24:14.800 --> 00:24:19.040]   And so around the dining room table, we built an autopilot out of Lego,
[00:24:19.040 --> 00:24:20.600]   stuck it in a radio-controlled airplane.
[00:24:20.600 --> 00:24:23.760]   And it kind of almost worked.
[00:24:23.760 --> 00:24:27.880]   And the kids thought that was mildly amusing for about a minute.
[00:24:27.880 --> 00:24:29.760]   And I was blown away.
[00:24:29.760 --> 00:24:31.880]   I was like, what just happened?
[00:24:31.880 --> 00:24:36.440]   Did we really just build a drone with children on the dining room table,
[00:24:36.440 --> 00:24:38.760]   out of Lego, and it worked?
[00:24:38.760 --> 00:24:40.320]   >> Wait, can I ask you a very,
[00:24:40.320 --> 00:24:44.120]   just having messed around with drones quite a bit.
[00:24:44.120 --> 00:24:48.040]   I feel like you're skipping over the part where the thing keeps crashing and
[00:24:48.040 --> 00:24:51.400]   breaking, and then you spend an hour putting it back together, and
[00:24:51.400 --> 00:24:52.920]   it crashes and breaks again.
[00:24:52.920 --> 00:24:54.440]   It's maddening, right?
[00:24:54.440 --> 00:24:55.640]   >> No, yeah, yeah.
[00:24:55.640 --> 00:25:01.720]   So I just told you the bit that got me excited, that put the idea in my brain.
[00:25:01.720 --> 00:25:05.320]   The next five years were just horrible.
[00:25:05.320 --> 00:25:08.280]   >> [LAUGH] >> But I couldn't let it, so
[00:25:08.280 --> 00:25:14.600]   basically what had happened in 2007 was a bunch of things that,
[00:25:14.600 --> 00:25:16.760]   in retrospect, seem obvious.
[00:25:16.760 --> 00:25:19.680]   But with 2007, it was beginning of the maker movement.
[00:25:19.680 --> 00:25:23.560]   So it was 3D printing, it was Arduino came out.
[00:25:23.560 --> 00:25:27.040]   But what it really was, was the launch of the iPhone, 2007.
[00:25:27.040 --> 00:25:28.640]   So what's in an iPhone?
[00:25:28.640 --> 00:25:32.200]   A bunch of things, but including our MEMS sensors,
[00:25:32.200 --> 00:25:36.160]   these sensors that were chips, and previous sensors were mechanical.
[00:25:36.160 --> 00:25:39.000]   A gyro was literally a mechanical gyroscope, and
[00:25:39.000 --> 00:25:41.840]   it was just unaffordable, unattainable.
[00:25:41.840 --> 00:25:45.200]   And so I call this the peace dividend of the smartphone wars.
[00:25:45.200 --> 00:25:49.520]   But basically, the components of an iPhone had now been so cheap and
[00:25:49.520 --> 00:25:53.800]   available that you could then put them together in different ways and
[00:25:53.800 --> 00:25:56.400]   explore adjacent space, so like a Fitbit.
[00:25:56.400 --> 00:25:59.680]   Well, the Wii controller, for example, was an accelerometer,
[00:25:59.680 --> 00:26:01.160]   a MEMS accelerometer.
[00:26:01.160 --> 00:26:04.920]   The Fitbit guys got a Wii controller, and just like I got a mind storm and said,
[00:26:04.920 --> 00:26:06.040]   what else could I do?
[00:26:06.040 --> 00:26:08.440]   They got a Wii controller, opened it up, saw the accelerometer, and
[00:26:08.440 --> 00:26:09.480]   thought, what else can we do?
[00:26:09.480 --> 00:26:11.440]   And they came up with Fitbit.
[00:26:11.440 --> 00:26:16.800]   And so there's a bunch of people who were sort of looking at the components
[00:26:16.800 --> 00:26:22.160]   that came out of smartphones and thinking, how do I recombine them
[00:26:22.160 --> 00:26:24.320]   to create something new and transform an industry?
[00:26:24.320 --> 00:26:25.240]   And so that's what we did.
[00:26:25.240 --> 00:26:29.040]   We basically, rather than drones, which had been aerospace-grade stuff, so
[00:26:29.040 --> 00:26:31.400]   you basically could take an airplane and subtract the pilot.
[00:26:31.400 --> 00:26:33.800]   We're like, take a smartphone and add wings.
[00:26:33.800 --> 00:26:39.680]   And that bottoms-up approach was completely radical and transformative and
[00:26:39.680 --> 00:26:41.800]   was, initially, was horrible.
[00:26:41.800 --> 00:26:42.960]   I mean, nothing worked.
[00:26:42.960 --> 00:26:44.000]   They crashed all the time.
[00:26:44.000 --> 00:26:47.640]   But because they were small and foam and cheap, nobody got hurt.
[00:26:47.640 --> 00:26:50.960]   And because they were small and foam and cheap, we could actually build a community,
[00:26:50.960 --> 00:26:55.520]   and we got tens of thousands of people contributing and
[00:26:55.520 --> 00:26:57.760]   beta testing for all the right reasons.
[00:26:57.760 --> 00:27:04.200]   And we collectively, as a community, innovated super fast so
[00:27:04.200 --> 00:27:14.440]   that we went from Lego to foam to plastic to basically dominating the drone world,
[00:27:14.440 --> 00:27:21.040]   including becoming the biggest drone producer in North America five years after that.
[00:27:21.040 --> 00:27:25.720]   With no funding, that all just happened, and it just kind of exploded out of nowhere.
[00:27:25.720 --> 00:27:29.240]   It's kind of like the way the internet kind of took over the telecom sector or
[00:27:29.240 --> 00:27:31.200]   PCs took over compute.
[00:27:31.200 --> 00:27:36.480]   This is a bunch of amateurs with open-source software and
[00:27:36.480 --> 00:27:39.960]   hacked-together stuff basically took over the future of aerospace.
[00:27:39.960 --> 00:27:41.280]   It was classic Gandhi stuff.
[00:27:41.280 --> 00:27:44.520]   First, they ignored, then they laughed, then they fought, then they lost.
[00:27:44.520 --> 00:27:48.400]   And today, it's pretty evident that the future of aerospace looks unmanned,
[00:27:48.400 --> 00:27:52.520]   it looks electric, it looks more like Silicon Valley than it does like Boeing or
[00:27:52.520 --> 00:27:57.680]   Airbus, just like SpaceX did to the launch alliance.
[00:27:57.680 --> 00:28:04.680]   The Silicon Valley drone model seems to be the future of aviation everywhere.
[00:28:04.680 --> 00:28:06.000]   That's so cool.
[00:28:06.000 --> 00:28:10.280]   And then how did you get into racing autonomous robots?
[00:28:10.280 --> 00:28:11.080]   Right, right.
[00:28:11.080 --> 00:28:15.240]   So okay, I started with the hobby, to industrialize my hobby,
[00:28:15.240 --> 00:28:18.600]   the drone community turns into a company, the company gets big.
[00:28:18.600 --> 00:28:21.800]   And now I'm running a company, which is all well and good.
[00:28:21.800 --> 00:28:26.440]   But again, still nerd, still wanting to get my hands dirty.
[00:28:26.440 --> 00:28:30.720]   Drones at this point, this is now 10 years on.
[00:28:30.720 --> 00:28:32.760]   So this is like, what year are we in, 20 years?
[00:28:32.760 --> 00:28:36.400]   This is like 2017, or so.
[00:28:36.400 --> 00:28:38.760]   So at this point, drones are kind of a solved problem.
[00:28:38.760 --> 00:28:42.080]   It was really hard for a while, the common filters and
[00:28:42.080 --> 00:28:45.360]   building robust, reliable systems.
[00:28:45.360 --> 00:28:49.080]   And connecting to the Internet and the data payloads and the computer vision,
[00:28:49.080 --> 00:28:52.240]   all that kind of stuff was really hard for a while, but now it's kind of solved.
[00:28:52.240 --> 00:28:56.000]   And I'm always looking for some unsolved problem, something that's challenging.
[00:28:56.000 --> 00:28:59.680]   And you would think that drones as a 3D problem would be harder than cars,
[00:28:59.680 --> 00:29:02.280]   which are a 2D problem, but they're not.
[00:29:02.280 --> 00:29:05.440]   And the reason being is that you can get away with all sorts of slop up there in
[00:29:05.440 --> 00:29:08.480]   the air, the air is largely empty, you have GPS.
[00:29:08.480 --> 00:29:11.360]   And so we didn't really care whether we're a meter off or
[00:29:11.360 --> 00:29:14.360]   we were just basic head, we had GPS, we positioned pose.
[00:29:14.360 --> 00:29:17.760]   We're kind of given to us, position pose is given to us by the autopilot.
[00:29:17.760 --> 00:29:22.120]   It's hard to get there, a lot of work to figure out where down is in an inertial
[00:29:22.120 --> 00:29:25.720]   frame, but and then position is given to us by GPS just for free.
[00:29:25.720 --> 00:29:29.680]   So you can't assume that you have GPS with the car, you often don't.
[00:29:29.680 --> 00:29:32.960]   You also, so you need to establish position some other way.
[00:29:32.960 --> 00:29:36.960]   And also you need a kind of level of precision that's like centimeter or
[00:29:36.960 --> 00:29:39.960]   less because there's lots of clutter on the street.
[00:29:39.960 --> 00:29:42.400]   And so it's basically became a computer vision problem.
[00:29:42.400 --> 00:29:45.800]   So drones were an inertial problem, basically.
[00:29:45.800 --> 00:29:48.600]   Cars are a computer vision deep learning problem.
[00:29:48.600 --> 00:29:52.000]   And computer vision deep learning was just less advanced than classic
[00:29:52.000 --> 00:29:53.000]   control theory.
[00:29:53.000 --> 00:29:55.840]   So it was an opportunity to kind of go deep on computer vision and
[00:29:55.840 --> 00:29:59.040]   deep learning and kind of get my brain going again.
[00:29:59.040 --> 00:30:02.120]   And once again, DIY drones led to an industry.
[00:30:02.120 --> 00:30:03.200]   So we're like, what should we call it?
[00:30:03.200 --> 00:30:04.360]   DIY RoboCars.
[00:30:04.360 --> 00:30:08.920]   [LAUGH] Cuz I don't know, we haven't figured out a name for autonomous cars yet.
[00:30:08.920 --> 00:30:10.160]   I went with RoboCars.
[00:30:10.160 --> 00:30:11.320]   And let's do it again.
[00:30:11.320 --> 00:30:14.160]   This time I'm not gonna screw up my hobby by turning into a company.
[00:30:14.160 --> 00:30:15.240]   I'm just gonna leave it a hobby.
[00:30:15.240 --> 00:30:19.240]   But let's get this flywheel going again.
[00:30:19.240 --> 00:30:23.280]   And once again, we had the enabling technologies which were finally ready.
[00:30:23.280 --> 00:30:28.080]   We had good compute in forms like, we start with Raspberry Pi 3s and 4s, and
[00:30:28.080 --> 00:30:29.240]   then Jets and Nanos.
[00:30:29.240 --> 00:30:32.560]   The job is to keep it affordable, democratize the technology.
[00:30:32.560 --> 00:30:34.480]   So we put a limit of $400.
[00:30:34.480 --> 00:30:36.200]   Nothing could cost more than $400.
[00:30:36.200 --> 00:30:37.440]   This is kind of what it looks like.
[00:30:37.440 --> 00:30:38.040]   >> No way.
[00:30:38.040 --> 00:30:40.440]   >> Yeah, this is a variant of it.
[00:30:40.440 --> 00:30:44.040]   But this is just basically an RC car chassis with a,
[00:30:44.040 --> 00:30:47.680]   this one happens to be a Raspberry Pi 4 on the top.
[00:30:47.680 --> 00:30:48.760]   >> Nice. >> And a camera.
[00:30:48.760 --> 00:30:51.840]   This one also happens to have an Intel RealSense T265,
[00:30:51.840 --> 00:30:53.080]   which I'm playing with right now.
[00:30:53.080 --> 00:30:54.160]   But basically that's all you need.
[00:30:54.160 --> 00:30:57.040]   You need a camera, you need a Raspberry Pi, you need an RC car.
[00:30:57.040 --> 00:30:59.680]   >> Ooh, can I show you, I got one that I, well, this is not yours, but
[00:30:59.680 --> 00:31:01.520]   I made one that's kind of similar.
[00:31:01.520 --> 00:31:04.040]   >> Yeah. >> It's a Raspberry Pi 3 here.
[00:31:04.040 --> 00:31:06.800]   >> Yeah. >> With a camera, similar camera.
[00:31:06.800 --> 00:31:09.600]   I guess the chassis is a lot crappier than your chassis there.
[00:31:09.600 --> 00:31:12.920]   >> Well, this one's actually not that good.
[00:31:12.920 --> 00:31:14.160]   I probably fiddled with it a lot.
[00:31:14.160 --> 00:31:16.400]   I added an encoder, a wheel encoder.
[00:31:16.400 --> 00:31:19.400]   So I'm getting the T65, sorry to nerd out a little bit.
[00:31:19.400 --> 00:31:22.280]   The Intel RealSense T265 is a really interesting sensor.
[00:31:22.280 --> 00:31:23.600]   It gives you basically position.
[00:31:23.600 --> 00:31:26.560]   It's a visual slam sensor, so it gives you position.
[00:31:26.560 --> 00:31:28.320]   But it's a lot better when it has an encoder,
[00:31:28.320 --> 00:31:29.440]   when it's matched with an encoder.
[00:31:29.440 --> 00:31:30.560]   It actually knows where it is.
[00:31:30.560 --> 00:31:35.600]   So it's doing it all visually with two, with an IMU and stereo vision, etc.
[00:31:35.600 --> 00:31:40.760]   It's trying to, it records what it sees and then records that as you follow a path.
[00:31:40.760 --> 00:31:44.040]   And then tries to replicate it again, all visually.
[00:31:44.040 --> 00:31:45.880]   But it can tend to drift over time.
[00:31:45.880 --> 00:31:47.720]   >> Wait, can I see that sensor again?
[00:31:47.720 --> 00:31:49.080]   >> Yeah, it's this one right there.
[00:31:49.080 --> 00:31:53.160]   >> So that's like two cameras?
[00:31:53.160 --> 00:31:55.240]   >> It's two cameras and an IMU.
[00:31:55.240 --> 00:31:56.240]   >> What's an IMU?
[00:31:56.240 --> 00:31:58.000]   >> An inertial measurement unit.
[00:31:58.000 --> 00:31:59.400]   It's an accelerometer.
[00:31:59.400 --> 00:32:03.280]   It's a combination of accelerometers, gyros and a magnetometer that creates a,
[00:32:03.280 --> 00:32:05.400]   it gives you a position.
[00:32:05.400 --> 00:32:05.960]   >> Gotcha.
[00:32:05.960 --> 00:32:07.960]   >> So your phone has one in it.
[00:32:07.960 --> 00:32:11.360]   So this one's using a framework called Donkey.
[00:32:11.360 --> 00:32:13.840]   And so TR Robocars is the community, but
[00:32:13.840 --> 00:32:17.600]   the actual project that is mostly used is called the Donkey Car.
[00:32:17.600 --> 00:32:21.280]   It's sort of, I would call it an MVP of self-driving cars.
[00:32:21.280 --> 00:32:23.840]   Which is, it's end-to-end deep learning.
[00:32:23.840 --> 00:32:26.800]   And it works in the real world, it works in simulation.
[00:32:26.800 --> 00:32:29.560]   And the basic model is behavioral cloning.
[00:32:29.560 --> 00:32:34.920]   So what you do is you drive with a PlayStation controller.
[00:32:34.920 --> 00:32:37.040]   You drive it around a track.
[00:32:37.040 --> 00:32:39.680]   And it records the video, or
[00:32:39.680 --> 00:32:44.080]   samples the video with stills as it goes around.
[00:32:44.080 --> 00:32:47.400]   And then matches those with the inputs from your controller.
[00:32:47.400 --> 00:32:48.320]   And so you now have a pair.
[00:32:48.320 --> 00:32:51.360]   You have basically, here's what the camera saw and
[00:32:51.360 --> 00:32:52.480]   here's what the driver did.
[00:32:52.480 --> 00:32:56.160]   And you send them out to the cloud and you run TensorFlow or whatever,
[00:32:56.160 --> 00:32:57.360]   Fast AI, whatever you're using.
[00:32:57.360 --> 00:33:00.640]   And you end up, you come back with a model, an inference layer.
[00:33:00.640 --> 00:33:03.280]   And then the model runs locally.
[00:33:03.280 --> 00:33:06.360]   So we train in the cloud or on your PC.
[00:33:06.360 --> 00:33:08.880]   Then you create a model, then the model runs locally.
[00:33:08.880 --> 00:33:11.240]   And then you switch into auto mode.
[00:33:11.240 --> 00:33:13.040]   And then it drives by itself,
[00:33:13.040 --> 00:33:16.800]   by simply sort of doing what you did, more or less, in the training session.
[00:33:16.800 --> 00:33:20.080]   So you just drive around three or four laps, maybe go clockwise,
[00:33:20.080 --> 00:33:22.960]   counterclockwise, a little domain randomization.
[00:33:22.960 --> 00:33:24.800]   And it should learn how to drive.
[00:33:24.800 --> 00:33:26.880]   Now that's one technique.
[00:33:26.880 --> 00:33:29.920]   In the physical world, that's the easiest way to train it.
[00:33:29.920 --> 00:33:33.600]   In our virtual environment, in our simulator, you can use different methods.
[00:33:33.600 --> 00:33:35.520]   So there we use things like reinforcement learning.
[00:33:35.520 --> 00:33:39.600]   And we give it reward functions and all that sort of thing.
[00:33:39.600 --> 00:33:44.560]   And where during COVID, we've really pushed it towards simulation.
[00:33:44.560 --> 00:33:48.160]   And the exact same thing works, the exact same code works.
[00:33:48.160 --> 00:33:51.040]   It doesn't have to be on a physical car, work on your laptop, and
[00:33:51.040 --> 00:33:53.840]   you're running in a Unity-based simulator.
[00:33:53.840 --> 00:33:55.160]   And so it's been a really good time for
[00:33:55.160 --> 00:33:59.320]   us to push hard on our simulation side of the equation.
[00:33:59.320 --> 00:34:01.880]   And one of the questions we'll have as COVID ends and
[00:34:01.880 --> 00:34:05.960]   we kind of return to physical races is,
[00:34:05.960 --> 00:34:08.000]   how well do our models translate to the real world?
[00:34:08.000 --> 00:34:09.720]   Our sim to real gap.
[00:34:09.720 --> 00:34:11.360]   >> Yeah, always a challenge.
[00:34:11.360 --> 00:34:12.360]   >> Exactly.
[00:34:12.360 --> 00:34:16.640]   And so we're working pretty closely with Unity right now to try to figure out
[00:34:16.640 --> 00:34:21.200]   how to improve the probability that our simulated created models will translate
[00:34:21.200 --> 00:34:24.160]   well, and so we think a lot about domain randomization.
[00:34:24.160 --> 00:34:27.680]   But one thing it's hard to remember, but
[00:34:27.680 --> 00:34:32.440]   when this car, that camera is like 12 inches off the ground.
[00:34:32.440 --> 00:34:36.080]   Try putting your head 12 inches off the ground and
[00:34:36.080 --> 00:34:38.480]   try to see whether you can detect anything.
[00:34:38.480 --> 00:34:42.480]   And it's just, I mean, everything's so distorted and reflections and
[00:34:42.480 --> 00:34:46.200]   shadows, and it's really hard to see the world from there.
[00:34:46.200 --> 00:34:48.560]   And so what we're trying to do is we're trying to,
[00:34:48.560 --> 00:34:50.360]   simulators are too perfect.
[00:34:50.360 --> 00:34:53.600]   It's perfect information, we can create any level of resolution,
[00:34:53.600 --> 00:34:54.680]   they don't have motion blur.
[00:34:54.680 --> 00:34:58.800]   And so we're actually trying to kind of, to make the simulator worse.
[00:34:58.800 --> 00:35:03.280]   And one of the problems we have here is that you'll train on the track, and
[00:35:03.280 --> 00:35:04.360]   on your own it works great.
[00:35:04.360 --> 00:35:06.800]   And then during the race, the crowd comes, and
[00:35:06.800 --> 00:35:09.000]   now you have spectators all around the track.
[00:35:09.000 --> 00:35:13.520]   And now you have all these legs, and it completely throws off the model.
[00:35:13.520 --> 00:35:16.960]   And so we're actually modeling people and
[00:35:16.960 --> 00:35:20.440]   randomly putting people around the track to train the model to ignore that.
[00:35:20.440 --> 00:35:23.320]   And we're trying to figure out, what is it we're really looking at?
[00:35:23.320 --> 00:35:24.520]   Which color channel?
[00:35:24.520 --> 00:35:25.520]   What contrast?
[00:35:25.520 --> 00:35:27.400]   What do shadows do?
[00:35:27.400 --> 00:35:30.920]   And we're trying to understand better how to robustify
[00:35:30.920 --> 00:35:34.440]   the model to do the sim to real well.
[00:35:34.440 --> 00:35:36.120]   >> Man, what a cool project.
[00:35:36.120 --> 00:35:37.840]   I have so many questions.
[00:35:37.840 --> 00:35:40.320]   Is it in the scope of Unity?
[00:35:40.320 --> 00:35:41.960]   I should probably know this, but I really just don't.
[00:35:41.960 --> 00:35:44.960]   So I think of Unity as a graphics company.
[00:35:44.960 --> 00:35:47.440]   Does their engine also model physics?
[00:35:47.440 --> 00:35:52.080]   >> Yeah, they've really ramped up the robotics side.
[00:35:52.080 --> 00:35:55.320]   So you think of them as a game engine, and of course, they're good at that.
[00:35:55.320 --> 00:35:57.400]   Competing with Unreal, they're kind of open source, and
[00:35:57.400 --> 00:35:59.920]   Unreal is less so, is not, I guess.
[00:35:59.920 --> 00:36:02.960]   But they're really pushing the robotics side.
[00:36:02.960 --> 00:36:04.760]   And yes, they use physics.
[00:36:04.760 --> 00:36:08.040]   So they use the NVIDIA physics engine in the background.
[00:36:08.040 --> 00:36:09.320]   And so it's quite good.
[00:36:09.320 --> 00:36:11.880]   And they have a whole team right now focused on robotics.
[00:36:11.880 --> 00:36:17.200]   They're initially focused on things like segmentation classification.
[00:36:17.200 --> 00:36:21.960]   So let's say, for example, you want to model a factory or a warehouse or
[00:36:21.960 --> 00:36:24.000]   the shelves of a 7-Eleven, etc.
[00:36:24.000 --> 00:36:29.920]   How do you identify an object, a carton of milk?
[00:36:29.920 --> 00:36:34.160]   Occluded, rotated, bad lighting, how do you make sure you can identify it well?
[00:36:34.160 --> 00:36:38.440]   And so they focus a lot on that, just sort of taking objects and
[00:36:38.440 --> 00:36:41.240]   then sticking them in virtual environments.
[00:36:41.240 --> 00:36:45.480]   And just creating a lot of noise and train the system to understand that.
[00:36:45.480 --> 00:36:49.600]   So they're also used a lot in full-size self-driving cars,
[00:36:49.600 --> 00:36:53.000]   because they create beautiful, photorealistic environments.
[00:36:53.000 --> 00:36:54.520]   And that's important as well.
[00:36:54.520 --> 00:36:57.080]   But what we're working on with them is video.
[00:36:57.080 --> 00:36:59.720]   I mean, yes, we screen grab the video, but the image moves.
[00:36:59.720 --> 00:37:03.200]   And so there's a correlation between the previous image and then the next image.
[00:37:03.200 --> 00:37:06.960]   So that includes things like motion blur, because our cars go really fast.
[00:37:06.960 --> 00:37:10.040]   They go probably 20, 30 miles an hour.
[00:37:10.040 --> 00:37:12.680]   But I mean, scale speed is like 150 miles an hour.
[00:37:12.680 --> 00:37:14.320]   And when your camera's a foot off the ground,
[00:37:14.320 --> 00:37:15.960]   it is a lot of motion blur and things like that.
[00:37:15.960 --> 00:37:17.920]   So we're starting to model that.
[00:37:17.920 --> 00:37:22.800]   We procedurally generate tracks so that we can do domain randomization with tracks,
[00:37:22.800 --> 00:37:25.360]   make sure that we give the tracks certain parameters that at least
[00:37:25.360 --> 00:37:26.480]   don't break the physics.
[00:37:26.480 --> 00:37:29.120]   So one thing you could do is you could create a virtual model that can handle
[00:37:29.120 --> 00:37:30.120]   any track.
[00:37:30.120 --> 00:37:31.720]   But in the real world, you've got things like physics,
[00:37:31.720 --> 00:37:34.640]   like the traction budget of your wheels, etc.
[00:37:34.640 --> 00:37:39.560]   So we have to build a model, at least some physics of the tracks are realistic.
[00:37:39.560 --> 00:37:44.920]   And basically, you want to be able to, your training,
[00:37:44.920 --> 00:37:50.000]   you want to be able to say, here's my model, here's my code,
[00:37:50.000 --> 00:37:52.400]   here's my hyperparameters, whatever.
[00:37:52.400 --> 00:37:55.480]   Stick it into the simulator, ideally in headless mode,
[00:37:55.480 --> 00:37:57.000]   so just running in the cloud.
[00:37:57.000 --> 00:38:01.800]   And I want you to run 1,000 iterations.
[00:38:01.800 --> 00:38:04.200]   And then I want to turn randomization on.
[00:38:04.200 --> 00:38:09.160]   So I want you to do 1,000 iterations of randomizing, lighting, shadows,
[00:38:09.160 --> 00:38:13.520]   motion blur, objects that are surrounding, textures.
[00:38:13.520 --> 00:38:15.920]   I want you to go through and randomize the courses as well.
[00:38:15.920 --> 00:38:18.320]   I want you to go clockwise and counterclockwise.
[00:38:18.320 --> 00:38:21.840]   I want you to change which track you're in at any point.
[00:38:21.840 --> 00:38:24.840]   Then I want you to add other cars that are also random.
[00:38:24.840 --> 00:38:28.280]   And so when you think about that, when you think about the industrial scale
[00:38:28.280 --> 00:38:32.560]   of just scenarios you can create, it gets really exciting.
[00:38:32.560 --> 00:38:35.040]   And so that's where Unity is focused right now.
[00:38:35.040 --> 00:38:36.600]   Cool.
[00:38:36.600 --> 00:38:37.960]   What's your hope for this?
[00:38:37.960 --> 00:38:40.520]   Is it the joy of making something?
[00:38:40.520 --> 00:38:41.520]   Or is there--
[00:38:41.520 --> 00:38:46.800]   Yeah, it's-- I mean, as you know, one of the rules of the maker movement
[00:38:46.800 --> 00:38:49.880]   is never ask why, because the answer is always because we can.
[00:38:49.880 --> 00:38:52.360]   My personal thing is that it's just really engaging.
[00:38:52.360 --> 00:38:57.640]   It gives me a reason to explore the cutting edge of machine learning
[00:38:57.640 --> 00:38:59.360]   and data science and things like that.
[00:38:59.360 --> 00:39:00.360]   So I need a reason.
[00:39:00.360 --> 00:39:01.640]   I'm like probably you.
[00:39:01.640 --> 00:39:03.520]   I can only learn by doing.
[00:39:03.520 --> 00:39:05.040]   And it gives me a reason to do it.
[00:39:05.040 --> 00:39:09.240]   As a community, our nominal reason is to democratize the technology,
[00:39:09.240 --> 00:39:10.480]   to basically--
[00:39:10.480 --> 00:39:12.760]   I don't have a real self-driving car.
[00:39:12.760 --> 00:39:14.800]   You probably don't have a real self-driving car.
[00:39:14.800 --> 00:39:17.520]   And that ain't right.
[00:39:17.520 --> 00:39:18.280]   Man, well said.
[00:39:18.280 --> 00:39:19.920]   I love it.
[00:39:19.920 --> 00:39:24.080]   So how do we make it so that more people can engage with self-driving cars
[00:39:24.080 --> 00:39:27.000]   without working for Google or Waymo or whatever?
[00:39:27.000 --> 00:39:30.960]   And the answer is you take the essence and you reduce it to a unit
[00:39:30.960 --> 00:39:33.840]   that anybody can have access to, exactly as we did with drones.
[00:39:33.840 --> 00:39:37.280]   I didn't have a Predator, so I made one out of Lego and foam.
[00:39:37.280 --> 00:39:39.680]   And I didn't have a self-driving car, so I made one out
[00:39:39.680 --> 00:39:42.200]   of toy parts and a Raspberry Pi.
[00:39:42.200 --> 00:39:44.640]   And so what you're seeing is this incredible diversity
[00:39:44.640 --> 00:39:46.160]   of people who are engaged.
[00:39:46.160 --> 00:39:49.840]   Last-- we do virtual races every month.
[00:39:49.840 --> 00:39:56.320]   Two races ago, number one, the number one winner was Japanese--
[00:39:56.320 --> 00:40:00.680]   I don't know what he does, but let's imagine just Japanese engineer.
[00:40:00.680 --> 00:40:05.280]   Number two was French teenager.
[00:40:05.280 --> 00:40:11.680]   Number three was a 12-year-old Indian girl from Canada.
[00:40:11.680 --> 00:40:17.400]   And then down the line are University of San Diego professors, retired people.
[00:40:17.400 --> 00:40:21.440]   It's just incredible diversity of people who can participate because it's--
[00:40:21.440 --> 00:40:23.760]   I mean, if you do it virtually, it doesn't cost anything.
[00:40:23.760 --> 00:40:25.320]   Just download some code and run it.
[00:40:25.320 --> 00:40:28.760]   And so we're really feeling like we're opening up
[00:40:28.760 --> 00:40:31.320]   the excitement of the industry to people who otherwise
[00:40:31.320 --> 00:40:32.440]   wouldn't have access to it.
[00:40:32.440 --> 00:40:34.060]   And some of them are doing it for fun.
[00:40:34.060 --> 00:40:35.960]   Some of them are doing it to get smart on--
[00:40:35.960 --> 00:40:39.520]   to give a tangible reason to learn machine learning.
[00:40:39.520 --> 00:40:42.120]   And some of them are doing it because they want it to be their next career.
[00:40:42.120 --> 00:40:45.480]   And so we find we have a lot of people who are kind of mid-career.
[00:40:45.480 --> 00:40:46.200]   They got it.
[00:40:46.200 --> 00:40:47.160]   They're an engineer or whatever.
[00:40:47.160 --> 00:40:49.600]   They got a job, but it's not exciting for them.
[00:40:49.600 --> 00:40:51.480]   And this is super exciting.
[00:40:51.480 --> 00:40:54.760]   And so it gives them the chance to sort of fall in love with tech again.
[00:40:54.760 --> 00:40:57.400]   And what are the axes that you can change stuff?
[00:40:57.400 --> 00:40:59.400]   I think one of the challenges of these simulations
[00:40:59.400 --> 00:41:01.680]   is it kind of constrains the hardware a bit, doesn't it?
[00:41:01.680 --> 00:41:04.060]   Or how do you think about that?
[00:41:04.060 --> 00:41:09.940]   The axes that we don't really mess with are things like cost and danger.
[00:41:09.940 --> 00:41:11.180]   So we like to keep them small.
[00:41:11.180 --> 00:41:12.620]   We like to keep them cheap.
[00:41:12.620 --> 00:41:13.940]   Everything-- so that's--
[00:41:13.940 --> 00:41:15.940]   I mean, there's some exceptions, and I can get into that later.
[00:41:15.940 --> 00:41:18.980]   But by and large, it should be something you can do indoors.
[00:41:18.980 --> 00:41:21.220]   It should be something that if it goes wrong, nobody gets hurt.
[00:41:21.220 --> 00:41:22.260]   So that's where we limit.
[00:41:22.260 --> 00:41:24.820]   Beyond that, the axes are really--
[00:41:24.820 --> 00:41:27.380]   there really aren't any constraints.
[00:41:27.380 --> 00:41:30.180]   So for example, there are a lot of ways to do self-driving cars
[00:41:30.180 --> 00:41:32.320]   and a lot of sensors that are available.
[00:41:32.320 --> 00:41:34.860]   So one of the things that's gotten super interesting of late
[00:41:34.860 --> 00:41:38.280]   is that 2D LiDAR has gotten really cheap.
[00:41:38.280 --> 00:41:39.760]   I have one of those, yeah.
[00:41:39.760 --> 00:41:43.600]   And so you can get 2D LiDAR now for about $80
[00:41:43.600 --> 00:41:45.360]   and a range of about 10 to 12 meters.
[00:41:45.360 --> 00:41:46.320]   So we can explore that.
[00:41:46.320 --> 00:41:50.520]   Now, right now, we just use LiDAR for obstacle avoidance
[00:41:50.520 --> 00:41:52.800]   because our courses don't have a lot of structure.
[00:41:52.800 --> 00:41:56.680]   They're basically just white lines on carpet or on the pavement.
[00:41:56.680 --> 00:41:58.320]   I showed you the real sensors.
[00:41:58.320 --> 00:42:00.500]   This particular one was positioned,
[00:42:00.500 --> 00:42:03.480]   but they also have one that's depth sensing, which is useful
[00:42:03.480 --> 00:42:05.600]   for, again, obstacle avoidance.
[00:42:05.600 --> 00:42:07.280]   Sorry, what is step sensing?
[00:42:07.280 --> 00:42:08.880]   Yeah, sorry, depth sensing.
[00:42:08.880 --> 00:42:10.400]   Depth sensing, forgive me.
[00:42:10.400 --> 00:42:14.240]   Another one is that we can actually go outdoors and use
[00:42:14.240 --> 00:42:18.560]   a drone autopilot on a car and simply navigate by GPS alone.
[00:42:18.560 --> 00:42:22.360]   Now, GPS is not high enough resolution,
[00:42:22.360 --> 00:42:26.840]   but now RTK GPS, which uses a base station and a moving one,
[00:42:26.840 --> 00:42:30.320]   is quite affordable and can get you centimeter level
[00:42:30.320 --> 00:42:31.000]   resolution.
[00:42:31.000 --> 00:42:35.120]   So this one here matches another GPS that's a base station
[00:42:35.120 --> 00:42:36.600]   that you have locally.
[00:42:36.600 --> 00:42:39.800]   It's interesting, but you're not using any sonar anywhere, huh?
[00:42:39.800 --> 00:42:41.200]   Sonar is really not used for us.
[00:42:41.200 --> 00:42:42.560]   Too unreliable?
[00:42:42.560 --> 00:42:46.360]   Well, there used to be something called the SparkFun
[00:42:46.360 --> 00:42:50.560]   Autonomous Vehicle Competition, which is no longer around.
[00:42:50.560 --> 00:42:52.440]   And that one was outdoors.
[00:42:52.440 --> 00:42:55.320]   And people originally used sonar to do things
[00:42:55.320 --> 00:42:58.760]   like avoid the hay bales on the side, et cetera.
[00:42:58.760 --> 00:42:59.880]   Very noisy.
[00:42:59.880 --> 00:43:02.320]   So there is not a sensor that exists
[00:43:02.320 --> 00:43:03.440]   that we haven't explored.
[00:43:03.440 --> 00:43:07.200]   So yes, we had sonar, but then we
[00:43:07.200 --> 00:43:13.480]   would create sonar arrays of 360 degree sonar.
[00:43:13.480 --> 00:43:17.600]   Then we would-- of course, sonar is really old school,
[00:43:17.600 --> 00:43:20.280]   but the most more recent ones are these time of flight
[00:43:20.280 --> 00:43:23.640]   sensors, these little tiny time of flight sensors.
[00:43:23.640 --> 00:43:25.640]   And so this one actually was just to calibrate,
[00:43:25.640 --> 00:43:28.800]   just to compare sonar with time of flight sensing.
[00:43:28.800 --> 00:43:29.800]   What's time of flight?
[00:43:29.800 --> 00:43:30.760]   Is that LIDAR?
[00:43:30.760 --> 00:43:31.840]   It's like LIDAR.
[00:43:31.840 --> 00:43:34.040]   It shines a light beam out and then measures
[00:43:34.040 --> 00:43:35.640]   the time it takes to come back.
[00:43:35.640 --> 00:43:36.320]   I see.
[00:43:36.320 --> 00:43:41.880]   So basically, sonar is quite a wide beam and very noisy.
[00:43:41.880 --> 00:43:43.200]   The environment can obstruct.
[00:43:43.200 --> 00:43:46.760]   Time of flight is much better and cheaper and smaller,
[00:43:46.760 --> 00:43:47.280]   et cetera.
[00:43:47.280 --> 00:43:48.200]   So we've tried a lot.
[00:43:48.200 --> 00:43:50.000]   What about radar?
[00:43:50.000 --> 00:43:51.160]   We have radar as well.
[00:43:51.160 --> 00:43:53.760]   Radar is still relatively expensive.
[00:43:53.760 --> 00:43:57.720]   Also, radar, it tends to be a relatively broad beam.
[00:43:57.720 --> 00:43:58.960]   And that's not a problem.
[00:43:58.960 --> 00:44:00.680]   So if you're in a full-sized car and you
[00:44:00.680 --> 00:44:02.960]   want to detect a car in front of you, it's fine for that.
[00:44:02.960 --> 00:44:04.360]   But we have other ways to do it, cheaper ways
[00:44:04.360 --> 00:44:05.960]   to do it, time of flight, for example.
[00:44:05.960 --> 00:44:09.360]   Because remember, our distances are like a couple of meters,
[00:44:09.360 --> 00:44:11.160]   not tens of meters.
[00:44:11.160 --> 00:44:13.720]   So we don't have any need for radar
[00:44:13.720 --> 00:44:15.880]   because we can solve it with time of flight.
[00:44:15.880 --> 00:44:20.800]   Then we have solid state LIDAR, which, again, is affordable.
[00:44:21.320 --> 00:44:22.760]   And mechanically, a little simpler.
[00:44:22.760 --> 00:44:23.760]   We do a lot of crashing.
[00:44:23.760 --> 00:44:26.360]   So mechanical robustness is a good thing.
[00:44:26.360 --> 00:44:26.840]   [CHUCKLES]
[00:44:26.840 --> 00:44:29.720]   We have-- there's, of course--
[00:44:29.720 --> 00:44:30.720]   the nice thing about--
[00:44:30.720 --> 00:44:32.680]   well, the spinning LIDAR I just showed you
[00:44:32.680 --> 00:44:34.880]   is basically a 2D planar one.
[00:44:34.880 --> 00:44:37.400]   The solid state LIDAR has kind of a wedge shape.
[00:44:37.400 --> 00:44:39.600]   And so you get a little bit more structure that way.
[00:44:39.600 --> 00:44:41.760]   But again, the depth sensing cameras
[00:44:41.760 --> 00:44:44.160]   can give you much the same information.
[00:44:44.160 --> 00:44:47.360]   And they also give you visual texture information,
[00:44:47.360 --> 00:44:50.240]   which is useful on top of that.
[00:44:50.240 --> 00:44:53.000]   I'm trying to think what else-- what other sensors we play with.
[00:44:53.000 --> 00:44:55.520]   Oh, there's a really smart one.
[00:44:55.520 --> 00:44:56.880]   So you can do a lot with cameras.
[00:44:56.880 --> 00:44:59.440]   And one of the winners uses--
[00:44:59.440 --> 00:45:01.320]   so most of these cameras, as you saw,
[00:45:01.320 --> 00:45:04.640]   are looking out, looking forward and a little bit down.
[00:45:04.640 --> 00:45:07.320]   And we're racing indoors.
[00:45:07.320 --> 00:45:08.960]   So what people realized is that if you
[00:45:08.960 --> 00:45:11.460]   know where you are on the track, you have a huge advantage.
[00:45:11.460 --> 00:45:12.480]   Because you know where the curves are.
[00:45:12.480 --> 00:45:13.800]   You can go fast on the straightaways
[00:45:13.800 --> 00:45:14.760]   and slow on the curves.
[00:45:14.760 --> 00:45:17.640]   And basically, you have foresight
[00:45:17.640 --> 00:45:18.960]   into what's going to happen.
[00:45:18.960 --> 00:45:21.520]   So how do you localize on an indoor track?
[00:45:21.520 --> 00:45:25.400]   And we have cones at the corners to detect
[00:45:25.400 --> 00:45:27.360]   where people are disqualified.
[00:45:27.360 --> 00:45:29.040]   And so people realized the cones were
[00:45:29.040 --> 00:45:32.360]   sort of a foot signature, a fingerprint, if you will,
[00:45:32.360 --> 00:45:33.320]   for the track.
[00:45:33.320 --> 00:45:35.960]   And so they would use LIDAR to identify the cones.
[00:45:35.960 --> 00:45:37.600]   Now, you can do it optically as well,
[00:45:37.600 --> 00:45:38.920]   because the cones are orange.
[00:45:38.920 --> 00:45:41.360]   And so they would basically localize that.
[00:45:41.360 --> 00:45:44.760]   And then a genius guy named Andy Sloan
[00:45:44.760 --> 00:45:47.120]   realized that there's another fingerprint
[00:45:47.120 --> 00:45:48.720]   of the track of the course, which
[00:45:48.720 --> 00:45:51.200]   is that the lights on the ceiling
[00:45:51.200 --> 00:45:52.400]   had a distinctive pattern.
[00:45:52.400 --> 00:45:55.080]   And so his car actually has a fisheye lens.
[00:45:55.080 --> 00:45:56.280]   The camera looks up.
[00:45:56.280 --> 00:45:57.640]   It has a fisheye lens.
[00:45:57.640 --> 00:46:00.640]   And it can see around it a little bit,
[00:46:00.640 --> 00:46:02.200]   but it also sees the ceiling.
[00:46:02.200 --> 00:46:05.040]   And it basically just steers by looking
[00:46:05.040 --> 00:46:07.760]   at the lights above it, which is absolutely brilliant.
[00:46:07.760 --> 00:46:09.320]   And you don't consider that cheating?
[00:46:09.320 --> 00:46:11.040]   You just-- any way to hack your--
[00:46:11.040 --> 00:46:12.360]   It works great indoors.
[00:46:12.360 --> 00:46:15.000]   But now we make them go outdoors as well.
[00:46:15.000 --> 00:46:16.200]   And so it'll fail outdoors.
[00:46:16.200 --> 00:46:18.800]   And so what you need is-- and then, as it happens,
[00:46:18.800 --> 00:46:22.160]   we do races in a place called Circuit Launch in Oakland
[00:46:22.160 --> 00:46:22.840]   near the airport.
[00:46:22.840 --> 00:46:25.040]   And they just renovated it during COVID,
[00:46:25.040 --> 00:46:27.680]   and they changed the lights.
[00:46:27.680 --> 00:46:29.720]   But yeah, so every trick you can think of--
[00:46:29.720 --> 00:46:31.600]   so it's called cone slam, by the way.
[00:46:31.600 --> 00:46:32.920]   Cone slam, yeah, yeah.
[00:46:32.920 --> 00:46:34.400]   Simultaneous location mapping.
[00:46:34.400 --> 00:46:36.440]   So cone slam and light slam.
[00:46:36.440 --> 00:46:39.720]   And then, anyway, I could go down the rabbit hole.
[00:46:39.720 --> 00:46:41.800]   But I just wanted to say that we do racing, which
[00:46:41.800 --> 00:46:44.760]   is largely about going fast and beating other people.
[00:46:44.760 --> 00:46:47.960]   But there's also ways to explore self-driving cars
[00:46:47.960 --> 00:46:50.960]   at a tiny scale in a city environment.
[00:46:50.960 --> 00:46:53.360]   And this is one cute version of it.
[00:46:53.360 --> 00:46:55.160]   Actually, I'm trying to remember, actually,
[00:46:55.160 --> 00:46:56.000]   what it's called.
[00:46:56.000 --> 00:46:57.720]   We'll put it in the show notes afterwards.
[00:46:57.720 --> 00:47:03.000]   But things like this use cameras and little raspberry pies.
[00:47:03.000 --> 00:47:04.320]   And it's called a Zoomie there.
[00:47:04.320 --> 00:47:05.720]   It just told me.
[00:47:05.720 --> 00:47:09.440]   And you can build a Lego-sized city with stop signs
[00:47:09.440 --> 00:47:11.400]   and street corners, et cetera.
[00:47:11.400 --> 00:47:13.680]   And so I actually-- you can go to Ikea
[00:47:13.680 --> 00:47:16.520]   and get these kids carpets that have cities for toy cars,
[00:47:16.520 --> 00:47:17.040]   et cetera.
[00:47:17.040 --> 00:47:19.200]   And you could actually run one of these in it.
[00:47:19.200 --> 00:47:20.800]   And it'll navigate the city.
[00:47:20.800 --> 00:47:22.480]   So these things are super--
[00:47:22.480 --> 00:47:24.160]   they use Jupyter Notebooks and Python.
[00:47:24.160 --> 00:47:27.720]   And they're really fun and easy and super cute.
[00:47:27.720 --> 00:47:31.640]   And you don't have to race to be able to participate.
[00:47:31.640 --> 00:47:33.600]   Wow, those eyes are so evocative, too.
[00:47:33.600 --> 00:47:34.920]   I love it.
[00:47:34.920 --> 00:47:36.000]   They are, yeah.
[00:47:36.000 --> 00:47:39.080]   Yeah, it just said, find Zoomie on your Wi-Fi.
[00:47:39.080 --> 00:47:41.120]   And then if you go there, it runs a little web server.
[00:47:41.120 --> 00:47:42.200]   And it's running a Jupyter Notebook.
[00:47:42.200 --> 00:47:45.520]   And you can do things like driving the town.
[00:47:45.520 --> 00:47:49.080]   And so what is the challenge to--
[00:47:49.080 --> 00:47:52.120]   what do the people that are winning these things focus on?
[00:47:52.120 --> 00:47:55.440]   Is it actually knowing your position and orientation
[00:47:55.440 --> 00:47:56.160]   really accurately?
[00:47:56.160 --> 00:48:00.760]   Or is it strategizing your path through the course?
[00:48:00.760 --> 00:48:01.480]   All of the above.
[00:48:01.480 --> 00:48:04.600]   It's things like racing lines, which is--
[00:48:04.600 --> 00:48:06.960]   basically, racing lines are the shortest path
[00:48:06.960 --> 00:48:08.080]   around the track.
[00:48:08.080 --> 00:48:10.080]   And going fast and straightaways and then
[00:48:10.080 --> 00:48:12.520]   braking at the right time, the classic racing stuff.
[00:48:12.520 --> 00:48:13.760]   Localization helps a lot.
[00:48:13.760 --> 00:48:15.920]   It allows you to create a strategy.
[00:48:15.920 --> 00:48:19.320]   Then there's passing strategies and avoidance strategies.
[00:48:19.320 --> 00:48:22.400]   And how do you win when you're going head to head,
[00:48:22.400 --> 00:48:23.560]   as they always are?
[00:48:23.560 --> 00:48:25.360]   Is drafting relevant at these low speeds?
[00:48:25.360 --> 00:48:27.080]   No, it's not.
[00:48:27.080 --> 00:48:28.280]   It's not.
[00:48:28.280 --> 00:48:31.480]   Yeah, I mean, they're just--
[00:48:31.480 --> 00:48:33.120]   they're going 20 miles an hour, but they're small.
[00:48:33.120 --> 00:48:34.800]   Biggest challenge, though-- and this
[00:48:34.800 --> 00:48:38.840]   is one that does not show up a lot in real self-driving cars.
[00:48:38.840 --> 00:48:41.880]   We're going freaking fast.
[00:48:41.880 --> 00:48:47.400]   So 20 miles an hour in a 1/10 car, that's 200 miles an hour.
[00:48:47.400 --> 00:48:49.920]   And so this is real-time robotics.
[00:48:49.920 --> 00:48:52.440]   And I don't know how much you've spent with real-time robotics,
[00:48:52.440 --> 00:48:55.440]   but 20 milliseconds is slow.
[00:48:55.440 --> 00:49:00.960]   So our inner loops, we could be running them at 1,000 hertz.
[00:49:00.960 --> 00:49:03.760]   Plus, do you do inference at 20 milliseconds on a Raspberry
[00:49:03.760 --> 00:49:04.800]   Pi 3?
[00:49:04.800 --> 00:49:05.920]   Depends.
[00:49:05.920 --> 00:49:07.400]   So obviously, we lower the--
[00:49:07.400 --> 00:49:10.360]   so no, we're not doing inference at 20 milliseconds
[00:49:10.360 --> 00:49:11.480]   on a Raspberry Pi 3.
[00:49:11.480 --> 00:49:16.680]   But we can do 100 milliseconds on a Raspberry Pi 4.
[00:49:16.680 --> 00:49:18.160]   And that's your AI loop.
[00:49:18.160 --> 00:49:20.200]   Then you might have a motor controller loop
[00:49:20.200 --> 00:49:21.200]   that's running faster.
[00:49:21.200 --> 00:49:23.440]   If you're running an IMU, et cetera, you might be detecting.
[00:49:23.440 --> 00:49:25.760]   The IMUs, which is, again, the inertial measurements,
[00:49:25.760 --> 00:49:28.080]   would be detecting something like drifting.
[00:49:28.080 --> 00:49:29.840]   So if you're supposed to be going straight
[00:49:29.840 --> 00:49:32.080]   and you actually have some lateral movement,
[00:49:32.080 --> 00:49:34.960]   that means that your wheels, your tires,
[00:49:34.960 --> 00:49:37.040]   have lost traction and you're skidding.
[00:49:37.040 --> 00:49:39.040]   So how do we do real-time?
[00:49:39.040 --> 00:49:44.560]   And the answer is, you need at least, I would say,
[00:49:44.560 --> 00:49:46.000]   30 frames per second.
[00:49:46.000 --> 00:49:49.440]   At least 30 frames a second.
[00:49:49.440 --> 00:49:52.520]   That's actually-- real cars are not going--
[00:49:52.520 --> 00:49:54.360]   are not sampling that fast.
[00:49:54.360 --> 00:49:56.200]   And if you're going 30 frames a second,
[00:49:56.200 --> 00:49:57.740]   you may have to make some concessions.
[00:49:57.740 --> 00:50:00.640]   So first of all, our cameras are relatively low res.
[00:50:00.640 --> 00:50:02.320]   So we're running at like 320.
[00:50:02.320 --> 00:50:06.760]   And our models are pretty simplified.
[00:50:06.760 --> 00:50:09.320]   You might have three or four layers, but no more than that.
[00:50:09.320 --> 00:50:11.320]   We're not running a lot of models simultaneously.
[00:50:11.320 --> 00:50:12.880]   So it's end-to-end neural networks.
[00:50:12.880 --> 00:50:14.800]   So basically, it's just pixels come in
[00:50:14.800 --> 00:50:17.560]   and commands to the steering go out.
[00:50:17.560 --> 00:50:20.640]   So we're not running parallel networks, et cetera.
[00:50:20.640 --> 00:50:22.400]   But yeah, these are all great challenges.
[00:50:22.400 --> 00:50:26.400]   If you tell somebody, keep it under $400 and win,
[00:50:26.400 --> 00:50:29.160]   it requires a lot of creative thinking about that.
[00:50:29.160 --> 00:50:31.320]   And you can't just throw compute at it.
[00:50:31.320 --> 00:50:33.960]   It's not OK to show up with the kind of stuff
[00:50:33.960 --> 00:50:35.800]   you'll find in the trunk of a Waymo.
[00:50:35.800 --> 00:50:37.520]   That's cheating.
[00:50:37.520 --> 00:50:41.000]   You show up with your Jetson Nano or your Raspberry Pi 4,
[00:50:41.000 --> 00:50:44.600]   and then you use some creative algorithm or technique to win.
[00:50:44.600 --> 00:50:46.080]   And that's the fun.
[00:50:46.080 --> 00:50:47.600]   Yeah, that is so fun.
[00:50:47.600 --> 00:50:49.920]   I mean, Jetson Nano or even Raspberry Pi 4,
[00:50:49.920 --> 00:50:51.800]   there's no joke these days, though.
[00:50:51.800 --> 00:50:52.320]   It's funny.
[00:50:52.320 --> 00:50:55.160]   To me, it's just like, this is amazing what we can do.
[00:50:55.160 --> 00:50:58.200]   Yeah, they're both like--
[00:50:58.200 --> 00:51:01.000]   I don't know, the Nano right now is like $60 or something,
[00:51:01.000 --> 00:51:02.480]   the 2 gigabyte one.
[00:51:02.480 --> 00:51:05.600]   And the Raspberry Pi 4 is about the same.
[00:51:05.600 --> 00:51:06.920]   So it's really great.
[00:51:06.920 --> 00:51:09.440]   But what's really important is the software frameworks
[00:51:09.440 --> 00:51:10.640]   now support them.
[00:51:10.640 --> 00:51:14.440]   So TensorFlow RT, Keras, Fast.ai,
[00:51:14.440 --> 00:51:18.320]   they're all starting to think about edge compute.
[00:51:18.320 --> 00:51:20.680]   I just want to say, they've put in so much effort,
[00:51:20.680 --> 00:51:21.800]   and they're so friendly.
[00:51:21.800 --> 00:51:23.160]   I feel like when I've asked questions,
[00:51:23.160 --> 00:51:24.760]   they've just been unbelievably helpful.
[00:51:24.760 --> 00:51:27.040]   So I don't know, I feel like I need to just give them
[00:51:27.040 --> 00:51:28.520]   a thank you for that.
[00:51:28.520 --> 00:51:29.360]   Absolutely.
[00:51:29.360 --> 00:51:30.800]   And everyone's doing it.
[00:51:30.800 --> 00:51:32.920]   So NVIDIA's obviously-- they didn't
[00:51:32.920 --> 00:51:35.320]   have to come out with a Jetson that cost $59.
[00:51:35.320 --> 00:51:37.240]   But they did.
[00:51:37.240 --> 00:51:40.320]   Amazon's set up a RoboMaker, which
[00:51:40.320 --> 00:51:42.120]   is their virtual environment for this.
[00:51:42.120 --> 00:51:45.320]   Microsoft is investing a huge amount into edge AI.
[00:51:45.320 --> 00:51:48.320]   Intel, the Intel RealSense I just told you about,
[00:51:48.320 --> 00:51:50.680]   Raspberry Pi, et cetera, all the Google stuff
[00:51:50.680 --> 00:51:53.040]   is focused on edge AI as well.
[00:51:53.040 --> 00:51:55.720]   So the notion that the edge--
[00:51:55.720 --> 00:51:58.920]   so the cloud and the cores is one thing.
[00:51:58.920 --> 00:52:01.440]   But the edge is completely different
[00:52:01.440 --> 00:52:05.240]   in that you have real-world inputs, real-time inputs,
[00:52:05.240 --> 00:52:06.880]   real-time outputs.
[00:52:06.880 --> 00:52:10.360]   And they tend to be small, cheap, power efficient, et
[00:52:10.360 --> 00:52:10.880]   cetera.
[00:52:10.880 --> 00:52:13.320]   And so you realize that the internet has always
[00:52:13.320 --> 00:52:14.920]   been this way, that it's a combination
[00:52:14.920 --> 00:52:16.040]   of the edge and the core.
[00:52:16.040 --> 00:52:17.400]   And that it shifts.
[00:52:17.400 --> 00:52:18.920]   Where's the thinking done?
[00:52:18.920 --> 00:52:19.960]   Where's the intelligence?
[00:52:19.960 --> 00:52:21.400]   And it's got to be some balance.
[00:52:21.400 --> 00:52:22.920]   And we got the cloud.
[00:52:22.920 --> 00:52:25.240]   We got the core down right.
[00:52:25.240 --> 00:52:29.000]   But the edge is an opportunity to basically pre-process
[00:52:29.000 --> 00:52:30.720]   a lot of data before you get it.
[00:52:30.720 --> 00:52:31.880]   Because we can gather so much data.
[00:52:31.880 --> 00:52:34.180]   If we can pre-process it with deep learning and the edge,
[00:52:34.180 --> 00:52:36.360]   it actually makes the core smarter as well.
[00:52:36.360 --> 00:52:37.200]   Totally.
[00:52:37.200 --> 00:52:39.560]   So it's really exciting what's happening right now.
[00:52:39.560 --> 00:52:42.000]   Not only with deep learning, but also computer vision.
[00:52:42.000 --> 00:52:45.280]   I'm a big fan of a project called OpenMV, which
[00:52:45.280 --> 00:52:46.400]   is basically--
[00:52:46.400 --> 00:52:48.480]   it looks just like one of these cameras, actually.
[00:52:48.480 --> 00:52:50.100]   So we've been talking a lot about deep learning.
[00:52:50.100 --> 00:52:51.800]   But computer vision is equally exciting.
[00:52:51.800 --> 00:52:53.120]   This is an OpenMV.
[00:52:53.120 --> 00:52:56.040]   And it's basically, again, a $50 board.
[00:52:56.040 --> 00:52:57.880]   But it's a camera.
[00:52:57.880 --> 00:52:59.720]   And it's got compute on board.
[00:52:59.720 --> 00:53:01.480]   And it's basically running OpenCV.
[00:53:01.480 --> 00:53:04.380]   And it runs it really well with the Python interface,
[00:53:04.380 --> 00:53:06.180]   a fantastic IDE.
[00:53:06.180 --> 00:53:10.700]   And you basically just stick this on anything.
[00:53:10.700 --> 00:53:13.740]   It can run a car just all by itself.
[00:53:13.740 --> 00:53:15.540]   And now you've got the stuff that
[00:53:15.540 --> 00:53:18.620]   was like a PhD 10 years ago of edge detection
[00:53:18.620 --> 00:53:23.860]   and some simple deep learning networks, object detection,
[00:53:23.860 --> 00:53:27.660]   all sorts of transforms, et cetera, all just built in,
[00:53:27.660 --> 00:53:28.900]   already built into this thing.
[00:53:28.900 --> 00:53:32.400]   And any kid can now use this to do sophisticated computer
[00:53:32.400 --> 00:53:32.900]   vision.
[00:53:32.900 --> 00:53:36.420]   So actually, cars that use nothing more than this
[00:53:36.420 --> 00:53:40.000]   have consistently scored in the top 10.
[00:53:40.000 --> 00:53:43.180]   And you can literally make a self-driving racing
[00:53:43.180 --> 00:53:46.220]   car for less than $100 with something like this.
[00:53:46.220 --> 00:53:48.340]   So cool.
[00:53:48.340 --> 00:53:51.220]   So before I let you go, I'd love to ask you
[00:53:51.220 --> 00:53:52.860]   a couple of broader questions.
[00:53:52.860 --> 00:53:54.660]   And I think one that--
[00:53:54.660 --> 00:53:56.660]   I think you watched the Peter Norvig episode.
[00:53:56.660 --> 00:53:58.400]   And I was really curious to ask him this.
[00:53:58.400 --> 00:54:00.700]   And you're here too as someone who's
[00:54:00.700 --> 00:54:06.260]   kind of been watching machine learning for longer than most.
[00:54:06.260 --> 00:54:09.220]   And I'm really curious what your perspective is,
[00:54:09.220 --> 00:54:12.460]   having sort of seen a long arc of this stuff.
[00:54:12.460 --> 00:54:14.220]   I guess everyone must ask these questions,
[00:54:14.220 --> 00:54:15.380]   so I feel a little shy asking them.
[00:54:15.380 --> 00:54:17.000]   But I'm really curious what you think.
[00:54:17.000 --> 00:54:19.500]   When do you think we'll see, for example,
[00:54:19.500 --> 00:54:22.860]   autonomous cars working in our life at all times?
[00:54:22.860 --> 00:54:24.660]   And where do you think this goes?
[00:54:24.660 --> 00:54:26.260]   Do you feel like there's probably
[00:54:26.260 --> 00:54:28.820]   fundamental limitations to what we're doing with neural
[00:54:28.820 --> 00:54:29.620]   networks now?
[00:54:29.620 --> 00:54:33.260]   Or do you feel like scaling up what we have
[00:54:33.260 --> 00:54:36.780]   leads to singularity-like outcomes?
[00:54:36.780 --> 00:54:38.360]   Everything I know about deep learning
[00:54:38.360 --> 00:54:40.940]   I probably learned from listening to your podcast.
[00:54:40.940 --> 00:54:42.940]   I mean, because I'm dabbling.
[00:54:42.940 --> 00:54:44.580]   Peter Norvig's a legend.
[00:54:44.580 --> 00:54:48.420]   But you were treating neural nets back in grad school, no?
[00:54:48.420 --> 00:54:50.860]   Yeah, but these were Hopfield nets.
[00:54:50.860 --> 00:54:54.100]   And we hadn't really figured out the whole notion of layers
[00:54:54.100 --> 00:54:56.620]   and convolution and all this kind of stuff.
[00:54:56.620 --> 00:54:59.020]   So there was a real dead end.
[00:54:59.020 --> 00:55:00.980]   And it was very frustrating.
[00:55:00.980 --> 00:55:07.460]   So look, with drones, once we got one drone to fly,
[00:55:07.460 --> 00:55:10.260]   I was like, sky's going to be dark with these things.
[00:55:10.260 --> 00:55:12.620]   They're essentially free.
[00:55:12.620 --> 00:55:14.100]   It's done.
[00:55:14.100 --> 00:55:15.900]   I mean, why do we--
[00:55:15.900 --> 00:55:20.100]   think of how great it would be to have total information
[00:55:20.100 --> 00:55:21.940]   awareness of our planet.
[00:55:21.940 --> 00:55:24.100]   Rather than waiting for the satellites to come by
[00:55:24.100 --> 00:55:26.180]   or for the clouds to clear or having cameras
[00:55:26.180 --> 00:55:27.980]   in every stoplight, what if we could just
[00:55:27.980 --> 00:55:31.460]   have a camera anywhere, anytime to measure our planet
[00:55:31.460 --> 00:55:33.340]   so we could manage it better?
[00:55:33.340 --> 00:55:36.180]   So it seemed to me obvious that the missing middle, if you
[00:55:36.180 --> 00:55:37.680]   will-- we had cameras on the ground
[00:55:37.680 --> 00:55:38.880]   and we had cameras in space.
[00:55:38.880 --> 00:55:40.620]   And the missing middle was the air,
[00:55:40.620 --> 00:55:43.340]   which is an opportunity to be anywhere,
[00:55:43.340 --> 00:55:45.340]   anytime, higher resolution.
[00:55:45.340 --> 00:55:49.820]   It just seemed like a good thing to instrument our planet.
[00:55:49.820 --> 00:55:50.700]   And yet, here we are.
[00:55:50.700 --> 00:55:52.540]   There's nothing in the air.
[00:55:52.540 --> 00:55:53.620]   I can't believe it.
[00:55:53.620 --> 00:55:57.060]   It's been like 15 years, and we still don't have--
[00:55:57.060 --> 00:55:58.900]   sky dark with these things.
[00:55:58.900 --> 00:56:01.060]   We really don't have any autonomous drones at all
[00:56:01.060 --> 00:56:03.500]   in operation, except for the military, like we had back
[00:56:03.500 --> 00:56:04.000]   then.
[00:56:04.000 --> 00:56:05.020]   So what happened?
[00:56:05.020 --> 00:56:06.860]   Well, the problem wasn't technical.
[00:56:06.860 --> 00:56:08.220]   The problem was regulatory.
[00:56:08.220 --> 00:56:10.340]   It is the FAA will not allow drones
[00:56:10.340 --> 00:56:12.620]   to fly beyond visual line of sight,
[00:56:12.620 --> 00:56:17.380]   won't allow them to fly without a one-to-one pilot--
[00:56:17.380 --> 00:56:22.460]   a pilot with sticks, like an animal.
[00:56:22.460 --> 00:56:25.180]   Basically, the FAA will not allow drones to be autonomous.
[00:56:25.180 --> 00:56:27.140]   It won't allow drones to be--
[00:56:27.140 --> 00:56:29.100]   us to break the one-to-one ratio, which we've
[00:56:29.100 --> 00:56:31.620]   achieved nothing, in a sense.
[00:56:31.620 --> 00:56:34.180]   Imagine a robot that could only work tele-operated.
[00:56:34.180 --> 00:56:35.620]   I mean, what have you achieved?
[00:56:35.620 --> 00:56:38.500]   We still have one person, one robot, and that's where we are.
[00:56:38.500 --> 00:56:40.340]   Drones essentially have to be tele-operated,
[00:56:40.340 --> 00:56:42.140]   or at least have someone monitoring
[00:56:42.140 --> 00:56:43.980]   autonomous operations, which is even worse,
[00:56:43.980 --> 00:56:45.740]   because now they're not doing anything.
[00:56:45.740 --> 00:56:46.780]   So that was disappointing.
[00:56:46.780 --> 00:56:48.620]   It was disappointing for a regulatory reason.
[00:56:48.620 --> 00:56:49.820]   And I can understand it.
[00:56:49.820 --> 00:56:51.820]   And I work with the FAA pretty closely.
[00:56:51.820 --> 00:56:52.900]   I'm trying to resolve it.
[00:56:52.900 --> 00:56:56.900]   But the question about cars is also about--
[00:56:56.900 --> 00:56:58.780]   it's more about society and regulation
[00:56:58.780 --> 00:57:00.020]   than it is about the cars.
[00:57:00.020 --> 00:57:02.340]   Can cars be autonomous today?
[00:57:02.340 --> 00:57:03.660]   Yes.
[00:57:03.660 --> 00:57:05.620]   Can they be autonomous everywhere perfectly?
[00:57:05.620 --> 00:57:06.620]   No.
[00:57:06.620 --> 00:57:09.660]   Should it be OK for cars to be deployed autonomously
[00:57:09.660 --> 00:57:12.780]   in some places, where they can be highly reliable,
[00:57:12.780 --> 00:57:13.700]   but not everywhere?
[00:57:13.700 --> 00:57:14.220]   Absolutely.
[00:57:14.220 --> 00:57:15.820]   And companies like Voyage are doing that
[00:57:15.820 --> 00:57:19.220]   with retirement communities, closed courses, if you will.
[00:57:19.220 --> 00:57:21.260]   So I think the question is, so are drones
[00:57:21.260 --> 00:57:22.380]   in use today autonomously?
[00:57:22.380 --> 00:57:23.580]   Yes.
[00:57:23.580 --> 00:57:25.060]   Are they overhead right now?
[00:57:25.060 --> 00:57:25.900]   No.
[00:57:25.900 --> 00:57:27.740]   Am I disappointed there aren't more of them?
[00:57:27.740 --> 00:57:28.220]   Yes.
[00:57:28.220 --> 00:57:31.580]   But obviously, they go where they're needed most.
[00:57:31.580 --> 00:57:33.500]   And I presume that self-driving cars--
[00:57:33.500 --> 00:57:35.620]   I think we're setting the wrong standard.
[00:57:35.620 --> 00:57:41.500]   Should we have self-driving Ubers in all cities?
[00:57:41.500 --> 00:57:42.260]   Probably not.
[00:57:42.260 --> 00:57:43.980]   There's not a lot of advantage to it.
[00:57:43.980 --> 00:57:45.900]   Waymo's doing a little bit in Arizona.
[00:57:45.900 --> 00:57:47.860]   But that's probably not a game changer.
[00:57:47.860 --> 00:57:50.100]   Where would self-driving cars be a game changer?
[00:57:50.100 --> 00:57:51.820]   I think, actually, retirement communities
[00:57:51.820 --> 00:57:52.940]   are a really good example.
[00:57:52.940 --> 00:57:56.580]   They're quite empowering and liberating for people.
[00:57:56.580 --> 00:58:00.260]   And so I think if you sort of reset and say,
[00:58:00.260 --> 00:58:02.260]   as the technology gets better, will we
[00:58:02.260 --> 00:58:08.820]   identify really useful places where it wants to be,
[00:58:08.820 --> 00:58:12.060]   and focus less on the tech and more about the marketplaces
[00:58:12.060 --> 00:58:15.460]   and the demand, will we find those places?
[00:58:15.460 --> 00:58:16.940]   And the answer is yes.
[00:58:16.940 --> 00:58:19.740]   And so I think that all the questions about when
[00:58:19.740 --> 00:58:21.780]   are self-driving cars come, they all kind of come
[00:58:21.780 --> 00:58:23.300]   from a technology place.
[00:58:23.300 --> 00:58:26.500]   And I think we're being Silicon Valley--
[00:58:26.500 --> 00:58:27.980]   we're in our Silicon Valley bubble.
[00:58:27.980 --> 00:58:31.900]   We really need to understand the needs, the use cases,
[00:58:31.900 --> 00:58:34.420]   the places that would benefit most from them,
[00:58:34.420 --> 00:58:36.460]   and think less about the tech and more about how
[00:58:36.460 --> 00:58:37.580]   it's going to be used.
[00:58:37.580 --> 00:58:38.300]   Interesting.
[00:58:38.300 --> 00:58:39.300]   Interesting perspective.
[00:58:39.300 --> 00:58:40.100]   Thanks.
[00:58:40.100 --> 00:58:42.700]   So there's sort of two questions that we always end with.
[00:58:42.700 --> 00:58:46.740]   And the second to last one is, from your perspective,
[00:58:46.740 --> 00:58:50.660]   especially from drones and robots,
[00:58:50.660 --> 00:58:53.180]   what's one underrated aspect of machine learning
[00:58:53.180 --> 00:58:55.580]   that you think people should pay more attention to?
[00:58:55.580 --> 00:58:58.580]   I think I mentioned I'm really into simulation
[00:58:58.580 --> 00:58:59.500]   and synthetic data.
[00:58:59.500 --> 00:59:01.780]   And I know you had a couple episodes now
[00:59:01.780 --> 00:59:02.980]   on synthetic data creation.
[00:59:02.980 --> 00:59:05.740]   But I do think this is the golden age of simulation.
[00:59:05.740 --> 00:59:07.300]   I work really closely with Microsoft.
[00:59:07.300 --> 00:59:10.700]   And if you've used Microsoft Flight Simulator 2020, which
[00:59:10.700 --> 00:59:13.860]   basically uses satellite and aerial data
[00:59:13.860 --> 00:59:17.740]   to recreate the entire planet photorealistically
[00:59:17.740 --> 00:59:19.860]   with using photogrammetry to create
[00:59:19.860 --> 00:59:21.500]   a 3D models of the planet.
[00:59:21.500 --> 00:59:24.140]   But I mean, like real time, like with weather and everything,
[00:59:24.140 --> 00:59:25.180]   like as it really is.
[00:59:25.180 --> 00:59:27.740]   I think this is the golden age of simulation, the golden age
[00:59:27.740 --> 00:59:28.740]   of rendering that.
[00:59:28.740 --> 00:59:34.460]   And as a result, our opportunity to use these powerful engines
[00:59:34.460 --> 00:59:36.540]   to train models better.
[00:59:36.540 --> 00:59:38.860]   We talked about domain randomization.
[00:59:38.860 --> 00:59:41.060]   We talked about synthetic data.
[00:59:41.060 --> 00:59:45.260]   But I'm most excited about that.
[00:59:45.260 --> 00:59:48.220]   Because I feel like we've kind of hit some limits
[00:59:48.220 --> 00:59:50.140]   in the ability of humans to train models.
[00:59:50.140 --> 00:59:54.420]   And even SCPT-3 is limited by the--
[00:59:54.420 --> 00:59:56.300]   as you've mentioned before, is limited
[00:59:56.300 --> 00:59:58.620]   by the amount of data on the internet, which sounds like a
[00:59:58.620 --> 01:00:00.420]   lot, but is never enough.
[01:00:00.420 --> 01:00:02.700]   And so I think that we need to start generating--
[01:00:02.700 --> 01:00:04.820]   we need to think really hard about our synthetic data
[01:00:04.820 --> 01:00:07.700]   generation strategies so that we can break through
[01:00:07.700 --> 01:00:10.580]   the limits of real data and start training them on things
[01:00:10.580 --> 01:00:12.780]   that we can only imagine.
[01:00:12.780 --> 01:00:14.540]   Totally.
[01:00:14.540 --> 01:00:16.540]   OK, and the final question is for you,
[01:00:16.540 --> 01:00:18.820]   and you've actually built a pretty sophisticated end
[01:00:18.820 --> 01:00:20.900]   to end ML system now.
[01:00:20.900 --> 01:00:23.580]   What's the biggest challenge of getting that to work?
[01:00:23.580 --> 01:00:24.660]   Or what's the challenge of getting that to work
[01:00:24.660 --> 01:00:27.380]   that people might not expect when you just sort of lay out
[01:00:27.380 --> 01:00:28.740]   what you're doing?
[01:00:28.740 --> 01:00:30.620]   So first of all, I should say, I did not build this.
[01:00:30.620 --> 01:00:31.860]   This is the Donkey Kara team.
[01:00:31.860 --> 01:00:34.980]   And there's a lot of people there who get credit
[01:00:34.980 --> 01:00:35.500]   for that.
[01:00:35.500 --> 01:00:39.500]   Tom Kramer was the originator of the current stack.
[01:00:39.500 --> 01:00:42.620]   So first of all, one thing you should know about end to end
[01:00:42.620 --> 01:00:43.740]   is that it is end to end.
[01:00:43.740 --> 01:00:46.340]   All we have is one channel.
[01:00:46.340 --> 01:00:48.620]   Pictures come in and controls go out.
[01:00:48.620 --> 01:00:50.380]   We're blessed to have things like TensorFlow
[01:00:50.380 --> 01:00:51.380]   that will do that.
[01:00:51.380 --> 01:00:54.980]   But once we start introducing other things like depth
[01:00:54.980 --> 01:00:57.820]   sensing and those other sensors we talk about,
[01:00:57.820 --> 01:01:00.780]   we're probably going to need to introduce
[01:01:00.780 --> 01:01:02.980]   multiple parallel networks running.
[01:01:02.980 --> 01:01:05.060]   Now, should the obstacle avoidance
[01:01:05.060 --> 01:01:07.300]   be also running on machine learning?
[01:01:07.300 --> 01:01:09.660]   Or should that be more sort of classical control theory,
[01:01:09.660 --> 01:01:12.420]   if then, if you will?
[01:01:12.420 --> 01:01:15.020]   How do we combine classic robotics control
[01:01:15.020 --> 01:01:16.540]   theory with deep learning?
[01:01:16.540 --> 01:01:17.540]   One's probabilistic.
[01:01:17.540 --> 01:01:18.780]   The other one's deterministic.
[01:01:18.780 --> 01:01:19.980]   How do we merge them?
[01:01:19.980 --> 01:01:21.900]   And so I think there's some interesting work
[01:01:21.900 --> 01:01:25.580]   to do to start to introduce multiple inputs.
[01:01:25.580 --> 01:01:27.460]   Right now, we have one input, one output.
[01:01:27.460 --> 01:01:29.980]   But of course, in robotics, it's MIMO,
[01:01:29.980 --> 01:01:31.660]   multiple input, multiple output.
[01:01:31.660 --> 01:01:36.220]   And I think if you stick to the $400 limit
[01:01:36.220 --> 01:01:39.820]   to be able to do multiple input, multiple output,
[01:01:39.820 --> 01:01:44.540]   deep learning in all of these channels is super interesting.
[01:01:44.540 --> 01:01:46.540]   I don't know whether we're there yet.
[01:01:46.540 --> 01:01:49.820]   But that's sort of--
[01:01:49.820 --> 01:01:51.380]   you asked, what have we learned?
[01:01:51.380 --> 01:01:55.020]   And we've learned that you can do one channel, one network
[01:01:55.020 --> 01:01:56.340]   pretty easily.
[01:01:56.340 --> 01:01:58.300]   And it works amazingly well.
[01:01:58.300 --> 01:02:00.780]   But it doesn't scale to multiple inputs.
[01:02:00.780 --> 01:02:02.540]   And if you really want to start winning
[01:02:02.540 --> 01:02:04.940]   against competitive races with other cars
[01:02:04.940 --> 01:02:07.020]   and actually doing what a human would do in a race,
[01:02:07.020 --> 01:02:09.620]   we're going to need to bring in all the channels and sensors
[01:02:09.620 --> 01:02:10.420]   and data we can.
[01:02:10.420 --> 01:02:12.620]   And that means a different architecture.
[01:02:12.620 --> 01:02:15.540]   Although the part of that car that's going to come down
[01:02:15.540 --> 01:02:17.500]   is the running neural networks.
[01:02:17.500 --> 01:02:19.380]   I mean, I feel like that's the thing that seems
[01:02:19.380 --> 01:02:21.420]   to be dropping the fastest.
[01:02:21.420 --> 01:02:22.660]   Well, that is good news.
[01:02:22.660 --> 01:02:27.620]   The Raspberry Pi 5 or the Xavier Jetson can do that.
[01:02:27.620 --> 01:02:30.460]   Then, yeah, maybe we can just apply our same technique
[01:02:30.460 --> 01:02:32.620]   and just say, OK, let's add another network
[01:02:32.620 --> 01:02:35.300]   to keep track of the other car, the other cars.
[01:02:35.300 --> 01:02:36.980]   Add a third network to keep track
[01:02:36.980 --> 01:02:39.300]   of the sliding, the friction, how the car is actually
[01:02:39.300 --> 01:02:42.540]   mechanically moving on the track with the IMU.
[01:02:42.540 --> 01:02:44.140]   And then find some way to merge them.
[01:02:44.140 --> 01:02:45.740]   That would be super exciting.
[01:02:45.740 --> 01:02:49.540]   I don't-- to do the whole thing at 30, 50,
[01:02:49.540 --> 01:02:53.020]   60 frames per second under $400, I
[01:02:53.020 --> 01:02:55.260]   don't think we're quite there yet.
[01:02:55.260 --> 01:02:56.300]   But you're right.
[01:02:56.300 --> 01:02:58.820]   That's going to be the focus over the next couple of years.
[01:02:58.820 --> 01:02:59.100]   Awesome.
[01:02:59.100 --> 01:02:59.980]   Well, thanks so much.
[01:02:59.980 --> 01:03:01.220]   It's an honor to talk to you.
[01:03:01.220 --> 01:03:02.540]   And that was so much fun.
[01:03:02.540 --> 01:03:04.100]   This was a pleasure.
[01:03:04.100 --> 01:03:07.980]   Thanks for listening to another episode of Gradient Dissent.
[01:03:07.980 --> 01:03:09.780]   Doing these interviews are a lot of fun.
[01:03:09.780 --> 01:03:11.900]   And it's especially fun for me when I can actually
[01:03:11.900 --> 01:03:14.580]   hear from the people that are listening to the episodes.
[01:03:14.580 --> 01:03:17.220]   So if you wouldn't mind leaving a comment
[01:03:17.220 --> 01:03:19.900]   and telling me what you think or starting a conversation,
[01:03:19.900 --> 01:03:22.380]   that would make me inspired to do more of these episodes.
[01:03:22.380 --> 01:03:25.180]   And also, if you wouldn't mind liking and subscribing,
[01:03:25.180 --> 01:03:26.580]   I'd appreciate that a lot.

