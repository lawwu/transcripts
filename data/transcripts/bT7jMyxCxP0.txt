
[00:00:00.120 --> 00:00:07.980]   Two years ago, in episode 164 of this podcast, I summarized where the scientific research
[00:00:07.980 --> 00:00:12.040]   currently stood when it came to the topic of smartphone, social media, and kids.
[00:00:12.040 --> 00:00:16.740]   I argued then that the scientific conversation on this topic had passed through three phases
[00:00:16.740 --> 00:00:19.220]   and was currently in a third phase.
[00:00:19.220 --> 00:00:24.080]   Today, I want to point to some new work that I think establishes that we have moved since
[00:00:24.080 --> 00:00:28.280]   then into a fourth phase and it's the most consequential one of all because it's the
[00:00:28.280 --> 00:00:30.820]   phase that's going to lead to some pretty drastic changes.
[00:00:30.820 --> 00:00:36.660]   I'm talking about one or two years from now, our culture is going to be very different when
[00:00:36.660 --> 00:00:38.700]   it comes to how we think about kids and these technologies.
[00:00:38.700 --> 00:00:40.320]   So here's what I want to do in today's deep dive.
[00:00:40.320 --> 00:00:44.620]   I want to explain this new phase that we have entered in the last year or so and tell you
[00:00:44.620 --> 00:00:48.760]   what changes are coming and what that means for you if you're a kid or for your own kids
[00:00:48.760 --> 00:00:52.580]   if you're a parent or maybe for your own life if you're somewhere in between.
[00:00:52.580 --> 00:00:57.440]   But let me start by going back very briefly to that episode from two years ago and mentioning
[00:00:57.440 --> 00:01:02.240]   the three phases of scientific research and opinions on smartphones and kids that I had
[00:01:02.240 --> 00:01:03.420]   summarized back in that episode.
[00:01:03.420 --> 00:01:08.980]   I said the first stage lasted from 2012 to 2017.
[00:01:08.980 --> 00:01:13.700]   This was the stage in which alarming correlations and reports begin to emerge.
[00:01:13.700 --> 00:01:18.780]   This is when you first begin to see things like, huh, it's kind of a mental health issue
[00:01:18.780 --> 00:01:19.680]   among teenagers.
[00:01:19.680 --> 00:01:21.620]   It's going up in a way it hadn't before.
[00:01:21.620 --> 00:01:22.800]   This is when we begin to say, huh.
[00:01:23.760 --> 00:01:26.500]   It's mainly anxiety and depression related disorders.
[00:01:26.500 --> 00:01:29.840]   Other types of common teen mental health disorders aren't going up as much.
[00:01:29.840 --> 00:01:33.340]   Oh, we're beginning to hear kids talk about, you know, I'm kind of on my phones more often.
[00:01:33.340 --> 00:01:34.440]   It was very correlational.
[00:01:34.440 --> 00:01:39.780]   But people began to worry something might be going on here with kids and phones.
[00:01:39.900 --> 00:01:42.740]   This next stage lasts from 2017 to 2020.
[00:01:42.740 --> 00:01:49.660]   This is when we begin to actually do retroactive research on this issue.
[00:01:49.660 --> 00:01:54.720]   What that means is social scientists, in particular social psychologists, would take very large data
[00:01:54.720 --> 00:01:58.480]   sets in which you would ask 100,000 people a bunch of questions and look for correlations
[00:01:58.480 --> 00:01:59.280]   in this data set.
[00:01:59.280 --> 00:02:03.640]   And they begin to find these connections between things like social media use and smartphone use
[00:02:03.640 --> 00:02:05.880]   and negative outcomes for young people.
[00:02:05.880 --> 00:02:06.740]   They found correlations.
[00:02:06.740 --> 00:02:11.420]   But I called this period in that original podcast episode, The Data Wars, because a lot of critics
[00:02:11.420 --> 00:02:14.500]   came out of the woodwork as well and said, well, it depends on how you analyze the data.
[00:02:14.500 --> 00:02:19.420]   And if you look at it this way, those correlations go away or they get smaller.
[00:02:19.420 --> 00:02:25.000]   Or we can find other things that are mundane that also have some correlations to harm.
[00:02:25.000 --> 00:02:28.720]   This was the period in which you would see a lot of elite publications that were just sort
[00:02:28.720 --> 00:02:31.460]   of shifting at this point between how do we feel about this?
[00:02:31.840 --> 00:02:38.040]   Begin to say things like, well, we're not sure yet if these technologies are causing harms for kids.
[00:02:38.040 --> 00:02:39.020]   This is a hypothesis.
[00:02:39.020 --> 00:02:40.560]   There's evidence on both sides.
[00:02:40.560 --> 00:02:43.360]   There's a lot of like on the one hand, on the other hand, reporting going on.
[00:02:43.360 --> 00:02:50.600]   The final stage I talked about back in that episode from 2023 was this idea that the opposition
[00:02:50.600 --> 00:02:54.380]   was beginning to quiet because other threads of evidence began to come in.
[00:02:54.660 --> 00:02:58.700]   In other words, we got other types of experimental design, some that were prospective, like randomized
[00:02:58.700 --> 00:03:02.620]   control trials, and other types that were retroactive but in very clever ways, looking,
[00:03:02.620 --> 00:03:06.900]   for example, at neighboring counties where high-speed internet arrived at different times.
[00:03:06.900 --> 00:03:11.400]   So they were demographically similar, but social media was widely adopted by one before the other
[00:03:11.400 --> 00:03:16.560]   and looking at differences in what was going on with mental health or actual prospective studies
[00:03:16.560 --> 00:03:20.240]   where you paid people to stop using social media and saw what happened, randomly selected,
[00:03:20.240 --> 00:03:21.520]   comparing them to a control group.
[00:03:21.980 --> 00:03:25.900]   And a lot of these different strains of evidence with different experimental designs were showing
[00:03:25.900 --> 00:03:26.720]   similar results.
[00:03:26.720 --> 00:03:31.940]   This sort of quieted the correlations, not causation, we're not quite sure if this is good or bad
[00:03:31.940 --> 00:03:33.260]   type of opposition.
[00:03:33.260 --> 00:03:36.880]   The sort of reporting of like, well, we're not quite sure if this is bad or not, that began
[00:03:36.880 --> 00:03:37.580]   to die down.
[00:03:37.580 --> 00:03:41.280]   That was the phase we were in until the last year or so.
[00:03:41.280 --> 00:03:47.840]   Last year or so, the evidence has really picked up to the point where now there is a very strong
[00:03:47.840 --> 00:03:55.800]   consensus emerging and this is beginning to, I think this is sort of persuading some major
[00:03:55.800 --> 00:03:56.740]   changes that are coming.
[00:03:56.740 --> 00:03:58.080]   I want to bring a paper up here.
[00:03:58.080 --> 00:03:59.560]   This was posted last month.
[00:03:59.560 --> 00:04:01.020]   It's sort of like a preprint.
[00:04:01.020 --> 00:04:06.220]   The title is, A Consensus Statement on Potential Negative Impacts of Smartphone and Social Media
[00:04:06.220 --> 00:04:07.820]   Use on Adolescent Mental Health.
[00:04:07.820 --> 00:04:11.940]   Now, if you're watching this instead of just listening, you'll see on the screen here this
[00:04:11.940 --> 00:04:13.740]   huge list of authors, right?
[00:04:14.040 --> 00:04:15.240]   Why are there so many authors?
[00:04:15.240 --> 00:04:21.280]   Because what they did here is they took a large collection of relevant researchers and they
[00:04:21.280 --> 00:04:24.940]   asked them like, hey, we're going to make a bunch of statements about the potential harms
[00:04:24.940 --> 00:04:25.880]   of phones and kids.
[00:04:25.880 --> 00:04:31.380]   Tell us if you think it's true, probably true, probably not true, or you don't know.
[00:04:31.380 --> 00:04:35.180]   Let's just see where the scientific community is.
[00:04:35.180 --> 00:04:40.540]   Now, remember, again, before I show you the results here, it wasn't that long ago, 2019,
[00:04:40.540 --> 00:04:47.840]   2020, it wasn't that long ago that if you looked at sort of reporting on social media, smartphones
[00:04:47.840 --> 00:04:50.520]   and harms for kids, you get a lot of like, we're not really sure yet.
[00:04:50.520 --> 00:04:52.100]   There's just some correlations, but we're not sure yet.
[00:04:52.100 --> 00:04:55.620]   Now, by 2025, this has shifted more significantly.
[00:04:55.620 --> 00:05:00.540]   I'm going to scroll through here to isolate what is one of the key graphs.
[00:05:00.680 --> 00:05:02.240]   All right, so I'm going to put this on the screen here.
[00:05:02.240 --> 00:05:12.060]   So there's a list on the left of claims about smartphones, social media, and kids in particular.
[00:05:12.060 --> 00:05:16.980]   And on the right, there's a stack bar chart where the blue is a percentage of people that
[00:05:16.980 --> 00:05:17.820]   says probably true.
[00:05:17.820 --> 00:05:23.180]   The yellow are people who say don't know, and the red are people who say it's probably false.
[00:05:23.180 --> 00:05:28.140]   They're asking these questions of that large group of experts, experts on these questions.
[00:05:28.680 --> 00:05:33.700]   And you can see, just looking at the shape of this, the probably trues dominate.
[00:05:33.700 --> 00:05:40.180]   There are no statements here for which the probably false outweigh the probably true.
[00:05:40.180 --> 00:05:45.740]   But for the first half of these, the probably true dominates.
[00:05:45.740 --> 00:05:48.840]   Five to one, ten to one dominates the probably false.
[00:05:48.840 --> 00:05:51.860]   Let me read some of these that have really strong support from the experts.
[00:05:53.040 --> 00:05:56.360]   Sleep deprivation and social deprivation can reduce mental health.
[00:05:56.360 --> 00:05:58.060]   Adolescent mental health has declined.
[00:05:58.060 --> 00:06:00.120]   Behavioral addiction can reduce mental health.
[00:06:00.120 --> 00:06:02.000]   Childhood shifted from play to phone.
[00:06:02.000 --> 00:06:03.900]   Social media can impair sleep.
[00:06:03.900 --> 00:06:06.380]   Social media increases visual social comparison in girls.
[00:06:06.380 --> 00:06:08.620]   Social media increases mental disorder exposure in girls.
[00:06:08.620 --> 00:06:10.280]   Social media can cause behavioral addiction.
[00:06:10.280 --> 00:06:13.900]   Social media can fragment attention.
[00:06:13.900 --> 00:06:17.140]   Social media increases predation, harassment in girls.
[00:06:17.140 --> 00:06:20.120]   Phone-free schools would benefit mental health.
[00:06:20.480 --> 00:06:22.920]   No smartphones before high school would benefit mental health.
[00:06:22.920 --> 00:06:25.580]   All of this, this is the first half.
[00:06:25.580 --> 00:06:35.040]   All of this are things that have at least like a three to four to one ratio of these experts saying this is probably true as compared to those who are saying it's probably false.
[00:06:36.100 --> 00:06:40.340]   So I think this is sort of a remarkable finding here.
[00:06:40.340 --> 00:06:45.800]   It says, no, no, now the experts are much more aligned with the idea that this is a problem.
[00:06:45.800 --> 00:06:47.640]   Right.
[00:06:47.640 --> 00:06:54.500]   This is causing these phones and in particular social media is causing real problems.
[00:06:55.320 --> 00:07:02.340]   Now, I think this is pushing us to a fourth phase of the discussion of phones and kids.
[00:07:02.340 --> 00:07:08.640]   And it's a fourth phase that I think of as the parents strike back.
[00:07:09.360 --> 00:07:10.700]   I was just at Disneyland.
[00:07:10.700 --> 00:07:13.640]   We went to the Galaxy's Edge Star Wars exhibit.
[00:07:13.640 --> 00:07:15.100]   I have Star Wars on my mind.
[00:07:15.100 --> 00:07:16.780]   The parents strike back.
[00:07:16.780 --> 00:07:18.680]   I think this is the phase we are in.
[00:07:18.680 --> 00:07:27.620]   As this consensus quickly solidified that these are causing problems, parents are beginning to say, then why the hell are we putting up with this with our kids?
[00:07:27.620 --> 00:07:32.780]   To emphasize this, I'm going to bring up another article here.
[00:07:32.780 --> 00:07:34.240]   Jesse, is this in an app?
[00:07:34.240 --> 00:07:34.960]   Yeah.
[00:07:35.380 --> 00:07:36.380]   Is there like a New York Times?
[00:07:36.380 --> 00:07:36.880]   I see it.
[00:07:36.880 --> 00:07:37.080]   Okay.
[00:07:37.080 --> 00:07:40.940]   I want to bring up another article here that surveys both parents and kids.
[00:07:40.940 --> 00:07:42.360]   This came out just last week.
[00:07:42.360 --> 00:07:46.280]   There's an op-ed in the New York Times that talks about the data I'm going to talk about.
[00:07:46.280 --> 00:07:50.700]   This op-ed, I have it on the screen here, was called We Don't Have to Give Into Smartphones.
[00:07:50.700 --> 00:08:03.220]   And it's co-authored by John Haidt, who you probably know at NYU, along with Will Johnson, who's the chief executive of the Harris Poll, and Zach Roush, who is also a researcher at NYU, who works with John Haidt.
[00:08:03.920 --> 00:08:12.040]   Now, they talk about, in this article, a series of surveys that John and Zach helped design with the Harris Poll.
[00:08:12.040 --> 00:08:13.980]   I want to read a couple quotes here.
[00:08:13.980 --> 00:08:15.620]   These both come from the articles.
[00:08:15.620 --> 00:08:20.440]   This is about how parents and kids themselves now think about these technologies.
[00:08:20.440 --> 00:08:21.660]   All right.
[00:08:21.700 --> 00:08:22.760]   So now I'm reading from the article.
[00:08:22.760 --> 00:08:29.280]   To better understand the tensions over technology playing out in American families, we worked with the Harris Poll to conduct two surveys.
[00:08:29.280 --> 00:08:38.480]   As we reported last year, our survey of 1,006 members of Gen Z found that many young people feel trapped, tethered to digital products like TikTok and Snapchat.
[00:08:39.160 --> 00:08:46.900]   Nearly half of all participants expressed regret about having access to many of the most popular social media platforms.
[00:08:47.280 --> 00:08:55.260]   Here we present the second part of our investigation, a nationally representative survey of 1,013 parents who have children under 18.
[00:08:55.260 --> 00:08:58.220]   The overall picture isn't any better.
[00:08:58.220 --> 00:09:00.960]   We find widespread feelings of entrapment and regret.
[00:09:00.960 --> 00:09:07.860]   Many parents gave their children smartphones and social media access early in their lives, yet many wish that social media had never been invented.
[00:09:07.860 --> 00:09:13.940]   And overwhelmingly, they support new social norms and policies that would protect kids from online harm.
[00:09:13.940 --> 00:09:17.240]   There's a couple of charts in here we can talk about briefly.
[00:09:17.240 --> 00:09:19.580]   This one I thought was pretty interesting.
[00:09:19.580 --> 00:09:26.980]   This is a stacked bar chart where there's different answers to fill in the blank in the following sentence.
[00:09:26.980 --> 00:09:33.620]   When I think about my child's experience growing up, I wish blank had never been invented.
[00:09:34.340 --> 00:09:41.160]   So the biggest answer to this was mature online content, 72% of parents said I wish that had not been invented.
[00:09:41.160 --> 00:09:45.760]   But then you have TikTok and Twitter tied with guns.
[00:09:45.760 --> 00:09:48.800]   That's 62% of parents said I wish that had never been invented.
[00:09:48.800 --> 00:09:50.420]   Snapchat's two percentage points away.
[00:09:50.420 --> 00:09:57.940]   Then you get alcohol, and within a percentage point or two after alcohol, you get Instagram, social media, and Facebook.
[00:09:57.940 --> 00:10:02.760]   Down towards the bottom, just so you don't think like, well, parents are worried about everything.
[00:10:03.300 --> 00:10:07.580]   The stuff we used to worry about, like television, right?
[00:10:07.580 --> 00:10:10.940]   Only 17% of parents wish that was never invented.
[00:10:10.940 --> 00:10:13.260]   What about video games?
[00:10:13.260 --> 00:10:15.400]   33% of parents.
[00:10:15.400 --> 00:10:16.640]   Hey, it's Cal.
[00:10:16.640 --> 00:10:28.240]   I wanted to interrupt briefly to say that if you're enjoying this video, then you need to check out my new book, Slow Productivity, The Lost Art of Accomplishment Without Burnout.
[00:10:28.460 --> 00:10:33.740]   This is like the Bible for most of the ideas we talk about here in these videos.
[00:10:33.740 --> 00:10:39.120]   You can get a free excerpt at calnewport.com slash slow.
[00:10:39.120 --> 00:10:40.900]   I know you're going to like it.
[00:10:40.900 --> 00:10:41.920]   Check it out.
[00:10:41.920 --> 00:10:43.260]   Now let's get back to the video.
[00:10:43.420 --> 00:10:45.120]   So what are we seeing here?
[00:10:45.120 --> 00:10:59.680]   We're seeing here that both kids and parents are picking up on what has become the consensus in the scientific community, which is these tools and some of the apps on them are hurting us and hurting our kids, and we're done with it.
[00:11:00.460 --> 00:11:02.760]   Nearly half the kids said, I wish this had never been invented.
[00:11:02.760 --> 00:11:04.520]   They don't want to use it.
[00:11:04.520 --> 00:11:15.240]   We have parents are as likely, they're rating TikTok, Twitter, and Snapchat as bad as guns in terms of wishing it hadn't been invented.
[00:11:16.240 --> 00:11:23.520]   This is a real problem, and parents are saying, hey, we have to now do something about it.
[00:11:23.520 --> 00:11:33.060]   We don't want to hear the sort of think tank conversation where people are trying to make themselves sound smart by being like, well, you know, it depends on the context.
[00:11:33.060 --> 00:11:50.000]   And, like, sometimes this is not so bad, and, like, maybe that is true, but I think right now we are in this new phase where people want change, and I think this change has begun and is going to play out in about the next year to three years, one to three-year window.
[00:11:50.000 --> 00:11:52.260]   What are the changes that are going to happen?
[00:11:52.260 --> 00:11:54.240]   And I think John Haidt nailed this, actually.
[00:11:54.240 --> 00:12:03.500]   So John Haidt, who has really dedicated his life to this issue in the last two years, laid out a collection of social norms that he's been pushing for.
[00:12:03.500 --> 00:12:08.960]   So he clarified his message based on all the work and summaries of research he's done over the past however many years.
[00:12:08.960 --> 00:12:11.060]   He said, here's the norms he would like to see.
[00:12:11.060 --> 00:12:13.360]   He listed four, but there's three of them that I think are relevant.
[00:12:13.360 --> 00:12:16.660]   One, don't give a kid a smartphone until high school.
[00:12:17.080 --> 00:12:23.140]   Two, don't give a kid access to social media on that smartphone until the age of 16, which is even later.
[00:12:23.140 --> 00:12:30.040]   And three, schools should really enforce a no-phone policy within their hallways.
[00:12:30.040 --> 00:12:37.060]   That last norm is happening nationwide, and when it happened, it began happening fast.
[00:12:37.060 --> 00:12:37.860]   Keep your eyes on this.
[00:12:37.860 --> 00:12:42.200]   Two years ago, this was, you know, D.C. public schools, where I am or wherever.
[00:12:42.200 --> 00:12:43.520]   People would be like, well, I don't know.
[00:12:43.520 --> 00:12:44.640]   Like, what if there's an emergency?
[00:12:44.640 --> 00:12:45.500]   I need to reach my kid.
[00:12:45.500 --> 00:12:48.400]   Now it is happening fast across the country.
[00:12:48.400 --> 00:12:52.280]   Schools are just boom, boom, boom, boom, boom, boom, putting these policies in place and meaning them.
[00:12:52.280 --> 00:12:53.680]   That happened fast.
[00:12:53.680 --> 00:12:58.980]   I think that social media until 16, this is going to start happening fast, too.
[00:12:58.980 --> 00:13:01.280]   I've reported in the pages of The New Yorker back in January.
[00:13:01.280 --> 00:13:02.520]   You can see my article on this.
[00:13:02.520 --> 00:13:03.740]   Australia passed a ban.
[00:13:03.740 --> 00:13:06.200]   Hey, you got to be 16 to use social media.
[00:13:06.200 --> 00:13:08.280]   I think there's pressure to do something like that in the U.S.
[00:13:08.280 --> 00:13:09.260]   I think they probably should.
[00:13:09.260 --> 00:13:13.320]   Is it going to stop all kids from having access to social media?
[00:13:13.320 --> 00:13:16.340]   No, but it's going to give parents to cover.
[00:13:16.340 --> 00:13:20.840]   It will give them cover to say, here's why I'm not allowing you to have these accounts because it's against the law.
[00:13:20.840 --> 00:13:23.580]   It gives cover to the parents that we see in the survey.
[00:13:23.580 --> 00:13:25.420]   Don't wish these things had not been invented.
[00:13:25.420 --> 00:13:28.780]   It helps them out when their kid says everyone is doing it and they say, I don't care.
[00:13:28.780 --> 00:13:29.500]   It's against the law.
[00:13:29.500 --> 00:13:31.320]   So I think it's going to be useful in that way.
[00:13:31.380 --> 00:13:40.000]   And if you think that there's somehow no way to put this sort of an age restriction on a product without having giant privacy violations, I mean, you got to speak to everything else in our culture that has age restrictions.
[00:13:40.000 --> 00:13:45.940]   If anything deserves it, this has to be among the collection of things that probably need some sort of age restriction.
[00:13:45.940 --> 00:13:47.160]   What about phones till high school?
[00:13:47.160 --> 00:13:48.080]   This is just cultural.
[00:13:48.080 --> 00:13:49.580]   There's a cultural shift.
[00:13:49.960 --> 00:13:55.300]   We reach an uneasy consensus that said, yeah, like middle school is like roughly when you should get phones.
[00:13:55.300 --> 00:13:56.160]   There's a chart in here.
[00:13:56.160 --> 00:13:57.480]   They asked the parents about it.
[00:13:57.480 --> 00:14:04.240]   About the 50% point, if you said, when did you give your kids phone, you reach majority point in the 10 to 12-year-old age.
[00:14:04.240 --> 00:14:05.020]   It's just too young.
[00:14:05.020 --> 00:14:06.520]   It should be 14 to 16.
[00:14:06.520 --> 00:14:08.620]   That is not that big of a shift.
[00:14:08.620 --> 00:14:10.120]   It's just cultural.
[00:14:10.220 --> 00:14:12.980]   We just thought like maybe middle school when this has happened, we just changed the culture.
[00:14:12.980 --> 00:14:13.640]   It should be high school.
[00:14:13.640 --> 00:14:16.900]   But as Haidt points out, the research shows us we'll make a really big difference.
[00:14:16.900 --> 00:14:19.460]   You are much more mature by high school versus middle school.
[00:14:19.460 --> 00:14:24.000]   Most importantly, you've gone through a lot more mental development.
[00:14:24.000 --> 00:14:24.880]   You've started puberty.
[00:14:24.880 --> 00:14:26.440]   You have more of identity development.
[00:14:26.440 --> 00:14:30.100]   You have more of a sort of academic foundation.
[00:14:30.100 --> 00:14:32.080]   Your brain is getting a little bit more used to schoolwork.
[00:14:32.080 --> 00:14:36.440]   You get to go through all these stages, these developmental stages, without that rapid type of stimuli.
[00:14:36.440 --> 00:14:39.000]   So I think these are coming fast.
[00:14:39.080 --> 00:14:45.260]   If you have a kid who is, let's say, seven years old or younger right now, they will unlikely get a phone before high school.
[00:14:45.260 --> 00:14:48.380]   And if social media is still a big thing at that point, and who knows?
[00:14:48.380 --> 00:14:50.140]   I think it's a lot more fragile than it used to be.
[00:14:50.140 --> 00:14:52.740]   This will be something where it's like, I don't know if you should be using this.
[00:14:52.740 --> 00:14:54.000]   If so, that's going to be later in high school.
[00:14:54.000 --> 00:14:55.100]   That is coming now.
[00:14:55.100 --> 00:15:00.540]   If you have a kid right now in these ages, it's kind of hard because it's all sort of you're in a liminal space between the two regimes.
[00:15:00.540 --> 00:15:05.660]   If you have a kid that's right now 18 years or older, like 18 and 25, they got screwed.
[00:15:05.660 --> 00:15:06.120]   I'm sorry.
[00:15:06.120 --> 00:15:07.520]   We experimented on them.
[00:15:08.300 --> 00:15:09.740]   Hey, kids are good at technology.
[00:15:09.740 --> 00:15:12.440]   Didn't Barack Obama use Facebook to help get elected?
[00:15:12.440 --> 00:15:13.260]   This must be good.
[00:15:13.260 --> 00:15:14.820]   You kind of got hosed.
[00:15:14.820 --> 00:15:15.180]   Sorry.
[00:15:15.180 --> 00:15:16.760]   If you're a kid right now, you're a parent.
[00:15:16.760 --> 00:15:17.420]   You have to battle.
[00:15:17.420 --> 00:15:19.480]   If your kids are younger, it's not going to be an issue.
[00:15:19.480 --> 00:15:20.880]   I think those norms are coming.
[00:15:20.880 --> 00:15:22.140]   So we're in phase three now.
[00:15:22.140 --> 00:15:23.360]   The parents strike back.
[00:15:23.360 --> 00:15:24.080]   They're ready for change.
[00:15:24.080 --> 00:15:24.800]   Changes are happening.
[00:15:25.100 --> 00:15:28.200]   So you can put this prediction down one to three years from now.
[00:15:28.200 --> 00:15:34.380]   Those three norms, I think, will be not universal but uncontroversial, that you as a parent can follow them.
[00:15:34.380 --> 00:15:35.780]   You will be part of a large crowd.
[00:15:35.780 --> 00:15:38.320]   The collective action problem will be solved.
[00:15:38.960 --> 00:15:40.460]   So I think that's good news, Jesse.
[00:15:40.460 --> 00:15:43.340]   I think it was this experiment with like kids are good with tech.
[00:15:43.340 --> 00:15:44.340]   Let's just give them phones.
[00:15:44.500 --> 00:15:45.660]   I think it was a problem.
[00:15:45.660 --> 00:15:48.460]   No one doubts it anymore.
[00:15:48.460 --> 00:15:49.980]   No one doubts it.
[00:15:49.980 --> 00:15:51.160]   We have the clear way out.
[00:15:51.160 --> 00:15:52.040]   We got to just take it.
[00:15:52.040 --> 00:15:52.820]   Yeah, it's hard.
[00:15:52.820 --> 00:15:53.280]   It's annoying.
[00:15:53.280 --> 00:15:54.100]   But we got to take it.
[00:15:54.100 --> 00:15:55.780]   So there we go.
[00:15:55.780 --> 00:15:56.460]   We had it easy.
[00:15:56.460 --> 00:15:57.120]   We didn't have phones.
[00:15:57.120 --> 00:16:01.040]   We had Pee Wee's Playhouse.
[00:16:01.040 --> 00:16:05.820]   I watched that Paul Rubens documentary on HBO.
[00:16:05.820 --> 00:16:06.380]   Yeah.
[00:16:06.380 --> 00:16:08.020]   The guy who played Pee Wee.
[00:16:08.020 --> 00:16:08.460]   Yeah.
[00:16:08.460 --> 00:16:10.760]   I didn't realize that was a crazy show.
[00:16:10.760 --> 00:16:12.120]   I remember watching it on CBS.
[00:16:12.460 --> 00:16:15.740]   But what he was saying was, and it was like a brilliant like performance art show.
[00:16:15.740 --> 00:16:18.000]   Like you didn't realize it, you know, as a kid.
[00:16:18.000 --> 00:16:20.960]   He said back then, Saturday morning TV, anything went.
[00:16:20.960 --> 00:16:22.060]   No one cared.
[00:16:22.060 --> 00:16:22.940]   Really?
[00:16:22.940 --> 00:16:23.840]   No one was paying attention.
[00:16:23.840 --> 00:16:26.800]   And if you look back, I think about some of those cartoons we had growing up.
[00:16:26.800 --> 00:16:33.100]   It was like weird, trippy animation, like where they would save money.
[00:16:33.100 --> 00:16:35.700]   And like, it was just crazy, weird, like He-Man.
[00:16:35.700 --> 00:16:36.700]   That's a weird show.
[00:16:36.700 --> 00:16:41.680]   It's like a homoerotic toy commercial in a way that was like really strange.
[00:16:41.940 --> 00:16:43.800]   And we like, we, we love that stuff.
[00:16:43.800 --> 00:16:44.360]   Yeah.
[00:16:44.360 --> 00:16:45.760]   GI Joe cartoons.
[00:16:45.760 --> 00:16:46.560]   It was a toy commercial.
[00:16:46.560 --> 00:16:47.480]   I loved it.
[00:16:47.480 --> 00:16:50.360]   They shot lasers at each other and didn't really die.
[00:16:50.360 --> 00:16:52.320]   And everyone parachuted out of their plane when it got shot down.
[00:16:52.320 --> 00:16:56.700]   I mean, this was, it was weird stuff used to be, used to be on TV back then.
[00:16:56.700 --> 00:16:58.200]   But you know what?
[00:16:58.200 --> 00:16:59.620]   Pee Wee's Playhouse, interesting show.
[00:16:59.620 --> 00:17:04.160]   Which what I'm trying to say is we had it better, but phones, I think it's changing and
[00:17:04.160 --> 00:17:04.740]   I'm glad it is.
[00:17:04.740 --> 00:17:08.420]   I've been yelling about this for a while, but I'm glad people with a louder voice are being
[00:17:08.420 --> 00:17:08.720]   heard.
[00:17:08.780 --> 00:17:10.220]   So, you know, good for them.
[00:17:10.220 --> 00:17:11.360]   All right.
[00:17:11.360 --> 00:17:13.520]   We got some good questions to get into.
[00:17:13.520 --> 00:17:16.480]   But first, let's hear from one of our sponsors.
[00:17:16.480 --> 00:17:20.160]   Talk about our friends here at Cozy Earth, a product that I love.
[00:17:20.160 --> 00:17:22.820]   It's been on my mind recently because it's the Father's Day season.
[00:17:22.820 --> 00:17:23.860]   Father's Day was recently.
[00:17:23.860 --> 00:17:26.340]   Think about us dads for a second.
[00:17:26.340 --> 00:17:30.320]   You know, we, we're out there working hard, you know, doing our thing.
[00:17:30.520 --> 00:17:34.000]   It's nice to come back to our home and think of it like a sanctuary.
[00:17:34.000 --> 00:17:37.520]   And one way to make that happen is to have Cozy Earth.
[00:17:37.520 --> 00:17:38.960]   I love my Cozy Earth sheets.
[00:17:38.960 --> 00:17:42.920]   As I mentioned, we own three or four different pairs so we can have them on our bed and the
[00:17:42.920 --> 00:17:43.360]   guest bed.
[00:17:43.360 --> 00:17:45.400]   And when one pair is dirty, we can have another pair on.
[00:17:45.400 --> 00:17:46.840]   I missed them when I was on our trip.
[00:17:46.840 --> 00:17:50.360]   I have a Cozy Earth sweatshirt.
[00:17:50.360 --> 00:17:52.120]   We have Cozy Earth towels.
[00:17:52.120 --> 00:17:53.220]   I just love the fabric.
[00:17:53.220 --> 00:17:55.860]   It's, it's cooling, incredibly soft.
[00:17:55.860 --> 00:17:57.100]   It's the softest sheets I've had.
[00:17:57.600 --> 00:17:59.140]   It feels great on your skin.
[00:17:59.140 --> 00:18:01.760]   Anyways, it makes me feel nice to come back.
[00:18:01.760 --> 00:18:03.260]   Oh, I just got a new Cozy Earth thing.
[00:18:03.260 --> 00:18:03.980]   What'd you get?
[00:18:03.980 --> 00:18:04.440]   T-shirt.
[00:18:04.440 --> 00:18:05.500]   Oh.
[00:18:05.500 --> 00:18:05.900]   Yeah.
[00:18:05.900 --> 00:18:06.420]   Right?
[00:18:06.420 --> 00:18:08.720]   Because I had the sweatshirt, which is good for the winter.
[00:18:08.720 --> 00:18:10.460]   But for the summer, I got the T-shirt.
[00:18:10.460 --> 00:18:14.320]   The Cozy Earth fabric, like when you have the sheets, it's, it's kind of cooling somehow
[00:18:14.320 --> 00:18:14.920]   to the touch.
[00:18:14.920 --> 00:18:18.020]   So the T-shirt's great for like, if you're working out or something like that.
[00:18:18.020 --> 00:18:22.000]   I mean, it's a nice looking T-shirt, but it feels like cool, especially here in DC, where
[00:18:22.000 --> 00:18:25.600]   I believe the weather forecast the week this comes out is all the degrees.
[00:18:25.600 --> 00:18:26.880]   I think that's what they said.
[00:18:26.900 --> 00:18:28.320]   It's just going to be terrible.
[00:18:28.320 --> 00:18:30.020]   They have pants too.
[00:18:30.020 --> 00:18:32.740]   I mean, hey, fathers, dads, think about it.
[00:18:32.740 --> 00:18:34.480]   This stuff is nice.
[00:18:34.480 --> 00:18:37.100]   Makes your house like a sanctuary.
[00:18:37.100 --> 00:18:37.960]   I love it.
[00:18:37.960 --> 00:18:39.820]   You get a risk-free purchase when you buy it.
[00:18:39.820 --> 00:18:42.160]   Lifetime warranty and all apparel items.
[00:18:42.160 --> 00:18:45.020]   I own basically everything Cozy Earth has.
[00:18:45.020 --> 00:18:47.820]   So Cozy Earth makes comfort death that lasts.
[00:18:47.820 --> 00:18:52.000]   And when we're in this Father's Day season, think about Father's Day.
[00:18:52.080 --> 00:18:57.100]   Go to CozyEarth.com and use the code DEEP for up to 40% off all men's apparel.
[00:18:57.100 --> 00:19:02.960]   That's CozyEarth.com, code DEEP for the dads who work hard during the nine to five and deserve
[00:19:02.960 --> 00:19:06.500]   the best during their five to nine.
[00:19:06.500 --> 00:19:12.100]   I also want to talk about a new sponsor, our friends at Mack Weldon.
[00:19:12.100 --> 00:19:18.440]   It's summertime now in DC, which means it's often, and I'm checking my notes here, hotter
[00:19:18.440 --> 00:19:23.580]   than Hades outside and more humid than a swamp.
[00:19:24.100 --> 00:19:25.020]   I guess it is a swamp.
[00:19:25.020 --> 00:19:29.040]   So you need clothes that's comfortable, that looks good, but breathes and can deal with
[00:19:29.040 --> 00:19:29.400]   sweat.
[00:19:29.400 --> 00:19:31.780]   This is why I love Mack Weldon.
[00:19:31.780 --> 00:19:38.320]   I'm actually wearing right now Mack Weldon Performance boxers, which keep you cool and dry
[00:19:38.320 --> 00:19:39.780]   and comfy all day.
[00:19:39.780 --> 00:19:43.540]   I got rid of all of my boxers and replaced them with Mack Weldon.
[00:19:43.540 --> 00:19:44.780]   That's how much I like them.
[00:19:44.780 --> 00:19:46.900]   I've long owned Mack Weldon undershirts.
[00:19:46.900 --> 00:19:52.080]   I think for the heat of DC, especially when you have to wear like a suit to go brief Congress.
[00:19:52.760 --> 00:19:55.800]   This is like the only time I wear suits is to brief Congress and talk.
[00:19:55.800 --> 00:19:57.180]   This is not very relatable, is it?
[00:19:57.180 --> 00:20:01.600]   So if you're going to Congress to brief them on AI, Mack Weldon is what you need to wear.
[00:20:01.600 --> 00:20:04.880]   But if you're wearing a suit for whatever in hot weather, I love their undershirts.
[00:20:04.880 --> 00:20:08.460]   They're form fitting, like a knit material, very breathable, really works with the sweat
[00:20:08.460 --> 00:20:11.520]   very well, but they have good looking outerwear as well.
[00:20:11.520 --> 00:20:16.460]   They've got shirts, they've got polos, they've got hoodies, very good looking, but it's breathable
[00:20:16.460 --> 00:20:17.820]   material, performance material.
[00:20:18.700 --> 00:20:23.980]   You can think of it as what you need to stay cool, comfortable, and stylish regardless of
[00:20:23.980 --> 00:20:24.920]   the temperature.
[00:20:24.920 --> 00:20:29.460]   You can look confident without having to call attention to your clothes because Mack Weldon
[00:20:29.460 --> 00:20:33.800]   balances classic pieces and updated details to keep you looking sharp.
[00:20:33.800 --> 00:20:36.900]   They're designed to fit your style and the demands of modern life.
[00:20:36.900 --> 00:20:41.880]   They look like really nicely done regular clothes, but they're done with performance fabrics that
[00:20:41.880 --> 00:20:45.560]   can keep up with what's going on, especially during these hot weather months.
[00:20:45.560 --> 00:20:52.220]   So give your closet a breath of fresh air, go to MackWeldon.com and get 25% off your first
[00:20:52.220 --> 00:20:56.840]   order of $125 or more when you use the promo code DEEPQUESTIONS.
[00:20:56.840 --> 00:21:03.780]   That's M-A-C-K-W-E-L-D-O-N.com and use that promo code DEEPQUESTIONS.
[00:21:03.780 --> 00:21:04.840]   All right.
[00:21:04.840 --> 00:21:08.320]   Speaking of questions, Jesse, let's do some ourselves.
[00:21:10.240 --> 00:21:11.760]   First question is from Henry.
[00:21:11.760 --> 00:21:16.100]   I'm a mid-career academic and just signed my first book contract for law.
[00:21:16.100 --> 00:21:18.280]   I have a work office and a home office.
[00:21:18.280 --> 00:21:21.420]   However, I'm thinking I need to rent a separate space to really focus.
[00:21:21.420 --> 00:21:22.580]   Is this too extreme?
[00:21:22.580 --> 00:21:25.120]   I always support that idea.
[00:21:25.120 --> 00:21:29.820]   I mean, if you can afford it, and honestly, this is a good use of the book advance in my
[00:21:29.820 --> 00:21:30.140]   opinion.
[00:21:30.140 --> 00:21:32.980]   Having a separate deep workspace is great.
[00:21:33.080 --> 00:21:37.740]   And I think people underestimate the value of renting low-cost office space.
[00:21:37.740 --> 00:21:40.940]   Like if you live in a town, the office space, it's above certain stores.
[00:21:40.940 --> 00:21:46.720]   Or if there's a office tower in your town, like Tacoma Park has like a 10-story, the metro
[00:21:46.720 --> 00:21:48.080]   center office building.
[00:21:48.080 --> 00:21:52.660]   There's a lot of vacancies, especially for the small offices, especially post-COVID, right?
[00:21:52.660 --> 00:21:54.220]   Go rent an office.
[00:21:54.820 --> 00:21:58.740]   You know, shell out a few hundred dollars a month if you can afford it professionally
[00:21:58.740 --> 00:22:02.560]   and have a place you go just to do your deep work.
[00:22:02.560 --> 00:22:07.380]   I'm telling you, it's a completely different mental experience than being at your normal
[00:22:07.380 --> 00:22:07.840]   computer.
[00:22:07.840 --> 00:22:09.460]   You're filing cabinets open.
[00:22:09.460 --> 00:22:11.580]   There's piles of bills and papers next to you.
[00:22:11.580 --> 00:22:15.540]   You've just answered your 700th email of the day and you're like, all right, time to write.
[00:22:15.540 --> 00:22:18.100]   And then you just open up Microsoft Word and want to get going.
[00:22:18.100 --> 00:22:19.520]   That is painful.
[00:22:20.160 --> 00:22:26.020]   But when you can go to your dedicated space, the transition happens as you move to that
[00:22:26.020 --> 00:22:26.240]   space.
[00:22:26.240 --> 00:22:27.380]   There's no other distractions there.
[00:22:27.380 --> 00:22:29.140]   Your mind associates that space with deep work.
[00:22:29.140 --> 00:22:29.980]   It really works well.
[00:22:29.980 --> 00:22:35.220]   If you want more evidence for this, go back and see my 2020, maybe 2021.
[00:22:35.220 --> 00:22:40.180]   I think it's a 2020 article for The New Yorker called, I don't think the article is called,
[00:22:40.180 --> 00:22:45.220]   but the term I introduce is work from near home, WFNH.
[00:22:45.220 --> 00:22:50.460]   And I talk about how famous writers throughout history who had very nice homes to write out
[00:22:50.460 --> 00:22:55.020]   of would often go to various centric places to do their writing because having a new space
[00:22:55.020 --> 00:23:01.720]   was very important, even if the new space was objectively worse than just writing at their
[00:23:01.720 --> 00:23:02.040]   home.
[00:23:02.040 --> 00:23:04.580]   It's not about featured or non-featured.
[00:23:04.580 --> 00:23:07.280]   It's not about nice versus non-nice or aesthetic versus ugly.
[00:23:07.280 --> 00:23:09.880]   It's about cognitive clarity versus cognitive clutter.
[00:23:09.880 --> 00:23:13.640]   So if you can pull that off, Henry, I would spend every dime of that advance.
[00:23:13.640 --> 00:23:18.620]   If it's, you know, this is just a bonus on office space to write the book, the experience
[00:23:18.620 --> 00:23:19.340]   will go much better.
[00:23:19.340 --> 00:23:25.000]   I mean, I'm speaking this from our like office suite that we sort of like superposely maintain
[00:23:25.000 --> 00:23:27.880]   here, but I love having my separate office here.
[00:23:27.880 --> 00:23:29.700]   All right.
[00:23:29.700 --> 00:23:30.320]   Who we got next?
[00:23:30.320 --> 00:23:31.620]   Next up is Alex.
[00:23:31.620 --> 00:23:36.480]   How should I deal with context switching for AI assisted coding workflows that have built
[00:23:36.480 --> 00:23:37.400]   in waiting periods?
[00:23:37.840 --> 00:23:44.140]   So I think the context for this question on context is when you use AI coding tools and
[00:23:44.140 --> 00:23:50.100]   I had someone kind of demoed this for me not long ago, these models take some time, right?
[00:23:50.100 --> 00:23:54.620]   There's a lot of like it's doing stuff and you can kind of see it like answers and coming
[00:23:54.620 --> 00:23:59.820]   back to those answers, then code and checks to code, especially the more agentic models like
[00:23:59.820 --> 00:24:05.660]   you would get with like Rue code or some of the newer agentic coding models that don't
[00:24:05.660 --> 00:24:11.120]   just produce code for your specific thing you asked for, but figures out like what are the
[00:24:11.120 --> 00:24:15.020]   different pieces and then code each of those pieces and test the pieces and ask you questions
[00:24:15.020 --> 00:24:18.140]   about there's a lot of waiting, a lot of waiting while it's doing these queries.
[00:24:18.800 --> 00:24:22.100]   I would recommend keeping your cognitive context uncorrupted.
[00:24:22.100 --> 00:24:27.680]   So if you're waiting a minute here, 30 seconds here, four minutes here, if you go and introduce
[00:24:27.680 --> 00:24:31.660]   a new cognitive context unrelated to the project that you're working on, it really is going
[00:24:31.660 --> 00:24:35.880]   to make it harder to make, you know, focus on that when you come back to it, to look at
[00:24:35.880 --> 00:24:40.000]   whatever results that are produced by the AI to figure out what to do next or write that
[00:24:40.000 --> 00:24:43.240]   next prompt or answer the questions that the AI agent is asking you.
[00:24:43.240 --> 00:24:44.360]   It is going to be hard.
[00:24:44.360 --> 00:24:49.360]   If you check your phone, if you check email, these are just such diverse, unrelated cognitive
[00:24:49.360 --> 00:24:51.360]   context to the coding project you're working on.
[00:24:51.360 --> 00:24:53.240]   You're just going to destroy that cognitive context.
[00:24:53.240 --> 00:24:58.360]   So I would, in that situation, be looking at other things within your code to work on, adding
[00:24:58.360 --> 00:25:01.900]   comments to the code that was just in there, thinking about like what's going to come next,
[00:25:01.900 --> 00:25:05.600]   trying to make sense of like a past contribution.
[00:25:05.600 --> 00:25:08.760]   Keep your context pure, right?
[00:25:08.760 --> 00:25:12.080]   It's going to make a huge difference in how efficiently you make progress.
[00:25:12.080 --> 00:25:14.980]   It's also going to make a huge difference on how much cognitive drag you feel.
[00:25:14.980 --> 00:25:16.720]   It can be a really exhausting experience.
[00:25:16.720 --> 00:25:21.160]   If you're trying to work with an email check here, a phone check here, back and forth, it
[00:25:21.160 --> 00:25:22.620]   just is going to feel more draining.
[00:25:22.620 --> 00:25:26.300]   In addition to being less efficient, you're just going to be thinking, ah, this is really
[00:25:26.300 --> 00:25:26.680]   hard.
[00:25:26.680 --> 00:25:30.300]   But if you keep the cognitive context pure after 15 or 20 minutes, you're going to flow.
[00:25:31.640 --> 00:25:36.520]   So find things to do that are related to the project, even if they're not that interesting
[00:25:36.520 --> 00:25:38.640]   while you're waiting for the AI to get back to you.
[00:25:38.640 --> 00:25:42.380]   Do you get urges to check email when you're doing deep work?
[00:25:42.380 --> 00:25:50.000]   Um, yeah, I have to like news more or yeah.
[00:25:50.000 --> 00:25:52.720]   If like there's something interesting going on, I want to check in on.
[00:25:52.720 --> 00:25:54.420]   Or to check a text message or something.
[00:25:54.420 --> 00:25:55.060]   Yeah.
[00:25:55.060 --> 00:25:55.820]   Text messages.
[00:25:55.920 --> 00:25:57.480]   I don't work with my phone nearby often.
[00:25:57.480 --> 00:25:58.940]   I'm just bad at my text messages.
[00:25:58.940 --> 00:26:03.260]   Uh, but the other things I do get, I might get tempted to like, cause like, oh, there's
[00:26:03.260 --> 00:26:04.340]   like an interesting story unfolding.
[00:26:04.340 --> 00:26:05.000]   I want to do it.
[00:26:05.000 --> 00:26:08.040]   Or if there's someone who I think writes interesting things, I might want to see if they've written
[00:26:08.040 --> 00:26:11.080]   something interesting or like go over and check the New York times or something like that.
[00:26:11.080 --> 00:26:13.580]   That's why I like having separate spaces for deep work.
[00:26:13.580 --> 00:26:19.700]   Like I really want to try to separate away from my normal digital cognitive context.
[00:26:20.100 --> 00:26:23.400]   So if people are in a cube and they have their phone, should they just like put it in the
[00:26:23.400 --> 00:26:25.500]   bag or something or put it in like a little drawer?
[00:26:25.500 --> 00:26:25.880]   Yeah.
[00:26:25.880 --> 00:26:31.220]   Uh, or put it into a do not disturb mode where only calls from like your spouse or school
[00:26:31.220 --> 00:26:34.680]   will come through and then the ringer's on and then you can put it in your drawer or your
[00:26:34.680 --> 00:26:36.580]   bag and be like, Hey, if there's an emergency, it'll ring.
[00:26:36.580 --> 00:26:37.480]   Otherwise I don't use it.
[00:26:37.480 --> 00:26:38.320]   Clarity matters.
[00:26:38.320 --> 00:26:43.240]   As soon as you have to have a war with yourself, like I'm going to look at my phone occasionally
[00:26:43.240 --> 00:26:44.020]   throughout today.
[00:26:44.020 --> 00:26:47.420]   Like it's a porous line, but I'm going to try not to look at it that often.
[00:26:47.600 --> 00:26:50.900]   That is a terrible gauntlet you've just laid down for your brain because your brain's
[00:26:50.900 --> 00:26:52.000]   going to say, well, what about right now?
[00:26:52.000 --> 00:26:53.060]   Okay.
[00:26:53.060 --> 00:26:54.000]   Oh, what about now?
[00:26:54.000 --> 00:26:54.900]   Not now?
[00:26:54.900 --> 00:26:55.460]   What about now?
[00:26:55.460 --> 00:26:55.640]   Right?
[00:26:55.640 --> 00:26:58.600]   Like it's going to, you're going to have to fight with your brain every minute about why
[00:26:58.600 --> 00:26:58.900]   not now?
[00:26:58.900 --> 00:26:59.340]   Why not now?
[00:26:59.340 --> 00:26:59.880]   Why not now?
[00:26:59.880 --> 00:27:03.500]   You're going to lose that fight eventually probably within the next five or 10 minutes
[00:27:03.500 --> 00:27:06.380]   where if instead you just have this clear rule, I have a special do not disturb mode
[00:27:06.380 --> 00:27:07.740]   on I've time blocked.
[00:27:07.740 --> 00:27:09.020]   I'm doing this deep work for two hours.
[00:27:09.020 --> 00:27:10.720]   I'm not looking at my phone for those two hours.
[00:27:10.720 --> 00:27:11.680]   That's just the rule.
[00:27:11.680 --> 00:27:15.820]   The only thing I argue I'm going to have with my brain is do I agree with that rule or not?
[00:27:16.720 --> 00:27:19.500]   That is a much easier argument to win because it's binary.
[00:27:19.500 --> 00:27:20.920]   I agree with this rule or not.
[00:27:20.920 --> 00:27:25.220]   You can have the argument once and then you've had it and then you can move on and focus on
[00:27:25.220 --> 00:27:25.680]   what you're doing.
[00:27:25.680 --> 00:27:29.520]   So I think clarity really matters, especially when it comes to things like phones.
[00:27:29.520 --> 00:27:30.940]   All right.
[00:27:30.940 --> 00:27:31.400]   Who do we got?
[00:27:31.400 --> 00:27:33.100]   Next up is Tim.
[00:27:33.560 --> 00:27:37.380]   I have 11-year-old boys and they get a day planner to get organized.
[00:27:37.380 --> 00:27:41.600]   I thought this might be a perfect opportunity to start teaching them organizational habits.
[00:27:41.600 --> 00:27:42.680]   What should I teach them?
[00:27:42.680 --> 00:27:49.040]   Well, I mean, I think by 11 years old, you need your database-driven multi-scale planning
[00:27:49.040 --> 00:27:53.040]   probably through like a multi-view notion implemented time blocking schema.
[00:27:53.720 --> 00:28:00.340]   And if you don't have that, you will probably fail in our modern economy and die early.
[00:28:00.340 --> 00:28:01.360]   So there you go.
[00:28:01.360 --> 00:28:01.960]   11.
[00:28:01.960 --> 00:28:02.240]   Okay.
[00:28:02.240 --> 00:28:05.420]   I can speak to this because I have a 12-year-old and they do give them a day planner.
[00:28:05.420 --> 00:28:06.340]   So I understand this.
[00:28:07.200 --> 00:28:08.360]   Here's how I start.
[00:28:08.360 --> 00:28:09.440]   Here's what I'm doing with my own kid.
[00:28:09.440 --> 00:28:13.280]   When I think about that age group, like 11 or 12, it's like fifth, sixth grade.
[00:28:13.280 --> 00:28:19.820]   Dual direction calendar-based planning, that's probably the initial skill to pick up.
[00:28:19.820 --> 00:28:22.220]   So what do I mean by dual direction calendar-based planning?
[00:28:22.220 --> 00:28:28.780]   Well, it means when you sit down, let's say at the beginning of a marking period or at the
[00:28:28.780 --> 00:28:32.900]   beginning of a week, like whatever time period we're talking about, one direction you go is
[00:28:32.900 --> 00:28:34.380]   you look ahead.
[00:28:34.380 --> 00:28:36.780]   Hey, what's due this week?
[00:28:37.120 --> 00:28:38.260]   You know, what's coming up?
[00:28:38.260 --> 00:28:40.780]   Let's make sure we have time for that on the calendar.
[00:28:40.780 --> 00:28:44.080]   So you have a math test coming up.
[00:28:44.080 --> 00:28:47.320]   You have a draft of this is due on Friday.
[00:28:47.320 --> 00:28:48.320]   Great.
[00:28:48.320 --> 00:28:50.020]   When are you going to do the work for these things?
[00:28:50.020 --> 00:28:55.780]   So, you know, that's a looking forward to like the week ahead and making sure that like
[00:28:55.780 --> 00:28:58.860]   you see what you need to do that week and that you've chosen when you're going to do it.
[00:28:58.860 --> 00:29:00.920]   The workload for 11-year-olds is pretty easy.
[00:29:00.920 --> 00:29:03.720]   So this is like an easy exercise to win at.
[00:29:03.720 --> 00:29:06.700]   So it's not about trying to squeeze efficiency out of these.
[00:29:07.040 --> 00:29:09.080]   Should I do the work the night before or be fine?
[00:29:09.080 --> 00:29:13.200]   It's to get used to this idea of I look at what's coming up and make a plan for when I'm
[00:29:13.200 --> 00:29:14.080]   going to do that work.
[00:29:14.080 --> 00:29:15.200]   That's looking forward.
[00:29:15.200 --> 00:29:16.040]   Direction number one.
[00:29:16.040 --> 00:29:18.580]   Direction number two is looking back from big deadlines.
[00:29:18.580 --> 00:29:23.720]   And I suggest you do this at the beginning of a season or a marking period or a quarter,
[00:29:23.720 --> 00:29:25.320]   however they break it up at your kid's school.
[00:29:25.660 --> 00:29:29.400]   That's where you go much farther in the future and say, what are big things that are coming
[00:29:29.400 --> 00:29:29.680]   up?
[00:29:29.680 --> 00:29:34.960]   And let's now work backwards from those and make sure we've marked in our calendar when
[00:29:34.960 --> 00:29:36.320]   we have to start thinking about them.
[00:29:36.320 --> 00:29:41.420]   Like, oh, there's this big fifth grade, your first research paper.
[00:29:42.200 --> 00:29:44.200]   And it's going to, we're going to start working on it.
[00:29:44.200 --> 00:29:48.600]   It's going to be due at the end of May or something like, great, let's go back and put a note here
[00:29:48.600 --> 00:29:50.080]   in April.
[00:29:50.080 --> 00:29:51.620]   Like, hey, start working on this.
[00:29:51.620 --> 00:29:57.820]   Or, you know, there's a big baseball tryout for like a travel team coming up.
[00:29:57.820 --> 00:30:01.880]   You're like, okay, so we really want to be practicing three times a week for a month ahead
[00:30:01.880 --> 00:30:03.000]   to kind of get sharp for it.
[00:30:03.040 --> 00:30:07.980]   Let's go now, work backwards a month before that deadline and put those things on the calendar.
[00:30:07.980 --> 00:30:12.360]   So you look forward to like the near future and make a plan for the things that's due.
[00:30:12.360 --> 00:30:17.840]   And you work backwards from the big things to make sure that when you get closer to those
[00:30:17.840 --> 00:30:20.840]   things, your calendar tells you like, hey, start thinking about this.
[00:30:20.840 --> 00:30:23.520]   So that gets you used to much more sort of long range forecasting.
[00:30:23.520 --> 00:30:24.940]   Oh, this thing's happening in two months.
[00:30:24.940 --> 00:30:26.860]   A month from now, I'm going to want to start working on it.
[00:30:26.860 --> 00:30:30.900]   And it's sort of like magic to see these things work, right?
[00:30:31.460 --> 00:30:35.160]   Again, it's not that anything that the 11-year-old is doing requires this.
[00:30:35.160 --> 00:30:38.840]   It's just the magic of seeing, oh, when I make a plan for my week ahead, I'm not stressed
[00:30:38.840 --> 00:30:39.420]   on Wednesday.
[00:30:39.420 --> 00:30:42.140]   I just know what to do and the stuff gets done and I get good grades.
[00:30:42.140 --> 00:30:43.020]   I don't have to think about it.
[00:30:43.020 --> 00:30:46.880]   Oh, I see if there's like something big that I want to do well on.
[00:30:46.880 --> 00:30:50.840]   If I work backwards from that deadline, hey, it may be in the moment like, wow, am I really
[00:30:50.840 --> 00:30:51.840]   going to work on this today?
[00:30:51.840 --> 00:30:54.040]   Like, this isn't even on my radar.
[00:30:54.040 --> 00:30:57.180]   This thing is not even due for a month, but I guess I'm going to work on it today because
[00:30:57.180 --> 00:30:58.820]   I made a plan working backwards from the deadline.
[00:30:58.820 --> 00:31:00.960]   And then when that goes really well, you're like, oh, that works well too.
[00:31:00.960 --> 00:31:05.240]   Those two things, when you get to high school, now they're important.
[00:31:05.240 --> 00:31:05.820]   Now it's killer.
[00:31:05.820 --> 00:31:09.780]   People who make a plan for their week ahead and work backwards from major paper and test
[00:31:09.780 --> 00:31:11.800]   deadlines, they don't get stressed out.
[00:31:11.800 --> 00:31:13.160]   They get really good grades.
[00:31:13.160 --> 00:31:15.200]   When you bring that to college, it's like a superpower.
[00:31:15.200 --> 00:31:20.300]   People think like, okay, you can probably move things, physical objects, just with the power
[00:31:20.300 --> 00:31:20.800]   of your mind.
[00:31:20.800 --> 00:31:25.340]   Because everyone else is just stumbling around trying to get this work done at 3 a.m.
[00:31:25.340 --> 00:31:27.340]   the day before two term papers are done.
[00:31:27.340 --> 00:31:30.880]   But you, at the beginning of your semester, work backwards from those deadlines and realize
[00:31:30.880 --> 00:31:34.220]   you needed to start them about a month ahead of time and alternate week by week between
[00:31:34.220 --> 00:31:36.200]   them to really get that done in a reasonable time frame.
[00:31:36.200 --> 00:31:37.680]   And you did, and it wasn't so bad.
[00:31:37.680 --> 00:31:43.080]   So that's the key skill I would teach a student at exactly that age.
[00:31:43.080 --> 00:31:46.200]   Looking forward to the week ahead, working backwards from major events in their life that
[00:31:46.200 --> 00:31:47.220]   they want to be prepared for.
[00:31:47.220 --> 00:31:48.840]   Just kind of get them used to that muscle.
[00:31:48.840 --> 00:31:50.000]   Yeah.
[00:31:50.080 --> 00:31:51.040]   And it makes a big difference.
[00:31:51.040 --> 00:31:53.140]   So I think they'll appreciate that.
[00:31:53.140 --> 00:31:54.540]   All right.
[00:31:54.540 --> 00:31:55.020]   Who do we got?
[00:31:55.020 --> 00:31:56.380]   Next up is Jason.
[00:31:56.380 --> 00:32:01.780]   I wonder if you have any recommendations for the soft side, the soft skills side of careers.
[00:32:01.780 --> 00:32:05.760]   I hear it time and time again that these skills are every bit, if not more important than
[00:32:05.760 --> 00:32:06.740]   technical skills.
[00:32:06.740 --> 00:32:09.420]   I don't know if that's entirely true.
[00:32:10.100 --> 00:32:14.480]   Now, let me say, first of all, my answer is biased because I come out of the computer
[00:32:14.480 --> 00:32:21.900]   science world and let's just say computer scientists aren't known as nuanced, scintillating
[00:32:21.900 --> 00:32:25.700]   conversationalists that try to be sort of nice about it.
[00:32:25.700 --> 00:32:29.900]   Some of us are technical, if that makes sense.
[00:32:29.900 --> 00:32:37.720]   We're not exactly, we're not the life of the party where the people making like very precise
[00:32:37.720 --> 00:32:41.620]   observations about the room in which the party is being held in a way that makes the host
[00:32:41.620 --> 00:32:42.800]   eventually say like, okay, great.
[00:32:42.800 --> 00:32:43.580]   Yeah, I get it.
[00:32:43.580 --> 00:32:43.840]   Okay.
[00:32:43.840 --> 00:32:44.120]   Yes.
[00:32:44.120 --> 00:32:45.580]   The lights are not an optimal pattern.
[00:32:45.580 --> 00:32:46.620]   I need to get back to my guest.
[00:32:46.620 --> 00:32:47.400]   That's computer scientists.
[00:32:47.400 --> 00:32:51.120]   So I'm from a world where soft skills don't necessarily go a huge way.
[00:32:51.120 --> 00:32:51.940]   Yes.
[00:32:51.940 --> 00:32:52.760]   You don't want to be a jerk.
[00:32:52.760 --> 00:33:00.820]   You want to be like a, like a nice person, but what really matters two things, and these
[00:33:00.820 --> 00:33:07.220]   are more important than soft skills, like being very personable, being, um,
[00:33:07.220 --> 00:33:12.040]   someone who like people really get along with, like you're really friendly to people, um,
[00:33:12.040 --> 00:33:13.060]   good networker.
[00:33:13.060 --> 00:33:15.120]   Here's what's more important first.
[00:33:15.120 --> 00:33:17.220]   And this is what you have to pick up right away in a new job.
[00:33:17.220 --> 00:33:18.780]   You need to be reliable.
[00:33:18.780 --> 00:33:20.680]   You don't drop the ball.
[00:33:20.680 --> 00:33:22.480]   If someone asks you to do something that gets done.
[00:33:22.480 --> 00:33:25.100]   And if you're not going to get it done in time, you let them know that it's not going
[00:33:25.100 --> 00:33:25.700]   to get done in time.
[00:33:25.700 --> 00:33:28.020]   And when it is going to get done, and then you deliver on that new date.
[00:33:28.020 --> 00:33:31.540]   People don't have to think about it after they hand something to you.
[00:33:31.540 --> 00:33:33.520]   They know you're reliable early on in your career.
[00:33:33.520 --> 00:33:35.280]   That's much more important than being personable.
[00:33:35.280 --> 00:33:36.660]   That's much more important than networking.
[00:33:36.660 --> 00:33:39.320]   That's much more important than, Hey, that's a really great guy.
[00:33:39.320 --> 00:33:42.380]   You can be weird, but you need to be reliable.
[00:33:42.380 --> 00:33:43.400]   That's incredibly valuable.
[00:33:43.400 --> 00:33:47.320]   This person will do the things I tell them to do.
[00:33:47.320 --> 00:33:47.740]   They'll do it.
[00:33:47.740 --> 00:33:49.620]   Well, they'll do it in a reasonable amount of time.
[00:33:49.620 --> 00:33:50.280]   I can trust them.
[00:33:50.280 --> 00:33:56.140]   Then two, so that you can do right away to it's career capital, rare and valuable skills.
[00:33:56.700 --> 00:34:02.460]   I can do this thing well that a lot of people can't, but it's valuable to you in our organization.
[00:34:02.460 --> 00:34:04.160]   That's what moves things.
[00:34:04.160 --> 00:34:08.300]   There's a lot of weird people in business, right?
[00:34:08.300 --> 00:34:12.600]   You're like, I don't know if I want to take a five hour train ride with that person there.
[00:34:12.660 --> 00:34:23.540]   I might get a long, you know, inquisition about the relative merits of Star Trek, deep space nine versus TNG, the next generation.
[00:34:23.540 --> 00:34:24.300]   Right.
[00:34:24.300 --> 00:34:25.760]   And it's going to be a long conversation.
[00:34:26.300 --> 00:34:31.200]   And, um, I don't want to hear about the gravity simulation on the space station DS nine.
[00:34:31.200 --> 00:34:31.760]   Right.
[00:34:31.760 --> 00:34:38.320]   But they are really good at a particular type of compliance law.
[00:34:38.320 --> 00:34:39.960]   They really understand it.
[00:34:39.960 --> 00:34:42.260]   It makes a whole HR system function.
[00:34:42.260 --> 00:34:43.920]   We'd be lost without them.
[00:34:43.920 --> 00:34:45.000]   And they're reliable.
[00:34:45.000 --> 00:34:46.120]   I don't care.
[00:34:46.120 --> 00:34:52.020]   They can wear their cork fake forehead or whatever cork or big ears.
[00:34:52.020 --> 00:34:52.420]   I don't know.
[00:34:52.420 --> 00:34:52.760]   Star Trek.
[00:34:52.760 --> 00:34:55.160]   Well, Jesse, I'm trying, I'm trying.
[00:34:55.160 --> 00:34:55.560]   I don't know.
[00:34:55.560 --> 00:34:56.660]   I'm just laughing over here.
[00:34:56.660 --> 00:34:57.860]   I think there's a character.
[00:34:57.860 --> 00:34:59.400]   I think Whoopi Goldberg was in this show.
[00:34:59.400 --> 00:35:00.620]   She's like a bartender.
[00:35:00.620 --> 00:35:03.080]   And there's like a character who had on like a goblin face.
[00:35:03.080 --> 00:35:04.040]   I don't know.
[00:35:04.040 --> 00:35:05.520]   I guess there's monsters in space.
[00:35:05.520 --> 00:35:07.540]   I don't understand these shows very much, but you know what I'm saying?
[00:35:07.540 --> 00:35:08.620]   That's okay.
[00:35:08.620 --> 00:35:12.240]   If I have rare and valuable skills, right?
[00:35:12.240 --> 00:35:14.960]   I have rare and valuable skills and I'm reliable.
[00:35:14.960 --> 00:35:16.140]   That's what really matters.
[00:35:16.140 --> 00:35:20.540]   Don't be a jerk and don't be unethical, but it's okay.
[00:35:20.540 --> 00:35:22.140]   If you're not super personable, it's okay.
[00:35:22.140 --> 00:35:25.060]   If you're introverted versus extroverted, it's okay.
[00:35:25.060 --> 00:35:27.440]   If you're not a great glad hander, you're not the life of the party.
[00:35:27.440 --> 00:35:32.180]   Those are the things, reliability and career capital that moves your career along.
[00:35:32.180 --> 00:35:35.040]   And I think that's, that's going to be the thing that really matters.
[00:35:35.040 --> 00:35:37.040]   All right.
[00:35:37.040 --> 00:35:37.500]   Who we got?
[00:35:37.500 --> 00:35:38.220]   Okay.
[00:35:38.220 --> 00:35:39.940]   By the way, can I say, well, here's one thing about computer science.
[00:35:39.940 --> 00:35:43.600]   Here's the worst thing about, I love computer scientists as my people, but here's the worst
[00:35:43.600 --> 00:35:44.180]   thing about them.
[00:35:44.440 --> 00:35:48.280]   If you're ever at like a con I used to go to a lot of conferences, the worst thing I think
[00:35:48.280 --> 00:35:51.420]   computer scientists will agree is you have a group of group of us get together.
[00:35:51.420 --> 00:35:52.240]   All right.
[00:35:52.240 --> 00:35:53.060]   We're going to go out to dinner.
[00:35:54.400 --> 00:36:00.840]   That decision-making process, endless, endless, they're algorithmic thinkers.
[00:36:00.840 --> 00:36:02.120]   There's like an optimal choice.
[00:36:02.120 --> 00:36:03.460]   We need to figure out the right algorithm.
[00:36:03.460 --> 00:36:04.280]   It like goes around.
[00:36:04.280 --> 00:36:05.460]   No one wants to commit to it.
[00:36:05.700 --> 00:36:11.720]   I once met up with, oh God, it wasn't Ramit Sethi, it was his brother Manish.
[00:36:11.720 --> 00:36:16.700]   I was in Rio, person's in a paper at a computer science conference.
[00:36:16.700 --> 00:36:22.720]   And he was there doing like lifestyle design, Tim Ferriss stuff, like dancing and what do
[00:36:22.720 --> 00:36:23.160]   they call it?
[00:36:23.160 --> 00:36:23.700]   Carnival.
[00:36:23.700 --> 00:36:27.180]   I was like, oh, come out, come meet us at the resort.
[00:36:27.180 --> 00:36:27.860]   Let's go out to dinner.
[00:36:27.860 --> 00:36:32.080]   And he was so fed up with the group of us trying to make a decision.
[00:36:32.080 --> 00:36:34.160]   He was finally like, we're just going.
[00:36:34.160 --> 00:36:35.240]   And he was like, let's go.
[00:36:35.240 --> 00:36:38.320]   And he just left because he was like a normal person and we were computer scientists.
[00:36:38.320 --> 00:36:39.740]   That's okay.
[00:36:39.740 --> 00:36:40.820]   We do very useful stuff.
[00:36:40.820 --> 00:36:42.440]   That's the same.
[00:36:42.440 --> 00:36:45.220]   And we all do well for ourselves because we're good at very specific things that's useful
[00:36:45.220 --> 00:36:45.660]   to the world.
[00:36:45.660 --> 00:36:47.040]   All right.
[00:36:47.040 --> 00:36:48.960]   What do we got?
[00:36:48.960 --> 00:36:50.580]   Next up is Cindy.
[00:36:50.580 --> 00:36:53.800]   My husband is struggling to find meaningful work.
[00:36:53.800 --> 00:36:58.680]   He feels very behind in his career and ultimately wants to make cool things with cool people.
[00:36:58.680 --> 00:37:03.460]   He has his bachelor's degree in English and economics and has worked so far in data analysis
[00:37:03.460 --> 00:37:05.040]   and proofreading, editing roles.
[00:37:05.040 --> 00:37:09.380]   His strengths are finding design flaws in everyday things and telling stories in compelling
[00:37:09.380 --> 00:37:10.000]   ways.
[00:37:10.000 --> 00:37:13.500]   I mean, Cindy, I think these things you're describing are too vague.
[00:37:13.500 --> 00:37:17.560]   Finding the design while telling stories in compelling ways, make cool things with cool
[00:37:17.560 --> 00:37:17.960]   people.
[00:37:17.960 --> 00:37:18.940]   It's career capital.
[00:37:18.940 --> 00:37:20.640]   What do you do that's rare and valuable?
[00:37:20.640 --> 00:37:22.360]   I can do this thing.
[00:37:22.360 --> 00:37:23.940]   It's valuable to you as an organization.
[00:37:23.940 --> 00:37:25.700]   It's hard to find people who can do it.
[00:37:26.760 --> 00:37:28.020]   You get a job, you get autonomy.
[00:37:28.020 --> 00:37:32.960]   That's the way to think about it is career capital.
[00:37:32.960 --> 00:37:33.900]   Where is my career capital?
[00:37:33.900 --> 00:37:34.720]   How do I get better?
[00:37:34.720 --> 00:37:39.560]   A lot of this sounds more like you're identifying what I want out of a job versus what I'm offering
[00:37:39.560 --> 00:37:40.080]   to the job.
[00:37:40.080 --> 00:37:42.760]   And when you make that mindset switch, it really opens things up.
[00:37:42.760 --> 00:37:44.900]   What can I offer to the world of work?
[00:37:45.720 --> 00:37:47.100]   And how can I make that more compelling?
[00:37:47.100 --> 00:37:51.640]   That's the right way to think about it when you're working for work, not what do I need
[00:37:51.640 --> 00:37:52.300]   in my job?
[00:37:52.300 --> 00:37:56.340]   Because when you build up that career capital, this is the argument in my book, So Good They
[00:37:56.340 --> 00:37:56.920]   Can't Ignore You.
[00:37:57.000 --> 00:38:00.840]   When you build up that career capital, that's what gives you the control and autonomy in
[00:38:00.840 --> 00:38:06.760]   your career to start putting in place over time the things you like, the making cool things
[00:38:06.760 --> 00:38:10.760]   with cool people or having more storytelling in your work.
[00:38:10.760 --> 00:38:15.020]   That's cool attributes you earn by having more career capital.
[00:38:15.020 --> 00:38:19.160]   The second thing I would say here is to throw in that I'm going to introduce a new term here,
[00:38:19.160 --> 00:38:19.380]   Justin.
[00:38:19.380 --> 00:38:20.640]   You're going to have to tell me if you like it or not.
[00:38:20.640 --> 00:38:23.640]   So I talk a lot about lifestyle-centric planning.
[00:38:23.640 --> 00:38:26.820]   I have an alternative term I'm playing with for this.
[00:38:26.820 --> 00:38:29.420]   As I'm working on my book, you got to tell me.
[00:38:29.420 --> 00:38:31.060]   Lifestyle engineering.
[00:38:31.060 --> 00:38:35.240]   In addition to the other term or replace it?
[00:38:35.240 --> 00:38:36.600]   Maybe long-term as a replacement.
[00:38:36.600 --> 00:38:37.940]   What are we going to do with the hats?
[00:38:37.940 --> 00:38:40.020]   VBLCCP.
[00:38:40.020 --> 00:38:46.640]   Well, I mean, there's literally twos of people who have those hats in the world right now.
[00:38:46.640 --> 00:38:50.840]   So yeah, if we change that, it would be a problem.
[00:38:50.840 --> 00:38:56.200]   Here's why I'm liking this term lifestyle engineering, because maybe it's a clearer way of getting
[00:38:56.200 --> 00:39:00.360]   at what I mean by lifestyle-centric planning, which is you're engineering a lifestyle by
[00:39:00.360 --> 00:39:03.720]   looking at the various pieces involved and what you're – like, what is the structure I'm
[00:39:03.720 --> 00:39:04.400]   trying to build here?
[00:39:04.400 --> 00:39:08.200]   And you sort of build it sort of systematically, solving some problems and building new structures.
[00:39:08.200 --> 00:39:12.500]   So I think of it as – like, lifestyle design is more exotic.
[00:39:12.500 --> 00:39:16.540]   Like, what do I want in my – you know, it's like I want to go live in Rio like Manish was
[00:39:16.540 --> 00:39:16.740]   doing.
[00:39:16.740 --> 00:39:19.380]   Lifestyle engineering is more my sort of systematic approach.
[00:39:19.380 --> 00:39:21.560]   What are the things I want in my ideal lifestyle?
[00:39:21.640 --> 00:39:24.440]   What's my sort of specs for my project here?
[00:39:24.440 --> 00:39:27.340]   Now, how do I build something that matches the specs?
[00:39:27.340 --> 00:39:29.140]   I can be very creative in how I do this.
[00:39:29.140 --> 00:39:32.300]   And there might be all sorts of different configurations of parts that makes this work.
[00:39:32.300 --> 00:39:35.860]   So you want to get really good at things that are very invaluable, and you want to think about
[00:39:35.860 --> 00:39:37.640]   this in a lifestyle engineering context.
[00:39:37.640 --> 00:39:39.340]   Not in a, like, let me just zone in.
[00:39:39.340 --> 00:39:43.920]   Like, I – to be happy, I need a job that is cool, and I can work with cool people on making
[00:39:43.920 --> 00:39:44.440]   cool things.
[00:39:44.440 --> 00:39:48.660]   It's no, I have a spec for my ideal lifestyle that I'm trying to engineer towards.
[00:39:48.660 --> 00:39:52.660]   My job is going to be a big piece of it, but there's other pieces I'm working on.
[00:39:52.660 --> 00:39:56.400]   And when I think of my job as just, like, one of the components I'm using to build this
[00:39:56.400 --> 00:39:57.820]   lifestyle, it takes the pressure off.
[00:39:57.820 --> 00:40:03.020]   And at first, it might be this allows us to live here and provides this much income, which
[00:40:03.020 --> 00:40:04.140]   makes these other things possible.
[00:40:04.140 --> 00:40:04.620]   Great.
[00:40:04.620 --> 00:40:06.700]   Our contraption here is getting closer to my spec.
[00:40:06.700 --> 00:40:09.200]   The job – the things I'm doing in the job, maybe who cares?
[00:40:09.620 --> 00:40:14.040]   But then stage two, I'm going to take this thing from this job, and I'm going to put
[00:40:14.040 --> 00:40:17.040]   an hour every morning before I get started deliberate practicing, getting really good
[00:40:17.040 --> 00:40:17.300]   at that.
[00:40:17.300 --> 00:40:21.180]   That career capital then is going to allow me to change this job to this, which increases
[00:40:21.180 --> 00:40:25.060]   the money, keeps the location, but now shifts what I'm doing on this job to have less of
[00:40:25.060 --> 00:40:26.820]   this thing I don't like and more of this thing I do like.
[00:40:26.820 --> 00:40:33.360]   And so you're building up a structure that is closer and closer to your spec.
[00:40:33.360 --> 00:40:35.900]   So you've got to really respect career capital.
[00:40:35.900 --> 00:40:38.920]   What can I offer the job world more than what my job offers me?
[00:40:39.280 --> 00:40:45.340]   And you see your job as part of a larger lifestyle engineering project and not as the underlying
[00:40:45.340 --> 00:40:49.180]   the solution for your life to be meaningful or not.
[00:40:49.180 --> 00:40:54.500]   When you have a family, you're married like you are here, the spec for your ideal lifestyle
[00:40:54.500 --> 00:40:58.100]   is going to have a lot of facets to it that are influenced by your job and not all about
[00:40:58.100 --> 00:41:00.660]   what specifically happens with your job when you're there.
[00:41:00.660 --> 00:41:03.780]   The book recommendation I'm going to make is So Good They Can't Ignore You.
[00:41:03.780 --> 00:41:07.380]   Cindy, I think that's the right book to read and maybe it will give some ideas.
[00:41:07.480 --> 00:41:10.400]   So I think a lot of this is sort of passion hypothesis stuff, just sort of gussied up
[00:41:10.400 --> 00:41:11.100]   without that word.
[00:41:11.100 --> 00:41:16.240]   I mean, the more you're talking about like what abstract traits I want my job to offer
[00:41:16.240 --> 00:41:19.560]   when you're looking for a job and less like what am I offering and how can that be more
[00:41:19.560 --> 00:41:22.380]   valuable, the more likely you are, I think, to get in this own trouble.
[00:41:22.380 --> 00:41:24.640]   All right.
[00:41:24.640 --> 00:41:25.500]   All right.
[00:41:25.500 --> 00:41:28.320]   We've got a final segment coming up, a what should I read segment.
[00:41:28.320 --> 00:41:29.240]   I want to tell you about a book.
[00:41:30.380 --> 00:41:31.200]   Oh, we have a call.
[00:41:31.200 --> 00:41:31.460]   Yep.
[00:41:31.460 --> 00:41:32.060]   Ooh.
[00:41:32.060 --> 00:41:32.440]   All right.
[00:41:32.440 --> 00:41:33.240]   I take it back.
[00:41:33.240 --> 00:41:35.100]   We have a call first before we get there.
[00:41:35.100 --> 00:41:36.360]   Jessie, let's hear this call.
[00:41:36.360 --> 00:41:38.740]   Hey, Cal.
[00:41:38.740 --> 00:41:39.520]   This is Denise.
[00:41:39.520 --> 00:41:44.220]   First, I want to thank you for everything I've learned from you, your podcast and your books.
[00:41:44.220 --> 00:41:49.940]   It's really helped me make sense out of my work life and also helped me plan as I look
[00:41:49.940 --> 00:41:53.020]   ahead to my upcoming retirement, which is exciting.
[00:41:53.020 --> 00:41:59.120]   I wanted to ask a question as to why when you're talking about making a text file and keeping
[00:41:59.120 --> 00:42:03.400]   your notes online, you never talk about keeping notes by hand.
[00:42:03.400 --> 00:42:10.900]   I'm really excited by the hand to brain connection and how many of our emotions and memories are
[00:42:10.900 --> 00:42:12.760]   triggered when we're taking notes by hand.
[00:42:12.760 --> 00:42:15.040]   I wondered if you could comment on this.
[00:42:15.040 --> 00:42:22.240]   I'm a journaler and love to draw and write what I see in nature or just personally and
[00:42:22.240 --> 00:42:24.160]   just interested in your opinion on that.
[00:42:24.160 --> 00:42:26.300]   Many thanks to you and also to Jesse.
[00:42:26.300 --> 00:42:28.800]   All right, Denise.
[00:42:28.800 --> 00:42:34.220]   Well, when it comes to handwriting notes, there are some I do and there's some I don't.
[00:42:34.220 --> 00:42:37.240]   So let me get into the distinction between the two because I also like handwriting things.
[00:42:37.240 --> 00:42:40.240]   I prefer it when I can do it.
[00:42:40.300 --> 00:42:41.660]   I like that connection to it.
[00:42:41.660 --> 00:42:44.460]   I have a couple of different tools I use for that, which I'll get into in a second.
[00:42:44.460 --> 00:42:50.100]   Where I use my digital file, my working memory dot TXT plain text unformatted file is for
[00:42:50.100 --> 00:42:54.540]   really taming and organizing the incoming of my day-to-day knowledge work.
[00:42:54.540 --> 00:42:59.820]   My email inbox, things that are showing up in meetings, things that I remember on the fly.
[00:42:59.820 --> 00:43:06.080]   The volume and details of this work is so significant that trying to track it on paper
[00:43:06.080 --> 00:43:10.320]   manually would be hopelessly inefficient, right?
[00:43:10.320 --> 00:43:15.780]   Because if I'm trying to empty my email inbox, for example, I'm going to go from email to
[00:43:15.780 --> 00:43:19.060]   descriptions of the relevant tasks in that text file.
[00:43:19.060 --> 00:43:22.800]   Then I'm going to organize that, throw out stuff I can ignore, consolidate things in the
[00:43:22.800 --> 00:43:23.540]   task that makes sense.
[00:43:23.600 --> 00:43:25.660]   It's like, oh, these four things all involve Jesse.
[00:43:25.660 --> 00:43:29.720]   Why don't I put these all here as like things to ask Jesse when I see him on Thursday, I'm going
[00:43:29.720 --> 00:43:32.460]   to put these all together and then I can move those over in the task.
[00:43:32.460 --> 00:43:37.920]   It's so much information is being typed, erased, and reorganized and edited.
[00:43:38.880 --> 00:43:39.820]   I need to be typing.
[00:43:39.820 --> 00:43:43.760]   I'm much faster typing than writing and it'd be way too much like crossing out, for example.
[00:43:43.760 --> 00:43:48.860]   So just in the flow of the fire hose of obligations and thoughts that fills like my knowledge work
[00:43:48.860 --> 00:43:52.360]   roles, my traditional knowledge work roles, work in memory.txt.
[00:43:52.360 --> 00:43:58.700]   However, I handwrite almost anything that's going to be brainstorming or long-term planning.
[00:43:58.700 --> 00:44:00.280]   I'm often using handwriting.
[00:44:00.440 --> 00:44:07.020]   I'm either using my Remarkable Pro notebook, which has within it 50 different notebooks
[00:44:07.020 --> 00:44:10.760]   that I use for books and article ideas and ideas about my life.
[00:44:10.760 --> 00:44:12.420]   There's all these notebooks in here.
[00:44:12.420 --> 00:44:13.780]   You write on the Remarkable surface.
[00:44:13.780 --> 00:44:17.740]   The Remarkable Pro is a fantastic product and it really does feel like real paper.
[00:44:17.740 --> 00:44:21.700]   I like to draw and circle and the Pro has colors.
[00:44:21.700 --> 00:44:26.160]   I highlight with different colors and draw boxes around things and I use that for planning.
[00:44:26.160 --> 00:44:29.140]   I also then use single-purpose notebooks, fields notes, notebooks.
[00:44:29.420 --> 00:44:34.480]   If there's a particular project, like I brought one with me just to work on a particular part
[00:44:34.480 --> 00:44:38.580]   of my new book when I was on my trip, I'll bring this one notebook with me that all I do
[00:44:38.580 --> 00:44:40.240]   with it is collect notes on this one thing.
[00:44:40.240 --> 00:44:47.320]   So if it's a generative thinking that's not particularly time-sensitive, I do prefer to
[00:44:47.320 --> 00:44:47.720]   handwrite.
[00:44:47.720 --> 00:44:49.940]   So it's just about knowing when you would do it.
[00:44:49.940 --> 00:44:53.800]   So thinking, planning, low time sensitivity, handwriting is fine.
[00:44:55.020 --> 00:45:00.060]   In the mix of it, like my knowledge workflow, get the fastest possible thing, which to me
[00:45:00.060 --> 00:45:00.760]   is like typing.
[00:45:00.760 --> 00:45:01.840]   How fast can I type?
[00:45:01.840 --> 00:45:02.520]   No formatting.
[00:45:02.520 --> 00:45:04.180]   Forget the spelling.
[00:45:04.180 --> 00:45:08.980]   I'll just format with asterisks and dashes for bullet points and sub-bullet points and
[00:45:08.980 --> 00:45:10.140]   let's just get information on there.
[00:45:10.140 --> 00:45:13.260]   So it just depends on the speed and volume of information that you're dealing with.
[00:45:14.420 --> 00:45:20.380]   All right, now we're ready for a final segment, the what to read segment.
[00:45:20.380 --> 00:45:21.680]   We're going to talk about a book I read on my trip.
[00:45:21.680 --> 00:45:25.080]   But first, let's hear briefly from another sponsor.
[00:45:25.080 --> 00:45:28.720]   So guys, wouldn't you like to look a little bit younger?
[00:45:28.720 --> 00:45:32.700]   Maybe get a few more compliments on your skin or feel more confident when you look in the
[00:45:32.700 --> 00:45:32.860]   mirror.
[00:45:32.980 --> 00:45:36.220]   That's exactly what Caldera Lab is here for.
[00:45:36.220 --> 00:45:39.680]   Their high-performance skincare is designed specifically for men.
[00:45:39.680 --> 00:45:43.660]   Simple, effective, and backed by science.
[00:45:43.660 --> 00:45:44.520]   Here's the thing.
[00:45:44.520 --> 00:45:49.780]   Men don't realize this until they get closer to middle age that like, oh, you really do need
[00:45:49.780 --> 00:45:51.200]   to put stuff on your skin.
[00:45:51.200 --> 00:45:53.100]   When you're 26, it doesn't matter.
[00:45:53.100 --> 00:45:58.940]   You're just doing splits and pounding kegs before you run marathons or whatever people do
[00:45:58.940 --> 00:45:59.500]   in their 20s.
[00:45:59.500 --> 00:46:03.540]   But there's this point, like as you approach these 40s, where you go to bed like that one
[00:46:03.540 --> 00:46:09.140]   day and then you wake up the next day and basically look like, you know, the grizzled pirate from
[00:46:09.140 --> 00:46:09.740]   a Disney movie.
[00:46:09.740 --> 00:46:17.380]   And people keep asking you if they can be a harpooner on your upcoming whaling voyage to
[00:46:17.380 --> 00:46:18.060]   the Arctic Ocean.
[00:46:18.060 --> 00:46:20.860]   And you have one eye that's kind of closed.
[00:46:20.860 --> 00:46:25.220]   You probably have an eye patch on and you look like 98 years old.
[00:46:25.220 --> 00:46:28.180]   It just kind of happens if you're not taking care of your skin.
[00:46:28.360 --> 00:46:30.320]   This is where these Caldera Labs products come in.
[00:46:30.320 --> 00:46:31.780]   Because if you're a man, you're like, what do I buy?
[00:46:31.780 --> 00:46:32.440]   Like, I don't know.
[00:46:32.440 --> 00:46:33.660]   Like, do I get a lotion?
[00:46:33.660 --> 00:46:36.740]   Should it have Regenerol in it?
[00:46:36.740 --> 00:46:38.680]   Is what is Maybelline?
[00:46:38.680 --> 00:46:39.820]   You don't know what's going on.
[00:46:39.820 --> 00:46:41.420]   This is made for men.
[00:46:41.420 --> 00:46:42.780]   So you don't have to worry about it.
[00:46:42.780 --> 00:46:45.960]   In a consumer study, 100% of men said their skin looks smooth and healthier.
[00:46:45.960 --> 00:46:49.320]   96.9% noticed improved hydration and texture.
[00:46:49.320 --> 00:46:52.040]   And 93.8% reported a more youthful experience.
[00:46:52.040 --> 00:46:54.280]   Here's three products I want to mention from Caldera.
[00:46:54.520 --> 00:46:55.700]   One is called The Good.
[00:46:55.700 --> 00:47:01.260]   That's an award-winning serum packed with 27 active botanicals and 3.4 million antioxidant
[00:47:01.260 --> 00:47:02.340]   units per drop.
[00:47:02.340 --> 00:47:02.800]   I counted.
[00:47:02.800 --> 00:47:03.340]   That's true.
[00:47:03.340 --> 00:47:06.320]   It'll help protect your skin from environmental stressors.
[00:47:06.320 --> 00:47:11.480]   They have an eye serum to help reduce the appearance of tired eyes, dark circles, and puffiness by
[00:47:11.480 --> 00:47:14.000]   using peptide complexes and adaptogens.
[00:47:14.580 --> 00:47:19.400]   And the base layer, this is the cool one that I think you should use every day, a nutrient-wrench
[00:47:19.400 --> 00:47:20.080]   moisturizer.
[00:47:20.080 --> 00:47:21.580]   Put it on every morning.
[00:47:21.580 --> 00:47:26.180]   It's infused with plant stem cells and snow mushroom extract known for their deep hydration and skin
[00:47:26.180 --> 00:47:28.140]   rejuvenating properties.
[00:47:28.140 --> 00:47:29.920]   Non-greasy matte finish.
[00:47:29.920 --> 00:47:31.740]   Your skin feels hydrated without the shine.
[00:47:31.740 --> 00:47:32.860]   Man, you got to use this stuff.
[00:47:32.860 --> 00:47:34.760]   Here's someone who's making it just for men.
[00:47:34.760 --> 00:47:36.020]   Makes it simple.
[00:47:36.020 --> 00:47:37.000]   All right?
[00:47:37.000 --> 00:47:41.060]   Skin care doesn't have to be complicated, but it should be good.
[00:47:41.060 --> 00:47:44.380]   Upgrade your routine with Caldera Lab and see the difference for yourself.
[00:47:44.380 --> 00:47:50.560]   Go to calderalab.com slash deep and use deep at checkout for 20% off your first order.
[00:47:50.560 --> 00:47:53.540]   If you don't use Caldera, you'll look like a grizzled pirate.
[00:47:53.540 --> 00:47:55.860]   I added that tagline, but I think that's a good one.
[00:47:55.860 --> 00:48:00.740]   I also want to talk about our longtime sponsor, Grammarly.
[00:48:00.740 --> 00:48:05.360]   From emails, reports, and project proposals, it's more challenging than ever to meet the demands
[00:48:05.360 --> 00:48:07.740]   of today's competing priorities without some help.
[00:48:08.340 --> 00:48:11.940]   Grammarly is the essential AI communication assistant that boosts productivity so you can
[00:48:11.940 --> 00:48:15.740]   get more of what you need done faster, no matter what or where you're writing.
[00:48:15.740 --> 00:48:17.200]   Look, we talk about this on the show.
[00:48:17.200 --> 00:48:21.680]   Knowledge work these days is a writing medium.
[00:48:21.680 --> 00:48:24.220]   Emails, Slack, reports.
[00:48:24.220 --> 00:48:28.660]   The better you are at writing, the better you'll be perceived, and the better you will do.
[00:48:28.660 --> 00:48:32.740]   Grammarly's AI-powered writing assistance makes you a better writer.
[00:48:32.880 --> 00:48:38.000]   It is like having a copy editor sitting over your shoulder to make the writing that you use
[00:48:38.000 --> 00:48:39.440]   just sound better.
[00:48:39.440 --> 00:48:45.380]   90% of professionals say Grammarly has saved them time in writing and editing their work.
[00:48:45.380 --> 00:48:49.060]   You can do things like, look at your tone.
[00:48:49.060 --> 00:48:50.260]   Is there a better way to say this?
[00:48:50.260 --> 00:48:54.180]   But you can also speed things up by saying, hey, can you give me some ideas here?
[00:48:54.180 --> 00:48:57.400]   Or a rough draft of what I'm trying to say that you can work off of.
[00:48:57.400 --> 00:49:00.580]   Some of those cool things you've heard about AI and writing, Grammarly integrates it into
[00:49:00.580 --> 00:49:04.980]   the apps you use on the devices that you actually use.
[00:49:04.980 --> 00:49:06.520]   You can write and edit quickly.
[00:49:06.520 --> 00:49:09.860]   93% of professionals report that Grammarly helped them get more work done.
[00:49:09.860 --> 00:49:14.740]   You deserve to be equipped with the best tools to do your job right with the right AI support.
[00:49:14.740 --> 00:49:18.160]   Grammarly also sets the standard for responsible AI you can trust.
[00:49:18.160 --> 00:49:19.920]   You've heard a lot about AI.
[00:49:20.820 --> 00:49:25.200]   I've argued the types of purposes that are, the applications that are useful right now
[00:49:25.200 --> 00:49:30.160]   are these ones that are well-fitted to generative AI's capabilities, like helping you with writing
[00:49:30.160 --> 00:49:31.260]   or writing-related tasks.
[00:49:31.260 --> 00:49:34.580]   Grammarly allows you to take advantage of that ability.
[00:49:34.580 --> 00:49:38.700]   So let Grammarly take the busy work off your plate so you can focus on high-impact work.
[00:49:38.700 --> 00:49:42.560]   Download Grammarly for free at grammarly.com slash podcast.
[00:49:42.560 --> 00:49:45.180]   That's grammarly.com slash podcast.
[00:49:45.180 --> 00:49:48.520]   All right, Jesse, let's move on now to our final segment.
[00:49:49.440 --> 00:49:52.340]   So I've been trying out this new final segment called What to Read.
[00:49:52.340 --> 00:49:56.300]   We talk a lot on the show about cultivating a deep life in the world of all these digital
[00:49:56.300 --> 00:50:01.840]   distractions, and you know I think one of the key strategies in cultivating more depth and
[00:50:01.840 --> 00:50:04.400]   less distractions is reading books and articles.
[00:50:04.400 --> 00:50:09.340]   So I want to talk more about things I've read that I think are interesting or good, whether
[00:50:09.340 --> 00:50:13.920]   they're about the deep life or just the type of thing someone who's living a deep life might
[00:50:13.920 --> 00:50:14.500]   enjoy reading.
[00:50:14.500 --> 00:50:17.580]   So today I want to talk about a book I read over my trip last week.
[00:50:18.220 --> 00:50:19.400]   I have it here.
[00:50:19.400 --> 00:50:20.700]   It's not very useful, Jesse.
[00:50:20.700 --> 00:50:21.900]   I took the dust jacket off.
[00:50:21.900 --> 00:50:25.080]   It's kind of a gray book, as you can see.
[00:50:25.080 --> 00:50:25.780]   It's so funny.
[00:50:25.780 --> 00:50:27.620]   They do need to work on the cover design.
[00:50:27.620 --> 00:50:30.400]   I would say there's probably a better cover design.
[00:50:30.400 --> 00:50:35.760]   Now this book is, I took the dust jacket off, but it's The Explorer's Gene by Alex Hutchinson.
[00:50:35.760 --> 00:50:37.600]   Enjoyed this book.
[00:50:37.600 --> 00:50:41.560]   I think the reference, The Explorer's Gene is probably a reference to Dave Epstein's book,
[00:50:41.560 --> 00:50:42.820]   The Sports Gene.
[00:50:43.400 --> 00:50:46.340]   Alex's last book, Endure, was about the science of endurance athletes.
[00:50:46.340 --> 00:50:47.700]   He kind of runs in similar circles.
[00:50:47.700 --> 00:50:52.460]   I don't know him, but he kind of runs in those same like Epstein, Steve Magnus, Brad Stolberg
[00:50:52.460 --> 00:50:53.460]   circles.
[00:50:53.460 --> 00:50:57.700]   So of writers with a background in like sports performance.
[00:50:57.700 --> 00:50:58.880]   I thought the book was really cool.
[00:50:58.880 --> 00:51:03.080]   Here's the central question that sets up is why do humans explore?
[00:51:03.080 --> 00:51:10.960]   And there's kind of a cool way Alex sets this up early where he talks about the peopling of the Polynesian
[00:51:10.960 --> 00:51:11.360]   islands.
[00:51:12.180 --> 00:51:14.200]   Like, why did we do that as a species?
[00:51:14.200 --> 00:51:18.160]   It is not easy to get to Easter Island.
[00:51:18.160 --> 00:51:20.640]   It is not easy to get to New Zealand.
[00:51:20.640 --> 00:51:22.200]   It's not easy to get to Hawaii.
[00:51:22.200 --> 00:51:29.080]   You had to be willing to put your life on the line, get in like a boat and just go.
[00:51:29.080 --> 00:51:30.480]   And he gets into like the research.
[00:51:30.480 --> 00:51:33.040]   It's like, look, we, we, this was probably intentional trips.
[00:51:33.040 --> 00:51:34.920]   Like the drift hypothesis has these sort of issues.
[00:51:34.920 --> 00:51:36.640]   So we, we, we explore.
[00:51:36.640 --> 00:51:37.320]   Why do we explore?
[00:51:37.320 --> 00:51:38.420]   The book wants to find out why.
[00:51:38.420 --> 00:51:40.540]   And it's really, it looks into the science of it.
[00:51:40.740 --> 00:51:43.020]   There's all sorts of different angles that he takes on this.
[00:51:43.020 --> 00:51:45.940]   He looks, there's some angles, there's some genes here that people who have it are more
[00:51:45.940 --> 00:51:48.180]   prone to an exploration mindset than others.
[00:51:48.180 --> 00:51:52.320]   But there's also just things that are hardwired into all people, like uncertainty minimization.
[00:51:52.320 --> 00:51:57.080]   He spends a lot of time with like multi-armed bandit exploration, voice exploitation trade-offs
[00:51:57.080 --> 00:51:58.980]   and why we might do this in our own mind.
[00:51:58.980 --> 00:52:01.340]   There's cultural aspects in this as well.
[00:52:01.340 --> 00:52:02.540]   Like what's shifted in our culture.
[00:52:02.540 --> 00:52:06.400]   It just gives you a sense of like, Hey, why do humans want to explore?
[00:52:06.400 --> 00:52:07.600]   Why is it good for us?
[00:52:07.600 --> 00:52:09.780]   And why might that affect the way we live our life?
[00:52:10.000 --> 00:52:12.320]   There's a section I want to read a quick quote from.
[00:52:12.320 --> 00:52:19.260]   He covers a lot of topics in this book, but most relevant perhaps to our show is where
[00:52:19.260 --> 00:52:24.680]   he's talking about some of modern technology and how it plays well or not so well with these
[00:52:24.680 --> 00:52:28.400]   instincts we have for humans to like actually go out there and explore.
[00:52:29.400 --> 00:52:32.320]   So let me read from page 172 here.
[00:52:32.320 --> 00:52:38.660]   To explore the world, you have to be in the world capable of acting on it and being act upon
[00:52:38.660 --> 00:52:42.280]   by it, making decisions whose outcomes are unknown and have consequences.
[00:52:42.280 --> 00:52:47.200]   Taking a penalty kick or playing a concerto are many adventures whose endings aren't yet
[00:52:47.200 --> 00:52:47.560]   written.
[00:52:47.560 --> 00:52:52.660]   Csikszentmihalyi's distinction reminds me of all the times I wandered through arcades as a
[00:52:52.660 --> 00:52:54.120]   kid with no quarters in my pocket.
[00:52:54.120 --> 00:52:58.800]   I'd stop to play in quotes some of the games, moving the joystick and punching the buttons
[00:52:58.800 --> 00:53:02.520]   as the game's demo mode cycled through its various worlds and showed me the adventures I
[00:53:02.520 --> 00:53:03.160]   could be having.
[00:53:03.160 --> 00:53:05.020]   But the joystick and buttons didn't do anything.
[00:53:05.020 --> 00:53:07.340]   I wasn't causally connected to these worlds.
[00:53:07.340 --> 00:53:08.780]   So I got bored very quickly.
[00:53:08.780 --> 00:53:12.420]   The flow experience that results from the use of skills leads to growth.
[00:53:12.420 --> 00:53:15.780]   Csikszentmihalyi wrote, passive entertainment leads nowhere.
[00:53:15.780 --> 00:53:20.240]   So there's an interesting argument in here that the more that we move towards the passive from
[00:53:20.240 --> 00:53:26.240]   the active, seeing things in photos on social media instead of going there, sending the tweet
[00:53:26.240 --> 00:53:33.000]   instead of actually being involved, you know, in the activism, playing the video game instead
[00:53:33.000 --> 00:53:39.180]   of playing in the softball league, you know, for your, your local fire department or whatever
[00:53:39.180 --> 00:53:39.500]   it is.
[00:53:39.500 --> 00:53:41.800]   This makes a, this makes a difference.
[00:53:41.800 --> 00:53:47.220]   We are meant to be in the world, exploring, learning, having errors, correcting the errors,
[00:53:47.220 --> 00:53:52.280]   updating our understanding, having suspense, extending effort, having victories and losses.
[00:53:52.280 --> 00:53:54.980]   This is what we makes life interesting.
[00:53:54.980 --> 00:53:56.080]   It's what our brain expects.
[00:53:56.080 --> 00:54:01.360]   It's what we are wired for as humans, both culturally and physiologically to do.
[00:54:01.740 --> 00:54:05.980]   And one of the unexpected, but powerful consequences of shifting towards a world of the digital
[00:54:05.980 --> 00:54:10.900]   is that we get alienated from this and we get listless.
[00:54:10.900 --> 00:54:11.980]   We get depressed.
[00:54:11.980 --> 00:54:12.760]   We get unhappy.
[00:54:12.760 --> 00:54:15.300]   We get, uh, emotionally dysregulated.
[00:54:15.300 --> 00:54:16.660]   It's not a great way to live.
[00:54:16.660 --> 00:54:21.040]   A life lived through a little screen is not the life that our brain evolved for.
[00:54:21.040 --> 00:54:23.580]   We try to tell ourselves it's better, but it's not.
[00:54:23.580 --> 00:54:24.200]   It's worse.
[00:54:24.200 --> 00:54:25.720]   And it's why we're so unhappy.
[00:54:26.720 --> 00:54:33.040]   And Alex makes a book length argument for why the exploratory lifestyle is a key part
[00:54:33.040 --> 00:54:33.600]   of the deep lifestyle.
[00:54:33.600 --> 00:54:34.400]   So anyways, good book.
[00:54:34.400 --> 00:54:36.420]   I read it in a couple of days.
[00:54:36.420 --> 00:54:39.280]   The Explorers Gene by Alex Hutchinson.
[00:54:39.280 --> 00:54:41.000]   There you go, Jesse.
[00:54:41.000 --> 00:54:43.860]   That's what I'm recommending to read this week.
[00:54:43.860 --> 00:54:45.880]   You should have him on the show.
[00:54:45.880 --> 00:54:46.520]   He's an interesting guy.
[00:54:46.520 --> 00:54:47.100]   Yeah.
[00:54:48.220 --> 00:54:49.620]   Uh, that's all the time we have.
[00:54:49.620 --> 00:54:53.680]   I've got busy work to do keeping the Nats new wind streak alive.
[00:54:53.680 --> 00:54:54.860]   They depend on me, of course.
[00:54:54.860 --> 00:54:59.640]   So I'll be back next week with another episode, but until then, as always, stay deep.
[00:54:59.640 --> 00:55:05.300]   Hey, if you like today's discussion about kids and phones, I want to know more about the potential
[00:55:05.300 --> 00:55:07.420]   harms for you as a adult.
[00:55:07.420 --> 00:55:10.780]   Check out episode 347 called the forgotten phone harms.
[00:55:10.780 --> 00:55:13.480]   There's some warnings there that I think you need to hear.
[00:55:13.480 --> 00:55:14.320]   Check it out.
[00:55:14.320 --> 00:55:21.840]   But as I will show, this specific rule is going to highlight a much more general issue
[00:55:21.840 --> 00:55:26.080]   that I think is afflicting our current discourse surrounding phones.
[00:55:26.080 --> 00:55:29.880]   It's an issue that I think is a problem and that we need to fix.

