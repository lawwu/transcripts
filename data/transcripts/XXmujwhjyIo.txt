
[00:00:00.000 --> 00:00:03.300]   can delay that supposed to happen. So for those 30 seconds,
[00:00:03.300 --> 00:00:06.140]   I'm freaking out and just double checking if I have not messed up
[00:00:06.140 --> 00:00:06.620]   anything.
[00:00:06.620 --> 00:00:08.740]   Sanyam Bhutani: Looks good.
[00:00:08.740 --> 00:00:12.060]   Sanyam Bhutani: I'll quickly make sure we're live and then
[00:00:12.060 --> 00:00:12.820]   get started.
[00:00:28.500 --> 00:00:31.300]   Also, I can see myself which means we're live. Hey,
[00:00:31.300 --> 00:00:34.380]   everybody, thank you for joining us on a Friday. As you can see,
[00:00:34.380 --> 00:00:38.620]   my hands are shaking again, which means I'm being joined by
[00:00:38.620 --> 00:00:41.500]   the absolute Kaggle legend, Chris Theod. Chris, thank you so
[00:00:41.500 --> 00:00:44.660]   much again for joining me on for the third time, I believe on
[00:00:44.660 --> 00:00:45.300]   the series.
[00:00:45.300 --> 00:00:47.340]   Chris Theodora (00.50.21): Thank you. Thanks for inviting me. I
[00:00:47.340 --> 00:00:48.740]   always enjoy being on your show.
[00:00:48.740 --> 00:00:52.500]   Sanyam Bhutani: You're too kind. I want to introduce you by
[00:00:52.500 --> 00:00:55.980]   showing your profile to the audience. I don't know anyone
[00:00:55.980 --> 00:01:00.100]   who would need an introduction. But still, I'll for anyone who's
[00:01:00.100 --> 00:01:04.700]   been living under the rug, Chris is number one in notebooks
[00:01:04.700 --> 00:01:08.160]   category, number one in discussion, globally, that's on
[00:01:08.160 --> 00:01:13.140]   Kaggle. He's in the top 12 in competition, and he was also the
[00:01:13.140 --> 00:01:17.540]   former number one datasets Grandmaster. As you can see,
[00:01:17.540 --> 00:01:20.940]   it's all yellow. It's all golden because he's a 4x Kaggle
[00:01:20.940 --> 00:01:24.300]   Grandmaster. He's a Grandmaster across all categories. And he's
[00:01:24.300 --> 00:01:29.540]   kindly agreed to share his six position solo gold solution with
[00:01:29.540 --> 00:01:34.020]   us. So we'll be diving into that. As a reminder to everyone,
[00:01:34.020 --> 00:01:37.020]   the usual structure in this series is I introduce the guest,
[00:01:37.020 --> 00:01:40.340]   we ask some questions around the journey, then we understand the
[00:01:40.340 --> 00:01:43.100]   competition, and I request them to share a walkthrough of the
[00:01:43.100 --> 00:01:45.820]   solution. And you're always welcome to ask any questions,
[00:01:45.820 --> 00:01:49.380]   please keep them coming in the chat, and I'll keep asking them
[00:01:49.380 --> 00:01:49.900]   to Chris.
[00:01:51.340 --> 00:01:55.260]   Chris, like I mentioned, is a 4x Kaggle Grandmaster. He works on
[00:01:55.260 --> 00:01:58.140]   data science and research problems at Nvidia. Last time I
[00:01:58.140 --> 00:02:02.140]   spoke to him, we talked about the Rexis competition, which is
[00:02:02.140 --> 00:02:04.620]   a recommender system competition. And you all would
[00:02:04.620 --> 00:02:07.460]   know him from Kaggle, where he's also been working on incredible
[00:02:07.460 --> 00:02:11.740]   problems. So, Chris, I want to start by asking where does this
[00:02:11.740 --> 00:02:15.740]   awesome passion of yours come from, come for Kaggle from?
[00:02:15.740 --> 00:02:18.260]   Because every time I speak to you, you're always so passionate
[00:02:18.260 --> 00:02:20.700]   and energetic about Kaggle. You're always very energetic on
[00:02:20.700 --> 00:02:23.020]   Kaggle forums as well. Where does that come from?
[00:02:23.020 --> 00:02:27.540]   Thanks. It's just, it's the feeling you get when you when
[00:02:27.540 --> 00:02:30.220]   you're doing what you're meant to be doing. I think ever since I
[00:02:30.220 --> 00:02:35.180]   was young, I just love data. I remember there was a story. I
[00:02:35.180 --> 00:02:38.180]   was four years old, and I was in a store and we're buying a new
[00:02:38.180 --> 00:02:40.100]   baseball or maybe I was five years old, we're buying a new
[00:02:40.100 --> 00:02:43.820]   baseball bat. And I was there with my parents. And we said we
[00:02:43.820 --> 00:02:46.380]   want a new bat. And they said, Well, we need the numbers off
[00:02:46.380 --> 00:02:50.140]   your old bat. And my parents said, Oh, we don't have that
[00:02:50.140 --> 00:02:52.780]   with us. Maybe we can come back. And I said, Oh, I know that. And
[00:02:52.780 --> 00:02:56.100]   I just immediately stated the all the numbers on the baseball
[00:02:56.100 --> 00:02:59.500]   bat, the serial number, the size, all the numbers. So my
[00:02:59.500 --> 00:03:02.940]   whole life, I've just loved numbers. I love data. As a small
[00:03:02.940 --> 00:03:06.380]   kid, I'd memorize them. And growing up, you know, data
[00:03:06.380 --> 00:03:09.700]   science didn't exist. And now all of a sudden, the field
[00:03:09.700 --> 00:03:12.340]   exists. So I'm just super excited to be a part of it.
[00:03:12.340 --> 00:03:16.380]   You've also taught in the past, we talked about this in our
[00:03:16.380 --> 00:03:21.740]   earlier interviews. I'm trying to understand how is it
[00:03:21.740 --> 00:03:25.060]   fulfilling to teach on Kaggle because you really teach a lot
[00:03:25.060 --> 00:03:28.460]   of stuff on Kaggle. Is it intentional? Do you really
[00:03:28.460 --> 00:03:31.540]   enjoy it? Or do you find it more fulfilling compared to other
[00:03:31.540 --> 00:03:34.140]   university teaching that you used to do?
[00:03:34.140 --> 00:03:39.940]   So I do miss so yes, I love teaching and I love and
[00:03:39.940 --> 00:03:43.060]   therefore I love doing it on Kaggle and however I can
[00:03:43.220 --> 00:03:47.100]   discussions, notebooks, and that I do miss sort of the the
[00:03:47.100 --> 00:03:50.900]   personal interaction that you get in a classroom. And I
[00:03:50.900 --> 00:03:54.260]   foresee that someday, you know, I'll get back working in the
[00:03:54.260 --> 00:03:54.780]   classroom.
[00:03:54.780 --> 00:04:00.260]   If you were to pick a category, since you're a grandmaster in
[00:04:00.260 --> 00:04:03.020]   all four, which which is your favorite from all four?
[00:04:05.780 --> 00:04:09.780]   Huh, that's a tough question. Okay, so let's see. Um,
[00:04:09.780 --> 00:04:18.460]   it's tough. I mean, I guess like, I know, it's not data
[00:04:18.460 --> 00:04:19.140]   sets.
[00:04:19.140 --> 00:04:24.900]   But, you know, I started out being a grandmaster in
[00:04:24.900 --> 00:04:27.220]   discussions and notebooks. So maybe one could say, since
[00:04:27.220 --> 00:04:30.100]   those are the two I sort of sought first, those are sort of
[00:04:30.100 --> 00:04:35.260]   what are sort of the most meaningful to me. And then it's
[00:04:35.260 --> 00:04:38.820]   been recently, which I've been focusing more on competitions,
[00:04:38.820 --> 00:04:41.860]   changing the nature of my sharing to kind of allow me to
[00:04:41.860 --> 00:04:44.820]   be more competitive. But I think at heart, I think at heart, I
[00:04:44.820 --> 00:04:48.220]   am a teacher. You know, my, I think my number one goal is
[00:04:48.220 --> 00:04:51.900]   just is a way is to play, I feel that data science is an
[00:04:51.900 --> 00:04:53.940]   opportunity to play, you're playing with data, you're
[00:04:53.940 --> 00:04:57.220]   playing with models, it's just kind of a playground. And then
[00:04:57.220 --> 00:04:59.980]   furthermore, I think I just love learning, I love seeing a new
[00:04:59.980 --> 00:05:03.260]   data set, you get to explore it and learn it. And then learning
[00:05:03.260 --> 00:05:05.740]   new, learning about new techniques, and what have you.
[00:05:05.740 --> 00:05:10.820]   So I think first and foremost, I like to learn and teach. But I
[00:05:10.820 --> 00:05:13.140]   mean, I guess as a final disclaimer, I could add
[00:05:13.140 --> 00:05:16.300]   competitions are so much more exciting, right? I mean, I get
[00:05:16.300 --> 00:05:20.860]   so excited. I like to see myself on the leaderboard, or my team
[00:05:20.860 --> 00:05:23.940]   on the leaderboard. I love the last day when you're doing you
[00:05:23.940 --> 00:05:26.580]   pick your final submissions, and you're watching the clock tick
[00:05:26.580 --> 00:05:29.780]   down, and you're excited to see what you think. So that that
[00:05:29.780 --> 00:05:34.220]   kind of excitement, though, I mean, I do love that.
[00:05:34.220 --> 00:05:39.700]   Sanyam Bhutani: How do you pick which competitions to join? CPMP
[00:05:39.700 --> 00:05:42.900]   John Truncheau, he shared he picks the competitions where he
[00:05:42.900 --> 00:05:45.260]   can learn the most. Do you follow a similar approach?
[00:05:45.260 --> 00:05:49.460]   Unknown: Somewhat, I mean, in general, I'll gravitate towards
[00:05:49.460 --> 00:05:52.980]   the competition, which has something new for me. So whether
[00:05:52.980 --> 00:05:55.580]   it be a new type of problem, a new type of data, a new
[00:05:55.580 --> 00:05:59.060]   technique to use. So that is my preference. I don't, you know, I
[00:05:59.060 --> 00:06:02.300]   wouldn't, yeah, I would not enjoy, for instance, just having
[00:06:02.300 --> 00:06:05.500]   a template solution, you know, that, for instance, whenever
[00:06:05.500 --> 00:06:08.300]   there's this type of problem, I just apply this code and I win,
[00:06:08.300 --> 00:06:11.620]   even though I could, I, that would be fun for me. So yeah, I
[00:06:11.620 --> 00:06:12.980]   guess I seek out new things.
[00:06:12.980 --> 00:06:18.300]   Sanyam Bhutani: And I was asking this off the record as well. How
[00:06:18.300 --> 00:06:21.220]   do you how do you balance so much effort that goes into
[00:06:21.220 --> 00:06:25.740]   Kaggle? Because you even right now have a huge lead of 3000
[00:06:25.740 --> 00:06:29.540]   points in one category. I think it's similar in notebooks. Do
[00:06:29.540 --> 00:06:33.060]   you ever face burnout or because Kaggle is very addictive to
[00:06:33.060 --> 00:06:36.020]   anyone who does it? They know? How do you balance that? And how
[00:06:36.020 --> 00:06:37.500]   do you avoid burnout if at all?
[00:06:37.500 --> 00:06:42.180]   Unknown: I guess I guess I avoid burnout because I enjoy it so
[00:06:42.180 --> 00:06:44.820]   much. You know, people always say that when they work when they
[00:06:44.820 --> 00:06:46.900]   work really hard, if it's something you know, they enjoy
[00:06:46.900 --> 00:06:50.260]   doing, then they're sort of have endless energy. And when it's
[00:06:50.260 --> 00:06:51.860]   when someone makes you do something you don't want to do,
[00:06:51.860 --> 00:06:56.260]   you get tired out. So I love it. And then yeah, I'm on there
[00:06:56.260 --> 00:06:58.620]   pretty often. I guess one thing is I don't I don't spend much
[00:06:58.620 --> 00:07:01.740]   time on other social media. So yes, people frequently ask me
[00:07:01.740 --> 00:07:04.260]   how can you spend so much time. So I think I don't spend much
[00:07:04.260 --> 00:07:05.900]   time on other social media. So you know, a lot of people are
[00:07:05.900 --> 00:07:09.220]   posted up on Twitter and Facebook, I guess generally, a
[00:07:09.220 --> 00:07:12.180]   lot of you know, basically, when I sort of want to reach out and
[00:07:12.180 --> 00:07:14.020]   share information, it's generally in the form of data
[00:07:14.020 --> 00:07:16.340]   science, and then I'll generally just pop on Kaggle and share
[00:07:16.340 --> 00:07:20.180]   something. So that's probably why I kind of stand out in the
[00:07:20.180 --> 00:07:23.260]   discussion that why I have so many posts, if other people,
[00:07:23.260 --> 00:07:27.060]   you know, you know, posted kind of on here as much they did on
[00:07:27.060 --> 00:07:30.980]   other social media, I suspect some other people might have,
[00:07:30.980 --> 00:07:34.180]   you know, a lot of me too.
[00:07:34.180 --> 00:07:37.620]   Sanyam Bhutani: I was just highlighting this graph. This is
[00:07:37.620 --> 00:07:41.780]   like some, some software engineers idle graph on GitHub.
[00:07:41.780 --> 00:07:44.780]   That's how it is for you on Kaggle as well. There was this
[00:07:44.780 --> 00:07:48.780]   gap, which I think correlates to the June one maybe relates to
[00:07:48.780 --> 00:07:51.620]   Rex's competition where you were participating on that. So your
[00:07:51.620 --> 00:07:54.180]   energy was focused there, but you're always active, very
[00:07:54.180 --> 00:07:57.100]   active, as you can see, on some days, a little bit less active
[00:07:57.100 --> 00:07:58.660]   on some other days on Kaggle.
[00:07:58.660 --> 00:08:01.380]   Yeah, yeah, yeah, it is interesting. Yeah, that's sort
[00:08:01.380 --> 00:08:03.100]   of what made my vacation. Yeah, you're right. I think the
[00:08:03.100 --> 00:08:05.340]   summer we were working on some Yeah, we're working on some,
[00:08:05.340 --> 00:08:09.260]   some projects off of Kaggle. And then I think that September,
[00:08:09.260 --> 00:08:14.740]   that's when I had taken a vacation. I was actually camping
[00:08:15.020 --> 00:08:19.860]   in a national forest. So I didn't even have connection to
[00:08:19.860 --> 00:08:22.860]   the internet. So I even if I wanted to sneak sneak on at
[00:08:22.860 --> 00:08:27.260]   night, I couldn't. So that's why that one there is no activity.
[00:08:27.260 --> 00:08:32.020]   In my first interview, you told me sometimes you get an idea and
[00:08:32.020 --> 00:08:34.940]   you're opening your eye and looking at the clock if you can
[00:08:34.940 --> 00:08:38.380]   get to work. Is that passion still at the same level? Do you
[00:08:38.380 --> 00:08:41.020]   still get ideas at the same level? And you excited to
[00:08:41.020 --> 00:08:43.780]   get it? It really is. I mean, it's sort of embarrassing. So I
[00:08:43.780 --> 00:08:47.940]   don't want to sound like you know, last night, actually, I
[00:08:47.940 --> 00:08:50.540]   actually, there was some code I was running, and I wanted to see
[00:08:50.540 --> 00:08:54.100]   the result. So I actually kind of rolled over my bed, and I
[00:08:54.100 --> 00:08:56.540]   accessed it on my cell phone just to check something and then
[00:08:56.540 --> 00:08:59.260]   I brought back to bed. So yeah, I mean, it's kind of always on
[00:08:59.260 --> 00:09:04.020]   my mind. Basically, yeah, yeah, hopping out of bed to try an
[00:09:04.020 --> 00:09:06.740]   idea or checking the results of something in the middle of the
[00:09:06.740 --> 00:09:09.980]   night. It's a yes, I still do that.
[00:09:11.700 --> 00:09:15.180]   Andreeja asked, sleep at all during the last week. Is the
[00:09:15.180 --> 00:09:16.460]   last week intense?
[00:09:16.460 --> 00:09:21.260]   For some, so it is intense. So my whole life. So yeah, and I
[00:09:21.260 --> 00:09:24.700]   have I have a pole to fuel, I guess it is somewhat typical to
[00:09:24.700 --> 00:09:27.580]   pull some all nighters. What's really surprising, I think in
[00:09:27.580 --> 00:09:30.700]   competitions is you would think so a competition lasts for three
[00:09:30.700 --> 00:09:34.420]   months, right? So you would think that, you know, you could
[00:09:34.420 --> 00:09:38.380]   have your solution in place, way ahead of time in school, I was
[00:09:38.380 --> 00:09:40.500]   never I never waited till the last second in school, if I had
[00:09:40.500 --> 00:09:43.220]   an assignment, I had it done, I had it done a week before it
[00:09:43.220 --> 00:09:47.860]   was due a project, a report, a coding project, it was always I
[00:09:47.860 --> 00:09:50.580]   had it weighed on. Unfortunately, I'm Kaggle, I've
[00:09:50.580 --> 00:09:52.460]   never sort of been able to do that. Because even though I have
[00:09:52.460 --> 00:09:55.020]   a salute, even though our team has me or our team has a
[00:09:55.020 --> 00:09:59.380]   solution, we're happy with a week before. Always in the last
[00:09:59.380 --> 00:10:02.660]   week, something emerges. For instance, in pet finder account,
[00:10:02.660 --> 00:10:07.860]   this is crazy. Two days before the competition ended. They just
[00:10:07.860 --> 00:10:11.700]   released a new model, this covenex model, the paper just
[00:10:11.700 --> 00:10:16.620]   hit get just hit on just just was released literally two days
[00:10:16.620 --> 00:10:21.100]   before. So the last two nights in Petcom, I basically pulled
[00:10:21.100 --> 00:10:24.500]   all nighters, I downloaded all the code all the weights, I
[00:10:24.500 --> 00:10:28.260]   mean, I had to try these two models. So I had the literally
[00:10:28.260 --> 00:10:33.420]   this covenex model, I downloaded the weights and, you know, it
[00:10:33.420 --> 00:10:36.860]   wasn't in the TIM repository. So basically, I had to do all these
[00:10:36.860 --> 00:10:39.460]   tricks to basically import it into PyTorch and get it to work.
[00:10:39.460 --> 00:10:43.260]   But I pulled, you know, I put in some hard hours the last two
[00:10:43.260 --> 00:10:46.140]   days, and then got it to work and my final ensemble use those.
[00:10:46.140 --> 00:10:49.540]   So it's this kind of thing that even up to the very last second,
[00:10:49.540 --> 00:10:51.980]   you have to pay attention. And that and that story is not
[00:10:51.980 --> 00:10:54.540]   unique. There's another story where our team, you know,
[00:10:54.540 --> 00:10:58.140]   retrained our models literally the last night. And literally,
[00:10:58.140 --> 00:11:02.060]   it was that submission, which pushed us into gold. So I wish
[00:11:02.060 --> 00:11:05.820]   it wasn't like this. I wish we could just be nine to five, I
[00:11:05.820 --> 00:11:08.100]   wish you could have your solution in place a week before
[00:11:08.100 --> 00:11:10.860]   and then just be sitting on your chair watching the comp end. But
[00:11:10.860 --> 00:11:14.540]   I find it to be competitive and to win gold, you have to work,
[00:11:14.540 --> 00:11:16.540]   unfortunately, up until the last second.
[00:11:16.540 --> 00:11:20.460]   Sanyam Bhutani: In the Nexus one, you told me that you were
[00:11:20.460 --> 00:11:23.860]   waiting for the result and it came right at the end marker, I
[00:11:23.860 --> 00:11:25.620]   think a few minutes before the deadline.
[00:11:25.620 --> 00:11:28.260]   Jason Ticketts: Yeah, absolutely. Because sometimes
[00:11:28.260 --> 00:11:30.540]   when you so yeah, I mean, sometimes you actually need the
[00:11:30.540 --> 00:11:34.020]   result of a submission to sort of know your strategy is or know
[00:11:34.020 --> 00:11:36.340]   you know, what's your next experiment or know what
[00:11:36.340 --> 00:11:39.940]   submission you'll check. So yeah, in Rexis, you know, it was
[00:11:39.940 --> 00:11:42.660]   a code competition, people are familiar with that. But
[00:11:42.660 --> 00:11:46.380]   furthermore, the code allowed 24 hours to run. So if you're
[00:11:46.380 --> 00:11:49.100]   familiar with Kaggle, if it's a code competition, there's
[00:11:49.100 --> 00:11:52.700]   usually a nine hour limit. That means that usually means you
[00:11:52.700 --> 00:11:55.180]   could submit something the night before, and maybe it runs
[00:11:55.180 --> 00:11:57.780]   overnight, you see it in the morning. But but in Rexis, it
[00:11:57.780 --> 00:12:01.460]   was 24 hours. So we had one code and we're trying to pack as many
[00:12:01.460 --> 00:12:05.420]   things as we can. So we were unsure whether our code would
[00:12:05.420 --> 00:12:09.900]   run in 24 hours. Imagine that a computer running for 24 hours.
[00:12:09.900 --> 00:12:12.940]   So we submitted something we packed in all these models, we
[00:12:12.940 --> 00:12:17.380]   had a big team, everybody made contributions. And it literally
[00:12:17.380 --> 00:12:21.460]   was 23 hours and 45 minutes and the submission had not come back
[00:12:21.460 --> 00:12:24.980]   yet. So our code was still running. And we and we knew this
[00:12:24.980 --> 00:12:27.780]   would have been our we we knew this would be our best if it
[00:12:27.780 --> 00:12:31.740]   only completed within 24 hours. But we were we we were sort of
[00:12:31.740 --> 00:12:36.060]   unsure. But luckily, we got the email within minutes, it
[00:12:36.060 --> 00:12:41.660]   literally code ran 23 hours and like, you know, 57 minutes and
[00:12:41.660 --> 00:12:44.820]   then it finished. And we got this email saying your
[00:12:44.820 --> 00:12:47.420]   submission was successful. And we were cheering. And that
[00:12:47.420 --> 00:12:50.420]   surely that and as we you know, predict that was our highest
[00:12:50.420 --> 00:12:53.980]   score, and it was our best sub and that won the comp. Granted,
[00:12:53.980 --> 00:12:56.500]   some of our other subs would have also won the comp. But you
[00:12:56.500 --> 00:12:59.980]   know, we were able to squeeze our best work right in.
[00:12:59.980 --> 00:13:06.500]   Sanyam Bhutani: You're at the level now where you really aim
[00:13:06.500 --> 00:13:10.500]   for the top. How do you keep learning still? So for example,
[00:13:10.500 --> 00:13:13.940]   you're not active on other social I get a lot of my info
[00:13:13.940 --> 00:13:17.500]   from Twitter, many Kagglers I believe to so as well. How do
[00:13:17.500 --> 00:13:20.340]   you find these papers? How do you try to keep up to date with
[00:13:20.340 --> 00:13:23.260]   stuff, research, everything?
[00:13:23.620 --> 00:13:27.060]   So I would say my my biggest resource is Kaggle itself. And
[00:13:27.060 --> 00:13:30.740]   this is you know, I really appreciate everybody sharing
[00:13:30.740 --> 00:13:33.740]   because a lot of times, for instance, the COVNEX model, you
[00:13:33.740 --> 00:13:36.660]   know, I was I was I learned about this COVNEX model I
[00:13:36.660 --> 00:13:39.660]   mentioned, this is this new model that was released two days
[00:13:39.660 --> 00:13:42.220]   before pet finder comp, I learned about it, because
[00:13:42.220 --> 00:13:47.180]   somebody posted a discussion post. And then I quickly
[00:13:47.180 --> 00:13:50.340]   googled and found it. Yeah, they're they're the posts. So
[00:13:50.340 --> 00:13:53.740]   right, see, look, you can see, so they came in. So one came in
[00:13:53.740 --> 00:13:57.500]   and if you remember, the competition ended 16 days ago.
[00:13:57.500 --> 00:14:00.780]   So somebody two days before the comp ends and said, Hey, guy in
[00:14:00.780 --> 00:14:03.340]   the paper literally was released. But that's, you know,
[00:14:03.340 --> 00:14:06.100]   where I learned about it. So yeah, basically reading
[00:14:06.100 --> 00:14:09.580]   previous reading competition solutions and reading. There's
[00:14:09.580 --> 00:14:13.060]   so many amazing Kagglers who share so much, you know, both
[00:14:13.060 --> 00:14:16.300]   both on papers, and they, they dive deep into stuff. And
[00:14:16.300 --> 00:14:18.620]   they're that's, that's one of my biggest sources of learning new
[00:14:18.620 --> 00:14:19.060]   stuff.
[00:14:20.060 --> 00:14:22.620]   Sanyam Bhutani: May I ask a stupid question? You're always
[00:14:22.620 --> 00:14:27.220]   so I, I want to say humble on Kaggle, because you're always
[00:14:27.220 --> 00:14:30.020]   engaging with people like me who also ask stupid questions on
[00:14:30.020 --> 00:14:33.420]   there. How do you not develop this ego? Because you're on the
[00:14:33.420 --> 00:14:37.140]   top of the leaderboard globally? How? How do you stay so humble?
[00:14:37.140 --> 00:14:40.100]   So,
[00:14:40.100 --> 00:14:43.580]   I thought about this, because I have been asked this before. And
[00:14:43.580 --> 00:14:48.500]   I think I've actually learned, I think I've learned a lot from
[00:14:48.500 --> 00:14:52.460]   this. I think I've learned in life, that if you truly want to
[00:14:52.460 --> 00:14:56.540]   learn, and if you truly want to grow, then you must be humble,
[00:14:56.540 --> 00:15:00.940]   right? Because the definition of growing is sort of become
[00:15:00.940 --> 00:15:03.460]   changing kind of becoming something you're not, you know,
[00:15:03.460 --> 00:15:06.860]   learning new things. If I, you know, right now think I know
[00:15:06.860 --> 00:15:10.380]   everything or my ways the best, I'm never going to take the time
[00:15:10.380 --> 00:15:16.180]   to look at what someone else is saying. So, you know, you might
[00:15:16.180 --> 00:15:20.340]   say, Oh, you know, my motivation is 100% altruistic. I'm, you
[00:15:20.340 --> 00:15:24.220]   know, I'm humble, because I, and I, and, and half it is I, you
[00:15:24.220 --> 00:15:25.980]   know, I love people, I care about people, I want to help
[00:15:25.980 --> 00:15:28.900]   people. But to be honest, I also realized that it's actually
[00:15:28.900 --> 00:15:31.980]   being humble, it's engaging in all of these discussions with
[00:15:31.980 --> 00:15:35.540]   everybody, no matter, no matter where they are, that's, that's a
[00:15:35.540 --> 00:15:38.820]   lot of times where I learned the most. It's amazing. I can think
[00:15:38.820 --> 00:15:41.500]   of some examples. But somebody might ask something that's silly
[00:15:41.500 --> 00:15:44.580]   like, oh, you know, you know, why did you change this hyper
[00:15:44.580 --> 00:15:48.020]   parameter in the you know, in your atom optimizer? And, you
[00:15:48.020 --> 00:15:49.980]   know, maybe someone else would just say, Oh, that's just like
[00:15:49.980 --> 00:15:52.500]   what people do. But you know, I take the time and I think, well,
[00:15:52.500 --> 00:15:54.460]   I know that's a simple question. But actually, it's a good
[00:15:54.460 --> 00:15:57.180]   question. So maybe I'll dig into it a little deeper. And then all
[00:15:57.180 --> 00:15:59.620]   of a sudden, I'll discover, oh, wait a second, there's actually
[00:15:59.620 --> 00:16:01.860]   two parameters in the atom optimizer, you know, maybe I
[00:16:01.860 --> 00:16:04.260]   thought it was one. So it's kind of like these conversations
[00:16:04.260 --> 00:16:08.980]   start, and then by being open to them, as the conversation
[00:16:08.980 --> 00:16:12.620]   proceeds, it opens my eyes, I'll learn something I didn't realize
[00:16:12.620 --> 00:16:15.740]   in the process of trying to explain something carefully to
[00:16:15.740 --> 00:16:18.140]   somebody, you realize there's something you didn't know, and
[00:16:18.140 --> 00:16:23.620]   then you have to read up on it. So all questions and discussions
[00:16:23.620 --> 00:16:24.340]   help me grow.
[00:16:24.340 --> 00:16:29.140]   Sanyam Bhutani: Yeah, your learning inspires many people
[00:16:29.140 --> 00:16:33.580]   like me also to learn. So we're really grateful for that. I want
[00:16:33.580 --> 00:16:36.540]   to transition now to talking about the competition. So
[00:16:36.540 --> 00:16:42.380]   sharing for anyone who wants to find Chris, you don't have to
[00:16:42.380 --> 00:16:45.860]   scroll at all. He's on the sixth position by himself. It's a
[00:16:45.860 --> 00:16:49.300]   solo goal. And I really want to point out to the audience that's
[00:16:49.300 --> 00:16:52.860]   foreign to Kaggle, this is really hard to achieve. And this
[00:16:52.860 --> 00:16:55.340]   is one of the requirements for becoming a competitions
[00:16:55.340 --> 00:16:58.260]   grandmaster. And I want to ask what what led you to the
[00:16:58.260 --> 00:17:01.340]   decision of just competing by yourself this time? Why didn't
[00:17:01.340 --> 00:17:01.980]   you team up?
[00:17:01.980 --> 00:17:07.660]   Chris Bounds: So in this particular comp, it was a
[00:17:07.660 --> 00:17:12.020]   conscious decision. I think it was because so there was a lot
[00:17:12.020 --> 00:17:14.900]   of speculation that there was gonna be a huge shakeup. The
[00:17:14.900 --> 00:17:18.660]   public leaderboard was behaving very strangely. It was acting
[00:17:18.660 --> 00:17:22.580]   very different than local validation. So you know, I had
[00:17:22.580 --> 00:17:25.420]   my theories about the shakeup. But nonetheless, you couldn't
[00:17:25.420 --> 00:17:27.900]   you couldn't ignore the fact that it was quite possible that
[00:17:27.900 --> 00:17:32.900]   there would be a shakeup. So that being said, um, you know, I
[00:17:32.900 --> 00:17:35.820]   was maybe considering team, I was maybe considering contacting
[00:17:35.820 --> 00:17:39.500]   some of my co workers who are also kind of up high. But in the
[00:17:39.500 --> 00:17:42.140]   end, the reason I didn't, I didn't, I didn't contact my co
[00:17:42.140 --> 00:17:45.780]   workers was, I actually felt that a part of the comp was a
[00:17:45.780 --> 00:17:48.300]   little bit of a lottery ticket. And you know, you get two final
[00:17:48.300 --> 00:17:51.860]   submissions. So each team gets two lottery tickets. And I sort
[00:17:51.860 --> 00:17:54.700]   of thought, you know, in terms of, you know, one of my one of
[00:17:54.700 --> 00:18:00.540]   my co workers, you know, doing doing, you know, placing in the
[00:18:00.540 --> 00:18:04.140]   top, it was maybe best for us all to, you know, just work on
[00:18:04.140 --> 00:18:07.420]   our own stuff and not collaborate, and therefore, get
[00:18:07.460 --> 00:18:09.460]   get sort of more lottery tickets, and then a higher
[00:18:09.460 --> 00:18:12.500]   chance that sort of someone you know, ends at the top.
[00:18:12.500 --> 00:18:15.180]   Sanyam Bhutani: For the audience, I want to mention
[00:18:15.180 --> 00:18:18.500]   there's an incredible Kaggle Grandmaster team at Nvidia.
[00:18:18.500 --> 00:18:20.900]   That's what Chris is referring to. You can think of legends
[00:18:20.900 --> 00:18:25.580]   like CPMP, Jeeba, people at the level of Chris, there are the
[00:18:25.580 --> 00:18:27.620]   KGmod team as they call it.
[00:18:27.620 --> 00:18:30.220]   Chris Bounds: Yeah, and you can see that did very well in the
[00:18:30.220 --> 00:18:35.340]   pet comp. So we actually have, you know, four in the top 16 or
[00:18:35.340 --> 00:18:38.460]   something like that you got. So that's Jeeba up there at number
[00:18:38.460 --> 00:18:42.100]   one, and then you got a Anadero there in place four on his team.
[00:18:42.100 --> 00:18:46.180]   I'm here in six, and then you could see that CPMP was right
[00:18:46.180 --> 00:18:46.820]   there.
[00:18:46.820 --> 00:18:49.740]   Sanyam Bhutani: Places outside the zone.
[00:18:49.740 --> 00:18:51.660]   Chris Bounds: Yeah, and that was really impressive. So he
[00:18:51.660 --> 00:18:54.300]   actually just started a few days before the competition ended.
[00:18:54.300 --> 00:18:56.700]   And he in the act, he made a really creative model, he did
[00:18:56.700 --> 00:19:00.100]   something nobody else did he applied ordinal regression. And
[00:19:00.100 --> 00:19:02.700]   his single that was a single model, which jumped to 18. So if
[00:19:02.700 --> 00:19:05.260]   he had more time, if he ensembles it with anything, he
[00:19:05.260 --> 00:19:08.380]   also would have been in gold. But yeah, it's cool. When you
[00:19:08.380 --> 00:19:12.420]   read the solution write ups, you can actually see how actually
[00:19:12.420 --> 00:19:15.180]   all the top solutions, everybody in the gold, there's many ways
[00:19:15.180 --> 00:19:17.740]   to approach the problem. And people all did much a lot of
[00:19:17.740 --> 00:19:20.900]   different things. As I said, you know, he used a different, he
[00:19:20.900 --> 00:19:25.020]   used a different loss, which is quite novel. Some people use the
[00:19:25.020 --> 00:19:29.180]   the rapids support, support vector regression. Some people
[00:19:29.180 --> 00:19:33.380]   like on a Darrow, he used xg boost, some people had creative
[00:19:33.380 --> 00:19:35.660]   ways of using old data. So actually, there was a lot of
[00:19:35.660 --> 00:19:37.660]   different little things that a lot of people approach the
[00:19:37.660 --> 00:19:40.540]   problem quite differently. And there's a variety of solutions
[00:19:40.540 --> 00:19:41.140]   at the top.
[00:19:41.140 --> 00:19:46.100]   Sanyam Bhutani: Yeah, we'd love I'd love to dive into your
[00:19:46.100 --> 00:19:50.380]   solutions as well. And I want to ask, what, why did you decide
[00:19:50.380 --> 00:19:54.020]   to enter this competition? What would lead you to signing up and
[00:19:54.020 --> 00:19:56.820]   from there, I'll start diving into the data as well.
[00:19:57.460 --> 00:19:59.780]   I will stay on the screen right here that right there is one
[00:19:59.780 --> 00:20:04.980]   reason. Look at this cat. A cat taking a photo. I mean, this
[00:20:04.980 --> 00:20:09.300]   comp, right? I mean, who doesn't want to explore data of pets. So
[00:20:09.300 --> 00:20:12.580]   you know, it's a really, it's a it's a super, it's a really fun
[00:20:12.580 --> 00:20:16.620]   comp. You know, it's for a great cause. It's going to help
[00:20:16.620 --> 00:20:19.660]   promote the adoption of animals looking at the data was fun at
[00:20:19.660 --> 00:20:23.340]   all. You know, we had 10s of 1000s of photos, and they're all
[00:20:23.340 --> 00:20:29.460]   of animals. So in that sense, you know, it's a really, it's a
[00:20:29.460 --> 00:20:36.740]   really a great comp, and it's a it's a fun comp. But then I
[00:20:36.740 --> 00:20:40.180]   guess, additionally, and I thought it was a great learning
[00:20:40.180 --> 00:20:43.940]   experience. So just recently, I was sort of motivated by one of
[00:20:43.940 --> 00:20:49.860]   my co workers, Dieter, who just took a took two first places in
[00:20:49.860 --> 00:20:52.700]   the in the latest Google Landmark competition, but he did
[00:20:52.700 --> 00:20:55.740]   so, which the solution this year was quite different than last
[00:20:55.740 --> 00:20:59.260]   year, which is he used a image transformer. So last year, I
[00:20:59.260 --> 00:21:02.980]   believe the models were image or CNNs. But this year, for the
[00:21:02.980 --> 00:21:05.380]   first time, he used a combination. And actually, he
[00:21:05.380 --> 00:21:08.020]   built a model architecture himself where he fused together
[00:21:08.020 --> 00:21:13.580]   a CNN with with a transformer. So yeah, there it is those both
[00:21:13.580 --> 00:21:17.980]   those two first places, they ended a few weeks. Oh, we have
[00:21:17.980 --> 00:21:20.540]   to scroll down. Oh, yeah, the 2021 one. So it's not as so he
[00:21:20.540 --> 00:21:23.020]   wanted. Yeah, there it is. So you can see it ended four months
[00:21:23.020 --> 00:21:25.620]   ago. So it ended just before the pet finder comp. And what was
[00:21:25.620 --> 00:21:30.140]   super exciting about it was, I'm always I'm always excited to see
[00:21:30.140 --> 00:21:32.820]   new technology when a comp right, I mean, the model he used
[00:21:32.820 --> 00:21:37.380]   did not exist a year ago. It was all the latest with transformers
[00:21:37.380 --> 00:21:40.540]   that was exciting. So basically, I was I was motivated by all
[00:21:40.540 --> 00:21:44.460]   these new models in the field of computer vision. So I sort of
[00:21:44.460 --> 00:21:48.260]   wanted to explore some. So this was my first time diving deeper
[00:21:48.260 --> 00:21:50.740]   into some of the transformers I had worked with bit before, but
[00:21:50.740 --> 00:21:55.300]   I had never worked with SWIN. There's a BIT. So there's some
[00:21:55.300 --> 00:21:57.620]   new transformers I got to use. I also played with, you know,
[00:21:57.620 --> 00:22:00.900]   trying to fuse CNNs together with transformers. So it was
[00:22:00.900 --> 00:22:04.780]   kind of a good learning experience to really explore the
[00:22:04.780 --> 00:22:08.820]   new state of the art models and image, which, unbelievably,
[00:22:08.820 --> 00:22:11.180]   they're changing every year, right? So that was another draw
[00:22:11.180 --> 00:22:11.620]   for me.
[00:22:11.620 --> 00:22:16.980]   May I ask another stupid question. So someone like me
[00:22:17.020 --> 00:22:19.980]   first downloads the paper, I start reading the paper, then I
[00:22:19.980 --> 00:22:22.820]   go to the repository, if you want to learn something new. So
[00:22:22.820 --> 00:22:25.900]   let's say you didn't know about attention at all when you first
[00:22:25.900 --> 00:22:29.180]   heard of it. And when we wanted to try vision transformers, how
[00:22:29.180 --> 00:22:31.260]   did you go about learning it?
[00:22:31.260 --> 00:22:35.260]   So I think the way I learn any new thing is really just getting
[00:22:35.260 --> 00:22:40.900]   just getting my just get hands on. So if any event, if so, you
[00:22:40.900 --> 00:22:44.060]   know, whether it be a new image model, you know, I recently
[00:22:44.060 --> 00:22:45.940]   entered a Santa competition, which was the traveling
[00:22:45.940 --> 00:22:48.740]   salesman problem, I actually had not worked on that previously.
[00:22:48.740 --> 00:22:51.340]   So any new type of problem or new type of technology, the
[00:22:51.340 --> 00:22:53.940]   first thing I'll do is download a small example, and I'll play
[00:22:53.940 --> 00:22:57.580]   with it. And it really is a play a playful experience. You just
[00:22:57.580 --> 00:23:00.540]   try a little example, you look at the outcome, you maybe you
[00:23:00.540 --> 00:23:03.580]   compare it to some things that you've done previously, compare
[00:23:03.580 --> 00:23:07.380]   a transformer to a CNN, start seeing the differences. For
[00:23:07.380 --> 00:23:10.620]   example, one of the one of the earliest things I noticed when
[00:23:10.620 --> 00:23:15.420]   comparing image transformers to CNNs and somebody made a post in
[00:23:15.420 --> 00:23:21.220]   the pet finder comp was how the models if they're trying to
[00:23:21.220 --> 00:23:26.020]   classify or regress an image, the models really pay attention
[00:23:26.020 --> 00:23:29.820]   to different things. So there's a thing called this grad cam,
[00:23:29.820 --> 00:23:33.140]   where when a when a model makes a prediction, you can actually
[00:23:33.140 --> 00:23:36.340]   highlight the part of the image that was used in making the
[00:23:36.340 --> 00:23:39.780]   decision. And if you actually apply grad cam on a CNN and pet
[00:23:39.780 --> 00:23:43.580]   finder comp, you would actually notice that the CNNs. So a CNN
[00:23:43.580 --> 00:23:47.260]   actually looks at clusters of local features. So it kind of
[00:23:47.260 --> 00:23:51.020]   looks it's kind of like zooming in. And if you notice, the CNN
[00:23:51.020 --> 00:23:53.340]   would actually look at the animal face, and it would sort
[00:23:53.340 --> 00:23:55.540]   of make the decision on whether this is a popular animal based
[00:23:55.540 --> 00:23:57.940]   on the face. Now, if you did the grad cam on the image
[00:23:57.940 --> 00:24:01.260]   transformer, the image transformer does a better job of
[00:24:01.260 --> 00:24:03.900]   collecting global features around the whole image and sort
[00:24:03.900 --> 00:24:07.180]   of utilizing all of them, it doesn't sort of look for it
[00:24:07.180 --> 00:24:10.060]   does better globally. And if you look at the grad cam, what are
[00:24:10.060 --> 00:24:13.500]   that what you actually saw was that the image transformer was
[00:24:13.500 --> 00:24:17.260]   actually looking at the entire posture, the whole body position
[00:24:17.260 --> 00:24:20.580]   of the animal. So was the animal facing the camera? Was the
[00:24:20.580 --> 00:24:24.700]   animal turning sideways? So you look, so this is in this, this
[00:24:24.700 --> 00:24:27.940]   emerges just from playing around, you know, nobody said
[00:24:27.940 --> 00:24:30.740]   you need to use grad cam. But if you're playing out with a new
[00:24:30.740 --> 00:24:34.100]   model, why not use the new model, you know, look at its
[00:24:34.100 --> 00:24:38.300]   grad cam, look at, you know, its training times, just do
[00:24:38.300 --> 00:24:40.460]   everything you're used to, and just kind of see how it's
[00:24:40.460 --> 00:24:42.060]   different than what you've previously done.
[00:24:42.060 --> 00:24:46.460]   I think it again, boils down to your true passion, because you
[00:24:46.460 --> 00:24:49.100]   love tinkering on Kaggle. And you love to learn that way.
[00:24:49.100 --> 00:24:51.380]   Yeah, tinkering. That's a good word. Actually, I love
[00:24:51.380 --> 00:24:52.900]   tinkering. And then it Yeah.
[00:24:52.900 --> 00:24:59.260]   Coming back to the competition. And again, shout out to Dieter
[00:24:59.260 --> 00:25:05.060]   who's a retired construction worker. Coming, coming to the
[00:25:05.060 --> 00:25:08.300]   competition, I want to explain the problem to the audience. So
[00:25:08.300 --> 00:25:11.420]   please correct me, Chris, I'm wrong. I'll try to do an okay
[00:25:11.420 --> 00:25:14.460]   job of explaining it. We were supposed to predict a
[00:25:14.460 --> 00:25:18.980]   popularity score. And that would tell the organization Pet
[00:25:18.980 --> 00:25:23.500]   Finder how easy it is to set a pet up for adoption. So their
[00:25:23.500 --> 00:25:26.580]   mission is to send pets for adoption, and they have a nice
[00:25:26.580 --> 00:25:30.180]   website. The end goal is to find a score and optimize for it so
[00:25:30.180 --> 00:25:32.140]   that they can get more pets adopted.
[00:25:36.260 --> 00:25:39.780]   And inside of the training data set, you had some metadata, I
[00:25:39.780 --> 00:25:42.540]   participated in the previous one, I don't think this was
[00:25:42.540 --> 00:25:45.300]   there, we were trying to calculate this manually. But
[00:25:45.300 --> 00:25:48.900]   this time, they actually tell you if the pet is in focus, if
[00:25:48.900 --> 00:25:53.220]   their eyes are both facing front, or one eye is detected,
[00:25:53.220 --> 00:25:57.300]   all of these metadata was there. And I think Chris will dive into
[00:25:57.300 --> 00:25:59.580]   how this played into a solution. And of course, they were
[00:25:59.580 --> 00:26:04.580]   different images of different pets that had the corresponding
[00:26:04.580 --> 00:26:08.540]   metadata. Anything that I missed here in the problem statement,
[00:26:08.540 --> 00:26:10.140]   I did a bad job, but still,
[00:26:10.140 --> 00:26:13.220]   no, no, you said that very well. Actually, I can even suggest if
[00:26:13.220 --> 00:26:16.580]   you click on discussion, let's see, click on discussion. And
[00:26:16.580 --> 00:26:20.780]   then maybe, okay, so then so scroll down slowly. Let's see,
[00:26:20.780 --> 00:26:23.060]   I'm looking for there's something about upload your pet
[00:26:23.060 --> 00:26:24.780]   photos, keep scrolling down.
[00:26:24.780 --> 00:26:26.260]   I remember it, I can search for it.
[00:26:26.260 --> 00:26:29.380]   It's on this page. It's on this page, or you can search for it.
[00:26:32.140 --> 00:26:34.940]   Yeah, share this. So then scroll down, this kind of sums the
[00:26:34.940 --> 00:26:36.420]   common I'll scroll down here.
[00:26:36.420 --> 00:26:41.620]   Okay, these little pictures. So here's some examples, right? So
[00:26:41.620 --> 00:26:44.420]   yeah, so the comp was, so it's rolling a little bit more, we
[00:26:44.420 --> 00:26:47.780]   can see eight pictures. Yeah. So basically, yeah, your model had
[00:26:47.780 --> 00:26:49.980]   to take the image of the pet, and then it would predict this
[00:26:49.980 --> 00:26:53.820]   top thing, which is the pop up pop popularity score, which is
[00:26:53.820 --> 00:26:57.020]   roughly basically saying how likely the photo will be
[00:26:57.020 --> 00:27:00.100]   clicked. And this will this will be helpful, because if we can
[00:27:00.100 --> 00:27:02.820]   figure out, you know, which photos get clicked, we obviously
[00:27:02.820 --> 00:27:06.580]   want animals to get adopted. So we can basically, essentially,
[00:27:06.580 --> 00:27:10.180]   help choose better photos, which the audience likes. And you can
[00:27:10.180 --> 00:27:14.420]   kind of see with your eye here. So these top eight all have high
[00:27:14.420 --> 00:27:19.060]   popular popularity scores. I'll give a shout out. And the bottom
[00:27:19.060 --> 00:27:24.500]   row, that's, that's my parents pet Stella there. They are the
[00:27:24.500 --> 00:27:29.700]   French Bulldog there, who did got a good popularity score. And
[00:27:29.700 --> 00:27:33.860]   then if you scroll down a little bit, you said these, so all
[00:27:33.860 --> 00:27:36.620]   these eight are ranked actually in order. So those top eight
[00:27:36.620 --> 00:27:38.940]   scored better scores in the low eight and already with your eye,
[00:27:38.940 --> 00:27:41.860]   you can see a difference, right? So the top eight, you know, the
[00:27:41.860 --> 00:27:45.780]   animals sort of centered in the middle of the picture. And the
[00:27:45.780 --> 00:27:48.380]   bottom eight, you know, it's more distractions, the animal,
[00:27:48.380 --> 00:27:51.140]   the animals, not the focus of the picture. But in sure enough,
[00:27:51.140 --> 00:27:55.940]   these scores here are what are what I'm actually these scores
[00:27:55.940 --> 00:27:59.420]   were generated by by my model. And you can see how you know,
[00:27:59.420 --> 00:28:02.180]   the model recognizes that, you know, photos that are sort of
[00:28:02.180 --> 00:28:05.700]   centered on the animal and the animal is smiling, they, yeah,
[00:28:05.700 --> 00:28:07.580]   these top photos get clicked more, you can see that the
[00:28:07.580 --> 00:28:10.460]   animals is more focused, the animal is smiling, and the
[00:28:10.460 --> 00:28:13.020]   bottom photos, it's kind of harder to see the animal in
[00:28:13.020 --> 00:28:15.940]   these photos get clicked less. This is just one observation.
[00:28:15.940 --> 00:28:18.140]   But you know, this is the this is the benefit of this
[00:28:18.140 --> 00:28:21.500]   competition. It'll help people understand, you know, which
[00:28:21.500 --> 00:28:24.460]   photos are sort of helping the pets get adopted, and then it
[00:28:24.460 --> 00:28:27.900]   could help us, you know, take and choose better photos and get
[00:28:27.900 --> 00:28:29.260]   more more pets adopted.
[00:28:29.260 --> 00:28:33.980]   Awesome. That makes sense. So when you first saw this
[00:28:33.980 --> 00:28:37.620]   competition, how did you set up a baseline? What was your first
[00:28:37.620 --> 00:28:40.300]   thought? I'm trying to understand how did you first
[00:28:40.300 --> 00:28:42.580]   when you saw the problem? What were your first thoughts? How
[00:28:42.580 --> 00:28:44.060]   did you approach the competition?
[00:28:44.060 --> 00:28:48.780]   Okay, so I kind of approach every competition the same,
[00:28:48.780 --> 00:28:53.940]   which is you set up a reliable, local validation, which means,
[00:28:53.940 --> 00:28:56.900]   you know, totally independent of a leaderboard, you know,
[00:28:56.900 --> 00:28:59.820]   without the leaderboard, you need a way of building a model
[00:28:59.820 --> 00:29:03.700]   and then essentially evaluating how well the model is doing. And
[00:29:03.700 --> 00:29:06.860]   this is called cross validation. So I did that. What's
[00:29:06.860 --> 00:29:09.420]   interesting is this was always a topic of debate in this
[00:29:09.420 --> 00:29:12.500]   competition, because this met. So this competition, the metric
[00:29:12.500 --> 00:29:17.420]   was a root mean squared error, which it's an image regression
[00:29:17.420 --> 00:29:20.220]   task, which actually is not, it's not, you know, super
[00:29:20.220 --> 00:29:24.460]   common, a lot of times they do more classification tasks. So a
[00:29:24.460 --> 00:29:28.820]   bunch of people are it's very easy, you know, when computing
[00:29:28.820 --> 00:29:33.540]   the local metrics, there's very easy ways to sort of compute
[00:29:33.540 --> 00:29:37.740]   incorrectly. So for example, if we just had an accuracy metric,
[00:29:37.740 --> 00:29:40.260]   or some other metric, you know, you can compute the metric for
[00:29:40.260 --> 00:29:43.900]   each individual batch, and then just kind of average the batches
[00:29:43.900 --> 00:29:46.700]   and that can give you one score. But since ultimately, the
[00:29:46.700 --> 00:29:49.780]   metrics a square root, you know, you can't you can't compute the
[00:29:49.780 --> 00:29:52.380]   metric on individual batches, because the average of many
[00:29:52.380 --> 00:29:55.140]   square roots is not itself a square root. So there was some
[00:29:55.140 --> 00:29:57.780]   subtle there was some, there was actually some subtleties in
[00:29:57.780 --> 00:30:01.780]   setting up your local about local CV correctly. And I think
[00:30:01.780 --> 00:30:04.860]   this really made a difference on how you place because for
[00:30:04.860 --> 00:30:07.300]   instance, there was some discussion posts, and people
[00:30:07.300 --> 00:30:11.300]   said, you know, I have a local validation score of 15. So that
[00:30:11.300 --> 00:30:14.420]   is phenomenal, like 15, you know, you would blow away the
[00:30:14.420 --> 00:30:17.780]   competition. But I believe the only way it's possible is there
[00:30:17.780 --> 00:30:19.940]   was sort of a there was potentially an error in the
[00:30:19.940 --> 00:30:24.260]   computation. So if you read a lot of the winners solution
[00:30:24.260 --> 00:30:28.660]   posts, basically, the best models were achieving local
[00:30:28.660 --> 00:30:32.380]   validations around 17. And I think the best team maybe got it
[00:30:32.380 --> 00:30:36.580]   low as low as 16.8. So that so if you set up your local
[00:30:36.580 --> 00:30:39.260]   validation correctly, that's the scores you should have been
[00:30:39.260 --> 00:30:42.580]   getting. If you were seeing things like 15, and that much
[00:30:42.580 --> 00:30:46.580]   lower, then there was sort of a problem. So this is just a
[00:30:46.580 --> 00:30:49.740]   roundabout way of describing the importance of why you have to
[00:30:49.740 --> 00:30:52.740]   really, really set up your local validation and make sure it's
[00:30:52.740 --> 00:30:55.740]   computing the score correctly, because at that point, moving
[00:30:55.740 --> 00:30:59.500]   forward in the competition, you just keep exploring ideas, and
[00:30:59.500 --> 00:31:03.260]   just and just evaluating them and just picking the ones that
[00:31:03.260 --> 00:31:05.580]   give you the best local validation score.
[00:31:05.580 --> 00:31:09.260]   Sanyam Bhutani: That makes sense. You also actively look
[00:31:09.260 --> 00:31:11.940]   at discussions because I saw in your solution, you pointed out
[00:31:11.940 --> 00:31:15.860]   there were leaks in some kernels that people had shared. How do
[00:31:15.860 --> 00:31:18.980]   you decide when to look at kernels? I know CPMP, he follows
[00:31:18.980 --> 00:31:21.940]   the approach where he looks at them later not to bias his
[00:31:21.940 --> 00:31:24.740]   approach that might have changed since the last time I spoke with
[00:31:24.740 --> 00:31:26.500]   him. Do you follow a similar strategy?
[00:31:26.500 --> 00:31:31.940]   Yeah, in general, in general, I'll approach a new problem. And
[00:31:31.940 --> 00:31:34.900]   I'll do it completely on my own for a week or two without
[00:31:34.900 --> 00:31:38.180]   looking at anything. That way I can you know, have an unbiased,
[00:31:38.180 --> 00:31:42.180]   I can kind of find my own approach, which is unbiased by
[00:31:42.180 --> 00:31:46.620]   things I hear. And then after I get to a point where I'm sort of
[00:31:46.620 --> 00:31:49.660]   have something decent, a lot of times I'll look online and see
[00:31:49.660 --> 00:31:51.780]   how it's comparing to what others are doing. And I'll look
[00:31:51.780 --> 00:31:55.180]   at some other approaches. That's my general strategy. Of course,
[00:31:55.180 --> 00:31:58.460]   it deviates a lot. You know, in this competition, my strategy
[00:31:58.460 --> 00:32:02.100]   was actually quite different. I would say that I would say that
[00:32:02.100 --> 00:32:05.940]   the biggest theme in this competition was how how weird
[00:32:05.940 --> 00:32:09.460]   the public leaderboard was. I mean, the public leaderboard was
[00:32:09.460 --> 00:32:13.020]   the best teams were only getting a public leaderboard of 17.5.
[00:32:13.220 --> 00:32:18.100]   Whereas, you know, accurate CVS were getting as low as 16.8. So
[00:32:18.100 --> 00:32:23.500]   there was this huge gap, almost a one gap. And it actually is a
[00:32:23.500 --> 00:32:26.980]   very, very big gap. If you do some statistical analysis
[00:32:26.980 --> 00:32:30.260]   locally, yeah. So let's just check the public leaderboard,
[00:32:30.260 --> 00:32:33.140]   you can see the top score is 17.5. Now click the button for
[00:32:33.140 --> 00:32:37.820]   the private leaderboard. You got 16.8. That's a huge difference.
[00:32:37.820 --> 00:32:42.180]   And if you do a statistical analysis, actually, that
[00:32:42.220 --> 00:32:46.460]   difference only occurs one in 100,000 or something, it's
[00:32:46.460 --> 00:32:50.140]   actually very, very rare. It turns out that something very
[00:32:50.140 --> 00:32:53.740]   rare happened here, the particular data that was chosen
[00:32:53.740 --> 00:32:55.780]   for the public leaderboard, if it came from the same
[00:32:55.780 --> 00:33:01.020]   distribution as all the data, it was a very rare subset. And I
[00:33:01.020 --> 00:33:04.860]   did some analysis early on. And since it was so rare, I was
[00:33:04.860 --> 00:33:08.340]   actually questioning whether it came from the same, whether the
[00:33:08.340 --> 00:33:11.420]   photos came from sort of the same distribution, I like many
[00:33:11.420 --> 00:33:14.700]   others, was wondering if there was something fishy with the
[00:33:14.700 --> 00:33:17.300]   test data, and if there'd be a huge shakeup. Okay, all that
[00:33:17.300 --> 00:33:20.860]   being said, that changed my approach to the problem, because
[00:33:20.860 --> 00:33:25.820]   there was this huge unknown factor between, you know, what
[00:33:25.820 --> 00:33:29.500]   will our final score be? And can we trust local validation? And
[00:33:29.500 --> 00:33:33.020]   whenever I see a huge unknown factor like this, my general
[00:33:33.020 --> 00:33:37.060]   strategy is to move towards an ensemble, because that protects
[00:33:37.060 --> 00:33:40.440]   you. You know, I could spend all day building one model and
[00:33:40.440 --> 00:33:43.620]   achieve an amazing CV score on one model, and maybe the
[00:33:43.620 --> 00:33:46.140]   leaderboard scores not so good. But I feel that's like putting
[00:33:46.140 --> 00:33:48.700]   all your eggs in one basket. If something fishy is going on,
[00:33:48.700 --> 00:33:51.900]   maybe that one model won't do so good. But when you explore an
[00:33:51.900 --> 00:33:54.940]   ensemble, that means you're trying out a whole bunch of
[00:33:54.940 --> 00:33:58.620]   different models. And you know, you try to make each one the
[00:33:58.620 --> 00:34:01.620]   best it can be. And yeah, and then you can use a technique
[00:34:01.620 --> 00:34:04.260]   called hill climbing. And the advantage of this is this
[00:34:04.260 --> 00:34:10.140]   protects against funny business or mystery in CV and LB.
[00:34:10.720 --> 00:34:15.200]   And when you do an approach like this, usually this is when I'll
[00:34:15.200 --> 00:34:18.680]   this is another this is usually frequently, I'll join a team,
[00:34:18.680 --> 00:34:21.840]   this is the best time to have a team. Because as an individual,
[00:34:21.840 --> 00:34:25.880]   it's very hard to make a diverse set of models, because everybody
[00:34:25.880 --> 00:34:29.720]   has their preferences, the ways they like to do things like the
[00:34:29.720 --> 00:34:34.520]   way general hyper parameters they use models they use styles,
[00:34:34.520 --> 00:34:37.680]   you know, it's very hard as a single individual. So in this
[00:34:37.680 --> 00:34:40.860]   competition, I actually depended heavily on public notebooks, I
[00:34:40.860 --> 00:34:45.580]   actually read nearly every public notebook. And I guess I
[00:34:45.580 --> 00:34:49.260]   read nearly every every public notebook that that was, you
[00:34:49.260 --> 00:34:53.160]   know, had had people voted up and it did well. And I actually
[00:34:53.160 --> 00:34:57.500]   I investigated each one, I downloaded nearly every one. And
[00:34:57.500 --> 00:35:01.620]   I optimized, I optimized everyone. So frequently, this is
[00:35:01.620 --> 00:35:05.100]   sort of why I discovered a lot of errors in the in the in their
[00:35:05.100 --> 00:35:09.340]   CVS. Most public notebooks had errors and how they computed CVS
[00:35:09.340 --> 00:35:12.060]   I had to correct many of them, not just the ones I I pointed
[00:35:12.060 --> 00:35:14.700]   out already, but there were others. So I would download
[00:35:14.700 --> 00:35:18.300]   them, I'd fix the CV, I would retune the model, I change a lot
[00:35:18.300 --> 00:35:21.420]   of things. And I would push each model to what I thought was the
[00:35:21.420 --> 00:35:26.980]   best. So to my, my end, my final ensemble in this solution was,
[00:35:26.980 --> 00:35:30.340]   you know, a few of my own models, but I actually used, I
[00:35:30.340 --> 00:35:33.660]   used a lot of versions of many other people, many public
[00:35:33.660 --> 00:35:38.340]   notebooks. And again, it was to protect myself against this sort
[00:35:38.340 --> 00:35:41.140]   of mystery. And I'm going to similar thing happened in
[00:35:41.140 --> 00:35:44.660]   melanoma comp, there was sort of a mystery and sort of a very
[00:35:44.660 --> 00:35:47.140]   diverse ensemble held out on top.
[00:35:47.140 --> 00:35:51.700]   I was just shitting the ensemble that you did.
[00:35:51.700 --> 00:35:55.300]   Yeah, so that's the best CV, you can see all those different
[00:35:55.300 --> 00:35:57.620]   models. And actually, if you look at my best LB ensemble, if
[00:35:57.620 --> 00:36:00.100]   you scroll down a little bit, you can see I even did some
[00:36:00.100 --> 00:36:05.180]   other ones. So I even added two more CNNs, this dense net, and
[00:36:05.180 --> 00:36:07.660]   that came from a public notebook. And then this
[00:36:07.660 --> 00:36:11.380]   inception also came from a public notebook. And actually,
[00:36:11.380 --> 00:36:14.300]   even efficient net, it started with with Robbins public
[00:36:14.300 --> 00:36:17.180]   notebook. But then I made some changes. I he originally he
[00:36:17.180 --> 00:36:21.180]   used a cat boost. As a stage two model, I changed that over to
[00:36:21.180 --> 00:36:24.180]   rapids, support vector regression, that actually gave
[00:36:24.180 --> 00:36:28.220]   me a pretty good boost. In the boat, the CV and the LB, I did
[00:36:28.220 --> 00:36:31.740]   some other changes. But you can see, with a huge diversity of
[00:36:31.740 --> 00:36:32.260]   models.
[00:36:32.260 --> 00:36:36.740]   Sanyam Bhutani: There's a question in the chat. And as a
[00:36:36.740 --> 00:36:39.940]   reminder to the audience, please keep asking the question in the
[00:36:39.940 --> 00:36:42.700]   YouTube chat. I'm actively looking at them. That's why you
[00:36:42.700 --> 00:36:46.820]   see my head rotating. But the question is, what is your
[00:36:46.820 --> 00:36:50.700]   training setup? And I'd love to extend that. How do you manage
[00:36:50.700 --> 00:36:55.660]   your ideas? How do you track your experiments? And is up do
[00:36:55.740 --> 00:36:58.780]   you set up a Docker environment? Do you use Anaconda? Because I'm
[00:36:58.780 --> 00:37:02.660]   always bombing my Nvidia CUDA setup and I have to reinstall it
[00:37:02.660 --> 00:37:03.220]   every time.
[00:37:03.220 --> 00:37:09.340]   I see. So I'm actually I'm actually very old school. So I
[00:37:09.340 --> 00:37:14.020]   actually I use a pencil and paper. And you can see those are
[00:37:14.020 --> 00:37:17.260]   my experiments. Those are some of the metrics. I've just got
[00:37:17.260 --> 00:37:23.380]   pages and pages of numbers. Pages of more numbers. Pages of
[00:37:23.380 --> 00:37:27.340]   more numbers. I might have gone through I don't know 4050 pages.
[00:37:27.340 --> 00:37:32.260]   And I just just keep writing it all down. So it's sort of old
[00:37:32.260 --> 00:37:35.820]   school. It's not it's not the most efficient thing. I've been
[00:37:35.820 --> 00:37:38.380]   people have told me about you know, these, there are some you
[00:37:38.380 --> 00:37:40.820]   write there's, I've heard of weights and biases, there's a
[00:37:40.820 --> 00:37:45.220]   bunch of public ways to actually keep track of all the
[00:37:45.220 --> 00:37:47.740]   experiments. And they have the advantage of showing you you
[00:37:47.740 --> 00:37:51.540]   know, plots and some analytical tools, which could be helpful.
[00:37:51.620 --> 00:37:54.260]   And maybe one day I'll switch over. But I've always been kind
[00:37:54.260 --> 00:37:57.100]   of a hands on again, you know, I talked about hands on earlier,
[00:37:57.100 --> 00:38:00.140]   what's more hands on than using this pencil, right? I'm kind of
[00:38:00.140 --> 00:38:04.020]   a hands on guy. So that's kind of what I do. So yeah, so as for
[00:38:04.020 --> 00:38:09.900]   experiments, I have lots of ideas. I'm running them all. I'm
[00:38:09.900 --> 00:38:13.860]   looking at I'm constantly making note of the CV scores. I'm also
[00:38:13.860 --> 00:38:18.260]   blessed to be working with Nvidia. So as a senior data
[00:38:18.260 --> 00:38:23.060]   scientist at Nvidia, you know, you know, Nvidia makes the GPU,
[00:38:23.060 --> 00:38:25.860]   right? So the company has computers, so I have access to
[00:38:25.860 --> 00:38:29.780]   computers. So specifically, I usually always have that. So I
[00:38:29.780 --> 00:38:34.700]   specifically I have access to a DGX station, which has four v
[00:38:34.700 --> 00:38:38.660]   100 GPUs. So that's, that's reserved for me, which so
[00:38:38.660 --> 00:38:41.860]   basically, I can always access that. And if I want, I could put
[00:38:41.860 --> 00:38:44.180]   in requests to try to get more machines and based on
[00:38:44.180 --> 00:38:48.620]   availability, I can potentially get more but I may or may not do
[00:38:48.620 --> 00:38:50.900]   that. In this comp, for instance, you know, I just use
[00:38:50.900 --> 00:38:55.380]   my DGX. And people said, How do you balance experiments? So I
[00:38:55.380 --> 00:38:57.780]   you know, I'm lucky to be working with a wonderful company
[00:38:57.780 --> 00:39:01.060]   and have access to GPUs. So you know, that that has four GPUs.
[00:39:01.060 --> 00:39:03.820]   So you know, I can just take an experiment and I throw it onto
[00:39:03.820 --> 00:39:07.180]   one GPU. And you know, I might run it overnight. And that's
[00:39:07.180 --> 00:39:10.740]   fine. I still have three more GPUs. Because you know, I do.
[00:39:12.820 --> 00:39:15.540]   So I you know, in video, of course, I do more than just
[00:39:15.540 --> 00:39:18.980]   gaggle. So I'm working on a lot of other projects, both
[00:39:18.980 --> 00:39:21.580]   internal, building models, analyzing data, and that
[00:39:21.580 --> 00:39:24.860]   requires GPUs. So you know, in my DGX, maybe a couple of my
[00:39:24.860 --> 00:39:28.220]   GPUs, I have to work on my other work, but I usually have some
[00:39:28.220 --> 00:39:32.340]   free GPUs. And I would say pretty much at all hours of the
[00:39:32.340 --> 00:39:36.260]   day, I'm basically even right now, for instance, I'm in a
[00:39:36.260 --> 00:39:39.940]   couple competitions. And as we speak, those GPUs are running
[00:39:39.980 --> 00:39:43.220]   and I'm running experiments. I always have some GPUs running
[00:39:43.220 --> 00:39:46.820]   experiments. When this call ends, I'll check on the results.
[00:39:46.820 --> 00:39:48.380]   I'll grab my pencil here.
[00:39:48.380 --> 00:39:55.220]   I'm very grateful to Nvidia. They also sent me an A6000,
[00:39:55.220 --> 00:39:58.300]   which is there in my machine, although I don't nearly put it
[00:39:58.300 --> 00:40:02.460]   to as any good use as you do. So I just have good things to say
[00:40:02.460 --> 00:40:08.500]   about Nvidia. Coming back to the questions, there's another one
[00:40:08.500 --> 00:40:11.780]   from the audience that fits in. What's your recipe to train
[00:40:11.780 --> 00:40:16.140]   neural networks? Any specific steps or methods that you
[00:40:16.140 --> 00:40:16.580]   follow?
[00:40:16.580 --> 00:40:21.020]   Okay, so neural networks are fun to train. So they actually
[00:40:21.020 --> 00:40:23.540]   remind so training a neural network reminds me of being a
[00:40:23.540 --> 00:40:27.940]   teacher. In the sense of training a neural network is
[00:40:27.940 --> 00:40:31.500]   like training students. You know, there's not one technique
[00:40:31.500 --> 00:40:35.100]   doesn't work for all. You have to sort of understand your
[00:40:35.100 --> 00:40:37.100]   students, you have to periodically stop and look at
[00:40:37.100 --> 00:40:41.020]   their progress. And depending on you have to sort of, so you
[00:40:41.020 --> 00:40:43.860]   have to frequently look at, you know, what are they, you know,
[00:40:43.860 --> 00:40:47.180]   frequent evaluations. In school, a teacher will give a quiz or an
[00:40:47.180 --> 00:40:49.980]   exam to see if the students are learning stuff and modify
[00:40:49.980 --> 00:40:52.300]   instruction. You have to do a similar thing with neural
[00:40:52.300 --> 00:40:54.540]   networks. You know, you train a neural network, you then have to
[00:40:54.540 --> 00:40:58.500]   look at its predictions. And you'll be surprised. You know,
[00:40:58.500 --> 00:41:01.620]   there was this other competition. It was the SETI
[00:41:01.620 --> 00:41:06.700]   competition, you had to look at, there was a, you had wave
[00:41:06.700 --> 00:41:08.940]   signals, and you had to determine if it was it was a
[00:41:08.940 --> 00:41:12.220]   classify as either an alien signal or not. Well, everybody
[00:41:12.220 --> 00:41:14.820]   converted it, everybody's using neural networks, they converted
[00:41:14.820 --> 00:41:18.340]   it to an image. And then they trained it. Well, what you
[00:41:18.340 --> 00:41:22.900]   noticed was, if you trained, if you trained, if you trained your
[00:41:22.900 --> 00:41:26.100]   neural network, and then you stopped and you and you
[00:41:26.100 --> 00:41:29.180]   evaluated the neural network with grad cam, you actually
[00:41:29.180 --> 00:41:32.380]   learned that the neural network was paying attention to the
[00:41:32.380 --> 00:41:36.740]   background. So imagine an image, which there's a bunch of noise
[00:41:36.740 --> 00:41:39.780]   and what have you because it's it's basically all of the all of
[00:41:39.780 --> 00:41:42.660]   the sort of wave signals in the air, which is just sort of noise.
[00:41:42.660 --> 00:41:45.900]   And there might be one strong white line, which represents
[00:41:45.900 --> 00:41:49.260]   some signal we're searching for. But yeah, oh, great. Wow, you're
[00:41:49.260 --> 00:41:54.220]   good at finding posts. Yeah, so here's grad cam, right? So you
[00:41:54.220 --> 00:41:56.980]   can actually see what you know, what's what's grad cam learning.
[00:41:56.980 --> 00:42:00.700]   And in these cases, this is good. So in this situation, this
[00:42:00.700 --> 00:42:03.860]   plot shows that the that the model is actually looking at the
[00:42:03.860 --> 00:42:07.260]   signal, those little lines are indeed the alien signal, the
[00:42:07.260 --> 00:42:11.260]   fake alien signal. This is good. Now, this is the result of
[00:42:11.260 --> 00:42:18.060]   training with mixup. So mixup constantly, you know, takes it
[00:42:18.060 --> 00:42:21.500]   cuts, you know, it takes multiple images and cuts a piece
[00:42:21.500 --> 00:42:25.420]   of one image, or sorry, no, it actually blends two images
[00:42:25.940 --> 00:42:30.180]   together. And the advantages, it's sort of it basically, if
[00:42:30.180 --> 00:42:32.660]   you have a signal in one image in a different background than
[00:42:32.660 --> 00:42:35.260]   another image, then it essentially blends them and then
[00:42:35.260 --> 00:42:38.740]   it superimposes this signal on this background. So when you
[00:42:38.740 --> 00:42:42.420]   train with mixup, you actually start to randomly change the
[00:42:42.420 --> 00:42:45.300]   background. So the model can no longer pay attention to
[00:42:45.300 --> 00:42:48.420]   background. Well, anyway, if you do grad cam on a model that was
[00:42:48.420 --> 00:42:51.580]   trained without mixup, you'll actually notice the model
[00:42:51.580 --> 00:42:54.060]   actually starts looking at the background and not the signal.
[00:42:54.260 --> 00:43:01.220]   You know, it says, Oh, you know, a frequent example, commonly
[00:43:01.220 --> 00:43:04.700]   used is, there was a thing where they were classifying dogs and
[00:43:04.700 --> 00:43:08.780]   cats. And the cats were sitting on pictures of cars. And the
[00:43:08.780 --> 00:43:13.900]   dogs were, say, sitting on a picture of a boat, a weird
[00:43:13.900 --> 00:43:17.100]   example, right? And then you train your model, and the model
[00:43:17.100 --> 00:43:20.100]   was achieving 99% accuracy. Well, what was the model doing?
[00:43:20.100 --> 00:43:23.340]   Whenever the model saw a car, it said cat, whenever the model
[00:43:23.340 --> 00:43:26.540]   saw a boat, it said dog. The point is, the model was looking
[00:43:26.540 --> 00:43:31.580]   at the background, not not the actual animal. And, and you only
[00:43:31.580 --> 00:43:35.260]   so is the long answer for how do you train a neural network, but
[00:43:35.260 --> 00:43:39.380]   you have to you have to carry out periodically, check to see
[00:43:39.380 --> 00:43:42.420]   what is your neural network learning? Is your neural network
[00:43:42.420 --> 00:43:45.860]   learning the signal? Or is it learning a spurious background?
[00:43:45.860 --> 00:43:49.380]   And what mistakes is it making? Look at look at the OS? What
[00:43:49.380 --> 00:43:52.500]   mistakes does it make? What does it get good? So you sort of,
[00:43:52.700 --> 00:43:55.500]   you have to just like working with a student, you have to
[00:43:55.500 --> 00:43:58.820]   analyze how your neural networks doing, and then that will inform
[00:43:58.820 --> 00:44:02.980]   you how to train the train the change, change the training. If
[00:44:02.980 --> 00:44:05.220]   it's focusing too much on the background, let's do something
[00:44:05.220 --> 00:44:09.220]   to remove that. If it's, um, if it's not, if it's making a whole
[00:44:09.220 --> 00:44:12.620]   bunch of errors, every time the image is blue, well, let's
[00:44:12.620 --> 00:44:16.020]   consider, you know, some data augmentation, changing the
[00:44:16.020 --> 00:44:19.660]   color. So you basically look at its mistakes, the same way you'd
[00:44:19.660 --> 00:44:22.500]   work with a student and then think, how could you how could
[00:44:22.500 --> 00:44:25.820]   you change the training process, so that you know, you'll avoid
[00:44:25.820 --> 00:44:28.420]   these mistakes, and that'll it'll do more of what it's doing.
[00:44:28.420 --> 00:44:28.940]   That's good.
[00:44:28.940 --> 00:44:34.700]   I wanted to point out an example of this. So you can do something
[00:44:34.700 --> 00:44:37.700]   called channel shuffle, where it basically changes the color and
[00:44:37.700 --> 00:44:40.500]   an RGB shift, basically what Chris was saying.
[00:44:40.500 --> 00:44:43.900]   Yeah, yeah, these are very, these are very effective
[00:44:43.900 --> 00:44:47.420]   techniques. So that was called a high level of how you train a
[00:44:47.420 --> 00:44:50.340]   neural network. Obviously, there's small choices of just
[00:44:50.340 --> 00:44:53.460]   hyper parameters, learning rates, batch sizes, and there I
[00:44:53.460 --> 00:44:56.700]   just kind of file, follow a standard procedure, you know,
[00:44:56.700 --> 00:45:00.940]   pick a few, look at your local validation score. And then you
[00:45:00.940 --> 00:45:03.540]   know, try it, try a few different learning rates, maybe
[00:45:03.540 --> 00:45:06.620]   go twice as large, half as large, try a few learning
[00:45:06.620 --> 00:45:11.660]   schedules. So I just sort of do somewhat of a, you know, in a
[00:45:11.660 --> 00:45:15.340]   formed grid grid search, you just a little trial and error.
[00:45:16.500 --> 00:45:21.260]   And then just kind of find hyper parameters that way. But you
[00:45:21.260 --> 00:45:24.020]   still have to observe the high level of your neural network.
[00:45:24.020 --> 00:45:25.940]   That's how you're going to win gold medals, you have to
[00:45:25.940 --> 00:45:28.980]   understand what is your neural network doing well, what is it
[00:45:28.980 --> 00:45:32.620]   doing poorly? And how can I train change the training, maybe
[00:45:32.620 --> 00:45:36.460]   it's data augmentation, maybe it's, you know, cut mix or mix
[00:45:36.460 --> 00:45:42.860]   up, maybe it's, maybe it's, you know, changing the sample
[00:45:42.860 --> 00:45:45.660]   weights, maybe it's not seeing the signal, because maybe it's
[00:45:45.660 --> 00:45:48.140]   not finding the fraudulent credit card transaction,
[00:45:48.140 --> 00:45:51.380]   because only point 1% are fraudulent. So we need to up
[00:45:51.380 --> 00:45:53.660]   sample, I mean, you have to sort of see what it's doing and not
[00:45:53.660 --> 00:45:56.620]   doing, and then sort of change the training procedure.
[00:45:56.620 --> 00:46:00.620]   That makes sense. Thank you. Thank you for that answer. Now,
[00:46:00.620 --> 00:46:03.420]   I'd love to transition into your solution. So if you could
[00:46:03.420 --> 00:46:07.020]   share a highlight of it, or talk around the solution that
[00:46:07.020 --> 00:46:10.900]   that's cool. Maybe I'll just have you if you since you have
[00:46:10.900 --> 00:46:13.260]   already set up a share screen, maybe you can just pull up my
[00:46:13.300 --> 00:46:16.140]   solution there. I have a discussion post, we can just
[00:46:16.140 --> 00:46:16.860]   work from there.
[00:46:16.860 --> 00:46:22.980]   Oh, great, great. Yeah, well, just let's just do this. So
[00:46:22.980 --> 00:46:25.060]   we'll just I'll just ask you to scroll. So we'll start here.
[00:46:25.060 --> 00:46:28.740]   Yeah, so we already discussed so okay. So here's the comp, we
[00:46:28.740 --> 00:46:31.340]   already discussed sort of my motivation for joining. I think
[00:46:31.340 --> 00:46:34.980]   it's a I think it's a really great comp helpful for pets.
[00:46:34.980 --> 00:46:40.980]   It's a it's a fun comp. Early on, we already discussed, I
[00:46:40.980 --> 00:46:43.700]   noticed that there was so the very first step I do in every
[00:46:43.700 --> 00:46:47.260]   comp is I build a local validation. And then maybe
[00:46:47.260 --> 00:46:50.780]   actually, if you can scroll down a little, I think. Perfect,
[00:46:50.780 --> 00:46:53.900]   perfect, right there. Yeah, so the very early on, I just set up
[00:46:53.900 --> 00:46:57.900]   a local validation, I start computing some scores. And
[00:46:57.900 --> 00:47:00.380]   actually, one of the earliest things you do in a competition
[00:47:00.380 --> 00:47:03.300]   is you need to make a submission. And that'll show
[00:47:03.300 --> 00:47:06.860]   you, you know, is the public leaderboard score the same as
[00:47:06.860 --> 00:47:10.500]   your local validation. And in this comp, it was not. So in
[00:47:10.500 --> 00:47:15.420]   some comps, so currently, I'm also in this. It's a it's an NLP
[00:47:15.420 --> 00:47:20.700]   comp with student writing. And it's turning out that the CV
[00:47:20.700 --> 00:47:24.060]   score and the LB score are literally one in the same. So
[00:47:24.060 --> 00:47:27.460]   some comps, you compute a local CV, you submit it. I mean, I if
[00:47:27.460 --> 00:47:31.740]   I increase my CV by point 001, the LB in that comp point 001. I
[00:47:31.740 --> 00:47:34.780]   mean, it's perfect. It's perfect. So that's an ideal
[00:47:34.780 --> 00:47:37.380]   situation. But you need to know what you're dealing with. So in
[00:47:37.380 --> 00:47:40.220]   this comp, I make a submission. And right away, there was a
[00:47:40.220 --> 00:47:42.860]   big difference. And then if you want to explore that, you can do
[00:47:42.860 --> 00:47:45.700]   some statistical analysis to see if the difference if the
[00:47:45.700 --> 00:47:50.780]   distance is explained by, you know, the leaderboard being a
[00:47:50.780 --> 00:47:55.020]   subset, or is the difference explained by the leaderboard is
[00:47:55.020 --> 00:47:57.420]   potentially different data, that's an important thing to
[00:47:57.420 --> 00:48:00.620]   evaluate. If you think the test data is different than your
[00:48:00.620 --> 00:48:04.100]   training data, you approach the competition different than if
[00:48:04.100 --> 00:48:07.180]   you think the test data comes from the same distribution, the
[00:48:07.180 --> 00:48:10.020]   train data, that is super, super important. I will stress
[00:48:10.020 --> 00:48:13.020]   that early on in the comp, you need to discover that that
[00:48:13.020 --> 00:48:15.660]   changes the whole way you approach the comp. And in this
[00:48:15.660 --> 00:48:18.460]   comp, it was unclear from the get go, there was evidence to
[00:48:18.460 --> 00:48:21.780]   support that the test data may actually be different than the
[00:48:21.780 --> 00:48:24.540]   training data. And that's why I told you early on, I sort of
[00:48:24.540 --> 00:48:28.980]   went with the route of an ensemble to a and go through LB
[00:48:28.980 --> 00:48:31.460]   probing, I tried to sort of explore the nature of the
[00:48:31.460 --> 00:48:35.140]   difference. I didn't get too far. But I did I did decide to
[00:48:35.140 --> 00:48:35.980]   go ensemble.
[00:48:38.580 --> 00:48:41.740]   Sanyam Bhutani: Is there ever a doubt when you're selecting some
[00:48:41.740 --> 00:48:42.060]   model?
[00:48:42.060 --> 00:48:45.260]   Chris Bounds: Oh, no, I have no doubt. I almost at the last
[00:48:45.260 --> 00:48:49.220]   second, I almost unselected that one. The reason is, you might
[00:48:49.220 --> 00:48:52.260]   say, well, Chris, you're always saying trust your CV, you're
[00:48:52.260 --> 00:48:54.780]   people say I'm a big advocate, why would I doubt? I'll tell
[00:48:54.780 --> 00:49:00.260]   you why I doubt. You trust your CV, when you believe the test
[00:49:00.260 --> 00:49:05.220]   data is the same as the training data. In that situation, your CV
[00:49:05.220 --> 00:49:10.660]   is the absolute best choice. Now, if you think that Kaggle
[00:49:10.660 --> 00:49:14.860]   has used a different test data than the training data, like
[00:49:14.860 --> 00:49:18.140]   let's say the test data had no pictures of dogs and cats. Let's
[00:49:18.140 --> 00:49:20.220]   say the test data, we can't see the test data, it's hidden.
[00:49:20.220 --> 00:49:25.620]   Let's say the test data is all pictures of hamsters and pet
[00:49:25.620 --> 00:49:30.580]   turtles. So if the test data is radically different than the
[00:49:30.580 --> 00:49:34.220]   training data, you have to start trusting the LB because at that
[00:49:34.220 --> 00:49:37.860]   point, the leaderboard score becomes more meaningful because
[00:49:37.860 --> 00:49:41.460]   the local validation score is on the dogs and cats. So you have
[00:49:41.460 --> 00:49:44.020]   to sort of make that decision call. And also, there's an in
[00:49:44.020 --> 00:49:46.860]   between some people you've heard of a formula, you take your
[00:49:46.860 --> 00:49:50.780]   leaderboard score, multiply by 20%, you know, plus your CV
[00:49:50.780 --> 00:49:54.540]   score, multiply by 80%. And you find the model that maximizes
[00:49:54.540 --> 00:49:59.740]   that. So in this comp, I did some analysis. And I actually
[00:49:59.740 --> 00:50:02.460]   somewhat believed that there was something fishy with the
[00:50:02.460 --> 00:50:06.540]   leaderboard. And that being said, I almost chose two
[00:50:06.540 --> 00:50:11.540]   different best LB subs. I had another LB sub, which was a
[00:50:11.540 --> 00:50:16.540]   ranked 40th. I felt it was highly diverse for my other LB
[00:50:16.540 --> 00:50:20.140]   sub. And I almost chose those two. Had I done that I would not
[00:50:20.140 --> 00:50:24.700]   have gotten gold. And part of the reason was I said, you know,
[00:50:24.700 --> 00:50:27.500]   this there's something strange going on here. But hey, I'm
[00:50:27.500 --> 00:50:30.860]   always tell people and trust your CV. I can't you know, do
[00:50:30.860 --> 00:50:34.220]   that lose and then all of a sudden do a discussion post and
[00:50:34.220 --> 00:50:38.140]   say, Hey, guys, you know, just like you all I couldn't do it.
[00:50:38.140 --> 00:50:41.820]   So I kind of in the end, stuck with the CV because I'm
[00:50:41.820 --> 00:50:44.140]   advocating that and once again, you know, it's never it's
[00:50:44.140 --> 00:50:46.540]   actually never let me down. So I'm glad I did.
[00:50:46.540 --> 00:50:51.580]   Sanyam Bhutani: It's for newbies or like people like me
[00:50:51.580 --> 00:50:56.420]   who have a vague idea but are not good at it. How can we set
[00:50:56.420 --> 00:50:57.340]   up a good CV?
[00:51:00.020 --> 00:51:05.020]   So the the base of the the de facto, the default CV is
[00:51:05.020 --> 00:51:09.300]   something called the crash cross validation, which is, you know,
[00:51:09.300 --> 00:51:12.700]   you're given training data, and then you got to split it into
[00:51:12.700 --> 00:51:15.540]   folds. So really, the only decision you know, you have to
[00:51:15.540 --> 00:51:18.100]   make locally is sort of how you break up the folds. And this you
[00:51:18.100 --> 00:51:21.580]   have to be careful of, you know, if there's users involved, or if
[00:51:21.580 --> 00:51:25.580]   certain test data is related to other test data, then you want
[00:51:25.580 --> 00:51:28.420]   to keep all of those examples say together in the same fold,
[00:51:28.420 --> 00:51:31.660]   that's something called a group fold. There's also things like
[00:51:31.660 --> 00:51:35.060]   stratified. I personally I think it's a little bit overused on
[00:51:35.060 --> 00:51:39.540]   Kaggle. It's particularly useful if you have rare targets, you
[00:51:39.540 --> 00:51:41.940]   know, for instance, let's say a target only occurs, let's say
[00:51:41.940 --> 00:51:46.460]   you're doing a multi label problem, and one of the targets
[00:51:46.460 --> 00:51:49.140]   only occurs, you know, point 1%. So they're very, very
[00:51:49.140 --> 00:51:51.860]   infrequent, what you want to make sure that every fold has at
[00:51:51.860 --> 00:51:55.420]   least some of them. And then you use the stratification and that
[00:51:55.420 --> 00:51:58.860]   forces that every fold has some, but when a target is, you know,
[00:51:58.860 --> 00:52:03.500]   is when you have, you know, 50% positive 50% negatives, there's
[00:52:03.500 --> 00:52:07.020]   no need to stratify, you just do a random split, it's fine. So
[00:52:07.020 --> 00:52:09.460]   you have to kind of decide how to make your folds. And then
[00:52:09.460 --> 00:52:12.900]   from that point, and then of course, you know, make sure that
[00:52:12.900 --> 00:52:15.140]   you're computing your metrics correctly, and what have you,
[00:52:15.140 --> 00:52:18.620]   each competition has a metric, some metrics are very confusing.
[00:52:18.620 --> 00:52:24.260]   For instance, in this new, this new object detection, it's the
[00:52:24.260 --> 00:52:27.260]   Great Barrier Reef one, the metric is quite confusing, it's
[00:52:27.260 --> 00:52:31.420]   the average of F2 scores over a range of IOU. So you have to
[00:52:31.420 --> 00:52:34.220]   make sure that you implement it correctly. So make sure very
[00:52:34.220 --> 00:52:37.060]   carefully that you implement it. And then once you set your
[00:52:37.060 --> 00:52:40.740]   folds, once you implement the metric, that's, that's pretty
[00:52:40.740 --> 00:52:43.660]   much, yeah, if you go to the evaluation page here, you can
[00:52:43.660 --> 00:52:47.340]   see, let's see. Yeah, yeah, you look, so it's very complicated,
[00:52:47.340 --> 00:52:50.180]   right? It's evaluated on F2 score at different
[00:52:50.180 --> 00:52:53.340]   intersections. So they're evaluated every point oh five.
[00:52:53.340 --> 00:52:58.140]   So that means that means there's 20 evaluations between point
[00:52:58.140 --> 00:53:01.820]   three and point eight. So it actually computes 20 different
[00:53:01.820 --> 00:53:04.580]   F2 scores and then averages them and then each one's pretty
[00:53:04.580 --> 00:53:07.220]   complicated. You know, they set an IOU threshold, so it's pretty
[00:53:07.220 --> 00:53:09.340]   elaborate. So you have to make sure that you implement it
[00:53:09.340 --> 00:53:15.140]   correctly. And then then you have your local validation.
[00:53:16.500 --> 00:53:19.980]   That makes sense. Sorry for keep, I keep going on tangent,
[00:53:19.980 --> 00:53:22.580]   but I have these burning questions that I want to ask.
[00:53:22.580 --> 00:53:27.380]   Right, so you set up your validation, then I scroll down
[00:53:27.380 --> 00:53:30.060]   the next one. So this was the next, there's some big, big
[00:53:30.060 --> 00:53:33.460]   things in this comp. This was not discussed very heavily, but
[00:53:33.460 --> 00:53:36.860]   this was pretty huge, actually. So if you go to the pet finders
[00:53:36.860 --> 00:53:41.460]   website, all the images are square. But the data they gave
[00:53:41.460 --> 00:53:46.740]   you are rectangles. Right? So you want to train your model to
[00:53:46.740 --> 00:53:49.860]   basically your model, you want your model to see the images as
[00:53:49.860 --> 00:53:53.100]   they are on the website, because that's what users are saying. So
[00:53:53.100 --> 00:53:55.260]   there wasn't too much discussion. So one thing people
[00:53:55.260 --> 00:53:58.140]   noticed that fast AI was doing very, very good in this
[00:53:58.140 --> 00:54:01.260]   competition. Yeah, here's the website, you see all of them are
[00:54:01.260 --> 00:54:04.540]   square. Also, let me point out, not only are they square,
[00:54:04.540 --> 00:54:08.100]   they're not distorted, right? If you take a rectangular image,
[00:54:08.100 --> 00:54:11.420]   and you smush it to a square, you would see a cat with a very
[00:54:11.420 --> 00:54:16.300]   thin head. These cats and dogs don't have thin head. These are
[00:54:16.300 --> 00:54:20.180]   not squished squares. These are crop squares, they take a
[00:54:20.180 --> 00:54:23.740]   rectangle and they cut out a square. So that's these two
[00:54:23.740 --> 00:54:27.380]   pictures in the bottom pictures. It's when I take I you take the
[00:54:27.380 --> 00:54:30.780]   dog image and you cut out the middle square. And the top
[00:54:30.780 --> 00:54:35.620]   image, you take a rectangle and you just resize it. So most
[00:54:35.620 --> 00:54:38.820]   people didn't discuss this until there was a few, most people
[00:54:38.820 --> 00:54:42.500]   didn't discuss this. But people pointed out how fast AI was
[00:54:42.500 --> 00:54:46.980]   performing fantastic. Part of the reason fast AI and you if
[00:54:46.980 --> 00:54:49.300]   you want to go to a notebook here, you can scroll down a
[00:54:49.300 --> 00:54:51.820]   little bit, there's a link. Or you can go to the you can go to
[00:54:51.820 --> 00:54:54.180]   the code, like you can go to the code section and find the
[00:54:54.180 --> 00:55:04.100]   highest voted code. So just sort by votes, or and then here we
[00:55:04.100 --> 00:55:07.860]   go pet finder, fast AI starter. So it's one of the most popular
[00:55:08.580 --> 00:55:12.100]   notebooks. And let's scroll down to their data loader. So scroll
[00:55:12.100 --> 00:55:13.540]   down to the data loader.
[00:55:13.540 --> 00:55:17.380]   Sorry, I wanted to mention I wanted to give a shout out to
[00:55:17.380 --> 00:55:21.740]   finish. He's 18 years old. He's doing his PhD. He's a absolute
[00:55:21.740 --> 00:55:26.100]   prodigy. He completed his master's at the age of 16. He
[00:55:26.100 --> 00:55:27.300]   is a legend.
[00:55:27.300 --> 00:55:30.660]   Fantastic. Thank you. Yeah, this this notebook was very helpful
[00:55:30.660 --> 00:55:34.300]   to me. This is one of the first notebooks I used. Super
[00:55:34.300 --> 00:55:38.900]   helpful. If you scroll down, keep scrolling down to the data
[00:55:38.900 --> 00:55:40.740]   loader. So I'm more
[00:55:40.740 --> 00:55:44.140]   I was trying to click on model training. It's not jumping.
[00:55:44.140 --> 00:55:48.860]   This Yeah, right here, right here. Okay. So here's the fast
[00:55:48.860 --> 00:55:52.020]   AI data loader. And you notice they use something called you
[00:55:52.020 --> 00:55:56.740]   see the resize. So most people didn't realize this. This is not
[00:55:56.740 --> 00:56:00.940]   the same as pytorch or album mutations resize. This is not
[00:56:00.940 --> 00:56:06.260]   the same as TensorFlow resize. When fast AI says resize, they
[00:56:06.260 --> 00:56:10.860]   mean crop. If you look at the explanation of the resize, they
[00:56:10.860 --> 00:56:15.860]   actually not only is it a crop, it's a random crop. So resize
[00:56:15.860 --> 00:56:20.500]   will actually randomly. Yeah, let's see if we can see it here.
[00:56:20.500 --> 00:56:28.020]   So size and then so let's scroll down. Oh, wait, random crop. No,
[00:56:28.020 --> 00:56:30.940]   these are the these are the area. These are the
[00:56:30.940 --> 00:56:35.580]   I think the first one is what you're looking for. It just
[00:56:35.580 --> 00:56:38.060]   crops into the center. Oh, yeah, that's good. That's good.
[00:56:38.060 --> 00:56:40.380]   Yeah, that's that's what Yeah, exactly. That's a good example.
[00:56:40.380 --> 00:56:43.700]   Yeah. So when when when fast AI says resize, what they're
[00:56:43.700 --> 00:56:47.580]   actually doing is they're doing a random max square crop. So
[00:56:47.580 --> 00:56:51.940]   when the photos are rectangle, then every time it's actually
[00:56:51.940 --> 00:56:55.660]   choosing, it's choosing the largest square because it by
[00:56:55.660 --> 00:56:59.100]   default means maintains aspect ratio, it chooses the largest
[00:56:59.100 --> 00:57:03.780]   square, it randomly picks one and then resize it to two to
[00:57:03.780 --> 00:57:06.580]   four, right, that's pretty involved. It says one word
[00:57:06.580 --> 00:57:12.180]   resize, but it's actually doing random maximum square crop.
[00:57:12.180 --> 00:57:15.980]   That's actually so not only is it resizing, it's already
[00:57:15.980 --> 00:57:19.820]   performing data augmentation, right? You're each time each
[00:57:19.820 --> 00:57:22.460]   time you choose that image, you're going to get a different
[00:57:22.500 --> 00:57:25.380]   square, maybe one time, your squares that are right, you
[00:57:25.380 --> 00:57:28.580]   only you know, you get more of the dog's head. So this was a
[00:57:28.580 --> 00:57:32.460]   huge reason that fast AI was performing so well. And you
[00:57:32.460 --> 00:57:35.660]   could and you know, people tried to duplicate people try to
[00:57:35.660 --> 00:57:39.820]   train the the swim transformer with pytorch. They were not
[00:57:39.820 --> 00:57:42.780]   duplicating the results. It wasn't until later in the last
[00:57:42.780 --> 00:57:46.780]   few weeks that one of the one user published the pytorch
[00:57:46.780 --> 00:57:50.100]   notebook that actually that actually mimic the fast AI
[00:57:50.100 --> 00:57:53.300]   performance. And the reason they were able to accomplish that is
[00:57:53.300 --> 00:57:58.500]   they actually correctly did this data loader, you know, instead
[00:57:58.500 --> 00:58:01.380]   of squishing the image, they did random square crops. And then
[00:58:01.380 --> 00:58:04.020]   this technique improves all models. For example, when I
[00:58:04.020 --> 00:58:06.860]   would download, you know, other CNN models, one of the first
[00:58:06.860 --> 00:58:12.740]   thing I changed is I changed the resize line to a random crop.
[00:58:12.740 --> 00:58:17.180]   And that immediately boosted all the CVS because I mean, yeah, I
[00:58:17.180 --> 00:58:20.580]   mean, look how funny that top image looks. I mean, who's
[00:58:20.580 --> 00:58:25.180]   gonna click on that skinny dog? So yeah, if you squeeze the
[00:58:25.180 --> 00:58:27.660]   images, they're not gonna be clicked on. So, you know,
[00:58:27.660 --> 00:58:30.820]   getting that getting the pre process to correct was was was
[00:58:30.820 --> 00:58:33.860]   pretty key in this comp, and help really help the models.
[00:58:33.860 --> 00:58:38.660]   That makes sense. Thank you. Continuing further.
[00:58:38.660 --> 00:58:44.380]   Yeah, so the next thing, as I said earlier, I was inspired by
[00:58:44.420 --> 00:58:48.300]   Dieter's win in landmark where he was both, both a
[00:58:48.300 --> 00:58:51.300]   convolutional neural networks and image transformers. So
[00:58:51.300 --> 00:58:55.620]   likewise, I wanted to use both here. So I didn't end up fusing
[00:58:55.620 --> 00:58:58.060]   them together, it turned out in this comp that sort of simple
[00:58:58.060 --> 00:59:01.340]   models were doing better, better, and actually low
[00:59:01.340 --> 00:59:03.900]   resolutions, we're doing very, very good. I mean, the idea is,
[00:59:03.900 --> 00:59:08.220]   you know, I think, you know, the reason someone clicks an image
[00:59:08.220 --> 00:59:12.100]   of a dog, it's not because when you zoom in on all these tiny,
[00:59:12.100 --> 00:59:16.540]   tiny pixels, you know, you see that their dog tag is silver,
[00:59:16.540 --> 00:59:20.380]   not red, you know, I think it's very high level, you could take
[00:59:20.380 --> 00:59:24.500]   the image and just blur it out. And basically, people made high
[00:59:24.500 --> 00:59:27.340]   level decisions, maybe what color is the dog, you know,
[00:59:27.340 --> 00:59:30.860]   whether it's a dog or a cat, what's the position is the face
[00:59:30.860 --> 00:59:33.660]   close up, I actually don't think you need you didn't need very,
[00:59:33.660 --> 00:59:36.300]   very high resolution. And therefore, you didn't need very
[00:59:36.300 --> 00:59:39.300]   powerful models that did all sorts of fancy stuff. So that
[00:59:39.300 --> 00:59:42.740]   being said, I ended up not using the CNNs with with image
[00:59:42.740 --> 00:59:45.940]   transformers. Nonetheless, though, each did provide a
[00:59:45.940 --> 00:59:49.380]   different perspective of looking at the image. And both did
[00:59:49.380 --> 00:59:55.180]   contribute to the solution. I was able to, you know, get CNNs
[00:59:55.180 --> 00:59:57.060]   to perform equally as transformers, which was a
[00:59:57.060 --> 01:00:00.380]   difficult thing to do. Many people weren't. One of the ways
[01:00:00.380 --> 01:00:03.380]   to help was we talked about getting the pre process, no one
[01:00:03.380 --> 01:00:06.820]   actually trained any CNNs with correctly squared images, like
[01:00:07.180 --> 01:00:09.660]   someone probably did, but a lot of the popular notebooks, you
[01:00:09.660 --> 01:00:13.620]   know, squished them, you can fix that. Also, for some reason,
[01:00:13.620 --> 01:00:18.060]   when when training a CNN on a regression task, it was quite
[01:00:18.060 --> 01:00:22.300]   finicky. So basically, you had to freeze parts of the backbone,
[01:00:22.300 --> 01:00:25.260]   maybe free the bat freeze the batch norm layers, maybe freeze
[01:00:25.260 --> 01:00:29.620]   the dropout, change the level of dropout. With the transformers,
[01:00:29.620 --> 01:00:31.700]   I didn't, I didn't see this making a difference. And I kind
[01:00:31.700 --> 01:00:33.780]   of forget, maybe the transformers don't use batch
[01:00:33.780 --> 01:00:37.060]   norm, maybe they don't, they use these that and drop out
[01:00:37.060 --> 01:00:39.420]   differently. But you didn't need really need to freeze the
[01:00:39.420 --> 01:00:44.020]   transformers. Another very powerful technique was to
[01:00:44.020 --> 01:00:48.620]   actually train the body and the head separately. So instead of
[01:00:48.620 --> 01:00:52.660]   just taking one model with a head and just training it, I was
[01:00:52.660 --> 01:00:57.860]   able to use Nvidia's support vector regression. So I actually
[01:00:57.860 --> 01:01:02.500]   would, I would train just the backbone. And then afterwards, I
[01:01:02.500 --> 01:01:06.260]   would freeze the backbone and then put those embeddings into
[01:01:06.260 --> 01:01:10.540]   the support vector regression and have a have SVR make the
[01:01:10.540 --> 01:01:13.860]   final prediction. And that was actually my most accurate CNN
[01:01:13.860 --> 01:01:17.780]   model was that there's a lot of alternatives this but the
[01:01:17.780 --> 01:01:20.860]   general idea is that you essentially you know, you can
[01:01:20.860 --> 01:01:24.460]   kind of treat the backbone in the head separately. And
[01:01:24.460 --> 01:01:26.820]   actually, if you look at the number one solution, so I
[01:01:26.820 --> 01:01:28.900]   actually trained my backbones. But if you look at the number
[01:01:28.900 --> 01:01:32.780]   one solution by Jibba, he didn't, if I hope I'm not saying
[01:01:32.780 --> 01:01:35.940]   this incorrectly, I don't think he even trained his
[01:01:35.940 --> 01:01:38.980]   backbones. So he would actually just download the backbones,
[01:01:38.980 --> 01:01:42.820]   which were already pre trained on the image nets. And then he
[01:01:42.820 --> 01:01:48.500]   just extract the embeddings. And then from there, he was able to
[01:01:48.500 --> 01:01:50.860]   take a bedding might be a you know, a vector of a bedding
[01:01:50.860 --> 01:01:54.380]   might be 1000 columns, it's an a vector of 1000 things. And from
[01:01:54.380 --> 01:02:01.540]   there, he also used a rapid support vector regression, which
[01:02:01.540 --> 01:02:05.220]   has the ability to handle huge data. So he would take, you
[01:02:05.220 --> 01:02:08.740]   know, multiple models and extract embeddings from
[01:02:08.740 --> 01:02:12.260]   multiple models, each of them themselves as 1000 columns, put
[01:02:12.260 --> 01:02:15.460]   them together, you're now talking about 10,000 of columns.
[01:02:15.460 --> 01:02:19.660]   And he would then just train all of that on a support on you
[01:02:19.660 --> 01:02:23.140]   know, a single rapid support vector regression. And you can
[01:02:23.140 --> 01:02:25.900]   see the advantage here. So he would take embeddings out of a
[01:02:25.900 --> 01:02:29.780]   CNN, he would take embeddings out of a transformer, there's,
[01:02:29.780 --> 01:02:32.260]   you know, dozens of different transformers, he would take
[01:02:32.260 --> 01:02:36.100]   embeddings out of different transformers. And each different
[01:02:36.100 --> 01:02:41.340]   model sees something different in the image. And each one of
[01:02:41.340 --> 01:02:44.860]   those different things that sees it puts in a new column. So
[01:02:44.860 --> 01:02:48.060]   jiva has this data data frame with, you know, 10s of 1000s of
[01:02:48.060 --> 01:02:50.820]   columns, which are coming from all these different models. And
[01:02:50.820 --> 01:02:54.820]   this is only using the pre training from image net, he
[01:02:54.820 --> 01:02:57.940]   didn't actually fine tune it further. And then you just train
[01:02:58.260 --> 01:03:02.340]   the rapids support vector regression on all of that. And
[01:03:02.340 --> 01:03:06.060]   it makes a prediction and that actually achieved his highest
[01:03:06.060 --> 01:03:10.300]   local CV, I think he got the CV down as low as 16.8, which is
[01:03:10.300 --> 01:03:14.900]   phenomenal. My model CV, my best CV only got as low as I think
[01:03:14.900 --> 01:03:19.980]   16.999. So he got a full point two. And if you look at his
[01:03:19.980 --> 01:03:23.100]   final leaderboard placement, he was actually he had a little bit
[01:03:23.100 --> 01:03:28.220]   of a lead over the rest. And I think it was really doing this.
[01:03:28.220 --> 01:03:31.540]   I think it was really he basically, you know, it's a
[01:03:31.540 --> 01:03:34.420]   superior way to ensemble models. It's a sort of a stacking
[01:03:34.420 --> 01:03:37.460]   approach. He didn't just take the predictions and average them.
[01:03:37.460 --> 01:03:41.460]   He essentially asked each model to tell us what are they
[01:03:41.460 --> 01:03:45.780]   observing in the images. And then he used all the models
[01:03:45.780 --> 01:03:49.380]   observations about these images, all the features, and then makes
[01:03:49.380 --> 01:03:54.020]   a final score. And that was a with a single support vector
[01:03:54.020 --> 01:03:55.780]   regression that was phenomenal.
[01:03:57.060 --> 01:03:59.140]   Sanyam Bhutani: Just wanted to point out for the audience. So
[01:03:59.140 --> 01:04:03.380]   this is from a paper by Zeller and Fergus and CNN's and I'm not
[01:04:03.380 --> 01:04:05.220]   sure if it's the same for transformers, they learn
[01:04:05.220 --> 01:04:08.620]   different things at different stages. So I think what you were
[01:04:08.620 --> 01:04:14.340]   saying, Chris, Jeeba would extract intermediate layers and
[01:04:14.340 --> 01:04:16.660]   put them into a model that goes into the SVR.
[01:04:16.660 --> 01:04:18.700]   Chris Bounds: Yeah, absolutely. And if you zoom in on that
[01:04:18.700 --> 01:04:19.900]   picture there on the right, I don't know if we have the
[01:04:19.900 --> 01:04:23.100]   ability to zoom in. But you can see how you know, and then
[01:04:23.100 --> 01:04:25.780]   scroll up upwards for people that are not familiar with that.
[01:04:25.900 --> 01:04:30.700]   Or, yeah, maybe you can't zoom in the later one. Okay. So
[01:04:30.700 --> 01:04:33.220]   people that are not familiar with CNN's in that top left
[01:04:33.220 --> 01:04:36.300]   image there with layer one, you see that the first layer of a
[01:04:36.300 --> 01:04:39.060]   CNN, it's just looking for lines, right? You've got
[01:04:39.060 --> 01:04:41.660]   diagonal lines that go from the top right, you've got some
[01:04:41.660 --> 01:04:44.860]   vertical lines, it's also analyzing color. So a CNN
[01:04:44.860 --> 01:04:47.260]   basically said, you know, that's what a CNN does. It basically
[01:04:47.260 --> 01:04:50.300]   says, Oh, I noticed there's a bunch of vertical lines, I
[01:04:50.300 --> 01:04:52.740]   noticed there's a bunch of patches of brown, I noticed
[01:04:52.740 --> 01:04:57.060]   there's a bunch of patches of white. So and then that's layer
[01:04:57.060 --> 01:05:00.740]   one. And then the the higher layers take combinations of
[01:05:00.740 --> 01:05:05.260]   those, you know, when I see a bunch of brown, surrounded by a
[01:05:05.260 --> 01:05:09.140]   bunch of white, you know, I can tell it's a, it's an animal
[01:05:09.140 --> 01:05:13.860]   with, you know, a dual tone for and then so it basically it uses
[01:05:13.860 --> 01:05:16.860]   the lower features to combine them to make higher features.
[01:05:16.860 --> 01:05:20.580]   And then at the end of the day, and now when it basically you
[01:05:20.580 --> 01:05:24.380]   could think of it as saying like, yes or no, like, yes, I
[01:05:24.380 --> 01:05:27.660]   saw a brown present. No, I didn't see a brown present. Or
[01:05:27.660 --> 01:05:31.100]   yes, I saw, you know, two eyeballs facing the camera
[01:05:31.100 --> 01:05:35.140]   because it saw it essentially recognize circles by looking at
[01:05:35.140 --> 01:05:38.900]   lines. If the if the cat was looking to the side, it didn't
[01:05:38.900 --> 01:05:43.060]   see eyeball. So the model says, Yes, I see eyeballs looking at
[01:05:43.060 --> 01:05:47.300]   the camera. The model says, you know, yes, I see this. So each
[01:05:47.300 --> 01:05:50.220]   of those columns sort of indicates, yes, I saw this. Yes,
[01:05:50.220 --> 01:05:53.060]   I saw this. Yes, I saw this. And then what the support vector
[01:05:53.060 --> 01:05:57.060]   regression does is based on what it did or did not see, it then
[01:05:57.060 --> 01:06:00.220]   makes a prediction. Oh, you saw the cat, you saw the animals
[01:06:00.220 --> 01:06:04.580]   facing the camera. Oh, you saw it was this color. Oh, you saw
[01:06:04.580 --> 01:06:08.020]   it had ears. Oh, you saw this. In this case, people are going
[01:06:08.020 --> 01:06:11.100]   to click it. In this case, people won't. And you know, he
[01:06:11.100 --> 01:06:15.900]   had 10,000 columns, that's a lot of information. And a support
[01:06:15.900 --> 01:06:18.940]   vector regression has many advantages. But one of them it
[01:06:18.940 --> 01:06:23.180]   does is as built in shrinkage, which is a feature selection. So
[01:06:23.180 --> 01:06:26.260]   by it won't be overwhelmed by all those columns, it'll
[01:06:26.260 --> 01:06:30.780]   basically it'll it'll it'll actually utilize it'll it'll
[01:06:30.780 --> 01:06:35.700]   choose the columns that it sees are most important. And that's
[01:06:35.700 --> 01:06:39.580]   very helpful. So you give it all that information, it it utilizes
[01:06:39.580 --> 01:06:42.540]   the important one and then makes a very accurate prediction.
[01:06:42.540 --> 01:06:48.700]   That makes sense. This is a question from the audience. Do
[01:06:48.820 --> 01:06:51.740]   you tune the hyper parameters? Or do you follow any approach
[01:06:51.740 --> 01:06:54.220]   there? What's your strategy around hyper parameter tuning?
[01:06:54.220 --> 01:07:00.940]   So I tuned some of them. Yeah, in general. Yeah, for each model,
[01:07:00.940 --> 01:07:04.940]   I'll pick a few to tune. I'll deem what I think are the most
[01:07:04.940 --> 01:07:07.940]   popular. You know, if we're talking, if we're talking about,
[01:07:07.940 --> 01:07:11.460]   you know, a neural network, you know, learning rate is very
[01:07:11.460 --> 01:07:16.900]   popular. I like to analyze the batch size, the number of epochs,
[01:07:17.220 --> 01:07:20.540]   things like that. If we're talking about boosted trees, you
[01:07:20.540 --> 01:07:25.900]   know, maybe I'll just tune the depth of the tree. Maybe I'll
[01:07:25.900 --> 01:07:30.220]   tune a sub sample parameter, a feature sub sample parameter,
[01:07:30.220 --> 01:07:33.940]   that's like three parameters. So personally, I think you should
[01:07:33.940 --> 01:07:37.260]   tune a few parameters. I'm not a huge advocate, you know, some
[01:07:37.260 --> 01:07:40.300]   people they'll take a model like boosted trees, and they'll tune,
[01:07:40.300 --> 01:07:42.940]   you know, 13 different parameters, I sort of think
[01:07:42.940 --> 01:07:45.380]   that's unnecessary, because in the time to do that, you can
[01:07:45.380 --> 01:07:47.820]   just create a new feature to make your model more accurate,
[01:07:47.820 --> 01:07:50.860]   or you can do something. So I would train a few that are
[01:07:50.860 --> 01:07:54.060]   important, you know, as I said, and then spend your time on
[01:07:54.060 --> 01:07:56.700]   other stuff, spend your time on, you know, data augmentation,
[01:07:56.700 --> 01:07:59.700]   spend your time on engineering new features, spend your time
[01:07:59.700 --> 01:08:03.380]   on, you know, improving the model in other ways.
[01:08:03.380 --> 01:08:08.660]   Thank you for that answer. Coming back to your solution
[01:08:08.660 --> 01:08:12.620]   continuing from here, you mentioned you put a SCR head on
[01:08:12.620 --> 01:08:14.940]   top of it, and you explain the intuition behind it.
[01:08:15.940 --> 01:08:19.420]   Yeah, and I had mentioned how so I just I just put one SBR head
[01:08:19.420 --> 01:08:23.420]   per one model. And as I said, it was able to boost my CNN model
[01:08:23.420 --> 01:08:26.300]   to be, you know, my best CNN model. And then I then I had
[01:08:26.300 --> 01:08:29.060]   mentioned how Jibba did something different. You know,
[01:08:29.060 --> 01:08:34.580]   he put one SBR head, he took multiple backbones, and then
[01:08:34.580 --> 01:08:37.580]   sort of like a stacking approach, pushed into one head.
[01:08:37.580 --> 01:08:39.500]   But yeah, I only did one head for one model.
[01:08:39.500 --> 01:08:44.580]   GY is a legend for a reason. I think the Lexus competition you
[01:08:44.580 --> 01:08:48.460]   mentioned, he also shared a different approach that you were
[01:08:48.460 --> 01:08:49.700]   completely blown away by.
[01:08:49.700 --> 01:08:52.860]   Absolutely, you know, absolutely. And I love work with
[01:08:52.860 --> 01:08:55.380]   him and other other Catalogram Masters. So I've been working at
[01:08:55.380 --> 01:08:57.940]   NVIDIA now for two years, and I'm on this team of Catalogram
[01:08:57.940 --> 01:09:01.340]   Masters. And I'll say that I have learned so much. You know,
[01:09:01.340 --> 01:09:04.860]   Jibba taught, I didn't actually understand targeting coding as
[01:09:04.860 --> 01:09:07.140]   well as I did before Jibba actually explained it to me.
[01:09:07.140 --> 01:09:08.860]   That was the one you mentioned.
[01:09:08.860 --> 01:09:12.260]   Yeah, exactly. Like, there's so many more things I was unaware
[01:09:12.260 --> 01:09:15.860]   of. You have to smooth the targeting coding, you actually
[01:09:15.860 --> 01:09:18.660]   have to apply it using a K-fold strategy. There's many, many
[01:09:18.660 --> 01:09:21.340]   things. And that was actually, you know, it was his idea using
[01:09:21.340 --> 01:09:24.820]   the targeting coding in 2020, which won the Rexus comp. But he
[01:09:24.820 --> 01:09:28.100]   showed me that. I mean, he's a master at all things. He was top
[01:09:28.100 --> 01:09:30.980]   number one for so many years. And it's, you know, there's a
[01:09:30.980 --> 01:09:34.380]   reason for that. But yeah, I mean, you know, his solution,
[01:09:34.380 --> 01:09:37.300]   it's, it doesn't surprise me that he made a beautifully
[01:09:37.300 --> 01:09:41.500]   stacked model. That's his thing. He can combine tons of models
[01:09:41.500 --> 01:09:44.300]   and not overfit. And that's what he did here. You know, he
[01:09:44.300 --> 01:09:47.700]   stacked the SBR on top many models. And that's, and that's
[01:09:47.700 --> 01:09:50.700]   actually sort of what targeting coding is targeting coding is
[01:09:50.700 --> 01:09:54.220]   actually, is actually a model in and of itself. When you take
[01:09:54.220 --> 01:09:56.740]   when you when you targeting code, you're essentially
[01:09:56.740 --> 01:09:59.540]   building a little model called a targeting coding model. That's
[01:09:59.540 --> 01:10:02.380]   why you need to be very careful. And then when you use that as a
[01:10:02.380 --> 01:10:05.380]   feature in your other model, you're essentially stacking on
[01:10:05.380 --> 01:10:08.820]   top of it. That's why it's super important to be careful to do
[01:10:08.820 --> 01:10:11.860]   targeting coding using folds and smoothing etc. Because you're
[01:10:11.860 --> 01:10:14.940]   essentially stacking. And whenever you stack, you have to
[01:10:14.940 --> 01:10:18.100]   be careful not to leak. It's very complicated. With
[01:10:18.100 --> 01:10:21.020]   validation, you have to be careful not to leave. You can't
[01:10:21.020 --> 01:10:27.900]   you know, use you can't use a target to you know, modify the
[01:10:27.900 --> 01:10:33.020]   same row, etc, etc. But yeah, he he knows how to do that. And he
[01:10:33.020 --> 01:10:36.020]   showed another. He showed it again in this comp.
[01:10:36.700 --> 01:10:38.820]   Sanyam Bhutani: Sorry for continuously going on tangents
[01:10:38.820 --> 01:10:39.820]   and distracting you.
[01:10:39.820 --> 01:10:43.180]   Unknown: Yeah, so yeah, we scroll down. So that was the
[01:10:43.180 --> 01:10:47.060]   CNN. So I also, you know, did a bunch of image, image
[01:10:47.060 --> 01:10:51.340]   transformers. And again, I say I started with some wonderful
[01:10:51.340 --> 01:10:53.900]   public notebooks, I actually started with the I love
[01:10:53.900 --> 01:10:57.900]   sciences, a fast AI notebook is fantastic. I think it was
[01:10:57.900 --> 01:11:01.140]   wonderful because it's so quick, it allowed people to dump to
[01:11:01.140 --> 01:11:05.220]   jump in so quickly. Fast AI is supported with the with the TIM
[01:11:05.220 --> 01:11:08.260]   repository. So if you want to try out a different model, you
[01:11:08.260 --> 01:11:11.340]   just change one word, that's it one word, you know, instead of
[01:11:11.340 --> 01:11:17.700]   using SWIN 224 large, you know, you could just you can change
[01:11:17.700 --> 01:11:20.700]   you can use this other transformers bit. And what's
[01:11:20.700 --> 01:11:24.340]   really cool, I say it right here. But um, so you know, if
[01:11:24.340 --> 01:11:28.300]   you import TIM, and then you write TIM list models, pre
[01:11:28.300 --> 01:11:32.460]   trained equals true, it gives you a list and TIM is fantastic.
[01:11:32.500 --> 01:11:34.140]   You have to scroll a lot.
[01:11:34.140 --> 01:11:38.980]   Oh, yeah. I mean, it's I don't know 1000 models. There's just
[01:11:38.980 --> 01:11:42.740]   too many models, right. But it's awesome. He's got he as soon as
[01:11:42.740 --> 01:11:45.620]   I mean, he's got models that have just been released. You
[01:11:45.620 --> 01:11:49.380]   know, within the last month, he's, he's, uh, he keeps it
[01:11:49.380 --> 01:11:53.860]   super, super up to date. Um, you know, he I think he does a lot
[01:11:53.860 --> 01:11:55.980]   of the pre training himself or he finds pre trained look
[01:11:55.980 --> 01:11:59.900]   already look at this already. Yeah, complex. I mean, it just
[01:11:59.900 --> 01:12:02.460]   came out, he's already adding it. And then what does that mean
[01:12:02.460 --> 01:12:05.700]   for us for the end user, that means we just change one word,
[01:12:05.700 --> 01:12:09.020]   you know, we have some code, and then we just change import
[01:12:09.020 --> 01:12:12.580]   coven, we just change, you know, import swim to import cov next.
[01:12:12.580 --> 01:12:16.860]   And then, you know, fast AI is nice. Basically, the rest of the
[01:12:16.860 --> 01:12:19.980]   pipeline is pretty robust. It can self a J, it could pick a
[01:12:19.980 --> 01:12:24.340]   learning rate, it could be a learning rate. As I said, it did
[01:12:24.340 --> 01:12:27.020]   a bunch of other things. So you could try all these different
[01:12:27.020 --> 01:12:30.820]   transformers by changing one word. And once you once you get
[01:12:30.820 --> 01:12:34.580]   the CV to print out correctly, you can just see what's good.
[01:12:34.580 --> 01:12:37.780]   And I did this, you know, as I said, you know, the compass
[01:12:37.780 --> 01:12:41.740]   three months every night, every night, I had some extra GPUs, I
[01:12:41.740 --> 01:12:47.660]   would just change the word, I would, I would keep notes here.
[01:12:47.660 --> 01:12:50.260]   And you know, I was super excited the morning I woke up
[01:12:50.260 --> 01:12:54.620]   with the bit so that the bit transformer, it actually it's a
[01:12:54.620 --> 01:12:58.060]   it's novelty is the way it's pre trained. So it's actually a
[01:12:58.060 --> 01:13:02.180]   semi semi super, it has a, an unsupervised way of preaching
[01:13:02.180 --> 01:13:05.260]   training the same way you pre trained Bert, but you show it
[01:13:05.260 --> 01:13:08.500]   images, then you hide parts of the images, and then you sort of
[01:13:08.500 --> 01:13:12.140]   ask the model to generate those parts of the images. So it has a
[01:13:12.140 --> 01:13:15.900]   it's quite diverse pre training from other transformers. And as
[01:13:15.900 --> 01:13:20.420]   such, you know, it was one of my best TV scores. But I should say
[01:13:20.420 --> 01:13:23.980]   this is very, very important to people. If you're building
[01:13:23.980 --> 01:13:27.140]   ensemble, so if you chose early on that ensembles your approach
[01:13:27.140 --> 01:13:32.500]   because of reasons we discussed, it's not so important than the
[01:13:32.500 --> 01:13:36.140]   CV score of an individual model. That's not that's not the most
[01:13:36.140 --> 01:13:39.780]   important thing. The most important thing is, yeah, so
[01:13:39.780 --> 01:13:44.780]   here's the the describing some of the model and the pre
[01:13:44.780 --> 01:13:47.900]   training. So the most important thing when you're building an
[01:13:47.900 --> 01:13:52.140]   ensemble, it's not how accurate is the new model, the most
[01:13:52.140 --> 01:13:57.660]   important thing is, let me add it to my existing collection of
[01:13:57.660 --> 01:14:03.180]   models. And let me see if the addition improves the overall
[01:14:03.180 --> 01:14:07.260]   CV. Right. So for instance, the VIT transformer, VIT
[01:14:07.260 --> 01:14:10.900]   transformer, it had a great it had a great CV score, I added it
[01:14:10.900 --> 01:14:16.540]   to my collection of models. The CV score got worse. So yeah, the
[01:14:16.540 --> 01:14:20.340]   VIT was doing good by itself. But did the VIT add diversity to
[01:14:20.340 --> 01:14:23.100]   the models? No, it didn't. It means the other models were
[01:14:23.100 --> 01:14:26.660]   already the other models were already seeing whatever the VIT
[01:14:26.660 --> 01:14:32.140]   saw. Now, let's talk about the the bit the VIT. This model,
[01:14:32.140 --> 01:14:36.580]   again, had a good CV score. I added it to the ensemble. And
[01:14:36.580 --> 01:14:40.580]   then boom, the CV score, you know, improved point one, I was
[01:14:40.580 --> 01:14:43.900]   like, Whoa, so there you have it. That's the hill climbing for
[01:14:43.900 --> 01:14:47.980]   you. When you build an ensemble. And frequently, you know, this
[01:14:47.980 --> 01:14:52.100]   will surprise people. You might build a model that has a
[01:14:52.100 --> 01:14:57.060]   terrible CV. This happened in a in a in melanoma comp, somebody
[01:14:57.060 --> 01:15:01.820]   made a tabular model just from metadata, the CV was terrible.
[01:15:01.820 --> 01:15:05.940]   However, you add it to an ensemble, and it shot the and
[01:15:05.940 --> 01:15:10.260]   improve the CV so much. The point is, the new model has to
[01:15:10.260 --> 01:15:15.500]   have information that the ensemble doesn't. So if the new
[01:15:15.500 --> 01:15:19.300]   model uses new features has a new type of pre training, maybe
[01:15:19.300 --> 01:15:22.500]   has access to new types of metadata, maybe was trained in a
[01:15:22.500 --> 01:15:26.420]   new way, maybe it was trained with new types of augmentation,
[01:15:26.420 --> 01:15:30.620]   the new model does something different. And it has a new
[01:15:30.620 --> 01:15:33.980]   perspective on what the prediction should be. And then
[01:15:33.980 --> 01:15:38.180]   you add it to your other models. And when I say add it, I don't
[01:15:38.180 --> 01:15:41.820]   mean give it, you know, 1%. I mean, you know, add it if you've
[01:15:41.820 --> 01:15:44.660]   if you already have five models, then you know, add it as a six
[01:15:44.660 --> 01:15:48.220]   model and add them all up and divide by six, you know, added
[01:15:48.220 --> 01:15:52.020]   in pretty significantly. And let's see, does it help your CV
[01:15:52.020 --> 01:15:56.740]   score or hurt your CV score. And I added the BIT one morning, it
[01:15:56.740 --> 01:16:00.900]   bumped my score. And actually, believe it or not, I made a
[01:16:00.900 --> 01:16:03.220]   submission to the leaderboard. And it bumped me the same much
[01:16:03.220 --> 01:16:06.180]   on leaderboard. So you know, people said things like CV and
[01:16:06.180 --> 01:16:09.860]   leaderboard didn't correlate. But for the most part, I would
[01:16:09.860 --> 01:16:13.740]   say, you know, 80% of the things that were helping me locally, I
[01:16:13.740 --> 01:16:15.500]   would then submit to the leaderboard and they helped me
[01:16:15.500 --> 01:16:19.380]   there was still, you know, 20% mystery, some things that didn't
[01:16:19.380 --> 01:16:23.100]   help me on local CV, I said, Well, I'll, you know, I'll add
[01:16:23.100 --> 01:16:27.300]   it to my LB ensemble, and I'll submit it and I did an improved
[01:16:27.300 --> 01:16:30.380]   leaderboard. So there were some models that I had two ensembles,
[01:16:30.380 --> 01:16:33.980]   I had my, my, my local CV ensemble, and I only added
[01:16:33.980 --> 01:16:36.260]   models, which helped it. And then I had a collection of
[01:16:36.260 --> 01:16:41.060]   models called my LB by best LB ensemble. And the same way, I
[01:16:41.060 --> 01:16:43.460]   would add a new model. And then I would submit it to the
[01:16:43.460 --> 01:16:46.100]   leaderboard. So I was basically building two subsets of models,
[01:16:46.100 --> 01:16:49.660]   and they became different. The dense net and the inception
[01:16:49.660 --> 01:16:52.300]   models that helped the leaderboard, they did not help
[01:16:52.300 --> 01:16:56.060]   my CV model, I just kept my two collections different. And then
[01:16:56.060 --> 01:16:58.580]   those are my Yeah, you see these are my two collections. And
[01:16:58.580 --> 01:17:04.300]   those are my those are my final two submissions. You can see
[01:17:04.300 --> 01:17:06.540]   actually keep right here, you can see something I did right
[01:17:06.540 --> 01:17:08.980]   here. I did this. This was the last night when I pulled the
[01:17:08.980 --> 01:17:12.220]   all nighter, you can look at my best CV model, I've got the
[01:17:12.220 --> 01:17:17.100]   covenex 384 with the dog cat auxiliary output, super excited
[01:17:17.100 --> 01:17:20.180]   about this. So I tried a lot to use the metadata in this
[01:17:20.180 --> 01:17:23.500]   competition, I wasn't able to actually get any benefit using
[01:17:23.500 --> 01:17:29.820]   the better metadata. There was someone who posted a data set.
[01:17:29.820 --> 01:17:33.580]   And I think he mostly maybe hand labeled every image in the
[01:17:33.580 --> 01:17:36.380]   training data, whether it was a dog or cat, or maybe he used the
[01:17:36.380 --> 01:17:38.980]   model, but I think he said he confirmed it by looking visually
[01:17:38.980 --> 01:17:43.740]   inspecting them. So I actually what I did was, I gave that as
[01:17:43.740 --> 01:17:48.540]   an auxiliary training task. So the thing is, here's a nice trick
[01:17:48.540 --> 01:17:52.140]   that people can use. If you have information about your training
[01:17:52.140 --> 01:17:55.860]   data that you do not have for the test data, well, you could
[01:17:55.860 --> 01:17:59.980]   still use that to help training, but you don't add it as an input,
[01:17:59.980 --> 01:18:03.340]   because we won't have it for the test data to input. So what you
[01:18:03.340 --> 01:18:07.220]   do is you use it as an output. So when you train your model,
[01:18:07.260 --> 01:18:10.900]   you train your model to predict two things, your model will
[01:18:10.900 --> 01:18:15.100]   predict the popularity, which is the probability of click and
[01:18:15.100 --> 01:18:18.860]   your model also predicts whether it's a cat or a dog.
[01:18:18.860 --> 01:18:23.580]   And then you can do a regression or just back propagate through
[01:18:23.580 --> 01:18:25.100]   that since you have the labels for that.
[01:18:25.100 --> 01:18:28.060]   Well, exactly. So I actually I use two different losses. So
[01:18:28.060 --> 01:18:32.220]   they're both back propagated separately. So you calculate the
[01:18:32.220 --> 01:18:35.620]   popularity score, and you back propagate that error, and you
[01:18:35.620 --> 01:18:39.100]   calculate dog and cat, and you back propagate that. And this is
[01:18:39.100 --> 01:18:42.300]   analogous to many things in life, right? If you're trying to,
[01:18:42.300 --> 01:18:46.060]   you know, be a better tennis player, maybe you train someone
[01:18:46.060 --> 01:18:49.340]   to, hey, go ahead and every once in a while, take three balls and
[01:18:49.340 --> 01:18:51.980]   just juggling with your hands. I mean, you teach somebody to do a
[01:18:51.980 --> 01:18:56.140]   new task. And, you know, different tasks can still help.
[01:18:56.140 --> 01:19:01.460]   And you try this out. And sure enough, when I added the dog cat
[01:19:01.460 --> 01:19:05.660]   as an auxiliary output, it boosted the CV a little bit. But
[01:19:05.660 --> 01:19:09.180]   even more significantly, like I said earlier, when I added it to
[01:19:09.180 --> 01:19:12.700]   the ensemble, it boosted the ensemble. The point is, it's a
[01:19:12.700 --> 01:19:18.580]   different model, right? It's the model was trained to be looking
[01:19:18.580 --> 01:19:22.180]   at the animal, maybe the other model didn't, but this model was
[01:19:22.180 --> 01:19:24.980]   looking is it a dog? Is it a cat? Is it so the model was
[01:19:24.980 --> 01:19:28.140]   diverse. And then when I added it to the ensemble, it boosted
[01:19:28.140 --> 01:19:32.900]   the score. And that that model boosted both the CV and the LB.
[01:19:32.900 --> 01:19:35.380]   And I discovered either the last night, maybe it was the second
[01:19:35.380 --> 01:19:39.940]   to last night, before the comp ended. I don't like to work last
[01:19:39.940 --> 01:19:44.860]   second, but I did it and improve the models and I had time to
[01:19:44.860 --> 01:19:45.900]   time to include it.
[01:19:45.900 --> 01:19:49.540]   Sanyam Bhutani: That makes sense. I can only imagine the
[01:19:49.540 --> 01:19:56.620]   adrenaline rush you would be having at that point. Awesome. I
[01:19:56.620 --> 01:19:59.140]   think only this portion is left things that didn't work.
[01:19:59.140 --> 01:20:03.660]   Yeah, so one thing I tried very often was, you know, we had
[01:20:03.660 --> 01:20:06.700]   tons of data from last year's comp, which means you know, we
[01:20:06.700 --> 01:20:11.980]   had, I forget was it 1000s of 1000s of more pet images. So I
[01:20:11.980 --> 01:20:15.500]   thought surely, um, you know, somehow this should be able to
[01:20:15.500 --> 01:20:19.300]   improve the model because fundamentally, the model, it
[01:20:19.300 --> 01:20:22.700]   needs to look at images of animals. So the more images you
[01:20:22.700 --> 01:20:25.220]   can show it, even if they have different labels could help. And
[01:20:25.220 --> 01:20:27.340]   the idea, one of the ideas, the way you do this is you would
[01:20:27.340 --> 01:20:31.660]   pre train it. So you do this, you take your model. And you
[01:20:31.660 --> 01:20:34.980]   first show it all the images from last year's comp. And you
[01:20:34.980 --> 01:20:39.460]   train it with a you put a head on the model, which predicts the
[01:20:39.460 --> 01:20:41.740]   last year's comp target, which was different than this year's
[01:20:41.740 --> 01:20:45.020]   comp, last year's comp target was something else. And you
[01:20:45.020 --> 01:20:47.540]   train with that, and you back propagate the error. And when it
[01:20:47.540 --> 01:20:49.780]   does it, it affects all the layers of the neural network.
[01:20:49.780 --> 01:20:52.580]   And those are the layers which are basically extracting
[01:20:52.580 --> 01:20:56.060]   features like, you know, is it a dog? Is it a cat? Are the
[01:20:56.060 --> 01:20:59.620]   eyeballs so it actually changes what it looks for? Okay, after
[01:20:59.620 --> 01:21:02.580]   you do that, you stop the training, you remove the head.
[01:21:02.580 --> 01:21:05.740]   And now you put a new head on the model. And now you train it
[01:21:05.740 --> 01:21:08.660]   with this year's competition data. And this year's target.
[01:21:08.660 --> 01:21:12.500]   This is the whole idea behind pre training the whole idea
[01:21:12.500 --> 01:21:15.460]   behind the TIM repository. They've been pre trained on
[01:21:15.460 --> 01:21:18.420]   image net, which is 10s of millions of images. And it has a
[01:21:18.420 --> 01:21:22.220]   benefit to us. Because by just letting the model look at
[01:21:22.220 --> 01:21:26.980]   images, the model will just learn to understand what is in
[01:21:26.980 --> 01:21:30.740]   an image, images have color, images of lines, images of
[01:21:30.740 --> 01:21:34.180]   shapes, you just train your model to recognize basic things.
[01:21:34.180 --> 01:21:37.380]   So I thought that surely that this could help the model by
[01:21:37.380 --> 01:21:40.020]   showing it some more dogs and cats. Unfortunately, it didn't.
[01:21:40.020 --> 01:21:43.140]   I tried things like pseudo labeling, which is you know, you
[01:21:43.140 --> 01:21:46.940]   take you take the images from last year, you predict some
[01:21:46.940 --> 01:21:51.860]   labels, a popularity scores on last year, you then just add it
[01:21:51.860 --> 01:21:54.060]   then it's not pre training anymore, then you can just
[01:21:54.060 --> 01:21:56.740]   combine it with the training data, and just train it on
[01:21:56.740 --> 01:22:02.580]   through. That didn't help. Um, I tried I tried taking last year's
[01:22:02.580 --> 01:22:05.260]   models that have already you know, won the comp and then
[01:22:05.260 --> 01:22:08.580]   using those models to predict on this year's comp and then
[01:22:08.580 --> 01:22:11.380]   basically for each this year's image, you know, add a new
[01:22:11.380 --> 01:22:14.900]   column of features, use those features. So I tried many, many
[01:22:14.900 --> 01:22:18.260]   things. In the end, I couldn't get anything to work. So I
[01:22:18.260 --> 01:22:22.940]   didn't I didn't use a last year's data at all. And then
[01:22:22.940 --> 01:22:27.060]   when I read all the winning solutions, I actually see that
[01:22:27.060 --> 01:22:32.260]   in the top six finalists. So three of them actually were able
[01:22:32.260 --> 01:22:35.100]   to use last year's competent successful fashion. So I did
[01:22:35.100 --> 01:22:39.420]   not a jib at first place did not I forget some other team did not
[01:22:39.420 --> 01:22:45.500]   maybe third place but then a on a Darrow the other cage you on
[01:22:45.500 --> 01:22:48.740]   and video he was able to successfully use his team his
[01:22:48.740 --> 01:22:52.100]   team and his team was able to successfully use last year's
[01:22:52.100 --> 01:22:55.300]   comps as were two other people and the way they used it was
[01:22:55.300 --> 01:22:59.660]   this quite creative. I wish I discovered it. So I didn't even
[01:22:59.660 --> 01:23:05.220]   notice this but it turns out that there was actually some so
[01:23:05.220 --> 01:23:10.300]   one third of the images this year, those same exact images
[01:23:10.300 --> 01:23:15.940]   were in a previous comp. So what you actually do is you build a
[01:23:15.940 --> 01:23:20.300]   model, which actually finds those similar images. And every
[01:23:20.300 --> 01:23:25.300]   time an image in this comp existed previously, you add the
[01:23:25.300 --> 01:23:29.940]   metadata. And the metadata was stuff like what breed is the
[01:23:29.940 --> 01:23:32.940]   animal, the metadata was stuff like how long did it take for
[01:23:32.940 --> 01:23:39.140]   the animal to be adopted? The metadata was stuff like I don't
[01:23:39.140 --> 01:23:41.460]   know, but basically, it was actually powerful metadata. It
[01:23:41.460 --> 01:23:44.900]   wasn't this year, the metadata was like, is the animal looking
[01:23:44.900 --> 01:23:47.580]   at the camera, I would say that's weak, because the model
[01:23:47.580 --> 01:23:51.340]   can already determine that. But there was some things last year,
[01:23:51.340 --> 01:23:55.740]   for instance, adoption speed. Um, I mean, that's a pretty
[01:23:55.740 --> 01:23:58.500]   powerful meta feature. So what they what some of the top teams
[01:23:58.500 --> 01:24:02.060]   did was for the one third of images this year, which were the
[01:24:02.060 --> 01:24:05.300]   same as last year, they ran it through a sort of a similarity
[01:24:05.300 --> 01:24:07.860]   model, they found them even during inference, they found the
[01:24:07.860 --> 01:24:11.700]   similar images, they took the metadata from last year, they
[01:24:11.700 --> 01:24:16.740]   concatenated it onto this year. And then for that one third of
[01:24:16.740 --> 01:24:21.140]   data, they use a special model that utilize the extra features.
[01:24:21.140 --> 01:24:25.580]   So for the other two thirds of inference, they just, you know,
[01:24:25.580 --> 01:24:28.340]   use their typical models. But then for that one third of
[01:24:28.340 --> 01:24:31.780]   images, they had some additional information, and they had
[01:24:31.780 --> 01:24:35.180]   trained additional models. And they said it gave them a pretty
[01:24:35.180 --> 01:24:41.100]   big boost. However, it's, it's clear that it gave a boost in
[01:24:41.100 --> 01:24:45.220]   local CV score, it's clear that it gave a boost in leader public
[01:24:45.220 --> 01:24:47.540]   leaderboard score, because that was actually the reason that
[01:24:47.540 --> 01:24:51.380]   many teams were high on public leaderboard. But I'm actually
[01:24:51.380 --> 01:24:54.980]   not sure if it has been confirmed on private leaderboard.
[01:24:54.980 --> 01:25:00.700]   Because surprisingly, if you look at the three teams that use
[01:25:01.100 --> 01:25:03.860]   metadata from last year, and then the three teams that did
[01:25:03.860 --> 01:25:08.260]   not, all among the top six, all their final private leaderboard
[01:25:08.260 --> 01:25:12.860]   scores are the same. So I think it may be the case that maybe
[01:25:12.860 --> 01:25:16.140]   the private images, maybe there was no overlap, you know, no
[01:25:16.140 --> 01:25:18.340]   one's really confirmed this, maybe there was actually no
[01:25:18.340 --> 01:25:21.260]   overlap between the private images, because I would think
[01:25:21.260 --> 01:25:24.540]   that the teams that used it would maybe have jumped higher
[01:25:24.540 --> 01:25:27.300]   if they didn't. So maybe in the end, you know, it helped on
[01:25:27.300 --> 01:25:31.380]   public, but maybe maybe in the end, using that meta actually
[01:25:31.380 --> 01:25:33.460]   didn't help on private, I think that's still to be determined.
[01:25:33.460 --> 01:25:36.020]   Awesome.
[01:25:36.020 --> 01:25:40.500]   I think we've covered the solution. So we can move on to
[01:25:40.500 --> 01:25:43.700]   the audience questions. Any anything you wanted to add from
[01:25:43.700 --> 01:25:44.340]   the solution?
[01:25:44.340 --> 01:25:50.740]   Sorry, anything remaining from the solution that we
[01:25:50.740 --> 01:25:55.740]   I'm happy we covered that we covered the solution.
[01:25:56.220 --> 01:25:59.140]   Thanks. Thanks for the comprehensive overview. This is
[01:25:59.140 --> 01:26:04.060]   a question by I think it's he's awesome. On Kaggle. He's also a
[01:26:04.060 --> 01:26:10.100]   grandmaster, I believe. Were you varying the losses on the output
[01:26:10.100 --> 01:26:12.780]   between the auxiliary and regular output?
[01:26:12.780 --> 01:26:19.260]   Um, so I did not tune it. Perhaps if I did tune it, I
[01:26:19.260 --> 01:26:21.220]   could have got better performance. But off the bat,
[01:26:23.100 --> 01:26:26.860]   off the bat, I just basically added it. So what the the clock
[01:26:26.860 --> 01:26:30.980]   so I for the predicting dog and cat, I just added a BC loss. And
[01:26:30.980 --> 01:26:36.540]   then for predicting. Oh, it's actually they're both BC losses.
[01:26:36.540 --> 01:26:38.180]   Because so what people were doing this, even though this
[01:26:38.180 --> 01:26:42.100]   comp was a regression comp. So I added it to the cog next, which
[01:26:42.100 --> 01:26:44.660]   was the image transformer for the for that particular image
[01:26:44.660 --> 01:26:47.780]   transformer, the popularity score I was predicting with a
[01:26:47.780 --> 01:26:51.420]   BC loss. So actually, I was predicting a BC loss and then
[01:26:51.420 --> 01:26:55.660]   afterwards rescaling it to the regression values between zero
[01:26:55.660 --> 01:26:59.060]   and 100. So essentially, I had to BC losses, one for popularity,
[01:26:59.060 --> 01:27:01.660]   one for dog cat, and I just waited in 5050.
[01:27:01.660 --> 01:27:03.700]   That makes sense.
[01:27:03.700 --> 01:27:06.900]   Yeah, I want to thank I want to thank also for I use the I use
[01:27:06.900 --> 01:27:09.860]   he contributed a lot of public notebooks and discussions. We
[01:27:09.860 --> 01:27:12.420]   earlier we talked about grad cam, I want to give the shout
[01:27:12.420 --> 01:27:15.180]   out to him. I think he was the first one to publish the
[01:27:15.180 --> 01:27:19.220]   difference between grad cam between the CNN and the image
[01:27:19.220 --> 01:27:22.140]   transformer and how one focuses on the face and the body. And
[01:27:22.140 --> 01:27:26.260]   he he he shared a lot of Yeah, he shared a lot of discussion
[01:27:26.260 --> 01:27:29.820]   posts, he actually did a lot of analysis, comparing using
[01:27:29.820 --> 01:27:33.580]   classification loss versus using regression loss, he did a lot of
[01:27:33.580 --> 01:27:36.940]   comparison comparing CNN versus transformers. And actually, it
[01:27:36.940 --> 01:27:40.340]   really motivated the direction I took early on, I kind of took a
[01:27:40.340 --> 01:27:44.020]   lot of things he said, and I really dope. So you know, he had
[01:27:44.020 --> 01:27:47.980]   come to some conclusions that using these losses in these
[01:27:47.980 --> 01:27:50.260]   models. And that was kind of the first things I investigated. So
[01:27:50.260 --> 01:27:54.900]   shout out to any he showed some code training some bit models. I
[01:27:54.900 --> 01:27:57.700]   was using that in the beginning. In the end, my in the end,
[01:27:57.700 --> 01:28:02.380]   though, as I found new transformers, the bits, I ended
[01:28:02.380 --> 01:28:06.020]   up removing them. But I used his work a lot and appreciate it.
[01:28:06.020 --> 01:28:09.900]   Also, is absolutely incredible. Thanks for joining us live.
[01:28:09.900 --> 01:28:15.260]   Awesome. There's another question. Why do you think SVR
[01:28:15.260 --> 01:28:18.580]   work better compared to just using gradient descent in the
[01:28:18.580 --> 01:28:19.300]   original head?
[01:28:19.300 --> 01:28:23.860]   Great question. So this is actually the second time I've
[01:28:23.860 --> 01:28:27.420]   done this SVR trick. It actually I used it in the common lit
[01:28:27.420 --> 01:28:31.220]   competition, which was a it was an NLP regression task. And now
[01:28:31.220 --> 01:28:35.380]   this is the second time using in this competition. And in each
[01:28:35.380 --> 01:28:38.700]   competition that gave a slight boost, I looked at my solution
[01:28:38.700 --> 01:28:41.260]   with and without it, I can clearly see that it increased me
[01:28:41.260 --> 01:28:44.540]   a couple ranks. Why it works, I think a few reasons. So first
[01:28:44.540 --> 01:28:46.540]   of all, there are other there are I will start out by saying
[01:28:46.540 --> 01:28:49.260]   there are other there are other options. For instance, in
[01:28:49.260 --> 01:28:51.860]   common lit, people are using this thing called Bayesian ridge,
[01:28:51.860 --> 01:28:55.620]   which actually worked very, very good. So you know, there are
[01:28:55.620 --> 01:29:00.700]   other options. I think the reason that SVR works great. And
[01:29:00.700 --> 01:29:04.420]   the reason Bayesian ridge works great is both ridge and SVR have
[01:29:04.420 --> 01:29:09.540]   an inherent. So ridge has an basically they both have an
[01:29:09.540 --> 01:29:16.980]   inherent feature reduction built in. So ridge. So they both try
[01:29:16.980 --> 01:29:19.460]   to remove features. So it's not that so just ordinary
[01:29:19.460 --> 01:29:22.140]   regression wouldn't but you have lasso regression, you've got
[01:29:22.140 --> 01:29:25.260]   ridge regression, these are types of aggression and s and
[01:29:25.260 --> 01:29:28.740]   SV SVR regression, these are types of regression that during
[01:29:28.740 --> 01:29:32.300]   the training process, they try to remove features. And what you
[01:29:32.300 --> 01:29:34.100]   have here is if you look at the embeddings from a neural
[01:29:34.100 --> 01:29:36.780]   network, it's really a lot of features, there's 1000s of
[01:29:36.780 --> 01:29:38.860]   features. And then if you do it, jib it in and combine them. So
[01:29:38.860 --> 01:29:41.620]   that's like so many features, and a lot of them are kind of
[01:29:41.620 --> 01:29:45.780]   not needed. So I think it's really important to use some
[01:29:45.780 --> 01:29:51.180]   type of ridge lasso, a shrinkage like SVR has to kind of really
[01:29:51.180 --> 01:29:54.900]   remove a lot of those. And that makes your model, you know,
[01:29:54.900 --> 01:29:58.140]   generalized better. And there are other approaches, you know,
[01:29:58.140 --> 01:30:01.900]   you can build a neural network head. And I think you I think
[01:30:01.900 --> 01:30:06.500]   you can actually apply different losses, like you can add an L2
[01:30:06.500 --> 01:30:09.900]   or L1 loss that actually prunes and actually kind of removes
[01:30:09.900 --> 01:30:12.740]   features from a neural network head. I think some optimizers,
[01:30:12.740 --> 01:30:15.500]   maybe Adam w does this. So there's a lot of alternatives.
[01:30:15.500 --> 01:30:20.140]   But I think a powerful thing is one, to, you know, prevent
[01:30:20.140 --> 01:30:22.620]   overfitting and make your model generalized by essentially
[01:30:22.620 --> 01:30:26.660]   reducing them or features. And then to something that I've seen
[01:30:26.660 --> 01:30:31.500]   both in the common lit comp, and the pet finder comp was this
[01:30:31.500 --> 01:30:36.940]   weird phenomenon where if you try to train the backbone and
[01:30:36.940 --> 01:30:40.860]   head all at once, in the regression task, you didn't get
[01:30:40.860 --> 01:30:44.220]   as good results as training them separately. And you can train
[01:30:44.220 --> 01:30:47.340]   them separately in different ways. One way is to just use
[01:30:47.340 --> 01:30:51.260]   different different learning rates at four different layers.
[01:30:51.260 --> 01:30:54.780]   And another way is just straight up freezing. So you know, you
[01:30:54.780 --> 01:30:59.740]   first freeze the head and train the backbone. And then you know,
[01:30:59.780 --> 01:31:02.540]   and then you freeze the backbone and unfreeze the head. So the
[01:31:02.540 --> 01:31:06.060]   whole discussion about using SVR or using Bayesian ridge or using
[01:31:06.060 --> 01:31:10.060]   whatever it's sort of, it also has the advantage of, of
[01:31:10.060 --> 01:31:13.300]   training the backbone and head separately. You know, you train
[01:31:13.300 --> 01:31:16.180]   the backbone in some way, and then you freeze the backbone.
[01:31:16.180 --> 01:31:21.860]   And then you're then training ahead. And I think that's why
[01:31:21.860 --> 01:31:26.700]   for those two reasons, I think that's why it is powerful. And
[01:31:26.700 --> 01:31:29.620]   I guess now if you want to speak, and then that's why SVR
[01:31:29.620 --> 01:31:32.260]   is powerful. Now, if you want to say why was rapids powerful. So
[01:31:32.260 --> 01:31:35.860]   rapids runs on GPU, which makes it faster than other forms of
[01:31:35.860 --> 01:31:39.540]   SVR. And the advantage there is what this speed allows you to
[01:31:39.540 --> 01:31:42.180]   do is you can handle more features. So for instance, what
[01:31:42.180 --> 01:31:45.340]   so in my situation, you know, I probably could have done it on
[01:31:45.340 --> 01:31:48.780]   CPU, because I only had, you know, a head for one model. But
[01:31:48.780 --> 01:31:51.740]   what Jibba did, when Jibba combined the embeddings of
[01:31:51.740 --> 01:31:54.540]   multiple models, he's now looking at 10s of 1000s of
[01:31:54.540 --> 01:31:57.100]   features. And I haven't tried it. But I think if you try to,
[01:31:57.380 --> 01:32:01.500]   if you try to train, you know, a GPU based SVR, or a GPU,
[01:32:01.500 --> 01:32:07.140]   sorry, if you try to train a CPU version of anything, I think
[01:32:07.140 --> 01:32:11.300]   it's going to be maybe too slow to actually be able to train
[01:32:11.300 --> 01:32:12.580]   with with so many columns.
[01:32:12.580 --> 01:32:16.660]   Sanyam Bhutani: Thanks, thanks for that clarification and
[01:32:16.660 --> 01:32:19.300]   elaborate answer. We're out of schedule time. Is it okay if I
[01:32:19.300 --> 01:32:21.620]   go five minutes over? I just have three more questions.
[01:32:21.620 --> 01:32:22.660]   Yeah, yeah, it's fine for me.
[01:32:24.580 --> 01:32:28.620]   Random question, if you were to pick your favorite model in the
[01:32:28.620 --> 01:32:31.220]   world of machine learning, just one model, which one would it
[01:32:31.220 --> 01:32:34.020]   be? Favorite algorithm or model?
[01:32:34.020 --> 01:32:42.700]   Probably a neural network. I feel I guess when I when I work
[01:32:42.700 --> 01:32:44.860]   with a neural network, I train a neural network, I feel more like
[01:32:44.860 --> 01:32:49.500]   a teacher. I feel
[01:32:52.780 --> 01:32:55.980]   a little unexpected. It's like, it might learn things you don't.
[01:32:55.980 --> 01:33:00.140]   It's, it's more of a black box. It's more unsure what it's
[01:33:00.140 --> 01:33:03.380]   learning. It's sort of trickier. It's more of an art form. So I
[01:33:03.380 --> 01:33:06.460]   kind of like it. And a lot of times the results surprise you.
[01:33:06.460 --> 01:33:11.260]   And I've always been, I think I've always been kind of drawn
[01:33:11.260 --> 01:33:14.420]   to types of neural networks. I mean, my other favorite is
[01:33:14.420 --> 01:33:17.740]   boosted trees, but I like neural networks.
[01:33:19.660 --> 01:33:23.620]   You don't have to answer this one. But you're many people's
[01:33:23.620 --> 01:33:26.940]   favorite Kaggler. Do you have any Kaggler to whom you really
[01:33:26.940 --> 01:33:27.540]   look up to?
[01:33:27.540 --> 01:33:36.340]   So I mean, as you said earlier, you know, I engage discussion
[01:33:36.340 --> 01:33:38.660]   with everybody. So I really follow everybody, people will be
[01:33:38.660 --> 01:33:43.940]   surprised how much I saw. Yeah, I'm I am I, if you go to my
[01:33:43.940 --> 01:33:46.860]   profile, I haven't actually checked off who I'm following.
[01:33:47.660 --> 01:33:50.100]   The reason is I don't need notifications. I just read
[01:33:50.100 --> 01:33:53.500]   everything, right? There's a lot of people I keep an eye on. So a
[01:33:53.500 --> 01:33:56.420]   lot of Kagglers, I'll frequently look at leaderboards just to see
[01:33:56.420 --> 01:33:59.260]   what competitions people are participating in. You know, all
[01:33:59.260 --> 01:34:01.980]   my former teammates, I follow them, I kind of see, oh, what
[01:34:01.980 --> 01:34:03.940]   are they up to? You know, nowadays, I've teamed with a
[01:34:03.940 --> 01:34:06.940]   huge variety of people, I'm always keeping an eye, you know,
[01:34:06.940 --> 01:34:09.780]   what comps are they in? What are they doing? I'm reading their
[01:34:09.780 --> 01:34:12.740]   discussion posts. I'm, you know, of course, always reading the
[01:34:12.740 --> 01:34:15.860]   work of the greats. But then, as you mentioned earlier, I read
[01:34:15.860 --> 01:34:19.020]   all the discussions, even of the new Kagglers, the people with,
[01:34:19.020 --> 01:34:22.060]   you know, the questions, I really like to kind of keep an
[01:34:22.060 --> 01:34:25.500]   eye on all of it, because I feel that there's something to learn
[01:34:25.500 --> 01:34:26.100]   from all of it.
[01:34:26.100 --> 01:34:29.820]   Sanyam Bhutani: Your passion really comes through. We're all
[01:34:29.820 --> 01:34:36.180]   grateful for it. This is another stupid question. But you've been
[01:34:36.180 --> 01:34:40.260]   very kind to me with always agreeing to my request. This is
[01:34:40.260 --> 01:34:43.020]   a greedy question. What's, what's one thing you want me to
[01:34:43.020 --> 01:34:46.660]   improve on in the series? If I interview my favorite Kagglers?
[01:34:46.660 --> 01:34:48.980]   Any feedback for me?
[01:34:48.980 --> 01:34:51.780]   Well, any critical feedback?
[01:34:51.780 --> 01:34:53.500]   Chris Bounds: So it looks like you're already making changes.
[01:34:53.500 --> 01:34:56.740]   But this is nice. So I really like your, your sort of
[01:34:56.740 --> 01:34:59.460]   changing your format now to kind of dive a little bit more into
[01:34:59.460 --> 01:35:02.340]   more specifics of the solution, which are providing, you know,
[01:35:02.340 --> 01:35:04.540]   more opportunities to sort of share the code, share the
[01:35:04.540 --> 01:35:06.980]   algorithms, dive into the science. So that's great.
[01:35:06.980 --> 01:35:11.140]   There's not many things I changed. I mean, I when I, you
[01:35:11.140 --> 01:35:14.340]   know, before the show, I told you, you're my favorite host,
[01:35:14.340 --> 01:35:19.180]   and you are, you have a great personality. Your, your, your
[01:35:19.180 --> 01:35:24.140]   shows, you cover a huge variety of things. I think that you ask
[01:35:24.140 --> 01:35:29.860]   good questions. You, you, you're also like me, you're excited,
[01:35:29.860 --> 01:35:33.380]   your passion shows through. That makes for a good discussion
[01:35:33.380 --> 01:35:34.140]   between us.
[01:35:34.140 --> 01:35:37.820]   Sanyam Bhutani: But I'm looking for critical feedback. I didn't
[01:35:37.820 --> 01:35:40.780]   ask this just because I wanted encouragement from you. I
[01:35:40.780 --> 01:35:43.260]   sincerely want some critical feedback, if any.
[01:35:43.260 --> 01:35:49.660]   Chris Bounds: Hi, let me think. Let me think. Um, nothing comes
[01:35:49.660 --> 01:35:50.140]   to mind.
[01:35:50.140 --> 01:35:56.420]   Sanyam Bhutani: Okay. With that, I'd love to wrap up because
[01:35:56.420 --> 01:36:01.620]   we've gone over time. Everyone, please find Chris on Kaggle. He
[01:36:01.620 --> 01:36:04.580]   lives on there practically, you can find him on any discussion
[01:36:04.580 --> 01:36:09.340]   post. He's super engaging. Like he was in this interview, you
[01:36:09.340 --> 01:36:11.860]   can ask him any question on there. And from what I've
[01:36:11.860 --> 01:36:14.660]   understood, he always replies to any question. So that's the best
[01:36:14.660 --> 01:36:18.180]   way to connect with him. He also has social media profiles, but
[01:36:18.180 --> 01:36:20.500]   I've never seen any post there. So I won't point them out.
[01:36:20.500 --> 01:36:26.460]   Awesome. Thanks. Thanks so much again, Chris. And thank you so
[01:36:26.460 --> 01:36:29.740]   much, audience for joining us live and for following the
[01:36:29.740 --> 01:36:31.140]   entire interview.
[01:36:31.140 --> 01:36:33.540]   Chris Bounds: Thanks so much once again for inviting me and
[01:36:33.540 --> 01:36:36.740]   thank you audience for watching and participating.
[01:36:36.740 --> 01:36:46.740]   [BLANK_AUDIO]

