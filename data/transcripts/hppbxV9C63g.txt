
[00:00:00.000 --> 00:00:02.200]   Let me ask you to this question,
[00:00:02.200 --> 00:00:06.340]   whether it's bell curve or any research on race differences,
[00:00:06.340 --> 00:00:12.440]   can that be used to increase the amount of racism
[00:00:12.440 --> 00:00:14.880]   in the world, can that be used to increase
[00:00:14.880 --> 00:00:16.920]   the amount of hate in the world?
[00:00:16.920 --> 00:00:21.920]   - My sense is there is such enormous reservoirs
[00:00:21.920 --> 00:00:27.920]   of hate and racism that have nothing to do
[00:00:27.920 --> 00:00:31.480]   with scientific knowledge of the data
[00:00:31.480 --> 00:00:34.080]   that speak against that.
[00:00:34.080 --> 00:00:39.080]   That, no, I don't wanna give racist groups a veto power
[00:00:39.080 --> 00:00:42.020]   over what scientists study.
[00:00:42.020 --> 00:00:46.960]   - The following is a conversation with Richard Heyer
[00:00:46.960 --> 00:00:49.320]   on the science of human intelligence.
[00:00:49.320 --> 00:00:51.720]   This is a highly controversial topic,
[00:00:51.720 --> 00:00:52.960]   but a critically important one
[00:00:52.960 --> 00:00:55.000]   for understanding the human mind.
[00:00:55.000 --> 00:00:57.680]   I hope you will join me in not shying away
[00:00:57.680 --> 00:00:59.980]   from difficult topics like this,
[00:00:59.980 --> 00:01:03.700]   and instead, let us try to navigate it
[00:01:03.700 --> 00:01:06.460]   with empathy, rigor, and grace.
[00:01:06.460 --> 00:01:08.800]   If you're watching this on video now,
[00:01:08.800 --> 00:01:11.500]   I should mention that I'm recording this introduction
[00:01:11.500 --> 00:01:14.580]   in an undisclosed location somewhere in the world.
[00:01:14.580 --> 00:01:17.320]   I'm safe and happy, and life is beautiful.
[00:01:17.320 --> 00:01:20.400]   This is the Alex Friedman Podcast.
[00:01:20.400 --> 00:01:22.360]   To support it, please check out our sponsors
[00:01:22.360 --> 00:01:23.620]   in the description.
[00:01:23.620 --> 00:01:26.960]   And now, dear friends, here's Richard Heyer.
[00:01:27.960 --> 00:01:29.920]   What are the measures of human intelligence,
[00:01:29.920 --> 00:01:31.600]   and how do we measure it?
[00:01:31.600 --> 00:01:35.880]   - Everybody has an idea of what they mean by intelligence.
[00:01:35.880 --> 00:01:40.080]   In the vernacular, what I mean by intelligence
[00:01:40.080 --> 00:01:42.600]   is just being smart, how well you reason,
[00:01:42.600 --> 00:01:45.200]   how well you figure things out,
[00:01:45.200 --> 00:01:48.740]   what you do when you don't know what to do.
[00:01:48.740 --> 00:01:53.740]   Those are just kinda everyday common sense definitions
[00:01:53.740 --> 00:01:56.680]   of how people use the word intelligence.
[00:01:56.680 --> 00:01:59.560]   If you wanna do research on intelligence,
[00:01:59.560 --> 00:02:03.400]   measuring something that you can study scientifically
[00:02:03.400 --> 00:02:05.060]   is a little trickier.
[00:02:05.060 --> 00:02:10.960]   And what almost all researchers who study intelligence use
[00:02:10.960 --> 00:02:16.740]   is the concept called the G factor, general intelligence.
[00:02:16.740 --> 00:02:19.600]   And that is what is common.
[00:02:19.600 --> 00:02:22.640]   That is a mental ability that is common
[00:02:22.640 --> 00:02:26.560]   to virtually all tests of mental abilities.
[00:02:26.560 --> 00:02:28.840]   - What's the origin of the term G factor, by the way?
[00:02:28.840 --> 00:02:32.120]   It's such a funny word for such a fundamental human thing.
[00:02:32.120 --> 00:02:35.620]   - The general factor really started with Charles Spearman.
[00:02:35.620 --> 00:02:41.600]   And he noticed, this is like, boy, more than 100 years ago.
[00:02:41.600 --> 00:02:46.600]   He noticed that when you tested people with different tests,
[00:02:46.600 --> 00:02:51.980]   all the tests were correlated positively.
[00:02:53.120 --> 00:02:57.360]   And so he was looking at student exams and things.
[00:02:57.360 --> 00:03:01.600]   And he invented the correlation coefficient, essentially.
[00:03:01.600 --> 00:03:06.360]   And when he used it to look at student performance
[00:03:06.360 --> 00:03:09.920]   on various topics, he found all the scores
[00:03:09.920 --> 00:03:11.920]   were correlated with each other
[00:03:11.920 --> 00:03:14.480]   and they were all positive correlations.
[00:03:14.480 --> 00:03:17.540]   So he inferred from this that there must be
[00:03:17.540 --> 00:03:21.180]   some common factor that was irrespective
[00:03:21.180 --> 00:03:23.320]   of the content of the test.
[00:03:23.320 --> 00:03:27.000]   - And positive correlation means if you do well
[00:03:27.000 --> 00:03:29.440]   on the first test, you're likely to do well
[00:03:29.440 --> 00:03:30.960]   on the second test.
[00:03:30.960 --> 00:03:35.800]   And presumably that holds for tests across even disciplines.
[00:03:35.800 --> 00:03:39.320]   So not within subject, but across subjects.
[00:03:39.320 --> 00:03:42.360]   So that's where the general comes in.
[00:03:42.360 --> 00:03:45.000]   Something about general intelligence.
[00:03:45.000 --> 00:03:46.920]   So when you were talking about measuring intelligence
[00:03:46.920 --> 00:03:50.080]   and trying to figure out something difficult
[00:03:50.080 --> 00:03:53.240]   about this world and how to solve the puzzles of this world,
[00:03:53.240 --> 00:03:56.600]   that means generally speaking, not some specific test,
[00:03:56.600 --> 00:03:58.120]   but across all tests.
[00:03:58.120 --> 00:03:59.300]   - Absolutely right.
[00:03:59.300 --> 00:04:03.320]   And people get hung up on this because they say,
[00:04:03.320 --> 00:04:06.520]   well, what about the ability to do X?
[00:04:06.520 --> 00:04:08.920]   Isn't that independent?
[00:04:08.920 --> 00:04:11.960]   And they said, I know somebody who's very good at this,
[00:04:11.960 --> 00:04:15.320]   but not so good at this, this other thing.
[00:04:15.320 --> 00:04:17.440]   And so there are a lot of examples like that,
[00:04:17.440 --> 00:04:19.940]   but it's a general tendency.
[00:04:19.940 --> 00:04:23.520]   So exceptions really don't disprove,
[00:04:23.520 --> 00:04:27.640]   you know, your everyday experience is not the same
[00:04:27.640 --> 00:04:30.740]   as what the data actually show.
[00:04:30.740 --> 00:04:32.720]   And your everyday experience, when you say,
[00:04:32.720 --> 00:04:36.560]   oh, I know someone who's good at X, but not so good at Y,
[00:04:36.560 --> 00:04:39.120]   that doesn't contradict the statement of about,
[00:04:39.120 --> 00:04:43.360]   he's not so good, but he's not the opposite.
[00:04:43.360 --> 00:04:46.520]   It's not a negative correlation.
[00:04:46.520 --> 00:04:49.880]   - Okay, so we're not, our anecdotal data,
[00:04:49.880 --> 00:04:53.720]   I know a guy who's really good at solving
[00:04:53.720 --> 00:04:55.840]   some kind of visual thing.
[00:04:55.840 --> 00:04:59.400]   That's not sufficient for us to understand actually
[00:04:59.400 --> 00:05:01.400]   the depths of that person's intelligence.
[00:05:01.400 --> 00:05:05.060]   So how this idea of G factor,
[00:05:05.060 --> 00:05:09.360]   how much evidence is there?
[00:05:09.360 --> 00:05:13.040]   How strong, you know, given across the decades
[00:05:13.040 --> 00:05:14.800]   that this idea has been around,
[00:05:14.800 --> 00:05:18.080]   how much has it been held up that there's a universal
[00:05:18.080 --> 00:05:22.500]   sort of horsepower of intelligence
[00:05:22.500 --> 00:05:24.000]   that's underneath all of it?
[00:05:24.000 --> 00:05:27.320]   All the different tests we do to try to get to this thing
[00:05:27.320 --> 00:05:30.400]   in the depths of the human mind,
[00:05:30.400 --> 00:05:32.960]   that's a universal stable measure
[00:05:32.960 --> 00:05:34.840]   of a person's intelligence.
[00:05:34.840 --> 00:05:38.440]   - You used a couple of words in there, stable and--
[00:05:38.440 --> 00:05:40.600]   - Are we gonna have to be precise with words?
[00:05:40.600 --> 00:05:42.680]   I was hoping we can get away with being poetic.
[00:05:42.680 --> 00:05:43.520]   - We can.
[00:05:43.520 --> 00:05:46.240]   There's a lot about research in general,
[00:05:46.240 --> 00:05:49.560]   not just intelligence research, that is poetic.
[00:05:49.560 --> 00:05:52.560]   Science has a poetic aspect to it,
[00:05:52.560 --> 00:05:55.800]   and good scientists are very intuitive.
[00:05:55.800 --> 00:05:59.200]   They're not just, hey, these are the numbers.
[00:05:59.200 --> 00:06:02.080]   You have to kind of step back and see the big picture.
[00:06:02.080 --> 00:06:05.920]   When it comes to intelligence research,
[00:06:05.920 --> 00:06:09.600]   you asked how well has this general concept held up?
[00:06:09.920 --> 00:06:12.280]   And I think I can say,
[00:06:12.280 --> 00:06:16.280]   without fear of being empirically contradicted,
[00:06:16.280 --> 00:06:21.120]   that it is the most replicated finding in all of psychology.
[00:06:21.120 --> 00:06:23.560]   Now, some cynics may say, well, big deal, psychology.
[00:06:23.560 --> 00:06:26.360]   We all know there's a replication crisis in psychology,
[00:06:26.360 --> 00:06:28.480]   and a lot of this stuff doesn't replicate.
[00:06:28.480 --> 00:06:29.720]   That's all true.
[00:06:29.720 --> 00:06:33.600]   There is no replication crisis when it comes to studying
[00:06:33.600 --> 00:06:36.820]   the existence of this general factor.
[00:06:36.820 --> 00:06:38.960]   Let me tell you some things about it.
[00:06:38.960 --> 00:06:41.520]   It looks like it's universal,
[00:06:41.520 --> 00:06:44.680]   that you find it in all cultures.
[00:06:44.680 --> 00:06:47.760]   The way you find it, step back one step,
[00:06:47.760 --> 00:06:51.760]   the way you find it is to give a battery of mental tests.
[00:06:51.760 --> 00:06:52.760]   What battery?
[00:06:52.760 --> 00:06:53.800]   You choose.
[00:06:53.800 --> 00:06:57.080]   Take a battery of any mental tests you want,
[00:06:57.080 --> 00:07:00.580]   give it to a large number of diverse people,
[00:07:00.580 --> 00:07:05.720]   and you will be able to extract statistically
[00:07:05.720 --> 00:07:09.020]   the commonality among all those tests.
[00:07:09.020 --> 00:07:12.460]   It's done by a technique called factor analysis.
[00:07:12.460 --> 00:07:17.460]   People think that this may be a statistical artifact
[00:07:17.460 --> 00:07:18.500]   of some kind.
[00:07:18.500 --> 00:07:21.340]   It is not a statistical artifact.
[00:07:21.340 --> 00:07:22.700]   - What is factor analysis?
[00:07:22.700 --> 00:07:26.140]   - Factor analysis is a way of looking at a big set of data
[00:07:26.140 --> 00:07:29.880]   and look at the correlation among the different test scores,
[00:07:29.880 --> 00:07:33.840]   and then find empirically the clusters of scores
[00:07:33.840 --> 00:07:35.620]   that go together.
[00:07:35.620 --> 00:07:37.340]   And there are different factors.
[00:07:37.340 --> 00:07:39.380]   So if you have a bunch of mental tests,
[00:07:39.380 --> 00:07:41.140]   there may be a verbal factor,
[00:07:41.140 --> 00:07:43.340]   there may be a numerical factor,
[00:07:43.340 --> 00:07:45.900]   there may be a visual spatial factor,
[00:07:45.900 --> 00:07:50.220]   but those factors have variants in common with each other.
[00:07:50.220 --> 00:07:51.980]   And that is the common,
[00:07:51.980 --> 00:07:55.360]   that's what's common among all the tests,
[00:07:55.360 --> 00:07:58.100]   and that's what gets labeled the G factor.
[00:07:58.100 --> 00:08:01.460]   So if you give a diverse battery of mental tests
[00:08:01.460 --> 00:08:04.740]   and you extract a G factor from it,
[00:08:04.740 --> 00:08:07.340]   that factor usually accounts for around half
[00:08:07.340 --> 00:08:10.400]   of the variances, the single biggest factor,
[00:08:10.400 --> 00:08:12.860]   but it's not the only factor,
[00:08:12.860 --> 00:08:17.200]   but it is the most reliable, it is the most stable,
[00:08:17.200 --> 00:08:22.200]   and it seems to be very much influenced by genetics.
[00:08:22.200 --> 00:08:26.660]   It's very hard to change the G factor
[00:08:26.660 --> 00:08:31.660]   with training or drugs or anything else.
[00:08:32.900 --> 00:08:34.980]   We don't know how to increase the G factor.
[00:08:34.980 --> 00:08:36.920]   - Okay, you said a lot of really interesting things there.
[00:08:36.920 --> 00:08:40.940]   So first, just to get people used to it
[00:08:40.940 --> 00:08:43.260]   in case they're not familiar with this idea,
[00:08:43.260 --> 00:08:45.820]   G factor is what we mean.
[00:08:45.820 --> 00:08:49.100]   So often there's this term used, IQ,
[00:08:49.100 --> 00:08:53.980]   which is the way IQ is used,
[00:08:53.980 --> 00:08:57.540]   they really mean G factor in regular conversation.
[00:08:57.540 --> 00:09:02.640]   'Cause what we mean by IQ, we mean intelligence,
[00:09:02.640 --> 00:09:04.480]   and what we mean by intelligence,
[00:09:04.480 --> 00:09:05.820]   we mean general intelligence,
[00:09:05.820 --> 00:09:08.840]   and general intelligence in the human mind
[00:09:08.840 --> 00:09:10.840]   from a psychology, from a serious,
[00:09:10.840 --> 00:09:13.900]   rigorous scientific perspective actually means G factor.
[00:09:13.900 --> 00:09:15.740]   So G factor equals intelligence,
[00:09:15.740 --> 00:09:18.440]   just in this conversation to define terms.
[00:09:18.440 --> 00:09:22.180]   Okay, so there's this stable thing called G factor.
[00:09:22.180 --> 00:09:27.180]   You said it, now, factor, you said factor many times,
[00:09:28.220 --> 00:09:33.220]   means a measure that potentially could be reduced
[00:09:33.220 --> 00:09:35.840]   to a single number across the different factors
[00:09:35.840 --> 00:09:40.360]   you mentioned, and what you said,
[00:09:40.360 --> 00:09:43.600]   it accounts for half, half-ish.
[00:09:43.600 --> 00:09:46.640]   Accounts for half-ish of what?
[00:09:46.640 --> 00:09:51.640]   Of variance across the different set of tests.
[00:09:53.760 --> 00:09:58.560]   So if you do for some reason well on some set of tests,
[00:09:58.560 --> 00:10:01.080]   what does that mean?
[00:10:01.080 --> 00:10:03.340]   So that means there's some unique capabilities
[00:10:03.340 --> 00:10:05.940]   outside of the G factor that might account for that,
[00:10:05.940 --> 00:10:07.500]   and what are those?
[00:10:07.500 --> 00:10:10.420]   What else is there besides the raw horsepower,
[00:10:10.420 --> 00:10:13.340]   the engine inside your mind that generates intelligence?
[00:10:13.340 --> 00:10:16.380]   - There are test-taking skills,
[00:10:16.380 --> 00:10:20.880]   there are specific abilities.
[00:10:20.880 --> 00:10:25.880]   Someone might be particularly good at mathematical things,
[00:10:25.880 --> 00:10:32.140]   mathematical concepts, even simple arithmetic.
[00:10:32.140 --> 00:10:34.320]   Some people are much better than others.
[00:10:34.320 --> 00:10:36.460]   You might know people who can,
[00:10:36.460 --> 00:10:41.460]   and short-term memory is another component of this.
[00:10:41.460 --> 00:10:46.900]   Short-term memory is one of the cognitive processes
[00:10:46.900 --> 00:10:50.240]   that's most highly correlated with the G factor.
[00:10:51.240 --> 00:10:54.020]   So--
[00:10:54.020 --> 00:10:56.260]   - So all those things like memory,
[00:10:56.260 --> 00:10:59.920]   test-taking skills account for variability
[00:10:59.920 --> 00:11:02.220]   across the test performances.
[00:11:02.220 --> 00:11:05.520]   But you say you can run, but you can't hide
[00:11:05.520 --> 00:11:09.920]   from the thing that God gave you, the genetics.
[00:11:09.920 --> 00:11:15.120]   So that G factor, science says that G factor's there.
[00:11:15.120 --> 00:11:16.900]   Each one of us have--
[00:11:16.900 --> 00:11:19.380]   - Each one of us has a G factor.
[00:11:19.380 --> 00:11:20.220]   - Oh boy.
[00:11:20.220 --> 00:11:21.420]   Some have more than others.
[00:11:21.420 --> 00:11:22.820]   - I'm getting uncomfortable already.
[00:11:22.820 --> 00:11:25.080]   - Well, IQ is a score.
[00:11:25.080 --> 00:11:32.260]   An IQ score is a very good estimate of the G factor.
[00:11:32.260 --> 00:11:36.100]   You can't measure G directly, there's no direct measure.
[00:11:36.100 --> 00:11:39.880]   You estimate it from these statistical techniques.
[00:11:39.880 --> 00:11:43.080]   But an IQ score is a good estimate, why?
[00:11:43.080 --> 00:11:46.420]   Because a standard IQ test is a battery
[00:11:46.420 --> 00:11:48.660]   of different mental abilities.
[00:11:48.660 --> 00:11:51.380]   You combine it into one score,
[00:11:51.380 --> 00:11:55.700]   and that score is highly correlated with the G factor,
[00:11:55.700 --> 00:12:00.140]   even if you get better scores on some subtests than others.
[00:12:00.140 --> 00:12:02.300]   Because again, it's what's common
[00:12:02.300 --> 00:12:04.300]   to all these mental abilities.
[00:12:04.300 --> 00:12:08.180]   - So a good IQ test, and I'll ask you about that,
[00:12:08.180 --> 00:12:12.620]   but a good IQ test tries to compress down
[00:12:12.620 --> 00:12:16.180]   that battery of tests, like tries to get a nice battery,
[00:12:16.180 --> 00:12:21.180]   a nice selection of variable tests into one test.
[00:12:21.180 --> 00:12:24.180]   And so in that way, it sneaks up to the G factor.
[00:12:24.180 --> 00:12:27.460]   And that's another interesting thing about G factor.
[00:12:27.460 --> 00:12:32.380]   Now you give, first of all, you have a great book
[00:12:32.380 --> 00:12:34.180]   on the neuroscience of intelligence.
[00:12:34.180 --> 00:12:37.500]   You have a great course, which is one I first learned.
[00:12:37.500 --> 00:12:39.820]   You're a great teacher, let me just say.
[00:12:39.820 --> 00:12:40.660]   - Thank you.
[00:12:40.660 --> 00:12:44.180]   - Your course at the teaching company,
[00:12:44.180 --> 00:12:45.820]   I hope I'm saying that correctly.
[00:12:45.820 --> 00:12:47.180]   - The Intelligent Brain.
[00:12:47.180 --> 00:12:50.500]   - The Intelligent Brain is when I first heard
[00:12:50.500 --> 00:12:53.820]   about this G factor, this mysterious thing
[00:12:53.820 --> 00:12:56.300]   that lurks in the darkness that we cannot quite shine
[00:12:56.300 --> 00:12:58.980]   a light on, we're trying to sneak up on.
[00:12:58.980 --> 00:13:00.540]   So the fact that there's this measure,
[00:13:00.540 --> 00:13:03.800]   stable measure of intelligence, we can't measure directly.
[00:13:03.800 --> 00:13:07.780]   But we can come up with a battery test
[00:13:07.780 --> 00:13:10.300]   or one test that includes a battery
[00:13:10.300 --> 00:13:15.300]   of variable type of questions that can,
[00:13:16.060 --> 00:13:20.900]   reliably or attempt to estimate in a stable way
[00:13:20.900 --> 00:13:23.300]   that G factor, that's a fascinating idea.
[00:13:23.300 --> 00:13:25.820]   So for me as an AI person, it's fascinating.
[00:13:25.820 --> 00:13:27.860]   It's fascinating there's something stable like that
[00:13:27.860 --> 00:13:30.620]   about the human mind, especially if it's grounded
[00:13:30.620 --> 00:13:33.660]   in genetics, it's both fascinating
[00:13:33.660 --> 00:13:38.220]   that as a researcher of the human mind
[00:13:38.220 --> 00:13:44.260]   and all the human psychological, sociological,
[00:13:44.260 --> 00:13:46.580]   ethical questions that start arising,
[00:13:46.580 --> 00:13:48.260]   it makes me uncomfortable.
[00:13:48.260 --> 00:13:50.180]   But truth can be uncomfortable.
[00:13:50.180 --> 00:13:54.180]   - I get that a lot about being uncomfortable
[00:13:54.180 --> 00:13:56.540]   talking about this.
[00:13:56.540 --> 00:13:59.760]   Let me go back and just say one more empirical thing.
[00:13:59.760 --> 00:14:07.060]   It doesn't matter which battery of tests you use.
[00:14:07.060 --> 00:14:10.700]   So there are countless tests.
[00:14:10.700 --> 00:14:13.500]   You can take any 12 of them at random,
[00:14:13.500 --> 00:14:17.100]   extract a G factor and another 12 at random
[00:14:17.100 --> 00:14:18.780]   and extract a G factor.
[00:14:18.780 --> 00:14:21.300]   And those G factors will be highly correlated
[00:14:21.300 --> 00:14:23.300]   like over 0.9 with each other.
[00:14:23.300 --> 00:14:27.020]   So it is a ubiquitous, it doesn't depend
[00:14:27.020 --> 00:14:30.260]   on the content of the test is what I'm trying to say.
[00:14:30.260 --> 00:14:34.020]   It is general among all those tests of mental ability.
[00:14:34.020 --> 00:14:37.900]   And tests of mental abilities include things like,
[00:14:37.900 --> 00:14:41.260]   geez, playing poker.
[00:14:41.260 --> 00:14:46.260]   Your skill at poker is not unrelated to G.
[00:14:46.260 --> 00:14:49.420]   Your skill at anything that requires reasoning
[00:14:49.420 --> 00:14:54.260]   and thinking, anything, spelling, arithmetic,
[00:14:54.260 --> 00:14:59.260]   more complex things, this concept is ubiquitous.
[00:14:59.260 --> 00:15:03.880]   And when you do batteries of tests in different cultures,
[00:15:03.880 --> 00:15:05.820]   you get the same thing.
[00:15:05.820 --> 00:15:08.860]   - So this says something interesting about the human mind
[00:15:08.860 --> 00:15:11.840]   that as a computer is designed to be general.
[00:15:11.840 --> 00:15:17.780]   So that means you can, so it's not easily made specialized.
[00:15:17.780 --> 00:15:23.660]   Meaning if you're going to be good at one thing,
[00:15:23.660 --> 00:15:29.780]   Miyamoto Musashi has this quote, he's an ancient warrior
[00:15:29.780 --> 00:15:31.900]   famous for the Book of Five Rings
[00:15:31.900 --> 00:15:33.420]   in the martial arts world.
[00:15:33.420 --> 00:15:36.620]   And the quote goes, "If you know the way broadly,
[00:15:36.620 --> 00:15:38.940]   "you will see it in everything."
[00:15:38.940 --> 00:15:42.780]   Meaning if you do one thing,
[00:15:42.780 --> 00:15:47.060]   it's going to generalize to everything.
[00:15:47.060 --> 00:15:49.700]   And that's an interesting thing about the human mind.
[00:15:49.700 --> 00:15:54.420]   So that's what the G factor reveals.
[00:15:54.420 --> 00:15:57.100]   Okay, so what's the difference,
[00:15:57.100 --> 00:15:58.940]   if you can elaborate a little bit further,
[00:15:58.940 --> 00:16:02.400]   between IQ and G factor, just because it's a source
[00:16:02.400 --> 00:16:03.580]   of confusion for people?
[00:16:03.580 --> 00:16:05.700]   - An IQ is a score.
[00:16:05.700 --> 00:16:08.300]   People use the word IQ to mean intelligence,
[00:16:08.300 --> 00:16:11.080]   but IQ has a more technical meaning
[00:16:11.080 --> 00:16:12.860]   for people who work in the field.
[00:16:12.860 --> 00:16:16.580]   And it's an IQ score, a score on a test
[00:16:16.580 --> 00:16:19.000]   that estimates the G factor.
[00:16:19.000 --> 00:16:22.060]   And the G factor is what's common
[00:16:22.060 --> 00:16:24.240]   among all these tests of mental ability.
[00:16:24.240 --> 00:16:27.080]   So if you think about, it's not a Venn diagram,
[00:16:27.080 --> 00:16:30.620]   but I guess you could make a Venn diagram out of it,
[00:16:30.620 --> 00:16:33.940]   but the G factor would be really at the core.
[00:16:33.940 --> 00:16:37.580]   What's common to everything.
[00:16:37.580 --> 00:16:42.580]   And what IQ scores do, is they allow a rank order
[00:16:42.580 --> 00:16:44.540]   of people on the score.
[00:16:44.540 --> 00:16:46.940]   And this is what makes people uncomfortable.
[00:16:46.940 --> 00:16:48.940]   This is where there's a lot of controversy
[00:16:48.940 --> 00:16:51.580]   about whether IQ tests are biased
[00:16:51.580 --> 00:16:54.420]   toward any one group or another.
[00:16:54.420 --> 00:16:59.100]   And a lot of the answers to these questions are very clear,
[00:16:59.100 --> 00:17:02.100]   but they also have a technical aspect of it
[00:17:02.100 --> 00:17:04.180]   that's not so easy to explain.
[00:17:04.180 --> 00:17:06.180]   - Well, we'll talk about the fascinating
[00:17:06.180 --> 00:17:08.380]   and the difficult things about all of this.
[00:17:08.380 --> 00:17:12.580]   So by the way, when you say rank order,
[00:17:12.580 --> 00:17:13.820]   that means you get a number,
[00:17:13.820 --> 00:17:17.540]   and that means one person, you can now compare.
[00:17:17.540 --> 00:17:20.900]   Like you could say that this other person
[00:17:20.900 --> 00:17:23.020]   is more intelligent than me.
[00:17:23.020 --> 00:17:25.820]   - Well, what you can say is IQ scores
[00:17:25.820 --> 00:17:28.300]   are interpreted really as percentiles.
[00:17:29.200 --> 00:17:34.200]   So that if you have an IQ of 140 and somebody else has 70,
[00:17:34.200 --> 00:17:38.680]   the metric is such that you cannot say the person
[00:17:38.680 --> 00:17:41.800]   with an IQ of 140 is twice as smart
[00:17:41.800 --> 00:17:46.000]   as a person with an IQ of 70.
[00:17:46.000 --> 00:17:49.920]   That would require a ratio scale with an absolute zero.
[00:17:49.920 --> 00:17:53.160]   Now you may think you know people with zero intelligence,
[00:17:53.160 --> 00:17:58.000]   but in fact, there is no absolute zero on an IQ scale.
[00:17:58.000 --> 00:18:00.020]   It's relative to other people.
[00:18:00.020 --> 00:18:03.240]   So relative to other people,
[00:18:03.240 --> 00:18:07.400]   somebody with an IQ score of 140 is in the upper
[00:18:07.400 --> 00:18:12.400]   less than 1%, whereas somebody with an IQ of 70
[00:18:12.400 --> 00:18:15.480]   is two standard deviations below the mean.
[00:18:15.480 --> 00:18:18.640]   That's a different percentile.
[00:18:18.640 --> 00:18:20.920]   - So it's similar to like in chess,
[00:18:20.920 --> 00:18:25.920]   you have an Elo rating that's designed to rank order people.
[00:18:27.760 --> 00:18:30.520]   So you can't say it's twice one person.
[00:18:30.520 --> 00:18:33.520]   If your Elo rating's twice another person,
[00:18:33.520 --> 00:18:36.160]   I don't think you're twice as good at chess.
[00:18:36.160 --> 00:18:37.920]   It's not stable in that way,
[00:18:37.920 --> 00:18:41.120]   because it's very difficult to do these kinds of comparisons.
[00:18:41.120 --> 00:18:45.960]   So what can we say about the number itself?
[00:18:45.960 --> 00:18:50.560]   Is that stable across tests and so on or no?
[00:18:50.560 --> 00:18:54.040]   - There are a number of statistical properties of any test.
[00:18:54.040 --> 00:18:56.440]   They're called psychometric properties.
[00:18:56.440 --> 00:18:59.320]   You have validity, you have reliability.
[00:18:59.320 --> 00:19:02.760]   Reliability, there are many different kinds of reliability.
[00:19:02.760 --> 00:19:05.960]   They all essentially measure stability.
[00:19:05.960 --> 00:19:09.760]   And IQ tests are stable within an individual.
[00:19:09.760 --> 00:19:11.920]   There are some longitudinal studies
[00:19:11.920 --> 00:19:15.800]   where children were measured at age 11.
[00:19:15.800 --> 00:19:18.120]   And again, when they were 70 years old
[00:19:18.120 --> 00:19:22.120]   and the two IQ scores are highly correlated with each other.
[00:19:22.120 --> 00:19:25.240]   This comes from a fascinating study from Scotland
[00:19:26.240 --> 00:19:31.240]   in the 1930s, some researchers decided to get an IQ test
[00:19:31.240 --> 00:19:36.120]   on every single child age 11 in the whole country.
[00:19:36.120 --> 00:19:37.600]   And they did.
[00:19:37.600 --> 00:19:42.600]   And those records were discovered in an old storeroom
[00:19:42.600 --> 00:19:47.280]   at the University of Edinburgh by a friend of mine,
[00:19:47.280 --> 00:19:52.280]   Ian Deary, who found the records, digitized them,
[00:19:52.280 --> 00:19:54.200]   and has done a lot of research
[00:19:54.200 --> 00:19:57.520]   on the people who are still alive today
[00:19:57.520 --> 00:19:58.840]   from that original study,
[00:19:58.840 --> 00:20:01.160]   including brain imaging research, by the way.
[00:20:01.160 --> 00:20:06.160]   Really, it's a fascinating group of people who are studied.
[00:20:06.160 --> 00:20:09.300]   Not to get ahead of the story,
[00:20:09.300 --> 00:20:12.560]   but one of the most interesting things they found
[00:20:12.560 --> 00:20:14.680]   is a very strong relationship
[00:20:14.680 --> 00:20:19.680]   between IQ measured at age 11 and mortality.
[00:20:21.680 --> 00:20:26.680]   So that, you know, 70 years later,
[00:20:26.680 --> 00:20:30.960]   they looked at the survival rates
[00:20:30.960 --> 00:20:33.280]   and they could get death records from everybody.
[00:20:33.280 --> 00:20:37.120]   And Scotland has universal healthcare for everybody.
[00:20:37.120 --> 00:20:40.040]   And it turned out if you divide people
[00:20:40.040 --> 00:20:44.040]   by their age 11 IQ score into quartiles,
[00:20:44.040 --> 00:20:48.720]   and then look at how many people are alive 70 years later,
[00:20:51.200 --> 00:20:54.640]   I know this is in the book, I have the graph in the book,
[00:20:54.640 --> 00:20:57.840]   but there are essentially twice as many people alive
[00:20:57.840 --> 00:21:01.680]   in the highest IQ quartile than in the lowest IQ quartile.
[00:21:01.680 --> 00:21:03.880]   - Interesting. - It's true in men and women.
[00:21:03.880 --> 00:21:06.920]   - Interesting.
[00:21:06.920 --> 00:21:08.100]   - So it makes a big difference.
[00:21:08.100 --> 00:21:12.920]   Now, why this is the case is not so clear
[00:21:12.920 --> 00:21:15.600]   since everyone had access to healthcare.
[00:21:15.600 --> 00:21:17.360]   - Well, there's a lot, and we'll talk about it,
[00:21:18.360 --> 00:21:22.120]   just the sentences you used now
[00:21:22.120 --> 00:21:25.800]   could be explained by nature or nurture.
[00:21:25.800 --> 00:21:27.000]   We don't know.
[00:21:27.000 --> 00:21:29.720]   Now, there's a lot of science that starts to then dig in
[00:21:29.720 --> 00:21:31.720]   and investigate that question.
[00:21:31.720 --> 00:21:33.720]   But let me linger on the IQ test.
[00:21:33.720 --> 00:21:37.400]   How are the test design, IQ test design, how do they work?
[00:21:37.400 --> 00:21:40.160]   Maybe some examples for people who are not aware.
[00:21:40.160 --> 00:21:44.040]   What makes a good IQ test question
[00:21:44.040 --> 00:21:47.320]   that sneaks up on this G factor?
[00:21:47.320 --> 00:21:49.760]   - Well, your question is interesting
[00:21:49.760 --> 00:21:53.360]   because you want me to give examples of items
[00:21:53.360 --> 00:21:55.240]   that make good items.
[00:21:55.240 --> 00:21:59.440]   And what makes a good item is not so much its content,
[00:21:59.440 --> 00:22:03.200]   but its empirical relationship to the total score
[00:22:03.200 --> 00:22:07.760]   that turns out to be valid by other means.
[00:22:07.760 --> 00:22:12.500]   So for example, let me give you an odd example
[00:22:12.500 --> 00:22:14.320]   from personality testing.
[00:22:14.320 --> 00:22:15.560]   - Nice.
[00:22:15.560 --> 00:22:18.040]   - So there's a personality test
[00:22:18.040 --> 00:22:22.720]   called the Minnesota Multiphasic Personality Inventory, MMPI.
[00:22:22.720 --> 00:22:24.120]   Been around for decades.
[00:22:24.120 --> 00:22:26.000]   - I've heard about this test recently
[00:22:26.000 --> 00:22:29.240]   because of the Johnny Depp and Amber Heard trial.
[00:22:29.240 --> 00:22:31.200]   I don't know if you've been paying attention to that.
[00:22:31.200 --> 00:22:32.040]   But they had psychologists--
[00:22:32.040 --> 00:22:33.560]   - I have not been paying attention to it.
[00:22:33.560 --> 00:22:35.800]   - They had psychologists on the stand,
[00:22:35.800 --> 00:22:38.900]   and they were talking, apparently those psychologists did,
[00:22:38.900 --> 00:22:42.240]   again, I'm learning so much from this trial.
[00:22:42.240 --> 00:22:45.840]   They did different, a battery of tests
[00:22:45.840 --> 00:22:50.420]   to diagnose personality disorders.
[00:22:50.420 --> 00:22:53.280]   Apparently there's that systematic way of doing so,
[00:22:53.280 --> 00:22:55.720]   and the Minnesota one is one of the ones
[00:22:55.720 --> 00:22:59.040]   that there's the most science on.
[00:22:59.040 --> 00:23:00.440]   There's a lot of great papers,
[00:23:00.440 --> 00:23:03.840]   which were all continuously cited on the stand,
[00:23:03.840 --> 00:23:05.040]   which is fascinating to watch.
[00:23:05.040 --> 00:23:06.480]   Sorry, a little bit of attention.
[00:23:06.480 --> 00:23:07.560]   - It's okay, I mean, this is interesting
[00:23:07.560 --> 00:23:09.560]   because you're right, it's been around for decades.
[00:23:09.560 --> 00:23:11.240]   There's a lot of scientific research
[00:23:11.240 --> 00:23:14.840]   on the psychometric properties of the test,
[00:23:14.840 --> 00:23:18.000]   including what it predicts with respect
[00:23:18.000 --> 00:23:22.320]   to different categories of personality disorder.
[00:23:22.320 --> 00:23:24.840]   But what I wanna mention is the content
[00:23:24.840 --> 00:23:26.880]   of the items on that test.
[00:23:26.880 --> 00:23:31.880]   All of the items are essentially true/false items.
[00:23:31.880 --> 00:23:35.900]   True or false, I prefer a shower to a bath.
[00:23:35.900 --> 00:23:41.200]   True or false, I think Lincoln was a better president
[00:23:41.200 --> 00:23:42.280]   than Washington.
[00:23:42.280 --> 00:23:46.580]   What have all these, what does that have to do?
[00:23:46.580 --> 00:23:49.720]   And the point is the content in these items,
[00:23:49.720 --> 00:23:54.720]   nobody knows why these items in aggregate predict anything,
[00:23:54.720 --> 00:23:57.900]   but empirically they do.
[00:23:57.900 --> 00:24:01.880]   It's a technique of choosing items for a test
[00:24:01.880 --> 00:24:04.820]   that is called dust bowl empiricism,
[00:24:04.820 --> 00:24:07.440]   that the content doesn't matter,
[00:24:07.440 --> 00:24:10.640]   but for some reason, when you get a criterion group
[00:24:10.640 --> 00:24:13.600]   of people with this disorder and you compare them
[00:24:13.600 --> 00:24:16.120]   to people without that disorder,
[00:24:16.120 --> 00:24:18.360]   these are the items that distinguish.
[00:24:18.360 --> 00:24:22.680]   Irrespective of content, it's a hard concept to grasp.
[00:24:22.680 --> 00:24:25.040]   - Well, first of all, it's fascinating.
[00:24:25.040 --> 00:24:32.120]   'Cause I consider myself part psychologist
[00:24:32.120 --> 00:24:35.360]   'cause I love human-robot interaction,
[00:24:35.360 --> 00:24:38.180]   and that's a problem, half of that problem
[00:24:38.180 --> 00:24:40.720]   is a psychology problem 'cause there's a human.
[00:24:40.720 --> 00:24:45.180]   So designing these tests to get at the questions
[00:24:45.180 --> 00:24:46.540]   is the fascinating part.
[00:24:46.540 --> 00:24:52.660]   What does dust bowl empiricism refer to?
[00:24:52.660 --> 00:24:57.420]   Does it refer to the final result?
[00:24:57.420 --> 00:25:01.500]   Yeah, so it's the test is dust bowl empiricism,
[00:25:01.500 --> 00:25:04.940]   but how do you arrive at the battery of questions?
[00:25:04.940 --> 00:25:08.060]   I presume one of the things, now again,
[00:25:08.060 --> 00:25:11.160]   I'm going to the excellent testimony in that trial,
[00:25:11.160 --> 00:25:14.760]   'cause they also explain the tests,
[00:25:14.760 --> 00:25:19.360]   that a bunch of the questions are kind of,
[00:25:19.360 --> 00:25:24.060]   make you forget that you're taking a test.
[00:25:24.060 --> 00:25:26.700]   Like, it makes it very difficult for you
[00:25:26.700 --> 00:25:31.700]   to somehow figure out what you're supposed to answer.
[00:25:31.700 --> 00:25:34.100]   - Yes, it's called social desirability.
[00:25:34.100 --> 00:25:35.580]   But we're getting a little far afield
[00:25:35.580 --> 00:25:37.400]   'cause I only wanted to give that example
[00:25:37.400 --> 00:25:39.200]   of dust bowl empiricism.
[00:25:39.200 --> 00:25:43.540]   When we talk about the items on an IQ test,
[00:25:43.540 --> 00:25:49.380]   many of those items in the dust bowl empiricism method
[00:25:49.380 --> 00:25:52.940]   have no face validity.
[00:25:52.940 --> 00:25:56.460]   In other words, they don't look like they measure anything.
[00:25:56.460 --> 00:25:57.540]   - Yes.
[00:25:57.540 --> 00:25:59.900]   - Whereas most intelligence tests,
[00:25:59.900 --> 00:26:01.500]   the items actually look like
[00:26:01.500 --> 00:26:03.860]   they're measuring some mental ability.
[00:26:03.860 --> 00:26:04.700]   So here's one of the--
[00:26:04.700 --> 00:26:06.980]   - Oh, so you were bringing that up as an example
[00:26:06.980 --> 00:26:08.200]   as what it is not.
[00:26:08.200 --> 00:26:09.040]   - Yes.
[00:26:09.040 --> 00:26:09.860]   - Got it.
[00:26:09.860 --> 00:26:12.880]   - Okay, so I don't want to go too far afield on it.
[00:26:12.880 --> 00:26:14.520]   - Too far afield is actually
[00:26:14.520 --> 00:26:16.100]   one of the names of this podcast,
[00:26:16.100 --> 00:26:19.080]   so I should mention that.
[00:26:19.080 --> 00:26:19.920]   - Far afield, yeah.
[00:26:19.920 --> 00:26:21.120]   - Far afield.
[00:26:21.120 --> 00:26:22.240]   Yeah, so anyway, sorry.
[00:26:22.240 --> 00:26:25.020]   So they feel the questions look like
[00:26:25.020 --> 00:26:28.040]   they passed the face validity test.
[00:26:28.040 --> 00:26:29.700]   - And some more than others.
[00:26:29.700 --> 00:26:32.500]   So for example, let me give you a couple of things here.
[00:26:33.840 --> 00:26:37.300]   One of the subtests on a standard IQ test
[00:26:37.300 --> 00:26:39.540]   is general information.
[00:26:39.540 --> 00:26:41.880]   Let me just think a little bit
[00:26:41.880 --> 00:26:44.340]   'cause I don't want to give you the actual item.
[00:26:44.340 --> 00:26:47.120]   But if I said, how far is it
[00:26:47.120 --> 00:26:51.140]   between Washington DC and Miami, Florida
[00:26:51.140 --> 00:26:54.720]   within 500 miles, plus or minus?
[00:26:54.720 --> 00:27:00.060]   Well, it's not a fact most people memorize,
[00:27:00.060 --> 00:27:02.680]   but you know something about geography.
[00:27:02.680 --> 00:27:04.440]   You say, well, I flew there once.
[00:27:04.440 --> 00:27:06.980]   I know planes fly 500 miles.
[00:27:06.980 --> 00:27:09.160]   You can kind of make an estimate.
[00:27:09.160 --> 00:27:13.880]   But it also seems like it would be very cultural.
[00:27:13.880 --> 00:27:20.200]   So there's that kind of general information.
[00:27:20.200 --> 00:27:22.760]   Then there's vocabulary test.
[00:27:22.760 --> 00:27:27.760]   What does regatta mean?
[00:27:27.760 --> 00:27:30.100]   And I choose that word
[00:27:30.100 --> 00:27:33.180]   because that word was removed from the IQ test
[00:27:33.180 --> 00:27:36.260]   because people complained that disadvantaged people
[00:27:36.260 --> 00:27:41.260]   would not know that word just from their everyday life.
[00:27:41.260 --> 00:27:47.220]   Here's another example from a different kind of subtest.
[00:27:47.220 --> 00:27:48.940]   - What's regatta, by the way?
[00:27:48.940 --> 00:27:51.020]   - Regatta is a--
[00:27:51.020 --> 00:27:52.220]   - I think I'm disadvantaged.
[00:27:52.220 --> 00:27:55.420]   - A sailing competition, a competition with boats.
[00:27:55.420 --> 00:27:58.780]   Not necessarily sailing, but a competition with boats.
[00:27:58.780 --> 00:28:02.180]   - Yep, yep, I'm probably disadvantaged in that way.
[00:28:02.180 --> 00:28:03.860]   Okay, excellent, so that was removed.
[00:28:03.860 --> 00:28:04.980]   Anyway, what you were saying.
[00:28:04.980 --> 00:28:07.840]   - Okay, so here's another subtest.
[00:28:07.840 --> 00:28:09.840]   I'm gonna repeat a string of numbers,
[00:28:09.840 --> 00:28:12.680]   and when I'm done, I want you to repeat them back to me.
[00:28:12.680 --> 00:28:13.520]   Ready?
[00:28:13.520 --> 00:28:19.360]   Seven, four, two, eight, one, six.
[00:28:19.360 --> 00:28:22.580]   - That's way too many.
[00:28:22.580 --> 00:28:25.480]   Seven, four, two, eight, one, six.
[00:28:25.480 --> 00:28:26.320]   - You get the idea.
[00:28:26.320 --> 00:28:30.480]   Now, the actual test starts with a smaller number,
[00:28:30.480 --> 00:28:33.520]   you know, like two numbers, and then as people get it right,
[00:28:33.520 --> 00:28:36.560]   you keep going, adding to the string of numbers
[00:28:36.560 --> 00:28:38.640]   until they can't do it anymore.
[00:28:38.640 --> 00:28:40.760]   Okay, but now try this.
[00:28:40.760 --> 00:28:43.800]   I'm gonna say some numbers, and when I'm done,
[00:28:43.800 --> 00:28:46.680]   I want you to repeat them to me backwards.
[00:28:46.680 --> 00:28:47.800]   - I quit.
[00:28:47.800 --> 00:28:51.560]   - Okay, now, so I gave you some examples
[00:28:51.560 --> 00:28:53.600]   of the kind of items on an IQ test.
[00:28:53.600 --> 00:28:55.280]   - Yes. - General information.
[00:28:55.280 --> 00:28:58.640]   I can't even remember all of it.
[00:28:58.640 --> 00:29:01.680]   General information, vocabulary,
[00:29:01.680 --> 00:29:06.680]   digit span forward and digit span backward.
[00:29:06.680 --> 00:29:08.960]   - Well, you said I can't even remember them.
[00:29:08.960 --> 00:29:10.500]   That's a good question for me.
[00:29:10.500 --> 00:29:14.560]   What does memory have to do with your function?
[00:29:14.560 --> 00:29:15.400]   - Let's hold on.
[00:29:15.400 --> 00:29:16.240]   - Okay, all right.
[00:29:16.240 --> 00:29:19.720]   - Let's just talk about these examples.
[00:29:19.720 --> 00:29:24.720]   Now, some of those items seem very cultural,
[00:29:24.720 --> 00:29:29.960]   and others seem less cultural.
[00:29:29.960 --> 00:29:35.360]   Which ones do you think, scores on which subtests
[00:29:35.360 --> 00:29:38.440]   are most highly correlated with the G factor?
[00:29:38.440 --> 00:29:42.560]   - Well, the two advances less cultural.
[00:29:42.560 --> 00:29:48.580]   - Well, it turns out vocabulary is highly correlated,
[00:29:49.580 --> 00:29:54.220]   and it turns out that digit span backwards
[00:29:54.220 --> 00:29:55.720]   is highly correlated.
[00:29:55.720 --> 00:29:58.620]   - How do you figure?
[00:29:58.620 --> 00:30:02.240]   - Now you have decades of research
[00:30:02.240 --> 00:30:04.580]   to answer the question, how do you figure?
[00:30:04.580 --> 00:30:08.460]   - Right, so now there's good research
[00:30:08.460 --> 00:30:11.320]   that gives you intuition about what kind of questions
[00:30:11.320 --> 00:30:16.320]   get added, just like there's something I've done,
[00:30:18.100 --> 00:30:20.300]   I've actually used for research,
[00:30:20.300 --> 00:30:22.020]   just send me an autonomous vehicle,
[00:30:22.020 --> 00:30:24.380]   like whether humans are paying attention,
[00:30:24.380 --> 00:30:26.820]   there's a body of literature that does
[00:30:26.820 --> 00:30:29.060]   like end-back tests, for example,
[00:30:29.060 --> 00:30:34.060]   where you have to put workload on the brain
[00:30:34.060 --> 00:30:37.820]   to do recall, memory recall,
[00:30:37.820 --> 00:30:42.100]   and that helps you kind of put some work onto the brain
[00:30:42.100 --> 00:30:44.260]   while the person is doing some other task,
[00:30:44.260 --> 00:30:46.820]   and there's some interesting research with that.
[00:30:47.700 --> 00:30:48.940]   But that's loading the memory,
[00:30:48.940 --> 00:30:52.260]   and so there's like research around stably
[00:30:52.260 --> 00:30:54.100]   what that means about the human mind,
[00:30:54.100 --> 00:30:57.140]   and here you're saying recall backwards
[00:30:57.140 --> 00:31:00.020]   is a good predictor.
[00:31:00.020 --> 00:31:01.740]   - It's a transformation.
[00:31:01.740 --> 00:31:04.120]   - Yeah, so you have to do some,
[00:31:04.120 --> 00:31:07.820]   like you have to load that into your brain,
[00:31:07.820 --> 00:31:11.220]   and not just remember it, but do something with it.
[00:31:11.220 --> 00:31:12.620]   - Right, now here's another example
[00:31:12.620 --> 00:31:14.460]   of a different kind of test,
[00:31:14.460 --> 00:31:18.340]   called the Hick paradigm, and it's not verbal at all.
[00:31:18.340 --> 00:31:23.140]   It's a little box, and there are a series of lights
[00:31:23.140 --> 00:31:27.420]   arranged in a semi-circle at the top of the box,
[00:31:27.420 --> 00:31:31.300]   and then there's a home button that you press,
[00:31:31.300 --> 00:31:33.880]   and when one of the lights goes on,
[00:31:33.880 --> 00:31:37.780]   there's a button next to each of those lights,
[00:31:37.780 --> 00:31:39.940]   you take your finger off the home button,
[00:31:39.940 --> 00:31:42.780]   and you just press the button next to the light
[00:31:42.780 --> 00:31:46.500]   that goes on, and so it's a very simple reaction time.
[00:31:46.500 --> 00:31:49.220]   Light goes on, as quick as you can, you press the button,
[00:31:49.220 --> 00:31:50.540]   and you get a reaction time.
[00:31:50.540 --> 00:31:53.820]   From the moment you lift your finger off the button,
[00:31:53.820 --> 00:31:57.780]   when you press the button where the light is,
[00:31:57.780 --> 00:32:02.160]   that reaction time doesn't really correlate
[00:32:02.160 --> 00:32:07.160]   with IQ very much, but if you change the instructions,
[00:32:07.160 --> 00:32:12.620]   and you say three lights are gonna come on simultaneously,
[00:32:13.100 --> 00:32:15.620]   I want you to press the button next to the light
[00:32:15.620 --> 00:32:17.860]   that's furthest from the other two.
[00:32:17.860 --> 00:32:21.260]   So maybe lights one and two go on,
[00:32:21.260 --> 00:32:24.260]   and light six goes on simultaneously.
[00:32:24.260 --> 00:32:26.120]   You take your finger off, and you would press
[00:32:26.120 --> 00:32:27.900]   the button by light six.
[00:32:27.900 --> 00:32:33.860]   That's, that reaction time to a more complex task,
[00:32:33.860 --> 00:32:38.360]   it's not really hard, almost everybody gets it all right,
[00:32:38.360 --> 00:32:42.520]   but your reaction time to that is highly correlated
[00:32:42.520 --> 00:32:43.740]   with the G factor.
[00:32:43.740 --> 00:32:46.020]   - This is fascinating, so reaction time,
[00:32:46.020 --> 00:32:48.580]   so there's a temporal aspect to this.
[00:32:48.580 --> 00:32:50.860]   So what role does time-- - Speed of processing.
[00:32:50.860 --> 00:32:53.020]   It's the speed of processing.
[00:32:53.020 --> 00:32:55.740]   - Is this also true for ones that take longer,
[00:32:55.740 --> 00:32:57.700]   like five, 10, 30 seconds?
[00:32:57.700 --> 00:33:01.180]   Is time part of the measure with some of these ideas?
[00:33:01.180 --> 00:33:05.620]   - Yes, and that is why some of the best IQ tests
[00:33:05.620 --> 00:33:10.620]   have a time limit, because if you have no time limit,
[00:33:10.620 --> 00:33:15.040]   people can do better, but it doesn't distinguish
[00:33:15.040 --> 00:33:17.760]   among people that well.
[00:33:17.760 --> 00:33:21.440]   So that adding the time element is important.
[00:33:21.440 --> 00:33:24.100]   So speed of information processing,
[00:33:24.100 --> 00:33:27.220]   and reaction time is a measure of speed
[00:33:27.220 --> 00:33:30.600]   of information processing, turns out to be related
[00:33:30.600 --> 00:33:31.920]   to the G factor.
[00:33:31.920 --> 00:33:35.040]   - But the G factor only accounts for maybe half
[00:33:35.040 --> 00:33:37.560]   or some amount on the test performance.
[00:33:37.560 --> 00:33:42.060]   For example, I get pretty bad test anxiety.
[00:33:42.060 --> 00:33:47.060]   Like I was never, I mean, I just don't enjoy tests.
[00:33:47.060 --> 00:33:51.300]   I enjoy going back into my cave and working.
[00:33:51.300 --> 00:33:55.200]   Like I've always enjoyed homework way more than tests,
[00:33:55.200 --> 00:33:57.780]   no matter how hard the homework is,
[00:33:57.780 --> 00:33:59.980]   'cause I can go back to the cave and hide away
[00:33:59.980 --> 00:34:00.820]   and think deeply.
[00:34:00.820 --> 00:34:02.700]   There's something about being watched
[00:34:02.700 --> 00:34:06.060]   and having a time limit that really makes me anxious,
[00:34:06.060 --> 00:34:09.520]   and I could just see the mind not operating optimally
[00:34:09.520 --> 00:34:11.640]   at all, but you're saying underneath there,
[00:34:11.640 --> 00:34:13.720]   there's still a G factor, there's still--
[00:34:13.720 --> 00:34:16.360]   - No question, no question.
[00:34:16.360 --> 00:34:17.280]   - Boy.
[00:34:17.280 --> 00:34:19.240]   - And if you get anxious taking the test,
[00:34:19.240 --> 00:34:22.140]   many people say, oh, I didn't do well 'cause I'm anxious.
[00:34:22.140 --> 00:34:24.960]   I hear that a lot.
[00:34:24.960 --> 00:34:28.320]   Well, fine, if you're really anxious during the test,
[00:34:28.320 --> 00:34:32.000]   the score will be a bad estimate of your G factor.
[00:34:32.000 --> 00:34:34.840]   It doesn't mean the G factor isn't there.
[00:34:34.840 --> 00:34:39.080]   And by the way, standardized tests like the SAT,
[00:34:39.080 --> 00:34:43.020]   they're essentially intelligence tests.
[00:34:43.020 --> 00:34:45.200]   They are highly G loaded.
[00:34:45.200 --> 00:34:49.200]   Now, the people who make the SAT don't wanna mention that.
[00:34:49.200 --> 00:34:54.000]   They have enough trouble justifying standardized testing,
[00:34:54.000 --> 00:34:56.000]   but to call it an intelligence test
[00:34:56.000 --> 00:34:58.400]   is really beyond the pale.
[00:34:58.400 --> 00:35:00.700]   But in fact, it's so highly correlated
[00:35:00.700 --> 00:35:03.200]   because it's a reasoning test.
[00:35:03.200 --> 00:35:06.160]   The SAT is a reasoning test, a verbal reasoning,
[00:35:06.160 --> 00:35:08.240]   mathematical reasoning.
[00:35:08.240 --> 00:35:12.240]   And if it's a reasoning test, it has to be related to G.
[00:35:12.240 --> 00:35:17.560]   But if people go in and take a standardized test,
[00:35:17.560 --> 00:35:20.120]   whether it's an IQ test or the SAT,
[00:35:20.120 --> 00:35:24.600]   and they happen to be sick that day with 102 fever,
[00:35:24.600 --> 00:35:29.600]   the score is not going to be a good estimate of their G.
[00:35:29.600 --> 00:35:33.120]   If they retake the test when they're not anxious
[00:35:33.120 --> 00:35:35.740]   or less anxious or don't have a fever,
[00:35:35.740 --> 00:35:39.960]   the score will go up and that will be a better estimate.
[00:35:39.960 --> 00:35:43.120]   But you can't say their G factor increased
[00:35:43.120 --> 00:35:45.160]   between the two tests.
[00:35:45.160 --> 00:35:46.480]   - Well, it's interesting.
[00:35:46.480 --> 00:35:50.000]   So the question is how wide of a battery of tests
[00:35:50.000 --> 00:35:53.380]   is required to estimate the G factor well?
[00:35:53.380 --> 00:35:55.160]   Because I'll give you as my personal example,
[00:35:55.160 --> 00:35:58.760]   I took the SAT in, I think it was called the ACT
[00:35:58.760 --> 00:36:02.880]   where I was too, also, I took SAT many times.
[00:36:02.880 --> 00:36:05.520]   Every single time I got a perfect on math.
[00:36:05.520 --> 00:36:08.800]   And verbal, the time limit on the verbal
[00:36:08.800 --> 00:36:11.000]   made me very anxious.
[00:36:11.000 --> 00:36:12.520]   I did not, I mean, part of it,
[00:36:12.520 --> 00:36:14.240]   I didn't speak English very well,
[00:36:14.240 --> 00:36:15.920]   but honestly, it was like,
[00:36:15.920 --> 00:36:17.480]   you're supposed to remember stuff.
[00:36:17.480 --> 00:36:18.800]   And like, I was so anxious.
[00:36:18.800 --> 00:36:20.940]   And like, as I'm reading, I'm sweating.
[00:36:20.940 --> 00:36:22.680]   I can't, you know that like,
[00:36:22.680 --> 00:36:27.040]   that feeling you have when you're reading a book
[00:36:27.040 --> 00:36:30.120]   and you just read a page and you know nothing
[00:36:30.120 --> 00:36:32.640]   about what you've read because you zoned out?
[00:36:32.640 --> 00:36:35.000]   That's the same feeling of like,
[00:36:35.000 --> 00:36:38.040]   I can't, I have to, you're like, nope.
[00:36:38.040 --> 00:36:41.120]   Read and understand and that anxiety is like,
[00:36:41.120 --> 00:36:44.880]   and you start seeing like the typography
[00:36:44.880 --> 00:36:47.120]   versus the content of the words.
[00:36:47.120 --> 00:36:50.800]   Like that was, I don't, it's interesting because
[00:36:50.800 --> 00:36:55.760]   I know that what they're measuring,
[00:36:55.760 --> 00:36:58.760]   I could see being correlated with something.
[00:36:58.760 --> 00:37:02.840]   But that anxiety or some aspect of the performance
[00:37:02.840 --> 00:37:07.020]   sure plays a factor.
[00:37:07.020 --> 00:37:10.400]   And I wonder how you sneak up in a stable way.
[00:37:10.400 --> 00:37:12.840]   I mean, this is a broader discussion about,
[00:37:12.840 --> 00:37:16.600]   that's like standardized testing, how you sneak up,
[00:37:16.600 --> 00:37:19.880]   how you get at the fact that I'm super anxious
[00:37:19.880 --> 00:37:21.440]   and still nevertheless measure
[00:37:21.440 --> 00:37:23.080]   some aspect of my intelligence.
[00:37:23.080 --> 00:37:26.640]   I wonder, I don't know if you can say to that,
[00:37:26.640 --> 00:37:28.600]   that time limit sure is a pain.
[00:37:28.600 --> 00:37:30.560]   - Well, let me say this.
[00:37:30.560 --> 00:37:34.200]   There are two ways to approach the very real problem
[00:37:34.200 --> 00:37:36.920]   that you say that some people just get anxious
[00:37:36.920 --> 00:37:39.000]   or not good test takers.
[00:37:39.000 --> 00:37:44.000]   By the way, part of testing is,
[00:37:44.000 --> 00:37:47.520]   you know the answer, you can figure out the answer
[00:37:47.520 --> 00:37:48.440]   or you can't.
[00:37:48.440 --> 00:37:51.640]   If you don't know the answer,
[00:37:51.640 --> 00:37:54.000]   there are many reasons you don't know the answer
[00:37:54.000 --> 00:37:55.280]   at that particular moment.
[00:37:55.280 --> 00:37:58.480]   You may have learned it once and forgotten it.
[00:37:58.480 --> 00:38:00.600]   You may, it may be on the tip of your tongue
[00:38:00.600 --> 00:38:01.920]   and you just can't get it
[00:38:01.920 --> 00:38:03.880]   because you're anxious about the time limit.
[00:38:03.880 --> 00:38:05.920]   You may never have learned it.
[00:38:05.920 --> 00:38:08.720]   You may never, you may have been exposed to it,
[00:38:08.720 --> 00:38:11.440]   but it was too complicated and you couldn't learn it.
[00:38:11.440 --> 00:38:14.000]   I mean, there are all kinds of reasons here,
[00:38:14.000 --> 00:38:18.840]   but for an individual to interpret your scores
[00:38:18.840 --> 00:38:23.360]   as an individual, whoever is interpreting the score
[00:38:23.360 --> 00:38:26.280]   has to take into account various things
[00:38:26.280 --> 00:38:29.200]   that would affect your individual score.
[00:38:29.200 --> 00:38:32.720]   And that's why decisions about college admission
[00:38:32.720 --> 00:38:35.720]   or anything else where tests are used
[00:38:35.720 --> 00:38:40.720]   are hardly ever the only criterion to make a decision.
[00:38:40.720 --> 00:38:44.120]   - And I think people are,
[00:38:44.120 --> 00:38:46.880]   college admissions letting go of that very much.
[00:38:46.880 --> 00:38:48.120]   - Oh yes, yeah.
[00:38:48.120 --> 00:38:51.040]   - But what does that even mean?
[00:38:51.040 --> 00:38:55.560]   Because is it possible to design standardized tests
[00:38:55.560 --> 00:38:58.400]   that do get, that are useful to college admissions?
[00:38:58.400 --> 00:38:59.720]   - Well, they already exist.
[00:38:59.720 --> 00:39:02.320]   The SAT is highly correlated
[00:39:02.320 --> 00:39:05.240]   with many aspects of success at college.
[00:39:05.240 --> 00:39:06.360]   - Here's the problem.
[00:39:06.360 --> 00:39:09.200]   So maybe you could speak to this.
[00:39:09.200 --> 00:39:13.360]   The correlation across the population versus individuals.
[00:39:13.360 --> 00:39:14.200]   So,
[00:39:14.200 --> 00:39:21.580]   our criminal justice system is designed to make sure,
[00:39:23.440 --> 00:39:27.280]   well, it's still, there's tragic cases
[00:39:27.280 --> 00:39:29.640]   where innocent people go to jail,
[00:39:29.640 --> 00:39:31.320]   but you try to avoid that.
[00:39:31.320 --> 00:39:34.400]   In the same way with testing,
[00:39:34.400 --> 00:39:38.740]   it just, it would suck for an SAT to miss genius.
[00:39:38.740 --> 00:39:43.240]   - Yes, and it's possible, but it's statistically unlikely.
[00:39:43.240 --> 00:39:45.880]   So it really comes down to,
[00:39:45.880 --> 00:39:50.520]   do which piece of information
[00:39:51.920 --> 00:39:56.920]   maximizes your decision-making ability?
[00:39:56.920 --> 00:40:03.600]   So, if you just use high school grades, it's okay,
[00:40:03.600 --> 00:40:07.160]   but you will miss some people
[00:40:07.160 --> 00:40:09.120]   who just don't do well in high school,
[00:40:09.120 --> 00:40:11.320]   but who are actually pretty smart,
[00:40:11.320 --> 00:40:13.960]   smart enough to be bored silly in high school,
[00:40:13.960 --> 00:40:14.920]   and they don't care,
[00:40:14.920 --> 00:40:17.760]   and their high school GPA isn't that good.
[00:40:17.760 --> 00:40:19.560]   So you will miss them,
[00:40:19.560 --> 00:40:24.560]   in the same sense that somebody who could be very able
[00:40:24.560 --> 00:40:28.320]   and ready for a college just doesn't do well on their SAT.
[00:40:28.320 --> 00:40:31.640]   This is why you make decisions
[00:40:31.640 --> 00:40:36.100]   with taking in a variety of information.
[00:40:36.100 --> 00:40:38.040]   The other thing I wanted to say,
[00:40:38.040 --> 00:40:43.800]   I talked about when you make a decision for an individual.
[00:40:43.800 --> 00:40:46.680]   Statistically, for groups,
[00:40:46.680 --> 00:40:50.020]   there are many people who have a disparity
[00:40:50.020 --> 00:40:53.040]   between their math score and their verbal score.
[00:40:53.040 --> 00:40:55.600]   That disparity, or the other way around,
[00:40:55.600 --> 00:40:58.640]   that disparity is called tilt.
[00:40:58.640 --> 00:41:01.720]   The score is tilted one way or the other,
[00:41:01.720 --> 00:41:05.040]   and that tilt has been studied empirically
[00:41:05.040 --> 00:41:07.280]   to see what that predicts.
[00:41:07.280 --> 00:41:09.400]   And in fact, you can't make predictions
[00:41:09.400 --> 00:41:14.400]   about college success based on tilt.
[00:41:14.840 --> 00:41:16.760]   And mathematics is a good example.
[00:41:16.760 --> 00:41:18.320]   There are many people,
[00:41:18.320 --> 00:41:21.080]   especially non-native speakers of English,
[00:41:21.080 --> 00:41:23.480]   come to this country, take the SATs,
[00:41:23.480 --> 00:41:26.840]   do very well on the math and not so well on the verbal.
[00:41:26.840 --> 00:41:30.380]   Well, if they're applying to a math program,
[00:41:30.380 --> 00:41:33.840]   the professors there who are making the decision
[00:41:33.840 --> 00:41:35.500]   or the admissions officers,
[00:41:35.500 --> 00:41:39.620]   don't wait so much to score on verbal,
[00:41:39.620 --> 00:41:42.120]   especially if it's a non-native speaker.
[00:41:42.120 --> 00:41:44.520]   - Well, so yeah, you have to try to,
[00:41:44.520 --> 00:41:47.800]   in the admission process, bring in the context.
[00:41:47.800 --> 00:41:50.760]   But non-native isn't really the problem.
[00:41:50.760 --> 00:41:53.720]   I mean, that was part of the problem for me.
[00:41:53.720 --> 00:41:57.960]   But it's the anxiety was, which it's interesting.
[00:41:57.960 --> 00:41:58.980]   It's interesting.
[00:41:58.980 --> 00:42:06.520]   Oh boy, reducing yourself down to numbers.
[00:42:06.520 --> 00:42:07.840]   But it's still true.
[00:42:07.840 --> 00:42:09.200]   It's still the truth.
[00:42:09.200 --> 00:42:10.720]   - Well-- - It's a painful truth.
[00:42:10.720 --> 00:42:13.120]   That same anxiety that led me to be
[00:42:13.880 --> 00:42:18.880]   to struggle with the SAT verbal tests
[00:42:18.880 --> 00:42:24.640]   is still within me in all ways of life.
[00:42:24.640 --> 00:42:26.860]   So maybe that's not anxiety.
[00:42:26.860 --> 00:42:28.760]   Maybe that's something,
[00:42:28.760 --> 00:42:32.400]   you know, like personality is also pretty stable.
[00:42:32.400 --> 00:42:34.480]   - Personality is stable.
[00:42:34.480 --> 00:42:39.480]   Personality does impact the way you navigate life.
[00:42:39.480 --> 00:42:41.020]   - Yeah.
[00:42:41.020 --> 00:42:42.480]   - There's no question.
[00:42:42.480 --> 00:42:45.680]   - Yeah, and we should say that the G factor in intelligence
[00:42:45.680 --> 00:42:50.400]   is not just about some kind of number on a paper.
[00:42:50.400 --> 00:42:54.760]   It also has to do with how you navigate life,
[00:42:54.760 --> 00:42:59.760]   how easy life is for you in this very complicated world.
[00:42:59.760 --> 00:43:02.880]   So personality's all tied into that
[00:43:02.880 --> 00:43:05.880]   in some deep fundamental way.
[00:43:05.880 --> 00:43:07.720]   - But now you've hit the key point
[00:43:07.720 --> 00:43:11.320]   about why we even want to study intelligence.
[00:43:11.320 --> 00:43:13.360]   And personality, I think, to a lesser extent.
[00:43:13.360 --> 00:43:17.480]   But that's my interest is more on intelligence.
[00:43:17.480 --> 00:43:20.140]   I went to graduate school and wanted to study personality,
[00:43:20.140 --> 00:43:22.620]   but that's kind of another story
[00:43:22.620 --> 00:43:25.180]   how I got kind of shifted from personality research
[00:43:25.180 --> 00:43:27.420]   over to intelligence research.
[00:43:27.420 --> 00:43:30.000]   Because it's not just a number.
[00:43:30.000 --> 00:43:32.520]   Intelligence is not just an IQ score.
[00:43:32.520 --> 00:43:34.700]   It's not just an SAT score.
[00:43:34.700 --> 00:43:37.640]   It's what those numbers reflect
[00:43:37.640 --> 00:43:42.140]   about your ability to navigate everyday life.
[00:43:42.140 --> 00:43:48.000]   It has been said that life is one long intelligence test.
[00:43:48.000 --> 00:43:50.800]   (laughing)
[00:43:50.800 --> 00:43:55.440]   And who can't relate to that?
[00:43:55.440 --> 00:43:58.480]   And if you doubt, see, another problem here
[00:43:58.480 --> 00:44:00.820]   is a lot of critics of intelligence research,
[00:44:00.820 --> 00:44:04.040]   intelligence testing, tend to be academics
[00:44:04.040 --> 00:44:07.320]   who, by and large, are pretty smart people.
[00:44:07.320 --> 00:44:10.080]   And pretty smart people, by and large,
[00:44:10.080 --> 00:44:12.920]   have enormous difficulty understanding
[00:44:12.920 --> 00:44:17.920]   what the world is like for people with IQs of 80 or 75.
[00:44:17.920 --> 00:44:23.080]   It is a completely different everyday experience.
[00:44:23.080 --> 00:44:28.080]   Even IQ scores of 85, 90,
[00:44:28.080 --> 00:44:31.840]   there's a popular television program, Judge Judy,
[00:44:31.840 --> 00:44:35.360]   where Judge Judy deals with everyday people
[00:44:35.360 --> 00:44:36.840]   with everyday problems.
[00:44:36.840 --> 00:44:39.480]   And you can see the full range
[00:44:39.480 --> 00:44:43.280]   of problem-solving ability demonstrated there.
[00:44:43.280 --> 00:44:45.360]   And sometimes she does it for laughs,
[00:44:45.360 --> 00:44:50.360]   but it really isn't funny because people who are,
[00:44:50.360 --> 00:44:54.540]   there are people who are very limited
[00:44:54.540 --> 00:44:59.240]   in their life navigation, let alone success,
[00:44:59.240 --> 00:45:04.720]   by having, by not having good reasoning skills,
[00:45:04.720 --> 00:45:06.960]   which cannot be taught.
[00:45:06.960 --> 00:45:09.600]   We know this, by the way, because there are many efforts.
[00:45:09.600 --> 00:45:11.320]   You know, the United States military,
[00:45:11.320 --> 00:45:14.160]   which excels at training people.
[00:45:14.160 --> 00:45:16.520]   I mean, I don't know that there's a better organization
[00:45:16.520 --> 00:45:20.320]   in the world for training diverse people.
[00:45:20.320 --> 00:45:22.760]   And they won't take people with IQs under,
[00:45:22.760 --> 00:45:25.400]   I think, 83 is the cutoff.
[00:45:25.400 --> 00:45:29.440]   Because they have found, they are unable to train
[00:45:29.440 --> 00:45:34.400]   people with lower IQs to do jobs in the military.
[00:45:34.400 --> 00:45:36.200]   - So one of the things that G-Factor
[00:45:36.200 --> 00:45:37.640]   has to do with is learning.
[00:45:37.640 --> 00:45:38.580]   - Absolutely.
[00:45:38.580 --> 00:45:42.680]   Some people learn faster than others.
[00:45:42.680 --> 00:45:45.480]   Some people learn more than others.
[00:45:45.480 --> 00:45:48.080]   Now, faster, by the way, is not necessarily better,
[00:45:48.080 --> 00:45:51.980]   as long as you get to the same place eventually.
[00:45:51.980 --> 00:45:56.360]   But, you know, there are professional schools
[00:45:56.360 --> 00:45:59.720]   that want students who can learn the fastest
[00:45:59.720 --> 00:46:03.120]   because they can learn more, or learn deeper,
[00:46:03.120 --> 00:46:08.120]   or all kinds of ideas about why you select people
[00:46:08.120 --> 00:46:09.560]   with the highest scores.
[00:46:09.560 --> 00:46:12.640]   And there's nothing funnier, by the way,
[00:46:12.640 --> 00:46:15.680]   to listen to a bunch of academics complain
[00:46:15.680 --> 00:46:19.400]   about the concept of intelligence and intelligence testing.
[00:46:19.400 --> 00:46:21.320]   And then you go to a faculty meeting
[00:46:21.320 --> 00:46:24.760]   where they're discussing who to hire among the applicants.
[00:46:24.760 --> 00:46:27.320]   And all they talk about is how smart the person is.
[00:46:27.320 --> 00:46:29.360]   - We'll get to that.
[00:46:29.360 --> 00:46:31.200]   We'll sneak up to that in different ways.
[00:46:31.200 --> 00:46:33.020]   But there's something about reducing a person
[00:46:33.020 --> 00:46:35.280]   to a number that in part is grounded
[00:46:35.280 --> 00:46:36.920]   to the person's genetics
[00:46:36.920 --> 00:46:38.800]   that makes people very uncomfortable.
[00:46:38.800 --> 00:46:40.480]   - But nobody does that.
[00:46:40.480 --> 00:46:43.800]   Nobody in the field actually does that.
[00:46:43.800 --> 00:46:48.800]   That is a worry that is a worry like,
[00:46:48.800 --> 00:46:55.880]   well, I don't wanna call it a conspiracy theory.
[00:46:55.880 --> 00:46:58.360]   I mean, it's a legitimate worry.
[00:46:58.360 --> 00:47:01.400]   But it just doesn't happen.
[00:47:01.400 --> 00:47:03.580]   Now, I had a professor in graduate school
[00:47:03.580 --> 00:47:05.860]   who was the only person I ever knew
[00:47:05.860 --> 00:47:10.860]   who considered the students only by their test scores.
[00:47:10.860 --> 00:47:14.080]   - Yes. - And later in his life,
[00:47:14.080 --> 00:47:16.400]   he kind of backed off that.
[00:47:16.400 --> 00:47:18.160]   But--
[00:47:18.160 --> 00:47:20.320]   - Let me ask you this.
[00:47:20.320 --> 00:47:21.540]   So we'll jump around.
[00:47:21.540 --> 00:47:22.860]   I'll come back to it.
[00:47:22.860 --> 00:47:29.500]   I tend to, I've had political discussions with people.
[00:47:29.500 --> 00:47:34.500]   And actually, my friend Michael Malice, he's an anarchist.
[00:47:34.500 --> 00:47:39.220]   I disagree with him on basically everything
[00:47:39.220 --> 00:47:44.220]   except the fact that love is a beautiful thing in this world.
[00:47:44.220 --> 00:47:50.580]   And he says this test about left versus right,
[00:47:50.580 --> 00:47:52.260]   whatever, it doesn't matter what the test is.
[00:47:52.260 --> 00:47:54.920]   But he believes, the question is,
[00:47:54.920 --> 00:47:57.900]   do you believe that some people are better than others?
[00:47:58.900 --> 00:48:03.900]   The question is ambiguous.
[00:48:03.900 --> 00:48:06.140]   Do you believe some people are better than others?
[00:48:06.140 --> 00:48:10.720]   And to me, sort of the immediate answer is no.
[00:48:10.720 --> 00:48:12.860]   It's a poetic question.
[00:48:12.860 --> 00:48:15.660]   It's an ambiguous question, right?
[00:48:15.660 --> 00:48:18.860]   Like, people wanna maybe,
[00:48:18.860 --> 00:48:20.700]   the temptation to ask better at what?
[00:48:20.700 --> 00:48:23.460]   Better at like sports, so on.
[00:48:23.460 --> 00:48:27.420]   No, to me, I stand with the sort of
[00:48:27.420 --> 00:48:29.980]   the founding documents of this country,
[00:48:29.980 --> 00:48:32.300]   which is all men are created equal.
[00:48:32.300 --> 00:48:34.380]   There's a basic humanity.
[00:48:34.380 --> 00:48:39.380]   And there's something about tests of intelligence.
[00:48:39.380 --> 00:48:43.420]   Just knowing that some people are different,
[00:48:43.420 --> 00:48:45.420]   like the science of intelligence that shows
[00:48:45.420 --> 00:48:47.420]   that some people are genetically
[00:48:47.420 --> 00:48:52.420]   in some stable way across a lifetime,
[00:48:52.420 --> 00:48:56.140]   have a greater intelligence than others,
[00:48:56.140 --> 00:49:01.140]   makes people feel like some people are better than others.
[00:49:01.140 --> 00:49:03.580]   And that makes them very uncomfortable.
[00:49:03.580 --> 00:49:06.940]   And maybe you can speak to that.
[00:49:06.940 --> 00:49:09.540]   The fact that some people are more intelligent than others
[00:49:09.540 --> 00:49:10.800]   in a way that's,
[00:49:10.800 --> 00:49:17.900]   cannot be compensated through education,
[00:49:17.900 --> 00:49:20.820]   through anything you do in life.
[00:49:21.820 --> 00:49:24.460]   What do we do with that?
[00:49:24.460 --> 00:49:25.900]   - Okay, there's a lot there.
[00:49:25.900 --> 00:49:29.940]   We haven't really talked about the genetics of it yet,
[00:49:29.940 --> 00:49:34.940]   but you are correct in that it is my interpretation
[00:49:34.940 --> 00:49:39.700]   of the data that genetics has a very important influence
[00:49:39.700 --> 00:49:41.380]   on the G factor.
[00:49:41.380 --> 00:49:42.980]   And this is controversial.
[00:49:42.980 --> 00:49:44.420]   We can talk about it.
[00:49:44.420 --> 00:49:47.020]   But if you think that genetics,
[00:49:47.020 --> 00:49:50.780]   that genes are deterministic, are always deterministic,
[00:49:50.780 --> 00:49:54.040]   that leads to kind of the worry that you expressed.
[00:49:54.040 --> 00:49:58.560]   But we know now in the 21st century
[00:49:58.560 --> 00:50:00.860]   that many genes are not deterministic,
[00:50:00.860 --> 00:50:02.780]   that are probabilistic,
[00:50:02.780 --> 00:50:07.780]   meaning their gene expression can be influenced.
[00:50:07.780 --> 00:50:11.060]   Now, whether they're influenced
[00:50:11.060 --> 00:50:14.020]   only by other biological variables
[00:50:14.020 --> 00:50:16.400]   or other genetic variables
[00:50:16.400 --> 00:50:19.100]   or environmental or cultural variables,
[00:50:19.100 --> 00:50:21.740]   that's where the controversy comes in.
[00:50:21.740 --> 00:50:27.140]   And we can discuss that in more detail if you like.
[00:50:27.140 --> 00:50:31.660]   But to go to the question about better, are people better,
[00:50:31.660 --> 00:50:36.660]   there's zero evidence that smart people are better
[00:50:36.660 --> 00:50:43.300]   with respect to important aspects of life,
[00:50:43.300 --> 00:50:47.060]   like honesty, even likability.
[00:50:47.980 --> 00:50:50.340]   I'm sure you know many very intelligent people
[00:50:50.340 --> 00:50:53.420]   who are not terribly likable or terribly kind
[00:50:53.420 --> 00:50:55.480]   or terribly honest.
[00:50:55.480 --> 00:50:56.760]   - Is there something to be said?
[00:50:56.760 --> 00:50:59.820]   So one of the things I've recently reread
[00:50:59.820 --> 00:51:01.080]   for the second time,
[00:51:01.080 --> 00:51:04.500]   I guess that's what the word reread means,
[00:51:04.500 --> 00:51:08.980]   the rise and fall of the Third Reich,
[00:51:08.980 --> 00:51:12.060]   which is, I think, the best telling
[00:51:12.060 --> 00:51:14.680]   of the rise and fall of Hitler.
[00:51:14.680 --> 00:51:17.860]   And one of the interesting things about the people
[00:51:17.860 --> 00:51:22.180]   that, how should I say it,
[00:51:22.180 --> 00:51:32.260]   justified or maybe propped up the ideas
[00:51:32.260 --> 00:51:35.900]   that Hitler put forward is the fact
[00:51:35.900 --> 00:51:38.420]   that they were extremely intelligent.
[00:51:38.420 --> 00:51:40.560]   They were the intellectual class.
[00:51:40.560 --> 00:51:46.220]   They were, it was obvious that they thought
[00:51:46.220 --> 00:51:49.500]   very deeply and rationally about the world.
[00:51:49.500 --> 00:51:51.580]   So what I would like to say is,
[00:51:51.580 --> 00:51:53.860]   one of the things that shows to me
[00:51:53.860 --> 00:51:57.940]   is some of the worst atrocities in the history of humanity
[00:51:57.940 --> 00:52:00.740]   have been committed by very intelligent people.
[00:52:00.740 --> 00:52:04.620]   So that means that intelligence
[00:52:04.620 --> 00:52:06.420]   doesn't make you a good person.
[00:52:06.420 --> 00:52:11.420]   I wonder if, you know, there's a G factor for intelligence.
[00:52:11.420 --> 00:52:15.280]   I wonder if there's a G factor for goodness.
[00:52:15.840 --> 00:52:19.200]   You know, they need you in good and evil.
[00:52:19.200 --> 00:52:21.720]   Of course, that's probably harder to measure
[00:52:21.720 --> 00:52:23.240]   'cause that's such a subjective thing,
[00:52:23.240 --> 00:52:25.320]   what it means to be good.
[00:52:25.320 --> 00:52:29.400]   And even the idea of evil is a deeply uncomfortable thing
[00:52:29.400 --> 00:52:31.360]   'cause how do we know?
[00:52:31.360 --> 00:52:33.500]   But it's independent, whatever it is,
[00:52:33.500 --> 00:52:36.040]   it's independent of intelligence.
[00:52:36.040 --> 00:52:37.960]   So I agree with you about that.
[00:52:37.960 --> 00:52:39.360]   But let me say this.
[00:52:39.360 --> 00:52:44.120]   I have also asserted my belief
[00:52:44.120 --> 00:52:47.240]   that more intelligence is better than less.
[00:52:47.240 --> 00:52:54.240]   That doesn't mean more intelligent people are better people,
[00:52:54.240 --> 00:52:55.840]   but all things being equal,
[00:52:55.840 --> 00:52:58.740]   would you like to be smarter or less smart?
[00:52:58.740 --> 00:53:01.280]   So if I had a pill, I have two pills,
[00:53:01.280 --> 00:53:02.880]   I said, this one will make you smarter,
[00:53:02.880 --> 00:53:04.480]   this one will make you dumber.
[00:53:04.480 --> 00:53:06.480]   Which one would you like?
[00:53:06.480 --> 00:53:07.960]   Are there any circumstances
[00:53:07.960 --> 00:53:09.840]   under which you would choose to be dumber?
[00:53:09.840 --> 00:53:11.560]   - Well, let me ask you this.
[00:53:11.560 --> 00:53:13.960]   That's a very nuanced and interesting question.
[00:53:13.960 --> 00:53:18.360]   There's been books written about this, right?
[00:53:18.360 --> 00:53:21.680]   Now we'll return to the hard questions,
[00:53:21.680 --> 00:53:22.760]   the interesting questions,
[00:53:22.760 --> 00:53:24.940]   but let me ask about human happiness.
[00:53:24.940 --> 00:53:29.200]   Does intelligence lead to happiness?
[00:53:29.200 --> 00:53:30.040]   - No.
[00:53:30.040 --> 00:53:34.960]   - So, okay, so back to the pill then.
[00:53:34.960 --> 00:53:38.980]   So why, when would you take the pill?
[00:53:38.980 --> 00:53:40.640]   So you said IQ 80.
[00:53:41.520 --> 00:53:46.520]   90, 100, 110, you start going through the quartiles
[00:53:46.520 --> 00:53:51.600]   and is it obvious, isn't there a diminishing returns
[00:53:51.600 --> 00:53:56.520]   and then it starts becoming negative?
[00:53:56.520 --> 00:53:59.300]   - This is an empirical question.
[00:53:59.300 --> 00:54:05.400]   And so that I have advocated in many forums
[00:54:06.160 --> 00:54:11.160]   more research on enhancing the G factor.
[00:54:11.160 --> 00:54:14.440]   Right now there have been many claims
[00:54:14.440 --> 00:54:17.060]   about enhancing intelligence
[00:54:17.060 --> 00:54:19.080]   with you mentioned the NBAC training,
[00:54:19.080 --> 00:54:22.640]   that was a big deal a few years ago, it doesn't work.
[00:54:22.640 --> 00:54:24.900]   Data's very clear, it does not work.
[00:54:24.900 --> 00:54:28.560]   - Or doing like memory tests, like training and so on.
[00:54:28.560 --> 00:54:32.720]   - Yeah, it may give you a better memory in the short run,
[00:54:32.720 --> 00:54:35.440]   but it doesn't impact your G factor.
[00:54:36.000 --> 00:54:40.920]   It was very popular a couple of decades ago
[00:54:40.920 --> 00:54:44.560]   that the idea that listening to Mozart
[00:54:44.560 --> 00:54:46.560]   could make you more intelligent.
[00:54:46.560 --> 00:54:48.200]   There was a paper published on this
[00:54:48.200 --> 00:54:50.320]   with somebody I knew published this paper.
[00:54:50.320 --> 00:54:54.600]   Intelligence researchers never believed it for a second.
[00:54:54.600 --> 00:54:57.800]   Been hundreds of studies, all the meta-analyses,
[00:54:57.800 --> 00:54:59.360]   all the summaries and so on.
[00:54:59.360 --> 00:55:04.040]   So there's nothing to it, nothing to it at all.
[00:55:04.680 --> 00:55:05.520]   (Luke laughs)
[00:55:05.520 --> 00:55:08.720]   But wouldn't it be something,
[00:55:08.720 --> 00:55:11.800]   wouldn't it be world shaking
[00:55:11.800 --> 00:55:15.920]   if you could take the normal distribution of intelligence,
[00:55:15.920 --> 00:55:17.460]   which we haven't really talked about yet,
[00:55:17.460 --> 00:55:20.360]   but IQ scores and the G factor
[00:55:20.360 --> 00:55:22.720]   is thought to be a normal distribution,
[00:55:22.720 --> 00:55:28.880]   and shift it to the right so that everybody is smarter.
[00:55:30.080 --> 00:55:34.280]   Even a half a standard deviation would be world shaking
[00:55:34.280 --> 00:55:38.660]   because there are many social problems,
[00:55:38.660 --> 00:55:43.200]   many, many social problems that are exacerbated
[00:55:43.200 --> 00:55:48.200]   by people with lower ability to reason stuff out
[00:55:48.200 --> 00:55:50.580]   and navigate everyday life.
[00:55:50.580 --> 00:55:53.740]   - So I wonder if there's a threshold.
[00:55:53.740 --> 00:55:58.740]   So maybe I would push back and say universal shifting
[00:55:59.380 --> 00:56:02.200]   of the normal distribution
[00:56:02.200 --> 00:56:05.000]   may not be the optimal way of shifting.
[00:56:05.000 --> 00:56:07.300]   Maybe it's better to,
[00:56:07.300 --> 00:56:10.580]   whatever the asymmetric kind of distribution is,
[00:56:10.580 --> 00:56:13.340]   is like really pushing the lower up
[00:56:13.340 --> 00:56:17.520]   versus trying to make the people
[00:56:17.520 --> 00:56:19.600]   at the average more intelligent.
[00:56:19.600 --> 00:56:21.020]   - So you're saying that if in fact
[00:56:21.020 --> 00:56:23.500]   there was some way to increase G,
[00:56:23.500 --> 00:56:27.760]   let's just call it metaphorically a pill, an IQ pill,
[00:56:27.760 --> 00:56:30.560]   we should only give it to people at the lower end?
[00:56:30.560 --> 00:56:34.880]   - No, it's just intuitively I can see
[00:56:34.880 --> 00:56:39.760]   that life becomes easier at the lower end if it's increased.
[00:56:39.760 --> 00:56:41.620]   It becomes less and less,
[00:56:41.620 --> 00:56:43.520]   it is an empirical scientific question,
[00:56:43.520 --> 00:56:46.140]   but it becomes less and less obvious to me
[00:56:46.140 --> 00:56:50.480]   that more intelligence is better.
[00:56:50.480 --> 00:56:55.480]   - At the high end, not because it would make life easier,
[00:56:56.460 --> 00:57:00.960]   but it would make whatever problems you're working on
[00:57:00.960 --> 00:57:02.660]   more solvable.
[00:57:02.660 --> 00:57:06.700]   And if you are working on artificial intelligence,
[00:57:06.700 --> 00:57:09.220]   there's a tremendous potential
[00:57:09.220 --> 00:57:13.300]   for that to improve society.
[00:57:13.300 --> 00:57:14.580]   - I understand.
[00:57:14.580 --> 00:57:18.980]   So at the whatever problems you're working on, yes,
[00:57:18.980 --> 00:57:21.720]   but there's also the problem of the human condition.
[00:57:21.720 --> 00:57:24.320]   There's love, there's fear,
[00:57:24.320 --> 00:57:26.720]   and all of those beautiful things
[00:57:26.720 --> 00:57:29.840]   that sometimes if you're good at solving problems,
[00:57:29.840 --> 00:57:32.340]   you're going to create more problems for yourself.
[00:57:32.340 --> 00:57:34.440]   I'm not exactly sure.
[00:57:34.440 --> 00:57:37.200]   So ignorance is bliss, is a thing.
[00:57:37.200 --> 00:57:38.400]   So there might be a place,
[00:57:38.400 --> 00:57:40.960]   there might be a sweet spot of intelligence
[00:57:40.960 --> 00:57:43.680]   given your environment, given your personality,
[00:57:43.680 --> 00:57:45.040]   all of those kinds of things,
[00:57:45.040 --> 00:57:48.160]   and that becomes less beautifully complicated
[00:57:48.160 --> 00:57:50.480]   the more and more intelligent you become.
[00:57:50.480 --> 00:57:53.160]   But that's a question for literature,
[00:57:53.160 --> 00:57:54.680]   not for science, perhaps.
[00:57:54.680 --> 00:57:56.200]   - Well, imagine this.
[00:57:56.200 --> 00:57:58.400]   Imagine there was an IQ pill,
[00:57:58.400 --> 00:58:01.580]   and it was developed by a private company,
[00:58:01.580 --> 00:58:05.040]   and they are willing to sell it to you.
[00:58:05.040 --> 00:58:07.880]   And whatever price they put on it,
[00:58:07.880 --> 00:58:09.480]   you are willing to pay it
[00:58:09.480 --> 00:58:11.720]   because you would like to be smarter.
[00:58:11.720 --> 00:58:14.320]   But just before they give you a pill,
[00:58:14.320 --> 00:58:17.680]   they give you a disclaimer form to sign.
[00:58:20.000 --> 00:58:21.000]   Don't hold us,
[00:58:21.000 --> 00:58:25.160]   you understand that this pill has no guarantee
[00:58:25.160 --> 00:58:26.960]   that your life is going to be better,
[00:58:26.960 --> 00:58:28.880]   and in fact, it could be worse.
[00:58:28.880 --> 00:58:32.200]   - Well, yes, that's how lawyers work,
[00:58:32.200 --> 00:58:35.160]   but I would love for science to answer the question,
[00:58:35.160 --> 00:58:36.640]   to try to predict if your life
[00:58:36.640 --> 00:58:38.680]   is going to be better or worse
[00:58:38.680 --> 00:58:41.200]   when you become more or less intelligent.
[00:58:41.200 --> 00:58:43.240]   It's a fascinating question
[00:58:43.240 --> 00:58:45.920]   about what is the sweet spot for the human condition.
[00:58:47.600 --> 00:58:49.840]   Some of the things we see as bugs
[00:58:49.840 --> 00:58:51.920]   might be actually features,
[00:58:51.920 --> 00:58:55.360]   may be crucial to our overall happiness,
[00:58:55.360 --> 00:58:59.080]   is our limitations might lead to more happiness than less.
[00:58:59.080 --> 00:59:02.720]   But again, more intelligence is better at the lower end.
[00:59:02.720 --> 00:59:06.440]   That's something that's less arguable
[00:59:06.440 --> 00:59:10.080]   and fascinating, if possible, to increase.
[00:59:10.080 --> 00:59:12.920]   - But you know, there's virtually no research
[00:59:12.920 --> 00:59:15.280]   that's based on a neuroscience approach
[00:59:15.280 --> 00:59:17.480]   to solving that problem.
[00:59:17.480 --> 00:59:20.760]   All the solutions that have been proposed
[00:59:20.760 --> 00:59:25.360]   to solve that problem or to ameliorate that problem
[00:59:25.360 --> 00:59:29.640]   are essentially based on the blank slate assumption
[00:59:29.640 --> 00:59:34.640]   that enriching the environment, removing barriers,
[00:59:34.640 --> 00:59:35.960]   all good things, by the way,
[00:59:35.960 --> 00:59:38.120]   I'm not against any of those things,
[00:59:38.120 --> 00:59:39.680]   but there's no empirical evidence
[00:59:39.680 --> 00:59:44.320]   that they're going to improve the general reasoning ability
[00:59:45.200 --> 00:59:47.880]   or make people more employable.
[00:59:47.880 --> 00:59:49.960]   - Have you read "Flowers of Algernon"?
[00:59:49.960 --> 00:59:50.800]   - Yes.
[00:59:50.800 --> 00:59:54.640]   - That's to the question of intelligence and happiness.
[00:59:54.640 --> 00:59:59.400]   - There are many profound aspects of that story.
[00:59:59.400 --> 01:00:01.800]   It was a film that was very good.
[01:00:01.800 --> 01:00:04.760]   The film was called "Charlie,"
[01:00:04.760 --> 01:00:07.460]   for the younger people who are listening to this.
[01:00:07.460 --> 01:00:11.720]   You might be able to stream it on Netflix or something.
[01:00:11.720 --> 01:00:16.720]   But it was a story about a person with very low IQ
[01:00:16.720 --> 01:00:21.760]   who underwent a surgical procedure in the brain
[01:00:21.760 --> 01:00:23.800]   and he slowly became a genius.
[01:00:23.800 --> 01:00:29.500]   And the tragedy of the story is the effect was temporary.
[01:00:29.500 --> 01:00:33.120]   It's a fascinating story, really.
[01:00:33.120 --> 01:00:36.600]   - That goes in contrast to the basic human experience
[01:00:36.600 --> 01:00:38.440]   that each of us individually have,
[01:00:38.440 --> 01:00:43.440]   but it raises the question of the full range of people
[01:00:43.440 --> 01:00:45.640]   you might be able to be,
[01:00:45.640 --> 01:00:48.760]   given different levels of intelligence.
[01:00:48.760 --> 01:00:51.940]   You've mentioned the normal distribution.
[01:00:51.940 --> 01:00:54.520]   So let's talk about it.
[01:00:54.520 --> 01:00:58.360]   There's a book called "The Bell Curve," written in 1994,
[01:00:58.360 --> 01:01:01.340]   written by psychologist Richard Herrnstein
[01:01:01.340 --> 01:01:04.520]   and political scientist Charles Murray.
[01:01:04.520 --> 01:01:07.140]   Why was this book so controversial?
[01:01:08.140 --> 01:01:10.740]   - This is a fascinating book.
[01:01:10.740 --> 01:01:12.620]   I know Charles Murray.
[01:01:12.620 --> 01:01:15.340]   I've had many conversations with him.
[01:01:15.340 --> 01:01:16.780]   - Yeah, what is the book about?
[01:01:16.780 --> 01:01:21.620]   - The book is about the importance of intelligence
[01:01:21.620 --> 01:01:24.140]   in everyday life.
[01:01:24.140 --> 01:01:27.520]   That's what the book is about.
[01:01:27.520 --> 01:01:29.180]   It's an empirical book.
[01:01:29.180 --> 01:01:34.180]   It has statistical analyses of very large databases
[01:01:34.180 --> 01:01:39.180]   that show that essentially IQ scores or their equivalent
[01:01:39.180 --> 01:01:44.640]   are correlated to all kinds of social problems
[01:01:44.640 --> 01:01:46.800]   and social benefits.
[01:01:46.800 --> 01:01:51.740]   And that in itself is not where the controversy
[01:01:51.740 --> 01:01:53.640]   about that book came.
[01:01:53.640 --> 01:01:57.580]   The controversy was about one chapter in that book.
[01:01:57.580 --> 01:02:02.240]   And that is a chapter about the average difference
[01:02:02.240 --> 01:02:06.740]   in mean scores between black Americans and white Americans.
[01:02:06.740 --> 01:02:08.460]   And these are the terms that were used
[01:02:08.460 --> 01:02:09.740]   in the book at the time
[01:02:09.740 --> 01:02:12.240]   and are still used to some extent.
[01:02:12.240 --> 01:02:19.040]   And historically, or really for decades,
[01:02:19.040 --> 01:02:26.200]   it has been observed that disadvantaged groups
[01:02:27.980 --> 01:02:32.920]   score on average lower than Caucasians
[01:02:32.920 --> 01:02:38.280]   on academic tests, tests of mental ability,
[01:02:38.280 --> 01:02:40.440]   and especially on IQ tests.
[01:02:40.440 --> 01:02:43.120]   And the difference is about a standard deviation,
[01:02:43.120 --> 01:02:46.600]   which is about 15 points, which is a substantial difference.
[01:02:46.600 --> 01:02:53.920]   In the book, Hernstein and Murray in this one chapter
[01:02:54.160 --> 01:02:58.260]   assert clearly and unambiguously
[01:02:58.260 --> 01:03:01.960]   that whether this average difference
[01:03:01.960 --> 01:03:06.960]   is due to genetics or not, they are agnostic.
[01:03:06.960 --> 01:03:08.420]   They don't know.
[01:03:08.420 --> 01:03:11.280]   Moreover, they assert they don't care
[01:03:11.280 --> 01:03:14.020]   because you wouldn't treat anybody differently
[01:03:14.020 --> 01:03:17.780]   knowing if there was a genetic component or not
[01:03:17.780 --> 01:03:20.700]   because that's a group average finding.
[01:03:20.700 --> 01:03:24.100]   Every individual has to be treated as an individual.
[01:03:24.100 --> 01:03:26.140]   You can't make any assumption
[01:03:26.140 --> 01:03:30.740]   about what that person's intellectual ability might be
[01:03:30.740 --> 01:03:33.260]   from the fact of a average group difference.
[01:03:33.260 --> 01:03:34.960]   They're very clear about this.
[01:03:34.960 --> 01:03:41.100]   Nonetheless, people took away,
[01:03:41.100 --> 01:03:43.180]   I'm gonna choose my words carefully
[01:03:43.180 --> 01:03:44.760]   'cause I have a feeling that many critics
[01:03:44.760 --> 01:03:49.140]   didn't actually read the book.
[01:03:49.140 --> 01:03:51.860]   They took away that Hernstein and Murray were saying
[01:03:51.860 --> 01:03:54.900]   that blacks are genetically inferior.
[01:03:54.900 --> 01:03:56.500]   That was the take-home message.
[01:03:56.500 --> 01:03:59.660]   And if they weren't saying it, they were implying it
[01:03:59.660 --> 01:04:02.700]   because they had a chapter that discussed
[01:04:02.700 --> 01:04:05.900]   this empirical observation of a difference.
[01:04:05.900 --> 01:04:10.500]   And isn't this horrible?
[01:04:10.500 --> 01:04:15.500]   And so the reaction to that book was incendiary.
[01:04:18.380 --> 01:04:22.500]   - What do we know about, from that book
[01:04:22.500 --> 01:04:24.140]   and the research beyond,
[01:04:24.140 --> 01:04:30.580]   about race differences and intelligence?
[01:04:30.580 --> 01:04:33.740]   - It's still the most incendiary topic in psychology.
[01:04:33.740 --> 01:04:35.820]   Nothing has changed that.
[01:04:35.820 --> 01:04:40.820]   Anybody who even discusses it is easily called a racist
[01:04:40.820 --> 01:04:42.980]   just for discussing it.
[01:04:42.980 --> 01:04:45.520]   It's become fashionable to find racism
[01:04:45.520 --> 01:04:49.900]   in any discussion like this.
[01:04:49.900 --> 01:04:51.300]   It's unfortunate.
[01:04:51.300 --> 01:04:56.020]   The short answer to your question is
[01:04:56.020 --> 01:05:01.900]   there's been very little actual research on this topic
[01:05:01.900 --> 01:05:03.820]   since 19--
[01:05:03.820 --> 01:05:05.180]   - Since the Bell Curve.
[01:05:05.180 --> 01:05:07.860]   - Since the Bell Curve, even before.
[01:05:07.860 --> 01:05:12.420]   This really became incendiary in 1969
[01:05:12.420 --> 01:05:15.720]   with an article published by an educational psychologist
[01:05:15.720 --> 01:05:17.720]   named Arthur Jensen.
[01:05:17.720 --> 01:05:20.480]   Let's just take a minute and go back to that
[01:05:20.480 --> 01:05:21.620]   to see the Bell Curve
[01:05:21.620 --> 01:05:25.000]   in a little bit more historical perspective.
[01:05:25.000 --> 01:05:29.300]   Arthur Jensen was a educational psychologist at UC Berkeley.
[01:05:29.300 --> 01:05:31.440]   I knew him as well.
[01:05:31.440 --> 01:05:36.440]   And in 1969 or '68, the Harvard Educational Review
[01:05:37.780 --> 01:05:42.620]   asked him to do a review article
[01:05:42.620 --> 01:05:47.540]   on the early childhood education programs
[01:05:47.540 --> 01:05:52.540]   that were designed to raise the IQs of minority students.
[01:05:52.540 --> 01:05:58.540]   This was before the federally funded Head Start program.
[01:05:58.540 --> 01:06:01.280]   Head Start had not really gotten underway
[01:06:01.280 --> 01:06:04.420]   at the time Jensen undertook his review
[01:06:04.420 --> 01:06:07.780]   of what were a number of demonstration programs.
[01:06:07.780 --> 01:06:13.660]   And these demonstration programs were for young children
[01:06:13.660 --> 01:06:15.740]   who were around kindergarten age.
[01:06:15.740 --> 01:06:17.720]   And they were specially designed
[01:06:17.720 --> 01:06:22.720]   to be cognitively stimulating, to provide lunches,
[01:06:22.720 --> 01:06:28.020]   do all the things that people thought would minimize
[01:06:28.020 --> 01:06:31.780]   this average gap of intelligence tests.
[01:06:31.780 --> 01:06:36.780]   There was a strong belief among virtually all psychologists
[01:06:36.780 --> 01:06:40.780]   that the cause of the gap was unequal opportunity
[01:06:40.780 --> 01:06:45.620]   due to racism, due to all negative things in the society.
[01:06:45.620 --> 01:06:49.500]   And if you could compensate for this,
[01:06:49.500 --> 01:06:51.220]   the gap would go away.
[01:06:51.220 --> 01:06:53.940]   So early childhood education back then
[01:06:53.940 --> 01:06:57.280]   was called literally compensatory education.
[01:06:57.280 --> 01:07:00.900]   Jensen looked at these programs.
[01:07:00.900 --> 01:07:02.180]   He was an empirical guy.
[01:07:02.180 --> 01:07:04.580]   He understood psychometrics.
[01:07:04.580 --> 01:07:08.780]   And he wrote a, it was over a hundred page article
[01:07:08.780 --> 01:07:12.120]   detailing these programs
[01:07:12.120 --> 01:07:15.380]   and the flaws in their research design.
[01:07:15.380 --> 01:07:17.660]   Some of the programs reported IQ gains
[01:07:17.660 --> 01:07:20.380]   of on average five points,
[01:07:20.380 --> 01:07:24.720]   but a few reported 10, 20, and even 30 point gains.
[01:07:24.720 --> 01:07:27.780]   One was called the miracle in Milwaukee.
[01:07:27.780 --> 01:07:30.460]   That investigator went to jail ultimately
[01:07:30.460 --> 01:07:32.080]   for fabricating data.
[01:07:32.080 --> 01:07:36.020]   But the point is that Jensen wrote an article that said,
[01:07:36.020 --> 01:07:40.020]   look, the opening sentence of his article is classic.
[01:07:40.020 --> 01:07:43.500]   The opening sentence is, I may not quote it exactly right,
[01:07:43.500 --> 01:07:47.100]   but it's, we have tried compensatory education
[01:07:47.100 --> 01:07:48.420]   and it has failed.
[01:07:48.420 --> 01:07:54.320]   And he showed that these gains were essentially nothing.
[01:07:54.540 --> 01:07:59.380]   You couldn't really document empirically any gains at all
[01:07:59.380 --> 01:08:04.100]   from these really earnest efforts to increase IQ.
[01:08:04.100 --> 01:08:08.780]   But he went a step further, a fateful step further.
[01:08:08.780 --> 01:08:12.460]   He said, not only have these efforts failed,
[01:08:12.460 --> 01:08:15.940]   but because they have had essentially no impact,
[01:08:15.940 --> 01:08:18.460]   we have to re-examine our assumption
[01:08:18.460 --> 01:08:22.100]   that these differences are caused by environmental things
[01:08:22.100 --> 01:08:24.420]   that we can address with education.
[01:08:24.420 --> 01:08:28.500]   We need to consider a genetic influence,
[01:08:28.500 --> 01:08:30.580]   whether there's a genetic influence
[01:08:30.580 --> 01:08:32.420]   on this group difference.
[01:08:32.420 --> 01:08:35.300]   - So you said that this is one of the more controversial
[01:08:35.300 --> 01:08:36.940]   works ever in science. - I think it's the most
[01:08:36.940 --> 01:08:41.660]   infamous paper in all of psychology, I would go on to say.
[01:08:41.660 --> 01:08:46.660]   Because in 1969, the genetic data was very skimpy
[01:08:46.660 --> 01:08:49.660]   on this question, skimpy and controversial.
[01:08:49.660 --> 01:08:50.820]   It's always been controversial,
[01:08:50.820 --> 01:08:53.820]   but it was even skimpy and controversial.
[01:08:53.820 --> 01:08:56.500]   It's kind of a long story that I go into a little bit
[01:08:56.500 --> 01:09:00.980]   in more detail in the book, "Neuroscience of Intelligence."
[01:09:00.980 --> 01:09:06.320]   But to say he was vilified is an understatement.
[01:09:06.320 --> 01:09:08.900]   I mean, he couldn't talk at the American
[01:09:08.900 --> 01:09:13.140]   Psychological Association without bomb threats
[01:09:13.140 --> 01:09:15.260]   clearing the lecture hall.
[01:09:15.260 --> 01:09:18.100]   Campus security watched him all the time.
[01:09:18.100 --> 01:09:19.420]   They opened his mail.
[01:09:20.300 --> 01:09:23.740]   He had to retreat to a different address.
[01:09:23.740 --> 01:09:28.740]   This was one of the earliest kinds,
[01:09:28.740 --> 01:09:30.500]   this is before the internet,
[01:09:30.500 --> 01:09:35.100]   and kind of internet social media mobs,
[01:09:35.100 --> 01:09:38.100]   but it was that intense.
[01:09:38.100 --> 01:09:42.740]   And I have written that overnight,
[01:09:42.740 --> 01:09:45.940]   after the publication of this article,
[01:09:45.940 --> 01:09:49.740]   all intelligence research became radioactive.
[01:09:49.740 --> 01:09:51.780]   Nobody wanted to talk about it.
[01:09:51.780 --> 01:09:55.020]   And then it didn't,
[01:09:55.020 --> 01:09:58.900]   nobody was doing more research.
[01:09:58.900 --> 01:10:02.040]   And then the bell curve came along,
[01:10:02.040 --> 01:10:05.700]   and the Jensen controversy was dying down.
[01:10:05.700 --> 01:10:08.100]   I have stories that Jensen told me about
[01:10:08.100 --> 01:10:10.860]   his interaction with the Nixon White House on this issue.
[01:10:10.860 --> 01:10:14.340]   I mean, this was like a really big deal.
[01:10:14.340 --> 01:10:16.180]   It was some unbelievable stories,
[01:10:16.180 --> 01:10:17.860]   but he told me this,
[01:10:17.860 --> 01:10:20.100]   so I kind of believe these stories.
[01:10:20.100 --> 01:10:21.540]   Nonetheless--
[01:10:21.540 --> 01:10:22.940]   - 25 years later.
[01:10:22.940 --> 01:10:23.900]   - 25 years later.
[01:10:23.900 --> 01:10:27.040]   - So all this silence basically saying,
[01:10:27.040 --> 01:10:32.300]   nobody wants to do this kind of research.
[01:10:32.300 --> 01:10:33.780]   There's so much pressure,
[01:10:33.780 --> 01:10:36.340]   so much attack against this kind of research.
[01:10:36.340 --> 01:10:41.340]   And here's sort of a bold, stupid, crazy people
[01:10:41.340 --> 01:10:44.940]   that decide to dive right back in.
[01:10:44.940 --> 01:10:46.540]   I wonder how much discussion there was.
[01:10:46.540 --> 01:10:48.740]   Do we include this chapter or not?
[01:10:48.740 --> 01:10:51.140]   - Murray has said they discussed it,
[01:10:51.140 --> 01:10:54.700]   and they felt they should include it,
[01:10:54.700 --> 01:10:59.620]   and they were very careful in the way they wrote it,
[01:10:59.620 --> 01:11:01.080]   which did them no good.
[01:11:01.080 --> 01:11:06.540]   So as a matter of fact, when the bell curve came out,
[01:11:06.540 --> 01:11:08.480]   it was so controversial.
[01:11:08.480 --> 01:11:13.300]   I got a call from a television show called Nightline.
[01:11:13.300 --> 01:11:16.820]   It was with a broadcaster called Ted Koppel,
[01:11:16.820 --> 01:11:20.620]   who had this evening show, I think it was on late at night,
[01:11:20.620 --> 01:11:21.600]   talked about news.
[01:11:21.600 --> 01:11:24.260]   It was a straight up news thing.
[01:11:24.260 --> 01:11:28.180]   And a producer called and asked if I would be on it
[01:11:28.180 --> 01:11:31.700]   to talk about the bell curve.
[01:11:31.700 --> 01:11:32.900]   And I said, you know,
[01:11:32.900 --> 01:11:36.660]   she asked me what I thought about the bell curve as a book.
[01:11:36.660 --> 01:11:38.580]   And I said, look, it's a very good book.
[01:11:38.580 --> 01:11:42.260]   It talks about the role of intelligence in society.
[01:11:43.100 --> 01:11:44.380]   And she said, no, no,
[01:11:44.380 --> 01:11:47.180]   what do you think about the chapter on race?
[01:11:47.180 --> 01:11:49.100]   That's what we want you to talk about.
[01:11:49.100 --> 01:11:52.460]   I remember this conversation.
[01:11:52.460 --> 01:11:53.460]   I said, well,
[01:11:53.460 --> 01:11:58.840]   she said, what would you say if you were on TV?
[01:11:58.840 --> 01:12:02.300]   And I said, well, what I would say is that
[01:12:02.300 --> 01:12:04.620]   it's not at all clear
[01:12:04.620 --> 01:12:09.620]   if there's any genetic component to intelligence,
[01:12:12.100 --> 01:12:13.620]   any differences,
[01:12:13.620 --> 01:12:17.460]   but if there were a strong genetic component,
[01:12:17.460 --> 01:12:19.040]   that would be a good thing.
[01:12:19.040 --> 01:12:23.180]   And, you know, complete silence
[01:12:23.180 --> 01:12:25.300]   on the other end of the phone.
[01:12:25.300 --> 01:12:28.180]   And she said, well, what do you mean?
[01:12:28.180 --> 01:12:32.580]   And I said, well, if it's the more genetic any difference is
[01:12:32.580 --> 01:12:35.100]   the more it's biological.
[01:12:35.100 --> 01:12:39.940]   And if it's biological, we can figure out how to fix it.
[01:12:39.940 --> 01:12:41.500]   - I see, that's interesting.
[01:12:41.500 --> 01:12:43.740]   She said, would you say that on television?
[01:12:43.740 --> 01:12:44.980]   - Yes. - I said, no.
[01:12:44.980 --> 01:12:45.820]   (laughing)
[01:12:45.820 --> 01:12:47.420]   And so that was the end of that.
[01:12:47.420 --> 01:12:51.940]   - So that's for more like biology is
[01:12:51.940 --> 01:12:58.260]   within the reach of science
[01:12:58.260 --> 01:13:02.020]   and the environment is a public policy,
[01:13:02.020 --> 01:13:04.080]   social and all those kinds of things.
[01:13:04.080 --> 01:13:06.900]   From your perspective,
[01:13:06.900 --> 01:13:10.740]   whichever one you think is more amenable to solutions
[01:13:10.740 --> 01:13:13.540]   in the short term is the one that excites you.
[01:13:13.540 --> 01:13:16.680]   But you saying that is good,
[01:13:16.680 --> 01:13:24.060]   the truth of genetic differences, no matter what,
[01:13:24.060 --> 01:13:29.060]   between groups is a painful,
[01:13:29.060 --> 01:13:35.660]   harmful, potentially dangerous thing.
[01:13:35.660 --> 01:13:38.060]   Let me ask you to this question,
[01:13:38.060 --> 01:13:42.200]   whether it's bell curve or any research on race differences,
[01:13:42.200 --> 01:13:48.300]   can that be used to increase the amount of racism
[01:13:48.300 --> 01:13:49.420]   in the world?
[01:13:49.420 --> 01:13:51.700]   Can that be used to increase the amount of hate
[01:13:51.700 --> 01:13:52.820]   in the world?
[01:13:52.820 --> 01:13:54.420]   Do you think about this kind of stuff?
[01:13:54.420 --> 01:13:57.400]   - I've thought about this a lot, not as a scientist,
[01:13:57.400 --> 01:13:58.540]   but as a person.
[01:13:58.540 --> 01:14:05.700]   And my sense is there is such enormous risk
[01:14:05.940 --> 01:14:10.940]   enormous reservoirs of hate and racism
[01:14:10.940 --> 01:14:14.940]   that have nothing to do with scientific knowledge
[01:14:14.940 --> 01:14:19.180]   of the data that speak against that.
[01:14:19.180 --> 01:14:24.180]   That no, I don't wanna give racist groups of veto power
[01:14:24.180 --> 01:14:27.700]   over what scientists study.
[01:14:27.700 --> 01:14:30.580]   If you think that the differences,
[01:14:30.580 --> 01:14:33.260]   and by the way, virtually no one disagrees
[01:14:33.260 --> 01:14:35.460]   that there are differences in scores.
[01:14:35.460 --> 01:14:38.540]   It's all about what causes them and how to fix it.
[01:14:38.540 --> 01:14:42.920]   So if you think this is a cultural problem,
[01:14:42.920 --> 01:14:44.900]   then you must ask the problem,
[01:14:44.900 --> 01:14:49.380]   do you want to change anything about the culture?
[01:14:49.380 --> 01:14:51.800]   Or are you okay with the culture?
[01:14:51.800 --> 01:14:53.380]   'Cause you don't feel it's appropriate
[01:14:53.380 --> 01:14:55.600]   to change a person's culture.
[01:14:55.600 --> 01:14:57.140]   So are you okay with that?
[01:14:57.140 --> 01:14:59.700]   And the fact that that may lead to disadvantages
[01:14:59.700 --> 01:15:01.580]   in school achievement?
[01:15:01.580 --> 01:15:02.480]   It's a question.
[01:15:03.540 --> 01:15:05.940]   If you think it's environmental,
[01:15:05.940 --> 01:15:10.380]   what are the environmental parameters that can be fixed?
[01:15:10.380 --> 01:15:15.380]   I'll tell you one, lead from gasoline in the atmosphere,
[01:15:15.380 --> 01:15:18.780]   lead in paint, lead in water.
[01:15:18.780 --> 01:15:20.820]   That's an environmental toxin
[01:15:20.820 --> 01:15:25.820]   that society has the means to eliminate, and they should.
[01:15:25.820 --> 01:15:30.260]   - Yeah, just to sort of trying to find some insight
[01:15:30.260 --> 01:15:32.580]   and conclusion to this very difficult topic.
[01:15:33.580 --> 01:15:38.580]   Is there been research on environment versus genetics,
[01:15:38.580 --> 01:15:41.740]   nature versus nurture on this question of race differences?
[01:15:41.740 --> 01:15:46.380]   - There is not, no one wants to do this research.
[01:15:46.380 --> 01:15:48.060]   First of all, it's hard research to do.
[01:15:48.060 --> 01:15:50.620]   Second of all, it's a minefield.
[01:15:50.620 --> 01:15:52.940]   No one wants to spend their career on it.
[01:15:52.940 --> 01:15:56.320]   Tenured people don't want to do it, let alone students.
[01:15:56.320 --> 01:15:59.580]   The way I talk about it,
[01:15:59.580 --> 01:16:02.440]   well, before I tell you the way I talk about it,
[01:16:02.440 --> 01:16:04.540]   I want to say one more thing about Jensen.
[01:16:04.540 --> 01:16:08.020]   He was once asked by a journalist straight out,
[01:16:08.020 --> 01:16:09.480]   "Are you a racist?"
[01:16:09.480 --> 01:16:12.500]   His answer was very interesting.
[01:16:12.500 --> 01:16:15.800]   His answer was, "I've thought about that a lot,
[01:16:15.800 --> 01:16:19.680]   "and I've concluded it doesn't matter."
[01:16:19.680 --> 01:16:23.660]   Now, I know what he meant by this.
[01:16:23.660 --> 01:16:25.820]   - The guts to say that, wow.
[01:16:25.820 --> 01:16:27.560]   - He was a very unusual person.
[01:16:27.560 --> 01:16:29.920]   I think he had a touch of Asperger's syndrome,
[01:16:29.920 --> 01:16:30.940]   to tell you the truth,
[01:16:30.940 --> 01:16:34.140]   because I saw him in many circumstances.
[01:16:34.140 --> 01:16:35.560]   - He would be canceled on Twitter
[01:16:35.560 --> 01:16:37.020]   immediately with that sentence.
[01:16:37.020 --> 01:16:41.060]   - Yeah, but what he meant was he had a hypothesis.
[01:16:41.060 --> 01:16:44.920]   And with respect to group differences,
[01:16:44.920 --> 01:16:47.420]   he called it the default hypothesis.
[01:16:47.420 --> 01:16:51.220]   He said whatever factors affect individual intelligence
[01:16:51.220 --> 01:16:54.340]   are likely the same factors that affect group differences.
[01:16:54.340 --> 01:16:58.260]   It was the default, but it was a hypothesis.
[01:16:58.260 --> 01:16:59.540]   It should be tested.
[01:16:59.540 --> 01:17:02.060]   And if it turned out empirical tests
[01:17:02.060 --> 01:17:03.700]   didn't support the hypothesis,
[01:17:03.700 --> 01:17:06.500]   he was happy to move on to something else.
[01:17:06.500 --> 01:17:11.500]   He was absolutely committed to that scientific ideal.
[01:17:11.500 --> 01:17:16.060]   It's an empirical question.
[01:17:16.060 --> 01:17:18.820]   We should look at it, and let's see what happens.
[01:17:18.820 --> 01:17:22.100]   - The scientific method cannot be racist,
[01:17:22.100 --> 01:17:23.500]   from his perspective.
[01:17:23.500 --> 01:17:25.860]   It doesn't matter what the scientists,
[01:17:27.340 --> 01:17:30.420]   if they follow the scientific method,
[01:17:30.420 --> 01:17:32.060]   it doesn't matter what they believe.
[01:17:32.060 --> 01:17:33.780]   - And if they are biased,
[01:17:33.780 --> 01:17:38.780]   and they consciously or unconsciously bias the data,
[01:17:38.780 --> 01:17:42.700]   other people will come along to replicate it.
[01:17:42.700 --> 01:17:47.700]   They will fail, and the process over time will work.
[01:17:47.700 --> 01:17:50.980]   - So let me push back on this idea,
[01:17:50.980 --> 01:17:56.400]   because psychology to me is full of gray areas.
[01:17:57.360 --> 01:18:00.600]   And what I've observed about psychology,
[01:18:00.600 --> 01:18:04.040]   even replication crisis aside,
[01:18:04.040 --> 01:18:06.200]   is that something about the media,
[01:18:06.200 --> 01:18:08.000]   something about journalism,
[01:18:08.000 --> 01:18:13.000]   something about the virality of ideas in the public sphere,
[01:18:13.000 --> 01:18:16.040]   they misinterpret.
[01:18:16.040 --> 01:18:20.400]   They take up things from studies willfully,
[01:18:20.400 --> 01:18:23.680]   or from ignorance, misinterpret findings,
[01:18:23.680 --> 01:18:25.760]   and tell narratives around that.
[01:18:26.760 --> 01:18:29.840]   I personally believe, for me,
[01:18:29.840 --> 01:18:31.520]   I'm not saying that broadly about science,
[01:18:31.520 --> 01:18:35.760]   but for me, it's my responsibility to anticipate
[01:18:35.760 --> 01:18:40.440]   the ways in which findings will be misinterpreted.
[01:18:40.440 --> 01:18:42.840]   So I've thought about this a lot,
[01:18:42.840 --> 01:18:47.020]   'cause I publish papers on semi-autonomous vehicles,
[01:18:47.020 --> 01:18:52.020]   and those, you know, cars, people dying cars.
[01:18:52.960 --> 01:18:56.360]   There's people that have written me letters saying,
[01:18:56.360 --> 01:18:59.120]   emails, nobody writes letters, I wish they did,
[01:18:59.120 --> 01:19:01.800]   that have blood on my hands,
[01:19:01.800 --> 01:19:03.800]   because of things that I would say,
[01:19:03.800 --> 01:19:06.200]   positive or negative, there's consequences.
[01:19:06.200 --> 01:19:09.280]   In the same way, when you're a researcher of intelligence,
[01:19:09.280 --> 01:19:12.040]   I'm sure you might get emails,
[01:19:12.040 --> 01:19:15.440]   or at least people might believe that a finding
[01:19:15.440 --> 01:19:17.880]   of your study is going to be used
[01:19:17.880 --> 01:19:19.080]   by a large number of people
[01:19:19.080 --> 01:19:21.240]   to increase the amount of hate in the world.
[01:19:22.640 --> 01:19:26.080]   I think there's some responsibility on scientists,
[01:19:26.080 --> 01:19:29.200]   but for me, I think there's a great responsibility
[01:19:29.200 --> 01:19:35.440]   to anticipate the ways things will be misinterpreted,
[01:19:35.440 --> 01:19:37.880]   and there, you have to, first of all,
[01:19:37.880 --> 01:19:41.000]   decide whether you want to say a thing at all,
[01:19:41.000 --> 01:19:43.480]   do the study at all, publish the study at all,
[01:19:43.480 --> 01:19:47.220]   and two, the words with which you explain it.
[01:19:47.220 --> 01:19:50.680]   I find this on Twitter a lot, actually,
[01:19:50.680 --> 01:19:53.240]   which is, when I write a tweet,
[01:19:53.240 --> 01:19:55.340]   and I'm usually just doing so innocently,
[01:19:55.340 --> 01:20:01.360]   I'll write it, it takes me five seconds to write it,
[01:20:01.360 --> 01:20:04.360]   or whatever, 30 seconds to write it,
[01:20:04.360 --> 01:20:05.880]   and then I'll think, all right,
[01:20:05.880 --> 01:20:08.960]   I close my eyes open and try to see
[01:20:08.960 --> 01:20:11.720]   how will the world interpret this,
[01:20:11.720 --> 01:20:14.400]   what are the ways in which this will be misinterpreted?
[01:20:14.400 --> 01:20:17.000]   And I'll sometimes adjust that tweet to see,
[01:20:18.480 --> 01:20:20.920]   yeah, so in my mind, it's clear,
[01:20:20.920 --> 01:20:24.040]   but that's because it's my mind from which this tweet came,
[01:20:24.040 --> 01:20:26.900]   but you have to think, in a fresh mind that sees this,
[01:20:26.900 --> 01:20:32.840]   and it's spread across a large number of other minds,
[01:20:32.840 --> 01:20:36.040]   how will the interpretation morph?
[01:20:36.040 --> 01:20:38.240]   I mean, for a tweet, it's a silly thing, it doesn't matter,
[01:20:38.240 --> 01:20:43.240]   but for a scientific paper and study and finding,
[01:20:43.240 --> 01:20:47.880]   I think it matters, so I don't know.
[01:20:47.880 --> 01:20:49.720]   I don't know what your thoughts about that,
[01:20:49.720 --> 01:20:53.740]   'cause maybe for Jensen, the data's there,
[01:20:53.740 --> 01:20:55.600]   what do you want me to do?
[01:20:55.600 --> 01:20:59.160]   This is a scientific process that's been carried out,
[01:20:59.160 --> 01:21:02.200]   if you think the data was polluted by bias,
[01:21:02.200 --> 01:21:04.640]   do other studies that reveal the bias,
[01:21:04.640 --> 01:21:07.240]   but the data's there.
[01:21:07.240 --> 01:21:14.680]   I'm not a poet, I'm not a literary writer,
[01:21:14.680 --> 01:21:15.640]   what do you want me to do?
[01:21:15.640 --> 01:21:17.520]   I'm just presenting you the data.
[01:21:17.520 --> 01:21:19.320]   What do you think on that spectrum?
[01:21:19.320 --> 01:21:21.080]   What's the role of a scientist?
[01:21:21.080 --> 01:21:23.500]   - The reason I do podcasts,
[01:21:23.500 --> 01:21:27.240]   the reason I write books for the public
[01:21:27.240 --> 01:21:30.400]   is to explain what I think the data mean
[01:21:30.400 --> 01:21:32.640]   and what I think the data don't mean.
[01:21:32.640 --> 01:21:36.100]   I don't do very much on Twitter
[01:21:36.100 --> 01:21:39.920]   other than to retweet references to papers.
[01:21:39.920 --> 01:21:42.480]   I don't think it's my role to explain these,
[01:21:42.480 --> 01:21:44.880]   'cause they're complicated, they're nuanced,
[01:21:46.440 --> 01:21:51.440]   but when you decide not to do a scientific study
[01:21:51.440 --> 01:21:54.400]   or not to publish a result
[01:21:54.400 --> 01:21:56.160]   because you're afraid the result
[01:21:56.160 --> 01:22:01.880]   could be harmful or insensitive,
[01:22:01.880 --> 01:22:04.100]   that's not an unreasonable thought,
[01:22:04.100 --> 01:22:09.240]   and people will make different conclusions
[01:22:09.240 --> 01:22:11.600]   and decisions about that.
[01:22:11.600 --> 01:22:12.640]   I wrote about this,
[01:22:13.880 --> 01:22:17.040]   I'm the editor of a journal called Intelligence,
[01:22:17.040 --> 01:22:20.600]   which publishes scientific papers.
[01:22:20.600 --> 01:22:24.240]   Sometimes we publish papers on group differences.
[01:22:24.240 --> 01:22:27.080]   Those papers sometimes are controversial.
[01:22:27.080 --> 01:22:29.640]   These papers are written for a scientific audience,
[01:22:29.640 --> 01:22:32.200]   they're not written for the Twitter audience,
[01:22:32.200 --> 01:22:35.620]   so I don't promote them very much on Twitter,
[01:22:35.620 --> 01:22:41.280]   but in a scientific paper,
[01:22:41.280 --> 01:22:43.800]   you have to now choose your words carefully
[01:22:43.800 --> 01:22:48.800]   also because those papers are picked up by non-scientists,
[01:22:48.800 --> 01:22:52.040]   by writers of various kinds,
[01:22:52.040 --> 01:22:56.160]   and you have to be available to discuss what you're saying
[01:22:56.160 --> 01:22:57.800]   and what you're not saying.
[01:22:57.800 --> 01:23:03.720]   Sometimes you are successful at having a good conversation,
[01:23:03.720 --> 01:23:09.200]   like we are today, that doesn't start out pejorative.
[01:23:09.200 --> 01:23:12.520]   Other times I have been asked to participate in debates
[01:23:12.520 --> 01:23:16.480]   where my role would be to justify race science.
[01:23:16.480 --> 01:23:19.520]   Well, you can see, you start out,
[01:23:19.520 --> 01:23:25.640]   and that was a BBC request that I received.
[01:23:25.640 --> 01:23:28.240]   - I have so much, it's a love-hate relationship,
[01:23:28.240 --> 01:23:32.960]   mostly hate, with these shallow journalism organizations,
[01:23:32.960 --> 01:23:35.120]   so they would want to use you
[01:23:35.120 --> 01:23:38.080]   as a kind of, in a debate setting,
[01:23:38.080 --> 01:23:39.800]   to communicate as to, like,
[01:23:39.800 --> 01:23:42.280]   there is race differences between groups,
[01:23:42.280 --> 01:23:44.160]   and make that into debate,
[01:23:44.160 --> 01:23:46.440]   and put you in a role of--
[01:23:46.440 --> 01:23:49.280]   - Justifying racism.
[01:23:49.280 --> 01:23:50.120]   - Justifying racism. - That's what
[01:23:50.120 --> 01:23:51.120]   they're asking me to do.
[01:23:51.120 --> 01:23:54.320]   - Versus, like, educating about this field
[01:23:54.320 --> 01:23:55.840]   of the science of intelligence, yeah.
[01:23:55.840 --> 01:23:57.960]   - I wanna say one more thing
[01:23:57.960 --> 01:24:01.280]   before we get off the normal distribution.
[01:24:01.280 --> 01:24:02.480]   You also asked me,
[01:24:02.480 --> 01:24:06.160]   what is the science after the bell curve?
[01:24:06.160 --> 01:24:09.600]   And the short answer is there's not much new work,
[01:24:09.600 --> 01:24:13.360]   but whatever work there is supports the idea
[01:24:13.360 --> 01:24:16.240]   that there still are group differences.
[01:24:16.240 --> 01:24:18.520]   It's arguable whether those differences
[01:24:18.520 --> 01:24:20.640]   have diminished at all or not,
[01:24:20.640 --> 01:24:24.920]   and there is still a major problem
[01:24:24.920 --> 01:24:28.240]   in underperformance for school achievement
[01:24:28.240 --> 01:24:33.400]   for many disadvantaged and minority students,
[01:24:33.400 --> 01:24:36.440]   and there so far is no way to fix it.
[01:24:37.320 --> 01:24:39.480]   What do we do with this information?
[01:24:39.480 --> 01:24:42.120]   Is this now a task?
[01:24:42.120 --> 01:24:44.000]   Now, we'll talk about the future
[01:24:44.000 --> 01:24:47.760]   on the neuroscience and the biology side,
[01:24:47.760 --> 01:24:51.200]   but in terms of this information as a society
[01:24:51.200 --> 01:24:53.560]   in the public policy, in the political space,
[01:24:53.560 --> 01:24:56.320]   in the social space, what do we do with this information?
[01:24:56.320 --> 01:24:57.960]   - I've thought a lot about this.
[01:24:57.960 --> 01:25:02.960]   The first step is to have people interested in policy
[01:25:02.960 --> 01:25:07.000]   understand what the data actually show
[01:25:07.000 --> 01:25:09.880]   to pay attention to intelligence data.
[01:25:09.880 --> 01:25:13.520]   You can read policy papers about education
[01:25:13.520 --> 01:25:15.920]   and using your word processor,
[01:25:15.920 --> 01:25:17.960]   you can search for the word intelligence.
[01:25:17.960 --> 01:25:22.200]   You can search a 20,000 word document in a second
[01:25:22.200 --> 01:25:26.880]   and find out the word intelligence does not appear anywhere.
[01:25:26.880 --> 01:25:31.880]   In most discussions about what to do about achievement gaps,
[01:25:31.880 --> 01:25:33.720]   I'm not talking about test gaps,
[01:25:33.720 --> 01:25:37.400]   I'm talking about actual achievement gaps in schools,
[01:25:37.400 --> 01:25:40.200]   which everyone agrees is a problem.
[01:25:40.200 --> 01:25:44.000]   The word intelligence doesn't appear among educators.
[01:25:44.000 --> 01:25:44.840]   - That's fascinating.
[01:25:44.840 --> 01:25:47.680]   - As a matter of fact, in California,
[01:25:47.680 --> 01:25:50.080]   there has been tremendous controversy
[01:25:50.080 --> 01:25:54.440]   about recent attempts to revise the curriculum for math
[01:25:54.440 --> 01:25:58.320]   in high schools, and we had a Stanford professor
[01:25:58.320 --> 01:26:02.880]   of education who was running this review assert
[01:26:02.880 --> 01:26:06.680]   there's no such thing as talent, mathematical talent.
[01:26:06.680 --> 01:26:12.360]   And she wanted to get rid of the advanced classes in math
[01:26:12.360 --> 01:26:15.400]   because not everyone could do that.
[01:26:15.400 --> 01:26:17.320]   Now, of course, this has been very controversial,
[01:26:17.320 --> 01:26:19.520]   they've retreated somewhat,
[01:26:19.520 --> 01:26:21.720]   but the idea that a university professor
[01:26:21.720 --> 01:26:23.600]   was in charge of this who believes
[01:26:23.600 --> 01:26:31.200]   that there's no talent, that it doesn't exist,
[01:26:31.920 --> 01:26:33.600]   this is rather shocking,
[01:26:33.600 --> 01:26:37.520]   let alone the complete absence of intelligence data.
[01:26:37.520 --> 01:26:39.040]   By the way, let me tell you something
[01:26:39.040 --> 01:26:42.040]   about what the intelligence data show.
[01:26:42.040 --> 01:26:43.640]   Let's take race out of it.
[01:26:43.640 --> 01:26:48.320]   Even though the origins of these studies
[01:26:48.320 --> 01:26:50.960]   were a long time ago,
[01:26:50.960 --> 01:26:53.960]   I'm blocking on the name of the report,
[01:26:53.960 --> 01:26:57.760]   the Coleman Report was a famous report about education,
[01:26:57.760 --> 01:27:01.960]   and they measured all kinds of variables about schools,
[01:27:01.960 --> 01:27:06.320]   about teachers, and they looked at academic achievement
[01:27:06.320 --> 01:27:08.200]   as an outcome.
[01:27:08.200 --> 01:27:12.720]   And they found the most predictive variables
[01:27:12.720 --> 01:27:17.680]   of education outcome were the variables the student brought
[01:27:17.680 --> 01:27:20.440]   with him or her into the school,
[01:27:20.440 --> 01:27:22.000]   essentially their ability.
[01:27:22.000 --> 01:27:26.480]   And that when you combine the school
[01:27:26.480 --> 01:27:29.520]   and the teacher variables together,
[01:27:29.520 --> 01:27:31.960]   the quality of the school, the funding of the school,
[01:27:31.960 --> 01:27:34.720]   the quality of the teachers, their education,
[01:27:34.720 --> 01:27:37.600]   you put all the teacher and school variables together,
[01:27:37.600 --> 01:27:40.300]   it barely accounted for 10% of the variance.
[01:27:40.300 --> 01:27:43.600]   And this has been replicated now.
[01:27:43.600 --> 01:27:50.400]   So the best research we have shows that school variables
[01:27:50.400 --> 01:27:54.800]   and teacher variables together account
[01:27:54.800 --> 01:27:58.200]   for about 10% of student academic achievement.
[01:27:58.200 --> 01:28:02.120]   Now, you wanna have some policy
[01:28:02.120 --> 01:28:04.840]   on improving academic achievement,
[01:28:04.840 --> 01:28:08.400]   how much money do you wanna put into teacher education?
[01:28:08.400 --> 01:28:11.720]   How much money do you wanna put into the quality
[01:28:11.720 --> 01:28:14.280]   of the school administration?
[01:28:14.280 --> 01:28:15.420]   You know who you can ask?
[01:28:15.420 --> 01:28:17.280]   You can ask the Gates Foundation,
[01:28:17.280 --> 01:28:21.600]   because they spent a tremendous amount of money doing that.
[01:28:21.600 --> 01:28:25.160]   And at the end of it, because they're measurement people,
[01:28:25.160 --> 01:28:27.600]   they wanna know the data,
[01:28:27.600 --> 01:28:29.680]   they found it had no impact at all.
[01:28:29.680 --> 01:28:33.480]   And they've kind of pulled out of that kind of program.
[01:28:33.480 --> 01:28:35.020]   - So, oh boy.
[01:28:35.020 --> 01:28:41.240]   Let me ask you, this is me talking, but there's--
[01:28:41.240 --> 01:28:42.680]   - Just the two of us.
[01:28:42.680 --> 01:28:44.920]   - Just the two of us, but I'm gonna say
[01:28:44.920 --> 01:28:46.680]   some funny and ridiculous things,
[01:28:46.680 --> 01:28:49.980]   so you surely are not approving of it.
[01:28:51.280 --> 01:28:53.280]   But there's a movie called Clerks.
[01:28:53.280 --> 01:28:56.400]   - I've seen it, I've seen it, yeah.
[01:28:56.400 --> 01:28:58.080]   - There's a funny scene in there
[01:28:58.080 --> 01:29:01.040]   where a lovely couple are talking about
[01:29:01.040 --> 01:29:03.960]   the number of previous sexual partners they had.
[01:29:03.960 --> 01:29:08.960]   And the woman says that, I believe she just had a handful,
[01:29:08.960 --> 01:29:12.640]   like two or three or something like that, sexual partners,
[01:29:12.640 --> 01:29:16.760]   but then she also mentioned that she,
[01:29:16.760 --> 01:29:20.400]   what's that called, fallatio, what's the scientific,
[01:29:20.400 --> 01:29:23.120]   but she went, you know, gave a blowjob,
[01:29:23.120 --> 01:29:26.240]   to 37 guys, I believe it is.
[01:29:26.240 --> 01:29:30.000]   And so that has to do with the truth.
[01:29:30.000 --> 01:29:34.440]   So sometimes, knowing the truth
[01:29:34.440 --> 01:29:40.320]   can get in the way of a successful relationship of love
[01:29:40.320 --> 01:29:42.080]   of some of the human flourishing.
[01:29:42.080 --> 01:29:46.380]   And that seems to me that's at the core here,
[01:29:46.380 --> 01:29:51.380]   that facing some kind of truth that's not able to be changed
[01:29:51.380 --> 01:29:56.100]   makes it difficult to sort of,
[01:29:56.100 --> 01:30:00.940]   is limiting as opposed to empowering.
[01:30:00.940 --> 01:30:02.300]   That's the concern.
[01:30:02.300 --> 01:30:07.220]   If you sort of test for intelligence and lay the data out,
[01:30:07.220 --> 01:30:10.220]   it feels like you will give up on certain people.
[01:30:10.220 --> 01:30:13.540]   You will sort of start binning people,
[01:30:13.540 --> 01:30:16.580]   it's like, well, this person is like,
[01:30:16.580 --> 01:30:19.060]   let's focus on the average people,
[01:30:19.060 --> 01:30:20.980]   or let's focus on the very intelligent people.
[01:30:20.980 --> 01:30:22.540]   That's the concern.
[01:30:22.540 --> 01:30:26.700]   And there's a kind of intuition
[01:30:26.700 --> 01:30:29.580]   that if we just don't measure,
[01:30:29.580 --> 01:30:31.660]   and we don't use that data,
[01:30:31.660 --> 01:30:33.620]   that we would treat everybody equal
[01:30:33.620 --> 01:30:37.860]   and give everybody equal opportunity.
[01:30:37.860 --> 01:30:39.680]   If we have the data in front of us,
[01:30:39.680 --> 01:30:44.680]   we're likely to misdistribute the amount
[01:30:44.680 --> 01:30:46.360]   of sort of attention we allocate,
[01:30:46.360 --> 01:30:49.400]   resources we allocate to people.
[01:30:49.400 --> 01:30:52.160]   That's probably the concern.
[01:30:52.160 --> 01:30:55.080]   - It's a realistic concern,
[01:30:55.080 --> 01:30:57.660]   but I think it's a misplaced concern
[01:30:57.660 --> 01:31:00.560]   if you wanna fix the problem.
[01:31:00.560 --> 01:31:02.040]   If you wanna fix the problem,
[01:31:02.040 --> 01:31:03.960]   you have to know what the problem is.
[01:31:03.960 --> 01:31:05.160]   - Yep.
[01:31:05.160 --> 01:31:06.800]   - Now, let me tell you this.
[01:31:06.800 --> 01:31:08.880]   Let's go back to the bell curve,
[01:31:08.880 --> 01:31:11.320]   not the bell curve, but the normal distribution.
[01:31:11.320 --> 01:31:12.400]   - Yes.
[01:31:12.400 --> 01:31:17.400]   - 16% of the population on average has an IQ under 85,
[01:31:17.400 --> 01:31:22.080]   which means they're very hard.
[01:31:22.080 --> 01:31:24.200]   If you have an IQ under 85,
[01:31:24.200 --> 01:31:26.760]   it's very hard to find gainful employment
[01:31:26.760 --> 01:31:31.240]   at a salary that sustains you,
[01:31:31.240 --> 01:31:34.800]   at least minimally, in modern life.
[01:31:34.800 --> 01:31:35.640]   Okay?
[01:31:35.640 --> 01:31:37.520]   Not impossible, but it's very difficult.
[01:31:38.520 --> 01:31:42.400]   16% of the population of the United States
[01:31:42.400 --> 01:31:47.400]   is about 51 or 52 million people with IQs under 85.
[01:31:47.400 --> 01:31:52.520]   This is not a small issue.
[01:31:52.520 --> 01:31:55.860]   14 million children have IQs under 85.
[01:31:55.860 --> 01:32:00.720]   Is this something we wanna ignore?
[01:32:00.720 --> 01:32:04.440]   Does this have any, what is the Venn diagram between,
[01:32:04.440 --> 01:32:08.200]   you know, when you have people with IQs under 85
[01:32:08.200 --> 01:32:13.140]   and you have achievement in school or achievement in life?
[01:32:13.140 --> 01:32:16.840]   There's a lot of overlap there.
[01:32:16.840 --> 01:32:19.680]   This is why, to go back to the IQ pill,
[01:32:19.680 --> 01:32:24.200]   if there were a way to shift that curve
[01:32:24.200 --> 01:32:31.520]   toward the higher end, that would have a big impact.
[01:32:31.520 --> 01:32:34.600]   - If I could maybe, before we talk about
[01:32:34.600 --> 01:32:36.340]   the impact on life and so on,
[01:32:37.360 --> 01:32:39.160]   some of the criticisms of the bell curve.
[01:32:39.160 --> 01:32:42.520]   So Stephen Jay Gould wrote that the bell curve
[01:32:42.520 --> 01:32:45.400]   rests on four incorrect assumptions.
[01:32:45.400 --> 01:32:47.480]   It would be just interesting to get your thoughts
[01:32:47.480 --> 01:32:49.520]   on the four assumptions, which are
[01:32:49.520 --> 01:32:52.520]   intelligence must be reducible to a single number,
[01:32:52.520 --> 01:32:55.280]   intelligence must be capable of rank ordering people
[01:32:55.280 --> 01:32:56.640]   in a linear order,
[01:32:56.640 --> 01:33:00.400]   intelligence must be primarily genetically based,
[01:33:00.400 --> 01:33:04.320]   and intelligence must be essentially immutable.
[01:33:04.320 --> 01:33:09.320]   Maybe not as criticisms, but as thoughts about intelligence.
[01:33:09.320 --> 01:33:13.600]   - Yeah, we could spend a lot of time on him.
[01:33:13.600 --> 01:33:14.640]   - On Stephen Jay Gould?
[01:33:14.640 --> 01:33:15.640]   - Yes. - Yeah.
[01:33:15.640 --> 01:33:20.640]   - He wrote that in what, about 1985, 1984?
[01:33:20.640 --> 01:33:26.000]   His views were overtly political, not scientific.
[01:33:26.000 --> 01:33:28.600]   He was a scientist, but his views on this
[01:33:28.600 --> 01:33:32.520]   were overtly political, and I would encourage
[01:33:32.520 --> 01:33:36.400]   people listening to this, if they really wanna understand
[01:33:36.400 --> 01:33:41.400]   his criticisms, they should just Google
[01:33:41.400 --> 01:33:47.400]   what he had to say, and Google the scientific reviews
[01:33:47.400 --> 01:33:51.440]   of his book, "The Mismeasure of Man,"
[01:33:51.440 --> 01:33:54.680]   and they will take these statements apart.
[01:33:54.680 --> 01:33:57.880]   They were wrong, not only were they wrong,
[01:33:57.880 --> 01:34:00.320]   but when he asserted in his first book
[01:34:00.320 --> 01:34:05.320]   that there was no biological basis, essentially, to IQ,
[01:34:05.320 --> 01:34:08.200]   by the time the second edition came around,
[01:34:08.200 --> 01:34:13.200]   there were studies of MRIs showing that brain size,
[01:34:13.200 --> 01:34:16.760]   brain volume, were correlated to IQ scores,
[01:34:16.760 --> 01:34:19.880]   which he declined to put in his book. (laughs)
[01:34:19.880 --> 01:34:21.800]   - So, okay, I'm learning a lot today.
[01:34:21.800 --> 01:34:25.720]   I didn't know, actually, the extent of his work.
[01:34:25.720 --> 01:34:28.860]   I was just using a few little snippets of criticism.
[01:34:28.860 --> 01:34:30.680]   - That's interesting, so there's a battle here.
[01:34:30.680 --> 01:34:32.640]   He wrote a book, "Mismeasure of Man,"
[01:34:32.640 --> 01:34:36.480]   that's missing a lot of the scientific grounding.
[01:34:36.480 --> 01:34:39.640]   - His book is highly popular in colleges today.
[01:34:39.640 --> 01:34:41.760]   You can find it in any college bookstore
[01:34:41.760 --> 01:34:43.400]   under assigned reading.
[01:34:43.400 --> 01:34:45.120]   It's highly popular. - "The Mismeasure of Man"?
[01:34:45.120 --> 01:34:46.720]   - Yes, highly influential.
[01:34:46.720 --> 01:34:48.600]   - Can you speak to "The Mismeasure of Man"?
[01:34:48.600 --> 01:34:50.720]   I'm undereducated about this, so what,
[01:34:50.720 --> 01:34:53.240]   is this the book basically criticizing
[01:34:53.240 --> 01:34:55.040]   the ideas in the book? - Yeah, yeah,
[01:34:55.040 --> 01:34:57.240]   where those four things came from.
[01:34:57.240 --> 01:35:02.240]   And it is really a book that was really taken apart
[01:35:02.240 --> 01:35:05.800]   point by point by a number of people
[01:35:05.800 --> 01:35:07.960]   who actually understood the data.
[01:35:07.960 --> 01:35:09.760]   And he didn't care.
[01:35:09.760 --> 01:35:12.480]   He didn't care, he didn't modify anything.
[01:35:12.480 --> 01:35:16.560]   - Listen, because this is such a sensitive topic,
[01:35:16.560 --> 01:35:18.320]   like I said, I believe
[01:35:18.320 --> 01:35:26.000]   the impact of the work, as it is misinterpreted,
[01:35:26.000 --> 01:35:28.160]   has to be considered,
[01:35:28.160 --> 01:35:31.320]   because it's not just going to be scientific discourse,
[01:35:31.320 --> 01:35:32.840]   it's going to be political discourse,
[01:35:32.840 --> 01:35:34.560]   there's going to be debates,
[01:35:34.560 --> 01:35:39.440]   there's going to be politically motivated people
[01:35:39.440 --> 01:35:41.640]   that will use messages in each direction,
[01:35:41.640 --> 01:35:45.240]   make something like the bell curve the enemy
[01:35:45.240 --> 01:35:50.240]   or the support for one's racist beliefs.
[01:35:50.240 --> 01:35:55.120]   And so I think you have to consider that,
[01:35:55.120 --> 01:35:56.640]   but it's difficult because
[01:35:56.640 --> 01:36:01.440]   Nietzsche was used by Hitler to justify
[01:36:01.440 --> 01:36:02.320]   a lot of his beliefs,
[01:36:02.320 --> 01:36:07.320]   and it's not exactly on Nietzsche to anticipate Hitler,
[01:36:07.320 --> 01:36:12.520]   or how his ideas will be misinterpreted and used for evil.
[01:36:12.520 --> 01:36:14.560]   But there's a balance there.
[01:36:14.560 --> 01:36:16.280]   So I understand, this is really interesting,
[01:36:16.280 --> 01:36:18.960]   I didn't know, is there any criticism
[01:36:18.960 --> 01:36:21.400]   of the book you find compelling or interesting
[01:36:21.400 --> 01:36:23.640]   or challenging to use from a scientific perspective?
[01:36:23.640 --> 01:36:25.880]   - There were factual criticisms
[01:36:25.880 --> 01:36:30.880]   about the nature of the statistics that were used,
[01:36:30.880 --> 01:36:32.600]   the statistical analyses,
[01:36:32.600 --> 01:36:34.640]   these are more technical criticisms,
[01:36:34.640 --> 01:36:38.160]   and they were addressed by Murray in a couple of articles
[01:36:38.160 --> 01:36:41.760]   where he took all the criticisms and spoke to them.
[01:36:41.760 --> 01:36:44.840]   And people listening to this podcast
[01:36:44.840 --> 01:36:46.920]   can certainly find all those online.
[01:36:46.920 --> 01:36:48.880]   And it's very interesting.
[01:36:48.880 --> 01:36:52.800]   But Murray went on to write some additional books,
[01:36:52.800 --> 01:36:54.800]   two in the last couple of years.
[01:36:54.800 --> 01:36:57.880]   One about human diversity,
[01:36:57.880 --> 01:37:00.240]   where he goes through the data,
[01:37:00.240 --> 01:37:05.240]   refuting the idea that race is only a social construct
[01:37:05.240 --> 01:37:07.960]   with no biological meaning.
[01:37:07.960 --> 01:37:11.080]   He discusses the data, it's a very good discussion,
[01:37:11.080 --> 01:37:12.560]   you don't have to agree with it,
[01:37:12.560 --> 01:37:16.440]   but he presents data in a cogent way,
[01:37:16.440 --> 01:37:19.120]   and he talks about the critics of that,
[01:37:19.120 --> 01:37:20.680]   and he talks about their data
[01:37:20.680 --> 01:37:23.480]   in a cogent, non-personal way.
[01:37:23.480 --> 01:37:26.920]   It's a very informative discussion.
[01:37:26.920 --> 01:37:28.920]   The book is called "Human Diversity."
[01:37:28.920 --> 01:37:32.320]   He talks about race and he talks about gender, same thing,
[01:37:32.320 --> 01:37:33.720]   about sex differences.
[01:37:33.720 --> 01:37:36.960]   And more recently, he's written
[01:37:36.960 --> 01:37:39.600]   what might be his final say on this,
[01:37:39.600 --> 01:37:41.640]   a book called "Facing Reality,"
[01:37:41.640 --> 01:37:44.920]   where he talks about this again.
[01:37:44.920 --> 01:37:49.640]   So, you know, he can certainly defend himself.
[01:37:49.640 --> 01:37:52.120]   He doesn't need me to do that.
[01:37:52.120 --> 01:37:55.040]   But I would urge people who have heard
[01:37:55.040 --> 01:37:58.160]   about him and the bell curve,
[01:37:58.160 --> 01:38:00.280]   and who think they know what's in it,
[01:38:00.280 --> 01:38:03.480]   you are likely incorrect,
[01:38:03.480 --> 01:38:06.320]   and you need to read it for yourself.
[01:38:06.320 --> 01:38:09.160]   - But it is, scientifically,
[01:38:09.160 --> 01:38:13.560]   it's a serious subject, it's a difficult subject.
[01:38:13.560 --> 01:38:15.640]   Ethically, it's a difficult subject.
[01:38:16.680 --> 01:38:19.800]   Everything you said here calmly and thoughtfully
[01:38:19.800 --> 01:38:20.720]   is difficult.
[01:38:20.720 --> 01:38:23.200]   It's difficult for me to even consider
[01:38:23.200 --> 01:38:24.760]   that G factor exists.
[01:38:24.760 --> 01:38:27.880]   I don't mean from like,
[01:38:27.880 --> 01:38:30.440]   that somehow G factor is inherently racist
[01:38:30.440 --> 01:38:32.280]   or sexist or whatever.
[01:38:32.280 --> 01:38:35.520]   It's just, it's difficult in the way that
[01:38:35.520 --> 01:38:38.240]   considering the fact that we die one day is difficult.
[01:38:38.240 --> 01:38:42.880]   That we are limited by our biology is difficult.
[01:38:42.880 --> 01:38:43.720]   And it's,
[01:38:46.320 --> 01:38:47.800]   at least from an American perspective,
[01:38:47.800 --> 01:38:49.960]   you like to believe that everything is possible
[01:38:49.960 --> 01:38:51.440]   in this world.
[01:38:51.440 --> 01:38:55.440]   - Well, that leads us to what I think
[01:38:55.440 --> 01:38:58.240]   we should do with this information.
[01:38:58.240 --> 01:39:03.320]   And what I think we should do with this information
[01:39:03.320 --> 01:39:06.360]   is unusual.
[01:39:06.360 --> 01:39:07.720]   - Uh-oh.
[01:39:07.720 --> 01:39:09.560]   - Because I think what we need to do
[01:39:09.560 --> 01:39:12.520]   is fund more neuroscience research
[01:39:12.520 --> 01:39:15.760]   on the molecular biology of learning and memory.
[01:39:15.760 --> 01:39:20.600]   Because one definition of intelligence
[01:39:20.600 --> 01:39:24.640]   is based on how much you can learn
[01:39:24.640 --> 01:39:26.600]   and how much you can remember.
[01:39:26.600 --> 01:39:27.440]   - Yes.
[01:39:27.440 --> 01:39:30.920]   - And if you accept that definition of intelligence,
[01:39:30.920 --> 01:39:35.600]   then there are molecular studies going on now,
[01:39:35.600 --> 01:39:40.600]   and Nobel Prizes being won on molecular biology
[01:39:40.840 --> 01:39:44.240]   or molecular neurobiology of learning and memory.
[01:39:44.240 --> 01:39:48.640]   Now, the step those researchers,
[01:39:48.640 --> 01:39:53.200]   those scientists need to take when it comes to intelligence
[01:39:53.200 --> 01:39:58.200]   is to focus on the concept of individual differences.
[01:39:58.200 --> 01:40:03.240]   Intelligence research has individual differences
[01:40:03.240 --> 01:40:04.840]   as its heart,
[01:40:04.840 --> 01:40:09.840]   because it assumes that people differ on this variable
[01:40:10.600 --> 01:40:13.040]   and those differences are meaningful
[01:40:13.040 --> 01:40:15.960]   and need understanding.
[01:40:15.960 --> 01:40:19.400]   Cognitive psychologists who have morphed
[01:40:19.400 --> 01:40:23.400]   into molecular biologists studying learning and memory
[01:40:23.400 --> 01:40:27.440]   hate the concept of individual differences historically.
[01:40:27.440 --> 01:40:29.240]   Some now are coming around to it.
[01:40:29.240 --> 01:40:34.760]   I once sat next to a Nobel Prize winner
[01:40:34.760 --> 01:40:37.840]   for his work on memory.
[01:40:37.840 --> 01:40:41.320]   And I asked him about individual differences.
[01:40:41.320 --> 01:40:42.760]   And he said, "Don't go there.
[01:40:42.760 --> 01:40:44.700]   "It'll set us back 50 years."
[01:40:44.700 --> 01:40:49.500]   But I said, "Don't you think they're the key, though,
[01:40:49.500 --> 01:40:50.400]   "to understand, you know,
[01:40:50.400 --> 01:40:53.960]   "why can some people remember more than others?"
[01:40:53.960 --> 01:40:55.960]   He said, "You don't wanna go there."
[01:40:55.960 --> 01:40:58.760]   - I think the 21st century will be remembered
[01:40:58.760 --> 01:41:00.440]   by the technology and the science
[01:41:00.440 --> 01:41:04.120]   that goes to individual differences.
[01:41:04.120 --> 01:41:05.560]   Because we have now data,
[01:41:05.560 --> 01:41:07.400]   we have now the tools to much, much better
[01:41:07.400 --> 01:41:10.120]   to start to measure, start to estimate,
[01:41:10.120 --> 01:41:12.080]   not just on the sort of through tests
[01:41:12.080 --> 01:41:14.600]   and IQ test type of things,
[01:41:14.600 --> 01:41:18.240]   sort of outside the body kind of things,
[01:41:18.240 --> 01:41:20.320]   but measuring all kinds of stuff about the body.
[01:41:20.320 --> 01:41:23.160]   So yeah, truly go into the molecular biology,
[01:41:23.160 --> 01:41:27.000]   to the neurobiology, to the neuroscience.
[01:41:27.000 --> 01:41:30.360]   Let me ask you about life.
[01:41:30.360 --> 01:41:31.960]   (both laugh)
[01:41:31.960 --> 01:41:36.760]   How does intelligence correlate with or lead to
[01:41:36.760 --> 01:41:39.040]   or has anything to do with career success?
[01:41:39.040 --> 01:41:41.040]   You've mentioned these kinds of things.
[01:41:41.040 --> 01:41:44.800]   Is there any data, you've had an excellent conversation
[01:41:44.800 --> 01:41:46.720]   with Jordan Peterson, for example.
[01:41:46.720 --> 01:41:50.320]   Is there any data on what intelligent means
[01:41:50.320 --> 01:41:53.440]   for success in life?
[01:41:53.440 --> 01:41:57.520]   - Success in life, there is a tremendous amount
[01:41:57.520 --> 01:42:02.520]   of validity data that looked at intelligence test scores
[01:42:05.760 --> 01:42:10.760]   and various measures of life success.
[01:42:10.760 --> 01:42:16.040]   Now, of course, life success is a pretty broad topic
[01:42:16.040 --> 01:42:22.160]   and not everybody agrees on what success means,
[01:42:22.160 --> 01:42:27.160]   but there's general agreement on certain aspects of success
[01:42:27.160 --> 01:42:30.120]   that can be measured.
[01:42:30.120 --> 01:42:33.360]   And those--
[01:42:33.360 --> 01:42:35.080]   - Including life expectancy, like you said.
[01:42:35.080 --> 01:42:38.240]   - Life expectancy, now there's life success.
[01:42:38.240 --> 01:42:47.080]   Life expectancy, I mean, that is such an interesting finding
[01:42:47.080 --> 01:42:52.480]   but IQ scores are also correlated to things like income.
[01:42:52.480 --> 01:42:59.120]   Now, okay, so who thinks income means you're successful?
[01:42:59.120 --> 01:43:01.400]   That's not the point.
[01:43:01.400 --> 01:43:06.400]   The point is that income is one empirical measure
[01:43:06.400 --> 01:43:09.360]   in this culture that says something
[01:43:09.360 --> 01:43:11.560]   about your level of success.
[01:43:11.560 --> 01:43:13.520]   You can define success in ways
[01:43:13.520 --> 01:43:16.080]   that have nothing to do with income.
[01:43:16.080 --> 01:43:18.640]   You can define success based
[01:43:18.640 --> 01:43:23.480]   on your evolutionary natural selection success.
[01:43:23.480 --> 01:43:29.840]   But for variables, and even that by the way
[01:43:29.840 --> 01:43:34.000]   is correlated to IQ in some studies.
[01:43:34.000 --> 01:43:39.000]   So however you wanna define success, IQ is important.
[01:43:39.000 --> 01:43:44.320]   It's not the only determinant.
[01:43:44.320 --> 01:43:46.840]   People get hung up on, well, what about personality?
[01:43:46.840 --> 01:43:49.400]   What about so-called emotional intelligence?
[01:43:49.400 --> 01:43:52.080]   Yes, all those things matter.
[01:43:52.080 --> 01:43:54.520]   The thing that matters empirically,
[01:43:54.520 --> 01:43:56.440]   the single thing that matters the most
[01:43:56.440 --> 01:43:59.280]   is your general ability,
[01:43:59.280 --> 01:44:01.800]   your general mental intellectual ability,
[01:44:01.800 --> 01:44:03.680]   your reasoning ability.
[01:44:03.680 --> 01:44:07.200]   And the more complex your vocation,
[01:44:07.200 --> 01:44:11.600]   the more complex your job, the more G matters.
[01:44:11.600 --> 01:44:14.680]   G doesn't matter in a lot of occupations
[01:44:14.680 --> 01:44:17.160]   don't require complex thinking.
[01:44:17.160 --> 01:44:21.040]   And there are occupations like that and G doesn't matter.
[01:44:21.040 --> 01:44:22.840]   Within an occupation,
[01:44:24.160 --> 01:44:28.360]   the G might not matter so much.
[01:44:28.360 --> 01:44:33.280]   So that if you look at all the professors at MIT,
[01:44:33.280 --> 01:44:39.840]   and had a way to rank order them on,
[01:44:39.840 --> 01:44:42.560]   there's a ceiling effect is what I'm saying.
[01:44:42.560 --> 01:44:47.200]   - Also, when you get past a certain threshold,
[01:44:47.200 --> 01:44:49.920]   then there's impact on wealth, for example,
[01:44:49.920 --> 01:44:51.680]   or career success.
[01:44:51.840 --> 01:44:54.280]   However, that's defined in each individual discipline,
[01:44:54.280 --> 01:44:56.800]   but after a certain point, it doesn't matter.
[01:44:56.800 --> 01:44:59.320]   - Actually, it does matter in certain things.
[01:44:59.320 --> 01:45:03.280]   So for example, there is a very classic study
[01:45:03.280 --> 01:45:06.920]   that was started at Johns Hopkins
[01:45:06.920 --> 01:45:08.800]   when I was a graduate student there.
[01:45:08.800 --> 01:45:11.360]   I actually worked on this study at the very beginning.
[01:45:11.360 --> 01:45:12.680]   It's the study of mathematically
[01:45:12.680 --> 01:45:15.680]   and scientifically precocious youth.
[01:45:15.680 --> 01:45:20.120]   And they gave junior high school students,
[01:45:20.120 --> 01:45:25.120]   age 11 and 12, the standard SAT math exam.
[01:45:25.120 --> 01:45:31.440]   And they found a very large number of students
[01:45:31.440 --> 01:45:33.840]   scored very high on this exam.
[01:45:33.840 --> 01:45:35.120]   Not a large number.
[01:45:35.120 --> 01:45:39.120]   I mean, they found many students when they cast the net,
[01:45:39.120 --> 01:45:40.760]   they're all a Baltimore.
[01:45:40.760 --> 01:45:42.560]   They found a number of students
[01:45:42.560 --> 01:45:45.280]   who scored as high on the SAT math
[01:45:45.280 --> 01:45:49.200]   when they were 12 years old as incoming Hopkins freshmen.
[01:45:50.160 --> 01:45:53.600]   And they said, "Gee, now this is interesting.
[01:45:53.600 --> 01:45:56.960]   "What shall we do now?"
[01:45:56.960 --> 01:45:59.840]   And on a case-by-case basis,
[01:45:59.840 --> 01:46:01.680]   they got some of those kids
[01:46:01.680 --> 01:46:05.040]   into their local community college math programs.
[01:46:05.040 --> 01:46:10.280]   Many of those kids went on to be very successful.
[01:46:10.280 --> 01:46:13.880]   And now there's a 50-year follow-up of those kids.
[01:46:13.880 --> 01:46:16.440]   And it turns out,
[01:46:17.680 --> 01:46:21.160]   these kids were in the top 1%.
[01:46:21.160 --> 01:46:24.800]   Okay, so everybody in this study is in the top 1%.
[01:46:24.800 --> 01:46:28.120]   If you take that group, that rarified group,
[01:46:28.120 --> 01:46:30.560]   and divide them into quartiles,
[01:46:30.560 --> 01:46:35.360]   so that you have the top 25% of the top 1%,
[01:46:35.360 --> 01:46:39.800]   and the bottom 25% of the top 1%,
[01:46:39.800 --> 01:46:44.800]   you can find on measurable variables of success
[01:46:45.800 --> 01:46:48.040]   variables of success,
[01:46:48.040 --> 01:46:51.720]   the top quartile does better than the bottom quartile
[01:46:51.720 --> 01:46:53.800]   in the top 1%.
[01:46:53.800 --> 01:46:56.360]   They have more patents, they have more publications,
[01:46:56.360 --> 01:46:59.480]   they have more tenure at universities.
[01:46:59.480 --> 01:47:00.840]   And this is based on,
[01:47:00.840 --> 01:47:05.960]   you're dividing them based on their score at age 12.
[01:47:05.960 --> 01:47:10.240]   - I wonder how much interesting data
[01:47:10.240 --> 01:47:12.720]   is in the variability, in the differences.
[01:47:12.720 --> 01:47:16.480]   So, but that's really, oh boy.
[01:47:16.480 --> 01:47:19.760]   That's very interesting, but it's also,
[01:47:19.760 --> 01:47:21.040]   I don't know, somehow painful.
[01:47:21.040 --> 01:47:22.800]   I don't know why it's so painful.
[01:47:22.800 --> 01:47:26.640]   That G-factor's so determinant,
[01:47:26.640 --> 01:47:30.760]   of even in the nuanced top percent.
[01:47:30.760 --> 01:47:32.800]   - Well, this is interesting that you find that painful.
[01:47:32.800 --> 01:47:36.800]   Do you find it painful that people with charisma
[01:47:36.800 --> 01:47:40.720]   can be very successful in life,
[01:47:40.720 --> 01:47:42.720]   even though having no other attributes
[01:47:42.720 --> 01:47:45.760]   other than they're famous and people like them?
[01:47:45.760 --> 01:47:47.400]   Do you find that painful?
[01:47:47.400 --> 01:47:51.120]   - Yes, if that charisma is untrainable.
[01:47:51.120 --> 01:47:53.320]   So one of the things, again,
[01:47:53.320 --> 01:47:56.760]   this is like I learned psychology from the Johnny Depp trial.
[01:47:56.760 --> 01:48:00.840]   But one of the things the psychologist,
[01:48:00.840 --> 01:48:02.320]   the personality psychologist,
[01:48:02.320 --> 01:48:03.440]   he can maybe speak to this,
[01:48:03.440 --> 01:48:07.200]   'cause he had interest in this for a time,
[01:48:07.200 --> 01:48:10.660]   is she was saying that personality,
[01:48:10.660 --> 01:48:15.400]   technically speaking, is the thing that doesn't change
[01:48:15.400 --> 01:48:16.960]   over a lifetime.
[01:48:16.960 --> 01:48:19.280]   It's the thing you're,
[01:48:19.280 --> 01:48:20.600]   I don't know if she was actually implying
[01:48:20.600 --> 01:48:21.680]   that you're born with it.
[01:48:21.680 --> 01:48:22.760]   - Well, it's a trait.
[01:48:22.760 --> 01:48:23.600]   - It's a trait that's--
[01:48:23.600 --> 01:48:27.200]   - It's a trait that's relatively stable over time.
[01:48:27.200 --> 01:48:28.960]   I think that's generally correct.
[01:48:28.960 --> 01:48:33.120]   - So to the degree your personality is stable over time,
[01:48:33.120 --> 01:48:36.000]   yes, that too is painful.
[01:48:36.840 --> 01:48:39.600]   'Cause what's not painful is the thing,
[01:48:39.600 --> 01:48:42.360]   if I'm fat and out of shape,
[01:48:42.360 --> 01:48:47.360]   I can exercise and become healthier in that way.
[01:48:47.360 --> 01:48:50.640]   If my diet is a giant mess
[01:48:50.640 --> 01:48:53.880]   and that's resulting in some kind of conditions
[01:48:53.880 --> 01:48:55.320]   that my body's experiencing,
[01:48:55.320 --> 01:48:58.040]   I can fix that by having a better diet.
[01:48:58.040 --> 01:49:00.480]   That's sort of my actions,
[01:49:00.480 --> 01:49:03.840]   my willed actions can make a change.
[01:49:03.840 --> 01:49:06.540]   If charisma is part of the personality
[01:49:06.540 --> 01:49:09.160]   that's the part of the charisma
[01:49:09.160 --> 01:49:11.880]   that is part of the personality that is stable,
[01:49:11.880 --> 01:49:15.400]   yeah, yeah, that's painful too.
[01:49:15.400 --> 01:49:18.400]   'Cause it's like, oh shit, I'm stuck with this.
[01:49:18.400 --> 01:49:19.880]   I'm stuck with this.
[01:49:19.880 --> 01:49:22.880]   - Well, I mean, and this pretty much generalizes
[01:49:22.880 --> 01:49:24.980]   to every aspect of your being.
[01:49:24.980 --> 01:49:27.520]   This is who you are, you gotta deal with it.
[01:49:27.520 --> 01:49:29.360]   And what it undermines, of course,
[01:49:29.360 --> 01:49:32.560]   is a realistic appreciation for this,
[01:49:32.560 --> 01:49:37.560]   undermines the fairly recent idea
[01:49:37.560 --> 01:49:40.760]   prevalent in this country,
[01:49:40.760 --> 01:49:44.020]   that if you work hard, you can be anything you wanna be.
[01:49:44.020 --> 01:49:47.460]   Which has morphed from the original idea
[01:49:47.460 --> 01:49:50.900]   that if you work hard, you can be successful.
[01:49:50.900 --> 01:49:52.840]   Those are two different things.
[01:49:52.840 --> 01:49:53.900]   - Yeah.
[01:49:53.900 --> 01:49:55.720]   - And now we have,
[01:49:55.720 --> 01:50:00.860]   if you work hard, you can be anything you wanna be.
[01:50:00.860 --> 01:50:03.440]   This is completely unrealistic.
[01:50:03.440 --> 01:50:05.220]   I'm sorry, it just is.
[01:50:05.220 --> 01:50:06.820]   Now you can work hard and be successful,
[01:50:06.820 --> 01:50:08.540]   there's no question.
[01:50:08.540 --> 01:50:11.740]   But you know what, I could work very hard
[01:50:11.740 --> 01:50:15.060]   and I am not going to be a successful
[01:50:15.060 --> 01:50:18.740]   theoretical physicist, I'm just not.
[01:50:18.740 --> 01:50:20.700]   - That said, I mean, we should,
[01:50:20.700 --> 01:50:22.900]   'cause we had this conversation already,
[01:50:22.900 --> 01:50:24.420]   but it's good to repeat.
[01:50:24.420 --> 01:50:27.700]   The fact that you're not going to be
[01:50:27.700 --> 01:50:30.140]   a theoretical physicist,
[01:50:30.140 --> 01:50:32.820]   is not judgment on your basic humanity.
[01:50:32.820 --> 01:50:35.580]   Returning again to the old man,
[01:50:35.580 --> 01:50:39.100]   which means men and women are created equal.
[01:50:39.100 --> 01:50:41.580]   So again, some of the differences we're talking about
[01:50:41.580 --> 01:50:44.860]   in quote unquote success, wealth,
[01:50:44.860 --> 01:50:50.620]   number of, whether you win a Nobel Prize or not,
[01:50:50.620 --> 01:50:55.620]   that doesn't put a measure on your basic humanity
[01:50:55.780 --> 01:51:00.780]   and basic value and even goodness of you as a human being.
[01:51:00.780 --> 01:51:06.860]   'Cause that, your basic role and value in society
[01:51:06.860 --> 01:51:10.900]   is largely within your control.
[01:51:10.900 --> 01:51:14.580]   It's some of these measures that we're talking about.
[01:51:14.580 --> 01:51:18.300]   It's good to remember this.
[01:51:18.300 --> 01:51:21.180]   One question about the Flynn effect.
[01:51:21.180 --> 01:51:23.260]   What is it?
[01:51:23.260 --> 01:51:26.300]   Are humans getting smarter over the years,
[01:51:26.300 --> 01:51:28.820]   over the decades, over the centuries?
[01:51:28.820 --> 01:51:31.540]   - The Flynn effect is, James Flynn,
[01:51:31.540 --> 01:51:34.020]   passed away about a year ago,
[01:51:34.020 --> 01:51:39.640]   published a set of analyses,
[01:51:39.640 --> 01:51:43.660]   going back a couple of decades,
[01:51:43.660 --> 01:51:46.060]   when he first noticed this,
[01:51:46.060 --> 01:51:51.060]   that IQ scores, when you looked over the years,
[01:51:51.500 --> 01:51:53.220]   seemed to be drifting up.
[01:51:53.220 --> 01:51:58.900]   Now this was not unknown to the people who make the test,
[01:51:58.900 --> 01:52:02.300]   because they re-norm the test periodically,
[01:52:02.300 --> 01:52:05.340]   and they have to re-norm the test periodically,
[01:52:05.340 --> 01:52:09.780]   because what 10 items correct meant
[01:52:09.780 --> 01:52:13.780]   relative to other people 50 years ago
[01:52:13.780 --> 01:52:18.660]   is not the same as what 10 items mean relative today.
[01:52:18.660 --> 01:52:21.340]   People are getting more things correct.
[01:52:21.340 --> 01:52:25.060]   Now, the scores have been drifting up about three points,
[01:52:25.060 --> 01:52:27.340]   IQ scores have been drifting up
[01:52:27.340 --> 01:52:30.160]   about three points per decade.
[01:52:30.160 --> 01:52:34.060]   This is not a personal effect, this is a cohort effect.
[01:52:34.060 --> 01:52:37.180]   Well, it's not for an individual, but--
[01:52:37.180 --> 01:52:39.580]   - The world, how do you, so what's the explanation?
[01:52:39.580 --> 01:52:42.460]   - And this has presented intelligence researchers
[01:52:42.460 --> 01:52:44.660]   with a great mystery.
[01:52:44.660 --> 01:52:46.300]   Two questions.
[01:52:46.300 --> 01:52:50.900]   First, is it effect on the 50% of the variance
[01:52:50.900 --> 01:52:55.180]   that's the G factor, or on the other 50%,
[01:52:55.180 --> 01:52:58.640]   and there's evidence that it is a G factor effect.
[01:52:58.640 --> 01:53:02.740]   And second, what on earth causes this,
[01:53:02.740 --> 01:53:05.860]   and doesn't this mean intelligence and G factor
[01:53:05.860 --> 01:53:10.260]   cannot be genetic, because the scale of natural selection
[01:53:10.260 --> 01:53:15.260]   is much, much longer than a couple of decades ago.
[01:53:15.260 --> 01:53:19.780]   And so it's been used to try to undermine the idea
[01:53:19.780 --> 01:53:23.500]   that there can be a genetic influence on intelligence.
[01:53:23.500 --> 01:53:28.660]   But certainly, it can be, the Flynn effect
[01:53:28.660 --> 01:53:32.140]   can affect the non-genetic aspects of intelligence,
[01:53:32.140 --> 01:53:37.140]   because genes account for maybe 50% of the variance.
[01:53:37.140 --> 01:53:40.980]   Maybe higher, it could be as high as 80% for adults,
[01:53:40.980 --> 01:53:44.200]   but let's just say 50% for discussion.
[01:53:46.480 --> 01:53:50.360]   So the Flynn effect, it's still a mystery.
[01:53:50.360 --> 01:53:51.200]   - It's still a mystery, that's interesting.
[01:53:51.200 --> 01:53:52.200]   - It's still a mystery,
[01:53:52.200 --> 01:53:54.080]   although the evidence is coming out.
[01:53:54.080 --> 01:53:56.760]   I told you before I edited a journal on intelligence,
[01:53:56.760 --> 01:54:00.520]   and we're doing a special issue in honor of James Flynn.
[01:54:00.520 --> 01:54:02.520]   So I'm starting to see papers now
[01:54:02.520 --> 01:54:04.840]   on really the latest research on this.
[01:54:04.840 --> 01:54:09.720]   I think most people who specialize in this area,
[01:54:09.720 --> 01:54:12.200]   of trying to understand the Flynn effect,
[01:54:12.200 --> 01:54:16.520]   are coming to the view, based on data,
[01:54:16.520 --> 01:54:20.420]   that it has to do with advances in nutrition and healthcare.
[01:54:20.420 --> 01:54:28.040]   And there's also evidence that the effect is slowing down,
[01:54:28.040 --> 01:54:30.440]   and possibly reversing.
[01:54:30.440 --> 01:54:31.320]   - Oh boy.
[01:54:31.320 --> 01:54:33.320]   So how would nutrition,
[01:54:33.320 --> 01:54:38.320]   so nutrition would still be connected to the G factor.
[01:54:38.320 --> 01:54:41.640]   So nutrition as it relates to the G factor,
[01:54:41.640 --> 01:54:45.080]   so the biology that leads to the intelligence.
[01:54:45.080 --> 01:54:45.920]   - Yes.
[01:54:45.920 --> 01:54:46.920]   - That would be the claim,
[01:54:46.920 --> 01:54:52.160]   the hypothesis being tested by the research.
[01:54:52.160 --> 01:54:55.320]   - Yes, and there's some evidence from infants
[01:54:55.320 --> 01:55:00.600]   that nutrition has made a difference.
[01:55:00.600 --> 01:55:02.860]   So it's not an unreasonable connection.
[01:55:02.860 --> 01:55:07.720]   But does it negate the idea that there's a genetic influence?
[01:55:07.720 --> 01:55:10.040]   Not logically at all.
[01:55:10.040 --> 01:55:11.880]   But it is very interesting.
[01:55:11.880 --> 01:55:15.560]   So that if you take an IQ test today,
[01:55:15.560 --> 01:55:21.040]   but you take the score and use the tables
[01:55:21.040 --> 01:55:25.020]   that were available in 1940,
[01:55:25.020 --> 01:55:28.040]   you're gonna wind up with a much higher IQ number.
[01:55:28.040 --> 01:55:34.040]   So are we really smarter than a couple of generations ago?
[01:55:34.040 --> 01:55:39.700]   No, but we might be able to solve problems a little better.
[01:55:40.700 --> 01:55:45.700]   And make use of our G because of things like Sesame Street
[01:55:45.700 --> 01:55:47.900]   and other curricula in school.
[01:55:47.900 --> 01:55:51.120]   More people are going to school.
[01:55:51.120 --> 01:55:56.220]   So there are a lot of factors here to disentangle.
[01:55:56.220 --> 01:55:57.580]   - It's fascinating though.
[01:55:57.580 --> 01:56:00.460]   It's fascinating that there's not clear answers yet.
[01:56:00.460 --> 01:56:05.140]   That as a population, we're getting smarter.
[01:56:05.140 --> 01:56:06.900]   When you just zoom out, that's what it looks like.
[01:56:06.900 --> 01:56:08.100]   As a population, we're getting smarter.
[01:56:08.100 --> 01:56:10.780]   And it's interesting to see what the effects of that are.
[01:56:10.780 --> 01:56:12.060]   I mean, this raises the question.
[01:56:12.060 --> 01:56:14.820]   We've mentioned it many times,
[01:56:14.820 --> 01:56:16.500]   but haven't clearly addressed it,
[01:56:16.500 --> 01:56:19.320]   which is nature versus nurture question.
[01:56:19.320 --> 01:56:22.100]   So how much of intelligence is nature?
[01:56:22.100 --> 01:56:23.900]   How much of it is nurture?
[01:56:23.900 --> 01:56:27.700]   How much of it is determined by genetics versus environment?
[01:56:27.700 --> 01:56:28.820]   - All of it.
[01:56:28.820 --> 01:56:30.260]   - All of it is genetics.
[01:56:30.260 --> 01:56:34.300]   - No, all of it is nature and nurture.
[01:56:34.300 --> 01:56:35.780]   - Yeah, so yes.
[01:56:35.780 --> 01:56:36.780]   Yes.
[01:56:36.780 --> 01:56:37.620]   - Okay.
[01:56:37.620 --> 01:56:40.740]   That's not as-
[01:56:40.740 --> 01:56:44.500]   - But how much of the variance can you apportion to either?
[01:56:44.500 --> 01:56:47.380]   Most of the people who work in this field say that
[01:56:47.380 --> 01:56:50.340]   that is the framing of that.
[01:56:50.340 --> 01:56:54.500]   If the question is framed that way, it can't be answered
[01:56:54.500 --> 01:56:55.920]   because nature and nurture
[01:56:55.920 --> 01:56:59.420]   are not two independent influences.
[01:56:59.420 --> 01:57:01.300]   They interact with each other.
[01:57:01.300 --> 01:57:06.300]   And understanding those interactions is so complex
[01:57:06.500 --> 01:57:11.500]   that many behavioral geneticists say it is today impossible
[01:57:11.500 --> 01:57:16.980]   and always will be impossible to disentangle that
[01:57:16.980 --> 01:57:21.140]   no matter what kind of advances there are in DNA technology
[01:57:21.140 --> 01:57:24.660]   and genomic informatics.
[01:57:24.660 --> 01:57:26.820]   - But there's still, to push back on that,
[01:57:26.820 --> 01:57:31.620]   that same intuition from behavioral geneticists
[01:57:31.620 --> 01:57:34.380]   would lead me to believe that there cannot possibly
[01:57:34.380 --> 01:57:36.040]   be a stable G factor.
[01:57:37.040 --> 01:57:38.960]   'Cause it's super complex.
[01:57:38.960 --> 01:57:43.820]   - Many of them would assert that as a logical outcome.
[01:57:43.820 --> 01:57:49.120]   But because I believe there is a stable G factor
[01:57:49.120 --> 01:57:52.480]   from lots of sources of data, not just one study,
[01:57:52.480 --> 01:57:54.940]   but lots of sources of data over decades,
[01:57:54.940 --> 01:58:00.160]   I am more amenable to the idea
[01:58:00.160 --> 01:58:03.880]   that whatever interactions between genes
[01:58:03.880 --> 01:58:08.880]   and environment exist, they can be explicated,
[01:58:08.880 --> 01:58:11.680]   they can be studied,
[01:58:11.680 --> 01:58:16.920]   and that information can be used as a basis
[01:58:16.920 --> 01:58:19.400]   for molecular biology of intelligence.
[01:58:19.400 --> 01:58:21.880]   - Yeah, so, and we'll do this exact question,
[01:58:21.880 --> 01:58:26.880]   'cause doesn't the stability of the G factor
[01:58:26.880 --> 01:58:32.160]   give you at least a hint that there is a biological basis
[01:58:32.920 --> 01:58:34.000]   for intelligence?
[01:58:34.000 --> 01:58:38.040]   - Yes, I think it's clear that the fact that
[01:58:38.040 --> 01:58:42.960]   an IQ score is correlated to things like thickness
[01:58:42.960 --> 01:58:47.040]   of your cortex, that it's correlated to
[01:58:47.040 --> 01:58:51.000]   glucose metabolic rate in your brain,
[01:58:51.000 --> 01:58:58.120]   that identical twins reared apart
[01:58:58.120 --> 01:59:01.900]   are highly similar in their IQ scores.
[01:59:01.900 --> 01:59:06.360]   These are all important observations
[01:59:06.360 --> 01:59:09.320]   that certainly more than, that indicate,
[01:59:09.320 --> 01:59:11.880]   not just suggest, but indicate
[01:59:11.880 --> 01:59:13.480]   that there's a biological basis.
[01:59:13.480 --> 01:59:15.240]   And does anyone believe intelligence
[01:59:15.240 --> 01:59:16.880]   has nothing to do with the brain?
[01:59:16.880 --> 01:59:20.920]   I mean, it's so obvious.
[01:59:20.920 --> 01:59:23.680]   - Well, indirectly, definitely has to do with it,
[01:59:23.680 --> 01:59:27.360]   but the question is, environment interacting with the brain,
[01:59:27.360 --> 01:59:32.360]   or is it the actual raw hardware of the brain?
[01:59:32.360 --> 01:59:39.600]   - Well, some would say that the raw hardware of the brain,
[01:59:39.600 --> 01:59:46.380]   as it develops from conception through adulthood,
[01:59:46.380 --> 01:59:49.980]   or at least through the childhood,
[01:59:49.980 --> 01:59:53.780]   that that so-called hardware that you are assuming
[01:59:53.780 --> 01:59:57.340]   is mostly genetic, in fact,
[01:59:57.340 --> 02:00:00.980]   is not as deterministic as you might think,
[02:00:00.980 --> 02:00:03.380]   that it is probabilistic,
[02:00:03.380 --> 02:00:05.420]   and what affects the probabilities
[02:00:05.420 --> 02:00:08.220]   are things like in uterine environment,
[02:00:08.220 --> 02:00:13.980]   and other factors like that, including chance,
[02:00:13.980 --> 02:00:18.860]   that chance affects the way the neurons
[02:00:18.860 --> 02:00:21.480]   are connecting during gestation.
[02:00:21.480 --> 02:00:26.720]   It's not, hey, it's pre-programmed.
[02:00:26.720 --> 02:00:30.520]   So there is pushback on the concept
[02:00:30.520 --> 02:00:32.720]   that genes provide a blueprint,
[02:00:32.720 --> 02:00:36.740]   that it's a lot more fluid.
[02:00:36.740 --> 02:00:38.940]   - Well, but also, yeah, so there's a lot,
[02:00:38.940 --> 02:00:43.940]   a lot happens in the first few months of development.
[02:00:43.940 --> 02:00:51.060]   So in nine months inside the mother's body,
[02:00:51.060 --> 02:00:56.060]   and in the few months afterwards,
[02:00:57.040 --> 02:00:58.580]   there's a lot of fascinating stuff,
[02:00:58.580 --> 02:01:01.720]   like including chance and luck, like you said,
[02:01:01.720 --> 02:01:03.040]   how things connect up.
[02:01:03.040 --> 02:01:06.160]   Man, the question is, afterwards,
[02:01:06.160 --> 02:01:07.480]   in your plasticity of the brain,
[02:01:07.480 --> 02:01:10.000]   how much adjustment there is relative to the environment,
[02:01:10.000 --> 02:01:12.340]   how much that affects the G factor,
[02:01:12.340 --> 02:01:15.560]   but that's where the whole conclusions of the studies
[02:01:15.560 --> 02:01:18.280]   that we've been talking about is,
[02:01:18.280 --> 02:01:20.880]   that seems to have less and less and less of an effect
[02:01:20.880 --> 02:01:23.840]   as pretty quickly.
[02:01:23.840 --> 02:01:27.540]   - Yes, and I do think there is more of a genetic,
[02:01:27.540 --> 02:01:30.860]   by my view, and I'm not an expert on this,
[02:01:30.860 --> 02:01:34.280]   I mean, genetics is a highly technical and complex subject.
[02:01:34.280 --> 02:01:37.940]   I am not a geneticist, not a behavioral geneticist,
[02:01:37.940 --> 02:01:42.900]   but my reading of this, my interpretation of this,
[02:01:42.900 --> 02:01:47.900]   is that there is a genetic blueprint, more or less,
[02:01:47.900 --> 02:01:51.020]   and that has a profound influence
[02:01:51.020 --> 02:01:54.180]   on your subsequent intellectual development,
[02:01:54.180 --> 02:01:56.340]   including the G factor.
[02:01:56.340 --> 02:02:01.340]   And that's not to say things can't happen to,
[02:02:01.340 --> 02:02:05.500]   I mean, if you think of that genes provide a potential,
[02:02:05.500 --> 02:02:10.500]   fine, and then various variables impact that potential.
[02:02:10.500 --> 02:02:15.780]   And every parent of a newborn, implicitly or explicitly,
[02:02:15.780 --> 02:02:19.480]   wants to maximize that potential.
[02:02:19.480 --> 02:02:21.940]   This is why you buy educational toys.
[02:02:21.940 --> 02:02:25.620]   This is why you pay attention to organic baby food.
[02:02:25.620 --> 02:02:28.840]   This is why you do all these things,
[02:02:28.840 --> 02:02:31.460]   because you want your baby to be as healthy
[02:02:31.460 --> 02:02:33.580]   and as smart as possible.
[02:02:33.580 --> 02:02:35.980]   And every parent will say that.
[02:02:35.980 --> 02:02:37.380]   - Is there a case to be made,
[02:02:37.380 --> 02:02:39.820]   can you steel me on the case,
[02:02:39.820 --> 02:02:44.820]   that genetics is a very tiny component of all of this,
[02:02:47.000 --> 02:02:49.460]   and the environment is essential?
[02:02:49.460 --> 02:02:50.980]   - I don't think the data supports
[02:02:50.980 --> 02:02:53.620]   that genetics is a tiny component.
[02:02:53.620 --> 02:02:55.140]   I think the data support the idea
[02:02:55.140 --> 02:02:57.820]   that the genetics is a very important,
[02:02:57.820 --> 02:03:01.080]   and I don't say component, I say influence.
[02:03:01.080 --> 02:03:03.540]   A very important influence.
[02:03:03.540 --> 02:03:07.700]   And the environment is a lot less than people believe.
[02:03:07.700 --> 02:03:10.780]   Most people believe environment plays a big role.
[02:03:10.780 --> 02:03:11.620]   I'm not so sure.
[02:03:11.620 --> 02:03:13.180]   - I guess what I'm asking you is,
[02:03:13.200 --> 02:03:18.200]   can you see where what you just said, it might be wrong?
[02:03:18.200 --> 02:03:22.120]   Can you imagine a world,
[02:03:22.120 --> 02:03:25.580]   and what kind of evidence would you need to see,
[02:03:25.580 --> 02:03:29.880]   to say, you know what, the intuition, the studies so far,
[02:03:29.880 --> 02:03:31.680]   like reversing the directions.
[02:03:31.680 --> 02:03:34.720]   So one of the cool things we have now more and more,
[02:03:34.720 --> 02:03:36.040]   is we're getting more and more data,
[02:03:36.040 --> 02:03:40.080]   and the rate of the data is escalating
[02:03:40.080 --> 02:03:41.800]   because of the digital world.
[02:03:41.800 --> 02:03:46.180]   So when you start to look at a very large scale of data,
[02:03:46.180 --> 02:03:49.600]   both on the biology side and the social side,
[02:03:49.600 --> 02:03:52.280]   we might be discovering some very counterintuitive things
[02:03:52.280 --> 02:03:53.820]   about society.
[02:03:53.820 --> 02:03:57.540]   We might see the edge cases that reveal
[02:03:57.540 --> 02:04:00.080]   that if we actually scale those edge cases,
[02:04:00.080 --> 02:04:02.640]   and they become like the norm,
[02:04:02.640 --> 02:04:06.220]   that we'll have a complete shift in our,
[02:04:06.220 --> 02:04:09.580]   like you'll see G-factor be able
[02:04:09.580 --> 02:04:11.940]   to be modified throughout life,
[02:04:11.940 --> 02:04:15.200]   in the teens and in later life.
[02:04:15.200 --> 02:04:18.280]   So is it any case you can make,
[02:04:18.280 --> 02:04:20.780]   or for where your current intuitions are wrong?
[02:04:20.780 --> 02:04:22.280]   - Yes, and it's a good question,
[02:04:22.280 --> 02:04:24.540]   because I think everyone should always be asked,
[02:04:24.540 --> 02:04:26.560]   what evidence would change your mind?
[02:04:26.560 --> 02:04:29.800]   It's certainly not only a fair question,
[02:04:29.800 --> 02:04:32.940]   it is really the key question for anybody working
[02:04:32.940 --> 02:04:36.580]   on any aspect of science.
[02:04:36.580 --> 02:04:41.580]   I think that if environment was very important,
[02:04:41.580 --> 02:04:45.860]   we would have seen it clearly by now.
[02:04:45.860 --> 02:04:49.820]   It would have been obvious that school interventions,
[02:04:49.820 --> 02:04:53.500]   compensatory education, early childhood education,
[02:04:53.500 --> 02:04:56.780]   all these things that have been earnestly tried,
[02:04:56.780 --> 02:04:59.480]   and well-funded, well-designed studies,
[02:04:59.480 --> 02:05:02.060]   would show some effect, and they don't.
[02:05:02.060 --> 02:05:02.900]   - They don't.
[02:05:02.900 --> 02:05:05.680]   What if the school, the way we've tried school,
[02:05:05.680 --> 02:05:08.300]   compensatory school sucks, and we need to do better?
[02:05:08.300 --> 02:05:09.780]   - That's what everybody said at the beginning,
[02:05:09.780 --> 02:05:11.660]   that's what everybody said to Jensen.
[02:05:11.660 --> 02:05:15.460]   He said, well, maybe we need to start earlier.
[02:05:15.460 --> 02:05:18.500]   Maybe we need not do pre-kindergarten,
[02:05:18.500 --> 02:05:19.900]   but pre-pre-kindergarten.
[02:05:19.900 --> 02:05:22.220]   Yeah, it's always an infinite,
[02:05:22.220 --> 02:05:24.460]   well, maybe we didn't get it right.
[02:05:24.460 --> 02:05:28.220]   But after decades of trying, 50 years,
[02:05:28.220 --> 02:05:30.700]   50 or 60 years of trying,
[02:05:30.700 --> 02:05:34.660]   surely something would have worked to the point
[02:05:34.660 --> 02:05:37.140]   where you could actually see a result,
[02:05:37.140 --> 02:05:42.140]   and not need a probability level at .05 on some means.
[02:05:42.140 --> 02:05:47.420]   So that's the kind of evidence that would change my mind.
[02:05:47.420 --> 02:05:52.380]   - Population-level interventions like schooling
[02:05:52.380 --> 02:05:57.380]   that you would see, like this actually has an effect.
[02:05:57.380 --> 02:06:01.020]   - Yes, and when you take adopted kids,
[02:06:01.020 --> 02:06:04.060]   and they grow up in another family,
[02:06:04.060 --> 02:06:06.740]   and you find out when those adopted kids are adults,
[02:06:06.740 --> 02:06:09.740]   their IQ scores don't correlate with the IQ scores
[02:06:09.740 --> 02:06:11.660]   of their adoptive parents,
[02:06:11.660 --> 02:06:14.300]   but they do correlate with their IQ scores
[02:06:14.300 --> 02:06:17.840]   of their biological parents, whom they've never met.
[02:06:17.840 --> 02:06:20.500]   I mean, these are important,
[02:06:20.500 --> 02:06:22.740]   these are powerful observations.
[02:06:22.740 --> 02:06:24.220]   - And it would be convincing to you
[02:06:24.220 --> 02:06:26.420]   if the reverse was true.
[02:06:26.420 --> 02:06:27.700]   - Yes, that would be more.
[02:06:27.700 --> 02:06:30.540]   And there is some data on adoption
[02:06:30.540 --> 02:06:34.340]   that indicates the adopted children
[02:06:34.340 --> 02:06:35.860]   are moving a little bit more
[02:06:35.860 --> 02:06:39.280]   toward their adoptive parents.
[02:06:39.280 --> 02:06:44.020]   But it's, to me, the overwhelming,
[02:06:44.020 --> 02:06:47.260]   I have this concept called the weight of evidence,
[02:06:47.260 --> 02:06:50.440]   where I don't interpret any one study too much.
[02:06:50.440 --> 02:06:53.460]   The weight of evidence tells me genes are important.
[02:06:53.460 --> 02:06:54.460]   But what does that mean?
[02:06:54.460 --> 02:06:56.700]   What does it mean that genes are important,
[02:06:56.700 --> 02:06:59.300]   knowing that gene expression,
[02:06:59.300 --> 02:07:02.620]   genes don't express themselves in a vacuum,
[02:07:02.620 --> 02:07:05.820]   they express themselves in an environment.
[02:07:05.820 --> 02:07:08.540]   So the environment has to have something to do with it,
[02:07:08.540 --> 02:07:11.420]   especially if the best genetic estimates
[02:07:11.420 --> 02:07:14.220]   of the amount of variance are around 50,
[02:07:14.220 --> 02:07:17.420]   or even if it's as high as 80%,
[02:07:17.420 --> 02:07:21.460]   it still leaves 20% of non-genetic.
[02:07:21.460 --> 02:07:25.580]   Now, maybe that is all luck, maybe that's all chance.
[02:07:25.580 --> 02:07:28.860]   I could believe that, I could easily believe that.
[02:07:28.860 --> 02:07:32.980]   So, but I do think,
[02:07:32.980 --> 02:07:36.500]   after 50 years of trying various interventions,
[02:07:36.500 --> 02:07:40.060]   and nothing works, including memory training,
[02:07:40.060 --> 02:07:41.780]   including listening to Mozart,
[02:07:41.780 --> 02:07:43.940]   including playing computer games,
[02:07:43.940 --> 02:07:46.380]   none of that has shown any impact
[02:07:46.380 --> 02:07:48.980]   on intelligence test scores.
[02:07:48.980 --> 02:07:51.980]   - Is there data on the intelligence,
[02:07:51.980 --> 02:07:56.980]   the IQ of parents as it relates to the children?
[02:07:57.020 --> 02:08:00.020]   - Yes, and there is some genetic evidence
[02:08:00.020 --> 02:08:04.340]   of kind of an interaction
[02:08:04.340 --> 02:08:08.580]   between the parents' IQ and the environment,
[02:08:08.580 --> 02:08:13.240]   high IQ parents provide an enriched environment,
[02:08:13.240 --> 02:08:17.860]   which then can impact the child in addition to the genes,
[02:08:17.860 --> 02:08:19.980]   it's that environment.
[02:08:19.980 --> 02:08:22.140]   So there are all these interactions that,
[02:08:23.860 --> 02:08:25.060]   but it's not, you know,
[02:08:25.060 --> 02:08:28.900]   think about the number of books in a household.
[02:08:28.900 --> 02:08:33.020]   This was a variable that's correlated with IQ, and--
[02:08:33.020 --> 02:08:34.300]   - It is. - Yeah.
[02:08:34.300 --> 02:08:35.580]   Well, why?
[02:08:35.580 --> 02:08:39.680]   Especially if the kid never reads any of the books.
[02:08:39.680 --> 02:08:42.940]   It's because more intelligent people
[02:08:42.940 --> 02:08:45.420]   have more books in their house.
[02:08:45.420 --> 02:08:47.900]   And if you're more intelligent,
[02:08:47.900 --> 02:08:50.200]   and there's a genetic component to that,
[02:08:51.100 --> 02:08:55.140]   the child will get those genes or some of those genes
[02:08:55.140 --> 02:08:57.300]   as well as the environment,
[02:08:57.300 --> 02:09:00.300]   but it's not the number of books in the house
[02:09:00.300 --> 02:09:04.020]   that actually directly impacts the child.
[02:09:04.020 --> 02:09:06.420]   So the two scenarios on this are,
[02:09:06.420 --> 02:09:07.540]   you find that,
[02:09:07.540 --> 02:09:12.940]   and this was used to get rid of the SAT test,
[02:09:12.940 --> 02:09:15.100]   oh, the SAT score is highly correlated
[02:09:15.100 --> 02:09:18.260]   with the social economic status of the parents.
[02:09:18.260 --> 02:09:21.260]   So all you're really measuring is how rich the parents are.
[02:09:21.260 --> 02:09:24.660]   Okay, well, why are the parents rich?
[02:09:24.660 --> 02:09:27.540]   - Yes. - Okay.
[02:09:27.540 --> 02:09:32.540]   And so you could, the opposite kind of syllogism
[02:09:32.540 --> 02:09:37.900]   is that people who are very bright make more money.
[02:09:37.900 --> 02:09:42.300]   They can afford homes in better neighborhoods
[02:09:42.300 --> 02:09:44.500]   so their kids get better schools.
[02:09:44.500 --> 02:09:46.700]   Now, the kids grow up bright.
[02:09:47.620 --> 02:09:50.540]   Where in that chain of events does that come from?
[02:09:50.540 --> 02:09:55.260]   Well, unless you have a genetically informative
[02:09:55.260 --> 02:09:58.940]   research design, where you look at siblings
[02:09:58.940 --> 02:10:02.600]   that have the same biological parents and so on,
[02:10:02.600 --> 02:10:05.460]   you can't really disentangle all that.
[02:10:05.460 --> 02:10:10.460]   Most studies of social economic status and intelligence
[02:10:10.460 --> 02:10:13.900]   do not have a genetically informed design.
[02:10:13.900 --> 02:10:17.660]   So any conclusions they make about the causality
[02:10:17.660 --> 02:10:22.660]   of the social economic status being the cause of the IQ
[02:10:22.660 --> 02:10:25.380]   is a stretch.
[02:10:25.380 --> 02:10:30.000]   And where you do find genetically informative designs,
[02:10:30.000 --> 02:10:35.140]   you find most of the variance in your outcome measures
[02:10:35.140 --> 02:10:38.860]   are due to the genetic component.
[02:10:38.860 --> 02:10:42.100]   And sometimes the SES adds a little,
[02:10:43.300 --> 02:10:46.300]   but the weight of evidence is it doesn't add
[02:10:46.300 --> 02:10:49.280]   very much variance to predict what's going on
[02:10:49.280 --> 02:10:52.620]   beyond the genetic variance.
[02:10:52.620 --> 02:10:56.020]   So when you actually look at it in some,
[02:10:56.020 --> 02:10:57.500]   and there aren't that many studies
[02:10:57.500 --> 02:11:00.140]   that have genetically informed designs,
[02:11:00.140 --> 02:11:02.980]   but when you do see those,
[02:11:02.980 --> 02:11:05.300]   the genes seem to have an advantage.
[02:11:05.300 --> 02:11:06.740]   - Sorry for the strange questions,
[02:11:06.740 --> 02:11:09.660]   but is there a connection between fertility
[02:11:13.100 --> 02:11:17.260]   or the number of kids that you have and G factor?
[02:11:17.260 --> 02:11:19.960]   So you know, the kind of conventional wisdom
[02:11:19.960 --> 02:11:24.960]   is people of, maybe is it higher economic status
[02:11:24.960 --> 02:11:28.620]   or something like that are having fewer children?
[02:11:28.620 --> 02:11:30.880]   I just loosely hear these kinds of things.
[02:11:30.880 --> 02:11:33.100]   Is there data that you're aware of
[02:11:33.100 --> 02:11:35.300]   in one direction or another on this?
[02:11:35.300 --> 02:11:38.980]   - Well, strange questions always get strange answers.
[02:11:38.980 --> 02:11:42.140]   - Yes, all right.
[02:11:42.140 --> 02:11:44.700]   So do you have a strange answer for that strange question?
[02:11:44.700 --> 02:11:48.180]   - The answer is there were some studies
[02:11:48.180 --> 02:11:52.000]   that indicated the more children in a family,
[02:11:52.000 --> 02:11:57.840]   the firstborn children would be more intelligent
[02:11:57.840 --> 02:12:00.620]   than the fourth or fifth or sixth.
[02:12:00.620 --> 02:12:05.220]   It's not clear that those studies hold up over time.
[02:12:05.220 --> 02:12:10.220]   And of course, what you see also is that families
[02:12:10.260 --> 02:12:14.740]   where there are multiple children, four, five, six, seven,
[02:12:14.740 --> 02:12:16.700]   you know, really big families,
[02:12:16.700 --> 02:12:23.640]   the social economic status of those families
[02:12:23.640 --> 02:12:26.720]   usually in the modern age is not that high.
[02:12:26.720 --> 02:12:30.860]   Maybe it used to be the aristocracy
[02:12:30.860 --> 02:12:33.420]   used to have a lot of kids, I'm not sure exactly.
[02:12:33.420 --> 02:12:38.420]   But there have been reports of correlations
[02:12:39.040 --> 02:12:41.600]   between IQ and fertility.
[02:12:41.600 --> 02:12:46.220]   But I'm not sure that the data are very strong
[02:12:46.220 --> 02:12:50.440]   that the firstborn child is always the smartest.
[02:12:50.440 --> 02:12:52.760]   It seems like there's some data to that,
[02:12:52.760 --> 02:12:54.860]   but I'm not current on that.
[02:12:54.860 --> 02:12:56.040]   - How would that be explained?
[02:12:56.040 --> 02:12:58.600]   That would be a nurture.
[02:12:58.600 --> 02:13:00.220]   - Well, it could be nurture.
[02:13:00.220 --> 02:13:03.100]   It could be in uterine environment.
[02:13:03.100 --> 02:13:06.200]   I mean-- - Boy, biology's complicated.
[02:13:06.200 --> 02:13:09.920]   - It's, and this is why this, you know,
[02:13:09.920 --> 02:13:13.220]   like many areas of science, you said earlier
[02:13:13.220 --> 02:13:15.580]   that there are a lot of gray areas
[02:13:15.580 --> 02:13:19.060]   and no definitive answers.
[02:13:19.060 --> 02:13:24.020]   This is not uncommon in science
[02:13:24.020 --> 02:13:27.820]   that the closer you look at a problem,
[02:13:27.820 --> 02:13:32.620]   the more questions you get, not the fewer questions,
[02:13:32.620 --> 02:13:35.660]   because the universe is complicated.
[02:13:35.660 --> 02:13:40.020]   And the idea that we have people on this planet
[02:13:40.020 --> 02:13:43.900]   who can study the first nanoseconds of the Big Bang,
[02:13:43.900 --> 02:13:46.860]   that's pretty amazing.
[02:13:46.860 --> 02:13:50.680]   And I've always said that if they can study
[02:13:50.680 --> 02:13:53.220]   the first nanoseconds of the Big Bang,
[02:13:53.220 --> 02:13:57.100]   we can certainly figure out something about intelligence
[02:13:57.100 --> 02:13:58.900]   that allows that.
[02:13:58.900 --> 02:14:00.940]   - I'm not sure what's more complicated,
[02:14:00.940 --> 02:14:04.720]   the human mind or the physics of the universe.
[02:14:05.560 --> 02:14:07.180]   It's unclear to me.
[02:14:07.180 --> 02:14:10.040]   I think we overemphasize-- - Well, that's a very
[02:14:10.040 --> 02:14:12.920]   humbling statement. (laughs)
[02:14:12.920 --> 02:14:15.740]   - Maybe it's a very human-centric, egotistical statement
[02:14:15.740 --> 02:14:18.000]   that our mind is somehow super complicated,
[02:14:18.000 --> 02:14:21.640]   but biology is a tricky one to unravel.
[02:14:21.640 --> 02:14:25.340]   Consciousness, what is that?
[02:14:25.340 --> 02:14:29.280]   - Well, I've always believed that consciousness
[02:14:29.280 --> 02:14:34.280]   and intelligence are the two real fundamental problems
[02:14:34.800 --> 02:14:35.920]   of the human brain.
[02:14:35.920 --> 02:14:40.640]   And therefore, I think they must be related.
[02:14:40.640 --> 02:14:43.400]   (both laugh)
[02:14:43.400 --> 02:14:46.400]   - Yeah, heart problems like walk together,
[02:14:46.400 --> 02:14:48.960]   holding hands kind of idea.
[02:14:48.960 --> 02:14:52.440]   - You may not know this, but I did some of the early research
[02:14:52.440 --> 02:14:54.800]   on anesthetic drugs with brain imaging,
[02:14:54.800 --> 02:14:57.720]   trying to answer the question, what part of the brain
[02:14:57.720 --> 02:15:01.440]   is the last to turn off when someone loses consciousness?
[02:15:01.440 --> 02:15:04.440]   And is that the first part of the brain to turn on
[02:15:04.440 --> 02:15:06.960]   when consciousness is regained?
[02:15:06.960 --> 02:15:09.080]   And I was working with an anesthesiologist
[02:15:09.080 --> 02:15:11.800]   named Mike Alkire, who's really brilliant at this.
[02:15:11.800 --> 02:15:15.400]   These were really the first studies of brain imaging
[02:15:15.400 --> 02:15:20.400]   using positron emission tomography long before fMRI.
[02:15:20.400 --> 02:15:24.720]   And you would inject a radioactive sugar
[02:15:24.720 --> 02:15:28.880]   that labeled the brain, and the harder the brain was working,
[02:15:28.880 --> 02:15:30.960]   the more sugar it would take up.
[02:15:30.960 --> 02:15:32.240]   And then you could make a picture
[02:15:32.240 --> 02:15:35.060]   of glucose use in the brain.
[02:15:35.060 --> 02:15:38.520]   And he was amazing.
[02:15:38.520 --> 02:15:40.320]   He managed to do this.
[02:15:40.320 --> 02:15:44.400]   In normal volunteers, he brought in an anesthetized
[02:15:44.400 --> 02:15:46.620]   as if they were going into surgery.
[02:15:46.620 --> 02:15:51.480]   And he managed all the human subjects requirements
[02:15:51.480 --> 02:15:53.040]   on this research.
[02:15:53.040 --> 02:15:56.200]   And he was brilliant at this.
[02:15:56.920 --> 02:16:01.920]   And what we did is we had these normal volunteers
[02:16:01.920 --> 02:16:05.000]   come in on three occasions.
[02:16:05.000 --> 02:16:08.640]   On one occasion, he gave them enough anesthetic drug
[02:16:08.640 --> 02:16:13.200]   so they were a little drowsy.
[02:16:13.200 --> 02:16:16.840]   And on another occasion, they came in
[02:16:16.840 --> 02:16:18.640]   and he fully anesthetized them.
[02:16:18.640 --> 02:16:25.160]   And he would say, "Mike, can you hear me?"
[02:16:25.900 --> 02:16:29.960]   And the person would say, "Uh, yeah."
[02:16:29.960 --> 02:16:33.960]   And then we would scan people
[02:16:33.960 --> 02:16:37.480]   and under no anesthetic condition.
[02:16:37.480 --> 02:16:39.480]   So same person.
[02:16:39.480 --> 02:16:43.480]   And we were looking to see if we could see
[02:16:43.480 --> 02:16:46.640]   the part of the brain turn off.
[02:16:46.640 --> 02:16:49.400]   He subsequently tried to do this with fMRI,
[02:16:49.400 --> 02:16:51.680]   which has a faster time resolution.
[02:16:51.680 --> 02:16:55.200]   And you could do it in real time as the person went under
[02:16:55.200 --> 02:16:56.700]   and then regain consciousness,
[02:16:56.700 --> 02:16:57.940]   where you couldn't do that with PET.
[02:16:57.940 --> 02:17:00.340]   You had to have three different occasions.
[02:17:00.340 --> 02:17:03.300]   And the results were absolutely fascinating.
[02:17:03.300 --> 02:17:05.980]   We did this with different anesthetic drugs
[02:17:05.980 --> 02:17:09.680]   and different drugs impacted different parts of the brain.
[02:17:09.680 --> 02:17:13.940]   So we were naturally looking for the common one.
[02:17:13.940 --> 02:17:16.900]   And it seemed to have something to do with the thalamus
[02:17:16.900 --> 02:17:19.460]   and consciousness.
[02:17:19.460 --> 02:17:22.800]   This was actual data on consciousness.
[02:17:23.660 --> 02:17:25.600]   Real, actual consciousness.
[02:17:25.600 --> 02:17:28.280]   - What part of the brain turns on?
[02:17:28.280 --> 02:17:30.740]   What part of the brain turns off?
[02:17:30.740 --> 02:17:32.160]   - It's not so clear.
[02:17:32.160 --> 02:17:35.880]   - But maybe has something to do with the thalamus.
[02:17:35.880 --> 02:17:39.920]   - The sequence of events seemed to have the thalamus in it.
[02:17:39.920 --> 02:17:41.080]   - Boy.
[02:17:41.080 --> 02:17:42.600]   - Now, here's the question.
[02:17:42.600 --> 02:17:45.720]   Are some people more conscious than others?
[02:17:45.720 --> 02:17:49.520]   Are there individual differences in consciousness?
[02:17:49.520 --> 02:17:53.000]   And I don't mean it in the psychedelic sense.
[02:17:53.000 --> 02:17:55.760]   I don't mean it in the political consciousness sense.
[02:17:55.760 --> 02:17:57.260]   I just mean it in everyday life.
[02:17:57.260 --> 02:17:59.460]   Do some people go through everyday life
[02:17:59.460 --> 02:18:01.560]   more conscious than others?
[02:18:01.560 --> 02:18:03.680]   And are those the people we might
[02:18:03.680 --> 02:18:06.040]   actually label more intelligent?
[02:18:06.040 --> 02:18:08.980]   So now, the other thing I was looking for
[02:18:08.980 --> 02:18:11.520]   is whether the parts of the brain we were seeing
[02:18:11.520 --> 02:18:14.560]   in the anesthesia studies were the same parts
[02:18:14.560 --> 02:18:17.780]   of the brain we were seeing in the intelligence studies.
[02:18:17.780 --> 02:18:22.520]   Now, this was very complicated, expensive research.
[02:18:22.520 --> 02:18:24.480]   We didn't really have funding to do this.
[02:18:24.480 --> 02:18:26.400]   We were trying to do it on the fly.
[02:18:26.400 --> 02:18:29.680]   I'm not sure anybody has pursued this.
[02:18:29.680 --> 02:18:31.560]   I'm retired now.
[02:18:31.560 --> 02:18:33.960]   He's gone on to other things.
[02:18:33.960 --> 02:18:36.480]   But I think it's an area of research
[02:18:36.480 --> 02:18:40.200]   that would be fascinating to see the parts.
[02:18:40.200 --> 02:18:43.160]   There are a lot more imaging studies now of consciousness.
[02:18:43.160 --> 02:18:45.120]   I'm just not up on them.
[02:18:45.120 --> 02:18:48.120]   - But basically, the question is which imaging,
[02:18:48.120 --> 02:18:52.360]   so newer imaging studies to see in high-resolution
[02:18:52.360 --> 02:18:55.320]   spatial and temporal way, which part of the brain
[02:18:55.320 --> 02:19:00.200]   lights up when you're doing intelligence tasks?
[02:19:00.200 --> 02:19:02.160]   And which parts of the brain lights up
[02:19:02.160 --> 02:19:03.600]   when you're doing consciousness tasks
[02:19:03.600 --> 02:19:05.800]   and see the interplay between them?
[02:19:05.800 --> 02:19:06.960]   Try to infer.
[02:19:06.960 --> 02:19:09.120]   I mean, that's the challenge of neuroscience.
[02:19:09.120 --> 02:19:14.120]   Without understanding deeply, looking from the outside,
[02:19:14.120 --> 02:19:19.420]   try to infer something about how the whole thing works.
[02:19:19.420 --> 02:19:21.060]   - Well, imagine this.
[02:19:21.060 --> 02:19:23.040]   Here's a simple question.
[02:19:23.040 --> 02:19:25.640]   Does it take more anesthetic drug
[02:19:25.640 --> 02:19:32.480]   to have a person lose consciousness
[02:19:32.480 --> 02:19:37.240]   if their IQ is 140 than a person with an IQ of 70?
[02:19:37.240 --> 02:19:41.320]   - That's an interesting way to study it, yeah.
[02:19:41.320 --> 02:19:46.320]   I mean, if there is a, if the answer to that is a stable yes,
[02:19:46.320 --> 02:19:47.920]   that's very interesting.
[02:19:47.920 --> 02:19:50.200]   - So I tried to find out.
[02:19:50.200 --> 02:19:53.160]   And I went to some anesthesiology textbooks
[02:19:53.160 --> 02:19:55.720]   about how you dose.
[02:19:55.720 --> 02:19:57.040]   And they dose by weight.
[02:19:57.040 --> 02:20:04.200]   And what I also learned, this is a little bit off subject,
[02:20:04.200 --> 02:20:09.880]   anesthesiologists are never sure how deep you are.
[02:20:09.880 --> 02:20:10.720]   - Yeah.
[02:20:10.720 --> 02:20:13.660]   - And they usually tell by poking you with a needle.
[02:20:13.660 --> 02:20:17.120]   And if you don't jump, they tell the surgeon to go ahead.
[02:20:17.120 --> 02:20:20.840]   I'm not sure that's literally true, but it's--
[02:20:20.840 --> 02:20:23.800]   - Well, it might be very difficult to know precisely
[02:20:23.800 --> 02:20:26.320]   how deep you are.
[02:20:26.320 --> 02:20:28.400]   It has to do with the same kind of measurements
[02:20:28.400 --> 02:20:30.500]   that you were doing with the consciousness.
[02:20:30.500 --> 02:20:34.640]   It's difficult to know.
[02:20:34.640 --> 02:20:35.960]   - So I don't lose my train of thought.
[02:20:35.960 --> 02:20:38.100]   I couldn't find in the textbooks anything
[02:20:38.100 --> 02:20:41.000]   about dosing by intelligence.
[02:20:41.000 --> 02:20:43.740]   I asked my friend, the anesthesiologist,
[02:20:43.740 --> 02:20:45.720]   he said, no, he doesn't know.
[02:20:45.720 --> 02:20:47.520]   I said, can we do a chart review
[02:20:47.520 --> 02:20:52.060]   and look at people using their years of education
[02:20:52.060 --> 02:20:54.280]   as a proxy for IQ?
[02:20:54.280 --> 02:20:56.720]   Because if someone's gone to graduate school,
[02:20:56.720 --> 02:20:58.280]   that tells you something.
[02:20:58.280 --> 02:21:00.240]   You can make some inference as opposed to someone
[02:21:00.240 --> 02:21:02.680]   who didn't graduate high school.
[02:21:02.680 --> 02:21:04.360]   Can we do a chart review?
[02:21:04.360 --> 02:21:08.880]   And he says, no, they never really put down the exact dose.
[02:21:08.880 --> 02:21:10.560]   No, he said, no.
[02:21:10.560 --> 02:21:15.560]   So to this day, the simple question,
[02:21:15.560 --> 02:21:19.240]   does it take more anesthetic drug to put someone under
[02:21:19.240 --> 02:21:23.440]   if they have a high IQ or less, or less?
[02:21:23.440 --> 02:21:24.640]   It could go either way.
[02:21:24.640 --> 02:21:27.520]   Because by the way, our early PET scan studies
[02:21:27.520 --> 02:21:32.520]   of intelligence found the unexpected result
[02:21:32.520 --> 02:21:37.360]   of an inverse correlation between glucose metabolic rate
[02:21:37.360 --> 02:21:38.520]   and intelligence.
[02:21:38.520 --> 02:21:41.280]   It wasn't how much a brain area lit up.
[02:21:42.960 --> 02:21:45.920]   How much it lit up was negatively correlated
[02:21:45.920 --> 02:21:47.960]   to how well they did on the test,
[02:21:47.960 --> 02:21:51.120]   which led to the brain efficiency hypothesis,
[02:21:51.120 --> 02:21:53.680]   which is still being studied today.
[02:21:53.680 --> 02:21:57.820]   And there's more and more evidence that the efficiency
[02:21:57.820 --> 02:22:01.360]   of brain information processing is more related
[02:22:01.360 --> 02:22:06.360]   to intelligence than just more activity.
[02:22:06.360 --> 02:22:10.680]   - Yeah, and it'll be interesting, again,
[02:22:10.680 --> 02:22:14.240]   it's a total hypothesis how much the relationship
[02:22:14.240 --> 02:22:17.000]   between intelligence and consciousness,
[02:22:17.000 --> 02:22:19.800]   it's not obvious that those two, if there's correlation,
[02:22:19.800 --> 02:22:24.320]   they could be inversely correlated.
[02:22:24.320 --> 02:22:26.000]   Wouldn't that be funny?
[02:22:26.000 --> 02:22:31.000]   If you, the consciousness factor,
[02:22:31.000 --> 02:22:35.680]   the C factor plus the G factor equals one.
[02:22:35.680 --> 02:22:40.000]   It's a nice trade-off.
[02:22:40.000 --> 02:22:43.080]   - You get a trade-off, how deeply you experience the world
[02:22:43.080 --> 02:22:48.040]   versus how deeply you're able to reason through the world.
[02:22:48.040 --> 02:22:50.360]   - What a great hypothesis.
[02:22:50.360 --> 02:22:53.800]   Certainly somebody listening to this can do this study.
[02:22:53.800 --> 02:22:57.360]   - Even if it's the aliens analyzing humans
[02:22:57.360 --> 02:22:59.080]   a few centuries from now.
[02:22:59.080 --> 02:23:01.140]   Let me ask you from an AI perspective.
[02:23:01.140 --> 02:23:06.800]   I don't know how much you've thought about machines,
[02:23:06.800 --> 02:23:09.680]   but there's the famous Turing test,
[02:23:09.680 --> 02:23:12.600]   test of intelligence for machines,
[02:23:12.600 --> 02:23:17.320]   which is a beautiful, almost like a cute formulation
[02:23:17.320 --> 02:23:22.320]   of intelligence that Alan Turing proposed.
[02:23:22.320 --> 02:23:26.760]   Basically conversation being if you can fool a human
[02:23:26.760 --> 02:23:31.760]   to think that a machine is a human that passes the test.
[02:23:34.960 --> 02:23:39.960]   I suppose you could do a similar thing for humans.
[02:23:39.960 --> 02:23:43.100]   If I can fool you that I'm intelligent,
[02:23:43.100 --> 02:23:46.660]   then that's a good test of intelligence.
[02:23:46.660 --> 02:23:50.180]   You're talking to two people,
[02:23:50.180 --> 02:23:57.880]   and the test is saying who has a higher IQ.
[02:23:57.880 --> 02:24:03.440]   It's an interesting test,
[02:24:03.440 --> 02:24:06.660]   'cause maybe charisma can be very useful there.
[02:24:06.660 --> 02:24:09.200]   You're only allowed to use conversation,
[02:24:09.200 --> 02:24:11.120]   which is the formulation of the Turing test.
[02:24:11.120 --> 02:24:15.000]   Anyway, all that to say is what are good tests
[02:24:15.000 --> 02:24:17.100]   of intelligence for machines?
[02:24:17.100 --> 02:24:20.680]   What do you think it takes to achieve
[02:24:20.680 --> 02:24:23.120]   human-level intelligence for machines?
[02:24:23.120 --> 02:24:25.520]   - Well, I have thought a little bit about this,
[02:24:25.520 --> 02:24:29.920]   but every time I think about these things,
[02:24:29.920 --> 02:24:34.920]   I rapidly reach the limits of my knowledge and imagination.
[02:24:34.920 --> 02:24:40.380]   So when Alexa first came out,
[02:24:40.380 --> 02:24:46.440]   and I think there was a competing one.
[02:24:46.440 --> 02:24:50.440]   Well, there was Siri with Apple, and Google had Alexa.
[02:24:50.440 --> 02:24:52.600]   - No, no, Amazon had Alexa.
[02:24:52.600 --> 02:24:56.400]   - Amazon had Alexa, and Google has something.
[02:24:56.400 --> 02:24:58.420]   So I proposed to one of my colleagues
[02:24:58.420 --> 02:25:02.920]   that he buy one of these, one of each,
[02:25:02.920 --> 02:25:06.180]   and then ask it questions from the IQ test.
[02:25:06.180 --> 02:25:08.800]   - Nice.
[02:25:08.800 --> 02:25:13.800]   - But it became apparent that they all search the internet
[02:25:13.800 --> 02:25:16.880]   so they all can find answers to questions
[02:25:16.880 --> 02:25:21.080]   like how far is it between Washington and Miami,
[02:25:21.080 --> 02:25:22.640]   and repeat after me.
[02:25:22.640 --> 02:25:26.080]   Now, I don't know if you said to Alexa,
[02:25:26.080 --> 02:25:30.420]   I'm going to repeat these numbers backwards to me.
[02:25:30.420 --> 02:25:32.780]   I don't know what would happen, I've never done it.
[02:25:32.780 --> 02:25:36.200]   But so one answer to your question is,
[02:25:36.200 --> 02:25:39.200]   try, you're gonna try it right now, let's try it.
[02:25:39.200 --> 02:25:40.040]   Let's try it.
[02:25:40.040 --> 02:25:41.360]   - No, no, no. - Yes, Siri.
[02:25:41.360 --> 02:25:46.080]   - So it would actually probably go to Google search,
[02:25:46.080 --> 02:25:48.540]   and it would be all confusing kind of stuff.
[02:25:48.540 --> 02:25:50.300]   It would fail.
[02:25:50.300 --> 02:25:54.620]   - Well, then I guess there's a test that it would fail.
[02:25:54.620 --> 02:25:58.280]   - Well, but that's not, that has to do more with the,
[02:25:58.280 --> 02:26:03.620]   you know, the language of communication versus the content.
[02:26:03.620 --> 02:26:06.700]   So if you did an IQ test to a person
[02:26:06.700 --> 02:26:07.700]   who doesn't speak English,
[02:26:07.700 --> 02:26:10.300]   and the test was administered in English,
[02:26:10.300 --> 02:26:11.580]   that's not really the test of--
[02:26:11.580 --> 02:26:13.220]   - Well, let's think about the computers
[02:26:13.220 --> 02:26:15.420]   that beat the Jeopardy champions.
[02:26:15.420 --> 02:26:20.040]   - Yeah, so that, because I happen to know
[02:26:20.040 --> 02:26:22.380]   how those are programmed, those are very hard-coded,
[02:26:22.380 --> 02:26:25.340]   and there's definitely a lack of intelligence there.
[02:26:25.340 --> 02:26:30.340]   There's something like IQ tests.
[02:26:30.340 --> 02:26:35.500]   There's a guy, artificial intelligence researcher,
[02:26:35.500 --> 02:26:38.120]   Francois Chollet, he's at Google,
[02:26:38.120 --> 02:26:40.860]   he's one of the seminal people in machine learning.
[02:26:40.860 --> 02:26:43.820]   He also, as a fun aside thing,
[02:26:43.820 --> 02:26:46.020]   developed an IQ test for machines.
[02:26:46.020 --> 02:26:47.700]   - Oh, I haven't heard that.
[02:26:47.700 --> 02:26:48.780]   I would just like to know about that.
[02:26:48.780 --> 02:26:51.260]   - I'll actually email you this,
[02:26:51.260 --> 02:26:53.260]   'cause it'd be very interesting for you.
[02:26:53.260 --> 02:26:54.480]   It doesn't get much attention,
[02:26:54.480 --> 02:26:57.260]   because people don't know what to do with it.
[02:26:57.260 --> 02:27:00.820]   But it deserves a lot of attention,
[02:27:00.820 --> 02:27:04.640]   which is, it basically does a pattern type of tests,
[02:27:04.640 --> 02:27:09.560]   where you have to do, you know, one standard one is,
[02:27:09.560 --> 02:27:13.500]   you're given three things, and you have to do a fourth one,
[02:27:13.500 --> 02:27:14.340]   that kind of thing.
[02:27:14.340 --> 02:27:16.780]   So you have to understand the pattern here.
[02:27:16.780 --> 02:27:19.920]   And for that, it really simplifies
[02:27:20.860 --> 02:27:21.700]   to,
[02:27:21.700 --> 02:27:26.360]   so the interesting thing is,
[02:27:26.360 --> 02:27:30.740]   he's trying not to achieve high IQ,
[02:27:30.740 --> 02:27:34.980]   he's trying to achieve like pretty low bar for IQ.
[02:27:34.980 --> 02:27:37.640]   Things that are kind of trivial for humans.
[02:27:37.640 --> 02:27:41.900]   And they're actually really tough for machines.
[02:27:41.900 --> 02:27:44.860]   Which is seeing, playing with these concepts
[02:27:44.860 --> 02:27:48.700]   of symmetry, of counting.
[02:27:48.700 --> 02:27:52.140]   Like if I give you one object, two objects, three objects,
[02:27:52.140 --> 02:27:54.740]   you'll know that the last one is four objects,
[02:27:54.740 --> 02:27:56.420]   you can like count them.
[02:27:56.420 --> 02:27:59.080]   You can cluster objects together.
[02:27:59.080 --> 02:28:01.060]   It's both visually and conceptually.
[02:28:01.060 --> 02:28:03.140]   We could do all these things with our mind
[02:28:03.140 --> 02:28:04.740]   that we take for granted.
[02:28:04.740 --> 02:28:07.340]   The objectness of things.
[02:28:07.340 --> 02:28:12.340]   We can like figure out what spatially is an object and isn't.
[02:28:12.340 --> 02:28:15.800]   And we can play with those ideas.
[02:28:17.380 --> 02:28:19.780]   And machines really struggle with that.
[02:28:19.780 --> 02:28:22.720]   So he really cleanly formulated these IQ tests.
[02:28:22.720 --> 02:28:27.060]   I wonder what like that would equate to for humans with IQ.
[02:28:27.060 --> 02:28:28.740]   But it'd be a very low IQ.
[02:28:28.740 --> 02:28:32.940]   But that's exactly the kind of formulation like,
[02:28:32.940 --> 02:28:34.660]   okay, we wanna be able to solve this.
[02:28:34.660 --> 02:28:35.900]   How do we solve this?
[02:28:35.900 --> 02:28:37.140]   And he does this as a challenge,
[02:28:37.140 --> 02:28:38.840]   and nobody's been able to,
[02:28:38.840 --> 02:28:42.060]   it's similar to the Alexa Prize,
[02:28:42.060 --> 02:28:45.620]   which is Amazon is hosting a conversational challenge.
[02:28:45.620 --> 02:28:48.780]   Nobody's been able to do well on his.
[02:28:48.780 --> 02:28:50.900]   But that's an interesting,
[02:28:50.900 --> 02:28:52.620]   those kinds of tests are interesting
[02:28:52.620 --> 02:28:57.420]   'cause we take for granted all the ability of the human mind
[02:28:57.420 --> 02:29:03.420]   to play with concepts and to formulate concepts
[02:29:03.420 --> 02:29:06.960]   out of novel things.
[02:29:06.960 --> 02:29:10.100]   So like things we've never seen before.
[02:29:10.100 --> 02:29:11.820]   We're able to use that.
[02:29:11.820 --> 02:29:14.460]   I mean, that's, I've talked to a few people
[02:29:14.460 --> 02:29:17.180]   that design IQ tests sort of online.
[02:29:17.180 --> 02:29:19.000]   They write IQ tests.
[02:29:19.000 --> 02:29:21.740]   And I was trying to get some questions from them.
[02:29:21.740 --> 02:29:23.900]   And they spoke to the fact that
[02:29:23.900 --> 02:29:25.540]   we can't really share questions with you
[02:29:25.540 --> 02:29:27.940]   because part of the,
[02:29:27.940 --> 02:29:31.580]   like first of all, it's really hard work
[02:29:31.580 --> 02:29:33.460]   to come up with questions.
[02:29:33.460 --> 02:29:34.980]   It's really, really hard work.
[02:29:34.980 --> 02:29:38.300]   It takes a lot of research, but it also takes a lot,
[02:29:38.300 --> 02:29:40.140]   novelty generating.
[02:29:40.140 --> 02:29:44.300]   You're constantly coming up with really new things.
[02:29:44.300 --> 02:29:47.780]   And part of the point is that
[02:29:47.780 --> 02:29:50.020]   they're not supposed to be public.
[02:29:50.020 --> 02:29:53.540]   They're supposed to be new to you when you look at them.
[02:29:53.540 --> 02:29:56.060]   It's interesting that the novelty is fundamental
[02:29:56.060 --> 02:29:57.620]   to the hardness of the problem.
[02:29:57.620 --> 02:30:01.540]   At least a part of what makes the problem hard
[02:30:01.540 --> 02:30:03.100]   is you've never seen it before.
[02:30:03.100 --> 02:30:05.860]   - Right, that's called fluid intelligence
[02:30:05.860 --> 02:30:08.780]   as opposed to what's called crystallized intelligence,
[02:30:08.780 --> 02:30:12.060]   which is your knowledge of facts.
[02:30:12.060 --> 02:30:13.900]   You know things.
[02:30:13.900 --> 02:30:17.540]   But can you use those things to solve a problem?
[02:30:17.540 --> 02:30:19.460]   Those are two different things.
[02:30:19.460 --> 02:30:21.540]   - Do you think we'll be able to,
[02:30:21.540 --> 02:30:22.740]   'cause we spoke,
[02:30:22.740 --> 02:30:25.660]   and I don't wanna miss an opportunity to talk about this,
[02:30:25.660 --> 02:30:27.380]   we spoke about the neurobiology,
[02:30:27.380 --> 02:30:30.260]   about the molecular biology of intelligence.
[02:30:30.260 --> 02:30:33.820]   Do you think one day we'll be able to modify the biology
[02:30:33.820 --> 02:30:39.500]   of, or the genetics of a person
[02:30:39.500 --> 02:30:42.860]   to modify their intelligence,
[02:30:42.860 --> 02:30:43.980]   to increase their intelligence?
[02:30:43.980 --> 02:30:45.100]   We started this conversation
[02:30:45.100 --> 02:30:47.060]   by talking about a pill you could take.
[02:30:47.060 --> 02:30:49.140]   Do you think that such a pill would exist?
[02:30:49.140 --> 02:30:51.300]   - Metaphorically, I do.
[02:30:51.300 --> 02:30:56.180]   And I am supremely confident that it's possible
[02:30:56.180 --> 02:30:58.660]   because I am supremely ignorant
[02:30:58.660 --> 02:31:01.100]   of the complexities of neurobiology.
[02:31:01.100 --> 02:31:02.660]   (Lex laughing)
[02:31:02.660 --> 02:31:03.980]   And so I have written--
[02:31:03.980 --> 02:31:04.940]   - Ignorance is bliss.
[02:31:04.940 --> 02:31:07.340]   - Well, I have written that the nightmares
[02:31:07.340 --> 02:31:09.620]   of neurobiologists,
[02:31:09.620 --> 02:31:11.260]   understanding the complexities,
[02:31:11.260 --> 02:31:16.260]   this cascade of events that happens at the synaptic level,
[02:31:16.260 --> 02:31:24.900]   that these nightmares are what fuel some people to solve.
[02:31:24.900 --> 02:31:28.420]   So some people, you have to be undaunted.
[02:31:28.420 --> 02:31:31.260]   I mean, yeah, this is not easy.
[02:31:31.260 --> 02:31:33.980]   Look, we're still trying to figure out cancer.
[02:31:33.980 --> 02:31:37.900]   It was only recently that they figured out
[02:31:37.900 --> 02:31:39.500]   why aspirin works.
[02:31:41.020 --> 02:31:42.980]   These are not easy problems,
[02:31:42.980 --> 02:31:47.980]   but I also have the perspective of the history of science
[02:31:47.980 --> 02:31:52.980]   is the history of solving problems
[02:31:52.980 --> 02:31:57.540]   that are extraordinarily complex.
[02:31:57.540 --> 02:31:58.740]   - And seem impossible at the time.
[02:31:58.740 --> 02:32:01.020]   - And seem impossible at the time.
[02:32:01.020 --> 02:32:03.900]   - And so one of the things you look at
[02:32:03.900 --> 02:32:06.060]   at companies like Neuralink,
[02:32:06.060 --> 02:32:08.460]   you have brain-computer interfaces,
[02:32:08.460 --> 02:32:10.180]   you start to delve into the human mind
[02:32:10.180 --> 02:32:12.420]   and start to talk about machines measuring,
[02:32:12.420 --> 02:32:14.740]   but also sending signals to the human mind,
[02:32:14.740 --> 02:32:19.740]   you start to wonder what impact that has on the G factor,
[02:32:19.740 --> 02:32:26.740]   modifying in small ways or in large ways the functioning,
[02:32:26.740 --> 02:32:29.860]   the mechanical, electrical,
[02:32:29.860 --> 02:32:34.180]   chemical functioning of the brain.
[02:32:34.180 --> 02:32:37.460]   - I look at everything about the brain.
[02:32:37.460 --> 02:32:39.780]   There are different levels of explanation.
[02:32:39.780 --> 02:32:42.420]   On one hand, you have a behavioral level,
[02:32:42.420 --> 02:32:45.940]   but then you have brain circuitry,
[02:32:45.940 --> 02:32:49.940]   and then you have neurons,
[02:32:49.940 --> 02:32:52.580]   and then you have dendrites,
[02:32:52.580 --> 02:32:55.140]   and then you have synapses,
[02:32:55.140 --> 02:32:59.900]   and then you have the neurotransmitters
[02:32:59.900 --> 02:33:05.740]   and the presynaptic and the postsynaptic terminals.
[02:33:05.740 --> 02:33:07.580]   And then you have all the things
[02:33:07.580 --> 02:33:10.620]   that influence neurotransmitters.
[02:33:10.620 --> 02:33:15.620]   And then you have the individual differences among people.
[02:33:15.620 --> 02:33:18.700]   Yeah, it's complicated,
[02:33:18.700 --> 02:33:23.700]   but 51 million people in the United States
[02:33:23.700 --> 02:33:28.940]   have IQs under 85 and struggle with everyday life.
[02:33:28.940 --> 02:33:36.940]   Shouldn't that motivate people to take a look at this?
[02:33:36.940 --> 02:33:39.540]   - Yeah, and to treat it seriously.
[02:33:39.540 --> 02:33:42.860]   Yeah, but I just want to linger one more time
[02:33:42.860 --> 02:33:47.340]   that we have to remember that the science of intelligence,
[02:33:47.340 --> 02:33:52.020]   the measure of intelligence
[02:33:52.020 --> 02:33:54.660]   is only a part of the human condition.
[02:33:54.660 --> 02:33:56.420]   The thing that makes life beautiful
[02:33:56.420 --> 02:33:59.260]   and the creation of beautiful things in this world
[02:33:59.260 --> 02:34:04.260]   is perhaps loosely correlated,
[02:34:04.380 --> 02:34:08.740]   but it's not dependent entirely on intelligence.
[02:34:08.740 --> 02:34:12.060]   - Absolutely, I certainly agree with that.
[02:34:12.060 --> 02:34:15.580]   - So for anyone sort of listening,
[02:34:15.580 --> 02:34:18.020]   I'm still not convinced that
[02:34:18.020 --> 02:34:23.140]   more intelligence is always better
[02:34:23.140 --> 02:34:26.060]   if you want to create beauty in this world.
[02:34:26.060 --> 02:34:27.180]   I don't know.
[02:34:27.180 --> 02:34:29.860]   - Well, I didn't say more intelligence is always better
[02:34:29.860 --> 02:34:31.340]   if you want to create beauty.
[02:34:31.340 --> 02:34:34.340]   I just said all things being equal,
[02:34:34.340 --> 02:34:36.380]   more is better than less.
[02:34:36.380 --> 02:34:37.420]   That's all I mean.
[02:34:37.420 --> 02:34:40.820]   - Yeah, but that's sort of that I just want to sort of say,
[02:34:40.820 --> 02:34:45.820]   'cause to me, one of the things that makes life great
[02:34:45.820 --> 02:34:48.620]   is the opportunity to create beautiful things,
[02:34:48.620 --> 02:34:52.860]   and so I just want to sort of empower people to do that
[02:34:52.860 --> 02:34:56.300]   no matter what some IQ test says.
[02:34:56.300 --> 02:34:57.580]   At the population level,
[02:34:57.580 --> 02:35:01.460]   we do need to look at IQ tests to help people.
[02:35:01.460 --> 02:35:02.980]   And to also inspire us, yeah,
[02:35:03.540 --> 02:35:04.380]   to take on some of these
[02:35:04.380 --> 02:35:07.820]   extremely difficult scientific questions.
[02:35:07.820 --> 02:35:12.460]   Do you have advice for young people in high school,
[02:35:12.460 --> 02:35:17.460]   in college, whether they're thinking about career
[02:35:17.460 --> 02:35:20.660]   or they're thinking about a life they can be proud of?
[02:35:20.660 --> 02:35:22.240]   Is there advice you can give?
[02:35:22.240 --> 02:35:28.860]   Whether they want to pursue psychology or biology
[02:35:28.860 --> 02:35:30.980]   or engineering, or they want to be artists
[02:35:30.980 --> 02:35:33.700]   and musicians and poets.
[02:35:33.700 --> 02:35:37.620]   - I can't advise anybody on that level
[02:35:37.620 --> 02:35:40.140]   of what their passion is. - Poetry.
[02:35:40.140 --> 02:35:45.500]   - But I can say if you're interested in psychology,
[02:35:45.500 --> 02:35:47.860]   if you're interested in science,
[02:35:47.860 --> 02:35:52.860]   and the science around the big questions
[02:35:52.860 --> 02:35:58.580]   of consciousness and intelligence and psychiatric illness,
[02:36:00.180 --> 02:36:03.820]   we haven't really talked about brain illnesses
[02:36:03.820 --> 02:36:05.900]   and what we might learn from,
[02:36:05.900 --> 02:36:08.980]   if you are trying to develop a drug
[02:36:08.980 --> 02:36:11.020]   to treat Alzheimer's disease,
[02:36:11.020 --> 02:36:13.540]   you are trying to develop a drug
[02:36:13.540 --> 02:36:17.480]   to impact learning and memory,
[02:36:17.480 --> 02:36:20.300]   which are core to intelligence.
[02:36:20.300 --> 02:36:23.660]   So it could well be that the so-called IQ pill
[02:36:23.660 --> 02:36:26.220]   will come from a pharmaceutical company
[02:36:26.220 --> 02:36:29.220]   trying to develop a drug for Alzheimer's disease.
[02:36:29.220 --> 02:36:31.380]   - Because that's exactly what you're trying to do, right?
[02:36:31.380 --> 02:36:34.700]   Yeah, just like you said. - Well, what will that drug do
[02:36:34.700 --> 02:36:38.340]   in a college student that doesn't have Alzheimer's disease?
[02:36:38.340 --> 02:36:43.340]   So I would encourage people who are interested in psychology,
[02:36:43.340 --> 02:36:47.660]   who are interested in science,
[02:36:47.660 --> 02:36:52.100]   to pursue a scientific career
[02:36:52.100 --> 02:36:54.020]   and address the big questions.
[02:36:55.140 --> 02:36:59.700]   And the most important thing I can tell you,
[02:36:59.700 --> 02:37:04.340]   if you're gonna be in kind of a research environment,
[02:37:04.340 --> 02:37:07.380]   is you gotta follow the data where the data take you.
[02:37:07.380 --> 02:37:10.340]   You can't decide in advance where you want the data to go.
[02:37:10.340 --> 02:37:12.420]   And if the data take you to places
[02:37:12.420 --> 02:37:16.180]   that you don't have the technical expertise to follow,
[02:37:16.180 --> 02:37:19.540]   like I would like to understand more
[02:37:19.540 --> 02:37:21.480]   about molecular biology,
[02:37:21.480 --> 02:37:24.820]   but I'm not gonna become a molecular biologist now,
[02:37:24.820 --> 02:37:27.020]   but I know people who are.
[02:37:27.020 --> 02:37:29.460]   And my job is to get them interested
[02:37:29.460 --> 02:37:32.620]   to take their expertise into this direction.
[02:37:32.620 --> 02:37:36.420]   And it's not so easy, but...
[02:37:36.420 --> 02:37:39.100]   - And if the data takes you to a place
[02:37:39.100 --> 02:37:42.760]   that's controversial, that's counterintuitive in this world,
[02:37:42.760 --> 02:37:49.140]   no, I would say it's probably a good idea
[02:37:49.140 --> 02:37:52.140]   to still push forward boldly,
[02:37:52.140 --> 02:37:56.380]   but to communicate the interpretation of the results
[02:37:56.380 --> 02:37:58.960]   with skill, with compassion,
[02:37:58.960 --> 02:38:04.780]   with a greater breadth of understanding of humanity,
[02:38:04.780 --> 02:38:08.760]   not just the science, of the impact of the results.
[02:38:08.760 --> 02:38:12.360]   - One famous psychologist wrote about this issue,
[02:38:12.360 --> 02:38:15.960]   that somehow a balance has to be found
[02:38:15.960 --> 02:38:19.940]   between pursuing the science and communicating it
[02:38:19.940 --> 02:38:22.000]   with respect to people's sensitivities.
[02:38:22.000 --> 02:38:24.580]   The legitimate sensitivities.
[02:38:24.580 --> 02:38:27.400]   Somehow, he didn't say how.
[02:38:27.400 --> 02:38:28.740]   - Somehow. - Somehow.
[02:38:28.740 --> 02:38:30.380]   And this is-- - Every part of that sentence,
[02:38:30.380 --> 02:38:34.960]   somehow, and balance is left up
[02:38:34.960 --> 02:38:37.380]   to the interpretation of the reader.
[02:38:37.380 --> 02:38:39.420]   Let me ask you, you said big questions,
[02:38:39.420 --> 02:38:42.440]   the biggest, or one of the biggest.
[02:38:42.440 --> 02:38:46.380]   We already talked about consciousness and intelligence,
[02:38:46.380 --> 02:38:48.420]   one of the most fascinating, one of the biggest questions,
[02:38:48.420 --> 02:38:51.260]   but let's talk about the why.
[02:38:51.260 --> 02:38:53.220]   Why are we here?
[02:38:53.220 --> 02:38:55.200]   What's the meaning of life?
[02:38:55.200 --> 02:38:56.980]   - Oh, I'm not gonna tell you.
[02:38:56.980 --> 02:38:58.980]   - You know, but you're not gonna tell me?
[02:38:58.980 --> 02:39:03.380]   This is very, I'm gonna have to wait for your next book.
[02:39:03.380 --> 02:39:05.540]   - The meaning of life, you know,
[02:39:05.540 --> 02:39:09.480]   we do the best we can to get through the day.
[02:39:09.480 --> 02:39:15.380]   - And then there's just the finite number of the days.
[02:39:15.380 --> 02:39:18.060]   Are you afraid of the finiteness of it?
[02:39:18.060 --> 02:39:19.140]   You think about your death? - I think about it
[02:39:19.140 --> 02:39:21.180]   more and more as I get older.
[02:39:21.180 --> 02:39:22.500]   - Yeah, I do.
[02:39:22.500 --> 02:39:26.100]   And it's one of these human things,
[02:39:26.100 --> 02:39:28.400]   that it is finite, we all know it.
[02:39:28.400 --> 02:39:35.300]   Most of us deny it and don't wanna think about it.
[02:39:35.300 --> 02:39:39.340]   Sometimes you think about it in terms of estate planning,
[02:39:39.340 --> 02:39:41.780]   you try to do the rational thing.
[02:39:41.780 --> 02:39:44.580]   Sometimes it makes you work harder
[02:39:44.580 --> 02:39:46.900]   'cause you know your time is more and more limited
[02:39:46.900 --> 02:39:48.560]   and you wanna get things done.
[02:39:50.740 --> 02:39:53.500]   I don't know where I am on that.
[02:39:53.500 --> 02:39:57.260]   It is just one of those things
[02:39:57.260 --> 02:39:59.660]   that's always in the back of my mind.
[02:39:59.660 --> 02:40:03.120]   And I don't think that's uncommon.
[02:40:03.120 --> 02:40:06.100]   - Well, it's just like G-factor intelligence,
[02:40:06.100 --> 02:40:09.300]   it's a hard truth that's there.
[02:40:09.300 --> 02:40:12.300]   And sometimes you kinda walk past it
[02:40:12.300 --> 02:40:15.300]   and you don't wanna look at it, but it's still there.
[02:40:15.300 --> 02:40:19.660]   - Yeah, yes, you can't escape it.
[02:40:19.660 --> 02:40:22.780]   And the thing about the G-factor intelligence
[02:40:22.780 --> 02:40:27.780]   is everybody knows this is true on a personal daily basis.
[02:40:27.780 --> 02:40:33.720]   Even if you think back to when you were in school,
[02:40:33.720 --> 02:40:36.760]   you know who the smart kids were.
[02:40:36.760 --> 02:40:40.860]   When you are on the phone talking
[02:40:40.860 --> 02:40:43.660]   to a customer service representative
[02:40:43.660 --> 02:40:46.700]   that in response to your detailed question
[02:40:46.700 --> 02:40:49.300]   is reading a script back to you
[02:40:49.300 --> 02:40:51.420]   and you get furious at this.
[02:40:51.420 --> 02:40:54.740]   Have you ever called this person a moron
[02:40:54.740 --> 02:40:56.820]   or wanted to call this person a moron?
[02:40:56.820 --> 02:40:58.340]   You're not listening to me.
[02:40:58.340 --> 02:41:01.380]   Everybody has had the experience of dealing with people
[02:41:01.380 --> 02:41:03.840]   who they think are not at their level.
[02:41:03.840 --> 02:41:09.180]   It's just common because that's the way human beings are.
[02:41:09.180 --> 02:41:11.020]   That's the way life is.
[02:41:11.020 --> 02:41:15.360]   - But we also have a poor estimation
[02:41:15.360 --> 02:41:16.620]   of our own intelligence.
[02:41:16.620 --> 02:41:19.220]   We have a poor, we're not always a great,
[02:41:19.220 --> 02:41:22.980]   our judgment of human character of other people
[02:41:22.980 --> 02:41:26.420]   is not as good as a battery of tests.
[02:41:26.420 --> 02:41:31.260]   That's where bias comes in.
[02:41:31.260 --> 02:41:34.820]   That's where our history, our emotions,
[02:41:34.820 --> 02:41:35.740]   all of that comes in.
[02:41:35.740 --> 02:41:37.940]   So people on the internet,
[02:41:37.940 --> 02:41:39.900]   there's such a thing as the internet
[02:41:39.900 --> 02:41:42.580]   and people on the internet will call each other dumb
[02:41:42.580 --> 02:41:43.420]   all the time.
[02:41:43.420 --> 02:41:48.420]   And that's the worry here
[02:41:48.420 --> 02:41:52.980]   is that we give up on people.
[02:41:52.980 --> 02:41:56.700]   We put them in a bin just because of one interaction
[02:41:56.700 --> 02:41:59.380]   or some small number of interactions
[02:41:59.380 --> 02:42:01.900]   as if that's it, they're hopeless.
[02:42:01.900 --> 02:42:03.440]   That's just in their genetics.
[02:42:03.440 --> 02:42:07.980]   But I think no matter what the science here says,
[02:42:07.980 --> 02:42:12.820]   once again, that does not mean we should not have compassion
[02:42:12.820 --> 02:42:14.860]   for our fellow man.
[02:42:14.860 --> 02:42:17.540]   - That's exactly what the science does say.
[02:42:17.540 --> 02:42:22.060]   It's not opposite of what the science says.
[02:42:22.060 --> 02:42:25.020]   Everything I know about psychology,
[02:42:25.020 --> 02:42:28.660]   everything I've learned about intelligence,
[02:42:28.660 --> 02:42:32.680]   everything points to the inexorable conclusion
[02:42:32.680 --> 02:42:37.680]   that you have to treat people as individuals respectfully
[02:42:37.680 --> 02:42:42.180]   and with compassion because through no fault of their own,
[02:42:42.180 --> 02:42:45.120]   some people are not as capable as others.
[02:42:45.120 --> 02:42:48.620]   And you wanna turn a blind eye to it,
[02:42:48.620 --> 02:42:51.500]   you wanna come up with theories
[02:42:51.500 --> 02:42:54.300]   about why that might be true, fine.
[02:42:54.300 --> 02:42:57.900]   I would like to fix some of it as best I can.
[02:42:57.900 --> 02:43:02.140]   - And everybody is deserving of love.
[02:43:02.140 --> 02:43:06.020]   Richard, this is a good way to end it, I think.
[02:43:06.020 --> 02:43:07.540]   - I'm just getting warmed up here, wasn't I?
[02:43:07.540 --> 02:43:08.380]   - I know.
[02:43:08.380 --> 02:43:11.820]   I know you can go for another many hours,
[02:43:11.820 --> 02:43:15.180]   but to respect your extremely valuable time,
[02:43:15.180 --> 02:43:16.620]   this was an amazing conversation.
[02:43:16.620 --> 02:43:19.980]   Thank you for the teaching company,
[02:43:19.980 --> 02:43:22.340]   the lectures you've given
[02:43:22.340 --> 02:43:24.460]   with the New York Science of Intelligence,
[02:43:24.460 --> 02:43:25.900]   just the work you're doing.
[02:43:25.900 --> 02:43:28.060]   It's a difficult topic,
[02:43:28.060 --> 02:43:31.380]   it's a topic that's controversial and sensitive to people,
[02:43:31.380 --> 02:43:35.060]   and to push forward boldly and in that nuanced way,
[02:43:35.060 --> 02:43:36.840]   just thank you for everything you do.
[02:43:36.840 --> 02:43:39.420]   And thank you for asking the big questions
[02:43:39.420 --> 02:43:42.140]   of intelligence, of consciousness.
[02:43:42.140 --> 02:43:43.460]   - Well, thank you for asking me.
[02:43:43.460 --> 02:43:45.540]   I mean, there's nothing like good conversation
[02:43:45.540 --> 02:43:46.620]   on these topics.
[02:43:46.620 --> 02:43:48.980]   - Thanks for listening to this conversation
[02:43:48.980 --> 02:43:50.380]   with Richard Heyer.
[02:43:50.380 --> 02:43:51.500]   To support this podcast,
[02:43:51.500 --> 02:43:54.380]   please check out our sponsors in the description.
[02:43:54.380 --> 02:43:56.220]   And now, let me leave you with some words
[02:43:56.220 --> 02:43:58.260]   from Albert Einstein.
[02:43:58.260 --> 02:44:00.540]   "It is not that I'm so smart,
[02:44:00.540 --> 02:44:03.340]   "but I stay with the questions much longer."
[02:44:03.340 --> 02:44:07.260]   Thank you for listening, and hope to see you next time.
[02:44:07.260 --> 02:44:09.840]   (upbeat music)
[02:44:09.840 --> 02:44:12.420]   (upbeat music)
[02:44:12.420 --> 02:44:22.420]   [BLANK_AUDIO]

