
[00:00:00.000 --> 00:00:03.200]   [MUSIC PLAYING]
[00:00:03.200 --> 00:00:06.760]   I'm excited to introduce our first speaker, Arthur
[00:00:06.760 --> 00:00:08.200]   from Mistral.
[00:00:08.200 --> 00:00:11.440]   Arthur is the founder and CEO of Mistral AI.
[00:00:11.440 --> 00:00:14.880]   Despite just being nine months old as a company
[00:00:14.880 --> 00:00:17.600]   and having many fewer resources than some
[00:00:17.600 --> 00:00:20.040]   of the large foundation model companies so far,
[00:00:20.040 --> 00:00:22.360]   I think they've really shocked everybody by putting out
[00:00:22.360 --> 00:00:26.000]   incredibly high quality models approaching GPT-4 and Calibre
[00:00:26.000 --> 00:00:26.800]   out into the open.
[00:00:26.800 --> 00:00:29.400]   So we're thrilled to have Arthur with us today,
[00:00:29.400 --> 00:00:30.880]   all the way from France, to share
[00:00:30.880 --> 00:00:35.160]   more about the opportunity behind building an open source.
[00:00:35.160 --> 00:00:38.440]   And please-- interviewing Arthur will be my partner,
[00:00:38.440 --> 00:00:41.400]   Matt Miller, who is dressed in his best French wear
[00:00:41.400 --> 00:00:46.220]   to honor Arthur today and helps lead our efforts in Europe.
[00:00:46.220 --> 00:00:48.320]   So please welcome Matt and Arthur.
[00:00:48.320 --> 00:00:53.640]   [APPLAUSE]
[00:00:53.640 --> 00:00:56.520]   With all the efficiency of a French train, right?
[00:00:56.520 --> 00:00:57.680]   Just--
[00:00:57.680 --> 00:00:58.400]   Right on time.
[00:00:58.400 --> 00:00:59.040]   Right on time.
[00:00:59.040 --> 00:01:00.720]   We were sweating a little bit back there
[00:01:00.720 --> 00:01:03.040]   because you just walked in the door.
[00:01:03.040 --> 00:01:03.840]   But good to see you.
[00:01:03.840 --> 00:01:05.360]   Thanks for coming all this way.
[00:01:05.360 --> 00:01:08.040]   Thanks for being with us here at AISN today.
[00:01:08.040 --> 00:01:09.760]   Thank you for hosting us.
[00:01:09.760 --> 00:01:11.120]   Yeah, absolutely.
[00:01:11.120 --> 00:01:13.480]   We'd love to maybe start with the background
[00:01:13.480 --> 00:01:17.480]   story of why you chose to start Mistral.
[00:01:17.480 --> 00:01:20.440]   And maybe just take us to the beginning.
[00:01:20.440 --> 00:01:22.640]   We all know about your successful career
[00:01:22.640 --> 00:01:25.920]   at DeepMind, your work on the Chinchilla paper.
[00:01:25.920 --> 00:01:27.560]   Tell us, maybe share with us-- we always
[00:01:27.560 --> 00:01:30.140]   love to hear at Sequoia, and I know that our founder community
[00:01:30.140 --> 00:01:32.160]   also loves to hear that spark that gave you
[00:01:32.160 --> 00:01:35.320]   the idea to launch and to start to break out and start
[00:01:35.320 --> 00:01:36.480]   your own company.
[00:01:36.480 --> 00:01:37.880]   Yeah, sure.
[00:01:37.880 --> 00:01:39.760]   So we started the company in April,
[00:01:39.760 --> 00:01:42.920]   but I guess the idea was out there for a couple of months
[00:01:42.920 --> 00:01:44.680]   before.
[00:01:44.680 --> 00:01:46.840]   TimothÃ©e and I were in master together.
[00:01:46.840 --> 00:01:48.480]   Guillaume and I were in school together.
[00:01:48.480 --> 00:01:50.120]   So we knew each other from before.
[00:01:50.120 --> 00:01:55.480]   And we had been in the field for 10 years doing research.
[00:01:55.480 --> 00:01:57.880]   And so we loved the way AI progressed
[00:01:57.880 --> 00:01:59.840]   because of the open exchanges that
[00:01:59.840 --> 00:02:03.960]   occurred between academic labs, industrial labs,
[00:02:03.960 --> 00:02:08.280]   and how everybody was able to build on top of one another.
[00:02:08.280 --> 00:02:11.720]   And it was still the case, I guess,
[00:02:11.720 --> 00:02:13.720]   even in the beginning of the LLM era,
[00:02:13.720 --> 00:02:19.120]   where OpenAI and DeepMind were actually
[00:02:19.120 --> 00:02:23.360]   contributing to one another roadmap.
[00:02:23.360 --> 00:02:26.000]   And this kind of stopped in 2022.
[00:02:26.000 --> 00:02:29.040]   So basically, one of the last papers
[00:02:29.040 --> 00:02:31.480]   doing important changes to the way we train models
[00:02:31.480 --> 00:02:32.360]   was Chinchilla.
[00:02:32.360 --> 00:02:35.080]   And that was the last model that Google ever
[00:02:35.080 --> 00:02:38.280]   published, last important model in the field
[00:02:38.280 --> 00:02:39.760]   that Google published.
[00:02:39.760 --> 00:02:42.560]   And so for us, it was a bit of a shame
[00:02:42.560 --> 00:02:48.120]   that the field stopped doing open contributions
[00:02:48.120 --> 00:02:50.180]   that early in the AI journey because we were very
[00:02:50.180 --> 00:02:53.160]   far away from finishing it.
[00:02:53.160 --> 00:02:56.800]   And so when we saw Chad GPT at the end of the year--
[00:02:56.800 --> 00:03:00.480]   and I think we reflected on the fact
[00:03:00.480 --> 00:03:03.160]   that there was some opportunity for doing things differently,
[00:03:03.160 --> 00:03:04.840]   for doing things from France.
[00:03:04.840 --> 00:03:07.320]   Because in France, as it turned out,
[00:03:07.320 --> 00:03:09.320]   there was a lot of talented people
[00:03:09.320 --> 00:03:12.400]   that were a bit bored in big tech companies.
[00:03:12.400 --> 00:03:14.600]   And so that's how we figured out that there
[00:03:14.600 --> 00:03:17.800]   was an opportunity for building very strong open source
[00:03:17.800 --> 00:03:22.600]   models, going very fast with a lean team of experienced people,
[00:03:22.600 --> 00:03:27.280]   and try to correct the direction that the field was taking.
[00:03:27.280 --> 00:03:31.520]   So we wanted to push the open source models much more.
[00:03:31.520 --> 00:03:33.060]   And I think we did a good job at that
[00:03:33.060 --> 00:03:36.720]   because we've been followed by various companies
[00:03:36.720 --> 00:03:38.720]   in our trajectory.
[00:03:38.720 --> 00:03:39.360]   Wonderful.
[00:03:39.360 --> 00:03:42.000]   And so it was really a lot of the open source movement
[00:03:42.000 --> 00:03:45.440]   was a lot of the drive behind starting the company.
[00:03:45.440 --> 00:03:50.480]   Yeah, that was one of the driver--
[00:03:50.480 --> 00:03:52.720]   our intention and the mission that we gave ourselves
[00:03:52.720 --> 00:03:55.800]   is really to bring AI to the hands of every developer.
[00:03:55.800 --> 00:03:57.280]   And the way it was done and the way
[00:03:57.280 --> 00:04:00.400]   it is still done by our competitors is very close.
[00:04:00.400 --> 00:04:03.120]   And so we want to push a much more open platform.
[00:04:03.120 --> 00:04:04.680]   And we want to spread the adoption
[00:04:04.680 --> 00:04:07.680]   and accelerate the adoption through that strategy.
[00:04:07.680 --> 00:04:11.760]   So that's very much at the core--
[00:04:11.760 --> 00:04:13.920]   the reason why we started the company.
[00:04:13.920 --> 00:04:14.720]   Wonderful.
[00:04:14.720 --> 00:04:18.200]   And just recently, I mean, fast forward to today,
[00:04:18.200 --> 00:04:19.520]   you released Mistral Large.
[00:04:19.520 --> 00:04:22.120]   You've been on this tear of amazing partnerships
[00:04:22.120 --> 00:04:25.120]   with Microsoft, Snowflake, Databricks, announcers.
[00:04:25.120 --> 00:04:27.540]   So how do you balance what you're
[00:04:27.540 --> 00:04:29.200]   going to do open source with what you're
[00:04:29.200 --> 00:04:30.280]   going to do commercially?
[00:04:30.280 --> 00:04:33.160]   And how you're going to think about the trade-off?
[00:04:33.160 --> 00:04:35.640]   Because that's something that many open source companies
[00:04:35.640 --> 00:04:36.560]   contend with.
[00:04:36.560 --> 00:04:38.320]   How do they keep their community thriving?
[00:04:38.320 --> 00:04:40.120]   But then how do they also build a successful business
[00:04:40.120 --> 00:04:41.840]   to contribute to their community?
[00:04:41.840 --> 00:04:43.200]   Yeah, it's a hard question.
[00:04:43.200 --> 00:04:45.040]   And the way we've addressed it is currently
[00:04:45.040 --> 00:04:46.880]   through two families of model.
[00:04:46.880 --> 00:04:49.320]   But this might evolve with time.
[00:04:49.320 --> 00:04:51.160]   We intend to stay the leader in open source.
[00:04:51.160 --> 00:04:54.320]   So that kind of puts a pressure on the open source family,
[00:04:54.320 --> 00:04:58.840]   because there's obviously some contenders out there.
[00:04:58.840 --> 00:05:02.280]   I think compared to how various software providers playing
[00:05:02.280 --> 00:05:06.200]   this strategy developed, we need to go faster.
[00:05:06.200 --> 00:05:08.240]   Because AI develops actually faster than software.
[00:05:08.240 --> 00:05:10.560]   It develops faster than databases.
[00:05:10.560 --> 00:05:12.480]   MongoDB played a very good game at that.
[00:05:12.480 --> 00:05:16.480]   And this is a good example of what we could do.
[00:05:16.480 --> 00:05:17.880]   But we need to adapt faster.
[00:05:17.880 --> 00:05:21.080]   So yeah, there's obviously this tension.
[00:05:21.080 --> 00:05:23.880]   And we are constantly thinking on how we should contribute
[00:05:23.880 --> 00:05:27.720]   to the community, but also how we should show and start
[00:05:27.720 --> 00:05:31.000]   getting some commercial adoption, enterprise deals,
[00:05:31.000 --> 00:05:31.520]   et cetera.
[00:05:31.520 --> 00:05:34.160]   And there's obviously a tension.
[00:05:34.160 --> 00:05:36.600]   And for now, I think we've done a good job at doing it.
[00:05:36.600 --> 00:05:39.960]   But it's a very dynamic thing to think through.
[00:05:39.960 --> 00:05:41.560]   So it's basically every week we think
[00:05:41.560 --> 00:05:44.720]   of what we should release next on both families.
[00:05:44.720 --> 00:05:48.600]   And you have been the fastest in developing models,
[00:05:48.600 --> 00:05:51.800]   fastest reaching different benchmarking levels,
[00:05:51.800 --> 00:05:54.560]   one of the most leanest in amount of expenditure
[00:05:54.560 --> 00:05:58.640]   to reach these benchmarks out of any of the foundational model
[00:05:58.640 --> 00:05:59.160]   companies.
[00:05:59.160 --> 00:06:01.640]   What do you think is giving you that advantage
[00:06:01.640 --> 00:06:05.040]   to move quicker than your predecessors
[00:06:05.040 --> 00:06:06.240]   and more efficiently?
[00:06:06.240 --> 00:06:12.200]   I think we like to get our hands dirty.
[00:06:12.200 --> 00:06:15.820]   Machine learning has always been about crunching numbers,
[00:06:15.820 --> 00:06:19.600]   looking at your data, doing a lot of extract, transform,
[00:06:19.600 --> 00:06:23.440]   and load, and things that are oftentimes not fascinating.
[00:06:23.440 --> 00:06:27.800]   And so we hire people that were willing to do that stuff.
[00:06:27.800 --> 00:06:32.240]   And I think that has been critical to our speed.
[00:06:32.240 --> 00:06:34.520]   And that's something that we want to keep up.
[00:06:34.520 --> 00:06:35.440]   Awesome.
[00:06:35.440 --> 00:06:37.900]   And in addition to the large model,
[00:06:37.900 --> 00:06:39.360]   you also have several small models
[00:06:39.360 --> 00:06:41.200]   that are extremely popular.
[00:06:41.200 --> 00:06:43.320]   When would you tell people that they should spend their time
[00:06:43.320 --> 00:06:44.680]   working with you on the small models?
[00:06:44.680 --> 00:06:46.520]   When would you tell them working on the large models?
[00:06:46.520 --> 00:06:48.840]   And where do you think the economic opportunity
[00:06:48.840 --> 00:06:49.840]   for Mistral lies?
[00:06:49.840 --> 00:06:53.920]   Is it in doing more of the big or doing more of the small?
[00:06:53.920 --> 00:06:56.560]   And I think this is an observation
[00:06:56.560 --> 00:06:59.640]   that every LLM provider has made,
[00:06:59.640 --> 00:07:02.800]   that one size does not fit all.
[00:07:02.800 --> 00:07:06.000]   And depending on what you want to--
[00:07:06.000 --> 00:07:07.840]   when you make an application, you typically
[00:07:07.840 --> 00:07:10.220]   have different large language model calls.
[00:07:10.220 --> 00:07:12.400]   And some should be low latency, because they don't
[00:07:12.400 --> 00:07:13.680]   require a lot of intelligence.
[00:07:13.680 --> 00:07:15.140]   But some should be higher latency
[00:07:15.140 --> 00:07:16.820]   and require more intelligence.
[00:07:16.820 --> 00:07:20.040]   And an efficient application should leverage both of them,
[00:07:20.040 --> 00:07:23.200]   potentially using the large models as an orchestrator
[00:07:23.200 --> 00:07:25.480]   for the small ones.
[00:07:25.480 --> 00:07:27.160]   And I think the challenge here is,
[00:07:27.160 --> 00:07:28.880]   how do you make sure that everything works?
[00:07:28.880 --> 00:07:31.580]   So you end up with a system that is not only a model,
[00:07:31.580 --> 00:07:33.720]   but it's really two models plus an outer loop
[00:07:33.720 --> 00:07:37.440]   of calling your model, calling systems, calling functions.
[00:07:37.440 --> 00:07:40.900]   And I think some of the developer challenges
[00:07:40.900 --> 00:07:43.580]   that we also want to address is, how do you
[00:07:43.580 --> 00:07:46.340]   make sure that this works, that you can evaluate it properly?
[00:07:46.340 --> 00:07:48.940]   How do you make sure that you can do continuous integration?
[00:07:48.940 --> 00:07:50.520]   How do you change--
[00:07:50.520 --> 00:07:52.720]   how do you move from one version to another of a model
[00:07:52.720 --> 00:07:54.820]   and make sure that your application has actually
[00:07:54.820 --> 00:07:56.860]   improved and not deteriorated?
[00:07:56.860 --> 00:08:00.140]   So all of these things are addressed by various companies.
[00:08:00.140 --> 00:08:01.900]   But these are also things that we
[00:08:01.900 --> 00:08:04.980]   think should be core to our value proposition.
[00:08:04.980 --> 00:08:07.420]   And what are some of the most exciting things
[00:08:07.420 --> 00:08:08.800]   you see being built on Mistral?
[00:08:08.800 --> 00:08:11.040]   What are the things that you get really excited about,
[00:08:11.040 --> 00:08:13.280]   that you see the community doing or customers doing?
[00:08:13.280 --> 00:08:17.000]   I think pretty much every young startup in the Bay Area
[00:08:17.000 --> 00:08:20.400]   has been using it for fine-tuning purposes,
[00:08:20.400 --> 00:08:22.720]   for fast application making.
[00:08:22.720 --> 00:08:26.240]   So really, I think part of the value of Mistral, for instance,
[00:08:26.240 --> 00:08:27.240]   is that it's very fast.
[00:08:27.240 --> 00:08:31.240]   And so you can make applications that are more involved.
[00:08:31.240 --> 00:08:35.740]   And so we've seen web search companies using us.
[00:08:35.740 --> 00:08:39.900]   We've seen all of the standard enterprise stuff
[00:08:39.900 --> 00:08:44.140]   as well, like knowledge management, marketing.
[00:08:44.140 --> 00:08:45.940]   The fact that you have access to the weights
[00:08:45.940 --> 00:08:48.940]   means that you can pour in your editorial tone much more.
[00:08:48.940 --> 00:08:52.300]   So that's-- yeah, we see the typical use cases.
[00:08:52.300 --> 00:08:55.580]   I think the-- but the value is that--
[00:08:55.580 --> 00:08:58.980]   or the open source part is that developers have control,
[00:08:58.980 --> 00:09:00.400]   so they can deploy it everywhere.
[00:09:00.400 --> 00:09:02.100]   They can have very high quality of service
[00:09:02.100 --> 00:09:05.380]   because they can use their dedicated instances,
[00:09:05.380 --> 00:09:06.180]   for instance.
[00:09:06.180 --> 00:09:08.820]   And they can modify the weights to suit their needs
[00:09:08.820 --> 00:09:10.960]   and to bump the performance to a level which
[00:09:10.960 --> 00:09:14.100]   is close to the largest ones, the largest models,
[00:09:14.100 --> 00:09:15.940]   while being much cheaper.
[00:09:15.940 --> 00:09:17.820]   And what's the next big thing do you
[00:09:17.820 --> 00:09:19.660]   think that we're going to get to see from you guys?
[00:09:19.660 --> 00:09:22.080]   Can you give us a sneak peek of what might be coming soon,
[00:09:22.080 --> 00:09:24.340]   or what we should be expecting from Mistral?
[00:09:24.340 --> 00:09:24.980]   Yeah, for sure.
[00:09:24.980 --> 00:09:28.780]   So we have-- so Mistral-Large was good, but not good enough.
[00:09:28.780 --> 00:09:31.540]   So we are working on improving it quite heavily.
[00:09:31.540 --> 00:09:35.140]   We have interesting open source models
[00:09:35.140 --> 00:09:40.660]   on various vertical domains that we'll be announcing very soon.
[00:09:40.660 --> 00:09:43.580]   We have-- the platform is currently just APIs,
[00:09:43.580 --> 00:09:45.340]   like serverless APIs.
[00:09:45.340 --> 00:09:47.740]   And so we are working on making customization part of it,
[00:09:47.740 --> 00:09:50.940]   so the fine tuning part.
[00:09:50.940 --> 00:09:53.860]   And obviously, and I think as many other companies,
[00:09:53.860 --> 00:09:57.740]   we're heavily betting on multilingual data
[00:09:57.740 --> 00:09:59.700]   and multilingual model.
[00:09:59.700 --> 00:10:02.780]   Because as a European company, we're also well-positioned.
[00:10:02.780 --> 00:10:05.100]   And this is a demand of our customers
[00:10:05.100 --> 00:10:08.220]   that I think is higher than here.
[00:10:08.220 --> 00:10:11.740]   And then, yeah, eventually, in the months to come,
[00:10:11.740 --> 00:10:15.340]   we will also release some multimodal models.
[00:10:15.340 --> 00:10:16.420]   OK, exciting.
[00:10:16.420 --> 00:10:18.300]   We'll look forward to that.
[00:10:18.300 --> 00:10:20.300]   As you mentioned, many of the people in this room
[00:10:20.300 --> 00:10:21.420]   are using Mistral models.
[00:10:21.420 --> 00:10:23.220]   Many of the companies we work with every day
[00:10:23.220 --> 00:10:25.020]   here in the Silicon Valley ecosystem
[00:10:25.020 --> 00:10:27.020]   are already working with Mistral.
[00:10:27.020 --> 00:10:28.540]   How should they work with you?
[00:10:28.540 --> 00:10:30.260]   And how should they work with the company?
[00:10:30.260 --> 00:10:34.000]   And what's the best way for them to work with you?
[00:10:34.000 --> 00:10:35.300]   Well, they can reach out.
[00:10:35.300 --> 00:10:37.620]   So we have some developer relations
[00:10:37.620 --> 00:10:40.620]   that are really pushing the community forward,
[00:10:40.620 --> 00:10:45.140]   making guides, also gathering use cases
[00:10:45.140 --> 00:10:47.900]   to showcase what you can build with Mistral models.
[00:10:47.900 --> 00:10:51.060]   So this is-- we're very investing a lot
[00:10:51.060 --> 00:10:52.900]   on the community.
[00:10:52.900 --> 00:10:56.020]   Something that basically makes the model better
[00:10:56.020 --> 00:11:00.340]   and that we are trying to set up is our ways for us
[00:11:00.340 --> 00:11:04.060]   to get evaluations, benchmarks, actual use cases on which we
[00:11:04.060 --> 00:11:05.660]   can evaluate our models on.
[00:11:05.660 --> 00:11:07.980]   And so having a mapping of what people
[00:11:07.980 --> 00:11:09.940]   are building with our model is also a way for us
[00:11:09.940 --> 00:11:13.620]   to make a better generation of new open source models.
[00:11:13.620 --> 00:11:18.300]   And so please engage with us to discuss how we can help,
[00:11:18.300 --> 00:11:19.860]   how-- discuss your use cases.
[00:11:19.860 --> 00:11:21.380]   We can advertise it.
[00:11:21.380 --> 00:11:25.340]   We can also gather some insight of the new evaluations
[00:11:25.340 --> 00:11:27.020]   that we should add to our evaluation suit
[00:11:27.020 --> 00:11:29.940]   to verify that our models are getting better over time.
[00:11:29.940 --> 00:11:32.380]   And on the commercial side, our models
[00:11:32.380 --> 00:11:33.580]   are available on our platform.
[00:11:33.580 --> 00:11:35.180]   So the commercial models are actually
[00:11:35.180 --> 00:11:38.660]   working better than the open source ones.
[00:11:38.660 --> 00:11:40.860]   They're also available on various cloud providers
[00:11:40.860 --> 00:11:44.500]   so that it facilitates adoption for enterprises.
[00:11:44.500 --> 00:11:46.620]   And customization capabilities like fine tuning,
[00:11:46.620 --> 00:11:49.020]   which really made the value of the open source models,
[00:11:49.020 --> 00:11:50.700]   are actually coming very soon.
[00:11:50.700 --> 00:11:51.420]   Wonderful.
[00:11:51.420 --> 00:11:53.500]   And you talked a little bit about the benefits
[00:11:53.500 --> 00:11:55.140]   of being in Europe.
[00:11:55.140 --> 00:11:56.660]   You touched on it briefly.
[00:11:56.660 --> 00:11:59.140]   You're already this example, global example,
[00:11:59.140 --> 00:12:01.340]   of the great innovations that can come from Europe
[00:12:01.340 --> 00:12:03.460]   and are coming from Europe.
[00:12:03.460 --> 00:12:06.180]   Talk a little bit more about the advantages of building
[00:12:06.180 --> 00:12:07.780]   a business from France and building
[00:12:07.780 --> 00:12:09.100]   this company from Europe.
[00:12:09.100 --> 00:12:11.060]   The advantage and drawbacks, I guess.
[00:12:11.060 --> 00:12:12.980]   Yeah, both, both.
[00:12:12.980 --> 00:12:14.900]   I guess one advantage is that you
[00:12:14.900 --> 00:12:18.020]   have a very strong junior pool of talent.
[00:12:18.020 --> 00:12:20.460]   So there's a lot of people coming
[00:12:20.460 --> 00:12:24.260]   from masters in France, in Poland, in the UK
[00:12:24.260 --> 00:12:27.260]   that we can train in like three months and get them up to speed,
[00:12:27.260 --> 00:12:32.020]   get them basically producing as much as a million dollar
[00:12:32.020 --> 00:12:36.100]   engineer in the Bay Area for 10 times the cost.
[00:12:36.100 --> 00:12:37.780]   So that's kind of efficient.
[00:12:37.780 --> 00:12:39.020]   Shh, don't tell them all that.
[00:12:39.020 --> 00:12:40.820]   They're going to all hire people in France.
[00:12:40.820 --> 00:12:43.300]   I'm sure.
[00:12:43.300 --> 00:12:47.300]   Like the workforce is very good, engineers and machine
[00:12:47.300 --> 00:12:50.020]   learning engineers.
[00:12:50.020 --> 00:12:53.580]   Generally speaking, we have a lot of support from the state,
[00:12:53.580 --> 00:12:56.620]   which is actually more important in Europe than in the US.
[00:12:56.620 --> 00:12:59.380]   They tend to over-regulate a bit too fast.
[00:12:59.380 --> 00:13:00.980]   So we've been telling them not to,
[00:13:00.980 --> 00:13:03.660]   but they don't always listen.
[00:13:03.660 --> 00:13:06.780]   And then generally, I mean, yeah,
[00:13:06.780 --> 00:13:08.700]   like European companies like to work with us
[00:13:08.700 --> 00:13:11.820]   because we're European and we are better
[00:13:11.820 --> 00:13:13.740]   in European languages, as it turns out.
[00:13:13.740 --> 00:13:16.100]   Like French, the French Mistral Lodge
[00:13:16.100 --> 00:13:18.340]   is actually probably the strongest French model out
[00:13:18.340 --> 00:13:19.380]   there.
[00:13:19.380 --> 00:13:22.420]   So yeah, I guess that's not an advantage,
[00:13:22.420 --> 00:13:24.300]   but at least there's a lot of opportunities
[00:13:24.300 --> 00:13:26.300]   that are geographical and that we're leveraging.
[00:13:26.300 --> 00:13:27.180]   Wonderful.
[00:13:27.180 --> 00:13:29.540]   And paint the picture for us five years from now.
[00:13:29.540 --> 00:13:31.460]   Like I know that this world's moving so fast.
[00:13:31.460 --> 00:13:32.960]   I mean, just think of all the things
[00:13:32.960 --> 00:13:35.020]   you've gone through in the two years.
[00:13:35.020 --> 00:13:36.820]   It's not even two years old as a company.
[00:13:36.820 --> 00:13:39.580]   It's almost two years old as a company.
[00:13:39.580 --> 00:13:42.540]   But five years from now, where does Mistral sit?
[00:13:42.540 --> 00:13:44.040]   What do you think you have achieved?
[00:13:44.040 --> 00:13:46.180]   What does this landscape look like?
[00:13:46.180 --> 00:13:49.620]   So our bet is that basically the platform
[00:13:49.620 --> 00:13:53.500]   and the infrastructure of artificial intelligence
[00:13:53.500 --> 00:13:54.700]   will be open.
[00:13:54.700 --> 00:13:59.040]   And based on that, we'll be able to create assistance and then
[00:13:59.040 --> 00:14:00.820]   potentially autonomous agent.
[00:14:00.820 --> 00:14:04.420]   And we believe that we can become this platform
[00:14:04.420 --> 00:14:06.940]   by being the most open platform out there,
[00:14:06.940 --> 00:14:09.420]   by being independent from cloud providers, et cetera.
[00:14:09.420 --> 00:14:12.260]   So in five years from now, I have literally no idea
[00:14:12.260 --> 00:14:13.720]   of what this is going to look like.
[00:14:13.720 --> 00:14:17.160]   If you looked at the field in 2019,
[00:14:17.160 --> 00:14:19.660]   I don't think you could bet on where we would be today.
[00:14:19.660 --> 00:14:22.580]   But we are evolving toward more and more autonomous agents.
[00:14:22.580 --> 00:14:24.100]   We can do more and more tasks.
[00:14:24.100 --> 00:14:26.860]   I think the way we work is going to be changed profoundly.
[00:14:26.860 --> 00:14:30.060]   And making such agents and assistants
[00:14:30.060 --> 00:14:31.460]   is going to be easier and easier.
[00:14:31.460 --> 00:14:33.740]   So right now, we're focusing on the developer world.
[00:14:33.740 --> 00:14:39.580]   But I expect that AI technology is, in itself,
[00:14:39.580 --> 00:14:43.660]   so easily controllable through human languages,
[00:14:43.660 --> 00:14:45.820]   human language that potentially, at some point,
[00:14:45.820 --> 00:14:47.760]   the developer becomes the user.
[00:14:47.760 --> 00:14:51.880]   And so we are evolving toward any user
[00:14:51.880 --> 00:14:54.520]   being able to create its own assistant
[00:14:54.520 --> 00:14:56.080]   or its own autonomous agent.
[00:14:56.080 --> 00:14:58.000]   I'm pretty sure that in five years from now,
[00:14:58.000 --> 00:15:02.000]   this will be something that you learn to do at school.
[00:15:02.000 --> 00:15:02.960]   Awesome.
[00:15:02.960 --> 00:15:04.760]   Well, we have about five minutes left.
[00:15:04.760 --> 00:15:06.840]   Just want to open up in case there's any questions
[00:15:06.840 --> 00:15:09.120]   from the audience.
[00:15:09.120 --> 00:15:09.880]   Don't be shy.
[00:15:09.880 --> 00:15:12.320]   Sonia's got a question.
[00:15:12.320 --> 00:15:14.120]   How do you see the future of open source
[00:15:14.120 --> 00:15:16.440]   versus commercial models playing out for your company?
[00:15:16.440 --> 00:15:18.820]   I think you made a huge splash with open source at first.
[00:15:18.820 --> 00:15:20.780]   As you mentioned, some of the commercial models
[00:15:20.780 --> 00:15:21.820]   are even better now.
[00:15:21.820 --> 00:15:23.160]   How do you imagine that plays out
[00:15:23.160 --> 00:15:25.100]   over the next handful of years?
[00:15:25.100 --> 00:15:26.860]   Well, I guess the one thing we optimize for
[00:15:26.860 --> 00:15:28.480]   is to be able to continuously produce
[00:15:28.480 --> 00:15:30.800]   open models with a sustainable business model
[00:15:30.800 --> 00:15:36.760]   to actually fuel the development of the next generation.
[00:15:36.760 --> 00:15:39.040]   And so I think that, as I've said,
[00:15:39.040 --> 00:15:41.240]   this is going to evolve with time.
[00:15:41.240 --> 00:15:42.880]   But in order to stay relevant, we
[00:15:42.880 --> 00:15:45.280]   need to stay the best at producing open source
[00:15:45.280 --> 00:15:47.520]   models, at least on some part of the spectrum.
[00:15:47.520 --> 00:15:49.020]   So that can be the small models, that
[00:15:49.020 --> 00:15:50.760]   can be the very big models.
[00:15:50.760 --> 00:15:52.400]   And so that's very much something
[00:15:52.400 --> 00:15:56.020]   that sets the constraints of whatever we can do.
[00:15:56.020 --> 00:15:58.160]   Staying relevant in the open source world,
[00:15:58.160 --> 00:16:01.320]   staying the best solution for developers
[00:16:01.320 --> 00:16:05.320]   is really our mission, and we'll keep doing it.
[00:16:05.320 --> 00:16:06.820]   David?
[00:16:06.820 --> 00:16:08.860]   There's got to be questions from more than just
[00:16:08.860 --> 00:16:10.080]   the Sequoia partners, guys.
[00:16:10.080 --> 00:16:11.080]   Come on.
[00:16:11.080 --> 00:16:14.960]   Can you talk to us a little bit about Llama3 and Facebook
[00:16:14.960 --> 00:16:17.360]   and how you think about competition with them?
[00:16:17.360 --> 00:16:21.040]   Well, Llama3 is working on, I guess, making models.
[00:16:21.040 --> 00:16:22.640]   I'm not sure they will be open source.
[00:16:22.640 --> 00:16:24.520]   I have no idea of what's going on there.
[00:16:24.520 --> 00:16:26.880]   So far, I think we've been delivering
[00:16:26.880 --> 00:16:28.320]   faster and smaller models.
[00:16:28.320 --> 00:16:30.520]   So we expect to be continuing doing it.
[00:16:30.520 --> 00:16:33.100]   But generally, the good thing about open source
[00:16:33.100 --> 00:16:36.560]   is that it's never too much of a competition, because once you
[00:16:36.560 --> 00:16:39.120]   have, like, if you have several actors,
[00:16:39.120 --> 00:16:43.280]   normally that should actually benefit to everybody.
[00:16:43.280 --> 00:16:45.280]   And so there should be some--
[00:16:45.280 --> 00:16:46.840]   if they turn out to be very strong,
[00:16:46.840 --> 00:16:48.340]   there will be some cross-pollination,
[00:16:48.340 --> 00:16:49.920]   and we'll welcome it.
[00:16:49.920 --> 00:16:51.680]   One thing that's made you guys different
[00:16:51.680 --> 00:16:53.440]   from other proprietary model providers
[00:16:53.440 --> 00:16:56.260]   is the partnerships with Snowflakes and Databricks,
[00:16:56.260 --> 00:16:58.720]   for example, and running natively in their clouds,
[00:16:58.720 --> 00:17:02.040]   as opposed to just having API connectivity.
[00:17:02.040 --> 00:17:05.280]   Curious if you can talk about why you did those deals,
[00:17:05.280 --> 00:17:07.760]   and then also what you see as the future of, say,
[00:17:07.760 --> 00:17:11.500]   Databricks or Snowflake in the brave new MLM world.
[00:17:11.500 --> 00:17:12.800]   I guess you should ask them.
[00:17:12.800 --> 00:17:16.680]   But I think, generally speaking, AI models become very strong
[00:17:16.680 --> 00:17:21.360]   if they are connected to data and grounding information.
[00:17:21.360 --> 00:17:23.840]   As it turns out, the enterprise data
[00:17:23.840 --> 00:17:26.160]   is oftentimes either on Snowflake or on Databricks,
[00:17:26.160 --> 00:17:28.680]   or sometimes on AWS.
[00:17:28.680 --> 00:17:32.560]   And so being able for customers to be
[00:17:32.560 --> 00:17:37.120]   able to deploy the technology exactly where their data is
[00:17:37.120 --> 00:17:38.520]   is, I think, quite important.
[00:17:38.520 --> 00:17:44.440]   I expect that this will continue being the case,
[00:17:44.440 --> 00:17:46.600]   especially as, I believe, we'll move on to more
[00:17:46.600 --> 00:17:47.920]   stateful AI deployment.
[00:17:47.920 --> 00:17:52.240]   So today, we deploy serverless APIs with not much state.
[00:17:52.240 --> 00:17:55.560]   It's really like lambda functions.
[00:17:55.560 --> 00:17:58.040]   But as we go forward and as we make models more and more
[00:17:58.040 --> 00:18:01.680]   specialized, as we make them more tuned to use cases,
[00:18:01.680 --> 00:18:05.240]   and as we make them self-improving,
[00:18:05.240 --> 00:18:06.600]   you will have to manage state.
[00:18:06.600 --> 00:18:09.880]   And those could actually be part of the data cloud.
[00:18:09.880 --> 00:18:12.720]   So there's an open question of where do you put the AI state.
[00:18:12.720 --> 00:18:14.840]   And I think that's--
[00:18:14.840 --> 00:18:16.880]   my understanding is that Snowflake and Databricks
[00:18:16.880 --> 00:18:19.840]   would like it to be on their data cloud.
[00:18:19.840 --> 00:18:22.440]   - And I think there was a question right behind him,
[00:18:22.440 --> 00:18:24.280]   the gray switch.
[00:18:24.280 --> 00:18:27.640]   - I'm curious where you draw the line between openness
[00:18:27.640 --> 00:18:28.620]   and proprietary.
[00:18:28.620 --> 00:18:30.640]   So you're releasing the weights.
[00:18:30.640 --> 00:18:32.840]   Would you also be comfortable sharing more
[00:18:32.840 --> 00:18:35.600]   about how you train the models, the recipe for how you collect
[00:18:35.600 --> 00:18:37.720]   the data, how you do mixture of experts training?
[00:18:37.720 --> 00:18:40.040]   Or do you draw the line at, like, we release the weights
[00:18:40.040 --> 00:18:41.640]   and the rest is proprietary?
[00:18:41.640 --> 00:18:42.800]   - That's where we draw the line.
[00:18:42.800 --> 00:18:44.240]   And I think the reason for that is
[00:18:44.240 --> 00:18:46.400]   that it's a very competitive landscape.
[00:18:46.400 --> 00:18:51.160]   And so it's similar to the tension
[00:18:51.160 --> 00:18:54.000]   there is in between having some form of revenue
[00:18:54.000 --> 00:18:56.000]   to sustain the next generation.
[00:18:56.000 --> 00:18:59.520]   And there's also a tension between what you actually
[00:18:59.520 --> 00:19:02.600]   disclose and everything that--
[00:19:02.600 --> 00:19:05.680]   yeah, in order to stay ahead of the curve
[00:19:05.680 --> 00:19:08.920]   and not to give your recipe to your competitors.
[00:19:08.920 --> 00:19:12.280]   And so, again, this is a moving line.
[00:19:12.280 --> 00:19:14.760]   There's also some game theory at stake.
[00:19:14.760 --> 00:19:17.920]   Like, if everybody starts doing it, then we could do it.
[00:19:17.920 --> 00:19:22.720]   But for now, we are not taking this risk, indeed.
[00:19:22.720 --> 00:19:26.680]   - I'm curious, when another company releases weights
[00:19:26.680 --> 00:19:29.800]   for a model like Grok, for example,
[00:19:29.800 --> 00:19:33.400]   and you only see the weights, what kinds of practices
[00:19:33.400 --> 00:19:36.800]   do you guys do internally to see what you can learn from it?
[00:19:36.800 --> 00:19:39.080]   - You can't learn a lot of things from weights.
[00:19:39.080 --> 00:19:40.440]   We don't even look at it.
[00:19:40.440 --> 00:19:42.120]   It's actually too big for us to deploy.
[00:19:42.120 --> 00:19:45.480]   Grok is quite big.
[00:19:45.480 --> 00:19:48.920]   - Or was there any architecture learning?
[00:19:48.920 --> 00:19:51.760]   - I guess they are using, like, a mixture of experts,
[00:19:51.760 --> 00:19:56.000]   pretty standard setting, with a couple of tricks
[00:19:56.000 --> 00:19:57.640]   that I knew about, actually.
[00:19:57.640 --> 00:20:01.720]   Yeah, there's not a lot of things
[00:20:01.720 --> 00:20:03.520]   to learn from the recipe themselves
[00:20:03.520 --> 00:20:04.640]   by looking at the weights.
[00:20:04.640 --> 00:20:07.200]   You can try to infer things, but that's--
[00:20:07.200 --> 00:20:09.960]   like, reverse engineering is not that easy.
[00:20:09.960 --> 00:20:11.600]   It's basically compressing information,
[00:20:11.600 --> 00:20:14.240]   and it compresses information sufficiently highly
[00:20:14.240 --> 00:20:16.960]   so that you can't really find out what's going on.
[00:20:16.960 --> 00:20:26.040]   - The cube is coming.
[00:20:26.040 --> 00:20:27.680]   - It's OK.
[00:20:27.680 --> 00:20:29.440]   Yeah, I'm just curious about, like,
[00:20:29.440 --> 00:20:31.520]   what are you guys going to focus on?
[00:20:31.520 --> 00:20:33.400]   The model sizes, your opinions on that.
[00:20:33.400 --> 00:20:35.840]   Is, like, you guys going to still go on the small?
[00:20:35.840 --> 00:20:39.000]   Or, yeah, going to go with the larger ones, basically?
[00:20:39.000 --> 00:20:43.200]   - So model size are kind of set by, like, scaling loads.
[00:20:43.200 --> 00:20:45.760]   So it depends on, like, the compute you have.
[00:20:45.760 --> 00:20:48.640]   Based on the compute you have, based on the learning
[00:20:48.640 --> 00:20:51.800]   infrastructure you want to go to, you make some choices.
[00:20:51.800 --> 00:20:54.360]   And so you optimize for training cost and for inference cost.
[00:20:54.360 --> 00:20:57.680]   And then there's obviously--
[00:20:57.680 --> 00:21:01.480]   there's the weights in between, like, for--
[00:21:01.480 --> 00:21:03.800]   depends on the weight that you put on the training cost
[00:21:03.800 --> 00:21:05.920]   amortization.
[00:21:05.920 --> 00:21:10.040]   The more you amortize it, the more you can compress models.
[00:21:10.040 --> 00:21:14.400]   But basically, our goal is to be low latency
[00:21:14.400 --> 00:21:17.480]   and to be relevant on the reasoning front.
[00:21:17.480 --> 00:21:19.880]   So that means having a family of model
[00:21:19.880 --> 00:21:22.080]   that goes from the small ones to the very large ones.
[00:21:22.680 --> 00:21:27.160]   [END PLAYBACK]
[00:21:27.160 --> 00:21:27.640]   - Hi.
[00:21:27.640 --> 00:21:30.320]   Are there any plans for Mistral to expand
[00:21:30.320 --> 00:21:32.280]   into the application stack?
[00:21:32.280 --> 00:21:35.480]   So, for example, when AI released the custom GPTs
[00:21:35.480 --> 00:21:37.840]   and the assistance API, is that the direction
[00:21:37.840 --> 00:21:40.040]   that you think that Mistral will take in the future?
[00:21:40.040 --> 00:21:40.560]   - Yeah.
[00:21:40.560 --> 00:21:43.040]   So I think, as I've said, we're really
[00:21:43.040 --> 00:21:45.120]   focusing on the developer first.
[00:21:45.120 --> 00:21:48.280]   But there's many-- like, the frontier
[00:21:48.280 --> 00:21:50.280]   is pretty thin in between developers and users
[00:21:50.280 --> 00:21:51.200]   for this technology.
[00:21:51.200 --> 00:21:54.840]   So that's the reason why we released an assistant
[00:21:54.840 --> 00:21:57.920]   demonstrator called Le Chat, which is the cat in English.
[00:21:57.920 --> 00:22:02.960]   And the point here is to expose it to enterprises as well
[00:22:02.960 --> 00:22:06.280]   and make them able to connect their data,
[00:22:06.280 --> 00:22:08.760]   connect their context.
[00:22:08.760 --> 00:22:14.120]   I think that answers some need from our customers
[00:22:14.120 --> 00:22:17.260]   that many of the people we've been talking to
[00:22:17.260 --> 00:22:18.760]   are willing to adopt the technology,
[00:22:18.760 --> 00:22:19.920]   but they need an entry point.
[00:22:19.920 --> 00:22:21.800]   So if you just give them APIs, they're
[00:22:21.800 --> 00:22:24.400]   going to say, OK, but I need an integrator.
[00:22:24.400 --> 00:22:26.440]   And then if you don't have an integrator at hand,
[00:22:26.440 --> 00:22:28.240]   and oftentimes this is the case, it's
[00:22:28.240 --> 00:22:30.040]   good if you have an off-the-shelf solution
[00:22:30.040 --> 00:22:32.200]   at least to get them into the technology
[00:22:32.200 --> 00:22:34.740]   and show them what they could build for their core business.
[00:22:34.740 --> 00:22:37.240]   So that's the reason why we now have two product offerings.
[00:22:37.240 --> 00:22:38.780]   The first one, which is the platform,
[00:22:38.780 --> 00:22:41.480]   and then we have Le Chat, which should evolve into an enterprise
[00:22:41.480 --> 00:22:42.480]   off-the-shelf solution.
[00:22:42.480 --> 00:22:47.800]   - More over there.
[00:22:47.800 --> 00:22:50.000]   Just wondering, where would you be drawing the line
[00:22:50.000 --> 00:22:52.320]   between stop doing prompt engineering
[00:22:52.320 --> 00:22:53.680]   and start doing fine-tuning?
[00:22:53.680 --> 00:22:55.760]   Because a lot of my friends and our customers
[00:22:55.760 --> 00:22:57.960]   are suffering from where they should be,
[00:22:57.960 --> 00:23:00.440]   stop doing more prompt engineering.
[00:23:00.440 --> 00:23:02.800]   - I think that's the number one pain point
[00:23:02.800 --> 00:23:08.680]   that is hard to solve from a product standpoint.
[00:23:08.680 --> 00:23:11.400]   The question is, normally your workflow
[00:23:11.400 --> 00:23:13.580]   should be what should you evaluate on.
[00:23:13.580 --> 00:23:17.520]   And based on that, have your model find out
[00:23:17.520 --> 00:23:20.220]   a way of solving your task.
[00:23:20.220 --> 00:23:22.600]   And so right now, this is still a bit manual.
[00:23:22.600 --> 00:23:26.120]   You go and you have several versions of prompting.
[00:23:26.120 --> 00:23:29.660]   But this is something that actually AI can help solving.
[00:23:29.660 --> 00:23:31.900]   And I expect that this is going to grow more and more
[00:23:31.900 --> 00:23:33.940]   automatically across time.
[00:23:33.940 --> 00:23:38.580]   And this is something that we'd love to try and enable.
[00:23:38.580 --> 00:23:40.780]   - I wanted to ask a bit more of a personal question.
[00:23:40.780 --> 00:23:43.700]   As a founder in the cutting edge of AI,
[00:23:43.700 --> 00:23:46.140]   how do you balance your time between explore and exploit?
[00:23:46.140 --> 00:23:48.460]   How do you yourself stay on top of a field that's
[00:23:48.460 --> 00:23:52.100]   rapidly evolving and becoming larger and deeper every day?
[00:23:52.100 --> 00:23:53.580]   How do you stay on top?
[00:23:53.580 --> 00:23:56.340]   - So I think this question has--
[00:23:56.340 --> 00:23:58.780]   I mean, we explore on the science part, on the product part,
[00:23:58.780 --> 00:24:00.700]   and on the business part.
[00:24:00.700 --> 00:24:04.180]   And the way you balance it is effectively hard.
[00:24:04.180 --> 00:24:06.460]   For a startup, you do have to exploit a lot
[00:24:06.460 --> 00:24:09.100]   because you need to ship fast.
[00:24:09.100 --> 00:24:10.660]   But on the science part, for instance,
[00:24:10.660 --> 00:24:12.060]   you have two or three people that
[00:24:12.060 --> 00:24:14.820]   are working on the next generation of models.
[00:24:14.820 --> 00:24:16.060]   And sometimes they lose time.
[00:24:16.060 --> 00:24:17.500]   But if you don't do that, you are
[00:24:17.500 --> 00:24:19.380]   at risk of becoming irrelevant.
[00:24:19.380 --> 00:24:21.900]   And this is very true for the product side as well.
[00:24:21.900 --> 00:24:24.340]   So right now, we have a very simple product.
[00:24:24.340 --> 00:24:26.900]   But being able to try out new features
[00:24:26.900 --> 00:24:31.420]   and see how they pick up is something that we need to do.
[00:24:31.420 --> 00:24:33.180]   And on the business part, you never
[00:24:33.180 --> 00:24:35.060]   know who is actually quite mature enough
[00:24:35.060 --> 00:24:36.460]   to use your technology.
[00:24:36.460 --> 00:24:41.580]   So yeah, the balance between exploitation and exploration
[00:24:41.580 --> 00:24:43.820]   is something that we master well at the science level
[00:24:43.820 --> 00:24:46.060]   because we've been doing it for years.
[00:24:46.060 --> 00:24:48.580]   And somehow, it transcribes into the product and the business.
[00:24:48.580 --> 00:24:50.580]   But I guess we are currently still
[00:24:50.580 --> 00:24:53.740]   learning to do it properly.
[00:24:53.740 --> 00:24:56.540]   - So one more question from me, and then I think we'll be done.
[00:24:56.540 --> 00:24:57.340]   We're out of time.
[00:24:57.340 --> 00:25:01.780]   But in the scope of two years, models big,
[00:25:01.780 --> 00:25:04.660]   models small that have taken the world by storm,
[00:25:04.660 --> 00:25:07.220]   killer go-to-market partnerships,
[00:25:07.220 --> 00:25:11.260]   just tremendous momentum at the center of the AI ecosystem.
[00:25:11.260 --> 00:25:13.220]   What advice would you give to founders here?
[00:25:13.220 --> 00:25:14.700]   What you have achieved and the pace
[00:25:14.700 --> 00:25:17.700]   at which you have achieved is truly extraordinary.
[00:25:17.700 --> 00:25:19.260]   What advice would you give to people
[00:25:19.260 --> 00:25:21.080]   here who are at different levels of starting and running
[00:25:21.080 --> 00:25:22.460]   and building their own businesses
[00:25:22.460 --> 00:25:25.100]   around the AI opportunity?
[00:25:25.100 --> 00:25:27.020]   - I would say it's always day one.
[00:25:27.020 --> 00:25:30.220]   So I guess, yeah, we are--
[00:25:30.220 --> 00:25:31.940]   I mean, we got some mind share.
[00:25:31.940 --> 00:25:34.700]   But I mean, there's still many proof points
[00:25:34.700 --> 00:25:36.540]   that we need to establish.
[00:25:36.540 --> 00:25:39.220]   And so, yeah, like, being a founder
[00:25:39.220 --> 00:25:42.420]   is basically waking up every day and figuring out
[00:25:42.420 --> 00:25:45.220]   that you need to build everything from scratch
[00:25:45.220 --> 00:25:46.540]   every time, all the time.
[00:25:46.540 --> 00:25:49.420]   So it's, I guess, a bit exhausting.
[00:25:49.420 --> 00:25:51.740]   But it's also exhilarating.
[00:25:51.740 --> 00:25:54.860]   And so I would recommend to be quite ambitious, usually.
[00:25:54.860 --> 00:25:57.420]   Being more ambitious--
[00:25:57.420 --> 00:26:00.900]   I mean, ambition can get you very far.
[00:26:00.900 --> 00:26:04.260]   And so, yeah, you should dream big.
[00:26:04.260 --> 00:26:06.180]   That would be my advice.
[00:26:06.180 --> 00:26:06.740]   - Awesome.
[00:26:06.740 --> 00:26:07.460]   Thank you, Artur.
[00:26:07.460 --> 00:26:09.780]   Thanks for being with us today.
[00:26:09.780 --> 00:26:12.020]   (applause)
[00:26:12.020 --> 00:26:15.020]   (audience applauds)

