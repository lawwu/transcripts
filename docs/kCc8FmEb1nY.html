<html><head><title>Let's build GPT: from scratch, in code, spelled out.</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Let's build GPT: from scratch, in code, spelled out.</h2><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY"><img src="https://i.ytimg.com/vi_webp/kCc8FmEb1nY/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=0">0:0</a> intro: ChatGPT, Transformers, nanoGPT, Shakespeare<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=472">7:52</a> reading and exploring the data<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=568">9:28</a> tokenization, train/val split<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=867">14:27</a> data loader: batches of chunks of data<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1331">22:11</a> simplest baseline: bigram language model, loss, generation<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2093">34:53</a> training the bigram model<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2280">38:0</a> port our code to a script<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2533">42:13</a> version 1: averaging past context with for loops, the weakest form of aggregation<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2831">47:11</a> the trick in self-attention: matrix multiply as weighted aggregation<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3114">51:54</a> version 2: using matrix multiply<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3282">54:42</a> version 3: adding softmax<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3506">58:26</a> minor code cleanup<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3618">60:18</a> positional encoding<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3720">62:0</a> THE CRUX OF THE VIDEO: version 4: self-attention<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4298">71:38</a> note 1: attention as communication<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4366">72:46</a> note 2: attention has no notion of space, operates over sets<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4420">73:40</a> note 3: there is no communication across batch dimension<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4454">74:14</a> note 4: encoder blocks vs. decoder blocks<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4539">75:39</a> note 5: attention vs. self-attention vs. cross-attention<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4616">76:56</a> note 6: "scaled" self-attention. why divide by sqrt(head_size)<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4751">79:11</a> inserting a single self-attention block to our network<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4919">81:59</a> multi-headed self-attention<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5065">84:25</a> feedforward layers of transformer block<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5208">86:48</a> residual connections<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5571">92:51</a> layernorm (and its relationship to our previous batchnorm)<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5869">97:49</a> scaling up the model! creating a few variables. adding dropout<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6159">102:39</a> encoder vs. decoder vs. both (?) Transformers<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6382">106:22</a> super quick walkthrough of nanoGPT, batched multi-headed self-attention<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6533">108:53</a> back to ChatGPT, GPT-3, pretraining vs. finetuning, RLHF<br><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6872">114:32</a> conclusions<br><br><div style="text-align: left;"><a href="./kCc8FmEb1nY.html">Whisper Transcript</a> | <a href="./transcript_kCc8FmEb1nY.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi everyone. So by now you have probably heard of ChatGPT. It has taken the world and the AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5" target="_blank">00:00:05.280</a></span> | <span class="t">community by storm and it is a system that allows you to interact with an AI and give it text-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=11" target="_blank">00:00:11.840</a></span> | <span class="t">tasks. So for example, we can ask ChatGPT to write us a small haiku about how important it is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=16" target="_blank">00:00:16.960</a></span> | <span class="t">people understand AI and then they can use it to improve the world and make it more prosperous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=20" target="_blank">00:00:20.800</a></span> | <span class="t">So when we run this, AI knowledge brings prosperity for all to see, embrace its power.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=28" target="_blank">00:00:28.080</a></span> | <span class="t">Okay, not bad. And so you could see that ChatGPT went from left to right and generated all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=33" target="_blank">00:00:33.200</a></span> | <span class="t">words sequentially. Now I asked it already the exact same prompt a little bit earlier and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=39" target="_blank">00:00:39.760</a></span> | <span class="t">generated a slightly different outcome. AI's power to grow, ignorance holds us back, learn, prosperity</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=46" target="_blank">00:00:46.080</a></span> | <span class="t">waits. So pretty good in both cases and slightly different. So you can see that ChatGPT is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=51" target="_blank">00:00:51.440</a></span> | <span class="t">probabilistic system and for any one prompt it can give us multiple answers sort of replying to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=58" target="_blank">00:00:58.160</a></span> | <span class="t">Now this is just one example of a prompt. People have come up with many, many examples and there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=62" target="_blank">00:01:02.640</a></span> | <span class="t">are entire websites that index interactions with ChatGPT and so many of them are quite humorous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=69" target="_blank">00:01:09.360</a></span> | <span class="t">Explain HTML to me like I'm a dog, write release notes for chess too, write a note about Elon Musk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=75" target="_blank">00:01:15.760</a></span> | <span class="t">buying a Twitter and so on. So as an example, please write a breaking news article about a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=82" target="_blank">00:01:22.080</a></span> | <span class="t">leaf falling from a tree. In a shocking turn of events, a leaf has fallen from a tree in the local</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=87" target="_blank">00:01:27.920</a></span> | <span class="t">park. Witnesses report that the leaf, which was previously attached to a branch of a tree, detached</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=92" target="_blank">00:01:32.800</a></span> | <span class="t">itself and fell to the ground. Very dramatic. So you can see that this is a pretty remarkable system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=98" target="_blank">00:01:38.560</a></span> | <span class="t">and it is what we call a language model because it models the sequence of words or characters or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=106" target="_blank">00:01:46.320</a></span> | <span class="t">tokens more generally and it knows how certain words follow each other in English language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=112" target="_blank">00:01:52.000</a></span> | <span class="t">And so from its perspective, what it is doing is it is completing the sequence. So I give it the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=117" target="_blank">00:01:57.840</a></span> | <span class="t">start of a sequence and it completes the sequence with the outcome. And so it's a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=123" target="_blank">00:02:03.280</a></span> | <span class="t">in that sense. Now I would like to focus on the under the hood components of what makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=130" target="_blank">00:02:10.080</a></span> | <span class="t">ChatGPT work. So what is the neural network under the hood that models the sequence of these words?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=136" target="_blank">00:02:16.400</a></span> | <span class="t">And that comes from this paper called "Attention is All You Need" in 2017, a landmark paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=142" target="_blank">00:02:22.880</a></span> | <span class="t">a landmark paper in AI that produced and proposed the transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=147" target="_blank">00:02:27.600</a></span> | <span class="t">So GPT is short for generatively pre-trained transformer. So transformer is the neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=155" target="_blank">00:02:35.440</a></span> | <span class="t">net that actually does all the heavy lifting under the hood. It comes from this paper in 2017.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=161" target="_blank">00:02:41.040</a></span> | <span class="t">Now if you read this paper, this reads like a pretty random machine translation paper and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=166" target="_blank">00:02:46.000</a></span> | <span class="t">because I think the authors didn't fully anticipate the impact that the transformer would have on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=169" target="_blank">00:02:49.920</a></span> | <span class="t">field. And this architecture that they produced in the context of machine translation in their case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=175" target="_blank">00:02:55.600</a></span> | <span class="t">actually ended up taking over the rest of AI in the next five years after. And so this architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=182" target="_blank">00:03:02.320</a></span> | <span class="t">with minor changes was copy pasted into a huge amount of applications in AI in more recent years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=188" target="_blank">00:03:08.960</a></span> | <span class="t">And that includes at the core of ChatGPT. Now we are not going to, what I'd like to do now is I'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=195" target="_blank">00:03:15.280</a></span> | <span class="t">like to build out something like ChatGPT, but we're not going to be able to of course reproduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=200" target="_blank">00:03:20.560</a></span> | <span class="t">ChatGPT. This is a very serious production grade system. It is trained on a good chunk of internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=207" target="_blank">00:03:27.760</a></span> | <span class="t">and then there's a lot of pre-training and fine tuning stages to it. And so it's very complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=212" target="_blank">00:03:32.960</a></span> | <span class="t">What I'd like to focus on is just to train a transformer based language model. And in our case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=219" target="_blank">00:03:39.200</a></span> | <span class="t">it's going to be a character level language model. I still think that is a very educational with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=224" target="_blank">00:03:44.480</a></span> | <span class="t">respect to how these systems work. So I don't want to train on the chunk of internet. We need a smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=229" target="_blank">00:03:49.520</a></span> | <span class="t">data set. In this case, I propose that we work with my favorite toy data set. It's called Tiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=234" target="_blank">00:03:54.800</a></span> | <span class="t">Shakespeare. And what it is is basically it's a concatenation of all of the works of Shakespeare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=240" target="_blank">00:04:00.240</a></span> | <span class="t">in my understanding. And so this is all of Shakespeare in a single file. This file is about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=245" target="_blank">00:04:05.760</a></span> | <span class="t">one megabyte and it's just all of Shakespeare. And what we are going to do now is we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=251" target="_blank">00:04:11.440</a></span> | <span class="t">to basically model how these characters follow each other. So for example, given a chunk of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=256" target="_blank">00:04:16.560</a></span> | <span class="t">these characters like this, given some context of characters in the past, the transformer neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=263" target="_blank">00:04:23.440</a></span> | <span class="t">network will look at the characters that I've highlighted and is going to predict that G</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=267" target="_blank">00:04:27.680</a></span> | <span class="t">is likely to come next in the sequence. And it's going to do that because we're going to train that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=272" target="_blank">00:04:32.000</a></span> | <span class="t">transformer on Shakespeare. And it's just going to try to produce character sequences that look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=277" target="_blank">00:04:37.840</a></span> | <span class="t">like this. And in that process, it's going to model all the patterns inside this data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=282" target="_blank">00:04:42.160</a></span> | <span class="t">So once we've trained the system, I'd just like to give you a preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=286" target="_blank">00:04:46.160</a></span> | <span class="t">We can generate infinite Shakespeare. And of course, it's a fake thing that looks kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=292" target="_blank">00:04:52.640</a></span> | <span class="t">Shakespeare. Apologies for there's some jank that I'm not able to resolve in here, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=303" target="_blank">00:05:03.760</a></span> | <span class="t">you can see how this is going character by character. And it's kind of like predicting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=307" target="_blank">00:05:07.600</a></span> | <span class="t">Shakespeare-like language. So "Verily, my lord, the sites have left thee again, the king,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=314" target="_blank">00:05:14.960</a></span> | <span class="t">coming with my curses with precious pale." And then "Tranio says something else," et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=320" target="_blank">00:05:20.880</a></span> | <span class="t">And this is just coming out of the transformer in a very similar manner as it would come out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=325" target="_blank">00:05:25.200</a></span> | <span class="t">in chat GPT. In our case, character by character, in chat GPT, it's coming out on the token by token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=332" target="_blank">00:05:32.240</a></span> | <span class="t">level. And tokens are these sort of like little sub-word pieces. So they're not word level. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=336" target="_blank">00:05:36.880</a></span> | <span class="t">kind of like word chunk level. And now I've already written this entire code to train these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=345" target="_blank">00:05:45.040</a></span> | <span class="t">transformers. And it is in a GitHub repository that you can find, and it's called nanoGPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=351" target="_blank">00:05:51.600</a></span> | <span class="t">So nanoGPT is a repository that you can find on my GitHub. And it's a repository for training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=357" target="_blank">00:05:57.680</a></span> | <span class="t">transformers on any given text. And what I think is interesting about it, because there's many ways</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=363" target="_blank">00:06:03.440</a></span> | <span class="t">to train transformers, but this is a very simple implementation. So it's just two files of 300</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=368" target="_blank">00:06:08.560</a></span> | <span class="t">lines of code each. One file defines the GPT model, the transformer, and one file trains it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=374" target="_blank">00:06:14.400</a></span> | <span class="t">on some given text dataset. And here I'm showing that if you train it on a open web text dataset,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=379" target="_blank">00:06:19.600</a></span> | <span class="t">which is a fairly large dataset of web pages, then I reproduce the performance of GPT2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=386" target="_blank">00:06:26.320</a></span> | <span class="t">So GPT2 is an early version of OpenAI's GPT from 2017, if I recall correctly. And I've only so far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=394" target="_blank">00:06:34.400</a></span> | <span class="t">reproduced the smallest 124 million parameter model. But basically, this is just proving that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=399" target="_blank">00:06:39.280</a></span> | <span class="t">the code base is correctly arranged. And I'm able to load the neural network weights that OpenAI has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=405" target="_blank">00:06:45.440</a></span> | <span class="t">released later. So you can take a look at the finished code here in nanoGPT. But what I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=411" target="_blank">00:06:51.200</a></span> | <span class="t">like to do in this lecture is I would like to basically write this repository from scratch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=417" target="_blank">00:06:57.040</a></span> | <span class="t">So we're going to begin with an empty file, and we're going to define a transformer piece by piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=422" target="_blank">00:07:02.160</a></span> | <span class="t">We're going to train it on the tiny Shakespeare dataset, and we'll see how we can then generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=428" target="_blank">00:07:08.640</a></span> | <span class="t">infinite Shakespeare. And of course, this can copy paste to any arbitrary text dataset that you like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=434" target="_blank">00:07:14.000</a></span> | <span class="t">But my goal really here is to just make you understand and appreciate how under the hood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=439" target="_blank">00:07:19.600</a></span> | <span class="t">chat-gpt works. And really, all that's required is a proficiency in Python and some basic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=447" target="_blank">00:07:27.040</a></span> | <span class="t">understanding of calculus and statistics. And it would help if you also see my previous videos</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=452" target="_blank">00:07:32.960</a></span> | <span class="t">on the same YouTube channel, in particular, my Make More series, where I define smaller and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=460" target="_blank">00:07:40.400</a></span> | <span class="t">simpler neural network language models. So multilayered perceptrons and so on. It really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=465" target="_blank">00:07:45.520</a></span> | <span class="t">introduces the language modeling framework. And then here in this video, we're going to focus on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=470" target="_blank">00:07:50.000</a></span> | <span class="t">the transformer neural network itself. Okay, so I created a new Google Colab Jupyter notebook here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=476" target="_blank">00:07:56.240</a></span> | <span class="t">And this will allow me to later easily share this code that we're going to develop together</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=480" target="_blank">00:08:00.960</a></span> | <span class="t">with you so you can follow along. So this will be in the video description later. Now, here I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=486" target="_blank">00:08:06.800</a></span> | <span class="t">just done some preliminaries. I downloaded the dataset, the tiny Shakespeare dataset at this URL,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=491" target="_blank">00:08:11.680</a></span> | <span class="t">and you can see that it's about a one megabyte file. Then here I opened the input.txt file and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=497" target="_blank">00:08:17.120</a></span> | <span class="t">just read in all the text as a string. And we see that we are working with one million characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=501" target="_blank">00:08:21.920</a></span> | <span class="t">roughly. And the first 1000 characters, if we just print them out, are basically what you would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=506" target="_blank">00:08:26.960</a></span> | <span class="t">expect. This is the first 1000 characters of the tiny Shakespeare dataset, roughly up to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=512" target="_blank">00:08:32.400</a></span> | <span class="t">So, so far, so good. Next, we're going to take this text. And the text is a sequence of characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=519" target="_blank">00:08:39.200</a></span> | <span class="t">in Python. So when I call the set constructor on it, I'm just going to get the set of all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=525" target="_blank">00:08:45.360</a></span> | <span class="t">characters that occur in this text. And then I call list on that to create a list of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=531" target="_blank">00:08:51.600</a></span> | <span class="t">characters instead of just a set so that I have an ordering, an arbitrary ordering. And then I sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=537" target="_blank">00:08:57.040</a></span> | <span class="t">that. So basically, we get just all the characters that occur in the entire dataset, and they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=541" target="_blank">00:09:01.600</a></span> | <span class="t">sorted. Now, the number of them is going to be our vocabulary size. These are the possible elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=547" target="_blank">00:09:07.280</a></span> | <span class="t">of our sequences. And we see that when I print here the characters, there's 65 of them in total.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=554" target="_blank">00:09:14.160</a></span> | <span class="t">There's a space character, and then all kinds of special characters, and then capitals and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=559" target="_blank">00:09:19.760</a></span> | <span class="t">lowercase letters. So that's our vocabulary. And that's the sort of like possible characters that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=565" target="_blank">00:09:25.440</a></span> | <span class="t">the model can see or emit. Okay, so next, we would like to develop some strategy to tokenize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=572" target="_blank">00:09:32.080</a></span> | <span class="t">the input text. Now, when people say tokenize, they mean convert the raw text as a string</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=578" target="_blank">00:09:38.640</a></span> | <span class="t">to some sequence of integers according to some vocabulary of possible elements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=584" target="_blank">00:09:44.640</a></span> | <span class="t">So as an example, here, we are going to be building a character-level language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=589" target="_blank">00:09:49.360</a></span> | <span class="t">So we're simply going to be translating individual characters into integers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=592" target="_blank">00:09:52.640</a></span> | <span class="t">So let me show you a chunk of code that sort of does that for us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=596" target="_blank">00:09:56.400</a></span> | <span class="t">So we're building both the encoder and the decoder. And let me just talk through what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=601" target="_blank">00:10:01.040</a></span> | <span class="t">happening here. When we encode an arbitrary text, like "Hi there," we're going to receive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=607" target="_blank">00:10:07.840</a></span> | <span class="t">a list of integers that represents that string. So for example, 46, 47, etc. And then we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=615" target="_blank">00:10:15.200</a></span> | <span class="t">have the reverse mapping. So we can take this list and decode it to get back the exact same string.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=621" target="_blank">00:10:21.600</a></span> | <span class="t">So it's really just like a translation to integers and back for arbitrary string. And for us,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=627" target="_blank">00:10:27.440</a></span> | <span class="t">it is done on a character level. Now, the way this was achieved is we just iterate over all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=632" target="_blank">00:10:32.640</a></span> | <span class="t">the characters here and create a lookup table from the character to the integer and vice versa.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=637" target="_blank">00:10:37.920</a></span> | <span class="t">And then to encode some string, we simply translate all the characters individually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=642" target="_blank">00:10:42.320</a></span> | <span class="t">And to decode it back, we use the reverse mapping and concatenate all of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=646" target="_blank">00:10:46.720</a></span> | <span class="t">Now, this is only one of many possible encodings or many possible sort of tokenizers. And it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=652" target="_blank">00:10:52.720</a></span> | <span class="t">a very simple one. But there's many other schemas that people have come up with in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=657" target="_blank">00:10:57.360</a></span> | <span class="t">So for example, Google uses Sentence Piece. So Sentence Piece will also encode text into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=663" target="_blank">00:11:03.280</a></span> | <span class="t">integers, but in a different schema and using a different vocabulary. And Sentence Piece is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=670" target="_blank">00:11:10.720</a></span> | <span class="t">sub-word sort of tokenizer. And what that means is that you're not encoding entire words, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=676" target="_blank">00:11:16.880</a></span> | <span class="t">you're not also encoding individual characters. It's a sub-word unit level. And that's usually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=682" target="_blank">00:11:22.800</a></span> | <span class="t">what's adopted in practice. For example, also OpenAI has this library called TicToken that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=687" target="_blank">00:11:27.600</a></span> | <span class="t">uses a byte pair encoding tokenizer. And that's what GPT uses. And you can also just encode words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=694" target="_blank">00:11:34.960</a></span> | <span class="t">into like Hello World into a list of integers. So as an example, I'm using the TicToken library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=701" target="_blank">00:11:41.120</a></span> | <span class="t">here. I'm getting the encoding for GPT-2 or that was used for GPT-2. Instead of just having 65</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=707" target="_blank">00:11:47.600</a></span> | <span class="t">possible characters or tokens, they have 50,000 tokens. And so when they encode the exact same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=714" target="_blank">00:11:54.720</a></span> | <span class="t">string, hi there, we only get a list of three integers. But those integers are not between 0</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=720" target="_blank">00:12:00.480</a></span> | <span class="t">and 64. They are between 0 and 50,256. So basically, you can trade off the codebook size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=730" target="_blank">00:12:10.320</a></span> | <span class="t">and the sequence lengths. So you can have very long sequences of integers with very small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=735" target="_blank">00:12:15.040</a></span> | <span class="t">vocabularies, or you can have short sequences of integers with very large vocabularies. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=743" target="_blank">00:12:23.520</a></span> | <span class="t">typically people use in practice these sub-word encodings, but I'd like to keep our tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=749" target="_blank">00:12:29.600</a></span> | <span class="t">very simple. So we're using character level tokenizer. And that means that we have very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=753" target="_blank">00:12:33.760</a></span> | <span class="t">small codebooks. We have very simple encode and decode functions, but we do get very long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=760" target="_blank">00:12:40.160</a></span> | <span class="t">sequences as a result. But that's the level at which we're going to stick with this lecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=764" target="_blank">00:12:44.160</a></span> | <span class="t">because it's the simplest thing. Okay, so now that we have an encoder and a decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=768" target="_blank">00:12:48.400</a></span> | <span class="t">effectively a tokenizer, we can tokenize the entire training set of Shakespeare. So here's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=773" target="_blank">00:12:53.680</a></span> | <span class="t">chunk of code that does that. And I'm going to start to use the PyTorch library and specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=778" target="_blank">00:12:58.000</a></span> | <span class="t">the torch.tensor from the PyTorch library. So we're going to take all of the text in Tiny</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=783" target="_blank">00:13:03.280</a></span> | <span class="t">Shakespeare, encode it, and then wrap it into a torch.tensor to get the data tensor. So here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=789" target="_blank">00:13:09.360</a></span> | <span class="t">what the data tensor looks like when I look at just the first 1000 characters or the 1000 elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=794" target="_blank">00:13:14.400</a></span> | <span class="t">of it. So we see that we have a massive sequence of integers. And this sequence of integers here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=800" target="_blank">00:13:20.080</a></span> | <span class="t">is basically an identical translation of the first 1000 characters here. So I believe, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=806" target="_blank">00:13:26.400</a></span> | <span class="t">that 0 is a newline character, and maybe 1 is a space. I'm not 100% sure. But from now on,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=812" target="_blank">00:13:32.560</a></span> | <span class="t">the entire data set of text is re-represented as just, it's just stretched out as a single,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=817" target="_blank">00:13:37.040</a></span> | <span class="t">very large sequence of integers. Let me do one more thing before we move on here. I'd like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=822" target="_blank">00:13:42.880</a></span> | <span class="t">separate out our data set into a train and a validation split. So in particular, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=828" target="_blank">00:13:48.320</a></span> | <span class="t">to take the first 90% of the data set and consider that to be the training data for the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=833" target="_blank">00:13:53.920</a></span> | <span class="t">And we're going to withhold the last 10% at the end of it to be the validation data. And this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=839" target="_blank">00:13:59.360</a></span> | <span class="t">will help us understand to what extent our model is overfitting. So we're going to basically hide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=844" target="_blank">00:14:04.000</a></span> | <span class="t">and keep the validation data on the side, because we don't want just a perfect memorization of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=848" target="_blank">00:14:08.880</a></span> | <span class="t">exact Shakespeare. We want a neural network that sort of creates Shakespeare-like text. And so it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=855" target="_blank">00:14:15.200</a></span> | <span class="t">should be fairly likely for it to produce the actual, stowed away, true Shakespeare text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=862" target="_blank">00:14:22.640</a></span> | <span class="t">And so we're going to use this to get a sense of the overfitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=867" target="_blank">00:14:27.200</a></span> | <span class="t">Okay, so now we would like to start plugging these text sequences or integer sequences into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=871" target="_blank">00:14:31.920</a></span> | <span class="t">the transformer so that it can train and learn those patterns. Now, the important thing to realize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=877" target="_blank">00:14:37.600</a></span> | <span class="t">is we're never going to actually feed entire text into a transformer all at once. That would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=882" target="_blank">00:14:42.000</a></span> | <span class="t">computationally very expensive and prohibitive. So when we actually train a transformer on a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=886" target="_blank">00:14:46.960</a></span> | <span class="t">of these data sets, we only work with chunks of the data set. And when we train the transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=891" target="_blank">00:14:51.680</a></span> | <span class="t">we basically sample random little chunks out of the training set and train on just chunks at a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=896" target="_blank">00:14:56.480</a></span> | <span class="t">time. And these chunks have basically some kind of a length and some maximum length. Now, the maximum</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=904" target="_blank">00:15:04.240</a></span> | <span class="t">length typically, at least in the code I usually write, is called block size. You can find it under</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=910" target="_blank">00:15:10.560</a></span> | <span class="t">different names like context length or something like that. Let's start with the block size of just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=914" target="_blank">00:15:14.560</a></span> | <span class="t">eight. And let me look at the first train data characters, the first block size plus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=919" target="_blank">00:15:19.920</a></span> | <span class="t">characters. I'll explain why plus one in a second. So this is the first nine characters in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=926" target="_blank">00:15:26.000</a></span> | <span class="t">sequence, in the training set. Now, what I'd like to point out is that when you sample a chunk of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=931" target="_blank">00:15:31.520</a></span> | <span class="t">data like this, so say these nine characters out of the training set, this actually has multiple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=937" target="_blank">00:15:37.440</a></span> | <span class="t">examples packed into it. And that's because all of these characters follow each other. And so what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=944" target="_blank">00:15:44.560</a></span> | <span class="t">this thing is going to say when we plug it into a transformer is we're going to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=949" target="_blank">00:15:49.600</a></span> | <span class="t">simultaneously train it to make prediction at every one of these positions. Now, in a chunk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=956" target="_blank">00:15:56.240</a></span> | <span class="t">of nine characters, there's actually eight individual examples packed in there. So there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=961" target="_blank">00:16:01.440</a></span> | <span class="t">the example that when 18, in the context of 18, 47 likely comes next. In a context of 18 and 47,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=970" target="_blank">00:16:10.080</a></span> | <span class="t">56 comes next. In the context of 18, 47, 56, 57 can come next, and so on. So that's the eight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=978" target="_blank">00:16:18.080</a></span> | <span class="t">individual examples. Let me actually spell it out with code. So here's a chunk of code to illustrate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=984" target="_blank">00:16:24.160</a></span> | <span class="t">X are the inputs to the transformer. It will just be the first block size characters. Y will be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=991" target="_blank">00:16:31.760</a></span> | <span class="t">next block size characters. So it's offset by one. And that's because Y are the targets for each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=998" target="_blank">00:16:38.960</a></span> | <span class="t">position in the input. And then here I'm iterating over all the block size of eight. And the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1005" target="_blank">00:16:45.680</a></span> | <span class="t">is always all the characters in X up to T and including T. And the target is always the T-th</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1012" target="_blank">00:16:52.720</a></span> | <span class="t">character, but in the targets array Y. So let me just run this. And basically it spells out what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1019" target="_blank">00:16:59.600</a></span> | <span class="t">I said in words. These are the eight examples hidden in a chunk of nine characters that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1025" target="_blank">00:17:05.680</a></span> | <span class="t">sampled from the training set. I want to mention one more thing. We train on all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1033" target="_blank">00:17:13.120</a></span> | <span class="t">eight examples here with context between one all the way up to context of block size. And we train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1039" target="_blank">00:17:19.440</a></span> | <span class="t">on that not just for computational reasons because we happen to have the sequence already or something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1043" target="_blank">00:17:23.280</a></span> | <span class="t">like that. It's not just done for efficiency. It's also done to make the transformer network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1049" target="_blank">00:17:29.440</a></span> | <span class="t">be used to seeing contexts all the way from as little as one all the way to block size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1055" target="_blank">00:17:35.120</a></span> | <span class="t">And we'd like the transformer to be used to seeing everything in between. And that's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1060" target="_blank">00:17:40.000</a></span> | <span class="t">useful later during inference because while we're sampling, we can start sampling generation with as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1065" target="_blank">00:17:45.440</a></span> | <span class="t">little as one character of context. And the transformer knows how to predict the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1069" target="_blank">00:17:49.200</a></span> | <span class="t">character with all the way up to just context of one. And so then it can predict everything up to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1074" target="_blank">00:17:54.320</a></span> | <span class="t">block size. And after block size, we have to start truncating because the transformer will never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1079" target="_blank">00:17:59.040</a></span> | <span class="t">receive more than block size inputs when it's predicting the next character.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1083" target="_blank">00:18:03.520</a></span> | <span class="t">Okay, so we've looked at the time dimension of the tensors that are going to be feeding into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1088" target="_blank">00:18:08.560</a></span> | <span class="t">the transformer. There's one more dimension to care about, and that is the batch dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1092" target="_blank">00:18:12.000</a></span> | <span class="t">And so as we're sampling these chunks of text, we're going to be actually every time we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1097" target="_blank">00:18:17.760</a></span> | <span class="t">to feed them into a transformer, we're going to have many batches of multiple chunks of text that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1102" target="_blank">00:18:22.080</a></span> | <span class="t">are all stacked up in a single tensor. And that's just done for efficiency just so that we can keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1106" target="_blank">00:18:26.720</a></span> | <span class="t">the GPUs busy because they are very good at parallel processing of data. And so we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1113" target="_blank">00:18:33.920</a></span> | <span class="t">want to process multiple chunks all at the same time. But those chunks are processed completely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1118" target="_blank">00:18:38.320</a></span> | <span class="t">independently, they don't talk to each other, and so on. So let me basically just generalize this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1123" target="_blank">00:18:43.200</a></span> | <span class="t">and introduce a batch dimension. Here's a chunk of code. Let me just run it, and then I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1128" target="_blank">00:18:48.560</a></span> | <span class="t">to explain what it does. So here, because we're going to start sampling random locations in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1134" target="_blank">00:18:54.640</a></span> | <span class="t">data sets to pull chunks from, I am setting the seed in the random number generator so that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1141" target="_blank">00:19:01.360</a></span> | <span class="t">numbers I see here are going to be the same numbers you see later if you try to reproduce this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1146" target="_blank">00:19:06.320</a></span> | <span class="t">Now the batch size here is how many independent sequences we are processing every forward-backward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1151" target="_blank">00:19:11.120</a></span> | <span class="t">pass of the transformer. The block size, as I explained, is the maximum context length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1156" target="_blank">00:19:16.640</a></span> | <span class="t">to make those predictions. So let's say batch size 4, block size 8, and then here's how we get batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1162" target="_blank">00:19:22.240</a></span> | <span class="t">for any arbitrary split. If the split is a training split, then we're going to look at train data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1167" target="_blank">00:19:27.600</a></span> | <span class="t">otherwise at val data. That gives us the data array. And then when I generate random positions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1175" target="_blank">00:19:35.280</a></span> | <span class="t">to grab a chunk out of, I actually generate batch size number of random offsets. So because this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1184" target="_blank">00:19:44.000</a></span> | <span class="t">4, ix is going to be 4 numbers that are randomly generated between 0 and len of data minus block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1191" target="_blank">00:19:51.360</a></span> | <span class="t">size. So it's just random offsets into the training set. And then x's, as I explained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1197" target="_blank">00:19:57.600</a></span> | <span class="t">are the first block size characters starting at i. The y's are the offset by 1 of that, so just add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1206" target="_blank">00:20:06.640</a></span> | <span class="t">plus 1. And then we're going to get those chunks for every one of integers i in ix and use a torch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1214" target="_blank">00:20:14.320</a></span> | <span class="t">dot stack to take all those one-dimensional tensors as we saw here, and we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1221" target="_blank">00:20:21.760</a></span> | <span class="t">stack them up as rows. And so they all become a row in a 4 by 8 tensor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1228" target="_blank">00:20:28.640</a></span> | <span class="t">So here's where I'm printing them. When I sample a batch xb and yb,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1233" target="_blank">00:20:33.600</a></span> | <span class="t">the inputs to the transformer now are the input x is the 4 by 8 tensor, four rows of eight columns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1244" target="_blank">00:20:44.960</a></span> | <span class="t">and each one of these is a chunk of the training set. And then the targets here are in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1252" target="_blank">00:20:52.160</a></span> | <span class="t">associated array y, and they will come in to the transformer all the way at the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1255" target="_blank">00:20:55.920</a></span> | <span class="t">to create the loss function. So they will give us the correct answer for every single position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1262" target="_blank">00:21:02.960</a></span> | <span class="t">inside x. And then these are the four independent rows. So spelled out as we did before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1272" target="_blank">00:21:12.320</a></span> | <span class="t">this 4 by 8 array contains a total of 32 examples, and they're completely independent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1278" target="_blank">00:21:18.640</a></span> | <span class="t">as far as the transformer is concerned. So when the input is 24, the target is 43,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1286" target="_blank">00:21:26.560</a></span> | <span class="t">or rather 43 here in the y array. When the input is 24, 43, the target is 58.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1291" target="_blank">00:21:31.840</a></span> | <span class="t">When the input is 24, 43, 58, the target is 5, etc. Or like when it is a 52, 58, 1, the target is 58.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1301" target="_blank">00:21:41.760</a></span> | <span class="t">Right, so you can sort of see this spelled out. These are the 32 independent examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1306" target="_blank">00:21:46.560</a></span> | <span class="t">packed in to a single batch of the input x, and then the desired targets are in y.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1312" target="_blank">00:21:52.720</a></span> | <span class="t">And so now this integer tensor of x is going to feed into the transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1320" target="_blank">00:22:00.560</a></span> | <span class="t">and that transformer is going to simultaneously process all these examples, and then look up the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1325" target="_blank">00:22:05.840</a></span> | <span class="t">correct integers to predict in every one of these positions in the tensor y. Okay, so now that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1332" target="_blank">00:22:12.560</a></span> | <span class="t">have our batch of input that we'd like to feed into a transformer, let's start basically feeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1336" target="_blank">00:22:16.960</a></span> | <span class="t">this into neural networks. Now we're going to start off with the simplest possible neural network,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1341" target="_blank">00:22:21.760</a></span> | <span class="t">which in the case of language modeling, in my opinion, is the bigram language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1345" target="_blank">00:22:25.280</a></span> | <span class="t">And we've covered the bigram language model in my Make More series in a lot of depth. And so here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1350" target="_blank">00:22:30.320</a></span> | <span class="t">I'm going to sort of go faster, and let's just implement the PyTorch module directly that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1354" target="_blank">00:22:34.960</a></span> | <span class="t">implements the bigram language model. So I'm importing the PyTorch NN module for reproducibility,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1363" target="_blank">00:22:43.120</a></span> | <span class="t">and then here I'm constructing a bigram language model, which is a subclass of NN module.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1367" target="_blank">00:22:47.680</a></span> | <span class="t">And then I'm calling it, and I'm passing in the inputs and the targets, and I'm just printing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1374" target="_blank">00:22:54.480</a></span> | <span class="t">Now when the inputs and targets come here, you see that I'm just taking the index,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1379" target="_blank">00:22:59.520</a></span> | <span class="t">the inputs x here, which I renamed to idx, and I'm just passing them into this token embedding table.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1385" target="_blank">00:23:05.120</a></span> | <span class="t">So what's going on here is that here in the constructor, we are creating a token embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1390" target="_blank">00:23:10.880</a></span> | <span class="t">table, and it is of size vocab size by vocab size. And we're using an n-dot embedding, which is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1398" target="_blank">00:23:18.480</a></span> | <span class="t">very thin wrapper around basically a tensor of shape vocab size by vocab size. And what's happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1404" target="_blank">00:23:24.640</a></span> | <span class="t">here is that when we pass idx here, every single integer in our input is going to refer to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1410" target="_blank">00:23:30.640</a></span> | <span class="t">embedding table, and is going to pluck out a row of that embedding table corresponding to its index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1416" target="_blank">00:23:36.000</a></span> | <span class="t">So 24 here will go to the embedding table, and will pluck out the 24th row. And then 43 will go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1423" target="_blank">00:23:43.040</a></span> | <span class="t">here and pluck out the 43rd row, etc. And then PyTorch is going to arrange all of this into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1428" target="_blank">00:23:48.880</a></span> | <span class="t">batch by time by channel tensor. In this case, batch is 4, time is 8, and c, which is the channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1438" target="_blank">00:23:58.480</a></span> | <span class="t">is vocab size or 65. And so we're just going to pluck out all those rows, arrange them in a b by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1444" target="_blank">00:24:04.320</a></span> | <span class="t">t by c, and now we're going to interpret this as the logits, which are basically the scores</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1449" target="_blank">00:24:09.520</a></span> | <span class="t">for the next character in the sequence. And so what's happening here is we are predicting what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1455" target="_blank">00:24:15.120</a></span> | <span class="t">comes next based on just the individual identity of a single token. And you can do that because,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1461" target="_blank">00:24:21.200</a></span> | <span class="t">I mean, currently the tokens are not talking to each other, and they're not seeing any context,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1466" target="_blank">00:24:26.080</a></span> | <span class="t">except for they're just seeing themselves. So I'm a token number 5, and then I can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1472" target="_blank">00:24:32.320</a></span> | <span class="t">make pretty decent predictions about what comes next just by knowing that I'm token 5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1476" target="_blank">00:24:36.560</a></span> | <span class="t">because some characters follow other characters in typical scenarios. So we saw a lot of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1483" target="_blank">00:24:43.680</a></span> | <span class="t">in a lot more depth in the MakeMore series. And here, if I just run this, then we currently get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1489" target="_blank">00:24:49.120</a></span> | <span class="t">the predictions, the scores, the logits for every one of the 4 by 8 positions. Now that we've made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1496" target="_blank">00:24:56.000</a></span> | <span class="t">predictions about what comes next, we'd like to evaluate the loss function. And so in MakeMore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1500" target="_blank">00:25:00.320</a></span> | <span class="t">series, we saw that a good way to measure a loss or a quality of the predictions is to use the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1506" target="_blank">00:25:06.000</a></span> | <span class="t">negative log likelihood loss, which is also implemented in PyTorch under the name cross</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1510" target="_blank">00:25:10.320</a></span> | <span class="t">entropy. So what we'd like to do here is loss is the cross entropy on the predictions and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1517" target="_blank">00:25:17.680</a></span> | <span class="t">targets. And so this measures the quality of the logits with respect to the targets. In other words,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1523" target="_blank">00:25:23.600</a></span> | <span class="t">we have the identity of the next character, so how well are we predicting the next character</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1528" target="_blank">00:25:28.560</a></span> | <span class="t">based on the logits? And intuitively, the correct dimension of logits, depending on whatever the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1536" target="_blank">00:25:36.960</a></span> | <span class="t">target is, should have a very high number, and all the other dimensions should be a very low number.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1541" target="_blank">00:25:41.040</a></span> | <span class="t">Now, the issue is that this won't actually-- this is what we want. We want to basically output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1547" target="_blank">00:25:47.280</a></span> | <span class="t">the logits and the loss. This is what we want, but unfortunately, this won't actually run.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1555" target="_blank">00:25:55.040</a></span> | <span class="t">We get an error message. But intuitively, we want to measure this. Now, when we go to the PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1563" target="_blank">00:26:03.040</a></span> | <span class="t">cross entropy documentation here, we're trying to call the cross entropy in its functional form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1570" target="_blank">00:26:10.800</a></span> | <span class="t">So that means we don't have to create a module for it. But here, when we go to the documentation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1576" target="_blank">00:26:16.000</a></span> | <span class="t">you have to look into the details of how PyTorch expects these inputs. And basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1580" target="_blank">00:26:20.720</a></span> | <span class="t">the issue here is PyTorch expects, if you have multidimensional input, which we do because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1586" target="_blank">00:26:26.160</a></span> | <span class="t">have a b by t by c tensor, then it actually really wants the channels to be the second dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1593" target="_blank">00:26:33.440</a></span> | <span class="t">here. So basically, it wants a b by c by t instead of a b by t by c. And so it's just the details of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1603" target="_blank">00:26:43.680</a></span> | <span class="t">how PyTorch treats these kinds of inputs. And so we don't actually want to deal with that. So what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1611" target="_blank">00:26:51.200</a></span> | <span class="t">we're going to do instead is we need to basically reshape our logits. So here's what I like to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1615" target="_blank">00:26:55.280</a></span> | <span class="t">I like to basically give names to the dimensions. So logits.shape is b by t by c and unpack those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1621" target="_blank">00:27:01.440</a></span> | <span class="t">numbers. And then let's say that logits equals logits.view. And we want it to be a b times t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1629" target="_blank">00:27:09.920</a></span> | <span class="t">by c, so just a two-dimensional array. So we're going to take all of these positions here, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1639" target="_blank">00:27:19.760</a></span> | <span class="t">we're going to stretch them out in a one-dimensional sequence and preserve the channel dimension as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1645" target="_blank">00:27:25.520</a></span> | <span class="t">the second dimension. So we're just kind of like stretching out the array so it's two-dimensional.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1650" target="_blank">00:27:30.640</a></span> | <span class="t">And in that case, it's going to better conform to what PyTorch sort of expects in its dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1655" target="_blank">00:27:35.440</a></span> | <span class="t">Now, we have to do the same to targets because currently targets are of shape b by t,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1664" target="_blank">00:27:44.560</a></span> | <span class="t">and we want it to be just b times t, so one-dimensional. Now, alternatively, you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1669" target="_blank">00:27:49.760</a></span> | <span class="t">always still just do minus one because PyTorch will guess what this should be if you want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1674" target="_blank">00:27:54.320</a></span> | <span class="t">lay it out. But let me just be explicit and say b times t. Once we reshape this, it will match</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1680" target="_blank">00:28:00.400</a></span> | <span class="t">the cross-entropy case, and then we should be able to evaluate our loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1684" target="_blank">00:28:04.560</a></span> | <span class="t">Okay, so with that right now, and we can do loss. And so currently we see that the loss is 4.87.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1694" target="_blank">00:28:14.480</a></span> | <span class="t">Now, because we have 65 possible vocabulary elements, we can actually guess at what the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1700" target="_blank">00:28:20.480</a></span> | <span class="t">should be. And in particular, we covered negative log-likelihood in a lot of detail. We are expecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1706" target="_blank">00:28:26.640</a></span> | <span class="t">log or ln of 1/65 and negative of that. So we're expecting the loss to be about 4.17,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1717" target="_blank">00:28:37.280</a></span> | <span class="t">but we're getting 4.87. And so that's telling us that the initial predictions are not super diffuse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1722" target="_blank">00:28:42.880</a></span> | <span class="t">They've got a little bit of entropy, and so we're guessing wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1725" target="_blank">00:28:45.680</a></span> | <span class="t">So yes, but actually we are able to evaluate the loss. Okay, so now that we can evaluate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1734" target="_blank">00:28:54.000</a></span> | <span class="t">quality of the model on some data, we'd like to also be able to generate from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1739" target="_blank">00:28:59.120</a></span> | <span class="t">So let's do the generation. Now, I'm going to go again a little bit faster here because I covered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1743" target="_blank">00:29:03.680</a></span> | <span class="t">all this already in previous videos. So here's a generate function for the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1752" target="_blank">00:29:12.240</a></span> | <span class="t">So we take the same kind of input, idx here, and basically this is the current</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1760" target="_blank">00:29:20.400</a></span> | <span class="t">context of some characters in some batch. So it's also b by t, and the job of generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1769" target="_blank">00:29:29.040</a></span> | <span class="t">is to basically take this b by t and extend it to be b by t plus 1, plus 2, plus 3. And so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1773" target="_blank">00:29:33.920</a></span> | <span class="t">just basically it continues the generation in all the batch dimensions in the time dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1779" target="_blank">00:29:39.120</a></span> | <span class="t">So that's its job, and it will do that for max new tokens. So you can see here on the bottom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1784" target="_blank">00:29:44.240</a></span> | <span class="t">there's going to be some stuff here, but on the bottom, whatever is predicted is concatenated on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1789" target="_blank">00:29:49.760</a></span> | <span class="t">top of the previous idx along the first dimension, which is the time dimension, to create a b by t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1795" target="_blank">00:29:55.120</a></span> | <span class="t">plus 1. So that becomes a new idx. So the job of generate is to take a b by t and make it a b by t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1801" target="_blank">00:30:01.280</a></span> | <span class="t">plus 1, plus 2, plus 3, as many as we want max new tokens. So this is the generation from the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1808" target="_blank">00:30:08.160</a></span> | <span class="t">Now inside the generation, what are we doing? We're taking the current indices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1812" target="_blank">00:30:12.000</a></span> | <span class="t">we're getting the predictions. So we get those are in the logits, and then the loss here is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1819" target="_blank">00:30:19.200</a></span> | <span class="t">going to be ignored because we're not using that, and we have no targets that are sort of ground</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1824" target="_blank">00:30:24.400</a></span> | <span class="t">truth targets that we're going to be comparing with. Then once we get the logits, we are only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1830" target="_blank">00:30:30.400</a></span> | <span class="t">focusing on the last step. So instead of a b by t by c, we're going to pluck out the negative one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1837" target="_blank">00:30:37.520</a></span> | <span class="t">the last element in the time dimension, because those are the predictions for what comes next.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1841" target="_blank">00:30:41.840</a></span> | <span class="t">So that gives us the logits, which we then convert to probabilities via softmax. And then we use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1847" target="_blank">00:30:47.840</a></span> | <span class="t">torch.multinomial to sample from those probabilities, and we ask PyTorch to give us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1852" target="_blank">00:30:52.080</a></span> | <span class="t">one sample. And so idx next will become a b by 1, because in each one of the batch dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1860" target="_blank">00:31:00.080</a></span> | <span class="t">we're going to have a single prediction for what comes next. So this num_samples equals 1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1864" target="_blank">00:31:04.560</a></span> | <span class="t">will make this b a 1. And then we're going to take those integers that come from the sampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1870" target="_blank">00:31:10.400</a></span> | <span class="t">process according to the probability distribution given here, and those integers get just concatenated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1875" target="_blank">00:31:15.360</a></span> | <span class="t">on top of the current sort of like running stream of integers. And this gives us a b by t plus 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1880" target="_blank">00:31:20.720</a></span> | <span class="t">And then we can return that. Now one thing here is you see how I'm calling self of idx, which will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1888" target="_blank">00:31:28.720</a></span> | <span class="t">end up going to the forward function. I'm not providing any targets, so currently this would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1893" target="_blank">00:31:33.520</a></span> | <span class="t">give an error because targets is sort of like not given. So targets has to be optional. So targets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1900" target="_blank">00:31:40.480</a></span> | <span class="t">is none by default. And then if targets is none, then there's no loss to create. So it's just loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1907" target="_blank">00:31:47.680</a></span> | <span class="t">is none. But else all of this happens and we can create a loss. So this will make it so if we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1915" target="_blank">00:31:55.840</a></span> | <span class="t">the targets, we provide them and get a loss. If we have no targets, we'll just get the logits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1921" target="_blank">00:32:01.360</a></span> | <span class="t">So this here will generate from the model. And let's take that for a ride now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1927" target="_blank">00:32:07.200</a></span> | <span class="t">Oops. So I have another code chunk here, which will generate for the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1933" target="_blank">00:32:13.280</a></span> | <span class="t">from the model. And OK, this is kind of crazy. So maybe let me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1936" target="_blank">00:32:16.720</a></span> | <span class="t">let me break this down. So these are the idx, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1940" target="_blank">00:32:20.960</a></span> | <span class="t">I'm creating a batch will be just one time will be just one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1949" target="_blank">00:32:29.600</a></span> | <span class="t">So I'm creating a little one by one tensor and it's holding a zero and the D type, the data type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1955" target="_blank">00:32:35.520</a></span> | <span class="t">is integer. So zero is going to be how we kick off the generation. And remember that zero is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1961" target="_blank">00:32:41.920</a></span> | <span class="t">the element standing for a new line character. So it's kind of like a reasonable thing to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1967" target="_blank">00:32:47.520</a></span> | <span class="t">feed in as the very first character in a sequence to be the new line. So it's going to be idx,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1974" target="_blank">00:32:54.080</a></span> | <span class="t">which we're going to feed in here. Then we're going to ask for 100 tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1978" target="_blank">00:32:58.640</a></span> | <span class="t">and then end that generate will continue that. Now, because generate works on the level of batches,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1986" target="_blank">00:33:06.160</a></span> | <span class="t">we then have to index into the zero throw to basically unplug the single batch dimension</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1993" target="_blank">00:33:13.760</a></span> | <span class="t">that exists. And then that gives us a time steps, just a one dimensional array of all the indices,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2001" target="_blank">00:33:21.600</a></span> | <span class="t">which we will convert to simple Python list from PyTorch tensor so that that can feed into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2008" target="_blank">00:33:28.560</a></span> | <span class="t">our decode function and convert those integers into text. So let me bring this back and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2015" target="_blank">00:33:35.680</a></span> | <span class="t">generating a hundred tokens. Let's run. And here's the generation that we achieved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2021" target="_blank">00:33:41.200</a></span> | <span class="t">So obviously it's garbage. And the reason it's garbage is because this is a totally random model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2026" target="_blank">00:33:46.400</a></span> | <span class="t">So next up, we're going to want to train this model. Now, one more thing I wanted to point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2030" target="_blank">00:33:50.320</a></span> | <span class="t">out here is this function is written to be general, but it's kind of like ridiculous right now because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2038" target="_blank">00:33:58.000</a></span> | <span class="t">we're feeding in all this, we're building out this context and we're concatenating it all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2042" target="_blank">00:34:02.800</a></span> | <span class="t">And we're always feeding it all into the model. But that's kind of ridiculous because this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2048" target="_blank">00:34:08.560</a></span> | <span class="t">just a simple bigram model. So to make, for example, this prediction about K,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2051" target="_blank">00:34:11.920</a></span> | <span class="t">we only needed this W, but actually what we fed into the model is we fed the entire sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2057" target="_blank">00:34:17.520</a></span> | <span class="t">And then we only looked at the very last piece and predicted K. So the only reason I'm writing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2063" target="_blank">00:34:23.440</a></span> | <span class="t">it in this way is because right now this is a bigram model, but I'd like to keep this function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2068" target="_blank">00:34:28.320</a></span> | <span class="t">fixed. And I'd like it to work later when our characters actually basically look further in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2076" target="_blank">00:34:36.000</a></span> | <span class="t">the history. And so right now the history is not used. So this looks silly, but eventually the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2081" target="_blank">00:34:41.120</a></span> | <span class="t">history will be used. And so that's why we want to do it this way. So just a quick comment on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2086" target="_blank">00:34:46.720</a></span> | <span class="t">So now we see that this is random. So let's train the model. So it becomes a bit less random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2093" target="_blank">00:34:53.280</a></span> | <span class="t">Okay, let's now train the model. So first what I'm going to do is I'm going to create a PyTorch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2097" target="_blank">00:34:57.760</a></span> | <span class="t">optimization object. So here we are using the optimizer AdamW. Now in the Makemore series,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2105" target="_blank">00:35:05.360</a></span> | <span class="t">we've only ever used stochastic gradient descent, the simplest possible optimizer, which you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2109" target="_blank">00:35:09.520</a></span> | <span class="t">using the SGD instead. But I want to use Adam, which is a much more advanced and popular optimizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2114" target="_blank">00:35:14.880</a></span> | <span class="t">and it works extremely well. For a typical good setting for the learning rate is roughly 3e-4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2121" target="_blank">00:35:21.760</a></span> | <span class="t">But for very, very small networks, like is the case here, you can get away with much,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2125" target="_blank">00:35:25.520</a></span> | <span class="t">much higher learning rates, 1e-3 or even higher probably. But let me create the optimizer object,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2131" target="_blank">00:35:31.280</a></span> | <span class="t">which will basically take the gradients and update the parameters using the gradients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2136" target="_blank">00:35:36.400</a></span> | <span class="t">And then here, our batch size up above was only 4. So let me actually use something bigger,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2142" target="_blank">00:35:42.720</a></span> | <span class="t">let's say 32. And then for some number of steps, we are sampling a new batch of data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2148" target="_blank">00:35:48.480</a></span> | <span class="t">we're evaluating the loss, we're zeroing out all the gradients from the previous step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2153" target="_blank">00:35:53.200</a></span> | <span class="t">getting the gradients for all the parameters, and then using those gradients to update our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2157" target="_blank">00:35:57.920</a></span> | <span class="t">parameters. So typical training loop, as we saw in the Makemore series. So let me now run this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2164" target="_blank">00:36:04.400</a></span> | <span class="t">for say 100 iterations and let's see what kind of losses we're going to get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2168" target="_blank">00:36:08.400</a></span> | <span class="t">So we started around 4.7 and now we're getting down to like 4.6, 4.5, etc. So the optimization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2178" target="_blank">00:36:18.320</a></span> | <span class="t">is definitely happening, but let's sort of try to increase the number of iterations and only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2184" target="_blank">00:36:24.800</a></span> | <span class="t">print at the end, because we probably will not train for longer. Okay, so we're down to 3.6,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2191" target="_blank">00:36:31.840</a></span> | <span class="t">roughly. Roughly down to 3. This is the most janky optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2207" target="_blank">00:36:47.200</a></span> | <span class="t">Okay, it's working. Let's just do 10,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2209" target="_blank">00:36:49.040</a></span> | <span class="t">And then from here, we want to copy this. And hopefully, we're going to get something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2217" target="_blank">00:36:57.280</a></span> | <span class="t">reasonable. And of course, it's not going to be Shakespeare from a bigram model, but at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2221" target="_blank">00:37:01.280</a></span> | <span class="t">we see that the loss is improving. And hopefully, we're expecting something a bit more reasonable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2226" target="_blank">00:37:06.480</a></span> | <span class="t">Okay, so we're down at about 2.5-ish. Let's see what we get. Okay, dramatic improvements,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2233" target="_blank">00:37:13.600</a></span> | <span class="t">certainly on what we had here. So let me just increase the number of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2238" target="_blank">00:37:18.240</a></span> | <span class="t">Okay, so we see that we're starting to get something at least like reasonable-ish.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2243" target="_blank">00:37:23.680</a></span> | <span class="t">Certainly not Shakespeare, but the model is making progress.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2250" target="_blank">00:37:30.640</a></span> | <span class="t">So that is the simplest possible model. So now what I'd like to do is...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2255" target="_blank">00:37:35.440</a></span> | <span class="t">Obviously, this is a very simple model because the tokens are not talking to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2261" target="_blank">00:37:41.600</a></span> | <span class="t">So given the previous context of whatever was generated, we're only looking at the very last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2266" target="_blank">00:37:46.160</a></span> | <span class="t">character to make the predictions about what comes next. So now these tokens have to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2271" target="_blank">00:37:51.280</a></span> | <span class="t">talking to each other and figuring out what is in the context so that they can make better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2276" target="_blank">00:37:56.000</a></span> | <span class="t">predictions for what comes next. And this is how we're going to kick off the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2280" target="_blank">00:38:00.400</a></span> | <span class="t">Okay, so next, I took the code that we developed in this Jupyter notebook,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2283" target="_blank">00:38:03.360</a></span> | <span class="t">and I converted it to be a script. And I'm doing this because I just want to simplify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2288" target="_blank">00:38:08.640</a></span> | <span class="t">our intermediate work into just the final product that we have at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2291" target="_blank">00:38:11.760</a></span> | <span class="t">So in the top here, I put all the hyperparameters that we've defined.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2296" target="_blank">00:38:16.640</a></span> | <span class="t">I introduced a few, and I'm going to speak to that in a little bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2299" target="_blank">00:38:19.360</a></span> | <span class="t">Otherwise, a lot of this should be recognizable. Reproducibility, read data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2305" target="_blank">00:38:25.200</a></span> | <span class="t">get the encoder and the decoder, create the train and test splits, use the data loader</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2311" target="_blank">00:38:31.440</a></span> | <span class="t">that gets a batch of the inputs and targets. This is new, and I'll talk about it in a second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2318" target="_blank">00:38:38.800</a></span> | <span class="t">Now, this is the background language model that we developed, and it can forward and give us a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2323" target="_blank">00:38:43.120</a></span> | <span class="t">logits and loss, and it can generate. And then here, we are creating the optimizer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2328" target="_blank">00:38:48.720</a></span> | <span class="t">and this is the training loop. So everything here should look pretty familiar. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2334" target="_blank">00:38:54.480</a></span> | <span class="t">some of the small things that I added, number one, I added the ability to run on a GPU if you have it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2340" target="_blank">00:39:00.560</a></span> | <span class="t">So if you have a GPU, then this will use CUDA instead of just CPU, and everything will be a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2345" target="_blank">00:39:05.520</a></span> | <span class="t">lot more faster. Now, when device becomes CUDA, then we need to make sure that when we load the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2351" target="_blank">00:39:11.040</a></span> | <span class="t">data, we move it to device. When we create the model, we want to move the model parameters to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2357" target="_blank">00:39:17.840</a></span> | <span class="t">device. So as an example, here we have the NN embedding table, and it's got a dot weight inside</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2364" target="_blank">00:39:24.080</a></span> | <span class="t">it, which stores the lookup table. So that would be moved to the GPU so that all the calculations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2370" target="_blank">00:39:30.160</a></span> | <span class="t">here happen on the GPU, and they can be a lot faster. And then finally here, when I'm creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2375" target="_blank">00:39:35.120</a></span> | <span class="t">the context that feeds it to generate, I have to make sure that I create on the device.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2379" target="_blank">00:39:39.200</a></span> | <span class="t">Number two, what I introduced is the fact that here in the training loop,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2385" target="_blank">00:39:45.680</a></span> | <span class="t">here I was just printing the loss.item inside the training loop, but this is a very noisy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2393" target="_blank">00:39:53.840</a></span> | <span class="t">measurement of the current loss because every batch will be more or less lucky.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2398" target="_blank">00:39:58.400</a></span> | <span class="t">And so what I want to do usually is I have an estimate loss function, and the estimate loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2405" target="_blank">00:40:05.360</a></span> | <span class="t">basically then goes up here, and it averages up the loss over multiple batches. So in particular,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2414" target="_blank">00:40:14.560</a></span> | <span class="t">we're going to iterate eval_iter_times, and we're going to basically get our loss, and then we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2419" target="_blank">00:40:19.520</a></span> | <span class="t">going to get the average loss for both splits. And so this will be a lot less noisy. So here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2425" target="_blank">00:40:25.280</a></span> | <span class="t">when we call the estimate loss, we're going to report the pretty accurate train and validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2430" target="_blank">00:40:30.240</a></span> | <span class="t">loss. Now, when we come back up, you'll notice a few things here. I'm setting the model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2435" target="_blank">00:40:35.680</a></span> | <span class="t">evaluation phase, and down here I'm resetting it back to training phase. Now, right now for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2441" target="_blank">00:40:41.520</a></span> | <span class="t">our model as is, this doesn't actually do anything because the only thing inside this model is this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2446" target="_blank">00:40:46.720</a></span> | <span class="t">nn.embedding, and this network would behave the same in both evaluation mode and training mode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2456" target="_blank">00:40:56.320</a></span> | <span class="t">We have no dropout layers, we have no batch norm layers, etc. But it is a good practice to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2461" target="_blank">00:41:01.040</a></span> | <span class="t">through what mode your neural network is in because some layers will have different behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2466" target="_blank">00:41:06.400</a></span> | <span class="t">at inference time or training time. And there's also this context manager, torch.nograd,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2473" target="_blank">00:41:13.680</a></span> | <span class="t">and this is just telling PyTorch that everything that happens inside this function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2477" target="_blank">00:41:17.280</a></span> | <span class="t">we will not call .backward on. And so PyTorch can be a lot more efficient with its memory use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2483" target="_blank">00:41:23.200</a></span> | <span class="t">because it doesn't have to store all the intermediate variables because we're never</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2487" target="_blank">00:41:27.120</a></span> | <span class="t">going to call backward. And so it can be a lot more memory efficient in that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2491" target="_blank">00:41:31.680</a></span> | <span class="t">So also a good practice to tell PyTorch when we don't intend to do backpropagation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2497" target="_blank">00:41:37.600</a></span> | <span class="t">So right now, this script is about 120 lines of code, and that's kind of our starter code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2504" target="_blank">00:41:44.320</a></span> | <span class="t">I'm calling it bigram.py, and I'm going to release it later. Now running this script</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2509" target="_blank">00:41:49.760</a></span> | <span class="t">gives us output in the terminal, and it looks something like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2513" target="_blank">00:41:53.600</a></span> | <span class="t">It basically, as I ran this code, it was giving me the train loss and the val loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2519" target="_blank">00:41:59.520</a></span> | <span class="t">and we see that we convert to somewhere around 2.5 with the bigram model. And then here's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2524" target="_blank">00:42:04.960</a></span> | <span class="t">sample that we produced at the end. And so we have everything packaged up in the script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2530" target="_blank">00:42:10.640</a></span> | <span class="t">and we're in a good position now to iterate on this. Okay, so we are almost ready to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2535" target="_blank">00:42:15.280</a></span> | <span class="t">writing our very first self-attention block for processing these tokens. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2541" target="_blank">00:42:21.280</a></span> | <span class="t">before we actually get there, I want to get you used to a mathematical trick that is used in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2546" target="_blank">00:42:26.800</a></span> | <span class="t">self-attention inside a transformer, and is really just at the heart of an efficient implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2552" target="_blank">00:42:32.880</a></span> | <span class="t">of self-attention. And so I want to work with this toy example to just get you used to this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2557" target="_blank">00:42:37.360</a></span> | <span class="t">operation, and then it's going to make it much more clear once we actually get to it in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2563" target="_blank">00:42:43.360</a></span> | <span class="t">script again. So let's create a b_t_t_c, where b, t, and c are just 4, 8, and 2 in this toy example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2570" target="_blank">00:42:50.240</a></span> | <span class="t">And these are basically channels, and we have batches, and we have the time component,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2576" target="_blank">00:42:56.640</a></span> | <span class="t">and we have some information at each point in the sequence, so c. Now, what we would like to do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2583" target="_blank">00:43:03.280</a></span> | <span class="t">we would like these tokens, so we have up to 8 tokens here in a batch, and these 8 tokens are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2589" target="_blank">00:43:09.600</a></span> | <span class="t">currently not talking to each other, and we would like them to talk to each other. We'd like to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2593" target="_blank">00:43:13.040</a></span> | <span class="t">couple them. And in particular, we want to couple them in a very specific way. So the token, for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2600" target="_blank">00:43:20.960</a></span> | <span class="t">example, at the fifth location, it should not communicate with tokens in the sixth, seventh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2606" target="_blank">00:43:26.000</a></span> | <span class="t">and eighth location, because those are future tokens in the sequence. The token on the fifth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2611" target="_blank">00:43:31.760</a></span> | <span class="t">location should only talk to the one in the fourth, third, second, and first. So information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2617" target="_blank">00:43:37.600</a></span> | <span class="t">only flows from previous context to the current time step, and we cannot get any information from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2622" target="_blank">00:43:42.640</a></span> | <span class="t">the future, because we are about to try to predict the future. So what is the easiest way for tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2629" target="_blank">00:43:49.600</a></span> | <span class="t">to communicate? The easiest way, I would say, is if we're a fifth token and I'd like to communicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2636" target="_blank">00:43:56.640</a></span> | <span class="t">with my past, the simplest way we can do that is to just do an average of all the preceding elements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2646" target="_blank">00:44:06.000</a></span> | <span class="t">So for example, if I'm the fifth token, I would like to take the channels that make up, that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2652" target="_blank">00:44:12.080</a></span> | <span class="t">information at my step, but then also the channels from the fourth step, third step, second step,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2656" target="_blank">00:44:16.880</a></span> | <span class="t">and the first step, I'd like to average those up, and then that would become sort of like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2661" target="_blank">00:44:21.200</a></span> | <span class="t">feature vector that summarizes me in the context of my history. Now, of course, just doing a sum,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2667" target="_blank">00:44:27.360</a></span> | <span class="t">or like an average, is an extremely weak form of interaction. Like this communication is extremely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2672" target="_blank">00:44:32.160</a></span> | <span class="t">lossy. We've lost a ton of information about the spatial arrangements of all those tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2676" target="_blank">00:44:36.160</a></span> | <span class="t">but that's okay for now. We'll see how we can bring that information back later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2680" target="_blank">00:44:40.080</a></span> | <span class="t">For now, what we would like to do is, for every single batch element independently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2685" target="_blank">00:44:45.920</a></span> | <span class="t">for every t-th token in that sequence, we'd like to now calculate the average of all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2692" target="_blank">00:44:52.880</a></span> | <span class="t">vectors in all the previous tokens, and also at this token. So let's write that out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2698" target="_blank">00:44:58.320</a></span> | <span class="t">I have a small snippet here, and instead of just fumbling around,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2702" target="_blank">00:45:02.720</a></span> | <span class="t">let me just copy paste it and talk to it. So in other words, we're going to create x,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2709" target="_blank">00:45:09.760</a></span> | <span class="t">and B-O-W is short for bag of words, because bag of words is kind of like a term that people use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2717" target="_blank">00:45:17.360</a></span> | <span class="t">when you are just averaging up things. So this is just a bag of words. Basically, there's a word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2721" target="_blank">00:45:21.760</a></span> | <span class="t">stored on every one of these eight locations, and we're doing a bag of words, we're just averaging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2726" target="_blank">00:45:26.080</a></span> | <span class="t">So in the beginning, we're going to say that it's just initialized at zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2730" target="_blank">00:45:30.480</a></span> | <span class="t">and then I'm doing a for loop here, so we're not being efficient yet. That's coming. But for now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2734" target="_blank">00:45:34.800</a></span> | <span class="t">we're just iterating over all the batch dimensions independently, iterating over time, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2740" target="_blank">00:45:40.560</a></span> | <span class="t">the previous tokens are at this batch dimension, and then everything up to and including the t-th</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2748" target="_blank">00:45:48.720</a></span> | <span class="t">token. So when we slice out x in this way, xprev becomes of shape how many t elements there were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2758" target="_blank">00:45:58.640</a></span> | <span class="t">in the past, and then of course, c, so all the two-dimensional information from these little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2763" target="_blank">00:46:03.600</a></span> | <span class="t">tokens. So that's the previous sort of chunk of tokens from my current sequence. And then I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2772" target="_blank">00:46:12.160</a></span> | <span class="t">just doing the average, or the mean, over the zero of dimensions. So I'm averaging out the time here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2777" target="_blank">00:46:17.520</a></span> | <span class="t">and I'm just going to get a little c one-dimensional vector, which I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2782" target="_blank">00:46:22.080</a></span> | <span class="t">store in x bag of words. So I can run this, and this is not going to be very informative, because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2791" target="_blank">00:46:31.040</a></span> | <span class="t">let's see, so this is x of zero, so this is the zeroth batch element, and then xbow at zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2796" target="_blank">00:46:36.400</a></span> | <span class="t">Now you see how at the first location here, you see that the two are equal, and that's because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2804" target="_blank">00:46:44.320</a></span> | <span class="t">we're just doing an average of this one token. But here, this one is now an average of these two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2810" target="_blank">00:46:50.560</a></span> | <span class="t">and now this one is an average of these three, and so on. And this last one is the average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2821" target="_blank">00:47:01.120</a></span> | <span class="t">of all of these elements, so vertical average, just averaging up all the tokens, now gives this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2826" target="_blank">00:47:06.240</a></span> | <span class="t">outcome here. So this is all well and good, but this is very inefficient. Now the trick is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2833" target="_blank">00:47:13.040</a></span> | <span class="t">we can be very, very efficient about doing this using matrix multiplication. So that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2838" target="_blank">00:47:18.000</a></span> | <span class="t">mathematical trick, and let me show you what I mean. Let's work with the toy example here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2842" target="_blank">00:47:22.000</a></span> | <span class="t">Let me run it, and I'll explain. I have a simple matrix here that is a three by three of all ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2849" target="_blank">00:47:29.920</a></span> | <span class="t">A matrix B of just random numbers, and it's a three by two, and a matrix C, which will be three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2854" target="_blank">00:47:34.800</a></span> | <span class="t">by three multiply three by two, which will give out a three by two. So here we're just using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2860" target="_blank">00:47:40.240</a></span> | <span class="t">matrix multiplication. So A multiply B gives us C. Okay, so how are these numbers in C</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2870" target="_blank">00:47:50.080</a></span> | <span class="t">achieved, right? So this number in the top left is the first row of A dot product with the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2878" target="_blank">00:47:58.320</a></span> | <span class="t">column of B. And since all the row of A right now is all just ones, then the dot product here with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2885" target="_blank">00:48:05.680</a></span> | <span class="t">this column of B is just going to do a sum of this column. So two plus six plus six is 14.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2892" target="_blank">00:48:12.400</a></span> | <span class="t">The element here in the output of C is also the first column here, the first row of A,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2898" target="_blank">00:48:18.320</a></span> | <span class="t">multiplied now with the second column of B. So seven plus four plus five is 16. Now you see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2905" target="_blank">00:48:25.280</a></span> | <span class="t">there's repeating elements here. So this 14 again is because this row is again all ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2909" target="_blank">00:48:29.520</a></span> | <span class="t">and it's multiplying the first column of B. So we get 14. And this one is, and so on. So this last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2915" target="_blank">00:48:35.360</a></span> | <span class="t">number here is the last row dot product last column. Now the trick here is the following.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2922" target="_blank">00:48:42.400</a></span> | <span class="t">This is just a boring number of, it's just a boring array of all ones. But Torch has this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2929" target="_blank">00:48:49.840</a></span> | <span class="t">function called trill, which is short for a triangular, something like that. And you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2936" target="_blank">00:48:56.880</a></span> | <span class="t">wrap it in Torch dot ones, and it will just return the lower triangular portion of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2941" target="_blank">00:49:01.520</a></span> | <span class="t">So now it will basically zero out these guys here. So we just get the lower triangular part.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2949" target="_blank">00:49:09.520</a></span> | <span class="t">Well, what happens if we do that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2951" target="_blank">00:49:11.680</a></span> | <span class="t">So now we'll have A like this and B like this. And now what are we getting here in C?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2960" target="_blank">00:49:20.240</a></span> | <span class="t">Well, what is this number? Well, this is the first row times the first column. And because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2965" target="_blank">00:49:25.680</a></span> | <span class="t">this is zeros, these elements here are now ignored. So we just get a two. And then this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2972" target="_blank">00:49:32.720</a></span> | <span class="t">number here is the first row times the second column. And because these are zeros, they get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2977" target="_blank">00:49:37.760</a></span> | <span class="t">ignored, and it's just seven. The seven multiplies this one. But look what happened here. Because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2983" target="_blank">00:49:43.520</a></span> | <span class="t">this is one and then zeros, what ended up happening is we're just plucking out the row,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2988" target="_blank">00:49:48.800</a></span> | <span class="t">this row of B, and that's what we got. Now here we have one, one, zero. So here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=2995" target="_blank">00:49:55.840</a></span> | <span class="t">one, one, zero dot product with these two columns will now give us two plus six, which is eight,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3000" target="_blank">00:50:00.880</a></span> | <span class="t">and seven plus four, which is 11. And because this is one, one, one, we ended up with the addition</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3007" target="_blank">00:50:07.040</a></span> | <span class="t">of all of them. And so basically, depending on how many ones and zeros we have here, we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3012" target="_blank">00:50:12.720</a></span> | <span class="t">basically doing a sum currently of the variable number of these rows, and that gets deposited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3019" target="_blank">00:50:19.520</a></span> | <span class="t">into C. So currently, we're doing sums because these are ones, but we can also do average,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3025" target="_blank">00:50:25.680</a></span> | <span class="t">right? And you can start to see how we could do average of the rows of B sort of in an incremental</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3032" target="_blank">00:50:32.160</a></span> | <span class="t">fashion. Because we don't have to, we can basically normalize these rows so that they sum to one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3038" target="_blank">00:50:38.400</a></span> | <span class="t">and then we're going to get an average. So if we took A, and then we did A equals A divide,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3043" target="_blank">00:50:43.520</a></span> | <span class="t">torch dot sum of A in the one-th dimension, and then let's keep dim as true. So therefore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3056" target="_blank">00:50:56.800</a></span> | <span class="t">the broadcasting will work out. So if I rerun this, you see now that these rows now sum to one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3063" target="_blank">00:51:03.600</a></span> | <span class="t">So this row is one, this row is 0.5, 0.5 is zero, and here we get one-thirds. And now when we do A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3069" target="_blank">00:51:09.760</a></span> | <span class="t">multiply B, what are we getting? Here we are just getting the first row, first row. Here now we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3076" target="_blank">00:51:16.320</a></span> | <span class="t">getting the average of the first two rows. Okay, so two and six average is four, and four and seven</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3083" target="_blank">00:51:23.920</a></span> | <span class="t">average is 5.5. And on the bottom here, we are now getting the average of these three rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3091" target="_blank">00:51:31.360</a></span> | <span class="t">So the average of all of elements of B are now deposited here. And so you can see that by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3097" target="_blank">00:51:37.600</a></span> | <span class="t">manipulating these elements of this multiplying matrix, and then multiplying it with any given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3104" target="_blank">00:51:44.400</a></span> | <span class="t">matrix, we can do these averages in this incremental fashion. Because we just get,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3109" target="_blank">00:51:49.680</a></span> | <span class="t">and we can manipulate that based on the elements of A. Okay, so that's very convenient. So let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3116" target="_blank">00:51:56.640</a></span> | <span class="t">swing back up here and see how we can vectorize this and make it much more efficient using what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3120" target="_blank">00:52:00.880</a></span> | <span class="t">we've learned. So in particular, we are going to produce an array A, but here I'm going to call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3127" target="_blank">00:52:07.840</a></span> | <span class="t">"weigh," short for "weights." But this is our A, and this is how much of every row we want to average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3135" target="_blank">00:52:15.920</a></span> | <span class="t">up. And it's going to be an average because you can see that these rows sum to one. So this is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3141" target="_blank">00:52:21.600</a></span> | <span class="t">A, and then our B in this example, of course, is X. So what's going to happen here now is that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3149" target="_blank">00:52:29.520</a></span> | <span class="t">are going to have an expo two. And this expo two is going to be weigh multiplying our X.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3158" target="_blank">00:52:38.000</a></span> | <span class="t">So let's think this through. Weigh is T by T, and this is matrix multiplying in PyTorch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3165" target="_blank">00:52:45.200</a></span> | <span class="t">a B by T by C. And it's giving us what shape. So PyTorch will come here and it will see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3173" target="_blank">00:52:53.360</a></span> | <span class="t">these shapes are not the same. So it will create a batch dimension here. And this is a batch matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3179" target="_blank">00:52:59.280</a></span> | <span class="t">multiply. And so it will apply this matrix multiplication in all the batch elements in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3185" target="_blank">00:53:05.040</a></span> | <span class="t">parallel and individually. And then for each batch element, there will be a T by T multiplying T by C</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3191" target="_blank">00:53:11.760</a></span> | <span class="t">exactly as we had below. So this will now create B by T by C, and expo two will now become identical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3204" target="_blank">00:53:24.480</a></span> | <span class="t">to expo. So we can see that torch.allclose of expo and expo two should be true. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3215" target="_blank">00:53:35.360</a></span> | <span class="t">so this kind of like convinces us that these are in fact the same. So expo and expo two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3224" target="_blank">00:53:44.880</a></span> | <span class="t">if I just print them, okay, we're not going to be able to just stare it down. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3232" target="_blank">00:53:52.960</a></span> | <span class="t">well, let me try expo basically just at the zeroth element and expo two at the zeroth element. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3237" target="_blank">00:53:57.360</a></span> | <span class="t">just the first batch, and we should see that this and that should be identical, which they are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3242" target="_blank">00:54:02.400</a></span> | <span class="t">Right. So what happened here? The trick is we were able to use batch matrix multiply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3248" target="_blank">00:54:08.720</a></span> | <span class="t">to do this aggregation, really. And it's a weighted aggregation. And the weights are specified in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3258" target="_blank">00:54:18.160</a></span> | <span class="t">T by T array. And we're basically doing weighted sums. And these weighted sums are according to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3265" target="_blank">00:54:25.920</a></span> | <span class="t">the weights inside here, they take on sort of this triangular form. And so that means that a token at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3272" target="_blank">00:54:32.640</a></span> | <span class="t">the T dimension will only get sort of information from the tokens preceding it. So that's exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3280" target="_blank">00:54:40.240</a></span> | <span class="t">what we want. And finally, I would like to rewrite it in one more way. And we're going to see why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3285" target="_blank">00:54:45.520</a></span> | <span class="t">that's useful. So this is the third version. And it's also identical to the first and second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3291" target="_blank">00:54:51.280</a></span> | <span class="t">But let me talk through it. It uses softmax. So trill here is this matrix, lower triangular ones,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3300" target="_blank">00:55:00.560</a></span> | <span class="t">way begins as all zero. Okay, so if I just print way in the beginning, it's all zero,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3309" target="_blank">00:55:09.520</a></span> | <span class="t">then I use masked fill. So what this is doing is way dot masked fill, it's all zeros. And I'm saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3317" target="_blank">00:55:17.840</a></span> | <span class="t">for all the elements where trill is equal to equal zero, make them be negative infinity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3323" target="_blank">00:55:23.760</a></span> | <span class="t">So all the elements where trill is zero will become negative infinity now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3328" target="_blank">00:55:28.080</a></span> | <span class="t">So this is what we get. And then the final one here is softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3336" target="_blank">00:55:36.240</a></span> | <span class="t">So if I take a softmax along every single, so dim is negative one, so along every single row,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3340" target="_blank">00:55:40.800</a></span> | <span class="t">if I do a softmax, what is that going to do? Well, softmax is also like a normalization operation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3352" target="_blank">00:55:52.160</a></span> | <span class="t">right? And so spoiler alert, you get the exact same matrix. Let me bring back the softmax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3359" target="_blank">00:55:59.120</a></span> | <span class="t">And recall that in softmax, we're going to exponentiate every single one of these.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3364" target="_blank">00:56:04.720</a></span> | <span class="t">And then we're going to divide by the sum. And so if we exponentiate every single element here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3369" target="_blank">00:56:09.760</a></span> | <span class="t">we're going to get a one. And here we're going to get basically zero, zero, zero, zero, everywhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3375" target="_blank">00:56:15.040</a></span> | <span class="t">else. And then when we normalize, we just get one. Here, we're going to get one, one, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3380" target="_blank">00:56:20.960</a></span> | <span class="t">zeros. And the softmax will again divide, and this will give us 0.5, 0.5, and so on. And so this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3387" target="_blank">00:56:27.680</a></span> | <span class="t">also the same way to produce this mask. Now, the reason that this is a bit more interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3394" target="_blank">00:56:34.560</a></span> | <span class="t">and the reason we're going to end up using it in self-attention, is that these weights here begin</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3401" target="_blank">00:56:41.120</a></span> | <span class="t">with zero. And you can think of this as like an interaction strength, or like an affinity. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3407" target="_blank">00:56:47.600</a></span> | <span class="t">basically, it's telling us how much of each token from the past do we want to aggregate and average</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3414" target="_blank">00:56:54.720</a></span> | <span class="t">up. And then this line is saying, tokens from the past cannot communicate. By setting them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3422" target="_blank">00:57:02.160</a></span> | <span class="t">negative infinity, we're saying that we will not aggregate anything from those tokens. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3428" target="_blank">00:57:08.000</a></span> | <span class="t">basically, this then goes through softmax, and through the weighted, and this is the aggregation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3431" target="_blank">00:57:11.840</a></span> | <span class="t">through matrix multiplication. And so what this is now is, you can think of these as, these zeros</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3439" target="_blank">00:57:19.920</a></span> | <span class="t">are currently just set by us to be zero. But a quick preview is that these affinities between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3446" target="_blank">00:57:26.240</a></span> | <span class="t">the tokens are not going to be just constant at zero, they're going to be data dependent. These</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3451" target="_blank">00:57:31.280</a></span> | <span class="t">tokens are going to start looking at each other, and some tokens will find other tokens more or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3455" target="_blank">00:57:35.920</a></span> | <span class="t">less interesting. And depending on what their values are, they're going to find each other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3460" target="_blank">00:57:40.880</a></span> | <span class="t">interesting to different amounts, and I'm going to call those affinities, I think. And then here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3465" target="_blank">00:57:45.680</a></span> | <span class="t">we are saying, the future cannot communicate with the past. We're going to clamp them. And then when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3471" target="_blank">00:57:51.440</a></span> | <span class="t">we normalize and sum, we're going to aggregate their values, depending on how interesting they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3477" target="_blank">00:57:57.120</a></span> | <span class="t">find each other. And so that's the preview for self-attention. And basically, long story short</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3483" target="_blank">00:58:03.280</a></span> | <span class="t">from this entire section is that you can do weighted aggregations of your past elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3489" target="_blank">00:58:09.440</a></span> | <span class="t">by using matrix multiplication of a lower triangular fashion. And then the elements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3496" target="_blank">00:58:16.640</a></span> | <span class="t">here in the lower triangular part are telling you how much of each element fuses into this position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3502" target="_blank">00:58:22.480</a></span> | <span class="t">So we're going to use this trick now to develop the self-attention block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3506" target="_blank">00:58:26.240</a></span> | <span class="t">So first, let's get some quick preliminaries out of the way. First, the thing I'm kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3511" target="_blank">00:58:31.200</a></span> | <span class="t">bothered by is that you see how we're passing in vocab size into the constructor? There's no need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3515" target="_blank">00:58:35.280</a></span> | <span class="t">to do that because vocab size is already defined up top as a global variable. So there's no need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3519" target="_blank">00:58:39.840</a></span> | <span class="t">to pass this stuff around. Next, what I want to do is I don't want to actually create, I want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3526" target="_blank">00:58:46.160</a></span> | <span class="t">create like a level of indirection here where we don't directly go to the embedding for the logits,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3531" target="_blank">00:58:51.920</a></span> | <span class="t">but instead we go through this intermediate phase because we're going to start making that bigger.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3536" target="_blank">00:58:56.400</a></span> | <span class="t">So let me introduce a new variable, nembed. It's short for number of embedding dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3543" target="_blank">00:59:03.520</a></span> | <span class="t">So nembed here will be, say, 32. That was a suggestion from GitHub Copilot, by the way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3551" target="_blank">00:59:11.120</a></span> | <span class="t">It also suggested 32, which is a good number. So this is an embedding table and only 32-dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3558" target="_blank">00:59:18.160</a></span> | <span class="t">embeddings. So then here, this is not going to give us logits directly. Instead, this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3563" target="_blank">00:59:23.760</a></span> | <span class="t">to give us token embeddings. That's what I'm going to call it. And then to go from the token embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3568" target="_blank">00:59:28.720</a></span> | <span class="t">to the logits, we're going to need a linear layer. So self.lmhead, let's call it, short for language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3574" target="_blank">00:59:34.560</a></span> | <span class="t">modeling head, is nnlinear from nembed up to vocab size. And then when we swing over here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3581" target="_blank">00:59:41.040</a></span> | <span class="t">we're actually going to get the logits by exactly what the Copilot says. Now, we have to be careful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3586" target="_blank">00:59:46.720</a></span> | <span class="t">here because this c and this c are not equal. This is nembed c and this is vocab size. So let's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3595" target="_blank">00:59:55.440</a></span> | <span class="t">say that nembed is equal to c. And then this just creates one spurious layer of interaction through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3602" target="_blank">01:00:02.160</a></span> | <span class="t">a linear layer, but this should basically run. So we see that this runs and this currently looks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3615" target="_blank">01:00:15.600</a></span> | <span class="t">kind of spurious, but we're going to build on top of this. Now, next up. So far, we've taken these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3621" target="_blank">01:00:21.280</a></span> | <span class="t">indices and we've encoded them based on the identity of the tokens inside IDX. The next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3628" target="_blank">01:00:28.320</a></span> | <span class="t">thing that people very often do is that we're not just encoding the identity of these tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3632" target="_blank">01:00:32.800</a></span> | <span class="t">but also their position. So we're going to have a second position embedding table here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3638" target="_blank">01:00:38.160</a></span> | <span class="t">So self.position_embedding_table is an embedding of block size by nembed. And so each position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3644" target="_blank">01:00:44.960</a></span> | <span class="t">from zero to block size minus one will also get its own embedding vector. And then here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3650" target="_blank">01:00:50.400</a></span> | <span class="t">first, let me decode b by t from IDX.shape. And then here, we're also going to have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3656" target="_blank">01:00:56.560</a></span> | <span class="t">pause embedding, which is the positional embedding. And this is tor-arrange. So this will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3662" target="_blank">01:01:02.560</a></span> | <span class="t">basically just integers from zero to t minus one. And all of those integers from zero to t minus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3668" target="_blank">01:01:08.160</a></span> | <span class="t">get embedded through the table to create a t by c. And then here, this gets renamed to just say x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3676" target="_blank">01:01:16.160</a></span> | <span class="t">And x will be the addition of the token embeddings with the positional embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3680" target="_blank">01:01:20.560</a></span> | <span class="t">And here, the broadcasting node will work out. So b by t by c plus t by c, this gets right-aligned,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3687" target="_blank">01:01:27.760</a></span> | <span class="t">a new dimension of one gets added, and it gets broadcasted across batch.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3691" target="_blank">01:01:31.360</a></span> | <span class="t">So at this point, x holds not just the token identities, but the positions at which these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3697" target="_blank">01:01:37.920</a></span> | <span class="t">tokens occur. And this is currently not that useful because, of course, we just have a simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3702" target="_blank">01:01:42.480</a></span> | <span class="t">bigram model. So it doesn't matter if you're in the fifth position, the second position, or wherever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3706" target="_blank">01:01:46.880</a></span> | <span class="t">It's all translation invariant at this stage. So this information currently wouldn't help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3711" target="_blank">01:01:51.200</a></span> | <span class="t">But as we work on the self-attention block, we'll see that this starts to matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3715" target="_blank">01:01:55.520</a></span> | <span class="t">Okay, so now we get the crux of self-attention. So this is probably the most important part of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3723" target="_blank">01:02:03.840</a></span> | <span class="t">this video to understand. We're going to implement a small self-attention for a single individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3729" target="_blank">01:02:09.280</a></span> | <span class="t">head, as they're called. So we start off with where we were. So all of this code is familiar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3734" target="_blank">01:02:14.400</a></span> | <span class="t">So right now, I'm working with an example where I changed the number of channels from 2 to 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3739" target="_blank">01:02:19.920</a></span> | <span class="t">So we have a 4 by 8 arrangement of tokens. And the information at each token is currently 32</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3747" target="_blank">01:02:27.360</a></span> | <span class="t">dimensional. But we just are working with random numbers. Now, we saw here that the code as we had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3754" target="_blank">01:02:34.480</a></span> | <span class="t">it before does a simple weight, simple average of all the past tokens and the current token. So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3762" target="_blank">01:02:42.800</a></span> | <span class="t">just the previous information and current information is just being mixed together in an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3766" target="_blank">01:02:46.080</a></span> | <span class="t">average. And that's what this code currently achieves. And it does so by creating this lower</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3770" target="_blank">01:02:50.800</a></span> | <span class="t">triangular structure, which allows us to mask out this weight matrix that we create. So we mask it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3779" target="_blank">01:02:59.040</a></span> | <span class="t">out and then we normalize it. And currently, when we initialize the affinities between all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3785" target="_blank">01:03:05.040</a></span> | <span class="t">different sort of tokens or nodes, I'm going to use those terms interchangeably. So when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3791" target="_blank">01:03:11.200</a></span> | <span class="t">initialize the affinities between all the different tokens to be 0, then we see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3795" target="_blank">01:03:15.680</a></span> | <span class="t">weight gives us this structure where every single row has these uniform numbers. And so that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3803" target="_blank">01:03:23.760</a></span> | <span class="t">then in this matrix multiply makes it so that we're doing a simple average. Now, we don't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3811" target="_blank">01:03:31.360</a></span> | <span class="t">want this to be all uniform because different tokens will find different other tokens more or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3818" target="_blank">01:03:38.880</a></span> | <span class="t">less interesting. And we want that to be data dependent. So, for example, if I'm a vowel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3822" target="_blank">01:03:42.880</a></span> | <span class="t">then maybe I'm looking for consonants in my past and maybe I want to know what those consonants</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3828" target="_blank">01:03:48.000</a></span> | <span class="t">are and I want that information to flow to me. And so I want to now gather information from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3833" target="_blank">01:03:53.520</a></span> | <span class="t">past, but I want to do it in a data dependent way. And this is the problem that self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3837" target="_blank">01:03:57.840</a></span> | <span class="t">solves. Now, the way self-attention solves this is the following. Every single node or every single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3844" target="_blank">01:04:04.400</a></span> | <span class="t">token at each position will emit two vectors. It will emit a query and it will emit a key.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3853" target="_blank">01:04:13.520</a></span> | <span class="t">Now, the query vector, roughly speaking, is what am I looking for? And the key vector,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3859" target="_blank">01:04:19.200</a></span> | <span class="t">roughly speaking, is what do I contain? And then the way we get affinities between these tokens now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3866" target="_blank">01:04:26.960</a></span> | <span class="t">in a sequence is we basically just do a dot product between the keys and the queries. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3872" target="_blank">01:04:32.880</a></span> | <span class="t">my query dot products with all the keys of all the other tokens and that dot product now becomes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3880" target="_blank">01:04:40.320</a></span> | <span class="t">way. And so if the key and the query are sort of aligned, they will interact to a very high amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3888" target="_blank">01:04:48.880</a></span> | <span class="t">and then I will get to learn more about that specific token as opposed to any other token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3895" target="_blank">01:04:55.040</a></span> | <span class="t">in the sequence. So, let's implement this now. We're going to implement a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3904" target="_blank">01:05:04.560</a></span> | <span class="t">what's called head of self-attention. So, this is just one head. There's a hyperparameter involved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3910" target="_blank">01:05:10.800</a></span> | <span class="t">with these heads, which is the head size. And then here I'm initializing linear modules and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3916" target="_blank">01:05:16.720</a></span> | <span class="t">I'm using bias equals false. So, these are just going to apply a matrix multiply with some fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3921" target="_blank">01:05:21.040</a></span> | <span class="t">weights. And now let me produce a key and queue, k and q, by forwarding these modules on x. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3930" target="_blank">01:05:30.960</a></span> | <span class="t">the size of this will now become b by t by 16 because that is the head size and the same here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3938" target="_blank">01:05:38.640</a></span> | <span class="t">b by t by 16. So, this being the head size. So, you see here that when I forward this linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3949" target="_blank">01:05:49.760</a></span> | <span class="t">on top of my x, all the tokens in all the positions in the b by t arrangement, all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3955" target="_blank">01:05:55.760</a></span> | <span class="t">in parallel and independently produce a key and a query. So, no communication has happened yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3961" target="_blank">01:06:01.040</a></span> | <span class="t">But the communication comes now. All the queries will dot product with all the keys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3966" target="_blank">01:06:06.960</a></span> | <span class="t">So, basically what we want is we want way now or the affinities between these to be query</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3974" target="_blank">01:06:14.480</a></span> | <span class="t">multiplying key. But we have to be careful with, we can't matrix multiply this. We actually need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3979" target="_blank">01:06:19.440</a></span> | <span class="t">to transpose k, but we have to be also careful because these are, when you have the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3985" target="_blank">01:06:25.760</a></span> | <span class="t">dimension. So, in particular, we want to transpose the last two dimensions, dimension negative one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3992" target="_blank">01:06:32.160</a></span> | <span class="t">and dimension negative two. So, negative two, negative one. And so, this matrix multiply now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=3999" target="_blank">01:06:39.840</a></span> | <span class="t">will basically do the following b by t by 16. Matrix multiplies b by 16 by t to give us b by t</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4011" target="_blank">01:06:51.600</a></span> | <span class="t">by t. Right? So, for every row of b, we're now going to have a t square matrix giving us the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4020" target="_blank">01:07:00.960</a></span> | <span class="t">affinities. And these are now the way. So, they're not zeros. They are now coming from this dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4027" target="_blank">01:07:07.120</a></span> | <span class="t">product between the keys and the queries. So, this can now run. I can run this. And the weighted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4033" target="_blank">01:07:13.760</a></span> | <span class="t">aggregation now is a function in a data-dependent manner between the keys and queries of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4038" target="_blank">01:07:18.960</a></span> | <span class="t">nodes. So, just inspecting what happened here, the way takes on this form. And you see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4047" target="_blank">01:07:27.440</a></span> | <span class="t">before way was just a constant. So, it was applied in the same way to all the batch elements. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4053" target="_blank">01:07:33.040</a></span> | <span class="t">now every single batch element will have different sort of way because every single batch element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4058" target="_blank">01:07:38.480</a></span> | <span class="t">contains different tokens at different positions. And so, this is now data-dependent. So, when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4064" target="_blank">01:07:44.480</a></span> | <span class="t">look at just the zeroth row, for example, in the input, these are the weights that came out. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4070" target="_blank">01:07:50.960</a></span> | <span class="t">so, you can see now that they're not just exactly uniform. And in particular, as an example here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4076" target="_blank">01:07:56.320</a></span> | <span class="t">for the last row, this was the eighth token. And the eighth token knows what content it has, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4081" target="_blank">01:08:01.680</a></span> | <span class="t">it knows at what position it's in. And now the eighth token, based on that, creates a query.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4088" target="_blank">01:08:08.400</a></span> | <span class="t">Hey, I'm looking for this kind of stuff. I'm a vowel. I'm on the eighth position. I'm looking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4092" target="_blank">01:08:12.880</a></span> | <span class="t">for any consonants at positions up to four. And then all the nodes get to emit keys. And maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4099" target="_blank">01:08:19.760</a></span> | <span class="t">one of the channels could be I am a consonant, and I am in a position up to four. And that key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4106" target="_blank">01:08:26.080</a></span> | <span class="t">would have a high number in that specific channel. And that's how the query and the key when they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4110" target="_blank">01:08:30.880</a></span> | <span class="t">dark product, they can find each other and create a high affinity. And when they have a high affinity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4115" target="_blank">01:08:35.760</a></span> | <span class="t">like say this token was pretty interesting to this eighth token, when they have a high affinity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4123" target="_blank">01:08:43.680</a></span> | <span class="t">then through the softmax, I will end up aggregating a lot of its information into my position. And so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4129" target="_blank">01:08:49.360</a></span> | <span class="t">I'll get to learn a lot about it. Now, we're looking at way after this has already happened.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4139" target="_blank">01:08:59.120</a></span> | <span class="t">Let me erase this operation as well. So, let me erase the masking and the softmax,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4143" target="_blank">01:09:03.120</a></span> | <span class="t">just to show you the under the hood internals and how that works. So, without the masking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4147" target="_blank">01:09:07.840</a></span> | <span class="t">and the softmax, way comes out like this, right? This is the outputs of the dark products.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4152" target="_blank">01:09:12.320</a></span> | <span class="t">And these are the raw outputs, and they take on values from negative two to positive two,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4157" target="_blank">01:09:17.920</a></span> | <span class="t">et cetera. So, that's the raw interactions and raw affinities between all the nodes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4164" target="_blank">01:09:24.160</a></span> | <span class="t">But now, if I'm a fifth node, I will not want to aggregate anything from the sixth node,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4169" target="_blank">01:09:29.360</a></span> | <span class="t">seventh node, and the eighth node. So, actually, we use the upper triangular masking. So, those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4175" target="_blank">01:09:35.200</a></span> | <span class="t">are not allowed to communicate. And now, we actually want to have a nice distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4181" target="_blank">01:09:41.680</a></span> | <span class="t">So, we don't want to aggregate negative 0.11 of this node. That's crazy. So, instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4186" target="_blank">01:09:46.880</a></span> | <span class="t">we exponentiate and normalize. And now, we get a nice distribution that sums to one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4191" target="_blank">01:09:51.440</a></span> | <span class="t">And this is telling us now in a data-dependent manner how much of information to aggregate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4195" target="_blank">01:09:55.600</a></span> | <span class="t">from any of these tokens in the past. So, that's way, and it's not zeros anymore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4202" target="_blank">01:10:02.160</a></span> | <span class="t">but it's calculated in this way. Now, there's one more part to a single self-attention head.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4210" target="_blank">01:10:10.080</a></span> | <span class="t">And that is that when we do the aggregation, we don't actually aggregate the tokens exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4214" target="_blank">01:10:14.240</a></span> | <span class="t">We aggregate, we produce one more value here, and we call that the value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4221" target="_blank">01:10:21.040</a></span> | <span class="t">So, in the same way that we produced key and query, we're also going to create a value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4224" target="_blank">01:10:24.640</a></span> | <span class="t">And then, here, we don't aggregate x. We calculate a v, which is just achieved by propagating this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4236" target="_blank">01:10:36.400</a></span> | <span class="t">linear on top of x again. And then, we output way multiplied by v. So, v is the elements that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4244" target="_blank">01:10:44.720</a></span> | <span class="t">we aggregate, or the vector that we aggregate, instead of the raw x. And now, of course, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4251" target="_blank">01:10:51.040</a></span> | <span class="t">will make it so that the output here of the single head will be 16-dimensional, because that is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4255" target="_blank">01:10:55.680</a></span> | <span class="t">head size. So, you can think of x as kind of like private information to this token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4261" target="_blank">01:11:01.600</a></span> | <span class="t">if you think about it that way. So, x is kind of private to this token. So, I'm a fifth token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4266" target="_blank">01:11:06.720</a></span> | <span class="t">and I have some identity, and my information is kept in vector x. And now, for the purposes of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4274" target="_blank">01:11:14.400</a></span> | <span class="t">the single head, here's what I'm interested in, here's what I have, and if you find me interesting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4281" target="_blank">01:11:21.200</a></span> | <span class="t">here's what I will communicate to you. And that's stored in v. And so, v is the thing that gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4286" target="_blank">01:11:26.320</a></span> | <span class="t">aggregated for the purposes of this single head between the different nodes. And that's basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4293" target="_blank">01:11:33.840</a></span> | <span class="t">the self-attention mechanism. This is what it does. There are a few notes that I would like to make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4300" target="_blank">01:11:40.080</a></span> | <span class="t">about attention. Number one, attention is a communication mechanism. You can really think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4305" target="_blank">01:11:45.680</a></span> | <span class="t">about it as a communication mechanism where you have a number of nodes in a directed graph,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4310" target="_blank">01:11:50.240</a></span> | <span class="t">where basically you have edges pointed between nodes like this. And what happens is every node</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4316" target="_blank">01:11:56.480</a></span> | <span class="t">has some vector of information, and it gets to aggregate information via a weighted sum from all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4322" target="_blank">01:12:02.160</a></span> | <span class="t">of the nodes that point to it. And this is done in a data-dependent manner, so depending on whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4327" target="_blank">01:12:07.760</a></span> | <span class="t">data is actually stored at each node at any point in time. Now, our graph doesn't look like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4333" target="_blank">01:12:13.840</a></span> | <span class="t">Our graph has a different structure. We have eight nodes because the block size is eight,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4338" target="_blank">01:12:18.240</a></span> | <span class="t">and there's always eight tokens. And the first node is only pointed to by itself. The second</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4345" target="_blank">01:12:25.040</a></span> | <span class="t">node is pointed to by the first node and itself, all the way up to the eighth node, which is pointed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4350" target="_blank">01:12:30.160</a></span> | <span class="t">to by all the previous nodes and itself. And so, that's the structure that our directed graph has,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4356" target="_blank">01:12:36.240</a></span> | <span class="t">or happens to have, in an autoregressive sort of scenario like language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4360" target="_blank">01:12:40.400</a></span> | <span class="t">But in principle, attention can be applied to any arbitrary directed graph, and it's just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4364" target="_blank">01:12:44.560</a></span> | <span class="t">communication mechanism between the nodes. The second node is that, notice that there's no notion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4369" target="_blank">01:12:49.680</a></span> | <span class="t">of space. So, attention simply acts over a set of vectors in this graph. And so, by default,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4376" target="_blank">01:12:56.400</a></span> | <span class="t">these nodes have no idea where they are positioned in the space. And that's why we need to encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4380" target="_blank">01:13:00.480</a></span> | <span class="t">them positionally and sort of give them some information that is anchored to a specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4384" target="_blank">01:13:04.800</a></span> | <span class="t">position so that they sort of know where they are. And this is different than, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4389" target="_blank">01:13:09.840</a></span> | <span class="t">from convolution, because if you run, for example, a convolution operation over some input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4393" target="_blank">01:13:13.840</a></span> | <span class="t">there is a very specific sort of layout of the information in space, and the convolutional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4399" target="_blank">01:13:19.280</a></span> | <span class="t">filters sort of act in space. And so, it's not like an attention. An attention is just a set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4405" target="_blank">01:13:25.920</a></span> | <span class="t">of vectors out there in space. They communicate. And if you want them to have a notion of space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4410" target="_blank">01:13:30.720</a></span> | <span class="t">you need to specifically add it, which is what we've done when we calculated the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4414" target="_blank">01:13:34.480</a></span> | <span class="t">positional encodings and added that information to the vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4420" target="_blank">01:13:40.160</a></span> | <span class="t">The next thing that I hope is very clear is that the elements across the batch dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4424" target="_blank">01:13:44.400</a></span> | <span class="t">which are independent examples, never talk to each other. They're always processed independently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4428" target="_blank">01:13:48.480</a></span> | <span class="t">And this is a batched matrix multiply that applies basically a matrix multiplication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4432" target="_blank">01:13:52.400</a></span> | <span class="t">kind of in parallel across the batch dimension. So, maybe it would be more accurate to say that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4437" target="_blank">01:13:57.280</a></span> | <span class="t">in this analogy of a directed graph, we really have, because the batch size is four,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4442" target="_blank">01:14:02.000</a></span> | <span class="t">we really have four separate pools of eight nodes, and those eight nodes only talk to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4447" target="_blank">01:14:07.200</a></span> | <span class="t">But in total, there's like 32 nodes that are being processed, but there's sort of four separate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4452" target="_blank">01:14:12.480</a></span> | <span class="t">pools of eight. You can look at it that way. The next note is that here in the case of language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4458" target="_blank">01:14:18.240</a></span> | <span class="t">modeling, we have this specific structure of directed graph where the future tokens will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4464" target="_blank">01:14:24.320</a></span> | <span class="t">not communicate to the past tokens. But this doesn't necessarily have to be the constraint</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4468" target="_blank">01:14:28.960</a></span> | <span class="t">in the general case. And in fact, in many cases, you may want to have all of the nodes talk to each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4474" target="_blank">01:14:34.800</a></span> | <span class="t">other fully. So, as an example, if you're doing sentiment analysis or something like that with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4479" target="_blank">01:14:39.200</a></span> | <span class="t">a transformer, you might have a number of tokens and you may want to have them all talk to each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4483" target="_blank">01:14:43.920</a></span> | <span class="t">other fully because later you are predicting, for example, the sentiment of the sentence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4488" target="_blank">01:14:48.320</a></span> | <span class="t">And so, it's okay for these nodes to talk to each other. And so, in those cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4493" target="_blank">01:14:53.440</a></span> | <span class="t">you will use an encoder block of self-attention. And all it means that it's an encoder block is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4499" target="_blank">01:14:59.600</a></span> | <span class="t">that you will delete this line of code, allowing all the nodes to completely talk to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4504" target="_blank">01:15:04.560</a></span> | <span class="t">What we're implementing here is sometimes called a decoder block. And it's called a decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4509" target="_blank">01:15:09.360</a></span> | <span class="t">because it is sort of like decoding language. And it's got this autoregressive format where you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4516" target="_blank">01:15:16.880</a></span> | <span class="t">to mask with the triangular matrix so that nodes from the future never talk to the past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4523" target="_blank">01:15:23.200</a></span> | <span class="t">Because they would give away the answer. And so, basically, in encoder blocks, you would delete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4527" target="_blank">01:15:27.920</a></span> | <span class="t">this, allow all the nodes to talk. In decoder blocks, this will always be present so that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4533" target="_blank">01:15:33.040</a></span> | <span class="t">have this triangular structure. But both are allowed and attention doesn't care. Attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4537" target="_blank">01:15:37.280</a></span> | <span class="t">supports arbitrary connectivity between nodes. The next thing I wanted to comment on is you keep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4541" target="_blank">01:15:41.680</a></span> | <span class="t">hearing me say attention, self-attention, etc. There's actually also something called cross</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4546" target="_blank">01:15:46.400</a></span> | <span class="t">attention. What is the difference? Basically, the reason this attention is self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4553" target="_blank">01:15:53.760</a></span> | <span class="t">is because the keys, queries, and the values are all coming from the same source, from x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4560" target="_blank">01:16:00.240</a></span> | <span class="t">So the same source, x, produces keys, queries, and values. So these nodes are self-attending.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4566" target="_blank">01:16:06.240</a></span> | <span class="t">But in principle, attention is much more general than that. For example, in encoder-decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4571" target="_blank">01:16:11.360</a></span> | <span class="t">transformers, you can have a case where the queries are produced from x, but the keys and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4577" target="_blank">01:16:17.120</a></span> | <span class="t">the values come from a whole separate external source. And sometimes from encoder blocks that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4582" target="_blank">01:16:22.640</a></span> | <span class="t">encode some context that we'd like to condition on. And so the keys and the values will actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4586" target="_blank">01:16:26.960</a></span> | <span class="t">come from a whole separate source. Those are nodes on the side. And here we're just producing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4591" target="_blank">01:16:31.760</a></span> | <span class="t">queries and we're reading off information from the side. So cross attention is used when there's a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4598" target="_blank">01:16:38.080</a></span> | <span class="t">separate source of nodes we'd like to pull information from into our nodes. And it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4604" target="_blank">01:16:44.080</a></span> | <span class="t">self-attention if we just have nodes that would like to look at each other and talk to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4607" target="_blank">01:16:47.440</a></span> | <span class="t">So this attention here happens to be self-attention. But in principle,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4613" target="_blank">01:16:53.440</a></span> | <span class="t">attention is a lot more general. Okay, and the last note at this stage is if we come to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4619" target="_blank">01:16:59.520</a></span> | <span class="t">attention is all you need paper here. We've already implemented attention. So given query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4623" target="_blank">01:17:03.840</a></span> | <span class="t">key and value, we've multiplied the query on the key. We've soft-maxed it. And then we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4629" target="_blank">01:17:09.680</a></span> | <span class="t">aggregating the values. There's one more thing that we're missing here, which is the dividing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4633" target="_blank">01:17:13.680</a></span> | <span class="t">by one over square root of the head size. The decay here is the head size. Why are they doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4638" target="_blank">01:17:18.960</a></span> | <span class="t">this? Why is this important? So they call it a scaled attention. And it's kind of like an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4644" target="_blank">01:17:24.880</a></span> | <span class="t">important normalization to basically have. The problem is if you have unit Gaussian inputs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4650" target="_blank">01:17:30.160</a></span> | <span class="t">so zero mean unit variance, k and q are unit Gaussian. And if you just do weigh naively,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4655" target="_blank">01:17:35.520</a></span> | <span class="t">then you see that your weigh actually will be, the variance will be on the order of head size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4660" target="_blank">01:17:40.000</a></span> | <span class="t">which in our case is 16. But if you multiply by one over head size square root, so this is square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4666" target="_blank">01:17:46.000</a></span> | <span class="t">root and this is one over, then the variance of weigh will be one. So it will be preserved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4671" target="_blank">01:17:51.440</a></span> | <span class="t">Now, why is this important? You'll notice that weigh here will feed into soft-max.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4679" target="_blank">01:17:59.520</a></span> | <span class="t">And so it's really important, especially at initialization, that weigh be fairly diffuse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4683" target="_blank">01:18:03.920</a></span> | <span class="t">So in our case here, we sort of locked out here and weigh had a fairly diffuse numbers here. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4691" target="_blank">01:18:11.760</a></span> | <span class="t">like this. Now, the problem is that because of soft-max, if weigh takes on very positive and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4698" target="_blank">01:18:18.160</a></span> | <span class="t">very negative numbers inside it, soft-max will actually converge towards one-hot vectors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4704" target="_blank">01:18:24.160</a></span> | <span class="t">And so I can illustrate that here. Say we are applying soft-max to a tensor of values that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4710" target="_blank">01:18:30.880</a></span> | <span class="t">are very close to zero, then we're going to get a diffuse thing out of soft-max. But the moment I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4716" target="_blank">01:18:36.000</a></span> | <span class="t">take the exact same thing and I start sharpening it and making it bigger by multiplying these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4720" target="_blank">01:18:40.000</a></span> | <span class="t">numbers by eight, for example, you'll see that the soft-max will start to sharpen. And in fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4724" target="_blank">01:18:44.560</a></span> | <span class="t">it will sharpen towards the max. So it will sharpen towards whatever number here is the highest.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4730" target="_blank">01:18:50.080</a></span> | <span class="t">And so basically, we don't want these values to be too extreme, especially at initialization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4734" target="_blank">01:18:54.480</a></span> | <span class="t">Otherwise, soft-max will be way too peaky. And you're basically aggregating information from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4740" target="_blank">01:19:00.800</a></span> | <span class="t">like a single node. Every node just aggregates information from a single other node. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4744" target="_blank">01:19:04.720</a></span> | <span class="t">not what we want, especially at initialization. And so the scaling is used just to control the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4749" target="_blank">01:19:09.840</a></span> | <span class="t">variance at initialization. Okay, so having said all that, let's now take our self-attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4755" target="_blank">01:19:15.040</a></span> | <span class="t">knowledge and let's take it for a spin. So here in the code, I've created this head module and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4761" target="_blank">01:19:21.120</a></span> | <span class="t">implements a single head of self-attention. So you give it a head size, and then here it creates the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4766" target="_blank">01:19:26.720</a></span> | <span class="t">key query and the value linear layers. Typically, people don't use biases in these. So those are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4772" target="_blank">01:19:32.640</a></span> | <span class="t">the linear projections that we're going to apply to all of our nodes. Now here, I'm creating this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4777" target="_blank">01:19:37.760</a></span> | <span class="t">trill variable. Trill is not a parameter of the module. So in sort of PyTorch naming conventions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4783" target="_blank">01:19:43.360</a></span> | <span class="t">this is called a buffer. It's not a parameter. And you have to assign it to the module using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4788" target="_blank">01:19:48.240</a></span> | <span class="t">a register buffer. So that creates the trill, the lower triangular matrix. And when we're given the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4794" target="_blank">01:19:54.960</a></span> | <span class="t">input x, this should look very familiar now. We calculate the keys, the queries. We calculate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4800" target="_blank">01:20:00.240</a></span> | <span class="t">attention scores in Sideway. We normalize it. So we're using scaled attention here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4805" target="_blank">01:20:05.280</a></span> | <span class="t">Then we make sure that future doesn't communicate with the past. So this makes it a decoder block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4811" target="_blank">01:20:11.920</a></span> | <span class="t">And then softmax, and then aggregate the value and output. Then here in the language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4817" target="_blank">01:20:17.520</a></span> | <span class="t">I'm creating a head in the constructor, and I'm calling it self-attention head.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4821" target="_blank">01:20:21.760</a></span> | <span class="t">And the head size, I'm going to keep as the same and embed, just for now. And then here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4829" target="_blank">01:20:29.040</a></span> | <span class="t">once we've encoded the information with the token embeddings and the position embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4834" target="_blank">01:20:34.160</a></span> | <span class="t">we're simply going to feed it into the self-attention head. And then the output of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4838" target="_blank">01:20:38.080</a></span> | <span class="t">that is going to go into the decoder language modeling head and create the logits. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4844" target="_blank">01:20:44.720</a></span> | <span class="t">the simplest way to plug in a self-attention component into our network right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4850" target="_blank">01:20:50.160</a></span> | <span class="t">I had to make one more change, which is that here in the generate, we have to make sure that our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4858" target="_blank">01:20:58.240</a></span> | <span class="t">IDX that we feed into the model, because now we're using positional embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4862" target="_blank">01:21:02.800</a></span> | <span class="t">we can never have more than block size coming in. Because if IDX is more than block size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4868" target="_blank">01:21:08.720</a></span> | <span class="t">then our position embedding table is going to run out of scope, because it only has embeddings for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4872" target="_blank">01:21:12.640</a></span> | <span class="t">up to block size. And so therefore, I added some code here to crop the context that we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4878" target="_blank">01:21:18.560</a></span> | <span class="t">feed into self, so that we never pass in more than block size elements. So those are the changes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4886" target="_blank">01:21:26.400</a></span> | <span class="t">and let's now train the network. So I also came up to the script here, and I decreased the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4891" target="_blank">01:21:31.120</a></span> | <span class="t">rate, because the self-attention can't tolerate very, very high learning rates. And then I also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4896" target="_blank">01:21:36.560</a></span> | <span class="t">increased the number of iterations, because the learning rate is lower. And then I trained it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4900" target="_blank">01:21:40.080</a></span> | <span class="t">and previously we were only able to get to up to 2.5, and now we are down to 2.4. So we definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4905" target="_blank">01:21:45.840</a></span> | <span class="t">see a little bit of an improvement from 2.5 to 2.4, roughly, but the text is still not amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4911" target="_blank">01:21:51.280</a></span> | <span class="t">So clearly, the self-attention head is doing some useful communication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4916" target="_blank">01:21:56.320</a></span> | <span class="t">but we still have a long way to go. Okay, so now we've implemented the scale.productAttention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4921" target="_blank">01:22:01.920</a></span> | <span class="t">Now next up, in the attention is all you need paper, there's something called multi-head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4926" target="_blank">01:22:06.000</a></span> | <span class="t">attention. And what is multi-head attention? It's just applying multiple attentions in parallel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4931" target="_blank">01:22:11.760</a></span> | <span class="t">and concatenating their results. So they have a little bit of diagram here. I don't know if this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4936" target="_blank">01:22:16.720</a></span> | <span class="t">is super clear. It's really just multiple attentions in parallel. So let's implement that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4943" target="_blank">01:22:23.120</a></span> | <span class="t">Fairly straightforward. If we want a multi-head attention, then we want multiple heads of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4948" target="_blank">01:22:28.160</a></span> | <span class="t">self-attention running in parallel. So in PyTorch, we can do this by simply creating multiple heads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4954" target="_blank">01:22:34.720</a></span> | <span class="t">So however many heads you want, and then what is the head size of each. And then we run all of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4963" target="_blank">01:22:43.280</a></span> | <span class="t">in parallel into a list, and simply concatenate all of the outputs. And we're concatenating over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4969" target="_blank">01:22:49.440</a></span> | <span class="t">the channel dimension. So the way this looks now is, we don't have just a single attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4974" target="_blank">01:22:54.720</a></span> | <span class="t">that has a head size of 32, because remember, an embed is 32. Instead of having one communication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4983" target="_blank">01:23:03.680</a></span> | <span class="t">channel, we now have four communication channels in parallel. And each one of these communication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4989" target="_blank">01:23:09.360</a></span> | <span class="t">channels typically will be smaller correspondingly. So because we have four communication channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4996" target="_blank">01:23:16.640</a></span> | <span class="t">we want eight-dimensional self-attention. And so from each communication channel, we're getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5001" target="_blank">01:23:21.120</a></span> | <span class="t">together eight-dimensional vectors. And then we have four of them, and that concatenates to give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5005" target="_blank">01:23:25.840</a></span> | <span class="t">us 32, which is the original and embed. And so this is kind of similar to, if you're familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5011" target="_blank">01:23:31.440</a></span> | <span class="t">with convolutions, this is kind of like a group convolution. Because basically, instead of having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5016" target="_blank">01:23:36.080</a></span> | <span class="t">one large convolution, we do convolution in groups, and that's multi-headed self-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5022" target="_blank">01:23:42.400</a></span> | <span class="t">And so then here, we just use SA heads, self-attention heads, instead. Now, I actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5028" target="_blank">01:23:48.320</a></span> | <span class="t">ran it, and scrolling down, I ran the same thing, and then we now get down to 2.28, roughly. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5037" target="_blank">01:23:57.040</a></span> | <span class="t">the output is still, the generation is still not amazing, but clearly the validation loss is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5041" target="_blank">01:24:01.200</a></span> | <span class="t">improving, because we were at 2.4 just now. And so it helps to have multiple communication channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5047" target="_blank">01:24:07.120</a></span> | <span class="t">because obviously, these tokens have a lot to talk about. They want to find the consonants,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5051" target="_blank">01:24:11.920</a></span> | <span class="t">the vowels, they want to find the vowels just from certain positions, they want to find any kinds of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5057" target="_blank">01:24:17.200</a></span> | <span class="t">different things. And so it helps to create multiple independent channels of communication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5061" target="_blank">01:24:21.440</a></span> | <span class="t">gather lots of different types of data, and then decode the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5065" target="_blank">01:24:25.920</a></span> | <span class="t">Now, going back to the paper for a second, of course, I didn't explain this figure in full</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5069" target="_blank">01:24:29.440</a></span> | <span class="t">detail, but we are starting to see some components of what we've already implemented. We have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5073" target="_blank">01:24:33.520</a></span> | <span class="t">positional encodings, the token encodings that add, we have the masked multi-headed attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5078" target="_blank">01:24:38.560</a></span> | <span class="t">implemented. Now, here's another multi-headed attention, which is a cross-attention to an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5083" target="_blank">01:24:43.680</a></span> | <span class="t">encoder, which we haven't, we're not going to implement in this case. I'm going to come back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5087" target="_blank">01:24:47.680</a></span> | <span class="t">to that later. But I want you to notice that there's a feedforward part here, and then this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5092" target="_blank">01:24:52.560</a></span> | <span class="t">is grouped into a block that gets repeated again and again. Now, the feedforward part here is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5097" target="_blank">01:24:57.280</a></span> | <span class="t">a simple multi-layer perceptron. So the multi-headed, so here position-wise feedforward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5104" target="_blank">01:25:04.960</a></span> | <span class="t">networks is just a simple little MLP. So I want to start basically in a similar fashion, also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5110" target="_blank">01:25:10.560</a></span> | <span class="t">adding computation into the network. And this computation is on a per node level. So I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5117" target="_blank">01:25:17.440</a></span> | <span class="t">already implemented it, and you can see the diff highlighted on the left here when I've added or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5121" target="_blank">01:25:21.440</a></span> | <span class="t">changed things. Now, before we had the multi-headed self-attention that did the communication,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5126" target="_blank">01:25:26.640</a></span> | <span class="t">but we went way too fast to calculate the logits. So the tokens looked at each other, but didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5132" target="_blank">01:25:32.560</a></span> | <span class="t">really have a lot of time to think on what they found from the other tokens. And so what I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5138" target="_blank">01:25:38.880</a></span> | <span class="t">implemented here is a little feedforward single layer. And this little layer is just a linear</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5144" target="_blank">01:25:44.240</a></span> | <span class="t">followed by a ReLU non-linearity, and that's it. So it's just a little layer, and then I call it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5151" target="_blank">01:25:51.120</a></span> | <span class="t">feedforward and embed. And then this feedforward is just called sequentially right after the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5157" target="_blank">01:25:57.680</a></span> | <span class="t">self-attention. So we self-attend, then we feedforward. And you'll notice that the feedforward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5163" target="_blank">01:26:03.040</a></span> | <span class="t">here, when it's applying linear, this is on a per token level. All the tokens do this independently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5168" target="_blank">01:26:08.560</a></span> | <span class="t">So the self-attention is the communication, and then once they've gathered all the data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5172" target="_blank">01:26:12.960</a></span> | <span class="t">now they need to think on that data individually. And so that's what feedforward is doing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5177" target="_blank">01:26:17.920</a></span> | <span class="t">and that's why I've added it here. Now, when I train this, the validation loss actually continues</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5182" target="_blank">01:26:22.720</a></span> | <span class="t">to go down, now to 2.24, which is down from 2.28. The output still looks kind of terrible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5189" target="_blank">01:26:29.440</a></span> | <span class="t">but at least we've improved the situation. And so as a preview, we're going to now start to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5195" target="_blank">01:26:35.120</a></span> | <span class="t">intersperse the communication with the computation. And that's also what the transformer does when it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5202" target="_blank">01:26:42.320</a></span> | <span class="t">has blocks that communicate and then compute, and it groups them and replicates them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5207" target="_blank">01:26:47.360</a></span> | <span class="t">Okay, so let me show you what we'd like to do. We'd like to do something like this. We have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5212" target="_blank">01:26:52.560</a></span> | <span class="t">a block, and this block is basically this part here, except for the cross-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5217" target="_blank">01:26:57.280</a></span> | <span class="t">Now, the block basically intersperses communication and then computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5221" target="_blank">01:27:01.920</a></span> | <span class="t">The communication is done using multi-headed self-attention, and then the computation is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5227" target="_blank">01:27:07.600</a></span> | <span class="t">done using a feedforward network on all the tokens independently. Now, what I've added</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5233" target="_blank">01:27:13.840</a></span> | <span class="t">here also is, you'll notice, this takes the number of embeddings in the embedding dimension and the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5239" target="_blank">01:27:19.600</a></span> | <span class="t">number of heads that we would like, which is kind of like group size in group convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5243" target="_blank">01:27:23.280</a></span> | <span class="t">And I'm saying that the number of heads we'd like is four. And so because this is 32,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5248" target="_blank">01:27:28.720</a></span> | <span class="t">we calculate that because this is 32, the number of heads should be four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5251" target="_blank">01:27:31.920</a></span> | <span class="t">The head size should be eight, so that everything sort of works out channel-wise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5257" target="_blank">01:27:37.520</a></span> | <span class="t">So this is how the transformer structures the sizes, typically. So the head size will become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5265" target="_blank">01:27:45.120</a></span> | <span class="t">eight, and then this is how we want to intersperse them. And then here, I'm trying to create blocks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5269" target="_blank">01:27:49.920</a></span> | <span class="t">which is just a sequential application of block, block, block. So then we're interspersing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5274" target="_blank">01:27:54.800</a></span> | <span class="t">communication feedforward many, many times, and then finally we decode. Now, I actually tried to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5280" target="_blank">01:28:00.720</a></span> | <span class="t">run this, and the problem is, this doesn't actually give a very good result. And the reason for that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5287" target="_blank">01:28:07.520</a></span> | <span class="t">is, we're starting to actually get a pretty deep neural net. And deep neural nets suffer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5292" target="_blank">01:28:12.480</a></span> | <span class="t">from optimization issues, and I think that's what we're kind of like slightly starting to run into.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5296" target="_blank">01:28:16.560</a></span> | <span class="t">So we need one more idea that we can borrow from the transformer paper to resolve those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5301" target="_blank">01:28:21.760</a></span> | <span class="t">difficulties. Now, there are two optimizations that dramatically help with the depth of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5306" target="_blank">01:28:26.400</a></span> | <span class="t">networks and make sure that the networks remain optimizable. Let's talk about the first one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5311" target="_blank">01:28:31.120</a></span> | <span class="t">The first one in this diagram is, you see this arrow here, and then this arrow and this arrow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5317" target="_blank">01:28:37.520</a></span> | <span class="t">those are skip connections, or sometimes called residual connections. They come from this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5322" target="_blank">01:28:42.400</a></span> | <span class="t">the Presidual Learning for Image Recognition, from about 2015, that introduced the concept.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5328" target="_blank">01:28:48.960</a></span> | <span class="t">Now, these are basically, what it means is, you transform the data, but then you have a skip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5335" target="_blank">01:28:55.120</a></span> | <span class="t">connection with addition from the previous features. Now, the way I like to visualize it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5340" target="_blank">01:29:00.720</a></span> | <span class="t">that I prefer, is the following. Here, the computation happens from the top to bottom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5347" target="_blank">01:29:07.440</a></span> | <span class="t">and basically, you have this residual pathway, and you are free to fork off from the residual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5352" target="_blank">01:29:12.880</a></span> | <span class="t">pathway, perform some computation, and then project back to the residual pathway via addition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5357" target="_blank">01:29:17.600</a></span> | <span class="t">And so you go from the inputs to the targets only via plus, and plus, and plus. And the reason this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5365" target="_blank">01:29:25.920</a></span> | <span class="t">is useful is because during backpropagation, remember from our micrograd video earlier,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5370" target="_blank">01:29:30.480</a></span> | <span class="t">addition distributes gradients equally to both of its branches that fed us the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5376" target="_blank">01:29:36.960</a></span> | <span class="t">And so the supervision, or the gradients from the loss, basically hop through every addition node</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5384" target="_blank">01:29:44.640</a></span> | <span class="t">all the way to the input, and then also fork off into the residual blocks. But basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5391" target="_blank">01:29:51.680</a></span> | <span class="t">you have this gradient superhighway that goes directly from the supervision all the way to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5396" target="_blank">01:29:56.000</a></span> | <span class="t">the input, unimpeded. And then these residual blocks are usually initialized in the beginning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5401" target="_blank">01:30:01.040</a></span> | <span class="t">so they contribute very, very little, if anything, to the residual pathway. They are initialized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5405" target="_blank">01:30:05.680</a></span> | <span class="t">that way. So in the beginning, they are almost kind of like not there. But then during the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5410" target="_blank">01:30:10.480</a></span> | <span class="t">optimization, they come online over time, and they start to contribute. But at least at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5417" target="_blank">01:30:17.040</a></span> | <span class="t">initialization, you can go from directly supervision to the input, gradient is unimpeded and just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5422" target="_blank">01:30:22.080</a></span> | <span class="t">flows, and then the blocks over time kick in. And so that dramatically helps with the optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5428" target="_blank">01:30:28.480</a></span> | <span class="t">So let's implement this. So coming back to our block here, basically what we want to do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5433" target="_blank">01:30:33.360</a></span> | <span class="t">we want to do x equals x plus self-attention, and x equals x plus self-upfeedforward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5439" target="_blank">01:30:39.440</a></span> | <span class="t">So this is x, and then we fork off and do some communication and come back. And we fork off,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5446" target="_blank">01:30:46.400</a></span> | <span class="t">and we do some computation and come back. So those are residual connections. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5451" target="_blank">01:30:51.440</a></span> | <span class="t">swinging back up here, we also have to introduce this projection. So nn.linear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5458" target="_blank">01:30:58.480</a></span> | <span class="t">And this is going to be from after we concatenate this. This is the size and embed. So this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5465" target="_blank">01:31:05.360</a></span> | <span class="t">output of the self-attention itself. But then we actually want to apply the projection,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5471" target="_blank">01:31:11.040</a></span> | <span class="t">and that's the result. So the projection is just a linear transformation of the outcome of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5476" target="_blank">01:31:16.800</a></span> | <span class="t">layer. So that's the projection back into the residual pathway. And then here in the feed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5482" target="_blank">01:31:22.560</a></span> | <span class="t">forward, it's going to be the same thing. I could have a self-dot projection here as well. But let</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5487" target="_blank">01:31:27.920</a></span> | <span class="t">me just simplify it, and let me couple it inside the same sequential container. And so this is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5495" target="_blank">01:31:35.360</a></span> | <span class="t">projection layer going back into the residual pathway. And so that's it. So now we can train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5503" target="_blank">01:31:43.280</a></span> | <span class="t">this. So I implemented one more small change. When you look into the paper again, you see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5509" target="_blank">01:31:49.280</a></span> | <span class="t">the dimensionality of input and output is 512 for them. And they're saying that the inner layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5514" target="_blank">01:31:54.080</a></span> | <span class="t">here in the feed forward has dimensionality of 2048. So there's a multiplier of 4. And so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5520" target="_blank">01:32:00.080</a></span> | <span class="t">inner layer of the feed forward network should be multiplied by 4 in terms of channel sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5525" target="_blank">01:32:05.040</a></span> | <span class="t">So I came here, and I multiplied 4 times embed here for the feed forward, and then from 4 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5530" target="_blank">01:32:10.560</a></span> | <span class="t">nembed coming back down to nembed when we go back to the projection. So adding a bit of computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5536" target="_blank">01:32:16.560</a></span> | <span class="t">here and growing that layer that is in the residual block on the side of the residual pathway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5542" target="_blank">01:32:22.960</a></span> | <span class="t">And then I train this, and we actually get down all the way to 2.08 validation loss. And we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5548" target="_blank">01:32:28.480</a></span> | <span class="t">see that the network is starting to get big enough that our train loss is getting ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5552" target="_blank">01:32:32.000</a></span> | <span class="t">of validation loss. So we start to see a little bit of overfitting. And our generations here are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5560" target="_blank">01:32:40.720</a></span> | <span class="t">still not amazing, but at least you see that we can see like is here, this now, grief, sink.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5565" target="_blank">01:32:45.440</a></span> | <span class="t">Like this starts to almost look like English. So yeah, we're starting to really get there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5571" target="_blank">01:32:51.520</a></span> | <span class="t">Okay, and the second innovation that is very helpful for optimizing very deep neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5575" target="_blank">01:32:55.600</a></span> | <span class="t">is right here. So we have this addition now, that's the residual part. But this norm is referring to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5580" target="_blank">01:33:00.480</a></span> | <span class="t">something called layer norm. So layer norm is implemented in PyTorch. It's a paper that came out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5585" target="_blank">01:33:05.360</a></span> | <span class="t">a while back here. And layer norm is very, very similar to batch norm. So remember back to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5593" target="_blank">01:33:13.600</a></span> | <span class="t">our Make More Series part three, we implemented batch normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5598" target="_blank">01:33:18.560</a></span> | <span class="t">And batch normalization basically just made sure that across the batch dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5604" target="_blank">01:33:24.080</a></span> | <span class="t">any individual neuron had unit Gaussian distribution. So it was zero mean and unit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5611" target="_blank">01:33:31.840</a></span> | <span class="t">standard deviation, one standard deviation output. So what I did here is I'm copy pasting the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5618" target="_blank">01:33:38.080</a></span> | <span class="t">norm 1D that we developed in our Make More Series. And see here, we can initialize, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5623" target="_blank">01:33:43.680</a></span> | <span class="t">this module, and we can have a batch of 32 100 dimensional vectors feeding through the batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5628" target="_blank">01:33:48.800</a></span> | <span class="t">norm layer. So what this does is it guarantees that when we look at just the zeroth column,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5635" target="_blank">01:33:55.520</a></span> | <span class="t">it's a zero mean, one standard deviation. So it's normalizing every single column of this input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5642" target="_blank">01:34:02.880</a></span> | <span class="t">Now the rows are not going to be normalized by default, because we're just normalizing columns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5649" target="_blank">01:34:09.600</a></span> | <span class="t">So let's not implement layer norm. It's very complicated. Look, we come here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5654" target="_blank">01:34:14.960</a></span> | <span class="t">we change this from zero to one. So we don't normalize the columns, we normalize the rows.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5660" target="_blank">01:34:20.880</a></span> | <span class="t">And now we've implemented layer norm. So now the columns are not going to be normalized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5668" target="_blank">01:34:28.080</a></span> | <span class="t">But the rows are going to be normalized for every individual example, it's 100 dimensional vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5674" target="_blank">01:34:34.960</a></span> | <span class="t">is normalized in this way. And because our computation now does not span across examples,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5680" target="_blank">01:34:40.640</a></span> | <span class="t">we can delete all of this buffers stuff, because we can always apply this operation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5688" target="_blank">01:34:48.080</a></span> | <span class="t">and don't need to maintain any running buffers. So we don't need the buffers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5692" target="_blank">01:34:52.080</a></span> | <span class="t">We don't, there's no distinction between training and test time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5697" target="_blank">01:34:57.280</a></span> | <span class="t">And we don't need these running buffers. We do keep gamma and beta, we don't need the momentum,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5704" target="_blank">01:35:04.800</a></span> | <span class="t">we don't care if it's training or not. And this is now a layer norm. And it normalizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5712" target="_blank">01:35:12.080</a></span> | <span class="t">the rows instead of the columns. And this here is identical to basically this here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5718" target="_blank">01:35:18.240</a></span> | <span class="t">So let's now implement layer norm in our transformer. Before I incorporate the layer norm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5723" target="_blank">01:35:23.760</a></span> | <span class="t">I just wanted to note that, as I said, very few details about the transformer have changed in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5728" target="_blank">01:35:28.160</a></span> | <span class="t">last five years. But this is actually something that slightly departs from the original paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5732" target="_blank">01:35:32.480</a></span> | <span class="t">You see that the add and norm is applied after the transformation. But now it is a bit more,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5740" target="_blank">01:35:40.400</a></span> | <span class="t">basically, common to apply the layer norm before the transformation. So there's a reshuffling of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5745" target="_blank">01:35:45.360</a></span> | <span class="t">the layer norms. So this is called the pre-norm formulation, and that's the one that we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5749" target="_blank">01:35:49.680</a></span> | <span class="t">to implement as well. So slight deviation from the original paper. Basically, we need to layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5754" target="_blank">01:35:54.320</a></span> | <span class="t">norms. Layer norm one is nn.layernorm, and we tell it how many, what is the embedding dimension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5762" target="_blank">01:36:02.640</a></span> | <span class="t">And we need the second layer norm. And then here, the layer norms are applied immediately on x.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5768" target="_blank">01:36:08.400</a></span> | <span class="t">So self.layernorm1 applied on x, and self.layernorm2 applied on x, before it goes into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5776" target="_blank">01:36:16.240</a></span> | <span class="t">self-attention and feedforward. And the size of the layer norm here is an embed, so 32.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5782" target="_blank">01:36:22.320</a></span> | <span class="t">So when the layer norm is normalizing our features, it is the normalization here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5790" target="_blank">01:36:30.160</a></span> | <span class="t">happens, the mean and the variance are taken over 32 numbers. So the batch and the time act as batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5796" target="_blank">01:36:36.320</a></span> | <span class="t">dimensions, both of them. So this is kind of like a per-token transformation that just normalizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5802" target="_blank">01:36:42.720</a></span> | <span class="t">the features and makes them unit mean, unit Gaussian at initialization. But of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5809" target="_blank">01:36:49.680</a></span> | <span class="t">because these layer norms inside it have these gamma and beta trainable parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5815" target="_blank">01:36:55.200</a></span> | <span class="t">the layer norm will eventually create outputs that might not be unit Gaussian,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5820" target="_blank">01:37:00.640</a></span> | <span class="t">but the optimization will determine that. So for now, this is incorporating the layer norms,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5826" target="_blank">01:37:06.720</a></span> | <span class="t">and let's train them up. Okay, so I let it run, and we see that we get down to 2.06,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5831" target="_blank">01:37:11.840</a></span> | <span class="t">which is better than the previous 2.08. So a slight improvement by adding the layer norms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5836" target="_blank">01:37:16.560</a></span> | <span class="t">And I'd expect that they help even more if we had a bigger and deeper network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5840" target="_blank">01:37:20.880</a></span> | <span class="t">One more thing I forgot to add is that there should be a layer norm here also typically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5845" target="_blank">01:37:25.280</a></span> | <span class="t">as at the end of the transformer and right before the final linear layer that decodes into vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5852" target="_blank">01:37:32.560</a></span> | <span class="t">So I added that as well. So at this stage, we actually have a pretty complete transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5857" target="_blank">01:37:37.360</a></span> | <span class="t">according to the original paper, and it's a decoder-only transformer. I'll talk about that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5862" target="_blank">01:37:42.000</a></span> | <span class="t">in a second. But at this stage, the major pieces are in place, so we can try to scale this up and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5867" target="_blank">01:37:47.040</a></span> | <span class="t">see how well we can push this number. Now, in order to scale up the model, I had to perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5871" target="_blank">01:37:51.600</a></span> | <span class="t">some cosmetic changes here to make it nicer. So I introduced this variable called n_layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5876" target="_blank">01:37:56.640</a></span> | <span class="t">which just specifies how many layers of the blocks we're going to have. I create a bunch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5881" target="_blank">01:38:01.600</a></span> | <span class="t">of blocks, and we have a new variable, number of heads as well. I pulled out the layer norm here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5887" target="_blank">01:38:07.040</a></span> | <span class="t">and so this is identical. Now, one thing that I did briefly change is I added dropout. So dropout</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5894" target="_blank">01:38:14.000</a></span> | <span class="t">is something that you can add right before the residual connection back into the residual pathway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5900" target="_blank">01:38:20.880</a></span> | <span class="t">So we can drop out that as the last layer here. We can drop out here at the end of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5907" target="_blank">01:38:27.200</a></span> | <span class="t">multi-headed restriction as well. And we can also drop out here when we calculate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5912" target="_blank">01:38:32.880</a></span> | <span class="t">basically affinities, and after the softmax, we can drop out some of those. So we can randomly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5919" target="_blank">01:38:39.200</a></span> | <span class="t">prevent some of the nodes from communicating. And so dropout comes from this paper from 2014 or so,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5926" target="_blank">01:38:46.720</a></span> | <span class="t">and basically it takes your neural net, and it randomly, every forward-backward pass,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5934" target="_blank">01:38:54.080</a></span> | <span class="t">shuts off some subset of neurons. So randomly drops them to zero and trains without them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5941" target="_blank">01:39:01.520</a></span> | <span class="t">And what this does effectively is because the mask of what's being dropped out has changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5946" target="_blank">01:39:06.880</a></span> | <span class="t">every single forward-backward pass, it ends up kind of training an ensemble of subnetworks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5952" target="_blank">01:39:12.400</a></span> | <span class="t">And then at test time, everything is fully enabled and kind of all of those subnetworks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5956" target="_blank">01:39:16.720</a></span> | <span class="t">are merged into a single ensemble, if you want to think about it that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5960" target="_blank">01:39:20.160</a></span> | <span class="t">So I would read the paper to get the full detail. For now, we're just going to stay on the level of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5965" target="_blank">01:39:25.200</a></span> | <span class="t">this is a regularization technique, and I added it because I'm about to scale up the model quite a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5970" target="_blank">01:39:30.320</a></span> | <span class="t">bit, and I was concerned about overfitting. So now when we scroll up to the top, we'll see that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5976" target="_blank">01:39:36.400</a></span> | <span class="t">I changed a number of hyperparameters here about our neural net. So I made the batch size be much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5981" target="_blank">01:39:41.040</a></span> | <span class="t">larger, now it's 64. I changed the block size to be 256, so previously it was just 8 characters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5987" target="_blank">01:39:47.440</a></span> | <span class="t">of context. Now it is 256 characters of context to predict the 257th. I brought down the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5995" target="_blank">01:39:55.440</a></span> | <span class="t">rate a little bit because the neural net is now much bigger, so I brought down the learning rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6000" target="_blank">01:40:00.080</a></span> | <span class="t">The embedding dimension is now 384, and there are six heads. So 384 divide 6 means that every head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6007" target="_blank">01:40:07.200</a></span> | <span class="t">is 64-dimensional as a standard. And then there are going to be six layers of that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6013" target="_blank">01:40:13.120</a></span> | <span class="t">and the dropout will be at 0.2. So every forward-backward pass, 20% of all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6018" target="_blank">01:40:18.240</a></span> | <span class="t">intermediate calculations are disabled and dropped to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6022" target="_blank">01:40:22.880</a></span> | <span class="t">And then I already trained this and I ran it, so drumroll, how well does it perform?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6029" target="_blank">01:40:29.440</a></span> | <span class="t">So let me just scroll up here. We get a validation loss of 1.48, which is actually quite a bit of an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6037" target="_blank">01:40:37.040</a></span> | <span class="t">improvement on what we had before, which I think was 2.07. So we went from 2.07 all the way down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6042" target="_blank">01:40:42.000</a></span> | <span class="t">to 1.48 just by scaling up this neural net with the code that we have. And this, of course, ran</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6047" target="_blank">01:40:47.120</a></span> | <span class="t">for a lot longer. This may be trained for, I want to say, about 15 minutes on my A100 GPU, so that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6052" target="_blank">01:40:52.960</a></span> | <span class="t">a pretty good GPU. And if you don't have a GPU, you're not going to be able to reproduce this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6057" target="_blank">01:40:57.600</a></span> | <span class="t">On a CPU, this would be, I would not run this on a CPU or a MacBook or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6062" target="_blank">01:41:02.640</a></span> | <span class="t">You'll have to break down the number of layers and the embedding dimension and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6067" target="_blank">01:41:07.040</a></span> | <span class="t">But in about 15 minutes, we can get this kind of a result. And I'm printing some of the Shakespeare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6074" target="_blank">01:41:14.640</a></span> | <span class="t">here, but what I did also is I printed 10,000 characters, so a lot more, and I wrote them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6079" target="_blank">01:41:19.040</a></span> | <span class="t">a file. And so here we see some of the outputs. So it's a lot more recognizable as the input text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6087" target="_blank">01:41:27.360</a></span> | <span class="t">file. So the input text file, just for reference, looked like this. So there's always someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6092" target="_blank">01:41:32.960</a></span> | <span class="t">speaking in this manner, and our predictions now take on that form. Except, of course, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6100" target="_blank">01:41:40.720</a></span> | <span class="t">nonsensical when you actually read them. So it is, "Every crimpty be a house. Oh, those probation."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6109" target="_blank">01:41:49.440</a></span> | <span class="t">"We give heed."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6110" target="_blank">01:41:50.240</a></span> | <span class="t">"Oho, sent me you mighty lord."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6117" target="_blank">01:41:57.840</a></span> | <span class="t">Anyway, so you can read through this. It's nonsensical, of course, but this is just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6125" target="_blank">01:42:05.120</a></span> | <span class="t">transformer trained on the character level for 1 million characters that come from Shakespeare.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6130" target="_blank">01:42:10.080</a></span> | <span class="t">So there's sort of like blabbers on in Shakespeare-like manner, but it doesn't,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6134" target="_blank">01:42:14.160</a></span> | <span class="t">of course, make sense at this scale. But I think it's still a pretty good demonstration</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6139" target="_blank">01:42:19.520</a></span> | <span class="t">of what's possible. So now I think that kind of concludes the programming section of this video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6148" target="_blank">01:42:28.320</a></span> | <span class="t">We basically kind of did a pretty good job of implementing this transformer, but the picture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6154" target="_blank">01:42:34.880</a></span> | <span class="t">doesn't exactly match up to what we've done. So what's going on with all these additional parts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6159" target="_blank">01:42:39.040</a></span> | <span class="t">here? So let me finish explaining this architecture and why it looks so funky. Basically, what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6164" target="_blank">01:42:44.400</a></span> | <span class="t">happening here is what we implemented here is a decoder-only transformer. So there's no component</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6170" target="_blank">01:42:50.640</a></span> | <span class="t">here. This part is called the encoder, and there's no cross-attention block here. Our block only has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6176" target="_blank">01:42:56.720</a></span> | <span class="t">a self-attention and the feedforward, so it is missing this third in-between piece here. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6182" target="_blank">01:43:02.960</a></span> | <span class="t">piece does cross-attention. So we don't have it, and we don't have the encoder. We just have the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6187" target="_blank">01:43:07.200</a></span> | <span class="t">decoder. And the reason we have a decoder only is because we are just generating text, and it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6193" target="_blank">01:43:13.360</a></span> | <span class="t">unconditioned on anything. We're just blabbering on according to a given dataset. What makes it a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6199" target="_blank">01:43:19.040</a></span> | <span class="t">decoder is that we are using the triangular mask in our transformer. So it has this autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6205" target="_blank">01:43:25.040</a></span> | <span class="t">property where we can just go and sample from it. So the fact that it's using the triangular mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6211" target="_blank">01:43:31.440</a></span> | <span class="t">to mask out the attention makes it a decoder, and it can be used for language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6216" target="_blank">01:43:36.560</a></span> | <span class="t">Now, the reason that the original paper had an encoder-decoder architecture is because it is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6221" target="_blank">01:43:41.520</a></span> | <span class="t">machine translation paper. So it is concerned with a different setting in particular. It expects some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6228" target="_blank">01:43:48.240</a></span> | <span class="t">tokens that encode, say for example, French, and then it is expected to decode the translation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6234" target="_blank">01:43:54.560</a></span> | <span class="t">in English. So typically, these here are special tokens. So you are expected to read in this and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6241" target="_blank">01:44:01.760</a></span> | <span class="t">condition on it. And then you start off the generation with a special token called start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6246" target="_blank">01:44:06.560</a></span> | <span class="t">So this is a special new token that you introduce and always place in the beginning. And then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6252" target="_blank">01:44:12.800</a></span> | <span class="t">network is expected to output neural networks are awesome, and then a special end token to finish</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6258" target="_blank">01:44:18.800</a></span> | <span class="t">the generation. So this part here will be decoded exactly as we've done it. Neural networks are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6266" target="_blank">01:44:26.080</a></span> | <span class="t">awesome will be identical to what we did. But unlike what we did, they want to condition the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6272" target="_blank">01:44:32.240</a></span> | <span class="t">generation on some additional information. And in that case, this additional information is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6277" target="_blank">01:44:37.680</a></span> | <span class="t">French sentence that they should be translating. So what they do now is they bring the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6283" target="_blank">01:44:43.680</a></span> | <span class="t">Now the encoder reads this part here. So we're only going to take the part of French, and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6290" target="_blank">01:44:50.400</a></span> | <span class="t">going to create tokens from it exactly as we've seen in our video. And we're going to put a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6295" target="_blank">01:44:55.920</a></span> | <span class="t">transformer on it. But there's going to be no triangular mask. And so all the tokens are allowed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6300" target="_blank">01:45:00.640</a></span> | <span class="t">to talk to each other as much as they want. And they're just encoding whatever's the content of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6305" target="_blank">01:45:05.440</a></span> | <span class="t">this French sentence. Once they've encoded it, they've they basically come out in the top here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6312" target="_blank">01:45:12.480</a></span> | <span class="t">And then what happens here is in our decoder, which does the language modeling, there's an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6318" target="_blank">01:45:18.960</a></span> | <span class="t">additional connection here to the outputs of the encoder. And that is brought in through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6324" target="_blank">01:45:24.640</a></span> | <span class="t">cross attention. So the queries are still generated from x. But now the keys and the values</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6330" target="_blank">01:45:30.800</a></span> | <span class="t">are coming from the side, the keys and the values are coming from the top generated by the nodes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6336" target="_blank">01:45:36.320</a></span> | <span class="t">that came outside of the decode the encoder. And those tops, the keys and the values, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6341" target="_blank">01:45:41.840</a></span> | <span class="t">the top of it, feed in on a side into every single block of the decoder. And so that's why there's an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6348" target="_blank">01:45:48.400</a></span> | <span class="t">additional cross attention. And really what it's doing is it's conditioning the decoding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6353" target="_blank">01:45:53.520</a></span> | <span class="t">not just on the past of this current decoding, but also on having seen the full, fully encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6361" target="_blank">01:46:01.440</a></span> | <span class="t">French prompt sort of. And so it's an encoder decoder model, which is why we have those two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6367" target="_blank">01:46:07.360</a></span> | <span class="t">transformers and additional block and so on. So we did not do this because we have no we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6372" target="_blank">01:46:12.480</a></span> | <span class="t">nothing to encode, there's no conditioning, we just have a text file, and we just want to imitate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6376" target="_blank">01:46:16.640</a></span> | <span class="t">And that's why we are using a decoder only transformer, exactly as done in GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6381" target="_blank">01:46:21.440</a></span> | <span class="t">Okay, so now I wanted to do a very brief walkthrough of nano GPT, which you can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6386" target="_blank">01:46:26.560</a></span> | <span class="t">on my GitHub. And now GPT is basically two files of interest. There's trained up by and model by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6393" target="_blank">01:46:33.040</a></span> | <span class="t">trained up by as all the boilerplate code for training the network. It is basically all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6398" target="_blank">01:46:38.320</a></span> | <span class="t">stuff that we had here is the training loop. It's just that it's a lot more complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6403" target="_blank">01:46:43.280</a></span> | <span class="t">because we're saving and loading checkpoints and pre trained weights. And we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6407" target="_blank">01:46:47.120</a></span> | <span class="t">decaying the learning rate and compiling the model and using distributed training across</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6411" target="_blank">01:46:51.520</a></span> | <span class="t">multiple nodes or GPUs. So the training that pie gets a little bit more hairy, complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6416" target="_blank">01:46:56.720</a></span> | <span class="t">there's more options, etc. But the model that I should look very, very similar to what we've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6423" target="_blank">01:47:03.520</a></span> | <span class="t">here. In fact, the model is almost identical. So first, here we have the causal self attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6430" target="_blank">01:47:10.080</a></span> | <span class="t">block. And all of this should look very, very recognizable to you. We're producing queries,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6434" target="_blank">01:47:14.720</a></span> | <span class="t">keys values, we're doing dot products, we're masking, applying softmax, optionally dropping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6440" target="_blank">01:47:20.560</a></span> | <span class="t">out. And here we are pulling the way the values. What is different here is that in our code,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6446" target="_blank">01:47:26.480</a></span> | <span class="t">I have separated out the multi headed attention into just a single individual head.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6452" target="_blank">01:47:32.720</a></span> | <span class="t">And then here, I have multiple heads, and I explicitly concatenate them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6457" target="_blank">01:47:37.680</a></span> | <span class="t">Whereas here, all of it is implemented in a batched manner inside a single causal self attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6463" target="_blank">01:47:43.200</a></span> | <span class="t">And so we don't just have a B and a T and a C dimension, we also end up with a fourth dimension,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6468" target="_blank">01:47:48.080</a></span> | <span class="t">which is the heads. And so it just gets a lot more sort of hairy, because we have four dimensional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6473" target="_blank">01:47:53.360</a></span> | <span class="t">array tensors now, but it is equivalent mathematically. So the exact same thing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6479" target="_blank">01:47:59.280</a></span> | <span class="t">happening as what we have, it's just it's a bit more efficient, because all the heads are now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6483" target="_blank">01:48:03.600</a></span> | <span class="t">treated as a batch dimension as well. Then we have the multilayer perceptron, it's using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6488" target="_blank">01:48:08.720</a></span> | <span class="t">Gelu nonlinearity, which is defined here, instead of Relu. And this is done just because OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6494" target="_blank">01:48:14.640</a></span> | <span class="t">used it, and I want to be able to load their checkpoints. The blocks of the transformer are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6499" target="_blank">01:48:19.520</a></span> | <span class="t">identical, the communicate and the compute phase as we saw, and then the GPT will be identical,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6504" target="_blank">01:48:24.720</a></span> | <span class="t">we have the position encodings, token encodings, the blocks, the layer norm at the end,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6510" target="_blank">01:48:30.080</a></span> | <span class="t">the final linear layer. And this should look all very recognizable. And there's a bit more here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6516" target="_blank">01:48:36.160</a></span> | <span class="t">because I'm loading checkpoints and stuff like that. I'm separating out the parameters into those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6520" target="_blank">01:48:40.480</a></span> | <span class="t">that should be weight decayed and those that shouldn't. But the generate function should also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6525" target="_blank">01:48:45.280</a></span> | <span class="t">be very, very similar. So a few details are different, but you should definitely be able to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6529" target="_blank">01:48:49.600</a></span> | <span class="t">look at this file and be able to understand a lot of the pieces now. So let's now bring things back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6535" target="_blank">01:48:55.040</a></span> | <span class="t">to chat-gpt. What would it look like if we wanted to train chat-gpt ourselves? And how does it relate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6540" target="_blank">01:49:00.320</a></span> | <span class="t">to what we learned today? Well, to train chat-gpt, there are roughly two stages. First is the pre</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6545" target="_blank">01:49:05.920</a></span> | <span class="t">training stage, and then the fine tuning stage. In the pre training stage, we are training on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6551" target="_blank">01:49:11.840</a></span> | <span class="t">large chunk of internet, and just trying to get a first decoder only transformer to babble text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6558" target="_blank">01:49:18.560</a></span> | <span class="t">So it's very, very similar to what we've done ourselves. Except we've done like a tiny little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6564" target="_blank">01:49:24.080</a></span> | <span class="t">baby pre training step. And so in our case, this is how you print a number of parameters. I printed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6572" target="_blank">01:49:32.080</a></span> | <span class="t">it and it's about 10 million. So this transformer that I created here to create a little Shakespeare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6577" target="_blank">01:49:37.120</a></span> | <span class="t">transformer was about 10 million parameters. Our data set is roughly 1 million characters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6584" target="_blank">01:49:44.880</a></span> | <span class="t">so roughly 1 million tokens. But you have to remember that OpenAI uses different vocabulary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6589" target="_blank">01:49:49.440</a></span> | <span class="t">They're not on the character level. They use these sub word chunks of words. And so they have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6594" target="_blank">01:49:54.960</a></span> | <span class="t">vocabulary of 50,000 roughly elements. And so their sequences are a bit more condensed. So our data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6602" target="_blank">01:50:02.320</a></span> | <span class="t">the Shakespeare data set would be probably around 300,000 tokens in the OpenAI vocabulary, roughly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6608" target="_blank">01:50:08.160</a></span> | <span class="t">So we trained about 10 million parameter model on roughly 300,000 tokens. Now, when you go to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6614" target="_blank">01:50:14.800</a></span> | <span class="t">GPT-3 paper and you look at the transformers that they trained, they trained a number of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6622" target="_blank">01:50:22.320</a></span> | <span class="t">transformers of different sizes. But the biggest transformer here has 175 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6627" target="_blank">01:50:27.680</a></span> | <span class="t">So ours is again 10 million. They used this number of layers in a transformer. This is the N embed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6634" target="_blank">01:50:34.160</a></span> | <span class="t">This is the number of heads. And this is the head size. And then this is the batch size.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6641" target="_blank">01:50:41.040</a></span> | <span class="t">So ours was 65. And the learning rate is similar. Now, when they trained this transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6647" target="_blank">01:50:47.600</a></span> | <span class="t">they trained on 300 billion tokens. So again, remember, ours is about 300,000. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6653" target="_blank">01:50:53.600</a></span> | <span class="t">about a million fold increase. And this number would not be even that large by today's standards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6659" target="_blank">01:50:59.200</a></span> | <span class="t">It'd be going up 1 trillion and above. So they are training a significantly larger model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6667" target="_blank">01:51:07.200</a></span> | <span class="t">on a good chunk of the internet. And that is the pre-training stage. But otherwise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6672" target="_blank">01:51:12.400</a></span> | <span class="t">these hyperparameters should be fairly recognizable to you. And the architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6675" target="_blank">01:51:15.920</a></span> | <span class="t">is actually nearly identical to what we implemented ourselves. But of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6679" target="_blank">01:51:19.760</a></span> | <span class="t">it's a massive infrastructure challenge to train this. You're talking about typically thousands of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6684" target="_blank">01:51:24.560</a></span> | <span class="t">GPUs having to talk to each other to train models of this size. So that's just the pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6690" target="_blank">01:51:30.720</a></span> | <span class="t">stage. Now, after you complete the pre-training stage, you don't get something that responds to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6696" target="_blank">01:51:36.480</a></span> | <span class="t">your questions with answers and is not helpful and et cetera. You get a document completer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6701" target="_blank">01:51:41.520</a></span> | <span class="t">So it babbles, but it doesn't babble Shakespeare. It babbles internet. It will create arbitrary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6708" target="_blank">01:51:48.000</a></span> | <span class="t">news articles and documents, and it will try to complete documents because that's what it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6711" target="_blank">01:51:51.760</a></span> | <span class="t">trained for. It's trying to complete the sequence. So when you give it a question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6715" target="_blank">01:51:55.360</a></span> | <span class="t">it would just potentially just give you more questions. It would follow with more questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6720" target="_blank">01:52:00.240</a></span> | <span class="t">It will do whatever it looks like some closed document would do in the training data on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6725" target="_blank">01:52:05.840</a></span> | <span class="t">internet. And so who knows, you're getting kind of like undefined behavior. It might basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6730" target="_blank">01:52:10.240</a></span> | <span class="t">answer with two questions with other questions. It might ignore your question. It might just try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6735" target="_blank">01:52:15.120</a></span> | <span class="t">to complete some news article. It's totally on the mind, as we say. So the second fine tuning stage</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6741" target="_blank">01:52:21.360</a></span> | <span class="t">is to actually align it to be an assistant. And this is the second stage. And so this chat GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6748" target="_blank">01:52:28.240</a></span> | <span class="t">blog post from OpenAI talks a little bit about how this stage is achieved. We basically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6755" target="_blank">01:52:35.120</a></span> | <span class="t">there's roughly three steps to this stage. So what they do here is they start to collect</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6759" target="_blank">01:52:39.920</a></span> | <span class="t">training data that looks specifically like what an assistant would do. So there are documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6764" target="_blank">01:52:44.800</a></span> | <span class="t">that have the format where the question is on top and then an answer is below. And they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6769" target="_blank">01:52:49.200</a></span> | <span class="t">a large number of these, but probably not on the order of the internet. This is probably on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6773" target="_blank">01:52:53.520</a></span> | <span class="t">order of maybe thousands of examples. And so they then fine tune the model to basically only focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6782" target="_blank">01:53:02.480</a></span> | <span class="t">on documents that look like that. And so you're starting to slowly align it. So it's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6786" target="_blank">01:53:06.880</a></span> | <span class="t">expect a question at the top and it's going to expect to complete the answer. And these very,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6791" target="_blank">01:53:11.840</a></span> | <span class="t">very large models are very sample efficient during their fine tuning. So this actually somehow works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6796" target="_blank">01:53:16.960</a></span> | <span class="t">But that's just step one. That's just fine tuning. So then they actually have more steps where,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6801" target="_blank">01:53:21.760</a></span> | <span class="t">okay, the second step is you let the model respond and then different raters look at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6806" target="_blank">01:53:26.800</a></span> | <span class="t">different responses and rank them for their preference as to which one is better than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6811" target="_blank">01:53:31.040</a></span> | <span class="t">other. They use that to train a reward model. So they can predict basically using a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6816" target="_blank">01:53:36.160</a></span> | <span class="t">network, how much of any candidate response would be desirable. And then once they have a reward</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6823" target="_blank">01:53:43.920</a></span> | <span class="t">model, they run PPO, which is a form of policy gradient reinforcement learning optimizer to fine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6831" target="_blank">01:53:51.360</a></span> | <span class="t">tune this sampling policy so that the answers that the chat GPT now generates are expected to score a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6840" target="_blank">01:54:00.000</a></span> | <span class="t">high reward according to the reward model. And so basically there's a whole aligning stage here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6846" target="_blank">01:54:06.240</a></span> | <span class="t">or fine tuning stage. It's got multiple steps in between there as well. And it takes the model from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6851" target="_blank">01:54:11.840</a></span> | <span class="t">being a document completer to a question answerer. And that's like a whole separate stage. A lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6858" target="_blank">01:54:18.560</a></span> | <span class="t">this data is not available publicly. It is internal to OpenAI and it's much harder to replicate this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6864" target="_blank">01:54:24.640</a></span> | <span class="t">stage. And so that's roughly what would give you a chat GPT. And nano-GPT focuses on the pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6871" target="_blank">01:54:31.680</a></span> | <span class="t">stage. Okay. And that's everything that I wanted to cover today. So we trained to summarize a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6878" target="_blank">01:54:38.000</a></span> | <span class="t">decoder only transformer following this famous paper, attention is all you need from 2017.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6883" target="_blank">01:54:43.840</a></span> | <span class="t">And so that's basically a GPT. We trained it on a tiny Shakespeare and got sensible results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6892" target="_blank">01:54:52.640</a></span> | <span class="t">All of the training code is roughly 200 lines of code. I will be releasing this code base.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6900" target="_blank">01:55:00.320</a></span> | <span class="t">So also it comes with all the Git log commits along the way as we built it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6905" target="_blank">01:55:05.200</a></span> | <span class="t">In addition to this code, I'm going to release the notebook, of course, the Google collab.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6911" target="_blank">01:55:11.520</a></span> | <span class="t">And I hope that gave you a sense for how you can train these models, like say GPT-3, that will be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6919" target="_blank">01:55:19.120</a></span> | <span class="t">architecturally basically identical to what we have, but they are somewhere between 10,000 and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6923" target="_blank">01:55:23.280</a></span> | <span class="t">1 million times bigger, depending on how you count. And so that's all I have for now. We did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6930" target="_blank">01:55:30.400</a></span> | <span class="t">not talk about any of the fine tuning stages that would typically go on top of this. So if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6934" target="_blank">01:55:34.880</a></span> | <span class="t">interested in something that's not just language modeling, but you actually want to, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6938" target="_blank">01:55:38.320</a></span> | <span class="t">say perform tasks or you want them to be aligned in a specific way, or you want to detect sentiment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6945" target="_blank">01:55:45.280</a></span> | <span class="t">or anything like that, basically anytime you don't want something that's just a document completer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6949" target="_blank">01:55:49.440</a></span> | <span class="t">you have to complete further stages of fine tuning, which we did not cover. And that could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6954" target="_blank">01:55:54.560</a></span> | <span class="t">be simple supervised fine tuning, or it can be something more fancy, like we see in Chatship-BT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6958" target="_blank">01:55:58.880</a></span> | <span class="t">where we actually train a reward model and then do rounds of PPO to align it with respect to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6963" target="_blank">01:56:03.840</a></span> | <span class="t">the reward model. So there's a lot more that can be done on top of it. I think for now we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6968" target="_blank">01:56:08.240</a></span> | <span class="t">starting to get to about two hours mark. So I'm going to kind of finish here. I hope you enjoyed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=6974" target="_blank">01:56:14.880</a></span> | <span class="t">the lecture and yeah go forth and transform. See you later.</span></div></div></body></html>