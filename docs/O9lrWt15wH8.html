<html><head><title>Long Form Question Answering (LFQA) in Haystack</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Long Form Question Answering (LFQA) in Haystack</h2><a href="https://www.youtube.com/watch?v=O9lrWt15wH8"><img src="https://i.ytimg.com/vi_webp/O9lrWt15wH8/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=260">4:20</a> Approaches to Question Answering<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=343">5:43</a> Components of QA Pipeline<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=538">8:58</a> LFQA Generator<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=580">9:40</a> Haystack Setup<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=632">10:32</a> Initialize Document Store<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=782">13:2</a> Getting Data<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1073">17:53</a> Indexing Embeddings<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1311">21:51</a> Initialize Generator<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1450">24:10</a> Asking Questions<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1572">26:12</a> Common Problems<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1772">29:32</a> Generator Memory<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1890">31:30</a> Few More Questions<br><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2094">34:54</a> Outro<br><br><div style="text-align: left;"><a href="./O9lrWt15wH8.html">Whisper Transcript</a> | <a href="./transcript_O9lrWt15wH8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=0" target="_blank">00:00:00.600</a></span> | <span class="t">Today, we are going to talk about a subdomain of question answering called long-form question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=8" target="_blank">00:00:08.480</a></span> | <span class="t">answering. Now, before we get into the specifics, let's just talk very quickly about question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=14" target="_blank">00:00:14.160</a></span> | <span class="t">answering as a subdomain of NLP. Question answering has, I think, exploded as a subdomain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=23" target="_blank">00:00:23.100</a></span> | <span class="t">of NLP in the past few years, mainly because I think question answering is an incredibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=31" target="_blank">00:00:31.300</a></span> | <span class="t">widely applicable use case for NLP. But it wasn't possible to do question answering or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=39" target="_blank">00:00:39.000</a></span> | <span class="t">not anything good with question answering until we had transformer models like BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=45" target="_blank">00:00:45.500</a></span> | <span class="t">So that means that as soon as we got something like BERT, the question answering became viable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=51" target="_blank">00:00:51.720</a></span> | <span class="t">and with the huge number of use cases for question answering, it obviously kind of took</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=59" target="_blank">00:00:59.300</a></span> | <span class="t">off. Now, question answering is quite complicated, but at its core, it's basically just the retrieval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=68" target="_blank">00:01:08.500</a></span> | <span class="t">of information in a more human-like way. And when we consider this, I think it makes it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=77" target="_blank">00:01:17.320</a></span> | <span class="t">really clear how broadly applicable question answering is, because almost every organization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=84" target="_blank">00:01:24.800</a></span> | <span class="t">in the world, if not all, are going to need to retrieve information. And for a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=92" target="_blank">00:01:32.960</a></span> | <span class="t">companies and particularly larger organizations, I think the act of information retrieval is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=100" target="_blank">00:01:40.120</a></span> | <span class="t">actually a big component of their day-to-day operations. Now, at the moment, most organizations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=109" target="_blank">00:01:49.240</a></span> | <span class="t">do information retrieval across a suite of tools. So they will have people using some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=117" target="_blank">00:01:57.640</a></span> | <span class="t">sort of internal search tools, which are typically keyword-based, which is generally not always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=126" target="_blank">00:02:06.080</a></span> | <span class="t">that helpful. Sometimes it's useful, but a lot of the time, it's not great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=132" target="_blank">00:02:12.720</a></span> | <span class="t">Then another key form of information retrieval in most organizations is literally person</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=139" target="_blank">00:02:19.840</a></span> | <span class="t">to person. So you go and ask someone who you think will probably know where some information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=145" target="_blank">00:02:25.600</a></span> | <span class="t">is, like a document or so on. And obviously, this sort of patchwork of information retrieval,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=154" target="_blank">00:02:34.200</a></span> | <span class="t">to an extent, sure it works, but it's inefficient. Now, if we consider that many organizations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=162" target="_blank">00:02:42.720</a></span> | <span class="t">contain thousands of employees, each of those employees producing pages upon pages of unstructured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=170" target="_blank">00:02:50.760</a></span> | <span class="t">data, e.g. pages of documents and texts that are meant for human consumption, in most cases,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=179" target="_blank">00:02:59.040</a></span> | <span class="t">all of that information is just being lost in some sort of void.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=184" target="_blank">00:03:04.400</a></span> | <span class="t">And rather than that information being lost in a void that we're never going to see again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=189" target="_blank">00:03:09.720</a></span> | <span class="t">and it becomes useless to the organization or the company, we can instead place it in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=196" target="_blank">00:03:16.960</a></span> | <span class="t">a database that a question answering agent has access to. And when we ask a question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=205" target="_blank">00:03:25.360</a></span> | <span class="t">to that Q&A agent, which we ask in a human-like way, it will go and retrieve the relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=210" target="_blank">00:03:30.420</a></span> | <span class="t">information for us instantly. Well, not instantly, but pretty close. The majority of data in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=217" target="_blank">00:03:37.600</a></span> | <span class="t">the world is unstructured. And there's a few different sources for this, but I think places</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=223" target="_blank">00:03:43.480</a></span> | <span class="t">like Forbes estimate that number to be around 90% of the world's data. So in your organization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=232" target="_blank">00:03:52.320</a></span> | <span class="t">you probably have a number similar to this. So 90% of your data is unstructured. That</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=238" target="_blank">00:03:58.240</a></span> | <span class="t">means it's meant for human consumption, not machines. And it means it's liable to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=243" target="_blank">00:04:03.400</a></span> | <span class="t">lost in that void where we're just never going to see that information ever again. Now, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=248" target="_blank">00:04:08.760</a></span> | <span class="t">massively inefficient. Question answering is an opportunity to not lose that and actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=257" target="_blank">00:04:17.140</a></span> | <span class="t">benefit from that information. Now, in question answering, there are two main approaches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=265" target="_blank">00:04:25.940</a></span> | <span class="t">In both cases of question answering, we saw those documents in, or usually we saw those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=274" target="_blank">00:04:34.040</a></span> | <span class="t">documents in a document store or vector database. So these documents are what we would call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=280" target="_blank">00:04:40.520</a></span> | <span class="t">sentences or paragraphs extracted from your, for example, PDFs or emails or whatever unstructured</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=288" target="_blank">00:04:48.920</a></span> | <span class="t">data you have out there. And we retrieve data from that. And then the next step is where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=297" target="_blank">00:04:57.080</a></span> | <span class="t">we have the two different forms of question answering. With that relevant information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=302" target="_blank">00:05:02.440</a></span> | <span class="t">that we have from our document store, based on a query that we've passed through there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=309" target="_blank">00:05:09.160</a></span> | <span class="t">we either generate an answer or we extract an answer. So obviously, when we're generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=316" target="_blank">00:05:16.480</a></span> | <span class="t">an answer, we look at all of the context that we've retrieved and we use an NLP model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=323" target="_blank">00:05:23.240</a></span> | <span class="t">generate some sort of human answer to our query based on that information. Otherwise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=332" target="_blank">00:05:32.220</a></span> | <span class="t">we use an extractive model, which is literally going to take a snippet of information from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=339" target="_blank">00:05:39.080</a></span> | <span class="t">the data that we have retrieved.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=342" target="_blank">00:05:42.600</a></span> | <span class="t">So there's a few components that I just described there. There was a document store at the start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=350" target="_blank">00:05:50.220</a></span> | <span class="t">When we're using a document store, which we will in most cases I'd imagine, we call that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=356" target="_blank">00:05:56.560</a></span> | <span class="t">open book question answering. Now, the reason it's called open book is it is like students</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=362" target="_blank">00:06:02.280</a></span> | <span class="t">in an exam. We have a typical exam. You don't have any outside materials to refer to. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=370" target="_blank">00:06:10.720</a></span> | <span class="t">have to rely on what is in your brain. That's very similar to using, for example, a generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=377" target="_blank">00:06:17.800</a></span> | <span class="t">model that, given a question, it doesn't refer to any document store. It just refers to what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=384" target="_blank">00:06:24.320</a></span> | <span class="t">is within its own memory or its own model memory. And that model memory has been built</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=391" target="_blank">00:06:31.280</a></span> | <span class="t">during model training. So that would be referred to as closed book, generative or abstractive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=398" target="_blank">00:06:38.560</a></span> | <span class="t">Q&A.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=399" target="_blank">00:06:39.960</a></span> | <span class="t">On the other hand, we have a document store. So that document store is like we are in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=404" target="_blank">00:06:44.880</a></span> | <span class="t">exam as students. And we have a open book that we can refer to for information. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=410" target="_blank">00:06:50.800</a></span> | <span class="t">not just relying on what is in our head. We're looking at the information in this book. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=416" target="_blank">00:06:56.240</a></span> | <span class="t">we still need to rely on the knowledge in our head in order to apply what is in that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=421" target="_blank">00:07:01.800</a></span> | <span class="t">book to the questions we're given in the exam. It's exactly the same for open book abstractive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=430" target="_blank">00:07:10.100</a></span> | <span class="t">question answering in that you have the generator model. But we're not just relying on a generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=437" target="_blank">00:07:17.760</a></span> | <span class="t">model to answer our questions. We are also relying on a document store, which is our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=442" target="_blank">00:07:22.520</a></span> | <span class="t">book and what is called a retrieval model. And this retrieval model is going to take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=449" target="_blank">00:07:29.320</a></span> | <span class="t">our question. It will encode it into a vector embedding, takes it to that document store,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=459" target="_blank">00:07:39.520</a></span> | <span class="t">which is actually just a vector database in our scenario of what we're doing. And in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=468" target="_blank">00:07:48.560</a></span> | <span class="t">vector database, what you have is lots of other vector embeddings, which are essentially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=474" target="_blank">00:07:54.740</a></span> | <span class="t">numerical representations of the documents that you stored in it before. So remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=480" target="_blank">00:08:00.720</a></span> | <span class="t">documents are those chunks of paragraph or sentences from different sources. That vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=486" target="_blank">00:08:06.400</a></span> | <span class="t">database has loads of these what we call context vectors. And we pass our query vector into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=497" target="_blank">00:08:17.360</a></span> | <span class="t">that document store or vector database, and we retrieve the most similar context vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=504" target="_blank">00:08:24.160</a></span> | <span class="t">from there and pass them back to our retrieval pipeline. Then that is passed to our generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=512" target="_blank">00:08:32.440</a></span> | <span class="t">model. Our generator model is going to see the query followed by the set of retrieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=519" target="_blank">00:08:39.280</a></span> | <span class="t">relevant, hopefully, context. And it uses all of that to generate an answer. So we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=528" target="_blank">00:08:48.360</a></span> | <span class="t">see with this open book format, we are passing a lot more information into the generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=533" target="_blank">00:08:53.960</a></span> | <span class="t">which allows the generator to answer more specific questions. Now, long form question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=540" target="_blank">00:09:00.960</a></span> | <span class="t">answering, which is what we are going to go through, is one form of this abstractive question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=549" target="_blank">00:09:09.180</a></span> | <span class="t">answering. The only difference with -- or the one thing that makes long form question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=554" target="_blank">00:09:14.960</a></span> | <span class="t">answering long form question answering is that the generator model has been trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=560" target="_blank">00:09:20.960</a></span> | <span class="t">to produce a multi-sentence output. So rather than just outputting maybe an answer of three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=569" target="_blank">00:09:29.600</a></span> | <span class="t">or four words or one sentence, it is going to try and output a full paragraph answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=576" target="_blank">00:09:36.280</a></span> | <span class="t">to you. So that's long form question answering, or LFQA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=580" target="_blank">00:09:40.760</a></span> | <span class="t">So we are going to implement LFQA in Haystack. Haystack is a very popular NLP library, mainly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=591" target="_blank">00:09:51.780</a></span> | <span class="t">for question answering. Now, to install Haystack and the other libraries that we need, today</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=599" target="_blank">00:09:59.140</a></span> | <span class="t">we do this. So we have PIP installed. We need the Pinecone client, farm Haystack, specify</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=606" target="_blank">00:10:06.180</a></span> | <span class="t">Pinecone in there, datasets, and pandas. Actually, I think you can ignore pandas. Let's remove</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=615" target="_blank">00:10:15.700</a></span> | <span class="t">that. So just these three here. With farm Haystack, we are going to be using something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=623" target="_blank">00:10:23.980</a></span> | <span class="t">called a Pinecone document store. So for that, you need either version 1.3 or above. Now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=632" target="_blank">00:10:32.380</a></span> | <span class="t">to initialize that Pinecone document store, so remember the document store is that thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=637" target="_blank">00:10:37.520</a></span> | <span class="t">that you saw on the right before, where we're storing all of our context vectors. We will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=644" target="_blank">00:10:44.780</a></span> | <span class="t">do this. So we first need an API key from Pinecone. So there's a link here. I'll just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=650" target="_blank">00:10:50.680</a></span> | <span class="t">open it and show you quickly. And that will bring you to this page here. Now, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=656" target="_blank">00:10:56.420</a></span> | <span class="t">sign up for free. You don't need to pay for anything. And we don't need to pay for anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=660" target="_blank">00:11:00.660</a></span> | <span class="t">to do what we're doing here either. It's all completely free. So you just sign up. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=666" target="_blank">00:11:06.380</a></span> | <span class="t">once you've signed up, you will see it should just be one project on your homepage. So for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=673" target="_blank">00:11:13.740</a></span> | <span class="t">me, it is the default project, James's default project. So you can go into that. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=680" target="_blank">00:11:20.660</a></span> | <span class="t">on the left over here, we have API keys. So we open that. And we get our default API key.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=688" target="_blank">00:11:28.000</a></span> | <span class="t">We can just copy it. So we come over here. And we use that to authenticate our Pinecone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=695" target="_blank">00:11:35.600</a></span> | <span class="t">document store back in our code. So I would paste that here. And with that, we just run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=702" target="_blank">00:11:42.720</a></span> | <span class="t">this. So we are initializing our document store. We are calling our index. So remember,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=708" target="_blank">00:11:48.480</a></span> | <span class="t">document store is actually a vector database in this case. And inside that vector database,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=714" target="_blank">00:11:54.680</a></span> | <span class="t">we have what's called an index. The index is basically the list of all the context vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=720" target="_blank">00:12:00.160</a></span> | <span class="t">that we have. We call that index haystack LFQA. Now, you can call it whatever you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=726" target="_blank">00:12:06.920</a></span> | <span class="t">But when you are wanting to load this document store again, you need to specify the correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=734" target="_blank">00:12:14.320</a></span> | <span class="t">index. That's all. That's the only difference it makes. Similarity, we're using cosine similarity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=740" target="_blank">00:12:20.420</a></span> | <span class="t">And we're using embedding dimensions 768. Now, it's important to align this to whatever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=748" target="_blank">00:12:28.880</a></span> | <span class="t">the similarity metric and embedding dimension of your retrieval model is. In our case, cosine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=756" target="_blank">00:12:36.600</a></span> | <span class="t">and 768. These are pretty typical retriever model metrics and dimensionalities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=764" target="_blank">00:12:44.200</a></span> | <span class="t">Now, we can go down. We can check our metric type. We can also see the number of documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=771" target="_blank">00:12:51.240</a></span> | <span class="t">and the embeddings that we have in there. Now, we don't have any at the moment because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=776" target="_blank">00:12:56.760</a></span> | <span class="t">we haven't pushed anything to our document store. We don't have any data. So we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=782" target="_blank">00:13:02.840</a></span> | <span class="t">to get some data. For that, we are going to use Hugging Face datasets. So over here. We're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=792" target="_blank">00:13:12.180</a></span> | <span class="t">going to use this dataset here, which is a set of snippets from Wikipedia. There are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=801" target="_blank">00:13:21.280</a></span> | <span class="t">a lot of them. In full, this dataset is 9 gigabytes. Now, to avoid downloading this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=807" target="_blank">00:13:27.820</a></span> | <span class="t">full dataset, what we do is set streaming equal to true. And what this will do is allow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=813" target="_blank">00:13:33.700</a></span> | <span class="t">us to iteratively load one record at a time from this dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=819" target="_blank">00:13:39.840</a></span> | <span class="t">And we can check what we have inside that dataset by running this. So next, we create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=825" target="_blank">00:13:45.480</a></span> | <span class="t">a iterable from our dataset. And we see this. So the main things to take note of here are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=834" target="_blank">00:13:54.060</a></span> | <span class="t">section title and passage text. Passage text is going to create our context or that document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=842" target="_blank">00:14:02.920</a></span> | <span class="t">And there are a couple of other things. So history is going to be what we are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=848" target="_blank">00:14:08.200</a></span> | <span class="t">filter for in our dataset. This is a very big dataset, and I don't want to process all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=852" target="_blank">00:14:12.880</a></span> | <span class="t">of it. So I'm restricting our scope to just history, and we're going to only return a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=858" target="_blank">00:14:18.200</a></span> | <span class="t">certain number of records from that section. That's important to us purely for that filtering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=864" target="_blank">00:14:24.560</a></span> | <span class="t">out of other sections or section titles. And we will include article title as metadata</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=876" target="_blank">00:14:36.700</a></span> | <span class="t">in our documents, although it's not really important because we're not actually going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=879" target="_blank">00:14:39.820</a></span> | <span class="t">to use it. It's just so you can see how you would include metadata in there in case you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=885" target="_blank">00:14:45.640</a></span> | <span class="t">did want to use it. So here, what we're doing is filtering only for documents that have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=892" target="_blank">00:14:52.740</a></span> | <span class="t">the section title history. And we just get this iterable object because we're streaming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=900" target="_blank">00:15:00.380</a></span> | <span class="t">So it just knows now when we're streaming one by one, when it's pulling an object, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=906" target="_blank">00:15:06.700</a></span> | <span class="t">going to check if that object section title starts with history. If it does, it will pull</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=913" target="_blank">00:15:13.100</a></span> | <span class="t">it. If not, it will move on to the next one. So we're just going to pull those with history.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=918" target="_blank">00:15:18.600</a></span> | <span class="t">Now what we need to do is process those and add them to our document store. Now what I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=925" target="_blank">00:15:25.620</a></span> | <span class="t">done here is said, "Okay, we are only going to pull 50,000 of those and no more." At that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=932" target="_blank">00:15:32.580</a></span> | <span class="t">point, we cut off. And it's actually, it cuts off just before 50,000. And what we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=938" target="_blank">00:15:38.660</a></span> | <span class="t">to do is we're going to add in a single batch. So we're going to loop through all of, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=944" target="_blank">00:15:44.020</a></span> | <span class="t">we're going to pull all of these records. We're going to collect 10,000 of them, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=948" target="_blank">00:15:48.420</a></span> | <span class="t">then we're going to add them to our document store. And this is a Haystack document object.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=957" target="_blank">00:15:57.380</a></span> | <span class="t">So we have a content. The content is the document text, that big paragraph you saw before. Meta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=964" target="_blank">00:16:04.540</a></span> | <span class="t">is any metadata that we'd like to add in there. Now with the Pinecone document store, we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=969" target="_blank">00:16:09.460</a></span> | <span class="t">use metadata filtering, although I won't show you how to do that here. But that can be really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=974" target="_blank">00:16:14.520</a></span> | <span class="t">useful if it's something you're interested in. So that's how you'd add metadata to your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=980" target="_blank">00:16:20.220</a></span> | <span class="t">document as well. And all I'm doing is adding that doc to a docs list. And we increase the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=988" target="_blank">00:16:28.700</a></span> | <span class="t">counter. And once the counter hits the batch size, which is the 10,000, we write those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=998" target="_blank">00:16:38.100</a></span> | <span class="t">documents to our document store. Now you will remember I said the document store is a vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1004" target="_blank">00:16:44.900</a></span> | <span class="t">database, and inside the vector database, we have vectors. At the moment, when we write</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1009" target="_blank">00:16:49.740</a></span> | <span class="t">those documents, we're not actually creating those vectors, because we haven't specified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1013" target="_blank">00:16:53.820</a></span> | <span class="t">the retriever model yet. We're going to do that later. So at the moment, what we're doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1018" target="_blank">00:16:58.860</a></span> | <span class="t">is kind of adding the documents as just plain text to almost be ready to be processed into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1027" target="_blank">00:17:07.700</a></span> | <span class="t">vectors to put into that vector database. So it's almost like they're in limbo, waiting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1032" target="_blank">00:17:12.820</a></span> | <span class="t">to be added to our database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1038" target="_blank">00:17:18.500</a></span> | <span class="t">So we add all of those. It can take a little bit of time, not too long, though. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1044" target="_blank">00:17:24.180</a></span> | <span class="t">once we hit or get close to 50,000, we break. So we stop the loop. And then we can see,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1052" target="_blank">00:17:32.100</a></span> | <span class="t">if we get the document count, we see that we have the almost 50,000 documents in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1058" target="_blank">00:17:38.340</a></span> | <span class="t">But then when we look at the embedding count, zero. And that's because they're waiting to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1064" target="_blank">00:17:44.620</a></span> | <span class="t">be added into the vector database, the text documents. So they exist as documents. They</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1070" target="_blank">00:17:50.760</a></span> | <span class="t">just don't exist as embeddings yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1073" target="_blank">00:17:53.860</a></span> | <span class="t">So what we now need to do is convert those documents into vector embeddings. Now, to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1084" target="_blank">00:18:04.060</a></span> | <span class="t">do that, we need a retriever model. Now, at this point, it's probably best to check if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1092" target="_blank">00:18:12.700</a></span> | <span class="t">you have a GPU that is available, like a CUDA-enabled GPU. If you don't, this step will take longer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1101" target="_blank">00:18:21.340</a></span> | <span class="t">unfortunately. But if you do, that's great, because this will be pretty quick in most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1106" target="_blank">00:18:26.380</a></span> | <span class="t">cases, depending on your GPU, of course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1111" target="_blank">00:18:31.300</a></span> | <span class="t">So we initialize our retriever model. So we're using the embedding retriever. And this allows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1118" target="_blank">00:18:38.380</a></span> | <span class="t">us to use what are called sentence transformer models from the sentence transformers library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1123" target="_blank">00:18:43.380</a></span> | <span class="t">Now, I'm using this model here. And we can find all the sentence transformer models over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1129" target="_blank">00:18:49.980</a></span> | <span class="t">on the HuggingFace model hub. So let's have a quick look at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1133" target="_blank">00:18:53.720</a></span> | <span class="t">So we are here, HuggingFace.co/models. And I can paste that model name. Maybe I'll just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1142" target="_blank">00:19:02.420</a></span> | <span class="t">do flight sentence embeddings. Now, flight sentence embeddings are a set of models that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1147" target="_blank">00:19:07.180</a></span> | <span class="t">were trained on a lot of data using the Flights library. But there are a lot of other sentence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1154" target="_blank">00:19:14.740</a></span> | <span class="t">transform models. See the one we're using here. So for example, if we go sentence transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1161" target="_blank">00:19:21.660</a></span> | <span class="t">you will see all of the default models used by the sentence transformers library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1168" target="_blank">00:19:28.100</a></span> | <span class="t">So we are using this MPNet model. We also specify that we're using sentence transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1174" target="_blank">00:19:34.980</a></span> | <span class="t">model format. And when we initialize our retriever, we also need to add the document store that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1180" target="_blank">00:19:40.740</a></span> | <span class="t">we'll be retrieving documents from. So we've already initialized our document store, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1186" target="_blank">00:19:46.300</a></span> | <span class="t">we just add that in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1189" target="_blank">00:19:49.900</a></span> | <span class="t">And at this point, it's time for us to update those embeddings. So when we say update embeddings,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1198" target="_blank">00:19:58.140</a></span> | <span class="t">what this is going to do is look at any of all of the documents that are ready and with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1204" target="_blank">00:20:04.140</a></span> | <span class="t">your document store. And it's going to use the retriever model that you pass here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1209" target="_blank">00:20:09.500</a></span> | <span class="t">embed them into vector representations of those contents. And then it's going to store</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1216" target="_blank">00:20:16.700</a></span> | <span class="t">those in your Pinecone Vector database. That will be processed. And at this point, we could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1223" target="_blank">00:20:23.620</a></span> | <span class="t">run this get embedding count again, and we would get this 49995 value.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1231" target="_blank">00:20:31.500</a></span> | <span class="t">Now another way that you can also see this number is if we go back to our Pinecone dashboard,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1241" target="_blank">00:20:41.980</a></span> | <span class="t">we can head over to our index, so Haystack LFQA. We click on that, scroll down, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1251" target="_blank">00:20:51.220</a></span> | <span class="t">can click on index info. And then we can see the total number of vectors, which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1255" target="_blank">00:20:55.140</a></span> | <span class="t">same. So that number will be reflected in your vector database once you have updated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1261" target="_blank">00:21:01.900</a></span> | <span class="t">the embeddings using your retriever model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1266" target="_blank">00:21:06.180</a></span> | <span class="t">And at that point, we can just test the first part of our LFQA pipeline, which is just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1273" target="_blank">00:21:13.820</a></span> | <span class="t">document store and a retriever. So we initialize this document search pipeline with our retriever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1279" target="_blank">00:21:19.900</a></span> | <span class="t">model, and we can ask the question, when was the first electric power system built? And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1285" target="_blank">00:21:25.900</a></span> | <span class="t">all this is going to do is retrieve the relevant context. It's not going to generate an answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1293" target="_blank">00:21:33.100</a></span> | <span class="t">yet. It's just going to retrieve what it thinks is the relevant context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1297" target="_blank">00:21:37.900</a></span> | <span class="t">So we have here electrical power system in 1881. Two electricians built the world's first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1306" target="_blank">00:21:46.140</a></span> | <span class="t">power system in Goldaming in England, which is pretty good. So that's pretty cool. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1316" target="_blank">00:21:56.060</a></span> | <span class="t">what we now need to do is we have our document store or vector database, and then we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1321" target="_blank">00:22:01.140</a></span> | <span class="t">our retriever model. Now we need to initialize our generator model to actually generate those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1326" target="_blank">00:22:06.180</a></span> | <span class="t">answers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1328" target="_blank">00:22:08.180</a></span> | <span class="t">So we come down here. We are going to be using a sequence-to-sequence generator. And we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1336" target="_blank">00:22:16.340</a></span> | <span class="t">going to be using this model here. So this, again, you can find this on the Hugging Face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1341" target="_blank">00:22:21.900</a></span> | <span class="t">Model Hub. And there are different generator models you can use here, but you do want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1349" target="_blank">00:22:29.780</a></span> | <span class="t">find one that has been trained for long-form question answering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1353" target="_blank">00:22:33.420</a></span> | <span class="t">So for example, we have the BART LFQA that you can find here, or you have the BART Explain</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1361" target="_blank">00:22:41.460</a></span> | <span class="t">Like I'm Five model that we can find here. Now, I think the BART LFQA model seems to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1368" target="_blank">00:22:48.840</a></span> | <span class="t">perform better, so we have gone with that. Also, it's been trained with a newer dataset.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1375" target="_blank">00:22:55.940</a></span> | <span class="t">And yeah, we just initialize it like that. Now, when we say sequence-to-sequence, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1380" target="_blank">00:23:00.620</a></span> | <span class="t">because it is taking in a sequence of characters or some input, and it's going to output a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1386" target="_blank">00:23:06.220</a></span> | <span class="t">sequence of characters, e.g. the output, the answer. And if you are curious, the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1393" target="_blank">00:23:13.700</a></span> | <span class="t">will look something like what you see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1396" target="_blank">00:23:16.420</a></span> | <span class="t">So we have the question, and then we have the user's query. It's followed by context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1401" target="_blank">00:23:21.780</a></span> | <span class="t">And then we have this P token here. And that P token indicates to the model the start of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1408" target="_blank">00:23:28.420</a></span> | <span class="t">new context that has been retrieved from our document store. So in this case, we've retrieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1415" target="_blank">00:23:35.100</a></span> | <span class="t">three contexts, and all of that is being passed to the generator model, where it will then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1421" target="_blank">00:23:41.900</a></span> | <span class="t">generate an answer based on all of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1424" target="_blank">00:23:44.780</a></span> | <span class="t">OK. So yeah, we just initialize the generator model, and then we initialize the generative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1433" target="_blank">00:23:53.700</a></span> | <span class="t">Q and A pipeline. We pass in the generator and the retriever model. We don't need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1438" target="_blank">00:23:58.580</a></span> | <span class="t">include document store here, because the document store has already been passed to the retriever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1443" target="_blank">00:24:03.700</a></span> | <span class="t">model when we're initializing that. So it's almost like it's embedded within the retriever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1448" target="_blank">00:24:08.860</a></span> | <span class="t">So we don't need to worry about adding that in there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1450" target="_blank">00:24:10.940</a></span> | <span class="t">And then we can begin asking questions. Now, this is where it starts to get, I think, more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1454" target="_blank">00:24:14.340</a></span> | <span class="t">interesting. Now, one thing to make note of here is we have this top K parameter, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1460" target="_blank">00:24:20.460</a></span> | <span class="t">that's just saying how many contexts to retrieve in the context of our retriever model, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1468" target="_blank">00:24:28.040</a></span> | <span class="t">then for the generator, how many answers to generate. So in this case, we're retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1473" target="_blank">00:24:33.900</a></span> | <span class="t">three contexts, and then we are generating one answer based on the query and those three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1479" target="_blank">00:24:39.780</a></span> | <span class="t">contexts, like we saw in the example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1483" target="_blank">00:24:43.820</a></span> | <span class="t">So in this, I'm asking, what is a wall of currents? It's good to be specific to test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1491" target="_blank">00:24:51.220</a></span> | <span class="t">this. And if we have the data within our data set, it seems to be pretty good at pulling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1498" target="_blank">00:24:58.960</a></span> | <span class="t">that out and producing a relatively accurate answer. So the wall of currents was a rivalry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1505" target="_blank">00:25:05.860</a></span> | <span class="t">between Thomas Edison and George Westinghouse's companies over which form of transmission,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1511" target="_blank">00:25:11.580</a></span> | <span class="t">DC or AC, was superior. That's the answer, which is pretty cool. And we can see what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1517" target="_blank">00:25:17.940</a></span> | <span class="t">it's pulled that from. So it's pulled it from this content, this content, and this content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1528" target="_blank">00:25:28.580</a></span> | <span class="t">So there were three parts that got fed into the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1534" target="_blank">00:25:34.860</a></span> | <span class="t">And that's good. We can see a lot of information there, but maybe we can see a little bit too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1539" target="_blank">00:25:39.140</a></span> | <span class="t">much information. So we can actually use the print answers utility to minimize what we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1546" target="_blank">00:25:46.900</a></span> | <span class="t">outputting there. And here we get just this, which is obviously a lot easier to read. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1552" target="_blank">00:25:52.180</a></span> | <span class="t">we just pass our result into print answers and specify details of minimum. The rest of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1557" target="_blank">00:25:57.140</a></span> | <span class="t">that is the same as what we asked before. So it's much more readable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1562" target="_blank">00:26:02.620</a></span> | <span class="t">Now one thing to point out here is that this is actually a very good answer, but maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1570" target="_blank">00:26:10.460</a></span> | <span class="t">there's not that much detail. Now, if we find that we're not getting much detail in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1576" target="_blank">00:26:16.100</a></span> | <span class="t">answers or that the answer is just wrong, what the issue might be is first, the retrieved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1586" target="_blank">00:26:26.180</a></span> | <span class="t">context may not contain any relevant information for the model to actually view and answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1593" target="_blank">00:26:33.800</a></span> | <span class="t">the question correctly. So it's not retrieving relevant information from that external open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1601" target="_blank">00:26:41.700</a></span> | <span class="t">book document source.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1604" target="_blank">00:26:44.100</a></span> | <span class="t">And the second is if it's not also not retrieving information from there and it's also not retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1610" target="_blank">00:26:50.660</a></span> | <span class="t">information from-- you remember I mentioned that these models can have a memory. If it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1615" target="_blank">00:26:55.280</a></span> | <span class="t">not able to find any relevant information within its memory for your particular query,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1622" target="_blank">00:27:02.860</a></span> | <span class="t">if both of those conditions are not satisfied, so we don't have relevant information coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1630" target="_blank">00:27:10.820</a></span> | <span class="t">from the external source and we don't have relevant information coming from the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1634" target="_blank">00:27:14.140</a></span> | <span class="t">memory, the generator is going to output usually something nonsensical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1641" target="_blank">00:27:21.580</a></span> | <span class="t">So in this scenario, we have two options really. The generator model, we can increase its size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1649" target="_blank">00:27:29.060</a></span> | <span class="t">so we can use a larger generator model because larger generator models have more model parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1655" target="_blank">00:27:35.820</a></span> | <span class="t">which means they have basically more memory that they have learned during training. Or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1663" target="_blank">00:27:43.340</a></span> | <span class="t">we can increase the amount of data that we are pulling from the document store. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1670" target="_blank">00:27:50.420</a></span> | <span class="t">we are just returning three documents or contexts, we can increase it to 10 because then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1677" target="_blank">00:27:57.780</a></span> | <span class="t">generator is being fed a lot more information and it might be that the correct information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1685" target="_blank">00:28:05.620</a></span> | <span class="t">that we need may come in maybe context five or context six and nine. And the generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1693" target="_blank">00:28:13.260</a></span> | <span class="t">will see that and be like, OK, that's the answer. I'm going to reformulate this into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1699" target="_blank">00:28:19.220</a></span> | <span class="t">my answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1702" target="_blank">00:28:22.120</a></span> | <span class="t">So we can try that here. Now, we already got a good answer, but we can just see what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1706" target="_blank">00:28:26.460</a></span> | <span class="t">get if we increase the retriever. So audio retrieved number of documents, so increase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1712" target="_blank">00:28:32.500</a></span> | <span class="t">that to 10. And we see that we get this much longer chunk of text now. And I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1720" target="_blank">00:28:40.060</a></span> | <span class="t">first half of this is relatively accurate. So we have this in 1891, first power system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1729" target="_blank">00:28:49.220</a></span> | <span class="t">was installed in the United States. I think that's relatively correct. And then it starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1736" target="_blank">00:28:56.780</a></span> | <span class="t">to get a little bit silly after that because we've pulled more context from our document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1745" target="_blank">00:29:05.660</a></span> | <span class="t">store. But with that, we have pulled in more irrelevant information because we're retrieving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1752" target="_blank">00:29:12.020</a></span> | <span class="t">10 now. So there's a good chance that the last few of those are not relevant. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1756" target="_blank">00:29:16.740</a></span> | <span class="t">feeding a lot of irrelevant information into our generator model. And so it starts to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1761" target="_blank">00:29:21.180</a></span> | <span class="t">confused and then it can start to ramble like we see here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1767" target="_blank">00:29:27.420</a></span> | <span class="t">So that's what we see happening. Another thing I just want to point out is that the generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1776" target="_blank">00:29:36.180</a></span> | <span class="t">has this memory. So a lot of people always think when they hear, okay, the generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1783" target="_blank">00:29:43.060</a></span> | <span class="t">has memory, does that mean I don't need the document store? Because we have this memory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1786" target="_blank">00:29:46.940</a></span> | <span class="t">can't I just fine tune the model so that it knows everything within my particular use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1791" target="_blank">00:29:51.300</a></span> | <span class="t">case? In some cases, yes, you might be able to do that. But it generally only works for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1799" target="_blank">00:29:59.500</a></span> | <span class="t">more general questions or general knowledge. If you start to get specific, it tends to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1805" target="_blank">00:30:05.980</a></span> | <span class="t">fail with that sort of memory part because the memory can only source so much information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1812" target="_blank">00:30:12.260</a></span> | <span class="t">And in the end, what you will probably need is you want a model with good memory so it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1817" target="_blank">00:30:17.660</a></span> | <span class="t">can maybe pull out some facts from there. But for anything specific, it's probably going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1822" target="_blank">00:30:22.260</a></span> | <span class="t">to need to refer to its document store.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1826" target="_blank">00:30:26.140</a></span> | <span class="t">So what we have done here is we've asked the same question, but this time I've replaced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1830" target="_blank">00:30:30.980</a></span> | <span class="t">the retrieve document with just nothing. And we can see the result of that straight away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1836" target="_blank">00:30:36.220</a></span> | <span class="t">So the answer is, I'm not sure what you mean by war. So it has no idea what the war occurrence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1843" target="_blank">00:30:43.300</a></span> | <span class="t">is. It doesn't have that information within its memory. So without that external document</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1848" target="_blank">00:30:48.860</a></span> | <span class="t">source, it doesn't know what to say. It's just, OK, I don't even know what war is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1857" target="_blank">00:30:57.380</a></span> | <span class="t">But like I said, in some cases, particularly when you're asking more general knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1862" target="_blank">00:31:02.700</a></span> | <span class="t">query, it will be able to pull that out from its memory. So who was the first person on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1868" target="_blank">00:31:08.300</a></span> | <span class="t">the moon? It knows this because it's such a common thing to know. It's probably seen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1874" target="_blank">00:31:14.500</a></span> | <span class="t">it in the training data that the model has been trained on a million times. Maybe not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1879" target="_blank">00:31:19.340</a></span> | <span class="t">a million, but a few times at least. So that is the first man to walk on the moon was Neil</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1886" target="_blank">00:31:26.500</a></span> | <span class="t">Armstrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1887" target="_blank">00:31:27.500</a></span> | <span class="t">OK, cool. So I think that's pretty much it. We can ask a few more questions. When was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1894" target="_blank">00:31:34.900</a></span> | <span class="t">the first electrical power system built? So we ask this in the start, and it will give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1898" target="_blank">00:31:38.980</a></span> | <span class="t">us this answer. If we want to confirm that this is correct-- so this is what I did with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1907" target="_blank">00:31:47.260</a></span> | <span class="t">this. I was a bit confused because Google was telling me something different. You can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1912" target="_blank">00:31:52.100</a></span> | <span class="t">print out the contents using this. So we loop through the result documents, and we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1919" target="_blank">00:31:59.220</a></span> | <span class="t">print dot content. And this, OK, so two electricians built the first power system at gold damming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1926" target="_blank">00:32:06.820</a></span> | <span class="t">in England. So that information is actually coming from somewhere. It's not just making</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1930" target="_blank">00:32:10.940</a></span> | <span class="t">it up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1932" target="_blank">00:32:12.220</a></span> | <span class="t">So that can be really useful. Another thing just to be aware of with generators is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1938" target="_blank">00:32:18.180</a></span> | <span class="t">they can generate misleading information. So you need to be careful with that. So for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1946" target="_blank">00:32:26.780</a></span> | <span class="t">example, in this one, I asked, where did COVID-19 originate? Now, this is pretty unfair because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1952" target="_blank">00:32:32.140</a></span> | <span class="t">the generator probably hasn't seen anything about COVID-19. And at the same time, it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1960" target="_blank">00:32:40.460</a></span> | <span class="t">have any COVID-19 information within its document store because we looked at history, not anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1967" target="_blank">00:32:47.540</a></span> | <span class="t">else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1969" target="_blank">00:32:49.060</a></span> | <span class="t">So it just says, COVID-19 isn't a virus, which it is. It's a bacterium. So straightaway,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1975" target="_blank">00:32:55.900</a></span> | <span class="t">that's pretty wrong. So just one example of where you need to just be cautious with this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1985" target="_blank">00:33:05.580</a></span> | <span class="t">sort of thing because it can just give completely wrong answers if it doesn't have the relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1990" target="_blank">00:33:10.780</a></span> | <span class="t">information available to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1992" target="_blank">00:33:12.820</a></span> | <span class="t">So with that, there's a couple of things you could do to mitigate that. You can, one, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=1998" target="_blank">00:33:18.180</a></span> | <span class="t">include the sources of information. If you build some sort of search interface, make</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2003" target="_blank">00:33:23.340</a></span> | <span class="t">sure you include those so users can look at that and see where this information is coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2007" target="_blank">00:33:27.700</a></span> | <span class="t">from. And two, there are confidence scores that are given to these answers. So you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2017" target="_blank">00:33:37.500</a></span> | <span class="t">put threshold. So you say anything below 0.2 confidence, we just don't show or we show,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2026" target="_blank">00:33:46.220</a></span> | <span class="t">I'm not confident in this answer, but it might be this or something along those lines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2034" target="_blank">00:33:54.580</a></span> | <span class="t">So that's just one drawback. We'll just go through a few final questions. So what was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2040" target="_blank">00:34:00.620</a></span> | <span class="t">NASA's most expensive project? I would say the Space Shuttle project. That's correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2047" target="_blank">00:34:07.260</a></span> | <span class="t">Tell me something interesting about the history of the Earth. In this case, it really, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2051" target="_blank">00:34:11.420</a></span> | <span class="t">nothing, it's not really history, I don't think. But it does give us an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2057" target="_blank">00:34:17.180</a></span> | <span class="t">fact about the magnetic field being weak compared to the rest of the solar system. I don't know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2061" target="_blank">00:34:21.460</a></span> | <span class="t">if that's true or not. It seems like it might not be. When it says compared to the rest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2067" target="_blank">00:34:27.140</a></span> | <span class="t">of the solar system, I'm thinking, is it weak compared to Mars? I don't think so. So that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2072" target="_blank">00:34:32.580</a></span> | <span class="t">might not be true. Another thing to be wary of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2075" target="_blank">00:34:35.300</a></span> | <span class="t">Who created the Nobel Prize and why? So this one is correct and I think quite interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2082" target="_blank">00:34:42.100</a></span> | <span class="t">And how is the Nobel Prize funded? We kind of see it down here, so I know the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2086" target="_blank">00:34:46.500</a></span> | <span class="t">is in there, hence why I've asked the question. And it tells you that as well with a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2092" target="_blank">00:34:52.300</a></span> | <span class="t">bit more information. So that is it for long-form question answering with Haystack. As I said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2103" target="_blank">00:35:03.340</a></span> | <span class="t">at the start, I think question answering is one of the most widely applicable forms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2109" target="_blank">00:35:09.860</a></span> | <span class="t">NLP or use cases of NLP. It can be applied almost everywhere. So it's a really good one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2118" target="_blank">00:35:18.700</a></span> | <span class="t">to just go away and see maybe I can implement document search in my organization or I can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2129" target="_blank">00:35:29.420</a></span> | <span class="t">create some sort of internal search engine that helps people in some way. And I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2136" target="_blank">00:35:36.740</a></span> | <span class="t">in a lot of organizations, it's very possible to do this and add a lot of benefit and reduce</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2144" target="_blank">00:35:44.420</a></span> | <span class="t">a lot of friction in day-to-day processes of most companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=O9lrWt15wH8&t=2150" target="_blank">00:35:50.940</a></span> | <span class="t">So that's it for this video. I hope it's been useful and I will see you in the next one.</span></div></div></body></html>