<html><head><title>Stanford CS25: V1 I Self Attention and Non-parametric transformers (NPTs)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V1 I Self Attention and Non-parametric transformers (NPTs)</h2><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk"><img src="https://i.ytimg.com/vi/zejXBg-2Vpk/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=0">0:0</a> <Untitled Chapter 1><br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=205">3:25</a> Fast Auto Repressive Decoding<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=841">14:1</a> Motivation and a Brief Summary<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=906">15:6</a> Parametric Prediction<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=962">16:2</a> Non-Parametric Transformer Architecture<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1420">23:40</a> Three Key Components to Npts<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1484">24:44</a> Dataset Matrix<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1508">25:8</a> Masking Matrix<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1610">26:50</a> Linear Embedding<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1863">31:3</a> Masking Based Training Objective<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1944">32:24</a> Stochastic Target Masking<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2240">37:20</a> Results<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2488">41:28</a> Poker Hand Data<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2552">42:32</a> Deep Kernel Learning<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3285">54:45</a> Semi-Synthetic Dataset<br><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3351">55:51</a> Attention Maps<br><br><div style="text-align: left;"><a href="./zejXBg-2Vpk.html">Whisper Transcript</a> | <a href="./transcript_zejXBg-2Vpk.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">>> Thanks so much. Great to be here and happy Halloween, belated Halloween everyone. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=10" target="_blank">00:00:10.880</a></span> | <span class="t">I think the talk is going to be split into two sections. So I'll start by spending like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=16" target="_blank">00:00:16.000</a></span> | <span class="t">10 minutes, 15 minutes chatting about transformers in general. But I'm assuming most of you are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=22" target="_blank">00:00:22.120</a></span> | <span class="t">familiar with them and we can move on to MPTs, which Yannick and Neil will be presenting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=28" target="_blank">00:00:28.960</a></span> | <span class="t">So let's see. I'm going to like try to fly through the transformer overview and maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=36" target="_blank">00:00:36.520</a></span> | <span class="t">spend a little bit extra time on like the history of transformers and maybe just tell</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=42" target="_blank">00:00:42.200</a></span> | <span class="t">the story a little bit. I think that might be more interesting. So just in terms of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=49" target="_blank">00:00:49.640</a></span> | <span class="t">transformer architecture, the two kinds of things that it introduced for the first time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=54" target="_blank">00:00:54.520</a></span> | <span class="t">were multi-head attention and self-attention. And then it combined those with fast autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=60" target="_blank">00:01:00.880</a></span> | <span class="t">decoding. So before the transformer, pretty much everyone was using LSTMs and LSTMs with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=67" target="_blank">00:01:07.560</a></span> | <span class="t">attention. But I'll try to get into the difference of self-attention, multi-head attention. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=76" target="_blank">00:01:16.520</a></span> | <span class="t">originally you would have two sequences and you would have a attention module, which would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=83" target="_blank">00:01:23.160</a></span> | <span class="t">attend from the source to the target. And so each token or each word in the source sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=89" target="_blank">00:01:29.120</a></span> | <span class="t">would get associated with, you know, a soft approximation of one element in the target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=94" target="_blank">00:01:34.800</a></span> | <span class="t">sequence. And so you'd end up with something like this. But with self-attention, we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=101" target="_blank">00:01:41.680</a></span> | <span class="t">away with the two separate sequences. We make them both the same. And so you're relating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=107" target="_blank">00:01:47.200</a></span> | <span class="t">each element within the sequence to another element in the sequence. And so the idea here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=116" target="_blank">00:01:56.320</a></span> | <span class="t">is that you're learning a relationship of the words within a sentence to the other words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=121" target="_blank">00:02:01.080</a></span> | <span class="t">So you can imagine something like an adjective, which is being applied to a noun. And so you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=126" target="_blank">00:02:06.240</a></span> | <span class="t">want to relate that adjective, like the blue ball, you want to relate blue as referring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=131" target="_blank">00:02:11.120</a></span> | <span class="t">to ball. So we're learning patterns within the sequence, intra-sequence patterns. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=139" target="_blank">00:02:19.480</a></span> | <span class="t">sorry, I gave this talk in Kenya, so I am using Kiswahili here. But with multi-head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=147" target="_blank">00:02:27.160</a></span> | <span class="t">attention, the idea is you have like each word represented by an embedding, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=152" target="_blank">00:02:32.200</a></span> | <span class="t">in the depth dimension here. And then you have your sentence of words. You split that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=156" target="_blank">00:02:36.720</a></span> | <span class="t">up into a bunch of different groups. So here I've chopped it depth-wise into four groups.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=163" target="_blank">00:02:43.080</a></span> | <span class="t">You apply attention to each one of these groups independently. And then when you get the result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=169" target="_blank">00:02:49.400</a></span> | <span class="t">back, you can catenate them together and you're back to your model dimension representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=176" target="_blank">00:02:56.760</a></span> | <span class="t">So what this lets you do is if each attention head, like each attention head can now focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=182" target="_blank">00:03:02.600</a></span> | <span class="t">on learning one pattern. So maybe attention head one is learning the relationship of adjectives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=189" target="_blank">00:03:09.240</a></span> | <span class="t">to nouns. And the second attention head can learn something different. So this lets us</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=195" target="_blank">00:03:15.600</a></span> | <span class="t">learn like a hierarchy or a list of different relationships. Okay. So that was self-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=204" target="_blank">00:03:24.560</a></span> | <span class="t">The other piece is fast autoregressive decoding. And do I really want to go into this? Okay,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=213" target="_blank">00:03:33.740</a></span> | <span class="t">I will. So the important thing about this is that if you're doing normal autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=220" target="_blank">00:03:40.100</a></span> | <span class="t">decoding, what you do is you generate your first token. And now conditioned on that first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=224" target="_blank">00:03:44.000</a></span> | <span class="t">token, you generate the second and conditioned on the first two, you generate the third and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=227" target="_blank">00:03:47.760</a></span> | <span class="t">so on and so forth. But that's super slow, right? Like it's a loop applying this thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=232" target="_blank">00:03:52.120</a></span> | <span class="t">again and again. And so what we can do instead is we make an assumption in the code that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=239" target="_blank">00:03:59.200</a></span> | <span class="t">our model always generates the right thing. And then we generate a prediction, only one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=247" target="_blank">00:04:07.360</a></span> | <span class="t">token ahead. So you have your outputs, which are Y, you have your targets, which are Y</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=266" target="_blank">00:04:26.760</a></span> | <span class="t">hat. And what you do is you feed in those gold targets so that you don't need to actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=274" target="_blank">00:04:34.480</a></span> | <span class="t">do this loop. So instead of assuming, instead of having to generate the first token, feed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=279" target="_blank">00:04:39.360</a></span> | <span class="t">it back into your architecture, generate a second token, you feed in the entire target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=284" target="_blank">00:04:44.360</a></span> | <span class="t">sequence and you just pretend that you generated all the right tokens up to position K. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=290" target="_blank">00:04:50.520</a></span> | <span class="t">then you predict the K plus first and you compute your loss on that. So in reality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=296" target="_blank">00:04:56.440</a></span> | <span class="t">your model might've generated at the beginning of training junk, but you're getting a loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=301" target="_blank">00:05:01.880</a></span> | <span class="t">as if your model had seen all the correct tokens and is now just predicting the next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=307" target="_blank">00:05:07.240</a></span> | <span class="t">one. This is a little bit subtle, but it's hugely impactful for training speed because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=313" target="_blank">00:05:13.280</a></span> | <span class="t">all of this can be done on parallel in parallel. And so it's actually what make transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=318" target="_blank">00:05:18.280</a></span> | <span class="t">so scalable. Okay. So in order to do this successfully, if you were just feeding in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=325" target="_blank">00:05:25.780</a></span> | <span class="t">all of the, all of the correct tokens, uh, naively, what would happen is your model would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=332" target="_blank">00:05:32.080</a></span> | <span class="t">just be able to, uh, look forward in time and cheat. So you've, you've put in all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=339" target="_blank">00:05:39.360</a></span> | <span class="t">your true targets, the things that you're trying to get your model to predict. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=344" target="_blank">00:05:44.200</a></span> | <span class="t">if that's where you're computing your loss on, if you could just look forward in time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=347" target="_blank">00:05:47.240</a></span> | <span class="t">and say, okay, I'm just going to grab that. And we'd get zero error trivially, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=351" target="_blank">00:05:51.360</a></span> | <span class="t">Cause you you've given it all the right answers. So what we have to do inside the architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=356" target="_blank">00:05:56.100</a></span> | <span class="t">is we need to actually prevent, uh, the attention mechanism from being able to look at tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=362" target="_blank">00:06:02.100</a></span> | <span class="t">that it shouldn't have been able to see already. Um, so the way that this looks is you create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=369" target="_blank">00:06:09.460</a></span> | <span class="t">a mask on your attention. Um, and so, sorry, this is the example of like doing a trivial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=376" target="_blank">00:06:16.780</a></span> | <span class="t">attention. If you don't mask your attention properly, um, what it's going to do is it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=382" target="_blank">00:06:22.220</a></span> | <span class="t">just going to look into the future, just grab the token that you're telling it to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=387" target="_blank">00:06:27.460</a></span> | <span class="t">and copy it over. And so it learned something trivial, something that doesn't actually generalize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=391" target="_blank">00:06:31.540</a></span> | <span class="t">And so what we do is we actually prevent it from attending to those tokens. We prevent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=396" target="_blank">00:06:36.100</a></span> | <span class="t">it from attending into the future for each position in the source sequence. We block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=402" target="_blank">00:06:42.460</a></span> | <span class="t">out, uh, everything that it shouldn't be able to see everything into the future. And then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=407" target="_blank">00:06:47.700</a></span> | <span class="t">as we move down, we gradually unblock so it can start to see into the past. Um, so those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=414" target="_blank">00:06:54.340</a></span> | <span class="t">are kind of like the two, the three major components of transformers, um, the self-attention,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=423" target="_blank">00:07:03.380</a></span> | <span class="t">the multi-head attention, and then deploying this gold targets, decoding is fast, autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=431" target="_blank">00:07:11.260</a></span> | <span class="t">attention. In terms of the story, which might be a little bit more interesting. Um, so transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=439" target="_blank">00:07:19.660</a></span> | <span class="t">I was an intern, uh, with Lukasz Kaiser, uh, at Google back in 2017. Um, and I was sitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=446" target="_blank">00:07:26.700</a></span> | <span class="t">next to Gnome, uh, and Ashish was like a couple of seats down from us. Um, and what's really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=453" target="_blank">00:07:33.900</a></span> | <span class="t">incredible is that essentially this entire project came together in like three months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=459" target="_blank">00:07:39.260</a></span> | <span class="t">and it was done. So I showed up at Google, uh, no, I'm had been working on autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=466" target="_blank">00:07:46.180</a></span> | <span class="t">models. Um, same thing with like Ashish and Yakov and Nikki. And, um, they just been kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=472" target="_blank">00:07:52.420</a></span> | <span class="t">of like exploring the space, figuring it out. Uh, and Lukasz and I, at the same time, we'd</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=477" target="_blank">00:07:57.620</a></span> | <span class="t">been working on this framework called tensor to tensor, um, which was like explicitly made</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=483" target="_blank">00:08:03.340</a></span> | <span class="t">for, uh, multimodal learning, autoregressive learning. Um, and Lukasz is kind of like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=490" target="_blank">00:08:10.900</a></span> | <span class="t">master of keeping track of everything that's happening in the field and adopting it. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=497" target="_blank">00:08:17.740</a></span> | <span class="t">so within tensor to tensor, there were like these, there was like these kind of emerging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=504" target="_blank">00:08:24.820</a></span> | <span class="t">little things that maybe one paper had been written about, uh, and people were interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=509" target="_blank">00:08:29.020</a></span> | <span class="t">in like layer norm, um, but it hadn't actually taken off yet. Uh, the warmup in the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=514" target="_blank">00:08:34.660</a></span> | <span class="t">rate schedule, um, all of these little pieces were just default, like on by default. Um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=523" target="_blank">00:08:43.420</a></span> | <span class="t">and so when gnome and Ashish and Nikki and Yakov came over and adopted tensor to tensor,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=530" target="_blank">00:08:50.660</a></span> | <span class="t">all of these things were just on by default. Um, and so a lot of people, when they look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=536" target="_blank">00:08:56.460</a></span> | <span class="t">at the, the transformer paper, it just seems like there's so many like arbitrary little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=540" target="_blank">00:09:00.940</a></span> | <span class="t">things thrown in. And when now, like in present day, these have become standard for like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=546" target="_blank">00:09:06.180</a></span> | <span class="t">lot of different training algorithms, like the learning rate warmup, um, the way that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=551" target="_blank">00:09:11.860</a></span> | <span class="t">we did initialization, uh, all of these pieces have just become the norm, but back then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=556" target="_blank">00:09:16.980</a></span> | <span class="t">had like kind of just been introduced. Um, and so we, uh, we spent a lot of time running</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=564" target="_blank">00:09:24.940</a></span> | <span class="t">ablations trying to figure out like, which were the necessary pieces and what made it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=568" target="_blank">00:09:28.420</a></span> | <span class="t">work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=569" target="_blank">00:09:29.420</a></span> | <span class="t">And if any of you have actually tried training transformers and tried like pulling out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=574" target="_blank">00:09:34.580</a></span> | <span class="t">learning rate warmup, um, or changing any of these little pieces, you'll see that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=579" target="_blank">00:09:39.860</a></span> | <span class="t">really does break down optimization. Like it actually really does, um, hurt performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=586" target="_blank">00:09:46.340</a></span> | <span class="t">for instance, like removing the layer norms, that type of thing. Um, so I always thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=592" target="_blank">00:09:52.180</a></span> | <span class="t">it was kind of funny how all of these random additions that Lukasz had just like thrown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=597" target="_blank">00:09:57.860</a></span> | <span class="t">in, cause he was playing around with them turned out to be crucial. Uh, and they were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=602" target="_blank">00:10:02.260</a></span> | <span class="t">just on by default. Um, so anyway, it was like three months. I remember, um, it all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=611" target="_blank">00:10:11.660</a></span> | <span class="t">really started coming together towards the end, like just before the NeurIPS deadline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=616" target="_blank">00:10:16.740</a></span> | <span class="t">Um, and I can still remember sitting in the micro kitchen and Ashish telling me like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=621" target="_blank">00:10:21.500</a></span> | <span class="t">that's just like, I was a little intern, uh, telling me like, this is going to be such</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=625" target="_blank">00:10:25.620</a></span> | <span class="t">a big deal. And I was like, yeah, sure. Okay. I have no idea what's happening. I just showed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=630" target="_blank">00:10:30.620</a></span> | <span class="t">up. Um, and he was like, no dude, like this, this actually matters. Like, you know, we,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=636" target="_blank">00:10:36.580</a></span> | <span class="t">we bumped up blue three points and I was like, sick, great anyway. Um, and then I can remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=645" target="_blank">00:10:45.620</a></span> | <span class="t">on the night of the deadline for NeurIPS, it was like 2am, uh, Ashish, Ashish was the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=654" target="_blank">00:10:54.340</a></span> | <span class="t">only one left at the office and we were still like moving around figures and like adjusting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=659" target="_blank">00:10:59.620</a></span> | <span class="t">things. And then, um, I went to bed, but Ashish stayed up and I slept in like this tiny little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=664" target="_blank">00:11:04.740</a></span> | <span class="t">phone booth. Um, and then for the other paper that I was submitting, I forgot to press submit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=671" target="_blank">00:11:11.580</a></span> | <span class="t">but luckily like some lady opened the door to the phone booth and hit me in the head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=676" target="_blank">00:11:16.740</a></span> | <span class="t">while I was sleeping in the morning. And just before the deadline, I got the paper in. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=682" target="_blank">00:11:22.100</a></span> | <span class="t">so I owe it to that lady, uh, for, for submitting to NeurIPS that year. But yeah, anyway, the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=689" target="_blank">00:11:29.740</a></span> | <span class="t">I think the crazy thing about transformers was that it all came together in like three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=692" target="_blank">00:11:32.900</a></span> | <span class="t">months. Like most of the ideas happened in that span. And it was just like this sprint</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=697" target="_blank">00:11:37.580</a></span> | <span class="t">towards the NeurIPS deadline. Um, I think a lot of the other members on the team, Jakob,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=703" target="_blank">00:11:43.220</a></span> | <span class="t">Lukasz, Shalom, Ashish, they knew how important it was, but for me, I was like, I don't know.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=708" target="_blank">00:11:48.500</a></span> | <span class="t">I really did not appreciate, uh, the impact. Um, but in retrospect, it's been amazing how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=715" target="_blank">00:11:55.540</a></span> | <span class="t">the community has kind of like come together and adopted it. Um, and I think most of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=721" target="_blank">00:12:01.860</a></span> | <span class="t">can be ascribed to the ease of optimization. It seems like very robust to hyper parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=727" target="_blank">00:12:07.980</a></span> | <span class="t">choices. So you don't need to like tune the hell out of it, spend a lot of time tweaking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=732" target="_blank">00:12:12.220</a></span> | <span class="t">little things. Um, and the other side is that it's like super tailored to the accelerators</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=737" target="_blank">00:12:17.060</a></span> | <span class="t">that we run on. Um, so it's like very paralyzable, um, hyper-efficient. Um, and so it lends itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=746" target="_blank">00:12:26.220</a></span> | <span class="t">to that kind of scaling law effort that's, that's really taken off in, in popularity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=751" target="_blank">00:12:31.900</a></span> | <span class="t">Okay. Uh, unless there are any questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=754" target="_blank">00:12:34.620</a></span> | <span class="t">That's such a cool story. Oh my God. We're both excited. So we just unmuted at the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=762" target="_blank">00:12:42.260</a></span> | <span class="t">time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=763" target="_blank">00:12:43.260</a></span> | <span class="t">Yeah. So that's, that's my section. If there's any questions, happy to answer them. Otherwise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=770" target="_blank">00:12:50.700</a></span> | <span class="t">uh, let's get into NPTs. NPTs are like, I think, um, there's such a nice next level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=778" target="_blank">00:12:58.540</a></span> | <span class="t">abstraction of the architecture. So you've probably seen the trend of, um, transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=784" target="_blank">00:13:04.140</a></span> | <span class="t">getting applied to, to new domains, um, first into vision and video and audio. Um, but this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=793" target="_blank">00:13:13.100</a></span> | <span class="t">is kind of like cutting back to an even more abstract level. Um, like I think tabular data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=799" target="_blank">00:13:19.580</a></span> | <span class="t">Yeah. I don't know. I'll let Yannick and Neil take over from here, but, uh, I think NPTs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=804" target="_blank">00:13:24.420</a></span> | <span class="t">is a pretty sick, pretty sick project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=808" target="_blank">00:13:28.900</a></span> | <span class="t">Thanks for the introduction. Um, thanks all for the invitation. We're very happy to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=813" target="_blank">00:13:33.740</a></span> | <span class="t">here and Neil and I are now going to tell you about our, um, self-attention between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=820" target="_blank">00:13:40.420</a></span> | <span class="t">data points paper, where we introduce, introduce the non-parametric transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=825" target="_blank">00:13:45.380</a></span> | <span class="t">Um, we'll start with a little bit of motivation, move on to explaining the architecture in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=830" target="_blank">00:13:50.260</a></span> | <span class="t">detail, then show you the experiments. This is more or less a step through of the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=834" target="_blank">00:13:54.580</a></span> | <span class="t">but maybe, you know, with a little bit of extra insight here and there, all right, as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=842" target="_blank">00:14:02.220</a></span> | <span class="t">promised motivation, I have a brief summary. So, um, we'll start by thinking about something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=848" target="_blank">00:14:08.060</a></span> | <span class="t">that we don't often think about. And that is that from CNNs to transformers, most of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=853" target="_blank">00:14:13.340</a></span> | <span class="t">supervised deep learning relies on parametric prediction. So what that means is that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=859" target="_blank">00:14:19.220</a></span> | <span class="t">have some self-training data and we want to learn to predict the outcomes Y from inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=865" target="_blank">00:14:25.020</a></span> | <span class="t">X. And for this, we set up some model with tunable parameters, theta, then we optimize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=871" target="_blank">00:14:31.020</a></span> | <span class="t">these parameters to maximize predictive likelihoods on a training set, or, you know, equivalently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=876" target="_blank">00:14:36.660</a></span> | <span class="t">we minimize some loss. And then after training, we have this optimized set of parameters theta</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=883" target="_blank">00:14:43.100</a></span> | <span class="t">and then at test time, we just put these into the model and use these parameters to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=888" target="_blank">00:14:48.340</a></span> | <span class="t">on novel test data. And so crucially here, our prediction at test time only depends on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=894" target="_blank">00:14:54.620</a></span> | <span class="t">these parameters, right? It's parametric. Also, that means that given these parameters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=900" target="_blank">00:15:00.340</a></span> | <span class="t">the prediction is entirely independent of the training data. And so why would we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=906" target="_blank">00:15:06.380</a></span> | <span class="t">to do parametric prediction? Well, it's really convenient because all that we've learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=911" target="_blank">00:15:11.260</a></span> | <span class="t">from the training data can be summarized in the parameters. And so prediction time, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=916" target="_blank">00:15:16.300</a></span> | <span class="t">only need these final parameters and we do not need to store the training data, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=919" target="_blank">00:15:19.820</a></span> | <span class="t">might be really, really large. On the other hand, we usually have models that already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=925" target="_blank">00:15:25.380</a></span> | <span class="t">predict for a bunch of data in parallel, right? Think of mini-batching in modern architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=930" target="_blank">00:15:30.920</a></span> | <span class="t">And actually things like batch norm already make these data interact. And so our thinking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=937" target="_blank">00:15:37.100</a></span> | <span class="t">here was that if we've got all of this data in parallel anyways, there's no reason not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=941" target="_blank">00:15:41.780</a></span> | <span class="t">to make use of it. And so more, a bit grander, we kind of challenged parametric prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=948" target="_blank">00:15:48.460</a></span> | <span class="t">as the dominant paradigm in deep learning. And so we want to give models the additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=953" target="_blank">00:15:53.780</a></span> | <span class="t">flexibility of using the training data directly when making predictions. And so a bit more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=960" target="_blank">00:16:00.340</a></span> | <span class="t">concretely, we introduced the non-parametric transformer architecture. And this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=966" target="_blank">00:16:06.220</a></span> | <span class="t">to be a general deep learning architecture, meaning we can apply it to a variety of scenarios.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=972" target="_blank">00:16:12.420</a></span> | <span class="t">NPTs will take the entire data set as input whenever possible. And NPTs then crucially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=979" target="_blank">00:16:19.540</a></span> | <span class="t">learn to predict from interactions between data points. And to achieve this, we use multi-head</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=986" target="_blank">00:16:26.140</a></span> | <span class="t">self-attention that, as Aiden has introduced us to, has just really established itself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=992" target="_blank">00:16:32.260</a></span> | <span class="t">as a general purpose layer for reasoning. We also take another thing from the NLP community</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=999" target="_blank">00:16:39.500</a></span> | <span class="t">and we use a stochastic masking mechanism. And we use that to tell NPTs where to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1005" target="_blank">00:16:45.300</a></span> | <span class="t">and also to regularize the learning task of it. And lastly, of course, we hope to convince</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1010" target="_blank">00:16:50.980</a></span> | <span class="t">you that this ends up working really, really well, and that this kind of simple idea of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1015" target="_blank">00:16:55.700</a></span> | <span class="t">learning to predict from the other data points of the input, from the training points of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1020" target="_blank">00:17:00.380</a></span> | <span class="t">the input, ends up working rather well. And so very briefly summarizing what we've heard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1028" target="_blank">00:17:08.980</a></span> | <span class="t">already. A, we input into NPTs the entire data set. And then B, let's say for the purpose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1035" target="_blank">00:17:15.780</a></span> | <span class="t">of this slide here, we only care about predicting the orange question mark in that green row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1042" target="_blank">00:17:22.280</a></span> | <span class="t">And then we can compare NPTs to parametric prediction, right? So a classical deep learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1047" target="_blank">00:17:27.780</a></span> | <span class="t">model would predict this target value only from the features of that single green input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1053" target="_blank">00:17:33.460</a></span> | <span class="t">To do that, it would use the parameters theta, those would depend on whatever training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1057" target="_blank">00:17:37.620</a></span> | <span class="t">we've seen and so on. But at test time, we only look at that single row for which we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1062" target="_blank">00:17:42.580</a></span> | <span class="t">care about the prediction. In contrast, NPTs predict an explicit dependence on all samples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1069" target="_blank">00:17:49.060</a></span> | <span class="t">in the input. They can look beyond that single green datum of interest and look at all other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1074" target="_blank">00:17:54.200</a></span> | <span class="t">samples that are there and consider their values for prediction. So this presents an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1078" target="_blank">00:17:58.440</a></span> | <span class="t">entirely different way of thinking about how we learn predictive mechanisms. And somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1084" target="_blank">00:18:04.540</a></span> | <span class="t">on Twitter called this KNN 2.0, which we would have not written in the paper, but maybe is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1089" target="_blank">00:18:09.760</a></span> | <span class="t">kind of a nice way of thinking about how NPTs can learn to predict. So of course, nonparametric</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1097" target="_blank">00:18:17.240</a></span> | <span class="t">models are a thing already. We didn't invent them at all. And I define them here as prediction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1103" target="_blank">00:18:23.720</a></span> | <span class="t">in explicit dependence on the training data, which is certainly what NPTs do. Classical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1109" target="_blank">00:18:29.200</a></span> | <span class="t">examples like Gaussian processes, k-nearest neighbor, kernel methods, those might be familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1114" target="_blank">00:18:34.320</a></span> | <span class="t">to you. And there exists also efforts to combine the benefits of nonparametrics and representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1120" target="_blank">00:18:40.280</a></span> | <span class="t">learning in a similar fashion to how we did it in NPTs. However, these approaches are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1127" target="_blank">00:18:47.220</a></span> | <span class="t">usually limited in some sense in comparison to NPTs, right? They're often kind of motivated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1131" target="_blank">00:18:51.960</a></span> | <span class="t">from the statistics community a bit more. They often require more finicky approximative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1135" target="_blank">00:18:55.920</a></span> | <span class="t">inference schemes, are limited in the interactions they can learn, or things like that. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1141" target="_blank">00:19:01.560</a></span> | <span class="t">we really think NPTs present maybe the most versatile and most widely applicable of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1147" target="_blank">00:19:07.760</a></span> | <span class="t">nonparametric prediction approaches. But that's something we explicitly wanted to have. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1152" target="_blank">00:19:12.240</a></span> | <span class="t">wanted to have something that's really easy to use, plug and play, works in a ton of scenarios,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1156" target="_blank">00:19:16.940</a></span> | <span class="t">and works really well. And so with that, I hand over to Neil, who's going to tell you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1163" target="_blank">00:19:23.380</a></span> | <span class="t">about the nonparametric transformer architecture in all of its details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1167" target="_blank">00:19:27.800</a></span> | <span class="t">Yeah, we also have one question. Go ahead. Yes, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1172" target="_blank">00:19:32.360</a></span> | <span class="t">Hi, Jendrik. Hi. So could you please go back to the previous slide?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1180" target="_blank">00:19:40.680</a></span> | <span class="t">The very previous slide? Yeah, yes. This slide, yeah. So in terms of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1185" target="_blank">00:19:45.440</a></span> | <span class="t">the problem definition, I think it's quite similar to some meta-learning problem, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1191" target="_blank">00:19:51.160</a></span> | <span class="t">basically there is a mapping from a data point on the data sets to some predictions. So could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1198" target="_blank">00:19:58.480</a></span> | <span class="t">you please suggest any differences between your problem setting and the meta-learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1205" target="_blank">00:20:05.040</a></span> | <span class="t">problem settings? I can't really figure out any differences between these two problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1211" target="_blank">00:20:11.760</a></span> | <span class="t">Well, I think it really depends on the framing that you want to have. So I would say meta-learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1219" target="_blank">00:20:19.240</a></span> | <span class="t">would be when I try to predict over multiple data sets. So when I try to learn some sort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1226" target="_blank">00:20:26.160</a></span> | <span class="t">of prediction model, or I can just plug in a different data set, and it will almost automatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1232" target="_blank">00:20:32.080</a></span> | <span class="t">give me new predictions on this different data distribution. But that's not what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1236" target="_blank">00:20:36.080</a></span> | <span class="t">do at all. We're training a single model for a fixed data set. And so this is why I wouldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1241" target="_blank">00:20:41.720</a></span> | <span class="t">really call that meta-learning, because we're trying to predict on the same tasks that all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1247" target="_blank">00:20:47.160</a></span> | <span class="t">the supervised deep learning, or any supervised machine learning method is trying to predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1253" target="_blank">00:20:53.400</a></span> | <span class="t">well on. Okay, so you mean you use kind of same test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1259" target="_blank">00:20:59.920</a></span> | <span class="t">set to test your training model, right? So basically, in meta-learning, we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1276" target="_blank">00:21:16.360</a></span> | <span class="t">test on different kind of meta-test sets. But in your case, you just want to use a test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1282" target="_blank">00:21:22.800</a></span> | <span class="t">set, which is similar to the distribution of your training set, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1289" target="_blank">00:21:29.600</a></span> | <span class="t">Yeah, absolutely. So we explore data set distribution shift a bit. I think it's a really interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1294" target="_blank">00:21:34.520</a></span> | <span class="t">scenario. I think meta-learning different data sets is also an interesting scenario,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1300" target="_blank">00:21:40.000</a></span> | <span class="t">right, when you have this model where you could just push in different data sets. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1304" target="_blank">00:21:44.160</a></span> | <span class="t">for the scope of this paper, it's very much training set, test set, they come from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1309" target="_blank">00:21:49.040</a></span> | <span class="t">same distribution, and we're just trying to do supervised learning in a standard setting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1315" target="_blank">00:21:55.720</a></span> | <span class="t">I see, cool. Thank you. Thank you for the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1319" target="_blank">00:21:59.720</a></span> | <span class="t">Yeah, and I would chime in a couple of additional things, I guess. So at least from what I understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1326" target="_blank">00:22:06.480</a></span> | <span class="t">from the problem definition of meta-learning, I think the aim is more perhaps being able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1331" target="_blank">00:22:11.960</a></span> | <span class="t">to perform well on a new data set with a relatively small number of additional gradient steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1336" target="_blank">00:22:16.280</a></span> | <span class="t">on that data set. So I think there are some interesting ways that you could actually consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1340" target="_blank">00:22:20.880</a></span> | <span class="t">applying NPTs in a meta-learning type setting. And so we'll get into this a little bit more,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1346" target="_blank">00:22:26.080</a></span> | <span class="t">but for example, there might be ways to essentially add in a new data set. So let's suppose we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1352" target="_blank">00:22:32.280</a></span> | <span class="t">trained on a bunch of different data sets. We now add in a new data set. We can perhaps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1356" target="_blank">00:22:36.480</a></span> | <span class="t">do some sorts of kind of zero shot meta-learning, basically, where there's no need for additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1363" target="_blank">00:22:43.800</a></span> | <span class="t">gradient steps because we're basically predicting kind of similar to how you might do prompting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1368" target="_blank">00:22:48.520</a></span> | <span class="t">nowadays in NLP literature. Anyways, yeah, I think we'll get into some more details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1374" target="_blank">00:22:54.800</a></span> | <span class="t">Just to chime in on that, I don't think that every meta-learning algorithm-- I think the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1384" target="_blank">00:23:04.640</a></span> | <span class="t">one that you're describing right now are optimization-based, but there are also black box ones. You don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1389" target="_blank">00:23:09.800</a></span> | <span class="t">need to further-- I think the main difference seems to be that there is one task versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1395" target="_blank">00:23:15.960</a></span> | <span class="t">multiple tasks for meta-learning. Yeah, I think so too. I think the main framing question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1403" target="_blank">00:23:23.640</a></span> | <span class="t">is whether or not there's multiple data sets. Cool. OK, awesome. If there's no other questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1413" target="_blank">00:23:33.360</a></span> | <span class="t">I'll dive a bit more into the architecture. Awesome. So there's three key components to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1422" target="_blank">00:23:42.920</a></span> | <span class="t">NPTs. I'm going to first state them at a high level, and then we'll go through each of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1426" target="_blank">00:23:46.480</a></span> | <span class="t">in more detail. So first of all, we take the entire data set, all data points as input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1433" target="_blank">00:23:53.440</a></span> | <span class="t">So for example, at test time, the model is going to take as input both training and test</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1437" target="_blank">00:23:57.880</a></span> | <span class="t">data, and we approximate this with mini-batches for large data. We apply self-attention between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1445" target="_blank">00:24:05.560</a></span> | <span class="t">data points. So for example, at test time, we model relationships amongst training points,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1450" target="_blank">00:24:10.960</a></span> | <span class="t">amongst test points, and between the two sets. And then finally, we have this masking-based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1457" target="_blank">00:24:17.240</a></span> | <span class="t">training objective. It's a BERT-like stochastic masking, and the key point is that we actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1462" target="_blank">00:24:22.680</a></span> | <span class="t">use it on both features as well as on training targets. And we'll get into why that leads</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1467" target="_blank">00:24:27.660</a></span> | <span class="t">to an interesting predictive mechanism later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1472" target="_blank">00:24:32.040</a></span> | <span class="t">So to start with this idea of data sets as input, there's two things that compose the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1477" target="_blank">00:24:37.140</a></span> | <span class="t">input to NPT. It's a full data set in the form of a matrix X and a masking matrix M.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1483" target="_blank">00:24:43.880</a></span> | <span class="t">And so Yannick has described this data set matrix a little bit. We basically have data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1488" target="_blank">00:24:48.200</a></span> | <span class="t">points as rows. The columns are attributes, and each attribute shares some kind of semantic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1493" target="_blank">00:24:53.160</a></span> | <span class="t">meaning among all of its data points. So say, for example, you're just doing single-target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1498" target="_blank">00:24:58.260</a></span> | <span class="t">classification or regression. The last column would be the target, and the rest of the matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1503" target="_blank">00:25:03.560</a></span> | <span class="t">would be input features. So for example, the pixels of an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1508" target="_blank">00:25:08.520</a></span> | <span class="t">We also have a masking matrix. So let's say we're thinking about mass language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1513" target="_blank">00:25:13.720</a></span> | <span class="t">The mass tokens will just tell us where we're going to conceal words and where we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1517" target="_blank">00:25:17.760</a></span> | <span class="t">to back-propagate a loss. We do a similar type of thing here, where we use this binary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1522" target="_blank">00:25:22.340</a></span> | <span class="t">mass matrix to specify which entries are mass. And the goal is to predict mass values from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1529" target="_blank">00:25:29.920</a></span> | <span class="t">observed values. I see that there was a question about handling inputs with different lengths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1538" target="_blank">00:25:38.440</a></span> | <span class="t">In the data sets we've considered, we'll get into it in the results section, but it's mostly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1543" target="_blank">00:25:43.360</a></span> | <span class="t">been sort of tabular and image data, where the lengths for each of the data points is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1547" target="_blank">00:25:47.840</a></span> | <span class="t">the same, but it would work just like padding. That would be a reasonable way to go about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1551" target="_blank">00:25:51.960</a></span> | <span class="t">that. There's also kind of an interesting-- yeah, go for it, Yannick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1556" target="_blank">00:25:56.500</a></span> | <span class="t">Just to add to that, I'm not sure if length refers to columns or to rows, right? Rows,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1562" target="_blank">00:26:02.720</a></span> | <span class="t">we don't care about how many rows. Length, padding or something would be an option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1567" target="_blank">00:26:07.520</a></span> | <span class="t">Yeah, my question was about column. Exactly, that makes sense. Awesome, thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1573" target="_blank">00:26:13.160</a></span> | <span class="t">Yeah, I mean, that goes along with the whole meta-learning discussion. I think if we wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1577" target="_blank">00:26:17.600</a></span> | <span class="t">to adapt to data sets that have a different number of data points per data set, we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1582" target="_blank">00:26:22.360</a></span> | <span class="t">take advantage of the fact that self-attention is kind of OK with that. Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1591" target="_blank">00:26:31.560</a></span> | <span class="t">So continuing on, left to discuss here is basically how we do the embedding. So to put</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1599" target="_blank">00:26:39.440</a></span> | <span class="t">this more explicitly, we have this data matrix that has n data points. It's called x, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1605" target="_blank">00:26:45.280</a></span> | <span class="t">it also has d attributes. And we have this binary mass matrix m. We're going to stack</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1609" target="_blank">00:26:49.160</a></span> | <span class="t">them, and then we're going to do a linear embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1612" target="_blank">00:26:52.800</a></span> | <span class="t">So specifically, we're doing the same linear embedding independently for each data point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1617" target="_blank">00:26:57.720</a></span> | <span class="t">We're learning a different embedding for each attribute. We have a positional encoding on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1622" target="_blank">00:27:02.320</a></span> | <span class="t">the index of the attributes because we don't really care about, say, being equivariant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1626" target="_blank">00:27:06.000</a></span> | <span class="t">over the columns. If it's tabular data, you, of course, want to treat all these kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1629" target="_blank">00:27:09.280</a></span> | <span class="t">heterogeneous columns differently. And then finally, we have an encoding on the type of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1634" target="_blank">00:27:14.000</a></span> | <span class="t">column, so whether or not it's continuous or categorical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1637" target="_blank">00:27:17.800</a></span> | <span class="t">And that ends up giving us this input data set representation that is dimensions n by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1642" target="_blank">00:27:22.760</a></span> | <span class="t">d by e. The second key component of NPTs is attention between data points. So to do that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1653" target="_blank">00:27:33.360</a></span> | <span class="t">we first take this representation we have and flatten to an n by d times e representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1660" target="_blank">00:27:40.040</a></span> | <span class="t">So basically, we're treating each of these d times e size rows as if it's a token representation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1666" target="_blank">00:27:46.120</a></span> | <span class="t">We're actually going to just accomplish this operation using multi-head self-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1670" target="_blank">00:27:50.720</a></span> | <span class="t">We've reviewed this a lot, but the nice thing is that we know from language modeling, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1674" target="_blank">00:27:54.600</a></span> | <span class="t">we stack this multiple times, we can model these higher order dependencies. And here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1678" target="_blank">00:27:58.040</a></span> | <span class="t">they're between data points, and that's really the key draw of this architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1682" target="_blank">00:28:02.480</a></span> | <span class="t">There's been other kind of instances of people using attention for similar sorts of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1686" target="_blank">00:28:06.960</a></span> | <span class="t">So for example, like attentive neural processes. A lot of times, they've sort of used just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1692" target="_blank">00:28:12.200</a></span> | <span class="t">a single layer as kind of a representational lookup. And we believe that this actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1697" target="_blank">00:28:17.320</a></span> | <span class="t">ends up limiting expressivity, and that by stacking this many times, you can learn more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1700" target="_blank">00:28:20.860</a></span> | <span class="t">complex relationships between the data points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1703" target="_blank">00:28:23.680</a></span> | <span class="t">Anil, we also have some questions. So you can go ahead first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1710" target="_blank">00:28:30.280</a></span> | <span class="t">Oh, cool. Thanks. I have a question about how you guys do the embedding. Is there always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1715" target="_blank">00:28:35.200</a></span> | <span class="t">part of these convolutional filters or linear layers? What is the type of embedding that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1721" target="_blank">00:28:41.520</a></span> | <span class="t">you guys use?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1722" target="_blank">00:28:42.520</a></span> | <span class="t">Yeah, so I'm attempting to go back to the slide. I think it's not very happy with me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1727" target="_blank">00:28:47.560</a></span> | <span class="t">right now. But yeah, so for tabular data, we did just linear embeddings, actually. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1735" target="_blank">00:28:55.960</a></span> | <span class="t">we could get into, I guess, details of featurization for categorical and continuous, but it's literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1740" target="_blank">00:29:00.120</a></span> | <span class="t">like, say, for categorical, you do a one-hot encoding, and then you learn this embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1744" target="_blank">00:29:04.440</a></span> | <span class="t">that is specific to that attribute. And then for numerical, I believe we were just standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1749" target="_blank">00:29:09.480</a></span> | <span class="t">normalizing. For the image data, we did end up using a ResNet-18 encoder for CIFAR-10.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1757" target="_blank">00:29:17.480</a></span> | <span class="t">However, I think that-- I mean, we'll discuss that a bit later in results, but that embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1763" target="_blank">00:29:23.160</a></span> | <span class="t">is a bit arbitrary. You can sort of do whatever. The key part of the architecture is the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1768" target="_blank">00:29:28.120</a></span> | <span class="t">between data points. So in terms of how you actually want to embed each attribute, it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1772" target="_blank">00:29:32.520</a></span> | <span class="t">kind of up to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1775" target="_blank">00:29:35.840</a></span> | <span class="t">Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1776" target="_blank">00:29:36.840</a></span> | <span class="t">I think-- you had a question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1782" target="_blank">00:29:42.360</a></span> | <span class="t">Same question, I was victorious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1786" target="_blank">00:29:46.040</a></span> | <span class="t">OK, awesome. Cool. So here we have attention between data points done. So we can also do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1794" target="_blank">00:29:54.080</a></span> | <span class="t">this attention between attributes. So we reshape back to this n by d by e representation, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1801" target="_blank">00:30:01.640</a></span> | <span class="t">then we can just apply self-attention independently to each row, in other words, to a single data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1806" target="_blank">00:30:06.760</a></span> | <span class="t">point. And the intuition for why we would kind of do this nested-type idea where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1811" target="_blank">00:30:11.320</a></span> | <span class="t">switch between attention between data points and attention between attributes is just we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1815" target="_blank">00:30:15.200</a></span> | <span class="t">trying to learn better per-data-point representations for the between-data-point interactions. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1821" target="_blank">00:30:21.440</a></span> | <span class="t">is literally just normal self-attention, as you'd see in language modeling or image classification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1826" target="_blank">00:30:26.600</a></span> | <span class="t">The attributes are the tokens here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1831" target="_blank">00:30:31.080</a></span> | <span class="t">And finally, we just rinse and repeat. So what are we actually getting out of this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1836" target="_blank">00:30:36.720</a></span> | <span class="t">To summarize, we're learning higher-order relationships between data points. We're learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1840" target="_blank">00:30:40.920</a></span> | <span class="t">transformations of individual data points. And then importantly, NPT is equivariant to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1846" target="_blank">00:30:46.640</a></span> | <span class="t">a permutation of the data points. This basically just reflects the intuition that the learned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1852" target="_blank">00:30:52.080</a></span> | <span class="t">relationships between the data points should not depend on the ordering in which you receive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1855" target="_blank">00:30:55.800</a></span> | <span class="t">them or in which you observe your data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1861" target="_blank">00:31:01.200</a></span> | <span class="t">The third key component of NPTs is a masking-based training objective. So recall that what we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1868" target="_blank">00:31:08.000</a></span> | <span class="t">trying to do is we're trying to predict missing entries from observed entries. And those masked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1873" target="_blank">00:31:13.000</a></span> | <span class="t">values can be both features or targets. So again, the classic use, say, in masked language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1878" target="_blank">00:31:18.320</a></span> | <span class="t">modeling is to do self-supervised learning on a sequence of tokens, which you could think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1882" target="_blank">00:31:22.320</a></span> | <span class="t">of as just having features in our setting. Ours is a bit different in that we do stochastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1888" target="_blank">00:31:28.960</a></span> | <span class="t">feature masking to mask feature values with a probability p sub feature. And then we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1893" target="_blank">00:31:33.320</a></span> | <span class="t">do this masking of training targets with this probability p sub target.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1899" target="_blank">00:31:39.540</a></span> | <span class="t">So if we write out the training objective, we are just taking a weighted sum of the negative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1905" target="_blank">00:31:45.280</a></span> | <span class="t">log likelihood loss from targets as well as from features. And of course, at test time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1910" target="_blank">00:31:50.000</a></span> | <span class="t">we're only going to mask and compute a loss over the targets of test points.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1915" target="_blank">00:31:55.220</a></span> | <span class="t">So to break this down a bit further and point out some of the cool parts of it here, the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1920" target="_blank">00:32:00.760</a></span> | <span class="t">thing that's highlighted right now on the far right is the term relating to the features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1925" target="_blank">00:32:05.280</a></span> | <span class="t">It's the feature masking. Basically, we find that this has a nice regularizing effect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1931" target="_blank">00:32:11.760</a></span> | <span class="t">More or less, the model can now predict anywhere and makes the task a bit harder and introduces</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1935" target="_blank">00:32:15.240</a></span> | <span class="t">some more supervision. And we found in an ablation for the tabular data sets that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1939" target="_blank">00:32:19.080</a></span> | <span class="t">helped for eight of 10 of those. And then there's this other term, which is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1943" target="_blank">00:32:23.880</a></span> | <span class="t">interesting. It's the stochastic target masking. And the idea is that you're actually going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1950" target="_blank">00:32:30.060</a></span> | <span class="t">to have some training targets unmasked to the model at input at training time, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1956" target="_blank">00:32:36.920</a></span> | <span class="t">means that the NPT can learn to predict the mask targets of certain training data points</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1962" target="_blank">00:32:42.400</a></span> | <span class="t">using the targets of other training data points as well as all of the training features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1967" target="_blank">00:32:47.680</a></span> | <span class="t">And so that means you don't actually need to memorize a mapping between training inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1972" target="_blank">00:32:52.240</a></span> | <span class="t">and outputs in your parameters. You can instead devote the representational capacity of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1976" target="_blank">00:32:56.240</a></span> | <span class="t">model to learn functions that use other training features and targets as input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1981" target="_blank">00:33:01.600</a></span> | <span class="t">So this is kind of getting into the idea of this sort of like learn KNN idea. Obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1986" target="_blank">00:33:06.380</a></span> | <span class="t">we can learn more complex relational lookups and those sorts of things from this. But you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1992" target="_blank">00:33:12.320</a></span> | <span class="t">can imagine one such case being we have a bunch of test data points coming in. We're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=1998" target="_blank">00:33:18.160</a></span> | <span class="t">going to look at their features and use that to assign them to clusters of training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2002" target="_blank">00:33:22.840</a></span> | <span class="t">points. And then our prediction for those points is just going to be an interpolation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2007" target="_blank">00:33:27.220</a></span> | <span class="t">of the training targets in that respective cluster. That's like an example of something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2011" target="_blank">00:33:31.400</a></span> | <span class="t">that this mechanism lets NPTs learn. All right. So if there's any questions, we can take them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2020" target="_blank">00:33:40.640</a></span> | <span class="t">now. Otherwise, I'm happy to take them in the discussion or something. All right. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2031" target="_blank">00:33:51.160</a></span> | <span class="t">let's discuss. Yeah, go for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2034" target="_blank">00:33:54.000</a></span> | <span class="t">I'm curious when you're using the entire data set, does that limit the type of data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2040" target="_blank">00:34:00.080</a></span> | <span class="t">you can use because of the size?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2043" target="_blank">00:34:03.120</a></span> | <span class="t">Yeah. So in practice, we do random mini batching as an approximation. So the idea is just to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2050" target="_blank">00:34:10.600</a></span> | <span class="t">say, if you have a reasonably large mini batch, you're going to benefit a bit from still having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2055" target="_blank">00:34:15.560</a></span> | <span class="t">kind of this lookup ability. Because if you have a reasonable number of classes, probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2059" target="_blank">00:34:19.760</a></span> | <span class="t">you're going to be able to learn some interesting mappings based on features and targets amongst</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2065" target="_blank">00:34:25.200</a></span> | <span class="t">those classes. We found in practice that-- and we'll get into this a little bit. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2070" target="_blank">00:34:30.720</a></span> | <span class="t">we do actually indeed learn to use relationships between data points on prediction for data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2078" target="_blank">00:34:38.160</a></span> | <span class="t">points where we're doing mini batching. And we also didn't necessarily find that you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2082" target="_blank">00:34:42.360</a></span> | <span class="t">like a ludicrously large batch size for this to be a thing. But I do think it's just--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2088" target="_blank">00:34:48.160</a></span> | <span class="t">this is, in general, an important point. And it's one that points us towards looking into,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2092" target="_blank">00:34:52.240</a></span> | <span class="t">say, sparse transformers literature for trying to expand to some larger data sets without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2098" target="_blank">00:34:58.120</a></span> | <span class="t">having the mini batching assumption.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2099" target="_blank">00:34:59.920</a></span> | <span class="t">Great. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2102" target="_blank">00:35:02.800</a></span> | <span class="t">If I can add a number to that, we can, without mini batching, accommodate data sets of around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2110" target="_blank">00:35:10.120</a></span> | <span class="t">like 8,000 points or so. So that already accounts for a fair proportion, I would say, of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2117" target="_blank">00:35:17.720</a></span> | <span class="t">tabular data sets out there. But we also do data sets with 11 million points where, obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2122" target="_blank">00:35:22.760</a></span> | <span class="t">we then resort to mini batching. So it's very good to have an idea of the sizes that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2127" target="_blank">00:35:27.600</a></span> | <span class="t">talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2129" target="_blank">00:35:29.440</a></span> | <span class="t">I'm curious on that. I mean, it's pretty exciting. I feel like you don't normally hear about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2135" target="_blank">00:35:35.000</a></span> | <span class="t">transformers being applied to data sets of size 8,000. I'm curious-- and we can talk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2142" target="_blank">00:35:42.360</a></span> | <span class="t">about this sort of later once we've covered the other material-- if you found that sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2145" target="_blank">00:35:45.640</a></span> | <span class="t">efficiency is one of the key gains here, or just experience working on small data sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2150" target="_blank">00:35:50.640</a></span> | <span class="t">of transformers generally. And yeah. But I'm happy to punt the answer to that until after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2155" target="_blank">00:35:55.480</a></span> | <span class="t">as part of the discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2157" target="_blank">00:35:57.760</a></span> | <span class="t">Yeah, I think that'd be really nice to talk about a bit. And it was something that, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2162" target="_blank">00:36:02.560</a></span> | <span class="t">general, I guess I'd say was surprising to us in terms of how robust NPTs were on small</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2167" target="_blank">00:36:07.600</a></span> | <span class="t">data sets, and how we surprisingly didn't have to tune a terrible number of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2171" target="_blank">00:36:11.560</a></span> | <span class="t">But we can get into details in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2177" target="_blank">00:36:17.560</a></span> | <span class="t">Awesome. So to get into the experiments, we focused a lot on tabular data because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2186" target="_blank">00:36:26.440</a></span> | <span class="t">a very general setting. And it's also notoriously challenging for deep learning. So we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2192" target="_blank">00:36:32.160</a></span> | <span class="t">tree-based boosting methods, stuff like XGBoost, is very dominant. And this is also a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2197" target="_blank">00:36:37.920</a></span> | <span class="t">relevant domain to, I think, people in industry and that sort of thing. So we were excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2202" target="_blank">00:36:42.260</a></span> | <span class="t">about the idea of trying to do better on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2204" target="_blank">00:36:44.940</a></span> | <span class="t">So we chose a broad selection of data sets varying across a few different dimensions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2211" target="_blank">00:36:51.120</a></span> | <span class="t">As we mentioned, on the order of hundreds to tens of millions of instances, broad range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2217" target="_blank">00:36:57.160</a></span> | <span class="t">in the number of features, in the composition of features in terms of being categorical</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2220" target="_blank">00:37:00.880</a></span> | <span class="t">or continuous, various types of tasks, binary and multi-class classification, as well as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2226" target="_blank">00:37:06.000</a></span> | <span class="t">regression. And like I said, the baselines were kind of the usual suspects for tabular</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2229" target="_blank">00:37:09.240</a></span> | <span class="t">data-- XGBoost, CatBoost, LightGBM, TuneMLPs, and TabNet, which is a transformer architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2236" target="_blank">00:37:16.200</a></span> | <span class="t">for tabular data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2239" target="_blank">00:37:19.360</a></span> | <span class="t">So to get into the results, here I'm showing the average rank for the various subtasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2245" target="_blank">00:37:25.720</a></span> | <span class="t">We did well in terms of rank-wise performance against methods like CatBoost and XGBoost,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2250" target="_blank">00:37:30.600</a></span> | <span class="t">which are designed specifically for tabular data. And in fact, we find that NPT is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2255" target="_blank">00:37:35.260</a></span> | <span class="t">top performer on four of the 10 of these data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2258" target="_blank">00:37:38.920</a></span> | <span class="t">On image data, I mentioned that we used a CNN encoder. And with that, we were performing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2263" target="_blank">00:37:43.560</a></span> | <span class="t">well on CIFAR-10. And we also think that, in general, with, let's say, new work on image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2269" target="_blank">00:37:49.440</a></span> | <span class="t">transformers on small data, this can probably just be done with linear patching. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2274" target="_blank">00:37:54.000</a></span> | <span class="t">this kind of-- the manner in which you're embedding things is probably not the key.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2279" target="_blank">00:37:59.000</a></span> | <span class="t">Neil, if I can jump in with two questions. Can you go back two slides first? One is just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2288" target="_blank">00:38:08.080</a></span> | <span class="t">a small, minor point. Back one more, please. Thank you. Here are the features. 50 plus.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2294" target="_blank">00:38:14.120</a></span> | <span class="t">What does plus mean here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2298" target="_blank">00:38:18.160</a></span> | <span class="t">I'll have to double-check what the exact number is. I'm pretty sure it's probably around 50,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2302" target="_blank">00:38:22.240</a></span> | <span class="t">I would guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2303" target="_blank">00:38:23.240</a></span> | <span class="t">Ah, so the 50 is really an order of. It's not like 150 or 5,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2309" target="_blank">00:38:29.320</a></span> | <span class="t">Yes. Yeah. I mean, I'll double-check for you, or you can check with the metadata statistics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2315" target="_blank">00:38:35.600</a></span> | <span class="t">at the end of the paper. But no, it wasn't arbitrarily large. I would say, though, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2323" target="_blank">00:38:43.480</a></span> | <span class="t">did these ablations on whether or not we actually need attention between attributes. We did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2329" target="_blank">00:38:49.040</a></span> | <span class="t">find that this ended up benefiting us. But you could perhaps do, say, just an MLP embedding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2337" target="_blank">00:38:57.680</a></span> | <span class="t">in that dimension and go to a relatively small number of hidden dimensions and fit an arbitrary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2343" target="_blank">00:39:03.280</a></span> | <span class="t">number of features. So I think that, yeah, if you kind of relax the necessity of attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2350" target="_blank">00:39:10.960</a></span> | <span class="t">between attributes, you can probably scale out at least that dimension quite a lot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2355" target="_blank">00:39:15.240</a></span> | <span class="t">OK. And then my second question, if you could go forward one slide. Thank you. Here, I'm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2362" target="_blank">00:39:22.360</a></span> | <span class="t">not sure I quite caught. What is it four of 10 data sets, two of 10 data sets and four</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2366" target="_blank">00:39:26.600</a></span> | <span class="t">of 10 mean?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2369" target="_blank">00:39:29.120</a></span> | <span class="t">This is of the of all the tabular data sets that we had. So. Oh, I see. OK. Yeah, exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2377" target="_blank">00:39:37.680</a></span> | <span class="t">Awesome. Any other questions?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2381" target="_blank">00:39:41.280</a></span> | <span class="t">The standard errors here, because I mean, there's like there's just 10 data sets, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2387" target="_blank">00:39:47.160</a></span> | <span class="t">Yeah, correct. 10 total tabular data sets. Yeah. But these are right. Yeah, these are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2393" target="_blank">00:39:53.200</a></span> | <span class="t">these are rank wise performance. Correct. OK, I'm just seeing. How the where the uncertainty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2401" target="_blank">00:40:01.920</a></span> | <span class="t">comes from in this case. Yeah, average averaged over four of 10 data sets, the rank. So for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2409" target="_blank">00:40:09.040</a></span> | <span class="t">each particular data set, we have a rank of all the different methods. Then we take the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2411" target="_blank">00:40:11.960</a></span> | <span class="t">average and the very answer of the of the rankings within each of the types of task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2420" target="_blank">00:40:20.360</a></span> | <span class="t">within binary classification, within multiclass, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2424" target="_blank">00:40:24.840</a></span> | <span class="t">We also, if you're curious, you know, have have the full results in the paper. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2428" target="_blank">00:40:28.920</a></span> | <span class="t">Thank you. We also have a couple of questions. Some of the questions on the.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2436" target="_blank">00:40:36.760</a></span> | <span class="t">Hey, yeah, thanks. I guess I just found it a little surprising that the worst performer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2443" target="_blank">00:40:43.840</a></span> | <span class="t">was can and given that it's also nonparametric, I guess, could you comment on that? And is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2451" target="_blank">00:40:51.560</a></span> | <span class="t">yeah. Is it that there's something like intrinsic to the NPT that makes it just exceptional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2457" target="_blank">00:40:57.600</a></span> | <span class="t">far beyond other nonparametric methods? Or yeah, why? Why is it that can performs the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2463" target="_blank">00:41:03.720</a></span> | <span class="t">worst here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2465" target="_blank">00:41:05.560</a></span> | <span class="t">Well, I suppose ultimately can and it is it's still a relatively naive predictive method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2471" target="_blank">00:41:11.720</a></span> | <span class="t">and that, you know, it might just be predicting based on kind of cluster means. So for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2478" target="_blank">00:41:18.600</a></span> | <span class="t">you know, I think this is probably universally true for all the data sets, but there's probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2481" target="_blank">00:41:21.720</a></span> | <span class="t">some amount of kind of additional reasoning that needs to occur over the features, at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2485" target="_blank">00:41:25.880</a></span> | <span class="t">least to basic level. So for example, like one of the data sets is this poker hand data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2489" target="_blank">00:41:29.480</a></span> | <span class="t">set where it's like a mapping between all of the different hands you have in poker and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2493" target="_blank">00:41:33.600</a></span> | <span class="t">what like they're commonly known to people like full houses or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2497" target="_blank">00:41:37.160</a></span> | <span class="t">So this, this requires some amount of reasoning over the features to be able to group things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2501" target="_blank">00:41:41.020</a></span> | <span class="t">together. So just taking like the cluster means of the featurization of those different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2506" target="_blank">00:41:46.920</a></span> | <span class="t">you know, hands is likely not going to give you a great predictive function. Whereas NPTs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2512" target="_blank">00:41:52.600</a></span> | <span class="t">can kind of do the classic thing where say you have an MLP type of thing over the features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2517" target="_blank">00:41:57.640</a></span> | <span class="t">or like a tree type of thing over the features, you can learn some sort of complex embedding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2522" target="_blank">00:42:02.440</a></span> | <span class="t">but then you also can do some nonparametric sort of prediction based on say like clusters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2528" target="_blank">00:42:08.040</a></span> | <span class="t">of embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2529" target="_blank">00:42:09.040</a></span> | <span class="t">I see. Yeah, that makes sense. I guess. What if, what if you used pre-trained embeddings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2536" target="_blank">00:42:16.180</a></span> | <span class="t">from a stack of encoders as, as your vector representation for the CNN, how do you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2543" target="_blank">00:42:23.020</a></span> | <span class="t">that would perform compared to the rest of the crowd?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2546" target="_blank">00:42:26.020</a></span> | <span class="t">Yeah. Yeah. So this is like, I mean, this idea is kind of like deep kernel learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2550" target="_blank">00:42:30.740</a></span> | <span class="t">or like, yeah, I believe it is deep kernel learning is basically you use an MLP independently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2558" target="_blank">00:42:38.980</a></span> | <span class="t">So you learn an MLP on each input data point, and then you apply a GP over all the representations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2564" target="_blank">00:42:44.580</a></span> | <span class="t">of those. So you get this sort of like complex embedding and then the lookups. The key difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2569" target="_blank">00:42:49.260</a></span> | <span class="t">between that type of idea and NPTs is that we also learn the relationships between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2574" target="_blank">00:42:54.060</a></span> | <span class="t">data points themselves, because we use this parametric attention mechanism to learn the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2578" target="_blank">00:42:58.460</a></span> | <span class="t">relationship. So we're not just learning like an embedding independently. We're basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2583" target="_blank">00:43:03.920</a></span> | <span class="t">backpropagating through the entire process, learning the ways in which we would try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2587" target="_blank">00:43:07.500</a></span> | <span class="t">embed this, but also the, the ways that say the lookup would occur. And essentially the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2593" target="_blank">00:43:13.340</a></span> | <span class="t">the relationships at a, that it could potentially be kind of higher order as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2597" target="_blank">00:43:17.540</a></span> | <span class="t">Okay, cool. Wait, one more, one more follow-up or.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2602" target="_blank">00:43:22.740</a></span> | <span class="t">Oh yeah, go for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2605" target="_blank">00:43:25.300</a></span> | <span class="t">Cool. Yeah. Thanks. So I guess then if, if the advantage of NPT has to do with sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2611" target="_blank">00:43:31.940</a></span> | <span class="t">the relationships between data points, then what if you, you know, took the, took the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2621" target="_blank">00:43:41.100</a></span> | <span class="t">let's say, you know, encoder representations and then you pass that as input, say for the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2628" target="_blank">00:43:48.680</a></span> | <span class="t">you know, 10 nearest neighbors, along with like some other like input representation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2636" target="_blank">00:43:56.460</a></span> | <span class="t">and sort of had this like weighted average like attention style where you, you weighted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2642" target="_blank">00:44:02.180</a></span> | <span class="t">the, the vectors of the nearest neighbors based on the attention weights between those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2651" target="_blank">00:44:11.020</a></span> | <span class="t">input data points. And then like the supplied input data point, and then like pass that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2657" target="_blank">00:44:17.180</a></span> | <span class="t">as, as you know, the, the vector to like the final prediction layer, like, do you think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2664" target="_blank">00:44:24.220</a></span> | <span class="t">that captures some amount of the relationship or, or is that off base?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2670" target="_blank">00:44:30.900</a></span> | <span class="t">So I think the nice part, like, and really what our idea is behind this whole thing is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2675" target="_blank">00:44:35.500</a></span> | <span class="t">just these sorts of instances where certain fixed kernels would perform particularly well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2680" target="_blank">00:44:40.900</a></span> | <span class="t">in tasks is like kind of an annoyance and like ultimately like tuning a lot of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2684" target="_blank">00:44:44.980</a></span> | <span class="t">types of things are trying to derive the predictive methods that might make a lot of sense for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2689" target="_blank">00:44:49.300</a></span> | <span class="t">a given situation kind of stinks. And ideally you'd want to just back propagate on a data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2694" target="_blank">00:44:54.060</a></span> | <span class="t">set and kind of learn these relationships yourself. So I actually would be really interested</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2698" target="_blank">00:44:58.180</a></span> | <span class="t">to see if we can come up with some synthetic experiments that have these sort of like very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2702" target="_blank">00:45:02.700</a></span> | <span class="t">particular can and like predictive mechanisms and just see if we can learn precisely those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2707" target="_blank">00:45:07.240</a></span> | <span class="t">and get, you know, zero error with NPS. And in fact, like we'll get into this a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2712" target="_blank">00:45:12.340</a></span> | <span class="t">bit with some of the interventional experiments we do, we have like kind of precise lookup</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2717" target="_blank">00:45:17.300</a></span> | <span class="t">functions that NPS end up being able to learn so we can learn interesting relational functions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2722" target="_blank">00:45:22.380</a></span> | <span class="t">Cool. Yeah. Thanks a lot. Appreciate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2727" target="_blank">00:45:27.140</a></span> | <span class="t">Cool. All right. I have one more question from. Yeah, sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2734" target="_blank">00:45:34.260</a></span> | <span class="t">I just wanted to clarify something about basically so at test time, you just take the exact same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2740" target="_blank">00:45:40.940</a></span> | <span class="t">data set and you just like add like your test examples, right? And then you like do the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2746" target="_blank">00:45:46.420</a></span> | <span class="t">same type of like masking. And is that how it works?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2750" target="_blank">00:45:50.620</a></span> | <span class="t">Yeah, correct. OK, got it. And I do have one more question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2755" target="_blank">00:45:55.300</a></span> | <span class="t">That is just because I'm I think I misunderstood like how like the effects of your NPT objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2762" target="_blank">00:46:02.700</a></span> | <span class="t">Do you mind going back to that slide? Sure. Yeah. Can you repeat one more time? Like what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2773" target="_blank">00:46:13.180</a></span> | <span class="t">makes this so special? Yeah. So the the regularizer on the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2779" target="_blank">00:46:19.060</a></span> | <span class="t">over the features, I would think of very similarly to self-supervised learning with just a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2784" target="_blank">00:46:24.780</a></span> | <span class="t">transformer like you're you're basically just introducing a lot more supervision and you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2789" target="_blank">00:46:29.380</a></span> | <span class="t">even if, say, you're just doing a supervised objective, this is kind of like some amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2793" target="_blank">00:46:33.420</a></span> | <span class="t">of reconstruction over the features. You learn a more interesting representation and like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2797" target="_blank">00:46:37.620</a></span> | <span class="t">what a regularizing effect, which we think is interesting, but perhaps not as interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2801" target="_blank">00:46:41.940</a></span> | <span class="t">as this stochastic target masking. This one is unique because in kind of standard parametric</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2808" target="_blank">00:46:48.220</a></span> | <span class="t">deep learning, you're not going to have an instance in your training process where you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2813" target="_blank">00:46:53.060</a></span> | <span class="t">taking targets as input. And so basically what happens is you have your training data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2820" target="_blank">00:47:00.940</a></span> | <span class="t">set as input, whatever, you're going to have some stochastic feature masking stuff happening</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2824" target="_blank">00:47:04.820</a></span> | <span class="t">on the features amongst the training targets. You're randomly going to have some of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2830" target="_blank">00:47:10.380</a></span> | <span class="t">unmasked and some of them will indeed be masked. You're going to be backpropagating a loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2834" target="_blank">00:47:14.380</a></span> | <span class="t">on the ones that are masked, of course, because, you know, you don't want your model to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2838" target="_blank">00:47:18.060</a></span> | <span class="t">those available at input if you're going to actually try to backpropagate a loss on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2842" target="_blank">00:47:22.620</a></span> | <span class="t">But you can use the other ones as input. And that means you can learn these kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2845" target="_blank">00:47:25.740</a></span> | <span class="t">interpolative functions. So that was like this whole idea of like being able to kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2849" target="_blank">00:47:29.660</a></span> | <span class="t">of learn KNN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2851" target="_blank">00:47:31.860</a></span> | <span class="t">But doesn't that allow the model to cheat again?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2856" target="_blank">00:47:36.620</a></span> | <span class="t">Yeah. So this is like an interesting point and actually like subtle. So I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2861" target="_blank">00:47:41.940</a></span> | <span class="t">really worthwhile to bring up. So first of all, we never actually backpropagate a loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2868" target="_blank">00:47:48.260</a></span> | <span class="t">on something that was visible to the model at input. And so if, for example, the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2874" target="_blank">00:47:54.740</a></span> | <span class="t">did actually end up basically overfitting on training labels, we would not observe the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2879" target="_blank">00:47:59.260</a></span> | <span class="t">model's ability to generalize to test data. We don't observe this. So obviously, it seems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2884" target="_blank">00:48:04.900</a></span> | <span class="t">like this kind of blocking of backpropagation on labels that are visible at input to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2891" target="_blank">00:48:11.500</a></span> | <span class="t">NPT is helping.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2893" target="_blank">00:48:13.380</a></span> | <span class="t">It could also be possible that in BERT style stochastic masking, you also randomly will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2898" target="_blank">00:48:18.740</a></span> | <span class="t">flip some labels to be in a different category. So this is like kind of just like a random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2904" target="_blank">00:48:24.940</a></span> | <span class="t">fine print that was introduced in the BERT masking text. We also do that. So it's possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2909" target="_blank">00:48:29.780</a></span> | <span class="t">that that somehow contributes to that. But it's probably pretty likely to just be the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2915" target="_blank">00:48:35.740</a></span> | <span class="t">fact that we're not backpropagating a loss on something that's visible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2919" target="_blank">00:48:39.380</a></span> | <span class="t">Great. Thanks. Makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2925" target="_blank">00:48:45.060</a></span> | <span class="t">I have two more questions if I can jump in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2926" target="_blank">00:48:46.900</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2927" target="_blank">00:48:47.900</a></span> | <span class="t">Sorry. Can we go to the metrics, the performance, the results slide?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2933" target="_blank">00:48:53.220</a></span> | <span class="t">Sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2934" target="_blank">00:48:54.220</a></span> | <span class="t">I feel like I missed something else. I'm sorry about this. So looking on the binary classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2939" target="_blank">00:48:59.820</a></span> | <span class="t">AUROC, can you clarify what these numbers mean? Are they the AUROC?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2948" target="_blank">00:49:08.860</a></span> | <span class="t">So this is the, so on each of the data sets, so say for a particular binary classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2955" target="_blank">00:49:15.740</a></span> | <span class="t">data set, we're going to get a ranking of the methods. We're going to repeat this. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2962" target="_blank">00:49:22.980</a></span> | <span class="t">Go for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2963" target="_blank">00:49:23.980</a></span> | <span class="t">So these numbers here are the relative ranking across in this particular case, the four data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2968" target="_blank">00:49:28.500</a></span> | <span class="t">sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2969" target="_blank">00:49:29.500</a></span> | <span class="t">Correct. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2970" target="_blank">00:49:30.500</a></span> | <span class="t">I see. So this, these values are not the AUROCs on average across the data sets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2976" target="_blank">00:49:36.380</a></span> | <span class="t">No. Yeah. They're not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2978" target="_blank">00:49:38.540</a></span> | <span class="t">I mean like averaging, averaging AUROC might make sense, but averaging things like accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2984" target="_blank">00:49:44.500</a></span> | <span class="t">and RMSE seems like a bad idea, right? Because you might have some data sets where everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2989" target="_blank">00:49:49.500</a></span> | <span class="t">has high accuracy or where RMSE needs something drastically different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2993" target="_blank">00:49:53.540</a></span> | <span class="t">I see. So this, these numbers here only tell us the relative ranking between the different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=2997" target="_blank">00:49:57.660</a></span> | <span class="t">methods, not how well they actually perform. I mean, it tells us how they perform relative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3002" target="_blank">00:50:02.220</a></span> | <span class="t">to one another, but not how well they perform. I see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3005" target="_blank">00:50:05.020</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3006" target="_blank">00:50:06.020</a></span> | <span class="t">But that's all in the appendix. We all have, we have that information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3008" target="_blank">00:50:08.340</a></span> | <span class="t">I see. Okay. I was, I was sitting here confused going like, why is AUROC, why is the best</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3012" target="_blank">00:50:12.360</a></span> | <span class="t">one the smallest? And accuracy, what is an accuracy of 2.5? Anyways. Okay. That makes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3016" target="_blank">00:50:16.820</a></span> | <span class="t">much more sense. Thank you both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3021" target="_blank">00:50:21.060</a></span> | <span class="t">Awesome. Great. So I'll try to speed through this just in the interest of time. But the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3029" target="_blank">00:50:29.460</a></span> | <span class="t">basically thing, the thing that you might be thinking after all of these results is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3033" target="_blank">00:50:33.580</a></span> | <span class="t">are we even learning any data point interactions on these real data sets?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3037" target="_blank">00:50:37.820</a></span> | <span class="t">And so basically we designed an experiment to figure this out. And the idea is that we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3042" target="_blank">00:50:42.140</a></span> | <span class="t">going to disallow NPT from using other data points when predicting on one of them. If</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3047" target="_blank">00:50:47.820</a></span> | <span class="t">we do that and we observe that NPT actually predicts or performs significantly worse,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3053" target="_blank">00:50:53.580</a></span> | <span class="t">it is indeed using these interactions between data points. A subtle challenge or it's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3059" target="_blank">00:50:59.140</a></span> | <span class="t">of like an added bonus we can get from this is that ideally we wouldn't actually break</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3063" target="_blank">00:51:03.860</a></span> | <span class="t">batch statistics. So let's say like the mean of each particular attribute. If we can find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3069" target="_blank">00:51:09.160</a></span> | <span class="t">a way to do this experiment such that we don't break these things, we can kind of rule out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3073" target="_blank">00:51:13.980</a></span> | <span class="t">the possibility that we learned something that's a bit similar to batch norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3078" target="_blank">00:51:18.260</a></span> | <span class="t">And so the way that we do this is we basically look at the predictions for each one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3082" target="_blank">00:51:22.380</a></span> | <span class="t">data points in sequence. So let's say in this case, we're looking at the prediction of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3086" target="_blank">00:51:26.820</a></span> | <span class="t">model for this particular green row. And it's going to be predicting in this last column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3090" target="_blank">00:51:30.860</a></span> | <span class="t">that has this question mark which is masked. What we're going to do is we're going to permute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3094" target="_blank">00:51:34.900</a></span> | <span class="t">each of the attributes independently amongst all other data points except for that one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3099" target="_blank">00:51:39.360</a></span> | <span class="t">So the information for that row, if it was kind of just predicting like a classic parametric</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3103" target="_blank">00:51:43.620</a></span> | <span class="t">deep model is still intact, but the information from all of the other rows is gone. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3108" target="_blank">00:51:48.980</a></span> | <span class="t">why we call this sort of the corruption experiment. And so we find in general, when we perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3114" target="_blank">00:51:54.540</a></span> | <span class="t">this experiment, performance kind of falls off a cliff for the vast majority of these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3118" target="_blank">00:51:58.940</a></span> | <span class="t">methods. And I'll note that the performances between the methods on a lot of these were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3123" target="_blank">00:52:03.580</a></span> | <span class="t">fairly close. And so this is actually indeed pretty significant. So for example, on protein,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3129" target="_blank">00:52:09.260</a></span> | <span class="t">we went from being the top performer amongst all the methods to the worst performer worse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3132" target="_blank">00:52:12.420</a></span> | <span class="t">than even like KNN or something like that. I'll also note that there's kind of this interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3138" target="_blank">00:52:18.700</a></span> | <span class="t">behavior where on these data sets like forest and kick and breast cancer, we actually observed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3143" target="_blank">00:52:23.740</a></span> | <span class="t">that there's basically no drop in performance. And we basically see this as kind of an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3148" target="_blank">00:52:28.660</a></span> | <span class="t">feature and not necessarily a bug of the model, which is that if we're backpropagating on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3154" target="_blank">00:52:34.020</a></span> | <span class="t">a given data set, the model can sort of just find that it's actually not that worthwhile</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3158" target="_blank">00:52:38.660</a></span> | <span class="t">to attempt to predict using some kind of relational predictive mechanism amongst data points and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3163" target="_blank">00:52:43.940</a></span> | <span class="t">can instead just learn to predict parametrically and basically ignore other data points when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3168" target="_blank">00:52:48.980</a></span> | <span class="t">it's predicting on any given one of them. And so this probably leads to some kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3173" target="_blank">00:52:53.700</a></span> | <span class="t">like interesting ideas where perhaps you could do like post hoc pruning or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3177" target="_blank">00:52:57.020</a></span> | <span class="t">that, taking away the tension between data points and doing fine tuning, let's say. Alright,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3185" target="_blank">00:53:05.580</a></span> | <span class="t">so now I'll hand over to Yannick to talk a bit about learning some interesting relationships.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3190" target="_blank">00:53:10.380</a></span> | <span class="t">Yeah, will you though? I see that we're at the end of what the time is, but like, I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3199" target="_blank">00:53:19.060</a></span> | <span class="t">there's a buffer planned in or something. I can go through this experiment, we can have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3204" target="_blank">00:53:24.140</a></span> | <span class="t">a bit of discussion. What do you guys prefer? Yeah, I think normally what we do is we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3211" target="_blank">00:53:31.580</a></span> | <span class="t">sort of stop the recording at this point and have an off the record discussion. And I guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3217" target="_blank">00:53:37.860</a></span> | <span class="t">the question to ask is, does anyone have any questions at this point? But I think we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3228" target="_blank">00:53:48.040</a></span> | <span class="t">basically been wanting questions as they come. So I personally feel fine just considering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3235" target="_blank">00:53:55.700</a></span> | <span class="t">this as sort of questions throughout. Yeah, I guess that sounds good. Yannick, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3242" target="_blank">00:54:02.420</a></span> | <span class="t">go forward with it, with your talk as planned and later we can see about the time thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3250" target="_blank">00:54:10.780</a></span> | <span class="t">I think this will only be like another four or five minutes talk. Yeah, yeah, that's good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3256" target="_blank">00:54:16.220</a></span> | <span class="t">Then go for it, yeah, for sure. Alright, so Neil has now told us how well NPTs perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3264" target="_blank">00:54:24.300</a></span> | <span class="t">in real data and that they do make use of information from other samples of the input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3269" target="_blank">00:54:29.780</a></span> | <span class="t">But we're not going to take this a bit further and come up with some toy experiments that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3274" target="_blank">00:54:34.300</a></span> | <span class="t">test the extent to which NPTs can learn to look up information from other rows, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3279" target="_blank">00:54:39.780</a></span> | <span class="t">the extent to which they can learn this nonparametric prediction mechanism. And so specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3285" target="_blank">00:54:45.020</a></span> | <span class="t">what we'll do is we'll create the following semi-synthetic data set. I want you to focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3290" target="_blank">00:54:50.120</a></span> | <span class="t">on A now. So we'll take one of the tabular data sets that we've used previously, specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3296" target="_blank">00:54:56.140</a></span> | <span class="t">the protein data set, but it doesn't really matter. What matters is that it's a regression</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3299" target="_blank">00:54:59.720</a></span> | <span class="t">data set. And so now what we do is we, the top half here is the original data set, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3306" target="_blank">00:55:06.460</a></span> | <span class="t">the bottom half is a copy of the original data set where we have unveiled the true target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3313" target="_blank">00:55:13.500</a></span> | <span class="t">value. So now NPTs could learn to use attention between data points to achieve arbitrarily</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3319" target="_blank">00:55:19.580</a></span> | <span class="t">good performance. They could learn to look up the target values in these matching duplicate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3324" target="_blank">00:55:24.860</a></span> | <span class="t">rows and then paste them back into that masked out target value. And then at test time, of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3331" target="_blank">00:55:31.740</a></span> | <span class="t">course, we put in a novel test data input where this mechanism is also possible just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3337" target="_blank">00:55:37.780</a></span> | <span class="t">to make sure that it hasn't learned to memorize anything, but has actually learned this correct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3343" target="_blank">00:55:43.100</a></span> | <span class="t">relational mechanism. And so what we see is that indeed, NPTs do successfully learn to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3349" target="_blank">00:55:49.220</a></span> | <span class="t">perform this lookup. So what I'm visualizing here is attention maps, and they very clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3353" target="_blank">00:55:53.420</a></span> | <span class="t">show that, let's say when predicting for this green row here, this first green row, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3358" target="_blank">00:55:58.380</a></span> | <span class="t">NPTs look at is exactly only that other green row here. And so this is really nice. We can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3367" target="_blank">00:56:07.260</a></span> | <span class="t">further look at the Pearson correlation between what NPTs should predict and what they actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3374" target="_blank">00:56:14.820</a></span> | <span class="t">do predict. And so this is 99.9%. This is much better than anything you could achieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3380" target="_blank">00:56:20.300</a></span> | <span class="t">with parametric prediction. And so it seems that NPTs here can actually discover this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3384" target="_blank">00:56:24.480</a></span> | <span class="t">mechanism. And discover here, I feel like it's the right word because NPTs could have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3390" target="_blank">00:56:30.740</a></span> | <span class="t">as we've seen, just also continue to predict in parametric fashion, right, from each row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3396" target="_blank">00:56:36.060</a></span> | <span class="t">independently. This is really kind of showing to us that there is this bias in the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3402" target="_blank">00:56:42.380</a></span> | <span class="t">to learn to predict from other rows. And of course, that is also very attractive in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3408" target="_blank">00:56:48.020</a></span> | <span class="t">setting because it allows you to achieve arbitrary load loss in this setting, or as lowest you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3413" target="_blank">00:56:53.380</a></span> | <span class="t">can optimize for it. And so we kind of take that to mean that our, you know, gradient</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3420" target="_blank">00:57:00.300</a></span> | <span class="t">based discovery, non-parametric philosophy seems to make some sense. And so we can take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3426" target="_blank">00:57:06.580</a></span> | <span class="t">this a bit further by performing somewhat of an interventional experiment that investigates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3431" target="_blank">00:57:11.820</a></span> | <span class="t">the extent to which NPTs have actually learned a robust, you know, causal mechanism that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3438" target="_blank">00:57:18.100</a></span> | <span class="t">underlying this semisynthetic data set. And so just appending, you know, this extra column</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3448" target="_blank">00:57:28.780</a></span> | <span class="t">of test data, that's already kind of cool, but I think we can take it a bit further and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3453" target="_blank">00:57:33.220</a></span> | <span class="t">actually study if this generalizes beyond the data that we see in the training set or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3457" target="_blank">00:57:37.900</a></span> | <span class="t">beyond data coming from this specific distribution. And so what we now do is we intervene on individual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3464" target="_blank">00:57:44.380</a></span> | <span class="t">duplicate data points at test time by varying their target value. So now we only care about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3470" target="_blank">00:57:50.620</a></span> | <span class="t">the prediction in a specific row. We do this across all rows, but at each time we just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3475" target="_blank">00:57:55.660</a></span> | <span class="t">cover a single row. What we do is we change the target value here, that what we're hoping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3480" target="_blank">00:58:00.780</a></span> | <span class="t">to see is that NPT just adjusts the prediction as well, right? There's a very simple intervention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3486" target="_blank">00:58:06.060</a></span> | <span class="t">experiment for us to test if NPTs have actually learned this mechanism. And to some extent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3490" target="_blank">00:58:10.820</a></span> | <span class="t">it also tests robustness because now we're associating target values with features that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3496" target="_blank">00:58:16.060</a></span> | <span class="t">are not part of the training distribution here. And so what we see is that as we adjust</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3504" target="_blank">00:58:24.140</a></span> | <span class="t">these values here, this is the kind of the duplicate value. And then we here see the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3509" target="_blank">00:58:29.020</a></span> | <span class="t">target value. As we adjust them, we can see the correlation stays really, really good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3513" target="_blank">00:58:33.380</a></span> | <span class="t">It's not quite 99.9%, like on average, we're now at 99.6, but it's still very, very good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3520" target="_blank">00:58:40.580</a></span> | <span class="t">And at this point you might be slightly annoyed with me because standard nonparametric models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3527" target="_blank">00:58:47.580</a></span> | <span class="t">can also solve this task. This is a task that I could solve by nearest neighbors. Sure,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3532" target="_blank">00:58:52.900</a></span> | <span class="t">maybe I would have to change the input format a bit because this is kind of like in a batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3537" target="_blank">00:58:57.020</a></span> | <span class="t">setting and I could just use masks, but most generally a nearest neighbor can also, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3542" target="_blank">00:59:02.580</a></span> | <span class="t">also looks up different input points based on their features. Nearest neighbor doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3548" target="_blank">00:59:08.180</a></span> | <span class="t">learn to do this. I still think it's cool that we need to learn this because it does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3552" target="_blank">00:59:12.100</a></span> | <span class="t">require a decent amount of computational sequences that we have to learn, like match all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3557" target="_blank">00:59:17.900</a></span> | <span class="t">features, look up target value, copy it back and so on. But it is in fact very easy for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3564" target="_blank">00:59:24.100</a></span> | <span class="t">us to complicate this task to a degree such that essentially no other model that we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3569" target="_blank">00:59:29.460</a></span> | <span class="t">of can solve this very easily. And so a really simple thing to do is just to add a plus one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3577" target="_blank">00:59:37.580</a></span> | <span class="t">to all of the duplicate values. So now nearest neighbor would look up the right row, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3585" target="_blank">00:59:45.980</a></span> | <span class="t">but it would always predict the wrong target with a plus one on it. And in fact, many of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3589" target="_blank">00:59:49.980</a></span> | <span class="t">the models that we're aware of, they're not modeling the joint distribution over features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3596" target="_blank">00:59:56.340</a></span> | <span class="t">and targets. What they're modeling is the conditional distribution of the targets given</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3601" target="_blank">01:00:01.580</a></span> | <span class="t">the input features. And so they also cannot do this. And so for us it's really not a problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3606" target="_blank">01:00:06.860</a></span> | <span class="t">at all. MPTs will just learn to subtract another one and no problems. And sure, this is also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3613" target="_blank">01:00:13.300</a></span> | <span class="t">still a very synthetic setting, but I do think, I mean, I challenge you to come up with some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3619" target="_blank">01:00:19.900</a></span> | <span class="t">thing that MPTs can't solve, but the other models can solve. I think this, in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3625" target="_blank">01:00:25.260</a></span> | <span class="t">this masking mechanism and the non-parametricity of the approach is really nice in general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3631" target="_blank">01:00:31.220</a></span> | <span class="t">and leads to lots of nice behavior in a variety of settings. And so with that, I think we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3636" target="_blank">01:00:36.940</a></span> | <span class="t">can go to the conclusions, which Neil is going to give you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3641" target="_blank">01:00:41.060</a></span> | <span class="t">Yeah, I think, I mean, we're going to cut out the main part here. I'll just fast forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3647" target="_blank">01:00:47.860</a></span> | <span class="t">Just look at them. Yeah, yeah. I was going to say, I think you'll get the gist. MPTs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3655" target="_blank">01:00:55.020</a></span> | <span class="t">take the entire data set as input and they use self-attention to model complex relationships</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3658" target="_blank">01:00:58.820</a></span> | <span class="t">between data points. They do well in experiments on tabular data as well as image data. We</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3666" target="_blank">01:01:06.300</a></span> | <span class="t">present some of these interventional experiments to show that they can solve complex reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3670" target="_blank">01:01:10.100</a></span> | <span class="t">tasks. There's some more experiments in the paper. I'd say that the interesting type of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3674" target="_blank">01:01:14.820</a></span> | <span class="t">future work is scaling type things. So we can, you know, not having this mini-batching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3680" target="_blank">01:01:20.020</a></span> | <span class="t">approximation and then also just trying to expand this to some more interesting application</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3684" target="_blank">01:01:24.060</a></span> | <span class="t">demands. So we talked a little bit about meta-learning, but it could also be things like, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3687" target="_blank">01:01:27.340</a></span> | <span class="t">few-shot generalization in general, domain adaptation, semi-supervised learning, et cetera.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3693" target="_blank">01:01:33.380</a></span> | <span class="t">So I think if there's some more questions, maybe we can do some more discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3698" target="_blank">01:01:38.340</a></span> | <span class="t">Yeah. I think sounds good. Great. Thanks for the talk. I think everyone had a fun time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3705" target="_blank">01:01:45.340</a></span> | <span class="t">I will just ask some general questions and then we can have like a discussion session</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3709" target="_blank">01:01:49.540</a></span> | <span class="t">with everyone after that. So I think one thing that I noticed is like this, like you said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3715" target="_blank">01:01:55.580</a></span> | <span class="t">this is similar to like KNNs and I thought like this seems similar to like graph neural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3719" target="_blank">01:01:59.620</a></span> | <span class="t">networks where you can think like each data point is like a node and then you can think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3723" target="_blank">01:02:03.660</a></span> | <span class="t">of everything as a fully connected graph and you're learning some sort of attention weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3726" target="_blank">01:02:06.820</a></span> | <span class="t">in this graph. So this is like a node prediction task you are kind of doing on this sort of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3731" target="_blank">01:02:11.700</a></span> | <span class="t">like graph structure. So any comments on that? Like, is it similar to like graph neural networks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3736" target="_blank">01:02:16.220</a></span> | <span class="t">or is it like other differences? Yeah, this is a very good observation. Yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3741" target="_blank">01:02:21.860</a></span> | <span class="t">I think there are a lot of similarities to work on graph neural networks. If we want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3746" target="_blank">01:02:26.340</a></span> | <span class="t">to talk about differences, the differences might be that we're kind of assuming a fully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3750" target="_blank">01:02:30.860</a></span> | <span class="t">connected graph, right? And so you could maybe also phrase that as we're discovering the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3756" target="_blank">01:02:36.380</a></span> | <span class="t">relational structure or as graph neural networks usually assume that it's given. But that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3760" target="_blank">01:02:40.940</a></span> | <span class="t">also not always true. And so there are a lot of similarities. I don't know, Neil, if there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3765" target="_blank">01:02:45.660</a></span> | <span class="t">was something specific you would like to mention, go ahead. But it's a very good observation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3769" target="_blank">01:02:49.980</a></span> | <span class="t">and we also do feel that that's the case. And we've added an extra section on related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3774" target="_blank">01:02:54.660</a></span> | <span class="t">work to graph neural networks in the updated version of the paper that will be online soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3780" target="_blank">01:03:00.620</a></span> | <span class="t">Yeah, I agree with everything you've said. I think the closest work from the GNN literature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3787" target="_blank">01:03:07.540</a></span> | <span class="t">that we were looking at a little bit was this neural relational inference paper, which uses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3791" target="_blank">01:03:11.260</a></span> | <span class="t">message-passing neural networks to try to kind of like learn edges that may or may not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3797" target="_blank">01:03:17.540</a></span> | <span class="t">exist and help for like extrapolating, I think, positions of like particles in like a multi-particle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3803" target="_blank">01:03:23.600</a></span> | <span class="t">system or something, which is like kind of a similar idea to us. Like, you know, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3807" target="_blank">01:03:27.700</a></span> | <span class="t">don't have these edges as given, the attention mechanism could kind of approximate an interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3811" target="_blank">01:03:31.900</a></span> | <span class="t">relationship amongst some interacting things. I see. Got it. Yeah, that's really cool. Another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3819" target="_blank">01:03:39.380</a></span> | <span class="t">thing is like, so you mostly look on like tabular data, but can you also like have other</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3823" target="_blank">01:03:43.020</a></span> | <span class="t">modalities, like if you want to do language or something, can you still use non-parametric</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3827" target="_blank">01:03:47.580</a></span> | <span class="t">transformers? Yeah, so I think part of our motivation for doing tabular was because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3834" target="_blank">01:03:54.580</a></span> | <span class="t">felt like tabular data is, in a sense, a generalization of, let's say, the language data, for example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3840" target="_blank">01:04:00.420</a></span> | <span class="t">I mean, I guess there's these other notions that people have brought up, like padding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3846" target="_blank">01:04:06.300</a></span> | <span class="t">but ultimately you can think of it as like a bunch of categorical attributes. So it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3851" target="_blank">01:04:11.700</a></span> | <span class="t">definitely generalizable to things like sentences and we do, you know, images. So, yeah. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3859" target="_blank">01:04:19.500</a></span> | <span class="t">actually like, I always go back and forth on whether or not I think smaller or larger</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3865" target="_blank">01:04:25.660</a></span> | <span class="t">data is more interesting for us. So I think small data is really interesting because we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3869" target="_blank">01:04:29.740</a></span> | <span class="t">can just fit the entire data set into it and all of this just works out of the box without</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3875" target="_blank">01:04:35.620</a></span> | <span class="t">any extra thought. But large data is actually also really interesting because, sure, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3881" target="_blank">01:04:41.740</a></span> | <span class="t">might have to introduce some approximative mechanism or some lookup mechanism because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3885" target="_blank">01:04:45.740</a></span> | <span class="t">you can't always have the entire data set in. But at the same time, you are very explicitly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3891" target="_blank">01:04:51.740</a></span> | <span class="t">kind of trading off the compute that you use to look up with the compute that you need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3897" target="_blank">01:04:57.700</a></span> | <span class="t">to store. Like how many parameters in GPT are used for storing data, right? There's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3903" target="_blank">01:05:03.460</a></span> | <span class="t">lots of memorization happening in these models and we know that. And so maybe we can use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3908" target="_blank">01:05:08.580</a></span> | <span class="t">the parameters more efficiently to learn lookup type behavior, right? That is more close to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3913" target="_blank">01:05:13.780</a></span> | <span class="t">this, you know, neural KNN or whatever. So I think these are very exciting questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3918" target="_blank">01:05:18.340</a></span> | <span class="t">Yeah, yeah. I'll also be looking forward to the future works because it seems like a very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3923" target="_blank">01:05:23.380</a></span> | <span class="t">good way to like do one-shot learning kind of situation. So, yeah, really very interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3928" target="_blank">01:05:28.700</a></span> | <span class="t">to see that. Okay, so I will stop the recording and we can have like any other questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3936" target="_blank">01:05:36.900</a></span> | <span class="t">Okay, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3937" target="_blank">01:05:37.900</a></span> | <span class="t">Okay, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3938" target="_blank">01:05:38.900</a></span> | <span class="t">Okay, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3939" target="_blank">01:05:39.900</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=zejXBg-2Vpk&t=3939" target="_blank">01:05:39.900</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>