<html><head><title>Building Transformer Tokenizers (Dhivehi NLP #1)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Building Transformer Tokenizers (Dhivehi NLP #1)</h2><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ"><img src="https://i.ytimg.com/vi/mjKqP3kRxbQ/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=66">1:6</a> Dhivehi Project<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=148">2:28</a> Hurdles for Low Resource Domains<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=261">4:21</a> Dhivehi Dataset<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=292">4:52</a> Download Dhivehi Corpus<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=505">8:25</a> Tokenizer Components<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=524">8:44</a> Normalizer Component<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=715">11:55</a> Pre-tokenization Component<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=899">14:59</a> Post-tokenization Component<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=986">16:26</a> Decoder Component<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1061">17:41</a> Tokenizer Implementation<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1264">21:4</a> Tokenizer Training<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1462">24:22</a> Post-processing Implementation<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1632">27:12</a> Decoder Implementation<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1687">28:7</a> Saving for Transformers<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1833">30:33</a> Tokenizer Test and Usage<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1896">31:36</a> Download Dhivehi Models<br><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1941">32:21</a> First Steps<br><br><div style="text-align: left;"><a href="./mjKqP3kRxbQ.html">Whisper Transcript</a> | <a href="./transcript_mjKqP3kRxbQ.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Today we're going to have a look at how we can design tokenizers or more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=5" target="_blank">00:00:05.760</a></span> | <span class="t">specifically a BERT tokenizer for low resource languages. So when I say low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=14" target="_blank">00:00:14.120</a></span> | <span class="t">resource language I mean a language where we don't really have that much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=19" target="_blank">00:00:19.160</a></span> | <span class="t">data and there is not already a tokenizer or transformer model out there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=26" target="_blank">00:00:26.680</a></span> | <span class="t">built for that specific language. Now there are transform models and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=33" target="_blank">00:00:33.540</a></span> | <span class="t">tokenizers for a lot or even most languages but there's still a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=42" target="_blank">00:00:42.600</a></span> | <span class="t">languages that are well simply less common and get less attention than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=50" target="_blank">00:00:50.600</a></span> | <span class="t">something like English or Chinese. So you may find if you're working on these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=56" target="_blank">00:00:56.400</a></span> | <span class="t">languages there are very few models out there or maybe no models out there. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=63" target="_blank">00:01:03.880</a></span> | <span class="t">that's what we're going to focus on today. We are going to more specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=68" target="_blank">00:01:08.960</a></span> | <span class="t">focus on building a tokenizer and in the future we're going to do more of this as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=73" target="_blank">00:01:13.640</a></span> | <span class="t">well more models and so on but we're going to focus on building a tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=78" target="_blank">00:01:18.160</a></span> | <span class="t">for the Divey language. Now Divey is the language of the Maldives so the Maldive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=85" target="_blank">00:01:25.440</a></span> | <span class="t">islands in the Indian Ocean I'm sure a lot of you probably know them but they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=90" target="_blank">00:01:30.000</a></span> | <span class="t">very beautiful islands incredibly amazing weather and generally I would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=97" target="_blank">00:01:37.360</a></span> | <span class="t">not usually think of the Maldives and NLP in the same context but there are a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=104" target="_blank">00:01:44.040</a></span> | <span class="t">lot of people that do and in particular there is a guy called Ashraq or Ismail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=109" target="_blank">00:01:49.560</a></span> | <span class="t">Ashraq and we've been speaking a lot about NLP and through that I've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=119" target="_blank">00:01:59.800</a></span> | <span class="t">made aware of how difficult it is to actually build models for languages</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=124" target="_blank">00:02:04.120</a></span> | <span class="t">where there is not much attention out there already. So what we decided to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=131" target="_blank">00:02:11.400</a></span> | <span class="t">is kind of team up and try and put together some transform models for the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=138" target="_blank">00:02:18.680</a></span> | <span class="t">Divey language and the first step to that is obviously the tokenizer. You need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=146" target="_blank">00:02:26.040</a></span> | <span class="t">tokenizer before you build anything else so there are a few hurdles that we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=152" target="_blank">00:02:32.200</a></span> | <span class="t">overcome when we're building these models so there are already there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=156" target="_blank">00:02:36.640</a></span> | <span class="t">zero well not zero there are some pre-trained models for Divey but they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=160" target="_blank">00:02:40.960</a></span> | <span class="t">not necessarily that useful for what we want to apply them to and you may think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=167" target="_blank">00:02:47.840</a></span> | <span class="t">okay there's those multilingual models with hundreds of languages included now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=172" target="_blank">00:02:52.840</a></span> | <span class="t">from at least what I've seen all of them miss Divey. Another thing that is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=177" target="_blank">00:02:57.800</a></span> | <span class="t">difficult with Divey and other low resource languages is actually finding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=183" target="_blank">00:03:03.160</a></span> | <span class="t">text data. Now labeled data is practically impossible for a lot of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=188" target="_blank">00:03:08.440</a></span> | <span class="t">these languages but unlabeled unstructured data maybe that's a bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=193" target="_blank">00:03:13.400</a></span> | <span class="t">more reasonable you can use a web scraper and scrape loads of text from whichever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=198" target="_blank">00:03:18.740</a></span> | <span class="t">language you are using the websites in that language on the internet and that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=203" target="_blank">00:03:23.320</a></span> | <span class="t">is what Ashraq has done to get the data set I'm using today. And as well as that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=210" target="_blank">00:03:30.240</a></span> | <span class="t">another really difficult thing is that Divey uses a very unique writing system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=216" target="_blank">00:03:36.840</a></span> | <span class="t">that is known as Fana and Fana looks really cool and is definitely very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=225" target="_blank">00:03:45.360</a></span> | <span class="t">unique and beautiful but it's not really very well supported even by those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=230" target="_blank">00:03:50.840</a></span> | <span class="t">multilingual language models you can see here it looks really cool you're also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=236" target="_blank">00:03:56.560</a></span> | <span class="t">going from right to left which is quite interesting everything's also in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=240" target="_blank">00:04:00.800</a></span> | <span class="t">same case there's no uppercase or lowercase which is again quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=244" target="_blank">00:04:04.480</a></span> | <span class="t">interesting I think so there's a lot of unique properties with this language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=250" target="_blank">00:04:10.440</a></span> | <span class="t">that we need to deal with and from what I've seen there are no current tokenizers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=256" target="_blank">00:04:16.320</a></span> | <span class="t">which actually support these characters so we really do need a tokenizer. First</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=262" target="_blank">00:04:22.080</a></span> | <span class="t">step is getting data so like I said before Ashraq went and did the hard part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=266" target="_blank">00:04:26.760</a></span> | <span class="t">and took or scraped a load of Divey text from the Divey Internet and he managed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=276" target="_blank">00:04:36.800</a></span> | <span class="t">to put together 16 or more than 16 million samples of Divey paragraphs and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=283" target="_blank">00:04:43.720</a></span> | <span class="t">sentences. Now obviously there are going to be little things in there that we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=288" target="_blank">00:04:48.320</a></span> | <span class="t">maybe don't want but for the most part it's actually very good. So step number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=294" target="_blank">00:04:54.040</a></span> | <span class="t">one is downloading the Divey corpus from Ashraq and you can see here so it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=300" target="_blank">00:05:00.720</a></span> | <span class="t">hosted over here on Hugging Face so we can use the datasets library to go ahead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=308" target="_blank">00:05:08.880</a></span> | <span class="t">and actually get that data which is pretty useful so we just do pip install</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=314" target="_blank">00:05:14.040</a></span> | <span class="t">if you don't have it already, datasets. Okay now once that's installed we can go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=322" target="_blank">00:05:22.120</a></span> | <span class="t">ahead and we just write this so we are going to Ashraq's Divey corpus and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=329" target="_blank">00:05:29.640</a></span> | <span class="t">are taking the train data split from that corpus. Now it's fairly big like I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=338" target="_blank">00:05:38.320</a></span> | <span class="t">said it's more than 16 million samples so what you can do if you don't want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=342" target="_blank">00:05:42.680</a></span> | <span class="t">load it all at once you can set streaming equals true and what that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=348" target="_blank">00:05:48.240</a></span> | <span class="t">do is create an iterable object which you can see down here and that means we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=355" target="_blank">00:05:55.120</a></span> | <span class="t">can form a for loop and iterate through the data one sample at time and not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=361" target="_blank">00:06:01.480</a></span> | <span class="t">download the full thing in one go we just download each sample as we look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=368" target="_blank">00:06:08.600</a></span> | <span class="t">through the whole list. So you can see here that's what I've done so the row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=376" target="_blank">00:06:16.800</a></span> | <span class="t">here in Divey train so going through the train split we're just printing one row</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=382" target="_blank">00:06:22.760</a></span> | <span class="t">at a time and again you can see that really cool Divey text in here. Now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=391" target="_blank">00:06:31.160</a></span> | <span class="t">there's just three samples here so it's very simple we just have almost like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=397" target="_blank">00:06:37.040</a></span> | <span class="t">dictionary we have text and then we have the Divey text following it so that is it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=405" target="_blank">00:06:45.200</a></span> | <span class="t">all I've done here so I'm creating a generator object because later on when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=413" target="_blank">00:06:53.480</a></span> | <span class="t">we are loading this data into the tokenizer that we're going to be loading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=416" target="_blank">00:06:56.920</a></span> | <span class="t">it in as a generator and that generator will expect us to load the text in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=424" target="_blank">00:07:04.280</a></span> | <span class="t">almost like lines so we'll expect to iterate through and just receive the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=429" target="_blank">00:07:09.160</a></span> | <span class="t">text it will not expect to receive a dictionary which contains the key text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=435" target="_blank">00:07:15.160</a></span> | <span class="t">which actually needs certain text it expects just this here okay nothing else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=443" target="_blank">00:07:23.560</a></span> | <span class="t">so I've done is create a generator object here and you don't need numerate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=449" target="_blank">00:07:29.960</a></span> | <span class="t">I'm not sure why that's there so remove that and all this does is iterate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=457" target="_blank">00:07:37.920</a></span> | <span class="t">through each row and extracts text from each row so it's literally going through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=463" target="_blank">00:07:43.120</a></span> | <span class="t">extracting this and nothing else so now when we actually use that that's what we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=472" target="_blank">00:07:52.120</a></span> | <span class="t">get so here we're using this Divey text function or generator we are using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=479" target="_blank">00:07:59.560</a></span> | <span class="t">exact same code we did before we're just printing the row you see now we don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=482" target="_blank">00:08:02.960</a></span> | <span class="t">get dictionary we get just plain text which is is what we want now that will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=489" target="_blank">00:08:09.080</a></span> | <span class="t">be fed into our tokenizer train from iterator method now we that's kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=496" target="_blank">00:08:16.740</a></span> | <span class="t">skipping ahead a bit so let's go back and take a look at where this tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=502" target="_blank">00:08:22.940</a></span> | <span class="t">is coming from in the first place okay so we have in our tokenizer we have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=510" target="_blank">00:08:30.500</a></span> | <span class="t">few different sets so let's say we have the tokenizer it's not just a tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=518" target="_blank">00:08:38.840</a></span> | <span class="t">there are different components or sub processes the very first is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=528" target="_blank">00:08:48.480</a></span> | <span class="t">normalization now this is optional you don't need to don't need to do this but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=535" target="_blank">00:08:55.640</a></span> | <span class="t">it's useful so given maybe we have something like we have these two words</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=545" target="_blank">00:09:05.360</a></span> | <span class="t">so this is specifically European languages here but we have C and C now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=554" target="_blank">00:09:14.520</a></span> | <span class="t">these are pretty similar and a lot of people may actually use these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=560" target="_blank">00:09:20.120</a></span> | <span class="t">interchangeably although they as far as I know are actually different words but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=565" target="_blank">00:09:25.800</a></span> | <span class="t">people may use them interchangeably and in if we would expect that then we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=570" target="_blank">00:09:30.800</a></span> | <span class="t">use something called NFKD Unicode normalization to actually take both</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=579" target="_blank">00:09:39.200</a></span> | <span class="t">these and create the same word which would just be SI and this is particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=584" target="_blank">00:09:44.800</a></span> | <span class="t">useful if you have weird characters so for example rather than the letter F</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=592" target="_blank">00:09:52.160</a></span> | <span class="t">like this you see people on social media using like the weird ones not like what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=599" target="_blank">00:09:59.460</a></span> | <span class="t">kind of like this it's all these weird characters and stuff but basically what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=603" target="_blank">00:10:03.580</a></span> | <span class="t">they mean is an F and because we're people we can understand that's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=608" target="_blank">00:10:08.440</a></span> | <span class="t">they're talking about but a machine learning model is not going to see those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=614" target="_blank">00:10:14.120</a></span> | <span class="t">as the same thing because they have different Unicode patterns so what we do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=619" target="_blank">00:10:19.280</a></span> | <span class="t">is use NFKD Unicode normalization and we convert them to being the same thing so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=624" target="_blank">00:10:24.320</a></span> | <span class="t">that can be quite useful another very useful thing is you can also lowercase</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=630" target="_blank">00:10:30.360</a></span> | <span class="t">within your normalization step so that's also useful now like I said before with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=637" target="_blank">00:10:37.840</a></span> | <span class="t">DeVay you don't have uppercase and lowercase so it's not really necessary for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=642" target="_blank">00:10:42.280</a></span> | <span class="t">that but if we do have for example English text in our data at any point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=649" target="_blank">00:10:49.040</a></span> | <span class="t">it's probably better we normalize it or lowercase it because that means we will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=655" target="_blank">00:10:55.280</a></span> | <span class="t">create less non-DeVay tokens so for example we have the word hello and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=666" target="_blank">00:11:06.360</a></span> | <span class="t">also have the word hello like this now without lowercasing these may become two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=673" target="_blank">00:11:13.840</a></span> | <span class="t">separate tokens and take up more space in our tokenizer vocabulary where we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=681" target="_blank">00:11:21.240</a></span> | <span class="t">only really want to keep DeVay characters or words so what we can do is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=686" target="_blank">00:11:26.600</a></span> | <span class="t">is lowercase that and that reduces the likelihood of getting duplicates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=692" target="_blank">00:11:32.600</a></span> | <span class="t">lowcase and uppercase non-DeVay characters in there so that's another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=697" target="_blank">00:11:37.360</a></span> | <span class="t">thing we will do so let me remove all of this so we are going to lowercase and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=708" target="_blank">00:11:48.560</a></span> | <span class="t">also use NFKD okay so that's the first component the next component after that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=717" target="_blank">00:11:57.480</a></span> | <span class="t">is pre-tokenization now pre-tokenization is a tokenization step that happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=729" target="_blank">00:12:09.160</a></span> | <span class="t">before we actually tokenize so what I mean by that so pre-tokenized let's say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=735" target="_blank">00:12:15.760</a></span> | <span class="t">we have we have a string hello world is probably easiest now what this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=748" target="_blank">00:12:28.120</a></span> | <span class="t">to do is just split this into very simple tokens so we might say anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=756" target="_blank">00:12:36.480</a></span> | <span class="t">with a space will get split or anything with space in between it will get split</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=762" target="_blank">00:12:42.080</a></span> | <span class="t">and maybe punctuation as well will get split so then we would end up with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=767" target="_blank">00:12:47.200</a></span> | <span class="t">token hello list from this we get hello we get world and we also get this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=779" target="_blank">00:12:59.120</a></span> | <span class="t">summation mark it's messy but I think that makes sense so that is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=786" target="_blank">00:13:06.560</a></span> | <span class="t">pre-tokenization step and then after that we actually have the model or the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=791" target="_blank">00:13:11.480</a></span> | <span class="t">tokenize itself now write model now this is where you have something like a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=799" target="_blank">00:13:19.920</a></span> | <span class="t">wordpiece tokenizer which is what we're going to use now wordpiece is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=803" target="_blank">00:13:23.400</a></span> | <span class="t">tokenizer that BERT uses and later on we're going to be using BERT models so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=807" target="_blank">00:13:27.240</a></span> | <span class="t">that's why I'm stuck with wordpiece and what this will do is it will take all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=813" target="_blank">00:13:33.240</a></span> | <span class="t">the tokens we've created and it will merge them into the most or the largest</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=823" target="_blank">00:13:43.360</a></span> | <span class="t">logical components I can think of so in this isn't very good example the hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=829" target="_blank">00:13:49.120</a></span> | <span class="t">world but let's say we have being maybe yep being so being for BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=839" target="_blank">00:13:59.520</a></span> | <span class="t">specifically this would probably get split into something like B and then a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=844" target="_blank">00:14:04.680</a></span> | <span class="t">sub word token which is always prefixed by the double hashtag symbol and that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=855" target="_blank">00:14:15.160</a></span> | <span class="t">would be ing so we get two tokens from that BERT or the BERT wordpiece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=862" target="_blank">00:14:22.240</a></span> | <span class="t">tokenizer sub word tokenizer so it doesn't split every word like hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=866" target="_blank">00:14:26.680</a></span> | <span class="t">probably just be hello but will split some words like this is being more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=872" target="_blank">00:14:32.420</a></span> | <span class="t">relevant if you split them which can be can be useful for example if you had</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=875" target="_blank">00:14:35.840</a></span> | <span class="t">like it snowed it is snowing and snow or snowboarding you would get snow in all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=882" target="_blank">00:14:42.260</a></span> | <span class="t">of those and then you get boarding or board and ing and get ing for snowing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=887" target="_blank">00:14:47.620</a></span> | <span class="t">and snow indeed but snowed so that can be quite useful to find patterns in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=896" target="_blank">00:14:56.580</a></span> | <span class="t">words or sub words next step is post processing so post processing and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=911" target="_blank">00:15:11.740</a></span> | <span class="t">is where we would add any special tokens to our text so BERT specifically would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=919" target="_blank">00:15:19.260</a></span> | <span class="t">use something like a what's called a classified token followed by hello world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=927" target="_blank">00:15:27.260</a></span> | <span class="t">followed by a separated token and you probably have padding tokens and all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=933" target="_blank">00:15:33.260</a></span> | <span class="t">these different things so we're adding in any special tokens there and we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=938" target="_blank">00:15:38.140</a></span> | <span class="t">also going to create different tensors so we will have an input IDs tensor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=947" target="_blank">00:15:47.300</a></span> | <span class="t">which will be the ID or integer values that represent each one of these word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=955" target="_blank">00:15:55.420</a></span> | <span class="t">tokens or sub word tokens we have token type IDs which is useful when you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=960" target="_blank">00:16:00.900</a></span> | <span class="t">sentence pairs and you will also have a attention mask tensor which tells BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=971" target="_blank">00:16:11.500</a></span> | <span class="t">or the transform model which tokens to actually pay attention to for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=976" target="_blank">00:16:16.100</a></span> | <span class="t">example ignore any padding tokens so I mean they're the main components of a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=981" target="_blank">00:16:21.300</a></span> | <span class="t">tokenizer but there is also another which we will I think always almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=987" target="_blank">00:16:27.140</a></span> | <span class="t">always add at least which is a decoder so when your model outputs let's say it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=995" target="_blank">00:16:35.300</a></span> | <span class="t">outputs a word prediction so it's predicting you've masked the word you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1000" target="_blank">00:16:40.940</a></span> | <span class="t">know let's say here we've covered hello and we said BERT what is that word and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1007" target="_blank">00:16:47.020</a></span> | <span class="t">BERT is trying to tell us hello but BERT doesn't know the string hello it just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1012" target="_blank">00:16:52.540</a></span> | <span class="t">knows token ID values so it's going to give us like it's going to say yeah this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1018" target="_blank">00:16:58.060</a></span> | <span class="t">is my prediction is the number three and obviously we're like okay great I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1022" target="_blank">00:17:02.540</a></span> | <span class="t">know what number three means so we need a decoder to take that number three and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1028" target="_blank">00:17:08.780</a></span> | <span class="t">translate that into something more readable for us which would be hello</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1033" target="_blank">00:17:13.380</a></span> | <span class="t">okay and that's that's what a decoder is for so obviously we don't need it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1038" target="_blank">00:17:18.940</a></span> | <span class="t">the input into BERT but we do need it we want to understand the output from BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1045" target="_blank">00:17:25.060</a></span> | <span class="t">so that's our tokenizer components reasonably high level but let's let's go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1053" target="_blank">00:17:33.180</a></span> | <span class="t">into the code and we'll have a look at how at least how we've implemented that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1057" target="_blank">00:17:37.100</a></span> | <span class="t">for our BERT wordpiece tokenizer so in this we are using the Hugging Face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1065" target="_blank">00:17:45.260</a></span> | <span class="t">tokenizers library which is is very good and definitely recommend you do the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1070" target="_blank">00:17:50.320</a></span> | <span class="t">otherwise this will be very difficult now the to install this you would just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1076" target="_blank">00:17:56.780</a></span> | <span class="t">pick install tokenizers there's nothing more to it than that and what I've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1082" target="_blank">00:18:02.540</a></span> | <span class="t">here is imported everything that we're going to be using now you can see a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1086" target="_blank">00:18:06.420</a></span> | <span class="t">of the components I mentioned earlier so we have we have decoders the models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1090" target="_blank">00:18:10.860</a></span> | <span class="t">which is a tokenizer itself normalizes pre tokenizers and the post processes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1098" target="_blank">00:18:18.580</a></span> | <span class="t">as well further on we have these other two classes and we'll go we'll get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1106" target="_blank">00:18:26.180</a></span> | <span class="t">them soon so I'll explain them later now first we want to do is actually we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1112" target="_blank">00:18:32.980</a></span> | <span class="t">not going in 1 2 3 4 like I said before because then we would be initializing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1118" target="_blank">00:18:38.980</a></span> | <span class="t">the normalization set first instead what we actually do is we initialize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1125" target="_blank">00:18:45.780</a></span> | <span class="t">tokenizer and the main component of that tokenizer is the model so in this case</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1131" target="_blank">00:18:51.220</a></span> | <span class="t">wordpiece so we initialize that using tokenizer here so you see up here we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1140" target="_blank">00:19:00.700</a></span> | <span class="t">have tokenizer this is just a wrapper so that we create a Hugging Face tokenizers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1148" target="_blank">00:19:08.380</a></span> | <span class="t">object and in there we need to pass the type tokenizer that I'm using and we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1153" target="_blank">00:19:13.820</a></span> | <span class="t">taking that from models up here and we're using wordpiece now in here we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1159" target="_blank">00:19:19.820</a></span> | <span class="t">also have the unknown token so you specify that so that's where your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1164" target="_blank">00:19:24.380</a></span> | <span class="t">tokenizer if it sees a word it doesn't know it will replace this okay it will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1170" target="_blank">00:19:30.820</a></span> | <span class="t">put new NK rather than just leaving it empty or not understanding this is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1178" target="_blank">00:19:38.100</a></span> | <span class="t">the only thing it can put there instead of raising an error or something so we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1184" target="_blank">00:19:44.620</a></span> | <span class="t">put that in there now after we have initialized a tokenizer instance we need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1192" target="_blank">00:19:52.180</a></span> | <span class="t">to set the tokenizer attributes which are going to relate to the components</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1198" target="_blank">00:19:58.580</a></span> | <span class="t">that we listed just a moment ago so here we set the normalizer attribute in our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1204" target="_blank">00:20:04.820</a></span> | <span class="t">tokenizer which we just initialize and we're setting that equal to normalizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1210" target="_blank">00:20:10.660</a></span> | <span class="t">sequence so there's a sequence of normalization sets here and we are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1217" target="_blank">00:20:17.300</a></span> | <span class="t">the lowercase first we locate everything and then we are using NFKD</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1223" target="_blank">00:20:23.420</a></span> | <span class="t">unicode normalization so there is flat so we've set normalization set then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1229" target="_blank">00:20:29.780</a></span> | <span class="t">do the pre tokenization set now pre tokenization is where we're splitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1236" target="_blank">00:20:36.220</a></span> | <span class="t">string into tokens so words or punctuation now the simplest way to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1244" target="_blank">00:20:44.980</a></span> | <span class="t">this is we use this white space tokenizer so all that does is splits on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1251" target="_blank">00:20:51.380</a></span> | <span class="t">either white space or on punctuation like commas or exclamation marks or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1256" target="_blank">00:20:56.260</a></span> | <span class="t">something like that so that's it we set out pre tokenizer and then we have this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1266" target="_blank">00:21:06.820</a></span> | <span class="t">so this was another part that we didn't mention so we imported this trainers so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1274" target="_blank">00:21:14.300</a></span> | <span class="t">we imported it here now trainers is basically the method that or function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1285" target="_blank">00:21:25.260</a></span> | <span class="t">that we'll be using to train or control the training process of our tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1292" target="_blank">00:21:32.140</a></span> | <span class="t">and all we're doing here is we're using a wordpiece trainer you can have a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1297" target="_blank">00:21:37.540</a></span> | <span class="t">wordpiece tokenizer model we are setting the vocabulary size so that's the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1303" target="_blank">00:21:43.060</a></span> | <span class="t">maximum number of tokens that our tokenizer will contain and then we also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1311" target="_blank">00:21:51.580</a></span> | <span class="t">need to set any special tokens so we already set one earlier but we need to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1315" target="_blank">00:21:55.140</a></span> | <span class="t">need to make sure that is included so with special tokens we probably won't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1322" target="_blank">00:22:02.660</a></span> | <span class="t">see them or we hopefully won't see them in our input text so or the text that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1330" target="_blank">00:22:10.460</a></span> | <span class="t">we'll be training on so what we do is we insert and now beforehand okay so we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1337" target="_blank">00:22:17.100</a></span> | <span class="t">have this known token padding token classified token separate token and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1342" target="_blank">00:22:22.180</a></span> | <span class="t">masculine token then here we set a min frequency so the minimum number of times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1347" target="_blank">00:22:27.180</a></span> | <span class="t">we need to see a token to add it to the vocabulary and then we also earlier on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1352" target="_blank">00:22:32.980</a></span> | <span class="t">you saw we had the sub words in our word piece tokenizer here we're just saying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1357" target="_blank">00:22:37.500</a></span> | <span class="t">the prefix identifies those so it's just a two symbols there now at this point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1368" target="_blank">00:22:48.220</a></span> | <span class="t">we're back to the start we were downloading the debate corpus again we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1372" target="_blank">00:22:52.140</a></span> | <span class="t">already covered it so we can skip that we already have the debate corpus and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1377" target="_blank">00:22:57.780</a></span> | <span class="t">are storing it in the generator text and then that's where we go into our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1383" target="_blank">00:23:03.940</a></span> | <span class="t">training step so the reason that we put TV or we create this TV text generator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1390" target="_blank">00:23:10.600</a></span> | <span class="t">is because we're training from iterator here which expects to receive lines of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1396" target="_blank">00:23:16.820</a></span> | <span class="t">text so we have text and then the trainer is equal to the trainer so the trainer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1404" target="_blank">00:23:24.560</a></span> | <span class="t">we define just up here so that controls the training process and that's it so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1412" target="_blank">00:23:32.220</a></span> | <span class="t">this once you run that that will run through all of the text in your TV text</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1420" target="_blank">00:23:40.060</a></span> | <span class="t">generator and train to the specifications you set in your trainer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1425" target="_blank">00:23:45.140</a></span> | <span class="t">object we can check so the tokenizer you can get the vocab size we said earlier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1431" target="_blank">00:23:51.300</a></span> | <span class="t">and you see this is 30,000 so as we as we would expect now before when I showed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1438" target="_blank">00:23:58.740</a></span> | <span class="t">you that list there were five sets and we've covered one which is normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1444" target="_blank">00:24:04.060</a></span> | <span class="t">to pre tokenization and three which would be our actual tokenization model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1454" target="_blank">00:24:14.820</a></span> | <span class="t">now after that we we train the tokenizer so we train using those first three sets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1460" target="_blank">00:24:20.900</a></span> | <span class="t">or components and then we still need to define that the next step which is the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1465" target="_blank">00:24:25.740</a></span> | <span class="t">post processing step now the first thing we do is we get our classifier ID so the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1474" target="_blank">00:24:34.620</a></span> | <span class="t">integer value that represents CLS and the integer value that represents SEP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1480" target="_blank">00:24:40.340</a></span> | <span class="t">we get both of those and we use this processing or processes template</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1486" target="_blank">00:24:46.700</a></span> | <span class="t">processing method to create this here which is looks quite messy but if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1494" target="_blank">00:24:54.020</a></span> | <span class="t">take a look at this here so we have the one input at the top and we have the two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1501" target="_blank">00:25:01.220</a></span> | <span class="t">inputs at the bottom so when you are feeding just a single sentence into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1507" target="_blank">00:25:07.020</a></span> | <span class="t">your BERT model what's going to happen is looking at code we are going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1511" target="_blank">00:25:11.500</a></span> | <span class="t">we are going to use this format so we're going to have our CLS token followed by A which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1517" target="_blank">00:25:17.220</a></span> | <span class="t">sentence one followed by the separated token now back to the image we have on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1527" target="_blank">00:25:27.260</a></span> | <span class="t">bottom we have two sentences now if we feed those into BERT they need to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1532" target="_blank">00:25:32.580</a></span> | <span class="t">understood as separate sentences to BERT or separate maybe question and context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1539" target="_blank">00:25:39.980</a></span> | <span class="t">for example now in that case back to our code we will use or we would format it as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1546" target="_blank">00:25:46.540</a></span> | <span class="t">a CLS token followed by sentence A the first one followed by a separated token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1553" target="_blank">00:25:53.580</a></span> | <span class="t">separate the two sentences and finally we would have sentence B after that and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1560" target="_blank">00:26:00.260</a></span> | <span class="t">then again we do finish with a separated token again now another thing that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1565" target="_blank">00:26:05.220</a></span> | <span class="t">different here is that we have this colon one for the pair now that's for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1571" target="_blank">00:26:11.020</a></span> | <span class="t">the token type IDs array so token type IDs tells BERT where we have sentence A</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1576" target="_blank">00:26:16.220</a></span> | <span class="t">and sentence B now in the case of a single sentence everything in token type IDs is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1582" target="_blank">00:26:22.460</a></span> | <span class="t">equal to zero so it's just all zero zero and zero the alternative where we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1591" target="_blank">00:26:31.420</a></span> | <span class="t">two sentences is that sentence A is going to be zero and everything related to sentence B is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1597" target="_blank">00:26:37.740</a></span> | <span class="t">going to be one it's as simple as that and then we need to specify the special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1603" target="_blank">00:26:43.420</a></span> | <span class="t">tokens that we're using here so we have CLS and we're specifying it again here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1608" target="_blank">00:26:48.340</a></span> | <span class="t">and mapping that to the actual token ID integer so we that's the post-processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1616" target="_blank">00:26:56.540</a></span> | <span class="t">step that's all sorted we don't need to do anything else with that now and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1623" target="_blank">00:27:03.900</a></span> | <span class="t">can move on to so after this our tokenizer will feed the input IDs that it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1630" target="_blank">00:27:10.060</a></span> | <span class="t">creates into the model and then we would move on to the decoder step so after</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1638" target="_blank">00:27:18.460</a></span> | <span class="t">BERT has finished processing whatever it's processing it's going to output you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1642" target="_blank">00:27:22.220</a></span> | <span class="t">a number like a word prediction maybe it's going to give you a token ID and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1647" target="_blank">00:27:27.260</a></span> | <span class="t">need to know okay how do we how do we decode that into something we can understand and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1651" target="_blank">00:27:31.420</a></span> | <span class="t">maybe it gives us a load of token IDs and what we need to do is say okay we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1658" target="_blank">00:27:38.060</a></span> | <span class="t">using a WordPiece tokenizer and we're going to decode from WordPiece and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1662" target="_blank">00:27:42.540</a></span> | <span class="t">also because we're using WordPiece as this prefix this is already set by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1667" target="_blank">00:27:47.540</a></span> | <span class="t">default by the way but I'm just putting in there in case you want to use a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1670" target="_blank">00:27:50.860</a></span> | <span class="t">prefix although I wouldn't recommend it but if you if you have reason to you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1675" target="_blank">00:27:55.620</a></span> | <span class="t">change that so that's our tokenizer and that that's it so we've initialized or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1684" target="_blank">00:28:04.500</a></span> | <span class="t">we've created our tokenizer and after that we move on to saving it into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1692" target="_blank">00:28:12.500</a></span> | <span class="t">format that is most useful to us so I think most of us when we are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1699" target="_blank">00:28:19.820</a></span> | <span class="t">tokenizer model we're probably going to use HoneyFace transformers not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1704" target="_blank">00:28:24.020</a></span> | <span class="t">HoneyFace tokenizers because they are two different libraries and when we load</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1710" target="_blank">00:28:30.340</a></span> | <span class="t">tokenizer with HoneyFace transformers we tend to use pre-trained tokenizer or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1714" target="_blank">00:28:34.980</a></span> | <span class="t">pre-trained tokenizer fast class now what we can do is save our tokenizer into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1725" target="_blank">00:28:45.700</a></span> | <span class="t">the format that is compatible with HoneyFace transformers and compatible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1730" target="_blank">00:28:50.740</a></span> | <span class="t">with this class specifically and to do that we first actually initialize the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1736" target="_blank">00:28:56.060</a></span> | <span class="t">tokenizer, the HoneyFace tokenizer tokenizer using this class so we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1742" target="_blank">00:29:02.420</a></span> | <span class="t">using pre-trained tokenizer fast and if you've used this before in HoneyFace transformers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1746" target="_blank">00:29:06.900</a></span> | <span class="t">we usually write from pre-trained and we load the model from here so like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1751" target="_blank">00:29:11.980</a></span> | <span class="t">based on case this time we're not using that not using any methods we're just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1756" target="_blank">00:29:16.260</a></span> | <span class="t">initializing the object directly we pass the tokenizer to tokenizer object then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1763" target="_blank">00:29:23.780</a></span> | <span class="t">also have the unknown token padding token and the other special tokens in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1767" target="_blank">00:29:27.420</a></span> | <span class="t">there as well okay so that is ready for us to save it's in the correct format now so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1777" target="_blank">00:29:37.060</a></span> | <span class="t">what we do is take full tokenizer which we've initialized here and we save it as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1782" target="_blank">00:29:42.320</a></span> | <span class="t">pre-trained model and what I'm doing here is saving it to the BERT based DB</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1787" target="_blank">00:29:47.900</a></span> | <span class="t">directory and once that's saved we're going to save these three files here and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1796" target="_blank">00:29:56.660</a></span> | <span class="t">from now we can actually just load it from pre-trained like we normally would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1801" target="_blank">00:30:01.700</a></span> | <span class="t">now just one thing when we load from pre-trained normally we probably are going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1807" target="_blank">00:30:07.260</a></span> | <span class="t">loading from the HuggingFace models hub in this case we're not loading from a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1813" target="_blank">00:30:13.180</a></span> | <span class="t">local directory so in some cases maybe you have this in a different directory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1818" target="_blank">00:30:18.840</a></span> | <span class="t">so you write your path here which would go to a different directory and then you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1825" target="_blank">00:30:25.180</a></span> | <span class="t">would have your model directory there okay so just be aware of that and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1831" target="_blank">00:30:31.620</a></span> | <span class="t">we can test our tokenizer with some debatex and we see okay cool this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1838" target="_blank">00:30:38.500</a></span> | <span class="t">debatex no idea what any of it means but it looks great and from that we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1846" target="_blank">00:30:46.660</a></span> | <span class="t">three tensors so we have these tensor which is two represents I think this CLS</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1855" target="_blank">00:30:55.220</a></span> | <span class="t">token and three here would represent our separator token the two special tokens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1860" target="_blank">00:31:00.500</a></span> | <span class="t">everything in between is debate or the punctuation like these brackets open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1867" target="_blank">00:31:07.860</a></span> | <span class="t">closing brackets comma or something else and then we have token type IDs now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1873" target="_blank">00:31:13.420</a></span> | <span class="t">only have one sentence here so sentence a all of that should be zero and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1882" target="_blank">00:31:22.940</a></span> | <span class="t">have the attention mass tensor as well in this case we don't have any padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1887" target="_blank">00:31:27.020</a></span> | <span class="t">that I've been padding so the attention master should just be one and that's it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1892" target="_blank">00:31:32.020</a></span> | <span class="t">our tokenizer is actually ready now if you do want to go ahead and actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1898" target="_blank">00:31:38.020</a></span> | <span class="t">load this tokenizer directly rather than going through all of this you can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1903" target="_blank">00:31:43.260</a></span> | <span class="t">write James Callum and load it like this because this is the on the hugging face</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1910" target="_blank">00:31:50.580</a></span> | <span class="t">modelers hub we we have a model and this also includes a BERT model as well so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1916" target="_blank">00:31:56.060</a></span> | <span class="t">you have the BERT model which can load and also the tokenizer so that is it for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1922" target="_blank">00:32:02.780</a></span> | <span class="t">this guide or walkthrough to building a BERT wordpiece tokenizer for a low</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1929" target="_blank">00:32:09.620</a></span> | <span class="t">resource or a language which does not have any currently supported tokenizer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1937" target="_blank">00:32:17.860</a></span> | <span class="t">so I hope this has been useful as I said the tokenizer is really just a first step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1944" target="_blank">00:32:24.660</a></span> | <span class="t">in what we hope will be a great way to support the debate language and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1953" target="_blank">00:32:33.820</a></span> | <span class="t">particularly the AI community over there in what they are building and doing by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1960" target="_blank">00:32:40.140</a></span> | <span class="t">putting together a few few BERT models that are fine-tuned or built for specific</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1965" target="_blank">00:32:45.860</a></span> | <span class="t">or different purposes and like this is the very first step in that so I hope</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=mjKqP3kRxbQ&t=1976" target="_blank">00:32:56.060</a></span> | <span class="t">it's all been very useful thank you very much for watching and I will see you in the next one. Bye!</span></div></div></body></html>