<html><head><title>Ethics for Data Science</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Ethics for Data Science</h2><a href="https://www.youtube.com/watch?v=krIVOb23EH8"><img src="https://i.ytimg.com/vi/krIVOb23EH8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=50">0:50</a> Ethics Issues<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=80">1:20</a> Feedback Loops<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=166">2:46</a> Case Study 2<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=244">4:4</a> Case Study 3<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=450">7:30</a> Questions<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=477">7:57</a> Unintended Consequences<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=491">8:11</a> Volkswagen<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=523">8:43</a> Ethics<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=654">10:54</a> Tech ethics syllabi<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=781">13:1</a> Core topics<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=973">16:13</a> Data containing errors<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1207">20:7</a> Feedback loops metrics<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1341">22:21</a> SAE grading software<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1444">24:4</a> Ill Go Transparency<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1540">25:40</a> Russia Today<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1782">29:42</a> Platform is the Message<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1871">31:11</a> Disinformation<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1896">31:36</a> Blitzscaling<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1948">32:28</a> Data Ethics<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2246">37:26</a> Bias<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2462">41:2</a> Privacy<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2761">46:1</a> Compass recidivism algorithm<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3003">50:3</a> Measurement bias<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3184">53:4</a> Are people biased<br><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3368">56:8</a> Algorithms in practice<br><br><div style="text-align: left;"><a href="./krIVOb23EH8.html">Whisper Transcript</a> | <a href="./transcript_krIVOb23EH8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">I'm Rachel Thomas, I am the founding director of the Center for Applied Data Ethics at the University of San Francisco and also co-founder of FAST AI together with Jeremy Howard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=10" target="_blank">00:00:10.000</a></span> | <span class="t">My background, I have a PhD in math and worked as a data scientist and software engineer in the tech industry and then have been working at USF on FAST AI for the past four years now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">So ethics issues are in the news. These articles I think are all from this fall, kind of showing up at this intersection of how technology is impacting our world in many kind of increasingly powerful ways, many of which really raise concerns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=45" target="_blank">00:00:45.000</a></span> | <span class="t">And I want to start by talking about three cases that I hope everyone working in technology knows about and is on the lookout for. So even if you only watch five minutes of this video, these are kind of the three cases I want you to see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=57" target="_blank">00:00:57.000</a></span> | <span class="t">And one is feedback loops. And so feedback loops can occur whenever your model is controlling the next round of data you get.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=65" target="_blank">00:01:05.000</a></span> | <span class="t">So the data that's returned quickly becomes flawed by the software itself and this can show up in many places. One example is with recommendation systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=75" target="_blank">00:01:15.000</a></span> | <span class="t">And so recommendation systems are ostensibly about predicting what content the user will like, but they're also determining what content the user is even exposed to and helping determine what has a chance of becoming popular.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=89" target="_blank">00:01:29.000</a></span> | <span class="t">And so YouTube has gotten a lot of a lot of tension about this for kind of highly recommending many conspiracy theories, many kind of very damaging conspiracy theories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=102" target="_blank">00:01:42.000</a></span> | <span class="t">There is also they've kind of put together recommendations of pedophilia picked out of what were kind of innocent home movies, but when are kind of strung together, ones that happen to have young girls in bathing suits or in their pajamas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=119" target="_blank">00:01:59.000</a></span> | <span class="t">So there's some really, really concerning results. And this is not something that any anybody intended. And we'll talk about this more later.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=127" target="_blank">00:02:07.000</a></span> | <span class="t">I think particularly for many of us coming from a science background, we're often used to thinking of like, oh, you know, like we observe the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=133" target="_blank">00:02:13.000</a></span> | <span class="t">But really, whenever you're building products that interact with the real world, you're also kind of controlling what the data looks like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=142" target="_blank">00:02:22.000</a></span> | <span class="t">Second case study I want everyone to know about comes from software that's used to determine poor people's health benefits. It's used in over half of the 50 states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=154" target="_blank">00:02:34.000</a></span> | <span class="t">And the Verge did an investigation on what happened when it was rolled out in Arkansas. And what happened is there was a bug in the software implementation that incorrectly cut coverage for people with cerebral palsy or diabetes, including Tammy Dobbs, who's pictured here and was interviewed in the article.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=171" target="_blank">00:02:51.000</a></span> | <span class="t">And so these are people that really needed this health care. And it was erroneously cut due to this bug. And so they were really and they couldn't get any sort of explanation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=183" target="_blank">00:03:03.000</a></span> | <span class="t">And there was no appeals or recourse process in place. And eventually, this all came out through a lengthy court case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=189" target="_blank">00:03:09.000</a></span> | <span class="t">But it's something where it caused a lot of a lot of suffering in the meantime. And so it's really important to implement systems with a way to identify and address mistakes and to do that quickly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=200" target="_blank">00:03:20.000</a></span> | <span class="t">And in a way that hopefully minimizes damage because we all know software can have bugs. Our code can behave in unexpected ways. And we need to be prepared for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=212" target="_blank">00:03:32.000</a></span> | <span class="t">I wrote more about this idea in a post two years ago, what HBR gets wrong about algorithms and bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=220" target="_blank">00:03:40.000</a></span> | <span class="t">And then third case study that everyone should know about. So this is Latonya Sweeney, who's director of the data privacy lab at Harvard. She has a PhD in computer science.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=230" target="_blank">00:03:50.000</a></span> | <span class="t">And she noticed several years ago that when you Google her name, you would get these ads saying Latonya Sweeney arrested, implying that she has a criminal record.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=240" target="_blank">00:04:00.000</a></span> | <span class="t">She's the only Latonya Sweeney and she has never been arrested. She paid $50 to the background check company and confirmed that she's never been arrested.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=248" target="_blank">00:04:08.000</a></span> | <span class="t">She tried Googling some other names and she noticed, for example, Kristin Lindquist got much more neutral ads that just say we found Kristin Lindquist, even though Kristin Lindquist has been arrested three times.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=260" target="_blank">00:04:20.000</a></span> | <span class="t">And so being a computer scientist, Dr. Sweeney to study this very systematically, she looked at over 2000 names and found that this pattern held in which disproportionately African American names were getting these ads suggesting that the person had a criminal record regardless of whether they did.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=278" target="_blank">00:04:38.000</a></span> | <span class="t">And traditionally European American or white names were getting more neutral ads. And this problem of kind of bias in advertising shows up a ton. Advertising is kind of the profit model for most of the major tech platforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=296" target="_blank">00:04:56.000</a></span> | <span class="t">And it kind of continues to pop up in high impact ways. Just last year there was research showing how Facebook's ad system discriminates even when the person placing the ad is not trying to do so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=309" target="_blank">00:05:09.000</a></span> | <span class="t">So for instance, the same housing ad, exact same text, if you change the photo between a white family and a black family, it's served to very different audiences. And so this is something that can really impact people when they're looking for housing, when they're applying for jobs and is a definite area of concern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=330" target="_blank">00:05:30.000</a></span> | <span class="t">So now I want to kind of step back and ask why does this matter? And so a very kind of extreme example is just that data collection has played a pivotal role in several genocides, including the Holocaust.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=345" target="_blank">00:05:45.000</a></span> | <span class="t">And so this is a photo of Adolf Hitler meeting with the CEO of IBM at the time. I think this photo is taken in 1937. And IBM continued to partner with the Nazis kind of long past when many other companies broke their ties.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=362" target="_blank">00:06:02.000</a></span> | <span class="t">They produced computers that were used in concentration camps to code, whether people were Jewish, how they were executed. And this is also different from now where you might sell somebody a computer and they never hear from them again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=377" target="_blank">00:06:17.000</a></span> | <span class="t">These machines require a lot of maintenance and kind of ongoing relationship with vendors to kind of upkeep and repair them. And it's something that a Swiss judge ruled.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=387" target="_blank">00:06:27.000</a></span> | <span class="t">It does not seem unreasonable to deduce that IBM's technical assistance facilitated the task of the Nazis in the commission of their crimes against humanity acts also involving accountancy and classification by IBM machines and utilized in the concentration camps themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=402" target="_blank">00:06:42.000</a></span> | <span class="t">I'm told that they haven't gotten around to apologizing yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=405" target="_blank">00:06:45.000</a></span> | <span class="t">Oh, that's terrible too. Yeah. Okay. Yeah. And so this is a very kind of a very sobering example, but I think it's important to keep in mind kind of what can go wrong and how technology can be used for for harm for very, very terrible harm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=426" target="_blank">00:07:06.000</a></span> | <span class="t">And so this just kind of raises a question questions that we all need to grapple with of how would you feel if you discovered that you had been part of a system that ended up hurting society, would you would you even know, would you be open to finding out kind of how how things you had built may have been harmful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=444" target="_blank">00:07:24.000</a></span> | <span class="t">And how can you help make sure this doesn't happen. And so I think these are questions that we all all need to grapple with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=453" target="_blank">00:07:33.000</a></span> | <span class="t">It's also important to think about unintended consequences on how your tech could be used or misused, whether that's by harassers by authoritarian governments for propaganda or disinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=467" target="_blank">00:07:47.000</a></span> | <span class="t">And then on a kind of a more concrete level, you could even end up in jail. And so there was a Volkswagen engineer who got prison time for his role in the diesel cheating case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=478" target="_blank">00:07:58.000</a></span> | <span class="t">So if you remember, this is where Volkswagen was cheating on emissions test and one of the kind of programmers that was a part of that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=486" target="_blank">00:08:06.000</a></span> | <span class="t">And that person was just following orders from what their boss told them to do. But that is not not a good excuse for for doing something that's unethical and so something to be aware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=500" target="_blank">00:08:20.000</a></span> | <span class="t">So ethics is the discipline dealing with what's good and bad. It's a set of moral principles. It's not a set of answers, but it's kind of learning what sort of what sort of questions to ask and even how to weigh these decisions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=515" target="_blank">00:08:35.000</a></span> | <span class="t">And I'll say some more about kind of ethical foundations and different ethical philosophies later later on in this lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=523" target="_blank">00:08:43.000</a></span> | <span class="t">But first, I'm going to kind of start with some some use cases. Ethics is not the same as religion, laws, social norms or feelings, although it does have overlap with all these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=534" target="_blank">00:08:54.000</a></span> | <span class="t">It's not a fixed set of rules. It's well-founded standards of right and wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=540" target="_blank">00:09:00.000</a></span> | <span class="t">And this is something where clearly not everybody agrees on the ethical action in every case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=546" target="_blank">00:09:06.000</a></span> | <span class="t">But that doesn't mean that kind of anything goes or that all actions are considered equally ethical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=552" target="_blank">00:09:12.000</a></span> | <span class="t">There are many things that are widely agreed upon and there are kind of a philosophical philosophical underpinnings for kind of making these decisions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=562" target="_blank">00:09:22.000</a></span> | <span class="t">And ethics is also the ongoing study and development of our ethical standards. It's a kind of never ending process of learning to kind of practice our ethical wisdom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=573" target="_blank">00:09:33.000</a></span> | <span class="t">I'm going to refer several times to so here I'm referring to a few articles from the Markula Center for Tech Ethics at Santa Clara University.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=582" target="_blank">00:09:42.000</a></span> | <span class="t">In particular, the work of Shannon Valor, Brian Green and Irina Reiku is fantastic and they have a lot of resources, some of which I'll circle back to later later in this talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=592" target="_blank">00:09:52.000</a></span> | <span class="t">I spent years of my life studying ethics. It was my major at university and so much time on the question of what is ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=601" target="_blank">00:10:01.000</a></span> | <span class="t">I think my takeaway from that is studying the philosophy ethics was not particularly helpful in learning about ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=608" target="_blank">00:10:08.000</a></span> | <span class="t">Yes, and I will try to keep this kind of very, very applied and very practical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=614" target="_blank">00:10:14.000</a></span> | <span class="t">Also very kind of tech industry specific of what what do you need in terms of applied ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=619" target="_blank">00:10:19.000</a></span> | <span class="t">Markula said it's great. They somehow they take stuff that I thought was super dry and turn it into useful checklists and things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=630" target="_blank">00:10:30.000</a></span> | <span class="t">I did want to note this was really neat.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=633" target="_blank">00:10:33.000</a></span> | <span class="t">So Casey Fiesler is a professor at University of Colorado that I really admire and she created a crowdsource spreadsheet of tech ethics syllabi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=641" target="_blank">00:10:41.000</a></span> | <span class="t">This was maybe two years ago and got over 200 syllabi entered into this this crowdsource spreadsheet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=648" target="_blank">00:10:48.000</a></span> | <span class="t">And then she did a meta analysis on them of kind of looking at all sorts of aspects of the syllabi and what's being taught and how it's being taught and published a paper on it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=659" target="_blank">00:10:59.000</a></span> | <span class="t">What do we teach when we teach tech ethics?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=662" target="_blank">00:11:02.000</a></span> | <span class="t">And a few interesting things about it is it raises there are a lot of ongoing discussions and lack of agreement on how to how to best teach tech ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=672" target="_blank">00:11:12.000</a></span> | <span class="t">Should it be a standalone course versus worked into every course in the curriculum?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=677" target="_blank">00:11:17.000</a></span> | <span class="t">Who should teach it? A computer scientist, a philosopher or a sociologist?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=683" target="_blank">00:11:23.000</a></span> | <span class="t">And she analyzed for the syllabi what was the course home and the instructor home.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=688" target="_blank">00:11:28.000</a></span> | <span class="t">And you can see that the instructors came from a range of courses, including a range of disciplines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=694" target="_blank">00:11:34.000</a></span> | <span class="t">Computer science, information science, philosophy, science and tech studies, engineering, law, math, business.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=701" target="_blank">00:11:41.000</a></span> | <span class="t">What topics to cover? A huge range of topics that can be covered, including a law and policy, privacy and surveillance, inequality, justice and human rights,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=712" target="_blank">00:11:52.000</a></span> | <span class="t">environmental impact, AI and robots, professional ethics, work in labor, cybersecurity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=718" target="_blank">00:11:58.000</a></span> | <span class="t">The list goes on and on. And so this is clearly more than can be covered in any even a full semester length course and certainly not in kind of a single single lecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=731" target="_blank">00:12:11.000</a></span> | <span class="t">What learning outcomes? This is an area where there's a little bit more agreement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=735" target="_blank">00:12:15.000</a></span> | <span class="t">We're kind of the number one skill that courses were trying to teach was critique followed by spotting issues, making arguments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=742" target="_blank">00:12:22.000</a></span> | <span class="t">And so a lot of this is just even learning to spot what the issues are and how to critically evaluate kind of a piece of technology or design proposal to see what could go wrong and what the risks could be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=757" target="_blank">00:12:37.000</a></span> | <span class="t">All right. So we're going to go through kind of a few different core topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=762" target="_blank">00:12:42.000</a></span> | <span class="t">And as I suggested, this is just going to be a kind of extreme subset of what could be covered.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=768" target="_blank">00:12:48.000</a></span> | <span class="t">We've tried to pick things that we think are very important and high impact. So one is recourse and accountability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=776" target="_blank">00:12:56.000</a></span> | <span class="t">So I already shared this example earlier of the system that is determining poor people's health care benefits, having a bug.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=785" target="_blank">00:13:05.000</a></span> | <span class="t">And something that was kind of terrible about this is nobody took responsibility even once the bug was found.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=792" target="_blank">00:13:12.000</a></span> | <span class="t">So the creator of the algorithm was interviewed and asked, they asked him, you know, should people be able to get an explanation for why their benefits have been cut?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=802" target="_blank">00:13:22.000</a></span> | <span class="t">And he gave this very callous answer of, you know, yeah, they probably should, but I should probably dust under my bed, you know, like who's going to do that, which is very callous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=812" target="_blank">00:13:32.000</a></span> | <span class="t">And then he ended up blaming the policymakers for how they had rolled out the algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=818" target="_blank">00:13:38.000</a></span> | <span class="t">The policymakers, you know, could blame the software engineers that implemented it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=823" target="_blank">00:13:43.000</a></span> | <span class="t">And so there was a lot of passing the buck here. Dana Boyd has said that, you know, it's always been a challenge for bureaucracy to assign responsibility or bureaucracy is used to evade responsibility.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=837" target="_blank">00:13:57.000</a></span> | <span class="t">And today's algorithmic systems are often extending bureaucracy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=842" target="_blank">00:14:02.000</a></span> | <span class="t">A couple of questions and comments about cultural context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=848" target="_blank">00:14:08.000</a></span> | <span class="t">Many notes that there didn't seem to be any mention of cultural contexts for ethics as part of those syllabi.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=855" target="_blank">00:14:15.000</a></span> | <span class="t">And somebody else was asking, how do you deal? You know, is this culturally dependent and how do you deal with that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=862" target="_blank">00:14:22.000</a></span> | <span class="t">It is culturally dependent. I will mention this briefly later on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=866" target="_blank">00:14:26.000</a></span> | <span class="t">So I'm going to share three different ethical philosophies that are kind of from the West. And we'll talk just briefly of one slide on, for instance, right now, there are a number of indigenous data sovereignty movements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=878" target="_blank">00:14:38.000</a></span> | <span class="t">And I know the Maori data sovereignty movement has been particularly active, but different, yeah, different cultures do have different views on ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=886" target="_blank">00:14:46.000</a></span> | <span class="t">And I think that the cultural context is incredibly important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=890" target="_blank">00:14:50.000</a></span> | <span class="t">And we will not get into it tonight, but there's also kind of a growing field of algorithmic colonialism and kind of studying what are some of the issues when you have technologies built in one particular country and culture being implemented, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=907" target="_blank">00:15:07.000</a></span> | <span class="t">halfway across the world in very different cultural context, often with little to no input from people, people living in that culture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=918" target="_blank">00:15:18.000</a></span> | <span class="t">Although I do want to say that there are things that are widely, although not universally agreed on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=925" target="_blank">00:15:25.000</a></span> | <span class="t">And so, for instance, the Universal Declaration on Human Rights, despite the name, it is not universally accepted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=931" target="_blank">00:15:31.000</a></span> | <span class="t">But many, many different countries have accepted that as a human rights framework and as those being fundamental rights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=937" target="_blank">00:15:37.000</a></span> | <span class="t">And so there are kind of principles that are often held cross-culturally, although, yeah, it's rare for something probably to be truly, truly universal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=950" target="_blank">00:15:50.000</a></span> | <span class="t">So returning to this topic of kind of accountability and recourse, something to keep in mind is the data contains errors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=958" target="_blank">00:15:58.000</a></span> | <span class="t">So there was a database used in California that's tracking supposedly gang members.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=967" target="_blank">00:16:07.000</a></span> | <span class="t">And an auditor found that there were 42 babies under the age of one who had been entered into this database.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=975" target="_blank">00:16:15.000</a></span> | <span class="t">And something concerning about the database is that it's basically never updated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=979" target="_blank">00:16:19.000</a></span> | <span class="t">I mean, people are added, but they're not removed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=981" target="_blank">00:16:21.000</a></span> | <span class="t">And so once you're in there, you're in there. And 28 of those babies were marked as having admitted to being gang members.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=988" target="_blank">00:16:28.000</a></span> | <span class="t">And so keep in mind that this is just a really obvious example of the error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=993" target="_blank">00:16:33.000</a></span> | <span class="t">But how many other kind of totally wrong entries are there?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=998" target="_blank">00:16:38.000</a></span> | <span class="t">Another example of data containing errors involves the three credit bureaus in the United States.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1007" target="_blank">00:16:47.000</a></span> | <span class="t">The FTC's large-scale study of credit reports found that 26 percent had at least one mistake in their files and 5 percent had errors that could be devastating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1016" target="_blank">00:16:56.000</a></span> | <span class="t">And this is the headline of an article that was written by a public radio reporter who went to get an apartment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1024" target="_blank">00:17:04.000</a></span> | <span class="t">And the landlord called him back afterwards and said, you know, your background check showed up that you had firearms convictions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1032" target="_blank">00:17:12.000</a></span> | <span class="t">And this person did not have any firearms convictions. And it's something where in most cases, the landlord would probably not even tell tell you and let you know that's why you weren't getting the apartment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1041" target="_blank">00:17:21.000</a></span> | <span class="t">And so this guy looked into it. I should note that this guy was white, which I'm sure helped him in getting the benefit of the doubt and found this error.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1051" target="_blank">00:17:31.000</a></span> | <span class="t">And he made dozens of calls and could not get it fixed until he told them that he was a reporter and that he was going to be writing about it, which is something that most of us would not be able to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1061" target="_blank">00:17:41.000</a></span> | <span class="t">But it was even once he had pinpointed the air and he had to talk to the county clerk in the place he used to live, it was still a very difficult process to get it updated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1074" target="_blank">00:17:54.000</a></span> | <span class="t">And this can have a huge, huge impact on people's lives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1080" target="_blank">00:18:00.000</a></span> | <span class="t">There's also the issue of when technology is used in ways that the creators may not have intended.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1086" target="_blank">00:18:06.000</a></span> | <span class="t">So, for instance, with facial recognition, it is pretty much entirely being developed for adults. Yet NYPD is putting the photos of children as young as age 11 into into databases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1099" target="_blank">00:18:19.000</a></span> | <span class="t">And we know the error rates are higher. This is not how it was developed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1104" target="_blank">00:18:24.000</a></span> | <span class="t">So this is this is a serious, serious concern. And there are a number of kind of misuses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1110" target="_blank">00:18:30.000</a></span> | <span class="t">The Georgetown Center for Privacy and Technology, which is fantastic, you should definitely be following them, did a report garbage in garbage out looking at how police were using facial recognition and practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1122" target="_blank">00:18:42.000</a></span> | <span class="t">And they found some really concerning examples. For instance, in one case NYPD had a photo of a suspect and they wasn't returning any matches.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1135" target="_blank">00:18:55.000</a></span> | <span class="t">And they said, well, this person kind of looks like Woody Harrelson. So then they googled the actor Woody Harrelson and put his face into the facial recognition and use that to generate leads.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1146" target="_blank">00:19:06.000</a></span> | <span class="t">And this is clearly not the correct use at all, but it's it's a way that it's being it's being used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1152" target="_blank">00:19:12.000</a></span> | <span class="t">And so there's kind of total lack of accountability here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1157" target="_blank">00:19:17.000</a></span> | <span class="t">And then another kind of study of cases in all 50 states of police officers kind of abusing confidential databases to look up ex-romantic partners or to look up activists.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1170" target="_blank">00:19:30.000</a></span> | <span class="t">And so, you know, here, this is not necessarily an error in the data, although that can be present as well, but kind of keeping in mind how it can be misused by the users.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1183" target="_blank">00:19:43.000</a></span> | <span class="t">The next topic is feedback loops and metrics. And so I talked a bit about feedback loops in the beginning as kind of one of one of the three key use cases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1193" target="_blank">00:19:53.000</a></span> | <span class="t">And so this is a topic I wrote a blog post about this fall. The problem with metrics is a big problem for AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1199" target="_blank">00:19:59.000</a></span> | <span class="t">And then together with David Yominsky, who's director of the Data Institute, expanded this into a paper, reliance on metrics is a fundamental challenge for AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1208" target="_blank">00:20:08.000</a></span> | <span class="t">And this was accepted to the ethics and data science conference.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1213" target="_blank">00:20:13.000</a></span> | <span class="t">But overemphasizing metrics can lead to a number of problems, including manipulation, gaming, myopic focus on short term goals, because it's easier to track short term quantities, unexpected negative consequences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1229" target="_blank">00:20:29.000</a></span> | <span class="t">And much of AI and machine learning centers on optimizing a metric.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1234" target="_blank">00:20:34.000</a></span> | <span class="t">This is kind of both the strength of machine learning as it's gotten really, really good at optimizing metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1239" target="_blank">00:20:39.000</a></span> | <span class="t">But I think this is also kind of inherently a weakness or a limitation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1245" target="_blank">00:20:45.000</a></span> | <span class="t">I'm going to give a few examples, and this can happen even not just in machine learning kind of but in analog examples as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1255" target="_blank">00:20:55.000</a></span> | <span class="t">So this is from a study of when English is England's public health system implemented a lot more targets around numbers in the early 2000s.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1267" target="_blank">00:21:07.000</a></span> | <span class="t">And the study was called what's what's measured is what matters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1270" target="_blank">00:21:10.000</a></span> | <span class="t">And so they found so one of the targets was around reducing our wait times, which seems like a good goal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1276" target="_blank">00:21:16.000</a></span> | <span class="t">However, this led to canceling scheduled operations to draft extra staff into the ER.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1283" target="_blank">00:21:23.000</a></span> | <span class="t">So if they felt like there are too many people in the ER, they would just start canceling operations so they could get more doctors requiring patients to wait in queues of ambulances because time waiting in an ambulance didn't count towards your ER wait time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1297" target="_blank">00:21:37.000</a></span> | <span class="t">Turning stretchers into beds by putting them in hallways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1301" target="_blank">00:21:41.000</a></span> | <span class="t">And there were also big discrepancies in the numbers reported by hospitals versus by patients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1305" target="_blank">00:21:45.000</a></span> | <span class="t">And so if you ask the hospital on average, how long are people waiting?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1309" target="_blank">00:21:49.000</a></span> | <span class="t">You get a very different answer than when you were asking the patients, how long did you have to wait?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1318" target="_blank">00:21:58.000</a></span> | <span class="t">Another another example is essay grading software.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1324" target="_blank">00:22:04.000</a></span> | <span class="t">And so this essay grading software, I believe, is being used in 22 states now in the United States.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1331" target="_blank">00:22:11.000</a></span> | <span class="t">Yes, 20 states and it tends to focus on metrics like sentence length, vocabulary, spelling, subject, verb agreement, because these are the things that we know how to measure and how to measure with a computer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1342" target="_blank">00:22:22.000</a></span> | <span class="t">But it can't evaluate things like creativity or novelty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1348" target="_blank">00:22:28.000</a></span> | <span class="t">However, gibberish essays with lots of sophisticated words score well and there are even examples of people creating computer programs to generate these kind of gibberish sophisticated essays and then they're graded by this other computer program and highly rated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1366" target="_blank">00:22:46.000</a></span> | <span class="t">There's also bias in this essays by African American students received lower grades from the computer than from expert human graders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1375" target="_blank">00:22:55.000</a></span> | <span class="t">And essays by students from mainland China received higher scores from the computer than from expert human graders and the authors of the study thought that this result suggests they may be using chunks of pre memorized text that score well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1394" target="_blank">00:23:14.000</a></span> | <span class="t">And this is these are just kind of two examples. I have a bunch more in the blog post and even more in the paper of ways that metrics can invite manipulation and gaming whenever they're they're given a lot of emphasis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1406" target="_blank">00:23:26.000</a></span> | <span class="t">And this is a good heart's laws, kind of a law that a lot of people talk about it as this idea that the more you rely on a metric, the kind of the less reliable it becomes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1420" target="_blank">00:23:40.000</a></span> | <span class="t">So returning to this example of feedback loops and recommendation systems, Guillaume Chaslot is a former Google slash YouTube engineer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1430" target="_blank">00:23:50.000</a></span> | <span class="t">YouTube is owned by Google and he wrote a really great post and he's done a ton to raise awareness about this issue and founded the nonprofit algo transparency, which kind of externally tries to monitor YouTube's recommendations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1444" target="_blank">00:24:04.000</a></span> | <span class="t">He's partnered with the Guardian and the Wall Street Journal to do investigations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1449" target="_blank">00:24:09.000</a></span> | <span class="t">But he wrote a post around how kind of in the in the earlier days, the recommendation system was designed to maximize watch time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1457" target="_blank">00:24:17.000</a></span> | <span class="t">And so and this is this is something else that's often going on with metrics is that any metric is just a proxy for what you truly care about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1466" target="_blank">00:24:26.000</a></span> | <span class="t">And so here, you know, the team at Google was saying, well, you know, if you're watching more YouTube, it signals to test that they're happier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1475" target="_blank">00:24:35.000</a></span> | <span class="t">However, this also ends up incentivizing content that tells you the rest of the media is lying because kind of believing that everybody else is lying will encourage you to spend more time on a particular platform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1488" target="_blank">00:24:48.000</a></span> | <span class="t">So Guillaume wrote a great post about this kind of mechanism that's at play.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1493" target="_blank">00:24:53.000</a></span> | <span class="t">And, you know, this is not just YouTube. This is any recommendation system could I think be susceptible to this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1500" target="_blank">00:25:00.000</a></span> | <span class="t">And there has been a lot of talk about kind of issues with many recommendation systems across platforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1508" target="_blank">00:25:08.000</a></span> | <span class="t">But it is it is something to be mindful of and something that the kind of creators of this did not anticipate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1516" target="_blank">00:25:16.000</a></span> | <span class="t">Then last year, Guillaume kind of gathered this data on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1522" target="_blank">00:25:22.000</a></span> | <span class="t">So here the X axis is the number of channels, number of YouTube channels recommending a video and the Y axis is the log of the views.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1531" target="_blank">00:25:31.000</a></span> | <span class="t">And we see this extreme outlier, which was Russia's today take Russia today's take on the Mueller report.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1537" target="_blank">00:25:37.000</a></span> | <span class="t">And this is something that Guillaume observed and then was picked up by the Washington Post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1543" target="_blank">00:25:43.000</a></span> | <span class="t">But this this strongly suggests that Russia today has perhaps gained the recommendation algorithm, which is which is not surprising.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1551" target="_blank">00:25:51.000</a></span> | <span class="t">And it's something that I think many content creators are conscious of and trying to experiment and see what what gets more heavily recommended and thus more views.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1562" target="_blank">00:26:02.000</a></span> | <span class="t">So it's also important to note that our online environments are designed to be addictive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1566" target="_blank">00:26:06.000</a></span> | <span class="t">And so when kind of what we click on is often used as a proxy of of what we enjoy or what we like, that's not necessarily, though, for of our kind of like our best selves or our higher selves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1578" target="_blank">00:26:18.000</a></span> | <span class="t">It's you know, it's what we're clicking on in this kind of highly addictive environment that's often appealing to some of our kind of lower instincts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1589" target="_blank">00:26:29.000</a></span> | <span class="t">St. up to Fecci uses the analogy of a cafeteria that's kind of shoving salty, sugary, fatty foods in our faces and then learning that, hey, people really like salty, sugary, fatty foods, which I think most of us do in a kind of very primal way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1604" target="_blank">00:26:44.000</a></span> | <span class="t">But we often, you know, kind of our higher self is like, oh, I don't want to be eating junk food all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1609" target="_blank">00:26:49.000</a></span> | <span class="t">And online, we often kind of don't have great mechanisms to say, you know, like, oh, I really want to read like more long form articles that took months to research and are going to take a long time to digest while we may want to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1625" target="_blank">00:27:05.000</a></span> | <span class="t">Our online environments are not not always conducive to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1629" target="_blank">00:27:09.000</a></span> | <span class="t">Yes. So if I make a comment about the false sense of security argument, which is very relevant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1636" target="_blank">00:27:16.000</a></span> | <span class="t">Masks and things. Did you have anything to say about this false sense of security argument?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1644" target="_blank">00:27:24.000</a></span> | <span class="t">Can you say more?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1651" target="_blank">00:27:31.000</a></span> | <span class="t">There's a common feedback at the moment that people shouldn't wear masks because they make a little sense of security that kind of makes sense to you from an ethical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1666" target="_blank">00:27:46.000</a></span> | <span class="t">No, that's I don't think that's a good argument at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1671" target="_blank">00:27:51.000</a></span> | <span class="t">In general, there's so many other people, including Jeremy, have pointed this out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1676" target="_blank">00:27:56.000</a></span> | <span class="t">There's so many actions we take to make our lives safer, whether that's wearing seat belts or wearing helmets when biking, practicing safe sex, like all sorts of things where we really want to maximize our safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1689" target="_blank">00:28:09.000</a></span> | <span class="t">And so I think in Zeynep Tefecti had a great thread on this today of it's not that there can never be any sort of impact in which people have a false sense of security, but it is something that you would really want to be gathering data on and build a strong case around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1705" target="_blank">00:28:25.000</a></span> | <span class="t">to just assume it's going to happen and that in most cases people can think of, even if that is a small second order effect, the effect of doing something that increases safety tends to have a much larger impact on actually increasing safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1722" target="_blank">00:28:42.000</a></span> | <span class="t">Do you have anything to add to that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1730" target="_blank">00:28:50.000</a></span> | <span class="t">Yeah, as I mentioned before, a lot of our incentives are focused on short term metrics. Long term things are much harder to measure and often involve kind of complex relationships.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1742" target="_blank">00:29:02.000</a></span> | <span class="t">And then the fundamental business model of most of the tech companies is around manipulating people's behavior and monopolizing their time. And these things I don't think in advertising is inherently bad, but they, I think it can be negative when taken to an extreme.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1759" target="_blank">00:29:19.000</a></span> | <span class="t">There's a great essay by James Grimmelman, "The Platform is the Message," and he points out these platforms are structurally at war with themselves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1770" target="_blank">00:29:30.000</a></span> | <span class="t">The same characteristics that make outrageous and offensive content unacceptable are what make it go viral in the first place. And so there's this kind of real tension here in which often things, yeah, that kind of can make content really offensive or unacceptable to us are also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1788" target="_blank">00:29:48.000</a></span> | <span class="t">what are kind of fueling their popularity and being promoted in many cases. And this is an interesting essay because he does this like really in depth dive on the Tide Pod Challenge, which was this meme around eating Tide Pods, which are poisonous, do not eat them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1807" target="_blank">00:30:07.000</a></span> | <span class="t">And he really analyzes it though. It's a great look at meme culture, which is very common and how kind of argues there's probably no example of someone talking about the Tide Pod Challenge that isn't partially ironic, which is common in memes that even kind of whatever you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1824" target="_blank">00:30:24.000</a></span> | <span class="t">saying, they're kind of layers of irony and different groups are interpreting them differently. And that even when you try to counteract them, you're still promoting them. So with the Tide Pod Challenge, a lot of like celebrities were telling people don't eat Tide Pods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1838" target="_blank">00:30:38.000</a></span> | <span class="t">But that was also then kind of perpetuating the popularity of this meme. So this is an essay I would recommend, I think it's pretty insightful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1849" target="_blank">00:30:49.000</a></span> | <span class="t">And so this is, we'll get to disinformation shortly, but the major tech platforms often incentivize and promote disinformation and this is unintentional, but it is somewhat built into their design and architecture, their recommendation systems and ultimately their business models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1869" target="_blank">00:31:09.000</a></span> | <span class="t">And then on the topic of metrics, I just want to bring up, so there's this idea of blitzscaling and the premise is that if a company grows big enough and fast enough, profits will eventually follow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1883" target="_blank">00:31:23.000</a></span> | <span class="t">It prioritizes speed over efficiency and risks potentially disastrous defeat. And Tim O'Reilly wrote a really great article last year talking about many of the problems with this approach, which I would say is incredibly widespread and is, I would say, the kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1898" target="_blank">00:31:38.000</a></span> | <span class="t">fundamental model underlying a lot of venture capital. And in it though, investors kind of end up anointing winners as opposed to market forces. It tends to lend itself towards creating monopolies and duopolies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1912" target="_blank">00:31:52.000</a></span> | <span class="t">It's bad for founders and people end up kind of spreading themselves too thin. So there are a number of significant downsides to this. Why am I bringing this up in an ethics lesson when we were talking about metrics?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1927" target="_blank">00:32:07.000</a></span> | <span class="t">But hockey stick growth requires automation and a reliance on metrics. Also prioritizing speed above all else doesn't leave time to reflect on ethics. And that is something that's hard that I think you do often have to kind of pause to think about ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1942" target="_blank">00:32:22.000</a></span> | <span class="t">And that following this model, when you do have a problem, it's often going to show up on a huge scale if you've scaled very quickly. So I think this is something to at least beware of.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1956" target="_blank">00:32:36.000</a></span> | <span class="t">So one person asks about is there a dichotomy between AI ethics, which seems like a very first world problem, and wars, poverty, environmental exploitation has been a level of problem, I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1977" target="_blank">00:32:57.000</a></span> | <span class="t">And there's an answer here, which is something else maybe you can comment on whether you agree or have anything to add, which is that AI ethics, they're saying, is very important also for other parts of the world, particularly in areas with high cell phone usage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=1992" target="_blank">00:33:12.000</a></span> | <span class="t">For example, many countries in Africa have high cell penetration. People get their news from Facebook and WhatsApp and YouTube, and though it's useful, it's been the source of many problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2001" target="_blank">00:33:21.000</a></span> | <span class="t">Do you have any comments on that kind of? Yeah, so I think the first question, so AI ethics, as I noted earlier, and I'm using the phrase data ethics here, but it's this very broad and it refers to a lot of things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2014" target="_blank">00:33:34.000</a></span> | <span class="t">I think if people are talking about the, you know, in the future, can computers achieve sentience and what are the ethics around that? And that is not my focus at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2026" target="_blank">00:33:46.000</a></span> | <span class="t">I am very much focused on, and this is our mission with the Center for Applied Data Ethics at the University of San Francisco, is kind of how are people being harmed now? What are the most immediate harms?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2036" target="_blank">00:33:56.000</a></span> | <span class="t">And so in that sense, I don't think that data ethics has to be a first world or kind of futuristic issue. It's what's happening now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2046" target="_blank">00:34:06.000</a></span> | <span class="t">And yeah, and as the person said, and a few examples, well, one example I'll get to later is definitely the genocide in Myanmar in which the Muslim minority, the Rohingya, are experiencing genocide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2061" target="_blank">00:34:21.000</a></span> | <span class="t">The UN has ruled that Facebook played a determining role in that, which is really intense and terrible. And so I think that's an example of technology leading to very real harm now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2076" target="_blank">00:34:36.000</a></span> | <span class="t">They're also, yeah, WhatsApp, which is owned by Facebook. There have been issues with people spreading disinformation and rumors and it's led to several lynching, dozens of lynchings in India of people kind of spreading these false rumors of, oh, there's a kidnapper coming around and in these kind of small remote villages and then a visitor or stranger shows up and gets killed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2100" target="_blank">00:35:00.000</a></span> | <span class="t">And WhatsApp also played a very important role or bad role in the election of Bolsonaro in Brazil, election of Duerte in the Philippines.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2110" target="_blank">00:35:10.000</a></span> | <span class="t">So I think technology is having a kind of very immediate impact on people and that those are the types of ethical questions I'm really interested in and that I hope you are interested in as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2125" target="_blank">00:35:25.000</a></span> | <span class="t">Do you have anything else to say about that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2129" target="_blank">00:35:29.000</a></span> | <span class="t">Well, I will talk about disinformation. I realize those were kind of some disinformation focus and I'm going to talk about bias first. I think it's bias and disinformation. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2138" target="_blank">00:35:38.000</a></span> | <span class="t">Question. When we talk about ethics, how much of this is intentional unethical behavior? I see a lot of the examples as more of competent behavior or bad modeling, whether product or models are rushed without sufficient testing, thought around bias, so forth, but not necessarily malignant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2156" target="_blank">00:35:56.000</a></span> | <span class="t">Yeah, no, I agree with that. I think that most of this is unintentional. I do think there's a often though, well, we'll get into some cases. I think that I think in many cases, the profit incentives are misaligned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2170" target="_blank">00:36:10.000</a></span> | <span class="t">And I do think that when people are earning a lot of money, it is very hard to consider actions that would reduce their profits, even if they would prevent harm and increase kind of ethics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2182" target="_blank">00:36:22.000</a></span> | <span class="t">And so I think that there's at some point where valuing profit over how people are being harmed is when does that become intentional is a question to debate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2196" target="_blank">00:36:36.000</a></span> | <span class="t">But I don't think people are setting out to say like I want to cause a genocide or I want to help an authoritarian leader get elected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2205" target="_blank">00:36:45.000</a></span> | <span class="t">Most people are not starting with that, but I think sometimes it's a carelessness and a thoughtlessness, but that I do think we are responsible for that and we're responsible to kind of be more careful and more thoughtful in how we approach things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2221" target="_blank">00:37:01.000</a></span> | <span class="t">All right, so bias. So bias, I think, is an issue that's probably gotten a lot of attention, which is great. And I want to get a little bit more in depth because sometimes discussions on bias stay a bit superficial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2233" target="_blank">00:37:13.000</a></span> | <span class="t">There was a great paper by Harini Suresh and John Gutag last year that looked at kind of came up with this taxonomy of different types of bias and how they had kind of different sources in the machine learning kind of pipeline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2249" target="_blank">00:37:29.000</a></span> | <span class="t">And it was really helpful because, you know, different sources have different causes and they also require different different approaches for addressing that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2258" target="_blank">00:37:38.000</a></span> | <span class="t">Harini wrote a blog post version of the paper as well, which I love when researchers do that. I hope more of you, if you're writing an academic paper, also write the blog post version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2268" target="_blank">00:37:48.000</a></span> | <span class="t">And I'm just going to go through a few of these types.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2272" target="_blank">00:37:52.000</a></span> | <span class="t">So one is representation bias. And so I would imagine many of you have heard of Joy Balamwini's work, which has rightly received a lot of publicity in gender shades.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2284" target="_blank">00:38:04.000</a></span> | <span class="t">She and Timnit Gebru investigated commercial computer vision products from Microsoft, IBM, and Face++.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2290" target="_blank">00:38:10.000</a></span> | <span class="t">And then Joy Balamwini and Debraji did a follow-up study that looked at Amazon and Keros and several other companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2298" target="_blank">00:38:18.000</a></span> | <span class="t">And the typical results they kind of found basically everywhere was that these products performed significantly worse on dark-skinned women.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2305" target="_blank">00:38:25.000</a></span> | <span class="t">So they were kind of doing worse on people with darker skin compared to lighter skin, worse on women than on men.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2312" target="_blank">00:38:32.000</a></span> | <span class="t">And then the kind of the intersection of that dark-skinned women had these very high air rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2316" target="_blank">00:38:36.000</a></span> | <span class="t">And so one example is IBM. Their product was 99.7 percent accurate on light-skinned men and only 65 percent accurate on dark-skinned women.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2327" target="_blank">00:38:47.000</a></span> | <span class="t">And again, this is a commercial computer vision product that was released. Question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2334" target="_blank">00:38:54.000</a></span> | <span class="t">There's a question from the Trimmel study group about the Volkswagen example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2340" target="_blank">00:39:00.000</a></span> | <span class="t">In many cases, it's management that drives and rewards unethical behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2345" target="_blank">00:39:05.000</a></span> | <span class="t">What can an individual engineer do in a case like this, especially in a place like Silicon Valley where people move companies so often?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2353" target="_blank">00:39:13.000</a></span> | <span class="t">Yeah, so I think I think that's a great point. And that is an example where I would have I would have much rather seen people that were higher ranking during jail time about this because I think that they were they were driving that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2366" target="_blank">00:39:26.000</a></span> | <span class="t">I think that it's great to remember that I know many people in the world don't have this option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2376" target="_blank">00:39:36.000</a></span> | <span class="t">But I think for many of us working in tech, particularly in Silicon Valley, we tend to have a lot of options and often more options than we realize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2383" target="_blank">00:39:43.000</a></span> | <span class="t">Like I talk to people frequently that feel trapped in their jobs, even though they're a software engineer in Silicon Valley and so many companies are hiring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2393" target="_blank">00:39:53.000</a></span> | <span class="t">And so I think it is important to use that leverage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2396" target="_blank">00:39:56.000</a></span> | <span class="t">I think a lot of the kind of employee organizing movements are very promising and that can be useful, but really trying to kind of vet the ethics of the company you're joining and also being willing to walk away if you if if you're able to do so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2415" target="_blank">00:40:15.000</a></span> | <span class="t">That's a great, great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2419" target="_blank">00:40:19.000</a></span> | <span class="t">So this is this example of representation bias here. The kind of way to address this is to build a more representative data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2426" target="_blank">00:40:26.000</a></span> | <span class="t">It's very important to keep consent in mind of the people if you're using pictures of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2432" target="_blank">00:40:32.000</a></span> | <span class="t">But Joy Balamini and Tim, Nick, did this as part of as part of gender shades.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2438" target="_blank">00:40:38.000</a></span> | <span class="t">However, this is the fact that this was a problem not just for one company, but basically kind of every company they looked at was due to this underlying problem, which is that in machine learning benchmark data sets for on a lot of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2455" target="_blank">00:40:55.000</a></span> | <span class="t">However, kind of several years ago, all the kind of popular facial data sets were primarily of light skinned men, for instance, IGB a kind of popular face data set several years ago, only 4% of the images were of dark skinned women.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2472" target="_blank">00:41:12.000</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2476" target="_blank">00:41:16.000</a></span> | <span class="t">Question. I've been worried about COVID-19 contact tracing and the erosion of privacy, location tracking, private surveillance companies, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2485" target="_blank">00:41:25.000</a></span> | <span class="t">What can we do to protect our digital rights post-COVID? Can we look to any examples in history of what to expect?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2492" target="_blank">00:41:32.000</a></span> | <span class="t">That is a huge question and something I have been thinking about as well. I'm going to put that off to later to talk about. And that is something where in the course I teach, I have an entire unit on privacy and surveillance, which I do not in tonight's lecture, but I can share some materials.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2511" target="_blank">00:41:51.000</a></span> | <span class="t">Although I am already really even just like rethinking how I'm going to teach privacy and surveillance in the age of COVID-19 compared to two months ago when I taught it the first time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2522" target="_blank">00:42:02.000</a></span> | <span class="t">But that is something I think about a lot and I will talk about later if we have time or on the forums if we don't. That's a great question, a very important question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2535" target="_blank">00:42:15.000</a></span> | <span class="t">On the topic and I will say and I have not had the time to look into them yet. I do know that there are groups that are working on what are kind of more privacy protecting approaches for tracking and they're also groups putting out like if we are going to use some sort of tracking, what are the safeguards that need to be in place to do it responsibly?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2555" target="_blank">00:42:35.000</a></span> | <span class="t">Yes, I've been looking at that too. It does seem like this is a solvable problem with technology. Not all of these problems are, but you can certainly store tracking history on somebody's cell phone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2569" target="_blank">00:42:49.000</a></span> | <span class="t">And then you could have something where you say when you've been infected and at that point you could tell people that they've been infected by sharing the location in a privacy preserving way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2584" target="_blank">00:43:04.000</a></span> | <span class="t">I think some people are trying to work on that. I'm not sure it's particularly technically a problem. So I think that sometimes there are ways to provide the minimum kind of level, you know, kind of application with keeping privacy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2601" target="_blank">00:43:21.000</a></span> | <span class="t">Yeah, and then I think it is very important to also have things of, you know, clear like expiration date, like we, you know, like looking back at 9/11 in the United States that kind of ushered in all these laws that were now kind of stuck with that have really eroded privacy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2616" target="_blank">00:43:36.000</a></span> | <span class="t">of anything we do around COVID-19 being very clear we are just doing this for COVID-19 and then there's a time limit and expires and it's kind of for this clear purpose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2627" target="_blank">00:43:47.000</a></span> | <span class="t">And there are also issues though of, you know, I mentioned earlier about data containing errors. I know this has already been an issue in some of other countries that we're doing kind of more surveillance focused approaches of, you know, what about like when it's wrong and people are getting kind of quarantined and they don't even know why and for no reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2647" target="_blank">00:44:07.000</a></span> | <span class="t">And so to be mindful of those. But yeah, we'll talk more about this kind of later on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2652" target="_blank">00:44:12.000</a></span> | <span class="t">Back to back to bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2657" target="_blank">00:44:17.000</a></span> | <span class="t">Yeah, we had kind of the benchmarks. So when the benchmark that's, you know, widely used has bias, then that is really kind of replicated at scale and we're seeing this with ImageNet as well, which is, you know, probably the most widely studied computer vision data set out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2674" target="_blank">00:44:34.000</a></span> | <span class="t">Two thirds of the ImageNet images are from the West. So this pie chart shows that the 45% of the images in ImageNet are from the United States, 7% from Great Britain, 6% from Italy, 3% from Canada, 3% from Australia.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2691" target="_blank">00:44:51.000</a></span> | <span class="t">You know, and we're covering a lot of this pie without having gotten to outside the West. And so then this has shown up in concrete ways of classifiers trained on ImageNet. So one of the categories is bridegroom, a man getting married.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2708" target="_blank">00:45:08.000</a></span> | <span class="t">There are a lot of, you know, cultural components to that. And so they have, you know, much higher error rates on bridegrooms from the Middle East or from the Global South.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2720" target="_blank">00:45:20.000</a></span> | <span class="t">And there are people now kind of working to diversify these data sets, but it is quite dangerous that they can really be kind of widely built on its scale or have been widely built on its scale before these biases were recognized.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2737" target="_blank">00:45:37.000</a></span> | <span class="t">Another case study is the Compass Residivism algorithm, which is used in determining who has to pay bail. So in the US, a very large number of people are in prison who have not even had a trial yet just because they're too poor to afford bail, as well as sentencing decisions and parole decisions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2756" target="_blank">00:45:56.000</a></span> | <span class="t">And ProPublica did a famous investigation in 2016 that I imagine many of you have heard of in which they found that the false positive rate for black defendants was nearly twice as high as for white defendants.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2770" target="_blank">00:46:10.000</a></span> | <span class="t">So black defendants were lit. A study from Dartmouth found that it was the software is no more accurate than Amazon mechanical Turk workers, so random people on the internet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2781" target="_blank">00:46:21.000</a></span> | <span class="t">It's also the software is, you know, this proprietary black box using over 130 inputs, and it's no more accurate than a linear classifier on three variables.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2792" target="_blank">00:46:32.000</a></span> | <span class="t">Yet it's still in use, and it's in use in many states. Wisconsin is one place where it was challenged, yet the Wisconsin Supreme Court upheld its use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2802" target="_blank">00:46:42.000</a></span> | <span class="t">If you're interested in the kind of topic of how you define fairness, because there is a lot of intricacy here, and I mean, I don't know anybody working on this who thinks that what Compass is doing is right, but they're using this different definition of fairness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2818" target="_blank">00:46:58.000</a></span> | <span class="t">Arvind Ranyan has a fantastic tutorial, 21 fairness definitions in their politics that I highly recommend.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2829" target="_blank">00:47:09.000</a></span> | <span class="t">And so going back to kind of this taxonomy of types of bias, this is an example of historical bias, and historical bias is a fundamental structural issue with the first step of the data generation process and it can exist even given perfect sampling and feature selection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2845" target="_blank">00:47:25.000</a></span> | <span class="t">So kind of with the image classifier, that was something where we could, you know, go gather a more representative set of images and that would help address it. That is not the case here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2854" target="_blank">00:47:34.000</a></span> | <span class="t">So gathering kind of more data on the US criminal justice system, it's all going to be biased because that's really kind of baked into baked into our history and our current state.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2866" target="_blank">00:47:46.000</a></span> | <span class="t">And so this is, I think, good, good to recognize.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2871" target="_blank">00:47:51.000</a></span> | <span class="t">One thing that can be done to try to at least mitigate this is to really talk to domain experts and by the people impacted. And so a really positive example of this is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2885" target="_blank">00:48:05.000</a></span> | <span class="t">tutorial from the Fairness Accountability and Transparency Conference that Christian Lum, who's the lead statistician for the Human Rights Data Analysis Group and now professor at UPenn, organized together with a former public defender, Elizabeth Bender,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2901" target="_blank">00:48:21.000</a></span> | <span class="t">who's the staff attorney for New York's Legal Aid Society, and Terrence Wilkerson, an innocent man who was arrested and could not afford bail.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2909" target="_blank">00:48:29.000</a></span> | <span class="t">And Elizabeth and Terrence were able to provide a lot of insight to how the criminal justice system works in practice, which is often kind of very different from the more kind of clean, logical abstractions that computer scientists deal with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2924" target="_blank">00:48:44.000</a></span> | <span class="t">But it's really important to understand those kind of intricacies of how this is going to be implemented and used in these messy, complicated, real-world systems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2933" target="_blank">00:48:53.000</a></span> | <span class="t">Question?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2937" target="_blank">00:48:57.000</a></span> | <span class="t">Aren't the AI biases transferred from real-life biases? For instance, how are people being treated differently? Isn't everyday phenomenon women too?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2948" target="_blank">00:49:08.000</a></span> | <span class="t">That's correct, yes. So this is often coming from real-world biases. And I'll come to this in a moment, but algorithmic systems can amplify those biases, so they can make them even worse. But they are often being learned from existing data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2966" target="_blank">00:49:26.000</a></span> | <span class="t">I asked it because I guess I often see this being raised as if it's kind of a reason not to worry about AI, so I thought it's not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2975" target="_blank">00:49:35.000</a></span> | <span class="t">Well, I'm going to get to that in a moment. I'm actually thinking two slides, so hold on to that question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2984" target="_blank">00:49:44.000</a></span> | <span class="t">I just want to talk about one other type of bias first, measurement bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=2988" target="_blank">00:49:48.000</a></span> | <span class="t">So this was an interesting paper by Sendiel Melanathan and Zayed Obermeyer, where they looked at historic electronic health record data to try to determine what factors are most predictive of stroke.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3000" target="_blank">00:50:00.000</a></span> | <span class="t">And they said, you know, this could be useful, like prioritizing patients at the ER.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3004" target="_blank">00:50:04.000</a></span> | <span class="t">And so they found that the number one most predictive factor was prior stroke, which that makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3010" target="_blank">00:50:10.000</a></span> | <span class="t">Second was cardiovascular disease. That's also that seems reasonable. And then third most kind of still very predictive factor was accidental injury, followed by having a benign breast lump, a colonoscopy or sinusitis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3026" target="_blank">00:50:26.000</a></span> | <span class="t">And so I'm not a medical doctor, but I can tell something weird is going on with factors three through six here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3032" target="_blank">00:50:32.000</a></span> | <span class="t">Like, why would these things be predictive of stroke? Does anyone want to think about about why this might be?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3046" target="_blank">00:50:46.000</a></span> | <span class="t">Any guesses you want to read? Oh, someone's. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3055" target="_blank">00:50:55.000</a></span> | <span class="t">OK, the first answer was they test for it anytime someone has stroke confirmation bias overfitting is because they happen to be in hospital already biased data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3069" target="_blank">00:51:09.000</a></span> | <span class="t">EHR records these events because the data was taken before certain advances in medical science.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3077" target="_blank">00:51:17.000</a></span> | <span class="t">These are these are all good guesses, not not quite what I was looking for, but good, good thinking. That's such a nice way of saying.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3086" target="_blank">00:51:26.000</a></span> | <span class="t">So what that what the researchers say here is that this was about their patients, their people that utilize health care a lot and people that don't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3095" target="_blank">00:51:35.000</a></span> | <span class="t">And they call it kind of high utility versus low utility of health care. And there are a lot of factors that go into this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3100" target="_blank">00:51:40.000</a></span> | <span class="t">I'm sure just who has health insurance and who can afford their copays. There may be cultural factors, maybe racial and gender bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3106" target="_blank">00:51:46.000</a></span> | <span class="t">There is racial and gender bias on how people are treated. So a lot of factors and basically people that utilize health care a lot,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3115" target="_blank">00:51:55.000</a></span> | <span class="t">they will go to a doctor when they have sinusitis and they will also go in when they're having a stroke.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3120" target="_blank">00:52:00.000</a></span> | <span class="t">And people that do not utilize health care much are probably not going to go in possibly for either.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3125" target="_blank">00:52:05.000</a></span> | <span class="t">And so what the authors write is that we haven't measured stroke, which is a region of the brain being denied kind of new blood and new oxygen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3134" target="_blank">00:52:14.000</a></span> | <span class="t">What we've measured is who had symptoms, who went to the doctor, received tests and then got this diagnosis of stroke.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3140" target="_blank">00:52:20.000</a></span> | <span class="t">And that seems like it might be a reasonable proxy for who had a stroke, but a proxy is never exactly what you wanted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3148" target="_blank">00:52:28.000</a></span> | <span class="t">And in many cases that that gap ends up being significant. And so this is just one form that measurement bias can take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3155" target="_blank">00:52:35.000</a></span> | <span class="t">But I think it's something to really kind of be on the lookout for because it can be quite subtle.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3159" target="_blank">00:52:39.000</a></span> | <span class="t">And so now starting to return to a point that was brought up earlier, aren't aren't people biased? Yes, yes, we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3167" target="_blank">00:52:47.000</a></span> | <span class="t">And so there have been dozens and dozens, if not hundreds of studies on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3174" target="_blank">00:52:54.000</a></span> | <span class="t">But I'm just going to quote a few, all of which are linked to in this Cyndale Melanathan New York Times article, if you want to find find the studies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3181" target="_blank">00:53:01.000</a></span> | <span class="t">So this all comes from, you know, peer reviewed research. But when doctors were shown identical files, they were much less likely to recommend a helpful cardiac procedure to black patients compared to white patients.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3192" target="_blank">00:53:12.000</a></span> | <span class="t">And so that was, you know, same file, but just changing the race of the patient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3197" target="_blank">00:53:17.000</a></span> | <span class="t">When bargaining for a used car, black people were offered initial prices, seven hundred dollars higher and received fewer concessions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3204" target="_blank">00:53:24.000</a></span> | <span class="t">Responding to apartment rental ads on Craigslist with a black name elicited fewer responses than with a white name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3210" target="_blank">00:53:30.000</a></span> | <span class="t">An all white jury was 16 points more likely to convict a black defendant than a white one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3215" target="_blank">00:53:35.000</a></span> | <span class="t">But when a jury had just one black member, it convicted both at the same rate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3220" target="_blank">00:53:40.000</a></span> | <span class="t">And so I share these to show that kind of no matter what type of data you're looking working on, whether that is medical data or sales data or housing data or criminal justice data, that it's very likely that there's there's bias in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3233" target="_blank">00:53:53.000</a></span> | <span class="t">There's a question. I was going to say, I find that last one really interesting, like this kind of idea that a single black member of a jury, I guess it has some kind of like anchoring impact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3243" target="_blank">00:54:03.000</a></span> | <span class="t">It kind of suggests that, you know, I'm sure you're going to talk about diversity later, but I just want to keep this in mind that maybe like even a tiny bit of diversity here just reminds people that there's a, you know, a range of different types of people and perspectives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3257" target="_blank">00:54:17.000</a></span> | <span class="t">No, that's it. That's a great point. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3263" target="_blank">00:54:23.000</a></span> | <span class="t">And so the question that was kind of asked earlier is, so why does algorithmic bias matter?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3268" target="_blank">00:54:28.000</a></span> | <span class="t">Like, I have just shown you that humans are really biased too. So why are we talking about algorithmic bias?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3275" target="_blank">00:54:35.000</a></span> | <span class="t">And people have brought this up kind of like, what's the fuss about it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3279" target="_blank">00:54:39.000</a></span> | <span class="t">And there, I think algorithmic bias is very significant and worth talking about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3285" target="_blank">00:54:45.000</a></span> | <span class="t">And I'm going to share four reasons for that. One is that machine learning can amplify bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3290" target="_blank">00:54:50.000</a></span> | <span class="t">So it's not just encoding existing biases, but in some cases, it's making them worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3294" target="_blank">00:54:54.000</a></span> | <span class="t">And there have been a few studies on this. One I like is from Maria de Artega of CMU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3301" target="_blank">00:55:01.000</a></span> | <span class="t">And here they were, they took people's, I think, job descriptions from LinkedIn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3307" target="_blank">00:55:07.000</a></span> | <span class="t">And what they found is that imbalances ended up being compounded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3311" target="_blank">00:55:11.000</a></span> | <span class="t">And so in the group of surgeons, only 14 percent were women. However, in the true positives, so they were trying to predict the job title from the summary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3323" target="_blank">00:55:23.000</a></span> | <span class="t">Women were only 11 percent in the true positives. So this kind of imbalance has gotten worse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3329" target="_blank">00:55:29.000</a></span> | <span class="t">And basically, there's kind of this asymmetry where the, you know, the algorithm has learned it's safer for women to kind of not guess surgeon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3342" target="_blank">00:55:42.000</a></span> | <span class="t">Another, so this is one reason, another reason that algorithmic bias is a concern is that algorithms are used very differently than human decision makers in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3353" target="_blank">00:55:53.000</a></span> | <span class="t">And so people sometimes talk about them as though they are plug and play interchangeable of, you know, with humans, this bias and the algorithm is, you know, this bias.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3361" target="_blank">00:56:01.000</a></span> | <span class="t">Why don't we just substitute it in? However, the whole system around it ends up kind of being different in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3368" target="_blank">00:56:08.000</a></span> | <span class="t">One, one kind of aspect of this is people are more likely to assume algorithms are objective or error free, even if they're given the option of a human override.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3378" target="_blank">00:56:18.000</a></span> | <span class="t">And so if you give a person, you know, even if you just say, I'm just giving the judge this recommendation, they don't have to follow it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3384" target="_blank">00:56:24.000</a></span> | <span class="t">If it's coming from a computer, many people are going to take that as objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3388" target="_blank">00:56:28.000</a></span> | <span class="t">In some cases also, there may be, you know, pressure from their boss to, you know, not disagree with the computer more times, you know, nobody's going to get fired by going with the computer recommendation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3400" target="_blank">00:56:40.000</a></span> | <span class="t">Algorithms are more likely to be implemented with no appeals process in place. And so we saw that earlier when we were talking about recourse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3409" target="_blank">00:56:49.000</a></span> | <span class="t">Algorithms are often used at scale. They can be replicating an identical bias at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3414" target="_blank">00:56:54.000</a></span> | <span class="t">And algorithmic systems are cheap. And all of these, I think, are interconnected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3418" target="_blank">00:56:58.000</a></span> | <span class="t">So in many cases, I think that algorithmic systems are being implemented not because they produce better outcomes for everyone, but because they're kind of a cheaper way to do things at scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3429" target="_blank">00:57:09.000</a></span> | <span class="t">You know, offering a recourse process is more expensive, being on the lookout for errors is more expensive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3435" target="_blank">00:57:15.000</a></span> | <span class="t">So this is kind of cost cutting measures. And Cathy O'Neill talks about many of these themes in her book, Weapons of Math Destruction, kind of under the idea that the privileged are processed by people, the poor are processed by algorithms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3447" target="_blank">00:57:27.000</a></span> | <span class="t">There's a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3449" target="_blank">00:57:29.000</a></span> | <span class="t">Two questions. This seems like an intensely deep topic, needing specialized expertise to avoid getting it wrong. If you were building an ML product, would you approach an academic institution for consultation on this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3462" target="_blank">00:57:42.000</a></span> | <span class="t">Do you see a data product development triad becoming maybe a quartet involving an ethics or data privacy expert?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3472" target="_blank">00:57:52.000</a></span> | <span class="t">So I think interdisciplinary work is very important. I would definitely focus on trying to find kind of domain experts on whatever your particular domain is who understand the intricacies of that domain is important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3488" target="_blank">00:58:08.000</a></span> | <span class="t">And I think with the academic it depends. You do want to make sure you get someone who's kind of applied enough to kind of understand how things are happening in industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3499" target="_blank">00:58:19.000</a></span> | <span class="t">But I think involving more people and people from more fields is a good approach on the whole.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3506" target="_blank">00:58:26.000</a></span> | <span class="t">Someone invents and publishes a better ML technique, like attention or transformers. And then next a graduate student demonstrates using it to improve facial recognition by 5%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3515" target="_blank">00:58:35.000</a></span> | <span class="t">And then a small startup publishes an app that does better facial recognition. And then a government uses the app to study downtown walking patterns and endangered species and after these successes for court audit monitoring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3525" target="_blank">00:58:45.000</a></span> | <span class="t">And then a repressive government then takes that method to identify ethnicities and then you get a genocide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3531" target="_blank">00:58:51.000</a></span> | <span class="t">No one's made a huge ethical error at any incremental step, yet the result is horrific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3536" target="_blank">00:58:56.000</a></span> | <span class="t">I have no doubt that Amazon will soon serve up a personally customized price for each item that maximizes their profits.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3542" target="_blank">00:59:02.000</a></span> | <span class="t">How can such ethical creep be addressed where the effect is remote from many small causes?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3552" target="_blank">00:59:12.000</a></span> | <span class="t">So yeah, so that that's a kind of a great summary of how these things can happen somewhat incrementally. I'll talk about some tools to implement kind of towards the end of this lesson that hopefully can help us.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3565" target="_blank">00:59:25.000</a></span> | <span class="t">So some of it is I think we do need to get better at kind of trying to think a few more steps ahead than we have been.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3571" target="_blank">00:59:31.000</a></span> | <span class="t">You know, in particular, we've seen examples of people, you know, there was the study of how to identify protesters in a crowd, even when they had scarves or sunglasses or hats on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3581" target="_blank">00:59:41.000</a></span> | <span class="t">You know, and when the researchers on that were questioned, they were like, oh, it never even occurred to us that bad guys would use this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3587" target="_blank">00:59:47.000</a></span> | <span class="t">You know, we just thought it would be for finding bad people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3591" target="_blank">00:59:51.000</a></span> | <span class="t">And so I do think kind of everyone should be building their ability to think a few more steps ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3599" target="_blank">00:59:59.000</a></span> | <span class="t">And part of this is like it's great to do this in teams, preferably in diverse teams can help with that process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3606" target="_blank">01:00:06.000</a></span> | <span class="t">Even on this question of computer vision, there has been, you know, just in the last few months, is it Joe Redmond, creator of YOLO, who has said that he's no longer working on computer vision just because he thinks the misuses so far outweigh the positives?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3624" target="_blank">01:00:24.000</a></span> | <span class="t">And Timnit Gebru said she's considering that as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3628" target="_blank">01:00:28.000</a></span> | <span class="t">So I think there are times where you have to consider.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3633" target="_blank">01:00:33.000</a></span> | <span class="t">And then I think also really actively thinking about how to what safeguards do we need to put in place to kind of address the the misuses that are happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3641" target="_blank">01:00:41.000</a></span> | <span class="t">Yes. I just wanted to say somebody really liked the Kathy O'Neill quote, privileged, processed by people, the poor, processed by algorithms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3649" target="_blank">01:00:49.000</a></span> | <span class="t">And they're looking forward to learning more, reading more from Kathy O'Neill. Is that a book that you recommend?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3654" target="_blank">01:00:54.000</a></span> | <span class="t">Yes. Yeah. And Kathy O'Neill also writes and Kathy O'Neill is a fellow, fellow math PhD, but she also has written a number of good articles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3666" target="_blank">01:01:06.000</a></span> | <span class="t">And the book kind of goes through a number of case studies of how algorithms are being used in different places.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3677" target="_blank">01:01:17.000</a></span> | <span class="t">So kind of in summary of humans are biased. Why do why are we making a fuss about algorithmic bias?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3685" target="_blank">01:01:25.000</a></span> | <span class="t">So one, as we saw earlier, machine learning can create food back loops.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3688" target="_blank">01:01:28.000</a></span> | <span class="t">So it's you know, it's not just kind of observing what's happening in the world, but it's also determining outcomes and it's kind of determining what future data is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3696" target="_blank">01:01:36.000</a></span> | <span class="t">Machine learning can amplify bias. Algorithms in humans are used very differently in practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3702" target="_blank">01:01:42.000</a></span> | <span class="t">And I will also say technology is power. And with that comes responsibility. And I think for all of us to have access to deep learning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3709" target="_blank">01:01:49.000</a></span> | <span class="t">we are still in a kind of very fortunate and small percentage of the world that is able to use this technology right now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3716" target="_blank">01:01:56.000</a></span> | <span class="t">And I hope I hope we will all use it responsibly and really take our power seriously.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3723" target="_blank">01:02:03.000</a></span> | <span class="t">And I just I just noticed the time and I think we're about to start next section on analyzing or kind of steps, steps we can take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3734" target="_blank">01:02:14.000</a></span> | <span class="t">So this would be a good a good place to take a break. So let's meet back in seven minutes at 7 45.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3744" target="_blank">01:02:24.000</a></span> | <span class="t">All right, let's start back up. And actually, I was at a slightly different place than I thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3751" target="_blank">01:02:31.000</a></span> | <span class="t">But just a few questions that you can ask about projects you're working on, and I hope you will ask about projects you're working on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3760" target="_blank">01:02:40.000</a></span> | <span class="t">The first is should we should we even be doing this and considering that maybe there's some work that we shouldn't do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3768" target="_blank">01:02:48.000</a></span> | <span class="t">There's a paper when the implication is not to design technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3773" target="_blank">01:02:53.000</a></span> | <span class="t">As engineers, we often tend to respond to problems with, you know, what can I make or build to to address this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3779" target="_blank">01:02:59.000</a></span> | <span class="t">But sometimes the answer is to not make or build anything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3784" target="_blank">01:03:04.000</a></span> | <span class="t">One example of research that I think has a huge amount of downside and really no upside I see was kind of to identify the ethnicity,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3794" target="_blank">01:03:14.000</a></span> | <span class="t">particularly for people of ethnic minorities. And so there was work done identifying the Chinese Uyghurs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3800" target="_blank">01:03:20.000</a></span> | <span class="t">which is the Muslim minority in Western China, which is since, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3804" target="_blank">01:03:24.000</a></span> | <span class="t">over a million people have been placed in internment camps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3807" target="_blank">01:03:27.000</a></span> | <span class="t">And so I think this is a very, very harmful, harmful line of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3813" target="_blank">01:03:33.000</a></span> | <span class="t">I think that the, you know, there have been at least two attempts of building,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3819" target="_blank">01:03:39.000</a></span> | <span class="t">building a classifier to try to identify someone's sexuality, which is it's probably just picking up on kind of stylistic differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3829" target="_blank">01:03:49.000</a></span> | <span class="t">But this is something that could also be quite, quite dangerous as in many countries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3833" target="_blank">01:03:53.000</a></span> | <span class="t">It's illegal to be gay. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3837" target="_blank">01:03:57.000</a></span> | <span class="t">So this is a question for me, which I don't know the answer to.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3842" target="_blank">01:04:02.000</a></span> | <span class="t">As that title says, a Stanford scientist says he built the gay dot using the lamest A.I. possible to prove a point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3849" target="_blank">01:04:09.000</a></span> | <span class="t">And my understanding is that point was to say, you know, I guess it's something like, hey, you could use fast A.I. lesson one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3857" target="_blank">01:04:17.000</a></span> | <span class="t">After an hour or two, you can build this thing. Anybody can do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3861" target="_blank">01:04:21.000</a></span> | <span class="t">You know, how do you feel about this idea that there's a role to demonstrate what's readily available with the technology we have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3869" target="_blank">01:04:29.000</a></span> | <span class="t">Yeah, I mean, that's the thing that I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3873" target="_blank">01:04:33.000</a></span> | <span class="t">So I appreciate that. And I'll talk about this a little bit later. Open A.I. with GPT to, I think, was trying to raise raise a debate around around dual use and what is responsible release of of dual use technology and what's a kind of responsible way to to raise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3894" target="_blank">01:04:54.000</a></span> | <span class="t">raise awareness of what is possible in the in the cases of researchers that have done this on the sexuality question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3902" target="_blank">01:05:02.000</a></span> | <span class="t">To me, it hasn't seemed like they've put adequate thought into how they're conducting that and who they're collaborating with to ensure that it is something that is leading to kind of helping address the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3919" target="_blank">01:05:19.000</a></span> | <span class="t">But I think you're right that I think there is probably some place for letting people know what is probably widely available now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3926" target="_blank">01:05:26.000</a></span> | <span class="t">Yeah, it reminds me a bit of like pen testing and info set where it's kind of considered it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3933" target="_blank">01:05:33.000</a></span> | <span class="t">Well, there's an ethical way that you can go about pointing out that it's trivially easy to break into some of the system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3939" target="_blank">01:05:39.000</a></span> | <span class="t">Yes, yeah, I would I would agree with that that there there is an ethical way, but I think that's something that we as a community still have more work to do and even determining what that is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3951" target="_blank">01:05:51.000</a></span> | <span class="t">Other questions to consider are what biases in the data and something I should highlight is people often ask me, you know, how can I do bias my data or ensure that it's bias free and that's not possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3964" target="_blank">01:06:04.000</a></span> | <span class="t">All data contains bias and the kind of most most important thing is just to understand kind of how your data set was created and what its limitations are so that you're not blindsided by that bias, but you're never going to fully remove it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3977" target="_blank">01:06:17.000</a></span> | <span class="t">And some of the I think most promising approaches in this area are work like Timnit Gebru's data sheets for data sets, which is kind of going through and asking kind of a bunch of questions about how your data set was created and for what purposes and how it's being maintained.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=3994" target="_blank">01:06:34.000</a></span> | <span class="t">And you know, what are the risk in that just to to really kind of be aware of of the context of your data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4002" target="_blank">01:06:42.000</a></span> | <span class="t">Can the code and data be audited? I think particularly in the United States, we have a lot of issues with when private companies are creating software that's really impacting people through the criminal justice system or hiring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4016" target="_blank">01:06:56.000</a></span> | <span class="t">And when these things are, you know, kind of their proprietary black boxes that are protected in court, this creates a lot of kind of issues of, you know, what are what are our rights around that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4027" target="_blank">01:07:07.000</a></span> | <span class="t">Looking at error rates for different subgroups is really important, and that's what's kind of so powerful about Joy Balamwini's work. If she had just looked at light skin versus dark skin and men versus women, she wouldn't have identified just how poorly the algorithms were doing on dark-skinned women.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4047" target="_blank">01:07:27.000</a></span> | <span class="t">What is the accuracy of a simple rule-based alternative? And this is something I think Jeremy talked about last week, which is just kind of good, good machine learning practice to have a baseline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4057" target="_blank">01:07:37.000</a></span> | <span class="t">But particularly in cases like the compass recidivism, where this 130 variable black box is not doing much better than a linear classifier on three variables, that raises kind of a question of why are we using this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4072" target="_blank">01:07:52.000</a></span> | <span class="t">And then what processes are in place to handle appeals or mistakes, because there will be errors in the data, there may be bugs in the implementation, and we need to have a process for recourse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4084" target="_blank">01:08:04.000</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4085" target="_blank">01:08:05.000</a></span> | <span class="t">Can you explain, this is for me now, sorry I'm asking my own questions, nobody voted them up at all. What's the thinking behind this idea that a simpler model, is this, you're kind of saying a simpler model of other things being the same, you should pick the simpler one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4101" target="_blank">01:08:21.000</a></span> | <span class="t">Is that what this baseline's for? And if so, what's the kind of thinking behind that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4106" target="_blank">01:08:26.000</a></span> | <span class="t">Well, I guess with the compass recidivism algorithm, some of this for me is linked to the proprietary black box nature and so you're right if maybe if we had a way to introspect and what were our rights around appealing something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4122" target="_blank">01:08:42.000</a></span> | <span class="t">But I would say yeah, like why use the more complex thing if the simpler one works the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4130" target="_blank">01:08:50.000</a></span> | <span class="t">And then how diverse is the team that built it and I'll talk more about team diversity later in this lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4139" target="_blank">01:08:59.000</a></span> | <span class="t">It says Jeremy at the start, but I'm not the teacher so it actually says Jeremy, do you think transfer learning makes this tougher, auditing the data that led to the initial model? I assume they mean Jeremy please ask Rachel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4152" target="_blank">01:09:12.000</a></span> | <span class="t">No, they were asking you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4156" target="_blank">01:09:16.000</a></span> | <span class="t">That's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4161" target="_blank">01:09:21.000</a></span> | <span class="t">Again, I think it's important. I would say I think it's important to have information probably on both data sets, what the initial data set used was and what the data set you use to fine tune it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4174" target="_blank">01:09:34.000</a></span> | <span class="t">Do you have thoughts on that? What she said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4180" target="_blank">01:09:40.000</a></span> | <span class="t">And then I'll say so while bias and fairness as well as accountability and transparency are important, they aren't everything.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4188" target="_blank">01:09:48.000</a></span> | <span class="t">And so there's this great paper, a mulching proposal by Oskis et al. And here they talk about a system for turning the elderly into high nutrient slurry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4200" target="_blank">01:10:00.000</a></span> | <span class="t">So this is something that's clearly unethical, but they propose a way to do it that is fair and accountable and transparent and meets these qualifications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4209" target="_blank">01:10:09.000</a></span> | <span class="t">And so that kind of shows some of the limitations of this framework as well as kind of being a good technique for kind of inspecting whatever framework you are using of trying to find something that's clearly unethical that could meet the standards you've put forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4229" target="_blank">01:10:29.000</a></span> | <span class="t">That technique, I really like it. It's my favorite technique from philosophy. It's this idea that you say, OK, given this premise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4240" target="_blank">01:10:40.000</a></span> | <span class="t">here's what it implies. And then you try and find an implied result, which intuitively is clearly insane.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4249" target="_blank">01:10:49.000</a></span> | <span class="t">So really, it's the number one philosophical thinking tool I got out of university, and sometimes you can have a lot of fun with it like this time too.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4259" target="_blank">01:10:59.000</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4263" target="_blank">01:11:03.000</a></span> | <span class="t">All right. So the next kind of big case study or topic I want to discuss is disinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4270" target="_blank">01:11:10.000</a></span> | <span class="t">So in 2016 in Houston, a group called Heart of Texas posted about a protest outside an Islamic center.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4283" target="_blank">01:11:23.000</a></span> | <span class="t">And they told people to come armed. Another Facebook group posted about a counterprotest to show up supporting freedom of religion and inclusivity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4295" target="_blank">01:11:35.000</a></span> | <span class="t">And so there were kind of a lot of people present at this and more people on the side supporting freedom of religion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4304" target="_blank">01:11:44.000</a></span> | <span class="t">And a reporter, though, for the Houston Chronicle noticed something odd, which he was not able to get in touch with the organizers for either side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4311" target="_blank">01:11:51.000</a></span> | <span class="t">And it came out many months later that both sides had been organized by Russian trolls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4317" target="_blank">01:11:57.000</a></span> | <span class="t">And so this is something where you had the people protesting were genuine Americans kind of protesting their beliefs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4326" target="_blank">01:12:06.000</a></span> | <span class="t">but they were doing it in this way that had been kind of completely framed very disingenuously by Russian operatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4338" target="_blank">01:12:18.000</a></span> | <span class="t">And so when thinking about disinformation, it is not people often think about so-called fake news and inspecting like a single post is this is this true or false.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4350" target="_blank">01:12:30.000</a></span> | <span class="t">But really, disinformation is often about orchestrated campaigns of manipulation and that it involves can evolve seeds of truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4361" target="_blank">01:12:41.000</a></span> | <span class="t">Kind of the best propaganda always involves kernels of truth, at least. It also involves kind of misleading context and can involve very kind of sincere, sincere people that get swept up in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4377" target="_blank">01:12:57.000</a></span> | <span class="t">A report came out this fall, an investigation from Stanford's Internet Observatory, where Renee DiResta and Alex Stamos work of Russia's kind of most recent disinformation or most recently identified disinformation campaign.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4394" target="_blank">01:13:14.000</a></span> | <span class="t">And it was operating in six different countries in Africa. It often purported to be local news sources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4402" target="_blank">01:13:22.000</a></span> | <span class="t">So it was a multi-platform. They were encouraging people to join their WhatsApp and Telegram groups and they were hiring local people as reporters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4410" target="_blank">01:13:30.000</a></span> | <span class="t">And a lot of the content was not necessarily disinformation. It was stuff on culture and sports and local weather.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4419" target="_blank">01:13:39.000</a></span> | <span class="t">I mean, there was a lot of kind of very pro-Russia coverage, but that it covered a range of topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4426" target="_blank">01:13:46.000</a></span> | <span class="t">It's kind of a very sophisticated phase of disinformation. And in many cases, it was hiring, hiring locals kind of as reporters to work for these sites.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4438" target="_blank">01:13:58.000</a></span> | <span class="t">And I should say, well, I've just given two examples of Russia. Russia certainly does not have a monopoly on disinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4443" target="_blank">01:14:03.000</a></span> | <span class="t">There are plenty of plenty of people involved in producing it kind of on a topical topical issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4454" target="_blank">01:14:14.000</a></span> | <span class="t">There's been a lot of disinformation around around coronavirus and Covid-19.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4461" target="_blank">01:14:21.000</a></span> | <span class="t">I in terms of kind of a personal level, if you're looking for advice on spotting disinformation or to share with loved ones about this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4470" target="_blank">01:14:30.000</a></span> | <span class="t">Mike Caulfield is a great person to follow and he's even so he tweets at Holden and then he has started an infodemic blog specifically about the about Covid-19.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4481" target="_blank">01:14:41.000</a></span> | <span class="t">But he talks about his approach and how people have been trained in schools for 12 years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4487" target="_blank">01:14:47.000</a></span> | <span class="t">Here's a text. Read it. Use your critical thinking skills to figure out what you think about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4492" target="_blank">01:14:52.000</a></span> | <span class="t">But professional fact checkers do the opposite.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4494" target="_blank">01:14:54.000</a></span> | <span class="t">They get to a page and they immediately get off of it and look for kind of higher, higher quality sources to see if they can find confirmation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4502" target="_blank">01:15:02.000</a></span> | <span class="t">Caulfield also really promotes the idea of a lot of critical thinking techniques that have been taught take a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4510" target="_blank">01:15:10.000</a></span> | <span class="t">And, you know, we're not going to spend 30 minutes evaluating each tweet that we see in our Twitter stream.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4515" target="_blank">01:15:15.000</a></span> | <span class="t">It's better to give people an approach that they can do in 30 seconds that, you know, it's not going to be fail proof if you're just doing something for 30 seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4522" target="_blank">01:15:22.000</a></span> | <span class="t">But it's better to to check than to have something that takes 30 minutes that you're just not going to do at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4528" target="_blank">01:15:28.000</a></span> | <span class="t">So I wanted to kind of put this out there as a resource and he has a whole kind of set of lessons at lessons.checkplease.cc and he's he's a professor.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4539" target="_blank">01:15:39.000</a></span> | <span class="t">And I in the data ethics course I'm teaching right now, I made my first lesson, the first half of which is kind of specifically about coronavirus disinformation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4550" target="_blank">01:15:50.000</a></span> | <span class="t">I've made that available on YouTube.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4552" target="_blank">01:15:52.000</a></span> | <span class="t">I've already shared it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4553" target="_blank">01:15:53.000</a></span> | <span class="t">And so I'll add a link on the forums if you want if you want a lot more detail on on disinformation than just kind of this short bit here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4563" target="_blank">01:16:03.000</a></span> | <span class="t">But so going back to kind of like what is disinformation, it's important to think of it as an ecosystem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4569" target="_blank">01:16:09.000</a></span> | <span class="t">Again, it's not just a single poster, a single news story that has, you know, is misleading or has false elements in it, but it's this really this broader ecosystem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4580" target="_blank">01:16:20.000</a></span> | <span class="t">Claire Wardle, First Draft News, who is a leading expert on this and does a lot around kind of training journalists and how journalists can report responsibly, talks about the trumpet of amplification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4591" target="_blank">01:16:31.000</a></span> | <span class="t">And this is where rumors or memes or things can start on 4chan and 8chan and then move to closed messaging groups such as WhatsApp, Telegram, Facebook Messenger from there to community conspiracy communities on Reddit or YouTube, then to kind of more mainstream social media and then picked up by the professional media and politicians.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4614" target="_blank">01:16:54.000</a></span> | <span class="t">And so this can make it very hard to address that it is this kind of multi platform. In many cases, campaigns may be utilizing kind of the differing rules or loopholes between between the different platforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4627" target="_blank">01:17:07.000</a></span> | <span class="t">And I think we certainly are seeing more and more examples where it doesn't have to go through all these steps, but can can can jump jump forward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4636" target="_blank">01:17:16.000</a></span> | <span class="t">And online discussion is very, very significant because people, it helps us form our opinions. And this is tough because I think most of us think of ourselves as pretty independent minded.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4649" target="_blank">01:17:29.000</a></span> | <span class="t">But discussion really does, you know, we evolved as kind of social beings and to be influenced by people in our in group and in opposition to people in our out group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4658" target="_blank">01:17:38.000</a></span> | <span class="t">And so online discussion impacts us. People discuss all sorts of things online. Here's a Reddit discussion about whether the US should cut defense spending.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4668" target="_blank">01:17:48.000</a></span> | <span class="t">You have comments, you're wrong. The defense budget is a good example of how badly the US spends money on the military.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4675" target="_blank">01:17:55.000</a></span> | <span class="t">Someone else says, yeah, but that's already happening. There's a huge increase in the military budget. The Pentagon budget's already increasing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4682" target="_blank">01:18:02.000</a></span> | <span class="t">I didn't mean to sound like stop paying for the military. I'm not saying that we cannot pay the bills, but I think it would make sense to cut defense spending.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4692" target="_blank">01:18:12.000</a></span> | <span class="t">Does anyone want to guess what subreddit this is from?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4704" target="_blank">01:18:24.000</a></span> | <span class="t">Unpopular opinion, news, change my view, net neutrality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4712" target="_blank">01:18:32.000</a></span> | <span class="t">Those are good guesses, but they're wrong. I love the way you say no.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4716" target="_blank">01:18:36.000</a></span> | <span class="t">This is all from, well, it's from the sub simulator GPT-2. So these comments were all written by GPT-2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4725" target="_blank">01:18:45.000</a></span> | <span class="t">And this is in good fun. It was clearly labeled on the subreddit that it's coming in. GPT-2 is a language model from open AI that was kind of in a trajectory of research that many, many groups were on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4743" target="_blank">01:19:03.000</a></span> | <span class="t">And so it was released, I guess, about a year ago and.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4750" target="_blank">01:19:10.000</a></span> | <span class="t">Should I read the unicorn story, Jeremy? OK, so many of you have probably have probably seen this. So here and this this was cherry picked, but this is still very, very impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4761" target="_blank">01:19:21.000</a></span> | <span class="t">So a human written prompt was given to the language model in a shocking finding. Scientists discovered a herd of unicorns living in a remote previously unexplored valley in the Andes Mountains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4772" target="_blank">01:19:32.000</a></span> | <span class="t">Even more surprising to the researchers was the fact that the unicorn spoke perfect English. And then the next part is all generated by the language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4782" target="_blank">01:19:42.000</a></span> | <span class="t">So this is a deep learning model that produced this and the computer model generated. Dr. Jorge Perez had what appeared to be a natural fountain surrounded by two peaks of rock and silver snow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4795" target="_blank">01:19:55.000</a></span> | <span class="t">Perez and the others then ventured further into the valley. By the time we reached the top of one peak, the water looked blue with some crystals on tops at Perez.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4804" target="_blank">01:20:04.000</a></span> | <span class="t">Perez and his friends were astonished to see the unicorn herd. These creatures could be seen from the air without having to move too much to see them. They were so close they could touch their horns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4815" target="_blank">01:20:15.000</a></span> | <span class="t">While examining these bizarre creatures, the scientists discovered that the creatures also spoke some fairly regular English. Perez stated we can see, for example, that they have a common language, something like a dialect or dialectic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4827" target="_blank">01:20:27.000</a></span> | <span class="t">And so I think this is really compelling prose to have been have been generated by a computer in this form.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4838" target="_blank">01:20:38.000</a></span> | <span class="t">So we've also seen advances in computers generating pictures, specifically GANs. So Katie Jones was listed on LinkedIn as a Russia and Eurasia fellow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4851" target="_blank">01:20:51.000</a></span> | <span class="t">She was connected to several people from mainstream Washington think tanks and the Associated Press discovered that she is not a real person. This photo was generated by a GAN.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4865" target="_blank">01:21:05.000</a></span> | <span class="t">And so this, I think, gets kind of scary when we start thinking about how how compelling the text that's being generated is and combining that with pictures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4875" target="_blank">01:21:15.000</a></span> | <span class="t">These photos are all from this person does not exist dot com generated by GANs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4882" target="_blank">01:21:22.000</a></span> | <span class="t">And there's a very, very real and imminent risk that online discussion will be swamped with fake manipulative agents to an even greater extent than it than it already has, and that this this can be used to influence public opinion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4899" target="_blank">01:21:39.000</a></span> | <span class="t">So actually, I guess, well, I'll keep going. I'm going back in time to twenty seventeen. The FCC was considering repealing net neutrality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4911" target="_blank">01:21:51.000</a></span> | <span class="t">And so they opened up for comments to see, you know, how do Americans feel about net neutrality?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4916" target="_blank">01:21:56.000</a></span> | <span class="t">And this is a sample of many of the comments that were opposed to net neutrality. They wanted to repeal it and included.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4924" target="_blank">01:22:04.000</a></span> | <span class="t">I'll just read a few clips. Americans, as opposed to Washington bureaucrats, deserve to enjoy the services they desire.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4932" target="_blank">01:22:12.000</a></span> | <span class="t">Individual citizens, as opposed to Washington bureaucrats, should be able to select whichever services they desire.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4938" target="_blank">01:22:18.000</a></span> | <span class="t">People like me, as opposed to so-called experts, should be free to buy whatever products they choose.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4943" target="_blank">01:22:23.000</a></span> | <span class="t">And these have been helpfully color coded. So you can kind of see a pattern that this was a bit of a mad libs where you had a few choices for green for the first noun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4955" target="_blank">01:22:35.000</a></span> | <span class="t">And then in orange or red, I guess it's as opposed to or rather than orange, we've got either Washington bureaucrats, so-called experts, the FCC and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4969" target="_blank">01:22:49.000</a></span> | <span class="t">And this analysis was done by Jeff Kao, who's now a computational journalist at ProPublica doing great work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4978" target="_blank">01:22:58.000</a></span> | <span class="t">And he did this analysis discovering this campaign in which these comments were designed to look unique but had been created kind of through some mail merge style, kind of putting together a mad libs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=4995" target="_blank">01:23:15.000</a></span> | <span class="t">Yes. So this was great work by Jeff. He found that while they received this, the FCC received over 22 million comments, less than 4% of them were truly unique.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5012" target="_blank">01:23:32.000</a></span> | <span class="t">And this is not all malicious activity. You know, there are many kind of ways where you get a template to contact your legislator about something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5021" target="_blank">01:23:41.000</a></span> | <span class="t">But, you know, in the example kind of shown previously, these were designed to look like they were unique when they weren't.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5028" target="_blank">01:23:48.000</a></span> | <span class="t">And more than 99% of the truly unique comments wanted to keep net neutrality. However, that was not the case if you looked at the full 22 million comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5040" target="_blank">01:24:00.000</a></span> | <span class="t">However, this was in 2017, which may not sound that long ago, but in the field of natural language processing, we've had like an entire kind of a revolution since then.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5051" target="_blank">01:24:11.000</a></span> | <span class="t">There's just been so much progress made. And this would be, I think, virtually impossible to catch today if someone was using a sophisticated language model to generate comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5063" target="_blank">01:24:23.000</a></span> | <span class="t">So Jess asks a question, which I'm going to treat it as a two-part question, even if it's not necessarily. What happens when there's so much AI trolling that most of what gets draped from the web is AI generated text?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5076" target="_blank">01:24:36.000</a></span> | <span class="t">And then the second part. And then what happens when you use that to generate more AI generated text?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5081" target="_blank">01:24:41.000</a></span> | <span class="t">Yeah, so for the first part, yeah, this is a real risk, or not risk, but kind of challenge we're facing of real humans can get drowned out when so much text is going to be AI trolling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5097" target="_blank">01:24:57.000</a></span> | <span class="t">And we're already seeing, and I, in the interest of time, I can talk about disinformation for hours and I had to cut a lot of stuff out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5106" target="_blank">01:25:06.000</a></span> | <span class="t">But many people have talked about how kind of the new form of censorship is about drowning people out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5114" target="_blank">01:25:14.000</a></span> | <span class="t">And so it's not necessarily kind of forbidding someone from saying something, but just totally, totally just drowning them out with a massive quantity of text and information and comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5127" target="_blank">01:25:27.000</a></span> | <span class="t">And AI can really facilitate that. And so I do not have a good solution to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5133" target="_blank">01:25:33.000</a></span> | <span class="t">In terms of AI learning from AI text, I mean, I think you're going to get systems that are potentially kind of less and less relevant to humans and may have harmful effects if they're kind of being used to create software that is interacting with or impacting humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5155" target="_blank">01:25:55.000</a></span> | <span class="t">So that's a concern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5159" target="_blank">01:25:59.000</a></span> | <span class="t">I mean, one of the things I find fascinating about this is we could get to a point where 99.99% of tweets and fast AI forum posts, whatever, are auto generated, particularly on kind of more like political type places where a lot of it's pretty low content, pretty basic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5180" target="_blank">01:26:20.000</a></span> | <span class="t">And the thing is, like, if it was actually good, you wouldn't even know. So what if I told you that 75% of the people you're talking to on the forum right now are actually bots?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5191" target="_blank">01:26:31.000</a></span> | <span class="t">How can you tell which ones they are? How would you prove whether I'm right or wrong?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5196" target="_blank">01:26:36.000</a></span> | <span class="t">Yeah, I think this is a real issue on Twitter of particularly people you don't know of wondering, like, is this an actual person or a bot? I think it's a common question people wonder about and can be hard to tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5215" target="_blank">01:26:55.000</a></span> | <span class="t">But I think it has significance for has a lot of significance for kind of how human government works. You know, I think there's something about humans being in society and having norms and rules and mechanisms that this can really undermine and make difficult.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5242" target="_blank">01:27:22.000</a></span> | <span class="t">And so when when GPT two came out, Jeremy Howard, co founder of fast AI was quoted in the Verge article on it. I've been trying to warn people about this for a while.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5255" target="_blank">01:27:35.000</a></span> | <span class="t">We have the technology to totally fill Twitter email and the web up with reasonable sounding context appropriate pros, which would drown out all other speech and be impossible to filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5269" target="_blank">01:27:49.000</a></span> | <span class="t">So one kind of step towards addressing this is the need for digital signatures. Orin Etziani, the head of the Allen Institute on AI, wrote about this in HBR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5285" target="_blank">01:28:05.000</a></span> | <span class="t">He wrote recent developments in AI point to an age where forgery of documents, pictures, audio recordings, videos and online identities will occur with unprecedented ease.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5295" target="_blank">01:28:15.000</a></span> | <span class="t">AI is poised to make high fidelity forgery inexpensive and automated, leading to potentially disastrous consequences for democracy, security and society and proposes kind of digital signatures as a means for authentication.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5311" target="_blank">01:28:31.000</a></span> | <span class="t">And I will say here, kind of one of the one of the additional risk of kind of all this forgery and fakes is that it also undermines people speaking the truth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5323" target="_blank">01:28:43.000</a></span> | <span class="t">And Zeynep Tefekci, who does a lot of research on protests around the world and in different social movements, has said that she's often approached by kind of whistleblowers and dissidents who in many cases will risk their lives to try to publicize like a wrongdoing or human rights violation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5343" target="_blank">01:29:03.000</a></span> | <span class="t">only to have kind of bad actors say, "Oh, that picture was photoshopped. That was faked." And that it's kind of now this big issue for whistleblowers and dissidents of how can they verify what they are saying and that kind of that need for verification.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5361" target="_blank">01:29:21.000</a></span> | <span class="t">And then someone you should definitely be following on this topic is Renee DiResta.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5367" target="_blank">01:29:27.000</a></span> | <span class="t">And she wrote a great article with Mike Godwin last year framing that we really need to think disinformation as a cyber security problem, you know, as these kind of coordinated campaigns of manipulation and bad actors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5381" target="_blank">01:29:41.000</a></span> | <span class="t">And there's, I think, some important work happening at Stanford as well on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5390" target="_blank">01:29:50.000</a></span> | <span class="t">All right. Questions on disinformation? Okay, so next step, ethical foundations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5399" target="_blank">01:29:59.000</a></span> | <span class="t">So now, so the fast AI approach, we always like to kind of ground everything in what are the real world case studies before we get to kind of the theory underpinning it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5408" target="_blank">01:30:08.000</a></span> | <span class="t">And I'm not going to go too deep on this at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5412" target="_blank">01:30:12.000</a></span> | <span class="t">So there is a fun article, "What Would an Avenger Do?" and a hat tip to Casey Fiesler for suggesting this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5421" target="_blank">01:30:21.000</a></span> | <span class="t">And it goes through kind of three common ethical philosophies, utilitarianism, and gives the example of Iron Man, trying to maximize good, deontological ethics of Captain America being an example of this, adhering to the right,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5439" target="_blank">01:30:39.000</a></span> | <span class="t">and then virtue ethics, Thor, living by a code of honor. And so I thought that was a nice reading. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5450" target="_blank">01:30:50.000</a></span> | <span class="t">"Where do you stand on the argument that social media companies are just neutral platforms and that problematic content is the entire responsibility of the users, just the same way that phone companies aren't held responsible when phones are used for scams or car companies are held responsible when vehicles are used for, say, terrorist attacks?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5470" target="_blank">01:31:10.000</a></span> | <span class="t">So I do not think that the platforms are neutral because they make a number of design decisions and enforcement decisions around even kind of what their terms of service are and how those are enforced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5487" target="_blank">01:31:27.000</a></span> | <span class="t">And that in keeping in mind, harassment can drive many people off of platforms. And so kind of many of those decisions is not that, oh, everybody gets to keep free speech when there's no enforcement, it's just changing kind of who is silenced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5508" target="_blank">01:31:48.000</a></span> | <span class="t">I do think that there are a lot of really difficult questions that are raised about this because I also think that the platforms, you know, they are not publishers, but they are in this, I think, kind of an intermediate area where they're performing many of the functions that publishers used to perform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5533" target="_blank">01:32:13.000</a></span> | <span class="t">So, you know, like a newspaper, which is curating which articles are in it, which is not what platforms are doing, but they are getting closer to that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5546" target="_blank">01:32:26.000</a></span> | <span class="t">I mean, something I come back to is it is an uncomfortable amount of power for private companies to have. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5555" target="_blank">01:32:35.000</a></span> | <span class="t">And so it does raise a lot of difficult decisions, but I do not believe that they are neutral.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5562" target="_blank">01:32:42.000</a></span> | <span class="t">So for this part, I mentioned the Marcula Center earlier. Definitely check out their site, Ethics and Technology Practice. They have a lot of useful resources.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5574" target="_blank">01:32:54.000</a></span> | <span class="t">And I'm going to go through these relatively quickly as just kind of examples. So they give some kind of deontological questions that technologists could ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5582" target="_blank">01:33:02.000</a></span> | <span class="t">And so deontological ethics are where you kind of have various kind of rights or duties that you might want to respect.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5592" target="_blank">01:33:12.000</a></span> | <span class="t">And this can include principles like privacy or autonomy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5600" target="_blank">01:33:20.000</a></span> | <span class="t">How might the dignity and autonomy of each stakeholder be impacted by this project?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5605" target="_blank">01:33:25.000</a></span> | <span class="t">What considerations of trust and of justice are relevant? Does this project involve any conflicting moral duties to others?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5614" target="_blank">01:33:34.000</a></span> | <span class="t">In some cases, you know, there'll be kind of conflict between different rights or duties you're considering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5621" target="_blank">01:33:41.000</a></span> | <span class="t">And so this is kind of an example, and they have more in the reading of the types of questions you could be asking kind of when evaluating of just even how do you evaluate kind of whether a project is ethical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5634" target="_blank">01:33:54.000</a></span> | <span class="t">Consequentialist questions. Who will be directly affected? Who will be indirectly affected?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5643" target="_blank">01:34:03.000</a></span> | <span class="t">And consequentialist includes utilitarianism as well as common good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5649" target="_blank">01:34:09.000</a></span> | <span class="t">Will the effects in aggregate create more good than harm and what types of good and harm?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5655" target="_blank">01:34:15.000</a></span> | <span class="t">Are you thinking about all the relevant types of harm and benefit, including psychological, political, environmental, moral, cognitive, emotional, institutional, cultural.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5664" target="_blank">01:34:24.000</a></span> | <span class="t">Also looking at long term benefits and harms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5668" target="_blank">01:34:28.000</a></span> | <span class="t">And then who experiences them? Is this something where the risk of the harm are going to fall disproportionately on the least powerful?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5675" target="_blank">01:34:35.000</a></span> | <span class="t">Who's going to be the ones to accrue the benefits?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5679" target="_blank">01:34:39.000</a></span> | <span class="t">Have you considered dual use? So these are these are again kind of questions you could use when trying to trying to evaluate a project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5686" target="_blank">01:34:46.000</a></span> | <span class="t">And I think in the recommendation of the Markkula Center is that this is a great activity to kind of to be doing as a team and as a group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5697" target="_blank">01:34:57.000</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5700" target="_blank">01:35:00.000</a></span> | <span class="t">I was going to say like I can't. I can't overstate how useful this tool is like you might think, oh, it's just a list of questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5710" target="_blank">01:35:10.000</a></span> | <span class="t">But like this is kind of to me, this is the this is the big gun tool for how you how you handle this is like if somebody is helping you think about the right set of questions and then you like go through them with a diverse group of people and discuss the questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5726" target="_blank">01:35:26.000</a></span> | <span class="t">I mean, that's that it's this is this is gold. Like, you know, go back and reread these and don't don't just skip over them because take take them to work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5734" target="_blank">01:35:34.000</a></span> | <span class="t">Use them next time you're talking about a project. They're a really great great set of questions to use a great tool in your toolbox.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5742" target="_blank">01:35:42.000</a></span> | <span class="t">Yeah. And go to the original reading has even kind of more detail and more elaboration on the questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5751" target="_blank">01:35:51.000</a></span> | <span class="t">And then they kind of give a summary of five potential ethical lenses, the rights approach, which option best respects the rights of all who have a stake, the justice approach, which option treats people equally or proportionally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5765" target="_blank">01:36:05.000</a></span> | <span class="t">And so these two are both deontological the utilitarian approach, which option will produce the most good and do the least harm, the common good approach, which option best serves the community as a whole, not just some members.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5779" target="_blank">01:36:19.000</a></span> | <span class="t">And so here, three and four are both consequentialist and then virtue approach, which option leads me to act as a sort of person I want to be and that can involve particular virtues of, you know, do you value trustworthiness or truth or courage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5797" target="_blank">01:36:37.000</a></span> | <span class="t">And so, I mean, a great activity if this is something that you're studying or talking about at work with your teammates, the Marcula Center has a number of case studies that you can talk through and we'll even ask you to kind of evaluate them, you know, evaluate them through these five lenses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5812" target="_blank">01:36:52.000</a></span> | <span class="t">and how does that kind of impact your your take on what the what the right thing to do is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5821" target="_blank">01:37:01.000</a></span> | <span class="t">It's kind of weird for a programmer a computer programmer data science in some ways in some ways to like think of these as tools like last day I or pandas or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5832" target="_blank">01:37:12.000</a></span> | <span class="t">But I mean, they absolutely are. This is like these like software tools for your brain, you know, to help you kind of go through a program that might help you debug your thinking.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5846" target="_blank">01:37:26.000</a></span> | <span class="t">Great, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5849" target="_blank">01:37:29.000</a></span> | <span class="t">And then as someone brought up earlier, so that was a kind of very Western centric intro to ethical philosophy. There are other ethical lenses and other cultures and I've been doing some reading, particularly on the the Maori worldview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5863" target="_blank">01:37:43.000</a></span> | <span class="t">I don't feel confident enough in my understanding that I could represent it, but it is very good to be mindful that the other other other ethical lenses out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5873" target="_blank">01:37:53.000</a></span> | <span class="t">And I do very much think that, you know, the people being impacted by a technology like their their ethical lens is kind of what matters and that this is is a particular issue when we have so many kind of a multinational corporations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5888" target="_blank">01:38:08.000</a></span> | <span class="t">And there's a interesting project going on in New Zealand now where the New Zealand government is kind of considering its AI approach and is at least ostensibly kind of wanting to wanting to include the Maori view on that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5902" target="_blank">01:38:22.000</a></span> | <span class="t">So that's a that's kind of a little a little bit of theory, but now I want to talk about some kind of practices you can implement in the workplace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5909" target="_blank">01:38:29.000</a></span> | <span class="t">Again, this is from the Markula Center. So this is their ethics toolkit, which I particularly like.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5916" target="_blank">01:38:36.000</a></span> | <span class="t">And I'm just I'm not going to go through all of them. I'm just going to tell you a few of my favorites.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5920" target="_blank">01:38:40.000</a></span> | <span class="t">So tool one is ethical risk sweeping. And this, I think, is similar to the idea of kind of pen testing that Jeremy mentioned earlier from security, but to have regularly scheduled ethical risk sweeps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5936" target="_blank">01:38:56.000</a></span> | <span class="t">And while no vulnerability, vulnerability is found is generally good news, that doesn't mean that it was a wasted effort and you keep doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5946" target="_blank">01:39:06.000</a></span> | <span class="t">Keep looking for for ethical risk one moment and then assume that you miss some risk in the initial project development.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5954" target="_blank">01:39:14.000</a></span> | <span class="t">Also, you have to set up the incentives properly where you're rewarding team members for spotting new ethical risk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5962" target="_blank">01:39:22.000</a></span> | <span class="t">So I've got some comments here. My comment here is about the learning rate finder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5967" target="_blank">01:39:27.000</a></span> | <span class="t">And I'm not going to bother with the exact mathematical definition, partly because I'm a terrible mathematician and partly because it doesn't matter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5973" target="_blank">01:39:33.000</a></span> | <span class="t">But if you just remember, oh, sorry, that's actually not me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5976" target="_blank">01:39:36.000</a></span> | <span class="t">I am just reading something that Patty Hendricks has trained a language model of me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5982" target="_blank">01:39:42.000</a></span> | <span class="t">So that was me reading the language model of me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5986" target="_blank">01:39:46.000</a></span> | <span class="t">That was great. Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=5992" target="_blank">01:39:52.000</a></span> | <span class="t">This is a tool one. I would say another kind of example of this, I think, is like red teaming of, you know, having a team within your org that's kind of trying to find your vulnerabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6003" target="_blank">01:40:03.000</a></span> | <span class="t">Tool three, another one I really like expanding the ethical circle. So whose interests, desires, skills, experiences and values have we just assumed rather than actually consulted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6016" target="_blank">01:40:16.000</a></span> | <span class="t">Who are all the stakeholders who will be directly affected and have we actually asked them what their interests are?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6025" target="_blank">01:40:25.000</a></span> | <span class="t">Who might use this product that we didn't expect to use it or for purposes that we didn't initially intend?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6031" target="_blank">01:40:31.000</a></span> | <span class="t">And so then a great implementation of this comes from the University of Washington's tech policy lab did a project called Diverse Voices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6044" target="_blank">01:40:44.000</a></span> | <span class="t">And it's neat. They have both a academic paper on it and then they also kind of have like a guide, lengthy guide on how you would implement this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6053" target="_blank">01:40:53.000</a></span> | <span class="t">But the idea is how to kind of organize expert panels around new technology.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6062" target="_blank">01:41:02.000</a></span> | <span class="t">And so they did a few samples. One was they're considering augmented reality and they held expert panels with people with disabilities, people who are formerly or currently incarcerated and with women to get their input and make sure that that was included.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6077" target="_blank">01:41:17.000</a></span> | <span class="t">They did a second one on an autonomous vehicle strategy document and organized expert panels with youth, with people that don't drive cars and with extremely low income people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6088" target="_blank">01:41:28.000</a></span> | <span class="t">And so I think this is a great guide if you're kind of unsure of how do you even go about setting something like this up to expand your circle, include more people and get perspectives that may be underrepresented by your employees.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6105" target="_blank">01:41:45.000</a></span> | <span class="t">So I just want to let you know that this resource is out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6112" target="_blank">01:41:52.000</a></span> | <span class="t">Tool six is think about the terrible people. And this can be hard because I think we're often, you know, thinking kind of positively or thinking about people like ourselves who don't have terrible intentions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6129" target="_blank">01:42:09.000</a></span> | <span class="t">But really think about who might want to abuse, steal, misinterpret, hack, destroy, or weaponize what we build.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6137" target="_blank">01:42:17.000</a></span> | <span class="t">Who will use it with alarming stupidity or irrationality?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6141" target="_blank">01:42:21.000</a></span> | <span class="t">What rewards, incentives, openings has our design inadvertently created for those people?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6146" target="_blank">01:42:26.000</a></span> | <span class="t">And so kind of remembering back to the section on metrics, you know, how are people going to be trying to game or manipulate this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6154" target="_blank">01:42:34.000</a></span> | <span class="t">And how can how can we then remove those rewards or incentives? And so this is this is an important kind of important step to take.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6164" target="_blank">01:42:44.000</a></span> | <span class="t">And then tool seven is closing the loop, ethical feedback and iteration, remembering this is never a finished task and identifying feedback channels that will give you kind of reliable data and integrating this process with quality management and user support</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6181" target="_blank">01:43:01.000</a></span> | <span class="t">and developing formal procedures and chains of responsibility for ethical iteration.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6186" target="_blank">01:43:06.000</a></span> | <span class="t">And this tool reminded me of a blog post by Alex Pierce that I really like. Alex Pierce was previously the chief legal officer at Medium.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6195" target="_blank">01:43:15.000</a></span> | <span class="t">And I guess this was a year ago. He interviewed something like 15 or 20 people that have worked in trust and safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6203" target="_blank">01:43:23.000</a></span> | <span class="t">And trust and safety includes content moderation, although it's not not solely content moderation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6209" target="_blank">01:43:29.000</a></span> | <span class="t">And kind of one of the ideas that came up that I really liked was one of one of the people and so many of these people have worked in trust and safety for years at big name companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6220" target="_blank">01:43:40.000</a></span> | <span class="t">And one of them said the separation of product people and trust people worries me because in a world where product managers and engineers and visionaries cared about this stuff, it would be baked into how things get built.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6231" target="_blank">01:43:51.000</a></span> | <span class="t">If things stay this way, that product and engineering are Mozart and everyone else's Alfred the butler, the big stuff is not going to change.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6239" target="_blank">01:43:59.000</a></span> | <span class="t">And so I think at least two people in this kind of talk about this idea of needing to better integrate trust and safety, which are often kind of on the front lines of seeing abuse and misuse of a technology product, integrating that more closely with product and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6253" target="_blank">01:44:13.000</a></span> | <span class="t">end so that it can kind of be more directly incorporated and you can have a tighter feedback loop there about what's going wrong and and how how that can be designed against.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6266" target="_blank">01:44:26.000</a></span> | <span class="t">Okay, so those were these were, well, I linked to a few blog posts and research I thought relevant but inspired by the mark my coolest centers tools for tech ethics and hopefully those are practices you could think about potentially implementing at your at your company.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6285" target="_blank">01:44:45.000</a></span> | <span class="t">So next I want to get into diversity, which I know came up earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6291" target="_blank">01:44:51.000</a></span> | <span class="t">So only 12% of machine learning researchers are women. This is kind of a very, very dire statistic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6301" target="_blank">01:45:01.000</a></span> | <span class="t">There's also kind of extreme lack of racial diversity and age diversity and other factors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6308" target="_blank">01:45:08.000</a></span> | <span class="t">And this is this is significant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6312" target="_blank">01:45:12.000</a></span> | <span class="t">A kind of positive example of what diversity can help with and a post Tracy chow who was a early, early engineer at Quora and later at Pinterest wrote that the first feature and so I think she was like one of the first five employees at Quora.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6328" target="_blank">01:45:28.000</a></span> | <span class="t">The first feature I built when I worked at Quora was the block button. I was eager to work on the feature because I personally felt antagonized and abused on the site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6336" target="_blank">01:45:36.000</a></span> | <span class="t">And she goes on to say that if she hadn't been there, you know, they might not have added the block button as soon as that's kind of like a direct example of how how having a diverse team can help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6347" target="_blank">01:45:47.000</a></span> | <span class="t">So my kind of key, key advice for anyone wanting to increase diversity is to start at the opposite end of the pipeline from from where people talk about the workplace.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6360" target="_blank">01:46:00.000</a></span> | <span class="t">I wrote a blog post five years ago. If you think women in tech is just a pipeline problem, you haven't been paying attention. And this was the most popular thing I had ever written until Jeremy and I wrote the the COVID-19 post last month.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6373" target="_blank">01:46:13.000</a></span> | <span class="t">So the second most most popular thing I've written.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6377" target="_blank">01:46:17.000</a></span> | <span class="t">But I linked to a ton of ton of research in there. A key statistic to understand is that 41% of women working in tech end up leaving the field compared to 17% of men.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6389" target="_blank">01:46:29.000</a></span> | <span class="t">And so this is something that recruiting more girls into into coding or tech is not going to address this problem if they keep leaving at very high rates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6399" target="_blank">01:46:39.000</a></span> | <span class="t">I just had a little peek at the YouTube chat and I see people are asking questions there. I just wanted to remind people that we are not that Rachel and I do not look at that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6410" target="_blank">01:46:50.000</a></span> | <span class="t">If you want to ask questions, you should use the forum thread. And if you see questions that you'd like, then please vote them up, such as this one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6421" target="_blank">01:47:01.000</a></span> | <span class="t">How about an ethical issue bounty program, just like the bug bounty programs that some companies have?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6430" target="_blank">01:47:10.000</a></span> | <span class="t">No, I think that's a neat idea. Yeah, rewarding people for for finding ethical issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6437" target="_blank">01:47:17.000</a></span> | <span class="t">And so the reason that women are more likely to leave tech is and this was found in a meta analysis of over 200 books, white papers, articles.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6449" target="_blank">01:47:29.000</a></span> | <span class="t">Women leave the tech industry because they're treated unfairly, underpaid, less likely to be fast-tracked than their male colleagues and unable to advance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6458" target="_blank">01:47:38.000</a></span> | <span class="t">And too often, diversity efforts end up just focusing on white women, which is wrong.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6465" target="_blank">01:47:45.000</a></span> | <span class="t">Interviews with 60 women of color who work in STEM research found that 100 percent had experienced discrimination and their particular stereotypes varied by race.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6473" target="_blank">01:47:53.000</a></span> | <span class="t">And so it's very important to focus on women of color in diversity efforts as a kind of the top priority.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6484" target="_blank">01:48:04.000</a></span> | <span class="t">A study found that men's voices are perceived as more persuasive fact-based and logical than women's voices, even when reading identical scripts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6495" target="_blank">01:48:15.000</a></span> | <span class="t">Researchers found that women receive more vague feedback and personality criticism and performance evaluations, whereas men are more likely to receive actionable advice tied to concrete business outcomes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6507" target="_blank">01:48:27.000</a></span> | <span class="t">When women receive mentorship, it's often advice on how they should change and gain more self-knowledge. When men receive mentorship, it's public endorsement of their authority.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6516" target="_blank">01:48:36.000</a></span> | <span class="t">Only one of these has been statistically linked to getting promoted. It's the public endorsement of authority.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6522" target="_blank">01:48:42.000</a></span> | <span class="t">And all these studies are linked to in another post I wrote called The Real Reason Women Quit Tech and How to Address It.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6528" target="_blank">01:48:48.000</a></span> | <span class="t">Is that a question, Jeremy? Yeah. So if you're interested, kind of these two blog posts I linked to a ton of relevant research on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6539" target="_blank">01:48:59.000</a></span> | <span class="t">And I think this is kind of the workplace is the place to start in addressing these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6547" target="_blank">01:49:07.000</a></span> | <span class="t">So another issue is tech interviews are terrible for everyone.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6553" target="_blank">01:49:13.000</a></span> | <span class="t">So now kind of working one step back from people that are already in your workplace, but thinking about the interview process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6560" target="_blank">01:49:20.000</a></span> | <span class="t">And I wrote a post on how to make tech interviews a little less awful and went through a ton of research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6565" target="_blank">01:49:25.000</a></span> | <span class="t">And I will say that the interview problem, I think, is a hard one. I think it's very time consuming and hard to interview people well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6575" target="_blank">01:49:35.000</a></span> | <span class="t">But kind of the two most interesting pieces of research I came across one was from Triple Bite, which is a recruiting company that interviews kind of does this first round technical interview for people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6590" target="_blank">01:49:50.000</a></span> | <span class="t">And then they interview at Y Combinator. It's a Y Combinator company. And then they interview at Y Combinator companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6597" target="_blank">01:49:57.000</a></span> | <span class="t">And so they have this very interesting data set where they've kind of given everybody the same technical interview and then they can see which companies people got off.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6604" target="_blank">01:50:04.000</a></span> | <span class="t">And these people got offers from when they were interviewing at many of the same companies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6609" target="_blank">01:50:09.000</a></span> | <span class="t">And the number one finding from their research is that the types of programmers that each company looks for often have little to do with what the company needs or does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6618" target="_blank">01:50:18.000</a></span> | <span class="t">Rather, they reflect company culture and the backgrounds of the founders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6622" target="_blank">01:50:22.000</a></span> | <span class="t">And this is something where they even gave the advice of if you're job hunting, try to look for companies where the founders have a similar background to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6633" target="_blank">01:50:33.000</a></span> | <span class="t">And that's something that makes sense. That's going to be much easier for certain people to do than others, in particular, given the gender and racial disparities in VC funding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6645" target="_blank">01:50:45.000</a></span> | <span class="t">That's going to make a big difference. Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6648" target="_blank">01:50:48.000</a></span> | <span class="t">Actually, I would say that was the most common advice I heard from VCs when I became a founder in the Bay Area was when recruiting focus on getting people from your network and people that are as like minded and similar as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6666" target="_blank">01:51:06.000</a></span> | <span class="t">That was by far the most common advice that I heard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6669" target="_blank">01:51:09.000</a></span> | <span class="t">Yeah, I mean, this is maybe like one of my controversial opinions. I do feel like ultimately like I get why people hire from their network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6678" target="_blank">01:51:18.000</a></span> | <span class="t">And I think that long term we all need to be developed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6682" target="_blank">01:51:22.000</a></span> | <span class="t">Well, particularly white people need to be developing more diverse networks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6685" target="_blank">01:51:25.000</a></span> | <span class="t">And that's like a 10 year project. That's not something you can do right when you're hiring, but really kind of developing a diverse network of friends and trusted acquaintances kind of over time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6701" target="_blank">01:51:41.000</a></span> | <span class="t">But yeah, thank you for that perspective to Jeremy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6705" target="_blank">01:51:45.000</a></span> | <span class="t">And then kind of the other study I found really interesting was one where they they gave people resumes and in one case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6715" target="_blank">01:51:55.000</a></span> | <span class="t">So one resume had more academic qualifications and then one had more practical experience and then they switched the gender.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6722" target="_blank">01:52:02.000</a></span> | <span class="t">One was a woman. One was a man or male name, a female name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6726" target="_blank">01:52:06.000</a></span> | <span class="t">And basically, people were more likely to hire the male and then they would use a post hoc justification of, oh, well, I chose him because he had more academic experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6734" target="_blank">01:52:14.000</a></span> | <span class="t">Or I chose him because he had more practical experience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6737" target="_blank">01:52:17.000</a></span> | <span class="t">And that's something that I think it's very human to use post hoc justifications.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6742" target="_blank">01:52:22.000</a></span> | <span class="t">But it's a real risk that definitely shows up in hiring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6749" target="_blank">01:52:29.000</a></span> | <span class="t">Ultimately, AI or any other technology developed or implemented by companies for financial advantage, i.e. more profit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6757" target="_blank">01:52:37.000</a></span> | <span class="t">Maybe the best way to incentivize ethical behavior is to tie financial or reputational risk to good behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6763" target="_blank">01:52:43.000</a></span> | <span class="t">In some ways, similar to how companies are now investing in cybersecurity because they don't want to be the next Equifax.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6769" target="_blank">01:52:49.000</a></span> | <span class="t">Can grassroots campaigns help in better ethical behavior with regards to their use of AI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6776" target="_blank">01:52:56.000</a></span> | <span class="t">That's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6777" target="_blank">01:52:57.000</a></span> | <span class="t">Yeah. And I think there are a lot of analogies with cybersecurity.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6780" target="_blank">01:53:00.000</a></span> | <span class="t">And I know that for a long time, I think it was hard for people to make or people had trouble making the case to their bosses of why they should be investing in cybersecurity, particularly because cybersecurity is, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6792" target="_blank">01:53:12.000</a></span> | <span class="t">something like when it's working well, you don't notice it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6796" target="_blank">01:53:16.000</a></span> | <span class="t">And so that can be can be hard to build the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6799" target="_blank">01:53:19.000</a></span> | <span class="t">So I think that there there is a place for grassroots campaigns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6804" target="_blank">01:53:24.000</a></span> | <span class="t">And I'm going to talk more about policy in a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6810" target="_blank">01:53:30.000</a></span> | <span class="t">It can be hard in some of these cases where there are not necessarily meaningful alternatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6819" target="_blank">01:53:39.000</a></span> | <span class="t">So I do think like monopolies can kind of kind of make that harder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6825" target="_blank">01:53:45.000</a></span> | <span class="t">That's a good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6832" target="_blank">01:53:52.000</a></span> | <span class="t">All right. So next step actually on this slide is the need for policy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6839" target="_blank">01:53:59.000</a></span> | <span class="t">And so I'm going to start with a case study of what's what's one thing that gets companies to take action.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6846" target="_blank">01:54:06.000</a></span> | <span class="t">And so, as I mentioned earlier, an investigator for the U.N. found that Facebook played a determining role in the Rohingya genocide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6856" target="_blank">01:54:16.000</a></span> | <span class="t">I think the best article I've read on this was by Timothy McLaughlin, who did a super, super in-depth dive on Facebook's role in Myanmar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6866" target="_blank">01:54:26.000</a></span> | <span class="t">And people people warned Facebook executives in 2013 and in 2014 and in 2015 how the platform was being used to spread hate speech and to incite violence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6880" target="_blank">01:54:40.000</a></span> | <span class="t">One person in 2015 even told Facebook executives that Facebook could play the same role in Myanmar that the radio broadcast played during the Rwandan genocide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6890" target="_blank">01:54:50.000</a></span> | <span class="t">And radio broadcast played a very terrible and kind of pivotal role in the Rwandan genocide.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6897" target="_blank">01:54:57.000</a></span> | <span class="t">Somebody close to it said that's not 2020 hindsight.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6900" target="_blank">01:55:00.000</a></span> | <span class="t">The scale of this problem was significant and it was already apparent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6904" target="_blank">01:55:04.000</a></span> | <span class="t">And despite this, in 2015, I believe Facebook only had four contractors who even spoke Burmese, the language of Myanmar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6914" target="_blank">01:55:14.000</a></span> | <span class="t">Question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6916" target="_blank">01:55:16.000</a></span> | <span class="t">That's an interesting one. How do you think about our opportunity to correct biases in artificial systems versus the behaviors we see in humans?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6925" target="_blank">01:55:25.000</a></span> | <span class="t">For example, a sentencing algorithm can be monitored and adjusted versus a specific biased judge who remains in their role for a long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6935" target="_blank">01:55:35.000</a></span> | <span class="t">I mean, theoretically, though, I think I feel a bit hesitant about the it's it'll be easier to correct bias in algorithms because I feel like the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6955" target="_blank">01:55:55.000</a></span> | <span class="t">you still need people kind of making the decisions to prioritize that like it requires kind of an overhaul of the system's priorities, I think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6968" target="_blank">01:56:08.000</a></span> | <span class="t">It also starts with the premise that there are people who can't be fired or disciplined or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6975" target="_blank">01:56:15.000</a></span> | <span class="t">I guess maybe for some judges that's true, but that kind of maybe suggests that judges shouldn't be lifetime appointments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6986" target="_blank">01:56:26.000</a></span> | <span class="t">Yeah, even then, I think you kind of need the change of heart of the people advocating for the new system, which I think can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=6995" target="_blank">01:56:35.000</a></span> | <span class="t">would be necessary in other case, kind of, and that that's kind of the critical piece of getting the people that are wanting to overhaul the values of a system.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7005" target="_blank">01:56:45.000</a></span> | <span class="t">So returning to this issue of the Rohingya genocide, and this is kind of continuing issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7017" target="_blank">01:56:57.000</a></span> | <span class="t">This is something that's just kind of really stunning to me that that there were so many warnings and that so many people tried to raise an alarm on this and that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7028" target="_blank">01:57:08.000</a></span> | <span class="t">so little action was taken. And even this was last year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7035" target="_blank">01:57:15.000</a></span> | <span class="t">Zuckerberg finally said that Facebook would add or maybe maybe this was actually this was probably two years ago, said that Facebook would add.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7042" target="_blank">01:57:22.000</a></span> | <span class="t">But this is, you know, after genocide is already happening, Facebook would add dozens of Burmese language content reviewers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7051" target="_blank">01:57:31.000</a></span> | <span class="t">So in contrast, so we have this. This is how Facebook really failed to respond in any any significant way in Myanmar.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7061" target="_blank">01:57:41.000</a></span> | <span class="t">Germany passed a much stricter law about hate speech and that's D.G. DZ. And the the potential penalty would be up to like 50 million euros.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7077" target="_blank">01:57:57.000</a></span> | <span class="t">Facebook hired 1200 people in under a year because they were so worried about this penalty. And so and I'm not saying that like this is a law we want to replicate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7086" target="_blank">01:58:06.000</a></span> | <span class="t">Here I'm just illustrating the difference between being told that you're contributing or playing a determining role in a genocide versus a significant financial penalty.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7098" target="_blank">01:58:18.000</a></span> | <span class="t">We have seen what the one thing that makes Facebook take action is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7102" target="_blank">01:58:22.000</a></span> | <span class="t">And so I think that that is really significant in remembering what the what the power of a credible threat of a significant fine is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7112" target="_blank">01:58:32.000</a></span> | <span class="t">And it has to be a lot more than just like a cost of doing business.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7119" target="_blank">01:58:39.000</a></span> | <span class="t">So I I really believe that we need both policy and ethical behavior within industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7126" target="_blank">01:58:46.000</a></span> | <span class="t">I think that policy is the appropriate tool for addressing negative externalities, misaligned economic incentives, race to the bottom situations and enforcing accountability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7138" target="_blank">01:58:58.000</a></span> | <span class="t">However, ethical behavior of individuals and of data scientists and software engineers working in industry is very much necessary as well because the law is not always going to keep up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7148" target="_blank">01:59:08.000</a></span> | <span class="t">It's not going to cover all the edge cases. We really need the people in industry to be making kind of ethical ethical decisions as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7155" target="_blank">01:59:15.000</a></span> | <span class="t">And so I believe both are significant and important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7161" target="_blank">01:59:21.000</a></span> | <span class="t">And then something to note here is that many many examples of kind of ethics issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7169" target="_blank">01:59:29.000</a></span> | <span class="t">And I haven't talked about all of these, but there was Amazon's facial recognition. The ACLU did a study finding that it incorrectly matched 28 members of Congress to criminal mugshots.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7182" target="_blank">01:59:42.000</a></span> | <span class="t">And this disproportionately included Congresspeople of color.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7187" target="_blank">01:59:47.000</a></span> | <span class="t">There's also this was a terrible article, not that the article was good, but the story is terrible of a city that's using this IBM dashboard for predictive policing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7198" target="_blank">01:59:58.000</a></span> | <span class="t">And a city official said, oh, like whenever you have machine learning, it's always 99 percent accurate, which is false and quite concerning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7208" target="_blank">02:00:08.000</a></span> | <span class="t">We had we had the issue in 2016 ProPublica discovered that you could place a housing ad on Facebook and say, you know, like, I don't want Latino or black people or I don't want wheelchair users to see this housing ad, which seems like a violation of the Fair Housing Act.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7227" target="_blank">02:00:27.000</a></span> | <span class="t">And so there's this article and Facebook was like, we're so sorry. And then over a year later, it was still going on. ProPublica went back and wrote another article about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7238" target="_blank">02:00:38.000</a></span> | <span class="t">There's also this issue of dozens of companies were placing ads on Facebook job ads and saying, like, we only want young people to see this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7248" target="_blank">02:00:48.000</a></span> | <span class="t">There's the Amazon creating the recruiting tool that penalized resumes that had the word women's in it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7257" target="_blank">02:00:57.000</a></span> | <span class="t">And so something something to note about these examples and many of the examples we've talked about today is that many of these are about human rights and civil rights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7267" target="_blank">02:01:07.000</a></span> | <span class="t">And it's a good article by Dominique Harrison of the Aspen Institute on this. And I kind of agree with Aneel Dash's framing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7276" target="_blank">02:01:16.000</a></span> | <span class="t">And he wrote, there is no technology industry anymore. Tech is being used in every industry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7282" target="_blank">02:01:22.000</a></span> | <span class="t">And so I think in particular, we need to consider human rights and civil rights such as housing, education, employment, criminal justice, voting and medical care and think about what rights we we want to safeguard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7295" target="_blank">02:01:35.000</a></span> | <span class="t">And I do think policy is the appropriate way to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7301" target="_blank">02:01:41.000</a></span> | <span class="t">And I think I mean, it's very easy to be discouraged about about regulation, but I think sometimes we overlook the the positive or the cases where where it's worked well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7315" target="_blank">02:01:55.000</a></span> | <span class="t">And so something I really liked about data sheets for data sets by Timnit Gebru et al is that they go through three case studies of how standardization and regular regulation came to different industries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7329" target="_blank">02:02:09.000</a></span> | <span class="t">And so it's the electronics industry around circuits and resistors. And so there, that's kind of around the standardization of what the specs are and what you write down about them, the pharmaceutical industry and car safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7340" target="_blank">02:02:20.000</a></span> | <span class="t">And none of these are perfect, but it's still it was a kind of very illuminating the case studies there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7346" target="_blank">02:02:26.000</a></span> | <span class="t">And in particular, I got very interested in the car safety one. And there's also a great 99 percent invisible episode.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7353" target="_blank">02:02:33.000</a></span> | <span class="t">This is a design podcast about it. And so some things I learned is that early cars had sharp metal knobs on the knobs on the dashboard that could lodge in people's skulls in a crash.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7367" target="_blank">02:02:47.000</a></span> | <span class="t">Non collapsible steering columns would frequently impale drivers. And then even after the collapsible steering column was invented, it wasn't actually implemented because there was no economic incentive to do so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7378" target="_blank">02:02:58.000</a></span> | <span class="t">But it's the collapsible steering column has this had saved more lives than anything other than the seat belt when it comes to car safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7388" target="_blank">02:03:08.000</a></span> | <span class="t">And there was also this just this widespread belief that cars were dangerous because of the people driving them. And it took it took consumer safety advocates decades to just even change the culture of discussion around this and to start kind of gathering and tracking the data and to put more of an onus on car companies around safety.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7407" target="_blank">02:03:27.000</a></span> | <span class="t">GM hired a private detective to trail Ralph Nader and try to dig up dirt on him. And so this was really a battle that we kind of I take for granted now.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7419" target="_blank">02:03:39.000</a></span> | <span class="t">And so kind of shows how much how much it can take to to change change the needle there. And then a kind of a more recent issue is that it wasn't until I believe 2011 that it was required that crash test dummies start representing the average female anatomy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7439" target="_blank">02:03:59.000</a></span> | <span class="t">In addition to previously was kind of just crushed test dummies were like men and that in a crash of the same impact, women were 40 percent more likely to be injured than men because that's kind of who the cars were being designed for.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7454" target="_blank">02:04:14.000</a></span> | <span class="t">So I thought I thought all this was very interesting and it can be helpful to kind of remember and remember some of the successes we've had.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7461" target="_blank">02:04:21.000</a></span> | <span class="t">And another area that's very relevant is environmental protections and kind of looking back and.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7472" target="_blank">02:04:32.000</a></span> | <span class="t">Maychick Seglowski has a great article on this. But you know, just remembering like in the U.S., we used to have rivers that would catch on fire and London had terrible, terrible smog and that these are things that were very would not have been possible to kind of solve as an individual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7487" target="_blank">02:04:47.000</a></span> | <span class="t">We really needed kind of coordinated, coordinated regulation on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7492" target="_blank">02:04:52.000</a></span> | <span class="t">All right. And so then on a kind of closing note, so I think a lot of the problems I've touched on tonight are really huge, huge and difficult problems and they're often kind of very complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7506" target="_blank">02:05:06.000</a></span> | <span class="t">And I.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7509" target="_blank">02:05:09.000</a></span> | <span class="t">I go into more detail on this in the course. So please, please check out the course once it's once it's released.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7514" target="_blank">02:05:14.000</a></span> | <span class="t">I always try to offer some like steps towards solutions, but I realize they're not they're not always, you know, as satisfying as I would like of like this is going to solve it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7524" target="_blank">02:05:24.000</a></span> | <span class="t">And that's because these are really, really difficult problems. And Julia Angwin, a former journalist from ProPublica and now the editor in chief of The Markup gave a really great interview on privacy last year that I liked and found very encouraging.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7542" target="_blank">02:05:42.000</a></span> | <span class="t">And she said, I strongly believe that in order to solve a problem, you have to diagnose it and that we're still in the diagnosis phase of this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7551" target="_blank">02:05:51.000</a></span> | <span class="t">If you think about the turn of the century and industrialization, we had, I don't know, 30 years of child labor, unlimited work hours, terrible working conditions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7561" target="_blank">02:06:01.000</a></span> | <span class="t">And it took a lot of journalists muckracking and advocacy to diagnose the problem and have some understanding of what it was and then the activism to get laws changed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7573" target="_blank">02:06:13.000</a></span> | <span class="t">I see my role as trying to make as clear as possible what the downsides are and diagnosing them really accurately so that they can be solvable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7580" target="_blank">02:06:20.000</a></span> | <span class="t">That's hard work and lots more people need to be doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7583" target="_blank">02:06:23.000</a></span> | <span class="t">I find that really encouraging and that I do think we should be working towards solutions, but I think just at this point, even better diagnosing and understanding kind of the complex problems we're facing is valuable work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7598" target="_blank">02:06:38.000</a></span> | <span class="t">A couple of people are very keen to see your full course on ethics. Is that something that they might be able to attend or buy or something?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7607" target="_blank">02:06:47.000</a></span> | <span class="t">So it will be released for free at some point this summer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7613" target="_blank">02:06:53.000</a></span> | <span class="t">And there was a paid in-person version offered at the Data Institute as a certificate, kind of similar to how this course was supposed to be offered in person.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7625" target="_blank">02:07:05.000</a></span> | <span class="t">The Data Ethics one was in person and that took place in January and February.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7629" target="_blank">02:07:09.000</a></span> | <span class="t">And then I'm currently teaching a version version for the Masters of Data Science students at USF and I will be releasing the free online version later, sometime before July.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=krIVOb23EH8&t=7641" target="_blank">02:07:21.000</a></span> | <span class="t">Thank you. I'll see you next time.</span></div></div></body></html>