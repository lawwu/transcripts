<html><head><title>Lesson 25: Deep Learning Foundations to Stable Diffusion</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 25: Deep Learning Foundations to Stable Diffusion</h2><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8"><img src="https://i.ytimg.com/vi/8AgZ9jcQ9v8/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./8AgZ9jcQ9v8.html">Whisper Transcript</a> | <a href="./transcript_8AgZ9jcQ9v8.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Hi everybody, and welcome to the last lesson of part two.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5" target="_blank">00:00:05.900</a></span> | <span class="t">Greetings Jono and Greetings Tanishk, how are you guys doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=9" target="_blank">00:00:09.400</a></span> | <span class="t">Good thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=11" target="_blank">00:00:11.060</a></span> | <span class="t">Doing well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=12" target="_blank">00:00:12.060</a></span> | <span class="t">Excited for the last lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=13" target="_blank">00:00:13.560</a></span> | <span class="t">It's been an interesting, fun journey.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=16" target="_blank">00:00:16.040</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=17" target="_blank">00:00:17.040</a></span> | <span class="t">I should explain, we're not quite completing all of stable diffusion in this part of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=23" target="_blank">00:00:23.440</a></span> | <span class="t">course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=24" target="_blank">00:00:24.440</a></span> | <span class="t">There's going to be one piece left for the next part of the course, which is the CLIP</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=28" target="_blank">00:00:28.320</a></span> | <span class="t">embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=29" target="_blank">00:00:29.320</a></span> | <span class="t">Because CLIP is NLP, and so the next part of the course we will be looking at NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=35" target="_blank">00:00:35.420</a></span> | <span class="t">So we will end up finishing stable diffusion from scratch, but we're going to have to have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=41" target="_blank">00:00:41.360</a></span> | <span class="t">a significant diversion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=43" target="_blank">00:00:43.360</a></span> | <span class="t">And what we thought was, given everything that's happened with GPT-4 and stuff since</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=50" target="_blank">00:00:50.680</a></span> | <span class="t">we started this course, we thought it makes more sense to delve into that quite deeply,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=56" target="_blank">00:00:56.520</a></span> | <span class="t">more soon.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=60" target="_blank">00:01:00.240</a></span> | <span class="t">And delay CLIP as a result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=62" target="_blank">00:01:02.800</a></span> | <span class="t">So hopefully people will feel comfortable with that decision, but I think we'll have a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=66" target="_blank">00:01:06.640</a></span> | <span class="t">of exciting NLP material coming up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=71" target="_blank">00:01:11.920</a></span> | <span class="t">So that's the rough plan.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=73" target="_blank">00:01:13.960</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=75" target="_blank">00:01:15.840</a></span> | <span class="t">So I think what we might do is maybe start by looking at a really interesting and quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=83" target="_blank">00:01:23.720</a></span> | <span class="t">successful application of pixel level diffusion by applying it not to pixels that represent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=90" target="_blank">00:01:30.400</a></span> | <span class="t">an image, but pixels that represent a sound, which is pretty crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=95" target="_blank">00:01:35.160</a></span> | <span class="t">So maybe Johnno, of course it's going to be Johnno, he does the crazy stuff, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=98" target="_blank">00:01:38.520</a></span> | <span class="t">great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=99" target="_blank">00:01:39.520</a></span> | <span class="t">So Johnno, show you your crazy and crazily successful approach to diffusion for pixels</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=105" target="_blank">00:01:45.760</a></span> | <span class="t">of sounds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=106" target="_blank">00:01:46.760</a></span> | <span class="t">Please.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=107" target="_blank">00:01:47.760</a></span> | <span class="t">Sure thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=108" target="_blank">00:01:48.760</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=109" target="_blank">00:01:49.760</a></span> | <span class="t">So this is going to be a little bit of intro and tell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=114" target="_blank">00:01:54.160</a></span> | <span class="t">Most of the code in the notebook is just copied and pasted from, I think, notebook 30.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=119" target="_blank">00:01:59.680</a></span> | <span class="t">But we're going to be trying to generate something other than just images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=123" target="_blank">00:02:03.600</a></span> | <span class="t">So specifically, I'm going to be loading up a dataset of bird calls.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=127" target="_blank">00:02:07.040</a></span> | <span class="t">These are just like short samples of, I think, 10 different classes of birds calling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=132" target="_blank">00:02:12.600</a></span> | <span class="t">And so we need to understand like, okay, well, this is a totally different domain, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=136" target="_blank">00:02:16.080</a></span> | <span class="t">This is audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=137" target="_blank">00:02:17.400</a></span> | <span class="t">If you look at the data, like, let's look at an example of the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=139" target="_blank">00:02:19.840</a></span> | <span class="t">This is coming from a hugging face dataset so that that line of code will download it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=143" target="_blank">00:02:23.560</a></span> | <span class="t">automatically if you haven't got it before, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=145" target="_blank">00:02:25.840</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=146" target="_blank">00:02:26.840</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=147" target="_blank">00:02:27.840</a></span> | <span class="t">So this will download it into a cache and then sort of handle a lot of, you created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=152" target="_blank">00:02:32.760</a></span> | <span class="t">this dataset, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=153" target="_blank">00:02:33.760</a></span> | <span class="t">Did you, is this already a dataset you found somewhere else or you made it or what?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=158" target="_blank">00:02:38.360</a></span> | <span class="t">This is a subset that I made from a much larger dataset of longer call recordings and from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=163" target="_blank">00:02:43.160</a></span> | <span class="t">an open website called Zeno Kanto.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=165" target="_blank">00:02:45.720</a></span> | <span class="t">So they collect all of these sound recordings from people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=168" target="_blank">00:02:48.320</a></span> | <span class="t">They have experts who help identify what birds are calling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=171" target="_blank">00:02:51.600</a></span> | <span class="t">And so all I did was find the audio peaks, like where is there most likely to be a bird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=176" target="_blank">00:02:56.840</a></span> | <span class="t">call and clip around those just to get a smaller dataset of things where there's actually something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=182" target="_blank">00:03:02.840</a></span> | <span class="t">happening.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=183" target="_blank">00:03:03.920</a></span> | <span class="t">Not a particularly amazing dataset in terms of like the recordings have a lot of background</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=188" target="_blank">00:03:08.960</a></span> | <span class="t">noise and stuff, but a fun, small audio one to play with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=192" target="_blank">00:03:12.200</a></span> | <span class="t">Um, yeah. And so when we talk about audio, you've got a microphone somewhere, it's reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=196" target="_blank">00:03:16.640</a></span> | <span class="t">like a pressure level, essentially, um, in the air with these sound waves.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=200" target="_blank">00:03:20.960</a></span> | <span class="t">And it's doing that some number of times per second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=203" target="_blank">00:03:23.000</a></span> | <span class="t">So we have a sample rate and in this case, the data has a sample rate of 32,000 samples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=208" target="_blank">00:03:28.520</a></span> | <span class="t">per second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=209" target="_blank">00:03:29.520</a></span> | <span class="t">So every second waveform that's being approximated, there's lots of little up across, up across,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=214" target="_blank">00:03:34.520</a></span> | <span class="t">up across kind of things, basically, correct?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=218" target="_blank">00:03:38.480</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=219" target="_blank">00:03:39.480</a></span> | <span class="t">Um, and so that's great for, you know, capturing the audio, um, but it's not so good for modeling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=224" target="_blank">00:03:44.800</a></span> | <span class="t">because we now have 30,000 values per second in this one big, one D array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=231" target="_blank">00:03:51.040</a></span> | <span class="t">Um, and so yeah, you can try and find models that can work with that kind of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=237" target="_blank">00:03:57.000</a></span> | <span class="t">Uh, but what we're going to do is a little hack and we're instead going to use something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=240" target="_blank">00:04:00.640</a></span> | <span class="t">called a spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=242" target="_blank">00:04:02.720</a></span> | <span class="t">So the original data is the main issue.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=245" target="_blank">00:04:05.200</a></span> | <span class="t">It's, it's, it's too big and slow to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=249" target="_blank">00:04:09.240</a></span> | <span class="t">It's, it's too big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=251" target="_blank">00:04:11.000</a></span> | <span class="t">Um, but also you have some, like some sound waves are at a hundred Hertz, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=258" target="_blank">00:04:18.400</a></span> | <span class="t">So they're, they're going up and down a hundred times a second and some are at a thousand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=261" target="_blank">00:04:21.520</a></span> | <span class="t">and some are at 10,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=263" target="_blank">00:04:23.080</a></span> | <span class="t">And often there's background noise that can have extremely high frequency components.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=267" target="_blank">00:04:27.260</a></span> | <span class="t">And so if you're looking just at the waveform, there's lots and lots of change second to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=272" target="_blank">00:04:32.560</a></span> | <span class="t">second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=273" target="_blank">00:04:33.560</a></span> | <span class="t">And there's some very long range dependencies of like, Oh, it's generally high here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=277" target="_blank">00:04:37.480</a></span> | <span class="t">It's generally low there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=279" target="_blank">00:04:39.240</a></span> | <span class="t">And so it can be quite hard to capture those patterns.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=281" target="_blank">00:04:41.240</a></span> | <span class="t">Um, and so part of it is, it's just a lot of samples to deal with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=284" target="_blank">00:04:44.880</a></span> | <span class="t">Um, but part of it also is that it's not like an image where you can just do a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=291" target="_blank">00:04:51.040</a></span> | <span class="t">and things nearby each other tend to be related or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=294" target="_blank">00:04:54.240</a></span> | <span class="t">Um, it's quite tricky to disentangle what's going on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=297" target="_blank">00:04:57.920</a></span> | <span class="t">Um, and so we have this idea of something called a spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=301" target="_blank">00:05:01.760</a></span> | <span class="t">Uh, this is a fancy 3d visualization, but it's basically just taking that audio and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=307" target="_blank">00:05:07.440</a></span> | <span class="t">mapping time on one axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=309" target="_blank">00:05:09.120</a></span> | <span class="t">So you can see as time goes by, we're moving along the X axis and then on the Y axis is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=313" target="_blank">00:05:13.960</a></span> | <span class="t">frequency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=315" target="_blank">00:05:15.480</a></span> | <span class="t">And so the, um, the peaks here show like intensity at different frequencies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=319" target="_blank">00:05:19.980</a></span> | <span class="t">And so if I make a pure note, you can see that that maps in the frequency domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=327" target="_blank">00:05:27.640</a></span> | <span class="t">Um, but when I'm talking, there's lots and lots of peaks and that's because our voices</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=332" target="_blank">00:05:32.320</a></span> | <span class="t">tend to produce a lot of overtones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=333" target="_blank">00:05:33.920</a></span> | <span class="t">So if I go, you can see there's a main notes, but there's also the subsequent notes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=338" target="_blank">00:05:38.880</a></span> | <span class="t">And if I play something like a chord, you can see this, you know, maybe three main peaks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=347" target="_blank">00:05:47.440</a></span> | <span class="t">and then each of those have these harmonics as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=350" target="_blank">00:05:50.360</a></span> | <span class="t">Um, so it captures a lot of information about the signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=353" target="_blank">00:05:53.560</a></span> | <span class="t">Um, and so we're going to turn our audio data into something like this, where even just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=359" target="_blank">00:05:59.720</a></span> | <span class="t">visually, if I'm a bird, you can see this really nice spatial pattern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=364" target="_blank">00:06:04.960</a></span> | <span class="t">And the hope is if we can generate that and then if we can find some way to turn it back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=369" target="_blank">00:06:09.160</a></span> | <span class="t">into audio and then we'll be off to the races.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=373" target="_blank">00:06:13.720</a></span> | <span class="t">And so, yeah, that's what I'm doing in this notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=375" target="_blank">00:06:15.800</a></span> | <span class="t">We have, um, I'm leaning on the diffusers docs, um, pipelines.audio diffusion.mal class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=385" target="_blank">00:06:25.240</a></span> | <span class="t">And so within the realm of spectrograms, there's a few different ways you can do it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=389" target="_blank">00:06:29.640</a></span> | <span class="t">So this is from the torch audio docs, um, but this notebook is from the hugging face diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=393" target="_blank">00:06:33.880</a></span> | <span class="t">models class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=395" target="_blank">00:06:35.280</a></span> | <span class="t">So we had that waveform, that's those raw samples and we'd like to convert that into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=399" target="_blank">00:06:39.840</a></span> | <span class="t">what they call the frequency domain, um, which is things like these spectrograms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=404" target="_blank">00:06:44.520</a></span> | <span class="t">Um, and so you can do a normal, normal spectrogram, a power spectrogram or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=410" target="_blank">00:06:50.960</a></span> | <span class="t">Um, but we often use something called a male spectrogram, which is exactly the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=416" target="_blank">00:06:56.440</a></span> | <span class="t">It's actually probably what's being visualized here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=419" target="_blank">00:06:59.320</a></span> | <span class="t">And it's something that's designed to map the, like the frequency ranges into a range</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=426" target="_blank">00:07:06.600</a></span> | <span class="t">that's, um, like tied to what human hearing is based on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=432" target="_blank">00:07:12.280</a></span> | <span class="t">And so rather than trying to capture all frequencies from, you know, zero Hertz to 40,000 Hertz,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=437" target="_blank">00:07:17.440</a></span> | <span class="t">a lot of which we can't even hear, it focuses in on the range of values that we tend to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=443" target="_blank">00:07:23.040</a></span> | <span class="t">be interested in as, as humans.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=445" target="_blank">00:07:25.400</a></span> | <span class="t">And also it does like a transformation into, into kind of like a log space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=451" target="_blank">00:07:31.720</a></span> | <span class="t">Um, so that the, the intensities like highs and lows correspond to loud and quiet for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=456" target="_blank">00:07:36.320</a></span> | <span class="t">human hearing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=457" target="_blank">00:07:37.320</a></span> | <span class="t">So it's very tuned for, um, the types of audio information that we actually might care about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=463" target="_blank">00:07:43.240</a></span> | <span class="t">rather than, you know, tens of thousands of kilohertz that any bats can hear.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=467" target="_blank">00:07:47.720</a></span> | <span class="t">Um, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=468" target="_blank">00:07:48.720</a></span> | <span class="t">So we're going to rely on a class to abstract this away, but it's going to basically give</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=472" target="_blank">00:07:52.200</a></span> | <span class="t">us a transformation from waveform to spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=476" target="_blank">00:07:56.320</a></span> | <span class="t">And then it's also going to help us go from spectrogram back to waveform.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=480" target="_blank">00:08:00.120</a></span> | <span class="t">Um, and so, uh, let me show you my data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=483" target="_blank">00:08:03.320</a></span> | <span class="t">I have this two image function that's going to take the audio array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=487" target="_blank">00:08:07.400</a></span> | <span class="t">It's going to use the male, um, class to handle turning that into, um, spectrograms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=494" target="_blank">00:08:14.320</a></span> | <span class="t">And the class also does things like it splits it up into chunks based on, you can set like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=498" target="_blank">00:08:18.400</a></span> | <span class="t">a desired, um, resolution I'd like 128 by 128 spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=504" target="_blank">00:08:24.320</a></span> | <span class="t">It says, okay, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=505" target="_blank">00:08:25.320</a></span> | <span class="t">I know how many, I know you need 128, like frequency bins for the frequency axis and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=509" target="_blank">00:08:29.600</a></span> | <span class="t">128 steps on the, on the time axis.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=513" target="_blank">00:08:33.640</a></span> | <span class="t">So it kind of handles that converting and resizing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=516" target="_blank">00:08:36.720</a></span> | <span class="t">Um, and then it gives us these audio slice to image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=520" target="_blank">00:08:40.520</a></span> | <span class="t">So that's taking a chunk of audio and turning it into the spectrogram.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=523" target="_blank">00:08:43.960</a></span> | <span class="t">And it also has the inverse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=525" target="_blank">00:08:45.600</a></span> | <span class="t">Um, so our dataset is fairly simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=529" target="_blank">00:08:49.200</a></span> | <span class="t">We just referencing our original audio datasets, but we're calling that to image function and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=535" target="_blank">00:08:55.240</a></span> | <span class="t">then returning it into a tensor and we're mapping it to minus 0.5 to 0.5, similarly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=541" target="_blank">00:09:01.920</a></span> | <span class="t">to what we've done with like the grayscale images in the past.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=545" target="_blank">00:09:05.080</a></span> | <span class="t">Um, so if you look at a sample from that data, we now have, instead of an audio waveform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=550" target="_blank">00:09:10.200</a></span> | <span class="t">of 32,000 or 64,000, if it's two seconds samples, we now have this 128 by 128 pixel spectrogram,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=561" target="_blank">00:09:21.200</a></span> | <span class="t">which looks like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=562" target="_blank">00:09:22.200</a></span> | <span class="t">Um, and it's just, it's grayscale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=563" target="_blank">00:09:23.800</a></span> | <span class="t">So this is just matplotlibs colors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=565" target="_blank">00:09:25.720</a></span> | <span class="t">Um, but we can test out going from the spectrogram back to audio using the image to audio function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=572" target="_blank">00:09:32.560</a></span> | <span class="t">that the male class has, um, and that should give us, um, now this isn't perfect because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=583" target="_blank">00:09:43.080</a></span> | <span class="t">the spectrogram shows the intensity at different frequencies, but with audio, you've also got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=587" target="_blank">00:09:47.680</a></span> | <span class="t">to worry about something called the phase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=590" target="_blank">00:09:50.040</a></span> | <span class="t">And so this image to audio function is actually behind the scenes doing a kind of iterative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=595" target="_blank">00:09:55.800</a></span> | <span class="t">approximation, um, with something called the Griffin Lynn algorithm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=599" target="_blank">00:09:59.600</a></span> | <span class="t">Um, so I'm not going to try and describe that here, but it's just, it's approximating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=604" target="_blank">00:10:04.600</a></span> | <span class="t">It's guessing what the phase should be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=606" target="_blank">00:10:06.620</a></span> | <span class="t">It's creating a spectrogram, it's comparing that to the original, it's updating, it's doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=610" target="_blank">00:10:10.400</a></span> | <span class="t">some sort of like iterative, very similar to like an optimization thing to try and generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=615" target="_blank">00:10:15.240</a></span> | <span class="t">an audio signal that would produce the spectrogram, which we're trying to invert.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=619" target="_blank">00:10:19.480</a></span> | <span class="t">So just to clarify, so my understanding, what you're saying is that the spectrogram is a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=626" target="_blank">00:10:26.200</a></span> | <span class="t">lossy conversion of the sound into an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=630" target="_blank">00:10:30.880</a></span> | <span class="t">Um, and specifically it's lossy because it, um, tells you the kind of intensity at each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=638" target="_blank">00:10:38.800</a></span> | <span class="t">point, but it's not, it's kind of like, is it like the difference between a sine wave</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=642" target="_blank">00:10:42.080</a></span> | <span class="t">and a, and a cosine wave?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=643" target="_blank">00:10:43.600</a></span> | <span class="t">Like they're just shifted in different ways.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=645" target="_blank">00:10:45.200</a></span> | <span class="t">We don't know how much it's shifted.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=647" target="_blank">00:10:47.320</a></span> | <span class="t">So coming back to the sound, you do have to get that, that shifting the phase correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=653" target="_blank">00:10:53.160</a></span> | <span class="t">And so it's trying to guess something and it sounds like it's not doing a great guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=657" target="_blank">00:10:57.000</a></span> | <span class="t">from the thing you showed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=659" target="_blank">00:10:59.840</a></span> | <span class="t">The original audio is also not that amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=661" target="_blank">00:11:01.940</a></span> | <span class="t">Um, but yes, the, the spectrogram back to audio task, this, these dotted lines are like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=667" target="_blank">00:11:07.240</a></span> | <span class="t">highlighting this is, yeah, it's an approximation and there are deep learning methods now that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=671" target="_blank">00:11:11.480</a></span> | <span class="t">can do that better, or at least that sound much higher quality, um, because you can train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=677" target="_blank">00:11:17.360</a></span> | <span class="t">a model somehow to go from this image-like representation back to an audio signal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=684" target="_blank">00:11:24.160</a></span> | <span class="t">Um, but we just use the approximation for this notebook.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=687" target="_blank">00:11:27.200</a></span> | <span class="t">Um, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=688" target="_blank">00:11:28.600</a></span> | <span class="t">So now that we can represent our data as like a grayscale 128 by 128 pixel image, um, everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=695" target="_blank">00:11:35.080</a></span> | <span class="t">else becomes very much the same as the previous diffusion models examples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=698" target="_blank">00:11:38.800</a></span> | <span class="t">We're going to use this noiseify function to add different amounts of noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=703" target="_blank">00:11:43.520</a></span> | <span class="t">And so we can see now we have our spectrograms, but with varying amounts of noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=707" target="_blank">00:11:47.320</a></span> | <span class="t">Added we can create a simple diffusion model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=710" target="_blank">00:11:50.920</a></span> | <span class="t">I'm just copying and pasting the results, but with one extra layer, um, just with very few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=716" target="_blank">00:11:56.320</a></span> | <span class="t">channels to go from 128 to 64 to 36, I mean, to 16 by eight to eight, um, no attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=724" target="_blank">00:12:04.960</a></span> | <span class="t">Just I think pretty much copied and pasted from notebook 30, uh, and train it for in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=731" target="_blank">00:12:11.080</a></span> | <span class="t">this case, 15 epochs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=732" target="_blank">00:12:12.360</a></span> | <span class="t">It took about, this is interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=734" target="_blank">00:12:14.400</a></span> | <span class="t">So you're using simple diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=738" target="_blank">00:12:18.440</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=739" target="_blank">00:12:19.440</a></span> | <span class="t">Um, so specifically, this is the simple diffusion model that you, um, I think I've already introduced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=745" target="_blank">00:12:25.120</a></span> | <span class="t">Maybe not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=746" target="_blank">00:12:26.120</a></span> | <span class="t">Um, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=747" target="_blank">00:12:27.120</a></span> | <span class="t">So briefly looked at it, so let's remind ourselves of what it does here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=751" target="_blank">00:12:31.200</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=752" target="_blank">00:12:32.200</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=753" target="_blank">00:12:33.200</a></span> | <span class="t">Um, so we have some number of down blocks with a specified number of channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=757" target="_blank">00:12:37.680</a></span> | <span class="t">And then the key insight from simple diffusion was that you often want to concentrate the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=761" target="_blank">00:12:41.440</a></span> | <span class="t">computes in the sort of middle at the low resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=764" target="_blank">00:12:44.480</a></span> | <span class="t">So that's these, these mid blocks and their transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=768" target="_blank">00:12:48.360</a></span> | <span class="t">Um, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=769" target="_blank">00:12:49.880</a></span> | <span class="t">Um, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=771" target="_blank">00:12:51.360</a></span> | <span class="t">Um, and so we can stack some number of those and then, um, the corresponding up path, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=777" target="_blank">00:12:57.680</a></span> | <span class="t">this is a unit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=778" target="_blank">00:12:58.680</a></span> | <span class="t">So we passing in the features from the, the down path as we go through those up blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=783" target="_blank">00:13:03.640</a></span> | <span class="t">Um, and so we're going to go take an, um, image and time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=789" target="_blank">00:13:09.000</a></span> | <span class="t">We can embed the time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=790" target="_blank">00:13:10.880</a></span> | <span class="t">We're going to go through our down blocks and saving the results, we're going to go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=797" target="_blank">00:13:17.800</a></span> | <span class="t">the mid blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=798" target="_blank">00:13:18.800</a></span> | <span class="t">There we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=799" target="_blank">00:13:19.800</a></span> | <span class="t">Through the mid blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=800" target="_blank">00:13:20.800</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=801" target="_blank">00:13:21.800</a></span> | <span class="t">And before that, you've also got the, um, embedding of the, uh, locations that self.la is the learnable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=810" target="_blank">00:13:30.320</a></span> | <span class="t">embeddings using scale and shift.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=812" target="_blank">00:13:32.360</a></span> | <span class="t">I remember.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=813" target="_blank">00:13:33.360</a></span> | <span class="t">Uh, right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=814" target="_blank">00:13:34.360</a></span> | <span class="t">So this is preparing it to go through the transformer blocks by adding some learnable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=818" target="_blank">00:13:38.240</a></span> | <span class="t">embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=819" target="_blank">00:13:39.240</a></span> | <span class="t">Mm-hmm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=820" target="_blank">00:13:40.240</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=821" target="_blank">00:13:41.240</a></span> | <span class="t">And then we reshaping it to be effectively a sequence since that's how we had written</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=828" target="_blank">00:13:48.920</a></span> | <span class="t">our transformer to have expect a 1D sequence of embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=832" target="_blank">00:13:52.840</a></span> | <span class="t">Um, and so once you've gone through those mid blocks, we reshape it back and then we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=837" target="_blank">00:13:57.080</a></span> | <span class="t">go through the up blocks passing in and also our saved outputs from the down path.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=842" target="_blank">00:14:02.640</a></span> | <span class="t">Um, yeah, so it's a nice, it's a nice model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=846" target="_blank">00:14:06.320</a></span> | <span class="t">And you can really control how much parameters and compute you're doing just by setting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=851" target="_blank">00:14:11.280</a></span> | <span class="t">like what are the number of features or channels at each of those down block stages and how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=856" target="_blank">00:14:16.720</a></span> | <span class="t">many mid blocks are you going to stack?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=858" target="_blank">00:14:18.960</a></span> | <span class="t">Um, and so if you want to scale it up, it's quite easy to say, oh, let me just add more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=862" target="_blank">00:14:22.520</a></span> | <span class="t">mid blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=863" target="_blank">00:14:23.520</a></span> | <span class="t">Maybe I'll add more channels, um, to the, to the down and up paths.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=867" target="_blank">00:14:27.360</a></span> | <span class="t">Um, and there's a very easy model to tweak to get a larger or smaller model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=872" target="_blank">00:14:32.280</a></span> | <span class="t">One fun thought I know is, um, simple diffusion only came out a couple of months ago and I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=878" target="_blank">00:14:38.160</a></span> | <span class="t">don't think, I think ours might be the first publicly available code for it because I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=884" target="_blank">00:14:44.040</a></span> | <span class="t">think the author has released the code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=885" target="_blank">00:14:45.840</a></span> | <span class="t">I suspect this is probably the first time maybe it's ever been used to generate audio</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=889" target="_blank">00:14:49.680</a></span> | <span class="t">before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=890" target="_blank">00:14:50.680</a></span> | <span class="t">Uh, possibly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=891" target="_blank">00:14:51.680</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=892" target="_blank">00:14:52.680</a></span> | <span class="t">I guess.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=893" target="_blank">00:14:53.680</a></span> | <span class="t">Um, I know a couple of people who've at least privately done their implementations when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=897" target="_blank">00:14:57.640</a></span> | <span class="t">I asked the author if he was releasing code, he said, oh, but it's simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=900" target="_blank">00:15:00.600</a></span> | <span class="t">It's just a bunch of transformer blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=902" target="_blank">00:15:02.880</a></span> | <span class="t">I'll release it eventually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=905" target="_blank">00:15:05.360</a></span> | <span class="t">Um, no, maybe, maybe not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=907" target="_blank">00:15:07.160</a></span> | <span class="t">I don't know the line then, but they were like, Oh, you can see the pseudo code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=911" target="_blank">00:15:11.120</a></span> | <span class="t">It's pretty easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=912" target="_blank">00:15:12.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=913" target="_blank">00:15:13.120</a></span> | <span class="t">It is pretty easy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=914" target="_blank">00:15:14.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=915" target="_blank">00:15:15.120</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=916" target="_blank">00:15:16.120</a></span> | <span class="t">So trains, the last goes down as we hope, um, sampling is exactly the same as generating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=921" target="_blank">00:15:21.660</a></span> | <span class="t">images normally.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=922" target="_blank">00:15:22.660</a></span> | <span class="t">Um, and that's going to give us the spectrograms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=925" target="_blank">00:15:25.840</a></span> | <span class="t">I'm using dealing with a hundred steps, um, and to actually listen to these samples, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=931" target="_blank">00:15:31.960</a></span> | <span class="t">then are just going to use that, um, image to audio function again, to take our grayscale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=937" target="_blank">00:15:37.840</a></span> | <span class="t">image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=938" target="_blank">00:15:38.840</a></span> | <span class="t">Um, and in this case, actually it expects a PIL image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=941" target="_blank">00:15:41.440</a></span> | <span class="t">So I first converted it to PIL, um, and then turn that back into audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=947" target="_blank">00:15:47.200</a></span> | <span class="t">And so we can play some of the generated samples.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=951" target="_blank">00:15:51.800</a></span> | <span class="t">Wow, that's so cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=956" target="_blank">00:15:56.680</a></span> | <span class="t">I don't know that I could guarantee what bird is making these calls and some of them are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=962" target="_blank">00:16:02.520</a></span> | <span class="t">better than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=963" target="_blank">00:16:03.520</a></span> | <span class="t">Like some of them are better than others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=966" target="_blank">00:16:06.520</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=967" target="_blank">00:16:07.520</a></span> | <span class="t">Some of the original samples sample, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=970" target="_blank">00:16:10.000</a></span> | <span class="t">So.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=971" target="_blank">00:16:11.000</a></span> | <span class="t">Exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=972" target="_blank">00:16:12.000</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=973" target="_blank">00:16:13.000</a></span> | <span class="t">So yeah, that's generating and fake bird calls with, with, um, spectrogram diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=978" target="_blank">00:16:18.120</a></span> | <span class="t">There's projects that do this on music.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=979" target="_blank">00:16:19.720</a></span> | <span class="t">Um, so the refusion projects based on text and yeah, there's, there's various other like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=988" target="_blank">00:16:28.720</a></span> | <span class="t">pre-trained models that do diffusion on spectrograms to produce, um, you know, music clips or voice</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=996" target="_blank">00:16:36.920</a></span> | <span class="t">or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=997" target="_blank">00:16:37.920</a></span> | <span class="t">Um, I may have frozen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1000" target="_blank">00:16:40.560</a></span> | <span class="t">Refusion is actually this stable diffusion model that's, that's fine tuned specifically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1004" target="_blank">00:16:44.840</a></span> | <span class="t">for, for this, for the spectrogram generation, which is, which I find very impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1009" target="_blank">00:16:49.960</a></span> | <span class="t">It's like a model that was originally for, you know, text to image is instead can also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1014" target="_blank">00:16:54.320</a></span> | <span class="t">generate the spectrograms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1015" target="_blank">00:16:55.680</a></span> | <span class="t">I guess there's still some useful information in, you know, the sort of text image model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1020" target="_blank">00:17:00.400</a></span> | <span class="t">that kind of generalizes, or you can still be used for text to audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1024" target="_blank">00:17:04.560</a></span> | <span class="t">So I found that a very interesting, impressive application as well as a refusion is an awesome</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1029" target="_blank">00:17:09.320</a></span> | <span class="t">name.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1030" target="_blank">00:17:10.320</a></span> | <span class="t">Indeed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1031" target="_blank">00:17:11.320</a></span> | <span class="t">It is, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1035" target="_blank">00:17:15.080</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1036" target="_blank">00:17:16.080</a></span> | <span class="t">And I guess since it's a latent model that leads us onto the next topic, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1038" target="_blank">00:17:18.840</a></span> | <span class="t">I was just going to say, we've got a natural segue there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1041" target="_blank">00:17:21.360</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1042" target="_blank">00:17:22.360</a></span> | <span class="t">So we're, um, if we want to replicate refusion, then, um, we'll need lightens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1051" target="_blank">00:17:31.520</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1053" target="_blank">00:17:33.520</a></span> | <span class="t">So the, the final non-NLP part of stable diffusion is this, uh, ability to use the more compressed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1061" target="_blank">00:17:41.200</a></span> | <span class="t">representation, uh, created by a VAE called Latens, um, instead of pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1068" target="_blank">00:17:48.080</a></span> | <span class="t">Um, so we're going to start today by creating a VAE, taking a look at how it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1074" target="_blank">00:17:54.520</a></span> | <span class="t">Um, so to remind you, as we learned back in the, the first lesson of this part of part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1081" target="_blank">00:18:01.160</a></span> | <span class="t">two, um, the VAE model converts the, um, 256 by 256 pixel, three channel into a, um, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1094" target="_blank">00:18:14.960</a></span> | <span class="t">it 64 by 64 by four?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1097" target="_blank">00:18:17.520</a></span> | <span class="t">It'll be 32 if it's 256, uh, it's 512 to 65.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1102" target="_blank">00:18:22.880</a></span> | <span class="t">Oh, 512 to 64.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1103" target="_blank">00:18:23.880</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1104" target="_blank">00:18:24.880</a></span> | <span class="t">So do a 32 by 32 by four.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1107" target="_blank">00:18:27.000</a></span> | <span class="t">So dramatically smaller, which makes life so much easier, um, which is, which is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1114" target="_blank">00:18:34.840</a></span> | <span class="t">nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1115" target="_blank">00:18:35.840</a></span> | <span class="t">Um, having said that, you know, simple diffusion does the first, you know, few, in fact, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1124" target="_blank">00:18:44.680</a></span> | <span class="t">know, all the downsampling pretty quickly and, and all the hard work happens, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1129" target="_blank">00:18:49.480</a></span> | <span class="t">at a 16 by 16 anyway.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1132" target="_blank">00:18:52.000</a></span> | <span class="t">So maybe it's, you know, with simple diffusion, it's not as big a deal as it used to be, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1136" target="_blank">00:18:56.560</a></span> | <span class="t">it's still, you know, it's very handy, particularly because for us folks with more normal amounts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1141" target="_blank">00:19:01.760</a></span> | <span class="t">of compute, we can take advantage of all that hard work that the stability.ai computers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1148" target="_blank">00:19:08.960</a></span> | <span class="t">did for us by creating the stable diffusion VAE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1153" target="_blank">00:19:13.000</a></span> | <span class="t">Um, so that's what we're going to do today, but first of all, we're going to create our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1158" target="_blank">00:19:18.200</a></span> | <span class="t">own.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1159" target="_blank">00:19:19.200</a></span> | <span class="t">Um, so let's do a VAE using fashion MNIST.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1163" target="_blank">00:19:23.360</a></span> | <span class="t">So the first or the first stuff is just the, the normal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1166" target="_blank">00:19:26.500</a></span> | <span class="t">One thing I am going to do for this simple example though, is I'm going to flatten the,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1171" target="_blank">00:19:31.120</a></span> | <span class="t">um, fashion MNIST pixels into a vector to make it as simple as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1178" target="_blank">00:19:38.160</a></span> | <span class="t">Um, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1180" target="_blank">00:19:40.840</a></span> | <span class="t">So we've, we're going to end up with vectors of length 784 because 28 by 28 784, uh, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1188" target="_blank">00:19:48.080</a></span> | <span class="t">going to create a single hidden layer MLP with, um, 400, um, hidden and then 200 outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1201" target="_blank">00:20:01.840</a></span> | <span class="t">So here's a linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1203" target="_blank">00:20:03.440</a></span> | <span class="t">So it's a sequential containing a linear and then an optimal activation function and an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1208" target="_blank">00:20:08.000</a></span> | <span class="t">optional normalization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1210" target="_blank">00:20:10.000</a></span> | <span class="t">Um, we'll update init weights so that we initialize linear layers as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1216" target="_blank">00:20:16.480</a></span> | <span class="t">Um, so before we create a VAE, which is a variational autoencoder, we'll create a normal autoencoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1223" target="_blank">00:20:23.800</a></span> | <span class="t">We've done this once before and we didn't have any luck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1227" target="_blank">00:20:27.440</a></span> | <span class="t">Um, in fact, we were so unsuccessful that we decided to go back and create a learner</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1233" target="_blank">00:20:33.060</a></span> | <span class="t">and come back a few weeks later once we knew what we were doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1236" target="_blank">00:20:36.400</a></span> | <span class="t">So here we are.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1237" target="_blank">00:20:37.400</a></span> | <span class="t">We're back.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1238" target="_blank">00:20:38.400</a></span> | <span class="t">We think we know what we're doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1239" target="_blank">00:20:39.400</a></span> | <span class="t">Um, so we're just going to recreate an autoencoder just like we did some lessons ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1244" target="_blank">00:20:44.920</a></span> | <span class="t">Um, so there's going to be an encoder, which is a sequential, which goes from our 768 inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1250" target="_blank">00:20:50.840</a></span> | <span class="t">to our 400 hidden and then a linear layer with our 400 hidden and then an output layer from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1256" target="_blank">00:20:56.860</a></span> | <span class="t">the 400 hidden to the 200 outputs of the encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1262" target="_blank">00:21:02.320</a></span> | <span class="t">So there we got our latents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1265" target="_blank">00:21:05.400</a></span> | <span class="t">And then the decoder will go from those 200 latents to our 400 hidden, have our hidden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1273" target="_blank">00:21:13.160</a></span> | <span class="t">layer and then come back to our 768 inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1279" target="_blank">00:21:19.840</a></span> | <span class="t">Um, all right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1283" target="_blank">00:21:23.800</a></span> | <span class="t">So we can optimize that in the usual way using Adam, um, and we'll do it for 20 epochs runs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1294" target="_blank">00:21:34.200</a></span> | <span class="t">pretty quickly cause it's quite a small dataset and quite a small model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1298" target="_blank">00:21:38.440</a></span> | <span class="t">Um, and so what we can then do, um, is we can grab a batch of our X who actually grabbed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1308" target="_blank">00:21:48.040</a></span> | <span class="t">the batch of X earlier, uh, way back here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1313" target="_blank">00:21:53.440</a></span> | <span class="t">So I've got a batch of images, um, and we can put it through our model, um, pop it back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1322" target="_blank">00:22:02.360</a></span> | <span class="t">on the CPU and we can then have a look at our original mini-batch and we have to reshape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1329" target="_blank">00:22:09.960</a></span> | <span class="t">it to 28 by 28 because we previously had flattened it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1333" target="_blank">00:22:13.840</a></span> | <span class="t">So there's our original and then, um, we can look at the result after putting it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1339" target="_blank">00:22:19.120</a></span> | <span class="t">our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1341" target="_blank">00:22:21.760</a></span> | <span class="t">And there it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1342" target="_blank">00:22:22.760</a></span> | <span class="t">And as you can see, it's, you know, very roughly regenerated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1347" target="_blank">00:22:27.600</a></span> | <span class="t">And so this is, um, not a massive compression, it's compressing it from 768 to 200.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1355" target="_blank">00:22:35.080</a></span> | <span class="t">And it's also not doing an amazing job of recreating the original details.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1358" target="_blank">00:22:38.660</a></span> | <span class="t">Um, but you know, this is the simplest possible auto encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1362" target="_blank">00:22:42.360</a></span> | <span class="t">So it's doing, you know, it's a lot better than our previous attempt.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1366" target="_blank">00:22:46.240</a></span> | <span class="t">Um, so that's good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1369" target="_blank">00:22:49.480</a></span> | <span class="t">So what we could now do is we could just generate some noise and then we're not even going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1375" target="_blank">00:22:55.080</a></span> | <span class="t">do diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1376" target="_blank">00:22:56.080</a></span> | <span class="t">So we're going to go and say like, okay, we've got a decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1378" target="_blank">00:22:58.160</a></span> | <span class="t">So let's just decode that noise and see what it creates.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1383" target="_blank">00:23:03.400</a></span> | <span class="t">And the answer is not anything great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1386" target="_blank">00:23:06.560</a></span> | <span class="t">I mean, I could kind of recognize that might be the start of a shoe.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1391" target="_blank">00:23:11.920</a></span> | <span class="t">Maybe that's the start of a bag.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1392" target="_blank">00:23:12.920</a></span> | <span class="t">I don't know, but it's not doing anything amazing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1396" target="_blank">00:23:16.140</a></span> | <span class="t">So we have not successfully created an image generator here, um, but there's a very simple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1402" target="_blank">00:23:22.480</a></span> | <span class="t">step we can do to make something that's more like an image generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1406" target="_blank">00:23:26.240</a></span> | <span class="t">The problem is that, um, these 200, um, this vector of length 200 recreating, there's no</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1415" target="_blank">00:23:35.880</a></span> | <span class="t">particular reason that things that are not in the dataset are going to create items of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1423" target="_blank">00:23:43.400</a></span> | <span class="t">clothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1424" target="_blank">00:23:44.400</a></span> | <span class="t">We haven't done anything to try to make that happen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1427" target="_blank">00:23:47.040</a></span> | <span class="t">We've already tried to make this work for things in the dataset, you know, and, um, therefore,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1434" target="_blank">00:23:54.560</a></span> | <span class="t">when we just randomly generate a bunch of, you know, a vector of length 200 or 16 vectors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1441" target="_blank">00:24:01.840</a></span> | <span class="t">of length 200 in this case, um, and then decode them, there's no particular reason to think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1447" target="_blank">00:24:07.440</a></span> | <span class="t">that they're going to create something that's recognizable as clothing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1453" target="_blank">00:24:13.840</a></span> | <span class="t">So the way a VAE tries to fix this is by, we've got the exact same encoder as before, except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1465" target="_blank">00:24:25.440</a></span> | <span class="t">it's just missing its final layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1469" target="_blank">00:24:29.080</a></span> | <span class="t">Its final layer has been moved over to here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1471" target="_blank">00:24:31.520</a></span> | <span class="t">I'll explain why there's two of them in a moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1474" target="_blank">00:24:34.020</a></span> | <span class="t">So we've got the inputs to hidden, the hidden to hidden, and then the hidden to the latent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1479" target="_blank">00:24:39.680</a></span> | <span class="t">The decoder is identical, okay, latent's to hidden, hidden to hidden, hidden to inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1489" target="_blank">00:24:49.280</a></span> | <span class="t">And then just as before, we call the encoder, um, but we do something a little bit weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1499" target="_blank">00:24:59.240</a></span> | <span class="t">next, which is that we actually have two separate final layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1505" target="_blank">00:25:05.080</a></span> | <span class="t">We've got one called mu for the final of the encoder and one called LV, which stands for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1512" target="_blank">00:25:12.120</a></span> | <span class="t">log of variance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1513" target="_blank">00:25:13.920</a></span> | <span class="t">So encoder has two different final layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1517" target="_blank">00:25:17.000</a></span> | <span class="t">So we're going to call both of them, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1520" target="_blank">00:25:20.460</a></span> | <span class="t">So we've now got two encoded 200 long lots of latents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1526" target="_blank">00:25:26.200</a></span> | <span class="t">What do we do with them?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1527" target="_blank">00:25:27.840</a></span> | <span class="t">What we do is we use them to generate random numbers and the random numbers have a mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1539" target="_blank">00:25:39.760</a></span> | <span class="t">of mu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1541" target="_blank">00:25:41.640</a></span> | <span class="t">So when you take a random zero one, so this creates zero one random numbers, mean zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1548" target="_blank">00:25:48.080</a></span> | <span class="t">standard deviation one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1549" target="_blank">00:25:49.780</a></span> | <span class="t">So if we add mu to it, they now have a mean of mu or approximately.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1554" target="_blank">00:25:54.760</a></span> | <span class="t">And if you multiply the random numbers by half of log of variance, e to the power of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1560" target="_blank">00:26:00.760</a></span> | <span class="t">that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1562" target="_blank">00:26:02.560</a></span> | <span class="t">So given this log of variance, this is going to give you standard deviation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1568" target="_blank">00:26:08.720</a></span> | <span class="t">So this is going to give you a standard deviation of e to the half LV and a mean of mu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1576" target="_blank">00:26:16.240</a></span> | <span class="t">Why the half?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1577" target="_blank">00:26:17.640</a></span> | <span class="t">It doesn't matter too much, but if you think about it, um, standard deviation is the square</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1583" target="_blank">00:26:23.040</a></span> | <span class="t">root, so the variance is squared.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1586" target="_blank">00:26:26.460</a></span> | <span class="t">So when you take the log, you can move that half into the multiplication because of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1594" target="_blank">00:26:34.800</a></span> | <span class="t">log trick.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1596" target="_blank">00:26:36.680</a></span> | <span class="t">That's why we just got the half here instead of the square root, which would be to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1601" target="_blank">00:26:41.000</a></span> | <span class="t">power of a half.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1604" target="_blank">00:26:44.240</a></span> | <span class="t">So this is just, yeah, this is just the standard deviation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1608" target="_blank">00:26:48.140</a></span> | <span class="t">So we've got the standard deviation times normally distributed random noise plus mu.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1612" target="_blank">00:26:52.060</a></span> | <span class="t">So we end up with normally distributed numbers, we're going to have 200 of them for each element</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1621" target="_blank">00:27:01.160</a></span> | <span class="t">of the batch where they have a standard deviation of the result of this final layer and a variance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1631" target="_blank">00:27:11.880</a></span> | <span class="t">which is the result or log variance of the result of this final layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1636" target="_blank">00:27:16.980</a></span> | <span class="t">And then finally we passed that through the decoder as usual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1641" target="_blank">00:27:21.320</a></span> | <span class="t">I explained why we passed back three things, but for now we're just worried about the fact</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1644" target="_blank">00:27:24.200</a></span> | <span class="t">we passed back the result of the decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1647" target="_blank">00:27:27.440</a></span> | <span class="t">So what this is going to do is it's going to generate, um, the, the result of calling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1654" target="_blank">00:27:34.960</a></span> | <span class="t">um, encode is going to be a little bit random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1660" target="_blank">00:27:40.480</a></span> | <span class="t">On average, you know, it's still generating exactly the same as before, which is the result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1665" target="_blank">00:27:45.640</a></span> | <span class="t">of a sequential model with, you know, MLP with one hidden layer, but it's also going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1672" target="_blank">00:27:52.480</a></span> | <span class="t">to add some randomness around that, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1675" target="_blank">00:27:55.860</a></span> | <span class="t">So this is, here's the bit, which is exactly the same as before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1678" target="_blank">00:27:58.320</a></span> | <span class="t">This is the same as calling encode before, but then here's the bit that adds some randomness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1683" target="_blank">00:28:03.120</a></span> | <span class="t">to it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1684" target="_blank">00:28:04.120</a></span> | <span class="t">And the amount of randomness is also itself random.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1688" target="_blank">00:28:08.400</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1689" target="_blank">00:28:09.600</a></span> | <span class="t">So then that gets run through the decoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1691" target="_blank">00:28:11.920</a></span> | <span class="t">Um, okay, so if we now just, um, well, you know, trained that, right, using the result</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1701" target="_blank">00:28:21.800</a></span> | <span class="t">of the decoder and using, um, I think we didn't use MSE loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1705" target="_blank">00:28:25.800</a></span> | <span class="t">We used a binary cross entropy loss, which we've seen before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1709" target="_blank">00:28:29.840</a></span> | <span class="t">Um, so if you've forgotten, you should definitely go back and rewatch that by really part one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1714" target="_blank">00:28:34.840</a></span> | <span class="t">Um, or we've done a bit of it in part two as well, binary cross entropy loss, um, with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1721" target="_blank">00:28:41.720</a></span> | <span class="t">logits means that you don't have to worry about doing the soft max.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1724" target="_blank">00:28:44.720</a></span> | <span class="t">It does the soft max for you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1726" target="_blank">00:28:46.800</a></span> | <span class="t">Um, so if we just, um, optimize this using BCE now, you would expect, and it would, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1735" target="_blank">00:28:55.480</a></span> | <span class="t">believe I haven't checked, um, that it would basically take this final, like this layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1739" target="_blank">00:28:59.840</a></span> | <span class="t">here and turn these all into zeros, um, as a result of which it would have no variance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1744" target="_blank">00:29:04.720</a></span> | <span class="t">at all. Um, and therefore it would behave exactly the same as the previous auto encoder.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1752" target="_blank">00:29:12.880</a></span> | <span class="t">Does that sound reasonable to you guys?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1755" target="_blank">00:29:15.360</a></span> | <span class="t">Yeah. Okay. Um, so that wouldn't help at all because what we actually want is we want some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1761" target="_blank">00:29:21.040</a></span> | <span class="t">variance and the reason we want some variance is we actually want to have it generate some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1768" target="_blank">00:29:28.560</a></span> | <span class="t">latents, which are not exactly our data. They're around our data, but not exactly our data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1775" target="_blank">00:29:35.000</a></span> | <span class="t">And then when it generates latents that are around our data, we want them to decode to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1780" target="_blank">00:29:40.640</a></span> | <span class="t">our, to the same thing. We want them to decode to the correct image. And so as a result,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1785" target="_blank">00:29:45.920</a></span> | <span class="t">if we can train that, right, something that it does include some variation and still decodes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1793" target="_blank">00:29:53.160</a></span> | <span class="t">back to the original image, then we've created a much more robust model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1798" target="_blank">00:29:58.360</a></span> | <span class="t">And then that's something that we would help then, that we would hope then when we say,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1802" target="_blank">00:30:02.400</a></span> | <span class="t">okay, well now decode some noise that it's going to decode to something better than this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1808" target="_blank">00:30:08.320</a></span> | <span class="t">So that's the idea of a VAE. So how do we get it to create, um, a log variance, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1818" target="_blank">00:30:18.520</a></span> | <span class="t">doesn't just go to zero? Um, well, we have a second, uh, loss term it's called the KL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1826" target="_blank">00:30:26.040</a></span> | <span class="t">divergence loss. We've got a key called KLD loss. And what we're going to do is our VAE</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1831" target="_blank">00:30:31.280</a></span> | <span class="t">loss is going to take the binary cross entropy between the actual decoded bit. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1840" target="_blank">00:30:40.320</a></span> | <span class="t">input zero and the target. Okay. So that's, this is exactly the same as before as this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1846" target="_blank">00:30:46.440</a></span> | <span class="t">binary cross entropy. And we're going to add it to this KLD loss, KL divergence. Now KL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1852" target="_blank">00:30:52.720</a></span> | <span class="t">divergence, the details don't matter terribly much. What's important is when we look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1857" target="_blank">00:30:57.560</a></span> | <span class="t">the KLD loss, it's getting past the input and the targets, but if you look, it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1863" target="_blank">00:31:03.520</a></span> | <span class="t">actually using the targets at all. So if we pull out in the, the input into its three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1870" target="_blank">00:31:10.840</a></span> | <span class="t">pieces, which is our predicted image, our mu and our log variance, we don't use this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1877" target="_blank">00:31:17.000</a></span> | <span class="t">either. So the BCE loss only uses the predicted image and the actual image. The KL divergence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1883" target="_blank">00:31:23.920</a></span> | <span class="t">loss only uses mu and log variance. And all it does is it returns a number, which says,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1895" target="_blank">00:31:35.360</a></span> | <span class="t">um, for each item in the batch, um, is mu close to zero and is log variance close to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1901" target="_blank">00:31:41.920</a></span> | <span class="t">one. How does it do that? Well, for mu, it's very easy. Mu squared. So if mu is close to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1910" target="_blank">00:31:50.920</a></span> | <span class="t">zero, then minimizing mu squared does exactly that, right? Um, if mu is one, then mu squared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1917" target="_blank">00:31:57.360</a></span> | <span class="t">is one. If mu is minus one, mu squared is one. If mu is zero, mu squared is zero. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1923" target="_blank">00:32:03.320</a></span> | <span class="t">the lowest you can get for a squared. Um, okay. So we've got a mu squared piece here, um,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1934" target="_blank">00:32:14.440</a></span> | <span class="t">and we've got a dot mean. So we're just taking, that's just basically taking the mean of all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1937" target="_blank">00:32:17.720</a></span> | <span class="t">the mus. And then there's another piece, which is we've got log variance minus e to the power</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1945" target="_blank">00:32:25.960</a></span> | <span class="t">of log variance. So if we look at that, so let's just grab a bunch of numbers between</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1953" target="_blank">00:32:33.640</a></span> | <span class="t">neg three and three and do number minus e to the power of that number. Um, and I'm just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1960" target="_blank">00:32:40.160</a></span> | <span class="t">going to pop in the one plus and the point five times as well. They matter much. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1964" target="_blank">00:32:44.120</a></span> | <span class="t">you can see that's got a minimum of zero. So when that's a minimum of zero, e to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1971" target="_blank">00:32:51.840</a></span> | <span class="t">power of that, which is what we're going to be using actually half times e to the power</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1977" target="_blank">00:32:57.800</a></span> | <span class="t">of that, but that's okay. Is what we're going to be using in our, um, dot forward method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1985" target="_blank">00:33:05.400</a></span> | <span class="t">That's going to be e to the power of zero, which is going to be one. So this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=1991" target="_blank">00:33:11.840</a></span> | <span class="t">to be minimized where, um, log variance exp equals one. So therefore this whole piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2001" target="_blank">00:33:21.000</a></span> | <span class="t">here will be minimized when mu is zero and LV is also zero. Um, and, and so therefore</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2011" target="_blank">00:33:31.600</a></span> | <span class="t">LV e to the power of LV is one. Now, the reason that it's specifically this form is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2020" target="_blank">00:33:40.280</a></span> | <span class="t">because, um, there's a specific mathematical thing called the KL divergence, which compares</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2028" target="_blank">00:33:48.800</a></span> | <span class="t">how similar to distributions are. And so the normal distribution can be fully characterized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2034" target="_blank">00:33:54.640</a></span> | <span class="t">by its main and its variance. And so this is actually more precisely calculating the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2040" target="_blank">00:34:00.460</a></span> | <span class="t">similarity that specifically the KL divergence between the actual mu and LV that we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2049" target="_blank">00:34:09.720</a></span> | <span class="t">and a distribution with a mean of zero and a variance of one. Um, um, but you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2056" target="_blank">00:34:16.920</a></span> | <span class="t">hopefully why conceptually we have this mu.pal two and why we have this LV.exp, um, LV minus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2066" target="_blank">00:34:26.480</a></span> | <span class="t">LV.exp here. Um, so that is our VAE loss. Did you guys have anything to add to any of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2078" target="_blank">00:34:38.720</a></span> | <span class="t">that description? So maybe to highlight the, the, the objective of this is to say rather</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2084" target="_blank">00:34:44.020</a></span> | <span class="t">than having it so that the exact point that an input is encoded to decodes back to that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2090" target="_blank">00:34:50.160</a></span> | <span class="t">input, we're saying number one, the space around that point should also decoded that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2095" target="_blank">00:34:55.080</a></span> | <span class="t">input because we're going to try and force some variance. And number two, the overall</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2098" target="_blank">00:34:58.700</a></span> | <span class="t">variance should be like, yeah, the, the overall space that it uses should be roughly zero</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2105" target="_blank">00:35:05.280</a></span> | <span class="t">mean and units and variance, right? So instead of able to like map each input to like an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2112" target="_blank">00:35:12.000</a></span> | <span class="t">arbitrary point and then decode only that exact point to an input, we now mapping them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2116" target="_blank">00:35:16.080</a></span> | <span class="t">to like a restricted range. And we're saying that not, not just each point, but its surroundings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2120" target="_blank">00:35:20.480</a></span> | <span class="t">as well should also decode back to something that looks like that image. Um, and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2125" target="_blank">00:35:25.200</a></span> | <span class="t">trying to like condition this latent space to be much nicer so that any arbitrary point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2129" target="_blank">00:35:29.960</a></span> | <span class="t">within that, um, range will hopefully map to something useful, which is a harder problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2135" target="_blank">00:35:35.540</a></span> | <span class="t">to solve, right? So we would expect given that this is exactly the same architecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2141" target="_blank">00:35:41.020</a></span> | <span class="t">we would expect its ability to actually decode would be worse than our previous attempt because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2148" target="_blank">00:35:48.960</a></span> | <span class="t">it's a harder problem that we're trying to solve, which is to just, we've got random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2152" target="_blank">00:35:52.200</a></span> | <span class="t">numbers in there as well now that we're hoping that this ability to generate images will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2156" target="_blank">00:35:56.280</a></span> | <span class="t">improve. Um, thanks, John. Okay. So I actually asked Bing about this, um, which is just,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2167" target="_blank">00:36:07.760</a></span> | <span class="t">this is more of an example of like, I think for, you know, now that we've got GPT for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2172" target="_blank">00:36:12.480</a></span> | <span class="t">and Bing and stuff, I find they're pretty good at answering questions that like I wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2177" target="_blank">00:36:17.660</a></span> | <span class="t">to explain to students what would happen if the variance of the latents was very low or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2181" target="_blank">00:36:21.960</a></span> | <span class="t">what if they were very high? So why do we want them to be one? And I thought like, Oh</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2185" target="_blank">00:36:25.760</a></span> | <span class="t">gosh, this is hard to explain. So maybe Bing can help. So I actually thought it's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2190" target="_blank">00:36:30.800</a></span> | <span class="t">good. So I'll just say what Bing said. So Bing says, if the variance of the latents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2194" target="_blank">00:36:34.480</a></span> | <span class="t">are very well low, then the encoder distribution would be very peaked and concentrated around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2201" target="_blank">00:36:41.320</a></span> | <span class="t">the main. So that was the thing we were describing earlier. If we had trained this without the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2205" target="_blank">00:36:45.800</a></span> | <span class="t">KLD loss at all, right, it would probably make the variance zero. And so therefore the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2211" target="_blank">00:36:51.200</a></span> | <span class="t">latent space would be less diverse and expressive and limit the ability of the decoder to reconstruct</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2216" target="_blank">00:36:56.280</a></span> | <span class="t">the data accurately, make it harder to generate new data that's different from the training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2220" target="_blank">00:37:00.560</a></span> | <span class="t">data, which is exactly what we're trying to do. And if the variance is very high, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2227" target="_blank">00:37:07.000</a></span> | <span class="t">the encoder would be very spread out and diffuse. It would be more, the latents would be more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2231" target="_blank">00:37:11.440</a></span> | <span class="t">noisy and random, make it easier to generate new data that's unrealistic or nonsensical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2239" target="_blank">00:37:19.560</a></span> | <span class="t">Okay. So that's why we want it to be exactly at a particular point. So when we train this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2247" target="_blank">00:37:27.960</a></span> | <span class="t">we can just pass VAE loss as our loss function, but it'd be nice to see how well it's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2253" target="_blank">00:37:33.280</a></span> | <span class="t">at reconstructing the original image and how it's going at creating a zero one distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2262" target="_blank">00:37:42.340</a></span> | <span class="t">data separately. So what I ended up doing was creating just a really simple thing called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2269" target="_blank">00:37:49.660</a></span> | <span class="t">func metric, which I derived from the capital M mean class in the torch, just trying to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2282" target="_blank">00:38:02.400</a></span> | <span class="t">find it here from the torcheval.metrics. So they've already got something that can just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2288" target="_blank">00:38:08.160</a></span> | <span class="t">calculate means. So obviously this stuff's all very simple and we've created our own</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2291" target="_blank">00:38:11.600</a></span> | <span class="t">metrics class ourselves back a while ago. And since we're using torcheval, I thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2295" target="_blank">00:38:15.440</a></span> | <span class="t">this is useful to see how we can create one, a custom metric where you can pass in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2300" target="_blank">00:38:20.640</a></span> | <span class="t">function to call before it calculates the mean. So if you call, so you might remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2308" target="_blank">00:38:28.340</a></span> | <span class="t">that the way torcheval works is it has this thing called update, which gets past the input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2312" target="_blank">00:38:32.400</a></span> | <span class="t">and the targets. So I add to the weighted sum, the result of calling some function on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2319" target="_blank">00:38:39.360</a></span> | <span class="t">the input and the targets. So we want two kind of new metrics. One is the, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2330" target="_blank">00:38:50.080</a></span> | <span class="t">to print it out as KLD, which is a func metric on KLD loss, someone who went to print out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2334" target="_blank">00:38:54.800</a></span> | <span class="t">as BCE, which is a func metric on BCE loss. And so the actual, when we call the learner,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2342" target="_blank">00:39:02.440</a></span> | <span class="t">the loss function we'll use is VAE loss, but we're going to pass in as metrics, this additional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2354" target="_blank">00:39:14.160</a></span> | <span class="t">metrics to print out. So it's just going to print them out. And in some ways it's a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2357" target="_blank">00:39:17.920</a></span> | <span class="t">inefficient because it's going to calculate KLD loss twice and BCE loss twice, one to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2363" target="_blank">00:39:23.000</a></span> | <span class="t">print it out and one to go into the, you know, actual loss function, but it doesn't take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2367" target="_blank">00:39:27.560</a></span> | <span class="t">long for that bit. So I think that's fine. So now when we call learn.fit, you can see</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2373" target="_blank">00:39:33.040</a></span> | <span class="t">it's printing them all out. So the BCE that we got last time was 0.26. And so this time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2382" target="_blank">00:39:42.400</a></span> | <span class="t">yeah, it's not as good. It's 0.31 because it's a harder problem and it's got randomness</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2387" target="_blank">00:39:47.400</a></span> | <span class="t">in it. And you can see here that the BCE and KLD are pretty similar scale when it starts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2396" target="_blank">00:39:56.000</a></span> | <span class="t">That's a good sign. If they weren't, you know, I could always in the loss function scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2401" target="_blank">00:40:01.240</a></span> | <span class="t">one of them up or down, but they're pretty similar to start with. So that's fine. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2406" target="_blank">00:40:06.760</a></span> | <span class="t">we train this for a while and then we can use exactly the same code for sampling as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2412" target="_blank">00:40:12.160</a></span> | <span class="t">before. And yeah, as we suspected, its ability to decode is worse. So it's actually not capturing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2421" target="_blank">00:40:21.240</a></span> | <span class="t">the LE at all, in fact, and the shoes got very blurry. But the hope is that when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2430" target="_blank">00:40:30.280</a></span> | <span class="t">call it on noise called the decoder on random noise, that's much better. We're getting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2436" target="_blank">00:40:36.920</a></span> | <span class="t">it's not amazing, but we are getting some recognizable shapes. So, you know, VAEs are,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2445" target="_blank">00:40:45.080</a></span> | <span class="t">you know, not generally going to get you as good a results as diffusion models are, although</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2452" target="_blank">00:40:52.360</a></span> | <span class="t">actually if you train really good ones for a really long time, they can be pretty impressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2457" target="_blank">00:40:57.240</a></span> | <span class="t">But yeah, even in this extremely simple, quick case, we've got something that can generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2461" target="_blank">00:41:01.800</a></span> | <span class="t">recognizable items of clothing. Did you guys want to add anything before we move on to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2468" target="_blank">00:41:08.520</a></span> | <span class="t">the stable diffusion VAE? Okay. So this VAE is very crappy. And as we mentioned, one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2484" target="_blank">00:41:24.680</a></span> | <span class="t">the key reasons to use a VAE is actually that you can benefit from all the compute time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2490" target="_blank">00:41:30.840</a></span> | <span class="t">that somebody else has put into training a good VAE.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2496" target="_blank">00:41:36.240</a></span> | <span class="t">Just also like one thing when you say good VAE, the one that we've trained here is good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2502" target="_blank">00:41:42.160</a></span> | <span class="t">at generating because it maps down to this like one, two dimensional vector and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2507" target="_blank">00:41:47.040</a></span> | <span class="t">back in a very useful way. And like, if you look at VAEs for generating, they'll often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2512" target="_blank">00:41:52.200</a></span> | <span class="t">have a pretty small dimension in the middle and it'll just be like this vector that gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2517" target="_blank">00:41:57.560</a></span> | <span class="t">mapped back up. And so VAE that's good for generating is slightly different to one that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2521" target="_blank">00:42:01.760</a></span> | <span class="t">good for compressing. And like the stable diffusion one, we'll see has this like special components</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2526" target="_blank">00:42:06.440</a></span> | <span class="t">still, it doesn't map it down to a single vector, it maps it down to 64 by 64 or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2532" target="_blank">00:42:12.840</a></span> | <span class="t">And I think that's smaller than the original, but for generating, we can't just put random</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2537" target="_blank">00:42:17.160</a></span> | <span class="t">noise in there and hope like a cohesive image will come out. So it's less good as a generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2543" target="_blank">00:42:23.920</a></span> | <span class="t">but it is good because it has this like compression and reconstruction ability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2547" target="_blank">00:42:27.480</a></span> | <span class="t">Cool. Yeah. So let's take a look. Now, to demonstrate this, we want to move to a more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2558" target="_blank">00:42:38.120</a></span> | <span class="t">difficult task because we want to show off how using Latents let us do stuff we couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2564" target="_blank">00:42:44.760</a></span> | <span class="t">do well before. So the more difficult task we're going to do is generating bigger images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2573" target="_blank">00:42:53.080</a></span> | <span class="t">and specifically generate images of bedrooms using the L Sun Bedrooms dataset. So L Sun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2581" target="_blank">00:43:01.960</a></span> | <span class="t">is a really nice dataset, which has many, many, many millions of images across 10 scene categories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2597" target="_blank">00:43:17.920</a></span> | <span class="t">and 20 object categories. And so it's very rare for people to use of the object categories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2605" target="_blank">00:43:25.600</a></span> | <span class="t">to be honest, but people quite often use the scene categories. They're a little more than</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2611" target="_blank">00:43:31.440</a></span> | <span class="t">a little can be extremely slow to download is that the website they come from is very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2615" target="_blank">00:43:35.200</a></span> | <span class="t">often down. So what I did was I put a subset of 20% of them onto AWS. They kindly provide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2626" target="_blank">00:43:46.000</a></span> | <span class="t">some free dataset hosting for our students. And also the original L signs in a slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2632" target="_blank">00:43:52.920</a></span> | <span class="t">complicated form. It's in something called an LMDB database. And so I turned them into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2636" target="_blank">00:43:56.520</a></span> | <span class="t">just normal images in folders. So you can download them directly from the AWS dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2644" target="_blank">00:44:04.480</a></span> | <span class="t">site that they've provided for us. So I'm just using fast core to save it and then using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2653" target="_blank">00:44:13.200</a></span> | <span class="t">Python's shutil to unpack the gzipped tar file. Okay. So that's given us once that runs, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2663" target="_blank">00:44:23.520</a></span> | <span class="t">is going to take a long time. And, you know, if it might be, you know, even more reliable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2675" target="_blank">00:44:35.080</a></span> | <span class="t">just to do this in the shell with wget or aria 2c or something than doing it through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2681" target="_blank">00:44:41.240</a></span> | <span class="t">Python. So this will work, but if it's taking a long time or whatever, maybe just delete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2684" target="_blank">00:44:44.760</a></span> | <span class="t">it and do it in the shell instead. Okay. So then I thought, all right, how do we turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2694" target="_blank">00:44:54.880</a></span> | <span class="t">these into Latents? Well, we could create a dataset in the usual ways. It's going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2704" target="_blank">00:45:04.480</a></span> | <span class="t">have a length. So we're going to grab all the files. So glob is a built into Python,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2711" target="_blank">00:45:11.920</a></span> | <span class="t">which we'll search for in this case, star dot jpeg. And if you've got star star slash,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2719" target="_blank">00:45:19.280</a></span> | <span class="t">that's going to search recursively as long as you pass recursive. So we're going to search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2724" target="_blank">00:45:24.480</a></span> | <span class="t">for all of the jpeg files inside our data slash bedroom folder. So that's what this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2736" target="_blank">00:45:36.160</a></span> | <span class="t">going to do. It's going to put them all into the files attribute. And so then when we get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2741" target="_blank">00:45:41.000</a></span> | <span class="t">an item, the ith item, it will find the ith file. It will read that image. So this is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2748" target="_blank">00:45:48.400</a></span> | <span class="t">PyTorch's read image. It's the fastest way to read a jpeg image. People often use PIL,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2758" target="_blank">00:45:58.040</a></span> | <span class="t">but it's quite hard to find a really well optimized PIL version that's really compiled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2763" target="_blank">00:46:03.400</a></span> | <span class="t">fast, whereas the PyTorch Torch Vision team have created a very, very fast read image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2771" target="_blank">00:46:11.320</a></span> | <span class="t">That's why I'm using theirs. And if you pass in image read mode.RGB, it will automatically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2778" target="_blank">00:46:18.600</a></span> | <span class="t">turn any one channel, black and white images, into three channel images for you. Or if there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2783" target="_blank">00:46:23.100</a></span> | <span class="t">are four channel images with transparency, it will turn those. So this is a nice way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2786" target="_blank">00:46:26.960</a></span> | <span class="t">to make sure they're all the same. And then this turns it into floats from not to one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2795" target="_blank">00:46:35.120</a></span> | <span class="t">And these images are generally very close to 256 by 256 pixels. So I just crop out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2800" target="_blank">00:46:40.480</a></span> | <span class="t">the top 250 by 256 bit, because I didn't really care that much. And we do need them to all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2809" target="_blank">00:46:49.000</a></span> | <span class="t">be the same size in order that we can then pass them to the stable diffusion VAE decoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2815" target="_blank">00:46:55.640</a></span> | <span class="t">as a batch. Otherwise it's going to take forever. So I can create a data loader that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2821" target="_blank">00:47:01.680</a></span> | <span class="t">to go through a bunch of them at a time. So 64 at a time. And use however many CPUs I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2830" target="_blank">00:47:10.320</a></span> | <span class="t">have as the number of workers. It's going to do it in parallel. And so the parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2836" target="_blank">00:47:16.000</a></span> | <span class="t">bit is the bit that's actually reading the JPEGs, which is otherwise going to be pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2841" target="_blank">00:47:21.000</a></span> | <span class="t">slow. So if we grab a batch, here it is. Here's what it looks like. Generally speaking, they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2847" target="_blank">00:47:27.000</a></span> | <span class="t">just bedrooms, although we've got one pretty risque situation in the bedroom. But on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2852" target="_blank">00:47:32.280</a></span> | <span class="t">whole, they're not safe for work. This is the first time I've actually seen an actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2856" target="_blank">00:47:36.720</a></span> | <span class="t">bedroom scene taking place, as it were. All right. So as you can see, this mini batch</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2864" target="_blank">00:47:44.320</a></span> | <span class="t">of, if I just grab the first 16 images, has three channels and 256 by 256 pixels. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2876" target="_blank">00:47:56.560</a></span> | <span class="t">how big that is for 16 images. So that's 728. So 3.145 million floats to represent this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2890" target="_blank">00:48:10.120</a></span> | <span class="t">Okay. So as we learned in the first lesson of part two, we can grab an autoencoder directly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2900" target="_blank">00:48:20.080</a></span> | <span class="t">using diffusers using from pre-trained. We can pop it onto our GPU. And importantly,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2908" target="_blank">00:48:28.320</a></span> | <span class="t">we don't have to say with torch.nograd anymore if we pass requires grad false. And remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2915" target="_blank">00:48:35.720</a></span> | <span class="t">this neat trick in PyTorch, if it ends in an underscore, it actually changes the thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2919" target="_blank">00:48:39.840</a></span> | <span class="t">that you're calling in place. So this is going to stop it from computing gradients, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2925" target="_blank">00:48:45.040</a></span> | <span class="t">would take a lot of time and a lot of memory otherwise. So let's test it out. Let's encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2932" target="_blank">00:48:52.760</a></span> | <span class="t">our mini batch. And so just like Johnno was saying, this has now made it much smaller.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2938" target="_blank">00:48:58.920</a></span> | <span class="t">It's got just in our 16 batch of 16, it's now a four channel 32 by 32. So if we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2946" target="_blank">00:49:06.480</a></span> | <span class="t">compare the previous size to the new size, it's 48 times smaller. So that's 48 times</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2953" target="_blank">00:49:13.960</a></span> | <span class="t">less memory it's going to need. And it's also going to be a lot less compute for a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2959" target="_blank">00:49:19.360</a></span> | <span class="t">to go across that image. So it's no good unless we can turn it back into the original image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2966" target="_blank">00:49:26.520</a></span> | <span class="t">So let's just have a look at what it looks like first. Now it's a four channel image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2969" target="_blank">00:49:29.540</a></span> | <span class="t">so we can't naturally look at it. But what I could do is just grab the first three channels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2976" target="_blank">00:49:36.600</a></span> | <span class="t">And then they're not going to be between 0 and 1. So if I just do dot sigmoid, now they're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2981" target="_blank">00:49:41.320</a></span> | <span class="t">between 0 and 1. And so you can see that our risque bedroom scene, you can still recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2986" target="_blank">00:49:46.540</a></span> | <span class="t">it. Or this bedroom, this bed here, you can still recognize it. So there's still that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=2993" target="_blank">00:49:53.400</a></span> | <span class="t">kind of like the basic geometry is still clearly there. But it's, yeah, it's clearly changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3000" target="_blank">00:50:00.840</a></span> | <span class="t">it a lot as well. So importantly, we can call decode on this 48 times smaller tensor. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3013" target="_blank">00:50:13.560</a></span> | <span class="t">it's really, I think, absolutely remarkable how good it is. I can't tell the difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3022" target="_blank">00:50:22.840</a></span> | <span class="t">to the original. Maybe if I zoom in a bit. Her face is a bit blurry. Was her face always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3034" target="_blank">00:50:34.760</a></span> | <span class="t">a bit blurry? No, it was always a bit blurry. First, second, third. Oh, hang on. Did that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3044" target="_blank">00:50:44.760</a></span> | <span class="t">used to look like a proper ND? Yeah, OK. So you can see this used to say that clearly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3049" target="_blank">00:50:49.360</a></span> | <span class="t">there's an ND here. And now you can't see those letters. So and this is actually a classic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3056" target="_blank">00:50:56.800</a></span> | <span class="t">thing that's known for this particular VAE is it's not able to regenerate writing correctly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3066" target="_blank">00:51:06.260</a></span> | <span class="t">at small font sizes. I think it's also pretty it's like I think we hear with the faces are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3072" target="_blank">00:51:12.360</a></span> | <span class="t">already pretty low resolution. But if you are at a higher resolution, the faces also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3076" target="_blank">00:51:16.320</a></span> | <span class="t">would probably not be converted appropriately. OK, cool. But overall, yeah, it's done a great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3084" target="_blank">00:51:24.400</a></span> | <span class="t">job. A couple of other things I wanted to note was like, so like you mentioned, like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3089" target="_blank">00:51:29.440</a></span> | <span class="t">a 40, I guess a factor of 48 degrees. Oftentimes people refer to mostly at the spatial resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3097" target="_blank">00:51:37.280</a></span> | <span class="t">So since it's going from 256 by 256 to 32 by 32. So that's like a factor of eight. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3105" target="_blank">00:51:45.200</a></span> | <span class="t">they sometimes will know, like, I think it's like F8 or something like this. They'll note</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3108" target="_blank">00:51:48.720</a></span> | <span class="t">the spatial resolution. So sometimes you may see that written out like that. And of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3114" target="_blank">00:51:54.760</a></span> | <span class="t">it is an eight squared decrease in the number of pixels, which is interesting. Right. Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3122" target="_blank">00:52:02.200</a></span> | <span class="t">And then the other thing I want to note was that the VAE is also trained with with a perceptual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3129" target="_blank">00:52:09.480</a></span> | <span class="t">loss objective, as well as technically like a like a discriminator, again, objective.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3136" target="_blank">00:52:16.840</a></span> | <span class="t">I don't know if you were going to go into that later now. So, yeah, so perceptual loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3142" target="_blank">00:52:22.440</a></span> | <span class="t">we've we've already discussed. Right. So the VAE is going to you know, when they trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3148" target="_blank">00:52:28.520</a></span> | <span class="t">it. So I think this was trained by Compviz, right, the, you know, Robin and Gang and used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3160" target="_blank">00:52:40.200</a></span> | <span class="t">stability.ai donated compute for that. And they went to be clear, actually, no, the VAE</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3168" target="_blank">00:52:48.160</a></span> | <span class="t">was actually trained separately. And it's actually a train on the open images data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3173" target="_blank">00:52:53.320</a></span> | <span class="t">And it was just this VAE that they trained by themselves on, you know, a small subset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3178" target="_blank">00:52:58.280</a></span> | <span class="t">of data. But because the VAE is so powerful, it's actually able to be applied to all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3184" target="_blank">00:53:04.360</a></span> | <span class="t">other data sets as well. Okay, great. Yeah. So they so they would have had a KL diversion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3193" target="_blank">00:53:13.960</a></span> | <span class="t">loss and they would have either had an MSC or BCE loss. I think it might have been an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3197" target="_blank">00:53:17.480</a></span> | <span class="t">MSC loss. They also had a perceptual loss, which is the thing we learned about when we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3202" target="_blank">00:53:22.880</a></span> | <span class="t">talked about super resolution, which is where when they compared the the output images to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3210" target="_blank">00:53:30.080</a></span> | <span class="t">the original images, they would have run that through a, you know, ImageNet trained or similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3218" target="_blank">00:53:38.440</a></span> | <span class="t">classifier and confirmed that the activations they got through that model was similar. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3225" target="_blank">00:53:45.560</a></span> | <span class="t">then the final bit is as Tanisha was mentioning is the adversarial loss, which is also known</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3235" target="_blank">00:53:55.280</a></span> | <span class="t">as a as a GAN loss. So a GAN is a generative adversarial network. And the GAN loss what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3246" target="_blank">00:54:06.040</a></span> | <span class="t">it does is it grabs it is actually more specifically what's called a patchwise GAN loss. And what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3257" target="_blank">00:54:17.800</a></span> | <span class="t">it does is it takes like a little section of an image. Right. And what they've done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3266" target="_blank">00:54:26.200</a></span> | <span class="t">is they train it's let's just simplify it for a moment and imagine that they've pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3272" target="_blank">00:54:32.120</a></span> | <span class="t">a classifier, right, where they've basically got something that you can pass it a real,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3278" target="_blank">00:54:38.680</a></span> | <span class="t">you know, patch from a bedroom scene and a and a fake patch from a bedroom scene. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3293" target="_blank">00:54:53.400</a></span> | <span class="t">they both go into the what's called the discriminator. And this is just a normal, you know, ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3308" target="_blank">00:55:08.160</a></span> | <span class="t">or whatever, which basically outputs something that either says, yep, the the image is real</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3322" target="_blank">00:55:22.040</a></span> | <span class="t">or nope, the image is fake. So sorry, I said it passes in two things. You just that was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3326" target="_blank">00:55:26.640</a></span> | <span class="t">wrong. You just pass in one thing and it returns either it's real or it's fake. And specifically,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3330" target="_blank">00:55:30.880</a></span> | <span class="t">it's going to give you something like the probability that it's real. There is another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3336" target="_blank">00:55:36.440</a></span> | <span class="t">version. I don't think it's what they use. You pass in two and it tells you which one's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3340" target="_blank">00:55:40.080</a></span> | <span class="t">relative. Do you remember Tanisha? Is it a relativistic GAN or a normal GAN? I think it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3345" target="_blank">00:55:45.160</a></span> | <span class="t">a normal one. Yeah. So the realistic GAN is when you pass in two images and it says which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3349" target="_blank">00:55:49.000</a></span> | <span class="t">is more real. The one we think that we remember correctly, they use as a regular GAN, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3354" target="_blank">00:55:54.000</a></span> | <span class="t">just tells you the probability that it's real. And so you can just train that by passing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3359" target="_blank">00:55:59.600</a></span> | <span class="t">in real images and fake images and having it learn to classify which ones are real and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3364" target="_blank">00:56:04.520</a></span> | <span class="t">which ones are fake. So now that once you've got that model trained, then as you train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3372" target="_blank">00:56:12.160</a></span> | <span class="t">your GAN, you pass in the patches of each image into the discriminator. So let's call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3381" target="_blank">00:56:21.480</a></span> | <span class="t">D here, right? And it's going to spit out the probability that that's real. And so if it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3389" target="_blank">00:56:29.120</a></span> | <span class="t">spat out 0.1 or something, then you're like, oh, dear, that's terrible. Our VAE is spitting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3398" target="_blank">00:56:38.580</a></span> | <span class="t">out pictures of bedrooms where the patches of it are easily recognized as not real. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3405" target="_blank">00:56:45.560</a></span> | <span class="t">the good news is that's going to generate derivatives, right? And so those derivatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3411" target="_blank">00:56:51.320</a></span> | <span class="t">then is going to tell you how to change the pixels of the original generated image to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3417" target="_blank">00:56:57.480</a></span> | <span class="t">make it trick the GAN better. And so what it will do is it will then use those derivatives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3425" target="_blank">00:57:05.280</a></span> | <span class="t">as per usual to update our VAE. And the VAE in this case is going to be called a generator,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3436" target="_blank">00:57:16.120</a></span> | <span class="t">right? That's the thing that's generating the pixels. And so the generator gets updated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3441" target="_blank">00:57:21.360</a></span> | <span class="t">to be better and better at tricking the discriminator. And after a while, what's going to happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3447" target="_blank">00:57:27.540</a></span> | <span class="t">is the generator is going to get so good that the discriminator gets fooled every time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3452" target="_blank">00:57:32.920</a></span> | <span class="t">right? And so then at that point, you can fine-tune the discriminator better by putting in your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3459" target="_blank">00:57:39.880</a></span> | <span class="t">better generated images, right? And then once your discriminator learns again how to recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3464" target="_blank">00:57:44.960</a></span> | <span class="t">the difference between real and fake, you can then use it to train the generator. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3470" target="_blank">00:57:50.600</a></span> | <span class="t">so this is kind of ping-ponging back and forth between the discriminator and the generator.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3476" target="_blank">00:57:56.120</a></span> | <span class="t">Like when GANs were first created, people were finding them very difficult to train. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3484" target="_blank">00:58:04.040</a></span> | <span class="t">actually a method we developed at Fast AI, I don't know if we were the first to do it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3488" target="_blank">00:58:08.520</a></span> | <span class="t">or not, was this idea of kind of pre-training a generator just using perceptual loss and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3496" target="_blank">00:58:16.160</a></span> | <span class="t">then pre-training a discriminator to be able to fool the generator and then ping-ponging</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3500" target="_blank">00:58:20.320</a></span> | <span class="t">backwards and forwards between them. After that, basically whenever the discriminator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3505" target="_blank">00:58:25.480</a></span> | <span class="t">got too good, start using the generator. Anytime the generator got too good, start using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3510" target="_blank">00:58:30.360</a></span> | <span class="t">discriminator. Nowadays, that's pretty standard, I think, to do it this way. And so, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3518" target="_blank">00:58:38.560</a></span> | <span class="t">this GAN loss, which is basically saying penalize for failing to fool the discriminator is called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3527" target="_blank">00:58:47.040</a></span> | <span class="t">an adversarial loss. To maybe motivate why you do this, if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3539" target="_blank">00:58:59.000</a></span> | <span class="t">just did it with a mean squared error or even a perceptual loss with such a high compression</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3545" target="_blank">00:59:05.880</a></span> | <span class="t">ratio, the VAEs tend to produce a fairly blurry output because it's not sure whether there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3551" target="_blank">00:59:11.200</a></span> | <span class="t">texture or not in this image or the edges aren't super well defined where they'll be because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3557" target="_blank">00:59:17.520</a></span> | <span class="t">it's going from one four-dimensional thing up to this whole patch of the image. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3564" target="_blank">00:59:24.800</a></span> | <span class="t">it tends to be a little bit blurry and hazy because it's kind of hedging its bets, whereas</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3569" target="_blank">00:59:29.980</a></span> | <span class="t">that's something that the discriminator can quite easily pick up. Oh, it's blurry. It must</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3574" target="_blank">00:59:34.760</a></span> | <span class="t">be fake. And so then it's having the discriminator, that is adversarial loss, is just kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3579" target="_blank">00:59:39.480</a></span> | <span class="t">saying, even if you're not sure exactly where this texture goes, rather go with a sharper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3583" target="_blank">00:59:43.920</a></span> | <span class="t">looking texture that looks real than with some blurry thing that's going to maximize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3589" target="_blank">00:59:49.920</a></span> | <span class="t">your MSE. And so it tricks it into kind of faking this higher resolution looking sharper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3596" target="_blank">00:59:56.600</a></span> | <span class="t">output. Yeah. And I'm not sure if we're going to come</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3602" target="_blank">01:00:02.400</a></span> | <span class="t">back and train our own GAN at some point, but if you're interested in training your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3610" target="_blank">01:00:10.660</a></span> | <span class="t">own GAN or-- you shouldn't call it a GAN, right? I mean, nowadays, we never really just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3617" target="_blank">01:00:17.080</a></span> | <span class="t">use a GAN. We have an adversarial loss as part of a training process. So if you want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3621" target="_blank">01:00:21.160</a></span> | <span class="t">to learn how to use adversarial loss in detail and see the code, the 2019 FastAI course Less</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3628" target="_blank">01:00:28.520</a></span> | <span class="t">than 7 at part 1 has a walkthrough. So we have sample code there. And maybe given time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3635" target="_blank">01:00:35.400</a></span> | <span class="t">we'll come back to it. OK. So quite often, people will call the VAE</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3649" target="_blank">01:00:49.680</a></span> | <span class="t">encoder when they're training a model, which to me makes no sense, right? Because the encoded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3655" target="_blank">01:00:55.360</a></span> | <span class="t">version of an image never changes unless you are using data augmentation and want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3661" target="_blank">01:01:01.360</a></span> | <span class="t">augmentation on-- sorry, to encode augmented images. I think it makes a lot more sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3667" target="_blank">01:01:07.520</a></span> | <span class="t">to just do a single run through your whole training set and encode everything once. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3673" target="_blank">01:01:13.800</a></span> | <span class="t">naturally, the question is then, well, where do you save that? Because it's going to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3677" target="_blank">01:01:17.040</a></span> | <span class="t">a lot of RAM. If you put this, leave it in RAM. And also, as soon as you restart your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3682" target="_blank">01:01:22.040</a></span> | <span class="t">computer, we've lost all that work. There's a very nifty file format you can use called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3687" target="_blank">01:01:27.680</a></span> | <span class="t">a memory mapped numpy file, which is what I'm going to use to save our latency. A memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3696" target="_blank">01:01:36.000</a></span> | <span class="t">mapped numpy file is basically-- what happens is you take the memory in RAM that numpy would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3704" target="_blank">01:01:44.480</a></span> | <span class="t">normally be using, and you literally copy it onto the hard disk, basically. That's what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3713" target="_blank">01:01:53.560</a></span> | <span class="t">they mean by memory mapped. There's a mapping between the memory in RAM and the memory in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3718" target="_blank">01:01:58.800</a></span> | <span class="t">hard disk. And if you change one, it changes the other, and vice versa. They're kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3722" target="_blank">01:02:02.200</a></span> | <span class="t">two ways of seeing the same thing. And so if you create a memory mapped numpy array,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3730" target="_blank">01:02:10.280</a></span> | <span class="t">then when you modify it, it's actually modifying it on disk. But thanks to the magic of your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3736" target="_blank">01:02:16.120</a></span> | <span class="t">operating system, it's using all kinds of beautiful caching and stuff to not make that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3742" target="_blank">01:02:22.620</a></span> | <span class="t">slower than using a normal numpy array. And it's going to be very clever at-- it doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3751" target="_blank">01:02:31.680</a></span> | <span class="t">have to store it all in RAM. It only stores the bits in RAM that you need at the moment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3756" target="_blank">01:02:36.360</a></span> | <span class="t">or that you've used recently. It's really nifty at caching and stuff. So it's kind of--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3761" target="_blank">01:02:41.360</a></span> | <span class="t">it's like magic, but it's using your operating system to do that magic for you. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3766" target="_blank">01:02:46.760</a></span> | <span class="t">going to create a memory mapped file using np.memmap. And so it's going to be stored somewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3773" target="_blank">01:02:53.660</a></span> | <span class="t">on your disk. So we're just going to put it here. And we're going to say, OK, so create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3778" target="_blank">01:02:58.840</a></span> | <span class="t">a memory map file in this place. It's going to contain 32-bit floats. So write the file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3786" target="_blank">01:03:06.000</a></span> | <span class="t">And the shape of this array is going to be the size of our data set, so 303,125 images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3793" target="_blank">01:03:13.840</a></span> | <span class="t">And each one is 4 by 32 by 32. OK. So that's our memory mapped file. And so now we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3802" target="_blank">01:03:22.200</a></span> | <span class="t">to go through our data loader, one mini batch of 24 at a time. And we're going to VAE encode</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3812" target="_blank">01:03:32.120</a></span> | <span class="t">that mini batch. And then we're going to grab the means from its latency. We don't want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3820" target="_blank">01:03:40.000</a></span> | <span class="t">random numbers. We want the actual midpoints, the means. So this is using the diffusers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3828" target="_blank">01:03:48.200</a></span> | <span class="t">version of that VAE. So pop that onto the CPU after we're done. And so that's going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3835" target="_blank">01:03:55.120</a></span> | <span class="t">to be mini batch of size 64 as PyTorch. Let's turn that into NumPy because PyTorch doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3841" target="_blank">01:04:01.360</a></span> | <span class="t">have a memory mapped thing, as far as I'm aware, but NumPy does. And so now that we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3845" target="_blank">01:04:05.480</a></span> | <span class="t">got this memory mapped array called a, then everything initially from 0 up to 64, not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3858" target="_blank">01:04:18.120</a></span> | <span class="t">including the 64, that whole sub part of the array is going to be set to the encoded version.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3864" target="_blank">01:04:24.040</a></span> | <span class="t">So it looks like we're just changing it in memory. But because this is a magic memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3870" target="_blank">01:04:30.160</a></span> | <span class="t">mapped file, it's actually going to save it to disk as well. So yeah, that's it. Amazingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3876" target="_blank">01:04:36.840</a></span> | <span class="t">enough. That's all you need to create a memory mapped NumPy array of our latents. When you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3883" target="_blank">01:04:43.120</a></span> | <span class="t">done, you actually have to call dot flush. And that's just something that says like anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3887" target="_blank">01:04:47.200</a></span> | <span class="t">that's just in cache at the moment, make sure it's actually written to disk. And then I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3893" target="_blank">01:04:53.760</a></span> | <span class="t">delete it because I just want to make sure that then I read it back correctly. So that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3898" target="_blank">01:04:58.720</a></span> | <span class="t">only going to happen once if the path doesn't exist. And then after that, this whole thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3904" target="_blank">01:05:04.120</a></span> | <span class="t">will be skipped. And instead, we're going to call mp.memmap again with an M path. But this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3909" target="_blank">01:05:09.640</a></span> | <span class="t">time in the same data type, the same shape, this time we're going to read it. Mode equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3914" target="_blank">01:05:14.400</a></span> | <span class="t">R means read it. And so let's check it. Let's just grab the first 16 latents that we read</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3924" target="_blank">01:05:24.000</a></span> | <span class="t">and decode them. And there they are. OK. So this is like not a very well-known technique,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3934" target="_blank">01:05:34.960</a></span> | <span class="t">I would say, sadly. But it's a really good one. You might be wondering like, well, what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3941" target="_blank">01:05:41.240</a></span> | <span class="t">about like compression? Like shouldn't you be zipping them or something like that? But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3945" target="_blank">01:05:45.720</a></span> | <span class="t">actually remember, these latents are already-- the whole point is they're highly compressed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3952" target="_blank">01:05:52.200</a></span> | <span class="t">So generally speaking, zipping latents from a good VAE doesn't do much. Because they almost</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3961" target="_blank">01:06:01.400</a></span> | <span class="t">look a bit random number-ish. OK. So we've now saved our entire LSUN bedroom. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3969" target="_blank">01:06:09.560</a></span> | <span class="t">a 20% subset, the bit that I've provided. Now, Latents. So we can now run it through--</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3978" target="_blank">01:06:18.040</a></span> | <span class="t">this is a nice thing. We can use exactly the same process from here on in as usual. OK.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3983" target="_blank">01:06:23.560</a></span> | <span class="t">So we've got the Noiser 5 of our usual collated version. Now, the Latents are much higher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3994" target="_blank">01:06:34.880</a></span> | <span class="t">than 1 standard deviation. So if we about divide it by 5, that takes it back to a standard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=3999" target="_blank">01:06:39.080</a></span> | <span class="t">deviation of about 1. I think in the paper they use like 0.18 or something. But this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4007" target="_blank">01:06:47.120</a></span> | <span class="t">is close enough to make it a unit standard deviation. So we can split it into a training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4014" target="_blank">01:06:54.960</a></span> | <span class="t">and a validation set. So just grab the first 90% of the training set and the last 10% for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4021" target="_blank">01:07:01.080</a></span> | <span class="t">the validation set. So those are our data sets. We use a batch size of 128. So now we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4027" target="_blank">01:07:07.620</a></span> | <span class="t">can use our data loaders class we created with the getDLs we created. So these are all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4031" target="_blank">01:07:11.520</a></span> | <span class="t">things we've created ourselves with the training set, the validation set, the batch size, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4037" target="_blank">01:07:17.680</a></span> | <span class="t">our collation function. So yeah, it's kind of nice. It's amazing how easy it is. A data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4046" target="_blank">01:07:26.360</a></span> | <span class="t">set has the same interface as a NumPy array or a list or whatever. So we can literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4054" target="_blank">01:07:34.260</a></span> | <span class="t">just use the NumPy array directly as a data set, which I think is really neat. This is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4060" target="_blank">01:07:40.120</a></span> | <span class="t">why it's useful to know about these foundational concepts, because you don't have to start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4065" target="_blank">01:07:45.400</a></span> | <span class="t">thinking like, oh, I wonder if there's some torch vision thing to use memmap NumPy files</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4070" target="_blank">01:07:50.720</a></span> | <span class="t">or something. It's like, oh, wait, they already do provide a data set interface. I don't have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4075" target="_blank">01:07:55.040</a></span> | <span class="t">to do anything. I just use them. So that's pretty magical. So we can test that now by</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4082" target="_blank">01:08:02.000</a></span> | <span class="t">grabbing a batch. And so this is being noisified. And so here we can see our noisified images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4090" target="_blank">01:08:10.040</a></span> | <span class="t">And so here's something crazy is that we can actually decode noisified images. And so here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4099" target="_blank">01:08:19.600</a></span> | <span class="t">I guess this one wasn't noisified much because it's a recognizable bedroom. And this is what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4104" target="_blank">01:08:24.040</a></span> | <span class="t">happens when you just decode random noise, something in between. So I think that's pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4110" target="_blank">01:08:30.320</a></span> | <span class="t">fun. Yeah, this next bit is all just copied from our previous notebook, create a model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4119" target="_blank">01:08:39.360</a></span> | <span class="t">organize it, train for a while. So this took me a few hours on a single GPU. Everything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4125" target="_blank">01:08:45.000</a></span> | <span class="t">I'm doing is on a single GPU. Literally nothing in this course, other than the stable diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4130" target="_blank">01:08:50.000</a></span> | <span class="t">stuff itself is trained on more than one GPU. The loss is much higher than usual. And that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4137" target="_blank">01:08:57.600</a></span> | <span class="t">not surprising because it's trying to generate latent pixels, which rare like it's much more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4145" target="_blank">01:09:05.360</a></span> | <span class="t">precise as to exactly what it wants. There's not like lots of pixels where the ones next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4151" target="_blank">01:09:11.200</a></span> | <span class="t">to each other are really similar or the whole background looks the same or whatever. A lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4155" target="_blank">01:09:15.200</a></span> | <span class="t">of that stuff, it's been compressed out. It's a more difficult thing to predict latent pixels.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4164" target="_blank">01:09:24.240</a></span> | <span class="t">So now we can sample from it in exactly the same way that we always have using DDIM. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4169" target="_blank">01:09:29.920</a></span> | <span class="t">now we need to make sure that we decode it, because the thing that it's sampled are latents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4179" target="_blank">01:09:39.280</a></span> | <span class="t">because the thing that we asked it to learn to predict are latents. And so now we can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4185" target="_blank">01:09:45.640</a></span> | <span class="t">take a look and we have bedrooms. And some of them look pretty good. I think this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4194" target="_blank">01:09:54.860</a></span> | <span class="t">looks pretty good. I think this one looks pretty good. This one, I don't have any idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4199" target="_blank">01:09:59.760</a></span> | <span class="t">what it is. And this one, like clearly there's bedroomy bits, but there's something, I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4207" target="_blank">01:10:07.480</a></span> | <span class="t">know, there's weird bits. So the fact that we're able to create 256 by 256 pixel images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4217" target="_blank">01:10:17.840</a></span> | <span class="t">where at least some of them look quite good in a couple of hours, I can't remember how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4223" target="_blank">01:10:23.340</a></span> | <span class="t">long it took to train, but it's a small number of hours in a single GPU is something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4226" target="_blank">01:10:26.520</a></span> | <span class="t">was not previously possible. And we're in a sense, we're totally cheating because we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4233" target="_blank">01:10:33.360</a></span> | <span class="t">using the stable diffusion VAE to do a lot of the hard work for us. But that's fine,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4240" target="_blank">01:10:40.720</a></span> | <span class="t">you know, because that VAE knows how to create all kinds of natural images and drawings and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4245" target="_blank">01:10:45.600</a></span> | <span class="t">portraits and royal paintings or whatever. So you can, I think, work in that latent space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4253" target="_blank">01:10:53.720</a></span> | <span class="t">quite comfortably. Yeah. Do you guys have anything you wanted to add about that? Oh, actually,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4261" target="_blank">01:11:01.280</a></span> | <span class="t">Tanishka, you've trained this for longer. I only trained it for 25 epochs. How long did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4266" target="_blank">01:11:06.160</a></span> | <span class="t">you, how many hours did you train it for? Cause you did, you did a hundred epochs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4270" target="_blank">01:11:10.200</a></span> | <span class="t">Yes, I did a hundred epochs. I didn't keep trying exactly, but I think it was about 15</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4274" target="_blank">01:11:14.400</a></span> | <span class="t">hours on an A100. A single A100. Yeah. I argued, I mean, the results, yeah, I'll show it. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4283" target="_blank">01:11:23.680</a></span> | <span class="t">I guess maybe slightly better, but you know, I guess you can, I see maybe. No, it is definitely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4294" target="_blank">01:11:34.360</a></span> | <span class="t">slightly better. The good ones are certainly slightly better. Yeah. Yeah. Like the bottom</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4298" target="_blank">01:11:38.760</a></span> | <span class="t">left one is better than any of mine, I think. So it's possible. Maybe at this point, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4303" target="_blank">01:11:43.520</a></span> | <span class="t">just may need to use more data, I guess, cause I guess we were using a 20% subset. So maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4308" target="_blank">01:11:48.560</a></span> | <span class="t">having more of that data to provide more diversity or something like that, maybe that might help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4313" target="_blank">01:11:53.000</a></span> | <span class="t">Yeah. Or maybe, have you tried doing the diffusers one for a hundred? No, I'm using this. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4320" target="_blank">01:12:00.360</a></span> | <span class="t">Our code here. Yeah. So I've got, all right. So I'll share my screen if you want to stop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4326" target="_blank">01:12:06.000</a></span> | <span class="t">sharing yours. So I do have, if we get around to this, maybe we can add the results back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4337" target="_blank">01:12:17.440</a></span> | <span class="t">to this notebook. Cause I do have a version that uses diffusers. So everything else is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4341" target="_blank">01:12:21.840</a></span> | <span class="t">identical. 25 epochs, except for the model for the previous one, I was using our, our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4351" target="_blank">01:12:31.920</a></span> | <span class="t">own MBU net model. So I have to change the channels now to four and a number of filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4357" target="_blank">01:12:37.760</a></span> | <span class="t">I think I might've increased it a bit. So then I tried using, yeah, the diffusers unit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4366" target="_blank">01:12:46.400</a></span> | <span class="t">with whatever their defaults were. And so I got, what did I get here? 243 with diffusers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4374" target="_blank">01:12:54.240</a></span> | <span class="t">I got a little bit better, 239. And yeah, I don't know if they're obviously better or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4387" target="_blank">01:13:07.160</a></span> | <span class="t">not. Like, this is a bit weird. I think like, actually, another thing we could try maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4397" target="_blank">01:13:17.000</a></span> | <span class="t">is do a hundred epochs, but use the diffusers number of channels and stuff that they used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4403" target="_blank">01:13:23.040</a></span> | <span class="t">for. Cause I think the defaults that they use actually for diffusers is not the same</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4406" target="_blank">01:13:26.800</a></span> | <span class="t">as stable diffusion. So maybe we could try stable diffusion, matched unit for a hundred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4412" target="_blank">01:13:32.080</a></span> | <span class="t">epochs. And if we get any nice results, maybe we can paste them into the bottom to show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4416" target="_blank">01:13:36.400</a></span> | <span class="t">people. Yeah. Yeah. Cool. Yeah. Do you guys have anything else to add at this point? All</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4429" target="_blank">01:13:49.600</a></span> | <span class="t">right. So I'll just mention one more thought in terms of like a bit of a interesting project</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4436" target="_blank">01:13:56.680</a></span> | <span class="t">people could play with. I don't know if this is too crazy. I don't think it's been done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4442" target="_blank">01:14:02.680</a></span> | <span class="t">before, but my thought was like, there was a huge difference in our super resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4448" target="_blank">01:14:08.720</a></span> | <span class="t">Do you remember a huge difference in our super resolution results when we used a pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4452" target="_blank">01:14:12.840</a></span> | <span class="t">model and when we used perceptual loss, but particularly when we used a pre-trained model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4462" target="_blank">01:14:22.560</a></span> | <span class="t">I thought we could use a pre-trained model, but we would need a pre-trained latent model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4467" target="_blank">01:14:27.240</a></span> | <span class="t">right? We would want something where our, you know, downsampling backbone was pre-trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4475" target="_blank">01:14:35.120</a></span> | <span class="t">model on latents. And so I just want to just show you what I've done and you guys, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4480" target="_blank">01:14:40.560</a></span> | <span class="t">know, if anybody watching wanted to try taking this further, I've just done the first bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4485" target="_blank">01:14:45.960</a></span> | <span class="t">for you to give you a sense, which is I've pre-trained an image net model, not tiny image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4489" target="_blank">01:14:49.960</a></span> | <span class="t">net, but a full image net model on latents as a classifier. And if you use this as a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4496" target="_blank">01:14:56.120</a></span> | <span class="t">backbone, you know, and also try maybe some of the other tricks that we found helpful,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4500" target="_blank">01:15:00.400</a></span> | <span class="t">like having res nets on the cross connections. These are all things that I don't think anybody's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4504" target="_blank">01:15:04.520</a></span> | <span class="t">done before. I don't know, the scientific literature is vast and I might've missed it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4509" target="_blank">01:15:09.160</a></span> | <span class="t">but I've not come across anybody do these tricks before. So obviously like we're, one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4516" target="_blank">01:15:16.880</a></span> | <span class="t">of the interesting parts of this, which is designed to be challenging is that we're using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4521" target="_blank">01:15:21.400</a></span> | <span class="t">bigger datasets now, but they're datasets that you can absolutely like run on a single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4527" target="_blank">01:15:27.000</a></span> | <span class="t">GPU, you know, a few tens of gigabytes, which fits on any modern hard drive easily. So these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4537" target="_blank">01:15:37.400</a></span> | <span class="t">like are good tests of your ability to kind of like move things around. And if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4543" target="_blank">01:15:43.080</a></span> | <span class="t">somewhere that doesn't have access to a decent internet connection or whatever, this might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4547" target="_blank">01:15:47.160</a></span> | <span class="t">be out of the question, in which case don't worry about it. But if you can, yes, try this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4552" target="_blank">01:15:52.080</a></span> | <span class="t">because it's good practice, I think, to make sure you can use these larger datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4559" target="_blank">01:15:59.500</a></span> | <span class="t">So image net itself, you can actually grab from Kaggle nowadays. So they call it the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4566" target="_blank">01:16:06.240</a></span> | <span class="t">object localization challenge, but actually this contains the full image net dataset or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4572" target="_blank">01:16:12.040</a></span> | <span class="t">the version that's used for the image net competition. So I think people generally call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4577" target="_blank">01:16:17.360</a></span> | <span class="t">that one case. You just have to accept the terms because that has like some distribution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4582" target="_blank">01:16:22.740</a></span> | <span class="t">terms. Yeah, exactly. So you've got to kind of sign in and then join the competition and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4588" target="_blank">01:16:28.040</a></span> | <span class="t">then yeah, accept the terms. So you can then download the dataset or you can also download</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4595" target="_blank">01:16:35.520</a></span> | <span class="t">it from Hugging Face. It'll be in a somewhat different format, but that'll work as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4604" target="_blank">01:16:44.240</a></span> | <span class="t">So I think I grabbed my version from Kaggle. So on Kaggle, you know, it's just a zip file,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4609" target="_blank">01:16:49.720</a></span> | <span class="t">you unzip it and it creates an ILSVRC directory, which I think is what they called the competition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4618" target="_blank">01:16:58.440</a></span> | <span class="t">Yeah, image net, large-scale visual recognition challenge. Okay. So then inside there, there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4627" target="_blank">01:17:07.320</a></span> | <span class="t">is a data and inside there, there is a CLS lock and that's actually where the, that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4631" target="_blank">01:17:11.400</a></span> | <span class="t">where actually everything's going to be. So just like before, I wanted to turn these all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4636" target="_blank">01:17:16.680</a></span> | <span class="t">into Latents. So I created in that directory, I created a Latents subdirectory and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4642" target="_blank">01:17:22.360</a></span> | <span class="t">time partly just to demonstrate how these things work, I wanted to do it a slightly different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4647" target="_blank">01:17:27.000</a></span> | <span class="t">way. Okay. So again, we're going to create our pre-trained VAE, pop it on the GPU, turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4654" target="_blank">01:17:34.280</a></span> | <span class="t">off gradients for it and I'm going to create a dataset. Now, one thing that's a bit weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4660" target="_blank">01:17:40.200</a></span> | <span class="t">about this is that because this is really quite a big dataset, like it's got 1.3 million</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4669" target="_blank">01:17:49.520</a></span> | <span class="t">files, the thing where we go glob star star slash star dot JPEG takes a few seconds, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4677" target="_blank">01:17:57.800</a></span> | <span class="t">know, and particularly if you're doing this on like, you know, an AWS file system or something,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4685" target="_blank">01:18:05.000</a></span> | <span class="t">it can take really quite a long time. On mine, it only took like three seconds, but I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4689" target="_blank">01:18:09.320</a></span> | <span class="t">want to wait three seconds. So I, you know, a common trick for these kinds of big things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4693" target="_blank">01:18:13.940</a></span> | <span class="t">is to create a cache, which is literally just a list of the files. So that's what this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4699" target="_blank">01:18:19.560</a></span> | <span class="t">this is. So I decided that Z pickle means a gzipped pickle. So what I do is if, if, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4705" target="_blank">01:18:25.680</a></span> | <span class="t">the cache exists, we just gzip dot open the files. If it doesn't, we use glob exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4712" target="_blank">01:18:32.760</a></span> | <span class="t">like before to find all the files. And then we also save a gzip file containing pickle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4720" target="_blank">01:18:40.680</a></span> | <span class="t">dot dump files. So pickle dot dump is what we use in Python to take basically any Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4725" target="_blank">01:18:45.960</a></span> | <span class="t">object list of dictionaries and dictionary of lists, whatever you like, and save them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4732" target="_blank">01:18:52.000</a></span> | <span class="t">And it's super fast, right? And I use gzip with compress level one to basically be like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4738" target="_blank">01:18:58.080</a></span> | <span class="t">compress it pretty well, but pretty fast. So this is a really nice way to create a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4745" target="_blank">01:19:05.480</a></span> | <span class="t">cache of that. So this is the same as always. And so our get item is going to grab the file.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4753" target="_blank">01:19:13.200</a></span> | <span class="t">It's going to read it in, turn it into a float. And what I did here was, you know, I'm being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4759" target="_blank">01:19:19.040</a></span> | <span class="t">a little bit lazy, but I just decided to center crop the middle, you know, so let's say it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4765" target="_blank">01:19:25.160</a></span> | <span class="t">was a 300 by 400 file, it's going to center crop the middle 300 by 300 section, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4772" target="_blank">01:19:32.080</a></span> | <span class="t">resize it to 256 by 256. So they'll be the same size. So yeah, we can now, oh, I managed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4782" target="_blank">01:19:42.480</a></span> | <span class="t">to create the VAU twice. So I can now just confirm, I can grab a batch from that data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4788" target="_blank">01:19:48.840</a></span> | <span class="t">loader, encode it. And here it is, and then decode it again. And here it is. So the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4795" target="_blank">01:19:55.560</a></span> | <span class="t">category must have been computer or something. So here's, as you can see, the VA is doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4800" target="_blank">01:20:00.560</a></span> | <span class="t">a good job of decoding pictures of computers. So I can do something really very similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4807" target="_blank">01:20:07.400</a></span> | <span class="t">to what we did before. If we haven't got that destination directory yet, create it, go through</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4812" target="_blank">01:20:12.200</a></span> | <span class="t">our data loader, encode a batch. And this time I'm not using a memmapped file, I'm actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4817" target="_blank">01:20:17.520</a></span> | <span class="t">going to save separate NumPy files for each one. So go through each element of the batch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4823" target="_blank">01:20:23.920</a></span> | <span class="t">each item. So I'm going to save it into the destination directory, which is the Latents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4829" target="_blank">01:20:29.680</a></span> | <span class="t">directory. And I'm going to give it exactly the same path as the original one contained,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4834" target="_blank">01:20:34.800</a></span> | <span class="t">because it contains the folder of what the label is. Make sure that the directory exists,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4845" target="_blank">01:20:45.640</a></span> | <span class="t">that we're saving it to, and save that just as a NumPy file. This is another way to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4852" target="_blank">01:20:52.080</a></span> | <span class="t">it. So this is going to be a separate NumPy file for each item. Does that make sense so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4858" target="_blank">01:20:58.960</a></span> | <span class="t">far? Okay, cool. So I could create a thing called a NumPy data set, which is exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4866" target="_blank">01:21:06.680</a></span> | <span class="t">the same as our images data set. But to get an item, we don't have to use, you know, open</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4873" target="_blank">01:21:13.240</a></span> | <span class="t">a JPEG anymore, we just call mp.load. So this is a nice way to like take something you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4878" target="_blank">01:21:18.120</a></span> | <span class="t">already got and change it slightly. So it's going to return the...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4884" target="_blank">01:21:24.040</a></span> | <span class="t">Where did you do this? Did the memory map file, Jeremy? Just out of interest?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4889" target="_blank">01:21:29.880</a></span> | <span class="t">Sorry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4890" target="_blank">01:21:30.880</a></span> | <span class="t">Where did you do this versus the memory map file? Was it just to show a different way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4894" target="_blank">01:21:34.160</a></span> | <span class="t">Just to show a different way. Yeah. Yeah. Absolutely no particularly good reason, honestly. Yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4903" target="_blank">01:21:43.240</a></span> | <span class="t">I like to kind of like demonstrate different approaches. And I think it's good for people's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4907" target="_blank">01:21:47.720</a></span> | <span class="t">Python coding if you make sure you understand what all the lines of code do. Yeah, they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4913" target="_blank">01:21:53.080</a></span> | <span class="t">both work fine, actually. It's partly also for my own experimental interest. It's like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4919" target="_blank">01:21:59.560</a></span> | <span class="t">oh, which one seems to kind of feel better? Yeah. All right. So create training and validation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4929" target="_blank">01:22:09.420</a></span> | <span class="t">data sets by grabbing all the NumPy files inside the training and validation folders.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4935" target="_blank">01:22:15.680</a></span> | <span class="t">And then I'm going to just create a training data loader for the training data set just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4940" target="_blank">01:22:20.960</a></span> | <span class="t">to see what the main and standard deviation is on the channel dimension. So this is every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4946" target="_blank">01:22:26.000</a></span> | <span class="t">dimension except channel what I mean over. And so there it is. And as you can see there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4950" target="_blank">01:22:30.800</a></span> | <span class="t">the main and standard deviation are not close to zero and one. So we're going to store away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4955" target="_blank">01:22:35.800</a></span> | <span class="t">that main and standard deviation such that we then... We've seen transform data set before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4962" target="_blank">01:22:42.520</a></span> | <span class="t">This is just applying a transform to a data set. We're going to apply the normalization</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4967" target="_blank">01:22:47.680</a></span> | <span class="t">and transform. In the past, we've used our own normalization that TorchVision has one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4973" target="_blank">01:22:53.800</a></span> | <span class="t">as well. So this is just demonstrating how to just use TorchVision's version. But it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4978" target="_blank">01:22:58.320</a></span> | <span class="t">literally just subtracting the main and dividing by the standard deviation. We're also going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4985" target="_blank">01:23:05.240</a></span> | <span class="t">to apply some data augmentation. We're going to use the same trick we've used before for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4990" target="_blank">01:23:10.520</a></span> | <span class="t">images that are very small, which is we're going to add a little bit of padding and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=4995" target="_blank">01:23:15.320</a></span> | <span class="t">randomly crop our original image size from that. So it's just like shifting it slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5001" target="_blank">01:23:21.960</a></span> | <span class="t">each time. And we're also going to use our random erasing. And it's nice because we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5006" target="_blank">01:23:26.360</a></span> | <span class="t">it all with broadcasting, this is going to apply equally well to a four-channel image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5011" target="_blank">01:23:31.400</a></span> | <span class="t">as it is to a three or I think we did originally for one. Now, I don't think anybody as far</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5019" target="_blank">01:23:39.960</a></span> | <span class="t">as I know has built classifiers from Latents before. So I didn't even know if this is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5023" target="_blank">01:23:43.860</a></span> | <span class="t">to work. So I visualized it. So we could have Tifem X and a Tifem Y. So for Tifem X, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5031" target="_blank">01:23:51.720</a></span> | <span class="t">can optionally add augmentation. And if you do, then apply the augmentation transforms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5038" target="_blank">01:23:58.040</a></span> | <span class="t">Now this is going to be applied one image at a time, but our augmentation transforms, some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5041" target="_blank">01:24:01.920</a></span> | <span class="t">of them expect a batch. So we create a extra unit axis on the front to be a batch of one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5047" target="_blank">01:24:07.480</a></span> | <span class="t">and then remove it again. And then Tifem Y, very much like we've seen before, we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5053" target="_blank">01:24:13.680</a></span> | <span class="t">to turn those half names into IDs. So there's our validation and training transform datasets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5063" target="_blank">01:24:23.880</a></span> | <span class="t">So that we can look at our results, we need a denormalization. So let's create our data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5071" target="_blank">01:24:31.120</a></span> | <span class="t">loaders and grab mini batches and show us. And so I was very pleased to see that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5078" target="_blank">01:24:38.480</a></span> | <span class="t">random arrays works actually extremely nicely. So you can see you get these kind of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5082" target="_blank">01:24:42.560</a></span> | <span class="t">weird patches, you know, weird patches. But they're still recognizable. So this is like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5093" target="_blank">01:24:53.480</a></span> | <span class="t">something I very, very often do is to answer like, oh, is this like thing I'm doing in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5097" target="_blank">01:24:57.680</a></span> | <span class="t">computer vision reasonable? It's like, well, can my human brain recognize it? So if I couldn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5102" target="_blank">01:25:02.160</a></span> | <span class="t">recognize this with a drilling platform myself, then I shouldn't expect a computer to be able</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5107" target="_blank">01:25:07.000</a></span> | <span class="t">to do it or that this is a compass or whatever. I'm so glad they got orders. So cute. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5113" target="_blank">01:25:13.840</a></span> | <span class="t">you can see the cropping it's done has also been fine. Like it's a little bit of a fuzzy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5118" target="_blank">01:25:18.120</a></span> | <span class="t">edge, but basically like it's not destroying the image at all. They're still recognizable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5126" target="_blank">01:25:26.920</a></span> | <span class="t">It's also a good example here of how difficult like this problem is, like the fact that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5131" target="_blank">01:25:31.280</a></span> | <span class="t">is seashore, I would have called this surface, you know, but maybe surface is not an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5135" target="_blank">01:25:35.080</a></span> | <span class="t">in that category. Yeah. Okay. This could be food, but actually it's a refrigerator. Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5146" target="_blank">01:25:46.840</a></span> | <span class="t">So our augmentation seems to be working well. So then I, yeah, basically I've just copied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5152" target="_blank">01:25:52.040</a></span> | <span class="t">and pasted, you know, our basic pieces here. And I kind of wanted to have it all in one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5156" target="_blank">01:25:56.360</a></span> | <span class="t">place just to remind myself of exactly what it is. So this is the preactivation version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5160" target="_blank">01:26:00.760</a></span> | <span class="t">of convolutions. The reason for that is if I want this to be a backbone for a diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5165" target="_blank">01:26:05.920</a></span> | <span class="t">model or a unit, then I remember that we found that preactivation works best for units. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5173" target="_blank">01:26:13.880</a></span> | <span class="t">therefore our backbone needs to be trained with preactivation. So we've got a preactivation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5177" target="_blank">01:26:17.340</a></span> | <span class="t">conv, got a res block, res blocks model with dropouts. This is all just copied from previous.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5188" target="_blank">01:26:28.640</a></span> | <span class="t">So I decided like I wanted to try to, you know, use the basic trick that we learnt about from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5194" target="_blank">01:26:34.760</a></span> | <span class="t">simple diffusion of trying to put most of our work in the later layers. So the first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5202" target="_blank">01:26:42.360</a></span> | <span class="t">layer just has one block, then two blocks, and then four blocks. And then I figured that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5208" target="_blank">01:26:48.680</a></span> | <span class="t">we might then delete these final blocks. These maybe you're going to just end up being for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5213" target="_blank">01:26:53.560</a></span> | <span class="t">classification. This might end up being our pre-trained backbone, or maybe we keep them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5217" target="_blank">01:26:57.960</a></span> | <span class="t">I don't know. You know, it's like, as I said, this hasn't been done before. So anyway, I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5222" target="_blank">01:27:02.960</a></span> | <span class="t">tried to design it in a way that we've got some, you know, we can mess around a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5227" target="_blank">01:27:07.460</a></span> | <span class="t">bit with how many of these we keep. And so also I tried to use very few channels in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5233" target="_blank">01:27:13.440</a></span> | <span class="t">first blocks. And so I jump up for the channels that are aware of the works going to do a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5240" target="_blank">01:27:20.800</a></span> | <span class="t">jump from 128 to 512. So that's why I designed it this way. You know, I haven't even taken</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5248" target="_blank">01:27:28.080</a></span> | <span class="t">it any further than this. So I don't know if it's going to be a useful backbone or not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5251" target="_blank">01:27:31.760</a></span> | <span class="t">I didn't even know if this is going to be possible to classify. It seemed very likely</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5255" target="_blank">01:27:35.720</a></span> | <span class="t">it was possible to classify, even based on the fact that you can still kind of recognize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5259" target="_blank">01:27:39.200</a></span> | <span class="t">it almost like I could probably recognize it's a computer maybe. So I thought it was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5264" target="_blank">01:27:44.760</a></span> | <span class="t">going to be possible. But yeah, this is all new. So that was the model I created. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5270" target="_blank">01:27:50.040</a></span> | <span class="t">then I trained it for 40 epochs. And you can see after one epoch, it was already 25% accurate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5283" target="_blank">01:28:03.120</a></span> | <span class="t">And that's it recognizing which one of a thousand categories is it. So I thought that was pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5287" target="_blank">01:28:07.960</a></span> | <span class="t">amazing. And so after 40 epochs, I ended up at 66%, which is really quite fantastic because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5296" target="_blank">01:28:16.280</a></span> | <span class="t">a ResNet 34 is kind of like 73% or 74% accuracy when trained for quite a lot longer. You know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5308" target="_blank">01:28:28.480</a></span> | <span class="t">so to me, this is extremely encouraging that, you know, this is a really pretty good ResNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5315" target="_blank">01:28:35.640</a></span> | <span class="t">at recognizing images from their latent representations without any decoding or whatever. So from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5324" target="_blank">01:28:44.560</a></span> | <span class="t">here, you know, if you want to, you guys could try, yeah, building a better bedroom diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5334" target="_blank">01:28:54.080</a></span> | <span class="t">model or whatever you like. It's not to be bedrooms. Actually, one of our colleagues</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5340" target="_blank">01:29:00.720</a></span> | <span class="t">Molly, I'm just going to find it. So one of our colleagues Molly actually used the, do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5348" target="_blank">01:29:08.640</a></span> | <span class="t">you guys remember, was it the celeb faces that she used? So there's a celeb A HQ data set</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5361" target="_blank">01:29:21.200</a></span> | <span class="t">that consists of images of faces of celebrities. And so what Molly did was she basically used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5369" target="_blank">01:29:29.240</a></span> | <span class="t">this exact notebook, but used this faces data set instead. And this one's really pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5376" target="_blank">01:29:36.220</a></span> | <span class="t">good, isn't it? You know, this one's really pretty good. They certainly look like celebrities,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5381" target="_blank">01:29:41.760</a></span> | <span class="t">that's for sure. So yeah, you could try this data set or whatever, but yeah, try it. Yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5388" target="_blank">01:29:48.280</a></span> | <span class="t">maybe try it with the pre-trained backbone, try it with ResNets on the cross connections,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5395" target="_blank">01:29:55.160</a></span> | <span class="t">try it with all the tricks we used in SuperRes, try it with perceptual loss. Some folks we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5400" target="_blank">01:30:00.200</a></span> | <span class="t">spoke to about the perceptual loss think it won't help with Latents because the underlying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5407" target="_blank">01:30:07.480</a></span> | <span class="t">VAE was already trained with perceptual loss, but we should try, you know, or you guys should</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5411" target="_blank">01:30:11.680</a></span> | <span class="t">try all these things. Yeah, so be sure to check out the forum as well to see what other people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5418" target="_blank">01:30:18.520</a></span> | <span class="t">have already tried here because it's a whole new world. But it's just an example of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5423" target="_blank">01:30:23.520</a></span> | <span class="t">kind of like fun research ideas I guess we can play with. Yeah, what do you guys think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5428" target="_blank">01:30:28.760</a></span> | <span class="t">about this? Are you like surprised that we're able to quickly get this kind of accuracy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5433" target="_blank">01:30:33.200</a></span> | <span class="t">from Latents or do you think this is a useful research path? What are your thoughts? Yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5439" target="_blank">01:30:39.560</a></span> | <span class="t">I think it's very interesting. Oh, go ahead. I was going to say the Latents are already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5443" target="_blank">01:30:43.080</a></span> | <span class="t">like a slightly compressed, richer representation of an image, right? So it makes sense that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5448" target="_blank">01:30:48.560</a></span> | <span class="t">that's a useful thing to train on. And 66%, I think AlexNet is like 63% or something like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5454" target="_blank">01:30:54.800</a></span> | <span class="t">that. So, you know, we were already at state of the art, what, eight years ago, whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5461" target="_blank">01:31:01.000</a></span> | <span class="t">It might be more like 10 years ago. I know time passes quickly. Yeah, yeah, I guess next</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5467" target="_blank">01:31:07.240</a></span> | <span class="t">year. Yeah, next year it is 10 years ago. But yeah, I'm kind of curious with the pre-training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5473" target="_blank">01:31:13.360</a></span> | <span class="t">the whole, the whole value for me for like using a pre-trained network where someone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5476" target="_blank">01:31:16.960</a></span> | <span class="t">else has done lots and lots of compute on ImageNet to learn some features and I'm going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5481" target="_blank">01:31:21.360</a></span> | <span class="t">to use that because it's kind of funny to be like, oh, well, let's pre-train for ourselves</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5486" target="_blank">01:31:26.320</a></span> | <span class="t">and then try and use that. I'm curious whether like how best you'd allocate that compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5492" target="_blank">01:31:32.240</a></span> | <span class="t">whether you should, if you've got 10 hours of GPU, just do 10 hours of training versus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5497" target="_blank">01:31:37.000</a></span> | <span class="t">like five hours of pre-training and five hours of training. I mean, based on our super res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5502" target="_blank">01:31:42.320</a></span> | <span class="t">thing, the pre-training like was so much better. So that's why I'm feeling somewhat hopeful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5509" target="_blank">01:31:49.360</a></span> | <span class="t">about this direction. Yeah. Yeah, I'm really curious to see how it goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5515" target="_blank">01:31:55.360</a></span> | <span class="t">I guess I was going to say it's like, yeah, I think there's just a lot of opportunities</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5518" target="_blank">01:31:58.760</a></span> | <span class="t">for I guess the latent doing stuff in the latents. And like, I guess maybe like, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5524" target="_blank">01:32:04.600</a></span> | <span class="t">you could, I mean, hear your trade classifier as a backbone, but you could think of like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5528" target="_blank">01:32:08.480</a></span> | <span class="t">trade classifiers on other things for, you know, guidance or things like this. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5533" target="_blank">01:32:13.080</a></span> | <span class="t">Of course, we've done some experiments with that. I know John has his mid you guidance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5538" target="_blank">01:32:18.040</a></span> | <span class="t">approach for some of these sort of things, but there are different approaches that you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5541" target="_blank">01:32:21.480</a></span> | <span class="t">can play around here that, you know, exploring in the latent space can make it computationally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5548" target="_blank">01:32:28.640</a></span> | <span class="t">cheaper than, you know, having to decode it every time you want to, you know, like you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5552" target="_blank">01:32:32.640</a></span> | <span class="t">have to look at the image and then maybe apply a classifier, apply some sort of guidance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5556" target="_blank">01:32:36.360</a></span> | <span class="t">on the image. But if you can do it directly in the latent space, a lot of interesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5560" target="_blank">01:32:40.080</a></span> | <span class="t">opportunities there as well. Yeah. And, you know, now we're showing that indeed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5564" target="_blank">01:32:44.120</a></span> | <span class="t">Yeah, yeah, style transfer is on latents. Everything on latents, like you also do models. Like that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5572" target="_blank">01:32:52.000</a></span> | <span class="t">something I've done to make a latent clip is just have it like try and mirror an image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5576" target="_blank">01:32:56.520</a></span> | <span class="t">space clip. And so for classifiers as well, you could like distill an image net classifier</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5581" target="_blank">01:33:01.440</a></span> | <span class="t">rather than just having the label, you try and like copy the logits. And then that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5586" target="_blank">01:33:06.480</a></span> | <span class="t">like an even richer signal, like you get more value per example. So then you can create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5593" target="_blank">01:33:13.120</a></span> | <span class="t">your latent version of some existing image classifier or object detector or multi-modal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5600" target="_blank">01:33:20.280</a></span> | <span class="t">model like clip. I feel funny about this because I'm like both excited about simple diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5606" target="_blank">01:33:26.200</a></span> | <span class="t">on the basis that it gets rid of latents, but I'm also excited about latents on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5609" target="_blank">01:33:29.440</a></span> | <span class="t">basis of it gets rid of most of the pixels. I don't know how I can be cheering for both,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5614" target="_blank">01:33:34.920</a></span> | <span class="t">but somehow I am. I guess may the best method win. So, you know, the folks that are finishing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5627" target="_blank">01:33:47.560</a></span> | <span class="t">this course, well, first of all, congratulations, because it's been a journey, particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5633" target="_blank">01:33:53.000</a></span> | <span class="t">part two, it's a journey, which requires a lot of patience and tenacity. You know, if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5638" target="_blank">01:33:58.840</a></span> | <span class="t">you've got to zip through by binging on the videos, that's totally fine. It's a good approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5643" target="_blank">01:34:03.280</a></span> | <span class="t">but you know, maybe go back now and do it more slowly and do the, you know, build it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5648" target="_blank">01:34:08.960</a></span> | <span class="t">yourself and really experiment. But assuming, you know, for folks who have got to the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5655" target="_blank">01:34:15.320</a></span> | <span class="t">of this and feel like, okay, I get it more or less. Yeah. Do you guys have any sense</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5661" target="_blank">01:34:21.000</a></span> | <span class="t">of like, what kind of things make sense to do now? You know, where would you guys go</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5668" target="_blank">01:34:28.840</a></span> | <span class="t">from here? I think that great opportunities implementing papers that I guess come along</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5675" target="_blank">01:34:35.520</a></span> | <span class="t">these days. And I think at this stage, no way. Yeah. But also at this stage, I think,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5684" target="_blank">01:34:44.760</a></span> | <span class="t">you know, we're already discussing research ideas. And I think, you know, we're in a solid</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5689" target="_blank">01:34:49.080</a></span> | <span class="t">position to come up with our own research ideas and explore, explore those ideas. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5693" target="_blank">01:34:53.800</a></span> | <span class="t">I think that's a, that's a real opportunity that we have here. I think that's best done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5699" target="_blank">01:34:59.520</a></span> | <span class="t">often collaboratively. So I'll just, you know, mention that Fast AI has a Discord, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5706" target="_blank">01:35:06.400</a></span> | <span class="t">if you've got to this point, then you're probably somebody who would benefit from, from being</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5711" target="_blank">01:35:11.640</a></span> | <span class="t">there. And yeah, just pop your head in and say, like, there's an introduction straight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5716" target="_blank">01:35:16.560</a></span> | <span class="t">to say hello. And you don't, you know, maybe say what you're interested in or whatever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5721" target="_blank">01:35:21.760</a></span> | <span class="t">because it's, it's nice to work with others, I think. I mean, both Jono and Tanishka only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5726" target="_blank">01:35:26.840</a></span> | <span class="t">know because of the Discord and the forums and so forth. So that would be one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5732" target="_blank">01:35:32.480</a></span> | <span class="t">And we also have a, we have a generative channel. So anything related to generative models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5738" target="_blank">01:35:38.800</a></span> | <span class="t">that's the place. So for example, Bali was posting some of her experiments in that channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5743" target="_blank">01:35:43.760</a></span> | <span class="t">I think there are other Fast AI members posting their experiments. So if you're doing anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5747" target="_blank">01:35:47.640</a></span> | <span class="t">generative model related, that's a great way to also get feedback and thoughts from, from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5753" target="_blank">01:35:53.400</a></span> | <span class="t">the community. Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5755" target="_blank">01:35:55.880</a></span> | <span class="t">I'd also say that like this, this, if you're at the stage where you finish this course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5760" target="_blank">01:36:00.560</a></span> | <span class="t">you actually understand how diffusion models work. You've got a good handle on what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5764" target="_blank">01:36:04.520</a></span> | <span class="t">different components and like stable diffusion are. And you know how to wrangle data for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5768" target="_blank">01:36:08.520</a></span> | <span class="t">training and all these things. You're like so far ahead of most people who are building</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5773" target="_blank">01:36:13.480</a></span> | <span class="t">in this space. And I've got lots of, lots of companies and people reaching out to me</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5778" target="_blank">01:36:18.440</a></span> | <span class="t">to say, do you know anybody who has like more than just, oh, I know how to like load stable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5783" target="_blank">01:36:23.040</a></span> | <span class="t">diffusion and make an image. Like, you know, someone who knows how to actually like tinkle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5785" target="_blank">01:36:25.920</a></span> | <span class="t">with it and make it better. And if you've got those skills, like don't feel like, oh,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5789" target="_blank">01:36:29.400</a></span> | <span class="t">I'm definitely not qualified to like apply or like, there's lots of stuff where, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5794" target="_blank">01:36:34.840</a></span> | <span class="t">just taking these ideas now and like just simple, sensible ideas that we've covered</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5799" target="_blank">01:36:39.200</a></span> | <span class="t">in the course that have come up and saying, oh, actually, maybe I could try that. Maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5802" target="_blank">01:36:42.480</a></span> | <span class="t">I could play with this, you know, take this experimentalist approach. I feel like there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5806" target="_blank">01:36:46.360</a></span> | <span class="t">actually a lot of people who would love to have you helping them build the million and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5811" target="_blank">01:36:51.200</a></span> | <span class="t">one little stable diffusion based apps or whatever that you're working on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5814" target="_blank">01:36:54.960</a></span> | <span class="t">And particularly like the thing we always talk about at Fast AI, which is particularly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5818" target="_blank">01:36:58.520</a></span> | <span class="t">if you can combine that with your domain expertise, you know, whether it be from your, your hobbies</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5825" target="_blank">01:37:05.320</a></span> | <span class="t">or your work in some completely different field or whatever, you know, there'll be lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5831" target="_blank">01:37:11.080</a></span> | <span class="t">of interesting ways to combine, you know, you probably are one of the only people in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5835" target="_blank">01:37:15.400</a></span> | <span class="t">the world right now that understand your areas of passion or of vocation as well as these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5844" target="_blank">01:37:24.280</a></span> | <span class="t">techniques. So, and again, that's a good place to kind of get on the forum or the discord</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5850" target="_blank">01:37:30.680</a></span> | <span class="t">or whatever and start having those conversations because it can be, yeah, it can be difficult</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5855" target="_blank">01:37:35.600</a></span> | <span class="t">when you're at the cutting edge, which you now are by definition.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5861" target="_blank">01:37:41.800</a></span> | <span class="t">All right. Well, we better go away and start figuring out how on earth GPT-4 works. I don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5870" target="_blank">01:37:50.680</a></span> | <span class="t">think we're going to necessarily build the whole GPT-4 from scratch, at least not at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5875" target="_blank">01:37:55.320</a></span> | <span class="t">that scale, but I'm sure we're going to have some interesting things happening with NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5881" target="_blank">01:38:01.000</a></span> | <span class="t">And Jano, Tanish, thank you so much. It's been a real pleasure. It was nice doing things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5886" target="_blank">01:38:06.160</a></span> | <span class="t">with the, with a live audience, but I got to say, I really enjoyed this experience of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5892" target="_blank">01:38:12.320</a></span> | <span class="t">doing stuff with you guys the last few lessons. So thank you so much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5896" target="_blank">01:38:16.280</a></span> | <span class="t">Yeah, thanks for having us. This is really, really fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5899" target="_blank">01:38:19.720</a></span> | <span class="t">All right. Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5900" target="_blank">01:38:20.720</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5901" target="_blank">01:38:21.720</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5902" target="_blank">01:38:22.720</a></span> | <span class="t">Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=8AgZ9jcQ9v8&t=5903" target="_blank">01:38:23.720</a></span> | <span class="t">Bye.</span></div></div></body></html>