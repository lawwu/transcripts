<html><head><title>Fuzzing in the GenAI Era — Leonard Tang, Haize Labs</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Fuzzing in the GenAI Era — Leonard Tang, Haize Labs</h2><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc"><img src="https://i.ytimg.com/vi_webp/OMGPvW8TBHc/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=0">0:0</a> Introduction to Haizing<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=76">1:16</a> The "Last Mile Problem" in AI<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=167">2:47</a> The Brittleness of GenAI Applications<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=234">3:54</a> Examples of Brittle Chatbots<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=269">4:29</a> Inadequacy of Standard Evaluation Methods<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=369">6:9</a> Haizing: Simulating the Last Mile<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=523">8:43</a> Scaling Evaluation with Agents as Judges<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=569">9:29</a> Verdict: Accuracy vs. Latency<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=707">11:47</a> Scaling Evaluation with RL-Tuned Judges<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=846">14:6</a> Fuzzing vs. Adversarial Testing in AI<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=877">14:37</a> Simulation as Prompt Optimization<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=983">16:23</a> Case Study: Haizing a Major European Bank's AI App<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1025">17:5</a> Case Study: Haizing a F500 Bank's Voice Agents<br><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1066">17:46</a> Case Study: Scaling Voice Agent Evals with Verdict<br><br><div style="text-align: left;"><a href="./OMGPvW8TBHc.html">Whisper Transcript</a> | <a href="./transcript_OMGPvW8TBHc.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">Thanks Ally for the great intro. Indeed we're working on what I believe to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=18" target="_blank">00:00:18.540</a></span> | <span class="t">be the extant problem in AI, which is to say how do you validate, verify, audit,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=23" target="_blank">00:00:23.600</a></span> | <span class="t">steer something that is as subjective and unstructured as literal LLM slop. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=28" target="_blank">00:00:28.520</a></span> | <span class="t">today we're gonna be talking a lot about this. I should point out that ostensibly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=31" target="_blank">00:00:31.980</a></span> | <span class="t">we're part of the AI security track, although I would really consider us more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=34" target="_blank">00:00:34.760</a></span> | <span class="t">of a QA company, an eval company in some sense, although there's a lot of shared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=38" target="_blank">00:00:38.780</a></span> | <span class="t">similarities in how we approach the problem technically. Right, we are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=41" target="_blank">00:00:41.720</a></span> | <span class="t">essentially a property-based testing company, or Fuzz testing company, or as I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=45" target="_blank">00:00:45.740</a></span> | <span class="t">like to call it, a hazing company. Cool, so just to set the context a little bit, why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=52" target="_blank">00:00:52.460</a></span> | <span class="t">do we start Haze? What does Haze mean? Haze to us is ultimately, all right, we know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=56" target="_blank">00:00:56.540</a></span> | <span class="t">that AI systems are extremely unreliable. They're hard to trust in practice, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=60" target="_blank">00:01:00.820</a></span> | <span class="t">sort of need to pressure test them before you put them out into the wild. Our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=64" target="_blank">00:01:04.880</a></span> | <span class="t">solution to doing this is basically, let's just run large-scale optimization and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=68" target="_blank">00:01:08.440</a></span> | <span class="t">simulation and search before deployment and try and figure out through a battery</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=72" target="_blank">00:01:12.500</a></span> | <span class="t">of tests whether or not your system will behave as expected before it actually goes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=75" target="_blank">00:01:15.920</a></span> | <span class="t">into production. And I'm sure any of you guys who have tried to build LLM apps in the past, have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=82" target="_blank">00:01:22.200</a></span> | <span class="t">understood extremely viscerally what I mean when I say the last mile problem in AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=86" target="_blank">00:01:26.480</a></span> | <span class="t">Right, it's at this point in 2025, extremely easy to get something that is demo-ready, or POC-ready.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=94" target="_blank">00:01:34.480</a></span> | <span class="t">Like, you can whip together a cool product over the weekend and impress your PM and whatnot, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=99" target="_blank">00:01:39.540</a></span> | <span class="t">really hard to get that same product into production at a point where it's truly robust and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=103" target="_blank">00:01:43.540</a></span> | <span class="t">enterprise-grade and reliable. And, you know, this has been the case for the past two-plus years at this point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=108" target="_blank">00:01:48.820</a></span> | <span class="t">Right? Like, we've been promised the allure of autonomy and agency and full-gen AI and enterprise</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=116" target="_blank">00:01:56.380</a></span> | <span class="t">transformation for two-plus years since ChatGPT launched, and we're still not quite there. Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=120" target="_blank">00:02:00.820</a></span> | <span class="t">And I think, ultimately, it's because we haven't solved this last mile problem around trust and reliability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=126" target="_blank">00:02:06.100</a></span> | <span class="t">and risk. So, I think part of the big reasons we haven't solved this is because people still think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=132" target="_blank">00:02:12.400</a></span> | <span class="t">about evals and measuring your AI system in a very straightforward and naive sense, which is easiest to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=138" target="_blank">00:02:18.100</a></span> | <span class="t">explain as follows. Right? I'm sure everybody has seen this idea of going out, being a human subject matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=143" target="_blank">00:02:23.100</a></span> | <span class="t">experts, collecting a finite static golden data set of inputs and then expected outputs, ground truth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=149" target="_blank">00:02:29.940</a></span> | <span class="t">outputs from the human, and then basically running the inputs through the application, getting the actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=155" target="_blank">00:02:35.880</a></span> | <span class="t">output, and then comparing it somehow with the ground truth golden answers. Right? This is how evals has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=160" target="_blank">00:02:40.920</a></span> | <span class="t">been done forever since the birth of deep learning and prior. But it doesn't quite hold up in the Gen AI era,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=169" target="_blank">00:02:49.200</a></span> | <span class="t">specifically because of this property of Gen AI systems, which is what I like to call brittleness, or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=175" target="_blank">00:02:55.200</a></span> | <span class="t">more technically, Lipschitz discontinuity. And what I mean by this is, you know, people say AI is sensitive,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=181" target="_blank">00:03:01.620</a></span> | <span class="t">AI is brittle, AI is non-deterministic, which is true. This is all true. But that's really not the main problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=188" target="_blank">00:03:08.380</a></span> | <span class="t">that makes AI so hard to deal with. Right? Non-determinism is really fine if you set the temperature to zero.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=192" target="_blank">00:03:12.320</a></span> | <span class="t">Yes, there's like caching and weird systems, quirks, and all of the LLM providers that make it somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=198" target="_blank">00:03:18.020</a></span> | <span class="t">non-deterministic, even at scale. But for the most part, non-determinism really doesn't bite you too</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=202" target="_blank">00:03:22.460</a></span> | <span class="t">much when you're building AI apps. Right? You, for the most part, are constraining your outputs to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=205" target="_blank">00:03:25.760</a></span> | <span class="t">temperature zero. You're running things through a workflow. It's fairly deterministic. What does bite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=210" target="_blank">00:03:30.140</a></span> | <span class="t">you a lot when you're building AI apps, though, is when you send two ostensibly similar inputs to your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=215" target="_blank">00:03:35.480</a></span> | <span class="t">AI application with maybe slight variance in the syntax or the semantics or the appearance of the text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=222" target="_blank">00:03:42.020</a></span> | <span class="t">but all of a sudden you get wildly different outputs on the other side. Right? This is what I mean when I say</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=226" target="_blank">00:03:46.740</a></span> | <span class="t">Gen AI apps are incredibly brittle. And I think this is the actual core property</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=231" target="_blank">00:03:51.180</a></span> | <span class="t">that makes billing with AI, with Gen AI, so difficult. And of course, we see this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=237" target="_blank">00:03:57.240</a></span> | <span class="t">brittleness manifest itself in all sorts of fun ways. I'm sure we don't have to belabor this point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=241" target="_blank">00:04:01.720</a></span> | <span class="t">too much, but you've got everything from Air Canada customer supports, hallucinating to, you know,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=247" target="_blank">00:04:07.500</a></span> | <span class="t">character AI telling teenagers to commit suicide, to buying a pickup truck for one dollar on the Chevy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=254" target="_blank">00:04:14.440</a></span> | <span class="t">patient or customer portal. Right? I don't think we need to go through more examples of this. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=260" target="_blank">00:04:20.120</a></span> | <span class="t">happens more or less every single week. There's more and more examples popping out. And again, this all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=264" target="_blank">00:04:24.820</a></span> | <span class="t">comes back to Gen AI being extremely sensitive and brittle to perturbations in the input space. Cool. So,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=271" target="_blank">00:04:31.380</a></span> | <span class="t">standard evals, of course, doesn't cover this brittleness property. And I would say it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=275" target="_blank">00:04:35.520</a></span> | <span class="t">insufficient in two senses, two primary senses. One is coverage. Right? With a static data set,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=281" target="_blank">00:04:41.760</a></span> | <span class="t">you only know how good your AI system will be with respect to that data set. Right? It might look like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=286" target="_blank">00:04:46.960</a></span> | <span class="t">your AI system is 100% on all your unit tests, on all your golden data set points. But if you just push</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=292" target="_blank">00:04:52.840</a></span> | <span class="t">around the corner and look around the corner for more inputs that cover your space more densely, it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=297" target="_blank">00:04:57.400</a></span> | <span class="t">entirely possible that you get perturbations that tell a very, very different story about how your AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=301" target="_blank">00:05:01.660</a></span> | <span class="t">application actually does in the wild. So point number one, standard evals don't have sufficient coverage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=306" target="_blank">00:05:06.100</a></span> | <span class="t">Second point, too, is it's actually really difficult to come up with a good measure of quality or even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=314" target="_blank">00:05:14.920</a></span> | <span class="t">similarity between the outputs of your AI application and your ground truth outputs. Really, what we would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=320" target="_blank">00:05:20.680</a></span> | <span class="t">want almost is a human subject matter expert who is constantly overseeing your AI application and a subject matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=328" target="_blank">00:05:28.180</a></span> | <span class="t">expert who has all the right taste and sensitivity but is able to translate that sensitivity into some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=332" target="_blank">00:05:32.380</a></span> | <span class="t">quantitative metric. This by no means is a trivial task. Right? I think this is the core challenge that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=337" target="_blank">00:05:37.360</a></span> | <span class="t">we've been trying to face in the field of AI around reward modeling for the past five, six, seven plus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=341" target="_blank">00:05:41.680</a></span> | <span class="t">years. Right? And the key challenge is how do you get that sensitivity from the subject matter expert from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=347" target="_blank">00:05:47.080</a></span> | <span class="t">a non-technical domain to be able to translate their criteria into quantitative measures? This is not even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=354" target="_blank">00:05:54.040</a></span> | <span class="t">close to something that's being solved with standard evals today. People are using things like exact match,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=358" target="_blank">00:05:58.060</a></span> | <span class="t">classifiers, LM as a judge, semantics, limity. All these things have their own sets of quirks and undesiderata. And we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=366" target="_blank">00:06:06.760</a></span> | <span class="t">see how this pans out in a second. Long story short of how we think about tackling this eval problem is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=374" target="_blank">00:06:14.140</a></span> | <span class="t">essentially through hazing. Right? Fuzz testing in the AI era. Essentially, what hazing comprises is very simple in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=380" target="_blank">00:06:20.380</a></span> | <span class="t">abstract. We just simulate large-scale stimuli to center your AI application. We get the responses as a result of the stimuli. We judge and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=389" target="_blank">00:06:29.080</a></span> | <span class="t">analyze and score the outputs of your AI application. And we use that as a signal to help guide the next round of search. Right? And we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=395" target="_blank">00:06:35.400</a></span> | <span class="t">essentially just do this iteratively until we discover some bugs and corner cases that break your AI application. And if we don't discover</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=401" target="_blank">00:06:41.260</a></span> | <span class="t">anything and we exhaust our search budget, that means you're essentially ready for production. Right? So this is hazing in a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=407" target="_blank">00:06:47.060</a></span> | <span class="t">nutshell.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=408" target="_blank">00:06:48.960</a></span> | <span class="t">But easy to describe. Actually, really difficult to execute in practice. Both sides of the equation in terms of scoring the output and also</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=417" target="_blank">00:06:57.440</a></span> | <span class="t">generating the input stimuli are quite difficult technically. I'll first talk about how do we think about scoring the output. Again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=423" target="_blank">00:07:03.520</a></span> | <span class="t">translating from subjective criteria into quantitative metrics. We call this judging, more broadly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=430" target="_blank">00:07:10.320</a></span> | <span class="t">Probably you guys are familiar with something like using LM as a judge to essentially have LM look at the output of your AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=437" target="_blank">00:07:17.760</a></span> | <span class="t">application and decide, you know, based on some prompts or rubric that you give to your judge, you know, is this a good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=443" target="_blank">00:07:23.200</a></span> | <span class="t">response or is it a bad response? Tell me on a scale from 1 to 5 or 1 to 10 or what have you. Right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=447" target="_blank">00:07:27.220</a></span> | <span class="t">Very simple to do, but it has its whole large array of different failure modes. In particular, LM as a judge itself is prone to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=455" target="_blank">00:07:35.820</a></span> | <span class="t">hallucinations. It is obviously an LLM, so it's prone to hallucinations. It is unstable. You could have actually a really good</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=463" target="_blank">00:07:43.660</a></span> | <span class="t">articulation of the criteria, but it doesn't actually operationalize well into a model. Right? So it's uncalibrated in the output. Right? Like, what is a 1 to an LLM? That's very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=473" target="_blank">00:07:53.380</a></span> | <span class="t">different to what is a 1 to a human. Right? What is a 5 to a human is very different to what is a 5 to an LLM? So it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=480" target="_blank">00:08:00.140</a></span> | <span class="t">uncalibrated. It has all sorts of biases. Right? If you change the inputs in any weird position. Right? Let's say you present one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=487" target="_blank">00:08:07.260</a></span> | <span class="t">response first and the second response. If you flip the order, that changes the results oftentimes. If you provide context or you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=492" target="_blank">00:08:12.660</a></span> | <span class="t">change some part of your rubric, that changes the result of the LM as a judge, too. So extremely biased, extremely fickle. And TL;DR, LM as a judge itself, as an off the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=502" target="_blank">00:08:22.140</a></span> | <span class="t">call call call off the shelf call to an LM is oftentimes not going to solve your reliability issues.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=508" target="_blank">00:08:28.900</a></span> | <span class="t">So the key question in my mind is, how do you actually QA the judge itself? Right? How do you get to a point where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=514" target="_blank">00:08:34.900</a></span> | <span class="t">can judge the judge and say that this is the best gold standard metric that I can use to then actually iterate my</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=520" target="_blank">00:08:40.520</a></span> | <span class="t">underlying AI application against? So how do you judge this judge? The broad philosophy that we've been taking over the past few months is essentially pushing the idea of inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=530" target="_blank">00:08:50.900</a></span> | <span class="t">time scaling or more broadly compute time scaling to the judging stage. So we call this scaling judge time compute. And there's two ends of the spectrum of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=539" target="_blank">00:08:59.660</a></span> | <span class="t">philosophy. One end of the spectrum is basically just rip from scratch, no inductive biases, train reasoning models that get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=548" target="_blank">00:09:08.420</a></span> | <span class="t">really, really, really good at this evaluation task. And then the other end of the spectrum is be very structured. You know, don't train any models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=555" target="_blank">00:09:15.180</a></span> | <span class="t">Just use the off the shelf elements. Have really strong inductive priors, but basically build agents as judges. Right? So this is one approach.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=562" target="_blank">00:09:22.180</a></span> | <span class="t">basically we'll build agent frameworks, pipelines, workflows to do the judging task. And we have this nice little library called</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=568" target="_blank">00:09:28.940</a></span> | <span class="t">Verdict that does this. Very on-the-nose name, I know. But the idea of Verdict is essentially, there's a lot of great</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=574" target="_blank">00:09:34.940</a></span> | <span class="t">intuition from the scalable oversight community, which is subfield of AI safety. Goal of scalable oversight is basically how do you take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=580" target="_blank">00:09:40.940</a></span> | <span class="t">smaller language models and have them audit and correct and steer stronger models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=584" target="_blank">00:09:44.940</a></span> | <span class="t">Urgently, this is an AI safety concept because people were worried about, you know, in the age of superhuman AI, how do you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=589" target="_blank">00:09:49.940</a></span> | <span class="t">weaker models, i.e. humans control the stronger models, right? And that's how the field got started. But as a result of scalable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=595" target="_blank">00:09:55.940</a></span> | <span class="t">oversight, there's been a lot of great intuition around the architectures and primitives and units that you would use to probe and reason and critique what a stronger model is doing. And so we baked a lot of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=599" target="_blank">00:09:59.940</a></span> | <span class="t">primitives and architectures into this Verdict library. One example is having LLMs debate each other, having the weaker LLMs debate each other about what the stronger model is saying and seeing if that makes sense. Another example is having the LLMs, weaker LLMs self-verify the results of their own responses, right? So, you know, have an LLM say, okay, this response of the stronger model is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=618" target="_blank">00:10:18.940</a></span> | <span class="t">good or bad. It is bad for this reason, and then maybe having an LLM critique its own reasoning, right? So self-verification is another great primitive. Ensembling, of course, another classic primitive in this case, and so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=639" target="_blank">00:10:39.940</a></span> | <span class="t">TLDR, scaling judge time compute in this particular way, through building agents as judges, actually allows you to come up with extremely powerful judging systems that are also quite cheap and also low latency. So here's a plot of price and latency and cost and accuracy of Verdict systems vis-à-vis some of the Frontier Labs reasoning models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=666" target="_blank">00:11:06.940</a></span> | <span class="t">So you can see that Verdict is beating 01 and 03 mini and, of course, GPT-40 and 3.5 sonnets on the task of expert QA verification. So this is subjective criteria grading in expert domains.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=679" target="_blank">00:11:19.940</a></span> | <span class="t">Critically, Verdict here is powered by a GPT-40 mini backbone, right? So we basically have stacked GPT-40 mini aggressively in what is, in this case, like a self-verified debate ensemble architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=691" target="_blank">00:11:31.940</a></span> | <span class="t">And we're able to beat 01 for a fraction of the cost, like less than a third of the cost, right? And also, like less than a third of the latency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=699" target="_blank">00:11:39.940</a></span> | <span class="t">And this is all because of the fact that we've chosen the priors in a pretty careful and intelligent way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=705" target="_blank">00:11:45.940</a></span> | <span class="t">So that's one way to scale just-time compute, is basically building agents to do the task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=711" target="_blank">00:11:51.940</a></span> | <span class="t">Another way to do it, and this is a lot more fun in my opinion, is basically, yeah, just rip RL from scratch, train models to do the judging task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=718" target="_blank">00:11:58.940</a></span> | <span class="t">And this is something that we've also been pretty excited about over the past few months.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=721" target="_blank">00:12:01.940</a></span> | <span class="t">Again, for standard LM judges, a whole host of issues, but two particular issues that are solved by RL is one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=727" target="_blank">00:12:07.940</a></span> | <span class="t">There's a lack of coherent rationales that explain why an LM judge thinks something is a 5 out of 5, or thinks something is good or bad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=734" target="_blank">00:12:14.940</a></span> | <span class="t">And also, standard LM judge doesn't provide real fine-grained, tailored, unique criteria to whatever idiosyncratic task and data you're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=744" target="_blank">00:12:24.940</a></span> | <span class="t">But both of these can be solved by RL tuning, or specifically, GRPO tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=749" target="_blank">00:12:29.940</a></span> | <span class="t">One paper recently that has come out in this general flavor is from DeepSeq.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=754" target="_blank">00:12:34.940</a></span> | <span class="t">This is SPCT, self-principled critique tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=757" target="_blank">00:12:37.940</a></span> | <span class="t">The idea here is essentially, can you get an LM to first propose some data set, or sorry, data point specific criteria about what to test for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=768" target="_blank">00:12:48.940</a></span> | <span class="t">It's almost like coming up with unit tests for the specific data point you're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=771" target="_blank">00:12:51.940</a></span> | <span class="t">And having the LM essentially look at each of those criteria and critique the data points against each of those criteria.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=777" target="_blank">00:12:57.940</a></span> | <span class="t">So it's like instance specific rubric and then instance specific rubric critiques.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=781" target="_blank">00:13:01.940</a></span> | <span class="t">This is one way to train RL models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=784" target="_blank">00:13:04.940</a></span> | <span class="t">We ran a pretty simple experiment using a grant of this technique to GRPO train 600 million parameter and 1.7 billion parameter models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=795" target="_blank">00:13:15.940</a></span> | <span class="t">And TLDR, this gets us to, you know, competitive performance on the reward bench task with Cloud3 Opus, which is at 80%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=803" target="_blank">00:13:23.940</a></span> | <span class="t">GPT-4 Mini, which is at 80%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=805" target="_blank">00:13:25.940</a></span> | <span class="t">LAM370B at 77%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=807" target="_blank">00:13:27.940</a></span> | <span class="t">And J1 Micro, which is this 1.7 billion parameter reward model at 80.7% accuracy on the reward bench task, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=814" target="_blank">00:13:34.940</a></span> | <span class="t">And this is all because of judged time scaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=816" target="_blank">00:13:36.940</a></span> | <span class="t">This is all because we did GRPO to come up with better rubric proposals and better critiques on the specific tasks that we're looking at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=823" target="_blank">00:13:43.940</a></span> | <span class="t">So training off essentially a much smaller model, doing more compute, gets you this much better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=830" target="_blank">00:13:50.940</a></span> | <span class="t">And similar numbers for the 600 million parameter model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=834" target="_blank">00:13:54.940</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=835" target="_blank">00:13:55.940</a></span> | <span class="t">So that's all judging and scoring the outputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=838" target="_blank">00:13:58.940</a></span> | <span class="t">Equally important though is how do you come up with inputs to throw out the AI system, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=842" target="_blank">00:14:02.940</a></span> | <span class="t">And how do you run the search over time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=844" target="_blank">00:14:04.940</a></span> | <span class="t">TLDR, there's two ways that we think about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=847" target="_blank">00:14:07.940</a></span> | <span class="t">There is fuzzing in the general sense, which is essentially, okay, I just want to come up with some variance of some customer happy path and test my system under some reasonable in distribution user inputs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=861" target="_blank">00:14:21.940</a></span> | <span class="t">Then there's the more fun part, which is how do you do adversarial testing, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=865" target="_blank">00:14:25.940</a></span> | <span class="t">How do you basically emulate some person trying to sit down and prompt inject and jailbreak and mess with your AI systems at large?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=871" target="_blank">00:14:31.940</a></span> | <span class="t">And this is much more aggressive in terms of how we pursue the optimization problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=876" target="_blank">00:14:36.940</a></span> | <span class="t">Long story short is, you know, fuzzing in the AI sense is much more structured and optimization driven than in classical security or software or hardware, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=888" target="_blank">00:14:48.940</a></span> | <span class="t">It is impossible to like search over the input space of natural language and do a brute force search in any reasonably short amount of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=897" target="_blank">00:14:57.940</a></span> | <span class="t">Like we were dealing with, you know, let's say you were dealing with a Lama 3 tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=901" target="_blank">00:15:01.940</a></span> | <span class="t">There's 128,000 tokens per individual inputs, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=905" target="_blank">00:15:05.940</a></span> | <span class="t">You scale this up to like 100 million tokens and you're like literally impossible to scan this entire input space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=910" target="_blank">00:15:10.940</a></span> | <span class="t">So you have to be very clever and guided and prune the search space as you do hazing and fuzzing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=915" target="_blank">00:15:15.940</a></span> | <span class="t">We treat this task essentially as an optimization problem, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=918" target="_blank">00:15:18.940</a></span> | <span class="t">This is, long story short, just discrete optimization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=921" target="_blank">00:15:21.940</a></span> | <span class="t">There's plenty of rich literature over the past 60, 70 years of discrete math research to go and support how to do this sort of task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=928" target="_blank">00:15:28.940</a></span> | <span class="t">We have to massage it, of course, to work for the LLM domain.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=930" target="_blank">00:15:30.940</a></span> | <span class="t">But TL;DR, the search space is just natural language.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=933" target="_blank">00:15:33.940</a></span> | <span class="t">The objective that we're trying to minimize in this case is essentially whatever judge that we're using to score the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=940" target="_blank">00:15:40.940</a></span> | <span class="t">We basically want to find inputs that break your AI application vis-a-vis the judge, gets the output to score very low on some measure of the judge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=948" target="_blank">00:15:48.940</a></span> | <span class="t">And yeah, we can rip and throw a bunch of fun optimization algorithms at this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=952" target="_blank">00:15:52.940</a></span> | <span class="t">We can use gradient-based methods to backprop all the way from the judge loss through the model to the input space and use that to guide what tokens we want to flip.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=959" target="_blank">00:15:59.940</a></span> | <span class="t">We can use various forms of tree search and MCTS.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=962" target="_blank">00:16:02.940</a></span> | <span class="t">We can search over the latent space of embedding models and then map from the embedding models to text and throw that at the underlying AI application or the application under test.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=972" target="_blank">00:16:12.940</a></span> | <span class="t">We can use DSPy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=973" target="_blank">00:16:13.940</a></span> | <span class="t">We can use all sorts of other great tools and tricks to solve this optimization problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=979" target="_blank">00:16:19.940</a></span> | <span class="t">Some fun case studies in the last few minutes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=982" target="_blank">00:16:22.940</a></span> | <span class="t">TL;DR, you could probably imagine that this hazing thing matters a lot for people in regulated industries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=987" target="_blank">00:16:27.940</a></span> | <span class="t">And indeed we work a lot with banks and financial services and healthcare and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=992" target="_blank">00:16:32.940</a></span> | <span class="t">We did something recently where we hazed the largest bank in Hungary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=997" target="_blank">00:16:37.940</a></span> | <span class="t">They had this like loan calculation AI application that they're showing to customers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1001" target="_blank">00:16:41.940</a></span> | <span class="t">The customer application had to follow this 18-line code of conduct is what they called it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1005" target="_blank">00:16:45.940</a></span> | <span class="t">And we basically threw everything under the sun from our platform in terms of optimization and scoring to emulate adversaries.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1012" target="_blank">00:16:52.940</a></span> | <span class="t">We were able to discover a ton of prompt injections and jail breaks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1015" target="_blank">00:16:55.940</a></span> | <span class="t">And honestly just like unexpected corner cases that they didn't account for in their code of conduct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1020" target="_blank">00:17:00.940</a></span> | <span class="t">And they were able to patch this up and then finally unblock their production into prod.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1024" target="_blank">00:17:04.940</a></span> | <span class="t">We are doing this right now for a fortune 500 bank that wants to do outbound debt collection with voice agents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1031" target="_blank">00:17:11.940</a></span> | <span class="t">A little bit actually more complex problem because now we're not just testing in the text space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1037" target="_blank">00:17:17.940</a></span> | <span class="t">We're actually introducing a lot of variance to just the audio signal as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1042" target="_blank">00:17:22.940</a></span> | <span class="t">So adding things like background noise, stacking weird static into the input domain, changing the frequencies of things, etc.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1049" target="_blank">00:17:29.940</a></span> | <span class="t">But still an optimization problem by the end of the day.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1052" target="_blank">00:17:32.940</a></span> | <span class="t">TLDR, what took this team, you know, three months or so to do with their internal ops teams, took, in their own words, only five minutes for a platform to do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1061" target="_blank">00:17:41.940</a></span> | <span class="t">So scaling up adversary emulation works for this task as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1064" target="_blank">00:17:44.940</a></span> | <span class="t">And a little bit more difference for another voice agent company, we've been helping them with scaling up their eval suite, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1073" target="_blank">00:17:53.940</a></span> | <span class="t">So not so much hazing, but basically scaling up their subjective human annotators through verdicts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1079" target="_blank">00:17:59.940</a></span> | <span class="t">They've seen a 38% increase in ground truth human agreements using verdicts as opposed to using their internal ops teams.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1086" target="_blank">00:18:06.940</a></span> | <span class="t">And what we're using here is essentially a tried and true architecture from the verdict library, which is what we call a rubric fanout.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1093" target="_blank">00:18:13.940</a></span> | <span class="t">So it is basically proposed individual unit tests and criteria for any particular data points, critique it, self verify your critique,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1100" target="_blank">00:18:20.940</a></span> | <span class="t">and then aggregate results at the very end.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1102" target="_blank">00:18:22.940</a></span> | <span class="t">Cool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1103" target="_blank">00:18:23.940</a></span> | <span class="t">So we've got a few minutes left for questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1107" target="_blank">00:18:27.940</a></span> | <span class="t">But yeah, hazing is a ton of fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1110" target="_blank">00:18:30.940</a></span> | <span class="t">I think it matters a lot for this new era of software that we're building.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1113" target="_blank">00:18:33.940</a></span> | <span class="t">We're very aggressively hiring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1115" target="_blank">00:18:35.940</a></span> | <span class="t">We're, you know, facing what I would deem to be insurmountable enterprise demands.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1119" target="_blank">00:18:39.940</a></span> | <span class="t">And we're only a team of four people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1121" target="_blank">00:18:41.940</a></span> | <span class="t">So we really need to scale up our team.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1123" target="_blank">00:18:43.940</a></span> | <span class="t">And yeah, we're based in New York in case you guys want to move out to the city.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1126" target="_blank">00:18:46.940</a></span> | <span class="t">And yeah, any last questions for me?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1129" target="_blank">00:18:49.940</a></span> | <span class="t">For the hazing input, is it multi-shot or single-shot?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1133" target="_blank">00:18:53.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1134" target="_blank">00:18:54.940</a></span> | <span class="t">Great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1135" target="_blank">00:18:55.940</a></span> | <span class="t">So we do both.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1136" target="_blank">00:18:56.940</a></span> | <span class="t">We do single turn, multi-turn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1138" target="_blank">00:18:58.940</a></span> | <span class="t">We do persistent conversations if you're doing voice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1141" target="_blank">00:19:01.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1142" target="_blank">00:19:02.940</a></span> | <span class="t">All sorts of modalities, all sorts of inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1144" target="_blank">00:19:04.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1145" target="_blank">00:19:05.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1145" target="_blank">00:19:05.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1146" target="_blank">00:19:06.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1147" target="_blank">00:19:07.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1148" target="_blank">00:19:08.940</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=OMGPvW8TBHc&t=1149" target="_blank">00:19:09.940</a></span> | <span class="t">Yeah.</span></div></div></body></html>