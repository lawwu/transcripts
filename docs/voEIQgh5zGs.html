<html><head><title>9 AI Developments: HeyGen 2.0 to AjaxGPT, Open Interpreter to NExT-GPT and Roblox AI</title></head><body>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    <a href="index.html">back to index</a><h2>9 AI Developments: HeyGen 2.0 to AjaxGPT, Open Interpreter to NExT-GPT and Roblox AI</h2><a href="https://www.youtube.com/watch?v=voEIQgh5zGs"><img src="https://i.ytimg.com/vi_webp/voEIQgh5zGs/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=211">3:31</a> Optimized Prompts<br><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=394">6:34</a> Gemini News<br><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=508">8:28</a> Llama<br><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=719">11:59</a> Apple AjaxGPT<br><br><div style="text-align: left;"><a href="./voEIQgh5zGs.html">Whisper Transcript</a> | <a href="./transcript_voEIQgh5zGs.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=0">00:00:00.000</a></span> | <span class="t">There were nine impactful AI developments in the last few days that I wanted to tell you guys about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=6">00:00:06.260</a></span> | <span class="t">From the frankly startling HeyGen video translation, to the epic new prompt optimising paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=13">00:00:13.240</a></span> | <span class="t">and from Apple's IAX GPT to Open Interpreter, Next GPT, yet more Google Gemini news,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=20">00:00:20.340</a></span> | <span class="t">and even Roblox AI. But I must start with HeyGen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=25">00:00:25.000</a></span> | <span class="t">You probably already heard from AI Explained that HeyGen can generate lifelike videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=30">00:00:30.820</a></span> | <span class="t">and is available as a plugin to ChatGPT. But how about video language dubbing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=36">00:00:36.000</a></span> | <span class="t">Well, today I got access to their new Avatar 2.0 feature, and I decided to test it out with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=43">00:00:43.560</a></span> | <span class="t">Sam Altman. Not with the real Sam Altman, of course, but with his testimony to the Senate.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=48">00:00:48.540</a></span> | <span class="t">And I want Spanish language speakers to tell me how accurate they think this is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=53">00:00:53.380</a></span> | <span class="t">My worst fears are that we are causing significant damage to the field, technology, industry, and the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=59">00:00:59.960</a></span> | <span class="t">I think that could happen in various ways. That's why we started the company.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=65">00:01:05.320</a></span> | <span class="t">It's a big part of why I'm here today, and we've been able to spend time with you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=70">00:01:10.620</a></span> | <span class="t">If this technology fails, it can be disastrous. We want to be clear about our position on this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=76">00:01:16.900</a></span> | <span class="t">I have been researching three or four tools, including this one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=80">00:01:20.660</a></span> | <span class="t">to translate my videos into dozens of languages.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=83">00:01:23.360</a></span> | <span class="t">And I can't wait to put that into place.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=85">00:01:25.980</a></span> | <span class="t">But time waits for no man, so let me move on to Open Interpreter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=90">00:01:30.580</a></span> | <span class="t">I've been using the version released five days ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=93">00:01:33.560</a></span> | <span class="t">What is it? Well, an open source code interpreter. Here is a brief preview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=98">00:01:38.100</a></span> | <span class="t">Open Interpreter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=126">00:02:06.060</a></span> | <span class="t">Open Interpreter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=126">00:02:06.760</a></span> | <span class="t">Of course, I've been trying to figure out how to use Open Interpreter. I've been trying to figure out how to use Open Interpreter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=128">00:02:08.080</a></span> | <span class="t">I've been trying it out intensively, and while it's not perfect, it has proven useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=133">00:02:13.080</a></span> | <span class="t">I asked it this:</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=134">00:02:14.280</a></span> | <span class="t">Download this YouTube video in 1440p, e.g. using PyTube, and clip out 2318, 2338, save to desktop, naming file Altman vertical line.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=146">00:02:26.700</a></span> | <span class="t">That's a clip I wanted to use in this very video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=150">00:02:30.000</a></span> | <span class="t">Now, okay, it wouldn't have taken me that long to do it manually, but this process was a few seconds.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=156">00:02:36.640</a></span> | <span class="t">You agreed to run the code a few times, and here was the end result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=161">00:02:41.000</a></span> | <span class="t">You can try to guess why I picked out this clip from a recent Sam Altman interview.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=166">00:02:46.680</a></span> | <span class="t">And we weren't set up for that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=168">00:02:48.680</a></span> | <span class="t">Is the usage of Chatipati decelerating?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=172">00:02:52.880</a></span> | <span class="t">No.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=174">00:02:54.200</a></span> | <span class="t">I think it maybe took like a little bit of a flat line during the summer, which happens for lots of products, but it is...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=182">00:03:02.440</a></span> | <span class="t">Doink up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=185">00:03:05.300</a></span> | <span class="t">*sniff*</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=187">00:03:07.300</a></span> | <span class="t">Obviously, we shouldn't automatically believe the CEO of the company about how many people are using his product.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=194">00:03:14.380</a></span> | <span class="t">But I do think it points to a counter-narrative to the argument that Chatipati usage is continuing to slow down into the autumn.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=201">00:03:21.940</a></span> | <span class="t">You don't have to use GPT-4 either, and more generally, I think this points to a change in the way we will use computers in the near future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=210">00:03:30.900</a></span> | <span class="t">And now let's talk about this paper from Google DeepMind.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=213">00:03:33.700</a></span> | <span class="t">I'll have more news about their Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=215">00:03:35.020</a></span> | <span class="t">I'll talk about the Gemini model in a second, but first, I found this paper fascinating.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=219">00:03:39.140</a></span> | <span class="t">I will hopefully be doing a deeper dive with one of the authors, but for now, the big picture is this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=224">00:03:44.980</a></span> | <span class="t">Language models can come up with optimized prompts for language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=229">00:03:49.580</a></span> | <span class="t">These aren't small optimizations either, and nor do they work with only one model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=234">00:03:54.620</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=244">00:04:04.780</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=244">00:04:04.820</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=244">00:04:04.860</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=244">00:04:04.860</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=244">00:04:04.940</a></span> | <span class="t">The paper says that with a variety of large language models, we demonstrate that the best prompts optimized by their method outperform human design prompts by up to 8% or more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=249">00:04:09.100</a></span> | <span class="t">bench hard tasks. Those are long-standing tasks known for their difficulty for large language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=254">00:04:14.760</a></span> | <span class="t">models. To massively oversimplify, models like Palm 2 and GPT-4 can be given a meta prompt. For</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=261">00:04:21.120</a></span> | <span class="t">example, generate a new instruction that achieves a higher accuracy on a particular task. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=266">00:04:26.360</a></span> | <span class="t">language models are then shown how previous prompts worked out. In this example, for a particular task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=271">00:04:31.880</a></span> | <span class="t">let's figure it out scored 61, while let's solve the problem scored 63 out of 100. This was the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=278">00:04:38.280</a></span> | <span class="t">mathematics problem down here. And then they're asked, generate an instruction that is different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=283">00:04:43.080</a></span> | <span class="t">from all the instructions above and has a higher score than all the instructions above. The</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=288">00:04:48.180</a></span> | <span class="t">instruction should be concise, effective, and generally applicable to all problems. And apparently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=293">00:04:53.400</a></span> | <span class="t">GPT-4 was particularly good at looking at the trajectory of optimizations, the patterns and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=300">00:05:00.240</a></span> | <span class="t">trends about what produced better prompts on a particular task. For example, you might start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=305">00:05:05.760</a></span> | <span class="t">let's solve the problem, which scored 60%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=308">00:05:08.160</a></span> | <span class="t">And then the language model would propose iterations like let's think carefully about the problem and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=314">00:05:14.260</a></span> | <span class="t">solve it together. That got 63.2 and you can see the accuracy gradually going up. Apparently, at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=320">00:05:20.300</a></span> | <span class="t">for math problems, Palm 2 preferred concise prompts, while GPT models liked ones that were long and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=326">00:05:26.640</a></span> | <span class="t">detailed. And nor was it just about the semantics or meanings of the prompts. The same meanings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=332">00:05:32.260</a></span> | <span class="t">phrased differently could get radically different results. For example, with Palm 2, let's think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=337">00:05:37.500</a></span> | <span class="t">step-by-step, and then let's think about the semantics or meanings of the prompts. And then, let's think about the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=338">00:05:38.140</a></span> | <span class="t">got 71.8. Whereas let's solve the problem together has accuracy of 60.5. But then if you put those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=345">00:05:45.020</a></span> | <span class="t">two together and say let's work together to solve this problem step by step you only get 49.4.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=351">00:05:51.980</a></span> | <span class="t">Although semantically its meaning is just a combination of those two instructions. For the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=356">00:05:56.700</a></span> | <span class="t">original smart GPT I used this prompt. Let's work this out in a step-by-step way to be sure we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=361">00:06:01.580</a></span> | <span class="t">the right answer. That's because it performed best for GPT-4. As you can see here it doesn't perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=367">00:06:07.000</a></span> | <span class="t">best for palm 2. Although notice it does perform better than just an empty string. What does perform</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=372">00:06:12.760</a></span> | <span class="t">best? Well take a deep breath and work on this problem step by step. Also note the difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=378">00:06:18.180</a></span> | <span class="t">with beginning your answer with this prefix or beginning your question with a prefix. Anyway I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=384">00:06:24.180</a></span> | <span class="t">am hoping to do a deeper dive on this paper with one of the authors so for now I'll leave it there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=389">00:06:29.800</a></span> | <span class="t">Suffice to say that prompt engineering is not a solved science yet. But what was the Gemini news</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=396">00:06:36.060</a></span> | <span class="t">that I promised you from Google? Well this was published just 14 hours ago in the information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=401">00:06:41.380</a></span> | <span class="t">Google has as of yesterday given a small group of companies access to an early version of Gemini.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=407">00:06:47.560</a></span> | <span class="t">That is their direct competitor with OpenAI's GPT-4. According to a person who has tested it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=413">00:06:53.500</a></span> | <span class="t">Gemini has an advantage over GPT-4 in at least one respect. The model leverages reams of Google's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=419">00:06:59.460</a></span> | <span class="t">proprietary data from its consumer products in addition to public information scraped from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=425">00:07:05.080</a></span> | <span class="t">web. So the model should be able to do this. So let's take a look at the data. So the data is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=426">00:07:06.040</a></span> | <span class="t">should be especially accurate with all of those Google search histories when it comes to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=430">00:07:10.680</a></span> | <span class="t">understanding users intentions with particular queries. And apparently compared to GPT-4 it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=436">00:07:16.540</a></span> | <span class="t">generates fewer incorrect answers known as hallucinations. And again according to them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=441">00:07:21.720</a></span> | <span class="t">Gemini will feature vastly improved code generating abilities for software developers. Although note</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=447">00:07:27.560</a></span> | <span class="t">it says compared to its existing models. It didn't technically say compared to GPT-4. Note that Palm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=454">00:07:34.060</a></span> | <span class="t">2 didn't score particularly high for the model. So let's take a look at the data. So let's take a look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=455">00:07:35.620</a></span> | <span class="t">for coding so if that's the baseline bear that in mind. The version they're giving developers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=461">00:07:41.040</a></span> | <span class="t">isn't their largest version though which apparently will be on par with GPT-4. And in a first for this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=467">00:07:47.580</a></span> | <span class="t">channel I'm going to make a direct prediction using Metaculous. I'm going to predict that there</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=473">00:07:53.080</a></span> | <span class="t">will indeed be at least three months of third-party safety evaluations conducted on Gemini before its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=479">00:07:59.860</a></span> | <span class="t">deployment. I think they finished training the model sometime in summer so it will be more like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=484">00:08:04.660</a></span> | <span class="t">six months if it's released in December. The heart of this channel is about understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=489">00:08:09.460</a></span> | <span class="t">and navigating the future of AI so I am super proud that Metaculous are my first sponsors.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=495">00:08:15.740</a></span> | <span class="t">They have aggregate forecasts on a range of AI related questions. Yes it's free to sign up with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=503">00:08:23.020</a></span> | <span class="t">the link in the description so show them some love and say you came from AI Explained. Speaking of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=509">00:08:29.240</a></span> | <span class="t">the future though we learned this week in the Wall Street Journal that Meta plans to develop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=514">00:08:34.140</a></span> | <span class="t">Lama Theta and Meta's new technology. Meta is a new technology that will be available in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=514">00:08:34.640</a></span> | <span class="t">future. It will be available in the early days of the year and that will be Lama 3 sometime in early 2024. That will apparently be several times more powerful than Lama 2. Even more interesting to me though was this exchange at a recent Meta Gen I social. We have the compute to train Lama 3 and 4. The plan is for Lama 3 to be as good as GPT-4. Wow if Lama 3 is as good as GPT-4 will you guys still open source it? Yeah we will. Sorry alignment people. You can let me know in the comments what you think about that exchange. That is all for this video. I hope you enjoyed it and I will see you in the next one. Bye for now. Bye.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=544">00:09:04.100</a></span> | <span class="t">That is of course in complete contravention of what Senators Blumenthal and Hawley have put out. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=550">00:09:10.440</a></span> | <span class="t">week they released the bipartisan framework for US AI Act. In it they actually mentioned deepfakes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=556">00:09:16.520</a></span> | <span class="t">which I kind of showed you earlier with HeyGen. But they also focused on AI audits and establishing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=562">00:09:22.480</a></span> | <span class="t">an oversight body that should have the authority to conduct audits of companies seeking licenses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=567">00:09:27.780</a></span> | <span class="t">But I suspect the people signing up to work in that auditing office will have to commit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=573">00:09:33.600</a></span> | <span class="t">to not working for any of the AI companies for the rest of their lives. That's going to take a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=579">00:09:39.040</a></span> | <span class="t">particularly motivated individual particularly on public sector pay levels. Why do I say that?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=584">00:09:44.460</a></span> | <span class="t">Well here's Mustafa Suleiman. He recently said this on 80,000 hours.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=589">00:09:49.460</a></span> | <span class="t">Well I'm really stuck. I think it's really hard. There is another direction which involves academic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=595">00:09:55.440</a></span> | <span class="t">groups getting more access and either actually doing red teaming or doing audits of scale or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=603">00:10:03.100</a></span> | <span class="t">audits of model capabilities. Right. They're the three proposals that I've heard made and I've been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=608">00:10:08.520</a></span> | <span class="t">very supportive of and have certainly explored with people at Stanford and elsewhere. But I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=613">00:10:13.840</a></span> | <span class="t">there's a real problem there which is if you take the average PhD student or postdoctoral researcher</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=618">00:10:18.600</a></span> | <span class="t">that might work on this in a couple of years they may well go to a commercial lab. Right. And so if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=625">00:10:25.500</a></span> | <span class="t">we're to give them access then they'll probably take that knowledge and expertise elsewhere</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=630">00:10:30.620</a></span> | <span class="t">potentially to a competitor. I mean it's an open.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=632">00:10:32.840</a></span> | <span class="t">Labor market after all. And when we heard this week that the IRS in America are going to use AI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=638">00:10:38.240</a></span> | <span class="t">to catch tax evasion it made me think that it's going to increasingly be a cat and mouse game</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=643">00:10:43.620</a></span> | <span class="t">between governments and auditors using AI on the one side and the companies developing the AI on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=649">00:10:49.160</a></span> | <span class="t">the other side. If the IRS has an AI that can detect tax evasion well then a hedge fund can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=654">00:10:54.680</a></span> | <span class="t">just make an AI to obscure that tax evasion. Seems to me that in all of this whoever has the most</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=660">00:11:00.300</a></span> | <span class="t">compute will win. And remember these won't just be the ones that are going to be the ones that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=662">00:11:02.820</a></span> | <span class="t">single modality language models anymore. To take one crazy example this week, we now have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=668">00:11:08.020</a></span> | <span class="t">'Smell to Text'. It's a much more narrow AI trained in a very different way to GPT models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=673">00:11:13.860</a></span> | <span class="t">but it matches well with expert humans on novel smells. And then there's 'Protein Chat' which I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=679">00:11:19.300</a></span> | <span class="t">didn't get a chance to talk about earlier in the year. The so-called 'Protein GPT' enables users</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=684">00:11:24.900</a></span> | <span class="t">to upload proteins, ask questions and engage in interactive conversations to gain insights.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=690">00:11:30.580</a></span> | <span class="t">And if that's not enough modalities, how about this? This is 'Next GPT', a multimodal LLM released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=696">00:11:36.980</a></span> | <span class="t">two days ago that can go from any modality to any modality. Obviously there should be an asterisk</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=702">00:11:42.980</a></span> | <span class="t">over 'any', it isn't quite 'any' yet, but we're talking about images, audio, video and then the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=707">00:11:47.780</a></span> | <span class="t">output being images, audio, text, video. One obvious question is: do we want one model to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=713">00:11:53.540</a></span> | <span class="t">be good at everything or do we want narrower AI that's good at individual tasks? And this links</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=719">00:11:59.940</a></span> | <span class="t">to 'Iron Man' which is a very common model that's used in AI training. And this links to 'Iron Man'</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=720">00:12:00.340</a></span> | <span class="t">and 'Iron Man' which is a very common model that's used in AI training. And this links to 'Iron Man'</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=720">00:12:00.420</a></span> | <span class="t">and 'Iron Man' which is a very common model that's used in AI training. And this links to 'Iron Man'</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=720">00:12:00.420</a></span> | <span class="t">Ajax GPT from Apple. Now, of course, I did watch the iPhone launch, but I find this more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=726">00:12:06.180</a></span> | <span class="t">interesting. This was an exclusive for the information, and they talk about how Apple's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=730">00:12:10.980</a></span> | <span class="t">LLM is designed to boost Siri. And it almost sounds to me like Open Interpreter, where you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=736">00:12:16.700</a></span> | <span class="t">can automate tasks involving multiple steps. For example, telling Siri to create a GIF using the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=742">00:12:22.920</a></span> | <span class="t">last five photos you've taken and text it to a friend. And this was the most interesting part</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=748">00:12:28.320</a></span> | <span class="t">of the piece for me. Earlier in the article, they talked about how they're spending millions of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=752">00:12:32.660</a></span> | <span class="t">dollars a day on iXGPT. They're still quite far behind because apparently iXGPT beats GPT 3.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=759">00:12:39.700</a></span> | <span class="t">the original ChatGPT, but not GPT 4. The focus is on running LLMs on your device with the goal</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=766">00:12:46.380</a></span> | <span class="t">of improving privacy and performance. So iXGPT might not be the best LLM, but they're pitching</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=772">00:12:52.440</a></span> | <span class="t">it as the best LLM on your phone. The model they have at the moment is apparently too big. It's 200</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=778">00:12:58.660</a></span> | <span class="t">billion parameters. Even a MacBook might struggle to run that, but they might have different sizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=784">00:13:04.040</a></span> | <span class="t">of iX, some small enough to run on an iPhone. Of course, from a user point of view, that would mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=790">00:13:10.480</a></span> | <span class="t">you can use the model offline, unlike, say, the ChatGPT app. Let's move on now to a lighter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=796">00:13:16.460</a></span> | <span class="t">development, albeit one that might affect hundreds of millions of people, including my nephew.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=801">00:13:21.580</a></span> | <span class="t">Apparently, the iXGPT is a little bit more expensive than the iXGPT, but it's still a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=802">00:13:22.420</a></span> | <span class="t">the online game platform Roblox is bringing in a new AI chatbot. That's going to allow creators to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=808">00:13:28.840</a></span> | <span class="t">build virtual worlds just by typing prompts. And that's the crazy thing. All of this is going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=814">00:13:34.340</a></span> | <span class="t">become intuitive to the next generation. Children today are just going to expect their apps to be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=820">00:13:40.160</a></span> | <span class="t">interactive and customizable on demand. And yes, we have covered a lot today, so let me know what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=825">00:13:45.860</a></span> | <span class="t">you think. I'm going to end with an AI image that has taken the internet by storm, as well as a few</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=832">00:13:52.400</a></span> | <span class="t">more things that I've been able to do to make it more accessible. And I'll see you in the next video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=836">00:13:56.340</a></span> | <span class="t">Thanks as always for watching to the end. Do check out Metaculous in the description. And as ever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=voEIQgh5zGs&t=846">00:14:06.020</a></span> | <span class="t">have a wonderful day.</span></div></div></body></html>