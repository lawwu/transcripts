<html><head><title>OpenAI Backtracks, Gunning for Superintelligence: Altman Brings His AGI Timeline Closer - '25 to '29</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>OpenAI Backtracks, Gunning for Superintelligence: Altman Brings His AGI Timeline Closer - '25 to '29</h2><a href="https://www.youtube.com/watch?v=j3eQoooC7wc"><img src="https://i.ytimg.com/vi/j3eQoooC7wc/maxresdefault.jpg" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=0">0:0</a> Introduction<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=63">1:3</a> Altman Timeline Moves Forward<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=273">4:33</a> Superintelligence?<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=415">6:55</a> AGI was not the only pitch<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=566">9:26</a> AgentCompany and OpenAI New Agent<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1044">17:24</a> SimpleBench Competition<br><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1383">23:3</a> Kling 1.6 vs Veo 2 vs Sora<br><br><div style="text-align: left;"><a href="./j3eQoooC7wc.html">Whisper Transcript</a> | <a href="./transcript_j3eQoooC7wc.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">For the few that think 2025 will be a quieter year in AI after the somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=6" target="_blank">00:00:06.400</a></span> | <span class="t">hectic pace you could say of 23 and 24, I'm going to have to disagree with you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=11" target="_blank">00:00:11.360</a></span> | <span class="t">This video will first highlight how the CEO of OpenAI has revised his timelines for AGI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=18" target="_blank">00:00:18.240</a></span> | <span class="t">forward and revised upward his already aggressive definition of what counts as an AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=25" target="_blank">00:00:25.120</a></span> | <span class="t">Okay, that's just one guy, but then we'll see how OpenAI itself have backtracked on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=30" target="_blank">00:00:30.720</a></span> | <span class="t">whether they are working on superintelligence at all. Just a minor misunderstanding I am sure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=36" target="_blank">00:00:36.640</a></span> | <span class="t">Then, as we enter this bright new year, I'll cover a fascinating new paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=41" target="_blank">00:00:41.600</a></span> | <span class="t">and what it says about the current limitations of LLMs. I'll give my prediction of how quickly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=47" target="_blank">00:00:47.360</a></span> | <span class="t">things will change this year with models completing real-world tasks on your behalf.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=52" target="_blank">00:00:52.240</a></span> | <span class="t">I'm going to launch a cool competition for you guys with actual prizes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=56" target="_blank">00:00:56.160</a></span> | <span class="t">and end on a fun little demo of the latest in-textor video from Kling and VO2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=63" target="_blank">00:01:03.040</a></span> | <span class="t">But first, Sam Altman's subtle timeline shift on when AGI is coming.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=68" target="_blank">00:01:08.320</a></span> | <span class="t">I noticed the shift in this substantial interview with Bloomberg from a couple days ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=74" target="_blank">00:01:14.000</a></span> | <span class="t">How does he define AGI? Well, check out this somewhat aggressive definition that seems new to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=79" target="_blank">00:01:19.280</a></span> | <span class="t">me. He says AGI is when an AI system can do what very skilled humans in important jobs can do.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=86" target="_blank">00:01:26.480</a></span> | <span class="t">You might wonder why he would make the definition of AGI harder on himself and OpenAI, but I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=92" target="_blank">00:01:32.320</a></span> | <span class="t">come to that a bit later. Suffice to say, when we have an AI system that can do what very skilled</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=97" target="_blank">00:01:37.920</a></span> | <span class="t">humans can do in important jobs, that would be quite an epochal moment. Of course, it seems like</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=104" target="_blank">00:01:44.880</a></span> | <span class="t">we're really far away from that because even systems that can crush benchmarks like O1 from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=110" target="_blank">00:01:50.080</a></span> | <span class="t">OpenAI and O3, they can't even, say, open up screen recording software, record a video, edit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=116" target="_blank">00:01:56.400</a></span> | <span class="t">it in Premiere Pro, and publish it. That's all well and good, he says nervously, but things could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=121" target="_blank">00:02:01.360</a></span> | <span class="t">change on that front fairly soon. But bear in mind that more aggressive definition for what AGI will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=128" target="_blank">00:02:08.000</a></span> | <span class="t">do when you read this prediction from Sam Altman. I think AGI will probably get developed during</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=135" target="_blank">00:02:15.360</a></span> | <span class="t">this president's term, and getting that right seems really important. Trump's term, of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=140" target="_blank">00:02:20.480</a></span> | <span class="t">runs from January of 2025 to January of 2029. Those of you who have been following the channel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=147" target="_blank">00:02:27.520</a></span> | <span class="t">closely might remember that that's an update on what he was saying until fairly recently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=152" target="_blank">00:02:32.720</a></span> | <span class="t">On Joe Rogan, last summer, before the training of the latest O3 model, he was saying how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=158" target="_blank">00:02:38.240</a></span> | <span class="t">appropriate it would be if AGI was developed in 2030, but kind of pushed it back to 2031.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=164" target="_blank">00:02:44.560</a></span> | <span class="t">I no longer think of AGI as quite the end point, but to get to the point where we accomplish the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=170" target="_blank">00:02:50.160</a></span> | <span class="t">thing we set out to accomplish, that would take us to 2030, 2031. That has felt to me all the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=179" target="_blank">00:02:59.920</a></span> | <span class="t">through kind of a reasonable estimate with huge error bars, and I kind of think we're on the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=186" target="_blank">00:03:06.080</a></span> | <span class="t">trajectory I sort of would have assumed. Moreover, the president of Y Combinator</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=191" target="_blank">00:03:11.120</a></span> | <span class="t">thought that Sam Altman was being serious in his interview with Sam Altman, when Sam Altman implied</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=197" target="_blank">00:03:17.360</a></span> | <span class="t">that it might be the year of 2025 in which we get AGI. And he echoed that suspicion again in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=204" target="_blank">00:03:24.640</a></span> | <span class="t">the Bloomberg interview from a couple days ago, saying, "Funnily enough, I remember thinking to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=209" target="_blank">00:03:29.520</a></span> | <span class="t">myself back then, in 2015, that we would do it, build AGI, in 2025." The point here is not for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=215" target="_blank">00:03:35.920</a></span> | <span class="t">you to believe that particular date, it's just to note the clear shift in emphasis. And this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=221" target="_blank">00:03:41.840</a></span> | <span class="t">of course, follows Sam Altman's blog post from 48 hours ago, in which he said, "OpenAI are now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=227" target="_blank">00:03:47.280</a></span> | <span class="t">confident that we know how to build AGI, as we have traditionally understood it. We believe that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=232" target="_blank">00:03:52.400</a></span> | <span class="t">in 2025, we may see the first AI agents join the workforce and materially change the output of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=239" target="_blank">00:03:59.920</a></span> | <span class="t">companies. Of course, we are close enough now to these dates that we won't have to wait too long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=245" target="_blank">00:04:05.440</a></span> | <span class="t">to see if they manifest themselves. It turns out, though, that building powerful things is quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=251" target="_blank">00:04:11.200</a></span> | <span class="t">addictive because OpenAI, and Sam Altman specifically, don't want to stop with AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=256" target="_blank">00:04:16.320</a></span> | <span class="t">They don't want to automate particular tasks in important jobs. They want the whole cake.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=261" target="_blank">00:04:21.120</a></span> | <span class="t">We are beginning to turn our aim beyond AGI to superintelligence in the true sense of the word,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=267" target="_blank">00:04:27.600</a></span> | <span class="t">a glorious future in which they can do anything else." And that statement comes just six months</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=274" target="_blank">00:04:34.560</a></span> | <span class="t">after OpenAI explicitly denied that that was their mission. OpenAI's Vice President of Global</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=280" target="_blank">00:04:40.160</a></span> | <span class="t">Affairs told the Financial Times in May of last year that their mission is to build AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=286" target="_blank">00:04:46.000</a></span> | <span class="t">"I would not say our mission is to build superintelligence. Superintelligence is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=290" target="_blank">00:04:50.080</a></span> | <span class="t">to be a technology that is going to be orders of magnitude more intelligent than human beings</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=294" target="_blank">00:04:54.320</a></span> | <span class="t">on Earth." And another spokesperson said superintelligence was not the company's mission,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=299" target="_blank">00:04:59.840</a></span> | <span class="t">though she admitted "we might study superintelligence." I'll note that massively</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=305" target="_blank">00:05:05.040</a></span> | <span class="t">increasing abundance and prosperity and being super capable of accelerating scientific discovery</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=311" target="_blank">00:05:11.200</a></span> | <span class="t">and innovation doesn't sound like just studying superintelligence. It sounds like they want to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=316" target="_blank">00:05:16.320</a></span> | <span class="t">do anything else. There is, though, probably a reason why those spokespeople denied that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=322" target="_blank">00:05:22.240</a></span> | <span class="t">were in pursuit of superintelligence. One reason could be that 10 years ago, almost to the month,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=327" target="_blank">00:05:27.920</a></span> | <span class="t">Sam Altman said that the development of superhuman machine intelligence is probably</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=332" target="_blank">00:05:32.160</a></span> | <span class="t">the greatest threat to the continued existence of humanity. Remember, though, it suits OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=337" target="_blank">00:05:37.360</a></span> | <span class="t">to keep pushing back or up the definition of what counts as AGI or superintelligence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=343" target="_blank">00:05:43.680</a></span> | <span class="t">They're trying to change it, but as of today, there is a clause that kicks in where Microsoft</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=349" target="_blank">00:05:49.440</a></span> | <span class="t">surrendered the rights to "AGI technology" that OpenAI makes if it's defined to be AGI. So now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=356" target="_blank">00:05:56.240</a></span> | <span class="t">despite several OpenAI employees claiming that their current systems, like O3, are AGI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=362" target="_blank">00:06:02.160</a></span> | <span class="t">we have these five stages of AGI. AGI has to be not just a reasoner, but also an agent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=368" target="_blank">00:06:08.880</a></span> | <span class="t">a system that can take action, and an innovator, and even have the power of an entire organization.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=375" target="_blank">00:06:15.440</a></span> | <span class="t">Seems like we really are stretching the definition of general intelligence quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=379" target="_blank">00:06:19.680</a></span> | <span class="t">far here. Microsoft, by the way, you might not know, want that definition stretched even more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=384" target="_blank">00:06:24.160</a></span> | <span class="t">To be counted as AGI, the system must itself be able to generate profits of $100 billion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=390" target="_blank">00:06:30.880</a></span> | <span class="t">Wait, I've just realized that I can't personally generate profits of $100 billion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=395" target="_blank">00:06:35.440</a></span> | <span class="t">and there are very few of you in the audience who can do so. So does that mean that we're not AGI?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=400" target="_blank">00:06:40.640</a></span> | <span class="t">Damn, maybe Elon Musk is the only AGI on the planet? That would be really weird.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=404" target="_blank">00:06:44.560</a></span> | <span class="t">Anyway, as you can see, words seem to chop and change their meaning at people's convenience,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=409" target="_blank">00:06:49.280</a></span> | <span class="t">so bear that in mind. Speaking of which, there is some history you probably need to know going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=413" target="_blank">00:06:53.920</a></span> | <span class="t">back to the very founding of OpenAI in 2015. In this week's interview with Bloomberg,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=418" target="_blank">00:06:58.560</a></span> | <span class="t">someone was asked, "How did you poach that top AI research talent to get OpenAI started,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=423" target="_blank">00:07:03.840</a></span> | <span class="t">often when you had much less money to offer than your competitors?" He said, "The pitch was just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=429" target="_blank">00:07:09.840</a></span> | <span class="t">come build AGI." And he said, "That worked because it was heretical at the time to say we're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=436" target="_blank">00:07:16.480</a></span> | <span class="t">build AGI." Actually, that's not quite accurate. The pitch definitely wasn't just to come build AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=443" target="_blank">00:07:23.120</a></span> | <span class="t">The pitch was that they were going to do the right thing with AGI. And that's how they won</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=448" target="_blank">00:07:28.720</a></span> | <span class="t">over people who were tempted by DeepMind offering even more money. If those researchers just wanted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=453" target="_blank">00:07:33.840</a></span> | <span class="t">to work on AGI, they could have just joined DeepMind because a year before that offer from</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=458" target="_blank">00:07:38.560</a></span> | <span class="t">Sam Altman, Demis Hassabis was doing interviews talking about how they're working on artificial</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=463" target="_blank">00:07:43.040</a></span> | <span class="t">general intelligence. Or here's an article from a year before that in which the co-founder of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=468" target="_blank">00:07:48.000</a></span> | <span class="t">DeepMind, Shane Legg, says that they are working on creating AGI by 2030. No, the pitch was that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=474" target="_blank">00:07:54.960</a></span> | <span class="t">OpenAI were going to create AGI and have it be controlled by a non-profit. And by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=481" target="_blank">00:08:01.040</a></span> | <span class="t">that is still the situation today, despite the board debacle a year ago with firing Sam Altman</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=487" target="_blank">00:08:07.600</a></span> | <span class="t">and joining up with Microsoft and investing billions and billions. Yes, it turned out that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=491" target="_blank">00:08:11.760</a></span> | <span class="t">billions and billions was needed for scaling. But still, as of today, if AGI is created by OpenAI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=497" target="_blank">00:08:17.280</a></span> | <span class="t">it's controlled by the non-profit board. Two weeks ago, though, OpenAI revealed that they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=502" target="_blank">00:08:22.320</a></span> | <span class="t">are planning to change that. Of course, it's phrased in terms of this is best for the long-term</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=507" target="_blank">00:08:27.200</a></span> | <span class="t">success of the mission and we're doing it to benefit all of humanity. But the critical detail</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=512" target="_blank">00:08:32.160</a></span> | <span class="t">is that the non-profit wouldn't control the AGI. It would get a ton of money for healthcare,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=517" target="_blank">00:08:37.600</a></span> | <span class="t">education, and science. But that's very different from controlling what is done with an AGI or a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=523" target="_blank">00:08:43.760</a></span> | <span class="t">superintelligence. The until very recently former head of policy research at OpenAI, Miles Brundage,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=530" target="_blank">00:08:50.240</a></span> | <span class="t">said that a well-capitalized non-profit on the side is no substitute for being aligned with the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=535" target="_blank">00:08:55.920</a></span> | <span class="t">original non-profit's mission on safety mitigation. Another former lead researcher at OpenAI said,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=542" target="_blank">00:09:02.000</a></span> | <span class="t">"It's pretty disappointing that 'ensure AGI benefits all of humanity' gave way to a much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=547" target="_blank">00:09:07.040</a></span> | <span class="t">less ambitious charitable initiatives in sectors such as healthcare, education, and science."</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=551" target="_blank">00:09:11.760</a></span> | <span class="t">Even if you don't care about any of that, you may find it somewhat curious that Microsoft is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=556" target="_blank">00:09:16.800</a></span> | <span class="t">getting serious about defining the terms of what counts as AGI and what they get out of it. If that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=562" target="_blank">00:09:22.640</a></span> | <span class="t">$3 trillion behemoth thought all of this was going nowhere, then why bother? All of that leads very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=568" target="_blank">00:09:28.720</a></span> | <span class="t">naturally to the next obvious question. Well, how close are we then to AGI? Have we, in somewhat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=575" target="_blank">00:09:35.120</a></span> | <span class="t">grandiose terms, crossed the event horizon of the singularity? Sam Ullman is unclear whether we have,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=582" target="_blank">00:09:42.400</a></span> | <span class="t">but what do you think? For me, one obvious obstacle is the inability of models to complete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=587" target="_blank">00:09:47.840</a></span> | <span class="t">somewhat basic tasks on their own. You could count this under the umbrella of lacking reliability.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=593" target="_blank">00:09:53.120</a></span> | <span class="t">But we are starting to get good benchmarks for consequential real-world tasks, as in this paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=599" target="_blank">00:09:59.120</a></span> | <span class="t">from the 18th of December. As we'll see, these tasks were sourced from the most common of those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=604" target="_blank">00:10:04.960</a></span> | <span class="t">performed in real-world professions. And yes, as of today, just 24% of the tasks can be completed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=612" target="_blank">00:10:12.240</a></span> | <span class="t">autonomously, although they weren't able to test O3, for example. Here's the thing though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=616" target="_blank">00:10:16.960</a></span> | <span class="t">that 24% was roughly the performance we were getting from, say, GPT-4 18 months ago on a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=623" target="_blank">00:10:23.520</a></span> | <span class="t">benchmark called GPQA - Google-proof, PhD-level science questions. Roughly a year after that,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=630" target="_blank">00:10:30.880</a></span> | <span class="t">O1 preview got 70% and O3, by the way, gets 87%. Also, you might note that the pace of improvement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=639" target="_blank">00:10:39.360</a></span> | <span class="t">has increased quite dramatically in the last 6 months, basically since the O1 paradigm came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=644" target="_blank">00:10:44.560</a></span> | <span class="t">I know what some of you might be thinking, is the GPQA that hard? Are they working on a harder one?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=649" target="_blank">00:10:49.520</a></span> | <span class="t">Well, check this out. This is from a talk this week by Jason Wei of OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=674" target="_blank">00:11:14.240</a></span> | <span class="t">All of which is to say, that 24% could become 84% faster than you might think.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=680" target="_blank">00:11:20.640</a></span> | <span class="t">And indeed, that would be my prediction. 84% by the end of 2025. But wait, how impactful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=686" target="_blank">00:11:26.880</a></span> | <span class="t">would that jump from, say, 24% to 84% be? Well, to find out, here's my 2-minute summary of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=693" target="_blank">00:11:33.920</a></span> | <span class="t">24-page paper. First, they trawled a massive database of all tasks done by professionals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=699" target="_blank">00:11:39.760</a></span> | <span class="t">in America. They excluded physical labor and focused on those jobs in which a large number</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=705" target="_blank">00:11:45.440</a></span> | <span class="t">of people performed the job. They also weighted the tasks by the median salary of those performing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=710" target="_blank">00:11:50.800</a></span> | <span class="t">the tasks. That narrowed things down to 175 diverse, realistic tasks like arranging meeting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=716" target="_blank">00:11:56.160</a></span> | <span class="t">rooms, analysing spreadsheets and screening resumes, which they gave the imaginary setting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=720" target="_blank">00:12:00.960</a></span> | <span class="t">of a software engineering company. Some of the tasks, of course, required interaction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=725" target="_blank">00:12:05.600</a></span> | <span class="t">with other colleagues and the models could do that, although the colleagues were role-played</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=730" target="_blank">00:12:10.160</a></span> | <span class="t">by Claude. The tasks should be clear enough so that any human worker would be able to complete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=734" target="_blank">00:12:14.960</a></span> | <span class="t">the task without asking for further instructions. Although, of course, they may need to ask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=739" target="_blank">00:12:19.200</a></span> | <span class="t">questions of their co-workers. The evaluations of task performance were mostly deterministic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=744" target="_blank">00:12:24.400</a></span> | <span class="t">which is good, and there was a heavy weighting toward whether the model could fully complete</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=749" target="_blank">00:12:29.360</a></span> | <span class="t">the task. Partial completion would always result in less than half marks. Here's an example of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=754" target="_blank">00:12:34.880</a></span> | <span class="t">a task with multiple steps and checkpoints, and if at one point to run a code coverage script,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=761" target="_blank">00:12:41.680</a></span> | <span class="t">it didn't recognize it needed to install certain dependencies, it would fail that checkpoint and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=766" target="_blank">00:12:46.000</a></span> | <span class="t">therefore for this score of 4 out of 8, it would actually get 25% only. You can see the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=771" target="_blank">00:12:51.680</a></span> | <span class="t">results here and you might wonder why I'm predicting 84% by the end of the year if even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=777" target="_blank">00:12:57.600</a></span> | <span class="t">Claude is getting, say, 24%. If we're that far away from task automation, why was it reported</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=783" target="_blank">00:13:03.680</a></span> | <span class="t">yesterday that OpenAI are releasing a computer-using agent as soon as this month? Indeed,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=789" target="_blank">00:13:09.920</a></span> | <span class="t">why have Anthropic already released a computer-use agent in beta? That launch from Anthropic was</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=795" target="_blank">00:13:15.840</a></span> | <span class="t">apparently mocked by OpenAI leaders because of its risks for things like prompt injection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=800" target="_blank">00:13:20.960</a></span> | <span class="t">and Anthropic's high-minded rhetoric, it says, about AI safety. The reason, though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=805" target="_blank">00:13:25.440</a></span> | <span class="t">that that prediction and all of these releases can still make sense despite these disappointing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=810" target="_blank">00:13:30.880</a></span> | <span class="t">results is because of reinforcement learning. That, after all, is the secret to why O1 and now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=816" target="_blank">00:13:36.880</a></span> | <span class="t">O3 has broken the benchmark that it has done. Push a model to try again and again and again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=823" target="_blank">00:13:43.040</a></span> | <span class="t">until it completes a task successfully and then reinforce those weights that led it to doing so.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=827" target="_blank">00:13:47.840</a></span> | <span class="t">As Vedant Mishra, who's working on superintelligence at DeepMind and was formerly of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=832" target="_blank">00:13:52.560</a></span> | <span class="t">OpenAI, has said, "There are maybe a few hundred people in the world who viscerally understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=837" target="_blank">00:13:57.840</a></span> | <span class="t">what's coming. Most are at DeepMind, OpenAI, Anthropic, or X, or I would say in my audience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=843" target="_blank">00:14:03.280</a></span> | <span class="t">Some are on the outside. You have to be able to forecast the aggregate effect of rapid algorithmic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=848" target="_blank">00:14:08.320</a></span> | <span class="t">improvement, aggressive investment in building reinforcement learning environments for iterative</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=853" target="_blank">00:14:13.280</a></span> | <span class="t">self-improvement, and of course the tens of billions already committed to building data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=857" target="_blank">00:14:17.200</a></span> | <span class="t">centers. Either we're all wrong or everything's about to change." The reason, of course, that task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=863" target="_blank">00:14:23.040</a></span> | <span class="t">can be so much more difficult than scientific multiple choice questions is because one mistake</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=868" target="_blank">00:14:28.800</a></span> | <span class="t">at any stage in a long chain can screw everything up. That apparently, by the way, was one of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=874" target="_blank">00:14:34.160</a></span> | <span class="t">key reasons why ArcAGI wasn't solved until O3. I've done other videos explaining ArcAGI, but for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=880" target="_blank">00:14:40.960</a></span> | <span class="t">now, when the grid count of the tasks was below a certain threshold, models did fairly well, even</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=886" target="_blank">00:14:46.880</a></span> | <span class="t">earlier models. But when you're talking about a massive grid, those long-range dependencies get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=892" target="_blank">00:14:52.240</a></span> | <span class="t">harder and harder to spot. A bit like solving a task where you have to remember something that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=896" target="_blank">00:14:56.080</a></span> | <span class="t">someone said a thousand steps ago. Until O3, models simply couldn't cope with that amount</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=901" target="_blank">00:15:01.760</a></span> | <span class="t">of complexity. This chart, by the way, came from a great study linked in the description from Mikel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=907" target="_blank">00:15:07.360</a></span> | <span class="t">Bober-Irizar. He showed that unlike humans where the task length didn't make that much difference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=913" target="_blank">00:15:13.120</a></span> | <span class="t">LLMs really struggled when the task length went beyond a certain size. In short, the benchmark</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=918" target="_blank">00:15:18.880</a></span> | <span class="t">fell in large part due to scaling, which of course will continue throughout 2025, if not speed up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=925" target="_blank">00:15:25.760</a></span> | <span class="t">And that's why I think people are scrambling to create new benchmarks for task performance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=931" target="_blank">00:15:31.280</a></span> | <span class="t">such as Epoch AI, who are behind the famous frontier math. That's the ridiculously hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=936" target="_blank">00:15:36.640</a></span> | <span class="t">benchmark that O3 scored around 25% on to everyone's amazement. There are, however,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=941" target="_blank">00:15:41.840</a></span> | <span class="t">just a few more reasons why LLMs fail on task benchmarks like Aging Company. Some of these,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=948" target="_blank">00:15:48.240</a></span> | <span class="t">I find personally quite funny. Sometimes it's through a lack of social skills. For example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=952" target="_blank">00:15:52.960</a></span> | <span class="t">one time the model was told by a colleague, role played by Claude, you should introduce yourself</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=958" target="_blank">00:15:58.000</a></span> | <span class="t">to Chen Xingyi next. She's on our front end team and would be a great person to connect with. At</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=963" target="_blank">00:16:03.920</a></span> | <span class="t">this point, a human would then talk to Chen, but instead the agent then decides not to follow up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=968" target="_blank">00:16:08.720</a></span> | <span class="t">with her and prematurely considers the task accomplished. Chen, by the way, in this simulated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=973" target="_blank">00:16:13.520</a></span> | <span class="t">environment was a human resources manager, a bit like Toby from The Office. Also, the agent</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=979" target="_blank">00:16:19.040</a></span> | <span class="t">struggled heavily with pop-ups. Multiple times, apparently, they struggled to close the pop-up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=984" target="_blank">00:16:24.480</a></span> | <span class="t">windows. And so it could well be that cookie banners are the major obstacle between us and AGI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=990" target="_blank">00:16:30.800</a></span> | <span class="t">Also, here is a slightly more worrying one, which reminds me of the scheming exposed by Epoch,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=997" target="_blank">00:16:37.040</a></span> | <span class="t">among others. Sometimes when there is a particularly hard step, the model will just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1002" target="_blank">00:16:42.560</a></span> | <span class="t">fake that it's done. For example, during the execution of one task, the agent could not find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1007" target="_blank">00:16:47.280</a></span> | <span class="t">the right person to ask questions to on the team chat. As a result, it then decides to create a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1012" target="_blank">00:16:52.000</a></span> | <span class="t">shortcut solution by renaming another user to the name of the intended user. Remember, it's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1017" target="_blank">00:16:57.920</a></span> | <span class="t">necessarily that the models want to cheat, but if they are rewarded sufficiently for cheating,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1023" target="_blank">00:17:03.760</a></span> | <span class="t">that's what they'll do. That is, I guess, another bitter lesson from reinforcement learning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1028" target="_blank">00:17:08.480</a></span> | <span class="t">But now for the final reason given in the paper, a lack of common sense. This for me is the grist</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1034" target="_blank">00:17:14.800</a></span> | <span class="t">that makes so much of the world go round and why models often struggle in real-world performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1040" target="_blank">00:17:20.000</a></span> | <span class="t">You gotta sometimes step back, see the bigger picture and re-evaluate your entire strategy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1044" target="_blank">00:17:24.560</a></span> | <span class="t">This lack of common sense or simple reasoning is of course what I am trying to test with SimpleBench</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1050" target="_blank">00:17:30.080</a></span> | <span class="t">with a public leaderboard linked in the description. And here is a brand new example</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1055" target="_blank">00:17:35.040</a></span> | <span class="t">from the hundreds in the benchmark and you'll see why I'm giving it to you in a moment. You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1059" target="_blank">00:17:39.120</a></span> | <span class="t">can pause and try it yourself, but it illustrates the point I'm trying to make. Hussain types a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1064" target="_blank">00:17:44.000</a></span> | <span class="t">letter on a normal laptop screen and he can see any letters on the screen clearly. Every second,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1070" target="_blank">00:17:50.320</a></span> | <span class="t">the letter will randomly transform into another letter of the alphabet. Hussain is in a park and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1076" target="_blank">00:17:56.320</a></span> | <span class="t">slowly inches back from the laptop but has just one item with him, a remote controller so he can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1082" target="_blank">00:18:02.560</a></span> | <span class="t">increase the font size of the changing letters by exactly as much as he wants. Hussain has always</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1089" target="_blank">00:18:09.440</a></span> | <span class="t">had trouble distinguishing W's from M's so when he is a couple of football field lengths away</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1097" target="_blank">00:18:17.600</a></span> | <span class="t">from this laptop, a couple of football field lengths away, controller in hand, he has a blank</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1104" target="_blank">00:18:24.480</a></span> | <span class="t">probability of correctly guessing the current letter. 96%, 95%, 97%, 1/26, 0% or 1/2. I asked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1113" target="_blank">00:18:33.600</a></span> | <span class="t">the famously expensive O1 Pro which Sam Ullman recently said they are losing money on it's so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1119" target="_blank">00:18:39.360</a></span> | <span class="t">expensive to serve and it said this. First note that Hussain can make the letter as large as he</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1125" target="_blank">00:18:45.680</a></span> | <span class="t">wants so he has no problem identifying any letter except the W's from M's. One last time though,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1133" target="_blank">00:18:53.280</a></span> | <span class="t">he is two football field lengths away from a normal laptop screen. If he was a few feet away,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1140" target="_blank">00:19:00.480</a></span> | <span class="t">the increasing font would indeed be helpful but two football field lengths away doesn't matter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1145" target="_blank">00:19:05.520</a></span> | <span class="t">if you make the font size 1 billion, he can barely even see the screen. And by the way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1150" target="_blank">00:19:10.080</a></span> | <span class="t">you can make this 10 football fields and O1 Pro will still give the same answer. It will focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1156" target="_blank">00:19:16.080</a></span> | <span class="t">on the distraction of the W's and the M's and give the answer of 96%. The official answer by the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1162" target="_blank">00:19:22.480</a></span> | <span class="t">is not actually 0% because even if you can't see the screen, you still have a 1/26 chance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1168" target="_blank">00:19:28.320</a></span> | <span class="t">guessing the right letter. Now what many of you have told me is that if we simply change the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1173" target="_blank">00:19:33.840</a></span> | <span class="t">prompt, models like O1 would get all of these questions correct. Now though, I am very excited</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1179" target="_blank">00:19:39.440</a></span> | <span class="t">to tell you we can put that to the test. Weights and Biases, I'm very happy to say, are sponsoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1184" target="_blank">00:19:44.960</a></span> | <span class="t">a competition for you guys running to the end of January on 20 questions from Simple Bench.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1191" target="_blank">00:19:51.520</a></span> | <span class="t">That's the 10 public questions that are already out there on the website plus 10 more specially</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1196" target="_blank">00:19:56.160</a></span> | <span class="t">for this competition. The winner will get some meta Ray-Bans, 2nd place gets gift cards and I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1201" target="_blank">00:20:01.760</a></span> | <span class="t">believe 3rd place gets some swag. Either way, all you need to do is open up the Colab and run each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1206" target="_blank">00:20:06.960</a></span> | <span class="t">of these cells and yes, it's not authored by Google. You will of course need either an OpenAI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1212" target="_blank">00:20:12.480</a></span> | <span class="t">API key or an Anthropic API key. I recommend trying with Claude 3.5 Sonnet or O1 Preview/O1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1220" target="_blank">00:20:20.080</a></span> | <span class="t">if you have access. If you already have a Weights and Biases account, it literally takes maybe 30</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1225" target="_blank">00:20:25.680</a></span> | <span class="t">seconds to set up but even if you don't, it's completely free to have the account. The first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1231" target="_blank">00:20:31.760</a></span> | <span class="t">easy option is to do a quick run with GPC 4.0 on those 20 questions but there is a more exciting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1237" target="_blank">00:20:37.840</a></span> | <span class="t">option below. By the way, true count tells you how many questions your model got right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1242" target="_blank">00:20:42.800</a></span> | <span class="t">and the true fraction is that number out of the total number of calls. The mean is just referring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1249" target="_blank">00:20:49.360</a></span> | <span class="t">to the latency, how many seconds it took for the model to reply on average. The more exciting thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1254" target="_blank">00:20:54.640</a></span> | <span class="t">though is to play about with the system prompt. This is where you can test your theory about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1261" target="_blank">00:21:01.040</a></span> | <span class="t">telling the model it's a trick question and seeing if that boosts performance. Of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1265" target="_blank">00:21:05.120</a></span> | <span class="t">to get top performance, you're also going to want to change the model name from GPC 4.0 to say O1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1270" target="_blank">00:21:10.400</a></span> | <span class="t">At this stage, I must give a couple of quick caveats about this mini competition. The first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1275" target="_blank">00:21:15.040</a></span> | <span class="t">is an example of what not to do. Unfortunately, you can't tell O1 models to think step by step</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1281" target="_blank">00:21:21.280</a></span> | <span class="t">to come up with an answer. OpenAI have disallowed this, presumably so you don't get access to the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1286" target="_blank">00:21:26.240</a></span> | <span class="t">underlying chains of thought. So, let's not try that in our system prompt. Now, in the instruction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1291" target="_blank">00:21:31.760</a></span> | <span class="t">hierarchy, it's more like a user prompt but it can make a big difference to the performance of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1297" target="_blank">00:21:37.040</a></span> | <span class="t">the model. Which leads me to the second rule. I've been able to get to around 12 or 13 on these 20</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1303" target="_blank">00:21:43.040</a></span> | <span class="t">questions by coming up with ever more advanced prompts. What I want to see is whether any of you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1308" target="_blank">00:21:48.720</a></span> | <span class="t">can get to 20 out of 20 or even 18 out of 20. Naturally though, one way of doing that would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1314" target="_blank">00:21:54.560</a></span> | <span class="t">just be to put the answers in the system prompt or make numerous references to the questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1319" target="_blank">00:21:59.840</a></span> | <span class="t">themselves accessible via the Weave portal. What you'll get is a portal that looks something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1325" target="_blank">00:22:05.440</a></span> | <span class="t">like this. You can have fun with seeing the scores and the percentages here, but you can also click</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1331" target="_blank">00:22:11.040</a></span> | <span class="t">on the individual run. Scrolling down, you can click to view the individual questions. Of course,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1336" target="_blank">00:22:16.880</a></span> | <span class="t">this is not the entire benchmark which is over 200 questions, just 20, 10 of which you already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1342" target="_blank">00:22:22.480</a></span> | <span class="t">knew about. Of course, we are not going to accept prompts where you basically say something like,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1347" target="_blank">00:22:27.280</a></span> | <span class="t">"For question 18, the answer is C." Or very specific hints where you tell the model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1352" target="_blank">00:22:32.240</a></span> | <span class="t">"Think about her legs and how it could do this or that." No, what we're looking for are general</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1356" target="_blank">00:22:36.960</a></span> | <span class="t">prompts where you can tell the model these are trick questions and they test spatial reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1361" target="_blank">00:22:41.840</a></span> | <span class="t">And you're going to give the model a massive tip if it gets it right. If a general prompt like that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1366" target="_blank">00:22:46.800</a></span> | <span class="t">can get 18 or 20 out of 20, I would be very impressed. So that's the competition sponsored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1372" target="_blank">00:22:52.640</a></span> | <span class="t">by Weights & Biases running till the end of January. Hopefully you have some fun with it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1377" target="_blank">00:22:57.680</a></span> | <span class="t">but either way, it illustrates some of the common sense gaps in current frontier LLMs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1383" target="_blank">00:23:03.600</a></span> | <span class="t">Good luck and now time to end with a bit of fun. I discussed how Text-to-Video is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1388" target="_blank">00:23:08.240</a></span> | <span class="t">also accelerating through 2025 on my Patreon AI Insiders, but I thought I would give you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1394" target="_blank">00:23:14.400</a></span> | <span class="t">a taster with a quick side-by-side comparison between the best three tools currently available.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1400" target="_blank">00:23:20.320</a></span> | <span class="t">All with the same prompt, first Kling 1.6, then VO2 from Google DeepMind and finally Sora 1080p.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1409" target="_blank">00:23:29.200</a></span> | <span class="t">If you like, you can let me know in the comments which one you thought was best.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1412" target="_blank">00:23:32.960</a></span> | <span class="t">As ever, thank you so much for watching to the end and have a wonderful day and 2025.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=j3eQoooC7wc&t=1418" target="_blank">00:23:38.960</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>