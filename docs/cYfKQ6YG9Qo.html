<html><head><title>Stanford CS25: V4 I From Large Language Models to Large Multimodal Models</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Stanford CS25: V4 I From Large Language Models to Large Multimodal Models</h2><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo"><img src="https://i.ytimg.com/vi/cYfKQ6YG9Qo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./cYfKQ6YG9Qo.html">Whisper Transcript</a> | <a href="./transcript_cYfKQ6YG9Qo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">- Hello, thank you all for joining CS25 Transformers today.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=5" target="_blank">00:00:05.000</a></span> | <span class="t">For today's talk, we have Ming Ding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=12" target="_blank">00:00:12.560</a></span> | <span class="t">a research scientist at Shippu AI based in Beijing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=16" target="_blank">00:00:16.640</a></span> | <span class="t">He obtained his bachelor's and doctoral degrees</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=19" target="_blank">00:00:19.520</a></span> | <span class="t">at Tsinghua University, and he does research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=22" target="_blank">00:00:22.320</a></span> | <span class="t">on multimodal generative models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=24" target="_blank">00:00:24.580</a></span> | <span class="t">and pre-training technologies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=27" target="_blank">00:00:27.000</a></span> | <span class="t">He has led or participated in the research works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=30" target="_blank">00:00:30.640</a></span> | <span class="t">about multimodal generative models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=32" target="_blank">00:00:32.680</a></span> | <span class="t">such as CogView and CogVideo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=35" target="_blank">00:00:35.360</a></span> | <span class="t">and multimodal understanding models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=37" target="_blank">00:00:37.280</a></span> | <span class="t">such as CogVLM and CogAgent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=41" target="_blank">00:00:41.040</a></span> | <span class="t">For today's attendance, the attendance form</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=43" target="_blank">00:00:43.280</a></span> | <span class="t">is up on the course website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=46" target="_blank">00:00:46.240</a></span> | <span class="t">And if you have any questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=48" target="_blank">00:00:48.080</a></span> | <span class="t">ask them through Slido, S-L-I-D-O,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=51" target="_blank">00:00:51.600</a></span> | <span class="t">and for the code, you just have to input CS25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=56" target="_blank">00:00:56.840</a></span> | <span class="t">Thank you, Ming, for today's talk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=59" target="_blank">00:00:59.320</a></span> | <span class="t">and I'm gonna pass it off to you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=61" target="_blank">00:01:01.440</a></span> | <span class="t">- Thank you for the instructors of CS25.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=66" target="_blank">00:01:06.560</a></span> | <span class="t">I was very happy to give a talk in Stanford University</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=70" target="_blank">00:01:10.960</a></span> | <span class="t">about multimodality and pre-training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=74" target="_blank">00:01:14.600</a></span> | <span class="t">And actually, I have checked all the previous talks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=82" target="_blank">00:01:22.320</a></span> | <span class="t">in CS25, and they are really diverse topics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=87" target="_blank">00:01:27.320</a></span> | <span class="t">Someone shared intuitions in their research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=93" target="_blank">00:01:33.000</a></span> | <span class="t">about pre-training, someone shared recent works</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=96" target="_blank">00:01:36.600</a></span> | <span class="t">about maybe MOE and some other technicals.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=100" target="_blank">00:01:40.600</a></span> | <span class="t">Actually, I'm working in a large language model company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=107" target="_blank">00:01:47.840</a></span> | <span class="t">in China, and our company working on pre-training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=112" target="_blank">00:01:52.560</a></span> | <span class="t">and maybe there's lots of different area</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=117" target="_blank">00:01:57.120</a></span> | <span class="t">from a large language model, and multimodality model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=122" target="_blank">00:02:02.120</a></span> | <span class="t">and generative model, diffusion,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=124" target="_blank">00:02:04.200</a></span> | <span class="t">and text-to-speech, something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=128" target="_blank">00:02:08.240</a></span> | <span class="t">So I lead all the multimodality model research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=131" target="_blank">00:02:11.800</a></span> | <span class="t">in Drupal AI, so I will share lots of different topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=136" target="_blank">00:02:16.640</a></span> | <span class="t">in this talk.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=138" target="_blank">00:02:18.400</a></span> | <span class="t">Some of them may be not very familiar to you,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=143" target="_blank">00:02:23.000</a></span> | <span class="t">so yeah, it's okay, but you can get more information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=148" target="_blank">00:02:28.000</a></span> | <span class="t">on different area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=150" target="_blank">00:02:30.600</a></span> | <span class="t">Yeah, I will talk about several aspects of transformers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=156" target="_blank">00:02:36.560</a></span> | <span class="t">and I will generally follow the history</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=162" target="_blank">00:02:42.880</a></span> | <span class="t">of a large language model, and say, "Why are we here?"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=167" target="_blank">00:02:47.880</a></span> | <span class="t">It's about large language model introduction and history,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=174" target="_blank">00:02:54.200</a></span> | <span class="t">and how did we get here?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=178" target="_blank">00:02:58.440</a></span> | <span class="t">It's about some practical techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=181" target="_blank">00:03:01.880</a></span> | <span class="t">for training large language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=184" target="_blank">00:03:04.760</a></span> | <span class="t">and what are we working on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=186" target="_blank">00:03:06.800</a></span> | <span class="t">It's about the last one year, the real language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=192" target="_blank">00:03:12.440</a></span> | <span class="t">and other techniques in the papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=196" target="_blank">00:03:16.480</a></span> | <span class="t">of all the real language model community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=200" target="_blank">00:03:20.240</a></span> | <span class="t">And finally, I will talk about some possible</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=205" target="_blank">00:03:25.160</a></span> | <span class="t">and valuable direction for research in multimodality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=209" target="_blank">00:03:29.160</a></span> | <span class="t">Okay, okay, well, I will share three moments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=215" target="_blank">00:03:35.200</a></span> | <span class="t">I think the most important three moments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=222" target="_blank">00:03:42.040</a></span> | <span class="t">in the development of language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=225" target="_blank">00:03:45.320</a></span> | <span class="t">The first moment is called BERT moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=230" target="_blank">00:03:50.640</a></span> | <span class="t">Actually, I got into the area at this moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=235" target="_blank">00:03:55.640</a></span> | <span class="t">It's very honored that I'm the first,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=240" target="_blank">00:04:00.280</a></span> | <span class="t">among the first group of people who published papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=244" target="_blank">00:04:04.480</a></span> | <span class="t">on the next year, the ACL, when BERT came out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=248" target="_blank">00:04:08.720</a></span> | <span class="t">And at that time, since we don't really know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=253" target="_blank">00:04:13.720</a></span> | <span class="t">what is the language modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=257" target="_blank">00:04:17.200</a></span> | <span class="t">So at that time, nearly all the people was talking</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=262" target="_blank">00:04:22.200</a></span> | <span class="t">about how can we get a better self-supervised method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=267" target="_blank">00:04:27.240</a></span> | <span class="t">for an option.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=269" target="_blank">00:04:29.160</a></span> | <span class="t">At that time, a common opinion is mask language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=274" target="_blank">00:04:34.880</a></span> | <span class="t">is just for, it's good at understanding the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=279" target="_blank">00:04:39.880</a></span> | <span class="t">And GPT, the autoregressive model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=283" target="_blank">00:04:43.720</a></span> | <span class="t">is better for text generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=286" target="_blank">00:04:46.840</a></span> | <span class="t">And T5 maybe can do the both, but is redundant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=291" target="_blank">00:04:51.840</a></span> | <span class="t">And that's true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=296" target="_blank">00:04:56.480</a></span> | <span class="t">But nowadays, we all say that GPT has not been so good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=301" target="_blank">00:05:01.480</a></span> | <span class="t">GPT has now nearly several bullet of the NLP problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=306" target="_blank">00:05:06.480</a></span> | <span class="t">Sometimes the scenes changes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=320" target="_blank">00:05:20.320</a></span> | <span class="t">and we will back from that time point</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=325" target="_blank">00:05:25.320</a></span> | <span class="t">and know how the language model changed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=330" target="_blank">00:05:30.200</a></span> | <span class="t">and how we got more and more knowledge about language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=334" target="_blank">00:05:34.920</a></span> | <span class="t">So at that time, I'm also among one of them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=339" target="_blank">00:05:39.920</a></span> | <span class="t">who want to develop a new self-supervised learning method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=348" target="_blank">00:05:48.280</a></span> | <span class="t">for NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=349" target="_blank">00:05:49.360</a></span> | <span class="t">We published a paper called GLM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=353" target="_blank">00:05:53.960</a></span> | <span class="t">and we want to unify the BERT, the mask language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=360" target="_blank">00:06:00.000</a></span> | <span class="t">and the autoregressive model, and T5, yeah,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=365" target="_blank">00:06:05.000</a></span> | <span class="t">in a decoder-only style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=369" target="_blank">00:06:09.560</a></span> | <span class="t">The, actually, the method is very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=373" target="_blank">00:06:13.640</a></span> | <span class="t">We just select a part of the sequence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=378" target="_blank">00:06:18.640</a></span> | <span class="t">and only do autoregressive modeling during this sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=387" target="_blank">00:06:27.560</a></span> | <span class="t">So if we select the mask area as all the sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=392" target="_blank">00:06:32.560</a></span> | <span class="t">it become a GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=394" target="_blank">00:06:34.960</a></span> | <span class="t">And part of them, it become BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=397" target="_blank">00:06:37.800</a></span> | <span class="t">So that's a method we found very efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=402" target="_blank">00:06:42.800</a></span> | <span class="t">And because we train it like a BERT,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=406" target="_blank">00:06:46.360</a></span> | <span class="t">it's about 15% of the masked area,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=409" target="_blank">00:06:49.960</a></span> | <span class="t">and they perform better than BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=411" target="_blank">00:06:51.800</a></span> | <span class="t">We train it as a GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=413" target="_blank">00:06:53.440</a></span> | <span class="t">They perform at the same as GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=416" target="_blank">00:06:56.600</a></span> | <span class="t">It's quite a, very broad thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=421" target="_blank">00:07:01.400</a></span> | <span class="t">But there's, the second moment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=426" target="_blank">00:07:06.400</a></span> | <span class="t">I think is very important, is the GPT-3 moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=433" target="_blank">00:07:13.360</a></span> | <span class="t">It tell us the scaling law is very important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=438" target="_blank">00:07:18.200</a></span> | <span class="t">So you can design different architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=444" target="_blank">00:07:24.200</a></span> | <span class="t">define different laws, different self-supervised tasks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=449" target="_blank">00:07:29.200</a></span> | <span class="t">and a different method to schedule different models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=455" target="_blank">00:07:35.280</a></span> | <span class="t">But the performance maybe has some upper bound.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=461" target="_blank">00:07:41.240</a></span> | <span class="t">But if you add more compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=467" target="_blank">00:07:47.160</a></span> | <span class="t">you can get, guaranteeing the performance improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=473" target="_blank">00:07:53.160</a></span> | <span class="t">You can predict the results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=478" target="_blank">00:07:58.120</a></span> | <span class="t">perplexity based on the fitted curve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=483" target="_blank">00:08:03.120</a></span> | <span class="t">So at that time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=488" target="_blank">00:08:08.920</a></span> | <span class="t">the language modeling has become more and more engineering.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=493" target="_blank">00:08:13.360</a></span> | <span class="t">If you have find a very good point,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=498" target="_blank">00:08:18.560</a></span> | <span class="t">you train a language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=500" target="_blank">00:08:20.560</a></span> | <span class="t">If you want to scale it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=502" target="_blank">00:08:22.080</a></span> | <span class="t">and your boss give you four times of monies,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=508" target="_blank">00:08:28.720</a></span> | <span class="t">you can buy four times of compute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=512" target="_blank">00:08:32.760</a></span> | <span class="t">You just assign the compute for more parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=517" target="_blank">00:08:37.760</a></span> | <span class="t">or training more tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=522" target="_blank">00:08:42.520</a></span> | <span class="t">This is called scaling law,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=526" target="_blank">00:08:46.760</a></span> | <span class="t">and they tell you how you can assign</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=531" target="_blank">00:08:51.520</a></span> | <span class="t">a different potential of your monies.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=535" target="_blank">00:08:55.800</a></span> | <span class="t">So at that time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=539" target="_blank">00:08:59.880</a></span> | <span class="t">you don't really, the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=544" target="_blank">00:09:04.000</a></span> | <span class="t">don't really need some maybe architecture innovation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=549" target="_blank">00:09:09.000</a></span> | <span class="t">or algorithm innovation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=554" target="_blank">00:09:14.240</a></span> | <span class="t">So it's become an engineering thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=558" target="_blank">00:09:18.840</a></span> | <span class="t">And the third moment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=564" target="_blank">00:09:24.680</a></span> | <span class="t">I think, which is more important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=568" target="_blank">00:09:28.160</a></span> | <span class="t">is called try-GPT moment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=571" target="_blank">00:09:31.200</a></span> | <span class="t">At that moment, it tells us a very important fact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=576" target="_blank">00:09:36.120</a></span> | <span class="t">is task adaptation is cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=579" target="_blank">00:09:39.640</a></span> | <span class="t">And what is very important is knowledge from point training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=584" target="_blank">00:09:44.640</a></span> | <span class="t">This is a very bitter lesson.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=590" target="_blank">00:09:50.120</a></span> | <span class="t">So I have told you that at that time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=595" target="_blank">00:09:55.040</a></span> | <span class="t">we designed different losses, different architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=600" target="_blank">00:10:00.040</a></span> | <span class="t">but some of the aim of design different losses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=606" target="_blank">00:10:06.880</a></span> | <span class="t">is to perform different tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=609" target="_blank">00:10:09.280</a></span> | <span class="t">For example, the autoregressive model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=612" target="_blank">00:10:12.600</a></span> | <span class="t">cannot fill in the blank in the sequence,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=616" target="_blank">00:10:16.400</a></span> | <span class="t">but GLM and the board can.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=618" target="_blank">00:10:18.920</a></span> | <span class="t">So we use different point training task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=623" target="_blank">00:10:23.400</a></span> | <span class="t">But currently, we know that the task adaptation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=628" target="_blank">00:10:28.400</a></span> | <span class="t">is very cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=629" target="_blank">00:10:29.440</a></span> | <span class="t">You just need to fine-tune your language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=632" target="_blank">00:10:32.560</a></span> | <span class="t">at the final period.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=635" target="_blank">00:10:35.880</a></span> | <span class="t">The only important thing is your point training loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=640" target="_blank">00:10:40.880</a></span> | <span class="t">The last figure is from instruct-GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=649" target="_blank">00:10:49.240</a></span> | <span class="t">It's actually the paper about try-GPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=654" target="_blank">00:10:54.960</a></span> | <span class="t">and how can we align a point training model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=658" target="_blank">00:10:58.680</a></span> | <span class="t">to a try-GPT model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=660" target="_blank">00:11:00.360</a></span> | <span class="t">It tells that the alignment can give a very cheap loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=665" target="_blank">00:11:05.400</a></span> | <span class="t">and a very huge improvement on human preference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=670" target="_blank">00:11:10.240</a></span> | <span class="t">compared to the original point trained language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=674" target="_blank">00:11:14.960</a></span> | <span class="t">And the right figure is actually a recent paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=679" target="_blank">00:11:19.960</a></span> | <span class="t">in our company.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=681" target="_blank">00:11:21.160</a></span> | <span class="t">It tells us a very important fact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=687" target="_blank">00:11:27.280</a></span> | <span class="t">Maybe it's intuitive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=690" target="_blank">00:11:30.520</a></span> | <span class="t">The fact is the performance of downstream task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=695" target="_blank">00:11:35.520</a></span> | <span class="t">is only related to the loss of point training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=701" target="_blank">00:11:41.960</a></span> | <span class="t">And it's not directly relevant to the model size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=710" target="_blank">00:11:50.920</a></span> | <span class="t">which means if a large model reach a very high loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=720" target="_blank">00:12:00.280</a></span> | <span class="t">because of lack of training,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=722" target="_blank">00:12:02.800</a></span> | <span class="t">and a small model, we train it more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=726" target="_blank">00:12:06.160</a></span> | <span class="t">and reach the same level of loss,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=730" target="_blank">00:12:10.040</a></span> | <span class="t">they performed exactly the same in the downstream tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=735" target="_blank">00:12:15.040</a></span> | <span class="t">So the so-called emergent ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=741" target="_blank">00:12:21.920</a></span> | <span class="t">and some other maybe strange rumors</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=748" target="_blank">00:12:28.200</a></span> | <span class="t">are not true.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=751" target="_blank">00:12:31.480</a></span> | <span class="t">Actually, the ability is not from the number or parameters</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=756" target="_blank">00:12:36.480</a></span> | <span class="t">of language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=759" target="_blank">00:12:39.360</a></span> | <span class="t">It's actually only relevant to the loss</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=764" target="_blank">00:12:44.360</a></span> | <span class="t">of your language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=767" target="_blank">00:12:47.040</a></span> | <span class="t">So all the language model become a game of curve fitting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=773" target="_blank">00:12:53.640</a></span> | <span class="t">It's actually the current situation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=778" target="_blank">00:12:58.640</a></span> | <span class="t">of language model research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=783" target="_blank">00:13:03.680</a></span> | <span class="t">So there's also some technical details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=789" target="_blank">00:13:09.440</a></span> | <span class="t">of a large language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=791" target="_blank">00:13:11.160</a></span> | <span class="t">Even we know it's not curve fitting,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=796" target="_blank">00:13:16.160</a></span> | <span class="t">but there's a lot of important things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=801" target="_blank">00:13:21.080</a></span> | <span class="t">So we will back from some basics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=804" target="_blank">00:13:24.240</a></span> | <span class="t">and talk about the transformer, the transformer architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=809" target="_blank">00:13:29.240</a></span> | <span class="t">A very interesting thing is the most important improvements</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=816" target="_blank">00:13:36.640</a></span> | <span class="t">nowadays are still from first also the transformer paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=821" target="_blank">00:13:41.640</a></span> | <span class="t">the norm, and maybe from his other papers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=827" target="_blank">00:13:47.400</a></span> | <span class="t">So actually, the real innovation in the architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=832" target="_blank">00:13:52.400</a></span> | <span class="t">is very small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=835" target="_blank">00:13:55.600</a></span> | <span class="t">I can summarize some common adaptation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=841" target="_blank">00:14:01.480</a></span> | <span class="t">on transformer currently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=844" target="_blank">00:14:04.920</a></span> | <span class="t">First is decoder only.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=846" target="_blank">00:14:06.480</a></span> | <span class="t">The original transformer is a encoder-decoder architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=850" target="_blank">00:14:10.840</a></span> | <span class="t">So it's redundant because the importance,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=857" target="_blank">00:14:17.120</a></span> | <span class="t">the encoder and the decoder should learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=862" target="_blank">00:14:22.120</a></span> | <span class="t">how to understand the text from different parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=867" target="_blank">00:14:27.160</a></span> | <span class="t">So it's redundant.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=869" target="_blank">00:14:29.800</a></span> | <span class="t">Currently, we only care about decoder-only architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=874" target="_blank">00:14:34.800</a></span> | <span class="t">The second one is pre-layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=878" target="_blank">00:14:38.600</a></span> | <span class="t">In the original transformer layer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=880" target="_blank">00:14:40.600</a></span> | <span class="t">the layer norm is after the residual connection.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=885" target="_blank">00:14:45.920</a></span> | <span class="t">It's called post-layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=888" target="_blank">00:14:48.480</a></span> | <span class="t">And currently, we usually use pre-layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=892" target="_blank">00:14:52.240</a></span> | <span class="t">The rotary position embedding is something very special</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=898" target="_blank">00:14:58.200</a></span> | <span class="t">because it's not published from a paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=900" target="_blank">00:15:00.240</a></span> | <span class="t">It's not published from a Chinese blog.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=904" target="_blank">00:15:04.240</a></span> | <span class="t">But currently, it's proven very efficient.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=913" target="_blank">00:15:13.880</a></span> | <span class="t">And the group query attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=917" target="_blank">00:15:17.240</a></span> | <span class="t">is actually from another paper, Norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=920" target="_blank">00:15:20.680</a></span> | <span class="t">It can seal the inference memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=924" target="_blank">00:15:24.280</a></span> | <span class="t">And TLU variant is also from Norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=928" target="_blank">00:15:28.640</a></span> | <span class="t">It's just a replacement of the MLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=933" target="_blank">00:15:33.640</a></span> | <span class="t">And mutual export is actually also from Norm's paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=941" target="_blank">00:15:41.120</a></span> | <span class="t">And you can use a thin flow of small parameter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=945" target="_blank">00:15:45.160</a></span> | <span class="t">to get better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=948" target="_blank">00:15:48.120</a></span> | <span class="t">So this is what's the current,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=953" target="_blank">00:15:53.120</a></span> | <span class="t">the most advanced open-source language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=957" target="_blank">00:15:57.520</a></span> | <span class="t">the architectural most advanced open-source language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=960" target="_blank">00:16:00.800</a></span> | <span class="t">for example, LAMA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=961" target="_blank">00:16:01.880</a></span> | <span class="t">Okay, we know there's architecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=967" target="_blank">00:16:07.000</a></span> | <span class="t">but how to train this transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=970" target="_blank">00:16:10.360</a></span> | <span class="t">is also very important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=971" target="_blank">00:16:11.880</a></span> | <span class="t">Just, we need to prepare a very powerful code base</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=978" target="_blank">00:16:18.400</a></span> | <span class="t">to train the large-language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=983" target="_blank">00:16:23.600</a></span> | <span class="t">So the first choice is DeepSpeed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=986" target="_blank">00:16:26.640</a></span> | <span class="t">It's a library from Microsoft.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=990" target="_blank">00:16:30.200</a></span> | <span class="t">And some of the most important optimization method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=995" target="_blank">00:16:35.880</a></span> | <span class="t">is from the paper called Xero from DeepSpeed group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1000" target="_blank">00:16:40.880</a></span> | <span class="t">Several years ago, some of us not really know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1010" target="_blank">00:16:50.360</a></span> | <span class="t">how to train a very large model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1013" target="_blank">00:16:53.920</a></span> | <span class="t">how to efficiently train them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1016" target="_blank">00:16:56.000</a></span> | <span class="t">But Xero gave us some advices.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1019" target="_blank">00:16:59.960</a></span> | <span class="t">For example, if we can find the most,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1025" target="_blank">00:17:05.800</a></span> | <span class="t">memory conception is actually the item states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1030" target="_blank">00:17:10.800</a></span> | <span class="t">The optimizer states, you must keep it for precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1037" target="_blank">00:17:17.400</a></span> | <span class="t">It's a float.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1040" target="_blank">00:17:20.760</a></span> | <span class="t">And the matrix is also a float.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1044" target="_blank">00:17:24.000</a></span> | <span class="t">The parameter and gradient, you can keep it half precision.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1048" target="_blank">00:17:28.480</a></span> | <span class="t">And you can have a fast computation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1054" target="_blank">00:17:34.480</a></span> | <span class="t">and save memories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1056" target="_blank">00:17:36.880</a></span> | <span class="t">The Xero one can scatter the mass weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1063" target="_blank">00:17:43.960</a></span> | <span class="t">and optimizer state into all the data parallel ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1068" target="_blank">00:17:48.800</a></span> | <span class="t">So if you have more ranks, more GPU cards,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1073" target="_blank">00:17:53.800</a></span> | <span class="t">you just use less GPU memory</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1081" target="_blank">00:18:01.240</a></span> | <span class="t">for each rank.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1084" target="_blank">00:18:04.320</a></span> | <span class="t">Another important technique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1087" target="_blank">00:18:07.640</a></span> | <span class="t">is called activation checkpointing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1090" target="_blank">00:18:10.040</a></span> | <span class="t">is actually recall the intermediate state</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1095" target="_blank">00:18:15.040</a></span> | <span class="t">and recompute when backward.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1098" target="_blank">00:18:18.360</a></span> | <span class="t">So we don't really need to record</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1102" target="_blank">00:18:22.000</a></span> | <span class="t">all the computation flow graph.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1104" target="_blank">00:18:24.760</a></span> | <span class="t">We just need to recall some of the hidden states.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1110" target="_blank">00:18:30.760</a></span> | <span class="t">It's to reduce all the activation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1114" target="_blank">00:18:34.520</a></span> | <span class="t">many layers into one layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1118" target="_blank">00:18:38.040</a></span> | <span class="t">And there's other methods to reduce memory conception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1123" target="_blank">00:18:43.040</a></span> | <span class="t">For example, the Xero 2 CPU offload,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1127" target="_blank">00:18:47.840</a></span> | <span class="t">which means you can offload some GPU memory to CPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1132" target="_blank">00:18:52.440</a></span> | <span class="t">And the Xero 3, I also call it fully sharded data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1137" target="_blank">00:18:57.440</a></span> | <span class="t">fully sharded data parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1139" target="_blank">00:18:59.920</a></span> | <span class="t">You can just shard your model into different cards.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1144" target="_blank">00:19:04.920</a></span> | <span class="t">And when you use the parameter,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1147" target="_blank">00:19:07.000</a></span> | <span class="t">you gather this parameter from the other ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1150" target="_blank">00:19:10.760</a></span> | <span class="t">So all this method is very complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1155" target="_blank">00:19:15.760</a></span> | <span class="t">but the DeepSpeed library</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1159" target="_blank">00:19:19.440</a></span> | <span class="t">have already give a very clean API to use it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1164" target="_blank">00:19:24.440</a></span> | <span class="t">It's currently, it's not very hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1168" target="_blank">00:19:28.160</a></span> | <span class="t">to train a very large-language model efficiently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1170" target="_blank">00:19:30.600</a></span> | <span class="t">And Megatron is another framework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1176" target="_blank">00:19:36.800</a></span> | <span class="t">to train large-language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1178" target="_blank">00:19:38.920</a></span> | <span class="t">It's also the most available framework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1182" target="_blank">00:19:42.680</a></span> | <span class="t">to train a super large-language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1185" target="_blank">00:19:45.080</a></span> | <span class="t">more than 100 billion parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1188" target="_blank">00:19:48.320</a></span> | <span class="t">It's using another set of optimization method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1193" target="_blank">00:19:53.200</a></span> | <span class="t">The first is called tensor parallel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1196" target="_blank">00:19:56.320</a></span> | <span class="t">The tensor parallel splits the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1200" target="_blank">00:20:00.080</a></span> | <span class="t">and has into different ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1203" target="_blank">00:20:03.680</a></span> | <span class="t">And it calls additional or reduce for attention and MLP,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1208" target="_blank">00:20:08.680</a></span> | <span class="t">but reduce all the parameters conception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1216" target="_blank">00:20:16.320</a></span> | <span class="t">and computing conception into different TP ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1225" target="_blank">00:20:25.440</a></span> | <span class="t">The pipeline parallel is to split the layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1229" target="_blank">00:20:29.840</a></span> | <span class="t">into different ranks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1231" target="_blank">00:20:31.600</a></span> | <span class="t">And it's also introduced bubbles in pipeline</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1236" target="_blank">00:20:36.600</a></span> | <span class="t">and there's some method for them pointerly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1241" target="_blank">00:20:41.240</a></span> | <span class="t">without their bubble to remove this conception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1246" target="_blank">00:20:46.240</a></span> | <span class="t">Yeah, maybe if you want to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1251" target="_blank">00:20:51.280</a></span> | <span class="t">a very large-language model one day,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1254" target="_blank">00:20:54.000</a></span> | <span class="t">you need to learn about all this kind of system scenes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1259" target="_blank">00:20:59.000</a></span> | <span class="t">because the current large-language model training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1263" target="_blank">00:21:03.160</a></span> | <span class="t">is actually an engineering work.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1265" target="_blank">00:21:05.520</a></span> | <span class="t">Yeah, MLP is not very important.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1270" target="_blank">00:21:10.440</a></span> | <span class="t">The important is MLCs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1272" target="_blank">00:21:12.840</a></span> | <span class="t">Okay, so another very important thing is long contexts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1282" target="_blank">00:21:22.920</a></span> | <span class="t">It's actually lossless long contexts,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1285" target="_blank">00:21:25.280</a></span> | <span class="t">which means we don't use sparse attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1287" target="_blank">00:21:27.640</a></span> | <span class="t">or other method to change the full attention behavior.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1292" target="_blank">00:21:32.640</a></span> | <span class="t">The current infrastructure to train long contexts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1300" target="_blank">00:21:40.240</a></span> | <span class="t">is beyond the imagination for AI guys five years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1305" target="_blank">00:21:45.240</a></span> | <span class="t">The last figure is actually my paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1310" target="_blank">00:21:50.680</a></span> | <span class="t">when I published several years ago in Euripse.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1315" target="_blank">00:21:55.680</a></span> | <span class="t">At that time, there's no such thing like GPT-3</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1322" target="_blank">00:22:02.560</a></span> | <span class="t">is on a board.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1323" target="_blank">00:22:03.440</a></span> | <span class="t">So this paper is actually very complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1328" target="_blank">00:22:08.440</a></span> | <span class="t">to schedule two different boards</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1334" target="_blank">00:22:14.720</a></span> | <span class="t">to mimic the retrieval, rehearsal, and forget process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1340" target="_blank">00:22:20.280</a></span> | <span class="t">in working memory or human to let the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1345" target="_blank">00:22:25.280</a></span> | <span class="t">to understand a very long context step by step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1350" target="_blank">00:22:30.840</a></span> | <span class="t">But actually, we can see that we can use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1355" target="_blank">00:22:35.840</a></span> | <span class="t">different system level technicals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1359" target="_blank">00:22:39.960</a></span> | <span class="t">to understand a very, very long context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1364" target="_blank">00:22:44.760</a></span> | <span class="t">For example, more than 100,000 words.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1369" target="_blank">00:22:49.760</a></span> | <span class="t">100,000 lines is for attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1373" target="_blank">00:22:53.560</a></span> | <span class="t">So it's just different from several years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1378" target="_blank">00:22:58.000</a></span> | <span class="t">And the many things is super simplified</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1382" target="_blank">00:23:02.840</a></span> | <span class="t">because of this improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1385" target="_blank">00:23:05.520</a></span> | <span class="t">A key technique is called context parallel,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1391" target="_blank">00:23:11.520</a></span> | <span class="t">which means we split the sequence into different ranks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1395" target="_blank">00:23:15.600</a></span> | <span class="t">and use re-attention or Ulysses</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1400" target="_blank">00:23:20.600</a></span> | <span class="t">and other technicals to finish the attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1406" target="_blank">00:23:26.600</a></span> | <span class="t">There's a library called Transformer-NG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1413" target="_blank">00:23:33.120</a></span> | <span class="t">and all this function is worked in this library.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1418" target="_blank">00:23:38.120</a></span> | <span class="t">And we need to handle the load balance of the attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1423" target="_blank">00:23:43.600</a></span> | <span class="t">to make every rank have the same computation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1426" target="_blank">00:23:46.480</a></span> | <span class="t">So this is actually changed lots of different research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1432" target="_blank">00:23:52.480</a></span> | <span class="t">and applications of NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1437" target="_blank">00:23:57.640</a></span> | <span class="t">For example, we summary and extract some facts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1442" target="_blank">00:24:02.640</a></span> | <span class="t">from the documents several years ago</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1448" target="_blank">00:24:08.400</a></span> | <span class="t">using like BM25 and other methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1454" target="_blank">00:24:14.400</a></span> | <span class="t">And currently we can just use a transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1458" target="_blank">00:24:18.320</a></span> | <span class="t">and the full attention to get the information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1461" target="_blank">00:24:21.720</a></span> | <span class="t">and understand it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1463" target="_blank">00:24:23.200</a></span> | <span class="t">It's quite important improvement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1468" target="_blank">00:24:28.200</a></span> | <span class="t">So using this very powerful infra,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1473" target="_blank">00:24:33.920</a></span> | <span class="t">we can train very large language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1477" target="_blank">00:24:37.040</a></span> | <span class="t">And for the alignment,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1479" target="_blank">00:24:39.600</a></span> | <span class="t">the first period is called SFT and supervised fine tuning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1484" target="_blank">00:24:44.280</a></span> | <span class="t">It's actually a very ordinary fine tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1488" target="_blank">00:24:48.360</a></span> | <span class="t">for language model, a high quality data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1493" target="_blank">00:24:53.120</a></span> | <span class="t">And the high quality data is usually from human notation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1498" target="_blank">00:24:58.120</a></span> | <span class="t">This human notation is not just core sourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1503" target="_blank">00:25:03.480</a></span> | <span class="t">You need to hear experts from different domains</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1507" target="_blank">00:25:07.880</a></span> | <span class="t">who writes this high quality answers to train the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1512" target="_blank">00:25:12.880</a></span> | <span class="t">For example, if you want the model to write some code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1518" target="_blank">00:25:18.280</a></span> | <span class="t">and explain the code in a very formative way,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1527" target="_blank">00:25:27.400</a></span> | <span class="t">you need to hear a very experienced programmer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1534" target="_blank">00:25:34.640</a></span> | <span class="t">to write some example to teach this language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1539" target="_blank">00:25:39.640</a></span> | <span class="t">It's not just core sourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1542" target="_blank">00:25:42.920</a></span> | <span class="t">This is quite different from the various human notation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1547" target="_blank">00:25:47.120</a></span> | <span class="t">We can also extract the question answer pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1555" target="_blank">00:25:55.400</a></span> | <span class="t">from more powerful models like GBT4 Turbo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1559" target="_blank">00:25:59.360</a></span> | <span class="t">to train our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1561" target="_blank">00:26:01.440</a></span> | <span class="t">But this is actually not allowed by OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1566" target="_blank">00:26:06.440</a></span> | <span class="t">So you cannot use this method to develop a model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1572" target="_blank">00:26:12.800</a></span> | <span class="t">to competing with them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1575" target="_blank">00:26:15.960</a></span> | <span class="t">But you actually, if you for research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1580" target="_blank">00:26:20.960</a></span> | <span class="t">you don't worry about this using that small method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1585" target="_blank">00:26:25.840</a></span> | <span class="t">about narrow surpass GBT4</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1588" target="_blank">00:26:28.480</a></span> | <span class="t">because there's a paper called "Way too strong generalization"</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1592" target="_blank">00:26:32.520</a></span> | <span class="t">and recall what I said just now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1597" target="_blank">00:26:37.520</a></span> | <span class="t">what was really important is your point training loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1603" target="_blank">00:26:43.120</a></span> | <span class="t">If your point training loss is lower</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1606" target="_blank">00:26:46.160</a></span> | <span class="t">than your teacher model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1609" target="_blank">00:26:49.160</a></span> | <span class="t">you can also surpass your teacher model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1614" target="_blank">00:26:54.600</a></span> | <span class="t">Even you use the FFT data from your teacher model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1619" target="_blank">00:26:59.600</a></span> | <span class="t">And another period of alignment is called IRHF.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1626" target="_blank">00:27:06.800</a></span> | <span class="t">It used reinforcement learning from human feedback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1630" target="_blank">00:27:10.520</a></span> | <span class="t">to improve the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1634" target="_blank">00:27:14.080</a></span> | <span class="t">But actually the most open language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1638" target="_blank">00:27:18.160</a></span> | <span class="t">didn't use this method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1640" target="_blank">00:27:20.360</a></span> | <span class="t">The main reason is PPO is very hard to implement.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1645" target="_blank">00:27:25.360</a></span> | <span class="t">It could be very powerful</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1651" target="_blank">00:27:31.760</a></span> | <span class="t">if your reward model is good enough,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1653" target="_blank">00:27:33.600</a></span> | <span class="t">but not easy to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1655" target="_blank">00:27:35.440</a></span> | <span class="t">So there's some more easy method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1660" target="_blank">00:27:40.440</a></span> | <span class="t">And most open source language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1665" target="_blank">00:27:45.480</a></span> | <span class="t">they use the DPO method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1667" target="_blank">00:27:47.800</a></span> | <span class="t">It's from paper from Stanford.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1670" target="_blank">00:27:50.640</a></span> | <span class="t">And we only need some pre-reference pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1675" target="_blank">00:27:55.640</a></span> | <span class="t">and use this formula to update your model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1681" target="_blank">00:28:01.000</a></span> | <span class="t">You don't really need a reward model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1686" target="_blank">00:28:06.160</a></span> | <span class="t">You don't really need a reward model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1690" target="_blank">00:28:10.120</a></span> | <span class="t">You just need some pairs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1692" target="_blank">00:28:12.680</a></span> | <span class="t">Maybe there's some on policy pairs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1695" target="_blank">00:28:15.600</a></span> | <span class="t">but it's much simpler and also very powerful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1700" target="_blank">00:28:20.600</a></span> | <span class="t">So these are basics of how to train a language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1710" target="_blank">00:28:30.560</a></span> | <span class="t">currently.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1713" target="_blank">00:28:33.920</a></span> | <span class="t">And it seems like it's nothing about NLP.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1721" target="_blank">00:28:41.640</a></span> | <span class="t">It's actually a party of MLC's guys.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1726" target="_blank">00:28:46.200</a></span> | <span class="t">So what are the LLM pre-trainer doing?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1730" target="_blank">00:28:50.640</a></span> | <span class="t">It's actually the most important thing is data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1735" target="_blank">00:28:55.640</a></span> | <span class="t">Currently the data cleaning, filtering, synthesizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1742" target="_blank">00:29:02.840</a></span> | <span class="t">is the most important thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1746" target="_blank">00:29:06.400</a></span> | <span class="t">of all the large language model company,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1749" target="_blank">00:29:09.480</a></span> | <span class="t">which is a open secret.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1752" target="_blank">00:29:12.520</a></span> | <span class="t">So the training info is basically what I said</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1757" target="_blank">00:29:17.520</a></span> | <span class="t">in the last several slides.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1765" target="_blank">00:29:25.160</a></span> | <span class="t">Maybe there's some other more advanced method,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1769" target="_blank">00:29:29.200</a></span> | <span class="t">but the improvement is maybe 20% or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1774" target="_blank">00:29:34.760</a></span> | <span class="t">But if you have a better data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1779" target="_blank">00:29:39.160</a></span> | <span class="t">and the performance of your language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1782" target="_blank">00:29:42.880</a></span> | <span class="t">is quite obvious.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1787" target="_blank">00:29:47.000</a></span> | <span class="t">So it's something like the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1792" target="_blank">00:29:52.000</a></span> | <span class="t">and some are told by the media</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1800" target="_blank">00:30:00.320</a></span> | <span class="t">is most one thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1803" target="_blank">00:30:03.360</a></span> | <span class="t">And, but actually most of the ML engineering</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1808" target="_blank">00:30:08.360</a></span> | <span class="t">in large language model company</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1813" target="_blank">00:30:13.320</a></span> | <span class="t">is actually cleaning the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1815" target="_blank">00:30:15.720</a></span> | <span class="t">So is this something a Stanford graduate student should do?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1820" target="_blank">00:30:20.720</a></span> | <span class="t">Maybe someone saying, yes, it's very low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1825" target="_blank">00:30:25.440</a></span> | <span class="t">I want to design some new algorithm architectures.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1829" target="_blank">00:30:29.040</a></span> | <span class="t">This is a rare ML research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1831" target="_blank">00:30:31.040</a></span> | <span class="t">but I have an opinion that the data,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1836" target="_blank">00:30:36.040</a></span> | <span class="t">the algorithm and architecture can transform to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1841" target="_blank">00:30:41.480</a></span> | <span class="t">So the data is the most general form,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1848" target="_blank">00:30:48.400</a></span> | <span class="t">but sometimes if you don't have enough compute,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1852" target="_blank">00:30:52.600</a></span> | <span class="t">it could be very hard to understand.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1858" target="_blank">00:30:58.240</a></span> | <span class="t">Hard to fit this kind of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1861" target="_blank">00:31:01.960</a></span> | <span class="t">And the algorithm is very hard to implement</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1866" target="_blank">00:31:06.960</a></span> | <span class="t">and not very general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1869" target="_blank">00:31:09.840</a></span> | <span class="t">The architecture is hard to perform what you want.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1874" target="_blank">00:31:14.840</a></span> | <span class="t">You design a new kind of architecture is very hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1878" target="_blank">00:31:18.600</a></span> | <span class="t">I will take a multi health question answering task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1884" target="_blank">00:31:24.560</a></span> | <span class="t">as an example.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1886" target="_blank">00:31:26.520</a></span> | <span class="t">The right figure is from the co-QA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1890" target="_blank">00:31:30.680</a></span> | <span class="t">It's also one of my papers when I was a student.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1895" target="_blank">00:31:35.680</a></span> | <span class="t">It's actually about a task to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1901" target="_blank">00:31:41.400</a></span> | <span class="t">we have very complex question</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1906" target="_blank">00:31:46.200</a></span> | <span class="t">and we need to find the task,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1908" target="_blank">00:31:48.800</a></span> | <span class="t">the task, find the answer from several documents,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1912" target="_blank">00:31:52.960</a></span> | <span class="t">but you need to find a chain reasoning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1917" target="_blank">00:31:57.960</a></span> | <span class="t">between different documents to get the final answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1922" target="_blank">00:32:02.480</a></span> | <span class="t">So at that time I proposed a method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1925" target="_blank">00:32:05.800</a></span> | <span class="t">involved a broad graph neural network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1929" target="_blank">00:32:09.760</a></span> | <span class="t">It's very complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1931" target="_blank">00:32:11.200</a></span> | <span class="t">And finally, I got a very good performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1938" target="_blank">00:32:18.200</a></span> | <span class="t">and 10 points better than the prior method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1943" target="_blank">00:32:23.200</a></span> | <span class="t">But yeah, this is actually some algorithm</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1949" target="_blank">00:32:29.880</a></span> | <span class="t">or architecture innovation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1955" target="_blank">00:32:35.160</a></span> | <span class="t">It's very fancy and get a very high score in ACL review.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1960" target="_blank">00:32:40.160</a></span> | <span class="t">But there's some other concurrent work use MCTS,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1967" target="_blank">00:32:47.760</a></span> | <span class="t">the Monte Carlo tree search and brought something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1971" target="_blank">00:32:51.160</a></span> | <span class="t">It's looks like algorithm level innovation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1975" target="_blank">00:32:55.120</a></span> | <span class="t">to solve this problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1976" target="_blank">00:32:56.880</a></span> | <span class="t">But currently this problem can be easily solved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1980" target="_blank">00:33:00.000</a></span> | <span class="t">by a very long context GPT and chain of thought reasoning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1985" target="_blank">00:33:05.000</a></span> | <span class="t">If you include nearly all the documents</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1989" target="_blank">00:33:09.520</a></span> | <span class="t">into your context, you don't need anything</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1993" target="_blank">00:33:13.520</a></span> | <span class="t">like a graph neural network or MCTS</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=1996" target="_blank">00:33:16.400</a></span> | <span class="t">to jump between the documents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2000" target="_blank">00:33:20.680</a></span> | <span class="t">You have all the context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2003" target="_blank">00:33:23.920</a></span> | <span class="t">and you can just finish using chain of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2008" target="_blank">00:33:28.640</a></span> | <span class="t">It's a data level solution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2011" target="_blank">00:33:31.480</a></span> | <span class="t">So the data level solution is of course the most simple one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2016" target="_blank">00:33:36.480</a></span> | <span class="t">because you just add the data into your training purpose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2023" target="_blank">00:33:43.160</a></span> | <span class="t">and you can just finish this task</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2025" target="_blank">00:33:45.920</a></span> | <span class="t">while not affect other tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2029" target="_blank">00:33:49.200</a></span> | <span class="t">So the data cleaning, filtering and synthesizing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2033" target="_blank">00:33:53.360</a></span> | <span class="t">is not a very easy work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2035" target="_blank">00:33:55.440</a></span> | <span class="t">and it actually very important view to do this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2040" target="_blank">00:34:00.440</a></span> | <span class="t">We should transform our view of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2052" target="_blank">00:34:12.200</a></span> | <span class="t">and algorithm architecture to fit the current era.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2056" target="_blank">00:34:16.480</a></span> | <span class="t">So, yeah, I have introduced some knowledge</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2063" target="_blank">00:34:23.960</a></span> | <span class="t">about language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2069" target="_blank">00:34:29.200</a></span> | <span class="t">So I will jump into the second part,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2073" target="_blank">00:34:33.000</a></span> | <span class="t">which is real language models in the past one year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2079" target="_blank">00:34:39.440</a></span> | <span class="t">So the past one year we have seen the real language models</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2084" target="_blank">00:34:44.440</a></span> | <span class="t">jump from nearly a very silly one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2091" target="_blank">00:34:51.640</a></span> | <span class="t">to currently very powerful ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2096" target="_blank">00:34:56.600</a></span> | <span class="t">So I will start from BLEAP2,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2100" target="_blank">00:35:00.080</a></span> | <span class="t">which is actually maybe I think the first work</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2105" target="_blank">00:35:05.720</a></span> | <span class="t">to bridge the clip and train a large language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2110" target="_blank">00:35:10.720</a></span> | <span class="t">to give the larger model the ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2114" target="_blank">00:35:14.760</a></span> | <span class="t">to understand the images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2118" target="_blank">00:35:18.640</a></span> | <span class="t">Actually, if we have an image encoder from a clip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2123" target="_blank">00:35:23.640</a></span> | <span class="t">and a large language model from anywhere,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2128" target="_blank">00:35:28.840</a></span> | <span class="t">so you can just insert a transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2134" target="_blank">00:35:34.560</a></span> | <span class="t">called Q-former to extract some important features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2139" target="_blank">00:35:39.440</a></span> | <span class="t">from image encoder and insert these features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2143" target="_blank">00:35:43.680</a></span> | <span class="t">into large language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2145" target="_blank">00:35:45.240</a></span> | <span class="t">But the space of image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2151" target="_blank">00:35:51.120</a></span> | <span class="t">and text features is different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2153" target="_blank">00:35:53.760</a></span> | <span class="t">So the Q-former is trainable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2156" target="_blank">00:35:56.680</a></span> | <span class="t">You'll need lots of text image pairs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2162" target="_blank">00:36:02.400</a></span> | <span class="t">and align the space of image features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2166" target="_blank">00:36:06.840</a></span> | <span class="t">and the language and the text features, the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2171" target="_blank">00:36:11.840</a></span> | <span class="t">So yeah, the Q-former actually did this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2176" target="_blank">00:36:16.920</a></span> | <span class="t">But there's a more simple method called LAVA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2184" target="_blank">00:36:24.200</a></span> | <span class="t">It's actually, you don't need to train it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2191" target="_blank">00:36:31.960</a></span> | <span class="t">you use a simple projection weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2196" target="_blank">00:36:36.200</a></span> | <span class="t">to transform the feature from your encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2201" target="_blank">00:36:41.200</a></span> | <span class="t">into the features in the larger model input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2206" target="_blank">00:36:46.360</a></span> | <span class="t">So it quickly becomes the most popular architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2212" target="_blank">00:36:52.360</a></span> | <span class="t">of your language models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2217" target="_blank">00:36:57.680</a></span> | <span class="t">COGVLM is a work from our group.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2222" target="_blank">00:37:02.680</a></span> | <span class="t">The motivation of COGVLM is to keep all the language behavior</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2230" target="_blank">00:37:10.840</a></span> | <span class="t">while we add an image understanding ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2236" target="_blank">00:37:16.800</a></span> | <span class="t">to the language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2240" target="_blank">00:37:20.680</a></span> | <span class="t">For LAVA and for the project,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2247" target="_blank">00:37:27.160</a></span> | <span class="t">for the previous method,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2248" target="_blank">00:37:28.680</a></span> | <span class="t">maybe you actually can train the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2253" target="_blank">00:37:33.680</a></span> | <span class="t">and get a better performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2259" target="_blank">00:37:39.480</a></span> | <span class="t">But it's about multimodality task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2267" target="_blank">00:37:47.560</a></span> | <span class="t">The language model ability,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2270" target="_blank">00:37:50.040</a></span> | <span class="t">language availability of the model will be reduced</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2273" target="_blank">00:37:53.240</a></span> | <span class="t">if you train the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2275" target="_blank">00:37:55.920</a></span> | <span class="t">during the text-image alignment.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2279" target="_blank">00:37:59.200</a></span> | <span class="t">So we first use a region export</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2284" target="_blank">00:38:04.200</a></span> | <span class="t">to add new parameters in the backbone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2292" target="_blank">00:38:12.000</a></span> | <span class="t">and the region exports only deal with the image features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2297" target="_blank">00:38:17.000</a></span> | <span class="t">And the original with phase forward layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2303" target="_blank">00:38:23.360</a></span> | <span class="t">and the QKB matrix deal with the original text features.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2307" target="_blank">00:38:27.360</a></span> | <span class="t">So the original behavior of language model is kept</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2312" target="_blank">00:38:32.360</a></span> | <span class="t">and we add lots of new parameters to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2319" target="_blank">00:38:39.000</a></span> | <span class="t">and get a better performance of multimodality models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2325" target="_blank">00:38:45.400</a></span> | <span class="t">The COGVLM achieves state-of-the-art performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2331" target="_blank">00:38:51.600</a></span> | <span class="t">of several benchmarks, including image captioning,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2335" target="_blank">00:38:55.160</a></span> | <span class="t">grounding, and VQA,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2337" target="_blank">00:38:57.640</a></span> | <span class="t">and some other very large model benchmarks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2341" target="_blank">00:39:01.960</a></span> | <span class="t">And it's also open source,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2343" target="_blank">00:39:03.800</a></span> | <span class="t">so you can download it from our GitHub.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2347" target="_blank">00:39:07.240</a></span> | <span class="t">Last month, I found that COGVLM is downloaded</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2353" target="_blank">00:39:13.560</a></span> | <span class="t">more than 500,000 times in the world.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2361" target="_blank">00:39:21.120</a></span> | <span class="t">In the last month.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2362" target="_blank">00:39:22.760</a></span> | <span class="t">So I think it's already helped lots of people.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2367" target="_blank">00:39:27.080</a></span> | <span class="t">And COG-Agent, another works from our group,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2373" target="_blank">00:39:33.880</a></span> | <span class="t">is to use a different architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2377" target="_blank">00:39:37.960</a></span> | <span class="t">because we want a high resolution with cross-attention.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2382" target="_blank">00:39:42.400</a></span> | <span class="t">Why is cross-attention?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2383" target="_blank">00:39:43.720</a></span> | <span class="t">Because we don't want to,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2387" target="_blank">00:39:47.960</a></span> | <span class="t">we just want a high-resolution input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2390" target="_blank">00:39:50.920</a></span> | <span class="t">I don't want to let all the hidden size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2394" target="_blank">00:39:54.000</a></span> | <span class="t">is as thin as the language model hidden size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2398" target="_blank">00:39:58.360</a></span> | <span class="t">which is very large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2399" target="_blank">00:39:59.480</a></span> | <span class="t">So we use cross-attention to deal with the low-resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2404" target="_blank">00:40:04.480</a></span> | <span class="t">The high-resolution channels is slightly complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2410" target="_blank">00:40:10.840</a></span> | <span class="t">but the performance is very good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2414" target="_blank">00:40:14.680</a></span> | <span class="t">We can find, this model is actually trained</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2419" target="_blank">00:40:19.680</a></span> | <span class="t">to be a web agent,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2424" target="_blank">00:40:24.840</a></span> | <span class="t">and it's just take a screenshot as input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2429" target="_blank">00:40:29.840</a></span> | <span class="t">and it will perform different operation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2437" target="_blank">00:40:37.600</a></span> | <span class="t">on the screenshot.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2442" target="_blank">00:40:42.200</a></span> | <span class="t">For example, this is a example for a search.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2447" target="_blank">00:40:47.200</a></span> | <span class="t">So the last year's best paper in CVPR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2452" target="_blank">00:40:52.520</a></span> | <span class="t">So we asked the model these questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2457" target="_blank">00:40:57.000</a></span> | <span class="t">It told me you need to type the best paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2460" target="_blank">00:41:00.960</a></span> | <span class="t">of CVPR 2000 and the 23 in the box at this position.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2465" target="_blank">00:41:05.960</a></span> | <span class="t">And step-by-step, finally, we gather information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2471" target="_blank">00:41:11.080</a></span> | <span class="t">And we can also use this method to do some tickets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2476" target="_blank">00:41:16.080</a></span> | <span class="t">or perform some other tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2481" target="_blank">00:41:21.080</a></span> | <span class="t">Yeah, this is also open-sourced.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2485" target="_blank">00:41:25.640</a></span> | <span class="t">Some other popular architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2489" target="_blank">00:41:29.560</a></span> | <span class="t">about variant-language modeling includes Wiry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2497" target="_blank">00:41:37.240</a></span> | <span class="t">It's actually an example of different variant features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2501" target="_blank">00:41:41.000</a></span> | <span class="t">I input, and it's largely improved the OCR performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2506" target="_blank">00:41:46.000</a></span> | <span class="t">But what I want to stress is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2510" target="_blank">00:41:50.480</a></span> | <span class="t">we actually, in our most advanced variant-language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2515" target="_blank">00:41:55.480</a></span> | <span class="t">GLM4V, we actually use a more simple architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2524" target="_blank">00:42:04.200</a></span> | <span class="t">It's actually a small adaptation upon Lava.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2529" target="_blank">00:42:09.200</a></span> | <span class="t">We just replaced the projection rate of Lava</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2536" target="_blank">00:42:16.040</a></span> | <span class="t">into a stride convolution to suppose high-resolution input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2541" target="_blank">00:42:21.560</a></span> | <span class="t">but to keep the computation in language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2545" target="_blank">00:42:25.360</a></span> | <span class="t">Using this architecture,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2547" target="_blank">00:42:27.520</a></span> | <span class="t">we can train the variant-language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2551" target="_blank">00:42:31.080</a></span> | <span class="t">mixed with the text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2552" target="_blank">00:42:32.520</a></span> | <span class="t">And finally, we get a good performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2557" target="_blank">00:42:37.280</a></span> | <span class="t">We can say that GLM4V can underpower GPT-4V</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2562" target="_blank">00:42:42.280</a></span> | <span class="t">or Gemini or CloudStory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2566" target="_blank">00:42:46.680</a></span> | <span class="t">And it's performed better in OCR benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2571" target="_blank">00:42:51.680</a></span> | <span class="t">for example, Document QA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2576" target="_blank">00:42:56.640</a></span> | <span class="t">And it's performed much better at Chinese OCR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2581" target="_blank">00:43:01.680</a></span> | <span class="t">This is an example of our most advanced GLM4V model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2586" target="_blank">00:43:06.680</a></span> | <span class="t">You can download our app from this chatglm.cn website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2595" target="_blank">00:43:15.760</a></span> | <span class="t">This is actually a very hard-to-recognize draft,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2607" target="_blank">00:43:27.960</a></span> | <span class="t">but it's also a meme.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2611" target="_blank">00:43:31.120</a></span> | <span class="t">The model can analyze it very accurately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2617" target="_blank">00:43:37.080</a></span> | <span class="t">and can translate what is really right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2622" target="_blank">00:43:42.080</a></span> | <span class="t">So yeah, you can experience our model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2627" target="_blank">00:43:47.480</a></span> | <span class="t">It's totally free from this website.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2631" target="_blank">00:43:51.280</a></span> | <span class="t">Okay, we have some introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2636" target="_blank">00:43:56.280</a></span> | <span class="t">about variant-language understanding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2639" target="_blank">00:43:59.000</a></span> | <span class="t">It's more about engineering, but it's multimodality.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2644" target="_blank">00:44:04.000</a></span> | <span class="t">And another half of the variant-language research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2648" target="_blank">00:44:08.320</a></span> | <span class="t">is about image generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2650" target="_blank">00:44:10.160</a></span> | <span class="t">and is also relevant to transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2653" target="_blank">00:44:13.360</a></span> | <span class="t">So I will also introduce the rule about image generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2661" target="_blank">00:44:21.840</a></span> | <span class="t">Yeah, for three or four years ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2666" target="_blank">00:44:26.840</a></span> | <span class="t">we already know that GPT is very powerful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2676" target="_blank">00:44:36.400</a></span> | <span class="t">So we want to autoregressively modeling the X generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2681" target="_blank">00:44:41.400</a></span> | <span class="t">for using the GPT architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2687" target="_blank">00:44:47.160</a></span> | <span class="t">So this is the work of CogView.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2692" target="_blank">00:44:52.160</a></span> | <span class="t">It's also my work at 2021.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2694" target="_blank">00:44:54.680</a></span> | <span class="t">It's a very simple framework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2706" target="_blank">00:45:06.000</a></span> | <span class="t">because we know that GPT can only predict</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2710" target="_blank">00:45:10.000</a></span> | <span class="t">multinomial distribution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2712" target="_blank">00:45:12.200</a></span> | <span class="t">So we need to find some method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2715" target="_blank">00:45:15.400</a></span> | <span class="t">to train the image in a discrete way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2720" target="_blank">00:45:20.400</a></span> | <span class="t">There's maybe 2020, there's a paper called RGPT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2726" target="_blank">00:45:26.880</a></span> | <span class="t">from OpenAI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2730" target="_blank">00:45:30.480</a></span> | <span class="t">It's trained directly on the pixel level</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2733" target="_blank">00:45:33.160</a></span> | <span class="t">for autoregressive modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2736" target="_blank">00:45:36.040</a></span> | <span class="t">But the sequence is very long.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2741" target="_blank">00:45:41.480</a></span> | <span class="t">So you cannot train a very high-resolution images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2746" target="_blank">00:45:46.480</a></span> | <span class="t">So we can first train an image tokenizer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2752" target="_blank">00:45:52.960</a></span> | <span class="t">It's actually a weak way to disquiet your image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2757" target="_blank">00:45:57.960</a></span> | <span class="t">into several tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2763" target="_blank">00:46:03.800</a></span> | <span class="t">And you prepare the sequence of a text image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2769" target="_blank">00:46:09.920</a></span> | <span class="t">as the first text for us, the image later,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2773" target="_blank">00:46:13.560</a></span> | <span class="t">and you can use GPT to train this kind of sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2778" target="_blank">00:46:18.560</a></span> | <span class="t">And finally, during the inference,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2782" target="_blank">00:46:22.600</a></span> | <span class="t">you first import the text and then predicts token by token</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2787" target="_blank">00:46:27.600</a></span> | <span class="t">in the image token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2789" target="_blank">00:46:29.760</a></span> | <span class="t">In the image, you can generate some image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2793" target="_blank">00:46:33.040</a></span> | <span class="t">Yeah, this is a very simple idea</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2796" target="_blank">00:46:36.280</a></span> | <span class="t">and a concurrent work called DALI</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2799" target="_blank">00:46:39.320</a></span> | <span class="t">and the most powerful work called PARTY</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2803" target="_blank">00:46:43.480</a></span> | <span class="t">is from the same idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2806" target="_blank">00:46:46.800</a></span> | <span class="t">Okay, but yeah, we know that we can generate image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2811" target="_blank">00:46:51.800</a></span> | <span class="t">using GPT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2818" target="_blank">00:46:58.200</a></span> | <span class="t">So a very natural idea is can we achieve</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2824" target="_blank">00:47:04.480</a></span> | <span class="t">some universal modeling for real language tasks?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2829" target="_blank">00:47:09.480</a></span> | <span class="t">So if we just tokenize the image, just like the text,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2834" target="_blank">00:47:14.920</a></span> | <span class="t">we can generate image, we can generate text from the image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2841" target="_blank">00:47:21.880</a></span> | <span class="t">we can generate image from text, and only generate text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2848" target="_blank">00:47:28.440</a></span> | <span class="t">So this is a very natural idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2851" target="_blank">00:47:31.240</a></span> | <span class="t">And I also did this in Colville too, maybe two years ago.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2856" target="_blank">00:47:36.240</a></span> | <span class="t">And yeah, the algorithm is also very simple.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2863" target="_blank">00:47:43.640</a></span> | <span class="t">It's just, in the sequence, you change different position</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2870" target="_blank">00:47:50.120</a></span> | <span class="t">of text and image sequence.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2876" target="_blank">00:47:56.200</a></span> | <span class="t">If first text, then image, and you mask all the things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2880" target="_blank">00:48:00.400</a></span> | <span class="t">it's text-to-image generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2881" target="_blank">00:48:01.960</a></span> | <span class="t">If first image, then text, it's image captioning.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2886" target="_blank">00:48:06.360</a></span> | <span class="t">And you can also guess other formats</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2890" target="_blank">00:48:10.360</a></span> | <span class="t">like mask autoencoder or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2898" target="_blank">00:48:18.080</a></span> | <span class="t">But the problem is when you compare</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2902" target="_blank">00:48:22.360</a></span> | <span class="t">this universal modeling system to diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2908" target="_blank">00:48:28.200</a></span> | <span class="t">or real language modeling, or real language model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2912" target="_blank">00:48:32.200</a></span> | <span class="t">you will find the image generation is worse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2916" target="_blank">00:48:36.840</a></span> | <span class="t">than the diffusion, and very slow compared to diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2921" target="_blank">00:48:41.160</a></span> | <span class="t">For image understanding, it performs worse</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2926" target="_blank">00:48:46.880</a></span> | <span class="t">than real language model, because when your image is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2934" target="_blank">00:48:54.000</a></span> | <span class="t">when you transform your image into these quiet tokens,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2939" target="_blank">00:48:59.000</a></span> | <span class="t">lots of information is lost during this process.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2945" target="_blank">00:49:05.840</a></span> | <span class="t">So the performance is worse than the real language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2951" target="_blank">00:49:11.720</a></span> | <span class="t">So using this method, you can achieve universal modeling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2957" target="_blank">00:49:17.280</a></span> | <span class="t">but you just achieve universal modeling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2963" target="_blank">00:49:23.560</a></span> | <span class="t">and you cannot achieve the best performance on any task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2968" target="_blank">00:49:28.560</a></span> | <span class="t">So the diffusion method actually wins the game</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2976" target="_blank">00:49:36.400</a></span> | <span class="t">or image generation and not the autoregressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2982" target="_blank">00:49:42.480</a></span> | <span class="t">Although in the NLP domain, the autoregressive method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2987" target="_blank">00:49:47.480</a></span> | <span class="t">is dominant, but in image generation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2991" target="_blank">00:49:51.160</a></span> | <span class="t">the winner is diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2993" target="_blank">00:49:53.520</a></span> | <span class="t">So what is diffusion?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2996" target="_blank">00:49:56.200</a></span> | <span class="t">Diffusion is actually another,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=2998" target="_blank">00:49:58.360</a></span> | <span class="t">is a totally different self-supervised learning method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3003" target="_blank">00:50:03.680</a></span> | <span class="t">compared to autoregressive method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3007" target="_blank">00:50:07.520</a></span> | <span class="t">You can also think it's autoregressive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3012" target="_blank">00:50:12.520</a></span> | <span class="t">on a Fourier domain or something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3016" target="_blank">00:50:16.240</a></span> | <span class="t">So, but actually, the DDPM is the original DDPM.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3021" target="_blank">00:50:21.440</a></span> | <span class="t">The DDPM is the original paper of diffusion model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3026" target="_blank">00:50:26.440</a></span> | <span class="t">is still the most popular framework of diffusion modeling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3031" target="_blank">00:50:31.640</a></span> | <span class="t">We can define lots of steps.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3036" target="_blank">00:50:36.760</a></span> | <span class="t">We gradually add in noise to a clean image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3042" target="_blank">00:50:42.040</a></span> | <span class="t">and we get different intermediate states,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3047" target="_blank">00:50:47.800</a></span> | <span class="t">and the training a model to predict the noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3051" target="_blank">00:50:51.520</a></span> | <span class="t">the original image, or something like V</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3056" target="_blank">00:50:56.520</a></span> | <span class="t">is the velocity of the angle of the logarithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3061" target="_blank">00:51:01.520</a></span> | <span class="t">actually, given the noisy important, noisy image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3067" target="_blank">00:51:07.040</a></span> | <span class="t">So it's totally different,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3071" target="_blank">00:51:11.040</a></span> | <span class="t">but the most advantage of diffusion model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3077" target="_blank">00:51:17.040</a></span> | <span class="t">or autoregressive model is that during sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3082" target="_blank">00:51:22.040</a></span> | <span class="t">we, during sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3087" target="_blank">00:51:27.080</a></span> | <span class="t">we can, during sampling,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3091" target="_blank">00:51:31.840</a></span> | <span class="t">we can use four utility or GPUs,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3096" target="_blank">00:51:36.840</a></span> | <span class="t">because in autoregressive model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3100" target="_blank">00:51:40.000</a></span> | <span class="t">when we decode a token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3102" target="_blank">00:51:42.320</a></span> | <span class="t">we actually erase the power of the GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3107" target="_blank">00:51:47.320</a></span> | <span class="t">It is the utility of GPU is very low.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3110" target="_blank">00:51:50.920</a></span> | <span class="t">If the batch size is small, the batch size is equal to one,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3114" target="_blank">00:51:54.880</a></span> | <span class="t">but for a diffusion model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3117" target="_blank">00:51:57.880</a></span> | <span class="t">we just input all the image into the model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3122" target="_blank">00:52:02.880</a></span> | <span class="t">So it can utilize the GPU,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3125" target="_blank">00:52:05.600</a></span> | <span class="t">and it can sampling much faster than autoregressive model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3130" target="_blank">00:52:10.600</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3132" target="_blank">00:52:12.840</a></span> | <span class="t">The related fusion model is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3135" target="_blank">00:52:15.840</a></span> | <span class="t">the related fusion model is our recent work,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3140" target="_blank">00:52:20.840</a></span> | <span class="t">but it's solved a problem in diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3146" target="_blank">00:52:26.120</a></span> | <span class="t">about the noise schedule across different resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3152" target="_blank">00:52:32.160</a></span> | <span class="t">The first thing is that you can see the left side</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3158" target="_blank">00:52:38.560</a></span> | <span class="t">you can see the left image is actually three images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3163" target="_blank">00:52:43.560</a></span> | <span class="t">with the same noise.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3170" target="_blank">00:52:50.160</a></span> | <span class="t">The A and B are two images with different resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3175" target="_blank">00:52:55.160</a></span> | <span class="t">and with the same noise level,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3178" target="_blank">00:52:58.600</a></span> | <span class="t">but the A is actually more blurred</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3181" target="_blank">00:53:01.280</a></span> | <span class="t">for us during the observation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3186" target="_blank">00:53:06.720</a></span> | <span class="t">The problem is we add independent noise,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3191" target="_blank">00:53:11.720</a></span> | <span class="t">and actually the original signal,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3196" target="_blank">00:53:16.720</a></span> | <span class="t">the image is not independent across the space.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3205" target="_blank">00:53:25.320</a></span> | <span class="t">So what we need to do is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3216" target="_blank">00:53:36.240</a></span> | <span class="t">if we want to transform a noisy schedule</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3220" target="_blank">00:53:40.280</a></span> | <span class="t">from a low resolution to high resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3222" target="_blank">00:53:42.560</a></span> | <span class="t">we need to use a block noise to find the equivalence</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3227" target="_blank">00:53:47.560</a></span> | <span class="t">on the high resolution images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3235" target="_blank">00:53:55.080</a></span> | <span class="t">And finally, we can keep the SNR</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3238" target="_blank">00:53:58.080</a></span> | <span class="t">in the frequency graph the same.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3244" target="_blank">00:54:04.800</a></span> | <span class="t">So using that method,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3249" target="_blank">00:54:09.800</a></span> | <span class="t">we can disentangle the noisy schedule</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3254" target="_blank">00:54:14.360</a></span> | <span class="t">and the actually network we use for diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3259" target="_blank">00:54:19.360</a></span> | <span class="t">Use a noisy schedule, we don't care about the resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3263" target="_blank">00:54:23.280</a></span> | <span class="t">we just use a block noise when we want to continue diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3268" target="_blank">00:54:28.280</a></span> | <span class="t">on a high resolution one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3271" target="_blank">00:54:31.840</a></span> | <span class="t">So the speed can improve because we don't need</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3276" target="_blank">00:54:36.840</a></span> | <span class="t">to re-generate the image from the high resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3283" target="_blank">00:54:43.360</a></span> | <span class="t">from the high condition on the low resolution image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3287" target="_blank">00:54:47.720</a></span> | <span class="t">on high resolution phase.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3290" target="_blank">00:54:50.840</a></span> | <span class="t">Okay, and we also scale up the relay diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3295" target="_blank">00:54:55.640</a></span> | <span class="t">to COGLUE3 after the paper, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3301" target="_blank">00:55:01.240</a></span> | <span class="t">The COGLUE3 is actually a large diffusion model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3306" target="_blank">00:55:06.240</a></span> | <span class="t">and after dissolution, it could be very fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3310" target="_blank">00:55:10.840</a></span> | <span class="t">because of the effectiveness of the relay diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3315" target="_blank">00:55:15.840</a></span> | <span class="t">Okay, finally, we get something relevant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3323" target="_blank">00:55:23.120</a></span> | <span class="t">to our topic, transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3328" target="_blank">00:55:28.400</a></span> | <span class="t">And actually, the previous works about the diffusion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3333" target="_blank">00:55:33.400</a></span> | <span class="t">is on UNET, and using transformer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3338" target="_blank">00:55:38.600</a></span> | <span class="t">is not trivial in diffusion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3342" target="_blank">00:55:42.800</a></span> | <span class="t">The first work I think maybe is solid enough</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3347" target="_blank">00:55:47.800</a></span> | <span class="t">is DIT from META, the author of this paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3355" target="_blank">00:55:55.280</a></span> | <span class="t">also the author of ASORA.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3357" target="_blank">00:55:57.200</a></span> | <span class="t">So the most important, most difference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3361" target="_blank">00:56:01.760</a></span> | <span class="t">between the original transformer and this DIT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3366" target="_blank">00:56:06.760</a></span> | <span class="t">is the IDA layer norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3371" target="_blank">00:56:11.000</a></span> | <span class="t">The IDA layer norm is predict scale and bias</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3376" target="_blank">00:56:16.000</a></span> | <span class="t">for different layer norm, scale and shifts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3381" target="_blank">00:56:21.040</a></span> | <span class="t">for different layer norm, conditioning on the time step.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3385" target="_blank">00:56:25.040</a></span> | <span class="t">It actually needs a very huge amount of parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3389" target="_blank">00:56:29.840</a></span> | <span class="t">It's six times our hidden size,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3394" target="_blank">00:56:34.240</a></span> | <span class="t">nearly equals to a QPV with per layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3399" target="_blank">00:56:39.240</a></span> | <span class="t">But the input is only one int.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3404" target="_blank">00:56:44.960</a></span> | <span class="t">It's actually very strange</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3407" target="_blank">00:56:47.520</a></span> | <span class="t">because the input is only one int,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3409" target="_blank">00:56:49.920</a></span> | <span class="t">and you need millions of parameters to transform it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3415" target="_blank">00:56:55.000</a></span> | <span class="t">So some method can reduce this theme in our practice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3420" target="_blank">00:57:00.000</a></span> | <span class="t">The Stable Diffusion 3, released recently,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3429" target="_blank">00:57:09.960</a></span> | <span class="t">use another architectures called MMDIT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3433" target="_blank">00:57:13.480</a></span> | <span class="t">The Stable Diffusion 3 first use our released code</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3438" target="_blank">00:57:18.240</a></span> | <span class="t">via M2Caption on the model, on the images,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3441" target="_blank">00:57:21.600</a></span> | <span class="t">and train a latent diffusion model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3443" target="_blank">00:57:23.640</a></span> | <span class="t">using this new architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3445" target="_blank">00:57:25.480</a></span> | <span class="t">The new architecture seem like very complicated,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3448" target="_blank">00:57:28.120</a></span> | <span class="t">but the most important thing is,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3452" target="_blank">00:57:32.200</a></span> | <span class="t">they use a region and text export like OVLM,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3458" target="_blank">00:57:38.200</a></span> | <span class="t">instead of cross-attention to T5 features</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3462" target="_blank">00:57:42.480</a></span> | <span class="t">like the previous ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3464" target="_blank">00:57:44.080</a></span> | <span class="t">So finally, we will talk shortly about video generation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3470" target="_blank">00:57:50.480</a></span> | <span class="t">because Sora is a currently very popular scene.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3475" target="_blank">00:57:55.480</a></span> | <span class="t">We published video generation work several years ago,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3483" target="_blank">00:58:03.280</a></span> | <span class="t">and finally, it is published earlier.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3488" target="_blank">00:58:08.120</a></span> | <span class="t">So it's maybe the first open-source language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3492" target="_blank">00:58:12.200</a></span> | <span class="t">for test video generation,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3493" target="_blank">00:58:13.560</a></span> | <span class="t">but the performance is much worse than the current Sora</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3497" target="_blank">00:58:17.520</a></span> | <span class="t">because it's autoregressive.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3500" target="_blank">00:58:20.240</a></span> | <span class="t">So using diffusion, we can get better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3504" target="_blank">00:58:24.000</a></span> | <span class="t">We currently also working for replication</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3507" target="_blank">00:58:27.200</a></span> | <span class="t">of Sora-like models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3508" target="_blank">00:58:28.960</a></span> | <span class="t">and we can summary that the improvement of Sora</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3513" target="_blank">00:58:33.960</a></span> | <span class="t">come from this aspects of forces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3521" target="_blank">00:58:41.880</a></span> | <span class="t">There's no flicking in the videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3525" target="_blank">00:58:45.480</a></span> | <span class="t">and it can generate high-quality images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3530" target="_blank">00:58:50.320</a></span> | <span class="t">The first one to de-flicking can be solved</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3534" target="_blank">00:58:54.360</a></span> | <span class="t">by the 3D latent encoder-decoder,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3539" target="_blank">00:58:59.360</a></span> | <span class="t">and if you train a diffusion decoder, it could be better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3544" target="_blank">00:59:04.200</a></span> | <span class="t">The high-quality is sense to the scaling up,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3550" target="_blank">00:59:10.160</a></span> | <span class="t">and it requires a very high resolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3555" target="_blank">00:59:15.840</a></span> | <span class="t">and this is something related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3560" target="_blank">00:59:20.600</a></span> | <span class="t">to the long-contact band tuning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3562" target="_blank">00:59:22.720</a></span> | <span class="t">and the context-parallel techniques</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3565" target="_blank">00:59:25.400</a></span> | <span class="t">in the language model infra,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3568" target="_blank">00:59:28.440</a></span> | <span class="t">which I introduced at the beginning of this course.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3573" target="_blank">00:59:33.080</a></span> | <span class="t">So the most important thing is to use the infra</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3578" target="_blank">00:59:38.080</a></span> | <span class="t">in language model training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3584" target="_blank">00:59:44.120</a></span> | <span class="t">into the diffusion and make it very easy to scale up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3589" target="_blank">00:59:49.120</a></span> | <span class="t">and scale up much larger than the other companies, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3597" target="_blank">00:59:57.280</a></span> | <span class="t">And finally, the most important thing is data coverage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3605" target="_blank">01:00:05.080</a></span> | <span class="t">It needs a very heavy data engineering and video recaption.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3609" target="_blank">01:00:09.200</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3614" target="_blank">01:00:14.680</a></span> | <span class="t">So this, I have introduced many topics</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3619" target="_blank">01:00:19.680</a></span> | <span class="t">of current multimodality print training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3624" target="_blank">01:00:24.360</a></span> | <span class="t">and some problems in this transformer community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3629" target="_blank">01:00:29.360</a></span> | <span class="t">So there are some trades I think will happen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3635" target="_blank">01:00:35.080</a></span> | <span class="t">in one or few years in the multimodality area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3642" target="_blank">01:00:42.080</a></span> | <span class="t">In the next one or two years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3645" target="_blank">01:00:45.520</a></span> | <span class="t">we can easily recognize grounding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3650" target="_blank">01:00:50.520</a></span> | <span class="t">all the common scenes, attributes, and the human expressions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3656" target="_blank">01:00:56.360</a></span> | <span class="t">and other lots of high-level vision scenes,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3661" target="_blank">01:01:01.680</a></span> | <span class="t">and all these scenes will be very cheap</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3664" target="_blank">01:01:04.520</a></span> | <span class="t">and be basically sold.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3667" target="_blank">01:01:07.160</a></span> | <span class="t">So this will happen in one or two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3672" target="_blank">01:01:12.160</a></span> | <span class="t">At that time, the long tail problem of auto driving</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3677" target="_blank">01:01:17.760</a></span> | <span class="t">could be alleviated, not solved, but largely alleviated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3684" target="_blank">01:01:24.200</a></span> | <span class="t">And the second prediction is the video understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3689" target="_blank">01:01:29.640</a></span> | <span class="t">will become very important in the next one or two years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3697" target="_blank">01:01:37.840</a></span> | <span class="t">Because it's very useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3700" target="_blank">01:01:40.160</a></span> | <span class="t">We have lots of video in the internet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3705" target="_blank">01:01:45.160</a></span> | <span class="t">and in our everyday life, but it's very hard.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3710" target="_blank">01:01:50.560</a></span> | <span class="t">And currently we cannot understand video well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3714" target="_blank">01:01:54.800</a></span> | <span class="t">And the most powerful video understanding model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3717" target="_blank">01:01:57.720</a></span> | <span class="t">currently is the Gemini 1.5,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3721" target="_blank">01:02:01.040</a></span> | <span class="t">but it's basically lots of hallucinations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3726" target="_blank">01:02:06.760</a></span> | <span class="t">and wrong counting and lots of weakness.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3731" target="_blank">01:02:11.520</a></span> | <span class="t">So there's very less room to improve.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3736" target="_blank">01:02:16.520</a></span> | <span class="t">Another thing is we have enough compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3744" target="_blank">01:02:24.320</a></span> | <span class="t">to deal with the video now,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3746" target="_blank">01:02:26.280</a></span> | <span class="t">and especially in the next one or two years,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3750" target="_blank">01:02:30.800</a></span> | <span class="t">because the next generation of Nvidia GPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3755" target="_blank">01:02:35.560</a></span> | <span class="t">and the requirements from a larger language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3760" target="_blank">01:02:40.560</a></span> | <span class="t">And another important thing is embodied AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3766" target="_blank">01:02:46.960</a></span> | <span class="t">Embodied AI will be more and more important in the research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3770" target="_blank">01:02:50.760</a></span> | <span class="t">and it will be very closely related</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3775" target="_blank">01:02:55.760</a></span> | <span class="t">to multi-modality research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3779" target="_blank">01:02:59.320</a></span> | <span class="t">although it cannot impact our real life in a few years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3784" target="_blank">01:03:04.880</a></span> | <span class="t">Because we now have planning ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3789" target="_blank">01:03:09.880</a></span> | <span class="t">with large language models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3792" target="_blank">01:03:12.280</a></span> | <span class="t">we can recognize all the things we remember in the models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3795" target="_blank">01:03:15.080</a></span> | <span class="t">And there will be some chances to get some new ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3800" target="_blank">01:03:20.080</a></span> | <span class="t">and a very astonishing demo of this embodied AI,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3810" target="_blank">01:03:30.800</a></span> | <span class="t">but they may be very expensive</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3815" target="_blank">01:03:35.800</a></span> | <span class="t">and cannot be used for everyday life.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3820" target="_blank">01:03:40.760</a></span> | <span class="t">So what should we do at that time?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3825" target="_blank">01:03:45.760</a></span> | <span class="t">For me, some researchers like me,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3832" target="_blank">01:03:52.400</a></span> | <span class="t">large language model company,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3834" target="_blank">01:03:54.280</a></span> | <span class="t">we got enough computer resources,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3839" target="_blank">01:03:59.480</a></span> | <span class="t">but for others,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3841" target="_blank">01:04:01.680</a></span> | <span class="t">so I think if you are a senior researcher,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3846" target="_blank">01:04:06.120</a></span> | <span class="t">so just follow your heart and ignore me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3849" target="_blank">01:04:09.440</a></span> | <span class="t">If you want to quickly gain some statisticians' papers impact,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3854" target="_blank">01:04:14.440</a></span> | <span class="t">I think maybe you can consider</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3859" target="_blank">01:04:19.480</a></span> | <span class="t">that the video understanding models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3862" target="_blank">01:04:22.840</a></span> | <span class="t">datasets, benchmarks,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3865" target="_blank">01:04:25.200</a></span> | <span class="t">especially datasets and benchmarks is very important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3868" target="_blank">01:04:28.200</a></span> | <span class="t">and in great need of the video understanding community.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3872" target="_blank">01:04:32.200</a></span> | <span class="t">Yeah, and for multi-modality,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3876" target="_blank">01:04:36.240</a></span> | <span class="t">and there's another topic I haven't talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3881" target="_blank">01:04:41.240</a></span> | <span class="t">in this lecture is speech or audio.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3886" target="_blank">01:04:46.640</a></span> | <span class="t">I recently learned some knowledge about audio,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3892" target="_blank">01:04:52.960</a></span> | <span class="t">and I lead the group of speech AI group</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3898" target="_blank">01:04:58.000</a></span> | <span class="t">in Drupal AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3899" target="_blank">01:04:59.200</a></span> | <span class="t">So I'm not a researcher about audio,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3903" target="_blank">01:05:03.400</a></span> | <span class="t">but I can say that the speech AI is underestimated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3908" target="_blank">01:05:08.400</a></span> | <span class="t">It's actually very important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3912" target="_blank">01:05:12.040</a></span> | <span class="t">for the user need and application,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3915" target="_blank">01:05:15.920</a></span> | <span class="t">but there's not enough GPU and research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3920" target="_blank">01:05:20.480</a></span> | <span class="t">researchers put into this areas like in language model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3925" target="_blank">01:05:25.240</a></span> | <span class="t">Yeah, finally, if you want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3927" target="_blank">01:05:27.200</a></span> | <span class="t">some very useful impact AI research,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3930" target="_blank">01:05:30.680</a></span> | <span class="t">which is very risky,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3933" target="_blank">01:05:33.120</a></span> | <span class="t">you need to make some system PhD student at once,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3938" target="_blank">01:05:38.120</a></span> | <span class="t">because the best algorithm must utilize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3945" target="_blank">01:05:45.080</a></span> | <span class="t">the current GPU and other hardware.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3954" target="_blank">01:05:54.160</a></span> | <span class="t">Yeah, so you just need to know some system PhD students,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3959" target="_blank">01:05:59.160</a></span> | <span class="t">and there should be another is a more difficult,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3965" target="_blank">01:06:05.240</a></span> | <span class="t">but influential is there's actually some room</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3972" target="_blank">01:06:12.800</a></span> | <span class="t">for new architectures,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3974" target="_blank">01:06:14.600</a></span> | <span class="t">for self-supervised learning and optimizers,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3979" target="_blank">01:06:19.400</a></span> | <span class="t">because the next generation of hardware</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3982" target="_blank">01:06:22.920</a></span> | <span class="t">will be totally different.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3985" target="_blank">01:06:25.600</a></span> | <span class="t">So maybe the transformer will have some competitors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3990" target="_blank">01:06:30.600</a></span> | <span class="t">and also the autoregressive modeling method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3996" target="_blank">01:06:36.840</a></span> | <span class="t">So there's some room,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=3997" target="_blank">01:06:37.960</a></span> | <span class="t">but it's very hard and some computational resourcing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4001" target="_blank">01:06:41.920</a></span> | <span class="t">And finally, the new ways to transform compute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4006" target="_blank">01:06:46.480</a></span> | <span class="t">to high quality data is very important,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4009" target="_blank">01:06:49.160</a></span> | <span class="t">because the high quality web data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4014" target="_blank">01:06:54.160</a></span> | <span class="t">is actually be crawled down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4017" target="_blank">01:06:57.040</a></span> | <span class="t">into almost every large language model company,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4023" target="_blank">01:07:03.600</a></span> | <span class="t">and it's currently not very enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4025" target="_blank">01:07:05.960</a></span> | <span class="t">So we need to find some new ways</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4029" target="_blank">01:07:09.400</a></span> | <span class="t">to transform compute to high quality data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4031" target="_blank">01:07:11.960</a></span> | <span class="t">For example, how to synthesizing the new data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4035" target="_blank">01:07:15.920</a></span> | <span class="t">using code execution results,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4039" target="_blank">01:07:19.320</a></span> | <span class="t">using maybe MCTS reinforcement learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4044" target="_blank">01:07:24.320</a></span> | <span class="t">or some other method is very big area</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4048" target="_blank">01:07:28.960</a></span> | <span class="t">in the last few years.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4053" target="_blank">01:07:33.200</a></span> | <span class="t">Yeah, I think I will end this lecture here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4058" target="_blank">01:07:38.200</a></span> | <span class="t">and thank you for the instructors and the audience.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4063" target="_blank">01:07:43.720</a></span> | <span class="t">Thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4064" target="_blank">01:07:44.960</a></span> | <span class="t">If you have some question,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4067" target="_blank">01:07:47.120</a></span> | <span class="t">you can send an email to this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4070" target="_blank">01:07:50.320</a></span> | <span class="t">and I will answer all the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4073" target="_blank">01:07:53.960</a></span> | <span class="t">Thank you very much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4074" target="_blank">01:07:54.960</a></span> | <span class="t">- Yeah, thank you very much, Ming,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4081" target="_blank">01:08:01.280</a></span> | <span class="t">for the amazing talk and all the useful advice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4084" target="_blank">01:08:04.520</a></span> | <span class="t">So we have some questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4086" target="_blank">01:08:06.840</a></span> | <span class="t">I got one through Zoom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4088" target="_blank">01:08:08.160</a></span> | <span class="t">and there's several also on Slido.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4091" target="_blank">01:08:11.360</a></span> | <span class="t">So Emily, are there any in-person questions</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4094" target="_blank">01:08:14.840</a></span> | <span class="t">from your end?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4095" target="_blank">01:08:15.680</a></span> | <span class="t">- Okay, if someone has some questions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4103" target="_blank">01:08:23.040</a></span> | <span class="t">you can type in the chatting in Zoom,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4108" target="_blank">01:08:28.040</a></span> | <span class="t">if you are using Zoom.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4110" target="_blank">01:08:30.880</a></span> | <span class="t">- Let me see.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4112" target="_blank">01:08:32.800</a></span> | <span class="t">Okay, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4116" target="_blank">01:08:36.600</a></span> | <span class="t">Here's some questions on Slido that I'll ask.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4119" target="_blank">01:08:39.080</a></span> | <span class="t">The first is that the success of long context windows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4123" target="_blank">01:08:43.520</a></span> | <span class="t">must come at a cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4125" target="_blank">01:08:45.600</a></span> | <span class="t">What is this cost?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4127" target="_blank">01:08:47.480</a></span> | <span class="t">- The cost is a very long time conception.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4133" target="_blank">01:08:53.760</a></span> | <span class="t">You just need to run your inference engine</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4140" target="_blank">01:09:00.960</a></span> | <span class="t">for a very long time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4143" target="_blank">01:09:03.760</a></span> | <span class="t">Actually, the current inference system</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4147" target="_blank">01:09:07.480</a></span> | <span class="t">of large-length model can be split into two periods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4153" target="_blank">01:09:13.480</a></span> | <span class="t">One is profiling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4155" target="_blank">01:09:15.280</a></span> | <span class="t">You need to import a very long context into your engine,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4160" target="_blank">01:09:20.280</a></span> | <span class="t">and then another is decode,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4164" target="_blank">01:09:24.320</a></span> | <span class="t">and you generate token by token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4169" target="_blank">01:09:29.040</a></span> | <span class="t">So most user case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4172" target="_blank">01:09:32.000</a></span> | <span class="t">they actually not generate a very long context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4175" target="_blank">01:09:35.640</a></span> | <span class="t">They don't understand a long context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4177" target="_blank">01:09:37.600</a></span> | <span class="t">and generate a very few tokens about the question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4182" target="_blank">01:09:42.600</a></span> | <span class="t">So we can bear maybe one minute</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4188" target="_blank">01:09:48.400</a></span> | <span class="t">to allow the language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4196" target="_blank">01:09:56.440</a></span> | <span class="t">just around the long context understanding,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4201" target="_blank">01:10:01.720</a></span> | <span class="t">and then begin to answer your question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4205" target="_blank">01:10:05.240</a></span> | <span class="t">So this is a cost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4206" target="_blank">01:10:06.640</a></span> | <span class="t">You need to wait for maybe several seconds or one minute.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4211" target="_blank">01:10:11.640</a></span> | <span class="t">Yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4214" target="_blank">01:10:14.360</a></span> | <span class="t">- Right, oops, I was muted, but yeah, thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4219" target="_blank">01:10:19.680</a></span> | <span class="t">That makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4220" target="_blank">01:10:20.960</a></span> | <span class="t">So there's two questions which are pretty similar,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4223" target="_blank">01:10:23.840</a></span> | <span class="t">all uploaded on Slido,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4226" target="_blank">01:10:26.120</a></span> | <span class="t">talking about the quality of data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4228" target="_blank">01:10:28.520</a></span> | <span class="t">So recently, folks have been saying that the quality of data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4231" target="_blank">01:10:31.400</a></span> | <span class="t">is what really determines final model performance</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4234" target="_blank">01:10:34.120</a></span> | <span class="t">compared to anything else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4236" target="_blank">01:10:36.280</a></span> | <span class="t">Do you agree?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4237" target="_blank">01:10:37.560</a></span> | <span class="t">And related to this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4239" target="_blank">01:10:39.320</a></span> | <span class="t">do you think there's still a lot of work to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4241" target="_blank">01:10:41.440</a></span> | <span class="t">around improving the architecture models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4244" target="_blank">01:10:44.160</a></span> | <span class="t">or has attention shifted to focus on data?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4246" target="_blank">01:10:46.840</a></span> | <span class="t">- Yeah, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4248" target="_blank">01:10:48.840</a></span> | <span class="t">I think this is very reasonable,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4251" target="_blank">01:10:51.760</a></span> | <span class="t">actually what the whole community is doing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4256" target="_blank">01:10:56.520</a></span> | <span class="t">is to improve the data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4258" target="_blank">01:10:58.200</a></span> | <span class="t">I just talk about this opinion in the lecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4265" target="_blank">01:11:05.360</a></span> | <span class="t">is the architecture, the algorithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4268" target="_blank">01:11:08.840</a></span> | <span class="t">the data can transform to each other.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4272" target="_blank">01:11:12.440</a></span> | <span class="t">If you have some idea,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4273" target="_blank">01:11:13.760</a></span> | <span class="t">you can inject the inductive bias into architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4277" target="_blank">01:11:17.120</a></span> | <span class="t">You can design a new algorithm,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4280" target="_blank">01:11:20.040</a></span> | <span class="t">and you can prepare some data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4284" target="_blank">01:11:24.040</a></span> | <span class="t">to tell your model to act like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4288" target="_blank">01:11:28.200</a></span> | <span class="t">So many of the very special cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4294" target="_blank">01:11:34.440</a></span> | <span class="t">you can use data to solve the problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4298" target="_blank">01:11:38.560</a></span> | <span class="t">So the high quality data is more important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4301" target="_blank">01:11:41.880</a></span> | <span class="t">than architecture updates for many tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4306" target="_blank">01:11:46.880</a></span> | <span class="t">I think if you can find a general update of transformer,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4313" target="_blank">01:11:53.760</a></span> | <span class="t">it's very valuable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4317" target="_blank">01:11:57.840</a></span> | <span class="t">If you just increase the power of the model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4322" target="_blank">01:12:02.400</a></span> | <span class="t">to fit in the data, it's very, very valuable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4326" target="_blank">01:12:06.800</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4327" target="_blank">01:12:07.640</a></span> | <span class="t">- All right, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4330" target="_blank">01:12:10.320</a></span> | <span class="t">Here's a question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4331" target="_blank">01:12:11.720</a></span> | <span class="t">Why is autoregressive architecture</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4333" target="_blank">01:12:13.640</a></span> | <span class="t">inferior to diffusion in image generation?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4336" target="_blank">01:12:16.520</a></span> | <span class="t">- Yeah, it's very complicated.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4344" target="_blank">01:12:24.480</a></span> | <span class="t">This question is very complicated, actually.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4347" target="_blank">01:12:27.200</a></span> | <span class="t">So the diffusion is totally different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4353" target="_blank">01:12:33.200</a></span> | <span class="t">in autoregressive to some extent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4357" target="_blank">01:12:37.320</a></span> | <span class="t">But the most important thing I have talked about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4360" target="_blank">01:12:40.480</a></span> | <span class="t">in the lecture is the speed of generation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4365" target="_blank">01:12:45.320</a></span> | <span class="t">For autoregressive model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4367" target="_blank">01:12:47.280</a></span> | <span class="t">if you use a very large model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4370" target="_blank">01:12:50.280</a></span> | <span class="t">you train it for a very long time,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4372" target="_blank">01:12:52.680</a></span> | <span class="t">I believe we can get a very good result.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4376" target="_blank">01:12:56.960</a></span> | <span class="t">We can also generate high quality images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4381" target="_blank">01:13:01.480</a></span> | <span class="t">using autoregressive methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4383" target="_blank">01:13:03.600</a></span> | <span class="t">This is okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4385" target="_blank">01:13:05.920</a></span> | <span class="t">But the time to generate an image is very, very long</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4390" target="_blank">01:13:10.920</a></span> | <span class="t">because we need to predict the token by token,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4394" target="_blank">01:13:14.400</a></span> | <span class="t">maybe a high resolution image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4398" target="_blank">01:13:18.720</a></span> | <span class="t">maybe thousands of tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4401" target="_blank">01:13:21.720</a></span> | <span class="t">But for diffusion, we use several steps</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4407" target="_blank">01:13:27.320</a></span> | <span class="t">or feed forwarding all the image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4412" target="_blank">01:13:32.320</a></span> | <span class="t">We don't need to token by token prediction.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4415" target="_blank">01:13:35.560</a></span> | <span class="t">It would be thousands times faster</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4420" target="_blank">01:13:40.040</a></span> | <span class="t">than autoregressive model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4421" target="_blank">01:13:41.480</a></span> | <span class="t">if you are generating high resolution images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4424" target="_blank">01:13:44.600</a></span> | <span class="t">So this is a very obvious advantage.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4429" target="_blank">01:13:49.600</a></span> | <span class="t">And for the modeling power,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4432" target="_blank">01:13:52.440</a></span> | <span class="t">I think the most important thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4434" target="_blank">01:13:54.400</a></span> | <span class="t">is maybe some relation between the space</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4439" target="_blank">01:13:59.400</a></span> | <span class="t">is actually we are not modeling well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4449" target="_blank">01:14:09.640</a></span> | <span class="t">by autoregressive model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4452" target="_blank">01:14:12.040</a></span> | <span class="t">because the left most pixel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4456" target="_blank">01:14:16.800</a></span> | <span class="t">and the right bottom pixel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4460" target="_blank">01:14:20.120</a></span> | <span class="t">is very far in autoregressive model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4465" target="_blank">01:14:25.000</a></span> | <span class="t">But in diffusion model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4468" target="_blank">01:14:28.160</a></span> | <span class="t">we can see each other, so it's not a problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4472" target="_blank">01:14:32.800</a></span> | <span class="t">But for autoregressive model,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4474" target="_blank">01:14:34.200</a></span> | <span class="t">it has position problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4476" target="_blank">01:14:36.120</a></span> | <span class="t">So it's not easy to model a very complicated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4481" target="_blank">01:14:41.120</a></span> | <span class="t">2D spatial problem.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4487" target="_blank">01:14:47.600</a></span> | <span class="t">This is also a possible reason,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4491" target="_blank">01:14:51.440</a></span> | <span class="t">but I cannot give a very good answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4496" target="_blank">01:14:56.440</a></span> | <span class="t">about this question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4499" target="_blank">01:14:59.600</a></span> | <span class="t">But yeah, there should be more research about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4504" target="_blank">01:15:04.600</a></span> | <span class="t">Yeah, thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4505" target="_blank">01:15:05.520</a></span> | <span class="t">- Right, great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4508" target="_blank">01:15:08.040</a></span> | <span class="t">Thanks for that detailed answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4509" target="_blank">01:15:09.880</a></span> | <span class="t">So someone is asking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4510" target="_blank">01:15:10.920</a></span> | <span class="t">how is the COG agent model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4512" target="_blank">01:15:12.560</a></span> | <span class="t">different from the COG VLM model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4516" target="_blank">01:15:16.080</a></span> | <span class="t">- Oh, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4516" target="_blank">01:15:16.920</a></span> | <span class="t">The COG agent model is actually fine-tuned</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4520" target="_blank">01:15:20.480</a></span> | <span class="t">from the COG VLM model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4522" target="_blank">01:15:22.000</a></span> | <span class="t">But the COG agent model deal with high resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4527" target="_blank">01:15:27.000</a></span> | <span class="t">and web screen cases</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4531" target="_blank">01:15:31.160</a></span> | <span class="t">because our motivation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4533" target="_blank">01:15:33.360</a></span> | <span class="t">is that the high-resolution inputs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4537" target="_blank">01:15:37.880</a></span> | <span class="t">for web pages is very important</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4539" target="_blank">01:15:39.520</a></span> | <span class="t">because there's many words, many icons,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4543" target="_blank">01:15:43.360</a></span> | <span class="t">something very small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4545" target="_blank">01:15:45.360</a></span> | <span class="t">And you'll need to use a very high-resolution model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4549" target="_blank">01:15:49.880</a></span> | <span class="t">to deal with it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4551" target="_blank">01:15:51.640</a></span> | <span class="t">But if you just extend the input resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4556" target="_blank">01:15:56.640</a></span> | <span class="t">or COG VLM, the conception is very high.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4564" target="_blank">01:16:04.200</a></span> | <span class="t">So we use a cross-attention module</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4569" target="_blank">01:16:09.080</a></span> | <span class="t">adding to the COG VLM to get a COG agent.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4572" target="_blank">01:16:12.320</a></span> | <span class="t">So this module is a much lighter weight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4576" target="_blank">01:16:16.400</a></span> | <span class="t">so we can deal with the high-resolution more easily, yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4581" target="_blank">01:16:21.120</a></span> | <span class="t">- Great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4584" target="_blank">01:16:24.680</a></span> | <span class="t">Here's a question about video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4587" target="_blank">01:16:27.560</a></span> | <span class="t">How do you think video understanding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4589" target="_blank">01:16:29.080</a></span> | <span class="t">will aid AI's ability</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4590" target="_blank">01:16:30.520</a></span> | <span class="t">to have a stronger physical understanding of the world?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4594" target="_blank">01:16:34.080</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4596" target="_blank">01:16:36.080</a></span> | <span class="t">Okay, that's a very good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4598" target="_blank">01:16:38.560</a></span> | <span class="t">I think, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4600" target="_blank">01:16:40.520</a></span> | <span class="t">My answer is yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4602" target="_blank">01:16:42.280</a></span> | <span class="t">But it's actually a bilateral problem</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4607" target="_blank">01:16:47.280</a></span> | <span class="t">because if you don't have some data source</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4615" target="_blank">01:16:55.680</a></span> | <span class="t">which contains physical rules,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4618" target="_blank">01:16:58.200</a></span> | <span class="t">you cannot train a good video understanding model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4627" target="_blank">01:17:07.240</a></span> | <span class="t">I think using the current real-language model</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4631" target="_blank">01:17:11.920</a></span> | <span class="t">for training method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4632" target="_blank">01:17:12.920</a></span> | <span class="t">because we need the text image or text video pairs to train.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4637" target="_blank">01:17:17.920</a></span> | <span class="t">And we actually did not use any self-supervised learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4646" target="_blank">01:17:26.280</a></span> | <span class="t">in the image or video.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4650" target="_blank">01:17:30.320</a></span> | <span class="t">So we cannot learn any knowledge from pure video or image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4657" target="_blank">01:17:37.680</a></span> | <span class="t">We actually deal with unnoticed data from a human side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4662" target="_blank">01:17:42.680</a></span> | <span class="t">So if you want to understand better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4672" target="_blank">01:17:52.240</a></span> | <span class="t">of the physical world using unnoticed videos,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4676" target="_blank">01:17:56.680</a></span> | <span class="t">we need to find some new method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4681" target="_blank">01:18:01.320</a></span> | <span class="t">for self-supervised learning or training method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4684" target="_blank">01:18:04.640</a></span> | <span class="t">Yeah, this is a very good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4688" target="_blank">01:18:08.200</a></span> | <span class="t">This is a very good question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4689" target="_blank">01:18:09.280</a></span> | <span class="t">Thank you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4690" target="_blank">01:18:10.120</a></span> | <span class="t">- Right, okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4692" target="_blank">01:18:12.880</a></span> | <span class="t">A couple more questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4694" target="_blank">01:18:14.120</a></span> | <span class="t">Someone is asking,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4697" target="_blank">01:18:17.320</a></span> | <span class="t">are there VQA tasks that involve multiple turns</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4700" target="_blank">01:18:20.440</a></span> | <span class="t">of conversation in a tree structure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4703" target="_blank">01:18:23.880</a></span> | <span class="t">similar to a tree of thoughts or beam search style?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4707" target="_blank">01:18:27.520</a></span> | <span class="t">- Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4710" target="_blank">01:18:30.400</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4711" target="_blank">01:18:31.240</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4713" target="_blank">01:18:33.920</a></span> | <span class="t">Maybe, but I still think it's different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4718" target="_blank">01:18:38.520</a></span> | <span class="t">and the tree of thoughts could be better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4722" target="_blank">01:18:42.560</a></span> | <span class="t">because it's aware of other mass information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4727" target="_blank">01:18:47.560</a></span> | <span class="t">For example, the wrong path,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4733" target="_blank">01:18:53.560</a></span> | <span class="t">the other failed case, something like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4741" target="_blank">01:19:01.960</a></span> | <span class="t">My experience is if you can include all the contacts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4746" target="_blank">01:19:06.960</a></span> | <span class="t">in your input, you always get better results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4753" target="_blank">01:19:13.600</a></span> | <span class="t">So yeah, maybe either tree of thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4760" target="_blank">01:19:20.000</a></span> | <span class="t">or some other different process procedure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4766" target="_blank">01:19:26.080</a></span> | <span class="t">and some other information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4769" target="_blank">01:19:29.960</a></span> | <span class="t">you just include them into the contents.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4773" target="_blank">01:19:33.080</a></span> | <span class="t">The language model will learn how to deal with them</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4777" target="_blank">01:19:37.040</a></span> | <span class="t">and understand better than the beam search,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4779" target="_blank">01:19:39.400</a></span> | <span class="t">which is actually a hard-code method</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4782" target="_blank">01:19:42.160</a></span> | <span class="t">to compare the probabilities.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4785" target="_blank">01:19:45.960</a></span> | <span class="t">It should be better if you do it right, yes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4790" target="_blank">01:19:50.960</a></span> | <span class="t">- Right, thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4792" target="_blank">01:19:52.120</a></span> | <span class="t">That's all the time we have for questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4793" target="_blank">01:19:53.840</a></span> | <span class="t">So thanks again to Ming for the great talk,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4796" target="_blank">01:19:56.240</a></span> | <span class="t">the detailed answers to all the questions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=cYfKQ6YG9Qo&t=4798" target="_blank">01:19:58.320</a></span> | <span class="t">[BLANK_AUDIO]</span></div></div></body></html>