<html><head><title>ModernBERT: Modern Bidirectional Encoder for Fast,Efficient, and Long Context Finetuning + Inference</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 95%;  /* Increased width to use more space */
        margin: auto;
        overflow: auto;  /* Added to handle overflow by adding a scrollbar if necessary */
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;  /* Ensure text alignment is consistent */
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>ModernBERT: Modern Bidirectional Encoder for Fast,Efficient, and Long Context Finetuning + Inference</h2><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo"><img src="https://i.ytimg.com/vi/GvMcxuVkcEo/maxresdefault.jpg" style="width:50%;"></a><div><br></div><div style="text-align: left;"><a href="./GvMcxuVkcEo.html">Whisper Transcript</a> | <a href="./transcript_GvMcxuVkcEo.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">then you can have, I don't know, a full piece of code rather than just one token at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=7" target="_blank">00:00:07.280</a></span> | <span class="t">So I think that was one of the biggest things because it doesn't surpass.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=13" target="_blank">00:00:13.000</a></span> | <span class="t">So for example, in speed, it doesn't surpass one of the base BERT, but in everything else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=20" target="_blank">00:00:20.400</a></span> | <span class="t">it surpasses every other model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=22" target="_blank">00:00:22.400</a></span> | <span class="t">So I think that was one of the key highlights for me.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=27" target="_blank">00:00:27.080</a></span> | <span class="t">I'm still trying to figure out where the code data is mentioned.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=32" target="_blank">00:00:32.840</a></span> | <span class="t">I know I read it inside of here, but I don't know where it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=37" target="_blank">00:00:37.840</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=38" target="_blank">00:00:38.840</a></span> | <span class="t">It should be very useful for code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=41" target="_blank">00:00:41.360</a></span> | <span class="t">Oh, yeah, there we go.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=45" target="_blank">00:00:45.160</a></span> | <span class="t">Here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=46" target="_blank">00:00:46.160</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=47" target="_blank">00:00:47.160</a></span> | <span class="t">Well, anything else that we should cover at a high level?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=50" target="_blank">00:00:50.400</a></span> | <span class="t">Otherwise, we should, I don't know, go through them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=55" target="_blank">00:00:55.760</a></span> | <span class="t">I'm relatively, this is relatively because we didn't appoint someone to lead this discussion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=62" target="_blank">00:01:02.240</a></span> | <span class="t">and I'm not ready to lead this discussion.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=66" target="_blank">00:01:06.560</a></span> | <span class="t">But I would say on my end, I think training it on two trillion tokens, like basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=74" target="_blank">00:01:14.720</a></span> | <span class="t">kind of updating every dimension of normal BERT into 2025 BERT, which I think was the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=82" target="_blank">00:01:22.060</a></span> | <span class="t">original name, makes sense, including these kind of alternating global local attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=90" target="_blank">00:01:30.760</a></span> | <span class="t">is something that is like very, very state of the art that I was only seeing in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=97" target="_blank">00:01:37.840</a></span> | <span class="t">of the papers, including at Character AI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=100" target="_blank">00:01:40.200</a></span> | <span class="t">And it's very surprising to see this applied to BERT.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=103" target="_blank">00:01:43.960</a></span> | <span class="t">But I felt like it was very well written in terms of the justification of how much these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=110" target="_blank">00:01:50.320</a></span> | <span class="t">things are downloaded and how they deserve to be updated, because they actually much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=117" target="_blank">00:01:57.160</a></span> | <span class="t">more efficient compared to other models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=121" target="_blank">00:02:01.240</a></span> | <span class="t">And that just makes a lot of sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=125" target="_blank">00:02:05.480</a></span> | <span class="t">One thing that I was, I've never understood in a lot of clarity is why the bidirectional</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=133" target="_blank">00:02:13.480</a></span> | <span class="t">encoder is so much more efficient than a causal decoder only model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=144" target="_blank">00:02:24.780</a></span> | <span class="t">I mean, I don't know if anyone can, it's probably well known, but I don't, I never understood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=151" target="_blank">00:02:31.440</a></span> | <span class="t">that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=152" target="_blank">00:02:32.440</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=153" target="_blank">00:02:33.440</a></span> | <span class="t">I mean, this is where if Ben is available to speak, he can probably be authoritative.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=160" target="_blank">00:02:40.860</a></span> | <span class="t">To me, it's just like, if you're literally like, the only reason you do decoder only</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=165" target="_blank">00:02:45.460</a></span> | <span class="t">is to generate the next token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=168" target="_blank">00:02:48.080</a></span> | <span class="t">That is what is very, very good at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=170" target="_blank">00:02:50.300</a></span> | <span class="t">But if your job is to fill in the middle or to do classification, then you might as well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=176" target="_blank">00:02:56.140</a></span> | <span class="t">look at the whole sentence all at once.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=180" target="_blank">00:03:00.140</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=181" target="_blank">00:03:01.140</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=182" target="_blank">00:03:02.140</a></span> | <span class="t">That's sort of, that's kind of what I suspected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=188" target="_blank">00:03:08.060</a></span> | <span class="t">Yeah, I feel like, I don't know, I don't know if there's anyone else has stuff they want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=194" target="_blank">00:03:14.380</a></span> | <span class="t">to add there, but yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=197" target="_blank">00:03:17.980</a></span> | <span class="t">If I may put in my two cents, the other advantage with encoder models is richness of information</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=205" target="_blank">00:03:25.980</a></span> | <span class="t">because you're not just attending to previous tokens, but every token's encoding is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=212" target="_blank">00:03:32.660</a></span> | <span class="t">to be based both on past and future tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=215" target="_blank">00:03:35.820</a></span> | <span class="t">So if you have some token that's making a future reference, it's not very common, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=222" target="_blank">00:03:42.180</a></span> | <span class="t">sometimes you get an adjective for some kind of reference to a future token that hasn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=226" target="_blank">00:03:46.420</a></span> | <span class="t">come yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=228" target="_blank">00:03:48.260</a></span> | <span class="t">Autoregressive models don't get a chance to encode that information because they haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=231" target="_blank">00:03:51.940</a></span> | <span class="t">seen that future token yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=234" target="_blank">00:03:54.620</a></span> | <span class="t">It's fine when you just need to predict the next token.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=238" target="_blank">00:03:58.940</a></span> | <span class="t">Probably the next token's encoding is going to try to reflect that information.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=243" target="_blank">00:04:03.300</a></span> | <span class="t">But when you're doing stuff like classification, like NER, named entity recognition, or you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=248" target="_blank">00:04:08.300</a></span> | <span class="t">doing sentiment analysis, you want that entire spectrum of information of both past and future</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=253" target="_blank">00:04:13.620</a></span> | <span class="t">tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=254" target="_blank">00:04:14.620</a></span> | <span class="t">Right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=255" target="_blank">00:04:15.620</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=256" target="_blank">00:04:16.620</a></span> | <span class="t">So the bidirectionality is what you're saying, basically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=262" target="_blank">00:04:22.140</a></span> | <span class="t">Yeah, exactly.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=263" target="_blank">00:04:23.900</a></span> | <span class="t">I think maybe if I were to play devil's advocate and disagree here, it would basically be that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=272" target="_blank">00:04:32.140</a></span> | <span class="t">there's no time to think, there's no chain of thought.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=274" target="_blank">00:04:34.860</a></span> | <span class="t">You just have to run attention on it, and then immediately come up with a classification</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=281" target="_blank">00:04:41.260</a></span> | <span class="t">or an answer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=282" target="_blank">00:04:42.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=283" target="_blank">00:04:43.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=284" target="_blank">00:04:44.260</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=285" target="_blank">00:04:45.260</a></span> | <span class="t">You sort of have less bandwidth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=286" target="_blank">00:04:46.260</a></span> | <span class="t">You have to encode all of the information and de-embedding and go from there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=292" target="_blank">00:04:52.900</a></span> | <span class="t">The chat is blowing up.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=294" target="_blank">00:04:54.780</a></span> | <span class="t">Steve, you want to...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=296" target="_blank">00:04:56.740</a></span> | <span class="t">What is this?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=297" target="_blank">00:04:57.740</a></span> | <span class="t">What's going on?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=299" target="_blank">00:04:59.420</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=300" target="_blank">00:05:00.420</a></span> | <span class="t">Who has questions or objectives they want to mention?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=305" target="_blank">00:05:05.460</a></span> | <span class="t">I have a question for Swix.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=310" target="_blank">00:05:10.260</a></span> | <span class="t">You spoke with the guys at Windsurf and they said that they were doing work on a retrieval</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=317" target="_blank">00:05:17.060</a></span> | <span class="t">model or at least a way of implementing retrieval so that it would get the right code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=323" target="_blank">00:05:23.860</a></span> | <span class="t">Do you know if they were training their own embedding model, and if so, how does it compare?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=327" target="_blank">00:05:27.540</a></span> | <span class="t">And if not, how does this model come into play?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=334" target="_blank">00:05:34.140</a></span> | <span class="t">I wouldn't be...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=335" target="_blank">00:05:35.140</a></span> | <span class="t">I would completely not be surprised if they were training their own model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=338" target="_blank">00:05:38.780</a></span> | <span class="t">I don't think they actually confirmed that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=341" target="_blank">00:05:41.900</a></span> | <span class="t">They said they were working on retrieval, but I don't know if they said it was their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=344" target="_blank">00:05:44.780</a></span> | <span class="t">own model or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=346" target="_blank">00:05:46.260</a></span> | <span class="t">I don't think it matters to them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=349" target="_blank">00:05:49.240</a></span> | <span class="t">They do train models for fun.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=350" target="_blank">00:05:50.960</a></span> | <span class="t">This is not one of those heavy blips for them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=354" target="_blank">00:05:54.100</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=355" target="_blank">00:05:55.100</a></span> | <span class="t">The beauty of these smaller models is that it's relatively cheap.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=367" target="_blank">00:06:07.500</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=371" target="_blank">00:06:11.260</a></span> | <span class="t">I'm just throwing questions out here, but does anyone know of...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=377" target="_blank">00:06:17.580</a></span> | <span class="t">Do you necessarily... would this embedding model be actually useful for, for example,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=383" target="_blank">00:06:23.700</a></span> | <span class="t">encoding a text description of a function and then retrieving that function, assuming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=390" target="_blank">00:06:30.580</a></span> | <span class="t">that it's also embedded?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=392" target="_blank">00:06:32.540</a></span> | <span class="t">Basically, RAG based on the actual text description versus the function itself.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=399" target="_blank">00:06:39.300</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=400" target="_blank">00:06:40.300</a></span> | <span class="t">I'm not sure if I'm...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=403" target="_blank">00:06:43.900</a></span> | <span class="t">They did put details in the paper about their...</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=408" target="_blank">00:06:48.900</a></span> | <span class="t">I think the level of detail that they put on the training and the testing, the evaluation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=413" target="_blank">00:06:53.940</a></span> | <span class="t">was actually really good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=414" target="_blank">00:06:54.940</a></span> | <span class="t">So, for example, in the training piece, instead of using 15% of masking, they used 30%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=421" target="_blank">00:07:01.660</a></span> | <span class="t">They used the warmup was very detailed.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=424" target="_blank">00:07:04.660</a></span> | <span class="t">They started with a 3 billion warmup and then increasing, and then they kept the learning</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=431" target="_blank">00:07:11.180</a></span> | <span class="t">rate constant, and then if they will see kind of like a plateau, then they will go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=436" target="_blank">00:07:16.900</a></span> | <span class="t">and adjust it, but just towards the very end of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=439" target="_blank">00:07:19.460</a></span> | <span class="t">Also, it was actually quite interesting that a lot of this stuff, they tested it in a RTX</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=446" target="_blank">00:07:26.180</a></span> | <span class="t">or 4090.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=447" target="_blank">00:07:27.780</a></span> | <span class="t">I did some fine tuning and I have an RTX 2008 version, which is similar to the 3000 versions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=456" target="_blank">00:07:36.460</a></span> | <span class="t">and it took about give or take 40 minutes to fine tune it on a 200,000 sample data set.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=464" target="_blank">00:07:44.820</a></span> | <span class="t">So, that was quite interesting, and I think the level of detail in the training was incredible,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=473" target="_blank">00:07:53.460</a></span> | <span class="t">and also in the evaluation piece, they do answer your question with the coding data</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=478" target="_blank">00:07:58.900</a></span> | <span class="t">set that they used to test it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=482" target="_blank">00:08:02.500</a></span> | <span class="t">Yeah, that's interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=487" target="_blank">00:08:07.940</a></span> | <span class="t">Okay, I have no idea how to guide this one, especially because normally I would try to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=505" target="_blank">00:08:25.900</a></span> | <span class="t">prep a slide deck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=508" target="_blank">00:08:28.180</a></span> | <span class="t">I have been too busy to do a slide deck.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=511" target="_blank">00:08:31.860</a></span> | <span class="t">But does anyone else have like a thing that they want to show that I can give you the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=518" target="_blank">00:08:38.100</a></span> | <span class="t">screen for?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=519" target="_blank">00:08:39.100</a></span> | <span class="t">I did take a bunch of notes on the paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=522" target="_blank">00:08:42.460</a></span> | <span class="t">If you want me, I can take it over and like walk through the notes that I took.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=529" target="_blank">00:08:49.700</a></span> | <span class="t">Go ahead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=532" target="_blank">00:08:52.860</a></span> | <span class="t">One second.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=536" target="_blank">00:08:56.020</a></span> | <span class="t">I did add the Nomec tuned version of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=541" target="_blank">00:09:01.180</a></span> | <span class="t">Basically, Nomec just added their Nomec data set and created Embed ModernBird, something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=547" target="_blank">00:09:07.020</a></span> | <span class="t">like that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=548" target="_blank">00:09:08.620</a></span> | <span class="t">And that was a useful, like something that you can start using for RAG, whereas ModernBird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=554" target="_blank">00:09:14.540</a></span> | <span class="t">was kind of like the baseline.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=559" target="_blank">00:09:19.500</a></span> | <span class="t">I try to use it a little bit in a data set that I don't think was very well represented</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=565" target="_blank">00:09:25.780</a></span> | <span class="t">in the data set that they use, and it wasn't that good, the use case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=569" target="_blank">00:09:29.940</a></span> | <span class="t">It was with a law-specific one, trying to detect the type of legal case that was in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=579" target="_blank">00:09:39.940</a></span> | <span class="t">the document.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=580" target="_blank">00:09:40.940</a></span> | <span class="t">And then it didn't really do very well until I fine-tuned it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=584" target="_blank">00:09:44.140</a></span> | <span class="t">So it's really good off the bat, but for some use cases, you might want to fine-tune it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=587" target="_blank">00:09:47.540</a></span> | <span class="t">and go out a little bit further.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=589" target="_blank">00:09:49.540</a></span> | <span class="t">Okay, so I took a few notes and I highlighted the things that I thought that they were quite</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=595" target="_blank">00:09:55.140</a></span> | <span class="t">useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=596" target="_blank">00:09:56.140</a></span> | <span class="t">So I'm just going to run through them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=597" target="_blank">00:09:57.140</a></span> | <span class="t">And if anybody has any questions, I might be able to answer them, I hope.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=600" target="_blank">00:10:00.900</a></span> | <span class="t">I might not.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=601" target="_blank">00:10:01.900</a></span> | <span class="t">I hope I am.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=603" target="_blank">00:10:03.900</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=604" target="_blank">00:10:04.900</a></span> | <span class="t">So I think I mentioned this a second ago that one of the coolest pieces is that this can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=612" target="_blank">00:10:12.100</a></span> | <span class="t">extract a lot of power from a single GPU, or you can do a lot with a single GPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=618" target="_blank">00:10:18.600</a></span> | <span class="t">That's something that I personally prefer if I have the ability to do so, but I know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=622" target="_blank">00:10:22.540</a></span> | <span class="t">that we all know that a lot of times you just need a much more powerful one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=628" target="_blank">00:10:28.740</a></span> | <span class="t">So they call it the most speed and memory efficient encoder and designed for inference</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=636" target="_blank">00:10:36.700</a></span> | <span class="t">on common GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=640" target="_blank">00:10:40.540</a></span> | <span class="t">They point out a couple of nice things regarding the drawbacks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=645" target="_blank">00:10:45.620</a></span> | <span class="t">So previous birds had a length limitation of about 512 tokens, which is so optimal for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=656" target="_blank">00:10:56.860</a></span> | <span class="t">model design, but then they increase in this one the vocabulary to 8,100 and something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=664" target="_blank">00:11:04.500</a></span> | <span class="t">And the nice thing about it is that they did it in a way in which they could parallelize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=670" target="_blank">00:11:10.300</a></span> | <span class="t">it nicely across the couple of GPUs that they used for training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=682" target="_blank">00:11:22.620</a></span> | <span class="t">So this might -- so they can be used in training in conjunction with LLMs, for example, detecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=687" target="_blank">00:11:27.500</a></span> | <span class="t">toxic prompts and preventing responses on routing queries in agentic frameworks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=693" target="_blank">00:11:33.380</a></span> | <span class="t">I added here that this might not be super obvious for new AI engineers that have worked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=697" target="_blank">00:11:37.660</a></span> | <span class="t">on decoder-only models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=698" target="_blank">00:11:38.900</a></span> | <span class="t">So you might want to have in a pipeline a smaller model, like a bird, like detecting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=704" target="_blank">00:11:44.860</a></span> | <span class="t">specific words, specific keywords, and then use that to say, like, oh, is there toxic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=709" target="_blank">00:11:49.860</a></span> | <span class="t">language in this prompt?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=712" target="_blank">00:11:52.020</a></span> | <span class="t">Or is there toxic language in this response back to the user?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=716" target="_blank">00:11:56.220</a></span> | <span class="t">And so you can have a pre and post LLM generation in an agentic framework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=724" target="_blank">00:12:04.480</a></span> | <span class="t">So the training data is limited in narrow domains and specifically in coding data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=730" target="_blank">00:12:10.140</a></span> | <span class="t">So lacking knowledge of recent events.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=732" target="_blank">00:12:12.180</a></span> | <span class="t">So it was quite nice to see that kind of like a new, refreshed look as to what bird could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=739" target="_blank">00:12:19.380</a></span> | <span class="t">be.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=741" target="_blank">00:12:21.900</a></span> | <span class="t">And then so overall -- both of them reach overall performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=746" target="_blank">00:12:26.580</a></span> | <span class="t">You saw the image that Strix show in the screen.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=752" target="_blank">00:12:32.180</a></span> | <span class="t">Even the transformer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=753" target="_blank">00:12:33.880</a></span> | <span class="t">They disabled the bias term in all the layers, except the final decoder and in the layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=760" target="_blank">00:12:40.140</a></span> | <span class="t">norm.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=761" target="_blank">00:12:41.140</a></span> | <span class="t">I keep hitting the ones that I -- sorry about that, Iro.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=766" target="_blank">00:12:46.480</a></span> | <span class="t">>> Weights are all you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=767" target="_blank">00:12:47.980</a></span> | <span class="t">>> Sorry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=768" target="_blank">00:12:48.980</a></span> | <span class="t">>> Weights are all you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=769" target="_blank">00:12:49.980</a></span> | <span class="t">>> Sorry?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=770" target="_blank">00:12:50.980</a></span> | <span class="t">>> Weights are all you need.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=771" target="_blank">00:12:51.980</a></span> | <span class="t">No biases.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=772" target="_blank">00:12:52.980</a></span> | <span class="t">>> So yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=773" target="_blank">00:12:53.980</a></span> | <span class="t">So they took the biases from the -- so they disabled the bias in all linear layers except</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=785" target="_blank">00:13:05.080</a></span> | <span class="t">for the final decoder linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=788" target="_blank">00:13:08.400</a></span> | <span class="t">And then they also disabled the bias in the layer norms.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=792" target="_blank">00:13:12.440</a></span> | <span class="t">So I thought that was quite interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=794" target="_blank">00:13:14.760</a></span> | <span class="t">And then they also used positional Rotary -- Rotary positional embeddings, Rope, instead</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=801" target="_blank">00:13:21.680</a></span> | <span class="t">of the absolute positional embeddings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=803" target="_blank">00:13:23.480</a></span> | <span class="t">So one of the things that was interesting about this paper is that a lot of the stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=806" target="_blank">00:13:26.820</a></span> | <span class="t">that they included inside the paper or for the -- for creating Modern Burn are based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=812" target="_blank">00:13:32.560</a></span> | <span class="t">on papers that come -- that all came out in 2024.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=816" target="_blank">00:13:36.880</a></span> | <span class="t">I was about to start counting like how many were there from 2024, but I think the final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=821" target="_blank">00:13:41.880</a></span> | <span class="t">number is actually quite large.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=824" target="_blank">00:13:44.200</a></span> | <span class="t">Which is nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=825" target="_blank">00:13:45.200</a></span> | <span class="t">A couple of things in the improvements.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=828" target="_blank">00:13:48.280</a></span> | <span class="t">So in alternating attention -- so the attention layers in Modern Burn alternate between global,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=834" target="_blank">00:13:54.200</a></span> | <span class="t">where every token within a sequence attends to every other token, and then local attention</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=838" target="_blank">00:13:58.960</a></span> | <span class="t">where tokens only attend to each other within a small sliding window.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=844" target="_blank">00:14:04.560</a></span> | <span class="t">So every layer employs a global attention with a Rope of 160 and remaining layers use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=851" target="_blank">00:14:11.760</a></span> | <span class="t">about 128 tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=853" target="_blank">00:14:13.920</a></span> | <span class="t">Global sliding window attention Rope of theta of 10,000.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=858" target="_blank">00:14:18.360</a></span> | <span class="t">I feel like if somebody else here knows a little bit more about exactly what this means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=863" target="_blank">00:14:23.200</a></span> | <span class="t">in much simpler terms, that would be super useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=865" target="_blank">00:14:25.720</a></span> | <span class="t">Because I was trying to wrap my head around exactly how does this look like in the implementation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=872" target="_blank">00:14:32.080</a></span> | <span class="t">piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=873" target="_blank">00:14:33.080</a></span> | <span class="t">But I guess it's more a matter of going into the code and seeing exactly how this gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=878" target="_blank">00:14:38.360</a></span> | <span class="t">implemented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=883" target="_blank">00:14:43.720</a></span> | <span class="t">Something interesting as well is that it unpads inputs before the token embedding layer and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=888" target="_blank">00:14:48.880</a></span> | <span class="t">optionally repads the model outputs, leading to a 10 to 20% performance improvement over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=893" target="_blank">00:14:53.920</a></span> | <span class="t">other unpadding methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=899" target="_blank">00:14:59.480</a></span> | <span class="t">Also uses a mixture of FlashAttention3 for global attention layers and FlashAttention2</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=906" target="_blank">00:15:06.760</a></span> | <span class="t">for local attention layers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=908" target="_blank">00:15:08.820</a></span> | <span class="t">I believe in the latest version of the transformers, the FlashAttention3 has not yet been implemented.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=914" target="_blank">00:15:14.400</a></span> | <span class="t">So if you go to the repo, you're gonna end up seeing that it says, hey, if you're gonna</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=918" target="_blank">00:15:18.640</a></span> | <span class="t">be using Attention3, make sure you pip install from the URL directly to the latest git commit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=924" target="_blank">00:15:24.220</a></span> | <span class="t">on the main branch rather than the latest version available in PyPI.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=931" target="_blank">00:15:31.120</a></span> | <span class="t">So that yields a Torch compile, yielded a 10% improvement in throughput with negable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=941" target="_blank">00:15:41.480</a></span> | <span class="t">compilation overhead.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=942" target="_blank">00:15:42.480</a></span> | <span class="t">Which I thought it was interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=945" target="_blank">00:15:45.520</a></span> | <span class="t">And so, I mentioned this one about the design through -- so, it was designed through many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=954" target="_blank">00:15:54.320</a></span> | <span class="t">small scale ablations to maximize the utilization of basket -- of a basket of common GPUs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=960" target="_blank">00:16:00.720</a></span> | <span class="t">I think if you are new today, or if you haven't read -- if you haven't worked as a data scientist,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=966" target="_blank">00:16:06.480</a></span> | <span class="t">but maybe you don't read a whole lot of research papers, you might actually not know what ablation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=970" target="_blank">00:16:10.560</a></span> | <span class="t">is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=971" target="_blank">00:16:11.560</a></span> | <span class="t">I had to Google it as well, even though I've read a few, but it just wasn't in my head.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=976" target="_blank">00:16:16.020</a></span> | <span class="t">So ablation studies, they are experiments where research is systematically removed or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=983" target="_blank">00:16:23.400</a></span> | <span class="t">ablate certain components of a model or system to understand their individual impact on performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=990" target="_blank">00:16:30.480</a></span> | <span class="t">It is a kind of like a control experiment when you're creating an architecture.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=995" target="_blank">00:16:35.160</a></span> | <span class="t">So the reason I mention that is because you're going to see the word "ablation" thrown in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=999" target="_blank">00:16:39.880</a></span> | <span class="t">in a lot of places.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1000" target="_blank">00:16:40.880</a></span> | <span class="t">And just assume that you know it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1003" target="_blank">00:16:43.160</a></span> | <span class="t">And I'm sure a lot of people here probably know it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1006" target="_blank">00:16:46.980</a></span> | <span class="t">So it uses 22 and 28 layers for the base and large model for a total of 149 to 395 million,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1016" target="_blank">00:16:56.840</a></span> | <span class="t">respectively.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1017" target="_blank">00:16:57.840</a></span> | <span class="t">And then the base one has a hidden size of 768, with a GLU expansion of 230, 2304, while</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1027" target="_blank">00:17:07.840</a></span> | <span class="t">the large one has a size of 1024, and a GLU expansion of 5248.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1039" target="_blank">00:17:19.200</a></span> | <span class="t">There's two trillion tokens of primarily English data on a variety of data sources, including</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1043" target="_blank">00:17:23.720</a></span> | <span class="t">web documents code and scientific literature.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1046" target="_blank">00:17:26.360</a></span> | <span class="t">So I don't know -- I don't remember seeing if there was a direct link to the dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1052" target="_blank">00:17:32.720</a></span> | <span class="t">that they used.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1053" target="_blank">00:17:33.720</a></span> | <span class="t">But it is open data, though.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1055" target="_blank">00:17:35.720</a></span> | <span class="t">And they're very explicit about it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1057" target="_blank">00:17:37.880</a></span> | <span class="t">They say that they use a modified version of OMO tokenizer, which provides a better</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1062" target="_blank">00:17:42.440</a></span> | <span class="t">token efficiency and performance on code-related tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1066" target="_blank">00:17:46.320</a></span> | <span class="t">So this adds to the -- to being good with coding -- with coding files in general.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1077" target="_blank">00:17:57.540</a></span> | <span class="t">And then it's nice that it keeps the same thing that we are used to seeing in encoder</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1084" target="_blank">00:18:04.080</a></span> | <span class="t">models like Verge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1085" target="_blank">00:18:05.080</a></span> | <span class="t">The last token being the CLS or the CEP, so you can play around with these ones.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1095" target="_blank">00:18:15.260</a></span> | <span class="t">So I mentioned this earlier at the very beginning, that apparently it was very common to use</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1099" target="_blank">00:18:19.800</a></span> | <span class="t">15% of masking when you are doing the training.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1102" target="_blank">00:18:22.640</a></span> | <span class="t">But then this one bumps it up to 30%.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1105" target="_blank">00:18:25.200</a></span> | <span class="t">They said that the 15% one has -- since the first paper has been shown to be suboptimal.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1114" target="_blank">00:18:34.460</a></span> | <span class="t">And then -- oh, a couple of things that -- about the training set that I thought were interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1120" target="_blank">00:18:40.120</a></span> | <span class="t">So they started with a warmup rate of -- so actually they -- so they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1125" target="_blank">00:18:45.020</a></span> | <span class="t">trained Motherbird Base at a constant learning rate of 0.004 for -- about -- sorry, 0.008</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1136" target="_blank">00:18:56.000</a></span> | <span class="t">for about 1.7 trillion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1137" target="_blank">00:18:57.860</a></span> | <span class="t">But they started with a 3 billion token warmup first.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1141" target="_blank">00:19:01.960</a></span> | <span class="t">And then after 2 billion token warmup, they trained Motherbird Large at a learning rate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1146" target="_blank">00:19:06.760</a></span> | <span class="t">of a smaller precision for 900 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1152" target="_blank">00:19:12.200</a></span> | <span class="t">So then they roll back and restarted the training at 0.000005 for the remaining 800 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1160" target="_blank">00:19:20.120</a></span> | <span class="t">tokens after -- if they will see a large loss plateau for 100 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1168" target="_blank">00:19:28.120</a></span> | <span class="t">So the batch size schedule, they warm up the batch size from 768 to 4680, over 50 billion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1180" target="_blank">00:19:40.880</a></span> | <span class="t">tokens, and from 448 to 4928, over 10 billion tokens.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1190" target="_blank">00:19:50.000</a></span> | <span class="t">And they talk a little bit how they do the context length extension.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1198" target="_blank">00:19:58.880</a></span> | <span class="t">And it's quite nice that they use -- they took this idea from two papers that were released</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1205" target="_blank">00:20:05.120</a></span> | <span class="t">on -- in this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1210" target="_blank">00:20:10.780</a></span> | <span class="t">Also in the text retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1212" target="_blank">00:20:12.520</a></span> | <span class="t">So I think this might address a little bit Sebastian's question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1219" target="_blank">00:20:19.520</a></span> | <span class="t">So they evaluate the model on both single vector dense passage retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1223" target="_blank">00:20:23.480</a></span> | <span class="t">So the entire document put into a -- into a dense -- into a vector.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1228" target="_blank">00:20:28.440</a></span> | <span class="t">And then setting the -- and then they also use -- they set the multi-vector covert setting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1235" target="_blank">00:20:35.280</a></span> | <span class="t">as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1236" target="_blank">00:20:36.680</a></span> | <span class="t">So they use different methodologies to evaluate it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1240" target="_blank">00:20:40.120</a></span> | <span class="t">In some of them, they retrieve documents completely using -- and add them in the context of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1248" target="_blank">00:20:48.440</a></span> | <span class="t">evaluation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1249" target="_blank">00:20:49.440</a></span> | <span class="t">And then in others, they will have chunks of a piece of text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1254" target="_blank">00:20:54.440</a></span> | <span class="t">And then they train every base model using the MS Marco and data set which mine -- with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1265" target="_blank">00:21:05.120</a></span> | <span class="t">mine hard negatives on 125 million samples with a batch size of 16, a learning rate and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1271" target="_blank">00:21:11.200</a></span> | <span class="t">warm up of 5% of the training using the sentence transformers.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1276" target="_blank">00:21:16.120</a></span> | <span class="t">So it's nice that you still see sentence transformers, like, still rocking it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1281" target="_blank">00:21:21.240</a></span> | <span class="t">They adapt the training set up to Jack covert 2.5, which was also part of a paper shown</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1288" target="_blank">00:21:28.960</a></span> | <span class="t">this year.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1289" target="_blank">00:21:29.960</a></span> | <span class="t">And then they train all the models distilling the knowledge from a teacher model using KL</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1294" target="_blank">00:21:34.480</a></span> | <span class="t">divergence between the normalized teacher and the student scores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1297" target="_blank">00:21:37.960</a></span> | <span class="t">They say -- okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1299" target="_blank">00:21:39.720</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1300" target="_blank">00:21:40.720</a></span> | <span class="t">Here it is.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1301" target="_blank">00:21:41.720</a></span> | <span class="t">So this is the results for all the models in the different evaluators that they use.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1310" target="_blank">00:21:50.800</a></span> | <span class="t">You can see here at the bottom that the base method is better in this particular one, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1320" target="_blank">00:22:00.360</a></span> | <span class="t">you still have better ones, the GT and the MLM are a little bit better in these two over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1324" target="_blank">00:22:04.600</a></span> | <span class="t">here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1325" target="_blank">00:22:05.600</a></span> | <span class="t">>> Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1326" target="_blank">00:22:06.600</a></span> | <span class="t">On this table of results, what's really exceptional is that if you adopt -- if you look at COBEAR</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1333" target="_blank">00:22:13.320</a></span> | <span class="t">versus dense passive retrieval on the multilingual long document retrieval, MLDR, you look at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1341" target="_blank">00:22:21.120</a></span> | <span class="t">the jump in performance.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1343" target="_blank">00:22:23.760</a></span> | <span class="t">It's huge.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1344" target="_blank">00:22:24.760</a></span> | <span class="t">For ModernBird, it's like 27.4 to 80.2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1348" target="_blank">00:22:28.360</a></span> | <span class="t">But for Bayer, I think it's benchmarking IR, the jump is not that big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1354" target="_blank">00:22:34.280</a></span> | <span class="t">So it seems like as your context length gets longer, doing a COBEAR-based approach really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1359" target="_blank">00:22:39.880</a></span> | <span class="t">gets you a lot more juice out of it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1361" target="_blank">00:22:41.280</a></span> | <span class="t">Of course, a lot more costs, but a lot more metrics, a lot more improved metrics.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1367" target="_blank">00:22:47.680</a></span> | <span class="t">>> Which one is the COBEAR approach?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1371" target="_blank">00:22:51.880</a></span> | <span class="t">>> You can see that there are eight columns of results, right?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1376" target="_blank">00:22:56.240</a></span> | <span class="t">The first three columns are dense passive retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1378" target="_blank">00:22:58.280</a></span> | <span class="t">The next two columns are COBEAR.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1380" target="_blank">00:23:00.680</a></span> | <span class="t">>> Thanks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1381" target="_blank">00:23:01.680</a></span> | <span class="t">>> Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1382" target="_blank">00:23:02.680</a></span> | <span class="t">And then what you probably want to compare is basically on the same benchmarks, BIR to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1387" target="_blank">00:23:07.760</a></span> | <span class="t">COBEAR, BEIR to BEIR, and MLDR out of domain to MLDR out of domain to see the comparison.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1397" target="_blank">00:23:17.480</a></span> | <span class="t">>> Yeah, that's a huge win.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1404" target="_blank">00:23:24.440</a></span> | <span class="t">>> Yeah, huge win.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1408" target="_blank">00:23:28.440</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1409" target="_blank">00:23:29.440</a></span> | <span class="t">So there's a couple more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1413" target="_blank">00:23:33.280</a></span> | <span class="t">There's a few -- there's another one as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1415" target="_blank">00:23:35.600</a></span> | <span class="t">Well, actually, let me -- let me see if I have something here for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1421" target="_blank">00:23:41.720</a></span> | <span class="t">So to mention the programming-related performance, they evaluated all models in the code search</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1426" target="_blank">00:23:46.080</a></span> | <span class="t">net.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1427" target="_blank">00:23:47.080</a></span> | <span class="t">So this is related to Sebastian's question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1429" target="_blank">00:23:49.800</a></span> | <span class="t">So a code-to-text benchmark where the model must identify relevant docstrings and comments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1436" target="_blank">00:23:56.360</a></span> | <span class="t">for code blocks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1437" target="_blank">00:23:57.360</a></span> | <span class="t">So actually, it's identifying the docstring as opposed to the code itself, but it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1441" target="_blank">00:24:01.840</a></span> | <span class="t">be useful still in finding a piece of content if you're doing information retrieval.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1449" target="_blank">00:24:09.680</a></span> | <span class="t">But it might be tricky if -- because especially nowadays, like, I don't know about everyone</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1454" target="_blank">00:24:14.540</a></span> | <span class="t">here in the call, I don't particularly -- I add comments.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1458" target="_blank">00:24:18.800</a></span> | <span class="t">I add docstrings inside functions, but I don't go to a massive degree -- to a massive length</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1465" target="_blank">00:24:25.600</a></span> | <span class="t">to add a lot of comments or a lot of doc -- like a giant docstring.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1469" target="_blank">00:24:29.800</a></span> | <span class="t">But for example, scikit-learn has probably the absolute best docstrings out there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1474" target="_blank">00:24:34.760</a></span> | <span class="t">NumPy and pandas and so on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1476" target="_blank">00:24:36.600</a></span> | <span class="t">If you were looking for functions inside of those, I can imagine that that's an easy one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1480" target="_blank">00:24:40.120</a></span> | <span class="t">or that's an easy win for it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1481" target="_blank">00:24:41.640</a></span> | <span class="t">But if you -- more recent tools, I can imagine that it might not see the same extensive docstring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1491" target="_blank">00:24:51.800</a></span> | <span class="t">in one of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1495" target="_blank">00:24:55.160</a></span> | <span class="t">They evaluated the benchmarks using co-IR and code-IR frameworks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1501" target="_blank">00:25:01.840</a></span> | <span class="t">So a single vector retrieval task.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1504" target="_blank">00:25:04.600</a></span> | <span class="t">And all of the models are reusing the best hyperparameters identified in section 3.1.2.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1514" target="_blank">00:25:14.960</a></span> | <span class="t">And then so here they have the -- this is related to memory.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1519" target="_blank">00:25:19.120</a></span> | <span class="t">So here they have memory batch size and inference in thousands of tokens per second, efficiency</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1524" target="_blank">00:25:24.240</a></span> | <span class="t">results in the consumer hardware GPU and RTX 4090, and average of the over ten run -- ten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1532" target="_blank">00:25:32.480</a></span> | <span class="t">runs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1533" target="_blank">00:25:33.480</a></span> | <span class="t">I don't know if anybody has any comments on this particular one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1539" target="_blank">00:25:39.280</a></span> | <span class="t">>> Yeah, I was actually kind of curious about what you were talking about the -- what is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1549" target="_blank">00:25:49.160</a></span> | <span class="t">it, CDN, they call it?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1551" target="_blank">00:25:51.720</a></span> | <span class="t">The data sets for evaluating code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1554" target="_blank">00:25:54.280</a></span> | <span class="t">Is that like -- is it normally evaluated that way?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1557" target="_blank">00:25:57.960</a></span> | <span class="t">By encoding the code and then trying to retrieve the correct docstring?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1563" target="_blank">00:26:03.560</a></span> | <span class="t">Is this like the normal benchmark that's used against encoders?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1566" target="_blank">00:26:06.320</a></span> | <span class="t">>> That is a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1569" target="_blank">00:26:09.960</a></span> | <span class="t">I have no idea.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1570" target="_blank">00:26:10.960</a></span> | <span class="t">>> I was under the impression it's the other way around.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1577" target="_blank">00:26:17.360</a></span> | <span class="t">>> You know, this would be a good thing for illicit or deep research.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1581" target="_blank">00:26:21.600</a></span> | <span class="t">I'm going to see if I can find that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1584" target="_blank">00:26:24.600</a></span> | <span class="t">>> Yeah, but that's a great question.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1589" target="_blank">00:26:29.280</a></span> | <span class="t">Maybe we have someone for any of the -- from cursor in this call or from any of the major</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1596" target="_blank">00:26:36.240</a></span> | <span class="t">IDEs that can say how they're doing it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1599" target="_blank">00:26:39.920</a></span> | <span class="t">We'll keep it a secret.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1605" target="_blank">00:26:45.920</a></span> | <span class="t">>> Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1606" target="_blank">00:26:46.920</a></span> | <span class="t">So the Motherbird large increases its lead despite having comparatively fewer parameters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1614" target="_blank">00:26:54.080</a></span> | <span class="t">So from 395 million to GT and MLM's large 435.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1621" target="_blank">00:27:01.700</a></span> | <span class="t">So that's nice being able to do a little bit more with less.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1626" target="_blank">00:27:06.400</a></span> | <span class="t">Then the Motherbird outperforms other long context models with at least a 9NDCG at ten</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1635" target="_blank">00:27:15.600</a></span> | <span class="t">points lead on both model sizes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1638" target="_blank">00:27:18.040</a></span> | <span class="t">I was a little bit -- a little bit thrown about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1641" target="_blank">00:27:21.240</a></span> | <span class="t">Like I didn't really get this and I had to reread this piece.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1644" target="_blank">00:27:24.880</a></span> | <span class="t">So what it essentially means is -- and then it also surpasses all existing base models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1656" target="_blank">00:27:36.040</a></span> | <span class="t">including DBERTA V3, becoming the first MLM trained model to do so, apparently, DBERTA</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1663" target="_blank">00:27:43.920</a></span> | <span class="t">V3 base was unbeaten in this -- in the glue benchmark.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1674" target="_blank">00:27:54.040</a></span> | <span class="t">And then it improved understanding of code at no detriment of its ability to process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1679" target="_blank">00:27:59.080</a></span> | <span class="t">natural text.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1680" target="_blank">00:28:00.080</a></span> | <span class="t">So it's nice.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1681" target="_blank">00:28:01.400</a></span> | <span class="t">You often see models that if they have been too fine tuned on code or too -- or they have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1687" target="_blank">00:28:07.520</a></span> | <span class="t">a large emphasis on code, that they don't perform that well on any other common natural</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1692" target="_blank">00:28:12.400</a></span> | <span class="t">language tasks.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1699" target="_blank">00:28:19.440</a></span> | <span class="t">And then so for the evaluation setting, so it is able to process batches twice as large</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1707" target="_blank">00:28:27.800</a></span> | <span class="t">as every other model, but on both input -- on both input length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1713" target="_blank">00:28:33.200</a></span> | <span class="t">But Motherbird is slightly less memory efficient than the original BERT, large on short context</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1719" target="_blank">00:28:39.360</a></span> | <span class="t">inputs.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1720" target="_blank">00:28:40.360</a></span> | <span class="t">So we talk about 500 and something.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1725" target="_blank">00:28:45.520</a></span> | <span class="t">But it can still process batches at least 60% bigger on the other one.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1729" target="_blank">00:28:49.720</a></span> | <span class="t">So it's just like one tiny piece or one small piece where it doesn't beat every single -- that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1736" target="_blank">00:28:56.640</a></span> | <span class="t">makes it so that it doesn't beat every single model at every single -- in every single characteristic.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1742" target="_blank">00:29:02.400</a></span> | <span class="t">But other than that, almost in every measure, it goes above all the other models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1750" target="_blank">00:29:10.940</a></span> | <span class="t">It is the first -- the first open model to feature an entire model on padding, and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1757" target="_blank">00:29:17.400</a></span> | <span class="t">is the first encoder designed in a hardware-aware way to maximize inference efficiency.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1764" target="_blank">00:29:24.720</a></span> | <span class="t">It is in a class-of-its-own encode and Colbert-style long context retrieval benchmark, scoring</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1770" target="_blank">00:29:30.820</a></span> | <span class="t">at least 6.85 and 9.1% points higher than the closest model, respectively, while remaining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1778" target="_blank">00:29:38.400</a></span> | <span class="t">state-of-the-art on short context retrieval in both single and multivector settings.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1784" target="_blank">00:29:44.160</a></span> | <span class="t">And -- oh, I thought that was interesting, that it says that the MLM objective gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1791" target="_blank">00:29:51.440</a></span> | <span class="t">the model some ability to generate text by suggesting a given token to replace the mask</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1797" target="_blank">00:29:57.160</a></span> | <span class="t">token, which could result in generation of harmful content.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1802" target="_blank">00:30:02.200</a></span> | <span class="t">They do say here that, however, it is not primarily a generative model, and as such,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1807" target="_blank">00:30:07.760</a></span> | <span class="t">it has not been trained to and therefore cannot generate a long context sequence, so it might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1812" target="_blank">00:30:12.040</a></span> | <span class="t">predict the next mask and so on in specific ways, but it's not like it's gonna go and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1817" target="_blank">00:30:17.600</a></span> | <span class="t">tell you or just cossign you in length.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1821" target="_blank">00:30:21.760</a></span> | <span class="t">It might say something harmful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1825" target="_blank">00:30:25.400</a></span> | <span class="t">In terms of the scaling, besides the architectural modifications, a key aspect of the study is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1831" target="_blank">00:30:31.040</a></span> | <span class="t">data scaling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1832" target="_blank">00:30:32.360</a></span> | <span class="t">However, other scaling access they note in terms of parameter are still left unexplored,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1839" target="_blank">00:30:39.200</a></span> | <span class="t">so there's -- so what the authors, I think, are saying here is that there's a lot of room</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1843" target="_blank">00:30:43.240</a></span> | <span class="t">for improvement, even if this is a large bump in improvement already.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1848" target="_blank">00:30:48.920</a></span> | <span class="t">And I think that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1850" target="_blank">00:30:50.920</a></span> | <span class="t">That's all, like, the highlights that I put when I was going over it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1854" target="_blank">00:30:54.740</a></span> | <span class="t">If anybody else has another comment or wants to touch on something else.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1865" target="_blank">00:31:05.480</a></span> | <span class="t">>> I think one thing the authors did that's implicit is compare it only against the BERT</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1871" target="_blank">00:31:11.960</a></span> | <span class="t">models rather than comparing it against the other, like, collection of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1876" target="_blank">00:31:16.360</a></span> | <span class="t">I mean, certainly sizes are different if you were to go on, like, the MTB leaderboard and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1882" target="_blank">00:31:22.640</a></span> | <span class="t">look at them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1884" target="_blank">00:31:24.080</a></span> | <span class="t">Yeah, I was somewhat surprised whenever I started to read into it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1889" target="_blank">00:31:29.200</a></span> | <span class="t">I thought there might be some mention of the other encoding models that are out there,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1894" target="_blank">00:31:34.040</a></span> | <span class="t">but that wasn't the case.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1897" target="_blank">00:31:37.000</a></span> | <span class="t">>> Yeah, there's a lot of variations of BERT, so I can imagine they pick -- they only pick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1905" target="_blank">00:31:45.680</a></span> | <span class="t">a selected few for specific reasons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1907" target="_blank">00:31:47.240</a></span> | <span class="t">They do mention in the paper why they pick a couple of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1911" target="_blank">00:31:51.400</a></span> | <span class="t">So the BERT or the Roberta and also obviously the base BERT, but they definitely could have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1923" target="_blank">00:32:03.560</a></span> | <span class="t">gone or maybe just left it for the reader to do a bit more testing and put stuff out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1929" target="_blank">00:32:09.160</a></span> | <span class="t">there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1932" target="_blank">00:32:12.160</a></span> | <span class="t">>> Sorry, I didn't -- your audio cut out for a bit.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1946" target="_blank">00:32:26.880</a></span> | <span class="t">I didn't hear what you said.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1947" target="_blank">00:32:27.880</a></span> | <span class="t">>> Oh, sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1948" target="_blank">00:32:28.880</a></span> | <span class="t">I was saying that I appreciate that you put the NDCG explainer there, the link.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1954" target="_blank">00:32:34.580</a></span> | <span class="t">>> It's a ranking similarity thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1957" target="_blank">00:32:37.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1958" target="_blank">00:32:38.120</a></span> | <span class="t">Yeah.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1959" target="_blank">00:32:39.120</a></span> | <span class="t">I just -- I feel like they could just say ranking score and then, you know, footnote</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1963" target="_blank">00:32:43.400</a></span> | <span class="t">NDCG, but it's the same thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1966" target="_blank">00:32:46.400</a></span> | <span class="t">It's always hard to remember all these things when you have -- you don't live in this world</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1970" target="_blank">00:32:50.840</a></span> | <span class="t">all the time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1973" target="_blank">00:32:53.320</a></span> | <span class="t">Yep.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1974" target="_blank">00:32:54.600</a></span> | <span class="t">I think we have Benjamin who said that he wanted to talk after we finish recording.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1982" target="_blank">00:33:02.720</a></span> | <span class="t">I really recommend reading the blog post.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1985" target="_blank">00:33:05.840</a></span> | <span class="t">That was very much more my level.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1989" target="_blank">00:33:09.440</a></span> | <span class="t">I don't really get involved in the training side.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1991" target="_blank">00:33:11.320</a></span> | <span class="t">I just want to see -- understand what I need to know as a user of the thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1996" target="_blank">00:33:16.040</a></span> | <span class="t">And then potentially as a fine tuner, you know, for stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=1999" target="_blank">00:33:19.280</a></span> | <span class="t">So but I think like a very major advance, I think it's going to be a workhorse tool.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2004" target="_blank">00:33:24.640</a></span> | <span class="t">So like I think multiple of us picked this last week and for good reason.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2008" target="_blank">00:33:28.520</a></span> | <span class="t">So I think we're happy to cut over to the offline part of the Convo, unless anyone else</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2014" target="_blank">00:33:34.120</a></span> | <span class="t">has things to share.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2016" target="_blank">00:33:36.600</a></span> | <span class="t">No?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2017" target="_blank">00:33:37.600</a></span> | <span class="t">Okay.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2018" target="_blank">00:33:38.600</a></span> | <span class="t">All right.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=GvMcxuVkcEo&t=2019" target="_blank">00:33:39.600</a></span> | <span class="t">I will pause recording and then Ben, Benjamin, you can come up.</span></div></div></body></html>