<html><head><title>Lesson 9: Cutting Edge Deep Learning for Coders</title>
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
        color: #333;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    h2, h3 {
        color: #333;
        text-align: center;
    }
    a {
        color: #0000FF;  /* Traditional blue color for links */
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        display: block;
        margin: auto;
        max-width: 100%;
    }
    .c {
        margin: 10px 0;
    }
    .s, .t {
        display: inline-block;
        margin-right: 5px;
    }
    .max-width {
        max-width: 800px;
        margin: auto;
        padding-left: 20px;
    }
    table {
        width: 100%;
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid #ddd;
        padding: 8px;
    }
    tr:nth-child(even) {
        background-color: #f2f2f2;
    }
    tr:nth-child(odd) {
        background-color: #e6e6e6;
    }
</style>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-69VLBMTTP0"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-69VLBMTTP0');
    </script>
    </head><body><div class='container'><a href="index.html">back to index</a><h2>Lesson 9: Cutting Edge Deep Learning for Coders</h2><a href="https://www.youtube.com/watch?v=I-P363wSv0Q"><img src="https://i.ytimg.com/vi_webp/I-P363wSv0Q/maxresdefault.webp" style="width:50%;"></a><div><br></div><h3>Chapters</h3><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=0">0:0</a> Intro<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=27">0:27</a> Wiki<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=205">3:25</a> Style Transfer<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=625">10:25</a> Reading the Paper<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=900">15:0</a> Notation<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1275">21:15</a> Citations<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1835">30:35</a> Super Resolution<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1985">33:5</a> Paper<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2380">39:40</a> Big holes arrays<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2445">40:45</a> The final network<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2590">43:10</a> Practical considerations<br><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3128">52:8</a> Deconvolution<br><br><div style="text-align: left;"><a href="./I-P363wSv0Q.html">Whisper Transcript</a> | <a href="./transcript_I-P363wSv0Q.html">Transcript Only Page</a></div><br><div style="max-width: 800px;"><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=0" target="_blank">00:00:00.000</a></span> | <span class="t">So, welcome back everybody. Thanks for coming and I hope you had a good week and had a fun</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5" target="_blank">00:00:05.260</a></span> | <span class="t">time playing around with artistic style. I know I did. I thought I'd show you. So I tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=15" target="_blank">00:00:15.000</a></span> | <span class="t">a couple of things myself over the week with this artistic style stuff. I've just tried</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=21" target="_blank">00:00:21.060</a></span> | <span class="t">a couple of simple little changes which I thought you might be interested in.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=26" target="_blank">00:00:26.000</a></span> | <span class="t">One thing before I talk about the artistic style is I just wanted to point out some of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=34" target="_blank">00:00:34.040</a></span> | <span class="t">the really cool stuff that people have been contributing over the week. If you haven't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=40" target="_blank">00:00:40.080</a></span> | <span class="t">come across it yet, be sure to check out the wiki. There's a nice thing in Discourse where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=47" target="_blank">00:00:47.640</a></span> | <span class="t">you can basically set any post as being a wiki, which means that anybody can edit it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=52" target="_blank">00:00:52.440</a></span> | <span class="t">So I created this wiki post early on, and by the end of the week we now have all kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=57" target="_blank">00:00:57.080</a></span> | <span class="t">of stuff with links to the stuff from the class, a summary of the paper, examples, a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=65" target="_blank">00:01:05.480</a></span> | <span class="t">list of all the links, both snippets, a handy list of steps that are necessary when you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=75" target="_blank">00:01:15.080</a></span> | <span class="t">doing style transfer, lots of stuff about the TensorFlow Dead Summit, and so forth. Lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=86" target="_blank">00:01:26.360</a></span> | <span class="t">of other threads. One I saw just this afternoon popped up, which was Greg from XinXin, talked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=96" target="_blank">00:01:36.640</a></span> | <span class="t">about trying to summarize what they've learned from lots of other threads across the forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=104" target="_blank">00:01:44.880</a></span> | <span class="t">This is a great thing that we can all do is when you look at lots of different things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=110" target="_blank">00:01:50.760</a></span> | <span class="t">and take some notes, if you put them on the forum for everybody else, this is super handy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=115" target="_blank">00:01:55.960</a></span> | <span class="t">So if you haven't quite caught up on all the stuff going on in the forum, looking at this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=120" target="_blank">00:02:00.240</a></span> | <span class="t">curating lesson 8 experiments thread would be probably a good place to start.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=127" target="_blank">00:02:07.200</a></span> | <span class="t">So a couple of little changes I made in my experiments. I tried thinking about how depending</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=136" target="_blank">00:02:16.360</a></span> | <span class="t">on what your starting point is for your optimizer, you get to a very different place. And so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=142" target="_blank">00:02:22.240</a></span> | <span class="t">clearly our convex optimization is not necessarily finding a local minimum, but at least saddle</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=148" target="_blank">00:02:28.920</a></span> | <span class="t">points it's not getting out of. So I tried something which was to take the random image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=155" target="_blank">00:02:35.560</a></span> | <span class="t">and just add a Gaussian blur to it. So that makes a random image into this kind of thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=163" target="_blank">00:02:43.280</a></span> | <span class="t">And I just found that even the plain style looked a lot smoother, so that was one change</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=169" target="_blank">00:02:49.140</a></span> | <span class="t">that I made which I thought worked quite well. Another change that I made just to play around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=174" target="_blank">00:02:54.040</a></span> | <span class="t">with it was that I added a different weight to each of the style layers. And so my zip</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=181" target="_blank">00:03:01.920</a></span> | <span class="t">now has a third thing in which is the weights, and I just multiply by the weight. So I thought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=187" target="_blank">00:03:07.000</a></span> | <span class="t">that those two things made my little bird look significantly better than my little bird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=191" target="_blank">00:03:11.440</a></span> | <span class="t">looked before, so I was happy with that. You could do a similar thing for content loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=196" target="_blank">00:03:16.320</a></span> | <span class="t">You could also maybe add more different layers of content loss and give them different weights</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=201" target="_blank">00:03:21.200</a></span> | <span class="t">as well. I'm not sure if anybody's tried that yet. Yes, Rachel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=212" target="_blank">00:03:32.360</a></span> | <span class="t">I have a question in regards to style transfer for cartoons. With cartoons, when we think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=217" target="_blank">00:03:37.560</a></span> | <span class="t">of transferring the style, what we really mean is transferring the contours of the cartoon</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=222" target="_blank">00:03:42.440</a></span> | <span class="t">to redraw the content in that style. This is not what style transferring is doing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=227" target="_blank">00:03:47.720</a></span> | <span class="t">How might I implement this? I don't know that anybody has quite figured that out, but I'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=233" target="_blank">00:03:53.080</a></span> | <span class="t">show you a couple of directions that may be useful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=236" target="_blank">00:03:56.600</a></span> | <span class="t">I've tried selecting activations that correspond with edges, and such is indicated by one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=244" target="_blank">00:04:04.040</a></span> | <span class="t">the calm visualization papers and comparing outputs from specifically those activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=250" target="_blank">00:04:10.760</a></span> | <span class="t">So I'll show you some things you could try. I haven't seen anybody do a great job of this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=255" target="_blank">00:04:15.520</a></span> | <span class="t">yet, but here's one example from the forum. Somebody pointed out that this cartoon approach</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=261" target="_blank">00:04:21.840</a></span> | <span class="t">didn't work very well with Dr. Seuss, but then when they changed their initial image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=266" target="_blank">00:04:26.760</a></span> | <span class="t">not to be random but to be the picture of the dog, it actually looked quite a lot better.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=270" target="_blank">00:04:30.800</a></span> | <span class="t">So there's one thing you could try. There's some very helpful diagrams that somebody posted</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=276" target="_blank">00:04:36.000</a></span> | <span class="t">which is fantastic. I like this summary of what happens if you add versus remove each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=285" target="_blank">00:04:45.400</a></span> | <span class="t">layer. So this is what happens if you remove block 0, block 1, block 2, block 3, and block</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=293" target="_blank">00:04:53.360</a></span> | <span class="t">4 to get a sense of how they impact things. You can see for the style that the last layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=298" target="_blank">00:04:58.560</a></span> | <span class="t">is really important to making it look good, at least for this image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=306" target="_blank">00:05:06.880</a></span> | <span class="t">One of you had some particularly nice examples. It seems like there's a certain taste. They're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=313" target="_blank">00:05:13.200</a></span> | <span class="t">kind of figuring out what photos go with what images. I thought this Einstein was terrific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=317" target="_blank">00:05:17.680</a></span> | <span class="t">I thought this was terrific as well. Brad came up with this really interesting insight</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=325" target="_blank">00:05:25.320</a></span> | <span class="t">that starting with this picture and adding a style to it creates this extraordinary shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=332" target="_blank">00:05:32.160</a></span> | <span class="t">here where, as he points out, you can tell it's a man sitting in the corner, but there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=336" target="_blank">00:05:36.360</a></span> | <span class="t">less than 10 brush strips. Sometimes this style transfer does things which are surprisingly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=342" target="_blank">00:05:42.660</a></span> | <span class="t">fantastic. I have no idea what this is even in the photos, so I don't know what it is in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=347" target="_blank">00:05:47.740</a></span> | <span class="t">the painting either. I guess I don't watch that kind of music enough.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=353" target="_blank">00:05:53.360</a></span> | <span class="t">So there's lots of interesting ideas you can try, and I've got a link here, and you might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=358" target="_blank">00:05:58.480</a></span> | <span class="t">have seen it in the PowerPoint, to a Keras implementation that has a whole list of things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=363" target="_blank">00:06:03.120</a></span> | <span class="t">that you can try. Here are some particular examples. All of these examples you can get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=372" target="_blank">00:06:12.640</a></span> | <span class="t">the details from this link. There's something called chain blurring. For some things, this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=379" target="_blank">00:06:19.160</a></span> | <span class="t">might work well for cartoons. Notice how the matrix doesn't do a good job with the cat</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=385" target="_blank">00:06:25.440</a></span> | <span class="t">when you use the classic This Is Our Paper. But if you use this chain blurring approach,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=391" target="_blank">00:06:31.720</a></span> | <span class="t">it does a fantastic job. So I wonder if that might be one secret to the cartoons.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=398" target="_blank">00:06:38.720</a></span> | <span class="t">Some of you I saw in the forum have already tried this, which is using color preservation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=402" target="_blank">00:06:42.420</a></span> | <span class="t">and luminance matching, which basically means you're still taking the style but you're not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=407" target="_blank">00:06:47.560</a></span> | <span class="t">taking the color. And I think in these particular examples, this is really great results. I think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=413" target="_blank">00:06:53.080</a></span> | <span class="t">it depends a lot on what things you tried with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=417" target="_blank">00:06:57.720</a></span> | <span class="t">You can go a lot further. For example, you can add a mask and then say just do color</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=423" target="_blank">00:07:03.880</a></span> | <span class="t">preservation for one part of the photo. So here the top part of the photo has got color</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=428" target="_blank">00:07:08.080</a></span> | <span class="t">preservation and the bottom hasn't. They even show in that code how you can use a mask to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=437" target="_blank">00:07:17.920</a></span> | <span class="t">say one part of my image should not be stylized. This is really crazy. Use masks to decide</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=449" target="_blank">00:07:29.240</a></span> | <span class="t">which one of two style images to use and then you can really generate some creative stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=454" target="_blank">00:07:34.320</a></span> | <span class="t">So there's a lot of stuff that you can play with and you can go beyond this to coming</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=458" target="_blank">00:07:38.120</a></span> | <span class="t">up with your own ideas.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=460" target="_blank">00:07:40.740</a></span> | <span class="t">Now some of the best stuff, you're going to learn a bit more today about how to do some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=464" target="_blank">00:07:44.560</a></span> | <span class="t">of these things better. But just to give an idea, if you go to likemo.net, you can literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=470" target="_blank">00:07:50.360</a></span> | <span class="t">draw something using four colors and then choose a style image and it will turn your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=477" target="_blank">00:07:57.520</a></span> | <span class="t">drawing into an image. Basically the idea is blue is going to be water and green is going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=482" target="_blank">00:08:02.760</a></span> | <span class="t">to be foliage and I guess red is going to be foreground. There's a lot of good examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=490" target="_blank">00:08:10.920</a></span> | <span class="t">of this kind of neural doodle they call it online.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=496" target="_blank">00:08:16.600</a></span> | <span class="t">Something else we'll learn more about how to do better today is if you go to affinelayer.com,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=501" target="_blank">00:08:21.240</a></span> | <span class="t">there's a very recent paper called Pics2Pics. We're going to be learning quite a bit in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=506" target="_blank">00:08:26.320</a></span> | <span class="t">this class about how to do segmentation, which is where you take a photo and turn it into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=511" target="_blank">00:08:31.560</a></span> | <span class="t">a colored image, basically saying the horse is here, the bicycle is here, the person is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=515" target="_blank">00:08:35.640</a></span> | <span class="t">here. This is basically doing the opposite. You start by drawing something, saying I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=520" target="_blank">00:08:40.440</a></span> | <span class="t">you to create something that has a window here and a window still here and a draw here</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=524" target="_blank">00:08:44.880</a></span> | <span class="t">and a column there, and it generates a photo, which is fairly remarkable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=531" target="_blank">00:08:51.840</a></span> | <span class="t">So the stuff we've learned so far won't quite get you to do these two things, but by the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=535" target="_blank">00:08:55.800</a></span> | <span class="t">end of today we should be able to. This is a nice example that I think some folks at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=542" target="_blank">00:09:02.760</a></span> | <span class="t">Adobe built showing that you could basically draw something and it would try and generate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=549" target="_blank">00:09:09.080</a></span> | <span class="t">an image that was close to your drawing where you just needed a small number of lines. Again</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=554" target="_blank">00:09:14.000</a></span> | <span class="t">we'll link to this paper from the resources. This actually shows it to you in real time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=561" target="_blank">00:09:21.400</a></span> | <span class="t">You can see that there's some new way of doing art that's starting to appear where you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=567" target="_blank">00:09:27.680</a></span> | <span class="t">necessarily need a whole lot of technique. I'm not promising it's going to turn you into</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=572" target="_blank">00:09:32.240</a></span> | <span class="t">a Van Gogh, but you can at least generate images that maybe are in your head in some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=576" target="_blank">00:09:36.000</a></span> | <span class="t">style that's somewhat similar to somebody else's. I think it's really interesting.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=585" target="_blank">00:09:45.880</a></span> | <span class="t">One thing I was thrilled to see is that at least two of you have already written blog</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=591" target="_blank">00:09:51.080</a></span> | <span class="t">posts on Medium. That was fantastic to see. So I hope more of you might try to do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=596" target="_blank">00:09:56.720</a></span> | <span class="t">this week. It definitely doesn't need to be something that takes a long time. I know some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=603" target="_blank">00:10:03.880</a></span> | <span class="t">of you are also planning on turning your forum posts into blog posts, so hopefully we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=609" target="_blank">00:10:09.400</a></span> | <span class="t">see a lot more blog posts this week popping up. I know the people who have done that have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=614" target="_blank">00:10:14.320</a></span> | <span class="t">found that a useful experience as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=619" target="_blank">00:10:19.240</a></span> | <span class="t">One of the things that I suggested doing pretty high on the list of priorities for this week's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=624" target="_blank">00:10:24.420</a></span> | <span class="t">assignment was to go through the paper knowing what it's going to say. I think this is really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=632" target="_blank">00:10:32.000</a></span> | <span class="t">helpful is when you already know how to do something is to go back over that paper, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=637" target="_blank">00:10:37.120</a></span> | <span class="t">this is a great way to learn how to read papers. You already know what it's telling you. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=641" target="_blank">00:10:41.440</a></span> | <span class="t">is like the way I learnt to read papers was totally this method.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=647" target="_blank">00:10:47.800</a></span> | <span class="t">So I've gone through and I've highlighted a few key things which as I went through I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=652" target="_blank">00:10:52.720</a></span> | <span class="t">thought were kind of important. In the abstract of the paper, let me ask, how many people</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=659" target="_blank">00:10:59.480</a></span> | <span class="t">kind of went back and relooked at this paper again? Quite a few of you, that's great. In</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=668" target="_blank">00:11:08.520</a></span> | <span class="t">the abstract, they basically say what is it that they're introducing. It's a system based</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=672" target="_blank">00:11:12.040</a></span> | <span class="t">on a deep neural network that creates artistic images of higher perceptual quality. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=676" target="_blank">00:11:16.440</a></span> | <span class="t">going to read this paper and hopefully at the end of it we'll know how to do that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=680" target="_blank">00:11:20.360</a></span> | <span class="t">Then in the first section, they tell us about the basic ideas. When CNNs are trained on</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=687" target="_blank">00:11:27.960</a></span> | <span class="t">object recognition, they developed a representation of an image. Along the processing hierarchy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=694" target="_blank">00:11:34.000</a></span> | <span class="t">of the network, it's transformed into representations that increasingly care about the actual content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=698" target="_blank">00:11:38.480</a></span> | <span class="t">compared to the pixel values. So it describes the basic idea of content loss. Then they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=706" target="_blank">00:11:46.360</a></span> | <span class="t">describe the basic idea of style loss, which is looking at the correlations between the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=712" target="_blank">00:11:52.120</a></span> | <span class="t">different filter responses over the spatial extent of the feature maps. This is one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=716" target="_blank">00:11:56.640</a></span> | <span class="t">these sentences that read on its own doesn't mean very much, but now that you know how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=721" target="_blank">00:12:01.560</a></span> | <span class="t">to do it, you can read it and you can see what that means, and then when you get to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=725" target="_blank">00:12:05.960</a></span> | <span class="t">the methods section, we learn more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=729" target="_blank">00:12:09.080</a></span> | <span class="t">So the idea here is that by including the feature correlations, and this answers one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=733" target="_blank">00:12:13.160</a></span> | <span class="t">of the questions that one of you had on the forum, by including feature correlations of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=736" target="_blank">00:12:16.640</a></span> | <span class="t">multiple layers, we obtain a multi-scale representation of the input image. This idea of a multi-scale</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=743" target="_blank">00:12:23.440</a></span> | <span class="t">representation is something we're going to be coming across a lot because a lot of this,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=748" target="_blank">00:12:28.040</a></span> | <span class="t">as we discussed last week, a lot of this class is about generative models. One of the tricky</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=753" target="_blank">00:12:33.600</a></span> | <span class="t">things with generative models is both to get the general idea of the thing you're trying</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=760" target="_blank">00:12:40.000</a></span> | <span class="t">to generate correct, but also get all the details correct. So the details generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=764" target="_blank">00:12:44.760</a></span> | <span class="t">require you to zoom into a small scale, and the big picture correct is about zooming out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=769" target="_blank">00:12:49.840</a></span> | <span class="t">to a large scale.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=771" target="_blank">00:12:51.680</a></span> | <span class="t">So this was one of the key things that they did in this paper was show you how to create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=775" target="_blank">00:12:55.600</a></span> | <span class="t">a style representation that included multiple resolutions. We now know that where they did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=781" target="_blank">00:13:01.360</a></span> | <span class="t">that was to use multiple style layers, and as we go through the layers of VGG, they gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=787" target="_blank">00:13:07.560</a></span> | <span class="t">become lower and lower resolution, larger and larger receptive fields.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=794" target="_blank">00:13:14.720</a></span> | <span class="t">I'm always great to look at the figures and make sure I was thrilled to see that some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=798" target="_blank">00:13:18.240</a></span> | <span class="t">of you were trying to recreate these figures, which actually turned out to be slightly non-trivial.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=805" target="_blank">00:13:25.360</a></span> | <span class="t">So we can see exactly what that figure is, and if you haven't tried it for yourself yet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=811" target="_blank">00:13:31.080</a></span> | <span class="t">you might want to try it, see if you can recreate this figure.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=815" target="_blank">00:13:35.280</a></span> | <span class="t">It's good to try and find in a paper the key thing that they're showing. In this case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=827" target="_blank">00:13:47.760</a></span> | <span class="t">they found that representations of content and style in a CNN are separable, and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=832" target="_blank">00:13:52.400</a></span> | <span class="t">can manipulate both to create new images. So again, hopefully now you can look at that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=838" target="_blank">00:13:58.200</a></span> | <span class="t">and say, Oh yeah, that makes sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=848" target="_blank">00:14:08.600</a></span> | <span class="t">You can see that with papers, certainly with this paper, there's often quite a lot of introduction</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=853" target="_blank">00:14:13.680</a></span> | <span class="t">that often says the same thing a bunch of different ways. The first time you read it,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=860" target="_blank">00:14:20.360</a></span> | <span class="t">one paragraph might not make sense, but later on they say it a different way and it starts</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=864" target="_blank">00:14:24.360</a></span> | <span class="t">to make more sense. So it's worth looking through the introductory remarks, maybe two</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=869" target="_blank">00:14:29.960</a></span> | <span class="t">or three times. They can certainly see that again, talking about the different layers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=876" target="_blank">00:14:36.840</a></span> | <span class="t">and how they behave.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=880" target="_blank">00:14:40.280</a></span> | <span class="t">Again, showing the results of some experiments. Again, you can see if you can recreate these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=889" target="_blank">00:14:49.520</a></span> | <span class="t">experiments, make sure you understand how to do it. And then there's a whole lot of stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=896" target="_blank">00:14:56.320</a></span> | <span class="t">I didn't find that interesting until we get to the section called methods.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=900" target="_blank">00:15:00.400</a></span> | <span class="t">So the method section is the section that hopefully you'll learn the most about reading</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=903" target="_blank">00:15:03.880</a></span> | <span class="t">papers after you've implemented something by reading the section called methods. I want</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=907" target="_blank">00:15:07.920</a></span> | <span class="t">to show you a few little tricks of notation. You do need to be careful of little details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=914" target="_blank">00:15:14.760</a></span> | <span class="t">that fly by. Like here, they used average pooling. That's a sentence which if you weren't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=919" target="_blank">00:15:19.880</a></span> | <span class="t">reading carefully, you could skip over it. We need to use average pooling, not math pooling.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=928" target="_blank">00:15:28.120</a></span> | <span class="t">So they will often have a section which explicitly says, Now I'm going to introduce the notation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=934" target="_blank">00:15:34.320</a></span> | <span class="t">This paper doesn't. This paper just introduces the notation as part of the discussion. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=939" target="_blank">00:15:39.800</a></span> | <span class="t">at some point, you'll start getting Greek letters or things with subscripts or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=946" target="_blank">00:15:46.760</a></span> | <span class="t">Notation starts appearing. And so at this point, you need to start looking very carefully.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=951" target="_blank">00:15:51.620</a></span> | <span class="t">And at least for me, I find I have to go back and read something many times to remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=956" target="_blank">00:15:56.400</a></span> | <span class="t">what's L, what's M, what's N. This is the annoying thing with math notation, is they're single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=962" target="_blank">00:16:02.720</a></span> | <span class="t">letters. They generally don't have any kind of mnemonic. Often though you'll find that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=967" target="_blank">00:16:07.440</a></span> | <span class="t">across papers in a particular field, they'll tend to reuse the same kind of English and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=973" target="_blank">00:16:13.000</a></span> | <span class="t">Greek letters for the same kinds of things. So M will generally be the number of rows,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=978" target="_blank">00:16:18.720</a></span> | <span class="t">capital M. Capital N will often be the number of columns. K will often be the index that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=985" target="_blank">00:16:25.280</a></span> | <span class="t">you're summing over, so on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=989" target="_blank">00:16:29.240</a></span> | <span class="t">So here, the first thing which is introduced is x with an arrow on top. So x with an arrow</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=995" target="_blank">00:16:35.520</a></span> | <span class="t">on top means it's a vector. It's actually an input image, but they're going to turn it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1001" target="_blank">00:16:41.900</a></span> | <span class="t">into a vector by flattening it out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1006" target="_blank">00:16:46.320</a></span> | <span class="t">So our image is called x. And then the CNN has a whole bunch of layers, and every time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1011" target="_blank">00:16:51.800</a></span> | <span class="t">you see something with a subscript or a superscript like this, you need to look at both of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1015" target="_blank">00:16:55.440</a></span> | <span class="t">two bits because they've both got a meaning. The big thing is like the main object. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1021" target="_blank">00:17:01.600</a></span> | <span class="t">in this case, capital N is a filter. And then the subscript or superscript is like in an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1028" target="_blank">00:17:08.160</a></span> | <span class="t">array or a tensor. In Python, it's like the thing in square brackets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1033" target="_blank">00:17:13.560</a></span> | <span class="t">So each filter has a letter l, which is like which number of the filter is it. And so often</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1041" target="_blank">00:17:21.320</a></span> | <span class="t">as I read a paper, I'll actually try to write code as I go and put little comments so that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1047" target="_blank">00:17:27.760</a></span> | <span class="t">I'll write layer, square bracket, layer number, plus square bracket, and then I have a comment</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1053" target="_blank">00:17:33.280</a></span> | <span class="t">after, say, ml, just to remind myself. So I'm creating the code and mapping it to the letters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1060" target="_blank">00:17:40.960</a></span> | <span class="t">So there are nl filters. We know from a CNN that each filter creates a feature map, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1066" target="_blank">00:17:46.600</a></span> | <span class="t">that's why there are nl feature maps. So remember, any time you see the same letter, it means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1071" target="_blank">00:17:51.240</a></span> | <span class="t">the same thing within a paper. Each feature map is of size m, and as I mentioned before,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1080" target="_blank">00:18:00.400</a></span> | <span class="t">m tends to be rows and m tends to be columns. So here it says m is the height times the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1087" target="_blank">00:18:07.720</a></span> | <span class="t">width of the feature map. So here we can see they've gone .flat, basically, to make it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1093" target="_blank">00:18:13.720</a></span> | <span class="t">all 1 row. Now this is another piece of notation you'll see all the time. A layer l can be stored</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1102" target="_blank">00:18:22.200</a></span> | <span class="t">in a matrix called f, and now the l has gone to the top. Same basic idea, just an index.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1109" target="_blank">00:18:29.800</a></span> | <span class="t">So the matrix f is going to contain our activations. And this thing here where it says r with a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1115" target="_blank">00:18:35.920</a></span> | <span class="t">little superscript has a very special meaning. It's referring to basically what is the shape</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1122" target="_blank">00:18:42.560</a></span> | <span class="t">of this. So when you see this shape, it says these are r means that they're floats, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1129" target="_blank">00:18:49.280</a></span> | <span class="t">this thing here means it's a matrix. You can see the x, so it means it's rows by a column.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1133" target="_blank">00:18:53.760</a></span> | <span class="t">So there are n rows and m columns in this matrix, and every matrix, there's one matrix</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1140" target="_blank">00:19:00.680</a></span> | <span class="t">for each layer, and there's a different number of rows and different number of columns for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1144" target="_blank">00:19:04.480</a></span> | <span class="t">each layer. So you can basically go through and map it to the code that you've already</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1149" target="_blank">00:19:09.920</a></span> | <span class="t">written. So I'm not going to read through the whole thing, but there's not very much here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1156" target="_blank">00:19:16.120</a></span> | <span class="t">and it would be good to make sure that you understand all of it, perhaps with the exception</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1161" target="_blank">00:19:21.240</a></span> | <span class="t">of the derivative, because we don't care about derivatives because they get done for us thanks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1165" target="_blank">00:19:25.880</a></span> | <span class="t">to a theano-intensor flow. So you can always skip the bits about derivatives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1176" target="_blank">00:19:36.000</a></span> | <span class="t">So then they do the same thing basically describing the Gram matrix. So they show here that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1183" target="_blank">00:19:43.140</a></span> | <span class="t">basic idea of the Gram matrix is that they create an inner product between the vectorized</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1189" target="_blank">00:19:49.320</a></span> | <span class="t">feature map i and j. So vectorized here means turned into a vector, so the way you turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1195" target="_blank">00:19:55.480</a></span> | <span class="t">a matrix into a vector is flattened. This means the inner product between the flattened feature</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1201" target="_blank">00:20:01.600</a></span> | <span class="t">maps, so those matrices we saw.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1207" target="_blank">00:20:07.640</a></span> | <span class="t">So hopefully you'll find this helpful. You'll see there will be small little differences.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1214" target="_blank">00:20:14.040</a></span> | <span class="t">So rather than taking the mean, they use here the sum, and then they divide back out the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1224" target="_blank">00:20:24.720</a></span> | <span class="t">number of rows and columns to create the mean this way. In our code, we actually put the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1229" target="_blank">00:20:29.980</a></span> | <span class="t">division inside the sum, so you'll see these little differences of how we implement things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1235" target="_blank">00:20:35.280</a></span> | <span class="t">And sometimes you may see actual meaningful differences, and that's often a suggestion</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1241" target="_blank">00:20:41.880</a></span> | <span class="t">of something you can try. So that describes the notation and the method, and that's it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1256" target="_blank">00:20:56.120</a></span> | <span class="t">But then very importantly, any time you come across some concept which you're not familiar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1263" target="_blank">00:21:03.080</a></span> | <span class="t">with, it will pretty much always have a reference, a citation. So you'll see there's little numbers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1275" target="_blank">00:21:15.480</a></span> | <span class="t">all over the place. There's lots of different ways of doing these references. But anytime</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1280" target="_blank">00:21:20.920</a></span> | <span class="t">you come across something which has a citation, like a new piece of notation or a new concept,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1287" target="_blank">00:21:27.360</a></span> | <span class="t">you don't know what it is. Generally the first time I see it in a paper, I ignore it. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1292" target="_blank">00:21:32.640</a></span> | <span class="t">if I keep reading and it turns out to be something that actually is important and I can't understand</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1297" target="_blank">00:21:37.720</a></span> | <span class="t">the basic idea at all, I generally then put this paper aside, I put it in my to-read file,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1304" target="_blank">00:21:44.440</a></span> | <span class="t">and make the new paper I'm reading the thing that it's citing. Because very often a paper</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1309" target="_blank">00:21:49.480</a></span> | <span class="t">is entirely meaningless until you've read one or two of the key papers it's based on.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1316" target="_blank">00:21:56.400</a></span> | <span class="t">Sometimes this can be like reading the dictionary if you don't get low English. It can be layer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1320" target="_blank">00:22:00.440</a></span> | <span class="t">upon layer of citations, and at some point you have to stop. I think you should find</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1328" target="_blank">00:22:08.800</a></span> | <span class="t">that the basic set of papers that things refer to is pretty much all stuff you guys know</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1335" target="_blank">00:22:15.440</a></span> | <span class="t">at this point. So I don't think you're going to get stuck in an infinite loop. But if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1339" target="_blank">00:22:19.360</a></span> | <span class="t">ever do, let us know in the forum and we'll try to help you get unstuck. Or if there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1347" target="_blank">00:22:27.200</a></span> | <span class="t">any notation you don't understand, let us know. In other words, the horrible things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1350" target="_blank">00:22:30.840</a></span> | <span class="t">about math is it's very hard to search for. It's not like you can take that function name</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1355" target="_blank">00:22:35.920</a></span> | <span class="t">and search for Python and the function name instead of some weird squiggly shape. So again,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1361" target="_blank">00:22:41.080</a></span> | <span class="t">feel free to ask if you're not sure about that. There is a great Wikipedia page which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1367" target="_blank">00:22:47.540</a></span> | <span class="t">lists, I think it's just called math notation or something, which lists pretty much every</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1374" target="_blank">00:22:54.440</a></span> | <span class="t">piece of notation. There are various places you can look up notation as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1381" target="_blank">00:23:01.720</a></span> | <span class="t">So that's the paper. Let's move to the next step. So I think what I might do is kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1397" target="_blank">00:23:17.160</a></span> | <span class="t">try and draw the basic idea of what we did before so that I can draw the idea of what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1402" target="_blank">00:23:22.200</a></span> | <span class="t">we're going to do differently this time. So previously, and now this thing is actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1405" target="_blank">00:23:25.920</a></span> | <span class="t">calibrated, we had a random image and we had a loss function. It doesn't matter what the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1418" target="_blank">00:23:38.560</a></span> | <span class="t">loss function was. We know that it happened to be a combination of style_loss plus content_loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1426" target="_blank">00:23:46.400</a></span> | <span class="t">What we did was we took our image, our random image, and we put it through this loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1435" target="_blank">00:23:55.400</a></span> | <span class="t">and we got out of it two things. One was the loss and the other was the gradients. And</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1442" target="_blank">00:24:02.880</a></span> | <span class="t">then we used the gradients with respect to the original pixels to change the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1448" target="_blank">00:24:08.800</a></span> | <span class="t">pixels. So we basically repeated that loop again and again, and the pixels gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1455" target="_blank">00:24:15.400</a></span> | <span class="t">changed to make the loss go down. So that's the basic approach that we just used. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1465" target="_blank">00:24:25.480</a></span> | <span class="t">a perfectly fine approach for what it is. And in fact, if you are wanting to do lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1471" target="_blank">00:24:31.240</a></span> | <span class="t">of different photos with lots of different styles, like if you created a web app where</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1477" target="_blank">00:24:37.320</a></span> | <span class="t">you said please upload any style image and any content image, here's your artistic style</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1483" target="_blank">00:24:43.320</a></span> | <span class="t">version, this is probably still the best, particularly with some of those tweaks I talked about.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1490" target="_blank">00:24:50.400</a></span> | <span class="t">But what if you wanted to create a web app that was a Van Gogh irises generator? Upload</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1497" target="_blank">00:24:57.520</a></span> | <span class="t">any image and I will give you that image in the style of Van Gogh's irises. You can do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1503" target="_blank">00:25:03.720</a></span> | <span class="t">better than this approach, and the reason you can do better is that we can do something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1508" target="_blank">00:25:08.520</a></span> | <span class="t">where you don't have to do a whole optimization run in order to create that output. Instead,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1516" target="_blank">00:25:16.500</a></span> | <span class="t">we can train a CNN to learn to output photos in the style of Van Gogh's irises. The basic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1524" target="_blank">00:25:24.760</a></span> | <span class="t">idea is very similar. What we're going to do this time is we're going to have lots of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1532" target="_blank">00:25:32.040</a></span> | <span class="t">images. We're going to take each image and feed it into the exact same loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1541" target="_blank">00:25:41.980</a></span> | <span class="t">that we used before, with the style loss plus the content loss. For the style loss, we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1550" target="_blank">00:25:50.440</a></span> | <span class="t">going to use Van Gogh's irises, and for the content loss, we're going to use the image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1559" target="_blank">00:25:59.960</a></span> | <span class="t">that we're currently looking at. What we do is rather than changing the pixels of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1569" target="_blank">00:26:09.800</a></span> | <span class="t">original photo, instead what we're going to do is we're going to train a CNN to take this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1580" target="_blank">00:26:20.320</a></span> | <span class="t">out of the way. Let's put a CNN in the middle. These are the layers of the CNN. We're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1603" target="_blank">00:26:43.960</a></span> | <span class="t">to try and get that CNN to spit out a new image. There's an input image and an output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1615" target="_blank">00:26:55.920</a></span> | <span class="t">image. This new CNN we've created is going to spit out an output image that when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1622" target="_blank">00:27:02.400</a></span> | <span class="t">put it through this loss function, hopefully it's going to give a small number. If it gives</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1630" target="_blank">00:27:10.500</a></span> | <span class="t">a small number, it means that the content of this photo still looks like the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1637" target="_blank">00:27:17.520</a></span> | <span class="t">photo's content, and the style of this new image looks like the style of Van Gogh's irises.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1644" target="_blank">00:27:24.520</a></span> | <span class="t">So if you think about it, when you have a CNN, you can really pick any loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1651" target="_blank">00:27:31.720</a></span> | <span class="t">you like. We've tended to use pretty simple loss functions so far like mean squared error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1657" target="_blank">00:27:37.160</a></span> | <span class="t">or cross entropy. In this case, we're going to use a very different loss function which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1663" target="_blank">00:27:43.000</a></span> | <span class="t">is going to be style plus content loss using the same approach that we used just before.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1671" target="_blank">00:27:51.000</a></span> | <span class="t">And because that was generated by a neural net, we know it's differentiable. And you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1676" target="_blank">00:27:56.520</a></span> | <span class="t">can optimize any loss function as long as the loss function is differentiable. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1683" target="_blank">00:28:03.520</a></span> | <span class="t">we now basically take the gradients of this output, not with respect to the input image,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1690" target="_blank">00:28:10.320</a></span> | <span class="t">but with respect to the CNN weights, then we can take those gradients and use them to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1698" target="_blank">00:28:18.600</a></span> | <span class="t">update the weights of the CNN so that the next iteration through the CNN will be slightly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1703" target="_blank">00:28:23.320</a></span> | <span class="t">better at turning that image into a picture that has a good style match with Van Gogh's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1708" target="_blank">00:28:28.880</a></span> | <span class="t">irises. Does that make sense? So at the end of this, we run this through lots of images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1716" target="_blank">00:28:36.560</a></span> | <span class="t">We're just training a regular CNN, and the only thing we've done differently is to replace</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1720" target="_blank">00:28:40.720</a></span> | <span class="t">the loss function with the style_loss plus content_loss that we just used. And so at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1727" target="_blank">00:28:47.080</a></span> | <span class="t">the end of it, we're going to have a CNN that has learnt to take any photo and will spit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1732" target="_blank">00:28:52.720</a></span> | <span class="t">out that photo in the style of Van Gogh's irises. And so this is a win, because it means now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1738" target="_blank">00:28:58.920</a></span> | <span class="t">in your web app, which is your Van Gogh's irises generator, you now don't have to run</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1743" target="_blank">00:29:03.880</a></span> | <span class="t">an optimization path on the new photo, you just do a single forward pass to a CNN, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1749" target="_blank">00:29:09.120</a></span> | <span class="t">is instant. This is going to limit the filters you use, let's say you have Photoshop and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1766" target="_blank">00:29:26.000</a></span> | <span class="t">you want to change multiple styles. Yeah, this is going to do just one type of style.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1775" target="_blank">00:29:35.320</a></span> | <span class="t">Is there a way of combining multiple styles, or is it just going to be a combination of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1781" target="_blank">00:29:41.480</a></span> | <span class="t">all of them? You can combine multiple styles by just having</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1785" target="_blank">00:29:45.960</a></span> | <span class="t">multiple bits of style loss for multiple images, but you're still going to have the problems</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1790" target="_blank">00:29:50.320</a></span> | <span class="t">that that network has only learned to create one kind of image. It may be possible to train</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1801" target="_blank">00:30:01.040</a></span> | <span class="t">it so it takes both a style image and a content image, but I don't think I've seen that done</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1806" target="_blank">00:30:06.360</a></span> | <span class="t">yet. Having said that, there is something simpler</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1821" target="_blank">00:30:21.820</a></span> | <span class="t">and in my opinion more useful we can do, which is rather than doing style loss plus content</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1829" target="_blank">00:30:29.040</a></span> | <span class="t">loss. Let's think of another interesting problem to solve, which is called super resolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1837" target="_blank">00:30:37.320</a></span> | <span class="t">Super resolution is something which, honestly, when Rachel and I started playing around with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1842" target="_blank">00:30:42.200</a></span> | <span class="t">it a while ago, nobody was that interested in it. But in the last year or so it's become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1847" target="_blank">00:30:47.560</a></span> | <span class="t">really hot. So we were kind of playing around with it quite a lot, we thought it was really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1856" target="_blank">00:30:56.120</a></span> | <span class="t">interesting but suddenly it's got hot. The basic idea of super resolution is you start</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1860" target="_blank">00:31:00.900</a></span> | <span class="t">off with a low-res photo. The reason I started getting interested in this was I wanted to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1865" target="_blank">00:31:05.600</a></span> | <span class="t">help my mom take her family photos that were often pretty low quality and blow them up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1872" target="_blank">00:31:12.320</a></span> | <span class="t">into something that was big and high quality that she could print out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1876" target="_blank">00:31:16.520</a></span> | <span class="t">So that's what you do. You try to take something which starts with a small low-res photo and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1883" target="_blank">00:31:23.080</a></span> | <span class="t">turns it into a big high-res photo. Now perhaps you can see that we can use a very similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1896" target="_blank">00:31:36.720</a></span> | <span class="t">technique for this. What we could do is between the low-res photo and the high-res photo,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1915" target="_blank">00:31:55.800</a></span> | <span class="t">we could introduce a CNN. That CNN could look a lot like the CNN from our last idea, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1920" target="_blank">00:32:00.720</a></span> | <span class="t">it's taking in as input a low-res image, and then it's sticking it into a loss function,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1931" target="_blank">00:32:11.240</a></span> | <span class="t">and the loss function is only going to calculate content loss. The content loss it will calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1938" target="_blank">00:32:18.520</a></span> | <span class="t">is between the input that it's got from the low-res after going through the CNN compared</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1944" target="_blank">00:32:24.960</a></span> | <span class="t">to the activations from the high-res. So in other words, has this CNN successfully created</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1953" target="_blank">00:32:33.400</a></span> | <span class="t">a bigger photo that has the same activations as the high-res photo does?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1958" target="_blank">00:32:38.960</a></span> | <span class="t">And so if we pick the right layer for the high-res photo, then that ought to mean that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1963" target="_blank">00:32:43.800</a></span> | <span class="t">we've constructed a new image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1974" target="_blank">00:32:54.960</a></span> | <span class="t">This is one of the things I wanted to talk about today. In fact, I think it's at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1980" target="_blank">00:33:00.600</a></span> | <span class="t">start of the next paper we're going to look at is they even talk about this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1986" target="_blank">00:33:06.760</a></span> | <span class="t">This is the paper we're going to look at today, Perceptual Losses for Real-Time Style Transfer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1990" target="_blank">00:33:10.760</a></span> | <span class="t">and Super Resolutions. This is from 2016. So it took about a year or so to go from the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=1995" target="_blank">00:33:15.560</a></span> | <span class="t">thing we just saw to this next stage. What they point out in the abstract here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2008" target="_blank">00:33:28.520</a></span> | <span class="t">people had done super resolution with CNNs before, but previously the loss function they</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2013" target="_blank">00:33:33.680</a></span> | <span class="t">used was simply the mean-squared error between the pixel outputs of the upscaling network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2020" target="_blank">00:33:40.240</a></span> | <span class="t">and the actual high-res image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2024" target="_blank">00:33:44.020</a></span> | <span class="t">The problem is that it turns out that that tends to create blurry images. It tends to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2029" target="_blank">00:33:49.360</a></span> | <span class="t">create blurry images because the CNN has no reason not to create blurry images. Blurry</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2037" target="_blank">00:33:57.600</a></span> | <span class="t">images actually tend to look pretty good in the loss function because as long as you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2041" target="_blank">00:34:01.440</a></span> | <span class="t">the general, oh this is probably somebody's face, I'll put a face color here, then it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2047" target="_blank">00:34:07.120</a></span> | <span class="t">going to be fine. Whereas if you take the second or third conv block of VGG, then it needs</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2053" target="_blank">00:34:13.800</a></span> | <span class="t">to know that this is an eyeball or it's not going to look good. So if you do it not with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2060" target="_blank">00:34:20.920</a></span> | <span class="t">pixel loss, but with the content loss we just learned about, you're probably going to get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2065" target="_blank">00:34:25.880</a></span> | <span class="t">better results.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2069" target="_blank">00:34:29.520</a></span> | <span class="t">Like many papers in deep learning, this paper introduces its own language. In the language</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2076" target="_blank">00:34:36.120</a></span> | <span class="t">of this paper, perceptual loss is what they call the mean-squared errors between the activations</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2084" target="_blank">00:34:44.040</a></span> | <span class="t">of a network with two images. So the thing we've been calling content loss, they call</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2090" target="_blank">00:34:50.120</a></span> | <span class="t">perceptual loss.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2093" target="_blank">00:34:53.280</a></span> | <span class="t">So one of the nice things they do at the start of this, and I really like it when papers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2097" target="_blank">00:34:57.760</a></span> | <span class="t">do this, is to say why is this paper important? Well this paper is important because many</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2102" target="_blank">00:35:02.460</a></span> | <span class="t">problems can be framed as image transformation tasks, where a system receives some input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2108" target="_blank">00:35:08.280</a></span> | <span class="t">and chucks out some other output. For example, denoising. Learn to take an input image that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2115" target="_blank">00:35:15.360</a></span> | <span class="t">full of noise and spit out a beautifully clean image. Super resolution, take an input image</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2121" target="_blank">00:35:21.360</a></span> | <span class="t">which is low-res and spit out a high-res. Colorization, take an input image which is black and white</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2127" target="_blank">00:35:27.320</a></span> | <span class="t">and spit out something which is color. Now one of the interesting things here is that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2132" target="_blank">00:35:32.720</a></span> | <span class="t">all of these examples, you can generate as much input data as you like by taking lots</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2139" target="_blank">00:35:39.580</a></span> | <span class="t">of images, which are either from your camera or you download off the internet or from ImageNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2144" target="_blank">00:35:44.320</a></span> | <span class="t">and you can make them lower-res. You can add noise. You can make them black and white.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2150" target="_blank">00:35:50.160</a></span> | <span class="t">So you can generate as much labeled data as you like. That's one of the really cool things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2153" target="_blank">00:35:53.880</a></span> | <span class="t">about this whole topic of generators.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2169" target="_blank">00:36:09.060</a></span> | <span class="t">With that example, going to lower-res imagery, it's algorithmically done. Is the neural net</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2179" target="_blank">00:36:19.680</a></span> | <span class="t">only going to learn how to transfer out something that's algorithmically done versus an actual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2185" target="_blank">00:36:25.600</a></span> | <span class="t">low-res imagery that doesn't have like --</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2190" target="_blank">00:36:30.500</a></span> | <span class="t">So one thing I'll just mention is the way you would create your labeled data is not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2194" target="_blank">00:36:34.560</a></span> | <span class="t">to do that low-res on the camera. You would grab the images that you've already taken</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2199" target="_blank">00:36:39.440</a></span> | <span class="t">and make them low-res just by doing filtering in OpenCV or whatever. That is algorithmic,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2210" target="_blank">00:36:50.840</a></span> | <span class="t">and it may not be perfect, but there's lots of ways of generating that low-res image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2218" target="_blank">00:36:58.480</a></span> | <span class="t">So there's lots of ways of creating a low-res image. Part of it is about how do you do that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2222" target="_blank">00:37:02.320</a></span> | <span class="t">creation of the low-res image and how well do you match the real low-res data you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2227" target="_blank">00:37:07.720</a></span> | <span class="t">going to be getting. But in the end, in this case, things like low-resolution images or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2234" target="_blank">00:37:14.480</a></span> | <span class="t">black and white images, it's so hard to start with something which could be like -- I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2240" target="_blank">00:37:20.160</a></span> | <span class="t">seen versions with just an 8x8 picture and turning it into a photo. It's so hard to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2248" target="_blank">00:37:28.240</a></span> | <span class="t">that regardless of how that 8x8 thing was created that often the details of how the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2254" target="_blank">00:37:34.640</a></span> | <span class="t">low-res image was created don't really matter too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2259" target="_blank">00:37:39.600</a></span> | <span class="t">There are some other examples they mention which is turning an image into an image which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2263" target="_blank">00:37:43.720</a></span> | <span class="t">includes segmentation. We'll learn more about this in coming lessons, but segmentation refers</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2271" target="_blank">00:37:51.040</a></span> | <span class="t">to taking a photo of something and creating a new image that basically has a different</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2276" target="_blank">00:37:56.000</a></span> | <span class="t">color for each object. Horses are green, cars are blue, buildings are red, that kind of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2281" target="_blank">00:38:01.960</a></span> | <span class="t">thing. That's called segmentation. As you know from things like the fisheries competition,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2287" target="_blank">00:38:07.360</a></span> | <span class="t">segmentation can be really important as a part of solving other bigger problems.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2292" target="_blank">00:38:12.640</a></span> | <span class="t">Another example they mention here is depth estimation. There are lots of important reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2296" target="_blank">00:38:16.520</a></span> | <span class="t">you would want to use depth estimation. For example, maybe you want to create some fancy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2301" target="_blank">00:38:21.800</a></span> | <span class="t">video effects where you start with a flat photo and you want to create some cool new</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2308" target="_blank">00:38:28.800</a></span> | <span class="t">Apple TV thing that moves around the photo with a parallax effect as if it was 3D. If</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2316" target="_blank">00:38:36.160</a></span> | <span class="t">you were able to use a CNN to figure out how far away every object was automatically, then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2322" target="_blank">00:38:42.520</a></span> | <span class="t">you could turn a 2D photo into a 3D image automatically.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2329" target="_blank">00:38:49.080</a></span> | <span class="t">Taking an image in and sticking an image out is kind of the idea in computer vision at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2334" target="_blank">00:38:54.680</a></span> | <span class="t">least of generative networks or generative models. This is why I wanted to talk a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2339" target="_blank">00:38:59.480</a></span> | <span class="t">about generative models during this class. It's not just about artistic style. Artistic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2345" target="_blank">00:39:05.500</a></span> | <span class="t">style was just my sneaky way of introducing you to the world of generative models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2355" target="_blank">00:39:15.120</a></span> | <span class="t">Let's look at how to create this super resolution idea. Part of your homework this week will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2363" target="_blank">00:39:23.640</a></span> | <span class="t">be to create the new approach to style transfer. I'm going to build the super resolution version,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2371" target="_blank">00:39:31.520</a></span> | <span class="t">which is a slightly simpler version, and then you're going to try and build on top of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2375" target="_blank">00:39:35.480</a></span> | <span class="t">to create the style transfer version. Make sure you let me know if you're not sure at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2383" target="_blank">00:39:43.680</a></span> | <span class="t">any point.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2384" target="_blank">00:39:44.680</a></span> | <span class="t">I've already created a sample of 20,000 image images, and I've created two sizes. One is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2394" target="_blank">00:39:54.560</a></span> | <span class="t">288x288, and one is 72x72, and they're available as bcols arrays. I actually posted the link</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2408" target="_blank">00:40:08.600</a></span> | <span class="t">to these last week, and it's on platform.fast.ai. So we'll open up those bcols arrays. One trick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2415" target="_blank">00:40:15.320</a></span> | <span class="t">you might have hopefully learned in part 1 is that you can turn a bcols array into a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2420" target="_blank">00:40:20.160</a></span> | <span class="t">numpy array by slicing it with everything. Any time you slice a bcols array, you get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2427" target="_blank">00:40:27.560</a></span> | <span class="t">back a numpy array. So if you slice everything, then this turns it into a numpy array. This</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2433" target="_blank">00:40:33.720</a></span> | <span class="t">is just a convenient way of sharing numpy arrays in this case. So we've now got an array of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2439" target="_blank">00:40:39.480</a></span> | <span class="t">low resolution images and an array of high resolution images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2445" target="_blank">00:40:45.360</a></span> | <span class="t">So let me start maybe by showing you the final network. Okay, this is the final network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2458" target="_blank">00:40:58.040</a></span> | <span class="t">So we start off by taking in a batch of low-res images. The very first thing we do is stick</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2466" target="_blank">00:41:06.600</a></span> | <span class="t">them through a convolutional block with a stride of 1. This is not going to change its</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2471" target="_blank">00:41:11.960</a></span> | <span class="t">size at all. This convolutional block has a filter size of 9, and it generates 64 filters.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2481" target="_blank">00:41:21.300</a></span> | <span class="t">So this is a very large filter size. Particularly nowadays, filter sizes tend to be 3. Actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2490" target="_blank">00:41:30.240</a></span> | <span class="t">in a lot of modern networks, the very first layer is very often a large filter size, just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2497" target="_blank">00:41:37.840</a></span> | <span class="t">the one, just one very first layer. And the reason is that it basically allows us to immediately</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2503" target="_blank">00:41:43.760</a></span> | <span class="t">increase the receptive field of all of the layers from now on. So by having 9x9, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2513" target="_blank">00:41:53.040</a></span> | <span class="t">we don't lose any information because we've gone from 3 channels to 64 filters. So each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2520" target="_blank">00:42:00.480</a></span> | <span class="t">of these 9x9 convolutions can actually have quite a lot of information because you've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2525" target="_blank">00:42:05.120</a></span> | <span class="t">got 64 filters. So you'll be seeing this quite a lot in modern CNN architectures, just a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2531" target="_blank">00:42:11.720</a></span> | <span class="t">single large filter conv layer. So this won't be unusual in the future.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2538" target="_blank">00:42:18.520</a></span> | <span class="t">Now the next thing, I'm going to give the green box behind you. Oh, just a moment, sorry.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2549" target="_blank">00:42:29.040</a></span> | <span class="t">The stride 1 is also pretty popular, I think. Well the stride 1 is important for this first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2556" target="_blank">00:42:36.600</a></span> | <span class="t">layer because you don't want to throw away any information yet. So in the very first</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2560" target="_blank">00:42:40.720</a></span> | <span class="t">layer, we want to keep the full image size. So with the stride 1, it doesn't change, it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2566" target="_blank">00:42:46.160</a></span> | <span class="t">doesn't downsample at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2567" target="_blank">00:42:47.680</a></span> | <span class="t">But there's also a lot of duplication, right? Like 9 filter size and 1 filter size?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2573" target="_blank">00:42:53.560</a></span> | <span class="t">They overlap a lot, absolutely. But that's okay. A good implementation of a convolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2582" target="_blank">00:43:02.080</a></span> | <span class="t">is going to hopefully memoize some of that, or at least keep it in cache. So it hopefully</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2588" target="_blank">00:43:08.200</a></span> | <span class="t">won't slow it down too much.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2591" target="_blank">00:43:11.040</a></span> | <span class="t">One of the discussions I was just having during the break was how practical are the things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2604" target="_blank">00:43:24.440</a></span> | <span class="t">that we're learning at the moment compared to part 1 where everything was just designed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2608" target="_blank">00:43:28.840</a></span> | <span class="t">entirely to be the most practical things which we have best practices for. And the answer</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2614" target="_blank">00:43:34.600</a></span> | <span class="t">is a lot of the stuff we're going to be learning, no one quite knows how practical it is because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2619" target="_blank">00:43:39.600</a></span> | <span class="t">a lot of it just hasn't really been around that long and isn't really that well understood</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2624" target="_blank">00:43:44.840</a></span> | <span class="t">and maybe there aren't really great libraries for it yet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2627" target="_blank">00:43:47.520</a></span> | <span class="t">So one of the things I'm actually hoping from this part 2 is by learning the edge of research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2634" target="_blank">00:43:54.800</a></span> | <span class="t">stuff or beyond amongst a diverse group is that some of you will look at it and think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2641" target="_blank">00:44:01.120</a></span> | <span class="t">about whatever you do 9 to 5 or 8 to 6 or whatever and think, oh, I wonder if I could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2648" target="_blank">00:44:08.920</a></span> | <span class="t">use that for this. If that ever pops into your head, please tell us. Please talk about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2656" target="_blank">00:44:16.320</a></span> | <span class="t">it on the forum because that's what we're most interested in. It's like, oh, you could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2660" target="_blank">00:44:20.920</a></span> | <span class="t">use super-resolution for blah or depth-finding for this or generative models in general for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2668" target="_blank">00:44:28.000</a></span> | <span class="t">this thing I do in pathology or architecture or satellite engineering or whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2675" target="_blank">00:44:35.360</a></span> | <span class="t">So it's going to require some imagination sometimes on your part. So often that's why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2682" target="_blank">00:44:42.440</a></span> | <span class="t">I do want to spend some time looking at stuff like this where it's like, okay, what are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2689" target="_blank">00:44:49.320</a></span> | <span class="t">the kinds of things this can be done for? I'm sure you know in your own field, one of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2695" target="_blank">00:44:55.280</a></span> | <span class="t">the differences between expert and beginner is the way an expert can look at something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2699" target="_blank">00:44:59.840</a></span> | <span class="t">from first principles and say, okay, I could use that for this totally different thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2705" target="_blank">00:45:05.640</a></span> | <span class="t">which has got nothing to do with the example that was originally given to me because I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2708" target="_blank">00:45:08.820</a></span> | <span class="t">know the basic steps are the same. That's what I'm hoping you guys will be able to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2716" target="_blank">00:45:16.080</a></span> | <span class="t">is not just say, okay, now I know how to do artistic style. Are there things in your field</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2733" target="_blank">00:45:33.680</a></span> | <span class="t">which have some similarities? We were going to talk about the super-resolution network.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2748" target="_blank">00:45:48.280</a></span> | <span class="t">We talked about the idea of the initial conv block. After the initial conv block, we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2757" target="_blank">00:45:57.720</a></span> | <span class="t">the computation. In any kind of generative network, there's the key work it has to do,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2766" target="_blank">00:46:06.640</a></span> | <span class="t">which in this case is starting with a low-res image, figure out what might that black dot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2773" target="_blank">00:46:13.720</a></span> | <span class="t">be. Is it a label or is it a wheel? Basically if you want to do really good upscaling, you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2782" target="_blank">00:46:22.360</a></span> | <span class="t">actually have to figure out what the objects are so you know what to draw. That's kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2788" target="_blank">00:46:28.920</a></span> | <span class="t">of like the key computation this CNN is going to have to learn to do. In generative models,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2795" target="_blank">00:46:35.760</a></span> | <span class="t">we generally like to do that computation at a low resolution. There's a couple of reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2801" target="_blank">00:46:41.400</a></span> | <span class="t">why. The first is that at a low resolution there's less work to do so the computation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2806" target="_blank">00:46:46.040</a></span> | <span class="t">is faster. But more importantly, at higher resolutions it generally means we have a smaller</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2813" target="_blank">00:46:53.280</a></span> | <span class="t">receptive field. It generally means we have less ability to capture large amounts of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2819" target="_blank">00:46:59.480</a></span> | <span class="t">image at once. If you want to do really great computations where you recognize that this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2829" target="_blank">00:47:09.560</a></span> | <span class="t">blob here is a face and therefore the dot inside it is an eyeball, then you're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2834" target="_blank">00:47:14.400</a></span> | <span class="t">to need enough of a receptive field to cover that whole area.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2838" target="_blank">00:47:18.760</a></span> | <span class="t">Now I noticed a couple of you asked for information about receptive fields on the forum thread.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2844" target="_blank">00:47:24.880</a></span> | <span class="t">There's quite a lot of information about this online, so Google is your friend here. But</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2850" target="_blank">00:47:30.960</a></span> | <span class="t">the basic idea is if you have a single convolutional filter of 3x3, the receptive field is 3x3.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2859" target="_blank">00:47:39.840</a></span> | <span class="t">So it's how much space can that convolutional filter impact.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2875" target="_blank">00:47:55.000</a></span> | <span class="t">On the other hand, what if you had a 3x3 filter which had a 3x3 filter as its input? So that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2885" target="_blank">00:48:05.600</a></span> | <span class="t">means that the center one took all of this. But what did this one take? Well this one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2892" target="_blank">00:48:12.000</a></span> | <span class="t">would have taken, depending on the stride, probably these ones here. And this one over</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2899" target="_blank">00:48:19.960</a></span> | <span class="t">here would have taken these ones here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2905" target="_blank">00:48:25.920</a></span> | <span class="t">So in other words, in the second layer, assuming a stride of 1, the receptive field is now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2911" target="_blank">00:48:31.880</a></span> | <span class="t">5x5, not 3x3. So the receptive field depends on two things. One is how many layers deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2921" target="_blank">00:48:41.600</a></span> | <span class="t">are you, and the second is how much did the previous layers either have a nonunit stride</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2928" target="_blank">00:48:48.680</a></span> | <span class="t">or maybe they had max pooling. So in some way they were becoming down sampled. Those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2933" target="_blank">00:48:53.960</a></span> | <span class="t">two things increased the receptive field.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2937" target="_blank">00:48:57.320</a></span> | <span class="t">And so the reason it's great to be doing layer computations on a large receptive field is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2944" target="_blank">00:49:04.040</a></span> | <span class="t">that it then allows you to look at the big picture and look at the context. It's not</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2949" target="_blank">00:49:09.400</a></span> | <span class="t">just edges anymore, but eyeballs and noses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2955" target="_blank">00:49:15.760</a></span> | <span class="t">So in this case, we have four blocks of computation where each block is a ResNet block. So for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2963" target="_blank">00:49:23.760</a></span> | <span class="t">those of you that don't recall how ResNet works, it would be a good idea to go back</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2968" target="_blank">00:49:28.520</a></span> | <span class="t">to Part 1 and review. But to remind ourselves, let's look at the code. Here's a ResNet block.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2975" target="_blank">00:49:35.880</a></span> | <span class="t">So all a ResNet block does is it takes some input and it does two convolutional blocks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2983" target="_blank">00:49:43.360</a></span> | <span class="t">on that input, and then it adds the result of those convolutions back to the original</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2989" target="_blank">00:49:49.240</a></span> | <span class="t">input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2990" target="_blank">00:49:50.240</a></span> | <span class="t">So you might remember from Part 1 we actually drew it. We said there's some input and it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=2994" target="_blank">00:49:54.600</a></span> | <span class="t">goes through two convolutional blocks and then it goes back and is added to the original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3003" target="_blank">00:50:03.200</a></span> | <span class="t">And if you remember, we basically said in that case we've got y equals x plus some function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3010" target="_blank">00:50:10.520</a></span> | <span class="t">of x, which means that the function equals y minus x and this thing here is a residual.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3024" target="_blank">00:50:24.640</a></span> | <span class="t">So a whole stack of residual blocks, ResNet blocks on top of each other can learn to gradually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3030" target="_blank">00:50:30.200</a></span> | <span class="t">get thrown in on whatever it's trying to do. In this case, what it's trying to do is get</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3035" target="_blank">00:50:35.800</a></span> | <span class="t">the information it's going to need to upscale this in a smart way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3041" target="_blank">00:50:41.400</a></span> | <span class="t">So we're going to be using a lot more of this idea of taking blocks that we know work well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3049" target="_blank">00:50:49.160</a></span> | <span class="t">for something and just reusing them. So then what's a conv block? All a conv block is in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3055" target="_blank">00:50:55.480</a></span> | <span class="t">this case is it's a convolution followed by a batch norm, optionally followed by an activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3064" target="_blank">00:51:04.360</a></span> | <span class="t">And one of the things we now know about ResNet blocks is that we generally don't want an activation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3072" target="_blank">00:51:12.920</a></span> | <span class="t">at the end. That's one of the things that a more recent paper discovered. So you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3077" target="_blank">00:51:17.400</a></span> | <span class="t">see that for my second conv block I have no activation.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3082" target="_blank">00:51:22.640</a></span> | <span class="t">I'm sure you've noticed throughout this course that I refactor my network architectures a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3088" target="_blank">00:51:28.360</a></span> | <span class="t">lot. My network architectures don't generally list every single layer, but they're generally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3093" target="_blank">00:51:33.320</a></span> | <span class="t">functions which have a bunch of layers. A lot of people don't do this. A lot of the architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3102" target="_blank">00:51:42.120</a></span> | <span class="t">you find online are like hundreds of lines of layer definitions. I think that's crazy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3107" target="_blank">00:51:47.480</a></span> | <span class="t">It's so easy to make mistakes when you do it that way, and so hard to really see what's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3111" target="_blank">00:51:51.680</a></span> | <span class="t">going on. In general, I would strongly recommend that you try to refactor your architectures</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3118" target="_blank">00:51:58.200</a></span> | <span class="t">so that by the time you write the final thing, it's half a page. You'll see plenty of examples</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3125" target="_blank">00:52:05.280</a></span> | <span class="t">of that, so hopefully that will be helpful.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3129" target="_blank">00:52:09.160</a></span> | <span class="t">So we've increased the receptive field, we've done a bunch of computation, but we still</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3134" target="_blank">00:52:14.600</a></span> | <span class="t">haven't actually changed the size of the image, which is not very helpful. So the next thing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3139" target="_blank">00:52:19.480</a></span> | <span class="t">we do is we're going to change the size of the image. And the first thing we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3143" target="_blank">00:52:23.440</a></span> | <span class="t">to learn is to do that with something that goes by many names. One is deconvolution,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3156" target="_blank">00:52:36.880</a></span> | <span class="t">another is transposed convolutions, and it's also known as fractionally strided convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3174" target="_blank">00:52:54.920</a></span> | <span class="t">In Keras they call them decomvolutions. And the basic idea is something which I've actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3184" target="_blank">00:53:04.320</a></span> | <span class="t">got a spreadsheet to show you. The basic idea is that you've got some kind of image, so here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3196" target="_blank">00:53:16.040</a></span> | <span class="t">a 4x4 image, and you put it through a 3x3 filter, a convolutional filter, and if you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3205" target="_blank">00:53:25.560</a></span> | <span class="t">doing valid convolutions, that's going to leave you with a 2x2 output, because here's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3214" target="_blank">00:53:34.040</a></span> | <span class="t">one 3x3, another 3x3, and four of them. So each one is grabbing the whole filter and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3225" target="_blank">00:53:45.080</a></span> | <span class="t">the appropriate part of the data. So it's just a standard 2D convolution.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3229" target="_blank">00:53:49.480</a></span> | <span class="t">So we've done that. Now let's say we want to undo that. We want something which can take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3235" target="_blank">00:53:55.680</a></span> | <span class="t">this result and recreate this input. How would you do that? So one way to do that would be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3245" target="_blank">00:54:05.120</a></span> | <span class="t">to take this result and put back that implicit padding. So let's surround it with all these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3255" target="_blank">00:54:15.400</a></span> | <span class="t">zeros such that now if we use some convolutional filter, and we're going to put it through this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3272" target="_blank">00:54:32.300</a></span> | <span class="t">entire matrix, a bunch of zeros with our result matrix in the middle, and then we can calculate</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3280" target="_blank">00:54:40.880</a></span> | <span class="t">our result in exactly the same way, just a normal convolutional filter.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3285" target="_blank">00:54:45.560</a></span> | <span class="t">So if we now use gradient descent, we can look and see, what is the error? So how much</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3292" target="_blank">00:54:52.920</a></span> | <span class="t">does this pixel differ from this pixel? And how much does this pixel differ from this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3301" target="_blank">00:55:01.000</a></span> | <span class="t">pixel? And then we add them all together to get our mean squared error. So we can now</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3307" target="_blank">00:55:07.000</a></span> | <span class="t">use gradient descent, which hopefully you remember from Part 1 in Excel is called solver.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3314" target="_blank">00:55:14.520</a></span> | <span class="t">And we can say, set this cell to a minimum by changing these cells. So this is basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3323" target="_blank">00:55:23.920</a></span> | <span class="t">like the simplest possible optimization. Solve that, and here's what it's come up with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3333" target="_blank">00:55:33.520</a></span> | <span class="t">So it's come up with a convolutional filter. You'll see that the result is not exactly</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3341" target="_blank">00:55:41.000</a></span> | <span class="t">the same as the original data, and of course, how could it be? We don't have enough information,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3346" target="_blank">00:55:46.240</a></span> | <span class="t">we only have 4 things to try and regenerate 16 things. But it's not terrible. And in general,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3353" target="_blank">00:55:53.760</a></span> | <span class="t">this is the challenge with upscaling. When you've got something that's blurred and down-sampled,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3361" target="_blank">00:56:01.200</a></span> | <span class="t">you've thrown away information. So the only way you can get information back is to guess</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3365" target="_blank">00:56:05.760</a></span> | <span class="t">what was there. But the important thing is that by using a convolution like this, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3372" target="_blank">00:56:12.040</a></span> | <span class="t">can learn those filters. So we can learn how to up-sample it in a way that gives us the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3378" target="_blank">00:56:18.920</a></span> | <span class="t">loss that we want. So this is what a deconvolution is. It's just a convolution on a padded input.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3388" target="_blank">00:56:28.320</a></span> | <span class="t">Now in this case, I've assumed that my convolutions had a unit strived. There was just 1 pixel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3395" target="_blank">00:56:35.320</a></span> | <span class="t">between each convolution. If your convolutions are of strived 2, then it looks like this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3403" target="_blank">00:56:43.440</a></span> | <span class="t">picture. And so you can see that as well as putting the 2 pixels around the outside, we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3410" target="_blank">00:56:50.040</a></span> | <span class="t">also put a 0 pixel in the middle. So these 4 cells are now our data cells, and you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3418" target="_blank">00:56:58.280</a></span> | <span class="t">then see it calculating the convolution through here. I strongly suggest looking at this link,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3425" target="_blank">00:57:05.000</a></span> | <span class="t">which is where this picture comes from. And in turn, this link comes from a fantastic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3431" target="_blank">00:57:11.920</a></span> | <span class="t">paper called the Convolution Arithmetic Guide, which is a really great paper. And so if you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3437" target="_blank">00:57:17.800</a></span> | <span class="t">want to know more about both convolutions and deconvolutions, you can look at this page</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3443" target="_blank">00:57:23.120</a></span> | <span class="t">and it's got lots of beautiful animations, including animations on transposed convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3451" target="_blank">00:57:31.200</a></span> | <span class="t">So you can see, this is the one I just showed you. So that's the one we just saw in Excel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3464" target="_blank">00:57:44.680</a></span> | <span class="t">So that's a really great site.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3473" target="_blank">00:57:53.160</a></span> | <span class="t">So that's what we're going to do first, is we're going to do deconvolutions. So in Keras,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3481" target="_blank">00:58:01.560</a></span> | <span class="t">a deconvolution is exactly the same as convolution, except with DE on the front. You've got all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3486" target="_blank">00:58:06.920</a></span> | <span class="t">the same stuff. How many filters do you want? What's the size of your filter? What's your</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3491" target="_blank">00:58:11.840</a></span> | <span class="t">stride or subsample, as they call it? Border mode, so close.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3497" target="_blank">00:58:17.040</a></span> | <span class="t">We have a question. If TensorFlow is the backend, shouldn't the batch normalization axis equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3505" target="_blank">00:58:25.040</a></span> | <span class="t">negative 1? And then there was a link to a GitHub conversation where Francois said that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3521" target="_blank">00:58:41.480</a></span> | <span class="t">for Theano, axis is 1.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3523" target="_blank">00:58:43.520</a></span> | <span class="t">No, it should be. And in fact, axis minus 1 is the default. So, yes. Thank you. Well</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3533" target="_blank">00:58:53.200</a></span> | <span class="t">spotted. Thank David Gutmann. He is also responsible for some of our beautiful pictures we saw</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3538" target="_blank">00:58:58.960</a></span> | <span class="t">earlier. So let's remove axis. That will make things look better. And go faster as well.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3556" target="_blank">00:59:16.040</a></span> | <span class="t">So just in case you weren't clear on that, you might remember from part 1 that the reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3560" target="_blank">00:59:20.040</a></span> | <span class="t">we had that axis equals 1 is because in Theano that was the channel axis. So we basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3564" target="_blank">00:59:24.920</a></span> | <span class="t">wanted not to throw away the xy information, the batch normal across channels. In Theano,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3571" target="_blank">00:59:31.360</a></span> | <span class="t">channel is now the last axis. And since minus 1 is the default, we actually don't need that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3583" target="_blank">00:59:43.800</a></span> | <span class="t">So that's our deconvolution blocks. So we're using a stride of 2,2. So that means that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3594" target="_blank">00:59:54.000</a></span> | <span class="t">each time we go through this deconvolution, it's going to be doubling the size of the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3597" target="_blank">00:59:57.560</a></span> | <span class="t">image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3598" target="_blank">00:59:58.560</a></span> | <span class="t">For some reason I don't fully understand it and haven't really looked into it. In Keras,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3603" target="_blank">01:00:03.000</a></span> | <span class="t">you actually have to tell it the shape of the output. So you can see here, you can actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3609" target="_blank">01:00:09.280</a></span> | <span class="t">see it's gone from 72x72 to 144x144 to 288x288. So because these are convolutional filters,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3618" target="_blank">01:00:18.160</a></span> | <span class="t">it's learning to upscale. But it's not upscaling with just three channels, it's upscaling with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3624" target="_blank">01:00:24.400</a></span> | <span class="t">64 filters. So that's how it's able to do more sophisticated stuff.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3631" target="_blank">01:00:31.280</a></span> | <span class="t">And then finally, we're kind of reversing things here. We have another 9x9 convolution in order</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3640" target="_blank">01:00:40.760</a></span> | <span class="t">to get back our three channels. So the idea is we previously had something with 64 channels,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3648" target="_blank">01:00:48.600</a></span> | <span class="t">and so we now want to turn it into something with just three channels, the three colors,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3652" target="_blank">01:00:52.680</a></span> | <span class="t">and to do that we want to use quite a bit of context. So we have a single 9x9 filter</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3658" target="_blank">01:00:58.040</a></span> | <span class="t">at the end to get our three channels out. So at the end we have a 288x288x3 tensor, in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3665" target="_blank">01:01:05.720</a></span> | <span class="t">other words, an image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3668" target="_blank">01:01:08.680</a></span> | <span class="t">So if we go ahead now and train this, then it's going to do basically what we want, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3673" target="_blank">01:01:13.920</a></span> | <span class="t">the thing we're going to have to do is create our loss function. And creating our loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3681" target="_blank">01:01:21.880</a></span> | <span class="t">is a little bit messy, but I'll take you through it slowly and hopefully it'll all make sense.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3693" target="_blank">01:01:33.120</a></span> | <span class="t">So let's remember some of the symbols here. Input, imp, is the original low-resolution</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3702" target="_blank">01:01:42.340</a></span> | <span class="t">input tensor. And then the output of this is called @p, and so let's call this whole</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3710" target="_blank">01:01:50.300</a></span> | <span class="t">network here, let's call it the upsampling network. So this is the thing that's actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3715" target="_blank">01:01:55.480</a></span> | <span class="t">responsible for doing the upsampling network. So we're going to take the upsampling network</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3720" target="_blank">01:02:00.120</a></span> | <span class="t">and we're going to attach it to VGG. And VGG is going to be used only as a loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3727" target="_blank">01:02:07.120</a></span> | <span class="t">to get the content lost.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3731" target="_blank">01:02:11.360</a></span> | <span class="t">So before we can take this output and stick it into VGG, we need to stick it through our</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3737" target="_blank">01:02:17.200</a></span> | <span class="t">standard mean subtraction pre-processing. So this is just the same thing that we did</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3741" target="_blank">01:02:21.880</a></span> | <span class="t">over and over again in Part 1. So let's now define this output as being this lambda function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3753" target="_blank">01:02:33.440</a></span> | <span class="t">applied to the output of our upsampling network. So that's what this is. This is just our pre-processed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3762" target="_blank">01:02:42.080</a></span> | <span class="t">upsampling network output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3767" target="_blank">01:02:47.520</a></span> | <span class="t">So we can now create a VGG network, and let's go through every layer and make it not trainable.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3777" target="_blank">01:02:57.400</a></span> | <span class="t">You can't ever make your loss function be trainable. The loss function is the fixed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3782" target="_blank">01:03:02.800</a></span> | <span class="t">in stone thing that tells you how well you're doing. So clearly you have to make sure VGG</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3787" target="_blank">01:03:07.440</a></span> | <span class="t">is not trainable. Which bit of the VGG network do we want? We're going to try a few things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3795" target="_blank">01:03:15.320</a></span> | <span class="t">I'm using block2.conf2. So relatively early, and the reason for that is that if you remember</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3801" target="_blank">01:03:21.920</a></span> | <span class="t">when we did the content reconstruction last week, the very first thing we did, we found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3807" target="_blank">01:03:27.640</a></span> | <span class="t">that you could basically totally reconstruct the original image from early layer activations,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3814" target="_blank">01:03:34.280</a></span> | <span class="t">or else by the time we got to block4 we've got pretty horrendous things. So we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3820" target="_blank">01:03:40.900</a></span> | <span class="t">to use a somewhat early block as our content loss, or as the paper calls it, the perceptual</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3829" target="_blank">01:03:49.200</a></span> | <span class="t">loss. You can play around with this and see how it goes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3836" target="_blank">01:03:56.400</a></span> | <span class="t">So now we're going to create two versions of this VGG output. This is something which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3844" target="_blank">01:04:04.120</a></span> | <span class="t">is I think very poorly understood or appreciated with the Keras dysfunctional API, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3852" target="_blank">01:04:12.360</a></span> | <span class="t">any kind of layer, and a model is a layer as far as Keras is concerned, can be treated</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3858" target="_blank">01:04:18.080</a></span> | <span class="t">as if it was a function. So we can take this model and pretend it's a function, and we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3864" target="_blank">01:04:24.760</a></span> | <span class="t">can pass it any tensor we like. And what that does is it creates a new model where those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3871" target="_blank">01:04:31.160</a></span> | <span class="t">two pieces are joined together. So VGG2 is now equal to this model on the top and this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3884" target="_blank">01:04:44.920</a></span> | <span class="t">model on the bottom. Remember this model was the result of our upsampling network followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3892" target="_blank">01:04:52.480</a></span> | <span class="t">by pre-processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3893" target="_blank">01:04:53.480</a></span> | <span class="t">In the upsampling network, is the lambda function to normalize the output image?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3900" target="_blank">01:05:00.840</a></span> | <span class="t">Yeah, that's a good point. So we use a fan activation which can go from -1 to 1. So if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3909" target="_blank">01:05:09.640</a></span> | <span class="t">you then go that plus 1 times 127.5, that gives you something that's between 0 and 255, which</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3915" target="_blank">01:05:15.720</a></span> | <span class="t">is the range that we want. Interestingly, this was suggested in the original paper and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3921" target="_blank">01:05:21.160</a></span> | <span class="t">supplementary materials. More recently, on Reddit I think it was, the author said that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3926" target="_blank">01:05:26.720</a></span> | <span class="t">they tried it without the fan activation and therefore without the final deprocessing and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3934" target="_blank">01:05:34.800</a></span> | <span class="t">it worked just as well. You can try doing that. If you wanted to try it, you would just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3939" target="_blank">01:05:39.440</a></span> | <span class="t">remove the activation and you would just remove this last thing entirely. But obviously if</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3946" target="_blank">01:05:46.640</a></span> | <span class="t">you do have a fan, then you need the output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3951" target="_blank">01:05:51.520</a></span> | <span class="t">This is actually something I've been playing with with a lot of different models. Any time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3955" target="_blank">01:05:55.760</a></span> | <span class="t">I have some particular range that I want, one way to enforce that is by having a fan</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3962" target="_blank">01:06:02.240</a></span> | <span class="t">or sigmoid followed by something that turns that into the range you want. It's not just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3967" target="_blank">01:06:07.080</a></span> | <span class="t">images. So we've got two versions of our BGG layer output. One which is based on the output</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3979" target="_blank">01:06:19.800</a></span> | <span class="t">of the upscaling network, and the other which is based on just an input. And this just an</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3988" target="_blank">01:06:28.560</a></span> | <span class="t">input is using the high-resolution shape as its input. So that makes sense because this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=3996" target="_blank">01:06:36.840</a></span> | <span class="t">BGG network is something that we're going to be using at the high-resolution scale. We're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4003" target="_blank">01:06:43.760</a></span> | <span class="t">going to be taking the high-resolution target image and the high-resolution up-sampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4008" target="_blank">01:06:48.800</a></span> | <span class="t">result and comparing them. Now that we've done all that, we're nearly there. We've now got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4018" target="_blank">01:06:58.840</a></span> | <span class="t">high-res perceptual activations and we've got the low-res up-sampled perceptual activations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4027" target="_blank">01:07:07.520</a></span> | <span class="t">We now just need to take the mean sum of squares between them, and here it is here. In Keras,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4035" target="_blank">01:07:15.520</a></span> | <span class="t">anytime you put something into a network, it has to be a layer. So if you want to take</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4040" target="_blank">01:07:20.400</a></span> | <span class="t">just a plain old function and turn it into a layer, you just chuck it inside a capital</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4046" target="_blank">01:07:26.080</a></span> | <span class="t">L lambda. So our final model is going to take our low-res input and our high-res input as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4059" target="_blank">01:07:39.120</a></span> | <span class="t">our two inputs and return this loss function as an output.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4065" target="_blank">01:07:45.560</a></span> | <span class="t">One last trick. When you fit things in Keras, it assumes that you're trying to take some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4072" target="_blank">01:07:52.920</a></span> | <span class="t">output and make it close to some target. In this case, our loss is the actual loss function</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4080" target="_blank">01:08:00.160</a></span> | <span class="t">we want. It's not that there's some target. We want to make it as low as possible. Since</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4085" target="_blank">01:08:05.480</a></span> | <span class="t">it's the sum of mean squared errors, it can't go beneath 0. So what we can do is we can basically</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4094" target="_blank">01:08:14.560</a></span> | <span class="t">check Keras and say that our target for the loss is 0. And you can't just use the scalar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4101" target="_blank">01:08:21.200</a></span> | <span class="t">0, remember every time we have a target set of labels in Keras, you need 1 for every row.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4109" target="_blank">01:08:29.160</a></span> | <span class="t">So we're going to create an array of zeros. That's just so that we can fit it into what</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4117" target="_blank">01:08:37.080</a></span> | <span class="t">Keras expects. And I kind of find that increasingly as I start to move away from the world trodden</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4127" target="_blank">01:08:47.440</a></span> | <span class="t">path of deep learning, more and more, particularly if you want to use Keras, you kind of have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4132" target="_blank">01:08:52.720</a></span> | <span class="t">to do weird little hacks like this. So there's a weird little pattern. There's probably more</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4139" target="_blank">01:08:59.080</a></span> | <span class="t">elegant ways of doing this, but this works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4142" target="_blank">01:09:02.200</a></span> | <span class="t">So we've got our loss function that we're trying to get every row as close to 0 as possible.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4147" target="_blank">01:09:07.720</a></span> | <span class="t">We have a question. If we're only using up to block2/conf2, could we pop off all the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4154" target="_blank">01:09:14.960</a></span> | <span class="t">layers afterwards to save some computation? Sure. It wouldn't be a bad idea at all.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4162" target="_blank">01:09:22.960</a></span> | <span class="t">So we compile it, we fit it. One thing you'll notice I've started doing is using this callback</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4177" target="_blank">01:09:37.080</a></span> | <span class="t">called TQDM notebook callback. TQDM is a really terrific library. Basically it does something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4186" target="_blank">01:09:46.520</a></span> | <span class="t">very simple, which is to add a progress meter to your loops. You can use it in a console,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4196" target="_blank">01:09:56.280</a></span> | <span class="t">as you can see. Basically where you've got a loop, you can add TQDM around it. That loop</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4203" target="_blank">01:10:03.520</a></span> | <span class="t">does just what it used to do, but it gets its progress. It even guesses how much time</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4209" target="_blank">01:10:09.440</a></span> | <span class="t">it's left and so forth. You can also use it inside a Jupyter notebook and it creates a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4215" target="_blank">01:10:15.920</a></span> | <span class="t">neat little graph that gradually goes up and shows you how long it's left and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4225" target="_blank">01:10:25.760</a></span> | <span class="t">So this is just a nice little trick. Use some learning rate annealing. At the end of training</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4235" target="_blank">01:10:35.600</a></span> | <span class="t">it for a few epochs, we can try out a model.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4240" target="_blank">01:10:40.720</a></span> | <span class="t">The model we're interested in is just the upsampling model. We're going to be feeding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4244" target="_blank">01:10:44.760</a></span> | <span class="t">the upsampling model low-res inputs and getting out the high-res outputs. We don't actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4250" target="_blank">01:10:50.400</a></span> | <span class="t">care about the value of the loss. I'll now define a model which takes the low-res input</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4257" target="_blank">01:10:57.480</a></span> | <span class="t">and spits out this output, our high-res output. With that model, we can try it called predict.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4268" target="_blank">01:11:08.120</a></span> | <span class="t">Here is our original low-resolution mashed potato, and here is our high-resolution mashed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4276" target="_blank">01:11:16.560</a></span> | <span class="t">potato. It's amazing what it's done. You can see in the original, the shadow of the leaf</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4285" target="_blank">01:11:25.080</a></span> | <span class="t">was very unclear, the bits in the mashed potato were just kind of big blobs. In this version</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4292" target="_blank">01:11:32.200</a></span> | <span class="t">we have bare shadows, hard edges, and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4299" target="_blank">01:11:39.920</a></span> | <span class="t">Question. Can you explain the size of the target? It's the first dimension of the high-res</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4304" target="_blank">01:11:44.520</a></span> | <span class="t">times 128. Why?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4317" target="_blank">01:11:57.600</a></span> | <span class="t">Obviously it's this number. This is basically the number of images that we have. Then it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4333" target="_blank">01:12:13.080</a></span> | <span class="t">128 because that layer has 128 filters, so this ends up giving you the mean squared error</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4349" target="_blank">01:12:29.200</a></span> | <span class="t">of 128 filter losses.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4358" target="_blank">01:12:38.520</a></span> | <span class="t">Question. Would popping the unused layers really save anything? Aren't you only getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4364" target="_blank">01:12:44.320</a></span> | <span class="t">the layers you want when you do the bgg.getLayer block2.com2?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4369" target="_blank">01:12:49.960</a></span> | <span class="t">I'm not sure. I can't quite think quickly enough. You can try it. It might not help.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4380" target="_blank">01:13:00.640</a></span> | <span class="t">Intuitively, what features is this model learning? What it's learning is it's looking at 20,000</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4389" target="_blank">01:13:09.720</a></span> | <span class="t">images, very, very low-resolution images like this. When there's a kind of a soft gray bit</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4400" target="_blank">01:13:20.480</a></span> | <span class="t">next to a hard bit in certain situations, that's probably a shadow, and when there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4405" target="_blank">01:13:25.240</a></span> | <span class="t">a shadow, this is what a shadow looks like, for example. It's learning that when there's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4411" target="_blank">01:13:31.520</a></span> | <span class="t">a curve, it doesn't actually meant to look like a jagged edge, but it's actually meant</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4414" target="_blank">01:13:34.960</a></span> | <span class="t">to look like something smooth. It's really learning what the world looks like. Then when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4423" target="_blank">01:13:43.880</a></span> | <span class="t">you take that world and blur it and make it small, what does it then look like? It's just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4430" target="_blank">01:13:50.640</a></span> | <span class="t">like when you look at a picture like this, particularly if you blur your eyes and de-focus</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4437" target="_blank">01:13:57.780</a></span> | <span class="t">your eyes, you can often see what it originally looked like because your brain basically is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4443" target="_blank">01:14:03.640</a></span> | <span class="t">doing the same thing. It's like when you read a really blurry text. You can still read it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4448" target="_blank">01:14:08.560</a></span> | <span class="t">because your brain is thinking like it knows. That must have been an E, that must have been</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4457" target="_blank">01:14:17.880</a></span> | <span class="t">an E. So are you suggesting there is a similar universality on the other way around? You</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4464" target="_blank">01:14:24.760</a></span> | <span class="t">know when BGG is saying the first layer is learning a line and then a square and a nose</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4470" target="_blank">01:14:30.540</a></span> | <span class="t">or an eye? Are you saying the same thing is true in this case? Yeah. Yeah, absolutely.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4478" target="_blank">01:14:38.120</a></span> | <span class="t">It has to be. There's no way to up-sample. There's an infinite number of ways you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4485" target="_blank">01:14:45.400</a></span> | <span class="t">up-sample. There's lost information. So in order to do it in a way that decreases this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4490" target="_blank">01:14:50.480</a></span> | <span class="t">lost function, it actually has to figure out what's probably there based on this context.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4498" target="_blank">01:14:58.240</a></span> | <span class="t">But don't you agree, just intuitively thinking about it, like example of the, you say, suggesting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4504" target="_blank">01:15:04.440</a></span> | <span class="t">like the album pictures for your mom. Would you think it would be a bit easier if we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4509" target="_blank">01:15:09.560</a></span> | <span class="t">just feeding you pictures of humans because it's like the interaction of the circle of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4513" target="_blank">01:15:13.840</a></span> | <span class="t">the eye and the nose is going to be a lot better. In the most extreme versions of super</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4520" target="_blank">01:15:20.320</a></span> | <span class="t">resolution networks, where they take 8 by 8 inches, you'll see that all of them pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4525" target="_blank">01:15:25.440</a></span> | <span class="t">much use the same dataset, which is something called the Celeb A. Celeb A is a dataset of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4530" target="_blank">01:15:30.440</a></span> | <span class="t">pictures of celebrity spaces. And all celebrity spaces are pretty similar. And so they show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4536" target="_blank">01:15:36.320</a></span> | <span class="t">these fantastic, and they are fantastic in amazing results, but they take an 8 by 8,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4541" target="_blank">01:15:41.360</a></span> | <span class="t">and it looks pretty close. And that's because they're taking advantage of this. In our case,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4548" target="_blank">01:15:48.600</a></span> | <span class="t">we've got 20,000 images from 1,000 categories. It's not going to do nearly as well. If we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4555" target="_blank">01:15:55.280</a></span> | <span class="t">wanted to do as well as the Celeb A versions, we would need hundreds of millions of images</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4560" target="_blank">01:16:00.960</a></span> | <span class="t">of 1,000 categories.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4562" target="_blank">01:16:02.760</a></span> | <span class="t">Yeah, it's just hard for me to imagine mashed potatoes in a face in the same category. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4568" target="_blank">01:16:08.960</a></span> | <span class="t">my biggest thing here.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4571" target="_blank">01:16:11.480</a></span> | <span class="t">The key thing to realize is there's nothing qualitatively different between what mashed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4576" target="_blank">01:16:16.000</a></span> | <span class="t">potato looks like in one face or another. So something can work to recognize the unique</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4583" target="_blank">01:16:23.480</a></span> | <span class="t">features of mashed potatoes. And a big enough network can learn enough examples, can learn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4589" target="_blank">01:16:29.720</a></span> | <span class="t">not just mashed potatoes, but writing and anger pictures and whatever.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4595" target="_blank">01:16:35.680</a></span> | <span class="t">So for your examples, you're most likely to be doing stuff which is more domain-specific.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4601" target="_blank">01:16:41.880</a></span> | <span class="t">And so you should use more domain-specific data taking advantage of exactly these transformations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4611" target="_blank">01:16:51.280</a></span> | <span class="t">One thing I mentioned here is I haven't used a test set, so another piece of the homework</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4628" target="_blank">01:17:08.280</a></span> | <span class="t">is to add in a test set and tell us, is this mashed potato overfit? Is this actually just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4639" target="_blank">01:17:19.340</a></span> | <span class="t">matching the particular training set version of this mashed potato or not? And if it is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4645" target="_blank">01:17:25.020</a></span> | <span class="t">overfitting, can you create something that doesn't overfit? So there's another piece</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4651" target="_blank">01:17:31.700</a></span> | <span class="t">of homework.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4653" target="_blank">01:17:33.800</a></span> | <span class="t">So it's very simple now to take this and turn it into our fast style transfer. So the fast</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4663" target="_blank">01:17:43.280</a></span> | <span class="t">style transfer is going to do exactly the same thing, but rather than turning something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4669" target="_blank">01:17:49.080</a></span> | <span class="t">low-res into something high-res, it's going to take something that's a photo and turn</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4674" target="_blank">01:17:54.840</a></span> | <span class="t">it into Van Gogh's irises.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4681" target="_blank">01:18:01.740</a></span> | <span class="t">So we're going to do that in just the same way. Rather than go from low-res through a</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4689" target="_blank">01:18:09.200</a></span> | <span class="t">CNN to find the content loss against high-res, we're going to take a photo through a CNN</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4698" target="_blank">01:18:18.880</a></span> | <span class="t">and do both style loss and content loss against a single fixed style image.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4707" target="_blank">01:18:27.320</a></span> | <span class="t">I've given you links here, so I have not implemented this for you, this is for you to implement,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4712" target="_blank">01:18:32.160</a></span> | <span class="t">but I have given you links to the original paper, and very importantly also to the supplementary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4716" target="_blank">01:18:36.560</a></span> | <span class="t">material, which is a little hard to find because there's two different versions, and only one</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4720" target="_blank">01:18:40.880</a></span> | <span class="t">of them is correct. And of course I don't tell you which one is correct.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4726" target="_blank">01:18:46.080</a></span> | <span class="t">So the supplementary material goes through all of the exact details of what was their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4733" target="_blank">01:18:53.900</a></span> | <span class="t">loss function, what was their processing, what was their exact architecture, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4739" target="_blank">01:18:59.080</a></span> | <span class="t">on and so forth.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4740" target="_blank">01:19:00.960</a></span> | <span class="t">So while I wait for that to load, like we did a doodle regeneration using the model's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4750" target="_blank">01:19:10.460</a></span> | <span class="t">photographers weights, could we create a regular image to see how you would look if you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4756" target="_blank">01:19:16.440</a></span> | <span class="t">a model?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4757" target="_blank">01:19:17.440</a></span> | <span class="t">I don't know. If you could come up with a loss function, which is how much does somebody</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4767" target="_blank">01:19:27.480</a></span> | <span class="t">look like a model? You could. So you'd have to come up with a loss function. And it would</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4773" target="_blank">01:19:33.960</a></span> | <span class="t">have to be something where you can generate labeled data.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4780" target="_blank">01:19:40.000</a></span> | <span class="t">One of the things they mentioned in the paper is that they found it very important to add</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4786" target="_blank">01:19:46.480</a></span> | <span class="t">quite a lot of padding, and specifically they didn't add zero padding, but they add reflection</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4793" target="_blank">01:19:53.400</a></span> | <span class="t">padding. So reflection padding literally means take the edge and reflect it to your padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4801" target="_blank">01:20:01.880</a></span> | <span class="t">I've written that for you because there isn't one, but you may find it interesting to look</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4806" target="_blank">01:20:06.600</a></span> | <span class="t">at this because this is one of the simplest examples of a custom layer. So we're going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4812" target="_blank">01:20:12.320</a></span> | <span class="t">to be using custom layers more and more, and so I don't want you to be afraid of them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4817" target="_blank">01:20:17.200</a></span> | <span class="t">So a custom layer in Keras is a Python class. If you haven't done OO programming in Python,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4827" target="_blank">01:20:27.320</a></span> | <span class="t">now's a good time to go and look at some tutorials because we're going to be doing quite a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4831" target="_blank">01:20:31.240</a></span> | <span class="t">of it, particularly for PyTorch. PyTorch absolutely relies on it. So we're going to create a class.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4837" target="_blank">01:20:37.400</a></span> | <span class="t">It has to inherit from layer. In Python, this is how you can create a constructor. Python's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4844" target="_blank">01:20:44.820</a></span> | <span class="t">OO syntax is really gross. You have to use a special weird custom name thing, which happens</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4851" target="_blank">01:20:51.060</a></span> | <span class="t">to be the constructor. Every single damn thing inside a class, you have to manually type out</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4856" target="_blank">01:20:56.520</a></span> | <span class="t">self-commerce as the first parameter. If you forget, you'll get stupid errors. In the constructor</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4865" target="_blank">01:21:05.280</a></span> | <span class="t">for a layer, this is basically a way you just save away any of the information you were</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4869" target="_blank">01:21:09.920</a></span> | <span class="t">given. In this case, you've said that I want this much padding, so you just have to save</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4874" target="_blank">01:21:14.680</a></span> | <span class="t">that somewhere and save only this much padding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4877" target="_blank">01:21:17.740</a></span> | <span class="t">And then you need to do two things in every Keras custom layer. One is you have to define</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4883" target="_blank">01:21:23.320</a></span> | <span class="t">something called get output shape 4. That is going to pass in the shape of an input,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4891" target="_blank">01:21:31.800</a></span> | <span class="t">and you have to return what is the shape of the output that that would create. So in this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4896" target="_blank">01:21:36.680</a></span> | <span class="t">case, if s is the shape of the input, then the output is going to be the same batch size</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4903" target="_blank">01:21:43.280</a></span> | <span class="t">and the same number of channels. And then we're going to add in twice the amount of padding</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4909" target="_blank">01:21:49.200</a></span> | <span class="t">for both the rows and columns. This is going to tell it, because remember one of the cool</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4914" target="_blank">01:21:54.240</a></span> | <span class="t">things about Keras is you just chuck the layers on top of each other, and it magically knows</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4919" target="_blank">01:21:59.640</a></span> | <span class="t">how big all the intermediate things are. It magically knows because every layer has this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4924" target="_blank">01:22:04.200</a></span> | <span class="t">thing defined. That's how it works.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4928" target="_blank">01:22:08.600</a></span> | <span class="t">The second thing you have to define is something called call. Call is the thing which will</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4933" target="_blank">01:22:13.000</a></span> | <span class="t">get your layer data and you have to return whatever your layer does. In our case, we</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4940" target="_blank">01:22:20.820</a></span> | <span class="t">want to cause it to add reflection padding. In this case, it happens that TensorFlow has</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4948" target="_blank">01:22:28.920</a></span> | <span class="t">something built in for that called tf.pad.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4951" target="_blank">01:22:31.240</a></span> | <span class="t">Obviously, generally it's nice to create Keras layers that would work with both Fiano and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4958" target="_blank">01:22:38.560</a></span> | <span class="t">TensorFlow backends by using that capital K dot notation. But in this case, Tiano didn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4965" target="_blank">01:22:45.200</a></span> | <span class="t">have anything obvious that did this easily, and since it was just for our class, I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4970" target="_blank">01:22:50.000</a></span> | <span class="t">decided just to make it TensorFlow.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4973" target="_blank">01:22:53.520</a></span> | <span class="t">So here is a complete layer. I can now use that layer in a network definition like this.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4981" target="_blank">01:23:01.680</a></span> | <span class="t">I can call dot predict, which will take an input and turn it into, you can see that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4988" target="_blank">01:23:08.280</a></span> | <span class="t">bird now has the left and right sides here being reflected.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=4995" target="_blank">01:23:15.960</a></span> | <span class="t">So that is there for you to use because in the supplementary material for the paper,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5005" target="_blank">01:23:25.000</a></span> | <span class="t">they add spatial reflection padding at the beginning of the network. And they add a lot</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5010" target="_blank">01:23:30.240</a></span> | <span class="t">40x40. And the reason they add a lot is because they mention in the supplementary material</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5017" target="_blank">01:23:37.720</a></span> | <span class="t">that they don't want to use same convolutions, they want to use valid convolutions in their</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5026" target="_blank">01:23:46.920</a></span> | <span class="t">computation because if you add any black borders during those computation steps, it creates</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5033" target="_blank">01:23:53.040</a></span> | <span class="t">weird artifacts on the edges of the images.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5036" target="_blank">01:23:56.200</a></span> | <span class="t">So you'll see that through this computation of all their residual blocks, the size gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5041" target="_blank">01:24:01.240</a></span> | <span class="t">smaller by 4 each time. And that's because these are valid convolutions. So that's why</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5046" target="_blank">01:24:06.880</a></span> | <span class="t">they have to add padding to the start so that these steps don't cause the image to become</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5053" target="_blank">01:24:13.640</a></span> | <span class="t">too small.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5056" target="_blank">01:24:16.240</a></span> | <span class="t">So this section here should look very familiar because it's the same as our app sampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5062" target="_blank">01:24:22.680</a></span> | <span class="t">network. A bunch of residual blocks, two decompositions, and one 9x9 convolution. So this is identical.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5072" target="_blank">01:24:32.720</a></span> | <span class="t">So you can copy it. This is the new bit. We've already talked about why we have this 9x9</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5084" target="_blank">01:24:44.120</a></span> | <span class="t">conv. But why do we have these downsampling convolutions to start with? We start with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5090" target="_blank">01:24:50.180</a></span> | <span class="t">an image up here of 336x336, and we halve its size, and then we halve its size again.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5098" target="_blank">01:24:58.940</a></span> | <span class="t">Why do we do that? The reason we do that is that, as I mentioned earlier, we want to do</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5107" target="_blank">01:25:07.360</a></span> | <span class="t">our computation at a lower resolution because it allows us to have a larger receptive field</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5114" target="_blank">01:25:14.760</a></span> | <span class="t">and it allows us to do less computation. So this pattern, where it's reflective, the last</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5125" target="_blank">01:25:25.040</a></span> | <span class="t">thing is the same as the top thing, the second last thing is the same as the second thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5129" target="_blank">01:25:29.880</a></span> | <span class="t">You can see it's like a reflection symmetric. It's really, really common in generative models.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5135" target="_blank">01:25:35.480</a></span> | <span class="t">It's first of all to take your object, down-sample it, increasing the number of channels at the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5141" target="_blank">01:25:41.240</a></span> | <span class="t">same time. So increasing the receptive field, you're creating more and more complex representations.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5147" target="_blank">01:25:47.040</a></span> | <span class="t">You then do a bunch of computation on those representations and then at the end you up-sample</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5152" target="_blank">01:25:52.080</a></span> | <span class="t">again. So you're going to see this pattern all the time. So that's why I wanted you guys</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5156" target="_blank">01:25:56.840</a></span> | <span class="t">to implement this yourself this week.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5162" target="_blank">01:26:02.080</a></span> | <span class="t">So there's that, the last major piece of your homework yesterday.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5173" target="_blank">01:26:13.080</a></span> | <span class="t">That's exactly the same as Decombolution Strive 2. So I remember I mentioned earlier that another</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5180" target="_blank">01:26:20.600</a></span> | <span class="t">name for Decombolution is fractionally strided convolution. So you can remember that little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5189" target="_blank">01:26:29.080</a></span> | <span class="t">picture we saw, this idea that you put little columns and rows of zeros in between each</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5194" target="_blank">01:26:34.960</a></span> | <span class="t">row and column. So you kind of think of it as doing like a half-stride at a time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5205" target="_blank">01:26:45.200</a></span> | <span class="t">So that's why this is exactly what we already have. I don't think you need to change it at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5210" target="_blank">01:26:50.760</a></span> | <span class="t">all except you'll need to change my same convolutions to valid convolutions. But this is well worth</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5220" target="_blank">01:27:00.000</a></span> | <span class="t">reading the whole supplementary material because it really has the details. It's so great when</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5227" target="_blank">01:27:07.640</a></span> | <span class="t">a paper has supplementary material like this, you'll often find the majority of papers don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5233" target="_blank">01:27:13.060</a></span> | <span class="t">actually tell you the details of how to do what they did, and many don't even have code.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5239" target="_blank">01:27:19.560</a></span> | <span class="t">These guys both have code and supplementary material, which makes this absolute A+ paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5245" target="_blank">01:27:25.640</a></span> | <span class="t">Plus it works great.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5250" target="_blank">01:27:30.600</a></span> | <span class="t">So that is super-resolution, perceptual losses, and so on and so forth. So I'm glad we got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5260" target="_blank">01:27:40.240</a></span> | <span class="t">there. Let's make sure I don't have any more slides. There's one other thing I'm going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5273" target="_blank">01:27:53.000</a></span> | <span class="t">show you, which is these deconvolutions can create some very ugly artifacts. I can show</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5282" target="_blank">01:28:02.720</a></span> | <span class="t">you some very ugly artifacts because I have some right here. You see it on the screen</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5290" target="_blank">01:28:10.040</a></span> | <span class="t">Rachel, this checkerboard? This is called a checkerboard pattern. The checkerboard pattern</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5300" target="_blank">01:28:20.480</a></span> | <span class="t">happens for a very specific reason. I've provided a link to this paper. It's an online paper.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5309" target="_blank">01:28:29.560</a></span> | <span class="t">You guys might remember Chris Ola. He had a lot of the best learning materials we looked</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5315" target="_blank">01:28:35.760</a></span> | <span class="t">at in Part 1. He's now got this cool thing called distill.pub, done with some of his</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5320" target="_blank">01:28:40.280</a></span> | <span class="t">colleagues at Google. He wrote this thing, discovering why is it that everybody gets</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5327" target="_blank">01:28:47.980</a></span> | <span class="t">these goddamn checkerboard patterns. What he shows is that it happens because you have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5337" target="_blank">01:28:57.160</a></span> | <span class="t">stride 2 size 3 convolutions, which means that every pair of convolutions sees one pixel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5344" target="_blank">01:29:04.700</a></span> | <span class="t">twice. So it's like a checkerboard is just a natural thing that's going to come out.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5351" target="_blank">01:29:11.720</a></span> | <span class="t">So they talk about this in some detail and all the kind of things you can do. But in</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5357" target="_blank">01:29:17.320</a></span> | <span class="t">the end, they point out two things. The first is that you can avoid this by making it that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5366" target="_blank">01:29:26.920</a></span> | <span class="t">your stride divides nicely into your size. So if I change size to 4, they're gone. So</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5379" target="_blank">01:29:39.920</a></span> | <span class="t">one thing you could try if you're getting checkerboard patterns, which you will, is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5384" target="_blank">01:29:44.840</a></span> | <span class="t">make your size 3 convolutions into size 4 convolutions.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5389" target="_blank">01:29:49.960</a></span> | <span class="t">The second thing that he suggests doing is not to use deconvolutions. Instead of using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5396" target="_blank">01:29:56.760</a></span> | <span class="t">a deconvolution, he suggests first of all doing an upsampling. What happens when you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5401" target="_blank">01:30:01.960</a></span> | <span class="t">do an upsampling is it's basically the opposite of Max Pauling. You take every pixel and you</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5408" target="_blank">01:30:08.440</a></span> | <span class="t">turn it into a 2x2 grid of that exact pixel. That's called upsampling. If you do an upsampling</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5417" target="_blank">01:30:17.720</a></span> | <span class="t">followed by a regular convolution, that also gets rid of the checkerboard pattern.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5423" target="_blank">01:30:23.400</a></span> | <span class="t">And as it happens, Keras has something to do that, which is called upsampling2D. So all</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5440" target="_blank">01:30:40.240</a></span> | <span class="t">this does is the opposite of Max Pauling. It's going to double the size of your image, at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5444" target="_blank">01:30:44.800</a></span> | <span class="t">which point you can use a standard normal unit-strided convolution and avoid the artifacts.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5451" target="_blank">01:30:51.680</a></span> | <span class="t">So extra credit after you get your network working is to change it to an upsampling and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5458" target="_blank">01:30:58.280</a></span> | <span class="t">unit-strided convolution network and see if the checkerboard artifacts go away.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5467" target="_blank">01:31:07.480</a></span> | <span class="t">So that is that. At the very end here I've got some suggestions for some more things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5474" target="_blank">01:31:14.960</a></span> | <span class="t">that you can look at. Let's move on. I want to talk about going big. Going big can mean</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5496" target="_blank">01:31:36.600</a></span> | <span class="t">two things. Of course it does mean we get to say big data, which is important. I'm very</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5506" target="_blank">01:31:46.760</a></span> | <span class="t">proud that even during the big data thing I never said big data without saying rude</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5513" target="_blank">01:31:53.360</a></span> | <span class="t">things about the stupid idea of big data. Who cares about how big it is? But in deep</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5518" target="_blank">01:31:58.560</a></span> | <span class="t">learning, sometimes we do need to use either large objects, like if you're doing diabetic</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5525" target="_blank">01:32:05.120</a></span> | <span class="t">retinopathy you all have like 4,000 by 4,000 pictures of eyeballs, or maybe you've got</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5530" target="_blank">01:32:10.360</a></span> | <span class="t">lots of objects, like if you're working with ImageNet. To handle this data that doesn't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5539" target="_blank">01:32:19.920</a></span> | <span class="t">fit in RAM, we need some tricks. I thought we would try some interesting project that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5546" target="_blank">01:32:26.400</a></span> | <span class="t">involves looking at the whole ImageNet competition dataset. The ImageNet competition dataset</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5552" target="_blank">01:32:32.040</a></span> | <span class="t">is about 1.5 million images in 1,000 categories. As I mentioned in the last class, if you try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5561" target="_blank">01:32:41.800</a></span> | <span class="t">to download it, it will give you a little form saying you have to use it for research</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5565" target="_blank">01:32:45.560</a></span> | <span class="t">purposes and that they're going to check it and blah blah blah. In practice, if you fill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5569" target="_blank">01:32:49.520</a></span> | <span class="t">out the form you'll get back an answer seconds later. So anybody who's got a terabyte of space,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5576" target="_blank">01:32:56.760</a></span> | <span class="t">and since you're building your own boxes, you now have a terabyte of space, you can</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5580" target="_blank">01:33:00.680</a></span> | <span class="t">go ahead and download ImageNet, and then you can start working through this project.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5586" target="_blank">01:33:06.740</a></span> | <span class="t">This project is about implementing a paper called 'Divides'. And 'Divides' is a really</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5595" target="_blank">01:33:15.320</a></span> | <span class="t">interesting paper. I actually just chatted to the author about it quite recently. An amazing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5603" target="_blank">01:33:23.920</a></span> | <span class="t">lady named Andrea Fromme, who's now at Clarify, which is a computer vision start-up. What she</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5610" target="_blank">01:33:30.560</a></span> | <span class="t">did was devise was she created a really interesting multimodal architecture. So multimodal means</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5618" target="_blank">01:33:38.160</a></span> | <span class="t">that we're going to be combining different types of objects. In her case, she was combining</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5625" target="_blank">01:33:45.360</a></span> | <span class="t">language with images. It's quite an early paper to look at this idea. She did something</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5631" target="_blank">01:33:51.800</a></span> | <span class="t">which was really interesting. She said normally when we do an ImageNet network, our final</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5640" target="_blank">01:34:00.280</a></span> | <span class="t">layer is a one-hot encoding of a category. So that means that a pug and a golden retriever</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5650" target="_blank">01:34:10.280</a></span> | <span class="t">are no more similar or different in terms of that encoding than a pug and a jumbo jet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5657" target="_blank">01:34:17.960</a></span> | <span class="t">And that seems kind of weird. If you had an encoding where similar things were similar</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5664" target="_blank">01:34:24.840</a></span> | <span class="t">in the encoding, you could do some pretty cool stuff. In particular, one of the key</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5671" target="_blank">01:34:31.000</a></span> | <span class="t">things she was trying to do is to create something which went beyond the 1000 ImageNet categories</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5677" target="_blank">01:34:37.160</a></span> | <span class="t">so that you could work with types of images that were not in ImageNet at all. So the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5684" target="_blank">01:34:44.440</a></span> | <span class="t">she did that was to say, alright, let's throw away the one-hot encoded category and let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5690" target="_blank">01:34:50.240</a></span> | <span class="t">replace it with a word embedding of the thing. So pug is no longer 0 0 0 1 0 0 0, but it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5699" target="_blank">01:34:59.840</a></span> | <span class="t">now the word-to-vec vector of the pug. And that's it. That's the entirety of the thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5706" target="_blank">01:35:06.880</a></span> | <span class="t">Train that and see what happens. I'll provide a link to the paper. One of the things I love</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5712" target="_blank">01:35:12.720</a></span> | <span class="t">about the paper is that what she does is to show quite an interesting range of the kinds</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5720" target="_blank">01:35:20.240</a></span> | <span class="t">of cool results and cool things you can do when you replace a one-hot encoded output with</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5726" target="_blank">01:35:26.400</a></span> | <span class="t">a vector output embedding.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5734" target="_blank">01:35:34.640</a></span> | <span class="t">Let's say this is an image of a pug. It's a type of dog. So pug gets turned into, let's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5763" target="_blank">01:36:03.320</a></span> | <span class="t">say pug is the 300th class in ImageNet. It's going to get turned into a 1000-long vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5773" target="_blank">01:36:13.560</a></span> | <span class="t">with a thousand zeros and a 1 in position 300. That's normally what we use as our target</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5783" target="_blank">01:36:23.040</a></span> | <span class="t">when we're doing image classification. We're going to throw that 1000-long thing away and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5789" target="_blank">01:36:29.320</a></span> | <span class="t">replace it with a 300-long thing. The 300-long thing will be the word vector for pug that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5798" target="_blank">01:36:38.400</a></span> | <span class="t">we downloaded from Word2Vec. Normally our input image comes in, it goes through some</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5814" target="_blank">01:36:54.800</a></span> | <span class="t">kind of computation in our CNN and it has to predict something. Normally the thing it</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5824" target="_blank">01:37:04.120</a></span> | <span class="t">has to predict is a whole bunch of zeros and a 1 here. So the way we do that is that the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5830" target="_blank">01:37:10.760</a></span> | <span class="t">last layer is a softmax layer which encourages one of the things to be much higher than the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5839" target="_blank">01:37:19.400</a></span> | <span class="t">others.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5840" target="_blank">01:37:20.400</a></span> | <span class="t">So what we do is we throw that away and we replace it with the word vector for that thing,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5852" target="_blank">01:37:32.160</a></span> | <span class="t">fox or pug or jumbo-jet. Since the word vector, so generally that might be 300 dimensions,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5860" target="_blank">01:37:40.800</a></span> | <span class="t">and that's dense, that's not lots of zeros, so we can't use a softmax layer at the end</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5866" target="_blank">01:37:46.280</a></span> | <span class="t">anymore. We probably now just use a regular linear layer.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5874" target="_blank">01:37:54.320</a></span> | <span class="t">So the hard part about doing this really is processing image data. There's nothing weird</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5883" target="_blank">01:38:03.080</a></span> | <span class="t">or interesting or tricky about the architecture. All we do is replace the last layer. So we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5888" target="_blank">01:38:08.280</a></span> | <span class="t">going to leverage big holes quite a lot. So we start off by inputting our usual stuff</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5894" target="_blank">01:38:14.760</a></span> | <span class="t">and don't forget with TensorFlow to call this limit_mem thing I created so that you don't</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5898" target="_blank">01:38:18.920</a></span> | <span class="t">use up all of your memory. One thing which can be very helpful is to define actually</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5906" target="_blank">01:38:26.320</a></span> | <span class="t">two parts. Once you've got your own box, you've got a bunch of spinning hard disks that are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5913" target="_blank">01:38:33.560</a></span> | <span class="t">big and slow and cheap, and maybe a couple of fast, expensive, small SSDs or NVMe drives.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5924" target="_blank">01:38:44.680</a></span> | <span class="t">So I generally think it's a good idea to define a path for both. This actually happens to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5931" target="_blank">01:38:51.920</a></span> | <span class="t">be a mount point that has my big, slow, cheap spinning disks, and this path happens to live</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5940" target="_blank">01:39:00.640</a></span> | <span class="t">somewhere, which is my fast SSDs. And that way, when I'm doing my code, any time I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5948" target="_blank">01:39:08.760</a></span> | <span class="t">got something I'm going to be accessing a lot, particularly if it's in a random order,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5953" target="_blank">01:39:13.000</a></span> | <span class="t">I want to make sure that that thing, as long as it's not too big, sits in this path, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5958" target="_blank">01:39:18.880</a></span> | <span class="t">anytime I'm accessing something which I'm accessing generally sequentially, which is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5963" target="_blank">01:39:23.880</a></span> | <span class="t">really big, I can put it in this path. This is one of the good reasons, another good reason</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5968" target="_blank">01:39:28.960</a></span> | <span class="t">to have your own box is that you get this kind of flexibility.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5975" target="_blank">01:39:35.920</a></span> | <span class="t">So the first thing we need is some word vectors. The paper builds their own Wikipedia word</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5989" target="_blank">01:39:49.120</a></span> | <span class="t">vectors. I actually think that the Word2vec vectors you can download from Google are maybe</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=5996" target="_blank">01:39:56.800</a></span> | <span class="t">a better choice here, so I've just gone ahead and shown how you can load that in. One of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6003" target="_blank">01:40:03.680</a></span> | <span class="t">the very nice things about Google's Word2vec word vectors is that in part 1, when we used</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6013" target="_blank">01:40:13.920</a></span> | <span class="t">word vectors, we tended to use GloVe. GloVe would not have a word vector for GoldenRetriever,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6021" target="_blank">01:40:21.480</a></span> | <span class="t">they would have a word vector for Golden. They don't have phrase things, whereas Google's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6028" target="_blank">01:40:28.640</a></span> | <span class="t">word vectors have phrases like GoldenRetriever. So for our thing, we really need to use Google's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6036" target="_blank">01:40:36.920</a></span> | <span class="t">Word2vec vectors, plus anything like that which has multi-part concepts as things that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6043" target="_blank">01:40:43.720</a></span> | <span class="t">we can look at.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6046" target="_blank">01:40:46.040</a></span> | <span class="t">So you can download Word2vec, I will make them available on our platform.ai site because</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6055" target="_blank">01:40:55.240</a></span> | <span class="t">the only way to get them otherwise is to get them from the author's Google Drive directory,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6061" target="_blank">01:41:01.120</a></span> | <span class="t">and trying to get to a Google Drive directory from Linux is an absolute nightmare. So I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6065" target="_blank">01:41:05.760</a></span> | <span class="t">will save them for you so that you don't have to get it.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6072" target="_blank">01:41:12.520</a></span> | <span class="t">So once you've got them, you can load them in, and they're in a weird proprietary binary.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6080" target="_blank">01:41:20.040</a></span> | <span class="t">If you're going to share data, why put it in a weird proprietary binary format in a Google</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6085" target="_blank">01:41:25.160</a></span> | <span class="t">Drive thing that you can't access from Linux? Anyway, this guy did, so I then save it as</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6090" target="_blank">01:41:30.560</a></span> | <span class="t">text to make it a bit easier to work with.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6094" target="_blank">01:41:34.880</a></span> | <span class="t">The word vectors themselves are in a very simple format, they're just the word followed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6099" target="_blank">01:41:39.840</a></span> | <span class="t">by a space, followed by the vector, space separated. I'm going to save them in a simple dictionary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6111" target="_blank">01:41:51.160</a></span> | <span class="t">format, so what I'm going to share with you guys will be the dictionary. So it's a dictionary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6115" target="_blank">01:41:55.360</a></span> | <span class="t">from a word or a phrase to a NumPy array.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6123" target="_blank">01:42:03.920</a></span> | <span class="t">I'm not sure I've used this idea of zip-star before, so I should talk about this a little</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6127" target="_blank">01:42:07.840</a></span> | <span class="t">bit. So if I've got a dictionary which maps from word to vector, how do I get out of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6137" target="_blank">01:42:17.600</a></span> | <span class="t">a list of the words and a list of the vectors? The short answer is like this. But let's think</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6146" target="_blank">01:42:26.420</a></span> | <span class="t">about what that's doing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6147" target="_blank">01:42:27.420</a></span> | <span class="t">So I don't know, we've used zip quite a bit. So normally with zip, you go like zip, list1,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6153" target="_blank">01:42:33.840</a></span> | <span class="t">list2, whatever. And what that returns is an iterator which first of all gives you element1</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6163" target="_blank">01:42:43.800</a></span> | <span class="t">of list1, element1 of list2, element1 of list3, and then element2 of list1, so forth. That's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6169" target="_blank">01:42:49.720</a></span> | <span class="t">what zip normally does.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6173" target="_blank">01:42:53.840</a></span> | <span class="t">There's a nice idea in Python that you can put a star before any argument. And if that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6182" target="_blank">01:43:02.800</a></span> | <span class="t">argument is an iterator, something that you can go through, it acts as if you had taken</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6189" target="_blank">01:43:09.680</a></span> | <span class="t">that whole list and actually put it inside those brackets.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6196" target="_blank">01:43:16.160</a></span> | <span class="t">So let's say that wtov list contained like fox, colon, array, hug, colon, array, and so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6214" target="_blank">01:43:34.000</a></span> | <span class="t">forth. When you go zip-star that, it's the same as actually taking the contents of that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6221" target="_blank">01:43:41.840</a></span> | <span class="t">list and putting them inside there.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6229" target="_blank">01:43:49.780</a></span> | <span class="t">You would want star-star if it was a dictionary star for list?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6234" target="_blank">01:43:54.520</a></span> | <span class="t">Not quite. Star just means you're treating it as an iterator. In this case we are using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6245" target="_blank">01:44:05.840</a></span> | <span class="t">a list, so let's talk about star-star another time. But you're right, in this case we have</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6253" target="_blank">01:44:13.920</a></span> | <span class="t">a list which is actually just in this form, fox, comma, array, hug, comma, array, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6264" target="_blank">01:44:24.160</a></span> | <span class="t">lots more.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6266" target="_blank">01:44:26.160</a></span> | <span class="t">So what this is going to do is when we zip this, it's going to basically take all of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6275" target="_blank">01:44:35.160</a></span> | <span class="t">these things and create one list for those. So this idea of zip-star is something we're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6292" target="_blank">01:44:52.360</a></span> | <span class="t">going to use quite a lot. Honestly I don't normally think about what it's doing, I just</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6298" target="_blank">01:44:58.720</a></span> | <span class="t">know that any time I've got like a list of tuples and I want to turn it into a tuple</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6306" target="_blank">01:45:06.160</a></span> | <span class="t">of lists, you just do zip-star. So that's all that is, it's just a little Python thing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6314" target="_blank">01:45:14.520</a></span> | <span class="t">So this gives us a list of words and a list of vectors. So any time I start looking at</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6320" target="_blank">01:45:20.040</a></span> | <span class="t">some new data, I always want to test it, and so I wanted to make sure this worked the way</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6326" target="_blank">01:45:26.280</a></span> | <span class="t">I thought it ought to work. So one thing I thought was, okay, let's look at the correlation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6330" target="_blank">01:45:30.600</a></span> | <span class="t">coefficient between small j Jeremy and big j Jeremy, and indeed there is some correlation</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6336" target="_blank">01:45:36.200</a></span> | <span class="t">which you would expect, or else the correlation between Jeremy and banana, I hate bananas,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6343" target="_blank">01:45:43.220</a></span> | <span class="t">so I was hoping this would be massively negative. Unfortunately it's not, but it is at least</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6347" target="_blank">01:45:47.240</a></span> | <span class="t">lower than the correlation between Jeremy and big Jeremy.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6350" target="_blank">01:45:50.200</a></span> | <span class="t">So it's not always easy to exactly test data, but try and come up with things that ought</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6356" target="_blank">01:45:56.800</a></span> | <span class="t">to be true and make sure they are true, so in this case this has given me some comfort</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6361" target="_blank">01:46:01.600</a></span> | <span class="t">that these word vectors behave the way I expect them to. Now I don't really care about capitalization,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6369" target="_blank">01:46:09.160</a></span> | <span class="t">so I'll just go ahead and create a lower-cased word2vec dictionary, where I just do the lower-cased</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6375" target="_blank">01:46:15.040</a></span> | <span class="t">version of everything. One trick here is I go through in reverse, because word2vec is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6383" target="_blank">01:46:23.920</a></span> | <span class="t">ordered where the most common words are first, so by going in reverse it means if there is</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6389" target="_blank">01:46:29.800</a></span> | <span class="t">both a capital J Jeremy and a small j Jeremy, the one that's going to end up in my dictionary</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6394" target="_blank">01:46:34.620</a></span> | <span class="t">will be the more common one. So what I want for device is to now get this word vector</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6407" target="_blank">01:46:47.180</a></span> | <span class="t">for each one of our 1000 categories in ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6413" target="_blank">01:46:53.640</a></span> | <span class="t">And then I'm going to go even further than that, because I want to go beyond ImageNet.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6418" target="_blank">01:46:58.880</a></span> | <span class="t">So I actually went and downloaded the original WordNet categories, and I filtered it down</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6425" target="_blank">01:47:05.440</a></span> | <span class="t">to find all the nouns, and I discovered that there are actually 82,000 nouns in WordNet,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6431" target="_blank">01:47:11.400</a></span> | <span class="t">which is quite a few, it's quite fun looking through them.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6434" target="_blank">01:47:14.920</a></span> | <span class="t">So I'm going to create a map of word vectors for every ImageNet category, one set, and</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6441" target="_blank">01:47:21.520</a></span> | <span class="t">every WordNet noun, another set. And so my goal in this project will be to try and create</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6447" target="_blank">01:47:27.080</a></span> | <span class="t">something that can do useful things with the full set of WordNet nouns. We're going to</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6452" target="_blank">01:47:32.320</a></span> | <span class="t">go beyond ImageNet. We've already got the 1000 ImageNet categories, we've used that</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6456" target="_blank">01:47:36.880</a></span> | <span class="t">many times before, so I'll grab those, load them in, and then I'll do the same thing for</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6467" target="_blank">01:47:47.480</a></span> | <span class="t">the full set of WordNet IDs, which I will share with you.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6474" target="_blank">01:47:54.840</a></span> | <span class="t">And so now I can go ahead and create a dictionary which goes through every one of my ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6485" target="_blank">01:48:05.120</a></span> | <span class="t">1000 categories and converts it into the word vector. Notice I have a filter here, and that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6494" target="_blank">01:48:14.400</a></span> | <span class="t">because some of the ImageNet categories won't be in Word2vec, and that's because sometimes</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6504" target="_blank">01:48:24.280</a></span> | <span class="t">the ImageNet categories will say things like hug bracket doc. They won't be exactly in the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6511" target="_blank">01:48:31.040</a></span> | <span class="t">same format. If you wanted to, you could probably get a better match than this, but I found</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6516" target="_blank">01:48:36.720</a></span> | <span class="t">even with this simple approach I managed to match 51,600 out of the 82,000 WordNet nouns,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6524" target="_blank">01:48:44.960</a></span> | <span class="t">which I thought was pretty good.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6528" target="_blank">01:48:48.800</a></span> | <span class="t">So what I did then was I created a list of all of the categories which didn't match,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6535" target="_blank">01:48:55.880</a></span> | <span class="t">and this commented out bit, as you can see, is something which literally just moved those</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6540" target="_blank">01:49:00.800</a></span> | <span class="t">folders out of the way so that they're not in my ImageNet path anymore.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6548" target="_blank">01:49:08.800</a></span> | <span class="t">So the details aren't very important, but hopefully you can see at the end of this process</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6553" target="_blank">01:49:13.240</a></span> | <span class="t">I've got something that maps every ImageNet category to a word vector, at least if I could</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6559" target="_blank">01:49:19.040</a></span> | <span class="t">find it, and every WordNet noun to a vector, at least if I could find it, and that I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6565" target="_blank">01:49:25.520</a></span> | <span class="t">modified my ImageNet data so that the categories I couldn't find moved those folders out of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6575" target="_blank">01:49:35.520</a></span> | <span class="t">the way. Nothing particularly interesting there. And that's because WordNet's not that big.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6586" target="_blank">01:49:46.520</a></span> | <span class="t">It's in RAM, so that's pretty straightforward. The images are a bit harder because we've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6590" target="_blank">01:49:50.520</a></span> | <span class="t">got a million or so images. So we're going to try everything we can to make this RAM</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6597" target="_blank">01:49:57.840</a></span> | <span class="t">as quickly as possible. To start with, even the very process of getting</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6610" target="_blank">01:50:10.120</a></span> | <span class="t">a list of the file names of everything in ImageNet takes a non-trivial amount of time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6616" target="_blank">01:50:16.120</a></span> | <span class="t">So everything that takes a non-trivial amount of time is going to save its output. So the</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6620" target="_blank">01:50:20.960</a></span> | <span class="t">first thing I do is I use glob, I can't remember if we used glob in Part 1, I think we did,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6627" target="_blank">01:50:27.480</a></span> | <span class="t">it's just a thing that's like ls star.start. So we use glob to grab all of the ImageNet</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6636" target="_blank">01:50:36.280</a></span> | <span class="t">training set, and then I just go ahead and pickle.dump that. For various reasons we'll</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6648" target="_blank">01:50:48.640</a></span> | <span class="t">see shortly, it's actually a very good idea though at this point to randomize that list</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6653" target="_blank">01:50:53.600</a></span> | <span class="t">of file names, put them in a random order. The basic idea is later on if we use chunks</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6662" target="_blank">01:51:02.040</a></span> | <span class="t">of file names that are next to each other, they're not all going to be the same type</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6666" target="_blank">01:51:06.920</a></span> | <span class="t">of thing. So by randomizing the file names now it's going to save us a bit of time, so</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6672" target="_blank">01:51:12.080</a></span> | <span class="t">then I can go ahead and save that randomized list. I've given it a different name, so I</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6677" target="_blank">01:51:17.040</a></span> | <span class="t">can always come back to the original.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6680" target="_blank">01:51:20.000</a></span> | <span class="t">So I want to resize all of my images to a constant size. I'm being a bit lazy here,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6685" target="_blank">01:51:25.480</a></span> | <span class="t">I'm going to resize them to 224x224, that's the input size for a lot of models obviously,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6692" target="_blank">01:51:32.640</a></span> | <span class="t">including the one that we're going to use. That would probably be better if we resize</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6699" target="_blank">01:51:39.000</a></span> | <span class="t">to something bigger and then we randomly zoom and crop. Maybe if we have time we'll try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6707" target="_blank">01:51:47.240</a></span> | <span class="t">that later, but for now we're just going to resize everything to 224x224.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6716" target="_blank">01:51:56.000</a></span> | <span class="t">So we have nearly a million images it turns out to resize to 224x224. That could be pretty</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6723" target="_blank">01:52:03.640</a></span> | <span class="t">slow. So I've got some handy tricks to make it much faster. Generally speaking there are</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6732" target="_blank">01:52:12.880</a></span> | <span class="t">three ways to make an algorithm significantly faster.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6742" target="_blank">01:52:22.480</a></span> | <span class="t">The three ways are memory locality, the second is SIMD also known as vectorization. The third</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6771" target="_blank">01:52:51.800</a></span> | <span class="t">is parallel processing. Rachel is very familiar with these because she's currently creating</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6781" target="_blank">01:53:01.920</a></span> | <span class="t">a course for the master students here on numerical linear algebra, which is very heavily about</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6788" target="_blank">01:53:08.480</a></span> | <span class="t">these things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6789" target="_blank">01:53:09.480</a></span> | <span class="t">So these are the three ways you can make data processing faster. Memory locality simply</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6795" target="_blank">01:53:15.160</a></span> | <span class="t">means in your computer you have lots of different kinds of memory. For example, level 1 cache,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6804" target="_blank">01:53:24.160</a></span> | <span class="t">level 2 cache, RAM, solid state disk, regular hard drives, whatever. The difference in speed</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6818" target="_blank">01:53:38.960</a></span> | <span class="t">as you go up from one to the other is generally like 10 times or 100 times or 1000 times slower.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6827" target="_blank">01:53:47.360</a></span> | <span class="t">You really, really, really don't want to go to the next level of the memory hierarchy</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6831" target="_blank">01:53:51.120</a></span> | <span class="t">if you can avoid it. Unfortunately level 1 cache might be more like 16k, level 2 cache</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6838" target="_blank">01:53:58.840</a></span> | <span class="t">might be a few meg, RAM is going to be a few gig, solid state drives is probably going</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6845" target="_blank">01:54:05.600</a></span> | <span class="t">to be a few hundreds of gig, and your hard drives are probably going to be a few terabytes.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6850" target="_blank">01:54:10.640</a></span> | <span class="t">So in reality you've got to be careful about how you manage these things. You want to try</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6855" target="_blank">01:54:15.880</a></span> | <span class="t">and make sure that you're putting stuff in the right place, that you're not filling up</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6861" target="_blank">01:54:21.600</a></span> | <span class="t">the resources unnecessarily, and that if you're going to use a piece of data multiple times,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6869" target="_blank">01:54:29.360</a></span> | <span class="t">try to use it each time, immediately use it again so that it's already in your cache.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6878" target="_blank">01:54:38.000</a></span> | <span class="t">The second thing, which is what we're about to look at, is SIMD, which stands for Single</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6883" target="_blank">01:54:43.140</a></span> | <span class="t">Instruction Multiple Data. Something that a shockingly large number of people even who</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6889" target="_blank">01:54:49.800</a></span> | <span class="t">claim to be professional computer programmers don't know is that every modern CPU is capable</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6897" target="_blank">01:54:57.840</a></span> | <span class="t">of, in a single operation, in a single thread, calculating multiple things at the same time.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6906" target="_blank">01:55:06.200</a></span> | <span class="t">And the way that it does it is that you basically create a little vector, generally about 8 things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6913" target="_blank">01:55:13.200</a></span> | <span class="t">and you put all the things you want to calculate. Let's say you want to take the square root</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6916" target="_blank">01:55:16.200</a></span> | <span class="t">of something. You put 8 things into this little vector, and then you call a particular CPU</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6923" target="_blank">01:55:23.920</a></span> | <span class="t">instruction which takes the square root of 8 floating point numbers that is in this register.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6932" target="_blank">01:55:32.360</a></span> | <span class="t">And it does it in a single clock cycle. So when we say clock cycle, your CPU might be</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6938" target="_blank">01:55:38.000</a></span> | <span class="t">2 or 3 GHz, so it's doing 2 or 3 billion things per second. Well it's not, it's doing 2 or</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6945" target="_blank">01:55:45.940</a></span> | <span class="t">3 billion times 8 things per second if you're using SIMD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6952" target="_blank">01:55:52.680</a></span> | <span class="t">Because so few people are aware of SIMD, and because a lot of programming environments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6957" target="_blank">01:55:57.040</a></span> | <span class="t">don't make it easy to use SIMD, a lot of stuff is not written to take advantage of SIMD,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6963" target="_blank">01:56:03.000</a></span> | <span class="t">including, for example, pretty much all of the image processing in Python.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6968" target="_blank">01:56:08.600</a></span> | <span class="t">However, you can do this. You can go pip install pillow SIMD, and that will replace your pillow,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6978" target="_blank">01:56:18.880</a></span> | <span class="t">and remember pillow is like the main Python imaging library, with a new version that does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6983" target="_blank">01:56:23.800</a></span> | <span class="t">use SIMD for at least some of its things.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6989" target="_blank">01:56:29.440</a></span> | <span class="t">Because SIMD only works on certain CPUs, any vaguely recent CPU works, but because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=6996" target="_blank">01:56:36.560</a></span> | <span class="t">only some, you have to add some special directives to the compiler to tell it, I have this kind</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7003" target="_blank">01:56:43.040</a></span> | <span class="t">of CPU, so please do use these kinds of instructions. And what pillow SIMD does, it actually literally</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7010" target="_blank">01:56:50.360</a></span> | <span class="t">replaces your existing pillow, so that's why you have to say pause/reinstall, because it's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7016" target="_blank">01:56:56.000</a></span> | <span class="t">going to be like, oh you already have a pillow, but this is like, no I want a pillow by SIMD.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7021" target="_blank">01:57:01.160</a></span> | <span class="t">So if you try this, you'll find that the speed of your resize literally goes up by 600%,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7028" target="_blank">01:57:08.280</a></span> | <span class="t">you don't have to change any code. I'm a huge fan of SIMD in general. It's one of the reasons</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7036" target="_blank">01:57:16.960</a></span> | <span class="t">I'm not particularly fond of Python, because it doesn't make it all easy to use SIMD, but</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7044" target="_blank">01:57:24.600</a></span> | <span class="t">luckily some people have written stuff in C which does use SIMD and then provided these</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7049" target="_blank">01:57:29.840</a></span> | <span class="t">Python interfaces.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7051" target="_blank">01:57:31.440</a></span> | <span class="t">Okay, so this is something to remember to try to get working when you go home. Before</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7057" target="_blank">01:57:37.260</a></span> | <span class="t">you do it, write a little benchmark that resizes 1000 images and times it, and then run this</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7063" target="_blank">01:57:43.840</a></span> | <span class="t">command and make sure that it gets 600% faster, that way you know it's actually working.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7071" target="_blank">01:57:51.200</a></span> | <span class="t">We have two questions, I don't know if you want to finish the three ways to do things</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7075" target="_blank">01:57:55.760</a></span> | <span class="t">faster first. One is, how could you get the relation between a pug and a dog and the photo</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7084" target="_blank">01:58:04.600</a></span> | <span class="t">of a pug and its relation to the bigger category of dog?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7089" target="_blank">01:58:09.840</a></span> | <span class="t">Yes, sure, we'll think about that.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7094" target="_blank">01:58:14.560</a></span> | <span class="t">Okay, now there, why do we want to randomize the file names, can't we use shuffle equals</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7101" target="_blank">01:58:21.920</a></span> | <span class="t">true on the Keras flowform directory?</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7106" target="_blank">01:58:26.960</a></span> | <span class="t">The short answer is kind of to do with locality. If you say shuffle equals true, you're jumping</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7112" target="_blank">01:58:32.480</a></span> | <span class="t">from here on the hard disk to here on the hard disk to here on the hard disk, and hard</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7116" target="_blank">01:58:36.640</a></span> | <span class="t">disks take that. Remember there's a spinning disk with a little needle, and the thing's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7121" target="_blank">01:58:41.840</a></span> | <span class="t">moving all over the place. So you want to be getting things that are all on a row. It's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7126" target="_blank">01:58:46.000</a></span> | <span class="t">basically the reason. As you'll see, this is going to basically work for the concept of</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7133" target="_blank">01:58:53.760</a></span> | <span class="t">dog versus pug, because the word vector for dog is very similar to word vector for pug,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7140" target="_blank">01:59:00.080</a></span> | <span class="t">so at the end we'll try it. We'll see if we can find dogs and see if it works. I'm sure</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7147" target="_blank">01:59:07.360</a></span> | <span class="t">it will.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7148" target="_blank">01:59:08.360</a></span> | <span class="t">Finally, parallel processing refers to the fact that any modern CPU has multiple cores,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7158" target="_blank">01:59:18.720</a></span> | <span class="t">which literally means multiple CPUs in your CPU. Often boxes that you buy for home might</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7167" target="_blank">01:59:27.320</a></span> | <span class="t">even have multiple CPUs in them. Again, Python is not great for parallel processing. Python</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7175" target="_blank">01:59:35.120</a></span> | <span class="t">3 is certainly a lot better. But a lot of stuff in Python doesn't use parallel processing</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7179" target="_blank">01:59:39.800</a></span> | <span class="t">very effectively. But a lot of modern CPUs have 10 cores or more, even for consumer CPU.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7189" target="_blank">01:59:49.320</a></span> | <span class="t">So if you're not using parallel processing, you're missing out on a 10x speedup. If you're</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7194" target="_blank">01:59:54.640</a></span> | <span class="t">not using SAMD, you're missing out on a 6-8x speedup. So if you can do both of these things,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7202" target="_blank">02:00:02.280</a></span> | <span class="t">you can get 50+. I mean you will, you'll get 50+ speedup, assuming your CPU has enough cores.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7210" target="_blank">02:00:10.080</a></span> | <span class="t">So we're going to do both. To get SAMD, we're just going to install it. To get parallel</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7214" target="_blank">02:00:14.560</a></span> | <span class="t">processing, we're probably not going to see all of it today, but we're going to be using</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7218" target="_blank">02:00:18.160</a></span> | <span class="t">parallel processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7221" target="_blank">02:00:21.720</a></span> | <span class="t">I define a few things to do my resizing. One thing is I've actually recently changed how</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7231" target="_blank">02:00:31.680</a></span> | <span class="t">I do resizing. As I'm sure you guys have noticed, in the past when I've resized things to square,</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7236" target="_blank">02:00:36.760</a></span> | <span class="t">I've tended to add a black border to the bottom or a black border to the right, because that's</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7242" target="_blank">02:00:42.680</a></span> | <span class="t">what Keras did. Now that I've looked into it, no best practice papers, capital results</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7251" target="_blank">02:00:51.240</a></span> | <span class="t">in a thing used that way.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7252" target="_blank">02:00:52.600</a></span> | <span class="t">And it makes perfect sense because CNN is going to have to learn to deal with the black</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7257" target="_blank">02:00:57.600</a></span> | <span class="t">border. You're throwing away all that information. What pretty much all the best practice approaches</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7264" target="_blank">02:01:04.760</a></span> | <span class="t">is to rather than rescale the longest side to be the size of your square and then fill</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7272" target="_blank">02:01:12.240</a></span> | <span class="t">it in with black, instead take the smallest side and make that the size of your square.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7278" target="_blank">02:01:18.960</a></span> | <span class="t">The other side's now too big, so just chop off the top and bottom, or chop off the right</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7283" target="_blank">02:01:23.680</a></span> | <span class="t">or right and left. That's called center cropping. So resizing and center cropping. What I've</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7291" target="_blank">02:01:31.080</a></span> | <span class="t">done here is I've got something which resizes to the size of the shortest side, and then</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7300" target="_blank">02:01:40.760</a></span> | <span class="t">over here I've got something which does the center cropping. You can look at the details</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7311" target="_blank">02:01:51.040</a></span> | <span class="t">when you get home if you like, it's not particularly exciting, so I've got something that does</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7315" target="_blank">02:01:55.600</a></span> | <span class="t">the resizing. This is something you can improve. Currently I'm making sure that it's a three</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7322" target="_blank">02:02:02.080</a></span> | <span class="t">channel image, so I'm not doing a black and white or something with an alpha channel.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7332" target="_blank">02:02:12.600</a></span> | <span class="t">So before I finish up, next time when we start is we're going to learn about parallel processing.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7342" target="_blank">02:02:22.560</a></span> | <span class="t">So anybody who's interested in pre-reading, feel free to start reading and playing around</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7348" target="_blank">02:02:28.040</a></span> | <span class="t">with Python parallel processing. Thanks everybody, see you next week. I hope your assignments</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7354" target="_blank">02:02:34.320</a></span> | <span class="t">go really well, and let me know if I can help you out in the forum.</span></div><div class="c"><span class="s"><a href="https://www.youtube.com/watch?v=I-P363wSv0Q&t=7356" target="_blank">02:02:36.800</a></span> | <span class="t">[applause]</span></div></div></body></html>